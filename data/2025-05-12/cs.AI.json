{
  "date": "2025-05-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-12 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型优化、多模态处理和应用创新等领域，亮点包括 LLM 的自提升机制、机器人强化学习进展，以及多模态融合在医学和知识图谱中的潜力，由知名学者如 Chelsea Finn 和 Jiawei Han 等推动的文章令人印象深刻。\n\n### 重点论文讨论\n我们先聊聊几篇重要且有话题度的论文，这些涉及 LLM 自提升、机器人学习和多模态知识蒸馏等领域，展示了 AI 领域的核心进展。相关论文按主题归类，以突出贡献。\n\n**LLM 自提升与安全（Self Rewarding Self Improving 和相关）**  \n- **Self Rewarding Self Improving（自我奖励自我提升）**：这篇论文由 Toby Simonds 等作者提出，展示了大型语言模型无需参考解决方案即可通过自我判断实现性能提升，主要贡献是通过强化学习在无答案领域生成可靠奖励信号，实现 8% 的性能改进，并超越 GPT-4o，在数据稀缺领域加速 AI 自主学习。  \n- **FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs（FalseReject: 用于提升 LLM 上下文安全性和缓解过度拒绝的资源）**：作者包括 Jiashen Du 等，该工作构建了一个 16k 查询数据集，通过图结构化框架减少 LLM 的过度拒绝，同时保持安全性和语言能力，主要发现是监督微调能显著降低不必要拒绝，同时在 29 个 SOTA 模型上验证了其有效性。\n\n**机器人与强化学习（What Matters for Batch Online Reinforcement Learning in Robotics? 和相关）**  \n- **What Matters for Batch Online Reinforcement Learning in Robotics?（机器人批量在线强化学习的关键因素）**：由 Chelsea Finn 等知名学者撰写，该论文通过系统实验分析了算法类、策略提取和策略表达性对机器人学习的影响，主要贡献是提出使用 Q 函数指导学习和隐式策略提取方法，提升性能并减少数据需求，在模拟和真实任务中表现出色。  \n- **Multi-source Plume Tracing via Multi-Agent Reinforcement Learning（通过多代理强化学习的多源羽流追踪）**：作者包括 Jane Cleland-Huang 等，该工作使用 LSTM-based 算法在复杂环境中定位污染源，主要发现是代理只需探索环境 1.29% 即可成功定位，显著优于传统方法。\n\n**多模态与知识蒸馏（Simple Semi-supervised Knowledge Distillation from Vision-Language Models 和相关）**  \n- **Simple Semi-supervised Knowledge Distillation from Vision-Language Models via Dual-Head Optimization（通过双头优化实现的简单半监督视觉-语言模型知识蒸馏）**：作者包括 Sung Ju Hwang 等，该论文提出双头优化框架，结合监督和蒸馏信号提升模型性能，主要贡献是显著提高图像分类准确率（在 ImageNet 上提升 3%），并在多模态任务中表现出色。  \n- **Benchmarking Retrieval-Augmented Generation for Chemistry（化学领域的检索增强生成基准）**：由 Jiawei Han 等作者领导，该工作构建了化学领域的 RAG 基准数据集，主要发现是结合多种检索算法能显著提升生成准确性，在知识密集任务中提供实用指导。\n\n其他论文涉及领域广泛，如医学 AI、图神经网络和生成模型，但许多是次要或技术细节导向的，这里快速掠过。例如，**Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories（基于 WiFi 轨迹的图神经网络节点嵌入和聚类楼层分离）** 提出了一种室内定位方法，准确率达 68.97%，但应用场景较窄；**Latent Behavior Diffusion for Sequential Reaction Generation in Dyadic Setting（双人设置下序列反应生成的潜在行为扩散）** 探索了人脸反应生成，但影响力有限。这些论文的核心术语如 Node2Vec 和 K-means 保留，但不展开讨论，以控制篇幅。\n\n总之，今天的论文突显了 AI 向更智能、更高效方向的演进，值得关注领域从业者深入阅读。明天的快报，我们将继续追踪最新动态！",
  "papers": [
    {
      "arxiv_id": "2505.08827v1",
      "title": "Self Rewarding Self Improving",
      "title_zh": "自我奖励自我改进",
      "authors": [
        "Toby Simonds",
        "Kevin Lopez",
        "Akira Yoshiyama",
        "Dominique Garmier"
      ],
      "abstract": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements.",
      "tldr_zh": "本研究证明，大型语言模型（LLMs）可以通过自我判断（self-judging）机制实现自我改进，利用生成和验证解决方案的非对称性，而无需参考答案。实验在 Countdown puzzles 和 MIT Integration Bee problems 上显示，LLMs 能提供可靠的奖励信号，支持强化学习（reinforcement learning），并与合成问题生成（synthetic question generation）结合，形成完整的自我改进循环。结果表明，该方法使 Qwen 2.5 7B 模型比基线提升 8%，并在积分任务上超越 GPT-4o。总体上，这开启了 LLMs 作为评判者的新范式，推动 AI 系统通过自我导向学习持续进步，尤其适用于数据稀缺或评估复杂的领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08827v1",
      "published_date": "2025-05-12 23:51:04 UTC",
      "updated_date": "2025-05-12 23:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:52:21.557235"
    },
    {
      "arxiv_id": "2505.08124v1",
      "title": "SLAG: Scalable Language-Augmented Gaussian Splatting",
      "title_zh": "SLAG: 可扩展语言增强高斯喷溅",
      "authors": [
        "Laszlo Szilagyi",
        "Francis Engelmann",
        "Jeannette Bohg"
      ],
      "abstract": "Language-augmented scene representations hold great promise for large-scale\nrobotics applications such as search-and-rescue, smart cities, and mining. Many\nof these scenarios are time-sensitive, requiring rapid scene encoding while\nalso being data-intensive, necessitating scalable solutions. Deploying these\nrepresentations on robots with limited computational resources further adds to\nthe challenge. To address this, we introduce SLAG, a multi-GPU framework for\nlanguage-augmented Gaussian splatting that enhances the speed and scalability\nof embedding large scenes. Our method integrates 2D visual-language model\nfeatures into 3D scenes using SAM and CLIP. Unlike prior approaches, SLAG\neliminates the need for a loss function to compute per-Gaussian language\nembeddings. Instead, it derives embeddings from 3D Gaussian scene parameters\nvia a normalized weighted average, enabling highly parallelized scene encoding.\nAdditionally, we introduce a vector database for efficient embedding storage\nand retrieval. Our experiments show that SLAG achieves an 18 times speedup in\nembedding computation on a 16-GPU setup compared to OpenGaussian, while\npreserving embedding quality on the ScanNet and LERF datasets. For more\ndetails, visit our project website: https://slag-project.github.io/.",
      "tldr_zh": "该研究提出 SLAG，一种可扩展的语言增强 Gaussian Splatting 框架，旨在为大规模机器人应用（如搜索救援和智能城市）提供快速且高效的场景编码，尤其适用于计算资源有限的设备。SLAG 通过整合 2D 视觉语言模型特征（如 SAM 和 CLIP）到 3D 场景中，并采用归一化加权平均从 3D Gaussian 场景参数派生嵌入，避免了传统损失函数计算，实现高度并行化处理和多 GPU 支持。实验结果表明，SLAG 在 16 GPU 设置下比 OpenGaussian 快 18 倍，同时在 ScanNet 和 LERF 数据集上保持嵌入质量，为实时语言增强场景表示奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08124v1",
      "published_date": "2025-05-12 23:32:24 UTC",
      "updated_date": "2025-05-12 23:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:52:33.988082"
    },
    {
      "arxiv_id": "2505.08123v1",
      "title": "JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections",
      "title_zh": "翻译失败",
      "authors": [
        "Qing Wu",
        "Hongjiang Wei",
        "Jingyi Yu",
        "S. Kevin Zhou",
        "Yuyao Zhang"
      ],
      "abstract": "Multi-material decomposition (MMD) enables quantitative reconstruction of\ntissue compositions in the human body, supporting a wide range of clinical\napplications. However, traditional MMD typically requires spectral CT scanners\nand pre-measured X-ray energy spectra, significantly limiting clinical\napplicability. To this end, various methods have been developed to perform MMD\nusing conventional (i.e., single-energy, SE) CT systems, commonly referred to\nas SEMMD. Despite promising progress, most SEMMD methods follow a two-step\nimage decomposition pipeline, which first reconstructs monochromatic CT images\nusing algorithms such as FBP, and then performs decomposition on these images.\nThe initial reconstruction step, however, neglects the energy-dependent\nattenuation of human tissues, introducing severe nonlinear beam hardening\nartifacts and noise into the subsequent decomposition. This paper proposes\nJSover, a fundamentally reformulated one-step SEMMD framework that jointly\nreconstructs multi-material compositions and estimates the energy spectrum\ndirectly from SECT projections. By explicitly incorporating physics-informed\nspectral priors into the SEMMD process, JSover accurately simulates a virtual\nspectral CT system from SE acquisitions, thereby improving the reliability and\naccuracy of decomposition. Furthermore, we introduce implicit neural\nrepresentation (INR) as an unsupervised deep learning solver for representing\nthe underlying material maps. The inductive bias of INR toward continuous image\npatterns constrains the solution space and further enhances estimation quality.\nExtensive experiments on both simulated and real CT datasets show that JSover\noutperforms state-of-the-art SEMMD methods in accuracy and computational\nefficiency.",
      "tldr_zh": "本研究针对多材料分解 (MMD) 在临床应用中的局限性，提出了一种新型框架 JSover，用于从单能 CT (SECT) 投影中联合估计能量谱和进行多材料分解。该框架采用一体的处理方法，整合基于物理的 spectral priors 和 implicit neural representation (INR) 作为无监督深度学习求解器，从而模拟虚拟光谱 CT 系统，减少 beam hardening 伪影和噪声，提高分解的准确性和可靠性。与传统两步 SEMMD 方法相比，JSover 通过 INR 的归纳偏差约束解空间，进一步提升了计算效率。在模拟和真实 CT 数据集上的实验显示，JSover 在准确性上优于现有最先进方法，并显著提高了整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08123v1",
      "published_date": "2025-05-12 23:32:21 UTC",
      "updated_date": "2025-05-12 23:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:52:45.378023"
    },
    {
      "arxiv_id": "2505.08106v1",
      "title": "Are LLMs complicated ethical dilemma analyzers?",
      "title_zh": "LLMs 是否是复杂的伦理困境分析器？",
      "authors": [
        "Jiashen",
        "Du",
        "Jesse Yao",
        "Allen Liu",
        "Zhekai Zhang"
      ],
      "abstract": "One open question in the study of Large Language Models (LLMs) is whether\nthey can emulate human ethical reasoning and act as believable proxies for\nhuman judgment. To investigate this, we introduce a benchmark dataset\ncomprising 196 real-world ethical dilemmas and expert opinions, each segmented\ninto five structured components: Introduction, Key Factors, Historical\nTheoretical Perspectives, Resolution Strategies, and Key Takeaways. We also\ncollect non-expert human responses for comparison, limited to the Key Factors\nsection due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini,\nClaude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric\nframework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine\nsimilarity, and Universal Sentence Encoder similarity. Metric weights are\ncomputed through an inversion-based ranking alignment and pairwise AHP\nanalysis, enabling fine-grained comparison of model outputs to expert\nresponses. Our results show that LLMs generally outperform non-expert humans in\nlexical and structural alignment, with GPT-4o-mini performing most consistently\nacross all sections. However, all models struggle with historical grounding and\nproposing nuanced resolution strategies, which require contextual abstraction.\nHuman responses, while less structured, occasionally achieve comparable\nsemantic similarity, suggesting intuitive moral reasoning. These findings\nhighlight both the strengths and current limitations of LLMs in ethical\ndecision-making.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能模拟人类道德推理并充当人类判断的代理，通过引入一个包含196个真实道德困境的基准数据集，每个困境分为Introduction、Key Factors、Historical Theoretical Perspectives、Resolution Strategies和Key Takeaways等部分。研究评估了GPT-4o-mini、Claude-3.5-Sonnet、Deepseek-V3和Gemini-1.5-Flash等模型，使用BLEU、Damerau-Levenshtein distance、TF-IDF cosine similarity和Universal Sentence Encoder similarity的复合指标框架，并通过inversion-based ranking alignment和pairwise AHP analysis计算权重。结果显示，LLMs在词汇和结构对齐上优于非专家人类响应，特别是GPT-4o-mini表现最稳定，但所有模型在历史背景和细致解决策略上存在困难，而人类响应虽结构较弱，却有时显示出直观的语义相似性，突显了LLMs在道德决策中的优势与局限。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "CS194-280 Advanced LLM Agents project. Project page:\n  https://github.com/ALT-JS/ethicaLLM",
      "pdf_url": "http://arxiv.org/pdf/2505.08106v1",
      "published_date": "2025-05-12 22:35:07 UTC",
      "updated_date": "2025-05-12 22:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:52:57.860449"
    },
    {
      "arxiv_id": "2505.08088v1",
      "title": "Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Rabia Yasa Kostas",
        "Kahraman Kostas"
      ],
      "abstract": "Indoor positioning systems (IPSs) are increasingly vital for location-based\nservices in complex multi-storey environments. This study proposes a novel\ngraph-based approach for floor separation using Wi-Fi fingerprint trajectories,\naddressing the challenge of vertical localization in indoor settings. We\nconstruct a graph where nodes represent Wi-Fi fingerprints, and edges are\nweighted by signal similarity and contextual transitions. Node2Vec is employed\nto generate low-dimensional embeddings, which are subsequently clustered using\nK-means to identify distinct floors. Evaluated on the Huawei University\nChallenge 2021 dataset, our method outperforms traditional community detection\nalgorithms, achieving an accuracy of 68.97%, an F1- score of 61.99%, and an\nAdjusted Rand Index of 57.19%. By publicly releasing the preprocessed dataset\nand implementation code, this work contributes to advancing research in indoor\npositioning. The proposed approach demonstrates robustness to signal noise and\narchitectural complexities, offering a scalable solution for floor-level\nlocalization.",
      "tldr_zh": "这篇论文提出了一种基于图的楼层分离方法，使用 Wi-Fi fingerprints 轨迹来解决室内定位系统（IPSs）在多层建筑中的垂直定位挑战。方法包括构建一个图（节点为 Wi-Fi fingerprints，边基于信号相似度和上下文转换加权）、利用 Node2Vec 生成低维节点嵌入，然后通过 K-means 聚类来识别不同楼层。在 Huawei University Challenge 2021 数据集上，该方法比传统社区检测算法表现出色，达到 68.97% 准确率、61.99% F1-score 和 57.19% Adjusted Rand Index。该方法显示出对信号噪声和建筑复杂性的鲁棒性，并通过公开预处理数据集和代码，促进了室内定位研究的进展。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08088v1",
      "published_date": "2025-05-12 21:46:36 UTC",
      "updated_date": "2025-05-12 21:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:53:10.076392"
    },
    {
      "arxiv_id": "2505.08825v1",
      "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Antonio Alarcon Granadeno",
        "Theodore Chambers",
        "Jane Cleland-Huang"
      ],
      "abstract": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon\ngas leak (2015) demonstrate the urgent need for rapid and reliable plume\ntracing algorithms to protect public health and the environment. Traditional\nmethods, such as gradient-based or biologically inspired approaches, often fail\nin realistic, turbulent conditions. To address these challenges, we present a\nMulti-Agent Reinforcement Learning (MARL) algorithm designed for localizing\nmultiple airborne pollution sources using a swarm of small uncrewed aerial\nsystems (sUAS). Our method models the problem as a Partially Observable Markov\nGame (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific\nDouble Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical\naction-observation pairs, effectively approximating latent states. Unlike prior\nwork, we use a general-purpose simulation environment based on the Gaussian\nPlume Model (GPM), incorporating realistic elements such as a three-dimensional\nenvironment, sensor noise, multiple interacting agents, and multiple plume\nsources. The incorporation of action histories as part of the inputs further\nenhances the adaptability of our model in complex, partially observable\nenvironments. Extensive simulations show that our algorithm significantly\noutperforms conventional approaches. Specifically, our model allows agents to\nexplore only 1.29\\% of the environment to successfully locate pollution\nsources.",
      "tldr_zh": "该研究针对工业灾难如 Bhopal 事件引发的烟羽追踪需求，提出一种基于 Multi-Agent Reinforcement Learning (MARL) 的算法，用于利用小型无人驾驶飞机 (sUAS) 群定位多个空气污染源，以应对传统梯度或生物启发方法在湍流环境中的不足。算法将问题建模为 Partially Observable Markov Game (POMG)，并采用 Long Short-Term Memory (LSTM)-based Action-specific Double Deep Recurrent Q-Network (ADDRQN)，通过整合行动-观察历史序列来近似潜在状态，并在 Gaussian Plume Model (GPM) 模拟环境中纳入三维现实因素如传感器噪声和多智能体交互。实验结果显示，该方法显著优于传统方法，仅需探索环境 1.29% 即可成功定位污染源，为高效的公共健康和环境保护提供可靠解决方案。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08825v1",
      "published_date": "2025-05-12 21:33:15 UTC",
      "updated_date": "2025-05-12 21:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:53:22.108614"
    },
    {
      "arxiv_id": "2505.08082v1",
      "title": "Fréchet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids",
      "title_zh": "Fréchet 电力场景距离：一种用于评估智能电网中生成式 AI 模型的",
      "authors": [
        "Yuting Cai",
        "Shaohuai Liu",
        "Chao Tian",
        "Le Xie"
      ],
      "abstract": "Generative artificial intelligence (AI) models in smart grids have advanced\nsignificantly in recent years due to their ability to generate large amounts of\nsynthetic data, which would otherwise be difficult to obtain in the real world\ndue to confidentiality constraints. A key challenge in utilizing such synthetic\ndata is how to assess the data quality produced from such generative models.\nTraditional Euclidean distance-based metrics only reflect pair-wise relations\nbetween two individual samples, and could fail in evaluating quality\ndifferences between groups of synthetic datasets. In this work, we propose a\nnovel metric based on the Fr\\'{e}chet Distance (FD) estimated between two\ndatasets in a learned feature space. The proposed method evaluates the quality\nof generation from a distributional perspective. Empirical results demonstrate\nthe superiority of the proposed metric across timescales and models, enhancing\nthe reliability of data-driven decision-making in smart grid operations.",
      "tldr_zh": "智能电网中，生成式AI模型可生成大量合成数据以弥补真实数据的获取限制，但传统Euclidean distance指标仅关注样本间配对关系，无法有效评估数据集组的质量差异。本文提出Fréchet Power-Scenario Distance，一种基于Fréchet Distance的度量方法，通过在学习特征空间评估两个数据集的分布差异，从整体视角提升生成质量评估。实证结果表明，该指标在多个时间尺度和社会模型上表现出优越性，提高了智能电网数据驱动决策的可靠性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08082v1",
      "published_date": "2025-05-12 21:32:23 UTC",
      "updated_date": "2025-05-12 21:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:53:33.438977"
    },
    {
      "arxiv_id": "2505.08080v1",
      "title": "Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Shu",
        "Xuansheng Wu",
        "Haiyan Zhao",
        "Mengnan Du",
        "Ninghao Liu"
      ],
      "abstract": "Sparse Autoencoders (SAEs) have recently emerged as powerful tools for\ninterpreting and steering the internal representations of large language models\n(LLMs). However, conventional approaches to analyzing SAEs typically rely\nsolely on input-side activations, without considering the causal influence\nbetween each latent feature and the model's output. This work is built on two\nkey hypotheses: (1) activated latents do not contribute equally to the\nconstruction of the model's output, and (2) only latents with high causal\ninfluence are effective for model steering. To validate these hypotheses, we\npropose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method\nthat identifies the most influential latents by incorporating output-side\ngradient information.",
      "tldr_zh": "本研究发现，传统Sparse Autoencoders (SAEs) 在解释和操控大型语言模型 (LLMs) 的内部表示时，仅依赖输入端激活，而忽略了潜在特征 (latent features) 对模型输出的因果影响。论文基于两个关键假设——激活的潜在特征对输出贡献不均等，且仅高因果影响的特征才适用于模型操控——提出了一种简单有效的Gradient Sparse Autoencoder (GradSAE) 方法，通过整合输出端的梯度信息来识别最有影响力的潜在特征。该方法验证了这些假设，并为提升LLMs 的可解释性和操控效果提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08080v1",
      "published_date": "2025-05-12 21:29:12 UTC",
      "updated_date": "2025-05-12 21:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:53:45.164186"
    },
    {
      "arxiv_id": "2505.08078v1",
      "title": "What Matters for Batch Online Reinforcement Learning in Robotics?",
      "title_zh": "翻译失败",
      "authors": [
        "Perry Dong",
        "Suvir Mirchandani",
        "Dorsa Sadigh",
        "Chelsea Finn"
      ],
      "abstract": "The ability to learn from large batches of autonomously collected data for\npolicy improvement -- a paradigm we refer to as batch online reinforcement\nlearning -- holds the promise of enabling truly scalable robot learning by\nsignificantly reducing the need for human effort of data collection while\ngetting benefits from self-improvement. Yet, despite the promise of this\nparadigm, it remains challenging to achieve due to algorithms not being able to\nlearn effectively from the autonomous data. For example, prior works have\napplied imitation learning and filtered imitation learning methods to the batch\nonline RL problem, but these algorithms often fail to efficiently improve from\nthe autonomously collected data or converge quickly to a suboptimal point. This\nraises the question of what matters for effective batch online RL in robotics.\nMotivated by this question, we perform a systematic empirical study of three\naxes -- (i) algorithm class, (ii) policy extraction methods, and (iii) policy\nexpressivity -- and analyze how these axes affect performance and scaling with\nthe amount of autonomous data. Through our analysis, we make several\nobservations. First, we observe that the use of Q-functions to guide batch\nonline RL significantly improves performance over imitation-based methods.\nBuilding on this, we show that an implicit method of policy extraction -- via\nchoosing the best action in the distribution of the policy -- is necessary over\ntraditional policy extraction methods from offline RL. Next, we show that an\nexpressive policy class is preferred over less expressive policy classes. Based\non this analysis, we propose a general recipe for effective batch online RL. We\nthen show a simple addition to the recipe of using temporally-correlated noise\nto obtain more diversity results in further performance gains. Our recipe\nobtains significantly better performance and scaling compared to prior methods.",
      "tldr_zh": "这篇论文探讨了批量在线强化学习（batch online reinforcement learning）在机器人领域的关键因素，旨在通过自主收集的数据实现政策改进并减少人类干预。作者通过系统实证研究分析了三个轴：(i) 算法类，(ii) 政策提取方法，以及(iii) 政策表达性，发现使用 Q-functions 指导算法比模仿学习方法更有效，隐式政策提取（如从政策分布中选择最佳动作）比传统方法必要，且更具表达性的政策类能显著提升性能。基于这些观察，论文提出一个通用配方，并通过添加时间相关噪声来增加数据多样性，进一步改善算法的表现和扩展性。最终，结果显示该方法在性能和数据规模上优于现有方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08078v1",
      "published_date": "2025-05-12 21:24:22 UTC",
      "updated_date": "2025-05-12 21:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:53:57.514062"
    },
    {
      "arxiv_id": "2505.08073v1",
      "title": "Explainable Reinforcement Learning Agents Using World Models",
      "title_zh": "使用世界模型的可解释强化学习代理",
      "authors": [
        "Madhuri Singh",
        "Amal Alabdulkarim",
        "Gennie Mansi",
        "Mark O. Riedl"
      ],
      "abstract": "Explainable AI (XAI) systems have been proposed to help people understand how\nAI systems produce outputs and behaviors. Explainable Reinforcement Learning\n(XRL) has an added complexity due to the temporal nature of sequential\ndecision-making. Further, non-AI experts do not necessarily have the ability to\nalter an agent or its policy. We introduce a technique for using World Models\nto generate explanations for Model-Based Deep RL agents. World Models predict\nhow the world will change when actions are performed, allowing for the\ngeneration of counterfactual trajectories. However, identifying what a user\nwanted the agent to do is not enough to understand why the agent did something\nelse. We augment Model-Based RL agents with a Reverse World Model, which\npredicts what the state of the world should have been for the agent to prefer a\ngiven counterfactual action. We show that explanations that show users what the\nworld should have been like significantly increase their understanding of the\nagent policy. We hypothesize that our explanations can help users learn how to\ncontrol the agents execution through by manipulating the environment.",
      "tldr_zh": "该研究提出了一种使用 World Models 生成解释的技术，旨在提升 Explainable Reinforcement Learning (XRL) 代理的可解释性，特别是针对序列决策的复杂性。方法通过 World Models 预测动作后的世界变化生成反事实轨迹 (counterfactual trajectories)，并引入 Reverse World Model 来预测代理偏好特定动作所需的世界状态，从而帮助用户理解代理行为。实验结果显示，这种解释方法显著提高了非AI专家对代理策略的理解，并假设能帮助用户通过操纵环境来控制代理执行。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The paper content spans 7 pages, followed by a page of references. It\n  contains 7 figures and 2 small tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08073v1",
      "published_date": "2025-05-12 21:18:31 UTC",
      "updated_date": "2025-05-12 21:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:54:09.567492"
    },
    {
      "arxiv_id": "2505.08823v1",
      "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits",
      "title_zh": "翻译失败",
      "authors": [
        "Cody Steinmetz",
        "Gavin Childress",
        "Aaron Herbst",
        "Gavin Jones",
        "Jasdeep Singh",
        "Eli Vang",
        "Keagan Weinstock"
      ],
      "abstract": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical.",
      "tldr_zh": "大语言模型 (LLMs) 的部署成本高，量化技术可减少内存和计算开销，但三元 (2-bit) 量化往往不稳定且影响准确率。本文提出一种简单方法：在每个线性投影前插入额外的 RMSNorm，并应用渐进的层-wise 量化时间表，稳定地微调全精度检查点为 1.58 位 LLMs。该方法无需增加模型复杂度，即可在标准语言建模基准上匹配或超过复杂的知识蒸馏管道。结果表明，仔细的归一化可显著缩小三元量化模型与全精度模型的准确率差距，使超低位推理变得实用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08823v1",
      "published_date": "2025-05-12 21:14:29 UTC",
      "updated_date": "2025-05-12 21:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:54:21.971031"
    },
    {
      "arxiv_id": "2505.08064v1",
      "title": "Justified Evidence Collection for Argument-based AI Fairness Assurance",
      "title_zh": "翻译失败",
      "authors": [
        "Alpay Sabuncuoglu",
        "Christopher Burr",
        "Carsten Maple"
      ],
      "abstract": "It is well recognised that ensuring fair AI systems is a complex\nsociotechnical challenge, which requires careful deliberation and continuous\noversight across all stages of a system's lifecycle, from defining requirements\nto model deployment and deprovisioning. Dynamic argument-based assurance cases,\nwhich present structured arguments supported by evidence, have emerged as a\nsystematic approach to evaluating and mitigating safety risks and hazards in\nAI-enabled system development and have also been extended to deal with broader\nnormative goals such as fairness and explainability. This paper introduces a\nsystems-engineering-driven framework, supported by software tooling, to\noperationalise a dynamic approach to argument-based assurance in two stages. In\nthe first stage, during the requirements planning phase, a multi-disciplinary\nand multi-stakeholder team define goals and claims to be established (and\nevidenced) by conducting a comprehensive fairness governance process. In the\nsecond stage, a continuous monitoring interface gathers evidence from existing\nartefacts (e.g. metrics from automated tests), such as model, data, and use\ncase documentation, to support these arguments dynamically. The framework's\neffectiveness is demonstrated through an illustrative case study in finance,\nwith a focus on supporting fairness-related arguments.",
      "tldr_zh": "该论文提出一个基于系统工程的框架，用于操作化动态的 argument-based assurance，确保AI系统的公平性。该框架分为两个阶段：首先，在需求规划阶段，由多学科多利益相关者团队通过全面的公平治理过程定义目标和声明；其次，通过持续监控接口从现有工件（如自动化测试指标、模型和数据文档）动态收集证据，支持这些论点。该框架的有效性通过一个金融领域的案例研究得到验证，重点在于增强公平相关的论点和证据收集。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "The paper is accepted for ACM Conference on Fairness, Accountability,\n  and Transparency (ACM FAccT '25)",
      "pdf_url": "http://arxiv.org/pdf/2505.08064v1",
      "published_date": "2025-05-12 21:05:33 UTC",
      "updated_date": "2025-05-12 21:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:54:32.253806"
    },
    {
      "arxiv_id": "2505.08054v1",
      "title": "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning",
      "title_zh": "FalseReject：一种通过结构化推理改善LLMs中上下文安全并缓解过度拒绝的资源",
      "authors": [
        "Zhehao Zhang",
        "Weijie Xu",
        "Fanyou Wu",
        "Chandan K. Reddy"
      ],
      "abstract": "Safety alignment approaches in large language models (LLMs) often lead to the\nover-refusal of benign queries, significantly diminishing their utility in\nsensitive scenarios. To address this challenge, we introduce FalseReject, a\ncomprehensive resource containing 16k seemingly toxic queries accompanied by\nstructured responses across 44 safety-related categories. We propose a\ngraph-informed adversarial multi-agent interaction framework to generate\ndiverse and complex prompts, while structuring responses with explicit\nreasoning to aid models in accurately distinguishing safe from unsafe contexts.\nFalseReject includes training datasets tailored for both standard\ninstruction-tuned models and reasoning-oriented models, as well as a\nhuman-annotated benchmark test set. Our extensive benchmarking on 29\nstate-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges.\nEmpirical results demonstrate that supervised finetuning with FalseReject\nsubstantially reduces unnecessary refusals without compromising overall safety\nor general language capabilities.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)中安全对齐导致的过度拒绝问题，引入了FalseReject资源，该资源包含16k个看似toxic的查询和44个安全相关类别的结构化响应，以帮助模型更好地区分安全上下文。研究提出了一种基于graph-informed adversarial multi-agent interaction框架的方法，通过生成多样化的复杂提示并添加显式推理来构建响应，从而减少不必要的拒绝。实验结果显示，在29个SOTA LLMs上基准测试后，使用FalseReject进行监督微调显著降低了过度拒绝率，同时维持了整体安全性和语言能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08054v1",
      "published_date": "2025-05-12 20:45:25 UTC",
      "updated_date": "2025-05-12 20:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:54:44.567131"
    },
    {
      "arxiv_id": "2505.08052v1",
      "title": "NAZM: Network Analysis of Zonal Metrics in Persian Poetic Tradition",
      "title_zh": "翻译失败",
      "authors": [
        "Kourosh Shahnazari",
        "Seyed Moein Ayyoubzadeh"
      ],
      "abstract": "This study formalizes a computational model to simulate classical Persian\npoets' dynamics of influence through constructing a multi-dimensional\nsimilarity network. Using a rigorously curated dataset based on Ganjoor's\ncorpus, we draw upon semantic, lexical, stylistic, thematic, and metrical\nfeatures to demarcate each poet's corpus. Each is contained within weighted\nsimilarity matrices, which are then appended to generate an aggregate graph\nshowing poet-to-poet influence. Further network investigation is carried out to\nidentify key poets, style hubs, and bridging poets by calculating degree,\ncloseness, betweenness, eigenvector, and Katz centrality measures. Further, for\ntypological insight, we use the Louvain community detection algorithm to\ndemarcate clusters of poets sharing both style and theme coherence, which\ncorrespond closely to acknowledged schools of literature like Sabk-e Hindi,\nSabk-e Khorasani, and the Bazgasht-e Adabi phenomenon. Our findings provide a\nnew data-driven view of Persian literature distinguished between canonical\nsignificance and interextual influence, thus highlighting relatively\nlesser-known figures who hold great structural significance. Combining\ncomputational linguistics with literary study, this paper produces an\ninterpretable and scalable model for poetic tradition, enabling retrospective\nreflection as well as forward-looking research within digital humanities.",
      "tldr_zh": "本研究通过构建多维相似性网络，模拟古典波斯诗人的影响动态，使用Ganjoor语料库的精选数据集，基于语义、词汇、风格、主题和韵律特征生成加权矩阵。研究计算了degree、closeness、betweenness、eigenvector和Katz centrality等指标，并应用Louvain community detection算法，识别关键诗人、风格中心、桥梁诗人以及对应文学流派的集群，如Sabk-e Hindi和Sabk-e Khorasani。结果提供了一个数据驱动的视角，区分规范意义与互文影响，突出了结构上重要的较不著名诗人，并为数字人文领域创建了一个可解释且可扩展的模型。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08052v1",
      "published_date": "2025-05-12 20:39:53 UTC",
      "updated_date": "2025-05-12 20:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:54:58.306466"
    },
    {
      "arxiv_id": "2505.08049v1",
      "title": "Bias or Optimality? Disentangling Bayesian Inference and Learning Biases in Human Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Prakhar Godara"
      ],
      "abstract": "Recent studies claim that human behavior in a two-armed Bernoulli bandit\n(TABB) task is described by positivity and confirmation biases, implying that\nhumans do not integrate new information objectively. However, we find that even\nif the agent updates its belief via objective Bayesian inference, fitting the\nstandard Q-learning model with asymmetric learning rates still recovers both\nbiases. Bayesian inference cast as an effective Q-learning algorithm has\nsymmetric, though decreasing, learning rates. We explain this by analyzing the\nstochastic dynamics of these learning systems using master equations. We find\nthat both confirmation bias and unbiased but decreasing learning rates yield\nthe same behavioral signatures. Finally, we propose experimental protocols to\ndisentangle true cognitive biases from artifacts of decreasing learning rates.",
      "tldr_zh": "本文研究质疑了人类在二臂伯努瓦赌博机(TABB)任务中的积极性和确认偏差是否为真实认知偏差，指出这些偏差可能源于模型拟合的伪像，即贝叶斯推理作为Q-learning算法时产生的对称但递减学习率。通过主方程分析学习系统的随机动态，作者发现确认偏差和无偏递减学习率会产生相同的行为特征。最终，提出实验协议来区分真正的认知偏差与递减学习率的效应，从而更准确地理解人类决策机制。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08049v1",
      "published_date": "2025-05-12 20:36:43 UTC",
      "updated_date": "2025-05-12 20:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:55:08.848648"
    },
    {
      "arxiv_id": "2505.08821v1",
      "title": "A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction",
      "title_zh": "基于 Transformer 模型的多时间尺度血糖预测比较研究",
      "authors": [
        "Meryem Altin Karagoz",
        "Marc D. Breton",
        "Anas El Fathi"
      ],
      "abstract": "Accurate blood glucose prediction can enable novel interventions for type 1\ndiabetes treatment, including personalized insulin and dietary adjustments.\nAlthough recent advances in transformer-based architectures have demonstrated\nthe power of attention mechanisms in complex multivariate time series\nprediction, their potential for blood glucose (BG) prediction remains\nunderexplored. We present a comparative analysis of transformer models for\nmulti-horizon BG prediction, examining forecasts up to 4 hours and input\nhistory up to 1 week. The publicly available DCLP3 dataset (n=112) was split\n(80%-10%-10%) for training, validation, and testing, and the OhioT1DM dataset\n(n=12) served as an external test set. We trained networks with point-wise,\npatch-wise, series-wise, and hybrid embeddings, using CGM, insulin, and meal\ndata. For short-term blood glucose prediction, Crossformer, a patch-wise\ntransformer architecture, achieved a superior 30-minute prediction of RMSE\n(15.6 mg / dL on OhioT1DM). For longer-term predictions (1h, 2h, and 4h),\nPatchTST, another path-wise transformer, prevailed with the lowest RMSE (24.6\nmg/dL, 36.1 mg/dL, and 46.5 mg/dL on OhioT1DM). In general, models that used\ntokenization through patches demonstrated improved accuracy with larger input\nsizes, with the best results obtained with a one-week history. These findings\nhighlight the promise of transformer-based architectures for BG prediction by\ncapturing and leveraging seasonal patterns in multivariate time-series data to\nimprove accuracy.",
      "tldr_zh": "本研究比较了基于Transformer模型在多时间尺度血糖预测中的性能，旨在为1型糖尿病治疗提供个性化干预，如胰岛素和饮食调整。使用DCLP3数据集（n=112）进行训练、验证和测试，以及OhioT1DM数据集（n=12）作为外部测试集，研究评估了点式、补丁式、序列式和混合嵌入策略，输入包括CGM、胰岛素和进餐数据。结果显示，Crossformer在短期预测（30分钟）中取得最佳RMSE（15.6 mg/dL），而PatchTST在长期预测（1h、2h和4h）中表现突出，RMSE分别为24.6 mg/dL、36.1 mg/dL和46.5 mg/dL；此外，使用补丁式嵌入和一周历史数据显著提升了模型准确性，证明了Transformer模型在捕捉多变量时间序列季节性模式方面的潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "7 pages, 2 figures, 1 table, 1st IFAC Workshop on Engineering\n  Diabetes Technologies (EDT 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.08821v1",
      "published_date": "2025-05-12 20:22:44 UTC",
      "updated_date": "2025-05-12 20:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:55:23.077631"
    },
    {
      "arxiv_id": "2505.08032v1",
      "title": "Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Bagher Hashemi Natanzi",
        "Zhicong Zhu",
        "Bo Tang"
      ],
      "abstract": "Adaptive beam switching in 6G networks is challenged by high frequencies,\nmobility, and blockage. We propose an Online Learning framework using Deep\nReinforcement Learning (DRL) with an enhanced state representation (velocity\nand blockage history), a GRU architecture, and prioritized experience replay\nfor real-time beam optimization. Validated via Nvidia Sionna under\ntime-correlated blockage, our approach significantly enhances resilience in\nSNR, throughput, and accuracy compared to a conventional heuristic.\nFurthermore, the enhanced DRL agent outperforms a reactive Multi-Armed Bandit\n(MAB) baseline by leveraging temporal dependencies, achieving lower performance\nvariability. This demonstrates the benefits of memory and prioritized learning\nfor robust 6G beam management, while confirming MAB as a strong baseline.",
      "tldr_zh": "本研究针对6G网络中自适应波束切换面临的高频、移动性和阻塞挑战，提出了一种基于在线学习的框架，利用Deep Reinforcement Learning (DRL)结合增强状态表示（速度和阻塞历史）、GRU架构以及优先经验回放，实现实时波束优化。在Nvidia Sionna模拟器中进行验证，该方法显著提升了SNR、吞吐量和准确性的弹性，并优于传统启发式方法和Multi-Armed Bandit (MAB)基线。通过利用时间依赖性，DRL代理实现了更低的性能变异性，展示了记忆与优先学习对鲁棒6G波束管理的关键优势。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08032v1",
      "published_date": "2025-05-12 19:59:05 UTC",
      "updated_date": "2025-05-12 19:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:55:34.077228"
    },
    {
      "arxiv_id": "2505.08025v1",
      "title": "PRISM: Complete Online Decentralized Multi-Agent Pathfinding with Rapid Information Sharing using Motion Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah Lee",
        "Zachary Serlin",
        "James Motes",
        "Brendan Long",
        "Marco Morales",
        "Nancy M. Amato"
      ],
      "abstract": "We introduce PRISM (Pathfinding with Rapid Information Sharing using Motion\nConstraints), a decentralized algorithm designed to address the multi-task\nmulti-agent pathfinding (MT-MAPF) problem. PRISM enables large teams of agents\nto concurrently plan safe and efficient paths for multiple tasks while avoiding\ncollisions. It employs a rapid communication strategy that uses information\npackets to exchange motion constraint information, enhancing cooperative\npathfinding and situational awareness, even in scenarios without direct\ncommunication. We prove that PRISM resolves and avoids all deadlock scenarios\nwhen possible, a critical challenge in decentralized pathfinding. Empirically,\nwe evaluate PRISM across five environments and 25 random scenarios,\nbenchmarking it against the centralized Conflict-Based Search (CBS) and the\ndecentralized Token Passing with Task Swaps (TPTS) algorithms. PRISM\ndemonstrates scalability and solution quality, supporting 3.4 times more agents\nthan CBS and handling up to 2.5 times more tasks in narrow passage environments\nthan TPTS. Additionally, PRISM matches CBS in solution quality while achieving\nfaster computation times, even under low-connectivity conditions. Its\ndecentralized design reduces the computational burden on individual agents,\nmaking it scalable for large environments. These results confirm PRISM's\nrobustness, scalability, and effectiveness in complex and dynamic pathfinding\nscenarios.",
      "tldr_zh": "本文提出PRISM算法，一种完全在线的去中心化多智能体路径规划方法，针对多任务多智能体路径规划(MT-MAPF)问题，通过快速信息共享和运动约束信息包交换来实现智能体间的协作，避免碰撞并解决所有可能的死锁场景。PRISM在五个环境和25个随机场景的实验中，与中心化算法Conflict-Based Search (CBS)和去中心化算法Token Passing with Task Swaps (TPTS)相比，支持3.4倍更多智能体，并在狭窄通道环境中处理2.5倍更多任务，同时在解决方案质量上与CBS相当但计算速度更快。总体而言，PRISM的去中心化设计提升了可扩展性和鲁棒性，适用于复杂动态路径规划场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "38 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08025v1",
      "published_date": "2025-05-12 19:48:32 UTC",
      "updated_date": "2025-05-12 19:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:55:46.298296"
    },
    {
      "arxiv_id": "2505.08021v1",
      "title": "The Correspondence Between Bounded Graph Neural Networks and Fragments of First-Order Logic",
      "title_zh": "翻译失败",
      "authors": [
        "Bernardo Cuenca Grau",
        "Przemysław A. Wałęga"
      ],
      "abstract": "Graph Neural Networks (GNNs) address two key challenges in applying deep\nlearning to graph-structured data: they handle varying size input graphs and\nensure invariance under graph isomorphism. While GNNs have demonstrated broad\napplicability, understanding their expressive power remains an important\nquestion. In this paper, we show that bounded GNN architectures correspond to\nspecific fragments of first-order logic (FO), including modal logic (ML),\ngraded modal logic (GML), modal logic with the universal modality (ML(A)), the\ntwo-variable fragment (FO2) and its extension with counting quantifiers (C2).\nTo establish these results, we apply methods and tools from finite model theory\nof first-order and modal logics to the domain of graph representation learning.\nThis provides a unifying framework for understanding the logical expressiveness\nof GNNs within FO.",
      "tldr_zh": "本研究探讨了有界 Graph Neural Networks (GNNs) 的表达能力，并证明其与一阶逻辑 (FO) 的特定片段相对应，包括模态逻辑 (ML)、分级模态逻辑 (GML)、带通用模态的模态逻辑 (ML(A))、二变量片段 (FO2) 及其带计数量词的扩展 (C2)。通过应用有限模型理论和模态逻辑工具到图表示学习领域，论文建立了 GNNs 处理图结构数据（如变大小输入和图同构不变性）的逻辑框架。结果提供了一个统一框架，深化了对 GNNs 表达性的理解，并为图学习理论带来新的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08021v1",
      "published_date": "2025-05-12 19:45:45 UTC",
      "updated_date": "2025-05-12 19:45:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:55:57.002984"
    },
    {
      "arxiv_id": "2505.08004v1",
      "title": "Large Language Models and Arabic Content: A Review",
      "title_zh": "大语言模型与阿拉伯内容：综述",
      "authors": [
        "Haneh Rhel",
        "Dmitri Roussinov"
      ],
      "abstract": "Over the past three years, the rapid advancement of Large Language Models\n(LLMs) has had a profound impact on multiple areas of Artificial Intelligence\n(AI), particularly in Natural Language Processing (NLP) across diverse\nlanguages, including Arabic. Although Arabic is considered one of the most\nwidely spoken languages across 27 countries in the Arabic world and used as a\nsecond language in some other non-Arabic countries as well, there is still a\nscarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face\nvarious challenges due to the complexities of the Arabic language, including\nits rich morphology, intricate structure, and diverse writing standards, among\nother factors. Researchers have been actively addressing these challenges,\ndemonstrating that pre-trained Large Language Models (LLMs) trained on\nmultilingual corpora achieve significant success in various Arabic NLP tasks.\nThis study provides an overview of using large language models (LLMs) for the\nArabic language, highlighting early pre-trained Arabic Language models across\nvarious NLP applications and their ability to handle diverse Arabic content\ntasks and dialects. It also provides an overview of how techniques like\nfinetuning and prompt engineering can enhance the performance of these models.\nAdditionally, the study summarizes common Arabic benchmarks and datasets while\npresenting our observations on the persistent upward trend in the adoption of\nLLMs.",
      "tldr_zh": "这篇论文回顾了过去三年大型语言模型（LLMs）在阿拉伯语内容中的应用及其对自然语言处理（NLP）领域的影响。论文强调了阿拉伯语的复杂性（如丰富的形态和多样书写标准）带来的挑战，以及通过预训练 LLMs 在多语言语料上训练取得的显著成功，包括处理各种 NLP 任务和方言的能力。研究还概述了微调（fine-tuning）和提示工程（prompt engineering）等技术如何提升模型性能，并总结了常见的阿拉伯基准和数据集，同时观察到 LLMs 采用的持续上升趋势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Original language: English This paper has been submitted to the First\n  International Conference on Artificial Intelligence and Generative AI\n  (FICAILY 2025), and it has been accepted for presentation at FICAILY on\n  9-10/July 2025 and for publication in the Springer Nature. Number of pages:\n  16 Publication status Accepted/In press - 7 Apr 2025\n  https://www.gena-ai-libya2025.com/",
      "pdf_url": "http://arxiv.org/pdf/2505.08004v1",
      "published_date": "2025-05-12 19:09:12 UTC",
      "updated_date": "2025-05-12 19:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:56:09.656007"
    },
    {
      "arxiv_id": "2505.08818v1",
      "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Amara Tariq",
        "Rimita Lahiri",
        "Charles Kahn",
        "Imon Banerjee"
      ],
      "abstract": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research.",
      "tldr_zh": "这篇立场论文（position paper）强调了在医疗领域采用视觉语言模型（VLM）时，需要重新结构化机器学习报告标准，以应对多阶段研究的多样性，如新模型开发、微调或直接应用。论文提出一个分类框架（categorization framework），并制定相应的报告标准，包括性能评估、数据报告协议以及稿件撰写建议，以确保研究的可重复性和直观理解。为促进社区采用，论文还提供了一个检查列表（checklist），作为标准化工具，提升 VLM 相关研究的质量和一致性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, 2, tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08818v1",
      "published_date": "2025-05-12 18:39:54 UTC",
      "updated_date": "2025-05-12 18:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:56:20.836027"
    },
    {
      "arxiv_id": "2505.07985v1",
      "title": "Fair Play for Individuals, Foul Play for Groups? Auditing Anonymization's Impact on ML Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Héber H. Arcolezi",
        "Mina Alishahi",
        "Adda-Akram Bendoukha",
        "Nesrine Kaaniche"
      ],
      "abstract": "Machine learning (ML) algorithms are heavily based on the availability of\ntraining data, which, depending on the domain, often includes sensitive\ninformation about data providers. This raises critical privacy concerns.\nAnonymization techniques have emerged as a practical solution to address these\nissues by generalizing features or suppressing data to make it more difficult\nto accurately identify individuals. Although recent studies have shown that\nprivacy-enhancing technologies can influence ML predictions across different\nsubgroups, thus affecting fair decision-making, the specific effects of\nanonymization techniques, such as $k$-anonymity, $\\ell$-diversity, and\n$t$-closeness, on ML fairness remain largely unexplored. In this work, we\nsystematically audit the impact of anonymization techniques on ML fairness,\nevaluating both individual and group fairness. Our quantitative study reveals\nthat anonymization can degrade group fairness metrics by up to four orders of\nmagnitude. Conversely, similarity-based individual fairness metrics tend to\nimprove under stronger anonymization, largely as a result of increased input\nhomogeneity. By analyzing varying levels of anonymization across diverse\nprivacy settings and data distributions, this study provides critical insights\ninto the trade-offs between privacy, fairness, and utility, offering actionable\nguidelines for responsible AI development. Our code is publicly available at:\nhttps://github.com/hharcolezi/anonymity-impact-fairness.",
      "tldr_zh": "这篇论文审计了匿名化技术（如 k-anonymity、ℓ-diversity 和 t-closeness）对机器学习(ML)公平性的影响，聚焦于隐私保护如何干扰公平决策。研究通过系统量化评估发现，匿名化可能使群体公平指标下降多达四个数量级，而基于相似性的个体公平指标往往因输入数据同质化而改善。作者分析了不同隐私设置和数据分布，揭示了隐私、公平性和效用之间的关键权衡，并提供了负责任的AI开发行动指南。代码已公开在GitHub上。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07985v1",
      "published_date": "2025-05-12 18:32:28 UTC",
      "updated_date": "2025-05-12 18:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:56:33.729975"
    },
    {
      "arxiv_id": "2505.07973v1",
      "title": "Probabilistic approach to longitudinal response prediction: application to radiomics from brain cancer imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Isabella Cama",
        "Michele Piana",
        "Cristina Campi",
        "Sara Garbarino"
      ],
      "abstract": "Longitudinal imaging analysis tracks disease progression and treatment\nresponse over time, providing dynamic insights into treatment efficacy and\ndisease evolution. Radiomic features extracted from medical imaging can support\nthe study of disease progression and facilitate longitudinal prediction of\nclinical outcomes. This study presents a probabilistic model for longitudinal\nresponse prediction, integrating baseline features with intermediate\nfollow-ups. The probabilistic nature of the model naturally allows to handle\nthe instrinsic uncertainty of the longitudinal prediction of disease\nprogression. We evaluate the proposed model against state-of-the-art disease\nprogression models in both a synthetic scenario and using a brain cancer\ndataset. Results demonstrate that the approach is competitive against existing\nmethods while uniquely accounting for uncertainty and controlling the growth of\nproblem dimensionality, eliminating the need for data from intermediate\nfollow-ups.",
      "tldr_zh": "这篇论文提出了一种概率模型（probabilistic model），用于纵向响应预测（longitudinal response prediction），并将其应用于脑癌影像的放射组学（radiomics），以整合基线特征和中间随访数据，同时处理预测中的固有不确定性。该模型在合成场景和真实脑癌数据集上进行了评估，结果显示其与现有方法竞争力相当，并通过控制问题维度增长，消除了对中间随访数据的依赖。该方法为跟踪疾病进展和治疗响应提供了更可靠的动态洞见。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "62P10 (Primary), 68T09, 92F05 (Secondary)"
      ],
      "primary_category": "stat.AP",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07973v1",
      "published_date": "2025-05-12 18:15:24 UTC",
      "updated_date": "2025-05-12 18:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:56:44.754606"
    },
    {
      "arxiv_id": "2505.07819v1",
      "title": "H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyang Lu",
        "Yufeng Tian",
        "Zhecheng Yuan",
        "Xianbang Wang",
        "Pu Hua",
        "Zhengrong Xue",
        "Huazhe Xu"
      ],
      "abstract": "Visuomotor policy learning has witnessed substantial progress in robotic\nmanipulation, with recent approaches predominantly relying on generative models\nto model the action distribution. However, these methods often overlook the\ncritical coupling between visual perception and action prediction. In this\nwork, we introduce $\\textbf{Triply-Hierarchical Diffusion\nPolicy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework\nthat explicitly incorporates hierarchical structures to strengthen the\nintegration between visual features and action generation. H$^{3}$DP contains\n$\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes\nRGB-D observations based on depth information; (2) multi-scale visual\nrepresentations that encode semantic features at varying levels of granularity;\nand (3) a hierarchically conditioned diffusion process that aligns the\ngeneration of coarse-to-fine actions with corresponding visual features.\nExtensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$\naverage relative improvement over baselines across $\\mathbf{44}$ simulation\ntasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual\nreal-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.",
      "tldr_zh": "该论文提出H$^{\\mathbf{3}}$DP，一种三层层次化扩散策略框架，用于提升视动觉学习在机器人操作中的性能，通过强化视觉感知与动作预测的耦合。框架包括三个关键层次：（1）基于深度信息的深度感知输入层组织RGB-D观察；（2）多尺度视觉表示编码不同粒度的语义特征；（3）层次化条件扩散过程，从粗到细生成动作并与视觉特征对齐。实验结果显示，H$^{\\mathbf{3}}$DP在44个模拟任务上比基线平均提升27.5%，并在4个真实双臂操作任务中表现出色，为机器人视动觉学习提供了更高效的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07819v1",
      "published_date": "2025-05-12 17:59:43 UTC",
      "updated_date": "2025-05-12 17:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:56:57.373807"
    },
    {
      "arxiv_id": "2505.07816v2",
      "title": "Graph neural networks and MSO",
      "title_zh": "图神经网络与 MSO",
      "authors": [
        "Veeti Ahvonen",
        "Damian Heiman",
        "Antti Kuusisto"
      ],
      "abstract": "We give an alternative proof for the existing result that recurrent graph\nneural networks working with reals have the same expressive power in\nrestriction to monadic second-order logic MSO as the graded modal substitution\ncalculus. The proof is based on constructing distributed automata that capture\nall MSO-definable node properties over trees. We also consider some variants of\nthe acceptance conditions.",
      "tldr_zh": "本研究提供了一个替代证明，证明了使用实数的递归图神经网络（recurrent graph neural networks）在单目二阶逻辑（MSO）的限制下，与graded modal substitution calculus具有相同的表达能力。该证明基于构建分布式自动机（distributed automata），以捕捉树上所有MSO可定义的节点属性。论文还探讨了接受条件的变体，进一步扩展了这一框架的应用潜力。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "F.4.1; F.1.1; I.2.0"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07816v2",
      "published_date": "2025-05-12 17:59:22 UTC",
      "updated_date": "2025-05-15 13:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:57:08.584441"
    },
    {
      "arxiv_id": "2505.07813v1",
      "title": "DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Tony Tao",
        "Mohan Kumar Srirama",
        "Jason Jingzhou Liu",
        "Kenneth Shaw",
        "Deepak Pathak"
      ],
      "abstract": "Large-scale, diverse robot datasets have emerged as a promising path toward\nenabling dexterous manipulation policies to generalize to novel environments,\nbut acquiring such datasets presents many challenges. While teleoperation\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\nwhat if people could use their own hands, just as they do in everyday life, to\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\ncollect hours of interactions across a multitude of environments and objects.\nTo record this data, we create DexWild-System, a low-cost, mobile, and\neasy-to-use device. The DexWild learning framework co-trains on both human and\nrobot demonstrations, leading to improved performance compared to training on\neach dataset individually. This combination results in robust robot policies\ncapable of generalizing to novel environments, tasks, and embodiments with\nminimal additional robot-specific data. Experimental results demonstrate that\nDexWild significantly improves performance, achieving a 68.5% success rate in\nunseen environments-nearly four times higher than policies trained with robot\ndata only-and offering 5.8x better cross-embodiment generalization. Video\nresults, codebases, and instructions at https://dexwild.github.io",
      "tldr_zh": "本论文提出 DexWild 系统，利用人类手部互动收集大规模、多样化数据集，以帮助灵巧操作机器人策略泛化到新环境。DexWild 采用低成本、移动易用的 DexWild-System 设备，让人们像日常生活中一样使用双手记录数据，并通过联合训练人类和机器人演示框架，提升策略性能。实验结果显示，该方法在未见环境中实现 68.5% 的成功率，比仅用机器人数据训练高出近四倍，并在跨机器人泛化能力上提升 5.8 倍。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "In RSS 2025. Website at https://dexwild.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.07813v1",
      "published_date": "2025-05-12 17:59:05 UTC",
      "updated_date": "2025-05-12 17:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:57:21.550857"
    },
    {
      "arxiv_id": "2505.07809v1",
      "title": "A Comparative Analysis of Static Word Embeddings for Hungarian",
      "title_zh": "匈牙利语静态词嵌入的比较分析",
      "authors": [
        "Máté Gedeon"
      ],
      "abstract": "This paper presents a comprehensive analysis of various static word\nembeddings for Hungarian, including traditional models such as Word2Vec,\nFastText, as well as static embeddings derived from BERT-based models using\ndifferent extraction methods. We evaluate these embeddings on both intrinsic\nand extrinsic tasks to provide a holistic view of their performance. For\nintrinsic evaluation, we employ a word analogy task, which assesses the\nembeddings ability to capture semantic and syntactic relationships. Our results\nindicate that traditional static embeddings, particularly FastText, excel in\nthis task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among\nthe BERT-based models, the X2Static method for extracting static embeddings\ndemonstrates superior performance compared to decontextualized and aggregate\nmethods, approaching the effectiveness of traditional static embeddings. For\nextrinsic evaluation, we utilize a bidirectional LSTM model to perform Named\nEntity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results\nreveal that embeddings derived from dynamic models, especially those extracted\nusing the X2Static method, outperform purely static embeddings. Notably, ELMo\nembeddings achieve the highest accuracy in both NER and POS tagging tasks,\nunderscoring the benefits of contextualized representations even when used in a\nstatic form. Our findings highlight the continued relevance of static word\nembeddings in NLP applications and the potential of advanced extraction methods\nto enhance the utility of BERT-based models. This piece of research contributes\nto the understanding of embedding performance in the Hungarian language and\nprovides valuable insights for future developments in the field. The training\nscripts, evaluation codes, restricted vocabulary, and extracted embeddings will\nbe made publicly available to support further research and reproducibility.",
      "tldr_zh": "本研究对匈牙利语的静态词嵌入进行了全面比较分析，包括传统模型如 Word2Vec 和 FastText，以及从 BERT 模型中提取的静态嵌入。评估采用内在任务（如词类比任务）和外在任务（如 Named Entity Recognition (NER) 和 Part-of-Speech (POS) 标注），结果显示 FastText 在内在任务中表现出色，获得高准确率和 Mean Reciprocal Rank (MRR) 分数，而 X2Static 方法从 BERT 模型提取的嵌入在外在任务中表现最佳，ELMo 嵌入则在 NER 和 POS 任务中实现最高准确率。该研究强调了静态词嵌入在自然语言处理中的持续价值，并通过公开训练脚本和提取嵌入资源，支持进一步的研究和可重复性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07809v1",
      "published_date": "2025-05-12 17:57:11 UTC",
      "updated_date": "2025-05-12 17:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:57:32.753842"
    },
    {
      "arxiv_id": "2505.07802v1",
      "title": "Improving Trajectory Stitching with Flow Models",
      "title_zh": "翻译失败",
      "authors": [
        "Reece O'Mahoney",
        "Wanming Yu",
        "Ioannis Havoutis"
      ],
      "abstract": "Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.",
      "tldr_zh": "本研究针对生成模型在轨迹规划中的局限性，特别是在处理训练集外完整轨迹时无法进行trajectory stitching的问题，提出了改进方案。论文优化了架构和数据集选择，并引入了一种新的训练和推理过程，以稳定和增强模型的拼接能力。在Franka Panda机器人模拟和真实硬件实验中，该方法显著优于基线模型，能够生成分布外边界条件的规划，并实现障碍避免，避开障碍规模高达基线的四倍。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07802v1",
      "published_date": "2025-05-12 17:50:10 UTC",
      "updated_date": "2025-05-12 17:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:57:44.963372"
    },
    {
      "arxiv_id": "2505.07796v1",
      "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
      "title_zh": "持续预训练中大型语言模型的学习动态",
      "authors": [
        "Xingjin Wang",
        "Howe Tissue",
        "Lu Wang",
        "Linjing Li",
        "Daniel Dajun Zeng"
      ],
      "abstract": "Continual Pre-Training (CPT) has become a popular and effective method to\napply strong foundation models to specific downstream tasks. In this work, we\nexplore the learning dynamics throughout the CPT process for large language\nmodels. We specifically focus on how general and downstream domain performance\nevolves at each training step, with domain performance measured via validation\nlosses. We have observed that the CPT loss curve fundamentally characterizes\nthe transition from one curve to another hidden curve, and could be described\nby decoupling the effects of distribution shift and learning rate annealing. We\nderive a CPT scaling law that combines the two factors, enabling the prediction\nof loss at any (continual) training steps and across learning rate schedules\n(LRS) in CPT. Our formulation presents a comprehensive understanding of several\ncritical factors in CPT, including loss potential, peak learning rate, training\nsteps, replay ratio, etc. Moreover, our approach can be adapted to customize\ntraining hyper-parameters to different CPT goals such as balancing general and\ndomain-specific performance. Extensive experiments demonstrate that our scaling\nlaw holds across various CPT datasets and training hyper-parameters.",
      "tldr_zh": "本研究探讨了 Continual Pre-Training (CPT) 在大型语言模型中的学习动态，重点分析一般性能和下游领域性能如何随训练步骤演变。研究者通过解耦分布偏移和学习率退火的影响，推导出一个 CPT scaling law，能够预测任意训练步骤的损失，并适用于不同学习率调度，从而全面理解关键因素如损失潜力、峰值学习率和重放比率。实验结果显示，该缩放定律在各种 CPT 数据集和训练超参数下均有效，并可用于自定义训练超参数，以平衡一般和领域特定性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICML2025 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2505.07796v1",
      "published_date": "2025-05-12 17:47:32 UTC",
      "updated_date": "2025-05-12 17:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:57:57.227135"
    },
    {
      "arxiv_id": "2505.07793v1",
      "title": "Overflow Prevention Enhances Long-Context Recurrent LLMs",
      "title_zh": "溢出预防增强长上下文循环LL",
      "authors": [
        "Assaf Ben-Kish",
        "Itamar Zimerman",
        "M. Jehanzeb Mirza",
        "James Glass",
        "Leonid Karlinsky",
        "Raja Giryes"
      ],
      "abstract": "A recent trend in LLMs is developing recurrent sub-quadratic models that\nimprove long-context processing efficiency. We investigate leading large\nlong-context models, focusing on how their fixed-size recurrent memory affects\ntheir performance. Our experiments reveal that, even when these models are\ntrained for extended contexts, their use of long contexts remains\nunderutilized. Specifically, we demonstrate that a chunk-based inference\nprocedure, which identifies and processes only the most relevant portion of the\ninput can mitigate recurrent memory failures and be effective for many\nlong-context tasks: On LongBench, our method improves the overall performance\nof Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%,\nRecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this\nsimple approach also leads to state-of-the-art results in the challenging\nLongBench v2 benchmark, showing competitive performance with equivalent size\nTransformers. Furthermore, our findings raise questions about whether recurrent\nmodels genuinely exploit long-range dependencies, as our single-chunk strategy\ndelivers stronger performance - even in tasks that presumably require\ncross-context relations.",
      "tldr_zh": "该研究调查了长上下文循环大型语言模型（LLMs）的性能问题，特别是固定大小循环内存的局限性。作者提出了一种基于块的推理程序，仅处理输入中最相关的部分，以防止内存溢出（overflow prevention），从而提升模型对长上下文的利用。在 LongBench 基准测试中，该方法使 Falcon3-Mamba-Inst-7B 性能提升 14%、Falcon-Mamba-Inst-7B 提升 28%、RecurrentGemma-IT-9B 提升 50% 和 RWKV6-Finch-7B 提升 51%，并在 LongBench v2 上达到 state-of-the-art 水平。该发现质疑了循环模型是否真正利用长距离依赖，即使在需要跨上下文关系的任务中，这种单块策略也表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07793v1",
      "published_date": "2025-05-12 17:45:05 UTC",
      "updated_date": "2025-05-12 17:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:58:09.519996"
    },
    {
      "arxiv_id": "2505.07775v1",
      "title": "Must Read: A Systematic Survey of Computational Persuasion",
      "title_zh": "必读：计算说服的系统性调查",
      "authors": [
        "Nimet Beyza Bozdag",
        "Shuhaib Mehri",
        "Xiaocheng Yang",
        "Hyeonjeong Ha",
        "Zirui Cheng",
        "Esin Durmus",
        "Jiaxuan You",
        "Heng Ji",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Persuasion is a fundamental aspect of communication, influencing\ndecision-making across diverse contexts, from everyday conversations to\nhigh-stakes scenarios such as politics, marketing, and law. The rise of\nconversational AI systems has significantly expanded the scope of persuasion,\nintroducing both opportunities and risks. AI-driven persuasion can be leveraged\nfor beneficial applications, but also poses threats through manipulation and\nunethical influence. Moreover, AI systems are not only persuaders, but also\nsusceptible to persuasion, making them vulnerable to adversarial attacks and\nbias reinforcement. Despite rapid advancements in AI-generated persuasive\ncontent, our understanding of what makes persuasion effective remains limited\ndue to its inherently subjective and context-dependent nature. In this survey,\nwe provide a comprehensive overview of computational persuasion, structured\naround three key perspectives: (1) AI as a Persuader, which explores\nAI-generated persuasive content and its applications; (2) AI as a Persuadee,\nwhich examines AI's susceptibility to influence and manipulation; and (3) AI as\na Persuasion Judge, which analyzes AI's role in evaluating persuasive\nstrategies, detecting manipulation, and ensuring ethical persuasion. We\nintroduce a taxonomy for computational persuasion research and discuss key\nchallenges, including evaluating persuasiveness, mitigating manipulative\npersuasion, and developing responsible AI-driven persuasive systems. Our survey\noutlines future research directions to enhance the safety, fairness, and\neffectiveness of AI-powered persuasion while addressing the risks posed by\nincreasingly capable language models.",
      "tldr_zh": "这篇调查论文系统综述了计算说服（Computational Persuasion），强调了说服在AI驱动通信中的重要性，包括机会（如有益应用）和风险（如操纵与偏见强化）。论文从三个关键视角组织内容：(1) AI as a Persuader，探讨AI生成说服性内容及其应用；(2) AI as a Persuadee，分析AI易受影响的漏洞；(3) AI as a Persuasion Judge，评估AI在检测操纵和确保道德说服中的角色。作者引入了一个分类法（taxonomy），讨论了关键挑战如评估说服有效性与开发负责任的AI系统，并提出未来研究方向，以提升AI说服的安全性、公平性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07775v1",
      "published_date": "2025-05-12 17:26:31 UTC",
      "updated_date": "2025-05-12 17:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:58:21.348840"
    },
    {
      "arxiv_id": "2505.07773v2",
      "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Xinji Mai",
        "Haotian Xu",
        "Xing W",
        "Weinong Wang",
        "Yingying Zhang",
        "Wenqiang Zhang"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks\nrequiring precise, verifiable computation. While Reinforcement Learning (RL)\nfrom outcome-based rewards enhances text-based reasoning, understanding how\nagents autonomously learn to leverage external tools like code execution\nremains crucial. We investigate RL from outcome-based rewards for\nTool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously\ngenerate and execute Python code for mathematical problems without supervised\ntool-use examples. Our central contribution is we demonstrate that as RL\ntraining progresses, key metrics scale predictably. Specifically, we observe\nstrong positive correlations where increased training steps lead to increases\nin the spontaneous code execution frequency, the average response length, and,\ncritically, the final task accuracy. This suggests a quantifiable relationship\nbetween computational effort invested in training and the emergence of\neffective, tool-augmented reasoning strategies. We implement a robust framework\nfeaturing a decoupled code execution environment and validate our findings\nacross standard RL algorithms and frameworks. Experiments show ZeroTIR\nsignificantly surpasses non-tool ZeroRL baselines on challenging math\nbenchmarks. Our findings provide a foundational understanding of how autonomous\ntool use is acquired and scales within Agent RL, offering a reproducible\nbenchmark for future studies. Code is released at\n\\href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\\_async\\_pipline}.",
      "tldr_zh": "该研究探讨了Agent RL在数学问题求解中的扩展规律，提出ZeroTIR框架，通过基于结果奖励的强化学习（RL）训练基础大型语言模型（LLMs），使模型自发生成并执行Python代码，而无需监督的工具使用示例。实验发现，随着训练步骤增加，代码执行频率、响应长度和任务准确率呈强正相关关系，揭示了计算努力与有效工具增强推理策略之间的可量化联系。相比非工具的ZeroRL基线，ZeroTIR在挑战性数学基准测试中显著提升性能，并提供了一个解耦的代码执行环境作为可重现基准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07773v2",
      "published_date": "2025-05-12 17:23:34 UTC",
      "updated_date": "2025-05-14 04:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:58:32.522298"
    },
    {
      "arxiv_id": "2505.07768v1",
      "title": "Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Yifeng Di",
        "Tianyi Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capability in\ncode generation. However, LLM-generated code is still plagued with a wide range\nof functional errors, especially for complex programming tasks that LLMs have\nnot seen before. Recent studies have shown that developers often struggle with\ninspecting and fixing incorrect code generated by LLMs, diminishing their\nproductivity and trust in LLM-based code generation. Inspired by the mutual\ngrounding theory in communication, we propose an interactive approach that\nleverages code comments as a medium for developers and LLMs to establish a\nshared understanding. Our approach facilitates iterative grounding by\ninterleaving code generation, inline comment generation, and contextualized\nuser feedback through editable comments to align generated code with developer\nintent. We evaluated our approach on two popular benchmarks and demonstrated\nthat our approach significantly improved multiple state-of-the-art LLMs, e.g.,\n17.1% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we\nconducted a user study with 12 participants in comparison to two baselines: (1)\ninteracting with GitHub Copilot, and (2) interacting with a multi-step code\ngeneration paradigm called Multi-Turn Program Synthesis. Participants completed\nthe given programming tasks 16.7% faster and with 10.5% improvement in task\nsuccess rate when using our approach. Both results show that interactively\nrefining code comments enables the collaborative establishment of mutual\ngrounding, leading to more accurate code generation and higher developer\nconfidence.",
      "tldr_zh": "这篇论文提出了一种交互式方法，通过双向注释级 mutual grounding 来提升 Large Language Models (LLMs) 的代码生成准确性，旨在解决 LLMs 在复杂任务中产生的功能错误问题。该方法利用代码注释作为媒介，实现代码生成、内联注释生成和用户反馈的迭代过程，帮助开发者和模型建立共享理解。在两个基准测试中，该方法显著改善了多种 state-of-the-art LLMs 的性能，例如 code-davinci-002 在 HumanEval 上 pass@1 提高了 17.1%。此外，用户研究显示，与 GitHub Copilot 和 Multi-Turn Program Synthesis 相比，使用该方法，参与者完成编程任务的速度提高了 16.7%，成功率提升了 10.5%，从而增强了开发者的信心和生产力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07768v1",
      "published_date": "2025-05-12 17:20:30 UTC",
      "updated_date": "2025-05-12 17:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:58:45.411420"
    },
    {
      "arxiv_id": "2505.07759v1",
      "title": "\"I Apologize For Not Understanding Your Policy\": Exploring the Specification and Evaluation of User-Managed Access Control Policies by AI Virtual Assistants",
      "title_zh": "“我为不理解您的政策而道歉”：探索 AI 虚拟助手对用户",
      "authors": [
        "Jennifer Mondragon",
        "Carlos Rubio-Medrano",
        "Gael Cruz",
        "Dvijesh Shastri"
      ],
      "abstract": "The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants\n(VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek\nhas turned them into convenient interfaces for managing emerging technologies\nsuch as Smart Homes, Smart Cars, Electronic Health Records, by means of\nexplicit commands,e.g., prompts, which can be even launched via voice, thus\nproviding a very convenient interface for end-users. However, the proper\nspecification and evaluation of User-Managed Access Control Policies (U-MAPs),\nthe rules issued and managed by end-users to govern access to sensitive data\nand device functionality - within these VAs presents significant challenges,\nsince such a process is crucial for preventing security vulnerabilities and\nprivacy leaks without impacting user experience. This study provides an initial\nexploratory investigation on whether current publicly-available VAs can manage\nU-MAPs effectively across differing scenarios. By conducting unstructured to\nstructured tests, we evaluated the comprehension of such VAs, revealing a lack\nof understanding in varying U-MAP approaches. Our research not only identifies\nkey limitations, but offers valuable insights into how VAs can be further\nimproved to manage complex authorization rules and adapt to dynamic changes.",
      "tldr_zh": "这篇论文探讨了AI虚拟助手(VAs)，如Google Gemini和ChatGPT，在管理User-Managed Access Control Policies (U-MAPs)时的表现，这些政策由用户定义，用于保护敏感数据和设备功能，以避免安全漏洞和隐私泄露。研究通过非结构化和结构化测试评估了现有VAs对不同U-MAPs的理解，发现它们在理解和处理这些规则方面存在显著不足。最终，论文识别了关键限制，并提供了改进VAs以更好地管理复杂授权规则和适应动态变化的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07759v1",
      "published_date": "2025-05-12 17:03:52 UTC",
      "updated_date": "2025-05-12 17:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:58:57.533446"
    },
    {
      "arxiv_id": "2505.07757v1",
      "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture",
      "title_zh": "情感梯度元认知 RSI（第一部分）：理论基础和单智能体架构",
      "authors": [
        "Rintaro Ando"
      ],
      "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement\n(EG-MRSI) framework, a novel architecture that integrates introspective\nmetacognition, emotion-based intrinsic motivation, and recursive\nself-modification into a unified theoretical system. The framework is\nexplicitly capable of overwriting its own learning algorithm under formally\nbounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation,\nEG-MRSI introduces a differentiable intrinsic reward function driven by\nconfidence, error, novelty, and cumulative success. This signal regulates both\na metacognitive mapping and a self-modification operator constrained by\nprovable safety mechanisms. We formally define the initial agent configuration,\nemotion-gradient dynamics, and RSI trigger conditions, and derive a\nreinforcement-compatible optimization objective that guides the agent's\ndevelopment trajectory. Meaning Density and Meaning Conversion Efficiency are\nintroduced as quantifiable metrics of semantic learning, closing the gap\nbetween internal structure and predictive informativeness. This Part I paper\nestablishes the single-agent theoretical foundations of EG-MRSI. Future parts\nwill extend this framework to include safety certificates and rollback\nprotocols (Part II), collective intelligence mechanisms (Part III), and\nfeasibility constraints including thermodynamic and computational limits (Part\nIV). Together, the EG-MRSI series provides a rigorous, extensible foundation\nfor open-ended and safe AGI.",
      "tldr_zh": "本论文提出了 Emotion-Gradient Metacognitive Recursive Self-Improvement (EG-MRSI) 框架，这是一个整合内省式 metacognition、基于情感的内在动机和递归自修改的统一系统，允许代理在形式化风险约束下重写自身学习算法。框架构建于 Noise-to-Meaning RSI (N2M-RSI) 基础上，引入了一个可微分的内在奖励函数，由信心、错误、新奇性和累积成功驱动，用于调节 metacognitive mapping 和自修改操作，同时通过可证明的安全机制确保稳定性。论文定义了初始代理配置、emotion-gradient dynamics 和 RSI 触发条件，并引入 Meaning Density 和 Meaning Conversion Efficiency 作为语义学习的量化指标，为开放式和安全的 AGI 提供单代理的理论基础，后续部分将扩展到安全证书和集体智能机制。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "F.1.2; I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 3 figures. Part I of a four-part series (Parts II-IV\n  forthcoming)",
      "pdf_url": "http://arxiv.org/pdf/2505.07757v1",
      "published_date": "2025-05-12 17:02:47 UTC",
      "updated_date": "2025-05-12 17:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:59:11.108349"
    },
    {
      "arxiv_id": "2505.07755v1",
      "title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems",
      "title_zh": "边缘计算系统中的 CPU 密集型流数据处理的",
      "authors": [
        "Tomasz Szydlo",
        "Viacheslaw Horbanow",
        "Dev Nandan Jha",
        "Shashikant Ilager",
        "Aleksander Slominski",
        "Rajiv Ranjan"
      ],
      "abstract": "Edge computing has emerged as a pivotal technology, offering significant\nadvantages such as low latency, enhanced data security, and reduced reliance on\ncentralized cloud infrastructure. These benefits are crucial for applications\nrequiring real-time data processing or strict security measures. Despite these\nadvantages, edge devices operating within edge clusters are often\nunderutilized. This inefficiency is mainly due to the absence of a holistic\nperformance profiling mechanism which can help dynamically adjust the desired\nsystem configuration for a given workload. Since edge computing environments\ninvolve a complex interplay between CPU frequency, power consumption, and\napplication performance, a deeper understanding of these correlations is\nessential. By uncovering these relationships, it becomes possible to make\ninformed decisions that enhance both computational efficiency and energy\nsavings. To address this gap, this paper evaluates the power consumption and\nperformance characteristics of a single processing node within an edge cluster\nusing a synthetic microbenchmark by varying the workload size and CPU\nfrequency. The results show how an optimal measure can lead to optimized usage\nof edge resources, given both performance and power consumption.",
      "tldr_zh": "该研究探讨了边缘计算(Edge Computing)系统中CPU密集型流数据处理的基准测试问题，强调其优势如低延迟和增强数据安全，但指出边缘设备常因缺乏整体性能分析机制而利用率低下。作者通过使用合成微基准测试(synthetic microbenchmark)，改变工作负载大小和CPU频率，评估单个处理节点的功耗(Power Consumption)和性能特征。结果显示，优化CPU频率等措施可显著提升计算效率和能源节约，为动态调整系统配置提供指导。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07755v1",
      "published_date": "2025-05-12 17:02:02 UTC",
      "updated_date": "2025-05-12 17:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:59:20.279857"
    },
    {
      "arxiv_id": "2505.07921v2",
      "title": "Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Xu",
        "Junyang Zhu",
        "Dongdong Zhou",
        "Hao Chen",
        "Yang Liu",
        "Jiangrong Shen",
        "Qiang Zhang"
      ],
      "abstract": "Deep neural networks (DNNs) excel in computer vision tasks, especially,\nfew-shot learning (FSL), which is increasingly important for generalizing from\nlimited examples. However, DNNs are computationally expensive with scalability\nissues in real world. Spiking Neural Networks (SNNs), with their event-driven\nnature and low energy consumption, are particularly efficient in processing\nsparse and dynamic data, though they still encounter difficulties in capturing\ncomplex spatiotemporal features and performing accurate cross-class\ncomparisons. To further enhance the performance and efficiency of SNNs in\nfew-shot learning, we propose a few-shot learning framework based on SNNs,\nwhich combines a self-feature extractor module and a cross-feature contrastive\nmodule to refine feature representation and reduce power consumption. We apply\nthe combination of temporal efficient training loss and InfoNCE loss to\noptimize the temporal dynamics of spike trains and enhance the discriminative\npower. Experimental results show that the proposed FSL-SNN significantly\nimproves the classification performance on the neuromorphic dataset N-Omniglot,\nand also achieves competitive performance to ANNs on static datasets such as\nCUB and miniImageNet with low power consumption.",
      "tldr_zh": "本研究提出了一种基于 Spiking Neural Networks (SNNs) 的高效 Few-shot Learning (FSL) 框架，旨在解决 SNNs 在捕捉复杂时空特征和跨类比较方面的挑战，同时降低计算能耗。该框架结合自特征提取模块和跨特征对比模块，优化特征表示，并使用 temporal efficient training loss 和 InfoNCE loss 来提升尖峰序列的时序动态和区分能力。实验结果显示，该框架在神经形态数据集 N-Omniglot 上显著提高了分类性能，并在静态数据集 CUB 和 miniImageNet 上与 Artificial Neural Networks (ANNs) 相比表现出竞争性优势，同时实现了更低的功耗。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07921v2",
      "published_date": "2025-05-12 16:51:08 UTC",
      "updated_date": "2025-05-15 02:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:59:32.696367"
    },
    {
      "arxiv_id": "2505.07728v1",
      "title": "Guiding Data Collection via Factored Scaling Curves",
      "title_zh": "翻译失败",
      "authors": [
        "Lihan Zha",
        "Apurva Badithela",
        "Michael Zhang",
        "Justin Lidard",
        "Jeremy Bao",
        "Emily Zhou",
        "David Snyder",
        "Allen Z. Ren",
        "Dhruv Shah",
        "Anirudha Majumdar"
      ],
      "abstract": "Generalist imitation learning policies trained on large datasets show great\npromise for solving diverse manipulation tasks. However, to ensure\ngeneralization to different conditions, policies need to be trained with data\ncollected across a large set of environmental factor variations (e.g., camera\npose, table height, distractors) $-$ a prohibitively expensive undertaking, if\ndone exhaustively. We introduce a principled method for deciding what data to\ncollect and how much to collect for each factor by constructing factored\nscaling curves (FSC), which quantify how policy performance varies as data\nscales along individual or paired factors. These curves enable targeted data\nacquisition for the most influential factor combinations within a given budget.\nWe evaluate the proposed method through extensive simulated and real-world\nexperiments, across both training-from-scratch and fine-tuning settings, and\nshow that it boosts success rates in real-world tasks in new environments by up\nto 26% over existing data-collection strategies. We further demonstrate how\nfactored scaling curves can effectively guide data collection using an offline\nmetric, without requiring real-world evaluation at scale.",
      "tldr_zh": "该研究针对训练通用模仿学习策略(generalist imitation learning policies)时的数据收集问题，提出了一种基于factored scaling curves (FSC)的指导方法，以量化策略性能随单个或成对环境因素（如相机位置、桌子高度）数据规模变化的规律，从而高效分配数据采集预算。FSC 允许优先针对最有影响的因素组合进行数据获取，避免了全面收集的昂贵成本。通过模拟和真实实验验证，该方法在从零训练和微调场景下，将真实任务在新环境中的成功率提高了高达26%，优于现有策略。此外，FSC 还能使用离线指标指导数据收集，无需大规模真实评估。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://factored-data-scaling.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.07728v1",
      "published_date": "2025-05-12 16:36:35 UTC",
      "updated_date": "2025-05-12 16:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:59:45.634788"
    },
    {
      "arxiv_id": "2505.07715v1",
      "title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Xu",
        "Jie Deng",
        "Jiangrong Shen",
        "Biwu Chen",
        "Huajin Tang",
        "Gang Pan"
      ],
      "abstract": "Event-based object detection has gained increasing attention due to its\nadvantages such as high temporal resolution, wide dynamic range, and\nasynchronous address-event representation. Leveraging these advantages, Spiking\nNeural Networks (SNNs) have emerged as a promising approach, offering low\nenergy consumption and rich spatiotemporal dynamics. To further enhance the\nperformance of event-based object detection, this study proposes a novel hybrid\nspike vision Transformer (HsVT) model. The HsVT model integrates a spatial\nfeature extraction module to capture local and global features, and a temporal\nfeature extraction module to model time dependencies and long-term patterns in\nevent sequences. This combination enables HsVT to capture spatiotemporal\nfeatures, improving its capability to handle complex event-based object\ndetection tasks. To support research in this area, we developed and publicly\nreleased The Fall Detection Dataset as a benchmark for event-based object\ndetection tasks. This dataset, captured using an event-based camera, ensures\nfacial privacy protection and reduces memory usage due to the event\nrepresentation format. We evaluated the HsVT model on GEN1 and Fall Detection\ndatasets across various model sizes. Experimental results demonstrate that HsVT\nachieves significant performance improvements in event detection with fewer\nparameters.",
      "tldr_zh": "本研究提出了一种Hybrid Spiking Vision Transformer (HsVT) 模型，用于事件-based物体检测，旨在利用事件相机的优势，如高时间分辨率和宽动态范围，同时结合Spiking Neural Networks (SNNs)的低能耗特性。HsVT 整合了空间特征提取模块（捕获局部和全局特征）和时间特征提取模块（建模事件序列的时间依赖性和长期模式），从而有效处理复杂时空特征。实验结果显示，该模型在GEN1和Fall Detection Dataset上实现了显著性能提升，同时参数更少，并公开了Fall Detection Dataset作为基准，支持面部隐私保护和内存优化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07715v1",
      "published_date": "2025-05-12 16:19:20 UTC",
      "updated_date": "2025-05-12 16:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:59:56.766930"
    },
    {
      "arxiv_id": "2505.07711v1",
      "title": "Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Sinha",
        "Sumit Kumar Jha",
        "Sunny Raj"
      ],
      "abstract": "We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where\nquantum computers are limited by noisy gates, some of which are more\nerror-prone than others and can render the final computation incomprehensible.\nQuantum circuit compilation algorithms attempt to minimize these noisy gates\nwhen mapping quantum algorithms onto quantum hardware but face computational\nchallenges that restrict their application to circuits with no more than 5-6\nqubits, necessitating the need to partition large circuits before the\napplication of noisy quantum gate minimization algorithms. The existing\ngeneration of these algorithms is heuristic in nature and does not account for\ndownstream gate minimization tasks. Large language models (LLMs) have the\npotential to change this and help improve quantum circuit partitions. This\npaper investigates the use of LLMs, such as Llama and Mistral, for partitioning\nquantum circuits by capitalizing on their abilities to understand and generate\ncode, including QASM. Specifically, we teach LLMs to partition circuits using\nthe quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through\nexperimental evaluations, we show that careful fine-tuning of open source LLMs\nenables us to obtain an accuracy of 53.4% for the partition task while\nover-the-shelf LLMs are unable to correctly partition circuits, using standard\n1-shot and few-shot training approaches.",
      "tldr_zh": "本文探讨了在 NISQ 时代量子计算中，使用 Large Language Models (LLMs) 如 Llama 和 Mistral 来优化量子电路分区，以减少噪声门的影响并提升编译效率。研究方法包括教 LLMs 理解和生成 QASM 代码，并采用 Berkeley Quantum Synthesis Toolkit 的快速分区方法进行电路分区。实验结果显示，细调开源 LLMs 后，分区任务的准确率达到 53.4%，而直接使用现成 LLMs 的 1-shot 或 few-shot 方法无法有效完成任务。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "7 pages, 2 tables and 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07711v1",
      "published_date": "2025-05-12 16:18:48 UTC",
      "updated_date": "2025-05-12 16:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:00:09.741568"
    },
    {
      "arxiv_id": "2505.07701v1",
      "title": "Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications",
      "title_zh": "轻量级端到端文本到语音合成，用于低资源设备应用",
      "authors": [
        "Biel Tura Vecino",
        "Adam Gabryś",
        "Daniel Mątwicki",
        "Andrzej Pomirski",
        "Tom Iddon",
        "Marius Cotescu",
        "Jaime Lorenzo-Trueba"
      ],
      "abstract": "Recent works have shown that modelling raw waveform directly from text in an\nend-to-end (E2E) fashion produces more natural-sounding speech than traditional\nneural text-to-speech (TTS) systems based on a cascade or two-stage approach.\nHowever, current E2E state-of-the-art models are computationally complex and\nmemory-consuming, making them unsuitable for real-time offline on-device\napplications in low-resource scenarios. To address this issue, we propose a\nLightweight E2E-TTS (LE2E) model that generates high-quality speech requiring\nminimal computational resources. We evaluate the proposed model on the LJSpeech\ndataset and show that it achieves state-of-the-art performance while being up\nto $90\\%$ smaller in terms of model parameters and $10\\times$ faster in\nreal-time-factor. Furthermore, we demonstrate that the proposed E2E training\nparadigm achieves better quality compared to an equivalent architecture trained\nin a two-stage approach. Our results suggest that LE2E is a promising approach\nfor developing real-time, high quality, low-resource TTS applications for\non-device applications.",
      "tldr_zh": "本研究提出了一种轻量级端到端文本到语音合成模型（LE2E），旨在解决传统E2E TTS系统在低资源设备上计算复杂和内存消耗大的问题，通过直接从文本建模原始波形来生成高质量的语音。实验在LJSpeech数据集上显示，LE2E模型的参数量减少90%，实时因子加快10倍，同时在性能上达到最先进水平，且E2E训练方式比等效的两阶段方法产生更好的语音质量。该方法为实时、高质量、低资源TTS应用的设备端部署提供了有前景的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Published as a conference paper at SSW 2023",
      "pdf_url": "http://arxiv.org/pdf/2505.07701v1",
      "published_date": "2025-05-12 16:10:15 UTC",
      "updated_date": "2025-05-12 16:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:00:21.422409"
    },
    {
      "arxiv_id": "2505.07920v1",
      "title": "Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions",
      "title_zh": "翻译失败",
      "authors": [
        "Daoze Zhang",
        "Zhijian Bao",
        "Sihang Du",
        "Zhiyi Zhao",
        "Kuangling Zhang",
        "Dezheng Bao",
        "Yang Yang"
      ],
      "abstract": "Peer review is a critical component of scientific progress in the fields like\nAI, but the rapid increase in submission volume has strained the reviewing\nsystem, which inevitably leads to reviewer shortages and declines review\nquality. Besides the growing research popularity, another key factor in this\noverload is the repeated resubmission of substandard manuscripts, largely due\nto the lack of effective tools for authors to self-evaluate their work before\nsubmission. Large Language Models (LLMs) show great promise in assisting both\nauthors and reviewers, and their performance is fundamentally limited by the\nquality of the peer review data. However, existing peer review datasets face\nthree major limitations: (1) limited data diversity, (2) inconsistent and\nlow-quality data due to the use of revised rather than initial submissions, and\n(3) insufficient support for tasks involving rebuttal and reviewer-author\ninteractions. To address these challenges, we introduce the largest\nconsistency-ensured peer review and rebuttal dataset named Re^2, which\ncomprises 19,926 initial submissions, 70,668 review comments, and 53,818\nrebuttals from 24 conferences and 21 workshops on OpenReview. Moreover, the\nrebuttal and discussion stage is framed as a multi-turn conversation paradigm\nto support both traditional static review tasks and dynamic interactive LLM\nassistants, providing more practical guidance for authors to refine their\nmanuscripts and helping alleviate the growing review burden. Our data and code\nare available in https://anonymous.4open.science/r/ReviewBench_anon/.",
      "tldr_zh": "该论文针对AI等领域同行评审（Peer Review）系统的负担问题，指出现有数据集存在数据多样性有限、不一致性及缺乏对rebuttal互动支持的局限。研究者引入了最大的一致性确保数据集Re²，包含19,926个初始提交、70,668个评论和53,818个rebuttals，来自24个会议和21个研讨会，并将rebuttal阶段设计为multi-turn conversation范式。Re²数据集支持传统静态任务和动态Large Language Models (LLMs)辅助应用，帮助作者自评和改进稿件，从而缓解评审压力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "2 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07920v1",
      "published_date": "2025-05-12 16:02:52 UTC",
      "updated_date": "2025-05-12 16:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:00:33.242238"
    },
    {
      "arxiv_id": "2505.07693v1",
      "title": "Belief Injection for Epistemic Control in Linguistic State Space",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian Dumbrava"
      ],
      "abstract": "This work introduces belief injection, a proactive epistemic control\nmechanism for artificial agents whose cognitive states are structured as\ndynamic ensembles of linguistic belief fragments. Grounded in the Semantic\nManifold framework, belief injection directly incorporates targeted linguistic\nbeliefs into an agent's internal cognitive state, influencing reasoning and\nalignment proactively rather than reactively. We delineate various injection\nstrategies, such as direct, context-aware, goal-oriented, and reflective\napproaches, and contrast belief injection with related epistemic control\nmechanisms, notably belief filtering. Additionally, this work discusses\npractical applications, implementation considerations, ethical implications,\nand outlines promising directions for future research into cognitive governance\nusing architecturally embedded belief injection.",
      "tldr_zh": "本研究提出了一种名为“belief injection”的主动认知控制机制，针对认知状态结构化为动态语言信念片段的智能体，基于“Semantic Manifold”框架，将目标语言信念直接整合到智能体的内部状态中，以主动影响其推理和对齐过程。该机制包括多种注入策略，如直接、上下文感知、目标导向和反思性方法，并与相关机制如“belief filtering”进行对比。论文讨论了“belief injection”的实际应用、实施考虑、伦理含义，并为未来认知治理研究指出了有前景的方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07693v1",
      "published_date": "2025-05-12 15:58:56 UTC",
      "updated_date": "2025-05-12 15:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:00:44.779697"
    },
    {
      "arxiv_id": "2505.07686v2",
      "title": "S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Muzhi Dai",
        "Chenxu Yang",
        "Qingyi Si"
      ],
      "abstract": "As Test-Time Scaling emerges as an active research focus in the large\nlanguage model community, advanced post-training methods increasingly emphasize\nextending chain-of-thought (CoT) generation length, thereby enhancing reasoning\ncapabilities to approach Deepseek R1-like reasoning models. However, recent\nstudies reveal that reasoning models (even Qwen3) consistently exhibit\nexcessive thought redundancy in CoT generation. This overthinking issue arises\nfrom the inherent limitations of conventional outcome-reward reinforcement\nlearning, which systematically overlooks the regulation of intermediate\nreasoning processes. This paper introduces Serial-Group Decaying-Reward Policy\nOptimization (S-GRPO), a novel reinforcement learning paradigm that enables\nmodels to implicitly evaluate the sufficiency of intermediate reasoning steps,\nthereby facilitating early exit in CoT generation. Unlike GRPO, which samples\nmultiple possible reasoning paths in parallel (parallel group), S-GRPO only\nsamples one reasoning path and serially selects multiple temporal positions\nfrom the path to exit thinking and directly generate answers (serial group).\nFor correct answers within a serial group, rewards gradually decrease based on\nthe exit positions along the reasoning path from front to back. This design\nencourages the model to produce more accurate and concise thoughts, while also\nincentivizing early thinking termination when appropriate. Empirical\nevaluations demonstrate that S-GRPO is compatible with state-of-the-art\nreasoning models, including Qwen3 and Deepseek-distill. Across diverse\nbenchmarks such as GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond,\nS-GRPO achieves a substantial reduction in sequence length (35.4% - 61.1%)\nwhile simultaneously improving accuracy (absolute 0.72% - 6.08%).",
      "tldr_zh": "这篇论文引入了 S-GRPO，一种基于强化学习的创新范式，旨在解决 Chain-of-Thought (CoT) 生成中的过度思考问题，通过允许模型在中间推理步骤中实现早期退出。S-GRPO 与传统 GRPO 不同，它仅采样一个推理路径，并串行选择退出位置，同时根据退出点逐渐减少奖励，以鼓励生成更准确、简洁的思考过程。实验结果显示，在 Qwen3 和 Deepseek-distill 等模型上，S-GRPO 在 GSM8K、AIME 2024 等基准中将序列长度减少 35.4% 至 61.1%，并同时提升准确率 0.72% 至 6.08%。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07686v2",
      "published_date": "2025-05-12 15:50:44 UTC",
      "updated_date": "2025-05-17 04:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:00:58.327522"
    },
    {
      "arxiv_id": "2505.07683v1",
      "title": "Multimodal Survival Modeling in the Age of Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Song",
        "Morgan Borjigin-Wang",
        "Irene Madejski",
        "Robert L. Grossman"
      ],
      "abstract": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.",
      "tldr_zh": "本文利用The Cancer Genome Atlas (TCGA) 的基因组、临床、图像和病理报告数据，探讨了在基础模型(FMs)时代训练多模态生存模型的可行性，通过从FMs提取零样本嵌入并进行多模态融合，显著优于单模态模型。研究强调了纳入病理报告文本的附加价值，并评估了基于模型的文本摘要和幻觉对模型性能的影响。总体上，这为现代化生存建模提供了新范式，提升了预测准确性和信息提取效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 7 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07683v1",
      "published_date": "2025-05-12 15:47:21 UTC",
      "updated_date": "2025-05-12 15:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:01:11.370529"
    },
    {
      "arxiv_id": "2505.07675v1",
      "title": "Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead $\\mathbf{\\texttt{O}}$ptimization",
      "title_zh": "翻译失败",
      "authors": [
        "Seongjae Kang",
        "Dong Bok Lee",
        "Hyungjoon Jang",
        "Sung Ju Hwang"
      ],
      "abstract": "Vision-language models (VLMs) have achieved remarkable success across diverse\ntasks by leveraging rich textual information with minimal labeled data.\nHowever, deploying such large models remains challenging, particularly in\nresource-constrained environments. Knowledge distillation (KD) offers a\nwell-established solution to this problem; however, recent KD approaches from\nVLMs often involve multi-stage training or additional tuning, increasing\ncomputational overhead and optimization complexity. In this paper, we propose\n$\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n$\\mathbf{\\texttt{O}}$ptimization ($\\mathbf{\\texttt{DHO}}$) -- a simple yet\neffective KD framework that transfers knowledge from VLMs to compact,\ntask-specific models in semi-supervised settings. Specifically, we introduce\ndual prediction heads that independently learn from labeled data and teacher\npredictions, and propose to linearly combine their outputs during inference. We\nobserve that $\\texttt{DHO}$ mitigates gradient conflicts between supervised and\ndistillation signals, enabling more effective feature learning than single-head\nKD baselines. As a result, extensive experiments show that $\\texttt{DHO}$\nconsistently outperforms baselines across multiple domains and fine-grained\ndatasets. Notably, on ImageNet, it achieves state-of-the-art performance,\nimproving accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively,\nwhile using fewer parameters.",
      "tldr_zh": "本研究提出了一种简单有效的知识蒸馏（Knowledge Distillation, KD）框架，名为Dual-Head Optimization (DHO)，旨在从Vision-Language Models (VLMs)向紧凑的任务特定模型转移知识，在半监督设置中解决资源受限环境的部署挑战。DHO 通过引入双预测头（dual prediction heads），分别从标记数据和教师预测中独立学习，并在推理时线性组合输出，从而缓解监督信号和蒸馏信号之间的梯度冲突，促进更有效的特征学习。实验结果显示，DHO 在多个领域和细粒度数据集上优于基线模型，尤其在ImageNet上，使用1%和10%标记数据时，准确率分别提高了3%和0.1%，并采用了更少的参数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 19 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.07675v1",
      "published_date": "2025-05-12 15:39:51 UTC",
      "updated_date": "2025-05-12 15:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:01:21.747102"
    },
    {
      "arxiv_id": "2505.07672v2",
      "title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit",
      "title_zh": "翻译失败",
      "authors": [
        "Arun S. Maiya"
      ],
      "abstract": "We present OnPrem$.$LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem$.$LLM supports multiple LLM backends -- including llama$.$cpp, Ollama,\nvLLM, and Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem$.$LLM also supports integration with a wide range of cloud\nLLM providers when permitted, enabling hybrid deployments that balance\nperformance with data control. A no-code web interface extends accessibility to\nnon-technical users.",
      "tldr_zh": "我们介绍了 OnPrem.LLM，这是一个基于 Python 的工具包，专为处理敏感非公开数据而设计，强调隐私保护并适用于离线或受限环境。工具包提供预构建管道，包括文档处理、RAG（检索增强生成）、信息提取、总结、分类以及提示/输出处理，仅需最小配置即可使用。OnPrem.LLM 支持多种 LLM 后端（如 llama.cpp、Ollama、vLLM 和 Hugging Face Transformers），并提供量化模型支持、GPU 加速、后端无缝切换，以及混合部署选项；此外，它还包括无代码 web 接口，提升了非技术用户的可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.07672v2",
      "published_date": "2025-05-12 15:36:27 UTC",
      "updated_date": "2025-05-13 02:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:01:33.318751"
    },
    {
      "arxiv_id": "2505.07671v1",
      "title": "Benchmarking Retrieval-Augmented Generation for Chemistry",
      "title_zh": "针对化学的检索增强生成基准测试",
      "authors": [
        "Xianrui Zhong",
        "Bowen Jin",
        "Siru Ouyang",
        "Yanzhen Shen",
        "Qiao Jin",
        "Yin Fang",
        "Zhiyong Lu",
        "Jiawei Han"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for\nenhancing large language models (LLMs) with external knowledge, particularly in\nscientific domains that demand specialized and dynamic information. Despite its\npromise, the application of RAG in the chemistry domain remains underexplored,\nprimarily due to the lack of high-quality, domain-specific corpora and\nwell-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a\ncomprehensive benchmark designed to systematically assess the effectiveness of\nRAG across a diverse set of chemistry-related tasks. The accompanying chemistry\ncorpus integrates heterogeneous knowledge sources, including scientific\nliterature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia\nentries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG\ntoolkit that supports five retrieval algorithms and eight LLMs. Using\nChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain\n-- achieving an average relative improvement of 17.4% over direct inference\nmethods. We further conduct in-depth analyses on retriever architectures,\ncorpus selection, and the number of retrieved passages, culminating in\npractical recommendations to guide future research and deployment of RAG\nsystems in the chemistry domain. The code and data is available at\nhttps://chemrag.github.io.",
      "tldr_zh": "本研究针对RAG（Retrieval-augmented Generation）在化学领域的应用不足，引入了ChemRAG-Bench基准，用于系统评估RAG在多样化学任务中的有效性，该基准整合了异构知识来源，如科学文献、PubChem数据库、PubMed摘要、教科书和Wikipedia条目。作者还开发了ChemRAG-Toolkit，一个模块化可扩展工具包，支持五种检索算法和八种LLMs。实验结果显示，RAG相较于直接推理方法平均提高了17.4%的性能。通过深入分析检索器架构、语料库选择和检索段落数量，该研究提供了实用建议，以指导RAG系统在化学领域的未来开发。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07671v1",
      "published_date": "2025-05-12 15:34:45 UTC",
      "updated_date": "2025-05-12 15:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:01:46.680731"
    },
    {
      "arxiv_id": "2505.07664v1",
      "title": "A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development",
      "title_zh": "翻译失败",
      "authors": [
        "Werner Geyer",
        "Jessica He",
        "Daita Sarkar",
        "Michelle Brachman",
        "Chris Hammond",
        "Jennifer Heins",
        "Zahra Ashktorab",
        "Carlos Rosemberg",
        "Charlie Hill"
      ],
      "abstract": "The broad availability of generative AI offers new opportunities to support\nvarious work domains, including agile software development. Agile epics are a\nkey artifact for product managers to communicate requirements to stakeholders.\nHowever, in practice, they are often poorly defined, leading to churn, delivery\ndelays, and cost overruns. In this industry case study, we investigate\nopportunities for large language models (LLMs) to evaluate agile epic quality\nin a global company. Results from a user study with 17 product managers\nindicate how LLM evaluations could be integrated into their work practices,\nincluding perceived values and usage in improving their epics. High levels of\nsatisfaction indicate that agile epics are a new, viable application of AI\nevaluations. However, our findings also outline challenges, limitations, and\nadoption barriers that can inform both practitioners and researchers on the\nintegration of such evaluations into future agile work practices.",
      "tldr_zh": "本研究通过一个行业案例研究，探讨了生成式 AI（特别是大型语言模型 LLMs）在敏捷软件开发中评估 Epic 质量的作用，以解决 Epic 定义不当导致的迭代混乱、延误和成本超支问题。研究涉及对 17 名产品经理进行用户研究，结果显示 LLMs 评估可以有效整合到他们的工作实践中，提高 Epic 质量，并获得高满意度。该方法为 AI 在敏捷开发中的应用提供了新机会，但也指出了挑战、限制和采用障碍，以指导未来的实践和研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07664v1",
      "published_date": "2025-05-12 15:31:16 UTC",
      "updated_date": "2025-05-12 15:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:01:56.895113"
    },
    {
      "arxiv_id": "2505.07637v1",
      "title": "Chronocept: Instilling a Sense of Time in Machines",
      "title_zh": "Chronocept: 赋予机器时间感",
      "authors": [
        "Krish Goel",
        "Sanskar Pandey",
        "KS Mahadevan",
        "Harsh Kumar",
        "Vishesh Khadaria"
      ],
      "abstract": "Human cognition is deeply intertwined with a sense of time, known as\nChronoception. This sense allows us to judge how long facts remain valid and\nwhen knowledge becomes outdated. Despite progress in vision, language, and\nmotor control, AI still struggles to reason about temporal validity. We\nintroduce Chronocept, the first benchmark to model temporal validity as a\ncontinuous probability distribution over time. Using skew-normal curves fitted\nalong semantically decomposed temporal axes, Chronocept captures nuanced\npatterns of emergence, decay, and peak relevance. It includes two datasets:\nBenchmark I (atomic facts) and Benchmark II (multi-sentence passages).\nAnnotations show strong inter-annotator agreement (84% and 89%). Our baselines\npredict curve parameters - location, scale, and skewness - enabling\ninterpretable, generalizable learning and outperforming classification-based\napproaches. Chronocept fills a foundational gap in AI's temporal reasoning,\nsupporting applications in knowledge grounding, fact-checking,\nretrieval-augmented generation (RAG), and proactive agents. Code and data are\npublicly available.",
      "tldr_zh": "该论文探讨了 AI 在时间有效性推理上的不足，引入 Chronocept 基准，这是首个将时间有效性建模为随时间变化的连续概率分布，使用 skew-normal curves 沿语义分解的时间轴捕捉出现、衰减和峰值相关性的细微模式。Chronocept 包括两个数据集：Benchmark I（原子事实）和 Benchmark II（多句段落），标注显示了高标注者间一致性（分别为 84% 和 89%）。基线模型通过预测曲线参数（如位置、规模和偏斜度）实现了可解释性和泛化性，优于基于分类的方法。该基准填补了 AI 时间推理的空白，支持知识接地、事实检查、retrieval-augmented generation (RAG) 和主动代理等应用，并公开了代码和数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 8 figures, 18 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07637v1",
      "published_date": "2025-05-12 15:07:32 UTC",
      "updated_date": "2025-05-12 15:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:02:10.712390"
    },
    {
      "arxiv_id": "2505.07634v2",
      "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents",
      "title_zh": "Neural Brain：一个受神经科学启发的具身代理框架",
      "authors": [
        "Jian Liu",
        "Xiongtao Shi",
        "Thai Duy Nguyen",
        "Haitian Zhang",
        "Tianxiang Zhang",
        "Wei Sun",
        "Yanjie Li",
        "Athanasios V. Vasilakos",
        "Giovanni Iacca",
        "Arshad Ali Khan",
        "Arvind Kumar",
        "Jae Won Cho",
        "Ajmal Mian",
        "Lihua Xie",
        "Erik Cambria",
        "Lin Wang"
      ],
      "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static,\ndata-driven models to dynamic systems capable of perceiving and interacting\nwith real-world environments. Despite advancements in pattern recognition and\nsymbolic reasoning, current AI systems, such as large language models, remain\ndisembodied, unable to physically engage with the world. This limitation has\ndriven the rise of embodied AI, where autonomous agents, such as humanoid\nrobots, must navigate and manipulate unstructured environments with human-like\nadaptability. At the core of this challenge lies the concept of Neural Brain, a\ncentral intelligence system designed to drive embodied agents with human-like\nadaptability. A Neural Brain must seamlessly integrate multimodal sensing and\nperception with cognitive capabilities. Achieving this also requires an\nadaptive memory system and energy-efficient hardware-software co-design,\nenabling real-time action in dynamic environments. This paper introduces a\nunified framework for the Neural Brain of embodied agents, addressing two\nfundamental challenges: (1) defining the core components of Neural Brain and\n(2) bridging the gap between static AI models and the dynamic adaptability\nrequired for real-world deployment. To this end, we propose a biologically\ninspired architecture that integrates multimodal active sensing,\nperception-cognition-action function, neuroplasticity-based memory storage and\nupdating, and neuromorphic hardware/software optimization. Furthermore, we also\nreview the latest research on embodied agents across these four aspects and\nanalyze the gap between current AI systems and human intelligence. By\nsynthesizing insights from neuroscience, we outline a roadmap towards the\ndevelopment of generalizable, autonomous agents capable of human-level\nintelligence in real-world scenarios.",
      "tldr_zh": "该研究提出“Neural Brain”框架，这是一种受神经科学启发的系统，旨在为“embodied agents”（如人形机器人）提供核心智能，以实现人类般的适应性。该框架整合了“multimodal sensing”、感知-认知-行动功能、“neuroplasticity-based memory”存储更新，以及“neuromorphic hardware/software”优化，解决静态AI模型与动态环境互动的挑战。通过回顾最新研究并分析AI与人类智能的差距，论文概述了开发通用自主代理的路线图，推动AI在真实场景中实现人类水平智能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "51 pages, 17 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07634v2",
      "published_date": "2025-05-12 15:05:34 UTC",
      "updated_date": "2025-05-14 12:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:02:22.978398"
    },
    {
      "arxiv_id": "2505.07917v1",
      "title": "Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Linus Stuhlmann",
        "Michael Alexander Saxer",
        "Jonathan Fürst"
      ],
      "abstract": "Biomedical question-answering (QA) systems require effective retrieval and\ngeneration components to ensure accuracy, efficiency, and scalability. This\nstudy systematically examines a Retrieval-Augmented Generation (RAG) system for\nbiomedical QA, evaluating retrieval strategies and response time trade-offs. We\nfirst assess state-of-the-art retrieval methods, including BM25, BioBERT,\nMedCPT, and a hybrid approach, alongside common data stores such as\nElasticsearch, MongoDB, and FAISS, on a ~10% subset of PubMed (2.4M documents)\nto measure indexing efficiency, retrieval latency, and retriever performance in\nthe end-to-end RAG system. Based on these insights, we deploy the final RAG\nsystem on the full 24M PubMed corpus, comparing different retrievers' impact on\noverall performance. Evaluations of the retrieval depth show that retrieving 50\ndocuments with BM25 before reranking with MedCPT optimally balances accuracy\n(0.90), recall (0.90), and response time (1.91s). BM25 retrieval time remains\nstable (82ms), while MedCPT incurs the main computational cost. These results\nhighlight previously not well-known trade-offs in retrieval depth, efficiency,\nand scalability for biomedical QA. With open-source code, the system is fully\nreproducible and extensible.",
      "tldr_zh": "本研究系统评估了Retrieval-Augmented Generation (RAG)系统在生物医学问答(Biomedical QA)中的应用，比较了BM25、BioBERT、MedCPT和混合检索方法，以及Elasticsearch、MongoDB和FAISS等数据存储的效率和性能。实验首先在PubMed的10%子集（2.4M文档）上测试了索引效率、检索延迟和整体RAG表现，然后扩展到完整24M文档语料库。结果显示，使用BM25检索50个文档后由MedCPT重新排序，能最佳平衡准确率（0.90）、召回率（0.90）和响应时间（1.91秒），同时突出了检索深度与效率的权衡。该系统开源且可复现，为生物医学QA的扩展提供了可靠框架。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at SDS25",
      "pdf_url": "http://arxiv.org/pdf/2505.07917v1",
      "published_date": "2025-05-12 14:51:47 UTC",
      "updated_date": "2025-05-12 14:51:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:02:35.831230"
    },
    {
      "arxiv_id": "2505.07621v1",
      "title": "Bang for the Buck: Vector Search on Cloud CPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Kuffo",
        "Peter Boncz"
      ],
      "abstract": "Vector databases have emerged as a new type of systems that support efficient\nquerying of high-dimensional vectors. Many of these offer their database as a\nservice in the cloud. However, the variety of available CPUs and the lack of\nvector search benchmarks across CPUs make it difficult for users to choose one.\nIn this study, we show that CPU microarchitectures available in the cloud\nperform significantly differently across vector search scenarios. For instance,\nin an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per\nsecond (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the\ntables turn. However, when looking at the number of queries per dollar (QP$),\nGraviton3 is the best option for most indexes and quantization settings, even\nover Graviton4 (Table 1). With this work, we hope to guide users in getting the\nbest \"bang for the buck\" when deploying vector search systems.",
      "tldr_zh": "这篇论文比较了云端可用 CPU 在向量搜索中的性能差异，旨在帮助用户根据查询性能 (QPS) 和性价比 (QP$) 选择最佳选项。通过基准测试，研究者评估了不同 CPU 微架构（如 AMD's Zen4、Intel's Sapphire Rapids、Graviton3 和 Graviton4）在 IVF index 和 HNSW indexes 等场景下的表现，发现 AMD's Zen4 在 IVF index 上比 Intel's Sapphire Rapids 快近 3 倍，但 HNSW indexes 则情况相反。总体结果显示，Graviton3 在大多数量化设置下提供最高的 QP$，为部署向量搜索系统提供了实用指导。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "To be published in Proceedings of 21st International Workshop on Data\n  Management on New Hardware (DaMoN '25)",
      "pdf_url": "http://arxiv.org/pdf/2505.07621v1",
      "published_date": "2025-05-12 14:44:21 UTC",
      "updated_date": "2025-05-12 14:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:02:47.114449"
    },
    {
      "arxiv_id": "2505.07615v1",
      "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Passoni",
        "Francesca Ronchini",
        "Luca Comanducci",
        "Romain Serizel",
        "Fabio Antonacci"
      ],
      "abstract": "Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.",
      "tldr_zh": "这篇论文分析了生成式文本到音频(Text-to-Audio)扩散模型的能源消耗问题，评估了7个最先进模型在推理时的能源使用情况，并探讨了生成参数变化（如参数调整）对能耗的影响。研究者通过Pareto-optimal解决方案寻找音频质量和能源消耗之间的最优平衡，旨在揭示性能与环境影响的权衡。最终发现为开发更高效的生成音频模型提供了宝贵见解。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07615v1",
      "published_date": "2025-05-12 14:36:47 UTC",
      "updated_date": "2025-05-12 14:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:02:57.893234"
    },
    {
      "arxiv_id": "2505.07610v2",
      "title": "Concept-Level Explainability for Auditing & Steering LLM Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Kenza Amara",
        "Rita Sevastjanova",
        "Mennatallah El-Assady"
      ],
      "abstract": "As large language models (LLMs) become widely deployed, concerns about their\nsafety and alignment grow. An approach to steer LLM behavior, such as\nmitigating biases or defending against jailbreaks, is to identify which parts\nof a prompt influence specific aspects of the model's output. Token-level\nattribution methods offer a promising solution, but still struggle in text\ngeneration, explaining the presence of each token in the output separately,\nrather than the underlying semantics of the entire LLM response. We introduce\nConceptX, a model-agnostic, concept-level explainability method that identifies\nthe concepts, i.e., semantically rich tokens in the prompt, and assigns them\nimportance based on the outputs' semantic similarity. Unlike current\ntoken-level methods, ConceptX also offers to preserve context integrity through\nin-place token replacements and supports flexible explanation goals, e.g.,\ngender bias. ConceptX enables both auditing, by uncovering sources of bias, and\nsteering, by modifying prompts to shift the sentiment or reduce the harmfulness\nof LLM responses, without requiring retraining. Across three LLMs, ConceptX\noutperforms token-level methods like TokenSHAP in both faithfulness and human\nalignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for\nrandom edits and lower attack success rates from 0.463 to 0.242, outperforming\nattribution and paraphrasing baselines. While prompt engineering and\nself-explaining methods sometimes yield safer responses, ConceptX offers a\ntransparent and faithful alternative for improving LLM safety and alignment,\ndemonstrating the practical value of attribution-based explainability in\nguiding LLM behavior.",
      "tldr_zh": "该论文提出ConceptX，一种模型无关的概念级解释方法，用于审计和引导LLM响应，以解决传统Token-level attribution方法在文本生成中无法捕捉整体语义的问题。ConceptX通过识别提示中的语义丰富概念并基于输出语义相似性分配重要性，同时利用in-place token replacements保留上下文完整性，支持灵活解释目标，如性别偏见，从而实现对偏见来源的审计和对响应的引导，而无需重新训练。实验结果显示，ConceptX在三个LLM上超越TokenSHAP，在忠实度和人类一致性上表现更优；在引导任务中，提升情感转移效果（从0.131提高到0.252），并将攻击成功率从0.463降至0.242。总体而言，ConceptX为提升LLM的安全性和对齐性提供了一个透明、可靠的替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 7 figures, Submission to Neurips 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07610v2",
      "published_date": "2025-05-12 14:31:51 UTC",
      "updated_date": "2025-05-19 14:00:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:03:10.525434"
    },
    {
      "arxiv_id": "2505.07608v1",
      "title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining",
      "title_zh": "MiMo: 解锁语言模型的推理潜力——从预训练到后训练",
      "authors": [
        "Xiaomi LLM-Core Team",
        ":",
        "Bingquan Xia",
        "Bowen Shen",
        "Cici",
        "Dawei Zhu",
        "Di Zhang",
        "Gang Wang",
        "Hailin Zhang",
        "Huaqiu Liu",
        "Jiebao Xiao",
        "Jinhao Dong",
        "Liang Zhao",
        "Peidian Li",
        "Peng Wang",
        "Shihua Yu",
        "Shimao Chen",
        "Weikun Wang",
        "Wenhan Ma",
        "Xiangwei Deng",
        "Yi Huang",
        "Yifan Song",
        "Zihan Jiang",
        "Bowen Ye",
        "Can Cai",
        "Chenhong He",
        "Dong Zhang",
        "Duo Zhang",
        "Guoan Wang",
        "Hao Tian",
        "Haochen Zhao",
        "Heng Qu",
        "Hongshen Xu",
        "Jun Shi",
        "Kainan Bao",
        "QingKai Fang",
        "Kang Zhou",
        "Kangyang Zhou",
        "Lei Li",
        "Menghang Zhu",
        "Nuo Chen",
        "Qiantong Wang",
        "Shaohui Liu",
        "Shicheng Li",
        "Shuhao Gu",
        "Shuhuai Ren",
        "Shuo Liu",
        "Sirui Deng",
        "Weiji Zhuang",
        "Weiwei Lv",
        "Wenyu Yang",
        "Xin Zhang",
        "Xing Yong",
        "Xing Zhang",
        "Xingchen Song",
        "Xinzhe Xu",
        "Xu Wang",
        "Yihan Yan",
        "Yu Tu",
        "Yuanyuan Tian",
        "Yudong Wang",
        "Yue Yu",
        "Zhenru Lin",
        "Zhichao Song",
        "Zihao Yue"
      ],
      "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with\noptimization across both pre-training and post-training stages. During\npre-training, we enhance the data preprocessing pipeline and employ a\nthree-stage data mixing strategy to strengthen the base model's reasoning\npotential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional\nMulti-Token Prediction objective for enhanced performance and accelerated\ninference speed. During post-training, we curate a dataset of 130K verifiable\nmathematics and programming problems for reinforcement learning, integrating a\ntest-difficulty-driven code-reward scheme to alleviate sparse-reward issues and\nemploying strategic data resampling to stabilize training. Extensive\nevaluations show that MiMo-7B-Base possesses exceptional reasoning potential,\noutperforming even much larger 32B models. The final RL-tuned model,\nMiMo-7B-RL, achieves superior performance on mathematics, code and general\nreasoning tasks, surpassing the performance of OpenAI o1-mini. The model\ncheckpoints are available at https://github.com/xiaomimimo/MiMo.",
      "tldr_zh": "我们介绍了 MiMo-7B，一种针对推理任务优化的语言模型，通过预训练和后训练阶段的全面优化来提升其推理潜力。在预训练中，采用增强的数据预处理管道、三阶段数据混合策略以及 Multi-Token Prediction 目标，在 25 万亿 tokens 上训练，显著提高了模型性能和推理速度。在后训练阶段，构建了 13 万可验证的数学和编程问题数据集，结合 test-difficulty-driven code-reward 方案和战略性数据重采样来解决稀疏奖励问题，最终 MiMo-7B-RL 在数学、代码和一般推理任务上超越 OpenAI o1-mini，展现出卓越的表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07608v1",
      "published_date": "2025-05-12 14:30:11 UTC",
      "updated_date": "2025-05-12 14:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:03:23.107052"
    },
    {
      "arxiv_id": "2505.07601v1",
      "title": "Characterizing the Investigative Methods of Fictional Detectives with Large Language Models",
      "title_zh": "利用大语言模型表征虚构侦探的调查方法",
      "authors": [
        "Edirlei Soares de Lima",
        "Marco A. Casanova",
        "Bruno Feijó",
        "Antonio L. Furtado"
      ],
      "abstract": "Detective fiction, a genre defined by its complex narrative structures and\ncharacter-driven storytelling, presents unique challenges for computational\nnarratology, a research field focused on integrating literary theory into\nautomated narrative generation. While traditional literary studies have offered\ndeep insights into the methods and archetypes of fictional detectives, these\nanalyses often focus on a limited number of characters and lack the scalability\nneeded for the extraction of unique traits that can be used to guide narrative\ngeneration methods. In this paper, we present an AI-driven approach for\nsystematically characterizing the investigative methods of fictional\ndetectives. Our multi-phase workflow explores the capabilities of 15 Large\nLanguage Models (LLMs) to extract, synthesize, and validate distinctive\ninvestigative traits of fictional detectives. This approach was tested on a\ndiverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes,\nWilliam Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin -\ncapturing the distinctive investigative styles that define each character. The\nidentified traits were validated against existing literary analyses and further\ntested in a reverse identification phase, achieving an overall accuracy of\n91.43%, demonstrating the method's effectiveness in capturing the distinctive\ninvestigative approaches of each detective. This work contributes to the\nbroader field of computational narratology by providing a scalable framework\nfor character analysis, with potential applications in AI-driven interactive\nstorytelling and automated narrative generation.",
      "tldr_zh": "该研究提出了一种AI驱动方法，利用Large Language Models (LLMs)来系统表征虚构侦探的调查方法，以解决计算叙事学(computational narratology)中传统分析的可扩展性问题。研究采用多阶段工作流程，使用15个LLMs从七位标志性侦探（如Sherlock Holmes和Hercule Poirot）中提取、合成和验证独特调查特征，并通过与现有文学分析对比以及反向识别阶段，达到了91.43%的准确率。实验结果证明了该方法的有效性，为AI驱动的互动故事生成和自动叙事生成提供了可扩展的框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07601v1",
      "published_date": "2025-05-12 14:24:58 UTC",
      "updated_date": "2025-05-12 14:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:03:35.366871"
    },
    {
      "arxiv_id": "2505.07596v1",
      "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Huang",
        "Xiaowei Yuan",
        "Yiming Ju",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce\nhallucinations in Large Language Models (LLMs). While reinforcement learning\n(RL) can enable LLMs to act as search agents by activating retrieval\ncapabilities, existing ones often underutilize their internal knowledge. This\ncan lead to redundant retrievals, potential harmful knowledge conflicts, and\nincreased inference latency. To address these limitations, an efficient and\nadaptive search agent capable of discerning optimal retrieval timing and\nsynergistically integrating parametric (internal) and retrieved (external)\nknowledge is in urgent need. This paper introduces the Reinforced\nInternal-External Knowledge Synergistic Reasoning Agent (IKEA), which could\nindentify its own knowledge boundary and prioritize the utilization of internal\nknowledge, resorting to external search only when internal knowledge is deemed\ninsufficient. This is achieved using a novel knowledge-boundary aware reward\nfunction and a knowledge-boundary aware training dataset. These are designed\nfor internal-external knowledge synergy oriented RL, incentivizing the model to\ndeliver accurate answers, minimize unnecessary retrievals, and encourage\nappropriate external searches when its own knowledge is lacking. Evaluations\nacross multiple knowledge reasoning tasks demonstrate that IKEA significantly\noutperforms baseline methods, reduces retrieval frequency significantly, and\nexhibits robust generalization capabilities.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在检索增强生成（RAG）中的问题，如冗余检索和知识冲突，提出了一种强化内部-外部知识协同推理代理（IKEA）。IKEA 通过知识边界感知奖励函数和训练数据集，启用模型识别自身知识边界，优先利用内部知识，并在不足时适时进行外部检索，从而优化知识协同并减少不必要查询。实验结果显示，IKEA 在多种知识推理任务上显著优于基线方法，降低了检索频率，并展现出强大的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07596v1",
      "published_date": "2025-05-12 14:21:57 UTC",
      "updated_date": "2025-05-12 14:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:03:45.931136"
    },
    {
      "arxiv_id": "2505.07591v1",
      "title": "A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Ye",
        "Caishuang Huang",
        "Zhuohan Chen",
        "Wenjie Fu",
        "Chenyuan Yang",
        "Leyi Yang",
        "Yilong Wu",
        "Peng Wang",
        "Meng Zhou",
        "Xiaolong Yang",
        "Tao Gui",
        "Qi Zhang",
        "Zhongchao Shi",
        "Jianping Fan",
        "Xuanjing Huang"
      ],
      "abstract": "Instruction following evaluates large language models (LLMs) on their ability\nto generate outputs that adhere to user-defined constraints. However, existing\nbenchmarks often rely on templated constraint prompts, which lack the diversity\nof real-world usage and limit fine-grained performance assessment. To fill this\ngap, we propose a multi-dimensional constraint framework encompassing three\nconstraint patterns, four constraint categories, and four difficulty levels.\nBuilding on this framework, we develop an automated instruction generation\npipeline that performs constraint expansion, conflict detection, and\ninstruction rewriting, yielding 1,200 code-verifiable instruction-following\ntest samples. We evaluate 19 LLMs across seven model families and uncover\nsubstantial variation in performance across constraint forms. For instance,\naverage performance drops from 77.67% at Level I to 32.96% at Level IV.\nFurthermore, we demonstrate the utility of our approach by using it to generate\ndata for reinforcement learning, achieving substantial gains in instruction\nfollowing without degrading general performance. In-depth analysis indicates\nthat these gains stem primarily from modifications in the model's attention\nmodules parameters, which enhance constraint recognition and adherence. Code\nand data are available in https://github.com/Junjie-Ye/MulDimIF.",
      "tldr_zh": "这篇论文提出一个多维约束框架，用于评估和提升大型语言模型(LLMs)在指令遵循方面的性能，该框架涵盖三个约束patterns、四个constraint categories和四个difficulty levels，以解决现有基准缺乏多样性和细粒度评估的问题。  \n他们开发了一个自动指令生成管道，包括约束expansion、冲突detection和指令rewriting，生成1200个可代码验证的测试样本。  \n在评估19个LLMs时，发现性能在不同约束形式下有显著差异，例如从Level I的77.67%降至Level IV的32.96%。  \n此外，通过使用该框架生成数据进行reinforcement learning，论文实现了指令遵循能力的显著提升，而不降低模型的一般性能；深入分析表明，这些改进主要源于attention modules参数的修改，提升了约束识别和遵守。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07591v1",
      "published_date": "2025-05-12 14:16:55 UTC",
      "updated_date": "2025-05-12 14:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:03:59.812959"
    },
    {
      "arxiv_id": "2505.13484v1",
      "title": "Evaluating Large Language Models for Real-World Engineering Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Rene Heesch",
        "Sebastian Eilermann",
        "Alexander Windmann",
        "Alexander Diedrich",
        "Philipp Rosenthal",
        "Oliver Niggemann"
      ],
      "abstract": "Large Language Models (LLMs) are transformative not only for daily activities\nbut also for engineering tasks. However, current evaluations of LLMs in\nengineering exhibit two critical shortcomings: (i) the reliance on simplified\nuse cases, often adapted from examination materials where correctness is easily\nverifiable, and (ii) the use of ad hoc scenarios that insufficiently capture\ncritical engineering competencies. Consequently, the assessment of LLMs on\ncomplex, real-world engineering problems remains largely unexplored. This paper\naddresses this gap by introducing a curated database comprising over 100\nquestions derived from authentic, production-oriented engineering scenarios,\nsystematically designed to cover core competencies such as product design,\nprognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art\nLLMs, including both cloud-based and locally hosted instances, to\nsystematically investigate their performance on complex engineering tasks. Our\nresults show that LLMs demonstrate strengths in basic temporal and structural\nreasoning but struggle significantly with abstract reasoning, formal modeling,\nand context-sensitive engineering logic.",
      "tldr_zh": "本文评估了大型语言模型(LLMs)在真实工程任务中的性能，指出现有评估方法存在两大缺陷：依赖简化用例和无法捕捉关键工程能力，从而忽略了复杂场景的测试。研究团队构建了一个包含超过100个问题的数据库，这些问题基于真实的、生产导向工程场景，系统覆盖产品设计、预测和诊断等核心能力。使用该数据集评估四种最先进的LLMs后，结果显示这些模型在基本的时间和结构推理方面表现出色，但在大胆推理、正式建模以及上下文敏感的工程逻辑上存在显著不足。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13484v1",
      "published_date": "2025-05-12 14:05:23 UTC",
      "updated_date": "2025-05-12 14:05:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:04:11.533128"
    },
    {
      "arxiv_id": "2505.07581v2",
      "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Wang",
        "Heyang Gao",
        "Xiaohe Bo",
        "Xu Chen",
        "Ji-Rong Wen"
      ],
      "abstract": "Leveraging large language model (LLM) based agents to simulate human social\nbehaviors has recently gained significant attention. In this paper, we\nintroduce a novel social simulator called YuLan-OneSim. Compared to previous\nworks, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free\nscenario construction: Users can simply describe and refine their simulation\nscenarios through natural language interactions with our simulator. All\nsimulation code is automatically generated, significantly reducing the need for\nprogramming expertise. (2) Comprehensive default scenarios: We implement 50\ndefault simulation scenarios spanning 8 domains, including economics,\nsociology, politics, psychology, organization, demographics, law, and\ncommunication, broadening access for a diverse range of social researchers. (3)\nEvolvable simulation: Our simulator is capable of receiving external feedback\nand automatically fine-tuning the backbone LLMs, significantly enhancing the\nsimulation quality. (4) Large-scale simulation: By developing a fully\nresponsive agent framework and a distributed simulation architecture, our\nsimulator can handle up to 100,000 agents, ensuring more stable and reliable\nsimulation results. (5) AI social researcher: Leveraging the above features, we\ndevelop an AI social researcher. Users only need to propose a research topic,\nand the AI researcher will automatically analyze the input, construct\nsimulation environments, summarize results, generate technical reports, review\nand refine the reports--completing the social science research loop. To\ndemonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate\nthe quality of the automatically generated scenarios, the reliability,\nefficiency, and scalability of the simulation process, as well as the\nperformance of the AI social researcher.",
      "tldr_zh": "本论文提出YuLan-OneSim，一种基于Large Language Models (LLM) 的新型社会模拟器，旨在通过LLM代理模拟人类社会行为。YuLan-OneSim 的五大创新包括：无代码的自然语言场景构建、50个覆盖经济、社会学、政治学等八个领域的默认场景、可接收反馈自动微调的演化模拟、支持多达10万代理的大规模分布式架构，以及AI社会研究者功能，能自动处理从研究主题分析到报告生成的完整流程。通过实验评估，该模拟器在场景质量、模拟可靠性和效率方面表现出色，为社会研究提供更便捷且可扩展的工具。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07581v2",
      "published_date": "2025-05-12 14:05:17 UTC",
      "updated_date": "2025-05-22 13:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:04:23.351369"
    },
    {
      "arxiv_id": "2505.07576v1",
      "title": "Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Barusco",
        "Francesco Borsatti",
        "Youssef Ben Khalifa",
        "Davide Dalle Pezze",
        "Gian Antonio Susto"
      ],
      "abstract": "Semiconductor manufacturing is a complex, multistage process. Automated\nvisual inspection of Scanning Electron Microscope (SEM) images is indispensable\nfor minimizing equipment downtime and containing costs. Most previous research\nconsiders supervised approaches, assuming a sufficient number of anomalously\nlabeled samples. On the contrary, Visual Anomaly Detection (VAD), an emerging\nresearch domain, focuses on unsupervised learning, avoiding the costly defect\ncollection phase while providing explanations of the predictions. We introduce\na benchmark for VAD in the semiconductor domain by leveraging the MIIC dataset.\nOur results demonstrate the efficacy of modern VAD approaches in this field.",
      "tldr_zh": "本研究评估了现代视觉异常检测（VAD）方法在半导体制造中的性能，通过一个比较性研究对比了传统监督方法和新兴的无监督 VAD 技术。研究者利用 MIIC 数据集引入了一个针对半导体领域的 VAD 基准，专注于 Scanning Electron Microscope (SEM) 图像的自动视觉检查，以减少设备停机时间和成本。结果显示，VAD 方法在避免昂贵的缺陷标记阶段的同时，提供预测解释，并证明其在实际应用中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07576v1",
      "published_date": "2025-05-12 13:56:59 UTC",
      "updated_date": "2025-05-12 13:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:04:34.442049"
    },
    {
      "arxiv_id": "2505.07573v1",
      "title": "Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework",
      "title_zh": "鲁棒的肾脏异常分割：基于AI框架的验证研究",
      "authors": [
        "Sarah de Boer",
        "Hartmut Häntze",
        "Kiran Vaidhya Venkadesh",
        "Myrthe A. D. Buser",
        "Gabriel E. Humpire Mamani",
        "Lina Xu",
        "Lisa C. Adams",
        "Jawed Nawabi",
        "Keno K. Bressem",
        "Bram van Ginneken",
        "Mathias Prokop",
        "Alessa Hering"
      ],
      "abstract": "Kidney abnormality segmentation has important potential to enhance the\nclinical workflow, especially in settings requiring quantitative assessments.\nKidney volume could serve as an important biomarker for renal diseases, with\nchanges in volume correlating directly with kidney function. Currently,\nclinical practice often relies on subjective visual assessment for evaluating\nkidney size and abnormalities, including tumors and cysts, which are typically\nstaged based on diameter, volume, and anatomical location. To support a more\nobjective and reproducible approach, this research aims to develop a robust,\nthoroughly validated kidney abnormality segmentation algorithm, made publicly\navailable for clinical and research use. We employ publicly available training\ndatasets and leverage the state-of-the-art medical image segmentation framework\nnnU-Net. Validation is conducted using both proprietary and public test\ndatasets, with segmentation performance quantified by Dice coefficient and the\n95th percentile Hausdorff distance. Furthermore, we analyze robustness across\nsubgroups based on patient sex, age, CT contrast phases, and tumor histologic\nsubtypes. Our findings demonstrate that our segmentation algorithm, trained\nexclusively on publicly available data, generalizes effectively to external\ntest sets and outperforms existing state-of-the-art models across all tested\ndatasets. Subgroup analyses reveal consistent high performance, indicating\nstrong robustness and reliability. The developed algorithm and associated code\nare publicly accessible at\nhttps://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.",
      "tldr_zh": "本研究针对肾脏异常分割问题，开发了一个基于 AI 的鲁棒框架，旨在提供更客观、可再现的临床评估方法，以取代主观视觉评估。研究使用公开数据集和 nnU-Net 框架进行训练，并通过 Dice coefficient 和 95th percentile Hausdorff distance 等指标在专有及公开测试集上进行验证。结果表明，该算法在外部数据集上泛化良好，优于现有模型，并在基于患者性别、年龄、CT 对比相和肿瘤组织亚型的子群分析中显示出一致的高性能。该框架及其代码已公开提供，供临床和研究使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07573v1",
      "published_date": "2025-05-12 13:53:19 UTC",
      "updated_date": "2025-05-12 13:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:04:47.466027"
    },
    {
      "arxiv_id": "2505.07911v1",
      "title": "Combining Bayesian Inference and Reinforcement Learning for Agent Decision Making: A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Chengmin Zhou",
        "Ville Kyrki",
        "Pasi Fränti",
        "Laura Ruotsalainen"
      ],
      "abstract": "Bayesian inference has many advantages in decision making of agents (e.g.\nrobotics/simulative agent) over a regular data-driven black-box neural network:\nData-efficiency, generalization, interpretability, and safety where these\nadvantages benefit directly/indirectly from the uncertainty quantification of\nBayesian inference. However, there are few comprehensive reviews to summarize\nthe progress of Bayesian inference on reinforcement learning (RL) for decision\nmaking to give researchers a systematic understanding. This paper focuses on\ncombining Bayesian inference with RL that nowadays is an important approach in\nagent decision making. To be exact, this paper discusses the following five\ntopics: 1) Bayesian methods that have potential for agent decision making.\nFirst basic Bayesian methods and models (Bayesian rule, Bayesian learning, and\nBayesian conjugate models) are discussed followed by variational inference,\nBayesian optimization, Bayesian deep learning, Bayesian active learning,\nBayesian generative models, Bayesian meta-learning, and lifelong Bayesian\nlearning. 2) Classical combinations of Bayesian methods with model-based RL\n(with approximation methods), model-free RL, and inverse RL. 3) Latest\ncombinations of potential Bayesian methods with RL. 4) Analytical comparisons\nof methods that combine Bayesian methods with RL with respect to\ndata-efficiency, generalization, interpretability, and safety. 5) In-depth\ndiscussions in six complex problem variants of RL, including unknown reward,\npartial-observability, multi-agent, multi-task, non-linear non-Gaussian, and\nhierarchical RL problems and the summary of how Bayesian methods work in the\ndata collection, data processing and policy learning stages of RL to pave the\nway for better agent decision-making strategies.",
      "tldr_zh": "这篇综述论文探讨了将Bayesian Inference与Reinforcement Learning (RL)结合用于代理决策（如机器人或模拟代理）的优势，包括数据效率、一般化、可解释性和安全性。论文系统总结了Bayesian方法（如Bayesian规则、变分推理、Bayesian优化等）及其与模型-based RL、模型-free RL和inverse RL的经典及最新结合方式，并进行了分析比较。最终，论文深入讨论了Bayesian方法在RL的复杂变体（如未知奖励、多代理或分层RL问题）中的作用，为提升代理决策策略提供全面指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07911v1",
      "published_date": "2025-05-12 13:34:50 UTC",
      "updated_date": "2025-05-12 13:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:04:58.949721"
    },
    {
      "arxiv_id": "2505.07553v1",
      "title": "Towards Requirements Engineering for RAG Systems",
      "title_zh": "面向 RAG 系统的需求工程研究",
      "authors": [
        "Tor Sporsem",
        "Rasmus Ulfsnes"
      ],
      "abstract": "This short paper explores how a maritime company develops and integrates\nlarge-language models (LLM). Specifically by looking at the requirements\nengineering for Retrieval Augmented Generation (RAG) systems in expert\nsettings. Through a case study at a maritime service provider, we demonstrate\nhow data scientists face a fundamental tension between user expectations of AI\nperfection and the correctness of the generated outputs. Our findings reveal\nthat data scientists must identify context-specific \"retrieval requirements\"\nthrough iterative experimentation together with users because they are the ones\nwho can determine correctness. We present an empirical process model describing\nhow data scientists practically elicited these \"retrieval requirements\" and\nmanaged system limitations. This work advances software engineering knowledge\nby providing insights into the specialized requirements engineering processes\nfor implementing RAG systems in complex domain-specific applications.",
      "tldr_zh": "这篇论文探讨了在专家环境中为检索增强生成（RAG）系统进行需求工程（Requirements Engineering）的过程，通过一个海事公司的案例研究揭示了数据科学家在用户对AI完美期望与生成输出正确性之间面临的根本张力。研究发现，数据科学家必须通过与用户的迭代实验来识别特定上下文的“retrieval requirements”，以评估和确保输出正确性，并管理系统限制。作者呈现了一个经验过程模型，描述了数据科学家如何实际引出这些需求并应对挑战。该工作推进了软件工程知识，提供对在复杂领域特定应用中实施RAG系统的专业见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to EASE 2025, 17-20 June, Istanbul, Turkey",
      "pdf_url": "http://arxiv.org/pdf/2505.07553v1",
      "published_date": "2025-05-12 13:30:44 UTC",
      "updated_date": "2025-05-12 13:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:05:11.790471"
    },
    {
      "arxiv_id": "2505.07552v1",
      "title": "Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies",
      "title_zh": "使用移动眼动追踪在行为课堂研究中的自动视觉注意力检测",
      "authors": [
        "Efe Bozkir",
        "Christian Kosel",
        "Tina Seidel",
        "Enkelejda Kasneci"
      ],
      "abstract": "Teachers' visual attention and its distribution across the students in\nclassrooms can constitute important implications for student engagement,\nachievement, and professional teacher training. Despite that, inferring the\ninformation about where and which student teachers focus on is not trivial.\nMobile eye tracking can provide vital help to solve this issue; however, the\nuse of mobile eye tracking alone requires a significant amount of manual\nannotations. To address this limitation, we present an automated processing\npipeline concept that requires minimal manually annotated data to recognize\nwhich student the teachers focus on. To this end, we utilize state-of-the-art\nface detection models and face recognition feature embeddings to train face\nrecognition models with transfer learning in the classroom context and combine\nthese models with the teachers' gaze from mobile eye trackers. We evaluated our\napproach with data collected from four different classrooms, and our results\nshow that while it is possible to estimate the visually focused students with\nreasonable performance in all of our classroom setups, U-shaped and small\nclassrooms led to the best results with accuracies of approximately 0.7 and\n0.9, respectively. While we did not evaluate our method for teacher-student\ninteractions and focused on the validity of the technical approach, as our\nmethodology does not require a vast amount of manually annotated data and\noffers a non-intrusive way of handling teachers' visual attention, it could\nhelp improve instructional strategies, enhance classroom management, and\nprovide feedback for professional teacher development.",
      "tldr_zh": "该论文提出了一种自动化视觉注意力检测方法，使用 mobile eye tracking 来分析教师在课堂上的注意力分布，从而评估其对学生参与和成就的影响。方法结合了 state-of-the-art face detection 模型、face recognition feature embeddings 和 transfer learning，通过迁移学习训练面部识别模型，仅需少量手动标注数据即可实现精确识别。实验结果显示，在四个不同课堂环境中，U-shaped 和小型课堂的准确率最高，分别为约0.7和0.9，这为非侵入式改善教学策略、课堂管理和教师专业发展提供了实用工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a long paper at the Educational Data Mining (EDM)\n  Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07552v1",
      "published_date": "2025-05-12 13:30:30 UTC",
      "updated_date": "2025-05-12 13:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:05:23.211981"
    },
    {
      "arxiv_id": "2505.07548v1",
      "title": "Noise Optimized Conditional Diffusion for Domain Adaptation",
      "title_zh": "噪声优化的条件",
      "authors": [
        "Lingkun Luo",
        "Shiqiang Hu",
        "Liming Chen"
      ],
      "abstract": "Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet\nthe scarcity of High-Confidence Pseudo-Labeled Target Domain Samples\n(\\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical\nalignment, causing DA failures. To address this challenge, we propose\n\\textbf{N}oise \\textbf{O}ptimized \\textbf{C}onditional \\textbf{D}iffusion for\n\\textbf{D}omain \\textbf{A}daptation (\\textbf{NOCDDA}), which seamlessly\nintegrates the generative capabilities of conditional diffusion models with the\ndecision-making requirements of DA to achieve task-coupled optimization for\nefficient adaptation. For robust cross-domain consistency, we modify the DA\nclassifier to align with the conditional diffusion classifier within a unified\noptimization framework, enabling forward training on noise-varying cross-domain\nsamples. Furthermore, we argue that the conventional \\( \\mathcal{N}(\\mathbf{0},\n\\mathbf{I}) \\) initialization in diffusion models often generates\nclass-confused hcpl-tds, compromising discriminative DA. To resolve this, we\nintroduce a class-aware noise optimization strategy that refines sampling\nregions for reverse class-specific hcpl-tds generation, effectively enhancing\ncross-domain alignment. Extensive experiments across 5 benchmark datasets and\n29 DA tasks demonstrate significant performance gains of \\textbf{NOCDDA} over\n31 state-of-the-art methods, validating its robustness and effectiveness.",
      "tldr_zh": "这篇论文针对Unsupervised Domain Adaptation (UDA)中High-Confidence Pseudo-Labeled Target Domain Samples (hcpl-tds)的稀缺问题，提出了Noise Optimized Conditional Diffusion for Domain Adaptation (NOCDDA)方法，通过整合条件扩散模型的生成能力与DA的决策需求，实现任务相关的优化框架。NOCDDA修改DA分类器以与条件扩散分类器对齐，并在统一框架下进行噪声变化样本的前向训练，同时引入类感知噪声优化策略，优化采样区域以生成更精确的hcpl-tds，从而提升跨域对齐。实验在5个基准数据集和29个UDA任务上显示，NOCDDA比31个最先进方法有显著性能提升，证明了其鲁棒性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures This work has been accepted by the International\n  Joint Conference on Artificial Intelligence (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.07548v1",
      "published_date": "2025-05-12 13:28:31 UTC",
      "updated_date": "2025-05-12 13:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:05:35.944640"
    },
    {
      "arxiv_id": "2505.07546v1",
      "title": "GRADA: Graph-based Reranker against Adversarial Documents Attack",
      "title_zh": "翻译失败",
      "authors": [
        "Jingjie Zheng",
        "Aryo Pradipta Gema",
        "Giwon Hong",
        "Xuanli He",
        "Pasquale Minervini",
        "Youcheng Sun",
        "Qiongkai Xu"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large\nlanguage models (LLMs) by integrating external knowledge from retrieved\ndocuments, thereby overcoming the limitations of models' static intrinsic\nknowledge. However, these systems are susceptible to adversarial attacks that\nmanipulate the retrieval process by introducing documents that are adversarial\nyet semantically similar to the query. Notably, while these adversarial\ndocuments resemble the query, they exhibit weak similarity to benign documents\nin the retrieval set. Thus, we propose a simple yet effective Graph-based\nReranking against Adversarial Document Attacks (GRADA) framework aiming at\npreserving retrieval quality while significantly reducing the success of\nadversaries. Our study evaluates the effectiveness of our approach through\nexperiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b,\nLlama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with\nresults from the Natural Questions dataset demonstrating up to an 80% reduction\nin attack success rates while maintaining minimal loss in accuracy.",
      "tldr_zh": "该论文提出 GRADA 框架，这是一个基于图形的重新排序方法，用于对抗 Retrieval Augmented Generation (RAG) 系统中的文档攻击问题。GRADA 通过构建图形结构来识别并降低与查询语义相似但与正常文档弱相关的对抗文档，从而在保持检索质量的同时显著减少攻击成功率。实验在五个 LLM（包括 GPT-3.5-Turbo、GPT-4o、Llama3.1-8b、Llama3.1-70b 和 Qwen2.5-7b）上进行，使用三个数据集评估，结果显示在 Natural Questions 数据集上攻击成功率降低高达 80%，而准确性损失最小。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07546v1",
      "published_date": "2025-05-12 13:27:35 UTC",
      "updated_date": "2025-05-12 13:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:05:47.711976"
    },
    {
      "arxiv_id": "2505.07910v1",
      "title": "Tuning for Trustworthiness -- Balancing Performance and Explanation Consistency in Neural Network Optimization",
      "title_zh": "针对可信度的调优——在神经网络优化中平衡性能和解释一致性",
      "authors": [
        "Alexander Hinterleitner",
        "Thomas Bartz-Beielstein"
      ],
      "abstract": "Despite the growing interest in Explainable Artificial Intelligence (XAI),\nexplainability is rarely considered during hyperparameter tuning or neural\narchitecture optimization, where the focus remains primarily on minimizing\npredictive loss. In this work, we introduce the novel concept of XAI\nconsistency, defined as the agreement among different feature attribution\nmethods, and propose new metrics to quantify it. For the first time, we\nintegrate XAI consistency directly into the hyperparameter tuning objective,\ncreating a multi-objective optimization framework that balances predictive\nperformance with explanation robustness. Implemented within the Sequential\nParameter Optimization Toolbox (SPOT), our approach uses both weighted\naggregation and desirability-based strategies to guide model selection. Through\nour proposed framework and supporting tools, we explore the impact of\nincorporating XAI consistency into the optimization process. This enables us to\ncharacterize distinct regions in the architecture configuration space: one\nregion with poor performance and comparatively low interpretability, another\nwith strong predictive performance but weak interpretability due to low\n\\gls{xai} consistency, and a trade-off region that balances both objectives by\noffering high interpretability alongside competitive performance. Beyond\nintroducing this novel approach, our research provides a foundation for future\ninvestigations into whether models from the trade-off zone-balancing\nperformance loss and XAI consistency-exhibit greater robustness by avoiding\noverfitting to training performance, thereby leading to more reliable\npredictions on out-of-distribution data.",
      "tldr_zh": "本文提出了一种新方法，将可解释人工智能（XAI）一致性——即不同特征归因方法之间的同意度——整合到神经网络超参数调优中，创建多目标优化框架，以平衡预测性能和解释鲁棒性。研究使用Sequential Parameter Optimization Toolbox (SPOT)工具，采用加权聚合和基于期望性的策略，探索架构配置空间的不同区域，包括性能差的低解释性区域、高性能但低XAI一致性的区域，以及权衡性能与解释性的最佳区域。主要发现表明，这种框架可能帮助模型避免过拟合，提高对分布外数据的可靠预测，为未来XAI优化研究奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07910v1",
      "published_date": "2025-05-12 13:19:14 UTC",
      "updated_date": "2025-05-12 13:19:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:06:00.161402"
    },
    {
      "arxiv_id": "2505.07534v1",
      "title": "The Human-Data-Model Interaction Canvas for Visual Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Jürgen Bernard"
      ],
      "abstract": "Visual Analytics (VA) integrates humans, data, and models as key actors in\ninsight generation and data-driven decision-making. This position paper values\nand reflects on 16 VA process models and frameworks and makes nine high-level\nobservations that motivate a fresh perspective on VA. The contribution is the\nHDMI Canvas, a perspective to VA that complements the strengths of existing VA\nprocess models and frameworks. It systematically characterizes diverse roles of\nhumans, data, and models, and how these actors benefit from and contribute to\nVA processes. The descriptive power of the HDMI Canvas eases the\ndifferentiation between a series of VA building blocks, rather than describing\ngeneral VA principles only. The canvas includes modern human-centered\nmethodologies, including human knowledge externalization and forms of feedback\nloops, while interpretable and explainable AI highlight model contributions\nbeyond their conventional outputs. The HDMI Canvas has generative power,\nguiding the design of new VA processes and is optimized for external\nstakeholders, improving VA outreach, interdisciplinary collaboration, and\nuser-centered design. The utility of the HDMI Canvas is demonstrated through\ntwo preliminary case studies.",
      "tldr_zh": "这篇论文回顾了16个Visual Analytics (VA)过程模型和框架，并基于九个高层观察提出HDMI Canvas作为一种新视角，以补充现有模型的优点。HDMI Canvas系统地描绘了人类、数据和模型在VA中的多样角色，包括人类知识外化、反馈循环以及interpretable and explainable AI的贡献，从而便于区分VA的构建块并指导新过程设计。该框架优化了外部利益相关者的参与，提升VA的推广、跨学科合作和用户中心设计，并通过两个初步案例研究验证了其实用性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 5 figures, LaTeX; to appear at the 16th International\n  EuroVis Workshop on Visual Analytics (EuroVA'25) as a position paper",
      "pdf_url": "http://arxiv.org/pdf/2505.07534v1",
      "published_date": "2025-05-12 13:15:31 UTC",
      "updated_date": "2025-05-12 13:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:06:12.292888"
    },
    {
      "arxiv_id": "2505.07533v1",
      "title": "IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Fall",
        "Federica Granese",
        "Alex Lence",
        "Dominique Fourer",
        "Blaise Hanczar",
        "Joe-Elie Salem",
        "Jean-Daniel Zucker",
        "Edi Prifti"
      ],
      "abstract": "Monitoring and analyzing electrocardiogram (ECG) signals, even under varying\nphysiological conditions, including those influenced by physical activity,\ndrugs and stress, is crucial to accurately assess cardiac health. However,\ncurrent AI-based methods often fail to account for how these factors interact\nand alter ECG patterns, ultimately limiting their applicability in real-world\nsettings. This study introduces IKrNet, a novel neural network model, which\nidentifies drug-specific patterns in ECGs amidst certain physiological\nconditions. IKrNet's architecture incorporates spatial and temporal dynamics by\nusing a convolutional backbone with varying receptive field size to capture\nspatial features. A bi-directional Long Short-Term Memory module is also\nemployed to model temporal dependencies. By treating heart rate variability as\na surrogate for physiological fluctuations, we evaluated IKrNet's performance\nacross diverse scenarios, including conditions with physical stress, drug\nintake alone, and a baseline without drug presence. Our assessment follows a\nclinical protocol in which 990 healthy volunteers were administered 80mg of\nSotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a\nlife-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art\nmodels' accuracy and stability in varying physiological conditions,\nunderscoring its clinical viability.",
      "tldr_zh": "该论文介绍了IKrNet，一种新型神经网络模型，旨在在生理变异性（如身体活动、药物和压力）条件下检测ECG中的药物特定模式，以解决现有AI方法忽略因素交互的局限性。IKrNet的架构结合了卷积骨干（convolutional backbone）以捕捉不同感受野大小的空间特征，以及双向Long Short-Term Memory模块来建模时间依赖。实验通过990名健康志愿者服用Sotalol的临床协议评估，IKrNet在各种场景下表现出优于现有模型的准确性和稳定性，突显了其临床可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07533v1",
      "published_date": "2025-05-12 13:14:47 UTC",
      "updated_date": "2025-05-12 13:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:06:24.976325"
    },
    {
      "arxiv_id": "2505.07531v1",
      "title": "QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads",
      "title_zh": "翻译失败",
      "authors": [
        "Khurram Mazher",
        "Saad Bin Nasir"
      ],
      "abstract": "We present QuantX: a tailored suite of recipes for LLM and VLM quantization.\nIt is capable of quantizing down to 3-bit resolutions with minimal loss in\nperformance. The quantization strategies in QuantX take into account\nhardware-specific constraints to achieve efficient dequantization during\ninference ensuring flexible trade-off between runtime speed, memory requirement\nand model accuracy. Our results demonstrate that QuantX achieves performance\nwithin 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for\nmultiple end user tasks and outperforms recently published state-of-the-art\nquantization techniques. This manuscript provides insights into the LLM\nquantization process that motivated the range of recipes and options that are\nincorporated in QuantX.",
      "tldr_zh": "本研究提出了 QuantX 框架，这是一个针对生成式 AI 工作负载的硬件感知量化工具套件，能够将 LLM 和 VLM 量化到 3 位分辨率，同时最小化性能损失。QuantX 的量化策略考虑硬件特定约束，实现高效的去量化过程，并在运行速度、内存需求和模型准确性之间提供灵活权衡。实验结果显示，QuantX 在 LlaVa-v1.6 量化到 3 位时，性能仅比未量化模型低 6%，并优于现有最先进量化技术；此外，论文还提供了 LLM 量化过程的见解和选项。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07531v1",
      "published_date": "2025-05-12 13:13:06 UTC",
      "updated_date": "2025-05-12 13:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:06:38.411861"
    },
    {
      "arxiv_id": "2505.07512v1",
      "title": "ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Huang",
        "Weiwen Liu",
        "Xingshan Zeng",
        "Yuefeng Huang",
        "Xinlong Hao",
        "Yuxian Wang",
        "Yirong Zeng",
        "Chuhan Wu",
        "Yasheng Wang",
        "Ruiming Tang",
        "Defu Lian"
      ],
      "abstract": "The tool-using capability of large language models (LLMs) enables them to\naccess up-to-date external information and handle complex tasks. Current\napproaches to enhancing this capability primarily rely on distilling advanced\nmodels by data synthesis. However, this method incurs significant costs\nassociated with advanced model usage and often results in data compatibility\nissues, led by the high discrepancy in the knowledge scope between the advanced\nmodel and the target model. To address these challenges, we propose\nToolACE-DEV, a self-improving framework for tool learning. First, we decompose\nthe tool-learning objective into sub-tasks that enhance basic tool-making and\ntool-using abilities. Then, we introduce a self-evolving paradigm that allows\nlightweight models to self-improve, reducing reliance on advanced LLMs.\nExtensive experiments validate the effectiveness of our approach across models\nof varying scales and architectures.",
      "tldr_zh": "该研究提出ToolACE-DEV框架，通过分解工具学习目标为子任务（如提升基本工具制作和使用能力），并引入自演化范式，让轻量级LLMs模型实现自我改进，从而减少对高级模型的依赖，避免数据合成带来的高成本和兼容性问题。该方法解决了现有工具学习方法的局限性，并在各种规模和架构的模型上进行了广泛实验，验证了其有效性。总的来说，ToolACE-DEV为LLMs的工具使用能力提供了更高效的自提升途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07512v1",
      "published_date": "2025-05-12 12:48:30 UTC",
      "updated_date": "2025-05-12 12:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:06:48.170316"
    },
    {
      "arxiv_id": "2505.07511v1",
      "title": "MAIS: Memory-Attention for Interactive Segmentation",
      "title_zh": "MAIS：用于交互式分割的记忆注意力机制",
      "authors": [
        "Mauricio Orbes-Arteaga",
        "Oeslle Lucena",
        "Sabastien Ourselin",
        "M. Jorge Cardoso"
      ],
      "abstract": "Interactive medical segmentation reduces annotation effort by refining\npredictions through user feedback. Vision Transformer (ViT)-based models, such\nas the Segment Anything Model (SAM), achieve state-of-the-art performance using\nuser clicks and prior masks as prompts. However, existing methods treat\ninteractions as independent events, leading to redundant corrections and\nlimited refinement gains. We address this by introducing MAIS, a\nMemory-Attention mechanism for Interactive Segmentation that stores past user\ninputs and segmentation states, enabling temporal context integration. Our\napproach enhances ViT-based segmentation across diverse imaging modalities,\nachieving more efficient and accurate refinements.",
      "tldr_zh": "交互式医疗分割通过用户反馈减少标注努力，但现有基于Vision Transformer (ViT)的方法，如Segment Anything Model (SAM)，将交互视为独立事件，导致冗余修正和改进有限。研究提出MAIS（Memory-Attention机制），它存储过去的用户输入和分割状态，实现时间上下文的整合，从而提升分割模型的效率。实验结果显示，MAIS在多种成像模式下显著提高了基于ViT的分割准确性和精炼能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07511v1",
      "published_date": "2025-05-12 12:48:27 UTC",
      "updated_date": "2025-05-12 12:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:06:59.733986"
    },
    {
      "arxiv_id": "2505.07509v1",
      "title": "HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Ding",
        "Tingting Wang",
        "Yupeng Gao",
        "Shuo Yu",
        "Jing Ren",
        "Feng Xia"
      ],
      "abstract": "Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the\nexpiration date of facts, which negatively impact reasoning performance on\nTKGs. However, existing reasoning methods primarily focus on positive\nimportance of historical facts, neglecting adverse effects of outdated facts.\nBesides, training on these outdated facts yields extra computational cost. To\naddress these challenges, we propose an outdated fact filtering framework named\nHALO, which quantifies the temporal validity of historical facts by exploring\nthe half-life theory to filter outdated facts in TKGs. HALO consists of three\nmodules: the temporal fact attention module, the dynamic relation-aware encoder\nmodule, and the outdated fact filtering module. Firstly, the temporal fact\nattention module captures the evolution of historical facts over time to\nidentify relevant facts. Secondly, the dynamic relation-aware encoder module is\ndesigned for efficiently predicting the half life of each fact. Finally, we\nconstruct a time decay function based on the half-life theory to quantify the\ntemporal validity of facts and filter outdated facts. Experimental results show\nthat HALO outperforms the state-of-the-art TKG reasoning methods on three\npublic datasets, demonstrating its effectiveness in detecting and filtering\noutdated facts (Codes are available at\nhttps://github.com/yushuowiki/K-Half/tree/main ).",
      "tldr_zh": "该研究针对时间知识图谱(Temporal Knowledge Graphs, TKGs)中过时事实导致的推理性能下降问题，提出了一种基于半衰期理论(Half Life-Based)的过滤框架HALO，以减少计算成本并缓解负面影响。HALO包括三个模块：temporal fact attention module用于捕捉历史事实的演变并识别相关事实；dynamic relation-aware encoder module用于预测每个事实的半衰期；outdated fact filtering module则基于半衰期构建时间衰减函数，量化事实的时效性并进行过滤。实验结果显示，HALO在三个公开数据集上优于现有TKG推理方法，证明了其在检测和过滤过时事实方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07509v1",
      "published_date": "2025-05-12 12:47:20 UTC",
      "updated_date": "2025-05-12 12:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:07:12.272133"
    },
    {
      "arxiv_id": "2505.07508v1",
      "title": "EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection",
      "title_zh": "EAGLE：用于高效图异常检测的对比学习",
      "authors": [
        "Jing Ren",
        "Mingliang Hou",
        "Zhixuan Liu",
        "Xiaomei Bai"
      ],
      "abstract": "Graph anomaly detection is a popular and vital task in various real-world\nscenarios, which has been studied for several decades. Recently, many studies\nextending deep learning-based methods have shown preferable performance on\ngraph anomaly detection. However, existing methods are lack of efficiency that\nis definitely necessary for embedded devices. Towards this end, we propose an\nEfficient Anomaly detection model on heterogeneous Graphs via contrastive\nLEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of\ntheir distances to the local context. The proposed method first samples\ninstance pairs on meta path-level for contrastive learning. Then, a graph\nautoencoder-based model is applied to learn informative node embeddings in an\nunsupervised way, which will be further combined with the discriminator to\npredict the anomaly scores of nodes. Experimental results show that EAGLE\noutperforms the state-of-the-art methods on three heterogeneous network\ndatasets.",
      "tldr_zh": "本文提出 EAGLE 模型，通过 Contrastive Learning 对比异常节点与正常节点的距离，实现高效的 Graph Anomaly Detection，尤其适用于嵌入式设备。方法包括在 meta path 级别采样实例对进行对比学习，然后使用 graph autoencoder 在无监督方式下学习节点嵌入，并结合 discriminator 预测节点的异常分数。实验结果表明，EAGLE 在三个异构网络数据集上优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07508v1",
      "published_date": "2025-05-12 12:45:07 UTC",
      "updated_date": "2025-05-12 12:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:07:24.141183"
    },
    {
      "arxiv_id": "2505.07908v1",
      "title": "A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny",
      "title_zh": "翻译失败",
      "authors": [
        "Karahan Sarıtaş",
        "Çağatay Yıldız"
      ],
      "abstract": "In this reproduction study, we revisit recent claims that self-attention\nimplements kernel principal component analysis (KPCA) (Teo et al., 2024),\npositing that (i) value vectors $V$ capture the eigenvectors of the Gram matrix\nof the keys, and (ii) that self-attention projects queries onto the principal\ncomponent axes of the key matrix $K$ in a feature space. Our analysis reveals\nthree critical inconsistencies: (1) No alignment exists between learned\nself-attention value vectors and what is proposed in the KPCA perspective, with\naverage similarity metrics (optimal cosine similarity $\\leq 0.32$, linear CKA\n(Centered Kernel Alignment) $\\leq 0.11$, kernel CKA $\\leq 0.32$) indicating\nnegligible correspondence; (2) Reported decreases in reconstruction loss\n$J_\\text{proj}$, arguably justifying the claim that the self-attention\nminimizes the projection error of KPCA, are misinterpreted, as the quantities\ninvolved differ by orders of magnitude ($\\sim\\!10^3$); (3) Gram matrix\neigenvalue statistics, introduced to justify that $V$ captures the eigenvector\nof the gram matrix, are irreproducible without undocumented\nimplementation-specific adjustments. Across 10 transformer architectures, we\nconclude that the KPCA interpretation of self-attention lacks empirical\nsupport.",
      "tldr_zh": "本研究对 Teo et al. (2024) 的声明进行了再现性检验，即自-attention 机制实现了核主成分分析 (KPCA)，其中值向量 $V$ 捕捉 Gram 矩阵的特征向量，且自-attention 将查询投影到关键矩阵 $K$ 的主成分轴上。分析揭示了三个关键不一致性：(1) 学习到的值向量与 KPCA 视角的特征向量对齐度极低（最佳 cosine similarity ≤ 0.32，linear CKA ≤ 0.11，kernel CKA ≤ 0.32）；(2) 重建损失 $J_\\text{proj}$ 的减少被误解，因为涉及量级差异达数千倍；(3) Gram 矩阵的特征值统计不可再现，需要未记录的实现调整。在 10 个 Transformer 架构上，研究得出自-attention 的 KPCA 解释缺乏经验支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07908v1",
      "published_date": "2025-05-12 12:38:46 UTC",
      "updated_date": "2025-05-12 12:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:07:38.379011"
    },
    {
      "arxiv_id": "2505.07473v1",
      "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Xu",
        "YiWei Mao",
        "XinYi Guan",
        "ZiLong Feng"
      ],
      "abstract": "The application of large language models (LLMs) in the field of coding is\nevolving rapidly: from code assistants, to autonomous coding agents, and then\nto generating complete projects through natural language. Early LLM code\nbenchmarks primarily focused on code generation accuracy, but these benchmarks\nhave gradually become saturated. Benchmark saturation weakens their guiding\nrole for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%.\nAmong various attempts to address benchmark saturation, approaches based on\nsoftware engineering have stood out, but the saturation of existing software\nengineering benchmarks is rapidly increasing. To address this, we propose a new\nbenchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks\nwith sequential dependencies. The tasks implement project features in sequence,\nsimulating real-world human development workflows. When designing Web-Bench, we\naim to cover the foundational elements of Web development: Web Standards and\nWeb Frameworks. Given the scale and complexity of these projects, which were\ndesigned by engineers with 5 to 10 years of experience, each presents a\nsignificant challenge. On average, a single project takes 4 to 8 hours for a\nsenior engineer to complete. On our given benchmark agent (Web-Agent), SOTA\n(Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better)\nthan SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss\nthat in any development field, Standards and Frameworks represent foundational\nknowledge and efficiency tools, respectively, and LLMs require optimization\ntailored to them.",
      "tldr_zh": "该研究针对大型语言模型(LLM)代码基准的饱和问题，提出了一种新基准Web-Bench，由50个项目组成，每个项目包含20个顺序依赖任务，模拟真实Web开发工作流。Web-Bench聚焦于Web Standards和Web Frameworks的核心元素，由经验丰富的工程师设计，每个项目平均需4-8小时完成。实验结果显示，在Web-Agent上，SOTA模型(Claude 3.7 Sonnet)的Pass@1仅为25.1%，远低于现有软件工程基准(SWE-Bench)，突显LLM在处理复杂Web任务时的不足。最后，论文强调Standards和Frameworks是开发领域的关键基础，LLM需针对这些方面进行优化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07473v1",
      "published_date": "2025-05-12 12:06:23 UTC",
      "updated_date": "2025-05-12 12:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:07:49.318132"
    },
    {
      "arxiv_id": "2505.07460v1",
      "title": "A Survey on Collaborative Mechanisms Between Large and Small Language Models",
      "title_zh": "大型语言模型与小型语言模型协作机制的综述",
      "authors": [
        "Yi Chen",
        "JiaHao Zhao",
        "HaoHao Han"
      ],
      "abstract": "Large Language Models (LLMs) deliver powerful AI capabilities but face\ndeployment challenges due to high resource costs and latency, whereas Small\nLanguage Models (SLMs) offer efficiency and deployability at the cost of\nreduced performance. Collaboration between LLMs and SLMs emerges as a crucial\nparadigm to synergistically balance these trade-offs, enabling advanced AI\napplications, especially on resource-constrained edge devices. This survey\nprovides a comprehensive overview of LLM-SLM collaboration, detailing various\ninteraction mechanisms (pipeline, routing, auxiliary, distillation, fusion),\nkey enabling technologies, and diverse application scenarios driven by\non-device needs like low latency, privacy, personalization, and offline\noperation. While highlighting the significant potential for creating more\nefficient, adaptable, and accessible AI, we also discuss persistent challenges\nincluding system overhead, inter-model consistency, robust task allocation,\nevaluation complexity, and security/privacy concerns. Future directions point\ntowards more intelligent adaptive frameworks, deeper model fusion, and\nexpansion into multimodal and embodied AI, positioning LLM-SLM collaboration as\na key driver for the next generation of practical and ubiquitous artificial\nintelligence.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)和小型语言模型(SLMs)之间的协作机制，以平衡LLMs的高性能与SLMs的资源效率，适用于资源受限的边缘设备。论文概述了多种交互方式，包括pipeline、routing、auxiliary、distillation和fusion机制，以及关键技术和应用场景，如低延迟、隐私保护、个性化及离线操作。研究强调这种协作能推动高效、可适应的AI发展，但面临挑战如系统开销、模型一致性、任务分配复杂性及安全问题。未来方向包括开发智能自适应框架、更深层模型融合，以及扩展到多模态和具身AI领域。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07460v1",
      "published_date": "2025-05-12 11:48:42 UTC",
      "updated_date": "2025-05-12 11:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:08:01.346396"
    },
    {
      "arxiv_id": "2505.07457v1",
      "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments",
      "title_zh": "生成式 AI 代理能表现得像人类吗？——来自实验室市场实验的证据",
      "authors": [
        "R. Maria del Rio-Chanona",
        "Marco Pangallo",
        "Cars Hommes"
      ],
      "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human\nbehavior in economic market experiments. Compared to previous studies, we focus\non dynamic feedback between LLM agents: the decisions of each LLM impact the\nmarket price at the current step, and so affect the decisions of the other LLMs\nat the next step. We compare LLM behavior to market dynamics observed in\nlaboratory settings and assess their alignment with human participants'\nbehavior. Our findings indicate that LLMs do not adhere strictly to rational\nexpectations, displaying instead bounded rationality, similarly to human\nparticipants. Providing a minimal context window i.e. memory of three previous\ntime steps, combined with a high variability setting capturing response\nheterogeneity, allows LLMs to replicate broad trends seen in human experiments,\nsuch as the distinction between positive and negative feedback markets.\nHowever, differences remain at a granular level--LLMs exhibit less\nheterogeneity in behavior than humans. These results suggest that LLMs hold\npromise as tools for simulating realistic human behavior in economic contexts,\nthough further research is needed to refine their accuracy and increase\nbehavioral diversity.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)是否能在经济市场实验中模仿人类行为，重点考察动态反馈机制，即每个LLM的决策会影响市场价格并反馈到后续决策。结果显示，LLMs 表现出有限理性(bounded rationality)，类似于人类参与者，并在提供最小上下文窗口（前三个时间步的记忆）和高变异性设置下，能复制人类实验中的总体趋势，如正负反馈市场的区别。虽然后者行为异质性不如人类精确，但这些发现表明LLMs 有潜力作为模拟人类行为的工具，需要进一步研究来提升其准确性和多样性。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07457v1",
      "published_date": "2025-05-12 11:44:46 UTC",
      "updated_date": "2025-05-12 11:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:08:13.530033"
    },
    {
      "arxiv_id": "2505.07453v1",
      "title": "How well do LLMs reason over tabular data, really?",
      "title_zh": "LLMs 在表格数据上进行推理的效果到底有多好，真的吗？",
      "authors": [
        "Cornelius Wolff",
        "Madelon Hulsebos"
      ],
      "abstract": "Large Language Models (LLMs) excel in natural language tasks, but less is\nknown about their reasoning capabilities over tabular data. Prior analyses\ndevise evaluation strategies that poorly reflect an LLM's realistic performance\non tabular queries. Moreover, we have a limited understanding of the robustness\nof LLMs towards realistic variations in tabular inputs. Therefore, we ask: Can\ngeneral-purpose LLMs reason over tabular data, really?, and focus on two\nquestions 1) are tabular reasoning capabilities of general-purpose LLMs robust\nto real-world characteristics of tabular inputs, and 2) how can we\nrealistically evaluate an LLM's performance on analytical tabular queries?\nBuilding on a recent tabular reasoning benchmark, we first surface shortcomings\nof its multiple-choice prompt evaluation strategy, as well as commonly used\nfree-form text metrics such as SacreBleu and BERT-score. We show that an\nLLM-as-a-judge procedure yields more reliable performance insights and unveil a\nsignificant deficit in tabular reasoning performance of LLMs. We then extend\nthe tabular inputs reflecting three common characteristics in practice: 1)\nmissing values, 2) duplicate entities, and 3) structural variations.\nExperiments show that the tabular reasoning capabilities of general-purpose\nLLMs suffer from these variations, stressing the importance of improving their\nrobustness for realistic tabular inputs.",
      "tldr_zh": "该研究质疑大型语言模型 (LLMs) 在表格数据上的推理能力，指出现有评估策略（如多选提示和指标 SacreBleu、BERT-score）无法真实反映模型表现，并提出使用 LLM-as-a-judge 程序来获得更可靠的性能评估。实验揭示，LLMs 在处理真实表格输入时存在显著缺陷，尤其在面对缺失值、重复实体和结构变化等常见特性时，推理能力不鲁棒。论文强调，需要改进 LLMs 的鲁棒性，以更好地适应实际分析性表格查询。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07453v1",
      "published_date": "2025-05-12 11:35:28 UTC",
      "updated_date": "2025-05-12 11:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:08:25.778069"
    },
    {
      "arxiv_id": "2505.07450v3",
      "title": "Prototype Augmented Hypernetworks for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Neil De La Fuente",
        "Maria Pilligua",
        "Daniel Vidal",
        "Albin Soutiff",
        "Cecilia Curreli",
        "Daniel Cremers",
        "Andrey Barsky"
      ],
      "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting\nprior knowledge, but gradient updates for a new task often overwrite the\nweights learned earlier, causing catastrophic forgetting (CF). We propose\nPrototype-Augmented Hypernetworks (PAH), a framework where a single\nhypernetwork, conditioned on learnable task prototypes, dynamically generates\ntask-specific classifier heads on demand. To mitigate forgetting, PAH combines\ncross-entropy with dual distillation losses, one to align logits and another to\nalign prototypes, ensuring stable feature representations across tasks.\nEvaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves\nstate-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7\n% and 4.4 % forgetting, respectively, surpassing prior methods without storing\nsamples or heads.",
      "tldr_zh": "该研究针对持续学习(Continual Learning)中的灾难性遗忘(Catastrophic Forgetting)问题，提出了一种Prototype-Augmented Hypernetworks (PAH)框架，该框架使用一个超网络结合可学习的任务原型，动态生成任务特定的分类器头，并通过交叉熵损失和双重蒸馏损失（对齐logits和原型）来维持特征表示的稳定性。PAH无需存储样本或头，在Split-CIFAR100和TinyImageNet数据集上实现了74.5%和63.7%的准确率，遗忘率仅为1.7%和4.4%，超过了现有方法。总的来说，这一创新为高效的持续学习提供了新的基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2025 (LatinX in CV)",
      "pdf_url": "http://arxiv.org/pdf/2505.07450v3",
      "published_date": "2025-05-12 11:25:54 UTC",
      "updated_date": "2025-05-16 16:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:08:38.054085"
    },
    {
      "arxiv_id": "2505.07447v2",
      "title": "Unified Continuous Generative Models",
      "title_zh": "统一的连续生成模型",
      "authors": [
        "Peng Sun",
        "Yi Jiang",
        "Tao Lin"
      ],
      "abstract": "Recent advances in continuous generative models, including multi-step\napproaches like diffusion and flow-matching (typically requiring 8-1000\nsampling steps) and few-step methods such as consistency models (typically 1-8\nsteps), have demonstrated impressive generative performance. However, existing\nwork often treats these approaches as distinct paradigms, resulting in separate\ntraining and sampling methodologies. We introduce a unified framework for\ntraining, sampling, and analyzing these models. Our implementation, the Unified\nContinuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves\nstate-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a\n675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID\nin 20 steps and a few-step model reaching 1.42 FID in just 2 steps.\nAdditionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at\n250 steps) improves performance to 1.06 FID in only 40 steps. Code is available\nat: https://github.com/LINs-lab/UCGM.",
      "tldr_zh": "本论文提出了一种统一框架，用于训练、采样和分析连续生成模型，包括多步方法（如扩散模型和流匹配）和少步方法（如一致性模型），以解决现有方法的分离问题。该框架通过 UCGM-T（统一连续生成模型训练器）实现了最先进性能，例如在 ImageNet 256x256 上，使用 675M 扩散变压器训练的多步模型在 20 步达到 1.30 FID，几步模型在 2 步达到 1.42 FID。应用 UCGM-S（采样器）到预训练模型后，将原 250 步的 1.26 FID 优化到 40 步的 1.06 FID。该工作为生成模型提供了高效且统一的解决方案，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/LINs-lab/UCGM",
      "pdf_url": "http://arxiv.org/pdf/2505.07447v2",
      "published_date": "2025-05-12 11:15:39 UTC",
      "updated_date": "2025-05-20 12:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:08:50.634095"
    },
    {
      "arxiv_id": "2505.07437v1",
      "title": "LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaotian Lin",
        "Yanlin Qi",
        "Yizhang Zhu",
        "Themis Palpanas",
        "Chengliang Chai",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Instruction tuning has emerged as a critical paradigm for improving the\ncapabilities and alignment of large language models (LLMs). However, existing\niterative model-aware data selection methods incur significant computational\noverhead, as they rely on repeatedly performing full-dataset model inference to\nestimate sample utility for subsequent training iterations, creating a\nfundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient\niterative data selection framework that accurately estimates sample utility\nentirely within the standard training loop, eliminating the need for costly\nadditional model inference. At its core, LEAD introduces Instance-Level Dynamic\nUncertainty (IDU), a theoretically grounded utility function combining\ninstantaneous training loss, gradient-based approximation of loss changes, and\nexponential smoothing of historical loss signals. To further scale efficiently\nto large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy,\nadaptively prioritizing informative clusters through a multi-armed bandit\nmechanism, followed by precise fine-grained selection of high-utility samples\nusing IDU. Extensive experiments across four diverse benchmarks show that LEAD\nsignificantly outperforms state-of-the-art methods, improving average model\nperformance by 6.1%-10.8% while using only 2.5% of the training data and\nreducing overall training time by 5-10x.",
      "tldr_zh": "本研究提出LEAD，一种高效的迭代数据选择框架，用于优化大型语言模型(LLMs)的指令微调，以解决现有方法因反复全数据集模型推理而导致的计算开销问题。LEAD的核心是Instance-Level Dynamic Uncertainty (IDU)效用函数，该函数结合即时训练损失、梯度-based损失变化近似以及历史损失信号的指数平滑，并在标准训练循环中估算样本效用；此外，它采用两阶段粗到细策略，通过multi-armed bandit机制优先选择信息丰富的集群，再用IDU精确筛选高效用样本。在四个多样化基准上的实验显示，LEAD仅使用2.5%的训练数据，就比最先进方法提高模型性能6.1%-10.8%，并将整体训练时间减少5-10倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07437v1",
      "published_date": "2025-05-12 10:57:51 UTC",
      "updated_date": "2025-05-12 10:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:09:02.762823"
    },
    {
      "arxiv_id": "2505.13483v1",
      "title": "EmoMeta: A Multimodal Dataset for Fine-grained Emotion Classification in Chinese Metaphors",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyuan Lu",
        "Yuxi Liu",
        "Dongyu Zhang",
        "Zhiyao Wu",
        "Jing Ren",
        "Feng Xia"
      ],
      "abstract": "Metaphors play a pivotal role in expressing emotions, making them crucial for\nemotional intelligence. The advent of multimodal data and widespread\ncommunication has led to a proliferation of multimodal metaphors, amplifying\nthe complexity of emotion classification compared to single-mode scenarios.\nHowever, the scarcity of research on constructing multimodal metaphorical\nfine-grained emotion datasets hampers progress in this domain. Moreover,\nexisting studies predominantly focus on English, overlooking potential\nvariations in emotional nuances across languages. To address these gaps, we\nintroduce a multimodal dataset in Chinese comprising 5,000 text-image pairs of\nmetaphorical advertisements. Each entry is meticulously annotated for metaphor\noccurrence, domain relations and fine-grained emotion classification\nencompassing joy, love, trust, fear, sadness, disgust, anger, surprise,\nanticipation, and neutral. Our dataset is publicly accessible\n(https://github.com/DUTIR-YSQ/EmoMeta), facilitating further advancements in\nthis burgeoning field.",
      "tldr_zh": "本研究引入了 EmoMeta，这是一个多模态数据集，专注于中文隐喻中的细粒度情感分类，以填补现有研究的空白。数据集包含 5,000 个文本-图像对，源自隐喻广告，并对每个条目进行了详细标注，包括隐喻发生、领域关系以及 10 种细粒度情感（如 joy, love, trust, fear, sadness, disgust, anger, surprise, anticipation 和 neutral）。通过提供公开可访问的资源（https://github.com/DUTIR-YSQ/EmoMeta），这项工作有助于推进多模态情感分类领域的进展，特别是针对非英语语言的复杂情感 nuances。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13483v1",
      "published_date": "2025-05-12 10:23:39 UTC",
      "updated_date": "2025-05-12 10:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:09:15.152163"
    },
    {
      "arxiv_id": "2505.07903v1",
      "title": "SEM: Reinforcement Learning for Search-Efficient Large Language Models",
      "title_zh": "SEM：用于搜索高效大语言模型的强化学习",
      "authors": [
        "Zeyang Sha",
        "Shiwen Cui",
        "Weiqiang Wang"
      ],
      "abstract": "Recent advancements in Large Language Models(LLMs) have demonstrated their\ncapabilities not only in reasoning but also in invoking external tools,\nparticularly search engines. However, teaching models to discern when to invoke\nsearch and when to rely on their internal knowledge remains a significant\nchallenge. Existing reinforcement learning approaches often lead to redundant\nsearch behaviors, resulting in inefficiencies and over-cost. In this paper, we\npropose SEM, a novel post-training reinforcement learning framework that\nexplicitly trains LLMs to optimize search usage. By constructing a balanced\ndataset combining MuSiQue and MMLU, we create scenarios where the model must\nlearn to distinguish between questions it can answer directly and those\nrequiring external retrieval. We design a structured reasoning template and\nemploy Group Relative Policy Optimization(GRPO) to post-train the model's\nsearch behaviors. Our reward function encourages accurate answering without\nunnecessary search while promoting effective retrieval when needed.\nExperimental results demonstrate that our method significantly reduces\nredundant search operations while maintaining or improving answer accuracy\nacross multiple challenging benchmarks. This framework advances the model's\nreasoning efficiency and extends its capability to judiciously leverage\nexternal knowledge.",
      "tldr_zh": "本研究提出 SEM 框架，这是一种后训练强化学习方法，旨在优化大型语言模型 (LLMs) 的搜索引擎使用效率，解决现有方法导致的冗余搜索问题。框架通过构建平衡数据集（结合 MuSiQue 和 MMLU），训练模型区分可直接回答的问题与需要外部检索的问题，并采用结构化推理模板和 Group Relative Policy Optimization (GRPO) 来引导搜索行为，同时设计奖励函数鼓励准确回答和必要检索。实验结果显示，SEM 显著减少了冗余搜索操作，同时在多个基准测试中维持或提升了答案准确性，从而提高了 LLMs 的推理效率和对外部知识的智能利用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07903v1",
      "published_date": "2025-05-12 09:45:40 UTC",
      "updated_date": "2025-05-12 09:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:09:26.754107"
    },
    {
      "arxiv_id": "2505.07393v1",
      "title": "AI in Money Matters",
      "title_zh": "翻译失败",
      "authors": [
        "Nadine Sandjo Tchatchoua",
        "Richard Harper"
      ],
      "abstract": "In November 2022, Europe and the world by and large were stunned by the birth\nof a new large language model : ChatGPT. Ever since then, both academic and\npopulist discussions have taken place in various public spheres such as\nLinkedIn and X(formerly known as Twitter) with the view to both understand the\ntool and its benefits for the society. The views of real actors in professional\nspaces, especially in regulated industries such as finance and law have been\nlargely missing. We aim to begin to close this gap by presenting results from\nan empirical investigation conducted through interviews with professional\nactors in the Fintech industry. The paper asks the question, how and to what\nextent are large language models in general and ChatGPT in particular being\nadopted and used in the Fintech industry? The results show that while the\nfintech experts we spoke with see a potential in using large language models in\nthe future, a lot of questions marks remain concerning how they are policed and\ntherefore might be adopted in a regulated industry such as Fintech. This paper\naims to add to the existing academic discussing around large language models,\nwith a contribution to our understanding of professional viewpoints.",
      "tldr_zh": "该论文探讨了大型语言模型（如 ChatGPT）在金融科技（Fintech）行业的采用和应用，通过对专业人士的访谈进行实证调查。研究发现，虽然Fintech专家认可这些模型的未来潜力，但监管问题和不确定性阻碍了其广泛使用。作者强调，这有助于填补现有学术讨论中的空白，提供真实专业视角，以加深对AI在受监管行业中的作用的理解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07393v1",
      "published_date": "2025-05-12 09:43:51 UTC",
      "updated_date": "2025-05-12 09:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:09:37.512040"
    },
    {
      "arxiv_id": "2505.07381v1",
      "title": "Few-shot Semantic Encoding and Decoding for Video Surveillance",
      "title_zh": "翻译失败",
      "authors": [
        "Baoping Cheng",
        "Yukun Zhang",
        "Liming Wang",
        "Xiaoyan Xie",
        "Tao Fu",
        "Dongkun Wang",
        "Xiaoming Tao"
      ],
      "abstract": "With the continuous increase in the number and resolution of video\nsurveillance cameras, the burden of transmitting and storing surveillance video\nis growing. Traditional communication methods based on Shannon's theory are\nfacing optimization bottlenecks. Semantic communication, as an emerging\ncommunication method, is expected to break through this bottleneck and reduce\nthe storage and transmission consumption of video. Existing semantic decoding\nmethods often require many samples to train the neural network for each scene,\nwhich is time-consuming and labor-intensive. In this study, a semantic encoding\nand decoding method for surveillance video is proposed. First, the sketch was\nextracted as semantic information, and a sketch compression method was proposed\nto reduce the bit rate of semantic information. Then, an image translation\nnetwork was proposed to translate the sketch into a video frame with a\nreference frame. Finally, a few-shot sketch decoding network was proposed to\nreconstruct video from sketch. Experimental results showed that the proposed\nmethod achieved significantly better video reconstruction performance than\nbaseline methods. The sketch compression method could effectively reduce the\nstorage and transmission consumption of semantic information with little\ncompromise on video quality. The proposed method provides a novel semantic\nencoding and decoding method that only needs a few training samples for each\nsurveillance scene, thus improving the practicality of the semantic\ncommunication system.",
      "tldr_zh": "本文提出了一种Few-shot语义编码和解码方法，用于视频监控，以解决传统通信方法在传输和存储负担上的瓶颈。方法包括提取草图作为语义信息、提出草图压缩技术降低比特率、使用图像翻译网络将草图与参考帧转化为视频帧，以及开发少样本草图解码网络重建视频。实验结果显示，该方法比基线方法实现了显著更好的视频重建性能，同时有效减少语义信息的存储和传输消耗，且仅需少量训练样本。总之，该方法提升了语义通信系统的实用性，为高效视频监控提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07381v1",
      "published_date": "2025-05-12 09:27:28 UTC",
      "updated_date": "2025-05-12 09:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:09:51.436365"
    },
    {
      "arxiv_id": "2505.07902v1",
      "title": "Multimodal Assessment of Classroom Discourse Quality: A Text-Centered Attention-Based Multi-Task Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Ruikun Hou",
        "Babette Bühler",
        "Tim Fütterer",
        "Efe Bozkir",
        "Peter Gerjets",
        "Ulrich Trautwein",
        "Enkelejda Kasneci"
      ],
      "abstract": "Classroom discourse is an essential vehicle through which teaching and\nlearning take place. Assessing different characteristics of discursive\npractices and linking them to student learning achievement enhances the\nunderstanding of teaching quality. Traditional assessments rely on manual\ncoding of classroom observation protocols, which is time-consuming and costly.\nDespite many studies utilizing AI techniques to analyze classroom discourse at\nthe utterance level, investigations into the evaluation of discursive practices\nthroughout an entire lesson segment remain limited. To address this gap, our\nstudy proposes a novel text-centered multimodal fusion architecture to assess\nthe quality of three discourse components grounded in the Global Teaching\nInSights (GTI) observation protocol: Nature of Discourse, Questioning, and\nExplanations. First, we employ attention mechanisms to capture inter- and\nintra-modal interactions from transcript, audio, and video streams. Second, a\nmulti-task learning approach is adopted to jointly predict the quality scores\nof the three components. Third, we formulate the task as an ordinal\nclassification problem to account for rating level order. The effectiveness of\nthese designed elements is demonstrated through an ablation study on the GTI\nGermany dataset containing 92 videotaped math lessons. Our results highlight\nthe dominant role of text modality in approaching this task. Integrating\nacoustic features enhances the model's consistency with human ratings,\nachieving an overall Quadratic Weighted Kappa score of 0.384, comparable to\nhuman inter-rater reliability (0.326). Our study lays the groundwork for the\nfuture development of automated discourse quality assessment to support teacher\nprofessional development through timely feedback on multidimensional discourse\npractices.",
      "tldr_zh": "本研究针对课堂话语质量评估的挑战，提出了一种以文本为核心的注意力机制多模态融合架构，评估基于 Global Teaching InSights (GTI) 协议的三个组件：Nature of Discourse、Questioning 和 Explanations。该方法通过注意力机制捕捉转录、音频和视频流的互作，结合 Multi-Task Learning 和序数分类问题来联合预测质量分数。在 GTI Germany 数据集的92节数学课实验中，结果显示文本模态发挥主导作用，整合声学特征后模型与人类评分的 Quadratic Weighted Kappa 得分达0.384，优于人类间评定可靠性(0.326)。这项工作为自动课堂话语质量评估奠定基础，支持教师专业发展提供及时反馈。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "The 18th International Conference on Educational Data Mining (EDM\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.07902v1",
      "published_date": "2025-05-12 09:24:21 UTC",
      "updated_date": "2025-05-12 09:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:10:02.794062"
    },
    {
      "arxiv_id": "2505.07901v1",
      "title": "Latent Behavior Diffusion for Sequential Reaction Generation in Dyadic Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Minh-Duc Nguyen",
        "Hyung-Jeong Yang",
        "Soo-Hyung Kim",
        "Ji-Eun Shin",
        "Seung-Won Kim"
      ],
      "abstract": "The dyadic reaction generation task involves synthesizing responsive facial\nreactions that align closely with the behaviors of a conversational partner,\nenhancing the naturalness and effectiveness of human-like interaction\nsimulations. This paper introduces a novel approach, the Latent Behavior\nDiffusion Model, comprising a context-aware autoencoder and a diffusion-based\nconditional generator that addresses the challenge of generating diverse and\ncontextually relevant facial reactions from input speaker behaviors. The\nautoencoder compresses high-dimensional input features, capturing dynamic\npatterns in listener reactions while condensing complex input data into a\nconcise latent representation, facilitating more expressive and contextually\nappropriate reaction synthesis. The diffusion-based conditional generator\noperates on the latent space generated by the autoencoder to predict realistic\nfacial reactions in a non-autoregressive manner. This approach allows for\ngenerating diverse facial reactions that reflect subtle variations in\nconversational cues and emotional states. Experimental results demonstrate the\neffectiveness of our approach in achieving superior performance in dyadic\nreaction synthesis tasks compared to existing methods.",
      "tldr_zh": "本文提出 Latent Behavior Diffusion Model，用于 dyadic reaction generation 任务，通过合成与对话伙伴行为紧密相关的面部反应，提升人机交互的自然性和有效性。该模型包括一个 context-aware autoencoder 和一个 diffusion-based conditional generator，其中 autoencoder 压缩高维输入特征并捕捉动态模式，生成简洁的 latent representation，而 generator 在此基础上非自回归地预测多样化、上下文相关的面部反应。实验结果显示，该方法在 dyadic reaction synthesis 任务中比现有方法表现出色，实现了更真实的反应生成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07901v1",
      "published_date": "2025-05-12 09:22:27 UTC",
      "updated_date": "2025-05-12 09:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:10:14.336209"
    },
    {
      "arxiv_id": "2505.07377v1",
      "title": "Examining the Role of LLM-Driven Interactions on Attention and Cognitive Engagement in Virtual Classrooms",
      "title_zh": "考察LLM驱动互动对虚拟课堂中注意力和认知参与的作用",
      "authors": [
        "Suleyman Ozdel",
        "Can Sarpkaya",
        "Efe Bozkir",
        "Hong Gao",
        "Enkelejda Kasneci"
      ],
      "abstract": "Transforming educational technologies through the integration of large\nlanguage models (LLMs) and virtual reality (VR) offers the potential for\nimmersive and interactive learning experiences. However, the effects of LLMs on\nuser engagement and attention in educational environments remain open\nquestions. In this study, we utilized a fully LLM-driven virtual learning\nenvironment, where peers and teachers were LLM-driven, to examine how students\nbehaved in such settings. Specifically, we investigate how peer question-asking\nbehaviors influenced student engagement, attention, cognitive load, and\nlearning outcomes and found that, in conditions where LLM-driven peer learners\nasked questions, students exhibited more targeted visual scanpaths, with their\nattention directed toward the learning content, particularly in complex\nsubjects. Our results suggest that peer questions did not introduce extraneous\ncognitive load directly, as the cognitive load is strongly correlated with\nincreased attention to the learning material. Considering these findings, we\nprovide design recommendations for optimizing VR learning spaces.",
      "tldr_zh": "本研究探讨了大型语言模型（LLM）驱动的互动在虚拟课堂中对学生注意力和认知参与的影响，特别关注同行提问行为。研究者构建了一个完全由 LLM 驱动的虚拟学习环境，观察学生在这种设置下的行为，发现当 LLM 驱动的同行提问时，学生表现出更针对性的视觉扫描路径（visual scanpaths），从而提升了对复杂学习内容的注意力，且未增加无关的认知负荷（extraneous cognitive load）。这些发现表明，认知负荷与注意力正相关，并据此提供优化虚拟现实（VR）学习空间的设计建议，以提升教育效果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to EDM 2025 (Eighteenth International Conference on\n  Educational Data Mining)",
      "pdf_url": "http://arxiv.org/pdf/2505.07377v1",
      "published_date": "2025-05-12 09:21:19 UTC",
      "updated_date": "2025-05-12 09:21:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:10:26.960240"
    },
    {
      "arxiv_id": "2505.07374v1",
      "title": "AIS Data-Driven Maritime Monitoring Based on Transformer: A Comprehensive Review",
      "title_zh": "基于 Transformer 的 AIS 数据驱动海洋监测：全面综述",
      "authors": [
        "Zhiye Xie",
        "Enmei Tu",
        "Xianping Fu",
        "Guoliang Yuan",
        "Yi Han"
      ],
      "abstract": "With the increasing demands for safety, efficiency, and sustainability in\nglobal shipping, Automatic Identification System (AIS) data plays an\nincreasingly important role in maritime monitoring. AIS data contains\nspatial-temporal variation patterns of vessels that hold significant research\nvalue in the marine domain. However, due to its massive scale, the full\npotential of AIS data has long remained untapped. With its powerful sequence\nmodeling capabilities, particularly its ability to capture long-range\ndependencies and complex temporal dynamics, the Transformer model has emerged\nas an effective tool for processing AIS data. Therefore, this paper reviews the\nresearch on Transformer-based AIS data-driven maritime monitoring, providing a\ncomprehensive overview of the current applications of Transformer models in the\nmarine field. The focus is on Transformer-based trajectory prediction methods,\nbehavior detection, and prediction techniques. Additionally, this paper\ncollects and organizes publicly available AIS datasets from the reviewed\npapers, performing data filtering, cleaning, and statistical analysis. The\nstatistical results reveal the operational characteristics of different vessel\ntypes, providing data support for further research on maritime monitoring\ntasks. Finally, we offer valuable suggestions for future research, identifying\ntwo promising research directions. Datasets are available at\nhttps://github.com/eyesofworld/Maritime-Monitoring.",
      "tldr_zh": "这篇论文对基于 Transformer 模型的 AIS 数据驱动海事监控进行了全面综述，强调了 Transformer 在处理大规模 AIS 数据时的优势，如捕捉长程依赖和复杂时间动态。论文重点审视了 Transformer 在船舶轨迹预测、行为检测和预测方面的应用，并收集、过滤、清洗了公开 AIS 数据集，通过统计分析揭示了不同船只类型的操作特征。最终，论文提出了两个有前景的研究方向，并提供了数据集链接（https://github.com/eyesofworld/Maritime-Monitoring），为未来海事监控研究提供数据支持。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07374v1",
      "published_date": "2025-05-12 09:17:43 UTC",
      "updated_date": "2025-05-12 09:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:10:39.550909"
    },
    {
      "arxiv_id": "2505.07372v1",
      "title": "Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data",
      "title_zh": "合成代码手术：使用 LLMs 和合成数据修复错误和漏洞",
      "authors": [
        "David de-Fitero-Dominguez",
        "Antonio Garcia-Cabot",
        "Eva Garcia-Lopez"
      ],
      "abstract": "This paper presents a novel methodology for enhancing Automated Program\nRepair (APR) through synthetic data generation utilizing Large Language Models\n(LLMs). Current APR systems are constrained by the limited availability of\nhigh-quality training data encompassing diverse bug types across multiple\nprogramming languages. The proposed approach addresses this limitation through\na two-phase process: a synthetic sample generation followed by a rigorous\nquality assessment. Multiple state-of-the-art LLMs were employed to generate\napproximately 30,000 paired examples of buggy and fixed code across 12\nprogramming languages and 13 bug categories. Subsequently, these samples\nunderwent cross-model evaluation against five criteria: correctness, code\nquality, security, performance, and completeness. Experimental evaluation on\nthe VulRepair test set dataset showed statistically significant improvements in\nPerfect Prediction rates, with the quality-filtered synthetic dataset\noutperforming both baseline and real-world commit data configurations in\ncertain scenarios. The methodology was validated through rigorous statistical\ntesting, including ANOVA and post-hoc Tukey's Honest Significant Difference\nanalysis. Furthermore, the best-performing configurations surpassed existing\nsystems despite using a less computationally intensive decoding strategy. This\nresearch establishes a self-bootstrapping paradigm in which LLMs generate and\nevaluate their own training data, potentially transforming approaches to data\nscarcity across software engineering tasks and advancing the development of\nrobust, adaptable tools for automated code maintenance.",
      "tldr_zh": "本研究提出了一种名为 Synthetic Code Surgery 的新方法，利用 Large Language Models (LLMs) 生成合成数据来提升 Automated Program Repair (APR)，以解决高质量训练数据稀缺的问题。该方法采用两阶段过程：首先生成约 30,000 对 buggy 和 fixed code 示例，覆盖 12 种编程语言和 13 种 bug 类别；随后通过跨模型评估，确保样本在正确性、代码质量、安全性、性能和完整性等五项标准上符合要求。实验结果显示，在 VulRepair 测试集上，使用质量过滤后的合成数据集，Perfect Prediction 率取得了统计显著的改进，并在某些场景下优于基线和真实世界提交数据配置。总体而言，该方法通过 LLMs 的自引导范式（如 ANOVA 和 Tukey's Honest Significant Difference 分析验证），为软件工程任务提供了一种应对数据稀缺的鲁棒解决方案，推动自动化代码维护工具的发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07372v1",
      "published_date": "2025-05-12 09:14:20 UTC",
      "updated_date": "2025-05-12 09:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:10:51.724173"
    },
    {
      "arxiv_id": "2505.07365v1",
      "title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Chao-Han Huck Yang",
        "Sreyan Ghosh",
        "Qing Wang",
        "Jaeyeon Kim",
        "Hengyi Hong",
        "Sonal Kumar",
        "Guirui Zhong",
        "Zhifeng Kong",
        "S Sakshi",
        "Vaibhavi Lokegaonkar",
        "Oriol Nieto",
        "Ramani Duraiswami",
        "Dinesh Manocha",
        "Gunhee Kim",
        "Jun Du",
        "Rafael Valle",
        "Bryan Catanzaro"
      ],
      "abstract": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering\n(AQA) benchmark spanning multiple domains of sound understanding. This task\ndefines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA)\nto test audio-language models on interactive question-answering over diverse\nacoustic scenes. We describe the dataset composition (from marine mammal calls\nto soundscapes and complex real-world clips), the evaluation protocol (top-1\naccuracy with answer-shuffling robustness), and baseline systems\n(Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the\ndevelopment set are compared, showing strong variation across models and\nsubsets. This challenge aims to advance the audio understanding and reasoning\ncapabilities of audio-language models toward human-level acuity, which are\ncrucial for enabling AI agents to perceive and interact about the world\neffectively.",
      "tldr_zh": "DCASE 2025 Challenge 的 Task 5 提出一个多领域音频问答（AQA）基准，旨在测试音频语言模型在 Bioacoustics（生物声学）、Temporal Soundscapes（时间声景）和 Complex QA（复杂 QA）等子集上的声学内容推理能力。该基准使用多样化数据集，包括海洋哺乳动物叫声、声景和真实世界音频剪辑，并采用 top-1 accuracy 和 answer-shuffling robustness 作为评估协议，基线系统包括 Qwen2-Audio-7B、AudioFlamingo 2 和 Gemini-2-Flash。初步结果显示模型在不同子集的表现存在显著差异，该挑战的目标是提升音频语言模型的理解和推理能力，达到人类水平，从而支持 AI 代理更有效地感知和互动世界。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Preprint. DCASE 2025 Audio QA Challenge:\n  https://dcase.community/challenge2025/task-audio-question-answering",
      "pdf_url": "http://arxiv.org/pdf/2505.07365v1",
      "published_date": "2025-05-12 09:04:16 UTC",
      "updated_date": "2025-05-12 09:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:11:05.753942"
    },
    {
      "arxiv_id": "2505.07364v1",
      "title": "GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance of deep unsupervised anomaly detection models",
      "title_zh": "翻译失败",
      "authors": [
        "Daria Zotova",
        "Nicolas Pinon",
        "Robin Trombetta",
        "Romain Bouet",
        "Julien Jung",
        "Carole Lartizien"
      ],
      "abstract": "Background and Objective. Research in the cross-modal medical image\ntranslation domain has been very productive over the past few years in tackling\nthe scarce availability of large curated multimodality datasets with the\npromising performance of GAN-based architectures. However, only a few of these\nstudies assessed task-based related performance of these synthetic data,\nespecially for the training of deep models. Method. We design and compare\ndifferent GAN-based frameworks for generating synthetic brain\n[18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first\nperform standard qualitative and quantitative visual quality evaluation. Then,\nwe explore further impact of using these fake PET data in the training of a\ndeep unsupervised anomaly detection (UAD) model designed to detect subtle\nepilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic\ntask-oriented quality metrics of the synthetic FDG PET data tailored to our\nunsupervised detection task, then use these fake data to train a use case UAD\nmodel combining a deep representation learning based on siamese autoencoders\nwith a OC-SVM density support estimation model. This model is trained on normal\nsubjects only and allows the detection of any variation from the pattern of the\nnormal population. We compare the detection performance of models trained on 35\npaired real MR T1 of normal subjects paired either on 35 true PET images or on\n35 synthetic PET images generated from the best performing generative models.\nPerformance analysis is conducted on 17 exams of epilepsy patients undergoing\nsurgery. Results. The best performing GAN-based models allow generating\nrealistic fake PET images of control subject with SSIM and PSNR values around\n0.9 and 23.8, respectively and in distribution (ID) with regard to the true\ncontrol dataset. The best UAD model trained on these synthetic normative PET\ndata allows reaching 74% sensitivity. Conclusion. Our results confirm that\nGAN-based models are the best suited for MR T1 to FDG PET translation,\noutperforming transformer or diffusion models. We also demonstrate the\ndiagnostic value of these synthetic data for the training of UAD models and\nevaluation on clinical exams of epilepsy patients. Our code and the normative\nimage dataset are available.",
      "tldr_zh": "本文研究利用 GAN 框架从 T1 MRI 生成合成 FDG PET 脑部图像，以解决多模态医疗数据集稀缺问题，并评估这些合成图像在训练深度无监督异常检测 (UAD) 模型中的应用。研究设计了不同 GAN 模型进行图像生成，并引入任务导向质量指标，如 SSIM 和 PSNR，显示合成图像质量高（SSIM 约 0.9，PSNR 约 23.8），UAD 模型使用这些图像训练后，在检测癫痫病变时达到 74% 敏感度。结果表明，GAN 优于 transformer 或 diffusion 模型，为临床癫痫诊断提供可靠的合成数据支持，并公开了代码和数据集。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07364v1",
      "published_date": "2025-05-12 09:00:03 UTC",
      "updated_date": "2025-05-12 09:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:11:16.978001"
    },
    {
      "arxiv_id": "2505.07345v1",
      "title": "QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines",
      "title_zh": "翻译失败",
      "authors": [
        "Ohjoon Kwon",
        "Changsu Lee",
        "Jihye Back",
        "Lim Sun Suk",
        "Inho Kang",
        "Donghyeon Jeon"
      ],
      "abstract": "Large language models (LLMs) have been widely used for relevance assessment\nin information retrieval. However, our study demonstrates that combining two\ndistinct small language models (SLMs) with different architectures can\noutperform LLMs in this task. Our approach -- QUPID -- integrates a generative\nSLM with an embedding-based SLM, achieving higher relevance judgment accuracy\nwhile reducing computational costs compared to state-of-the-art LLM solutions.\nThis computational efficiency makes QUPID highly scalable for real-world search\nsystems processing millions of queries daily. In experiments across diverse\ndocument types, our method demonstrated consistent performance improvements\n(Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x\nfaster inference times. Furthermore, when integrated into production search\npipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how\narchitectural diversity in model combinations can significantly enhance both\nsearch relevance and operational efficiency in information retrieval systems.",
      "tldr_zh": "本研究提出QUPID框架，通过结合两个不同架构的小语言模型(SLMs)——一个生成式SLM和一个基于嵌入的SLM——来提升韩国搜索引擎的信息检索相关性评估性能。相比传统的大型语言模型(LLMs)，QUPID实现了更高的相关性判断准确率，同时降低了计算成本，并使系统更适合处理数百万日常查询。实验结果显示，在多种文档类型上，QUPID的Cohen's Kappa达到0.646，比领先LLMs的0.387显著提高，且推理时间快60倍；在实际生产环境中，nDCG@5得分提升1.9%。这些发现强调了模型架构多样性在增强搜索相关性和操作效率方面的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07345v1",
      "published_date": "2025-05-12 08:35:09 UTC",
      "updated_date": "2025-05-12 08:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:11:26.890221"
    },
    {
      "arxiv_id": "2505.07344v4",
      "title": "Generative Pre-trained Autoregressive Diffusion Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Zhang",
        "Jiacheng Jiang",
        "Guoqing Ma",
        "Zhiying Lu",
        "Haoyang Huang",
        "Jianlong Yuan",
        "Nan Duan"
      ],
      "abstract": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.",
      "tldr_zh": "本研究提出 GPDiT，一种生成式预训练自回归扩散 Transformer，将扩散模型和自回归建模的优势统一，用于长序列视频合成。GPDiT 在连续潜在空间中自回归预测未来潜在帧，使用扩散损失来增强运动动态和帧间语义一致性，同时引入轻量级因果注意力变体和无参数旋转-based 时间条件机制，以提升训练和推理效率。实验结果表明，GPDiT 在视频生成质量、视频表示能力和少样本学习任务上表现出色，展示了其作为连续空间视频建模框架的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07344v4",
      "published_date": "2025-05-12 08:32:39 UTC",
      "updated_date": "2025-05-22 06:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:11:39.389157"
    },
    {
      "arxiv_id": "2505.08814v1",
      "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test",
      "title_zh": "翻译失败",
      "authors": [
        "Wenkai Li",
        "Xiaoqi Li",
        "Yingjie Mao",
        "Yishun Wang"
      ],
      "abstract": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models.",
      "tldr_zh": "本研究旨在通过覆盖度测试（coverage test）探索深度神经网络（DNNs）在图像识别中的行为模式，特别分析模型深度、配置信息与四种覆盖度指标（primary functionality, boundary, hierarchy, and structural coverage）之间的关系。研究者进行了实证实验，使用LeNet、VGG和ResNet等不同架构的10个模型（深度从5到54层），并比较这些指标的表现，同时调查了修改后的决策/条件覆盖度与数据集大小的相关性。结果显示，这些实验揭示了模型深度和配置对神经网络覆盖度的影响模式，并提出了三个未来研究方向，以提升DNNs的安全测试。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08814v1",
      "published_date": "2025-05-12 08:25:55 UTC",
      "updated_date": "2025-05-12 08:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:11:50.851084"
    },
    {
      "arxiv_id": "2505.07339v1",
      "title": "Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory Decision-Making Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Lima",
        "Nina Grgić-Hlača",
        "Markus Langer",
        "Yixin Zou"
      ],
      "abstract": "Affirmative algorithms have emerged as a potential answer to algorithmic\ndiscrimination, seeking to redress past harms and rectify the source of\nhistorical injustices. We present the results of two experiments ($N$$=$$1193$)\ncapturing laypeople's perceptions of affirmative algorithms -- those which\nexplicitly prioritize the historically marginalized -- in hiring and criminal\njustice. We contrast these opinions about affirmative algorithms with folk\nattitudes towards algorithms that prioritize the privileged (i.e.,\ndiscriminatory) and systems that make decisions independently of demographic\ngroups (i.e., fair). We find that people -- regardless of their political\nleaning and identity -- view fair algorithms favorably and denounce\ndiscriminatory systems. In contrast, we identify disagreements concerning\naffirmative algorithms: liberals and racial minorities rate affirmative systems\nas positively as their fair counterparts, whereas conservatives and those from\nthe dominant racial group evaluate affirmative algorithms as negatively as\ndiscriminatory systems. We identify a source of these divisions: people have\nvarying beliefs about who (if anyone) is marginalized, shaping their views of\naffirmative algorithms. We discuss the possibility of bridging these\ndisagreements to bring people together towards affirmative algorithms.",
      "tldr_zh": "这篇论文通过两个实验（N=1193）调查了普通人对公平算法(fair algorithms)、肯定性算法(affirmative algorithms)和歧视性算法(discriminatory algorithms)在招聘和刑事司法领域的态度。结果显示，人们普遍支持fair algorithms并反对discriminatory algorithms，但对affirmative algorithms存在分歧：自由主义者和种族少数群体视其为积极的，而保守主义者和主导种族群体则将其视为负面。论文指出，这种分歧源于人们对边缘化群体的不同认知，并探讨了通过弥合这些分歧来促进对affirmative algorithms的共识的可能性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07339v1",
      "published_date": "2025-05-12 08:25:15 UTC",
      "updated_date": "2025-05-12 08:25:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:12:03.294879"
    },
    {
      "arxiv_id": "2505.07336v1",
      "title": "SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixuan Zhang",
        "Xiaopeng Li",
        "Qi Liu"
      ],
      "abstract": "Background subtraction (BGS) is utilized to detect moving objects in a video\nand is commonly employed at the onset of object tracking and human recognition\nprocesses. Nevertheless, existing BGS techniques utilizing deep learning still\nencounter challenges with various background noises in videos, including\nvariations in lighting, shifts in camera angles, and disturbances like air\nturbulence or swaying trees. To address this problem, we design a spiking\nautoencoder network, termed SAEN-BGS, based on noise resilience and\ntime-sequence sensitivity of spiking neural networks (SNNs) to enhance the\nseparation of foreground and background. To eliminate unnecessary background\nnoise and preserve the important foreground elements, we begin by creating the\ncontinuous spiking conv-and-dconv block, which serves as the fundamental\nbuilding block for the decoder in SAEN-BGS. Moreover, in striving for enhanced\nenergy efficiency, we introduce a novel self-distillation spiking supervised\nlearning method grounded in ANN-to-SNN frameworks, resulting in decreased power\nconsumption. In extensive experiments conducted on CDnet-2014 and DAVIS-2016\ndatasets, our approach demonstrates superior segmentation performance relative\nto other baseline methods, even when challenged by complex scenarios with\ndynamic backgrounds.",
      "tldr_zh": "本研究针对背景减法 (BGS) 在视频中检测移动物体时面临的挑战，如光照变化、相机角度偏移和背景噪声，提出了一种高效的脉冲自编码器网络 SAEN-BGS。SAEN-BGS 利用脉冲神经网络 (SNNs) 的噪声鲁棒性和时间序列敏感性，设计了连续脉冲 conv-and-dconv 块作为解码器基础块，以有效分离前景和背景并减少不必要噪声。同时，引入基于 ANN-to-SNN 框架的自蒸馏脉冲监督学习方法，提升了能量效率并降低了功耗。在 CDnet-2014 和 DAVIS-2016 数据集上的实验中，SAEN-BGS 在复杂动态背景场景下表现出优于基线方法的分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Pattern Recognition",
      "pdf_url": "http://arxiv.org/pdf/2505.07336v1",
      "published_date": "2025-05-12 08:21:47 UTC",
      "updated_date": "2025-05-12 08:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:12:15.786403"
    },
    {
      "arxiv_id": "2505.07320v1",
      "title": "Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Li",
        "Ling Luo",
        "Uwe Aickelin"
      ],
      "abstract": "Medical research, particularly in predicting patient outcomes, heavily relies\non medical time series data extracted from Electronic Health Records (EHR),\nwhich provide extensive information on patient histories. Despite rigorous\nexamination, labeling errors are inevitable and can significantly impede\naccurate predictions of patient outcome. To address this challenge, we propose\nan \\textbf{A}ttention-based Learning Framework with Dynamic\n\\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy\n\\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a\ntwo-component Beta mixture model to identify the certain and uncertain sets of\ninstances based on the fitness distribution of each class, and it captures\nglobal temporal dynamics while dynamically calibrating labels from the\nuncertain set or augmenting confident instances from the certain set.\nExperimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and\nseveral benchmark datasets from the UCR and UEA repositories, demonstrate that\nour model ACTLL has achieved state-of-the-art performance, especially under\nhigh noise levels.",
      "tldr_zh": "该研究针对电子健康记录 (EHR) 中的噪声标签问题，提出了一种基于注意力的学习框架 ACTLL，用于处理医疗时间序列数据中的标注错误。该框架采用两组件 Beta mixture model 来区分实例的确定集和不确定集，同时捕捉全局时间动态，并动态校准不确定集的标签或增强确定集的置信实例。在 eICU、MIMIC-IV-ED 等大型 EHR 数据集以及 UCR 和 UEA 基准数据集上的实验表明，ACTLL 在高噪声水平下实现了最先进性能，显著提升了患者结果预测的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07320v1",
      "published_date": "2025-05-12 08:06:16 UTC",
      "updated_date": "2025-05-12 08:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:12:28.061066"
    },
    {
      "arxiv_id": "2505.07317v1",
      "title": "How Do Companies Manage the Environmental Sustainability of AI? An Interview Study About Green AI Efforts and Regulations",
      "title_zh": "翻译失败",
      "authors": [
        "Ashmita Sampatsing",
        "Sophie Vos",
        "Emma Beauxis-Aussalet",
        "Justus Bogner"
      ],
      "abstract": "With the ever-growing adoption of artificial intelligence (AI), AI-based\nsoftware and its negative impact on the environment are no longer negligible,\nand studying and mitigating this impact has become a critical area of research.\nHowever, it is currently unclear which role environmental sustainability plays\nduring AI adoption in industry and how AI regulations influence Green AI\npractices and decision-making in industry. We therefore aim to investigate the\nGreen AI perception and management of industry practitioners. To this end, we\nconducted a total of 11 interviews with participants from 10 different\norganizations that adopted AI-based software. The interviews explored three\nmain themes: AI adoption, current efforts in mitigating the negative\nenvironmental impact of AI, and the influence of the EU AI Act and the\nCorporate Sustainability Reporting Directive (CSRD). Our findings indicate that\n9 of 11 participants prioritized business efficiency during AI adoption, with\nminimal consideration of environmental sustainability. Monitoring and\nmitigation of AI's environmental impact were very limited. Only one participant\nmonitored negative environmental effects. Regarding applied mitigation\npractices, six participants reported no actions, with the others sporadically\nmentioning techniques like prompt engineering, relying on smaller models, or\nnot overusing AI. Awareness and compliance with the EU AI Act are low, with\nonly one participant reporting on its influence, while the CSRD drove\nsustainability reporting efforts primarily in larger companies. All in all, our\nfindings reflect a lack of urgency and priority for sustainable AI among these\ncompanies. We suggest that current regulations are not very effective, which\nhas implications for policymakers. Additionally, there is a need to raise\nindustry awareness, but also to provide user-friendly techniques and tools for\nGreen AI practices.",
      "tldr_zh": "这篇论文通过对11位行业从业者的访谈，调查了公司在AI采用过程中如何管理环境可持续性，以及Green AI努力和法规（如EU AI Act和CSRD）的影响。研究发现，大多数参与者优先考虑业务效率，而对AI的环境负面影响监控和缓解措施非常有限，仅一人进行监测，且缓解实践如prompt engineering或使用较小模型仅 sporadically 应用。总体而言，行业对Green AI的紧迫感不足，现有法规效果不佳，论文建议政策制定者加强监管、提高意识，并提供用户友好的工具以促进可持续AI实践。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for publication at the 11th International Conference on ICT\n  for Sustainability (ICT4S'25), see https://conf.researchr.org/home/ict4s-2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07317v1",
      "published_date": "2025-05-12 08:03:55 UTC",
      "updated_date": "2025-05-12 08:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:12:41.640263"
    },
    {
      "arxiv_id": "2505.07315v1",
      "title": "FedIFL: A federated cross-domain diagnostic framework for motor-driven systems with inconsistent fault modes",
      "title_zh": "翻译失败",
      "authors": [
        "Zexiao Wang",
        "Yankai Wang",
        "Xiaoqiang Liao",
        "Xinguo Ming",
        "Weiming Shen"
      ],
      "abstract": "Due to the scarcity of industrial data, individual equipment users,\nparticularly start-ups, struggle to independently train a comprehensive fault\ndiagnosis model; federated learning enables collaborative training while\nensuring data privacy, making it an ideal solution. However, the diversity of\nworking conditions leads to variations in fault modes, resulting in\ninconsistent label spaces across different clients. In federated diagnostic\nscenarios, label space inconsistency leads to local models focus on\nclient-specific fault modes and causes local models from different clients to\nmap different failure modes to similar feature representations, which weakens\nthe aggregated global model's generalization. To tackle this issue, this\narticle proposed a federated cross-domain diagnostic framework termed Federated\nInvariant Features Learning (FedIFL). In intra-client training, prototype\ncontrastive learning mitigates intra-client domain shifts, subsequently,\nfeature generating ensures local models can access distributions of other\nclients in a privacy-friendly manner. Besides, in cross-client training, a\nfeature disentanglement mechanism is introduced to mitigate cross-client domain\nshifts, specifically, an instance-level federated instance consistency loss is\ndesigned to ensure the instance-level consistency of invariant features between\ndifferent clients, furthermore, a federated instance personalization loss and\nan orthogonal loss are constructed to distinguish specific features that from\nthe invariant features. Eventually, the aggregated model achieves promising\ngeneralization among global label spaces, enabling accurate fault diagnosis for\ntarget clients' Motor Driven Systems (MDSs) with inconsistent label spaces.\nExperiments on real-world MDSs validate the effectiveness and superiority of\nFedIFL in federated cross-domain diagnosis with inconsistent fault modes.",
      "tldr_zh": "这篇论文提出 FedIFL 框架，一种联邦学习方法，用于处理电机驱动系统（MDSs）在不同客户端标签空间不一致的故障诊断问题，通过原型对比学习和特征生成缓解内部领域偏移，并在跨客户端训练中引入特征解耦机制（如实例级一致性损失、个性化损失和正交损失）来提升模型的泛化能力。FedIFL 确保了隐私友好下的全局模型聚合，使其能够准确诊断不一致故障模式。实验在真实世界 MDSs 上验证了该框架的有效性和优越性，显著提高了诊断准确率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07315v1",
      "published_date": "2025-05-12 08:00:49 UTC",
      "updated_date": "2025-05-12 08:00:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:12:53.099168"
    },
    {
      "arxiv_id": "2505.07313v2",
      "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study",
      "title_zh": "翻译失败",
      "authors": [
        "Baixuan Xu",
        "Chunyang Li",
        "Weiqi Wang",
        "Wei Fan",
        "Tianshi Zheng",
        "Haochen Shi",
        "Tao Fan",
        "Yangqiu Song",
        "Qiang Yang"
      ],
      "abstract": "Designing effective collaboration structure for multi-agent LLM systems to\nenhance collective reasoning is crucial yet remains under-explored. In this\npaper, we systematically investigate how collaborative reasoning performance is\naffected by three key design dimensions: (1) Expertise-Domain Alignment, (2)\nCollaboration Paradigm (structured workflow vs. diversity-driven integration),\nand (3) System Scale. Our findings reveal that expertise alignment benefits are\nhighly domain-contingent, proving most effective for contextual reasoning\ntasks. Furthermore, collaboration focused on integrating diverse knowledge\nconsistently outperforms rigid task decomposition. Finally, we empirically\nexplore the impact of scaling the multi-agent system with expertise\nspecialization and study the computational trade off, highlighting the need for\nmore efficient communication protocol design. This work provides concrete\nguidelines for configuring specialized multi-agent system and identifies\ncritical architectural trade-offs and bottlenecks for scalable multi-agent\nreasoning. The code will be made available upon acceptance.",
      "tldr_zh": "本研究探讨了多智能体LLM系统中的协作结构如何提升集体推理性能，通过一个探索性设计研究系统调查了三个关键维度：Expertise-Domain Alignment、Collaboration Paradigm（结构化工作流 vs. 多样性驱动整合）和System Scale。结果表明，专业知识对齐的益处高度依赖于任务类型，在上下文推理任务中最为有效，而强调多样知识整合的协作方式优于刚性任务分解。该研究还分析了系统规模扩展的影响，包括计算权衡，并为配置专业化多智能体系统提供了具体指导，同时指出了可扩展架构中的关键权衡和瓶颈。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.07313v2",
      "published_date": "2025-05-12 07:59:13 UTC",
      "updated_date": "2025-05-16 09:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:13:05.560825"
    },
    {
      "arxiv_id": "2505.07299v1",
      "title": "Interpretable Event Diagnosis in Water Distribution Networks",
      "title_zh": "水分配网络中可解释的事件诊断",
      "authors": [
        "André Artelt",
        "Stelios G. Vrachimis",
        "Demetrios G. Eliades",
        "Ulrike Kuhl",
        "Barbara Hammer",
        "Marios M. Polycarpou"
      ],
      "abstract": "The increasing penetration of information and communication technologies in\nthe design, monitoring, and control of water systems enables the use of\nalgorithms for detecting and identifying unanticipated events (such as leakages\nor water contamination) using sensor measurements. However, data-driven\nmethodologies do not always give accurate results and are often not trusted by\noperators, who may prefer to use their engineering judgment and experience to\ndeal with such events.\n  In this work, we propose a framework for interpretable event diagnosis -- an\napproach that assists the operators in associating the results of algorithmic\nevent diagnosis methodologies with their own intuition and experience. This is\nachieved by providing contrasting (i.e., counterfactual) explanations of the\nresults provided by fault diagnosis algorithms; their aim is to improve the\nunderstanding of the algorithm's inner workings by the operators, thus enabling\nthem to take a more informed decision by combining the results with their\npersonal experiences. Specifically, we propose counterfactual event\nfingerprints, a representation of the difference between the current event\ndiagnosis and the closest alternative explanation, which can be presented in a\ngraphical way. The proposed methodology is applied and evaluated on a realistic\nuse case using the L-Town benchmark.",
      "tldr_zh": "该研究针对水分配网络中事件诊断（如泄漏或污染）的挑战，提出一个可解释事件诊断（Interpretable Event Diagnosis）框架，以帮助操作员将算法结果与他们的工程判断和经验相结合。框架通过提供对比性解释（Counterfactual Explanations），即展示当前诊断与最近替代解释的差异，采用图形化的Counterfactual Event Fingerprints来提升操作员对算法内部机制的理解，从而支持更 informed 的决策。该方法在L-Town Benchmark的现实用例中进行了评估，展示了其在提高事件检测准确性和可信度方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07299v1",
      "published_date": "2025-05-12 07:36:00 UTC",
      "updated_date": "2025-05-12 07:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:13:16.066596"
    },
    {
      "arxiv_id": "2505.07294v1",
      "title": "HuB: Learning Extreme Humanoid Balance",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Zhang",
        "Boyuan Zheng",
        "Ruiqian Nai",
        "Yingdong Hu",
        "Yen-Jen Wang",
        "Geng Chen",
        "Fanqi Lin",
        "Jiongye Li",
        "Chuye Hong",
        "Koushil Sreenath",
        "Yang Gao"
      ],
      "abstract": "The human body demonstrates exceptional motor capabilities-such as standing\nsteadily on one foot or performing a high kick with the leg raised over 1.5\nmeters-both requiring precise balance control. While recent research on\nhumanoid control has leveraged reinforcement learning to track human motions\nfor skill acquisition, applying this paradigm to balance-intensive tasks\nremains challenging. In this work, we identify three key obstacles: instability\nfrom reference motion errors, learning difficulties due to morphological\nmismatch, and the sim-to-real gap caused by sensor noise and unmodeled\ndynamics. To address these challenges, we propose HuB (Humanoid Balance), a\nunified framework that integrates reference motion refinement, balance-aware\npolicy learning, and sim-to-real robustness training, with each component\ntargeting a specific challenge. We validate our approach on the Unitree G1\nhumanoid robot across challenging quasi-static balance tasks, including extreme\nsingle-legged poses such as Swallow Balance and Bruce Lee's Kick. Our policy\nremains stable even under strong physical disturbances-such as a forceful\nsoccer strike-while baseline methods consistently fail to complete these tasks.\nProject website: https://hub-robot.github.io",
      "tldr_zh": "该论文提出 HuB 框架，用于学习极端人形机器人的平衡控制，针对强化学习在平衡密集任务中的挑战，包括参考动作错误、形态不匹配以及模拟到现实的差距问题。HuB 通过整合参考动作精炼、平衡感知策略学习和模拟到现实的鲁棒性训练，构建一个统一的方法来提升机器人稳定性。在 Unitree G1 机器人上实验验证显示，该框架在极端单腿姿势任务（如 Swallow Balance 和 Bruce Lee's Kick）中表现出色，即使面对强物理干扰（如足球猛击）也能保持稳定，而基线方法则失败。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://hub-robot.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.07294v1",
      "published_date": "2025-05-12 07:31:42 UTC",
      "updated_date": "2025-05-12 07:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:13:28.550955"
    },
    {
      "arxiv_id": "2505.07289v1",
      "title": "Semantic Retention and Extreme Compression in LLMs: Can We Have Both?",
      "title_zh": "翻译失败",
      "authors": [
        "Stanislas Laborde",
        "Martin Cousseau",
        "Antoun Yaacoub",
        "Lionel Prevost"
      ],
      "abstract": "The exponential growth in Large Language Model (LLM) deployment has\nintensified the need for efficient model compression techniques to reduce\ncomputational and memory costs. While pruning and quantization have shown\npromise, their combined potential remains largely unexplored. In this paper, we\nexamine joint compression and how strategically combining pruning and\nquantization could yield superior performance-to-compression ratios compared to\nsingle-method approaches. Recognizing the challenges in accurately assessing\nLLM performance, we address key limitations of previous evaluation frameworks\nand introduce the Semantic Retention Compression Rate (SrCr), a novel metric\nthat quantifies the trade-off between model compression and semantic\npreservation, facilitating the optimization of pruning-quantization\nconfigurations. Experiments demonstrate that our recommended combination\nachieves, on average, a 20% performance increase compared to an equivalent\nquantization-only model at the same theoretical compression rate.",
      "tldr_zh": "本论文探讨了大型语言模型(LLMs)中实现语义保留与极端压缩的平衡可能性，强调了修剪(pruning)和量化(quantization)的联合应用，以获得更高的性能压缩比。作者引入了新的指标Semantic Retention Compression Rate (SrCr)，用于量化模型压缩与语义保留的权衡，从而优化修剪和量化配置。实验结果表明，这种联合方法在相同理论压缩率下，比仅使用量化的模型平均提高了20%的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68P30 (Primary) 68T07, 68T50 (Secondary)",
        "I.2.6; I.5.1; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in the Proceedings of the 2025 International\n  Joint Conference on Neural Networks (IJCNN); this arXiv version includes an\n  appendix with 6 result tables; 10 pages, 15 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07289v1",
      "published_date": "2025-05-12 07:23:19 UTC",
      "updated_date": "2025-05-12 07:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:13:39.756472"
    },
    {
      "arxiv_id": "2505.07286v1",
      "title": "Piloting Structure-Based Drug Design via Modality-Specific Optimal Schedule",
      "title_zh": "翻译失败",
      "authors": [
        "Keyue Qiu",
        "Yuxuan Song",
        "Zhehuan Fan",
        "Peidong Liu",
        "Zhe Zhang",
        "Mingyue Zheng",
        "Hao Zhou",
        "Wei-Ying Ma"
      ],
      "abstract": "Structure-Based Drug Design (SBDD) is crucial for identifying bioactive\nmolecules. Recent deep generative models are faced with challenges in geometric\nstructure modeling. A major bottleneck lies in the twisted probability path of\nmulti-modalities -- continuous 3D positions and discrete 2D topologies -- which\njointly determine molecular geometries. By establishing the fact that noise\nschedules decide the Variational Lower Bound (VLB) for the twisted probability\npath, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored\narea, which optimizes VLB as a path integral for SBDD. Our model effectively\nenhances molecular geometries and interaction modeling, achieving\nstate-of-the-art PoseBusters passing rate of 95.9% on CrossDock, more than 10%\nimprovement upon strong baselines, while maintaining high affinities and robust\nintramolecular validity evaluated on held-out test set.",
      "tldr_zh": "这篇论文针对 Structure-Based Drug Design (SBDD) 的几何结构建模挑战，提出了一种基于模态特定最优调度的 VLB-Optimal Scheduling (VOS) 策略，以优化多模态扭曲概率路径（包括连续的 3D 位置和离散的 2D 拓扑）。VOS 通过将 Variational Lower Bound (VLB) 作为路径积分来最大化模型性能，从而提升分子几何和交互建模。实验结果显示，该方法在 CrossDock 数据集上实现了 95.9% 的 PoseBusters 通过率，比强基线模型提高了 10%，并保持了高亲和力和分子内部有效性。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07286v1",
      "published_date": "2025-05-12 07:18:09 UTC",
      "updated_date": "2025-05-12 07:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:13:52.764999"
    },
    {
      "arxiv_id": "2505.07899v1",
      "title": "DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise",
      "title_zh": "DeltaEdit：通过控制叠加噪声增强大语言模型",
      "authors": [
        "Ding Cao",
        "Yuchen Cai",
        "Rongxi Guo",
        "Xuesong He",
        "Guiquan Liu"
      ],
      "abstract": "Sequential knowledge editing techniques aim to continuously update the\nknowledge in large language models at a low cost, preventing the models from\ngenerating outdated or incorrect information. However, existing sequential\nediting methods suffer from a significant decline in editing success rates\nafter long-term editing. Through theoretical analysis and experiments, we\nidentify that as the number of edits increases, the model's output increasingly\ndeviates from the desired target, leading to a drop in editing success rates.\nWe refer to this issue as the accumulation of superimposed noise problem. To\naddress this, we identify the factors contributing to this deviation and\npropose DeltaEdit, a novel method that optimizes update parameters through a\ndynamic orthogonal constraints strategy, effectively reducing interference\nbetween edits to mitigate deviation. Experimental results demonstrate that\nDeltaEdit significantly outperforms existing methods in edit success rates and\nthe retention of generalization capabilities, ensuring stable and reliable\nmodel performance even under extensive sequential editing.",
      "tldr_zh": "现有顺序编辑(Sequential Editing)技术旨在低成本地持续更新大型语言模型(Large Language Models)的知识，但长期编辑后会因叠加噪声(Superimposed Noise)积累导致编辑成功率显著下降。论文通过理论分析和实验识别了这一问题，并提出DeltaEdit方法，使用动态正交约束策略(dynamic orthogonal constraints strategy)优化更新参数，减少编辑间的干扰。实验结果显示，DeltaEdit在编辑成功率和泛化能力保留上显著优于现有方法，即使进行大量顺序编辑也能保持模型的稳定性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07899v1",
      "published_date": "2025-05-12 07:11:26 UTC",
      "updated_date": "2025-05-12 07:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:14:04.965441"
    },
    {
      "arxiv_id": "2505.07280v1",
      "title": "Predicting Music Track Popularity by Convolutional Neural Networks on Spotify Features and Spectrogram of Audio Waveform",
      "title_zh": "翻译失败",
      "authors": [
        "Navid Falah",
        "Behnam Yousefimehr",
        "Mehdi Ghatee"
      ],
      "abstract": "In the digital streaming landscape, it's becoming increasingly challenging\nfor artists and industry experts to predict the success of music tracks. This\nstudy introduces a pioneering methodology that uses Convolutional Neural\nNetworks (CNNs) and Spotify data analysis to forecast the popularity of music\ntracks. Our approach takes advantage of Spotify's wide range of features,\nincluding acoustic attributes based on the spectrogram of audio waveform,\nmetadata, and user engagement metrics, to capture the complex patterns and\nrelationships that influence a track's popularity. Using a large dataset\ncovering various genres and demographics, our CNN-based model shows impressive\neffectiveness in predicting the popularity of music tracks. Additionally, we've\nconducted extensive experiments to assess the strength and adaptability of our\nmodel across different musical styles and time periods, with promising results\nyielding a 97\\% F1 score. Our study not only offers valuable insights into the\ndynamic landscape of digital music consumption but also provides the music\nindustry with advanced predictive tools for assessing and predicting the\nsuccess of music tracks.",
      "tldr_zh": "本研究使用 Convolutional Neural Networks (CNNs) 结合 Spotify 特征（如音频波形的 Spectrogram、元数据和用户互动指标）来预测音乐曲目的流行度。研究基于大型数据集，覆盖多种音乐流派和人口统计，通过广泛实验验证了模型的适应性和有效性，取得了 97% 的 F1 score。总体而言，该方法不仅揭示了数字音乐消费的复杂模式，还为音乐行业提供了先进的预测工具，以评估和提升曲目成功潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "68T05, 68T10, 68T37",
        "I.2.6; I.2.1"
      ],
      "primary_category": "cs.SD",
      "comment": "12 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07280v1",
      "published_date": "2025-05-12 07:03:17 UTC",
      "updated_date": "2025-05-12 07:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:14:16.036975"
    },
    {
      "arxiv_id": "2505.08810v1",
      "title": "Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Bappa Muktar",
        "Vincent Fono",
        "Adama Nouboukpo"
      ],
      "abstract": "Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent\nTransportation Systems (ITS), particularly in enabling real-time communication\nfor emergency vehicles. However, Distributed Denial of Service (DDoS) attacks,\nwhich interfere with safety-critical communication channels, can severely\nimpair their reliability. This study introduces a robust and scalable framework\nto detect DDoS attacks in highway-based VANET environments. A synthetic dataset\nwas constructed using Network Simulator 3 (NS-3) in conjunction with the\nSimulation of Urban Mobility (SUMO) and further enriched with real-world\nmobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM).\nThree traffic categories were simulated: DDoS, VoIP, and TCP-based video\nstreaming (VideoTCP). The data preprocessing pipeline included normalization,\nsignal-to-noise ratio (SNR) feature engineering, missing value imputation, and\nclass balancing using the Synthetic Minority Over-sampling Technique (SMOTE).\nFeature importance was assessed using SHapley Additive exPlanations (SHAP).\nEleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB),\nAdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN).\nXGB and CB achieved the best performance, each attaining an F1-score of 96%.\nThese results highlight the robustness of the proposed framework and its\npotential for real-time deployment in VANETs to secure critical emergency\ncommunications.",
      "tldr_zh": "该研究针对VANETs（Vehicular Ad Hoc Networks）中DDoS（Distributed Denial of Service）攻击对紧急车辆通信的干扰，提出了一种鲁棒且可扩展的检测框架。研究者使用NS-3和SUMO模拟器构建合成数据集，并结合德国A81公路的真实移动轨迹，模拟DDoS、VoIP和VideoTCP三种流量；数据预处理包括归一化、SNR特征工程、缺失值填充以及SMOTE类平衡，并通过SHAP评估特征重要性。基准测试了11个分类器，如XGBoost（XGB）和CatBoost（CB），结果显示XGB和CB均达到96%的F1-score，证明该框架适用于实时部署以保护关键紧急通信。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08810v1",
      "published_date": "2025-05-12 07:00:04 UTC",
      "updated_date": "2025-05-12 07:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:14:29.035530"
    },
    {
      "arxiv_id": "2505.07271v1",
      "title": "On the Robustness of Reward Models for Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Jiwoo Hong",
        "Noah Lee",
        "Eunki Kim",
        "Guijin Son",
        "Woojin Chung",
        "Aman Gupta",
        "Shao Tang",
        "James Thorne"
      ],
      "abstract": "The Bradley-Terry (BT) model is widely practiced in reward modeling for\nreinforcement learning with human feedback (RLHF). Despite its effectiveness,\nreward models (RMs) trained with BT model loss are prone to over-optimization,\nlosing generalizability to unseen input distributions. In this paper, we study\nthe cause of over-optimization in RM training and its downstream effects on the\nRLHF procedure, accentuating the importance of distributional robustness of RMs\nin unseen data. First, we show that the excessive dispersion of hidden state\nnorms is the main source of over-optimization. Then, we propose batch-wise\nsum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch,\nconstraining the rewards with extreme magnitudes. We assess the impact of BSR\nin improving robustness in RMs through four scenarios of over-optimization,\nwhere BSR consistently manifests better robustness. Subsequently, we compare\nthe plain BT model and BSR on RLHF training and empirically show that robust\nRMs better align the policy to the gold preference model. Finally, we apply BSR\nto high-quality data and models, which surpasses state-of-the-art RMs in the 8B\nscale by adding more than 5% in complex preference prediction tasks. By\nconducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length\nby 40% while adding a 7% increase in win rate, further highlighting that\nrobustness in RMs induces robustness in RLHF training. We release the code,\ndata, and models: https://github.com/LinkedIn-XFACT/RM-Robustness.",
      "tldr_zh": "该论文探讨了 Bradley-Terry (BT) 模型在强化学习与人类反馈 (RLHF) 中的奖励模型 (RMs) 训练问题，指出其易于过优化，导致在未见数据上泛化性差，主要源于隐藏状态范数的过度分散。作者提出 batch-wise sum-to-zero regularization (BSR) 方法，通过约束每批奖励和为零来限制极端奖励值，并在四个过优化场景中验证了 BSR 显著提升 RMs 的鲁棒性。实验结果显示，使用 BSR 的 RMs 在 RLHF 训练中更好地对齐策略，并在 8B 规模模型上提高了超过 5% 的复杂偏好预测性能，同时通过 RLOO 训练使 AlpacaEval 2.0 的生成长度减少 40% 并增加 7% 的获胜率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07271v1",
      "published_date": "2025-05-12 06:48:26 UTC",
      "updated_date": "2025-05-12 06:48:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:14:42.669144"
    },
    {
      "arxiv_id": "2505.08809v1",
      "title": "MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges",
      "title_zh": "翻译失败",
      "authors": [
        "Shixi Qin",
        "Zhiyong Yang",
        "Shilong Bao",
        "Shi Wang",
        "Qianqian Xu",
        "Qingming Huang"
      ],
      "abstract": "This paper focuses on implanting multiple heterogeneous backdoor triggers in\nbridge-based diffusion models designed for complex and arbitrary input\ndistributions. Existing backdoor formulations mainly address single-attack\nscenarios and are limited to Gaussian noise input models. To fill this gap, we\npropose MixBridge, a novel diffusion Schr\\\"odinger bridge (DSB) framework to\ncater to arbitrary input distributions (taking I2I tasks as special cases).\nBeyond this trait, we demonstrate that backdoor triggers can be injected into\nMixBridge by directly training with poisoned image pairs. This eliminates the\nneed for the cumbersome modifications to stochastic differential equations\nrequired in previous studies, providing a flexible tool to study backdoor\nbehavior for bridge models. However, a key question arises: can a single DSB\nmodel train multiple backdoor triggers? Unfortunately, our theory shows that\nwhen attempting this, the model ends up following the geometric mean of benign\nand backdoored distributions, leading to performance conflict across backdoor\ntasks. To overcome this, we propose a Divide-and-Merge strategy to mix\ndifferent bridges, where models are independently pre-trained for each specific\nobjective (Divide) and then integrated into a unified model (Merge). In\naddition, a Weight Reallocation Scheme (WRS) is also designed to enhance the\nstealthiness of MixBridge. Empirical studies across diverse generation tasks\nspeak to the efficacy of MixBridge.",
      "tldr_zh": "本论文提出 MixBridge，一种新型的扩散 Schrödinger Bridge (DSB) 框架，用于在桥接模型中植入多个异构后门触发器，以应对复杂任意输入分布的图像到图像 (I2I) 任务，克服了现有方法仅限于单一攻击和高斯噪声输入的局限性。MixBridge 通过直接使用中毒图像对进行训练来注入后门触发器，避免了以往对随机微分方程的繁琐修改；然而，理论分析显示，单一 DSB 模型在处理多个触发器时会因跟随良性和后门分布的几何均值而导致性能冲突。针对此问题，论文引入 Divide-and-Merge 策略（独立预训练每个目标模型后整合）和 Weight Reallocation Scheme (WRS) 来提升模型的隐蔽性和兼容性。实证研究在多种生成任务中验证了 MixBridge 的有效性，展示了其作为后门攻击研究的灵活工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08809v1",
      "published_date": "2025-05-12 06:40:23 UTC",
      "updated_date": "2025-05-12 06:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:14:54.043500"
    },
    {
      "arxiv_id": "2505.07261v2",
      "title": "CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ce Hao",
        "Anxing Xiao",
        "Zhiwei Xue",
        "Harold Soh"
      ],
      "abstract": "Diffusion-based planners have shown strong performance in short-horizon tasks\nbut often fail in complex, long-horizon settings. We trace the failure to loose\ncoupling between high-level (HL) sub-goal selection and low-level (LL)\ntrajectory generation, which leads to incoherent plans and degraded\nperformance. We propose Coupled Hierarchical Diffusion (CHD), a framework that\nmodels HL sub-goals and LL trajectories jointly within a unified diffusion\nprocess. A shared classifier passes LL feedback upstream so that sub-goals\nself-correct while sampling proceeds. This tight HL-LL coupling improves\ntrajectory coherence and enables scalable long-horizon diffusion planning.\nExperiments across maze navigation, tabletop manipulation, and household\nenvironments show that CHD consistently outperforms both flat and hierarchical\ndiffusion baselines. Our website is: https://sites.google.com/view/chd2025/home",
      "tldr_zh": "该研究发现，Diffusion-based planners在短时任务中表现良好，但由于高层（HL）子目标选择和低层（LL）轨迹生成之间的松散耦合，导致长时任务中计划不连贯。为此，提出Coupled Hierarchical Diffusion (CHD)框架，通过在统一扩散过程中联合建模HL子目标和LL轨迹，并利用共享分类器将LL反馈传递回HL，实现子目标的自我修正，从而提升轨迹连贯性和长时规划的可扩展性。实验结果显示，在迷宫导航、桌面操作和家庭环境中，CHD 比平坦和分层扩散基线模型表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07261v2",
      "published_date": "2025-05-12 06:21:48 UTC",
      "updated_date": "2025-05-13 09:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:15:05.077015"
    },
    {
      "arxiv_id": "2505.07260v1",
      "title": "UMoE: Unifying Attention and FFN with Shared Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhang Yang",
        "Chaozheng Wang",
        "Jing Li"
      ],
      "abstract": "Sparse Mixture of Experts (MoE) architectures have emerged as a promising\napproach for scaling Transformer models. While initial works primarily\nincorporated MoE into feed-forward network (FFN) layers, recent studies have\nexplored extending the MoE paradigm to attention layers to enhance model\nperformance. However, existing attention-based MoE layers require specialized\nimplementations and demonstrate suboptimal performance compared to their\nFFN-based counterparts. In this paper, we aim to unify the MoE designs in\nattention and FFN layers by introducing a novel reformulation of the attention\nmechanism, revealing an underlying FFN-like structure within attention modules.\nOur proposed architecture, UMoE, achieves superior performance through\nattention-based MoE layers while enabling efficient parameter sharing between\nFFN and attention components.",
      "tldr_zh": "该研究针对 Sparse Mixture of Experts (MoE) 在 Transformer 模型中的应用，指出现有 attention-based MoE 层需要特殊实现且性能不如 FFN-based MoE。论文提出 UMoE 架构，通过重新表述 attention 机制，揭示其内在的 FFN-like 结构，从而统一 attention 和 FFN 层的 MoE 设计，并实现参数共享。实验结果显示，UMoE 通过 attention-based MoE 层显著提升了模型性能，提供了一种更高效的参数扩展方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07260v1",
      "published_date": "2025-05-12 06:21:44 UTC",
      "updated_date": "2025-05-12 06:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:15:15.824530"
    },
    {
      "arxiv_id": "2505.07258v1",
      "title": "No Query, No Access",
      "title_zh": "无查询、无访问",
      "authors": [
        "Wenqiang Wang",
        "Siyuan Liang",
        "Yangshijie Zhang",
        "Xiaojun Jia",
        "Hao Lin",
        "Xiaochun Cao"
      ],
      "abstract": "Textual adversarial attacks mislead NLP models, including Large Language\nModels (LLMs), by subtly modifying text. While effective, existing attacks\noften require knowledge of the victim model, extensive queries, or access to\ntraining data, limiting real-world feasibility. To overcome these constraints,\nwe introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which\noperates using only victim texts. To prevent access to the victim model, we\ncreate a shadow dataset with publicly available pre-trained models and\nclustering methods as a foundation for developing substitute models. To address\nthe low attack success rate (ASR) due to insufficient information feedback, we\npropose the hierarchical substitution model design, generating substitute\nmodels to mitigate the failure of a single substitute model at the decision\nboundary.\n  Concurrently, we use diverse adversarial example generation, employing\nvarious attack methods to generate and select the adversarial example with\nbetter similarity and attack effectiveness. Experiments on the Emotion and SST5\ndatasets show that VDBA outperforms state-of-the-art methods, achieving an ASR\nimprovement of 52.08\\% while significantly reducing attack queries to 0. More\nimportantly, we discover that VDBA poses a significant threat to LLMs such as\nQwen2 and the GPT family, and achieves the highest ASR of 45.99% even without\naccess to the API, confirming that advanced NLP models still face serious\nsecurity risks. Our codes can be found at\nhttps://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/",
      "tldr_zh": "本研究提出了一种Victim Data-based Adversarial Attack (VDBA)，一种无需访问受害者模型或进行查询的文本对抗攻击方法，仅依赖受害者文本来误导NLP模型，包括Large Language Models (LLMs)。VDBA通过创建shadow dataset和hierarchical substitution model设计来生成替代模型，并采用diverse adversarial example generation多种攻击策略，以提高attack success rate (ASR)并优化对抗样本的相似性和有效性。在Emotion和SST5数据集上的实验显示，VDBA比现有方法提升ASR达52.08%，并对Qwen2和GPT系列LLMs构成重大威胁，即使无API访问也能达到45.99%的ASR，凸显了高级NLP模型的安全风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07258v1",
      "published_date": "2025-05-12 06:19:59 UTC",
      "updated_date": "2025-05-12 06:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:15:29.464103"
    },
    {
      "arxiv_id": "2505.07251v1",
      "title": "Incomplete In-context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqiang Wang",
        "Yangshijie Zhang"
      ],
      "abstract": "Large vision language models (LVLMs) achieve remarkable performance through\nVision In-context Learning (VICL), a process that depends significantly on\ndemonstrations retrieved from an extensive collection of annotated examples\n(retrieval database). Existing studies often assume that the retrieval database\ncontains annotated examples for all labels. However, in real-world scenarios,\ndelays in database updates or incomplete data annotation may result in the\nretrieval database containing labeled samples for only a subset of classes. We\nrefer to this phenomenon as an \\textbf{incomplete retrieval database} and\ndefine the in-context learning under this condition as \\textbf{Incomplete\nIn-context Learning (IICL)}. To address this challenge, we propose\n\\textbf{Iterative Judgments and Integrated Prediction (IJIP)}, a two-stage\nframework designed to mitigate the limitations of IICL. The Iterative Judgments\nStage reformulates an \\(\\boldsymbol{m}\\)-class classification problem into a\nseries of \\(\\boldsymbol{m}\\) binary classification tasks, effectively\nconverting the IICL setting into a standard VICL scenario. The Integrated\nPrediction Stage further refines the classification process by leveraging both\nthe input image and the predictions from the Iterative Judgments Stage to\nenhance overall classification accuracy. IJIP demonstrates considerable\nperformance across two LVLMs and two datasets under three distinct conditions\nof label incompleteness, achieving the highest accuracy of 93.9\\%. Notably,\neven in scenarios where labels are fully available, IJIP still achieves the\nbest performance of all six baselines. Furthermore, IJIP can be directly\napplied to \\textbf{Prompt Learning} and is adaptable to the \\textbf{text\ndomain}.",
      "tldr_zh": "该研究探讨了大型视觉语言模型(LVLMs)在不完整检索数据库下的Incomplete In-context Learning (IICL)问题，即当数据库缺少某些标签时，Vision In-context Learning (VICL)的性能受限。论文提出Iterative Judgments and Integrated Prediction (IJIP)框架，包括两个阶段：第一阶段将多类分类问题转化为一系列二元分类任务，以模拟标准VICL；第二阶段结合输入图像和初步预测来优化最终分类准确性。实验结果显示，IJIP在两个LVLMs和两个数据集上，在标签不完整条件下最高准确率达93.9%，并优于所有基线，甚至适用于完整标签场景、Prompt Learning和文本领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07251v1",
      "published_date": "2025-05-12 05:57:39 UTC",
      "updated_date": "2025-05-12 05:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:15:39.290327"
    },
    {
      "arxiv_id": "2505.07247v2",
      "title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peichao Lai",
        "Kexuan Zhang",
        "Yi Lin",
        "Linyihan Zhang",
        "Feiyang Ye",
        "Jinhao Yan",
        "Yanwei Xu",
        "Conghui He",
        "Yilei Wang",
        "Wentao Zhang",
        "Bin Cui"
      ],
      "abstract": "Subjective Answer Grading (SAG) plays a crucial role in education,\nstandardized testing, and automated assessment systems, particularly for\nevaluating short-form responses in Short Answer Scoring (SAS). However,\nexisting approaches often produce coarse-grained scores and lack detailed\nreasoning. Although large language models (LLMs) have demonstrated potential as\nzero-shot evaluators, they remain susceptible to bias, inconsistencies with\nhuman judgment, and limited transparency in scoring decisions. To overcome\nthese limitations, we introduce SAS-Bench, a benchmark specifically designed\nfor LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring,\nexpert-annotated error categories, and a diverse range of question types\nderived from real-world subject-specific exams. This benchmark facilitates\ndetailed evaluation of model reasoning processes and explainability. We also\nrelease an open-source dataset containing 1,030 questions and 4,109 student\nresponses, each annotated by domain experts. Furthermore, we conduct\ncomprehensive experiments with various LLMs, identifying major challenges in\nscoring science-related questions and highlighting the effectiveness of\nfew-shot prompting in improving scoring accuracy. Our work offers valuable\ninsights into the development of more robust, fair, and educationally\nmeaningful LLM-based evaluation systems.",
      "tldr_zh": "本文引入 SAS-Bench，这是一个细粒度基准，用于评估 Large Language Models (LLMs) 在 Short Answer Scoring (SAS) 任务中的表现，旨在解决现有方法评分粗糙和缺乏详细推理的问题。SAS-Bench 提供分步评分、专家标注的错误类别，以及从真实考试中得来的多样问题类型，并发布开源数据集，包括 1,030 个问题和 4,109 个学生响应。实验结果显示，LLMs 在评分科学相关问题时面临主要挑战，但 few-shot prompting 可以显著提高准确性。该基准为开发更稳健、公平且教育意义的 LLM 评估系统提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07247v2",
      "published_date": "2025-05-12 05:43:21 UTC",
      "updated_date": "2025-05-15 11:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:15:53.186357"
    },
    {
      "arxiv_id": "2505.07245v1",
      "title": "REMEDI: Relative Feature Enhanced Meta-Learning with Distillation for Imbalanced Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Liu",
        "Huanhuan Ren",
        "Yu Guan",
        "Xiuxu Wang",
        "Wang Lv",
        "Zhiqiang Hu",
        "Yaxi Chen"
      ],
      "abstract": "Predicting future vehicle purchases among existing owners presents a critical\nchallenge due to extreme class imbalance (<0.5% positive rate) and complex\nbehavioral patterns. We propose REMEDI (Relative feature Enhanced Meta-learning\nwith Distillation for Imbalanced prediction), a novel multi-stage framework\naddressing these challenges. REMEDI first trains diverse base models to capture\ncomplementary aspects of user behavior. Second, inspired by comparative\nop-timization techniques, we introduce relative performance meta-features\n(deviation from ensemble mean, rank among peers) for effective model fusion\nthrough a hybrid-expert architecture. Third, we distill the ensemble's\nknowledge into a single efficient model via supervised fine-tuning with MSE\nloss, enabling practical deployment. Evaluated on approximately 800,000 vehicle\nowners, REMEDI significantly outperforms baseline approaches, achieving the\nbusiness target of identifying ~50% of actual buyers within the top 60,000\nrecommendations at ~10% precision. The distilled model preserves the ensemble's\npredictive power while maintaining deployment efficiency, demonstrating\nREMEDI's effectiveness for imbalanced prediction in industry settings.",
      "tldr_zh": "该研究提出 REMEDI 框架，用于处理极端类不平衡预测（如车辆购买行为，<0.5% 正例率）的问题。REMEDI 通过多阶段方法，首先训练多样化的基模型捕捉用户行为的互补方面；其次，引入相对性能元特征（如与集合均值的偏差和排名）来实现模型融合的混合专家架构；最后，通过监督微调和 MSE 损失将知识蒸馏到一个高效模型中，便于部署。在约 80 万车主数据上，REMEDI 显著优于基线方法，实现了业务目标：在前 60,000 推荐中识别约 50% 的实际买家，精确率达 ~10%。该框架证明了在工业环境中 Meta-Learning with Distillation 的有效性，同时兼顾预测性能和部署效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07245v1",
      "published_date": "2025-05-12 05:40:20 UTC",
      "updated_date": "2025-05-12 05:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:16:04.680043"
    },
    {
      "arxiv_id": "2505.07897v1",
      "title": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano Rando",
        "Luca Romani",
        "Alessio Sampieri",
        "Yuta Kyuragi",
        "Luca Franco",
        "Fabio Galasso",
        "Tatsunori Hashimoto",
        "John Yang"
      ],
      "abstract": "Context lengths for models have grown rapidly, from thousands to millions of\ntokens in just a few years. The extreme context sizes of modern long-context\nmodels have made it difficult to construct realistic long-context benchmarks --\nnot only due to the cost of collecting million-context tasks but also in\nidentifying realistic scenarios that require significant contexts. We identify\ncode comprehension and repair as a natural testbed and challenge task for\nlong-context models and introduce LongCodeBench (LCB), a benchmark to test LLM\ncoding abilities in long-context scenarios. Our benchmark tests both the\ncomprehension and repair capabilities of LCLMs in realistic and important\nsettings by drawing from real-world GitHub issues and constructing QA\n(LongCodeQA) and bug fixing (LongSWE-Bench) tasks. We carefully stratify the\ncomplexity of our benchmark, enabling us to evaluate models across different\nscales -- ranging from Qwen2.5 14B Instruct to Google's flagship Gemini model.\nWe find that long-context remains a weakness for all models, with performance\ndrops such as from 29% to 3% for Claude 3.5 Sonnet, or from 70.2% to 40% for\nQwen2.5.",
      "tldr_zh": "本研究引入LongCodeBench (LCB)，一个基准测试框架，用于评估大型语言模型(LLMs)在百万上下文窗口下的编码能力，特别针对代码理解和修复任务，以解决构建现实长上下文基准的挑战。LCB基于真实GitHub问题构建了QA任务(LongCodeQA)和错误修复任务(LongSWE-Bench)，并按复杂性分层，允许评估从Qwen2.5 14B到Gemini等不同规模的模型。结果显示，长上下文仍是模型的弱点，导致性能大幅下降，例如Claude 3.5 Sonnet从29%降至3%，Qwen2.5从70.2%降至40%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07897v1",
      "published_date": "2025-05-12 05:38:03 UTC",
      "updated_date": "2025-05-12 05:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:16:16.991797"
    },
    {
      "arxiv_id": "2505.07239v1",
      "title": "Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity",
      "title_zh": "Comet：通过预测激活稀疏性加速大型语言模型的私有推理",
      "authors": [
        "Guang Yan",
        "Yuhui Zhang",
        "Zimu Guo",
        "Lutan Zhao",
        "Xiaojun Chen",
        "Chen Wang",
        "Wenhao Wang",
        "Dan Meng",
        "Rui Hou"
      ],
      "abstract": "With the growing use of large language models (LLMs) hosted on cloud\nplatforms to offer inference services, privacy concerns about the potential\nleakage of sensitive information are escalating. Secure multi-party computation\n(MPC) is a promising solution to protect the privacy in LLM inference. However,\nMPC requires frequent inter-server communication, causing high performance\noverhead.\n  Inspired by the prevalent activation sparsity of LLMs, where most neuron are\nnot activated after non-linear activation functions, we propose an efficient\nprivate inference system, Comet. This system employs an accurate and fast\npredictor to predict the sparsity distribution of activation function output.\nAdditionally, we introduce a new private inference protocol. It efficiently and\nsecurely avoids computations involving zero values by exploiting the spatial\nlocality of the predicted sparse distribution. While this computation-avoidance\napproach impacts the spatiotemporal continuity of KV cache entries, we address\nthis challenge with a low-communication overhead cache refilling strategy that\nmerges miss requests and incorporates a prefetching mechanism. Finally, we\nevaluate Comet on four common LLMs and compare it with six state-of-the-art\nprivate inference systems. Comet achieves a 1.87x-2.63x speedup and a\n1.94x-2.64x communication reduction.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)私有推理中的隐私泄露风险，提出了一种名为Comet的系统，通过预测激活稀疏性(activation sparsity)来加速Secure multi-party computation (MPC)过程。Comet采用一个准确且快速的预测器来预估激活函数输出的稀疏分布，并引入一个新私有推理协议，利用预测的稀疏分布的空间局部性，避免涉及零值的计算，同时通过低通信开销的缓存重填策略（包括合并miss请求和预取机制）处理KV cache条目的连续性问题。在四个常见LLMs上的实验中，Comet相较六种最先进系统实现了1.87x-2.63x的加速和1.94x-2.64x的通信减少，从而提升了私有推理的效率和性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to SP 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07239v1",
      "published_date": "2025-05-12 05:29:30 UTC",
      "updated_date": "2025-05-12 05:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:16:29.498248"
    },
    {
      "arxiv_id": "2505.07236v1",
      "title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Oleg Sautenkov",
        "Yasheerah Yaqoot",
        "Muhammad Ahsan Mustafa",
        "Faryal Batool",
        "Jeffrin Sam",
        "Artem Lykov",
        "Chih-Yung Wen",
        "Dzmitry Tsetserukou"
      ],
      "abstract": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous\nUAV mission generation, built on large language and vision-language models\n(LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to\ninterpret satellite imagery, ground high-level natural language instructions,\nand collaboratively generate UAV trajectories with minimal human supervision. A\ncore component is a vision-grounded, pixel-pointing mechanism that enables\nprecise localization of semantic targets on aerial maps. To support real-time\nadaptability, we introduce a reactive thinking loop, allowing agents to\niteratively reflect on observations, revise mission goals, and coordinate\ndynamically in evolving environments.\n  UAV-CodeAgents is evaluated on large-scale mission scenarios involving\nindustrial and environmental fire detection. Our results show that a lower\ndecoding temperature (0.5) yields higher planning reliability and reduced\nexecution time, with an average mission creation time of 96.96 seconds and a\nsuccess rate of 93%. We further fine-tune Qwen2.5VL-7B on 9,000 annotated\nsatellite images, achieving strong spatial grounding across diverse visual\ncategories. To foster reproducibility and future research, we will release the\nfull codebase and a novel benchmark dataset for vision-language-based UAV\nplanning.",
      "tldr_zh": "本研究提出UAV-CodeAgents，一种可扩展的多智能体框架，利用ReAct（Reason + Act）范式和视觉语言模型（VLMs/LLMs），实现自主无人机（UAV）任务规划，通过解读卫星图像和自然语言指令来协作生成轨迹。核心组件包括视觉定位机制和反应式思考循环，支持精确目标定位和实时环境适应，减少人为干预。实验在工业和环境火情检测场景中评估，结果显示低解码温度（0.5）提升了规划可靠性，平均任务创建时间为96.96秒，成功率达93%；此外，通过在9000张标注卫星图像上微调Qwen2.5VL-7B模型，框架实现了强化的空间定位能力，并将发布代码和基准数据集以促进后续研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted",
      "pdf_url": "http://arxiv.org/pdf/2505.07236v1",
      "published_date": "2025-05-12 05:23:51 UTC",
      "updated_date": "2025-05-12 05:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:16:40.826141"
    },
    {
      "arxiv_id": "2505.07233v2",
      "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiashuo Sun",
        "Xianrui Zhong",
        "Sizhe Zhou",
        "Jiawei Han"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems combine large language models\n(LLMs) with external knowledge retrieval, making them highly effective for\nknowledge-intensive tasks. A crucial but often under-explored component of\nthese systems is the reranker. Since irrelevant documents in RAG systems can\nmislead the generator, the reranker plays a vital role in refining retrieved\ndocuments to enhance generation quality and explainability. However, it is\nchallenging to determine the appropriate number of documents ($k$) that the\nreranker should select: too few may result in missing critical information,\nwhile too many introduce noise and inefficiencies. Although recent studies have\nexplored LLM-based rerankers, they primarily leverage internal model knowledge\nand overlook the rich supervisory signals that LLMs can provide, such as using\nresponse quality as feedback for optimizing reranking decisions. In this paper,\nwe propose DynamicRAG, a novel RAG framework where the reranker dynamically\nadjusts both the order and number of retrieved documents based on the query. We\nmodel the reranker as an agent optimized through reinforcement learning (RL),\nusing rewards derived from LLM output quality. Across seven knowledge-intensive\ndatasets, DynamicRAG demonstrates superior performance, achieving\nstate-of-the-art results among models of same parameter sizes. The model, data\nand code are available at https://github.com/GasolSun36/DynamicRAG.",
      "tldr_zh": "这篇论文提出了 DynamicRAG，一种新型 Retrieval-Augmented Generation (RAG) 框架，通过利用 Large Language Model (LLMs) 输出作为反馈信号来动态优化 reranking 过程。框架将 reranker 建模为一个通过强化学习 (RL) 优化的代理，根据查询动态调整检索文档的顺序和数量，以避免信息缺失或引入噪声。在七个知识密集型数据集上，DynamicRAG 表现出色，实现了同参数规模模型的 state-of-the-art 性能，并提供了开源模型、数据和代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 7 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07233v2",
      "published_date": "2025-05-12 05:19:01 UTC",
      "updated_date": "2025-05-16 02:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:16:53.762820"
    },
    {
      "arxiv_id": "2505.07215v1",
      "title": "Measuring General Intelligence with Generated Games",
      "title_zh": "使用生成的游戏衡量通用智能",
      "authors": [
        "Vivek Verma",
        "David Huang",
        "William Chen",
        "Dan Klein",
        "Nicholas Tomlin"
      ],
      "abstract": "We present gg-bench, a collection of game environments designed to evaluate\ngeneral reasoning capabilities in language models. Unlike most static\nbenchmarks, gg-bench is a data generating process where new evaluation\ninstances can be generated at will. In particular, gg-bench is synthetically\ngenerated by (1) using a large language model (LLM) to generate natural\nlanguage descriptions of novel games, (2) using the LLM to implement each game\nin code as a Gym environment, and (3) training reinforcement learning (RL)\nagents via self-play on the generated games. We evaluate language models by\ntheir winrate against these RL agents by prompting models with the game\ndescription, current board state, and a list of valid moves, after which models\noutput the moves they wish to take. gg-bench is challenging: state-of-the-art\nLLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench\nusing in-context learning, while reasoning models such as o1, o3-mini and\nDeepSeek-R1 achieve average winrates of 31-36%. We release the generated games,\ndata generation process, and evaluation code in order to support future\nmodeling work and expansion of our benchmark.",
      "tldr_zh": "这篇论文提出了一种名为 gg-bench 的动态游戏环境集合，用于评估语言模型的一般推理能力。方法包括使用 LLM 生成新游戏的自然语言描述和 Gym 环境代码，随后通过自对弈训练 RL agents，并评估模型通过游戏描述、棋盘状态和有效移动的提示输出来对弈的胜率。实验结果显示，顶级 LLM 如 GPT-4o 和 Claude 3.5 Sonnet 的胜率仅为7-9%，而推理模型如 o1 和 o3-mini 达到31-36%，突显了 gg-bench 的挑战性；作者还发布了生成的游戏、数据生成过程和评估代码，以支持未来模型开发。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07215v1",
      "published_date": "2025-05-12 04:01:03 UTC",
      "updated_date": "2025-05-12 04:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:17:06.381205"
    },
    {
      "arxiv_id": "2505.07214v2",
      "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent",
      "title_zh": "翻译失败",
      "authors": [
        "Pascal Spiegler",
        "Arash Harirpoush",
        "Yiming Xiao"
      ],
      "abstract": "Crucial in disease analysis and surgical planning, manual segmentation of\nvolumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and\nchallenging to master, while fully automatic algorithms can benefit from user\nfeedback. Therefore, with the complementary power of the latest radiological AI\nfoundation models and virtual reality (VR)'s intuitive data interaction, we\npropose SAMIRA, a novel conversational AI agent that assists users with\nlocalizing, segmenting, and visualizing 3D medical concepts in VR. Through\nspeech-based interaction, the agent helps users understand radiological\nfeatures, locate clinical targets, and generate segmentation masks that can be\nrefined with just a few point prompts. The system also supports true-to-scale\n3D visualization of segmented pathology to enhance patient-specific anatomical\nunderstanding. Furthermore, to determine the optimal interaction paradigm under\nnear-far attention-switching for refining segmentation masks in an immersive,\nhuman-in-the-loop workflow, we compare VR controller pointing, head pointing,\nand eye tracking as input modes. With a user study, evaluations demonstrated a\nhigh usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as\nstrong support for the proposed VR system's guidance, training potential, and\nintegration of AI in radiological segmentation tasks.",
      "tldr_zh": "该研究针对手动医疗图像分割（如MRI、CT扫描）的低效问题，提出了一种用户中心交互式系统SAMIRA，该系统结合放射学AI基础模型和VR技术，通过语音交互帮助用户定位、分割和可视化3D医学概念，并支持基于点提示的掩码精炼和真实比例的3D病理可视化。为了优化VR中的注意力切换交互，该系统比较了VR控制器指向、头部指向和眼动追踪三种输入模式。用户研究结果显示，SAMIRA的可用性得分高（SUS=90.0 ± 9.0）、任务负载低，并证明了其在放射学分割任务中的指导和培训潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07214v2",
      "published_date": "2025-05-12 03:47:05 UTC",
      "updated_date": "2025-05-15 05:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:17:17.422130"
    },
    {
      "arxiv_id": "2505.07896v1",
      "title": "Bridging Large Language Models and Single-Cell Transcriptomics in Dissecting Selective Motor Neuron Vulnerability",
      "title_zh": "翻译失败",
      "authors": [
        "Douglas Jiang",
        "Zilin Dai",
        "Luxuan Zhang",
        "Qiyi Yu",
        "Haoqi Sun",
        "Feng Tian"
      ],
      "abstract": "Understanding cell identity and function through single-cell level sequencing\ndata remains a key challenge in computational biology. We present a novel\nframework that leverages gene-specific textual annotations from the NCBI Gene\ndatabase to generate biologically contextualized cell embeddings. For each cell\nin a single-cell RNA sequencing (scRNA-seq) dataset, we rank genes by\nexpression level, retrieve their NCBI Gene descriptions, and transform these\ndescriptions into vector embedding representations using large language models\n(LLMs). The models used include OpenAI text-embedding-ada-002,\ntext-embedding-3-small, and text-embedding-3-large (Jan 2024), as well as\ndomain-specific models BioBERT and SciBERT. Embeddings are computed via an\nexpression-weighted average across the top N most highly expressed genes in\neach cell, providing a compact, semantically rich representation. This\nmultimodal strategy bridges structured biological data with state-of-the-art\nlanguage modeling, enabling more interpretable downstream applications such as\ncell-type clustering, cell vulnerability dissection, and trajectory inference.",
      "tldr_zh": "本研究提出了一种新框架，将大型语言模型（LLMs）与单细胞转录组学（scRNA-seq）相结合，旨在通过NCBI Gene数据库的基因特定文本注释生成生物学背景化的细胞嵌入。该方法对每个细胞按基因表达水平排名，检索相应基因描述，并使用LLMs（如OpenAI text-embedding-ada-002、text-embedding-3-small、text-embedding-3-large、BioBERT和SciBERT）将这些描述转化为向量嵌入，然后通过对每个细胞中表达最高的N个基因进行加权平均，得到紧凑且语义丰富的表示。这种多模态策略桥接了结构化生物数据与先进语言模型，支持更可解释的下游应用，包括细胞类型聚类、细胞易损性剖析（如选择性运动神经元易损性）和轨迹推断。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07896v1",
      "published_date": "2025-05-12 03:39:33 UTC",
      "updated_date": "2025-05-12 03:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:17:29.493669"
    },
    {
      "arxiv_id": "2505.07895v1",
      "title": "Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks",
      "title_zh": "多模态异构网络中基于模态相互影响的表示学习，用于节点分类",
      "authors": [
        "Jiafan Li",
        "Jiaqi Zhu",
        "Liang Chang",
        "Yilin Li",
        "Miaomiao Li",
        "Yang Wang",
        "Hongan Wang"
      ],
      "abstract": "Nowadays, numerous online platforms can be described as multi-modal\nheterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's\nproduct review networks. Accurately categorizing nodes within these networks is\ncrucial for analyzing the corresponding entities, which requires effective\nrepresentation learning on nodes. However, existing multi-modal fusion methods\noften adopt either early fusion strategies which may lose the unique\ncharacteristics of individual modalities, or late fusion approaches overlooking\nthe cross-modal guidance in GNN-based information propagation. In this paper,\nwe propose a novel model for node classification in MMHNs, named Heterogeneous\nGraph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node\nrepresentations by capturing the mutual influence of multiple modalities during\nthe information propagation process, within the framework of heterogeneous\ngraph transformer. Specifically, a nested inter-modal attention mechanism is\nintegrated into the inter-node attention to achieve adaptive multi-modal\nfusion, and modality alignment is also taken into account to encourage the\npropagation among nodes with consistent similarities across all modalities.\nMoreover, an attention loss is augmented to mitigate the impact of missing\nmodalities. Extensive experiments validate the superiority of the model in the\nnode classification task, providing an innovative view to handle multi-modal\ndata, especially when accompanied with network structures.",
      "tldr_zh": "本论文针对多模态异构网络（MMHNs）中的节点分类问题，提出了一种新模型Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA)，旨在通过捕获模态之间的相互影响来提升节点表示学习。HGNN-IMA在异构图变换器框架下，采用嵌套的跨模态注意力机制（inter-modal attention）实现自适应多模态融合，并通过模态对齐（modality alignment）和注意力损失（attention loss）来处理缺失模态及其传播问题。实验结果显示，该模型在节点分类任务上优于现有early fusion和late fusion方法，提供了一种创新视角来处理带网络结构的多模态数据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07895v1",
      "published_date": "2025-05-12 02:59:46 UTC",
      "updated_date": "2025-05-12 02:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:17:42.459185"
    },
    {
      "arxiv_id": "2505.08808v1",
      "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction",
      "title_zh": "SparseMeXT：释放稀疏表示用于高清",
      "authors": [
        "Anqing Jiang",
        "Jinhao Chai",
        "Yu Gao",
        "Yiru Wang",
        "Yuwen Heng",
        "Zhigang Sun",
        "Hao Sun",
        "Zezhong Zhao",
        "Li Sun",
        "Jian Zhou",
        "Lijuan Zhu",
        "Shugong Xu",
        "Hao Zhao"
      ],
      "abstract": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield.",
      "tldr_zh": "该论文提出 SparseMeXT 框架，通过系统优化 sparse representations 来提升 HD 地图构建的效率和性能，解决现有方法依赖密集 BEV 特征的计算密集问题。关键创新包括专用网络架构用于 sparse map feature extraction、sparse-dense segmentation 辅助任务以整合几何和语义线索，以及基于物理 priors 的 denoising 模块来精炼预测。实验在 nuScenes 数据集上取得 state-of-the-art 结果，SparseMeXT-Tiny 达到 55.5% mAP at 32 fps，SparseMeXT-Large 则达 68.9% mAP at over 20 fps。这些进展证明了 sparse representations 的潜力，重新定义了 HD 地图构建中的效率与性能权衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08808v1",
      "published_date": "2025-05-12 02:26:58 UTC",
      "updated_date": "2025-05-12 02:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:17:54.181710"
    },
    {
      "arxiv_id": "2505.07178v1",
      "title": "Accountability of Generative AI: Exploring a Precautionary Approach for \"Artificially Created Nature\"",
      "title_zh": "翻译失败",
      "authors": [
        "Yuri Nakao"
      ],
      "abstract": "The rapid development of generative artificial intelligence (AI) technologies\nraises concerns about the accountability of sociotechnical systems. Current\ngenerative AI systems rely on complex mechanisms that make it difficult for\neven experts to fully trace the reasons behind the outputs. This paper first\nexamines existing research on AI transparency and accountability and argues\nthat transparency is not a sufficient condition for accountability but can\ncontribute to its improvement. We then discuss that if it is not possible to\nmake generative AI transparent, generative AI technology becomes ``artificially\ncreated nature'' in a metaphorical sense, and suggest using the precautionary\nprinciple approach to consider AI risks. Finally, we propose that a platform\nfor citizen participation is needed to address the risks of generative AI.",
      "tldr_zh": "这篇论文探讨了 generative AI 的责任问题，强调其复杂机制使输出原因难以追踪，并审视现有 AI 透明度和责任研究，认为透明有助于但不足以确保责任。作者提出，如果 generative AI 无法实现透明，它可被比喻为“artificially created nature”，并建议采用 precautionary principle 来评估潜在风险。最后，论文主张建立公民参与平台，以共同应对 generative AI 的风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07178v1",
      "published_date": "2025-05-12 02:10:55 UTC",
      "updated_date": "2025-05-12 02:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:18:04.405257"
    },
    {
      "arxiv_id": "2505.08807v1",
      "title": "Security of Internet of Agents: Attacks and Countermeasures",
      "title_zh": "翻译失败",
      "authors": [
        "Yuntao Wang",
        "Yanghe Pan",
        "Shaolong Guo",
        "Zhou Su"
      ],
      "abstract": "With the rise of large language and vision-language models, AI agents have\nevolved into autonomous, interactive systems capable of perception, reasoning,\nand decision-making. As they proliferate across virtual and physical domains,\nthe Internet of Agents (IoA) has emerged as a key infrastructure for enabling\nscalable and secure coordination among heterogeneous agents. This survey offers\na comprehensive examination of the security and privacy landscape in IoA\nsystems. We begin by outlining the IoA architecture and its distinct\nvulnerabilities compared to traditional networks, focusing on four critical\naspects: identity authentication threats, cross-agent trust issues, embodied\nsecurity, and privacy risks. We then review existing and emerging defense\nmechanisms and highlight persistent challenges. Finally, we identify open\nresearch directions to advance the development of resilient and\nprivacy-preserving IoA ecosystems.",
      "tldr_zh": "这篇调查论文探讨了Internet of Agents (IoA)系统的安全和隐私问题，随着AI代理（包括大型语言模型和视觉语言模型）的兴起，IoA已成为异构代理之间可扩展协调的关键基础设施。论文分析了IoA架构的独特漏洞，聚焦于四个关键方面：身份认证威胁、跨代理信任问题、实体安全以及隐私风险，并审阅了现有的防御机制及持续挑战。最终，论文识别了开放研究方向，以推动构建弹性且隐私保护的IoA生态系统。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 5 figures, 3 tables, submitted to IEEE OJCS",
      "pdf_url": "http://arxiv.org/pdf/2505.08807v1",
      "published_date": "2025-05-12 02:04:57 UTC",
      "updated_date": "2025-05-12 02:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:18:16.724776"
    },
    {
      "arxiv_id": "2505.07176v1",
      "title": "Internet of Agents: Fundamentals, Applications, and Challenges",
      "title_zh": "代理互联网：基础、应用和挑战",
      "authors": [
        "Yuntao Wang",
        "Shaolong Guo",
        "Yanghe Pan",
        "Zhou Su",
        "Fahao Chen",
        "Tom H. Luan",
        "Peng Li",
        "Jiawen Kang",
        "Dusit Niyato"
      ],
      "abstract": "With the rapid proliferation of large language models and vision-language\nmodels, AI agents have evolved from isolated, task-specific systems into\nautonomous, interactive entities capable of perceiving, reasoning, and acting\nwithout human intervention. As these agents proliferate across virtual and\nphysical environments, from virtual assistants to embodied robots, the need for\na unified, agent-centric infrastructure becomes paramount. In this survey, we\nintroduce the Internet of Agents (IoA) as a foundational framework that enables\nseamless interconnection, dynamic discovery, and collaborative orchestration\namong heterogeneous agents at scale. We begin by presenting a general IoA\narchitecture, highlighting its hierarchical organization, distinguishing\nfeatures relative to the traditional Internet, and emerging applications. Next,\nwe analyze the key operational enablers of IoA, including capability\nnotification and discovery, adaptive communication protocols, dynamic task\nmatching, consensus and conflict-resolution mechanisms, and incentive models.\nFinally, we identify open research directions toward building resilient and\ntrustworthy IoA ecosystems.",
      "tldr_zh": "这篇调查论文介绍了 Internet of Agents (IoA) 框架，作为一种统一的基础设施，支持异构 AI agents 在虚拟和物理环境中的无缝互联、动态发现和协作编排。IoA 采用层次化架构，突出了其与传统 Internet 的区别，并探讨了新兴应用，如虚拟助理和机器人系统。论文分析了关键操作启用器，包括 capability notification and discovery、adaptive communication protocols、dynamic task matching、consensus and conflict-resolution mechanisms 以及 incentive models，并指出了构建 resilient and trustworthy IoA 生态系统的开放研究方向。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "22 pages,10 figures, 8 tables. Submitted to IEEE TCCN",
      "pdf_url": "http://arxiv.org/pdf/2505.07176v1",
      "published_date": "2025-05-12 02:04:37 UTC",
      "updated_date": "2025-05-12 02:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:18:30.126506"
    },
    {
      "arxiv_id": "2505.07171v1",
      "title": "ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongho Kim",
        "Chanyeong Heo",
        "Jaehee Jung"
      ],
      "abstract": "Knowledge Graphs (KGs), composed of triples in the form of (head, relation,\ntail) and consisting of entities and relations, play a key role in information\nretrieval systems such as question answering, entity search, and\nrecommendation. In real-world KGs, although many entities exist, the relations\nexhibit a long-tail distribution, which can hinder information retrieval\nperformance. Previous few-shot knowledge graph completion studies focused\nexclusively on the positive triple information that exists in the graph or,\nwhen negative triples were incorporated, used them merely as a signal to\nindicate incorrect triples. To overcome this limitation, we propose\nRelation-Based Conditional Diffusion with Attention Pooling (ReCDAP). First,\nnegative triples are generated by randomly replacing the tail entity in the\nsupport set. By conditionally incorporating positive information in the KG and\nnon-existent negative information into the diffusion process, the model\nseparately estimates the latent distributions for positive and negative\nrelations. Moreover, including an attention pooler enables the model to\nleverage the differences between positive and negative cases explicitly.\nExperiments on two widely used datasets demonstrate that our method outperforms\nexisting approaches, achieving state-of-the-art performance. The code is\navailable at https://github.com/hou27/ReCDAP-FKGC.",
      "tldr_zh": "本研究针对知识图谱（KGs）中关系长尾分布问题，提出了一种名为 ReCDAP 的方法，用于少样本知识图谱补全（Few-Shot Knowledge Graph Completion）。ReCDAP 通过生成负三元组并将正负信息条件性地融入扩散过程（Conditional Diffusion），结合注意力池化（Attention Pooling）来分别估计正负关系的潜在分布，从而显式利用正负案例的差异。实验在两个常用数据集上表明，该方法超过了现有方法，达到了最先进性能，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by SIGIR 2025, 5 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.07171v1",
      "published_date": "2025-05-12 01:49:52 UTC",
      "updated_date": "2025-05-12 01:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:18:41.408540"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 132,
  "processed_papers_count": 132,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T22:19:01.767767"
}