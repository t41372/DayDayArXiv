[
  {
    "arxiv_id": "2505.08827v1",
    "title": "Self Rewarding Self Improving",
    "authors": [
      "Toby Simonds",
      "Kevin Lopez",
      "Akira Yoshiyama",
      "Dominique Garmier"
    ],
    "abstract": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08827v1",
    "published_date": "2025-05-12 23:51:04 UTC",
    "updated_date": "2025-05-12 23:51:04 UTC"
  },
  {
    "arxiv_id": "2505.08124v1",
    "title": "SLAG: Scalable Language-Augmented Gaussian Splatting",
    "authors": [
      "Laszlo Szilagyi",
      "Francis Engelmann",
      "Jeannette Bohg"
    ],
    "abstract": "Language-augmented scene representations hold great promise for large-scale\nrobotics applications such as search-and-rescue, smart cities, and mining. Many\nof these scenarios are time-sensitive, requiring rapid scene encoding while\nalso being data-intensive, necessitating scalable solutions. Deploying these\nrepresentations on robots with limited computational resources further adds to\nthe challenge. To address this, we introduce SLAG, a multi-GPU framework for\nlanguage-augmented Gaussian splatting that enhances the speed and scalability\nof embedding large scenes. Our method integrates 2D visual-language model\nfeatures into 3D scenes using SAM and CLIP. Unlike prior approaches, SLAG\neliminates the need for a loss function to compute per-Gaussian language\nembeddings. Instead, it derives embeddings from 3D Gaussian scene parameters\nvia a normalized weighted average, enabling highly parallelized scene encoding.\nAdditionally, we introduce a vector database for efficient embedding storage\nand retrieval. Our experiments show that SLAG achieves an 18 times speedup in\nembedding computation on a 16-GPU setup compared to OpenGaussian, while\npreserving embedding quality on the ScanNet and LERF datasets. For more\ndetails, visit our project website: https://slag-project.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08124v1",
    "published_date": "2025-05-12 23:32:24 UTC",
    "updated_date": "2025-05-12 23:32:24 UTC"
  },
  {
    "arxiv_id": "2505.08123v1",
    "title": "JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections",
    "authors": [
      "Qing Wu",
      "Hongjiang Wei",
      "Jingyi Yu",
      "S. Kevin Zhou",
      "Yuyao Zhang"
    ],
    "abstract": "Multi-material decomposition (MMD) enables quantitative reconstruction of\ntissue compositions in the human body, supporting a wide range of clinical\napplications. However, traditional MMD typically requires spectral CT scanners\nand pre-measured X-ray energy spectra, significantly limiting clinical\napplicability. To this end, various methods have been developed to perform MMD\nusing conventional (i.e., single-energy, SE) CT systems, commonly referred to\nas SEMMD. Despite promising progress, most SEMMD methods follow a two-step\nimage decomposition pipeline, which first reconstructs monochromatic CT images\nusing algorithms such as FBP, and then performs decomposition on these images.\nThe initial reconstruction step, however, neglects the energy-dependent\nattenuation of human tissues, introducing severe nonlinear beam hardening\nartifacts and noise into the subsequent decomposition. This paper proposes\nJSover, a fundamentally reformulated one-step SEMMD framework that jointly\nreconstructs multi-material compositions and estimates the energy spectrum\ndirectly from SECT projections. By explicitly incorporating physics-informed\nspectral priors into the SEMMD process, JSover accurately simulates a virtual\nspectral CT system from SE acquisitions, thereby improving the reliability and\naccuracy of decomposition. Furthermore, we introduce implicit neural\nrepresentation (INR) as an unsupervised deep learning solver for representing\nthe underlying material maps. The inductive bias of INR toward continuous image\npatterns constrains the solution space and further enhances estimation quality.\nExtensive experiments on both simulated and real CT datasets show that JSover\noutperforms state-of-the-art SEMMD methods in accuracy and computational\nefficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.08123v1",
    "published_date": "2025-05-12 23:32:21 UTC",
    "updated_date": "2025-05-12 23:32:21 UTC"
  },
  {
    "arxiv_id": "2505.08106v1",
    "title": "Are LLMs complicated ethical dilemma analyzers?",
    "authors": [
      "Jiashen",
      "Du",
      "Jesse Yao",
      "Allen Liu",
      "Zhekai Zhang"
    ],
    "abstract": "One open question in the study of Large Language Models (LLMs) is whether\nthey can emulate human ethical reasoning and act as believable proxies for\nhuman judgment. To investigate this, we introduce a benchmark dataset\ncomprising 196 real-world ethical dilemmas and expert opinions, each segmented\ninto five structured components: Introduction, Key Factors, Historical\nTheoretical Perspectives, Resolution Strategies, and Key Takeaways. We also\ncollect non-expert human responses for comparison, limited to the Key Factors\nsection due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini,\nClaude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric\nframework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine\nsimilarity, and Universal Sentence Encoder similarity. Metric weights are\ncomputed through an inversion-based ranking alignment and pairwise AHP\nanalysis, enabling fine-grained comparison of model outputs to expert\nresponses. Our results show that LLMs generally outperform non-expert humans in\nlexical and structural alignment, with GPT-4o-mini performing most consistently\nacross all sections. However, all models struggle with historical grounding and\nproposing nuanced resolution strategies, which require contextual abstraction.\nHuman responses, while less structured, occasionally achieve comparable\nsemantic similarity, suggesting intuitive moral reasoning. These findings\nhighlight both the strengths and current limitations of LLMs in ethical\ndecision-making.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "CS194-280 Advanced LLM Agents project. Project page:\n  https://github.com/ALT-JS/ethicaLLM",
    "pdf_url": "http://arxiv.org/pdf/2505.08106v1",
    "published_date": "2025-05-12 22:35:07 UTC",
    "updated_date": "2025-05-12 22:35:07 UTC"
  },
  {
    "arxiv_id": "2505.08088v1",
    "title": "Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories",
    "authors": [
      "Rabia Yasa Kostas",
      "Kahraman Kostas"
    ],
    "abstract": "Indoor positioning systems (IPSs) are increasingly vital for location-based\nservices in complex multi-storey environments. This study proposes a novel\ngraph-based approach for floor separation using Wi-Fi fingerprint trajectories,\naddressing the challenge of vertical localization in indoor settings. We\nconstruct a graph where nodes represent Wi-Fi fingerprints, and edges are\nweighted by signal similarity and contextual transitions. Node2Vec is employed\nto generate low-dimensional embeddings, which are subsequently clustered using\nK-means to identify distinct floors. Evaluated on the Huawei University\nChallenge 2021 dataset, our method outperforms traditional community detection\nalgorithms, achieving an accuracy of 68.97%, an F1- score of 61.99%, and an\nAdjusted Rand Index of 57.19%. By publicly releasing the preprocessed dataset\nand implementation code, this work contributes to advancing research in indoor\npositioning. The proposed approach demonstrates robustness to signal noise and\narchitectural complexities, offering a scalable solution for floor-level\nlocalization.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08088v1",
    "published_date": "2025-05-12 21:46:36 UTC",
    "updated_date": "2025-05-12 21:46:36 UTC"
  },
  {
    "arxiv_id": "2505.08825v1",
    "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning",
    "authors": [
      "Pedro Antonio Alarcon Granadeno",
      "Theodore Chambers",
      "Jane Cleland-Huang"
    ],
    "abstract": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon\ngas leak (2015) demonstrate the urgent need for rapid and reliable plume\ntracing algorithms to protect public health and the environment. Traditional\nmethods, such as gradient-based or biologically inspired approaches, often fail\nin realistic, turbulent conditions. To address these challenges, we present a\nMulti-Agent Reinforcement Learning (MARL) algorithm designed for localizing\nmultiple airborne pollution sources using a swarm of small uncrewed aerial\nsystems (sUAS). Our method models the problem as a Partially Observable Markov\nGame (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific\nDouble Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical\naction-observation pairs, effectively approximating latent states. Unlike prior\nwork, we use a general-purpose simulation environment based on the Gaussian\nPlume Model (GPM), incorporating realistic elements such as a three-dimensional\nenvironment, sensor noise, multiple interacting agents, and multiple plume\nsources. The incorporation of action histories as part of the inputs further\nenhances the adaptability of our model in complex, partially observable\nenvironments. Extensive simulations show that our algorithm significantly\noutperforms conventional approaches. Specifically, our model allows agents to\nexplore only 1.29\\% of the environment to successfully locate pollution\nsources.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08825v1",
    "published_date": "2025-05-12 21:33:15 UTC",
    "updated_date": "2025-05-12 21:33:15 UTC"
  },
  {
    "arxiv_id": "2505.08082v1",
    "title": "Fréchet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids",
    "authors": [
      "Yuting Cai",
      "Shaohuai Liu",
      "Chao Tian",
      "Le Xie"
    ],
    "abstract": "Generative artificial intelligence (AI) models in smart grids have advanced\nsignificantly in recent years due to their ability to generate large amounts of\nsynthetic data, which would otherwise be difficult to obtain in the real world\ndue to confidentiality constraints. A key challenge in utilizing such synthetic\ndata is how to assess the data quality produced from such generative models.\nTraditional Euclidean distance-based metrics only reflect pair-wise relations\nbetween two individual samples, and could fail in evaluating quality\ndifferences between groups of synthetic datasets. In this work, we propose a\nnovel metric based on the Fr\\'{e}chet Distance (FD) estimated between two\ndatasets in a learned feature space. The proposed method evaluates the quality\nof generation from a distributional perspective. Empirical results demonstrate\nthe superiority of the proposed metric across timescales and models, enhancing\nthe reliability of data-driven decision-making in smart grid operations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08082v1",
    "published_date": "2025-05-12 21:32:23 UTC",
    "updated_date": "2025-05-12 21:32:23 UTC"
  },
  {
    "arxiv_id": "2505.08080v1",
    "title": "Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders",
    "authors": [
      "Dong Shu",
      "Xuansheng Wu",
      "Haiyan Zhao",
      "Mengnan Du",
      "Ninghao Liu"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have recently emerged as powerful tools for\ninterpreting and steering the internal representations of large language models\n(LLMs). However, conventional approaches to analyzing SAEs typically rely\nsolely on input-side activations, without considering the causal influence\nbetween each latent feature and the model's output. This work is built on two\nkey hypotheses: (1) activated latents do not contribute equally to the\nconstruction of the model's output, and (2) only latents with high causal\ninfluence are effective for model steering. To validate these hypotheses, we\npropose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method\nthat identifies the most influential latents by incorporating output-side\ngradient information.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08080v1",
    "published_date": "2025-05-12 21:29:12 UTC",
    "updated_date": "2025-05-12 21:29:12 UTC"
  },
  {
    "arxiv_id": "2505.08078v1",
    "title": "What Matters for Batch Online Reinforcement Learning in Robotics?",
    "authors": [
      "Perry Dong",
      "Suvir Mirchandani",
      "Dorsa Sadigh",
      "Chelsea Finn"
    ],
    "abstract": "The ability to learn from large batches of autonomously collected data for\npolicy improvement -- a paradigm we refer to as batch online reinforcement\nlearning -- holds the promise of enabling truly scalable robot learning by\nsignificantly reducing the need for human effort of data collection while\ngetting benefits from self-improvement. Yet, despite the promise of this\nparadigm, it remains challenging to achieve due to algorithms not being able to\nlearn effectively from the autonomous data. For example, prior works have\napplied imitation learning and filtered imitation learning methods to the batch\nonline RL problem, but these algorithms often fail to efficiently improve from\nthe autonomously collected data or converge quickly to a suboptimal point. This\nraises the question of what matters for effective batch online RL in robotics.\nMotivated by this question, we perform a systematic empirical study of three\naxes -- (i) algorithm class, (ii) policy extraction methods, and (iii) policy\nexpressivity -- and analyze how these axes affect performance and scaling with\nthe amount of autonomous data. Through our analysis, we make several\nobservations. First, we observe that the use of Q-functions to guide batch\nonline RL significantly improves performance over imitation-based methods.\nBuilding on this, we show that an implicit method of policy extraction -- via\nchoosing the best action in the distribution of the policy -- is necessary over\ntraditional policy extraction methods from offline RL. Next, we show that an\nexpressive policy class is preferred over less expressive policy classes. Based\non this analysis, we propose a general recipe for effective batch online RL. We\nthen show a simple addition to the recipe of using temporally-correlated noise\nto obtain more diversity results in further performance gains. Our recipe\nobtains significantly better performance and scaling compared to prior methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08078v1",
    "published_date": "2025-05-12 21:24:22 UTC",
    "updated_date": "2025-05-12 21:24:22 UTC"
  },
  {
    "arxiv_id": "2505.08073v1",
    "title": "Explainable Reinforcement Learning Agents Using World Models",
    "authors": [
      "Madhuri Singh",
      "Amal Alabdulkarim",
      "Gennie Mansi",
      "Mark O. Riedl"
    ],
    "abstract": "Explainable AI (XAI) systems have been proposed to help people understand how\nAI systems produce outputs and behaviors. Explainable Reinforcement Learning\n(XRL) has an added complexity due to the temporal nature of sequential\ndecision-making. Further, non-AI experts do not necessarily have the ability to\nalter an agent or its policy. We introduce a technique for using World Models\nto generate explanations for Model-Based Deep RL agents. World Models predict\nhow the world will change when actions are performed, allowing for the\ngeneration of counterfactual trajectories. However, identifying what a user\nwanted the agent to do is not enough to understand why the agent did something\nelse. We augment Model-Based RL agents with a Reverse World Model, which\npredicts what the state of the world should have been for the agent to prefer a\ngiven counterfactual action. We show that explanations that show users what the\nworld should have been like significantly increase their understanding of the\nagent policy. We hypothesize that our explanations can help users learn how to\ncontrol the agents execution through by manipulating the environment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The paper content spans 7 pages, followed by a page of references. It\n  contains 7 figures and 2 small tables",
    "pdf_url": "http://arxiv.org/pdf/2505.08073v1",
    "published_date": "2025-05-12 21:18:31 UTC",
    "updated_date": "2025-05-12 21:18:31 UTC"
  },
  {
    "arxiv_id": "2505.08823v1",
    "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits",
    "authors": [
      "Cody Steinmetz",
      "Gavin Childress",
      "Aaron Herbst",
      "Gavin Jones",
      "Jasdeep Singh",
      "Eli Vang",
      "Keagan Weinstock"
    ],
    "abstract": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08823v1",
    "published_date": "2025-05-12 21:14:29 UTC",
    "updated_date": "2025-05-12 21:14:29 UTC"
  },
  {
    "arxiv_id": "2505.08064v1",
    "title": "Justified Evidence Collection for Argument-based AI Fairness Assurance",
    "authors": [
      "Alpay Sabuncuoglu",
      "Christopher Burr",
      "Carsten Maple"
    ],
    "abstract": "It is well recognised that ensuring fair AI systems is a complex\nsociotechnical challenge, which requires careful deliberation and continuous\noversight across all stages of a system's lifecycle, from defining requirements\nto model deployment and deprovisioning. Dynamic argument-based assurance cases,\nwhich present structured arguments supported by evidence, have emerged as a\nsystematic approach to evaluating and mitigating safety risks and hazards in\nAI-enabled system development and have also been extended to deal with broader\nnormative goals such as fairness and explainability. This paper introduces a\nsystems-engineering-driven framework, supported by software tooling, to\noperationalise a dynamic approach to argument-based assurance in two stages. In\nthe first stage, during the requirements planning phase, a multi-disciplinary\nand multi-stakeholder team define goals and claims to be established (and\nevidenced) by conducting a comprehensive fairness governance process. In the\nsecond stage, a continuous monitoring interface gathers evidence from existing\nartefacts (e.g. metrics from automated tests), such as model, data, and use\ncase documentation, to support these arguments dynamically. The framework's\neffectiveness is demonstrated through an illustrative case study in finance,\nwith a focus on supporting fairness-related arguments.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "The paper is accepted for ACM Conference on Fairness, Accountability,\n  and Transparency (ACM FAccT '25)",
    "pdf_url": "http://arxiv.org/pdf/2505.08064v1",
    "published_date": "2025-05-12 21:05:33 UTC",
    "updated_date": "2025-05-12 21:05:33 UTC"
  },
  {
    "arxiv_id": "2505.08054v1",
    "title": "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning",
    "authors": [
      "Zhehao Zhang",
      "Weijie Xu",
      "Fanyou Wu",
      "Chandan K. Reddy"
    ],
    "abstract": "Safety alignment approaches in large language models (LLMs) often lead to the\nover-refusal of benign queries, significantly diminishing their utility in\nsensitive scenarios. To address this challenge, we introduce FalseReject, a\ncomprehensive resource containing 16k seemingly toxic queries accompanied by\nstructured responses across 44 safety-related categories. We propose a\ngraph-informed adversarial multi-agent interaction framework to generate\ndiverse and complex prompts, while structuring responses with explicit\nreasoning to aid models in accurately distinguishing safe from unsafe contexts.\nFalseReject includes training datasets tailored for both standard\ninstruction-tuned models and reasoning-oriented models, as well as a\nhuman-annotated benchmark test set. Our extensive benchmarking on 29\nstate-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges.\nEmpirical results demonstrate that supervised finetuning with FalseReject\nsubstantially reduces unnecessary refusals without compromising overall safety\nor general language capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08054v1",
    "published_date": "2025-05-12 20:45:25 UTC",
    "updated_date": "2025-05-12 20:45:25 UTC"
  },
  {
    "arxiv_id": "2505.08052v1",
    "title": "NAZM: Network Analysis of Zonal Metrics in Persian Poetic Tradition",
    "authors": [
      "Kourosh Shahnazari",
      "Seyed Moein Ayyoubzadeh"
    ],
    "abstract": "This study formalizes a computational model to simulate classical Persian\npoets' dynamics of influence through constructing a multi-dimensional\nsimilarity network. Using a rigorously curated dataset based on Ganjoor's\ncorpus, we draw upon semantic, lexical, stylistic, thematic, and metrical\nfeatures to demarcate each poet's corpus. Each is contained within weighted\nsimilarity matrices, which are then appended to generate an aggregate graph\nshowing poet-to-poet influence. Further network investigation is carried out to\nidentify key poets, style hubs, and bridging poets by calculating degree,\ncloseness, betweenness, eigenvector, and Katz centrality measures. Further, for\ntypological insight, we use the Louvain community detection algorithm to\ndemarcate clusters of poets sharing both style and theme coherence, which\ncorrespond closely to acknowledged schools of literature like Sabk-e Hindi,\nSabk-e Khorasani, and the Bazgasht-e Adabi phenomenon. Our findings provide a\nnew data-driven view of Persian literature distinguished between canonical\nsignificance and interextual influence, thus highlighting relatively\nlesser-known figures who hold great structural significance. Combining\ncomputational linguistics with literary study, this paper produces an\ninterpretable and scalable model for poetic tradition, enabling retrospective\nreflection as well as forward-looking research within digital humanities.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08052v1",
    "published_date": "2025-05-12 20:39:53 UTC",
    "updated_date": "2025-05-12 20:39:53 UTC"
  },
  {
    "arxiv_id": "2505.08049v1",
    "title": "Bias or Optimality? Disentangling Bayesian Inference and Learning Biases in Human Decision-Making",
    "authors": [
      "Prakhar Godara"
    ],
    "abstract": "Recent studies claim that human behavior in a two-armed Bernoulli bandit\n(TABB) task is described by positivity and confirmation biases, implying that\nhumans do not integrate new information objectively. However, we find that even\nif the agent updates its belief via objective Bayesian inference, fitting the\nstandard Q-learning model with asymmetric learning rates still recovers both\nbiases. Bayesian inference cast as an effective Q-learning algorithm has\nsymmetric, though decreasing, learning rates. We explain this by analyzing the\nstochastic dynamics of these learning systems using master equations. We find\nthat both confirmation bias and unbiased but decreasing learning rates yield\nthe same behavioral signatures. Finally, we propose experimental protocols to\ndisentangle true cognitive biases from artifacts of decreasing learning rates.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08049v1",
    "published_date": "2025-05-12 20:36:43 UTC",
    "updated_date": "2025-05-12 20:36:43 UTC"
  },
  {
    "arxiv_id": "2505.08821v1",
    "title": "A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction",
    "authors": [
      "Meryem Altin Karagoz",
      "Marc D. Breton",
      "Anas El Fathi"
    ],
    "abstract": "Accurate blood glucose prediction can enable novel interventions for type 1\ndiabetes treatment, including personalized insulin and dietary adjustments.\nAlthough recent advances in transformer-based architectures have demonstrated\nthe power of attention mechanisms in complex multivariate time series\nprediction, their potential for blood glucose (BG) prediction remains\nunderexplored. We present a comparative analysis of transformer models for\nmulti-horizon BG prediction, examining forecasts up to 4 hours and input\nhistory up to 1 week. The publicly available DCLP3 dataset (n=112) was split\n(80%-10%-10%) for training, validation, and testing, and the OhioT1DM dataset\n(n=12) served as an external test set. We trained networks with point-wise,\npatch-wise, series-wise, and hybrid embeddings, using CGM, insulin, and meal\ndata. For short-term blood glucose prediction, Crossformer, a patch-wise\ntransformer architecture, achieved a superior 30-minute prediction of RMSE\n(15.6 mg / dL on OhioT1DM). For longer-term predictions (1h, 2h, and 4h),\nPatchTST, another path-wise transformer, prevailed with the lowest RMSE (24.6\nmg/dL, 36.1 mg/dL, and 46.5 mg/dL on OhioT1DM). In general, models that used\ntokenization through patches demonstrated improved accuracy with larger input\nsizes, with the best results obtained with a one-week history. These findings\nhighlight the promise of transformer-based architectures for BG prediction by\ncapturing and leveraging seasonal patterns in multivariate time-series data to\nimprove accuracy.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "q-bio.QM",
    "comment": "7 pages, 2 figures, 1 table, 1st IFAC Workshop on Engineering\n  Diabetes Technologies (EDT 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.08821v1",
    "published_date": "2025-05-12 20:22:44 UTC",
    "updated_date": "2025-05-12 20:22:44 UTC"
  },
  {
    "arxiv_id": "2505.08032v1",
    "title": "Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience",
    "authors": [
      "Seyed Bagher Hashemi Natanzi",
      "Zhicong Zhu",
      "Bo Tang"
    ],
    "abstract": "Adaptive beam switching in 6G networks is challenged by high frequencies,\nmobility, and blockage. We propose an Online Learning framework using Deep\nReinforcement Learning (DRL) with an enhanced state representation (velocity\nand blockage history), a GRU architecture, and prioritized experience replay\nfor real-time beam optimization. Validated via Nvidia Sionna under\ntime-correlated blockage, our approach significantly enhances resilience in\nSNR, throughput, and accuracy compared to a conventional heuristic.\nFurthermore, the enhanced DRL agent outperforms a reactive Multi-Armed Bandit\n(MAB) baseline by leveraging temporal dependencies, achieving lower performance\nvariability. This demonstrates the benefits of memory and prioritized learning\nfor robust 6G beam management, while confirming MAB as a strong baseline.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08032v1",
    "published_date": "2025-05-12 19:59:05 UTC",
    "updated_date": "2025-05-12 19:59:05 UTC"
  },
  {
    "arxiv_id": "2505.08025v1",
    "title": "PRISM: Complete Online Decentralized Multi-Agent Pathfinding with Rapid Information Sharing using Motion Constraints",
    "authors": [
      "Hannah Lee",
      "Zachary Serlin",
      "James Motes",
      "Brendan Long",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "abstract": "We introduce PRISM (Pathfinding with Rapid Information Sharing using Motion\nConstraints), a decentralized algorithm designed to address the multi-task\nmulti-agent pathfinding (MT-MAPF) problem. PRISM enables large teams of agents\nto concurrently plan safe and efficient paths for multiple tasks while avoiding\ncollisions. It employs a rapid communication strategy that uses information\npackets to exchange motion constraint information, enhancing cooperative\npathfinding and situational awareness, even in scenarios without direct\ncommunication. We prove that PRISM resolves and avoids all deadlock scenarios\nwhen possible, a critical challenge in decentralized pathfinding. Empirically,\nwe evaluate PRISM across five environments and 25 random scenarios,\nbenchmarking it against the centralized Conflict-Based Search (CBS) and the\ndecentralized Token Passing with Task Swaps (TPTS) algorithms. PRISM\ndemonstrates scalability and solution quality, supporting 3.4 times more agents\nthan CBS and handling up to 2.5 times more tasks in narrow passage environments\nthan TPTS. Additionally, PRISM matches CBS in solution quality while achieving\nfaster computation times, even under low-connectivity conditions. Its\ndecentralized design reduces the computational burden on individual agents,\nmaking it scalable for large environments. These results confirm PRISM's\nrobustness, scalability, and effectiveness in complex and dynamic pathfinding\nscenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "38 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08025v1",
    "published_date": "2025-05-12 19:48:32 UTC",
    "updated_date": "2025-05-12 19:48:32 UTC"
  },
  {
    "arxiv_id": "2505.08021v1",
    "title": "The Correspondence Between Bounded Graph Neural Networks and Fragments of First-Order Logic",
    "authors": [
      "Bernardo Cuenca Grau",
      "Przemysław A. Wałęga"
    ],
    "abstract": "Graph Neural Networks (GNNs) address two key challenges in applying deep\nlearning to graph-structured data: they handle varying size input graphs and\nensure invariance under graph isomorphism. While GNNs have demonstrated broad\napplicability, understanding their expressive power remains an important\nquestion. In this paper, we show that bounded GNN architectures correspond to\nspecific fragments of first-order logic (FO), including modal logic (ML),\ngraded modal logic (GML), modal logic with the universal modality (ML(A)), the\ntwo-variable fragment (FO2) and its extension with counting quantifiers (C2).\nTo establish these results, we apply methods and tools from finite model theory\nof first-order and modal logics to the domain of graph representation learning.\nThis provides a unifying framework for understanding the logical expressiveness\nof GNNs within FO.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.08021v1",
    "published_date": "2025-05-12 19:45:45 UTC",
    "updated_date": "2025-05-12 19:45:45 UTC"
  },
  {
    "arxiv_id": "2505.08004v1",
    "title": "Large Language Models and Arabic Content: A Review",
    "authors": [
      "Haneh Rhel",
      "Dmitri Roussinov"
    ],
    "abstract": "Over the past three years, the rapid advancement of Large Language Models\n(LLMs) has had a profound impact on multiple areas of Artificial Intelligence\n(AI), particularly in Natural Language Processing (NLP) across diverse\nlanguages, including Arabic. Although Arabic is considered one of the most\nwidely spoken languages across 27 countries in the Arabic world and used as a\nsecond language in some other non-Arabic countries as well, there is still a\nscarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face\nvarious challenges due to the complexities of the Arabic language, including\nits rich morphology, intricate structure, and diverse writing standards, among\nother factors. Researchers have been actively addressing these challenges,\ndemonstrating that pre-trained Large Language Models (LLMs) trained on\nmultilingual corpora achieve significant success in various Arabic NLP tasks.\nThis study provides an overview of using large language models (LLMs) for the\nArabic language, highlighting early pre-trained Arabic Language models across\nvarious NLP applications and their ability to handle diverse Arabic content\ntasks and dialects. It also provides an overview of how techniques like\nfinetuning and prompt engineering can enhance the performance of these models.\nAdditionally, the study summarizes common Arabic benchmarks and datasets while\npresenting our observations on the persistent upward trend in the adoption of\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Original language: English This paper has been submitted to the First\n  International Conference on Artificial Intelligence and Generative AI\n  (FICAILY 2025), and it has been accepted for presentation at FICAILY on\n  9-10/July 2025 and for publication in the Springer Nature. Number of pages:\n  16 Publication status Accepted/In press - 7 Apr 2025\n  https://www.gena-ai-libya2025.com/",
    "pdf_url": "http://arxiv.org/pdf/2505.08004v1",
    "published_date": "2025-05-12 19:09:12 UTC",
    "updated_date": "2025-05-12 19:09:12 UTC"
  },
  {
    "arxiv_id": "2505.08818v1",
    "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare",
    "authors": [
      "Amara Tariq",
      "Rimita Lahiri",
      "Charles Kahn",
      "Imon Banerjee"
    ],
    "abstract": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "15 pages, 2, tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08818v1",
    "published_date": "2025-05-12 18:39:54 UTC",
    "updated_date": "2025-05-12 18:39:54 UTC"
  },
  {
    "arxiv_id": "2505.07985v1",
    "title": "Fair Play for Individuals, Foul Play for Groups? Auditing Anonymization's Impact on ML Fairness",
    "authors": [
      "Héber H. Arcolezi",
      "Mina Alishahi",
      "Adda-Akram Bendoukha",
      "Nesrine Kaaniche"
    ],
    "abstract": "Machine learning (ML) algorithms are heavily based on the availability of\ntraining data, which, depending on the domain, often includes sensitive\ninformation about data providers. This raises critical privacy concerns.\nAnonymization techniques have emerged as a practical solution to address these\nissues by generalizing features or suppressing data to make it more difficult\nto accurately identify individuals. Although recent studies have shown that\nprivacy-enhancing technologies can influence ML predictions across different\nsubgroups, thus affecting fair decision-making, the specific effects of\nanonymization techniques, such as $k$-anonymity, $\\ell$-diversity, and\n$t$-closeness, on ML fairness remain largely unexplored. In this work, we\nsystematically audit the impact of anonymization techniques on ML fairness,\nevaluating both individual and group fairness. Our quantitative study reveals\nthat anonymization can degrade group fairness metrics by up to four orders of\nmagnitude. Conversely, similarity-based individual fairness metrics tend to\nimprove under stronger anonymization, largely as a result of increased input\nhomogeneity. By analyzing varying levels of anonymization across diverse\nprivacy settings and data distributions, this study provides critical insights\ninto the trade-offs between privacy, fairness, and utility, offering actionable\nguidelines for responsible AI development. Our code is publicly available at:\nhttps://github.com/hharcolezi/anonymity-impact-fairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07985v1",
    "published_date": "2025-05-12 18:32:28 UTC",
    "updated_date": "2025-05-12 18:32:28 UTC"
  },
  {
    "arxiv_id": "2505.07973v1",
    "title": "Probabilistic approach to longitudinal response prediction: application to radiomics from brain cancer imaging",
    "authors": [
      "Isabella Cama",
      "Michele Piana",
      "Cristina Campi",
      "Sara Garbarino"
    ],
    "abstract": "Longitudinal imaging analysis tracks disease progression and treatment\nresponse over time, providing dynamic insights into treatment efficacy and\ndisease evolution. Radiomic features extracted from medical imaging can support\nthe study of disease progression and facilitate longitudinal prediction of\nclinical outcomes. This study presents a probabilistic model for longitudinal\nresponse prediction, integrating baseline features with intermediate\nfollow-ups. The probabilistic nature of the model naturally allows to handle\nthe instrinsic uncertainty of the longitudinal prediction of disease\nprogression. We evaluate the proposed model against state-of-the-art disease\nprogression models in both a synthetic scenario and using a brain cancer\ndataset. Results demonstrate that the approach is competitive against existing\nmethods while uniquely accounting for uncertainty and controlling the growth of\nproblem dimensionality, eliminating the need for data from intermediate\nfollow-ups.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "62P10 (Primary), 68T09, 92F05 (Secondary)"
    ],
    "primary_category": "stat.AP",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.07973v1",
    "published_date": "2025-05-12 18:15:24 UTC",
    "updated_date": "2025-05-12 18:15:24 UTC"
  },
  {
    "arxiv_id": "2505.07819v1",
    "title": "H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning",
    "authors": [
      "Yiyang Lu",
      "Yufeng Tian",
      "Zhecheng Yuan",
      "Xianbang Wang",
      "Pu Hua",
      "Zhengrong Xue",
      "Huazhe Xu"
    ],
    "abstract": "Visuomotor policy learning has witnessed substantial progress in robotic\nmanipulation, with recent approaches predominantly relying on generative models\nto model the action distribution. However, these methods often overlook the\ncritical coupling between visual perception and action prediction. In this\nwork, we introduce $\\textbf{Triply-Hierarchical Diffusion\nPolicy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework\nthat explicitly incorporates hierarchical structures to strengthen the\nintegration between visual features and action generation. H$^{3}$DP contains\n$\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes\nRGB-D observations based on depth information; (2) multi-scale visual\nrepresentations that encode semantic features at varying levels of granularity;\nand (3) a hierarchically conditioned diffusion process that aligns the\ngeneration of coarse-to-fine actions with corresponding visual features.\nExtensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$\naverage relative improvement over baselines across $\\mathbf{44}$ simulation\ntasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual\nreal-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07819v1",
    "published_date": "2025-05-12 17:59:43 UTC",
    "updated_date": "2025-05-12 17:59:43 UTC"
  },
  {
    "arxiv_id": "2505.07816v2",
    "title": "Graph neural networks and MSO",
    "authors": [
      "Veeti Ahvonen",
      "Damian Heiman",
      "Antti Kuusisto"
    ],
    "abstract": "We give an alternative proof for the existing result that recurrent graph\nneural networks working with reals have the same expressive power in\nrestriction to monadic second-order logic MSO as the graded modal substitution\ncalculus. The proof is based on constructing distributed automata that capture\nall MSO-definable node properties over trees. We also consider some variants of\nthe acceptance conditions.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "F.4.1; F.1.1; I.2.0"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07816v2",
    "published_date": "2025-05-12 17:59:22 UTC",
    "updated_date": "2025-05-15 13:32:24 UTC"
  },
  {
    "arxiv_id": "2505.07813v1",
    "title": "DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies",
    "authors": [
      "Tony Tao",
      "Mohan Kumar Srirama",
      "Jason Jingzhou Liu",
      "Kenneth Shaw",
      "Deepak Pathak"
    ],
    "abstract": "Large-scale, diverse robot datasets have emerged as a promising path toward\nenabling dexterous manipulation policies to generalize to novel environments,\nbut acquiring such datasets presents many challenges. While teleoperation\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\nwhat if people could use their own hands, just as they do in everyday life, to\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\ncollect hours of interactions across a multitude of environments and objects.\nTo record this data, we create DexWild-System, a low-cost, mobile, and\neasy-to-use device. The DexWild learning framework co-trains on both human and\nrobot demonstrations, leading to improved performance compared to training on\neach dataset individually. This combination results in robust robot policies\ncapable of generalizing to novel environments, tasks, and embodiments with\nminimal additional robot-specific data. Experimental results demonstrate that\nDexWild significantly improves performance, achieving a 68.5% success rate in\nunseen environments-nearly four times higher than policies trained with robot\ndata only-and offering 5.8x better cross-embodiment generalization. Video\nresults, codebases, and instructions at https://dexwild.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "In RSS 2025. Website at https://dexwild.github.io",
    "pdf_url": "http://arxiv.org/pdf/2505.07813v1",
    "published_date": "2025-05-12 17:59:05 UTC",
    "updated_date": "2025-05-12 17:59:05 UTC"
  },
  {
    "arxiv_id": "2505.07809v1",
    "title": "A Comparative Analysis of Static Word Embeddings for Hungarian",
    "authors": [
      "Máté Gedeon"
    ],
    "abstract": "This paper presents a comprehensive analysis of various static word\nembeddings for Hungarian, including traditional models such as Word2Vec,\nFastText, as well as static embeddings derived from BERT-based models using\ndifferent extraction methods. We evaluate these embeddings on both intrinsic\nand extrinsic tasks to provide a holistic view of their performance. For\nintrinsic evaluation, we employ a word analogy task, which assesses the\nembeddings ability to capture semantic and syntactic relationships. Our results\nindicate that traditional static embeddings, particularly FastText, excel in\nthis task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among\nthe BERT-based models, the X2Static method for extracting static embeddings\ndemonstrates superior performance compared to decontextualized and aggregate\nmethods, approaching the effectiveness of traditional static embeddings. For\nextrinsic evaluation, we utilize a bidirectional LSTM model to perform Named\nEntity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results\nreveal that embeddings derived from dynamic models, especially those extracted\nusing the X2Static method, outperform purely static embeddings. Notably, ELMo\nembeddings achieve the highest accuracy in both NER and POS tagging tasks,\nunderscoring the benefits of contextualized representations even when used in a\nstatic form. Our findings highlight the continued relevance of static word\nembeddings in NLP applications and the potential of advanced extraction methods\nto enhance the utility of BERT-based models. This piece of research contributes\nto the understanding of embedding performance in the Hungarian language and\nprovides valuable insights for future developments in the field. The training\nscripts, evaluation codes, restricted vocabulary, and extracted embeddings will\nbe made publicly available to support further research and reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07809v1",
    "published_date": "2025-05-12 17:57:11 UTC",
    "updated_date": "2025-05-12 17:57:11 UTC"
  },
  {
    "arxiv_id": "2505.07802v1",
    "title": "Improving Trajectory Stitching with Flow Models",
    "authors": [
      "Reece O'Mahoney",
      "Wanming Yu",
      "Ioannis Havoutis"
    ],
    "abstract": "Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07802v1",
    "published_date": "2025-05-12 17:50:10 UTC",
    "updated_date": "2025-05-12 17:50:10 UTC"
  },
  {
    "arxiv_id": "2505.07796v1",
    "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
    "authors": [
      "Xingjin Wang",
      "Howe Tissue",
      "Lu Wang",
      "Linjing Li",
      "Daniel Dajun Zeng"
    ],
    "abstract": "Continual Pre-Training (CPT) has become a popular and effective method to\napply strong foundation models to specific downstream tasks. In this work, we\nexplore the learning dynamics throughout the CPT process for large language\nmodels. We specifically focus on how general and downstream domain performance\nevolves at each training step, with domain performance measured via validation\nlosses. We have observed that the CPT loss curve fundamentally characterizes\nthe transition from one curve to another hidden curve, and could be described\nby decoupling the effects of distribution shift and learning rate annealing. We\nderive a CPT scaling law that combines the two factors, enabling the prediction\nof loss at any (continual) training steps and across learning rate schedules\n(LRS) in CPT. Our formulation presents a comprehensive understanding of several\ncritical factors in CPT, including loss potential, peak learning rate, training\nsteps, replay ratio, etc. Moreover, our approach can be adapted to customize\ntraining hyper-parameters to different CPT goals such as balancing general and\ndomain-specific performance. Extensive experiments demonstrate that our scaling\nlaw holds across various CPT datasets and training hyper-parameters.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML2025 (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2505.07796v1",
    "published_date": "2025-05-12 17:47:32 UTC",
    "updated_date": "2025-05-12 17:47:32 UTC"
  },
  {
    "arxiv_id": "2505.07793v1",
    "title": "Overflow Prevention Enhances Long-Context Recurrent LLMs",
    "authors": [
      "Assaf Ben-Kish",
      "Itamar Zimerman",
      "M. Jehanzeb Mirza",
      "James Glass",
      "Leonid Karlinsky",
      "Raja Giryes"
    ],
    "abstract": "A recent trend in LLMs is developing recurrent sub-quadratic models that\nimprove long-context processing efficiency. We investigate leading large\nlong-context models, focusing on how their fixed-size recurrent memory affects\ntheir performance. Our experiments reveal that, even when these models are\ntrained for extended contexts, their use of long contexts remains\nunderutilized. Specifically, we demonstrate that a chunk-based inference\nprocedure, which identifies and processes only the most relevant portion of the\ninput can mitigate recurrent memory failures and be effective for many\nlong-context tasks: On LongBench, our method improves the overall performance\nof Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%,\nRecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this\nsimple approach also leads to state-of-the-art results in the challenging\nLongBench v2 benchmark, showing competitive performance with equivalent size\nTransformers. Furthermore, our findings raise questions about whether recurrent\nmodels genuinely exploit long-range dependencies, as our single-chunk strategy\ndelivers stronger performance - even in tasks that presumably require\ncross-context relations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07793v1",
    "published_date": "2025-05-12 17:45:05 UTC",
    "updated_date": "2025-05-12 17:45:05 UTC"
  },
  {
    "arxiv_id": "2505.07775v1",
    "title": "Must Read: A Systematic Survey of Computational Persuasion",
    "authors": [
      "Nimet Beyza Bozdag",
      "Shuhaib Mehri",
      "Xiaocheng Yang",
      "Hyeonjeong Ha",
      "Zirui Cheng",
      "Esin Durmus",
      "Jiaxuan You",
      "Heng Ji",
      "Gokhan Tur",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "Persuasion is a fundamental aspect of communication, influencing\ndecision-making across diverse contexts, from everyday conversations to\nhigh-stakes scenarios such as politics, marketing, and law. The rise of\nconversational AI systems has significantly expanded the scope of persuasion,\nintroducing both opportunities and risks. AI-driven persuasion can be leveraged\nfor beneficial applications, but also poses threats through manipulation and\nunethical influence. Moreover, AI systems are not only persuaders, but also\nsusceptible to persuasion, making them vulnerable to adversarial attacks and\nbias reinforcement. Despite rapid advancements in AI-generated persuasive\ncontent, our understanding of what makes persuasion effective remains limited\ndue to its inherently subjective and context-dependent nature. In this survey,\nwe provide a comprehensive overview of computational persuasion, structured\naround three key perspectives: (1) AI as a Persuader, which explores\nAI-generated persuasive content and its applications; (2) AI as a Persuadee,\nwhich examines AI's susceptibility to influence and manipulation; and (3) AI as\na Persuasion Judge, which analyzes AI's role in evaluating persuasive\nstrategies, detecting manipulation, and ensuring ethical persuasion. We\nintroduce a taxonomy for computational persuasion research and discuss key\nchallenges, including evaluating persuasiveness, mitigating manipulative\npersuasion, and developing responsible AI-driven persuasive systems. Our survey\noutlines future research directions to enhance the safety, fairness, and\neffectiveness of AI-powered persuasion while addressing the risks posed by\nincreasingly capable language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07775v1",
    "published_date": "2025-05-12 17:26:31 UTC",
    "updated_date": "2025-05-12 17:26:31 UTC"
  },
  {
    "arxiv_id": "2505.07773v2",
    "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving",
    "authors": [
      "Xinji Mai",
      "Haotian Xu",
      "Xing W",
      "Weinong Wang",
      "Yingying Zhang",
      "Wenqiang Zhang"
    ],
    "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks\nrequiring precise, verifiable computation. While Reinforcement Learning (RL)\nfrom outcome-based rewards enhances text-based reasoning, understanding how\nagents autonomously learn to leverage external tools like code execution\nremains crucial. We investigate RL from outcome-based rewards for\nTool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously\ngenerate and execute Python code for mathematical problems without supervised\ntool-use examples. Our central contribution is we demonstrate that as RL\ntraining progresses, key metrics scale predictably. Specifically, we observe\nstrong positive correlations where increased training steps lead to increases\nin the spontaneous code execution frequency, the average response length, and,\ncritically, the final task accuracy. This suggests a quantifiable relationship\nbetween computational effort invested in training and the emergence of\neffective, tool-augmented reasoning strategies. We implement a robust framework\nfeaturing a decoupled code execution environment and validate our findings\nacross standard RL algorithms and frameworks. Experiments show ZeroTIR\nsignificantly surpasses non-tool ZeroRL baselines on challenging math\nbenchmarks. Our findings provide a foundational understanding of how autonomous\ntool use is acquired and scales within Agent RL, offering a reproducible\nbenchmark for future studies. Code is released at\n\\href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\\_async\\_pipline}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07773v2",
    "published_date": "2025-05-12 17:23:34 UTC",
    "updated_date": "2025-05-14 04:15:06 UTC"
  },
  {
    "arxiv_id": "2505.07768v1",
    "title": "Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding",
    "authors": [
      "Yifeng Di",
      "Tianyi Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capability in\ncode generation. However, LLM-generated code is still plagued with a wide range\nof functional errors, especially for complex programming tasks that LLMs have\nnot seen before. Recent studies have shown that developers often struggle with\ninspecting and fixing incorrect code generated by LLMs, diminishing their\nproductivity and trust in LLM-based code generation. Inspired by the mutual\ngrounding theory in communication, we propose an interactive approach that\nleverages code comments as a medium for developers and LLMs to establish a\nshared understanding. Our approach facilitates iterative grounding by\ninterleaving code generation, inline comment generation, and contextualized\nuser feedback through editable comments to align generated code with developer\nintent. We evaluated our approach on two popular benchmarks and demonstrated\nthat our approach significantly improved multiple state-of-the-art LLMs, e.g.,\n17.1% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we\nconducted a user study with 12 participants in comparison to two baselines: (1)\ninteracting with GitHub Copilot, and (2) interacting with a multi-step code\ngeneration paradigm called Multi-Turn Program Synthesis. Participants completed\nthe given programming tasks 16.7% faster and with 10.5% improvement in task\nsuccess rate when using our approach. Both results show that interactively\nrefining code comments enables the collaborative establishment of mutual\ngrounding, leading to more accurate code generation and higher developer\nconfidence.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07768v1",
    "published_date": "2025-05-12 17:20:30 UTC",
    "updated_date": "2025-05-12 17:20:30 UTC"
  },
  {
    "arxiv_id": "2505.07759v1",
    "title": "\"I Apologize For Not Understanding Your Policy\": Exploring the Specification and Evaluation of User-Managed Access Control Policies by AI Virtual Assistants",
    "authors": [
      "Jennifer Mondragon",
      "Carlos Rubio-Medrano",
      "Gael Cruz",
      "Dvijesh Shastri"
    ],
    "abstract": "The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants\n(VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek\nhas turned them into convenient interfaces for managing emerging technologies\nsuch as Smart Homes, Smart Cars, Electronic Health Records, by means of\nexplicit commands,e.g., prompts, which can be even launched via voice, thus\nproviding a very convenient interface for end-users. However, the proper\nspecification and evaluation of User-Managed Access Control Policies (U-MAPs),\nthe rules issued and managed by end-users to govern access to sensitive data\nand device functionality - within these VAs presents significant challenges,\nsince such a process is crucial for preventing security vulnerabilities and\nprivacy leaks without impacting user experience. This study provides an initial\nexploratory investigation on whether current publicly-available VAs can manage\nU-MAPs effectively across differing scenarios. By conducting unstructured to\nstructured tests, we evaluated the comprehension of such VAs, revealing a lack\nof understanding in varying U-MAP approaches. Our research not only identifies\nkey limitations, but offers valuable insights into how VAs can be further\nimproved to manage complex authorization rules and adapt to dynamic changes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07759v1",
    "published_date": "2025-05-12 17:03:52 UTC",
    "updated_date": "2025-05-12 17:03:52 UTC"
  },
  {
    "arxiv_id": "2505.07757v1",
    "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture",
    "authors": [
      "Rintaro Ando"
    ],
    "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement\n(EG-MRSI) framework, a novel architecture that integrates introspective\nmetacognition, emotion-based intrinsic motivation, and recursive\nself-modification into a unified theoretical system. The framework is\nexplicitly capable of overwriting its own learning algorithm under formally\nbounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation,\nEG-MRSI introduces a differentiable intrinsic reward function driven by\nconfidence, error, novelty, and cumulative success. This signal regulates both\na metacognitive mapping and a self-modification operator constrained by\nprovable safety mechanisms. We formally define the initial agent configuration,\nemotion-gradient dynamics, and RSI trigger conditions, and derive a\nreinforcement-compatible optimization objective that guides the agent's\ndevelopment trajectory. Meaning Density and Meaning Conversion Efficiency are\nintroduced as quantifiable metrics of semantic learning, closing the gap\nbetween internal structure and predictive informativeness. This Part I paper\nestablishes the single-agent theoretical foundations of EG-MRSI. Future parts\nwill extend this framework to include safety certificates and rollback\nprotocols (Part II), collective intelligence mechanisms (Part III), and\nfeasibility constraints including thermodynamic and computational limits (Part\nIV). Together, the EG-MRSI series provides a rigorous, extensible foundation\nfor open-ended and safe AGI.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "F.1.2; I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 3 figures. Part I of a four-part series (Parts II-IV\n  forthcoming)",
    "pdf_url": "http://arxiv.org/pdf/2505.07757v1",
    "published_date": "2025-05-12 17:02:47 UTC",
    "updated_date": "2025-05-12 17:02:47 UTC"
  },
  {
    "arxiv_id": "2505.07755v1",
    "title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems",
    "authors": [
      "Tomasz Szydlo",
      "Viacheslaw Horbanow",
      "Dev Nandan Jha",
      "Shashikant Ilager",
      "Aleksander Slominski",
      "Rajiv Ranjan"
    ],
    "abstract": "Edge computing has emerged as a pivotal technology, offering significant\nadvantages such as low latency, enhanced data security, and reduced reliance on\ncentralized cloud infrastructure. These benefits are crucial for applications\nrequiring real-time data processing or strict security measures. Despite these\nadvantages, edge devices operating within edge clusters are often\nunderutilized. This inefficiency is mainly due to the absence of a holistic\nperformance profiling mechanism which can help dynamically adjust the desired\nsystem configuration for a given workload. Since edge computing environments\ninvolve a complex interplay between CPU frequency, power consumption, and\napplication performance, a deeper understanding of these correlations is\nessential. By uncovering these relationships, it becomes possible to make\ninformed decisions that enhance both computational efficiency and energy\nsavings. To address this gap, this paper evaluates the power consumption and\nperformance characteristics of a single processing node within an edge cluster\nusing a synthetic microbenchmark by varying the workload size and CPU\nfrequency. The results show how an optimal measure can lead to optimized usage\nof edge resources, given both performance and power consumption.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07755v1",
    "published_date": "2025-05-12 17:02:02 UTC",
    "updated_date": "2025-05-12 17:02:02 UTC"
  },
  {
    "arxiv_id": "2505.07921v2",
    "title": "Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning",
    "authors": [
      "Qi Xu",
      "Junyang Zhu",
      "Dongdong Zhou",
      "Hao Chen",
      "Yang Liu",
      "Jiangrong Shen",
      "Qiang Zhang"
    ],
    "abstract": "Deep neural networks (DNNs) excel in computer vision tasks, especially,\nfew-shot learning (FSL), which is increasingly important for generalizing from\nlimited examples. However, DNNs are computationally expensive with scalability\nissues in real world. Spiking Neural Networks (SNNs), with their event-driven\nnature and low energy consumption, are particularly efficient in processing\nsparse and dynamic data, though they still encounter difficulties in capturing\ncomplex spatiotemporal features and performing accurate cross-class\ncomparisons. To further enhance the performance and efficiency of SNNs in\nfew-shot learning, we propose a few-shot learning framework based on SNNs,\nwhich combines a self-feature extractor module and a cross-feature contrastive\nmodule to refine feature representation and reduce power consumption. We apply\nthe combination of temporal efficient training loss and InfoNCE loss to\noptimize the temporal dynamics of spike trains and enhance the discriminative\npower. Experimental results show that the proposed FSL-SNN significantly\nimproves the classification performance on the neuromorphic dataset N-Omniglot,\nand also achieves competitive performance to ANNs on static datasets such as\nCUB and miniImageNet with low power consumption.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07921v2",
    "published_date": "2025-05-12 16:51:08 UTC",
    "updated_date": "2025-05-15 02:56:21 UTC"
  },
  {
    "arxiv_id": "2505.07728v1",
    "title": "Guiding Data Collection via Factored Scaling Curves",
    "authors": [
      "Lihan Zha",
      "Apurva Badithela",
      "Michael Zhang",
      "Justin Lidard",
      "Jeremy Bao",
      "Emily Zhou",
      "David Snyder",
      "Allen Z. Ren",
      "Dhruv Shah",
      "Anirudha Majumdar"
    ],
    "abstract": "Generalist imitation learning policies trained on large datasets show great\npromise for solving diverse manipulation tasks. However, to ensure\ngeneralization to different conditions, policies need to be trained with data\ncollected across a large set of environmental factor variations (e.g., camera\npose, table height, distractors) $-$ a prohibitively expensive undertaking, if\ndone exhaustively. We introduce a principled method for deciding what data to\ncollect and how much to collect for each factor by constructing factored\nscaling curves (FSC), which quantify how policy performance varies as data\nscales along individual or paired factors. These curves enable targeted data\nacquisition for the most influential factor combinations within a given budget.\nWe evaluate the proposed method through extensive simulated and real-world\nexperiments, across both training-from-scratch and fine-tuning settings, and\nshow that it boosts success rates in real-world tasks in new environments by up\nto 26% over existing data-collection strategies. We further demonstrate how\nfactored scaling curves can effectively guide data collection using an offline\nmetric, without requiring real-world evaluation at scale.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://factored-data-scaling.github.io",
    "pdf_url": "http://arxiv.org/pdf/2505.07728v1",
    "published_date": "2025-05-12 16:36:35 UTC",
    "updated_date": "2025-05-12 16:36:35 UTC"
  },
  {
    "arxiv_id": "2505.07715v1",
    "title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras",
    "authors": [
      "Qi Xu",
      "Jie Deng",
      "Jiangrong Shen",
      "Biwu Chen",
      "Huajin Tang",
      "Gang Pan"
    ],
    "abstract": "Event-based object detection has gained increasing attention due to its\nadvantages such as high temporal resolution, wide dynamic range, and\nasynchronous address-event representation. Leveraging these advantages, Spiking\nNeural Networks (SNNs) have emerged as a promising approach, offering low\nenergy consumption and rich spatiotemporal dynamics. To further enhance the\nperformance of event-based object detection, this study proposes a novel hybrid\nspike vision Transformer (HsVT) model. The HsVT model integrates a spatial\nfeature extraction module to capture local and global features, and a temporal\nfeature extraction module to model time dependencies and long-term patterns in\nevent sequences. This combination enables HsVT to capture spatiotemporal\nfeatures, improving its capability to handle complex event-based object\ndetection tasks. To support research in this area, we developed and publicly\nreleased The Fall Detection Dataset as a benchmark for event-based object\ndetection tasks. This dataset, captured using an event-based camera, ensures\nfacial privacy protection and reduces memory usage due to the event\nrepresentation format. We evaluated the HsVT model on GEN1 and Fall Detection\ndatasets across various model sizes. Experimental results demonstrate that HsVT\nachieves significant performance improvements in event detection with fewer\nparameters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07715v1",
    "published_date": "2025-05-12 16:19:20 UTC",
    "updated_date": "2025-05-12 16:19:20 UTC"
  },
  {
    "arxiv_id": "2505.07711v1",
    "title": "Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations",
    "authors": [
      "Pranav Sinha",
      "Sumit Kumar Jha",
      "Sunny Raj"
    ],
    "abstract": "We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where\nquantum computers are limited by noisy gates, some of which are more\nerror-prone than others and can render the final computation incomprehensible.\nQuantum circuit compilation algorithms attempt to minimize these noisy gates\nwhen mapping quantum algorithms onto quantum hardware but face computational\nchallenges that restrict their application to circuits with no more than 5-6\nqubits, necessitating the need to partition large circuits before the\napplication of noisy quantum gate minimization algorithms. The existing\ngeneration of these algorithms is heuristic in nature and does not account for\ndownstream gate minimization tasks. Large language models (LLMs) have the\npotential to change this and help improve quantum circuit partitions. This\npaper investigates the use of LLMs, such as Llama and Mistral, for partitioning\nquantum circuits by capitalizing on their abilities to understand and generate\ncode, including QASM. Specifically, we teach LLMs to partition circuits using\nthe quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through\nexperimental evaluations, we show that careful fine-tuning of open source LLMs\nenables us to obtain an accuracy of 53.4% for the partition task while\nover-the-shelf LLMs are unable to correctly partition circuits, using standard\n1-shot and few-shot training approaches.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "7 pages, 2 tables and 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.07711v1",
    "published_date": "2025-05-12 16:18:48 UTC",
    "updated_date": "2025-05-12 16:18:48 UTC"
  },
  {
    "arxiv_id": "2505.07701v1",
    "title": "Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications",
    "authors": [
      "Biel Tura Vecino",
      "Adam Gabryś",
      "Daniel Mątwicki",
      "Andrzej Pomirski",
      "Tom Iddon",
      "Marius Cotescu",
      "Jaime Lorenzo-Trueba"
    ],
    "abstract": "Recent works have shown that modelling raw waveform directly from text in an\nend-to-end (E2E) fashion produces more natural-sounding speech than traditional\nneural text-to-speech (TTS) systems based on a cascade or two-stage approach.\nHowever, current E2E state-of-the-art models are computationally complex and\nmemory-consuming, making them unsuitable for real-time offline on-device\napplications in low-resource scenarios. To address this issue, we propose a\nLightweight E2E-TTS (LE2E) model that generates high-quality speech requiring\nminimal computational resources. We evaluate the proposed model on the LJSpeech\ndataset and show that it achieves state-of-the-art performance while being up\nto $90\\%$ smaller in terms of model parameters and $10\\times$ faster in\nreal-time-factor. Furthermore, we demonstrate that the proposed E2E training\nparadigm achieves better quality compared to an equivalent architecture trained\nin a two-stage approach. Our results suggest that LE2E is a promising approach\nfor developing real-time, high quality, low-resource TTS applications for\non-device applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Published as a conference paper at SSW 2023",
    "pdf_url": "http://arxiv.org/pdf/2505.07701v1",
    "published_date": "2025-05-12 16:10:15 UTC",
    "updated_date": "2025-05-12 16:10:15 UTC"
  },
  {
    "arxiv_id": "2505.07920v1",
    "title": "Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions",
    "authors": [
      "Daoze Zhang",
      "Zhijian Bao",
      "Sihang Du",
      "Zhiyi Zhao",
      "Kuangling Zhang",
      "Dezheng Bao",
      "Yang Yang"
    ],
    "abstract": "Peer review is a critical component of scientific progress in the fields like\nAI, but the rapid increase in submission volume has strained the reviewing\nsystem, which inevitably leads to reviewer shortages and declines review\nquality. Besides the growing research popularity, another key factor in this\noverload is the repeated resubmission of substandard manuscripts, largely due\nto the lack of effective tools for authors to self-evaluate their work before\nsubmission. Large Language Models (LLMs) show great promise in assisting both\nauthors and reviewers, and their performance is fundamentally limited by the\nquality of the peer review data. However, existing peer review datasets face\nthree major limitations: (1) limited data diversity, (2) inconsistent and\nlow-quality data due to the use of revised rather than initial submissions, and\n(3) insufficient support for tasks involving rebuttal and reviewer-author\ninteractions. To address these challenges, we introduce the largest\nconsistency-ensured peer review and rebuttal dataset named Re^2, which\ncomprises 19,926 initial submissions, 70,668 review comments, and 53,818\nrebuttals from 24 conferences and 21 workshops on OpenReview. Moreover, the\nrebuttal and discussion stage is framed as a multi-turn conversation paradigm\nto support both traditional static review tasks and dynamic interactive LLM\nassistants, providing more practical guidance for authors to refine their\nmanuscripts and helping alleviate the growing review burden. Our data and code\nare available in https://anonymous.4open.science/r/ReviewBench_anon/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "2 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.07920v1",
    "published_date": "2025-05-12 16:02:52 UTC",
    "updated_date": "2025-05-12 16:02:52 UTC"
  },
  {
    "arxiv_id": "2505.07693v1",
    "title": "Belief Injection for Epistemic Control in Linguistic State Space",
    "authors": [
      "Sebastian Dumbrava"
    ],
    "abstract": "This work introduces belief injection, a proactive epistemic control\nmechanism for artificial agents whose cognitive states are structured as\ndynamic ensembles of linguistic belief fragments. Grounded in the Semantic\nManifold framework, belief injection directly incorporates targeted linguistic\nbeliefs into an agent's internal cognitive state, influencing reasoning and\nalignment proactively rather than reactively. We delineate various injection\nstrategies, such as direct, context-aware, goal-oriented, and reflective\napproaches, and contrast belief injection with related epistemic control\nmechanisms, notably belief filtering. Additionally, this work discusses\npractical applications, implementation considerations, ethical implications,\nand outlines promising directions for future research into cognitive governance\nusing architecturally embedded belief injection.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.07693v1",
    "published_date": "2025-05-12 15:58:56 UTC",
    "updated_date": "2025-05-12 15:58:56 UTC"
  },
  {
    "arxiv_id": "2505.07686v2",
    "title": "S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models",
    "authors": [
      "Muzhi Dai",
      "Chenxu Yang",
      "Qingyi Si"
    ],
    "abstract": "As Test-Time Scaling emerges as an active research focus in the large\nlanguage model community, advanced post-training methods increasingly emphasize\nextending chain-of-thought (CoT) generation length, thereby enhancing reasoning\ncapabilities to approach Deepseek R1-like reasoning models. However, recent\nstudies reveal that reasoning models (even Qwen3) consistently exhibit\nexcessive thought redundancy in CoT generation. This overthinking issue arises\nfrom the inherent limitations of conventional outcome-reward reinforcement\nlearning, which systematically overlooks the regulation of intermediate\nreasoning processes. This paper introduces Serial-Group Decaying-Reward Policy\nOptimization (S-GRPO), a novel reinforcement learning paradigm that enables\nmodels to implicitly evaluate the sufficiency of intermediate reasoning steps,\nthereby facilitating early exit in CoT generation. Unlike GRPO, which samples\nmultiple possible reasoning paths in parallel (parallel group), S-GRPO only\nsamples one reasoning path and serially selects multiple temporal positions\nfrom the path to exit thinking and directly generate answers (serial group).\nFor correct answers within a serial group, rewards gradually decrease based on\nthe exit positions along the reasoning path from front to back. This design\nencourages the model to produce more accurate and concise thoughts, while also\nincentivizing early thinking termination when appropriate. Empirical\nevaluations demonstrate that S-GRPO is compatible with state-of-the-art\nreasoning models, including Qwen3 and Deepseek-distill. Across diverse\nbenchmarks such as GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond,\nS-GRPO achieves a substantial reduction in sequence length (35.4% - 61.1%)\nwhile simultaneously improving accuracy (absolute 0.72% - 6.08%).",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07686v2",
    "published_date": "2025-05-12 15:50:44 UTC",
    "updated_date": "2025-05-17 04:01:57 UTC"
  },
  {
    "arxiv_id": "2505.07683v1",
    "title": "Multimodal Survival Modeling in the Age of Foundation Models",
    "authors": [
      "Steven Song",
      "Morgan Borjigin-Wang",
      "Irene Madejski",
      "Robert L. Grossman"
    ],
    "abstract": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 7 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.07683v1",
    "published_date": "2025-05-12 15:47:21 UTC",
    "updated_date": "2025-05-12 15:47:21 UTC"
  },
  {
    "arxiv_id": "2505.07675v1",
    "title": "Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead $\\mathbf{\\texttt{O}}$ptimization",
    "authors": [
      "Seongjae Kang",
      "Dong Bok Lee",
      "Hyungjoon Jang",
      "Sung Ju Hwang"
    ],
    "abstract": "Vision-language models (VLMs) have achieved remarkable success across diverse\ntasks by leveraging rich textual information with minimal labeled data.\nHowever, deploying such large models remains challenging, particularly in\nresource-constrained environments. Knowledge distillation (KD) offers a\nwell-established solution to this problem; however, recent KD approaches from\nVLMs often involve multi-stage training or additional tuning, increasing\ncomputational overhead and optimization complexity. In this paper, we propose\n$\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n$\\mathbf{\\texttt{O}}$ptimization ($\\mathbf{\\texttt{DHO}}$) -- a simple yet\neffective KD framework that transfers knowledge from VLMs to compact,\ntask-specific models in semi-supervised settings. Specifically, we introduce\ndual prediction heads that independently learn from labeled data and teacher\npredictions, and propose to linearly combine their outputs during inference. We\nobserve that $\\texttt{DHO}$ mitigates gradient conflicts between supervised and\ndistillation signals, enabling more effective feature learning than single-head\nKD baselines. As a result, extensive experiments show that $\\texttt{DHO}$\nconsistently outperforms baselines across multiple domains and fine-grained\ndatasets. Notably, on ImageNet, it achieves state-of-the-art performance,\nimproving accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively,\nwhile using fewer parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "41 pages, 19 figures, preprint",
    "pdf_url": "http://arxiv.org/pdf/2505.07675v1",
    "published_date": "2025-05-12 15:39:51 UTC",
    "updated_date": "2025-05-12 15:39:51 UTC"
  },
  {
    "arxiv_id": "2505.07672v2",
    "title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit",
    "authors": [
      "Arun S. Maiya"
    ],
    "abstract": "We present OnPrem$.$LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem$.$LLM supports multiple LLM backends -- including llama$.$cpp, Ollama,\nvLLM, and Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem$.$LLM also supports integration with a wide range of cloud\nLLM providers when permitted, enabling hybrid deployments that balance\nperformance with data control. A no-code web interface extends accessibility to\nnon-technical users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.07672v2",
    "published_date": "2025-05-12 15:36:27 UTC",
    "updated_date": "2025-05-13 02:43:26 UTC"
  },
  {
    "arxiv_id": "2505.07671v1",
    "title": "Benchmarking Retrieval-Augmented Generation for Chemistry",
    "authors": [
      "Xianrui Zhong",
      "Bowen Jin",
      "Siru Ouyang",
      "Yanzhen Shen",
      "Qiao Jin",
      "Yin Fang",
      "Zhiyong Lu",
      "Jiawei Han"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for\nenhancing large language models (LLMs) with external knowledge, particularly in\nscientific domains that demand specialized and dynamic information. Despite its\npromise, the application of RAG in the chemistry domain remains underexplored,\nprimarily due to the lack of high-quality, domain-specific corpora and\nwell-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a\ncomprehensive benchmark designed to systematically assess the effectiveness of\nRAG across a diverse set of chemistry-related tasks. The accompanying chemistry\ncorpus integrates heterogeneous knowledge sources, including scientific\nliterature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia\nentries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG\ntoolkit that supports five retrieval algorithms and eight LLMs. Using\nChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain\n-- achieving an average relative improvement of 17.4% over direct inference\nmethods. We further conduct in-depth analyses on retriever architectures,\ncorpus selection, and the number of retrieved passages, culminating in\npractical recommendations to guide future research and deployment of RAG\nsystems in the chemistry domain. The code and data is available at\nhttps://chemrag.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07671v1",
    "published_date": "2025-05-12 15:34:45 UTC",
    "updated_date": "2025-05-12 15:34:45 UTC"
  },
  {
    "arxiv_id": "2505.07664v1",
    "title": "A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development",
    "authors": [
      "Werner Geyer",
      "Jessica He",
      "Daita Sarkar",
      "Michelle Brachman",
      "Chris Hammond",
      "Jennifer Heins",
      "Zahra Ashktorab",
      "Carlos Rosemberg",
      "Charlie Hill"
    ],
    "abstract": "The broad availability of generative AI offers new opportunities to support\nvarious work domains, including agile software development. Agile epics are a\nkey artifact for product managers to communicate requirements to stakeholders.\nHowever, in practice, they are often poorly defined, leading to churn, delivery\ndelays, and cost overruns. In this industry case study, we investigate\nopportunities for large language models (LLMs) to evaluate agile epic quality\nin a global company. Results from a user study with 17 product managers\nindicate how LLM evaluations could be integrated into their work practices,\nincluding perceived values and usage in improving their epics. High levels of\nsatisfaction indicate that agile epics are a new, viable application of AI\nevaluations. However, our findings also outline challenges, limitations, and\nadoption barriers that can inform both practitioners and researchers on the\nintegration of such evaluations into future agile work practices.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07664v1",
    "published_date": "2025-05-12 15:31:16 UTC",
    "updated_date": "2025-05-12 15:31:16 UTC"
  },
  {
    "arxiv_id": "2505.07637v1",
    "title": "Chronocept: Instilling a Sense of Time in Machines",
    "authors": [
      "Krish Goel",
      "Sanskar Pandey",
      "KS Mahadevan",
      "Harsh Kumar",
      "Vishesh Khadaria"
    ],
    "abstract": "Human cognition is deeply intertwined with a sense of time, known as\nChronoception. This sense allows us to judge how long facts remain valid and\nwhen knowledge becomes outdated. Despite progress in vision, language, and\nmotor control, AI still struggles to reason about temporal validity. We\nintroduce Chronocept, the first benchmark to model temporal validity as a\ncontinuous probability distribution over time. Using skew-normal curves fitted\nalong semantically decomposed temporal axes, Chronocept captures nuanced\npatterns of emergence, decay, and peak relevance. It includes two datasets:\nBenchmark I (atomic facts) and Benchmark II (multi-sentence passages).\nAnnotations show strong inter-annotator agreement (84% and 89%). Our baselines\npredict curve parameters - location, scale, and skewness - enabling\ninterpretable, generalizable learning and outperforming classification-based\napproaches. Chronocept fills a foundational gap in AI's temporal reasoning,\nsupporting applications in knowledge grounding, fact-checking,\nretrieval-augmented generation (RAG), and proactive agents. Code and data are\npublicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 8 figures, 18 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.07637v1",
    "published_date": "2025-05-12 15:07:32 UTC",
    "updated_date": "2025-05-12 15:07:32 UTC"
  },
  {
    "arxiv_id": "2505.07634v2",
    "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents",
    "authors": [
      "Jian Liu",
      "Xiongtao Shi",
      "Thai Duy Nguyen",
      "Haitian Zhang",
      "Tianxiang Zhang",
      "Wei Sun",
      "Yanjie Li",
      "Athanasios V. Vasilakos",
      "Giovanni Iacca",
      "Arshad Ali Khan",
      "Arvind Kumar",
      "Jae Won Cho",
      "Ajmal Mian",
      "Lihua Xie",
      "Erik Cambria",
      "Lin Wang"
    ],
    "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static,\ndata-driven models to dynamic systems capable of perceiving and interacting\nwith real-world environments. Despite advancements in pattern recognition and\nsymbolic reasoning, current AI systems, such as large language models, remain\ndisembodied, unable to physically engage with the world. This limitation has\ndriven the rise of embodied AI, where autonomous agents, such as humanoid\nrobots, must navigate and manipulate unstructured environments with human-like\nadaptability. At the core of this challenge lies the concept of Neural Brain, a\ncentral intelligence system designed to drive embodied agents with human-like\nadaptability. A Neural Brain must seamlessly integrate multimodal sensing and\nperception with cognitive capabilities. Achieving this also requires an\nadaptive memory system and energy-efficient hardware-software co-design,\nenabling real-time action in dynamic environments. This paper introduces a\nunified framework for the Neural Brain of embodied agents, addressing two\nfundamental challenges: (1) defining the core components of Neural Brain and\n(2) bridging the gap between static AI models and the dynamic adaptability\nrequired for real-world deployment. To this end, we propose a biologically\ninspired architecture that integrates multimodal active sensing,\nperception-cognition-action function, neuroplasticity-based memory storage and\nupdating, and neuromorphic hardware/software optimization. Furthermore, we also\nreview the latest research on embodied agents across these four aspects and\nanalyze the gap between current AI systems and human intelligence. By\nsynthesizing insights from neuroscience, we outline a roadmap towards the\ndevelopment of generalizable, autonomous agents capable of human-level\nintelligence in real-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "51 pages, 17 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.07634v2",
    "published_date": "2025-05-12 15:05:34 UTC",
    "updated_date": "2025-05-14 12:56:45 UTC"
  },
  {
    "arxiv_id": "2505.07917v1",
    "title": "Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation",
    "authors": [
      "Linus Stuhlmann",
      "Michael Alexander Saxer",
      "Jonathan Fürst"
    ],
    "abstract": "Biomedical question-answering (QA) systems require effective retrieval and\ngeneration components to ensure accuracy, efficiency, and scalability. This\nstudy systematically examines a Retrieval-Augmented Generation (RAG) system for\nbiomedical QA, evaluating retrieval strategies and response time trade-offs. We\nfirst assess state-of-the-art retrieval methods, including BM25, BioBERT,\nMedCPT, and a hybrid approach, alongside common data stores such as\nElasticsearch, MongoDB, and FAISS, on a ~10% subset of PubMed (2.4M documents)\nto measure indexing efficiency, retrieval latency, and retriever performance in\nthe end-to-end RAG system. Based on these insights, we deploy the final RAG\nsystem on the full 24M PubMed corpus, comparing different retrievers' impact on\noverall performance. Evaluations of the retrieval depth show that retrieving 50\ndocuments with BM25 before reranking with MedCPT optimally balances accuracy\n(0.90), recall (0.90), and response time (1.91s). BM25 retrieval time remains\nstable (82ms), while MedCPT incurs the main computational cost. These results\nhighlight previously not well-known trade-offs in retrieval depth, efficiency,\nand scalability for biomedical QA. With open-source code, the system is fully\nreproducible and extensible.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at SDS25",
    "pdf_url": "http://arxiv.org/pdf/2505.07917v1",
    "published_date": "2025-05-12 14:51:47 UTC",
    "updated_date": "2025-05-12 14:51:47 UTC"
  },
  {
    "arxiv_id": "2505.07621v1",
    "title": "Bang for the Buck: Vector Search on Cloud CPUs",
    "authors": [
      "Leonardo Kuffo",
      "Peter Boncz"
    ],
    "abstract": "Vector databases have emerged as a new type of systems that support efficient\nquerying of high-dimensional vectors. Many of these offer their database as a\nservice in the cloud. However, the variety of available CPUs and the lack of\nvector search benchmarks across CPUs make it difficult for users to choose one.\nIn this study, we show that CPU microarchitectures available in the cloud\nperform significantly differently across vector search scenarios. For instance,\nin an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per\nsecond (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the\ntables turn. However, when looking at the number of queries per dollar (QP$),\nGraviton3 is the best option for most indexes and quantization settings, even\nover Graviton4 (Table 1). With this work, we hope to guide users in getting the\nbest \"bang for the buck\" when deploying vector search systems.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "To be published in Proceedings of 21st International Workshop on Data\n  Management on New Hardware (DaMoN '25)",
    "pdf_url": "http://arxiv.org/pdf/2505.07621v1",
    "published_date": "2025-05-12 14:44:21 UTC",
    "updated_date": "2025-05-12 14:44:21 UTC"
  },
  {
    "arxiv_id": "2505.07615v1",
    "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models",
    "authors": [
      "Riccardo Passoni",
      "Francesca Ronchini",
      "Luca Comanducci",
      "Romain Serizel",
      "Fabio Antonacci"
    ],
    "abstract": "Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07615v1",
    "published_date": "2025-05-12 14:36:47 UTC",
    "updated_date": "2025-05-12 14:36:47 UTC"
  },
  {
    "arxiv_id": "2505.07610v2",
    "title": "Concept-Level Explainability for Auditing & Steering LLM Responses",
    "authors": [
      "Kenza Amara",
      "Rita Sevastjanova",
      "Mennatallah El-Assady"
    ],
    "abstract": "As large language models (LLMs) become widely deployed, concerns about their\nsafety and alignment grow. An approach to steer LLM behavior, such as\nmitigating biases or defending against jailbreaks, is to identify which parts\nof a prompt influence specific aspects of the model's output. Token-level\nattribution methods offer a promising solution, but still struggle in text\ngeneration, explaining the presence of each token in the output separately,\nrather than the underlying semantics of the entire LLM response. We introduce\nConceptX, a model-agnostic, concept-level explainability method that identifies\nthe concepts, i.e., semantically rich tokens in the prompt, and assigns them\nimportance based on the outputs' semantic similarity. Unlike current\ntoken-level methods, ConceptX also offers to preserve context integrity through\nin-place token replacements and supports flexible explanation goals, e.g.,\ngender bias. ConceptX enables both auditing, by uncovering sources of bias, and\nsteering, by modifying prompts to shift the sentiment or reduce the harmfulness\nof LLM responses, without requiring retraining. Across three LLMs, ConceptX\noutperforms token-level methods like TokenSHAP in both faithfulness and human\nalignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for\nrandom edits and lower attack success rates from 0.463 to 0.242, outperforming\nattribution and paraphrasing baselines. While prompt engineering and\nself-explaining methods sometimes yield safer responses, ConceptX offers a\ntransparent and faithful alternative for improving LLM safety and alignment,\ndemonstrating the practical value of attribution-based explainability in\nguiding LLM behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 7 figures, Submission to Neurips 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07610v2",
    "published_date": "2025-05-12 14:31:51 UTC",
    "updated_date": "2025-05-19 14:00:52 UTC"
  },
  {
    "arxiv_id": "2505.07608v1",
    "title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining",
    "authors": [
      "Xiaomi LLM-Core Team",
      ":",
      "Bingquan Xia",
      "Bowen Shen",
      "Cici",
      "Dawei Zhu",
      "Di Zhang",
      "Gang Wang",
      "Hailin Zhang",
      "Huaqiu Liu",
      "Jiebao Xiao",
      "Jinhao Dong",
      "Liang Zhao",
      "Peidian Li",
      "Peng Wang",
      "Shihua Yu",
      "Shimao Chen",
      "Weikun Wang",
      "Wenhan Ma",
      "Xiangwei Deng",
      "Yi Huang",
      "Yifan Song",
      "Zihan Jiang",
      "Bowen Ye",
      "Can Cai",
      "Chenhong He",
      "Dong Zhang",
      "Duo Zhang",
      "Guoan Wang",
      "Hao Tian",
      "Haochen Zhao",
      "Heng Qu",
      "Hongshen Xu",
      "Jun Shi",
      "Kainan Bao",
      "QingKai Fang",
      "Kang Zhou",
      "Kangyang Zhou",
      "Lei Li",
      "Menghang Zhu",
      "Nuo Chen",
      "Qiantong Wang",
      "Shaohui Liu",
      "Shicheng Li",
      "Shuhao Gu",
      "Shuhuai Ren",
      "Shuo Liu",
      "Sirui Deng",
      "Weiji Zhuang",
      "Weiwei Lv",
      "Wenyu Yang",
      "Xin Zhang",
      "Xing Yong",
      "Xing Zhang",
      "Xingchen Song",
      "Xinzhe Xu",
      "Xu Wang",
      "Yihan Yan",
      "Yu Tu",
      "Yuanyuan Tian",
      "Yudong Wang",
      "Yue Yu",
      "Zhenru Lin",
      "Zhichao Song",
      "Zihao Yue"
    ],
    "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with\noptimization across both pre-training and post-training stages. During\npre-training, we enhance the data preprocessing pipeline and employ a\nthree-stage data mixing strategy to strengthen the base model's reasoning\npotential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional\nMulti-Token Prediction objective for enhanced performance and accelerated\ninference speed. During post-training, we curate a dataset of 130K verifiable\nmathematics and programming problems for reinforcement learning, integrating a\ntest-difficulty-driven code-reward scheme to alleviate sparse-reward issues and\nemploying strategic data resampling to stabilize training. Extensive\nevaluations show that MiMo-7B-Base possesses exceptional reasoning potential,\noutperforming even much larger 32B models. The final RL-tuned model,\nMiMo-7B-RL, achieves superior performance on mathematics, code and general\nreasoning tasks, surpassing the performance of OpenAI o1-mini. The model\ncheckpoints are available at https://github.com/xiaomimimo/MiMo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07608v1",
    "published_date": "2025-05-12 14:30:11 UTC",
    "updated_date": "2025-05-12 14:30:11 UTC"
  },
  {
    "arxiv_id": "2505.07601v1",
    "title": "Characterizing the Investigative Methods of Fictional Detectives with Large Language Models",
    "authors": [
      "Edirlei Soares de Lima",
      "Marco A. Casanova",
      "Bruno Feijó",
      "Antonio L. Furtado"
    ],
    "abstract": "Detective fiction, a genre defined by its complex narrative structures and\ncharacter-driven storytelling, presents unique challenges for computational\nnarratology, a research field focused on integrating literary theory into\nautomated narrative generation. While traditional literary studies have offered\ndeep insights into the methods and archetypes of fictional detectives, these\nanalyses often focus on a limited number of characters and lack the scalability\nneeded for the extraction of unique traits that can be used to guide narrative\ngeneration methods. In this paper, we present an AI-driven approach for\nsystematically characterizing the investigative methods of fictional\ndetectives. Our multi-phase workflow explores the capabilities of 15 Large\nLanguage Models (LLMs) to extract, synthesize, and validate distinctive\ninvestigative traits of fictional detectives. This approach was tested on a\ndiverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes,\nWilliam Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin -\ncapturing the distinctive investigative styles that define each character. The\nidentified traits were validated against existing literary analyses and further\ntested in a reverse identification phase, achieving an overall accuracy of\n91.43%, demonstrating the method's effectiveness in capturing the distinctive\ninvestigative approaches of each detective. This work contributes to the\nbroader field of computational narratology by providing a scalable framework\nfor character analysis, with potential applications in AI-driven interactive\nstorytelling and automated narrative generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07601v1",
    "published_date": "2025-05-12 14:24:58 UTC",
    "updated_date": "2025-05-12 14:24:58 UTC"
  },
  {
    "arxiv_id": "2505.07596v1",
    "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent",
    "authors": [
      "Ziyang Huang",
      "Xiaowei Yuan",
      "Yiming Ju",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce\nhallucinations in Large Language Models (LLMs). While reinforcement learning\n(RL) can enable LLMs to act as search agents by activating retrieval\ncapabilities, existing ones often underutilize their internal knowledge. This\ncan lead to redundant retrievals, potential harmful knowledge conflicts, and\nincreased inference latency. To address these limitations, an efficient and\nadaptive search agent capable of discerning optimal retrieval timing and\nsynergistically integrating parametric (internal) and retrieved (external)\nknowledge is in urgent need. This paper introduces the Reinforced\nInternal-External Knowledge Synergistic Reasoning Agent (IKEA), which could\nindentify its own knowledge boundary and prioritize the utilization of internal\nknowledge, resorting to external search only when internal knowledge is deemed\ninsufficient. This is achieved using a novel knowledge-boundary aware reward\nfunction and a knowledge-boundary aware training dataset. These are designed\nfor internal-external knowledge synergy oriented RL, incentivizing the model to\ndeliver accurate answers, minimize unnecessary retrievals, and encourage\nappropriate external searches when its own knowledge is lacking. Evaluations\nacross multiple knowledge reasoning tasks demonstrate that IKEA significantly\noutperforms baseline methods, reduces retrieval frequency significantly, and\nexhibits robust generalization capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07596v1",
    "published_date": "2025-05-12 14:21:57 UTC",
    "updated_date": "2025-05-12 14:21:57 UTC"
  },
  {
    "arxiv_id": "2505.07591v1",
    "title": "A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models",
    "authors": [
      "Junjie Ye",
      "Caishuang Huang",
      "Zhuohan Chen",
      "Wenjie Fu",
      "Chenyuan Yang",
      "Leyi Yang",
      "Yilong Wu",
      "Peng Wang",
      "Meng Zhou",
      "Xiaolong Yang",
      "Tao Gui",
      "Qi Zhang",
      "Zhongchao Shi",
      "Jianping Fan",
      "Xuanjing Huang"
    ],
    "abstract": "Instruction following evaluates large language models (LLMs) on their ability\nto generate outputs that adhere to user-defined constraints. However, existing\nbenchmarks often rely on templated constraint prompts, which lack the diversity\nof real-world usage and limit fine-grained performance assessment. To fill this\ngap, we propose a multi-dimensional constraint framework encompassing three\nconstraint patterns, four constraint categories, and four difficulty levels.\nBuilding on this framework, we develop an automated instruction generation\npipeline that performs constraint expansion, conflict detection, and\ninstruction rewriting, yielding 1,200 code-verifiable instruction-following\ntest samples. We evaluate 19 LLMs across seven model families and uncover\nsubstantial variation in performance across constraint forms. For instance,\naverage performance drops from 77.67% at Level I to 32.96% at Level IV.\nFurthermore, we demonstrate the utility of our approach by using it to generate\ndata for reinforcement learning, achieving substantial gains in instruction\nfollowing without degrading general performance. In-depth analysis indicates\nthat these gains stem primarily from modifications in the model's attention\nmodules parameters, which enhance constraint recognition and adherence. Code\nand data are available in https://github.com/Junjie-Ye/MulDimIF.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07591v1",
    "published_date": "2025-05-12 14:16:55 UTC",
    "updated_date": "2025-05-12 14:16:55 UTC"
  },
  {
    "arxiv_id": "2505.13484v1",
    "title": "Evaluating Large Language Models for Real-World Engineering Tasks",
    "authors": [
      "Rene Heesch",
      "Sebastian Eilermann",
      "Alexander Windmann",
      "Alexander Diedrich",
      "Philipp Rosenthal",
      "Oliver Niggemann"
    ],
    "abstract": "Large Language Models (LLMs) are transformative not only for daily activities\nbut also for engineering tasks. However, current evaluations of LLMs in\nengineering exhibit two critical shortcomings: (i) the reliance on simplified\nuse cases, often adapted from examination materials where correctness is easily\nverifiable, and (ii) the use of ad hoc scenarios that insufficiently capture\ncritical engineering competencies. Consequently, the assessment of LLMs on\ncomplex, real-world engineering problems remains largely unexplored. This paper\naddresses this gap by introducing a curated database comprising over 100\nquestions derived from authentic, production-oriented engineering scenarios,\nsystematically designed to cover core competencies such as product design,\nprognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art\nLLMs, including both cloud-based and locally hosted instances, to\nsystematically investigate their performance on complex engineering tasks. Our\nresults show that LLMs demonstrate strengths in basic temporal and structural\nreasoning but struggle significantly with abstract reasoning, formal modeling,\nand context-sensitive engineering logic.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13484v1",
    "published_date": "2025-05-12 14:05:23 UTC",
    "updated_date": "2025-05-12 14:05:23 UTC"
  },
  {
    "arxiv_id": "2505.07581v2",
    "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models",
    "authors": [
      "Lei Wang",
      "Heyang Gao",
      "Xiaohe Bo",
      "Xu Chen",
      "Ji-Rong Wen"
    ],
    "abstract": "Leveraging large language model (LLM) based agents to simulate human social\nbehaviors has recently gained significant attention. In this paper, we\nintroduce a novel social simulator called YuLan-OneSim. Compared to previous\nworks, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free\nscenario construction: Users can simply describe and refine their simulation\nscenarios through natural language interactions with our simulator. All\nsimulation code is automatically generated, significantly reducing the need for\nprogramming expertise. (2) Comprehensive default scenarios: We implement 50\ndefault simulation scenarios spanning 8 domains, including economics,\nsociology, politics, psychology, organization, demographics, law, and\ncommunication, broadening access for a diverse range of social researchers. (3)\nEvolvable simulation: Our simulator is capable of receiving external feedback\nand automatically fine-tuning the backbone LLMs, significantly enhancing the\nsimulation quality. (4) Large-scale simulation: By developing a fully\nresponsive agent framework and a distributed simulation architecture, our\nsimulator can handle up to 100,000 agents, ensuring more stable and reliable\nsimulation results. (5) AI social researcher: Leveraging the above features, we\ndevelop an AI social researcher. Users only need to propose a research topic,\nand the AI researcher will automatically analyze the input, construct\nsimulation environments, summarize results, generate technical reports, review\nand refine the reports--completing the social science research loop. To\ndemonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate\nthe quality of the automatically generated scenarios, the reliability,\nefficiency, and scalability of the simulation process, as well as the\nperformance of the AI social researcher.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07581v2",
    "published_date": "2025-05-12 14:05:17 UTC",
    "updated_date": "2025-05-22 13:01:39 UTC"
  },
  {
    "arxiv_id": "2505.07576v1",
    "title": "Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study",
    "authors": [
      "Manuel Barusco",
      "Francesco Borsatti",
      "Youssef Ben Khalifa",
      "Davide Dalle Pezze",
      "Gian Antonio Susto"
    ],
    "abstract": "Semiconductor manufacturing is a complex, multistage process. Automated\nvisual inspection of Scanning Electron Microscope (SEM) images is indispensable\nfor minimizing equipment downtime and containing costs. Most previous research\nconsiders supervised approaches, assuming a sufficient number of anomalously\nlabeled samples. On the contrary, Visual Anomaly Detection (VAD), an emerging\nresearch domain, focuses on unsupervised learning, avoiding the costly defect\ncollection phase while providing explanations of the predictions. We introduce\na benchmark for VAD in the semiconductor domain by leveraging the MIIC dataset.\nOur results demonstrate the efficacy of modern VAD approaches in this field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07576v1",
    "published_date": "2025-05-12 13:56:59 UTC",
    "updated_date": "2025-05-12 13:56:59 UTC"
  },
  {
    "arxiv_id": "2505.07573v1",
    "title": "Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework",
    "authors": [
      "Sarah de Boer",
      "Hartmut Häntze",
      "Kiran Vaidhya Venkadesh",
      "Myrthe A. D. Buser",
      "Gabriel E. Humpire Mamani",
      "Lina Xu",
      "Lisa C. Adams",
      "Jawed Nawabi",
      "Keno K. Bressem",
      "Bram van Ginneken",
      "Mathias Prokop",
      "Alessa Hering"
    ],
    "abstract": "Kidney abnormality segmentation has important potential to enhance the\nclinical workflow, especially in settings requiring quantitative assessments.\nKidney volume could serve as an important biomarker for renal diseases, with\nchanges in volume correlating directly with kidney function. Currently,\nclinical practice often relies on subjective visual assessment for evaluating\nkidney size and abnormalities, including tumors and cysts, which are typically\nstaged based on diameter, volume, and anatomical location. To support a more\nobjective and reproducible approach, this research aims to develop a robust,\nthoroughly validated kidney abnormality segmentation algorithm, made publicly\navailable for clinical and research use. We employ publicly available training\ndatasets and leverage the state-of-the-art medical image segmentation framework\nnnU-Net. Validation is conducted using both proprietary and public test\ndatasets, with segmentation performance quantified by Dice coefficient and the\n95th percentile Hausdorff distance. Furthermore, we analyze robustness across\nsubgroups based on patient sex, age, CT contrast phases, and tumor histologic\nsubtypes. Our findings demonstrate that our segmentation algorithm, trained\nexclusively on publicly available data, generalizes effectively to external\ntest sets and outperforms existing state-of-the-art models across all tested\ndatasets. Subgroup analyses reveal consistent high performance, indicating\nstrong robustness and reliability. The developed algorithm and associated code\nare publicly accessible at\nhttps://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "35 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.07573v1",
    "published_date": "2025-05-12 13:53:19 UTC",
    "updated_date": "2025-05-12 13:53:19 UTC"
  },
  {
    "arxiv_id": "2505.07911v1",
    "title": "Combining Bayesian Inference and Reinforcement Learning for Agent Decision Making: A Review",
    "authors": [
      "Chengmin Zhou",
      "Ville Kyrki",
      "Pasi Fränti",
      "Laura Ruotsalainen"
    ],
    "abstract": "Bayesian inference has many advantages in decision making of agents (e.g.\nrobotics/simulative agent) over a regular data-driven black-box neural network:\nData-efficiency, generalization, interpretability, and safety where these\nadvantages benefit directly/indirectly from the uncertainty quantification of\nBayesian inference. However, there are few comprehensive reviews to summarize\nthe progress of Bayesian inference on reinforcement learning (RL) for decision\nmaking to give researchers a systematic understanding. This paper focuses on\ncombining Bayesian inference with RL that nowadays is an important approach in\nagent decision making. To be exact, this paper discusses the following five\ntopics: 1) Bayesian methods that have potential for agent decision making.\nFirst basic Bayesian methods and models (Bayesian rule, Bayesian learning, and\nBayesian conjugate models) are discussed followed by variational inference,\nBayesian optimization, Bayesian deep learning, Bayesian active learning,\nBayesian generative models, Bayesian meta-learning, and lifelong Bayesian\nlearning. 2) Classical combinations of Bayesian methods with model-based RL\n(with approximation methods), model-free RL, and inverse RL. 3) Latest\ncombinations of potential Bayesian methods with RL. 4) Analytical comparisons\nof methods that combine Bayesian methods with RL with respect to\ndata-efficiency, generalization, interpretability, and safety. 5) In-depth\ndiscussions in six complex problem variants of RL, including unknown reward,\npartial-observability, multi-agent, multi-task, non-linear non-Gaussian, and\nhierarchical RL problems and the summary of how Bayesian methods work in the\ndata collection, data processing and policy learning stages of RL to pave the\nway for better agent decision-making strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07911v1",
    "published_date": "2025-05-12 13:34:50 UTC",
    "updated_date": "2025-05-12 13:34:50 UTC"
  },
  {
    "arxiv_id": "2505.07553v1",
    "title": "Towards Requirements Engineering for RAG Systems",
    "authors": [
      "Tor Sporsem",
      "Rasmus Ulfsnes"
    ],
    "abstract": "This short paper explores how a maritime company develops and integrates\nlarge-language models (LLM). Specifically by looking at the requirements\nengineering for Retrieval Augmented Generation (RAG) systems in expert\nsettings. Through a case study at a maritime service provider, we demonstrate\nhow data scientists face a fundamental tension between user expectations of AI\nperfection and the correctness of the generated outputs. Our findings reveal\nthat data scientists must identify context-specific \"retrieval requirements\"\nthrough iterative experimentation together with users because they are the ones\nwho can determine correctness. We present an empirical process model describing\nhow data scientists practically elicited these \"retrieval requirements\" and\nmanaged system limitations. This work advances software engineering knowledge\nby providing insights into the specialized requirements engineering processes\nfor implementing RAG systems in complex domain-specific applications.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to EASE 2025, 17-20 June, Istanbul, Turkey",
    "pdf_url": "http://arxiv.org/pdf/2505.07553v1",
    "published_date": "2025-05-12 13:30:44 UTC",
    "updated_date": "2025-05-12 13:30:44 UTC"
  },
  {
    "arxiv_id": "2505.07552v1",
    "title": "Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies",
    "authors": [
      "Efe Bozkir",
      "Christian Kosel",
      "Tina Seidel",
      "Enkelejda Kasneci"
    ],
    "abstract": "Teachers' visual attention and its distribution across the students in\nclassrooms can constitute important implications for student engagement,\nachievement, and professional teacher training. Despite that, inferring the\ninformation about where and which student teachers focus on is not trivial.\nMobile eye tracking can provide vital help to solve this issue; however, the\nuse of mobile eye tracking alone requires a significant amount of manual\nannotations. To address this limitation, we present an automated processing\npipeline concept that requires minimal manually annotated data to recognize\nwhich student the teachers focus on. To this end, we utilize state-of-the-art\nface detection models and face recognition feature embeddings to train face\nrecognition models with transfer learning in the classroom context and combine\nthese models with the teachers' gaze from mobile eye trackers. We evaluated our\napproach with data collected from four different classrooms, and our results\nshow that while it is possible to estimate the visually focused students with\nreasonable performance in all of our classroom setups, U-shaped and small\nclassrooms led to the best results with accuracies of approximately 0.7 and\n0.9, respectively. While we did not evaluate our method for teacher-student\ninteractions and focused on the validity of the technical approach, as our\nmethodology does not require a vast amount of manually annotated data and\noffers a non-intrusive way of handling teachers' visual attention, it could\nhelp improve instructional strategies, enhance classroom management, and\nprovide feedback for professional teacher development.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a long paper at the Educational Data Mining (EDM)\n  Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07552v1",
    "published_date": "2025-05-12 13:30:30 UTC",
    "updated_date": "2025-05-12 13:30:30 UTC"
  },
  {
    "arxiv_id": "2505.07548v1",
    "title": "Noise Optimized Conditional Diffusion for Domain Adaptation",
    "authors": [
      "Lingkun Luo",
      "Shiqiang Hu",
      "Liming Chen"
    ],
    "abstract": "Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet\nthe scarcity of High-Confidence Pseudo-Labeled Target Domain Samples\n(\\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical\nalignment, causing DA failures. To address this challenge, we propose\n\\textbf{N}oise \\textbf{O}ptimized \\textbf{C}onditional \\textbf{D}iffusion for\n\\textbf{D}omain \\textbf{A}daptation (\\textbf{NOCDDA}), which seamlessly\nintegrates the generative capabilities of conditional diffusion models with the\ndecision-making requirements of DA to achieve task-coupled optimization for\nefficient adaptation. For robust cross-domain consistency, we modify the DA\nclassifier to align with the conditional diffusion classifier within a unified\noptimization framework, enabling forward training on noise-varying cross-domain\nsamples. Furthermore, we argue that the conventional \\( \\mathcal{N}(\\mathbf{0},\n\\mathbf{I}) \\) initialization in diffusion models often generates\nclass-confused hcpl-tds, compromising discriminative DA. To resolve this, we\nintroduce a class-aware noise optimization strategy that refines sampling\nregions for reverse class-specific hcpl-tds generation, effectively enhancing\ncross-domain alignment. Extensive experiments across 5 benchmark datasets and\n29 DA tasks demonstrate significant performance gains of \\textbf{NOCDDA} over\n31 state-of-the-art methods, validating its robustness and effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures This work has been accepted by the International\n  Joint Conference on Artificial Intelligence (IJCAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.07548v1",
    "published_date": "2025-05-12 13:28:31 UTC",
    "updated_date": "2025-05-12 13:28:31 UTC"
  },
  {
    "arxiv_id": "2505.07546v1",
    "title": "GRADA: Graph-based Reranker against Adversarial Documents Attack",
    "authors": [
      "Jingjie Zheng",
      "Aryo Pradipta Gema",
      "Giwon Hong",
      "Xuanli He",
      "Pasquale Minervini",
      "Youcheng Sun",
      "Qiongkai Xu"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large\nlanguage models (LLMs) by integrating external knowledge from retrieved\ndocuments, thereby overcoming the limitations of models' static intrinsic\nknowledge. However, these systems are susceptible to adversarial attacks that\nmanipulate the retrieval process by introducing documents that are adversarial\nyet semantically similar to the query. Notably, while these adversarial\ndocuments resemble the query, they exhibit weak similarity to benign documents\nin the retrieval set. Thus, we propose a simple yet effective Graph-based\nReranking against Adversarial Document Attacks (GRADA) framework aiming at\npreserving retrieval quality while significantly reducing the success of\nadversaries. Our study evaluates the effectiveness of our approach through\nexperiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b,\nLlama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with\nresults from the Natural Questions dataset demonstrating up to an 80% reduction\nin attack success rates while maintaining minimal loss in accuracy.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07546v1",
    "published_date": "2025-05-12 13:27:35 UTC",
    "updated_date": "2025-05-12 13:27:35 UTC"
  },
  {
    "arxiv_id": "2505.07910v1",
    "title": "Tuning for Trustworthiness -- Balancing Performance and Explanation Consistency in Neural Network Optimization",
    "authors": [
      "Alexander Hinterleitner",
      "Thomas Bartz-Beielstein"
    ],
    "abstract": "Despite the growing interest in Explainable Artificial Intelligence (XAI),\nexplainability is rarely considered during hyperparameter tuning or neural\narchitecture optimization, where the focus remains primarily on minimizing\npredictive loss. In this work, we introduce the novel concept of XAI\nconsistency, defined as the agreement among different feature attribution\nmethods, and propose new metrics to quantify it. For the first time, we\nintegrate XAI consistency directly into the hyperparameter tuning objective,\ncreating a multi-objective optimization framework that balances predictive\nperformance with explanation robustness. Implemented within the Sequential\nParameter Optimization Toolbox (SPOT), our approach uses both weighted\naggregation and desirability-based strategies to guide model selection. Through\nour proposed framework and supporting tools, we explore the impact of\nincorporating XAI consistency into the optimization process. This enables us to\ncharacterize distinct regions in the architecture configuration space: one\nregion with poor performance and comparatively low interpretability, another\nwith strong predictive performance but weak interpretability due to low\n\\gls{xai} consistency, and a trade-off region that balances both objectives by\noffering high interpretability alongside competitive performance. Beyond\nintroducing this novel approach, our research provides a foundation for future\ninvestigations into whether models from the trade-off zone-balancing\nperformance loss and XAI consistency-exhibit greater robustness by avoiding\noverfitting to training performance, thereby leading to more reliable\npredictions on out-of-distribution data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07910v1",
    "published_date": "2025-05-12 13:19:14 UTC",
    "updated_date": "2025-05-12 13:19:14 UTC"
  },
  {
    "arxiv_id": "2505.07534v1",
    "title": "The Human-Data-Model Interaction Canvas for Visual Analytics",
    "authors": [
      "Jürgen Bernard"
    ],
    "abstract": "Visual Analytics (VA) integrates humans, data, and models as key actors in\ninsight generation and data-driven decision-making. This position paper values\nand reflects on 16 VA process models and frameworks and makes nine high-level\nobservations that motivate a fresh perspective on VA. The contribution is the\nHDMI Canvas, a perspective to VA that complements the strengths of existing VA\nprocess models and frameworks. It systematically characterizes diverse roles of\nhumans, data, and models, and how these actors benefit from and contribute to\nVA processes. The descriptive power of the HDMI Canvas eases the\ndifferentiation between a series of VA building blocks, rather than describing\ngeneral VA principles only. The canvas includes modern human-centered\nmethodologies, including human knowledge externalization and forms of feedback\nloops, while interpretable and explainable AI highlight model contributions\nbeyond their conventional outputs. The HDMI Canvas has generative power,\nguiding the design of new VA processes and is optimized for external\nstakeholders, improving VA outreach, interdisciplinary collaboration, and\nuser-centered design. The utility of the HDMI Canvas is demonstrated through\ntwo preliminary case studies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 5 figures, LaTeX; to appear at the 16th International\n  EuroVis Workshop on Visual Analytics (EuroVA'25) as a position paper",
    "pdf_url": "http://arxiv.org/pdf/2505.07534v1",
    "published_date": "2025-05-12 13:15:31 UTC",
    "updated_date": "2025-05-12 13:15:31 UTC"
  },
  {
    "arxiv_id": "2505.07533v1",
    "title": "IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability",
    "authors": [
      "Ahmad Fall",
      "Federica Granese",
      "Alex Lence",
      "Dominique Fourer",
      "Blaise Hanczar",
      "Joe-Elie Salem",
      "Jean-Daniel Zucker",
      "Edi Prifti"
    ],
    "abstract": "Monitoring and analyzing electrocardiogram (ECG) signals, even under varying\nphysiological conditions, including those influenced by physical activity,\ndrugs and stress, is crucial to accurately assess cardiac health. However,\ncurrent AI-based methods often fail to account for how these factors interact\nand alter ECG patterns, ultimately limiting their applicability in real-world\nsettings. This study introduces IKrNet, a novel neural network model, which\nidentifies drug-specific patterns in ECGs amidst certain physiological\nconditions. IKrNet's architecture incorporates spatial and temporal dynamics by\nusing a convolutional backbone with varying receptive field size to capture\nspatial features. A bi-directional Long Short-Term Memory module is also\nemployed to model temporal dependencies. By treating heart rate variability as\na surrogate for physiological fluctuations, we evaluated IKrNet's performance\nacross diverse scenarios, including conditions with physical stress, drug\nintake alone, and a baseline without drug presence. Our assessment follows a\nclinical protocol in which 990 healthy volunteers were administered 80mg of\nSotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a\nlife-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art\nmodels' accuracy and stability in varying physiological conditions,\nunderscoring its clinical viability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07533v1",
    "published_date": "2025-05-12 13:14:47 UTC",
    "updated_date": "2025-05-12 13:14:47 UTC"
  },
  {
    "arxiv_id": "2505.07531v1",
    "title": "QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads",
    "authors": [
      "Khurram Mazher",
      "Saad Bin Nasir"
    ],
    "abstract": "We present QuantX: a tailored suite of recipes for LLM and VLM quantization.\nIt is capable of quantizing down to 3-bit resolutions with minimal loss in\nperformance. The quantization strategies in QuantX take into account\nhardware-specific constraints to achieve efficient dequantization during\ninference ensuring flexible trade-off between runtime speed, memory requirement\nand model accuracy. Our results demonstrate that QuantX achieves performance\nwithin 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for\nmultiple end user tasks and outperforms recently published state-of-the-art\nquantization techniques. This manuscript provides insights into the LLM\nquantization process that motivated the range of recipes and options that are\nincorporated in QuantX.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07531v1",
    "published_date": "2025-05-12 13:13:06 UTC",
    "updated_date": "2025-05-12 13:13:06 UTC"
  },
  {
    "arxiv_id": "2505.07512v1",
    "title": "ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution",
    "authors": [
      "Xu Huang",
      "Weiwen Liu",
      "Xingshan Zeng",
      "Yuefeng Huang",
      "Xinlong Hao",
      "Yuxian Wang",
      "Yirong Zeng",
      "Chuhan Wu",
      "Yasheng Wang",
      "Ruiming Tang",
      "Defu Lian"
    ],
    "abstract": "The tool-using capability of large language models (LLMs) enables them to\naccess up-to-date external information and handle complex tasks. Current\napproaches to enhancing this capability primarily rely on distilling advanced\nmodels by data synthesis. However, this method incurs significant costs\nassociated with advanced model usage and often results in data compatibility\nissues, led by the high discrepancy in the knowledge scope between the advanced\nmodel and the target model. To address these challenges, we propose\nToolACE-DEV, a self-improving framework for tool learning. First, we decompose\nthe tool-learning objective into sub-tasks that enhance basic tool-making and\ntool-using abilities. Then, we introduce a self-evolving paradigm that allows\nlightweight models to self-improve, reducing reliance on advanced LLMs.\nExtensive experiments validate the effectiveness of our approach across models\nof varying scales and architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07512v1",
    "published_date": "2025-05-12 12:48:30 UTC",
    "updated_date": "2025-05-12 12:48:30 UTC"
  },
  {
    "arxiv_id": "2505.07511v1",
    "title": "MAIS: Memory-Attention for Interactive Segmentation",
    "authors": [
      "Mauricio Orbes-Arteaga",
      "Oeslle Lucena",
      "Sabastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "abstract": "Interactive medical segmentation reduces annotation effort by refining\npredictions through user feedback. Vision Transformer (ViT)-based models, such\nas the Segment Anything Model (SAM), achieve state-of-the-art performance using\nuser clicks and prior masks as prompts. However, existing methods treat\ninteractions as independent events, leading to redundant corrections and\nlimited refinement gains. We address this by introducing MAIS, a\nMemory-Attention mechanism for Interactive Segmentation that stores past user\ninputs and segmentation states, enabling temporal context integration. Our\napproach enhances ViT-based segmentation across diverse imaging modalities,\nachieving more efficient and accurate refinements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07511v1",
    "published_date": "2025-05-12 12:48:27 UTC",
    "updated_date": "2025-05-12 12:48:27 UTC"
  },
  {
    "arxiv_id": "2505.07509v1",
    "title": "HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs",
    "authors": [
      "Feng Ding",
      "Tingting Wang",
      "Yupeng Gao",
      "Shuo Yu",
      "Jing Ren",
      "Feng Xia"
    ],
    "abstract": "Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the\nexpiration date of facts, which negatively impact reasoning performance on\nTKGs. However, existing reasoning methods primarily focus on positive\nimportance of historical facts, neglecting adverse effects of outdated facts.\nBesides, training on these outdated facts yields extra computational cost. To\naddress these challenges, we propose an outdated fact filtering framework named\nHALO, which quantifies the temporal validity of historical facts by exploring\nthe half-life theory to filter outdated facts in TKGs. HALO consists of three\nmodules: the temporal fact attention module, the dynamic relation-aware encoder\nmodule, and the outdated fact filtering module. Firstly, the temporal fact\nattention module captures the evolution of historical facts over time to\nidentify relevant facts. Secondly, the dynamic relation-aware encoder module is\ndesigned for efficiently predicting the half life of each fact. Finally, we\nconstruct a time decay function based on the half-life theory to quantify the\ntemporal validity of facts and filter outdated facts. Experimental results show\nthat HALO outperforms the state-of-the-art TKG reasoning methods on three\npublic datasets, demonstrating its effectiveness in detecting and filtering\noutdated facts (Codes are available at\nhttps://github.com/yushuowiki/K-Half/tree/main ).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07509v1",
    "published_date": "2025-05-12 12:47:20 UTC",
    "updated_date": "2025-05-12 12:47:20 UTC"
  },
  {
    "arxiv_id": "2505.07508v1",
    "title": "EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection",
    "authors": [
      "Jing Ren",
      "Mingliang Hou",
      "Zhixuan Liu",
      "Xiaomei Bai"
    ],
    "abstract": "Graph anomaly detection is a popular and vital task in various real-world\nscenarios, which has been studied for several decades. Recently, many studies\nextending deep learning-based methods have shown preferable performance on\ngraph anomaly detection. However, existing methods are lack of efficiency that\nis definitely necessary for embedded devices. Towards this end, we propose an\nEfficient Anomaly detection model on heterogeneous Graphs via contrastive\nLEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of\ntheir distances to the local context. The proposed method first samples\ninstance pairs on meta path-level for contrastive learning. Then, a graph\nautoencoder-based model is applied to learn informative node embeddings in an\nunsupervised way, which will be further combined with the discriminator to\npredict the anomaly scores of nodes. Experimental results show that EAGLE\noutperforms the state-of-the-art methods on three heterogeneous network\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07508v1",
    "published_date": "2025-05-12 12:45:07 UTC",
    "updated_date": "2025-05-12 12:45:07 UTC"
  },
  {
    "arxiv_id": "2505.07908v1",
    "title": "A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny",
    "authors": [
      "Karahan Sarıtaş",
      "Çağatay Yıldız"
    ],
    "abstract": "In this reproduction study, we revisit recent claims that self-attention\nimplements kernel principal component analysis (KPCA) (Teo et al., 2024),\npositing that (i) value vectors $V$ capture the eigenvectors of the Gram matrix\nof the keys, and (ii) that self-attention projects queries onto the principal\ncomponent axes of the key matrix $K$ in a feature space. Our analysis reveals\nthree critical inconsistencies: (1) No alignment exists between learned\nself-attention value vectors and what is proposed in the KPCA perspective, with\naverage similarity metrics (optimal cosine similarity $\\leq 0.32$, linear CKA\n(Centered Kernel Alignment) $\\leq 0.11$, kernel CKA $\\leq 0.32$) indicating\nnegligible correspondence; (2) Reported decreases in reconstruction loss\n$J_\\text{proj}$, arguably justifying the claim that the self-attention\nminimizes the projection error of KPCA, are misinterpreted, as the quantities\ninvolved differ by orders of magnitude ($\\sim\\!10^3$); (3) Gram matrix\neigenvalue statistics, introduced to justify that $V$ captures the eigenvector\nof the gram matrix, are irreproducible without undocumented\nimplementation-specific adjustments. Across 10 transformer architectures, we\nconclude that the KPCA interpretation of self-attention lacks empirical\nsupport.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07908v1",
    "published_date": "2025-05-12 12:38:46 UTC",
    "updated_date": "2025-05-12 12:38:46 UTC"
  },
  {
    "arxiv_id": "2505.07473v1",
    "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks",
    "authors": [
      "Kai Xu",
      "YiWei Mao",
      "XinYi Guan",
      "ZiLong Feng"
    ],
    "abstract": "The application of large language models (LLMs) in the field of coding is\nevolving rapidly: from code assistants, to autonomous coding agents, and then\nto generating complete projects through natural language. Early LLM code\nbenchmarks primarily focused on code generation accuracy, but these benchmarks\nhave gradually become saturated. Benchmark saturation weakens their guiding\nrole for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%.\nAmong various attempts to address benchmark saturation, approaches based on\nsoftware engineering have stood out, but the saturation of existing software\nengineering benchmarks is rapidly increasing. To address this, we propose a new\nbenchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks\nwith sequential dependencies. The tasks implement project features in sequence,\nsimulating real-world human development workflows. When designing Web-Bench, we\naim to cover the foundational elements of Web development: Web Standards and\nWeb Frameworks. Given the scale and complexity of these projects, which were\ndesigned by engineers with 5 to 10 years of experience, each presents a\nsignificant challenge. On average, a single project takes 4 to 8 hours for a\nsenior engineer to complete. On our given benchmark agent (Web-Agent), SOTA\n(Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better)\nthan SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss\nthat in any development field, Standards and Frameworks represent foundational\nknowledge and efficiency tools, respectively, and LLMs require optimization\ntailored to them.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.07473v1",
    "published_date": "2025-05-12 12:06:23 UTC",
    "updated_date": "2025-05-12 12:06:23 UTC"
  },
  {
    "arxiv_id": "2505.07460v1",
    "title": "A Survey on Collaborative Mechanisms Between Large and Small Language Models",
    "authors": [
      "Yi Chen",
      "JiaHao Zhao",
      "HaoHao Han"
    ],
    "abstract": "Large Language Models (LLMs) deliver powerful AI capabilities but face\ndeployment challenges due to high resource costs and latency, whereas Small\nLanguage Models (SLMs) offer efficiency and deployability at the cost of\nreduced performance. Collaboration between LLMs and SLMs emerges as a crucial\nparadigm to synergistically balance these trade-offs, enabling advanced AI\napplications, especially on resource-constrained edge devices. This survey\nprovides a comprehensive overview of LLM-SLM collaboration, detailing various\ninteraction mechanisms (pipeline, routing, auxiliary, distillation, fusion),\nkey enabling technologies, and diverse application scenarios driven by\non-device needs like low latency, privacy, personalization, and offline\noperation. While highlighting the significant potential for creating more\nefficient, adaptable, and accessible AI, we also discuss persistent challenges\nincluding system overhead, inter-model consistency, robust task allocation,\nevaluation complexity, and security/privacy concerns. Future directions point\ntowards more intelligent adaptive frameworks, deeper model fusion, and\nexpansion into multimodal and embodied AI, positioning LLM-SLM collaboration as\na key driver for the next generation of practical and ubiquitous artificial\nintelligence.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07460v1",
    "published_date": "2025-05-12 11:48:42 UTC",
    "updated_date": "2025-05-12 11:48:42 UTC"
  },
  {
    "arxiv_id": "2505.07457v1",
    "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments",
    "authors": [
      "R. Maria del Rio-Chanona",
      "Marco Pangallo",
      "Cars Hommes"
    ],
    "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human\nbehavior in economic market experiments. Compared to previous studies, we focus\non dynamic feedback between LLM agents: the decisions of each LLM impact the\nmarket price at the current step, and so affect the decisions of the other LLMs\nat the next step. We compare LLM behavior to market dynamics observed in\nlaboratory settings and assess their alignment with human participants'\nbehavior. Our findings indicate that LLMs do not adhere strictly to rational\nexpectations, displaying instead bounded rationality, similarly to human\nparticipants. Providing a minimal context window i.e. memory of three previous\ntime steps, combined with a high variability setting capturing response\nheterogeneity, allows LLMs to replicate broad trends seen in human experiments,\nsuch as the distinction between positive and negative feedback markets.\nHowever, differences remain at a granular level--LLMs exhibit less\nheterogeneity in behavior than humans. These results suggest that LLMs hold\npromise as tools for simulating realistic human behavior in economic contexts,\nthough further research is needed to refine their accuracy and increase\nbehavioral diversity.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07457v1",
    "published_date": "2025-05-12 11:44:46 UTC",
    "updated_date": "2025-05-12 11:44:46 UTC"
  },
  {
    "arxiv_id": "2505.07453v1",
    "title": "How well do LLMs reason over tabular data, really?",
    "authors": [
      "Cornelius Wolff",
      "Madelon Hulsebos"
    ],
    "abstract": "Large Language Models (LLMs) excel in natural language tasks, but less is\nknown about their reasoning capabilities over tabular data. Prior analyses\ndevise evaluation strategies that poorly reflect an LLM's realistic performance\non tabular queries. Moreover, we have a limited understanding of the robustness\nof LLMs towards realistic variations in tabular inputs. Therefore, we ask: Can\ngeneral-purpose LLMs reason over tabular data, really?, and focus on two\nquestions 1) are tabular reasoning capabilities of general-purpose LLMs robust\nto real-world characteristics of tabular inputs, and 2) how can we\nrealistically evaluate an LLM's performance on analytical tabular queries?\nBuilding on a recent tabular reasoning benchmark, we first surface shortcomings\nof its multiple-choice prompt evaluation strategy, as well as commonly used\nfree-form text metrics such as SacreBleu and BERT-score. We show that an\nLLM-as-a-judge procedure yields more reliable performance insights and unveil a\nsignificant deficit in tabular reasoning performance of LLMs. We then extend\nthe tabular inputs reflecting three common characteristics in practice: 1)\nmissing values, 2) duplicate entities, and 3) structural variations.\nExperiments show that the tabular reasoning capabilities of general-purpose\nLLMs suffer from these variations, stressing the importance of improving their\nrobustness for realistic tabular inputs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.07453v1",
    "published_date": "2025-05-12 11:35:28 UTC",
    "updated_date": "2025-05-12 11:35:28 UTC"
  },
  {
    "arxiv_id": "2505.07450v3",
    "title": "Prototype Augmented Hypernetworks for Continual Learning",
    "authors": [
      "Neil De La Fuente",
      "Maria Pilligua",
      "Daniel Vidal",
      "Albin Soutiff",
      "Cecilia Curreli",
      "Daniel Cremers",
      "Andrey Barsky"
    ],
    "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting\nprior knowledge, but gradient updates for a new task often overwrite the\nweights learned earlier, causing catastrophic forgetting (CF). We propose\nPrototype-Augmented Hypernetworks (PAH), a framework where a single\nhypernetwork, conditioned on learnable task prototypes, dynamically generates\ntask-specific classifier heads on demand. To mitigate forgetting, PAH combines\ncross-entropy with dual distillation losses, one to align logits and another to\nalign prototypes, ensuring stable feature representations across tasks.\nEvaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves\nstate-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7\n% and 4.4 % forgetting, respectively, surpassing prior methods without storing\nsamples or heads.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2025 (LatinX in CV)",
    "pdf_url": "http://arxiv.org/pdf/2505.07450v3",
    "published_date": "2025-05-12 11:25:54 UTC",
    "updated_date": "2025-05-16 16:21:05 UTC"
  },
  {
    "arxiv_id": "2505.07447v2",
    "title": "Unified Continuous Generative Models",
    "authors": [
      "Peng Sun",
      "Yi Jiang",
      "Tao Lin"
    ],
    "abstract": "Recent advances in continuous generative models, including multi-step\napproaches like diffusion and flow-matching (typically requiring 8-1000\nsampling steps) and few-step methods such as consistency models (typically 1-8\nsteps), have demonstrated impressive generative performance. However, existing\nwork often treats these approaches as distinct paradigms, resulting in separate\ntraining and sampling methodologies. We introduce a unified framework for\ntraining, sampling, and analyzing these models. Our implementation, the Unified\nContinuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves\nstate-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a\n675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID\nin 20 steps and a few-step model reaching 1.42 FID in just 2 steps.\nAdditionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at\n250 steps) improves performance to 1.06 FID in only 40 steps. Code is available\nat: https://github.com/LINs-lab/UCGM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/LINs-lab/UCGM",
    "pdf_url": "http://arxiv.org/pdf/2505.07447v2",
    "published_date": "2025-05-12 11:15:39 UTC",
    "updated_date": "2025-05-20 12:27:53 UTC"
  },
  {
    "arxiv_id": "2505.07437v1",
    "title": "LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning",
    "authors": [
      "Xiaotian Lin",
      "Yanlin Qi",
      "Yizhang Zhu",
      "Themis Palpanas",
      "Chengliang Chai",
      "Nan Tang",
      "Yuyu Luo"
    ],
    "abstract": "Instruction tuning has emerged as a critical paradigm for improving the\ncapabilities and alignment of large language models (LLMs). However, existing\niterative model-aware data selection methods incur significant computational\noverhead, as they rely on repeatedly performing full-dataset model inference to\nestimate sample utility for subsequent training iterations, creating a\nfundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient\niterative data selection framework that accurately estimates sample utility\nentirely within the standard training loop, eliminating the need for costly\nadditional model inference. At its core, LEAD introduces Instance-Level Dynamic\nUncertainty (IDU), a theoretically grounded utility function combining\ninstantaneous training loss, gradient-based approximation of loss changes, and\nexponential smoothing of historical loss signals. To further scale efficiently\nto large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy,\nadaptively prioritizing informative clusters through a multi-armed bandit\nmechanism, followed by precise fine-grained selection of high-utility samples\nusing IDU. Extensive experiments across four diverse benchmarks show that LEAD\nsignificantly outperforms state-of-the-art methods, improving average model\nperformance by 6.1%-10.8% while using only 2.5% of the training data and\nreducing overall training time by 5-10x.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07437v1",
    "published_date": "2025-05-12 10:57:51 UTC",
    "updated_date": "2025-05-12 10:57:51 UTC"
  },
  {
    "arxiv_id": "2505.13483v1",
    "title": "EmoMeta: A Multimodal Dataset for Fine-grained Emotion Classification in Chinese Metaphors",
    "authors": [
      "Xingyuan Lu",
      "Yuxi Liu",
      "Dongyu Zhang",
      "Zhiyao Wu",
      "Jing Ren",
      "Feng Xia"
    ],
    "abstract": "Metaphors play a pivotal role in expressing emotions, making them crucial for\nemotional intelligence. The advent of multimodal data and widespread\ncommunication has led to a proliferation of multimodal metaphors, amplifying\nthe complexity of emotion classification compared to single-mode scenarios.\nHowever, the scarcity of research on constructing multimodal metaphorical\nfine-grained emotion datasets hampers progress in this domain. Moreover,\nexisting studies predominantly focus on English, overlooking potential\nvariations in emotional nuances across languages. To address these gaps, we\nintroduce a multimodal dataset in Chinese comprising 5,000 text-image pairs of\nmetaphorical advertisements. Each entry is meticulously annotated for metaphor\noccurrence, domain relations and fine-grained emotion classification\nencompassing joy, love, trust, fear, sadness, disgust, anger, surprise,\nanticipation, and neutral. Our dataset is publicly accessible\n(https://github.com/DUTIR-YSQ/EmoMeta), facilitating further advancements in\nthis burgeoning field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13483v1",
    "published_date": "2025-05-12 10:23:39 UTC",
    "updated_date": "2025-05-12 10:23:39 UTC"
  },
  {
    "arxiv_id": "2505.07903v1",
    "title": "SEM: Reinforcement Learning for Search-Efficient Large Language Models",
    "authors": [
      "Zeyang Sha",
      "Shiwen Cui",
      "Weiqiang Wang"
    ],
    "abstract": "Recent advancements in Large Language Models(LLMs) have demonstrated their\ncapabilities not only in reasoning but also in invoking external tools,\nparticularly search engines. However, teaching models to discern when to invoke\nsearch and when to rely on their internal knowledge remains a significant\nchallenge. Existing reinforcement learning approaches often lead to redundant\nsearch behaviors, resulting in inefficiencies and over-cost. In this paper, we\npropose SEM, a novel post-training reinforcement learning framework that\nexplicitly trains LLMs to optimize search usage. By constructing a balanced\ndataset combining MuSiQue and MMLU, we create scenarios where the model must\nlearn to distinguish between questions it can answer directly and those\nrequiring external retrieval. We design a structured reasoning template and\nemploy Group Relative Policy Optimization(GRPO) to post-train the model's\nsearch behaviors. Our reward function encourages accurate answering without\nunnecessary search while promoting effective retrieval when needed.\nExperimental results demonstrate that our method significantly reduces\nredundant search operations while maintaining or improving answer accuracy\nacross multiple challenging benchmarks. This framework advances the model's\nreasoning efficiency and extends its capability to judiciously leverage\nexternal knowledge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07903v1",
    "published_date": "2025-05-12 09:45:40 UTC",
    "updated_date": "2025-05-12 09:45:40 UTC"
  },
  {
    "arxiv_id": "2505.07393v1",
    "title": "AI in Money Matters",
    "authors": [
      "Nadine Sandjo Tchatchoua",
      "Richard Harper"
    ],
    "abstract": "In November 2022, Europe and the world by and large were stunned by the birth\nof a new large language model : ChatGPT. Ever since then, both academic and\npopulist discussions have taken place in various public spheres such as\nLinkedIn and X(formerly known as Twitter) with the view to both understand the\ntool and its benefits for the society. The views of real actors in professional\nspaces, especially in regulated industries such as finance and law have been\nlargely missing. We aim to begin to close this gap by presenting results from\nan empirical investigation conducted through interviews with professional\nactors in the Fintech industry. The paper asks the question, how and to what\nextent are large language models in general and ChatGPT in particular being\nadopted and used in the Fintech industry? The results show that while the\nfintech experts we spoke with see a potential in using large language models in\nthe future, a lot of questions marks remain concerning how they are policed and\ntherefore might be adopted in a regulated industry such as Fintech. This paper\naims to add to the existing academic discussing around large language models,\nwith a contribution to our understanding of professional viewpoints.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07393v1",
    "published_date": "2025-05-12 09:43:51 UTC",
    "updated_date": "2025-05-12 09:43:51 UTC"
  },
  {
    "arxiv_id": "2505.07381v1",
    "title": "Few-shot Semantic Encoding and Decoding for Video Surveillance",
    "authors": [
      "Baoping Cheng",
      "Yukun Zhang",
      "Liming Wang",
      "Xiaoyan Xie",
      "Tao Fu",
      "Dongkun Wang",
      "Xiaoming Tao"
    ],
    "abstract": "With the continuous increase in the number and resolution of video\nsurveillance cameras, the burden of transmitting and storing surveillance video\nis growing. Traditional communication methods based on Shannon's theory are\nfacing optimization bottlenecks. Semantic communication, as an emerging\ncommunication method, is expected to break through this bottleneck and reduce\nthe storage and transmission consumption of video. Existing semantic decoding\nmethods often require many samples to train the neural network for each scene,\nwhich is time-consuming and labor-intensive. In this study, a semantic encoding\nand decoding method for surveillance video is proposed. First, the sketch was\nextracted as semantic information, and a sketch compression method was proposed\nto reduce the bit rate of semantic information. Then, an image translation\nnetwork was proposed to translate the sketch into a video frame with a\nreference frame. Finally, a few-shot sketch decoding network was proposed to\nreconstruct video from sketch. Experimental results showed that the proposed\nmethod achieved significantly better video reconstruction performance than\nbaseline methods. The sketch compression method could effectively reduce the\nstorage and transmission consumption of semantic information with little\ncompromise on video quality. The proposed method provides a novel semantic\nencoding and decoding method that only needs a few training samples for each\nsurveillance scene, thus improving the practicality of the semantic\ncommunication system.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07381v1",
    "published_date": "2025-05-12 09:27:28 UTC",
    "updated_date": "2025-05-12 09:27:28 UTC"
  },
  {
    "arxiv_id": "2505.07902v1",
    "title": "Multimodal Assessment of Classroom Discourse Quality: A Text-Centered Attention-Based Multi-Task Learning Approach",
    "authors": [
      "Ruikun Hou",
      "Babette Bühler",
      "Tim Fütterer",
      "Efe Bozkir",
      "Peter Gerjets",
      "Ulrich Trautwein",
      "Enkelejda Kasneci"
    ],
    "abstract": "Classroom discourse is an essential vehicle through which teaching and\nlearning take place. Assessing different characteristics of discursive\npractices and linking them to student learning achievement enhances the\nunderstanding of teaching quality. Traditional assessments rely on manual\ncoding of classroom observation protocols, which is time-consuming and costly.\nDespite many studies utilizing AI techniques to analyze classroom discourse at\nthe utterance level, investigations into the evaluation of discursive practices\nthroughout an entire lesson segment remain limited. To address this gap, our\nstudy proposes a novel text-centered multimodal fusion architecture to assess\nthe quality of three discourse components grounded in the Global Teaching\nInSights (GTI) observation protocol: Nature of Discourse, Questioning, and\nExplanations. First, we employ attention mechanisms to capture inter- and\nintra-modal interactions from transcript, audio, and video streams. Second, a\nmulti-task learning approach is adopted to jointly predict the quality scores\nof the three components. Third, we formulate the task as an ordinal\nclassification problem to account for rating level order. The effectiveness of\nthese designed elements is demonstrated through an ablation study on the GTI\nGermany dataset containing 92 videotaped math lessons. Our results highlight\nthe dominant role of text modality in approaching this task. Integrating\nacoustic features enhances the model's consistency with human ratings,\nachieving an overall Quadratic Weighted Kappa score of 0.384, comparable to\nhuman inter-rater reliability (0.326). Our study lays the groundwork for the\nfuture development of automated discourse quality assessment to support teacher\nprofessional development through timely feedback on multidimensional discourse\npractices.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "The 18th International Conference on Educational Data Mining (EDM\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.07902v1",
    "published_date": "2025-05-12 09:24:21 UTC",
    "updated_date": "2025-05-12 09:24:21 UTC"
  },
  {
    "arxiv_id": "2505.07901v1",
    "title": "Latent Behavior Diffusion for Sequential Reaction Generation in Dyadic Setting",
    "authors": [
      "Minh-Duc Nguyen",
      "Hyung-Jeong Yang",
      "Soo-Hyung Kim",
      "Ji-Eun Shin",
      "Seung-Won Kim"
    ],
    "abstract": "The dyadic reaction generation task involves synthesizing responsive facial\nreactions that align closely with the behaviors of a conversational partner,\nenhancing the naturalness and effectiveness of human-like interaction\nsimulations. This paper introduces a novel approach, the Latent Behavior\nDiffusion Model, comprising a context-aware autoencoder and a diffusion-based\nconditional generator that addresses the challenge of generating diverse and\ncontextually relevant facial reactions from input speaker behaviors. The\nautoencoder compresses high-dimensional input features, capturing dynamic\npatterns in listener reactions while condensing complex input data into a\nconcise latent representation, facilitating more expressive and contextually\nappropriate reaction synthesis. The diffusion-based conditional generator\noperates on the latent space generated by the autoencoder to predict realistic\nfacial reactions in a non-autoregressive manner. This approach allows for\ngenerating diverse facial reactions that reflect subtle variations in\nconversational cues and emotional states. Experimental results demonstrate the\neffectiveness of our approach in achieving superior performance in dyadic\nreaction synthesis tasks compared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07901v1",
    "published_date": "2025-05-12 09:22:27 UTC",
    "updated_date": "2025-05-12 09:22:27 UTC"
  },
  {
    "arxiv_id": "2505.07377v1",
    "title": "Examining the Role of LLM-Driven Interactions on Attention and Cognitive Engagement in Virtual Classrooms",
    "authors": [
      "Suleyman Ozdel",
      "Can Sarpkaya",
      "Efe Bozkir",
      "Hong Gao",
      "Enkelejda Kasneci"
    ],
    "abstract": "Transforming educational technologies through the integration of large\nlanguage models (LLMs) and virtual reality (VR) offers the potential for\nimmersive and interactive learning experiences. However, the effects of LLMs on\nuser engagement and attention in educational environments remain open\nquestions. In this study, we utilized a fully LLM-driven virtual learning\nenvironment, where peers and teachers were LLM-driven, to examine how students\nbehaved in such settings. Specifically, we investigate how peer question-asking\nbehaviors influenced student engagement, attention, cognitive load, and\nlearning outcomes and found that, in conditions where LLM-driven peer learners\nasked questions, students exhibited more targeted visual scanpaths, with their\nattention directed toward the learning content, particularly in complex\nsubjects. Our results suggest that peer questions did not introduce extraneous\ncognitive load directly, as the cognitive load is strongly correlated with\nincreased attention to the learning material. Considering these findings, we\nprovide design recommendations for optimizing VR learning spaces.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to EDM 2025 (Eighteenth International Conference on\n  Educational Data Mining)",
    "pdf_url": "http://arxiv.org/pdf/2505.07377v1",
    "published_date": "2025-05-12 09:21:19 UTC",
    "updated_date": "2025-05-12 09:21:19 UTC"
  },
  {
    "arxiv_id": "2505.07374v1",
    "title": "AIS Data-Driven Maritime Monitoring Based on Transformer: A Comprehensive Review",
    "authors": [
      "Zhiye Xie",
      "Enmei Tu",
      "Xianping Fu",
      "Guoliang Yuan",
      "Yi Han"
    ],
    "abstract": "With the increasing demands for safety, efficiency, and sustainability in\nglobal shipping, Automatic Identification System (AIS) data plays an\nincreasingly important role in maritime monitoring. AIS data contains\nspatial-temporal variation patterns of vessels that hold significant research\nvalue in the marine domain. However, due to its massive scale, the full\npotential of AIS data has long remained untapped. With its powerful sequence\nmodeling capabilities, particularly its ability to capture long-range\ndependencies and complex temporal dynamics, the Transformer model has emerged\nas an effective tool for processing AIS data. Therefore, this paper reviews the\nresearch on Transformer-based AIS data-driven maritime monitoring, providing a\ncomprehensive overview of the current applications of Transformer models in the\nmarine field. The focus is on Transformer-based trajectory prediction methods,\nbehavior detection, and prediction techniques. Additionally, this paper\ncollects and organizes publicly available AIS datasets from the reviewed\npapers, performing data filtering, cleaning, and statistical analysis. The\nstatistical results reveal the operational characteristics of different vessel\ntypes, providing data support for further research on maritime monitoring\ntasks. Finally, we offer valuable suggestions for future research, identifying\ntwo promising research directions. Datasets are available at\nhttps://github.com/eyesofworld/Maritime-Monitoring.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07374v1",
    "published_date": "2025-05-12 09:17:43 UTC",
    "updated_date": "2025-05-12 09:17:43 UTC"
  },
  {
    "arxiv_id": "2505.07372v1",
    "title": "Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data",
    "authors": [
      "David de-Fitero-Dominguez",
      "Antonio Garcia-Cabot",
      "Eva Garcia-Lopez"
    ],
    "abstract": "This paper presents a novel methodology for enhancing Automated Program\nRepair (APR) through synthetic data generation utilizing Large Language Models\n(LLMs). Current APR systems are constrained by the limited availability of\nhigh-quality training data encompassing diverse bug types across multiple\nprogramming languages. The proposed approach addresses this limitation through\na two-phase process: a synthetic sample generation followed by a rigorous\nquality assessment. Multiple state-of-the-art LLMs were employed to generate\napproximately 30,000 paired examples of buggy and fixed code across 12\nprogramming languages and 13 bug categories. Subsequently, these samples\nunderwent cross-model evaluation against five criteria: correctness, code\nquality, security, performance, and completeness. Experimental evaluation on\nthe VulRepair test set dataset showed statistically significant improvements in\nPerfect Prediction rates, with the quality-filtered synthetic dataset\noutperforming both baseline and real-world commit data configurations in\ncertain scenarios. The methodology was validated through rigorous statistical\ntesting, including ANOVA and post-hoc Tukey's Honest Significant Difference\nanalysis. Furthermore, the best-performing configurations surpassed existing\nsystems despite using a less computationally intensive decoding strategy. This\nresearch establishes a self-bootstrapping paradigm in which LLMs generate and\nevaluate their own training data, potentially transforming approaches to data\nscarcity across software engineering tasks and advancing the development of\nrobust, adaptable tools for automated code maintenance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07372v1",
    "published_date": "2025-05-12 09:14:20 UTC",
    "updated_date": "2025-05-12 09:14:20 UTC"
  },
  {
    "arxiv_id": "2505.07365v1",
    "title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge",
    "authors": [
      "Chao-Han Huck Yang",
      "Sreyan Ghosh",
      "Qing Wang",
      "Jaeyeon Kim",
      "Hengyi Hong",
      "Sonal Kumar",
      "Guirui Zhong",
      "Zhifeng Kong",
      "S Sakshi",
      "Vaibhavi Lokegaonkar",
      "Oriol Nieto",
      "Ramani Duraiswami",
      "Dinesh Manocha",
      "Gunhee Kim",
      "Jun Du",
      "Rafael Valle",
      "Bryan Catanzaro"
    ],
    "abstract": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering\n(AQA) benchmark spanning multiple domains of sound understanding. This task\ndefines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA)\nto test audio-language models on interactive question-answering over diverse\nacoustic scenes. We describe the dataset composition (from marine mammal calls\nto soundscapes and complex real-world clips), the evaluation protocol (top-1\naccuracy with answer-shuffling robustness), and baseline systems\n(Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the\ndevelopment set are compared, showing strong variation across models and\nsubsets. This challenge aims to advance the audio understanding and reasoning\ncapabilities of audio-language models toward human-level acuity, which are\ncrucial for enabling AI agents to perceive and interact about the world\neffectively.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Preprint. DCASE 2025 Audio QA Challenge:\n  https://dcase.community/challenge2025/task-audio-question-answering",
    "pdf_url": "http://arxiv.org/pdf/2505.07365v1",
    "published_date": "2025-05-12 09:04:16 UTC",
    "updated_date": "2025-05-12 09:04:16 UTC"
  },
  {
    "arxiv_id": "2505.07364v1",
    "title": "GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance of deep unsupervised anomaly detection models",
    "authors": [
      "Daria Zotova",
      "Nicolas Pinon",
      "Robin Trombetta",
      "Romain Bouet",
      "Julien Jung",
      "Carole Lartizien"
    ],
    "abstract": "Background and Objective. Research in the cross-modal medical image\ntranslation domain has been very productive over the past few years in tackling\nthe scarce availability of large curated multimodality datasets with the\npromising performance of GAN-based architectures. However, only a few of these\nstudies assessed task-based related performance of these synthetic data,\nespecially for the training of deep models. Method. We design and compare\ndifferent GAN-based frameworks for generating synthetic brain\n[18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first\nperform standard qualitative and quantitative visual quality evaluation. Then,\nwe explore further impact of using these fake PET data in the training of a\ndeep unsupervised anomaly detection (UAD) model designed to detect subtle\nepilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic\ntask-oriented quality metrics of the synthetic FDG PET data tailored to our\nunsupervised detection task, then use these fake data to train a use case UAD\nmodel combining a deep representation learning based on siamese autoencoders\nwith a OC-SVM density support estimation model. This model is trained on normal\nsubjects only and allows the detection of any variation from the pattern of the\nnormal population. We compare the detection performance of models trained on 35\npaired real MR T1 of normal subjects paired either on 35 true PET images or on\n35 synthetic PET images generated from the best performing generative models.\nPerformance analysis is conducted on 17 exams of epilepsy patients undergoing\nsurgery. Results. The best performing GAN-based models allow generating\nrealistic fake PET images of control subject with SSIM and PSNR values around\n0.9 and 23.8, respectively and in distribution (ID) with regard to the true\ncontrol dataset. The best UAD model trained on these synthetic normative PET\ndata allows reaching 74% sensitivity. Conclusion. Our results confirm that\nGAN-based models are the best suited for MR T1 to FDG PET translation,\noutperforming transformer or diffusion models. We also demonstrate the\ndiagnostic value of these synthetic data for the training of UAD models and\nevaluation on clinical exams of epilepsy patients. Our code and the normative\nimage dataset are available.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07364v1",
    "published_date": "2025-05-12 09:00:03 UTC",
    "updated_date": "2025-05-12 09:00:03 UTC"
  },
  {
    "arxiv_id": "2505.07345v1",
    "title": "QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines",
    "authors": [
      "Ohjoon Kwon",
      "Changsu Lee",
      "Jihye Back",
      "Lim Sun Suk",
      "Inho Kang",
      "Donghyeon Jeon"
    ],
    "abstract": "Large language models (LLMs) have been widely used for relevance assessment\nin information retrieval. However, our study demonstrates that combining two\ndistinct small language models (SLMs) with different architectures can\noutperform LLMs in this task. Our approach -- QUPID -- integrates a generative\nSLM with an embedding-based SLM, achieving higher relevance judgment accuracy\nwhile reducing computational costs compared to state-of-the-art LLM solutions.\nThis computational efficiency makes QUPID highly scalable for real-world search\nsystems processing millions of queries daily. In experiments across diverse\ndocument types, our method demonstrated consistent performance improvements\n(Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x\nfaster inference times. Furthermore, when integrated into production search\npipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how\narchitectural diversity in model combinations can significantly enhance both\nsearch relevance and operational efficiency in information retrieval systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07345v1",
    "published_date": "2025-05-12 08:35:09 UTC",
    "updated_date": "2025-05-12 08:35:09 UTC"
  },
  {
    "arxiv_id": "2505.07344v4",
    "title": "Generative Pre-trained Autoregressive Diffusion Transformer",
    "authors": [
      "Yuan Zhang",
      "Jiacheng Jiang",
      "Guoqing Ma",
      "Zhiying Lu",
      "Haoyang Huang",
      "Jianlong Yuan",
      "Nan Duan"
    ],
    "abstract": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07344v4",
    "published_date": "2025-05-12 08:32:39 UTC",
    "updated_date": "2025-05-22 06:43:31 UTC"
  },
  {
    "arxiv_id": "2505.08814v1",
    "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test",
    "authors": [
      "Wenkai Li",
      "Xiaoqi Li",
      "Yingjie Mao",
      "Yishun Wang"
    ],
    "abstract": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08814v1",
    "published_date": "2025-05-12 08:25:55 UTC",
    "updated_date": "2025-05-12 08:25:55 UTC"
  },
  {
    "arxiv_id": "2505.07339v1",
    "title": "Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory Decision-Making Algorithms",
    "authors": [
      "Gabriel Lima",
      "Nina Grgić-Hlača",
      "Markus Langer",
      "Yixin Zou"
    ],
    "abstract": "Affirmative algorithms have emerged as a potential answer to algorithmic\ndiscrimination, seeking to redress past harms and rectify the source of\nhistorical injustices. We present the results of two experiments ($N$$=$$1193$)\ncapturing laypeople's perceptions of affirmative algorithms -- those which\nexplicitly prioritize the historically marginalized -- in hiring and criminal\njustice. We contrast these opinions about affirmative algorithms with folk\nattitudes towards algorithms that prioritize the privileged (i.e.,\ndiscriminatory) and systems that make decisions independently of demographic\ngroups (i.e., fair). We find that people -- regardless of their political\nleaning and identity -- view fair algorithms favorably and denounce\ndiscriminatory systems. In contrast, we identify disagreements concerning\naffirmative algorithms: liberals and racial minorities rate affirmative systems\nas positively as their fair counterparts, whereas conservatives and those from\nthe dominant racial group evaluate affirmative algorithms as negatively as\ndiscriminatory systems. We identify a source of these divisions: people have\nvarying beliefs about who (if anyone) is marginalized, shaping their views of\naffirmative algorithms. We discuss the possibility of bridging these\ndisagreements to bring people together towards affirmative algorithms.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07339v1",
    "published_date": "2025-05-12 08:25:15 UTC",
    "updated_date": "2025-05-12 08:25:15 UTC"
  },
  {
    "arxiv_id": "2505.07336v1",
    "title": "SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction",
    "authors": [
      "Zhixuan Zhang",
      "Xiaopeng Li",
      "Qi Liu"
    ],
    "abstract": "Background subtraction (BGS) is utilized to detect moving objects in a video\nand is commonly employed at the onset of object tracking and human recognition\nprocesses. Nevertheless, existing BGS techniques utilizing deep learning still\nencounter challenges with various background noises in videos, including\nvariations in lighting, shifts in camera angles, and disturbances like air\nturbulence or swaying trees. To address this problem, we design a spiking\nautoencoder network, termed SAEN-BGS, based on noise resilience and\ntime-sequence sensitivity of spiking neural networks (SNNs) to enhance the\nseparation of foreground and background. To eliminate unnecessary background\nnoise and preserve the important foreground elements, we begin by creating the\ncontinuous spiking conv-and-dconv block, which serves as the fundamental\nbuilding block for the decoder in SAEN-BGS. Moreover, in striving for enhanced\nenergy efficiency, we introduce a novel self-distillation spiking supervised\nlearning method grounded in ANN-to-SNN frameworks, resulting in decreased power\nconsumption. In extensive experiments conducted on CDnet-2014 and DAVIS-2016\ndatasets, our approach demonstrates superior segmentation performance relative\nto other baseline methods, even when challenged by complex scenarios with\ndynamic backgrounds.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by Pattern Recognition",
    "pdf_url": "http://arxiv.org/pdf/2505.07336v1",
    "published_date": "2025-05-12 08:21:47 UTC",
    "updated_date": "2025-05-12 08:21:47 UTC"
  },
  {
    "arxiv_id": "2505.07320v1",
    "title": "Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records",
    "authors": [
      "Yuhao Li",
      "Ling Luo",
      "Uwe Aickelin"
    ],
    "abstract": "Medical research, particularly in predicting patient outcomes, heavily relies\non medical time series data extracted from Electronic Health Records (EHR),\nwhich provide extensive information on patient histories. Despite rigorous\nexamination, labeling errors are inevitable and can significantly impede\naccurate predictions of patient outcome. To address this challenge, we propose\nan \\textbf{A}ttention-based Learning Framework with Dynamic\n\\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy\n\\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a\ntwo-component Beta mixture model to identify the certain and uncertain sets of\ninstances based on the fitness distribution of each class, and it captures\nglobal temporal dynamics while dynamically calibrating labels from the\nuncertain set or augmenting confident instances from the certain set.\nExperimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and\nseveral benchmark datasets from the UCR and UEA repositories, demonstrate that\nour model ACTLL has achieved state-of-the-art performance, especially under\nhigh noise levels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07320v1",
    "published_date": "2025-05-12 08:06:16 UTC",
    "updated_date": "2025-05-12 08:06:16 UTC"
  },
  {
    "arxiv_id": "2505.07317v1",
    "title": "How Do Companies Manage the Environmental Sustainability of AI? An Interview Study About Green AI Efforts and Regulations",
    "authors": [
      "Ashmita Sampatsing",
      "Sophie Vos",
      "Emma Beauxis-Aussalet",
      "Justus Bogner"
    ],
    "abstract": "With the ever-growing adoption of artificial intelligence (AI), AI-based\nsoftware and its negative impact on the environment are no longer negligible,\nand studying and mitigating this impact has become a critical area of research.\nHowever, it is currently unclear which role environmental sustainability plays\nduring AI adoption in industry and how AI regulations influence Green AI\npractices and decision-making in industry. We therefore aim to investigate the\nGreen AI perception and management of industry practitioners. To this end, we\nconducted a total of 11 interviews with participants from 10 different\norganizations that adopted AI-based software. The interviews explored three\nmain themes: AI adoption, current efforts in mitigating the negative\nenvironmental impact of AI, and the influence of the EU AI Act and the\nCorporate Sustainability Reporting Directive (CSRD). Our findings indicate that\n9 of 11 participants prioritized business efficiency during AI adoption, with\nminimal consideration of environmental sustainability. Monitoring and\nmitigation of AI's environmental impact were very limited. Only one participant\nmonitored negative environmental effects. Regarding applied mitigation\npractices, six participants reported no actions, with the others sporadically\nmentioning techniques like prompt engineering, relying on smaller models, or\nnot overusing AI. Awareness and compliance with the EU AI Act are low, with\nonly one participant reporting on its influence, while the CSRD drove\nsustainability reporting efforts primarily in larger companies. All in all, our\nfindings reflect a lack of urgency and priority for sustainable AI among these\ncompanies. We suggest that current regulations are not very effective, which\nhas implications for policymakers. Additionally, there is a need to raise\nindustry awareness, but also to provide user-friendly techniques and tools for\nGreen AI practices.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for publication at the 11th International Conference on ICT\n  for Sustainability (ICT4S'25), see https://conf.researchr.org/home/ict4s-2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07317v1",
    "published_date": "2025-05-12 08:03:55 UTC",
    "updated_date": "2025-05-12 08:03:55 UTC"
  },
  {
    "arxiv_id": "2505.07315v1",
    "title": "FedIFL: A federated cross-domain diagnostic framework for motor-driven systems with inconsistent fault modes",
    "authors": [
      "Zexiao Wang",
      "Yankai Wang",
      "Xiaoqiang Liao",
      "Xinguo Ming",
      "Weiming Shen"
    ],
    "abstract": "Due to the scarcity of industrial data, individual equipment users,\nparticularly start-ups, struggle to independently train a comprehensive fault\ndiagnosis model; federated learning enables collaborative training while\nensuring data privacy, making it an ideal solution. However, the diversity of\nworking conditions leads to variations in fault modes, resulting in\ninconsistent label spaces across different clients. In federated diagnostic\nscenarios, label space inconsistency leads to local models focus on\nclient-specific fault modes and causes local models from different clients to\nmap different failure modes to similar feature representations, which weakens\nthe aggregated global model's generalization. To tackle this issue, this\narticle proposed a federated cross-domain diagnostic framework termed Federated\nInvariant Features Learning (FedIFL). In intra-client training, prototype\ncontrastive learning mitigates intra-client domain shifts, subsequently,\nfeature generating ensures local models can access distributions of other\nclients in a privacy-friendly manner. Besides, in cross-client training, a\nfeature disentanglement mechanism is introduced to mitigate cross-client domain\nshifts, specifically, an instance-level federated instance consistency loss is\ndesigned to ensure the instance-level consistency of invariant features between\ndifferent clients, furthermore, a federated instance personalization loss and\nan orthogonal loss are constructed to distinguish specific features that from\nthe invariant features. Eventually, the aggregated model achieves promising\ngeneralization among global label spaces, enabling accurate fault diagnosis for\ntarget clients' Motor Driven Systems (MDSs) with inconsistent label spaces.\nExperiments on real-world MDSs validate the effectiveness and superiority of\nFedIFL in federated cross-domain diagnosis with inconsistent fault modes.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07315v1",
    "published_date": "2025-05-12 08:00:49 UTC",
    "updated_date": "2025-05-12 08:00:49 UTC"
  },
  {
    "arxiv_id": "2505.07313v2",
    "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study",
    "authors": [
      "Baixuan Xu",
      "Chunyang Li",
      "Weiqi Wang",
      "Wei Fan",
      "Tianshi Zheng",
      "Haochen Shi",
      "Tao Fan",
      "Yangqiu Song",
      "Qiang Yang"
    ],
    "abstract": "Designing effective collaboration structure for multi-agent LLM systems to\nenhance collective reasoning is crucial yet remains under-explored. In this\npaper, we systematically investigate how collaborative reasoning performance is\naffected by three key design dimensions: (1) Expertise-Domain Alignment, (2)\nCollaboration Paradigm (structured workflow vs. diversity-driven integration),\nand (3) System Scale. Our findings reveal that expertise alignment benefits are\nhighly domain-contingent, proving most effective for contextual reasoning\ntasks. Furthermore, collaboration focused on integrating diverse knowledge\nconsistently outperforms rigid task decomposition. Finally, we empirically\nexplore the impact of scaling the multi-agent system with expertise\nspecialization and study the computational trade off, highlighting the need for\nmore efficient communication protocol design. This work provides concrete\nguidelines for configuring specialized multi-agent system and identifies\ncritical architectural trade-offs and bottlenecks for scalable multi-agent\nreasoning. The code will be made available upon acceptance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.07313v2",
    "published_date": "2025-05-12 07:59:13 UTC",
    "updated_date": "2025-05-16 09:41:23 UTC"
  },
  {
    "arxiv_id": "2505.07299v1",
    "title": "Interpretable Event Diagnosis in Water Distribution Networks",
    "authors": [
      "André Artelt",
      "Stelios G. Vrachimis",
      "Demetrios G. Eliades",
      "Ulrike Kuhl",
      "Barbara Hammer",
      "Marios M. Polycarpou"
    ],
    "abstract": "The increasing penetration of information and communication technologies in\nthe design, monitoring, and control of water systems enables the use of\nalgorithms for detecting and identifying unanticipated events (such as leakages\nor water contamination) using sensor measurements. However, data-driven\nmethodologies do not always give accurate results and are often not trusted by\noperators, who may prefer to use their engineering judgment and experience to\ndeal with such events.\n  In this work, we propose a framework for interpretable event diagnosis -- an\napproach that assists the operators in associating the results of algorithmic\nevent diagnosis methodologies with their own intuition and experience. This is\nachieved by providing contrasting (i.e., counterfactual) explanations of the\nresults provided by fault diagnosis algorithms; their aim is to improve the\nunderstanding of the algorithm's inner workings by the operators, thus enabling\nthem to take a more informed decision by combining the results with their\npersonal experiences. Specifically, we propose counterfactual event\nfingerprints, a representation of the difference between the current event\ndiagnosis and the closest alternative explanation, which can be presented in a\ngraphical way. The proposed methodology is applied and evaluated on a realistic\nuse case using the L-Town benchmark.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07299v1",
    "published_date": "2025-05-12 07:36:00 UTC",
    "updated_date": "2025-05-12 07:36:00 UTC"
  },
  {
    "arxiv_id": "2505.07294v1",
    "title": "HuB: Learning Extreme Humanoid Balance",
    "authors": [
      "Tong Zhang",
      "Boyuan Zheng",
      "Ruiqian Nai",
      "Yingdong Hu",
      "Yen-Jen Wang",
      "Geng Chen",
      "Fanqi Lin",
      "Jiongye Li",
      "Chuye Hong",
      "Koushil Sreenath",
      "Yang Gao"
    ],
    "abstract": "The human body demonstrates exceptional motor capabilities-such as standing\nsteadily on one foot or performing a high kick with the leg raised over 1.5\nmeters-both requiring precise balance control. While recent research on\nhumanoid control has leveraged reinforcement learning to track human motions\nfor skill acquisition, applying this paradigm to balance-intensive tasks\nremains challenging. In this work, we identify three key obstacles: instability\nfrom reference motion errors, learning difficulties due to morphological\nmismatch, and the sim-to-real gap caused by sensor noise and unmodeled\ndynamics. To address these challenges, we propose HuB (Humanoid Balance), a\nunified framework that integrates reference motion refinement, balance-aware\npolicy learning, and sim-to-real robustness training, with each component\ntargeting a specific challenge. We validate our approach on the Unitree G1\nhumanoid robot across challenging quasi-static balance tasks, including extreme\nsingle-legged poses such as Swallow Balance and Bruce Lee's Kick. Our policy\nremains stable even under strong physical disturbances-such as a forceful\nsoccer strike-while baseline methods consistently fail to complete these tasks.\nProject website: https://hub-robot.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://hub-robot.github.io",
    "pdf_url": "http://arxiv.org/pdf/2505.07294v1",
    "published_date": "2025-05-12 07:31:42 UTC",
    "updated_date": "2025-05-12 07:31:42 UTC"
  },
  {
    "arxiv_id": "2505.07289v1",
    "title": "Semantic Retention and Extreme Compression in LLMs: Can We Have Both?",
    "authors": [
      "Stanislas Laborde",
      "Martin Cousseau",
      "Antoun Yaacoub",
      "Lionel Prevost"
    ],
    "abstract": "The exponential growth in Large Language Model (LLM) deployment has\nintensified the need for efficient model compression techniques to reduce\ncomputational and memory costs. While pruning and quantization have shown\npromise, their combined potential remains largely unexplored. In this paper, we\nexamine joint compression and how strategically combining pruning and\nquantization could yield superior performance-to-compression ratios compared to\nsingle-method approaches. Recognizing the challenges in accurately assessing\nLLM performance, we address key limitations of previous evaluation frameworks\nand introduce the Semantic Retention Compression Rate (SrCr), a novel metric\nthat quantifies the trade-off between model compression and semantic\npreservation, facilitating the optimization of pruning-quantization\nconfigurations. Experiments demonstrate that our recommended combination\nachieves, on average, a 20% performance increase compared to an equivalent\nquantization-only model at the same theoretical compression rate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68P30 (Primary) 68T07, 68T50 (Secondary)",
      "I.2.6; I.5.1; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication in the Proceedings of the 2025 International\n  Joint Conference on Neural Networks (IJCNN); this arXiv version includes an\n  appendix with 6 result tables; 10 pages, 15 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.07289v1",
    "published_date": "2025-05-12 07:23:19 UTC",
    "updated_date": "2025-05-12 07:23:19 UTC"
  },
  {
    "arxiv_id": "2505.07286v1",
    "title": "Piloting Structure-Based Drug Design via Modality-Specific Optimal Schedule",
    "authors": [
      "Keyue Qiu",
      "Yuxuan Song",
      "Zhehuan Fan",
      "Peidong Liu",
      "Zhe Zhang",
      "Mingyue Zheng",
      "Hao Zhou",
      "Wei-Ying Ma"
    ],
    "abstract": "Structure-Based Drug Design (SBDD) is crucial for identifying bioactive\nmolecules. Recent deep generative models are faced with challenges in geometric\nstructure modeling. A major bottleneck lies in the twisted probability path of\nmulti-modalities -- continuous 3D positions and discrete 2D topologies -- which\njointly determine molecular geometries. By establishing the fact that noise\nschedules decide the Variational Lower Bound (VLB) for the twisted probability\npath, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored\narea, which optimizes VLB as a path integral for SBDD. Our model effectively\nenhances molecular geometries and interaction modeling, achieving\nstate-of-the-art PoseBusters passing rate of 95.9% on CrossDock, more than 10%\nimprovement upon strong baselines, while maintaining high affinities and robust\nintramolecular validity evaluated on held-out test set.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Accepted to ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07286v1",
    "published_date": "2025-05-12 07:18:09 UTC",
    "updated_date": "2025-05-12 07:18:09 UTC"
  },
  {
    "arxiv_id": "2505.07899v1",
    "title": "DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise",
    "authors": [
      "Ding Cao",
      "Yuchen Cai",
      "Rongxi Guo",
      "Xuesong He",
      "Guiquan Liu"
    ],
    "abstract": "Sequential knowledge editing techniques aim to continuously update the\nknowledge in large language models at a low cost, preventing the models from\ngenerating outdated or incorrect information. However, existing sequential\nediting methods suffer from a significant decline in editing success rates\nafter long-term editing. Through theoretical analysis and experiments, we\nidentify that as the number of edits increases, the model's output increasingly\ndeviates from the desired target, leading to a drop in editing success rates.\nWe refer to this issue as the accumulation of superimposed noise problem. To\naddress this, we identify the factors contributing to this deviation and\npropose DeltaEdit, a novel method that optimizes update parameters through a\ndynamic orthogonal constraints strategy, effectively reducing interference\nbetween edits to mitigate deviation. Experimental results demonstrate that\nDeltaEdit significantly outperforms existing methods in edit success rates and\nthe retention of generalization capabilities, ensuring stable and reliable\nmodel performance even under extensive sequential editing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07899v1",
    "published_date": "2025-05-12 07:11:26 UTC",
    "updated_date": "2025-05-12 07:11:26 UTC"
  },
  {
    "arxiv_id": "2505.07280v1",
    "title": "Predicting Music Track Popularity by Convolutional Neural Networks on Spotify Features and Spectrogram of Audio Waveform",
    "authors": [
      "Navid Falah",
      "Behnam Yousefimehr",
      "Mehdi Ghatee"
    ],
    "abstract": "In the digital streaming landscape, it's becoming increasingly challenging\nfor artists and industry experts to predict the success of music tracks. This\nstudy introduces a pioneering methodology that uses Convolutional Neural\nNetworks (CNNs) and Spotify data analysis to forecast the popularity of music\ntracks. Our approach takes advantage of Spotify's wide range of features,\nincluding acoustic attributes based on the spectrogram of audio waveform,\nmetadata, and user engagement metrics, to capture the complex patterns and\nrelationships that influence a track's popularity. Using a large dataset\ncovering various genres and demographics, our CNN-based model shows impressive\neffectiveness in predicting the popularity of music tracks. Additionally, we've\nconducted extensive experiments to assess the strength and adaptability of our\nmodel across different musical styles and time periods, with promising results\nyielding a 97\\% F1 score. Our study not only offers valuable insights into the\ndynamic landscape of digital music consumption but also provides the music\nindustry with advanced predictive tools for assessing and predicting the\nsuccess of music tracks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "68T05, 68T10, 68T37",
      "I.2.6; I.2.1"
    ],
    "primary_category": "cs.SD",
    "comment": "12 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.07280v1",
    "published_date": "2025-05-12 07:03:17 UTC",
    "updated_date": "2025-05-12 07:03:17 UTC"
  },
  {
    "arxiv_id": "2505.08810v1",
    "title": "Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication",
    "authors": [
      "Bappa Muktar",
      "Vincent Fono",
      "Adama Nouboukpo"
    ],
    "abstract": "Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent\nTransportation Systems (ITS), particularly in enabling real-time communication\nfor emergency vehicles. However, Distributed Denial of Service (DDoS) attacks,\nwhich interfere with safety-critical communication channels, can severely\nimpair their reliability. This study introduces a robust and scalable framework\nto detect DDoS attacks in highway-based VANET environments. A synthetic dataset\nwas constructed using Network Simulator 3 (NS-3) in conjunction with the\nSimulation of Urban Mobility (SUMO) and further enriched with real-world\nmobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM).\nThree traffic categories were simulated: DDoS, VoIP, and TCP-based video\nstreaming (VideoTCP). The data preprocessing pipeline included normalization,\nsignal-to-noise ratio (SNR) feature engineering, missing value imputation, and\nclass balancing using the Synthetic Minority Over-sampling Technique (SMOTE).\nFeature importance was assessed using SHapley Additive exPlanations (SHAP).\nEleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB),\nAdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN).\nXGB and CB achieved the best performance, each attaining an F1-score of 96%.\nThese results highlight the robustness of the proposed framework and its\npotential for real-time deployment in VANETs to secure critical emergency\ncommunications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08810v1",
    "published_date": "2025-05-12 07:00:04 UTC",
    "updated_date": "2025-05-12 07:00:04 UTC"
  },
  {
    "arxiv_id": "2505.07271v1",
    "title": "On the Robustness of Reward Models for Language Model Alignment",
    "authors": [
      "Jiwoo Hong",
      "Noah Lee",
      "Eunki Kim",
      "Guijin Son",
      "Woojin Chung",
      "Aman Gupta",
      "Shao Tang",
      "James Thorne"
    ],
    "abstract": "The Bradley-Terry (BT) model is widely practiced in reward modeling for\nreinforcement learning with human feedback (RLHF). Despite its effectiveness,\nreward models (RMs) trained with BT model loss are prone to over-optimization,\nlosing generalizability to unseen input distributions. In this paper, we study\nthe cause of over-optimization in RM training and its downstream effects on the\nRLHF procedure, accentuating the importance of distributional robustness of RMs\nin unseen data. First, we show that the excessive dispersion of hidden state\nnorms is the main source of over-optimization. Then, we propose batch-wise\nsum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch,\nconstraining the rewards with extreme magnitudes. We assess the impact of BSR\nin improving robustness in RMs through four scenarios of over-optimization,\nwhere BSR consistently manifests better robustness. Subsequently, we compare\nthe plain BT model and BSR on RLHF training and empirically show that robust\nRMs better align the policy to the gold preference model. Finally, we apply BSR\nto high-quality data and models, which surpasses state-of-the-art RMs in the 8B\nscale by adding more than 5% in complex preference prediction tasks. By\nconducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length\nby 40% while adding a 7% increase in win rate, further highlighting that\nrobustness in RMs induces robustness in RLHF training. We release the code,\ndata, and models: https://github.com/LinkedIn-XFACT/RM-Robustness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07271v1",
    "published_date": "2025-05-12 06:48:26 UTC",
    "updated_date": "2025-05-12 06:48:26 UTC"
  },
  {
    "arxiv_id": "2505.08809v1",
    "title": "MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges",
    "authors": [
      "Shixi Qin",
      "Zhiyong Yang",
      "Shilong Bao",
      "Shi Wang",
      "Qianqian Xu",
      "Qingming Huang"
    ],
    "abstract": "This paper focuses on implanting multiple heterogeneous backdoor triggers in\nbridge-based diffusion models designed for complex and arbitrary input\ndistributions. Existing backdoor formulations mainly address single-attack\nscenarios and are limited to Gaussian noise input models. To fill this gap, we\npropose MixBridge, a novel diffusion Schr\\\"odinger bridge (DSB) framework to\ncater to arbitrary input distributions (taking I2I tasks as special cases).\nBeyond this trait, we demonstrate that backdoor triggers can be injected into\nMixBridge by directly training with poisoned image pairs. This eliminates the\nneed for the cumbersome modifications to stochastic differential equations\nrequired in previous studies, providing a flexible tool to study backdoor\nbehavior for bridge models. However, a key question arises: can a single DSB\nmodel train multiple backdoor triggers? Unfortunately, our theory shows that\nwhen attempting this, the model ends up following the geometric mean of benign\nand backdoored distributions, leading to performance conflict across backdoor\ntasks. To overcome this, we propose a Divide-and-Merge strategy to mix\ndifferent bridges, where models are independently pre-trained for each specific\nobjective (Divide) and then integrated into a unified model (Merge). In\naddition, a Weight Reallocation Scheme (WRS) is also designed to enhance the\nstealthiness of MixBridge. Empirical studies across diverse generation tasks\nspeak to the efficacy of MixBridge.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08809v1",
    "published_date": "2025-05-12 06:40:23 UTC",
    "updated_date": "2025-05-12 06:40:23 UTC"
  },
  {
    "arxiv_id": "2505.07261v2",
    "title": "CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks",
    "authors": [
      "Ce Hao",
      "Anxing Xiao",
      "Zhiwei Xue",
      "Harold Soh"
    ],
    "abstract": "Diffusion-based planners have shown strong performance in short-horizon tasks\nbut often fail in complex, long-horizon settings. We trace the failure to loose\ncoupling between high-level (HL) sub-goal selection and low-level (LL)\ntrajectory generation, which leads to incoherent plans and degraded\nperformance. We propose Coupled Hierarchical Diffusion (CHD), a framework that\nmodels HL sub-goals and LL trajectories jointly within a unified diffusion\nprocess. A shared classifier passes LL feedback upstream so that sub-goals\nself-correct while sampling proceeds. This tight HL-LL coupling improves\ntrajectory coherence and enables scalable long-horizon diffusion planning.\nExperiments across maze navigation, tabletop manipulation, and household\nenvironments show that CHD consistently outperforms both flat and hierarchical\ndiffusion baselines. Our website is: https://sites.google.com/view/chd2025/home",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07261v2",
    "published_date": "2025-05-12 06:21:48 UTC",
    "updated_date": "2025-05-13 09:28:39 UTC"
  },
  {
    "arxiv_id": "2505.07260v1",
    "title": "UMoE: Unifying Attention and FFN with Shared Experts",
    "authors": [
      "Yuanhang Yang",
      "Chaozheng Wang",
      "Jing Li"
    ],
    "abstract": "Sparse Mixture of Experts (MoE) architectures have emerged as a promising\napproach for scaling Transformer models. While initial works primarily\nincorporated MoE into feed-forward network (FFN) layers, recent studies have\nexplored extending the MoE paradigm to attention layers to enhance model\nperformance. However, existing attention-based MoE layers require specialized\nimplementations and demonstrate suboptimal performance compared to their\nFFN-based counterparts. In this paper, we aim to unify the MoE designs in\nattention and FFN layers by introducing a novel reformulation of the attention\nmechanism, revealing an underlying FFN-like structure within attention modules.\nOur proposed architecture, UMoE, achieves superior performance through\nattention-based MoE layers while enabling efficient parameter sharing between\nFFN and attention components.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07260v1",
    "published_date": "2025-05-12 06:21:44 UTC",
    "updated_date": "2025-05-12 06:21:44 UTC"
  },
  {
    "arxiv_id": "2505.07258v1",
    "title": "No Query, No Access",
    "authors": [
      "Wenqiang Wang",
      "Siyuan Liang",
      "Yangshijie Zhang",
      "Xiaojun Jia",
      "Hao Lin",
      "Xiaochun Cao"
    ],
    "abstract": "Textual adversarial attacks mislead NLP models, including Large Language\nModels (LLMs), by subtly modifying text. While effective, existing attacks\noften require knowledge of the victim model, extensive queries, or access to\ntraining data, limiting real-world feasibility. To overcome these constraints,\nwe introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which\noperates using only victim texts. To prevent access to the victim model, we\ncreate a shadow dataset with publicly available pre-trained models and\nclustering methods as a foundation for developing substitute models. To address\nthe low attack success rate (ASR) due to insufficient information feedback, we\npropose the hierarchical substitution model design, generating substitute\nmodels to mitigate the failure of a single substitute model at the decision\nboundary.\n  Concurrently, we use diverse adversarial example generation, employing\nvarious attack methods to generate and select the adversarial example with\nbetter similarity and attack effectiveness. Experiments on the Emotion and SST5\ndatasets show that VDBA outperforms state-of-the-art methods, achieving an ASR\nimprovement of 52.08\\% while significantly reducing attack queries to 0. More\nimportantly, we discover that VDBA poses a significant threat to LLMs such as\nQwen2 and the GPT family, and achieves the highest ASR of 45.99% even without\naccess to the API, confirming that advanced NLP models still face serious\nsecurity risks. Our codes can be found at\nhttps://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07258v1",
    "published_date": "2025-05-12 06:19:59 UTC",
    "updated_date": "2025-05-12 06:19:59 UTC"
  },
  {
    "arxiv_id": "2505.07251v1",
    "title": "Incomplete In-context Learning",
    "authors": [
      "Wenqiang Wang",
      "Yangshijie Zhang"
    ],
    "abstract": "Large vision language models (LVLMs) achieve remarkable performance through\nVision In-context Learning (VICL), a process that depends significantly on\ndemonstrations retrieved from an extensive collection of annotated examples\n(retrieval database). Existing studies often assume that the retrieval database\ncontains annotated examples for all labels. However, in real-world scenarios,\ndelays in database updates or incomplete data annotation may result in the\nretrieval database containing labeled samples for only a subset of classes. We\nrefer to this phenomenon as an \\textbf{incomplete retrieval database} and\ndefine the in-context learning under this condition as \\textbf{Incomplete\nIn-context Learning (IICL)}. To address this challenge, we propose\n\\textbf{Iterative Judgments and Integrated Prediction (IJIP)}, a two-stage\nframework designed to mitigate the limitations of IICL. The Iterative Judgments\nStage reformulates an \\(\\boldsymbol{m}\\)-class classification problem into a\nseries of \\(\\boldsymbol{m}\\) binary classification tasks, effectively\nconverting the IICL setting into a standard VICL scenario. The Integrated\nPrediction Stage further refines the classification process by leveraging both\nthe input image and the predictions from the Iterative Judgments Stage to\nenhance overall classification accuracy. IJIP demonstrates considerable\nperformance across two LVLMs and two datasets under three distinct conditions\nof label incompleteness, achieving the highest accuracy of 93.9\\%. Notably,\neven in scenarios where labels are fully available, IJIP still achieves the\nbest performance of all six baselines. Furthermore, IJIP can be directly\napplied to \\textbf{Prompt Learning} and is adaptable to the \\textbf{text\ndomain}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07251v1",
    "published_date": "2025-05-12 05:57:39 UTC",
    "updated_date": "2025-05-12 05:57:39 UTC"
  },
  {
    "arxiv_id": "2505.07247v2",
    "title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models",
    "authors": [
      "Peichao Lai",
      "Kexuan Zhang",
      "Yi Lin",
      "Linyihan Zhang",
      "Feiyang Ye",
      "Jinhao Yan",
      "Yanwei Xu",
      "Conghui He",
      "Yilei Wang",
      "Wentao Zhang",
      "Bin Cui"
    ],
    "abstract": "Subjective Answer Grading (SAG) plays a crucial role in education,\nstandardized testing, and automated assessment systems, particularly for\nevaluating short-form responses in Short Answer Scoring (SAS). However,\nexisting approaches often produce coarse-grained scores and lack detailed\nreasoning. Although large language models (LLMs) have demonstrated potential as\nzero-shot evaluators, they remain susceptible to bias, inconsistencies with\nhuman judgment, and limited transparency in scoring decisions. To overcome\nthese limitations, we introduce SAS-Bench, a benchmark specifically designed\nfor LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring,\nexpert-annotated error categories, and a diverse range of question types\nderived from real-world subject-specific exams. This benchmark facilitates\ndetailed evaluation of model reasoning processes and explainability. We also\nrelease an open-source dataset containing 1,030 questions and 4,109 student\nresponses, each annotated by domain experts. Furthermore, we conduct\ncomprehensive experiments with various LLMs, identifying major challenges in\nscoring science-related questions and highlighting the effectiveness of\nfew-shot prompting in improving scoring accuracy. Our work offers valuable\ninsights into the development of more robust, fair, and educationally\nmeaningful LLM-based evaluation systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07247v2",
    "published_date": "2025-05-12 05:43:21 UTC",
    "updated_date": "2025-05-15 11:01:45 UTC"
  },
  {
    "arxiv_id": "2505.07245v1",
    "title": "REMEDI: Relative Feature Enhanced Meta-Learning with Distillation for Imbalanced Prediction",
    "authors": [
      "Fei Liu",
      "Huanhuan Ren",
      "Yu Guan",
      "Xiuxu Wang",
      "Wang Lv",
      "Zhiqiang Hu",
      "Yaxi Chen"
    ],
    "abstract": "Predicting future vehicle purchases among existing owners presents a critical\nchallenge due to extreme class imbalance (<0.5% positive rate) and complex\nbehavioral patterns. We propose REMEDI (Relative feature Enhanced Meta-learning\nwith Distillation for Imbalanced prediction), a novel multi-stage framework\naddressing these challenges. REMEDI first trains diverse base models to capture\ncomplementary aspects of user behavior. Second, inspired by comparative\nop-timization techniques, we introduce relative performance meta-features\n(deviation from ensemble mean, rank among peers) for effective model fusion\nthrough a hybrid-expert architecture. Third, we distill the ensemble's\nknowledge into a single efficient model via supervised fine-tuning with MSE\nloss, enabling practical deployment. Evaluated on approximately 800,000 vehicle\nowners, REMEDI significantly outperforms baseline approaches, achieving the\nbusiness target of identifying ~50% of actual buyers within the top 60,000\nrecommendations at ~10% precision. The distilled model preserves the ensemble's\npredictive power while maintaining deployment efficiency, demonstrating\nREMEDI's effectiveness for imbalanced prediction in industry settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07245v1",
    "published_date": "2025-05-12 05:40:20 UTC",
    "updated_date": "2025-05-12 05:40:20 UTC"
  },
  {
    "arxiv_id": "2505.07897v1",
    "title": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows",
    "authors": [
      "Stefano Rando",
      "Luca Romani",
      "Alessio Sampieri",
      "Yuta Kyuragi",
      "Luca Franco",
      "Fabio Galasso",
      "Tatsunori Hashimoto",
      "John Yang"
    ],
    "abstract": "Context lengths for models have grown rapidly, from thousands to millions of\ntokens in just a few years. The extreme context sizes of modern long-context\nmodels have made it difficult to construct realistic long-context benchmarks --\nnot only due to the cost of collecting million-context tasks but also in\nidentifying realistic scenarios that require significant contexts. We identify\ncode comprehension and repair as a natural testbed and challenge task for\nlong-context models and introduce LongCodeBench (LCB), a benchmark to test LLM\ncoding abilities in long-context scenarios. Our benchmark tests both the\ncomprehension and repair capabilities of LCLMs in realistic and important\nsettings by drawing from real-world GitHub issues and constructing QA\n(LongCodeQA) and bug fixing (LongSWE-Bench) tasks. We carefully stratify the\ncomplexity of our benchmark, enabling us to evaluate models across different\nscales -- ranging from Qwen2.5 14B Instruct to Google's flagship Gemini model.\nWe find that long-context remains a weakness for all models, with performance\ndrops such as from 29% to 3% for Claude 3.5 Sonnet, or from 70.2% to 40% for\nQwen2.5.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07897v1",
    "published_date": "2025-05-12 05:38:03 UTC",
    "updated_date": "2025-05-12 05:38:03 UTC"
  },
  {
    "arxiv_id": "2505.07239v1",
    "title": "Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity",
    "authors": [
      "Guang Yan",
      "Yuhui Zhang",
      "Zimu Guo",
      "Lutan Zhao",
      "Xiaojun Chen",
      "Chen Wang",
      "Wenhao Wang",
      "Dan Meng",
      "Rui Hou"
    ],
    "abstract": "With the growing use of large language models (LLMs) hosted on cloud\nplatforms to offer inference services, privacy concerns about the potential\nleakage of sensitive information are escalating. Secure multi-party computation\n(MPC) is a promising solution to protect the privacy in LLM inference. However,\nMPC requires frequent inter-server communication, causing high performance\noverhead.\n  Inspired by the prevalent activation sparsity of LLMs, where most neuron are\nnot activated after non-linear activation functions, we propose an efficient\nprivate inference system, Comet. This system employs an accurate and fast\npredictor to predict the sparsity distribution of activation function output.\nAdditionally, we introduce a new private inference protocol. It efficiently and\nsecurely avoids computations involving zero values by exploiting the spatial\nlocality of the predicted sparse distribution. While this computation-avoidance\napproach impacts the spatiotemporal continuity of KV cache entries, we address\nthis challenge with a low-communication overhead cache refilling strategy that\nmerges miss requests and incorporates a prefetching mechanism. Finally, we\nevaluate Comet on four common LLMs and compare it with six state-of-the-art\nprivate inference systems. Comet achieves a 1.87x-2.63x speedup and a\n1.94x-2.64x communication reduction.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to SP 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.07239v1",
    "published_date": "2025-05-12 05:29:30 UTC",
    "updated_date": "2025-05-12 05:29:30 UTC"
  },
  {
    "arxiv_id": "2505.07236v1",
    "title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning",
    "authors": [
      "Oleg Sautenkov",
      "Yasheerah Yaqoot",
      "Muhammad Ahsan Mustafa",
      "Faryal Batool",
      "Jeffrin Sam",
      "Artem Lykov",
      "Chih-Yung Wen",
      "Dzmitry Tsetserukou"
    ],
    "abstract": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous\nUAV mission generation, built on large language and vision-language models\n(LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to\ninterpret satellite imagery, ground high-level natural language instructions,\nand collaboratively generate UAV trajectories with minimal human supervision. A\ncore component is a vision-grounded, pixel-pointing mechanism that enables\nprecise localization of semantic targets on aerial maps. To support real-time\nadaptability, we introduce a reactive thinking loop, allowing agents to\niteratively reflect on observations, revise mission goals, and coordinate\ndynamically in evolving environments.\n  UAV-CodeAgents is evaluated on large-scale mission scenarios involving\nindustrial and environmental fire detection. Our results show that a lower\ndecoding temperature (0.5) yields higher planning reliability and reduced\nexecution time, with an average mission creation time of 96.96 seconds and a\nsuccess rate of 93%. We further fine-tune Qwen2.5VL-7B on 9,000 annotated\nsatellite images, achieving strong spatial grounding across diverse visual\ncategories. To foster reproducibility and future research, we will release the\nfull codebase and a novel benchmark dataset for vision-language-based UAV\nplanning.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted",
    "pdf_url": "http://arxiv.org/pdf/2505.07236v1",
    "published_date": "2025-05-12 05:23:51 UTC",
    "updated_date": "2025-05-12 05:23:51 UTC"
  },
  {
    "arxiv_id": "2505.07233v2",
    "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation",
    "authors": [
      "Jiashuo Sun",
      "Xianrui Zhong",
      "Sizhe Zhou",
      "Jiawei Han"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems combine large language models\n(LLMs) with external knowledge retrieval, making them highly effective for\nknowledge-intensive tasks. A crucial but often under-explored component of\nthese systems is the reranker. Since irrelevant documents in RAG systems can\nmislead the generator, the reranker plays a vital role in refining retrieved\ndocuments to enhance generation quality and explainability. However, it is\nchallenging to determine the appropriate number of documents ($k$) that the\nreranker should select: too few may result in missing critical information,\nwhile too many introduce noise and inefficiencies. Although recent studies have\nexplored LLM-based rerankers, they primarily leverage internal model knowledge\nand overlook the rich supervisory signals that LLMs can provide, such as using\nresponse quality as feedback for optimizing reranking decisions. In this paper,\nwe propose DynamicRAG, a novel RAG framework where the reranker dynamically\nadjusts both the order and number of retrieved documents based on the query. We\nmodel the reranker as an agent optimized through reinforcement learning (RL),\nusing rewards derived from LLM output quality. Across seven knowledge-intensive\ndatasets, DynamicRAG demonstrates superior performance, achieving\nstate-of-the-art results among models of same parameter sizes. The model, data\nand code are available at https://github.com/GasolSun36/DynamicRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 7 figures, 15 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.07233v2",
    "published_date": "2025-05-12 05:19:01 UTC",
    "updated_date": "2025-05-16 02:47:07 UTC"
  },
  {
    "arxiv_id": "2505.07215v1",
    "title": "Measuring General Intelligence with Generated Games",
    "authors": [
      "Vivek Verma",
      "David Huang",
      "William Chen",
      "Dan Klein",
      "Nicholas Tomlin"
    ],
    "abstract": "We present gg-bench, a collection of game environments designed to evaluate\ngeneral reasoning capabilities in language models. Unlike most static\nbenchmarks, gg-bench is a data generating process where new evaluation\ninstances can be generated at will. In particular, gg-bench is synthetically\ngenerated by (1) using a large language model (LLM) to generate natural\nlanguage descriptions of novel games, (2) using the LLM to implement each game\nin code as a Gym environment, and (3) training reinforcement learning (RL)\nagents via self-play on the generated games. We evaluate language models by\ntheir winrate against these RL agents by prompting models with the game\ndescription, current board state, and a list of valid moves, after which models\noutput the moves they wish to take. gg-bench is challenging: state-of-the-art\nLLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench\nusing in-context learning, while reasoning models such as o1, o3-mini and\nDeepSeek-R1 achieve average winrates of 31-36%. We release the generated games,\ndata generation process, and evaluation code in order to support future\nmodeling work and expansion of our benchmark.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07215v1",
    "published_date": "2025-05-12 04:01:03 UTC",
    "updated_date": "2025-05-12 04:01:03 UTC"
  },
  {
    "arxiv_id": "2505.07214v2",
    "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent",
    "authors": [
      "Pascal Spiegler",
      "Arash Harirpoush",
      "Yiming Xiao"
    ],
    "abstract": "Crucial in disease analysis and surgical planning, manual segmentation of\nvolumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and\nchallenging to master, while fully automatic algorithms can benefit from user\nfeedback. Therefore, with the complementary power of the latest radiological AI\nfoundation models and virtual reality (VR)'s intuitive data interaction, we\npropose SAMIRA, a novel conversational AI agent that assists users with\nlocalizing, segmenting, and visualizing 3D medical concepts in VR. Through\nspeech-based interaction, the agent helps users understand radiological\nfeatures, locate clinical targets, and generate segmentation masks that can be\nrefined with just a few point prompts. The system also supports true-to-scale\n3D visualization of segmented pathology to enhance patient-specific anatomical\nunderstanding. Furthermore, to determine the optimal interaction paradigm under\nnear-far attention-switching for refining segmentation masks in an immersive,\nhuman-in-the-loop workflow, we compare VR controller pointing, head pointing,\nand eye tracking as input modes. With a user study, evaluations demonstrated a\nhigh usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as\nstrong support for the proposed VR system's guidance, training potential, and\nintegration of AI in radiological segmentation tasks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07214v2",
    "published_date": "2025-05-12 03:47:05 UTC",
    "updated_date": "2025-05-15 05:47:33 UTC"
  },
  {
    "arxiv_id": "2505.07896v1",
    "title": "Bridging Large Language Models and Single-Cell Transcriptomics in Dissecting Selective Motor Neuron Vulnerability",
    "authors": [
      "Douglas Jiang",
      "Zilin Dai",
      "Luxuan Zhang",
      "Qiyi Yu",
      "Haoqi Sun",
      "Feng Tian"
    ],
    "abstract": "Understanding cell identity and function through single-cell level sequencing\ndata remains a key challenge in computational biology. We present a novel\nframework that leverages gene-specific textual annotations from the NCBI Gene\ndatabase to generate biologically contextualized cell embeddings. For each cell\nin a single-cell RNA sequencing (scRNA-seq) dataset, we rank genes by\nexpression level, retrieve their NCBI Gene descriptions, and transform these\ndescriptions into vector embedding representations using large language models\n(LLMs). The models used include OpenAI text-embedding-ada-002,\ntext-embedding-3-small, and text-embedding-3-large (Jan 2024), as well as\ndomain-specific models BioBERT and SciBERT. Embeddings are computed via an\nexpression-weighted average across the top N most highly expressed genes in\neach cell, providing a compact, semantically rich representation. This\nmultimodal strategy bridges structured biological data with state-of-the-art\nlanguage modeling, enabling more interpretable downstream applications such as\ncell-type clustering, cell vulnerability dissection, and trajectory inference.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07896v1",
    "published_date": "2025-05-12 03:39:33 UTC",
    "updated_date": "2025-05-12 03:39:33 UTC"
  },
  {
    "arxiv_id": "2505.07895v1",
    "title": "Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks",
    "authors": [
      "Jiafan Li",
      "Jiaqi Zhu",
      "Liang Chang",
      "Yilin Li",
      "Miaomiao Li",
      "Yang Wang",
      "Hongan Wang"
    ],
    "abstract": "Nowadays, numerous online platforms can be described as multi-modal\nheterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's\nproduct review networks. Accurately categorizing nodes within these networks is\ncrucial for analyzing the corresponding entities, which requires effective\nrepresentation learning on nodes. However, existing multi-modal fusion methods\noften adopt either early fusion strategies which may lose the unique\ncharacteristics of individual modalities, or late fusion approaches overlooking\nthe cross-modal guidance in GNN-based information propagation. In this paper,\nwe propose a novel model for node classification in MMHNs, named Heterogeneous\nGraph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node\nrepresentations by capturing the mutual influence of multiple modalities during\nthe information propagation process, within the framework of heterogeneous\ngraph transformer. Specifically, a nested inter-modal attention mechanism is\nintegrated into the inter-node attention to achieve adaptive multi-modal\nfusion, and modality alignment is also taken into account to encourage the\npropagation among nodes with consistent similarities across all modalities.\nMoreover, an attention loss is augmented to mitigate the impact of missing\nmodalities. Extensive experiments validate the superiority of the model in the\nnode classification task, providing an innovative view to handle multi-modal\ndata, especially when accompanied with network structures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07895v1",
    "published_date": "2025-05-12 02:59:46 UTC",
    "updated_date": "2025-05-12 02:59:46 UTC"
  },
  {
    "arxiv_id": "2505.08808v1",
    "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction",
    "authors": [
      "Anqing Jiang",
      "Jinhao Chai",
      "Yu Gao",
      "Yiru Wang",
      "Yuwen Heng",
      "Zhigang Sun",
      "Hao Sun",
      "Zezhong Zhao",
      "Li Sun",
      "Jian Zhou",
      "Lijuan Zhu",
      "Shugong Xu",
      "Hao Zhao"
    ],
    "abstract": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08808v1",
    "published_date": "2025-05-12 02:26:58 UTC",
    "updated_date": "2025-05-12 02:26:58 UTC"
  },
  {
    "arxiv_id": "2505.07178v1",
    "title": "Accountability of Generative AI: Exploring a Precautionary Approach for \"Artificially Created Nature\"",
    "authors": [
      "Yuri Nakao"
    ],
    "abstract": "The rapid development of generative artificial intelligence (AI) technologies\nraises concerns about the accountability of sociotechnical systems. Current\ngenerative AI systems rely on complex mechanisms that make it difficult for\neven experts to fully trace the reasons behind the outputs. This paper first\nexamines existing research on AI transparency and accountability and argues\nthat transparency is not a sufficient condition for accountability but can\ncontribute to its improvement. We then discuss that if it is not possible to\nmake generative AI transparent, generative AI technology becomes ``artificially\ncreated nature'' in a metaphorical sense, and suggest using the precautionary\nprinciple approach to consider AI risks. Finally, we propose that a platform\nfor citizen participation is needed to address the risks of generative AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07178v1",
    "published_date": "2025-05-12 02:10:55 UTC",
    "updated_date": "2025-05-12 02:10:55 UTC"
  },
  {
    "arxiv_id": "2505.08807v1",
    "title": "Security of Internet of Agents: Attacks and Countermeasures",
    "authors": [
      "Yuntao Wang",
      "Yanghe Pan",
      "Shaolong Guo",
      "Zhou Su"
    ],
    "abstract": "With the rise of large language and vision-language models, AI agents have\nevolved into autonomous, interactive systems capable of perception, reasoning,\nand decision-making. As they proliferate across virtual and physical domains,\nthe Internet of Agents (IoA) has emerged as a key infrastructure for enabling\nscalable and secure coordination among heterogeneous agents. This survey offers\na comprehensive examination of the security and privacy landscape in IoA\nsystems. We begin by outlining the IoA architecture and its distinct\nvulnerabilities compared to traditional networks, focusing on four critical\naspects: identity authentication threats, cross-agent trust issues, embodied\nsecurity, and privacy risks. We then review existing and emerging defense\nmechanisms and highlight persistent challenges. Finally, we identify open\nresearch directions to advance the development of resilient and\nprivacy-preserving IoA ecosystems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 5 figures, 3 tables, submitted to IEEE OJCS",
    "pdf_url": "http://arxiv.org/pdf/2505.08807v1",
    "published_date": "2025-05-12 02:04:57 UTC",
    "updated_date": "2025-05-12 02:04:57 UTC"
  },
  {
    "arxiv_id": "2505.07176v1",
    "title": "Internet of Agents: Fundamentals, Applications, and Challenges",
    "authors": [
      "Yuntao Wang",
      "Shaolong Guo",
      "Yanghe Pan",
      "Zhou Su",
      "Fahao Chen",
      "Tom H. Luan",
      "Peng Li",
      "Jiawen Kang",
      "Dusit Niyato"
    ],
    "abstract": "With the rapid proliferation of large language models and vision-language\nmodels, AI agents have evolved from isolated, task-specific systems into\nautonomous, interactive entities capable of perceiving, reasoning, and acting\nwithout human intervention. As these agents proliferate across virtual and\nphysical environments, from virtual assistants to embodied robots, the need for\na unified, agent-centric infrastructure becomes paramount. In this survey, we\nintroduce the Internet of Agents (IoA) as a foundational framework that enables\nseamless interconnection, dynamic discovery, and collaborative orchestration\namong heterogeneous agents at scale. We begin by presenting a general IoA\narchitecture, highlighting its hierarchical organization, distinguishing\nfeatures relative to the traditional Internet, and emerging applications. Next,\nwe analyze the key operational enablers of IoA, including capability\nnotification and discovery, adaptive communication protocols, dynamic task\nmatching, consensus and conflict-resolution mechanisms, and incentive models.\nFinally, we identify open research directions toward building resilient and\ntrustworthy IoA ecosystems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "22 pages,10 figures, 8 tables. Submitted to IEEE TCCN",
    "pdf_url": "http://arxiv.org/pdf/2505.07176v1",
    "published_date": "2025-05-12 02:04:37 UTC",
    "updated_date": "2025-05-12 02:04:37 UTC"
  },
  {
    "arxiv_id": "2505.07171v1",
    "title": "ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion",
    "authors": [
      "Jeongho Kim",
      "Chanyeong Heo",
      "Jaehee Jung"
    ],
    "abstract": "Knowledge Graphs (KGs), composed of triples in the form of (head, relation,\ntail) and consisting of entities and relations, play a key role in information\nretrieval systems such as question answering, entity search, and\nrecommendation. In real-world KGs, although many entities exist, the relations\nexhibit a long-tail distribution, which can hinder information retrieval\nperformance. Previous few-shot knowledge graph completion studies focused\nexclusively on the positive triple information that exists in the graph or,\nwhen negative triples were incorporated, used them merely as a signal to\nindicate incorrect triples. To overcome this limitation, we propose\nRelation-Based Conditional Diffusion with Attention Pooling (ReCDAP). First,\nnegative triples are generated by randomly replacing the tail entity in the\nsupport set. By conditionally incorporating positive information in the KG and\nnon-existent negative information into the diffusion process, the model\nseparately estimates the latent distributions for positive and negative\nrelations. Moreover, including an attention pooler enables the model to\nleverage the differences between positive and negative cases explicitly.\nExperiments on two widely used datasets demonstrate that our method outperforms\nexisting approaches, achieving state-of-the-art performance. The code is\navailable at https://github.com/hou27/ReCDAP-FKGC.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by SIGIR 2025, 5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2505.07171v1",
    "published_date": "2025-05-12 01:49:52 UTC",
    "updated_date": "2025-05-12 01:49:52 UTC"
  }
]