[
  {
    "arxiv_id": "2505.08827v2",
    "title": "RLSR: Reinforcement Learning from Self Reward",
    "authors": [
      "Toby Simonds",
      "Kevin Lopez",
      "Akira Yoshiyama",
      "Dominique Garmier"
    ],
    "abstract": "Large language models can generate solutions to complex problems, but training them with reinforcement learning typically requires verifiable rewards that are expensive to create and not possible for all domains. We demonstrate that LLMs can effectively self-improve through self-judging without reference solutions, leveraging the inherent asymmetry between generating and verifying solutions. Our experiments show that models can provide reliable reward signals without ground truth answers, enabling reinforcement learning in domains where verifiable rewards are impractical. By implementing self-judging across Countdown puzzles and integration problems, we achieve performance comparable to formal verification without ground truth solutions. Most notably, Qwen 2.5 7B DeepSeek Distilled trained with self-rewards qualifies for the prestigious MIT Integration Bee competition, performance through self-supervised improvement. When combined with synthetic question generation, we establish a complete self-improvement loop where models generate practice problems, solve them, and evaluate their own performance without any external validation. Our findings demonstrate that LLM judges can provide effective reward signals for training, unlocking reinforcement learning in countless domains previously limited by reward engineering challenges. This work represents a significant step toward autonomous AI systems that continuously improve through self-directed learning rather than human-guided training, potentially accelerating progress across domains where training data is scarce or evaluation is complex.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08827v2",
    "published_date": "2025-05-12 23:51:04 UTC",
    "updated_date": "2025-08-06 23:51:16 UTC"
  },
  {
    "arxiv_id": "2505.08124v2",
    "title": "SLAG: Scalable Language-Augmented Gaussian Splatting",
    "authors": [
      "Laszlo Szilagyi",
      "Francis Engelmann",
      "Jeannette Bohg"
    ],
    "abstract": "Language-augmented scene representations hold great promise for large-scale robotics applications such as search-and-rescue, smart cities, and mining. Many of these scenarios are time-sensitive, requiring rapid scene encoding while also being data-intensive, necessitating scalable solutions. Deploying these representations on robots with limited computational resources further adds to the challenge. To address this, we introduce SLAG, a multi-GPU framework for language-augmented Gaussian splatting that enhances the speed and scalability of embedding large scenes. Our method integrates 2D visual-language model features into 3D scenes using SAM and CLIP. Unlike prior approaches, SLAG eliminates the need for a loss function to compute per-Gaussian language embeddings. Instead, it derives embeddings from 3D Gaussian scene parameters via a normalized weighted average, enabling highly parallelized scene encoding. Additionally, we introduce a vector database for efficient embedding storage and retrieval. Our experiments show that SLAG achieves an 18 times speedup in embedding computation on a 16-GPU setup compared to OpenGaussian, while preserving embedding quality on the ScanNet and LERF datasets. For more details, visit our project website: https://slag-project.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08124v2",
    "published_date": "2025-05-12 23:32:24 UTC",
    "updated_date": "2025-08-17 18:16:21 UTC"
  },
  {
    "arxiv_id": "2505.08123v1",
    "title": "JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections",
    "authors": [
      "Qing Wu",
      "Hongjiang Wei",
      "Jingyi Yu",
      "S. Kevin Zhou",
      "Yuyao Zhang"
    ],
    "abstract": "Multi-material decomposition (MMD) enables quantitative reconstruction of tissue compositions in the human body, supporting a wide range of clinical applications. However, traditional MMD typically requires spectral CT scanners and pre-measured X-ray energy spectra, significantly limiting clinical applicability. To this end, various methods have been developed to perform MMD using conventional (i.e., single-energy, SE) CT systems, commonly referred to as SEMMD. Despite promising progress, most SEMMD methods follow a two-step image decomposition pipeline, which first reconstructs monochromatic CT images using algorithms such as FBP, and then performs decomposition on these images. The initial reconstruction step, however, neglects the energy-dependent attenuation of human tissues, introducing severe nonlinear beam hardening artifacts and noise into the subsequent decomposition. This paper proposes JSover, a fundamentally reformulated one-step SEMMD framework that jointly reconstructs multi-material compositions and estimates the energy spectrum directly from SECT projections. By explicitly incorporating physics-informed spectral priors into the SEMMD process, JSover accurately simulates a virtual spectral CT system from SE acquisitions, thereby improving the reliability and accuracy of decomposition. Furthermore, we introduce implicit neural representation (INR) as an unsupervised deep learning solver for representing the underlying material maps. The inductive bias of INR toward continuous image patterns constrains the solution space and further enhances estimation quality. Extensive experiments on both simulated and real CT datasets show that JSover outperforms state-of-the-art SEMMD methods in accuracy and computational efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.08123v1",
    "published_date": "2025-05-12 23:32:21 UTC",
    "updated_date": "2025-05-12 23:32:21 UTC"
  },
  {
    "arxiv_id": "2505.22673v1",
    "title": "Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion",
    "authors": [
      "Wasif Khan",
      "Kyle B. See",
      "Simon Kato",
      "Ziqian Huang",
      "Amy Lazarte",
      "Kyle Douglas",
      "Xiangyang Lou",
      "Teng J. Peng",
      "Dhanashree Rajderkar",
      "John Rees",
      "Pina Sanelli",
      "Amita Singh",
      "Ibrahim Tuna",
      "Christina A. Wilson",
      "Ruogu Fang"
    ],
    "abstract": "Perfusion imaging is extensively utilized to assess hemodynamic status and tissue perfusion in various organs. Computed tomography perfusion (CTP) imaging plays a key role in the early assessment and planning of stroke treatment. While CTP provides essential perfusion parameters to identify abnormal blood flow in the brain, the use of contrast agents in CTP can lead to allergic reactions and adverse side effects, along with costing USD 4.9 billion worldwide in 2022. To address these challenges, we propose a novel deep learning framework called Multitask Automated Generation of Intermodal CT perfusion maps (MAGIC). This framework combines generative artificial intelligence and physiological information to map non-contrast computed tomography (CT) imaging to multiple contrast-free CTP imaging maps. We demonstrate enhanced image fidelity by incorporating physiological characteristics into the loss terms. Our network was trained and validated using CT image data from patients referred for stroke at UF Health and demonstrated robustness to abnormalities in brain perfusion activity. A double-blinded study was conducted involving seven experienced neuroradiologists and vascular neurologists. This study validated MAGIC's visual quality and diagnostic accuracy showing favorable performance compared to clinical perfusion imaging with intravenous contrast injection. Overall, MAGIC holds great promise in revolutionizing healthcare by offering contrast-free, cost-effective, and rapid perfusion imaging.",
    "categories": [
      "q-bio.TO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.TO",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2505.22673v1",
    "published_date": "2025-05-12 22:58:55 UTC",
    "updated_date": "2025-05-12 22:58:55 UTC"
  },
  {
    "arxiv_id": "2505.08106v1",
    "title": "Are LLMs complicated ethical dilemma analyzers?",
    "authors": [
      "Jiashen",
      "Du",
      "Jesse Yao",
      "Allen Liu",
      "Zhekai Zhang"
    ],
    "abstract": "One open question in the study of Large Language Models (LLMs) is whether they can emulate human ethical reasoning and act as believable proxies for human judgment. To investigate this, we introduce a benchmark dataset comprising 196 real-world ethical dilemmas and expert opinions, each segmented into five structured components: Introduction, Key Factors, Historical Theoretical Perspectives, Resolution Strategies, and Key Takeaways. We also collect non-expert human responses for comparison, limited to the Key Factors section due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini, Claude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric framework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine similarity, and Universal Sentence Encoder similarity. Metric weights are computed through an inversion-based ranking alignment and pairwise AHP analysis, enabling fine-grained comparison of model outputs to expert responses. Our results show that LLMs generally outperform non-expert humans in lexical and structural alignment, with GPT-4o-mini performing most consistently across all sections. However, all models struggle with historical grounding and proposing nuanced resolution strategies, which require contextual abstraction. Human responses, while less structured, occasionally achieve comparable semantic similarity, suggesting intuitive moral reasoning. These findings highlight both the strengths and current limitations of LLMs in ethical decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "CS194-280 Advanced LLM Agents project. Project page: https://github.com/ALT-JS/ethicaLLM",
    "pdf_url": "https://arxiv.org/pdf/2505.08106v1",
    "published_date": "2025-05-12 22:35:07 UTC",
    "updated_date": "2025-05-12 22:35:07 UTC"
  },
  {
    "arxiv_id": "2507.18640v1",
    "title": "How good are humans at detecting AI-generated images? Learnings from an experiment",
    "authors": [
      "Thomas Roca",
      "Anthony Cintron Roman",
      "Jehú Torres Vega",
      "Marcelo Duarte",
      "Pengce Wang",
      "Kevin White",
      "Amit Misra",
      "Juan Lavista Ferres"
    ],
    "abstract": "As AI-powered image generation improves, a key question is how well human beings can differentiate between \"real\" and AI-generated or modified images. Using data collected from the online game \"Real or Not Quiz.\", this study investigates how effectively people can distinguish AI-generated images from real ones. Participants viewed a randomized set of real and AI-generated images, aiming to identify their authenticity. Analysis of approximately 287,000 image evaluations by over 12,500 global participants revealed an overall success rate of only 62\\%, indicating a modest ability, slightly above chance. Participants were most accurate with human portraits but struggled significantly with natural and urban landscapes. These results highlight the inherent challenge humans face in distinguishing AI-generated visual content, particularly images without obvious artifacts or stylistic cues. This study stresses the need for transparency tools, such as watermarks and robust AI detection tools to mitigate the risks of misinformation arising from AI-generated content",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18640v1",
    "published_date": "2025-05-12 21:55:13 UTC",
    "updated_date": "2025-05-12 21:55:13 UTC"
  },
  {
    "arxiv_id": "2505.08088v2",
    "title": "Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories",
    "authors": [
      "Rabia Yasa Kostas",
      "Kahraman Kostas"
    ],
    "abstract": "Indoor positioning systems (IPSs) are increasingly vital for location-based services in complex multi-storey environments. This study proposes a novel graph-based approach for floor separation using Wi-Fi fingerprint trajectories, addressing the challenge of vertical localization in indoor settings. We construct a graph where nodes represent Wi-Fi fingerprints, and edges are weighted by signal similarity and contextual transitions. Node2Vec is employed to generate low-dimensional embeddings, which are subsequently clustered using K-means to identify distinct floors. Evaluated on the Huawei University Challenge 2021 dataset, our method outperforms traditional community detection algorithms, achieving an accuracy of 68.97\\%, an F1-score of 61.99\\%, and an Adjusted Rand Index of 57.19\\%. By publicly releasing the preprocessed dataset and implementation code, this work contributes to advancing research in indoor positioning. The proposed approach demonstrates robustness to signal noise and architectural complexities, offering a scalable solution for floor-level localization.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08088v2",
    "published_date": "2025-05-12 21:46:36 UTC",
    "updated_date": "2025-06-13 15:48:03 UTC"
  },
  {
    "arxiv_id": "2505.08825v1",
    "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning",
    "authors": [
      "Pedro Antonio Alarcon Granadeno",
      "Theodore Chambers",
      "Jane Cleland-Huang"
    ],
    "abstract": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon gas leak (2015) demonstrate the urgent need for rapid and reliable plume tracing algorithms to protect public health and the environment. Traditional methods, such as gradient-based or biologically inspired approaches, often fail in realistic, turbulent conditions. To address these challenges, we present a Multi-Agent Reinforcement Learning (MARL) algorithm designed for localizing multiple airborne pollution sources using a swarm of small uncrewed aerial systems (sUAS). Our method models the problem as a Partially Observable Markov Game (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific Double Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical action-observation pairs, effectively approximating latent states. Unlike prior work, we use a general-purpose simulation environment based on the Gaussian Plume Model (GPM), incorporating realistic elements such as a three-dimensional environment, sensor noise, multiple interacting agents, and multiple plume sources. The incorporation of action histories as part of the inputs further enhances the adaptability of our model in complex, partially observable environments. Extensive simulations show that our algorithm significantly outperforms conventional approaches. Specifically, our model allows agents to explore only 1.29\\% of the environment to successfully locate pollution sources.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "13 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.08825v1",
    "published_date": "2025-05-12 21:33:15 UTC",
    "updated_date": "2025-05-12 21:33:15 UTC"
  },
  {
    "arxiv_id": "2505.08082v2",
    "title": "Fréchet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids",
    "authors": [
      "Yuting Cai",
      "Shaohuai Liu",
      "Chao Tian",
      "Le Xie"
    ],
    "abstract": "Generative artificial intelligence (AI) models in smart grids have advanced significantly in recent years due to their ability to generate large amounts of synthetic data, which would otherwise be difficult to obtain in the real world due to confidentiality constraints. A key challenge in utilizing such synthetic data is how to assess the data quality produced from such generative models. Traditional Euclidean distance-based metrics only reflect pair-wise relations between two individual samples, and could fail in evaluating quality differences between groups of synthetic datasets. In this work, we propose a novel metric based on the Fréchet Distance (FD) estimated between two datasets in a learned feature space. The proposed method evaluates the quality of generation from a distributional perspective. Empirical results demonstrate the superiority of the proposed metric across timescales and models, enhancing the reliability of data-driven decision-making in smart grid operations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08082v2",
    "published_date": "2025-05-12 21:32:23 UTC",
    "updated_date": "2025-10-23 20:54:25 UTC"
  },
  {
    "arxiv_id": "2505.08080v2",
    "title": "Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders",
    "authors": [
      "Dong Shu",
      "Xuansheng Wu",
      "Haiyan Zhao",
      "Mengnan Du",
      "Ninghao Liu"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have recently emerged as powerful tools for interpreting and steering the internal representations of large language models (LLMs). However, conventional approaches to analyzing SAEs typically rely solely on input-side activations, without considering the causal influence between each latent feature and the model's output. This work is built on two key hypotheses: (1) activated latents do not contribute equally to the construction of the model's output, and (2) only latents with high causal influence are effective for model steering. To validate these hypotheses, we propose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method that identifies the most influential latents by incorporating output-side gradient information.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2025 Main",
    "pdf_url": "https://arxiv.org/pdf/2505.08080v2",
    "published_date": "2025-05-12 21:29:12 UTC",
    "updated_date": "2025-09-23 16:43:51 UTC"
  },
  {
    "arxiv_id": "2505.08078v1",
    "title": "What Matters for Batch Online Reinforcement Learning in Robotics?",
    "authors": [
      "Perry Dong",
      "Suvir Mirchandani",
      "Dorsa Sadigh",
      "Chelsea Finn"
    ],
    "abstract": "The ability to learn from large batches of autonomously collected data for policy improvement -- a paradigm we refer to as batch online reinforcement learning -- holds the promise of enabling truly scalable robot learning by significantly reducing the need for human effort of data collection while getting benefits from self-improvement. Yet, despite the promise of this paradigm, it remains challenging to achieve due to algorithms not being able to learn effectively from the autonomous data. For example, prior works have applied imitation learning and filtered imitation learning methods to the batch online RL problem, but these algorithms often fail to efficiently improve from the autonomously collected data or converge quickly to a suboptimal point. This raises the question of what matters for effective batch online RL in robotics. Motivated by this question, we perform a systematic empirical study of three axes -- (i) algorithm class, (ii) policy extraction methods, and (iii) policy expressivity -- and analyze how these axes affect performance and scaling with the amount of autonomous data. Through our analysis, we make several observations. First, we observe that the use of Q-functions to guide batch online RL significantly improves performance over imitation-based methods. Building on this, we show that an implicit method of policy extraction -- via choosing the best action in the distribution of the policy -- is necessary over traditional policy extraction methods from offline RL. Next, we show that an expressive policy class is preferred over less expressive policy classes. Based on this analysis, we propose a general recipe for effective batch online RL. We then show a simple addition to the recipe of using temporally-correlated noise to obtain more diversity results in further performance gains. Our recipe obtains significantly better performance and scaling compared to prior methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08078v1",
    "published_date": "2025-05-12 21:24:22 UTC",
    "updated_date": "2025-05-12 21:24:22 UTC"
  },
  {
    "arxiv_id": "2505.08073v2",
    "title": "Explainable Reinforcement Learning Agents Using World Models",
    "authors": [
      "Madhuri Singh",
      "Amal Alabdulkarim",
      "Gennie Mansi",
      "Mark O. Riedl"
    ],
    "abstract": "Explainable AI (XAI) systems have been proposed to help people understand how AI systems produce outputs and behaviors. Explainable Reinforcement Learning (XRL) has an added complexity due to the temporal nature of sequential decision-making. Further, non-AI experts do not necessarily have the ability to alter an agent or its policy. We introduce a technique for using World Models to generate explanations for Model-Based Deep RL agents. World Models predict how the world will change when actions are performed, allowing for the generation of counterfactual trajectories. However, identifying what a user wanted the agent to do is not enough to understand why the agent did something else. We augment Model-Based RL agents with a Reverse World Model, which predicts what the state of the world should have been for the agent to prefer a given counterfactual action. We show that explanations that show users what the world should have been like significantly increase their understanding of the agent policy. We hypothesize that our explanations can help users learn how to control the agents execution through by manipulating the environment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by Workshop on Explainable Artificial Intelligence (XAI) at IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08073v2",
    "published_date": "2025-05-12 21:18:31 UTC",
    "updated_date": "2025-08-18 01:05:06 UTC"
  },
  {
    "arxiv_id": "2505.08823v1",
    "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits",
    "authors": [
      "Cody Steinmetz",
      "Gavin Childress",
      "Aaron Herbst",
      "Gavin Jones",
      "Jasdeep Singh",
      "Eli Vang",
      "Keagan Weinstock"
    ],
    "abstract": "Large language models (LLMs) have transformed natural-language processing, yet their scale makes real-world deployment costly. Post-training quantization reduces memory and computation but often degrades accuracy, while quantization-aware training can recover performance at the cost of extra training. Pushing quantization to the ternary (2-bit) regime yields even larger savings but is notoriously unstable. Building on recent work showing that a bias-free, RMS-normalized Transformer with straight-through estimation can reach 1.58-bit precision, we demonstrate that simply inserting RMS normalization before every linear projection and applying a gradual, layer-wise quantization schedule stably fine-tunes full-precision checkpoints into ternary LLMs. Our approach matches or surpasses more elaborate knowledge-distillation pipelines on standard language-modeling benchmarks without adding model complexity. These results indicate that careful normalization alone can close much of the accuracy gap between ternary and full-precision LLMs, making ultra-low-bit inference practical.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08823v1",
    "published_date": "2025-05-12 21:14:29 UTC",
    "updated_date": "2025-05-12 21:14:29 UTC"
  },
  {
    "arxiv_id": "2505.08064v1",
    "title": "Justified Evidence Collection for Argument-based AI Fairness Assurance",
    "authors": [
      "Alpay Sabuncuoglu",
      "Christopher Burr",
      "Carsten Maple"
    ],
    "abstract": "It is well recognised that ensuring fair AI systems is a complex sociotechnical challenge, which requires careful deliberation and continuous oversight across all stages of a system's lifecycle, from defining requirements to model deployment and deprovisioning. Dynamic argument-based assurance cases, which present structured arguments supported by evidence, have emerged as a systematic approach to evaluating and mitigating safety risks and hazards in AI-enabled system development and have also been extended to deal with broader normative goals such as fairness and explainability. This paper introduces a systems-engineering-driven framework, supported by software tooling, to operationalise a dynamic approach to argument-based assurance in two stages. In the first stage, during the requirements planning phase, a multi-disciplinary and multi-stakeholder team define goals and claims to be established (and evidenced) by conducting a comprehensive fairness governance process. In the second stage, a continuous monitoring interface gathers evidence from existing artefacts (e.g. metrics from automated tests), such as model, data, and use case documentation, to support these arguments dynamically. The framework's effectiveness is demonstrated through an illustrative case study in finance, with a focus on supporting fairness-related arguments.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "The paper is accepted for ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT '25)",
    "pdf_url": "https://arxiv.org/pdf/2505.08064v1",
    "published_date": "2025-05-12 21:05:33 UTC",
    "updated_date": "2025-05-12 21:05:33 UTC"
  },
  {
    "arxiv_id": "2505.08054v2",
    "title": "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning",
    "authors": [
      "Zhehao Zhang",
      "Weijie Xu",
      "Fanyou Wu",
      "Chandan K. Reddy"
    ],
    "abstract": "Safety alignment approaches in large language models (LLMs) often lead to the over-refusal of benign queries, significantly diminishing their utility in sensitive scenarios. To address this challenge, we introduce FalseReject, a comprehensive resource containing 16k seemingly toxic queries accompanied by structured responses across 44 safety-related categories. We propose a graph-informed adversarial multi-agent interaction framework to generate diverse and complex prompts, while structuring responses with explicit reasoning to aid models in accurately distinguishing safe from unsafe contexts. FalseReject includes training datasets tailored for both standard instruction-tuned models and reasoning-oriented models, as well as a human-annotated benchmark test set. Our extensive benchmarking on 29 state-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges. Empirical results demonstrate that supervised finetuning with FalseReject substantially reduces unnecessary refusals without compromising overall safety or general language capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at COLM 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08054v2",
    "published_date": "2025-05-12 20:45:25 UTC",
    "updated_date": "2025-07-15 10:03:15 UTC"
  },
  {
    "arxiv_id": "2505.08052v2",
    "title": "NAZM: Network Analysis of Zonal Metrics in Persian Poetic Tradition",
    "authors": [
      "Kourosh Shahnazari",
      "Seyed Moein Ayyoubzadeh",
      "Mohammadamin Fazli",
      "Mohammadali Keshtparvar"
    ],
    "abstract": "This study formalizes a computational model to simulate classical Persian poets' dynamics of influence through constructing a multi-dimensional similarity network. Using a rigorously curated dataset based on Ganjoor's corpus, we draw upon semantic, lexical, stylistic, thematic, and metrical features to demarcate each poet's corpus. Each is contained within weighted similarity matrices, which are then appended to generate an aggregate graph showing poet-to-poet influence. Further network investigation is carried out to identify key poets, style hubs, and bridging poets by calculating degree, closeness, betweenness, eigenvector, and Katz centrality measures. Further, for typological insight, we use the Louvain community detection algorithm to demarcate clusters of poets sharing both style and theme coherence, which correspond closely to acknowledged schools of literature like Sabk-e Hindi, Sabk-e Khorasani, and the Bazgasht-e Adabi phenomenon. Our findings provide a new data-driven view of Persian literature distinguished between canonical significance and interextual influence, thus highlighting relatively lesser-known figures who hold great structural significance. Combining computational linguistics with literary study, this paper produces an interpretable and scalable model for poetic tradition, enabling retrospective reflection as well as forward-looking research within digital humanities.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08052v2",
    "published_date": "2025-05-12 20:39:53 UTC",
    "updated_date": "2025-05-29 20:44:10 UTC"
  },
  {
    "arxiv_id": "2505.08049v1",
    "title": "Bias or Optimality? Disentangling Bayesian Inference and Learning Biases in Human Decision-Making",
    "authors": [
      "Prakhar Godara"
    ],
    "abstract": "Recent studies claim that human behavior in a two-armed Bernoulli bandit (TABB) task is described by positivity and confirmation biases, implying that humans do not integrate new information objectively. However, we find that even if the agent updates its belief via objective Bayesian inference, fitting the standard Q-learning model with asymmetric learning rates still recovers both biases. Bayesian inference cast as an effective Q-learning algorithm has symmetric, though decreasing, learning rates. We explain this by analyzing the stochastic dynamics of these learning systems using master equations. We find that both confirmation bias and unbiased but decreasing learning rates yield the same behavioral signatures. Finally, we propose experimental protocols to disentangle true cognitive biases from artifacts of decreasing learning rates.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08049v1",
    "published_date": "2025-05-12 20:36:43 UTC",
    "updated_date": "2025-05-12 20:36:43 UTC"
  },
  {
    "arxiv_id": "2505.08821v1",
    "title": "A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction",
    "authors": [
      "Meryem Altin Karagoz",
      "Marc D. Breton",
      "Anas El Fathi"
    ],
    "abstract": "Accurate blood glucose prediction can enable novel interventions for type 1 diabetes treatment, including personalized insulin and dietary adjustments. Although recent advances in transformer-based architectures have demonstrated the power of attention mechanisms in complex multivariate time series prediction, their potential for blood glucose (BG) prediction remains underexplored. We present a comparative analysis of transformer models for multi-horizon BG prediction, examining forecasts up to 4 hours and input history up to 1 week. The publicly available DCLP3 dataset (n=112) was split (80%-10%-10%) for training, validation, and testing, and the OhioT1DM dataset (n=12) served as an external test set. We trained networks with point-wise, patch-wise, series-wise, and hybrid embeddings, using CGM, insulin, and meal data. For short-term blood glucose prediction, Crossformer, a patch-wise transformer architecture, achieved a superior 30-minute prediction of RMSE (15.6 mg / dL on OhioT1DM). For longer-term predictions (1h, 2h, and 4h), PatchTST, another path-wise transformer, prevailed with the lowest RMSE (24.6 mg/dL, 36.1 mg/dL, and 46.5 mg/dL on OhioT1DM). In general, models that used tokenization through patches demonstrated improved accuracy with larger input sizes, with the best results obtained with a one-week history. These findings highlight the promise of transformer-based architectures for BG prediction by capturing and leveraging seasonal patterns in multivariate time-series data to improve accuracy.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "q-bio.QM",
    "comment": "7 pages, 2 figures, 1 table, 1st IFAC Workshop on Engineering Diabetes Technologies (EDT 2025)",
    "pdf_url": "https://arxiv.org/pdf/2505.08821v1",
    "published_date": "2025-05-12 20:22:44 UTC",
    "updated_date": "2025-05-12 20:22:44 UTC"
  },
  {
    "arxiv_id": "2505.08032v2",
    "title": "Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience",
    "authors": [
      "Seyed Bagher Hashemi Natanzi",
      "Zhicong Zhu",
      "Bo Tang"
    ],
    "abstract": "Adaptive beam switching is essential for mission-critical military and commercial 6G networks but faces major challenges from high carrier frequencies, user mobility, and frequent blockages. While existing machine learning (ML) solutions often focus on maximizing instantaneous throughput, this can lead to unstable policies with high signaling overhead. This paper presents an online Deep Reinforcement Learning (DRL) framework designed to learn an operationally stable policy. By equipping the DRL agent with an enhanced state representation that includes blockage history, and a stability-centric reward function, we enable it to prioritize long-term link quality over transient gains. Validated in a challenging 100-user scenario using the Sionna library, our agent achieves throughput comparable to a reactive Multi-Armed Bandit (MAB) baseline. Specifically, our proposed framework improves link stability by approximately 43% compared to a vanilla DRL approach, achieving operational reliability competitive with MAB while maintaining high data rates. This work demonstrates that by reframing the optimization goal towards operational stability, DRL can deliver efficient, reliable, and real-time beam management solutions for next-generation mission-critical networks.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08032v2",
    "published_date": "2025-05-12 19:59:05 UTC",
    "updated_date": "2025-12-03 03:45:41 UTC"
  },
  {
    "arxiv_id": "2505.08025v1",
    "title": "PRISM: Complete Online Decentralized Multi-Agent Pathfinding with Rapid Information Sharing using Motion Constraints",
    "authors": [
      "Hannah Lee",
      "Zachary Serlin",
      "James Motes",
      "Brendan Long",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "abstract": "We introduce PRISM (Pathfinding with Rapid Information Sharing using Motion Constraints), a decentralized algorithm designed to address the multi-task multi-agent pathfinding (MT-MAPF) problem. PRISM enables large teams of agents to concurrently plan safe and efficient paths for multiple tasks while avoiding collisions. It employs a rapid communication strategy that uses information packets to exchange motion constraint information, enhancing cooperative pathfinding and situational awareness, even in scenarios without direct communication. We prove that PRISM resolves and avoids all deadlock scenarios when possible, a critical challenge in decentralized pathfinding. Empirically, we evaluate PRISM across five environments and 25 random scenarios, benchmarking it against the centralized Conflict-Based Search (CBS) and the decentralized Token Passing with Task Swaps (TPTS) algorithms. PRISM demonstrates scalability and solution quality, supporting 3.4 times more agents than CBS and handling up to 2.5 times more tasks in narrow passage environments than TPTS. Additionally, PRISM matches CBS in solution quality while achieving faster computation times, even under low-connectivity conditions. Its decentralized design reduces the computational burden on individual agents, making it scalable for large environments. These results confirm PRISM's robustness, scalability, and effectiveness in complex and dynamic pathfinding scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "38 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.08025v1",
    "published_date": "2025-05-12 19:48:32 UTC",
    "updated_date": "2025-05-12 19:48:32 UTC"
  },
  {
    "arxiv_id": "2505.08021v3",
    "title": "The Correspondence Between Bounded Graph Neural Networks and Fragments of First-Order Logic",
    "authors": [
      "Bernardo Cuenca Grau",
      "Eva Feng",
      "Przemysław A. Wałęga"
    ],
    "abstract": "Graph Neural Networks (GNNs) address two key challenges in applying deep learning to graph-structured data: they handle varying size input graphs and ensure invariance under graph isomorphism. While GNNs have demonstrated broad applicability, understanding their expressive power remains an important question. In this paper, we propose GNN architectures that correspond precisely to prominent fragments of first-order logic (FO), including various modal logics as well as more expressive two-variable fragments. To establish these results, we apply methods from finite model theory of first-order and modal logics to the domain of graph representation learning. Our results provide a unifying framework for understanding the logical expressiveness of GNNs within FO.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.08021v3",
    "published_date": "2025-05-12 19:45:45 UTC",
    "updated_date": "2025-11-17 10:29:25 UTC"
  },
  {
    "arxiv_id": "2505.08004v1",
    "title": "Large Language Models and Arabic Content: A Review",
    "authors": [
      "Haneh Rhel",
      "Dmitri Roussinov"
    ],
    "abstract": "Over the past three years, the rapid advancement of Large Language Models (LLMs) has had a profound impact on multiple areas of Artificial Intelligence (AI), particularly in Natural Language Processing (NLP) across diverse languages, including Arabic. Although Arabic is considered one of the most widely spoken languages across 27 countries in the Arabic world and used as a second language in some other non-Arabic countries as well, there is still a scarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face various challenges due to the complexities of the Arabic language, including its rich morphology, intricate structure, and diverse writing standards, among other factors. Researchers have been actively addressing these challenges, demonstrating that pre-trained Large Language Models (LLMs) trained on multilingual corpora achieve significant success in various Arabic NLP tasks. This study provides an overview of using large language models (LLMs) for the Arabic language, highlighting early pre-trained Arabic Language models across various NLP applications and their ability to handle diverse Arabic content tasks and dialects. It also provides an overview of how techniques like finetuning and prompt engineering can enhance the performance of these models. Additionally, the study summarizes common Arabic benchmarks and datasets while presenting our observations on the persistent upward trend in the adoption of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Original language: English This paper has been submitted to the First International Conference on Artificial Intelligence and Generative AI (FICAILY 2025), and it has been accepted for presentation at FICAILY on 9-10/July 2025 and for publication in the Springer Nature. Number of pages: 16 Publication status Accepted/In press - 7 Apr 2025 https://www.gena-ai-libya2025.com/",
    "pdf_url": "https://arxiv.org/pdf/2505.08004v1",
    "published_date": "2025-05-12 19:09:12 UTC",
    "updated_date": "2025-05-12 19:09:12 UTC"
  },
  {
    "arxiv_id": "2505.08818v1",
    "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare",
    "authors": [
      "Amara Tariq",
      "Rimita Lahiri",
      "Charles Kahn",
      "Imon Banerjee"
    ],
    "abstract": "The intricate and multifaceted nature of vision language model (VLM) development, adaptation, and application necessitates the establishment of clear and standardized reporting protocols, particularly within the high-stakes context of healthcare. Defining these reporting standards is inherently challenging due to the diverse nature of studies involving VLMs, which vary significantly from the development of all new VLMs or finetuning for domain alignment to off-the-shelf use of VLM for targeted diagnosis and prediction tasks. In this position paper, we argue that traditional machine learning reporting standards and evaluation guidelines must be restructured to accommodate multiphase VLM studies; it also has to be organized for intuitive understanding of developers while maintaining rigorous standards for reproducibility. To facilitate community adoption, we propose a categorization framework for VLM studies and outline corresponding reporting standards that comprehensively address performance evaluation, data reporting protocols, and recommendations for manuscript composition. These guidelines are organized according to the proposed categorization scheme. Lastly, we present a checklist that consolidates reporting standards, offering a standardized tool to ensure consistency and quality in the publication of VLM-related research.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "15 pages, 2, tables, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.08818v1",
    "published_date": "2025-05-12 18:39:54 UTC",
    "updated_date": "2025-05-12 18:39:54 UTC"
  },
  {
    "arxiv_id": "2505.07985v2",
    "title": "Fair Play for Individuals, Foul Play for Groups? Auditing Anonymization's Impact on ML Fairness",
    "authors": [
      "Héber H. Arcolezi",
      "Mina Alishahi",
      "Adda-Akram Bendoukha",
      "Nesrine Kaaniche"
    ],
    "abstract": "Machine learning (ML) algorithms are heavily based on the availability of training data, which, depending on the domain, often includes sensitive information about data providers. This raises critical privacy concerns. Anonymization techniques have emerged as a practical solution to address these issues by generalizing features or suppressing data to make it more difficult to accurately identify individuals. Although recent studies have shown that privacy-enhancing technologies can influence ML predictions across different subgroups, thus affecting fair decision-making, the specific effects of anonymization techniques, such as $k$-anonymity, $\\ell$-diversity, and $t$-closeness, on ML fairness remain largely unexplored. In this work, we systematically audit the impact of anonymization techniques on ML fairness, evaluating both individual and group fairness. Our quantitative study reveals that anonymization can degrade group fairness metrics by up to fourfold. Conversely, similarity-based individual fairness metrics tend to improve under stronger anonymization, largely as a result of increased input homogeneity. By analyzing varying levels of anonymization across diverse privacy settings and data distributions, this study provides critical insights into the trade-offs between privacy, fairness, and utility, offering actionable guidelines for responsible AI development. Our code is publicly available at: https://github.com/hharcolezi/anonymity-impact-fairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "ECAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07985v2",
    "published_date": "2025-05-12 18:32:28 UTC",
    "updated_date": "2025-10-31 13:13:34 UTC"
  },
  {
    "arxiv_id": "2505.07973v1",
    "title": "Probabilistic approach to longitudinal response prediction: application to radiomics from brain cancer imaging",
    "authors": [
      "Isabella Cama",
      "Michele Piana",
      "Cristina Campi",
      "Sara Garbarino"
    ],
    "abstract": "Longitudinal imaging analysis tracks disease progression and treatment response over time, providing dynamic insights into treatment efficacy and disease evolution. Radiomic features extracted from medical imaging can support the study of disease progression and facilitate longitudinal prediction of clinical outcomes. This study presents a probabilistic model for longitudinal response prediction, integrating baseline features with intermediate follow-ups. The probabilistic nature of the model naturally allows to handle the instrinsic uncertainty of the longitudinal prediction of disease progression. We evaluate the proposed model against state-of-the-art disease progression models in both a synthetic scenario and using a brain cancer dataset. Results demonstrate that the approach is competitive against existing methods while uniquely accounting for uncertainty and controlling the growth of problem dimensionality, eliminating the need for data from intermediate follow-ups.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "21 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.07973v1",
    "published_date": "2025-05-12 18:15:24 UTC",
    "updated_date": "2025-05-12 18:15:24 UTC"
  },
  {
    "arxiv_id": "2505.07819v2",
    "title": "H$^3$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning",
    "authors": [
      "Yiyang Lu",
      "Yufeng Tian",
      "Zhecheng Yuan",
      "Xianbang Wang",
      "Pu Hua",
      "Zhengrong Xue",
      "Huazhe Xu"
    ],
    "abstract": "Visuomotor policy learning has witnessed substantial progress in robotic manipulation, with recent approaches predominantly relying on generative models to model the action distribution. However, these methods often overlook the critical coupling between visual perception and action prediction. In this work, we introduce $\\textbf{Triply-Hierarchical Diffusion Policy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework that explicitly incorporates hierarchical structures to strengthen the integration between visual features and action generation. H$^{3}$DP contains $\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes RGB-D observations based on depth information; (2) multi-scale visual representations that encode semantic features at varying levels of granularity; and (3) a hierarchically conditioned diffusion process that aligns the generation of coarse-to-fine actions with corresponding visual features. Extensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$ average relative improvement over baselines across $\\mathbf{44}$ simulation tasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual real-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07819v2",
    "published_date": "2025-05-12 17:59:43 UTC",
    "updated_date": "2025-06-17 08:36:51 UTC"
  },
  {
    "arxiv_id": "2505.07816v2",
    "title": "Graph neural networks and MSO",
    "authors": [
      "Veeti Ahvonen",
      "Damian Heiman",
      "Antti Kuusisto"
    ],
    "abstract": "We give an alternative proof for the existing result that recurrent graph neural networks working with reals have the same expressive power in restriction to monadic second-order logic MSO as the graded modal substitution calculus. The proof is based on constructing distributed automata that capture all MSO-definable node properties over trees. We also consider some variants of the acceptance conditions.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07816v2",
    "published_date": "2025-05-12 17:59:22 UTC",
    "updated_date": "2025-05-15 13:32:24 UTC"
  },
  {
    "arxiv_id": "2505.07813v1",
    "title": "DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies",
    "authors": [
      "Tony Tao",
      "Mohan Kumar Srirama",
      "Jason Jingzhou Liu",
      "Kenneth Shaw",
      "Deepak Pathak"
    ],
    "abstract": "Large-scale, diverse robot datasets have emerged as a promising path toward enabling dexterous manipulation policies to generalize to novel environments, but acquiring such datasets presents many challenges. While teleoperation provides high-fidelity datasets, its high cost limits its scalability. Instead, what if people could use their own hands, just as they do in everyday life, to collect data? In DexWild, a diverse team of data collectors uses their hands to collect hours of interactions across a multitude of environments and objects. To record this data, we create DexWild-System, a low-cost, mobile, and easy-to-use device. The DexWild learning framework co-trains on both human and robot demonstrations, leading to improved performance compared to training on each dataset individually. This combination results in robust robot policies capable of generalizing to novel environments, tasks, and embodiments with minimal additional robot-specific data. Experimental results demonstrate that DexWild significantly improves performance, achieving a 68.5% success rate in unseen environments-nearly four times higher than policies trained with robot data only-and offering 5.8x better cross-embodiment generalization. Video results, codebases, and instructions at https://dexwild.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "In RSS 2025. Website at https://dexwild.github.io",
    "pdf_url": "https://arxiv.org/pdf/2505.07813v1",
    "published_date": "2025-05-12 17:59:05 UTC",
    "updated_date": "2025-05-12 17:59:05 UTC"
  },
  {
    "arxiv_id": "2505.07809v1",
    "title": "A Comparative Analysis of Static Word Embeddings for Hungarian",
    "authors": [
      "Máté Gedeon"
    ],
    "abstract": "This paper presents a comprehensive analysis of various static word embeddings for Hungarian, including traditional models such as Word2Vec, FastText, as well as static embeddings derived from BERT-based models using different extraction methods. We evaluate these embeddings on both intrinsic and extrinsic tasks to provide a holistic view of their performance. For intrinsic evaluation, we employ a word analogy task, which assesses the embeddings ability to capture semantic and syntactic relationships. Our results indicate that traditional static embeddings, particularly FastText, excel in this task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among the BERT-based models, the X2Static method for extracting static embeddings demonstrates superior performance compared to decontextualized and aggregate methods, approaching the effectiveness of traditional static embeddings. For extrinsic evaluation, we utilize a bidirectional LSTM model to perform Named Entity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results reveal that embeddings derived from dynamic models, especially those extracted using the X2Static method, outperform purely static embeddings. Notably, ELMo embeddings achieve the highest accuracy in both NER and POS tagging tasks, underscoring the benefits of contextualized representations even when used in a static form. Our findings highlight the continued relevance of static word embeddings in NLP applications and the potential of advanced extraction methods to enhance the utility of BERT-based models. This piece of research contributes to the understanding of embedding performance in the Hungarian language and provides valuable insights for future developments in the field. The training scripts, evaluation codes, restricted vocabulary, and extracted embeddings will be made publicly available to support further research and reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07809v1",
    "published_date": "2025-05-12 17:57:11 UTC",
    "updated_date": "2025-05-12 17:57:11 UTC"
  },
  {
    "arxiv_id": "2505.07802v2",
    "title": "Improving Trajectory Stitching with Flow Models",
    "authors": [
      "Reece O'Mahoney",
      "Wanming Yu",
      "Ioannis Havoutis"
    ],
    "abstract": "Generative models have shown great promise as trajectory planners, given their affinity to modeling complex distributions and guidable inference process. Previous works have successfully applied these in the context of robotic manipulation but perform poorly when the required solution does not exist as a complete trajectory within the training set. We identify that this is a result of being unable to plan via stitching, and subsequently address the architectural and dataset choices needed to remedy this. On top of this, we propose a novel addition to the training and inference procedures to both stabilize and enhance these capabilities. We demonstrate the efficacy of our approach by generating plans with out of distribution boundary conditions and performing obstacle avoidance on the Franka Panda in simulation and on real hardware. In both of these tasks our method performs significantly better than the baselines and is able to avoid obstacles up to four times as large.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07802v2",
    "published_date": "2025-05-12 17:50:10 UTC",
    "updated_date": "2025-06-03 16:45:05 UTC"
  },
  {
    "arxiv_id": "2505.07796v2",
    "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
    "authors": [
      "Xingjin Wang",
      "Howe Tissue",
      "Lu Wang",
      "Linjing Li",
      "Daniel Dajun Zeng"
    ],
    "abstract": "Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML2025 (Oral)",
    "pdf_url": "https://arxiv.org/pdf/2505.07796v2",
    "published_date": "2025-05-12 17:47:32 UTC",
    "updated_date": "2025-06-19 10:38:17 UTC"
  },
  {
    "arxiv_id": "2505.07793v2",
    "title": "Overflow Prevention Enhances Long-Context Recurrent LLMs",
    "authors": [
      "Assaf Ben-Kish",
      "Itamar Zimerman",
      "M. Jehanzeb Mirza",
      "Lior Wolf",
      "James Glass",
      "Leonid Karlinsky",
      "Raja Giryes"
    ],
    "abstract": "A recent trend in LLMs is developing recurrent sub-quadratic models that improve long-context processing efficiency. We investigate leading large long-context models, focusing on how their fixed-size recurrent memory affects their performance. Our experiments reveal that, even when these models are trained for extended contexts, their use of long contexts remains underutilized. Specifically, we demonstrate that a chunk-based inference procedure, which identifies and processes only the most relevant portion of the input can mitigate recurrent memory failures and be effective for many long-context tasks: On LongBench, our method improves the overall performance of Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%, RecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this simple approach also leads to state-of-the-art results in the challenging LongBench v2 benchmark, showing competitive performance with equivalent size Transformers. Furthermore, our findings raise questions about whether recurrent models genuinely exploit long-range dependencies, as our single-chunk strategy delivers stronger performance - even in tasks that presumably require cross-context relations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Official Implementation: https://github.com/assafbk/OPRM",
    "pdf_url": "https://arxiv.org/pdf/2505.07793v2",
    "published_date": "2025-05-12 17:45:05 UTC",
    "updated_date": "2025-09-08 20:57:22 UTC"
  },
  {
    "arxiv_id": "2505.07775v1",
    "title": "Must Read: A Systematic Survey of Computational Persuasion",
    "authors": [
      "Nimet Beyza Bozdag",
      "Shuhaib Mehri",
      "Xiaocheng Yang",
      "Hyeonjeong Ha",
      "Zirui Cheng",
      "Esin Durmus",
      "Jiaxuan You",
      "Heng Ji",
      "Gokhan Tur",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "Persuasion is a fundamental aspect of communication, influencing decision-making across diverse contexts, from everyday conversations to high-stakes scenarios such as politics, marketing, and law. The rise of conversational AI systems has significantly expanded the scope of persuasion, introducing both opportunities and risks. AI-driven persuasion can be leveraged for beneficial applications, but also poses threats through manipulation and unethical influence. Moreover, AI systems are not only persuaders, but also susceptible to persuasion, making them vulnerable to adversarial attacks and bias reinforcement. Despite rapid advancements in AI-generated persuasive content, our understanding of what makes persuasion effective remains limited due to its inherently subjective and context-dependent nature. In this survey, we provide a comprehensive overview of computational persuasion, structured around three key perspectives: (1) AI as a Persuader, which explores AI-generated persuasive content and its applications; (2) AI as a Persuadee, which examines AI's susceptibility to influence and manipulation; and (3) AI as a Persuasion Judge, which analyzes AI's role in evaluating persuasive strategies, detecting manipulation, and ensuring ethical persuasion. We introduce a taxonomy for computational persuasion research and discuss key challenges, including evaluating persuasiveness, mitigating manipulative persuasion, and developing responsible AI-driven persuasive systems. Our survey outlines future research directions to enhance the safety, fairness, and effectiveness of AI-powered persuasion while addressing the risks posed by increasingly capable language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07775v1",
    "published_date": "2025-05-12 17:26:31 UTC",
    "updated_date": "2025-05-12 17:26:31 UTC"
  },
  {
    "arxiv_id": "2505.07773v4",
    "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving",
    "authors": [
      "Xinji Mai",
      "Haotian Xu",
      "Zhong-Zhi Li",
      "Xing W",
      "Weinong Wang",
      "Jian Hu",
      "Yingying Zhang",
      "Wenqiang Zhang"
    ],
    "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks requiring precise, verifiable computation. While Reinforcement Learning (RL) from outcome-based rewards enhances text-based reasoning, understanding how agents autonomously learn to leverage external tools like code execution remains crucial. We investigate RL from outcome-based rewards for Tool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously generate and execute Python code for mathematical problems without supervised tool-use examples. Our central contribution is we demonstrate that as RL training progresses, key metrics scale predictably. Specifically, we observe strong positive correlations where increased training steps lead to increases in the spontaneous code execution frequency, the average response length, and, critically, the final task accuracy. This suggests a quantifiable relationship between computational effort invested in training and the emergence of effective, tool-augmented reasoning strategies. We implement a robust framework featuring a decoupled code execution environment and validate our findings across standard RL algorithms and frameworks. Experiments show ZeroTIR significantly surpasses non-tool ZeroRL baselines on challenging math benchmarks. Our findings provide a foundational understanding of how autonomous tool use is acquired and scales within Agent RL, offering a reproducible benchmark for future studies. Code is released at \\href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\\_async\\_pipline}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07773v4",
    "published_date": "2025-05-12 17:23:34 UTC",
    "updated_date": "2025-08-20 12:20:55 UTC"
  },
  {
    "arxiv_id": "2505.07768v1",
    "title": "Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding",
    "authors": [
      "Yifeng Di",
      "Tianyi Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capability in code generation. However, LLM-generated code is still plagued with a wide range of functional errors, especially for complex programming tasks that LLMs have not seen before. Recent studies have shown that developers often struggle with inspecting and fixing incorrect code generated by LLMs, diminishing their productivity and trust in LLM-based code generation. Inspired by the mutual grounding theory in communication, we propose an interactive approach that leverages code comments as a medium for developers and LLMs to establish a shared understanding. Our approach facilitates iterative grounding by interleaving code generation, inline comment generation, and contextualized user feedback through editable comments to align generated code with developer intent. We evaluated our approach on two popular benchmarks and demonstrated that our approach significantly improved multiple state-of-the-art LLMs, e.g., 17.1% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we conducted a user study with 12 participants in comparison to two baselines: (1) interacting with GitHub Copilot, and (2) interacting with a multi-step code generation paradigm called Multi-Turn Program Synthesis. Participants completed the given programming tasks 16.7% faster and with 10.5% improvement in task success rate when using our approach. Both results show that interactively refining code comments enables the collaborative establishment of mutual grounding, leading to more accurate code generation and higher developer confidence.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to ICSE 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07768v1",
    "published_date": "2025-05-12 17:20:30 UTC",
    "updated_date": "2025-05-12 17:20:30 UTC"
  },
  {
    "arxiv_id": "2505.07759v1",
    "title": "\"I Apologize For Not Understanding Your Policy\": Exploring the Specification and Evaluation of User-Managed Access Control Policies by AI Virtual Assistants",
    "authors": [
      "Jennifer Mondragon",
      "Carlos Rubio-Medrano",
      "Gael Cruz",
      "Dvijesh Shastri"
    ],
    "abstract": "The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants (VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek has turned them into convenient interfaces for managing emerging technologies such as Smart Homes, Smart Cars, Electronic Health Records, by means of explicit commands,e.g., prompts, which can be even launched via voice, thus providing a very convenient interface for end-users. However, the proper specification and evaluation of User-Managed Access Control Policies (U-MAPs), the rules issued and managed by end-users to govern access to sensitive data and device functionality - within these VAs presents significant challenges, since such a process is crucial for preventing security vulnerabilities and privacy leaks without impacting user experience. This study provides an initial exploratory investigation on whether current publicly-available VAs can manage U-MAPs effectively across differing scenarios. By conducting unstructured to structured tests, we evaluated the comprehension of such VAs, revealing a lack of understanding in varying U-MAP approaches. Our research not only identifies key limitations, but offers valuable insights into how VAs can be further improved to manage complex authorization rules and adapt to dynamic changes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07759v1",
    "published_date": "2025-05-12 17:03:52 UTC",
    "updated_date": "2025-05-12 17:03:52 UTC"
  },
  {
    "arxiv_id": "2505.07757v1",
    "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture",
    "authors": [
      "Rintaro Ando"
    ],
    "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement (EG-MRSI) framework, a novel architecture that integrates introspective metacognition, emotion-based intrinsic motivation, and recursive self-modification into a unified theoretical system. The framework is explicitly capable of overwriting its own learning algorithm under formally bounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation, EG-MRSI introduces a differentiable intrinsic reward function driven by confidence, error, novelty, and cumulative success. This signal regulates both a metacognitive mapping and a self-modification operator constrained by provable safety mechanisms. We formally define the initial agent configuration, emotion-gradient dynamics, and RSI trigger conditions, and derive a reinforcement-compatible optimization objective that guides the agent's development trajectory. Meaning Density and Meaning Conversion Efficiency are introduced as quantifiable metrics of semantic learning, closing the gap between internal structure and predictive informativeness. This Part I paper establishes the single-agent theoretical foundations of EG-MRSI. Future parts will extend this framework to include safety certificates and rollback protocols (Part II), collective intelligence mechanisms (Part III), and feasibility constraints including thermodynamic and computational limits (Part IV). Together, the EG-MRSI series provides a rigorous, extensible foundation for open-ended and safe AGI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 3 figures. Part I of a four-part series (Parts II-IV forthcoming)",
    "pdf_url": "https://arxiv.org/pdf/2505.07757v1",
    "published_date": "2025-05-12 17:02:47 UTC",
    "updated_date": "2025-05-12 17:02:47 UTC"
  },
  {
    "arxiv_id": "2505.07755v1",
    "title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems",
    "authors": [
      "Tomasz Szydlo",
      "Viacheslaw Horbanow",
      "Dev Nandan Jha",
      "Shashikant Ilager",
      "Aleksander Slominski",
      "Rajiv Ranjan"
    ],
    "abstract": "Edge computing has emerged as a pivotal technology, offering significant advantages such as low latency, enhanced data security, and reduced reliance on centralized cloud infrastructure. These benefits are crucial for applications requiring real-time data processing or strict security measures. Despite these advantages, edge devices operating within edge clusters are often underutilized. This inefficiency is mainly due to the absence of a holistic performance profiling mechanism which can help dynamically adjust the desired system configuration for a given workload. Since edge computing environments involve a complex interplay between CPU frequency, power consumption, and application performance, a deeper understanding of these correlations is essential. By uncovering these relationships, it becomes possible to make informed decisions that enhance both computational efficiency and energy savings. To address this gap, this paper evaluates the power consumption and performance characteristics of a single processing node within an edge cluster using a synthetic microbenchmark by varying the workload size and CPU frequency. The results show how an optimal measure can lead to optimized usage of edge resources, given both performance and power consumption.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07755v1",
    "published_date": "2025-05-12 17:02:02 UTC",
    "updated_date": "2025-05-12 17:02:02 UTC"
  },
  {
    "arxiv_id": "2506.06288v1",
    "title": "DELPHYNE: A Pre-Trained Model for General and Financial Time Series",
    "authors": [
      "Xueying Ding",
      "Aakriti Mittal",
      "Achintya Gopal"
    ],
    "abstract": "Time-series data is a vital modality within data science communities. This is particularly valuable in financial applications, where it helps in detecting patterns, understanding market behavior, and making informed decisions based on historical data. Recent advances in language modeling have led to the rise of time-series pre-trained models that are trained on vast collections of datasets and applied to diverse tasks across financial domains. However, across financial applications, existing time-series pre-trained models have not shown boosts in performance over simple finance benchmarks in both zero-shot and fine-tuning settings. This phenomenon occurs because of a i) lack of financial data within the pre-training stage, and ii) the negative transfer effect due to inherently different time-series patterns across domains. Furthermore, time-series data is continuous, noisy, and can be collected at varying frequencies and with varying lags across different variables, making this data more challenging to model than languages. To address the above problems, we introduce a Pre-trained MoDEL for FINance TimE-series (Delphyne). Delphyne achieves competitive performance to existing foundation and full-shot models with few fine-tuning steps on publicly available datasets, and also shows superior performances on various financial tasks.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.06288v1",
    "published_date": "2025-05-12 16:53:29 UTC",
    "updated_date": "2025-05-12 16:53:29 UTC"
  },
  {
    "arxiv_id": "2505.07921v2",
    "title": "Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning",
    "authors": [
      "Qi Xu",
      "Junyang Zhu",
      "Dongdong Zhou",
      "Hao Chen",
      "Yang Liu",
      "Jiangrong Shen",
      "Qiang Zhang"
    ],
    "abstract": "Deep neural networks (DNNs) excel in computer vision tasks, especially, few-shot learning (FSL), which is increasingly important for generalizing from limited examples. However, DNNs are computationally expensive with scalability issues in real world. Spiking Neural Networks (SNNs), with their event-driven nature and low energy consumption, are particularly efficient in processing sparse and dynamic data, though they still encounter difficulties in capturing complex spatiotemporal features and performing accurate cross-class comparisons. To further enhance the performance and efficiency of SNNs in few-shot learning, we propose a few-shot learning framework based on SNNs, which combines a self-feature extractor module and a cross-feature contrastive module to refine feature representation and reduce power consumption. We apply the combination of temporal efficient training loss and InfoNCE loss to optimize the temporal dynamics of spike trains and enhance the discriminative power. Experimental results show that the proposed FSL-SNN significantly improves the classification performance on the neuromorphic dataset N-Omniglot, and also achieves competitive performance to ANNs on static datasets such as CUB and miniImageNet with low power consumption.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07921v2",
    "published_date": "2025-05-12 16:51:08 UTC",
    "updated_date": "2025-05-15 02:56:21 UTC"
  },
  {
    "arxiv_id": "2505.07728v1",
    "title": "Guiding Data Collection via Factored Scaling Curves",
    "authors": [
      "Lihan Zha",
      "Apurva Badithela",
      "Michael Zhang",
      "Justin Lidard",
      "Jeremy Bao",
      "Emily Zhou",
      "David Snyder",
      "Allen Z. Ren",
      "Dhruv Shah",
      "Anirudha Majumdar"
    ],
    "abstract": "Generalist imitation learning policies trained on large datasets show great promise for solving diverse manipulation tasks. However, to ensure generalization to different conditions, policies need to be trained with data collected across a large set of environmental factor variations (e.g., camera pose, table height, distractors) $-$ a prohibitively expensive undertaking, if done exhaustively. We introduce a principled method for deciding what data to collect and how much to collect for each factor by constructing factored scaling curves (FSC), which quantify how policy performance varies as data scales along individual or paired factors. These curves enable targeted data acquisition for the most influential factor combinations within a given budget. We evaluate the proposed method through extensive simulated and real-world experiments, across both training-from-scratch and fine-tuning settings, and show that it boosts success rates in real-world tasks in new environments by up to 26% over existing data-collection strategies. We further demonstrate how factored scaling curves can effectively guide data collection using an offline metric, without requiring real-world evaluation at scale.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://factored-data-scaling.github.io",
    "pdf_url": "https://arxiv.org/pdf/2505.07728v1",
    "published_date": "2025-05-12 16:36:35 UTC",
    "updated_date": "2025-05-12 16:36:35 UTC"
  },
  {
    "arxiv_id": "2505.07715v1",
    "title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras",
    "authors": [
      "Qi Xu",
      "Jie Deng",
      "Jiangrong Shen",
      "Biwu Chen",
      "Huajin Tang",
      "Gang Pan"
    ],
    "abstract": "Event-based object detection has gained increasing attention due to its advantages such as high temporal resolution, wide dynamic range, and asynchronous address-event representation. Leveraging these advantages, Spiking Neural Networks (SNNs) have emerged as a promising approach, offering low energy consumption and rich spatiotemporal dynamics. To further enhance the performance of event-based object detection, this study proposes a novel hybrid spike vision Transformer (HsVT) model. The HsVT model integrates a spatial feature extraction module to capture local and global features, and a temporal feature extraction module to model time dependencies and long-term patterns in event sequences. This combination enables HsVT to capture spatiotemporal features, improving its capability to handle complex event-based object detection tasks. To support research in this area, we developed and publicly released The Fall Detection Dataset as a benchmark for event-based object detection tasks. This dataset, captured using an event-based camera, ensures facial privacy protection and reduces memory usage due to the event representation format. We evaluated the HsVT model on GEN1 and Fall Detection datasets across various model sizes. Experimental results demonstrate that HsVT achieves significant performance improvements in event detection with fewer parameters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07715v1",
    "published_date": "2025-05-12 16:19:20 UTC",
    "updated_date": "2025-05-12 16:19:20 UTC"
  },
  {
    "arxiv_id": "2505.07711v1",
    "title": "Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations",
    "authors": [
      "Pranav Sinha",
      "Sumit Kumar Jha",
      "Sunny Raj"
    ],
    "abstract": "We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where quantum computers are limited by noisy gates, some of which are more error-prone than others and can render the final computation incomprehensible. Quantum circuit compilation algorithms attempt to minimize these noisy gates when mapping quantum algorithms onto quantum hardware but face computational challenges that restrict their application to circuits with no more than 5-6 qubits, necessitating the need to partition large circuits before the application of noisy quantum gate minimization algorithms. The existing generation of these algorithms is heuristic in nature and does not account for downstream gate minimization tasks. Large language models (LLMs) have the potential to change this and help improve quantum circuit partitions. This paper investigates the use of LLMs, such as Llama and Mistral, for partitioning quantum circuits by capitalizing on their abilities to understand and generate code, including QASM. Specifically, we teach LLMs to partition circuits using the quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through experimental evaluations, we show that careful fine-tuning of open source LLMs enables us to obtain an accuracy of 53.4% for the partition task while over-the-shelf LLMs are unable to correctly partition circuits, using standard 1-shot and few-shot training approaches.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "7 pages, 2 tables and 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.07711v1",
    "published_date": "2025-05-12 16:18:48 UTC",
    "updated_date": "2025-05-12 16:18:48 UTC"
  },
  {
    "arxiv_id": "2505.07701v1",
    "title": "Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications",
    "authors": [
      "Biel Tura Vecino",
      "Adam Gabryś",
      "Daniel Mątwicki",
      "Andrzej Pomirski",
      "Tom Iddon",
      "Marius Cotescu",
      "Jaime Lorenzo-Trueba"
    ],
    "abstract": "Recent works have shown that modelling raw waveform directly from text in an end-to-end (E2E) fashion produces more natural-sounding speech than traditional neural text-to-speech (TTS) systems based on a cascade or two-stage approach. However, current E2E state-of-the-art models are computationally complex and memory-consuming, making them unsuitable for real-time offline on-device applications in low-resource scenarios. To address this issue, we propose a Lightweight E2E-TTS (LE2E) model that generates high-quality speech requiring minimal computational resources. We evaluate the proposed model on the LJSpeech dataset and show that it achieves state-of-the-art performance while being up to $90\\%$ smaller in terms of model parameters and $10\\times$ faster in real-time-factor. Furthermore, we demonstrate that the proposed E2E training paradigm achieves better quality compared to an equivalent architecture trained in a two-stage approach. Our results suggest that LE2E is a promising approach for developing real-time, high quality, low-resource TTS applications for on-device applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Published as a conference paper at SSW 2023",
    "pdf_url": "https://arxiv.org/pdf/2505.07701v1",
    "published_date": "2025-05-12 16:10:15 UTC",
    "updated_date": "2025-05-12 16:10:15 UTC"
  },
  {
    "arxiv_id": "2505.07920v1",
    "title": "Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions",
    "authors": [
      "Daoze Zhang",
      "Zhijian Bao",
      "Sihang Du",
      "Zhiyi Zhao",
      "Kuangling Zhang",
      "Dezheng Bao",
      "Yang Yang"
    ],
    "abstract": "Peer review is a critical component of scientific progress in the fields like AI, but the rapid increase in submission volume has strained the reviewing system, which inevitably leads to reviewer shortages and declines review quality. Besides the growing research popularity, another key factor in this overload is the repeated resubmission of substandard manuscripts, largely due to the lack of effective tools for authors to self-evaluate their work before submission. Large Language Models (LLMs) show great promise in assisting both authors and reviewers, and their performance is fundamentally limited by the quality of the peer review data. However, existing peer review datasets face three major limitations: (1) limited data diversity, (2) inconsistent and low-quality data due to the use of revised rather than initial submissions, and (3) insufficient support for tasks involving rebuttal and reviewer-author interactions. To address these challenges, we introduce the largest consistency-ensured peer review and rebuttal dataset named Re^2, which comprises 19,926 initial submissions, 70,668 review comments, and 53,818 rebuttals from 24 conferences and 21 workshops on OpenReview. Moreover, the rebuttal and discussion stage is framed as a multi-turn conversation paradigm to support both traditional static review tasks and dynamic interactive LLM assistants, providing more practical guidance for authors to refine their manuscripts and helping alleviate the growing review burden. Our data and code are available in https://anonymous.4open.science/r/ReviewBench_anon/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "2 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.07920v1",
    "published_date": "2025-05-12 16:02:52 UTC",
    "updated_date": "2025-05-12 16:02:52 UTC"
  },
  {
    "arxiv_id": "2505.07693v1",
    "title": "Belief Injection for Epistemic Control in Linguistic State Space",
    "authors": [
      "Sebastian Dumbrava"
    ],
    "abstract": "This work introduces belief injection, a proactive epistemic control mechanism for artificial agents whose cognitive states are structured as dynamic ensembles of linguistic belief fragments. Grounded in the Semantic Manifold framework, belief injection directly incorporates targeted linguistic beliefs into an agent's internal cognitive state, influencing reasoning and alignment proactively rather than reactively. We delineate various injection strategies, such as direct, context-aware, goal-oriented, and reflective approaches, and contrast belief injection with related epistemic control mechanisms, notably belief filtering. Additionally, this work discusses practical applications, implementation considerations, ethical implications, and outlines promising directions for future research into cognitive governance using architecturally embedded belief injection.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.07693v1",
    "published_date": "2025-05-12 15:58:56 UTC",
    "updated_date": "2025-05-12 15:58:56 UTC"
  },
  {
    "arxiv_id": "2505.07686v2",
    "title": "S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models",
    "authors": [
      "Muzhi Dai",
      "Chenxu Yang",
      "Qingyi Si"
    ],
    "abstract": "As Test-Time Scaling emerges as an active research focus in the large language model community, advanced post-training methods increasingly emphasize extending chain-of-thought (CoT) generation length, thereby enhancing reasoning capabilities to approach Deepseek R1-like reasoning models. However, recent studies reveal that reasoning models (even Qwen3) consistently exhibit excessive thought redundancy in CoT generation. This overthinking issue arises from the inherent limitations of conventional outcome-reward reinforcement learning, which systematically overlooks the regulation of intermediate reasoning processes. This paper introduces Serial-Group Decaying-Reward Policy Optimization (S-GRPO), a novel reinforcement learning paradigm that enables models to implicitly evaluate the sufficiency of intermediate reasoning steps, thereby facilitating early exit in CoT generation. Unlike GRPO, which samples multiple possible reasoning paths in parallel (parallel group), S-GRPO only samples one reasoning path and serially selects multiple temporal positions from the path to exit thinking and directly generate answers (serial group). For correct answers within a serial group, rewards gradually decrease based on the exit positions along the reasoning path from front to back. This design encourages the model to produce more accurate and concise thoughts, while also incentivizing early thinking termination when appropriate. Empirical evaluations demonstrate that S-GRPO is compatible with state-of-the-art reasoning models, including Qwen3 and Deepseek-distill. Across diverse benchmarks such as GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond, S-GRPO achieves a substantial reduction in sequence length (35.4% - 61.1%) while simultaneously improving accuracy (absolute 0.72% - 6.08%).",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07686v2",
    "published_date": "2025-05-12 15:50:44 UTC",
    "updated_date": "2025-05-17 04:01:57 UTC"
  },
  {
    "arxiv_id": "2505.07683v3",
    "title": "Multimodal Cancer Modeling in the Age of Foundation Model Embeddings",
    "authors": [
      "Steven Song",
      "Morgan Borjigin-Wang",
      "Irene Madejski",
      "Robert L. Grossman"
    ],
    "abstract": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a large-scale reference dataset in cancer through its harmonized genomics, clinical, and imaging data. Numerous prior studies have developed bespoke deep learning models over TCGA for tasks such as cancer survival prediction. A modern paradigm in biomedical deep learning is the development of foundation models (FMs) to derive feature embeddings agnostic to a specific modeling task. Biomedical text especially has seen growing development of FMs. While TCGA contains free-text data as pathology reports, these have been historically underutilized. Here, we investigate the ability to train classical machine learning models over multimodal, zero-shot FM embeddings of cancer data. We demonstrate the ease and additive effect of multimodal fusion, outperforming unimodal models. Further, we show the benefit of including pathology report text and rigorously evaluate the effect of model-based text summarization and hallucination. Overall, we propose an embedding-centric approach to multimodal cancer modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "camera ready version for ML4H 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07683v3",
    "published_date": "2025-05-12 15:47:21 UTC",
    "updated_date": "2025-11-06 14:32:39 UTC"
  },
  {
    "arxiv_id": "2505.07675v2",
    "title": "Simple yet Effective Semi-supervised Knowledge Distillation from Vision-Language Models via Dual-Head Optimization",
    "authors": [
      "Seongjae Kang",
      "Dong Bok Lee",
      "Hyungjoon Jang",
      "Sung Ju Hwang"
    ],
    "abstract": "Semi-supervised learning (SSL) has emerged as a practical solution for addressing data scarcity challenges by leveraging unlabeled data. Recently, vision-language models (VLMs), pre-trained on massive image-text pairs, have demonstrated remarkable zero-/few-shot performance that often surpasses SSL approaches due to their exceptional generalization capabilities. This gap motivates us to question: how can we effectively harness the powerful generalization capabilities of VLMs into task-specific models? Knowledge distillation (KD) offers a natural framework for transferring VLM capabilities, but we identify that it suffers from gradient conflicts between supervised and distillation losses. To address this challenge, we propose Dual-Head Optimization (DHO), which introduces dual prediction heads for each distinct signal. We observe that DHO resolves gradient conflicts, enabling improved feature learning compared to single-head KD baselines, with practical benefits of minimal computational overhead and test-time hyperparameter tuning without retraining. Extensive experiments across 15 datasets show that DHO consistently outperforms KD baselines, often outperforming teacher models with smaller student models. DHO also achieves new state-of-the-art performance on both in-distribution ImageNet semi-supervised learning and out-of-distribution generalization across ImageNet variants. We publicly release our code and model checkpoints to facilitate future research at https://github.com/erjui/DHO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "38 pages, 17 figures, preprint",
    "pdf_url": "https://arxiv.org/pdf/2505.07675v2",
    "published_date": "2025-05-12 15:39:51 UTC",
    "updated_date": "2025-09-30 14:13:57 UTC"
  },
  {
    "arxiv_id": "2505.07672v3",
    "title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit",
    "authors": [
      "Arun S. Maiya"
    ],
    "abstract": "We present OnPrem$.$LLM, a Python-based toolkit for applying large language models (LLMs) to sensitive, non-public data in offline or restricted environments. The system is designed for privacy-preserving use cases and provides prebuilt pipelines for document processing and storage, retrieval-augmented generation (RAG), information extraction, summarization, classification, and prompt/output processing with minimal configuration. OnPrem$.$LLM supports multiple LLM backends -- including llama$.$cpp, Ollama, vLLM, and Hugging Face Transformers -- with quantized model support, GPU acceleration, and seamless backend switching. Although designed for fully local execution, OnPrem$.$LLM also supports integration with a wide range of cloud LLM providers when permitted, enabling hybrid deployments that balance performance with data control. A no-code web interface extends accessibility to non-technical users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.07672v3",
    "published_date": "2025-05-12 15:36:27 UTC",
    "updated_date": "2025-09-26 14:32:04 UTC"
  },
  {
    "arxiv_id": "2505.07671v1",
    "title": "Benchmarking Retrieval-Augmented Generation for Chemistry",
    "authors": [
      "Xianrui Zhong",
      "Bowen Jin",
      "Siru Ouyang",
      "Yanzhen Shen",
      "Qiao Jin",
      "Yin Fang",
      "Zhiyong Lu",
      "Jiawei Han"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for enhancing large language models (LLMs) with external knowledge, particularly in scientific domains that demand specialized and dynamic information. Despite its promise, the application of RAG in the chemistry domain remains underexplored, primarily due to the lack of high-quality, domain-specific corpora and well-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a comprehensive benchmark designed to systematically assess the effectiveness of RAG across a diverse set of chemistry-related tasks. The accompanying chemistry corpus integrates heterogeneous knowledge sources, including scientific literature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia entries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG toolkit that supports five retrieval algorithms and eight LLMs. Using ChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain -- achieving an average relative improvement of 17.4% over direct inference methods. We further conduct in-depth analyses on retriever architectures, corpus selection, and the number of retrieved passages, culminating in practical recommendations to guide future research and deployment of RAG systems in the chemistry domain. The code and data is available at https://chemrag.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07671v1",
    "published_date": "2025-05-12 15:34:45 UTC",
    "updated_date": "2025-05-12 15:34:45 UTC"
  },
  {
    "arxiv_id": "2506.01968v1",
    "title": "Efficient ANN-SNN Conversion with Error Compensation Learning",
    "authors": [
      "Chang Liu",
      "Jiangrong Shen",
      "Xuming Ran",
      "Mingkun Xu",
      "Qi Xu",
      "Yi Xu",
      "Gang Pan"
    ],
    "abstract": "Artificial neural networks (ANNs) have demonstrated outstanding performance in numerous tasks, but deployment in resource-constrained environments remains a challenge due to their high computational and memory requirements. Spiking neural networks (SNNs) operate through discrete spike events and offer superior energy efficiency, providing a bio-inspired alternative. However, current ANN-to-SNN conversion often results in significant accuracy loss and increased inference time due to conversion errors such as clipping, quantization, and uneven activation. This paper proposes a novel ANN-to-SNN conversion framework based on error compensation learning. We introduce a learnable threshold clipping function, dual-threshold neurons, and an optimized membrane potential initialization strategy to mitigate the conversion error. Together, these techniques address the clipping error through adaptive thresholds, dynamically reduce the quantization error through dual-threshold neurons, and minimize the non-uniformity error by effectively managing the membrane potential. Experimental results on CIFAR-10, CIFAR-100, ImageNet datasets show that our method achieves high-precision and ultra-low latency among existing conversion methods. Using only two time steps, our method significantly reduces the inference time while maintains competitive accuracy of 94.75% on CIFAR-10 dataset under ResNet-18 structure. This research promotes the practical application of SNNs on low-power hardware, making efficient real-time processing possible.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.01968v1",
    "published_date": "2025-05-12 15:31:34 UTC",
    "updated_date": "2025-05-12 15:31:34 UTC"
  },
  {
    "arxiv_id": "2505.07664v1",
    "title": "A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development",
    "authors": [
      "Werner Geyer",
      "Jessica He",
      "Daita Sarkar",
      "Michelle Brachman",
      "Chris Hammond",
      "Jennifer Heins",
      "Zahra Ashktorab",
      "Carlos Rosemberg",
      "Charlie Hill"
    ],
    "abstract": "The broad availability of generative AI offers new opportunities to support various work domains, including agile software development. Agile epics are a key artifact for product managers to communicate requirements to stakeholders. However, in practice, they are often poorly defined, leading to churn, delivery delays, and cost overruns. In this industry case study, we investigate opportunities for large language models (LLMs) to evaluate agile epic quality in a global company. Results from a user study with 17 product managers indicate how LLM evaluations could be integrated into their work practices, including perceived values and usage in improving their epics. High levels of satisfaction indicate that agile epics are a new, viable application of AI evaluations. However, our findings also outline challenges, limitations, and adoption barriers that can inform both practitioners and researchers on the integration of such evaluations into future agile work practices.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07664v1",
    "published_date": "2025-05-12 15:31:16 UTC",
    "updated_date": "2025-05-12 15:31:16 UTC"
  },
  {
    "arxiv_id": "2508.00827v4",
    "title": "Legal Knowledge Graph Foundations, Part I: URI-Addressable Abstract Works (LRMoo F1 to schema.org)",
    "authors": [
      "Hudson de Martim"
    ],
    "abstract": "Building upon a formal, event-centric model for the diachronic evolution of legal norms grounded in the IFLA Library Reference Model (LRMoo), this paper addresses the essential first step of publishing this model's foundational entity-the abstract legal Work (F1)-on the Semantic Web. We propose a detailed, property-by-property mapping of the LRMoo F1 Work to the widely adopted schema.org/Legislation vocabulary. Using Brazilian federal legislation from the Normas.leg.br portal as a practical case study, we demonstrate how to create interoperable, machine-readable descriptions via JSON-LD, focusing on stable URN identifiers, core metadata, and norm relationships. This structured mapping establishes a stable, URI-addressable anchor for each legal norm, creating a verifiable \"ground truth\". It provides the essential, interoperable foundation upon which subsequent layers of the model, such as temporal versions (Expressions) and internal components, can be built. By bridging formal ontology with web-native standards, this work paves the way for building deterministic and reliable Legal Knowledge Graphs (LKGs), overcoming the limitations of purely probabilistic models.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CY",
      "cs.IR"
    ],
    "primary_category": "cs.DL",
    "comment": "This version formalizes the LRMoo event-centric model for the legal lifecycle (enactment, publication). This provides a more precise and ontologically-grounded mapping to Schema.org, with a clearer case study and improved diagrams",
    "pdf_url": "https://arxiv.org/pdf/2508.00827v4",
    "published_date": "2025-05-12 15:11:11 UTC",
    "updated_date": "2025-10-02 15:15:20 UTC"
  },
  {
    "arxiv_id": "2505.07637v1",
    "title": "Chronocept: Instilling a Sense of Time in Machines",
    "authors": [
      "Krish Goel",
      "Sanskar Pandey",
      "KS Mahadevan",
      "Harsh Kumar",
      "Vishesh Khadaria"
    ],
    "abstract": "Human cognition is deeply intertwined with a sense of time, known as Chronoception. This sense allows us to judge how long facts remain valid and when knowledge becomes outdated. Despite progress in vision, language, and motor control, AI still struggles to reason about temporal validity. We introduce Chronocept, the first benchmark to model temporal validity as a continuous probability distribution over time. Using skew-normal curves fitted along semantically decomposed temporal axes, Chronocept captures nuanced patterns of emergence, decay, and peak relevance. It includes two datasets: Benchmark I (atomic facts) and Benchmark II (multi-sentence passages). Annotations show strong inter-annotator agreement (84% and 89%). Our baselines predict curve parameters - location, scale, and skewness - enabling interpretable, generalizable learning and outperforming classification-based approaches. Chronocept fills a foundational gap in AI's temporal reasoning, supporting applications in knowledge grounding, fact-checking, retrieval-augmented generation (RAG), and proactive agents. Code and data are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 8 figures, 18 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.07637v1",
    "published_date": "2025-05-12 15:07:32 UTC",
    "updated_date": "2025-05-12 15:07:32 UTC"
  },
  {
    "arxiv_id": "2505.07634v3",
    "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents",
    "authors": [
      "Jian Liu",
      "Xiongtao Shi",
      "Thai Duy Nguyen",
      "Haitian Zhang",
      "Tianxiang Zhang",
      "Wei Sun",
      "Yanjie Li",
      "Athanasios V. Vasilakos",
      "Giovanni Iacca",
      "Arshad Ali Khan",
      "Arvind Kumar",
      "Jae Won Cho",
      "Ajmal Mian",
      "Lihua Xie",
      "Erik Cambria",
      "Lin Wang"
    ],
    "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static, data-driven models to dynamic systems capable of perceiving and interacting with real-world environments. Despite advancements in pattern recognition and symbolic reasoning, current AI systems, such as large language models, remain disembodied, unable to physically engage with the world. This limitation has driven the rise of embodied AI, where autonomous agents, such as humanoid robots, must navigate and manipulate unstructured environments with human-like adaptability. At the core of this challenge lies the concept of Neural Brain, a central intelligence system designed to drive embodied agents with human-like adaptability. A Neural Brain must seamlessly integrate multimodal sensing and perception with cognitive capabilities. Achieving this also requires an adaptive memory system and energy-efficient hardware-software co-design, enabling real-time action in dynamic environments. This paper introduces a unified framework for the Neural Brain of embodied agents, addressing two fundamental challenges: (1) defining the core components of Neural Brain and (2) bridging the gap between static AI models and the dynamic adaptability required for real-world deployment. To this end, we propose a biologically inspired architecture that integrates multimodal active sensing, perception-cognition-action function, neuroplasticity-based memory storage and updating, and neuromorphic hardware/software optimization. Furthermore, we also review the latest research on embodied agents across these four aspects and analyze the gap between current AI systems and human intelligence. By synthesizing insights from neuroscience, we outline a roadmap towards the development of generalizable, autonomous agents capable of human-level intelligence in real-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "51 pages, 17 figures, 9 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.07634v3",
    "published_date": "2025-05-12 15:05:34 UTC",
    "updated_date": "2025-10-06 10:13:41 UTC"
  },
  {
    "arxiv_id": "2505.07917v2",
    "title": "Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation",
    "authors": [
      "Linus Stuhlmann",
      "Michael Alexander Saxer",
      "Jonathan Fürst"
    ],
    "abstract": "Biomedical question-answering (QA) systems require effective retrieval and generation components to ensure accuracy, efficiency, and scalability. This study systematically examines a Retrieval-Augmented Generation (RAG) system for biomedical QA, evaluating retrieval strategies and response time trade-offs. We first assess state-of-the-art retrieval methods, including BM25, BioBERT, MedCPT, and a hybrid approach, alongside common data stores such as Elasticsearch, MongoDB, and FAISS, on a ~10% subset of PubMed (2.4M documents) to measure indexing efficiency, retrieval latency, and retriever performance in the end-to-end RAG system. Based on these insights, we deploy the final RAG system on the full 24M PubMed corpus, comparing different retrievers' impact on overall performance. Evaluations of the retrieval depth show that retrieving 50 documents with BM25 before reranking with MedCPT optimally balances accuracy (0.90), recall (0.90), and response time (1.91s). BM25 retrieval time remains stable (82ms), while MedCPT incurs the main computational cost. These results highlight previously not well-known trade-offs in retrieval depth, efficiency, and scalability for biomedical QA. With open-source code, the system is fully reproducible and extensible.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Minor wording corrections and updated author contact information",
    "pdf_url": "https://arxiv.org/pdf/2505.07917v2",
    "published_date": "2025-05-12 14:51:47 UTC",
    "updated_date": "2026-01-13 17:00:37 UTC"
  },
  {
    "arxiv_id": "2505.07621v1",
    "title": "Bang for the Buck: Vector Search on Cloud CPUs",
    "authors": [
      "Leonardo Kuffo",
      "Peter Boncz"
    ],
    "abstract": "Vector databases have emerged as a new type of systems that support efficient querying of high-dimensional vectors. Many of these offer their database as a service in the cloud. However, the variety of available CPUs and the lack of vector search benchmarks across CPUs make it difficult for users to choose one. In this study, we show that CPU microarchitectures available in the cloud perform significantly differently across vector search scenarios. For instance, in an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per second (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the tables turn. However, when looking at the number of queries per dollar (QP$), Graviton3 is the best option for most indexes and quantization settings, even over Graviton4 (Table 1). With this work, we hope to guide users in getting the best \"bang for the buck\" when deploying vector search systems.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "To be published in Proceedings of 21st International Workshop on Data Management on New Hardware (DaMoN '25)",
    "pdf_url": "https://arxiv.org/pdf/2505.07621v1",
    "published_date": "2025-05-12 14:44:21 UTC",
    "updated_date": "2025-05-12 14:44:21 UTC"
  },
  {
    "arxiv_id": "2505.07615v2",
    "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models",
    "authors": [
      "Riccardo Passoni",
      "Francesca Ronchini",
      "Luca Comanducci",
      "Romain Serizel",
      "Fabio Antonacci"
    ],
    "abstract": "Text-to-audio models have recently emerged as a powerful technology for generating sound from textual descriptions. However, their high computational demands raise concerns about energy consumption and environmental impact. In this paper, we conduct an analysis of the energy usage of 7 state-of-the-art text-to-audio diffusion-based generative models, evaluating to what extent variations in generation parameters affect energy consumption at inference time. We also aim to identify an optimal balance between audio quality and energy consumption by considering Pareto-optimal solutions across all selected models. Our findings provide insights into the trade-offs between performance and environmental impact, contributing to the development of more efficient generative audio models.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at WASPAA 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07615v2",
    "published_date": "2025-05-12 14:36:47 UTC",
    "updated_date": "2025-07-16 17:59:28 UTC"
  },
  {
    "arxiv_id": "2505.07610v2",
    "title": "Concept-Level Explainability for Auditing & Steering LLM Responses",
    "authors": [
      "Kenza Amara",
      "Rita Sevastjanova",
      "Mennatallah El-Assady"
    ],
    "abstract": "As large language models (LLMs) become widely deployed, concerns about their safety and alignment grow. An approach to steer LLM behavior, such as mitigating biases or defending against jailbreaks, is to identify which parts of a prompt influence specific aspects of the model's output. Token-level attribution methods offer a promising solution, but still struggle in text generation, explaining the presence of each token in the output separately, rather than the underlying semantics of the entire LLM response. We introduce ConceptX, a model-agnostic, concept-level explainability method that identifies the concepts, i.e., semantically rich tokens in the prompt, and assigns them importance based on the outputs' semantic similarity. Unlike current token-level methods, ConceptX also offers to preserve context integrity through in-place token replacements and supports flexible explanation goals, e.g., gender bias. ConceptX enables both auditing, by uncovering sources of bias, and steering, by modifying prompts to shift the sentiment or reduce the harmfulness of LLM responses, without requiring retraining. Across three LLMs, ConceptX outperforms token-level methods like TokenSHAP in both faithfulness and human alignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for random edits and lower attack success rates from 0.463 to 0.242, outperforming attribution and paraphrasing baselines. While prompt engineering and self-explaining methods sometimes yield safer responses, ConceptX offers a transparent and faithful alternative for improving LLM safety and alignment, demonstrating the practical value of attribution-based explainability in guiding LLM behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 7 figures, Submission to Neurips 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07610v2",
    "published_date": "2025-05-12 14:31:51 UTC",
    "updated_date": "2025-05-19 14:00:52 UTC"
  },
  {
    "arxiv_id": "2505.07608v2",
    "title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining",
    "authors": [
      "LLM-Core Xiaomi",
      ":",
      "Bingquan Xia",
      "Bowen Shen",
      "Cici",
      "Dawei Zhu",
      "Di Zhang",
      "Gang Wang",
      "Hailin Zhang",
      "Huaqiu Liu",
      "Jiebao Xiao",
      "Jinhao Dong",
      "Liang Zhao",
      "Peidian Li",
      "Peng Wang",
      "Shihua Yu",
      "Shimao Chen",
      "Weikun Wang",
      "Wenhan Ma",
      "Xiangwei Deng",
      "Yi Huang",
      "Yifan Song",
      "Zihan Jiang",
      "Bowen Ye",
      "Can Cai",
      "Chenhong He",
      "Dong Zhang",
      "Duo Zhang",
      "Guoan Wang",
      "Hao Tian",
      "Haochen Zhao",
      "Heng Qu",
      "Hongshen Xu",
      "Jun Shi",
      "Kainan Bao",
      "Kai Fang",
      "Kang Zhou",
      "Kangyang Zhou",
      "Lei Li",
      "Menghang Zhu",
      "Nuo Chen",
      "Qiantong Wang",
      "Shaohui Liu",
      "Shicheng Li",
      "Shuhao Gu",
      "Shuhuai Ren",
      "Shuo Liu",
      "Sirui Deng",
      "Weiji Zhuang",
      "Weiwei Lv",
      "Wenyu Yang",
      "Xin Zhang",
      "Xing Yong",
      "Xing Zhang",
      "Xingchen Song",
      "Xinzhe Xu",
      "Xu Wang",
      "Yihan Yan",
      "Yu Tu",
      "Yuanyuan Tian",
      "Yudong Wang",
      "Yue Yu",
      "Zhenru Lin",
      "Zhichao Song",
      "Zihao Yue"
    ],
    "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing strategy to strengthen the base model's reasoning potential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional Multi-Token Prediction objective for enhanced performance and accelerated inference speed. During post-training, we curate a dataset of 130K verifiable mathematics and programming problems for reinforcement learning, integrating a test-difficulty-driven code-reward scheme to alleviate sparse-reward issues and employing strategic data resampling to stabilize training. Extensive evaluations show that MiMo-7B-Base possesses exceptional reasoning potential, outperforming even much larger 32B models. The final RL-tuned model, MiMo-7B-RL, achieves superior performance on mathematics, code and general reasoning tasks, surpassing the performance of OpenAI o1-mini. The model checkpoints are available at https://github.com/xiaomimimo/MiMo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07608v2",
    "published_date": "2025-05-12 14:30:11 UTC",
    "updated_date": "2025-06-05 11:49:09 UTC"
  },
  {
    "arxiv_id": "2505.07601v1",
    "title": "Characterizing the Investigative Methods of Fictional Detectives with Large Language Models",
    "authors": [
      "Edirlei Soares de Lima",
      "Marco A. Casanova",
      "Bruno Feijó",
      "Antonio L. Furtado"
    ],
    "abstract": "Detective fiction, a genre defined by its complex narrative structures and character-driven storytelling, presents unique challenges for computational narratology, a research field focused on integrating literary theory into automated narrative generation. While traditional literary studies have offered deep insights into the methods and archetypes of fictional detectives, these analyses often focus on a limited number of characters and lack the scalability needed for the extraction of unique traits that can be used to guide narrative generation methods. In this paper, we present an AI-driven approach for systematically characterizing the investigative methods of fictional detectives. Our multi-phase workflow explores the capabilities of 15 Large Language Models (LLMs) to extract, synthesize, and validate distinctive investigative traits of fictional detectives. This approach was tested on a diverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes, William Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin - capturing the distinctive investigative styles that define each character. The identified traits were validated against existing literary analyses and further tested in a reverse identification phase, achieving an overall accuracy of 91.43%, demonstrating the method's effectiveness in capturing the distinctive investigative approaches of each detective. This work contributes to the broader field of computational narratology by providing a scalable framework for character analysis, with potential applications in AI-driven interactive storytelling and automated narrative generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07601v1",
    "published_date": "2025-05-12 14:24:58 UTC",
    "updated_date": "2025-05-12 14:24:58 UTC"
  },
  {
    "arxiv_id": "2505.07596v1",
    "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent",
    "authors": [
      "Ziyang Huang",
      "Xiaowei Yuan",
      "Yiming Ju",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce hallucinations in Large Language Models (LLMs). While reinforcement learning (RL) can enable LLMs to act as search agents by activating retrieval capabilities, existing ones often underutilize their internal knowledge. This can lead to redundant retrievals, potential harmful knowledge conflicts, and increased inference latency. To address these limitations, an efficient and adaptive search agent capable of discerning optimal retrieval timing and synergistically integrating parametric (internal) and retrieved (external) knowledge is in urgent need. This paper introduces the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), which could indentify its own knowledge boundary and prioritize the utilization of internal knowledge, resorting to external search only when internal knowledge is deemed insufficient. This is achieved using a novel knowledge-boundary aware reward function and a knowledge-boundary aware training dataset. These are designed for internal-external knowledge synergy oriented RL, incentivizing the model to deliver accurate answers, minimize unnecessary retrievals, and encourage appropriate external searches when its own knowledge is lacking. Evaluations across multiple knowledge reasoning tasks demonstrate that IKEA significantly outperforms baseline methods, reduces retrieval frequency significantly, and exhibits robust generalization capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07596v1",
    "published_date": "2025-05-12 14:21:57 UTC",
    "updated_date": "2025-05-12 14:21:57 UTC"
  },
  {
    "arxiv_id": "2505.07591v1",
    "title": "A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models",
    "authors": [
      "Junjie Ye",
      "Caishuang Huang",
      "Zhuohan Chen",
      "Wenjie Fu",
      "Chenyuan Yang",
      "Leyi Yang",
      "Yilong Wu",
      "Peng Wang",
      "Meng Zhou",
      "Xiaolong Yang",
      "Tao Gui",
      "Qi Zhang",
      "Zhongchao Shi",
      "Jianping Fan",
      "Xuanjing Huang"
    ],
    "abstract": "Instruction following evaluates large language models (LLMs) on their ability to generate outputs that adhere to user-defined constraints. However, existing benchmarks often rely on templated constraint prompts, which lack the diversity of real-world usage and limit fine-grained performance assessment. To fill this gap, we propose a multi-dimensional constraint framework encompassing three constraint patterns, four constraint categories, and four difficulty levels. Building on this framework, we develop an automated instruction generation pipeline that performs constraint expansion, conflict detection, and instruction rewriting, yielding 1,200 code-verifiable instruction-following test samples. We evaluate 19 LLMs across seven model families and uncover substantial variation in performance across constraint forms. For instance, average performance drops from 77.67% at Level I to 32.96% at Level IV. Furthermore, we demonstrate the utility of our approach by using it to generate data for reinforcement learning, achieving substantial gains in instruction following without degrading general performance. In-depth analysis indicates that these gains stem primarily from modifications in the model's attention modules parameters, which enhance constraint recognition and adherence. Code and data are available in https://github.com/Junjie-Ye/MulDimIF.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07591v1",
    "published_date": "2025-05-12 14:16:55 UTC",
    "updated_date": "2025-05-12 14:16:55 UTC"
  },
  {
    "arxiv_id": "2505.13484v1",
    "title": "Evaluating Large Language Models for Real-World Engineering Tasks",
    "authors": [
      "Rene Heesch",
      "Sebastian Eilermann",
      "Alexander Windmann",
      "Alexander Diedrich",
      "Philipp Rosenthal",
      "Oliver Niggemann"
    ],
    "abstract": "Large Language Models (LLMs) are transformative not only for daily activities but also for engineering tasks. However, current evaluations of LLMs in engineering exhibit two critical shortcomings: (i) the reliance on simplified use cases, often adapted from examination materials where correctness is easily verifiable, and (ii) the use of ad hoc scenarios that insufficiently capture critical engineering competencies. Consequently, the assessment of LLMs on complex, real-world engineering problems remains largely unexplored. This paper addresses this gap by introducing a curated database comprising over 100 questions derived from authentic, production-oriented engineering scenarios, systematically designed to cover core competencies such as product design, prognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art LLMs, including both cloud-based and locally hosted instances, to systematically investigate their performance on complex engineering tasks. Our results show that LLMs demonstrate strengths in basic temporal and structural reasoning but struggle significantly with abstract reasoning, formal modeling, and context-sensitive engineering logic.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13484v1",
    "published_date": "2025-05-12 14:05:23 UTC",
    "updated_date": "2025-05-12 14:05:23 UTC"
  },
  {
    "arxiv_id": "2505.07581v3",
    "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models",
    "authors": [
      "Lei Wang",
      "Heyang Gao",
      "Xiaohe Bo",
      "Xu Chen",
      "Ji-Rong Wen"
    ],
    "abstract": "Leveraging large language model (LLM) based agents to simulate human social behaviors has recently gained significant attention. In this paper, we introduce a novel social simulator called YuLan-OneSim. Compared to previous works, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free scenario construction: Users can simply describe and refine their simulation scenarios through natural language interactions with our simulator. All simulation code is automatically generated, significantly reducing the need for programming expertise. (2) Comprehensive default scenarios: We implement 50 default simulation scenarios spanning 8 domains, including economics, sociology, politics, psychology, organization, demographics, law, and communication, broadening access for a diverse range of social researchers. (3) Evolvable simulation: Our simulator is capable of receiving external feedback and automatically fine-tuning the backbone LLMs, significantly enhancing the simulation quality. (4) Large-scale simulation: By developing a fully responsive agent framework and a distributed simulation architecture, our simulator can handle up to 100,000 agents, ensuring more stable and reliable simulation results. (5) AI social researcher: Leveraging the above features, we develop an AI social researcher. Users only need to propose a research topic, and the AI researcher will automatically analyze the input, construct simulation environments, summarize results, generate technical reports, review and refine the reports--completing the social science research loop. To demonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate the quality of the automatically generated scenarios, the reliability, efficiency, and scalability of the simulation process, as well as the performance of the AI social researcher.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07581v3",
    "published_date": "2025-05-12 14:05:17 UTC",
    "updated_date": "2025-08-26 08:03:56 UTC"
  },
  {
    "arxiv_id": "2505.07576v1",
    "title": "Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study",
    "authors": [
      "Manuel Barusco",
      "Francesco Borsatti",
      "Youssef Ben Khalifa",
      "Davide Dalle Pezze",
      "Gian Antonio Susto"
    ],
    "abstract": "Semiconductor manufacturing is a complex, multistage process. Automated visual inspection of Scanning Electron Microscope (SEM) images is indispensable for minimizing equipment downtime and containing costs. Most previous research considers supervised approaches, assuming a sufficient number of anomalously labeled samples. On the contrary, Visual Anomaly Detection (VAD), an emerging research domain, focuses on unsupervised learning, avoiding the costly defect collection phase while providing explanations of the predictions. We introduce a benchmark for VAD in the semiconductor domain by leveraging the MIIC dataset. Our results demonstrate the efficacy of modern VAD approaches in this field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07576v1",
    "published_date": "2025-05-12 13:56:59 UTC",
    "updated_date": "2025-05-12 13:56:59 UTC"
  },
  {
    "arxiv_id": "2505.07573v1",
    "title": "Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework",
    "authors": [
      "Sarah de Boer",
      "Hartmut Häntze",
      "Kiran Vaidhya Venkadesh",
      "Myrthe A. D. Buser",
      "Gabriel E. Humpire Mamani",
      "Lina Xu",
      "Lisa C. Adams",
      "Jawed Nawabi",
      "Keno K. Bressem",
      "Bram van Ginneken",
      "Mathias Prokop",
      "Alessa Hering"
    ],
    "abstract": "Kidney abnormality segmentation has important potential to enhance the clinical workflow, especially in settings requiring quantitative assessments. Kidney volume could serve as an important biomarker for renal diseases, with changes in volume correlating directly with kidney function. Currently, clinical practice often relies on subjective visual assessment for evaluating kidney size and abnormalities, including tumors and cysts, which are typically staged based on diameter, volume, and anatomical location. To support a more objective and reproducible approach, this research aims to develop a robust, thoroughly validated kidney abnormality segmentation algorithm, made publicly available for clinical and research use. We employ publicly available training datasets and leverage the state-of-the-art medical image segmentation framework nnU-Net. Validation is conducted using both proprietary and public test datasets, with segmentation performance quantified by Dice coefficient and the 95th percentile Hausdorff distance. Furthermore, we analyze robustness across subgroups based on patient sex, age, CT contrast phases, and tumor histologic subtypes. Our findings demonstrate that our segmentation algorithm, trained exclusively on publicly available data, generalizes effectively to external test sets and outperforms existing state-of-the-art models across all tested datasets. Subgroup analyses reveal consistent high performance, indicating strong robustness and reliability. The developed algorithm and associated code are publicly accessible at https://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "35 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.07573v1",
    "published_date": "2025-05-12 13:53:19 UTC",
    "updated_date": "2025-05-12 13:53:19 UTC"
  },
  {
    "arxiv_id": "2505.07911v1",
    "title": "Combining Bayesian Inference and Reinforcement Learning for Agent Decision Making: A Review",
    "authors": [
      "Chengmin Zhou",
      "Ville Kyrki",
      "Pasi Fränti",
      "Laura Ruotsalainen"
    ],
    "abstract": "Bayesian inference has many advantages in decision making of agents (e.g. robotics/simulative agent) over a regular data-driven black-box neural network: Data-efficiency, generalization, interpretability, and safety where these advantages benefit directly/indirectly from the uncertainty quantification of Bayesian inference. However, there are few comprehensive reviews to summarize the progress of Bayesian inference on reinforcement learning (RL) for decision making to give researchers a systematic understanding. This paper focuses on combining Bayesian inference with RL that nowadays is an important approach in agent decision making. To be exact, this paper discusses the following five topics: 1) Bayesian methods that have potential for agent decision making. First basic Bayesian methods and models (Bayesian rule, Bayesian learning, and Bayesian conjugate models) are discussed followed by variational inference, Bayesian optimization, Bayesian deep learning, Bayesian active learning, Bayesian generative models, Bayesian meta-learning, and lifelong Bayesian learning. 2) Classical combinations of Bayesian methods with model-based RL (with approximation methods), model-free RL, and inverse RL. 3) Latest combinations of potential Bayesian methods with RL. 4) Analytical comparisons of methods that combine Bayesian methods with RL with respect to data-efficiency, generalization, interpretability, and safety. 5) In-depth discussions in six complex problem variants of RL, including unknown reward, partial-observability, multi-agent, multi-task, non-linear non-Gaussian, and hierarchical RL problems and the summary of how Bayesian methods work in the data collection, data processing and policy learning stages of RL to pave the way for better agent decision-making strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07911v1",
    "published_date": "2025-05-12 13:34:50 UTC",
    "updated_date": "2025-05-12 13:34:50 UTC"
  },
  {
    "arxiv_id": "2505.07553v1",
    "title": "Towards Requirements Engineering for RAG Systems",
    "authors": [
      "Tor Sporsem",
      "Rasmus Ulfsnes"
    ],
    "abstract": "This short paper explores how a maritime company develops and integrates large-language models (LLM). Specifically by looking at the requirements engineering for Retrieval Augmented Generation (RAG) systems in expert settings. Through a case study at a maritime service provider, we demonstrate how data scientists face a fundamental tension between user expectations of AI perfection and the correctness of the generated outputs. Our findings reveal that data scientists must identify context-specific \"retrieval requirements\" through iterative experimentation together with users because they are the ones who can determine correctness. We present an empirical process model describing how data scientists practically elicited these \"retrieval requirements\" and managed system limitations. This work advances software engineering knowledge by providing insights into the specialized requirements engineering processes for implementing RAG systems in complex domain-specific applications.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to EASE 2025, 17-20 June, Istanbul, Turkey",
    "pdf_url": "https://arxiv.org/pdf/2505.07553v1",
    "published_date": "2025-05-12 13:30:44 UTC",
    "updated_date": "2025-05-12 13:30:44 UTC"
  },
  {
    "arxiv_id": "2505.07552v2",
    "title": "Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies",
    "authors": [
      "Efe Bozkir",
      "Christian Kosel",
      "Tina Seidel",
      "Enkelejda Kasneci"
    ],
    "abstract": "Teachers' visual attention and its distribution across the students in classrooms can constitute important implications for student engagement, achievement, and professional teacher training. Despite that, inferring the information about where and which student teachers focus on is not trivial. Mobile eye tracking can provide vital help to solve this issue; however, the use of mobile eye tracking alone requires a significant amount of manual annotations. To address this limitation, we present an automated processing pipeline concept that requires minimal manually annotated data to recognize which student the teachers focus on. To this end, we utilize state-of-the-art face detection models and face recognition feature embeddings to train face recognition models with transfer learning in the classroom context and combine these models with the teachers' gaze from mobile eye trackers. We evaluated our approach with data collected from four different classrooms, and our results show that while it is possible to estimate the visually focused students with reasonable performance in all of our classroom setups, U-shaped and small classrooms led to the best results with accuracies of approximately 0.7 and 0.9, respectively. While we did not evaluate our method for teacher-student interactions and focused on the validity of the technical approach, as our methodology does not require a vast amount of manually annotated data and offers a non-intrusive way of handling teachers' visual attention, it could help improve instructional strategies, enhance classroom management, and provide feedback for professional teacher development.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "Full paper at the Educational Data Mining (EDM) Conference 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07552v2",
    "published_date": "2025-05-12 13:30:30 UTC",
    "updated_date": "2025-09-25 07:41:50 UTC"
  },
  {
    "arxiv_id": "2505.07548v1",
    "title": "Noise Optimized Conditional Diffusion for Domain Adaptation",
    "authors": [
      "Lingkun Luo",
      "Shiqiang Hu",
      "Liming Chen"
    ],
    "abstract": "Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet the scarcity of High-Confidence Pseudo-Labeled Target Domain Samples (\\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical alignment, causing DA failures. To address this challenge, we propose \\textbf{N}oise \\textbf{O}ptimized \\textbf{C}onditional \\textbf{D}iffusion for \\textbf{D}omain \\textbf{A}daptation (\\textbf{NOCDDA}), which seamlessly integrates the generative capabilities of conditional diffusion models with the decision-making requirements of DA to achieve task-coupled optimization for efficient adaptation. For robust cross-domain consistency, we modify the DA classifier to align with the conditional diffusion classifier within a unified optimization framework, enabling forward training on noise-varying cross-domain samples. Furthermore, we argue that the conventional \\( \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) \\) initialization in diffusion models often generates class-confused hcpl-tds, compromising discriminative DA. To resolve this, we introduce a class-aware noise optimization strategy that refines sampling regions for reverse class-specific hcpl-tds generation, effectively enhancing cross-domain alignment. Extensive experiments across 5 benchmark datasets and 29 DA tasks demonstrate significant performance gains of \\textbf{NOCDDA} over 31 state-of-the-art methods, validating its robustness and effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures This work has been accepted by the International Joint Conference on Artificial Intelligence (IJCAI 2025)",
    "pdf_url": "https://arxiv.org/pdf/2505.07548v1",
    "published_date": "2025-05-12 13:28:31 UTC",
    "updated_date": "2025-05-12 13:28:31 UTC"
  },
  {
    "arxiv_id": "2505.07546v3",
    "title": "GRADA: Graph-based Reranking against Adversarial Documents Attack",
    "authors": [
      "Jingjie Zheng",
      "Aryo Pradipta Gema",
      "Giwon Hong",
      "Xuanli He",
      "Pasquale Minervini",
      "Youcheng Sun",
      "Qiongkai Xu"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large language models (LLMs) by integrating external knowledge from retrieved documents, thereby overcoming the limitations of models' static intrinsic knowledge. However, these systems are susceptible to adversarial attacks that manipulate the retrieval process by introducing documents that are adversarial yet semantically similar to the query. Notably, while these adversarial documents resemble the query, they exhibit weak similarity to benign documents in the retrieval set. Thus, we propose a simple yet effective Graph-based Reranking against Adversarial Document Attacks (GRADA) framework aiming at preserving retrieval quality while significantly reducing the success of adversaries. Our study evaluates the effectiveness of our approach through experiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b, Llama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with results from the Natural Questions dataset demonstrating up to an 80% reduction in attack success rates while maintaining minimal loss in accuracy.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07546v3",
    "published_date": "2025-05-12 13:27:35 UTC",
    "updated_date": "2025-09-18 01:20:24 UTC"
  },
  {
    "arxiv_id": "2505.07910v2",
    "title": "Tuning for Trustworthiness -- Balancing Performance and Explanation Consistency in Neural Network Optimization",
    "authors": [
      "Alexander Hinterleitner",
      "Thomas Bartz-Beielstein"
    ],
    "abstract": "Despite the growing interest in Explainable Artificial Intelligence (XAI), explainability is rarely considered during hyperparameter tuning or neural architecture optimization, where the focus remains primarily on minimizing predictive loss. In this work, we introduce the novel concept of XAI consistency, defined as the agreement among different feature attribution methods, and propose new metrics to quantify it. For the first time, we integrate XAI consistency directly into the hyperparameter tuning objective, creating a multi-objective optimization framework that balances predictive performance with explanation robustness. Implemented within the Sequential Parameter Optimization Toolbox (SPOT), our approach uses both weighted aggregation and desirability-based strategies to guide model selection. Through our proposed framework and supporting tools, we explore the impact of incorporating XAI consistency into the optimization process. This enables us to characterize distinct regions in the architecture configuration space: one region with poor performance and comparatively low interpretability, another with strong predictive performance but weak interpretability due to low \\gls{xai} consistency, and a trade-off region that balances both objectives by offering high interpretability alongside competitive performance. Beyond introducing this novel approach, our research provides a foundation for future investigations into whether models from the trade-off zone-balancing performance loss and XAI consistency-exhibit greater robustness by avoiding overfitting to training performance, thereby leading to more reliable predictions on out-of-distribution data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07910v2",
    "published_date": "2025-05-12 13:19:14 UTC",
    "updated_date": "2025-05-23 13:49:55 UTC"
  },
  {
    "arxiv_id": "2505.07534v1",
    "title": "The Human-Data-Model Interaction Canvas for Visual Analytics",
    "authors": [
      "Jürgen Bernard"
    ],
    "abstract": "Visual Analytics (VA) integrates humans, data, and models as key actors in insight generation and data-driven decision-making. This position paper values and reflects on 16 VA process models and frameworks and makes nine high-level observations that motivate a fresh perspective on VA. The contribution is the HDMI Canvas, a perspective to VA that complements the strengths of existing VA process models and frameworks. It systematically characterizes diverse roles of humans, data, and models, and how these actors benefit from and contribute to VA processes. The descriptive power of the HDMI Canvas eases the differentiation between a series of VA building blocks, rather than describing general VA principles only. The canvas includes modern human-centered methodologies, including human knowledge externalization and forms of feedback loops, while interpretable and explainable AI highlight model contributions beyond their conventional outputs. The HDMI Canvas has generative power, guiding the design of new VA processes and is optimized for external stakeholders, improving VA outreach, interdisciplinary collaboration, and user-centered design. The utility of the HDMI Canvas is demonstrated through two preliminary case studies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 5 figures, LaTeX; to appear at the 16th International EuroVis Workshop on Visual Analytics (EuroVA'25) as a position paper",
    "pdf_url": "https://arxiv.org/pdf/2505.07534v1",
    "published_date": "2025-05-12 13:15:31 UTC",
    "updated_date": "2025-05-12 13:15:31 UTC"
  },
  {
    "arxiv_id": "2505.07533v1",
    "title": "IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability",
    "authors": [
      "Ahmad Fall",
      "Federica Granese",
      "Alex Lence",
      "Dominique Fourer",
      "Blaise Hanczar",
      "Joe-Elie Salem",
      "Jean-Daniel Zucker",
      "Edi Prifti"
    ],
    "abstract": "Monitoring and analyzing electrocardiogram (ECG) signals, even under varying physiological conditions, including those influenced by physical activity, drugs and stress, is crucial to accurately assess cardiac health. However, current AI-based methods often fail to account for how these factors interact and alter ECG patterns, ultimately limiting their applicability in real-world settings. This study introduces IKrNet, a novel neural network model, which identifies drug-specific patterns in ECGs amidst certain physiological conditions. IKrNet's architecture incorporates spatial and temporal dynamics by using a convolutional backbone with varying receptive field size to capture spatial features. A bi-directional Long Short-Term Memory module is also employed to model temporal dependencies. By treating heart rate variability as a surrogate for physiological fluctuations, we evaluated IKrNet's performance across diverse scenarios, including conditions with physical stress, drug intake alone, and a baseline without drug presence. Our assessment follows a clinical protocol in which 990 healthy volunteers were administered 80mg of Sotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a life-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art models' accuracy and stability in varying physiological conditions, underscoring its clinical viability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07533v1",
    "published_date": "2025-05-12 13:14:47 UTC",
    "updated_date": "2025-05-12 13:14:47 UTC"
  },
  {
    "arxiv_id": "2505.07531v2",
    "title": "QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads",
    "authors": [
      "Muhammad Ahmad",
      "Khurram Mazher",
      "Saqib Akram",
      "Ahmad Tameem",
      "Saad Bin Nasir"
    ],
    "abstract": "We present QuantX: a tailored suite of recipes for LLM and VLM quantization. It is capable of quantizing down to 3-bit resolutions with minimal loss in performance. The quantization strategies in QuantX take into account hardware-specific constraints to achieve efficient dequantization during inference ensuring flexible trade-off between runtime speed, memory requirement and model accuracy. Our results demonstrate that QuantX achieves performance within 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for multiple end user tasks and outperforms recently published state-of-the-art quantization techniques. We further integrate one particular technique from QuantX into the popular Llama.cpp framework and show its feasibility in terms of runtime compared to the mainstream quantization techniques from Llama.cpp. Lastly, this manuscript provides insights into the LLM quantization process that motivated the range of recipes and options that are incorporated in QuantX.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07531v2",
    "published_date": "2025-05-12 13:13:06 UTC",
    "updated_date": "2025-09-12 12:03:22 UTC"
  },
  {
    "arxiv_id": "2505.07512v1",
    "title": "ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution",
    "authors": [
      "Xu Huang",
      "Weiwen Liu",
      "Xingshan Zeng",
      "Yuefeng Huang",
      "Xinlong Hao",
      "Yuxian Wang",
      "Yirong Zeng",
      "Chuhan Wu",
      "Yasheng Wang",
      "Ruiming Tang",
      "Defu Lian"
    ],
    "abstract": "The tool-using capability of large language models (LLMs) enables them to access up-to-date external information and handle complex tasks. Current approaches to enhancing this capability primarily rely on distilling advanced models by data synthesis. However, this method incurs significant costs associated with advanced model usage and often results in data compatibility issues, led by the high discrepancy in the knowledge scope between the advanced model and the target model. To address these challenges, we propose ToolACE-DEV, a self-improving framework for tool learning. First, we decompose the tool-learning objective into sub-tasks that enhance basic tool-making and tool-using abilities. Then, we introduce a self-evolving paradigm that allows lightweight models to self-improve, reducing reliance on advanced LLMs. Extensive experiments validate the effectiveness of our approach across models of varying scales and architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07512v1",
    "published_date": "2025-05-12 12:48:30 UTC",
    "updated_date": "2025-05-12 12:48:30 UTC"
  },
  {
    "arxiv_id": "2505.07511v1",
    "title": "MAIS: Memory-Attention for Interactive Segmentation",
    "authors": [
      "Mauricio Orbes-Arteaga",
      "Oeslle Lucena",
      "Sabastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "abstract": "Interactive medical segmentation reduces annotation effort by refining predictions through user feedback. Vision Transformer (ViT)-based models, such as the Segment Anything Model (SAM), achieve state-of-the-art performance using user clicks and prior masks as prompts. However, existing methods treat interactions as independent events, leading to redundant corrections and limited refinement gains. We address this by introducing MAIS, a Memory-Attention mechanism for Interactive Segmentation that stores past user inputs and segmentation states, enabling temporal context integration. Our approach enhances ViT-based segmentation across diverse imaging modalities, achieving more efficient and accurate refinements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07511v1",
    "published_date": "2025-05-12 12:48:27 UTC",
    "updated_date": "2025-05-12 12:48:27 UTC"
  },
  {
    "arxiv_id": "2505.07509v1",
    "title": "HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs",
    "authors": [
      "Feng Ding",
      "Tingting Wang",
      "Yupeng Gao",
      "Shuo Yu",
      "Jing Ren",
      "Feng Xia"
    ],
    "abstract": "Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the expiration date of facts, which negatively impact reasoning performance on TKGs. However, existing reasoning methods primarily focus on positive importance of historical facts, neglecting adverse effects of outdated facts. Besides, training on these outdated facts yields extra computational cost. To address these challenges, we propose an outdated fact filtering framework named HALO, which quantifies the temporal validity of historical facts by exploring the half-life theory to filter outdated facts in TKGs. HALO consists of three modules: the temporal fact attention module, the dynamic relation-aware encoder module, and the outdated fact filtering module. Firstly, the temporal fact attention module captures the evolution of historical facts over time to identify relevant facts. Secondly, the dynamic relation-aware encoder module is designed for efficiently predicting the half life of each fact. Finally, we construct a time decay function based on the half-life theory to quantify the temporal validity of facts and filter outdated facts. Experimental results show that HALO outperforms the state-of-the-art TKG reasoning methods on three public datasets, demonstrating its effectiveness in detecting and filtering outdated facts (Codes are available at https://github.com/yushuowiki/K-Half/tree/main ).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07509v1",
    "published_date": "2025-05-12 12:47:20 UTC",
    "updated_date": "2025-05-12 12:47:20 UTC"
  },
  {
    "arxiv_id": "2505.07508v1",
    "title": "EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection",
    "authors": [
      "Jing Ren",
      "Mingliang Hou",
      "Zhixuan Liu",
      "Xiaomei Bai"
    ],
    "abstract": "Graph anomaly detection is a popular and vital task in various real-world scenarios, which has been studied for several decades. Recently, many studies extending deep learning-based methods have shown preferable performance on graph anomaly detection. However, existing methods are lack of efficiency that is definitely necessary for embedded devices. Towards this end, we propose an Efficient Anomaly detection model on heterogeneous Graphs via contrastive LEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of their distances to the local context. The proposed method first samples instance pairs on meta path-level for contrastive learning. Then, a graph autoencoder-based model is applied to learn informative node embeddings in an unsupervised way, which will be further combined with the discriminator to predict the anomaly scores of nodes. Experimental results show that EAGLE outperforms the state-of-the-art methods on three heterogeneous network datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07508v1",
    "published_date": "2025-05-12 12:45:07 UTC",
    "updated_date": "2025-05-12 12:45:07 UTC"
  },
  {
    "arxiv_id": "2505.07908v1",
    "title": "A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny",
    "authors": [
      "Karahan Sarıtaş",
      "Çağatay Yıldız"
    ],
    "abstract": "In this reproduction study, we revisit recent claims that self-attention implements kernel principal component analysis (KPCA) (Teo et al., 2024), positing that (i) value vectors $V$ capture the eigenvectors of the Gram matrix of the keys, and (ii) that self-attention projects queries onto the principal component axes of the key matrix $K$ in a feature space. Our analysis reveals three critical inconsistencies: (1) No alignment exists between learned self-attention value vectors and what is proposed in the KPCA perspective, with average similarity metrics (optimal cosine similarity $\\leq 0.32$, linear CKA (Centered Kernel Alignment) $\\leq 0.11$, kernel CKA $\\leq 0.32$) indicating negligible correspondence; (2) Reported decreases in reconstruction loss $J_\\text{proj}$, arguably justifying the claim that the self-attention minimizes the projection error of KPCA, are misinterpreted, as the quantities involved differ by orders of magnitude ($\\sim\\!10^3$); (3) Gram matrix eigenvalue statistics, introduced to justify that $V$ captures the eigenvector of the gram matrix, are irreproducible without undocumented implementation-specific adjustments. Across 10 transformer architectures, we conclude that the KPCA interpretation of self-attention lacks empirical support.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07908v1",
    "published_date": "2025-05-12 12:38:46 UTC",
    "updated_date": "2025-05-12 12:38:46 UTC"
  },
  {
    "arxiv_id": "2505.07473v1",
    "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks",
    "authors": [
      "Kai Xu",
      "YiWei Mao",
      "XinYi Guan",
      "ZiLong Feng"
    ],
    "abstract": "The application of large language models (LLMs) in the field of coding is evolving rapidly: from code assistants, to autonomous coding agents, and then to generating complete projects through natural language. Early LLM code benchmarks primarily focused on code generation accuracy, but these benchmarks have gradually become saturated. Benchmark saturation weakens their guiding role for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%. Among various attempts to address benchmark saturation, approaches based on software engineering have stood out, but the saturation of existing software engineering benchmarks is rapidly increasing. To address this, we propose a new benchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks with sequential dependencies. The tasks implement project features in sequence, simulating real-world human development workflows. When designing Web-Bench, we aim to cover the foundational elements of Web development: Web Standards and Web Frameworks. Given the scale and complexity of these projects, which were designed by engineers with 5 to 10 years of experience, each presents a significant challenge. On average, a single project takes 4 to 8 hours for a senior engineer to complete. On our given benchmark agent (Web-Agent), SOTA (Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better) than SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss that in any development field, Standards and Frameworks represent foundational knowledge and efficiency tools, respectively, and LLMs require optimization tailored to them.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 15 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.07473v1",
    "published_date": "2025-05-12 12:06:23 UTC",
    "updated_date": "2025-05-12 12:06:23 UTC"
  },
  {
    "arxiv_id": "2505.07460v1",
    "title": "A Survey on Collaborative Mechanisms Between Large and Small Language Models",
    "authors": [
      "Yi Chen",
      "JiaHao Zhao",
      "HaoHao Han"
    ],
    "abstract": "Large Language Models (LLMs) deliver powerful AI capabilities but face deployment challenges due to high resource costs and latency, whereas Small Language Models (SLMs) offer efficiency and deployability at the cost of reduced performance. Collaboration between LLMs and SLMs emerges as a crucial paradigm to synergistically balance these trade-offs, enabling advanced AI applications, especially on resource-constrained edge devices. This survey provides a comprehensive overview of LLM-SLM collaboration, detailing various interaction mechanisms (pipeline, routing, auxiliary, distillation, fusion), key enabling technologies, and diverse application scenarios driven by on-device needs like low latency, privacy, personalization, and offline operation. While highlighting the significant potential for creating more efficient, adaptable, and accessible AI, we also discuss persistent challenges including system overhead, inter-model consistency, robust task allocation, evaluation complexity, and security/privacy concerns. Future directions point towards more intelligent adaptive frameworks, deeper model fusion, and expansion into multimodal and embodied AI, positioning LLM-SLM collaboration as a key driver for the next generation of practical and ubiquitous artificial intelligence.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07460v1",
    "published_date": "2025-05-12 11:48:42 UTC",
    "updated_date": "2025-05-12 11:48:42 UTC"
  },
  {
    "arxiv_id": "2505.07457v1",
    "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments",
    "authors": [
      "R. Maria del Rio-Chanona",
      "Marco Pangallo",
      "Cars Hommes"
    ],
    "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human behavior in economic market experiments. Compared to previous studies, we focus on dynamic feedback between LLM agents: the decisions of each LLM impact the market price at the current step, and so affect the decisions of the other LLMs at the next step. We compare LLM behavior to market dynamics observed in laboratory settings and assess their alignment with human participants' behavior. Our findings indicate that LLMs do not adhere strictly to rational expectations, displaying instead bounded rationality, similarly to human participants. Providing a minimal context window i.e. memory of three previous time steps, combined with a high variability setting capturing response heterogeneity, allows LLMs to replicate broad trends seen in human experiments, such as the distinction between positive and negative feedback markets. However, differences remain at a granular level--LLMs exhibit less heterogeneity in behavior than humans. These results suggest that LLMs hold promise as tools for simulating realistic human behavior in economic contexts, though further research is needed to refine their accuracy and increase behavioral diversity.",
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07457v1",
    "published_date": "2025-05-12 11:44:46 UTC",
    "updated_date": "2025-05-12 11:44:46 UTC"
  },
  {
    "arxiv_id": "2505.07453v3",
    "title": "How well do LLMs reason over tabular data, really?",
    "authors": [
      "Cornelius Wolff",
      "Madelon Hulsebos"
    ],
    "abstract": "Large Language Models (LLMs) excel in natural language tasks, but less is known about their reasoning capabilities over tabular data. Prior analyses devise evaluation strategies that poorly reflect an LLM's realistic performance on tabular queries. Moreover, we have a limited understanding of the robustness of LLMs towards realistic variations in tabular inputs. Therefore, we ask: Can general-purpose LLMs reason over tabular data, really?, and focus on two questions 1) are tabular reasoning capabilities of general-purpose LLMs robust to real-world characteristics of tabular inputs, and 2) how can we realistically evaluate an LLM's performance on analytical tabular queries? Building on a recent tabular reasoning benchmark, we first surface shortcomings of its multiple-choice prompt evaluation strategy, as well as commonly used free-form text metrics such as SacreBleu and BERT-score. We show that an LLM-as-a-judge procedure yields more reliable performance insights and unveil a significant deficit in tabular reasoning performance of LLMs. We then extend the tabular inputs reflecting three common characteristics in practice: 1) missing values, 2) duplicate entities, and 3) structural variations. Experiments show that the tabular reasoning capabilities of general-purpose LLMs suffer from these variations, stressing the importance of improving their robustness for realistic tabular inputs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.07453v3",
    "published_date": "2025-05-12 11:35:28 UTC",
    "updated_date": "2025-11-04 14:30:24 UTC"
  },
  {
    "arxiv_id": "2505.07450v3",
    "title": "Prototype Augmented Hypernetworks for Continual Learning",
    "authors": [
      "Neil De La Fuente",
      "Maria Pilligua",
      "Daniel Vidal",
      "Albin Soutiff",
      "Cecilia Curreli",
      "Daniel Cremers",
      "Andrey Barsky"
    ],
    "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting prior knowledge, but gradient updates for a new task often overwrite the weights learned earlier, causing catastrophic forgetting (CF). We propose Prototype-Augmented Hypernetworks (PAH), a framework where a single hypernetwork, conditioned on learnable task prototypes, dynamically generates task-specific classifier heads on demand. To mitigate forgetting, PAH combines cross-entropy with dual distillation losses, one to align logits and another to align prototypes, ensuring stable feature representations across tasks. Evaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves state-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7 % and 4.4 % forgetting, respectively, surpassing prior methods without storing samples or heads.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2025 (LatinX in CV)",
    "pdf_url": "https://arxiv.org/pdf/2505.07450v3",
    "published_date": "2025-05-12 11:25:54 UTC",
    "updated_date": "2025-05-16 16:21:05 UTC"
  },
  {
    "arxiv_id": "2505.07447v2",
    "title": "Unified Continuous Generative Models",
    "authors": [
      "Peng Sun",
      "Yi Jiang",
      "Tao Lin"
    ],
    "abstract": "Recent advances in continuous generative models, including multi-step approaches like diffusion and flow-matching (typically requiring 8-1000 sampling steps) and few-step methods such as consistency models (typically 1-8 steps), have demonstrated impressive generative performance. However, existing work often treats these approaches as distinct paradigms, resulting in separate training and sampling methodologies. We introduce a unified framework for training, sampling, and analyzing these models. Our implementation, the Unified Continuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves state-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a 675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID in 20 steps and a few-step model reaching 1.42 FID in just 2 steps. Additionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at 250 steps) improves performance to 1.06 FID in only 40 steps. Code is available at: https://github.com/LINs-lab/UCGM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/LINs-lab/UCGM",
    "pdf_url": "https://arxiv.org/pdf/2505.07447v2",
    "published_date": "2025-05-12 11:15:39 UTC",
    "updated_date": "2025-05-20 12:27:53 UTC"
  },
  {
    "arxiv_id": "2505.07437v1",
    "title": "LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning",
    "authors": [
      "Xiaotian Lin",
      "Yanlin Qi",
      "Yizhang Zhu",
      "Themis Palpanas",
      "Chengliang Chai",
      "Nan Tang",
      "Yuyu Luo"
    ],
    "abstract": "Instruction tuning has emerged as a critical paradigm for improving the capabilities and alignment of large language models (LLMs). However, existing iterative model-aware data selection methods incur significant computational overhead, as they rely on repeatedly performing full-dataset model inference to estimate sample utility for subsequent training iterations, creating a fundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient iterative data selection framework that accurately estimates sample utility entirely within the standard training loop, eliminating the need for costly additional model inference. At its core, LEAD introduces Instance-Level Dynamic Uncertainty (IDU), a theoretically grounded utility function combining instantaneous training loss, gradient-based approximation of loss changes, and exponential smoothing of historical loss signals. To further scale efficiently to large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy, adaptively prioritizing informative clusters through a multi-armed bandit mechanism, followed by precise fine-grained selection of high-utility samples using IDU. Extensive experiments across four diverse benchmarks show that LEAD significantly outperforms state-of-the-art methods, improving average model performance by 6.1%-10.8% while using only 2.5% of the training data and reducing overall training time by 5-10x.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07437v1",
    "published_date": "2025-05-12 10:57:51 UTC",
    "updated_date": "2025-05-12 10:57:51 UTC"
  },
  {
    "arxiv_id": "2505.13483v1",
    "title": "EmoMeta: A Multimodal Dataset for Fine-grained Emotion Classification in Chinese Metaphors",
    "authors": [
      "Xingyuan Lu",
      "Yuxi Liu",
      "Dongyu Zhang",
      "Zhiyao Wu",
      "Jing Ren",
      "Feng Xia"
    ],
    "abstract": "Metaphors play a pivotal role in expressing emotions, making them crucial for emotional intelligence. The advent of multimodal data and widespread communication has led to a proliferation of multimodal metaphors, amplifying the complexity of emotion classification compared to single-mode scenarios. However, the scarcity of research on constructing multimodal metaphorical fine-grained emotion datasets hampers progress in this domain. Moreover, existing studies predominantly focus on English, overlooking potential variations in emotional nuances across languages. To address these gaps, we introduce a multimodal dataset in Chinese comprising 5,000 text-image pairs of metaphorical advertisements. Each entry is meticulously annotated for metaphor occurrence, domain relations and fine-grained emotion classification encompassing joy, love, trust, fear, sadness, disgust, anger, surprise, anticipation, and neutral. Our dataset is publicly accessible (https://github.com/DUTIR-YSQ/EmoMeta), facilitating further advancements in this burgeoning field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13483v1",
    "published_date": "2025-05-12 10:23:39 UTC",
    "updated_date": "2025-05-12 10:23:39 UTC"
  },
  {
    "arxiv_id": "2507.21058v1",
    "title": "Categorical Classification of Book Summaries Using Word Embedding Techniques",
    "authors": [
      "Kerem Keskin",
      "Mümine Kaya Keleş"
    ],
    "abstract": "In this study, book summaries and categories taken from book sites were classified using word embedding methods, natural language processing techniques and machine learning algorithms. In addition, one hot encoding, Word2Vec and Term Frequency - Inverse Document Frequency (TF-IDF) methods, which are frequently used word embedding methods were used in this study and their success was compared. Additionally, the combination table of the pre-processing methods used is shown and added to the table. Looking at the results, it was observed that Support Vector Machine, Naive Bayes and Logistic Regression Models and TF-IDF and One-Hot Encoder word embedding techniques gave more successful results for Turkish texts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "in Turkish language. This paper was published in the proceedings of the 6th International Conference on Data Science and Applications ICONDATA24, held on September between 2 and 6, 2024, in Pristina, Kosovo. For full text book see https://www.icondata.org/en/proceedings-books",
    "pdf_url": "https://arxiv.org/pdf/2507.21058v1",
    "published_date": "2025-05-12 09:57:37 UTC",
    "updated_date": "2025-05-12 09:57:37 UTC"
  },
  {
    "arxiv_id": "2505.07903v1",
    "title": "SEM: Reinforcement Learning for Search-Efficient Large Language Models",
    "authors": [
      "Zeyang Sha",
      "Shiwen Cui",
      "Weiqiang Wang"
    ],
    "abstract": "Recent advancements in Large Language Models(LLMs) have demonstrated their capabilities not only in reasoning but also in invoking external tools, particularly search engines. However, teaching models to discern when to invoke search and when to rely on their internal knowledge remains a significant challenge. Existing reinforcement learning approaches often lead to redundant search behaviors, resulting in inefficiencies and over-cost. In this paper, we propose SEM, a novel post-training reinforcement learning framework that explicitly trains LLMs to optimize search usage. By constructing a balanced dataset combining MuSiQue and MMLU, we create scenarios where the model must learn to distinguish between questions it can answer directly and those requiring external retrieval. We design a structured reasoning template and employ Group Relative Policy Optimization(GRPO) to post-train the model's search behaviors. Our reward function encourages accurate answering without unnecessary search while promoting effective retrieval when needed. Experimental results demonstrate that our method significantly reduces redundant search operations while maintaining or improving answer accuracy across multiple challenging benchmarks. This framework advances the model's reasoning efficiency and extends its capability to judiciously leverage external knowledge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07903v1",
    "published_date": "2025-05-12 09:45:40 UTC",
    "updated_date": "2025-05-12 09:45:40 UTC"
  },
  {
    "arxiv_id": "2505.07393v1",
    "title": "AI in Money Matters",
    "authors": [
      "Nadine Sandjo Tchatchoua",
      "Richard Harper"
    ],
    "abstract": "In November 2022, Europe and the world by and large were stunned by the birth of a new large language model : ChatGPT. Ever since then, both academic and populist discussions have taken place in various public spheres such as LinkedIn and X(formerly known as Twitter) with the view to both understand the tool and its benefits for the society. The views of real actors in professional spaces, especially in regulated industries such as finance and law have been largely missing. We aim to begin to close this gap by presenting results from an empirical investigation conducted through interviews with professional actors in the Fintech industry. The paper asks the question, how and to what extent are large language models in general and ChatGPT in particular being adopted and used in the Fintech industry? The results show that while the fintech experts we spoke with see a potential in using large language models in the future, a lot of questions marks remain concerning how they are policed and therefore might be adopted in a regulated industry such as Fintech. This paper aims to add to the existing academic discussing around large language models, with a contribution to our understanding of professional viewpoints.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07393v1",
    "published_date": "2025-05-12 09:43:51 UTC",
    "updated_date": "2025-05-12 09:43:51 UTC"
  },
  {
    "arxiv_id": "2505.07381v1",
    "title": "Few-shot Semantic Encoding and Decoding for Video Surveillance",
    "authors": [
      "Baoping Cheng",
      "Yukun Zhang",
      "Liming Wang",
      "Xiaoyan Xie",
      "Tao Fu",
      "Dongkun Wang",
      "Xiaoming Tao"
    ],
    "abstract": "With the continuous increase in the number and resolution of video surveillance cameras, the burden of transmitting and storing surveillance video is growing. Traditional communication methods based on Shannon's theory are facing optimization bottlenecks. Semantic communication, as an emerging communication method, is expected to break through this bottleneck and reduce the storage and transmission consumption of video. Existing semantic decoding methods often require many samples to train the neural network for each scene, which is time-consuming and labor-intensive. In this study, a semantic encoding and decoding method for surveillance video is proposed. First, the sketch was extracted as semantic information, and a sketch compression method was proposed to reduce the bit rate of semantic information. Then, an image translation network was proposed to translate the sketch into a video frame with a reference frame. Finally, a few-shot sketch decoding network was proposed to reconstruct video from sketch. Experimental results showed that the proposed method achieved significantly better video reconstruction performance than baseline methods. The sketch compression method could effectively reduce the storage and transmission consumption of semantic information with little compromise on video quality. The proposed method provides a novel semantic encoding and decoding method that only needs a few training samples for each surveillance scene, thus improving the practicality of the semantic communication system.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07381v1",
    "published_date": "2025-05-12 09:27:28 UTC",
    "updated_date": "2025-05-12 09:27:28 UTC"
  },
  {
    "arxiv_id": "2505.07902v1",
    "title": "Multimodal Assessment of Classroom Discourse Quality: A Text-Centered Attention-Based Multi-Task Learning Approach",
    "authors": [
      "Ruikun Hou",
      "Babette Bühler",
      "Tim Fütterer",
      "Efe Bozkir",
      "Peter Gerjets",
      "Ulrich Trautwein",
      "Enkelejda Kasneci"
    ],
    "abstract": "Classroom discourse is an essential vehicle through which teaching and learning take place. Assessing different characteristics of discursive practices and linking them to student learning achievement enhances the understanding of teaching quality. Traditional assessments rely on manual coding of classroom observation protocols, which is time-consuming and costly. Despite many studies utilizing AI techniques to analyze classroom discourse at the utterance level, investigations into the evaluation of discursive practices throughout an entire lesson segment remain limited. To address this gap, our study proposes a novel text-centered multimodal fusion architecture to assess the quality of three discourse components grounded in the Global Teaching InSights (GTI) observation protocol: Nature of Discourse, Questioning, and Explanations. First, we employ attention mechanisms to capture inter- and intra-modal interactions from transcript, audio, and video streams. Second, a multi-task learning approach is adopted to jointly predict the quality scores of the three components. Third, we formulate the task as an ordinal classification problem to account for rating level order. The effectiveness of these designed elements is demonstrated through an ablation study on the GTI Germany dataset containing 92 videotaped math lessons. Our results highlight the dominant role of text modality in approaching this task. Integrating acoustic features enhances the model's consistency with human ratings, achieving an overall Quadratic Weighted Kappa score of 0.384, comparable to human inter-rater reliability (0.326). Our study lays the groundwork for the future development of automated discourse quality assessment to support teacher professional development through timely feedback on multidimensional discourse practices.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "The 18th International Conference on Educational Data Mining (EDM 2025)",
    "pdf_url": "https://arxiv.org/pdf/2505.07902v1",
    "published_date": "2025-05-12 09:24:21 UTC",
    "updated_date": "2025-05-12 09:24:21 UTC"
  },
  {
    "arxiv_id": "2505.07901v1",
    "title": "Latent Behavior Diffusion for Sequential Reaction Generation in Dyadic Setting",
    "authors": [
      "Minh-Duc Nguyen",
      "Hyung-Jeong Yang",
      "Soo-Hyung Kim",
      "Ji-Eun Shin",
      "Seung-Won Kim"
    ],
    "abstract": "The dyadic reaction generation task involves synthesizing responsive facial reactions that align closely with the behaviors of a conversational partner, enhancing the naturalness and effectiveness of human-like interaction simulations. This paper introduces a novel approach, the Latent Behavior Diffusion Model, comprising a context-aware autoencoder and a diffusion-based conditional generator that addresses the challenge of generating diverse and contextually relevant facial reactions from input speaker behaviors. The autoencoder compresses high-dimensional input features, capturing dynamic patterns in listener reactions while condensing complex input data into a concise latent representation, facilitating more expressive and contextually appropriate reaction synthesis. The diffusion-based conditional generator operates on the latent space generated by the autoencoder to predict realistic facial reactions in a non-autoregressive manner. This approach allows for generating diverse facial reactions that reflect subtle variations in conversational cues and emotional states. Experimental results demonstrate the effectiveness of our approach in achieving superior performance in dyadic reaction synthesis tasks compared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07901v1",
    "published_date": "2025-05-12 09:22:27 UTC",
    "updated_date": "2025-05-12 09:22:27 UTC"
  },
  {
    "arxiv_id": "2505.07377v1",
    "title": "Examining the Role of LLM-Driven Interactions on Attention and Cognitive Engagement in Virtual Classrooms",
    "authors": [
      "Suleyman Ozdel",
      "Can Sarpkaya",
      "Efe Bozkir",
      "Hong Gao",
      "Enkelejda Kasneci"
    ],
    "abstract": "Transforming educational technologies through the integration of large language models (LLMs) and virtual reality (VR) offers the potential for immersive and interactive learning experiences. However, the effects of LLMs on user engagement and attention in educational environments remain open questions. In this study, we utilized a fully LLM-driven virtual learning environment, where peers and teachers were LLM-driven, to examine how students behaved in such settings. Specifically, we investigate how peer question-asking behaviors influenced student engagement, attention, cognitive load, and learning outcomes and found that, in conditions where LLM-driven peer learners asked questions, students exhibited more targeted visual scanpaths, with their attention directed toward the learning content, particularly in complex subjects. Our results suggest that peer questions did not introduce extraneous cognitive load directly, as the cognitive load is strongly correlated with increased attention to the learning material. Considering these findings, we provide design recommendations for optimizing VR learning spaces.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to EDM 2025 (Eighteenth International Conference on Educational Data Mining)",
    "pdf_url": "https://arxiv.org/pdf/2505.07377v1",
    "published_date": "2025-05-12 09:21:19 UTC",
    "updated_date": "2025-05-12 09:21:19 UTC"
  },
  {
    "arxiv_id": "2505.07374v1",
    "title": "AIS Data-Driven Maritime Monitoring Based on Transformer: A Comprehensive Review",
    "authors": [
      "Zhiye Xie",
      "Enmei Tu",
      "Xianping Fu",
      "Guoliang Yuan",
      "Yi Han"
    ],
    "abstract": "With the increasing demands for safety, efficiency, and sustainability in global shipping, Automatic Identification System (AIS) data plays an increasingly important role in maritime monitoring. AIS data contains spatial-temporal variation patterns of vessels that hold significant research value in the marine domain. However, due to its massive scale, the full potential of AIS data has long remained untapped. With its powerful sequence modeling capabilities, particularly its ability to capture long-range dependencies and complex temporal dynamics, the Transformer model has emerged as an effective tool for processing AIS data. Therefore, this paper reviews the research on Transformer-based AIS data-driven maritime monitoring, providing a comprehensive overview of the current applications of Transformer models in the marine field. The focus is on Transformer-based trajectory prediction methods, behavior detection, and prediction techniques. Additionally, this paper collects and organizes publicly available AIS datasets from the reviewed papers, performing data filtering, cleaning, and statistical analysis. The statistical results reveal the operational characteristics of different vessel types, providing data support for further research on maritime monitoring tasks. Finally, we offer valuable suggestions for future research, identifying two promising research directions. Datasets are available at https://github.com/eyesofworld/Maritime-Monitoring.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07374v1",
    "published_date": "2025-05-12 09:17:43 UTC",
    "updated_date": "2025-05-12 09:17:43 UTC"
  },
  {
    "arxiv_id": "2505.07372v1",
    "title": "Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data",
    "authors": [
      "David de-Fitero-Dominguez",
      "Antonio Garcia-Cabot",
      "Eva Garcia-Lopez"
    ],
    "abstract": "This paper presents a novel methodology for enhancing Automated Program Repair (APR) through synthetic data generation utilizing Large Language Models (LLMs). Current APR systems are constrained by the limited availability of high-quality training data encompassing diverse bug types across multiple programming languages. The proposed approach addresses this limitation through a two-phase process: a synthetic sample generation followed by a rigorous quality assessment. Multiple state-of-the-art LLMs were employed to generate approximately 30,000 paired examples of buggy and fixed code across 12 programming languages and 13 bug categories. Subsequently, these samples underwent cross-model evaluation against five criteria: correctness, code quality, security, performance, and completeness. Experimental evaluation on the VulRepair test set dataset showed statistically significant improvements in Perfect Prediction rates, with the quality-filtered synthetic dataset outperforming both baseline and real-world commit data configurations in certain scenarios. The methodology was validated through rigorous statistical testing, including ANOVA and post-hoc Tukey's Honest Significant Difference analysis. Furthermore, the best-performing configurations surpassed existing systems despite using a less computationally intensive decoding strategy. This research establishes a self-bootstrapping paradigm in which LLMs generate and evaluate their own training data, potentially transforming approaches to data scarcity across software engineering tasks and advancing the development of robust, adaptable tools for automated code maintenance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07372v1",
    "published_date": "2025-05-12 09:14:20 UTC",
    "updated_date": "2025-05-12 09:14:20 UTC"
  },
  {
    "arxiv_id": "2505.07365v1",
    "title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge",
    "authors": [
      "Chao-Han Huck Yang",
      "Sreyan Ghosh",
      "Qing Wang",
      "Jaeyeon Kim",
      "Hengyi Hong",
      "Sonal Kumar",
      "Guirui Zhong",
      "Zhifeng Kong",
      "S Sakshi",
      "Vaibhavi Lokegaonkar",
      "Oriol Nieto",
      "Ramani Duraiswami",
      "Dinesh Manocha",
      "Gunhee Kim",
      "Jun Du",
      "Rafael Valle",
      "Bryan Catanzaro"
    ],
    "abstract": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering (AQA) benchmark spanning multiple domains of sound understanding. This task defines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA) to test audio-language models on interactive question-answering over diverse acoustic scenes. We describe the dataset composition (from marine mammal calls to soundscapes and complex real-world clips), the evaluation protocol (top-1 accuracy with answer-shuffling robustness), and baseline systems (Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the development set are compared, showing strong variation across models and subsets. This challenge aims to advance the audio understanding and reasoning capabilities of audio-language models toward human-level acuity, which are crucial for enabling AI agents to perceive and interact about the world effectively.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Preprint. DCASE 2025 Audio QA Challenge: https://dcase.community/challenge2025/task-audio-question-answering",
    "pdf_url": "https://arxiv.org/pdf/2505.07365v1",
    "published_date": "2025-05-12 09:04:16 UTC",
    "updated_date": "2025-05-12 09:04:16 UTC"
  },
  {
    "arxiv_id": "2505.07364v1",
    "title": "GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance of deep unsupervised anomaly detection models",
    "authors": [
      "Daria Zotova",
      "Nicolas Pinon",
      "Robin Trombetta",
      "Romain Bouet",
      "Julien Jung",
      "Carole Lartizien"
    ],
    "abstract": "Background and Objective. Research in the cross-modal medical image translation domain has been very productive over the past few years in tackling the scarce availability of large curated multimodality datasets with the promising performance of GAN-based architectures. However, only a few of these studies assessed task-based related performance of these synthetic data, especially for the training of deep models. Method. We design and compare different GAN-based frameworks for generating synthetic brain [18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first perform standard qualitative and quantitative visual quality evaluation. Then, we explore further impact of using these fake PET data in the training of a deep unsupervised anomaly detection (UAD) model designed to detect subtle epilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic task-oriented quality metrics of the synthetic FDG PET data tailored to our unsupervised detection task, then use these fake data to train a use case UAD model combining a deep representation learning based on siamese autoencoders with a OC-SVM density support estimation model. This model is trained on normal subjects only and allows the detection of any variation from the pattern of the normal population. We compare the detection performance of models trained on 35 paired real MR T1 of normal subjects paired either on 35 true PET images or on 35 synthetic PET images generated from the best performing generative models. Performance analysis is conducted on 17 exams of epilepsy patients undergoing surgery. Results. The best performing GAN-based models allow generating realistic fake PET images of control subject with SSIM and PSNR values around 0.9 and 23.8, respectively and in distribution (ID) with regard to the true control dataset. The best UAD model trained on these synthetic normative PET data allows reaching 74% sensitivity. Conclusion. Our results confirm that GAN-based models are the best suited for MR T1 to FDG PET translation, outperforming transformer or diffusion models. We also demonstrate the diagnostic value of these synthetic data for the training of UAD models and evaluation on clinical exams of epilepsy patients. Our code and the normative image dataset are available.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07364v1",
    "published_date": "2025-05-12 09:00:03 UTC",
    "updated_date": "2025-05-12 09:00:03 UTC"
  },
  {
    "arxiv_id": "2505.07345v1",
    "title": "QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines",
    "authors": [
      "Ohjoon Kwon",
      "Changsu Lee",
      "Jihye Back",
      "Lim Sun Suk",
      "Inho Kang",
      "Donghyeon Jeon"
    ],
    "abstract": "Large language models (LLMs) have been widely used for relevance assessment in information retrieval. However, our study demonstrates that combining two distinct small language models (SLMs) with different architectures can outperform LLMs in this task. Our approach -- QUPID -- integrates a generative SLM with an embedding-based SLM, achieving higher relevance judgment accuracy while reducing computational costs compared to state-of-the-art LLM solutions. This computational efficiency makes QUPID highly scalable for real-world search systems processing millions of queries daily. In experiments across diverse document types, our method demonstrated consistent performance improvements (Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x faster inference times. Furthermore, when integrated into production search pipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how architectural diversity in model combinations can significantly enhance both search relevance and operational efficiency in information retrieval systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07345v1",
    "published_date": "2025-05-12 08:35:09 UTC",
    "updated_date": "2025-05-12 08:35:09 UTC"
  },
  {
    "arxiv_id": "2505.07344v5",
    "title": "Generative Pre-trained Autoregressive Diffusion Transformer",
    "authors": [
      "Yuan Zhang",
      "Jiacheng Jiang",
      "Guoqing Ma",
      "Zhiying Lu",
      "Haoyang Huang",
      "Jianlong Yuan",
      "Nan Duan",
      "Daxin Jiang"
    ],
    "abstract": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive Diffusion Transformer that unifies the strengths of diffusion and autoregressive modeling for long-range video synthesis, within a continuous latent space. Instead of predicting discrete tokens, GPDiT autoregressively predicts future latent frames using a diffusion loss, enabling natural modeling of motion dynamics and semantic consistency across frames. This continuous autoregressive framework not only enhances generation quality but also endows the model with representation capabilities. Additionally, we introduce a lightweight causal attention variant and a parameter-free rotation-based time-conditioning mechanism, improving both the training and inference efficiency. Extensive experiments demonstrate that GPDiT achieves strong performance in video generation quality, video representation ability, and few-shot learning tasks, highlighting its potential as an effective framework for video modeling in continuous space.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07344v5",
    "published_date": "2025-05-12 08:32:39 UTC",
    "updated_date": "2025-10-08 09:22:25 UTC"
  },
  {
    "arxiv_id": "2505.08814v2",
    "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test",
    "authors": [
      "Wenkai Li",
      "Xiaoqi Li",
      "Yingjie Mao",
      "Yishun Wang"
    ],
    "abstract": "Deep neural networks (DNNs) play a crucial role in the field of artificial intelligence, and their security-related testing has been a prominent research focus. By inputting test cases, the behavior of models is examined for anomalies, and coverage metrics are utilized to determine the extent of neurons covered by these test cases. With the widespread application and advancement of DNNs, different types of neural behaviors have garnered attention, leading to the emergence of various coverage metrics for neural networks. However, there is currently a lack of empirical research on these coverage metrics, specifically in analyzing the relationships and patterns between model depth, configuration information, and neural network coverage. This paper aims to investigate the relationships and patterns of four coverage metrics: primary functionality, boundary, hierarchy, and structural coverage. A series of empirical experiments were conducted, selecting LeNet, VGG, and ResNet as different DNN architectures, along with 10 models of varying depths ranging from 5 to 54 layers, to compare and study the relationships between different depths, configuration information, and various neural network coverage metrics. Additionally, an investigation was carried out on the relationships between modified decision/condition coverage and dataset size. Finally, three potential future directions are proposed to further contribute to the security testing of DNN Models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08814v2",
    "published_date": "2025-05-12 08:25:55 UTC",
    "updated_date": "2026-01-15 14:53:58 UTC"
  },
  {
    "arxiv_id": "2505.07339v1",
    "title": "Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory Decision-Making Algorithms",
    "authors": [
      "Gabriel Lima",
      "Nina Grgić-Hlača",
      "Markus Langer",
      "Yixin Zou"
    ],
    "abstract": "Affirmative algorithms have emerged as a potential answer to algorithmic discrimination, seeking to redress past harms and rectify the source of historical injustices. We present the results of two experiments ($N$$=$$1193$) capturing laypeople's perceptions of affirmative algorithms -- those which explicitly prioritize the historically marginalized -- in hiring and criminal justice. We contrast these opinions about affirmative algorithms with folk attitudes towards algorithms that prioritize the privileged (i.e., discriminatory) and systems that make decisions independently of demographic groups (i.e., fair). We find that people -- regardless of their political leaning and identity -- view fair algorithms favorably and denounce discriminatory systems. In contrast, we identify disagreements concerning affirmative algorithms: liberals and racial minorities rate affirmative systems as positively as their fair counterparts, whereas conservatives and those from the dominant racial group evaluate affirmative algorithms as negatively as discriminatory systems. We identify a source of these divisions: people have varying beliefs about who (if anyone) is marginalized, shaping their views of affirmative algorithms. We discuss the possibility of bridging these disagreements to bring people together towards affirmative algorithms.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07339v1",
    "published_date": "2025-05-12 08:25:15 UTC",
    "updated_date": "2025-05-12 08:25:15 UTC"
  },
  {
    "arxiv_id": "2505.07336v1",
    "title": "SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction",
    "authors": [
      "Zhixuan Zhang",
      "Xiaopeng Li",
      "Qi Liu"
    ],
    "abstract": "Background subtraction (BGS) is utilized to detect moving objects in a video and is commonly employed at the onset of object tracking and human recognition processes. Nevertheless, existing BGS techniques utilizing deep learning still encounter challenges with various background noises in videos, including variations in lighting, shifts in camera angles, and disturbances like air turbulence or swaying trees. To address this problem, we design a spiking autoencoder network, termed SAEN-BGS, based on noise resilience and time-sequence sensitivity of spiking neural networks (SNNs) to enhance the separation of foreground and background. To eliminate unnecessary background noise and preserve the important foreground elements, we begin by creating the continuous spiking conv-and-dconv block, which serves as the fundamental building block for the decoder in SAEN-BGS. Moreover, in striving for enhanced energy efficiency, we introduce a novel self-distillation spiking supervised learning method grounded in ANN-to-SNN frameworks, resulting in decreased power consumption. In extensive experiments conducted on CDnet-2014 and DAVIS-2016 datasets, our approach demonstrates superior segmentation performance relative to other baseline methods, even when challenged by complex scenarios with dynamic backgrounds.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by Pattern Recognition",
    "pdf_url": "https://arxiv.org/pdf/2505.07336v1",
    "published_date": "2025-05-12 08:21:47 UTC",
    "updated_date": "2025-05-12 08:21:47 UTC"
  },
  {
    "arxiv_id": "2505.07320v2",
    "title": "Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records",
    "authors": [
      "Yuhao Li",
      "Ling Luo",
      "Uwe Aickelin"
    ],
    "abstract": "Medical research, particularly in predicting patient outcomes, heavily relies on medical time series data extracted from Electronic Health Records (EHR), which provide extensive information on patient histories. Despite rigorous examination, labeling errors are inevitable and can significantly impede accurate predictions of patient outcome. To address this challenge, we propose an \\textbf{A}ttention-based Learning Framework with Dynamic \\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy \\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a two-component Beta mixture model to identify the certain and uncertain sets of instances based on the fitness distribution of each class, and it captures global temporal dynamics while dynamically calibrating labels from the uncertain set or augmenting confident instances from the certain set. Experimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and several benchmark datasets from the UCR and UEA repositories, demonstrate that our model ACTLL has achieved state-of-the-art performance, especially under high noise levels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07320v2",
    "published_date": "2025-05-12 08:06:16 UTC",
    "updated_date": "2025-06-03 05:38:40 UTC"
  },
  {
    "arxiv_id": "2505.07317v2",
    "title": "How Do Companies Manage the Environmental Sustainability of AI? An Interview Study About Green AI Efforts and Regulations",
    "authors": [
      "Ashmita Sampatsing",
      "Sophie Vos",
      "Emma Beauxis-Aussalet",
      "Justus Bogner"
    ],
    "abstract": "With the ever-growing adoption of artificial intelligence (AI), AI-based software and its negative impact on the environment are no longer negligible, and studying and mitigating this impact has become a critical area of research. However, it is currently unclear which role environmental sustainability plays during AI adoption in industry and how AI regulations influence Green AI practices and decision-making in industry. We therefore aim to investigate the Green AI perception and management of industry practitioners. To this end, we conducted a total of 11 interviews with participants from 10 different organizations that adopted AI-based software. The interviews explored three main themes: AI adoption, current efforts in mitigating the negative environmental impact of AI, and the influence of the EU AI Act and the Corporate Sustainability Reporting Directive (CSRD). Our findings indicate that 9 of 11 participants prioritized business efficiency during AI adoption, with minimal consideration of environmental sustainability. Monitoring and mitigation of AI's environmental impact were very limited. Only one participant monitored negative environmental effects. Regarding applied mitigation practices, six participants reported no actions, with the others sporadically mentioning techniques like prompt engineering, relying on smaller models, or not overusing AI. Awareness and compliance with the EU AI Act are low, with only one participant reporting on its influence, while the CSRD drove sustainability reporting efforts primarily in larger companies. All in all, our findings reflect a lack of urgency and priority for sustainable AI among these companies. We suggest that current regulations are not very effective, which has implications for policymakers. Additionally, there is a need to raise industry awareness, but also to provide user-friendly techniques and tools for Green AI practices.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for publication at the 11th International Conference on ICT for Sustainability (ICT4S'25), see https://conf.researchr.org/home/ict4s-2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07317v2",
    "published_date": "2025-05-12 08:03:55 UTC",
    "updated_date": "2025-11-26 14:27:22 UTC"
  },
  {
    "arxiv_id": "2505.07315v2",
    "title": "FedIFL: A federated cross-domain diagnostic framework for motor-driven systems with inconsistent fault modes",
    "authors": [
      "Zexiao Wang",
      "Yankai Wang",
      "Xiaoqiang Liao",
      "Xinguo Ming",
      "Weiming Shen"
    ],
    "abstract": "Due to the scarcity of industrial data, individual equipment users, particularly start-ups, struggle to independently train a comprehensive fault diagnosis model; federated learning enables collaborative training while ensuring data privacy, making it an ideal solution. However, the diversity of working conditions leads to variations in fault modes, resulting in inconsistent label spaces across different clients. In federated diagnostic scenarios, label space inconsistency leads to local models focus on client-specific fault modes and causes local models from different clients to map different failure modes to similar feature representations, which weakens the aggregated global model's generalization. To tackle this issue, this article proposed a federated cross-domain diagnostic framework termed Federated Invariant Features Learning (FedIFL). In intra-client training, prototype contrastive learning mitigates intra-client domain shifts, subsequently, feature generating ensures local models can access distributions of other clients in a privacy-friendly manner. Besides, in cross-client training, a feature disentanglement mechanism is introduced to mitigate cross-client domain shifts, specifically, an instance-level federated instance consistency loss is designed to ensure the instance-level consistency of invariant features between different clients, furthermore, a federated instance personalization loss and an orthogonal loss are constructed to distinguish specific features that from the invariant features. Eventually, the aggregated model achieves promising generalization among global label spaces, enabling accurate fault diagnosis for target clients' Motor Driven Systems (MDSs) with inconsistent label spaces. Experiments on real-world MDSs validate the effectiveness and superiority of FedIFL in federated cross-domain diagnosis with inconsistent fault modes.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Based on reviewer feedback, we realized that the proposed FedIFL framework does not strictly conform to federated learning principles, since sharing primary features, label spaces and generator parameters with a central server may violate FL privacy requirements",
    "pdf_url": "https://arxiv.org/pdf/2505.07315v2",
    "published_date": "2025-05-12 08:00:49 UTC",
    "updated_date": "2025-12-05 07:36:18 UTC"
  },
  {
    "arxiv_id": "2505.07313v2",
    "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study",
    "authors": [
      "Baixuan Xu",
      "Chunyang Li",
      "Weiqi Wang",
      "Wei Fan",
      "Tianshi Zheng",
      "Haochen Shi",
      "Tao Fan",
      "Yangqiu Song",
      "Qiang Yang"
    ],
    "abstract": "Designing effective collaboration structure for multi-agent LLM systems to enhance collective reasoning is crucial yet remains under-explored. In this paper, we systematically investigate how collaborative reasoning performance is affected by three key design dimensions: (1) Expertise-Domain Alignment, (2) Collaboration Paradigm (structured workflow vs. diversity-driven integration), and (3) System Scale. Our findings reveal that expertise alignment benefits are highly domain-contingent, proving most effective for contextual reasoning tasks. Furthermore, collaboration focused on integrating diverse knowledge consistently outperforms rigid task decomposition. Finally, we empirically explore the impact of scaling the multi-agent system with expertise specialization and study the computational trade off, highlighting the need for more efficient communication protocol design. This work provides concrete guidelines for configuring specialized multi-agent system and identifies critical architectural trade-offs and bottlenecks for scalable multi-agent reasoning. The code will be made available upon acceptance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.07313v2",
    "published_date": "2025-05-12 07:59:13 UTC",
    "updated_date": "2025-05-16 09:41:23 UTC"
  },
  {
    "arxiv_id": "2505.07299v1",
    "title": "Interpretable Event Diagnosis in Water Distribution Networks",
    "authors": [
      "André Artelt",
      "Stelios G. Vrachimis",
      "Demetrios G. Eliades",
      "Ulrike Kuhl",
      "Barbara Hammer",
      "Marios M. Polycarpou"
    ],
    "abstract": "The increasing penetration of information and communication technologies in the design, monitoring, and control of water systems enables the use of algorithms for detecting and identifying unanticipated events (such as leakages or water contamination) using sensor measurements. However, data-driven methodologies do not always give accurate results and are often not trusted by operators, who may prefer to use their engineering judgment and experience to deal with such events.\n  In this work, we propose a framework for interpretable event diagnosis -- an approach that assists the operators in associating the results of algorithmic event diagnosis methodologies with their own intuition and experience. This is achieved by providing contrasting (i.e., counterfactual) explanations of the results provided by fault diagnosis algorithms; their aim is to improve the understanding of the algorithm's inner workings by the operators, thus enabling them to take a more informed decision by combining the results with their personal experiences. Specifically, we propose counterfactual event fingerprints, a representation of the difference between the current event diagnosis and the closest alternative explanation, which can be presented in a graphical way. The proposed methodology is applied and evaluated on a realistic use case using the L-Town benchmark.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07299v1",
    "published_date": "2025-05-12 07:36:00 UTC",
    "updated_date": "2025-05-12 07:36:00 UTC"
  },
  {
    "arxiv_id": "2505.07294v2",
    "title": "HuB: Learning Extreme Humanoid Balance",
    "authors": [
      "Tong Zhang",
      "Boyuan Zheng",
      "Ruiqian Nai",
      "Yingdong Hu",
      "Yen-Jen Wang",
      "Geng Chen",
      "Fanqi Lin",
      "Jiongye Li",
      "Chuye Hong",
      "Koushil Sreenath",
      "Yang Gao"
    ],
    "abstract": "The human body demonstrates exceptional motor capabilities-such as standing steadily on one foot or performing a high kick with the leg raised over 1.5 meters-both requiring precise balance control. While recent research on humanoid control has leveraged reinforcement learning to track human motions for skill acquisition, applying this paradigm to balance-intensive tasks remains challenging. In this work, we identify three key obstacles: instability from reference motion errors, learning difficulties due to morphological mismatch, and the sim-to-real gap caused by sensor noise and unmodeled dynamics. To address these challenges, we propose HuB (Humanoid Balance), a unified framework that integrates reference motion refinement, balance-aware policy learning, and sim-to-real robustness training, with each component targeting a specific challenge. We validate our approach on the Unitree G1 humanoid robot across challenging quasi-static balance tasks, including extreme single-legged poses such as Swallow Balance and Bruce Lee's Kick. Our policy remains stable even under strong physical disturbances-such as a forceful soccer strike-while baseline methods consistently fail to complete these tasks. Project website: https://hub-robot.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2025 (Oral Presentation). Project website: https://hub-robot.github.io",
    "pdf_url": "https://arxiv.org/pdf/2505.07294v2",
    "published_date": "2025-05-12 07:31:42 UTC",
    "updated_date": "2025-08-17 08:03:16 UTC"
  },
  {
    "arxiv_id": "2505.07289v1",
    "title": "Semantic Retention and Extreme Compression in LLMs: Can We Have Both?",
    "authors": [
      "Stanislas Laborde",
      "Martin Cousseau",
      "Antoun Yaacoub",
      "Lionel Prevost"
    ],
    "abstract": "The exponential growth in Large Language Model (LLM) deployment has intensified the need for efficient model compression techniques to reduce computational and memory costs. While pruning and quantization have shown promise, their combined potential remains largely unexplored. In this paper, we examine joint compression and how strategically combining pruning and quantization could yield superior performance-to-compression ratios compared to single-method approaches. Recognizing the challenges in accurately assessing LLM performance, we address key limitations of previous evaluation frameworks and introduce the Semantic Retention Compression Rate (SrCr), a novel metric that quantifies the trade-off between model compression and semantic preservation, facilitating the optimization of pruning-quantization configurations. Experiments demonstrate that our recommended combination achieves, on average, a 20% performance increase compared to an equivalent quantization-only model at the same theoretical compression rate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication in the Proceedings of the 2025 International Joint Conference on Neural Networks (IJCNN); this arXiv version includes an appendix with 6 result tables; 10 pages, 15 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.07289v1",
    "published_date": "2025-05-12 07:23:19 UTC",
    "updated_date": "2025-05-12 07:23:19 UTC"
  },
  {
    "arxiv_id": "2505.07286v2",
    "title": "Piloting Structure-Based Drug Design via Modality-Specific Optimal Schedule",
    "authors": [
      "Keyue Qiu",
      "Yuxuan Song",
      "Zhehuan Fan",
      "Peidong Liu",
      "Zhe Zhang",
      "Mingyue Zheng",
      "Hao Zhou",
      "Wei-Ying Ma"
    ],
    "abstract": "Structure-Based Drug Design (SBDD) is crucial for identifying bioactive molecules. Recent deep generative models are faced with challenges in geometric structure modeling. A major bottleneck lies in the twisted probability path of multi-modalities -- continuous 3D positions and discrete 2D topologies -- which jointly determine molecular geometries. By establishing the fact that noise schedules decide the Variational Lower Bound (VLB) for the twisted probability path, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored area, which optimizes VLB as a path integral for SBDD. Our model effectively enhances molecular geometries and interaction modeling, achieving state-of-the-art PoseBusters passing rate of 95.9% on CrossDock, more than 10% improvement upon strong baselines, while maintaining high affinities and robust intramolecular validity evaluated on held-out test set. Code is available at https://github.com/AlgoMole/MolCRAFT.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Accepted to ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07286v2",
    "published_date": "2025-05-12 07:18:09 UTC",
    "updated_date": "2025-06-05 12:37:46 UTC"
  },
  {
    "arxiv_id": "2505.07899v2",
    "title": "On the Superimposed Noise Accumulation Problem in Sequential Knowledge Editing of Large Language Models",
    "authors": [
      "Ding Cao",
      "Yuchen Cai",
      "Yuqing Huang",
      "Xuesong He",
      "Rongxi Guo",
      "Guiquan Liu",
      "Guangzhong Sun"
    ],
    "abstract": "Sequential knowledge editing techniques aim to continuously update knowledge in large language models at low cost, preventing models from generating outdated or incorrect information. However, existing sequential editing methods suffer from a significant decline in editing success rates after long-term editing. Through theoretical analysis and experiments, our findings reveal that as the number of edits increases, the model's output increasingly deviates from the desired target, leading to a drop in editing success rates. We refer to this issue as the superimposed noise accumulation problem. Our further analysis demonstrates that the problem is related to the erroneous activation of irrelevant knowledge and conflicts between activated knowledge. Based on this analysis, a method named DeltaEdit is proposed that reduces conflicts between knowledge through dynamic orthogonal constraint strategies. Experiments show that DeltaEdit significantly reduces superimposed noise, achieving a 16.8% improvement in editing performance over the strongest baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07899v2",
    "published_date": "2025-05-12 07:11:26 UTC",
    "updated_date": "2025-11-27 09:22:11 UTC"
  },
  {
    "arxiv_id": "2505.07280v1",
    "title": "Predicting Music Track Popularity by Convolutional Neural Networks on Spotify Features and Spectrogram of Audio Waveform",
    "authors": [
      "Navid Falah",
      "Behnam Yousefimehr",
      "Mehdi Ghatee"
    ],
    "abstract": "In the digital streaming landscape, it's becoming increasingly challenging for artists and industry experts to predict the success of music tracks. This study introduces a pioneering methodology that uses Convolutional Neural Networks (CNNs) and Spotify data analysis to forecast the popularity of music tracks. Our approach takes advantage of Spotify's wide range of features, including acoustic attributes based on the spectrogram of audio waveform, metadata, and user engagement metrics, to capture the complex patterns and relationships that influence a track's popularity. Using a large dataset covering various genres and demographics, our CNN-based model shows impressive effectiveness in predicting the popularity of music tracks. Additionally, we've conducted extensive experiments to assess the strength and adaptability of our model across different musical styles and time periods, with promising results yielding a 97\\% F1 score. Our study not only offers valuable insights into the dynamic landscape of digital music consumption but also provides the music industry with advanced predictive tools for assessing and predicting the success of music tracks.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "12 pages, 6 figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.07280v1",
    "published_date": "2025-05-12 07:03:17 UTC",
    "updated_date": "2025-05-12 07:03:17 UTC"
  },
  {
    "arxiv_id": "2505.08810v1",
    "title": "Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication",
    "authors": [
      "Bappa Muktar",
      "Vincent Fono",
      "Adama Nouboukpo"
    ],
    "abstract": "Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent Transportation Systems (ITS), particularly in enabling real-time communication for emergency vehicles. However, Distributed Denial of Service (DDoS) attacks, which interfere with safety-critical communication channels, can severely impair their reliability. This study introduces a robust and scalable framework to detect DDoS attacks in highway-based VANET environments. A synthetic dataset was constructed using Network Simulator 3 (NS-3) in conjunction with the Simulation of Urban Mobility (SUMO) and further enriched with real-world mobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM). Three traffic categories were simulated: DDoS, VoIP, and TCP-based video streaming (VideoTCP). The data preprocessing pipeline included normalization, signal-to-noise ratio (SNR) feature engineering, missing value imputation, and class balancing using the Synthetic Minority Over-sampling Technique (SMOTE). Feature importance was assessed using SHapley Additive exPlanations (SHAP). Eleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB), AdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN). XGB and CB achieved the best performance, each attaining an F1-score of 96%. These results highlight the robustness of the proposed framework and its potential for real-time deployment in VANETs to secure critical emergency communications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08810v1",
    "published_date": "2025-05-12 07:00:04 UTC",
    "updated_date": "2025-05-12 07:00:04 UTC"
  },
  {
    "arxiv_id": "2505.07271v1",
    "title": "On the Robustness of Reward Models for Language Model Alignment",
    "authors": [
      "Jiwoo Hong",
      "Noah Lee",
      "Eunki Kim",
      "Guijin Son",
      "Woojin Chung",
      "Aman Gupta",
      "Shao Tang",
      "James Thorne"
    ],
    "abstract": "The Bradley-Terry (BT) model is widely practiced in reward modeling for reinforcement learning with human feedback (RLHF). Despite its effectiveness, reward models (RMs) trained with BT model loss are prone to over-optimization, losing generalizability to unseen input distributions. In this paper, we study the cause of over-optimization in RM training and its downstream effects on the RLHF procedure, accentuating the importance of distributional robustness of RMs in unseen data. First, we show that the excessive dispersion of hidden state norms is the main source of over-optimization. Then, we propose batch-wise sum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch, constraining the rewards with extreme magnitudes. We assess the impact of BSR in improving robustness in RMs through four scenarios of over-optimization, where BSR consistently manifests better robustness. Subsequently, we compare the plain BT model and BSR on RLHF training and empirically show that robust RMs better align the policy to the gold preference model. Finally, we apply BSR to high-quality data and models, which surpasses state-of-the-art RMs in the 8B scale by adding more than 5% in complex preference prediction tasks. By conducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length by 40% while adding a 7% increase in win rate, further highlighting that robustness in RMs induces robustness in RLHF training. We release the code, data, and models: https://github.com/LinkedIn-XFACT/RM-Robustness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07271v1",
    "published_date": "2025-05-12 06:48:26 UTC",
    "updated_date": "2025-05-12 06:48:26 UTC"
  },
  {
    "arxiv_id": "2505.08809v2",
    "title": "MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges",
    "authors": [
      "Shixi Qin",
      "Zhiyong Yang",
      "Shilong Bao",
      "Shi Wang",
      "Qianqian Xu",
      "Qingming Huang"
    ],
    "abstract": "This paper focuses on implanting multiple heterogeneous backdoor triggers in bridge-based diffusion models designed for complex and arbitrary input distributions. Existing backdoor formulations mainly address single-attack scenarios and are limited to Gaussian noise input models. To fill this gap, we propose MixBridge, a novel diffusion Schrödinger bridge (DSB) framework to cater to arbitrary input distributions (taking I2I tasks as special cases). Beyond this trait, we demonstrate that backdoor triggers can be injected into MixBridge by directly training with poisoned image pairs. This eliminates the need for the cumbersome modifications to stochastic differential equations required in previous studies, providing a flexible tool to study backdoor behavior for bridge models. However, a key question arises: can a single DSB model train multiple backdoor triggers? Unfortunately, our theory shows that when attempting this, the model ends up following the geometric mean of benign and backdoored distributions, leading to performance conflict across backdoor tasks. To overcome this, we propose a Divide-and-Merge strategy to mix different bridges, where models are independently pre-trained for each specific objective (Divide) and then integrated into a unified model (Merge). In addition, a Weight Reallocation Scheme (WRS) is also designed to enhance the stealthiness of MixBridge. Empirical studies across diverse generation tasks speak to the efficacy of MixBridge.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08809v2",
    "published_date": "2025-05-12 06:40:23 UTC",
    "updated_date": "2025-05-26 09:54:13 UTC"
  },
  {
    "arxiv_id": "2505.07261v3",
    "title": "CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks",
    "authors": [
      "Ce Hao",
      "Anxing Xiao",
      "Zhiwei Xue",
      "Harold Soh"
    ],
    "abstract": "Diffusion-based planners have shown strong performance in short-horizon tasks but often fail in complex, long-horizon settings. We trace the failure to loose coupling between high-level (HL) sub-goal selection and low-level (LL) trajectory generation, which leads to incoherent plans and degraded performance. We propose Coupled Hierarchical Diffusion (CHD), a framework that models HL sub-goals and LL trajectories jointly within a unified diffusion process. A shared classifier passes LL feedback upstream so that sub-goals self-correct while sampling proceeds. This tight HL-LL coupling improves trajectory coherence and enables scalable long-horizon diffusion planning. Experiments across maze navigation, tabletop manipulation, and household environments show that CHD consistently outperforms both flat and hierarchical diffusion baselines. Our website is: https://sites.google.com/view/chd2025/home",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07261v3",
    "published_date": "2025-05-12 06:21:48 UTC",
    "updated_date": "2025-10-12 04:52:00 UTC"
  },
  {
    "arxiv_id": "2505.07260v2",
    "title": "UMoE: Unifying Attention and FFN with Shared Experts",
    "authors": [
      "Yuanhang Yang",
      "Chaozheng Wang",
      "Jing Li"
    ],
    "abstract": "Sparse Mixture of Experts (MoE) architectures have emerged as a promising approach for scaling Transformer models. While initial works primarily incorporated MoE into feed-forward network (FFN) layers, recent studies have explored extending the MoE paradigm to attention layers to enhance model performance. However, existing attention-based MoE layers require specialized implementations and demonstrate suboptimal performance compared to their FFN-based counterparts. In this paper, we aim to unify MoE designs in attention and FFN layers by introducing a novel reformulation of the attention mechanism, that reveals an underlying FFN-like structure within attention modules. Our proposed architecture, UMoE, achieves superior performance through attention-based MoE layers while enabling efficient parameter sharing between FFN and attention components.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025 Spotlight",
    "pdf_url": "https://arxiv.org/pdf/2505.07260v2",
    "published_date": "2025-05-12 06:21:44 UTC",
    "updated_date": "2025-10-23 09:59:10 UTC"
  },
  {
    "arxiv_id": "2505.07258v2",
    "title": "No Query, No Access",
    "authors": [
      "Wenqiang Wang",
      "Siyuan Liang",
      "Yangshijie Zhang",
      "Xiaojun Jia",
      "Hao Lin",
      "Xiaochun Cao"
    ],
    "abstract": "Textual adversarial attacks mislead NLP models, including Large Language Models (LLMs), by subtly modifying text. While effective, existing attacks often require knowledge of the victim model, extensive queries, or access to training data, limiting real-world feasibility. To overcome these constraints, we introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which operates using only victim texts. To prevent access to the victim model, we create a shadow dataset with publicly available pre-trained models and clustering methods as a foundation for developing substitute models. To address the low attack success rate (ASR) due to insufficient information feedback, we propose the hierarchical substitution model design, generating substitute models to mitigate the failure of a single substitute model at the decision boundary.\n  Concurrently, we use diverse adversarial example generation, employing various attack methods to generate and select the adversarial example with better similarity and attack effectiveness. Experiments on the Emotion and SST5 datasets show that VDBA outperforms state-of-the-art methods, achieving an ASR improvement of 52.08\\% while significantly reducing attack queries to 0. More importantly, we discover that VDBA poses a significant threat to LLMs such as Qwen2 and the GPT family, and achieves the highest ASR of 45.99% even without access to the API, confirming that advanced NLP models still face serious security risks. Our codes can be found at https://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07258v2",
    "published_date": "2025-05-12 06:19:59 UTC",
    "updated_date": "2025-08-07 18:03:20 UTC"
  },
  {
    "arxiv_id": "2505.07251v1",
    "title": "Incomplete In-context Learning",
    "authors": [
      "Wenqiang Wang",
      "Yangshijie Zhang"
    ],
    "abstract": "Large vision language models (LVLMs) achieve remarkable performance through Vision In-context Learning (VICL), a process that depends significantly on demonstrations retrieved from an extensive collection of annotated examples (retrieval database). Existing studies often assume that the retrieval database contains annotated examples for all labels. However, in real-world scenarios, delays in database updates or incomplete data annotation may result in the retrieval database containing labeled samples for only a subset of classes. We refer to this phenomenon as an \\textbf{incomplete retrieval database} and define the in-context learning under this condition as \\textbf{Incomplete In-context Learning (IICL)}. To address this challenge, we propose \\textbf{Iterative Judgments and Integrated Prediction (IJIP)}, a two-stage framework designed to mitigate the limitations of IICL. The Iterative Judgments Stage reformulates an \\(\\boldsymbol{m}\\)-class classification problem into a series of \\(\\boldsymbol{m}\\) binary classification tasks, effectively converting the IICL setting into a standard VICL scenario. The Integrated Prediction Stage further refines the classification process by leveraging both the input image and the predictions from the Iterative Judgments Stage to enhance overall classification accuracy. IJIP demonstrates considerable performance across two LVLMs and two datasets under three distinct conditions of label incompleteness, achieving the highest accuracy of 93.9\\%. Notably, even in scenarios where labels are fully available, IJIP still achieves the best performance of all six baselines. Furthermore, IJIP can be directly applied to \\textbf{Prompt Learning} and is adaptable to the \\textbf{text domain}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07251v1",
    "published_date": "2025-05-12 05:57:39 UTC",
    "updated_date": "2025-05-12 05:57:39 UTC"
  },
  {
    "arxiv_id": "2505.07247v2",
    "title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models",
    "authors": [
      "Peichao Lai",
      "Kexuan Zhang",
      "Yi Lin",
      "Linyihan Zhang",
      "Feiyang Ye",
      "Jinhao Yan",
      "Yanwei Xu",
      "Conghui He",
      "Yilei Wang",
      "Wentao Zhang",
      "Bin Cui"
    ],
    "abstract": "Subjective Answer Grading (SAG) plays a crucial role in education, standardized testing, and automated assessment systems, particularly for evaluating short-form responses in Short Answer Scoring (SAS). However, existing approaches often produce coarse-grained scores and lack detailed reasoning. Although large language models (LLMs) have demonstrated potential as zero-shot evaluators, they remain susceptible to bias, inconsistencies with human judgment, and limited transparency in scoring decisions. To overcome these limitations, we introduce SAS-Bench, a benchmark specifically designed for LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring, expert-annotated error categories, and a diverse range of question types derived from real-world subject-specific exams. This benchmark facilitates detailed evaluation of model reasoning processes and explainability. We also release an open-source dataset containing 1,030 questions and 4,109 student responses, each annotated by domain experts. Furthermore, we conduct comprehensive experiments with various LLMs, identifying major challenges in scoring science-related questions and highlighting the effectiveness of few-shot prompting in improving scoring accuracy. Our work offers valuable insights into the development of more robust, fair, and educationally meaningful LLM-based evaluation systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07247v2",
    "published_date": "2025-05-12 05:43:21 UTC",
    "updated_date": "2025-05-15 11:01:45 UTC"
  },
  {
    "arxiv_id": "2505.07245v1",
    "title": "REMEDI: Relative Feature Enhanced Meta-Learning with Distillation for Imbalanced Prediction",
    "authors": [
      "Fei Liu",
      "Huanhuan Ren",
      "Yu Guan",
      "Xiuxu Wang",
      "Wang Lv",
      "Zhiqiang Hu",
      "Yaxi Chen"
    ],
    "abstract": "Predicting future vehicle purchases among existing owners presents a critical challenge due to extreme class imbalance (<0.5% positive rate) and complex behavioral patterns. We propose REMEDI (Relative feature Enhanced Meta-learning with Distillation for Imbalanced prediction), a novel multi-stage framework addressing these challenges. REMEDI first trains diverse base models to capture complementary aspects of user behavior. Second, inspired by comparative op-timization techniques, we introduce relative performance meta-features (deviation from ensemble mean, rank among peers) for effective model fusion through a hybrid-expert architecture. Third, we distill the ensemble's knowledge into a single efficient model via supervised fine-tuning with MSE loss, enabling practical deployment. Evaluated on approximately 800,000 vehicle owners, REMEDI significantly outperforms baseline approaches, achieving the business target of identifying ~50% of actual buyers within the top 60,000 recommendations at ~10% precision. The distilled model preserves the ensemble's predictive power while maintaining deployment efficiency, demonstrating REMEDI's effectiveness for imbalanced prediction in industry settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07245v1",
    "published_date": "2025-05-12 05:40:20 UTC",
    "updated_date": "2025-05-12 05:40:20 UTC"
  },
  {
    "arxiv_id": "2505.07897v3",
    "title": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows",
    "authors": [
      "Stefano Rando",
      "Luca Romani",
      "Alessio Sampieri",
      "Luca Franco",
      "John Yang",
      "Yuta Kyuragi",
      "Fabio Galasso",
      "Tatsunori Hashimoto"
    ],
    "abstract": "Context lengths for models have grown rapidly, from thousands to millions of tokens in just a few years. The extreme context sizes of modern long-context models have made it difficult to construct realistic long-context benchmarks -- not only due to the cost of collecting million-context tasks but also in identifying realistic scenarios that require significant contexts. We identify code comprehension and repair as a natural testbed and challenge task for long-context models and introduce LongCodeBench (LCB), a benchmark to test LLM coding abilities in long-context scenarios. Our benchmark tests both the comprehension and repair capabilities of LCLMs in realistic and important settings by drawing from real-world GitHub issues and constructing QA (LongCodeQA) and bug fixing (LongSWE-Bench) tasks. We carefully stratify the complexity of our benchmark, enabling us to evaluate models across different scales -- ranging from Qwen2.5 14B Instruct to Google's flagship Gemini model. We find that long-context remains a weakness for all models, with performance drops such as from 29% to 3% for Claude 3.5 Sonnet, or from 70.2% to 40% for Qwen2.5. The LCB dataset is available publicly at https://huggingface.co/datasets/Steefano/LCB and the codebase to replicate the work on this paper at https://github.com/Zteefano/long-code-bench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07897v3",
    "published_date": "2025-05-12 05:38:03 UTC",
    "updated_date": "2025-10-22 01:04:53 UTC"
  },
  {
    "arxiv_id": "2505.07239v1",
    "title": "Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity",
    "authors": [
      "Guang Yan",
      "Yuhui Zhang",
      "Zimu Guo",
      "Lutan Zhao",
      "Xiaojun Chen",
      "Chen Wang",
      "Wenhao Wang",
      "Dan Meng",
      "Rui Hou"
    ],
    "abstract": "With the growing use of large language models (LLMs) hosted on cloud platforms to offer inference services, privacy concerns about the potential leakage of sensitive information are escalating. Secure multi-party computation (MPC) is a promising solution to protect the privacy in LLM inference. However, MPC requires frequent inter-server communication, causing high performance overhead.\n  Inspired by the prevalent activation sparsity of LLMs, where most neuron are not activated after non-linear activation functions, we propose an efficient private inference system, Comet. This system employs an accurate and fast predictor to predict the sparsity distribution of activation function output. Additionally, we introduce a new private inference protocol. It efficiently and securely avoids computations involving zero values by exploiting the spatial locality of the predicted sparse distribution. While this computation-avoidance approach impacts the spatiotemporal continuity of KV cache entries, we address this challenge with a low-communication overhead cache refilling strategy that merges miss requests and incorporates a prefetching mechanism. Finally, we evaluate Comet on four common LLMs and compare it with six state-of-the-art private inference systems. Comet achieves a 1.87x-2.63x speedup and a 1.94x-2.64x communication reduction.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to SP 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07239v1",
    "published_date": "2025-05-12 05:29:30 UTC",
    "updated_date": "2025-05-12 05:29:30 UTC"
  },
  {
    "arxiv_id": "2505.07236v1",
    "title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning",
    "authors": [
      "Oleg Sautenkov",
      "Yasheerah Yaqoot",
      "Muhammad Ahsan Mustafa",
      "Faryal Batool",
      "Jeffrin Sam",
      "Artem Lykov",
      "Chih-Yung Wen",
      "Dzmitry Tsetserukou"
    ],
    "abstract": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous UAV mission generation, built on large language and vision-language models (LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to interpret satellite imagery, ground high-level natural language instructions, and collaboratively generate UAV trajectories with minimal human supervision. A core component is a vision-grounded, pixel-pointing mechanism that enables precise localization of semantic targets on aerial maps. To support real-time adaptability, we introduce a reactive thinking loop, allowing agents to iteratively reflect on observations, revise mission goals, and coordinate dynamically in evolving environments.\n  UAV-CodeAgents is evaluated on large-scale mission scenarios involving industrial and environmental fire detection. Our results show that a lower decoding temperature (0.5) yields higher planning reliability and reduced execution time, with an average mission creation time of 96.96 seconds and a success rate of 93%. We further fine-tune Qwen2.5VL-7B on 9,000 annotated satellite images, achieving strong spatial grounding across diverse visual categories. To foster reproducibility and future research, we will release the full codebase and a novel benchmark dataset for vision-language-based UAV planning.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted",
    "pdf_url": "https://arxiv.org/pdf/2505.07236v1",
    "published_date": "2025-05-12 05:23:51 UTC",
    "updated_date": "2025-05-12 05:23:51 UTC"
  },
  {
    "arxiv_id": "2505.07233v2",
    "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation",
    "authors": [
      "Jiashuo Sun",
      "Xianrui Zhong",
      "Sizhe Zhou",
      "Jiawei Han"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems combine large language models (LLMs) with external knowledge retrieval, making them highly effective for knowledge-intensive tasks. A crucial but often under-explored component of these systems is the reranker. Since irrelevant documents in RAG systems can mislead the generator, the reranker plays a vital role in refining retrieved documents to enhance generation quality and explainability. However, it is challenging to determine the appropriate number of documents ($k$) that the reranker should select: too few may result in missing critical information, while too many introduce noise and inefficiencies. Although recent studies have explored LLM-based rerankers, they primarily leverage internal model knowledge and overlook the rich supervisory signals that LLMs can provide, such as using response quality as feedback for optimizing reranking decisions. In this paper, we propose DynamicRAG, a novel RAG framework where the reranker dynamically adjusts both the order and number of retrieved documents based on the query. We model the reranker as an agent optimized through reinforcement learning (RL), using rewards derived from LLM output quality. Across seven knowledge-intensive datasets, DynamicRAG demonstrates superior performance, achieving state-of-the-art results among models of same parameter sizes. The model, data and code are available at https://github.com/GasolSun36/DynamicRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 7 figures, 15 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.07233v2",
    "published_date": "2025-05-12 05:19:01 UTC",
    "updated_date": "2025-05-16 02:47:07 UTC"
  },
  {
    "arxiv_id": "2505.07215v1",
    "title": "Measuring General Intelligence with Generated Games",
    "authors": [
      "Vivek Verma",
      "David Huang",
      "William Chen",
      "Dan Klein",
      "Nicholas Tomlin"
    ],
    "abstract": "We present gg-bench, a collection of game environments designed to evaluate general reasoning capabilities in language models. Unlike most static benchmarks, gg-bench is a data generating process where new evaluation instances can be generated at will. In particular, gg-bench is synthetically generated by (1) using a large language model (LLM) to generate natural language descriptions of novel games, (2) using the LLM to implement each game in code as a Gym environment, and (3) training reinforcement learning (RL) agents via self-play on the generated games. We evaluate language models by their winrate against these RL agents by prompting models with the game description, current board state, and a list of valid moves, after which models output the moves they wish to take. gg-bench is challenging: state-of-the-art LLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench using in-context learning, while reasoning models such as o1, o3-mini and DeepSeek-R1 achieve average winrates of 31-36%. We release the generated games, data generation process, and evaluation code in order to support future modeling work and expansion of our benchmark.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07215v1",
    "published_date": "2025-05-12 04:01:03 UTC",
    "updated_date": "2025-05-12 04:01:03 UTC"
  },
  {
    "arxiv_id": "2505.07214v3",
    "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent",
    "authors": [
      "Pascal Spiegler",
      "Arash Harirpoush",
      "Yiming Xiao"
    ],
    "abstract": "Crucial in disease analysis and surgical planning, manual segmentation of volumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and challenging to master, while fully automatic algorithms can benefit from user feedback. Therefore, with the complementary power of the latest radiological AI foundation models and virtual reality (VR)'s intuitive data interaction, we propose SAMIRA, a novel conversational AI agent for medical VR that assists users with localizing, segmenting, and visualizing 3D medical concepts. Through speech-based interaction, the agent helps users understand radiological features, locate clinical targets, and generate segmentation masks that can be refined with just a few point prompts. The system also supports true-to-scale 3D visualization of segmented pathology to enhance patient-specific anatomical understanding. Furthermore, to determine the optimal interaction paradigm under near-far attention-switching for refining segmentation masks in an immersive, human-in-the-loop workflow, we compare VR controller pointing, head pointing, and eye tracking as input modes. With a user study, evaluations demonstrated a high usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as strong support for the proposed VR system's guidance, training potential, and integration of AI in radiological segmentation tasks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07214v3",
    "published_date": "2025-05-12 03:47:05 UTC",
    "updated_date": "2025-05-25 01:26:38 UTC"
  },
  {
    "arxiv_id": "2505.07896v1",
    "title": "Bridging Large Language Models and Single-Cell Transcriptomics in Dissecting Selective Motor Neuron Vulnerability",
    "authors": [
      "Douglas Jiang",
      "Zilin Dai",
      "Luxuan Zhang",
      "Qiyi Yu",
      "Haoqi Sun",
      "Feng Tian"
    ],
    "abstract": "Understanding cell identity and function through single-cell level sequencing data remains a key challenge in computational biology. We present a novel framework that leverages gene-specific textual annotations from the NCBI Gene database to generate biologically contextualized cell embeddings. For each cell in a single-cell RNA sequencing (scRNA-seq) dataset, we rank genes by expression level, retrieve their NCBI Gene descriptions, and transform these descriptions into vector embedding representations using large language models (LLMs). The models used include OpenAI text-embedding-ada-002, text-embedding-3-small, and text-embedding-3-large (Jan 2024), as well as domain-specific models BioBERT and SciBERT. Embeddings are computed via an expression-weighted average across the top N most highly expressed genes in each cell, providing a compact, semantically rich representation. This multimodal strategy bridges structured biological data with state-of-the-art language modeling, enabling more interpretable downstream applications such as cell-type clustering, cell vulnerability dissection, and trajectory inference.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07896v1",
    "published_date": "2025-05-12 03:39:33 UTC",
    "updated_date": "2025-05-12 03:39:33 UTC"
  },
  {
    "arxiv_id": "2505.07895v3",
    "title": "Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks",
    "authors": [
      "Jiafan Li",
      "Jiaqi Zhu",
      "Liang Chang",
      "Yilin Li",
      "Miaomiao Li",
      "Yang Wang",
      "Hongan Wang"
    ],
    "abstract": "Nowadays, numerous online platforms can be described as multi-modal heterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's product review networks. Accurately categorizing nodes within these networks is crucial for analyzing the corresponding entities, which requires effective representation learning on nodes. However, existing multi-modal fusion methods often adopt either early fusion strategies which may lose the unique characteristics of individual modalities, or late fusion approaches overlooking the cross-modal guidance in GNN-based information propagation. In this paper, we propose a novel model for node classification in MMHNs, named Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node representations by capturing the mutual influence of multiple modalities during the information propagation process, within the framework of heterogeneous graph transformer. Specifically, a nested inter-modal attention mechanism is integrated into the inter-node attention to achieve adaptive multi-modal fusion, and modality alignment is also taken into account to encourage the propagation among nodes with consistent similarities across all modalities. Moreover, an attention loss is augmented to mitigate the impact of missing modalities. Extensive experiments validate the superiority of the model in the node classification task, providing an innovative view to handle multi-modal data, especially when accompanied with network structures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07895v3",
    "published_date": "2025-05-12 02:59:46 UTC",
    "updated_date": "2025-06-19 09:49:10 UTC"
  },
  {
    "arxiv_id": "2505.08808v1",
    "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction",
    "authors": [
      "Anqing Jiang",
      "Jinhao Chai",
      "Yu Gao",
      "Yiru Wang",
      "Yuwen Heng",
      "Zhigang Sun",
      "Hao Sun",
      "Zezhong Zhao",
      "Li Sun",
      "Jian Zhou",
      "Lijuan Zhu",
      "Shugong Xu",
      "Hao Zhao"
    ],
    "abstract": "Recent advancements in high-definition \\emph{HD} map construction have demonstrated the effectiveness of dense representations, which heavily rely on computationally intensive bird's-eye view \\emph{BEV} features. While sparse representations offer a more efficient alternative by avoiding dense BEV processing, existing methods often lag behind due to the lack of tailored designs. These limitations have hindered the competitiveness of sparse representations in online HD map construction. In this work, we systematically revisit and enhance sparse representation techniques, identifying key architectural and algorithmic improvements that bridge the gap with--and ultimately surpass--dense approaches. We introduce a dedicated network architecture optimized for sparse map feature extraction, a sparse-dense segmentation auxiliary task to better leverage geometric and semantic cues, and a denoising module guided by physical priors to refine predictions. Through these enhancements, our method achieves state-of-the-art performance on the nuScenes dataset, significantly advancing HD map construction and centerline detection. Specifically, SparseMeXt-Tiny reaches a mean average precision \\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base attains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large achieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for sparse representations in HD map construction. These results underscore the untapped potential of sparse methods, challenging the conventional reliance on dense representations and redefining efficiency-performance trade-offs in the field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08808v1",
    "published_date": "2025-05-12 02:26:58 UTC",
    "updated_date": "2025-05-12 02:26:58 UTC"
  },
  {
    "arxiv_id": "2505.07178v1",
    "title": "Accountability of Generative AI: Exploring a Precautionary Approach for \"Artificially Created Nature\"",
    "authors": [
      "Yuri Nakao"
    ],
    "abstract": "The rapid development of generative artificial intelligence (AI) technologies raises concerns about the accountability of sociotechnical systems. Current generative AI systems rely on complex mechanisms that make it difficult for even experts to fully trace the reasons behind the outputs. This paper first examines existing research on AI transparency and accountability and argues that transparency is not a sufficient condition for accountability but can contribute to its improvement. We then discuss that if it is not possible to make generative AI transparent, generative AI technology becomes ``artificially created nature'' in a metaphorical sense, and suggest using the precautionary principle approach to consider AI risks. Finally, we propose that a platform for citizen participation is needed to address the risks of generative AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.07178v1",
    "published_date": "2025-05-12 02:10:55 UTC",
    "updated_date": "2025-05-12 02:10:55 UTC"
  },
  {
    "arxiv_id": "2505.08807v1",
    "title": "Security of Internet of Agents: Attacks and Countermeasures",
    "authors": [
      "Yuntao Wang",
      "Yanghe Pan",
      "Shaolong Guo",
      "Zhou Su"
    ],
    "abstract": "With the rise of large language and vision-language models, AI agents have evolved into autonomous, interactive systems capable of perception, reasoning, and decision-making. As they proliferate across virtual and physical domains, the Internet of Agents (IoA) has emerged as a key infrastructure for enabling scalable and secure coordination among heterogeneous agents. This survey offers a comprehensive examination of the security and privacy landscape in IoA systems. We begin by outlining the IoA architecture and its distinct vulnerabilities compared to traditional networks, focusing on four critical aspects: identity authentication threats, cross-agent trust issues, embodied security, and privacy risks. We then review existing and emerging defense mechanisms and highlight persistent challenges. Finally, we identify open research directions to advance the development of resilient and privacy-preserving IoA ecosystems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 5 figures, 3 tables, submitted to IEEE OJCS",
    "pdf_url": "https://arxiv.org/pdf/2505.08807v1",
    "published_date": "2025-05-12 02:04:57 UTC",
    "updated_date": "2025-05-12 02:04:57 UTC"
  },
  {
    "arxiv_id": "2505.07176v2",
    "title": "Internet of Agents: Fundamentals, Applications, and Challenges",
    "authors": [
      "Yuntao Wang",
      "Shaolong Guo",
      "Yanghe Pan",
      "Zhou Su",
      "Fahao Chen",
      "Tom H. Luan",
      "Peng Li",
      "Jiawen Kang",
      "Dusit Niyato"
    ],
    "abstract": "With the rapid proliferation of large language models and vision-language models, AI agents have evolved from isolated, task-specific systems into autonomous, interactive entities capable of perceiving, reasoning, and acting without human intervention. As these agents proliferate across virtual and physical environments, from virtual assistants to embodied robots, the need for a unified, agent-centric infrastructure becomes paramount. In this survey, we introduce the Internet of Agents (IoA) as a foundational framework that enables seamless interconnection, dynamic discovery, and collaborative orchestration among heterogeneous agents at scale. We begin by presenting a general IoA architecture, highlighting its hierarchical organization, distinguishing features relative to the traditional Internet, and emerging applications. Next, we analyze the key operational enablers of IoA, including capability notification and discovery, adaptive communication protocols, dynamic task matching, consensus and conflict-resolution mechanisms, and incentive models. Finally, we identify open research directions toward building resilient and trustworthy IoA ecosystems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "25 pages,10 figures, 10 tables. Accepted by IEEE TCCN in Oct. 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07176v2",
    "published_date": "2025-05-12 02:04:37 UTC",
    "updated_date": "2025-10-16 09:32:37 UTC"
  },
  {
    "arxiv_id": "2505.07171v1",
    "title": "ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion",
    "authors": [
      "Jeongho Kim",
      "Chanyeong Heo",
      "Jaehee Jung"
    ],
    "abstract": "Knowledge Graphs (KGs), composed of triples in the form of (head, relation, tail) and consisting of entities and relations, play a key role in information retrieval systems such as question answering, entity search, and recommendation. In real-world KGs, although many entities exist, the relations exhibit a long-tail distribution, which can hinder information retrieval performance. Previous few-shot knowledge graph completion studies focused exclusively on the positive triple information that exists in the graph or, when negative triples were incorporated, used them merely as a signal to indicate incorrect triples. To overcome this limitation, we propose Relation-Based Conditional Diffusion with Attention Pooling (ReCDAP). First, negative triples are generated by randomly replacing the tail entity in the support set. By conditionally incorporating positive information in the KG and non-existent negative information into the diffusion process, the model separately estimates the latent distributions for positive and negative relations. Moreover, including an attention pooler enables the model to leverage the differences between positive and negative cases explicitly. Experiments on two widely used datasets demonstrate that our method outperforms existing approaches, achieving state-of-the-art performance. The code is available at https://github.com/hou27/ReCDAP-FKGC.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by SIGIR 2025, 5 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2505.07171v1",
    "published_date": "2025-05-12 01:49:52 UTC",
    "updated_date": "2025-05-12 01:49:52 UTC"
  },
  {
    "arxiv_id": "2505.07161v1",
    "title": "Towards Actionable Pedagogical Feedback: A Multi-Perspective Analysis of Mathematics Teaching and Tutoring Dialogue",
    "authors": [
      "Jannatun Naim",
      "Jie Cao",
      "Fareen Tasneem",
      "Jennifer Jacobs",
      "Brent Milne",
      "James Martin",
      "Tamara Sumner"
    ],
    "abstract": "Effective feedback is essential for refining instructional practices in mathematics education, and researchers often turn to advanced natural language processing (NLP) models to analyze classroom dialogues from multiple perspectives. However, utterance-level discourse analysis encounters two primary challenges: (1) multifunctionality, where a single utterance may serve multiple purposes that a single tag cannot capture, and (2) the exclusion of many utterances from domain-specific discourse move classifications, leading to their omission in feedback. To address these challenges, we proposed a multi-perspective discourse analysis that integrates domain-specific talk moves with dialogue act (using the flattened multi-functional SWBD-MASL schema with 43 tags) and discourse relation (applying Segmented Discourse Representation Theory with 16 relations). Our top-down analysis framework enables a comprehensive understanding of utterances that contain talk moves, as well as utterances that do not contain talk moves. This is applied to two mathematics education datasets: TalkMoves (teaching) and SAGA22 (tutoring). Through distributional unigram analysis, sequential talk move analysis, and multi-view deep dive, we discovered meaningful discourse patterns, and revealed the vital role of utterances without talk moves, demonstrating that these utterances, far from being mere fillers, serve crucial functions in guiding, acknowledging, and structuring classroom discourse. These insights underscore the importance of incorporating discourse relations and dialogue acts into AI-assisted education systems to enhance feedback and create more responsive learning environments. Our framework may prove helpful for providing human educator feedback, but also aiding in the development of AI agents that can effectively emulate the roles of both educators and students.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EDM'2025",
    "pdf_url": "https://arxiv.org/pdf/2505.07161v1",
    "published_date": "2025-05-12 00:48:17 UTC",
    "updated_date": "2025-05-12 00:48:17 UTC"
  }
]