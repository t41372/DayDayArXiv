{
  "date": "2026-01-17",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„å­¦æœ¯æ—¥æŠ¥ä¸“æ ä½œè€…ã€‚\n\næ¬¢è¿æ¥åˆ° **UTC æ—¶é—´ 2026-01-17** çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä¸€å¥è¯æ€»ç»“ä»Šå¤©ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹æŠ—æ€§ä¸åæ€ã€‚**æ¨ç†ï¼ˆReasoningï¼‰** é¢†åŸŸè¿æ¥äº†å…³äº Long-CoT â€œæ€ç»´é™·é˜±â€çš„æ·±åº¦å‰–æï¼Œä»¥åŠä»£ç éªŒè¯å™¨ï¼ˆCode Verifiersï¼‰çš„å¼ºåŒ–å­¦ä¹ æ–°èŒƒå¼ï¼›**Agent** é¢†åŸŸåˆ™å‡ºç°äº†å— LSTM å¯å‘çš„é•¿ä¸Šä¸‹æ–‡å¤šæ™ºèƒ½ä½“æ¶æ„å’Œé«˜éš¾åº¦çš„ CLI å‘½ä»¤è¡ŒåŸºå‡†æµ‹è¯•ï¼›**å®‰å…¨**æ–¹é¢ï¼Œè§†è§‰ Token å‹ç¼©å¸¦æ¥çš„è„†å¼±æ€§å’Œæ— éœ€è®­ç»ƒçš„æˆå‘˜æ¨æ–­æ”»å‡»ï¼ˆMIAï¼‰ä»¤äººè­¦é†’ã€‚\n\nä»¥ä¸‹æ˜¯ä»Šå¤©çš„ç²¾é€‰æ·±åº¦è§£è¯»ï¼š\n\n---\n\n### ğŸš€ æ·±åº¦æ¨ç†ä¸ä»£ç ç”Ÿæˆ (Reasoning & Code)\n\n**1. [æ¨è] æ­ç§˜ Long-CoT çš„æ­»èƒ¡åŒ**\n**æ ‡é¢˜ï¼šThinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart (Long-CoT ä¸­çš„æ€ç»´é™·é˜±ï¼šå¯åº¦é‡ç ”ç©¶ä¸é™·é˜±æ„ŸçŸ¥è‡ªé€‚åº”é‡å¯)**\n*   **æ ¸å¿ƒå‘ç°ï¼š** Long-CoT è™½ç„¶é€šè¿‡æ‰©å±•æ¨ç†æå‡äº†èƒ½åŠ›ï¼Œä½†ä½œè€…å‘ç°äº†ä¸€ä¸ªè‡´å‘½é—®é¢˜ï¼š**æ€ç»´é™·é˜±ï¼ˆThinking Trapsï¼‰**ã€‚å³æ¨¡å‹ä¸€æ—¦æ—©æœŸåšå‡ºé”™è¯¯æ‰¿è¯ºï¼Œåç»­çš„é•¿ç¯‡å¤§è®ºå¾€å¾€åªæ˜¯åœ¨â€œåœ†è°â€ï¼Œå³ä½¿è‡ªæˆ‘åæ€ä¹Ÿæ— æ³•è·³å‡ºã€‚åœ¨ DAPO-MATH å­é›†ä¸­ï¼Œ89% çš„å¤±è´¥æ¡ˆä¾‹éƒ½æºäºæ­¤ã€‚\n*   **æ–¹æ³•ï¼š** æå‡ºäº† **TAAR** æ¡†æ¶ï¼Œè®­ç»ƒä¸€ä¸ªè¯Šæ–­ç­–ç•¥æ¥é¢„æµ‹è½¨è¿¹ä¸­çš„â€œé™·é˜±â€ä½ç½®ï¼Œå¹¶åœ¨æ¨ç†æ—¶è‡ªåŠ¨æˆªæ–­å¹¶é‡å¯ï¼ˆRestartï¼‰ï¼Œç”šè‡³é€šè¿‡æé«˜é‡‡æ ·æ¸©åº¦æ¥å¼ºè¡Œå¼•å…¥æ‰°åŠ¨ï¼Œæ‰“ç ´æ­»å¾ªç¯ã€‚\n\n**2. [é‡ç£…] ä»£ç éªŒè¯å™¨çš„å¼ºåŒ–å­¦ä¹ é…æ–¹**\n**æ ‡é¢˜ï¼šAletheia: What Makes RLVR For Code Verifiers Tick? (Aletheiaï¼šæ˜¯ä»€ä¹ˆè®©ä»£ç éªŒè¯å™¨çš„ RLVR èµ·ä½œç”¨ï¼Ÿ)**\n*   **æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹ä»£ç ç”Ÿæˆåè®­ç»ƒï¼ˆPost-trainingï¼‰ï¼Œç ”ç©¶äº†åŸºäº RLVRï¼ˆReinforcement Learning from Verifiable Rewardsï¼‰çš„éªŒè¯å™¨ã€‚ä½œè€…å¼€æºäº† **Aletheia** æµ‹è¯•åºŠã€‚\n*   **å…³é”®æ´å¯Ÿï¼š** ç ”ç©¶å‘ç°ï¼Œè™½ç„¶ RLVR æ•ˆæœæ˜¾è‘—ï¼Œä½†é…æ–¹å¯ä»¥ç®€åŒ–ã€‚å¯¹äºå°è§„æ¨¡éªŒè¯å™¨ï¼Œ**On-policy learning**ï¼ˆåœ¨çº¿ç­–ç•¥å­¦ä¹ ï¼‰æ˜¯å…³é”®ï¼›è€Œå¯¹äºå¤§è§„æ¨¡éªŒè¯å™¨ï¼Œ**Thinking-based training**ï¼ˆåŸºäºæ€ç»´é“¾çš„è®­ç»ƒï¼‰åˆ™æ˜¯æ ¸å¿ƒã€‚è¿™ä¸ºä»£ç å¤§æ¨¡å‹çš„ scaling laws æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚\n\n**3. ç¥ç»ç¬¦å·æ¨ç†å›å½’**\n**æ ‡é¢˜ï¼šImandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic (Imandra CodeLogicianï¼šç”¨äºè½¯ä»¶é€»è¾‘ç²¾ç¡®åˆ†æçš„ç¥ç»ç¬¦å·æ¨ç†)**\n*   **æ ¸å¿ƒï¼š** ç°åœ¨çš„ LLM å†™ä»£ç è¿˜è¡Œï¼Œä½†åšä¸¥æ ¼çš„æ•°å­¦æ¨ç†å’Œå½¢å¼åŒ–éªŒè¯å¾ˆå¼±ã€‚æœ¬æ–‡æå‡ºäº† **CodeLogician**ï¼Œä¸€ä¸ªç¥ç»ç¬¦å· Agentï¼Œç»“åˆäº† LLM å’Œå·¥ä¸šçº§è‡ªåŠ¨æ¨ç†å¼•æ“ï¼ˆImandraXï¼‰ã€‚\n*   **æ•ˆæœï¼š** ä¸å†åªæ˜¯è®© LLM ççŒœï¼Œè€Œæ˜¯æ„å»ºå½¢å¼åŒ–æ¨¡å‹ã€‚åœ¨æ–°å»ºçš„ `code-logic-bench` åŸºå‡†ä¸Šï¼Œç›¸æ¯”çº¯ LLMï¼Œæ¨ç†å‡†ç¡®ç‡æå‡äº† 41-47 ä¸ªç™¾åˆ†ç‚¹ã€‚\n\n---\n\n### ğŸ¤– æ™ºèƒ½ä½“ä¸é•¿ä¸Šä¸‹æ–‡ (Agents & Long-Context)\n\n**4. LSTM å¤æ´»ï¼Ÿå¤šæ™ºèƒ½ä½“æ–°æ¶æ„**\n**æ ‡é¢˜ï¼šLSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding (LSTM-MASï¼šå— LSTM å¯å‘çš„é•¿ä¸Šä¸‹æ–‡ç†è§£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ)**\n*   **è„‘æ´ï¼š** é¢å¯¹é•¿æ–‡æœ¬ï¼Œç°æœ‰çš„å¤šæ™ºèƒ½ä½“å®¹æ˜“äº§ç”Ÿè¯¯å·®ç´¯ç§¯ã€‚ä½œè€…å±…ç„¶ä» **LSTM** ä¸­æ±²å–çµæ„Ÿï¼Œè®¾è®¡äº†ä¸€ä¸ªé“¾å¼ Agent æ¶æ„ã€‚\n*   **æœºåˆ¶ï¼š** ç³»ç»Ÿä¸­çš„ Agent åˆ†åˆ«æ‰®æ¼” LSTM ä¸­çš„ä¸åŒè§’è‰²ï¼šWorkerï¼ˆå¤„ç†ï¼‰ã€Filterï¼ˆé—å¿˜/è¿‡æ»¤ï¼‰ã€Judgeï¼ˆçº é”™ï¼‰ã€Managerï¼ˆå…¨å±€é—¨æ§ï¼‰ã€‚åœ¨ NarrativeQA ç­‰æ•°æ®é›†ä¸Šæ¯”ä¹‹å‰çš„ SOTA æ–¹æ³• CoA æå‡äº† 40% ä»¥ä¸Šã€‚\n\n**5. çœŸæ­£çš„é»‘å®¢å¸å›½åŸºå‡†æµ‹è¯•**\n**æ ‡é¢˜ï¼šTerminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces (Terminal-Benchï¼šåœ¨å‘½ä»¤è¡Œç•Œé¢ä¸­å¯¹ Agent è¿›è¡Œé«˜éš¾åº¦ç°å®ä»»åŠ¡åŸºå‡†æµ‹è¯•)**\n*   **èƒŒæ™¯ï¼š** å¾ˆå¤š Agent benchmark å¤ªç®€å•æˆ–å¤ªè™šã€‚\n*   **è´¡çŒ®ï¼š** å‘å¸ƒäº† **Terminal-Bench 2.0**ï¼ŒåŒ…å« 89 ä¸ªå—çœŸå®å·¥ä½œæµå¯å‘çš„ CLI ä»»åŠ¡ã€‚\n*   **ç»“æœï¼š** å³ä½¿æ˜¯å‰æ²¿æ¨¡å‹ï¼Œé€šè¿‡ç‡ä¹Ÿä¸åˆ° 65%ã€‚è¿™æ‰æ˜¯æ£€éªŒ Agent çœŸçš„èƒ½ä¸èƒ½â€œå¹²æ´»â€çš„ç¡¬æ ¸è€ƒåœºã€‚\n\n**6. å¯¹æŠ—â€œä¸Šä¸‹æ–‡è…çƒ‚â€**\n**æ ‡é¢˜ï¼šARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents (ARCï¼šç”¨äºé•¿ç¨‹ä¿¡æ¯æœç´¢ Agent çš„ä¸»åŠ¨åæ€é©±åŠ¨ä¸Šä¸‹æ–‡ç®¡ç†)**\n*   **é—®é¢˜ï¼š** ä»»åŠ¡ä¸€é•¿ï¼ŒAgent çš„ä¸Šä¸‹æ–‡å°±å®¹æ˜“ç”±â€œContext Rotâ€ï¼ˆä¸Šä¸‹æ–‡è…çƒ‚ï¼‰ï¼Œå……æ»¡äº†æ— å…³ä¿¡æ¯æˆ–æ—©æœŸé”™è¯¯ã€‚\n*   **æ–¹æ³•ï¼š** æŠŠä¸Šä¸‹æ–‡ç®¡ç†å˜æˆä¸€ä¸ª**ä¸»åŠ¨çš„ã€åæ€é©±åŠ¨**çš„è¿‡ç¨‹ï¼Œè€Œä¸æ˜¯è¢«åŠ¨å †ç§¯ã€‚Agent ä¼šç›‘æ§å¹¶â€œä¿®å‰ª/é‡ç»„â€è‡ªå·±çš„è®°å¿†ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸å¤šæ¨¡æ€ (Vision & Multimodal)\n\n**7. ç»Ÿä¸€åˆ†å‰²ä¸æŠ å›¾**\n**æ ‡é¢˜ï¼šSegment and Matte Anything in a Unified Model (åœ¨ç»Ÿä¸€æ¨¡å‹ä¸­åˆ†å‰²å’ŒæŠ å›¾ä»»ä½•äº‹ç‰©)**\n*   **æ–¹æ³•ï¼š** æå‡ºäº† **SAMA** (Segment And Matte Anything)ï¼Œè¿™æ˜¯ SAM (Segment Anything Model) çš„è½»é‡çº§æ‰©å±•ã€‚\n*   **äº®ç‚¹ï¼š** åœ¨ä¸€ä¸ªæ¨¡å‹é‡ŒåŒæ—¶æå®šé«˜è´¨é‡çš„åˆ†å‰²å’Œäº¤äº’å¼æŠ å›¾ï¼ˆMattingï¼‰ï¼Œå¼•å…¥äº† MVLE æ¨¡å—æ•æ‰ç»†èŠ‚ï¼Œå‚æ•°å¢åŠ å¾ˆå°‘ä½†æ•ˆæœ SOTAã€‚\n\n**8. å‹ç¼©è§†è§‰ Token çš„ä»£ä»·**\n**æ ‡é¢˜ï¼šLess Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models (å°‘å³æ˜¯å¤šâ€”â€”ç›´åˆ°å´©æºƒï¼šå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸­è§†è§‰ Token å‹ç¼©çš„å®‰å…¨é™·é˜±)**\n*   **è­¦ç¤ºï¼š** ä¸ºäº†å¿«ï¼Œå¤§å®¶éƒ½åœ¨å‹ç¼© Vision Tokenã€‚ä½†ä½œè€…å‘ç°ï¼Œè¿™ä¸¥é‡ç ´åäº†é²æ£’æ€§ã€‚\n*   **æ”»å‡»ï¼š** æå‡ºäº† **Compression-Aware Attack**ï¼Œåªéœ€å¾®å°çš„æ‰°åŠ¨æ”¹å˜ Token çš„é‡è¦æ€§æ’åºï¼Œå°±èƒ½è®©å‹ç¼©æœºåˆ¶ä¸¢å¼ƒå…³é”®ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å‹ç¼©æ¨¡å¼ä¸‹å®Œå…¨å¤±æ•ˆï¼Œè€Œæœªå‹ç¼©æ¨¡å¼å´æ­£å¸¸ï¼ˆéå¸¸éšè”½ï¼‰ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€éšç§ä¸ä¼¦ç† (Safety & Privacy)\n\n**9. æå…¶å¼ºå¤§çš„æˆå‘˜æ¨æ–­æ”»å‡»**\n**æ ‡é¢˜ï¼šPowerful Training-Free Membership Inference Against Autoregressive Language Models (é’ˆå¯¹è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„å¼ºå¤§å…è®­ç»ƒæˆå‘˜æ¨æ–­)**\n*   **æ–¹æ³•ï¼š** æå‡ºäº† **EZ-MIA**ã€‚æ ¸å¿ƒè§‚å¯Ÿæ˜¯ï¼šæ¨¡å‹â€œè®°ä½â€çš„æ•°æ®ï¼Œå¾€å¾€åœ¨å®ƒ**é¢„æµ‹é”™è¯¯**çš„åœ°æ–¹ä¾ç„¶è¡¨ç°å‡ºå¼‚å¸¸é«˜çš„æ¦‚ç‡ï¼ˆError Zoneï¼‰ã€‚\n*   **æˆ˜ç»©ï¼š** æ— éœ€è®­ç»ƒä»»ä½•å‚è€ƒæ¨¡å‹ï¼Œåœ¨æä½è¯¯æŠ¥ç‡ï¼ˆ0.1% FPRï¼‰ä¸‹ï¼Œæ£€æµ‹ç‡æ¯”å‰äººé«˜ 8 å€ã€‚è¿™å¯¹å¾®è°ƒæ¨¡å‹çš„éšç§å®¡è®¡æ˜¯å·¨å¤§çš„æŒ‘æˆ˜ã€‚\n\n**10. è‡ªåŠ¨é©¾é©¶ LLM çš„å®‰å…¨åˆ†ç±»å­¦**\n**æ ‡é¢˜ï¼šDriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants (DriveSafeï¼šåŸºäº LLM çš„å®‰å…¨å…³é”®å‹é©¾é©¶åŠ©æ‰‹çš„é£é™©åˆ†ç±»å­¦)**\n*   **ç°çŠ¶ï¼š** LLM ä¸Šè½¦ï¼ˆè½¦è½½åŠ©æ‰‹ï¼‰å¾ˆç«ï¼Œä½†ä¸‡ä¸€å®ƒçæŒ‡æŒ¥æ€ä¹ˆåŠï¼Ÿ\n*   **è´¡çŒ®ï¼š** å»ºç«‹äº†åŒ…å« 129 ä¸ªç»†ç²’åº¦é£é™©ç±»åˆ«çš„ **DriveSafe** åˆ†ç±»å­¦ã€‚æµ‹è¯•å‘ç°ç›®å‰çš„ LLM ç»å¸¸æ— æ³•æ­£ç¡®æ‹’ç»ä¸å®‰å…¨æˆ–è¿è§„çš„é©¾é©¶æŒ‡ä»¤ã€‚\n\n---\n\n### ğŸ’¡ è„‘æ´ä¸æ–°æ–¹å‘ (Novel Ideas)\n\n**11. ç›´æ¥ç”¨äººè„‘æ•°æ®è®­ç»ƒ AIï¼Ÿ**\n**æ ‡é¢˜ï¼šA New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data (äººå·¥æ™ºèƒ½æ–°ç­–ç•¥ï¼šç›´æ¥åœ¨äººè„‘æ•°æ®ä¸Šè®­ç»ƒåŸºç¡€æ¨¡å‹)**\n*   **è§‚ç‚¹ï¼š** ç°åœ¨çš„ AI è¿˜æ˜¯å­¦äººç±»äº§ç”Ÿçš„æ–‡æœ¬ï¼ˆäºŒæ‰‹çŸ¥è¯†ï¼‰ã€‚ä½œè€…æ¿€è¿›åœ°æå‡ºï¼Œåº”è¯¥ç›´æ¥åˆ©ç”¨ç¥ç»å½±åƒæ•°æ®ï¼ˆfMRIç­‰ï¼‰è¿›è¡Œ **RLHB** (Reinforcement Learning from Human Brain) å’Œ **CoTHB**ã€‚è™½ç„¶ç›®å‰è¿˜åœ¨ç†è®ºæ¢è®¨é˜¶æ®µï¼Œä½†è§†è§’éå¸¸ç‹¬ç‰¹ã€‚\n\n**12. æ›´åŠ ç¯ä¿çš„ç»“æ„åŒ–è¾“å‡ºæ ¼å¼ TOON**\n**æ ‡é¢˜ï¼šAre LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs (LLM å‡†å¤‡å¥½è¿æ¥ TOON äº†å—ï¼Ÿç»“æ„æ­£ç¡®æ€§ä¸å¯æŒç»­æ€§çš„æƒè¡¡åŸºå‡†æµ‹è¯•)**\n*   **å‘ç°ï¼š** JSON å’Œ XML å¤ªå•°å—¦ï¼Œæµªè´¹ Token å’Œç®—åŠ›ã€‚ä½œè€…æ¨å´‡ **TOON** æ ¼å¼ï¼Œæ›´ç´§å‡‘ã€ç¢³æ’æ”¾æ›´ä½ã€‚è™½ç„¶ç›®å‰æ¨¡å‹å¯¹å®ƒçš„åŸç”Ÿæ”¯æŒä¸å¦‚ JSONï¼Œä½†é€šè¿‡æå‡æ¨¡å‹èƒ½åŠ›å¯ä»¥å¼¥è¡¥ã€‚\n\n---\n\n### ğŸ¥ åŒ»ç–—ä¸ç§‘å­¦ (Medical & Science)\n\n*   **ç—…ç†å¤§æ¨¡å‹ä¼˜åŒ– (Paper 2):** é’ˆå¯¹å…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰å·¨å¤§çš„åˆ†è¾¨ç‡ï¼Œæå‡ºäº†ä¸€ç§ç©ºé—´æ„ŸçŸ¥æ³¨æ„åŠ›å’Œéä¿¡æ¯ Token è¿‡æ»¤ç­–ç•¥ï¼Œæ˜¾å­˜å ç”¨å¤§é™ï¼Œæ€§èƒ½åè€Œæå‡ã€‚\n*   **ç—…ç†é¢„æµ‹ä¿®æ­£ (Paper 13):** åˆ©ç”¨æ¡ä»¶éšæœºåœº (CRF) ä¿®æ­£å¤šæ¨¡æ€å¤§æ¨¡å‹çš„ç—…ç†é¢„æµ‹ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ŒHuman-in-the-loop æ•ˆæœæ˜¾è‘—ã€‚\n\n---\n\n### ğŸ“ å…¶ä»–å€¼å¾—å…³æ³¨çš„è®ºæ–‡ (Quick Skim)\n\n*   **[Paper 23] å•†ä¸šå»ºè®® Agent:** å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ†æå®¢æˆ·è¯„è®ºï¼Œç”Ÿæˆå¯æ‰§è¡Œçš„å•†ä¸šå»ºè®®ã€‚\n*   **[Paper 35] Double-Calibration:** åŒé‡æ ¡å‡†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ RAG ä¸­çš„å¹»è§‰å’Œç½®ä¿¡åº¦ä¸å‡†é—®é¢˜ã€‚\n*   **[Paper 43] DevBench:** ä¸€ä¸ªåŸºäºçœŸå®å¼€å‘è€…é¥æµ‹æ•°æ®çš„ä»£ç ç”Ÿæˆ Benchmarkï¼Œå¼ºè°ƒç”Ÿæ€æœ‰æ•ˆæ€§ã€‚\n*   **[Paper 6] äºº-äºº-AI ä¸‰è§’ç¼–ç¨‹:** ç ”ç©¶å‘ç°ï¼ŒæŠŠ AI å½“ä½œâ€œç¬¬ä¸‰ä¸ªåˆä½œè€…â€è€Œä¸æ˜¯æ›¿ä»£è€…ï¼Œèƒ½æ›´å¥½åœ°ä¿ƒè¿›äººç±»çš„å­¦ä¹ å’Œç¤¾äº¤å­˜åœ¨æ„Ÿã€‚\n*   **[Paper 51] å®šæ€§ç ”ç©¶è¾…åŠ©:** ä½¿ç”¨ GPT è¾…åŠ©å½’çº³ä¸»é¢˜åˆ†æï¼ˆThematic Analysisï¼‰ï¼Œå¼ºè°ƒäººç±»ä»æŒæ¡è§£é‡Šæƒã€‚\n\nä»Šå¤©çš„ arXiv å¿«æŠ¥å°±åˆ°è¿™é‡Œã€‚ç¥å¤§å®¶ç§‘ç ”é¡ºåˆ©ï¼Œä¸è¦æ‰è¿› Thinking Trapsï¼ğŸ‘‹",
  "papers": [
    {
      "arxiv_id": "2601.12186v1",
      "title": "Aletheia: What Makes RLVR For Code Verifiers Tick?",
      "title_zh": "Aletheiaï¼šä»£ç éªŒè¯å™¨ RLVR çš„è¿è¡Œæœºåˆ¶æ¢ç©¶",
      "authors": [
        "Vatsal Venkatkrishna",
        "Indraneil Paul",
        "Iryna Gurevych"
      ],
      "abstract": "Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ›å»ºå¹¶å¼€æºäº† Aletheiaï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¯¹ä»£ç éªŒè¯å™¨ï¼ˆcode verifiersï¼‰ç¨³å¥æ€§è¿›è¡ŒåŸºäºæ‰§è¡Œï¼ˆexecution-groundedï¼‰è¯„ä¼°çš„å—æ§æµ‹è¯•å¹³å°ã€‚ç ”ç©¶è€…ç³»ç»Ÿè€ƒå¯Ÿäº†åŸºäºå¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰è®­ç»ƒä»£ç éªŒè¯å™¨çš„æ ¸å¿ƒè¦ç´ ï¼ŒåŒ…æ‹¬ä¸­é—´æ€ç»´é“¾ï¼ˆthinking tracesï¼‰ã€è´Ÿæ ·æœ¬å­¦ä¹ å’ŒåŒç­–ç•¥ï¼ˆon-policyï¼‰è®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œå°½ç®¡ RLVR å±•ç°äº†æœ€ä¼˜æ€§èƒ½ï¼Œä½†å…¶è®­ç»ƒæ–¹æ¡ˆå­˜åœ¨ç®€åŒ–ç©ºé—´ã€‚ç ”ç©¶æ­ç¤ºäº†ä»£ç éªŒè¯åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µçš„æ‰©å±•æ•ˆåº”ï¼ˆscalingï¼‰ï¼šåœ¨è¾ƒå°è§„æ¨¡çš„éªŒè¯å™¨ä¸­ï¼ŒåŒç­–ç•¥å­¦ä¹ æ˜¯æˆåŠŸçš„å…³é”®ï¼›è€Œåœ¨è¾ƒå¤§è§„æ¨¡ä¸‹ï¼ŒåŸºäºæ€ç»´çš„è®­ç»ƒï¼ˆthinking-based trainingï¼‰åˆ™æˆä¸ºæœ€é‡è¦çš„ç»„æˆéƒ¨åˆ†ã€‚è¯¥å·¥ä½œä¸ºåœ¨æ‰§è¡Œåé¦ˆéš¾ä»¥è·å–çš„åœºæ™¯ä¸‹æå‡ä»£ç ç”Ÿæˆè´¨é‡æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12186v1",
      "published_date": "2026-01-17 22:30:45 UTC",
      "updated_date": "2026-01-17 22:30:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:12.129097+00:00"
    },
    {
      "arxiv_id": "2601.12150v1",
      "title": "Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models",
      "title_zh": "é€šè¿‡å¤§åˆ†è¾¨ç‡æ¨ç†ä¼˜åŒ–æå‡ç—…ç†åŸºç¡€æ¨¡å‹çš„è¯Šæ–­æ€§èƒ½",
      "authors": [
        "Mengxuan Hu",
        "Zihan Guan",
        "John Kang",
        "Sheng Li",
        "Zhongliang Zhou"
      ],
      "abstract": "Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ç—…ç†åŸºç¡€æ¨¡å‹(Pathology Foundation Models)çš„ç©ºé—´ä¸æ—¶é—´é«˜æ•ˆæ¨ç†ç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡å…¨åˆ‡ç‰‡å›¾åƒ(WSIs)æ—¶é¢ä¸´çš„æ˜¾å­˜æ¶ˆè€—æ¿€å¢ä¸å½¢æ€ç»†èŠ‚ä¸¢å¤±é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡ç©ºé—´æ„ŸçŸ¥é‚»è¿‘å—(spatially aware neighboring blocks)ç¨€ç–åŒ–æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶åˆ©ç”¨å…¨å±€æ³¨æ„åŠ›åˆ†æ•°è¿‡æ»¤éä¿¡æ¯æ€§ä»¤ç‰Œ(tokens)ï¼Œå®ç°äº†åœ¨ç›¸åŒGPUé¢„ç®—ä¸‹å¤„ç†æ›´é«˜åˆ†è¾¨ç‡çš„è¾“å…¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç­–ç•¥åœ¨ROIåˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†é«˜è¾¾7.67%çš„æ€§èƒ½æå‡ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†æ¨ç†è€—æ—¶ã€‚è¿™ä¸€ä¼˜åŒ–æ–¹æ¡ˆä¸ºç—…ç†AIæ¨¡å‹åœ¨ä¸´åºŠå¤§è§„æ¨¡å½±åƒåˆ†æä¸­çš„å®é™…åº”ç”¨æä¾›äº†é«˜æ•ˆä¸”ç²¾å‡†çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.12150v1",
      "published_date": "2026-01-17 19:50:40 UTC",
      "updated_date": "2026-01-17 19:50:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:03.090506+00:00"
    },
    {
      "arxiv_id": "2601.12147v1",
      "title": "Segment and Matte Anything in a Unified Model",
      "title_zh": "ç»Ÿä¸€æ¨¡å‹ä¸‹çš„ä¸‡ç‰©åˆ†å‰²ä¸æŠ å›¾",
      "authors": [
        "Zezhong Fan",
        "Xiaohan Li",
        "Topojoy Biswas",
        "Kaushiki Nag",
        "Kannan Achan"
      ],
      "abstract": "Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SAMA (Segment And Matte Anything)ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ Segment Anything (SAM) çš„è½»é‡çº§æ‰©å±•æ¡†æ¶ï¼Œæ—¨åœ¨ç»Ÿä¸€å®ç°é«˜è´¨é‡çš„äº¤äº’å¼å›¾åƒåˆ†å‰²å’ŒæŠ å›¾ (Matting)ã€‚ä¸ºäº†è§£å†³ SAM åˆ†å‰²ç²¾åº¦ä¸è¶³åŠæ— æ³•ç”Ÿæˆç»†ç²’åº¦ alpha mattes çš„é—®é¢˜ï¼ŒSAMA å¼•å…¥äº† Multi-View Localization Encoder (MVLE) æ¥æ•æ‰å±€éƒ¨è§†å›¾çš„è¯¦ç»†ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨ Localization Adapter (Local-Adapter) ç»†åŒ–è¾¹ç•Œç»†èŠ‚ã€‚è¯¥æ¶æ„é€šè¿‡é›†æˆåŒé¢„æµ‹å¤´è®¾è®¡ï¼Œèƒ½å¤ŸåŒæ­¥ç”Ÿæˆåˆ†å‰²å’ŒæŠ å›¾æ©ç ï¼Œä¸”ä»…å¢åŠ äº†æå°‘çš„é¢å¤–å‚æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSAMA åœ¨å¤šä¸ªåˆ†å‰²å’ŒæŠ å›¾åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº† SOTA æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„å“è¶Šé€‚åº”æ€§å’Œæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12147v1",
      "published_date": "2026-01-17 19:43:10 UTC",
      "updated_date": "2026-01-17 19:43:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:05.228199+00:00"
    },
    {
      "arxiv_id": "2601.12141v1",
      "title": "TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals",
      "title_zh": "TIDEï¼šä¸€ç§é¢å‘æ—¶åºæ‰©å±•ç›®æ ‡è§„åˆ’çš„è½¨è¿¹å¯å‘å¼æ·±åº¦ä¼˜å…ˆæ¢ç´¢æ–¹æ³•",
      "authors": [
        "Yuliia Suprun",
        "Khen Elimelech",
        "Lydia E. Kavraki",
        "Moshe Y. Vardi"
      ],
      "abstract": "Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½å’Œæœºå™¨äººé¢†åŸŸä¸­å…·æœ‰ Temporally Extended Goals (TEGs) çš„ä»»åŠ¡è§„åˆ’éš¾é¢˜ï¼Œæå‡ºäº† TIDE (Trace-Informed Depth-first Exploration) æ–¹æ³•ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†åŸºäº Linear Temporal Logic on finite traces (LTLf) çš„æ—¶åºè§„åˆ’æ—¶ï¼Œå¾€å¾€ç¼ºä¹æœ‰æ•ˆçš„å¯å‘å¼ä¿¡æ¯æ¥å¼•å¯¼æœç´¢ã€‚TIDE é€šè¿‡å°†å¤æ‚çš„æ—¶åºé—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯ç”± off-the-shelf planners è§£å†³çš„ reach-avoid å­é—®é¢˜ï¼Œå¹¶åˆ©ç”¨æˆæœ¬é©±åŠ¨çš„å¯å‘å¼ç®—æ³•åœ¨é¢†åŸŸå›¾ä¸­ä¼˜å…ˆæ¢ç´¢æœ‰å‰æ™¯çš„ automaton tracesã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†è‡ªé€‚åº”å›æº¯æœºåˆ¶ï¼Œé€šè¿‡é‡æ–°è®¡ç®—æˆæœ¬å’Œæƒ©ç½šä¸å¯è¡Œè½¬æ¢æ¥ç¡®ä¿è§„åˆ’çš„å®Œå¤‡æ€§ä¸æ•ˆç‡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTIDE åœ¨å¤„ç†æ—¶åºæ‰©å±•ç›®æ ‡æ–¹é¢å…·æœ‰ä¼˜å¼‚çš„æ€§èƒ½ï¼Œæ˜¯ç°æœ‰è§„åˆ’æ–¹æ³•ä½“ç³»çš„é‡è¦è¡¥å……ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12141v1",
      "published_date": "2026-01-17 19:07:03 UTC",
      "updated_date": "2026-01-17 19:07:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:07.996237+00:00"
    },
    {
      "arxiv_id": "2601.12138v1",
      "title": "DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants",
      "title_zh": "DriveSafeï¼šé¢å‘å®‰å…¨å…³é”®å‹å¤§è¯­è¨€æ¨¡å‹é©¾é©¶åŠ©æ‰‹çš„å±‚æ¬¡åŒ–é£é™©åˆ†ç±»ä½“ç³»",
      "authors": [
        "Abhishek Kumar",
        "Riya Tapwal",
        "Carsten Maple"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) é›†æˆåˆ°è½¦è½½åŠ©æ‰‹æ—¶é¢ä¸´çš„é¢†åŸŸç‰¹å®šé£é™©ï¼ŒæŒ‡å‡ºäº†ç°æœ‰é€šç”¨å®‰å…¨æ¡†æ¶åœ¨æ•æ‰é©¾é©¶åœºæ™¯å®‰å…¨ã€æ³•å¾‹åŠä¼¦ç†é£é™©æ–¹é¢çš„ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº† DriveSafeï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 129 ä¸ªç»†ç²’åº¦åŸå­é£é™©ç±»åˆ«çš„å››å±‚åˆ†çº§é£é™©åˆ†ç±»æ³• (Risk Taxonomy)ï¼Œæ¶µç›–äº†æŠ€æœ¯ã€æ³•å¾‹ã€ç¤¾ä¼šå’Œä¼¦ç†å››ä¸ªç»´åº¦ã€‚é€šè¿‡å¯¹å…­ç§ä¸»æµ LLMs çš„è¯„ä¼°ï¼Œè¯¥ç ”ç©¶å‘ç°ç°æœ‰æ¨¡å‹åœ¨å¤„ç†ä¸å®‰å…¨æˆ–è¿è§„çš„é©¾é©¶ç›¸å…³æŸ¥è¯¢æ—¶å¸¸è¡¨ç°å‡ºä¸å½“çš„æ‹’ç»è¡Œä¸ºã€‚è¿™å‡¸æ˜¾äº†é€šç”¨å®‰å…¨å¯¹é½ (Safety Alignment) åœ¨é©¾é©¶ç‰¹å®šåœºæ™¯ä¸‹çš„å±€é™æ€§ï¼Œä¸ºæ„å»ºæ›´å®‰å…¨ã€åˆè§„çš„é©¾é©¶åŠ©æ‰‹æä¾›äº†ç³»ç»Ÿæ€§å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12138v1",
      "published_date": "2026-01-17 18:50:47 UTC",
      "updated_date": "2026-01-17 18:50:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:11.095175+00:00"
    },
    {
      "arxiv_id": "2601.12134v1",
      "title": "Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning",
      "title_zh": "äºº-äºº-AI ä¸‰å…ƒåä½œç¼–ç¨‹ï¼šæ­ç¤ºåä½œå­¦ä¹ ä¸­ AI æ™ºèƒ½ä½“çš„è§’è‰²ä¸äººç±»ä¼™ä¼´çš„ä»·å€¼",
      "authors": [
        "Taufiq Daryanto",
        "Xiaohan Ding",
        "Kaike Ping",
        "Lance T. Wilhelm",
        "Yan Chen",
        "Chris Brown",
        "Eugenia H. Rho"
      ],
      "abstract": "As AI assistance becomes embedded in programming practice, researchers have increasingly examined how these systems help learners generate code and work more efficiently. However, these studies often position AI as a replacement for human collaboration and overlook the social and learning-oriented aspects that emerge in collaborative programming. Our work introduces human-human-AI (HHAI) triadic programming, where an AI agent serves as an additional collaborator rather than a substitute for a human partner. Through a within-subjects study with 20 participants, we show that triadic collaboration enhances collaborative learning and social presence compared to the dyadic human-AI (HAI) baseline. In the triadic HHAI conditions, participants relied significantly less on AI-generated code in their work. This effect was strongest in the HHAI-shared condition, where participants had an increased sense of responsibility to understand AI suggestions before applying them. These findings demonstrate how triadic settings activate socially shared regulation of learning by making AI use visible and accountable to a human peer, suggesting that AI systems that augment rather than automate peer collaboration can better preserve the learning processes that collaborative programming relies on.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†â€œäºº-äºº-AI (Human-Human-AI, HHAI)â€ä¸‰å…ƒç¼–ç¨‹æ¨¡å¼ï¼Œæ—¨åœ¨æ¢è®¨å½“AIä½œä¸ºé¢å¤–åä½œè€…è€Œéäººç±»ä¼™ä¼´çš„æ›¿ä»£å“æ—¶ï¼Œå¯¹åä½œå­¦ä¹ äº§ç”Ÿçš„å½±å“ã€‚é€šè¿‡20åå‚ä¸è€…çš„å—è¯•è€…å†…å®éªŒ(within-subjects study)ï¼Œç ”ç©¶å‘ç°HHAIæ¨¡å¼ç›¸æ¯”ä¼ ç»Ÿçš„â€œäºº-AI (Human-AI, HAI)â€äºŒå…ƒæ¨¡å¼èƒ½æ˜¾è‘—æå‡åä½œå­¦ä¹ æ•ˆæœå’Œç¤¾äº¤å­˜åœ¨æ„Ÿ(social presence)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä¸‰å…ƒæ¨¡å¼ä¸‹å‚ä¸è€…å¯¹AIç”Ÿæˆä»£ç çš„ä¾èµ–ç¨‹åº¦æ˜¾è‘—é™ä½ï¼Œä¸”åœ¨â€œHHAI-sharedâ€æ¡ä»¶ä¸‹ï¼Œå­¦ä¹ è€…åœ¨åº”ç”¨AIå»ºè®®å‰ä¼šäº§ç”Ÿæ›´å¼ºçš„ç†è§£è´£ä»»æ„Ÿã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œä¸‰å…ƒè®¾å®šé€šè¿‡ä½¿AIçš„ä½¿ç”¨å¯¹åŒä¼´å¯è§ä¸”è´Ÿè´£ï¼Œæ¿€æ´»äº†ç¤¾ä¼šå…±äº«è°ƒèŠ‚å­¦ä¹ (socially shared regulation of learning)ï¼Œå¼ºè°ƒäº†AIåº”ä»¥å¢å¼ºè€Œéè‡ªåŠ¨åŒ–åŒä¼´åä½œçš„æ–¹å¼æ¥ä¿ç•™å­¦ä¹ è¿‡ç¨‹çš„ä»·å€¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12134v1",
      "published_date": "2026-01-17 18:32:54 UTC",
      "updated_date": "2026-01-17 18:32:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:15.733830+00:00"
    },
    {
      "arxiv_id": "2601.12132v1",
      "title": "Bengali Text Classification: An Evaluation of Large Language Model Approaches",
      "title_zh": "å­ŸåŠ æ‹‰è¯­æ–‡æœ¬åˆ†ç±»ï¼šå¤§è¯­è¨€æ¨¡å‹æ–¹æ³•çš„è¯„ä¼°",
      "authors": [
        "Md Mahmudul Hoque",
        "Md Mehedi Hassain",
        "Md Hojaifa Tanvir",
        "Rahul Nandy"
      ],
      "abstract": "Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the \"Sports\" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº† Large Language Models (LLMs) åœ¨å­ŸåŠ æ‹‰è¯­æ–°é—»æ–‡ç« åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œæ—¨åœ¨è§£å†³è¯¥è¯­è¨€åœ¨ NLP é¢†åŸŸé¢ä¸´çš„æ ‡æ³¨æ•°æ®åŒ®ä¹å’Œé¢„è®­ç»ƒæ¨¡å‹ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚ç ”ç©¶åœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹å¯¹æ¯”äº† LLaMA 3.1 8B Instructã€LLaMA 3.2 3B Instruct å’Œ Qwen 2.5 7B Instruct ä¸‰ç§æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQwen 2.5 å–å¾—äº† 72% çš„æœ€é«˜åˆ†ç±»å‡†ç¡®ç‡ï¼Œåœ¨ \"Sports\" ç±»åˆ«ä¸­è¡¨ç°å°¤ä¸ºå¼ºåŠ²ï¼Œæ˜¾è‘—ä¼˜äº LLaMA ç³»åˆ—æ¨¡å‹ã€‚è¯¥ç ”ç©¶è¯å®äº† LLMs åœ¨å¤„ç†èµ„æºç¨€ç¼ºè¯­è¨€æ–‡æœ¬åˆ†ç±»æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶æŒ‡å‡ºæœªæ¥å°†ä¾§é‡äºä¼˜åŒ– Fine-tuning ç­–ç•¥ä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12132v1",
      "published_date": "2026-01-17 18:25:19 UTC",
      "updated_date": "2026-01-17 18:25:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:18.953400+00:00"
    },
    {
      "arxiv_id": "2601.12126v1",
      "title": "UniMo: Unified Motion Generation and Understanding with Chain of Thought",
      "title_zh": "UniMoï¼šåŸºäºé“¾å¼æ€ç»´çš„ç»Ÿä¸€åŠ¨ä½œç”Ÿæˆä¸ç†è§£",
      "authors": [
        "Guocun Wang",
        "Kenkun Liu",
        "Jing Lin",
        "Guorui Song",
        "Jian Li",
        "Xiaoguang Han"
      ],
      "abstract": "Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UniMo æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ 3D äººä½“è¿åŠ¨ç”Ÿæˆä¸ç†è§£ä»»åŠ¡åœ¨å¯è§£é‡Šæ€§ã€è¯­ä¹‰å¯¹é½ä»¥åŠå¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨è¿åŠ¨åºåˆ—é¢„æµ‹ä¸­å­˜åœ¨çš„ç´¯ç§¯è¯¯å·®é—®é¢˜ã€‚é€šè¿‡ç›‘ç£å¾®è°ƒ (SFT)ï¼ŒUniMo å°†è¿åŠ¨è¯­è¨€ä¿¡æ¯ä¸å¯è§£é‡Šçš„é“¾å¼æ€ç»´ (Chain of Thought, CoT) æ¨ç†é›†æˆåˆ°æ¨¡å‹ä¸­ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ– (Group Relative Policy Optimization, GRPO) çš„å¼ºåŒ–å­¦ä¹ åæœŸè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä¼˜åŒ–ä»¤ç‰Œç»„æ¥ç¡®ä¿ç»“æ„æ­£ç¡®æ€§å’Œè¯­ä¹‰å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUniMo åœ¨è¿åŠ¨ç”Ÿæˆå’Œç†è§£ä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰çš„ç»Ÿä¸€æ¨¡å‹å’Œç‰¹å®šä»»åŠ¡æ¨¡å‹ï¼Œè¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›çš„æ€§èƒ½ (SOTA)ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12126v1",
      "published_date": "2026-01-17 17:56:49 UTC",
      "updated_date": "2026-01-17 17:56:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:20.421044+00:00"
    },
    {
      "arxiv_id": "2601.12124v1",
      "title": "SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data",
      "title_zh": "SynQPï¼šåˆæˆæ•°æ®è´¨é‡ä¸éšç§é£é™©è¯„ä¼°æ¡†æ¶åŠæŒ‡æ ‡",
      "authors": [
        "Bing Hu",
        "Yixin Li",
        "Asma Bahamyirou",
        "Helen Chen"
      ],
      "abstract": "The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \\(\\ge0.97\\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SynQPï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°åˆæˆæ•°æ® (Synthetic Data) è´¨é‡ä¸éšç§é£é™©çš„å¼€æºæ¡†æ¶ã€‚ä¸ºäº†è§£å†³åŒ»ç–—ç­‰é¢†åŸŸå› æ•æ„Ÿæ•°æ®è·å–éš¾è€Œå¯¼è‡´çš„éšç§è¯„ä¼°åŸºå‡†ç¼ºå¤±é—®é¢˜ï¼ŒSynQP é‡‡ç”¨æ¨¡æ‹Ÿæ•æ„Ÿæ•°æ®è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿äº†åŸå§‹æ•°æ®çš„æœºå¯†æ€§ã€‚ç ”ç©¶è€…è¿˜æå‡ºäº†ä¸€ç§æ–°å‹èº«ä»½æ³„éœ²é£é™© (Identity Disclosure Risk) æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæ¯”ç°æœ‰æ–¹æ³•æ›´ç²¾ç¡®åœ°è¡¡é‡æœºå™¨å­¦ä¹ æ¨¡å‹çš„éšç§é£é™©ã€‚å®éªŒé€šè¿‡å¯¹ CTGAN çš„åŸºå‡†æµ‹è¯•è¯æ˜ï¼Œç»“åˆå·®åˆ†éšç§ (Differential Privacy, DP) çš„æ¨¡å‹å¯å°†èº«ä»½æ³„éœ²å’Œæˆå‘˜æ¨ç†æ”»å‡» (Membership-Inference Attack, MIA) é£é™©é™è‡³ç›‘ç®¡é˜ˆå€¼ä»¥ä¸‹ã€‚è¯¥æ¡†æ¶ä¸ºæå‡éšç§è¯„ä¼°çš„é€æ˜åº¦å’Œå¯é æ€§æä¾›äº†å…³é”®å·¥å…·ï¼Œæ¨åŠ¨äº†åˆæˆæ•°æ®åœ¨åŒ»ç–—å¥åº·é¢†åŸŸçš„å®‰å…¨åº”ç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 Pages, 22nd Annual International Conference on Privacy, Security, and Trust (PST2025), Fredericton, Canada",
      "pdf_url": "https://arxiv.org/pdf/2601.12124v1",
      "published_date": "2026-01-17 17:51:14 UTC",
      "updated_date": "2026-01-17 17:51:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:24.625750+00:00"
    },
    {
      "arxiv_id": "2601.12104v1",
      "title": "Powerful Training-Free Membership Inference Against Autoregressive Language Models",
      "title_zh": "é’ˆå¯¹è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆå…è®­ç»ƒæˆå‘˜æ¨ç†",
      "authors": [
        "David IliÄ‡",
        "David StanojeviÄ‡",
        "Kostadin Cvejoski"
      ],
      "abstract": "Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º EZ-MIA çš„æ— éœ€è®­ç»ƒçš„æˆå‘˜æ¨ç†æ”»å‡»(Membership Inference Attack, MIA)æ¡†æ¶ï¼Œæ—¨åœ¨æ›´æœ‰æ•ˆåœ°è¯„ä¼°å¾®è°ƒè¯­è¨€æ¨¡å‹æ³„éœ²æ•æ„Ÿä¿¡æ¯çš„éšç§é£é™©ã€‚è¯¥æ–¹æ³•åŸºäºä¸€ä¸ªæ ¸å¿ƒè§‚å¯Ÿï¼šæ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†åœ¨â€œé”™è¯¯ä½ç½®â€ï¼ˆå³é¢„æµ‹é”™è¯¯ä½†æ¦‚ç‡å€¼ä»å¼‚å¸¸åé«˜çš„è¯å…ƒï¼‰è¡¨ç°æœ€å¼ºã€‚ç ”ç©¶äººå‘˜ä¸ºæ­¤å¼•å…¥äº† Error Zone (EZ) scoreï¼Œé€šè¿‡è¡¡é‡è¿™äº›ä½ç½®ç›¸å¯¹äºé¢„è®­ç»ƒå‚è€ƒæ¨¡å‹çš„æ¦‚ç‡åç§»æ–¹å‘ä¸å¹³è¡¡æ¥è¯†åˆ«æˆå‘˜èº«ä»½ï¼Œä¸”ä»…éœ€ä¸¤æ¬¡å‰å‘ä¼ æ’­ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ 1% çš„ä½è¯¯æŠ¥ç‡ä¸‹ï¼ŒEZ-MIA åœ¨ GPT-2 å’Œ Llama-2-7B ç­‰æ¨¡å‹ä¸Šçš„æ£€æµ‹ç‡æ¯”ç°æœ‰æœ€ä¼˜æ–¹æ³•æé«˜äº† 3 å€ä»¥ä¸Šï¼Œç”šè‡³åœ¨æ›´ä¸¥è‹›çš„ 0.1% è¯¯æŠ¥ç‡ä¸‹è¡¨ç°ä¾ç„¶å¼ºåŠ²ã€‚è¿™ä¸€ç ”ç©¶æ­ç¤ºäº†å¾®è°ƒè¯­è¨€æ¨¡å‹çš„éšç§é£é™©è¿œè¶…æ­¤å‰è®¤çŸ¥ï¼Œä¸ºå¯ä¿¡éƒ¨ç½²å’Œéšç§å®¡è®¡æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures; appendix with additional experiments and derivations",
      "pdf_url": "https://arxiv.org/pdf/2601.12104v1",
      "published_date": "2026-01-17 16:59:41 UTC",
      "updated_date": "2026-01-17 16:59:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:29.577771+00:00"
    },
    {
      "arxiv_id": "2601.12099v1",
      "title": "Large language models struggle with ethnographic text annotation",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹åœ¨æ°‘æ—å¿—æ–‡æœ¬æ ‡æ³¨ä¸­é¢ä¸´æŒ‘æˆ˜",
      "authors": [
        "Leonardo S. Goodall",
        "Dor Shilton",
        "Daniel A. Mullins",
        "Harvey Whitehouse"
      ],
      "abstract": "Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº† 7 ç§å…ˆè¿›çš„ Large Language Models (LLMs) åœ¨æ°‘æ—å¿—æ–‡æœ¬æ ‡æ³¨ (ethnographic text annotation) æ–¹é¢çš„è¡¨ç°ï¼Œæµ‹è¯•æ¶µç›–äº† 567 ç¯‡æ°‘æ—å¿—ç‰‡æ®µä¸­çš„ 121 ç§ä»ªå¼ç‰¹å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMs çš„æ ‡æ³¨å‡†ç¡®ç‡è¿œä½äºå¯é è‡ªåŠ¨æ ‡æ³¨çš„è¦æ±‚ï¼Œå°¤å…¶åœ¨å¤„ç†é•¿æ–‡æœ¬ã€å®šåºåŒºåˆ† (ordinal distinctions) ä»¥åŠæ¨¡ç³Šæ¦‚å¿µæ—¶é¢ä¸´æ˜¾è‘—å›°éš¾ã€‚ç ”ç©¶å‘ç°äººç±»ç¼–ç å‘˜çš„ä¿¡åº¦ (human inter-coder reliability) æ„æˆäº†æ¨¡å‹è¡¨ç°çš„ä¸Šé™ï¼Œå³äººç±»éš¾ä»¥è¾¾æˆå…±è¯†çš„ä»»åŠ¡å¯¹æ¨¡å‹è€Œè¨€ä¹ŸåŒæ ·å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å³ä¾¿åœ¨äººç±»èƒ½å¤Ÿè¾¾æˆä¸€è‡´çš„ç‰¹å¾ä¸Šï¼Œæ¨¡å‹çš„è¡¨ç°ä»ä¸åŠäººç±»ä¸“å®¶ï¼Œè¡¨æ˜ LLMs ç›®å‰å°šä¸èƒ½å–ä»£äººç±»åœ¨æ°‘æ—å¿—æ ‡æ³¨é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12099v1",
      "published_date": "2026-01-17 16:39:07 UTC",
      "updated_date": "2026-01-17 16:39:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:42.599706+00:00"
    },
    {
      "arxiv_id": "2601.12095v1",
      "title": "Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding",
      "title_zh": "ç¥ç»åŒæ„åŸŸï¼šä¸€ç§åŸºäº Transformer çš„ä»£æ•°æ•°å€¼åµŒå…¥",
      "authors": [
        "Hamidreza Sadeghi",
        "Saeedeh Momtazi",
        "Reza Safabakhsh"
      ],
      "abstract": "Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.",
      "tldr_zh": "### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ§¬\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº† Neural Isomorphic Fields (NIF)ï¼Œè¿™æ˜¯ä¸€ç§åŸºäº Transformer çš„ä»£æ•°æ•°å€¼åµŒå…¥ (Algebraic Numerical Embedding) æ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³ç¥ç»ç½‘ç»œåœ¨å¤„ç†æç«¯æ•°å€¼æ—¶é¢ä¸´çš„æº¢å‡ºã€ä¸‹æº¢åŠä¸ç¨³å®šæ€§é—®é¢˜ã€‚é€šè¿‡åœ¨ç¥ç»å±‚é¢æŠ½è±¡å‡ºç¾¤ (Groups) å’ŒåŸŸ (Fields) ç­‰ä»£æ•°ç»“æ„ï¼Œè¯¥æ¨¡å‹é¦–æ¬¡å®ç°äº†åœ¨å›ºå®šé•¿åº¦çš„å‘é‡ç©ºé—´å†…ä¿ç•™æœ‰ç†æ•°çš„åŠ æ³•ã€ä¹˜æ³•åŠæ¯”è¾ƒç­‰ä»£æ•°è¿ç®—æ€§è´¨ã€‚å®éªŒè¯æ˜ï¼ŒNIF åœ¨åŠ æ³•çš„å°é—­æ€§å’Œç»“åˆå¾‹ç­‰æ ¸å¿ƒæµ‹è¯•ä¸­è¾¾åˆ°äº† 95% ä»¥ä¸Šçš„å‡†ç¡®ç‡ï¼Œä½†åœ¨ä¹˜æ³•è¿ç®—ä¸Šä»é¢ä¸´æŒ‘æˆ˜ï¼ˆå‡†ç¡®ç‡ä¸º 53%-73%ï¼‰ã€‚è¯¥æˆæœé€šè¿‡åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ç»´æŒä»£æ•°ç»“æ„ï¼Œä¸ºæ„å»ºå…·å¤‡ä»£æ•°ä¸€è‡´æ€§çš„ç¥ç»æ•°å€¼å¤„ç†æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚\n\n---\n\nå¸Œæœ›è¿™ä¸ªæ‘˜è¦èƒ½å¤Ÿç²¾å‡†åœ°æ¦‚æ‹¬è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹ï¼å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦è½¬æ¢ï¼Œæˆ–è€…æƒ³é’ˆå¯¹ NIF æ¡†æ¶çš„å®éªŒç»“æœè¿›è¡Œæ›´æ·±å…¥çš„æ¢è®¨ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12095v1",
      "published_date": "2026-01-17 16:25:52 UTC",
      "updated_date": "2026-01-17 16:25:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:56.189033+00:00"
    },
    {
      "arxiv_id": "2601.12082v1",
      "title": "Conditional Random Fields for Interactive Refinement of Histopathological Predictions",
      "title_zh": "ç”¨äºç»„ç»‡ç—…ç†å­¦é¢„æµ‹äº¤äº’å¼ç²¾ç»†åŒ–çš„æ¡ä»¶éšæœºåœº",
      "authors": [
        "Tiffanie Godelaine",
        "Maxime Zanella",
        "Karim El Khoury",
        "SaÃ¯d Mahmoudi",
        "BenoÃ®t Macq",
        "Christophe De Vleeschouwer"
      ],
      "abstract": "Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HistoCRFæ¡†æ¶ï¼Œåˆ©ç”¨Conditional Random Fields (CRFs) ä¼˜åŒ–Vision-Language Models (VLMs) åœ¨ç»„ç»‡ç—…ç†å­¦é¢„æµ‹ä¸­çš„zero-shotè¡¨ç°ï¼Œä¸”æ— éœ€é¢å¤–æ¨¡å‹è®­ç»ƒã€‚è¯¥æ¡†æ¶é€šè¿‡å®šä¹‰æ–°é¢–çš„pairwise potentialæ¥æå‡æ ‡ç­¾å¤šæ ·æ€§ï¼Œå¹¶æ”¯æŒåˆ©ç”¨ä¸“å®¶æ ‡æ³¨è¿›è¡Œäº¤äº’å¼ç»†åŒ–ã€‚åœ¨äº”ä¸ªç»„ç»‡ç—…ç†å­¦æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHistoCRFåœ¨æ— æ ‡æ³¨æƒ…å†µä¸‹å¯å°†å¹³å‡å‡†ç¡®ç‡æé«˜16.0%ï¼Œåœ¨ä»…100ä¸ªä¸“å®¶æ ‡æ³¨ä¸‹å¯æå‡27.5%ã€‚æ­¤å¤–ï¼Œç»“åˆhuman-in-the-loopè¿­ä»£ä¿®æ­£æœºåˆ¶åï¼ŒåŒç­‰æ ‡æ³¨é‡ä¸‹çš„å‡†ç¡®ç‡å¢ç›Šè¿›ä¸€æ­¥è¾¾åˆ°32.6%ï¼Œä¸ºé«˜ç²¾åº¦çš„äº¤äº’å¼ç—…ç†è¯Šæ–­è¾…åŠ©æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12082v1",
      "published_date": "2026-01-17 15:19:40 UTC",
      "updated_date": "2026-01-17 15:19:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:46.403544+00:00"
    },
    {
      "arxiv_id": "2601.12068v1",
      "title": "Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset",
      "title_zh": "å¼¥åˆå­ŸåŠ æ‹‰è¯­åŒ»ç–—é¸¿æ²Ÿï¼šåŸºäºç—‡çŠ¶-ç–¾ç—…æ•°æ®é›†çš„æœºå™¨å­¦ä¹ ç–¾ç—…é¢„æµ‹",
      "authors": [
        "Rowzatul Zannat",
        "Abdullah Al Shafi",
        "Abdul Muntakim"
      ],
      "abstract": "Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å­ŸåŠ æ‹‰è¯­ (Bangla) åŒ»ç–—èµ„æºæœ‰é™çš„é—®é¢˜ï¼Œå¼€å‘å¹¶å…¬å¼€äº†ä¸€ä¸ªåŒ…å« 85 ç§ç–¾ç—…å’Œ 758 ä¸ªç—‡çŠ¶-ç–¾ç—…å…³ç³»çš„å­ŸåŠ æ‹‰è¯­æ•°æ®é›†ã€‚ç ”ç©¶æ—¨åœ¨åˆ©ç”¨è¯¥æ•°æ®é›†é€šè¿‡å­ŸåŠ æ‹‰è¯­ç—‡çŠ¶è¾“å…¥å®ç°ç–¾ç—…é¢„æµ‹ (Disease Prediction)ï¼Œä»¥æå‡è¯¥è¯­ç§äººç¾¤çš„åŒ»ç–—å¯åŠæ€§ã€‚å®éªŒè¯„ä¼°äº†å¤šç§æœºå™¨å­¦ä¹  (Machine Learning) æ¨¡å‹ï¼Œå…¶ä¸­ç»“åˆäº†æœ€ä¼˜æ¨¡å‹çš„è½¯æŠ•ç¥¨ (Soft Voting) å’Œç¡¬æŠ•ç¥¨ (Hard Voting) é›†æˆå­¦ä¹  (Ensemble Learning) æ–¹æ³•è¾¾åˆ°äº† 98% çš„å‡†ç¡®ç‡ã€‚è¯¥æˆæœä¸ºæœ¬åœ°åŒ–å¥åº·ä¿¡æ¯å­¦å’Œæ—©æœŸç–¾ç—…æ£€æµ‹å¥ å®šäº†åŸºç¡€ï¼Œæœ‰åŠ©äºå¢å¼ºå­ŸåŠ æ‹‰è¯­ç¤¾åŒºçš„åŒ»ç–—å¹²é¢„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12068v1",
      "published_date": "2026-01-17 14:33:01 UTC",
      "updated_date": "2026-01-17 14:33:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:50.762318+00:00"
    },
    {
      "arxiv_id": "2601.12061v1",
      "title": "Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation",
      "title_zh": "é¢å‘å¤šè¯è¯­ç»“æ„æ ‡æ³¨çš„ä»£ç ç°¿æ³¨å…¥å¼å¯¹è¯åˆ†å‰²ï¼šå¤§è¯­è¨€æ¨¡å‹è¾…åŠ©ä¸æ— é‡‘æ ‡è¯„ä¼°",
      "authors": [
        "Jinsook Lee",
        "Kirk Vanacore",
        "Zhuqian Zhou",
        "Jeanine Grutter",
        "Rene F. Kizilcec"
      ],
      "abstract": "Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Codebook-Injected Dialogue Segmentation æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ Dialogue Act (DA) æ ‡æ³¨ä¸­å› è·¨è¯è¯­ç»“æ„å¯¼è‡´çš„ç‰‡æ®µè¾¹ç•Œä¸ä¸€è‡´é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å°† downstream annotation criteria æ³¨å…¥åˆ†å‰²è¿‡ç¨‹ï¼Œå¹¶å¼•å…¥äº†é’ˆå¯¹ span consistency å’Œ distinctiveness çš„æ— é‡‘æ ‡å‡† (Gold-Label-Free) è¯„ä¼°ä½“ç³»ã€‚å®éªŒå¯¹æ¯”äº† LLM è¾…åŠ©åˆ†å‰²å™¨ä¸ retrieval-augmented åŸºçº¿æ¨¡å‹ï¼Œå‘ç° DA-awareness èƒ½æ˜¾è‘—æå‡ç‰‡æ®µå†…éƒ¨çš„ä¸€è‡´æ€§ï¼Œä½†åœ¨è¾¹ç•ŒåŒºåˆ†åº¦ä¸äººç±»åˆ†å¸ƒä¸€è‡´æ€§ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒï¼Œå¯¹è¯åˆ†å‰²åº”ä½œä¸ºä¸€ç§å…³é”®çš„è®¾è®¡é€‰æ‹©ï¼Œæ ¹æ®å…·ä½“çš„ä¸‹æ¸¸ä»»åŠ¡ç›®æ ‡è¿›è¡Œä¼˜åŒ–ï¼Œè€Œéè¿½æ±‚å•ä¸€çš„æ€§èƒ½è¯„åˆ†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review for ACL 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12061v1",
      "published_date": "2026-01-17 14:17:13 UTC",
      "updated_date": "2026-01-17 14:17:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:56.513372+00:00"
    },
    {
      "arxiv_id": "2601.12055v1",
      "title": "Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer",
      "title_zh": "é€šè¿‡ç›¸ä¼¼æ€§å‚æ•°è¿ç§»å®ç°è§å…‰æ˜¾å¾®å›¾åƒå»å™ªä¸­çš„æ·±åº¦å›¾åƒå…ˆéªŒå‚æ•°è‡ªåŠ¨é€‰æ‹©",
      "authors": [
        "Lina Meyer",
        "Felix Wissel",
        "Tobias Knopp",
        "Susanne Pfefferle",
        "Ralf Fliegert",
        "Maximilian Sandmann",
        "Liana Uebler",
        "Franziska MÃ¶ckl",
        "BjÃ¶rn-Philipp Diercks",
        "David Lohr",
        "RenÃ© Werner"
      ],
      "abstract": "Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AUTO-DIPï¼Œä¸€ç§é’ˆå¯¹è§å…‰æ˜¾å¾®å›¾åƒå»å™ªçš„è‡ªåŠ¨å‚æ•°è½¬ç§»æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ·±åº¦å›¾åƒå…ˆéªŒ (Deep Image Prior, DIP) åœ¨ç½‘ç»œæ¶æ„é€‰æ‹©å’Œè¿­ä»£åœæ­¢ç‚¹ä¼˜åŒ–ä¸Šè¿‡äºè€—æ—¶çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•åŸºäºç›¸ä¼¼å›¾åƒå…·æœ‰ç›¸ä¼¼æœ€ä¼˜å‚æ•°é…ç½®çš„å‡è®¾ï¼Œé€šè¿‡æ„å»ºæ ¡å‡†é›†å¹¶åˆ©ç”¨å›¾åƒå…ƒæ•°æ® (Metadata) ç›¸ä¼¼æ€§ï¼ˆå¦‚æ˜¾å¾®é•œç±»å‹ã€æ ·æœ¬ç§ç±»ï¼‰å®ç°å‚æ•°çš„è‡ªåŠ¨é€‰æ‹©ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAUTO-DIP åœ¨å¤šä¸ªå¼€æºåŠæœ¬åœ°è§å…‰æ˜¾å¾®æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºåŸå§‹ DIP åŸºçº¿æ¨¡å‹å’Œå˜åˆ†å»å™ª (Variational Denoising) æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤„ç†æé«˜å™ªå£°çš„å›¾åƒæ—¶ï¼Œè¯¥æ¡†æ¶å±•ç°äº†æ˜¾è‘—çš„å»å™ªæ€§èƒ½æå‡ä¸åº”ç”¨æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12055v1",
      "published_date": "2026-01-17 13:47:41 UTC",
      "updated_date": "2026-01-17 13:47:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:02.072574+00:00"
    },
    {
      "arxiv_id": "2601.12053v1",
      "title": "A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data",
      "title_zh": "äººå·¥æ™ºèƒ½æ–°æˆ˜ç•¥ï¼šç›´æ¥åŸºäºäººè„‘æ•°æ®è®­ç»ƒåŸºåº§æ¨¡å‹",
      "authors": [
        "MaÃ«l Donoso"
      ],
      "abstract": "While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. However, this data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. In this paper, we explore a new strategy for artificial intelligence: moving beyond surface-level statistical regularities by training foundation models directly on human brain data. We hypothesize that neuroimaging data could open a window into elements of human cognition that are not accessible through observable actions, and argue that this additional knowledge could be used, alongside classical training data, to overcome some of the current limitations of foundation models. While previous research has demonstrated the possibility to train classical machine learning or deep learning models on neural patterns, this path remains largely unexplored for high-level cognitive functions. Here, we classify the current limitations of foundation models, as well as the promising brain regions and cognitive processes that could be leveraged to address them, along four levels: perception, valuation, execution, and integration. Then, we propose two methods that could be implemented to prioritize the use of limited neuroimaging data for strategically chosen, high-value steps in foundation model training: reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB). We also discuss the potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities. We argue that brain-trained foundation models could represent a realistic and effective middle ground between continuing to scale current architectures and exploring alternative, neuroscience-inspired solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…¨æ–°çš„äººå·¥æ™ºèƒ½ç­–ç•¥ï¼Œå³ç›´æ¥åœ¨äººç±»å¤§è„‘æ•°æ®ï¼ˆhuman brain dataï¼‰ä¸Šè®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆfoundation modelsï¼‰ï¼Œæ—¨åœ¨è¶…è¶Šä¼ ç»Ÿçš„è¡¨é¢ç»Ÿè®¡è§„å¾‹ï¼Œè·å–æ— æ³•é€šè¿‡è§‚å¯Ÿè¡Œä¸ºç›´æ¥è·å–çš„æ·±å±‚äººç±»è®¤çŸ¥ä¿¡æ¯ã€‚è®ºæ–‡é€šè¿‡æ„ŸçŸ¥ï¼ˆperceptionï¼‰ã€è¯„ä¼°ï¼ˆvaluationï¼‰ã€æ‰§è¡Œï¼ˆexecutionï¼‰å’Œæ•´åˆï¼ˆintegrationï¼‰å››ä¸ªç»´åº¦åˆ†æäº†åŸºç¡€æ¨¡å‹çš„å±€é™æ€§ï¼Œå¹¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨ç›¸å…³å¤§è„‘åŒºåŸŸæ•°æ®åŠ ä»¥è§£å†³ã€‚ä½œè€…æå‡ºäº†ä¸¤ç§å…·ä½“è®­ç»ƒæ–¹æ³•ï¼šåŸºäºäººç±»å¤§è„‘çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning from Human Brain, RLHBï¼‰å’ŒåŸºäºäººç±»å¤§è„‘çš„é“¾å¼æ€ç»´ï¼ˆChain of Thought from Human Brain, CoTHBï¼‰ï¼Œä»¥ä¼˜åŒ–åŸºç¡€æ¨¡å‹çš„è®­ç»ƒæµç¨‹ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰æä¾›äº†æ–°è·¯å¾„ï¼Œè¢«è®¤ä¸ºæ˜¯ç°æœ‰æ¨¡å‹è§„æ¨¡åŒ–è·¯çº¿ä¸ç¥ç»ç§‘å­¦å¯å‘å¼æ–¹æ¡ˆä¹‹é—´çš„ä¸€ç§åˆ‡å®æœ‰æ•ˆçš„ä¸­é—´æ–¹æ¡ˆã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12053v1",
      "published_date": "2026-01-17 13:38:51 UTC",
      "updated_date": "2026-01-17 13:38:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:24:59.621149+00:00"
    },
    {
      "arxiv_id": "2601.12049v1",
      "title": "\\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions",
      "title_zh": "FocaLogicï¼šåŸºäºé€»è¾‘çš„è§†è§‰æ¨¡å‹å†³ç­–è§£é‡Š",
      "authors": [
        "Chenchen Zhao",
        "Muxi Chen",
        "Qiang Xu"
      ],
      "abstract": "Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† FocaLogicï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ¨¡å‹æ— å…³ï¼ˆmodel-agnosticï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åŸºäºé€»è¾‘çš„è¡¨ç¤ºæ¥è§£é‡Šå’Œé‡åŒ–è§†è§‰æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶é€šè¿‡è¯†åˆ«å†³å®šæ¨¡å‹é¢„æµ‹çš„å…³é”®è§†è§‰åŒºåŸŸå­é›†ï¼ˆç§°ä¸º visual focusesï¼‰ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç²¾ç¡®ä¸”ç®€æ´çš„é€»è¾‘è¡¨è¾¾å¼ï¼Œå®ç°äº†é€æ˜ä¸”ç»“æ„åŒ–çš„è§£é‡Šã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†ä¸€å¥—å®šé‡æŒ‡æ ‡ï¼ˆåŒ…æ‹¬ focus precisionã€recall å’Œ divergenceï¼‰ï¼Œç”¨äºå®¢è§‚è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡Œä¸ºã€‚å®éªŒåˆ†æè¯æ˜ï¼ŒFocaLogic èƒ½å¤Ÿæœ‰æ•ˆæ­ç¤ºæ¨¡å‹åœ¨è®­ç»ƒä¸­çš„æ³¨æ„åŠ›é›†ä¸­è¶‹åŠ¿ã€æ³›åŒ–è¿‡ç¨‹ä¸­çš„å‡†ç¡®åº¦æå‡ï¼Œä»¥åŠåœ¨åè§å’Œå¯¹æŠ—æ”»å‡»ä¸‹çš„å¼‚å¸¸è¡¨ç°ï¼Œä¸ºè§†è§‰æ¨¡å‹è§£é‡Šæä¾›äº†ä¸€ç§ç³»ç»ŸåŒ–ä¸”å¯æ‰©å±•çš„å®šé‡è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12049v1",
      "published_date": "2026-01-17 13:28:02 UTC",
      "updated_date": "2026-01-17 13:28:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:01.065778+00:00"
    },
    {
      "arxiv_id": "2601.12042v1",
      "title": "Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models",
      "title_zh": "å°‘å³æ˜¯å¤šï¼Œç›´è‡³å´©æºƒï¼šå¤§è§†è§‰è¯­è¨€æ¨¡å‹ä¸­è§†è§‰ Token å‹ç¼©çš„å®‰å…¨é™·é˜±",
      "authors": [
        "Xiaomei Zhang",
        "Zhaoxi Zhang",
        "Leo Yu Zhang",
        "Yanjun Zhang",
        "Guanhong Tao",
        "Shirui Pan"
      ],
      "abstract": "Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†è§†è§‰å¤§è¯­è¨€æ¨¡å‹ (LVLMs) ä¸­è§†è§‰ç‰¹å¾å‹ç¼© (Visual token compression) å¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œå‘ç°è™½ç„¶å‹ç¼©æå‡äº†æ¨ç†æ•ˆç‡ï¼Œä½†ä¼šæ˜¾è‘—é™ä½æ¨¡å‹çš„é²æ£’æ€§ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œé²æ£’æ€§ä¸‹é™çš„æ ¸å¿ƒåŸå› åœ¨äºç‰¹å¾é‡è¦æ€§æ’åºçš„ä¸ç¨³å®šæ€§ï¼Œå¾®å°çš„æ‰°åŠ¨å³å¯å¯¼è‡´å‹ç¼©æœºåˆ¶é”™è¯¯åœ°ä¸¢å¼ƒå…³é”®ä¿¡æ¯ï¼Œä¸”è¿™ç±»æ¼æ´ä»…åœ¨å¼€å¯å‹ç¼©æ—¶æ˜¾ç°ï¼Œå…·æœ‰æå¼ºçš„éšè”½æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é’ˆå¯¹å‹ç¼©æœºåˆ¶çš„æ”»å‡»æ–¹æ³• Compression-Aware Attack (CAA) åŠå…¶é»‘ç›’å˜ä½“ Transfer CAAï¼Œç”¨äºç³»ç»Ÿæ€§åœ°è¯±å¯¼æ¨¡å‹åœ¨å‹ç¼©æ¨ç†æ—¶äº§ç”Ÿæ•…éšœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„é˜²å¾¡æªæ–½ä¿æŠ¤æ•ˆæœæœ‰é™ï¼Œè¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨è¿½æ±‚æ¨¡å‹æ•ˆç‡ä¸ä¿éšœå®‰å…¨ä¹‹é—´å­˜åœ¨æ­¤å‰è¢«å¿½è§†çš„æƒè¡¡ (Trade-off) å…³ç³»ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12042v1",
      "published_date": "2026-01-17 13:02:41 UTC",
      "updated_date": "2026-01-17 13:02:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:07.651162+00:00"
    },
    {
      "arxiv_id": "2601.12040v1",
      "title": "Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty",
      "title_zh": "è¯­è¨€æ¨¡å‹ä¸­çš„å±€éƒ¨æ¨ç†ï¼šåŸºäºä¸ç¡®å®šæ€§å¼•å¯¼çš„æœç´¢ä¸ä¼˜åŒ–",
      "authors": [
        "Murilo da Luz",
        "Bruno BrandÃ£o",
        "Luana Martins",
        "Gustavo Oliveira",
        "Bryan de Oliveira",
        "Luckeciano Melo",
        "Telma Soares"
      ],
      "abstract": "The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PREGU (Partial Reasoning Guided by Uncertainty)ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤šæ­¥æ¨ç†åŠæ•°å­¦é€»è¾‘ä»»åŠ¡ä¸­çš„å±€é™æ€§ã€‚PREGU é€šè¿‡å®æ—¶ç›‘æµ‹è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è¾“å‡ºåˆ†å¸ƒç†µ (entropy) æ¥è¯†åˆ«ä¸ç¡®å®šæ€§ï¼Œå¹¶åœ¨ç†µå€¼è¶…è¿‡é˜ˆå€¼æ—¶ä¸»åŠ¨ä¸­æ–­ç”Ÿæˆã€‚éšåï¼Œè¯¥æ–¹æ³•åœ¨æ½œåœ¨ç©ºé—´ (latent space) ä¸­æ‰§è¡Œå±€éƒ¨æœç´¢ï¼Œå¹¶ç»“åˆ Soft Reasoning æŠ€æœ¯å¯¹éƒ¨åˆ†æ¨ç†è·¯å¾„è¿›è¡Œç²¾ç»†åŒ–è°ƒæ•´ä¸ä¼˜åŒ–ã€‚åœ¨ GSM8Kã€StrategyQA ç­‰å››ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPREGU çš„è¡¨ç°ä¼˜äºæˆ–æŒå¹³äº Soft Reasoning æ–¹æ³•ï¼Œæœ‰åŠ›è¯æ˜äº†ç†µæ˜¯è§¦å‘é€‰æ‹©æ€§æ¨ç†ä¼˜åŒ–çš„æœ‰æ•ˆä¿¡å·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12040v1",
      "published_date": "2026-01-17 13:00:17 UTC",
      "updated_date": "2026-01-17 13:00:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:14.973073+00:00"
    },
    {
      "arxiv_id": "2601.12038v1",
      "title": "Abstract Argumentation with Subargument Relations",
      "title_zh": "å…·æœ‰å­è®ºè¾©å…³ç³»çš„æŠ½è±¡è®ºè¾©",
      "authors": [
        "Beishui Liao"
      ],
      "abstract": "Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ Dung çš„æŠ½è±¡è®ºè¯æ¡†æ¶ (Abstract Argumentation Framework) ä¸­å¼•å…¥æ˜¾å¼å­è®ºç‚¹å…³ç³» (Subargument Relations) çš„å¿…è¦æ€§ï¼Œä»¥å¼¥è¡¥ä¼ ç»Ÿæ¡†æ¶ä»…ä¾èµ–æ”»å‡»å…³ç³» (Attack Relation) è€Œå¿½ç•¥å†…éƒ¨ç»“æ„ä¾èµ–çš„å±€é™ã€‚è®ºæ–‡å°†å­è®ºç‚¹å…³ç³»è§†ä¸ºä¸æ”»å‡»å…³ç³»å¹¶åˆ—çš„åŸºæœ¬å…³ç³»ï¼Œæ·±å…¥åˆ†æäº†ä¸¤è€…çš„äº¤äº’ä½œç”¨åŠå…¶å¯¹åŸºæœ¬è¯­ä¹‰å±æ€§ (Semantic Properties) çš„å½±å“ã€‚è¯¥æ¡†æ¶ä¸ºç»“æ„åŒ–ä¿¡æ¯æä¾›äº†ä¸€ç§åŸåˆ™æ€§çš„æŠ½è±¡æ–¹æ³•ï¼Œå¹¶è¿›ä¸€æ­¥é˜æ˜äº†å­è®ºç‚¹åœ¨æŠ½è±¡æ¥å—æ€§æ¨ç† (Acceptability Reasoning) ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.12038v1",
      "published_date": "2026-01-17 12:54:10 UTC",
      "updated_date": "2026-01-17 12:54:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:28.068085+00:00"
    },
    {
      "arxiv_id": "2601.12030v1",
      "title": "ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents",
      "title_zh": "ARCï¼šé¢å‘é•¿ç¨‹ä¿¡æ¯è·å–æ™ºèƒ½ä½“çš„ä¸»åŠ¨å¼åæ€é©±åŠ¨ä¸Šä¸‹æ–‡ç®¡ç†",
      "authors": [
        "Yilun Yao",
        "Shan Huang",
        "Elsie Dai",
        "Zhewen Tan",
        "Zhenyu Duan",
        "Shousheng Jia",
        "Yanbing Jiang",
        "Tong Yang"
      ],
      "abstract": "Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ARC æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ç¨‹ä¿¡æ¯å¯»æ±‚ï¼ˆLong-Horizon Information Seekingï¼‰ä»»åŠ¡ä¸­å¸¸è§çš„ä¸Šä¸‹æ–‡é€€åŒ–ï¼ˆContext Rotï¼‰é—®é¢˜ã€‚ARC æ˜¯é¦–ä¸ªå°†ä¸Šä¸‹æ–‡ç®¡ç†å»ºæ¨¡ä¸ºä¸»åŠ¨ã€åå°„é©±åŠ¨ï¼ˆActive and Reflection-drivenï¼‰è¿‡ç¨‹çš„ç³»ç»Ÿï¼Œå°†ä¸Šä¸‹æ–‡è§†ä¸ºæ‰§è¡ŒæœŸé—´çš„å¯å˜æ¨ç†çŠ¶æ€ã€‚é€šè¿‡å¼•å…¥åå°„é©±åŠ¨çš„ç›‘æµ‹ä¸ä¿®è®¢æœºåˆ¶ï¼Œè¯¥æ¡†æ¶å…è®¸æ™ºèƒ½ä½“åœ¨æ£€æµ‹åˆ°ä¿¡æ¯å¤±å‡†æˆ–æ€§èƒ½ä¸‹é™æ—¶ä¸»åŠ¨é‡ç»„å…¶å·¥ä½œä¸Šä¸‹æ–‡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒARC åœ¨å¤šä¸ªé•¿ç¨‹æ£€ç´¢åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºè¢«åŠ¨çš„ä¸Šä¸‹æ–‡å‹ç¼©æ–¹æ³•ï¼Œåœ¨ BrowseComp-ZH æµ‹è¯•é›†ä¸Šä½¿ Qwen2.5-32B-Instruct çš„å‡†ç¡®ç‡æå‡äº† 11% çš„ç»å¯¹å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12030v1",
      "published_date": "2026-01-17 12:17:50 UTC",
      "updated_date": "2026-01-17 12:17:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:29.902533+00:00"
    },
    {
      "arxiv_id": "2601.12024v1",
      "title": "A Multi-Agent System for Generating Actionable Business Advice",
      "title_zh": "ä¸€ç§ç”¨äºç”Ÿæˆå¯æ“ä½œå•†ä¸šå»ºè®®çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Kartikey Singh Bhandari",
        "Tanish Jain",
        "Archit Agrawal",
        "Dhruv Kumar",
        "Praveen Kumar",
        "Pratik Narang"
      ],
      "abstract": "Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº LLMs çš„å¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨å°†å¤§è§„æ¨¡å®¢æˆ·è¯„è®ºè¯­æ–™åº“è½¬åŒ–ä¸ºå…·æœ‰å¯æ“ä½œæ€§çš„ä¸šåŠ¡å»ºè®®ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆèšç±»ï¼ˆclusteringï¼‰ã€å»ºè®®ç”Ÿæˆã€è¿­ä»£è¯„ä¼°å’Œå¯è¡Œæ€§æ’åºï¼ˆfeasibility based rankingï¼‰å››ä¸ªç»„ä»¶ï¼Œå®ç°äº†è¯­æ–™æç‚¼ä¸åé¦ˆé©±åŠ¨çš„å»ºè®®ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å¯æ“ä½œæ€§ï¼ˆactionabilityï¼‰ã€ç‰¹å¼‚æ€§ï¼ˆspecificityï¼‰å’Œéå†—ä½™æ€§ï¼ˆnon-redundancyï¼‰æ–¹é¢å‡æ˜¾è‘—ä¼˜äºå•æ¨¡å‹åŸºçº¿ã€‚ç ”ç©¶è¿˜è¯æ˜ï¼Œä¸­å‹æ¨¡å‹åœ¨è¯¥æ¡†æ¶ä¸‹çš„è¡¨ç°èƒ½å¤Ÿæ¥è¿‘å¤§å‹æ¨¡å‹ï¼Œä¸ºä¼ä¸šæä¾›äº†å…¼å…·æ·±åº¦æ¨ç†ä¸å®ç”¨æ€§çš„å†³ç­–æ”¯æŒæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12024v1",
      "published_date": "2026-01-17 12:07:55 UTC",
      "updated_date": "2026-01-17 12:07:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:37.567021+00:00"
    },
    {
      "arxiv_id": "2601.12019v1",
      "title": "Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning",
      "title_zh": "å€ŸåŠ›å¤§è¯­è¨€æ¨¡å‹çš„è°„åªšç‰¹æ€§ï¼šé€šè¿‡å¯¹ç«‹ç«‹åœºæ¨ç†å¯¹æŠ—ç‚¹å‡»è¯±é¥µ",
      "authors": [
        "Chaowei Zhang",
        "Xiansheng Luo",
        "Zewei Zhang",
        "Yi Zhu",
        "Jipeng Qiang",
        "Longwei Wang"
      ],
      "abstract": "The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ£€æµ‹ç‚¹å‡»è¯±é¥µ(clickbait)æ—¶å­˜åœ¨çš„è°„åªš(Sycophancy)å€¾å‘ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨è¯¥ç‰¹æ€§ç”Ÿæˆå¯¹ç«‹è§†è§’æ¨ç†çš„æ–°ç­–ç•¥ã€‚é€šè¿‡è®¾è®¡è‡ªæˆ‘æ›´æ–°å¯¹ç«‹ç«‹åœºæ¨ç†ç”Ÿæˆ(SORG)æ¡†æ¶ï¼ŒLLMsèƒ½å¤Ÿé’ˆå¯¹æ–°é—»æ ‡é¢˜è‡ªåŠ¨äº§ç”Ÿé«˜è´¨é‡çš„â€œèµåŒâ€ä¸â€œåå¯¹â€æ¨ç†å¯¹ï¼Œä¸”æ— éœ€ä¾èµ–äººå·¥æ ‡æ³¨ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†åŸºäºå¯¹ç«‹æ¨ç†çš„ç‚¹å‡»è¯±é¥µæ£€æµ‹(ORCD)æ¨¡å‹ï¼Œç»“åˆBERTç¼–ç å™¨ä¸å¯¹æ¯”å­¦ä¹ (contrastive learning)æŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨LLMç”Ÿæˆçš„ä¿¡ç”¨è¯„åˆ†è¿›è¡Œå¼•å¯¼ï¼Œæœ‰æ•ˆå¢å¼ºäº†æ£€æµ‹çš„é²æ£’æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºå½“å‰çš„SOTAåŸºå‡†æ¨¡å‹ã€å¾®è°ƒçš„å°è¯­è¨€æ¨¡å‹ä»¥åŠç›´æ¥çš„LLM Promptingæ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12019v1",
      "published_date": "2026-01-17 11:57:23 UTC",
      "updated_date": "2026-01-17 11:57:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:42.029493+00:00"
    },
    {
      "arxiv_id": "2601.12014v1",
      "title": "Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ˜¯å¦å·²ä¸º TOON åšå¥½å‡†å¤‡ï¼Ÿæ–°å‹ç»“æ„åŒ–è¾“å‡ºæ ¼å¼ä¸­ç»“æ„æ­£ç¡®æ€§ä¸å¯æŒç»­æ€§æƒè¡¡çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Elio Masciari",
        "Vincenzo Moscato",
        "Enea Vincenzo Napolitano",
        "Gian Marco Orlando",
        "Marco Perillo",
        "Diego Russo"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.\n  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºæ—¶ï¼Œå…¶ç»“æ„æ­£ç¡®æ€§ä¸ç¯å¢ƒå¯æŒç»­æ€§ï¼ˆSustainabilityï¼‰ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªè¡¡é‡ Token ä½¿ç”¨é‡ã€ç”Ÿæˆæ—¶é—´å’Œç¢³æ’æ”¾çš„è¯„ä¼°æ¡†æ¶ï¼Œå¹¶å®šä¹‰äº†ç¯å¢ƒæ„ŸçŸ¥ç”Ÿæˆæ­£ç¡®æ€§å¾—åˆ†ï¼ˆGCS_envï¼‰è¿™ä¸€ç»¼åˆæŒ‡æ ‡ã€‚é€šè¿‡åœ¨å¤šç§ LLMs ä¸Šå¯¹æ¯”æ–°å‹ TOON æ ¼å¼ä¸ä¼ ç»Ÿçš„ JSONã€XMLã€YAML æ ¼å¼ï¼Œç ”ç©¶å‘ç° TOON èƒ½æ˜¾è‘—é™ä½æ’æ”¾å¹¶æé«˜è¾“å‡ºç´§å‡‘åº¦ï¼Œä½†åœ¨æ¨¡å‹ç¼ºä¹åŸç”Ÿæ”¯æŒæ—¶å­˜åœ¨æ­£ç¡®æ€§ä¸‹é™çš„å–èˆã€‚ç»“æœè¡¨æ˜ï¼Œå¢åŠ æ¨¡å‹å®¹é‡å¯æœ‰æ•ˆç¼“è§£æ­£ç¡®æ€§é—®é¢˜ï¼Œè¯æ˜äº† TOON ç­‰ç´§å‡‘å‹è¡¨ç¤ºæ³•åœ¨å¤§è§„æ¨¡ã€ç¢³æ•æ„Ÿçš„ LLM éƒ¨ç½²ä¸­å…·æœ‰æ˜¾è‘—çš„å®è·µä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12014v1",
      "published_date": "2026-01-17 11:42:02 UTC",
      "updated_date": "2026-01-17 11:42:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:42.434453+00:00"
    },
    {
      "arxiv_id": "2601.12003v2",
      "title": "Robust Verification of Concurrent Stochastic Games",
      "title_zh": "å¹¶å‘éšæœºåšå¼ˆçš„é²æ£’éªŒè¯",
      "authors": [
        "Angel Y. He",
        "David Parker"
      ],
      "abstract": "Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified - an unrealistic requirement in many real-world settings. We introduce *robust CSGs* and their subclass *interval CSGs* (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for *robust* verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹è¿›è¡Œå¹¶å‘å†³ç­–çš„é—®é¢˜ï¼Œæå‡ºäº† robust CSGsï¼ˆç¨³å¥å¹¶å‘éšæœºåšå¼ˆï¼‰åŠå…¶å­ç±» interval CSGs (ICSGs)ï¼Œä»¥è§£å†³ä¼ ç»Ÿæ¨¡å‹ä¸­è½¬ç§»æ¦‚ç‡å¿…é¡»ç²¾ç¡®æŒ‡å®šçš„å±€é™æ€§ã€‚ç ”ç©¶å¼€å‘äº†ä¸€å¥—å…¨æ–°çš„ robust éªŒè¯æ¡†æ¶ï¼Œä¸ºæœ‰é™å’Œæ— é™æ—¶ç•Œç›®æ ‡æä¾›äº†ç†è®ºåŸºç¡€ä¸é«˜æ•ˆç®—æ³•ï¼Œå¹¶åŒæ—¶æ¶µç›–äº† zero-sum å’ŒåŸºäº Nash equilibria çš„ nonzero-sum åšå¼ˆè®¾å®šã€‚ä½œè€…åœ¨ PRISM-games æ¨¡å‹æ£€éªŒå™¨ä¸­å®ç°äº†è¯¥æ–¹æ³•ï¼Œé€šè¿‡ä¸€ç³»åˆ—å¤§å‹åŸºå‡†æµ‹è¯•è¯æ˜äº†å¯¹ ICSGs è¿›è¡Œç¨³å¥éªŒè¯çš„å¯è¡Œæ€§ï¼Œä¸ºä¸ç¡®å®šç¯å¢ƒä¸‹çš„è‡ªä¸»ç³»ç»ŸéªŒè¯ä¸æ§åˆ¶æä¾›äº†é‡è¦æ”¯æŒã€‚\n\n---\nå¦‚æœä½ æœ‰æ›´å¤šè®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæ¬¢è¿éšæ—¶æä¾›ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.GT",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.LO",
      "comment": "Extended version of a paper accepted to TACAS 2026. Main text: 17 pages, 2 figures, 2 tables; Appendix: 37 pages, 3 figures, 3 tables. Minor revisions and clarifications to the appendix; no changes to results",
      "pdf_url": "https://arxiv.org/pdf/2601.12003v2",
      "published_date": "2026-01-17 10:42:44 UTC",
      "updated_date": "2026-01-21 09:31:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:40.446555+00:00"
    },
    {
      "arxiv_id": "2601.12002v1",
      "title": "Kernel-Based Learning of Safety Barriers",
      "title_zh": "åŸºäºæ ¸æ–¹æ³•çš„å®‰å…¨å±éšœå­¦ä¹ ",
      "authors": [
        "Oliver SchÃ¶n",
        "Zhengang Zhong",
        "Sadegh Soudjani"
      ],
      "abstract": "The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹å…·æœ‰ç¦»æ•£æ—¶é—´éšæœºåŠ¨åŠ›å­¦çš„é»‘ç›’ç³»ç»Ÿ(black-box systems)å®‰å…¨æ€§éªŒè¯ä¸åˆæˆçš„æ•°æ®é©±åŠ¨æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ç³»ç»Ÿè½¨è¿¹ç›´æ¥å­¦ä¹ æ§åˆ¶å±éšœè¯ä¹¦(control barrier certificates)ï¼Œå¹¶åˆ©ç”¨æ¡ä»¶å‡å€¼åµŒå…¥(conditional mean embeddings)å°†æ•°æ®æ˜ å°„è‡³å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´(RKHS)ï¼Œé€šè¿‡æ„å»ºRKHSæ­§ä¹‰é›†(ambiguity set)å¢å¼ºäº†ç³»ç»Ÿå¯¹åˆ†å¸ƒå¤–(out-of-distribution)è¡Œä¸ºçš„é²æ£’æ€§ã€‚ä¸ºäº†æå‡è®¡ç®—æ•ˆç‡ï¼Œç ”ç©¶é‡‡ç”¨æœ‰é™å‚…é‡Œå¶å±•å¼€(finite Fourier expansion)å°†å¤æ‚çš„åŠæ— é™ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºçº¿æ€§è§„åˆ’ï¼Œå¹¶ç»“åˆå¿«é€Ÿå‚…é‡Œå¶å˜æ¢(FFT)å®ç°äº†é«˜åº¦å¯æ‰©å±•çš„éªŒè¯æ¡†æ¶ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŒ…å«ç¥ç»ç½‘ç»œæ§åˆ¶å™¨çš„é»‘ç›’ç³»ç»Ÿä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶èƒ½æ¨å¹¿è‡³å®‰å…¨æ€§ä»¥å¤–çš„é€šç”¨æ—¶åºé€»è¾‘è§„èŒƒ(temporal logic specifications)ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "44 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12002v1",
      "published_date": "2026-01-17 10:42:35 UTC",
      "updated_date": "2026-01-17 10:42:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:48.725010+00:00"
    },
    {
      "arxiv_id": "2601.11998v1",
      "title": "Hybrid IDS Using Signature-Based and Anomaly-Based Detection",
      "title_zh": "ç»“åˆç‰¹å¾æ£€æµ‹ä¸å¼‚å¸¸æ£€æµ‹çš„æ··åˆå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ",
      "authors": [
        "Messaouda Boutassetta",
        "Amina Makhlouf",
        "Newfel Messaoudi",
        "Abdelmadjid Benmachiche",
        "Ines Boutabia"
      ],
      "abstract": "Intrusion detection systems (IDS) are essential for protecting computer systems and networks against a wide range of cyber threats that continue to evolve over time. IDS are commonly categorized into two main types, each with its own strengths and limitations, such as difficulty in detecting previously unseen attacks and the tendency to generate high false positive rates. This paper presents a comprehensive survey and a conceptual overview of Hybrid IDS, which integrate signature-based and anomaly-based detection techniques to enhance attack detection capabilities. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. In addition, recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, are reviewed. Finally, this work outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ··åˆå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ (Hybrid IDS) è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°å’Œæ¦‚å¿µæ€§æ¦‚è¿°ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆåŸºäºç­¾å (Signature-based) å’ŒåŸºäºå¼‚å¸¸ (Anomaly-based) çš„æ£€æµ‹æŠ€æœ¯æ¥å¢å¼ºç½‘ç»œæ”»å‡»çš„è¯†åˆ«èƒ½åŠ›ã€‚è®ºæ–‡ç³»ç»Ÿæ€§åœ°åˆ†ç±»äº†ç°æœ‰æ¨¡å‹ï¼Œå¹¶åˆ†æäº†å…¶åœ¨é‡‘èç³»ç»Ÿã€ç©ºä¸­äº¤é€šç®¡åˆ¶åŠç¤¾äº¤ç½‘ç»œç­‰å…³é”®é¢†åŸŸçš„åº”ç”¨ä¼˜åŠ¿ä¸å±€é™æ€§ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å›é¡¾äº†æœºå™¨å­¦ä¹  (Machine Learning) å’Œäº‘éƒ¨ç½² (Cloud-based deployments) ç­‰å‰æ²¿æŠ€æœ¯åœ¨ Hybrid IDS ä¸­çš„åº”ç”¨è¶‹åŠ¿ã€‚æœ€åï¼Œè¯¥ç ”ç©¶ä¸ºæœªæ¥å¼€å‘å…·å¤‡é«˜æˆæœ¬æ•ˆç›Šä¸”èƒ½æœ‰æ•ˆæ£€æµ‹å¤æ‚æ–°å…´æ”»å‡»çš„é˜²å¾¡æ–¹æ¡ˆæŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages,The Second National Conference on Artificial Intelligence and Information Technologies (NCAIIT25)",
      "pdf_url": "https://arxiv.org/pdf/2601.11998v1",
      "published_date": "2026-01-17 10:19:57 UTC",
      "updated_date": "2026-01-17 10:19:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:48.502627+00:00"
    },
    {
      "arxiv_id": "2601.11995v1",
      "title": "Learning Audio-Visual Embeddings with Inferred Latent Interaction Graphs",
      "title_zh": "åŸºäºæ¨æ–­æ½œåœ¨äº¤äº’å›¾çš„è§†å¬åµŒå…¥å­¦ä¹ ",
      "authors": [
        "Donghuo Zeng",
        "Hao Niu",
        "Yanan Wang",
        "Masato Taya"
      ],
      "abstract": "Learning robust audio-visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences - background noise, unrelated elements, or unannotated events. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. For example, a video labeled \"train\" might also contain motorcycle audio and visual, because \"motorcycle\" is not the chosen annotation; standard methods treat these co-occurrences as negatives to true motorcycle anchors elsewhere, creating false negatives and missing true cross-modal dependencies. We propose a framework that leverages soft-label predictions and inferred latent interactions to address these issues: (1) Audio-Visual Semantic Alignment Loss (AV-SAL) trains a teacher network to produce aligned soft-label distributions across modalities, assigning nonzero probability to co-occurring but unannotated events and enriching the supervision signal. (2) Inferred Latent Interaction Graph (ILI) applies the GRaSP algorithm to teacher soft labels to infer a sparse, directed dependency graph among classes. This graph highlights directional dependencies (e.g., \"Train (visual)\" -> \"Motorcycle (audio)\") that expose likely semantic or conditional relationships between classes; these are interpreted as estimated dependency patterns. (3) Latent Interaction Regularizer (LIR): A student network is trained with both metric loss and a regularizer guided by the ILI graph, pulling together embeddings of dependency-linked but unlabeled pairs in proportion to their soft-label probabilities. Experiments on AVE and VEGAS benchmarks show consistent improvements in mean average precision (mAP), demonstrating that integrating inferred latent interactions into embedding learning enhances robustness and semantic coherence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†å¬åµŒå…¥ (Audio-Visual Embeddings) å­¦ä¹ ä¸­ï¼Œä¼ ç»Ÿå¯¹æ¯”å­¦ä¹ æ–¹æ³•å®¹æ˜“å°†å…±å­˜ä½†æœªæ ‡æ³¨çš„äº‹ä»¶è¯¯åˆ¤ä¸ºè´Ÿæ ·æœ¬ï¼ˆFalse Negativesï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨æ¨æ–­æ½œåœ¨äº¤äº’å›¾çš„æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥è§†å¬è¯­ä¹‰å¯¹é½æŸå¤± (Audio-Visual Semantic Alignment Loss, AV-SAL)ï¼Œé€šè¿‡æ•™å¸ˆç½‘ç»œç”Ÿæˆçš„è½¯æ ‡ç­¾æ•æ‰å…±å­˜äº‹ä»¶çš„è¯­ä¹‰ï¼›åŒæ—¶åˆ©ç”¨æ¨æ–­æ½œåœ¨äº¤äº’å›¾ (Inferred Latent Interaction Graph, ILI) æ­ç¤ºç±»åˆ«é—´çš„å®šå‘ä¾èµ–å…³ç³»ã€‚æœ€åï¼Œé€šè¿‡æ½œåœ¨äº¤äº’æ­£åˆ™åŒ–é¡¹ (Latent Interaction Regularizer, LIR) æŒ‡å¯¼å­¦ç”Ÿç½‘ç»œï¼Œä½¿å…·æœ‰æ½œåœ¨å…³è”çš„æœªæ ‡è®°æ ·æœ¬å¯¹åœ¨åµŒå…¥ç©ºé—´ä¸­æ›´åŠ æ¥è¿‘ã€‚åœ¨ AVE å’Œ VEGAS åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†å¹³å‡ç²¾åº¦å‡å€¼ (mAP)ï¼Œå¢å¼ºäº†è§†å¬è¡¨å¾å­¦ä¹ çš„é²æ£’æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.MM",
      "comment": "16 pages, 5 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.11995v1",
      "published_date": "2026-01-17 10:13:07 UTC",
      "updated_date": "2026-01-17 10:13:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:57.192064+00:00"
    },
    {
      "arxiv_id": "2601.11979v1",
      "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion",
      "title_zh": "è¿‡ç¨‹å¼ä¸Šä¸‹æ–‡å­¦ä¹ ï¼šé€šè¿‡åŠ¨æ€ç¤ºä¾‹æ’å…¥å¢å¼ºæ•°å­¦æ¨ç†èƒ½åŠ›",
      "authors": [
        "Ang Gao",
        "Changshuo Zhang",
        "Xiao Zhang",
        "Deyang Li",
        "Minjun Zhao",
        "Fangchao Liu",
        "Xinyu Zhang"
      ],
      "abstract": "In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Process In-Context Learning (PICL)ï¼Œä¸€ç§æ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æ•°å­¦æ¨ç†èƒ½åŠ›çš„åŠ¨æ€ç¤ºä¾‹é›†æˆæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰ In-Context Learning (ICL) é™æ€ä½¿ç”¨ç¤ºä¾‹ã€æ— æ³•åº”å¯¹å¤šæ­¥æ¨ç†ä¸­å®æ—¶å›°æƒ‘ç‚¹çš„å±€é™æ€§ï¼ŒPICL å®ç°äº†æ ¹æ®æ¨ç†éœ€æ±‚åŠ¨æ€æ’å…¥ç¤ºä¾‹ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ†ææ¨ç†è¿‡ç¨‹ä¸­çš„è¯­ä¹‰å’Œç†µ (entropy) æ¥è¯†åˆ«å›°æƒ‘ç‚¹ï¼Œå¹¶ä»ç¤ºä¾‹åº“ä¸­æ£€ç´¢åŒ¹é…çš„ç¤ºä¾‹å®æ—¶æ’å…¥ï¼Œä»¥å¼•å¯¼åç»­æ­¥éª¤ã€‚å®éªŒè¡¨æ˜ï¼ŒPICL æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£äº†æ¨ç†ä¸­æœŸçš„é”™è¯¯ç´¯ç§¯ï¼Œçªæ˜¾äº†åœ¨å¤æ‚é€»è¾‘ä»»åŠ¡ä¸­é‡‡ç”¨è‡ªé€‚åº”ç¤ºä¾‹æ’å…¥çš„ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11979v1",
      "published_date": "2026-01-17 09:20:06 UTC",
      "updated_date": "2026-01-17 09:20:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:25:58.030783+00:00"
    },
    {
      "arxiv_id": "2601.11977v1",
      "title": "One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints",
      "title_zh": "éšç§çº¦æŸä¸‹åŸºäºåå˜é‡å¼•å¯¼ä¸“å®¶æ¨¡å‹çš„å•æ ·æœ¬ä»·æ ¼é¢„æµ‹",
      "authors": [
        "Ren He",
        "Yinliang Xu",
        "Jinfeng Wang",
        "Jeremy Watson",
        "Jian Song"
      ],
      "abstract": "Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MoE Encoder æ¨¡å—ï¼Œæ—¨åœ¨è§£å†³ç”µåŠ›ç³»ç»Ÿé¢„æµ‹ä¸­å¤æ‚çš„å¤šå˜é‡ä¾èµ–ä»¥åŠéšç§ä¿æŠ¤ (Privacy Constraints) ä¸‹çš„æ³›åŒ–éš¾é¢˜ã€‚è¯¥æ¨¡å—é€šè¿‡åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„ tokenization ä¸ encoding é˜¶æ®µä¹‹é—´å¼•å…¥ç¨€ç–çš„ Mixture-of-Experts (MoE) å±‚ï¼Œå®ç°äº†å°†å¤šå˜é‡é¢„æµ‹è½¬åŒ–ä¸ºä¸“å®¶å¼•å¯¼çš„å•å˜é‡ä»»åŠ¡ï¼Œä»è€Œç²¾å‡†æ•æ‰å˜é‡é—´å…³ç³»ã€‚æ­¤å¤–ï¼Œè¯¥æ¶æ„æ”¯æŒè”é‚¦å­¦ä¹  (Federated Learning) æ¨¡å¼ä¸‹çš„æœ¬åœ°åŒ–è®­ç»ƒå’Œè½»é‡çº§å‚æ•°å…±äº«ï¼Œç¡®ä¿äº†åŸå§‹æ•°æ®çš„éšç§å®‰å…¨ã€‚å®éªŒè¯æ˜ï¼ŒMoE Encoder åœ¨å¤šå˜é‡æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†é¢„æµ‹ç²¾åº¦ï¼Œä¸”åœ¨è·¨åŒºåŸŸè¿ç§»åœºæ™¯ä¸‹è¡¨ç°å‡ºæé«˜çš„æ•ˆç‡ä¸å¯æ‰©å±•æ€§ï¼Œä¸ºåŸºç¡€æ—¶é—´åºåˆ—æ¨¡å‹æä¾›äº†ä¸€ç§å…·å¤‡éšç§æ„ŸçŸ¥èƒ½åŠ›çš„æ‰©å±•æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11977v1",
      "published_date": "2026-01-17 09:13:57 UTC",
      "updated_date": "2026-01-17 09:13:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:09.715154+00:00"
    },
    {
      "arxiv_id": "2601.11974v1",
      "title": "Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement",
      "title_zh": "åƒäººç±»ä¸€æ ·å­¦ä¹ ï¼šåˆ©ç”¨å…ƒè®¤çŸ¥åæ€å®ç°é«˜æ•ˆè‡ªæˆ‘æå‡",
      "authors": [
        "Xinmeng Hou",
        "Peiliang Gong",
        "Bohao Qu",
        "Wuqi Wang",
        "Qing Guo",
        "Yang Liu"
      ],
      "abstract": "While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MARS (Metacognitive Agent Reflective Self-improvement) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ™ºèƒ½ä½“å—é™äºé™æ€æç¤ºè¯ä»¥åŠç°æœ‰è‡ªæ”¹è¿›æ¡†æ¶è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚å—æ•™è‚²å¿ƒç†å­¦å¯å‘ï¼ŒMARS æ¨¡æ‹Ÿäººç±»å­¦ä¹ è¿‡ç¨‹ï¼Œå°† principle-based reflectionï¼ˆæŠ½è±¡è§„èŒƒè§„åˆ™ä»¥é¿å…é”™è¯¯ï¼‰ä¸ procedural reflectionï¼ˆæ¨å¯¼æˆåŠŸçš„æ­¥éª¤ç­–ç•¥ï¼‰ç›¸ç»“åˆã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨å•ä¸ªå¾ªç¯å‘¨æœŸå†…å°†è¿™äº›åå°„è§è§£åˆæˆä¼˜åŒ–æŒ‡ä»¤ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿç³»ç»Ÿåœ°å®Œå–„æ¨ç†é€»è¾‘ï¼Œä¸”æ— éœ€æŒç»­çš„åœ¨çº¿åé¦ˆã€‚åœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜ï¼ŒMARS åœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„å…ˆè¿›è‡ªè¿›åŒ–ç³»ç»Ÿï¼Œå¹¶æ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„è‡ªè¿›åŒ–ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11974v1",
      "published_date": "2026-01-17 09:12:26 UTC",
      "updated_date": "2026-01-17 09:12:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:11.516630+00:00"
    },
    {
      "arxiv_id": "2601.11969v1",
      "title": "$\\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models",
      "title_zh": "$\\texttt{MemoryRewardBench}$ï¼šå¤§è¯­è¨€æ¨¡å‹é•¿æœŸè®°å¿†ç®¡ç†å¥–åŠ±æ¨¡å‹çš„è¯„ä¼°åŸºå‡†",
      "authors": [
        "Zecheng Tang",
        "Baibei Ji",
        "Ruoxi Sun",
        "Haitian Wang",
        "WangJie You",
        "Zhang Yijun",
        "Wenpeng Zhu",
        "Ji Qi",
        "Juntao Li",
        "Min Zhang"
      ],
      "abstract": "Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† $\\texttt{MemoryRewardBench}$ï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨ç³»ç»Ÿæ€§è¯„ä¼°å¥–åŠ±æ¨¡å‹ (Reward Models, RMs) åœ¨å¤§è¯­è¨€æ¨¡å‹é•¿æ•ˆè®°å¿†ç®¡ç†ä¸­è¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†æ¶µç›–äº†é•¿ä¸Šä¸‹æ–‡ç†è§£ä¸é•¿ç¯‡ç”Ÿæˆä»»åŠ¡ï¼Œæ¶‰åŠ 10 ç§ä¸åŒçš„è®°å¿†ç®¡ç†æ¨¡å¼ï¼Œä¸Šä¸‹æ–‡é•¿åº¦è·¨åº¦ä» 8K åˆ° 128K tokensã€‚é€šè¿‡å¯¹ 13 ç§å‰æ²¿ RMs çš„è¯„ä¼°å‘ç°ï¼Œå¼€æºæ¨¡å‹ä¸ç§æœ‰æ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®è·æ­£åœ¨ç¼©å°ï¼Œä¸”æ–°ä¸€ä»£æ¨¡å‹åœ¨è¯„ä¼°èƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºå‰ä»£æ¨¡å‹ã€‚è¯¥å·¥ä½œä¸ä»…æ­ç¤ºäº†å½“å‰ RMs çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œè¿˜æŒ‡å‡ºäº†å…¶åœ¨è¯„ä¼° LLM è®°å¿†ç®¡ç†æ—¶çš„åŸºæœ¬å±€é™æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11969v1",
      "published_date": "2026-01-17 09:04:53 UTC",
      "updated_date": "2026-01-17 09:04:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:14.000610+00:00"
    },
    {
      "arxiv_id": "2601.11960v1",
      "title": "R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning",
      "title_zh": "R$^2$POï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„è®­ç»ƒè½¨è¿¹ä¸æ¨ç†å“åº”è§£è€¦",
      "authors": [
        "Jingchu Wang",
        "Bingbing Xu",
        "Yige Yuan",
        "Bin Xie",
        "Xiaoqian Sun",
        "Huawei Shen"
      ],
      "abstract": "Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† $R^2$PO (Residual Rollout Policy Optimization)ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLM) åœ¨å¼ºåŒ–å­¦ä¹ æ¨ç†è®­ç»ƒä¸­ï¼Œæ¨ç†å“åº”çš„ç¨³å®šæ€§ä¸è®­ç»ƒè½¨è¿¹çš„å¤šæ ·æ€§ä¹‹é—´çš„ç›®æ ‡å†²çªã€‚é€šè¿‡åœ¨ç­–ç•¥ä¹‹ä¸Šå¼•å…¥è½»é‡çº§çš„ Residual Rollout-Headï¼Œè¯¥æ–¹æ³•å®ç°äº†è®­ç»ƒè½¨è¿¹ä¸æ¨ç†å“åº”çš„è§£è€¦ï¼Œä»è€Œåœ¨ä¿æŒæ¨ç†ç”Ÿæˆç¨³å®šçš„åŒæ—¶ï¼Œåœ¨è®­ç»ƒé˜¶æ®µå®ç°å—æ§çš„è½¨è¿¹å¤šæ ·åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œ$R^2$PO åœ¨ MATH-500 å’Œ APPS åŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«å–å¾—äº† 3.1% å’Œ 2.4% çš„å¹³å‡å‡†ç¡®ç‡å¢ç›Šã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æ˜¾è‘—å‡å°‘äº†æ ¼å¼é”™è¯¯å¹¶æœ‰æ•ˆç¼“è§£äº†é•¿åº¦åè§ (length bias)ï¼Œä¸ºå®ç°æ›´ç¨³å®šã€é«˜æ•ˆçš„æ¨ç†ä¼˜åŒ–æä¾›äº†ä¿éšœã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11960v1",
      "published_date": "2026-01-17 08:30:50 UTC",
      "updated_date": "2026-01-17 08:30:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:17.370666+00:00"
    },
    {
      "arxiv_id": "2601.11956v1",
      "title": "Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence",
      "title_zh": "Double-Calibrationï¼šé€šè¿‡çŸ¥è¯†ä¸æ¨ç†ç½®ä¿¡åº¦æ ¡å‡†è¿ˆå‘å¯ä¿¡å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Yuyin Lu",
        "Ziran Liang",
        "Yanghui Rao",
        "Wenqi Fan",
        "Fu Lee Wang",
        "Qing Li"
      ],
      "abstract": "Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DoublyCal æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ ¡å‡†çŸ¥è¯†å’Œæ¨ç†ä¿¡å¿ƒæ¥æå‡å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„å¯é æ€§ï¼Œå¹¶è§£å†³å…¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­å› å¹»è§‰å¯¼è‡´çš„ä¸ç¡®å®šæ€§é‡åŒ–ç¼ºå¤±é—®é¢˜ã€‚è¯¥æ¡†æ¶åŸºäºåŒé‡æ ¡å‡† (double-calibration) åŸåˆ™ï¼Œé¦–å…ˆåˆ©ç”¨è½»é‡åŒ–ä»£ç†æ¨¡å‹ç”Ÿæˆå¸¦æœ‰æ ¡å‡†ç½®ä¿¡åº¦çš„çŸ¥è¯†å›¾è°± (Knowledge Graph) è¯æ®ã€‚éšåï¼Œè¿™äº›ç»è¿‡æ ¡å‡†çš„æ”¯æŒè¯æ®å¼•å¯¼é»‘ç›’ LLM è¿›è¡Œæœ€ç»ˆé¢„æµ‹ï¼Œç¡®ä¿é¢„æµ‹ç»“æœä¸ä»…æ›´å‡†ç¡®ï¼Œä¸”å…¶ç½®ä¿¡åº¦åˆ†æ•°å¯æº¯æºè‡³è¯æ®çš„ä¸ç¡®å®šæ€§ã€‚åœ¨çŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDoublyCal åœ¨ä¿æŒä½ token æˆæœ¬çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†é»‘ç›’ LLM çš„é¢„æµ‹å‡†ç¡®ç‡å’Œç½®ä¿¡åº¦æ ¡å‡† (confidence calibration) æ•ˆæœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11956v1",
      "published_date": "2026-01-17 08:18:38 UTC",
      "updated_date": "2026-01-17 08:18:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:22.793630+00:00"
    },
    {
      "arxiv_id": "2601.11940v1",
      "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart",
      "title_zh": "é•¿é“¾å¼æ€ç»´ä¸­çš„æ€ç»´é™·é˜±ï¼šé‡åŒ–ç ”ç©¶ä¸é™·é˜±æ„ŸçŸ¥å‹è‡ªé€‚åº”é‡å¯",
      "authors": [
        "Kang Chen",
        "Fan Yu",
        "Junjie Nian",
        "Shihan Zhao",
        "Zhuoka Feng",
        "Zijun Yao",
        "Heng Wang",
        "Minshen Yu",
        "Yixin Cao"
      ],
      "abstract": "Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é•¿é“¾å¼æ€ç»´ (Long Chain-of-Thought) åœ¨æ‰©å±•æ¨ç†èƒ½åŠ›æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºæ¨¡å‹å®¹æ˜“é™·å…¥â€œæ€ç»´é™·é˜±â€ (Thinking Traps)ï¼Œå³åœ¨æ—©æœŸé”™è¯¯æäº¤åï¼Œåç»­çš„åå°„æˆ–éªŒè¯å¾€å¾€æ— æ³•ä¿®æ­£æ ¹æºæ€§é”™è¯¯ã€‚åˆ†ææ˜¾ç¤ºï¼Œåœ¨ DAPO-MATH æ•°æ®é›†çš„å¤±è´¥æ¡ˆä¾‹ä¸­ï¼Œé«˜è¾¾ 89% è¡¨ç°å‡ºæ­¤ç±»é™·é˜±ç‰¹å¾ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† TAAR (Trap-Aware Adaptive Restart) æ¨ç†é˜¶æ®µæ§åˆ¶æ¡†æ¶ï¼Œé€šè¿‡è®­ç»ƒè¯Šæ–­ç­–ç•¥æ¥é¢„æµ‹è½¨è¿¹æˆªæ–­ä½ç½® (trap index) ä¸é€ƒé€¸æ¦‚ç‡ (escape probability)ã€‚TAAR åœ¨æ¨ç†æ—¶èƒ½è‡ªåŠ¨æˆªæ–­å—é™·è½¨è¿¹å¹¶è‡ªé€‚åº”é‡å¯è§£ç ï¼Œé’ˆå¯¹ä¸¥é‡å—é™·æƒ…å†µä¼šæ–½åŠ é«˜é‡‡æ ·æ¸©åº¦æˆ–ç»“æ„åŒ–é‡å¯åç¼€ä»¥å¼•å¯¼æ¨¡å‹è„±å›°ã€‚å®éªŒè¯æ˜ï¼ŒTAAR åœ¨ AIME25 å’Œ GPQA-Diamond ç­‰å¤æ‚æ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œä¸”æ— éœ€å¯¹åŸºåº§æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11940v1",
      "published_date": "2026-01-17 07:26:02 UTC",
      "updated_date": "2026-01-17 07:26:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:24.973596+00:00"
    },
    {
      "arxiv_id": "2601.11935v1",
      "title": "Big Data Workload Profiling for Energy-Aware Cloud Resource Management",
      "title_zh": "é¢å‘èƒ½è€—æ„ŸçŸ¥äº‘èµ„æºç®¡ç†çš„å¤§æ•°æ®å·¥ä½œè´Ÿè½½å‰–æ",
      "authors": [
        "Milan Parikh",
        "Aniket Abhishek Soni",
        "Sneja Mitinbhai Shah",
        "Ayush Raj Jha"
      ],
      "abstract": "Cloud data centers face increasing pressure to reduce operational energy consumption as big data workloads continue to grow in scale and complexity. This paper presents a workload aware and energy efficient scheduling framework that profiles CPU utilization, memory demand, and storage IO behavior to guide virtual machine placement decisions. By combining historical execution logs with real time telemetry, the proposed system predicts the energy and performance impact of candidate placements and enables adaptive consolidation while preserving service level agreement compliance. The framework is evaluated using representative Hadoop MapReduce, Spark MLlib, and ETL workloads deployed on a multi node cloud testbed. Experimental results demonstrate consistent energy savings of 15 to 20 percent compared to a baseline scheduler, with negligible performance degradation. These findings highlight workload profiling as a practical and scalable strategy for improving the sustainability of cloud based big data processing environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§èƒ½æ•ˆæ„ŸçŸ¥çš„äº‘èµ„æºç®¡ç†è°ƒåº¦æ¡†æ¶ï¼Œæ—¨åœ¨é™ä½å¤§æ•°æ®èƒŒæ™¯ä¸‹äº‘æ•°æ®ä¸­å¿ƒçš„è¿è¥èƒ½è€—ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯¹ CPU utilizationã€memory demand å’Œ storage IO behavior è¿›è¡Œ Workload Profilingï¼Œå¹¶ç»“åˆå†å²æ‰§è¡Œæ—¥å¿—ä¸å®æ—¶é¥æµ‹æ•°æ®æ¥æŒ‡å¯¼ virtual machine (VM) çš„æ”¾ç½®å†³ç­–ã€‚ç³»ç»Ÿèƒ½å¤Ÿåœ¨ç¡®ä¿ service level agreement (SLA) åˆè§„çš„å‰æä¸‹ï¼Œé¢„æµ‹å¹¶ä¼˜åŒ–æ”¾ç½®æ–¹æ¡ˆä»¥å®ç°è‡ªé€‚åº”èµ„æºæ•´åˆã€‚åœ¨ Hadoop MapReduceã€Spark MLlib å’Œ ETL ç­‰å·¥ä½œè´Ÿè½½ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆç›¸æ¯”åŸºçº¿è°ƒåº¦å™¨å¯å®ç° 15% è‡³ 20% çš„èƒ½è€—èŠ‚çœï¼Œä¸”æ€§èƒ½ä¸‹é™å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "10 pages, 3 figures. Accepted and presented at the 2026 International Conference on Data Analytics for Sustainability and Engineering Technology (DASET 2026), Track: Big Data and Machine Learning Applications",
      "pdf_url": "https://arxiv.org/pdf/2601.11935v1",
      "published_date": "2026-01-17 06:50:51 UTC",
      "updated_date": "2026-01-17 06:50:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:30.192726+00:00"
    },
    {
      "arxiv_id": "2601.11920v1",
      "title": "Enhancing LLM-Based Data Annotation with Error Decomposition",
      "title_zh": "é€šè¿‡é”™è¯¯åˆ†è§£æå‡åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ•°æ®æ ‡æ³¨",
      "authors": [
        "Zhen Xu",
        "Vedant Khatri",
        "Yijun Dai",
        "Xiner Liu",
        "Siyan Li",
        "Xuanming Zhang",
        "Renzhe Yu"
      ],
      "abstract": "Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºé”™è¯¯åˆ†è§£(Error Decomposition)çš„è¯Šæ–­æ€§è¯„ä¼°èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ä¸»è§‚æ•°æ®æ ‡æ³¨ä»»åŠ¡æ—¶ï¼Œå› ä¾èµ–å•ä¸€å¯¹é½æŒ‡æ ‡(alignment metric)è€Œæ©ç›–ä¸åŒç±»å‹é”™è¯¯çš„é—®é¢˜ã€‚è¯¥èŒƒå¼å¼•å…¥äº†äººæœºååŒ(human-in-the-loop)æœºåˆ¶ï¼Œå¹¶å»ºç«‹äº†ä¸€ä¸ªä»æ¥æºï¼ˆæ¨¡å‹ç‰¹å®š vs. ä»»åŠ¡å›ºæœ‰ï¼‰å’Œç±»å‹ï¼ˆè¾¹ç•Œæ¨¡ç³Š vs. æ¦‚å¿µè¯†åˆ«é”™è¯¯ï¼‰ä¸¤ä¸ªç»´åº¦å‡ºå‘çš„è¯Šæ–­åˆ†ç±»æ³•(diagnostic taxonomy)ã€‚é€šè¿‡å¯¹å››é¡¹æ•™è‚²é¢†åŸŸæ ‡æ³¨ä»»åŠ¡çš„éªŒè¯ï¼Œç ”ç©¶è¯æ˜äº†è¯¥èŒƒå¼èƒ½æœ‰æ•ˆåˆ†è§£æ ‡æ³¨é”™è¯¯ï¼Œå¹¶æ­ç¤ºäº†åœ¨ç‰¹å®šä»»åŠ¡ä¸­è¿½æ±‚æé«˜å¯¹é½ç‡çš„ä¸ç°å®æ€§ã€‚æœ¬å·¥ä½œä¸ºè¯„ä¼°ç‰¹å®šä»»åŠ¡æ˜¯å¦é€‚åˆLLMæ ‡æ³¨æä¾›äº†ä½æˆæœ¬çš„è¯Šæ–­å·¥å…·ï¼Œå¹¶ä¸ºåç»­çš„æŠ€æœ¯ä¼˜åŒ–æä¾›äº†å…·æœ‰å®è·µæ„ä¹‰çš„æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11920v1",
      "published_date": "2026-01-17 05:43:17 UTC",
      "updated_date": "2026-01-17 05:43:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:48.774654+00:00"
    },
    {
      "arxiv_id": "2601.11913v1",
      "title": "LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding",
      "title_zh": "LSTM-MASï¼šå—é•¿çŸ­æœŸè®°å¿†å¯å‘çš„é•¿ä¸Šä¸‹æ–‡ç†è§£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Yichen Jiang",
        "Peng Ye",
        "Jiakang Yuan",
        "Chongjun Tu",
        "Lei Bai",
        "Tao Chen"
      ],
      "abstract": "Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶å—é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (LSTM) çš„å¯å‘ï¼Œæå‡ºäº†åä¸º LSTM-MAS çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£ä¸­é¢ä¸´çš„è®¡ç®—ç“¶é¢ˆã€é”™è¯¯ç´¯ç§¯å’Œå¹»è§‰ä¼ æ’­ç­‰æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨é“¾å¼æ¶æ„ï¼Œé€šè¿‡æ¨¡æ‹Ÿ LSTM çš„é—¨æ§å’Œå­˜å‚¨æœºåˆ¶ç»„ç»‡äº†å››ç±»æ™ºèƒ½ä½“ï¼šè´Ÿè´£åˆ†æ®µç†è§£çš„ Worker agentã€å‡å°‘å†—ä½™çš„ Filter agentã€è¿›è¡ŒæŒç»­é”™è¯¯æ£€æµ‹çš„ Judge agent ä»¥åŠå…¨å±€è°ƒæ§ä¿¡æ¯ä¿ç•™çš„ Manager agentã€‚è¿™ç§è®¾è®¡å®ç°äº†å—æ§çš„ä¿¡æ¯è½¬ç§»å’Œé€‰æ‹©æ€§çš„é•¿ç¨‹ä¾èµ–å»ºæ¨¡ï¼Œæœ‰æ•ˆå¢å¼ºäº†ä¿¡æ¯åœ¨é•¿æ–‡æœ¬æ®µè½é—´çš„ä¼ é€’ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLSTM-MAS åœ¨ NarrativeQAã€HotpotQA ç­‰å¤šä¸ªé•¿æ–‡æœ¬åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤šæ™ºèƒ½ä½“æ–¹æ³• CoAï¼Œå…¶ä¸­åœ¨ HotpotQA ä¸Šçš„æ€§èƒ½æå‡è¾¾åˆ°äº† 121.57%ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.11913v1",
      "published_date": "2026-01-17 05:16:23 UTC",
      "updated_date": "2026-01-17 05:16:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:33.371644+00:00"
    },
    {
      "arxiv_id": "2601.11907v1",
      "title": "Towards Airborne Object Detection: A Deep Learning Analysis",
      "title_zh": "è¿ˆå‘ç©ºä¸­ç›®æ ‡æ£€æµ‹ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†æ",
      "authors": [
        "Prosenjit Chatterjee",
        "ANK Zaman"
      ],
      "abstract": "The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç©ºä¸­å¹³å°ï¼ˆå¦‚æ— äººæœºã€UAV ç­‰ï¼‰è‡ªåŠ¨åŒ–å¨èƒè¯„ä¼°çš„ç´§è¿«éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åŸºäº EfficientNetB4 çš„åŒä»»åŠ¡æ¨¡å‹ï¼Œæ—¨åœ¨åŒæ­¥å®ç°ç©ºä¸­ç›®æ ‡çš„åˆ†ç±» (Classification) ä¸å¨èƒç­‰çº§é¢„æµ‹ (Threat-level Prediction)ã€‚ä¸ºäº†è§£å†³é«˜è´¨é‡è®­ç»ƒæ•°æ®çš„åŒ®ä¹ï¼Œç ”ç©¶äººå‘˜é€šè¿‡èšåˆå’Œç²¾ç‚¼å¤šä¸ªå…¬å…±æ•°æ®æºæ„å»ºäº† AODTA Datasetã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEfficientNetB4 æ¨¡å‹åœ¨ç›®æ ‡åˆ†ç±»å’Œå¨èƒé¢„æµ‹ä¸­åˆ†åˆ«è¾¾åˆ°äº† 96% å’Œ 90% çš„å‡†ç¡®ç‡ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº ResNet-50 åŸºå‡†æ¨¡å‹ã€‚å°½ç®¡æ ‡é¢˜æåŠæ£€æµ‹ï¼Œä½†è¯¥å·¥ä½œé‡ç‚¹åœ¨äºåˆ©ç”¨é¢„å®šä½å›¾åƒè¿›è¡Œé«˜æ•ˆçš„æ¨ç†åˆ†æï¼Œä¸ºé¢†ç©ºå®‰å…¨ç®¡ç†å’Œå›½é˜²ç›‘æ§æä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æŒã€‚\n\n---\næœŸå¾…è¿™äº›æ‘˜è¦èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦å¤„ç†ï¼Œæ¬¢è¿éšæ—¶å‘é€ç»™æˆ‘ï¼",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11907v1",
      "published_date": "2026-01-17 04:47:47 UTC",
      "updated_date": "2026-01-17 04:47:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:26:34.916247+00:00"
    },
    {
      "arxiv_id": "2601.11905v1",
      "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning",
      "title_zh": "LIBRAï¼šé¢å‘ä¸ªæ€§åŒ–è¯Šç–—è§„åˆ’çš„èåˆè¯­è¨€æ¨¡å‹å¤šè‡‚è€è™æœºè¿½ç´¢ç®—æ³•",
      "authors": [
        "Junyu Cao",
        "Ruijiang Gao",
        "Esmaeil Keyvanshokooh",
        "Jianhao Ma"
      ],
      "abstract": "We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LIBRA (Language Model-Informed Bandit Recourse Algorithm)ï¼Œè¿™æ˜¯ä¸€ä¸ªå°†ç®—æ³•è¿½æº¯ (algorithmic recourse)ã€ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœº (contextual bandits) ä¸å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ç›¸ç»“åˆçš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–ä¸ªæ€§åŒ–åŒ»ç–—ç­‰é«˜é£é™©é¢†åŸŸçš„å†³ç­–ã€‚ç ”ç©¶è€…é¦–å…ˆå®šä¹‰äº†è¿½æº¯è€è™æœºé—®é¢˜ (recourse bandit problem)ï¼Œå¹¶å¼€å‘äº†å¹¿ä¹‰çº¿æ€§è¿½æº¯è€è™æœº (GLRB) ç®—æ³•ã€‚LIBRA è¿›ä¸€æ­¥åˆ©ç”¨ LLM çš„é¢†åŸŸçŸ¥è¯†ä¸ºè€è™æœºå­¦ä¹ æä¾›æŒ‡å¯¼ï¼Œå¹¶å…·å¤‡çƒ­å¯åŠ¨ (warm-start)ã€æä½çš„ LLM è°ƒç”¨é¢‘ç‡ä»¥åŠåœ¨ LLM ä¸å¯é æ—¶çš„é²æ£’æ€§ (robustness) ä¸‰å¤§ç†è®ºä¿éšœã€‚å®éªŒç»“æœï¼ˆåŒ…æ‹¬é«˜è¡€å‹ç®¡ç†æ¡ˆä¾‹ç ”ç©¶ï¼‰è¡¨æ˜ï¼ŒLIBRA åœ¨é™ä½ç´¯è®¡é—æ†¾ (regret)ã€æå‡æ²»ç–—è´¨é‡å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¸ºå¯ä¿¡çš„ LLM ä¸è€è™æœºåä½œæä¾›äº†æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "cs.AI",
      "comment": "50 pages. Previous version with human-AI collaboration: arXiv:2410.14640",
      "pdf_url": "https://arxiv.org/pdf/2601.11905v1",
      "published_date": "2026-01-17 04:37:20 UTC",
      "updated_date": "2026-01-17 04:37:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:00.805927+00:00"
    },
    {
      "arxiv_id": "2601.11903v1",
      "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems",
      "title_zh": "AEMAï¼šé¢å‘å¯ä¿¡ä¸å—æ§æ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿçš„å¯éªŒè¯è¯„ä¼°æ¡†æ¶",
      "authors": [
        "YenTing Lee",
        "Keerthi Koneru",
        "Zahra Moslemi",
        "Sheethal Kumar",
        "Ramesh Radhakrishnan"
      ],
      "abstract": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AEMA (Adaptive Evaluation Multi-Agent)ï¼Œè¿™æ˜¯ä¸€ä¸ªè¿‡ç¨‹æ„ŸçŸ¥ (process-aware) ä¸”å¯å®¡è®¡çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨è¯„ä¼°æ—¶é¢ä¸´çš„åè°ƒæ€§ã€é€æ˜åº¦å’Œå¯éªŒè¯æ€§æŒ‘æˆ˜ã€‚ç›¸æ¯”ä¼ ç»Ÿçš„å•å“åº”è¯„åˆ†æˆ–å•ä¸€çš„ LLM-as-a-Judge æ¨¡å¼ï¼ŒAEMA èƒ½å¤Ÿåœ¨äººå·¥ç›‘ç£ (human oversight) ä¸‹è§„åˆ’ã€æ‰§è¡Œå¹¶èšåˆè·¨å¼‚æ„å·¥ä½œæµçš„å¤šæ­¥éª¤è¯„ä¼°ï¼Œæ˜¾è‘—æå‡äº†è¯„ä¼°çš„ç¨³å®šæ€§å’Œäººç±»å¯¹é½ (human alignment) ç¨‹åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAEMA åœ¨æ¨¡æ‹Ÿçš„ä¼ä¸šçº§ä¸šåŠ¡åœºæ™¯ä¸­æä¾›äº†é€æ˜ä¸”å¯è¿½æº¯çš„è¯„ä¼°è®°å½•ï¼Œä¸ºå®ç°è´Ÿè´£ä»»ä¸”å¯ä¿¡çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¯„ä¼°æä¾›äº†å¯é‡å¤çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Workshop on W51: How Can We Trust and Control Agentic AI? Toward Alignment, Robustness, and Verifiability in Autonomous LLM Agents at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11903v1",
      "published_date": "2026-01-17 04:09:02 UTC",
      "updated_date": "2026-01-17 04:09:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:02.108382+00:00"
    },
    {
      "arxiv_id": "2601.11895v1",
      "title": "DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models",
      "title_zh": "DevBenchï¼šåŸºäºå¼€å‘è€…çœŸå®è¡Œä¸ºçš„ä»£ç ç”Ÿæˆæ¨¡å‹è¯„æµ‹åŸºå‡†",
      "authors": [
        "Pareesa Ameneh Golnari",
        "Adarsh Kumarappan",
        "Wen Wen",
        "Xiaoyu Liu",
        "Gabriel Ryan",
        "Yuting Sun",
        "Shengyu Fu",
        "Elsie Nallipogu"
      ],
      "abstract": "DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DevBenchï¼Œä¸€ä¸ªç”±é¥æµ‹æ•°æ®é©±åŠ¨ (telemetry-driven) çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å®é™…ä»£ç è¡¥å…¨ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¯¥åŸºå‡†åŒ…å«æ¶µç›– 6 ç§ç¼–ç¨‹è¯­è¨€å’Œ 6 ä¸ªä»»åŠ¡ç±»åˆ«çš„ 1,800 ä¸ªè¯„ä¼°å®ä¾‹ï¼Œæ•°æ®æºè‡ªçœŸå®çš„å¼€å‘è€…é¥æµ‹ï¼Œå¼ºè°ƒç”Ÿæ€æœ‰æ•ˆæ€§ (ecological validity) å¹¶æœ‰æ•ˆé¿å…äº†è®­ç»ƒæ•°æ®æ±¡æŸ“ã€‚è¯„ä¼°ä½“ç³»ç»“åˆäº†åŠŸèƒ½æ­£ç¡®æ€§ (functional correctness)ã€åŸºäºç›¸ä¼¼åº¦çš„æŒ‡æ ‡ä»¥åŠä¸“æ³¨äºå®ç”¨æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§çš„ LLM-judge è¯„æµ‹ã€‚é€šè¿‡å¯¹ 9 ç§æœ€å…ˆè¿›æ¨¡å‹çš„æµ‹è¯•ï¼ŒDevBench æ­ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨è¯­æ³•ç²¾åº¦å’Œè¯­ä¹‰æ¨ç†æ–¹é¢çš„å·®å¼‚ï¼Œä¸ºå®é™…éƒ¨ç½²ä¸­çš„æ¨¡å‹é€‰æ‹©å’Œæ”¹è¿›æä¾›äº†å…³é”®çš„è¯Šæ–­æ€§è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11895v1",
      "published_date": "2026-01-17 03:33:08 UTC",
      "updated_date": "2026-01-17 03:33:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:10.914590+00:00"
    },
    {
      "arxiv_id": "2601.11885v1",
      "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment",
      "title_zh": "MyGramï¼šé¢å‘å¤šæ¨¡æ€å®ä½“å¯¹é½çš„å…·æœ‰å…¨å±€åˆ†å¸ƒçš„æ¨¡æ€æ„ŸçŸ¥å›¾ Transformer",
      "authors": [
        "Zhifei Li",
        "Ziyue Qin",
        "Xiangyu Luo",
        "Xiaoju Hou",
        "Yue Zhao",
        "Miao Zhang",
        "Zhifang Huang",
        "Kui Xiao",
        "Bing Yang"
      ],
      "abstract": "Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MyGramï¼Œä¸€ç§å…·æœ‰å…¨å±€åˆ†å¸ƒçš„æ¨¡æ€æ„ŸçŸ¥å›¾è½¬æ¢å™¨ (Modality-aware Graph Transformer)ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å®ä½“å¯¹é½ (Multi-modal Entity Alignment) ä¸­æ¨¡æ€å†…ç»“æ„ä¸Šä¸‹æ–‡ä¿¡æ¯è¢«å¿½è§†ä»¥åŠæ˜“å—æµ…å±‚ç‰¹å¾å¹²æ‰°çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼€å‘æ¨¡æ€æ‰©æ•£å­¦ä¹ æ¨¡å— (Modality Diffusion Learning Module) æ¥æ•æ‰æ·±å±‚ç»“æ„ä¸Šä¸‹æ–‡å¹¶å®ç°ç»†ç²’åº¦èåˆï¼Œå¹¶å¼•å…¥äº† Gram Loss æ­£åˆ™åŒ–çº¦æŸï¼Œé€šè¿‡æœ€å°åŒ–å¤šæ¨¡æ€ç‰¹å¾å½¢æˆçš„å››ç»´å¹³è¡Œå…­é¢ä½“ä½“ç§¯æ¥ç¡®ä¿è·¨æ¨¡æ€çš„å…¨å±€åˆ†å¸ƒä¸€è‡´æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMyGram åœ¨äº”ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œåœ¨ FBDB15Kã€FBYG15K å’Œ DBP15K æ•°æ®é›†çš„ Hits@1 æŒ‡æ ‡ä¸Šåˆ†åˆ«å®ç°äº†æœ€é«˜ 4.8%ã€9.9% å’Œ 4.3% çš„æå‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11885v1",
      "published_date": "2026-01-17 02:51:42 UTC",
      "updated_date": "2026-01-17 02:51:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:10.584010+00:00"
    },
    {
      "arxiv_id": "2601.11880v1",
      "title": "TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures",
      "title_zh": "TF-CoDiTï¼šåŸºäºæ‰©æ•£ Transformer çš„å›½å€ºæœŸè´§æ¡ä»¶æ—¶é—´åºåˆ—åˆæˆ",
      "authors": [
        "Yingxiao Zhang",
        "Jiaxin Duan",
        "Junfu Zhang",
        "Ke Feng"
      ],
      "abstract": "Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TF-CoDiTï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè¯­è¨€æ§åˆ¶å›½å€ºæœŸè´§ï¼ˆTreasury Futuresï¼‰åˆæˆçš„ Diffusion Transformersï¼ˆDiTï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ­¤ç±»æ•°æ®åœ¨ä½æ ·æœ¬é‡ã€å¸‚åœºä¾èµ–æ€§å’Œå¤šå˜é‡ç›¸å…³æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°† 1D æ—¶é—´åºåˆ—è½¬æ¢ä¸ºç¦»æ•£å°æ³¢å˜æ¢ï¼ˆDiscrete Wavelet Transform, DWTï¼‰ç³»æ•°çŸ©é˜µæ¥è¾…åŠ©ä½æ•°æ®å­¦ä¹ ï¼Œå¹¶åˆ©ç”¨ U-shape VAE åˆ†å±‚ç¼–ç è·¨é€šé“ä¾èµ–å…³ç³»ï¼Œä»è€Œå®ç°æ½œåœ¨æ‰©æ•£ç”Ÿæˆï¼ˆLatent Diffusion Generationï¼‰ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…å¼•å…¥äº†é‡‘èå¸‚åœºå±æ€§åè®®ï¼ˆFinancial Market Attribute Protocol, FinMAPï¼‰ä»¥æ ‡å‡†åŒ–å¸‚åœºåŠ¨æ€çš„æ–‡æœ¬æè¿°ï¼Œä¸ºç”Ÿæˆè¿‡ç¨‹æä¾›ç²¾ç¡®çš„æ¡ä»¶å¼•å¯¼ã€‚å®éªŒè¡¨æ˜ï¼ŒTF-CoDiT åœ¨ 2015 å¹´è‡³ 2025 å¹´çš„å¤šç§æ•°æ®åˆæˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç”Ÿæˆæ•°æ®çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä½è‡³ 0.433ï¼Œä¸”åœ¨ä¸åŒåˆçº¦å’Œæ—¶é—´è·¨åº¦ä¸Šå‡å±•ç°å‡ºå¼ºåŠ²çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11880v1",
      "published_date": "2026-01-17 02:27:56 UTC",
      "updated_date": "2026-01-17 02:27:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:12.913270+00:00"
    },
    {
      "arxiv_id": "2601.11876v1",
      "title": "AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal",
      "title_zh": "ç»¿åœ°äººå·¥æ™ºèƒ½ï¼šåˆ©ç”¨è‡ªä¸»å¯¼èˆªä¸è®¡ç®—æœºè§†è§‰å®ç°å…¬å›­åƒåœ¾æ¸…ç†",
      "authors": [
        "Christopher Kao",
        "Akhil Pathapati",
        "James Davis"
      ],
      "abstract": "There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¬å›­è‰åªåƒåœ¾æ¸…ç†é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤Ÿè‡ªä¸»å¯¼èˆªã€è¯†åˆ«å¹¶æ‹¾å–åƒåœ¾çš„æœºå™¨äººç³»ç»Ÿã€‚ç³»ç»Ÿé‡‡ç”¨ç”Ÿæˆæ ‘è¦†ç›–ç®—æ³•(Spanning Tree Coverage, STC)è§„åˆ’è¦†ç›–è·¯å¾„ï¼Œå¹¶ç»“åˆå®æ—¶åŠ¨æ€å®šä½æŠ€æœ¯(Real-Time Kinematic, RTK) GPSå®ç°äº†å˜ç±³çº§çš„é«˜ç²¾åº¦è·¯å¾„è·Ÿè¸ªã€‚åœ¨è®¡ç®—æœºè§†è§‰æ–¹é¢ï¼Œåˆ©ç”¨ResNet50å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å®ç°äº†94.52%çš„åƒåœ¾æ£€æµ‹å‡†ç¡®ç‡ã€‚ç»“åˆä¸“é—¨è®¾è®¡çš„æ‹¾å–æœºæ„ï¼Œè¯¥æ–¹æ¡ˆæœ€ç»ˆè¾¾åˆ°äº†80%çš„ç»¼åˆæˆåŠŸç‡ï¼Œè¯æ˜äº†åœ¨è‰åœ°ç¯å¢ƒä¸­ä½¿ç”¨è‡ªä¸»æœºå™¨äººè¿›è¡Œåƒåœ¾æ¸…ç†çš„æŠ€æœ¯å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in IEEE/SICE SII 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.11876v1",
      "published_date": "2026-01-17 02:05:05 UTC",
      "updated_date": "2026-01-17 02:05:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:13.015690+00:00"
    },
    {
      "arxiv_id": "2601.11868v1",
      "title": "Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces",
      "title_zh": "Terminal-Benchï¼šé’ˆå¯¹å‘½ä»¤è¡Œç•Œé¢å¤æ‚çœŸå®ä»»åŠ¡çš„æ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•",
      "authors": [
        "Mike A. Merrill",
        "Alexander G. Shaw",
        "Nicholas Carlini",
        "Boxuan Li",
        "Harsh Raj",
        "Ivan Bercovich",
        "Lin Shi",
        "Jeong Yeon Shin",
        "Thomas Walshe",
        "E. Kelly Buchanan",
        "Junhong Shen",
        "Guanghao Ye",
        "Haowei Lin",
        "Jason Poulos",
        "Maoyu Wang",
        "Marianna Nezhurina",
        "Jenia Jitsev",
        "Di Lu",
        "Orfeas Menis Mastromichalakis",
        "Zhiwei Xu",
        "Zizhao Chen",
        "Yue Liu",
        "Robert Zhang",
        "Leon Liangyu Chen",
        "Anurag Kashyap",
        "Jan-Lucas Uslu",
        "Jeffrey Li",
        "Jianbo Wu",
        "Minghao Yan",
        "Song Bian",
        "Vedang Sharma",
        "Ke Sun",
        "Steven Dillmann",
        "Akshay Anand",
        "Andrew Lanpouthakoun",
        "Bardia Koopah",
        "Changran Hu",
        "Etash Guha",
        "Gabriel H. S. Dreiman",
        "Jiacheng Zhu",
        "Karl Krauth",
        "Li Zhong",
        "Niklas Muennighoff",
        "Robert Amanfu",
        "Shangyin Tan",
        "Shreyas Pimpalgaonkar",
        "Tushar Aggarwal",
        "Xiangning Lin",
        "Xin Lan",
        "Xuandong Zhao",
        "Yiqing Liang",
        "Yuanli Wang",
        "Zilong Wang",
        "Changzhi Zhou",
        "David Heineman",
        "Hange Liu",
        "Harsh Trivedi",
        "John Yang",
        "Junhong Lin",
        "Manish Shetty",
        "Michael Yang",
        "Nabil Omi",
        "Negin Raoof",
        "Shanda Li",
        "Terry Yue Zhuo",
        "Wuwei Lin",
        "Yiwei Dai",
        "Yuxin Wang",
        "Wenhao Chai",
        "Shang Zhou",
        "Dariush Wahdany",
        "Ziyu She",
        "Jiaming Hu",
        "Zhikang Dong",
        "Yuxuan Zhu",
        "Sasha Cui",
        "Ahson Saiyed",
        "ArinbjÃ¶rn Kolbeinsson",
        "Jesse Hu",
        "Christopher Michael Rytting",
        "Ryan Marten",
        "Yixin Wang",
        "Alex Dimakis",
        "Andy Konwinski",
        "Ludwig Schmidt"
      ],
      "abstract": "AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at https://www.tbench.ai/ .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Terminal-Bench 2.0ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å‘½ä»¤è¡Œç•Œé¢ (Command Line Interfaces) ä¸­å¤æ‚ä¸”çœŸå®ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºå‡†ç¼ºä¹çœŸå®æ„Ÿæˆ–éš¾åº¦ä¸è¶³ä»¥è¡¡é‡å‰æ²¿æ¨¡å‹çš„é—®é¢˜ã€‚è¯¥åŸºå‡†åŒ…å« 89 ä¸ªæºè‡ªçœŸå®å·¥ä½œæµçš„ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½é…å¤‡äº†ç‹¬ç«‹çš„è¿è¡Œç¯å¢ƒã€äººå·¥ç¼–å†™çš„è§£å†³æ–¹æ¡ˆä»¥åŠå…¨é¢çš„éªŒè¯æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›®å‰çš„å°–ç«¯æ¨¡å‹ (Frontier models) å’Œæ™ºèƒ½ä½“åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„å¾—åˆ†ä½äº 65%ã€‚é€šè¿‡å¯¹é”™è¯¯ç±»å‹çš„æ·±å…¥åˆ†æï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºäº†æ¨¡å‹å’Œæ™ºèƒ½ä½“æœªæ¥æ”¹è¿›çš„å…³é”®é¢†åŸŸï¼Œå¹¶å‘å¸ƒäº†ç›¸å…³æ•°æ®é›†å’Œè¯„ä¼°å¥—ä»¶ä»¥æ”¯æŒåç»­ç ”ç©¶ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11868v1",
      "published_date": "2026-01-17 01:29:30 UTC",
      "updated_date": "2026-01-17 01:29:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:16.280372+00:00"
    },
    {
      "arxiv_id": "2601.11863v1",
      "title": "Utilizing Metadata for Better Retrieval-Augmented Generation",
      "title_zh": "åˆ©ç”¨å…ƒæ•°æ®ä¼˜åŒ–æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Raquib Bin Yousuf",
        "Shengzhe Xu",
        "Mandar Sharma",
        "Andrew Neeser",
        "Chris Latimer",
        "Naren Ramakrishnan"
      ],
      "abstract": "Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.",
      "tldr_zh": "æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†åœ¨Retrieval-Augmented Generation (RAG)ä¸­åˆ©ç”¨å…ƒæ•°æ®ï¼ˆmetadataï¼‰æå‡æ£€ç´¢è´¨é‡çš„æ–¹æ³•ï¼Œç‰¹åˆ«é’ˆå¯¹ç›‘ç®¡æ–‡ä»¶ç­‰å…·æœ‰é«˜åº¦é‡å¤æ€§çš„ç»“æ„åŒ–è¯­æ–™åº“ã€‚ä½œè€…å¯¹æ¯”äº†å°†å…ƒæ•°æ®ä½œä¸ºæ–‡æœ¬å‰ç¼€/åç¼€ã€ç»Ÿä¸€åµŒå…¥ï¼ˆunified embeddingï¼‰ã€åæœŸèåˆæ£€ç´¢ä»¥åŠæŸ¥è¯¢é‡å†™ç­‰å¤šç§ç­–ç•¥ï¼Œå‘ç°å‰ç¼€æ‹¼æ¥å’Œç»Ÿä¸€åµŒå…¥æ–¹æ¡ˆåœ¨æ£€ç´¢æŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ã€‚é€šè¿‡åˆ†æåµŒå…¥ç©ºé—´ï¼Œç ”ç©¶æŒ‡å‡ºå…ƒæ•°æ®çš„åŠ å…¥èƒ½æ˜¾è‘—å¢å¼ºæ–‡æ¡£å†…èšåŠ›ï¼ˆintra-document cohesionï¼‰å¹¶å‡å°‘æ–‡æ¡£é—´æ··æ·†ï¼Œä»è€Œæé«˜æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚è¯¥å·¥ä½œè¿˜é€šè¿‡å­—æ®µæ¶ˆèå®éªŒéªŒè¯äº†ç»“æ„åŒ–ä¿¡æ¯çš„æ¶ˆæ­§ä½œç”¨ï¼Œå¹¶å¼€æºäº†ç›¸å…³ä»£ç å’ŒRAGMATE-10Kæ•°æ®é›†ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "The 48th European Conference on Information Retrieval (ECIR 2026)",
      "pdf_url": "https://arxiv.org/pdf/2601.11863v1",
      "published_date": "2026-01-17 01:11:03 UTC",
      "updated_date": "2026-01-17 01:11:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:25.635270+00:00"
    },
    {
      "arxiv_id": "2601.11859v1",
      "title": "Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization",
      "title_zh": "åŸºäºæ‘Šé”€ä¼˜åŒ–çš„çº§è” Transformerï¼šå®ç°é²æ£’ä¸”å¯æ‰©å±•çš„ SLA åˆ†è§£",
      "authors": [
        "Cyril Shih-Huan Hsu"
      ],
      "abstract": "The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Casformerï¼Œä¸€ç§çº§è” Transformer (cascaded Transformer) æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ 6G ç½‘ç»œåˆ‡ç‰‡ä¸­ç«¯åˆ°ç«¯ (E2E) æœåŠ¡ç­‰çº§åè®® (SLA) åˆ†è§£é¢ä¸´çš„è®¡ç®—å¤æ‚åº¦é«˜å’Œå»¶è¿Ÿå¤§çš„æŒ‘æˆ˜ã€‚è¯¥æ¶æ„é€šè¿‡é¢†åŸŸç‰¹å®šçš„ç¼–ç å™¨æ•´åˆå†å²åé¦ˆï¼Œå¹¶åˆ©ç”¨ Transformer èšåˆå™¨æ•è·è·¨é¢†åŸŸä¾èµ–ï¼Œç»“åˆå—é¢†åŸŸå‘ŠçŸ¥ç¥ç»ç½‘ç»œ (DINNs) å¯å‘çš„æ‘Šé”€ä¼˜åŒ– (amortized optimization) æŠ€æœ¯æ¥å­¦ä¹ ç¨³å®šçš„å‰å‘åˆ†è§£ç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼ŒCasformer åœ¨åˆ†è§£è´¨é‡ã€å¯æ‰©å±•æ€§å’Œç¨³å¥æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„åŸºäºä¼˜åŒ–çš„æ¡†æ¶ï¼Œå°¤å…¶åœ¨åŠ¨è¡å’Œå™ªå£°ç½‘ç»œç¯å¢ƒä¸‹è¡¨ç°å“è¶Šã€‚å…¶å‰å‘æ¨ç†è®¾è®¡æ˜¾è‘—é™ä½äº†è¿è¡Œå¤æ‚åº¦ï¼Œä¸º 5G åŠæœªæ¥ç½‘ç»œç¯å¢ƒä¸­çš„å®æ—¶ SLA ç®¡ç†æä¾›äº†é«˜æ•ˆçš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11859v1",
      "published_date": "2026-01-17 01:01:53 UTC",
      "updated_date": "2026-01-17 01:01:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:25.298857+00:00"
    },
    {
      "arxiv_id": "2601.11854v1",
      "title": "ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System",
      "title_zh": "ATODï¼šé¢å‘æ™ºèƒ½ä½“åŒ–ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶ä¸åŸºå‡†",
      "authors": [
        "Yifei Zhang",
        "Hooshang Nayyeri",
        "Rinat Khaziev",
        "Emine Yilmaz",
        "Gokhan Tur",
        "Dilek Hakkani-TÃ¼r",
        "Hari Thadakamalla"
      ],
      "abstract": "Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ATODï¼Œä¸€ä¸ªä¸“é—¨ç”¨äº Agentic Task-Oriented Dialogue (TOD) ç³»ç»Ÿçš„åŸºå‡†æµ‹è¯•å’Œåˆæˆå¯¹è¯ç”Ÿæˆæµæ°´çº¿ï¼Œæ—¨åœ¨å¡«è¡¥ç°æœ‰åŸºå‡†åœ¨è¯„ä¼°å¤šç›®æ ‡åè°ƒã€ä¸»åŠ¨æ€§å’Œé•¿æœŸæ¨ç†ç­‰ Agentic è¡Œä¸ºæ–¹é¢çš„ç©ºç™½ã€‚åŸºäºæ­¤ï¼Œä½œè€…æ„å»ºäº† ATOD-Eval ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œå°†å¤šç»´åº¦çš„ Agentic ç‰¹æ€§è½¬åŒ–ä¸ºç»†ç²’åº¦æŒ‡æ ‡ï¼Œæ”¯æŒå¯é‡å¤çš„ç¦»çº¿ä¸åœ¨çº¿è¯„ä¼°ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§å¼ºæ•ˆçš„åŸºäºè®°å¿†çš„è¯„ä¼°å™¨ï¼Œå®éªŒè¯æ˜ ATOD-Eval èƒ½å…¨é¢è¡¡é‡ä»»åŠ¡å®Œæˆåº¦åŠæ¨¡å‹èƒ½åŠ›ï¼Œä¸”è¯¥è¯„ä¼°å™¨åœ¨å‡†ç¡®æ€§ä¸æ•ˆç‡çš„å¹³è¡¡ä¸Šä¼˜äºç°æœ‰çš„åŸºäº LLM çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11854v1",
      "published_date": "2026-01-17 00:53:43 UTC",
      "updated_date": "2026-01-17 00:53:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:26.983860+00:00"
    },
    {
      "arxiv_id": "2601.11850v1",
      "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority",
      "title_zh": "äººæœºåä½œå½’çº³å¼ä¸»é¢˜åˆ†æï¼šAI å¼•å¯¼çš„åˆ†æä¸äººç±»çš„é˜é‡Šæƒå¨",
      "authors": [
        "Matthew Nyaaba",
        "Min SungEun",
        "Mary Abiswin Apam",
        "Kwame Owoahene Acheampong",
        "Emmanuel Dwamena",
        "Xiaoming Zhai"
      ],
      "abstract": "The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (GenAI) åœ¨å®šæ€§ç ”ç©¶ä¸­çš„åº”ç”¨ï¼Œå¹¶æå‡ºäº† HACITA (Human-Artificial Intelligence Collaborative Inductive Thematic Analysis) åä½œæ¡†æ¶ã€‚ç ”ç©¶è€…å¼€å‘äº†åä¸º ITA-GPT çš„ä¸“ç”¨å·¥å…·ï¼Œé€šè¿‡ç»“æ„åŒ–æç¤ºæ”¯æŒåæ€æ€§ä¸»é¢˜åˆ†æ (Reflexive Thematic Analysis) å’Œé€å­—ç¼–ç  (Verbatim Coding) ç­‰æµç¨‹ï¼Œå®ç°åŠè‡ªåŠ¨åŒ–çš„å½’çº³ä¸»é¢˜åˆ†æã€‚ç ”ç©¶å‘ç°ï¼ŒITA-GPT ä½œä¸ºç¨‹åºæ€§æ”¯æ¶ (Procedural Scaffold) æœ‰æ•ˆä¼˜åŒ–äº†åˆ†æå·¥ä½œæµå¹¶å¢å¼ºäº†é€æ˜åº¦ä¸å¯å®¡è®¡æ€§ã€‚æœ€ç»ˆç»“æœè¡¨æ˜ï¼Œè™½ç„¶ AI æä¾›äº†å¼ºåŠ›è¾…åŠ©ï¼Œä½†æ ¸å¿ƒçš„è§£é‡Šæƒ (Interpretive Authority) ä»ç”±äººç±»ç ”ç©¶è€…é€šè¿‡æŒç»­çš„åˆ¤æ–­ä¸å¹²é¢„æŒæ¡ï¼Œå±•ç¤ºäº†è´Ÿè´£ä»»çš„äººæœºåä½œæ¨¡å¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11850v1",
      "published_date": "2026-01-17 00:38:36 UTC",
      "updated_date": "2026-01-17 00:38:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:36.641054+00:00"
    },
    {
      "arxiv_id": "2601.11840v1",
      "title": "Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic",
      "title_zh": "Imandra CodeLogicianï¼šé¢å‘è½¯ä»¶é€»è¾‘ç²¾å‡†åˆ†æçš„ç¥ç»ç¬¦å·æ¨ç†",
      "authors": [
        "Hongyu Lin",
        "Samer Abdallah",
        "Makar Valentinov",
        "Paul Brennan",
        "Elijah Kagan",
        "Christoph M. Wintersteiger",
        "Denis Ignatovich",
        "Grant Passmore"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.\n  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.\n  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.\n  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CodeLogicianï¼Œä¸€ç§ç”¨äºç²¾ç¡®åˆ†æè½¯ä»¶é€»è¾‘çš„ neurosymbolic æ™ºèƒ½ä½“ï¼Œæ—¨åœ¨è§£å†³ Large Language Models (LLMs) åœ¨ç¨‹åºè¡Œä¸ºç²¾ç¡®æ•°å­¦æ¨ç†æ–¹é¢çš„å±€é™æ€§ã€‚CodeLogician ä¸å·¥ä¸šçº§è‡ªåŠ¨æ¨ç†å¼•æ“ ImandraX é›†æˆï¼Œåˆ©ç”¨ LLMs æ„å»ºè½¯ä»¶ç³»ç»Ÿçš„æ˜¾å¼å½¢å¼åŒ–æ¨¡å‹ï¼Œä»è€Œå®ç°å¯¹å¤æ‚è¯­ä¹‰é—®é¢˜çš„æ·±åº¦è‡ªåŠ¨åŒ–æ¨ç†ã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥æ¨å‡ºäº† code-logic-bench åŸºå‡†æµ‹è¯•ï¼Œä¸“é—¨è¡¡é‡æ¨¡å‹åœ¨ç¨‹åºçŠ¶æ€ç©ºé—´ã€æ§åˆ¶æµåŠè¾¹ç¼˜æƒ…å†µä¸‹çš„æ¨ç†æ­£ç¡®æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½¢å¼åŒ–å¢å¼ºä½¿æ¨ç†å‡†ç¡®ç‡æå‡äº† 41-47 ä¸ªç™¾åˆ†ç‚¹ï¼Œè¯æ˜äº† neurosymbolic é›†æˆæ˜¯å®ç°ä¸¥è°¨ã€è‡ªä¸»è½¯ä»¶ç†è§£çš„å…³é”®è·¯å¾„ã€‚\n\n---\nå¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦è½¬æ¢ï¼Œæˆ–è€…æƒ³é’ˆå¯¹æœ¬æ–‡çš„ neurosymbolic æ–¹æ³•è¿›è¡Œæ›´æ·±å…¥çš„è®¨è®ºï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "52 pages, 23 figures. Includes a new benchmark dataset (code-logic-bench) and evaluation of neurosymbolic reasoning for software analysis",
      "pdf_url": "https://arxiv.org/pdf/2601.11840v1",
      "published_date": "2026-01-17 00:16:41 UTC",
      "updated_date": "2026-01-17 00:16:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:27:40.848711+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 52,
  "processed_papers_count": 52,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-22T23:28:29.271674+00:00"
}