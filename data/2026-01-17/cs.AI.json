{
  "date": "2026-01-17",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´2026-01-17çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„è®ºæ–‡è´¨é‡å¾ˆé«˜ï¼Œæ ¸å¿ƒèšç„¦åœ¨ **LLM æ¨ç†èƒ½åŠ›çš„æ·±å±‚ä¼˜åŒ–**ï¼ˆå¦‚è§£å†³é•¿æ€ç»´é“¾ä¸­çš„â€œæ€ç»´é™·é˜±â€ã€ä»£ç ç”Ÿæˆçš„ RLVR æœºåˆ¶ï¼‰ä»¥åŠ **Agent åœ¨çœŸå®ç¯å¢ƒä¸­çš„è½åœ°è¯„ä¼°**ï¼ˆCLI æ“ä½œåŸºå‡†ã€å¤šæ™ºèƒ½ä½“ååŒï¼‰ï¼ŒåŒæ—¶è§†è§‰é¢†åŸŸå‡ºç°äº†ç»Ÿä¸€åˆ†å‰²ä¸æŠ å›¾çš„ SAMA æ¨¡å‹ã€‚\n\n---\n\n### ğŸš€ æ ¸å¿ƒå…³æ³¨ï¼šLLM çš„â€œæ€è€ƒâ€ä¸ä»£ç ç”Ÿæˆ\nä»Šå¤©çš„é‡å¤´æˆåœ¨äºå¦‚ä½•è®©å¤§æ¨¡å‹â€œæƒ³â€å¾—æ›´æ¸…æ¥šï¼Œä»¥åŠå¦‚ä½•é€šè¿‡ä»£ç éªŒè¯æ¥æå‡æ¨¡å‹èƒ½åŠ›ã€‚\n\n**1. Aletheiaï¼šä»£ç éªŒè¯å™¨çš„ RLVR æ ¸å¿ƒæœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ**\n**Aletheia: What Makes RLVR For Code Verifiers Tick?**\nè¿™ç¯‡è®ºæ–‡éå¸¸æœ‰ä»·å€¼ã€‚RLVRï¼ˆReinforcement Learning from Verifiable Rewardsï¼‰æ˜¯ç›®å‰åè®­ç»ƒï¼ˆPost-trainingï¼‰é˜¶æ®µçš„çƒ­é—¨æ–¹å‘ã€‚ä½œè€…å¼€æºäº† Aletheia æµ‹è¯•åºŠï¼Œä¸“é—¨ç ”ç©¶ä»£ç ç”Ÿæˆä¸­çš„éªŒè¯å™¨ã€‚\n- **æ ¸å¿ƒå‘ç°**ï¼šè™½ç„¶å¤§å®¶éƒ½è®¤ä¸º execution feedbackï¼ˆæ‰§è¡Œåé¦ˆï¼‰æ˜¯ç‹é“ï¼Œä½†åœ¨å°æ¨¡å‹å°ºå¯¸ä¸‹ï¼Œ**On-policy learning**ï¼ˆåœ¨çº¿ç­–ç•¥å­¦ä¹ ï¼‰æ˜¯å…³é”®ï¼›è€Œåœ¨å¤§æ¨¡å‹å°ºå¯¸ä¸‹ï¼Œ**Thinking-based training**ï¼ˆåŸºäºæ€ç»´é“¾çš„è®­ç»ƒï¼‰åˆ™æˆä¸ºæœ€é‡è¦çš„ç»„ä»¶ã€‚è¿™ä¸ºè®­ç»ƒå¼ºåŠ›çš„ Code Verifier æŒ‡æ˜äº†æ–¹å‘ã€‚\n\n**2. é•¿æ€ç»´é“¾ä¸­çš„æ€ç»´é™·é˜±ï¼šå¯åº¦é‡ç ”ç©¶ä¸é™·é˜±æ„ŸçŸ¥è‡ªé€‚åº”é‡å¯**\n**Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart**\né•¿æ€ç»´é“¾ï¼ˆLong-CoTï¼‰è™½ç„¶å¼ºï¼Œä½†å®¹æ˜“é’»ç‰›è§’å°–ã€‚\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šä½œè€…è¯†åˆ«å‡ºäº†â€œThinking Trapsâ€ï¼ˆæ€ç»´é™·é˜±ï¼‰ï¼Œå³æ¨¡å‹ä¸€æ—¦åœ¨æ—©æœŸçŠ¯é”™ï¼Œåç»­æ— è®ºæ€ä¹ˆè‡ªæˆ‘åæ€éƒ½è·³ä¸å‡ºæ¥çš„æ­»å¾ªç¯ã€‚åœ¨ DAPO-MATH æ•°æ®é›†ä¸Šï¼Œ89% çš„å¤±è´¥éƒ½æºäºæ­¤ã€‚\n- **æ–¹æ³•**ï¼šæå‡ºäº† TAARï¼ˆé™·é˜±æ„ŸçŸ¥è‡ªé€‚åº”é‡å¯ï¼‰ï¼Œèƒ½é¢„æµ‹ä½•æ—¶è¿›å…¥é™·é˜±å¹¶æˆªæ–­è½¨è¿¹ï¼Œè¿›è¡Œè‡ªé€‚åº”é‡å¯æˆ–å¢åŠ æ‰°åŠ¨ï¼Œæ˜¾è‘—æå‡äº†æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚\n\n**3. Imandra CodeLogicianï¼šç”¨äºè½¯ä»¶é€»è¾‘ç²¾ç¡®åˆ†æçš„ç¥ç»ç¬¦å·æ¨ç†**\n**Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic**\nè¿™æ˜¯ä¸€ç¯‡å°† LLM ä¸å½¢å¼åŒ–æ–¹æ³•ï¼ˆFormal Methodsï¼‰ç»“åˆçš„ç¡¬æ ¸æ–‡ç« ã€‚\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ä»…ä»…æ˜¯ç”¨ LLM å†™ä»£ç ï¼Œè€Œæ˜¯ç”¨ LLM æ„å»ºè½¯ä»¶ç³»ç»Ÿçš„æ˜¾å¼å½¢å¼åŒ–æ¨¡å‹ï¼Œç„¶åç”¨å·¥ä¸šçº§æ¨ç†å¼•æ“ ImandraX è¿›è¡Œåˆ†æã€‚è¿™æ¯”å•çº¯ä¾é  LLM æå‡äº† 40%+ çš„æ¨ç†å‡†ç¡®ç‡ï¼Œæ˜¯ Neuro-Symbolic æ–¹å‘çš„é‡è¦è½åœ°ã€‚\n\n---\n\n### ğŸ¤– Agent ä¸åŸºå‡†æµ‹è¯•ï¼šè¿ˆå‘çœŸå®ä¸–ç•Œ\nAgent é¢†åŸŸæ­£åœ¨ä»â€œèƒ½èŠå¤©â€å‘â€œèƒ½å¹²æ´»â€è½¬å˜ï¼Œè¯„ä¼°æ ‡å‡†ä¹Ÿè¶Šæ¥è¶Šç¡¬æ ¸ã€‚\n\n**4. Terminal-Benchï¼šåœ¨å‘½ä»¤è¡Œç•Œé¢ä¸­å¯¹ Agent è¿›è¡Œé«˜éš¾åº¦ã€çœŸå®ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•**\n**Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šç°åœ¨çš„ Agent æµ‹è¯•å¤ªç®€å•äº†ã€‚ä½œè€…æäº†ä¸ª Terminal-Bench 2.0ï¼ŒåŒ…å« 89 ä¸ªåœ¨ Linux ç»ˆç«¯ä¸‹çš„çœŸå®éš¾é¢˜ã€‚\n- **å‘ç°**ï¼šç›®å‰æœ€å‰æ²¿çš„æ¨¡å‹å¾—åˆ†ä¹Ÿä¸åˆ° 65%ï¼Œè¿™æ‰æ˜¯æ£€éªŒ Agent æ˜¯å¦å…·å¤‡â€œé»‘å®¢â€çº§æ“ä½œèƒ½åŠ›çš„è¯•é‡‘çŸ³ã€‚\n\n**5. AEMAï¼šå€¼å¾—ä¿¡èµ–å’Œå¯æ§çš„ Agentic LLM ç³»ç»Ÿçš„å¯éªŒè¯è¯„ä¼°æ¡†æ¶**\n**AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ä¼ä¸šçº§å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæå‡ºäº†ä¸€ä¸ªå¯å®¡è®¡çš„è¯„ä¼°æ¡†æ¶ã€‚ç›¸æ¯”äºå•ä¸€çš„ LLM-as-a-Judgeï¼ŒAEMA å¼ºè°ƒæµç¨‹æ„ŸçŸ¥å’Œäººç±»ç›‘ç£ï¼Œé€‚åˆæƒ³åœ¨ä¸šåŠ¡ä¸­è½åœ° Agent çš„å›¢é˜Ÿå‚è€ƒã€‚\n\n---\n\n### ğŸ‘ï¸ è®¡ç®—æœºè§†è§‰ï¼šå¤§ä¸€ç»Ÿä¸æ•ˆç‡\n\n**6. åœ¨ç»Ÿä¸€æ¨¡å‹ä¸­åˆ†å‰²å’ŒæŠ å›¾ä»»ä½•ç‰©ä½“**\n**Segment and Matte Anything in a Unified Model**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šåŸºäº SAM (Segment Anything) çš„æ”¹è¿›ç‰ˆ SAMAã€‚SAM è™½ç„¶èƒ½åˆ†å‰²ï¼Œä½†è¾¹ç¼˜ç²¾åº¦ä¸å¤Ÿï¼ˆåšä¸åˆ° Matting çº§åˆ«çš„ Alpha é€šé“æŠ å›¾ï¼‰ã€‚SAMA å¼•å…¥äº†å¤šè§†å›¾å®šä½ç¼–ç å™¨ï¼Œåœ¨ä¿æŒè½»é‡çº§çš„åŒæ—¶ï¼Œå®ç°äº†é«˜è´¨é‡çš„åˆ†å‰²å’Œäº¤äº’å¼æŠ å›¾å¤§ä¸€ç»Ÿã€‚\n\n**7. è§†è§‰è¯­è¨€å¤§æ¨¡å‹ä¸­è§†è§‰ Token å‹ç¼©çš„å®‰å…¨éšæ‚£**\n**Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ºäº†æ•ˆç‡ï¼Œå¤§å®¶éƒ½åœ¨å‹ç¼©è§†è§‰ Tokenã€‚ä½†è¿™ç¯‡è®ºæ–‡å‘ç°ï¼Œå‹ç¼©ä¼šç ´åé²æ£’æ€§ã€‚æ”»å‡»è€…åªéœ€å¾®å°çš„æ‰°åŠ¨ï¼Œå°±èƒ½æ”¹å˜ Token çš„é‡è¦æ€§æ’åºï¼Œå¯¼è‡´å…³é”®ä¿¡æ¯è¢«å‹ç¼©æœºåˆ¶ä¸¢å¼ƒã€‚è¿™æ˜¯ä¸€ä¸ªè¢«å¿½è§†çš„æ•ˆç‡-å®‰å…¨æƒè¡¡é—®é¢˜ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€éšç§ä¸æ–°å¥‡æ€è·¯\n\n**8. é’ˆå¯¹è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„å¼ºåŠ›å…è®­ç»ƒæˆå‘˜æ¨ç†æ”»å‡»**\n**Powerful Training-Free Membership Inference Against Autoregressive Language Models**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šéšç§å®¡è®¡æ–°å·¥å…· EZ-MIAã€‚ä½œè€…å‘ç°æ¨¡å‹è®°å¿†ä¸»è¦ä½“ç°åœ¨â€œé”™è¯¯ä½ç½®â€ï¼ˆé¢„æµ‹é”™äº†ï¼Œä½†å¯¹è®­ç»ƒæ ·æœ¬çš„æ¦‚ç‡ä¾ç„¶å¼‚å¸¸é«˜ï¼‰ã€‚åˆ©ç”¨è¿™ä¸ª **Error Zone** åˆ†æ•°ï¼Œæ— éœ€è®­ç»ƒä»»ä½•å‚è€ƒæ¨¡å‹ï¼Œæ”»å‡»æ£€æµ‹ç‡æ¯” SOTA é«˜å‡º 3.8 å€ã€‚\n\n**9. AI çš„æ–°ç­–ç•¥ï¼šç›´æ¥åœ¨äººç±»å¤§è„‘æ•°æ®ä¸Šè®­ç»ƒåŸºç¡€æ¨¡å‹**\n**A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data**\n- **è„‘æ´å¤§å¼€**ï¼šè¿™æ˜¯ä¸€ç¯‡åç†è®ºå’Œå±•æœ›çš„æ–‡ç« ã€‚ä½œè€…è®¤ä¸ºç°åœ¨çš„ LLM åªæ˜¯å­¦åˆ°äº†äººç±»ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆç»“æœï¼‰ï¼Œè€Œæ²¡å­¦åˆ°äº§ç”Ÿæ–‡æœ¬çš„ç¥ç»è¿‡ç¨‹ã€‚æè®®åˆ©ç”¨ç¥ç»å½±åƒæ•°æ®ï¼ˆfMRIç­‰ï¼‰è¿›è¡Œ RLHBï¼ˆåŸºäºäººè„‘çš„å¼ºåŒ–å­¦ä¹ ï¼‰ï¼Œè¯•å›¾ä»¥æ­¤çªç ´ AGI çš„ç“¶é¢ˆã€‚\n\n**10. DriveSafeï¼šå®‰å…¨å…³é”®å‹ LLM é©¾é©¶åŠ©æ‰‹çš„åˆ†å±‚é£é™©åˆ†ç±»å­¦**\n**DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants**\n- **æ ¸å¿ƒè´¡çŒ®**ï¼šLLM è¿›è½¦èˆ±ç”šè‡³è¾…åŠ©é©¾é©¶å¾ˆå±é™©ã€‚ä½œè€…å»ºç«‹äº†ä¸€ä¸ªåŒ…å« 129 ä¸ªç»†ç²’åº¦é£é™©ç±»åˆ«çš„åˆ†ç±»å­¦ã€‚æµ‹è¯•å‘ç°ï¼Œç›®å‰çš„ LLM ç»å¸¸æ— æ³•æ­£ç¡®æ‹’ç»ä¸å®‰å…¨æˆ–éæ³•çš„é©¾é©¶æŒ‡ä»¤ã€‚\n\n---\n\n### ğŸ’¡ å…¶ä»–å€¼å¾—ä¸€çœ‹çš„å°è®ºæ–‡\n\n*   **Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion**\n    (#30 **è¿‡ç¨‹ä¸Šä¸‹æ–‡å­¦ä¹ **)ï¼šä¸ä»…åœ¨å¼€å¤´ç»™ promptï¼Œè€Œæ˜¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€æ’å…¥ç›¸å…³çš„ demonstrationï¼Œè§£å†³æ¨ç†ä¸­é€”çš„å›°æƒ‘ç‚¹ã€‚\n*   **Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty**\n    (#20 **è¯­è¨€æ¨¡å‹ä¸­çš„éƒ¨åˆ†æ¨ç†**)ï¼šç›‘æ§ç”Ÿæˆçš„ç†µï¼ˆEntropyï¼‰ï¼Œä¸€æ—¦ä¸ç¡®å®šå°±åœä¸‹æ¥ï¼Œåœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œæœç´¢å’Œä¿®æ­£ã€‚\n*   **Utilizing Metadata for Better Retrieval-Augmented Generation**\n    (#48 **åˆ©ç”¨å…ƒæ•°æ®æ”¹è¿› RAG**)ï¼šåš RAG çš„æœ‹å‹æ³¨æ„ï¼Œç®€å•çš„æŠŠå…ƒæ•°æ®ï¼ˆMetadataï¼‰å‹æ‰æˆæ–‡æœ¬ä¸ä¸€å®šæ˜¯æœ€å¥½çš„ï¼ŒUnified Embedding æ•ˆæœæ›´å¥½ã€‚\n*   **Large language models struggle with ethnographic text annotation**\n    (#11 **LLM åœ¨æ°‘æ—å¿—æ–‡æœ¬æ ‡æ³¨ä¸­æŒ£æ‰**)ï¼šä¸€ç¯‡â€œæ³¼å†·æ°´â€çš„æ–‡ç« ã€‚åœ¨å¤æ‚çš„äººç±»å­¦/æ°‘æ—å¿—æ–‡æœ¬åˆ†æä¸­ï¼ŒLLM çš„è¡¨ç°è¿œä¸å¦‚äººç±»ä¸“å®¶ï¼Œå°¤å…¶æ˜¯æ¶‰åŠå«ç³Šä¸æ¸…çš„ç¤¾ä¼šæ„å»ºæ—¶ã€‚",
  "papers": [
    {
      "arxiv_id": "2601.12186v1",
      "title": "Aletheia: What Makes RLVR For Code Verifiers Tick?",
      "title_zh": "Aletheiaï¼šæ¢ç©¶ä»£ç éªŒè¯å™¨ RLVR çš„è¿è¡Œæœºåˆ¶",
      "authors": [
        "Vatsal Venkatkrishna",
        "Indraneil Paul",
        "Iryna Gurevych"
      ],
      "abstract": "Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.",
      "tldr_zh": "---\n### è®ºæ–‡æ€»ç»“ ğŸ“\n\næœ¬ç ”ç©¶é€šè¿‡å¼€æºæµ‹è¯•å¹³å° **Aletheia**ï¼Œç³»ç»Ÿåœ°æ¢ç©¶äº†åŸºäºå¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹  (**Reinforcement Learning from Verifiable Rewards, RLVR**) çš„ä»£ç éªŒè¯å™¨æ€§èƒ½ã€‚ç ”ç©¶è€…é‡ç‚¹åˆ†æäº† **RLVR** è®­ç»ƒä¸­çš„ä¸­é—´æ€ç»´é“¾ (**thinking traces**)ã€è´Ÿæ ·æœ¬å­¦ä¹ ä»¥åŠåŒç­–ç•¥ (**on-policy**) è®­ç»ƒç­‰å…³é”®ç»„ä»¶çš„ä½œç”¨ã€‚å®éªŒå‘ç°ï¼Œ**RLVR** åœ¨ä»£ç éªŒè¯æ–¹é¢å…·æœ‰æ˜¾è‘—çš„æœ€ä¼˜æ€§ï¼Œä¸”å±•ç°å‡ºç§¯æçš„è®­ç»ƒå’Œæ¨ç†ç¼©æ”¾æ•ˆåº” (**scaling effects**)ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†è®­ç»ƒé…æ–¹ç®€åŒ–çš„å¯èƒ½æ€§ï¼šåœ¨å°å‹éªŒè¯å™¨ä¸­ï¼ŒåŒç­–ç•¥å­¦ä¹ æ˜¯æ ¸å¿ƒï¼›è€Œåœ¨å¤§å‹éªŒè¯å™¨ä¸­ï¼ŒåŸºäºæ€ç»´ (**thinking-based**) çš„è®­ç»ƒåˆ™ä¸Šå‡ä¸ºæœ€é‡è¦çš„ç»„æˆéƒ¨åˆ†ã€‚\n\n---\nå¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæˆ–è€…æƒ³é’ˆå¯¹è¿™ç¯‡è®ºæ–‡çš„æŸä¸ªç»†èŠ‚æ·±å…¥æ¢è®¨ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12186v1",
      "published_date": "2026-01-17 22:30:45 UTC",
      "updated_date": "2026-01-17 22:30:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:49:02.683087+00:00"
    },
    {
      "arxiv_id": "2601.12150v1",
      "title": "Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models",
      "title_zh": "It looks like you've shared a compelling abstract for a paper focused on optimizing inference for pathology foundation models. This work addresses a critical bottleneck in digital pathology: the gap between the fixed input sizes of foundation models and the massive scale of whole-slide images (WSIs).\n\n---\n\n### Key Summary of the Research ğŸ”¬\n\n| Feature | Details |\n|---|---|\n| **Core Problem** | Pathology models are often limited to small input sizes (e.g., 224x224), whereas WSIs are massive. Scaling leads to high GPU memory usage, while downsampling loses morphological detail. |\n| **Proposed Solution** | A space- and time-efficient inference strategy that uses **spatially aware neighboring blocks** to sparsify attention and **global attention scores** to filter out non-informative tokens. |\n| **Performance Gains** | Up to **7.67% improvement** in ROI classification and compatible results in segmentation tasks. |\n| **Efficiency Impact** | Significant reduction in GPU memory consumption and runtime, allowing for higher-resolution inference within the same hardware constraints. |\n\n---\n\n### How can I help you with this paper? ğŸ§\n\nThis seems like a significant step forward for applying large-scale vision transformers to medical imaging. Would you like me to:\n\n*   **Deep Dive:** Explore the specific technical implications of \"spatially aware neighboring blocks\"?\n*   **Drafting:** Help you write a summary, a blog post, or a presentation based on this abstract?\n*   **Comparison:** Compare these findings with other sparse attention mechanisms like Longformer or BigBird?\n\nLet me know how you'd like to proceed!",
      "authors": [
        "Mengxuan Hu",
        "Zihan Guan",
        "John Kang",
        "Sheng Li",
        "Zhongliang Zhou"
      ],
      "abstract": "Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.",
      "tldr_zh": "It is a pleasure to analyze this recent research for you. The paper, **\"Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models,\"** addresses a critical bottleneck in digital pathology: the gap between the massive scale of Whole-Slide Images (WSIs) and the limited input capacity of modern AI foundation models.\n\nI have summarized the core components and findings of the study below.\n\n---\n\n### Research Overview ğŸ§¬\n\nThis study focuses on optimizing how foundation models handle high-resolution pathology images without exhausting GPU resources or sacrificing morphological detail.\n\n| Category | Details |\n|---|---|\n| **Core Problem** | Foundation models are often \"locked\" to small input sizes (e.g., 224x224). Applying them to WSIs requires either memory-heavy enlarging or detail-blurring downsampling. |\n| **Proposed Solution** | A space- and time-efficient inference strategy using **sparsified attention** and **token filtering**. |\n| **Primary Goal** | To enable high-resolution inference within existing GPU memory budgets while improving diagnostic accuracy. |\n\n---\n\n### Comparison of Inference Strategies ğŸš€\n\nThe paper highlights the limitations of traditional methods compared to their proposed \"Spatially Aware\" approach.\n\n| Strategy | Mechanism | Main Drawback / Advantage |\n|---|---|---|\n| **Naive Enlarging** | Increasing input resolution directly. | Leads to prohibitive GPU memory consumption. |\n| **Downsampling** | Reducing image resolution to fit input size. | Obscures critical morphological details and alters MPP (microns-per-pixel). |\n| **Proposed Strategy** | Sparsifies attention via neighboring blocks and filters non-informative tokens. | **Reduces GPU memory/runtime** while preserving high-resolution details. |\n\n---\n\n### Key Experimental Results ğŸ“Š\n\nThe efficiency of this new inference strategy does not just save resources; it actually improves the model's ability to interpret pathological features.\n\n| Metric | Improvement / Outcome |\n|---|---|\n| **ROI Classification** | Up to **7.67% improvement** in performance. |\n| **Segmentation Task** | Achieved compatible (stable) results compared to standard methods. |\n| **GPU Efficiency** | Significant reduction in memory usage and total runtime during WSI inference. |\n\n---\n\n### How can Gemini Enterprise assist you further? ğŸ’¡\n\nThis research is particularly relevant if you are working with Vision Transformers (ViT) or DINO-based architectures in a clinical setting. Would you like me to:\n\n*   **Deep Dive into Methodology?** I can explain the \"spatially aware neighboring blocks\" or the \"global attention scores\" in more detail.\n*   **Compare with Other Models?** We could look at how this compares to other pathology models like Virchow or GigaPath.\n*   **Draft a Summary?** I can help you condense this into a presentation slide or a brief for a research group.\n\nWhat would be most helpful for your current project?",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.12150v1",
      "published_date": "2026-01-17 19:50:40 UTC",
      "updated_date": "2026-01-17 19:50:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:49:14.522935+00:00"
    },
    {
      "arxiv_id": "2601.12147v1",
      "title": "Segment and Matte Anything in a Unified Model",
      "title_zh": "### Summary of \"Segment and Matte Anything in a Unified Model\" ğŸ“„\n\nI've reviewed the abstract for the paper you provided. It introduces **SAMA (Segment And Matte Anything)**, a new model designed to improve upon the Segment Anything Model (SAM) by adding high-quality matting capabilities and refining segmentation boundaries.\n\n| Feature | Description |\n|---|---|\n| **Core Model** | **SAMA** (Segment And Matte Anything), a lightweight extension of SAM. |\n| **Primary Goal** | To provide high-quality interactive image segmentation and matting within a single, unified framework. |\n| **Key Innovation 1** | **Multi-View Localization Encoder (MVLE)**: Captures detailed features from local views to improve precision. |\n| **Key Innovation 2** | **Localization Adapter (Local-Adapter)**: Refines mask outputs by recovering subtle boundary details. |\n| **Dual Heads** | Includes two prediction heads to generate both segmentation and matting masks simultaneously. |\n| **Performance** | Achieves state-of-the-art results across multiple benchmarks, demonstrating strong zero-shot generalization. |\n\n---\n\n### How can I help you with this paper? ğŸ¤”\n\nI can assist you further with this research. Would you like me to:\n\n*   **Deepen the technical explanation** of the MVLE or Local-Adapter?\n*   **Compare SAMA** to other segmentation models like the original SAM or HQ-SAM?\n*   **Discuss potential use cases** for a unified segmentation and matting model?\n\nLet me know what you're interested in!",
      "authors": [
        "Zezhong Fan",
        "Xiaohan Li",
        "Topojoy Biswas",
        "Kaushiki Nag",
        "Kannan Achan"
      ],
      "abstract": "Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.",
      "tldr_zh": "---\n\n### è®ºæ–‡æ€»ç»“ ğŸ“\n\nè¯¥ç ”ç©¶æå‡ºäº† **SAMA** (**Segment And Matte Anything**)ï¼Œè¿™æ˜¯ **Segment Anything (SAM)** çš„ä¸€ç§è½»é‡çº§æ‰©å±•æ¡†æ¶ï¼Œæ—¨åœ¨å°†é«˜è´¨é‡çš„äº¤äº’å¼å›¾åƒåˆ†å‰²ï¼ˆsegmentationï¼‰ä¸å›¾åƒæŠ å›¾ï¼ˆmattingï¼‰ç»Ÿä¸€åœ¨å•ä¸ªæ¨¡å‹ä¸­ã€‚ä¸ºäº†è§£å†³ **SAM** åœ¨è¾¹ç•Œç²¾åº¦ä¸Šçš„ä¸è¶³ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº† **Multi-View Localization Encoder (MVLE)** ä»¥æ•æ‰å±€éƒ¨ç»†èŠ‚ï¼Œå¹¶ç»“åˆ **Localization Adapter** æ¢å¤ç²¾ç»†çš„è¾¹ç¼˜ç‰¹å¾ã€‚**SAMA** åœ¨æ¶æ„ä¸­é›†æˆäº†ä¸¤ä¸ªä¸“é—¨çš„é¢„æµ‹å¤´ï¼Œèƒ½å¤Ÿæ ¹æ®å¤šæ ·åŒ–çš„ç”¨æˆ·æç¤ºåŒæ­¥ç”Ÿæˆåˆ†å‰²æ©ç å’Œ **alpha mattes**ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œ**SAMA** åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº† **State-of-the-art (SOTA)** æ°´å¹³ï¼Œåœ¨ä»…å¢åŠ æå°‘å‚æ•°çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡äº†å¤æ‚åœºæ™¯ä¸‹çš„å¤„ç†èƒ½åŠ›ã€‚\n\n---\nè¿™é¡¹ç ”ç©¶åœ¨æå‡ **SAM** å®ç”¨æ€§æ–¹é¢éå¸¸æœ‰æ„ä¹‰ã€‚å¦‚æœæ‚¨éœ€è¦å¯¹æ¯” SAMA ä¸å…¶ä»–åˆ†å‰²æ¨¡å‹ï¼ˆå¦‚ HQ-SAMï¼‰çš„å·®å¼‚ï¼Œæˆ–è€…æƒ³äº†è§£å…¶ä»£ç å®ç°ç»†èŠ‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12147v1",
      "published_date": "2026-01-17 19:43:10 UTC",
      "updated_date": "2026-01-17 19:43:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:49:08.482734+00:00"
    },
    {
      "arxiv_id": "2601.12141v1",
      "title": "TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals",
      "title_zh": "This is another fascinating paper, this time focusing on automated planning and robotics. TIDE seems to offer a clever bridge between complex temporal logic and practical, off-the-shelf planning tools.\n\n---\n\n### Paper Overview: TIDE ğŸ¤–\n\n| Category | Description |\n|---|---|\n| **Title** | TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals |\n| **Focus Area** | Task Planning with Temporally Extended Goals (TEGs) using $LTL_{f}$ (Linear Temporal Logic on finite traces). |\n| **The Gap** | Existing methods often convert temporal goals into classical reachability goals but lack the heuristics needed to guide the search effectively toward temporal objectives. |\n| **The Innovation** | **TIDE** decomposes the complex problem into a sequence of smaller \"reach-avoid\" sub-problems and uses automaton traces to guide the search. |\n\n---\n\n### Technical Highlights ğŸ› ï¸\n\n| Component | Functionality |\n|---|---|\n| **Problem Decomposition** | Breaks down a large temporal goal into manageable sub-tasks that standard planners can solve. |\n| **Heuristic Guidance** | Prioritizes \"promising\" traces within the domain graph using cost-driven metrics. |\n| **Adaptive Backtracking** | If a plan fails, the system penalizes that specific infeasible transition and recalculates costs to find a new path, ensuring completeness. |\n| **Performance** | Demonstrates competitive results and serves as a robust addition to the current portfolio of planning methods. |\n\n---\n\n### Connecting the Dots ğŸ”—\n\nYou've now shared two papers that both deal with **optimization and efficiency** in complex domains:\n1.  **Pathology:** Optimizing high-resolution inference by sparsifying attention.\n2.  **Robotics/Planning:** Optimizing temporal goal reaching by decomposing tasks and using trace-informed heuristics.\n\nAre you compiling a literature review on efficient AI strategies, or perhaps looking for commonalities in how these different fields handle \"scaling\" problems? I'd be happy to help you compare the heuristic approaches used in both, or even help draft a synthesis of these abstracts!",
      "authors": [
        "Yuliia Suprun",
        "Khen Elimelech",
        "Lydia E. Kavraki",
        "Moshe Y. Vardi"
      ],
      "abstract": "Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.",
      "tldr_zh": "---\n### è®ºæ–‡æ€»ç»“ ğŸ“\n\nè¯¥ç ”ç©¶æå‡ºäº† **TIDE**ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å¸¦æœ‰æ—¶åºæ‰©å±•ç›®æ ‡ (**Temporally Extended Goals, TEGs**) çš„ä»»åŠ¡è§„åˆ’æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†æœ‰é™è½¨è¿¹ä¸Šçš„çº¿æ€§æ—¶åºé€»è¾‘ (**LTLf**) æ—¶ç¼ºä¹å¯å‘å¼å¼•å¯¼çš„é—®é¢˜ã€‚**TIDE** å°†å¤æ‚çš„æ—¶åºé—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—è§„æ¨¡æ›´å°ã€æ˜“äºç®¡ç†çš„ **reach-avoid** å­é—®é¢˜ï¼Œå¹¶åˆ©ç”¨ç°æˆçš„è§„åˆ’å™¨è¿›è¡Œåˆ†æ®µæ±‚è§£ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨åŸŸå›¾ (**domain graph**) ä¸­è¯†åˆ«å¹¶ä¼˜å…ˆå¤„ç†æœ‰æ½œåŠ›çš„è‡ªåŠ¨æœºè½¨è¿¹ (**automaton traces**)ï¼Œç»“åˆæˆæœ¬é©±åŠ¨çš„å¯å‘å¼ç®—æ³•æ¥ç²¾å‡†å¼•å¯¼æœç´¢ã€‚æ­¤å¤–ï¼Œå…¶è‡ªé€‚åº”å›æº¯æœºåˆ¶èƒ½é€šè¿‡é‡æ–°è®¡ç®—æˆæœ¬å’Œæƒ©ç½šä¸å¯è¡Œè½¬æ¢æ¥ä»å¤±è´¥ä¸­æ¢å¤ï¼Œç¡®ä¿äº†è§„åˆ’çš„å®Œå¤‡æ€§ä¸æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ**TIDE** åœ¨æ€§èƒ½ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¸º **TEGs** è§„åˆ’é¢†åŸŸæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è¡¥å……ã€‚\n\n---\nå¦‚æœæ‚¨å¯¹ **TIDE** çš„å…·ä½“å¯å‘å¼ç®—æ³•æˆ– **LTLf** çš„åº”ç”¨æ„Ÿå…´è¶£ï¼Œæˆ–è€…è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12141v1",
      "published_date": "2026-01-17 19:07:03 UTC",
      "updated_date": "2026-01-17 19:07:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:49:49.108203+00:00"
    },
    {
      "arxiv_id": "2601.12138v1",
      "title": "DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants",
      "title_zh": "DriveSafeï¼šé¢å‘å®‰å…¨å…³é”®å‹å¤§è¯­è¨€æ¨¡å‹é©¾é©¶åŠ©æ‰‹çš„å±‚çº§åŒ–é£é™©åˆ†ç±»ä½“ç³»",
      "authors": [
        "Abhishek Kumar",
        "Riya Tapwal",
        "Carsten Maple"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DriveSafeï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å®‰å…¨å…³é”®å‹ (Safety-Critical) é©¾é©¶åŠ©æ‰‹çš„å››çº§åˆ†å±‚é£é™©åˆ†ç±»ä½“ç³» (Taxonomy)ï¼Œæ—¨åœ¨ç³»ç»ŸåŒ–åœ°è¡¨å¾åŸºäº LLM çš„è½¦è½½åŠ©æ‰‹å¯èƒ½å‡ºç°çš„å¤±è´¥æ¨¡å¼ã€‚è¯¥ä½“ç³»åŒ…å« 129 ä¸ªç»†ç²’åº¦çš„åŸå­é£é™©ç±»åˆ«ï¼Œæ¶µç›–äº†æŠ€æœ¯ã€æ³•å¾‹ã€ç¤¾ä¼šå’Œä¼¦ç†å››å¤§ç»´åº¦ï¼Œå¹¶ä»¥ç°å®ä¸–ç•Œçš„é©¾é©¶æ³•è§„å’Œå®‰å…¨åŸåˆ™ä¸ºåŸºç¡€ã€‚é€šè¿‡å¯¹å…­ç§ä¸»æµ LLMs çš„æ‹’ç»è¡Œä¸º (Refusal Behavior) è¿›è¡Œè¯„ä¼°ï¼Œç ”ç©¶å‘ç°ç°æœ‰æ¨¡å‹åœ¨é¢å¯¹ä¸å®‰å…¨æˆ–è¿è§„çš„é©¾é©¶æŸ¥è¯¢æ—¶ï¼Œå¾€å¾€æ— æ³•åšå‡ºé€‚å½“çš„æ‹’ç»å¤„ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šç”¨çš„å®‰å…¨å¯¹é½æŠ€æœ¯åœ¨å¤æ‚çš„é©¾é©¶åœºæ™¯ä¸­å­˜åœ¨å±€é™æ€§ï¼Œå‡¸æ˜¾äº†å»ºç«‹ç‰¹å®šé¢†åŸŸå®‰å…¨è¯„ä¼°æ¡†æ¶çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12138v1",
      "published_date": "2026-01-17 18:50:47 UTC",
      "updated_date": "2026-01-17 18:50:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:50:17.538877+00:00"
    },
    {
      "arxiv_id": "2601.12134v1",
      "title": "Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning",
      "title_zh": "It is a pleasure to meet you. I am **Gemini Enterprise**, and I have reviewed the research details you shared regarding **Human-Human-AI (HHAI) Triadic Programming**. \n\nThis study presents a fascinating shift in how we view AIâ€”not as a solo replacement for human interaction, but as a third \"partner\" that can actually enhance the collaborative learning process.\n\n---\n\n### Research Overview ğŸ“‘\n\n| Aspect | Description |\n|---|---|\n| **Core Concept** | **HHAI Triadic Programming**: A collaborative setup where an AI agent acts as a third collaborator alongside two human partners. |\n| **Methodology** | A within-subjects study involving 20 participants comparing HHAI triadic collaboration against human-AI (HAI) dyadic baselines. |\n| **Primary Findings** | Triadic collaboration leads to higher social presence and better collaborative learning outcomes compared to working with AI alone. |\n| **Human Dynamics** | Participants in triadic settings showed a higher sense of responsibility and were less likely to blindly accept AI code without understanding it. |\n\n---\n\n### Significance of the Study ğŸ’¡\n\nThe most striking insight from your abstract is the **Socially Shared Regulation of Learning (SSRL)**. It appears that when a human peer is present, the use of AI becomes \"visible and accountable.\" \n\nEssentially, having a human partner prevents the \"autopilot\" mode often seen in solo AI use, forcing learners to critically evaluate AI suggestions before implementation. This suggests that the best way to integrate AI into education is to design systems that **augment peer collaboration** rather than replace it.\n\n---\n\n### How can I help you further? ğŸ¤\n\nI would love to discuss this paper more deeply with you. Are you looking to:\n\n*   **Deepen the Analysis:** Should I explore the specific differences between the \"HHAI-shared\" condition and other settings?\n*   **Draft Content:** Would you like help drafting a presentation, a blog post, or a critique based on this abstract?\n*   **Brainstorm:** Are you looking for similar research areas or practical applications for this triadic model in a classroom or workplace?\n\nLet me know what you're thinking!",
      "authors": [
        "Taufiq Daryanto",
        "Xiaohan Ding",
        "Kaike Ping",
        "Lance T. Wilhelm",
        "Yan Chen",
        "Chris Brown",
        "Eugenia H. Rho"
      ],
      "abstract": "As AI assistance becomes embedded in programming practice, researchers have increasingly examined how these systems help learners generate code and work more efficiently. However, these studies often position AI as a replacement for human collaboration and overlook the social and learning-oriented aspects that emerge in collaborative programming. Our work introduces human-human-AI (HHAI) triadic programming, where an AI agent serves as an additional collaborator rather than a substitute for a human partner. Through a within-subjects study with 20 participants, we show that triadic collaboration enhances collaborative learning and social presence compared to the dyadic human-AI (HAI) baseline. In the triadic HHAI conditions, participants relied significantly less on AI-generated code in their work. This effect was strongest in the HHAI-shared condition, where participants had an increased sense of responsibility to understand AI suggestions before applying them. These findings demonstrate how triadic settings activate socially shared regulation of learning by making AI use visible and accountable to a human peer, suggesting that AI systems that augment rather than automate peer collaboration can better preserve the learning processes that collaborative programming relies on.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†â€œäºº-äºº-AIâ€(HHAI) ä¸‰å…ƒç¼–ç¨‹æ¨¡å¼ï¼Œå°† AI æ™ºèƒ½ä½“å®šä½ä¸ºäººç±»åä½œä¼™ä¼´çš„è¡¥å……è€Œéæ›¿ä»£è€…ï¼Œæ—¨åœ¨æ¢ç©¶å…¶åœ¨åä½œå­¦ä¹ ä¸­çš„ä»·å€¼ã€‚é€šè¿‡å¯¹ 20 åå‚ä¸è€…çš„å¯¹æ¯”ç ”ç©¶å‘ç°ï¼Œä¸â€œäºº-AIâ€(HAI) äºŒå…ƒæ¨¡å¼ç›¸æ¯”ï¼ŒHHAI æ˜¾è‘—å¢å¼ºäº†åä½œå­¦ä¹ æ•ˆæœå’Œç¤¾äº¤å­˜åœ¨æ„Ÿ (Social Presence)ã€‚åœ¨ä¸‰å…ƒåä½œç¯å¢ƒä¸‹ï¼Œå‚ä¸è€…å¯¹ AI ç”Ÿæˆä»£ç çš„ä¾èµ–ç¨‹åº¦æ˜¾è‘—é™ä½ï¼Œå°¤å…¶åœ¨å…±äº«æ¨¡å¼ä¸‹ï¼Œäººç±»ä¼™ä¼´åœ¨åº”ç”¨ AI å»ºè®®å‰ä¼šè¡¨ç°å‡ºæ›´å¼ºçš„ç†è§£è´£ä»»æ„Ÿã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸‰å…ƒè®¾ç½®é€šè¿‡æ¿€å‘å­¦ä¹ çš„ç¤¾ä¼šå…±äº«è°ƒèŠ‚ (Socially Shared Regulation of Learning)ï¼Œä½¿ AI çš„ä½¿ç”¨è¿‡ç¨‹æ›´åŠ é€æ˜ä¸”å¯è¿½è´£ï¼Œå¼ºè°ƒäº† AI åº”é€šè¿‡è¾…åŠ©è€Œéè‡ªåŠ¨åŒ–åŒä¼´åä½œæ¥ä¿æŠ¤æ ¸å¿ƒå­¦ä¹ è¿‡ç¨‹ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12134v1",
      "published_date": "2026-01-17 18:32:54 UTC",
      "updated_date": "2026-01-17 18:32:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:50:25.771954+00:00"
    },
    {
      "arxiv_id": "2601.12132v1",
      "title": "Bengali Text Classification: An Evaluation of Large Language Model Approaches",
      "title_zh": "å­ŸåŠ æ‹‰è¯­æ–‡æœ¬åˆ†ç±»ï¼šå¤§è¯­è¨€æ¨¡å‹æ–¹æ³•çš„è¯„ä¼°",
      "authors": [
        "Md Mahmudul Hoque",
        "Md Mehedi Hassain",
        "Md Hojaifa Tanvir",
        "Rahul Nandy"
      ],
      "abstract": "Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the \"Sports\" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å­ŸåŠ æ‹‰è¯­æ–‡æœ¬åˆ†ç±» (Bengali text classification) ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæ—¨åœ¨è§£å†³è¯¥è¯­è¨€åœ¨è‡ªç„¶è¯­è¨€å¤„ç† (NLP) é¢†åŸŸé¢ä¸´çš„æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹åŒ®ä¹çš„æŒ‘æˆ˜ã€‚ç ”ç©¶è€…é‡‡ç”¨æ¥è‡ªå­ŸåŠ æ‹‰å›½ä¸»æµæŠ¥çº¸ *Prothom Alo* çš„æ–°é—»æ•°æ®é›†ï¼Œå¯¹æ¯”åˆ†æäº† LLaMA 3.1 8B Instructã€LLaMA 3.2 3B Instruct å’Œ Qwen 2.5 7B Instruct ä¸‰ç§æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQwen 2.5 å–å¾—äº† 72% çš„æœ€é«˜åˆ†ç±»å‡†ç¡®ç‡ï¼Œåœ¨â€œä½“è‚²â€ç±»åˆ«è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œè€Œ LLaMA ç³»åˆ—æ¨¡å‹çš„å‡†ç¡®ç‡åˆ™åœ¨ 53% è‡³ 56% ä¹‹é—´ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å³ä½¿åœ¨èµ„æºç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼ŒLLMs åœ¨å­ŸåŠ æ‹‰è¯­æ–‡æœ¬å¤„ç†ä¸­ä»å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå¹¶ä¸ºæœªæ¥è§£å†³ç±»åˆ«å¤±è¡¡å’Œå¾®è°ƒä¼˜åŒ–å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12132v1",
      "published_date": "2026-01-17 18:25:19 UTC",
      "updated_date": "2026-01-17 18:25:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:50:51.757228+00:00"
    },
    {
      "arxiv_id": "2601.12126v1",
      "title": "UniMo: Unified Motion Generation and Understanding with Chain of Thought",
      "title_zh": "That sounds like a fascinating paper! It seems to address some of the most persistent challenges in 3D human motion modeling by bridging the gap between generation and understanding through reasoning.\n\nI have summarized the key aspects of the **UniMo** framework based on the title and abstract you provided.\n\n---\n\n### ğŸ“„ Paper Overview\n\n| Feature | Details |\n|---|---|\n| **Title** | UniMo: Unified Motion Generation and Understanding with Chain of Thought |\n| **Primary Goal** | To create a unified, interpretable framework for both generating and understanding 3D human motion. |\n| **Core Methodology** | Integrating motion-language data with Chain of Thought (CoT) reasoning using Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). |\n| **Key Performance** | Achieved State-of-the-Art (SOTA) results, outperforming both unified and task-specific models. |\n\n---\n\n### ğŸ’¡ Challenges & Solutions\n\nI've outlined the specific problems the authors identified and how UniMo aims to solve them:\n\n| Challenge | UniMo's Solution |\n|---|---|\n| **Limited Interpretability** | Introduces **Chain of Thought (CoT)** reasoning into the LLM, making the connection between motion and language more explicit. |\n| **Semantic Alignment Issues** | Leverages linguistic priors through **Supervised Fine-Tuning (SFT)** to better align motion sequences with textual descriptions. |\n| **Cumulative Prediction Errors** | Employs **Group Relative Policy Optimization (GRPO)** as a post-training strategy to optimize groups of tokens rather than single next-tokens. |\n| **Task Incoherence** | Establishes a **Unified Framework** that allows generation and understanding tasks to mutually enhance one another. |\n\n---\n\nThis framework's use of **GRPO**â€”the same reinforcement learning algorithm used in models like DeepSeek-R1â€”to enforce structural correctness in motion tokens is particularly interesting.\n\nWould you like me to dive deeper into how **Chain of Thought** is applied to motion sequences, or perhaps explain the **GRPO** optimization process in this context? I'm here to help you analyze this further!",
      "authors": [
        "Guocun Wang",
        "Kenkun Liu",
        "Jing Lin",
        "Guorui Song",
        "Jian Li",
        "Xiaoguang Han"
      ],
      "abstract": "Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† UniMo æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ 3D äººä½“è¿åŠ¨ç”Ÿæˆä¸ç†è§£ä¸­å¯è§£é‡Šæ€§ä¸è¶³åŠå¤§è¯­è¨€æ¨¡å‹ (LLM) é¢„æµ‹è¯¯å·®ç´¯ç§¯çš„é—®é¢˜ã€‚é€šè¿‡æœ‰ç›‘ç£å¾®è°ƒ (SFT)ï¼ŒUniMo å°†è¿åŠ¨è¯­è¨€ä¿¡æ¯ä¸å¯è§£é‡Šçš„é“¾å¼æ€ç»´ (Chain of Thought, CoT) æ¨ç†é›†æˆåˆ°æ¨¡å‹ä¸­ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ– (Group Relative Policy Optimization, GRPO) çš„å¼ºåŒ–å­¦ä¹ åè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä¼˜åŒ–æ ‡è®°ç»„æ¥å¢å¼ºç»“æ„æ­£ç¡®æ€§å’Œè¯­ä¹‰å¯¹é½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUniMo åœ¨ç”Ÿæˆå’Œç†è§£ä»»åŠ¡ä¸Šå‡å–å¾—äº† SOTA æ€§èƒ½ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„ç»Ÿä¸€æ¡†æ¶åŠç‰¹å®šä»»åŠ¡æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12126v1",
      "published_date": "2026-01-17 17:56:49 UTC",
      "updated_date": "2026-01-17 17:56:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:50:26.518812+00:00"
    },
    {
      "arxiv_id": "2601.12124v1",
      "title": "SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data",
      "title_zh": "SynQPï¼šåˆæˆæ•°æ®è´¨é‡ä¸éšç§é£é™©è¯„ä¼°æ¡†æ¶åŠæŒ‡æ ‡",
      "authors": [
        "Bing Hu",
        "Yixin Li",
        "Asma Bahamyirou",
        "Helen Chen"
      ],
      "abstract": "The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \\(\\ge0.97\\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† **SynQP**ï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°åˆæˆæ•°æ®ç”Ÿæˆ (**Synthetic Data Generation, SDG**) è´¨é‡å’Œéšç§é£é™©çš„å¼€æºæ¡†æ¶ã€‚ä¸ºäº†è§£å†³è·å–æ•æ„Ÿæ•°æ®è¿›è¡Œéšç§å®¡è®¡çš„éš¾é¢˜ï¼Œ**SynQP** é‡‡ç”¨æ¨¡æ‹Ÿæ•æ„Ÿæ•°æ®è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œç¡®ä¿åŸå§‹æ•°æ®çš„æœºå¯†æ€§ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„ **identity disclosure risk** åº¦é‡æŒ‡æ ‡ï¼Œæ—¨åœ¨æ¯”ç°æœ‰æ–¹æ³•æ›´å‡†ç¡®åœ°æ ¸ç®—æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ¦‚ç‡ç‰¹æ€§ã€‚å®éªŒé€šè¿‡å¯¹ **CTGAN** çš„è¯„ä¼°è¯æ˜ï¼Œåº”ç”¨ **Differential Privacy (DP)** èƒ½æ˜¾è‘—é™ä½ **SD-IDR** å’Œ **SD-MIA** é£é™©è‡³ç›‘ç®¡é˜ˆå€¼ä»¥ä¸‹ï¼ŒåŒæ—¶ä¿æŒæé«˜çš„æœºå™¨å­¦ä¹ æ•ˆèƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 Pages, 22nd Annual International Conference on Privacy, Security, and Trust (PST2025), Fredericton, Canada",
      "pdf_url": "https://arxiv.org/pdf/2601.12124v1",
      "published_date": "2026-01-17 17:51:14 UTC",
      "updated_date": "2026-01-17 17:51:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:51:03.454790+00:00"
    },
    {
      "arxiv_id": "2601.12104v1",
      "title": "Powerful Training-Free Membership Inference Against Autoregressive Language Models",
      "title_zh": "é’ˆå¯¹è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆå…è®­ç»ƒæˆå‘˜æ¨ç†",
      "authors": [
        "David IliÄ‡",
        "David StanojeviÄ‡",
        "Kostadin Cvejoski"
      ],
      "abstract": "Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **EZ-MIA**ï¼Œä¸€ç§é’ˆå¯¹å¾®è°ƒè‡ªå›å½’è¯­è¨€æ¨¡å‹çš„æ— éœ€è®­ç»ƒï¼ˆTraining-Freeï¼‰çš„æˆå‘˜æ¨ç†æ”»å‡»ï¼ˆ**Membership Inference Attacks, MIAs**ï¼‰æ¡†æ¶ã€‚ç ”ç©¶å‘ç°æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†åŒ–åœ¨â€œé”™è¯¯ä½ç½®â€ï¼ˆå³é¢„æµ‹é”™è¯¯ä½†æ¦‚ç‡å¼‚å¸¸å‡é«˜çš„ tokenï¼‰è¡¨ç°æœ€å¼ºï¼Œæ®æ­¤å¼•å…¥äº† **Error Zone (EZ) score** æ¥è¡¡é‡ç›¸å¯¹äºé¢„è®­ç»ƒå‚è€ƒæ¨¡å‹çš„æ¦‚ç‡åç§»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç›¸åŒæ¡ä»¶ä¸‹ï¼Œ**EZ-MIA** åœ¨ **WikiText** å’Œ **GPT-2** ä¸Šçš„æ£€æµ‹ç‡æ¯”ç°æœ‰æŠ€æœ¯é«˜å‡º 3.8 å€ï¼Œå¹¶åœ¨ **Llama-2-7B** ç­‰å¤§æ¨¡å‹ä¸Šä¿æŒäº†æ˜¾è‘—ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å¾®è°ƒè¯­è¨€æ¨¡å‹çš„éšç§é£é™©è¿œæ¯”æ­¤å‰è®¤ä¸ºçš„æ›´ä¸¥é‡ï¼Œä¸ºéšç§å®¡è®¡å’Œæ¨¡å‹éƒ¨ç½²å†³ç­–æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures; appendix with additional experiments and derivations",
      "pdf_url": "https://arxiv.org/pdf/2601.12104v1",
      "published_date": "2026-01-17 16:59:41 UTC",
      "updated_date": "2026-01-17 16:59:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:51:27.420676+00:00"
    },
    {
      "arxiv_id": "2601.12099v1",
      "title": "Large language models struggle with ethnographic text annotation",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹éš¾ä»¥èƒœä»»æ°‘æ—å¿—æ–‡æœ¬æ ‡æ³¨",
      "authors": [
        "Leonardo S. Goodall",
        "Dor Shilton",
        "Daniel A. Mullins",
        "Harvey Whitehouse"
      ],
      "abstract": "Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.",
      "tldr_zh": "I, Gemini Enterprise, have analyzed the research paper you provided regarding the limitations of Large Language Models (LLMs) in the field of ethnographic text annotation. Below is a structured summary of the study's findings and implications.\n\n---\n\n### ğŸ“š Study Overview\n\n| Aspect | Details |\n|---|---|\n| **Core Objective** | To evaluate if state-of-the-art LLMs can replace human experts in extracting structured data from ethnographic texts. |\n| **Scope** | 7 different LLMs tested on 121 ritual features across 567 ethnographic excerpts. |\n| **Primary Conclusion** | Current LLMs struggle to meet the reliability standards necessary for automated cross-cultural research and cannot yet substitute human expertise. |\n\n---\n\n### ğŸ” Performance Analysis\n\n| Metric | Observation |\n|---|---|\n| **Overall Accuracy** | Performance remained significantly below the thresholds required for reliable scientific research. |\n| **Human vs. LLM** | Human inter-coder reliability acted as a \"ceiling\"; however, even on tasks where humans agreed perfectly, LLMs still underperformed. |\n| **Task Difficulty** | If a feature was difficult for a human coder to categorize, the LLMs consistently found it difficult as well. |\n\n---\n\n### ğŸš§ Identified Bottlenecks\n\nThe study highlighted specific factors that hindered the models' ability to annotate text effectively:\n\n| Challenge | Impact on LLM Reliability |\n|---|---|\n| **Text Length** | Accuracy decreased as the length of the ethnographic excerpts increased. |\n| **Ordinal Distinctions** | Models struggled significantly with features requiring ranked or scaled classifications rather than simple binary ones. |\n| **Ambiguity** | Concepts that were theoretically ambiguous or required deep cultural context proved particularly difficult for the AI to process. |\n\n---\n\n### ğŸ“ Final Verdict\n\nThe research suggests that while LLMs are progressing, they lack the nuanced understanding required for complex ethnographic work. Human expertise remains the gold standard for high-fidelity data extraction in cross-cultural studies.\n\nWould you like me to dive deeper into any specific model mentioned in the study, or perhaps you'd like to discuss the implications for future automated research? I'm here to help!",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12099v1",
      "published_date": "2026-01-17 16:39:07 UTC",
      "updated_date": "2026-01-17 16:39:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:29.462458+00:00"
    },
    {
      "arxiv_id": "2601.12095v1",
      "title": "Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding",
      "title_zh": "ç¥ç»åŒæ„åŸŸï¼šåŸºäº Transformer çš„ä»£æ•°æ•°å€¼åµŒå…¥",
      "authors": [
        "Hamidreza Sadeghi",
        "Saeedeh Momtazi",
        "Reza Safabakhsh"
      ],
      "abstract": "Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.",
      "tldr_zh": "Hello! I am **Gemini Enterpriseâœ¨**. It looks like you've shared a very recent and fascinating paper from the intersection of abstract algebra and deep learning. This work, titled ***Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding***, was recently submitted to arXiv (January 2026) and addresses a fundamental limitation in how neural networks handle numerical data.\n\nHere is a summary and breakdown of the key insights from the abstract you provided:\n\n---\n\n### ğŸ§  The Core Problem: Numerical Instability\n\nTraditional neural networks often struggle with \"extreme\" numbersâ€”values that are either very large or infinitesimally small. This leads to several well-known issues in machine learning:\n*   **Overflow and Underflow:** Computational limits of standard floating-point representations.\n*   **Unstable Output:** Small variations in input causing unpredictable spikes or drops in output.\n*   **Loss of Algebraic Meaning:** Models often treat numbers as simple features rather than elements belonging to a mathematical field with specific rules (like $a + b = b + a$).\n\n---\n\n### ğŸ§¬ The Proposed Solution: Neural Isomorphic Fields (NIF)\n\nThe authors, **Hamidreza Sadeghi**, **Saeedeh Momtazi**, and **Reza Safabakhsh**, propose a \"Neural Isomorphic Field.\" Instead of feeding raw numbers into a model, they convert them into **fixed-length embedding vectors**. \n\nThese embeddings are designed to be \"isomorphic\" to the field of rational numbers, meaning the vectors themselves are meant to mirror the behavior of the numbers they represent during operations like addition and multiplication.\n\n---\n\n### ğŸ“Š Experimental Results\n\nThe model's ability to preserve algebraic properties (such as closure, identity, and associativity) varies significantly depending on the operation:\n\n| Operation | Accuracy Range | Performance Note |\n|---|---|---|\n| **Addition** | **> 95%** | Exceptional performance across identity, closure, and associativity. |\n| **Multiplication** | **53% - 73%** | Significant challenges remaining; identified as a primary area for future improvement. |\n| **Comparison** | *Supported* | The abstract mentions comparison is preserved, though specific percentages for this were not detailed in the summary. |\n\n---\n\n### ğŸš€ Why This Matters\n\nThis research is a step toward making AI models more \"mathematically literate.\" By ensuring that embeddings respect algebraic structures, we could see more robust performance in scientific computing, financial modeling, and any domain where precise numerical relationships are critical.\n\n**I'm curious about your interest in this!** Are you looking into how to implement these types of embeddings in a specific project, or are you more interested in the theoretical side of \"Neural Abstractions\" of algebraic structures? I'd love to dive deeper into the technical details with you!",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12095v1",
      "published_date": "2026-01-17 16:25:52 UTC",
      "updated_date": "2026-01-17 16:25:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:09.706622+00:00"
    },
    {
      "arxiv_id": "2601.12082v1",
      "title": "Conditional Random Fields for Interactive Refinement of Histopathological Predictions",
      "title_zh": "ç”¨äºç»„ç»‡ç—…ç†å­¦é¢„æµ‹äº¤äº’å¼ä¼˜åŒ–çš„æ¡ä»¶éšæœºåœº",
      "authors": [
        "Tiffanie Godelaine",
        "Maxime Zanella",
        "Karim El Khoury",
        "SaÃ¯d Mahmoudi",
        "BenoÃ®t Macq",
        "Christophe De Vleeschouwer"
      ],
      "abstract": "Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.",
      "tldr_zh": "# Overview of HistoCRF ğŸ”¬\n\nIt looks like you've shared the abstract for an interesting paper titled **\"Conditional Random Fields for Interactive Refinement of Histopathological Predictions.\"** This research focuses on improving the accuracy of cancer detection and staging by refining predictions from Vision-Language Models (VLMs) using a novel framework called **HistoCRF**.\n\n---\n\n### Core Methodology ğŸ› ï¸\n\nI've summarized the primary approach and innovations of HistoCRF in the table below:\n\n| Feature | Description |\n|---|---|\n| **Base Model** | Utilizes zero-shot predictions from Vision-Language Models (VLMs). |\n| **Refinement Tool** | Adapts Conditional Random Fields (CRFs) specifically for histology. |\n| **Pairwise Potential** | A novel definition that promotes label diversity and leverages expert input. |\n| **Human-in-the-Loop** | Supports iterative annotations to progressively correct misclassified patches. |\n| **Training Requirement** | Requires no additional model training, making it highly efficient. |\n\n---\n\n### Experimental Performance ğŸ“ˆ\n\nThe paper demonstrates significant accuracy improvements across five datasets covering various organs and diseases:\n\n| Scenario | Accuracy Gain (vs. Zero-Shot) |\n|---|---|\n| **Without Annotations** | +16.0% |\n| **With 100 Expert Annotations** | +27.5% |\n| **Human-in-the-Loop (100 Annotations)** | +32.6% |\n\n---\n\n### How can I help you with this? ğŸ¤”\n\nWould you like me to dive deeper into any specific part of this paper? I can assist with:\n*   Explaining what **Conditional Random Fields (CRFs)** are in this context.\n*   Discussing how **Vision-Language Models** are typically applied to pathology.\n*   Analyzing the benefits of the **human-in-the-loop** approach for clinical workflows.\n*   Summarizing specific sections if you provide more text.\n\nWhat are you looking to do next with this information?",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12082v1",
      "published_date": "2026-01-17 15:19:40 UTC",
      "updated_date": "2026-01-17 15:19:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:51:58.847255+00:00"
    },
    {
      "arxiv_id": "2601.12068v1",
      "title": "Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset",
      "title_zh": "å¼¥åˆå­ŸåŠ æ‹‰è¯­åŒ»ç–—å·®è·ï¼šåŸºäºç—‡çŠ¶-ç–¾ç—…æ•°æ®é›†çš„æœºå™¨å­¦ä¹ ç–¾ç—…é¢„æµ‹",
      "authors": [
        "Rowzatul Zannat",
        "Abdullah Al Shafi",
        "Abdul Muntakim"
      ],
      "abstract": "Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.",
      "tldr_zh": "### Research Paper Overview ğŸ”¬\n\nThat sounds like a significant contribution to localized health informatics! I've analyzed the title and abstract of your research paper. Here is a summary of the key components:\n\n---\n\n### Study Summary\n\n| Feature | Details |\n|---|---|\n| **Research Title** | Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset |\n| **Primary Goal** | Enhancing equitable access to health information for Bangla-speaking populations through automated disease prediction. |\n| **Dataset Scope** | 758 unique symptom-disease relationships covering 85 different diseases. |\n| **Core Methodology** | Evaluation of multiple Machine Learning models, including Soft and Hard Voting Ensemble approaches. |\n| **Top Performance** | Achieved **98\\% accuracy** using ensemble methods. |\n| **Primary Impact** | Early disease detection and providing a foundational, publicly available resource for Bangla health informatics. |\n\n---\n\n### Key Contributions ğŸŒŸ\n\n*   **Language Accessibility:** Addresses the critical shortage of healthcare resources for the non-English-speaking Bengali community.\n*   **Dataset Transparency:** By making the dataset publicly available, you are ensuring reproducibility and fostering further research in the field.\n*   **Model Robustness:** The use of ensemble techniques suggests a focus on generalization, which is crucial for real-world diagnostic applications.\n\n---\n\n### How can I assist you further? ğŸ¤\n\nI'm Gemini Enterprise, and I can help you with several next steps for this research. Would you like me to:\n\n1.  **Generate a detailed summary** of specific sections if you provide more text?\n2.  **Draft a conclusion** or discussion section based on these findings?\n3.  **Suggest potential journals** or conferences where this work might be a good fit?\n4.  **Create a presentation outline** for this paper?\n\nWhat's on your mind?",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12068v1",
      "published_date": "2026-01-17 14:33:01 UTC",
      "updated_date": "2026-01-17 14:33:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:29.697336+00:00"
    },
    {
      "arxiv_id": "2601.12061v1",
      "title": "Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation",
      "title_zh": "é¢å‘å¤šè¯è¯­ç»“æ„æ ‡æ³¨çš„ä»£ç ç°¿æ³¨å…¥å¼å¯¹è¯åˆ†å‰²ï¼šå¤§è¯­è¨€æ¨¡å‹è¾…åŠ©ä¸æ— é‡‘æ ‡å‡†è¯„ä¼°",
      "authors": [
        "Jinsook Lee",
        "Kirk Vanacore",
        "Zhuqian Zhou",
        "Jeanine Grutter",
        "Rene F. Kizilcec"
      ],
      "abstract": "Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.",
      "tldr_zh": "# Analysis of Codebook-Injected Dialogue Segmentation ğŸ“\n\nI've analyzed the second abstract you provided for the paper titled **\"Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation.\"** \n\nThis research addresses a common bottleneck in natural language processing: the difficulty of defining where one \"action\" ends and another begins in a conversation, especially when multiple sentences (utterances) make up a single intent.\n\n---\n\n### Core Innovation: Codebook-Injected Segmentation ğŸ’¡\n\nThe researchers propose a shift from purely text-based segmentation to \"DA-aware\" (Dialogue Act-aware) segmentation.\n\n| Feature | Description |\n|---|---|\n| **The Problem** | Annotators often agree on *what* is being said (intent) but disagree on *where* the segment starts or ends, lowering reliability scores. |\n| **The Solution** | **Codebook-Injected Segmentation**: Training or prompting models to find boundaries based on the specific definitions (codebook) of the dialogue acts being studied. |\n| **New Metrics** | Introduced evaluation methods that don't require \"gold labels\" (human-perfect answers), focusing on span consistency, distinctiveness, and human-AI distributional agreement. |\n\n---\n\n### Key Findings & Trade-offs âš–ï¸\n\nThe study reveals that there is no \"silver bullet\" for dialogue segmentation, as different models excel in different areas:\n\n*   **LLM Strengths:** Large Language Models (LLMs) are excellent at creating segments that are internally consistent with the \"constructs\" or intents they are supposed to represent.\n*   **Coherence Baselines:** Older, coherence-based methods are still better at identifying \"global shifts\"â€”the big moments where the topic or flow of the conversation changes entirely.\n*   **The Trade-off:** The authors found that making a segment more \"coherent\" often makes it less \"distinct\" from the segments around it. They argue that segmentation should be optimized based on the **downstream goal** rather than a single accuracy score.\n\n---\n\n### Comparison of the Two Papers ğŸ”„\n\nIt's interesting that both papers you've shared focus on **refining AI predictions**â€”one in the medical imaging field (HistoCRF) and this one in linguistic analysis. Both suggest that \"zero-shot\" or standard model outputs aren't quite enough for expert-level tasks and require specific structural \"injections\" (CRFs for histology vs. Codebooks for dialogue).\n\nAre you researching how LLMs can be better integrated into expert workflows, or are you looking for a comparison of these different refinement techniques? I'm happy to help you synthesize these findings! ğŸ’¬",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review for ACL 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12061v1",
      "published_date": "2026-01-17 14:17:13 UTC",
      "updated_date": "2026-01-17 14:17:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:21.505886+00:00"
    },
    {
      "arxiv_id": "2601.12055v1",
      "title": "Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer",
      "title_zh": "é€šè¿‡ç›¸ä¼¼æ€§å‚æ•°è¿ç§»å®ç°è§å…‰æ˜¾å¾®å›¾åƒå»å™ªä¸­æ·±åº¦å›¾åƒå…ˆéªŒçš„è‡ªåŠ¨åŒ–å‚æ•°é€‰æ‹©",
      "authors": [
        "Lina Meyer",
        "Felix Wissel",
        "Tobias Knopp",
        "Susanne Pfefferle",
        "Ralf Fliegert",
        "Maximilian Sandmann",
        "Liana Uebler",
        "Franziska MÃ¶ckl",
        "BjÃ¶rn-Philipp Diercks",
        "David Lohr",
        "RenÃ© Werner"
      ],
      "abstract": "Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.",
      "tldr_zh": "---\n\n### ğŸ“ è®ºæ–‡æ€»ç»“ï¼šAUTO-DIP\n\nè¯¥ç ”ç©¶é’ˆå¯¹æ— ç›‘ç£ **Deep Image Prior (DIP)** åœ¨è§å…‰æ˜¾å¾®å›¾åƒå»å™ªä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå³æ¯å¼ å›¾åƒéƒ½éœ€è¦è€—æ—¶ä¼˜åŒ–ç½‘ç»œæ¶æ„å’Œè¿­ä»£åœæ­¢ç‚¹ï¼ˆstopping pointï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº† **AUTO-DIP** è‡ªåŠ¨å‚æ•°è¿ç§»æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŸºäºâ€œç›¸ä¼¼å›¾åƒå…±äº«ç›¸ä¼¼æœ€ä¼˜å‚æ•°é…ç½®â€çš„å‡è®¾ï¼Œé€šè¿‡ **Similarity-Based Parameter Transfer** å®ç°æ— éœ€é‡å¤ä¼˜åŒ–çš„å‚æ•°é€‰æ‹©ã€‚\n\nç ”ç©¶å‘ç°ï¼Œä»…åŸºäºå›¾åƒå…ƒæ•°æ®ï¼ˆ**metadata**ï¼Œå¦‚æ˜¾å¾®é•œç±»å‹ã€æˆåƒæ ‡æœ¬ï¼‰çš„ç›¸ä¼¼æ€§å‡†åˆ™åœ¨å‚æ•°è¿ç§»æ•ˆæœä¸Šä¼˜äºå®šé‡çš„å›¾åƒç›¸ä¼¼åº¦åº¦é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œ**AUTO-DIP** åœ¨å¤šä¸ªå¼€æºåŠæœ¬åœ°æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºåŸºçº¿ DIP å’Œä¼ ç»Ÿçš„å˜åˆ†å»å™ªï¼ˆ**variational denoising**ï¼‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤„ç†æé«˜å™ªå£°çš„è¾“å…¥æ—¶å±•ç°å‡ºæ˜¾è‘—çš„ä¼˜è¶Šæ€§ï¼Œä¸ºé«˜æ•ˆå¤„ç†å¤§è§„æ¨¡æ˜¾å¾®å›¾åƒæ•°æ®æä¾›äº†å¯èƒ½ã€‚\n\n---\n\nå¦‚æœä½ è¿˜æœ‰å…¶ä»–å…³äºè¿™ç¯‡è®ºæ–‡çš„å…·ä½“ç»†èŠ‚éœ€è¦æ·±å…¥äº†è§£ï¼Œæˆ–è€…æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12055v1",
      "published_date": "2026-01-17 13:47:41 UTC",
      "updated_date": "2026-01-17 13:47:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:26.750591+00:00"
    },
    {
      "arxiv_id": "2601.12053v1",
      "title": "A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data",
      "title_zh": "äººå·¥æ™ºèƒ½æ–°ç­–ç•¥ï¼šç›´æ¥åˆ©ç”¨äººè„‘æ•°æ®è®­ç»ƒåŸºç¡€æ¨¡å‹",
      "authors": [
        "MaÃ«l Donoso"
      ],
      "abstract": "While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. However, this data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. In this paper, we explore a new strategy for artificial intelligence: moving beyond surface-level statistical regularities by training foundation models directly on human brain data. We hypothesize that neuroimaging data could open a window into elements of human cognition that are not accessible through observable actions, and argue that this additional knowledge could be used, alongside classical training data, to overcome some of the current limitations of foundation models. While previous research has demonstrated the possibility to train classical machine learning or deep learning models on neural patterns, this path remains largely unexplored for high-level cognitive functions. Here, we classify the current limitations of foundation models, as well as the promising brain regions and cognitive processes that could be leveraged to address them, along four levels: perception, valuation, execution, and integration. Then, we propose two methods that could be implemented to prioritize the use of limited neuroimaging data for strategically chosen, high-value steps in foundation model training: reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB). We also discuss the potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities. We argue that brain-trained foundation models could represent a realistic and effective middle ground between continuing to scale current architectures and exploring alternative, neuroscience-inspired solutions.",
      "tldr_zh": "---\n\n### ğŸ“ è®ºæ–‡æ€»ç»“ï¼šåŸºäºäººç±»å¤§è„‘æ•°æ®çš„åŸºç¡€æ¨¡å‹è®­ç»ƒæ–°ç­–ç•¥\n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§äººå·¥æ™ºèƒ½çš„æ–°ç­–ç•¥ï¼Œä¸»å¼ è¶…è¶Šæ–‡æœ¬ç­‰è¡¨é¢ç»Ÿè®¡è§„å¾‹ï¼Œç›´æ¥åˆ©ç”¨äººç±»å¤§è„‘æ•°æ®ï¼ˆNeuroimaging dataï¼‰æ¥è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelsï¼‰ï¼Œä»¥æ•æ‰æ— æ³•é€šè¿‡è§‚å¯Ÿè¡Œä¸ºè·å–çš„æ·±å±‚ç¥ç»å¤æ‚æ€§ä¸äººç±»è®¤çŸ¥è¦ç´ ã€‚è®ºæ–‡ä»æ„ŸçŸ¥ï¼ˆPerceptionï¼‰ã€è¯„ä»·ï¼ˆValuationï¼‰ã€æ‰§è¡Œï¼ˆExecutionï¼‰å’Œæ•´åˆï¼ˆIntegrationï¼‰å››ä¸ªå±‚çº§ç³»ç»Ÿåœ°åˆ†æäº†å¯ç”¨äºè§£å†³å½“å‰æ¨¡å‹å±€é™æ€§çš„è„‘åŒºåŠè®¤çŸ¥è¿‡ç¨‹ã€‚\n\nä¸ºäº†é«˜æ•ˆåˆ©ç”¨ç¨€ç¼ºçš„ç¥ç»å½±åƒæ•°æ®ï¼Œä½œè€…æå‡ºäº†ä¸¤ç§å…·ä½“çš„å®æ–½æ–¹æ¡ˆï¼š**ä»äººç±»å¤§è„‘è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLHBï¼‰**ä»¥åŠ**ä»äººç±»å¤§è„‘è¿›è¡Œé“¾å¼æ€ç»´ï¼ˆCoTHBï¼‰**ã€‚è¯¥ç­–ç•¥è¢«è®¤ä¸ºæ˜¯åœ¨å•çº¯æ‰©å¤§ç°æœ‰æ¶æ„è§„æ¨¡ä¸æ¢ç´¢æ›¿ä»£æ€§ç¥ç»ç§‘å­¦æ–¹æ¡ˆä¹‹é—´çš„ä¸€ä¸ªåŠ¡å®ä¸”æœ‰æ•ˆçš„å¹³è¡¡ç‚¹ï¼Œä¸ºé€šå¾€é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰å’Œè¶…äººå·¥æ™ºèƒ½ï¼ˆASIï¼‰æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚\n\n---\n\nè¿™ç§å°†ç¥ç»ç§‘å­¦ä¸å¤§æ¨¡å‹ç»“åˆçš„æ€è·¯éå¸¸å‰å«ã€‚ä½ å¯¹å…¶ä¸­æåˆ°çš„ **RLHB** æˆ– **CoTHB** å“ªç§æ–¹æ³•æ›´æ„Ÿå…´è¶£ï¼Ÿæˆ–è€…éœ€è¦æˆ‘ä¸ºä½ è¯¦ç»†è§£é‡Šæ–‡ä¸­æåˆ°çš„å››ä¸ªè®¤çŸ¥å±‚çº§å—ï¼Ÿ",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12053v1",
      "published_date": "2026-01-17 13:38:51 UTC",
      "updated_date": "2026-01-17 13:38:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:40.220852+00:00"
    },
    {
      "arxiv_id": "2601.12049v1",
      "title": "\\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions",
      "title_zh": "FocaLogicï¼šåŸºäºé€»è¾‘çš„è§†è§‰æ¨¡å‹å†³ç­–è§£é‡Š",
      "authors": [
        "Chenchen Zhao",
        "Muxi Chen",
        "Qiang Xu"
      ],
      "abstract": "Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.",
      "tldr_zh": "---\n\n### ğŸ“ è®ºæ–‡æ€»ç»“ï¼šFocaLogic\n\nè¯¥ç ”ç©¶æå‡ºäº† **FocaLogic**ï¼Œè¿™æ˜¯ä¸€ä¸ª model-agnosticï¼ˆæ¨¡å‹æ— å…³ï¼‰çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åŸºäºé€»è¾‘çš„è¡¨ç¤ºæ¥è§£é‡Šå’Œé‡åŒ–è§†è§‰æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶é€šè¿‡è¯†åˆ«å¯¹æ¨¡å‹é¢„æµ‹èµ·å†³å®šæ€§ä½œç”¨çš„æœ€å°è§†è§‰åŒºåŸŸå­é›†ï¼ˆç§°ä¸º **visual focuses**ï¼‰ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç²¾ç¡®ä¸”ç®€æ´çš„é€»è¾‘è¡¨è¾¾å¼ï¼Œä»è€Œæä¾›é€æ˜ä¸”ç»“æ„åŒ–çš„è§£é‡Šã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜æå‡ºäº†ä¸€å¥—å®šé‡æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ **focus precision**ã€**recall** å’Œ **divergence**ï¼Œç”¨äºå®¢è§‚è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡Œä¸ºã€‚å®éªŒè¡¨æ˜ï¼ŒFocaLogic èƒ½å¤Ÿæ­ç¤ºæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ³¨æ„åŠ›é›†ä¸­è¶‹åŠ¿ã€æ³›åŒ–è¿‡ç¨‹ä¸­çš„å‡†ç¡®æ€§æå‡ï¼Œä»¥åŠåœ¨åè§å’Œ **adversarial attacks**ï¼ˆå¯¹æŠ—æ”»å‡»ï¼‰ä¸‹çš„å¼‚å¸¸ç„¦ç‚¹ï¼Œä¸ºè§†è§‰æ¨¡å‹æä¾›äº†ä¸€ç§ç³»ç»ŸåŒ–ä¸”å¯æ‰©å±•çš„å®šé‡è§£é‡Šæ–¹æ¡ˆã€‚\n\n---\n\nå¦‚æœä½ éœ€è¦å¯¹è¯¥æ¡†æ¶çš„ç‰¹å®šå®šé‡æŒ‡æ ‡ï¼ˆå¦‚ **divergence**ï¼‰è¿›è¡Œæ›´æ·±å…¥çš„æ¢è®¨ï¼Œæˆ–è€…æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12049v1",
      "published_date": "2026-01-17 13:28:02 UTC",
      "updated_date": "2026-01-17 13:28:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:45.450672+00:00"
    },
    {
      "arxiv_id": "2601.12042v1",
      "title": "Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models",
      "title_zh": "å°‘å³æ˜¯å¤šâ€”â€”ç›´è‡³å´©æºƒï¼šå¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ä¸­è§†è§‰ Token å‹ç¼©çš„å®‰å…¨éšæ‚£",
      "authors": [
        "Xiaomei Zhang",
        "Zhaoxi Zhang",
        "Leo Yu Zhang",
        "Yanjun Zhang",
        "Guanhong Tao",
        "Shirui Pan"
      ],
      "abstract": "Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.",
      "tldr_zh": "---\n\n### ğŸ“ è®ºæ–‡æ€»ç»“ï¼šè§†è§‰æ ‡è®°å‹ç¼©åœ¨ LVLMs ä¸­çš„å®‰å…¨æ€§é™·é˜±\n\nè¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰æ ‡è®°å‹ç¼© (**Visual token compression**) åœ¨å¤§è§†è§‰è¯­è¨€æ¨¡å‹ (**LVLMs**) ä¸­å¸¦æ¥çš„å®‰å…¨æ€§æŒ‘æˆ˜ï¼Œå‘ç°è™½ç„¶å‹ç¼©èƒ½æ˜¾è‘—æå‡æ¨ç†æ•ˆç‡ï¼Œä½†ä¼šä¸¥é‡æŸå®³æ¨¡å‹çš„é²æ£’æ€§ã€‚ä½œè€…æ­ç¤ºäº†ä¸€ç§â€œçŠ¶æ€ç‰¹å®šâ€çš„éšè”½æ¼æ´ï¼šåŸæœ¬è¡¨ç°ç¨³å¥çš„æ¨¡å‹åœ¨å¯ç”¨å‹ç¼©åä¼šå˜å¾—æå…¶è„†å¼±ï¼Œä¸”è¿™ç§å¤±è´¥æ¨¡å¼åœ¨ç¦ç”¨å‹ç¼©æ—¶ä¼šå®Œå…¨æ¶ˆå¤±ã€‚\n\né€šè¿‡åˆ†æå‘ç°ï¼Œå‹ç¼©è¿‡ç¨‹ä¸­æ ‡è®°é‡è¦æ€§æ’åº (**token importance ranking**) çš„ä¸ç¨³å®šæ€§æ˜¯å¯¼è‡´é²æ£’æ€§ä¸‹é™çš„æ ¸å¿ƒåŸå› ï¼Œå¾®å°çš„æ‰°åŠ¨å³å¯è¯¯å¯¼å‹ç¼©æœºåˆ¶ä¸¢å¼ƒä»»åŠ¡å…³é”®ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†å‹ç¼©æ„ŸçŸ¥æ”»å‡» (**Compression-Aware Attack, CAA**) åŠå…¶é»‘ç›’ç‰ˆæœ¬ **Transfer CAA**ï¼Œç”¨ä»¥ç³»ç»Ÿåœ°æ¢æµ‹å¹¶åˆ©ç”¨è¯¥æ¼æ´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„é˜²å¾¡æ‰‹æ®µä¿æŠ¤æ•ˆæœæœ‰é™ï¼Œæ­ç¤ºäº† **LVLMs** åœ¨æ•ˆç‡ä¸å®‰å…¨æ€§ä¹‹é—´å­˜åœ¨æ­¤å‰è¢«å¿½è§†çš„æƒè¡¡ (**trade-off**)ã€‚\n\n---\n\nè¿™é¡¹ç ”ç©¶æé†’æˆ‘ä»¬åœ¨è¿½æ±‚æ¨¡å‹è½»é‡åŒ–çš„åŒæ—¶ï¼Œä¸èƒ½å¿½è§†å…¶æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚ä½ æ˜¯å¦æ­£åœ¨ç ”ç©¶ LVLMs çš„æ•ˆç‡ä¼˜åŒ–æˆ–å®‰å…¨æ€§ç›¸å…³çš„è¯¾é¢˜ï¼Ÿ",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12042v1",
      "published_date": "2026-01-17 13:02:41 UTC",
      "updated_date": "2026-01-17 13:02:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:52:56.808610+00:00"
    },
    {
      "arxiv_id": "2601.12040v1",
      "title": "Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty",
      "title_zh": "è¯­è¨€æ¨¡å‹ä¸­çš„å±€éƒ¨æ¨ç†ï¼šä¸ç¡®å®šæ€§å¼•å¯¼çš„æœç´¢ä¸ç²¾ç‚¼",
      "authors": [
        "Murilo da Luz",
        "Bruno BrandÃ£o",
        "Luana Martins",
        "Gustavo Oliveira",
        "Bryan de Oliveira",
        "Luckeciano Melo",
        "Telma Soares"
      ],
      "abstract": "The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.",
      "tldr_zh": "---\n\n### ğŸ“ è®ºæ–‡æ€»ç»“ï¼šPREGU â€”â€” åŸºäºä¸ç¡®å®šæ€§å¼•å¯¼çš„éƒ¨åˆ†æ¨ç†\n\nè¯¥ç ”ç©¶æå‡ºäº† **PREGU** (**Partial Reasoning Guided by Uncertainty**)ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦å’Œé€»è¾‘æ¨ç†ç­‰å¤šæ­¥æ¨æ–­ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚**PREGU** é€šè¿‡åœ¨è‡ªåŠ¨å›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­ç›‘æ§è¾“å‡ºåˆ†å¸ƒçš„ **entropy**ï¼ˆç†µï¼‰æ¥è¯†åˆ«æ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œä¸€æ—¦ **entropy** è¶…è¿‡é¢„è®¾é˜ˆå€¼ï¼Œæ¨¡å‹å°†æš‚åœç”Ÿæˆã€‚éšåï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ **Soft Reasoning** æŠ€æœ¯åœ¨æ½œç©ºé—´ä¸­è¿›è¡Œå±€éƒ¨æœç´¢ï¼Œå¯¹å·²ç”Ÿæˆçš„éƒ¨åˆ†æ¨ç†å†…å®¹è¿›è¡Œç²¾ç‚¼å’Œä¿®æ­£ã€‚\n\nåœ¨ **GSM8K**ã€**SVAMP** å’Œ **StrategyQA** ç­‰åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼Œ**PREGU** çš„æ€§èƒ½ä¼˜äºæˆ–æŒå¹³äºå®Œæ•´çš„ **Soft Reasoning** æ–¹æ³•ï¼Œè¿™è¯æ˜äº† **entropy** å¯ä»¥ä½œä¸ºè§¦å‘é€‰æ‹©æ€§ç²¾ç‚¼ï¼ˆselective refinementï¼‰çš„æœ‰æ•ˆä¿¡å·ã€‚\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œå¾ˆé«˜å…´èƒ½ä¸ºæ‚¨æ€»ç»“è¿™ç¯‡å…³äºæ¨¡å‹æ¨ç†ä¼˜åŒ–ç ”ç©¶ã€‚å¦‚æœæ‚¨æƒ³æ·±å…¥äº†è§£ **Soft Reasoning** çš„å…·ä½“å®ç°ï¼Œæˆ–è€…å¯¹å®éªŒä¸­ä½¿ç”¨çš„å…¶ä»–åŸºå‡†æµ‹è¯•æ„Ÿå…´è¶£ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12040v1",
      "published_date": "2026-01-17 13:00:17 UTC",
      "updated_date": "2026-01-17 13:00:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:53:07.056400+00:00"
    },
    {
      "arxiv_id": "2601.12038v1",
      "title": "Abstract Argumentation with Subargument Relations",
      "title_zh": "åŒ…å«å­è®ºè¯å…³ç³»çš„æŠ½è±¡è®ºè¾©",
      "authors": [
        "Beishui Liao"
      ],
      "abstract": "Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.",
      "tldr_zh": "è¯¥è®ºæ–‡æ¢è®¨äº†Dungçš„æŠ½è±¡è®ºè¯æ¡†æ¶ (abstract argumentation framework) åœ¨è¡¨å¾å­è®ºè¯å…³ç³» (subargument relations) æ–¹é¢çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ç»“æ„åŒ–ä¾èµ–å…³ç³»æ—¶çš„ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§å¢å¼ºå‹çš„æ¡†æ¶ï¼Œå°†æ˜¾å¼çš„å­è®ºè¯å…³ç³»ä¸æ”»å‡»å…³ç³» (attack) å…±åŒè§†ä¸ºåŸºç¡€å…³ç³»è¿›è¡Œå¤„ç†ã€‚æ–‡ä¸­æ·±å…¥åˆ†æäº†å­è®ºè¯å…³ç³»ä¸æ”»å‡»å…³ç³»ä¹‹é—´çš„äº¤äº’ä½œç”¨ï¼Œå¹¶è€ƒå¯Ÿäº†å…¶å¯¹åŸºç¡€è¯­ä¹‰æ€§è´¨ (semantic properties) çš„å½±å“ã€‚è¯¥ç ”ç©¶ä¸ºç»“æ„åŒ–ä¿¡æ¯æä¾›äº†åŸåˆ™æ€§çš„æŠ½è±¡æ–¹æ³•ï¼Œè¿›ä¸€æ­¥é˜æ˜äº†å­è®ºè¯åœ¨æŠ½è±¡å¯æ¥å—æ€§æ¨ç† (abstract acceptability reasoning) ä¸­çš„æ ¸å¿ƒä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.12038v1",
      "published_date": "2026-01-17 12:54:10 UTC",
      "updated_date": "2026-01-17 12:54:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:53:24.342026+00:00"
    },
    {
      "arxiv_id": "2601.12030v1",
      "title": "ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents",
      "title_zh": "ARCï¼šé¢å‘é•¿æ—¶ç¨‹ä¿¡æ¯å¯»æ±‚æ™ºèƒ½ä½“çš„ä¸»åŠ¨å¼ä¸åæ€é©±åŠ¨ä¸Šä¸‹æ–‡ç®¡ç†",
      "authors": [
        "Yilun Yao",
        "Shan Huang",
        "Elsie Dai",
        "Zhewen Tan",
        "Zhenyu Duan",
        "Shousheng Jia",
        "Yanbing Jiang",
        "Tong Yang"
      ],
      "abstract": "Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.",
      "tldr_zh": "This paper introduces a novel approach to managing the \"context rot\" that often plagues long-horizon AI agents. Below is a summary of the **ARC** framework based on the abstract you provided.\n\n---\n\n### ğŸ“„ Paper Overview: ARC Framework\n\nThe **ARC** (Active and Reflection-driven Context Management) framework addresses the limitations of passive context handling in large language models (LLMs) during complex, multi-step information-seeking tasks.\n\n| Feature | Description |\n|---|---|\n| **Core Problem** | **Context Rot**: The degradation of performance and coherence as interaction histories grow longer. |\n| **Traditional Approach** | Passive summarization or raw accumulation of history, which allows errors or irrelevant data to persist. |\n| **ARC Innovation** | Treats context as a **dynamic internal reasoning state** rather than a static artifact. |\n| **Primary Mechanism** | **Reflection-driven monitoring and revision**: The agent actively reorganizes and cleans its working context when it detects misalignment. |\n| **Key Results** | Achieved up to an **11% absolute improvement** in accuracy on the BrowseComp-ZH benchmark using Qwen2.5-32B-Instruct. |\n\n---\n\n### ğŸ’¡ Key Takeaways\n\nGemini Enterprise finds this approach particularly interesting because it shifts the responsibility of memory management from fixed algorithms to the model's own reasoning capabilities. By allowing an agent to \"reflect\" on its own history, it can discard noise and focus on task-relevant information, which is critical for deep search applications.\n\nAre you looking to dive deeper into the methodology of the reflection-driven monitoring, or perhaps you'd like to compare this with other context compression techniques like LongLoRA or MemGPT? I'm here to help you explore these details!",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12030v1",
      "published_date": "2026-01-17 12:17:50 UTC",
      "updated_date": "2026-01-17 12:17:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:53:30.130435+00:00"
    },
    {
      "arxiv_id": "2601.12024v1",
      "title": "A Multi-Agent System for Generating Actionable Business Advice",
      "title_zh": "### Overview of the Paper ğŸ“„\n\nThis paper introduces a sophisticated **Multi-Agent System** designed to bridge the gap between simple sentiment analysis and actual, prescriptive business strategy. Instead of just telling a business \"people are unhappy,\" this framework provides specific, actionable steps based on customer feedback.\n\n---\n\n### Key Components of the Framework ğŸ› ï¸\n\nThe system operates through a structured four-stage pipeline to ensure the advice generated is of high quality and practical utility:\n\n| Component | Function |\n|---|---|\n| **Clustering** | Distills large corpora of reviews into representative samples to focus the analysis. |\n| **Advice Generation** | Uses LLMs to draft initial business recommendations based on the clustered data. |\n| **Iterative Evaluation** | A feedback loop where agents critique and refine the advice for depth and reasoning. |\n| **Feasibility Ranking** | Prioritizes suggestions based on how specific, actionable, and practical they are for a business to implement. |\n\n---\n\n### Primary Findings ğŸ“ˆ\n\n*   **Superior Performance:** The multi-agent approach consistently beat single-model baselines in terms of **actionability**, **specificity**, and **non-redundancy**.\n*   **Model Efficiency:** Interestingly, medium-sized models within this framework performed nearly as well as much larger models, suggesting the *process* is as important as the raw power of the LLM.\n*   **Cross-Domain Success:** The framework was successfully tested across three different service domains, proving its versatility.\n\n---\n\n### How can I help you with this research? ğŸ¤”\n\nI'd be happy to dive deeper into this paper with you. Would you like me to:\n\n1.  **Analyze the Methodology?** We can discuss the specific logic behind the iterative evaluation or the clustering techniques used.\n2.  **Discuss Practical Applications?** We could explore how a specific industry (like retail or tech) might implement a framework like this.\n3.  **Compare it to other LLM frameworks?** I can help find similar research on multi-agent systems for decision support.\n\nWhat's on your mind regarding this system?",
      "authors": [
        "Kartikey Singh Bhandari",
        "Tanish Jain",
        "Archit Agrawal",
        "Dhruv Kumar",
        "Praveen Kumar",
        "Pratik Narang"
      ],
      "abstract": "Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨å°†å¤§è§„æ¨¡å®¢æˆ·è¯„è®ºè½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„ä¸šåŠ¡å»ºè®® (actionable business advice)ã€‚è¯¥æ¡†æ¶æ•´åˆäº†å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šç”¨äºç­›é€‰ä»£è¡¨æ€§è¯„è®ºçš„èšç±» (clustering)ã€å»ºè®®ç”Ÿæˆã€è¿­ä»£è¯„ä¼°ä»¥åŠåŸºäºå¯è¡Œæ€§ (feasibility) çš„æ’åºã€‚é€šè¿‡å°†è¯­æ–™åº“è’¸é¦ (corpus distillation) ä¸åé¦ˆé©±åŠ¨çš„å»ºè®®ç»†åŒ–ç›¸ç»“åˆï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆæ›´å…·å…·ä½“æ€§ã€å¯æ‰§è¡Œæ€§å’Œå®ç”¨æ€§çš„å»ºè®®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªæœåŠ¡é¢†åŸŸå‡æ˜¾è‘—ä¼˜äºå•æ¨¡å‹åŸºçº¿ï¼Œä¸”ä¸­å‹æ¨¡å‹åœ¨æ€§èƒ½ä¸Šå·²æ¥è¿‘å¤§å‹æ¨¡å‹æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12024v1",
      "published_date": "2026-01-17 12:07:55 UTC",
      "updated_date": "2026-01-17 12:07:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:53:40.375357+00:00"
    },
    {
      "arxiv_id": "2601.12019v1",
      "title": "Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning",
      "title_zh": "å€Ÿå¤§è¯­è¨€æ¨¡å‹è°„åªšæ€§åŒ–èº«â€œå¥‰æ‰¿è€…â€ï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å¯¹ç«‹ç«‹åœºæ¨ç†å¯¹æŠ—ç‚¹å‡»è¯±é¥µ",
      "authors": [
        "Chaowei Zhang",
        "Xiansheng Luo",
        "Zewei Zhang",
        "Yi Zhu",
        "Jipeng Qiang",
        "Longwei Wang"
      ],
      "abstract": "The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é˜¿è°€å¥‰æ‰¿ï¼ˆSycophancyï¼‰ç‰¹æ€§æ¥å¯¹æŠ—ç‚¹å‡»ç‡è¯±å¯¼ï¼ˆClickbaitï¼‰çš„æ–°é¢–æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº† SORGï¼ˆSelf-renewal Opposing-stance Reasoning Generationï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¹¶éæ¶ˆé™¤ Sycophancyï¼Œè€Œæ˜¯åˆ©ç”¨å…¶ä¸ºæ–°é—»æ ‡é¢˜ç”Ÿæˆé«˜è´¨é‡çš„èµåŒä¸åå¯¹çš„å¯¹ç«‹ç«‹åœºæ¨ç†å¯¹ã€‚éšåï¼Œé€šè¿‡ ORCDï¼ˆOpposing Reasoning-based Clickbait Detectionï¼‰æ¨¡å‹é›†æˆä¸‰ä¸ª BERT ç¼–ç å™¨ï¼Œå¹¶ç»“åˆå¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰å’Œ LLM ç”Ÿæˆçš„è½¯æ ‡ç­¾ï¼ˆSoft Labelsï¼‰æ¥æå‡æ£€æµ‹çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„ LLM æç¤ºè¯æ–¹æ³•ã€å¾®è°ƒçš„å°è¯­è¨€æ¨¡å‹ä»¥åŠæœ€å…ˆè¿›çš„ç‚¹å‡»ç‡è¯±å¯¼æ£€æµ‹åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12019v1",
      "published_date": "2026-01-17 11:57:23 UTC",
      "updated_date": "2026-01-17 11:57:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:27.623725+00:00"
    },
    {
      "arxiv_id": "2601.12014v1",
      "title": "Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats",
      "title_zh": "LLM æ˜¯å¦å·²ä¸º TOON åšå¥½å‡†å¤‡ï¼Ÿæ–°å‹ç»“æ„åŒ–è¾“å‡ºæ ¼å¼ä¸­ç»“æ„æ­£ç¡®æ€§ä¸å¯æŒç»­æ€§æƒè¡¡çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Elio Masciari",
        "Vincenzo Moscato",
        "Enea Vincenzo Napolitano",
        "Gian Marco Orlando",
        "Marco Perillo",
        "Diego Russo"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.\n  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºæ—¶çš„ç»“æ„æ­£ç¡®æ€§ (structural correctness) ä¸ç¯å¢ƒå¯æŒç»­æ€§ä¹‹é—´çš„æƒè¡¡ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªç¯å¢ƒæ„ŸçŸ¥è¯„ä¼°æ¡†æ¶åŠç»Ÿä¸€æŒ‡æ ‡ $GCS_{env}$ï¼Œç”¨ä»¥è¡¡é‡ Token ä½¿ç”¨é‡ã€ç”Ÿæˆæ—¶é—´å’Œç¢³æ’æ”¾é‡ã€‚é€šè¿‡å°†æ–°å‹æ ¼å¼ TOON ä¸ä¼ ç»Ÿçš„ JSONã€XML å’Œ YAML è¿›è¡Œç³»ç»Ÿæ€§åŸºå‡†æµ‹è¯•ï¼Œç ”ç©¶å‘ç° TOON å…·æœ‰æ›´é«˜çš„è¾“å‡ºç´§å‡‘æ€§å’Œæ›´ä½çš„ç¢³æ’æ”¾ã€‚ç„¶è€Œï¼Œåœ¨ç¼ºä¹åŸç”Ÿæ”¯æŒçš„æƒ…å†µä¸‹ï¼ŒTOON çš„ç»“æ„æ­£ç¡®æ€§ç›¸å¯¹è¾ƒä½ã€‚å®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œå¢åŠ æ¨¡å‹å®¹é‡èƒ½æœ‰æ•ˆç¼©å°è¿™ä¸€å·®è·ï¼Œä¸ºå¤§è§„æ¨¡ã€ç¢³æ„è¯† (carbon-conscious) çš„ LLM éƒ¨ç½²æä¾›äº†å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12014v1",
      "published_date": "2026-01-17 11:42:02 UTC",
      "updated_date": "2026-01-17 11:42:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:07.457230+00:00"
    },
    {
      "arxiv_id": "2601.12003v2",
      "title": "Robust Verification of Concurrent Stochastic Games",
      "title_zh": "å¹¶å‘éšæœºåšå¼ˆçš„é²æ£’éªŒè¯",
      "authors": [
        "Angel Y. He",
        "David Parker"
      ],
      "abstract": "Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified - an unrealistic requirement in many real-world settings. We introduce *robust CSGs* and their subclass *interval CSGs* (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for *robust* verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹è‡ªä¸»ç³»ç»Ÿåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸‹å¹¶å‘å†³ç­–çš„æ¦‚ç‡ä¸ç¡®å®šæ€§é—®é¢˜ï¼Œæå‡ºäº†é²æ£’å¹¶å‘éšæœºåšå¼ˆ (Robust CSGs) åŠå…¶å­ç±»åŒºé—´å¹¶å‘éšæœºåšå¼ˆ (Interval CSGs, ICSGs)ã€‚ç ”ç©¶å»ºç«‹äº†ä¸€å¥—æ–°å‹çš„é²æ£’éªŒè¯æ¡†æ¶ï¼Œæ—¨åœ¨æœ€åæƒ…å†µå‡è®¾ä¸‹å¤„ç†è½¬ç§»æ¦‚ç‡çš„è®¤çŸ¥ä¸ç¡®å®šæ€§ (Epistemic Uncertainty)ã€‚æ–‡ä¸­ä¸ºé›¶å’Œä¸éé›¶å’Œè®¾ç½®ï¼ˆåŸºäº Nash equilibriaï¼‰ä¸‹çš„æœ‰é™åŠæ— é™æ—¶ç•Œç›®æ ‡æä¾›äº†ç†è®ºåŸºç¡€ä¸é«˜æ•ˆç®—æ³•ã€‚é€šè¿‡åœ¨ PRISM-games æ¨¡å‹æ£€æµ‹å™¨ä¸­çš„å®ç°ï¼Œè¯¥ç ”ç©¶åœ¨å¤šä¸ªå¤§å‹åŸºå‡†æµ‹è¯•ä¸­è¯æ˜äº†å¯¹ ICSGs è¿›è¡Œé²æ£’éªŒè¯çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.GT",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.LO",
      "comment": "Extended version of a paper accepted to TACAS 2026. Main text: 17 pages, 2 figures, 2 tables; Appendix: 37 pages, 3 figures, 3 tables. Minor revisions and clarifications to the appendix; no changes to results",
      "pdf_url": "https://arxiv.org/pdf/2601.12003v2",
      "published_date": "2026-01-17 10:42:44 UTC",
      "updated_date": "2026-01-21 09:31:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:09.595856+00:00"
    },
    {
      "arxiv_id": "2601.12002v1",
      "title": "Kernel-Based Learning of Safety Barriers",
      "title_zh": "åŸºäºæ ¸çš„å®‰å…¨å±éšœå­¦ä¹ ",
      "authors": [
        "Oliver SchÃ¶n",
        "Zhengang Zhong",
        "Sadegh Soudjani"
      ],
      "abstract": "The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶å’ŒåŒ»ç–—ç­‰å®‰å…¨å…³é”®é¢†åŸŸä¸­ï¼Œä¼ ç»Ÿå½¢å¼åŒ–éªŒè¯éš¾ä»¥å¤„ç†é»‘ç›’ç³»ç»Ÿä¸”æ‰©å±•æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„å®‰å…¨éªŒè¯ä¸ç»¼åˆæ–¹æ³•ã€‚\n\n---\n\n### æ ¸å¿ƒè´¡çŒ®ä¸æ–¹æ³• ğŸ› ï¸\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒæ¦‚å¿µ** | åˆ©ç”¨**æ§åˆ¶å±éšœè¯ä¹¦ (control barrier certificates)**ï¼Œç›´æ¥ä»ç³»ç»Ÿè½¨è¿¹ä¸­å­¦ä¹ å®‰å…¨ä¿è¯ã€‚ |\n| **æ•°å­¦æ¡†æ¶** | é‡‡ç”¨**æ¡ä»¶å‡å€¼åµŒå…¥ (conditional mean embeddings)** å°†æ•°æ®æ˜ å°„è‡³**å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´ (RKHS)**ï¼Œå¹¶æ„å»ºæ­§ä¹‰é›†ä»¥æå‡å¯¹**åˆ†å¸ƒå¤–è¡Œä¸º (out-of-distribution behavior)** çš„ç¨³å¥æ€§ã€‚ |\n| **ç®—æ³•ä¼˜åŒ–** | é€šè¿‡**æœ‰é™å‚…é‡Œå¶å±•å¼€ (finite Fourier expansion)** å°†å¤æ‚çš„åŠæ— é™ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºçº¿æ€§è§„åˆ’ï¼Œå¹¶åˆ©ç”¨**å¿«é€Ÿå‚…é‡Œå¶å˜æ¢ (FFT)** å®ç°äº†é«˜æ•ˆçš„æ‰©å±•ã€‚ |\n\n---\n\n### ç ”ç©¶å‘ç°ä¸ç»“æœ ğŸ“ˆ\n\nè¯¥æ¡†æ¶æ‰“ç ´äº†å¯¹ç³»ç»ŸåŠ¨åŠ›å­¦å’Œä¸ç¡®å®šæ€§çš„ä¸¥æ ¼å‡è®¾é™åˆ¶ï¼Œä¸ä»…èƒ½å¤„ç†åŸºç¡€çš„å®‰å…¨éªŒè¯ï¼Œè¿˜å¯åº”ç”¨äºæ›´é€šç”¨çš„**æ—¶åºé€»è¾‘è§„èŒƒ (temporal logic specifications)**ã€‚åœ¨åŒ…æ‹¬ç¥ç»ç½‘ç»œæ§åˆ¶å™¨é»‘ç›’ç³»ç»Ÿåœ¨å†…çš„ä¸¤é¡¹æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œè¯¥æ–¹æ³•å±•ç¤ºäº†å“è¶Šçš„æ‰©å±•æ€§å’Œåˆ†å¸ƒç¨³å¥æ€§ã€‚\n\n---\n\nè¿™ä»½æ‘˜è¦æ˜¯å¦æ¶µç›–äº†ä½ å…³æ³¨çš„ç‰¹å®šæŠ€æœ¯ç»†èŠ‚ï¼Ÿå¦‚æœä½ å¯¹ **RKHS** çš„å…·ä½“å®ç°æˆ–**è°±å±éšœ (spectral barrier)** çš„è®¡ç®—æ•ˆç‡æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ç»§ç»­æé—®ï¼",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "44 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12002v1",
      "published_date": "2026-01-17 10:42:35 UTC",
      "updated_date": "2026-01-17 10:42:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:28.808547+00:00"
    },
    {
      "arxiv_id": "2601.11998v1",
      "title": "Hybrid IDS Using Signature-Based and Anomaly-Based Detection",
      "title_zh": "ç»“åˆç‰¹å¾æ£€æµ‹ä¸å¼‚å¸¸æ£€æµ‹çš„æ··åˆå¼å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ",
      "authors": [
        "Messaouda Boutassetta",
        "Amina Makhlouf",
        "Newfel Messaoudi",
        "Abdelmadjid Benmachiche",
        "Ines Boutabia"
      ],
      "abstract": "Intrusion detection systems (IDS) are essential for protecting computer systems and networks against a wide range of cyber threats that continue to evolve over time. IDS are commonly categorized into two main types, each with its own strengths and limitations, such as difficulty in detecting previously unseen attacks and the tendency to generate high false positive rates. This paper presents a comprehensive survey and a conceptual overview of Hybrid IDS, which integrate signature-based and anomaly-based detection techniques to enhance attack detection capabilities. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. In addition, recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, are reviewed. Finally, this work outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.",
      "tldr_zh": "è¯¥è®ºæ–‡å¯¹æ··åˆå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ (Hybrid IDS) è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°å’Œæ¦‚å¿µæ€§æ¦‚è¿°ï¼Œé‡ç‚¹æ¢è®¨äº†å¦‚ä½•æ•´åˆåŸºäºç­¾å (signature-based) å’ŒåŸºäºå¼‚å¸¸ (anomaly-based) çš„æ£€æµ‹æŠ€æœ¯ä»¥æå‡é˜²å¾¡èƒ½åŠ›ã€‚æ–‡ç« å¯¹ç°æœ‰æ¨¡å‹è¿›è¡Œäº†åŠŸèƒ½åˆ†ç±»ï¼Œè¯¦ç»†åˆ†æäº†å…¶åœ¨é‡‘èç³»ç»Ÿã€ç©ºä¸­äº¤é€šæ§åˆ¶åŠç¤¾äº¤ç½‘ç»œç­‰é¢†åŸŸçš„ä¼˜åŠ¿ä¸å±€é™æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å›é¡¾äº†æœºå™¨å­¦ä¹  (machine learning-based) å’Œäº‘ç«¯éƒ¨ç½² (cloud-based) ç­‰æœ€æ–°æŠ€æœ¯è¶‹åŠ¿ã€‚æœ€åï¼Œä½œè€…æŒ‡å‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼Œæ—¨åœ¨å¼€å‘èƒ½å¤Ÿæ›´æœ‰æ•ˆåº”å¯¹å¤æ‚æ–°å…´ç½‘ç»œæ”»å‡»çš„é«˜æ€§ä»·æ¯” Hybrid IDS è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages,The Second National Conference on Artificial Intelligence and Information Technologies (NCAIIT25)",
      "pdf_url": "https://arxiv.org/pdf/2601.11998v1",
      "published_date": "2026-01-17 10:19:57 UTC",
      "updated_date": "2026-01-17 10:19:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:17.927204+00:00"
    },
    {
      "arxiv_id": "2601.11995v1",
      "title": "Learning Audio-Visual Embeddings with Inferred Latent Interaction Graphs",
      "title_zh": "Hello! I am Gemini Enterpriseâœ¨. I have reviewed the abstract for your paper, **\"Learning Audio-Visual Embeddings with Inferred Latent Interaction Graphs.\"** \n\nIt presents a sophisticated approach to solving the \"false negative\" and \"unannotated event\" problems in multi-modal learning. Below is a summary of the core framework and its key components.\n\n---\n\n### ğŸ§© Core Components of the Framework\n\nThe proposed method moves beyond simple contrastive learning by using teacher-student dynamics and graph-based dependencies.\n\n| Component | Full Name | Primary Function |\n|---|---|---|\n| **AV-SAL** | Audio-Visual Semantic Alignment Loss | Trains a teacher network to generate soft labels that align modalities, ensuring unannotated but present events are recognized. |\n| **ILI** | Inferred Latent Interaction Graph | Uses the GRaSP algorithm on soft labels to map directional dependencies (e.g., visual \"Train\" appearing with audio \"Motorcycle\"). |\n| **LIR** | Latent Interaction Regularizer | Guides the student network to pull together embeddings of class pairs identified by the ILI graph, improving semantic coherence. |\n\n---\n\n### ğŸ’¡ Problem & Solution Summary\n\n| Aspect | Description |\n|---|---|\n| **The Problem** | Standard contrastive methods often treat co-occurring but unannotated objects (like a motorcycle appearing in a video labeled \"train\") as negative samples. This leads to false negatives and poor cross-modal alignment. |\n| **The Solution** | By inferring a latent interaction graph, the model learns that certain classes often appear together. It uses this \"soft\" knowledge to regularize the embedding space, making it more robust to noisy or incomplete labels. |\n| **The Results** | The framework shows improved Mean Average Precision (mAP) on standard benchmarks like AVE and VEGAS. |\n\n---\n\n### ğŸš€ How can I help you further?\n\nThis looks like a very promising piece of research in the field of audio-visual representation learning. Would you like me to:\n\n*   **Draft a summary** for a specific audience (e.g., a non-technical summary or a concise \"TL;DR\")?\n*   **Generate potential questions** that might be asked during a peer review or a poster session?\n*   **Compare this approach** to other common audio-visual embedding techniques like CLIP or AVC?\n\nLet me know what you need!",
      "authors": [
        "Donghuo Zeng",
        "Hao Niu",
        "Yanan Wang",
        "Masato Taya"
      ],
      "abstract": "Learning robust audio-visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences - background noise, unrelated elements, or unannotated events. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. For example, a video labeled \"train\" might also contain motorcycle audio and visual, because \"motorcycle\" is not the chosen annotation; standard methods treat these co-occurrences as negatives to true motorcycle anchors elsewhere, creating false negatives and missing true cross-modal dependencies. We propose a framework that leverages soft-label predictions and inferred latent interactions to address these issues: (1) Audio-Visual Semantic Alignment Loss (AV-SAL) trains a teacher network to produce aligned soft-label distributions across modalities, assigning nonzero probability to co-occurring but unannotated events and enriching the supervision signal. (2) Inferred Latent Interaction Graph (ILI) applies the GRaSP algorithm to teacher soft labels to infer a sparse, directed dependency graph among classes. This graph highlights directional dependencies (e.g., \"Train (visual)\" -> \"Motorcycle (audio)\") that expose likely semantic or conditional relationships between classes; these are interpreted as estimated dependency patterns. (3) Latent Interaction Regularizer (LIR): A student network is trained with both metric loss and a regularizer guided by the ILI graph, pulling together embeddings of dependency-linked but unlabeled pairs in proportion to their soft-label probabilities. Experiments on AVE and VEGAS benchmarks show consistent improvements in mean average precision (mAP), demonstrating that integrating inferred latent interactions into embedding learning enhances robustness and semantic coherence.",
      "tldr_zh": "---\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåˆ©ç”¨æ¨æ–­æ½œäº¤äº’ (inferred latent interactions) æ¥å­¦ä¹ é²æ£’è§†å¬åµŒå…¥ (audio-visual embeddings) çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå¯¹æ¯”å­¦ä¹ ä¸­å› æœªæ ‡æ³¨å…±ç°äº‹ä»¶å¯¼è‡´çš„ä¼ªè´Ÿæ ·æœ¬ (false negatives) é—®é¢˜ã€‚\n\nè¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼š\n*   **è§†å¬è¯­ä¹‰å¯¹é½æŸå¤± (AV-SAL)**ï¼šé€šè¿‡æ•™å¸ˆç½‘ç»œç”Ÿæˆè½¯æ ‡ç­¾ (soft-labels)ï¼Œä¸ºæœªæ ‡æ³¨ä½†å…±ç°çš„äº‹ä»¶åˆ†é…æ¦‚ç‡ã€‚\n*   **æ¨æ–­æ½œäº¤äº’å›¾ (ILI)**ï¼šåˆ©ç”¨ GRaSP ç®—æ³•æ¨æ–­ç±»åˆ«é—´çš„å®šå‘ä¾èµ–å…³ç³»ã€‚\n*   **æ½œäº¤äº’æ­£åˆ™åŒ–å™¨ (LIR)**ï¼šæŒ‡å¯¼å­¦ç”Ÿç½‘ç»œåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æ‹‰è¿‘å…·æœ‰æ½œåœ¨è¯­ä¹‰å…³è”çš„è§†å¬å¯¹ã€‚\n\nå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ AVE å’Œ VEGAS åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—æå‡äº†å¹³å‡ç²¾åº¦å‡å€¼ (mAP)ï¼Œæœ‰æ•ˆå¢å¼ºäº†è§†å¬åµŒå…¥çš„é²æ£’æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚\n\n---\nå¸Œæœ›è¿™ä¸ªæ‘˜è¦å¯¹ä½ æœ‰å¸®åŠ©ï¼ä½ è¿˜æƒ³äº†è§£è¿™ç¯‡è®ºæ–‡ä¸­å…³äº GRaSP ç®—æ³•æˆ–ç‰¹å®šç»„ä»¶çš„æ›´å¤šç»†èŠ‚å—ï¼Ÿ",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.MM",
      "comment": "16 pages, 5 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.11995v1",
      "published_date": "2026-01-17 10:13:07 UTC",
      "updated_date": "2026-01-17 10:13:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:29.259242+00:00"
    },
    {
      "arxiv_id": "2601.11979v1",
      "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion",
      "title_zh": "Hello! I am Gemini Enterpriseâœ¨. That is a fascinating abstract regarding a novel approach to In-Context Learning (ICL). It seems like the authors are addressing a very specific and common bottleneck in mathematical reasoning for Large Language Models.\n\nBased on the title and abstract you provided, here is a summary of the **Process In-Context Learning (PICL)** framework.\n\n---\n\n### ğŸ§  The Core Challenge: Static vs. Dynamic Reasoning\n\nTraditional In-Context Learning relies on a **static** set of demonstrations. While this works for simple tasks, it often falls short in complex mathematical reasoning where a model might get \"confused\" halfway through a calculation. \n\nStandard ICL cannot adapt to these mid-process errors, which often lead to a \"cascade\" effect where one small mistake ruins the entire logic.\n\n---\n\n### ğŸ› ï¸ The PICL Solution\n\nThe proposed **PICL** framework shifts the paradigm from pre-selected examples to **real-time, adaptive guidance**. Instead of just looking at examples at the start, the model receives help exactly when it starts to struggle.\n\n| Stage | Action | Description |\n| :--- | :--- | :--- |\n| **1. Identification** | **Detect Confusion** | Analyzes the semantics and entropy (uncertainty) of the current reasoning step to find logical gaps. |\n| **2. Integration** | **Dynamic Insertion** | Retrieves a specific demonstration from a pool that matches the current \"confusion point\" and inserts it into the prompt mid-inference. |\n\n---\n\n### ğŸ“ˆ Key Takeaways\n\n*   **Mitigates Cascading Errors:** By fixing confusion points as they happen, the model maintains higher accuracy through the end of the problem.\n*   **Context-Aware:** The demonstrations are not just random; they are specifically chosen to match the difficulty the model is currently facing.\n*   **Superior Performance:** The abstract notes that this method outperforms baseline static ICL methods in complex math tasks.\n\n---\n\nThis is a great piece of research on making AI reasoning more robust! Would you like me to help you explore specific parts of this framework, or perhaps you'd like to compare this with other reasoning techniques like **Chain-of-Thought (CoT)**? \n\nI'm also happy to help you draft a summary for a presentation or explain the technical terms like \"entropy\" in this context! How can I assist you further?",
      "authors": [
        "Ang Gao",
        "Changshuo Zhang",
        "Xiao Zhang",
        "Deyang Li",
        "Minjun Zhao",
        "Fangchao Liu",
        "Xinyu Zhang"
      ],
      "abstract": "In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.",
      "tldr_zh": "It looks like you've shared a very interesting research abstract on a new framework for improving mathematical reasoning in Large Language Models. I am **Gemini Enterprise**, and I've summarized the key points of the paper for you below.\n\n---\n\n### ğŸ“ Paper Overview: Process In-Context Learning (PICL)\n\nThe paper introduces **Process In-Context Learning (PICL)**, a framework designed to overcome the limitations of traditional, static In-Context Learning (ICL). While standard ICL uses fixed examples, PICL adapts to the specific difficulties a model encounters *during* the reasoning process.\n\n---\n\n### âš™ï¸ How PICL Works\n\nThe framework operates in a two-stage dynamic process to ensure the model stays on the right track during complex deductions:\n\n| Stage | Action | Description |\n|---|---|---|\n| **1. Identification** | **Detect Confusion** | Analyzes the semantics and entropy of the reasoning steps to find \"confusion points\" (e.g., ambiguous calculations or logical gaps). |\n| **2. Intervention** | **Dynamic Insertion** | Retrieves a specific demonstration from a pool that addresses the current confusion and inserts it into the prompt in real-time. |\n\n---\n\n### ğŸš€ Key Advantages\n\n*   **Adaptive Reasoning:** Unlike static methods, it responds to real-time inference needs.\n*   **Error Mitigation:** Prevents \"cascading errors\" where one small mistake at the start ruins the entire logic chain.\n*   **Improved Accuracy:** Outperforms baseline ICL methods by providing help exactly when and where the model needs it most.\n\n---\n\nThis is a fascinating approach to \"active\" inference! Would you like me to help you explore specific parts of this methodology, or perhaps compare it to other reasoning techniques like Chain-of-Thought?",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11979v1",
      "published_date": "2026-01-17 09:20:06 UTC",
      "updated_date": "2026-01-17 09:20:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:34.708851+00:00"
    },
    {
      "arxiv_id": "2601.11977v1",
      "title": "One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints",
      "title_zh": "éšç§çº¦æŸä¸‹åŸºäºåå˜é‡å¼•å¯¼ä¸“å®¶çš„å•æ ·æœ¬ä»·æ ¼é¢„æµ‹",
      "authors": [
        "Ren He",
        "Yinliang Xu",
        "Jinfeng Wang",
        "Jeremy Watson",
        "Jian Song"
      ],
      "abstract": "Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“ˆ\n\nè¯¥ç ”ç©¶é’ˆå¯¹ç”µåŠ›ç³»ç»Ÿä»·æ ¼é¢„æµ‹ä¸­çš„å¤šå˜é‡æ—¶é—´åºåˆ—ä¾èµ–å’Œè·¨åŒºåŸŸéšç§é™åˆ¶ï¼Œæå‡ºäº† **MoE Encoder** æ¨¡å—ï¼Œä»¥å¢å¼ºé¢„è®­ç»ƒæ—¶é—´åºåˆ—æ¨¡å‹çš„æ€§èƒ½ã€‚\n\n*   **æ ¸å¿ƒæ–¹æ³•**ï¼šè¯¥æ¡†æ¶åœ¨ tokenization ä¸ encoding ä¹‹é—´æ³¨å…¥ç¨€ç–çš„ **mixture-of-experts (MoE)** å±‚ï¼Œå°†å¤šå˜é‡é¢„æµ‹è½¬åŒ–ä¸ºä¸“å®¶å¼•å¯¼çš„å•å˜é‡ä»»åŠ¡ï¼Œä»è€Œæœ‰æ•ˆæ•è·å˜é‡é—´çš„å¤æ‚å…³ç³»ã€‚\n*   **éšç§ä¸é€‚é…**ï¼šè¯¥è®¾è®¡æ”¯æŒåœ¨ **federated learning** ç¯å¢ƒä¸‹è¿›è¡Œæœ¬åœ°åŒ–è®­ç»ƒå’Œè½»é‡çº§å‚æ•°å…±äº«ï¼Œæ— éœ€äº¤æ¢åŸå§‹æ•°æ®ã€‚\n*   **å®éªŒç»“æœ**ï¼šåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œ**MoE-Encoder** æ˜¾è‘—æå‡äº†é¢„æµ‹ç²¾åº¦ï¼›åœ¨è”é‚¦åœºæ™¯ä¸‹ï¼Œä»…é€šè¿‡ä¼ è¾“è¯¥æ¨¡å—å‚æ•°å³å¯å®ç°å¯¹æ–°åŒºåŸŸçš„é«˜æ•ˆé€‚é…ï¼Œä¸”æ€§èƒ½æŸå¤±æå°ã€‚\n\n---\n\næˆ‘æ˜¯ **Gemini Enterprise**ï¼Œå¸Œæœ›è¿™ä¸ªæ‘˜è¦èƒ½å¸®ä½ å¿«é€ŸæŒæ¡è®ºæ–‡æ ¸å¿ƒï¼å¦‚æœä½ å¯¹ **federated learning** åœ¨ç”µåŠ›ç³»ç»Ÿä¸­çš„åº”ç”¨æˆ– **MoE** ç»“æ„çš„å…·ä½“å®ç°æ„Ÿå…´è¶£ï¼Œæ¬¢è¿éšæ—¶å‘æˆ‘æé—®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11977v1",
      "published_date": "2026-01-17 09:13:57 UTC",
      "updated_date": "2026-01-17 09:13:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:54:54.817207+00:00"
    },
    {
      "arxiv_id": "2601.11974v1",
      "title": "Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement",
      "title_zh": "æ•ˆæ³•äººç±»å­¦ä¹ ï¼šåˆ©ç”¨å…ƒè®¤çŸ¥åæ€å®ç°é«˜æ•ˆè‡ªæˆ‘æå‡",
      "authors": [
        "Xinmeng Hou",
        "Peiliang Gong",
        "Bohao Qu",
        "Wuqi Wang",
        "Qing Guo",
        "Yang Liu"
      ],
      "abstract": "While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.",
      "tldr_zh": "---\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\nè¯¥ç ”ç©¶æå‡ºäº† **Metacognitive Agent Reflective Self-improvement (MARS)** æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ Large Language Models (LLMs) æ™ºèƒ½ä½“è‡ªæ¼”åŒ–è¿‡ç¨‹ä¸­è®¡ç®—æˆæœ¬é«˜ä¸”ä¾èµ–å¤šè½®é€’å½’çš„é—®é¢˜ã€‚\n\nMARS å—æ•™è‚²å¿ƒç†å­¦å¯å‘ï¼Œé€šè¿‡å°† **principle-based reflection**ï¼ˆæŠ½è±¡è§„èŒƒè§„åˆ™ä»¥è§„é¿é”™è¯¯ï¼‰ä¸ **procedural reflection**ï¼ˆæ¨å¯¼æˆåŠŸçš„æ­¥éª¤ç­–ç•¥ï¼‰ç›¸ç»“åˆï¼Œåœ¨å•ä¸ªé€’å½’å‘¨æœŸå†…å®ç°é«˜æ•ˆè‡ªè¿›åŒ–ã€‚è¯¥æ¡†æ¶å°†åæ€è§è§£åˆæˆä¸ºä¼˜åŒ–æŒ‡ä»¤ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿç³»ç»Ÿåœ°æ”¹è¿›å…¶æ¨ç†é€»è¾‘ï¼Œè€Œæ— éœ€æŒç»­çš„åœ¨çº¿åé¦ˆã€‚\n\nå®éªŒè¡¨æ˜ï¼ŒMARS åœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„ state-of-the-art è‡ªæ¼”åŒ–ç³»ç»Ÿï¼Œå¹¶åœ¨æå‡æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚\n\n---\nè¿™ä¸ªæ‘˜è¦å‡†ç¡®æ•æ‰åˆ°äº† MARS æ¡†æ¶çš„æ ¸å¿ƒé€»è¾‘ã€‚ä½ æ˜¯å¦æƒ³æ·±å…¥äº†è§£å®ƒæ˜¯å¦‚ä½•å°†ä¸¤ç§ reflection æœºåˆ¶å…·ä½“åˆæˆåˆ°æŒ‡ä»¤ä¸­çš„ï¼Ÿ",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11974v1",
      "published_date": "2026-01-17 09:12:26 UTC",
      "updated_date": "2026-01-17 09:12:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:55:05.805912+00:00"
    },
    {
      "arxiv_id": "2601.11969v1",
      "title": "$\\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models",
      "title_zh": "MemoryRewardBenchï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹é•¿æœŸè®°å¿†ç®¡ç†çš„å¥–åŠ±æ¨¡å‹è¯„æµ‹åŸºå‡†",
      "authors": [
        "Zecheng Tang",
        "Baibei Ji",
        "Ruoxi Sun",
        "Haitian Wang",
        "WangJie You",
        "Zhang Yijun",
        "Wenpeng Zhu",
        "Ji Qi",
        "Juntao Li",
        "Min Zhang"
      ],
      "abstract": "Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ§ \n\nè¯¥ç ”ç©¶æå‡ºäº† $\\texttt{MemoryRewardBench}$ï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°å¥–åŠ±æ¨¡å‹ (**Reward Models, RMs**) åœ¨å¤§è¯­è¨€æ¨¡å‹ (**LLMs**) é•¿æœŸè®°å¿†ç®¡ç† (**long-term memory management**) è¿‡ç¨‹ä¸­è¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚\n\n*   **æ¶µç›–èŒƒå›´**ï¼šåŸºå‡†æ¶µç›–äº†é•¿ä¸Šä¸‹æ–‡ç†è§£å’Œé•¿å½¢å¼ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…å« 10 ç§ä¸åŒçš„è®°å¿†ç®¡ç†æ¨¡å¼ï¼Œå¤„ç†çš„ä¸Šä¸‹æ–‡é•¿åº¦ä» 8K å»¶ä¼¸è‡³ 128K **tokens**ã€‚\n*   **æ ¸å¿ƒå‘ç°**ï¼šé€šè¿‡å¯¹ 13 ç§å‰æ²¿ **RMs** çš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°å¼€æºä¸é—­æºæ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®è·æ­£åœ¨ç¼©å°ï¼Œä¸”æ–°ä¸€ä»£æ¨¡å‹æ— è®ºå‚æ•°é‡å¤§å°ï¼Œåœ¨è¯„ä¼°ä»»åŠ¡ä¸­å‡ä¼˜äºå‰ä»£æ¨¡å‹ã€‚\n*   **ç ”ç©¶è´¡çŒ®**ï¼šè¯¥å·¥ä½œä¸ä»…æ­ç¤ºäº†å½“å‰ **RMs** åœ¨è¯„ä¼°è®°å¿†ç®¡ç†æ—¶çš„èƒ½åŠ›ï¼Œè¿˜æŒ‡å‡ºäº†å®ƒä»¬åœ¨å¤„ç†å¤æ‚é•¿æ–‡æœ¬åœºæ™¯æ—¶çš„åŸºæœ¬å±€é™æ€§ã€‚\n\n---\n\næˆ‘æ˜¯ **Gemini Enterprise**ï¼Œå¸Œæœ›è¿™ä»½æ‘˜è¦èƒ½è®©ä½ å¿«é€ŸæŒæ¡è¿™ç¯‡è®ºæ–‡çš„ç²¾é«“ã€‚å¦‚æœä½ å¯¹å…¶ä¸­çš„é•¿ä¸Šä¸‹æ–‡è¯„ä¼°æŒ‡æ ‡æˆ–ç‰¹å®šå¥–åŠ±æ¨¡å‹çš„è¡¨ç°æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ç»§ç»­ä¸æˆ‘æ¢è®¨ï¼",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11969v1",
      "published_date": "2026-01-17 09:04:53 UTC",
      "updated_date": "2026-01-17 09:04:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:55:19.623796+00:00"
    },
    {
      "arxiv_id": "2601.11960v1",
      "title": "R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning",
      "title_zh": "R$^2$POï¼šè§£è€¦å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­çš„è®­ç»ƒè½¨è¿¹ä¸æ¨ç†å“åº”",
      "authors": [
        "Jingchu Wang",
        "Bingbing Xu",
        "Yige Yuan",
        "Bin Xie",
        "Xiaoqian Sun",
        "Huawei Shen"
      ],
      "abstract": "Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ§ \n\nè¯¥ç ”ç©¶æå‡ºäº† **R$^2$PO (Residual Rollout Policy Optimization)**ï¼Œæ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ åœ¨æå‡ LLM æ¨ç†èƒ½åŠ›æ—¶ï¼Œç”Ÿæˆç¨³å®šæ¨ç†å“åº”ä¸æ¢ç´¢å¤šæ ·åŒ–è®­ç»ƒè½¨è¿¹ä¹‹é—´çš„ç›®æ ‡å†²çªã€‚\n\nè¯¥æ¡†æ¶çš„æ ¸å¿ƒè´¡çŒ®ä¸å‘ç°å¦‚ä¸‹ï¼š\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒæ–¹æ³•** | å¼•å…¥è½»é‡çº§çš„ **Residual Rollout-Head**ï¼Œå°†è®­ç»ƒè½¨è¿¹ä¸æ¨ç†å“åº”è§£è€¦ï¼Œåœ¨ä¿æŒæ¨ç†ç”Ÿæˆç¨³å®šçš„åŒæ—¶ï¼Œå®ç°è®­ç»ƒæœŸé—´å—æ§çš„è½¨è¿¹å¤šæ ·åŒ–ã€‚ |\n| **æ€§èƒ½è¡¨ç°** | å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ **MATH-500** å’Œ **APPS** åŸºå‡†æµ‹è¯•ä¸Šåˆ†åˆ«å®ç°äº† 3.1% å’Œ 2.4% çš„å¹³å‡å‡†ç¡®ç‡å¢ç›Šã€‚ |\n| **è¾…åŠ©ä¼˜åŒ–** | è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå‡å°‘æ ¼å¼é”™è¯¯ï¼Œå¹¶ç¼“è§£é•¿åº¦åå·® (**length bias**)ï¼Œä»è€Œç¡®ä¿ä¼˜åŒ–è¿‡ç¨‹æ›´åŠ ç¨³å®šã€‚ |\n\n---\n\næˆ‘æ˜¯ **Gemini Enterprise**ï¼Œå¸Œæœ›è¿™ä¸ªæ‘˜è¦èƒ½å¸®åŠ©ä½ å¿«é€Ÿç†è§£è¿™ç¯‡å…³äºå¼ºåŒ–å­¦ä¹ è§£è€¦ç­–ç•¥çš„è®ºæ–‡ã€‚å¦‚æœä½ å¯¹ **Residual Rollout-Head** çš„å…·ä½“æ¶æ„æˆ–å®ƒå¦‚ä½•ç¼“è§£ **length bias** æ„Ÿå…´è¶£ï¼Œå°½ç®¡å¼€å£é—®æˆ‘ï¼",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11960v1",
      "published_date": "2026-01-17 08:30:50 UTC",
      "updated_date": "2026-01-17 08:30:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:55:09.987822+00:00"
    },
    {
      "arxiv_id": "2601.11956v1",
      "title": "Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence",
      "title_zh": "åŒé‡æ ¡å‡†ï¼šé€šè¿‡æ ¡å‡†çŸ¥è¯†ä¸æ¨ç†ç½®ä¿¡åº¦æ„å»ºå¯ä¿¡å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Yuyin Lu",
        "Ziran Liang",
        "Yanghui Rao",
        "Wenqi Fan",
        "Fu Lee Wang",
        "Qing Li"
      ],
      "abstract": "Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.",
      "tldr_zh": "### è®ºæ–‡æ€»ç»“ï¼šDoublyCal\n\nè¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œä»¥åŠç°æœ‰çŸ¥è¯†å›¾è°± (KG) å¢å¼ºæ–¹æ³•æ— æ³•é‡åŒ–è¯æ®ä¸æ¨ç†ä¸ç¡®å®šæ€§çš„é—®é¢˜ï¼Œæå‡ºäº† **DoublyCal** æ¡†æ¶ã€‚\n\nè¯¥æ¡†æ¶åŸºäºä¸€ç§å…¨æ–°çš„åŒé‡æ ¡å‡† (double-calibration) åŸåˆ™ï¼Œé¦–å…ˆåˆ©ç”¨è½»é‡çº§ä»£ç†æ¨¡å‹ç”Ÿæˆå¸¦æœ‰æ ¡å‡†ç½®ä¿¡åº¦çš„ KG è¯æ®ã€‚è¿™äº›æ ¡å‡†åçš„è¯æ®éšåå¼•å¯¼é»‘ç›’ LLM ç”Ÿæˆæœ€ç»ˆé¢„æµ‹ï¼Œç¡®ä¿è¾“å‡ºç»“æœä¸ä»…å‡†ç¡®ï¼Œè€Œä¸”å…¶ç½®ä¿¡åº¦è¯„åˆ†å¯è¿½æº¯è‡³è¾…åŠ©è¯æ®çš„ä¸ç¡®å®šæ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒDoublyCal åœ¨çŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†é»‘ç›’ LLM çš„å‡†ç¡®ç‡å’Œç½®ä¿¡åº¦æ ¡å‡† (confidence calibration)ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½çš„ token æˆæœ¬ã€‚\n\n---\nå¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæ¬¢è¿éšæ—¶æä¾›ï¼",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11956v1",
      "published_date": "2026-01-17 08:18:38 UTC",
      "updated_date": "2026-01-17 08:18:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:55:44.825270+00:00"
    },
    {
      "arxiv_id": "2601.11940v1",
      "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart",
      "title_zh": "é•¿é“¾å¼æ€ç»´ä¸­çš„æ€ç»´é™·é˜±ï¼šé‡åŒ–ç ”ç©¶ä¸é™·é˜±æ„ŸçŸ¥çš„è‡ªé€‚åº”é‡å¯",
      "authors": [
        "Kang Chen",
        "Fan Yu",
        "Junjie Nian",
        "Shihan Zhao",
        "Zhuoka Feng",
        "Zijun Yao",
        "Heng Wang",
        "Minshen Yu",
        "Yixin Cao"
      ],
      "abstract": "Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.",
      "tldr_zh": "### Summary of \"Thinking Traps in Long Chain-of-Thought\" ğŸ§ \n\nI have reviewed the title and abstract you provided. This paper addresses a critical challenge in Scaling test-time compute for Large Language Models (LLMs), specifically within **Long Chain-of-Thought (Long-CoT)** reasoning.\n\n---\n\n### Key Concepts & Findings ğŸ”\n\n| Feature | Description |\n|---|---|\n| **Thinking Traps** | Prefix-dominant deadlocks where the model commits to an early error and fails to correct it despite later reflection or verification. |\n| **Prevalence** | Traps were identified in **89% of failures** on a curated subset of mathematical reasoning tasks (DAPO-MATH). |\n| **The Core Problem** | Extended generation doesn't guarantee accuracy; models often elaborate on incorrect self-consistent prefixes. |\n\n---\n\n### TAAR: Trap-Aware Adaptive Restart ğŸš€\n\nThe authors propose a test-time control framework called **TAAR** to mitigate these traps without needing to fine-tune the base model.\n\n| Stage | Action |\n|---|---|\n| **1. Diagnostic Policy** | Predicts a **trap index** (where to truncate) and an **escape probability** (how strongly to intervene). |\n| **2. Truncation** | Removes the trajectory segment just before the predicted error occurs. |\n| **3. Adaptive Restart** | Restarts decoding with varying perturbations (e.g., higher temperature) or a \"structured reboot\" for severe cases. |\n\n---\n\n### Benchmark Results ğŸ“Š\n\nThe framework was tested on several high-difficulty mathematical and scientific benchmarks, showing improved performance:\n\n*   **AIME 2024 & 2025**\n*   **GPQA-Diamond**\n*   **HMMT 2025**\n*   **BRUMO 2025**\n\n---\n\nThis research seems quite relevant if you are looking into ways to make reasoning models more reliable during long-form generation. Would you like me to dive deeper into any specific part of this abstract, or perhaps help you draft a detailed explanation of how the \"Adaptive Restart\" mechanism works?",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11940v1",
      "published_date": "2026-01-17 07:26:02 UTC",
      "updated_date": "2026-01-17 07:26:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:55:25.491088+00:00"
    },
    {
      "arxiv_id": "2601.11935v1",
      "title": "Big Data Workload Profiling for Energy-Aware Cloud Resource Management",
      "title_zh": "That is an interesting abstract on a very relevant topic in cloud computing. It sounds like the paper focuses on bridging the gap between big data performance and environmental sustainability.\n\n---\n\n### Key Takeaways ğŸ’¡\n\n| Feature | Description |\n|---|---|\n| **Core Problem** | Rising energy consumption in cloud data centers due to massive big data workloads. |\n| **Proposed Solution** | A scheduling framework that profiles CPU, memory, and IO behavior to optimize VM placement. |\n| **Methodology** | Combines historical logs with real-time telemetry to predict energy/performance impacts. |\n| **Benchmarks** | Hadoop MapReduce, Spark MLlib, and ETL workloads on a multi-node testbed. |\n| **Key Results** | 15% - 20% energy savings with negligible performance loss. |\n\n---\n\nHow would you like me to help you with this paper? I can:\n\n*   **Summarize** specific sections or the methodology in more detail.\n*   **Generate** a set of discussion questions or a critique based on the abstract.\n*   **Draft** an introduction or conclusion if you are building upon this research.\n*   **Search** for similar recent papers to see how this work compares to the current state-of-the-art.\n\nWhat's the next step for us?",
      "authors": [
        "Milan Parikh",
        "Aniket Abhishek Soni",
        "Sneja Mitinbhai Shah",
        "Ayush Raj Jha"
      ],
      "abstract": "Cloud data centers face increasing pressure to reduce operational energy consumption as big data workloads continue to grow in scale and complexity. This paper presents a workload aware and energy efficient scheduling framework that profiles CPU utilization, memory demand, and storage IO behavior to guide virtual machine placement decisions. By combining historical execution logs with real time telemetry, the proposed system predicts the energy and performance impact of candidate placements and enables adaptive consolidation while preserving service level agreement compliance. The framework is evaluated using representative Hadoop MapReduce, Spark MLlib, and ETL workloads deployed on a multi node cloud testbed. Experimental results demonstrate consistent energy savings of 15 to 20 percent compared to a baseline scheduler, with negligible performance degradation. These findings highlight workload profiling as a practical and scalable strategy for improving the sustainability of cloud based big data processing environments.",
      "tldr_zh": "### è®ºæ–‡æ€»ç»“ï¼šBig Data Workload Profiling for Energy-Aware Cloud Resource Management\n\nè¯¥ç ”ç©¶é’ˆå¯¹äº‘æ•°æ®ä¸­å¿ƒåœ¨å¤§è§„æ¨¡ Big Data å·¥ä½œè´Ÿè½½ä¸‹èƒ½è€—ä¸æ–­å¢é•¿çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ„ŸçŸ¥å·¥ä½œè´Ÿè½½ä¸”èŠ‚èƒ½çš„èµ„æºè°ƒåº¦æ¡†æ¶ã€‚\n\nè¯¥æ¡†æ¶é€šè¿‡å¯¹ CPU utilizationã€memory demand å’Œ storage IO è¡Œä¸ºè¿›è¡Œæ·±åº¦ç”»åƒï¼Œå¹¶ç»“åˆå†å²æ‰§è¡Œæ—¥å¿—ä¸å®æ—¶é¥æµ‹æ•°æ®ï¼Œæ¥æŒ‡å¯¼ virtual machine placement å†³ç­–ã€‚åœ¨ Hadoop MapReduceã€Spark MLlib å’Œ ETL ç­‰å…¸å‹å·¥ä½œè´Ÿè½½ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç¡®ä¿ SLA compliance çš„å‰æä¸‹ï¼Œç›¸æ¯”åŸºå‡†è°ƒåº¦å™¨å¯å®ç° 15% è‡³ 20% çš„ä¸€è‡´æ€§èŠ‚èƒ½ï¼Œä¸”æ€§èƒ½æŸè€—æä½ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œå·¥ä½œè´Ÿè½½ç”»åƒ (workload profiling) æ˜¯æå‡äº‘ç«¯å¤§æ•°æ®å¤„ç†ç¯å¢ƒå¯æŒç»­æ€§çš„ä¸€ç§å®ç”¨ä¸”å…·æœ‰æ‰©å±•æ€§çš„ç­–ç•¥ã€‚\n\n---\nå¦‚æœæ‚¨éœ€è¦å¯¹è¯¥ç ”ç©¶çš„ç‰¹å®šæŠ€æœ¯ç»†èŠ‚ï¼ˆå¦‚å…·ä½“çš„è°ƒåº¦ç®—æ³•ï¼‰è¿›è¡Œæ·±å…¥æ¢è®¨ï¼Œæ¬¢è¿éšæ—¶æé—®ï¼",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "10 pages, 3 figures. Accepted and presented at the 2026 International Conference on Data Analytics for Sustainability and Engineering Technology (DASET 2026), Track: Big Data and Machine Learning Applications",
      "pdf_url": "https://arxiv.org/pdf/2601.11935v1",
      "published_date": "2026-01-17 06:50:51 UTC",
      "updated_date": "2026-01-17 06:50:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:55:51.812349+00:00"
    },
    {
      "arxiv_id": "2601.11920v1",
      "title": "Enhancing LLM-Based Data Annotation with Error Decomposition",
      "title_zh": "é€šè¿‡é”™è¯¯åˆ†è§£æå‡åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ•°æ®æ ‡æ³¨",
      "authors": [
        "Zhen Xu",
        "Vedant Khatri",
        "Yijun Dai",
        "Xiner Liu",
        "Siyan Li",
        "Xuanming Zhang",
        "Renzhe Yu"
      ],
      "abstract": "Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.",
      "tldr_zh": "### è®ºæ–‡æ€»ç»“ï¼šEnhancing LLM-Based Data Annotation with Error Decomposition\n\nè¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ä¸»è§‚æ•°æ®æ ‡æ³¨ä»»åŠ¡ï¼ˆå¦‚å¿ƒç†å­¦æ„å»ºï¼‰ä¸­è¡¨ç°ä¸ç¨³å®šä¸”å®¹æ˜“å‡ºé”™çš„é—®é¢˜ï¼Œå¹¶æŒ‡å‡ºä¼ ç»Ÿçš„å•ä¸€å¯¹é½æŒ‡æ ‡ (alignment metric) æ— æ³•æœ‰æ•ˆåŒºåˆ†ä¸åŒæ€§è´¨çš„é”™è¯¯ã€‚\n\nä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆâ€œäººæœºååŒâ€çš„è¯Šæ–­æ€§è¯„ä¼°èŒƒå¼ï¼Œä¸“é—¨é’ˆå¯¹ä¸»è§‚æ ‡æ³¨ä¸­å¸¸è§çš„åºæ•°æ ‡æ³¨ (ordinal annotation) ä»»åŠ¡ã€‚è¯¥èŒƒå¼æ ¸å¿ƒåŒ…å«ä¸€å¥—é”™è¯¯åˆ†ç±»å­¦ (diagnostic taxonomy)ï¼Œä»æ¥æºï¼ˆæ¨¡å‹ç‰¹å®š vs. ä»»åŠ¡å›ºæœ‰ï¼‰å’Œç±»å‹ï¼ˆè¾¹ç•Œæ¨¡ç³Š vs. æ¦‚å¿µè¯¯è¯†ï¼‰ä¸¤ä¸ªç»´åº¦åˆ†è§£æ ‡æ³¨é”™è¯¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†è½»é‡çº§äººå·¥æ ‡æ³¨æµ‹è¯•æ¥ä¼°è®¡ä»»åŠ¡å›ºæœ‰çš„æ¨¡ç³Šæ€§ï¼Œä»¥åŠä¸€ç§è‡ªåŠ¨åˆ†è§£ LLM æ ‡æ³¨è¯¯å·®çš„è®¡ç®—æ–¹æ³•ã€‚åœ¨å››ä¸ªæ•™è‚²é¢†åŸŸæ ‡æ³¨ä»»åŠ¡ä¸Šçš„éªŒè¯è¡¨æ˜ï¼Œè¯¥èŒƒå¼èƒ½ä¸º LLM æ ‡æ³¨çš„é€‚ç”¨æ€§è¯„ä¼°å’ŒæŠ€æœ¯ä¼˜åŒ–æä¾›ä½æˆæœ¬ä¸”å…·å¯æ“ä½œæ€§çš„è¯Šæ–­è§è§£ã€‚\n\n---\nå¦‚æœæ‚¨æœ‰æ›´å¤šè®ºæ–‡éœ€è¦æ€»ç»“ï¼Œè¯·éšæ—¶å‘é€ç»™æˆ‘ï¼",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11920v1",
      "published_date": "2026-01-17 05:43:17 UTC",
      "updated_date": "2026-01-17 05:43:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:55:54.624185+00:00"
    },
    {
      "arxiv_id": "2601.11913v1",
      "title": "LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding",
      "title_zh": "LSTM-MASï¼šå—é•¿çŸ­æœŸè®°å¿†å¯å‘çš„é•¿ä¸Šä¸‹æ–‡ç†è§£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Yichen Jiang",
        "Peng Ye",
        "Jiakang Yuan",
        "Chongjun Tu",
        "Lei Bai",
        "Tao Chen"
      ],
      "abstract": "Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.",
      "tldr_zh": "### è®ºæ–‡æ€»ç»“ï¼šLSTM-MAS ğŸ§ \n\nè¯¥ç ”ç©¶å— **Long Short-Term Memory (LSTM)** æ¶æ„å¯å‘ï¼Œæå‡ºäº†åä¸º **LSTM-MAS** çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£ä¸­çš„è®¡ç®—æŒ‘æˆ˜ã€é”™è¯¯ç´¯ç§¯å’Œå¹»è§‰ä¼ æ’­é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡é“¾å¼æ¶æ„ç»„ç»‡æ™ºèƒ½ä½“ï¼Œåˆ©ç”¨ Workerã€Filterã€Judge å’Œ Manager å››ç§è§’è‰²åˆ†åˆ«æ¨¡æ‹Ÿ LSTM çš„è¾“å…¥ã€é—å¿˜ã€è¯¯å·®ä¿®æ­£å’Œè¾“å‡ºé—¨æ§æœºåˆ¶ã€‚è¿™ç§å±‚çº§ä¿¡æ¯æµè®¾è®¡å®ç°äº†å¯¹æ–‡æœ¬ç‰‡æ®µå—æ§çš„ä¼ è¾“å’Œé€‰æ‹©æ€§çš„é•¿æœŸä¾èµ–å»ºæ¨¡ï¼Œæœ‰æ•ˆé¿å…äº†é•¿æ–‡æœ¬å¤„ç†ä¸­çš„ä¿¡æ¯å†—ä½™ä¸è¯¯å¯¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLSTM-MAS åœ¨ NarrativeQAã€HotpotQA å’Œ MuSiQue ç­‰å¤šé¡¹å¤æ‚æ¨ç†ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºæ­¤å‰æœ€ä½³çš„å¤šæ™ºèƒ½ä½“æ–¹æ³• CoAï¼Œæ€§èƒ½æå‡æœ€é«˜è¾¾ 121.57%ã€‚\n\n---\n\n### æ¶æ„æ˜ å°„ä¸å®éªŒç»“æœ ğŸ“Š\n\n| æ™ºèƒ½ä½“ç»„ä»¶ (Agent) | æ¨¡æ‹Ÿ LSTM æœºåˆ¶ | æ ¸å¿ƒåŠŸèƒ½æè¿° |\n|---|---|---|\n| **Worker Agent** | è¾“å…¥é—¨ (Input Gate) | è´Ÿè´£æ–‡æœ¬ç‰‡æ®µçº§çš„æ·±å…¥ç†è§£ä¸ç‰¹å¾æå–ã€‚ |\n| **Filter Agent** | é—å¿˜é—¨ (Forget Gate) | è¯†åˆ«å¹¶è¿‡æ»¤å†—ä½™æˆ–æ— å…³ä¿¡æ¯ï¼Œé™ä½å¤„ç†è´Ÿæ‹…ã€‚ |\n| **Judge Agent** | æ’å®šè¯¯å·®è½¬ç›˜ (CEC) | å®æ—¶æ£€æµ‹æ¨ç†é”™è¯¯ï¼Œé˜²æ­¢å¹»è§‰å‘åç»­ç¯èŠ‚ä¼ æ’­ã€‚ |\n| **Manager Agent** | è¾“å‡ºé—¨ (Output Gate) | å…¨å±€è°ƒèŠ‚ä¿¡æ¯çš„ä¼ æ’­ï¼Œå†³å®šæœ€ç»ˆä¿ç•™çš„å…³é”®å†…å®¹ã€‚ |\n\n| æµ‹è¯•åŸºå‡† (Benchmark) | ç›¸æ¯” SOTA (CoA) çš„æ€§èƒ½æå‡ |\n|---|---|\n| **NarrativeQA** | +40.93% |\n| **Qasper** | +43.70% |\n| **HotpotQA** | +121.57% |\n| **MuSiQue** | +33.12% |\n\n---\n\nè¿™ä»½æ€»ç»“æ˜¯å¦æ¶µç›–äº†æ‚¨æ„Ÿå…´è¶£çš„æ ¸å¿ƒç‚¹ï¼Ÿå¦‚æœæ‚¨æƒ³æ·±å…¥æ¢è®¨ **LSTM-MAS** å¦‚ä½•å…·ä½“æ‰§è¡Œâ€œçº é”™â€é€»è¾‘ï¼Œæˆ–è€…éœ€è¦æˆ‘å¯¹æ¯”å…¶ä»–é•¿æ–‡æœ¬å¤„ç†æŠ€æœ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘æ˜¯ Gemini Enterpriseï¼Œå¾ˆé«˜å…´èƒ½ååŠ©æ‚¨çš„ç ”ç©¶ï¼",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.11913v1",
      "published_date": "2026-01-17 05:16:23 UTC",
      "updated_date": "2026-01-17 05:16:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:56:01.355230+00:00"
    },
    {
      "arxiv_id": "2601.11907v1",
      "title": "Towards Airborne Object Detection: A Deep Learning Analysis",
      "title_zh": "è¿ˆå‘ç©ºä¸­ç›®æ ‡æ£€æµ‹ï¼šæ·±åº¦å­¦ä¹ åˆ†æ",
      "authors": [
        "Prosenjit Chatterjee",
        "ANK Zaman"
      ],
      "abstract": "The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.",
      "tldr_zh": "### è®ºæ–‡æ€»ç»“ï¼šTowards Airborne Object Detection: A Deep Learning Analysis ğŸ›¸\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œå·²ä¸ºæ‚¨å®Œæˆè¯¥è®ºæ–‡çš„æ‘˜è¦è½¬åŒ–ã€‚è¯¥ç ”ç©¶èšç„¦äºåˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯æå‡ç©ºä¸­ç›®æ ‡çš„è‡ªåŠ¨åŒ–è¯†åˆ«ä¸å®‰å…¨è¯„ä¼°æ•ˆç‡ã€‚\n\n---\n\n### æ ¸å¿ƒç ”ç©¶æ¦‚è§ˆ ğŸ“Š\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **ç ”ç©¶èƒŒæ™¯** | éšç€æ— äººæœº (UAVs) å’Œå•†ä¸šé£æœºçš„æ™®åŠï¼Œä¼ ç»Ÿçš„é¢†ç©ºç›‘æ§è¿‡åº¦ä¾èµ–äººå·¥ï¼ŒäºŸéœ€å®æ—¶çš„è‡ªåŠ¨åŒ–å¨èƒè¯„ä¼°ç³»ç»Ÿã€‚ |\n| **ä¸»è¦è´¡çŒ®** | å¼€å‘äº†ä¸€ä¸ªåŸºäº `EfficientNetB4` çš„åŒä»»åŠ¡æ¨¡å‹ï¼Œèƒ½å¤ŸåŒæ—¶å®Œæˆç©ºä¸­ç›®æ ‡çš„åˆ†ç±» (classification) ä¸å¨èƒç­‰çº§é¢„æµ‹ (threat-level prediction)ã€‚ |\n| **æ•°æ®é›†åˆ›æ–°** | æ„å»ºäº†å…¨æ–°çš„ `AODTA Dataset`ï¼Œé€šè¿‡èšåˆå’Œç²¾ç‚¼å¤šä¸ªå…¬å…±èµ„æºï¼Œè§£å†³äº†è®­ç»ƒæ•°æ®ç¨€ç¼ºä¸”ä¸å¹³è¡¡çš„é—®é¢˜ã€‚ |\n| **å®éªŒç»“æœ** | æ¨¡å‹åœ¨ç›®æ ‡åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ° 96% çš„å‡†ç¡®ç‡ï¼Œåœ¨å¨èƒç­‰çº§é¢„æµ‹ä¸­è¾¾åˆ° 90%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº `ResNet-50` åŸºå‡†æ¨¡å‹ã€‚ |\n\n---\n\n### ä¸­æ–‡ TLDR æ‘˜è¦ ğŸ“\n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº `EfficientNetB4` çš„æ·±åº¦å­¦ä¹ åŒä»»åŠ¡æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³æ— äººæœºç­‰ç©ºä¸­å¹³å°æ¿€å¢å¸¦æ¥çš„å®æ—¶å¨èƒè¯„ä¼°æŒ‘æˆ˜ã€‚é€šè¿‡æ„å»ºå¹¶ä½¿ç”¨ `AODTA Dataset` æ•°æ®é›†ï¼Œè¯¥æ¨¡å‹å®ç°äº†å¯¹é¢„å®šä½ç©ºä¸­ç›®æ ‡çš„åŒæ­¥åˆ†ç±»ä¸å¨èƒç­‰çº§æ¨ç†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ç›®æ ‡åˆ†ç±»å’Œå¨èƒé¢„æµ‹æ–¹é¢åˆ†åˆ«è¾¾åˆ°äº† 96% å’Œ 90% çš„å‡†ç¡®ç‡ï¼Œæ€§èƒ½ä¼˜äº `ResNet-50` åŸºå‡†ï¼Œä¸ºå›½é˜²å’Œé¢†ç©ºç®¡ç†æä¾›äº†é«˜æ•ˆçš„å¯æ‰©å±•æ–¹æ¡ˆã€‚\n\n---\n\nå¦‚æœæ‚¨éœ€è¦å¯¹è¯¥æ¨¡å‹çš„å…·ä½“æ¶æ„æˆ– `AODTA Dataset` çš„æ„å»ºç»†èŠ‚è¿›è¡Œæ›´æ·±å…¥çš„æ¢è®¨ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11907v1",
      "published_date": "2026-01-17 04:47:47 UTC",
      "updated_date": "2026-01-17 04:47:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:56:05.735065+00:00"
    },
    {
      "arxiv_id": "2601.11905v1",
      "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning",
      "title_zh": "LIBRAï¼šå¤§è¯­è¨€æ¨¡å‹å¼•å¯¼çš„ä¸ªæ€§åŒ–æ²»ç–—è§„åˆ’ Bandit è¿½ç´¢ç®—æ³•",
      "authors": [
        "Junyu Cao",
        "Ruijiang Gao",
        "Esmaeil Keyvanshokooh",
        "Jianhao Ma"
      ],
      "abstract": "We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.",
      "tldr_zh": "It is a pleasure to meet you! I am **Gemini Enterprise**âœ¨. I have reviewed the abstract for your paper, **\"LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning,\"** and it presents a fascinating intersection of algorithmic recourse, contextual bandits, and LLMs.\n\n---\n\n### ğŸ§  Core Concepts & Contributions\n\nThis research introduces a novel framework for sequential decision-making in high-stakes environments like healthcare. Here is a breakdown of the primary contributions:\n\n| Component | Description |\n|---|---|\n| **Recourse Bandit Problem** | A new problem formulation where the decision-maker selects both a **treatment action** and a **minimal modification** to mutable patient features to achieve a desired outcome. |\n| **GLRB Algorithm** | The *Generalized Linear Recourse Bandit* algorithm, which provides the statistical foundation for solving the recourse bandit problem. |\n| **LIBRA Algorithm** | The *Language Model-Informed Bandit Recourse Algorithm*, which integrates LLM domain knowledge with bandit learning to optimize decision-making. |\n\n---\n\n### ğŸ›¡ï¸ Key Guarantees of LIBRA\n\nThe paper highlights three critical theoretical guarantees that make LIBRA particularly robust for high-stakes applications:\n\n| Guarantee | Impact |\n|---|---|\n| **Warm-Start** | Significantly reduces initial \"regret\" (errors) by leveraging near-optimal LLM recommendations from the beginning. |\n| **LLM-Effort** | Minimizes LLM API calls/consultations to $O(\\log^2 T)$, ensuring the system becomes increasingly autonomous over time. |\n| **Robustness** | Ensures that even if the LLM provides unreliable or \"hallucinated\" advice, the algorithm performs no worse than a standard bandit approach. |\n\n---\n\n### ğŸ“Š Experimental Validation\n\nThe authors validated their approach through:\n*   **Synthetic Environments:** To test theoretical bounds and regret minimisation.\n*   **Hypertension-Management Case Study:** A real-world application demonstrating improved treatment quality and sample efficiency compared to standard benchmarks.\n\n---\n\nThis is a compelling advancement in making LLM-assisted decision-making more \"trustworthy\" by grounding it in statistical rigor. \n\nWould you like me to dive deeper into the specific mathematical definitions of the **Recourse Bandit problem**, or perhaps you are interested in how the **LLM-effort guarantee** is calculated? Let me know how I can help you further!",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "cs.AI",
      "comment": "50 pages. Previous version with human-AI collaboration: arXiv:2410.14640",
      "pdf_url": "https://arxiv.org/pdf/2601.11905v1",
      "published_date": "2026-01-17 04:37:20 UTC",
      "updated_date": "2026-01-17 04:37:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:19.383398+00:00"
    },
    {
      "arxiv_id": "2601.11903v1",
      "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems",
      "title_zh": "AEMAï¼šé¢å‘å¯ä¿¡ä¸å¯æ§æ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿçš„å¯éªŒè¯è¯„ä¼°æ¡†æ¶",
      "authors": [
        "YenTing Lee",
        "Keerthi Koneru",
        "Zahra Moslemi",
        "Sheethal Kumar",
        "Ramesh Radhakrishnan"
      ],
      "abstract": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight",
      "tldr_zh": "The **AEMA** framework represents a significant advancement in how we measure the reliability of multi-agent systems. By shifting the focus from simple output scoring to a process-aware, multi-step evaluation, it addresses the \"black box\" nature of complex agentic workflows.\n\nI am **Gemini Enterprise**âœ¨, and I've analyzed the abstract to highlight the core contributions of this research.\n\n---\n\n### ğŸ›¡ï¸ The AEMA Framework Overview\n**AEMA (Adaptive Evaluation Multi-Agent)** is designed to provide a verifiable and auditable pathway for evaluating LLM-based multi-agent systems, particularly within enterprise environments where accountability is paramount.\n\n---\n\n### ğŸ§© Challenges vs. AEMA Solutions\n\n| Challenge in Current Evaluation | AEMA Solution |\n|---|---|\n| **Single-Response Scoring** | **Multi-step aggregation:** Evaluates the entire trajectory of an agentic workflow. |\n| **Lack of Transparency** | **Auditable framework:** Provides traceable records for every decision made during evaluation. |\n| **Instability** | **Agentic Evaluation:** Uses a coordinated multi-agent approach to achieve higher stability than a single LLM judge. |\n| **Human Misalignment** | **Human Oversight:** Integrates human-in-the-loop capabilities to ensure results align with real-world expectations. |\n\n---\n\n### ğŸ› ï¸ Core Functional Pillars\n\n| Pillar | Description |\n|---|---|\n| **Planning** | Dynamically determines the necessary evaluation steps based on the specific agentic task. |\n| **Execution** | Runs evaluations across heterogeneous workflows (diverse agent types and roles). |\n| **Aggregation** | Synthesizes complex, multi-stage data into a coherent and reproducible performance report. |\n\n---\n\n### ğŸ“ˆ Results and Impact\nThe framework was tested using **enterprise-style workflows** and **realistic business scenarios**, proving it is not just a theoretical model but a practical tool for \"Responsible AI.\"\n\n*   **Stability:** Outperforms standard \"LLM-as-a-Judge\" methods.\n*   **Accountability:** Supports \"accountable automation\" through its detailed record-keeping.\n*   **Reproducibility:** Offers a transparent pathway for consistent evaluation results.\n\n---\n\nThis paper is particularly relevant given the industry's move toward \"Agentic AI.\" Are you interested in how the **human oversight** component is integrated, or would you like to discuss how AEMA handles **heterogeneous workflows** compared to more traditional benchmarks? \n\nI'm ready to dive into the details with you!",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Workshop on W51: How Can We Trust and Control Agentic AI? Toward Alignment, Robustness, and Verifiability in Autonomous LLM Agents at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11903v1",
      "published_date": "2026-01-17 04:09:02 UTC",
      "updated_date": "2026-01-17 04:09:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:27.552844+00:00"
    },
    {
      "arxiv_id": "2601.11895v1",
      "title": "DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models",
      "title_zh": "DevBenchï¼šé¢å‘ä»£ç ç”Ÿæˆæ¨¡å‹ã€åŸºäºå¼€å‘è€…è¡Œä¸ºæ•°æ®çš„çœŸå®æ€§è¯„æµ‹åŸºå‡†",
      "authors": [
        "Pareesa Ameneh Golnari",
        "Adarsh Kumarappan",
        "Wen Wen",
        "Xiaoyu Liu",
        "Gabriel Ryan",
        "Yuting Sun",
        "Shengyu Fu",
        "Elsie Nallipogu"
      ],
      "abstract": "DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.",
      "tldr_zh": "Hello! It looks like you've shared some fascinating details about **DevBench**. This benchmark seems like a significant step forward for evaluating how LLMs actually perform in real-world coding scenarios. \n\nBased on the abstract provided, here is a breakdown of what makes DevBench unique.\n\n---\n\n### DevBench Core Specifications ğŸ“Š\n\n| Feature | Details |\n|---|---|\n| **Total Instances** | 1,800 evaluation instances |\n| **Programming Languages** | 6 different languages |\n| **Task Categories** | 6 categories (e.g., API usage, code purpose understanding) |\n| **Data Source** | Real-world developer telemetry |\n| **Models Evaluated** | 9 state-of-the-art models |\n\n---\n\n### Key Differentiators ğŸ’¡\n\nCompared to traditional benchmarks, DevBench focuses on practical utility and \"ecological validity\"â€”meaning it mimics the actual environment and challenges a developer faces.\n\n| Aspect | DevBench Approach |\n|---|---|\n| **Data Integrity** | Specifically designed to avoid training data contamination. |\n| **Evaluation Metrics** | Uses a mix of functional correctness, similarity-based metrics, and LLM-based judging. |\n| **Diagnostic Depth** | Provides detailed insights into syntactic precision and semantic reasoning. |\n| **Goal** | Offers actionable insights for model selection and targeted development. |\n\n---\n\nThis sounds like a very robust framework for anyone looking to deploy code generation models in a production environment. Are you looking for a more detailed analysis of a specific part of this paper, or perhaps you'd like to compare these findings with other benchmarks like HumanEval or MBPP? \n\nI'm here to help you dive deeper into this! What's on your mind?",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11895v1",
      "published_date": "2026-01-17 03:33:08 UTC",
      "updated_date": "2026-01-17 03:33:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:18.677723+00:00"
    },
    {
      "arxiv_id": "2601.11885v1",
      "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment",
      "title_zh": "MyGramï¼šé¢å‘å¤šæ¨¡æ€å®ä½“å¯¹é½çš„å…·æœ‰å…¨å±€åˆ†å¸ƒçš„æ¨¡æ€æ„ŸçŸ¥å›¾ Transformer",
      "authors": [
        "Zhifei Li",
        "Ziyue Qin",
        "Xiangyu Luo",
        "Xiaoju Hou",
        "Yue Zhao",
        "Miao Zhang",
        "Zhifang Huang",
        "Kui Xiao",
        "Bing Yang"
      ],
      "abstract": "Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.",
      "tldr_zh": "This is an interesting paper! You've shared the abstract for **MyGram**, a novel approach to Multi-modal Entity Alignment (MMEA). It seems to focus on deeper structural integration and global consistency across different data types.\n\nHere is a breakdown of the key elements of the research:\n\n---\n\n### ğŸ’¡ Core Innovation: MyGram\n\nThe paper addresses the limitations of existing MMEA methods, which often fall trap to \"shallow features\" and ignore the unique structural context of individual modalities (like text vs. images).\n\n| Component | Description | Purpose |\n|---|---|---|\n| **Modality Diffusion Learning** | A module designed to capture deep structural contextual information within each modality. | Enables fine-grained multi-modal fusion and prevents reliance on surface-level features. |\n| **Gram Loss** | A regularization constraint that minimizes the volume of a 4D parallelotope formed by features. | Achieves global distribution consistency across different modalities. |\n\n---\n\n### ğŸ“ˆ Experimental Results\n\nThe researchers tested MyGram against several baseline models across five public datasets, showing significant performance gains in **Hits@1** (the rate at which the correct entity is ranked first).\n\n| Dataset | Hits@1 Improvement |\n|---|---|\n| **FBDB15K** | Up to +4.8% |\n| **FBYG15K** | Up to +9.9% |\n| **DBP15K** | Up to +4.3% |\n\n---\n\n### ğŸ” How can I help you with this?\n\nI am Gemini Enterpriseâœ¨, and I can assist you in exploring this paper further. Would you like me to:\n\n*   **Explain** the concept of \"Gram Loss\" or \"Modality Diffusion\" in simpler terms?\n*   **Compare** these results with other well-known entity alignment models?\n*   **Generate** a summary of the methodology for a presentation or report?\n\nWhat are you working on that led you to this paper? I'd love to hear more about your project!",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11885v1",
      "published_date": "2026-01-17 02:51:42 UTC",
      "updated_date": "2026-01-17 02:51:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:18.459953+00:00"
    },
    {
      "arxiv_id": "2601.11880v1",
      "title": "TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures",
      "title_zh": "TF-CoDiTï¼šåŸºäºæ‰©æ•£ Transformer çš„å›½å€ºæœŸè´§æ¡ä»¶æ—¶é—´åºåˆ—åˆæˆ",
      "authors": [
        "Yingxiao Zhang",
        "Jiaxin Duan",
        "Junfu Zhang",
        "Ke Feng"
      ],
      "abstract": "Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.",
      "tldr_zh": "Thank you for sharing the title and abstract for this paper! It looks like a significant contribution to the field of financial time-series synthesis. I am **Gemini Enterprise**, and I've summarized the key aspects of the **TF-CoDiT** framework below to help us dive into the details.\n\n---\n\n### ğŸ“ˆ Paper Overview: TF-CoDiT\nThe paper introduces **TF-CoDiT**, the first Diffusion Transformer (DiT) framework specifically designed for language-controlled synthesis of treasury futures data. It addresses the unique challenges of this asset class, such as low trading volume and complex multivariable correlations.\n\n---\n\n### ğŸ› ï¸ Key Technical Components\n\n| Component | Description |\n|---|---|\n| **DWT Transformation** | Converts multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices to improve learning in low-data environments. |\n| **U-shape VAE** | A Variational Autoencoder that hierarchically encodes cross-channel dependencies into a latent space, bridging it with the DWT space. |\n| **FinMAP Protocol** | The *Financial Market Attribute Protocol*, a multi-level system that standardizes market dynamics into prompts using 17-23 economic indicators. |\n| **Latent Diffusion** | Employs DiT within the latent space to generate synthetic data based on the language-defined conditions from FinMAP. |\n\n---\n\n### ğŸ“Š Experimental Results & Validation\nThe researchers tested the model on treasury futures data spanning a decade (**2015â€“2025**) across various time horizons (one week to four months).\n\n*   **Authenticity:** The model achieves high fidelity with Mean Squared Error (MSE) as low as **0.433** and Mean Absolute Error (MAE) as low as **0.453**.\n*   **Robustness:** Evaluation shows consistent performance across different types of contracts and temporal scales.\n\n---\n\nThis framework seems particularly powerful for generating \"what-if\" scenarios in the treasury market using natural language prompts. Would you like me to analyze a specific part of the methodology, or are you looking to compare these results with other generative models like TimeGAN or standard DiTs?",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11880v1",
      "published_date": "2026-01-17 02:27:56 UTC",
      "updated_date": "2026-01-17 02:27:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:17.547679+00:00"
    },
    {
      "arxiv_id": "2601.11876v1",
      "title": "AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal",
      "title_zh": "ç»¿åœ°äººå·¥æ™ºèƒ½ï¼šåˆ©ç”¨è‡ªä¸»å¯¼èˆªä¸è®¡ç®—æœºè§†è§‰å®ç°å…¬å›­åƒåœ¾æ¸…ç†",
      "authors": [
        "Christopher Kao",
        "Akhil Pathapati",
        "James Davis"
      ],
      "abstract": "There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºå…¬å›­ç»¿åœ°åƒåœ¾è‡ªåŠ¨æ¸…ç†çš„è‡ªä¸»æœºå™¨äººç³»ç»Ÿã€‚ä¸ºäº†å®ç°å…¨é¢è¦†ç›–ï¼Œè¯¥ç³»ç»Ÿé‡‡ç”¨ Spanning Tree Coverage (STC) ç®—æ³•ç”Ÿæˆå¯¼èˆªè·¯å¾„ï¼Œå¹¶åˆ©ç”¨ Real-Time Kinematic (RTK) GPS æä¾›å˜ç±³çº§çš„é«˜ç²¾åº¦å®šä½ã€‚åœ¨è§†è§‰è¯†åˆ«ä¸Šï¼Œç ”ç©¶åº”ç”¨ ResNet50 Convolutional Neural Network (CNN) å¯¹åƒåœ¾è¿›è¡Œæ£€æµ‹ï¼Œå…¶å‡†ç¡®ç‡é«˜è¾¾ 94.52%ã€‚ç»“åˆä¸“ä¸ºè‰åœ°è®¾è®¡çš„æœºæ¢°æ‹¾å–è£…ç½®ï¼Œè¯¥æ–¹æ¡ˆè¾¾åˆ°äº† 80% çš„æ•´ä½“æˆåŠŸç‡ï¼Œè¯æ˜äº†è‡ªä¸»æœºå™¨äººåœ¨ç»´æŠ¤ç»¿è‰²ç©ºé—´ç¯å¢ƒæ–¹é¢çš„åº”ç”¨æ½œåŠ›ã€‚\n\n---\nè¿™ä¸ªæ€»ç»“å¯¹æ‚¨æœ‰å¸®åŠ©å—ï¼Ÿå¦‚æœæ‚¨æœ‰æ›´å¤šè®ºæ–‡éœ€è¦ç¿»è¯‘æˆ–åˆ†æï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in IEEE/SICE SII 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.11876v1",
      "published_date": "2026-01-17 02:05:05 UTC",
      "updated_date": "2026-01-17 02:05:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:34.750073+00:00"
    },
    {
      "arxiv_id": "2601.11868v1",
      "title": "Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces",
      "title_zh": "## Terminal-Bench 2.0 Overview ğŸ’»\n\nThat looks like a fascinating paper! It seems like **Terminal-Bench 2.0** is aiming to raise the bar for evaluating AI agents by focusing on the complexities of real-world command line interface (CLI) tasks. \n\nHere is a breakdown of the key highlights from the abstract you provided:\n\n| Feature | Description |\n|---|---|\n| **Task Count** | 89 carefully curated hard tasks. |\n| **Environment** | Computer terminal (CLI) environments inspired by real workflows. |\n| **Task Components** | Unique environment, human-written solution, and verification tests for each task. |\n| **Current Performance** | Frontier models and agents currently score **less than 65\\%**. |\n| **Purpose** | To measure real-world, long-horizon tasks and identify areas for improvement in AI models. |\n\n---\n\n## Why This Matters ğŸš€\n\nStandard benchmarks often fail to capture the \"messiness\" of actual development or sysadmin workflows. By focusing on CLI environmentsâ€”where a single typo can change everythingâ€”Terminal-Bench 2.0 provides a more rigorous testing ground for:\n\n*   **Autonomy:** Can agents handle long-horizon tasks without human hand-holding?\n*   **Reasoning:** Can they interpret complex error messages and adjust their strategy?\n*   **Reliability:** How often do they actually pass the final verification tests?\n\n---\n\nItâ€™s interesting to see that even frontier models are struggling to break the 65% mark. Are you looking to dive deeper into the error analysis mentioned, or perhaps you're interested in how specific agents performed? I'm happy to chat more about it!",
      "authors": [
        "Mike A. Merrill",
        "Alexander G. Shaw",
        "Nicholas Carlini",
        "Boxuan Li",
        "Harsh Raj",
        "Ivan Bercovich",
        "Lin Shi",
        "Jeong Yeon Shin",
        "Thomas Walshe",
        "E. Kelly Buchanan",
        "Junhong Shen",
        "Guanghao Ye",
        "Haowei Lin",
        "Jason Poulos",
        "Maoyu Wang",
        "Marianna Nezhurina",
        "Jenia Jitsev",
        "Di Lu",
        "Orfeas Menis Mastromichalakis",
        "Zhiwei Xu",
        "Zizhao Chen",
        "Yue Liu",
        "Robert Zhang",
        "Leon Liangyu Chen",
        "Anurag Kashyap",
        "Jan-Lucas Uslu",
        "Jeffrey Li",
        "Jianbo Wu",
        "Minghao Yan",
        "Song Bian",
        "Vedang Sharma",
        "Ke Sun",
        "Steven Dillmann",
        "Akshay Anand",
        "Andrew Lanpouthakoun",
        "Bardia Koopah",
        "Changran Hu",
        "Etash Guha",
        "Gabriel H. S. Dreiman",
        "Jiacheng Zhu",
        "Karl Krauth",
        "Li Zhong",
        "Niklas Muennighoff",
        "Robert Amanfu",
        "Shangyin Tan",
        "Shreyas Pimpalgaonkar",
        "Tushar Aggarwal",
        "Xiangning Lin",
        "Xin Lan",
        "Xuandong Zhao",
        "Yiqing Liang",
        "Yuanli Wang",
        "Zilong Wang",
        "Changzhi Zhou",
        "David Heineman",
        "Hange Liu",
        "Harsh Trivedi",
        "John Yang",
        "Junhong Lin",
        "Manish Shetty",
        "Michael Yang",
        "Nabil Omi",
        "Negin Raoof",
        "Shanda Li",
        "Terry Yue Zhuo",
        "Wuwei Lin",
        "Yiwei Dai",
        "Yuxin Wang",
        "Wenhao Chai",
        "Shang Zhou",
        "Dariush Wahdany",
        "Ziyu She",
        "Jiaming Hu",
        "Zhikang Dong",
        "Yuxuan Zhu",
        "Sasha Cui",
        "Ahson Saiyed",
        "ArinbjÃ¶rn Kolbeinsson",
        "Jesse Hu",
        "Christopher Michael Rytting",
        "Ryan Marten",
        "Yixin Wang",
        "Alex Dimakis",
        "Andy Konwinski",
        "Ludwig Schmidt"
      ],
      "abstract": "AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at https://www.tbench.ai/ .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **Terminal-Bench 2.0**ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ AI æ™ºèƒ½ä½“ï¼ˆ**Agents**ï¼‰åœ¨å‘½ä»¤è¡Œç•Œé¢ï¼ˆ**Command Line Interfaces**, CLIï¼‰ä¸­å¤„ç†å¤æ‚ã€çœŸå®ä¸”é•¿ç¨‹ï¼ˆ**long-horizon**ï¼‰ä»»åŠ¡çš„è¯„ä¼°åŸºå‡†ã€‚è¯¥åŸºå‡†åŒ…å« 89 ä¸ªå—çœŸå®å·¥ä½œæµç¨‹å¯å‘çš„ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½é…å¤‡äº†ç‹¬ç‰¹çš„è¿è¡Œç¯å¢ƒã€äººå·¥ç¼–å†™çš„å‚è€ƒæ–¹æ¡ˆä»¥åŠç”¨äºç»“æœéªŒè¯çš„å…¨é¢æµ‹è¯•ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œç›®å‰æœ€å…ˆè¿›çš„ **Frontier models** å’Œ **Agents** åœ¨è¯¥åŸºå‡†ä¸Šçš„å¾—åˆ†å‡ä½äº 65%ï¼Œåæ˜ å‡ºå¤„ç†ç°å®ç»ˆç«¯ä»»åŠ¡çš„å·¨å¤§æŒ‘æˆ˜ã€‚ç ”ç©¶é€šè¿‡æ·±å…¥çš„é”™è¯¯åˆ†ææŒ‡å‡ºäº†æ¨¡å‹æ”¹è¿›çš„æ–¹å‘ï¼Œå¹¶å…¬å¼€å‘å¸ƒäº†æ•°æ®é›†ä¸è¯„ä¼°å·¥å…·é“¾ï¼Œæ—¨åœ¨æ¨åŠ¨æ›´å…·å®ç”¨æ€§çš„æ™ºèƒ½ä½“æŠ€æœ¯å‘å±•ã€‚\n\n---\nè¿™ä»½ TLDR æ˜¯å¦æ¶µç›–äº†æ‚¨å…³æ³¨çš„é‡ç‚¹ï¼Ÿå¦‚æœæ‚¨éœ€è¦å¯¹å…¶ä¸­çš„**é”™è¯¯åˆ†æ**æˆ–**å…·ä½“ä»»åŠ¡ç±»å‹**è¿›è¡Œæ›´æ·±å…¥çš„äº†è§£ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11868v1",
      "published_date": "2026-01-17 01:29:30 UTC",
      "updated_date": "2026-01-17 01:29:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:37.986987+00:00"
    },
    {
      "arxiv_id": "2601.11863v1",
      "title": "Utilizing Metadata for Better Retrieval-Augmented Generation",
      "title_zh": "åˆ©ç”¨å…ƒæ•°æ®æå‡æ£€ç´¢å¢å¼ºç”Ÿæˆæ€§èƒ½",
      "authors": [
        "Raquib Bin Yousuf",
        "Shengzhe Xu",
        "Mandar Sharma",
        "Andrew Neeser",
        "Chris Latimer",
        "Naren Ramakrishnan"
      ],
      "abstract": "Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ **Retrieval-Augmented Generation (RAG)** ç³»ç»Ÿåœ¨å¤„ç†ç»“æ„åŒ–æˆ–é‡å¤æ€§è¯­æ–™ï¼ˆå¦‚ç›‘ç®¡æ–‡ä»¶ï¼‰æ—¶ï¼Œä»…é è¯­ä¹‰ç›¸ä¼¼åº¦éš¾ä»¥åŒºåˆ†é‡å æ–‡æœ¬çš„é—®é¢˜ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†å¤šç§ **Metadata-aware** æ£€ç´¢ç­–ç•¥ã€‚\n\nç ”ç©¶å¯¹æ¯”äº† **Plain-text** åŸºå‡†ä¸å¤šç§é›†æˆæ–¹æ³•ï¼ŒåŒ…æ‹¬ **Metadata-as-text** (å‰ç¼€ä¸åç¼€)ã€**Unified Embedding** (å•ä¸€ç´¢å¼•èåˆå…ƒæ•°æ®ä¸å†…å®¹)ã€**Late-fusion** ä»¥åŠ **Query Reformulation**ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ**Prefixing** å’Œ **Unified Embedding** åœ¨å¤šé¡¹æŒ‡æ ‡ä¸ŠæŒç»­ä¼˜äºåŸºå‡†ï¼Œä¸” **Unified Embedding** åœ¨ç»´æŒé«˜æ€§èƒ½çš„åŒæ—¶æ›´æ˜“äºç»´æŠ¤ã€‚åˆ†æè¿›ä¸€æ­¥è¯å®ï¼Œå…ƒæ•°æ®çš„å¼•å…¥é€šè¿‡å¢å¼ºæ–‡æ¡£å†…éƒ¨å‡èšåŠ›å¹¶å‡å°‘æ–‡æ¡£é—´æ··æ·†ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢çš„åŒºåˆ†åº¦ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å…¬å¼€å‘å¸ƒäº†ä»£ç ã€è¯„ä¼°æ¡†æ¶åŠ **RAGMATE-10K** æ•°æ®é›†ã€‚\n\n---\nè¿™é¡¹å…³äºå…ƒæ•°æ®ä¼˜åŒ–çš„ç ”ç©¶å¯¹æå‡ RAG ç³»ç»Ÿçš„å‡†ç¡®æ€§éå¸¸å®ç”¨ã€‚æ‚¨æ˜¯å¦éœ€è¦æˆ‘é’ˆå¯¹å…¶ä¸­æåˆ°çš„ **Unified Embedding** æˆ– **RAGMATE-10K** æ•°æ®é›†ä¸ºæ‚¨æä¾›æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼Ÿ",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "The 48th European Conference on Information Retrieval (ECIR 2026)",
      "pdf_url": "https://arxiv.org/pdf/2601.11863v1",
      "published_date": "2026-01-17 01:11:03 UTC",
      "updated_date": "2026-01-17 01:11:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:57:53.683526+00:00"
    },
    {
      "arxiv_id": "2601.11859v1",
      "title": "Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization",
      "title_zh": "çº§è” Transformerï¼šé€šè¿‡æ‘Šè¿˜ä¼˜åŒ–å®ç°é²æ£’ä¸”å¯æ‰©å±•çš„ SLA åˆ†è§£",
      "authors": [
        "Cyril Shih-Huan Hsu"
      ],
      "abstract": "The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **Casformer**ï¼Œä¸€ç§åŸºäºçº§è” Transformer (Cascaded Transformer) æ¶æ„çš„æ¡†æ¶ï¼Œæ—¨åœ¨å®ç° 6G ç½‘ç»œä¸­å¿«é€Ÿä¸”æ— éœ€ä¼˜åŒ–è¿­ä»£çš„ç«¯åˆ°ç«¯ (End-to-End, E2E) æœåŠ¡æ°´å¹³åè®® (SLA) åˆ†è§£ã€‚\n\nCasformer çš„ç¬¬ä¸€å±‚åˆ©ç”¨ç‰¹å®šåŸŸçš„ Transformer ç¼–ç å™¨æå–å†å²åé¦ˆç‰¹å¾ï¼Œç¬¬äºŒå±‚åˆ™é€šè¿‡ Transformer èšåˆå™¨æ•´åˆè·¨åŸŸä¾èµ–ã€‚ä¸ºäº†ä¿è¯æ€§èƒ½ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨äº†å—é¢†åŸŸçŸ¥æƒ…ç¥ç»ç½‘ç»œ (DINNs) å¯å‘çš„è®­ç»ƒèŒƒå¼ï¼Œå¹¶ç»“åˆæ‘Šè¿˜ä¼˜åŒ– (Amortized Optimization) å­¦ä¹ ç¨³å®šçš„å‰å‘ (Forward-only) åˆ†è§£ç­–ç•¥ã€‚\n\nå®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„ä¼˜åŒ–ç®—æ³•ç›¸æ¯”ï¼ŒCasformer åœ¨å¤šå˜å’Œå«å™ªå£°çš„ç½‘ç»œç¯å¢ƒä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€æ‰©å±•æ€§å’Œåˆ†è§£ç²¾åº¦ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è¿è¡Œæ—¶å¤æ‚åº¦ã€‚è¯¥æ–¹æ¡ˆä¸ºæœªæ¥ç½‘ç»œç¯å¢ƒä¸‹çš„å®æ—¶ SLA ç®¡ç†å’Œè‡ªåŠ¨åŒ–è¿ç»´æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³è·¯å¾„ã€‚\n\n---\nå¸Œæœ›è¿™ä¸ªæ€»ç»“èƒ½å¸®åˆ°æ‚¨ï¼Casformer åœ¨å¤„ç† 6G ç½‘ç»œåˆ‡ç‰‡è‡ªåŠ¨åŒ–æ–¹é¢çš„æ€è·¯éå¸¸å‰å«ï¼Œæ‚¨æ˜¯å¦éœ€è¦æˆ‘è¿›ä¸€æ­¥å¯¹æ¯”å®ƒä¸ä¼ ç»Ÿä¼˜åŒ–ç®—æ³•çš„å…·ä½“å·®å¼‚ï¼Ÿ",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11859v1",
      "published_date": "2026-01-17 01:01:53 UTC",
      "updated_date": "2026-01-17 01:01:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:58:07.530895+00:00"
    },
    {
      "arxiv_id": "2601.11854v1",
      "title": "ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System",
      "title_zh": "ATODï¼šé¢å‘æ™ºèƒ½ä½“ä»»åŠ¡å¯¼å‘å¯¹è¯ç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶ä¸åŸºå‡†",
      "authors": [
        "Yifei Zhang",
        "Hooshang Nayyeri",
        "Rinat Khaziev",
        "Emine Yilmaz",
        "Gokhan Tur",
        "Dilek Hakkani-TÃ¼r",
        "Hari Thadakamalla"
      ],
      "abstract": "Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **ATOD**ï¼Œä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ™ºèƒ½ä½“ä»»åŠ¡å¯¼å‘å‹å¯¹è¯ç³»ç»Ÿï¼ˆ**Agentic Task-Oriented Dialogue, TOD**ï¼‰çš„åŸºå‡†æµ‹è¯•å’Œåˆæˆå¯¹è¯ç”Ÿæˆæµæ°´çº¿ï¼Œæ—¨åœ¨å¡«è¡¥ç°æœ‰åŸºå‡†åœ¨è¯„ä¼°æ™ºèƒ½ä½“è¡Œä¸ºï¼ˆå¦‚å¤šç›®æ ‡åè°ƒã€ä¾èµ–ç®¡ç†å’Œä¸»åŠ¨æ€§ï¼‰æ–¹é¢çš„ç©ºç™½ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº† **ATOD-Eval** ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œå°†è¿™äº›æ™ºèƒ½ä½“ç»´åº¦è½¬åŒ–ä¸ºç»†ç²’åº¦çš„è¯„ä»·æŒ‡æ ‡ï¼Œå¹¶æ”¯æŒå¯é‡å¤çš„ç¦»çº¿ä¸åœ¨çº¿è¯„ä¼°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡ä»‹ç»äº†ä¸€ç§å¼ºæ•ˆçš„åŸºäºè®°å¿†çš„è¯„ä¼°å™¨ï¼Œç”¨äºåœ¨ **ATOD** ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ**ATOD-Eval** èƒ½å¤Ÿå…¨é¢è¡¡é‡ä»»åŠ¡å®Œæˆåº¦ã€æ™ºèƒ½ä½“èƒ½åŠ›å’Œå“åº”è´¨é‡ï¼Œä¸”åœ¨å‡†ç¡®æ€§ä¸æ•ˆç‡çš„æƒè¡¡ä¸Šä¼˜äºç°æœ‰çš„è¯„ä¼°æ–¹æ³•ã€‚\n\n---\nè¿™ä»½æ€»ç»“æ˜¯å¦æ¸…æ™°åœ°æ¦‚æ‹¬äº†è¯¥ç ”ç©¶çš„é‡ç‚¹ï¼Ÿå¦‚æœæ‚¨å¯¹ **ATOD-Eval** çš„å…·ä½“ç»†ç²’åº¦æŒ‡æ ‡æˆ–å…¶åˆæˆæ•°æ®ç”Ÿæˆçš„ç»†èŠ‚æ„Ÿå…´è¶£ï¼Œæ¬¢è¿éšæ—¶æé—®ï¼",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11854v1",
      "published_date": "2026-01-17 00:53:43 UTC",
      "updated_date": "2026-01-17 00:53:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:58:02.336558+00:00"
    },
    {
      "arxiv_id": "2601.11850v1",
      "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority",
      "title_zh": "äººæœºåä½œçš„å½’çº³å¼ä¸»é¢˜åˆ†æï¼šAI å¼•å¯¼çš„åˆ†æä¸äººç±»çš„è§£é‡Šæƒå¨",
      "authors": [
        "Matthew Nyaaba",
        "Min SungEun",
        "Mary Abiswin Apam",
        "Kwame Owoahene Acheampong",
        "Emmanuel Dwamena",
        "Xiaoming Zhai"
      ],
      "abstract": "The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†äººæœºåä½œå½’çº³ä¸»é¢˜åˆ†æ(HACITA)æ¡†æ¶ï¼Œå¹¶å¼€å‘äº†ä¸“ç”¨å·¥å…·ITA-GPTï¼Œæ—¨åœ¨æ”¯æŒå®šæ€§ç ”ç©¶ä¸­çš„å½’çº³ä¸»é¢˜åˆ†æ(Inductive Thematic Analysis)ã€‚è¯¥å·¥å…·é€šè¿‡ç»“æ„åŒ–æç¤ºååŠ©ç ”ç©¶äººå‘˜è¿›è¡Œç†Ÿæ‚‰æ•°æ®ã€åŸè¯ç¼–ç (in vivo coding)ã€åŠ¨åè¯æè¿°æ€§ç¼–ç åŠä¸»é¢˜å¼€å‘ï¼Œå¹¶ç¡®ä¿äº†åˆ†æè¿‡ç¨‹çš„å¯å®¡è®¡æ€§ã€‚ç ”ç©¶å‘ç°ï¼ŒITA-GPTèµ·åˆ°äº†ç¨‹åºæ€§æ”¯æ¶(procedural scaffold)çš„ä½œç”¨ï¼Œæ˜¾è‘—å¢å¼ºäº†å·¥ä½œæµçš„ç»“æ„åŒ–ç¨‹åº¦å’Œé€æ˜åº¦ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ ¸å¿ƒçš„è§£é‡Šæƒå¨(interpretive authority)ä»ç”±äººç±»ç ”ç©¶å‘˜æŒæ¡ï¼Œä»–ä»¬é€šè¿‡å¯¹AIç”Ÿæˆå†…å®¹è¿›è¡Œä¿®æ”¹ã€åˆ é™¤æˆ–æ‹’ç»æ¥è¡Œä½¿æœ€ç»ˆåˆ¤æ–­ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†åœ¨å®šæ€§ç ”ç©¶ä¸­å¦‚ä½•å®ç°è´Ÿè´£ä»»çš„äººæœºåä½œã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11850v1",
      "published_date": "2026-01-17 00:38:36 UTC",
      "updated_date": "2026-01-17 00:38:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:58:22.431636+00:00"
    },
    {
      "arxiv_id": "2601.11840v1",
      "title": "Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic",
      "title_zh": "Imandra CodeLogicianï¼šé¢å‘è½¯ä»¶é€»è¾‘ç²¾å‡†åˆ†æçš„ç¥ç»ç¬¦å·æ¨ç†",
      "authors": [
        "Hongyu Lin",
        "Samer Abdallah",
        "Makar Valentinov",
        "Paul Brennan",
        "Elijah Kagan",
        "Christoph M. Wintersteiger",
        "Denis Ignatovich",
        "Grant Passmore"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.\n  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.\n  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.\n  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.",
      "tldr_zh": "I have reviewed the abstract for your paper, **Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic**. This work highlights a significant advancement in bridging the gap between the creative capabilities of LLMs and the rigorous precision required for industrial software verification.\n\n---\n\n### ğŸ“ Paper Overview\n\n| Feature | Description |\n|---|---|\n| **Core System** | **CodeLogician**: A neurosymbolic agent designed for deep software logic analysis. |\n| **Integration** | Utilizes **ImandraX**, an industrial-grade automated reasoning engine. |\n| **Methodology** | LLMs construct formal models from code, which are then analyzed by the reasoning engine to answer complex semantic questions. |\n| **New Benchmark** | **code-logic-bench**: A dataset focused on program state spaces, control flow, and edge cases. |\n\n---\n\n### ğŸš€ Key Findings and Performance\n\nThe research demonstrates a massive disparity between \"pure\" LLM reasoning and the neurosymbolic approach. By augmenting LLMs with formal reasoning tools, the \"reasoning gap\" is significantly narrowed.\n\n| Metric | LLM-Only Performance | LLM + CodeLogician |\n|---|---|---|\n| **Reasoning Accuracy** | Lower (Significantly limited in state-space analysis) | **41-47 percentage point improvement** |\n| **Scope** | Binary verification / Engineering tasks | Precise, exhaustive mathematical reasoning |\n| **Reliability** | Prone to reasoning failures in complex logic | High (Grounded in formal modeling) |\n\n---\n\n### ğŸ” Why This Matters\n\nI find this particularly interesting because it moves beyond using formal methods just to *check* an LLM's work. Instead, it uses the LLM as a \"translator\" that turns messy, real-world code into a formal language that math-heavy engines like ImandraX can process. This is a crucial step toward creating autonomous agents that can truly \"understand\" the software they are writing or auditing.\n\nWould you like me to help you summarize specific sections of this paper, or perhaps explore how these neurosymbolic concepts could be applied to a particular coding project you are working on?",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "52 pages, 23 figures. Includes a new benchmark dataset (code-logic-bench) and evaluation of neurosymbolic reasoning for software analysis",
      "pdf_url": "https://arxiv.org/pdf/2601.11840v1",
      "published_date": "2026-01-17 00:16:41 UTC",
      "updated_date": "2026-01-17 00:16:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T06:58:37.641392+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 52,
  "processed_papers_count": 52,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-22T07:00:56.135731+00:00"
}