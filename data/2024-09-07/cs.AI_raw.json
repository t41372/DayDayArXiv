[
  {
    "arxiv_id": "2409.04934v2",
    "title": "Maximizing Relation Extraction Potential: A Data-Centric Study to Unveil Challenges and Opportunities",
    "authors": [
      "Anushka Swarup",
      "Avanti Bhandarkar",
      "Olivia P. Dizon-Paradis",
      "Ronald Wilson",
      "Damon L. Woodard"
    ],
    "abstract": "Relation extraction is a Natural Language Processing task that aims to\nextract relationships from textual data. It is a critical step for information\nextraction. Due to its wide-scale applicability, research in relation\nextraction has rapidly scaled to using highly advanced neural networks. Despite\ntheir computational superiority, modern relation extractors fail to handle\ncomplicated extraction scenarios. However, a comprehensive performance analysis\nof the state-of-the-art extractors that compile these challenges has been\nmissing from the literature, and this paper aims to bridge this gap. The goal\nhas been to investigate the possible data-centric characteristics that impede\nneural relation extraction. Based on extensive experiments conducted using 15\nstate-of-the-art relation extraction algorithms ranging from recurrent\narchitectures to large language models and seven large-scale datasets, this\nresearch suggests that modern relation extractors are not robust to complex\ndata and relation characteristics. It emphasizes pivotal issues, such as\ncontextual ambiguity, correlating relations, long-tail data, and fine-grained\nrelation distributions. In addition, it sets a marker for future directions to\nalleviate these issues, thereby proving to be a critical resource for novice\nand advanced researchers. Efficient handling of the challenges described can\nhave significant implications for the field of information extraction, which is\na critical part of popular systems such as search engines and chatbots. Data\nand relevant code can be found at\n\\url{https://aaig.ece.ufl.edu/projects/relation-extraction}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This work has been published to the IEEE Access (2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.04934v2",
    "published_date": "2024-09-07 23:40:47 UTC",
    "updated_date": "2024-11-25 20:16:02 UTC"
  },
  {
    "arxiv_id": "2409.04926v1",
    "title": "A $Δ$-evaluation function for column permutation problems",
    "authors": [
      "Júnior R. Lima",
      "Viníicius Gandra M. Santos",
      "Marco Antonio M. Carvalho"
    ],
    "abstract": "In this study, a new $\\Delta$-evaluation method is introduced for solving a\ncolumn permutation problem defined on a sparse binary matrix with the\nconsecutive ones property. This problem models various $\\mathcal{NP}$-hard\nproblems in graph theory and industrial manufacturing contexts. The\ncomputational experiments compare the processing time of the\n$\\Delta$-evaluation method with two other methods used in well-known local\nsearch procedures. The study considers a comprehensive set of instances of\nwell-known problems, such as Gate Matrix Layout and Minimization of Open\nStacks. The proposed evaluation method is generally competitive and\nparticularly useful for large and dense instances. It can be easily integrated\ninto local search and metaheuristic algorithms to improve solutions without\nsignificantly increasing processing time.",
    "categories": [
      "cs.AI",
      "math.CO",
      "math.OC",
      "90",
      "J.6"
    ],
    "primary_category": "cs.AI",
    "comment": "technical report",
    "pdf_url": "http://arxiv.org/pdf/2409.04926v1",
    "published_date": "2024-09-07 22:50:25 UTC",
    "updated_date": "2024-09-07 22:50:25 UTC"
  },
  {
    "arxiv_id": "2409.04922v1",
    "title": "Nearest Neighbor CCP-Based Molecular Sequence Analysis",
    "authors": [
      "Sarwan Ali",
      "Prakash Chourasia",
      "Bipin Koirala",
      "Murray Patterson"
    ],
    "abstract": "Molecular sequence analysis is crucial for comprehending several biological\nprocesses, including protein-protein interactions, functional annotation, and\ndisease classification. The large number of sequences and the inherently\ncomplicated nature of protein structures make it challenging to analyze such\ndata. Finding patterns and enhancing subsequent research requires the use of\ndimensionality reduction and feature selection approaches. Recently, a method\ncalled Correlated Clustering and Projection (CCP) has been proposed as an\neffective method for biological sequencing data. The CCP technique is still\ncostly to compute even though it is effective for sequence visualization.\nFurthermore, its utility for classifying molecular sequences is still\nuncertain. To solve these two problems, we present a Nearest Neighbor\nCorrelated Clustering and Projection (CCP-NN)-based technique for efficiently\npreprocessing molecular sequence data. To group related molecular sequences and\nproduce representative supersequences, CCP makes use of sequence-to-sequence\ncorrelations. As opposed to conventional methods, CCP doesn't rely on matrix\ndiagonalization, therefore it can be applied to a range of machine-learning\nproblems. We estimate the density map and compute the correlation using a\nnearest-neighbor search technique. We performed molecular sequence\nclassification using CCP and CCP-NN representations to assess the efficacy of\nour proposed approach. Our findings show that CCP-NN considerably improves\nclassification task accuracy as well as significantly outperforms CCP in terms\nof computational runtime.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CC",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04922v1",
    "published_date": "2024-09-07 22:06:00 UTC",
    "updated_date": "2024-09-07 22:06:00 UTC"
  },
  {
    "arxiv_id": "2409.04920v1",
    "title": "MoistNet: Machine Vision-based Deep Learning Models for Wood Chip Moisture Content Measurement",
    "authors": [
      "Abdur Rahman",
      "Jason Street",
      "James Wooten",
      "Mohammad Marufuzzaman",
      "Veera G. Gude",
      "Randy Buchanan",
      "Haifeng Wang"
    ],
    "abstract": "Quick and reliable measurement of wood chip moisture content is an\neverlasting problem for numerous forest-reliant industries such as biofuel,\npulp and paper, and bio-refineries. Moisture content is a critical attribute of\nwood chips due to its direct relationship with the final product quality.\nConventional techniques for determining moisture content, such as oven-drying,\npossess some drawbacks in terms of their time-consuming nature, potential\nsample damage, and lack of real-time feasibility. Furthermore, alternative\ntechniques, including NIR spectroscopy, electrical capacitance, X-rays, and\nmicrowaves, have demonstrated potential; nevertheless, they are still\nconstrained by issues related to portability, precision, and the expense of the\nrequired equipment. Hence, there is a need for a moisture content determination\nmethod that is instant, portable, non-destructive, inexpensive, and precise.\nThis study explores the use of deep learning and machine vision to predict\nmoisture content classes from RGB images of wood chips. A large-scale image\ndataset comprising 1,600 RGB images of wood chips has been collected and\nannotated with ground truth labels, utilizing the results of the oven-drying\ntechnique. Two high-performing neural networks, MoistNetLite and MoistNetMax,\nhave been developed leveraging Neural Architecture Search (NAS) and\nhyperparameter optimization. The developed models are evaluated and compared\nwith state-of-the-art deep learning models. Results demonstrate that\nMoistNetLite achieves 87% accuracy with minimal computational overhead, while\nMoistNetMax exhibits exceptional precision with a 91% accuracy in wood chip\nmoisture content class prediction. With improved accuracy and faster prediction\nspeed, our proposed MoistNet models hold great promise for the wood chip\nprocessing industry.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04920v1",
    "published_date": "2024-09-07 22:03:13 UTC",
    "updated_date": "2024-09-07 22:03:13 UTC"
  },
  {
    "arxiv_id": "2409.04915v1",
    "title": "Activation Function Optimization Scheme for Image Classification",
    "authors": [
      "Abdur Rahman",
      "Lu He",
      "Haifeng Wang"
    ],
    "abstract": "Activation function has a significant impact on the dynamics, convergence,\nand performance of deep neural networks. The search for a consistent and\nhigh-performing activation function has always been a pursuit during deep\nlearning model development. Existing state-of-the-art activation functions are\nmanually designed with human expertise except for Swish. Swish was developed\nusing a reinforcement learning-based search strategy. In this study, we propose\nan evolutionary approach for optimizing activation functions specifically for\nimage classification tasks, aiming to discover functions that outperform\ncurrent state-of-the-art options. Through this optimization framework, we\nobtain a series of high-performing activation functions denoted as Exponential\nError Linear Unit (EELU). The developed activation functions are evaluated for\nimage classification tasks from two perspectives: (1) five state-of-the-art\nneural network architectures, such as ResNet50, AlexNet, VGG16, MobileNet, and\nCompact Convolutional Transformer which cover computationally heavy to light\nneural networks, and (2) eight standard datasets, including CIFAR10,\nImagenette, MNIST, Fashion MNIST, Beans, Colorectal Histology, CottonWeedID15,\nand TinyImageNet which cover from typical machine vision benchmark,\nagricultural image applications to medical image applications. Finally, we\nstatistically investigate the generalization of the resultant activation\nfunctions developed through the optimization scheme. With a Friedman test, we\nconclude that the optimization scheme is able to generate activation functions\nthat outperform the existing standard ones in 92.8% cases among 28 different\ncases studied, and $-x\\cdot erf(e^{-x})$ is found to be the best activation\nfunction for image classification generated by the optimization scheme.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04915v1",
    "published_date": "2024-09-07 21:40:15 UTC",
    "updated_date": "2024-09-07 21:40:15 UTC"
  },
  {
    "arxiv_id": "2409.04909v1",
    "title": "Efficient Training of Transformers for Molecule Property Prediction on Small-scale Datasets",
    "authors": [
      "Shivesh Prakash"
    ],
    "abstract": "The blood-brain barrier (BBB) serves as a protective barrier that separates\nthe brain from the circulatory system, regulating the passage of substances\ninto the central nervous system. Assessing the BBB permeability of potential\ndrugs is crucial for effective drug targeting. However, traditional\nexperimental methods for measuring BBB permeability are challenging and\nimpractical for large-scale screening. Consequently, there is a need to develop\ncomputational approaches to predict BBB permeability. This paper proposes a GPS\nTransformer architecture augmented with Self Attention, designed to perform\nwell in the low-data regime. The proposed approach achieved a state-of-the-art\nperformance on the BBB permeability prediction task using the BBBP dataset,\nsurpassing existing models. With a ROC-AUC of 78.8%, the approach sets a\nstate-of-the-art by 5.5%. We demonstrate that standard Self Attention coupled\nwith GPS transformer performs better than other variants of attention coupled\nwith GPS Transformer.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04909v1",
    "published_date": "2024-09-07 21:07:12 UTC",
    "updated_date": "2024-09-07 21:07:12 UTC"
  },
  {
    "arxiv_id": "2409.04896v1",
    "title": "Reinforcement Learning-Based Adaptive Load Balancing for Dynamic Cloud Environments",
    "authors": [
      "Kavish Chawla"
    ],
    "abstract": "Efficient load balancing is crucial in cloud computing environments to ensure\noptimal resource utilization, minimize response times, and prevent server\noverload. Traditional load balancing algorithms, such as round-robin or least\nconnections, are often static and unable to adapt to the dynamic and\nfluctuating nature of cloud workloads. In this paper, we propose a novel\nadaptive load balancing framework using Reinforcement Learning (RL) to address\nthese challenges. The RL-based approach continuously learns and improves the\ndistribution of tasks by observing real-time system performance and making\ndecisions based on traffic patterns and resource availability. Our framework is\ndesigned to dynamically reallocate tasks to minimize latency and ensure\nbalanced resource usage across servers. Experimental results show that the\nproposed RL-based load balancer outperforms traditional algorithms in terms of\nresponse time, resource utilization, and adaptability to changing workloads.\nThese findings highlight the potential of AI-driven solutions for enhancing the\nefficiency and scalability of cloud infrastructures.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI",
      "68M14, 68T05"
    ],
    "primary_category": "cs.DC",
    "comment": "Length: 6 pages (including references) Figures: 3 figures Submission\n  Type: Conference paper Keywords: Reinforcement Learning, Load Balancing,\n  Cloud Computing, Adaptive Algorithms, AI-driven Load Management",
    "pdf_url": "http://arxiv.org/pdf/2409.04896v1",
    "published_date": "2024-09-07 19:40:48 UTC",
    "updated_date": "2024-09-07 19:40:48 UTC"
  },
  {
    "arxiv_id": "2409.04887v1",
    "title": "Defeasible Reasoning on Concepts",
    "authors": [
      "Yiwen Ding",
      "Krishna Manoorkar",
      "Ni Wayan Switrayni",
      "Ruoding Wang"
    ],
    "abstract": "In this paper, we take first steps toward developing defeasible reasoning on\nconcepts in KLM framework. We define generalizations of cumulative reasoning\nsystem C and cumulative reasoning system with loop CL to conceptual setting. We\nalso generalize cumulative models, cumulative ordered models, and preferential\nmodels to conceptual setting and show the soundness and completeness results\nfor these models.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04887v1",
    "published_date": "2024-09-07 19:08:17 UTC",
    "updated_date": "2024-09-07 19:08:17 UTC"
  },
  {
    "arxiv_id": "2409.13717v2",
    "title": "DiVA-DocRE: A Discriminative and Voice-Aware Paradigm for Document-Level Relation Extraction",
    "authors": [
      "Yiheng Wu",
      "Roman Yangarber",
      "Xian Mao"
    ],
    "abstract": "The remarkable capabilities of Large Language Models (LLMs) in text\ncomprehension and generation have revolutionized Information Extraction (IE).\nOne such advancement is in Document-level Relation Triplet Extraction (DocRTE),\na critical task in information systems that aims to extract entities and their\nsemantic relationships from documents. However, existing methods are primarily\ndesigned for Sentence level Relation Triplet Extraction (SentRTE), which\ntypically handles a limited set of relations and triplet facts within a single\nsentence. Additionally, some approaches treat relations as candidate choices\nintegrated into prompt templates, resulting in inefficient processing and\nsuboptimal performance when determining the relation elements in triplets. To\naddress these limitations, we introduce a Discriminative and Voice Aware\nParadigm DiVA. DiVA involves only two steps: performing document-level relation\nextraction (DocRE) and then identifying the subject object entities based on\nthe relation. No additional processing is required simply input the document to\ndirectly obtain the triplets. This streamlined process more accurately reflects\nreal-world scenarios for triplet extraction. Our innovation lies in\ntransforming DocRE into a discriminative task, where the model pays attention\nto each relation and to the often overlooked issue of active vs. passive voice\nwithin the triplet. Our experiments on the Re-DocRED and DocRED datasets\ndemonstrate state-of-the-art results for the DocRTE task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "After internal discussions among the co-authors, we have decided to\n  withdraw the manuscript due to a change in research direction and a lack of\n  unanimous agreement to proceed with publication at this time",
    "pdf_url": "http://arxiv.org/pdf/2409.13717v2",
    "published_date": "2024-09-07 18:47:38 UTC",
    "updated_date": "2025-04-08 10:43:00 UTC"
  },
  {
    "arxiv_id": "2409.04882v1",
    "title": "Learning to Open and Traverse Doors with a Legged Manipulator",
    "authors": [
      "Mike Zhang",
      "Yuntao Ma",
      "Takahiro Miki",
      "Marco Hutter"
    ],
    "abstract": "Using doors is a longstanding challenge in robotics and is of significant\npractical interest in giving robots greater access to human-centric spaces. The\ntask is challenging due to the need for online adaptation to varying door\nproperties and precise control in manipulating the door panel and navigating\nthrough the confined doorway. To address this, we propose a learning-based\ncontroller for a legged manipulator to open and traverse through doors. The\ncontroller is trained using a teacher-student approach in simulation to learn\nrobust task behaviors as well as estimate crucial door properties during the\ninteraction. Unlike previous works, our approach is a single control policy\nthat can handle both push and pull doors through learned behaviour which infers\nthe opening direction during deployment without prior knowledge. The policy was\ndeployed on the ANYmal legged robot with an arm and achieved a success rate of\n95.0% in repeated trials conducted in an experimental setting. Additional\nexperiments validate the policy's effectiveness and robustness to various doors\nand disturbances. A video overview of the method and experiments can be found\nat youtu.be/tQDZXN_k5NU.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04882v1",
    "published_date": "2024-09-07 18:27:46 UTC",
    "updated_date": "2024-09-07 18:27:46 UTC"
  },
  {
    "arxiv_id": "2409.04880v1",
    "title": "Towards identifying Source credibility on Information Leakage in Digital Gadget Market",
    "authors": [
      "Neha Kumaru",
      "Garvit Gupta",
      "Shreyas Mongia",
      "Shubham Singh",
      "Ponnurangam Kumaraguru",
      "Arun Balaji Buduru"
    ],
    "abstract": "The use of Social media to share content is on a constant rise. One of the\ncapsize effect of information sharing on Social media includes the spread of\nsensitive information on the public domain. With the digital gadget market\nbecoming highly competitive and ever-evolving, the trend of an increasing\nnumber of sensitive posts leaking information on devices in social media is\nobserved. Many web-blogs on digital gadget market have mushroomed recently,\nmaking the problem of information leak all pervasive. Credible leaks on\nspecifics of an upcoming device can cause a lot of financial damage to the\nrespective organization. Hence, it is crucial to assess the credibility of the\nplatforms that continuously post about a smartphone or digital gadget leaks. In\nthis work, we analyze the headlines of leak web-blog posts and their\ncorresponding official press-release. We first collect 54, 495 leak and\npress-release headlines for different smartphones. We train our custom NER\nmodel to capture the evolving smartphone names with an accuracy of 82.14% on\nmanually annotated results. We further propose a credibility score metric for\nthe web-blog, based on the number of falsified and authentic smartphone leak\nposts.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04880v1",
    "published_date": "2024-09-07 18:20:33 UTC",
    "updated_date": "2024-09-07 18:20:33 UTC"
  },
  {
    "arxiv_id": "2409.05916v1",
    "title": "Unlocking Potential Binders: Multimodal Pretraining DEL-Fusion for Denoising DNA-Encoded Libraries",
    "authors": [
      "Chunbin Gu",
      "Mutian He",
      "Hanqun Cao",
      "Guangyong Chen",
      "Chang-yu Hsieh",
      "Pheng Ann Heng"
    ],
    "abstract": "In the realm of drug discovery, DNA-encoded library (DEL) screening\ntechnology has emerged as an efficient method for identifying high-affinity\ncompounds. However, DEL screening faces a significant challenge: noise arising\nfrom nonspecific interactions within complex biological systems. Neural\nnetworks trained on DEL libraries have been employed to extract compound\nfeatures, aiming to denoise the data and uncover potential binders to the\ndesired therapeutic target. Nevertheless, the inherent structure of DEL,\nconstrained by the limited diversity of building blocks, impacts the\nperformance of compound encoders. Moreover, existing methods only capture\ncompound features at a single level, further limiting the effectiveness of the\ndenoising strategy. To mitigate these issues, we propose a Multimodal\nPretraining DEL-Fusion model (MPDF) that enhances encoder capabilities through\npretraining and integrates compound features across various scales. We develop\npretraining tasks applying contrastive objectives between different compound\nrepresentations and their text descriptions, enhancing the compound encoders'\nability to acquire generic features. Furthermore, we propose a novel DEL-fusion\nframework that amalgamates compound information at the atomic, submolecular,\nand molecular levels, as captured by various compound encoders. The synergy of\nthese innovations equips MPDF with enriched, multi-scale features, enabling\ncomprehensive downstream denoising. Evaluated on three DEL datasets, MPDF\ndemonstrates superior performance in data processing and analysis for\nvalidation tasks. Notably, MPDF offers novel insights into identifying\nhigh-affinity molecules, paving the way for improved DEL utility in drug\ndiscovery.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05916v1",
    "published_date": "2024-09-07 17:32:21 UTC",
    "updated_date": "2024-09-07 17:32:21 UTC"
  },
  {
    "arxiv_id": "2409.13715v2",
    "title": "Introducing MeMo: A Multimodal Dataset for Memory Modelling in Multiparty Conversations",
    "authors": [
      "Maria Tsfasman",
      "Bernd Dudzik",
      "Kristian Fenech",
      "Andras Lorincz",
      "Catholijn M. Jonker",
      "Catharine Oertel"
    ],
    "abstract": "Conversational memory is the process by which humans encode, retain and\nretrieve verbal, non-verbal and contextual information from a conversation.\nSince human memory is selective, differing recollections of the same events can\nlead to misunderstandings and misalignments within a group. Yet, conversational\nfacilitation systems, aimed at advancing the quality of group interactions,\nusually focus on tracking users' states within an individual session, ignoring\nwhat remains in each participant's memory after the interaction. Understanding\nconversational memory can be used as a source of information on the long-term\ndevelopment of social connections within a group. This paper introduces the\nMeMo corpus, the first conversational dataset annotated with participants'\nmemory retention reports, aimed at facilitating computational modelling of\nhuman conversational memory. The MeMo corpus includes 31 hours of small-group\ndiscussions on Covid-19, repeated 3 times over the term of 2 weeks. It\nintegrates validated behavioural and perceptual measures, audio, video, and\nmultimodal annotations, offering a valuable resource for studying and modelling\nconversational memory and group dynamics. By introducing the MeMo corpus,\nanalysing its validity, and demonstrating its usefulness for future research,\nthis paper aims to pave the way for future research in conversational memory\nmodelling for intelligent system development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13715v2",
    "published_date": "2024-09-07 16:09:36 UTC",
    "updated_date": "2024-10-15 11:29:25 UTC"
  },
  {
    "arxiv_id": "2409.04849v1",
    "title": "FedModule: A Modular Federated Learning Framework",
    "authors": [
      "Chuyi Chen",
      "Zhe Zhang",
      "Yanchao Zhao"
    ],
    "abstract": "Federated learning (FL) has been widely adopted across various applications,\nsuch as healthcare, finance, and smart cities. However, as experimental\nscenarios become more complex, existing FL frameworks and benchmarks have\nstruggled to keep pace. This paper introduces FedModule, a flexible and\nextensible FL experimental framework that has been open-sourced to support\ndiverse FL paradigms and provide comprehensive benchmarks for complex\nexperimental scenarios. FedModule adheres to the \"one code, all scenarios\"\nprinciple and employs a modular design that breaks the FL process into\nindividual components, allowing for the seamless integration of different FL\nparadigms. The framework supports synchronous, asynchronous, and personalized\nfederated learning, with over 20 implemented algorithms. Experiments conducted\non public datasets demonstrate the flexibility and extensibility of FedModule.\nThe framework offers multiple execution modes-including linear, threaded,\nprocess-based, and distributed-enabling users to tailor their setups to various\nexperimental needs. Additionally, FedModule provides extensive logging and\ntesting capabilities, which facilitate detailed performance analysis of FL\nalgorithms. Comparative evaluations against existing FL toolkits, such as\nTensorFlow Federated, PySyft, Flower, and FLGo, highlight FedModule's superior\nscalability, flexibility, and comprehensive benchmark support. By addressing\nthe limitations of current FL frameworks, FedModule marks a significant\nadvancement in FL experimentation, providing researchers and practitioners with\na robust tool for developing and evaluating FL algorithms across a wide range\nof scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04849v1",
    "published_date": "2024-09-07 15:03:12 UTC",
    "updated_date": "2024-09-07 15:03:12 UTC"
  },
  {
    "arxiv_id": "2409.04840v2",
    "title": "Sample and Oracle Efficient Reinforcement Learning for MDPs with Linearly-Realizable Value Functions",
    "authors": [
      "Zakaria Mhammedi"
    ],
    "abstract": "Designing sample-efficient and computationally feasible reinforcement\nlearning (RL) algorithms is particularly challenging in environments with large\nor infinite state and action spaces. In this paper, we advance this effort by\npresenting an efficient algorithm for Markov Decision Processes (MDPs) where\nthe state-action value function of any policy is linear in a given feature map.\nThis challenging setting can model environments with infinite states and\nactions, strictly generalizes classic linear MDPs, and currently lacks a\ncomputationally efficient algorithm under online access to the MDP.\nSpecifically, we introduce a new RL algorithm that efficiently finds a\nnear-optimal policy in this setting, using a number of episodes and calls to a\ncost-sensitive classification (CSC) oracle that are both polynomial in the\nproblem parameters. Notably, our CSC oracle can be efficiently implemented when\nthe feature dimension is constant, representing a clear improvement over\nstate-of-the-art methods, which require solving non-convex problems with\nhorizon-many variables and can incur computational costs that are exponential\nin the horizon.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04840v2",
    "published_date": "2024-09-07 14:38:05 UTC",
    "updated_date": "2024-10-03 16:23:07 UTC"
  },
  {
    "arxiv_id": "2409.04834v2",
    "title": "Reducing Events to Augment Log-based Anomaly Detection Models: An Empirical Study",
    "authors": [
      "Lingzhe Zhang",
      "Tong Jia",
      "Kangjin Wang",
      "Mengxi Jia",
      "Yang Yong",
      "Ying Li"
    ],
    "abstract": "As software systems grow increasingly intricate, the precise detection of\nanomalies have become both essential and challenging. Current log-based anomaly\ndetection methods depend heavily on vast amounts of log data leading to\ninefficient inference and potential misguidance by noise logs. However, the\nquantitative effects of log reduction on the effectiveness of anomaly detection\nremain unexplored. Therefore, we first conduct a comprehensive study on six\ndistinct models spanning three datasets. Through the study, the impact of log\nquantity and their effectiveness in representing anomalies is qualifies,\nuncovering three distinctive log event types that differently influence model\nperformance. Drawing from these insights, we propose LogCleaner: an efficient\nmethodology for the automatic reduction of log events in the context of anomaly\ndetection. Serving as middleware between software systems and models,\nLogCleaner continuously updates and filters anti-events and duplicative-events\nin the raw generated logs. Experimental outcomes highlight LogCleaner's\ncapability to reduce over 70% of log events in anomaly detection, accelerating\nthe model's inference speed by approximately 300%, and universally improving\nthe performance of models for anomaly detection.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted By ESEM'24",
    "pdf_url": "http://arxiv.org/pdf/2409.04834v2",
    "published_date": "2024-09-07 14:02:02 UTC",
    "updated_date": "2024-09-15 02:32:30 UTC"
  },
  {
    "arxiv_id": "2409.04833v1",
    "title": "Achieving Peak Performance for Large Language Models: A Systematic Review",
    "authors": [
      "Zhyar Rzgar K Rostam",
      "Sándor Szénási",
      "Gábor Kertész"
    ],
    "abstract": "In recent years, large language models (LLMs) have achieved remarkable\nsuccess in natural language processing (NLP). LLMs require an extreme amount of\nparameters to attain high performance. As models grow into the\ntrillion-parameter range, computational and memory costs increase\nsignificantly. This makes it difficult for many researchers to access the\nresources needed to train or apply these models. Optimizing LLM performance\ninvolves two main approaches: fine-tuning pre-trained models for specific tasks\nto achieve state-of-the-art performance, and reducing costs or improving\ntraining time while maintaining similar performance. This paper presents a\nsystematic literature review (SLR) following the Preferred Reporting Items for\nSystematic Reviews and Meta-Analyses (PRISMA) statement. We reviewed 65\npublications out of 983 from 2017 to December 2023, retrieved from 5 databases.\nThe study presents methods to optimize and accelerate LLMs while achieving\ncutting-edge results without sacrificing accuracy. We begin with an overview of\nthe development of language modeling, followed by a detailed explanation of\ncommonly used frameworks and libraries, and a taxonomy for improving and\nspeeding up LLMs based on three classes: LLM training, LLM inference, and\nsystem serving. We then delve into recent optimization and acceleration\nstrategies such as training optimization, hardware optimization, scalability\nand reliability, accompanied by the taxonomy and categorization of these\nstrategies. Finally, we provide an in-depth comparison of each class and\nstrategy, with two case studies on optimizing model training and enhancing\ninference efficiency. These case studies showcase practical approaches to\naddress LLM resource limitations while maintaining performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages, 7 figures, 8 tables. Journal Article: IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2409.04833v1",
    "published_date": "2024-09-07 13:57:41 UTC",
    "updated_date": "2024-09-07 13:57:41 UTC"
  },
  {
    "arxiv_id": "2409.04832v1",
    "title": "Reward-Directed Score-Based Diffusion Models via q-Learning",
    "authors": [
      "Xuefeng Gao",
      "Jiale Zha",
      "Xun Yu Zhou"
    ],
    "abstract": "We propose a new reinforcement learning (RL) formulation for training\ncontinuous-time score-based diffusion models for generative AI to generate\nsamples that maximize reward functions while keeping the generated\ndistributions close to the unknown target data distributions. Different from\nmost existing studies, our formulation does not involve any pretrained model\nfor the unknown score functions of the noise-perturbed data distributions. We\npresent an entropy-regularized continuous-time RL problem and show that the\noptimal stochastic policy has a Gaussian distribution with a known covariance\nmatrix. Based on this result, we parameterize the mean of Gaussian policies and\ndevelop an actor-critic type (little) q-learning algorithm to solve the RL\nproblem. A key ingredient in our algorithm design is to obtain noisy\nobservations from the unknown score function via a ratio estimator.\nNumerically, we show the effectiveness of our approach by comparing its\nperformance with two state-of-the-art RL methods that fine-tune pretrained\nmodels. Finally, we discuss extensions of our RL formulation to probability\nflow ODE implementation of diffusion models and to conditional diffusion\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04832v1",
    "published_date": "2024-09-07 13:55:45 UTC",
    "updated_date": "2024-09-07 13:55:45 UTC"
  },
  {
    "arxiv_id": "2409.04831v1",
    "title": "MILE: A Mutation Testing Framework of In-Context Learning Systems",
    "authors": [
      "Zeming Wei",
      "Yihao Zhang",
      "Meng Sun"
    ],
    "abstract": "In-context Learning (ICL) has achieved notable success in the applications of\nlarge language models (LLMs). By adding only a few input-output pairs that\ndemonstrate a new task, the LLM can efficiently learn the task during inference\nwithout modifying the model parameters. Such mysterious ability of LLMs has\nattracted great research interests in understanding, formatting, and improving\nthe in-context demonstrations, while still suffering from drawbacks like\nblack-box mechanisms and sensitivity against the selection of examples. In this\nwork, inspired by the foundations of adopting testing techniques in machine\nlearning (ML) systems, we propose a mutation testing framework designed to\ncharacterize the quality and effectiveness of test data for ICL systems. First,\nwe propose several mutation operators specialized for ICL demonstrations, as\nwell as corresponding mutation scores for ICL test sets. With comprehensive\nexperiments, we showcase the effectiveness of our framework in evaluating the\nreliability and quality of ICL test suites. Our code is available at\nhttps://github.com/weizeming/MILE.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04831v1",
    "published_date": "2024-09-07 13:51:42 UTC",
    "updated_date": "2024-09-07 13:51:42 UTC"
  },
  {
    "arxiv_id": "2409.04829v1",
    "title": "NASH: Neural Architecture and Accelerator Search for Multiplication-Reduced Hybrid Models",
    "authors": [
      "Yang Xu",
      "Huihong Shi",
      "Zhongfeng Wang"
    ],
    "abstract": "The significant computational cost of multiplications hinders the deployment\nof deep neural networks (DNNs) on edge devices. While multiplication-free\nmodels offer enhanced hardware efficiency, they typically sacrifice accuracy.\nAs a solution, multiplication-reduced hybrid models have emerged to combine the\nbenefits of both approaches. Particularly, prior works, i.e., NASA and NASA-F,\nleverage Neural Architecture Search (NAS) to construct such hybrid models,\nenhancing hardware efficiency while maintaining accuracy. However, they either\nentail costly retraining or encounter gradient conflicts, limiting both search\nefficiency and accuracy. Additionally, they overlook the acceleration\nopportunity introduced by accelerator search, yielding sub-optimal hardware\nperformance. To overcome these limitations, we propose NASH, a Neural\narchitecture and Accelerator Search framework for multiplication-reduced Hybrid\nmodels. Specifically, as for NAS, we propose a tailored zero-shot metric to\npre-identify promising hybrid models before training, enhancing search\nefficiency while alleviating gradient conflicts. Regarding accelerator search,\nwe innovatively introduce coarse-to-fine search to streamline the search\nprocess. Furthermore, we seamlessly integrate these two levels of searches to\nunveil NASH, obtaining the optimal model and accelerator pairing. Experiments\nvalidate our effectiveness, e.g., when compared with the state-of-the-art\nmultiplication-based system, we can achieve $\\uparrow$$2.14\\times$ throughput\nand $\\uparrow$$2.01\\times$ FPS with $\\uparrow$$0.25\\%$ accuracy on CIFAR-100,\nand $\\uparrow$$1.40\\times$ throughput and $\\uparrow$$1.19\\times$ FPS with\n$\\uparrow$$0.56\\%$ accuracy on Tiny-ImageNet. Codes are available at\n\\url{https://github.com/xuyang527/NASH.}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04829v1",
    "published_date": "2024-09-07 13:42:40 UTC",
    "updated_date": "2024-09-07 13:42:40 UTC"
  },
  {
    "arxiv_id": "2409.04828v3",
    "title": "POINTS: Improving Your Vision-language Model with Affordable Strategies",
    "authors": [
      "Yuan Liu",
      "Zhongyin Zhao",
      "Ziyuan Zhuang",
      "Le Tian",
      "Xiao Zhou",
      "Jie Zhou"
    ],
    "abstract": "In recent years, vision-language models have made significant strides,\nexcelling in tasks like optical character recognition and geometric\nproblem-solving. However, several critical issues remain: 1) Proprietary models\noften lack transparency about their architectures, while open-source models\nneed more detailed ablations of their training strategies. 2) Pre-training data\nin open-source works is under-explored, with datasets added empirically, making\nthe process cumbersome. 3) Fine-tuning often focuses on adding datasets,\nleading to diminishing returns. To address these issues, we propose the\nfollowing contributions: 1) We trained a robust baseline model using the latest\nadvancements in vision-language models, introducing effective improvements and\nconducting comprehensive ablation and validation for each technique. 2)\nInspired by recent work on large language models, we filtered pre-training data\nusing perplexity, selecting the lowest perplexity data for training. This\napproach allowed us to train on a curated 1M dataset, achieving competitive\nperformance. 3) During visual instruction tuning, we used model soup on\ndifferent datasets when adding more datasets yielded marginal improvements.\nThese innovations resulted in a 9B parameter model that performs competitively\nwith state-of-the-art models. Our strategies are efficient and lightweight,\nmaking them easily adoptable by the community.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "v2",
    "pdf_url": "http://arxiv.org/pdf/2409.04828v3",
    "published_date": "2024-09-07 13:41:37 UTC",
    "updated_date": "2024-11-05 02:32:06 UTC"
  },
  {
    "arxiv_id": "2409.04822v1",
    "title": "Exploring Straightforward Conversational Red-Teaming",
    "authors": [
      "George Kour",
      "Naama Zwerdling",
      "Marcel Zalmanovici",
      "Ateret Anaby-Tavor",
      "Ora Nova Fandina",
      "Eitan Farchi"
    ],
    "abstract": "Large language models (LLMs) are increasingly used in business dialogue\nsystems but they pose security and ethical risks. Multi-turn conversations,\nwhere context influences the model's behavior, can be exploited to produce\nundesired responses. In this paper, we examine the effectiveness of utilizing\noff-the-shelf LLMs in straightforward red-teaming approaches, where an attacker\nLLM aims to elicit undesired output from a target LLM, comparing both\nsingle-turn and conversational red-teaming tactics. Our experiments offer\ninsights into various usage strategies that significantly affect their\nperformance as red teamers. They suggest that off-the-shelf models can act as\neffective red teamers and even adjust their attack strategy based on past\nattempts, although their effectiveness decreases with greater alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04822v1",
    "published_date": "2024-09-07 13:28:01 UTC",
    "updated_date": "2024-09-07 13:28:01 UTC"
  },
  {
    "arxiv_id": "2409.04820v1",
    "title": "FreeAugment: Data Augmentation Search Across All Degrees of Freedom",
    "authors": [
      "Tom Bekor",
      "Niv Nayman",
      "Lihi Zelnik-Manor"
    ],
    "abstract": "Data augmentation has become an integral part of deep learning, as it is\nknown to improve the generalization capabilities of neural networks. Since the\nmost effective set of image transformations differs between tasks and domains,\nautomatic data augmentation search aims to alleviate the extreme burden of\nmanually finding the optimal image transformations. However, current methods\nare not able to jointly optimize all degrees of freedom: (1) the number of\ntransformations to be applied, their (2) types, (3) order, and (4) magnitudes.\nMany existing methods risk picking the same transformation more than once,\nlimit the search to two transformations only, or search for the number of\ntransformations exhaustively or iteratively in a myopic manner. Our approach,\nFreeAugment, is the first to achieve global optimization of all four degrees of\nfreedom simultaneously, using a fully differentiable method. It efficiently\nlearns the number of transformations and a probability distribution over their\npermutations, inherently refraining from redundant repetition while sampling.\nOur experiments demonstrate that this joint learning of all degrees of freedom\nsignificantly improves performance, achieving state-of-the-art results on\nvarious natural image benchmarks and beyond across other domains. Project page\nat https://tombekor.github.io/FreeAugment-web",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "math.OC",
      "I.2; I.4"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.04820v1",
    "published_date": "2024-09-07 13:26:12 UTC",
    "updated_date": "2024-09-07 13:26:12 UTC"
  },
  {
    "arxiv_id": "2409.04819v1",
    "title": "Top-GAP: Integrating Size Priors in CNNs for more Interpretability, Robustness, and Bias Mitigation",
    "authors": [
      "Lars Nieradzik",
      "Henrike Stephani",
      "Janis Keuper"
    ],
    "abstract": "This paper introduces Top-GAP, a novel regularization technique that enhances\nthe explainability and robustness of convolutional neural networks. By\nconstraining the spatial size of the learned feature representation, our method\nforces the network to focus on the most salient image regions, effectively\nreducing background influence. Using adversarial attacks and the Effective\nReceptive Field, we show that Top-GAP directs more attention towards object\npixels rather than the background. This leads to enhanced interpretability and\nrobustness. We achieve over 50% robust accuracy on CIFAR-10 with PGD\n$\\epsilon=\\frac{8}{255}$ and $20$ iterations while maintaining the original\nclean accuracy. Furthermore, we see increases of up to 5% accuracy against\ndistribution shifts. Our approach also yields more precise object localization,\nas evidenced by up to 25% improvement in Intersection over Union (IOU) compared\nto methods like GradCAM and Recipro-CAM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "eXCV Workshop at ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.04819v1",
    "published_date": "2024-09-07 13:24:59 UTC",
    "updated_date": "2024-09-07 13:24:59 UTC"
  },
  {
    "arxiv_id": "2409.04813v2",
    "title": "Generalized Learning of Coefficients in Spectral Graph Convolutional Networks",
    "authors": [
      "Mustafa Coşkun",
      "Ananth Grama",
      "Mehmet Koyutürk"
    ],
    "abstract": "Spectral Graph Convolutional Networks (GCNs) have gained popularity in graph\nmachine learning applications due, in part, to their flexibility in\nspecification of network propagation rules. These propagation rules are often\nconstructed as polynomial filters whose coefficients are learned using label\ninformation during training. In contrast to learned polynomial filters,\nexplicit filter functions are useful in capturing relationships between network\ntopology and distribution of labels across the network. A number of algorithms\nincorporating either approach have been proposed; however the relationship\nbetween filter functions and polynomial approximations is not fully resolved.\nThis is largely due to the ill-conditioned nature of the linear systems that\nmust be solved to derive polynomial approximations of filter functions. To\naddress this challenge, we propose a novel Arnoldi orthonormalization-based\nalgorithm, along with a unifying approach, called G-Arnoldi-GCN that can\nefficiently and effectively approximate a given filter function with a\npolynomial. We evaluate G-Arnoldi-GCN in the context of multi-class node\nclassification across ten datasets with diverse topological characteristics.\nOur experiments show that G-Arnoldi-GCN consistently outperforms\nstate-of-the-art methods when suitable filter functions are employed. Overall,\nG-Arnoldi-GCN opens important new directions in graph machine learning by\nenabling the explicit design and application of diverse filter functions. Code\nlink: https://github.com/mustafaCoskunAgu/GArnoldi-GCN",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04813v2",
    "published_date": "2024-09-07 12:53:44 UTC",
    "updated_date": "2024-10-01 07:28:39 UTC"
  },
  {
    "arxiv_id": "2409.04808v1",
    "title": "HULLMI: Human vs LLM identification with explainability",
    "authors": [
      "Prathamesh Dinesh Joshi",
      "Sahil Pocker",
      "Raj Abhijit Dandekar",
      "Rajat Dandekar",
      "Sreedath Panat"
    ],
    "abstract": "As LLMs become increasingly proficient at producing human-like responses,\nthere has been a rise of academic and industrial pursuits dedicated to flagging\na given piece of text as \"human\" or \"AI\". Most of these pursuits involve modern\nNLP detectors like T5-Sentinel and RoBERTa-Sentinel, without paying too much\nattention to issues of interpretability and explainability of these models. In\nour study, we provide a comprehensive analysis that shows that traditional ML\nmodels (Naive-Bayes,MLP, Random Forests, XGBoost) perform as well as modern NLP\ndetectors, in human vs AI text detection. We achieve this by implementing a\nrobust testing procedure on diverse datasets, including curated corpora and\nreal-world samples. Subsequently, by employing the explainable AI technique\nLIME, we uncover parts of the input that contribute most to the prediction of\neach model, providing insights into the detection process. Our study\ncontributes to the growing need for developing production-level LLM detection\ntools, which can leverage a wide range of traditional as well as modern NLP\ndetectors we propose. Finally, the LIME techniques we demonstrate also have the\npotential to equip these detection tools with interpretability analysis\nfeatures, making them more reliable and trustworthy in various domains like\neducation, healthcare, and media.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.04808v1",
    "published_date": "2024-09-07 12:27:25 UTC",
    "updated_date": "2024-09-07 12:27:25 UTC"
  },
  {
    "arxiv_id": "2409.04795v1",
    "title": "Phrase-Level Adversarial Training for Mitigating Bias in Neural Network-based Automatic Essay Scoring",
    "authors": [
      "Haddad Philip",
      "Tsegaye Misikir Tashu"
    ],
    "abstract": "Automatic Essay Scoring (AES) is widely used to evaluate candidates for\neducational purposes. However, due to the lack of representative data, most\nexisting AES systems are not robust, and their scoring predictions are biased\ntowards the most represented data samples. In this study, we propose a\nmodel-agnostic phrase-level method to generate an adversarial essay set to\naddress the biases and robustness of AES models. Specifically, we construct an\nattack test set comprising samples from the original test set and adversarially\ngenerated samples using our proposed method. To evaluate the effectiveness of\nthe attack strategy and data augmentation, we conducted a comprehensive\nanalysis utilizing various neural network scoring models. Experimental results\nshow that the proposed approach significantly improves AES model performance in\nthe presence of adversarial examples and scenarios without such attacks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04795v1",
    "published_date": "2024-09-07 11:22:35 UTC",
    "updated_date": "2024-09-07 11:22:35 UTC"
  },
  {
    "arxiv_id": "2409.04793v1",
    "title": "Action is the primary key: a categorical framework for episode description and logical reasoning",
    "authors": [
      "Yoshiki Fukada"
    ],
    "abstract": "This research presents a computational framework for describing and\nrecognizing episodes and for logical reasoning. This framework, named\ncognitive-logs, consists of a set of relational and graph databases.\nCognitive-logs record knowledge, particularly in episodes that consist of\n\"actions\" represented by verbs in natural languages and \"participants\" who\nperform the actions. These objects are connected by arrows (morphisms) that\nlink each action to its participant and link cause to effect. Operations based\non category theory enable comparisons between episodes and deductive\ninferences, including abstractions of stories. One of the goals of this study\nis to develop a database-driven artificial intelligence. This artificial\nintelligence thinks like a human but possesses the accuracy and rigour of a\nmachine. The vast capacities of databases (up to petabyte scales in current\ntechnologies) enable the artificial intelligence to store a greater volume of\nknowledge than neural-network based artificial intelligences. Cognitive-logs\nserve as a model of human cognition and designed with references to cognitive\nlinguistics. Cognitive-logs also have the potential to model various human mind\nactivities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 18 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.04793v1",
    "published_date": "2024-09-07 11:09:47 UTC",
    "updated_date": "2024-09-07 11:09:47 UTC"
  },
  {
    "arxiv_id": "2409.04792v2",
    "title": "Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn",
    "authors": [
      "Hongyao Tang",
      "Glen Berseth"
    ],
    "abstract": "Deep neural networks provide Reinforcement Learning (RL) powerful function\napproximators to address large-scale decision-making problems. However, these\napproximators introduce challenges due to the non-stationary nature of RL\ntraining. One source of the challenges in RL is that output predictions can\nchurn, leading to uncontrolled changes after each batch update for states not\nincluded in the batch. Although such a churn phenomenon exists in each step of\nnetwork training, how churn occurs and impacts RL remains under-explored. In\nthis work, we start by characterizing churn in a view of Generalized Policy\nIteration with function approximation, and we discover a chain effect of churn\nthat leads to a cycle where the churns in value estimation and policy\nimprovement compound and bias the learning dynamics throughout the iteration.\nFurther, we concretize the study and focus on the learning issues caused by the\nchain effect in different settings, including greedy action deviation in\nvalue-based methods, trust region violation in proximal policy optimization,\nand dual bias of policy value in actor-critic methods. We then propose a method\nto reduce the chain effect across different settings, called Churn Approximated\nReductIoN (CHAIN), which can be easily plugged into most existing DRL\nalgorithms. Our experiments demonstrate the effectiveness of our method in both\nreducing churn and improving learning performance across online and offline,\nvalue-based and policy-based RL settings, as well as a scaling setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024. Project page:\n  https://bluecontra.github.io/CHAIN",
    "pdf_url": "http://arxiv.org/pdf/2409.04792v2",
    "published_date": "2024-09-07 11:08:20 UTC",
    "updated_date": "2024-12-11 09:40:27 UTC"
  },
  {
    "arxiv_id": "2409.04787v1",
    "title": "Selective Self-Rehearsal: A Fine-Tuning Approach to Improve Generalization in Large Language Models",
    "authors": [
      "Sonam Gupta",
      "Yatin Nandwani",
      "Asaf Yehudai",
      "Mayank Mishra",
      "Gaurav Pandey",
      "Dinesh Raghu",
      "Sachindra Joshi"
    ],
    "abstract": "Fine-tuning Large Language Models (LLMs) on specific datasets is a common\npractice to improve performance on target tasks. However, this performance gain\noften leads to overfitting, where the model becomes too specialized in either\nthe task or the characteristics of the training data, resulting in a loss of\ngeneralization. This paper introduces Selective Self-Rehearsal (SSR), a\nfine-tuning approach that achieves performance comparable to the standard\nsupervised fine-tuning (SFT) while improving generalization. SSR leverages the\nfact that there can be multiple valid responses to a query. By utilizing the\nmodel's correct responses, SSR reduces model specialization during the\nfine-tuning stage. SSR first identifies the correct model responses from the\ntraining set by deploying an appropriate LLM as a judge. Then, it fine-tunes\nthe model using the correct model responses and the gold response for the\nremaining samples. The effectiveness of SSR is demonstrated through experiments\non the task of identifying unanswerable queries across various datasets. The\nresults show that standard SFT can lead to an average performance drop of up to\n$16.7\\%$ on multiple benchmarks, such as MMLU and TruthfulQA. In contrast, SSR\nresults in close to $2\\%$ drop on average, indicating better generalization\ncapabilities compared to standard SFT.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.04787v1",
    "published_date": "2024-09-07 10:21:03 UTC",
    "updated_date": "2024-09-07 10:21:03 UTC"
  },
  {
    "arxiv_id": "2409.13714v1",
    "title": "TracrBench: Generating Interpretability Testbeds with Large Language Models",
    "authors": [
      "Hannes Thurnherr",
      "Jérémy Scheurer"
    ],
    "abstract": "Achieving a mechanistic understanding of transformer-based language models is\nan open challenge, especially due to their large number of parameters.\nMoreover, the lack of ground truth mappings between model weights and their\nfunctional roles hinders the effective evaluation of interpretability methods,\nimpeding overall progress. Tracr, a method for generating compiled transformers\nwith inherent ground truth mappings in RASP, has been proposed to address this\nissue. However, manually creating a large number of models needed for verifying\ninterpretability methods is labour-intensive and time-consuming. In this work,\nwe present a novel approach for generating interpretability test beds using\nlarge language models (LLMs) and introduce TracrBench, a novel dataset\nconsisting of 121 manually written and LLM-generated, human-validated RASP\nprograms and their corresponding transformer weights. During this process, we\nevaluate the ability of frontier LLMs to autonomously generate RASP programs\nand find that this task poses significant challenges. GPT-4-turbo, with a\n20-shot prompt and best-of-5 sampling, correctly implements only 57 out of 101\ntest programs, necessitating the manual implementation of the remaining\nprograms. With its 121 samples, TracrBench aims to serve as a valuable testbed\nfor evaluating and comparing interpretability methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages + appendix, 4 figures, ICML Mechanistic Interpretability\n  Workshop",
    "pdf_url": "http://arxiv.org/pdf/2409.13714v1",
    "published_date": "2024-09-07 10:02:51 UTC",
    "updated_date": "2024-09-07 10:02:51 UTC"
  },
  {
    "arxiv_id": "2409.04775v3",
    "title": "Scalable Task Planning via Large Language Models and Structured World Representations",
    "authors": [
      "Rodrigo Pérez-Dattari",
      "Zhaoting Li",
      "Robert Babuška",
      "Jens Kober",
      "Cosimo Della Santina"
    ],
    "abstract": "Planning methods struggle with computational intractability in solving\ntask-level problems in large-scale environments. This work explores leveraging\nthe commonsense knowledge encoded in LLMs to empower planning techniques to\ndeal with these complex scenarios. We achieve this by efficiently using LLMs to\nprune irrelevant components from the planning problem's state space,\nsubstantially simplifying its complexity. We demonstrate the efficacy of this\nsystem through extensive experiments within a household simulation environment,\nalongside real-world validation using a 7-DoF manipulator (video\nhttps://youtu.be/6ro2UOtOQS4).",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.04775v3",
    "published_date": "2024-09-07 09:30:26 UTC",
    "updated_date": "2025-02-12 20:13:21 UTC"
  },
  {
    "arxiv_id": "2409.04774v1",
    "title": "Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models",
    "authors": [
      "Junfeng Tian",
      "Da Zheng",
      "Yang Cheng",
      "Rui Wang",
      "Colin Zhang",
      "Debing Zhang"
    ],
    "abstract": "Large language models (LLM) have prioritized expanding the context window\nfrom which models can incorporate more information. However, training models to\nhandle long contexts presents significant challenges. These include the\nscarcity of high-quality natural long-context data, the potential for\nperformance degradation on short-context tasks, and the reduced training\nefficiency associated with attention mechanisms. In this paper, we introduce\nUntie the Knots (\\textbf{UtK}), a novel data augmentation strategy employed\nduring the continue pre-training phase, designed to efficiently enable LLMs to\ngain long-context capabilities without the need to modify the existing data\nmixture. In particular, we chunk the documents, shuffle the chunks, and create\na complex and knotted structure of long texts; LLMs are then trained to untie\nthese knots and identify relevant segments within seemingly chaotic token\nsequences. This approach greatly improves the model's performance by accurately\nattending to relevant information in long context and the training efficiency\nis also largely increased. We conduct extensive experiments on models with 7B\nand 72B parameters, trained on 20 billion tokens, demonstrating that UtK\nachieves 75\\% and 84.5\\% accurracy on RULER at 128K context length,\nsignificantly outperforming other long context strategies. The trained models\nwill open-source for further research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04774v1",
    "published_date": "2024-09-07 09:28:55 UTC",
    "updated_date": "2024-09-07 09:28:55 UTC"
  },
  {
    "arxiv_id": "2409.04744v2",
    "title": "Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework",
    "authors": [
      "Yongxin Deng",
      "Xihe Qiu",
      "Jue Chen",
      "Xiaoyu Tan"
    ],
    "abstract": "The inherent uncertainty in the environmental transition model of\nReinforcement Learning (RL) necessitates a delicate balance between exploration\nand exploitation. This balance is crucial for optimizing computational\nresources to accurately estimate expected rewards for the agent. In scenarios\nwith sparse rewards, such as robotic control systems, achieving this balance is\nparticularly challenging. However, given that many environments possess\nextensive prior knowledge, learning from the ground up in such contexts may be\nredundant. To address this issue, we propose Language Model Guided reward\nTuning (LMGT), a novel, sample-efficient framework. LMGT leverages the\ncomprehensive prior knowledge embedded in Large Language Models (LLMs) and\ntheir proficiency in processing non-standard data forms, such as wiki\ntutorials. By utilizing LLM-guided reward shifts, LMGT adeptly balances\nexploration and exploitation, thereby guiding the agent's exploratory behavior\nand enhancing sample efficiency. We have rigorously evaluated LMGT across\nvarious RL tasks and evaluated it in the embodied robotic environment\nHousekeep. Our results demonstrate that LMGT consistently outperforms baseline\nmethods. Furthermore, the findings suggest that our framework can substantially\nreduce the computational resources required during the RL training phase.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04744v2",
    "published_date": "2024-09-07 07:40:43 UTC",
    "updated_date": "2025-05-02 09:58:28 UTC"
  },
  {
    "arxiv_id": "2409.15329v1",
    "title": "Causality-Driven Reinforcement Learning for Joint Communication and Sensing",
    "authors": [
      "Anik Roy",
      "Serene Banerjee",
      "Jishnu Sadasivan",
      "Arnab Sarkar",
      "Soumyajit Dey"
    ],
    "abstract": "The next-generation wireless network, 6G and beyond, envisions to integrate\ncommunication and sensing to overcome interference, improve spectrum\nefficiency, and reduce hardware and power consumption. Massive Multiple-Input\nMultiple Output (mMIMO)-based Joint Communication and Sensing (JCAS) systems\nrealize this integration for 6G applications such as autonomous driving, as it\nrequires accurate environmental sensing and time-critical communication with\nneighboring vehicles. Reinforcement Learning (RL) is used for mMIMO antenna\nbeamforming in the existing literature. However, the huge search space for\nactions associated with antenna beamforming causes the learning process for the\nRL agent to be inefficient due to high beam training overhead. The learning\nprocess does not consider the causal relationship between action space and the\nreward, and gives all actions equal importance. In this work, we explore a\ncausally-aware RL agent which can intervene and discover causal relationships\nfor mMIMO-based JCAS environments, during the training phase. We use a state\ndependent action dimension selection strategy to realize causal discovery for\nRL-based JCAS. Evaluation of the causally-aware RL framework in different JCAS\nscenarios shows the benefit of our proposed framework over baseline methods in\nterms of the beamforming gain.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "18 pages, 9 figures, 4 tables, 1 algorithm",
    "pdf_url": "http://arxiv.org/pdf/2409.15329v1",
    "published_date": "2024-09-07 07:15:57 UTC",
    "updated_date": "2024-09-07 07:15:57 UTC"
  },
  {
    "arxiv_id": "2409.04740v1",
    "title": "Up-sampling-only and Adaptive Mesh-based GNN for Simulating Physical Systems",
    "authors": [
      "Fu Lin",
      "Jiasheng Shi",
      "Shijie Luo",
      "Qinpei Zhao",
      "Weixiong Rao",
      "Lei Chen"
    ],
    "abstract": "Traditional simulation of complex mechanical systems relies on numerical\nsolvers of Partial Differential Equations (PDEs), e.g., using the Finite\nElement Method (FEM). The FEM solvers frequently suffer from intensive\ncomputation cost and high running time. Recent graph neural network (GNN)-based\nsimulation models can improve running time meanwhile with acceptable accuracy.\nUnfortunately, they are hard to tailor GNNs for complex mechanical systems,\nincluding such disadvantages as ineffective representation and inefficient\nmessage propagation (MP). To tackle these issues, in this paper, with the\nproposed Up-sampling-only and Adaptive MP techniques, we develop a novel\nhierarchical Mesh Graph Network, namely UA-MGN, for efficient and effective\nmechanical simulation. Evaluation on two synthetic and one real datasets\ndemonstrates the superiority of the UA-MGN. For example, on the Beam dataset,\ncompared to the state-of-the-art MS-MGN, UA-MGN leads to 40.99% lower errors\nbut using only 43.48% fewer network parameters and 4.49% fewer floating point\noperations (FLOPs).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04740v1",
    "published_date": "2024-09-07 07:09:58 UTC",
    "updated_date": "2024-09-07 07:09:58 UTC"
  },
  {
    "arxiv_id": "2409.04732v2",
    "title": "VidLPRO: A $\\underline{Vid}$eo-$\\underline{L}$anguage $\\underline{P}$re-training Framework for $\\underline{Ro}$botic and Laparoscopic Surgery",
    "authors": [
      "Mohammadmahdi Honarmand",
      "Muhammad Abdullah Jamal",
      "Omid Mohareri"
    ],
    "abstract": "We introduce VidLPRO, a novel video-language (VL) pre-training framework\ndesigned specifically for robotic and laparoscopic surgery. While existing\nsurgical VL models primarily rely on contrastive learning, we propose a more\ncomprehensive approach to capture the intricate temporal dynamics and align\nvideo with language. VidLPRO integrates video-text contrastive learning,\nvideo-text matching, and masked language modeling objectives to learn rich VL\nrepresentations. To support this framework, we present GenSurg+, a carefully\ncurated dataset derived from GenSurgery, comprising 17k surgical video clips\npaired with captions generated by GPT-4 using transcripts extracted by the\nWhisper model. This dataset addresses the need for large-scale, high-quality VL\ndata in the surgical domain. Extensive experiments on benchmark datasets,\nincluding Cholec80 and AutoLaparo, demonstrate the efficacy of our approach.\nVidLPRO achieves state-of-the-art performance in zero-shot surgical phase\nrecognition, significantly outperforming existing surgical VL models such as\nSurgVLP and HecVL. Our model demonstrates improvements of up to 21.5\\% in\naccuracy and 15.7% in F1 score, setting a new benchmark in the field. Notably,\nVidLPRO exhibits robust performance even with single-frame inference, while\neffectively scaling with increased temporal context. Ablation studies reveal\nthe impact of frame sampling strategies on model performance and computational\nefficiency. These results underscore VidLPRO's potential as a foundation model\nfor surgical video understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04732v2",
    "published_date": "2024-09-07 06:33:12 UTC",
    "updated_date": "2024-09-11 23:12:53 UTC"
  },
  {
    "arxiv_id": "2409.04723v1",
    "title": "NapTune: Efficient Model Tuning for Mood Classification using Previous Night's Sleep Measures along with Wearable Time-series",
    "authors": [
      "Debaditya Shome",
      "Nasim Montazeri Ghahjaverestan",
      "Ali Etemad"
    ],
    "abstract": "Sleep is known to be a key factor in emotional regulation and overall mental\nhealth. In this study, we explore the integration of sleep measures from the\nprevious night into wearable-based mood recognition. To this end, we propose\nNapTune, a novel prompt-tuning framework that utilizes sleep-related measures\nas additional inputs to a frozen pre-trained wearable time-series encoder by\nadding and training lightweight prompt parameters to each Transformer layer.\nThrough rigorous empirical evaluation, we demonstrate that the inclusion of\nsleep data using NapTune not only improves mood recognition performance across\ndifferent wearable time-series namely ECG, PPG, and EDA, but also makes it more\nsample-efficient. Our method demonstrates significant improvements over the\nbest baselines and unimodal variants. Furthermore, we analyze the impact of\nadding sleep-related measures on recognizing different moods as well as the\ninfluence of individual sleep-related measures.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted at ICMI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.04723v1",
    "published_date": "2024-09-07 06:06:04 UTC",
    "updated_date": "2024-09-07 06:06:04 UTC"
  },
  {
    "arxiv_id": "2409.04720v1",
    "title": "A Comprehensive Survey on Evidential Deep Learning and Its Applications",
    "authors": [
      "Junyu Gao",
      "Mengyuan Chen",
      "Liangyu Xiang",
      "Changsheng Xu"
    ],
    "abstract": "Reliable uncertainty estimation has become a crucial requirement for the\nindustrial deployment of deep learning algorithms, particularly in high-risk\napplications such as autonomous driving and medical diagnosis. However,\nmainstream uncertainty estimation methods, based on deep ensembling or Bayesian\nneural networks, generally impose substantial computational overhead. To\naddress this challenge, a novel paradigm called Evidential Deep Learning (EDL)\nhas emerged, providing reliable uncertainty estimation with minimal additional\ncomputation in a single forward pass. This survey provides a comprehensive\noverview of the current research on EDL, designed to offer readers a broad\nintroduction to the field without assuming prior knowledge. Specifically, we\nfirst delve into the theoretical foundation of EDL, the subjective logic\ntheory, and discuss its distinctions from other uncertainty estimation\nframeworks. We further present existing theoretical advancements in EDL from\nfour perspectives: reformulating the evidence collection process, improving\nuncertainty estimation via OOD samples, delving into various training\nstrategies, and evidential regression networks. Thereafter, we elaborate on its\nextensive applications across various machine learning paradigms and downstream\ntasks. In the end, an outlook on future directions for better performances and\nbroader adoption of EDL is provided, highlighting potential research avenues.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04720v1",
    "published_date": "2024-09-07 05:55:06 UTC",
    "updated_date": "2024-09-07 05:55:06 UTC"
  },
  {
    "arxiv_id": "2409.04711v1",
    "title": "Algorithmic Scenario Generation as Quality Diversity Optimization",
    "authors": [
      "Stefanos Nikolaidis"
    ],
    "abstract": "The increasing complexity of robots and autonomous agents that interact with\npeople highlights the critical need for approaches that systematically test\nthem before deployment. This review paper presents a general framework for\nsolving this problem, describes the insights that we have gained from working\non each component of the framework, and shows how integrating these components\nleads to the discovery of a diverse range of realistic and challenging\nscenarios that reveal previously unknown failures in deployed robotic systems\ninteracting with people.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04711v1",
    "published_date": "2024-09-07 05:20:41 UTC",
    "updated_date": "2024-09-07 05:20:41 UTC"
  },
  {
    "arxiv_id": "2409.04707v1",
    "title": "Enhancing Deep Learning with Optimized Gradient Descent: Bridging Numerical Methods and Neural Network Training",
    "authors": [
      "Yuhan Ma",
      "Dan Sun",
      "Erdi Gao",
      "Ningjing Sang",
      "Iris Li",
      "Guanming Huang"
    ],
    "abstract": "Optimization theory serves as a pivotal scientific instrument for achieving\noptimal system performance, with its origins in economic applications to\nidentify the best investment strategies for maximizing benefits. Over the\ncenturies, from the geometric inquiries of ancient Greece to the calculus\ncontributions by Newton and Leibniz, optimization theory has significantly\nadvanced. The persistent work of scientists like Lagrange, Cauchy, and von\nNeumann has fortified its progress. The modern era has seen an unprecedented\nexpansion of optimization theory applications, particularly with the growth of\ncomputer science, enabling more sophisticated computational practices and\nwidespread utilization across engineering, decision analysis, and operations\nresearch. This paper delves into the profound relationship between optimization\ntheory and deep learning, highlighting the omnipresence of optimization\nproblems in the latter. We explore the gradient descent algorithm and its\nvariants, which are the cornerstone of optimizing neural networks. The chapter\nintroduces an enhancement to the SGD optimizer, drawing inspiration from\nnumerical optimization methods, aiming to enhance interpretability and\naccuracy. Our experiments on diverse deep learning tasks substantiate the\nimproved algorithm's efficacy. The paper concludes by emphasizing the\ncontinuous development of optimization theory and its expanding role in solving\nintricate problems, enhancing computational capabilities, and informing better\npolicy decisions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04707v1",
    "published_date": "2024-09-07 04:37:20 UTC",
    "updated_date": "2024-09-07 04:37:20 UTC"
  },
  {
    "arxiv_id": "2409.04704v1",
    "title": "A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting",
    "authors": [
      "Cheng Wan",
      "Chenjie Xie",
      "Longfei Liu",
      "Dan Wu",
      "Ye Li"
    ],
    "abstract": "Continuous blood pressure (BP) monitoring is essential for timely diagnosis\nand intervention in critical care settings. However, BP varies significantly\nacross individuals, this inter-patient variability motivates the development of\npersonalized models tailored to each patient's physiology. In this work, we\npropose a personalized BP forecasting model mainly using electrocardiogram\n(ECG) and photoplethysmogram (PPG) signals. This time-series model incorporates\n2D representation learning to capture complex physiological relationships.\nExperiments are conducted on datasets collected from three diverse scenarios\nwith BP measurements from 60 subjects total. Results demonstrate that the model\nachieves accurate and robust BP forecasts across scenarios within the\nAssociation for the Advancement of Medical Instrumentation (AAMI) standard\ncriteria. This reliable early detection of abnormal fluctuations in BP is\ncrucial for at-risk patients undergoing surgery or intensive care. The proposed\nmodel provides a valuable addition for continuous BP tracking to reduce\nmortality and improve prognosis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.04704v1",
    "published_date": "2024-09-07 04:24:15 UTC",
    "updated_date": "2024-09-07 04:24:15 UTC"
  },
  {
    "arxiv_id": "2409.04693v1",
    "title": "MuAP: Multi-step Adaptive Prompt Learning for Vision-Language Model with Missing Modality",
    "authors": [
      "Ruiting Dai",
      "Yuqiao Tan",
      "Lisi Mo",
      "Tao He",
      "Ke Qin",
      "Shuang Liang"
    ],
    "abstract": "Recently, prompt learning has garnered considerable attention for its success\nin various Vision-Language (VL) tasks. However, existing prompt-based models\nare primarily focused on studying prompt generation and prompt strategies with\ncomplete modality settings, which does not accurately reflect real-world\nscenarios where partial modality information may be missing. In this paper, we\npresent the first comprehensive investigation into prompt learning behavior\nwhen modalities are incomplete, revealing the high sensitivity of prompt-based\nmodels to missing modalities. To this end, we propose a novel Multi-step\nAdaptive Prompt Learning (MuAP) framework, aiming to generate multimodal\nprompts and perform multi-step prompt tuning, which adaptively learns knowledge\nby iteratively aligning modalities. Specifically, we generate multimodal\nprompts for each modality and devise prompt strategies to integrate them into\nthe Transformer model. Subsequently, we sequentially perform prompt tuning from\nsingle-stage and alignment-stage, allowing each modality-prompt to be\nautonomously and adaptively learned, thereby mitigating the imbalance issue\ncaused by only textual prompts that are learnable in previous works. Extensive\nexperiments demonstrate the effectiveness of our MuAP and this model achieves\nsignificant improvements compared to the state-of-the-art on all benchmark\ndatasets",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04693v1",
    "published_date": "2024-09-07 03:33:46 UTC",
    "updated_date": "2024-09-07 03:33:46 UTC"
  },
  {
    "arxiv_id": "2409.13712v1",
    "title": "Good Idea or Not, Representation of LLM Could Tell",
    "authors": [
      "Yi Xu",
      "Bo Xue",
      "Shuqian Sheng",
      "Cheng Deng",
      "Jiaxin Ding",
      "Zanwei Shen",
      "Luoyi Fu",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "abstract": "In the ever-expanding landscape of academic research, the proliferation of\nideas presents a significant challenge for researchers: discerning valuable\nideas from the less impactful ones. The ability to efficiently evaluate the\npotential of these ideas is crucial for the advancement of science and paper\nreview. In this work, we focus on idea assessment, which aims to leverage the\nknowledge of large language models to assess the merit of scientific ideas.\nFirst, we investigate existing text evaluation research and define the problem\nof quantitative evaluation of ideas. Second, we curate and release a benchmark\ndataset from nearly four thousand manuscript papers with full texts,\nmeticulously designed to train and evaluate the performance of different\napproaches to this task. Third, we establish a framework for quantifying the\nvalue of ideas by employing representations in a specific layer of large\nlanguage models. Experimental results show that the scores predicted by our\nmethod are relatively consistent with those of humans. Our findings suggest\nthat the representations of large language models hold more potential in\nquantifying the value of ideas than their generative outputs, demonstrating a\npromising avenue for automating the idea assessment process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13712v1",
    "published_date": "2024-09-07 02:07:22 UTC",
    "updated_date": "2024-09-07 02:07:22 UTC"
  }
]