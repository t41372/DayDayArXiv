[
  {
    "arxiv_id": "2409.15359v2",
    "title": "Watch Your Steps: Observable and Modular Chains of Thought",
    "authors": [
      "Cassandra A. Cohen",
      "William W. Cohen"
    ],
    "abstract": "We propose a variant of chain of thought (CoT) prompting called Program Trace\nPrompting that makes explanations more observable while preserving the power,\ngenerality and flexibility of CoT. In our approach, few-shot CoT demonstrations\nare wrapped in a formal syntax based on Python, and each prompt: identifies and\nnames steps; defines the input/output behavior of steps; and replaces CoT\nexplanations of in-context examples with chains of these formalized steps on\nthe same examples. Program Trace Prompting is applicable to many tasks,\nachieving strong results on the 23 diverse tasks in the BIG-Bench Hard\nbenchmark. More importantly, by instrumenting explanations in this way, we\nenable new types of analysis. In particular, we identify \"non-local errors\"\n(which correspond to incorrectly learning the reasoning method illustrated in\nthe demonstrations) as an unaddressed issue in CoT learning, and we present\nmethods for verifying the modularity of steps in a CoT explanation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15359v2",
    "published_date": "2024-09-17 23:47:20 UTC",
    "updated_date": "2024-10-01 20:24:38 UTC"
  },
  {
    "arxiv_id": "2409.11605v1",
    "title": "Harnessing AI data-driven global weather models for climate attribution: An analysis of the 2017 Oroville Dam extreme atmospheric river",
    "authors": [
      "Jorge Baño-Medina",
      "Agniv Sengupta",
      "Allison Michaelis",
      "Luca Delle Monache",
      "Julie Kalansky",
      "Duncan Watson-Parris"
    ],
    "abstract": "AI data-driven models (Graphcast, Pangu Weather, Fourcastnet, and SFNO) are\nexplored for storyline-based climate attribution due to their short inference\ntimes, which can accelerate the number of events studied, and provide real time\nattributions when public attention is heightened. The analysis is framed on the\nextreme atmospheric river episode of February 2017 that contributed to the\nOroville dam spillway incident in Northern California. Past and future\nsimulations are generated by perturbing the initial conditions with the\npre-industrial and the late-21st century temperature climate change signals,\nrespectively. The simulations are compared to results from a dynamical model\nwhich represents plausible pseudo-realities under both climate environments.\nOverall, the AI models show promising results, projecting a 5-6 % increase in\nthe integrated water vapor over the Oroville dam in the present day compared to\nthe pre-industrial, in agreement with the dynamical model. Different\ngeopotential-moisture-temperature dependencies are unveiled for each of the\nAI-models tested, providing valuable information for understanding the\nphysicality of the attribution response. However, the AI models tend to\nsimulate weaker attribution values than the pseudo-reality imagined by the\ndynamical model, suggesting some reduced extrapolation skill, especially for\nthe late-21st century regime. Large ensembles generated with an AI model (>500\nmembers) produced statistically significant present-day to pre-industrial\nattribution results, unlike the >20-member ensemble from the dynamical model.\nThis analysis highlights the potential of AI models to conduct attribution\nanalysis, while emphasizing future lines of work on explainable artificial\nintelligence to gain confidence in these tools, which can enable reliable\nattribution studies in real-time.",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "This Work has been submitted to Artificial Intelligence for the Earth\n  Systems",
    "pdf_url": "http://arxiv.org/pdf/2409.11605v1",
    "published_date": "2024-09-17 23:34:39 UTC",
    "updated_date": "2024-09-17 23:34:39 UTC"
  },
  {
    "arxiv_id": "2409.11600v1",
    "title": "No Saved Kaleidosope: an 100% Jitted Neural Network Coding Language with Pythonic Syntax",
    "authors": [
      "Augusto Seben da Rosa",
      "Marlon Daniel Angeli",
      "Jorge Aikes Junior",
      "Alef Iury Ferreira",
      "Lucas Rafael Gris",
      "Anderson da Silva Soares",
      "Arnaldo Candido Junior",
      "Frederico Santos de Oliveira",
      "Gabriel Trevisan Damke",
      "Rafael Teixeira Sousa"
    ],
    "abstract": "We developed a jitted compiler for training Artificial Neural Networks using\nC++, LLVM and Cuda. It features object-oriented characteristics, strong typing,\nparallel workers for data pre-processing, pythonic syntax for expressions,\nPyTorch like model declaration and Automatic Differentiation. We implement the\nmechanisms of cache and pooling in order to manage VRAM, cuBLAS for high\nperformance matrix multiplication and cuDNN for convolutional layers. Our\nexperiments with Residual Convolutional Neural Networks on ImageNet, we reach\nsimilar speed but degraded performance. Also, the GRU network experiments show\nsimilar accuracy, but our compiler have degraded speed in that task. However,\nour compiler demonstrates promising results at the CIFAR-10 benchmark, in which\nwe reach the same performance and about the same speed as PyTorch. We make the\ncode publicly available at: https://github.com/NoSavedDATA/NoSavedKaleidoscope",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LG",
      "68T07",
      "D.3; I.2; I.4; I.7"
    ],
    "primary_category": "cs.PL",
    "comment": "12 pages, 3 figures and 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.11600v1",
    "published_date": "2024-09-17 23:15:39 UTC",
    "updated_date": "2024-09-17 23:15:39 UTC"
  },
  {
    "arxiv_id": "2409.11598v3",
    "title": "Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation",
    "authors": [
      "To Eun Kim",
      "Fernando Diaz"
    ],
    "abstract": "Modern language models frequently include retrieval components to improve\ntheir outputs, giving rise to a growing number of retrieval-augmented\ngeneration (RAG) systems. Yet, most existing work in RAG has underemphasized\nfair ranking techniques and neglected the diverse interests of all\nstakeholders. In this paper, we present the first comprehensive study of RAG\nsystems that incorporate fairness-aware rankings, focusing on both ranking\nfairness and attribution fairness - ensuring equitable exposure of sources\ncited in the final text. We specifically examine item-side fairness, i.e.,\nwhether retrieved documents receive balanced exposure, and assess how this\naffects both the system's overall performance and the eventual distribution of\ncited sources. Across twelve RAG models and seven tasks, we find that\nfairness-aware retrieval frequently retains or even improves ranking\neffectiveness and generation quality, countering the widespread belief that\nfairness compromises system performance. Moreover, we show that fair retrieval\nleads to more balanced attribution in the final responses, ensuring that the\ncited sources are credited more equitably. Our results underscore the\nimportance of item-side fairness throughout both retrieval and generation\nphases, offering key insights for building more responsible and equitable RAG\nsystems and illustrating promising avenues for future exploration in fair\nranking and source attribution.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Top 5 Spotlight at AFME Workshop at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.11598v3",
    "published_date": "2024-09-17 23:10:04 UTC",
    "updated_date": "2025-02-25 04:13:34 UTC"
  },
  {
    "arxiv_id": "2409.11593v2",
    "title": "Self-Contrastive Forward-Forward Algorithm",
    "authors": [
      "Xing Chen",
      "Dongshu Liu",
      "Jeremie Laydevant",
      "Julie Grollier"
    ],
    "abstract": "Agents that operate autonomously benefit from lifelong learning capabilities.\nHowever, compatible training algorithms must comply with the decentralized\nnature of these systems, which imposes constraints on both the parameter counts\nand the computational resources. The Forward-Forward (FF) algorithm is one of\nthese. FF relies only on feedforward operations, the same used for inference,\nfor optimizing layer-wise objectives. This purely forward approach eliminates\nthe need for transpose operations required in traditional backpropagation.\nDespite its potential, FF has failed to reach state-of-the-art performance on\nmost standard benchmark tasks, in part due to unreliable negative data\ngeneration methods for unsupervised learning.\n  In this work, we propose the Self-Contrastive Forward-Forward (SCFF)\nalgorithm, a competitive training method aimed at closing this performance gap.\nInspired by standard self-supervised contrastive learning for vision tasks,\nSCFF generates positive and negative inputs applicable across various datasets.\nThe method demonstrates superior performance compared to existing unsupervised\nlocal learning algorithms on several benchmark datasets, including MNIST,\nCIFAR-10, STL-10, and Tiny ImageNet. We extend FF's application to training\nrecurrent neural networks, expanding its utility to sequential data tasks.\nThese findings pave the way for high-accuracy, real-time learning on\nresource-constrained edge devices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11593v2",
    "published_date": "2024-09-17 22:58:20 UTC",
    "updated_date": "2025-03-27 15:57:57 UTC"
  },
  {
    "arxiv_id": "2409.17169v3",
    "title": "REAL: Response Embedding-based Alignment for LLMs",
    "authors": [
      "Honggen Zhang",
      "Xufeng Zhao",
      "Igor Molybog",
      "June Zhang"
    ],
    "abstract": "Aligning large language models (LLMs) to human preferences is a crucial step\nin building helpful and safe AI tools, which usually involve training on\nsupervised datasets. Popular algorithms such as Direct Preference Optimization\nrely on pairs of AI-generated responses ranked according to human feedback. The\nresponse pair annotation process is the most labor-intensive and costly part of\nthe alignment pipeline, and improving its efficiency and annotation quality\nwould have a meaningful impact on AI development. We propose REAL: Response\nEmbedding-based Alignment for LLMs, a strategy for constructing a high-quality\ntraining dataset that focuses on acquiring the most informative response pairs\nfor labeling out of a set of response candidates. Our selection process is\nbased on embedding responses independently of prompts. Experimental results on\nreal-world dataset SHP2 and synthetic HH-RLHF benchmarks indicate that choosing\ndissimilar response pairs enhances the direct alignment of LLMs while reducing\ninherited labeling errors. The model aligned on dissimilar response pairs\nobtained a better margin and win rate on the dialogue task. Our findings\nsuggest that focusing on distinct pairs can reduce the label error to improve\nthe efficiency of LLM alignment, saving up to 65% of annotators' work.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17169v3",
    "published_date": "2024-09-17 22:40:54 UTC",
    "updated_date": "2024-12-21 02:07:14 UTC"
  },
  {
    "arxiv_id": "2409.11589v1",
    "title": "ProSLM : A Prolog Synergized Language Model for explainable Domain Specific Knowledge Based Question Answering",
    "authors": [
      "Priyesh Vakharia",
      "Abigail Kufeldt",
      "Max Meyers",
      "Ian Lane",
      "Leilani Gilpin"
    ],
    "abstract": "Neurosymbolic approaches can add robustness to opaque neural systems by\nincorporating explainable symbolic representations. However, previous\napproaches have not used formal logic to contextualize queries to and validate\noutputs of large language models (LLMs). We propose \\systemname{}, a novel\nneurosymbolic framework, to improve the robustness and reliability of LLMs in\nquestion-answering tasks. We provide \\systemname{} with a domain-specific\nknowledge base, a logical reasoning system, and an integration to an existing\nLLM. This framework has two capabilities (1) context gathering: generating\nexplainable and relevant context for a given query, and (2) validation:\nconfirming and validating the factual accuracy of a statement in accordance\nwith a knowledge base (KB). Our work opens a new area of neurosymbolic\ngenerative AI text validation and user personalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeSy 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.11589v1",
    "published_date": "2024-09-17 22:34:33 UTC",
    "updated_date": "2024-09-17 22:34:33 UTC"
  },
  {
    "arxiv_id": "2410.03552v1",
    "title": "Evaluating Investment Risks in LATAM AI Startups: Ranking of Investment Potential and Framework for Valuation",
    "authors": [
      "Abraham Ramos-Torres",
      "Laura N. Montoya"
    ],
    "abstract": "The growth of the tech startup ecosystem in Latin America (LATAM) is driven\nby innovative entrepreneurs addressing market needs across various sectors.\nHowever, these startups encounter unique challenges and risks that require\nspecific management approaches. This paper explores a case study with the Total\nAddressable Market (TAM), Serviceable Available Market (SAM), and Serviceable\nObtainable Market (SOM) metrics within the context of the online food delivery\nindustry in LATAM, serving as a model for valuing startups using the Discounted\nCash Flow (DCF) method. By analyzing key emerging powers such as Argentina,\nColombia, Uruguay, Costa Rica, Panama, and Ecuador, the study highlights the\npotential and profitability of AI-driven startups in the region through the\ndevelopment of a ranking of emerging powers in Latin America for tech startup\ninvestment. The paper also examines the political, economic, and competitive\nrisks faced by startups and offers strategic insights on mitigating these risks\nto maximize investment returns. Furthermore, the research underscores the value\nof diversifying investment portfolios with startups in emerging markets,\nemphasizing the opportunities for substantial growth and returns despite\ninherent risks.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "q-fin.PM",
      "q-fin.PR"
    ],
    "primary_category": "q-fin.GN",
    "comment": "21 pages, 7 figures, 8 tables, Accepted for publication to the\n  International Association for Applied Business Research Journal (IAABR)",
    "pdf_url": "http://arxiv.org/pdf/2410.03552v1",
    "published_date": "2024-09-17 22:31:46 UTC",
    "updated_date": "2024-09-17 22:31:46 UTC"
  },
  {
    "arxiv_id": "2409.11583v1",
    "title": "Uncertainty Decomposition and Error Margin Detection of Homodyned-K Distribution in Quantitative Ultrasound",
    "authors": [
      "Dorsa Ameri",
      "Ali K. Z. Tehrani",
      "Ivan M. Rosado-Mendez",
      "Hassan Rivaz"
    ],
    "abstract": "Homodyned K-distribution (HK-distribution) parameter estimation in\nquantitative ultrasound (QUS) has been recently addressed using Bayesian Neural\nNetworks (BNNs). BNNs have been shown to significantly reduce computational\ntime in speckle statistics-based QUS without compromising accuracy and\nprecision. Additionally, they provide estimates of feature uncertainty, which\ncan guide the clinician's trust in the reported feature value. The total\npredictive uncertainty in Bayesian modeling can be decomposed into epistemic\n(uncertainty over the model parameters) and aleatoric (uncertainty inherent in\nthe data) components. By decomposing the predictive uncertainty, we can gain\ninsights into the factors contributing to the total uncertainty. In this study,\nwe propose a method to compute epistemic and aleatoric uncertainties for\nHK-distribution parameters ($\\alpha$ and $k$) estimated by a BNN, in both\nsimulation and experimental data. In addition, we investigate the relationship\nbetween the prediction error and both uncertainties, shedding light on the\ninterplay between these uncertainties and HK parameters errors.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "eess.IV",
      "physics.med-ph",
      "stat.ML"
    ],
    "primary_category": "eess.SP",
    "comment": "4 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.11583v1",
    "published_date": "2024-09-17 22:16:49 UTC",
    "updated_date": "2024-09-17 22:16:49 UTC"
  },
  {
    "arxiv_id": "2409.18992v2",
    "title": "A Review of Mechanistic Models of Event Comprehension",
    "authors": [
      "Tan T. Nguyen"
    ],
    "abstract": "This review examines theoretical assumptions and computational models of\nevent comprehension, tracing the evolution from discourse comprehension\ntheories to contemporary event cognition frameworks. The review covers key\ndiscourse comprehension accounts, including Construction-Integration, Event\nIndexing, Causal Network, and Resonance models, highlighting their\ncontributions to understanding cognitive processes in comprehension. I then\ndiscuss contemporary theoretical frameworks of event comprehension, including\nEvent Segmentation Theory (Zacks et al., 2007), the Event Horizon Model\n(Radvansky & Zacks, 2014), and Hierarchical Generative Framework (Kuperberg,\n2021), which emphasize prediction, causality, and multilevel representations in\nevent understanding. Building on these theories, I evaluate five computational\nmodels of event comprehension: REPRISE (Butz et al., 2019), Structured Event\nMemory (SEM; Franklin et al., 2020), the Lu model (Lu et al., 2022), the\nGumbsch model (Gumbsch et al., 2022), and the Elman and McRae model (2019). The\nanalysis focuses on their approaches to hierarchical processing, prediction\nmechanisms, and representation learning. Key themes that emerge include the use\nof hierarchical structures as inductive biases, the importance of prediction in\ncomprehension, and diverse strategies for learning event dynamics. The review\nidentifies critical areas for future research, including the need for more\nsophisticated approaches to learning structured representations, integrating\nepisodic memory mechanisms, and developing adaptive updating algorithms for\nworking event models. By synthesizing insights from both theoretical frameworks\nand computational implementations, this review aims to advance our\nunderstanding of human event comprehension and guide future modeling efforts in\ncognitive science.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.18992v2",
    "published_date": "2024-09-17 22:10:05 UTC",
    "updated_date": "2024-11-25 16:55:33 UTC"
  },
  {
    "arxiv_id": "2409.11576v1",
    "title": "Automating proton PBS treatment planning for head and neck cancers using policy gradient-based deep reinforcement learning",
    "authors": [
      "Qingqing Wang",
      "Chang Chang"
    ],
    "abstract": "Proton pencil beam scanning (PBS) treatment planning for head and neck (H&N)\ncancers is a time-consuming and experience-demanding task where a large number\nof planning objectives are involved. Deep reinforcement learning (DRL) has\nrecently been introduced to the planning processes of intensity-modulated\nradiation therapy and brachytherapy for prostate, lung, and cervical cancers.\nHowever, existing approaches are built upon the Q-learning framework and\nweighted linear combinations of clinical metrics, suffering from poor\nscalability and flexibility and only capable of adjusting a limited number of\nplanning objectives in discrete action spaces. We propose an automatic\ntreatment planning model using the proximal policy optimization (PPO) algorithm\nand a dose distribution-based reward function for proton PBS treatment planning\nof H&N cancers. Specifically, a set of empirical rules is used to create\nauxiliary planning structures from target volumes and organs-at-risk (OARs),\nalong with their associated planning objectives. These planning objectives are\nfed into an in-house optimization engine to generate the spot monitor unit (MU)\nvalues. A decision-making policy network trained using PPO is developed to\niteratively adjust the involved planning objective parameters in a continuous\naction space and refine the PBS treatment plans using a novel dose\ndistribution-based reward function. Proton H&N treatment plans generated by the\nmodel show improved OAR sparing with equal or superior target coverage when\ncompared with human-generated plans. Moreover, additional experiments on liver\ncancer demonstrate that the proposed method can be successfully generalized to\nother treatment sites. To the best of our knowledge, this is the first\nDRL-based automatic treatment planning model capable of achieving human-level\nperformance for H&N cancers.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11576v1",
    "published_date": "2024-09-17 22:01:56 UTC",
    "updated_date": "2024-09-17 22:01:56 UTC"
  },
  {
    "arxiv_id": "2409.11564v2",
    "title": "Preference Tuning with Human Feedback on Language, Speech, and Vision Tasks: A Survey",
    "authors": [
      "Genta Indra Winata",
      "Hanyang Zhao",
      "Anirban Das",
      "Wenpin Tang",
      "David D. Yao",
      "Shi-Xiong Zhang",
      "Sambit Sahu"
    ],
    "abstract": "Preference tuning is a crucial process for aligning deep generative models\nwith human preferences. This survey offers a thorough overview of recent\nadvancements in preference tuning and the integration of human feedback. The\npaper is organized into three main sections: 1) introduction and preliminaries:\nan introduction to reinforcement learning frameworks, preference tuning tasks,\nmodels, and datasets across various modalities: language, speech, and vision,\nas well as different policy approaches, 2) in-depth exploration of each\npreference tuning approach: a detailed analysis of the methods used in\npreference tuning, and 3) applications, discussion, and future directions: an\nexploration of the applications of preference tuning in downstream tasks,\nincluding evaluation methods for different modalities, and an outlook on future\nresearch directions. Our objective is to present the latest methodologies in\npreference tuning and model alignment, enhancing the understanding of this\nfield for researchers and practitioners. We hope to encourage further\nengagement and innovation in this area.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Survey paper",
    "pdf_url": "http://arxiv.org/pdf/2409.11564v2",
    "published_date": "2024-09-17 21:28:51 UTC",
    "updated_date": "2024-11-03 01:51:57 UTC"
  },
  {
    "arxiv_id": "2410.02783v1",
    "title": "Enhancing Mental Health Support through Human-AI Collaboration: Toward Secure and Empathetic AI-enabled chatbots",
    "authors": [
      "Rawan AlMakinah",
      "Andrea Norcini-Pala",
      "Lindsey Disney",
      "M. Abdullah Canbaz"
    ],
    "abstract": "Access to mental health support remains limited, particularly in marginalized\ncommunities where structural and cultural barriers hinder timely care. This\npaper explores the potential of AI-enabled chatbots as a scalable solution,\nfocusing on advanced large language models (LLMs)-GPT v4, Mistral Large, and\nLLama V3.1-and assessing their ability to deliver empathetic, meaningful\nresponses in mental health contexts. While these models show promise in\ngenerating structured responses, they fall short in replicating the emotional\ndepth and adaptability of human therapists. Additionally, trustworthiness,\nbias, and privacy challenges persist due to unreliable datasets and limited\ncollaboration with mental health professionals. To address these limitations,\nwe propose a federated learning framework that ensures data privacy, reduces\nbias, and integrates continuous validation from clinicians to enhance response\nquality. This approach aims to develop a secure, evidence-based AI chatbot\ncapable of offering trustworthy, empathetic, and bias-reduced mental health\nsupport, advancing AI's role in digital mental health care.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "68T01, 62P15",
      "I.2.0; K.4.0; H.5.0"
    ],
    "primary_category": "cs.CY",
    "comment": "17 pages, 9 Figures",
    "pdf_url": "http://arxiv.org/pdf/2410.02783v1",
    "published_date": "2024-09-17 20:49:13 UTC",
    "updated_date": "2024-09-17 20:49:13 UTC"
  },
  {
    "arxiv_id": "2409.11552v1",
    "title": "Multi-Domain Data Aggregation for Axon and Myelin Segmentation in Histology Images",
    "authors": [
      "Armand Collin",
      "Arthur Boschet",
      "Mathieu Boudreau",
      "Julien Cohen-Adad"
    ],
    "abstract": "Quantifying axon and myelin properties (e.g., axon diameter, myelin\nthickness, g-ratio) in histology images can provide useful information about\nmicrostructural changes caused by neurodegenerative diseases. Automatic tissue\nsegmentation is an important tool for these datasets, as a single stained\nsection can contain up to thousands of axons. Advances in deep learning have\nmade this task quick and reliable with minimal overhead, but a deep learning\nmodel trained by one research group will hardly ever be usable by other groups\ndue to differences in their histology training data. This is partly due to\nsubject diversity (different body parts, species, genetics, pathologies) and\nalso to the range of modern microscopy imaging techniques resulting in a wide\nvariability of image features (i.e., contrast, resolution). There is a pressing\nneed to make AI accessible to neuroscience researchers to facilitate and\naccelerate their workflow, but publicly available models are scarce and poorly\nmaintained. Our approach is to aggregate data from multiple imaging modalities\n(bright field, electron microscopy, Raman spectroscopy) and species (mouse,\nrat, rabbit, human), to create an open-source, durable tool for axon and myelin\nsegmentation. Our generalist model makes it easier for researchers to process\ntheir data and can be fine-tuned for better performance on specific domains. We\nstudy the benefits of different aggregation schemes. This multi-domain\nsegmentation model performs better than single-modality dedicated learners\n(p=0.03077), generalizes better on out-of-distribution data and is easier to\nuse and maintain. Importantly, we package the segmentation tool into a\nwell-maintained open-source software ecosystem (see\nhttps://github.com/axondeepseg/axondeepseg).",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.11552v1",
    "published_date": "2024-09-17 20:47:32 UTC",
    "updated_date": "2024-09-17 20:47:32 UTC"
  },
  {
    "arxiv_id": "2409.11547v2",
    "title": "Small Language Models can Outperform Humans in Short Creative Writing: A Study Comparing SLMs with Humans and LLMs",
    "authors": [
      "Guillermo Marco",
      "Luz Rello",
      "Julio Gonzalo"
    ],
    "abstract": "In this paper, we evaluate the creative fiction writing abilities of a\nfine-tuned small language model (SLM), BART-large, and compare its performance\nto human writers and two large language models (LLMs): GPT-3.5 and GPT-4o. Our\nevaluation consists of two experiments: (i) a human study in which 68\nparticipants rated short stories from humans and the SLM on grammaticality,\nrelevance, creativity, and attractiveness, and (ii) a qualitative linguistic\nanalysis examining the textual characteristics of stories produced by each\nmodel. In the first experiment, BART-large outscored average human writers\noverall (2.11 vs. 1.85), a 14% relative improvement, though the slight human\nadvantage in creativity was not statistically significant. In the second\nexperiment, qualitative analysis showed that while GPT-4o demonstrated\nnear-perfect coherence and used less cliche phrases, it tended to produce more\npredictable language, with only 3% of its synopses featuring surprising\nassociations (compared to 15% for BART). These findings highlight how model\nsize and fine-tuning influence the balance between creativity, fluency, and\ncoherence in creative writing tasks, and demonstrate that smaller models can,\nin certain contexts, rival both humans and larger models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as Main Conference Paper at COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.11547v2",
    "published_date": "2024-09-17 20:40:02 UTC",
    "updated_date": "2025-01-13 15:37:03 UTC"
  },
  {
    "arxiv_id": "2409.11546v1",
    "title": "NCT-CRC-HE: Not All Histopathological Datasets Are Equally Useful",
    "authors": [
      "Andrey Ignatov",
      "Grigory Malivenko"
    ],
    "abstract": "Numerous deep learning-based solutions have been proposed for\nhistopathological image analysis over the past years. While they usually\ndemonstrate exceptionally high accuracy, one key question is whether their\nprecision might be affected by low-level image properties not related to\nhistopathology but caused by microscopy image handling and pre-processing. In\nthis paper, we analyze a popular NCT-CRC-HE-100K colorectal cancer dataset used\nin numerous prior works and show that both this dataset and the obtained\nresults may be affected by data-specific biases. The most prominent revealed\ndataset issues are inappropriate color normalization, severe JPEG artifacts\ninconsistent between different classes, and completely corrupted tissue samples\nresulting from incorrect image dynamic range handling. We show that even the\nsimplest model using only 3 features per image (red, green and blue color\nintensities) can demonstrate over 50% accuracy on this 9-class dataset, while\nusing color histogram not explicitly capturing cell morphology features yields\nover 82% accuracy. Moreover, we show that a basic EfficientNet-B0 ImageNet\npretrained model can achieve over 97.7% accuracy on this dataset, outperforming\nall previously proposed solutions developed for this task, including dedicated\nfoundation histopathological models and large cell morphology-aware neural\nnetworks. The NCT-CRC-HE dataset is publicly available and can be freely used\nto replicate the presented results. The codes and pre-trained models used in\nthis paper are available at\nhttps://github.com/gmalivenko/NCT-CRC-HE-experiments",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11546v1",
    "published_date": "2024-09-17 20:36:03 UTC",
    "updated_date": "2024-09-17 20:36:03 UTC"
  },
  {
    "arxiv_id": "2409.11527v2",
    "title": "Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent",
    "authors": [
      "Fatemeh Haji",
      "Mazal Bethany",
      "Maryam Tabar",
      "Jason Chiang",
      "Anthony Rios",
      "Peyman Najafirad"
    ],
    "abstract": "Multi-agent strategies have emerged as a promising approach to enhance the\nreasoning abilities of Large Language Models (LLMs) by assigning specialized\nroles in the problem-solving process. Concurrently, Tree of Thoughts (ToT)\nmethods have shown potential in improving reasoning for complex\nquestion-answering tasks by exploring diverse reasoning paths. A critical\nlimitation in multi-agent reasoning is the 'Reasoner' agent's shallow\nexploration of reasoning paths. While ToT strategies could help mitigate this\nproblem, they may generate flawed reasoning branches, which could harm the\ntrustworthiness of the final answer. To leverage the strengths of both\nmulti-agent reasoning and ToT strategies, we introduce a novel approach\ncombining ToT-based Reasoner agents with a Thought Validator agent. Multiple\nReasoner agents operate in parallel, employing ToT to explore diverse reasoning\npaths. The Thought Validator then scrutinizes these paths, considering a\nReasoner's conclusion only if its reasoning is valid. This method enables a\nmore robust voting strategy by discarding faulty reasoning paths, enhancing the\nsystem's ability to tackle tasks requiring systematic and trustworthy\nreasoning. Our method demonstrates superior performance compared to existing\ntechniques when evaluated on the GSM8K dataset, outperforming the standard ToT\nstrategy by an average 5.6% across four LLMs. The code and related content can\nbe found in: https://github.com/SecureAIAutonomyLab/MA-ToT",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11527v2",
    "published_date": "2024-09-17 19:54:37 UTC",
    "updated_date": "2024-11-05 01:34:26 UTC"
  },
  {
    "arxiv_id": "2409.11513v2",
    "title": "Mamba Fusion: Learning Actions Through Questioning",
    "authors": [
      "Zhikang Dong",
      "Apoorva Beedu",
      "Jason Sheinkopf",
      "Irfan Essa"
    ],
    "abstract": "Video Language Models (VLMs) are crucial for generalizing across diverse\ntasks and using language cues to enhance learning. While transformer-based\narchitectures have been the de facto in vision-language training, they face\nchallenges like quadratic computational complexity, high GPU memory usage, and\ndifficulty with long-term dependencies. To address these limitations, we\nintroduce MambaVL, a novel model that leverages recent advancements in\nselective state space modality fusion to efficiently capture long-range\ndependencies and learn joint representations for vision and language data.\nMambaVL utilizes a shared state transition matrix across both modalities,\nallowing the model to capture information about actions from multiple\nperspectives within the scene. Furthermore, we propose a question-answering\ntask that helps guide the model toward relevant cues. These questions provide\ncritical information about actions, objects, and environmental context, leading\nto enhanced performance. As a result, MambaVL achieves state-of-the-art\nperformance in action recognition on the Epic-Kitchens-100 dataset and\noutperforms baseline methods in action anticipation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11513v2",
    "published_date": "2024-09-17 19:36:37 UTC",
    "updated_date": "2025-01-30 22:50:16 UTC"
  },
  {
    "arxiv_id": "2409.11509v2",
    "title": "FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction",
    "authors": [
      "Ziwei Li",
      "Xiaoqi Wang",
      "Hong-You Chen",
      "Han-Wei Shen",
      "Wei-Lun Chao"
    ],
    "abstract": "Federated learning (FL) has rapidly evolved as a promising paradigm that\nenables collaborative model training across distributed participants without\nexchanging their local data. Despite its broad applications in fields such as\ncomputer vision, graph learning, and natural language processing, the\ndevelopment of a data projection model that can be effectively used to\nvisualize data in the context of FL is crucial yet remains heavily\nunder-explored. Neighbor embedding (NE) is an essential technique for\nvisualizing complex high-dimensional data, but collaboratively learning a joint\nNE model is difficult. The key challenge lies in the objective function, as\neffective visualization algorithms like NE require computing loss functions\namong pairs of data. In this paper, we introduce \\textsc{FedNE}, a novel\napproach that integrates the \\textsc{FedAvg} framework with the contrastive NE\ntechnique, without any requirements of shareable data. To address the lack of\ninter-client repulsion which is crucial for the alignment in the global\nembedding space, we develop a surrogate loss function that each client learns\nand shares with each other. Additionally, we propose a data-mixing strategy to\naugment the local data, aiming to relax the problems of invisible neighbors and\nfalse neighbors constructed by the local $k$NN graphs. We conduct comprehensive\nexperiments on both synthetic and real-world datasets. The results demonstrate\nthat our \\textsc{FedNE} can effectively preserve the neighborhood data\nstructures and enhance the alignment in the global embedding space compared to\nseveral baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11509v2",
    "published_date": "2024-09-17 19:23:24 UTC",
    "updated_date": "2024-10-14 00:55:57 UTC"
  },
  {
    "arxiv_id": "2410.02780v2",
    "title": "Guess What I Think: Streamlined EEG-to-Image Generation with Latent Diffusion Models",
    "authors": [
      "Eleonora Lopez",
      "Luigi Sigillo",
      "Federica Colonnese",
      "Massimo Panella",
      "Danilo Comminiello"
    ],
    "abstract": "Generating images from brain waves is gaining increasing attention due to its\npotential to advance brain-computer interface (BCI) systems by understanding\nhow brain signals encode visual cues. Most of the literature has focused on\nfMRI-to-Image tasks as fMRI is characterized by high spatial resolution.\nHowever, fMRI is an expensive neuroimaging modality and does not allow for\nreal-time BCI. On the other hand, electroencephalography (EEG) is a low-cost,\nnon-invasive, and portable neuroimaging technique, making it an attractive\noption for future real-time applications. Nevertheless, EEG presents inherent\nchallenges due to its low spatial resolution and susceptibility to noise and\nartifacts, which makes generating images from EEG more difficult. In this\npaper, we address these problems with a streamlined framework based on the\nControlNet adapter for conditioning a latent diffusion model (LDM) through EEG\nsignals. We conduct experiments and ablation studies on popular benchmarks to\ndemonstrate that the proposed method beats other state-of-the-art models.\nUnlike these methods, which often require extensive preprocessing, pretraining,\ndifferent losses, and captioning models, our approach is efficient and\nstraightforward, requiring only minimal preprocessing and a few components. The\ncode is available at https://github.com/LuigiSigillo/GWIT.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.02780v2",
    "published_date": "2024-09-17 19:07:13 UTC",
    "updated_date": "2025-01-10 18:14:56 UTC"
  },
  {
    "arxiv_id": "2409.11501v1",
    "title": "Egalitarian Language Representation in Language Models: It All Begins with Tokenizers",
    "authors": [
      "Menan Velayuthan",
      "Kengatharaiyer Sarveswaran"
    ],
    "abstract": "Tokenizers act as a bridge between human language and the latent space of\nlanguage models, influencing how language is represented in these models. Due\nto the immense popularity of English-Centric Large Language Models (LLMs),\nefforts are being made to adapt them for other languages. However, we\ndemonstrate that, from a tokenization standpoint, not all tokenizers offer fair\nrepresentation for complex script languages such as Tamil, Sinhala, and Hindi,\nprimarily due to the choice of pre-tokenization methods. We go further to show\nthat pre-tokenization plays a more critical role than the tokenization\nalgorithm itself in achieving an egalitarian representation of these complex\nscript languages. To address this, we introduce an improvement to the Byte Pair\nEncoding (BPE) algorithm by incorporating graphemes, which we term Grapheme\nPair Encoding (GPE). Our experiments show that grapheme-based character\nextraction outperforms byte-level tokenizers for complex scripts. We validate\nthis approach through experiments on Tamil, Sinhala, and Hindi.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Content - 8 pages, References - 3 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.11501v1",
    "published_date": "2024-09-17 19:05:37 UTC",
    "updated_date": "2024-09-17 19:05:37 UTC"
  },
  {
    "arxiv_id": "2409.11500v1",
    "title": "Multi-Document Grounded Multi-Turn Synthetic Dialog Generation",
    "authors": [
      "Young-Suk Lee",
      "Chulaka Gunasekara",
      "Danish Contractor",
      "Ramón Fernandez Astudillo",
      "Radu Florian"
    ],
    "abstract": "We introduce a technique for multi-document grounded multi-turn synthetic\ndialog generation that incorporates three main ideas. First, we control the\noverall dialog flow using taxonomy-driven user queries that are generated with\nChain-of-Thought (CoT) prompting. Second, we support the generation of\nmulti-document grounded dialogs by mimicking real-world use of retrievers to\nupdate the grounding documents after every user-turn in the dialog. Third, we\napply LLM-as-a-Judge to filter out queries with incorrect answers. Human\nevaluation of the synthetic dialog data suggests that the data is diverse,\ncoherent, and includes mostly correct answers. Both human and automatic\nevaluations of answerable queries indicate that models fine-tuned on synthetic\ndialogs consistently out-perform those fine-tuned on existing human generated\ntraining data across four publicly available multi-turn document grounded\nbenchmark test sets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11500v1",
    "published_date": "2024-09-17 19:02:39 UTC",
    "updated_date": "2024-09-17 19:02:39 UTC"
  },
  {
    "arxiv_id": "2409.11498v1",
    "title": "Augment, Drop & Swap: Improving Diversity in LLM Captions for Efficient Music-Text Representation Learning",
    "authors": [
      "Ilaria Manco",
      "Justin Salamon",
      "Oriol Nieto"
    ],
    "abstract": "Audio-text contrastive models have become a powerful approach in music\nrepresentation learning. Despite their empirical success, however, little is\nknown about the influence of key design choices on the quality of music-text\nrepresentations learnt through this framework. In this work, we expose these\ndesign choices within the constraints of limited data and computation budgets,\nand establish a more solid understanding of their impact grounded in empirical\nobservations along three axes: the choice of base encoders, the level of\ncuration in training data, and the use of text augmentation. We find that data\ncuration is the single most important factor for music-text contrastive\ntraining in resource-constrained scenarios. Motivated by this insight, we\nintroduce two novel techniques, Augmented View Dropout and TextSwap, which\nincrease the diversity and descriptiveness of text inputs seen in training.\nThrough our experiments we demonstrate that these are effective at boosting\nperformance across different pre-training regimes, model architectures, and\ndownstream data distributions, without incurring higher computational costs or\nrequiring additional training data.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "To appear in the Proceedings of the 25th International Society for\n  Music Information Retrieval Conference (ISMIR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.11498v1",
    "published_date": "2024-09-17 19:00:21 UTC",
    "updated_date": "2024-09-17 19:00:21 UTC"
  },
  {
    "arxiv_id": "2410.03551v1",
    "title": "Constructive Apraxia: An Unexpected Limit of Instructible Vision-Language Models and Analog for Human Cognitive Disorders",
    "authors": [
      "David Noever",
      "Samantha E. Miller Noever"
    ],
    "abstract": "This study reveals an unexpected parallel between instructible\nvision-language models (VLMs) and human cognitive disorders, specifically\nconstructive apraxia. We tested 25 state-of-the-art VLMs, including GPT-4\nVision, DALL-E 3, and Midjourney v5, on their ability to generate images of the\nPonzo illusion, a task that requires basic spatial reasoning and is often used\nin clinical assessments of constructive apraxia. Remarkably, 24 out of 25\nmodels failed to correctly render two horizontal lines against a perspective\nbackground, mirroring the deficits seen in patients with parietal lobe damage.\nThe models consistently misinterpreted spatial instructions, producing tilted\nor misaligned lines that followed the perspective of the background rather than\nremaining horizontal. This behavior is strikingly similar to how apraxia\npatients struggle to copy or construct simple figures despite intact visual\nperception and motor skills. Our findings suggest that current VLMs, despite\ntheir advanced capabilities in other domains, lack fundamental spatial\nreasoning abilities akin to those impaired in constructive apraxia. This\nlimitation in AI systems provides a novel computational model for studying\nspatial cognition deficits and highlights a critical area for improvement in\nVLM architecture and training methodologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03551v1",
    "published_date": "2024-09-17 18:46:57 UTC",
    "updated_date": "2024-09-17 18:46:57 UTC"
  },
  {
    "arxiv_id": "2409.11489v1",
    "title": "Beyond Algorithmic Fairness: A Guide to Develop and Deploy Ethical AI-Enabled Decision-Support Tools",
    "authors": [
      "Rosemarie Santa Gonzalez",
      "Ryan Piansky",
      "Sue M Bae",
      "Justin Biddle",
      "Daniel Molzahn"
    ],
    "abstract": "The integration of artificial intelligence (AI) and optimization hold\nsubstantial promise for improving the efficiency, reliability, and resilience\nof engineered systems. Due to the networked nature of many engineered systems,\nethically deploying methodologies at this intersection poses challenges that\nare distinct from other AI settings, thus motivating the development of ethical\nguidelines tailored to AI-enabled optimization. This paper highlights the need\nto go beyond fairness-driven algorithms to systematically address ethical\ndecisions spanning the stages of modeling, data curation, results analysis, and\nimplementation of optimization-based decision support tools. Accordingly, this\npaper identifies ethical considerations required when deploying algorithms at\nthe intersection of AI and optimization via case studies in power systems as\nwell as supply chain and logistics. Rather than providing a prescriptive set of\nrules, this paper aims to foster reflection and awareness among researchers and\nencourage consideration of ethical implications at every step of the\ndecision-making process.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11489v1",
    "published_date": "2024-09-17 18:37:53 UTC",
    "updated_date": "2024-09-17 18:37:53 UTC"
  },
  {
    "arxiv_id": "2410.02779v1",
    "title": "Learning variant product relationship and variation attributes from e-commerce website structures",
    "authors": [
      "Pedro Herrero-Vidal",
      "You-Lin Chen",
      "Cris Liu",
      "Prithviraj Sen",
      "Lichao Wang"
    ],
    "abstract": "We introduce VARM, variant relationship matcher strategy, to identify pairs\nof variant products in e-commerce catalogs. Traditional definitions of entity\nresolution are concerned with whether product mentions refer to the same\nunderlying product. However, this fails to capture product relationships that\nare critical for e-commerce applications, such as having similar, but not\nidentical, products listed on the same webpage or share reviews. Here, we\nformulate a new type of entity resolution in variant product relationships to\ncapture these similar e-commerce product links. In contrast with the\ntraditional definition, the new definition requires both identifying if two\nproducts are variant matches of each other and what are the attributes that\nvary between them. To satisfy these two requirements, we developed a strategy\nthat leverages the strengths of both encoding and generative AI models. First,\nwe construct a dataset that captures webpage product links, and therefore\nvariant product relationships, to train an encoding LLM to predict variant\nmatches for any given pair of products. Second, we use RAG prompted generative\nLLMs to extract variation and common attributes amongst groups of variant\nproducts. To validate our strategy, we evaluated model performance using real\ndata from one of the world's leading e-commerce retailers. The results showed\nthat our strategy outperforms alternative solutions and paves the way to\nexploiting these new type of product relationships.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02779v1",
    "published_date": "2024-09-17 18:24:27 UTC",
    "updated_date": "2024-09-17 18:24:27 UTC"
  },
  {
    "arxiv_id": "2409.11404v3",
    "title": "AraDiCE: Benchmarks for Dialectal and Cultural Capabilities in LLMs",
    "authors": [
      "Basel Mousi",
      "Nadir Durrani",
      "Fatema Ahmad",
      "Md. Arid Hasan",
      "Maram Hasanain",
      "Tameem Kabbani",
      "Fahim Dalvi",
      "Shammur Absar Chowdhury",
      "Firoj Alam"
    ],
    "abstract": "Arabic, with its rich diversity of dialects, remains significantly\nunderrepresented in Large Language Models, particularly in dialectal\nvariations. We address this gap by introducing seven synthetic datasets in\ndialects alongside Modern Standard Arabic (MSA), created using Machine\nTranslation (MT) combined with human post-editing. We present AraDiCE, a\nbenchmark for Arabic Dialect and Cultural Evaluation. We evaluate LLMs on\ndialect comprehension and generation, focusing specifically on low-resource\nArabic dialects. Additionally, we introduce the first-ever fine-grained\nbenchmark designed to evaluate cultural awareness across the Gulf, Egypt, and\nLevant regions, providing a novel dimension to LLM evaluation. Our findings\ndemonstrate that while Arabic-specific models like Jais and AceGPT outperform\nmultilingual models on dialectal tasks, significant challenges persist in\ndialect identification, generation, and translation. This work contributes\n$\\approx$45K post-edited samples, a cultural benchmark, and highlights the\nimportance of tailored training to improve LLM performance in capturing the\nnuances of diverse Arabic dialects and cultural contexts. We have released the\ndialectal translation models and benchmarks developed in this study\n(https://huggingface.co/datasets/QCRI/AraDiCE).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Benchmarking, Culturally Informed, Large Language Models, Arabic NLP,\n  LLMs, Arabic Dialect, Dialectal Benchmarking",
    "pdf_url": "http://arxiv.org/pdf/2409.11404v3",
    "published_date": "2024-09-17 17:59:25 UTC",
    "updated_date": "2024-12-17 21:15:26 UTC"
  },
  {
    "arxiv_id": "2409.11402v2",
    "title": "NVLM: Open Frontier-Class Multimodal LLMs",
    "authors": [
      "Wenliang Dai",
      "Nayeon Lee",
      "Boxin Wang",
      "Zhuolin Yang",
      "Zihan Liu",
      "Jon Barker",
      "Tuomas Rintamaki",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Wei Ping"
    ],
    "abstract": "We introduce NVLM 1.0, a family of frontier-class multimodal large language\nmodels (LLMs) that achieve state-of-the-art results on vision-language tasks,\nrivaling the leading proprietary models (e.g., GPT-4o) and open-access models\n(e.g., Llama 3-V 405B and InternVL 2). Remarkably, NVLM 1.0 shows improved\ntext-only performance over its LLM backbone after multimodal training. In terms\nof model design, we perform a comprehensive comparison between decoder-only\nmultimodal LLMs (e.g., LLaVA) and cross-attention-based models (e.g.,\nFlamingo). Based on the strengths and weaknesses of both approaches, we propose\na novel architecture that enhances both training efficiency and multimodal\nreasoning capabilities. Furthermore, we introduce a 1-D tile-tagging design for\ntile-based dynamic high-resolution images, which significantly boosts\nperformance on multimodal reasoning and OCR-related tasks. Regarding training\ndata, we meticulously curate and provide detailed information on our multimodal\npretraining and supervised fine-tuning datasets. Our findings indicate that\ndataset quality and task diversity are more important than scale, even during\nthe pretraining phase, across all architectures. Notably, we develop\nproduction-grade multimodality for the NVLM-1.0 models, enabling them to excel\nin vision-language tasks while maintaining and even improving text-only\nperformance compared to their LLM backbones. To achieve this, we craft and\nintegrate a high-quality text-only dataset into multimodal training, alongside\na substantial amount of multimodal math and reasoning data, leading to enhanced\nmath and coding capabilities across modalities. To advance research in the\nfield, we release the model weights at https://huggingface.co/nvidia/NVLM-D-72B\nand will open-source the training code for the community soon.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "Fixed the typos. For more information, please visit our project page\n  at: https://research.nvidia.com/labs/adlr/NVLM-1",
    "pdf_url": "http://arxiv.org/pdf/2409.11402v2",
    "published_date": "2024-09-17 17:59:06 UTC",
    "updated_date": "2024-10-22 23:13:34 UTC"
  },
  {
    "arxiv_id": "2410.00037v2",
    "title": "Moshi: a speech-text foundation model for real-time dialogue",
    "authors": [
      "Alexandre Défossez",
      "Laurent Mazaré",
      "Manu Orsini",
      "Amélie Royer",
      "Patrick Pérez",
      "Hervé Jégou",
      "Edouard Grave",
      "Neil Zeghidour"
    ],
    "abstract": "We introduce Moshi, a speech-text foundation model and full-duplex spoken\ndialogue framework. Current systems for spoken dialogue rely on pipelines of\nindependent components, namely voice activity detection, speech recognition,\ntextual dialogue and text-to-speech. Such frameworks cannot emulate the\nexperience of real conversations. First, their complexity induces a latency of\nseveral seconds between interactions. Second, text being the intermediate\nmodality for dialogue, non-linguistic information that modifies meaning -- such\nas emotion or non-speech sounds -- is lost in the interaction. Finally, they\nrely on a segmentation into speaker turns, which does not take into account\noverlapping speech, interruptions and interjections. Moshi solves these\nindependent issues altogether by casting spoken dialogue as speech-to-speech\ngeneration. Starting from a text language model backbone, Moshi generates\nspeech as tokens from the residual quantizer of a neural audio codec, while\nmodeling separately its own speech and that of the user into parallel streams.\nThis allows for the removal of explicit speaker turns, and the modeling of\narbitrary conversational dynamics. We moreover extend the hierarchical\nsemantic-to-acoustic token generation of previous work to first predict\ntime-aligned text tokens as a prefix to audio tokens. Not only this \"Inner\nMonologue\" method significantly improves the linguistic quality of generated\nspeech, but we also illustrate how it can provide streaming speech recognition\nand text-to-speech. Our resulting model is the first real-time full-duplex\nspoken large language model, with a theoretical latency of 160ms, 200ms in\npractice, and is available at https://github.com/kyutai-labs/moshi.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00037v2",
    "published_date": "2024-09-17 17:55:39 UTC",
    "updated_date": "2024-10-02 09:11:45 UTC"
  },
  {
    "arxiv_id": "2409.11393v2",
    "title": "LLM-Agent-UMF: LLM-based Agent Unified Modeling Framework for Seamless Integration of Multi Active/Passive Core-Agents",
    "authors": [
      "Amine Ben Hassouna",
      "Hana Chaari",
      "Ines Belhaj"
    ],
    "abstract": "In an era where vast amounts of data are collected and processed from diverse\nsources, there is a growing demand to develop sophisticated AI systems capable\nof intelligently fusing and analyzing this information. To address these\nchallenges, researchers have turned towards integrating tools into LLM-powered\nagents to enhance the overall information fusion process. However, the\nconjunction of these technologies and the proposed enhancements in several\nstate-of-the-art works followed a non-unified software architecture resulting\nin a lack of modularity and terminological inconsistencies among researchers.\nTo address these issues, we propose a novel LLM-based Agent Unified Modeling\nFramework (LLM-Agent-UMF) that aims to establish a clear foundation for agent\ndevelopment from both functional and software architectural perspectives. Our\nframework distinguishes between the different components of an LLM-based agent,\nsetting LLMs, and tools apart from a new element, the core-agent, playing the\nrole of the central coordinator of the agent. This pivotal entity comprises\nfive modules: planning, memory, profile, action, and security - the latter\noften neglected in previous works. By classifying core-agents into passive and\nactive types based on their authoritative natures, we propose various\nmulti-core agent architectures that combine unique characteristics of\ndistinctive agents to tackle complex tasks more efficiently. We evaluate our\nframework by applying it to thirteen state-of-the-art agents, thereby\ndemonstrating its alignment with their functionalities and clarifying the\noverlooked architectural aspects. Moreover, we thoroughly assess five of our\nproposed architectures through the integration of existing agents into new\nhybrid active/passive core-agents architectures. This analysis provides\ninsights into potential improvements and highlights challenges involved in\ncombining specific agents.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.MA"
    ],
    "primary_category": "cs.SE",
    "comment": "36 pages, 19 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.11393v2",
    "published_date": "2024-09-17 17:54:17 UTC",
    "updated_date": "2024-10-31 11:07:11 UTC"
  },
  {
    "arxiv_id": "2409.11456v3",
    "title": "Two Stage Segmentation of Cervical Tumors using PocketNet",
    "authors": [
      "Awj Twam",
      "Adrian E. Celaya",
      "Megan C. Jacobsen",
      "Rachel Glenn",
      "Peng Wei",
      "Jia Sun",
      "Ann Klopp",
      "Aradhana M. Venkatesan",
      "David Fuentes"
    ],
    "abstract": "Cervical cancer remains the fourth most common malignancy amongst women\nworldwide.1 Concurrent chemoradiotherapy (CRT) serves as the mainstay\ndefinitive treatment regimen for locally advanced cervical cancers and includes\nexternal beam radiation followed by brachytherapy.2 Integral to radiotherapy\ntreatment planning is the routine contouring of both the target tumor at the\nlevel of the cervix, associated gynecologic anatomy and the adjacent organs at\nrisk (OARs). However, manual contouring of these structures is both time and\nlabor intensive and associated with known interobserver variability that can\nimpact treatment outcomes. While multiple tools have been developed to\nautomatically segment OARs and the high-risk clinical tumor volume (HR-CTV)\nusing computed tomography (CT) images,3,4,5,6 the development of deep\nlearning-based tumor segmentation tools using routine T2-weighted (T2w)\nmagnetic resonance imaging (MRI) addresses an unmet clinical need to improve\nthe routine contouring of both anatomical structures and cervical cancers,\nthereby increasing quality and consistency of radiotherapy planning. This work\napplied a novel deep-learning model (PocketNet) to segment the cervix, vagina,\nuterus, and tumor(s) on T2w MRI. The performance of the PocketNet architecture\nwas evaluated, when trained on data via five-fold cross validation. PocketNet\nachieved a mean Dice-Sorensen similarity coefficient (DSC) exceeding 70% for\ntumor segmentation and 80% for organ segmentation. Validation on a publicly\navailable dataset from The Cancer Imaging Archive (TCIA) demonstrated the\nmodels robustness, achieving DSC scores of 67.3% for tumor segmentation and\n80.8% for organ segmentation. These results suggest that PocketNet is robust to\nvariations in contrast protocols, providing reliable segmentation of the\nregions of interest.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11456v3",
    "published_date": "2024-09-17 17:48:12 UTC",
    "updated_date": "2025-02-12 20:10:41 UTC"
  },
  {
    "arxiv_id": "2409.11378v1",
    "title": "Diversify and Conquer: Diversity-Centric Data Selection with Iterative Refinement",
    "authors": [
      "Simon Yu",
      "Liangyu Chen",
      "Sara Ahmadian",
      "Marzieh Fadaee"
    ],
    "abstract": "Finetuning large language models on instruction data is crucial for enhancing\npre-trained knowledge and improving instruction-following capabilities. As\ninstruction datasets proliferate, selecting optimal data for effective training\nbecomes increasingly important. This work addresses the question: How can we\ndetermine the optimal subset of data for effective training? While existing\nresearch often emphasizes local criteria like instance quality for subset\nselection, we argue that a global approach focused on data diversity is more\ncritical. Our method employs k-means clustering to ensure the selected subset\neffectively represents the full dataset. We propose an iterative refinement\nmethod inspired by active learning techniques to resample instances from\nclusters, reassessing each cluster's importance and sampling weight in every\ntraining iteration. This approach reduces the effect of outliers and\nautomatically filters out clusters containing low-quality data. Through\nextensive evaluation across natural language reasoning, general world\nknowledge, code and math reasoning tasks, and by fine-tuning models from\nvarious families, we observe consistent improvements, achieving a 7% increase\nover random selection and a 3.8% improvement over state-of-the-art sampling\nmethods. Our work highlights the significance of diversity-first sampling when\nfinetuning LLMs to enhance performance across a broad array of evaluation\ntasks. Our code is available at\nhttps://github.com/for-ai/iterative-data-selection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.11378v1",
    "published_date": "2024-09-17 17:25:31 UTC",
    "updated_date": "2024-09-17 17:25:31 UTC"
  },
  {
    "arxiv_id": "2409.11375v1",
    "title": "Multi-OCT-SelfNet: Integrating Self-Supervised Learning with Multi-Source Data Fusion for Enhanced Multi-Class Retinal Disease Classification",
    "authors": [
      "Fatema-E- Jannat",
      "Sina Gholami",
      "Jennifer I. Lim",
      "Theodore Leng",
      "Minhaj Nur Alam",
      "Hamed Tabkhi"
    ],
    "abstract": "In the medical domain, acquiring large datasets poses significant challenges\ndue to privacy concerns. Nonetheless, the development of a robust deep-learning\nmodel for retinal disease diagnosis necessitates a substantial dataset for\ntraining. The capacity to generalize effectively on smaller datasets remains a\npersistent challenge. The scarcity of data presents a significant barrier to\nthe practical implementation of scalable medical AI solutions. To address this\nissue, we've combined a wide range of data sources to improve performance and\ngeneralization to new data by giving it a deeper understanding of the data\nrepresentation from multi-modal datasets and developed a self-supervised\nframework based on large language models (LLMs), SwinV2 to gain a deeper\nunderstanding of multi-modal dataset representations, enhancing the model's\nability to extrapolate to new data for the detection of eye diseases using\noptical coherence tomography (OCT) images. We adopt a two-phase training\nmethodology, self-supervised pre-training, and fine-tuning on a downstream\nsupervised classifier. An ablation study conducted across three datasets\nemploying various encoder backbones, without data fusion, with low data\navailability setting, and without self-supervised pre-training scenarios,\nhighlights the robustness of our method. Our findings demonstrate consistent\nperformance across these diverse conditions, showcasing superior generalization\ncapabilities compared to the baseline model, ResNet-50.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 9 tables, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.11375v1",
    "published_date": "2024-09-17 17:22:35 UTC",
    "updated_date": "2024-09-17 17:22:35 UTC"
  },
  {
    "arxiv_id": "2409.11363v1",
    "title": "CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark",
    "authors": [
      "Zachary S. Siegel",
      "Sayash Kapoor",
      "Nitya Nagdir",
      "Benedikt Stroebl",
      "Arvind Narayanan"
    ],
    "abstract": "AI agents have the potential to aid users on a variety of consequential\ntasks, including conducting scientific research. To spur the development of\nuseful agents, we need benchmarks that are challenging, but more crucially,\ndirectly correspond to real-world tasks of interest. This paper introduces such\na benchmark, designed to measure the accuracy of AI agents in tackling a\ncrucial yet surprisingly challenging aspect of scientific research:\ncomputational reproducibility. This task, fundamental to the scientific\nprocess, involves reproducing the results of a study using the provided code\nand data. We introduce CORE-Bench (Computational Reproducibility Agent\nBenchmark), a benchmark consisting of 270 tasks based on 90 scientific papers\nacross three disciplines (computer science, social science, and medicine).\nTasks in CORE-Bench consist of three difficulty levels and include both\nlanguage-only and vision-language tasks. We provide an evaluation system to\nmeasure the accuracy of agents in a fast and parallelizable way, saving days of\nevaluation time for each run compared to a sequential implementation. We\nevaluated two baseline agents: the general-purpose AutoGPT and a task-specific\nagent called CORE-Agent. We tested both variants using two underlying language\nmodels: GPT-4o and GPT-4o-mini. The best agent achieved an accuracy of 21% on\nthe hardest task, showing the vast scope for improvement in automating routine\nscientific tasks. Having agents that can reproduce existing work is a necessary\nstep towards building agents that can conduct novel research and could verify\nand improve the performance of other research agents. We hope that CORE-Bench\ncan improve the state of reproducibility and spur the development of future\nresearch agents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "Benchmark harness and code available at\n  http://github.com/siegelz/core-bench",
    "pdf_url": "http://arxiv.org/pdf/2409.11363v1",
    "published_date": "2024-09-17 17:13:19 UTC",
    "updated_date": "2024-09-17 17:13:19 UTC"
  },
  {
    "arxiv_id": "2409.11360v3",
    "title": "AI Suggestions Homogenize Writing Toward Western Styles and Diminish Cultural Nuances",
    "authors": [
      "Dhruv Agarwal",
      "Mor Naaman",
      "Aditya Vashistha"
    ],
    "abstract": "Large language models (LLMs) are being increasingly integrated into everyday\nproducts and services, such as coding tools and writing assistants. As these\nembedded AI applications are deployed globally, there is a growing concern that\nthe AI models underlying these applications prioritize Western values. This\npaper investigates what happens when a Western-centric AI model provides\nwriting suggestions to users from a different cultural background. We conducted\na cross-cultural controlled experiment with 118 participants from India and the\nUnited States who completed culturally grounded writing tasks with and without\nAI suggestions. Our analysis reveals that AI provided greater efficiency gains\nfor Americans compared to Indians. Moreover, AI suggestions led Indian\nparticipants to adopt Western writing styles, altering not just what is written\nbut also how it is written. These findings show that Western-centric AI models\nhomogenize writing toward Western norms, diminishing nuances that differentiate\ncultural expression.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.11360v3",
    "published_date": "2024-09-17 17:07:30 UTC",
    "updated_date": "2025-03-12 22:40:12 UTC"
  },
  {
    "arxiv_id": "2409.11356v2",
    "title": "RenderWorld: World Model with Self-Supervised 3D Label",
    "authors": [
      "Ziyang Yan",
      "Wenzhen Dong",
      "Yihua Shao",
      "Yuhang Lu",
      "Liu Haiyang",
      "Jingwen Liu",
      "Haozhe Wang",
      "Zhe Wang",
      "Yan Wang",
      "Fabio Remondino",
      "Yuexin Ma"
    ],
    "abstract": "End-to-end autonomous driving with vision-only is not only more\ncost-effective compared to LiDAR-vision fusion but also more reliable than\ntraditional methods. To achieve a economical and robust purely visual\nautonomous driving system, we propose RenderWorld, a vision-only end-to-end\nautonomous driving framework, which generates 3D occupancy labels using a\nself-supervised gaussian-based Img2Occ Module, then encodes the labels by\nAM-VAE, and uses world model for forecasting and planning. RenderWorld employs\nGaussian Splatting to represent 3D scenes and render 2D images greatly improves\nsegmentation accuracy and reduces GPU memory consumption compared with\nNeRF-based methods. By applying AM-VAE to encode air and non-air separately,\nRenderWorld achieves more fine-grained scene element representation, leading to\nstate-of-the-art performance in both 4D occupancy forecasting and motion\nplanning from autoregressive world model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in 2025 IEEE International Conference on Robotics and\n  Automation (ICRA)",
    "pdf_url": "http://arxiv.org/pdf/2409.11356v2",
    "published_date": "2024-09-17 17:00:52 UTC",
    "updated_date": "2025-02-13 05:20:48 UTC"
  },
  {
    "arxiv_id": "2409.11350v1",
    "title": "Clinical Validation of a Real-Time Machine Learning-based System for the Detection of Acute Myeloid Leukemia by Flow Cytometry",
    "authors": [
      "Lauren M. Zuromski",
      "Jacob Durtschi",
      "Aimal Aziz",
      "Jeffrey Chumley",
      "Mark Dewey",
      "Paul English",
      "Muir Morrison",
      "Keith Simmon",
      "Blaine Whipple",
      "Brendan O'Fallon",
      "David P. Ng"
    ],
    "abstract": "Machine-learning (ML) models in flow cytometry have the potential to reduce\nerror rates, increase reproducibility, and boost the efficiency of clinical\nlabs. While numerous ML models for flow cytometry data have been proposed, few\nstudies have described the clinical deployment of such models. Realizing the\npotential gains of ML models in clinical labs requires not only an accurate\nmodel, but infrastructure for automated inference, error detection, analytics\nand monitoring, and structured data extraction. Here, we describe an ML model\nfor detection of Acute Myeloid Leukemia (AML), along with the infrastructure\nsupporting clinical implementation. Our infrastructure leverages the resilience\nand scalability of the cloud for model inference, a Kubernetes-based workflow\nsystem that provides model reproducibility and resource management, and a\nsystem for extracting structured diagnoses from full-text reports. We also\ndescribe our model monitoring and visualization platform, an essential element\nfor ensuring continued model accuracy. Finally, we present a post-deployment\nanalysis of impacts on turn-around time and compare production accuracy to the\noriginal validation statistics.",
    "categories": [
      "q-bio.TO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.TO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11350v1",
    "published_date": "2024-09-17 16:53:47 UTC",
    "updated_date": "2024-09-17 16:53:47 UTC"
  },
  {
    "arxiv_id": "2409.11340v2",
    "title": "OmniGen: Unified Image Generation",
    "authors": [
      "Shitao Xiao",
      "Yueze Wang",
      "Junjie Zhou",
      "Huaying Yuan",
      "Xingrun Xing",
      "Ruiran Yan",
      "Chaofan Li",
      "Shuting Wang",
      "Tiejun Huang",
      "Zheng Liu"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has unified language generation\ntasks and revolutionized human-machine interaction. However, in the realm of\nimage generation, a unified model capable of handling various tasks within a\nsingle framework remains largely unexplored. In this work, we introduce\nOmniGen, a new diffusion model for unified image generation. OmniGen is\ncharacterized by the following features: 1) Unification: OmniGen not only\ndemonstrates text-to-image generation capabilities but also inherently supports\nvarious downstream tasks, such as image editing, subject-driven generation, and\nvisual-conditional generation. 2) Simplicity: The architecture of OmniGen is\nhighly simplified, eliminating the need for additional plugins. Moreover,\ncompared to existing diffusion models, it is more user-friendly and can\ncomplete complex tasks end-to-end through instructions without the need for\nextra intermediate steps, greatly simplifying the image generation workflow. 3)\nKnowledge Transfer: Benefit from learning in a unified format, OmniGen\neffectively transfers knowledge across different tasks, manages unseen tasks\nand domains, and exhibits novel capabilities. We also explore the model's\nreasoning capabilities and potential applications of the chain-of-thought\nmechanism. This work represents the first attempt at a general-purpose image\ngeneration model, and we will release our resources at\nhttps://github.com/VectorSpaceLab/OmniGen to foster future advancements.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Update the paper for OmniGen-v1",
    "pdf_url": "http://arxiv.org/pdf/2409.11340v2",
    "published_date": "2024-09-17 16:42:46 UTC",
    "updated_date": "2024-11-21 14:09:12 UTC"
  },
  {
    "arxiv_id": "2409.11321v2",
    "title": "SOAP: Improving and Stabilizing Shampoo using Adam",
    "authors": [
      "Nikhil Vyas",
      "Depen Morwani",
      "Rosie Zhao",
      "Mujin Kwun",
      "Itai Shapira",
      "David Brandfonbrener",
      "Lucas Janson",
      "Sham Kakade"
    ],
    "abstract": "There is growing evidence of the effectiveness of Shampoo, a higher-order\npreconditioning method, over Adam in deep learning optimization tasks. However,\nShampoo's drawbacks include additional hyperparameters and computational\noverhead when compared to Adam, which only updates running averages of first-\nand second-moment quantities. This work establishes a formal connection between\nShampoo (implemented with the 1/2 power) and Adafactor -- a memory-efficient\napproximation of Adam -- showing that Shampoo is equivalent to running\nAdafactor in the eigenbasis of Shampoo's preconditioner. This insight leads to\nthe design of a simpler and computationally efficient algorithm:\n$\\textbf{S}$hampo$\\textbf{O}$ with $\\textbf{A}$dam in the\n$\\textbf{P}$reconditioner's eigenbasis (SOAP).\n  With regards to improving Shampoo's computational efficiency, the most\nstraightforward approach would be to simply compute Shampoo's\neigendecomposition less frequently. Unfortunately, as our empirical results\nshow, this leads to performance degradation that worsens with this frequency.\nSOAP mitigates this degradation by continually updating the running average of\nthe second moment, just as Adam does, but in the current (slowly changing)\ncoordinate basis. Furthermore, since SOAP is equivalent to running Adam in a\nrotated space, it introduces only one additional hyperparameter (the\npreconditioning frequency) compared to Adam. We empirically evaluate SOAP on\nlanguage model pre-training with 360m and 660m sized models. In the large batch\nregime, SOAP reduces the number of iterations by over 40% and wall clock time\nby over 35% compared to AdamW, with approximately 20% improvements in both\nmetrics compared to Shampoo. An implementation of SOAP is available at\nhttps://github.com/nikhilvyas/SOAP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11321v2",
    "published_date": "2024-09-17 16:18:05 UTC",
    "updated_date": "2025-01-31 18:52:42 UTC"
  },
  {
    "arxiv_id": "2409.11316v2",
    "title": "MSDNet: Multi-Scale Decoder for Few-Shot Semantic Segmentation via Transformer-Guided Prototyping",
    "authors": [
      "Amirreza Fateh",
      "Mohammad Reza Mohammadi",
      "Mohammad Reza Jahed Motlagh"
    ],
    "abstract": "Few-shot Semantic Segmentation addresses the challenge of segmenting objects\nin query images with only a handful of annotated examples. However, many\nprevious state-of-the-art methods either have to discard intricate local\nsemantic features or suffer from high computational complexity. To address\nthese challenges, we propose a new Few-shot Semantic Segmentation framework\nbased on the transformer architecture. Our approach introduces the spatial\ntransformer decoder and the contextual mask generation module to improve the\nrelational understanding between support and query images. Moreover, we\nintroduce a multi-scale decoder to refine the segmentation mask by\nincorporating features from different resolutions in a hierarchical manner.\nAdditionally, our approach integrates global features from intermediate encoder\nstages to improve contextual understanding, while maintaining a lightweight\nstructure to reduce complexity. This balance between performance and efficiency\nenables our method to achieve state-of-the-art results on benchmark datasets\nsuch as $PASCAL-5^i$ and $COCO-20^i$ in both 1-shot and 5-shot settings.\nNotably, our model with only 1.5 million parameters demonstrates competitive\nperformance while overcoming limitations of existing methodologies.\nhttps://github.com/amirrezafateh/MSDNet",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11316v2",
    "published_date": "2024-09-17 16:14:03 UTC",
    "updated_date": "2024-12-28 15:45:22 UTC"
  },
  {
    "arxiv_id": "2409.11299v3",
    "title": "TTT-Unet: Enhancing U-Net with Test-Time Training Layers for Biomedical Image Segmentation",
    "authors": [
      "Rong Zhou",
      "Zhengqing Yuan",
      "Zhiling Yan",
      "Weixiang Sun",
      "Kai Zhang",
      "Yiwei Li",
      "Yanfang Ye",
      "Xiang Li",
      "Lifang He",
      "Lichao Sun"
    ],
    "abstract": "Biomedical image segmentation is crucial for accurately diagnosing and\nanalyzing various diseases. However, Convolutional Neural Networks (CNNs) and\nTransformers, the most commonly used architectures for this task, struggle to\neffectively capture long-range dependencies due to the inherent locality of\nCNNs and the computational complexity of Transformers. To address this\nlimitation, we introduce TTT-Unet, a novel framework that integrates Test-Time\nTraining (TTT) layers into the traditional U-Net architecture for biomedical\nimage segmentation. TTT-Unet dynamically adjusts model parameters during the\ntesting time, enhancing the model's ability to capture both local and\nlong-range features. We evaluate TTT-Unet on multiple medical imaging datasets,\nincluding 3D abdominal organ segmentation in CT and MR images, instrument\nsegmentation in endoscopy images, and cell segmentation in microscopy images.\nThe results demonstrate that TTT-Unet consistently outperforms state-of-the-art\nCNN-based and Transformer-based segmentation models across all tasks. The code\nis available at https://github.com/rongzhou7/TTT-Unet.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11299v3",
    "published_date": "2024-09-17 15:52:40 UTC",
    "updated_date": "2024-12-06 02:45:11 UTC"
  },
  {
    "arxiv_id": "2409.11295v5",
    "title": "EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage",
    "authors": [
      "Zeyi Liao",
      "Lingbo Mo",
      "Chejian Xu",
      "Mintong Kang",
      "Jiawei Zhang",
      "Chaowei Xiao",
      "Yuan Tian",
      "Bo Li",
      "Huan Sun"
    ],
    "abstract": "Generalist web agents have demonstrated remarkable potential in autonomously\ncompleting a wide range of tasks on real websites, significantly boosting human\nproductivity. However, web tasks, such as booking flights, usually involve\nusers' PII, which may be exposed to potential privacy risks if web agents\naccidentally interact with compromised websites, a scenario that remains\nlargely unexplored in the literature. In this work, we narrow this gap by\nconducting the first study on the privacy risks of generalist web agents in\nadversarial environments. First, we present a realistic threat model for\nattacks on the website, where we consider two adversarial targets: stealing\nusers' specific PII or the entire user request. Then, we propose a novel attack\nmethod, termed Environmental Injection Attack (EIA). EIA injects malicious\ncontent designed to adapt well to environments where the agents operate and our\nwork instantiates EIA specifically for privacy scenarios in web environments.\nWe collect 177 action steps that involve diverse PII categories on realistic\nwebsites from the Mind2Web, and conduct experiments using one of the most\ncapable generalist web agent frameworks to date. The results demonstrate that\nEIA achieves up to 70% ASR in stealing specific PII and 16% ASR for full user\nrequest. Additionally, by accessing the stealthiness and experimenting with a\ndefensive system prompt, we indicate that EIA is hard to detect and mitigate.\nNotably, attacks that are not well adapted for a webpage can be detected via\nhuman inspection, leading to our discussion about the trade-off between\nsecurity and autonomy. However, extra attackers' efforts can make EIA\nseamlessly adapted, rendering such supervision ineffective. Thus, we further\ndiscuss the defenses at the pre- and post-deployment stages of the websites\nwithout relying on human supervision and call for more advanced defense\nstrategies.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.11295v5",
    "published_date": "2024-09-17 15:49:44 UTC",
    "updated_date": "2025-03-12 20:54:00 UTC"
  },
  {
    "arxiv_id": "2409.11294v1",
    "title": "Navigating Process Mining: A Case study using pm4py",
    "authors": [
      "Ali Jlidi",
      "László Kovács"
    ],
    "abstract": "Process-mining techniques have emerged as powerful tools for analyzing event\ndata to gain insights into business processes. In this paper, we present a\ncomprehensive analysis of road traffic fine management processes using the\npm4py library in Python. We start by importing an event log dataset and explore\nits characteristics, including the distribution of activities and process\nvariants. Through filtering and statistical analysis, we uncover key patterns\nand variations in the process executions. Subsequently, we apply various\nprocess-mining algorithms, including the Alpha Miner, Inductive Miner, and\nHeuristic Miner, to discover process models from the event log data. We\nvisualize the discovered models to understand the workflow structures and\ndependencies within the process. Additionally, we discuss the strengths and\nlimitations of each mining approach in capturing the underlying process\ndynamics. Our findings shed light on the efficiency and effectiveness of road\ntraffic fine management processes, providing valuable insights for process\noptimization and decision-making. This study demonstrates the utility of pm4py\nin facilitating process mining tasks and its potential for analyzing real-world\nbusiness processes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11294v1",
    "published_date": "2024-09-17 15:48:46 UTC",
    "updated_date": "2024-09-17 15:48:46 UTC"
  },
  {
    "arxiv_id": "2409.11290v1",
    "title": "Neural Networks for Vehicle Routing Problem",
    "authors": [
      "László Kovács",
      "Ali Jlidi"
    ],
    "abstract": "The Vehicle Routing Problem is about optimizing the routes of vehicles to\nmeet the needs of customers at specific locations. The route graph consists of\ndepots on several levels and customer positions. Several optimization methods\nhave been developed over the years, most of which are based on some type of\nclassic heuristic: genetic algorithm, simulated annealing, tabu search, ant\ncolony optimization, firefly algorithm. Recent developments in machine learning\nprovide a new toolset, the rich family of neural networks, for tackling complex\nproblems. The main area of application of neural networks is the area of\nclassification and regression. Route optimization can be viewed as a new\nchallenge for neural networks. The article first presents an analysis of the\napplicability of neural network tools, then a novel graphical neural network\nmodel is presented in detail. The efficiency analysis based on test experiments\nshows the applicability of the proposed NN architecture.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11290v1",
    "published_date": "2024-09-17 15:45:30 UTC",
    "updated_date": "2024-09-17 15:45:30 UTC"
  },
  {
    "arxiv_id": "2409.11283v4",
    "title": "Zero-resource Hallucination Detection for Text Generation via Graph-based Contextual Knowledge Triples Modeling",
    "authors": [
      "Xinyue Fang",
      "Zhen Huang",
      "Zhiliang Tian",
      "Minghui Fang",
      "Ziyi Pan",
      "Quntian Fang",
      "Zhihua Wen",
      "Hengyue Pan",
      "Dongsheng Li"
    ],
    "abstract": "LLMs obtain remarkable performance but suffer from hallucinations. Most\nresearch on detecting hallucination focuses on the questions with short and\nconcrete correct answers that are easy to check the faithfulness. Hallucination\ndetections for text generation with open-ended answers are more challenging.\nSome researchers use external knowledge to detect hallucinations in generated\ntexts, but external resources for specific scenarios are hard to access. Recent\nstudies on detecting hallucinations in long text without external resources\nconduct consistency comparison among multiple sampled outputs. To handle long\ntexts, researchers split long texts into multiple facts and individually\ncompare the consistency of each pairs of facts. However, these methods (1)\nhardly achieve alignment among multiple facts; (2) overlook dependencies\nbetween multiple contextual facts. In this paper, we propose a graph-based\ncontext-aware (GCA) hallucination detection for text generations, which aligns\nknowledge facts and considers the dependencies between contextual knowledge\ntriples in consistency comparison. Particularly, to align multiple facts, we\nconduct a triple-oriented response segmentation to extract multiple knowledge\ntriples. To model dependencies among contextual knowledge triple (facts), we\nconstruct contextual triple into a graph and enhance triples' interactions via\nmessage passing and aggregating via RGCN. To avoid the omission of knowledge\ntriples in long text, we conduct a LLM-based reverse verification via\nreconstructing the knowledge triples. Experiments show that our model enhances\nhallucination detection and excels all baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2409.11283v4",
    "published_date": "2024-09-17 15:38:36 UTC",
    "updated_date": "2025-03-07 04:29:19 UTC"
  },
  {
    "arxiv_id": "2409.11277v1",
    "title": "Machine Learning and Theory Ladenness -- A Phenomenological Account",
    "authors": [
      "Alberto Termine",
      "Emanuele Ratti",
      "Alessandro Facchini"
    ],
    "abstract": "In recent years, the dissemination of machine learning (ML) methodologies in\nscientific research has prompted discussions on theory ladenness. More\nspecifically, the issue of theory ladenness has remerged as questions about\nwhether and how ML models (MLMs) and ML modelling strategies are impacted by\nthe domain theory of the scientific field in which ML is used and implemented\n(e.g., physics, chemistry, biology, etc). On the one hand, some have argued\nthat there is no difference between traditional (pre ML) and ML assisted\nscience. In both cases, theory plays an essential and unavoidable role in the\nanalysis of phenomena and the construction and use of models. Others have\nargued instead that ML methodologies and models are theory independent and, in\nsome cases, even theory free. In this article, we argue that both positions are\noverly simplistic and do not advance our understanding of the interplay between\nML methods and domain theories. Specifically, we provide an analysis of theory\nladenness in ML assisted science. Our analysis reveals that, while the\nconstruction of MLMs can be relatively independent of domain theory, the\npractical implementation and interpretation of these models within a given\nspecific domain still relies on fundamental theoretical assumptions and\nbackground knowledge.",
    "categories": [
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages with reference",
    "pdf_url": "http://arxiv.org/pdf/2409.11277v1",
    "published_date": "2024-09-17 15:29:14 UTC",
    "updated_date": "2024-09-17 15:29:14 UTC"
  },
  {
    "arxiv_id": "2409.11274v1",
    "title": "Task Arithmetic for Language Expansion in Speech Translation",
    "authors": [
      "Yao-Fei Cheng",
      "Hayato Futami",
      "Yosuke Kashiwagi",
      "Emiru Tsunoo",
      "Wen Shen Teo",
      "Siddhant Arora",
      "Shinji Watanabe"
    ],
    "abstract": "Recent advances in large language models (LLMs) have gained interest in\nspeech-text multimodal foundation models, achieving strong performance on\ninstruction-based speech translation (ST). However, expanding language pairs\nfrom an existing instruction-tuned ST system is costly due to the necessity of\nre-training on a combination of new and previous datasets. We propose to expand\nnew language pairs by merging the model trained on new language pairs and the\nexisting model, using task arithmetic. We find that the direct application of\ntask arithmetic for ST causes the merged model to fail to follow instructions;\nthus, generating translation in incorrect languages. To eliminate language\nconfusion, we propose an augmented task arithmetic method that merges an\nadditional language control model. It is trained to generate the correct target\nlanguage token following the instructions. Our experiments demonstrate that our\nproposed language control model can achieve language expansion by eliminating\nlanguage confusion. In our MuST-C and CoVoST-2 experiments, it shows up to 4.66\nand 4.92 BLEU scores improvement, respectively. In addition, we demonstrate the\nuse of our task arithmetic framework can expand to a language pair where\nneither paired ST training data nor a pre-trained ST model is available. We\nfirst synthesize the ST system from machine translation (MT) systems via task\nanalogy, then merge the synthesized ST system to the existing ST model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11274v1",
    "published_date": "2024-09-17 15:25:11 UTC",
    "updated_date": "2024-09-17 15:25:11 UTC"
  },
  {
    "arxiv_id": "2409.11272v7",
    "title": "LOLA -- An Open-Source Massively Multilingual Large Language Model",
    "authors": [
      "Nikit Srivastava",
      "Denis Kuchelev",
      "Tatiana Moteu Ngoli",
      "Kshitij Shetty",
      "Michael Röder",
      "Hamada Zahera",
      "Diego Moussallem",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "abstract": "This paper presents LOLA, a massively multilingual large language model\ntrained on more than 160 languages using a sparse Mixture-of-Experts\nTransformer architecture. Our architectural and implementation choices address\nthe challenge of harnessing linguistic diversity while maintaining efficiency\nand avoiding the common pitfalls of multilinguality. Our analysis of the\nevaluation results shows competitive performance in natural language generation\nand understanding tasks. Additionally, we demonstrate how the learned\nexpert-routing mechanism exploits implicit phylogenetic linguistic patterns to\npotentially alleviate the curse of multilinguality. We provide an in-depth look\nat the training process, an analysis of the datasets, and a balanced\nexploration of the model's strengths and limitations. As an open-source model,\nLOLA promotes reproducibility and serves as a robust foundation for future\nresearch. Our findings enable the development of compute-efficient multilingual\nmodels with strong, scalable performance across languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11272v7",
    "published_date": "2024-09-17 15:23:08 UTC",
    "updated_date": "2025-02-02 10:59:51 UTC"
  },
  {
    "arxiv_id": "2409.11267v2",
    "title": "Integrating Reinforcement Learning and Model Predictive Control with Applications to Microgrids",
    "authors": [
      "Caio Fabio Oliveira da Silva",
      "Azita Dabiri",
      "Bart De Schutter"
    ],
    "abstract": "This work proposes an approach that integrates reinforcement learning and\nmodel predictive control (MPC) to solve finite-horizon optimal control problems\nin mixed-logical dynamical systems efficiently. Optimization-based control of\nsuch systems with discrete and continuous decision variables entails the online\nsolution of mixed-integer linear programs, which suffer from the curse of\ndimensionality. Our approach aims to mitigate this issue by decoupling the\ndecision on the discrete variables from the decision on the continuous\nvariables. In the proposed approach, reinforcement learning determines the\ndiscrete decision variables and simplifies the online optimization problem of\nthe MPC controller from a mixed-integer linear program to a linear program,\nsignificantly reducing the computational time. A fundamental contribution of\nthis work is the definition of the decoupled Q-function, which plays a crucial\nrole in making the learning problem tractable in a combinatorial action space.\nWe motivate the use of recurrent neural networks to approximate the decoupled\nQ-function and show how they can be employed in a reinforcement learning\nsetting. Simulation experiments on a microgrid system using real-world data\ndemonstrate that the proposed method substantially reduces the online\ncomputation time of MPC while maintaining high feasibility and low\nsuboptimality.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11267v2",
    "published_date": "2024-09-17 15:17:16 UTC",
    "updated_date": "2025-04-14 09:44:22 UTC"
  },
  {
    "arxiv_id": "2409.11262v2",
    "title": "The Sounds of Home: A Speech-Removed Residential Audio Dataset for Sound Event Detection",
    "authors": [
      "Gabriel Bibbó",
      "Thomas Deacon",
      "Arshdeep Singh",
      "Mark D. Plumbley"
    ],
    "abstract": "This paper presents a residential audio dataset to support sound event\ndetection research for smart home applications aimed at promoting wellbeing for\nolder adults. The dataset is constructed by deploying audio recording systems\nin the homes of 8 participants aged 55-80 years for a 7-day period. Acoustic\ncharacteristics are documented through detailed floor plans and construction\nmaterial information to enable replication of the recording environments for AI\nmodel deployment. A novel automated speech removal pipeline is developed, using\npre-trained audio neural networks to detect and remove segments containing\nspoken voice, while preserving segments containing other sound events. The\nresulting dataset consists of privacy-compliant audio recordings that\naccurately capture the soundscapes and activities of daily living within\nresidential spaces. The paper details the dataset creation methodology, the\nspeech removal pipeline utilizing cascaded model architectures, and an analysis\nof the vocal label distribution to validate the speech removal process. This\ndataset enables the development and benchmarking of sound event detection\nmodels tailored specifically for in-home applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11262v2",
    "published_date": "2024-09-17 15:10:36 UTC",
    "updated_date": "2024-10-04 10:35:03 UTC"
  },
  {
    "arxiv_id": "2409.11258v1",
    "title": "Attacking Slicing Network via Side-channel Reinforcement Learning Attack",
    "authors": [
      "Wei Shao",
      "Chandra Thapa",
      "Rayne Holland",
      "Sarah Ali Siddiqui",
      "Seyit Camtepe"
    ],
    "abstract": "Network slicing in 5G and the future 6G networks will enable the creation of\nmultiple virtualized networks on a shared physical infrastructure. This\ninnovative approach enables the provision of tailored networks to accommodate\nspecific business types or industry users, thus delivering more customized and\nefficient services. However, the shared memory and cache in network slicing\nintroduce security vulnerabilities that have yet to be fully addressed. In this\npaper, we introduce a reinforcement learning-based side-channel cache attack\nframework specifically designed for network slicing environments. Unlike\ntraditional cache attack methods, our framework leverages reinforcement\nlearning to dynamically identify and exploit cache locations storing sensitive\ninformation, such as authentication keys and user registration data. We assume\nthat one slice network is compromised and demonstrate how the attacker can\ninduce another shared slice to send registration requests, thereby estimating\nthe cache locations of critical data. By formulating the cache timing channel\nattack as a reinforcement learning-driven guessing game between the attack\nslice and the victim slice, our model efficiently explores possible actions to\npinpoint memory blocks containing sensitive information. Experimental results\nshowcase the superiority of our approach, achieving a success rate of\napproximately 95\\% to 98\\% in accurately identifying the storage locations of\nsensitive data. This high level of accuracy underscores the potential risks in\nshared network slicing environments and highlights the need for robust security\nmeasures to safeguard against such advanced side-channel attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.11258v1",
    "published_date": "2024-09-17 15:07:05 UTC",
    "updated_date": "2024-09-17 15:07:05 UTC"
  },
  {
    "arxiv_id": "2409.11449v1",
    "title": "Evaluation of pretrained language models on music understanding",
    "authors": [
      "Yannis Vasilakis",
      "Rachel Bittner",
      "Johan Pauwels"
    ],
    "abstract": "Music-text multimodal systems have enabled new approaches to Music\nInformation Research (MIR) applications such as audio-to-text and text-to-audio\nretrieval, text-based song generation, and music captioning. Despite the\nreported success, little effort has been put into evaluating the musical\nknowledge of Large Language Models (LLM). In this paper, we demonstrate that\nLLMs suffer from 1) prompt sensitivity, 2) inability to model negation (e.g.\n'rock song without guitar'), and 3) sensitivity towards the presence of\nspecific words. We quantified these properties as a triplet-based accuracy,\nevaluating the ability to model the relative similarity of labels in a\nhierarchical ontology. We leveraged the Audioset ontology to generate triplets\nconsisting of an anchor, a positive (relevant) label, and a negative (less\nrelevant) label for the genre and instruments sub-tree. We evaluated the\ntriplet-based musical knowledge for six general-purpose Transformer-based\nmodels. The triplets obtained through this methodology required filtering, as\nsome were difficult to judge and therefore relatively uninformative for\nevaluation purposes. Despite the relatively high accuracy reported,\ninconsistencies are evident in all six models, suggesting that off-the-shelf\nLLMs need adaptation to music before use.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11449v1",
    "published_date": "2024-09-17 14:44:49 UTC",
    "updated_date": "2024-09-17 14:44:49 UTC"
  },
  {
    "arxiv_id": "2409.11232v2",
    "title": "Fast Analysis of the OpenAI O1-Preview Model in Solving Random K-SAT Problem: Does the LLM Solve the Problem Itself or Call an External SAT Solver?",
    "authors": [
      "Raffaele Marino"
    ],
    "abstract": "In this manuscript, I present an analysis on the performance of OpenAI\nO1-preview model in solving random K-SAT instances for K$\\in {2,3,4}$ as a\nfunction of $\\alpha=M/N$ where $M$ is the number of clauses and $N$ is the\nnumber of variables of the satisfiable problem. I show that the model can call\nan external SAT solver to solve the instances, rather than solving them\ndirectly. Despite using external solvers, the model reports incorrect\nassignments as output. Moreover, I propose and present an analysis to quantify\nwhether the OpenAI O1-preview model demonstrates a spark of intelligence or\nmerely makes random guesses when outputting an assignment for a Boolean\nsatisfiability problem.",
    "categories": [
      "cs.CL",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11232v2",
    "published_date": "2024-09-17 14:29:03 UTC",
    "updated_date": "2024-09-20 07:53:16 UTC"
  },
  {
    "arxiv_id": "2409.11228v2",
    "title": "Learning Source Disentanglement in Neural Audio Codec",
    "authors": [
      "Xiaoyu Bie",
      "Xubo Liu",
      "Gaël Richard"
    ],
    "abstract": "Neural audio codecs have significantly advanced audio compression by\nefficiently converting continuous audio signals into discrete tokens. These\ncodecs preserve high-quality sound and enable sophisticated sound generation\nthrough generative models trained on these tokens. However, existing neural\ncodec models are typically trained on large, undifferentiated audio datasets,\nneglecting the essential discrepancies between sound domains like speech,\nmusic, and environmental sound effects. This oversight complicates data\nmodeling and poses additional challenges to the controllability of sound\ngeneration. To tackle these issues, we introduce the Source-Disentangled Neural\nAudio Codec (SD-Codec), a novel approach that combines audio coding and source\nseparation. By jointly learning audio resynthesis and separation, SD-Codec\nexplicitly assigns audio signals from different domains to distinct codebooks,\nsets of discrete representations. Experimental results indicate that SD-Codec\nnot only maintains competitive resynthesis quality but also, supported by the\nseparation results, demonstrates successful disentanglement of different\nsources in the latent space, thereby enhancing interpretability in audio codec\nand providing potential finer control over the audio generation process.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "ICASSP 2025, project page: https://xiaoyubie1994.github.io/sdcodec/",
    "pdf_url": "http://arxiv.org/pdf/2409.11228v2",
    "published_date": "2024-09-17 14:21:02 UTC",
    "updated_date": "2025-02-11 10:35:04 UTC"
  },
  {
    "arxiv_id": "2409.11195v1",
    "title": "SDP: Spiking Diffusion Policy for Robotic Manipulation with Learnable Channel-Wise Membrane Thresholds",
    "authors": [
      "Zhixing Hou",
      "Maoxu Gao",
      "Hang Yu",
      "Mengyu Yang",
      "Chio-In Ieong"
    ],
    "abstract": "This paper introduces a Spiking Diffusion Policy (SDP) learning method for\nrobotic manipulation by integrating Spiking Neurons and Learnable Channel-wise\nMembrane Thresholds (LCMT) into the diffusion policy model, thereby enhancing\ncomputational efficiency and achieving high performance in evaluated tasks.\nSpecifically, the proposed SDP model employs the U-Net architecture as the\nbackbone for diffusion learning within the Spiking Neural Network (SNN). It\nstrategically places residual connections between the spike convolution\noperations and the Leaky Integrate-and-Fire (LIF) nodes, thereby preventing\ndisruptions to the spiking states. Additionally, we introduce a temporal\nencoding block and a temporal decoding block to transform static and dynamic\ndata with timestep $T_S$ into each other, enabling the transmission of data\nwithin the SNN in spike format. Furthermore, we propose LCMT to enable the\nadaptive acquisition of membrane potential thresholds, thereby matching the\nconditions of varying membrane potentials and firing rates across channels and\navoiding the cumbersome process of manually setting and tuning hyperparameters.\nEvaluating the SDP model on seven distinct tasks with SNN timestep $T_S=4$, we\nachieve results comparable to those of the ANN counterparts, along with faster\nconvergence speeds than the baseline SNN method. This improvement is\naccompanied by a reduction of 94.3\\% in dynamic energy consumption estimated on\n45nm hardware.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11195v1",
    "published_date": "2024-09-17 13:53:36 UTC",
    "updated_date": "2024-09-17 13:53:36 UTC"
  },
  {
    "arxiv_id": "2409.11192v1",
    "title": "Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory",
    "authors": [
      "Eunhae Lee"
    ],
    "abstract": "One application area of long-term memory (LTM) capabilities with increasing\ntraction is personal AI companions and assistants. With the ability to retain\nand contextualize past interactions and adapt to user preferences, personal AI\ncompanions and assistants promise a profound shift in how we interact with AI\nand are on track to become indispensable in personal and professional settings.\nHowever, this advancement introduces new challenges and vulnerabilities that\nrequire careful consideration regarding the deployment and widespread use of\nthese systems. The goal of this paper is to explore the broader implications of\nbuilding and deploying personal AI applications with LTM capabilities using a\nholistic evaluation approach. This will be done in three ways: 1) reviewing the\ntechnological underpinnings of LTM in Large Language Models, 2) surveying\ncurrent personal AI companions and assistants, and 3) analyzing critical\nconsiderations and implications of deploying and using these applications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11192v1",
    "published_date": "2024-09-17 13:48:29 UTC",
    "updated_date": "2024-09-17 13:48:29 UTC"
  },
  {
    "arxiv_id": "2409.11190v2",
    "title": "SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer",
    "authors": [
      "Anmol Gautam",
      "Kishore Kumar",
      "Adarsh Jha",
      "Mukunda NS",
      "Ishaan Bhola"
    ],
    "abstract": "We present SuperCoder2.0, an advanced autonomous system designed to enhance\nsoftware development through artificial intelligence. The system combines an\nAI-native development approach with intelligent agents to enable fully\nautonomous coding. Key focus areas include a retry mechanism with error output\ntraceback, comprehensive code rewriting and replacement using Abstract Syntax\nTree (ast) parsing to minimize linting issues, code embedding technique for\nretrieval-augmented generation, and a focus on localizing methods for\nproblem-solving rather than identifying specific line numbers. The methodology\nemploys a three-step hierarchical search space reduction approach for code base\nnavigation and bug localization:utilizing Retrieval Augmented Generation (RAG)\nand a Repository File Level Map to identify candidate files, (2) narrowing down\nto the most relevant files using a File Level Schematic Map, and (3) extracting\n'relevant locations' within these files. Code editing is performed through a\ntwo-part module comprising CodeGeneration and CodeEditing, which generates\nmultiple solutions at different temperature values and replaces entire methods\nor classes to maintain code integrity. A feedback loop executes\nrepository-level test cases to validate and refine solutions. Experiments\nconducted on the SWE-bench Lite dataset demonstrate SuperCoder2.0's\neffectiveness, achieving correct file localization in 84.33% of cases within\nthe top 5 candidates and successfully resolving 34% of test instances. This\nperformance places SuperCoder2.0 fourth globally on the SWE-bench leaderboard.\nThe system's ability to handle diverse repositories and problem types\nhighlights its potential as a versatile tool for autonomous software\ndevelopment. Future work will focus on refining the code editing process and\nexploring advanced embedding models for improved natural language to code\nmapping.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11190v2",
    "published_date": "2024-09-17 13:44:42 UTC",
    "updated_date": "2024-10-27 05:57:07 UTC"
  },
  {
    "arxiv_id": "2410.02773v1",
    "title": "Mind the Uncertainty in Human Disagreement: Evaluating Discrepancies between Model Predictions and Human Responses in VQA",
    "authors": [
      "Jian Lan",
      "Diego Frassinelli",
      "Barbara Plank"
    ],
    "abstract": "Large vision-language models frequently struggle to accurately predict\nresponses provided by multiple human annotators, particularly when those\nresponses exhibit human uncertainty. In this study, we focus on the Visual\nQuestion Answering (VQA) task, and we comprehensively evaluate how well the\nstate-of-the-art vision-language models correlate with the distribution of\nhuman responses. To do so, we categorize our samples based on their levels\n(low, medium, high) of human uncertainty in disagreement (HUD) and employ not\nonly accuracy but also three new human-correlated metrics in VQA, to\ninvestigate the impact of HUD. To better align models with humans, we also\nverify the effect of common calibration and human calibration. Our results show\nthat even BEiT3, currently the best model for this task, struggles to capture\nthe multi-label distribution inherent in diverse human responses. Additionally,\nwe observe that the commonly used accuracy-oriented calibration technique\nadversely affects BEiT3's ability to capture HUD, further widening the gap\nbetween model predictions and human distributions. In contrast, we show the\nbenefits of calibrating models towards human distributions for VQA, better\naligning model confidence with human uncertainty. Our findings highlight that\nfor VQA, the consistent alignment between human responses and model predictions\nis understudied and should become the next crucial target of future studies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02773v1",
    "published_date": "2024-09-17 13:44:25 UTC",
    "updated_date": "2024-09-17 13:44:25 UTC"
  },
  {
    "arxiv_id": "2409.11174v1",
    "title": "Identifying Influential nodes in Brain Networks via Self-Supervised Graph-Transformer",
    "authors": [
      "Yanqing Kang",
      "Di Zhu",
      "Haiyang Zhang",
      "Enze Shi",
      "Sigang Yu",
      "Jinru Wu",
      "Xuhui Wang",
      "Xuan Liu",
      "Geng Chen",
      "Xi Jiang",
      "Tuo Zhang",
      "Shu Zhang"
    ],
    "abstract": "Studying influential nodes (I-nodes) in brain networks is of great\nsignificance in the field of brain imaging. Most existing studies consider\nbrain connectivity hubs as I-nodes. However, this approach relies heavily on\nprior knowledge from graph theory, which may overlook the intrinsic\ncharacteristics of the brain network, especially when its architecture is not\nfully understood. In contrast, self-supervised deep learning can learn\nmeaningful representations directly from the data. This approach enables the\nexploration of I-nodes for brain networks, which is also lacking in current\nstudies. This paper proposes a Self-Supervised Graph Reconstruction framework\nbased on Graph-Transformer (SSGR-GT) to identify I-nodes, which has three main\ncharacteristics. First, as a self-supervised model, SSGR-GT extracts the\nimportance of brain nodes to the reconstruction. Second, SSGR-GT uses\nGraph-Transformer, which is well-suited for extracting features from brain\ngraphs, combining both local and global characteristics. Third, multimodal\nanalysis of I-nodes uses graph-based fusion technology, combining functional\nand structural brain information. The I-nodes we obtained are distributed in\ncritical areas such as the superior frontal lobe, lateral parietal lobe, and\nlateral occipital lobe, with a total of 56 identified across different\nexperiments. These I-nodes are involved in more brain networks than other\nregions, have longer fiber connections, and occupy more central positions in\nstructural connectivity. They also exhibit strong connectivity and high node\nefficiency in both functional and structural networks. Furthermore, there is a\nsignificant overlap between the I-nodes and both the structural and functional\nrich-club. These findings enhance our understanding of the I-nodes within the\nbrain network, and provide new insights for future research in further\nunderstanding the brain working mechanisms.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11174v1",
    "published_date": "2024-09-17 13:31:28 UTC",
    "updated_date": "2024-09-17 13:31:28 UTC"
  },
  {
    "arxiv_id": "2409.11148v3",
    "title": "Improving the Efficiency of Visually Augmented Language Models",
    "authors": [
      "Paula Ontalvilla",
      "Aitor Ormazabal",
      "Gorka Azkune"
    ],
    "abstract": "Despite the impressive performance of autoregressive Language Models (LM) it\nhas been shown that due to reporting bias, LMs lack visual knowledge, i.e. they\ndo not know much about the visual world and its properties. To augment LMs with\nvisual knowledge, existing solutions often rely on explicit images, requiring\ntime-consuming retrieval or image generation systems. This paper shows that\nexplicit images are not necessary to visually augment an LM. Instead, we use\nvisually-grounded text representations obtained from the well-known CLIP\nmultimodal system. For a fair comparison, we modify VALM, a visually-augmented\nLM which uses image retrieval and representation, to work directly with\nvisually-grounded text representations. We name this new model BLIND-VALM. We\nshow that BLIND-VALM performs on par with VALM for Visual Language\nUnderstanding (VLU), Natural Language Understanding (NLU) and Language Modeling\ntasks, despite being significantly more efficient and simpler. We also show\nthat scaling up our model within the compute budget of VALM, either increasing\nthe model or pre-training corpus size, we outperform VALM for all the\nevaluation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.11148v3",
    "published_date": "2024-09-17 13:02:19 UTC",
    "updated_date": "2024-12-14 17:17:48 UTC"
  },
  {
    "arxiv_id": "2409.11145v2",
    "title": "High-Resolution Speech Restoration with Latent Diffusion Model",
    "authors": [
      "Tushar Dhyani",
      "Florian Lux",
      "Michele Mancusi",
      "Giorgio Fabbro",
      "Fritz Hohl",
      "Ngoc Thang Vu"
    ],
    "abstract": "Traditional speech enhancement methods often oversimplify the task of\nrestoration by focusing on a single type of distortion. Generative models that\nhandle multiple distortions frequently struggle with phone reconstruction and\nhigh-frequency harmonics, leading to breathing and gasping artifacts that\nreduce the intelligibility of reconstructed speech. These models are also\ncomputationally demanding, and many solutions are restricted to producing\noutputs in the wide-band frequency range, which limits their suitability for\nprofessional applications. To address these challenges, we propose Hi-ResLDM, a\nnovel generative model based on latent diffusion designed to remove multiple\ndistortions and restore speech recordings to studio quality, sampled at 48kHz.\nWe benchmark Hi-ResLDM against state-of-the-art methods that leverage GAN and\nConditional Flow Matching (CFM) components, demonstrating superior performance\nin regenerating high-frequency-band details. Hi-ResLDM not only excels in\nnon-instrusive metrics but is also consistently preferred in human evaluation\nand performs competitively on intrusive evaluations, making it ideal for\nhigh-resolution speech restoration.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11145v2",
    "published_date": "2024-09-17 12:55:23 UTC",
    "updated_date": "2025-02-10 10:06:57 UTC"
  },
  {
    "arxiv_id": "2409.18989v1",
    "title": "SC-Phi2: A Fine-tuned Small Language Model for StarCraft II Macromanagement Tasks",
    "authors": [
      "Muhammad Junaid Khan",
      "Gita Sukthankar"
    ],
    "abstract": "This paper introduces SC-Phi2, a fine-tuned StarCraft II small language model\nfor macromanagement tasks. Small language models, like Phi2, Gemma, and\nDistilBERT, are streamlined versions of large language models (LLMs) with fewer\nparameters that require less power and memory to run. To teach Microsoft's Phi2\nmodel about StarCraft, we create a new SC2 text dataset with information about\nStarCraft races, roles, and actions and use it to fine-tune Phi-2 with\nself-supervised learning. We pair this language model with a Vision Transformer\n(ViT) from the pre-trained BLIP-2 (Bootstrapping Language Image Pre-training)\nmodel, fine-tuning it on the MSC replay dataset. This enables us to construct\ndynamic prompts that include visual game state information. Unlike the large\nmodels used in StarCraft LLMs such as GPT-3.5, Phi2 is trained primarily on\ntextbook data and contains little inherent knowledge of StarCraft II beyond\nwhat is provided by our training process. By using LoRA (Low-rank Adaptation)\nand quantization, our model can be trained on a single GPU. We demonstrate that\nour model performs well at micromanagement tasks such as build order and global\nstate prediction with a small number of parameters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.18989v1",
    "published_date": "2024-09-17 12:50:32 UTC",
    "updated_date": "2024-09-17 12:50:32 UTC"
  },
  {
    "arxiv_id": "2409.11138v1",
    "title": "Learning Generalized Hamiltonians using fully Symplectic Mappings",
    "authors": [
      "Harsh Choudhary",
      "Chandan Gupta",
      "Vyacheslav kungrutsev",
      "Melvin Leok",
      "Georgios Korpas"
    ],
    "abstract": "Many important physical systems can be described as the evolution of a\nHamiltonian system, which has the important property of being conservative,\nthat is, energy is conserved throughout the evolution. Physics Informed Neural\nNetworks and in particular Hamiltonian Neural Networks have emerged as a\nmechanism to incorporate structural inductive bias into the NN model. By\nensuring physical invariances are conserved, the models exhibit significantly\nbetter sample complexity and out-of-distribution accuracy than standard NNs.\nLearning the Hamiltonian as a function of its canonical variables, typically\nposition and velocity, from sample observations of the system thus becomes a\ncritical task in system identification and long-term prediction of system\nbehavior. However, to truly preserve the long-run physical conservation\nproperties of Hamiltonian systems, one must use symplectic integrators for a\nforward pass of the system's simulation. While symplectic schemes have been\nused in the literature, they are thus far limited to situations when they\nreduce to explicit algorithms, which include the case of separable Hamiltonians\nor augmented non-separable Hamiltonians. We extend it to generalized\nnon-separable Hamiltonians, and noting the self-adjoint property of symplectic\nintegrators, we bypass computationally intensive backpropagation through an ODE\nsolver. We show that the method is robust to noise and provides a good\napproximation of the system Hamiltonian when the state variables are sampled\nfrom a noisy observation. In the numerical results, we show the performance of\nthe method concerning Hamiltonian reconstruction and conservation, indicating\nits particular advantage for non-separable systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to The 39th Annual AAAI Conference on Artificial\n  Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2409.11138v1",
    "published_date": "2024-09-17 12:45:49 UTC",
    "updated_date": "2024-09-17 12:45:49 UTC"
  },
  {
    "arxiv_id": "2409.11123v1",
    "title": "Gradient-free Post-hoc Explainability Using Distillation Aided Learnable Approach",
    "authors": [
      "Debarpan Bhattacharya",
      "Amir H. Poorjam",
      "Deepak Mittal",
      "Sriram Ganapathy"
    ],
    "abstract": "The recent advancements in artificial intelligence (AI), with the release of\nseveral large models having only query access, make a strong case for\nexplainability of deep models in a post-hoc gradient free manner. In this\npaper, we propose a framework, named distillation aided explainability (DAX),\nthat attempts to generate a saliency-based explanation in a model agnostic\ngradient free application. The DAX approach poses the problem of explanation in\na learnable setting with a mask generation network and a distillation network.\nThe mask generation network learns to generate the multiplier mask that finds\nthe salient regions of the input, while the student distillation network aims\nto approximate the local behavior of the black-box model. We propose a joint\noptimization of the two networks in the DAX framework using the locally\nperturbed input samples, with the targets derived from input-output access to\nthe black-box model. We extensively evaluate DAX across different modalities\n(image and audio), in a classification setting, using a diverse set of\nevaluations (intersection over union with ground truth, deletion based and\nsubjective human evaluation based measures) and benchmark it with respect to\n$9$ different methods. In these evaluations, the DAX significantly outperforms\nthe existing approaches on all modalities and evaluation metrics.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 10 figures, Accepted in IEEE Journal of Selected Topics in\n  Signal Processing (JSTSP), 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.11123v1",
    "published_date": "2024-09-17 12:21:11 UTC",
    "updated_date": "2024-09-17 12:21:11 UTC"
  },
  {
    "arxiv_id": "2409.11114v2",
    "title": "Diversity-grounded Channel Prototypical Learning for Out-of-Distribution Intent Detection",
    "authors": [
      "Bo Liu",
      "Liming Zhan",
      "Yujie Feng",
      "Zexin Lu",
      "Chengqiang Xie",
      "Lei Xue",
      "Albert Y. S. Lam",
      "Xiao-Ming Wu"
    ],
    "abstract": "In the realm of task-oriented dialogue systems, a robust intent detection\nmechanism must effectively handle malformed utterances encountered in\nreal-world scenarios. This study presents a novel fine-tuning framework for\nlarge language models (LLMs) aimed at enhancing in-distribution (ID) intent\nclassification and out-of-distribution (OOD) intent detection, which utilizes\nsemantic matching with prototypes derived from ID class names. By harnessing\nthe highly distinguishable representations of LLMs, we construct semantic\nprototypes for each ID class using a diversity-grounded prompt tuning approach.\nWe rigorously test our framework in a challenging OOD context, where ID and OOD\nclasses are semantically close yet distinct, referred to as \\emph{near} OOD\ndetection. For a thorough assessment, we benchmark our method against the\nprevalent fine-tuning approaches. The experimental findings reveal that our\nmethod demonstrates superior performance in both few-shot ID intent\nclassification and near-OOD intent detection tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2409.11114v2",
    "published_date": "2024-09-17 12:07:17 UTC",
    "updated_date": "2024-09-20 14:03:36 UTC"
  },
  {
    "arxiv_id": "2410.02771v1",
    "title": "Complex-valued convolutional neural network classification of hand gesture from radar images",
    "authors": [
      "Shokooh Khandan"
    ],
    "abstract": "Hand gesture recognition systems have yielded many exciting advancements in\nthe last decade and become more popular in HCI (human-computer interaction)\nwith several application areas, which spans from safety and security\napplications to automotive field. Various deep neural network architectures\nhave already been inspected for hand gesture recognition systems, including\nmulti-layer perceptron (MLP), convolutional neural network (CNN), recurrent\nneural network (RNN) and a cascade of the last two architectures known as\nCNN-RNN. However, a major problem still exists, which is most of the existing\nML algorithms are designed and developed the building blocks and techniques for\nreal-valued (RV). Researchers applied various RV techniques on the\ncomplex-valued (CV) radar images, such as converting a CV optimisation problem\ninto a RV one, by splitting the complex numbers into their real and imaginary\nparts. However, the major disadvantage of this method is that the resulting\nalgorithm will double the network dimensions. Recent work on RNNs and other\nfundamental theoretical analysis suggest that CV numbers have a richer\nrepresentational capacity, but due to the absence of the building blocks\nrequired to design such models, the performance of CV networks are\nmarginalised. In this report, we propose a fully CV-CNN, including all building\nblocks, forward and backward operations, and derivatives all in complex domain.\nWe explore our proposed classification model on two sets of CV hand gesture\nradar images in comparison with the equivalent RV model. In chapter five, we\npropose a CV-forward residual network, for the purpose of binary classification\nof the two sets of CV hand gesture radar datasets and compare its performance\nwith our proposed CV-CNN and a baseline CV-forward CNN.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07 (Primary), 90C30 (Secondary)",
      "I.2.6; G.1.6"
    ],
    "primary_category": "cs.CV",
    "comment": "173 pages, 36 tables, 50 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.02771v1",
    "published_date": "2024-09-17 11:49:14 UTC",
    "updated_date": "2024-09-17 11:49:14 UTC"
  },
  {
    "arxiv_id": "2409.11078v1",
    "title": "MonoKAN: Certified Monotonic Kolmogorov-Arnold Network",
    "authors": [
      "Alejandro Polo-Molina",
      "David Alfaya",
      "Jose Portela"
    ],
    "abstract": "Artificial Neural Networks (ANNs) have significantly advanced various fields\nby effectively recognizing patterns and solving complex problems. Despite these\nadvancements, their interpretability remains a critical challenge, especially\nin applications where transparency and accountability are essential. To address\nthis, explainable AI (XAI) has made progress in demystifying ANNs, yet\ninterpretability alone is often insufficient. In certain applications, model\npredictions must align with expert-imposed requirements, sometimes exemplified\nby partial monotonicity constraints. While monotonic approaches are found in\nthe literature for traditional Multi-layer Perceptrons (MLPs), they still face\ndifficulties in achieving both interpretability and certified partial\nmonotonicity. Recently, the Kolmogorov-Arnold Network (KAN) architecture, based\non learnable activation functions parametrized as splines, has been proposed as\na more interpretable alternative to MLPs. Building on this, we introduce a\nnovel ANN architecture called MonoKAN, which is based on the KAN architecture\nand achieves certified partial monotonicity while enhancing interpretability.\nTo achieve this, we employ cubic Hermite splines, which guarantee monotonicity\nthrough a set of straightforward conditions. Additionally, by using positive\nweights in the linear combinations of these splines, we ensure that the network\npreserves the monotonic relationships between input and output. Our experiments\ndemonstrate that MonoKAN not only enhances interpretability but also improves\npredictive performance across the majority of benchmarks, outperforming\nstate-of-the-art monotonic MLP approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "68T07, 68T05, 41A15"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.11078v1",
    "published_date": "2024-09-17 11:10:59 UTC",
    "updated_date": "2024-09-17 11:10:59 UTC"
  },
  {
    "arxiv_id": "2409.11074v2",
    "title": "RoMath: A Mathematical Reasoning Benchmark in Romanian",
    "authors": [
      "Adrian Cosma",
      "Ana-Maria Bucur",
      "Emilian Radoi"
    ],
    "abstract": "Mathematics has long been conveyed through natural language, primarily for\nhuman understanding. With the rise of mechanized mathematics and proof\nassistants, there is a growing need to understand informal mathematical text,\nyet most existing benchmarks focus solely on English, overlooking other\nlanguages. This paper introduces RoMath, a Romanian mathematical reasoning\nbenchmark suite comprising three datasets: RoMath-Baccalaureate,\nRoMath-Competitions and RoMath-Synthetic, which cover a range of mathematical\ndomains and difficulty levels, aiming to improve non-English language models\nand promote multilingual AI development. By focusing on Romanian, a\nlow-resource language with unique linguistic features, RoMath addresses the\nlimitations of Anglo-centric models and emphasizes the need for dedicated\nresources beyond simple automatic translation. We benchmark several open-weight\nlanguage models, highlighting the importance of creating resources for\nunderrepresented languages. We make the code and dataset available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "4 Figures, 12 Tables",
    "pdf_url": "http://arxiv.org/pdf/2409.11074v2",
    "published_date": "2024-09-17 11:03:46 UTC",
    "updated_date": "2024-09-20 15:47:51 UTC"
  },
  {
    "arxiv_id": "2409.11071v2",
    "title": "Improve Machine Learning carbon footprint using Parquet dataset format and Mixed Precision training for regression models -- Part II",
    "authors": [
      "Andrew Antonopoulos"
    ],
    "abstract": "This is the 2nd part of the dissertation for my master degree and compared\nthe power consumption using the Comma-Separated-Values (CSV) and parquet\ndataset format with the default floating point (32bit) and Nvidia mixed\nprecision (16bit and 32bit) while training a regression ML model. The same\ncustom PC as per the 1st part, which was dedicated to the classification\ntesting and analysis, was built to perform the experiments, and different ML\nhyper-parameters, such as batch size, neurons, and epochs, were chosen to build\nDeep Neural Networks (DNN). A benchmarking test with default hyper-parameter\nvalues for the DNN was used as a reference, while the experiments used a\ncombination of different settings. The results were recorded in Excel, and\ndescriptive statistics were chosen to calculate the mean between the groups and\ncompare them using graphs and tables. The outcome was positive when using mixed\nprecision combined with specific hyper-parameters. Compared to the\nbenchmarking, optimising the regression models reduced the power consumption\nbetween 7 and 11 Watts. The regression results show that while mixed precision\ncan help improve power consumption, we must carefully consider the\nhyper-parameters. A high number of batch sizes and neurons will negatively\naffect power consumption. However, this research required inferential\nstatistics, specifically ANOVA and T-test, to compare the relationship between\nthe means. The results reported no statistical significance between the means\nin the regression tests and accepted H0. Therefore, choosing different ML\ntechniques and the Parquet dataset format will not improve the computational\npower consumption and the overall ML carbon footprint. However, a more\nextensive implementation with a cluster of GPUs can increase the sample size\nsignificantly, as it is an essential factor and can change the outcome of the\nstatistical analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, 16 tables, 19 figures. arXiv admin note: substantial text\n  overlap with arXiv:2409.07853",
    "pdf_url": "http://arxiv.org/pdf/2409.11071v2",
    "published_date": "2024-09-17 10:53:03 UTC",
    "updated_date": "2024-09-20 08:54:44 UTC"
  },
  {
    "arxiv_id": "2409.11055v4",
    "title": "Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant",
    "authors": [
      "Jemin Lee",
      "Sihyeong Park",
      "Jinse Kwon",
      "Jihun Oh",
      "Yongin Kwon"
    ],
    "abstract": "Quantization has gained attention as a promising solution for the\ncost-effective deployment of large and small language models. However, most\nprior work has been limited to perplexity or basic knowledge tasks and lacks a\ncomprehensive evaluation of recent models like Llama-3.3. In this paper, we\nconduct a comprehensive evaluation of instruction-tuned models spanning 1B to\n405B parameters, applying four quantization methods across 13 datasets. Our\nfindings reveal that (1) quantized models generally surpass smaller FP16\nbaselines, yet they often struggle with instruction-following and hallucination\ndetection; (2) FP8 consistently emerges as the most robust option across tasks,\nand AWQ tends to outperform GPTQ in weight-only quantization; (3) smaller\nmodels can suffer severe accuracy drops at 4-bit quantization, while 70B-scale\nmodels maintain stable performance; (4) notably, \\textit{hard} tasks do not\nalways experience the largest accuracy losses, indicating that quantization\nmagnifies a model's inherent weaknesses rather than simply correlating with\ntask difficulty; and (5) an LLM-based judge (MT-Bench) highlights significant\nperformance declines in Coding and STEM tasks, though it occasionally reports\nimprovements in reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in IJCAI 2025, 21 pages, 2 figure",
    "pdf_url": "http://arxiv.org/pdf/2409.11055v4",
    "published_date": "2024-09-17 10:31:37 UTC",
    "updated_date": "2025-05-12 02:25:24 UTC"
  },
  {
    "arxiv_id": "2409.11052v1",
    "title": "A logical alarm for misaligned binary classifiers",
    "authors": [
      "Andrés Corrada-Emmanuel",
      "Ilya Parker",
      "Ramesh Bharadwaj"
    ],
    "abstract": "If two agents disagree in their decisions, we may suspect they are not both\ncorrect. This intuition is formalized for evaluating agents that have carried\nout a binary classification task. Their agreements and disagreements on a joint\ntest allow us to establish the only group evaluations logically consistent with\ntheir responses. This is done by establishing a set of axioms (algebraic\nrelations) that must be universally obeyed by all evaluations of binary\nresponders. A complete set of such axioms are possible for each ensemble of\nsize N. The axioms for $N = 1, 2$ are used to construct a fully logical alarm -\none that can prove that at least one ensemble member is malfunctioning using\nonly unlabeled data. The similarities of this approach to formal software\nverification and its utility for recent agendas of safe guaranteed AI are\ndiscussed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "62G99 (Primary), 14Q99 (Secondary)",
      "I.2.3"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 7 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2409.11052v1",
    "published_date": "2024-09-17 10:19:22 UTC",
    "updated_date": "2024-09-17 10:19:22 UTC"
  },
  {
    "arxiv_id": "2410.05274v2",
    "title": "Scale-Invariant Object Detection by Adaptive Convolution with Unified Global-Local Context",
    "authors": [
      "Amrita Singh",
      "Snehasis Mukherjee"
    ],
    "abstract": "Dense features are important for detecting minute objects in images.\nUnfortunately, despite the remarkable efficacy of the CNN models in multi-scale\nobject detection, CNN models often fail to detect smaller objects in images due\nto the loss of dense features during the pooling process. Atrous convolution\naddresses this issue by applying sparse kernels. However, sparse kernels often\ncan lose the multi-scale detection efficacy of the CNN model. In this paper, we\npropose an object detection model using a Switchable (adaptive) Atrous\nConvolutional Network (SAC-Net) based on the efficientDet model. A fixed atrous\nrate limits the performance of the CNN models in the convolutional layers. To\novercome this limitation, we introduce a switchable mechanism that allows for\ndynamically adjusting the atrous rate during the forward pass. The proposed\nSAC-Net encapsulates the benefits of both low-level and high-level features to\nachieve improved performance on multi-scale object detection tasks, without\nlosing the dense features. Further, we apply a depth-wise switchable atrous\nrate to the proposed network, to improve the scale-invariant features. Finally,\nwe apply global context on the proposed model. Our extensive experiments on\nbenchmark datasets demonstrate that the proposed SAC-Net outperforms the\nstate-of-the-art models by a significant margin in terms of accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05274v2",
    "published_date": "2024-09-17 10:08:37 UTC",
    "updated_date": "2025-03-05 08:36:27 UTC"
  },
  {
    "arxiv_id": "2409.11446v1",
    "title": "Volvo Discovery Challenge at ECML-PKDD 2024",
    "authors": [
      "Mahmoud Rahat",
      "Peyman Sheikholharam Mashhadi",
      "Sławomir Nowaczyk",
      "Shamik Choudhury",
      "Leo Petrin",
      "Thorsteinn Rognvaldsson",
      "Andreas Voskou",
      "Carlo Metta",
      "Claudio Savelli"
    ],
    "abstract": "This paper presents an overview of the Volvo Discovery Challenge, held during\nthe ECML-PKDD 2024 conference. The challenge's goal was to predict the failure\nrisk of an anonymized component in Volvo trucks using a newly published\ndataset. The test data included observations from two generations (gen1 and\ngen2) of the component, while the training data was provided only for gen1. The\nchallenge attracted 52 data scientists from around the world who submitted a\ntotal of 791 entries. We provide a brief description of the problem definition,\nchallenge setup, and statistics about the submissions. In the section on\nwinning methodologies, the first, second, and third-place winners of the\ncompetition briefly describe their proposed methods and provide GitHub links to\ntheir implemented code. The shared code can be interesting as an advanced\nmethodology for researchers in the predictive maintenance domain. The\ncompetition was hosted on the Codabench platform.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ECML/PKDD 2024, Discovery Challenge",
    "pdf_url": "http://arxiv.org/pdf/2409.11446v1",
    "published_date": "2024-09-17 10:05:24 UTC",
    "updated_date": "2024-09-17 10:05:24 UTC"
  },
  {
    "arxiv_id": "2410.02769v1",
    "title": "Fundamentals of legislation for autonomous artificial intelligence systems",
    "authors": [
      "Anna Romanova"
    ],
    "abstract": "The article proposes a method for forming a dedicated operational context in\ncourse of development and implementation of autonomous corporate management\nsystems based on example of autonomous systems for a board of directors. The\nsignificant part of the operational context for autonomous company management\nsystems is the regulatory and legal environment within which corporations\noperate. In order to create a special operational context for autonomous\nartificial intelligence systems, the wording of local regulatory documents can\nbe simultaneously presented in two versions: for use by people and for use by\nautonomous systems. In this case, the artificial intelligence system will get a\nwell-defined operational context that allows such a system to perform functions\nwithin the required standards. Local regulations that provide for the specifics\nof the joint work of individuals and autonomous artificial intelligence systems\ncan create the basis of the relevant legislation governing the development and\nimplementation of autonomous systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "in Russian language",
    "pdf_url": "http://arxiv.org/pdf/2410.02769v1",
    "published_date": "2024-09-17 09:50:23 UTC",
    "updated_date": "2024-09-17 09:50:23 UTC"
  },
  {
    "arxiv_id": "2409.11024v1",
    "title": "D2Vformer: A Flexible Time Series Prediction Model Based on Time Position Embedding",
    "authors": [
      "Xiaobao Song",
      "Hao Wang",
      "Liwei Deng",
      "Yuxin He",
      "Wenming Cao",
      "Chi-Sing Leungc"
    ],
    "abstract": "Time position embeddings capture the positional information of time steps,\noften serving as auxiliary inputs to enhance the predictive capabilities of\ntime series models. However, existing models exhibit limitations in capturing\nintricate time positional information and effectively utilizing these\nembeddings. To address these limitations, this paper proposes a novel model\ncalled D2Vformer. Unlike typical prediction methods that rely on RNNs or\nTransformers, this approach can directly handle scenarios where the predicted\nsequence is not adjacent to the input sequence or where its length dynamically\nchanges. In comparison to conventional methods, D2Vformer undoubtedly saves a\nsignificant amount of training resources. In D2Vformer, the Date2Vec module\nuses the timestamp information and feature sequences to generate time position\nembeddings. Afterward, D2Vformer introduces a new fusion block that utilizes an\nattention mechanism to explore the similarity in time positions between the\nembeddings of the input sequence and the predicted sequence, thereby generating\npredictions based on this similarity. Through extensive experiments on six\ndatasets, we demonstrate that Date2Vec outperforms other time position\nembedding methods, and D2Vformer surpasses state-of-the-art methods in both\nfixed-length and variable-length prediction tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11024v1",
    "published_date": "2024-09-17 09:39:37 UTC",
    "updated_date": "2024-09-17 09:39:37 UTC"
  },
  {
    "arxiv_id": "2409.11022v4",
    "title": "DynamicNER: A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition",
    "authors": [
      "Hanjun Luo",
      "Yingbin Jin",
      "Xinfeng Li",
      "Xuecheng Liu",
      "Ruizhe Chen",
      "Tong Shang",
      "Kun Wang",
      "Qingsong Wen",
      "Zuozhu Liu"
    ],
    "abstract": "With the advancement of Large Language Models (LLMs), more and more\nresearchers apply LLMs for Named Entity Recognition (NER) methods, bringing\nvitality to this classical Natural Language Processing task. However, existing\ndatasets are designed for traditional machine learning methods, inadequate for\nLLM-based methods in terms of corpus selection, entity categorization, and\ndesign logic. This limitation leads to less effective evaluation and model\nfine-tuning. To address this issue, we propose DynamicNER, the first NER\ndataset specifically designed for LLMs and with dynamic categorization,\ntranscending the limitations of fixed categorization in existing datasets. It\nis also multi-lingual and multi-granular, covering 8 languages and 155 entity\ntypes, with corpus spanning multiple specialized domains. Furthermore, in\nresponse to the limitations demonstrated by existing LLM-based methods during\nDynamicNER testing, we develop CascadeNER, a novel NER method based on a\ntwo-stage strategy and lightweight LLMs, addressing the problems in current\nmethods. Experiments show that DynamicNER is an effective benchmark for\nLLM-based NER methods, and CascadeNER outperforms existing methods with fewer\ncomputational resources. Our work is opened at\nhttps://github.com/CascadeNER/CascadeNER.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11022v4",
    "published_date": "2024-09-17 09:32:12 UTC",
    "updated_date": "2025-02-24 08:46:07 UTC"
  },
  {
    "arxiv_id": "2409.11011v1",
    "title": "Enhanced segmentation of femoral bone metastasis in CT scans of patients using synthetic data generation with 3D diffusion models",
    "authors": [
      "Emile Saillard",
      "Aurélie Levillain",
      "David Mitton",
      "Jean-Baptiste Pialat",
      "Cyrille Confavreux",
      "Hélène Follet",
      "Thomas Grenier"
    ],
    "abstract": "Purpose: Bone metastasis have a major impact on the quality of life of\npatients and they are diverse in terms of size and location, making their\nsegmentation complex. Manual segmentation is time-consuming, and expert\nsegmentations are subject to operator variability, which makes obtaining\naccurate and reproducible segmentations of bone metastasis on CT-scans a\nchallenging yet important task to achieve. Materials and Methods: Deep learning\nmethods tackle segmentation tasks efficiently but require large datasets along\nwith expert manual segmentations to generalize on new images. We propose an\nautomated data synthesis pipeline using 3D Denoising Diffusion Probabilistic\nModels (DDPM) to enchance the segmentation of femoral metastasis from CT-scan\nvolumes of patients. We used 29 existing lesions along with 26 healthy femurs\nto create new realistic synthetic metastatic images, and trained a DDPM to\nimprove the diversity and realism of the simulated volumes. We also\ninvestigated the operator variability on manual segmentation. Results: We\ncreated 5675 new volumes, then trained 3D U-Net segmentation models on real and\nsynthetic data to compare segmentation performance, and we evaluated the\nperformance of the models depending on the amount of synthetic data used in\ntraining. Conclusion: Our results showed that segmentation models trained with\nsynthetic data outperformed those trained on real volumes only, and that those\nmodels perform especially well when considering operator variability.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "14 pages, 5 figures 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.11011v1",
    "published_date": "2024-09-17 09:21:19 UTC",
    "updated_date": "2024-09-17 09:21:19 UTC"
  },
  {
    "arxiv_id": "2409.11003v1",
    "title": "Single-stage TTS with Masked Audio Token Modeling and Semantic Knowledge Distillation",
    "authors": [
      "Gerard I. Gállego",
      "Roy Fejgin",
      "Chunghsin Yeh",
      "Xiaoyu Liu",
      "Gautam Bhattacharya"
    ],
    "abstract": "Audio token modeling has become a powerful framework for speech synthesis,\nwith two-stage approaches employing semantic tokens remaining prevalent. In\nthis paper, we aim to simplify this process by introducing a semantic knowledge\ndistillation method that enables high-quality speech generation in a single\nstage. Our proposed model improves speech quality, intelligibility, and speaker\nsimilarity compared to a single-stage baseline. Although two-stage systems\nstill lead in intelligibility, our model significantly narrows the gap while\ndelivering comparable speech quality. These findings showcase the potential of\nsingle-stage models to achieve efficient, high-quality TTS with a more compact\nand streamlined architecture.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "Demo page: see https://narsistts.github.io",
    "pdf_url": "http://arxiv.org/pdf/2409.11003v1",
    "published_date": "2024-09-17 09:08:43 UTC",
    "updated_date": "2024-09-17 09:08:43 UTC"
  },
  {
    "arxiv_id": "2409.10999v1",
    "title": "Enhancing Low-Resource Language and Instruction Following Capabilities of Audio Language Models",
    "authors": [
      "Potsawee Manakul",
      "Guangzhi Sun",
      "Warit Sirichotedumrong",
      "Kasima Tharnpipitchai",
      "Kunat Pipatanakul"
    ],
    "abstract": "Audio language models can understand audio inputs and perform a range of\naudio-related tasks based on instructions, such as speech recognition and audio\ncaptioning, where the instructions are usually textual prompts. Audio language\nmodels are mostly initialized from pre-trained audio encoders and large\nlanguage models (LLMs). Although these pre-trained components were developed to\nsupport multiple languages, audio-language models are trained predominantly on\nEnglish data, which may limit their usability to only English instructions or\nEnglish speech inputs. First, this paper examines the performance of existing\naudio language models in an underserved language using Thai as an example. This\npaper demonstrates that, despite being built on multilingual backbones, audio\nlanguage models do not exhibit cross-lingual emergent abilities to low-resource\nlanguages. Second, this paper studies data mixture for developing audio\nlanguage models that are optimized for a target language as well as English. In\naddition. this paper integrates audio comprehension and speech\ninstruction-following capabilities into a single unified model. Our experiments\nprovide insights into data mixture for enhancing instruction-following\ncapabilities in both a low-resource language and English. Our model,\nTyphoon-Audio, outperforms existing open-source audio language models by a\nconsiderable margin, and it is comparable to state-of-the-art Gemini-1.5-Pro in\nboth English and Thai languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages. Preprint under review",
    "pdf_url": "http://arxiv.org/pdf/2409.10999v1",
    "published_date": "2024-09-17 09:04:03 UTC",
    "updated_date": "2024-09-17 09:04:03 UTC"
  },
  {
    "arxiv_id": "2409.10994v3",
    "title": "Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs",
    "authors": [
      "Dingjie Song",
      "Wenjun Wang",
      "Shunian Chen",
      "Xidong Wang",
      "Michael Guan",
      "Benyou Wang"
    ],
    "abstract": "The rapid advancement of Multimodal Large Language Models (MLLMs) has led to\nremarkable performances across various domains. However, this progress is\naccompanied by a substantial surge in the resource consumption of these models.\nWe address this pressing issue by introducing a new approach, Token Reduction\nusing CLIP Metric (TRIM), aimed at improving the efficiency of MLLMs without\nsacrificing their performance. Inspired by human attention patterns in Visual\nQuestion Answering (VQA) tasks, TRIM presents a fresh perspective on the\nselection and reduction of image tokens. The TRIM method has been extensively\ntested across 12 datasets, and the results demonstrate a significant reduction\nin computational overhead while maintaining a consistent level of performance.\nThis research marks a critical stride in efficient MLLM development, promoting\ngreater accessibility and sustainability of high-performing models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.10994v3",
    "published_date": "2024-09-17 08:56:27 UTC",
    "updated_date": "2024-12-17 02:05:27 UTC"
  },
  {
    "arxiv_id": "2409.10989v2",
    "title": "GOSt-MT: A Knowledge Graph for Occupation-related Gender Biases in Machine Translation",
    "authors": [
      "Orfeas Menis Mastromichalakis",
      "Giorgos Filandrianos",
      "Eva Tsouparopoulou",
      "Dimitris Parsanoglou",
      "Maria Symeonaki",
      "Giorgos Stamou"
    ],
    "abstract": "Gender bias in machine translation (MT) systems poses significant challenges\nthat often result in the reinforcement of harmful stereotypes. Especially in\nthe labour domain where frequently occupations are inaccurately associated with\nspecific genders, such biases perpetuate traditional gender stereotypes with a\nsignificant impact on society. Addressing these issues is crucial for ensuring\nequitable and accurate MT systems. This paper introduces a novel approach to\nstudying occupation-related gender bias through the creation of the GOSt-MT\n(Gender and Occupation Statistics for Machine Translation) Knowledge Graph.\nGOSt-MT integrates comprehensive gender statistics from real-world labour data\nand textual corpora used in MT training. This Knowledge Graph allows for a\ndetailed analysis of gender bias across English, French, and Greek,\nfacilitating the identification of persistent stereotypes and areas requiring\nintervention. By providing a structured framework for understanding how\noccupations are gendered in both labour markets and MT systems, GOSt-MT\ncontributes to efforts aimed at making MT systems more equitable and reducing\ngender biases in automated translations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the KG-STAR'24: Workshop on Knowledge Graphs for\n  Responsible AI co-located with the 33rd ACM CIKM Conference, October 25,\n  2024, Boise, Idaho",
    "pdf_url": "http://arxiv.org/pdf/2409.10989v2",
    "published_date": "2024-09-17 08:44:20 UTC",
    "updated_date": "2024-10-04 12:13:42 UTC"
  },
  {
    "arxiv_id": "2409.10986v1",
    "title": "Control-flow Reconstruction Attacks on Business Process Models",
    "authors": [
      "Henrik Kirchmann",
      "Stephan A. Fahrenkrog-Petersen",
      "Felix Mannhardt",
      "Matthias Weidlich"
    ],
    "abstract": "Process models may be automatically generated from event logs that contain\nas-is data of a business process. While such models generalize over the\ncontrol-flow of specific, recorded process executions, they are often also\nannotated with behavioural statistics, such as execution frequencies.Based\nthereon, once a model is published, certain insights about the original process\nexecutions may be reconstructed, so that an external party may extract\nconfidential information about the business process. This work is the first to\nempirically investigate such reconstruction attempts based on process models.\nTo this end, we propose different play-out strategies that reconstruct the\ncontrol-flow from process trees, potentially exploiting frequency annotations.\nTo assess the potential success of such reconstruction attacks on process\nmodels, and hence the risks imposed by publishing them, we compare the\nreconstructed process executions with those of the original log for several\nreal-world datasets.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10986v1",
    "published_date": "2024-09-17 08:42:55 UTC",
    "updated_date": "2024-09-17 08:42:55 UTC"
  },
  {
    "arxiv_id": "2409.10964v2",
    "title": "Active learning for energy-based antibody optimization and enhanced screening",
    "authors": [
      "Kairi Furui",
      "Masahito Ohue"
    ],
    "abstract": "Accurate prediction and optimization of protein-protein binding affinity is\ncrucial for therapeutic antibody development. Although machine learning-based\nprediction methods $\\Delta\\Delta G$ are suitable for large-scale mutant\nscreening, they struggle to predict the effects of multiple mutations for\ntargets without existing binders. Energy function-based methods, though more\naccurate, are time consuming and not ideal for large-scale screening. To\naddress this, we propose an active learning workflow that efficiently trains a\ndeep learning model to learn energy functions for specific targets, combining\nthe advantages of both approaches. Our method integrates the RDE-Network deep\nlearning model with Rosetta's energy function-based Flex ddG to efficiently\nexplore mutants. In a case study targeting HER2-binding Trastuzumab mutants,\nour approach significantly improved the screening performance over random\nselection and demonstrated the ability to identify mutants with better binding\nproperties without experimental $\\Delta\\Delta G$ data. This workflow advances\ncomputational antibody design by combining machine learning, physics-based\ncomputations, and active learning to achieve more efficient antibody\ndevelopment.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.BM",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.10964v2",
    "published_date": "2024-09-17 08:01:58 UTC",
    "updated_date": "2024-09-18 07:37:31 UTC"
  },
  {
    "arxiv_id": "2410.00916v1",
    "title": "IBM Quantum Computers: Evolution, Performance, and Future Directions",
    "authors": [
      "M. AbuGhanem"
    ],
    "abstract": "Quantum computers represent a transformative frontier in computational\ntechnology, promising exponential speedups beyond classical computing limits.\nIBM Quantum has led significant advancements in both hardware and software,\nproviding access to quantum hardware via IBM Cloud since 2016, achieving a\nmilestone with the world's first accessible quantum computer. This article\nexplores IBM's quantum computing journey, focusing on the development of\npractical quantum computers. We summarize the evolution and advancements of IBM\nQuantum's processors across generations, including their recent breakthrough\nsurpassing the 1,000-qubit barrier. The paper reviews detailed performance\nmetrics across various hardware, tracing their evolution over time and\nhighlighting IBM Quantum's transition from the noisy intermediate-scale quantum\n(NISQ) computing era towards fault-tolerant quantum computing capabilities.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00916v1",
    "published_date": "2024-09-17 07:50:50 UTC",
    "updated_date": "2024-09-17 07:50:50 UTC"
  },
  {
    "arxiv_id": "2409.10956v1",
    "title": "Versatile Incremental Learning: Towards Class and Domain-Agnostic Incremental Learning",
    "authors": [
      "Min-Yeong Park",
      "Jae-Ho Lee",
      "Gyeong-Moon Park"
    ],
    "abstract": "Incremental Learning (IL) aims to accumulate knowledge from sequential input\ntasks while overcoming catastrophic forgetting. Existing IL methods typically\nassume that an incoming task has only increments of classes or domains,\nreferred to as Class IL (CIL) or Domain IL (DIL), respectively. In this work,\nwe consider a more challenging and realistic but under-explored IL scenario,\nnamed Versatile Incremental Learning (VIL), in which a model has no prior of\nwhich of the classes or domains will increase in the next task. In the proposed\nVIL scenario, the model faces intra-class domain confusion and inter-domain\nclass confusion, which makes the model fail to accumulate new knowledge without\ninterference with learned knowledge. To address these issues, we propose a\nsimple yet effective IL framework, named Incremental Classifier with Adaptation\nShift cONtrol (ICON). Based on shifts of learnable modules, we design a novel\nregularization method called Cluster-based Adaptation Shift conTrol (CAST) to\ncontrol the model to avoid confusion with the previously learned knowledge and\nthereby accumulate the new knowledge more effectively. Moreover, we introduce\nan Incremental Classifier (IC) which expands its output nodes to address the\noverwriting issue from different domains corresponding to a single class while\nmaintaining the previous knowledge. We conducted extensive experiments on three\nbenchmarks, showcasing the effectiveness of our method across all the\nscenarios, particularly in cases where the next task can be randomly altered.\nOur implementation code is available at https://github.com/KHU-AGI/VIL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 6 figures, 6 tables, ECCV 2024 Poster",
    "pdf_url": "http://arxiv.org/pdf/2409.10956v1",
    "published_date": "2024-09-17 07:44:28 UTC",
    "updated_date": "2024-09-17 07:44:28 UTC"
  },
  {
    "arxiv_id": "2409.10955v1",
    "title": "Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style",
    "authors": [
      "Yuepei Li",
      "Kang Zhou",
      "Qiao Qiao",
      "Bach Nguyen",
      "Qing Wang",
      "Qi Li"
    ],
    "abstract": "Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by\nincorporating external information into the response generation process.\nHowever, how context-faithful LLMs are and what factors influence LLMs'\ncontext-faithfulness remain largely unexplored. In this study, we investigate\nthe impact of memory strength and evidence presentation on LLMs' receptiveness\nto external evidence. We introduce a method to quantify the memory strength of\nLLMs by measuring the divergence in LLMs' responses to different paraphrases of\nthe same question, which is not considered by previous works. We also generate\nevidence in various styles to evaluate the effects of evidence in different\nstyles. Two datasets are used for evaluation: Natural Questions (NQ) with\npopular questions and popQA featuring long-tail questions. Our results show\nthat for questions with high memory strength, LLMs are more likely to rely on\ninternal memory, particularly for larger LLMs such as GPT-4. On the other hand,\npresenting paraphrased evidence significantly increases LLMs' receptiveness\ncompared to simple repetition or adding details.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10955v1",
    "published_date": "2024-09-17 07:44:06 UTC",
    "updated_date": "2024-09-17 07:44:06 UTC"
  },
  {
    "arxiv_id": "2409.10944v1",
    "title": "Contrasformer: A Brain Network Contrastive Transformer for Neurodegenerative Condition Identification",
    "authors": [
      "Jiaxing Xu",
      "Kai He",
      "Mengcheng Lan",
      "Qingtian Bian",
      "Wei Li",
      "Tieying Li",
      "Yiping Ke",
      "Miao Qiao"
    ],
    "abstract": "Understanding neurological disorder is a fundamental problem in neuroscience,\nwhich often requires the analysis of brain networks derived from functional\nmagnetic resonance imaging (fMRI) data. Despite the prevalence of Graph Neural\nNetworks (GNNs) and Graph Transformers in various domains, applying them to\nbrain networks faces challenges. Specifically, the datasets are severely\nimpacted by the noises caused by distribution shifts across sub-populations and\nthe neglect of node identities, both obstruct the identification of\ndisease-specific patterns. To tackle these challenges, we propose\nContrasformer, a novel contrastive brain network Transformer. It generates a\nprior-knowledge-enhanced contrast graph to address the distribution shifts\nacross sub-populations by a two-stream attention mechanism. A cross attention\nwith identity embedding highlights the identity of nodes, and three auxiliary\nlosses ensure group consistency. Evaluated on 4 functional brain network\ndatasets over 4 different diseases, Contrasformer outperforms the\nstate-of-the-art methods for brain networks by achieving up to 10.8\\%\nimprovement in accuracy, which demonstrates its efficacy in neurological\ndisorder identification. Case studies illustrate its interpretability,\nespecially in the context of neuroscience. This paper provides a solution for\nanalyzing brain networks, offering valuable insights into neurological\ndisorders. Our code is available at\n\\url{https://github.com/AngusMonroe/Contrasformer}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10944v1",
    "published_date": "2024-09-17 07:26:02 UTC",
    "updated_date": "2024-09-17 07:26:02 UTC"
  },
  {
    "arxiv_id": "2409.10932v2",
    "title": "Early Detection of Coronary Heart Disease Using Hybrid Quantum Machine Learning Approach",
    "authors": [
      "Mehroush Banday",
      "Sherin Zafar",
      "Parul Agarwal",
      "M Afshar Alam",
      "Abubeker K M"
    ],
    "abstract": "Coronary heart disease (CHD) is a severe cardiac disease, and hence, its\nearly diagnosis is essential as it improves treatment results and saves money\non medical care. The prevailing development of quantum computing and machine\nlearning (ML) technologies may bring practical improvement to the performance\nof CHD diagnosis. Quantum machine learning (QML) is receiving tremendous\ninterest in various disciplines due to its higher performance and capabilities.\nA quantum leap in the healthcare industry will increase processing power and\noptimise multiple models. Techniques for QML have the potential to forecast\ncardiac disease and help in early detection. To predict the risk of coronary\nheart disease, a hybrid approach utilizing an ensemble machine learning model\nbased on QML classifiers is presented in this paper. Our approach, with its\nunique ability to address multidimensional healthcare data, reassures the\nmethod's robustness by fusing quantum and classical ML algorithms in a\nmulti-step inferential framework. The marked rise in heart disease and death\nrates impacts worldwide human health and the global economy. Reducing cardiac\nmorbidity and mortality requires early detection of heart disease. In this\nresearch, a hybrid approach utilizes techniques with quantum computing\ncapabilities to tackle complex problems that are not amenable to conventional\nmachine learning algorithms and to minimize computational expenses. The\nproposed method has been developed in the Raspberry Pi 5 Graphics Processing\nUnit (GPU) platform and tested on a broad dataset that integrates clinical and\nimaging data from patients suffering from CHD and healthy controls. Compared to\nclassical machine learning models, the accuracy, sensitivity, F1 score, and\nspecificity of the proposed hybrid QML model used with CHD are manifold higher.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "I found a mistake in methodology presentation. Also I have observed\n  more precised results with new dataset. So my research guide ask me to modify\n  the current version",
    "pdf_url": "http://arxiv.org/pdf/2409.10932v2",
    "published_date": "2024-09-17 07:08:39 UTC",
    "updated_date": "2024-10-01 15:21:05 UTC"
  },
  {
    "arxiv_id": "2409.10921v1",
    "title": "KALE: An Artwork Image Captioning System Augmented with Heterogeneous Graph",
    "authors": [
      "Yanbei Jiang",
      "Krista A. Ehinger",
      "Jey Han Lau"
    ],
    "abstract": "Exploring the narratives conveyed by fine-art paintings is a challenge in\nimage captioning, where the goal is to generate descriptions that not only\nprecisely represent the visual content but also offer a in-depth interpretation\nof the artwork's meaning. The task is particularly complex for artwork images\ndue to their diverse interpretations and varied aesthetic principles across\ndifferent artistic schools and styles. In response to this, we present KALE\nKnowledge-Augmented vision-Language model for artwork Elaborations), a novel\napproach that enhances existing vision-language models by integrating artwork\nmetadata as additional knowledge. KALE incorporates the metadata in two ways:\nfirstly as direct textual input, and secondly through a multimodal\nheterogeneous knowledge graph. To optimize the learning of graph\nrepresentations, we introduce a new cross-modal alignment loss that maximizes\nthe similarity between the image and its corresponding metadata. Experimental\nresults demonstrate that KALE achieves strong performance (when evaluated with\nCIDEr, in particular) over existing state-of-the-art work across several\nartwork datasets. Source code of the project is available at\nhttps://github.com/Yanbei-Jiang/Artwork-Interpretation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.10921v1",
    "published_date": "2024-09-17 06:39:18 UTC",
    "updated_date": "2024-09-17 06:39:18 UTC"
  },
  {
    "arxiv_id": "2409.10909v1",
    "title": "GenCRF: Generative Clustering and Reformulation Framework for Enhanced Intent-Driven Information Retrieval",
    "authors": [
      "Wonduk Seo",
      "Haojie Zhang",
      "Yueyang Zhang",
      "Changhao Zhang",
      "Songyao Duan",
      "Lixin Su",
      "Daiting Shi",
      "Jiashu Zhao",
      "Dawei Yin"
    ],
    "abstract": "Query reformulation is a well-known problem in Information Retrieval (IR)\naimed at enhancing single search successful completion rate by automatically\nmodifying user's input query. Recent methods leverage Large Language Models\n(LLMs) to improve query reformulation, but often generate limited and redundant\nexpansions, potentially constraining their effectiveness in capturing diverse\nintents. In this paper, we propose GenCRF: a Generative Clustering and\nReformulation Framework to capture diverse intentions adaptively based on\nmultiple differentiated, well-generated queries in the retrieval phase for the\nfirst time. GenCRF leverages LLMs to generate variable queries from the initial\nquery using customized prompts, then clusters them into groups to distinctly\nrepresent diverse intents. Furthermore, the framework explores to combine\ndiverse intents query with innovative weighted aggregation strategies to\noptimize retrieval performance and crucially integrates a novel Query\nEvaluation Rewarding Model (QERM) to refine the process through feedback loops.\nEmpirical experiments on the BEIR benchmark demonstrate that GenCRF achieves\nstate-of-the-art performance, surpassing previous query reformulation SOTAs by\nup to 12% on nDCG@10. These techniques can be adapted to various LLMs,\nsignificantly boosting retriever performance and advancing the field of\nInformation Retrieval.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10909v1",
    "published_date": "2024-09-17 05:59:32 UTC",
    "updated_date": "2024-09-17 05:59:32 UTC"
  },
  {
    "arxiv_id": "2410.01827v1",
    "title": "Analysis of Convolutional Neural Network-based Image Classifications: A Multi-Featured Application for Rice Leaf Disease Prediction and Recommendations for Farmers",
    "authors": [
      "Biplov Paneru",
      "Bishwash Paneru",
      "Krishna Bikram Shah"
    ],
    "abstract": "This study presents a novel method for improving rice disease classification\nusing 8 different convolutional neural network (CNN) algorithms, which will\nfurther the field of precision agriculture. Tkinter-based application that\noffers farmers a feature-rich interface. With the help of this cutting-edge\napplication, farmers will be able to make timely and well-informed decisions by\nenabling real-time disease prediction and providing personalized\nrecommendations. Together with the user-friendly Tkinter interface, the smooth\nintegration of cutting-edge CNN transfer learning algorithms-based technology\nthat include ResNet-50, InceptionV3, VGG16, and MobileNetv2 with the UCI\ndataset represents a major advancement toward modernizing agricultural\npractices and guaranteeing sustainable crop management. Remarkable outcomes\ninclude 75% accuracy for ResNet-50, 90% accuracy for DenseNet121, 84% accuracy\nfor VGG16, 95.83% accuracy for MobileNetV2, 91.61% accuracy for DenseNet169,\nand 86% accuracy for InceptionV3. These results give a concise summary of the\nmodels' capabilities, assisting researchers in choosing appropriate strategies\nfor precise and successful rice crop disease identification. A severe\noverfitting has been seen on VGG19 with 70% accuracy and Nasnet with 80.02%\naccuracy. On Renset101, only an accuracy of 54% could be achieved, along with\nonly 33% on efficientNetB0. A MobileNetV2-trained model was successfully\ndeployed on a TKinter GUI application to make predictions using image or\nreal-time video capture.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01827v1",
    "published_date": "2024-09-17 05:32:01 UTC",
    "updated_date": "2024-09-17 05:32:01 UTC"
  },
  {
    "arxiv_id": "2409.18988v1",
    "title": "A Unified Framework to Classify Business Activities into International Standard Industrial Classification through Large Language Models for Circular Economy",
    "authors": [
      "Xiang Li",
      "Lan Zhao",
      "Junhao Ren",
      "Yajuan Sun",
      "Chuan Fu Tan",
      "Zhiquan Yeo",
      "Gaoxi Xiao"
    ],
    "abstract": "Effective information gathering and knowledge codification are pivotal for\ndeveloping recommendation systems that promote circular economy practices. One\npromising approach involves the creation of a centralized knowledge repository\ncataloguing historical waste-to-resource transactions, which subsequently\nenables the generation of recommendations based on past successes. However, a\nsignificant barrier to constructing such a knowledge repository lies in the\nabsence of a universally standardized framework for representing business\nactivities across disparate geographical regions. To address this challenge,\nthis paper leverages Large Language Models (LLMs) to classify textual data\ndescribing economic activities into the International Standard Industrial\nClassification (ISIC), a globally recognized economic activity classification\nframework. This approach enables any economic activity descriptions provided by\nbusinesses worldwide to be categorized into the unified ISIC standard,\nfacilitating the creation of a centralized knowledge repository. Our approach\nachieves a 95% accuracy rate on a 182-label test dataset with fine-tuned GPT-2\nmodel. This research contributes to the global endeavour of fostering\nsustainable circular economy practices by providing a standardized foundation\nfor knowledge codification and recommendation systems deployable across\nregions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures, accepted in 2024 IEEE International Conference on\n  Industrial Engineering and Engineering Management (IEEM 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.18988v1",
    "published_date": "2024-09-17 05:30:08 UTC",
    "updated_date": "2024-09-17 05:30:08 UTC"
  },
  {
    "arxiv_id": "2409.10898v2",
    "title": "LLMs & XAI for Water Sustainability: Seasonal Water Quality Prediction with LIME Explainable AI and a RAG-based Chatbot for Insights",
    "authors": [
      "Biplov Paneru",
      "Bishwash Paneru"
    ],
    "abstract": "Ensuring safe water supplies requires effective water quality monitoring,\nespecially in developing countries like Nepal, where contamination risks are\nhigh. This paper introduces a hybrid deep learning model to predict Nepal's\nseasonal water quality using a small dataset with multiple water quality\nparameters. Models such as CatBoost, XGBoost, Extra Trees, and LightGBM, along\nwith a neural network combining CNN and RNN layers, are used to capture\ntemporal and spatial patterns in the data. The model demonstrated notable\naccuracy improvements, aiding proactive water quality control. CatBoost,\nXGBoost, and Extra Trees Regressor predicted Water Quality Index (WQI) values\nwith an average RMSE of 1.2 and an R2 score of 0.99. Additionally, classifiers\nachieved 99 percent accuracy, cross-validated across models. LIME analysis\nhighlighted the importance of indicators like EC and DO levels in XGBoost\nclassification decisions. The neural network model achieved 92 percent\nclassification accuracy and an R2 score of 0.97, with an RMSE of 2.87 in\nregression analysis. Furthermore, a multifunctional application was developed\nto predict WQI values using both regression and classification methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10898v2",
    "published_date": "2024-09-17 05:26:59 UTC",
    "updated_date": "2025-01-30 15:47:33 UTC"
  },
  {
    "arxiv_id": "2410.02768v2",
    "title": "Uncertainty-Guided Self-Questioning and Answering for Video-Language Alignment",
    "authors": [
      "Jin Chen",
      "Kaijing Ma",
      "Haojian Huang",
      "Han Fang",
      "Hao Sun",
      "Mehdi Hosseinzadeh",
      "Zhe Liu"
    ],
    "abstract": "The development of multi-modal models has been rapidly advancing, with some\ndemonstrating remarkable capabilities. However, annotating video-text pairs\nremains expensive and insufficient. Take video question answering (VideoQA)\ntasks as an example, human annotated questions and answers often cover only\npart of the video, since the corresponding text is often short and monotonous,\nleading to underutilization of video. To address this, we propose a\nBootstrapping Video-Language Alignment framework (BoViLA), a self-training\nmethod that augments question samples during training process through LLM-based\nself-questioning and answering, which help model exploit video information and\nthe internal knowledge of LLMs more thoroughly to improve modality alignment.\nHowever, low-quality self-generated questions may instead contaminate the\nperformance, especially in the early stages of training, as we have observed in\nour experiments. To filter bad self-generated questions, we introduce\nEvidential Deep Learning (EDL) to estimate uncertainty and assess the quality\nof self-generated questions by evaluating the modality alignment within the\ncontext. To the best of our knowledge, this work is the first to explore\nLLM-based self-training frameworks for modality alignment. We evaluate BoViLA\non five strong VideoQA benchmarks, where it outperforms several\nstate-of-the-art methods and demonstrate its effectiveness and generality.\nAdditionally, we provide extensive analyses of the self-training framework and\nthe EDL-based uncertainty filtering mechanism. The code will be made available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02768v2",
    "published_date": "2024-09-17 05:17:37 UTC",
    "updated_date": "2025-05-06 09:02:57 UTC"
  },
  {
    "arxiv_id": "2409.10889v1",
    "title": "Shaking the Fake: Detecting Deepfake Videos in Real Time via Active Probes",
    "authors": [
      "Zhixin Xie",
      "Jun Luo"
    ],
    "abstract": "Real-time deepfake, a type of generative AI, is capable of \"creating\"\nnon-existing contents (e.g., swapping one's face with another) in a video. It\nhas been, very unfortunately, misused to produce deepfake videos (during web\nconferences, video calls, and identity authentication) for malicious purposes,\nincluding financial scams and political misinformation. Deepfake detection, as\nthe countermeasure against deepfake, has attracted considerable attention from\nthe academic community, yet existing works typically rely on learning passive\nfeatures that may perform poorly beyond seen datasets. In this paper, we\npropose SFake, a new real-time deepfake detection method that innovatively\nexploits deepfake models' inability to adapt to physical interference.\nSpecifically, SFake actively sends probes to trigger mechanical vibrations on\nthe smartphone, resulting in the controllable feature on the footage.\nConsequently, SFake determines whether the face is swapped by deepfake based on\nthe consistency of the facial area with the probe pattern. We implement SFake,\nevaluate its effectiveness on a self-built dataset, and compare it with six\nother detection methods. The results show that SFake outperforms other\ndetection methods with higher detection accuracy, faster process speed, and\nlower memory consumption.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10889v1",
    "published_date": "2024-09-17 04:58:30 UTC",
    "updated_date": "2024-09-17 04:58:30 UTC"
  },
  {
    "arxiv_id": "2409.12244v1",
    "title": "Sparks of Artificial General Intelligence(AGI) in Semiconductor Material Science: Early Explorations into the Next Frontier of Generative AI-Assisted Electron Micrograph Analysis",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Geethan Sannidhi",
      "Sreeja Gangasani",
      "Chidaksh Ravuru",
      "Venkataramana Runkana"
    ],
    "abstract": "Characterizing materials with electron micrographs poses significant\nchallenges for automated labeling due to the complex nature of nanomaterial\nstructures. To address this, we introduce a fully automated, end-to-end\npipeline that leverages recent advances in Generative AI. It is designed for\nanalyzing and understanding the microstructures of semiconductor materials with\neffectiveness comparable to that of human experts, contributing to the pursuit\nof Artificial General Intelligence (AGI) in nanomaterial identification. Our\napproach utilizes Large MultiModal Models (LMMs) such as GPT-4V, alongside\ntext-to-image models like DALLE-3. We integrate a GPT-4 guided Visual Question\nAnswering (VQA) method to analyze nanomaterial images, generate synthetic\nnanomaterial images via DALLE-3, and employ in-context learning with few-shot\nprompting in GPT-4V for accurate nanomaterial identification. Our method\nsurpasses traditional techniques by enhancing the precision of nanomaterial\nidentification and optimizing the process for high-throughput screening.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at Deployable AI (DAI) Workshop at AAAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2409.12244v1",
    "published_date": "2024-09-17 04:25:27 UTC",
    "updated_date": "2024-09-17 04:25:27 UTC"
  },
  {
    "arxiv_id": "2409.10870v1",
    "title": "Adaptive Large Language Models By Layerwise Attention Shortcuts",
    "authors": [
      "Prateek Verma",
      "Mert Pilanci"
    ],
    "abstract": "Transformer architectures are the backbone of the modern AI revolution.\nHowever, they are based on simply stacking the same blocks in dozens of layers\nand processing information sequentially from one block to another. In this\npaper, we propose to challenge this and introduce adaptive computations for\nLLM-like setups, which allow the final layer to attend to all of the\nintermediate layers as it deems fit through the attention mechanism, thereby\nintroducing computational \\textbf{attention shortcuts}. These shortcuts can\nthus make the architecture depth and context adaptive. We showcase four\ndifferent datasets, namely acoustic tokens, natural language, and symbolic\nmusic, and we achieve superior performance for GPT-like architecture. We give\nevidence via attention maps that the models learn complex dependencies across\nlayers that are adaptive in context and depth depending on the input tokens.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.10870v1",
    "published_date": "2024-09-17 03:46:01 UTC",
    "updated_date": "2024-09-17 03:46:01 UTC"
  },
  {
    "arxiv_id": "2409.12165v1",
    "title": "NSSR-DIL: Null-Shot Image Super-Resolution Using Deep Identity Learning",
    "authors": [
      "Sree Rama Vamsidhar S",
      "Rama Krishna Gorthi"
    ],
    "abstract": "The present State-of-the-Art (SotA) Image Super-Resolution (ISR) methods\nemploy Deep Learning (DL) techniques using a large amount of image data. The\nprimary limitation to extending the existing SotA ISR works for real-world\ninstances is their computational and time complexities. In this paper, contrary\nto the existing methods, we present a novel and computationally efficient ISR\nalgorithm that is independent of the image dataset to learn the ISR task. The\nproposed algorithm reformulates the ISR task from generating the Super-Resolved\n(SR) images to computing the inverse of the kernels that span the degradation\nspace. We introduce Deep Identity Learning, exploiting the identity relation\nbetween the degradation and inverse degradation models. The proposed approach\nneither relies on the ISR dataset nor on a single input low-resolution (LR)\nimage (like the self-supervised method i.e. ZSSR) to model the ISR task. Hence\nwe term our model as Null-Shot Super-Resolution Using Deep Identity Learning\n(NSSR-DIL). The proposed NSSR-DIL model requires fewer computational resources,\nat least by an order of 10, and demonstrates a competitive performance on\nbenchmark ISR datasets. Another salient aspect of our proposition is that the\nNSSR-DIL framework detours retraining the model and remains the same for\nvarying scale factors like X2, X3, and X4. This makes our highly efficient ISR\nmodel more suitable for real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.12165v1",
    "published_date": "2024-09-17 03:43:07 UTC",
    "updated_date": "2024-09-17 03:43:07 UTC"
  },
  {
    "arxiv_id": "2409.11445v2",
    "title": "Jailbreaking Large Language Models with Symbolic Mathematics",
    "authors": [
      "Emet Bethany",
      "Mazal Bethany",
      "Juan Arturo Nolazco Flores",
      "Sumit Kumar Jha",
      "Peyman Najafirad"
    ],
    "abstract": "Recent advancements in AI safety have led to increased efforts in training\nand red-teaming large language models (LLMs) to mitigate unsafe content\ngeneration. However, these safety mechanisms may not be comprehensive, leaving\npotential vulnerabilities unexplored. This paper introduces MathPrompt, a novel\njailbreaking technique that exploits LLMs' advanced capabilities in symbolic\nmathematics to bypass their safety mechanisms. By encoding harmful natural\nlanguage prompts into mathematical problems, we demonstrate a critical\nvulnerability in current AI safety measures. Our experiments across 13\nstate-of-the-art LLMs reveal an average attack success rate of 73.6\\%,\nhighlighting the inability of existing safety training mechanisms to generalize\nto mathematically encoded inputs. Analysis of embedding vectors shows a\nsubstantial semantic shift between original and encoded prompts, helping\nexplain the attack's success. This work emphasizes the importance of a holistic\napproach to AI safety, calling for expanded red-teaming efforts to develop\nrobust safeguards across all potential input types and their associated risks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.11445v2",
    "published_date": "2024-09-17 03:39:45 UTC",
    "updated_date": "2024-11-05 08:46:01 UTC"
  },
  {
    "arxiv_id": "2409.10849v1",
    "title": "SIFToM: Robust Spoken Instruction Following through Theory of Mind",
    "authors": [
      "Lance Ying",
      "Jason Xinyu Liu",
      "Shivam Aarya",
      "Yizirui Fang",
      "Stefanie Tellex",
      "Joshua B. Tenenbaum",
      "Tianmin Shu"
    ],
    "abstract": "Spoken language instructions are ubiquitous in agent collaboration. However,\nin human-robot collaboration, recognition accuracy for human speech is often\ninfluenced by various speech and environmental factors, such as background\nnoise, the speaker's accents, and mispronunciation. When faced with noisy or\nunfamiliar auditory inputs, humans use context and prior knowledge to\ndisambiguate the stimulus and take pragmatic actions, a process referred to as\ntop-down processing in cognitive science. We present a cognitively inspired\nmodel, Speech Instruction Following through Theory of Mind (SIFToM), to enable\nrobots to pragmatically follow human instructions under diverse speech\nconditions by inferring the human's goal and joint plan as prior for speech\nperception and understanding. We test SIFToM in simulated home experiments\n(VirtualHome 2). Results show that the SIFToM model outperforms\nstate-of-the-art speech and language models, approaching human-level accuracy\non challenging speech instruction following tasks. We then demonstrate its\nability at the task planning level on a mobile manipulator for breakfast\npreparation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.10849v1",
    "published_date": "2024-09-17 02:36:10 UTC",
    "updated_date": "2024-09-17 02:36:10 UTC"
  },
  {
    "arxiv_id": "2409.10848v1",
    "title": "3DFacePolicy: Speech-Driven 3D Facial Animation with Diffusion Policy",
    "authors": [
      "Xuanmeng Sha",
      "Liyun Zhang",
      "Tomohiro Mashita",
      "Yuki Uranishi"
    ],
    "abstract": "Audio-driven 3D facial animation has made immersive progress both in research\nand application developments. The newest approaches focus on Transformer-based\nmethods and diffusion-based methods, however, there is still gap in the\nvividness and emotional expression between the generated animation and real\nhuman face. To tackle this limitation, we propose 3DFacePolicy, a diffusion\npolicy model for 3D facial animation prediction. This method generates variable\nand realistic human facial movements by predicting the 3D vertex trajectory on\nthe 3D facial template with diffusion policy instead of facial generation for\nevery frame. It takes audio and vertex states as observations to predict the\nvertex trajectory and imitate real human facial expressions, which keeps the\ncontinuous and natural flow of human emotions. The experiments show that our\napproach is effective in variable and dynamic facial motion synthesizing.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10848v1",
    "published_date": "2024-09-17 02:30:34 UTC",
    "updated_date": "2024-09-17 02:30:34 UTC"
  },
  {
    "arxiv_id": "2409.18987v1",
    "title": "Efficient and Personalized Mobile Health Event Prediction via Small Language Models",
    "authors": [
      "Xin Wang",
      "Ting Dang",
      "Vassilis Kostakos",
      "Hong Jia"
    ],
    "abstract": "Healthcare monitoring is crucial for early detection, timely intervention,\nand the ongoing management of health conditions, ultimately improving\nindividuals' quality of life. Recent research shows that Large Language Models\n(LLMs) have demonstrated impressive performance in supporting healthcare tasks.\nHowever, existing LLM-based healthcare solutions typically rely on cloud-based\nsystems, which raise privacy concerns and increase the risk of personal\ninformation leakage. As a result, there is growing interest in running these\nmodels locally on devices like mobile phones and wearables to protect users'\nprivacy. Small Language Models (SLMs) are potential candidates to solve privacy\nand computational issues, as they are more efficient and better suited for\nlocal deployment. However, the performance of SLMs in healthcare domains has\nnot yet been investigated. This paper examines the capability of SLMs to\naccurately analyze health data, such as steps, calories, sleep minutes, and\nother vital statistics, to assess an individual's health status. Our results\nshow that, TinyLlama, which has 1.1 billion parameters, utilizes 4.31 GB\nmemory, and has 0.48s latency, showing the best performance compared other four\nstate-of-the-art (SOTA) SLMs on various healthcare applications. Our results\nindicate that SLMs could potentially be deployed on wearable or mobile devices\nfor real-time health monitoring, providing a practical solution for efficient\nand privacy-preserving healthcare.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.18987v1",
    "published_date": "2024-09-17 01:57:57 UTC",
    "updated_date": "2024-09-17 01:57:57 UTC"
  },
  {
    "arxiv_id": "2409.10831v2",
    "title": "PDMX: A Large-Scale Public Domain MusicXML Dataset for Symbolic Music Processing",
    "authors": [
      "Phillip Long",
      "Zachary Novack",
      "Taylor Berg-Kirkpatrick",
      "Julian McAuley"
    ],
    "abstract": "The recent explosion of generative AI-Music systems has raised numerous\nconcerns over data copyright, licensing music from musicians, and the conflict\nbetween open-source AI and large prestige companies. Such issues highlight the\nneed for publicly available, copyright-free musical data, in which there is a\nlarge shortage, particularly for symbolic music data. To alleviate this issue,\nwe present PDMX: a large-scale open-source dataset of over 250K public domain\nMusicXML scores collected from the score-sharing forum MuseScore, making it the\nlargest available copyright-free symbolic music dataset to our knowledge. PDMX\nadditionally includes a wealth of both tag and user interaction metadata,\nallowing us to efficiently analyze the dataset and filter for high quality\nuser-generated scores. Given the additional metadata afforded by our data\ncollection process, we conduct multitrack music generation experiments\nevaluating how different representative subsets of PDMX lead to different\nbehaviors in downstream models, and how user-rating statistics can be used as\nan effective measure of data quality. Examples can be found at\nhttps://pnlong.github.io/PDMX.demo/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to 2025 IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP)",
    "pdf_url": "http://arxiv.org/pdf/2409.10831v2",
    "published_date": "2024-09-17 01:48:42 UTC",
    "updated_date": "2025-03-17 03:08:29 UTC"
  },
  {
    "arxiv_id": "2409.10825v3",
    "title": "Unveiling and Mitigating Bias in Large Language Model Recommendations: A Path to Fairness",
    "authors": [
      "Anindya Bijoy Das",
      "Shahnewaz Karim Sakib"
    ],
    "abstract": "excel in delivering comprehensive suggestions by deeply analyzing content and\nuser behavior. However, they often inherit biases from skewed training data,\nfavoring mainstream content while underrepresenting diverse or non-traditional\noptions. This study explores the interplay between bias and LLM-based\nrecommendation systems, focusing on music, song, and book recommendations\nacross diverse demographic and cultural groups. This paper analyzes bias in\nLLM-based recommendation systems across multiple models (GPT, LLaMA, and\nGemini), revealing its deep and pervasive impact on outcomes. Intersecting\nidentities and contextual factors, like socioeconomic status, further amplify\nbiases, complicating fair recommendations across diverse groups. Our findings\nreveal that bias in these systems is deeply ingrained, yet even simple\ninterventions like prompt engineering can significantly reduce it. We further\npropose a retrieval-augmented generation strategy to mitigate bias more\neffectively. Numerical experiments validate these strategies, demonstrating\nboth the pervasive nature of bias and the impact of the proposed solutions.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10825v3",
    "published_date": "2024-09-17 01:37:57 UTC",
    "updated_date": "2024-12-02 07:00:57 UTC"
  },
  {
    "arxiv_id": "2409.10821v1",
    "title": "PReLU: Yet Another Single-Layer Solution to the XOR Problem",
    "authors": [
      "Rafael C. Pinto",
      "Anderson R. Tavares"
    ],
    "abstract": "This paper demonstrates that a single-layer neural network using Parametric\nRectified Linear Unit (PReLU) activation can solve the XOR problem, a simple\nfact that has been overlooked so far. We compare this solution to the\nmulti-layer perceptron (MLP) and the Growing Cosine Unit (GCU) activation\nfunction and explain why PReLU enables this capability. Our results show that\nthe single-layer PReLU network can achieve 100\\% success rate in a wider range\nof learning rates while using only three learnable parameters.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10821v1",
    "published_date": "2024-09-17 01:28:40 UTC",
    "updated_date": "2024-09-17 01:28:40 UTC"
  },
  {
    "arxiv_id": "2409.10811v3",
    "title": "Grounded GUI Understanding for Vision Based Spatial Intelligent Agent: Exemplified by Virtual Reality Apps",
    "authors": [
      "Shuqing Li",
      "Binchang Li",
      "Yepang Liu",
      "Cuiyun Gao",
      "Jianping Zhang",
      "Shing-Chi Cheung",
      "Michael R. Lyu"
    ],
    "abstract": "In recent years, spatial computing Virtual Reality (VR) has emerged as a\ntransformative technology, offering users immersive and interactive experiences\nacross diversified virtual environments. Users can interact with VR apps\nthrough interactable GUI elements (IGEs) on the stereoscopic three-dimensional\n(3D) graphical user interface (GUI). The accurate recognition of these IGEs is\ninstrumental, serving as the foundation of many software engineering tasks,\nincluding automated testing and effective GUI search. The most recent IGE\ndetection approaches for 2D mobile apps typically train a supervised object\ndetection model based on a large-scale manually-labeled GUI dataset, usually\nwith a pre-defined set of clickable GUI element categories like buttons and\nspinners. Such approaches can hardly be applied to IGE detection in VR apps,\ndue to a multitude of challenges including complexities posed by\nopen-vocabulary and heterogeneous IGE categories, intricacies of\ncontext-sensitive interactability, and the necessities of precise spatial\nperception and visual-semantic alignment for accurate IGE detection results.\nThus, it is necessary to embark on the IGE research tailored to VR apps. In\nthis paper, we propose the first zero-shot cOntext-sensitive inteRactable GUI\nElemeNT dEtection framework for virtual Reality apps, named Orienter. By\nimitating human behaviors, Orienter observes and understands the semantic\ncontexts of VR app scenes first, before performing the detection. The detection\nprocess is iterated within a feedback-directed validation and reflection loop.\nSpecifically, Orienter contains three components, including (1) Semantic\ncontext comprehension, (2) Reflection-directed IGE candidate detection, and (3)\nContext-sensitive interactability classification. Extensive experiments\ndemonstrate that Orienter is more effective than the state-of-the-art GUI\nelement detection approaches.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.MM",
      "D.2.5; H.5.1; H.5.2; I.4.8"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10811v3",
    "published_date": "2024-09-17 00:58:00 UTC",
    "updated_date": "2024-10-26 05:38:02 UTC"
  }
]