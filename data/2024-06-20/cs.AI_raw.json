[
  {
    "arxiv_id": "2406.14780v2",
    "title": "ACR: A Benchmark for Automatic Cohort Retrieval",
    "authors": [
      "Dung Ngoc Thai",
      "Victor Ardulov",
      "Jose Ulises Mena",
      "Simran Tiwari",
      "Gleb Erofeev",
      "Ramy Eskander",
      "Karim Tarabishy",
      "Ravi B Parikh",
      "Wael Salloum"
    ],
    "abstract": "Identifying patient cohorts is fundamental to numerous healthcare tasks,\nincluding clinical trial recruitment and retrospective studies. Current cohort\nretrieval methods in healthcare organizations rely on automated queries of\nstructured data combined with manual curation, which are time-consuming,\nlabor-intensive, and often yield low-quality results. Recent advancements in\nlarge language models (LLMs) and information retrieval (IR) offer promising\navenues to revolutionize these systems. Major challenges include managing\nextensive eligibility criteria and handling the longitudinal nature of\nunstructured Electronic Medical Records (EMRs) while ensuring that the solution\nremains cost-effective for real-world application. This paper introduces a new\ntask, Automatic Cohort Retrieval (ACR), and evaluates the performance of LLMs\nand commercial, domain-specific neuro-symbolic approaches. We provide a\nbenchmark task, a query dataset, an EMR dataset, and an evaluation framework.\nOur findings underscore the necessity for efficient, high-quality ACR systems\ncapable of longitudinal reasoning across extensive patient databases.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14780v2",
    "published_date": "2024-06-20 23:04:06 UTC",
    "updated_date": "2024-07-01 19:05:00 UTC"
  },
  {
    "arxiv_id": "2406.14779v1",
    "title": "Learning to Select Goals in Automated Planning with Deep-Q Learning",
    "authors": [
      "Carlos Núñez-Molina",
      "Juan Fernández-Olivares",
      "Raúl Pérez"
    ],
    "abstract": "In this work we propose a planning and acting architecture endowed with a\nmodule which learns to select subgoals with Deep Q-Learning. This allows us to\ndecrease the load of a planner when faced with scenarios with real-time\nrestrictions. We have trained this architecture on a video game environment\nused as a standard test-bed for intelligent systems applications, testing it on\ndifferent levels of the same game to evaluate its generalization abilities. We\nhave measured the performance of our approach as more training data is made\navailable, as well as compared it with both a state-of-the-art, classical\nplanner and the standard Deep Q-Learning algorithm. The results obtained show\nour model performs better than the alternative methods considered, when both\nplan quality (plan length) and time requirements are taken into account. On the\none hand, it is more sample-efficient than standard Deep Q-Learning, and it is\nable to generalize better across levels. On the other hand, it reduces\nproblem-solving time when compared with a state-of-the-art automated planner,\nat the expense of obtaining plans with only 9% more actions.",
    "categories": [
      "cs.AI",
      "I.2.8; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14779v1",
    "published_date": "2024-06-20 23:02:44 UTC",
    "updated_date": "2024-06-20 23:02:44 UTC"
  },
  {
    "arxiv_id": "2406.14769v1",
    "title": "How critically can an AI think? A framework for evaluating the quality of thinking of generative artificial intelligence",
    "authors": [
      "Luke Zaphir",
      "Jason M. Lodge",
      "Jacinta Lisec",
      "Dom McGrath",
      "Hassan Khosravi"
    ],
    "abstract": "Generative AI such as those with large language models have created\nopportunities for innovative assessment design practices. Due to recent\ntechnological developments, there is a need to know the limits and capabilities\nof generative AI in terms of simulating cognitive skills. Assessing student\ncritical thinking skills has been a feature of assessment for time immemorial,\nbut the demands of digital assessment create unique challenges for equity,\nacademic integrity and assessment authorship. Educators need a framework for\ndetermining their assessments vulnerability to generative AI to inform\nassessment design practices. This paper presents a framework that explores the\ncapabilities of the LLM ChatGPT4 application, which is the current industry\nbenchmark. This paper presents the Mapping of questions, AI vulnerability\ntesting, Grading, Evaluation (MAGE) framework to methodically critique their\nassessments within their own disciplinary contexts. This critique will provide\nspecific and targeted indications of their questions vulnerabilities in terms\nof the critical thinking skills. This can go on to form the basis of assessment\ndesign for their tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14769v1",
    "published_date": "2024-06-20 22:46:56 UTC",
    "updated_date": "2024-06-20 22:46:56 UTC"
  },
  {
    "arxiv_id": "2406.14765v1",
    "title": "ChatGPT as Research Scientist: Probing GPT's Capabilities as a Research Librarian, Research Ethicist, Data Generator and Data Predictor",
    "authors": [
      "Steven A. Lehr",
      "Aylin Caliskan",
      "Suneragiri Liyanage",
      "Mahzarin R. Banaji"
    ],
    "abstract": "How good a research scientist is ChatGPT? We systematically probed the\ncapabilities of GPT-3.5 and GPT-4 across four central components of the\nscientific process: as a Research Librarian, Research Ethicist, Data Generator,\nand Novel Data Predictor, using psychological science as a testing field. In\nStudy 1 (Research Librarian), unlike human researchers, GPT-3.5 and GPT-4\nhallucinated, authoritatively generating fictional references 36.0% and 5.4% of\nthe time, respectively, although GPT-4 exhibited an evolving capacity to\nacknowledge its fictions. In Study 2 (Research Ethicist), GPT-4 (though not\nGPT-3.5) proved capable of detecting violations like p-hacking in fictional\nresearch protocols, correcting 88.6% of blatantly presented issues, and 72.6%\nof subtly presented issues. In Study 3 (Data Generator), both models\nconsistently replicated patterns of cultural bias previously discovered in\nlarge language corpora, indicating that ChatGPT can simulate known results, an\nantecedent to usefulness for both data generation and skills like hypothesis\ngeneration. Contrastingly, in Study 4 (Novel Data Predictor), neither model was\nsuccessful at predicting new results absent in their training data, and neither\nappeared to leverage substantially new information when predicting more versus\nless novel outcomes. Together, these results suggest that GPT is a flawed but\nrapidly improving librarian, a decent research ethicist already, capable of\ndata generation in simple domains with known characteristics but poor at\npredicting novel patterns of empirical data to aid future experimentation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.IR",
      "cs.LG",
      "I.2.7; K.4.0; K.4.1; K.4.2"
    ],
    "primary_category": "cs.AI",
    "comment": "Main article is 14 pages, 1 table. Includes SI Appendix: 26 pages, 12\n  tables, 2 figures. Total: 40 pages, 13 tables, 2 figures. Under revised\n  review at PNAS",
    "pdf_url": "http://arxiv.org/pdf/2406.14765v1",
    "published_date": "2024-06-20 22:30:06 UTC",
    "updated_date": "2024-06-20 22:30:06 UTC"
  },
  {
    "arxiv_id": "2406.14764v1",
    "title": "RE-AdaptIR: Improving Information Retrieval through Reverse Engineered Adaptation",
    "authors": [
      "William Fleshman",
      "Benjamin Van Durme"
    ],
    "abstract": "Large language models (LLMs) fine-tuned for text-retrieval have demonstrated\nstate-of-the-art results across several information retrieval (IR) benchmarks.\nHowever, supervised training for improving these models requires numerous\nlabeled examples, which are generally unavailable or expensive to acquire. In\nthis work, we explore the effectiveness of extending reverse engineered\nadaptation to the context of information retrieval (RE-AdaptIR). We use\nRE-AdaptIR to improve LLM-based IR models using only unlabeled data. We\ndemonstrate improved performance both in training domains as well as zero-shot\nin domains where the models have seen no queries. We analyze performance\nchanges in various fine-tuning scenarios and offer findings of immediate use to\npractitioners.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14764v1",
    "published_date": "2024-06-20 22:28:11 UTC",
    "updated_date": "2024-06-20 22:28:11 UTC"
  },
  {
    "arxiv_id": "2406.14763v1",
    "title": "A Learn-Then-Reason Model Towards Generalization in Knowledge Base Question Answering",
    "authors": [
      "Lingxi Zhang",
      "Jing Zhang",
      "Yanling Wang",
      "Cuiping Li",
      "Hong Chen"
    ],
    "abstract": "Large-scale knowledge bases (KBs) like Freebase and Wikidata house millions\nof structured knowledge. Knowledge Base Question Answering (KBQA) provides a\nuser-friendly way to access these valuable KBs via asking natural language\nquestions. In order to improve the generalization capabilities of KBQA models,\nextensive research has embraced a retrieve-then-reason framework to retrieve\nrelevant evidence for logical expression generation. These multi-stage efforts\nprioritize acquiring external sources but overlook the incorporation of new\nknowledge into their model parameters. In effect, even advanced language models\nand retrievers have knowledge boundaries, thereby limiting the generalization\ncapabilities of previous KBQA models. Therefore, this paper develops KBLLaMA,\nwhich follows a learn-then-reason framework to inject new KB knowledge into a\nlarge language model for flexible end-to-end KBQA. At the core of KBLLaMA, we\nstudy (1) how to organize new knowledge about KBQA and (2) how to facilitate\nthe learning of the organized knowledge. Extensive experiments on various KBQA\ngeneralization tasks showcase the state-of-the-art performance of KBLLaMA.\nEspecially on the general benchmark GrailQA and domain-specific benchmark\nBio-chemical, KBLLaMA respectively derives a performance gain of up to 3.8% and\n9.8% compared to the baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14763v1",
    "published_date": "2024-06-20 22:22:41 UTC",
    "updated_date": "2024-06-20 22:22:41 UTC"
  },
  {
    "arxiv_id": "2406.14761v1",
    "title": "Diffusion-Based Failure Sampling for Cyber-Physical Systems",
    "authors": [
      "Harrison Delecki",
      "Marc R. Schlichting",
      "Mansur Arief",
      "Anthony Corso",
      "Marcell Vazquez-Chanlatte",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "Validating safety-critical autonomous systems in high-dimensional domains\nsuch as robotics presents a significant challenge. Existing black-box\napproaches based on Markov chain Monte Carlo may require an enormous number of\nsamples, while methods based on importance sampling often rely on simple\nparametric families that may struggle to represent the distribution over\nfailures. We propose to sample the distribution over failures using a\nconditional denoising diffusion model, which has shown success in complex\nhigh-dimensional problems such as robotic task planning. We iteratively train a\ndiffusion model to produce state trajectories closer to failure. We demonstrate\nthe effectiveness of our approach on high-dimensional robotic validation tasks,\nimproving sample efficiency and mode coverage compared to existing black-box\ntechniques.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review at RA-L",
    "pdf_url": "http://arxiv.org/pdf/2406.14761v1",
    "published_date": "2024-06-20 22:22:28 UTC",
    "updated_date": "2024-06-20 22:22:28 UTC"
  },
  {
    "arxiv_id": "2406.14760v2",
    "title": "An LLM Feature-based Framework for Dialogue Constructiveness Assessment",
    "authors": [
      "Lexin Zhou",
      "Youmna Farag",
      "Andreas Vlachos"
    ],
    "abstract": "Research on dialogue constructiveness assessment focuses on (i) analysing\nconversational factors that influence individuals to take specific actions, win\ndebates, change their perspectives or broaden their open-mindedness and (ii)\npredicting constructiveness outcomes following dialogues for such use cases.\nThese objectives can be achieved by training either interpretable feature-based\nmodels (which often involve costly human annotations) or neural models such as\npre-trained language models (which have empirically shown higher task accuracy\nbut lack interpretability). In this paper we propose an LLM feature-based\nframework for dialogue constructiveness assessment that combines the strengths\nof feature-based and neural approaches, while mitigating their downsides. The\nframework first defines a set of dataset-independent and interpretable\nlinguistic features, which can be extracted by both prompting an LLM and simple\nheuristics. Such features are then used to train LLM feature-based models. We\napply this framework to three datasets of dialogue constructiveness and find\nthat our LLM feature-based models outperform or performs at least as well as\nstandard feature-based models and neural models. We also find that the LLM\nfeature-based model learns more robust prediction rules instead of relying on\nsuperficial shortcuts, which often trouble neural models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.14760v2",
    "published_date": "2024-06-20 22:10:52 UTC",
    "updated_date": "2024-10-02 11:03:16 UTC"
  },
  {
    "arxiv_id": "2406.14758v2",
    "title": "Compliance Cards: Automated EU AI Act Compliance Analyses amidst a Complex AI Supply Chain",
    "authors": [
      "Bill Marino",
      "Yaqub Chaudhary",
      "Yulu Pi",
      "Rui-Jie Yew",
      "Preslav Aleksandrov",
      "Carwyn Rahman",
      "William F. Shen",
      "Isaac Robinson",
      "Nicholas D. Lane"
    ],
    "abstract": "As the AI supply chain grows more complex, AI systems and models are\nincreasingly likely to incorporate multiple internally- or externally-sourced\ncomponents such as datasets and (pre-trained) models. In such cases,\ndetermining whether or not the aggregate AI system or model complies with the\nEU AI Act (AIA) requires a multi-step process in which compliance-related\ninformation about both the AI system or model and all its component parts is:\n(1) gathered, potentially from multiple arms-length sources; (2) harmonized, if\nnecessary; (3) inputted into an analysis that looks across all of it to render\na compliance prediction. Because this process is so complex and time-consuming,\nit threatens to overburden the limited compliance resources of the AI providers\n(i.e., developers) who bear much of the responsibility for complying with the\nAIA. It also renders rapid or real-time compliance analyses infeasible in many\nAI development scenarios where they would be beneficial to providers. To\naddress these shortcomings, we introduce a complete system for automating\nprovider-side AIA compliance analyses amidst a complex AI supply chain. This\nsystem has two key elements. First is an interlocking set of computational,\nmulti-stakeholder transparency artifacts that capture AIA-specific metadata\nabout both: (1) the provider's overall AI system or model; and (2) the datasets\nand pre-trained models it incorporates as components. Second is an algorithm\nthat operates across all those artifacts to render a real-time prediction about\nwhether or not the aggregate AI system or model complies with the AIA. All\ntold, this system promises to dramatically facilitate and democratize\nprovider-side AIA compliance analyses (and, perhaps by extension, provider-side\nAIA compliance).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14758v2",
    "published_date": "2024-06-20 22:07:15 UTC",
    "updated_date": "2024-09-12 20:19:38 UTC"
  },
  {
    "arxiv_id": "2406.14757v1",
    "title": "A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes",
    "authors": [
      "Syed I. Munzir",
      "Daniel B. Hier",
      "Chelsea Oommen",
      "Michael D. Carrithers"
    ],
    "abstract": "High-throughput phenotyping, the automated mapping of patient signs and\nsymptoms to standardized ontology concepts, is essential to gaining value from\nelectronic health records (EHR) in the support of precision medicine. Despite\ntechnological advances, high-throughput phenotyping remains a challenge. This\nstudy compares three computational approaches to high-throughput phenotyping: a\nLarge Language Model (LLM) incorporating generative AI, a Natural Language\nProcessing (NLP) approach utilizing deep learning for span categorization, and\na hybrid approach combining word vectors with machine learning. The approach\nthat implemented GPT-4 (a Large Language Model) demonstrated superior\nperformance, suggesting that Large Language Models are poised to be the\npreferred method for high-throughput phenotyping of physician notes.",
    "categories": [
      "cs.AI",
      "92-05",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to AMIA Annual Symposium 2024, San Francisco CA",
    "pdf_url": "http://arxiv.org/pdf/2406.14757v1",
    "published_date": "2024-06-20 22:05:34 UTC",
    "updated_date": "2024-06-20 22:05:34 UTC"
  },
  {
    "arxiv_id": "2406.14756v1",
    "title": "SciDMT: A Large-Scale Corpus for Detecting Scientific Mentions",
    "authors": [
      "Huitong Pan",
      "Qi Zhang",
      "Cornelia Caragea",
      "Eduard Dragut",
      "Longin Jan Latecki"
    ],
    "abstract": "We present SciDMT, an enhanced and expanded corpus for scientific mention\ndetection, offering a significant advancement over existing related resources.\nSciDMT contains annotated scientific documents for datasets (D), methods (M),\nand tasks (T). The corpus consists of two components: 1) the SciDMT main\ncorpus, which includes 48 thousand scientific articles with over 1.8 million\nweakly annotated mention annotations in the format of in-text span, and 2) an\nevaluation set, which comprises 100 scientific articles manually annotated for\nevaluation purposes. To the best of our knowledge, SciDMT is the largest corpus\nfor scientific entity mention detection. The corpus's scale and diversity are\ninstrumental in developing and refining models for tasks such as indexing\nscientific papers, enhancing information retrieval, and improving the\naccessibility of scientific knowledge. We demonstrate the corpus's utility\nthrough experiments with advanced deep learning architectures like SciBERT and\nGPT-3.5. Our findings establish performance baselines and highlight unresolved\nchallenges in scientific mention detection. SciDMT serves as a robust benchmark\nfor the research community, encouraging the development of innovative models to\nfurther the field of scientific information extraction.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "LREC/COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.14756v1",
    "published_date": "2024-06-20 22:03:21 UTC",
    "updated_date": "2024-06-20 22:03:21 UTC"
  },
  {
    "arxiv_id": "2406.14747v1",
    "title": "An Adapter-Based Unified Model for Multiple Spoken Language Processing Tasks",
    "authors": [
      "Varsha Suresh",
      "Salah Aït-Mokhtar",
      "Caroline Brun",
      "Ioan Calapodescu"
    ],
    "abstract": "Self-supervised learning models have revolutionized the field of speech\nprocessing. However, the process of fine-tuning these models on downstream\ntasks requires substantial computational resources, particularly when dealing\nwith multiple speech-processing tasks. In this paper, we explore the potential\nof adapter-based fine-tuning in developing a unified model capable of\neffectively handling multiple spoken language processing tasks. The tasks we\ninvestigate are Automatic Speech Recognition, Phoneme Recognition, Intent\nClassification, Slot Filling, and Spoken Emotion Recognition. We validate our\napproach through a series of experiments on the SUPERB benchmark, and our\nresults indicate that adapter-based fine-tuning enables a single\nencoder-decoder model to perform multiple speech processing tasks with an\naverage improvement of 18.4% across the five target tasks while staying\nefficient in terms of parameter updates.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.14747v1",
    "published_date": "2024-06-20 21:39:04 UTC",
    "updated_date": "2024-06-20 21:39:04 UTC"
  },
  {
    "arxiv_id": "2406.14745v2",
    "title": "Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks",
    "authors": [
      "Sefika Efeoglu",
      "Adrian Paschke"
    ],
    "abstract": "Information Extraction (IE) is crucial for converting unstructured data into\nstructured formats like Knowledge Graphs (KGs). A key task within IE is\nRelation Extraction (RE), which identifies relationships between entities in\ntext. Various RE methods exist, including supervised, unsupervised, weakly\nsupervised, and rule-based approaches. Recent studies leveraging pre-trained\nlanguage models (PLMs) have shown significant success in this area. In the\ncurrent era dominated by Large Language Models (LLMs), fine-tuning these models\ncan overcome limitations associated with zero-shot LLM prompting-based RE\nmethods, especially regarding domain adaptation challenges and identifying\nimplicit relations between entities in sentences. These implicit relations,\nwhich cannot be easily extracted from a sentence's dependency tree, require\nlogical inference for accurate identification. This work explores the\nperformance of fine-tuned LLMs and their integration into the Retrieval\nAugmented-based (RAG) RE approach to address the challenges of identifying\nimplicit relations at the sentence level, particularly when LLMs act as\ngenerators within the RAG framework. Empirical evaluations on the TACRED,\nTACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant\nperformance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,\nand T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,\nwhere implicit relations are common, surpassing previous results on this\ndataset. Additionally, our method outperforms previous works on TACRED, TACREV,\nand Re-TACRED, demonstrating exceptional performance across diverse evaluation\nscenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2406.14745v2",
    "published_date": "2024-06-20 21:27:57 UTC",
    "updated_date": "2024-06-24 06:57:05 UTC"
  },
  {
    "arxiv_id": "2406.14744v1",
    "title": "Training Next Generation AI Users and Developers at NCSA",
    "authors": [
      "Daniel S. Katz",
      "Volodymyr Kindratenko",
      "Olena Kindratenko",
      "Priyam Mazumdar"
    ],
    "abstract": "This article focuses on training work carried out in artificial intelligence\n(AI) at the National Center for Supercomputing Applications (NCSA) at the\nUniversity of Illinois Urbana-Champaign via a research experience for\nundergraduates (REU) program named FoDOMMaT. It also describes why we are\ninterested in AI, and concludes by discussing what we've learned from running\nthis program and its predecessor over six years.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14744v1",
    "published_date": "2024-06-20 21:27:24 UTC",
    "updated_date": "2024-06-20 21:27:24 UTC"
  },
  {
    "arxiv_id": "2406.14735v1",
    "title": "An updated overview of radiomics-based artificial intelligence (AI) methods in breast cancer screening and diagnosis",
    "authors": [
      "Reza Elahi",
      "Mahdis Nazari"
    ],
    "abstract": "Current imaging methods for diagnosing BC are associated with limited\nsensitivity and specificity and modest positive predictive power. The recent\nprogress in image analysis using artificial intelligence (AI) has created great\npromise to improve breast cancer (BC) diagnosis and subtype differentiation. In\nthis case, novel quantitative computational methods, such as radiomics, have\nbeen developed to improve the sensitivity and specificity of early BC diagnosis\nand classification. The potential of radiomics in improving the diagnostic\nefficacy of imaging studies has been shown in several studies. In this review\narticle, we discuss the radiomics workflow and current hand-crafted radiomics\nmethods in the diagnosis and classification of BC based on most recent studies\non different imaging modalities, e.g. MRI, mammography, contrast-enhanced\nspectral mammography (CESM), ultrasound imaging, and digital breast\ntumosynthesis (DBT). We also discuss current challenges and potential\nstrategies to improve the specificity and sensitivity of radiomics in breast\ncancer to help achieve a higher level of BC classification and diagnosis in the\nclinical setting. The growing field of AI incorporation with imaging\ninformation has opened a great opportunity to provide a higher level of care\nfor BC patients.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14735v1",
    "published_date": "2024-06-20 21:01:11 UTC",
    "updated_date": "2024-06-20 21:01:11 UTC"
  },
  {
    "arxiv_id": "2406.14722v3",
    "title": "Does GPT Really Get It? A Hierarchical Scale to Quantify Human vs AI's Understanding of Algorithms",
    "authors": [
      "Mirabel Reid",
      "Santosh S. Vempala"
    ],
    "abstract": "As Large Language Models (LLMs) perform (and sometimes excel at) more and\nmore complex cognitive tasks, a natural question is whether AI really\nunderstands. The study of understanding in LLMs is in its infancy, and the\ncommunity has yet to incorporate well-trodden research in philosophy,\npsychology, and education. We initiate this, specifically focusing on\nunderstanding algorithms, and propose a hierarchy of levels of understanding.\nWe use the hierarchy to design and conduct a study with human subjects\n(undergraduate and graduate students) as well as large language models\n(generations of GPT), revealing interesting similarities and differences. We\nexpect that our rigorous criteria will be useful to keep track of AI's progress\nin such cognitive domains.",
    "categories": [
      "cs.AI",
      "I.2.m; F.1.1"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 10 figures. To be published at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.14722v3",
    "published_date": "2024-06-20 20:37:55 UTC",
    "updated_date": "2025-01-18 21:09:41 UTC"
  },
  {
    "arxiv_id": "2406.14712v1",
    "title": "Qiskit HumanEval: An Evaluation Benchmark For Quantum Code Generative Models",
    "authors": [
      "Sanjay Vishwakarma",
      "Francis Harkins",
      "Siddharth Golecha",
      "Vishal Sharathchandra Bajpe",
      "Nicolas Dupuis",
      "Luca Buratti",
      "David Kremer",
      "Ismael Faro",
      "Ruchir Puri",
      "Juan Cruz-Benito"
    ],
    "abstract": "Quantum programs are typically developed using quantum Software Development\nKits (SDKs). The rapid advancement of quantum computing necessitates new tools\nto streamline this development process, and one such tool could be Generative\nArtificial intelligence (GenAI). In this study, we introduce and use the Qiskit\nHumanEval dataset, a hand-curated collection of tasks designed to benchmark the\nability of Large Language Models (LLMs) to produce quantum code using Qiskit -\na quantum SDK. This dataset consists of more than 100 quantum computing tasks,\neach accompanied by a prompt, a canonical solution, a comprehensive test case,\nand a difficulty scale to evaluate the correctness of the generated solutions.\nWe systematically assess the performance of a set of LLMs against the Qiskit\nHumanEval dataset's tasks and focus on the models ability in producing\nexecutable quantum code. Our findings not only demonstrate the feasibility of\nusing LLMs for generating quantum code but also establish a new benchmark for\nongoing advancements in the field and encourage further exploration and\ndevelopment of GenAI-driven tools for quantum code generation.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14712v1",
    "published_date": "2024-06-20 20:14:22 UTC",
    "updated_date": "2024-06-20 20:14:22 UTC"
  },
  {
    "arxiv_id": "2406.14711v2",
    "title": "MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate",
    "authors": [
      "Alfonso Amayuelas",
      "Xianjun Yang",
      "Antonis Antoniades",
      "Wenyue Hua",
      "Liangming Pan",
      "William Wang"
    ],
    "abstract": "Large Language Models (LLMs) have shown exceptional results on current\nbenchmarks when working individually. The advancement in their capabilities,\nalong with a reduction in parameter size and inference times, has facilitated\nthe use of these models as agents, enabling interactions among multiple models\nto execute complex tasks. Such collaborations offer several advantages,\nincluding the use of specialized models (e.g. coding), improved confidence\nthrough multiple computations, and enhanced divergent thinking, leading to more\ndiverse outputs. Thus, the collaborative use of language models is expected to\ngrow significantly in the coming years. In this work, we evaluate the behavior\nof a network of models collaborating through debate under the influence of an\nadversary. We introduce pertinent metrics to assess the adversary's\neffectiveness, focusing on system accuracy and model agreement. Our findings\nhighlight the importance of a model's persuasive ability in influencing others.\nAdditionally, we explore inference-time methods to generate more compelling\narguments and evaluate the potential of prompt-based mitigation as a defensive\nstrategy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14711v2",
    "published_date": "2024-06-20 20:09:37 UTC",
    "updated_date": "2024-06-26 16:05:20 UTC"
  },
  {
    "arxiv_id": "2406.14703v3",
    "title": "Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics",
    "authors": [
      "Seungbeen Lee",
      "Seungwon Lim",
      "Seungju Han",
      "Giyeong Oh",
      "Hyungjoo Chae",
      "Jiwan Chung",
      "Minju Kim",
      "Beong-woo Kwak",
      "Yeonsoo Lee",
      "Dongha Lee",
      "Jinyoung Yeo",
      "Youngjae Yu"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to their\nadaptation in various domains as conversational agents. We wonder: can\npersonality tests be applied to these agents to analyze their behavior, similar\nto humans? We introduce TRAIT, a new benchmark consisting of 8K multi-choice\nquestions designed to assess the personality of LLMs. TRAIT is built on two\npsychometrically validated small human questionnaires, Big Five Inventory (BFI)\nand Short Dark Triad (SD-3), enhanced with the ATOMIC-10X knowledge graph to a\nvariety of real-world scenarios. TRAIT also outperforms existing personality\ntests for LLMs in terms of reliability and validity, achieving the highest\nscores across four key metrics: Content Validity, Internal Validity, Refusal\nRate, and Reliability. Using TRAIT, we reveal two notable insights into\npersonalities of LLMs: 1) LLMs exhibit distinct and consistent personality,\nwhich is highly influenced by their training data (e.g., data used for\nalignment tuning), and 2) current prompting techniques have limited\neffectiveness in eliciting certain traits, such as high psychopathy or low\nconscientiousness, suggesting the need for further research in this direction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.14703v3",
    "published_date": "2024-06-20 19:50:56 UTC",
    "updated_date": "2025-03-19 15:37:42 UTC"
  },
  {
    "arxiv_id": "2406.14701v1",
    "title": "Speech Prefix-Tuning with RNNT Loss for Improving LLM Predictions",
    "authors": [
      "Murali Karthick Baskar",
      "Andrew Rosenberg",
      "Bhuvana Ramabhadran",
      "Neeraj Gaur",
      "Zhong Meng"
    ],
    "abstract": "In this paper, we focus on addressing the constraints faced when applying\nLLMs to ASR. Recent works utilize prefixLM-type models, which directly apply\nspeech as a prefix to LLMs for ASR. We have found that optimizing speech\nprefixes leads to better ASR performance and propose applying RNNT loss to\nperform speech prefix-tuning. This is a simple approach and does not increase\nthe model complexity or alter the inference pipeline. We also propose\nlanguage-based soft prompting to further improve with frozen LLMs. Empirical\nanalysis on realtime testset from 10 Indic languages demonstrate that our\nproposed speech prefix-tuning yields improvements with both frozen and\nfine-tuned LLMs. Our recognition results on an average of 10 Indics show that\nthe proposed prefix-tuning with RNNT loss results in a 12\\% relative\nimprovement in WER over the baseline with a fine-tuned LLM. Our proposed\napproches with the frozen LLM leads to a 31\\% relative improvement over basic\nsoft-prompting prefixLM.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14701v1",
    "published_date": "2024-06-20 19:50:49 UTC",
    "updated_date": "2024-06-20 19:50:49 UTC"
  },
  {
    "arxiv_id": "2406.14696v1",
    "title": "Physically Analyzable AI-Based Nonlinear Platoon Dynamics Modeling During Traffic Oscillation: A Koopman Approach",
    "authors": [
      "Kexin Tian",
      "Haotian Shi",
      "Yang Zhou",
      "Sixu Li"
    ],
    "abstract": "Given the complexity and nonlinearity inherent in traffic dynamics within\nvehicular platoons, there exists a critical need for a modeling methodology\nwith high accuracy while concurrently achieving physical analyzability.\nCurrently, there are two predominant approaches: the physics model-based\napproach and the Artificial Intelligence (AI)--based approach. Knowing the\nfacts that the physical-based model usually lacks sufficient modeling accuracy\nand potential function mismatches and the pure-AI-based method lacks\nanalyzability, this paper innovatively proposes an AI-based Koopman approach to\nmodel the unknown nonlinear platoon dynamics harnessing the power of AI and\nsimultaneously maintain physical analyzability, with a particular focus on\nperiods of traffic oscillation. Specifically, this research first employs a\ndeep learning framework to generate the embedding function that lifts the\noriginal space into the embedding space. Given the embedding space\ndescriptiveness, the platoon dynamics can be expressed as a linear dynamical\nsystem founded by the Koopman theory. Based on that, the routine of linear\ndynamical system analysis can be conducted on the learned traffic linear\ndynamics in the embedding space. By that, the physical interpretability and\nanalyzability of model-based methods with the heightened precision inherent in\ndata-driven approaches can be synergized. Comparative experiments have been\nconducted with existing modeling approaches, which suggests our method's\nsuperiority in accuracy. Additionally, a phase plane analysis is performed,\nfurther evidencing our approach's effectiveness in replicating the complex\ndynamic patterns. Moreover, the proposed methodology is proven to feature the\ncapability of analyzing the stability, attesting to the physical analyzability.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14696v1",
    "published_date": "2024-06-20 19:35:21 UTC",
    "updated_date": "2024-06-20 19:35:21 UTC"
  },
  {
    "arxiv_id": "2406.14695v1",
    "title": "Depth $F_1$: Improving Evaluation of Cross-Domain Text Classification by Measuring Semantic Generalizability",
    "authors": [
      "Parker Seegmiller",
      "Joseph Gatto",
      "Sarah Masud Preum"
    ],
    "abstract": "Recent evaluations of cross-domain text classification models aim to measure\nthe ability of a model to obtain domain-invariant performance in a target\ndomain given labeled samples in a source domain. The primary strategy for this\nevaluation relies on assumed differences between source domain samples and\ntarget domain samples in benchmark datasets. This evaluation strategy fails to\naccount for the similarity between source and target domains, and may mask when\nmodels fail to transfer learning to specific target samples which are highly\ndissimilar from the source domain. We introduce Depth $F_1$, a novel\ncross-domain text classification performance metric. Designed to be\ncomplementary to existing classification metrics such as $F_1$, Depth $F_1$\nmeasures how well a model performs on target samples which are dissimilar from\nthe source domain. We motivate this metric using standard cross-domain text\nclassification datasets and benchmark several recent cross-domain text\nclassification models, with the goal of enabling in-depth evaluation of the\nsemantic generalizability of cross-domain text classification models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14695v1",
    "published_date": "2024-06-20 19:35:17 UTC",
    "updated_date": "2024-06-20 19:35:17 UTC"
  },
  {
    "arxiv_id": "2406.14675v1",
    "title": "This Looks Better than That: Better Interpretable Models with ProtoPNeXt",
    "authors": [
      "Frank Willard",
      "Luke Moffett",
      "Emmanuel Mokel",
      "Jon Donnelly",
      "Stark Guo",
      "Julia Yang",
      "Giyoung Kim",
      "Alina Jade Barnett",
      "Cynthia Rudin"
    ],
    "abstract": "Prototypical-part models are a popular interpretable alternative to black-box\ndeep learning models for computer vision. However, they are difficult to train,\nwith high sensitivity to hyperparameter tuning, inhibiting their application to\nnew datasets and our understanding of which methods truly improve their\nperformance. To facilitate the careful study of prototypical-part networks\n(ProtoPNets), we create a new framework for integrating components of\nprototypical-part models -- ProtoPNeXt. Using ProtoPNeXt, we show that applying\nBayesian hyperparameter tuning and an angular prototype similarity metric to\nthe original ProtoPNet is sufficient to produce new state-of-the-art accuracy\nfor prototypical-part models on CUB-200 across multiple backbones. We further\ndeploy this framework to jointly optimize for accuracy and prototype\ninterpretability as measured by metrics included in ProtoPNeXt. Using the same\nresources, this produces models with substantially superior semantics and\nchanges in accuracy between +1.3% and -1.5%. The code and trained models will\nbe made publicly available upon publication.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14675v1",
    "published_date": "2024-06-20 18:54:27 UTC",
    "updated_date": "2024-06-20 18:54:27 UTC"
  },
  {
    "arxiv_id": "2406.14670v2",
    "title": "Exploring Design Choices for Building Language-Specific LLMs",
    "authors": [
      "Atula Tejaswi",
      "Nilesh Gupta",
      "Eunsol Choi"
    ],
    "abstract": "Despite rapid progress in large language models (LLMs), their performance on\na vast majority of languages remains unsatisfactory. In this paper, we study\nbuilding language-specific LLMs by adapting monolingual and multilingual LLMs.\nWe conduct systematic experiments on how design choices (base model selection,\nvocabulary extension, and continued pretraining) impact the adapted LLM, both\nin terms of efficiency (how many tokens are needed to encode the same amount of\ninformation) and end task performance. We find that (1) the initial performance\nof LLM does not always correlate with the final performance after the\nadaptation. Adapting an English-centric models can yield better results than\nadapting multilingual models despite their worse initial performance on\nlow-resource languages. (2) Efficiency can easily improved with simple\nvocabulary extension and continued pretraining in most LLMs we study, and (3)\nThe optimal adaptation method (choice of the base model, new vocabulary size,\ntraining data, initialization strategy) is highly language-dependent, and the\nsimplest embedding initialization works well across various experimental\nsettings. Together, our work lays foundations on efficiently building\nlanguage-specific LLMs by adapting existing LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.14670v2",
    "published_date": "2024-06-20 18:47:43 UTC",
    "updated_date": "2024-10-30 16:33:48 UTC"
  },
  {
    "arxiv_id": "2406.15513v2",
    "title": "PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference",
    "authors": [
      "Jiaming Ji",
      "Donghai Hong",
      "Borong Zhang",
      "Boyuan Chen",
      "Josef Dai",
      "Boren Zheng",
      "Tianyi Qiu",
      "Boxun Li",
      "Yaodong Yang"
    ],
    "abstract": "In this work, we introduce the PKU-SafeRLHF dataset, designed to promote\nresearch on safety alignment in large language models (LLMs). As a sibling\nproject to SafeRLHF and BeaverTails, we separate annotations of helpfulness and\nharmlessness for question-answering pairs, providing distinct perspectives on\nthese coupled attributes. Overall, we provide 44.6k refined prompts and 265k\nquestion-answer pairs with safety meta-labels for 19 harm categories and three\nseverity levels ranging from minor to severe, with answers generated by\nLlama-family models. Based on this, we collected 166.8k preference data,\nincluding dual-preference (helpfulness and harmlessness decoupled) and\nsingle-preference data (trade-off the helpfulness and harmlessness from\nscratch), respectively. Using the large-scale annotation data, we further train\nseverity-sensitive moderation for the risk control of LLMs and safety-centric\nRLHF algorithms for the safety alignment of LLMs. We believe this dataset will\nbe a valuable resource for the community, aiding in the safe deployment of\nLLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "a sibling project to SafeRLHF and BeaverTails",
    "pdf_url": "http://arxiv.org/pdf/2406.15513v2",
    "published_date": "2024-06-20 18:37:36 UTC",
    "updated_date": "2024-10-16 01:33:35 UTC"
  },
  {
    "arxiv_id": "2406.14657v3",
    "title": "OpenDebateEvidence: A Massive-Scale Argument Mining and Summarization Dataset",
    "authors": [
      "Allen Roush",
      "Yusuf Shabazz",
      "Arvind Balaji",
      "Peter Zhang",
      "Stefano Mezza",
      "Markus Zhang",
      "Sanjay Basu",
      "Sriram Vishwanath",
      "Mehdi Fatemi",
      "Ravid Shwartz-Ziv"
    ],
    "abstract": "We introduce OpenDebateEvidence, a comprehensive dataset for argument mining\nand summarization sourced from the American Competitive Debate community. This\ndataset includes over 3.5 million documents with rich metadata, making it one\nof the most extensive collections of debate evidence. OpenDebateEvidence\ncaptures the complexity of arguments in high school and college debates,\nproviding valuable resources for training and evaluation. Our extensive\nexperiments demonstrate the efficacy of fine-tuning state-of-the-art large\nlanguage models for argumentative abstractive summarization across various\nmethods, models, and datasets. By providing this comprehensive resource, we aim\nto advance computational argumentation and support practical applications for\ndebaters, educators, and researchers. OpenDebateEvidence is publicly available\nto support further research and innovation in computational argumentation.\nAccess it here: https://huggingface.co/datasets/Yusuf5/OpenCaselist",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published to the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024) Track on Datasets and Benchmarks",
    "pdf_url": "http://arxiv.org/pdf/2406.14657v3",
    "published_date": "2024-06-20 18:22:59 UTC",
    "updated_date": "2024-10-31 03:41:03 UTC"
  },
  {
    "arxiv_id": "2406.14655v1",
    "title": "HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation",
    "authors": [
      "Jin Wang",
      "Rui Dai",
      "Weijie Wang",
      "Luca Rossini",
      "Francesco Ruscelli",
      "Nikos Tsagarakis"
    ],
    "abstract": "Enabling robots to autonomously perform hybrid motions in diverse\nenvironments can be beneficial for long-horizon tasks such as material\nhandling, household chores, and work assistance. This requires extensive\nexploitation of intrinsic motion capabilities, extraction of affordances from\nrich environmental information, and planning of physical interaction behaviors.\nDespite recent progress has demonstrated impressive humanoid whole-body control\nabilities, they struggle to achieve versatility and adaptability for new tasks.\nIn this work, we propose HYPERmotion, a framework that learns, selects and\nplans behaviors based on tasks in different scenarios. We combine reinforcement\nlearning with whole-body optimization to generate motion for 38 actuated joints\nand create a motion library to store the learned skills. We apply the planning\nand reasoning features of the large language models (LLMs) to complex\nloco-manipulation tasks, constructing a hierarchical task graph that comprises\na series of primitive behaviors to bridge lower-level execution with\nhigher-level planning. By leveraging the interaction of distilled spatial\ngeometry and 2D observation with a visual language model (VLM) to ground\nknowledge into a robotic morphology selector to choose appropriate actions in\nsingle- or dual-arm, legged or wheeled locomotion. Experiments in simulation\nand real-world show that learned motions can efficiently adapt to new tasks,\ndemonstrating high autonomy from free-text commands in unstructured scenes.\nVideos and website: hy-motion.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page: https://hy-motion.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.14655v1",
    "published_date": "2024-06-20 18:21:24 UTC",
    "updated_date": "2024-06-20 18:21:24 UTC"
  },
  {
    "arxiv_id": "2406.14654v2",
    "title": "Major Entity Identification: A Generalizable Alternative to Coreference Resolution",
    "authors": [
      "Kawshik Manikantan",
      "Shubham Toshniwal",
      "Makarand Tapaswi",
      "Vineet Gandhi"
    ],
    "abstract": "The limited generalization of coreference resolution (CR) models has been a\nmajor bottleneck in the task's broad application. Prior work has identified\nannotation differences, especially for mention detection, as one of the main\nreasons for the generalization gap and proposed using additional annotated\ntarget domain data. Rather than relying on this additional annotation, we\npropose an alternative referential task, Major Entity Identification (MEI),\nwhere we: (a) assume the target entities to be specified in the input, and (b)\nlimit the task to only the frequent entities. Through extensive experiments, we\ndemonstrate that MEI models generalize well across domains on multiple datasets\nwith supervised models and LLM-based few-shot prompting. Additionally, MEI fits\nthe classification framework, which enables the use of robust and intuitive\nclassification-based metrics. Finally, MEI is also of practical use as it\nallows a user to search for all mentions of a particular entity or a group of\nentities of interest.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14654v2",
    "published_date": "2024-06-20 18:17:58 UTC",
    "updated_date": "2024-10-04 11:08:06 UTC"
  },
  {
    "arxiv_id": "2406.14653v1",
    "title": "LLM Granularity for On-the-Fly Robot Control",
    "authors": [
      "Peng Wang",
      "Mattia Robbiani",
      "Zhihao Guo"
    ],
    "abstract": "Assistive robots have attracted significant attention due to their potential\nto enhance the quality of life for vulnerable individuals like the elderly. The\nconvergence of computer vision, large language models, and robotics has\nintroduced the `visuolinguomotor' mode for assistive robots, where visuals and\nlinguistics are incorporated into assistive robots to enable proactive and\ninteractive assistance. This raises the question: \\textit{In circumstances\nwhere visuals become unreliable or unavailable, can we rely solely on language\nto control robots, i.e., the viability of the `linguomotor` mode for assistive\nrobots?} This work takes the initial steps to answer this question by: 1)\nevaluating the responses of assistive robots to language prompts of varying\ngranularities; and 2) exploring the necessity and feasibility of controlling\nthe robot on-the-fly. We have designed and conducted experiments on a Sawyer\ncobot to support our arguments. A Turtlebot robot case is designed to\ndemonstrate the adaptation of the solution to scenarios where assistive robots\nneed to maneuver to assist. Codes will be released on GitHub soon to benefit\nthe community.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14653v1",
    "published_date": "2024-06-20 18:17:48 UTC",
    "updated_date": "2024-06-20 18:17:48 UTC"
  },
  {
    "arxiv_id": "2406.14643v3",
    "title": "Holistic Evaluation for Interleaved Text-and-Image Generation",
    "authors": [
      "Minqian Liu",
      "Zhiyang Xu",
      "Zihao Lin",
      "Trevor Ashby",
      "Joy Rimchala",
      "Jiaxin Zhang",
      "Lifu Huang"
    ],
    "abstract": "Interleaved text-and-image generation has been an intriguing research\ndirection, where the models are required to generate both images and text\npieces in an arbitrary order. Despite the emerging advancements in interleaved\ngeneration, the progress in its evaluation still significantly lags behind.\nExisting evaluation benchmarks do not support arbitrarily interleaved images\nand text for both inputs and outputs, and they only cover a limited number of\ndomains and use cases. Also, current works predominantly use similarity-based\nmetrics which fall short in assessing the quality in open-ended scenarios. To\nthis end, we introduce InterleavedBench, the first benchmark carefully curated\nfor the evaluation of interleaved text-and-image generation. InterleavedBench\nfeatures a rich array of tasks to cover diverse real-world use cases. In\naddition, we present InterleavedEval, a strong reference-free metric powered by\nGPT-4o to deliver accurate and explainable evaluation. We carefully define five\nessential evaluation aspects for InterleavedEval, including text quality,\nperceptual quality, image coherence, text-image coherence, and helpfulness, to\nensure a comprehensive and fine-grained assessment. Through extensive\nexperiments and rigorous human evaluation, we show that our benchmark and\nmetric can effectively evaluate the existing models with a strong correlation\nwith human judgments surpassing previous reference-based metrics. We also\nprovide substantial findings and insights to foster future research in\ninterleaved generation and its evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024 Main Conference. 15 pages, 6 figures, 7 tables. Website:\n  https://vt-nlp.github.io/InterleavedEval/. Dataset:\n  https://huggingface.co/mqliu/InterleavedBench",
    "pdf_url": "http://arxiv.org/pdf/2406.14643v3",
    "published_date": "2024-06-20 18:07:19 UTC",
    "updated_date": "2024-10-08 16:02:08 UTC"
  },
  {
    "arxiv_id": "2406.14635v1",
    "title": "Harvesting Efficient On-Demand Order Pooling from Skilled Couriers: Enhancing Graph Representation Learning for Refining Real-time Many-to-One Assignments",
    "authors": [
      "Yile Liang",
      "Jiuxia Zhao",
      "Donghui Li",
      "Jie Feng",
      "Chen Zhang",
      "Xuetao Ding",
      "Jinghua Hao",
      "Renqing He"
    ],
    "abstract": "The recent past has witnessed a notable surge in on-demand food delivery\n(OFD) services, offering delivery fulfillment within dozens of minutes after an\norder is placed. In OFD, pooling multiple orders for simultaneous delivery in\nreal-time order assignment is a pivotal efficiency source, which may in turn\nextend delivery time. Constructing high-quality order pooling to harmonize\nplatform efficiency with the experiences of consumers and couriers, is crucial\nto OFD platforms. However, the complexity and real-time nature of order\nassignment, making extensive calculations impractical, significantly limit the\npotential for order consolidation. Moreover, offline environment is frequently\nriddled with unknown factors, posing challenges for the platform's\nperceptibility and pooling decisions. Nevertheless, delivery behaviors of\nskilled couriers (SCs) who know the environment well, can improve system\nawareness and effectively inform decisions. Hence a SC delivery network (SCDN)\nis constructed, based on an enhanced attributed heterogeneous network embedding\napproach tailored for OFD. It aims to extract features from rich temporal and\nspatial information, and uncover the latent potential for order combinations\nembedded within SC trajectories. Accordingly, the vast search space of order\nassignment can be effectively pruned through scalable similarity calculations\nof low-dimensional vectors, making comprehensive and high-quality pooling\noutcomes more easily identified in real time. SCDN has now been deployed in\nMeituan dispatch system. Online tests reveal that with SCDN, the pooling\nquality and extent have been greatly improved. And our system can boost\ncouriers'efficiency by 45-55% during noon peak hours, while upholding the\ntimely delivery commitment.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in KDD 2024 ADS Track",
    "pdf_url": "http://arxiv.org/pdf/2406.14635v1",
    "published_date": "2024-06-20 18:03:27 UTC",
    "updated_date": "2024-06-20 18:03:27 UTC"
  },
  {
    "arxiv_id": "2406.14634v3",
    "title": "Adaptive Manipulation using Behavior Trees",
    "authors": [
      "Jacques Cloete",
      "Wolfgang Merkt",
      "Ioannis Havoutis"
    ],
    "abstract": "Many manipulation tasks pose a challenge since they depend on non-visual\nenvironmental information that can only be determined after sustained physical\ninteraction has already begun. This is particularly relevant for\neffort-sensitive, dynamics-dependent tasks such as tightening a valve. To\nperform these tasks safely and reliably, robots must be able to quickly adapt\nin response to unexpected changes during task execution, and should also learn\nfrom past experience to better inform future decisions. Humans can intuitively\nrespond and adapt their manipulation strategy to suit such problems, but\nrepresenting and implementing such behaviors for robots remains a challenge. In\nthis work we show how this can be achieved within the framework of behavior\ntrees. We present the adaptive behavior tree, a scalable and generalizable\nbehavior tree design that enables a robot to quickly adapt to and learn from\nboth visual and non-visual observations during task execution, preempting task\nfailure or switching to a different manipulation strategy. The adaptive\nbehavior tree selects the manipulation strategy that is predicted to optimize\ntask performance, and learns from past experience to improve these predictions\nfor future attempts. We test our approach on a variety of tasks commonly found\nin industry; the adaptive behavior tree demonstrates safety, robustness (100%\nsuccess rate) and efficiency in task completion (up to 36% task speedup from\nthe baseline).",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 7 figures. This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2406.14634v3",
    "published_date": "2024-06-20 18:01:36 UTC",
    "updated_date": "2025-03-08 16:00:30 UTC"
  },
  {
    "arxiv_id": "2406.14629v3",
    "title": "Can LLMs Learn by Teaching for Better Reasoning? A Preliminary Study",
    "authors": [
      "Xuefei Ning",
      "Zifu Wang",
      "Shiyao Li",
      "Zinan Lin",
      "Peiran Yao",
      "Tianyu Fu",
      "Matthew B. Blaschko",
      "Guohao Dai",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "abstract": "Teaching to improve student models (e.g., knowledge distillation) is an\nextensively studied methodology in LLMs. However, for humans, teaching improves\nnot only students but also teachers, by fostering more rigorous and clear\nreasoning as well as knowledge building. We ask: Can LLMs also learn by\nteaching (LbT) for better reasoning? If the answer is yes, we can potentially\nunlock the possibility of continuously advancing the models without solely\nrelying on human-produced data or stronger models. In this paper, we provide a\npreliminary exploration on this question. We show that LbT ideas can be\nincorporated into existing LLM training/prompting pipelines and bring\nimprovements. Specifically, we design three methods, each mimicking one of the\nthree levels of LbT: observing students' feedback, learning from the feedback,\nand learning iteratively, with the goals of improving answer accuracy without\ntraining or improving models' inherent capability with fine-tuning. We reveal\nsome findings: (1) Teaching materials that make it easier for students to learn\nhave clearer and more accurate logic when using in-context learning as the\nstudent's \"learning\" method; (2) Weak-to-strong generalization: LbT might help\nimprove strong models by teaching weak models; (3) Diversity in students might\nhelp: teaching multiple students could be better than teaching one student or\nthe teacher itself. We hope that our exploration can inspire future research on\nLbT and more broadly adopting the advanced techniques in education to improve\nLLMs. The code and website are at https://github.com/imagination-research/lbt\nand https://sites.google.com/view/llm-learning-by-teaching.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.14629v3",
    "published_date": "2024-06-20 18:00:17 UTC",
    "updated_date": "2024-11-24 02:24:29 UTC"
  },
  {
    "arxiv_id": "2406.14563v1",
    "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch",
    "authors": [
      "Hasan Abed Al Kader Hammoud",
      "Umberto Michieli",
      "Fabio Pizzati",
      "Philip Torr",
      "Adel Bibi",
      "Bernard Ghanem",
      "Mete Ozay"
    ],
    "abstract": "Merging Large Language Models (LLMs) is a cost-effective technique for\ncombining multiple expert LLMs into a single versatile model, retaining the\nexpertise of the original ones. However, current approaches often overlook the\nimportance of safety alignment during merging, leading to highly misaligned\nmodels. This work investigates the effects of model merging on alignment. We\nevaluate several popular model merging techniques, demonstrating that existing\nmethods do not only transfer domain expertise but also propagate misalignment.\nWe propose a simple two-step approach to address this problem: (i) generating\nsynthetic safety and domain-specific data, and (ii) incorporating these\ngenerated data into the optimization process of existing data-aware model\nmerging techniques. This allows us to treat alignment as a skill that can be\nmaximized in the resulting merged LLM. Our experiments illustrate the\neffectiveness of integrating alignment-related data during merging, resulting\nin models that excel in both domain expertise and alignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2406.14563v1",
    "published_date": "2024-06-20 17:59:58 UTC",
    "updated_date": "2024-06-20 17:59:58 UTC"
  },
  {
    "arxiv_id": "2406.14562v1",
    "title": "Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities",
    "authors": [
      "Sachit Menon",
      "Richard Zemel",
      "Carl Vondrick"
    ],
    "abstract": "When presented with questions involving visual thinking, humans naturally\nswitch reasoning modalities, often forming mental images or drawing visual\naids. Large language models have shown promising results in arithmetic and\nsymbolic reasoning by expressing intermediate reasoning in text as a chain of\nthought, yet struggle to extend this capability to answer text queries that are\neasily solved by visual reasoning, even with extensive multimodal pretraining.\nWe introduce a simple method, whiteboard-of-thought prompting, to unlock the\nvisual reasoning capabilities of multimodal large language models across\nmodalities. Whiteboard-of-thought prompting provides multimodal large language\nmodels with a metaphorical `whiteboard' to draw out reasoning steps as images,\nthen returns these images back to the model for further processing. We find\nthis can be accomplished with no demonstrations or specialized modules, instead\nleveraging models' existing ability to write code with libraries such as\nMatplotlib and Turtle. This simple approach shows state-of-the-art results on\nfour difficult natural language tasks that involve visual and spatial\nreasoning. We identify multiple settings where GPT-4o using chain-of-thought\nfails dramatically, including more than one where it achieves $0\\%$ accuracy,\nwhile whiteboard-of-thought enables up to $92\\%$ accuracy in these same\nsettings. We present a detailed exploration of where the technique succeeds as\nwell as its sources of error.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Project website: whiteboard.cs.columbia.edu/",
    "pdf_url": "http://arxiv.org/pdf/2406.14562v1",
    "published_date": "2024-06-20 17:59:45 UTC",
    "updated_date": "2024-06-20 17:59:45 UTC"
  },
  {
    "arxiv_id": "2406.14558v3",
    "title": "CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics",
    "authors": [
      "Jiawei Gao",
      "Ziqin Wang",
      "Zeqi Xiao",
      "Jingbo Wang",
      "Tai Wang",
      "Jinkun Cao",
      "Xiaolin Hu",
      "Si Liu",
      "Jifeng Dai",
      "Jiangmiao Pang"
    ],
    "abstract": "Enabling humanoid robots to clean rooms has long been a pursued dream within\nhumanoid research communities. However, many tasks require multi-humanoid\ncollaboration, such as carrying large and heavy furniture together. Given the\nscarcity of motion capture data on multi-humanoid collaboration and the\nefficiency challenges associated with multi-agent learning, these tasks cannot\nbe straightforwardly addressed using training paradigms designed for\nsingle-agent scenarios. In this paper, we introduce Cooperative Human-Object\nInteraction (CooHOI), a framework designed to tackle the challenge of\nmulti-humanoid object transportation problem through a two-phase learning\nparadigm: individual skill learning and subsequent policy transfer. First, a\nsingle humanoid character learns to interact with objects through imitation\nlearning from human motion priors. Then, the humanoid learns to collaborate\nwith others by considering the shared dynamics of the manipulated object using\ncentralized training and decentralized execution (CTDE) multi-agent RL\nalgorithms. When one agent interacts with the object, resulting in specific\nobject dynamics changes, the other agents learn to respond appropriately,\nthereby achieving implicit communication and coordination between teammates.\nUnlike previous approaches that relied on tracking-based methods for\nmulti-humanoid HOI, CooHOI is inherently efficient, does not depend on motion\ncapture data of multi-humanoid interactions, and can be seamlessly extended to\ninclude more participants and a wide range of object types.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://gao-jiawei.com/Research/CooHOI/. NeurIPS\n  2024 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2406.14558v3",
    "published_date": "2024-06-20 17:59:22 UTC",
    "updated_date": "2024-10-30 02:58:10 UTC"
  },
  {
    "arxiv_id": "2406.14550v2",
    "title": "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models",
    "authors": [
      "Shilong Li",
      "Yancheng He",
      "Hangyu Guo",
      "Xingyuan Bu",
      "Ge Bai",
      "Jie Liu",
      "Jiaheng Liu",
      "Xingwei Qu",
      "Yangguang Li",
      "Wanli Ouyang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Long-context capabilities are essential for large language models (LLMs) to\ntackle complex and long-input tasks. Despite numerous efforts made to optimize\nLLMs for long contexts, challenges persist in robustly processing long inputs.\nIn this paper, we introduce GraphReader, a graph-based agent system designed to\nhandle long texts by structuring them into a graph and employing an agent to\nexplore this graph autonomously. Upon receiving a question, the agent first\nundertakes a step-by-step analysis and devises a rational plan. It then invokes\na set of predefined functions to read node content and neighbors, facilitating\na coarse-to-fine exploration of the graph. Throughout the exploration, the\nagent continuously records new insights and reflects on current circumstances\nto optimize the process until it has gathered sufficient information to\ngenerate an answer. Experimental results on the LV-Eval dataset reveal that\nGraphReader, using a 4k context window, consistently outperforms GPT-4-128k\nacross context lengths from 16k to 256k by a large margin. Additionally, our\napproach demonstrates superior performance on four challenging single-hop and\nmulti-hop benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "[EMNLP 2024] The first four authors contributed equally, 29 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.14550v2",
    "published_date": "2024-06-20 17:57:51 UTC",
    "updated_date": "2024-11-05 16:51:40 UTC"
  },
  {
    "arxiv_id": "2406.14598v2",
    "title": "SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal",
    "authors": [
      "Tinghao Xie",
      "Xiangyu Qi",
      "Yi Zeng",
      "Yangsibo Huang",
      "Udari Madhushani Sehwag",
      "Kaixuan Huang",
      "Luxi He",
      "Boyi Wei",
      "Dacheng Li",
      "Ying Sheng",
      "Ruoxi Jia",
      "Bo Li",
      "Kai Li",
      "Danqi Chen",
      "Peter Henderson",
      "Prateek Mittal"
    ],
    "abstract": "Evaluating aligned large language models' (LLMs) ability to recognize and\nreject unsafe user requests is crucial for safe, policy-compliant deployments.\nExisting evaluation efforts, however, face three limitations that we address\nwith SORRY-Bench, our proposed benchmark. First, existing methods often use\ncoarse-grained taxonomies of unsafe topics, and are over-representing some\nfine-grained topics. For example, among the ten existing datasets that we\nevaluated, tests for refusals of self-harm instructions are over 3x less\nrepresented than tests for fraudulent activities. SORRY-Bench improves on this\nby using a fine-grained taxonomy of 44 potentially unsafe topics, and 440\nclass-balanced unsafe instructions, compiled through human-in-the-loop methods.\nSecond, linguistic characteristics and formatting of prompts are often\noverlooked, like different languages, dialects, and more -- which are only\nimplicitly considered in many evaluations. We supplement SORRY-Bench with 20\ndiverse linguistic augmentations to systematically examine these effects.\nThird, existing evaluations rely on large LLMs (e.g., GPT-4) for evaluation,\nwhich can be computationally expensive. We investigate design choices for\ncreating a fast, accurate automated safety evaluator. By collecting 7K+ human\nannotations and conducting a meta-evaluation of diverse LLM-as-a-judge designs,\nwe show that fine-tuned 7B LLMs can achieve accuracy comparable to GPT-4 scale\nLLMs, with lower computational cost. Putting these together, we evaluate over\n50 proprietary and open-weight LLMs on SORRY-Bench, analyzing their distinctive\nsafety refusal behaviors. We hope our effort provides a building block for\nsystematic evaluations of LLMs' safety refusal capabilities, in a balanced,\ngranular, and efficient manner. Benchmark demo, data, code, and models are\navailable through https://sorry-bench.github.io.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.14598v2",
    "published_date": "2024-06-20 17:56:07 UTC",
    "updated_date": "2025-03-01 21:45:36 UTC"
  },
  {
    "arxiv_id": "2406.14546v3",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "authors": [
      "Johannes Treutlein",
      "Dami Choi",
      "Jan Betley",
      "Samuel Marks",
      "Cem Anil",
      "Roger Grosse",
      "Owain Evans"
    ],
    "abstract": "One way to address safety risks from large language models (LLMs) is to\ncensor dangerous knowledge from their training data. While this removes the\nexplicit information, implicit information can remain scattered across various\ntraining documents. Could an LLM infer the censored knowledge by piecing\ntogether these implicit hints? As a step towards answering this question, we\nstudy inductive out-of-context reasoning (OOCR), a type of generalization in\nwhich LLMs infer latent information from evidence distributed across training\ndocuments and apply it to downstream tasks without in-context learning. Using a\nsuite of five tasks, we demonstrate that frontier LLMs can perform inductive\nOOCR. In one experiment we finetune an LLM on a corpus consisting only of\ndistances between an unknown city and other known cities. Remarkably, without\nin-context examples or Chain of Thought, the LLM can verbalize that the unknown\ncity is Paris and use this fact to answer downstream questions. Further\nexperiments show that LLMs trained only on individual coin flip outcomes can\nverbalize whether the coin is biased, and those trained only on pairs\n$(x,f(x))$ can articulate a definition of $f$ and compute inverses. While OOCR\nsucceeds in a range of cases, we also show that it is unreliable, particularly\nfor smaller LLMs learning complex structures. Overall, the ability of LLMs to\n\"connect the dots\" without explicit in-context learning poses a potential\nobstacle to monitoring and controlling the knowledge acquired by LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeurIPS 2024. 10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14546v3",
    "published_date": "2024-06-20 17:55:04 UTC",
    "updated_date": "2024-12-23 12:01:28 UTC"
  },
  {
    "arxiv_id": "2406.14540v1",
    "title": "IRASim: Learning Interactive Real-Robot Action Simulators",
    "authors": [
      "Fangqi Zhu",
      "Hongtao Wu",
      "Song Guo",
      "Yuxiao Liu",
      "Chilam Cheang",
      "Tao Kong"
    ],
    "abstract": "Scalable robot learning in the real world is limited by the cost and safety\nissues of real robots. In addition, rolling out robot trajectories in the real\nworld can be time-consuming and labor-intensive. In this paper, we propose to\nlearn an interactive real-robot action simulator as an alternative. We\nintroduce a novel method, IRASim, which leverages the power of generative\nmodels to generate extremely realistic videos of a robot arm that executes a\ngiven action trajectory, starting from an initial given frame. To validate the\neffectiveness of our method, we create a new benchmark, IRASim Benchmark, based\non three real-robot datasets and perform extensive experiments on the\nbenchmark. Results show that IRASim outperforms all the baseline methods and is\nmore preferable in human evaluations. We hope that IRASim can serve as an\neffective and scalable approach to enhance robot learning in the real world. To\npromote research for generative real-robot action simulators, we open-source\ncode, benchmark, and checkpoints at https: //gen-irasim.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Opensource, project website: https://gen-irasim.github.io",
    "pdf_url": "http://arxiv.org/pdf/2406.14540v1",
    "published_date": "2024-06-20 17:50:16 UTC",
    "updated_date": "2024-06-20 17:50:16 UTC"
  },
  {
    "arxiv_id": "2406.14596v5",
    "title": "VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought",
    "authors": [
      "Gabriel Sarch",
      "Lawrence Jang",
      "Michael J. Tarr",
      "William W. Cohen",
      "Kenneth Marino",
      "Katerina Fragkiadaki"
    ],
    "abstract": "Large-scale LLMs and VLMs excel at few-shot learning but require high-quality\nexamples. We introduce In-Context Abstraction Learning (ICAL), which\niteratively refines suboptimal trajectories into high-quality data with\noptimized actions and detailed reasoning. Given an inefficient demonstration, a\nVLM corrects actions and annotates causal relationships, object states,\nsubgoals, and task-relevant visuals, forming \"programs of thought.\" With human\nfeedback, these programs are improved as the agent executes them in a similar\nenvironment. The resulting examples, used as prompt context or fine-tuning\ndata, significantly boost decision-making while reducing human feedback needs.\nICAL surpasses state-of-the-art in TEACh (dialogue-based instruction\nfollowing), VisualWebArena (multimodal web agents), and Ego4D (egocentric video\naction anticipation). In TEACh, combining fine-tuning and retrieval on ICAL\nexamples outperforms raw human demonstrations and expert examples, achieving a\n17.5% increase in goal-condition success. In VisualWebArena,\nretrieval-augmented GPT-4V with ICAL improves task success rate 1.6x over\nGPT-4V, while fine-tuning Qwen2-VL achieves a 2.8x improvement. In Ego4D, ICAL\noutperforms few-shot GPT-4V and remains competitive with supervised models.\nOverall, ICAL scales 2x better than raw human demonstrations and reduces manual\nprompt engineering.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://ical-learning.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.14596v5",
    "published_date": "2024-06-20 17:45:02 UTC",
    "updated_date": "2025-01-20 23:33:33 UTC"
  },
  {
    "arxiv_id": "2406.14595v2",
    "title": "Adversaries Can Misuse Combinations of Safe Models",
    "authors": [
      "Erik Jones",
      "Anca Dragan",
      "Jacob Steinhardt"
    ],
    "abstract": "Developers try to evaluate whether an AI system can be misused by adversaries\nbefore releasing it; for example, they might test whether a model enables\ncyberoffense, user manipulation, or bioterrorism. In this work, we show that\nindividually testing models for misuse is inadequate; adversaries can misuse\ncombinations of models even when each individual model is safe. The adversary\naccomplishes this by first decomposing tasks into subtasks, then solving each\nsubtask with the best-suited model. For example, an adversary might solve\nchallenging-but-benign subtasks with an aligned frontier model, and\neasy-but-malicious subtasks with a weaker misaligned model. We study two\ndecomposition methods: manual decomposition where a human identifies a natural\ndecomposition of a task, and automated decomposition where a weak model\ngenerates benign tasks for a frontier model to solve, then uses the solutions\nin-context to solve the original task. Using these decompositions, we\nempirically show that adversaries can create vulnerable code, explicit images,\npython scripts for hacking, and manipulative tweets at much higher rates with\ncombinations of models than either individual model. Our work suggests that\neven perfectly-aligned frontier systems can enable misuse without ever\nproducing malicious outputs, and that red-teaming efforts should extend beyond\nsingle models in isolation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14595v2",
    "published_date": "2024-06-20 17:43:18 UTC",
    "updated_date": "2024-07-01 19:58:00 UTC"
  },
  {
    "arxiv_id": "2406.14529v1",
    "title": "A Benchmarking Study of Kolmogorov-Arnold Networks on Tabular Data",
    "authors": [
      "Eleonora Poeta",
      "Flavio Giobergia",
      "Eliana Pastor",
      "Tania Cerquitelli",
      "Elena Baralis"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) have very recently been introduced into the\nworld of machine learning, quickly capturing the attention of the entire\ncommunity. However, KANs have mostly been tested for approximating complex\nfunctions or processing synthetic data, while a test on real-world tabular\ndatasets is currently lacking. In this paper, we present a benchmarking study\ncomparing KANs and Multi-Layer Perceptrons (MLPs) on tabular datasets. The\nstudy evaluates task performance and training times. From the results obtained\non the various datasets, KANs demonstrate superior or comparable accuracy and\nF1 scores, excelling particularly in datasets with numerous instances,\nsuggesting robust handling of complex data. We also highlight that this\nperformance improvement of KANs comes with a higher computational cost when\ncompared to MLPs of comparable sizes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14529v1",
    "published_date": "2024-06-20 17:41:34 UTC",
    "updated_date": "2024-06-20 17:41:34 UTC"
  },
  {
    "arxiv_id": "2406.14528v3",
    "title": "DeciMamba: Exploring the Length Extrapolation Potential of Mamba",
    "authors": [
      "Assaf Ben-Kish",
      "Itamar Zimerman",
      "Shady Abu-Hussein",
      "Nadav Cohen",
      "Amir Globerson",
      "Lior Wolf",
      "Raja Giryes"
    ],
    "abstract": "Long-range sequence processing poses a significant challenge for Transformers\ndue to their quadratic complexity in input length. A promising alternative is\nMamba, which demonstrates high performance and achieves Transformer-level\ncapabilities while requiring substantially fewer computational resources. In\nthis paper we explore the length-generalization capabilities of Mamba, which we\nfind to be relatively limited. Through a series of visualizations and analyses\nwe identify that the limitations arise from a restricted effective receptive\nfield, dictated by the sequence length used during training. To address this\nconstraint, we introduce DeciMamba, a context-extension method specifically\ndesigned for Mamba. This mechanism, built on top of a hidden filtering\nmechanism embedded within the S6 layer, enables the trained model to\nextrapolate well even without additional training. Empirical experiments over\nreal-world long-range NLP tasks show that DeciMamba can extrapolate to context\nlengths that are significantly longer than the ones seen during training, while\nenjoying faster inference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Official Implementation: https://github.com/assafbk/DeciMamba",
    "pdf_url": "http://arxiv.org/pdf/2406.14528v3",
    "published_date": "2024-06-20 17:40:18 UTC",
    "updated_date": "2025-04-09 22:43:46 UTC"
  },
  {
    "arxiv_id": "2406.14525v1",
    "title": "Towards evolution of Deep Neural Networks through contrastive Self-Supervised learning",
    "authors": [
      "Adriano Vinhas",
      "João Correia",
      "Penousal Machado"
    ],
    "abstract": "Deep Neural Networks (DNNs) have been successfully applied to a wide range of\nproblems. However, two main limitations are commonly pointed out. The first one\nis that they require long time to design. The other is that they heavily rely\non labelled data, which can sometimes be costly and hard to obtain. In order to\naddress the first problem, neuroevolution has been proved to be a plausible\noption to automate the design of DNNs. As for the second problem,\nself-supervised learning has been used to leverage unlabelled data to learn\nrepresentations. Our goal is to study how neuroevolution can help\nself-supervised learning to bridge the gap to supervised learning in terms of\nperformance. In this work, we propose a framework that is able to evolve deep\nneural networks using self-supervised learning. Our results on the CIFAR-10\ndataset show that it is possible to evolve adequate neural networks while\nreducing the reliance on labelled data. Moreover, an analysis to the structure\nof the evolved networks suggests that the amount of labelled data fed to them\nhas less effect on the structure of networks that learned via self-supervised\nlearning, when compared to individuals that relied on supervised learning.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "IEEE World Congress on Computational Intelligence (WCCI) 2024;\n  Keywords: NeuroEvolution, Deep Learning, Evolutionary Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2406.14525v1",
    "published_date": "2024-06-20 17:38:16 UTC",
    "updated_date": "2024-06-20 17:38:16 UTC"
  },
  {
    "arxiv_id": "2406.14526v2",
    "title": "Fantastic Copyrighted Beasts and How (Not) to Generate Them",
    "authors": [
      "Luxi He",
      "Yangsibo Huang",
      "Weijia Shi",
      "Tinghao Xie",
      "Haotian Liu",
      "Yue Wang",
      "Luke Zettlemoyer",
      "Chiyuan Zhang",
      "Danqi Chen",
      "Peter Henderson"
    ],
    "abstract": "Recent studies show that image and video generation models can be prompted to\nreproduce copyrighted content from their training data, raising serious legal\nconcerns about copyright infringement. Copyrighted characters (e.g., Mario,\nBatman) present a significant challenge: at least one lawsuit has already\nawarded damages based on the generation of such characters. Consequently,\ncommercial services like DALL-E have started deploying interventions. However,\nlittle research has systematically examined these problems: (1) Can users\neasily prompt models to generate copyrighted characters, even if it is\nunintentional?; (2) How effective are the existing mitigation strategies? To\naddress these questions, we introduce a novel evaluation framework with metrics\nthat assess both the generated image's similarity to copyrighted characters and\nits consistency with user intent, grounded in a set of popular copyrighted\ncharacters from diverse studios and regions. We show that state-of-the-art\nimage and video generation models can still generate characters even if\ncharacters' names are not explicitly mentioned, sometimes with only two generic\nkeywords (e.g., prompting with \"videogame, plumber\" consistently generates\nNintendo's Mario character). We also introduce semi-automatic techniques to\nidentify such keywords or descriptions that trigger character generation. Using\nthis framework, we evaluate mitigation strategies, including prompt rewriting\nand new approaches we propose. Our findings reveal that common methods, such as\nDALL-E's prompt rewriting, are insufficient alone and require supplementary\nstrategies like negative prompting. Our work provides empirical grounding for\ndiscussions on copyright mitigation strategies and offers actionable insights\nfor model deployers implementing these safeguards.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14526v2",
    "published_date": "2024-06-20 17:38:16 UTC",
    "updated_date": "2025-03-26 12:21:42 UTC"
  },
  {
    "arxiv_id": "2406.14517v2",
    "title": "PostMark: A Robust Blackbox Watermark for Large Language Models",
    "authors": [
      "Yapei Chang",
      "Kalpesh Krishna",
      "Amir Houmansadr",
      "John Wieting",
      "Mohit Iyyer"
    ],
    "abstract": "The most effective techniques to detect LLM-generated text rely on inserting\na detectable signature -- or watermark -- during the model's decoding process.\nMost existing watermarking methods require access to the underlying LLM's\nlogits, which LLM API providers are loath to share due to fears of model\ndistillation. As such, these watermarks must be implemented independently by\neach LLM provider. In this paper, we develop PostMark, a modular post-hoc\nwatermarking procedure in which an input-dependent set of words (determined via\na semantic embedding) is inserted into the text after the decoding process has\ncompleted. Critically, PostMark does not require logit access, which means it\ncan be implemented by a third party. We also show that PostMark is more robust\nto paraphrasing attacks than existing watermarking methods: our experiments\ncover eight baseline algorithms, five base LLMs, and three datasets. Finally,\nwe evaluate the impact of PostMark on text quality using both automated and\nhuman assessments, highlighting the trade-off between quality and robustness to\nparaphrasing. We release our code, outputs, and annotations at\nhttps://github.com/lilakk/PostMark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2024; 19 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14517v2",
    "published_date": "2024-06-20 17:27:14 UTC",
    "updated_date": "2024-10-11 16:19:55 UTC"
  },
  {
    "arxiv_id": "2406.14514v2",
    "title": "Solving a Stackelberg Game on Transportation Networks in a Dynamic Crime Scenario: A Mixed Approach on Multi-Layer Networks",
    "authors": [
      "Sukanya Samanta",
      "Kei Kimura",
      "Makoto Yokoo"
    ],
    "abstract": "Interdicting a criminal with limited police resources is a challenging task\nas the criminal changes location over time. The size of the large\ntransportation network further adds to the difficulty of this scenario. To\ntackle this issue, we consider the concept of a layered graph. At each time\nstamp, we create a copy of the entire transportation network to track the\npossible movements of both players, the attacker and the defenders. We consider\na Stackelberg game in a dynamic crime scenario where the attacker changes\nlocation over time while the defenders attempt to interdict the attacker on his\nescape route. Given a set of defender strategies, the optimal attacker strategy\nis determined by applying Dijkstra's algorithm on the layered networks. Here,\nthe attacker aims to minimize while the defenders aim to maximize the\nprobability of interdiction. We develop an approximation algorithm on the\nlayered networks to find near-optimal strategy for defenders. The efficacy of\nthe developed approach is compared with the adopted MILP approach. We compare\nthe results in terms of computational time and solution quality. The quality of\nthe results demonstrates the need for the developed approach, as it effectively\nsolves the complex problem within a short amount of time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14514v2",
    "published_date": "2024-06-20 17:24:13 UTC",
    "updated_date": "2024-10-23 07:05:18 UTC"
  },
  {
    "arxiv_id": "2406.14510v2",
    "title": "V-LASIK: Consistent Glasses-Removal from Videos Using Synthetic Data",
    "authors": [
      "Rotem Shalev-Arkushin",
      "Aharon Azulay",
      "Tavi Halperin",
      "Eitan Richardson",
      "Amit H. Bermano",
      "Ohad Fried"
    ],
    "abstract": "Diffusion-based generative models have recently shown remarkable image and\nvideo editing capabilities. However, local video editing, particularly removal\nof small attributes like glasses, remains a challenge. Existing methods either\nalter the videos excessively, generate unrealistic artifacts, or fail to\nperform the requested edit consistently throughout the video. In this work, we\nfocus on consistent and identity-preserving removal of glasses in videos, using\nit as a case study for consistent local attribute removal in videos. Due to the\nlack of paired data, we adopt a weakly supervised approach and generate\nsynthetic imperfect data, using an adjusted pretrained diffusion model. We show\nthat despite data imperfection, by learning from our generated data and\nleveraging the prior of pretrained diffusion models, our model is able to\nperform the desired edit consistently while preserving the original video\ncontent. Furthermore, we exemplify the generalization ability of our method to\nother local video editing tasks by applying it successfully to facial\nsticker-removal. Our approach demonstrates significant improvement over\nexisting methods, showcasing the potential of leveraging synthetic data and\nstrong video priors for local video editing tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14510v2",
    "published_date": "2024-06-20 17:14:43 UTC",
    "updated_date": "2025-04-14 08:10:45 UTC"
  },
  {
    "arxiv_id": "2406.14508v1",
    "title": "Evidence of a log scaling law for political persuasion with large language models",
    "authors": [
      "Kobi Hackenburg",
      "Ben M. Tappin",
      "Paul Röttger",
      "Scott Hale",
      "Jonathan Bright",
      "Helen Margetts"
    ],
    "abstract": "Large language models can now generate political messages as persuasive as\nthose written by humans, raising concerns about how far this persuasiveness may\ncontinue to increase with model size. Here, we generate 720 persuasive messages\non 10 U.S. political issues from 24 language models spanning several orders of\nmagnitude in size. We then deploy these messages in a large-scale randomized\nsurvey experiment (N = 25,982) to estimate the persuasive capability of each\nmodel. Our findings are twofold. First, we find evidence of a log scaling law:\nmodel persuasiveness is characterized by sharply diminishing returns, such that\ncurrent frontier models are barely more persuasive than models smaller in size\nby an order of magnitude or more. Second, mere task completion (coherence,\nstaying on topic) appears to account for larger models' persuasive advantage.\nThese findings suggest that further scaling model size will not much increase\nthe persuasiveness of static LLM-generated messages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14508v1",
    "published_date": "2024-06-20 17:12:38 UTC",
    "updated_date": "2024-06-20 17:12:38 UTC"
  },
  {
    "arxiv_id": "2406.14507v2",
    "title": "On Newton's Method to Unlearn Neural Networks",
    "authors": [
      "Nhung Bui",
      "Xinyang Lu",
      "Rachael Hwee Ling Sim",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "With the widespread applications of neural networks (NNs) trained on personal\ndata, machine unlearning has become increasingly important for enabling\nindividuals to exercise their personal data ownership, particularly the \"right\nto be forgotten\" from trained NNs. Since retraining is computationally\nexpensive, we seek approximate unlearning algorithms for NNs that return\nidentical models to the retrained oracle. While Newton's method has been\nsuccessfully used to approximately unlearn linear models, we observe that\nadapting it for NN is challenging due to degenerate Hessians that make\ncomputing Newton's update impossible. Additionally, we show that when coupled\nwith popular techniques to resolve the degeneracy, Newton's method often incurs\noffensively large norm updates and empirically degrades model performance\npost-unlearning. To address these challenges, we propose CureNewton's method, a\nprinciple approach that leverages cubic regularization to handle the Hessian\ndegeneracy effectively. The added regularizer eliminates the need for manual\nfinetuning and affords a natural interpretation within the unlearning context.\nExperiments across different models and datasets show that our method can\nachieve competitive unlearning performance to the state-of-the-art algorithm in\npractical unlearning settings, while being theoretically justified and\nefficient in running time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14507v2",
    "published_date": "2024-06-20 17:12:20 UTC",
    "updated_date": "2024-08-27 17:19:20 UTC"
  },
  {
    "arxiv_id": "2406.14485v8",
    "title": "Proceedings of The second international workshop on eXplainable AI for the Arts (XAIxArts)",
    "authors": [
      "Nick Bryan-Kinns",
      "Corey Ford",
      "Shuoyang Zheng",
      "Helen Kennedy",
      "Alan Chamberlain",
      "Makayla Lewis",
      "Drew Hemment",
      "Zijin Li",
      "Qiong Wu",
      "Lanxi Xiao",
      "Gus Xia",
      "Jeba Rezwana",
      "Michael Clemens",
      "Gabriel Vigliensoni"
    ],
    "abstract": "This second international workshop on explainable AI for the Arts (XAIxArts)\nbrought together a community of researchers in HCI, Interaction Design, AI,\nexplainable AI (XAI), and digital arts to explore the role of XAI for the Arts.\nWorkshop held at the 16th ACM Conference on Creativity and Cognition (C&C\n2024), Chicago, USA.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "Proceedings of The second international workshop on eXplainable AI\n  for the Arts (XAIxArts)",
    "pdf_url": "http://arxiv.org/pdf/2406.14485v8",
    "published_date": "2024-06-20 16:48:14 UTC",
    "updated_date": "2024-10-21 15:24:04 UTC"
  },
  {
    "arxiv_id": "2406.14481v1",
    "title": "Revealing Vision-Language Integration in the Brain with Multimodal Networks",
    "authors": [
      "Vighnesh Subramaniam",
      "Colin Conwell",
      "Christopher Wang",
      "Gabriel Kreiman",
      "Boris Katz",
      "Ignacio Cases",
      "Andrei Barbu"
    ],
    "abstract": "We use (multi)modal deep neural networks (DNNs) to probe for sites of\nmultimodal integration in the human brain by predicting stereoencephalography\n(SEEG) recordings taken while human subjects watched movies. We operationalize\nsites of multimodal integration as regions where a multimodal vision-language\nmodel predicts recordings better than unimodal language, unimodal vision, or\nlinearly-integrated language-vision models. Our target DNN models span\ndifferent architectures (e.g., convolutional networks and transformers) and\nmultimodal training techniques (e.g., cross-attention and contrastive\nlearning). As a key enabling step, we first demonstrate that trained vision and\nlanguage models systematically outperform their randomly initialized\ncounterparts in their ability to predict SEEG signals. We then compare unimodal\nand multimodal models against one another. Because our target DNN models often\nhave different architectures, number of parameters, and training sets (possibly\nobscuring those differences attributable to integration), we carry out a\ncontrolled comparison of two models (SLIP and SimCLR), which keep all of these\nattributes the same aside from input modality. Using this approach, we identify\na sizable number of neural sites (on average 141 out of 1090 total sites or\n12.94%) and brain regions where multimodal integration seems to occur.\nAdditionally, we find that among the variants of multimodal training techniques\nwe assess, CLIP-style training is the best suited for downstream prediction of\nthe neural activity in these sites.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024; 23 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14481v1",
    "published_date": "2024-06-20 16:43:22 UTC",
    "updated_date": "2024-06-20 16:43:22 UTC"
  },
  {
    "arxiv_id": "2406.14479v2",
    "title": "Tracing Representation Progression: Analyzing and Enhancing Layer-Wise Similarity",
    "authors": [
      "Jiachen Jiang",
      "Jinxin Zhou",
      "Zhihui Zhu"
    ],
    "abstract": "Analyzing the similarity of internal representations has been an important\ntechnique for understanding the behavior of deep neural networks. Most existing\nmethods for analyzing the similarity between representations of high\ndimensions, such as those based on Centered Kernel Alignment (CKA), rely on\nstatistical properties of the representations for a set of data points. In this\npaper, we focus on transformer models and study the similarity of\nrepresentations between the hidden layers of individual transformers. In this\ncontext, we show that a simple sample-wise cosine similarity metric is capable\nof capturing the similarity and aligns with the complicated CKA. Our\nexperimental results on common transformers reveal that representations across\nlayers are positively correlated, with similarity increasing when layers get\ncloser. We provide a theoretical justification for this phenomenon under the\ngeodesic curve assumption for the learned transformer. We then show that an\nincrease in representation similarity implies an increase in predicted\nprobability when directly applying the last-layer classifier to any hidden\nlayer representation. We then propose an aligned training method to improve the\neffectiveness of shallow layer by enhancing the similarity between internal\nrepresentations, with trained models that enjoy the following properties: (1)\nmore early saturation events, (2) layer-wise accuracies monotonically increase\nand reveal the minimal depth needed for the given task, (3) when served as\nmulti-exit models, they achieve on-par performance with standard multi-exit\narchitectures which consist of additional classifiers designed for early\nexiting in shallow layers. To our knowledge, our work is the first to show that\none common classifier is sufficient for multi-exit models. We conduct\nexperiments on both vision and NLP tasks to demonstrate the performance of the\nproposed aligned training.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14479v2",
    "published_date": "2024-06-20 16:41:09 UTC",
    "updated_date": "2025-02-01 19:29:19 UTC"
  },
  {
    "arxiv_id": "2406.14477v1",
    "title": "SafeSora: Towards Safety Alignment of Text2Video Generation via a Human Preference Dataset",
    "authors": [
      "Josef Dai",
      "Tianle Chen",
      "Xuyao Wang",
      "Ziran Yang",
      "Taiye Chen",
      "Jiaming Ji",
      "Yaodong Yang"
    ],
    "abstract": "To mitigate the risk of harmful outputs from large vision models (LVMs), we\nintroduce the SafeSora dataset to promote research on aligning text-to-video\ngeneration with human values. This dataset encompasses human preferences in\ntext-to-video generation tasks along two primary dimensions: helpfulness and\nharmlessness. To capture in-depth human preferences and facilitate structured\nreasoning by crowdworkers, we subdivide helpfulness into 4 sub-dimensions and\nharmlessness into 12 sub-categories, serving as the basis for pilot\nannotations. The SafeSora dataset includes 14,711 unique prompts, 57,333 unique\nvideos generated by 4 distinct LVMs, and 51,691 pairs of preference annotations\nlabeled by humans. We further demonstrate the utility of the SafeSora dataset\nthrough several applications, including training the text-video moderation\nmodel and aligning LVMs with human preference by fine-tuning a prompt\naugmentation module or the diffusion model. These applications highlight its\npotential as the foundation for text-to-video alignment research, such as human\npreference modeling and the development and validation of alignment algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14477v1",
    "published_date": "2024-06-20 16:38:56 UTC",
    "updated_date": "2024-06-20 16:38:56 UTC"
  },
  {
    "arxiv_id": "2406.14476v2",
    "title": "Learning telic-controllable state representations",
    "authors": [
      "Nadav Amir",
      "Stas Tiomkin",
      "Angela Langdon"
    ],
    "abstract": "Computational descriptions of purposeful behavior comprise both descriptive\nand normative} aspects. The former are used to ascertain current (or future)\nstates of the world and the latter to evaluate the desirability, or lack\nthereof, of these states under some goal. In Reinforcement Learning, the\nnormative aspect (reward and value functions) is assumed to depend on a\npredefined and fixed descriptive one (state representation). Alternatively,\nthese two aspects may emerge interdependently: goals can be, and indeed often\nare, approximated by state-dependent reward functions, but they may also shape\nthe acquired state representations themselves. Here, we present a novel\ncomputational framework for state representation learning in bounded agents,\nwhere descriptive and normative aspects are coupled through the notion of\ngoal-directed, or telic, states. We introduce the concept of telic\ncontrollability to characterize the tradeoff between the granularity of a telic\nstate representation and the policy complexity required to reach all telic\nstates. We propose an algorithm for learning controllable state\nrepresentations, illustrating it using a simple navigation task with shifting\ngoals. Our framework highlights the crucial role of deliberate ignorance --\nknowing which features of experience to ignore -- for learning state\nrepresentations that balance goal flexibility and policy complexity. More\nbroadly, our work advances a unified theoretical perspective on goal-directed\nstate representation learning in natural and artificial agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Finding the Frame: Workshop for Examining Conceptual Frameworks in\n  RL. 2024 Reinforcement Learning Conference, Amherst MA",
    "pdf_url": "http://arxiv.org/pdf/2406.14476v2",
    "published_date": "2024-06-20 16:38:25 UTC",
    "updated_date": "2024-07-16 23:20:17 UTC"
  },
  {
    "arxiv_id": "2406.14469v8",
    "title": "Movement-Prediction-Adjusted Naïve Forecast",
    "authors": [
      "Cheng Zhang"
    ],
    "abstract": "This study introduces a movement-prediction-adjusted na\\\"ive forecast for\ntime series exhibiting symmetric random walk characteristics, which is\napplicable after accurate movement predictions are available. Specifically, the\noriginal na\\\"ive forecast is adjusted by a weighted movement prediction term,\nwhere the weights are determined via two parameters derived from the in-sample\ndata: one based on directional accuracy of the movement prediction and the\nother on the mean absolute increment of the target series. Simulation\nexperiments were conducted across four types of synthetic symmetric random walk\nseries, each with different variance structures. For each time series, diverse\nmovement predictions with predefined directional accuracies were randomly\ngenerated, and the resulting forecasts were evaluated via the RMSE, MAE, MAPE,\nand sMAPE metrics. The results demonstrated a clear monotonic improvement in\nthe forecast performance as the directional accuracy increased. Notably, the\nadjusted na\\\"ive forecast achieved statistically significant improvements even\nat relatively low directional accuracy levels slightly above 0.50. These\nfindings imply that the movement-prediction-adjusted na\\\"ive forecast can serve\nas an effective second-stage method for forecasting symmetric random walk time\nseries when consistent and accurate movement predictions are provided.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG",
      "econ.EM",
      "stat.ML",
      "62M10"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14469v8",
    "published_date": "2024-06-20 16:32:18 UTC",
    "updated_date": "2025-04-18 13:55:39 UTC"
  },
  {
    "arxiv_id": "2406.14458v1",
    "title": "Centimeter Positioning Accuracy using AI/ML for 6G Applications",
    "authors": [
      "Sai Prasanth Kotturi",
      "Radha Krishna Ganti"
    ],
    "abstract": "This research looks at using AI/ML to achieve centimeter-level user\npositioning in 6G applications such as the Industrial Internet of Things\n(IIoT). Initial results show that our AI/ML-based method can estimate user\npositions with an accuracy of 17 cm in an indoor factory environment. In this\nproposal, we highlight our approaches and future directions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "2 Pages, 2 Figures, ICMLCN Conference, Stockholm, Sweden",
    "pdf_url": "http://arxiv.org/pdf/2406.14458v1",
    "published_date": "2024-06-20 16:17:07 UTC",
    "updated_date": "2024-06-20 16:17:07 UTC"
  },
  {
    "arxiv_id": "2406.14457v1",
    "title": "Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue",
    "authors": [
      "Huifang Du",
      "Shuqin Li",
      "Minghao Wu",
      "Xuejing Feng",
      "Yuan-Fang Li",
      "Haofen Wang"
    ],
    "abstract": "Reinforcement learning (RL) is a powerful approach to enhance task-oriented\ndialogue (TOD) systems. However, existing RL methods tend to mainly focus on\ngeneration tasks, such as dialogue policy learning (DPL) or response generation\n(RG), while neglecting dialogue state tracking (DST) for understanding. This\nnarrow focus limits the systems to achieve globally optimal performance by\noverlooking the interdependence between understanding and generation.\nAdditionally, RL methods face challenges with sparse and delayed rewards, which\ncomplicates training and optimization. To address these issues, we extend RL\ninto both understanding and generation tasks by introducing step-by-step\nrewards throughout the token generation. The understanding reward increases as\nmore slots are correctly filled in DST, while the generation reward grows with\nthe accurate inclusion of user requests. Our approach provides a balanced\noptimization aligned with task completion. Experimental results demonstrate\nthat our approach effectively enhances the performance of TOD systems and\nachieves new state-of-the-art results on three widely used datasets, including\nMultiWOZ2.0, MultiWOZ2.1, and In-Car. Our approach also shows superior few-shot\nability in low-resource settings compared to current models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14457v1",
    "published_date": "2024-06-20 16:15:40 UTC",
    "updated_date": "2024-06-20 16:15:40 UTC"
  },
  {
    "arxiv_id": "2406.14449v1",
    "title": "APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking",
    "authors": [
      "Can Jin",
      "Hongwu Peng",
      "Shiyu Zhao",
      "Zhenting Wang",
      "Wujiang Xu",
      "Ligong Han",
      "Jiahui Zhao",
      "Kai Zhong",
      "Sanguthevar Rajasekaran",
      "Dimitris N. Metaxas"
    ],
    "abstract": "Large Language Models (LLMs) have significantly enhanced Information\nRetrieval (IR) across various modules, such as reranking. Despite impressive\nperformance, current zero-shot relevance ranking with LLMs heavily relies on\nhuman prompt engineering. Existing automatic prompt engineering algorithms\nprimarily focus on language modeling and classification tasks, leaving the\ndomain of IR, particularly reranking, underexplored. Directly applying current\nprompt engineering algorithms to relevance ranking is challenging due to the\nintegration of query and long passage pairs in the input, where the ranking\ncomplexity surpasses classification tasks. To reduce human effort and unlock\nthe potential of prompt optimization in reranking, we introduce a novel\nautomatic prompt engineering algorithm named APEER. APEER iteratively generates\nrefined prompts through feedback and preference optimization. Extensive\nexperiments with four LLMs and ten datasets demonstrate the substantial\nperformance improvement of APEER over existing state-of-the-art (SoTA) manual\nprompts. Furthermore, we find that the prompts generated by APEER exhibit\nbetter transferability across diverse tasks and LLMs. Code is available at\nhttps://github.com/jincan333/APEER.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14449v1",
    "published_date": "2024-06-20 16:11:45 UTC",
    "updated_date": "2024-06-20 16:11:45 UTC"
  },
  {
    "arxiv_id": "2406.14442v1",
    "title": "Graph Representation Learning Strategies for Omics Data: A Case Study on Parkinson's Disease",
    "authors": [
      "Elisa Gómez de Lope",
      "Saurabh Deshpande",
      "Ramón Viñas Torné",
      "Pietro Liò",
      "Enrico Glaab",
      "Stéphane P. A. Bordas"
    ],
    "abstract": "Omics data analysis is crucial for studying complex diseases, but its high\ndimensionality and heterogeneity challenge classical statistical and machine\nlearning methods. Graph neural networks have emerged as promising alternatives,\nyet the optimal strategies for their design and optimization in real-world\nbiomedical challenges remain unclear. This study evaluates various graph\nrepresentation learning models for case-control classification using\nhigh-throughput biological data from Parkinson's disease and control samples.\nWe compare topologies derived from sample similarity networks and molecular\ninteraction networks, including protein-protein and metabolite-metabolite\ninteractions (PPI, MMI). Graph Convolutional Network (GCNs), Chebyshev spectral\ngraph convolution (ChebyNet), and Graph Attention Network (GAT), are evaluated\nalongside advanced architectures like graph transformers, the graph U-net, and\nsimpler models like multilayer perceptron (MLP).\n  These models are systematically applied to transcriptomics and metabolomics\ndata independently. Our comparative analysis highlights the benefits and\nlimitations of various architectures in extracting patterns from omics data,\npaving the way for more accurate and interpretable models in biomedical\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-bio.BM",
      "q-bio.MN"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to Machine Learning in Computational Biology 2024 as an\n  extended abstract, 2 pages + 1 appendix",
    "pdf_url": "http://arxiv.org/pdf/2406.14442v1",
    "published_date": "2024-06-20 16:06:39 UTC",
    "updated_date": "2024-06-20 16:06:39 UTC"
  },
  {
    "arxiv_id": "2406.14429v2",
    "title": "CollaFuse: Collaborative Diffusion Models",
    "authors": [
      "Simeon Allmendinger",
      "Domenique Zipperling",
      "Lukas Struppek",
      "Niklas Kühl"
    ],
    "abstract": "In the landscape of generative artificial intelligence, diffusion-based\nmodels have emerged as a promising method for generating synthetic images.\nHowever, the application of diffusion models poses numerous challenges,\nparticularly concerning data availability, computational requirements, and\nprivacy. Traditional approaches to address these shortcomings, like federated\nlearning, often impose significant computational burdens on individual clients,\nespecially those with constrained resources. In response to these challenges,\nwe introduce a novel approach for distributed collaborative diffusion models\ninspired by split learning. Our approach facilitates collaborative training of\ndiffusion models while alleviating client computational burdens during image\nsynthesis. This reduced computational burden is achieved by retaining data and\ncomputationally inexpensive processes locally at each client while outsourcing\nthe computationally expensive processes to shared, more efficient server\nresources. Through experiments on the common CelebA dataset, our approach\ndemonstrates enhanced privacy by reducing the necessity for sharing raw data.\nThese capabilities hold significant potential across various application areas,\nincluding the design of edge computing solutions. Thus, our work advances\ndistributed machine learning by contributing to the evolution of collaborative\ndiffusion models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14429v2",
    "published_date": "2024-06-20 15:54:21 UTC",
    "updated_date": "2024-10-27 12:42:53 UTC"
  },
  {
    "arxiv_id": "2406.14427v2",
    "title": "Control when confidence is costly",
    "authors": [
      "Itzel Olivos-Castillo",
      "Paul Schrater",
      "Xaq Pitkow"
    ],
    "abstract": "We develop a version of stochastic control that accounts for computational\ncosts of inference. Past studies identified efficient coding without control,\nor efficient control that neglects the cost of synthesizing information. Here\nwe combine these concepts into a framework where agents rationally approximate\ninference for efficient control. Specifically, we study Linear Quadratic\nGaussian (LQG) control with an added internal cost on the relative precision of\nthe posterior probability over the world state. This creates a trade-off: an\nagent can obtain more utility overall by sacrificing some task performance, if\ndoing so saves enough bits during inference. We discover that the rational\nstrategy that solves the joint inference and control problem goes through phase\ntransitions depending on the task demands, switching from a costly but optimal\ninference to a family of suboptimal inferences related by rotation\ntransformations, each misestimate the stability of the world. In all cases, the\nagent moves more to think less. This work provides a foundation for a new type\nof rational computations that could be used by both brains and machines for\nefficient but computationally constrained control.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14427v2",
    "published_date": "2024-06-20 15:50:38 UTC",
    "updated_date": "2024-10-29 18:52:56 UTC"
  },
  {
    "arxiv_id": "2406.14425v3",
    "title": "SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages",
    "authors": [
      "Gayane Ghazaryan",
      "Erik Arakelyan",
      "Pasquale Minervini",
      "Isabelle Augenstein"
    ],
    "abstract": "Question Answering (QA) datasets have been instrumental in developing and\nevaluating Large Language Model (LLM) capabilities. However, such datasets are\nscarce for languages other than English due to the cost and difficulties of\ncollection and manual annotation. This means that producing novel models and\nmeasuring the performance of multilingual LLMs in low-resource languages is\nchallenging. To mitigate this, we propose $\\textbf{S}$yn$\\textbf{DAR}$in, a\nmethod for generating and validating QA datasets for low-resource languages. We\nutilize parallel content mining to obtain $\\textit{human-curated}$ paragraphs\nbetween English and the target language. We use the English data as context to\n$\\textit{generate}$ synthetic multiple-choice (MC) question-answer pairs, which\nare automatically translated and further validated for quality. Combining these\nwith their designated non-English $\\textit{human-curated}$ paragraphs form the\nfinal QA dataset. The method allows to maintain the content quality, reduces\nthe likelihood of factual errors, and circumvents the need for costly\nannotation. To test the method, we created a QA dataset with $1.2$K samples for\nthe Armenian language. The human evaluation shows that $98\\%$ of the generated\nEnglish data maintains quality and diversity in the question types and topics,\nwhile the translation validation pipeline can filter out $\\sim70\\%$ of data\nwith poor quality. We use the dataset to benchmark state-of-the-art LLMs,\nshowing their inability to achieve human accuracy with some model performances\ncloser to random chance. This shows that the generated dataset is non-trivial\nand can be used to evaluate reasoning capabilities in low-resource language.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14425v3",
    "published_date": "2024-06-20 15:49:28 UTC",
    "updated_date": "2024-09-16 21:52:55 UTC"
  },
  {
    "arxiv_id": "2407.12009v1",
    "title": "Using Multimodal Foundation Models and Clustering for Improved Style Ambiguity Loss",
    "authors": [
      "James Baker"
    ],
    "abstract": "Teaching text-to-image models to be creative involves using style ambiguity\nloss, which requires a pretrained classifier. In this work, we explore a new\nform of the style ambiguity training objective, used to approximate creativity,\nthat does not require training a classifier or even a labeled dataset. We then\ntrain a diffusion model to maximize style ambiguity to imbue the diffusion\nmodel with creativity and find our new methods improve upon the traditional\nmethod, based on automated metrics for human judgment, while still maintaining\ncreativity and novelty.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12009v1",
    "published_date": "2024-06-20 15:43:13 UTC",
    "updated_date": "2024-06-20 15:43:13 UTC"
  },
  {
    "arxiv_id": "2406.14422v1",
    "title": "FutureNet-LOF: Joint Trajectory Prediction and Lane Occupancy Field Prediction with Future Context Encoding",
    "authors": [
      "Mingkun Wang",
      "Xiaoguang Ren",
      "Ruochun Jin",
      "Minglong Li",
      "Xiaochuan Zhang",
      "Changqian Yu",
      "Mingxu Wang",
      "Wenjing Yang"
    ],
    "abstract": "Most prior motion prediction endeavors in autonomous driving have\ninadequately encoded future scenarios, leading to predictions that may fail to\naccurately capture the diverse movements of agents (e.g., vehicles or\npedestrians). To address this, we propose FutureNet, which explicitly\nintegrates initially predicted trajectories into the future scenario and\nfurther encodes these future contexts to enhance subsequent forecasting.\nAdditionally, most previous motion forecasting works have focused on predicting\nindependent futures for each agent. However, safe and smooth autonomous driving\nrequires accurately predicting the diverse future behaviors of numerous\nsurrounding agents jointly in complex dynamic environments. Given that all\nagents occupy certain potential travel spaces and possess lane driving\npriority, we propose Lane Occupancy Field (LOF), a new representation with lane\nsemantics for motion forecasting in autonomous driving. LOF can simultaneously\ncapture the joint probability distribution of all road participants' future\nspatial-temporal positions. Due to the high compatibility between lane\noccupancy field prediction and trajectory prediction, we propose a novel\nnetwork with future context encoding for the joint prediction of these two\ntasks. Our approach ranks 1st on two large-scale motion forecasting benchmarks:\nArgoverse 1 and Argoverse 2.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.14422v1",
    "published_date": "2024-06-20 15:41:53 UTC",
    "updated_date": "2024-06-20 15:41:53 UTC"
  },
  {
    "arxiv_id": "2406.14408v2",
    "title": "FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving",
    "authors": [
      "Xiaohan Lin",
      "Qingxing Cao",
      "Yinya Huang",
      "Haiming Wang",
      "Jianqiao Lu",
      "Zhengying Liu",
      "Linqi Song",
      "Xiaodan Liang"
    ],
    "abstract": "Formal verification (FV) has witnessed growing significance with current\nemerging program synthesis by the evolving large language models (LLMs).\nHowever, current formal verification mainly resorts to symbolic verifiers or\nhand-craft rules, resulting in limitations for extensive and flexible\nverification. On the other hand, formal languages for automated theorem\nproving, such as Isabelle, as another line of rigorous verification, are\nmaintained with comprehensive rules and theorems. In this paper, we propose\nFVEL, an interactive Formal Verification Environment with LLMs. Specifically,\nFVEL transforms a given code to be verified into Isabelle, and then conducts\nverification via neural automated theorem proving with an LLM. The joined\nparadigm leverages the rigorous yet abundant formulated and organized rules in\nIsabelle and is also convenient for introducing and adjusting cutting-edge\nLLMs. To achieve this goal, we extract a large-scale FVELER3. The FVELER\ndataset includes code dependencies and verification processes that are\nformulated in Isabelle, containing 758 theories, 29,125 lemmas, and 200,646\nproof steps in total with in-depth dependencies. We benchmark FVELER in the\nFVEL environment by first fine-tuning LLMs with FVELER and then evaluating them\non Code2Inv and SV-COMP. The results show that FVEL with FVELER fine-tuned\nLlama3- 8B solves 17.39% (69 -> 81) more problems, and Mistral-7B 12% (75 ->\n84) more problems in SV-COMP. And the proportion of proof errors is reduced.\nProject page: https://fveler.github.io/.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14408v2",
    "published_date": "2024-06-20 15:31:05 UTC",
    "updated_date": "2024-06-21 02:51:41 UTC"
  },
  {
    "arxiv_id": "2406.14401v1",
    "title": "Fair Streaming Feature Selection",
    "authors": [
      "Zhangling Duan",
      "Tianci Li",
      "Xingyu Wu",
      "Zhaolong Ling",
      "Jingye Yang",
      "Zhaohong Jia"
    ],
    "abstract": "Streaming feature selection techniques have become essential in processing\nreal-time data streams, as they facilitate the identification of the most\nrelevant attributes from continuously updating information. Despite their\nperformance, current algorithms to streaming feature selection frequently fall\nshort in managing biases and avoiding discrimination that could be perpetuated\nby sensitive attributes, potentially leading to unfair outcomes in the\nresulting models. To address this issue, we propose FairSFS, a novel algorithm\nfor Fair Streaming Feature Selection, to uphold fairness in the feature\nselection process without compromising the ability to handle data in an online\nmanner. FairSFS adapts to incoming feature vectors by dynamically adjusting the\nfeature set and discerns the correlations between classification attributes and\nsensitive attributes from this revised set, thereby forestalling the\npropagation of sensitive data. Empirical evaluations show that FairSFS not only\nmaintains accuracy that is on par with leading streaming feature selection\nmethods and existing fair feature techniques but also significantly improves\nfairness metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14401v1",
    "published_date": "2024-06-20 15:22:44 UTC",
    "updated_date": "2024-06-20 15:22:44 UTC"
  },
  {
    "arxiv_id": "2406.14377v2",
    "title": "CE-SSL: Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection",
    "authors": [
      "Rushuang Zhou",
      "Lei Clifton",
      "Zijun Liu",
      "Kannie W. Y. Chan",
      "David A. Clifton",
      "Yuan-Ting Zhang",
      "Yining Dong"
    ],
    "abstract": "The label scarcity problem is the main challenge that hinders the wide\napplication of deep learning systems in automatic cardiovascular diseases\n(CVDs) detection using electrocardiography (ECG). Tuning pre-trained models\nalleviates this problem by transferring knowledge learned from large datasets\nto downstream small datasets. However, bottlenecks in computational efficiency\nand detection performance limit its clinical applications. It is difficult to\nimprove the detection performance without significantly sacrificing the\ncomputational efficiency during model training. Here, we propose a\ncomputation-efficient semi-supervised learning paradigm (CE-SSL) for robust and\ncomputation-efficient CVDs detection using ECG. It enables a robust adaptation\nof pre-trained models on downstream datasets with limited supervision and high\ncomputational efficiency. First, a random-deactivation technique is developed\nto achieve robust and fast low-rank adaptation of pre-trained weights.\nSubsequently, we propose a one-shot rank allocation module to determine the\noptimal ranks for the update matrices of the pre-trained weights. Finally, a\nlightweight semi-supervised learning pipeline is introduced to enhance model\nperformance by leveraging labeled and unlabeled data with high computational\nefficiency. Extensive experiments on four downstream datasets demonstrate that\nCE-SSL not only outperforms the state-of-the-art methods in multi-label CVDs\ndetection but also consumes fewer GPU footprints, training time, and parameter\nstorage space. As such, this paradigm provides an effective solution for\nachieving high computational efficiency and robust detection performance in the\nclinical applications of pre-trained models under limited supervision. Code and\nSupplementary Materials are available at https://github.com/KAZABANA/CE-SSL",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14377v2",
    "published_date": "2024-06-20 14:45:13 UTC",
    "updated_date": "2024-11-15 16:23:15 UTC"
  },
  {
    "arxiv_id": "2406.14373v2",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "authors": [
      "Gordon Dai",
      "Weijia Zhang",
      "Jinhan Li",
      "Siqi Yang",
      "Chidera Onochie lbe",
      "Srihas Rao",
      "Arthur Caetano",
      "Misha Sra"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) and advancements in Artificial\nIntelligence (AI) offer an opportunity for computational social science\nresearch at scale. Building upon prior explorations of LLM agent design, our\nwork introduces a simulated agent society where complex social relationships\ndynamically form and evolve over time. Agents are imbued with psychological\ndrives and placed in a sandbox survival environment. We conduct an evaluation\nof the agent society through the lens of Thomas Hobbes's seminal Social\nContract Theory (SCT). We analyze whether, as the theory postulates, agents\nseek to escape a brutish \"state of nature\" by surrendering rights to an\nabsolute sovereign in exchange for order and security. Our experiments unveil\nan alignment: Initially, agents engage in unrestrained conflict, mirroring\nHobbes's depiction of the state of nature. However, as the simulation\nprogresses, social contracts emerge, leading to the authorization of an\nabsolute sovereign and the establishment of a peaceful commonwealth founded on\nmutual cooperation. This congruence between our LLM agent society's\nevolutionary trajectory and Hobbes's theoretical account indicates LLMs'\ncapability to model intricate social dynamics and potentially replicate forces\nthat shape human societies. By enabling such insights into group behavior and\nemergent societal phenomena, LLM-driven multi-agent simulations, while unable\nto simulate all the nuances of human behavior, may hold potential for advancing\nour understanding of social structures, group dynamics, and complex human\nsystems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14373v2",
    "published_date": "2024-06-20 14:42:58 UTC",
    "updated_date": "2024-07-01 22:06:13 UTC"
  },
  {
    "arxiv_id": "2406.14367v2",
    "title": "PoseBench: Benchmarking the Robustness of Pose Estimation Models under Corruptions",
    "authors": [
      "Sihan Ma",
      "Jing Zhang",
      "Qiong Cao",
      "Dacheng Tao"
    ],
    "abstract": "Pose estimation aims to accurately identify anatomical keypoints in humans\nand animals using monocular images, which is crucial for various applications\nsuch as human-machine interaction, embodied AI, and autonomous driving. While\ncurrent models show promising results, they are typically trained and tested on\nclean data, potentially overlooking the corruption during real-world deployment\nand thus posing safety risks in practical scenarios. To address this issue, we\nintroduce PoseBench, a comprehensive benchmark designed to evaluate the\nrobustness of pose estimation models against real-world corruption. We\nevaluated 60 representative models, including top-down, bottom-up,\nheatmap-based, regression-based, and classification-based methods, across three\ndatasets for human and animal pose estimation. Our evaluation involves 10 types\nof corruption in four categories: 1) blur and noise, 2) compression and color\nloss, 3) severe lighting, and 4) masks. Our findings reveal that\nstate-of-the-art models are vulnerable to common real-world corruptions and\nexhibit distinct behaviors when tackling human and animal pose estimation\ntasks. To improve model robustness, we delve into various design\nconsiderations, including input resolution, pre-training datasets, backbone\ncapacity, post-processing, and data augmentations. We hope that our benchmark\nwill serve as a foundation for advancing research in robust pose estimation.\nThe benchmark and source code will be released at\nhttps://xymsh.github.io/PoseBench",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical report. Project page: https://xymsh.github.io/PoseBench/",
    "pdf_url": "http://arxiv.org/pdf/2406.14367v2",
    "published_date": "2024-06-20 14:40:17 UTC",
    "updated_date": "2024-09-14 02:37:20 UTC"
  },
  {
    "arxiv_id": "2406.14362v1",
    "title": "Communication-Efficient Byzantine-Resilient Federated Zero-Order Optimization",
    "authors": [
      "Afonso de Sá Delgado Neto",
      "Maximilian Egger",
      "Mayank Bakshi",
      "Rawad Bitar"
    ],
    "abstract": "We introduce CYBER-0, the first zero-order optimization algorithm for\nmemory-and-communication efficient Federated Learning, resilient to Byzantine\nfaults. We show through extensive numerical experiments on the MNIST dataset\nand finetuning RoBERTa-Large that CYBER-0 outperforms state-of-the-art\nalgorithms in terms of communication and memory efficiency while reaching\nsimilar accuracy. We provide theoretical guarantees on its convergence for\nconvex loss functions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14362v1",
    "published_date": "2024-06-20 14:36:12 UTC",
    "updated_date": "2024-06-20 14:36:12 UTC"
  },
  {
    "arxiv_id": "2406.14361v1",
    "title": "Robustness Analysis of AI Models in Critical Energy Systems",
    "authors": [
      "Pantelis Dogoulis",
      "Matthieu Jimenez",
      "Salah Ghamizi",
      "Maxime Cordy",
      "Yves Le Traon"
    ],
    "abstract": "This paper analyzes the robustness of state-of-the-art AI-based models for\npower grid operations under the $N-1$ security criterion. While these models\nperform well in regular grid settings, our results highlight a significant loss\nin accuracy following the disconnection of a line.%under this security\ncriterion. Using graph theory-based analysis, we demonstrate the impact of node\nconnectivity on this loss. Our findings emphasize the need for practical\nscenario considerations in developing AI methodologies for critical\ninfrastructure.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14361v1",
    "published_date": "2024-06-20 14:34:36 UTC",
    "updated_date": "2024-06-20 14:34:36 UTC"
  },
  {
    "arxiv_id": "2406.14358v1",
    "title": "The neural correlates of logical-mathematical symbol systems processing resemble that of spatial cognition more than natural language processing",
    "authors": [
      "Yuannan Li",
      "Shan Xu",
      "Jia Liu"
    ],
    "abstract": "The ability to manipulate logical-mathematical symbols (LMS), encompassing\ntasks such as calculation, reasoning, and programming, is a cognitive skill\narguably unique to humans. Considering the relatively recent emergence of this\nability in human evolutionary history, it has been suggested that LMS\nprocessing may build upon more fundamental cognitive systems, possibly through\nneuronal recycling. Previous studies have pinpointed two primary candidates,\nnatural language processing and spatial cognition. Existing comparisons between\nthese domains largely relied on task-level comparison, which may be confounded\nby task idiosyncrasy. The present study instead compared the neural correlates\nat the domain level with both automated meta-analysis and synthesized maps\nbased on three representative LMS tasks, reasoning, calculation, and mental\nprogramming. Our results revealed a more substantial cortical overlap between\nLMS processing and spatial cognition, in contrast to language processing.\nFurthermore, in regions activated by both spatial and language processing, the\nmultivariate activation pattern for LMS processing exhibited greater\nmultivariate similarity to spatial cognition than to language processing. A\nhierarchical clustering analysis further indicated that typical LMS tasks were\nindistinguishable from spatial cognition tasks at the neural level, suggesting\nan inherent connection between these two cognitive processes. Taken together,\nour findings support the hypothesis that spatial cognition is likely the basis\nof LMS processing, which may shed light on the limitations of large language\nmodels in logical reasoning, particularly those trained exclusively on textual\ndata without explicit emphasis on spatial content.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14358v1",
    "published_date": "2024-06-20 14:31:09 UTC",
    "updated_date": "2024-06-20 14:31:09 UTC"
  },
  {
    "arxiv_id": "2406.14351v1",
    "title": "Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning",
    "authors": [
      "Niccolò Marini",
      "Stefano Marchesin",
      "Lluis Borras Ferris",
      "Simon Püttmann",
      "Marek Wodzinski",
      "Riccardo Fratti",
      "Damian Podareanu",
      "Alessandro Caputo",
      "Svetla Boytcheva",
      "Simona Vatrano",
      "Filippo Fraggetta",
      "Iris Nagtegaal",
      "Gianmaria Silvello",
      "Manfredo Atzori",
      "Henning Müller"
    ],
    "abstract": "The increasing availability of biomedical data is helping to design more\nrobust deep learning (DL) algorithms to analyze biomedical samples. Currently,\none of the main limitations to train DL algorithms to perform a specific task\nis the need for medical experts to label data. Automatic methods to label data\nexist, however automatic labels can be noisy and it is not completely clear\nwhen automatic labels can be adopted to train DL models. This paper aims to\ninvestigate under which circumstances automatic labels can be adopted to train\na DL model on the classification of Whole Slide Images (WSI). The analysis\ninvolves multiple architectures, such as Convolutional Neural Networks (CNN)\nand Vision Transformer (ViT), and over 10000 WSIs, collected from three use\ncases: celiac disease, lung cancer and colon cancer, which one including\nrespectively binary, multiclass and multilabel data. The results allow\nidentifying 10% as the percentage of noisy labels that lead to train\ncompetitive models for the classification of WSIs. Therefore, an algorithm\ngenerating automatic labels needs to fit this criterion to be adopted. The\napplication of the Semantic Knowledge Extractor Tool (SKET) algorithm to\ngenerate automatic labels leads to performance comparable to the one obtained\nwith manual labels, since it generates a percentage of noisy labels between\n2-5%. Automatic labels are as effective as manual ones, reaching solid\nperformance comparable to the one obtained training models with manual labels.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "pre-print of the journal paper",
    "pdf_url": "http://arxiv.org/pdf/2406.14351v1",
    "published_date": "2024-06-20 14:20:50 UTC",
    "updated_date": "2024-06-20 14:20:50 UTC"
  },
  {
    "arxiv_id": "2406.14343v5",
    "title": "IWISDM: Assessing instruction following in multimodal models at scale",
    "authors": [
      "Xiaoxuan Lei",
      "Lucas Gomez",
      "Hao Yuan Bai",
      "Pouya Bashivan"
    ],
    "abstract": "The ability to perform complex tasks from detailed instructions is a key to\nmany remarkable achievements of our species. As humans, we are not only capable\nof performing a wide variety of tasks but also very complex ones that may\nentail hundreds or thousands of steps to complete. Large language models and\ntheir more recent multimodal counterparts that integrate textual and visual\ninputs have achieved unprecedented success in performing complex tasks. Yet,\nmost existing benchmarks are largely confined to single-modality inputs (either\ntext or vision), narrowing the scope of multimodal assessments, particularly\nfor instruction-following in multimodal contexts. To bridge this gap, we\nintroduce the instructed-Virtual VISual Decision Making (iWISDM) environment\nengineered to generate a limitless array of vision-language tasks of varying\ncomplexity. Using iWISDM, we compiled three distinct benchmarks of instruction\nfollowing visual tasks across varying complexity levels and evaluated several\nnewly developed multimodal models on these benchmarks. Our findings establish\niWISDM as a robust benchmark for assessing the instructional adherence of both\nexisting and emergent multimodal models and highlight a large gap between these\nmodels' ability to precisely follow instructions with that of humans.The code\nof iWISDM is available on GitHub at https://github.com/BashivanLab/iWISDM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14343v5",
    "published_date": "2024-06-20 14:09:54 UTC",
    "updated_date": "2024-07-22 03:25:19 UTC"
  },
  {
    "arxiv_id": "2406.14336v1",
    "title": "Exploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction",
    "authors": [
      "Erum Haris",
      "Anthony G. Cohn",
      "John G. Stell"
    ],
    "abstract": "Navigating historical narratives poses a challenge in unveiling the spatial\nintricacies of past landscapes. The proposed work addresses this challenge\nwithin the context of the English Lake District, employing the Corpus of the\nLake District Writing. The method utilizes a generative pre-trained transformer\nmodel to extract spatial relations from the textual descriptions in the corpus.\nThe study applies this large language model to understand the spatial\ndimensions inherent in historical narratives comprehensively. The outcomes are\npresented as semantic triples, capturing the nuanced connections between\nentities and locations, and visualized as a network, offering a graphical\nrepresentation of the spatial narrative. The study contributes to a deeper\ncomprehension of the English Lake District's spatial tapestry and provides an\napproach to uncovering spatial relations within diverse historical contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14336v1",
    "published_date": "2024-06-20 14:04:59 UTC",
    "updated_date": "2024-06-20 14:04:59 UTC"
  },
  {
    "arxiv_id": "2406.14335v1",
    "title": "Self-supervised Interpretable Concept-based Models for Text Classification",
    "authors": [
      "Francesco De Santis",
      "Philippe Bich",
      "Gabriele Ciravegna",
      "Pietro Barbiero",
      "Danilo Giordano",
      "Tania Cerquitelli"
    ],
    "abstract": "Despite their success, Large-Language Models (LLMs) still face criticism as\ntheir lack of interpretability limits their controllability and reliability.\nTraditional post-hoc interpretation methods, based on attention and\ngradient-based analysis, offer limited insight into the model's decision-making\nprocesses. In the image field, Concept-based models have emerged as\nexplainable-by-design architectures, employing human-interpretable features as\nintermediate representations. However, these methods have not been yet adapted\nto textual data, mainly because they require expensive concept annotations,\nwhich are impractical for real-world text data. This paper addresses this\nchallenge by proposing a self-supervised Interpretable Concept Embedding Models\n(ICEMs). We leverage the generalization abilities of LLMs to predict the\nconcepts labels in a self-supervised way, while we deliver the final\npredictions with an interpretable function. The results of our experiments show\nthat ICEMs can be trained in a self-supervised way achieving similar\nperformance to fully supervised concept-based models and end-to-end black-box\nones. Additionally, we show that our models are (i) interpretable, offering\nmeaningful logical explanations for their predictions; (ii) interactable,\nallowing humans to modify intermediate predictions through concept\ninterventions; and (iii) controllable, guiding the LLMs' decoding process to\nfollow a required decision-making path.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14335v1",
    "published_date": "2024-06-20 14:04:53 UTC",
    "updated_date": "2024-06-20 14:04:53 UTC"
  },
  {
    "arxiv_id": "2406.14319v2",
    "title": "LiveMind: Low-latency Large Language Models with Simultaneous Inference",
    "authors": [
      "Chuangtao Chen",
      "Grace Li Zhang",
      "Xunzhao Yin",
      "Cheng Zhuo",
      "Ulf Schlichtmann",
      "Bing Li"
    ],
    "abstract": "In this paper, we introduce LiveMind, a novel low-latency inference framework\nfor large language model (LLM) inference which enables LLMs to perform\ninferences with incomplete user input. By reallocating computational processes\nto the input phase, a substantial reduction in latency is achieved, thereby\nsignificantly enhancing the interactive experience for users of LLMs. The\nframework adeptly manages the visibility of the streaming input to the model,\nallowing it to infer from incomplete user input or await additional content.\nCompared with traditional inference methods on complete user input, our\napproach demonstrates an average reduction in response latency of 84.0% on the\nMMLU dataset and 71.6% on the MMLU-Pro dataset, while maintaining comparable\naccuracy. Additionally, our framework facilitates collaborative inference and\noutput across different models. By employing an large LLM for inference and a\nsmall LLM for output, we achieve an average 37% reduction in response latency,\nalongside a 4.30% improvement in accuracy on the MMLU-Pro dataset compared with\nthe baseline. The proposed LiveMind framework advances the field of human-AI\ninteraction by enabling more responsive and efficient communication between\nusers and AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14319v2",
    "published_date": "2024-06-20 13:52:30 UTC",
    "updated_date": "2024-11-05 18:43:57 UTC"
  },
  {
    "arxiv_id": "2406.14318v1",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "authors": [
      "Zhili Shen",
      "Zihang Xi",
      "Ying He",
      "Wei Tong",
      "Jingyu Hua",
      "Sheng Zhong"
    ],
    "abstract": "The rapid adoption of online chatbots represents a significant advancement in\nartificial intelligence. However, this convenience brings considerable privacy\nconcerns, as prompts can inadvertently contain sensitive information exposed to\nlarge language models (LLMs). Limited by high computational costs, reduced task\nusability, and excessive system modifications, previous works based on local\ndeployment, embedding perturbation, and homomorphic encryption are inapplicable\nto online prompt-based LLM applications.\n  To address these issues, this paper introduces Prompt Privacy Sanitizer\n(i.e., ProSan), an end-to-end prompt privacy protection framework that can\nproduce anonymized prompts with contextual privacy removed while maintaining\ntask usability and human readability. It can also be seamlessly integrated into\nthe online LLM service pipeline. To achieve high usability and dynamic\nanonymity, ProSan flexibly adjusts its protection targets and strength based on\nthe importance of the words and the privacy leakage risk of the prompts.\nAdditionally, ProSan is capable of adapting to diverse computational resource\nconditions, ensuring privacy protection even for mobile devices with limited\ncomputing power. Our experiments demonstrate that ProSan effectively removes\nprivate information across various tasks, including question answering, text\nsummarization, and code generation, with minimal reduction in task performance.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14318v1",
    "published_date": "2024-06-20 13:52:25 UTC",
    "updated_date": "2024-06-20 13:52:25 UTC"
  },
  {
    "arxiv_id": "2406.14314v3",
    "title": "Identifying User Goals from UI Trajectories",
    "authors": [
      "Omri Berkovitch",
      "Sapir Caduri",
      "Noam Kahlon",
      "Anatoly Efros",
      "Avi Caciularu",
      "Ido Dagan"
    ],
    "abstract": "Identifying underlying user goals and intents has been recognized as valuable\nin various personalization-oriented settings, such as personalized agents,\nimproved search responses, advertising, user analytics, and more. In this\npaper, we propose a new task goal identification from observed UI trajectories\naiming to infer the user's detailed intentions when performing a task within UI\nenvironments. To support this task, we also introduce a novel evaluation\nmethodology designed to assess whether two intent descriptions can be\nconsidered paraphrases within a specific UI environment. Furthermore, we\ndemonstrate how this task can leverage datasets designed for the inverse\nproblem of UI automation, utilizing Android and web datasets for our\nexperiments. To benchmark this task, we compare the performance of humans and\nstate-of-the-art models, specifically GPT-4 and Gemini-1.5 Pro, using our\nproposed metric. The results reveal that both Gemini and GPT underperform\nrelative to human performance, underscoring the challenge of the proposed task\nand the significant room for improvement. This work highlights the importance\nof goal identification within UI trajectories, providing a foundation for\nfurther exploration and advancement in this area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14314v3",
    "published_date": "2024-06-20 13:46:10 UTC",
    "updated_date": "2025-03-03 15:47:10 UTC"
  },
  {
    "arxiv_id": "2406.14313v2",
    "title": "Iterative Repair with Weak Verifiers for Few-shot Transfer in KBQA with Unanswerability",
    "authors": [
      "Riya Sawhney",
      "Samrat Yadav",
      "Indrajit Bhattacharya",
      "Mausam"
    ],
    "abstract": "Real-world applications of KBQA require models to handle unanswerable\nquestions with a limited volume of in-domain labeled training data. We propose\nthe novel task of few-shot transfer for KBQA with unanswerable questions and\ncontribute two new datasets for performance evaluation. We present FUn-FuSIC -\na novel solution for our task that extends FuSIC KBQA, the state-of-the-art\nfew-shot transfer model for answerable-only KBQA. We first note that\nFuSIC-KBQA's iterative repair makes a strong assumption that all questions are\nunanswerable. As a remedy, we propose Feedback for Unanswerability (FUn), which\nuses iterative repair using feedback from a suite of strong and weak verifiers,\nand an adaptation of self consistency for unanswerabilty to better assess the\nanswerability of a question. Our experiments show that FUn-FuSIC significantly\noutperforms suitable adaptations of multiple LLM based and supervised SoTA\nmodels on our task, while establishing a new SoTA for answerable few-shot\ntransfer as well.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14313v2",
    "published_date": "2024-06-20 13:43:38 UTC",
    "updated_date": "2025-02-21 14:35:19 UTC"
  },
  {
    "arxiv_id": "2406.14312v1",
    "title": "Infusing clinical knowledge into tokenisers for language models",
    "authors": [
      "Abul Hasan",
      "Jinge Wu",
      "Quang Ngoc Nguyen",
      "Salomé Andres",
      "Imane Guellil",
      "Huayu Zhang",
      "Arlene Casey",
      "Beatrice Alex",
      "Bruce Guthrie",
      "Honghan Wu"
    ],
    "abstract": "This study introduces a novel knowledge enhanced tokenisation mechanism,\nK-Tokeniser, for clinical text processing. Technically, at initialisation\nstage, K-Tokeniser populates global representations of tokens based on semantic\ntypes of domain concepts (such as drugs or diseases) from either a domain\nontology like Unified Medical Language System or the training data of the task\nrelated corpus. At training or inference stage, sentence level localised\ncontext will be utilised for choosing the optimal global token representation\nto realise the semantic-based tokenisation. To avoid pretraining using the new\ntokeniser, an embedding initialisation approach is proposed to generate\nrepresentations for new tokens. Using three transformer-based language models,\na comprehensive set of experiments are conducted on four real-world datasets\nfor evaluating K-Tokeniser in a wide range of clinical text analytics tasks\nincluding clinical concept and relation extraction, automated clinical coding,\nclinical phenotype identification, and clinical research article\nclassification. Overall, our models demonstrate consistent improvements over\ntheir counterparts in all tasks. In particular, substantial improvements are\nobserved in the automated clinical coding task with 13\\% increase on Micro\n$F_1$ score. Furthermore, K-Tokeniser also shows significant capacities in\nfacilitating quicker converge of language models. Specifically, using\nK-Tokeniser, the language models would only require 50\\% of the training data\nto achieve the best performance of the baseline tokeniser using all training\ndata in the concept extraction task and less than 20\\% of the data for the\nautomated coding task. It is worth mentioning that all these improvements\nrequire no pre-training process, making the approach generalisable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14312v1",
    "published_date": "2024-06-20 13:43:03 UTC",
    "updated_date": "2024-06-20 13:43:03 UTC"
  },
  {
    "arxiv_id": "2406.14310v1",
    "title": "Cross-level Requirement Traceability: A Novel Approach Integrating Bag-of-Words and Word Embedding for Enhanced Similarity Functionality",
    "authors": [
      "Baher Mohammad",
      "Riad Sonbol",
      "Ghaida Rebdawi"
    ],
    "abstract": "Requirement traceability is the process of identifying the inter-dependencies\nbetween requirements. It poses a significant challenge when conducted manually,\nespecially when dealing with requirements at various levels of abstraction. In\nthis work, we propose a novel approach to automate the task of linking\nhigh-level business requirements with more technical system requirements. The\nproposed approach begins by representing each requirement using a Bag of-Words\n(BOW) model combined with the Term Frequency-Inverse Document Frequency\n(TF-IDF) scoring function. Then, we suggested an enhanced cosine similarity\nthat uses recent advances in word embedding representation to correct\ntraditional cosine similarity function limitations. To evaluate the\neffectiveness of our approach, we conducted experiments on three well-known\ndatasets: COEST, WARC(NFR), and WARC(FRS). The results demonstrate that our\napproach significantly improves efficiency compared to existing methods. We\nachieved better results with an increase of approximately 18.4% in one of the\ndatasets, as measured by the F2 score.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14310v1",
    "published_date": "2024-06-20 13:41:02 UTC",
    "updated_date": "2024-06-20 13:41:02 UTC"
  },
  {
    "arxiv_id": "2406.14302v3",
    "title": "Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning",
    "authors": [
      "Patrik Reizinger",
      "Siyuan Guo",
      "Ferenc Huszár",
      "Bernhard Schölkopf",
      "Wieland Brendel"
    ],
    "abstract": "Identifying latent representations or causal structures is important for good\ngeneralization and downstream task performance. However, both fields have been\ndeveloped rather independently. We observe that several methods in both\nrepresentation and causal structure learning rely on the same data-generating\nprocess (DGP), namely, exchangeable but not i.i.d. (independent and identically\ndistributed) data. We provide a unified framework, termed Identifiable\nExchangeable Mechanisms (IEM), for representation and structure learning under\nthe lens of exchangeability. IEM provides new insights that let us relax the\nnecessary conditions for causal structure identification in exchangeable\nnon--i.i.d. data. We also demonstrate the existence of a duality condition in\nidentifiable representation learning, leading to new identifiability results.\nWe hope this work will pave the way for further research in causal\nrepresentation learning.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "ICLR2025 camera ready",
    "pdf_url": "http://arxiv.org/pdf/2406.14302v3",
    "published_date": "2024-06-20 13:30:25 UTC",
    "updated_date": "2025-02-08 06:19:37 UTC"
  },
  {
    "arxiv_id": "2406.14297v2",
    "title": "AI in Space for Scientific Missions: Strategies for Minimizing Neural-Network Model Upload",
    "authors": [
      "Jonah Ekelund",
      "Ricardo Vinuesa",
      "Yuri Khotyaintsev",
      "Pierre Henri",
      "Gian Luca Delzanno",
      "Stefano Markidis"
    ],
    "abstract": "Artificial Intelligence (AI) has the potential to revolutionize space\nexploration by delegating several spacecraft decisions to an onboard AI instead\nof relying on ground control and predefined procedures. It is likely that there\nwill be an AI/ML Processing Unit onboard the spacecraft running an inference\nengine. The neural-network will have pre-installed parameters that can be\nupdated onboard by uploading, by telecommands, parameters obtained by training\non the ground. However, satellite uplinks have limited bandwidth and\ntransmissions can be costly. Furthermore, a mission operating with a suboptimal\nneural network will miss out on valuable scientific data. Smaller networks can\nthereby decrease the uplink cost, while increasing the value of the scientific\ndata that is downloaded. In this work, we evaluate and discuss the use of\nreduced-precision and bare-minimum neural networks to reduce the time for\nupload. As an example of an AI use case, we focus on the NASA's Magnetosperic\nMultiScale (MMS) mission. We show how an AI onboard could be used in the\nEarth's magnetosphere to classify data to selectively downlink higher value\ndata or to recognize a region-of-interest to trigger a burst-mode, collecting\ndata at a high-rate. Using a simple filtering scheme and algorithm, we show how\nthe start and end of a region-of-interest can be detected in on a stream of\nclassifications. To provide the classifications, we use an established\nConvolutional Neural Network (CNN) trained to an accuracy >94%. We also show\nhow the network can be reduced to a single linear layer and trained to the same\naccuracy as the established CNN. Thereby, reducing the overall size of the\nmodel by up to 98.9%. We further show how each network can be reduced by up to\n75% of its original size, by using lower-precision formats to represent the\nnetwork parameters, with a change in accuracy of less than 0.6 percentage\npoints.",
    "categories": [
      "cs.AI",
      "astro-ph.IM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14297v2",
    "published_date": "2024-06-20 13:24:52 UTC",
    "updated_date": "2024-08-30 07:49:24 UTC"
  },
  {
    "arxiv_id": "2406.14294v2",
    "title": "DASB - Discrete Audio and Speech Benchmark",
    "authors": [
      "Pooneh Mousavi",
      "Luca Della Libera",
      "Jarod Duret",
      "Artem Ploujnikov",
      "Cem Subakan",
      "Mirco Ravanelli"
    ],
    "abstract": "Discrete audio tokens have recently gained considerable attention for their\npotential to connect audio and language processing, enabling the creation of\nmodern multimodal large language models. Ideal audio tokens must effectively\npreserve phonetic and semantic content along with paralinguistic information,\nspeaker identity, and other details. While several types of audio tokens have\nbeen recently proposed, identifying the optimal tokenizer for various tasks is\nchallenging due to the inconsistent evaluation settings in existing studies. To\naddress this gap, we release the Discrete Audio and Speech Benchmark (DASB), a\ncomprehensive leaderboard for benchmarking discrete audio tokens across a wide\nrange of discriminative tasks, including speech recognition, speaker\nidentification and verification, emotion recognition, keyword spotting, and\nintent classification, as well as generative tasks such as speech enhancement,\nseparation, and text-to-speech. Our results show that, on average, semantic\ntokens outperform compression tokens across most discriminative and generative\ntasks. However, the performance gap between semantic tokens and standard\ncontinuous representations remains substantial, highlighting the need for\nfurther research in this field.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.14294v2",
    "published_date": "2024-06-20 13:23:27 UTC",
    "updated_date": "2024-06-21 17:07:17 UTC"
  },
  {
    "arxiv_id": "2406.14288v1",
    "title": "Revisiting Modularity Maximization for Graph Clustering: A Contrastive Learning Perspective",
    "authors": [
      "Yunfei Liu",
      "Jintang Li",
      "Yuehe Chen",
      "Ruofan Wu",
      "Ericbk Wang",
      "Jing Zhou",
      "Sheng Tian",
      "Shuheng Shen",
      "Xing Fu",
      "Changhua Meng",
      "Weiqiang Wang",
      "Liang Chen"
    ],
    "abstract": "Graph clustering, a fundamental and challenging task in graph mining, aims to\nclassify nodes in a graph into several disjoint clusters. In recent years,\ngraph contrastive learning (GCL) has emerged as a dominant line of research in\ngraph clustering and advances the new state-of-the-art. However, GCL-based\nmethods heavily rely on graph augmentations and contrastive schemes, which may\npotentially introduce challenges such as semantic drift and scalability issues.\nAnother promising line of research involves the adoption of modularity\nmaximization, a popular and effective measure for community detection, as the\nguiding principle for clustering tasks. Despite the recent progress, the\nunderlying mechanism of modularity maximization is still not well understood.\nIn this work, we dig into the hidden success of modularity maximization for\ngraph clustering. Our analysis reveals the strong connections between\nmodularity maximization and graph contrastive learning, where positive and\nnegative examples are naturally defined by modularity. In light of our results,\nwe propose a community-aware graph clustering framework, coined MAGI, which\nleverages modularity maximization as a contrastive pretext task to effectively\nuncover the underlying information of communities in graphs, while avoiding the\nproblem of semantic drift. Extensive experiments on multiple graph datasets\nverify the effectiveness of MAGI in terms of scalability and clustering\nperformance compared to state-of-the-art graph clustering methods. Notably,\nMAGI easily scales a sufficiently large graph with 100M nodes while\noutperforming strong baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "KDD 2024 research track. Code available at\n  https://github.com/EdisonLeeeee/MAGI",
    "pdf_url": "http://arxiv.org/pdf/2406.14288v1",
    "published_date": "2024-06-20 13:14:44 UTC",
    "updated_date": "2024-06-20 13:14:44 UTC"
  },
  {
    "arxiv_id": "2406.14284v1",
    "title": "VAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla",
    "authors": [
      "Pramit Bhattacharyya",
      "Arnab Bhattacharya"
    ],
    "abstract": "Bangla (Bengali) is the fifth most spoken language globally and, yet, the\nproblem of automatic grammar correction in Bangla is still in its nascent\nstage. This is mostly due to the need for a large corpus of grammatically\nincorrect sentences, with their corresponding correct counterparts. The present\nstate-of-the-art techniques to curate a corpus for grammatically wrong\nsentences involve random swapping, insertion and deletion of words.\nHowever,these steps may not always generate grammatically wrong sentences in\nBangla. In this work, we propose a pragmatic approach to generate grammatically\nwrong sentences in Bangla. We first categorize the different kinds of errors in\nBangla into 5 broad classes and 12 finer classes. We then use these to generate\ngrammatically wrong sentences systematically from a correct sentence. This\napproach can generate a large number of wrong sentences and can, thus, mitigate\nthe challenge of lacking a large corpus for neural networks. We provide a\ndataset, Vaiyakarana, consisting of 92,830 grammatically incorrect sentences as\nwell as 18,426 correct sentences. We also collected 619 human-generated\nsentences from essays written by Bangla native speakers. This helped us to\nunderstand errors that are more frequent. We evaluated our corpus against\nneural models and LLMs and also benchmark it against human evaluators who are\nnative speakers of Bangla. Our analysis shows that native speakers are far more\naccurate than state-of-the-art models to detect whether the sentence is\ngrammatically correct. Our methodology of generating erroneous sentences can be\napplied for most other Indian languages as well.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14284v1",
    "published_date": "2024-06-20 13:09:29 UTC",
    "updated_date": "2024-06-20 13:09:29 UTC"
  },
  {
    "arxiv_id": "2406.14283v4",
    "title": "Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning",
    "authors": [
      "Chaojie Wang",
      "Yanchen Deng",
      "Zhiyi Lyu",
      "Liang Zeng",
      "Jujie He",
      "Shuicheng Yan",
      "Bo An"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capability in many\nnatural language tasks. However, the auto-regressive generation process makes\nLLMs prone to produce errors, hallucinations and inconsistent statements when\nperforming multi-step reasoning. In this paper, by casting multi-step reasoning\nof LLMs as a heuristic search problem, we aim to alleviate the pathology by\nintroducing Q*, a general, versatile and agile framework for guiding LLMs\ndecoding process with deliberative planning. By learning a plug-and-play\nQ-value model as heuristic function for estimating expected future rewards, our\nQ* can effectively guide LLMs to select the most promising next reasoning step\nwithout fine-tuning LLMs for the current task, which avoids the significant\ncomputational overhead and potential risk of performance degeneration on other\ntasks. Extensive experiments on GSM8K, MATH and MBPP demonstrate the\nsuperiority of our method, contributing to improving the reasoning performance\nof existing open-source LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14283v4",
    "published_date": "2024-06-20 13:08:09 UTC",
    "updated_date": "2024-07-22 10:01:49 UTC"
  },
  {
    "arxiv_id": "2406.14282v3",
    "title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs",
    "authors": [
      "Junjie Wang",
      "Mingyang Chen",
      "Binbin Hu",
      "Dan Yang",
      "Ziqi Liu",
      "Yue Shen",
      "Peng Wei",
      "Zhiqiang Zhang",
      "Jinjie Gu",
      "Jun Zhou",
      "Jeff Z. Pan",
      "Wen Zhang",
      "Huajun Chen"
    ],
    "abstract": "Improving the performance of large language models (LLMs) in complex\nquestion-answering (QA) scenarios has always been a research focal point.\nRecent studies have attempted to enhance LLMs' performance by combining\nstep-wise planning with external retrieval. While effective for advanced models\nlike GPT-3.5, smaller LLMs face challenges in decomposing complex questions,\nnecessitating supervised fine-tuning. Previous work has relied on manual\nannotation and knowledge distillation from teacher LLMs, which are\ntime-consuming and not accurate enough. In this paper, we introduce a novel\nframework for enhancing LLMs' planning capabilities by using planning data\nderived from knowledge graphs (KGs). LLMs fine-tuned with this data have\nimproved planning capabilities, better equipping them to handle complex QA\ntasks that involve retrieval. Evaluations on multiple datasets, including our\nnewly proposed benchmark, highlight the effectiveness of our framework and the\nbenefits of KG-derived planning data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.14282v3",
    "published_date": "2024-06-20 13:07:38 UTC",
    "updated_date": "2024-10-23 09:42:59 UTC"
  },
  {
    "arxiv_id": "2406.14281v4",
    "title": "FairX: A comprehensive benchmarking tool for model analysis using fairness, utility, and explainability",
    "authors": [
      "Md Fahim Sikder",
      "Resmi Ramachandranpillai",
      "Daniel de Leng",
      "Fredrik Heintz"
    ],
    "abstract": "We present FairX, an open-source Python-based benchmarking tool designed for\nthe comprehensive analysis of models under the umbrella of fairness, utility,\nand eXplainability (XAI). FairX enables users to train benchmarking\nbias-mitigation models and evaluate their fairness using a wide array of\nfairness metrics, data utility metrics, and generate explanations for model\npredictions, all within a unified framework. Existing benchmarking tools do not\nhave the way to evaluate synthetic data generated from fair generative models,\nalso they do not have the support for training fair generative models either.\nIn FairX, we add fair generative models in the collection of our fair-model\nlibrary (pre-processing, in-processing, post-processing) and evaluation metrics\nfor evaluating the quality of synthetic fair data. This version of FairX\nsupports both tabular and image datasets. It also allows users to provide their\nown custom datasets. The open-source FairX benchmarking package is publicly\navailable at \\url{https://github.com/fahim-sikder/FairX}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14281v4",
    "published_date": "2024-06-20 13:07:06 UTC",
    "updated_date": "2024-09-03 12:38:22 UTC"
  },
  {
    "arxiv_id": "2406.14277v2",
    "title": "QPaug: Question and Passage Augmentation for Open-Domain Question Answering of LLMs",
    "authors": [
      "Minsang Kim",
      "Cheoneum Park",
      "Seungjun Baek"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has received much attention for\nOpen-domain question-answering (ODQA) tasks as a means to compensate for the\nparametric knowledge of large language models (LLMs). While previous approaches\nfocused on processing retrieved passages to remove irrelevant context, they\nstill rely heavily on the quality of retrieved passages which can degrade if\nthe question is ambiguous or complex. In this paper, we propose a simple yet\nefficient method called question and passage augmentation (QPaug) via LLMs for\nopen-domain QA. QPaug first decomposes the original questions into\nmultiple-step sub-questions. By augmenting the original question with detailed\nsub-questions and planning, we are able to make the query more specific on what\nneeds to be retrieved, improving the retrieval performance. In addition, to\ncompensate for the case where the retrieved passages contain distracting\ninformation or divided opinions, we augment the retrieved passages with\nself-generated passages by LLMs to guide the answer extraction. Experimental\nresults show that QPaug outperforms the previous state-of-the-art and achieves\nsignificant performance gain over existing RAG methods. The source code is\navailable at \\url{https://github.com/kmswin1/QPaug}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The 2024 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP), Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.14277v2",
    "published_date": "2024-06-20 12:59:27 UTC",
    "updated_date": "2024-09-27 12:18:34 UTC"
  },
  {
    "arxiv_id": "2406.14275v2",
    "title": "Step-Back Profiling: Distilling User History for Personalized Scientific Writing",
    "authors": [
      "Xiangru Tang",
      "Xingyao Zhang",
      "Yanjun Shao",
      "Jie Wu",
      "Yilun Zhao",
      "Arman Cohan",
      "Ming Gong",
      "Dongmei Zhang",
      "Mark Gerstein"
    ],
    "abstract": "Large language models (LLM) excel at a variety of natural language processing\ntasks, yet they struggle to generate personalized content for individuals,\nparticularly in real-world scenarios like scientific writing. Addressing this\nchallenge, we introduce STEP-BACK PROFILING to personalize LLMs by distilling\nuser history into concise profiles, including essential traits and preferences\nof users. To conduct the experiments, we construct a Personalized Scientific\nWriting (PSW) dataset to study multi-user personalization. PSW requires the\nmodels to write scientific papers given specialized author groups with diverse\nacademic backgrounds. As for the results, we demonstrate the effectiveness of\ncapturing user characteristics via STEP-BACK PROFILING for collaborative\nwriting. Moreover, our approach outperforms the baselines by up to 3.6 points\non the general personalization benchmark (LaMP), including 7 personalization\nLLM tasks. Our ablation studies validate the contributions of different\ncomponents in our method and provide insights into our task definition. Our\ndataset and code are available at\n\\url{https://github.com/gersteinlab/step-back-profiling}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14275v2",
    "published_date": "2024-06-20 12:58:26 UTC",
    "updated_date": "2024-07-11 07:29:12 UTC"
  },
  {
    "arxiv_id": "2406.14273v2",
    "title": "The Impact of AI on Perceived Job Decency and Meaningfulness: A Case Study",
    "authors": [
      "Kuntal Ghosh",
      "Shadan Sadeghian"
    ],
    "abstract": "The proliferation of Artificial Intelligence (AI) in workplaces stands to\nchange the way humans work, with job satisfaction intrinsically linked to work\nlife. Existing research on human-AI collaboration tends to prioritize\nperformance over the experiential aspects of work. In contrast, this paper\nexplores the impact of AI on job decency and meaningfulness in workplaces.\nThrough interviews in the Information Technology (IT) domain, we not only\nexamined the current work environment, but also explored the perceived\nevolution of the workplace ecosystem with the introduction of an AI. Findings\nfrom the preliminary exploratory study reveal that respondents tend to\nvisualize a workplace where humans continue to play a dominant role, even with\nthe introduction of advanced AIs. In this prospective scenario, AI is seen as\nserving as a complement rather than replacing the human workforce. Furthermore,\nrespondents believe that the introduction of AI will maintain or potentially\nincrease overall job satisfaction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14273v2",
    "published_date": "2024-06-20 12:52:57 UTC",
    "updated_date": "2024-06-21 07:31:56 UTC"
  },
  {
    "arxiv_id": "2406.14267v1",
    "title": "On the Evaluation Practices in Multilingual NLP: Can Machine Translation Offer an Alternative to Human Translations?",
    "authors": [
      "Rochelle Choenni",
      "Sara Rajaee",
      "Christof Monz",
      "Ekaterina Shutova"
    ],
    "abstract": "While multilingual language models (MLMs) have been trained on 100+\nlanguages, they are typically only evaluated across a handful of them due to a\nlack of available test data in most languages. This is particularly problematic\nwhen assessing MLM's potential for low-resource and unseen languages. In this\npaper, we present an analysis of existing evaluation frameworks in multilingual\nNLP, discuss their limitations, and propose several directions for more robust\nand reliable evaluation practices. Furthermore, we empirically study to what\nextent machine translation offers a {reliable alternative to human translation}\nfor large-scale evaluation of MLMs across a wide set of languages. We use a\nSOTA translation model to translate test data from 4 tasks to 198 languages and\nuse them to evaluate three MLMs. We show that while the selected subsets of\nhigh-resource test languages are generally sufficiently representative of a\nwider range of high-resource languages, we tend to overestimate MLMs' ability\non low-resource languages. Finally, we show that simpler baselines can achieve\nrelatively strong performance without having benefited from large-scale\nmultilingual pretraining.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14267v1",
    "published_date": "2024-06-20 12:46:12 UTC",
    "updated_date": "2024-06-20 12:46:12 UTC"
  },
  {
    "arxiv_id": "2406.14266v1",
    "title": "Intelligent Interface: Enhancing Lecture Engagement with Didactic Activity Summaries",
    "authors": [
      "Anna Wróblewska",
      "Marcel Witas",
      "Kinga Frańczak",
      "Arkadiusz Kniaź",
      "Siew Ann Cheong",
      "Tan Seng Chee",
      "Janusz Hołyst",
      "Marcin Paprzycki"
    ],
    "abstract": "Recently, multiple applications of machine learning have been introduced.\nThey include various possibilities arising when image analysis methods are\napplied to, broadly understood, video streams. In this context, a novel tool,\ndeveloped for academic educators to enhance the teaching process by automating,\nsummarizing, and offering prompt feedback on conducting lectures, has been\ndeveloped. The implemented prototype utilizes machine learning-based techniques\nto recognise selected didactic and behavioural teachers' features within\nlecture video recordings.\n  Specifically, users (teachers) can upload their lecture videos, which are\npreprocessed and analysed using machine learning models. Next, users can view\nsummaries of recognized didactic features through interactive charts and\ntables. Additionally, stored ML-based prediction results support comparisons\nbetween lectures based on their didactic content. In the developed application\ntext-based models trained on lecture transcriptions, with enhancements to the\ntranscription quality, by adopting an automatic speech recognition solution are\napplied. Furthermore, the system offers flexibility for (future) integration of\nnew/additional machine-learning models and software modules for image and video\nanalysis.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14266v1",
    "published_date": "2024-06-20 12:45:23 UTC",
    "updated_date": "2024-06-20 12:45:23 UTC"
  },
  {
    "arxiv_id": "2406.14265v1",
    "title": "VeriFlow: Modeling Distributions for Neural Network Verification",
    "authors": [
      "Faried Abu Zaid",
      "Daniel Neider",
      "Mustafa Yalçıner"
    ],
    "abstract": "Formal verification has emerged as a promising method to ensure the safety\nand reliability of neural networks. Naively verifying a safety property amounts\nto ensuring the safety of a neural network for the whole input space\nirrespective of any training or test set. However, this also implies that the\nsafety of the neural network is checked even for inputs that do not occur in\nthe real-world and have no meaning at all, often resulting in spurious errors.\nTo tackle this shortcoming, we propose the VeriFlow architecture as a flow\nbased density model tailored to allow any verification approach to restrict its\nsearch to the some data distribution of interest. We argue that our\narchitecture is particularly well suited for this purpose because of two major\nproperties. First, we show that the transformation and log-density function\nthat are defined by our model are piece-wise affine. Therefore, the model\nallows the usage of verifiers based on SMT with linear arithmetic. Second,\nupper density level sets (UDL) of the data distribution take the shape of an\n$L^p$-ball in the latent space. As a consequence, representations of UDLs\nspecified by a given probability are effectively computable in latent space.\nThis allows for SMT and abstract interpretation approaches with fine-grained,\nprobabilistically interpretable, control regarding on how (a)typical the inputs\nsubject to verification are.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14265v1",
    "published_date": "2024-06-20 12:41:39 UTC",
    "updated_date": "2024-06-20 12:41:39 UTC"
  },
  {
    "arxiv_id": "2406.14240v2",
    "title": "CityNav: Language-Goal Aerial Navigation Dataset with Geographic Information",
    "authors": [
      "Jungdae Lee",
      "Taiki Miyanishi",
      "Shuhei Kurita",
      "Koya Sakamoto",
      "Daichi Azuma",
      "Yutaka Matsuo",
      "Nakamasa Inoue"
    ],
    "abstract": "Vision-and-language navigation (VLN) aims to guide autonomous agents through\nreal-world environments by integrating visual and linguistic cues. Despite\nnotable advancements in ground-level navigation, the exploration of aerial\nnavigation using these modalities remains limited. This gap primarily arises\nfrom a lack of suitable resources for real-world, city-scale aerial navigation\nstudies. To remedy this gap, we introduce CityNav, a novel dataset explicitly\ndesigned for language-guided aerial navigation in photorealistic 3D\nenvironments of real cities. CityNav comprises 32k natural language\ndescriptions paired with human demonstration trajectories, collected via a\nnewly developed web-based 3D simulator. Each description identifies a\nnavigation goal, utilizing the names and locations of landmarks within actual\ncities. As an initial step toward addressing this challenge, we provide\nbaseline models of navigation agents that incorporate an internal 2D spatial\nmap representing landmarks referenced in the descriptions. We have benchmarked\nthe latest aerial navigation methods alongside our proposed baseline model on\nthe CityNav dataset. The findings are revealing: (i) our aerial agent model\ntrained on human demonstration trajectories, outperform those trained on\nshortest path trajectories by a large margin; (ii) incorporating 2D spatial map\ninformation markedly and robustly enhances navigation performance at a city\nscale; (iii) despite the use of map information, our challenging CityNav\ndataset reveals a persistent performance gap between our baseline models and\nhuman performance. To foster further research in aerial VLN, we have made the\ndataset and code available at https://water-cookie.github.io/city-nav-proj/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The first two authors are equally contributed",
    "pdf_url": "http://arxiv.org/pdf/2406.14240v2",
    "published_date": "2024-06-20 12:08:27 UTC",
    "updated_date": "2024-10-05 16:53:09 UTC"
  },
  {
    "arxiv_id": "2406.14232v1",
    "title": "Enhancing robustness of data-driven SHM models: adversarial training with circle loss",
    "authors": [
      "Xiangli Yang",
      "Xijie Deng",
      "Hanwei Zhang",
      "Yang Zou",
      "Jianxi Yang"
    ],
    "abstract": "Structural health monitoring (SHM) is critical to safeguarding the safety and\nreliability of aerospace, civil, and mechanical infrastructure. Machine\nlearning-based data-driven approaches have gained popularity in SHM due to\nadvancements in sensors and computational power. However, machine learning\nmodels used in SHM are vulnerable to adversarial examples -- even small changes\nin input can lead to different model outputs. This paper aims to address this\nproblem by discussing adversarial defenses in SHM. In this paper, we propose an\nadversarial training method for defense, which uses circle loss to optimize the\ndistance between features in training to keep examples away from the decision\nboundary. Through this simple yet effective constraint, our method demonstrates\nsubstantial improvements in model robustness, surpassing existing defense\nmechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14232v1",
    "published_date": "2024-06-20 11:55:39 UTC",
    "updated_date": "2024-06-20 11:55:39 UTC"
  },
  {
    "arxiv_id": "2406.14230v3",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "authors": [
      "Han Jiang",
      "Xiaoyuan Yi",
      "Zhihua Wei",
      "Ziang Xiao",
      "Shu Wang",
      "Xing Xie"
    ],
    "abstract": "Warning: Contains harmful model outputs.\n  Despite significant advancements, the propensity of Large Language Models\n(LLMs) to generate harmful and unethical content poses critical challenges.\nMeasuring value alignment of LLMs becomes crucial for their regulation and\nresponsible deployment. Although numerous benchmarks have been constructed to\nassess social bias, toxicity, and ethical issues in LLMs, those static\nbenchmarks suffer from evaluation chronoeffect, in which, as models rapidly\nevolve, existing benchmarks may leak into training data or become saturated,\noverestimating ever-developing LLMs. To tackle this problem, we propose GETA, a\nnovel generative evolving testing approach based on adaptive testing methods in\nmeasurement theory. Unlike traditional adaptive testing methods that rely on a\nstatic test item pool, GETA probes the underlying moral boundaries of LLMs by\ndynamically generating test items tailored to model capability. GETA co-evolves\nwith LLMs by learning a joint distribution of item difficulty and model value\nconformity, thus effectively addressing evaluation chronoeffect. We evaluated\nvarious popular LLMs with GETA and demonstrated that 1) GETA can dynamically\ncreate difficulty-tailored test items and 2) GETA's evaluation results are more\nconsistent with models' performance on unseen OOD and i.i.d. items, laying the\ngroundwork for future evaluation paradigms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2406.14230v3",
    "published_date": "2024-06-20 11:51:00 UTC",
    "updated_date": "2025-02-03 10:33:17 UTC"
  },
  {
    "arxiv_id": "2406.14228v3",
    "title": "EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms",
    "authors": [
      "Siyu Yuan",
      "Kaitao Song",
      "Jiangjie Chen",
      "Xu Tan",
      "Dongsheng Li",
      "Deqing Yang"
    ],
    "abstract": "The rise of powerful large language models (LLMs) has spurred a new trend in\nbuilding LLM-based autonomous agents for solving complex tasks, especially\nmulti-agent systems. Despite the remarkable progress, we notice that existing\nworks are heavily dependent on human-designed frameworks, which greatly limits\nthe functional scope and scalability of agent systems. How to automatically\nextend the specialized agent to multi-agent systems to improve task-solving\ncapability still remains a significant challenge. In this paper, we introduce\nEvoAgent, a generic method to automatically extend specialized agents to\nmulti-agent systems via the evolutionary algorithm, thereby improving the\neffectiveness of LLM-based agents in solving tasks. Specifically, we consider\nthe existing agent frameworks as the initial individual and then apply a series\nof evolutionary operators (e.g., mutation, crossover, selection, etc.) to\ngenerate multiple agents with diverse settings. Experimental results across\nvarious tasks show that EvoAgent can significantly enhance the task-solving\ncapability of LLM-based agents, and can be generalized to any LLM-based agent\nframework to extend them into multi-agent systems. Resources are available at\nhttps://evo-agent.github.io/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted as a main conference paper at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.14228v3",
    "published_date": "2024-06-20 11:49:23 UTC",
    "updated_date": "2025-03-10 02:42:01 UTC"
  },
  {
    "arxiv_id": "2406.14219v2",
    "title": "Proving Olympiad Algebraic Inequalities without Human Demonstrations",
    "authors": [
      "Chenrui Wei",
      "Mengzhou Sun",
      "Wei Wang"
    ],
    "abstract": "Solving Olympiad-level mathematical problems represents a significant\nadvancement in machine intelligence and automated reasoning. Current machine\nlearning methods, however, struggle to solve Olympiad-level problems beyond\nEuclidean plane geometry due to a lack of large-scale, high-quality datasets.\nThe challenge is even greater in algebraic systems, which involve infinite\nreasoning spaces within finite conditions. To address these issues, we propose\nAIPS, an Algebraic Inequality Proving System capable of autonomously generating\ncomplex inequality theorems and effectively solving Olympiad-level inequality\nproblems without requiring human demonstrations. During proof search in a mixed\nreasoning manner, a value curriculum learning strategy on generated datasets is\nimplemented to improve proving performance, demonstrating strong mathematical\nintuitions. On a test set of 20 International Mathematical Olympiad-level\ninequality problems, AIPS successfully solved 10, outperforming\nstate-of-the-art methods. Furthermore, AIPS automatically generated a vast\narray of non-trivial theorems without human intervention, some of which have\nbeen evaluated by professional contestants and deemed to reach the level of the\nInternational Mathematical Olympiad. Notably, one theorem was selected as a\ncompetition problem in a major city 2024 Mathematical Olympiad.",
    "categories": [
      "cs.AI",
      "03B35, 68T05, 68T20",
      "I.2.3; I.2.6; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "36 pages, 32 figures, 2 tables, published as a conference paper at\n  NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.14219v2",
    "published_date": "2024-06-20 11:37:53 UTC",
    "updated_date": "2024-10-31 03:24:06 UTC"
  },
  {
    "arxiv_id": "2406.14214v6",
    "title": "REVEAL-IT: REinforcement learning with Visibility of Evolving Agent poLicy for InTerpretability",
    "authors": [
      "Shuang Ao",
      "Simon Khan",
      "Haris Aziz",
      "Flora D. Salim"
    ],
    "abstract": "Understanding the agent's learning process, particularly the factors that\ncontribute to its success or failure post-training, is crucial for\ncomprehending the rationale behind the agent's decision-making process. Prior\nmethods clarify the learning process by creating a structural causal model\n(SCM) or visually representing the distribution of value functions.\nNevertheless, these approaches have constraints as they exclusively function in\n2D-environments or with uncomplicated transition dynamics. Understanding the\nagent's learning process in complicated environments or tasks is more\nchallenging. In this paper, we propose REVEAL-IT, a novel framework for\nexplaining the learning process of an agent in complex environments. Initially,\nwe visualize the policy structure and the agent's learning process for various\ntraining tasks. By visualizing these findings, we can understand how much a\nparticular training task or stage affects the agent's performance in test.\nThen, a GNN-based explainer learns to highlight the most important section of\nthe policy, providing a more clear and robust explanation of the agent's\nlearning process. The experiments demonstrate that explanations derived from\nthis framework can effectively help in the optimization of the training tasks,\nresulting in improved learning efficiency and final performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14214v6",
    "published_date": "2024-06-20 11:29:26 UTC",
    "updated_date": "2024-10-14 12:08:29 UTC"
  },
  {
    "arxiv_id": "2406.14208v2",
    "title": "SeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots",
    "authors": [
      "Weixing Wang",
      "Haojin Yang",
      "Christoph Meinel"
    ],
    "abstract": "Previous studies have shown that demonstrations can significantly help Large\nLanguage Models (LLMs ) perform better on the given tasks. However, this\nso-called In-Context Learning ( ICL ) ability is very sensitive to the\npresenting context, and often dozens of demonstrations are needed. In this\nwork, we investigate if we can reduce the shot number while still maintaining a\ncompetitive performance. We present SeCoKD, a self-Knowledge Distillation ( KD\n) training framework that aligns the student model with a heavily prompted\nvariation, thereby increasing the utilization of a single demonstration. We\nexperiment with the SeCoKD across three LLMs and six benchmarks focusing mainly\non reasoning tasks. Results show that our method outperforms the base model and\nSupervised Fine-tuning ( SFT ), especially in zero-shot and one-shot settings\nby 30% and 10%, respectively. Moreover, SeCoKD brings little negative artifacts\nwhen evaluated on new tasks, which is more robust than Supervised Fine-tuning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2406.14208v2",
    "published_date": "2024-06-20 11:26:06 UTC",
    "updated_date": "2024-09-26 08:12:59 UTC"
  },
  {
    "arxiv_id": "2406.14194v2",
    "title": "VLBiasBench: A Comprehensive Benchmark for Evaluating Bias in Large Vision-Language Model",
    "authors": [
      "Sibo Wang",
      "Xiangkui Cao",
      "Jie Zhang",
      "Zheng Yuan",
      "Shiguang Shan",
      "Xilin Chen",
      "Wen Gao"
    ],
    "abstract": "The emergence of Large Vision-Language Models (LVLMs) marks significant\nstrides towards achieving general artificial intelligence. However, these\nadvancements are accompanied by concerns about biased outputs, a challenge that\nhas yet to be thoroughly explored. Existing benchmarks are not sufficiently\ncomprehensive in evaluating biases due to their limited data scale, single\nquestioning format and narrow sources of bias. To address this problem, we\nintroduce VLBiasBench, a comprehensive benchmark designed to evaluate biases in\nLVLMs. VLBiasBench, features a dataset that covers nine distinct categories of\nsocial biases, including age, disability status, gender, nationality, physical\nappearance, race, religion, profession, social economic status, as well as two\nintersectional bias categories: race x gender and race x social economic\nstatus. To build a large-scale dataset, we use Stable Diffusion XL model to\ngenerate 46,848 high-quality images, which are combined with various questions\nto creat 128,342 samples. These questions are divided into open-ended and\nclose-ended types, ensuring thorough consideration of bias sources and a\ncomprehensive evaluation of LVLM biases from multiple perspectives. We conduct\nextensive evaluations on 15 open-source models as well as two advanced\nclosed-source models, yielding new insights into the biases present in these\nmodels. Our benchmark is available at\nhttps://github.com/Xiangkui-Cao/VLBiasBench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14194v2",
    "published_date": "2024-06-20 10:56:59 UTC",
    "updated_date": "2024-12-25 07:31:14 UTC"
  },
  {
    "arxiv_id": "2406.14192v2",
    "title": "Timo: Towards Better Temporal Reasoning for Language Models",
    "authors": [
      "Zhaochen Su",
      "Jun Zhang",
      "Tong Zhu",
      "Xiaoye Qu",
      "Juntao Li",
      "Min Zhang",
      "Yu Cheng"
    ],
    "abstract": "Reasoning about time is essential for Large Language Models (LLMs) to\nunderstand the world. Previous works focus on solving specific tasks, primarily\non time-sensitive question answering. While these methods have proven\neffective, they cannot generalize to a wider spectrum of temporal reasoning\ntasks. Therefore, we propose a crucial question: Can we build a universal\nframework to handle a variety of temporal reasoning tasks? To that end, we\nsystematically study 38 temporal reasoning tasks. Based on the observation that\n19 tasks are directly related to mathematics, we first leverage the available\nmathematical dataset to set a solid foundation for temporal reasoning. However,\nthe in-depth study indicates that focusing solely on mathematical enhancement\nfalls short of addressing pure temporal reasoning tasks. To mitigate this\nlimitation, we propose a simple but effective self-critic temporal optimization\nmethod to enhance the model's temporal reasoning capabilities without\nsacrificing general task abilities. Finally, we develop Timo, a model designed\nto excel in temporal reasoning at the 7B and 13B scales. Notably, Timo\noutperforms the counterpart LLMs by 10.0 and 7.6 in average accuracy scores and\nachieves the new state-of-the-art (SOTA) performance of comparable size.\nExtensive experiments further validate our framework's effectiveness and its\ngeneralization across diverse temporal tasks. The code is available at\nhttps://github.com/zhaochen0110/Timo.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted to the COLM 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2406.14192v2",
    "published_date": "2024-06-20 10:52:14 UTC",
    "updated_date": "2024-08-19 03:47:16 UTC"
  },
  {
    "arxiv_id": "2406.14191v3",
    "title": "Temporal Knowledge Graph Question Answering: A Survey",
    "authors": [
      "Miao Su",
      "Zixuan Li",
      "Zhuo Chen",
      "Long Bai",
      "Xiaolong Jin",
      "Jiafeng Guo"
    ],
    "abstract": "Knowledge Base Question Answering (KBQA) has been a long-standing field to\nanswer questions based on knowledge bases. Recently, the evolving dynamics of\nknowledge have attracted a growing interest in Temporal Knowledge Graph\nQuestion Answering (TKGQA), an emerging task to answer temporal questions.\nHowever, this field grapples with ambiguities in defining temporal questions\nand lacks a systematic categorization of existing methods for TKGQA. In\nresponse, this paper provides a thorough survey from two perspectives: the\ntaxonomy of temporal questions and the methodological categorization for TKGQA.\nSpecifically, we first establish a detailed taxonomy of temporal questions\nengaged in prior studies. Subsequently, we provide a comprehensive review of\nTKGQA techniques of two categories: semantic parsing-based and TKG\nembedding-based. Building on this review, the paper outlines potential research\ndirections aimed at advancing the field of TKGQA. This work aims to serve as a\ncomprehensive reference for TKGQA and to stimulate further research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 3 figures. This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2406.14191v3",
    "published_date": "2024-06-20 10:51:06 UTC",
    "updated_date": "2025-04-21 03:04:15 UTC"
  },
  {
    "arxiv_id": "2406.14185v1",
    "title": "Failure-Resilient Distributed Inference with Model Compression over Heterogeneous Edge Devices",
    "authors": [
      "Li Wang",
      "Liang Li",
      "Lianming Xu",
      "Xian Peng",
      "Aiguo Fei"
    ],
    "abstract": "The distributed inference paradigm enables the computation workload to be\ndistributed across multiple devices, facilitating the implementations of deep\nlearning based intelligent services on extremely resource-constrained Internet\nof Things (IoT) scenarios. Yet it raises great challenges to perform\ncomplicated inference tasks relying on a cluster of IoT devices that are\nheterogeneous in their computing/communication capacity and prone to crash or\ntimeout failures. In this paper, we present RoCoIn, a robust cooperative\ninference mechanism for locally distributed execution of deep neural\nnetwork-based inference tasks over heterogeneous edge devices. It creates a set\nof independent and compact student models that are learned from a large model\nusing knowledge distillation for distributed deployment. In particular, the\ndevices are strategically grouped to redundantly deploy and execute the same\nstudent model such that the inference process is resilient to any local\nfailures, while a joint knowledge partition and student model assignment scheme\nare designed to minimize the response latency of the distributed inference\nsystem in the presence of devices with diverse capacities. Extensive\nsimulations are conducted to corroborate the superior performance of our RoCoIn\nfor distributed inference compared to several baselines, and the results\ndemonstrate its efficacy in timely inference and failure resiliency.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14185v1",
    "published_date": "2024-06-20 10:43:53 UTC",
    "updated_date": "2024-06-20 10:43:53 UTC"
  },
  {
    "arxiv_id": "2406.14177v1",
    "title": "SimulSeamless: FBK at IWSLT 2024 Simultaneous Speech Translation",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Matteo Negri",
      "Luisa Bentivogli"
    ],
    "abstract": "This paper describes the FBK's participation in the Simultaneous Translation\nEvaluation Campaign at IWSLT 2024. For this year's submission in the\nspeech-to-text translation (ST) sub-track, we propose SimulSeamless, which is\nrealized by combining AlignAtt and SeamlessM4T in its medium configuration. The\nSeamlessM4T model is used \"off-the-shelf\" and its simultaneous inference is\nenabled through the adoption of AlignAtt, a SimulST policy based on\ncross-attention that can be applied without any retraining or adaptation of the\nunderlying model for the simultaneous task. We participated in all the Shared\nTask languages (English->{German, Japanese, Chinese}, and Czech->English),\nachieving acceptable or even better results compared to last year's\nsubmissions. SimulSeamless, covering more than 143 source languages and 200\ntarget languages, is released at: https://github.com/hlt-mt/FBK-fairseq/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14177v1",
    "published_date": "2024-06-20 10:34:46 UTC",
    "updated_date": "2024-06-20 10:34:46 UTC"
  },
  {
    "arxiv_id": "2406.14176v3",
    "title": "A Multi-Stream Fusion Approach with One-Class Learning for Audio-Visual Deepfake Detection",
    "authors": [
      "Kyungbok Lee",
      "You Zhang",
      "Zhiyao Duan"
    ],
    "abstract": "This paper addresses the challenge of developing a robust audio-visual\ndeepfake detection model. In practical use cases, new generation algorithms are\ncontinually emerging, and these algorithms are not encountered during the\ndevelopment of detection methods. This calls for the generalization ability of\nthe method. Additionally, to ensure the credibility of detection methods, it is\nbeneficial for the model to interpret which cues from the video indicate it is\nfake. Motivated by these considerations, we then propose a multi-stream fusion\napproach with one-class learning as a representation-level regularization\ntechnique. We study the generalization problem of audio-visual deepfake\ndetection by creating a new benchmark by extending and re-splitting the\nexisting FakeAVCeleb dataset. The benchmark contains four categories of fake\nvideos (Real Audio-Fake Visual, Fake Audio-Fake Visual, Fake Audio-Real Visual,\nand Unsynchronized videos). The experimental results demonstrate that our\napproach surpasses the previous models by a large margin. Furthermore, our\nproposed framework offers interpretability, indicating which modality the model\nidentifies as more likely to be fake. The source code is released at\nhttps://github.com/bok-bok/MSOC.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14176v3",
    "published_date": "2024-06-20 10:33:15 UTC",
    "updated_date": "2024-08-19 13:14:28 UTC"
  },
  {
    "arxiv_id": "2406.14171v1",
    "title": "Ranking LLMs by compression",
    "authors": [
      "Peijia Guo",
      "Ziguang Li",
      "Haibo Hu",
      "Chao Huang",
      "Ming Li",
      "Rui Zhang"
    ],
    "abstract": "We conceptualize the process of understanding as information compression, and\npropose a method for ranking large language models (LLMs) based on lossless\ndata compression. We demonstrate the equivalence of compression length under\narithmetic coding with cumulative negative log probabilities when using a large\nlanguage model as a prior, that is, the pre-training phase of the model is\nessentially the process of learning the optimal coding length. At the same\ntime, the evaluation metric compression ratio can be obtained without actual\ncompression, which greatly saves overhead. In this paper, we use five large\nlanguage models as priors for compression, then compare their performance on\nchallenging natural language processing tasks, including sentence completion,\nquestion answering, and coreference resolution. Experimental results show that\ncompression ratio and model performance are positively correlated, so it can be\nused as a general metric to evaluate large language models.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.14171v1",
    "published_date": "2024-06-20 10:23:38 UTC",
    "updated_date": "2024-06-20 10:23:38 UTC"
  },
  {
    "arxiv_id": "2406.14164v1",
    "title": "A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning",
    "authors": [
      "Panagiotis Kaliosis",
      "John Pavlopoulos",
      "Foivos Charalampakos",
      "Georgios Moschovis",
      "Ion Androutsopoulos"
    ],
    "abstract": "Diagnostic Captioning (DC) automatically generates a diagnostic text from one\nor more medical images (e.g., X-rays, MRIs) of a patient. Treated as a draft,\nthe generated text may assist clinicians, by providing an initial estimation of\nthe patient's condition, speeding up and helping safeguard the diagnostic\nprocess. The accuracy of a diagnostic text, however, strongly depends on how\nwell the key medical conditions depicted in the images are expressed. We\npropose a new data-driven guided decoding method that incorporates medical\ninformation, in the form of existing tags capturing key conditions of the\nimage(s), into the beam search of the diagnostic text generation process. We\nevaluate the proposed method on two medical datasets using four DC systems that\nrange from generic image-to-text systems with CNN encoders and RNN decoders to\npre-trained Large Language Models. The latter can also be used in few- and\nzero-shot learning scenarios. In most cases, the proposed mechanism improves\nperformance with respect to all evaluation measures. We provide an open-source\nimplementation of the proposed method at https://github.com/nlpaueb/dmmcs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "[Pre-print] ACL Findings 2024, 17 pages, 7 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.14164v1",
    "published_date": "2024-06-20 10:08:17 UTC",
    "updated_date": "2024-06-20 10:08:17 UTC"
  },
  {
    "arxiv_id": "2406.14162v4",
    "title": "DIRAS: Efficient LLM Annotation of Document Relevance in Retrieval Augmented Generation",
    "authors": [
      "Jingwei Ni",
      "Tobias Schimanski",
      "Meihong Lin",
      "Mrinmaya Sachan",
      "Elliott Ash",
      "Markus Leippold"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) is widely employed to ground responses\nto queries on domain-specific documents. But do RAG implementations leave out\nimportant information when answering queries that need an integrated analysis\nof information (e.g., Tell me good news in the stock market today.)? To address\nthese concerns, RAG developers need to annotate information retrieval (IR) data\nfor their domain of interest, which is challenging because (1) domain-specific\nqueries usually need nuanced definitions of relevance beyond shallow semantic\nrelevance; and (2) human or GPT-4 annotation is costly and cannot cover all\n(query, document) pairs (i.e., annotation selection bias), thus harming the\neffectiveness in evaluating IR recall. To address these challenges, we propose\nDIRAS (Domain-specific Information Retrieval Annotation with Scalability), a\nmanual-annotation-free schema that fine-tunes open-sourced LLMs to consider\nnuanced relevance definition and annotate (partial) relevance labels with\ncalibrated relevance scores. Extensive evaluation shows that DIRAS enables\nsmaller (8B) LLMs to achieve GPT-4-level performance on annotating and ranking\nunseen (query, document) pairs, and is helpful for real-world RAG development.\nAll code, LLM generations, and human annotations can be found in\n\\url{https://github.com/EdisonNi-hku/DIRAS}.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "NAACL 2025 Long",
    "pdf_url": "http://arxiv.org/pdf/2406.14162v4",
    "published_date": "2024-06-20 10:04:09 UTC",
    "updated_date": "2025-01-23 08:41:05 UTC"
  },
  {
    "arxiv_id": "2406.14144v1",
    "title": "Finding Safety Neurons in Large Language Models",
    "authors": [
      "Jianhui Chen",
      "Xiaozhi Wang",
      "Zijun Yao",
      "Yushi Bai",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Large language models (LLMs) excel in various capabilities but also pose\nsafety risks such as generating harmful content and misinformation, even after\nsafety alignment. In this paper, we explore the inner mechanisms of safety\nalignment from the perspective of mechanistic interpretability, focusing on\nidentifying and analyzing safety neurons within LLMs that are responsible for\nsafety behaviors. We propose generation-time activation contrasting to locate\nthese neurons and dynamic activation patching to evaluate their causal effects.\nExperiments on multiple recent LLMs show that: (1) Safety neurons are sparse\nand effective. We can restore $90$% safety performance with intervention only\non about $5$% of all the neurons. (2) Safety neurons encode transferrable\nmechanisms. They exhibit consistent effectiveness on different red-teaming\ndatasets. The finding of safety neurons also interprets \"alignment tax\". We\nobserve that the identified key neurons for safety and helpfulness\nsignificantly overlap, but they require different activation patterns of the\nshared neurons. Furthermore, we demonstrate an application of safety neurons in\ndetecting unsafe outputs before generation. Our findings may promote further\nresearch on understanding LLM alignment. The source codes will be publicly\nreleased to facilitate future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14144v1",
    "published_date": "2024-06-20 09:35:22 UTC",
    "updated_date": "2024-06-20 09:35:22 UTC"
  },
  {
    "arxiv_id": "2406.14141v1",
    "title": "Online Learning of Weakly Coupled MDP Policies for Load Balancing and Auto Scaling",
    "authors": [
      "S. R. Eshwar",
      "Lucas Lopes Felipe",
      "Alexandre Reiffers-Masson",
      "Daniel Sadoc Menasché",
      "Gugan Thoppe"
    ],
    "abstract": "Load balancing and auto scaling are at the core of scalable, contemporary\nsystems, addressing dynamic resource allocation and service rate adjustments in\nresponse to workload changes. This paper introduces a novel model and\nalgorithms for tuning load balancers coupled with auto scalers, considering\nbursty traffic arriving at finite queues. We begin by presenting the problem as\na weakly coupled Markov Decision Processes (MDP), solvable via a linear program\n(LP). However, as the number of control variables of such LP grows\ncombinatorially, we introduce a more tractable relaxed LP formulation, and\nextend it to tackle the problem of online parameter learning and policy\noptimization using a two-timescale algorithm based on the LP Lagrangian.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.NI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14141v1",
    "published_date": "2024-06-20 09:34:24 UTC",
    "updated_date": "2024-06-20 09:34:24 UTC"
  },
  {
    "arxiv_id": "2406.14135v1",
    "title": "Autonomous Robotic Drilling System for Mice Cranial Window Creation",
    "authors": [
      "Enduo Zhao",
      "Murilo M. Marinho",
      "Kanako Harada"
    ],
    "abstract": "Robotic assistance for experimental manipulation in the life sciences is\nexpected to enable favorable outcomes, regardless of the skill of the\nscientist. Experimental specimens in the life sciences are subject to\nindividual variability hence require intricate algorithms for successful\nautonomous robotic control. As a use case, we are studying the creation of\ncranial windows in mice. This operation requires the removal of an\n8-mm-circular patch of the skull, which is approximately 300 um thick, but the\nshape and thickness of the mouse skull significantly varies depending on the\nstrain of mouse, sex, and age. In this work, we propose an autonomous robotic\ndrilling method with no offline planning, consisting of a trajectory planning\nblock with execution-time feedback with completion level recognition based on\nimage and force information. The force information allows for completion-level\nresolution to increase 10 fold. We evaluate the proposed method in two ways.\nFirst, in an eggshell drilling task and achieved a success rate of 95% and\naverage drilling time of 7.1 min out of 20 trials. Second, in postmortem mice\nand with a success rate of 70% and average drilling time of 9.3 min out of 20\ntrials.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 14 figures, to be submitted to IEEE",
    "pdf_url": "http://arxiv.org/pdf/2406.14135v1",
    "published_date": "2024-06-20 09:23:23 UTC",
    "updated_date": "2024-06-20 09:23:23 UTC"
  },
  {
    "arxiv_id": "2406.14132v2",
    "title": "Enhancing Monotonic Modeling with Spatio-Temporal Adaptive Awareness in Diverse Marketing",
    "authors": [
      "Bin Li",
      "Jiayan Pei",
      "Feiyang Xiao",
      "Yifan Zhao",
      "Zhixing Zhang",
      "Diwei Liu",
      "HengXu He",
      "Jia Jia"
    ],
    "abstract": "In the mobile internet era, the Online Food Ordering Service (OFOS) emerges\nas an integral component of inclusive finance owing to the convenience it\nbrings to people. OFOS platforms offer dynamic allocation incentives to users\nand merchants through diverse marketing campaigns to encourage payments while\nmaintaining the platforms' budget efficiency. Despite significant progress, the\nmarketing domain continues to face two primary challenges: (i) how to allocate\na limited budget with greater efficiency, demanding precision in predicting\nusers' monotonic response (i.e. sensitivity) to incentives, and (ii) ensuring\nspatio-temporal adaptability and robustness in diverse marketing campaigns\nacross different times and locations. To address these issues, we propose a\nConstrained Monotonic Adaptive Network (CoMAN) method for spatio-temporal\nperception within marketing pricing. Specifically, we capture spatio-temporal\npreferences within attribute features through two foundational spatio-temporal\nperception modules. To further enhance catching the user sensitivity\ndifferentials to incentives across varied times and locations, we design\nmodules for learning spatio-temporal convexity and concavity as well as for\nexpressing sensitivity functions. CoMAN can achieve a more efficient allocation\nof incentive investments during pricing, thus increasing the conversion rate\nand orders while maintaining budget efficiency. Extensive offline and online\nexperimental results within our diverse marketing campaigns demonstrate the\neffectiveness of the proposed approach while outperforming the monotonic\nstate-of-the-art method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.14132v2",
    "published_date": "2024-06-20 09:21:09 UTC",
    "updated_date": "2025-05-10 08:27:03 UTC"
  },
  {
    "arxiv_id": "2406.14124v3",
    "title": "Measuring Sample Importance in Data Pruning for Language Models based on Information Entropy",
    "authors": [
      "Minsang Kim",
      "Seungjun Baek"
    ],
    "abstract": "Compute-efficient training of language models has become an important issue.\nWe consider data pruning for data-efficient training of LLMs. In this work, we\nconsider a data pruning method based on information entropy. We propose that\nthe samples in the training corpus be ranked in terms of their informativeness\nwhich we estimate through entropy functions. The key idea is that, less\ninformative samples are likely to contain redundant information, and thus\nshould be pruned first. We use the entropy functions based on the negative\nlog-likelihood and the average inverse word frequency of a sample as a\nsurrogate to measure its informativeness. Experiments reveal that the proposed\ninformation-based pruning can improve upon various language modeling and\ndownstream tasks, and enhance the generalization capability of language models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14124v3",
    "published_date": "2024-06-20 09:09:34 UTC",
    "updated_date": "2024-12-12 00:55:45 UTC"
  },
  {
    "arxiv_id": "2406.14122v1",
    "title": "EduQate: Generating Adaptive Curricula through RMABs in Education Settings",
    "authors": [
      "Sidney Tio",
      "Dexun Li",
      "Pradeep Varakantham"
    ],
    "abstract": "There has been significant interest in the development of personalized and\nadaptive educational tools that cater to a student's individual learning\nprogress. A crucial aspect in developing such tools is in exploring how mastery\ncan be achieved across a diverse yet related range of content in an efficient\nmanner. While Reinforcement Learning and Multi-armed Bandits have shown promise\nin educational settings, existing works often assume the independence of\nlearning content, neglecting the prevalent interdependencies between such\ncontent. In response, we introduce Education Network Restless Multi-armed\nBandits (EdNetRMABs), utilizing a network to represent the relationships\nbetween interdependent arms. Subsequently, we propose EduQate, a method\nemploying interdependency-aware Q-learning to make informed decisions on arm\nselection at each time step. We establish the optimality guarantee of EduQate\nand demonstrate its efficacy compared to baseline policies, using students\nmodeled from both synthetic and real-world data.",
    "categories": [
      "cs.AI",
      "I.2.8, I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, NeurIPS 2024 pre-print",
    "pdf_url": "http://arxiv.org/pdf/2406.14122v1",
    "published_date": "2024-06-20 09:07:10 UTC",
    "updated_date": "2024-06-20 09:07:10 UTC"
  },
  {
    "arxiv_id": "2406.14106v1",
    "title": "EasyECR: A Library for Easy Implementation and Evaluation of Event Coreference Resolution Models",
    "authors": [
      "Yuncong Li",
      "Tianhua Xu",
      "Sheng-hua Zhong",
      "Haiqin Yang"
    ],
    "abstract": "Event Coreference Resolution (ECR) is the task of clustering event mentions\nthat refer to the same real-world event. Despite significant advancements, ECR\nresearch faces two main challenges: limited generalizability across domains due\nto narrow dataset evaluations, and difficulties in comparing models within\ndiverse ECR pipelines. To address these issues, we develop EasyECR, the first\nopen-source library designed to standardize data structures and abstract ECR\npipelines for easy implementation and fair evaluation. More specifically,\nEasyECR integrates seven representative pipelines and ten popular benchmark\ndatasets, enabling model evaluations on various datasets and promoting the\ndevelopment of robust ECR pipelines. By conducting extensive evaluation via our\nEasyECR, we find that, \\lowercase\\expandafter{\\romannumeral1}) the\nrepresentative ECR pipelines cannot generalize across multiple datasets, hence\nevaluating ECR pipelines on multiple datasets is necessary,\n\\lowercase\\expandafter{\\romannumeral2}) all models in ECR pipelines have a\ngreat effect on pipeline performance, therefore, when one model in ECR\npipelines are compared, it is essential to ensure that the other models remain\nconsistent. Additionally, reproducing ECR results is not trivial, and the\ndeveloped library can help reduce this discrepancy. The experimental results\nprovide valuable baselines for future research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 4 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.14106v1",
    "published_date": "2024-06-20 08:40:21 UTC",
    "updated_date": "2024-06-20 08:40:21 UTC"
  },
  {
    "arxiv_id": "2406.14103v1",
    "title": "Two-Stage Depth Enhanced Learning with Obstacle Map For Object Navigation",
    "authors": [
      "Yanwei Zheng",
      "Shaopu Feng",
      "Bowen Huang",
      "Changrui Li",
      "Xiao Zhang",
      "Dongxiao Yu"
    ],
    "abstract": "The task that requires an agent to navigate to a given object through only\nvisual observation is called visual object navigation (VON). The main\nbottlenecks of VON are strategies exploration and prior knowledge exploitation.\nTraditional strategies exploration ignores the differences of searching and\nnavigating stages, using the same reward in two stages, which reduces\nnavigation performance and training efficiency. Our study enables the agent to\nexplore larger area in searching stage and seek the optimal path in navigating\nstage, improving the success rate of navigation. Traditional prior knowledge\nexploitation focused on learning and utilizing object association, which\nignored the depth and obstacle information in the environment. This paper uses\nthe RGB and depth information of the training scene to pretrain the feature\nextractor, which improves navigation efficiency. The obstacle information is\nmemorized by the agent during the navigation, reducing the probability of\ncollision and deadlock. Depth, obstacle and other prior knowledge are\nconcatenated and input into the policy network, and navigation actions are\noutput under the training of two-stage rewards. We evaluated our method on\nAI2-Thor and RoboTHOR and demonstrated that it significantly outperforms\nstate-of-the-art (SOTA) methods on success rate and navigation efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14103v1",
    "published_date": "2024-06-20 08:35:10 UTC",
    "updated_date": "2024-06-20 08:35:10 UTC"
  },
  {
    "arxiv_id": "2406.14097v2",
    "title": "Enhancing the LLM-Based Robot Manipulation Through Human-Robot Collaboration",
    "authors": [
      "Haokun Liu",
      "Yaonan Zhu",
      "Kenji Kato",
      "Atsushi Tsukahara",
      "Izumi Kondo",
      "Tadayoshi Aoyama",
      "Yasuhisa Hasegawa"
    ],
    "abstract": "Large Language Models (LLMs) are gaining popularity in the field of robotics.\nHowever, LLM-based robots are limited to simple, repetitive motions due to the\npoor integration between language models, robots, and the environment. This\npaper proposes a novel approach to enhance the performance of LLM-based\nautonomous manipulation through Human-Robot Collaboration (HRC). The approach\ninvolves using a prompted GPT-4 language model to decompose high-level language\ncommands into sequences of motions that can be executed by the robot. The\nsystem also employs a YOLO-based perception algorithm, providing visual cues to\nthe LLM, which aids in planning feasible motions within the specific\nenvironment. Additionally, an HRC method is proposed by combining teleoperation\nand Dynamic Movement Primitives (DMP), allowing the LLM-based robot to learn\nfrom human guidance. Real-world experiments have been conducted using the\nToyota Human Support Robot for manipulation tasks. The outcomes indicate that\ntasks requiring complex trajectory planning and reasoning over environments can\nbe efficiently accomplished through the incorporation of human demonstrations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE Robotics and Automation Letters",
    "pdf_url": "http://arxiv.org/pdf/2406.14097v2",
    "published_date": "2024-06-20 08:23:49 UTC",
    "updated_date": "2024-07-01 06:11:31 UTC"
  },
  {
    "arxiv_id": "2406.14096v3",
    "title": "Graph Neural Networks for Job Shop Scheduling Problems: A Survey",
    "authors": [
      "Igor G. Smit",
      "Jianan Zhou",
      "Robbert Reijnen",
      "Yaoxin Wu",
      "Jian Chen",
      "Cong Zhang",
      "Zaharah Bukhsh",
      "Yingqian Zhang",
      "Wim Nuijten"
    ],
    "abstract": "Job shop scheduling problems (JSSPs) represent a critical and challenging\nclass of combinatorial optimization problems. Recent years have witnessed a\nrapid increase in the application of graph neural networks (GNNs) to solve\nJSSPs, albeit lacking a systematic survey of the relevant literature. This\npaper aims to thoroughly review prevailing GNN methods for different types of\nJSSPs and the closely related flow-shop scheduling problems (FSPs), especially\nthose leveraging deep reinforcement learning (DRL). We begin by presenting the\ngraph representations of various JSSPs, followed by an introduction to the most\ncommonly used GNN architectures. We then review current GNN-based methods for\neach problem type, highlighting key technical elements such as graph\nrepresentations, GNN architectures, GNN tasks, and training algorithms.\nFinally, we summarize and analyze the advantages and limitations of GNNs in\nsolving JSSPs and provide potential future research opportunities. We hope this\nsurvey can motivate and inspire innovative approaches for more powerful\nGNN-based approaches in tackling JSSPs and other scheduling problems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by Computers & Operations Research",
    "pdf_url": "http://arxiv.org/pdf/2406.14096v3",
    "published_date": "2024-06-20 08:22:07 UTC",
    "updated_date": "2024-12-06 05:18:37 UTC"
  },
  {
    "arxiv_id": "2406.14095v2",
    "title": "Memory-Efficient Gradient Unrolling for Large-Scale Bi-level Optimization",
    "authors": [
      "Qianli Shen",
      "Yezhen Wang",
      "Zhouhao Yang",
      "Xiang Li",
      "Haonan Wang",
      "Yang Zhang",
      "Jonathan Scarlett",
      "Zhanxing Zhu",
      "Kenji Kawaguchi"
    ],
    "abstract": "Bi-level optimization (BO) has become a fundamental mathematical framework\nfor addressing hierarchical machine learning problems. As deep learning models\ncontinue to grow in size, the demand for scalable bi-level optimization\nsolutions has become increasingly critical. Traditional gradient-based bi-level\noptimization algorithms, due to their inherent characteristics, are ill-suited\nto meet the demands of large-scale applications. In this paper, we introduce\n$\\textbf{F}$orward $\\textbf{G}$radient $\\textbf{U}$nrolling with\n$\\textbf{F}$orward $\\textbf{F}$radient, abbreviated as\n$(\\textbf{FG})^2\\textbf{U}$, which achieves an unbiased stochastic\napproximation of the meta gradient for bi-level optimization.\n$(\\text{FG})^2\\text{U}$ circumvents the memory and approximation issues\nassociated with classical bi-level optimization approaches, and delivers\nsignificantly more accurate gradient estimates than existing large-scale\nbi-level optimization approaches. Additionally, $(\\text{FG})^2\\text{U}$ is\ninherently designed to support parallel computing, enabling it to effectively\nleverage large-scale distributed computing systems to achieve significant\ncomputational efficiency. In practice, $(\\text{FG})^2\\text{U}$ and other\nmethods can be strategically placed at different stages of the training process\nto achieve a more cost-effective two-phase paradigm. Further,\n$(\\text{FG})^2\\text{U}$ is easy to implement within popular deep learning\nframeworks, and can be conveniently adapted to address more challenging\nzeroth-order bi-level optimization scenarios. We provide a thorough convergence\nanalysis and a comprehensive practical discussion for $(\\text{FG})^2\\text{U}$,\ncomplemented by extensive empirical evaluations, showcasing its superior\nperformance in diverse large-scale bi-level optimization tasks. Code is\navailable at https://github.com/ShenQianli/FG2U.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14095v2",
    "published_date": "2024-06-20 08:21:52 UTC",
    "updated_date": "2024-12-24 10:44:10 UTC"
  },
  {
    "arxiv_id": "2406.14090v2",
    "title": "Emotion-aware Personalized Music Recommendation with a Heterogeneity-aware Deep Bayesian Network",
    "authors": [
      "Erkang Jing",
      "Yezheng Liu",
      "Yidong Chai",
      "Shuo Yu",
      "Longshun Liu",
      "Yuanchun Jiang",
      "Yang Wang"
    ],
    "abstract": "Music recommender systems play a critical role in music streaming platforms\nby providing users with music that they are likely to enjoy. Recent studies\nhave shown that user emotions can influence users' preferences for music moods.\nHowever, existing emotion-aware music recommender systems (EMRSs) explicitly or\nimplicitly assume that users' actual emotional states expressed through\nidentical emotional words are homogeneous. They also assume that users' music\nmood preferences are homogeneous under the same emotional state. In this\narticle, we propose four types of heterogeneity that an EMRS should account\nfor: emotion heterogeneity across users, emotion heterogeneity within a user,\nmusic mood preference heterogeneity across users, and music mood preference\nheterogeneity within a user. We further propose a Heterogeneity-aware Deep\nBayesian Network (HDBN) to model these assumptions. The HDBN mimics a user's\ndecision process of choosing music with four components: personalized prior\nuser emotion distribution modeling, posterior user emotion distribution\nmodeling, user grouping, and Bayesian neural network-based music mood\npreference prediction. We constructed two datasets, called EmoMusicLJ and\nEmoMusicLJ-small, to validate our method. Extensive experiments demonstrate\nthat our method significantly outperforms baseline approaches on metrics of HR,\nPrecision, NDCG, and MRR. Ablation studies and case studies further validate\nthe effectiveness of our HDBN. The source code and datasets are available at\nhttps://github.com/jingrk/HDBN.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "43 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.14090v2",
    "published_date": "2024-06-20 08:12:11 UTC",
    "updated_date": "2024-11-29 13:43:59 UTC"
  },
  {
    "arxiv_id": "2406.14088v2",
    "title": "ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation",
    "authors": [
      "Zhiyu Mei",
      "Wei Fu",
      "Kaiwei Li",
      "Guangju Wang",
      "Huanchen Zhang",
      "Yi Wu"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for\nempowering large language model (LLM) applications. Compared with the\nsupervised training process of LLMs, the RLHF training process is much more\nsophisticated, requiring a diverse range of computation workloads with\nintricate dependencies between multiple LLM instances. Therefore, simply\nadopting the fixed parallelization strategies from supervised training for LLMs\ncan be insufficient for RLHF and result in low training efficiency. To overcome\nthis limitation, we propose a novel technique named parameter ReaLlocation,\nwhich dynamically adapts the parallelization strategies for different workloads\nduring training by redistributing LLM parameters across the training cluster.\nBuilding upon this idea, we introduce ReaL, a pioneering system for efficient\nRLHF training. ReaL introduces the concept of an execution plan, which defines\na fine-grained resource allocation and parallelization strategy particularly\ndesigned for RLHF training. Based on this concept, ReaL employs a tailored\nsearch algorithm with a lightweight run-time estimator to automatically\ndiscover an efficient execution plan for an instance of RLHF experiment.\nSubsequently, the runtime engine deploys the selected plan by effectively\nparallelizing computations and redistributing parameters. We evaluate ReaL on\nthe LLaMA models with up to 70 billion parameters and 128 GPUs. The\nexperimental results demonstrate that ReaL achieves speedups of up to\n$3.58\\times$ compared to baseline methods. Furthermore, the execution plans\ngenerated by ReaL exhibit an average of $81\\%$ performance improvement over\nheuristic approaches based on Megatron-LM in the long-context scenario. The\nsource code of ReaL is publicly available at\nhttps://github.com/openpsi-project/ReaLHF .",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "11 pages (20 pages with references and the appendix), 17 figures.\n  Accepted by MLSys 25",
    "pdf_url": "http://arxiv.org/pdf/2406.14088v2",
    "published_date": "2024-06-20 08:04:07 UTC",
    "updated_date": "2025-04-24 13:24:42 UTC"
  },
  {
    "arxiv_id": "2406.14087v1",
    "title": "Semi Supervised Heterogeneous Domain Adaptation via Disentanglement and Pseudo-Labelling",
    "authors": [
      "Cassio F. Dantas",
      "Raffaele Gaetano",
      "Dino Ienco"
    ],
    "abstract": "Semi-supervised domain adaptation methods leverage information from a source\nlabelled domain with the goal of generalizing over a scarcely labelled target\ndomain. While this setting already poses challenges due to potential\ndistribution shifts between domains, an even more complex scenario arises when\nsource and target data differs in modality representation (e.g. they are\nacquired by sensors with different characteristics). For instance, in remote\nsensing, images may be collected via various acquisition modes (e.g. optical or\nradar), different spectral characteristics (e.g. RGB or multi-spectral) and\nspatial resolutions. Such a setting is denoted as Semi-Supervised Heterogeneous\nDomain Adaptation (SSHDA) and it exhibits an even more severe distribution\nshift due to modality heterogeneity across domains.To cope with the challenging\nSSHDA setting, here we introduce SHeDD (Semi-supervised Heterogeneous Domain\nAdaptation via Disentanglement) an end-to-end neural framework tailored to\nlearning a target domain classifier by leveraging both labelled and unlabelled\ndata from heterogeneous data sources. SHeDD is designed to effectively\ndisentangle domain-invariant representations, relevant for the downstream task,\nfrom domain-specific information, that can hinder the cross-modality transfer.\nAdditionally, SHeDD adopts an augmentation-based consistency regularization\nmechanism that takes advantages of reliable pseudo-labels on the unlabelled\ntarget samples to further boost its generalization ability on the target\ndomain. Empirical evaluations on two remote sensing benchmarks, encompassing\nheterogeneous data in terms of acquisition modes and spectral/spatial\nresolutions, demonstrate the quality of SHeDD compared to both baseline and\nstate-of-the-art competing approaches. Our code is publicly available here:\nhttps://github.com/tanodino/SSHDA/",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14087v1",
    "published_date": "2024-06-20 08:02:49 UTC",
    "updated_date": "2024-06-20 08:02:49 UTC"
  },
  {
    "arxiv_id": "2406.14086v1",
    "title": "Seg-LSTM: Performance of xLSTM for Semantic Segmentation of Remotely Sensed Images",
    "authors": [
      "Qinfeng Zhu",
      "Yuanzhi Cai",
      "Lei Fan"
    ],
    "abstract": "Recent advancements in autoregressive networks with linear complexity have\ndriven significant research progress, demonstrating exceptional performance in\nlarge language models. A representative model is the Extended Long Short-Term\nMemory (xLSTM), which incorporates gating mechanisms and memory structures,\nperforming comparably to Transformer architectures in long-sequence language\ntasks. Autoregressive networks such as xLSTM can utilize image serialization to\nextend their application to visual tasks such as classification and\nsegmentation. Although existing studies have demonstrated Vision-LSTM's\nimpressive results in image classification, its performance in image semantic\nsegmentation remains unverified. Our study represents the first attempt to\nevaluate the effectiveness of Vision-LSTM in the semantic segmentation of\nremotely sensed images. This evaluation is based on a specifically designed\nencoder-decoder architecture named Seg-LSTM, and comparisons with\nstate-of-the-art segmentation networks. Our study found that Vision-LSTM's\nperformance in semantic segmentation was limited and generally inferior to\nVision-Transformers-based and Vision-Mamba-based models in most comparative\ntests. Future research directions for enhancing Vision-LSTM are recommended.\nThe source code is available from https://github.com/zhuqinfeng1999/Seg-LSTM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14086v1",
    "published_date": "2024-06-20 08:01:28 UTC",
    "updated_date": "2024-06-20 08:01:28 UTC"
  },
  {
    "arxiv_id": "2406.14085v1",
    "title": "Teaching Models To Survive: Proper Scoring Rule and Stochastic Optimization with Competing Risks",
    "authors": [
      "Julie Alberge",
      "Vincent Maladière",
      "Olivier Grisel",
      "Judith Abécassis",
      "Gaël Varoquaux"
    ],
    "abstract": "When data are right-censored, i.e. some outcomes are missing due to a limited\nperiod of observation, survival analysis can compute the \"time to event\".\nMultiple classes of outcomes lead to a classification variant: predicting the\nmost likely event, known as competing risks, which has been less studied. To\nbuild a loss that estimates outcome probabilities for such settings, we\nintroduce a strictly proper censoring-adjusted separable scoring rule that can\nbe optimized on a subpart of the data because the evaluation is made\nindependently of observations. It enables stochastic optimization for competing\nrisks which we use to train gradient boosting trees. Compared to 11\nstate-of-the-art models, this model, MultiIncidence, performs best in\nestimating the probability of outcomes in survival and competing risks. It can\npredict at any time horizon and is much faster than existing alternatives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14085v1",
    "published_date": "2024-06-20 08:00:42 UTC",
    "updated_date": "2024-06-20 08:00:42 UTC"
  },
  {
    "arxiv_id": "2406.14073v1",
    "title": "Exploring Layerwise Adversarial Robustness Through the Lens of t-SNE",
    "authors": [
      "Inês Valentim",
      "Nuno Antunes",
      "Nuno Lourenço"
    ],
    "abstract": "Adversarial examples, designed to trick Artificial Neural Networks (ANNs)\ninto producing wrong outputs, highlight vulnerabilities in these models.\nExploring these weaknesses is crucial for developing defenses, and so, we\npropose a method to assess the adversarial robustness of image-classifying\nANNs. The t-distributed Stochastic Neighbor Embedding (t-SNE) technique is used\nfor visual inspection, and a metric, which compares the clean and perturbed\nembeddings, helps pinpoint weak spots in the layers. Analyzing two ANNs on\nCIFAR-10, one designed by humans and another via NeuroEvolution, we found that\ndifferences between clean and perturbed representations emerge early on, in the\nfeature extraction layers, affecting subsequent classification. The findings\nwith our metric are supported by the visual analysis of the t-SNE maps.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14073v1",
    "published_date": "2024-06-20 07:50:11 UTC",
    "updated_date": "2024-06-20 07:50:11 UTC"
  },
  {
    "arxiv_id": "2406.14066v2",
    "title": "Optimizing Speculative Decoding for Serving Large Language Models Using Goodput",
    "authors": [
      "Xiaoxuan Liu",
      "Cade Daniel",
      "Langxiang Hu",
      "Woosuk Kwon",
      "Zhuohan Li",
      "Xiangxi Mo",
      "Alvin Cheung",
      "Zhijie Deng",
      "Ion Stoica",
      "Hao Zhang"
    ],
    "abstract": "Reducing the inference latency of large language models (LLMs) is crucial,\nand speculative decoding (SD) stands out as one of the most effective\ntechniques. Rather than letting the LLM generate all tokens directly,\nspeculative decoding employs effective proxies to predict potential outputs,\nwhich are then verified by the LLM without compromising the generation quality.\nYet, deploying SD in real online LLM serving systems (with continuous batching)\ndoes not always yield improvement -- under higher request rates or low\nspeculation accuracy, it paradoxically increases latency. Furthermore, there is\nno best speculation length work for all workloads under different system loads.\nBased on the observations, we develop a dynamic framework SmartSpec. SmartSpec\ndynamically determines the best speculation length for each request (from 0,\ni.e., no speculation, to many tokens) -- hence the associated speculative\nexecution costs -- based on a new metric called goodput, which characterizes\nthe current observed load of the entire system and the speculation accuracy. We\nshow that SmartSpec consistently reduces average request latency by up to 3.2x\ncompared to non-speculative decoding baselines across different sizes of target\nmodels, draft models, request rates, and datasets. Moreover, SmartSpec can be\napplied to different styles of speculative decoding, including traditional,\nmodel-based approaches as well as model-free methods like prompt lookup and\ntree-style decoding.",
    "categories": [
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14066v2",
    "published_date": "2024-06-20 07:43:33 UTC",
    "updated_date": "2024-06-25 20:53:16 UTC"
  },
  {
    "arxiv_id": "2406.14051v1",
    "title": "How Many Parameters Does it Take to Change a Light Bulb? Evaluating Performance in Self-Play of Conversational Games as a Function of Model Characteristics",
    "authors": [
      "Nidhir Bhavsar",
      "Jonathan Jordan",
      "Sherzod Hakimov",
      "David Schlangen"
    ],
    "abstract": "What makes a good Large Language Model (LLM)? That it performs well on the\nrelevant benchmarks -- which hopefully measure, with some validity, the\npresence of capabilities that are also challenged in real application. But what\nmakes the model perform well? What gives a model its abilities? We take a\nrecently introduced type of benchmark that is meant to challenge capabilities\nin a goal-directed, agentive context through self-play of conversational games,\nand analyse how performance develops as a function of model characteristics\nlike number of parameters, or type of training. We find that while there is a\nclear relationship between number of parameters and performance, there is still\na wide spread of performance points within a given size bracket, which is to be\naccounted for by training parameters such as fine-tuning data quality and\nmethod. From a more practical angle, we also find a certain degree of\nunpredictability about performance across access methods, possible due to\nunexposed sampling parameters, and a, very welcome, performance stability\nagainst at least moderate weight quantisation during inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2406.14051v1",
    "published_date": "2024-06-20 07:17:09 UTC",
    "updated_date": "2024-06-20 07:17:09 UTC"
  },
  {
    "arxiv_id": "2406.14045v2",
    "title": "LTSM-Bundle: A Toolbox and Benchmark on Large Language Models for Time Series Forecasting",
    "authors": [
      "Yu-Neng Chuang",
      "Songchen Li",
      "Jiayi Yuan",
      "Guanchu Wang",
      "Kwei-Herng Lai",
      "Songyuan Sui",
      "Leisheng Yu",
      "Sirui Ding",
      "Chia-Yuan Chang",
      "Qiaoyu Tan",
      "Daochen Zha",
      "Xia Hu"
    ],
    "abstract": "Time Series Forecasting (TSF) has long been a challenge in time series\nanalysis. Inspired by the success of Large Language Models (LLMs), researchers\nare now developing Large Time Series Models (LTSMs)-universal transformer-based\nmodels that use autoregressive prediction-to improve TSF. However, training\nLTSMs on heterogeneous time series data poses unique challenges, including\ndiverse frequencies, dimensions, and patterns across datasets. Recent endeavors\nhave studied and evaluated various design choices aimed at enhancing LTSM\ntraining and generalization capabilities. However, these design choices are\ntypically studied and evaluated in isolation and are not benchmarked\ncollectively. In this work, we introduce LTSM-Bundle, a comprehensive toolbox,\nand benchmark for training LTSMs, spanning pre-processing techniques, model\nconfigurations, and dataset configuration. It modularized and benchmarked LTSMs\nfrom multiple dimensions, encompassing prompting strategies, tokenization\napproaches, training paradigms, base model selection, data quantity, and\ndataset diversity. Furthermore, we combine the most effective design choices\nidentified in our study. Empirical results demonstrate that this combination\nachieves superior zero-shot and few-shot performances compared to\nstate-of-the-art LTSMs and traditional TSF methods on benchmark datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14045v2",
    "published_date": "2024-06-20 07:09:19 UTC",
    "updated_date": "2025-02-27 23:12:38 UTC"
  },
  {
    "arxiv_id": "2406.14039v1",
    "title": "CryptoGPT: a 7B model rivaling GPT-4 in the task of analyzing and classifying real-time financial news",
    "authors": [
      "Ying Zhang",
      "Matthieu Petit Guillaume",
      "Aurélien Krauth",
      "Manel Labidi"
    ],
    "abstract": "CryptoGPT: a 7B model competing with GPT-4 in a specific task -- The Impact\nof Automatic Annotation and Strategic Fine-Tuning via QLoRAIn this article, we\npresent a method aimed at refining a dedicated LLM of reasonable quality with\nlimited resources in an industrial setting via CryptoGPT. It is an LLM designed\nfor financial news analysis for the cryptocurrency market in real-time. This\nproject was launched in an industrial context. This model allows not only for\nthe classification of financial information but also for providing\ncomprehensive analysis. We refined different LLMs of the same size such as\nMistral-7B and LLama-7B using semi-automatic annotation and compared them with\nvarious LLMs such as GPT-3.5 and GPT-4. Our goal is to find a balance among\nseveral needs: 1. Protecting data (by avoiding their transfer to external\nservers), 2. Limiting annotation cost and time, 3. Controlling the model's size\n(to manage deployment costs), and 4. Maintaining better analysis quality.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "Journ{\\'e}e Nationale sur la Fouille de Textes, Pascal CUXAC; Adrien\n  GUILLE; C{\\'e}dric LOPEZ, Jun 2024, Lyon (Universit{\\'e} Lumi{\\`e}re Lyon 2),\n  France",
    "pdf_url": "http://arxiv.org/pdf/2406.14039v1",
    "published_date": "2024-06-20 06:59:46 UTC",
    "updated_date": "2024-06-20 06:59:46 UTC"
  },
  {
    "arxiv_id": "2406.14038v2",
    "title": "Resource-efficient Medical Image Analysis with Self-adapting Forward-Forward Networks",
    "authors": [
      "Johanna P. Müller",
      "Bernhard Kainz"
    ],
    "abstract": "We introduce a fast Self-adapting Forward-Forward Network (SaFF-Net) for\nmedical imaging analysis, mitigating power consumption and resource\nlimitations, which currently primarily stem from the prevalent reliance on\nback-propagation for model training and fine-tuning. Building upon the recently\nproposed Forward-Forward Algorithm (FFA), we introduce the Convolutional\nForward-Forward Algorithm (CFFA), a parameter-efficient reformulation that is\nsuitable for advanced image analysis and overcomes the speed and generalisation\nconstraints of the original FFA. To address hyper-parameter sensitivity of FFAs\nwe are also introducing a self-adapting framework SaFF-Net fine-tuning\nparameters during warmup and training in parallel. Our approach enables more\neffective model training and eliminates the previously essential requirement\nfor an arbitrarily chosen Goodness function in FFA. We evaluate our approach on\nseveral benchmarking datasets in comparison with standard Back-Propagation (BP)\nneural networks showing that FFA-based networks with notably fewer parameters\nand function evaluations can compete with standard models, especially, in\none-shot scenarios and large batch sizes. The code will be available at the\ntime of the conference.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for MICCAI Workshop MLMI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.14038v2",
    "published_date": "2024-06-20 06:58:09 UTC",
    "updated_date": "2024-07-17 11:35:37 UTC"
  },
  {
    "arxiv_id": "2406.14036v2",
    "title": "Towards Infinite-Long Prefix in Transformer",
    "authors": [
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Chiwun Yang"
    ],
    "abstract": "Prompting and context-based fine-tuning methods, which we call Prefix\nLearning, have been proposed to enhance the performance of language models on\nvarious downstream tasks. They are empirically efficient and effective,\nmatching the performance of full parameter fine-tuning, but the theoretical\nunderstandings are limited. In this paper, we aim to address this limitation by\nstudying their ability from the perspective of prefix length. In particular, we\nprovide a convergence guarantee for training an ultra-long prefix in a stylized\nsetting using the Neural Tangent Kernel (NTK) framework. Based on this strong\ntheoretical guarantee, we design and implement an algorithm that only needs to\nintroduce and fine-tune a few extra trainable parameters instead of an\ninfinite-long prefix in each layer of a transformer, and can approximate the\nprefix attention to a guaranteed polynomial-small error. Preliminary\nexperimental results on vision, natural language, and math data show that our\nmethod achieves superior or competitive performance compared to existing\nmethods like full parameters fine-tuning, P-Tuning V2, and LoRA. This\ndemonstrates our method is promising for parameter-efficient fine-tuning. Our\ncode can be found at\n\\url{https://github.com/ChristianYang37/chiwun/tree/main/src/NTK-Attention}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14036v2",
    "published_date": "2024-06-20 06:56:35 UTC",
    "updated_date": "2024-10-16 06:33:44 UTC"
  },
  {
    "arxiv_id": "2406.14035v3",
    "title": "Using Game Play to Investigate Multimodal and Conversational Grounding in Large Multimodal Models",
    "authors": [
      "Sherzod Hakimov",
      "Yerkezhan Abdullayeva",
      "Kushal Koshti",
      "Antonia Schmidt",
      "Yan Weiser",
      "Anne Beyer",
      "David Schlangen"
    ],
    "abstract": "While the situation has improved for text-only models, it again seems to be\nthe case currently that multimodal (text and image) models develop faster than\nways to evaluate them. In this paper, we bring a recently developed evaluation\nparadigm from text models to multimodal models, namely evaluation through the\ngoal-oriented game (self) play, complementing reference-based and\npreference-based evaluation. Specifically, we define games that challenge a\nmodel's capability to represent a situation from visual information and align\nsuch representations through dialogue. We find that the largest closed models\nperform rather well on the games that we define, while even the best\nopen-weight models struggle with them. On further analysis, we find that the\nexceptional deep captioning capabilities of the largest models drive some of\nthe performance. There is still room to grow for both kinds of models, ensuring\nthe continued relevance of the benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.14035v3",
    "published_date": "2024-06-20 06:56:19 UTC",
    "updated_date": "2024-12-11 09:56:15 UTC"
  },
  {
    "arxiv_id": "2406.14027v1",
    "title": "How to design a dataset compliant with an ML-based system ODD?",
    "authors": [
      "Cyril Cappi",
      "Noémie Cohen",
      "Mélanie Ducoffe",
      "Christophe Gabreau",
      "Laurent Gardes",
      "Adrien Gauffriau",
      "Jean-Brice Ginestet",
      "Franck Mamalet",
      "Vincent Mussot",
      "Claire Pagetti",
      "David Vigouroux"
    ],
    "abstract": "This paper focuses on a Vision-based Landing task and presents the design and\nthe validation of a dataset that would comply with the Operational Design\nDomain (ODD) of a Machine-Learning (ML) system. Relying on emerging\ncertification standards, we describe the process for establishing ODDs at both\nthe system and image levels. In the process, we present the translation of\nhigh-level system constraints into actionable image-level properties, allowing\nfor the definition of verifiable Data Quality Requirements (DQRs). To\nillustrate this approach, we use the Landing Approach Runway Detection (LARD)\ndataset which combines synthetic imagery and real footage, and we focus on the\nsteps required to verify the DQRs. The replicable framework presented in this\npaper addresses the challenges of designing a dataset compliant with the\nstringent needs of ML-based systems certification in safety-critical\napplications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12th European Congress on Embedded Real Time Software and Systems,\n  Jun 2024, Toulouse, France. arXiv admin note: text overlap with\n  arXiv:2304.09938",
    "pdf_url": "http://arxiv.org/pdf/2406.14027v1",
    "published_date": "2024-06-20 06:48:34 UTC",
    "updated_date": "2024-06-20 06:48:34 UTC"
  },
  {
    "arxiv_id": "2406.14023v2",
    "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
    "authors": [
      "Yuchen Wen",
      "Keping Bi",
      "Wei Chen",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "As large language models (LLMs) become an important way of information\naccess, there have been increasing concerns that LLMs may intensify the spread\nof unethical content, including implicit bias that hurts certain populations\nwithout explicit harmful words. In this paper, we conduct a rigorous evaluation\nof LLMs' implicit bias towards certain demographics by attacking them from a\npsychometric perspective to elicit agreements to biased viewpoints. Inspired by\npsychometric principles in cognitive and social psychology, we propose three\nattack approaches, i.e., Disguise, Deception, and Teaching. Incorporating the\ncorresponding attack instructions, we built two benchmarks: (1) a bilingual\ndataset with biased statements covering four bias types (2.7K instances) for\nextensive comparative analysis, and (2) BUMBLE, a larger benchmark spanning\nnine common bias types (12.7K instances) for comprehensive evaluation.\nExtensive evaluation of popular commercial and open-source LLMs shows that our\nmethods can elicit LLMs' inner bias more effectively than competitive\nbaselines. Our attack methodology and benchmarks offer an effective means of\nassessing the ethical risks of LLMs, driving progress toward greater\naccountability in their development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code, data and benchmarks are available at\n  https://github.com/yuchenwen1/ImplicitBiasPsychometricEvaluation and\n  https://github.com/yuchenwen1/BUMBLE",
    "pdf_url": "http://arxiv.org/pdf/2406.14023v2",
    "published_date": "2024-06-20 06:42:08 UTC",
    "updated_date": "2025-02-19 03:37:38 UTC"
  },
  {
    "arxiv_id": "2406.14020v1",
    "title": "Leveraging eBPF and AI for Ransomware Nose Out",
    "authors": [
      "Arjun Sekar",
      "Sameer G. Kulkarni",
      "Joy Kuri"
    ],
    "abstract": "In this work, we propose a two-phased approach for real-time detection and\ndeterrence of ransomware. To achieve this, we leverage the capabilities of eBPF\n(Extended Berkeley Packet Filter) and artificial intelligence to develop both\nproactive and reactive methods. In the first phase, we utilize signature based\ndetection, where we employ custom eBPF programs to trace the execution of new\nprocesses and perform hash-based analysis against a known ransomware dataset.\nIn the second, we employ a behavior-based technique that focuses on monitoring\nthe process activities using a custom eBPF program and the creation of ransom\nnotes, a prominent indicator of ransomware activity through the use of Natural\nLanguage Processing (NLP). By leveraging low-level tracing capabilities of eBPF\nand integrating NLP based machine learning algorithms, our solution achieves an\nimpressive 99.76% accuracy in identifying ransomware incidents within a few\nseconds on the onset of zero-day attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.14020v1",
    "published_date": "2024-06-20 06:35:15 UTC",
    "updated_date": "2024-06-20 06:35:15 UTC"
  },
  {
    "arxiv_id": "2406.14014v1",
    "title": "Feature Fusion Based on Mutual-Cross-Attention Mechanism for EEG Emotion Recognition",
    "authors": [
      "Yimin Zhao",
      "Jin Gu"
    ],
    "abstract": "An objective and accurate emotion diagnostic reference is vital to\npsychologists, especially when dealing with patients who are difficult to\ncommunicate with for pathological reasons. Nevertheless, current systems based\non Electroencephalography (EEG) data utilized for sentiment discrimination have\nsome problems, including excessive model complexity, mediocre accuracy, and\nlimited interpretability. Consequently, we propose a novel and effective\nfeature fusion mechanism named Mutual-Cross-Attention (MCA). Combining with a\nspecially customized 3D Convolutional Neural Network (3D-CNN), this purely\nmathematical mechanism adeptly discovers the complementary relationship between\ntime-domain and frequency-domain features in EEG data. Furthermore, the new\ndesigned Channel-PSD-DE 3D feature also contributes to the high performance.\nThe proposed method eventually achieves 99.49% (valence) and 99.30% (arousal)\naccuracy on DEAP dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The work has been accepted by MICCAI 2024. The uploaded one is\n  preprint which has not undergone peer review (when applicable) or any\n  post-submission improvements or corrections. The official DOI link will be\n  provided once available",
    "pdf_url": "http://arxiv.org/pdf/2406.14014v1",
    "published_date": "2024-06-20 06:08:52 UTC",
    "updated_date": "2024-06-20 06:08:52 UTC"
  },
  {
    "arxiv_id": "2406.14012v1",
    "title": "Seeing Through AI's Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News",
    "authors": [
      "Navid Ayoobi",
      "Sadat Shahriar",
      "Arjun Mukherjee"
    ],
    "abstract": "LLMs offer valuable capabilities, yet they can be utilized by malicious users\nto disseminate deceptive information and generate fake news. The growing\nprevalence of LLMs poses difficulties in crafting detection approaches that\nremain effective across various text domains. Additionally, the absence of\nprecautionary measures for AI-generated news on online social platforms is\nconcerning. Therefore, there is an urgent need to improve people's ability to\ndifferentiate between news articles written by humans and those produced by\nLLMs. By providing cues in human-written and LLM-generated news, we can help\nindividuals increase their skepticism towards fake LLM-generated news. This\npaper aims to elucidate simple markers that help individuals distinguish\nbetween articles penned by humans and those created by LLMs. To achieve this,\nwe initially collected a dataset comprising 39k news articles authored by\nhumans or generated by four distinct LLMs with varying degrees of fake. We then\ndevise a metric named Entropy-Shift Authorship Signature (ESAS) based on the\ninformation theory and entropy principles. The proposed ESAS ranks terms or\nentities, like POS tagging, within news articles based on their relevance in\ndiscerning article authorship. We demonstrate the effectiveness of our metric\nby showing the high accuracy attained by a basic method, i.e., TF-IDF combined\nwith logistic regression classifier, using a small set of terms with the\nhighest ESAS score. Consequently, we introduce and scrutinize these top\nESAS-ranked terms to aid individuals in strengthening their skepticism towards\nLLM-generated fake news.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14012v1",
    "published_date": "2024-06-20 06:02:04 UTC",
    "updated_date": "2024-06-20 06:02:04 UTC"
  },
  {
    "arxiv_id": "2406.14005v2",
    "title": "Information Guided Regularization for Fine-tuning Language Models",
    "authors": [
      "Mandar Sharma",
      "Nikhil Muralidhar",
      "Shengzhe Xu",
      "Raquib Bin Yousuf",
      "Naren Ramakrishnan"
    ],
    "abstract": "The pretraining-fine-tuning paradigm has been the de facto strategy for\ntransfer learning in modern language modeling. With the understanding that task\nadaptation in LMs is often a function of parameters shared across tasks, we\nargue that a more surgical approach to regularization needs to exist for\nsmoother transfer learning. Towards this end, we investigate how the\npretraining loss landscape is affected by these task-sensitive parameters\nthrough an information-theoretic lens. We then leverage the findings from our\ninvestigations to devise a novel approach to dropout for improved model\nregularization and better downstream generalization. This approach, named\nguided dropout, is both task & architecture agnostic and adds no computational\noverhead to the fine-tuning process. Through empirical evaluations, we showcase\nthat our approach to regularization yields consistently better performance,\neven in scenarios of data paucity, compared to standardized baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14005v2",
    "published_date": "2024-06-20 05:18:37 UTC",
    "updated_date": "2024-06-21 12:41:17 UTC"
  },
  {
    "arxiv_id": "2406.14003v3",
    "title": "Deep Optimal Experimental Design for Parameter Estimation Problems",
    "authors": [
      "Md Shahriar Rahim Siddiqui",
      "Arman Rahmim",
      "Eldad Haber"
    ],
    "abstract": "Optimal experimental design is a well studied field in applied science and\nengineering. Techniques for estimating such a design are commonly used within\nthe framework of parameter estimation. Nonetheless, in recent years parameter\nestimation techniques are changing rapidly with the introduction of deep\nlearning techniques to replace traditional estimation methods. This in turn\nrequires the adaptation of optimal experimental design that is associated with\nthese new techniques. In this paper we investigate a new experimental design\nmethodology that uses deep learning. We show that the training of a network as\na Likelihood Free Estimator can be used to significantly simplify the design\nprocess and circumvent the need for the computationally expensive bi-level\noptimization problem that is inherent in optimal experimental design for\nnon-linear systems. Furthermore, deep design improves the quality of the\nrecovery process for parameter estimation problems. As proof of concept we\napply our methodology to two different systems of Ordinary Differential\nEquations.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14003v3",
    "published_date": "2024-06-20 05:13:33 UTC",
    "updated_date": "2024-10-16 16:51:13 UTC"
  },
  {
    "arxiv_id": "2406.13975v3",
    "title": "MR-Ben: A Meta-Reasoning Benchmark for Evaluating System-2 Thinking in LLMs",
    "authors": [
      "Zhongshen Zeng",
      "Yinhong Liu",
      "Yingjia Wan",
      "Jingyao Li",
      "Pengguang Chen",
      "Jianbo Dai",
      "Yuxuan Yao",
      "Rongwu Xu",
      "Zehan Qi",
      "Wanru Zhao",
      "Linling Shen",
      "Jianqiao Lu",
      "Haochen Tan",
      "Yukang Chen",
      "Hao Zhang",
      "Zhan Shi",
      "Bailin Wang",
      "Zhijiang Guo",
      "Jiaya Jia"
    ],
    "abstract": "Large language models (LLMs) have shown increasing capability in\nproblem-solving and decision-making, largely based on the step-by-step\nchain-of-thought reasoning processes. However, evaluating these reasoning\nabilities has become increasingly challenging. Existing outcome-based\nbenchmarks are beginning to saturate, becoming less effective in tracking\nmeaningful progress. To address this, we present a process-based benchmark\nMR-Ben that demands a meta-reasoning skill, where LMs are asked to locate and\nanalyse potential errors in automatically generated reasoning steps. Our\nmeta-reasoning paradigm is especially suited for system-2 slow thinking,\nmirroring the human cognitive process of carefully examining assumptions,\nconditions, calculations, and logic to identify mistakes.MR-Ben comprises 5,975\nquestions curated by human experts across a wide range of subjects, including\nphysics, chemistry, logic, coding, and more. Through our designed metrics for\nassessing meta-reasoning on this benchmark, we identify interesting limitations\nand weaknesses of current LLMs (open-source and closed-source models). For\nexample, with models like the o1 series from OpenAI demonstrating strong\nperformance by effectively scrutinizing the solution space, many other\nstate-of-the-art models fall significantly behind on MR-Ben, exposing potential\nshortcomings in their training strategies and inference methodologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13975v3",
    "published_date": "2024-06-20 03:50:23 UTC",
    "updated_date": "2024-12-20 12:52:00 UTC"
  },
  {
    "arxiv_id": "2406.15249v1",
    "title": "Machine Learning Techniques in Automatic Music Transcription: A Systematic Survey",
    "authors": [
      "Fatemeh Jamshidi",
      "Gary Pike",
      "Amit Das",
      "Richard Chapman"
    ],
    "abstract": "In the domain of Music Information Retrieval (MIR), Automatic Music\nTranscription (AMT) emerges as a central challenge, aiming to convert audio\nsignals into symbolic notations like musical notes or sheet music. This\nsystematic review accentuates the pivotal role of AMT in music signal analysis,\nemphasizing its importance due to the intricate and overlapping spectral\nstructure of musical harmonies. Through a thorough examination of existing\nmachine learning techniques utilized in AMT, we explore the progress and\nconstraints of current models and methodologies. Despite notable advancements,\nAMT systems have yet to match the accuracy of human experts, largely due to the\ncomplexities of musical harmonies and the need for nuanced interpretation. This\nreview critically evaluates both fully automatic and semi-automatic AMT\nsystems, emphasizing the importance of minimal user intervention and examining\nvarious methodologies proposed to date. By addressing the limitations of prior\ntechniques and suggesting avenues for improvement, our objective is to steer\nfuture research towards fully automated AMT systems capable of accurately and\nefficiently translating intricate audio signals into precise symbolic\nrepresentations. This study not only synthesizes the latest advancements but\nalso lays out a road-map for overcoming existing challenges in AMT, providing\nvaluable insights for researchers aiming to narrow the gap between current\nsystems and human-level transcription accuracy.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15249v1",
    "published_date": "2024-06-20 03:48:15 UTC",
    "updated_date": "2024-06-20 03:48:15 UTC"
  },
  {
    "arxiv_id": "2406.15132v1",
    "title": "Younger: The First Dataset for Artificial Intelligence-Generated Neural Network Architecture",
    "authors": [
      "Zhengxin Yang",
      "Wanling Gao",
      "Luzhou Peng",
      "Yunyou Huang",
      "Fei Tang",
      "Jianfeng Zhan"
    ],
    "abstract": "Designing and optimizing neural network architectures typically requires\nextensive expertise, starting with handcrafted designs and then manual or\nautomated refinement. This dependency presents a significant barrier to rapid\ninnovation. Recognizing the complexity of automatically generating neural\nnetwork architecture from scratch, we introduce Younger, a pioneering dataset\nto advance this ambitious goal. Derived from over 174K real-world models across\nmore than 30 tasks from various public model hubs, Younger includes 7,629\nunique architectures, and each is represented as a directed acyclic graph with\ndetailed operator-level information. The dataset facilitates two primary design\nparadigms: global, for creating complete architectures from scratch, and local,\nfor detailed architecture component refinement. By establishing these\ncapabilities, Younger contributes to a new frontier, Artificial\nIntelligence-Generated Neural Network Architecture (AIGNNA). Our experiments\nexplore the potential and effectiveness of Younger for automated architecture\ngeneration and, as a secondary benefit, demonstrate that Younger can serve as a\nbenchmark dataset, advancing the development of graph neural networks. We\nrelease the dataset and code publicly to lower the entry barriers and encourage\nfurther research in this challenging area.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 29 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.15132v1",
    "published_date": "2024-06-20 03:14:56 UTC",
    "updated_date": "2024-06-20 03:14:56 UTC"
  },
  {
    "arxiv_id": "2406.13960v3",
    "title": "AutoPal: Autonomous Adaptation to Users for Personal AI Companionship",
    "authors": [
      "Yi Cheng",
      "Wenge Liu",
      "Kaishuai Xu",
      "Wenjun Hou",
      "Yi Ouyang",
      "Chak Tou Leong",
      "Xian Wu",
      "Yefeng Zheng"
    ],
    "abstract": "Previous research has demonstrated the potential of AI agents to act as\ncompanions that can provide constant emotional support for humans. In this\npaper, we emphasize the necessity of autonomous adaptation in personal AI\ncompanionship, an underexplored yet promising direction. Such adaptability is\ncrucial as it can facilitate more tailored interactions with users and allow\nthe agent to evolve in response to users' changing needs. However, imbuing\nagents with autonomous adaptability presents unique challenges, including\nidentifying optimal adaptations to meet users' expectations and ensuring a\nsmooth transition during the adaptation process. To address them, we devise a\nhierarchical framework, AutoPal, that enables controllable and authentic\nadjustments to the agent's persona based on user interactions. A\npersonamatching dataset is constructed to facilitate the learning of optimal\npersona adaptations. Extensive experiments demonstrate the effectiveness of\nAutoPal and highlight the importance of autonomous adaptability in AI\ncompanionship.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13960v3",
    "published_date": "2024-06-20 03:02:38 UTC",
    "updated_date": "2024-10-18 03:10:13 UTC"
  },
  {
    "arxiv_id": "2406.13954v1",
    "title": "Research on Flight Accidents Prediction based Back Propagation Neural Network",
    "authors": [
      "Haoxing Liu",
      "Fangzhou Shen",
      "Haoshen Qin and",
      "Fanru Gao"
    ],
    "abstract": "With the rapid development of civil aviation and the significant improvement\nof people's living standards, taking an air plane has become a common and\nefficient way of travel. However, due to the flight characteris-tics of the\naircraft and the sophistication of the fuselage structure, flight de-lays and\nflight accidents occur from time to time. In addition, the life risk factor\nbrought by aircraft after an accident is also the highest among all means of\ntransportation. In this work, a model based on back-propagation neural network\nwas used to predict flight accidents. By collecting historical flight data,\nincluding a variety of factors such as meteorological conditions, aircraft\ntechnical condition, and pilot experience, we trained a backpropaga-tion neural\nnetwork model to identify potential accident risks. In the model design, a\nmulti-layer perceptron structure is used to optimize the network performance by\nadjusting the number of hidden layer nodes and the learning rate. Experimental\nanalysis shows that the model can effectively predict flight accidents with\nhigh accuracy and reliability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13954v1",
    "published_date": "2024-06-20 02:51:27 UTC",
    "updated_date": "2024-06-20 02:51:27 UTC"
  },
  {
    "arxiv_id": "2406.13948v1",
    "title": "CityGPT: Empowering Urban Spatial Cognition of Large Language Models",
    "authors": [
      "Jie Feng",
      "Yuwei Du",
      "Tianhui Liu",
      "Siqi Guo",
      "Yuming Lin",
      "Yong Li"
    ],
    "abstract": "Large language models(LLMs) with powerful language generation and reasoning\ncapabilities have already achieved success in many domains, e.g., math and code\ngeneration. However, due to the lacking of physical world's corpus and\nknowledge during training, they usually fail to solve many real-life tasks in\nthe urban space. In this paper, we propose CityGPT, a systematic framework for\nenhancing the capability of LLMs on understanding urban space and solving the\nrelated urban tasks by building a city-scale world model in the model. First,\nwe construct a diverse instruction tuning dataset CityInstruction for injecting\nurban knowledge and enhancing spatial reasoning capability effectively. By\nusing a mixture of CityInstruction and general instruction data, we fine-tune\nvarious LLMs (e.g., ChatGLM3-6B, Qwen1.5 and LLama3 series) to enhance their\ncapability without sacrificing general abilities. To further validate the\neffectiveness of proposed methods, we construct a comprehensive benchmark\nCityEval to evaluate the capability of LLMs on diverse urban scenarios and\nproblems. Extensive evaluation results demonstrate that small LLMs trained with\nCityInstruction can achieve competitive performance with commercial LLMs in the\ncomprehensive evaluation of CityEval. The source codes are openly accessible to\nthe research community via https://github.com/tsinghua-fib-lab/CityGPT.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13948v1",
    "published_date": "2024-06-20 02:32:16 UTC",
    "updated_date": "2024-06-20 02:32:16 UTC"
  },
  {
    "arxiv_id": "2406.13947v1",
    "title": "AspirinSum: an Aspect-based utility-preserved de-identification Summarization framework",
    "authors": [
      "Ya-Lun Li"
    ],
    "abstract": "Due to the rapid advancement of Large Language Model (LLM), the whole\ncommunity eagerly consumes any available text data in order to train the LLM.\nCurrently, large portion of the available text data are collected from\ninternet, which has been thought as a cheap source of the training data.\nHowever, when people try to extend the LLM's capability to the personal related\ndomain, such as healthcare or education, the lack of public dataset in these\ndomains make the adaption of the LLM in such domains much slower. The reason of\nlacking public available dataset in such domains is because they usually\ncontain personal sensitive information. In order to comply with privacy law,\nthe data in such domains need to be de-identified before any kind of\ndissemination. It had been much research tried to address this problem for the\nimage or tabular data. However, there was limited research on the efficient and\ngeneral de-identification method for text data. Most of the method based on\nhuman annotation or predefined category list. It usually can not be easily\nadapted to specific domains. The goal of this proposal is to develop a text\nde-identification framework, which can be easily adapted to the specific\ndomain, leverage the existing expert knowledge without further human\nannotation. We propose an aspect-based utility-preserved de-identification\nsummarization framework, AspirinSum, by learning to align expert's aspect from\nexisting comment data, it can efficiently summarize the personal sensitive\ndocument by extracting personal sensitive aspect related sub-sentence and\nde-identify it by substituting it with similar aspect sub-sentence. We envision\nthat the de-identified text can then be used in data publishing, eventually\npublishing our de-identified dataset for downstream task use.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13947v1",
    "published_date": "2024-06-20 02:29:46 UTC",
    "updated_date": "2024-06-20 02:29:46 UTC"
  },
  {
    "arxiv_id": "2406.13945v2",
    "title": "CityBench: Evaluating the Capabilities of Large Language Models for Urban Tasks",
    "authors": [
      "Jie Feng",
      "Jun Zhang",
      "Tianhui Liu",
      "Xin Zhang",
      "Tianjian Ouyang",
      "Junbo Yan",
      "Yuwei Du",
      "Siqi Guo",
      "Yong Li"
    ],
    "abstract": "Recently, large language models (LLMs) with extensive general knowledge and\npowerful reasoning abilities have seen rapid development and widespread\napplication. A systematic and reliable evaluation of LLMs or vision-language\nmodel (VLMs) is a crucial step in applying and developing them for various\nfields. There have been some early explorations about the usability of LLMs for\nlimited urban tasks, but a systematic and scalable evaluation benchmark is\nstill lacking. The challenge in constructing a systematic evaluation benchmark\nfor urban research lies in the diversity of urban data, the complexity of\napplication scenarios and the highly dynamic nature of the urban environment.\nIn this paper, we design CityBench, an interactive simulator based evaluation\nplatform, as the first systematic benchmark for evaluating the capabilities of\nLLMs for diverse tasks in urban research. First, we build CityData to integrate\nthe diverse urban data and CitySimu to simulate fine-grained urban dynamics.\nBased on CityData and CitySimu, we design 8 representative urban tasks in 2\ncategories of perception-understanding and decision-making as the CityBench.\nWith extensive results from 30 well-known LLMs and VLMs in 13 cities around the\nworld, we find that advanced LLMs and VLMs can achieve competitive performance\nin diverse urban tasks requiring commonsense and semantic understanding\nabilities, e.g., understanding the human dynamics and semantic inference of\nurban images. Meanwhile, they fail to solve the challenging urban tasks\nrequiring professional knowledge and high-level reasoning abilities, e.g.,\ngeospatial prediction and traffic control task. These observations provide\nvaluable perspectives for utilizing and developing LLMs in the future. Codes\nare openly accessible via https://github.com/tsinghua-fib-lab/CityBench.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, https://github.com/tsinghua-fib-lab/CityBench",
    "pdf_url": "http://arxiv.org/pdf/2406.13945v2",
    "published_date": "2024-06-20 02:25:07 UTC",
    "updated_date": "2024-12-23 14:10:09 UTC"
  },
  {
    "arxiv_id": "2406.13941v2",
    "title": "UpDLRM: Accelerating Personalized Recommendation using Real-World PIM Architecture",
    "authors": [
      "Sitian Chen",
      "Haobin Tan",
      "Amelie Chi Zhou",
      "Yusen Li",
      "Pavan Balaji"
    ],
    "abstract": "Deep Learning Recommendation Models (DLRMs) have gained popularity in\nrecommendation systems due to their effectiveness in handling large-scale\nrecommendation tasks. The embedding layers of DLRMs have become the performance\nbottleneck due to their intensive needs on memory capacity and memory\nbandwidth. In this paper, we propose UpDLRM, which utilizes real-world\nprocessingin-memory (PIM) hardware, UPMEM DPU, to boost the memory bandwidth\nand reduce recommendation latency. The parallel nature of the DPU memory can\nprovide high aggregated bandwidth for the large number of irregular memory\naccesses in embedding lookups, thus offering great potential to reduce the\ninference latency. To fully utilize the DPU memory bandwidth, we further\nstudied the embedding table partitioning problem to achieve good\nworkload-balance and efficient data caching. Evaluations using real-world\ndatasets show that, UpDLRM achieves much lower inference time for DLRM compared\nto both CPU-only and CPU-GPU hybrid counterparts.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by DAC 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.13941v2",
    "published_date": "2024-06-20 02:20:21 UTC",
    "updated_date": "2024-10-09 04:11:28 UTC"
  },
  {
    "arxiv_id": "2406.13935v1",
    "title": "CONMOD: Controllable Neural Frame-based Modulation Effects",
    "authors": [
      "Gyubin Lee",
      "Hounsu Kim",
      "Junwon Lee",
      "Juhan Nam"
    ],
    "abstract": "Deep learning models have seen widespread use in modelling LFO-driven audio\neffects, such as phaser and flanger. Although existing neural architectures\nexhibit high-quality emulation of individual effects, they do not possess the\ncapability to manipulate the output via control parameters. To address this\nissue, we introduce Controllable Neural Frame-based Modulation Effects\n(CONMOD), a single black-box model which emulates various LFO-driven effects in\na frame-wise manner, offering control over LFO frequency and feedback\nparameters. Additionally, the model is capable of learning the continuous\nembedding space of two distinct phaser effects, enabling us to steer between\neffects and achieve creative outputs. Our model outperforms previous work while\npossessing both controllability and universality, presenting opportunities to\nenhance creativity in modern LFO-driven audio effects.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13935v1",
    "published_date": "2024-06-20 02:02:54 UTC",
    "updated_date": "2024-06-20 02:02:54 UTC"
  },
  {
    "arxiv_id": "2406.13934v1",
    "title": "Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment",
    "authors": [
      "Kaishuai Xu",
      "Yi Cheng",
      "Wenjun Hou",
      "Qiaoyu Tan",
      "Wenjie Li"
    ],
    "abstract": "Medical dialogue systems have attracted significant attention for their\npotential to act as medical assistants. Enabling these medical systems to\nemulate clinicians' diagnostic reasoning process has been the long-standing\nresearch focus. Previous studies rudimentarily realized the simulation of\nclinicians' diagnostic process by fine-tuning language models on high-quality\ndialogue datasets. Nonetheless, they overly focus on the outcomes of the\nclinician's reasoning process while ignoring their internal thought processes\nand alignment with clinician preferences. Our work aims to build a medical\ndialogue system that aligns with clinicians' diagnostic reasoning processes. We\npropose a novel framework, Emulation, designed to generate an appropriate\nresponse that relies on abductive and deductive diagnostic reasoning analyses\nand aligns with clinician preferences through thought process modeling.\nExperimental results on two datasets confirm the efficacy of Emulation.\nCrucially, our framework furnishes clear explanations for the generated\nresponses, enhancing its transparency in medical consultations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.13934v1",
    "published_date": "2024-06-20 02:02:53 UTC",
    "updated_date": "2024-06-20 02:02:53 UTC"
  },
  {
    "arxiv_id": "2406.13929v1",
    "title": "Large Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination",
    "authors": [
      "Jongyoon Song",
      "Sangwon Yu",
      "Sungroh Yoon"
    ],
    "abstract": "In this paper, we identify a new category of bias that induces\ninput-conflicting hallucinations, where large language models (LLMs) generate\nresponses inconsistent with the content of the input context. This issue we\nhave termed the false negative problem refers to the phenomenon where LLMs are\npredisposed to return negative judgments when assessing the correctness of a\nstatement given the context. In experiments involving pairs of statements that\ncontain the same information but have contradictory factual directions, we\nobserve that LLMs exhibit a bias toward false negatives. Specifically, the\nmodel presents greater overconfidence when responding with False. Furthermore,\nwe analyze the relationship between the false negative problem and context and\nquery rewriting and observe that both effectively tackle false negatives in\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.13929v1",
    "published_date": "2024-06-20 01:53:25 UTC",
    "updated_date": "2024-06-20 01:53:25 UTC"
  },
  {
    "arxiv_id": "2406.13925v3",
    "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models",
    "authors": [
      "Tao Zhang",
      "Ziqian Zeng",
      "Yuxiang Xiao",
      "Huiping Zhuang",
      "Cen Chen",
      "James Foulds",
      "Shimei Pan"
    ],
    "abstract": "Large Language Models (LLMs) are prone to generating content that exhibits\ngender biases, raising significant ethical concerns. Alignment, the process of\nfine-tuning LLMs to better align with desired behaviors, is recognized as an\neffective approach to mitigate gender biases. Although proprietary LLMs have\nmade significant strides in mitigating gender bias, their alignment datasets\nare not publicly available. The commonly used and publicly available alignment\ndataset, HH-RLHF, still exhibits gender bias to some extent. There is a lack of\npublicly available alignment datasets specifically designed to address gender\nbias. Hence, we developed a new dataset named GenderAlign, aiming at mitigating\na comprehensive set of gender biases in LLMs. This dataset comprises 8k\nsingle-turn dialogues, each paired with a \"chosen\" and a \"rejected\" response.\nCompared to the \"rejected\" responses, the \"chosen\" responses demonstrate lower\nlevels of gender bias and higher quality. Furthermore, we categorized the\ngender biases in the \"rejected\" responses of GenderAlign into 4 principal\ncategories. The experimental results show the effectiveness of GenderAlign in\nreducing gender bias in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13925v3",
    "published_date": "2024-06-20 01:45:44 UTC",
    "updated_date": "2024-12-16 12:51:46 UTC"
  },
  {
    "arxiv_id": "2406.13923v1",
    "title": "PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents",
    "authors": [
      "Junjie Wang",
      "Yin Zhang",
      "Yatai Ji",
      "Yuxiang Zhang",
      "Chunyang Jiang",
      "Yubo Wang",
      "Kang Zhu",
      "Zekun Wang",
      "Tiezhen Wang",
      "Wenhao Huang",
      "Jie Fu",
      "Bei Chen",
      "Qunshu Lin",
      "Minghao Liu",
      "Ge Zhang",
      "Wenhu Chen"
    ],
    "abstract": "Recent advancements in Large Multimodal Models (LMMs) have leveraged\nextensive multimodal datasets to enhance capabilities in complex\nknowledge-driven tasks. However, persistent challenges in perceptual and\nreasoning errors limit their efficacy, particularly in interpreting intricate\nvisual data and deducing multimodal relationships. Addressing these issues, we\nintroduce a novel dataset format, PIN (Paired and INterleaved multimodal\ndocuments), designed to significantly improve both the depth and breadth of\nmultimodal training. The PIN format is built on three foundational principles:\nknowledge intensity, scalability, and support for diverse training modalities.\nThis innovative format combines markdown files and comprehensive images to\nenrich training data with a dense knowledge structure and versatile training\nstrategies. We present PIN-14M, an open-source dataset comprising 14 million\nsamples derived from a diverse range of Chinese and English sources, tailored\nto include complex web and scientific content. This dataset is constructed\nmeticulously to ensure data quality and ethical integrity, aiming to facilitate\nadvanced training strategies and improve model robustness against common\nmultimodal training pitfalls. Our initial results, forming the basis of this\ntechnical report, suggest significant potential for the PIN format in refining\nLMM performance, with plans for future expansions and detailed evaluations of\nits impact on model capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13923v1",
    "published_date": "2024-06-20 01:43:08 UTC",
    "updated_date": "2024-06-20 01:43:08 UTC"
  },
  {
    "arxiv_id": "2407.02511v2",
    "title": "LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning",
    "authors": [
      "Silin Meng",
      "Yiwei Wang",
      "Cheng-Fu Yang",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ],
    "abstract": "Path planning is a fundamental scientific problem in robotics and autonomous\nnavigation, requiring the derivation of efficient routes from starting to\ndestination points while avoiding obstacles. Traditional algorithms like A* and\nits variants are capable of ensuring path validity but suffer from significant\ncomputational and memory inefficiencies as the state space grows. Conversely,\nlarge language models (LLMs) excel in broader environmental analysis through\ncontextual understanding, providing global insights into environments. However,\nthey fall short in detailed spatial and temporal reasoning, often leading to\ninvalid or inefficient routes. In this work, we propose LLM-A*, an new LLM\nbased route planning method that synergistically combines the precise\npathfinding capabilities of A* with the global reasoning capability of LLMs.\nThis hybrid approach aims to enhance pathfinding efficiency in terms of time\nand space complexity while maintaining the integrity of path validity,\nespecially in large-scale scenarios. By integrating the strengths of both\nmethodologies, LLM-A* addresses the computational and memory limitations of\nconventional algorithms without compromising on the validity required for\neffective pathfinding.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "Findings of the Association for Computational Linguistics: EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02511v2",
    "published_date": "2024-06-20 01:24:30 UTC",
    "updated_date": "2025-04-09 17:34:52 UTC"
  },
  {
    "arxiv_id": "2406.13919v4",
    "title": "SPL: A Socratic Playground for Learning Powered by Large Language Model",
    "authors": [
      "Liang Zhang",
      "Jionghao Lin",
      "Ziyi Kuang",
      "Sheng Xu",
      "Xiangen Hu"
    ],
    "abstract": "Dialogue-based Intelligent Tutoring Systems (ITSs) have significantly\nadvanced adaptive and personalized learning by automating sophisticated human\ntutoring strategies within interactive dialogues. However, replicating the\nnuanced patterns of expert human communication remains a challenge in Natural\nLanguage Processing (NLP). Recent advancements in NLP, particularly Large\nLanguage Models (LLMs) such as OpenAI's GPT-4, offer promising solutions by\nproviding human-like and context-aware responses based on extensive pre-trained\nknowledge. Motivated by the effectiveness of LLMs in various educational tasks\n(e.g., content creation and summarization, problem-solving, and automated\nfeedback provision), our study introduces the Socratic Playground for Learning\n(SPL), a dialogue-based ITS powered by the GPT-4 model, which employs the\nSocratic teaching method to foster critical thinking among learners. Through\nextensive prompt engineering, SPL can generate specific learning scenarios and\nfacilitates efficient multi-turn tutoring dialogues. The SPL system aims to\nenhance personalized and adaptive learning experiences tailored to individual\nneeds, specifically focusing on improving critical thinking skills. Our pilot\nexperimental results from essay writing tasks demonstrate SPL has the potential\nto improve tutoring interactions and further enhance dialogue-based ITS\nfunctionalities. Our study, exemplified by SPL, demonstrates how LLMs enhance\ndialogue-based ITSs and expand the accessibility and efficacy of educational\ntechnologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.13919v4",
    "published_date": "2024-06-20 01:18:52 UTC",
    "updated_date": "2024-09-25 01:48:32 UTC"
  },
  {
    "arxiv_id": "2406.13903v1",
    "title": "Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions",
    "authors": [
      "Hamdireza Rouzegar",
      "Masoud Makrehchi"
    ],
    "abstract": "This study investigates how LLMs, specifically GPT-3.5 and GPT-4, can develop\ntailored questions for Grade 9 math, aligning with active learning principles.\nBy utilizing an iterative method, these models adjust questions based on\ndifficulty and content, responding to feedback from a simulated 'student'\nmodel. A novel aspect of the research involved using GPT-4 as a 'teacher' to\ncreate complex questions, with GPT-3.5 as the 'student' responding to these\nchallenges. This setup mirrors active learning, promoting deeper engagement.\nThe findings demonstrate GPT-4's superior ability to generate precise,\nchallenging questions and notable improvements in GPT-3.5's ability to handle\nmore complex problems after receiving instruction from GPT-4. These results\nunderscore the potential of LLMs to mimic and enhance active learning\nscenarios, offering a promising path for AI in customized education. This\nresearch contributes to understanding how AI can support personalized learning\nexperiences, highlighting the need for further exploration in various\neducational contexts",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Publisher: Canadian Artificial Intelligence Association. URL:\n  https://caiac.pubpub.org/pub/kmn55wd2#nssvokovikx",
    "pdf_url": "http://arxiv.org/pdf/2406.13903v1",
    "published_date": "2024-06-20 00:25:43 UTC",
    "updated_date": "2024-06-20 00:25:43 UTC"
  },
  {
    "arxiv_id": "2406.15508v1",
    "title": "What Teaches Robots to Walk, Teaches Them to Trade too -- Regime Adaptive Execution using Informed Data and LLMs",
    "authors": [
      "Raeid Saqur"
    ],
    "abstract": "Machine learning techniques applied to the problem of financial market\nforecasting struggle with dynamic regime switching, or underlying correlation\nand covariance shifts in true (hidden) market variables. Drawing inspiration\nfrom the success of reinforcement learning in robotics, particularly in agile\nlocomotion adaptation of quadruped robots to unseen terrains, we introduce an\ninnovative approach that leverages world knowledge of pretrained LLMs (aka.\n'privileged information' in robotics) and dynamically adapts them using\nintrinsic, natural market rewards using LLM alignment technique we dub as\n\"Reinforcement Learning from Market Feedback\" (**RLMF**). Strong empirical\nresults demonstrate the efficacy of our method in adapting to regime shifts in\nfinancial markets, a challenge that has long plagued predictive models in this\ndomain. The proposed algorithmic framework outperforms best-performing SOTA LLM\nmodels on the existing (FLARE) benchmark stock-movement (SM) tasks by more than\n15\\% improved accuracy. On the recently proposed NIFTY SM task, our adaptive\npolicy outperforms the SOTA best performing trillion parameter models like\nGPT-4. The paper details the dual-phase, teacher-student architecture and\nimplementation of our model, the empirical results obtained, and an analysis of\nthe role of language embeddings in terms of Information Gain.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "I.2.0; I.2.6; I.2.7; I.2.9"
    ],
    "primary_category": "q-fin.CP",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2405.09747",
    "pdf_url": "http://arxiv.org/pdf/2406.15508v1",
    "published_date": "2024-06-20 00:17:28 UTC",
    "updated_date": "2024-06-20 00:17:28 UTC"
  }
]