{
  "date": "2024-11-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-15 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 108 篇论文，主要聚焦 AI 模型优化（如 LLM 的角色扮演和代理系统）、医疗图像处理、强化学习和多模态融合等领域，其中 AmoebaLLM 和 Orca 等文章在高效 LLM 构建和代理交互上令人印象深刻，著名学者如 Jeff Dean 的回应论文也值得关注。\n\n以下是今日论文的精选摘要，我优先选取了重要、创新性和话题度高的文章（如 AI 安全、医疗应用和高效模型），并快速掠过一些较基础或小众的论文。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 重点论文讨论\n\n1. **AmoebaLLM: Constructing Any-Shape Large Language Models for Efficient and Instant Deployment**  \n   这篇论文提出 AmoebaLLM 框架，用于构建任意形状的 LLM 子网络，实现高效部署。核心贡献是通过知识保留策略、形状感知 LoRA 和蒸馏方案，优化 LLM 的准确性和效率，适用于多样平台；NeurIPS 2024 接受，展示 LLM 适应性的新标准。\n\n2. **Being Considerate as a Pathway Towards Pluralistic Alignment for Agentic AI**  \n   作者探讨 AI 代理的多元对齐，强调考虑他人福祉以促进和谐行为。关键发现是通过代理学习实现价值观整合，提升 AI 在复杂环境中的合作潜力；NeurIPS 2024 工作坊论文，相关作者如 Sheila A. McIlraith 等知名学者。\n\n3. **Chain of Alignment: Integrating Public Will with Expert Intelligence for Language Model Alignment**  \n   该工作引入链式对齐方法，将公众意愿与专家知识整合到 LLM 训练中。主要贡献是生成规则奖励函数，提升模型与人类价值观的契合；NeurIPS 2024 论文，提供 AI 行为评估新框架。\n\n4. **Leveraging large language models for efficient representation learning for entity resolution**  \n   提出 TriBERTa 系统，使用预训练 LLM 和三元组损失函数优化实体匹配表示。核心发现是比 SBERT 和 TF-IDF 高 3-19% 的性能，提升数据驱动场景的鲁棒性。\n\n5. **Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits**  \n   通过整合人格特质（如 BigFive 模型）提升 LLM 的角色扮演能力。关键创新是数据增强和提示调优方法，显著改善社交平台生成内容；代码开源，展示 LLM 在个性化对话中的潜力。\n\n6. **EyeDiff: text-to-image diffusion model improves rare eye disease diagnosis**  \n   利用扩散模型生成多模态眼部图像，提升稀有眼病诊断。核心贡献是结合真实数据训练，显著提高检测准确性（如在 ISIC2019 上表现优异），为医疗 AI 提供实用工具。\n\n7. **DeepMedcast: A Deep Learning Method for Generating Intermediate Weather Forecasts among Multiple NWP Models**  \n   提出 DeepMedcast 模型，融合多个数值天气预报模型生成中长期预测。主要发现是提升全球天气和气候信号预测准确性（如 Madden-Julian Oscillation），为无缝天气预报铺路。\n\n8. **TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models**  \n   设计 TEESlice 方法，在 TEE 中保护敏感模型权重。核心贡献是分区策略减少计算开销，同时抵抗预训练模型攻击，提升 AI 安全。\n\n9. **That Chip Has Sailed: A Critique of Unfounded Skepticism Around AI for Chip Design**  \n   作者 Jeff Dean 回应对 AI 芯片设计的质疑，论证强化学习（如 AlphaChip）在芯片布局中的超人性能。关键发现是 AI 已实际部署于 Alphabet 等公司，强调其影响力和开源价值。\n\n10. **JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**  \n   开发 JRadiEvo 模型，通过进化优化合并生成日语放射学报告。核心贡献是使用少量数据（50 个样本）实现高准确性，适用于资源有限的医疗场景。\n\n11. **PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**  \n   提出 PFML 框架，自监督学习时间序列数据，避免表示坍缩。关键发现是提升分类任务性能（如婴儿姿势和睡眠阶段），适用于医疗传感器数据。\n\n12. **The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use**  \n   探索 GUI 代理（如 Claude 3.5）在桌面任务中的能力。核心贡献是开源框架和基准任务，展示 AI 在交互式环境中的潜力。\n\n### 其他论文快速掠过\n剩余论文中，一些领域如强化学习（e.g., \"Off-Dynamics Reinforcement Learning via Domain Adaptation and Reward Augmented Imitation\"，贡献：改进跨域策略学习）和计算机视觉（e.g., \"Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation\"，贡献：无训练分割图像）有细微创新，但不具话题度；医疗和 AI 安全论文（如 \"Evaluating Creativity and Deception in Large Language Models\"，贡献：测试 LLM 在游戏中的创造力和欺骗性）则重复现有主题；物理和数学论文（如 \"A minimalistic representation model for head direction system\"，贡献：建模头部方向系统）较理论化，影响力有限，故从简。总体而言，今天的更新突显 AI 在实际应用中的进展，值得跟踪。明日见！",
  "papers": [
    {
      "arxiv_id": "2411.10629v1",
      "title": "Leveraging large language models for efficient representation learning for entity resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaowei Xu",
        "Bi T. Foua",
        "Xingqiao Wang",
        "Vivek Gunasekaran",
        "John R. Talburt"
      ],
      "abstract": "In this paper, the authors propose TriBERTa, a supervised entity resolution\nsystem that utilizes a pre-trained large language model and a triplet loss\nfunction to learn representations for entity matching. The system consists of\ntwo steps: first, name entity records are fed into a Sentence Bidirectional\nEncoder Representations from Transformers (SBERT) model to generate vector\nrepresentations, which are then fine-tuned using contrastive learning based on\na triplet loss function. Fine-tuned representations are used as input for\nentity matching tasks, and the results show that the proposed approach\noutperforms state-of-the-art representations, including SBERT without\nfine-tuning and conventional Term Frequency-Inverse Document Frequency\n(TF-IDF), by a margin of 3 - 19%. Additionally, the representations generated\nby TriBERTa demonstrated increased robustness, maintaining consistently higher\nperformance across a range of datasets. The authors also discussed the\nimportance of entity resolution in today's data-driven landscape and the\nchallenges that arise when identifying and reconciling duplicate data across\ndifferent sources. They also described the ER process, which involves several\ncrucial steps, including blocking, entity matching, and clustering.",
      "tldr_zh": "本研究提出TriBERTa，一种基于预训练大型语言模型的监督实体解析系统，利用三元组损失函数(triplet loss)进行对比学习，以高效学习实体匹配的表示。系统首先通过SBERT模型生成实体记录的向量表示，然后进行微调优化。实验结果显示，TriBERTa在实体匹配任务上比SBERT无微调和TF-IDF等基准方法提高了3-19%的性能，并展现出更高的鲁棒性，在多种数据集上保持稳定表现。该方法突出了实体解析在数据驱动环境中的重要性，并解决了跨源数据重复识别的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages and 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10629v1",
      "published_date": "2024-11-15 23:24:07 UTC",
      "updated_date": "2024-11-15 23:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:43:36.444383"
    },
    {
      "arxiv_id": "2411.10627v1",
      "title": "Is thermography a viable solution for detecting pressure injuries in dark skin patients?",
      "title_zh": "热成像是否是检测深色皮肤患者压迫性损伤的可行解决方案？",
      "authors": [
        "Miriam Asare-Baiden",
        "Kathleen Jordan",
        "Andrew Chung",
        "Sharon Eve Sonenblum",
        "Joyce C. Ho"
      ],
      "abstract": "Pressure injury (PI) detection is challenging, especially in dark skin tones,\ndue to the unreliability of visual inspection. Thermography has been suggested\nas a viable alternative as temperature differences in the skin can indicate\nimpending tissue damage. Although deep learning models have demonstrated\nconsiderable promise toward reliably detecting PI, the existing work fails to\nevaluate the performance on darker skin tones and varying data collection\nprotocols. In this paper, we introduce a new thermal and optical imaging\ndataset of 35 participants focused on darker skin tones where temperature\ndifferences are induced through cooling and cupping protocols. We vary the\nimage collection process to include different cameras, lighting, patient pose,\nand camera distance. We compare the performance of a small convolutional neural\nnetwork (CNN) trained on either the thermal or the optical images on all skin\ntones. Our preliminary results suggest that thermography-based CNN is robust to\ndata collection protocols for all skin tones.",
      "tldr_zh": "该研究探讨了热成像（thermography）是否能有效检测深色皮肤患者的压力损伤（PI），因为传统视觉检查在深色皮肤上可靠性不足。研究者引入了一个新数据集，包含35名参与者的热图像和光学图像，通过冷却和拔罐协议诱导温度差异，并考虑了不同相机、照明、患者姿势和相机距离等变量。实验使用小型卷积神经网络（CNN）分别在热图像和光学图像上训练，结果显示基于热成像的CNN对所有皮肤色调的数据收集协议具有鲁棒性，表明热成像是一种潜在可行的检测解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.10627v1",
      "published_date": "2024-11-15 23:22:21 UTC",
      "updated_date": "2024-11-15 23:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:43:47.906987"
    },
    {
      "arxiv_id": "2411.10624v1",
      "title": "Weak Permission is not Well-Founded, Grounded and Stable",
      "title_zh": "翻译失败",
      "authors": [
        "Guido Governatori"
      ],
      "abstract": "We consider the notion of weak permission as the failure to conclude that the\nopposite obligation. We investigate the issue from the point of non-monotonic\nreasoning, specifically logic programming and structured argumentation, and we\nshow that it is not possible to capture weak permission in the presence of\ndeontic conflicts under the well-founded, grounded and (sceptical) stable\nsemantics.",
      "tldr_zh": "本论文探讨了weak permission的概念，即未能得出相反义务的失败，并从non-monotonic reasoning的角度进行分析，特别是通过logic programming和structured argumentation方法。研究发现，在存在deontic conflicts的情况下，无法在well-founded、grounded或(sceptical) stable semantics下有效捕捉weak permission，这揭示了这些语义框架的局限性。总的来说，此工作强调了弱权限在道德冲突场景中的挑战，为进一步改进非单调推理提供了理论基础。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10624v1",
      "published_date": "2024-11-15 23:14:30 UTC",
      "updated_date": "2024-11-15 23:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:44:00.468720"
    },
    {
      "arxiv_id": "2411.10617v1",
      "title": "Attraction-Repulsion Swarming: A Generalized Framework of t-SNE via Force Normalization and Tunable Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Jingcheng Lu",
        "Jeff Calder"
      ],
      "abstract": "We propose a new method for data visualization based on attraction-repulsion\nswarming (ARS) dynamics, which we call ARS visualization. ARS is a generalized\nframework that is based on viewing the t-distributed stochastic neighbor\nembedding (t-SNE) visualization technique as a swarm of interacting agents\ndriven by attraction and repulsion. Motivated by recent developments in\nswarming, we modify the t-SNE dynamics to include a normalization by the\n\\emph{total influence}, which results in better posed dynamics in which we can\nuse a data size independent time step (of $h=1$) and a simple iteration,\nwithout the need for the array of optimization tricks employed in t-SNE. ARS\nalso includes the ability to separately tune the attraction and repulsion\nkernels, which gives the user control over the tightness within clusters and\nthe spacing between them in the visualization.\n  In contrast with t-SNE, our proposed ARS data visualization method is not\ngradient descent on the Kullback-Leibler divergence, and can be viewed solely\nas an interacting particle system driven by attraction and repulsion forces. We\nprovide theoretical results illustrating how the choice of interaction kernel\naffects the dynamics, and experimental results to validate our method and\ncompare to t-SNE on the MNIST and Cifar-10 data sets.",
      "tldr_zh": "这篇论文提出了ARS visualization，一种基于吸引-排斥swarming动态的数据可视化方法，作为t-SNE的泛化框架。ARS通过对总影响进行force normalization和可调交互内核，改进了t-SNE的动态，实现数据大小无关的时间步长（h=1）和简化迭代过程，从而更好地控制集群内的紧密性和集群间的间距。与t-SNE不同，ARS作为一个纯粹的受吸引-排斥力驱动的粒子系统，而非Kullback-Leibler divergence的梯度下降。实验结果在MNIST和Cifar-10数据集上验证了ARS的优越性，展示了其在可视化性能上的提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.CA",
        "math.DS",
        "math.NA",
        "stat.ML",
        "68T09, 65M06, 35Q70"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10617v1",
      "published_date": "2024-11-15 22:42:11 UTC",
      "updated_date": "2024-11-15 22:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:44:13.694069"
    },
    {
      "arxiv_id": "2411.10613v1",
      "title": "Being Considerate as a Pathway Towards Pluralistic Alignment for Agentic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Parand A. Alamdari",
        "Toryn Q. Klassen",
        "Rodrigo Toro Icarte",
        "Sheila A. McIlraith"
      ],
      "abstract": "Pluralistic alignment is concerned with ensuring that an AI system's\nobjectives and behaviors are in harmony with the diversity of human values and\nperspectives. In this paper we study the notion of pluralistic alignment in the\ncontext of agentic AI, and in particular in the context of an agent that is\ntrying to learn a policy in a manner that is mindful of the values and\nperspective of others in the environment. To this end, we show how being\nconsiderate of the future wellbeing and agency of other (human) agents can\npromote a form of pluralistic alignment.",
      "tldr_zh": "本论文探讨了多元主义对齐(pluralistic alignment)在代理式 AI(agentic AI)中的应用，强调AI系统需考虑环境中的人类价值观和视角多样性，以确保其目标和行为与多方利益一致。作者提出，通过AI“being considerate”（即关注其他代理的未来福祉和代理性），可以作为一种路径来促进这种对齐。研究表明，这种考虑周到的策略有助于AI在学习政策时实现更和谐的互动，从而提升AI的整体可接受性和伦理性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Pluralistic Alignment Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10613v1",
      "published_date": "2024-11-15 22:34:09 UTC",
      "updated_date": "2024-11-15 22:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:44:23.702120"
    },
    {
      "arxiv_id": "2411.10606v1",
      "title": "AmoebaLLM: Constructing Any-Shape Large Language Models for Efficient and Instant Deployment",
      "title_zh": "AmoebaLLM：构建任意形状的大语言模型用于高效和即时部署",
      "authors": [
        "Yonggan Fu",
        "Zhongzhi Yu",
        "Junwei Li",
        "Jiayi Qian",
        "Yongan Zhang",
        "Xiangchi Yuan",
        "Dachuan Shi",
        "Roman Yakunin",
        "Yingyan Celine Lin"
      ],
      "abstract": "Motivated by the transformative capabilities of large language models (LLMs)\nacross various natural language tasks, there has been a growing demand to\ndeploy these models effectively across diverse real-world applications and\nplatforms. However, the challenge of efficiently deploying LLMs has become\nincreasingly pronounced due to the varying application-specific performance\nrequirements and the rapid evolution of computational platforms, which feature\ndiverse resource constraints and deployment flows. These varying requirements\nnecessitate LLMs that can adapt their structures (depth and width) for optimal\nefficiency across different platforms and application specifications. To\naddress this critical gap, we propose AmoebaLLM, a novel framework designed to\nenable the instant derivation of LLM subnets of arbitrary shapes, which achieve\nthe accuracy-efficiency frontier and can be extracted immediately after a\none-time fine-tuning. In this way, AmoebaLLM significantly facilitates rapid\ndeployment tailored to various platforms and applications. Specifically,\nAmoebaLLM integrates three innovative components: (1) a knowledge-preserving\nsubnet selection strategy that features a dynamic-programming approach for\ndepth shrinking and an importance-driven method for width shrinking; (2) a\nshape-aware mixture of LoRAs to mitigate gradient conflicts among subnets\nduring fine-tuning; and (3) an in-place distillation scheme with loss-magnitude\nbalancing as the fine-tuning objective. Extensive experiments validate that\nAmoebaLLM not only sets new standards in LLM adaptability but also successfully\ndelivers subnets that achieve state-of-the-art trade-offs between accuracy and\nefficiency.",
      "tldr_zh": "该论文提出 AmoebaLLM 框架，用于构建任意形状的 Large Language Models (LLMs)，以适应不同平台的资源约束和应用需求，实现高效且即时的部署。框架的核心组件包括：知识保留的子网络选择策略（如动态规划的 depth shrinking 和重要性驱动的 width shrinking）、shape-aware mixture of LoRAs 来缓解微调时的梯度冲突，以及 in-place distillation scheme with loss-magnitude balancing 作为微调目标。这些创新设计确保子网络在一次 fine-tuning 后即可提取，并达到准确性和效率的最佳平衡。实验结果表明，AmoebaLLM 在 LLM 适应性上设定新标准，提供最先进的准确率与效率权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10606v1",
      "published_date": "2024-11-15 22:02:28 UTC",
      "updated_date": "2024-11-15 22:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:44:36.723206"
    },
    {
      "arxiv_id": "2411.10599v1",
      "title": "Generating Energy-efficient code with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Cappendijk",
        "Pepijn de Reus",
        "Ana Oprescu"
      ],
      "abstract": "The increasing electricity demands of personal computers, communication\nnetworks, and data centers contribute to higher atmospheric greenhouse gas\nemissions, which in turn lead to global warming and climate change. Therefore\nthe energy consumption of code must be minimized. Code can be generated by\nlarge language models. We look at the influence of prompt modification on the\nenergy consumption of the code generated. We use three different Python code\nproblems of varying difficulty levels. Prompt modification is done by adding\nthe sentence ``Give me an energy-optimized solution for this problem'' or by\nusing two Python coding best practices. The large language models used are\nCodeLlama-70b, CodeLlama-70b-Instruct, CodeLlama-70b-Python,\nDeepSeek-Coder-33b-base, and DeepSeek-Coder-33b-instruct. We find a decrease in\nenergy consumption for a specific combination of prompt optimization, LLM, and\nPython code problem. However, no single optimization prompt consistently\ndecreases energy consumption for the same LLM across the different Python code\nproblems.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(LLMs)生成能源高效代码，以减少计算机系统能源消耗并缓解温室气体排放问题。研究者通过修改提示词（如添加“Give me an energy-optimized solution for this problem”或应用Python编码最佳实践）来测试生成的Python代码能源效率，并评估了多种LLMs（如CodeLlama-70b和DeepSeek-Coder-33b）。结果表明，特定提示优化、LLM和代码问题的组合可降低能源消耗，但没有单一优化策略能一致适用于同一LLMs下的不同问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10599v1",
      "published_date": "2024-11-15 21:45:58 UTC",
      "updated_date": "2024-11-15 21:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:44:48.374978"
    },
    {
      "arxiv_id": "2411.10596v1",
      "title": "A minimalistic representation model for head direction system",
      "title_zh": "翻译失败",
      "authors": [
        "Minglu Zhao",
        "Dehong Xu",
        "Deqian Kong",
        "Wen-Hao Zhang",
        "Ying Nian Wu"
      ],
      "abstract": "We present a minimalistic representation model for the head direction (HD)\nsystem, aiming to learn a high-dimensional representation of head direction\nthat captures essential properties of HD cells. Our model is a representation\nof rotation group $U(1)$, and we study both the fully connected version and\nconvolutional version. We demonstrate the emergence of Gaussian-like tuning\nprofiles and a 2D circle geometry in both versions of the model. We also\ndemonstrate that the learned model is capable of accurate path integration.",
      "tldr_zh": "我们提出一个针对头方向 (HD) 系统的最小化表示模型，旨在学习高维表示以捕捉 HD 细胞的基本属性。模型基于旋转群 U(1)，并研究了全连接版本和卷积版本。结果显示，模型中出现了 Gaussian-like tuning profiles 和 2D 圆形几何，并能够实现准确的 path integration。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Workshop on Symmetry and Geometry in Neural Representations\n  (NeurReps) at NeurIPS 2024, Extended Abstract Track",
      "pdf_url": "http://arxiv.org/pdf/2411.10596v1",
      "published_date": "2024-11-15 21:38:33 UTC",
      "updated_date": "2024-11-15 21:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:44:59.556982"
    },
    {
      "arxiv_id": "2411.12758v1",
      "title": "An exploration of the effect of quantisation on energy consumption and inference time of StarCoder2",
      "title_zh": "翻译失败",
      "authors": [
        "Pepijn de Reus",
        "Ana Oprescu",
        "Jelle Zuidema"
      ],
      "abstract": "This study examines quantisation and pruning strategies to reduce energy\nconsumption in code Large Language Models (LLMs) inference. Using StarCoder2,\nwe observe increased energy demands with quantization due to lower throughput\nand some accuracy losses. Conversely, pruning reduces energy usage but impairs\nperformance. The results highlight challenges and trade-offs in LLM model\ncompression. We suggest future work on hardware-optimized quantization to\nenhance efficiency with minimal loss in accuracy.",
      "tldr_zh": "本研究探讨了量化（quantisation）和剪枝（pruning）策略对代码大语言模型（LLMs）推理能耗的影响，以StarCoder2为例。结果显示，量化虽然旨在降低能耗，但由于吞吐量（throughput）降低和部分准确性损失，反而增加了能源需求；相反，剪枝能减少能源使用，但会损害模型性能。这些发现突出了LLMs模型压缩中的权衡挑战，并建议未来通过硬件优化量化来实现更高效率，同时最小化准确性损失。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12758v1",
      "published_date": "2024-11-15 21:28:19 UTC",
      "updated_date": "2024-11-15 21:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:45:12.187837"
    },
    {
      "arxiv_id": "2411.10588v3",
      "title": "A dataset of questions on decision-theoretic reasoning in Newcomb-like problems",
      "title_zh": "翻译失败",
      "authors": [
        "Caspar Oesterheld",
        "Emery Cooper",
        "Miles Kodama",
        "Linh Chi Nguyen",
        "Ethan Perez"
      ],
      "abstract": "We introduce a dataset of natural-language questions in the decision theory\nof so-called Newcomb-like problems. Newcomb-like problems include, for\ninstance, decision problems in which an agent interacts with a similar other\nagent, and thus has to reason about the fact that the other agent will likely\nreason in similar ways. Evaluating LLM reasoning about Newcomb-like problems is\nimportant because interactions between foundation-model-based agents will often\nbe Newcomb-like. Some ways of reasoning about Newcomb-like problems may allow\nfor greater cooperation between models.\n  Our dataset contains both capabilities questions (i.e., questions with a\nunique, uncontroversially correct answer) and attitude questions (i.e.,\nquestions about which decision theorists would disagree). We use our dataset\nfor an investigation of decision-theoretical capabilities and expressed\nattitudes and their interplay in existing models (different models by OpenAI,\nAnthropic, Meta, GDM, Reka, etc.), as well as models under simple prompt-based\ninterventions. We find, among other things, that attitudes vary significantly\nbetween existing models; that high capabilities are associated with attitudes\nmore favorable toward so-called evidential decision theory; and that attitudes\nare consistent across different types of questions.",
      "tldr_zh": "本文引入了一个包含自然语言问题的数据集，专注于Newcomb-like problems的决策理论推理，这些问题涉及代理互动和类似推理，以促进基础模型间合作。数据集分为capabilities questions（有唯一正确答案）和attitude questions（决策理论家可能不同意），并用于评估OpenAI、Anthropic等现有LLM模型的能力和态度。研究发现，不同模型的态度差异显著，高能力与evidential decision theory更相关，且态度在问题类型间保持一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "48 pages, 15 figures; code and data at\n  https://github.com/casparoe/newcomblike_questions_dataset; corrected error in\n  funding acknowledgments",
      "pdf_url": "http://arxiv.org/pdf/2411.10588v3",
      "published_date": "2024-11-15 21:19:04 UTC",
      "updated_date": "2024-12-15 20:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:45:24.298941"
    },
    {
      "arxiv_id": "2411.10581v1",
      "title": "On the Shortcut Learning in Multilingual Neural Machine Translation",
      "title_zh": "关于多语言神经机器翻译中的捷径学习",
      "authors": [
        "Wenxuan Wang",
        "Wenxiang Jiao",
        "Jen-tse Huang",
        "Zhaopeng Tu",
        "Michael R. Lyu"
      ],
      "abstract": "In this study, we revisit the commonly-cited off-target issue in multilingual\nneural machine translation (MNMT). By carefully designing experiments on\ndifferent MNMT scenarios and models, we attribute the off-target issue to the\noverfitting of the shortcuts of (non-centric, centric) language mappings.\nSpecifically, the learned shortcuts biases MNMT to mistakenly translate\nnon-centric languages into the centric language instead of the expected\nnon-centric language for zero-shot translation. Analyses on learning dynamics\nshow that the shortcut learning generally occurs in the later stage of model\ntraining, and multilingual pretraining accelerates and aggravates the shortcut\nlearning. Based on these observations, we propose a simple and effective\ntraining strategy to eliminate the shortcuts in MNMT models by leveraging the\nforgetting nature of model training. The only difference from the standard\ntraining is that we remove the training instances that may induce the shortcut\nlearning in the later stage of model training. Without introducing any\nadditional data and computational costs, our approach can consistently and\nsignificantly improve the zero-shot translation performance by alleviating the\nshortcut learning for different MNMT models and benchmarks.",
      "tldr_zh": "本研究探讨了多语言神经机器翻译 (MNMT) 中的 shortcut learning 问题，即模型过度拟合语言映射的快捷方式，导致零射翻译错误地将非中心语言翻译成中心语言。分析显示，这种快捷方式学习主要发生在训练后期，且多语言预训练会加速和加剧这一现象。为解决此问题，研究提出了一种简单训练策略，通过在训练后期移除可能诱发 shortcut learning 的实例，利用模型的遗忘特性来消除这些偏差。该方法无需额外数据或计算成本，即可显著提升不同 MNMT 模型在各种基准上的零射翻译性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by Neurocomputing 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10581v1",
      "published_date": "2024-11-15 21:09:36 UTC",
      "updated_date": "2024-11-15 21:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:45:36.567023"
    },
    {
      "arxiv_id": "2411.12591v1",
      "title": "Thinking Before Looking: Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination",
      "title_zh": "翻译失败",
      "authors": [
        "Haojie Zheng",
        "Tianyang Xu",
        "Hanchi Sun",
        "Shu Pu",
        "Ruoxi Chen",
        "Lichao Sun"
      ],
      "abstract": "Multimodal large language models (MLLMs) have advanced the integration of\nvisual and linguistic modalities, establishing themselves as the dominant\nparadigm for visual-language tasks. Current approaches like chain of thought\n(CoT) reasoning have augmented the cognitive capabilities of large language\nmodels (LLMs), yet their adaptation to MLLMs is hindered by heightened risks of\nhallucination in cross-modality comprehension. In this paper, we find that the\nthinking while looking paradigm in current multimodal CoT approaches--where\nreasoning chains are generated alongside visual input--fails to mitigate\nhallucinations caused by misleading images. To address these limitations, we\npropose the Visual Inference Chain (VIC) framework, a novel approach that\nconstructs reasoning chains using textual context alone before introducing\nvisual input, effectively reducing cross-modal biases and enhancing multimodal\nreasoning accuracy. Comprehensive evaluations demonstrate that VIC\nsignificantly improves zero-shot performance across various vision-related\ntasks, mitigating hallucinations while refining the reasoning capabilities of\nMLLMs. Our code repository can be found at\nhttps://github.com/Terry-Xu-666/visual_inference_chain.",
      "tldr_zh": "当前的多模态大语言模型 (MLLMs) 在视觉语言任务中面临 hallucination 问题，尤其是 Chain of Thought (CoT) 推理方法在处理视觉输入时容易受误导图像影响。论文提出 Visual Inference Chain (VIC) 框架，该方法先基于文本上下文构建推理链，然后再引入视觉输入，从而减少跨模态偏差并提升多模态推理准确性。实验评估显示，VIC 显著提高了 MLLMs 在各种视觉相关任务的 zero-shot 性能，同时有效缓解了 hallucination 问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12591v1",
      "published_date": "2024-11-15 21:01:37 UTC",
      "updated_date": "2024-11-15 21:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:45:49.059734"
    },
    {
      "arxiv_id": "2411.14456v1",
      "title": "Can Artificial Intelligence Generate Quality Research Topics Reflecting Patient Concerns?",
      "title_zh": "人工智能是否能生成反映患者关切的优质研究主题？",
      "authors": [
        "Jiyeong Kim",
        "Michael L. Chen",
        "Shawheen J. Rezaei",
        "Mariana Ramirez-Posada",
        "Jennifer L. Caswell-Jin",
        "Allison W. Kurian",
        "Fauzia Riaz",
        "Kavita Y. Sarin",
        "Jean Y. Tang",
        "Steven M. Asch",
        "Eleni Linos"
      ],
      "abstract": "Patient-centered research is increasingly important in narrowing the gap\nbetween research and patient care, yet incorporating patient perspectives into\nhealth research has been inconsistent. We propose an automated framework\nleveraging innovative natural language processing (NLP) and artificial\nintelligence (AI) with patient portal messages to generate research ideas that\nprioritize important patient issues. We further quantified the quality of\nAI-generated research topics. To define patient clinical concerns, we analyzed\n614,464 patient messages from 25,549 individuals with breast or skin cancer\nobtained from a large academic hospital (2013 to 2024), constructing a 2-staged\nunsupervised NLP topic model. Then, we generated research topics to resolve the\ndefined issues using a widely used AI (ChatGPT-4o, OpenAI Inc, April 2024\nversion) with prompt-engineering strategies. We guided AI to perform\nmulti-level tasks: 1) knowledge interpretation and summarization (e.g.,\ninterpreting and summarizing the NLP-defined topics), 2) knowledge generation\n(e.g., generating research ideas corresponding to patients issues), 3)\nself-reflection and correction (e.g., ensuring and revising the research ideas\nafter searching for scientific articles), and 4) self-reassurance (e.g.,\nconfirming and finalizing the research ideas). Six highly experienced breast\noncologists and dermatologists assessed the significance and novelty of\nAI-generated research topics using a 5-point Likert scale (1-exceptional,\n5-poor). One-third of the AI-suggested research topics were highly significant\nand novel when both scores were lower than the average. Two-thirds of the\nAI-suggested topics were novel in both cancers. Our findings demonstrate that\nAI-generated research topics reflecting patient perspectives via a large volume\nof patient messages can meaningfully guide future directions in\npatient-centered health research.",
      "tldr_zh": "本研究探讨 AI 是否能生成反映患者关切的优质研究主题，提出一个自动化框架，利用 natural language processing (NLP) 和 artificial intelligence (AI) 分析患者门户消息。\n研究团队分析了 61 万多条乳腺癌和皮肤癌患者消息（2013-2024），通过 2 阶段无监督 NLP 主题模型定义患者临床关切，并使用 ChatGPT-4o 结合提示工程策略进行知识解释、生成、自我反思和修正，以产生相关研究想法。\n专家评估显示，三分之一的 AI 生成主题在重要性和新颖性上得分较高（5 点 Likert 量表平均以下），两分之三在两种癌症中显示新颖性。\n总体结果证明，该框架能有效从患者视角引导患者中心健康研究的未来方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14456v1",
      "published_date": "2024-11-15 20:24:38 UTC",
      "updated_date": "2024-11-15 20:24:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:46:02.852777"
    },
    {
      "arxiv_id": "2411.10564v2",
      "title": "Vision Eagle Attention: a new lens for advancing image classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mahmudul Hasan"
      ],
      "abstract": "In computer vision tasks, the ability to focus on relevant regions within an\nimage is crucial for improving model performance, particularly when key\nfeatures are small, subtle, or spatially dispersed. Convolutional neural\nnetworks (CNNs) typically treat all regions of an image equally, which can lead\nto inefficient feature extraction. To address this challenge, I have introduced\nVision Eagle Attention, a novel attention mechanism that enhances visual\nfeature extraction using convolutional spatial attention. The model applies\nconvolution to capture local spatial features and generates an attention map\nthat selectively emphasizes the most informative regions of the image. This\nattention mechanism enables the model to focus on discriminative features while\nsuppressing irrelevant background information. I have integrated Vision Eagle\nAttention into a lightweight ResNet-18 architecture, demonstrating that this\ncombination results in an efficient and powerful model. I have evaluated the\nperformance of the proposed model on three widely used benchmark datasets:\nFashionMNIST, Intel Image Classification, and OracleMNIST, with a primary focus\non image classification. Experimental results show that the proposed approach\nimproves classification accuracy. Additionally, this method has the potential\nto be extended to other vision tasks, such as object detection, segmentation,\nand visual tracking, offering a computationally efficient solution for a wide\nrange of vision-based applications. Code is available at:\nhttps://github.com/MahmudulHasan11085/Vision-Eagle-Attention.git",
      "tldr_zh": "该研究引入了Vision Eagle Attention，一种新型注意力机制，用于提升图像分类性能，通过卷积空间注意力捕获局部特征并生成注意力映射，以重点关注图像中信息丰富的区域，同时抑制无关背景。作者将该机制集成到轻量级ResNet-18架构中，并在FashionMNIST、Intel Image Classification和OracleMNIST基准数据集上进行评估，结果显示分类准确率得到显著改善。该方法不仅提供高效的视觉特征提取，还可扩展应用于物体检测、分割和视觉跟踪等其他计算机视觉任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.10564v2",
      "published_date": "2024-11-15 20:21:59 UTC",
      "updated_date": "2024-12-09 05:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:47:47.092130"
    },
    {
      "arxiv_id": "2411.10561v1",
      "title": "Pragmatic information of aesthetic appraisal",
      "title_zh": "翻译失败",
      "authors": [
        "Peter beim Graben"
      ],
      "abstract": "A phenomenological model for aesthetic appraisal is proposed in terms of\npragmatic information for a dynamic update semantics over belief states on an\naesthetic appreciator. The model qualitatively correlates with aesthetic\npleasure ratings in an experimental study on cadential effects in Western tonal\nmusic. Finally, related computational and neurodynamical accounts are\ndiscussed.",
      "tldr_zh": "本论文提出了一种基于实用信息(Pragmatic information)的现象学模型(Phenomenological model)，用于动态更新语义(Dynamic update semantics)来处理审美欣赏者(Aesthetic appreciator)的信念状态(Belief states)，从而评估审美评价(Aesthetic appraisal)。在针对西方调性音乐(Western tonal music)的终止效果(Cadential effects)实验中，该模型与审美愉悦评级(Aesthetic pleasure ratings)显示出定性相关。最终，论文讨论了相关的计算和神经动力学账户(Computational and neurodynamical accounts)。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10561v1",
      "published_date": "2024-11-15 20:15:15 UTC",
      "updated_date": "2024-11-15 20:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:46:25.231154"
    },
    {
      "arxiv_id": "2411.10555v1",
      "title": "Low-Rank Optimal Transport through Factor Relaxation with Latent Coupling",
      "title_zh": "低秩最优传输通过因子松弛与潜在耦合",
      "authors": [
        "Peter Halmos",
        "Xinhao Liu",
        "Julian Gold",
        "Benjamin J Raphael"
      ],
      "abstract": "Optimal transport (OT) is a general framework for finding a minimum-cost\ntransport plan, or coupling, between probability distributions, and has many\napplications in machine learning. A key challenge in applying OT to massive\ndatasets is the quadratic scaling of the coupling matrix with the size of the\ndataset. [Forrow et al. 2019] introduced a factored coupling for the\nk-Wasserstein barycenter problem, which [Scetbon et al. 2021] adapted to solve\nthe primal low-rank OT problem. We derive an alternative parameterization of\nthe low-rank problem based on the $\\textit{latent coupling}$ (LC) factorization\npreviously introduced by [Lin et al. 2021] generalizing [Forrow et al. 2019].\nThe LC factorization has multiple advantages for low-rank OT including\ndecoupling the problem into three OT problems and greater flexibility and\ninterpretability. We leverage these advantages to derive a new algorithm\n$\\textit{Factor Relaxation with Latent Coupling}$ (FRLC), which uses\n$\\textit{coordinate}$ mirror descent to compute the LC factorization. FRLC\nhandles multiple OT objectives (Wasserstein, Gromov-Wasserstein, Fused\nGromov-Wasserstein), and marginal constraints (balanced, unbalanced, and\nsemi-relaxed) with linear space complexity. We provide theoretical results on\nFRLC, and demonstrate superior performance on diverse applications -- including\ngraph clustering and spatial transcriptomics -- while demonstrating its\ninterpretability.",
      "tldr_zh": "本文提出了一种基于 latent coupling (LC) 分解的 low-rank Optimal Transport (OT) 参数化方法，以解决 OT 在大规模数据集中的耦合矩阵计算挑战，该方法将问题分解为三个独立的 OT 问题，提高了灵活性和可解释性。作者开发了 Factor Relaxation with Latent Coupling (FRLC) 算法，使用 coordinate mirror descent 进行优化，支持多种 OT 目标（如 Wasserstein、Gromov-Wasserstein 和 Fused Gromov-Wasserstein）以及边际约束（如 balanced、unbalanced 和 semi-relaxed），并实现了线性空间复杂度。实验结果显示，FRLC 在图聚类和空间转录组学等应用中比现有方法表现出色，并提供了理论支持和良好的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "53 pages, 13 figures, NeurIPS 2024. Comments welcome!",
      "pdf_url": "http://arxiv.org/pdf/2411.10555v1",
      "published_date": "2024-11-15 20:07:15 UTC",
      "updated_date": "2024-11-15 20:07:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:46:38.750064"
    },
    {
      "arxiv_id": "2411.12589v2",
      "title": "ULTra: Unveiling Latent Token Interpretability in Transformer-Based Understanding and Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Hesam Hosseini",
        "Ghazal Hosseini Mighan",
        "Amirabbas Afzali",
        "Sajjad Amini",
        "Amir Houmansadr"
      ],
      "abstract": "Transformers have revolutionized Computer Vision (CV) through self-attention\nmechanisms. However, their complexity makes latent token representations\ndifficult to interpret. We introduce ULTra, a framework for interpreting\nTransformer embeddings and uncovering meaningful semantic patterns within them.\nULTra enables unsupervised semantic segmentation using pre-trained models\nwithout requiring fine-tuning. Additionally, we propose a self-supervised\ntraining approach that refines segmentation performance by learning an external\ntransformation matrix without modifying the underlying model. Our method\nachieves state-of-the-art performance in unsupervised semantic segmentation,\noutperforming existing segmentation methods. Furthermore, we validate ULTra for\nmodel interpretation on both synthetic and real-world scenarios, including\nObject Selection and interpretable text summarization using LLMs, demonstrating\nits broad applicability in explaining the semantic structure of latent token\nrepresentations.",
      "tldr_zh": "本研究提出 ULTra 框架，用于解释 Transformer 模型中的潜在 token 表示，并揭示其内在语义模式，以解决 Transformer 在计算机视觉 (CV) 中的复杂性和可解释性挑战。ULTra 实现无监督语义 segmentation，利用预训练模型无需微调，并引入一种自监督训练方法，通过学习外部转换矩阵来提升分割性能，而不改变底层模型。该方法在无监督语义 segmentation 任务上达到最先进水平，优于现有方法，并在合成和真实场景（如 Object Selection 和可解释文本摘要 using LLMs）中验证了其广泛适用性，用于模型解释和语义结构分析。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12589v2",
      "published_date": "2024-11-15 19:36:50 UTC",
      "updated_date": "2025-03-22 19:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:46:48.420972"
    },
    {
      "arxiv_id": "2411.10534v1",
      "title": "Chain of Alignment: Integrating Public Will with Expert Intelligence for Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Konya",
        "Aviv Ovadya",
        "Kevin Feng",
        "Quan Ze Chen",
        "Lisa Schirch",
        "Colin Irwin",
        "Amy X. Zhang"
      ],
      "abstract": "We introduce a method to measure the alignment between public will and\nlanguage model (LM) behavior that can be applied to fine-tuning, online\noversight, and pre-release safety checks. Our `chain of alignment' (CoA)\napproach produces a rule based reward (RBR) by creating model behavior\n$\\textit{rules}$ aligned to normative $\\textit{objectives}$ aligned to\n$\\textit{public will}$. This factoring enables a nonexpert public to directly\nspecify their will through the normative objectives, while expert intelligence\nis used to figure out rules entailing model behavior that best achieves those\nobjectives. We validate our approach by applying it across three different\ndomains of LM prompts related to mental health. We demonstrate a public input\nprocess built on collective dialogues and bridging-based ranking that reliably\nproduces normative objectives supported by at least $96\\% \\pm 2\\%$ of the US\npublic. We then show that rules developed by mental health experts to achieve\nthose objectives enable a RBR that evaluates an LM response's alignment with\nthe objectives similarly to human experts (Pearson's $r=0.841$, $AUC=0.964$).\nBy measuring alignment with objectives that have near unanimous public support,\nthese CoA RBRs provide an approximate measure of alignment between LM behavior\nand public will.",
      "tldr_zh": "该研究引入了Chain of Alignment (CoA)方法，用于衡量公众意愿与语言模型(LM)行为的对齐度，并应用于LM的微调、在线监督和预发布安全检查。CoA通过将公众意愿转化为规范目标，再由专家制定相应规则来生成基于规则的奖励(RBR)，从而让非专家公众直接参与决策，同时利用专家智能确保规则的有效性。在心理健康领域的实验中，基于集体对话和桥接式排名的公众输入过程获得了至少96% ± 2%的美国公众支持，且RBR评估结果与人类专家高度一致(Pearson’s r=0.841, AUC=0.964)，为评估LM行为与公众意愿对齐度提供了可靠的近似测量。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Pluralistic Alignment Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10534v1",
      "published_date": "2024-11-15 19:10:39 UTC",
      "updated_date": "2024-11-15 19:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:47:01.293017"
    },
    {
      "arxiv_id": "2411.10446v2",
      "title": "VeriGraph: Scene Graphs for Execution Verifiable Robot Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Ekpo",
        "Mara Levy",
        "Saksham Suri",
        "Chuong Huynh",
        "Abhinav Shrivastava"
      ],
      "abstract": "Recent advancements in vision-language models (VLMs) offer potential for\nrobot task planning, but challenges remain due to VLMs' tendency to generate\nincorrect action sequences. To address these limitations, we propose VeriGraph,\na novel framework that integrates VLMs for robotic planning while verifying\naction feasibility. VeriGraph employs scene graphs as an intermediate\nrepresentation, capturing key objects and spatial relationships to improve plan\nverification and refinement. The system generates a scene graph from input\nimages and uses it to iteratively check and correct action sequences generated\nby an LLM-based task planner, ensuring constraints are respected and actions\nare executable. Our approach significantly enhances task completion rates\nacross diverse manipulation scenarios, outperforming baseline methods by 58%\nfor language-based tasks and 30% for image-based tasks.",
      "tldr_zh": "本论文提出 VeriGraph 框架，用于执行可验证的机器人规划，以解决视觉语言模型 (VLMs) 生成错误行动序列的挑战。框架通过 scene graphs 作为中间表示，捕捉输入图像中的关键对象和空间关系，并迭代检查和修正 LLM-based 任务规划器生成的行动序列，确保符合约束并可执行。实验结果显示，VeriGraph 在多样化操作场景中显著提升任务完成率，比基线方法在语言-based 任务上提高 58%，在图像-based 任务上提高 30%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10446v2",
      "published_date": "2024-11-15 18:59:51 UTC",
      "updated_date": "2024-11-21 15:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:47:12.521027"
    },
    {
      "arxiv_id": "2411.10436v1",
      "title": "Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization",
      "title_zh": "通过针对幻觉的直接偏好优化缓解多模态大语言模型中的幻觉",
      "authors": [
        "Yuhan Fu",
        "Ruobing Xie",
        "Xingwu Sun",
        "Zhanhui Kang",
        "Xirong Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are known to hallucinate, which\nlimits their practical applications. Recent works have attempted to apply\nDirect Preference Optimization (DPO) to enhance the performance of MLLMs, but\nhave shown inconsistent improvements in mitigating hallucinations. To address\nthis issue more effectively, we introduce Hallucination-targeted Direct\nPreference Optimization (HDPO) to reduce hallucinations in MLLMs. Unlike\nprevious approaches, our method tackles hallucinations from their diverse forms\nand causes. Specifically, we develop three types of preference pair data\ntargeting the following causes of MLLM hallucinations: (1) insufficient visual\ncapabilities, (2) long context generation, and (3) multimodal conflicts.\nExperimental results demonstrate that our method achieves superior performance\nacross multiple hallucination evaluation datasets, surpassing most\nstate-of-the-art (SOTA) methods and highlighting the potential of our approach.\nAblation studies and in-depth analyses further confirm the effectiveness of our\nmethod and suggest the potential for further improvements through scaling up.",
      "tldr_zh": "这项研究针对Multimodal Large Language Models (MLLMs)中的幻觉(hallucination)问题，提出了一种Hallucination-targeted Direct Preference Optimization (HDPO)方法，以更有效地缓解这一问题。HDPO通过开发三种类型的偏好对数据，分别针对MLLMs幻觉的成因，包括视觉能力不足、长上下文生成和多模态冲突，从而提升模型的鲁棒性。实验结果显示，HDPO在多个幻觉评估数据集上超越了State-of-the-art (SOTA)方法，消融研究进一步证实了其有效性，并指出通过扩展规模可实现更多改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10436v1",
      "published_date": "2024-11-15 18:56:01 UTC",
      "updated_date": "2024-11-15 18:56:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:47:25.009838"
    },
    {
      "arxiv_id": "2411.10431v1",
      "title": "Mitigating Parameter Degeneracy using Joint Conditional Diffusion Model for WECC Composite Load Model in Power Systems",
      "title_zh": "使用联合条件扩散模型缓解 WECC 复合负荷模型",
      "authors": [
        "Feiqin Zhu",
        "Dmitrii Torbunov",
        "Yihui Ren",
        "Zhongjing Jiang",
        "Tianqiao Zhao",
        "Amirthagunaraj Yogarathnam",
        "Meng Yue"
      ],
      "abstract": "Data-driven modeling for dynamic systems has gained widespread attention in\nrecent years. Its inverse formulation, parameter estimation, aims to infer the\ninherent model parameters from observations. However, parameter degeneracy,\nwhere different combinations of parameters yield the same observable output,\nposes a critical barrier to accurately and uniquely identifying model\nparameters. In the context of WECC composite load model (CLM) in power systems,\nutility practitioners have observed that CLM parameters carefully selected for\none fault event may not perform satisfactorily in another fault. Here, we\ninnovate a joint conditional diffusion model-based inverse problem solver\n(JCDI), that incorporates a joint conditioning architecture with simultaneous\ninputs of multi-event observations to improve parameter generalizability.\nSimulation studies on the WECC CLM show that the proposed JCDI effectively\nreduces uncertainties of degenerate parameters, thus the parameter estimation\nerror is decreased by 42.1% compared to a single-event learning scheme. This\nenables the model to achieve high accuracy in predicting power trajectories\nunder different fault events, including electronic load tripping and motor\nstalling, outperforming standard deep reinforcement learning and supervised\nlearning approaches. We anticipate this work will contribute to mitigating\nparameter degeneracy in system dynamics, providing a general parameter\nestimation framework across various scientific domains.",
      "tldr_zh": "该论文针对电力系统中的 WECC composite load model 解决 parameter degeneracy 问题，即不同参数组合导致相同输出，从而影响参数估计的准确性。作者提出了一种 Joint Conditional Diffusion Model (JCDI)，通过联合条件架构和多事件观察输入，实现参数估计的泛化性提升。实验结果显示，JCDI 减少了退化参数的不确定性，与单事件学习方案相比，参数估计错误降低 42.1%，并在预测各种故障事件（如电子负载跳闸和电机失速）下的功率轨迹时，优于标准深度强化学习和监督学习方法。该方法为缓解系统动力学中的 parameter degeneracy 提供了一个通用框架，适用于多个科学领域。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10431v1",
      "published_date": "2024-11-15 18:53:08 UTC",
      "updated_date": "2024-11-15 18:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:48:00.490805"
    },
    {
      "arxiv_id": "2411.10422v1",
      "title": "Evaluating Creativity and Deception in Large Language Models: A Simulation Framework for Multi-Agent Balderdash",
      "title_zh": "评估大语言模型的创造力和欺骗性：多智能体 Balderdash 的模拟框架",
      "authors": [
        "Parsa Hejabi",
        "Elnaz Rahmati",
        "Alireza S. Ziabari",
        "Preni Golazizian",
        "Jesse Thomason",
        "Morteza Dehghani"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive capabilities in complex\ntasks and interactive environments, yet their creativity remains underexplored.\nThis paper introduces a simulation framework utilizing the game Balderdash to\nevaluate both the creativity and logical reasoning of LLMs. In Balderdash,\nplayers generate fictitious definitions for obscure terms to deceive others\nwhile identifying correct definitions. Our framework enables multiple LLM\nagents to participate in this game, assessing their ability to produce\nplausible definitions and strategize based on game rules and history. We\nimplemented a centralized game engine featuring various LLMs as participants\nand a judge LLM to evaluate semantic equivalence. Through a series of\nexperiments, we analyzed the performance of different LLMs, examining metrics\nsuch as True Definition Ratio, Deception Ratio, and Correct Guess Ratio. The\nresults provide insights into the creative and deceptive capabilities of LLMs,\nhighlighting their strengths and areas for improvement. Specifically, the study\nreveals that infrequent vocabulary in LLMs' input leads to poor reasoning on\ngame rules and historical context\n(https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash).",
      "tldr_zh": "本研究提出了一种模拟框架，使用游戏Balderdash评估Large Language Models (LLMs)的创造力和逻辑推理能力，聚焦于LLMs生成虚假定义以欺骗他人并识别正确定义的性能。框架允许多个LLM代理参与游戏，通过集中的游戏引擎和一个判断LLM评估语义等价性，同时考虑游戏规则和历史背景来制定策略。实验分析了不同LLMs的表现，使用指标如True Definition Ratio、Deception Ratio和Correct Guess Ratio，结果显示LLMs在创造性方面有优势，但输入中不常见词汇会削弱其对规则和背景的推理能力。该框架为理解LLMs的欺骗潜力提供了新见解，并附有开源实现（https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash）。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at Wordplay: When Language Meets Games @ ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10422v1",
      "published_date": "2024-11-15 18:42:48 UTC",
      "updated_date": "2024-11-15 18:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:48:10.631766"
    },
    {
      "arxiv_id": "2411.10416v1",
      "title": "Towards Automatic Evaluation of Task-Oriented Dialogue Flows",
      "title_zh": "迈向任务导向对话流的自动评估",
      "authors": [
        "Mehrnoosh Mirtaheri",
        "Nikhil Varghese",
        "Chandra Khatri",
        "Amol Kelkar"
      ],
      "abstract": "Task-oriented dialogue systems rely on predefined conversation schemes\n(dialogue flows) often represented as directed acyclic graphs. These flows can\nbe manually designed or automatically generated from previously recorded\nconversations. Due to variations in domain expertise or reliance on different\nsets of prior conversations, these dialogue flows can manifest in significantly\ndifferent graph structures. Despite their importance, there is no standard\nmethod for evaluating the quality of dialogue flows. We introduce FuDGE (Fuzzy\nDialogue-Graph Edit Distance), a novel metric that evaluates dialogue flows by\nassessing their structural complexity and representational coverage of the\nconversation data. FuDGE measures how well individual conversations align with\na flow and, consequently, how well a set of conversations is represented by the\nflow overall. Through extensive experiments on manually configured flows and\nflows generated by automated techniques, we demonstrate the effectiveness of\nFuDGE and its evaluation framework. By standardizing and optimizing dialogue\nflows, FuDGE enables conversational designers and automated techniques to\nachieve higher levels of efficiency and automation.",
      "tldr_zh": "本研究针对任务导向对话系统（Task-Oriented Dialogue Systems）的对话流（通常表示为有向无环图）提出了一种自动评估方法，解决现有对话流缺乏标准质量评估的问题。作者引入了 FuDGE（Fuzzy Dialogue-Graph Edit Distance）指标，该指标通过评估对话流的结构复杂性和对对话数据的表示覆盖，来衡量单个对话与流之间的匹配程度，以及整体对话集的代表性。通过广泛实验，FuDGE 在手动和自动生成的对话流上证明了其有效性，帮助对话设计师和自动化技术实现更高的效率和自动化水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10416v1",
      "published_date": "2024-11-15 18:35:00 UTC",
      "updated_date": "2024-11-15 18:35:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:48:22.266215"
    },
    {
      "arxiv_id": "2411.10411v2",
      "title": "Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Karmann",
        "Onay Urfalioglu"
      ],
      "abstract": "Recent progress in interactive point prompt based Image Segmentation allows\nto significantly reduce the manual effort to obtain high quality semantic\nlabels. State-of-the-art unsupervised methods use self-supervised pre-trained\nmodels to obtain pseudo-labels which are used in training a prompt-based\nsegmentation model. In this paper, we propose a novel unsupervised and\ntraining-free approach based solely on the self-attention of Stable Diffusion.\nWe interpret the self-attention tensor as a Markov transition operator, which\nenables us to iteratively construct a Markov chain. Pixel-wise counting of the\nrequired number of iterations along the Markov chain to reach a relative\nprobability threshold yields a Markov-iteration-map, which we simply call a\nMarkov-map. Compared to the raw attention maps, we show that our proposed\nMarkov-map has less noise, sharper semantic boundaries and more uniform values\nwithin semantically similar regions. We integrate the Markov-map in a simple\nyet effective truncated nearest neighbor framework to obtain interactive point\nprompt based segmentation. Despite being training-free, we experimentally show\nthat our approach yields excellent results in terms of Number of Clicks (NoC),\neven outperforming state-of-the-art training based unsupervised methods in most\nof the datasets. Code is available at https://github.com/mkarmann/m2n2.",
      "tldr_zh": "本文提出了一种无需训练的无监督交互式图像分割方法，名为 Repurposing Stable Diffusion Attention，通过利用 Stable Diffusion 的自注意力张量作为 Markov 转移算子来构建 Markov 链。方法计算像素沿 Markov 链到达相对概率阈值的迭代次数，生成 Markov-map，该图具有更少的噪声、更清晰的语义边界和更均匀的区域值，并将其整合到截断最近邻框架中实现点提示分割。实验结果显示，该方法在多个数据集上表现出色，在点击次数（NoC）指标上甚至优于现有基于训练的无监督方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.10411v2",
      "published_date": "2024-11-15 18:29:59 UTC",
      "updated_date": "2025-03-20 16:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:48:34.329211"
    },
    {
      "arxiv_id": "2411.10406v2",
      "title": "How to Build a Quantum Supercomputer: Scaling from Hundreds to Millions of Qubits",
      "title_zh": "如何构建量子超级计算机：从数百到数百万量子比特的扩展",
      "authors": [
        "Masoud Mohseni",
        "Artur Scherer",
        "K. Grace Johnson",
        "Oded Wertheim",
        "Matthew Otten",
        "Navid Anjum Aadit",
        "Yuri Alexeev",
        "Kirk M. Bresniker",
        "Kerem Y. Camsari",
        "Barbara Chapman",
        "Soumitra Chatterjee",
        "Gebremedhin A. Dagnew",
        "Aniello Esposito",
        "Farah Fahim",
        "Marco Fiorentino",
        "Archit Gajjar",
        "Abdullah Khalid",
        "Xiangzhou Kong",
        "Bohdan Kulchytskyy",
        "Elica Kyoseva",
        "Ruoyu Li",
        "P. Aaron Lott",
        "Igor L. Markov",
        "Robert F. McDermott",
        "Giacomo Pedretti",
        "Pooja Rao",
        "Eleanor Rieffel",
        "Allyson Silva",
        "John Sorebo",
        "Panagiotis Spentzouris",
        "Ziv Steiner",
        "Boyan Torosov",
        "Davide Venturelli",
        "Robert J. Visser",
        "Zak Webb",
        "Xin Zhan",
        "Yonatan Cohen",
        "Pooya Ronagh",
        "Alan Ho",
        "Raymond G. Beausoleil",
        "John M. Martinis"
      ],
      "abstract": "In the span of four decades, quantum computation has evolved from an\nintellectual curiosity to a potentially realizable technology. Today,\nsmall-scale demonstrations have become possible for quantum algorithmic\nprimitives on hundreds of physical qubits and proof-of-principle\nerror-correction on a single logical qubit. Nevertheless, despite significant\nprogress and excitement, the path toward a full-stack scalable technology is\nlargely unknown. There are significant outstanding quantum hardware,\nfabrication, software architecture, and algorithmic challenges that are either\nunresolved or overlooked. These issues could seriously undermine the arrival of\nutility-scale quantum computers for the foreseeable future. Here, we provide a\ncomprehensive review of these scaling challenges. We show how the road to\nscaling could be paved by adopting existing semiconductor technology to build\nmuch higher-quality qubits, employing system engineering approaches, and\nperforming distributed quantum computation within heterogeneous\nhigh-performance computing infrastructures. These opportunities for research\nand development could unlock certain promising applications, in particular,\nefficient quantum simulation/learning of quantum data generated by natural or\nengineered quantum systems. To estimate the true cost of such promises, we\nprovide a detailed resource and sensitivity analysis for classically hard\nquantum chemistry calculations on surface-code error-corrected quantum\ncomputers given current, target, and desired hardware specifications based on\nsuperconducting qubits, accounting for a realistic distribution of errors.\nFurthermore, we argue that, to tackle industry-scale classical optimization and\nmachine learning problems in a cost-effective manner, heterogeneous\nquantum-probabilistic computing with custom-designed accelerators should be\nconsidered as a complementary path toward scalability.",
      "tldr_zh": "这篇论文审视了从数百到数百万量子位（qubits）扩展量子计算机的挑战与路径，强调了硬件、制造、软件架构和算法方面的未解决问题，这些可能推迟实用量子计算机的实现。主要贡献包括提出采用半导体技术提升量子位质量、运用系统工程方法和分布式量子计算整合异构高性能计算基础设施，以实现高效量子模拟和学习量子数据。通过详细的资源和敏感性分析，论文评估了基于超导量子位（superconducting qubits）和表面码错误修正（surface-code error-corrected）的量子计算机在量子化学计算中的成本，发现优化这些规格可显著降低计算开销。最后，论文建议考虑异构量子-概率计算（heterogeneous quantum-probabilistic computing）作为处理大规模经典优化和机器学习问题的互补策略，以提升整体可扩展性。",
      "categories": [
        "quant-ph",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "quant-ph",
      "comment": "76 pages, 46 figures. General revision, added figures, added\n  references, added appendices",
      "pdf_url": "http://arxiv.org/pdf/2411.10406v2",
      "published_date": "2024-11-15 18:22:46 UTC",
      "updated_date": "2025-01-31 18:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:48:46.601819"
    },
    {
      "arxiv_id": "2411.10397v2",
      "title": "Features that Make a Difference: Leveraging Gradients for Improved Dictionary Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffrey Olmo",
        "Jared Wilson",
        "Max Forsey",
        "Bryce Hepner",
        "Thomas Vin Howe",
        "David Wingate"
      ],
      "abstract": "Sparse Autoencoders (SAEs) are a promising approach for extracting neural\nnetwork representations by learning a sparse and overcomplete decomposition of\nthe network's internal activations. However, SAEs are traditionally trained\nconsidering only activation values and not the effect those activations have on\ndownstream computations. This limits the information available to learn\nfeatures, and biases the autoencoder towards neglecting features which are\nrepresented with small activation values but strongly influence model outputs.\nTo address this, we introduce Gradient SAEs (g-SAEs), which modify the\n$k$-sparse autoencoder architecture by augmenting the TopK activation function\nto rely on the gradients of the input activation when selecting the $k$\nelements. For a given sparsity level, g-SAEs produce reconstructions that are\nmore faithful to original network performance when propagated through the\nnetwork. Additionally, we find evidence that g-SAEs learn latents that are on\naverage more effective at steering models in arbitrary contexts. By considering\nthe downstream effects of activations, our approach leverages the dual nature\nof neural network features as both $\\textit{representations}$, retrospectively,\nand $\\textit{actions}$, prospectively. While previous methods have approached\nthe problem of feature discovery primarily focused on the former aspect, g-SAEs\nrepresent a step towards accounting for the latter as well.",
      "tldr_zh": "本研究指出，传统 Sparse Autoencoders (SAEs) 在提取神经网络激活表示时，仅考虑激活值而忽略其对下游计算的影响，导致忽略那些激活值小但对模型输出有重大影响的特征。为解决此问题，论文提出 Gradient SAEs (g-SAEs)，通过在 TopK 激活函数中整合输入激活的梯度来选择 k 个元素，从而提升特征学习的效果。实验结果显示，g-SAEs 产生的重构更忠实于原网络性能，并在模型引导方面表现出平均更高的有效性。该方法强调神经网络特征的双重角色，既作为回顾性的表示，也作为前瞻性的行动。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 10 figures. Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.10397v2",
      "published_date": "2024-11-15 18:03:52 UTC",
      "updated_date": "2025-03-31 20:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:48:58.892922"
    },
    {
      "arxiv_id": "2411.10389v1",
      "title": "Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization",
      "title_zh": "使用关键点定位的深度学习在不平衡数据集上进行微尺度裂纹检测",
      "authors": [
        "Fatahlla Moreh",
        "Yusuf Hasan",
        "Bilal Zahid Hussain",
        "Mohammad Ammar",
        "Sven Tomforde"
      ],
      "abstract": "Internal crack detection has been a subject of focus in structural health\nmonitoring. By focusing on crack detection in structural datasets, it is\ndemonstrated that deep learning (DL) methods can effectively analyze seismic\nwave fields interacting with micro-scale cracks, which are beyond the\nresolution of conventional visual inspection. This work explores a novel\napplication of DL-based key point detection technique, where cracks are\nlocalized by predicting the coordinates of four key points that define a\nbounding region of the crack. The study not only opens new research directions\nfor non-visual applications but also effectively mitigates the impact of\nimbalanced data which poses a challenge for previous DL models, as it can be\nbiased toward predicting the majority class (non-crack regions). Popular DL\ntechniques, such as the Inception blocks, are used and investigated. The model\nshows an overall reduction in loss when applied to micro-scale crack detection\nand is reflected in the lower average deviation between the location of actual\nand predicted cracks, with an average Intersection over Union (IoU) being 0.511\nfor all micro cracks (greater than 0.00 micrometers) and 0.631 for larger micro\ncracks (greater than 4 micrometers).",
      "tldr_zh": "这篇论文利用深度学习（DL）方法，通过关键点本地化技术（如预测定义裂缝边界区域的四个关键点坐标）来检测微尺度裂缝，从而解决了结构健康监测中地震波场分析的挑战，并有效缓解了不平衡数据集导致的模型偏向问题。研究采用了Inception blocks等流行DL技术，显著降低了检测损失，并提高了裂缝位置预测的准确性。实验结果显示，平均Intersection over Union (IoU) 达到0.511（所有微裂缝）和0.631（大于4微米的较大微裂缝），为非视觉应用开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10389v1",
      "published_date": "2024-11-15 17:50:46 UTC",
      "updated_date": "2024-11-15 17:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:49:39.691662"
    },
    {
      "arxiv_id": "2411.10385v1",
      "title": "Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning",
      "title_zh": "低延迟任务导向通信",
      "authors": [
        "Yalin E. Sagduyu",
        "Tugba Erpek",
        "Aylin Yener",
        "Sennur Ulukus"
      ],
      "abstract": "In this paper, we address task-oriented (or goal-oriented) communications\nwhere an encoder at the transmitter learns compressed latent representations of\ndata, which are then transmitted over a wireless channel. At the receiver, a\ndecoder performs a machine learning task, specifically for classifying the\nreceived signals. The deep neural networks corresponding to the encoder-decoder\npair are jointly trained, taking both channel and data characteristics into\naccount. Our objective is to achieve high accuracy in completing the underlying\ntask while minimizing the number of channel uses determined by the encoder's\noutput size. To this end, we propose a multi-round, multi-task learning (MRMTL)\napproach for the dynamic update of channel uses in multi-round transmissions.\nThe transmitter incrementally sends an increasing number of encoded samples\nover the channel based on the feedback from the receiver, and the receiver\nutilizes the signals from a previous round to enhance the task performance,\nrather than only considering the latest transmission. This approach employs\nmulti-task learning to jointly optimize accuracy across varying number of\nchannel uses, treating each configuration as a distinct task. By evaluating the\nconfidence of the receiver in task decisions, MRMTL decides on whether to\nallocate additional channel uses in multiple rounds. We characterize both the\naccuracy and the delay (total number of channel uses) of MRMTL, demonstrating\nthat it achieves the accuracy close to that of conventional methods requiring\nlarge numbers of channel uses, but with reduced delay by incorporating signals\nfrom a prior round. We consider the CIFAR-10 dataset, convolutional neural\nnetwork architectures, and AWGN and Rayleigh channel models for performance\nevaluation. We show that MRMTL significantly improves the efficiency of\ntask-oriented communications, balancing accuracy and latency effectively.",
      "tldr_zh": "这篇论文探讨了任务导向通信（task-oriented communications），提出了一种多轮多任务学习（MRMTL）方法，通过联合训练编码器和解码器来优化数据传输和机器学习任务（如信号分类）的准确率，同时最小化通道使用次数。MRMTL 框架允许发射机基于接收器反馈逐步增加编码样本传输，并在多轮中利用先前信号增强任务性能，将不同通道配置视为独立任务进行联合优化。实验结果显示，该方法在 CIFAR-10 数据集和 AWGN/Rayleigh 通道模型下，实现了与传统方法相当的准确率，但显著降低了延迟，提高了通信效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "cs.NI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10385v1",
      "published_date": "2024-11-15 17:48:06 UTC",
      "updated_date": "2024-11-15 17:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:49:22.588460"
    },
    {
      "arxiv_id": "2411.10371v2",
      "title": "A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Qing Cheng",
        "Zefan Zeng",
        "Xingchen Hu",
        "Yuehang Si",
        "Zhong Liu"
      ],
      "abstract": "Event Causality Identification (ECI) has become a crucial task in Natural\nLanguage Processing (NLP), aimed at automatically extracting causalities from\ntextual data. In this survey, we systematically address the foundational\nprinciples, technical frameworks, and challenges of ECI, offering a\ncomprehensive taxonomy to categorize and clarify current research\nmethodologies, as well as a quantitative assessment of existing models. We\nfirst establish a conceptual framework for ECI, outlining key definitions,\nproblem formulations, and evaluation standards. Our taxonomy classifies ECI\nmethods according to the two primary tasks of sentence-level (SECI) and\ndocument-level (DECI) event causality identification. For SECI, we examine\nfeature pattern-based matching, deep semantic encoding, causal knowledge\npre-training and prompt-based fine-tuning, and external knowledge enhancement\nmethods. For DECI, we highlight approaches focused on event graph reasoning and\nprompt-based techniques to address the complexity of cross-sentence causal\ninference. Additionally, we analyze the strengths, limitations, and open\nchallenges of each approach. We further conduct an extensive quantitative\nevaluation of various ECI methods on two benchmark datasets. Finally, we\nexplore future research directions, highlighting promising pathways to overcome\ncurrent limitations and broaden ECI applications.",
      "tldr_zh": "这篇论文对Event Causality Identification (ECI)进行了全面调查，旨在从Natural Language Processing (NLP)角度探讨从文本中自动提取因果关系的核心原则、技术框架和挑战。论文提出一个分类法，将ECI方法分为句子级(SECI)和文档级(DECI)，并详细分析SECI的特征模式匹配、深度语义编码、因果知识预训练及提示-based微调，以及DECI的事件图推理和提示-based技术，同时评估各方法的优势、局限性和开放问题。作者在两个基准数据集上进行了定量评估，发现现有模型存在改进空间，并指出了未来研究方向，如克服跨句因果推理的复杂性和扩展ECI的应用场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10371v2",
      "published_date": "2024-11-15 17:19:42 UTC",
      "updated_date": "2024-11-25 16:55:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:49:33.911165"
    },
    {
      "arxiv_id": "2411.10369v1",
      "title": "Towards High-Fidelity 3D Portrait Generation with Rich Details by Cross-View Prior-Aware Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Wei",
        "Wencheng Han",
        "Xingping Dong",
        "Jianbing Shen"
      ],
      "abstract": "Recent diffusion-based Single-image 3D portrait generation methods typically\nemploy 2D diffusion models to provide multi-view knowledge, which is then\ndistilled into 3D representations. However, these methods usually struggle to\nproduce high-fidelity 3D models, frequently yielding excessively blurred\ntextures. We attribute this issue to the insufficient consideration of\ncross-view consistency during the diffusion process, resulting in significant\ndisparities between different views and ultimately leading to blurred 3D\nrepresentations. In this paper, we address this issue by comprehensively\nexploiting multi-view priors in both the conditioning and diffusion procedures\nto produce consistent, detail-rich portraits. From the conditioning standpoint,\nwe propose a Hybrid Priors Diffsion model, which explicitly and implicitly\nincorporates multi-view priors as conditions to enhance the status consistency\nof the generated multi-view portraits. From the diffusion perspective,\nconsidering the significant impact of the diffusion noise distribution on\ndetailed texture generation, we propose a Multi-View Noise Resamplig Strategy\nintegrated within the optimization process leveraging cross-view priors to\nenhance representation consistency. Extensive experiments demonstrate that our\nmethod can produce 3D portraits with accurate geometry and rich details from a\nsingle image. The project page is at\n\\url{https://haoran-wei.github.io/Portrait-Diffusion}.",
      "tldr_zh": "本文提出了一种基于Cross-View Prior-Aware Diffusion的方法，旨在解决现有diffusion-based单图像3D人像生成技术的模糊纹理问题，该问题源于扩散过程中跨视图一致性不足。通过Hybrid Priors Diffusion模型显式和隐式整合multi-view priors作为条件，提高生成多视图人像的状态一致性；同时，引入Multi-View Noise Resampling Strategy，在优化过程中利用跨视图先验增强表示一致性。实验结果显示，该方法能从单图像生成具有准确几何和丰富细节的高保真3D人像。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10369v1",
      "published_date": "2024-11-15 17:19:18 UTC",
      "updated_date": "2024-11-15 17:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:49:47.939996"
    },
    {
      "arxiv_id": "2411.10368v1",
      "title": "Mechanisms of Generative Image-to-Image Translation Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Guangzong Chen",
        "Mingui Sun",
        "Zhi-Hong Mao",
        "Kangni Liu",
        "Wenyan Jia"
      ],
      "abstract": "Generative Adversarial Networks (GANs) are a class of neural networks that\nhave been widely used in the field of image-to-image translation. In this\npaper, we propose a streamlined image-to-image translation network with a\nsimpler architecture compared to existing models. We investigate the\nrelationship between GANs and autoencoders and provide an explanation for the\nefficacy of employing only the GAN component for tasks involving image\ntranslation. We show that adversarial for GAN models yields results comparable\nto those of existing methods without additional complex loss penalties.\nSubsequently, we elucidate the rationale behind this phenomenon. We also\nincorporate experimental results to demonstrate the validity of our findings.",
      "tldr_zh": "本文提出了一种简化架构的图像到图像翻译网络，旨在减少复杂性，同时探讨 Generative Adversarial Networks (GANs) 与 autoencoders 的关系。作者解释了为什么仅使用 GAN 组件即可实现与现有方法相当的图像翻译效果，而无需额外的复杂损失函数。实验结果验证了这一现象，证明了该方法的有效性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10368v1",
      "published_date": "2024-11-15 17:17:46 UTC",
      "updated_date": "2024-11-15 17:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:49:57.910024"
    },
    {
      "arxiv_id": "2411.10367v1",
      "title": "Continual Adversarial Reinforcement Learning (CARL) of False Data Injection detection: forgetting and explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Pooja Aslami",
        "Kejun Chen",
        "Timothy M. Hansen",
        "Malik Hassanaly"
      ],
      "abstract": "False data injection attacks (FDIAs) on smart inverters are a growing concern\nlinked to increased renewable energy production. While data-based FDIA\ndetection methods are also actively developed, we show that they remain\nvulnerable to impactful and stealthy adversarial examples that can be crafted\nusing Reinforcement Learning (RL). We propose to include such adversarial\nexamples in data-based detection training procedure via a continual adversarial\nRL (CARL) approach. This way, one can pinpoint the deficiencies of data-based\ndetection, thereby offering explainability during their incremental\nimprovement. We show that a continual learning implementation is subject to\ncatastrophic forgetting, and additionally show that forgetting can be addressed\nby employing a joint training strategy on all generated FDIA scenarios.",
      "tldr_zh": "该论文探讨了针对智能逆变器的False Data Injection attacks (FDIAs)，这些攻击通过Reinforcement Learning (RL)生成的对抗样本可能绕过现有数据驱动的检测方法。作者提出Continual Adversarial Reinforcement Learning (CARL)方法，将对抗样本整合到检测训练中，以识别缺陷并提供explainability，从而实现检测的逐步优化。研究发现，CARL在持续学习过程中易受catastrophic forgetting影响，但通过joint training strategy在所有FDIA场景上进行联合训练，可以有效缓解这一问题。该方法为提升FDIA检测的鲁棒性和可解释性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10367v1",
      "published_date": "2024-11-15 17:17:06 UTC",
      "updated_date": "2024-11-15 17:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:50:11.577999"
    },
    {
      "arxiv_id": "2411.10364v2",
      "title": "Forming Auxiliary High-confident Instance-level Loss to Promote Learning from Label Proportions",
      "title_zh": "形成辅助高置信度实例级损失以促进基于标签比例的学习",
      "authors": [
        "Tianhao Ma",
        "Han Chen",
        "Juncheng Hu",
        "Yungang Zhu",
        "Ximing Li"
      ],
      "abstract": "Learning from label proportions (LLP), i.e., a challenging weakly-supervised\nlearning task, aims to train a classifier by using bags of instances and the\nproportions of classes within bags, rather than annotated labels for each\ninstance. Beyond the traditional bag-level loss, the mainstream methodology of\nLLP is to incorporate an auxiliary instance-level loss with pseudo-labels\nformed by predictions. Unfortunately, we empirically observed that the\npseudo-labels are are often inaccurate due to over-smoothing, especially for\nthe scenarios with large bag sizes, hurting the classifier induction. To\nalleviate this problem, we suggest a novel LLP method, namely Learning from\nLabel Proportions with Auxiliary High-confident Instance-level Loss\n(L^2P-AHIL). Specifically, we propose a dual entropy-based weight (DEW) method\nto adaptively measure the confidences of pseudo-labels. It simultaneously\nemphasizes accurate predictions at the bag level and avoids overly smoothed\npredictions. We then form high-confident instance-level loss with DEW, and\njointly optimize it with the bag-level loss in a self-training manner. The\nexperimental results on benchmark datasets show that L^2P-AHIL can surpass the\nexisting baseline methods, and the performance gain can be more significant as\nthe bag size increases. The implementation of our method is available at\nhttps://github.com/TianhaoMa5/LLP-AHIL.",
      "tldr_zh": "该论文针对从标签比例学习（Learning from Label Proportions, LLP）这一弱监督学习任务，提出了一种新方法L^2P-AHIL，以解决伪标签（pseudo-labels）因过度平滑（over-smoothing）而导致的不准确问题，尤其在大型 bags 场景下。方法引入双熵-based 权重（Dual Entropy-based Weight, DEW）来自适应评估伪标签的置信度，同时强调 bags 级别的准确预测并避免过度平滑。作者通过形成高置信实例级损失，并将其与 bags 级别损失在自训练方式中联合优化，实验结果显示L^2P-AHIL在基准数据集上超过了现有基线方法，且性能提升在 bags 尺寸增大时更为显著。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a conference paper at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.10364v2",
      "published_date": "2024-11-15 17:14:18 UTC",
      "updated_date": "2025-03-24 03:41:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:50:23.590812"
    },
    {
      "arxiv_id": "2411.10340v1",
      "title": "Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis",
      "title_zh": "基于领域适应的边缘计算用于跨",
      "authors": [
        "Yanzhi Wang",
        "Chu Wang",
        "Jinhong Wu",
        "Ziyang Yu",
        "Qi Zhou"
      ],
      "abstract": "Fault diagnosis technology supports the healthy operation of mechanical\nequipment. However, the variations conditions during the operation of\nmechanical equipment lead to significant disparities in data distribution,\nposing challenges to fault diagnosis. Furthermore, when deploying applications,\ntraditional methods often encounter issues such as latency and data security.\nTherefore, conducting fault diagnosis and deploying application methods under\ncross-operating conditions holds significant value. This paper proposes a\ndomain adaptation-based lightweight fault diagnosis framework for edge\ncomputing scenarios. Incorporating the local maximum mean discrepancy into\nknowledge transfer aligns the feature distributions of different domains in a\nhigh-dimensional feature space, to discover a common feature space across\ndomains. The acquired fault diagnosis expertise from the cloud-model is\ntransferred to the lightweight edge-model using adaptation knowledge transfer\nmethods. While ensuring real-time diagnostic capabilities, accurate fault\ndiagnosis is achieved across working conditions. We conducted validation\nexperiments on the NVIDIA Jetson Xavier NX kit. In terms of diagnostic\nperformance, the proposed method significantly improved diagnostic accuracy,\nwith average increases of 34.44% and 17.33% compared to the comparison method,\nrespectively. Regarding lightweight effectiveness, proposed method achieved an\naverage inference speed increase of 80.47%. Additionally, compared to the\ncloud-model, the parameter count of the edge-model decreased by 96.37%, while\nthe Flops decreased by 83.08%.",
      "tldr_zh": "本论文针对机械设备故障诊断中数据分布差异、延迟和数据安全挑战，提出了一种基于Domain Adaptation的轻量级框架，适用于边缘计算场景。该框架通过将局部最大均值差异（local maximum mean discrepancy）融入知识转移中，对齐不同域的高维特征分布，并从云模型向边缘模型传输适应知识，从而实现跨工作条件下的实时准确诊断。实验在NVIDIA Jetson Xavier NX上验证，该方法相比基准方法平均提高了34.44%和17.33%的诊断准确率，同时推理速度提升80.47%，边缘模型参数减少96.37%、Flops减少83.08%，显著提升了诊断效率和轻量级性能。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "28 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10340v1",
      "published_date": "2024-11-15 16:40:43 UTC",
      "updated_date": "2024-11-15 16:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:50:34.774661"
    },
    {
      "arxiv_id": "2411.10329v2",
      "title": "Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Huming Qiu",
        "Guanxu Chen",
        "Mi Zhang",
        "Xiaohan Zhang",
        "Xiaoyu You",
        "Min Yang"
      ],
      "abstract": "In recent years, text-to-image (T2I) generation models have made significant\nprogress in generating high-quality images that align with text descriptions.\nHowever, these models also face the risk of unsafe generation, potentially\nproducing harmful content that violates usage policies, such as explicit\nmaterial. Existing safe generation methods typically focus on suppressing\ninappropriate content by erasing undesired concepts from visual\nrepresentations, while neglecting to sanitize the textual representation.\nAlthough these methods help mitigate the risk of misuse to some extent, their\nrobustness remains insufficient when dealing with adversarial attacks.\n  Given that semantic consistency between input text and output image is a core\nrequirement of T2I models, we identify that textual representations are likely\nthe primary source of unsafe generation. To this end, we propose Embedding\nSanitizer (ES), which enhances the safety of T2I models by sanitizing\ninappropriate concepts in prompt embeddings. To our knowledge, ES is the first\ninterpretable safe generation framework that assigns a score to each token in\nthe prompt to indicate its potential harmfulness. In addition, ES adopts a\nplug-and-play modular design, offering compatibility for seamless integration\nwith various T2I models and other safeguards. Evaluations on five prompt\nbenchmarks show that ES outperforms eleven existing safeguard baselines,\nachieving state-of-the-art robustness while maintaining high-quality image\ngeneration.",
      "tldr_zh": "近年来，Text-to-Image (T2I) 生成模型虽能产生高质量图像，但存在生成有害内容的风险，如显式材料，现有方法主要通过删除视觉表示中的不适当概念，却忽略了文本表示的净化，导致对抗攻击鲁棒性不足。作者提出 Embedding Sanitizer (ES)，通过净化提示嵌入中的不适当概念，为每个提示标记分配危害分数，这是首个可解释的安全生成框架，并采用即插即用设计以兼容各种 T2I 模型和其他安全措施。在五个提示基准上的评估显示，ES 优于11个现有基准，实现了最先进的鲁棒性，同时保持高质量图像生成。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10329v2",
      "published_date": "2024-11-15 16:29:02 UTC",
      "updated_date": "2025-04-15 12:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:50:47.352998"
    },
    {
      "arxiv_id": "2411.10323v1",
      "title": "The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Hu",
        "Mingyu Ouyang",
        "Difei Gao",
        "Mike Zheng Shou"
      ],
      "abstract": "The recently released model, Claude 3.5 Computer Use, stands out as the first\nfrontier AI model to offer computer use in public beta as a graphical user\ninterface (GUI) agent. As an early beta, its capability in the real-world\ncomplex environment remains unknown. In this case study to explore Claude 3.5\nComputer Use, we curate and organize a collection of carefully designed tasks\nspanning a variety of domains and software. Observations from these cases\ndemonstrate Claude 3.5 Computer Use's unprecedented ability in end-to-end\nlanguage to desktop actions. Along with this study, we provide an\nout-of-the-box agent framework for deploying API-based GUI automation models\nwith easy implementation. Our case studies aim to showcase a groundwork of\ncapabilities and limitations of Claude 3.5 Computer Use with detailed analyses\nand bring to the fore questions about planning, action, and critic, which must\nbe considered for future improvement. We hope this preliminary exploration will\ninspire future research into the GUI agent community. All the test cases in the\npaper can be tried through the project:\nhttps://github.com/showlab/computer_use_ootb.",
      "tldr_zh": "该论文对Claude 3.5 Computer Use进行了初步案例研究，作为首个公开beta版本的GUI agent，评估其在真实复杂环境中的能力。研究者设计了涵盖多种领域和软件的精心任务，观察到该模型在端到端语言到桌面动作方面表现出前所未有的性能，并提供了一个基于API的GUI自动化代理框架以便快速实施。结果分析了Claude 3.5 Computer Use的优点和局限性，如规划、行动和批评方面的挑战，并呼吁未来研究以此为基础，推动GUI agent社区的发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "40 pages, 21 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.10323v1",
      "published_date": "2024-11-15 16:23:52 UTC",
      "updated_date": "2024-11-15 16:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:51:01.172285"
    },
    {
      "arxiv_id": "2411.10308v1",
      "title": "A Realistic Collimated X-Ray Image Simulation Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin El-Zein",
        "Dominik Eckert",
        "Thomas Weber",
        "Maximilian Rohleder",
        "Ludwig Ritschl",
        "Steffen Kappler",
        "Andreas Maier"
      ],
      "abstract": "Collimator detection remains a challenging task in X-ray systems with\nunreliable or non-available information about the detectors position relative\nto the source. This paper presents a physically motivated image processing\npipeline for simulating the characteristics of collimator shadows in X-ray\nimages. By generating randomized labels for collimator shapes and locations,\nincorporating scattered radiation simulation, and including Poisson noise, the\npipeline enables the expansion of limited datasets for training deep neural\nnetworks. We validate the proposed pipeline by a qualitative and quantitative\ncomparison against real collimator shadows. Furthermore, it is demonstrated\nthat utilizing simulated data within our deep learning framework not only\nserves as a suitable substitute for actual collimators but also enhances the\ngeneralization performance when applied to real-world data.",
      "tldr_zh": "本论文提出一个基于物理原理的图像处理管道，用于模拟 X-ray 图像中的 collimator shadows，以解决检测器位置信息不可靠时的挑战。该管道通过生成随机的 collimator shapes 和 locations 标签、模拟散射辐射以及添加 Poisson noise，来扩展用于训练 deep neural networks 的数据集。实验结果显示，该模拟数据不仅能有效替代真实 collimator 数据，还能提升模型在真实世界数据的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10308v1",
      "published_date": "2024-11-15 16:04:01 UTC",
      "updated_date": "2024-11-15 16:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:51:10.504249"
    },
    {
      "arxiv_id": "2411.10293v3",
      "title": "RETR: Multi-View Radar Detection Transformer for Indoor Perception",
      "title_zh": "RETR：多视图雷达检测 Transformer 用于室内感知",
      "authors": [
        "Ryoma Yataka",
        "Adriano Cardace",
        "Pu Perry Wang",
        "Petros Boufounos",
        "Ryuhei Takahashi"
      ],
      "abstract": "Indoor radar perception has seen rising interest due to affordable costs\ndriven by emerging automotive imaging radar developments and the benefits of\nreduced privacy concerns and reliability under hazardous conditions (e.g., fire\nand smoke). However, existing radar perception pipelines fail to account for\ndistinctive characteristics of the multi-view radar setting. In this paper, we\npropose Radar dEtection TRansformer (RETR), an extension of the popular DETR\narchitecture, tailored for multi-view radar perception. RETR inherits the\nadvantages of DETR, eliminating the need for hand-crafted components for object\ndetection and segmentation in the image plane. More importantly, RETR\nincorporates carefully designed modifications such as 1) depth-prioritized\nfeature similarity via a tunable positional encoding (TPE); 2) a tri-plane loss\nfrom both radar and camera coordinates; and 3) a learnable radar-to-camera\ntransformation via reparameterization, to account for the unique multi-view\nradar setting. Evaluated on two indoor radar perception datasets, our approach\noutperforms existing state-of-the-art methods by a margin of 15.38+ AP for\nobject detection and 11.91+ IoU for instance segmentation, respectively. Our\nimplementation is available at\nhttps://github.com/merlresearch/radar-detection-transformer.",
      "tldr_zh": "本研究针对室内雷达感知的独特挑战（如多视图设置），提出RETR，一种基于DETR架构的Transformer模型，用于改进物体检测和实例分割。RETR引入关键创新，包括可调位置编码(TPE)实现深度优先特征相似性、三平面损失整合雷达和相机坐标、以及可学习的雷达到相机转换，以适应多视图雷达特性。实验结果显示，在两个室内雷达数据集上，RETR分别比现有最先进方法提升15.38+ AP在物体检测和11.91+ IoU在实例分割上，展示了其在隐私友好和鲁棒性场景中的潜力。开源实现可访问https://github.com/merlresearch/radar-detection-transformer。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "math.DG"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, Accepted to NeurIPS 2024, Github Link:\n  https://github.com/merlresearch/radar-detection-transformer",
      "pdf_url": "http://arxiv.org/pdf/2411.10293v3",
      "published_date": "2024-11-15 15:51:25 UTC",
      "updated_date": "2025-01-17 19:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:51:23.016840"
    },
    {
      "arxiv_id": "2411.10290v1",
      "title": "The ParClusterers Benchmark Suite (PCBS): A Fine-Grained Analysis of Scalable Graph Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Shangdi Yu",
        "Jessica Shi",
        "Jamison Meindl",
        "David Eisenstat",
        "Xiaoen Ju",
        "Sasan Tavakkol",
        "Laxman Dhulipala",
        "Jakub Łącki",
        "Vahab Mirrokni",
        "Julian Shun"
      ],
      "abstract": "We introduce the ParClusterers Benchmark Suite (PCBS) -- a collection of\nhighly scalable parallel graph clustering algorithms and benchmarking tools\nthat streamline comparing different graph clustering algorithms and\nimplementations.\n  The benchmark includes clustering algorithms that target a wide range of\nmodern clustering use cases, including community detection, classification, and\ndense subgraph mining.\n  The benchmark toolkit makes it easy to run and evaluate multiple instances of\ndifferent clustering algorithms, which can be useful for fine-tuning the\nperformance of clustering on a given task, and for comparing different\nclustering algorithms based on different metrics of interest, including\nclustering quality and running time.\n  Using PCBS, we evaluate a broad collection of real-world graph clustering\ndatasets. Somewhat surprisingly, we find that the best quality results are\nobtained by algorithms that not included in many popular graph clustering\ntoolkits. The PCBS provides a standardized way to evaluate and judge the\nquality-performance tradeoffs of the active research area of scalable graph\nclustering algorithms. We believe it will help enable fair, accurate, and\nnuanced evaluation of graph clustering algorithms in the future.",
      "tldr_zh": "本研究引入了ParClusterers Benchmark Suite (PCBS)，一个高度可扩展的并行图聚类算法集合和基准测试工具，用于简化不同graph clustering算法的比较和评估。PCBS涵盖了多种现代聚类用例，包括community detection、classification和dense subgraph mining，并提供便捷的工具来运行多实例算法，评估指标如聚类质量和运行时间。通过对真实世界图聚类数据集的评估，研究发现一些未包含在流行工具包中的算法取得了最佳质量结果。该套件为可扩展图聚类算法的质量-性能权衡提供标准化框架，促进未来研究的公平和细致比较。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.DC",
      "comment": "This is a preliminary version of a paper that will appear at VLDB'25",
      "pdf_url": "http://arxiv.org/pdf/2411.10290v1",
      "published_date": "2024-11-15 15:47:32 UTC",
      "updated_date": "2024-11-15 15:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:51:35.936247"
    },
    {
      "arxiv_id": "2411.10285v2",
      "title": "Systolic Arrays and Structured Pruning Co-design for Efficient Transformers in Edge Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Palacios",
        "Rafael Medina",
        "Jean-Luc Rouas",
        "Giovanni Ansaloni",
        "David Atienza"
      ],
      "abstract": "Efficient deployment of resource-intensive transformers on edge devices\nnecessitates cross-stack optimization. We thus study the interrelation between\nstructured pruning and systolic acceleration, matching the size of pruned\nblocks with the systolic array dimensions. In this setting, computations of\npruned weight blocks can be skipped, reducing run-time and energy consumption,\nbut potentially impacting quality of service (QoS). To evaluate the trade-offs\nbetween systolic array size and sparsity opportunities, we present a novel\nco-design framework that integrates algorithmic optimization, system\nsimulation, and hardware design. Targeting speech recognition and machine\ntranslation using transformers as case study, we analyze how configuration\nchoices across the stack affect performance metrics. Results demonstrate that\nstructured pruning on systems featuring systolic array acceleration can\neffectively increase performance, while maintaining high QoS levels. Up to 44%\nsystem-wide speedups due to structured pruning and quantization were measured,\nwith only 1.4% word error rate degradation on the standard LibriSpeech dataset.",
      "tldr_zh": "这篇论文探讨了在边缘系统中高效部署资源密集型 Transformers 的方法，通过 Systolic Arrays 和 Structured Pruning 的联合设计来优化性能。研究者提出一个新型框架，整合算法优化、系统模拟和硬件设计，将剪枝块大小匹配脉动阵列维度，从而跳过不必要的计算并降低能耗，同时评估对服务质量（QoS）的潜在影响。以语音识别和机器翻译为案例研究，结果显示这种联合方法实现了高达44%的系统级加速，仅在LibriSpeech数据集上导致1.4%的单词错误率下降。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "68T50",
        "C.3; B.5.1; I.2.7"
      ],
      "primary_category": "cs.AR",
      "comment": "8 pages, GLSVLSI'25",
      "pdf_url": "http://arxiv.org/pdf/2411.10285v2",
      "published_date": "2024-11-15 15:40:49 UTC",
      "updated_date": "2025-05-12 12:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:51:48.445598"
    },
    {
      "arxiv_id": "2411.10279v1",
      "title": "Lateral Movement Detection via Time-aware Subgraph Classification on Authentication Logs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Zhou",
        "Jiacheng Yao",
        "Xuanze Chen",
        "Shanqing Yu",
        "Qi Xuan",
        "Xiaoniu Yang"
      ],
      "abstract": "Lateral movement is a crucial component of advanced persistent threat (APT)\nattacks in networks. Attackers exploit security vulnerabilities in internal\nnetworks or IoT devices, expanding their control after initial infiltration to\nsteal sensitive data or carry out other malicious activities, posing a serious\nthreat to system security. Existing research suggests that attackers generally\nemploy seemingly unrelated operations to mask their malicious intentions,\nthereby evading existing lateral movement detection methods and hiding their\nintrusion traces. In this regard, we analyze host authentication log data from\na graph perspective and propose a multi-scale lateral movement detection\nframework called LMDetect. The main workflow of this framework proceeds as\nfollows: 1) Construct a heterogeneous multigraph from host authentication log\ndata to strengthen the correlations among internal system entities; 2) Design a\ntime-aware subgraph generator to extract subgraphs centered on authentication\nevents from the heterogeneous authentication multigraph; 3) Design a\nmulti-scale attention encoder that leverages both local and global attention to\ncapture hidden anomalous behavior patterns in the authentication subgraphs,\nthereby achieving lateral movement detection. Extensive experiments on two\nreal-world authentication log datasets demonstrate the effectiveness and\nsuperiority of our framework in detecting lateral movement behaviors.",
      "tldr_zh": "该论文针对高级持续性威胁(APT)攻击中的横向移动(lateral movement)问题，提出了一种多尺度检测框架LMDetect，通过分析主机认证日志来识别隐藏的恶意行为。框架的核心步骤包括：从认证日志构建异构多图(heterogeneous multigraph)以强化实体间关联、设计时间感知子图生成器(time-aware subgraph generator)提取以认证事件为中心的子图，以及使用多尺度注意力编码器(multi-scale attention encoder)结合局部和全局注意力捕获异常模式。实验在两个真实世界认证日志数据集上验证了LMDetect的有效性和优越性，显著提升了横向移动行为的检测准确率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10279v1",
      "published_date": "2024-11-15 15:35:56 UTC",
      "updated_date": "2024-11-15 15:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:52:00.400587"
    },
    {
      "arxiv_id": "2411.10272v2",
      "title": "P$^2$ Law: Scaling Law for Post-Training After Model Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodong Chen",
        "Yuxuan Hu",
        "Xiaokang Zhang",
        "Yanling Wang",
        "Cuiping Li",
        "Hong Chen",
        "Jing Zhang"
      ],
      "abstract": "Pruning has become a widely adopted technique for reducing the hardware\nrequirements of large language models (LLMs). To recover model performance\nafter pruning, post-training is commonly employed to mitigate the resulting\nperformance degradation. While post-training benefits from larger datasets,\nonce the dataset size is already substantial, increasing the training data\nprovides only limited performance gains. To balance post-training cost and\nmodel performance, it is necessary to explore the optimal amount of\npost-training data.Through extensive experiments on the Llama-3 and Qwen-2.5\nseries models, pruned using various common pruning methods, we uncover the\nscaling \\textbf{Law} for \\textbf{P}ost-training after model \\textbf{P}runing,\nreferred to as the P$^2$ Law.This law identifies four key factors for\npredicting the pruned model's post-training loss: the model size before\npruning, the number of post-training tokens, the pruning rate, and the model's\nloss before pruning. Moreover, P$^2$ Law can generalize to larger dataset\nsizes, larger model sizes, and higher pruning rates, offering valuable insights\nfor the post-training of pruned LLMs.",
      "tldr_zh": "本研究探讨了在大型语言模型（LLMs）剪枝后，通过后训练恢复性能的优化问题。作者通过对 Llama-3 和 Qwen-2.5 系列模型的广泛实验，提出了 P² Law，这是一个预测剪枝模型后训练损失的缩放定律，涉及四个关键因素：剪枝前模型大小、后训练标记数、剪枝率和剪枝前模型损失。该定律有助于平衡后训练成本和性能，并在更大的数据集、更大的模型规模以及更高的剪枝率下具有良好的泛化性，为剪枝 LLMs 的后训练提供宝贵指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10272v2",
      "published_date": "2024-11-15 15:28:42 UTC",
      "updated_date": "2024-12-16 12:00:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:52:11.919419"
    },
    {
      "arxiv_id": "2411.10257v2",
      "title": "The Unreasonable Effectiveness of Guidance for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Kaiser",
        "Nikolas Adaloglou",
        "Markus Kollmann"
      ],
      "abstract": "Guidance is an error-correcting technique used to improve the perceptual\nquality of images generated by diffusion models. Typically, the correction is\nachieved by linear extrapolation, using an auxiliary diffusion model that has\nlower performance than the primary model. Using a 2D toy example, we show that\nit is highly beneficial when the auxiliary model exhibits similar errors as the\nprimary one but stronger. We verify this finding in higher dimensions, where we\nshow that competitive generative performance to state-of-the-art guidance\nmethods can be achieved when the auxiliary model differs from the primary one\nonly by having stronger weight regularization. As an independent contribution,\nwe investigate whether upweighting long-range spatial dependencies improves\nvisual fidelity. The result is a novel guidance method, which we call sliding\nwindow guidance (SWG), that guides the primary model with itself by\nconstraining its receptive field. Intriguingly, SWG aligns better with human\npreferences than state-of-the-art guidance methods while requiring neither\ntraining, architectural modifications, nor class conditioning. The code will be\nreleased.",
      "tldr_zh": "该研究探讨了Guidance在扩散模型中的非凡有效性，用于提升生成图像的感知质量。作者通过2D玩具示例和更高维度实验发现，当辅助扩散模型与主模型具有类似但更强的错误（如更强的权重正则化），指导效果最佳，能与最先进方法媲美。作为新贡献，他们提出Sliding Window Guidance (SWG)方法，该方法通过约束主模型的感受野来指导自身，从而增强长距离空间依赖性。SWG无需额外训练、架构修改或类别条件，即可比现有方法更符合人类偏好，为扩散模型优化提供了实用途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. 30 pages, 19 figures in total, including appendix",
      "pdf_url": "http://arxiv.org/pdf/2411.10257v2",
      "published_date": "2024-11-15 15:04:04 UTC",
      "updated_date": "2024-12-20 14:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:52:23.624974"
    },
    {
      "arxiv_id": "2411.10255v2",
      "title": "Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Yaseen Jabarulla",
        "Theodor Uden",
        "Thomas Jack",
        "Philipp Beerbaum",
        "Steffen Oeltze-Jafra"
      ],
      "abstract": "Pediatric heart diseases present a broad spectrum of congenital and acquired\ndiseases. More complex congenital malformations require a differentiated and\nmultimodal decision-making process, usually including echocardiography as a\ncentral imaging method. Artificial intelligence (AI) offers considerable\npromise for clinicians by facilitating automated interpretation of pediatric\nechocardiography data. However, adapting AI technologies for pediatric\nechocardiography analysis has challenges such as limited public data\navailability, data privacy, and AI model transparency. Recently, researchers\nhave focused on disruptive technologies, such as federated learning (FL) and\nexplainable AI (XAI), to improve automatic diagnostic and decision support\nworkflows. This study offers a comprehensive overview of the limitations and\nopportunities of AI in pediatric echocardiography, emphasizing the synergistic\nworkflow and role of XAI and FL, identifying research gaps, and exploring\npotential future developments. Additionally, three relevant clinical use cases\ndemonstrate the functionality of XAI and FL with a focus on (i) view\nrecognition, (ii) disease classification, (iii) segmentation of cardiac\nstructures, and (iv) quantitative assessment of cardiac function.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在儿科心脏超声中的应用，重点分析了挑战（如数据可用性有限、隐私问题和模型透明度不足）以及机遇，特别是Explainable AI (XAI)和Federated Learning (FL)的协同作用，以提升自动诊断和决策支持工作流。论文提供了全面概述，识别了研究空白并展望未来发展，同时通过三个临床用例（包括视图识别、疾病分类、心脏结构分割和心脏功能定量评估）展示了XAI和FL的实际功能。这些创新有望改善儿科心脏疾病的诊断准确性和可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted for peer review to an Elsevier journal. This version\n  includes revisions to align with the journals guidelines and template. Any\n  footnotes previously present in [V1] referring to Frontiers have been removed\n  for clarity",
      "pdf_url": "http://arxiv.org/pdf/2411.10255v2",
      "published_date": "2024-11-15 15:03:34 UTC",
      "updated_date": "2025-03-27 20:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:52:36.624279"
    },
    {
      "arxiv_id": "2411.10234v1",
      "title": "Generative AI in Multimodal User Interfaces: Trends, Challenges, and Cross-Platform Adaptability",
      "title_zh": "生成式 AI 在多模态用户界面中的应用：趋势、挑战和跨平台适应性",
      "authors": [
        "J. Bieniek",
        "M. Rahouti",
        "D. C. Verma"
      ],
      "abstract": "As the boundaries of human computer interaction expand, Generative AI emerges\nas a key driver in reshaping user interfaces, introducing new possibilities for\npersonalized, multimodal and cross-platform interactions. This integration\nreflects a growing demand for more adaptive and intuitive user interfaces that\ncan accommodate diverse input types such as text, voice and video, and deliver\nseamless experiences across devices. This paper explores the integration of\ngenerative AI in modern user interfaces, examining historical developments and\nfocusing on multimodal interaction, cross-platform adaptability and dynamic\npersonalization. A central theme is the interface dilemma, which addresses the\nchallenge of designing effective interactions for multimodal large language\nmodels, assessing the trade-offs between graphical, voice-based and immersive\ninterfaces. The paper further evaluates lightweight frameworks tailored for\nmobile platforms, spotlighting the role of mobile hardware in enabling scalable\nmultimodal AI. Technical and ethical challenges, including context retention,\nprivacy concerns and balancing cloud and on-device processing are thoroughly\nexamined. Finally, the paper outlines future directions such as emotionally\nadaptive interfaces, predictive AI driven user interfaces and real-time\ncollaborative systems, underscoring generative AI's potential to redefine\nadaptive user-centric interfaces across platforms.",
      "tldr_zh": "本论文探讨了Generative AI在Multimodal User Interfaces中的应用，分析其推动个性化、多模态（如文本、语音和视频）交互以及跨平台适应性的趋势和历史发展。论文重点评估了界面困境，包括设计多模态Large Language Models交互时的权衡（如图形、语音和沉浸式界面）、轻量级移动框架的技术挑战（如上下文保留、隐私问题和云端与设备处理平衡），以及相关的伦理问题。最终，论文展望了未来方向，如情感适应界面、预测性AI驱动界面和实时协作系统，强调Generative AI在打造用户-centric跨平台界面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10234v1",
      "published_date": "2024-11-15 14:49:58 UTC",
      "updated_date": "2024-11-15 14:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:52:48.394464"
    },
    {
      "arxiv_id": "2411.10232v2",
      "title": "ColorEdit: Training-free Image-Guided Color editing with diffusion model",
      "title_zh": "翻译失败",
      "authors": [
        "Xingxi Yin",
        "Zhi Li",
        "Jingfeng Zhang",
        "Chenglin Li",
        "Yin Zhang"
      ],
      "abstract": "Text-to-image (T2I) diffusion models, with their impressive generative\ncapabilities, have been adopted for image editing tasks, demonstrating\nremarkable efficacy. However, due to attention leakage and collision between\nthe cross-attention map of the object and the new color attribute from the text\nprompt, text-guided image editing methods may fail to change the color of an\nobject, resulting in a misalignment between the resulting image and the text\nprompt. In this paper, we conduct an in-depth analysis on the process of\ntext-guided image synthesizing and what semantic information different\ncross-attention blocks have learned. We observe that the visual representation\nof an object is determined in the up-block of the diffusion model in the early\nstage of the denoising process, and color adjustment can be achieved through\nvalue matrices alignment in the cross-attention layer. Based on our findings,\nwe propose a straightforward, yet stable, and effective image-guided method to\nmodify the color of an object without requiring any additional fine-tuning or\ntraining. Lastly, we present a benchmark dataset called COLORBENCH, the first\nbenchmark to evaluate the performance of color change methods. Extensive\nexperiments validate the effectiveness of our method in object-level color\nediting and surpass the performance of popular text-guided image editing\napproaches in both synthesized and real images.",
      "tldr_zh": "该论文分析了文本到图像（T2I）扩散模型在图像编辑中的问题，特别是文本引导方法由于注意力泄漏和跨注意力（cross-attention）冲突，导致对象颜色改变失败。作者发现，对象的视觉表示在扩散模型的 up-block 中于去噪过程早期确定，并可以通过跨注意力层的 value matrices alignment 实现颜色调整。基于此，他们提出 ColorEdit，一种无需额外训练的图像引导颜色编辑方法，并引入了首个基准数据集 COLORBENCH 用于评估性能。实验结果显示，该方法在对象级颜色编辑中优于现有文本引导方法，在合成和真实图像上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10232v2",
      "published_date": "2024-11-15 14:45:58 UTC",
      "updated_date": "2025-04-30 04:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:53:00.144226"
    },
    {
      "arxiv_id": "2411.10231v1",
      "title": "A Low-Resolution Image is Worth 1x1 Words: Enabling Fine Image Super-Resolution with Transformers and TaylorShift",
      "title_zh": "翻译失败",
      "authors": [
        "Sanath Budakegowdanadoddi Nagaraju",
        "Brian Bernhard Moser",
        "Tobias Christian Nauen",
        "Stanislav Frolov",
        "Federico Raue",
        "Andreas Dengel"
      ],
      "abstract": "Transformer-based Super-Resolution (SR) models have recently advanced image\nreconstruction quality, yet challenges remain due to computational complexity\nand an over-reliance on large patch sizes, which constrain fine-grained detail\nenhancement. In this work, we propose TaylorIR to address these limitations by\nutilizing a patch size of 1x1, enabling pixel-level processing in any\ntransformer-based SR model. To address the significant computational demands\nunder the traditional self-attention mechanism, we employ the TaylorShift\nattention mechanism, a memory-efficient alternative based on Taylor series\nexpansion, achieving full token-to-token interactions with linear complexity.\nExperimental results demonstrate that our approach achieves new\nstate-of-the-art SR performance while reducing memory consumption by up to 60%\ncompared to traditional self-attention-based transformers.",
      "tldr_zh": "该研究针对Transformer-based Super-Resolution (SR) 模型的计算复杂性和对大patch尺寸的依赖问题，提出TaylorIR方法，使用1x1 patch尺寸实现像素级处理，从而提升细粒度图像细节增强。\nTaylorIR采用TaylorShift注意力机制，这是一种基于Taylor系列展开的内存高效替代方案，实现线性复杂度的全token-to-token交互。\n实验结果表明，该方法在SR性能上达到新状态-of-the-art，同时将内存消耗降低多达60%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10231v1",
      "published_date": "2024-11-15 14:43:58 UTC",
      "updated_date": "2024-11-15 14:43:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:53:11.632637"
    },
    {
      "arxiv_id": "2411.10224v2",
      "title": "EVOKE: Elevating Chest X-ray Report Generation via Multi-View Contrastive Learning and Patient-Specific Knowledge",
      "title_zh": "EVOKE：通过多视图对比学习和患者特定知识提升胸部X光报告生成",
      "authors": [
        "Qiguang Miao",
        "Kang Liu",
        "Zhuoqi Ma",
        "Yunan Li",
        "Xiaolu Kang",
        "Ruixuan Liu",
        "Tianyi Liu",
        "Kun Xie",
        "Zhicheng Jiao"
      ],
      "abstract": "Radiology reports are crucial for planning treatment strategies and\nfacilitating effective doctor-patient communication. However, the manual\ncreation of these reports places a significant burden on radiologists. While\nautomatic radiology report generation presents a promising solution, existing\nmethods often rely on single-view radiographs, which constrain diagnostic\naccuracy. To address this challenge, we propose \\textbf{EVOKE}, a novel chest\nX-ray report generation framework that incorporates multi-view contrastive\nlearning and patient-specific knowledge. Specifically, we introduce a\nmulti-view contrastive learning method that enhances visual representation by\naligning multi-view radiographs with their corresponding report. After that, we\npresent a knowledge-guided report generation module that integrates available\npatient-specific indications (e.g., symptom descriptions) to trigger the\nproduction of accurate and coherent radiology reports. To support research in\nmulti-view report generation, we construct Multi-view CXR and Two-view CXR\ndatasets using publicly available sources. Our proposed EVOKE surpasses recent\nstate-of-the-art methods across multiple datasets, achieving a 2.9\\%\nF\\textsubscript{1} RadGraph improvement on MIMIC-CXR, a 7.3\\% BLEU-1\nimprovement on MIMIC-ABN, a 3.1\\% BLEU-4 improvement on Multi-view CXR, and an\n8.2\\% F\\textsubscript{1,mic-14} CheXbert improvement on Two-view CXR.",
      "tldr_zh": "该研究提出EVOKE框架，以提升胸部X光报告生成，通过多视图对比学习(multi-view contrastive learning)和患者特定知识(patient-specific knowledge)来解决现有方法的局限性。具体来说，该框架首先使用多视图对比学习方法对齐多视图X光片及其报告以增强视觉表示，然后通过知识引导报告生成模块整合患者症状等信息，生成更准确和连贯的放射学报告。为支持研究，该团队构建了Multi-view CXR和Two-view CXR数据集。实验结果显示，EVOKE在多个数据集上超越现有方法，包括MIMIC-CXR上的F1 RadGraph提高2.9%、MIMIC-ABN上的BLEU-1提高7.3%、Multi-view CXR上的BLEU-4提高3.1%以及Two-view CXR上的F1,mic-14 CheXbert提高8.2%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The code is available at https://github.com/mk-runner/EVOKE",
      "pdf_url": "http://arxiv.org/pdf/2411.10224v2",
      "published_date": "2024-11-15 14:38:13 UTC",
      "updated_date": "2025-03-12 09:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:53:24.525682"
    },
    {
      "arxiv_id": "2411.10213v1",
      "title": "An Empirical Study on LLM-based Agents for Automated Bug Fixing",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangxin Meng",
        "Zexiong Ma",
        "Pengfei Gao",
        "Chao Peng"
      ],
      "abstract": "Large language models (LLMs) and LLM-based Agents have been applied to fix\nbugs automatically, demonstrating the capability in addressing software defects\nby engaging in development environment interaction, iterative validation and\ncode modification. However, systematic analysis of these agent and non-agent\nsystems remain limited, particularly regarding performance variations among\ntop-performing ones. In this paper, we examine seven proprietary and\nopen-source systems on the SWE-bench Lite benchmark for automated bug fixing.\nWe first assess each system's overall performance, noting instances solvable by\nall or none of these sytems, and explore why some instances are uniquely solved\nby specific system types. We also compare fault localization accuracy at file\nand line levels and evaluate bug reproduction capabilities, identifying\ninstances solvable only through dynamic reproduction. Through analysis, we\nconcluded that further optimization is needed in both the LLM itself and the\ndesign of Agentic flow to improve the effectiveness of the Agent in bug fixing.",
      "tldr_zh": "这篇论文通过实证研究评估了基于大型语言模型(LLM)的代理在自动bug修复中的性能，测试了七个专有和开源系统在SWE-bench Lite基准上的表现。研究比较了这些系统的整体修复效果、故障定位准确性（包括文件和行级别）以及bug再现能力，发现某些bug仅由特定系统解决，且动态再现是关键因素。最终结论指出，需要进一步优化LLM本身和代理流程设计，以提升bug修复的整体有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10213v1",
      "published_date": "2024-11-15 14:19:15 UTC",
      "updated_date": "2024-11-15 14:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:53:35.637796"
    },
    {
      "arxiv_id": "2411.10504v1",
      "title": "USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction and Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Kang Chen",
        "Jiyuan Zhang",
        "Zecheng Hao",
        "Yajing Zheng",
        "Tiejun Huang",
        "Zhaofei Yu"
      ],
      "abstract": "Spike cameras, as an innovative neuromorphic camera that captures scenes with\nthe 0-1 bit stream at 40 kHz, are increasingly employed for the 3D\nreconstruction task via Neural Radiance Fields (NeRF) or 3D Gaussian Splatting\n(3DGS). Previous spike-based 3D reconstruction approaches often employ a\ncasecased pipeline: starting with high-quality image reconstruction from spike\nstreams based on established spike-to-image reconstruction algorithms, then\nprogressing to camera pose estimation and 3D reconstruction. However, this\ncascaded approach suffers from substantial cumulative errors, where quality\nlimitations of initial image reconstructions negatively impact pose estimation,\nultimately degrading the fidelity of the 3D reconstruction. To address these\nissues, we propose a synergistic optimization framework, \\textbf{USP-Gaussian},\nthat unifies spike-based image reconstruction, pose correction, and Gaussian\nsplatting into an end-to-end framework. Leveraging the multi-view consistency\nafforded by 3DGS and the motion capture capability of the spike camera, our\nframework enables a joint iterative optimization that seamlessly integrates\ninformation between the spike-to-image network and 3DGS. Experiments on\nsynthetic datasets with accurate poses demonstrate that our method surpasses\nprevious approaches by effectively eliminating cascading errors. Moreover, we\nintegrate pose optimization to achieve robust 3D reconstruction in real-world\nscenarios with inaccurate initial poses, outperforming alternative methods by\neffectively reducing noise and preserving fine texture details. Our code, data\nand trained models will be available at\n\\url{https://github.com/chenkang455/USP-Gaussian}.",
      "tldr_zh": "该论文提出 USP-Gaussian 框架，将基于 Spike cameras 的图像重建、姿态校正和 3D Gaussian Splatting 统一到一个端到端优化系统中，旨在解决传统级联管道中累计错误的难题。框架通过利用 3DGS 的多视图一致性和 Spike cameras 的运动捕获能力，实现图像重建网络与 3DGS 的联合迭代优化，从而提升整体重建精度。实验结果显示，该方法在合成数据集上超越了现有方法，消除了级联错误；在真实场景中，通过姿态优化，实现了更鲁棒的 3D 重建，减少噪声并保留精细纹理细节。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10504v1",
      "published_date": "2024-11-15 14:15:16 UTC",
      "updated_date": "2024-11-15 14:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:53:48.646997"
    },
    {
      "arxiv_id": "2411.10197v2",
      "title": "A logic for reasoning with inconsistent knowledge -- A reformulation using nowadays terminology (2024)",
      "title_zh": "翻译失败",
      "authors": [
        "Nico Roos"
      ],
      "abstract": "In many situations humans have to reason with inconsistent knowledge. These\ninconsistencies may occur due to not fully reliable sources of information. In\norder to reason with inconsistent knowledge, it is not possible to view a set\nof premisses as absolute truths as is done in predicate logic. Viewing the set\nof premisses as a set of assumptions, however, it is possible to deduce useful\nconclusions from an inconsistent set of premisses. In this paper a logic for\nreasoning with inconsistent knowledge is described. This logic is a\ngeneralization of the work of N. Rescher [15]. In the logic a reliability\nrelation is used to choose between incompatible assumptions. These choices are\nonly made when a contradiction is derived. As long as no contradiction is\nderived, the knowledge is assumed to be consistent. This makes it possible to\ndefine an argumentation-based deduction process for the logic. For the logic a\nsemantics based on the ideas of Y. Shoham [22, 23], is defined. It turns out\nthat the semantics for the logic is a preferential semantics according to the\ndefinition S. Kraus, D. Lehmann and M. Magidor [12]. Therefore the logic is a\nlogic of system P and possesses all the properties of an ideal non-monotonic\nlogic.",
      "tldr_zh": "本论文重新表述了一种用于处理inconsistent knowledge的逻辑系统，针对信息来源不可靠导致的不一致问题，将前提视为假设而非绝对真理，从而从矛盾前提中推导出有用结论。该系统基于N. Rescher的工作进行推广，引入reliability relation在出现矛盾时选择不兼容假设，并定义了argumentation-based deduction过程和基于Y. Shoham的语义。该逻辑的语义被证明是一种preferential semantics，属于system P的非单调逻辑，具有理想的非单调逻辑属性。",
      "categories": [
        "cs.AI",
        "68T27, 68T30",
        "I.2.3"
      ],
      "primary_category": "cs.AI",
      "comment": "The original version was published in the Artificial Intelligence\n  journal. This original version uses 'justifications' in the proof system,\n  which we would call nowadays 'arguments'. The current version presents the\n  same results but now using the terminology of an assumption-based\n  argumentation system",
      "pdf_url": "http://arxiv.org/pdf/2411.10197v2",
      "published_date": "2024-11-15 13:53:05 UTC",
      "updated_date": "2024-12-13 15:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:55:59.432785"
    },
    {
      "arxiv_id": "2411.12756v1",
      "title": "FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Rishit Kapoor",
        "Jesher Joshua",
        "Muralidharan Vijayarangan",
        "Natarajan B"
      ],
      "abstract": "This research work introduces a novel approach to the classification of\nAlzheimer's disease by using the advanced deep learning techniques combined\nwith secure data processing methods. This research work primary uses transfer\nlearning models such as ResNet, ImageNet, and VNet to extract high-level\nfeatures from medical image data. Thereafter, these pre-trained models were\nfine-tuned for Alzheimer's related subtle patterns such that the model is\ncapable of robust feature extraction over varying data sources. Further, the\nfederated learning approaches were incorporated to tackle a few other\nchallenges related to classification, aimed to provide better prediction\nperformance and protect data privacy. The proposed model was built using\nfederated learning without sharing sensitive patient data. This way, the\ndecentralized model benefits from the large and diversified dataset that it is\ntrained upon while ensuring confidentiality. The cipher-based encryption\nmechanism is added that allows us to secure the transportation of data and\nfurther ensure the privacy and integrity of patient information throughout\ntraining and classification. The results of the experiments not only help to\nimprove the accuracy of the classification of Alzheimer's but at the same time\nprovides a framework for secure and collaborative analysis of health care data.",
      "tldr_zh": "该研究提出了一种名为 FedCL-Ensemble Learning 的框架，结合 Federated Continual Learning 和 Ensemble Transfer Learning，用于阿尔茨海默病 MRI 分类，同时保护患者隐私。该框架利用预训练模型如 ResNet、ImageNet 和 VNet 提取特征，并通过微调适应数据变异，同时采用联邦学习方法在不共享敏感数据的情况下实现分布式训练和加密传输。实验结果显示，该方法显著提高了分类准确率，并为安全的医疗数据协作分析提供了可靠的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.12756v1",
      "published_date": "2024-11-15 13:49:22 UTC",
      "updated_date": "2024-11-15 13:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:54:10.580234"
    },
    {
      "arxiv_id": "2411.10191v2",
      "title": "FengWu-W2S: A deep learning model for seamless weather-to-subseasonal forecast of global atmosphere",
      "title_zh": "FengWu-W2S：一种用于全球大气无缝天气到次季节",
      "authors": [
        "Fenghua Ling",
        "Kang Chen",
        "Jiye Wu",
        "Tao Han",
        "Jing-Jia Luo",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Seamless forecasting that produces warning information at continuum\ntimescales based on only one system is a long-standing pursuit for\nweather-climate service. While the rapid advancement of deep learning has\ninduced revolutionary changes in classical forecasting field, current efforts\nare still focused on building separate AI models for weather and climate\nforecasts. To explore the seamless forecasting ability based on one AI model,\nwe propose FengWu-Weather to Subseasonal (FengWu-W2S), which builds on the\nFengWu global weather forecast model and incorporates an ocean-atmosphere-land\ncoupling structure along with a diverse perturbation strategy. FengWu-W2S can\ngenerate 6-hourly atmosphere forecasts extending up to 42 days through an\nautoregressive and seamless manner. Our hindcast results demonstrate that\nFengWu-W2S reliably predicts atmospheric conditions out to 3-6 weeks ahead,\nenhancing predictive capabilities for global surface air temperature,\nprecipitation, geopotential height and intraseasonal signals such as the\nMadden-Julian Oscillation (MJO) and North Atlantic Oscillation (NAO). Moreover,\nour ablation experiments on forecast error growth from daily to seasonal\ntimescales reveal potential pathways for developing AI-based integrated system\nfor seamless weather-climate forecasting in the future.",
      "tldr_zh": "本研究提出了一种深度学习模型FengWu-W2S，旨在实现基于单一AI系统的无缝天气到亚季节预报，构建于FengWu全球天气预报模型之上，并整合了海洋-大气-陆地耦合结构和多样化扰动策略。该模型通过自回归方式生成长达42天的6小时间隔大气预报，后验测试显示其能可靠预测3-6周内的全球表面空气温度、降水、地表高度以及内部季节信号如Madden-Julian Oscillation (MJO)和North Atlantic Oscillation (NAO)。此外，消融实验揭示了从日常到季节尺度预测误差增长的机制，为未来开发AI-based集成天气-气候预报系统提供了潜在路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10191v2",
      "published_date": "2024-11-15 13:44:37 UTC",
      "updated_date": "2024-11-20 01:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:54:23.764679"
    },
    {
      "arxiv_id": "2411.10184v1",
      "title": "Agentic LLMs in the Supply Chain: Towards Autonomous Multi-Agent Consensus-Seeking",
      "title_zh": "翻译失败",
      "authors": [
        "Valeria Jannelli",
        "Stefan Schoepf",
        "Matthias Bickel",
        "Torbjørn Netland",
        "Alexandra Brintrup"
      ],
      "abstract": "This paper explores how Large Language Models (LLMs) can automate\nconsensus-seeking in supply chain management (SCM), where frequent decisions on\nproblems such as inventory levels and delivery times require coordination among\ncompanies. Traditional SCM relies on human consensus in decision-making to\navoid emergent problems like the bullwhip effect. Some routine consensus\nprocesses, especially those that are time-intensive and costly, can be\nautomated. Existing solutions for automated coordination have faced challenges\ndue to high entry barriers locking out SMEs, limited capabilities, and limited\nadaptability in complex scenarios. However, recent advances in Generative AI,\nparticularly LLMs, show promise in overcoming these barriers. LLMs, trained on\nvast datasets can negotiate, reason, and plan, facilitating near-human-level\nconsensus at scale with minimal entry barriers. In this work, we identify key\nlimitations in existing approaches and propose autonomous LLM agents to address\nthese gaps. We introduce a series of novel, supply chain-specific\nconsensus-seeking frameworks tailored for LLM agents and validate the\neffectiveness of our approach through a case study in inventory management. To\naccelerate progress within the SCM community, we open-source our code,\nproviding a foundation for further advancements in LLM-powered autonomous\nsupply chain solutions.",
      "tldr_zh": "这篇论文探讨了如何利用自治大型语言模型 (LLMs) 代理来自动化供应链管理 (SCM) 中的共识决策，例如库存水平和交货时间，以避免传统问题如牛鞭效应。作者识别了现有自动化方案的局限性，包括高进入壁垒和适应性差，并提出了一系列针对 LLM 代理的供应链特定共识框架。实验通过库存管理的案例研究验证了该方法的有效性，并开源代码以推动 SCM 社区的进一步发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10184v1",
      "published_date": "2024-11-15 13:33:10 UTC",
      "updated_date": "2024-11-15 13:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:54:35.580073"
    },
    {
      "arxiv_id": "2411.10176v1",
      "title": "Let people fail! Exploring the influence of explainable virtual and robotic agents in learning-by-doing tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Matarese",
        "Francesco Rea",
        "Katharina J. Rohlfing",
        "Alessandra Sciutti"
      ],
      "abstract": "Collaborative decision-making with artificial intelligence (AI) agents\npresents opportunities and challenges. While human-AI performance often\nsurpasses that of individuals, the impact of such technology on human behavior\nremains insufficiently understood, primarily when AI agents can provide\njustifiable explanations for their suggestions. This study compares the effects\nof classic vs. partner-aware explanations on human behavior and performance\nduring a learning-by-doing task. Three participant groups were involved: one\ninteracting with a computer, another with a humanoid robot, and a third one\nwithout assistance. Results indicated that partner-aware explanations\ninfluenced participants differently based on the type of artificial agents\ninvolved. With the computer, participants enhanced their task completion times.\nAt the same time, those interacting with the humanoid robot were more inclined\nto follow its suggestions, although they did not reduce their timing.\nInterestingly, participants autonomously performing the learning-by-doing task\ndemonstrated superior knowledge acquisition than those assisted by explainable\nAI (XAI). These findings raise profound questions and have significant\nimplications for automated tutoring and human-AI collaboration.",
      "tldr_zh": "这篇论文探讨了可解释虚拟和机器人代理（explainable virtual and robotic agents）对学习-by-doing任务的影响，比较了经典解释与伙伴感知解释（partner-aware explanations）对人类行为和表现的差异。实验涉及三组参与者：与计算机互动的组改善了任务完成时间，与人形机器人互动的组更倾向于遵循其建议但未减少完成时间，而无辅助组则展现出更强的知识获取能力。这些发现揭示了XAI在人-AI协作（human-AI collaboration）中的潜在局限性，并为自动化辅导系统提供了重要启示，强调了允许人们独立失败的价值。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10176v1",
      "published_date": "2024-11-15 13:22:04 UTC",
      "updated_date": "2024-11-15 13:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:54:48.019859"
    },
    {
      "arxiv_id": "2411.10175v2",
      "title": "The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning",
      "title_zh": "预训练视觉表示在基于模型的强化学习中的出人意料无效性",
      "authors": [
        "Moritz Schneider",
        "Robert Krug",
        "Narunas Vaskevicius",
        "Luigi Palmieri",
        "Joschka Boedecker"
      ],
      "abstract": "Visual Reinforcement Learning (RL) methods often require extensive amounts of\ndata. As opposed to model-free RL, model-based RL (MBRL) offers a potential\nsolution with efficient data utilization through planning. Additionally, RL\nlacks generalization capabilities for real-world tasks. Prior work has shown\nthat incorporating pre-trained visual representations (PVRs) enhances sample\nefficiency and generalization. While PVRs have been extensively studied in the\ncontext of model-free RL, their potential in MBRL remains largely unexplored.\nIn this paper, we benchmark a set of PVRs on challenging control tasks in a\nmodel-based RL setting. We investigate the data efficiency, generalization\ncapabilities, and the impact of different properties of PVRs on the performance\nof model-based agents. Our results, perhaps surprisingly, reveal that for MBRL\ncurrent PVRs are not more sample efficient than learning representations from\nscratch, and that they do not generalize better to out-of-distribution (OOD)\nsettings. To explain this, we analyze the quality of the trained dynamics\nmodel. Furthermore, we show that data diversity and network architecture are\nthe most important contributors to OOD generalization performance.",
      "tldr_zh": "这篇论文探讨了Pre-Trained Visual Representations (PVRs)在Model-Based Reinforcement Learning (MBRL)中的表现，结果出人意料地显示PVRs并未带来预期的优势。通过在挑战性控制任务上基准测试一系列PVRs，研究者评估了其数据效率、泛化能力和相关属性。结果表明，PVRs在MBRL中并不比从零开始学习表示更高效，也不更擅长处理Out-of-Distribution (OOD)设置；相反，数据多样性和网络架构是提升OOD泛化性能的最重要因素。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024). Project page: https://schneimo.com/pvr4mbrl/",
      "pdf_url": "http://arxiv.org/pdf/2411.10175v2",
      "published_date": "2024-11-15 13:21:26 UTC",
      "updated_date": "2025-01-15 15:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:55:01.071769"
    },
    {
      "arxiv_id": "2411.10174v1",
      "title": "A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Benoit Coqueret",
        "Mathieu Carbone",
        "Olivier Sentieys",
        "Gabriel Zaid"
      ],
      "abstract": "During the past decade, Deep Neural Networks (DNNs) proved their value on a\nlarge variety of subjects. However despite their high value and public\naccessibility, the protection of the intellectual property of DNNs is still an\nissue and an emerging research field. Recent works have successfully extracted\nfully-connected DNNs using cryptanalytic methods in hard-label settings,\nproving that it was possible to copy a DNN with high fidelity, i.e., high\nsimilitude in the output predictions. However, the current cryptanalytic\nattacks cannot target complex, i.e., not fully connected, DNNs and are limited\nto special cases of neurons present in deep networks.\n  In this work, we introduce a new end-to-end attack framework designed for\nmodel extraction of embedded DNNs with high fidelity. We describe a new\nblack-box side-channel attack which splits the DNN in several linear parts for\nwhich we can perform cryptanalytic extraction and retrieve the weights in\nhard-label settings. With this method, we are able to adapt cryptanalytic\nextraction, for the first time, to non-fully connected DNNs, while maintaining\na high fidelity. We validate our contributions by targeting several\narchitectures implemented on a microcontroller unit, including a Multi-Layer\nPerceptron (MLP) of 1.7 million parameters and a shortened MobileNetv1. Our\nframework successfully extracts all of these DNNs with high fidelity (88.4% for\nthe MobileNetv1 and 93.2% for the MLP). Furthermore, we use the stolen model to\ngenerate adversarial examples and achieve close to white-box performance on the\nvictim's model (95.8% and 96.7% transfer rate).",
      "tldr_zh": "本文提出了一种新的端到端攻击框架，用于在硬标签设置下，通过侧信道攻击（side-channel attacks）提取非全连接Deep Neural Networks (DNNs)的模型，从而解决现有密码分析方法的局限性。该框架将DNN分解为多个线性部分，进行密码分析提取权重，确保高fidelity提取。实验验证了该方法在微控制器上针对Multi-Layer Perceptron (MLP)（1.7百万参数）和缩短的MobileNetv1的适用性，分别实现了93.2%和88.4%的fidelity，并成功生成对抗样本，转移率接近白盒攻击水平（95.8%和96.7%）。这为DNN知识产权保护提供了重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10174v1",
      "published_date": "2024-11-15 13:19:59 UTC",
      "updated_date": "2024-11-15 13:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:55:12.844724"
    },
    {
      "arxiv_id": "2411.10173v1",
      "title": "Semantics and Spatiality of Emergent Communication",
      "title_zh": "涌现通信的语义和空间性",
      "authors": [
        "Rotem Ben Zion",
        "Boaz Carmeli",
        "Orr Paradise",
        "Yonatan Belinkov"
      ],
      "abstract": "When artificial agents are jointly trained to perform collaborative tasks\nusing a communication channel, they develop opaque goal-oriented communication\nprotocols. Good task performance is often considered sufficient evidence that\nmeaningful communication is taking place, but existing empirical results show\nthat communication strategies induced by common objectives can be\ncounterintuitive whilst solving the task nearly perfectly. In this work, we\nidentify a goal-agnostic prerequisite to meaningful communication, which we\nterm semantic consistency, based on the idea that messages should have similar\nmeanings across instances. We provide a formal definition for this idea, and\nuse it to compare the two most common objectives in the field of emergent\ncommunication: discrimination and reconstruction. We prove, under mild\nassumptions, that semantically inconsistent communication protocols can be\noptimal solutions to the discrimination task, but not to reconstruction. We\nfurther show that the reconstruction objective encourages a stricter property,\nspatial meaningfulness, which also accounts for the distance between messages.\nExperiments with emergent communication games validate our theoretical results.\nThese findings demonstrate an inherent advantage of distance-based\ncommunication goals, and contextualize previous empirical discoveries.",
      "tldr_zh": "该论文探讨了紧急通信（emergent communication）中语义一致性（semantic consistency）和空间意义性（spatial meaningfulness）的概念，强调任务表现良好并不等同于有意义的通信。作者定义语义一致性作为通信协议的必要条件，并通过理论证明比较了区分和重构两种常见目标，发现区分任务可能导致语义不一致的协议，而重构任务则能确保语义一致性。重构目标进一步促进空间意义性，考虑消息之间的距离。实验验证了这些结果，证明基于距离的通信目标具有固有优势。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, to be published in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10173v1",
      "published_date": "2024-11-15 13:19:27 UTC",
      "updated_date": "2024-11-15 13:19:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:55:24.291175"
    },
    {
      "arxiv_id": "2411.10172v1",
      "title": "Increasing the Accessibility of Causal Domain Knowledge via Causal Information Extraction Methods: A Case Study in the Semiconductor Manufacturing Industry",
      "title_zh": "翻译失败",
      "authors": [
        "Houssam Razouk",
        "Leonie Benischke",
        "Daniel Garber",
        "Roman Kern"
      ],
      "abstract": "The extraction of causal information from textual data is crucial in the\nindustry for identifying and mitigating potential failures, enhancing process\nefficiency, prompting quality improvements, and addressing various operational\nchallenges. This paper presents a study on the development of automated methods\nfor causal information extraction from actual industrial documents in the\nsemiconductor manufacturing industry. The study proposes two types of causal\ninformation extraction methods, single-stage sequence tagging (SST) and\nmulti-stage sequence tagging (MST), and evaluates their performance using\nexisting documents from a semiconductor manufacturing company, including\npresentation slides and FMEA (Failure Mode and Effects Analysis) documents. The\nstudy also investigates the effect of representation learning on downstream\ntasks. The presented case study showcases that the proposed MST methods for\nextracting causal information from industrial documents are suitable for\npractical applications, especially for semi structured documents such as FMEAs,\nwith a 93\\% F1 score. Additionally, MST achieves a 73\\% F1 score on texts\nextracted from presentation slides. Finally, the study highlights the\nimportance of choosing a language model that is more aligned with the domain\nand in-domain fine-tuning.",
      "tldr_zh": "这篇论文研究了通过因果信息提取方法提高半导体制造行业因果领域知识的可访问性，焦点在于从工业文档中自动提取因果信息以识别故障并优化流程。论文提出两种方法：单阶段序列标记 (SST) 和多阶段序列标记 (MST)，并在真实文档（如演示幻灯片和 FMEA）上评估其性能。实验结果显示，MST 在 FMEA 等半结构化文档上达到 93% F1 分数，在演示幻灯片上达到 73% F1 分数，同时强调了表示学习和选择与领域相关的语言模型进行微调的重要性。该研究为工业应用提供了实用框架，提升了因果知识的提取效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10172v1",
      "published_date": "2024-11-15 13:18:18 UTC",
      "updated_date": "2024-11-15 13:18:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:55:36.577973"
    },
    {
      "arxiv_id": "2411.10171v2",
      "title": "Imagine-2-Drive: Leveraging High-Fidelity World Models via Multi-Modal Diffusion Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Anant Garg",
        "K Madhava Krishna"
      ],
      "abstract": "World Model-based Reinforcement Learning (WMRL) enables sample efficient\npolicy learning by reducing the need for online interactions which can\npotentially be costly and unsafe, especially for autonomous driving. However,\nexisting world models often suffer from low prediction fidelity and compounding\none-step errors, leading to policy degradation over long horizons.\nAdditionally, traditional RL policies, often deterministic or single\nGaussian-based, fail to capture the multi-modal nature of decision-making in\ncomplex driving scenarios. To address these challenges, we propose\nImagine-2-Drive, a novel WMRL framework that integrates a high-fidelity world\nmodel with a multi-modal diffusion-based policy actor. It consists of two key\ncomponents: DiffDreamer, a diffusion-based world model that generates future\nobservations simultaneously, mitigating error accumulation, and DPA (Diffusion\nPolicy Actor), a diffusion-based policy that models diverse and multi-modal\ntrajectory distributions. By training DPA within DiffDreamer, our method\nenables robust policy learning with minimal online interactions. We evaluate\nour method in CARLA using standard driving benchmarks and demonstrate that it\noutperforms prior world model baselines, improving Route Completion and Success\nRate by 15% and 20% respectively.",
      "tldr_zh": "本研究提出Imagine-2-Drive框架，利用高保真世界模型(World Models)结合多模态扩散策略(Diffusion Policies)，以提升World Model-based Reinforcement Learning (WMRL)在自动驾驶中的样本效率和鲁棒性。该框架包括DiffDreamer组件，通过扩散模型同时生成未来观察，减少错误积累；以及DPA (Diffusion Policy Actor)组件，建模多模态轨迹分布以处理复杂驾驶场景。通过在DiffDreamer中训练DPA，该方法显著减少在线互动需求。在CARLA基准测试中，Imagine-2-Drive比现有基线提升Route Completion 15%和Success Rate 20%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.10171v2",
      "published_date": "2024-11-15 13:17:54 UTC",
      "updated_date": "2025-03-09 18:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:55:47.438867"
    },
    {
      "arxiv_id": "2411.10168v1",
      "title": "Evaluating the role of `Constitutions' for learning from AI feedback",
      "title_zh": "评估 `Constitutions` 在从 AI 反馈学习中的作用",
      "authors": [
        "Saskia Redgate",
        "Andrew M. Bean",
        "Adam Mahdi"
      ],
      "abstract": "The growing capabilities of large language models (LLMs) have led to their\nuse as substitutes for human feedback for training and assessing other LLMs.\nThese methods often rely on `constitutions', written guidelines which a critic\nmodel uses to provide feedback and improve generations. We investigate how the\nchoice of constitution affects feedback quality by using four different\nconstitutions to improve patient-centered communication in medical interviews.\nIn pairwise comparisons conducted by 215 human raters, we found that detailed\nconstitutions led to better results regarding emotive qualities. However, none\nof the constitutions outperformed the baseline in learning more\npractically-oriented skills related to information gathering and provision. Our\nfindings indicate that while detailed constitutions should be prioritised,\nthere are possible limitations to the effectiveness of AI feedback as a reward\nsignal in certain areas.",
      "tldr_zh": "本研究评估了“constitutions”（书面指南）在从AI反馈中学习中的作用，特别针对大语言模型（LLMs）用于替代人类反馈的场景。研究者使用四种不同的constitutions来提升医疗访谈中的患者中心沟通，通过215名人类评估者的配对比较发现，详细的constitutions在情感品质方面表现更好。然而，在信息收集和提供等实际技能上，没有任何constitution优于基线模型。这些发现表明，虽然应优先采用详细的constitutions，但AI反馈作为奖励信号在某些领域可能存在局限性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 2 figures. In NeurIPS 2024 Workshop on Language Gamification",
      "pdf_url": "http://arxiv.org/pdf/2411.10168v1",
      "published_date": "2024-11-15 13:16:11 UTC",
      "updated_date": "2024-11-15 13:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:56:09.917663"
    },
    {
      "arxiv_id": "2411.10156v5",
      "title": "Mitigating Sycophancy in Decoder-Only Transformer Architectures: Synthetic Data Intervention",
      "title_zh": "翻译失败",
      "authors": [
        "Libo Wang"
      ],
      "abstract": "To address the sycophancy problem caused by reinforcement learning from human\nfeedback in large language models, this research applies synthetic data\nintervention technology to the decoder-only transformer architecture. Based on\nthe research gaps in the existing literature, the researcher designed an\nexperimental process to reduce the tendency of models to cater by generating\ndiversified data, and used GPT4o as an experimental tool for verification. The\nexperiment used 100 true and false questions, and compared the performance of\nthe model trained with synthetic data intervention and the original untrained\nmodel on multiple indicators. The results show that the SDI training model\nsupports the technology in terms of accuracy rate and sycophancy rate and has\nsignificant effectiveness in reducing sycophancy phenomena.",
      "tldr_zh": "本研究针对大型语言模型中由 reinforcement learning from human feedback 引起的 sycophancy 问题，提出 synthetic data intervention 技术应用于 decoder-only transformer 架构，以生成多样化数据并减少模型的迎合倾向。研究设计了一个实验过程，使用 GPT-4o 作为工具，对 100 个真假问题进行测试，并比较了训练后模型与原始模型的性能。结果表明，采用 synthetic data intervention 的模型在准确率和 sycophancy 率上均有显著提升，有效缓解了 sycophancy 现象。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The data set, experimental process, code and data results have been\n  uploaded to Github repository, the link is\n  https://github.com/brucewang123456789/GeniusTrail/tree/main/Synthetic%20Data%20Intervention",
      "pdf_url": "http://arxiv.org/pdf/2411.10156v5",
      "published_date": "2024-11-15 12:59:46 UTC",
      "updated_date": "2025-03-20 13:29:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:56:23.192515"
    },
    {
      "arxiv_id": "2411.10152v1",
      "title": "Causal Time-Series Synchronization for Multi-Dimensional Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Mayr",
        "Georgios C. Chasparis",
        "Josef Küng"
      ],
      "abstract": "The process industry's high expectations for Digital Twins require modeling\napproaches that can generalize across tasks and diverse domains with\npotentially different data dimensions and distributional shifts i.e.,\nFoundational Models. Despite success in natural language processing and\ncomputer vision, transfer learning with (self-) supervised signals for\npre-training general-purpose models is largely unexplored in the context of\nDigital Twins in the process industry due to challenges posed by\nmulti-dimensional time-series data, lagged cause-effect dependencies, complex\ncausal structures, and varying number of (exogenous) variables. We propose a\nnovel channel-dependent pre-training strategy that leverages synchronized\ncause-effect pairs to overcome these challenges by breaking down the\nmulti-dimensional time-series data into pairs of cause-effect variables. Our\napproach focuses on: (i) identifying highly lagged causal relationships using\ndata-driven methods, (ii) synchronizing cause-effect pairs to generate training\nsamples for channel-dependent pre-training, and (iii) evaluating the\neffectiveness of this approach in channel-dependent forecasting. Our\nexperimental results demonstrate significant improvements in forecasting\naccuracy and generalization capability compared to traditional training\nmethods.",
      "tldr_zh": "这篇论文针对过程工业的 Digital Twins 提出了一种新的通道依赖预训练策略，用于处理多维时间序列数据的挑战，如滞后的因果依赖和复杂的因果结构。该策略通过数据驱动方法识别高度滞后的因果关系，并同步因果对生成训练样本，从而实现通道依赖的预测预训练。与传统方法相比，实验结果显示该方法显著提升了预测准确性和泛化能力。整体上，这为构建通用型数字孪生模型提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.10152v1",
      "published_date": "2024-11-15 12:50:57 UTC",
      "updated_date": "2024-11-15 12:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:56:34.887746"
    },
    {
      "arxiv_id": "2411.10137v1",
      "title": "Legal Evalutions and Challenges of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Wang",
        "Huan Zhao",
        "Zhenyuan Yang",
        "Peng Shu",
        "Junhao Chen",
        "Haobo Sun",
        "Ruixi Liang",
        "Shixin Li",
        "Pengcheng Shi",
        "Longjun Ma",
        "Zongjia Liu",
        "Zhengliang Liu",
        "Tianyang Zhong",
        "Yutong Zhang",
        "Chong Ma",
        "Xin Zhang",
        "Tuo Zhang",
        "Tianli Ding",
        "Yudan Ren",
        "Tianming Liu",
        "Xi Jiang",
        "Shu Zhang"
      ],
      "abstract": "In this paper, we review legal testing methods based on Large Language Models\n(LLMs), using the OPENAI o1 model as a case study to evaluate the performance\nof large models in applying legal provisions. We compare current\nstate-of-the-art LLMs, including open-source, closed-source, and legal-specific\nmodels trained specifically for the legal domain. Systematic tests are\nconducted on English and Chinese legal cases, and the results are analyzed in\ndepth. Through systematic testing of legal cases from common law systems and\nChina, this paper explores the strengths and weaknesses of LLMs in\nunderstanding and applying legal texts, reasoning through legal issues, and\npredicting judgments. The experimental results highlight both the potential and\nlimitations of LLMs in legal applications, particularly in terms of challenges\nrelated to the interpretation of legal language and the accuracy of legal\nreasoning. Finally, the paper provides a comprehensive analysis of the\nadvantages and disadvantages of various types of models, offering valuable\ninsights and references for the future application of AI in the legal field.",
      "tldr_zh": "这篇论文审查了基于 Large Language Models (LLMs) 的法律测试方法，以 OPENAI o1 模型为例，评估其在应用法律条款方面的性能，并比较了开源、闭源和法律专用模型。研究通过对英语和中文法律案例进行系统测试，分析了 LLMs 在理解法律文本、推理法律问题和预测判决方面的优势和劣势。实验结果显示，LLMs 在法律应用中展现出潜力，但面临法律语言解释和推理准确性的挑战。最终，该论文提供了对各种模型优缺点的全面分析，为 AI 在法律领域的未来应用提供了宝贵见解和参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10137v1",
      "published_date": "2024-11-15 12:23:12 UTC",
      "updated_date": "2024-11-15 12:23:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:58:48.255759"
    },
    {
      "arxiv_id": "2411.10115v2",
      "title": "Memorization in Attention-only Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Léo Dana",
        "Muni Sreenivas Pydi",
        "Yann Chevaleyre"
      ],
      "abstract": "Recent research has explored the memorization capacity of multi-head\nattention, but these findings are constrained by unrealistic limitations on the\ncontext size. We present a novel proof for language-based Transformers that\nextends the current hypothesis to any context size. Our approach improves upon\nthe state-of-the-art by achieving more effective exact memorization with an\nattention layer, while also introducing the concept of approximate memorization\nof distributions. Through experimental validation, we demonstrate that our\nproposed bounds more accurately reflect the true memorization capacity of\nlanguage models, and provide a precise comparison with prior work.",
      "tldr_zh": "这篇论文探讨了仅使用注意力的Transformers模型中的记忆能力，提出一个新证明，将多头注意力(multi-head attention)的记忆假设扩展到任意上下文大小(context size)。他们改进了精确记忆(exact memorization)的效率，并引入了近似记忆(approximate memorization)分布的概念，以更好地捕捉模型性能。实验结果显示，该方法更准确地反映了语言模型的真实记忆能力，并提供了与现有研究的精确比较。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 6 figures, submitted to AISTATS 2025,",
      "pdf_url": "http://arxiv.org/pdf/2411.10115v2",
      "published_date": "2024-11-15 11:29:31 UTC",
      "updated_date": "2025-03-10 08:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:56:58.419508"
    },
    {
      "arxiv_id": "2411.10109v1",
      "title": "Generative Agent Simulations of 1,000 People",
      "title_zh": "翻译失败",
      "authors": [
        "Joon Sung Park",
        "Carolyn Q. Zou",
        "Aaron Shaw",
        "Benjamin Mako Hill",
        "Carrie Cai",
        "Meredith Ringel Morris",
        "Robb Willer",
        "Percy Liang",
        "Michael S. Bernstein"
      ],
      "abstract": "The promise of human behavioral simulation--general-purpose computational\nagents that replicate human behavior across domains--could enable broad\napplications in policymaking and social science. We present a novel agent\narchitecture that simulates the attitudes and behaviors of 1,052 real\nindividuals--applying large language models to qualitative interviews about\ntheir lives, then measuring how well these agents replicate the attitudes and\nbehaviors of the individuals that they represent. The generative agents\nreplicate participants' responses on the General Social Survey 85% as\naccurately as participants replicate their own answers two weeks later, and\nperform comparably in predicting personality traits and outcomes in\nexperimental replications. Our architecture reduces accuracy biases across\nracial and ideological groups compared to agents given demographic\ndescriptions. This work provides a foundation for new tools that can help\ninvestigate individual and collective behavior.",
      "tldr_zh": "本研究提出了一种新型生成代理架构，使用大型语言模型（LLMs）处理1,052个真实个体的定性访谈数据，以模拟他们的态度和行为。实验结果显示，这些代理在General Social Survey上复制参与者响应的准确率达到85%，与参与者自身两周后重复答案的准确率相当，并在预测个性特征和实验结果方面表现类似。相比基于人口统计描述的代理，该架构显著减少了种族和意识形态群体的偏差，为政策制定和社会科学领域提供了解析个体和集体行为的工具基础。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10109v1",
      "published_date": "2024-11-15 11:14:34 UTC",
      "updated_date": "2024-11-15 11:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:57:10.468035"
    },
    {
      "arxiv_id": "2411.10108v1",
      "title": "Identifying Key Drivers of Heatwaves: A Novel Spatio-Temporal Framework for Extreme Event Detection",
      "title_zh": "翻译失败",
      "authors": [
        "J. Pérez-Aracil",
        "C. Peláez-Rodríguez",
        "Ronan McAdam",
        "Antonello Squintu",
        "Cosmin M. Marina",
        "Eugenio Lorente-Ramos",
        "Niklas Luther",
        "Veronica Torralba",
        "Enrico Scoccimarro",
        "Leone Cavicchia",
        "Matteo Giuliani",
        "Eduardo Zorita",
        "Felicitas Hansen",
        "David Barriopedro",
        "Ricardo Garcia-Herrera",
        "Pedro A. Gutiérrez",
        "Jürg Luterbacher",
        "Elena Xoplaki",
        "Andrea Castelletti",
        "S. Salcedo-Sanz"
      ],
      "abstract": "Heatwaves (HWs) are extreme atmospheric events that produce significant\nsocietal and environmental impacts. Predicting these extreme events remains\nchallenging, as their complex interactions with large-scale atmospheric and\nclimatic variables are difficult to capture with traditional statistical and\ndynamical models. This work presents a general method for driver identification\nin extreme climate events. A novel framework (STCO-FS) is proposed to identify\nkey immediate (short-term) HW drivers by combining clustering algorithms with\nan ensemble evolutionary algorithm. The framework analyzes spatio-temporal\ndata, reduces dimensionality by grouping similar geographical nodes for each\nvariable, and develops driver selection in spatial and temporal domains,\nidentifying the best time lags between predictive variables and HW occurrences.\nThe proposed method has been applied to analyze HWs in the Adda river basin in\nItaly. The approach effectively identifies significant variables influencing\nHWs in this region. This research can potentially enhance our understanding of\nHW drivers and predictability.",
      "tldr_zh": "本研究针对Heatwaves（热浪）预测的挑战，提出了一种新型时空框架STCO-FS，用于识别极端气候事件的关键驱动因素。该框架结合聚类算法和集成进化算法，对时空数据进行分析，通过减少维度（如分组相似地理节点）和在空间及时间域选择驱动因素，识别预测变量与Heatwaves发生的最佳时间滞后。在意大利Adda河盆地的实际应用中，该方法有效识别了影响Heatwaves的重要变量，提升了对这些事件的理解和预测能力。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "28 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.10108v1",
      "published_date": "2024-11-15 11:09:34 UTC",
      "updated_date": "2024-11-15 11:09:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:57:23.859657"
    },
    {
      "arxiv_id": "2411.10500v1",
      "title": "Edge-Only Universal Adversarial Attacks in Distributed Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Giulio Rossolini",
        "Tommaso Baldi",
        "Alessandro Biondi",
        "Giorgio Buttazzo"
      ],
      "abstract": "Distributed learning frameworks, which partition neural network models across\nmultiple computing nodes, enhance efficiency in collaborative edge-cloud\nsystems but may also introduce new vulnerabilities. In this work, we explore\nthe feasibility of generating universal adversarial attacks when an attacker\nhas access to the edge part of the model only, which consists in the first\nnetwork layers. Unlike traditional universal adversarial perturbations (UAPs)\nthat require full model knowledge, our approach shows that adversaries can\ninduce effective mispredictions in the unknown cloud part by leveraging key\nfeatures on the edge side. Specifically, we train lightweight classifiers from\nintermediate features available at the edge, i.e., before the split point, and\nuse them in a novel targeted optimization to craft effective UAPs. Our results\non ImageNet demonstrate strong attack transferability to the unknown cloud\npart. Additionally, we analyze the capability of an attacker to achieve\ntargeted adversarial effect with edge-only knowledge, revealing intriguing\nbehaviors. By introducing the first adversarial attacks with edge-only\nknowledge in split inference, this work underscores the importance of\naddressing partial model access in adversarial robustness, encouraging further\nresearch in this area.",
      "tldr_zh": "这篇论文探讨了分布式学习中，仅通过访问模型的边缘部分（即第一层网络）来生成通用对抗攻击（UAPs）的可行性，旨在揭示这种攻击对边缘-云系统的潜在威胁。研究方法包括训练轻量级分类器从边缘的中间特征入手，并采用新型目标优化技术来创建有效的 UAPs，而无需完整模型知识。实验结果在 ImageNet 数据集上显示，这些攻击具有强烈的转移性，能够诱导未知云部分的错误预测，并分析了针对性对抗行为的特性。该工作首次在分割推理中引入边缘-only 攻击，强调了在对抗鲁棒性中处理部分模型访问的重要性，并鼓励进一步研究。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10500v1",
      "published_date": "2024-11-15 11:06:24 UTC",
      "updated_date": "2024-11-15 11:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:57:34.845911"
    },
    {
      "arxiv_id": "2411.10100v1",
      "title": "Multi-Task Adversarial Variational Autoencoder for Estimating Biological Brain Age with Multimodal Neuroimaging",
      "title_zh": "多任务对抗变分自编码器用于通过多模态神经影像估计生物脑年龄",
      "authors": [
        "Muhammad Usman",
        "Azka Rehman",
        "Abdullah Shahid",
        "Abd Ur Rehman",
        "Sung-Min Gho",
        "Aleum Lee",
        "Tariq M. Khan",
        "Imran Razzak"
      ],
      "abstract": "Despite advances in deep learning for estimating brain age from structural\nMRI data, incorporating functional MRI data is challenging due to its complex\nstructure and the noisy nature of functional connectivity measurements. To\naddress this, we present the Multitask Adversarial Variational Autoencoder, a\ncustom deep learning framework designed to improve brain age predictions\nthrough multimodal MRI data integration. This model separates latent variables\ninto generic and unique codes, isolating shared and modality-specific features.\nBy integrating multitask learning with sex classification as an additional\ntask, the model captures sex-specific aging patterns. Evaluated on the OpenBHB\ndataset, a large multisite brain MRI collection, the model achieves a mean\nabsolute error of 2.77 years, outperforming traditional methods. This success\npositions M-AVAE as a powerful tool for metaverse-based healthcare applications\nin brain age estimation.",
      "tldr_zh": "该论文提出 Multi-Task Adversarial Variational Autoencoder (M-AVAE) 框架，用于通过多模态 MRI 数据（如结构和功能 MRI）估计生物大脑年龄，解决功能连接数据复杂性和噪声问题。\nM-AVAE 通过分离潜在变量为通用和独特代码，捕捉共享及模式特定特征，并结合多任务学习（如性别分类）来识别性别相关的老化模式。\n在 OpenBHB 数据集上，该模型实现了 2.77 年的平均绝对误差，优于传统方法，并为元宇宙医疗应用中的大脑年龄估计提供强大工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10100v1",
      "published_date": "2024-11-15 10:50:36 UTC",
      "updated_date": "2024-11-15 10:50:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:57:47.413127"
    },
    {
      "arxiv_id": "2411.10091v1",
      "title": "AI and the Future of Work in Africa White Paper",
      "title_zh": "AI 与非洲工作未来的白皮书",
      "authors": [
        "Jacki O'Neill",
        "Vukosi Marivate",
        "Barbara Glover",
        "Winnie Karanu",
        "Girmaw Abebe Tadesse",
        "Akua Gyekye",
        "Anne Makena",
        "Wesley Rosslyn-Smith",
        "Matthew Grollnek",
        "Charity Wayua",
        "Rehema Baguma",
        "Angel Maduke",
        "Sarah Spencer",
        "Daniel Kandie",
        "Dennis Ndege Maari",
        "Natasha Mutangana",
        "Maxamed Axmed",
        "Nyambura Kamau",
        "Muhammad Adamu",
        "Frank Swaniker",
        "Brian Gatuguti",
        "Jonathan Donner",
        "Mark Graham",
        "Janet Mumo",
        "Caroline Mbindyo",
        "Charlette N'Guessan",
        "Irene Githinji",
        "Lesego Makhafola",
        "Sean Kruger",
        "Olivia Etyang",
        "Mulang Onando",
        "Joe Sevilla",
        "Nanjira Sambuli",
        "Martin Mbaya",
        "Paul Breloff",
        "Gideon M. Anapey",
        "Tebogo L. Mogaleemang",
        "Tiyani Nghonyama",
        "Muthoni Wanyoike",
        "Bhekani Mbuli",
        "Lawrence Nderu",
        "Wambui Nyabero",
        "Uzma Alam",
        "Kayode Olaleye",
        "Caroline Njenga",
        "Abigail Sellen",
        "David Kairo",
        "Rutendo Chabikwa",
        "Najeeb G. Abdulhamid",
        "Ketry Kubasu",
        "Chinasa T. Okolo",
        "Eugenia Akpo",
        "Joel Budu",
        "Issa Karambal",
        "Joseph Berkoh",
        "William Wasswa",
        "Muchai Njagwi",
        "Rob Burnet",
        "Loise Ochanda",
        "Hanlie de Bod",
        "Elizabeth Ankrah",
        "Selemani Kinyunyu",
        "Mutembei Kariuki",
        "Angel Maduke",
        "Kizito Kiyimba",
        "Farida Eleshin",
        "Lillian Secelela Madeje",
        "Catherine Muraga",
        "Ida Nganga",
        "Judy Gichoya",
        "Tabbz Maina",
        "Samuel Maina",
        "Muchai Mercy",
        "Millicent Ochieng",
        "Stephanie Nyairo"
      ],
      "abstract": "This white paper is the output of a multidisciplinary workshop in Nairobi\n(Nov 2023). Led by a cross-organisational team including Microsoft Research,\nNEPAD, Lelapa AI, and University of Oxford. The workshop brought together\ndiverse thought-leaders from various sectors and backgrounds to discuss the\nimplications of Generative AI for the future of work in Africa. Discussions\ncentred around four key themes: Macroeconomic Impacts; Jobs, Skills and Labour\nMarkets; Workers' Perspectives and Africa-Centris AI Platforms. The white paper\nprovides an overview of the current state and trends of generative AI and its\napplications in different domains, as well as the challenges and risks\nassociated with its adoption and regulation. It represents a diverse set of\nperspectives to create a set of insights and recommendations which aim to\nencourage debate and collaborative action towards creating a dignified future\nof work for everyone across Africa.",
      "tldr_zh": "这篇白皮书是2023年11月在Nairobi举办的多学科研讨会的成果，由Microsoft Research、NEPAD、Lelapa AI和Oxford大学等组织领导。研讨会聚集了来自不同领域的思想领袖，讨论生成式AI（Generative AI）对非洲未来工作的影响，包括宏观经济影响、工作技能和劳动力市场、工人的视角以及以非洲为中心的AI平台。白皮书概述了生成式AI的当前状态、趋势及其在各领域的应用，同时分析了其采用和监管的挑战与风险，并基于多样视角提出见解和推荐，以促进辩论和合作行动，打造非洲的尊严未来工作。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10091v1",
      "published_date": "2024-11-15 10:34:59 UTC",
      "updated_date": "2024-11-15 10:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:57:58.561725"
    },
    {
      "arxiv_id": "2411.10087v3",
      "title": "PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse",
      "title_zh": "翻译失败",
      "authors": [
        "Einari Vaaras",
        "Manu Airaksinen",
        "Okko Räsänen"
      ],
      "abstract": "Self-supervised learning (SSL) is a data-driven learning approach that\nutilizes the innate structure of the data to guide the learning process. In\ncontrast to supervised learning, which depends on external labels, SSL utilizes\nthe inherent characteristics of the data to produce its own supervisory signal.\nHowever, one frequent issue with SSL methods is representation collapse, where\nthe model outputs a constant input-invariant feature representation. This issue\nhinders the potential application of SSL methods to new data modalities, as\ntrying to avoid representation collapse wastes researchers' time and effort.\nThis paper introduces a novel SSL algorithm for time-series data called\nPrediction of Functionals from Masked Latents (PFML). Instead of predicting\nmasked input signals or their latent representations directly, PFML operates by\npredicting statistical functionals of the input signal corresponding to masked\nembeddings, given a sequence of unmasked embeddings. The algorithm is designed\nto avoid representation collapse, rendering it straightforwardly applicable to\ndifferent time-series data domains, such as novel sensor modalities in clinical\ndata. We demonstrate the effectiveness of PFML through complex, real-life\nclassification tasks across three different data modalities: infant posture and\nmovement classification from multi-sensor inertial measurement unit data,\nemotion recognition from speech data, and sleep stage classification from EEG\ndata. The results show that PFML is superior to a conceptually similar SSL\nmethod and a contrastive learning-based SSL method. Additionally, PFML is on\npar with the current state-of-the-art SSL method, while also being conceptually\nsimpler and without suffering from representation collapse.",
      "tldr_zh": "该论文针对 Self-Supervised Learning (SSL) 中的 Representation Collapse 问题，提出了一种新算法 PFML，用于时间序列数据的学习。PFML 的方法是通过预测被掩盖嵌入对应的输入信号的 Statistical Functionals，而非直接预测信号或其潜在表示，从而确保模型避免表示坍缩，并易于应用于不同数据领域，如临床传感器数据。实验结果显示，PFML 在婴儿姿势和运动分类、情绪识别以及睡眠阶段分类等真实任务中，优于对比学习方法和类似 SSL 方法，并与最先进方法性能相当，同时其设计更简单易用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2411.10087v3",
      "published_date": "2024-11-15 10:16:38 UTC",
      "updated_date": "2025-04-08 09:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:59:00.250240"
    },
    {
      "arxiv_id": "2411.10084v1",
      "title": "Adapting the Biological SSVEP Response to Artificial Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Emirhan Böge",
        "Yasemin Gunindi",
        "Erchan Aptoula",
        "Nihan Alp",
        "Huseyin Ozkan"
      ],
      "abstract": "Neuron importance assessment is crucial for understanding the inner workings\nof artificial neural networks (ANNs) and improving their interpretability and\nefficiency. This paper introduces a novel approach to neuron significance\nassessment inspired by frequency tagging, a technique from neuroscience. By\napplying sinusoidal contrast modulation to image inputs and analyzing resulting\nneuron activations, this method enables fine-grained analysis of a network's\ndecision-making processes. Experiments conducted with a convolutional neural\nnetwork for image classification reveal notable harmonics and intermodulations\nin neuron-specific responses under part-based frequency tagging. These findings\nsuggest that ANNs exhibit behavior akin to biological brains in tuning to\nflickering frequencies, thereby opening avenues for neuron/filter importance\nassessment through frequency tagging. The proposed method holds promise for\napplications in network pruning, and model interpretability, contributing to\nthe advancement of explainable artificial intelligence and addressing the lack\nof transparency in neural networks. Future research directions include\ndeveloping novel loss functions to encourage biologically plausible behavior in\nANNs.",
      "tldr_zh": "本论文提出一种受神经科学频率标记启发的神经元重要性评估方法，通过对图像输入施加正弦对比度调制并分析神经元激活，实现对ANNs决策过程的细粒度分析。实验在卷积神经网络的图像分类任务中发现，神经元响应中存在显著的谐波和互调，展现出类似于生物大脑对闪烁频率的调谐行为。该方法为ANNs的网络修剪和模型可解释性提供新途径，推动可解释人工智能的发展，并建议未来研究开发新的损失函数以增强ANNs的生物学合理性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10084v1",
      "published_date": "2024-11-15 10:02:48 UTC",
      "updated_date": "2024-11-15 10:02:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:59:11.866729"
    },
    {
      "arxiv_id": "2411.10072v1",
      "title": "Real-Time AI-Driven People Tracking and Counting Using Overhead Cameras",
      "title_zh": "翻译失败",
      "authors": [
        "Ishrath Ahamed",
        "Chamith Dilshan Ranathunga",
        "Dinuka Sandun Udayantha",
        "Benny Kai Kiat Ng",
        "Chau Yuen"
      ],
      "abstract": "Accurate people counting in smart buildings and intelligent transportation\nsystems is crucial for energy management, safety protocols, and resource\nallocation. This is especially critical during emergencies, where precise\noccupant counts are vital for safe evacuation. Existing methods struggle with\nlarge crowds, often losing accuracy with even a few additional people. To\naddress this limitation, this study proposes a novel approach combining a new\nobject tracking algorithm, a novel counting algorithm, and a fine-tuned object\ndetection model. This method achieves 97% accuracy in real-time people counting\nwith a frame rate of 20-27 FPS on a low-power edge computer.",
      "tldr_zh": "这项研究针对智能建筑和交通系统中的人员计数问题，强调其在能源管理、安全协议和紧急疏散中的关键作用，因为现有方法在大人群中准确性不足。论文提出了一种新方法，结合新型物体跟踪算法（object tracking algorithm）、新型计数算法和微调的对象检测模型（object detection model），以实现实时人员跟踪和计数。在低功耗边缘计算机上，该方法达到了97%的准确率，并维持20-27 FPS的帧率，显著提升了实际应用性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted to IEEE Region 10 conference (TENCON) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10072v1",
      "published_date": "2024-11-15 09:37:49 UTC",
      "updated_date": "2024-11-15 09:37:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:59:23.275813"
    },
    {
      "arxiv_id": "2411.10071v1",
      "title": "Evidential Federated Learning for Skin Lesion Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Rutger Hendrix",
        "Federica Proietto Salanitri",
        "Concetto Spampinato",
        "Simone Palazzo",
        "Ulas Bagci"
      ],
      "abstract": "We introduce FedEvPrompt, a federated learning approach that integrates\nprinciples of evidential deep learning, prompt tuning, and knowledge\ndistillation for distributed skin lesion classification. FedEvPrompt leverages\ntwo sets of prompts: b-prompts (for low-level basic visual knowledge) and\nt-prompts (for task-specific knowledge) prepended to frozen pre-trained Vision\nTransformer (ViT) models trained in an evidential learning framework to\nmaximize class evidences. Crucially, knowledge sharing across federation\nclients is achieved only through knowledge distillation on attention maps\ngenerated by the local ViT models, ensuring enhanced privacy preservation\ncompared to traditional parameter or synthetic image sharing methodologies.\nFedEvPrompt is optimized within a round-based learning paradigm, where each\nround involves training local models followed by attention maps sharing with\nall federation clients. Experimental validation conducted in a real distributed\nsetting, on the ISIC2019 dataset, demonstrates the superior performance of\nFedEvPrompt against baseline federated learning algorithms and knowledge\ndistillation methods, without sharing model parameters. In conclusion,\nFedEvPrompt offers a promising approach for federated learning, effectively\naddressing challenges such as data heterogeneity, imbalance, privacy\npreservation, and knowledge sharing.",
      "tldr_zh": "本研究提出FedEvPrompt，一种联邦学习方法，结合evidential deep learning、prompt tuning和knowledge distillation，用于分布式皮肤病变图像分类。该方法使用b-prompts（低级基本视觉知识）和t-prompts（任务特定知识）附加到冻结的预训练Vision Transformer (ViT)模型上，并在evidential learning框架中训练，以最大化类证据，同时通过知识蒸馏在注意力图上共享知识，确保隐私保护而不共享模型参数。在ISIC2019数据集的真实分布式实验中，FedEvPrompt优于基线联邦学习算法和知识蒸馏方法，有效解决了数据异质性、不平衡、隐私保护和知识共享等挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a conference paper at ICPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10071v1",
      "published_date": "2024-11-15 09:34:28 UTC",
      "updated_date": "2024-11-15 09:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:59:35.576920"
    },
    {
      "arxiv_id": "2411.10063v1",
      "title": "Federated Domain Generalization via Prompt Learning and Aggregation",
      "title_zh": "基于提示学习和聚合的联邦域泛化",
      "authors": [
        "Shuai Gong",
        "Chaoran Cui",
        "Chunyun Zhang",
        "Wenna Wang",
        "Xiushan Nie",
        "Lei Zhu"
      ],
      "abstract": "Federated domain generalization (FedDG) aims to improve the global model\ngeneralization in unseen domains by addressing data heterogeneity under\nprivacy-preserving constraints. A common strategy in existing FedDG studies\ninvolves sharing domain-specific knowledge among clients, such as spectrum\ninformation, class prototypes, and data styles. However, this knowledge is\nextracted directly from local client samples, and sharing such sensitive\ninformation poses a potential risk of data leakage, which might not fully meet\nthe requirements of FedDG. In this paper, we introduce prompt learning to adapt\npre-trained vision-language models (VLMs) in the FedDG scenario, and leverage\nlocally learned prompts as a more secure bridge to facilitate knowledge\ntransfer among clients. Specifically, we propose a novel FedDG framework\nthrough Prompt Learning and AggregatioN (PLAN), which comprises two training\nstages to collaboratively generate local prompts and global prompts at each\nfederated round. First, each client performs both text and visual prompt\nlearning using their own data, with local prompts indirectly synchronized by\nregarding the global prompts as a common reference. Second, all domain-specific\nlocal prompts are exchanged among clients and selectively aggregated into the\nglobal prompts using lightweight attention-based aggregators. The global\nprompts are finally applied to adapt VLMs to unseen target domains. As our PLAN\nframework requires training only a limited number of prompts and lightweight\naggregators, it offers notable advantages in computational and communication\nefficiency for FedDG. Extensive experiments demonstrate the superior\ngeneralization ability of PLAN across four benchmark datasets.",
      "tldr_zh": "该论文针对联邦域泛化（FedDG）问题，提出一种基于提示学习和聚合（PLAN）的框架，以在隐私保护约束下处理数据异质性并提升全局模型在新领域的泛化能力。PLAN 框架包括两个训练阶段：首先，每个客户端使用本地数据进行文本和视觉 prompt learning，并通过全局提示作为参考间接同步本地提示；其次，客户端交换并使用轻量级注意力-based 聚合器选择性地聚合本地提示生成全局提示。实验结果显示，PLAN 在四个基准数据集上表现出优越的泛化性能，同时显著提高了计算和通信效率。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2411.10063v1",
      "published_date": "2024-11-15 09:26:00 UTC",
      "updated_date": "2024-11-15 09:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:59:48.415902"
    },
    {
      "arxiv_id": "2411.10057v1",
      "title": "KuaiFormer: Transformer-Based Retrieval at Kuaishou",
      "title_zh": "翻译失败",
      "authors": [
        "Chi Liu",
        "Jiangxia Cao",
        "Rui Huang",
        "Kai Zheng",
        "Qiang Luo",
        "Kun Gai",
        "Guorui Zhou"
      ],
      "abstract": "In large-scale content recommendation systems, retrieval serves as the\ninitial stage in the pipeline, responsible for selecting thousands of candidate\nitems from billions of options to pass on to ranking modules. Traditionally,\nthe dominant retrieval method has been Embedding-Based Retrieval (EBR) using a\nDeep Neural Network (DNN) dual-tower structure. However, applying transformer\nin retrieval tasks has been the focus of recent research, though real-world\nindustrial deployment still presents significant challenges. In this paper, we\nintroduce KuaiFormer, a novel transformer-based retrieval framework deployed in\na large-scale content recommendation system. KuaiFormer fundamentally redefines\nthe retrieval process by shifting from conventional score estimation tasks\n(such as click-through rate estimate) to a transformer-driven Next Action\nPrediction paradigm. This shift enables more effective real-time interest\nacquisition and multi-interest extraction, significantly enhancing retrieval\nperformance. KuaiFormer has been successfully integrated into Kuaishou App's\nshort-video recommendation system since May 2024, serving over 400 million\ndaily active users and resulting in a marked increase in average daily usage\ntime of Kuaishou users. We provide insights into both the technical and\nbusiness aspects of deploying transformer in large-scale recommendation\nsystems, addressing practical challenges encountered during industrial\nimplementation. Our findings offer valuable guidance for engineers and\nresearchers aiming to leverage transformer models to optimize large-scale\ncontent recommendation systems.",
      "tldr_zh": "本文提出 KuaiFormer，一种基于 Transformer 的检索框架，用于 Kuaishou 的大规模内容推荐系统，将传统 Embedding-Based Retrieval (EBR) 的评分估计任务转变为 Next Action Prediction 范式，从而实现更有效的实时兴趣获取和多兴趣提取。相比传统的 Deep Neural Network (DNN) 双塔结构，KuaiFormer 显著提升了检索性能，并在 2024 年 5 月部署到 Kuaishou App 中，为超过 4 亿日活跃用户服务，导致用户平均每日使用时间明显增加。该框架的工业应用提供了宝贵的洞见，帮助工程师和研究人员优化大型推荐系统。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10057v1",
      "published_date": "2024-11-15 09:20:46 UTC",
      "updated_date": "2024-11-15 09:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T00:59:59.645591"
    },
    {
      "arxiv_id": "2411.10055v1",
      "title": "Towards unearthing neglected climate innovations from scientific literature using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "César Quilodrán-Casas",
        "Christopher Waite",
        "Nicole Alhadeff",
        "Diyona Dsouza",
        "Cathal Hughes",
        "Larissa Kunstel-Tabet",
        "Alyssa Gilbert"
      ],
      "abstract": "Climate change poses an urgent global threat, needing the rapid\nidentification and deployment of innovative solutions. We hypothesise that many\nof these solutions already exist within scientific literature but remain\nunderutilised. To address this gap, this study employs a curated dataset\nsourced from OpenAlex, a comprehensive repository of scientific papers.\nUtilising Large Language Models (LLMs), such as GPT4-o from OpenAI, we evaluate\ntitle-abstract pairs from scientific papers on seven dimensions, covering\nclimate change mitigation potential, stage of technological development, and\nreadiness for deployment. The outputs of the language models are then compared\nwith human evaluations to assess their effectiveness in identifying promising\nyet overlooked climate innovations. Our findings suggest that these LLM-based\nmodels can effectively augment human expertise, uncovering climate solutions\nthat are potentially impactful but with far greater speed, throughput and\nconsistency. Here, we focused on UK-based solutions, but the workflow is\nregion-agnostic. This work contributes to the discovery of neglected\ninnovations in scientific literature and demonstrates the potential of AI in\nenhancing climate action strategies.",
      "tldr_zh": "这篇论文探讨了利用 Large Language Models (LLMs) 如 GPT-4o 从科学文献中挖掘被忽略的气候创新解决方案，以应对气候变化的全球威胁。研究基于 OpenAlex 数据集，对科学论文的标题-摘要对进行七个维度的评估，包括气候变化缓解潜力、技术发展阶段和部署准备度，并将 LLMs 输出与人类评估进行比较。结果显示，LLMs 能有效增强人类专业知识，提供更快速、一致的识别过程，焦点虽在英国解决方案，但工作流程可适用于其他区域。该工作为发现科学文献中的 neglected innovations 提供了新途径，并展示了 AI 在气候行动策略中的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages. Accepted in the LatinX in AI workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10055v1",
      "published_date": "2024-11-15 09:17:40 UTC",
      "updated_date": "2024-11-15 09:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:00:12.387743"
    },
    {
      "arxiv_id": "2411.10053v1",
      "title": "That Chip Has Sailed: A Critique of Unfounded Skepticism Around AI for Chip Design",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Goldie",
        "Azalia Mirhoseini",
        "Jeff Dean"
      ],
      "abstract": "In 2020, we introduced a deep reinforcement learning method capable of\ngenerating superhuman chip layouts, which we then published in Nature and\nopen-sourced on GitHub. AlphaChip has inspired an explosion of work on AI for\nchip design, and has been deployed in state-of-the-art chips across Alphabet\nand extended by external chipmakers. Even so, a non-peer-reviewed invited paper\nat ISPD 2023 questioned its performance claims, despite failing to run our\nmethod as described in Nature. For example, it did not pre-train the RL method\n(removing its ability to learn from prior experience), used substantially fewer\ncompute resources (20x fewer RL experience collectors and half as many GPUs),\ndid not train to convergence (standard practice in machine learning), and\nevaluated on test cases that are not representative of modern chips. Recently,\nIgor Markov published a meta-analysis of three papers: our peer-reviewed Nature\npaper, the non-peer-reviewed ISPD paper, and Markov's own unpublished paper\n(though he does not disclose that he co-authored it). Although AlphaChip has\nalready achieved widespread adoption and impact, we publish this response to\nensure that no one is wrongly discouraged from innovating in this impactful\narea.",
      "tldr_zh": "本论文是对AI在芯片设计领域应用的批评进行回应，作者维护了2020年发表在Nature上的AlphaChip方法，该方法使用深度强化学习生成超人性能的芯片布局，并已在Alphabet的芯片中部署和开源。批评主要来自ISPD 2023的一篇非同行评审论文，该论文未正确执行AlphaChip（如未预训练、资源不足和未达收敛），导致其性能评估不具代表性。作者进一步回应Igor Markov的元分析，强调这些质疑基于错误假设，并呼吁继续在这一高影响领域创新，以避免误导未来的研究。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10053v1",
      "published_date": "2024-11-15 09:11:10 UTC",
      "updated_date": "2024-11-15 09:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:00:23.307749"
    },
    {
      "arxiv_id": "2411.10050v1",
      "title": "Jal Anveshak: Prediction of fishing zones using fine-tuned LlaMa 2",
      "title_zh": "翻译失败",
      "authors": [
        "Arnav Mejari",
        "Maitreya Vaghulade",
        "Paarshva Chitaliya",
        "Arya Telang",
        "Lynette D'mello"
      ],
      "abstract": "In recent years, the global and Indian government efforts in monitoring and\ncollecting data related to the fisheries industry have witnessed significant\nadvancements. Despite this wealth of data, there exists an untapped potential\nfor leveraging artificial intelligence based technological systems to benefit\nIndian fishermen in coastal areas. To fill this void in the Indian technology\necosystem, the authors introduce Jal Anveshak. This is an application framework\nwritten in Dart and Flutter that uses a Llama 2 based Large Language Model\nfine-tuned on pre-processed and augmented government data related to fishing\nyield and availability. Its main purpose is to help Indian fishermen safely get\nthe maximum yield of fish from coastal areas and to resolve their fishing\nrelated queries in multilingual and multimodal ways.",
      "tldr_zh": "该研究介绍了 Jal Anveshak，一个基于 Dart 和 Flutter 构建的应用框架，旨在利用人工智能帮助印度沿海渔民。该框架使用 fine-tuned Llama 2 Large Language Model，对政府提供的渔业数据进行预处理和增强，以预测渔场位置并最大化鱼获量。Jal Anveshak 支持多语言和多模式查询响应，提升渔民的安全性和效率，为印度渔业技术生态填补了空白。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10050v1",
      "published_date": "2024-11-15 09:05:03 UTC",
      "updated_date": "2024-11-15 09:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:00:35.117124"
    },
    {
      "arxiv_id": "2411.10048v1",
      "title": "Physics-informed neural networks need a physicist to be accurate: the case of mass and heat transport in Fischer-Tropsch catalyst particles",
      "title_zh": "翻译失败",
      "authors": [
        "Tymofii Nikolaienko",
        "Harshil Patel",
        "Aniruddha Panda",
        "Subodh Madhav Joshi",
        "Stanislav Jaso",
        "Kaushic Kalyanaraman"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as an influential\ntechnology, merging the swift and automated capabilities of machine learning\nwith the precision and dependability of simulations grounded in theoretical\nphysics. PINNs are often employed to solve algebraic or differential equations\nto replace some or even all steps of multi-stage computational workflows,\nleading to their significant speed-up. However, wide adoption of PINNs is still\nhindered by reliability issues, particularly at extreme ends of the input\nparameter ranges. In this study, we demonstrate this in the context of a system\nof coupled non-linear differential reaction-diffusion and heat transfer\nequations related to Fischer-Tropsch synthesis, which are solved by a\nfinite-difference method with a PINN used in evaluating their source terms. It\nis shown that the testing strategies traditionally used to assess the accuracy\nof neural networks as function approximators can overlook the peculiarities\nwhich ultimately cause instabilities of the finite-difference solver. We\npropose a domain knowledge-based modifications to the PINN architecture\nensuring its correct asymptotic behavior. When combined with an improved\nnumerical scheme employed as an initial guess generator, the proposed\nmodifications are shown to recover the overall stability of the simulations,\nwhile preserving the speed-up brought by PINN as the workflow component. We\ndiscuss the possible applications of the proposed hybrid transport equation\nsolver in context of chemical reactors simulations.",
      "tldr_zh": "本研究探讨了Physics-Informed Neural Networks (PINNs) 在处理Fischer-Tropsch合成中质量和热传输方程时的可靠性问题，发现传统测试策略无法捕捉导致有限差分求解器不稳定的特殊性。作者提出基于领域知识的PINN架构修改，确保其正确渐近行为，并结合改进的数值方案作为初始猜测生成器，从而恢复模拟稳定性，同时保持PINN带来的计算加速。实验结果显示，这种混合求解器在化学反应器模拟中具有潜在应用前景，提高了整体模拟的准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10048v1",
      "published_date": "2024-11-15 08:55:31 UTC",
      "updated_date": "2024-11-15 08:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:00:47.455830"
    },
    {
      "arxiv_id": "2411.10036v1",
      "title": "Rethinking Normalization Strategies and Convolutional Kernels for Multimodal Image Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Dan He",
        "Guofen Wang",
        "Weisheng Li",
        "Yucheng Shu",
        "Wenbo Li",
        "Lijian Yang",
        "Yuping Huang",
        "Feiyan Li"
      ],
      "abstract": "Multimodal image fusion (MMIF) aims to integrate information from different\nmodalities to obtain a comprehensive image, aiding downstream tasks. However,\nexisting methods tend to prioritize natural image fusion and focus on\ninformation complementary and network training strategies. They ignore the\nessential distinction between natural and medical image fusion and the\ninfluence of underlying components. This paper dissects the significant\ndifferences between the two tasks regarding fusion goals, statistical\nproperties, and data distribution. Based on this, we rethink the suitability of\nthe normalization strategy and convolutional kernels for end-to-end\nMMIF.Specifically, this paper proposes a mixture of instance normalization and\ngroup normalization to preserve sample independence and reinforce intrinsic\nfeature correlation.This strategy promotes the potential of enriching feature\nmaps, thus boosting fusion performance. To this end, we further introduce the\nlarge kernel convolution, effectively expanding receptive fields and enhancing\nthe preservation of image detail. Moreover, the proposed multipath adaptive\nfusion module recalibrates the decoder input with features of various scales\nand receptive fields, ensuring the transmission of crucial information.\nExtensive experiments demonstrate that our method exhibits state-of-the-art\nperformance in multiple fusion tasks and significantly improves downstream\napplications. The code is available at https://github.com/HeDan-11/LKC-FUNet.",
      "tldr_zh": "该论文重新审视了多模态图像融合（Multimodal Image Fusion, MMIF）中归一化策略和卷积核（Convolutional Kernels）的适用性，强调了自然图像和医疗图像在融合目标、统计属性及数据分布上的关键差异。作者提出了一种混合归一化策略（mixture of Instance Normalization and Group Normalization），结合大卷积核（large kernel convolution）和多路径自适应融合模块，以保留样本独立性、增强特征相关性，并扩大感受野从而更好地保留图像细节。实验结果表明，该方法在多种融合任务中实现了state-of-the-art性能，并显著提升了下游应用的效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10036v1",
      "published_date": "2024-11-15 08:36:24 UTC",
      "updated_date": "2024-11-15 08:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:01:01.120411"
    },
    {
      "arxiv_id": "2411.10032v1",
      "title": "VMID: A Multimodal Fusion LLM Framework for Detecting and Identifying Misinformation of Short Videos",
      "title_zh": "VMID：一种多模态融合LLM框架，用于检测和识别短视频虚假信息",
      "authors": [
        "Weihao Zhong",
        "Yinhao Xiao",
        "Minghui Xu",
        "Xiuzhen Cheng"
      ],
      "abstract": "Short video platforms have become important channels for news dissemination,\noffering a highly engaging and immediate way for users to access current events\nand share information. However, these platforms have also emerged as\nsignificant conduits for the rapid spread of misinformation, as fake news and\nrumors can leverage the visual appeal and wide reach of short videos to\ncirculate extensively among audiences. Existing fake news detection methods\nmainly rely on single-modal information, such as text or images, or apply only\nbasic fusion techniques, limiting their ability to handle the complex,\nmulti-layered information inherent in short videos. To address these\nlimitations, this paper presents a novel fake news detection method based on\nmultimodal information, designed to identify misinformation through a\nmulti-level analysis of video content. This approach effectively utilizes\ndifferent modal representations to generate a unified textual description,\nwhich is then fed into a large language model for comprehensive evaluation. The\nproposed framework successfully integrates multimodal features within videos,\nsignificantly enhancing the accuracy and reliability of fake news detection.\nExperimental results demonstrate that the proposed approach outperforms\nexisting models in terms of accuracy, robustness, and utilization of multimodal\ninformation, achieving an accuracy of 90.93%, which is significantly higher\nthan the best baseline model (SV-FEND) at 81.05%. Furthermore, case studies\nprovide additional evidence of the effectiveness of the approach in accurately\ndistinguishing between fake news, debunking content, and real incidents,\nhighlighting its reliability and robustness in real-world applications.",
      "tldr_zh": "本文提出VMID框架，这是一个多模态融合LLM（Large Language Model）方法，旨在检测和识别短视频中的假新闻问题。该框架通过多级别分析视频内容，融合文本、图像等模态信息生成统一的文本描述，然后输入LLM进行综合评估，从而提升检测的准确性和可靠性。实验结果显示，VMID的准确率达到90.93%，比最佳基线模型SV-FEND的81.05%高出显著优势，并在案例研究中证明了其在区分假新闻、辟谣内容和真实事件方面的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2211.10973 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2411.10032v1",
      "published_date": "2024-11-15 08:20:26 UTC",
      "updated_date": "2024-11-15 08:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:01:12.345112"
    },
    {
      "arxiv_id": "2411.10028v2",
      "title": "MOT FCG++: Enhanced Representation of Spatio-temporal Motion and Appearance Features",
      "title_zh": "翻译失败",
      "authors": [
        "Yanzhao Fang"
      ],
      "abstract": "The goal of multi-object tracking (MOT) is to detect and track all objects in\na scene across frames, while maintaining a unique identity for each object.\nMost existing methods rely on the spatial-temporal motion features and\nappearance embedding features of the detected objects in consecutive frames.\nEffectively and robustly representing the spatial and appearance features of\nlong trajectories has become a critical factor affecting the performance of\nMOT. We propose a novel approach for appearance and spatial-temporal motion\nfeature representation, improving upon the hierarchical clustering association\nmethod MOT FCG. For spatialtemporal motion features, we first propose Diagonal\nModulated GIoU, which more accurately represents the relationship between the\nposition and shape of the objects. Second, Mean Constant Velocity Modeling is\nproposed to reduce the effect of observation noise on target motion state\nestimation. For appearance features, we utilize a dynamic appearance\nrepresentation that incorporates confidence information, enabling the\ntrajectory appearance features to be more robust and global. Based on the\nbaseline model MOT FCG, we have realized further improvements in the\nperformance of all. we achieved 63.1 HOTA, 76.9 MOTA and 78.2 IDF1 on the MOT17\ntest set, and also achieved competitive performance on the MOT20 and DanceTrack\nsets.",
      "tldr_zh": "这篇论文提出了 MOT FCG++ 方法，旨在提升多对象跟踪 (MOT) 中空间-时间运动特征和外观特征的表示，改进于基线模型 MOT FCG。针对运动特征，该方法引入 Diagonal Modulated GIoU 以更精确地捕捉对象的位置和形状关系，并采用 Mean Constant Velocity Modeling 来减少观察噪声对目标运动状态估计的影响；同时，对于外观特征，使用动态表示结合置信度信息，使轨迹特征更鲁棒和全局。在实验中，MOT FCG++ 在 MOT17 测试集上实现了 63.1 HOTA、76.9 MOTA 和 78.2 IDF1 的性能，并在 MOT20 和 DanceTrack 数据集上取得了竞争性结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10028v2",
      "published_date": "2024-11-15 08:17:05 UTC",
      "updated_date": "2024-11-21 07:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:01:24.341083"
    },
    {
      "arxiv_id": "2411.13578v1",
      "title": "COOD: Concept-based Zero-shot OOD Detection",
      "title_zh": "COOD：基于概念的零样本 OOD 检测",
      "authors": [
        "Zhendong Liu",
        "Yi Nian",
        "Henry Peng Zou",
        "Li Li",
        "Xiyang Hu",
        "Yue Zhao"
      ],
      "abstract": "How can models effectively detect out-of-distribution (OOD) samples in\ncomplex, multi-label settings without extensive retraining? Existing OOD\ndetection methods struggle to capture the intricate semantic relationships and\nlabel co-occurrences inherent in multi-label settings, often requiring large\namounts of training data and failing to generalize to unseen label\ncombinations. While large language models have revolutionized zero-shot OOD\ndetection, they primarily focus on single-label scenarios, leaving a critical\ngap in handling real-world tasks where samples can be associated with multiple\ninterdependent labels. To address these challenges, we introduce COOD, a novel\nzero-shot multi-label OOD detection framework. COOD leverages pre-trained\nvision-language models, enhancing them with a concept-based label expansion\nstrategy and a new scoring function. By enriching the semantic space with both\npositive and negative concepts for each label, our approach models complex\nlabel dependencies, precisely differentiating OOD samples without the need for\nadditional training. Extensive experiments demonstrate that our method\nsignificantly outperforms existing approaches, achieving approximately 95%\naverage AUROC on both VOC and COCO datasets, while maintaining robust\nperformance across varying numbers of labels and different types of OOD\nsamples.",
      "tldr_zh": "该论文提出COOD，一种基于概念的零-shot OOD检测框架，旨在解决多标签设置中模型难以捕捉复杂语义关系和标签共现的问题，而无需额外训练。COOD利用预训练的vision-language模型，通过concept-based label expansion策略和新的scoring function扩展语义空间，包括每个标签的正负概念，从而精确区分OOD样本。实验结果显示，该方法在VOC和COCO数据集上平均AUROC约95%，在不同标签数量和OOD类型上表现出色，显著优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13578v1",
      "published_date": "2024-11-15 08:15:48 UTC",
      "updated_date": "2024-11-15 08:15:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:01:35.280192"
    },
    {
      "arxiv_id": "2411.10015v1",
      "title": "MicroCrackAttentionNeXt: Advancing Microcrack Detection in Wave Field Analysis Using Deep Neural Networks through Feature Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Fatahlla Moreh",
        "Yusuf Hasan",
        "Bilal Zahid Hussain",
        "Mohammad Ammar",
        "Sven Tomforde"
      ],
      "abstract": "Micro Crack detection using deep neural networks (DNNs) through an automated\npipeline using wave fields interacting with the damaged areas is highly sought\nafter. These high-dimensional spatio-temporal crack data are limited, and these\ndatasets have large dimensions in the temporal domain. The dataset presents a\nsubstantial class imbalance, with crack pixels constituting an average of only\n5% of the total pixels per sample. This extreme class imbalance poses a\nchallenge for deep learning models with the different micro-scale cracks, as\nthe network can be biased toward predicting the majority class, generally\nleading to poor detection accuracy. This study builds upon the previous\nbenchmark SpAsE-Net, an asymmetric encoder-decoder network for micro-crack\ndetection. The impact of various activation and loss functions were examined\nthrough feature space visualization using the manifold discovery and analysis\n(MDA) algorithm. The optimized architecture and training methodology achieved\nan accuracy of 86.85%.",
      "tldr_zh": "本研究提出MicroCrackAttentionNeXt，一种基于深度神经网络(DNNs)的框架，用于提升波场分析中微裂纹检测的性能，针对数据集的类别不平衡（裂纹像素仅占5%）和高维时空特性等问题。构建于先前的SpAsE-Net不对称编码器-解码器网络，该方法通过流形发现和分析(MDA)算法进行特征空间可视化，优化了激活函数和损失函数以减少模型偏向。实验结果显示，该优化架构在微裂纹检测任务上达到了86.85%的准确率，显著改善了检测精度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10015v1",
      "published_date": "2024-11-15 07:50:01 UTC",
      "updated_date": "2024-11-15 07:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:01:47.800865"
    },
    {
      "arxiv_id": "2411.10010v1",
      "title": "DeepMedcast: A Deep Learning Method for Generating Intermediate Weather Forecasts among Multiple NWP Models",
      "title_zh": "DeepMedcast：一个深度学习方法，用于在多个 NWP 模型之间生成中间天气预报",
      "authors": [
        "Atsushi Kudo"
      ],
      "abstract": "Numerical weather prediction (NWP) centers around the world operate a variety\nof NWP models, and recent advances in AI-driven NWP models have increased the\navailability of diverse NWP outputs. While this expansion holds the potential\nto improve forecast accuracy, it also raises a critical challenge of\nidentifying the most reliable predictions for specific forecast scenarios.\nTraditional approaches, such as ensemble or weighted averaging, combine\nmultiple NWP outputs but often generate unrealistic atmospheric fields,\ncomplicating the production of reliable and consistent forecasts in operational\nsettings. In this study, we introduce DeepMedcast, a deep learning method that\ngenerates intermediate forecast, or \"medcast\", between two or more NWP outputs.\nUnlike ensemble averaging, DeepMedcast can provide consistent and explainable\nmedcast without distorting meteorological fields. This paper details the\nmethodology and case studies of DeepMedcast, discussing its advantages and\npotential contributions to operational forecasting.",
      "tldr_zh": "该研究针对多个数值天气预报 (NWP) 模型的输出整合问题，提出了一种深度学习方法 DeepMedcast，用于生成中间天气预报（medcast），以解决传统集成或加权平均方法可能导致不现实大气场的挑战。DeepMedcast 通过深度学习技术在两个或多个 NWP 输出之间创建一致且可解释的预测，避免扭曲气象场，从而提升预报的可靠性和准确性。论文详细阐述了该方法的原理、案例研究及其在操作预报中的潜在优势和贡献。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10010v1",
      "published_date": "2024-11-15 07:42:16 UTC",
      "updated_date": "2024-11-15 07:42:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:01:59.600178"
    },
    {
      "arxiv_id": "2411.10008v1",
      "title": "Graph-based Complexity for Causal Effect by Empirical Plug-in",
      "title_zh": "翻译失败",
      "authors": [
        "Rina Dechter",
        "Annie Raichev",
        "Alexander Ihler",
        "Jin Tian"
      ],
      "abstract": "This paper focuses on the computational complexity of computing empirical\nplug-in estimates for causal effect queries. Given a causal graph and\nobservational data, any identifiable causal query can be estimated from an\nexpression over the observed variables, called the estimand. The estimand can\nthen be evaluated by plugging in probabilities computed empirically from data.\nIn contrast to conventional wisdom, which assumes that high dimensional\nprobabilistic functions will lead to exponential evaluation time of the\nestimand. We show that computation can be done efficiently, potentially in time\nlinear in the data size, depending on the estimand's hypergraph.\n  In particular, we show that both the treewidth and hypertree width of the\nestimand's structure bound the evaluation complexity of the plug-in estimands,\nanalogous to their role in the complexity of probabilistic inference in\ngraphical models. Often, the hypertree width provides a more effective bound,\nsince the empirical distributions are sparse.",
      "tldr_zh": "本论文探讨了使用经验插值（empirical plug-in）估计因果效应查询的计算复杂度问题，通过给定因果图和观测数据，将可识别的因果查询转化为estimand表达式，并从观测变量中进行评估。论文挑战传统观点，证明了计算过程可以高效进行，可能线性于数据大小，这取决于estimand的超图结构。特别地，estimand的treewidth和hypertree width被证明会限制评估复杂度，与图形模型中的概率推理类似，其中hypertree width因经验分布的稀疏性提供了更有效的边界。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10008v1",
      "published_date": "2024-11-15 07:42:01 UTC",
      "updated_date": "2024-11-15 07:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:02:11.596784"
    },
    {
      "arxiv_id": "2411.10006v1",
      "title": "Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits",
      "title_zh": "Orca：通过整合人格特质增强大型语言模型的角色扮演能力",
      "authors": [
        "Yuxuan Huang"
      ],
      "abstract": "Large language models has catalyzed the development of personalized dialogue\nsystems, numerous role-playing conversational agents have emerged. While\nprevious research predominantly focused on enhancing the model's capability to\nfollow instructions by designing character profiles, neglecting the\npsychological factors that drive human conversations. In this paper, we propose\nOrca, a framework for data processing and training LLMs of custom characters by\nintegrating personality traits. Orca comprises four stages: (1) Personality\ntraits inferring, leverage LLMs to infer user's BigFive personality trait\nreports and scores. (2) Data Augment, simulate user's profile, background\nstory, and psychological activities. (3) Dataset construction,\npersonality-conditioned instruction prompting (PCIP) to stimulate LLMs. (4)\nModeling and Training, personality-conditioned instruction tuning (PTIT and\nPSIT), using the generated data to enhance existing open-source LLMs. We\nintroduce OrcaBench, the first benchmark for evaluating the quality of content\ngenerated by LLMs on social platforms across multiple scales. Our experiments\ndemonstrate that our proposed model achieves superior performance on this\nbenchmark, demonstrating its excellence and effectiveness in perceiving\npersonality traits that significantly improve role-playing abilities. Our Code\nis available at https://github.com/Aipura/Orca.",
      "tldr_zh": "本研究提出 Orca 框架，用于通过整合 BigFive 个性特质来提升大型语言模型 (LLMs) 的角色扮演能力。Orca 包括四个阶段：(1) Personality traits inferring，利用 LLMs 推断用户的个性特质报告；(2) Data Augment，模拟用户资料、背景故事和心理活动；(3) Dataset construction，通过 personality-conditioned instruction prompting (PCIP) 生成数据集；(4) Modeling and Training，使用 personality-conditioned instruction tuning (PTIT 和 PSIT) 训练模型。同时，论文引入 OrcaBench 基准，用于评估 LLMs 在社交平台上生成内容的质量。实验结果显示，Orca 框架显著提高了模型的角色扮演表现，证明了个性特质整合的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10006v1",
      "published_date": "2024-11-15 07:35:47 UTC",
      "updated_date": "2024-11-15 07:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:02:23.992822"
    },
    {
      "arxiv_id": "2411.10004v1",
      "title": "EyeDiff: text-to-image diffusion model improves rare eye disease diagnosis",
      "title_zh": "EyeDiff：文本到图像扩散模型改善罕见眼部疾病诊断",
      "authors": [
        "Ruoyu Chen",
        "Weiyi Zhang",
        "Bowen Liu",
        "Xiaolan Chen",
        "Pusheng Xu",
        "Shunming Liu",
        "Mingguang He",
        "Danli Shi"
      ],
      "abstract": "The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
      "tldr_zh": "本文提出 EyeDiff，一种基于 text-to-image diffusion model 的模型，用于从自然语言提示生成多模态眼科图像，以解决稀有眼部疾病诊断中的数据不足和不平衡问题。EyeDiff 利用先进的 latent diffusion model 训练于八个大型数据集，涵盖 14 种图像模式和超过 80 种眼部疾病，并成功适应十个多国家外部数据集。生成图像能准确捕捉病变特征，与文本提示高度一致，经客观指标和专家评估证实。整合这些图像后，显著提升了稀有疾病检测的准确性，优于传统 oversampling 方法，为眼科诊断模型的发展提供变革性解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "28 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.10004v1",
      "published_date": "2024-11-15 07:30:53 UTC",
      "updated_date": "2024-11-15 07:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:02:36.373818"
    },
    {
      "arxiv_id": "2411.10000v1",
      "title": "DuSEGO: Dual Second-order Equivariant Graph Ordinary Differential Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Yingxu Wang",
        "Nan Yin",
        "Mingyan Xiao",
        "Xinhao Yi",
        "Siwei Liu",
        "Shangsong Liang"
      ],
      "abstract": "Graph Neural Networks (GNNs) with equivariant properties have achieved\nsignificant success in modeling complex dynamic systems and molecular\nproperties. However, their expressiveness ability is limited by: (1) Existing\nmethods often overlook the over-smoothing issue caused by traditional GNN\nmodels, as well as the gradient explosion or vanishing problems in deep GNNs.\n(2) Most models operate on first-order information, neglecting that the real\nworld often consists of second-order systems, which further limits the model's\nrepresentation capabilities. To address these issues, we propose the\n\\textbf{Du}al \\textbf{S}econd-order \\textbf{E}quivariant \\textbf{G}raph\n\\textbf{O}rdinary Differential Equation (\\method{}) for equivariant\nrepresentation. Specifically, \\method{} apply the dual second-order equivariant\ngraph ordinary differential equations (Graph ODEs) on graph embeddings and node\ncoordinates, simultaneously. Theoretically, we first prove that \\method{}\nmaintains the equivariant property. Furthermore, we provide theoretical\ninsights showing that \\method{} effectively alleviates the over-smoothing\nproblem in both feature representation and coordinate update. Additionally, we\ndemonstrate that the proposed \\method{} mitigates the exploding and vanishing\ngradients problem, facilitating the training of deep multi-layer GNNs.\nExtensive experiments on benchmark datasets validate the superiority of the\nproposed \\method{} compared to baselines.",
      "tldr_zh": "本研究针对图神经网络（GNNs）的等变性（equivariant properties）在建模复杂动态系统和分子属性时的局限性，提出了DuSEGO框架，即双二阶等变图常微分方程（Dual Second-order Equivariant Graph Ordinary Differential Equation）。DuSEGO同时在图嵌入（graph embeddings）和节点坐标（node coordinates）上应用双二阶等变图ODEs，以解决传统GNNs的过平滑问题（over-smoothing）、梯度爆炸或消失问题（gradient explosion or vanishing），并提升对二阶系统的表示能力。理论上，该框架证明了其保持等变性（equivariant property），并有效缓解了特征表示和坐标更新的过平滑问题，同时便于训练深度多层GNNs。在基准数据集上的广泛实验显示，DuSEGO比基线模型表现出色，验证了其优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10000v1",
      "published_date": "2024-11-15 07:15:05 UTC",
      "updated_date": "2024-11-15 07:15:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:02:49.586127"
    },
    {
      "arxiv_id": "2411.09996v1",
      "title": "Building 6G Radio Foundation Models with Transformer Architectures",
      "title_zh": "使用 Transformer 架构构建 6G 无线电基础模型",
      "authors": [
        "Ahmed Aboulfotouh",
        "Ashkan Eshaghbeigi",
        "Hatem Abou-Zeid"
      ],
      "abstract": "Foundation deep learning (DL) models are general models, designed to learn\ngeneral, robust and adaptable representations of their target modality,\nenabling finetuning across a range of downstream tasks. These models are\npretrained on large, unlabeled datasets using self-supervised learning (SSL).\nFoundation models have demonstrated better generalization than traditional\nsupervised approaches, a critical requirement for wireless communications where\nthe dynamic environment demands model adaptability. In this work, we propose\nand demonstrate the effectiveness of a Vision Transformer (ViT) as a radio\nfoundation model for spectrogram learning. We introduce a Masked Spectrogram\nModeling (MSM) approach to pretrain the ViT in a self-supervised fashion. We\nevaluate the ViT-based foundation model on two downstream tasks: Channel State\nInformation (CSI)-based Human Activity sensing and Spectrogram Segmentation.\nExperimental results demonstrate competitive performance to supervised training\nwhile generalizing across diverse domains. Notably, the pretrained ViT model\noutperforms a four-times larger model that is trained from scratch on the\nspectrogram segmentation task, while requiring significantly less training\ntime, and achieves competitive performance on the CSI-based human activity\nsensing task. This work demonstrates the effectiveness of ViT with MSM for\npretraining as a promising technique for scalable foundation model development\nin future 6G networks.",
      "tldr_zh": "本文提出使用Vision Transformer (ViT)构建6G无线基础模型，通过Masked Spectrogram Modeling (MSM)进行自监督学习（SSL），以在大型未标注数据集上预训练模型，实现对无线通信动态环境的更好适应。实验评估显示，该模型在Channel State Information (CSI)-based人类活动感知和频谱图分割等下游任务上表现出色，与监督训练相比具有更强的泛化能力。特别地，预训练的ViT模型在频谱图分割任务上优于四倍大的从零训练模型，且训练时间显著减少，为未来6G网络的可扩展基础模型开发提供了高效技术。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09996v1",
      "published_date": "2024-11-15 07:01:44 UTC",
      "updated_date": "2024-11-15 07:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:03:01.916690"
    },
    {
      "arxiv_id": "2411.10496v1",
      "title": "Guided Learning: Lubricating End-to-End Modeling for Multi-stage Decision-making",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Guo",
        "Saizhuo Wang",
        "Yiyan Qi"
      ],
      "abstract": "Multi-stage decision-making is crucial in various real-world artificial\nintelligence applications, including recommendation systems, autonomous\ndriving, and quantitative investment systems. In quantitative investment, for\nexample, the process typically involves several sequential stages such as\nfactor mining, alpha prediction, portfolio optimization, and sometimes order\nexecution. While state-of-the-art end-to-end modeling aims to unify these\nstages into a single global framework, it faces significant challenges: (1)\ntraining such a unified neural network consisting of multiple stages between\ninitial inputs and final outputs often leads to suboptimal solutions, or even\ncollapse, and (2) many decision-making scenarios are not easily reducible to\nstandard prediction problems. To overcome these challenges, we propose Guided\nLearning, a novel methodological framework designed to enhance end-to-end\nlearning in multi-stage decision-making. We introduce the concept of a\n``guide'', a function that induces the training of intermediate neural network\nlayers towards some phased goals, directing gradients away from suboptimal\ncollapse. For decision scenarios lacking explicit supervisory labels, we\nincorporate a utility function that quantifies the ``reward'' of the throughout\ndecision. Additionally, we explore the connections between Guided Learning and\nclassic machine learning paradigms such as supervised, unsupervised,\nsemi-supervised, multi-task, and reinforcement learning. Experiments on\nquantitative investment strategy building demonstrate that guided learning\nsignificantly outperforms both traditional stage-wise approaches and existing\nend-to-end methods.",
      "tldr_zh": "该论文针对多阶段决策（如推荐系统、自动驾驶和量化投资）中的端到端建模挑战，提出Guided Learning框架，以解决训练次优或崩溃的问题。Guided Learning引入“guide”函数来引导中间神经网络层的训练，防止梯度崩溃，并使用utility function量化决策奖励，以处理缺少监督标签的场景。该框架还探讨了与supervised learning、unsupervised learning、semi-supervised learning、multi-task learning和reinforcement learning等经典范式的联系。实验结果显示，在量化投资策略构建中，Guided Learning显著优于传统阶段式方法和现有端到端方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10496v1",
      "published_date": "2024-11-15 06:54:25 UTC",
      "updated_date": "2024-11-15 06:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:03:13.757514"
    },
    {
      "arxiv_id": "2411.09986v2",
      "title": "Unlocking Transfer Learning for Open-World Few-Shot Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Byeonggeun Kim",
        "Juntae Lee",
        "Kyuhong Shim",
        "Simyung Chang"
      ],
      "abstract": "Few-Shot Open-Set Recognition (FSOSR) targets a critical real-world\nchallenge, aiming to categorize inputs into known categories, termed closed-set\nclasses, while identifying open-set inputs that fall outside these classes.\nAlthough transfer learning where a model is tuned to a given few-shot task has\nbecome a prominent paradigm in closed-world, we observe that it fails to expand\nto open-world. To unlock this challenge, we propose a two-stage method which\nconsists of open-set aware meta-learning with open-set free transfer learning.\nIn the open-set aware meta-learning stage, a model is trained to establish a\nmetric space that serves as a beneficial starting point for the subsequent\nstage. During the open-set free transfer learning stage, the model is further\nadapted to a specific target task through transfer learning. Additionally, we\nintroduce a strategy to simulate open-set examples by modifying the training\ndataset or generating pseudo open-set examples. The proposed method achieves\nstate-of-the-art performance on two widely recognized benchmarks, miniImageNet\nand tieredImageNet, with only a 1.5\\% increase in training effort. Our work\ndemonstrates the effectiveness of transfer learning in FSOSR.",
      "tldr_zh": "该研究针对 Few-Shot Open-Set Recognition (FSOSR) 的挑战，提出一种两阶段方法，以解锁迁移学习在开放世界中的应用。第一阶段通过 open-set aware meta-learning 训练模型，建立一个有利于后续适应的度量空间；第二阶段则进行 open-set free transfer learning，将模型细化到特定任务。此外，该方法引入模拟 open-set 示例的策略，如修改训练数据集或生成伪示例，最终在 miniImageNet 和 tieredImageNet 基准上实现最先进性能，仅增加 1.5% 的训练努力，证明了迁移学习在 FSOSR 中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09986v2",
      "published_date": "2024-11-15 06:43:49 UTC",
      "updated_date": "2025-05-03 16:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:03:24.901065"
    },
    {
      "arxiv_id": "2411.09972v1",
      "title": "Large Language Models as User-Agents for Evaluating Task-Oriented-Dialogue Systems",
      "title_zh": "大语言模型作为用户代理用于评估面向任务的对话系统",
      "authors": [
        "Taaha Kazi",
        "Ruiliang Lyu",
        "Sizhe Zhou",
        "Dilek Hakkani-Tur",
        "Gokhan Tur"
      ],
      "abstract": "Traditionally, offline datasets have been used to evaluate task-oriented\ndialogue (TOD) models. These datasets lack context awareness, making them\nsuboptimal benchmarks for conversational systems. In contrast, user-agents,\nwhich are context-aware, can simulate the variability and unpredictability of\nhuman conversations, making them better alternatives as evaluators. Prior\nresearch has utilized large language models (LLMs) to develop user-agents. Our\nwork builds upon this by using LLMs to create user-agents for the evaluation of\nTOD systems. This involves prompting an LLM, using in-context examples as\nguidance, and tracking the user-goal state. Our evaluation of diversity and\ntask completion metrics for the user-agents shows improved performance with the\nuse of better prompts. Additionally, we propose methodologies for the automatic\nevaluation of TOD models within this dynamic framework.",
      "tldr_zh": "本研究指出，传统任务导向对话 (TOD) 系统的评估依赖离线数据集，但这些数据集缺乏上下文感知，无法有效模拟真实对话的变异性。为此，作者使用 Large Language Models (LLMs) 作为用户代理，通过提示、in-context examples 指导和跟踪 user-goal state 来评估 TOD 系统。实验结果显示，使用优化提示能显著提升用户代理的多样性和任务完成度，并提出动态框架下的自动评估方法，为 TOD 系统评估提供更可靠的基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09972v1",
      "published_date": "2024-11-15 06:05:45 UTC",
      "updated_date": "2024-11-15 06:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:03:37.071205"
    },
    {
      "arxiv_id": "2411.09969v1",
      "title": "Steering AI-Driven Personalization of Scientific Text for General Audiences",
      "title_zh": "翻译失败",
      "authors": [
        "Taewook Kim",
        "Dhruv Agarwal",
        "Jordan Ackerman",
        "Manaswi Saha"
      ],
      "abstract": "Digital media platforms (e.g., social media, science blogs) offer\nopportunities to communicate scientific content to general audiences at scale.\nHowever, these audiences vary in their scientific expertise, literacy levels,\nand personal backgrounds, making effective science communication challenging.\nTo address this challenge, we designed TranSlider, an AI-powered tool that\ngenerates personalized translations of scientific text based on individual user\nprofiles (e.g., hobbies, location, and education). Our tool features an\ninteractive slider that allows users to steer the degree of personalization\nfrom 0 (weakly relatable) to 100 (strongly relatable), leveraging LLMs to\ngenerate the translations with given degrees. Through an exploratory study with\n15 participants, we investigated both the utility of these AI-personalized\ntranslations and how interactive reading features influenced users'\nunderstanding and reading experiences. We found that participants who preferred\nhigher degrees of personalization appreciated the relatable and contextual\ntranslations, while those who preferred lower degrees valued concise\ntranslations with subtle contextualization. Furthermore, participants reported\nthe compounding effect of multiple translations on their understanding of\nscientific content. Given these findings, we discuss several implications of\nAI-personalized translation tools in facilitating communication in\ncollaborative contexts.",
      "tldr_zh": "本研究针对科学内容向普通受众传播的挑战，提出 TranSlider，一种 AI 驱动工具，用于根据用户配置文件（如爱好、位置和教育水平）生成个性化的科学文本翻译。TranSlider 采用交互式滑块让用户调整个性化程度（从 0 表示弱相关到 100 表示强相关），并利用 LLMs 来动态生成翻译。通过一项涉及 15 名参与者的探索性研究，发现偏好高个性化用户更欣赏相关性和上下文化翻译，而偏好低个性化用户则青睐简洁的版本；此外，多重翻译能增强用户对科学内容的理解。研究讨论了此类 AI 工具在促进协作环境中沟通的潜在含义。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2411.09969v1",
      "published_date": "2024-11-15 05:55:23 UTC",
      "updated_date": "2024-11-15 05:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:03:50.476420"
    },
    {
      "arxiv_id": "2411.09968v1",
      "title": "Seeing Clearly by Layer Two: Enhancing Attention Heads to Alleviate Hallucination in LVLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaofeng Zhang",
        "Yihao Quan",
        "Chaochen Gu",
        "Chen Shen",
        "Xiaosong Yuan",
        "Shaotian Yan",
        "Hao Cheng",
        "Kaijie Wu",
        "Jieping Ye"
      ],
      "abstract": "The hallucination problem in multimodal large language models (MLLMs) remains\na common issue. Although image tokens occupy a majority of the input sequence\nof MLLMs, there is limited research to explore the relationship between image\ntokens and hallucinations. In this paper, we analyze the distribution of\nattention scores for image tokens across each layer and head of the model,\nrevealing an intriguing and common phenomenon: most hallucinations are closely\nlinked to the pattern of attention sinks in the self-attention matrix of image\ntokens, where shallow layers exhibit dense attention sinks and deeper layers\nshow sparse attention sinks. We further analyze the attention heads of\ndifferent layers and find that heads with high-density attention sink in the\nimage part play a positive role in alleviating hallucinations. In this paper,\nwe propose a training-free method named \\textcolor{red}{\\textbf{E}}nhancing\n\\textcolor{red}{\\textbf{A}}ttention \\textcolor{red}{\\textbf{H}}eads (EAH), an\napproach designed to enhance the convergence of image tokens attention sinks in\nthe shallow layers. EAH identifies the attention head that shows the vision\nsink in a shallow layer and extracts its attention matrix. This attention map\nis then broadcast to other heads in the layer, thereby strengthening the layer\nto pay more attention to the image itself. With extensive experiments, EAH\nshows significant hallucination-mitigating performance on different MLLMs and\nmetrics, proving its effectiveness and generality.",
      "tldr_zh": "这篇论文分析了多模态大语言模型(MLLMs)中图像标记的注意力分布，发现浅层注意力头存在密集的attention sinks，而这些现象与幻觉问题密切相关，高密度attention sinks的头在减轻幻觉方面发挥积极作用。作者提出了一种无训练方法Enhancing Attention Heads (EAH)，通过识别浅层中显示视觉陷阱的注意力头、提取其注意力矩阵并广播到层内其他头，从而增强模型对图像标记的关注。实验结果表明，EAH 在多种MLLMs和评估指标上显著降低了幻觉发生率，证明了其有效性和通用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09968v1",
      "published_date": "2024-11-15 05:51:29 UTC",
      "updated_date": "2024-11-15 05:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:04:01.446890"
    },
    {
      "arxiv_id": "2411.09955v2",
      "title": "Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh Tam Nguyen",
        "Zhao Ren",
        "Trinh Pham",
        "Thanh Trung Huynh",
        "Phi Le Nguyen",
        "Hongzhi Yin",
        "Quoc Viet Hung Nguyen"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) and multimodal learning\nhas transformed digital content creation and manipulation. Traditional visual\nediting tools require significant expertise, limiting accessibility. Recent\nstrides in instruction-based editing have enabled intuitive interaction with\nvisual content, using natural language as a bridge between user intent and\ncomplex editing operations. This survey provides an overview of these\ntechniques, focusing on how LLMs and multimodal models empower users to achieve\nprecise visual modifications without deep technical knowledge. By synthesizing\nover 100 publications, we explore methods from generative adversarial networks\nto diffusion models, examining multimodal integration for fine-grained content\ncontrol. We discuss practical applications across domains such as fashion, 3D\nscene manipulation, and video synthesis, highlighting increased accessibility\nand alignment with human intuition. Our survey compares existing literature,\nemphasizing LLM-empowered editing, and identifies key challenges to stimulate\nfurther research. We aim to democratize powerful visual editing across various\nindustries, from entertainment to education. Interested readers are encouraged\nto access our repository at\nhttps://github.com/tamlhp/awesome-instruction-editing.",
      "tldr_zh": "这篇调查综述探讨了大型语言模型(LLMs)和多模态学习如何提升图像和多媒体内容的指令引导编辑控制，解决了传统工具的专业门槛问题。通过自然语言指令，用户可以直观地实现精确视觉修改。作者综合了超过100篇文献，从生成对抗网络(GAN)到扩散模型，分析了多模态集成技术在时尚、3D场景操作和视频合成等领域的应用，提高了编辑的可访问性和与人类直觉的契合。调查强调了LLMs在编辑中的关键作用，识别了现有挑战，并呼吁进一步研究以促进视觉编辑在娱乐和教育等行业的民主化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Fixed a serious error in author information",
      "pdf_url": "http://arxiv.org/pdf/2411.09955v2",
      "published_date": "2024-11-15 05:18:15 UTC",
      "updated_date": "2024-11-21 05:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:04:13.202830"
    },
    {
      "arxiv_id": "2411.09952v1",
      "title": "GGAvatar: Reconstructing Garment-Separated 3D Gaussian Splatting Avatars from Monocular Video",
      "title_zh": "GGAvatar：从单目视频重建",
      "authors": [
        "Jingxuan Chen"
      ],
      "abstract": "Avatar modelling has broad applications in human animation and virtual\ntry-ons. Recent advancements in this field have focused on high-quality and\ncomprehensive human reconstruction but often overlook the separation of\nclothing from the body. To bridge this gap, this paper introduces GGAvatar\n(Garment-separated 3D Gaussian Splatting Avatar), which relies on monocular\nvideos. Through advanced parameterized templates and unique phased training,\nthis model effectively achieves decoupled, editable, and realistic\nreconstruction of clothed humans. Comparative evaluations with other costly\nmodels confirm GGAvatar's superior quality and efficiency in modelling both\nclothed humans and separable garments. The paper also showcases applications in\nclothing editing, as illustrated in Figure 1, highlighting the model's benefits\nand the advantages of effective disentanglement. The code is available at\nhttps://github.com/J-X-Chen/GGAvatar/.",
      "tldr_zh": "本论文提出 GGAvatar，一种从单目视频重建服装分离的 3D Gaussian Splatting 头像的方法，旨在解决现有模型忽略服装与身体分离的问题。通过高级参数化模板和独特的阶段化训练，该框架实现了解耦、可编辑且逼真的穿衣人类重建。与其他昂贵模型相比，GGAvatar 在建模质量和效率上表现出色，并展示了服装编辑等实际应用。代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "MMAsia'24 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2411.09952v1",
      "published_date": "2024-11-15 05:09:20 UTC",
      "updated_date": "2024-11-15 05:09:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:04:25.217937"
    },
    {
      "arxiv_id": "2411.09945v1",
      "title": "TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ding Li",
        "Ziqi Zhang",
        "Mengyu Yao",
        "Yifeng Cai",
        "Yao Guo",
        "Xiangqun Chen"
      ],
      "abstract": "Trusted Execution Environments (TEE) are used to safeguard on-device models.\nHowever, directly employing TEEs to secure the entire DNN model is challenging\ndue to the limited computational speed. Utilizing GPU can accelerate DNN's\ncomputation speed but commercial widely-available GPUs usually lack security\nprotection. To this end, scholars introduce TSDP, a method that protects\nprivacy-sensitive weights within TEEs and offloads insensitive weights to GPUs.\nNevertheless, current methods do not consider the presence of a knowledgeable\nadversary who can access abundant publicly available pre-trained models and\ndatasets. This paper investigates the security of existing methods against such\na knowledgeable adversary and reveals their inability to fulfill their security\npromises. Consequently, we introduce a novel partition before training\nstrategy, which effectively separates privacy-sensitive weights from other\ncomponents of the model. Our evaluation demonstrates that our approach can\noffer full model protection with a computational cost reduced by a factor of\n10. In addition to traditional CNN models, we also demonstrate the scalability\nto large language models. Our approach can compress the private functionalities\nof the large language model to lightweight slices and achieve the same level of\nprotection as the shielding-whole-model baseline.",
      "tldr_zh": "本论文提出TEESlice，一种新型策略，用于在Trusted Execution Environments (TEE)中保护敏感神经网络模型，针对攻击者拥有预训练模型和数据集的场景。现有方法如TSDP虽将隐私敏感权重置于TEE中并外包非敏感权重至GPU，但无法有效抵御知识丰富的攻击者。论文引入“partition before training”策略，通过在训练前分离隐私敏感权重，实现模型的安全分区。实验结果显示，该方法提供全模型保护，同时将计算成本降低10倍，并扩展适用于CNN和大型语言模型，将私有功能压缩为轻量级切片。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by TOSEM. Extended version of the S&P24 paper\n  (arXiv:2310.07152)",
      "pdf_url": "http://arxiv.org/pdf/2411.09945v1",
      "published_date": "2024-11-15 04:52:11 UTC",
      "updated_date": "2024-11-15 04:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:04:37.911167"
    },
    {
      "arxiv_id": "2411.09933v1",
      "title": "JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging",
      "title_zh": "JRadiEvo：通过模型合并的进化优化增强的日语放射学报告生成模型",
      "authors": [
        "Kaito Baba",
        "Ryota Yagi",
        "Junichiro Takahashi",
        "Risa Kishikawa",
        "Satoshi Kodera"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs), foundational\nmodels (FMs) have seen significant advancements. Healthcare is one of the most\ncrucial application areas for these FMs, given the significant time and effort\nrequired for physicians to analyze large volumes of patient data. Recent\nefforts have focused on adapting multimodal FMs to the medical domain through\ntechniques like instruction-tuning, leading to the development of medical\nfoundation models (MFMs). However, these approaches typically require large\namounts of training data to effectively adapt models to the medical field.\nMoreover, most existing models are trained on English datasets, limiting their\npracticality in non-English-speaking regions where healthcare professionals and\npatients are not always fluent in English. The need for translation introduces\nadditional costs and inefficiencies. To address these challenges, we propose a\n\\textbf{J}apanese \\textbf{Radi}ology report generation model enhanced by\n\\textbf{Evo}lutionary optimization of model merging (JRadiEvo). This is the\nfirst attempt to extend a non-medical vision-language foundation model to the\nmedical domain through evolutionary optimization of model merging. We\nsuccessfully created a model that generates accurate Japanese reports from\nX-ray images using only 50 translated samples from publicly available data.\nThis model, developed with highly efficient use of limited data, outperformed\nleading models from recent research trained on much larger datasets.\nAdditionally, with only 8 billion parameters, this relatively compact\nfoundation model can be deployed locally within hospitals, making it a\npractical solution for environments where APIs and other external services\ncannot be used due to strict privacy and security requirements.",
      "tldr_zh": "本研究提出 JRadiEvo，一种通过进化优化(model merging)的日语放射学报告生成模型，旨在解决大型语言模型(LLMs)和基础模型(FMs)在医疗领域的训练数据需求大和语言限制问题。\n该模型从非医疗视觉语言基础模型扩展到医疗领域，仅使用50个翻译样本，通过进化优化合并技术实现高效适应。\n实验结果显示，JRadiEvo 生成的日语放射报告准确性优于使用更大数据集训练的领先模型。\n此外，该模型参数仅8亿，能在医院本地部署，符合严格的隐私和安全要求。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS'24 Workshop on AIM-FM: Advancements In Medical\n  Foundation Models: Explainability, Robustness, Security, and Beyond",
      "pdf_url": "http://arxiv.org/pdf/2411.09933v1",
      "published_date": "2024-11-15 04:16:50 UTC",
      "updated_date": "2024-11-15 04:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:04:48.845503"
    },
    {
      "arxiv_id": "2411.09921v2",
      "title": "Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level",
      "title_zh": "基于运动的视频推理：像素级别的运动理解和感知",
      "authors": [
        "Andong Deng",
        "Tongjia Chen",
        "Shoubin Yu",
        "Taojiannan Yang",
        "Lincoln Spencer",
        "Yapeng Tian",
        "Ajmal Saeed Mian",
        "Mohit Bansal",
        "Chen Chen"
      ],
      "abstract": "In this paper, we introduce Motion-Grounded Video Reasoning, a new motion\nunderstanding task that requires generating visual answers (video segmentation\nmasks) according to the input question, and hence needs implicit spatiotemporal\nreasoning and grounding. This task extends existing spatiotemporal grounding\nwork focusing on explicit action/motion grounding, to a more general format by\nenabling implicit reasoning via questions. To facilitate the development of the\nnew task, we collect a large-scale dataset called GROUNDMORE, which comprises\n1,715 video clips, 249K object masks that are deliberately designed with 4\nquestion types (Causal, Sequential, Counterfactual, and Descriptive) for\nbenchmarking deep and comprehensive motion reasoning abilities. GROUNDMORE\nuniquely requires models to generate visual answers, providing a more concrete\nand visually interpretable response than plain texts. It evaluates models on\nboth spatiotemporal grounding and reasoning, fostering to address complex\nchallenges in motion-related video reasoning, temporal perception, and\npixel-level understanding. Furthermore, we introduce a novel baseline model\nnamed Motion-Grounded Video Reasoning Assistant (MORA). MORA incorporates the\nmultimodal reasoning ability from the Multimodal LLM, the pixel-level\nperception capability from the grounding model (SAM), and the temporal\nperception ability from a lightweight localization head. MORA achieves\nrespectable performance on GROUNDMORE outperforming the best existing visual\ngrounding baseline model by an average of 21.5% relatively. We hope this novel\nand challenging task will pave the way for future advancements in robust and\ngeneral motion understanding via video reasoning segmentation",
      "tldr_zh": "本文提出Motion-Grounded Video Reasoning任务，这是一种新颖的运动理解任务，要求模型根据输入问题生成视觉答案（如视频分割掩码），涉及隐式时空推理和grounding，从而扩展了传统显式动作grounding的范围。作者构建了大规模数据集GROUNDMORE，包含1,715个视频剪辑和249K对象掩码，设计了Causal、Sequential、Counterfactual和Descriptive四种问题类型，用于评估模型的深度运动推理、时空grounding和像素级理解能力。针对此任务，他们引入基线模型MORA，该模型整合Multimodal LLM的多模态推理能力、SAM的像素级感知能力和轻量级localization head的时间感知功能，在GROUNDMORE上平均性能比最佳现有visual grounding模型高出21.5%。这项工作有望推动视频推理分割领域的稳健运动理解进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.09921v2",
      "published_date": "2024-11-15 03:45:09 UTC",
      "updated_date": "2025-04-04 03:20:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:05:02.879770"
    },
    {
      "arxiv_id": "2411.09909v1",
      "title": "AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Janghwan Lee",
        "Jiwoong Park",
        "Jinseok Kim",
        "Yongjik Kim",
        "Jungju Oh",
        "Jinwook Oh",
        "Jungwook Choi"
      ],
      "abstract": "Scaling Large Language Models (LLMs) with extended context lengths has\nincreased the need for efficient low-bit quantization to manage their\nsubstantial computational demands. However, reducing precision to 4 bits\nfrequently degrades performance due to activation outliers. To address this, we\npropose Asymmetric Microscaling 4-bit Floating-Point (AMXFP4) for efficient LLM\ninference. This novel data format leverages asymmetric shared scales to\nmitigate outliers while naturally capturing the asymmetry introduced by\ngroup-wise quantization. Unlike conventional 4-bit quantization methods that\nrely on data rotation and costly calibration, AMXFP4 uses asymmetric shared\nscales for direct 4-bit casting, achieving near-ideal quantization accuracy\nacross various LLM tasks, including multi-turn conversations, long-context\nreasoning, and visual question answering. Our AMXFP4 format significantly\noutperforms MXFP4 and other leading quantization techniques, enabling robust,\ncalibration-free 4-bit inference.",
      "tldr_zh": "该研究针对大型语言模型(LLM)扩展上下文长度带来的计算需求，提出Asymmetric Microscaling 4-bit Floating-Point (AMXFP4)数据格式，以解决4位量化中激活异常值(activation outliers)导致的性能下降问题。AMXFP4通过不对称共享缩放(asymmetric shared scales)来缓解异常值并处理分组量化引入的不对称性，实现无需数据旋转和昂贵的校准的直接4位转换。实验结果显示，AMXFP4在多轮对话、长上下文推理和视觉问答等任务中显著优于MXFP4和其他量化技术，提供鲁棒且高效的4-bit LLM推理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09909v1",
      "published_date": "2024-11-15 03:11:19 UTC",
      "updated_date": "2024-11-15 03:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:05:13.318105"
    },
    {
      "arxiv_id": "2411.09900v1",
      "title": "Statistical Analysis of Policy Space Compression Problem",
      "title_zh": "政策空间压缩问题的统计分析",
      "authors": [
        "Majid Molaei",
        "Marcello Restelli",
        "Alberto Maria Metelli",
        "Matteo Papini"
      ],
      "abstract": "Policy search methods are crucial in reinforcement learning, offering a\nframework to address continuous state-action and partially observable problems.\nHowever, the complexity of exploring vast policy spaces can lead to significant\ninefficiencies. Reducing the policy space through policy compression emerges as\na powerful, reward-free approach to accelerate the learning process. This\ntechnique condenses the policy space into a smaller, representative set while\nmaintaining most of the original effectiveness. Our research focuses on\ndetermining the necessary sample size to learn this compressed set accurately.\nWe employ R\\'enyi divergence to measure the similarity between true and\nestimated policy distributions, establishing error bounds for good\napproximations. To simplify the analysis, we employ the $l_1$ norm, determining\nsample size requirements for both model-based and model-free settings. Finally,\nwe correlate the error bounds from the $l_1$ norm with those from R\\'enyi\ndivergence, distinguishing between policies near the vertices and those in the\nmiddle of the policy space, to determine the lower and upper bounds for the\nrequired sample sizes.",
      "tldr_zh": "该研究针对强化学习中策略搜索的效率问题，提出通过策略压缩（policy compression）来减少策略空间，从而加速学习过程，同时保持原有效果。作者使用 Rényi 散度来衡量真实和估计策略分布的相似性，并建立误差界；同时引入 l1 范数简化分析，确定模型-based 和模型-free 设置下所需的样本大小。最终，论文将 l1 范数误差界与 Rényi 散度相关联，根据策略在空间中的位置（如接近顶点或中间）给出样本大小的下限和上限，提供了一个更精确的统计框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09900v1",
      "published_date": "2024-11-15 02:46:55 UTC",
      "updated_date": "2024-11-15 02:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:05:25.658168"
    },
    {
      "arxiv_id": "2411.09891v1",
      "title": "Off-Dynamics Reinforcement Learning via Domain Adaptation and Reward Augmented Imitation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihong Guo",
        "Yixuan Wang",
        "Yuanyuan Shi",
        "Pan Xu",
        "Anqi Liu"
      ],
      "abstract": "Training a policy in a source domain for deployment in the target domain\nunder a dynamics shift can be challenging, often resulting in performance\ndegradation. Previous work tackles this challenge by training on the source\ndomain with modified rewards derived by matching distributions between the\nsource and the target optimal trajectories. However, pure modified rewards only\nensure the behavior of the learned policy in the source domain resembles\ntrajectories produced by the target optimal policies, which does not guarantee\noptimal performance when the learned policy is actually deployed to the target\ndomain. In this work, we propose to utilize imitation learning to transfer the\npolicy learned from the reward modification to the target domain so that the\nnew policy can generate the same trajectories in the target domain. Our\napproach, Domain Adaptation and Reward Augmented Imitation Learning (DARAIL),\nutilizes the reward modification for domain adaptation and follows the general\nframework of generative adversarial imitation learning from observation (GAIfO)\nby applying a reward augmented estimator for the policy optimization step.\nTheoretically, we present an error bound for our method under a mild assumption\nregarding the dynamics shift to justify the motivation of our method.\nEmpirically, our method outperforms the pure modified reward method without\nimitation learning and also outperforms other baselines in benchmark\noff-dynamics environments.",
      "tldr_zh": "这篇论文解决了Off-Dynamics Reinforcement Learning中的挑战，即训练策略在源域后部署到目标域时，由于动态变化导致性能下降。作者提出DARAIL方法，通过奖励修改实现域适应(Domain Adaptation)，并结合奖励增强估计器和生成对抗模仿学习从观察(GAIfO)框架，将源域策略转移到目标域以生成最优轨迹。理论上，该方法在动态变化的温和假设下提供了错误边界；实验结果显示，DARAIL在基准环境中优于纯奖励修改方法和其他基线，显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.09891v1",
      "published_date": "2024-11-15 02:35:20 UTC",
      "updated_date": "2024-11-15 02:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:05:37.173898"
    },
    {
      "arxiv_id": "2412.04473v1",
      "title": "Take Package as Language: Anomaly Detection Using Transformer",
      "title_zh": "将数据包视为语言：使用 Transformer 进行异常检测",
      "authors": [
        "Jie Huang"
      ],
      "abstract": "Network data packet anomaly detection faces numerous challenges, including\nexploring new anomaly supervision signals, researching weakly supervised\nanomaly detection, and improving model interpretability. This paper proposes\nNIDS-GPT, a GPT-based causal language model for network intrusion detection.\nUnlike previous work, NIDS-GPT innovatively treats each number in the packet as\nan independent \"word\" rather than packet fields, enabling a more fine-grained\ndata representation. We adopt an improved GPT-2 model and design special\ntokenizers and embedding layers to better capture the structure and semantics\nof network data. NIDS-GPT has good scalability, supports unsupervised\npre-training, and enhances model interpretability through attention weight\nvisualization. Experiments on the CICIDS2017 and car-hacking datasets show that\nNIDS-GPT achieves 100\\% accuracy under extreme imbalance conditions, far\nsurpassing traditional methods; it also achieves over 90\\% accuracy in one-shot\nlearning. These results demonstrate NIDS-GPT's excellent performance and\npotential in handling complex network anomaly detection tasks, especially in\ndata-imbalanced and resource-constrained scenarios. The code is available at\n\\url{https://github.com/woshixiaobai2019/nids-gpt.gi",
      "tldr_zh": "本文提出NIDS-GPT，一种基于Transformer的因果语言模型，用于网络数据包异常检测，通过将每个数字视为独立“词”而非字段，实现更细粒度的数据表示。模型采用改进的GPT-2，并设计专用标记器和嵌入层，支持无监督预训练，并通过注意力权重可视化提升可解释性。实验在CICIDS2017和car-hacking数据集上显示，NIDS-GPT在极端不平衡条件下达到100%准确率，在单样本学习中超过90%，远超传统方法，尤其适用于数据不平衡和资源受限场景。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.04473v1",
      "published_date": "2024-11-15 02:00:43 UTC",
      "updated_date": "2024-11-15 02:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:05:49.880514"
    },
    {
      "arxiv_id": "2411.09874v1",
      "title": "A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Chin-Sung Tung",
        "Sheng-Fu Liang",
        "Shu-Feng Chang",
        "Chung-Ping Young"
      ],
      "abstract": "Electroencephalography (EEG) plays a crucial role in the diagnosis of various\nneurological disorders. However, small hospitals and clinics often lack\nadvanced EEG signal analysis systems and are prone to misinterpretation in\nmanual EEG reading. This study proposes an innovative hybrid artificial\nintelligence (AI) system for automatic interpretation of EEG background\nactivity and report generation. The system combines deep learning models for\nposterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and\nexpert-designed algorithms for abnormality detection. For PDR prediction, 1530\nlabeled EEGs were used, and the best ensemble model achieved a mean absolute\nerror (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of\n91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI\nsystem significantly outperformed neurologists in detecting generalized\nbackground slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated\nimproved focal abnormality detection, although not statistically significant (p\n= 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset\nand the Temple University Abnormal EEG Corpus showed consistent performance\n(F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability.\nThe use of large language models (LLMs) for report generation demonstrated 100%\naccuracy, verified by three other independent LLMs. This hybrid AI system\nprovides an easily scalable and accurate solution for EEG interpretation in\nresource-limited settings, assisting neurologists in improving diagnostic\naccuracy and reducing misdiagnosis rates.",
      "tldr_zh": "本论文提出了一种混合人工智能（AI）系统，用于自动分析脑电图（EEG）背景活动并生成报告，以解决小医院资源不足和手动解读易出错的问题。该系统整合深度学习模型进行后优势节律（PDR）预测、无监督伪像去除，以及专家设计的算法检测异常；在1530个标记EEG数据集上，系统实现了MAE 0.237、RMSE 0.359和准确率91.8%（在0.6Hz误差内）。实验结果显示，AI在检测广义背景减慢时显著优于神经科医生（p=0.02，F1：AI 0.93 vs. 0.82），并在不同数据集上展现出良好的泛化性（F1分数分别为0.884和0.835）。此外，利用大型语言模型（LLMs）生成的报告达到100%准确率，为资源有限环境提供可扩展的EEG解读解决方案，提高诊断准确性和减少误诊。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "Example code available at https://github.com/tcs211/AI_EEEG_REPORT",
      "pdf_url": "http://arxiv.org/pdf/2411.09874v1",
      "published_date": "2024-11-15 01:49:17 UTC",
      "updated_date": "2024-11-15 01:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:06:04.146718"
    },
    {
      "arxiv_id": "2411.09852v2",
      "title": "InterFormer: Towards Effective Heterogeneous Interaction Learning for Click-Through Rate Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhichen Zeng",
        "Xiaolong Liu",
        "Mengyue Hang",
        "Xiaoyi Liu",
        "Qinghai Zhou",
        "Chaofei Yang",
        "Yiqun Liu",
        "Yichen Ruan",
        "Laming Chen",
        "Yuxin Chen",
        "Yujia Hao",
        "Jiaqi Xu",
        "Jade Nie",
        "Xi Liu",
        "Buyun Zhang",
        "Wei Wen",
        "Siyang Yuan",
        "Kai Wang",
        "Wen-Yen Chen",
        "Yiping Han",
        "Huayu Li",
        "Chunzhi Yang",
        "Bo Long",
        "Philip S. Yu",
        "Hanghang Tong",
        "Jiyan Yang"
      ],
      "abstract": "Click-through rate (CTR) prediction, which predicts the probability of a user\nclicking an ad, is a fundamental task in recommender systems. The emergence of\nheterogeneous information, such as user profile and behavior sequences, depicts\nuser interests from different aspects. A mutually beneficial integration of\nheterogeneous information is the cornerstone towards the success of CTR\nprediction. However, most of the existing methods suffer from two fundamental\nlimitations, including (1) insufficient inter-mode interaction due to the\nunidirectional information flow between modes, and (2) aggressive information\naggregation caused by early summarization, resulting in excessive information\nloss. To address the above limitations, we propose a novel module named\nInterFormer to learn heterogeneous information interaction in an interleaving\nstyle. To achieve better interaction learning, InterFormer enables\nbidirectional information flow for mutually beneficial learning across\ndifferent modes. To avoid aggressive information aggregation, we retain\ncomplete information in each data mode and use a separate bridging arch for\neffective information selection and summarization. Our proposed InterFormer\nachieves state-of-the-art performance on three public datasets and a\nlarge-scale industrial dataset.",
      "tldr_zh": "该论文针对点击率（CTR）预测任务，提出了一种新模块InterFormer，以有效学习异构信息（如用户资料和行为序列）的交互。该方法通过启用双向信息流动，实现不同模式间的互惠学习，避免了现有方法的单向信息流问题。同时，InterFormer保留每个数据模式的完整信息，并采用单独的桥梁架构进行信息选择和总结，从而减少早期聚合导致的信息丢失。在三个公共数据集和一个大规模工业数据集上，InterFormer实现了最先进性能，显著提升了CTR预测的准确性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.09852v2",
      "published_date": "2024-11-15 00:20:36 UTC",
      "updated_date": "2025-01-08 01:44:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:08:06.551986"
    },
    {
      "arxiv_id": "2411.09850v1",
      "title": "Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements",
      "title_zh": "通过整合精心设计的测量来增强扩散后验采样用于逆问题",
      "authors": [
        "Shijie Zhou",
        "Huaisheng Zhu",
        "Rohan Sharma",
        "Ruiyi Zhang",
        "Kaiyi Ji",
        "Changyou Chen"
      ],
      "abstract": "Diffusion models have emerged as a powerful foundation model for visual\ngeneration. With an appropriate sampling process, it can effectively serve as a\ngenerative prior to solve general inverse problems. Current posterior sampling\nbased methods take the measurement (i.e., degraded image sample) into the\nposterior sampling to infer the distribution of the target data (i.e., clean\nimage sample). However, in this manner, we show that high-frequency information\ncan be prematurely introduced during the early stages, which could induce\nlarger posterior estimate errors during the restoration sampling. To address\nthis issue, we first reveal that forming the log posterior gradient with the\nnoisy measurement ( i.e., samples from a diffusion forward process) instead of\nthe clean one can benefit the reverse process. Consequently, we propose a novel\ndiffusion posterior sampling method DPS-CM, which incorporates a Crafted\nMeasurement (i.e., samples generated by a reverse denoising process, compared\nto random sampling with noise in standard methods) to form the posterior\nestimate. This integration aims to mitigate the misalignment with the diffusion\nprior caused by cumulative posterior estimate errors. Experimental results\ndemonstrate that our approach significantly improves the overall capacity to\nsolve general and noisy inverse problems, such as Gaussian deblurring,\nsuper-resolution, inpainting, nonlinear deblurring, and tasks with Poisson\nnoise, relative to existing approaches.",
      "tldr_zh": "本文研究了如何通过整合Crafted Measurements来提升Diffusion Models在逆问题中的后验采样性能。当前方法在使用测量样本进行后验估计时，容易在早期阶段过早引入高频信息，导致估计错误；为此，作者提出DPS-CM方法，使用反向去噪过程生成的噪声样本代替随机噪声，形成更准确的log posterior gradient，以减少与扩散先验的不匹配。实验结果表明，该方法在Gaussian deblurring、super-resolution、inpainting以及非线性去模糊和Poisson噪声任务上，比现有方法显著提高了恢复性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09850v1",
      "published_date": "2024-11-15 00:06:57 UTC",
      "updated_date": "2024-11-15 00:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:06:25.281629"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 108,
  "processed_papers_count": 108,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T01:08:26.237781"
}