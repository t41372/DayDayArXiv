{
  "date": "2025-01-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-05 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的更新聚焦于 AI 模型的优化、安全性和应用扩展，包括语言模型的鲁棒性提升、不确定性量化技术，以及在医疗和生物领域的创新应用；亮点包括脑信号解码与文本生成、蛋白质设计扩散模型，以及多位知名学者（如 Wang 团队）参与的论文，这些工作可能推动 AI 在高风险领域的可靠性和实际部署。\n\n### AI 模型优化与安全\n这些论文探讨了语言模型的鲁棒性和安全机制，优先关注那些有潜在话题度和创新贡献的。\n- **从浅层模式到语义理解：基于对比集微调语言模型 (From Superficial Patterns to Semantic Understanding: Fine-Tuning Language Models on Contrast Sets)**：Daniel Petrov 等人的工作揭示了语言模型在对比集上的脆弱性，通过微调策略提升模型对复杂语言模式的鲁棒性，主要贡献是恢复模型在分布外数据的准确率至近 90%，强调了多样训练数据的重要性。\n- **从偶然不确定到认识不确定：探索 AI 中的不确定性量化技术 (From Aleatoric to Epistemic: Exploring Uncertainty Quantification Techniques in Artificial Intelligence)**：Tianyang Wang 等多位作者的综述区分了偶然不确定性和认识不确定性，讨论了概率方法、集成学习和生成模型的应用；关键发现是这些技术提升了 AI 在医疗和自动系统中的决策可靠性，并指出了可扩展性和解释性挑战。\n- **层级自暴露和修补：针对越狱攻击的肯定令牌缓解 (Layer-Level Self-Exposure and Patch: Affirmative Token Mitigation for Jailbreak Attack Defense)**：Yang Ouyang 等人提出 Layer-AdvPatcher 方法，通过自增强数据集修补特定层来防御越狱攻击，主要贡献是降低有害输出率，同时保持安全查询的性能。\n- **后门令牌遗忘：暴露和防御预训练语言模型中的后门 (Backdoor Token Unlearning: Exposing and Defending Backdoors in Pretrained Language Models)**：Peihai Jiang 等人开发了 BTU 框架，检测并消除嵌入层中的异常参数；主要发现是通过细粒度遗忘技术有效减少后门风险，而不影响主要任务性能。\n\n其他相关论文，如 **特质的领导者：通过社会语言建模预测用户影响水平 (Traits of a Leader: User Influence Level Prediction through Sociolinguistic Modeling)**（Denys Katerenchuk 等人，使用人口统计和个性数据提升影响预测准确性）和 **更坚固的文本，更智能的模型：提升对抗防御基准 (Tougher Text, Smarter Models: Raising the Bar for Adversarial Defence Benchmarks)**（Yang Wang 等人，建立全面基准测试对抗防御），快速掠过，它们扩展了模型鲁棒性但未有突破性创新。\n\n### 生物与医疗应用\n这些工作强调 AI 在蛋白质设计和医疗中的潜力，特别突出创新模型。\n- **从热力学到蛋白质设计：用于生物分子生成的扩散模型 (From thermodynamics to protein design: Diffusion models for biomolecule generation towards autonomous protein engineering)**：Wen-ran Li 等人综述了扩散模型（如 DDPM 和 SGM）在蛋白质生成中的应用，主要贡献是提出 E(3) 等变性策略，提升蛋白质设计的物理稳定性和自主工程潜力。\n- **LLM 帮助缓解脑信号中的跨主体变异性 (LLMs Help Alleviate the Cross-Subject Variability in Brain Signal and Language Alignment)**：Yifei Liu 等人使用 LLM 作为去噪代理，从 EEG 信号中提取主体无关语义特征；关键发现是提升了脑机接口的泛化性和鲁棒性。\n- **解码 fMRI 数据为标题：使用前缀语言建模 (Decoding fMRI Data into Captions using Prefix Language Modeling)**：Vyacheslav Shen 等人提出使用 DINOv2 和 GPT-2 模型，从 fMRI 信号预测图像嵌入；主要贡献是减少计算需求，同时改善跨模态对齐。\n- **衡琴-RA-v1：基于传统中医数据集的类风湿关节炎诊断 LLM (Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine)**：Yishen Liu 等人构建了首个针对中医的 RA 模型，使用 HQ-GCM-RA-C1 数据集；主要发现是超越部分中医从业者的诊断准确性。\n\n其他如 **基于掩码自动编码器的实验室值表示学习 (Representation Learning of Lab Values via Masked AutoEncoder)**（David Restrepo 等人，提升 EHR 数据插值公平性）和 **区块链与 AI 在 MedIoT 中的信任 (Trust and Dependability in Blockchain & AI Based MedIoT Applications)**，这些在医疗 AI 应用中提供补充，但未有重大突破，故从简。\n\n### 图像处理与高效计算\n快速聚焦高效框架和图像任务的论文。\n- **多聚合器时间扭曲异构图神经网络：用于个性化微视频推荐 (Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for Personalized Micro-Video Recommendation)**：Jinkun Han 等人提出 MTHGNN 模型，捕获用户偏好动态变化；主要贡献是提升微视频推荐的及时性和准确性。\n- **Tighnari：基于分层交叉注意力的多模态植物物种预测 (Tighnari: Multi-modal Plant Species Prediction Based on Hierarchical Cross-Attention Using Graph-Based and Vision Backbone-Extracted Features)**：Haixu Liu 等人使用分层交叉注意力融合多模态数据；关键发现是改善了生物多样性管理中的物种预测性能。\n- **高效的高分辨率视觉-语言模型架构 (Efficient Architectures for High Resolution Vision-Language Models)**：Miguel Carvalho 等人介绍 Pheye 框架，处理高分辨率图像细节；主要贡献是减少参数同时提升细粒度理解。\n\n其余如 **视频时刻检索的高效关键词注意 (Watch Video, Catch Keyword: Context-aware Keyword Attention for Moment Retrieval and Highlight Detection)**（Sung Jin Um 等人，提升视频查询准确性）和 **KM-UNet：用于医疗图像分割的 KAN Mamba UNet (KM-UNet KAN Mamba UNet for medical image segmentation)**，这些在图像分割和推荐中优化了效率，但非核心焦点，故简要提及。\n\n今天的更新总体上体现了 AI 向实际应用转型的趋势，总计 46 篇论文中，以 AI 安全和生物应用最具影响力。如果您对特定领域感兴趣，建议关注不确定性量化或脑信号解码相关工作！",
  "papers": [
    {
      "arxiv_id": "2501.02683v2",
      "title": "From Superficial Patterns to Semantic Understanding: Fine-Tuning Language Models on Contrast Sets",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Petrov"
      ],
      "abstract": "Large-scale pre-trained language models have demonstrated high performance on\nstandard datasets for natural language inference (NLI) tasks. Unfortunately,\nthese evaluations can be misleading, as although the models can perform well on\nin-distribution data, they perform poorly on out-of-distribution test sets,\nsuch as contrast sets. Contrast sets consist of perturbed instances of data\nthat have very minor, but meaningful, changes to the input that alter the gold\nlabel, revealing how models can learn superficial patterns in the training data\nrather than learning more sophisticated language nuances. As an example, the\nELECTRA-small language model achieves nearly 90% accuracy on an SNLI dataset\nbut drops to 75% when tested on an out-of-distribution contrast set. The\nresearch carried out in this study explores how the robustness of a language\nmodel can be improved by exposing it to small amounts of more complex contrast\nsets during training to help it better learn language patterns. With this\napproach, the model recovers performance and achieves nearly 90% accuracy on\ncontrast sets, highlighting the importance of diverse and challenging training\ndata.",
      "tldr_zh": "本研究揭示了大型预训练语言模型在自然语言推理（NLI）标准数据集上表现出色，但对分布外数据如 contrast sets 的性能显著下降，因为模型往往学习 superficial patterns 而非真正的 semantic understanding。例如，ELECTRA-small 在 SNLI 数据集上达到近 90% 准确率，但对比集上降至 75%。为了提升鲁棒性，研究通过在 fine-tuning 过程中引入少量更复杂的 contrast sets，帮助模型更好地学习语言模式。结果表明，这种方法使模型在 contrast sets 上恢复到近 90% 准确率，突出了使用多样化和具有挑战性的训练数据的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02683v2",
      "published_date": "2025-01-05 23:19:55 UTC",
      "updated_date": "2025-01-08 01:27:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:33:59.470750"
    },
    {
      "arxiv_id": "2501.03282v1",
      "title": "From Aleatoric to Epistemic: Exploring Uncertainty Quantification Techniques in Artificial Intelligence",
      "title_zh": "从 Aleator",
      "authors": [
        "Tianyang Wang",
        "Yunze Wang",
        "Jun Zhou",
        "Benji Peng",
        "Xinyuan Song",
        "Charles Zhang",
        "Xintian Sun",
        "Qian Niu",
        "Junyu Liu",
        "Silin Chen",
        "Keyu Chen",
        "Ming Li",
        "Pohsun Feng",
        "Ziqian Bi",
        "Ming Liu",
        "Yichao Zhang",
        "Cheng Fei",
        "Caitlyn Heqi Yin",
        "Lawrence KQ Yan"
      ],
      "abstract": "Uncertainty quantification (UQ) is a critical aspect of artificial\nintelligence (AI) systems, particularly in high-risk domains such as\nhealthcare, autonomous systems, and financial technology, where decision-making\nprocesses must account for uncertainty. This review explores the evolution of\nuncertainty quantification techniques in AI, distinguishing between aleatoric\nand epistemic uncertainties, and discusses the mathematical foundations and\nmethods used to quantify these uncertainties. We provide an overview of\nadvanced techniques, including probabilistic methods, ensemble learning,\nsampling-based approaches, and generative models, while also highlighting\nhybrid approaches that integrate domain-specific knowledge. Furthermore, we\nexamine the diverse applications of UQ across various fields, emphasizing its\nimpact on decision-making, predictive accuracy, and system robustness. The\nreview also addresses key challenges such as scalability, efficiency, and\nintegration with explainable AI, and outlines future directions for research in\nthis rapidly developing area. Through this comprehensive survey, we aim to\nprovide a deeper understanding of UQ's role in enhancing the reliability,\nsafety, and trustworthiness of AI systems.",
      "tldr_zh": "这篇综述探讨了人工智能(AI)中不确定性量化(UQ)技术的发展，区分了aleatoric（随机）和epistemic（知识相关）不确定性，并阐述了其数学基础和量化方法，包括概率方法、ensemble learning、sampling-based approaches、generative models以及整合领域知识的混合方法。论文概述了UQ在高风险领域如医疗、自动系统和金融中的应用，提升了决策、预测准确性和系统鲁棒性，同时强调其对AI可靠性和安全性的重要作用。最终，它指出了关键挑战如可扩展性、效率和与explainable AI的整合，并展望了未来研究方向，以进一步提升AI系统的可信度。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.03282v1",
      "published_date": "2025-01-05 23:14:47 UTC",
      "updated_date": "2025-01-05 23:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:33:49.896915"
    },
    {
      "arxiv_id": "2501.04046v1",
      "title": "Traits of a Leader: User Influence Level Prediction through Sociolinguistic Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Denys Katerenchuk",
        "Rivka Levitan"
      ],
      "abstract": "Recognition of a user's influence level has attracted much attention as human\ninteractions move online. Influential users have the ability to sway others'\nopinions to achieve some goals. As a result, predicting users' level of\ninfluence can help to understand social networks, forecast trends, prevent\nmisinformation, etc. However, predicting user influence is a challenging\nproblem because the concept of influence is specific to a situation or a\ndomain, and user communications are limited to text. In this work, we define\nuser influence level as a function of community endorsement and develop a model\nthat significantly outperforms the baseline by leveraging demographic and\npersonality data. This approach consistently improves RankDCG scores across\neight different domains.",
      "tldr_zh": "这篇论文探讨了通过社会语言学建模(Sociolinguistic Modeling)预测用户影响力的方法，以帮助理解社交网络、预测趋势和防止误信息。作者将用户影响级别定义为社区认可的函数，并开发了一个模型，利用人口统计和个性数据来提升预测准确性。该模型在八个不同领域中显著超过了基线，RankDCG 分数得到一致改善。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.04046v1",
      "published_date": "2025-01-05 22:37:19 UTC",
      "updated_date": "2025-01-05 22:37:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:34:02.094046"
    },
    {
      "arxiv_id": "2501.02680v1",
      "title": "From thermodynamics to protein design: Diffusion models for biomolecule generation towards autonomous protein engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Wen-ran Li",
        "Xavier F. Cadet",
        "David Medina-Ortiz",
        "Mehdi D. Davari",
        "Ramanathan Sowdhamini",
        "Cedric Damour",
        "Yu Li",
        "Alain Miranville",
        "Frederic Cadet"
      ],
      "abstract": "Protein design with desirable properties has been a significant challenge for\nmany decades. Generative artificial intelligence is a promising approach and\nhas achieved great success in various protein generation tasks. Notably,\ndiffusion models stand out for their robust mathematical foundations and\nimpressive generative capabilities, offering unique advantages in certain\napplications such as protein design. In this review, we first give the\ndefinition and characteristics of diffusion models and then focus on two\nstrategies: Denoising Diffusion Probabilistic Models and Score-based Generative\nModels, where DDPM is the discrete form of SGM. Furthermore, we discuss their\napplications in protein design, peptide generation, drug discovery, and\nprotein-ligand interaction. Finally, we outline the future perspectives of\ndiffusion models to advance autonomous protein design and engineering. The E(3)\ngroup consists of all rotations, reflections, and translations in\nthree-dimensions. The equivariance on the E(3) group can keep the physical\nstability of the frame of each amino acid as much as possible, and we reflect\non how to keep the diffusion model E(3) equivariant for protein generation.",
      "tldr_zh": "这篇评论文章回顾了扩散模型（Diffusion Models）在蛋白质设计中的应用，强调其在生成式人工智能中的优势，特别是通过Denoising Diffusion Probabilistic Models (DDPM) 和 Score-based Generative Models (SGM) 等策略来生成生物分子。论文首先定义了扩散模型的特点，并讨论了其在蛋白质设计、肽生成、药物发现以及蛋白-配体相互作用等领域的实际应用。最终，文章展望了未来发展，包括如何使扩散模型在 E(3) 群上保持等变性，以提升蛋白结构的物理稳定性和推进自主蛋白工程。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02680v1",
      "published_date": "2025-01-05 22:36:43 UTC",
      "updated_date": "2025-01-05 22:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:34:14.125858"
    },
    {
      "arxiv_id": "2501.02666v2",
      "title": "Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for Personalized Micro-Video Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinkun Han",
        "Wei Li",
        "Zhipeng Cai",
        "Yingshu Li"
      ],
      "abstract": "Micro-video recommendation is attracting global attention and becoming a\npopular daily service for people of all ages. Recently, Graph Neural\nNetworks-based micro-video recommendation has displayed performance improvement\nfor many kinds of recommendation tasks. However, the existing works fail to\nfully consider the characteristics of micro-videos, such as the high timeliness\nof news nature micro-video recommendation and sequential interactions of\nfrequently changed interests. In this paper, a novel Multi-aggregator\nTime-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed for\npersonalized news nature micro-video recommendation based on sequential\nsessions, where characteristics of micro-videos are comprehensively studied,\nusers' preference is mined via multi-aggregator, the temporal and dynamic\nchanges of users' preference are captured, and timeliness is considered.\nThrough the comparison with the state-of-the-arts, the experimental results\nvalidate the superiority of our MTHGNN model.",
      "tldr_zh": "该论文提出了一种名为Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network (MTHGNN)的模型，用于个性化新闻性质微视频推荐，旨在解决现有Graph Neural Networks (GNN)方法未充分考虑微视频的高时效性和顺序交互等特性的问题。MTHGNN通过多聚合器挖掘用户偏好，捕捉用户偏好的时间动态变化，并整合异构图神经网络来处理基于顺序会话的推荐任务。实验结果表明，该模型在微视频推荐性能上优于现有最先进方法，验证了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02666v2",
      "published_date": "2025-01-05 21:14:35 UTC",
      "updated_date": "2025-03-21 16:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:34:26.664219"
    },
    {
      "arxiv_id": "2501.02654v2",
      "title": "Tougher Text, Smarter Models: Raising the Bar for Adversarial Defence Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Wang",
        "Chenghua Lin"
      ],
      "abstract": "Recent advancements in natural language processing have highlighted the\nvulnerability of deep learning models to adversarial attacks. While various\ndefence mechanisms have been proposed, there is a lack of comprehensive\nbenchmarks that evaluate these defences across diverse datasets, models, and\ntasks. In this work, we address this gap by presenting an extensive benchmark\nfor textual adversarial defence that significantly expands upon previous work.\nOur benchmark incorporates a wide range of datasets, evaluates state-of-the-art\ndefence mechanisms, and extends the assessment to include critical tasks such\nas single-sentence classification, similarity and paraphrase identification,\nnatural language inference, and commonsense reasoning. This work not only\nserves as a valuable resource for researchers and practitioners in the field of\nadversarial robustness but also identifies key areas for future research in\ntextual adversarial defence. By establishing a new standard for benchmarking in\nthis domain, we aim to accelerate progress towards more robust and reliable\nnatural language processing systems.",
      "tldr_zh": "这篇论文强调了自然语言处理(NLP)模型对对抗攻击(adversarial attacks)的脆弱性，并指出现有防御机制(defence mechanisms)缺乏全面基准评估。研究者提出一个扩展的基准测试，涵盖多样化的数据集、模型和任务，包括单句分类(single-sentence classification)、相似性和改写识别(similarity and paraphrase identification)、自然语言推理(natural language inference)以及常识推理(commonsense reasoning)。通过评估最先进的防御机制，该基准不仅为研究者和从业者提供宝贵资源，还识别了未来研究的重点领域，最终旨在提升NLP系统的鲁棒性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Will be presented as an oral in-person presentation at the conference\n  of COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.02654v2",
      "published_date": "2025-01-05 20:39:52 UTC",
      "updated_date": "2025-01-08 14:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:34:37.976780"
    },
    {
      "arxiv_id": "2501.02649v1",
      "title": "Tighnari: Multi-modal Plant Species Prediction Based on Hierarchical Cross-Attention Using Graph-Based and Vision Backbone-Extracted Features",
      "title_zh": "翻译失败",
      "authors": [
        "Haixu Liu",
        "Penghao Jiang",
        "Zerui Tao",
        "Muyan Wan",
        "Qiuzhuang Sun"
      ],
      "abstract": "Predicting plant species composition in specific spatiotemporal contexts\nplays an important role in biodiversity management and conservation, as well as\nin improving species identification tools. Our work utilizes 88,987 plant\nsurvey records conducted in specific spatiotemporal contexts across Europe. We\nalso use the corresponding satellite images, time series data, climate time\nseries, and other rasterized environmental data such as land cover, human\nfootprint, bioclimatic, and soil variables as training data to train the model\nto predict the outcomes of 4,716 plant surveys. We propose a feature\nconstruction and result correction method based on the graph structure. Through\ncomparative experiments, we select the best-performing backbone networks for\nfeature extraction in both temporal and image modalities. In this process, we\nbuilt a backbone network based on the Swin-Transformer Block for extracting\ntemporal Cubes features. We then design a hierarchical cross-attention\nmechanism capable of robustly fusing features from multiple modalities. During\ntraining, we adopt a 10-fold cross-fusion method based on fine-tuning and use a\nThreshold Top-K method for post-processing. Ablation experiments demonstrate\nthe improvements in model performance brought by our proposed solution\npipeline.",
      "tldr_zh": "本研究提出Tighnari模型，用于预测特定时空背景下的植物物种组成，支持生物多样性管理和保护。模型利用88,987条欧洲植物调查记录、卫星图像、时间序列数据、气候数据等多模态数据进行训练，结合基于图结构的特征构建方法和视觉骨干网络（如Swin-Transformer Block）提取特征。核心创新是设计分层交叉注意力(hierarchical cross-attention)机制来融合多模态特征，并采用10折交叉融合和Threshold Top-K后处理方法。消融实验显示，该方法显著提高了模型性能，在预测4,716个植物调查结果时取得了更好的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR GeolifeCLEF",
      "pdf_url": "http://arxiv.org/pdf/2501.02649v1",
      "published_date": "2025-01-05 20:30:07 UTC",
      "updated_date": "2025-01-05 20:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:34:50.589418"
    },
    {
      "arxiv_id": "2501.02648v2",
      "title": "Representation Learning of Lab Values via Masked AutoEncoder",
      "title_zh": "通过 Masked",
      "authors": [
        "David Restrepo",
        "Chenwei Wu",
        "Yueran Jia",
        "Jaden K. Sun",
        "Jack Gallifant",
        "Catherine G. Bielick",
        "Yugang Jia",
        "Leo A. Celi"
      ],
      "abstract": "Accurate imputation of missing laboratory values in electronic health records\n(EHRs) is critical to enable robust clinical predictions and reduce biases in\nAI systems in healthcare. Existing methods, such as variational autoencoders\n(VAEs) and decision tree-based approaches such as XGBoost, struggle to model\nthe complex temporal and contextual dependencies in EHR data, mainly in\nunderrepresented groups. In this work, we propose Lab-MAE, a novel\ntransformer-based masked autoencoder framework that leverages self-supervised\nlearning for the imputation of continuous sequential lab values. Lab-MAE\nintroduces a structured encoding scheme that jointly models laboratory test\nvalues and their corresponding timestamps, enabling explicit capturing temporal\ndependencies. Empirical evaluation on the MIMIC-IV dataset demonstrates that\nLab-MAE significantly outperforms the state-of-the-art baselines such as\nXGBoost across multiple metrics, including root mean square error (RMSE),\nR-squared (R2), and Wasserstein distance (WD). Notably, Lab-MAE achieves\nequitable performance across demographic groups of patients, advancing fairness\nin clinical predictions. We further investigate the role of follow-up\nlaboratory values as potential shortcut features, revealing Lab-MAE's\nrobustness in scenarios where such data is unavailable. The findings suggest\nthat our transformer-based architecture, adapted to the characteristics of the\nEHR data, offers a foundation model for more accurate and fair clinical\nimputation models. In addition, we measure and compare the carbon footprint of\nLab-MAE with the baseline XGBoost model, highlighting its environmental\nrequirements.",
      "tldr_zh": "该研究提出了一种名为 Lab-MAE 的 transformer-based masked autoencoder 框架，利用 self-supervised learning 来实现电子健康记录 (EHRs) 中缺失实验室值的准确 imputation。Lab-MAE 通过结构化的编码方案联合建模实验室值及其时间戳，从而更好地捕捉复杂的时间和上下文依赖。实验在 MIMIC-IV 数据集上显示，Lab-MAE 在 RMSE、R2 和 Wasserstein distance 等指标上显著优于基线模型如 XGBoost，并在不同人口群体中实现了公平性能，同时探讨了后续实验室值作为潜在 shortcut features 的影响，并比较了其碳足迹。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages main text, 8 appendix",
      "pdf_url": "http://arxiv.org/pdf/2501.02648v2",
      "published_date": "2025-01-05 20:26:49 UTC",
      "updated_date": "2025-01-09 11:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:35:02.811030"
    },
    {
      "arxiv_id": "2501.02647v1",
      "title": "Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Ellis Solaiman",
        "Christa Awad"
      ],
      "abstract": "This paper critically reviews the integration of Artificial Intelligence (AI)\nand blockchain technologies in the context of Medical Internet of Things\n(MedIoT) applications, where they collectively promise to revolutionize\nhealthcare delivery. By examining current research, we underscore AI's\npotential in advancing diagnostics and patient care, alongside blockchain's\ncapacity to bolster data security and patient privacy. We focus particularly on\nthe imperative to cultivate trust and ensure reliability within these systems.\nOur review highlights innovative solutions for managing healthcare data and\nchallenges such as ensuring scalability, maintaining privacy, and promoting\nethical practices within the MedIoT domain. We present a vision for integrating\nAI-driven insights with blockchain security in healthcare, offering a\ncomprehensive review of current research and future directions. We conclude\nwith a set of identified research gaps and propose that addressing these is\ncrucial for achieving the dependable, secure, and patient -centric MedIoT\napplications of tomorrow.",
      "tldr_zh": "本论文审视了人工智能(AI)和区块链技术在医疗物联网(MedIoT)应用中的整合，强调这些技术如何提升诊断、患者护理、数据安全和隐私，从而革新医疗服务。作者通过分析现有研究，突出了构建信任和可靠性的关键需求，并讨论了挑战如系统可扩展性、隐私保护和伦理实践的创新解决方案。论文提出了将AI洞见与区块链安全相结合的愿景，并指出了未来研究空白，以推动开发可靠、以患者为中心的MedIoT应用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02647v1",
      "published_date": "2025-01-05 20:21:22 UTC",
      "updated_date": "2025-01-05 20:21:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:35:13.610761"
    },
    {
      "arxiv_id": "2501.02629v2",
      "title": "Layer-Level Self-Exposure and Patch: Affirmative Token Mitigation for Jailbreak Attack Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Ouyang",
        "Hengrui Gu",
        "Shuhang Lin",
        "Wenyue Hua",
        "Jie Peng",
        "Bhavya Kailkhura",
        "Meijun Gao",
        "Tianlong Chen",
        "Kaixiong Zhou"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in diverse\napplications, including chatbot assistants and code generation, aligning their\nbehavior with safety and ethical standards has become paramount. However,\njailbreak attacks, which exploit vulnerabilities to elicit unintended or\nharmful outputs, threaten LLMs' safety significantly. In this paper, we\nintroduce Layer-AdvPatcher, a novel methodology designed to defend against\njailbreak attacks by utilizing an unlearning strategy to patch specific layers\nwithin LLMs through self-augmented datasets. Our insight is that certain\nlayer(s), tend to produce affirmative tokens when faced with harmful prompts.\nBy identifying these layers and adversarially exposing them to generate more\nharmful data, one can understand their inherent and diverse vulnerabilities to\nattacks. With these exposures, we then \"unlearn\" these issues, reducing the\nimpact of affirmative tokens and hence minimizing jailbreak risks while keeping\nthe model's responses to safe queries intact. We conduct extensive experiments\non two models, four benchmark datasets, and multiple state-of-the-art jailbreak\nattacks to demonstrate the efficacy of our approach. Results indicate that our\nframework reduces the harmfulness and attack success rate of jailbreak attacks\nwithout compromising utility for benign queries compared to recent defense\nmethods. Our code is publicly available at:\nhttps://github.com/oyy2000/LayerAdvPatcher",
      "tldr_zh": "本研究提出Layer-AdvPatcher，一种创新的unlearning策略，用于防御大型语言模型(LLMs)面对jailbreak attacks时的漏洞。该方法通过识别易产生affirmative tokens的特定层，进行层级自我暴露生成更多有害数据，然后针对这些层进行修复，从而减少模型对有害提示的响应，同时保持对安全查询的正常性能。在多个模型、基准数据集和先进攻击实验中，Layer-AdvPatcher显著降低了攻击成功率和有害输出风险，证明了其有效性，且相关代码已开源。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages, 4 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2501.02629v2",
      "published_date": "2025-01-05 19:06:03 UTC",
      "updated_date": "2025-02-12 04:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:35:25.518848"
    },
    {
      "arxiv_id": "2501.02628v1",
      "title": "Cracks in The Stack: Hidden Vulnerabilities and Licensing Risks in LLM Pre-Training Datasets",
      "title_zh": "Cracks in The Stack：LLM 预训练数据集中的隐藏漏洞和许可风险",
      "authors": [
        "Mahmoud Jahanshahi",
        "Audris Mockus"
      ],
      "abstract": "A critical part of creating code suggestion systems is the pre-training of\nLarge Language Models on vast amounts of source code and natural language text,\noften of questionable origin or quality. This may contribute to the presence of\nbugs and vulnerabilities in code generated by LLMs. While efforts to identify\nbugs at or after code generation exist, it is preferable to pre-train or\nfine-tune LLMs on curated, high-quality, and compliant datasets. The need for\nvast amounts of training data necessitates that such curation be automated,\nminimizing human intervention.\n  We propose an automated source code autocuration technique that leverages the\ncomplete version history of open-source software projects to improve the\nquality of training data. This approach leverages the version history of all\nOSS projects to identify training data samples that have been modified or have\nundergone changes in at least one OSS project, and pinpoint a subset of samples\nthat include fixes for bugs or vulnerabilities. We evaluate this method using\nThe Stack v2 dataset, and find that 17% of the code versions in the dataset\nhave newer versions, with 17% of those representing bug fixes, including 2.36%\naddressing known CVEs. The deduplicated version of Stack v2 still includes\nblobs vulnerable to 6,947 known CVEs. Furthermore, 58% of the blobs in the\ndataset were never modified after creation, suggesting they likely represent\nsoftware with minimal or no use. Misidentified blob origins present an\nadditional challenge, as they lead to the inclusion of non-permissively\nlicensed code, raising serious compliance concerns.\n  By addressing these issues, the training of new models can avoid perpetuating\nbuggy code patterns or license violations. We expect our results to inspire\nprocess improvements for automated data curation, with the potential to enhance\nthe reliability of outputs generated by AI tools.",
      "tldr_zh": "这篇论文揭示了LLM预训练数据集（如The Stack v2）中隐藏的漏洞和许可风险，这些问题可能导致AI生成的代码包含bugs或非合规代码。作者提出了一种自动化源代码自动整理技术，利用开源软件项目的版本历史来识别已修改的代码样本，并优先选取bug修复内容。实验结果显示，在The Stack v2中，17%的代码版本有更新，其中17%涉及bug修复，包括2.36%修复了已知CVEs，且58%的代码块从未被修改，表明潜在使用问题。该方法有助于提升训练数据质量，避免AI工具 perpetuating buggy代码模式和许可违规，从而提高输出可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in the Second International Workshop on Large Language\n  Models for Code (LLM4Code 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.02628v1",
      "published_date": "2025-01-05 18:54:25 UTC",
      "updated_date": "2025-01-05 18:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:35:38.093712"
    },
    {
      "arxiv_id": "2501.02621v1",
      "title": "LLMs Help Alleviate the Cross-Subject Variability in Brain Signal and Language Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Liu",
        "Hengwei Ye",
        "Shuhang Li"
      ],
      "abstract": "Decoding human activity from EEG signals has long been a popular research\ntopic. While recent studies have increasingly shifted focus from single-subject\nto cross-subject analysis, few have explored the model's ability to perform\nzero-shot predictions on EEG signals from previously unseen subjects. This\nresearch aims to investigate whether deep learning methods can capture\nsubject-independent semantic information inherent in human EEG signals. Such\ninsights are crucial for Brain-Computer Interfaces (BCI) because, on one hand,\nthey demonstrate the model's robustness against subject-specific temporal\nbiases, and on the other, they significantly enhance the generalizability of\ndownstream tasks. We employ Large Language Models (LLMs) as denoising agents to\nextract subject-independent semantic features from noisy EEG signals.\nExperimental results, including ablation studies, highlight the pivotal role of\nLLMs in decoding subject-independent semantic information from noisy EEG data.\nWe hope our findings will contribute to advancing BCI research and assist both\nacademia and industry in applying EEG signals to a broader range of\napplications.",
      "tldr_zh": "本研究探讨了从 EEG 信号中解码人类活动时存在的跨主体变异性（cross-subject variability）问题，特别关注模型在零样本预测中捕捉主体无关语义信息的能力。研究采用 Large Language Models (LLMs) 作为去噪代理，从噪声 EEG 信号中提取主体独立的语义特征，从而提升模型的鲁棒性和下游任务的泛化性。实验结果和消融研究证实了 LLMs 在处理 EEG 数据中的关键作用，有望推动 Brain-Computer Interfaces (BCI) 研究，并扩展 EEG 信号在学术和工业应用中的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02621v1",
      "published_date": "2025-01-05 18:29:39 UTC",
      "updated_date": "2025-01-05 18:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:35:49.871578"
    },
    {
      "arxiv_id": "2501.02600v1",
      "title": "TAPAS: Thermal- and Power-Aware Scheduling for LLM Inference in Cloud Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Jovan Stojkovic",
        "Chaojie Zhang",
        "Íñigo Goiri",
        "Esha Choukse",
        "Haoran Qiu",
        "Rodrigo Fonseca",
        "Josep Torrellas",
        "Ricardo Bianchini"
      ],
      "abstract": "The rising demand for generative large language models (LLMs) poses\nchallenges for thermal and power management in cloud datacenters. Traditional\ntechniques often are inadequate for LLM inference due to the fine-grained,\nmillisecond-scale execution phases, each with distinct performance, thermal,\nand power profiles. Additionally, LLM inference workloads are sensitive to\nvarious configuration parameters (e.g., model parallelism, size, and\nquantization) that involve trade-offs between performance, temperature, power,\nand output quality. Moreover, clouds often co-locate SaaS and IaaS workloads,\neach with different levels of visibility and flexibility. We propose TAPAS, a\nthermal- and power-aware framework designed for LLM inference clusters in the\ncloud. TAPAS enhances cooling and power oversubscription capabilities, reducing\nthe total cost of ownership (TCO) while effectively handling emergencies (e.g.,\ncooling and power failures). The system leverages historical temperature and\npower data, along with the adaptability of SaaS workloads, to: (1) efficiently\nplace new GPU workload VMs within cooling and power constraints, (2) route LLM\ninference requests across SaaS VMs, and (3) reconfigure SaaS VMs to manage load\nspikes and emergency situations. Our evaluation on a large GPU cluster\ndemonstrates significant reductions in thermal and power throttling events,\nboosting system efficiency.",
      "tldr_zh": "该研究针对大型语言模型(LLM)推理在云平台中带来的热管理和功耗挑战，提出TAPAS框架，这是一个热量和功耗感知的调度系统。TAPAS利用历史温度和功耗数据以及SaaS工作负载的适应性，来优化GPU工作负载的放置、LLM推理请求的路由，以及SaaS VM的重新配置，以处理负载峰值和紧急情况（如冷却或功耗故障）。实验结果显示，在大型GPU集群上，TAPAS显著减少了热量和功耗节流事件，提高了系统效率并降低了总拥有成本(TCO)。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02600v1",
      "published_date": "2025-01-05 16:51:17 UTC",
      "updated_date": "2025-01-05 16:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:36:02.177915"
    },
    {
      "arxiv_id": "2501.02599v1",
      "title": "Empowering Bengali Education with AI: Solving Bengali Math Word Problems through Transformer Models",
      "title_zh": "用 AI 赋能 Bengali 教育：通过 Transformer 模型解决 Bengali 数学文字问题",
      "authors": [
        "Jalisha Jashim Era",
        "Bidyarthi Paul",
        "Tahmid Sattar Aothoi",
        "Mirazur Rahman Zim",
        "Faisal Muhammad Shah"
      ],
      "abstract": "Mathematical word problems (MWPs) involve the task of converting textual\ndescriptions into mathematical equations. This poses a significant challenge in\nnatural language processing, particularly for low-resource languages such as\nBengali. This paper addresses this challenge by developing an innovative\napproach to solving Bengali MWPs using transformer-based models, including\nBasic Transformer, mT5, BanglaT5, and mBART50. To support this effort, the\n\"PatiGonit\" dataset was introduced, containing 10,000 Bengali math problems,\nand these models were fine-tuned to translate the word problems into equations\naccurately. The evaluation revealed that the mT5 model achieved the highest\naccuracy of 97.30%, demonstrating the effectiveness of transformer models in\nthis domain. This research marks a significant step forward in Bengali natural\nlanguage processing, offering valuable methodologies and resources for\neducational AI tools. By improving math education, it also supports the\ndevelopment of advanced problem-solving skills for Bengali-speaking students.",
      "tldr_zh": "这篇论文针对低资源语言孟加拉语的数学文字问题（MWPs），提出了一种基于 Transformer 模型的方法，包括 Basic Transformer、mT5、BanglaT5 和 mBART50，用于将文本描述转化为数学方程。\n为了支持研究，他们引入了名为 PatiGonit 的数据集，包含 10,000 个孟加拉语数学问题，并对这些模型进行了微调以提升准确性。\n实验结果显示，mT5 模型取得了 97.30% 的最高准确率，这为孟加拉语自然语言处理提供了重要资源和方法，并有助于改善孟加拉语学生的数学教育和问题解决技能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02599v1",
      "published_date": "2025-01-05 16:50:55 UTC",
      "updated_date": "2025-01-05 16:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:36:14.928285"
    },
    {
      "arxiv_id": "2501.03279v1",
      "title": "Revolutionizing Encrypted Traffic Classification with MH-Net: A Multi-View Heterogeneous Graph Model",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhen Zhang",
        "Haodong Yue",
        "Xi Xiao",
        "Le Yu",
        "Qing Li",
        "Zhen Ling",
        "Ye Zhang"
      ],
      "abstract": "With the growing significance of network security, the classification of\nencrypted traffic has emerged as an urgent challenge. Traditional byte-based\ntraffic analysis methods are constrained by the rigid granularity of\ninformation and fail to fully exploit the diverse correlations between bytes.\nTo address these limitations, this paper introduces MH-Net, a novel approach\nfor classifying network traffic that leverages multi-view heterogeneous traffic\ngraphs to model the intricate relationships between traffic bytes. The essence\nof MH-Net lies in aggregating varying numbers of traffic bits into multiple\ntypes of traffic units, thereby constructing multi-view traffic graphs with\ndiverse information granularities. By accounting for different types of byte\ncorrelations, such as header-payload relationships, MH-Net further endows the\ntraffic graph with heterogeneity, significantly enhancing model performance.\nNotably, we employ contrastive learning in a multi-task manner to strengthen\nthe robustness of the learned traffic unit representations. Experiments\nconducted on the ISCX and CIC-IoT datasets for both the packet-level and\nflow-level traffic classification tasks demonstrate that MH-Net achieves the\nbest overall performance compared to dozens of SOTA methods.",
      "tldr_zh": "该研究针对加密流量分类的挑战，提出 MH-Net，一种基于多视图异构图模型的方法，以克服传统字节分析方法的粒度限制和相关性利用不足。MH-Net 通过聚合不同数量的流量位构建多视图流量图，并考虑如 header-payload 关系的字节异构性，同时采用多任务 contrastive learning 来增强流量单位表示的鲁棒性。这种创新方法显著提升了模型性能，在 ISCX 和 CIC-IoT 数据集上的包级和流级分类任务中，MH-Net 优于数十种 SOTA 方法，实现了最佳整体表现。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by AAAI 2025. The code is available at\n  https://github.com/ViktorAxelsen/MH-Net. arXiv admin note: text overlap with\n  arXiv:2402.07501",
      "pdf_url": "http://arxiv.org/pdf/2501.03279v1",
      "published_date": "2025-01-05 16:50:41 UTC",
      "updated_date": "2025-01-05 16:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:36:25.698702"
    },
    {
      "arxiv_id": "2501.02593v3",
      "title": "Evolving Skeletons: Motion Dynamics in Action Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jushang Qiu",
        "Lei Wang"
      ],
      "abstract": "Skeleton-based action recognition has gained significant attention for its\nability to efficiently represent spatiotemporal information in a lightweight\nformat. Most existing approaches use graph-based models to process skeleton\nsequences, where each pose is represented as a skeletal graph structured around\nhuman physical connectivity. Among these, the Spatiotemporal Graph\nConvolutional Network (ST-GCN) has become a widely used framework.\nAlternatively, hypergraph-based models, such as the Hyperformer, capture\nhigher-order correlations, offering a more expressive representation of complex\njoint interactions. A recent advancement, termed Taylor Videos, introduces\nmotion-enhanced skeleton sequences by embedding motion concepts, providing a\nfresh perspective on interpreting human actions in skeleton-based action\nrecognition. In this paper, we conduct a comprehensive evaluation of both\ntraditional skeleton sequences and Taylor-transformed skeletons using ST-GCN\nand Hyperformer models on the NTU-60 and NTU-120 datasets. We compare skeletal\ngraph and hypergraph representations, analyzing static poses against\nmotion-injected poses. Our findings highlight the strengths and limitations of\nTaylor-transformed skeletons, demonstrating their potential to enhance motion\ndynamics while exposing current challenges in fully using their benefits. This\nstudy underscores the need for innovative skeletal modelling techniques to\neffectively handle motion-rich data and advance the field of action\nrecognition.",
      "tldr_zh": "本研究评估了基于骨骼的动作识别技术，比较了传统骨骼序列和引入运动概念的 Taylor Videos 方法。作者使用 Spatiotemporal Graph Convolutional Network (ST-GCN) 和 Hyperformer 模型，在 NTU-60 和 NTU-120 数据集上进行全面实验，分析了静态姿势与注入运动的姿势在图和超图表示中的表现。结果显示，Taylor Videos 增强了动作识别中的运动动态，但也暴露了当前模型在充分利用其优势时的局限性。该研究强调了开发创新骨骼建模技术的重要性，以更好地处理丰富运动数据并推动动作识别领域的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the Companion Proceedings of the ACM Web Conference (WWW\n  Companion 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.02593v3",
      "published_date": "2025-01-05 16:16:10 UTC",
      "updated_date": "2025-02-24 04:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:36:37.787563"
    },
    {
      "arxiv_id": "2501.02584v1",
      "title": "Efficient Architectures for High Resolution Vision-Language Models",
      "title_zh": "高分辨率视觉语言模型的高效架构",
      "authors": [
        "Miguel Carvalho",
        "Bruno Martins"
      ],
      "abstract": "Vision-Language Models (VLMs) have recently experienced significant\nadvancements. However, challenges persist in the accurate recognition of fine\ndetails within high resolution images, which limits performance in multiple\ntasks. This work introduces Pheye, a novel architecture that efficiently\nprocesses high-resolution images while training fewer parameters than similarly\nsized VLMs. Notably, Pheye achieves a high efficiency while maintaining strong\nperformance, particularly in tasks that demand fine-grained image understanding\nand/or the handling of scene-text.",
      "tldr_zh": "本文研究了 Vision-Language Models (VLMs) 在处理高分辨率图像时面临的挑战，特别是识别精细细节的准确性问题。作者提出了一种新型架构 Pheye，它能高效处理高分辨率图像，同时比同规模 VLMs 训练更少的参数。实验结果显示，Pheye 在需要细粒度图像理解和处理 scene-text 的任务中保持了强劲性能，从而提升了整体效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.02584v1",
      "published_date": "2025-01-05 15:41:26 UTC",
      "updated_date": "2025-01-05 15:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:36:49.543121"
    },
    {
      "arxiv_id": "2501.02572v1",
      "title": "Energy Optimization of Multi-task DNN Inference in MEC-assisted XR Devices: A Lyapunov-Guided Reinforcement Learning Approach",
      "title_zh": "多任务 DNN 推理在 MEC 辅助 XR 设备中的能量优化：一种 Lyapunov 引导的强化学习方法",
      "authors": [
        "Yanzan Sun",
        "Jiacheng Qiu",
        "Guangjin Pan",
        "Shugong Xu",
        "Shunqing Zhang",
        "Xiaoyun Wang",
        "Shuangfeng Han"
      ],
      "abstract": "Extended reality (XR), blending virtual and real worlds, is a key application\nof future networks. While AI advancements enhance XR capabilities, they also\nimpose significant computational and energy challenges on lightweight XR\ndevices. In this paper, we developed a distributed queue model for multi-task\nDNN inference, addressing issues of resource competition and queue coupling. In\nresponse to the challenges posed by the high energy consumption and limited\nresources of XR devices, we designed a dual time-scale joint optimization\nstrategy for model partitioning and resource allocation, formulated as a\nbi-level optimization problem. This strategy aims to minimize the total energy\nconsumption of XR devices while ensuring queue stability and adhering to\ncomputational and communication resource constraints. To tackle this problem,\nwe devised a Lyapunov-guided Proximal Policy Optimization algorithm, named\nLyaPPO. Numerical results demonstrate that the LyaPPO algorithm outperforms the\nbaselines, achieving energy conservation of 24.79% to 46.14% under varying\nresource capacities. Specifically, the proposed algorithm reduces the energy\nconsumption of XR devices by 24.29% to 56.62% compared to baseline algorithms.",
      "tldr_zh": "本论文针对 MEC（Mobile Edge Computing）辅助的 XR（Extended Reality）设备在多任务 DNN（Deep Neural Network）推理中面临的计算和能量挑战，提出了一种分布式队列模型来处理资源竞争和队列耦合问题。作者设计了双时间尺度联合优化策略，包括模型分区和资源分配，构建为双层优化问题，以最小化 XR 设备的总能量消耗，同时确保队列稳定性和资源约束。为解决此问题，开发了 Lyapunov-guided Proximal Policy Optimization 算法（LyaPPO），该算法在数值实验中比基线方法节省 24.79% 到 46.14% 的能量，具体减少 XR 设备能耗 24.29% 到 56.62%。这项工作为高效的 XR 设备能量管理提供了可行方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "13 pages, 7 figures. This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2501.02572v1",
      "published_date": "2025-01-05 15:07:41 UTC",
      "updated_date": "2025-01-05 15:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:37:02.101007"
    },
    {
      "arxiv_id": "2501.02570v1",
      "title": "Decoding fMRI Data into Captions using Prefix Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Vyacheslav Shen",
        "Kassymzhomart Kunanbayev",
        "Dae-Shik Kim"
      ],
      "abstract": "With the advancements in Large Language and Latent Diffusion models, brain\ndecoding has achieved remarkable results in recent years. The works on the NSD\ndataset, with stimuli images from the COCO dataset, leverage the embeddings\nfrom the CLIP model for image reconstruction and GIT for captioning. However,\nthe current captioning approach introduces the challenge of potential data\ncontamination given that the GIT model was trained on the COCO dataset. In this\nwork, we present an alternative method for decoding brain signals into image\ncaptions by predicting a DINOv2 model's embedding of an image from the\ncorresponding fMRI signal and then providing its [CLS] token as the prefix to\nthe GPT-2 language model which decreases computational requirements\nconsiderably. Additionally, instead of commonly used Linear Regression, we\nexplore 3D Convolutional Neural Network mapping of fMRI signals to image\nembedding space for better accounting positional information of voxels.",
      "tldr_zh": "这篇论文提出了一种新的方法，用于将 fMRI 数据解码成图像标题，以解决现有方法（如使用 GIT 模型）可能存在的训练数据污染问题。方法包括从 fMRI 信号预测 DINOv2 模型的图像嵌入，并将该嵌入的 [CLS] 标记作为前缀输入到 GPT-2 语言模型中，从而生成标题并显著降低计算需求。此外，论文探索使用 3D Convolutional Neural Network 代替传统的线性回归，来更好地捕捉 fMRI 体素的位置信息，提高解码准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 2 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.02570v1",
      "published_date": "2025-01-05 15:06:25 UTC",
      "updated_date": "2025-01-05 15:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:37:14.204791"
    },
    {
      "arxiv_id": "2501.02564v3",
      "title": "Balanced Multi-view Clustering",
      "title_zh": "平衡多视图聚类",
      "authors": [
        "Zhenglai Li",
        "Jun Wang",
        "Chang Tang",
        "Xinzhong Zhu",
        "Wei Zhang",
        "Xinwang Liu"
      ],
      "abstract": "Multi-view clustering (MvC) aims to integrate information from different\nviews to enhance the capability of the model in capturing the underlying data\nstructures. The widely used joint training paradigm in MvC is potentially not\nfully leverage the multi-view information, since the imbalanced and\nunder-optimized view-specific features caused by the uniform learning objective\nfor all views. For instance, particular views with more discriminative\ninformation could dominate the learning process in the joint training paradigm,\nleading to other views being under-optimized. To alleviate this issue, we first\nanalyze the imbalanced phenomenon in the joint-training paradigm of multi-view\nclustering from the perspective of gradient descent for each view-specific\nfeature extractor. Then, we propose a novel balanced multi-view clustering\n(BMvC) method, which introduces a view-specific contrastive regularization\n(VCR) to modulate the optimization of each view. Concretely, VCR preserves the\nsample similarities captured from the joint features and view-specific ones\ninto the clustering distributions corresponding to view-specific features to\nenhance the learning process of view-specific feature extractors. Additionally,\na theoretical analysis is provided to illustrate that VCR adaptively modulates\nthe magnitudes of gradients for updating the parameters of view-specific\nfeature extractors to achieve a balanced multi-view learning procedure. In such\na manner, BMvC achieves a better trade-off between the exploitation of\nview-specific patterns and the exploration of view-invariance patterns to fully\nlearn the multi-view information for the clustering task. Finally, a set of\nexperiments are conducted to verify the superiority of the proposed method\ncompared with state-of-the-art approaches on eight benchmark MvC datasets.",
      "tldr_zh": "多视图聚类 (Multi-view Clustering) 存在联合训练范式导致的视图间不平衡问题，其中某些视图主导学习过程，使其他视图优化不足。论文提出了一种新型方法 Balanced Multi-view Clustering (BMvC)，通过引入视图特定对比正则化 (VCR) 来调节每个视图的优化，确保样本相似性在聚类分布中得到保留，从而平衡视图特定模式和视图不变模式的探索。理论分析表明，VCR 可自适应调节梯度大小以实现均衡学习，最终实验在八个基准数据集上验证了 BMvC 比现有方法表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02564v3",
      "published_date": "2025-01-05 14:42:47 UTC",
      "updated_date": "2025-02-04 11:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:37:25.862552"
    },
    {
      "arxiv_id": "2501.02559v1",
      "title": "KM-UNet KAN Mamba UNet for medical image segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yibo Zhang"
      ],
      "abstract": "Medical image segmentation is a critical task in medical imaging analysis.\nTraditional CNN-based methods struggle with modeling long-range dependencies,\nwhile Transformer-based models, despite their success, suffer from quadratic\ncomputational complexity. To address these limitations, we propose KM-UNet, a\nnovel U-shaped network architecture that combines the strengths of\nKolmogorov-Arnold Networks (KANs) and state-space models (SSMs). KM-UNet\nleverages the Kolmogorov-Arnold representation theorem for efficient feature\nrepresentation and SSMs for scalable long-range modeling, achieving a balance\nbetween accuracy and computational efficiency. We evaluate KM-UNet on five\nbenchmark datasets: ISIC17, ISIC18, CVC, BUSI, and GLAS. Experimental results\ndemonstrate that KM-UNet achieves competitive performance compared to\nstate-of-the-art methods in medical image segmentation tasks. To the best of\nour knowledge, KM-UNet is the first medical image segmentation framework\nintegrating KANs and SSMs. This work provides a valuable baseline and new\ninsights for the development of more efficient and interpretable medical image\nsegmentation systems. The code is open source at\nhttps://github.com/2760613195/KM_UNet\n  Keywords:KAN,Manba, state-space models,UNet, Medical image segmentation, Deep\nlearning",
      "tldr_zh": "该论文提出 KM-UNet，一种新型 U-shaped 网络架构，用于医疗图像分割，旨在解决传统 CNN 方法在处理长距离依赖方面的不足以及 Transformer 方法的二次计算复杂度问题。KM-UNet 结合 Kolmogorov-Arnold Networks (KANs) 用于高效特征表示，以及 state-space models (SSMs) 来实现可扩展的长距离建模，从而平衡准确性和计算效率。在 ISIC17、ISIC18、CVC、Busi 和 GLAS 等五个基准数据集上进行评估，结果显示 KM-UNet 的性能与最先进方法相当，并作为首个整合 KANs 和 SSMs 的框架，为更高效和可解释的医疗图像分割系统提供新见解和开源基准（代码见 https://github.com/2760613195/KM_UNet）。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02559v1",
      "published_date": "2025-01-05 14:21:07 UTC",
      "updated_date": "2025-01-05 14:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:37:38.944648"
    },
    {
      "arxiv_id": "2501.02548v1",
      "title": "AMM: Adaptive Modularized Reinforcement Model for Multi-city Traffic Signal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Zherui Huang",
        "Yicheng Liu",
        "Chumeng Liang",
        "Guanjie Zheng"
      ],
      "abstract": "Traffic signal control (TSC) is an important and widely studied direction.\nRecently, reinforcement learning (RL) methods have been used to solve TSC\nproblems and achieve superior performance over conventional TSC methods.\nHowever, applying RL methods to the real world is challenging due to the huge\ncost of experiments in real-world traffic environments. One possible solution\nis TSC domain adaptation, which adapts trained models to target environments\nand reduces the number of interactions and the training cost. However, existing\nTSC domain adaptation methods still face two major issues: the lack of\nconsideration for differences across cities and the low utilization of\nmulti-city data.\n  To solve aforementioned issues, we propose an approach named Adaptive\nModularized Model (AMM). By modularizing TSC problems and network models, we\novercome the challenge of possible changes in environmental observations. We\nalso aggregate multi-city experience through meta-learning. We conduct\nextensive experiments on different cities and show that AMM can achieve\nexcellent performance with limited interactions in target environments and\noutperform existing methods. We also demonstrate the feasibility and\ngeneralizability of our method.",
      "tldr_zh": "该论文针对多城市交通信号控制(TSC)问题，提出了一种Adaptive Modularized Model (AMM)，通过模块化TSC问题和网络模型来应对城市间环境观察差异，并利用元学习(meta-learning)聚合多城市数据，从而提升模型的领域适应能力。AMM方法解决了现有TSC领域适应方法忽略城市差异和数据利用率低的问题，减少了目标环境中的交互次数和训练成本。在不同城市的大规模实验中，AMM展示了优异性能，显著超越基线方法，并证明了其可行性和泛化性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02548v1",
      "published_date": "2025-01-05 13:59:08 UTC",
      "updated_date": "2025-01-05 13:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:37:49.979789"
    },
    {
      "arxiv_id": "2501.02546v1",
      "title": "TreeMatch: A Fully Unsupervised WSD System Using Dependency Knowledge on a Specific Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Tran",
        "Chris Bowes",
        "David Brown",
        "Ping Chen",
        "Max Choly",
        "Wei Ding"
      ],
      "abstract": "Word sense disambiguation (WSD) is one of the main challenges in\nComputational Linguistics. TreeMatch is a WSD system originally developed using\ndata from SemEval 2007 Task 7 (Coarse-grained English All-words Task) that has\nbeen adapted for use in SemEval 2010 Task 17 (All-words Word Sense\nDisambiguation on a Specific Domain). The system is based on a fully\nunsupervised method using dependency knowledge drawn from a domain specific\nknowledge base that was built for this task. When evaluated on the task, the\nsystem precision performs above the Most Frequent Selection baseline.",
      "tldr_zh": "TreeMatch 是一种完全无监督的 WSD (Word Sense Disambiguation) 系统，最初基于 SemEval 2007 Task 7 的数据，并被适应用于 SemEval 2010 Task 17（特定领域的全词歧义消解）。该系统利用从特定领域知识库中提取的 dependency knowledge 来进行歧义消解，而无需监督训练。实验结果显示，TreeMatch 的精确度超过了 Most Frequent Selection 基准，在特定领域任务中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02546v1",
      "published_date": "2025-01-05 13:56:04 UTC",
      "updated_date": "2025-01-05 13:56:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:38:01.035196"
    },
    {
      "arxiv_id": "2501.02535v1",
      "title": "A completely uniform transformer for parity",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Kozachinskiy",
        "Tomasz Steifer"
      ],
      "abstract": "We construct a 3-layer constant-dimension transformer, recognizing the parity\nlanguage, where neither parameter matrices nor the positional encoding depend\non the input length. This improves upon a construction of Chiang and Cholak who\nuse a positional encoding, depending on the input length (but their\nconstruction has 2 layers).",
      "tldr_zh": "本研究构建了一个 3 层、维度恒定的 Transformer 模型，用于识别 parity 语言，其参数矩阵和位置编码均不依赖于输入长度，从而实现完全统一的设计。相比于 Chiang 和 Cholak 的先前构造，该模型虽增加了层数，但消除了对输入长度依赖的位置编码。整体改进提升了模型的通用性和灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.02535v1",
      "published_date": "2025-01-05 13:32:13 UTC",
      "updated_date": "2025-01-05 13:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:38:14.083619"
    },
    {
      "arxiv_id": "2501.02532v1",
      "title": "Evaluating Large Language Models Against Human Annotators in Latent Content Analysis: Sentiment, Political Leaning, Emotional Intensity, and Sarcasm",
      "title_zh": "翻译失败",
      "authors": [
        "Ljubisa Bojic",
        "Olga Zagovora",
        "Asta Zelenkauskaite",
        "Vuk Vukovic",
        "Milan Cabarkapa",
        "Selma Veseljević Jerkovic",
        "Ana Jovančevic"
      ],
      "abstract": "In the era of rapid digital communication, vast amounts of textual data are\ngenerated daily, demanding efficient methods for latent content analysis to\nextract meaningful insights. Large Language Models (LLMs) offer potential for\nautomating this process, yet comprehensive assessments comparing their\nperformance to human annotators across multiple dimensions are lacking. This\nstudy evaluates the reliability, consistency, and quality of seven\nstate-of-the-art LLMs, including variants of OpenAI's GPT-4, Gemini, Llama, and\nMixtral, relative to human annotators in analyzing sentiment, political\nleaning, emotional intensity, and sarcasm detection. A total of 33 human\nannotators and eight LLM variants assessed 100 curated textual items,\ngenerating 3,300 human and 19,200 LLM annotations, with LLMs evaluated across\nthree time points to examine temporal consistency. Inter-rater reliability was\nmeasured using Krippendorff's alpha, and intra-class correlation coefficients\nassessed consistency over time. The results reveal that both humans and LLMs\nexhibit high reliability in sentiment analysis and political leaning\nassessments, with LLMs demonstrating higher internal consistency than humans.\nIn emotional intensity, LLMs displayed higher agreement compared to humans,\nthough humans rated emotional intensity significantly higher. Both groups\nstruggled with sarcasm detection, evidenced by low agreement. LLMs showed\nexcellent temporal consistency across all dimensions, indicating stable\nperformance over time. This research concludes that LLMs, especially GPT-4, can\neffectively replicate human analysis in sentiment and political leaning,\nalthough human expertise remains essential for emotional intensity\ninterpretation. The findings demonstrate the potential of LLMs for consistent\nand high-quality performance in certain areas of latent content analysis.",
      "tldr_zh": "这篇论文评估了七种大型语言模型（LLMs），包括GPT-4变体、Gemini、Llama和Mixtral，与人类标注者在情感（sentiment）、政治倾向（political leaning）、情感强度（emotional intensity）和讽刺检测（sarcasm）等维度的潜在内容分析中的表现。研究通过33名人类标注者和八个LLM变体对100个文本项进行评估，共生成3,300个人类标注和19,200个LLM标注，并使用Krippendorff's alpha和内部相关系数（intra-class correlation coefficients）来衡量可靠性、一致性和时间稳定性。结果显示，LLMs在情感和政治倾向分析中表现出高可靠性且内部一致性优于人类，在情感强度上协议更高但评分较低，而在讽刺检测上两者均表现不佳；此外，LLMs显示出优秀的temporal consistency。论文结论认为，LLMs尤其是GPT-4可有效复制人类分析，但人类在情感强度解释方面仍不可或缺。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.02532v1",
      "published_date": "2025-01-05 13:28:15 UTC",
      "updated_date": "2025-01-05 13:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:38:28.130926"
    },
    {
      "arxiv_id": "2501.02523v1",
      "title": "Face-MakeUp: Multimodal Facial Prompts for Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Dai",
        "Mingming Jia",
        "Yinxiu Zhou",
        "Hang Xing",
        "Chenghang Li"
      ],
      "abstract": "Facial images have extensive practical applications. Although the current\nlarge-scale text-image diffusion models exhibit strong generation capabilities,\nit is challenging to generate the desired facial images using only text prompt.\nImage prompts are a logical choice. However, current methods of this type\ngenerally focus on general domain. In this paper, we aim to optimize image\nmakeup techniques to generate the desired facial images. Specifically, (1) we\nbuilt a dataset of 4 million high-quality face image-text pairs\n(FaceCaptionHQ-4M) based on LAION-Face to train our Face-MakeUp model; (2) to\nmaintain consistency with the reference facial image, we extract/learn\nmulti-scale content features and pose features for the facial image,\nintegrating these into the diffusion model to enhance the preservation of\nfacial identity features for diffusion models. Validation on two face-related\ntest datasets demonstrates that our Face-MakeUp can achieve the best\ncomprehensive performance.All codes are available\nat:https://github.com/ddw2AIGROUP2CQUPT/Face-MakeUp",
      "tldr_zh": "该论文针对文本-图像生成模型在创建面部图像时的挑战，提出Face-MakeUp方法，使用多模态面部提示来优化生成效果，以克服仅靠文本prompt的局限性。具体而言，研究者构建了FaceCaptionHQ-4M数据集（包含400万高质量面部图像-文本对），并通过提取多尺度内容特征和姿势特征，将其整合到diffusion model中，以增强面部身份特征的保留。在两个面部相关测试数据集上的验证显示，Face-MakeUp实现了最佳的综合性能，并开源了相关代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02523v1",
      "published_date": "2025-01-05 12:46:31 UTC",
      "updated_date": "2025-01-05 12:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:38:39.223026"
    },
    {
      "arxiv_id": "2501.02521v1",
      "title": "Remote Inference over Dynamic Links via Adaptive Rate Deep Task-Oriented Vector Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Eyal Fishel",
        "May Malka",
        "Shai Ginzach",
        "Nir Shlezinger"
      ],
      "abstract": "A broad range of technologies rely on remote inference, wherein data acquired\nis conveyed over a communication channel for inference in a remote server.\nCommunication between the participating entities is often carried out over\nrate-limited channels, necessitating data compression for reducing latency.\nWhile deep learning facilitates joint design of the compression mapping along\nwith encoding and inference rules, existing learned compression mechanisms are\nstatic, and struggle in adapting their resolution to changes in channel\nconditions and to dynamic links. To address this, we propose Adaptive Rate\nTask-Oriented Vector Quantization (ARTOVeQ), a learned compression mechanism\nthat is tailored for remote inference over dynamic links. ARTOVeQ is based on\ndesigning nested codebooks along with a learning algorithm employing\nprogressive learning. We show that ARTOVeQ extends to support low-latency\ninference that is gradually refined via successive refinement principles, and\nthat it enables the simultaneous usage of multiple resolutions when conveying\nhigh-dimensional data. Numerical results demonstrate that the proposed scheme\nyields remote deep inference that operates with multiple rates, supports a\nbroad range of bit budgets, and facilitates rapid inference that gradually\nimproves with more bits exchanged, while approaching the performance of\nsingle-rate deep quantization methods.",
      "tldr_zh": "这篇论文提出了一种适应性速率的深度任务导向向量量化方法 ARTOVeQ，用于动态链路上的远程推理，以应对通信通道条件变化带来的挑战。ARTOVeQ 通过设计 nested codebooks 和采用 progressive learning 算法，实现数据压缩的灵活调整，支持低延迟推理和 successive refinement 原则的逐步改进。实验结果显示，该方法支持多种速率和比特预算，提供渐进式性能提升，并接近单速率深度量化方法的推理准确性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "13 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.02521v1",
      "published_date": "2025-01-05 12:38:13 UTC",
      "updated_date": "2025-01-05 12:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:38:50.164898"
    },
    {
      "arxiv_id": "2502.00005v1",
      "title": "A Study about Distribution and Acceptance of Conversational Agents for Mental Health in Germany: Keep the Human in the Loop?",
      "title_zh": "翻译失败",
      "authors": [
        "Christina Lukas"
      ],
      "abstract": "Good mental health enables individuals to cope with the normal stresses of\nlife. In Germany, approximately one-quarter of the adult population is affected\nby mental illnesses. Teletherapy and digital health applications are available\nto bridge gaps in care and relieve healthcare professionals. The acceptance of\nthese tools is a strongly influencing factor for their effectiveness, which\nalso needs to be evaluated for AI-based conversational agents (CAs) (e. g.\nChatGPT, Siri) to assess the risks and potential for integration into\ntherapeutic practice. This study investigates the perspectives of both the\ngeneral population and healthcare professionals with the following questions:\n1. How frequently are CAs used for mental health? 2. How high is the acceptance\nof CAs in the field of mental health? 3. To what extent is the use of CAs in\ncounselling, diagnosis, and treatment acceptable? To address these questions,\ntwo quantitative online surveys were conducted with 444 participants from the\ngeneral population and 351 healthcare professionals. Statistical analyses show\nthat 27 % of the surveyed population already confide their concerns to CAs. Not\nonly experience with this technology but also experience with telemedicine\nshows a higher acceptance among both groups for using CAs for mental health.\nAdditionally, participants from the general population were more likely to\nsupport CAs as companions controlled by healthcare professionals rather than as\nadditional experts for the professionals. CAs have the potential to support\nmental health, particularly in counselling. Future research should examine the\ninfluence of different communication media and further possibilities of\naugmented intelligence. With the right balance between technology and human\ncare, integration into patient-professional interaction can be achieved.",
      "tldr_zh": "这篇论文调查了德国普通大众和医疗专业人员对对话代理（CAs，如 ChatGPT）在精神健康领域的使用和接受度，旨在评估其在桥接医疗缺口中的潜力，同时强调保持人类参与。研究通过两份在线调查（涉及444名普通大众和351名医疗专业人员）进行统计分析，发现27%的受访者已向CAs倾诉担忧，且使用经验和远程医疗（telemedicine）经验会提高接受度。结果显示，CAs在咨询中具有支持潜力，但受访者更倾向于将其作为由专业人员控制的伴侣，而非独立专家。作者建议未来研究探索不同通信媒体和增强智能（augmented intelligence）的可能性，以实现技术和人类护理的平衡。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Master's thesis",
      "pdf_url": "http://arxiv.org/pdf/2502.00005v1",
      "published_date": "2025-01-05 12:20:18 UTC",
      "updated_date": "2025-01-05 12:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:39:04.608860"
    },
    {
      "arxiv_id": "2501.02508v1",
      "title": "PTEENet: Post-Trained Early-Exit Neural Networks Augmentation for Inference Cost Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Assaf Lahiany",
        "Yehudit Aperstein"
      ],
      "abstract": "For many practical applications, a high computational cost of inference over\ndeep network architectures might be unacceptable. A small degradation in the\noverall inference accuracy might be a reasonable price to pay for a significant\nreduction in the required computational resources. In this work, we describe a\nmethod for introducing \"shortcuts\" into the DNN feedforward inference process\nby skipping costly feedforward computations whenever possible. The proposed\nmethod is based on the previously described BranchyNet (Teerapittayanon et al.,\n2016) and the EEnet (Demir, 2019) architectures that jointly train the main\nnetwork and early exit branches. We extend those methods by attaching branches\nto pre-trained models and, thus, eliminating the need to alter the original\nweights of the network. We also suggest a new branch architecture based on\nconvolutional building blocks to allow enough training capacity when applied on\nlarge DNNs. The proposed architecture includes confidence heads that are used\nfor predicting the confidence level in the corresponding early exits. By\ndefining adjusted thresholds on these confidence extensions, we can control in\nreal-time the amount of data exiting from each branch and the overall tradeoff\nbetween speed and accuracy of our model. In our experiments, we evaluate our\nmethod using image datasets (SVHN and CIFAR10) and several DNN architectures\n(ResNet, DenseNet, VGG) with varied depth. Our results demonstrate that the\nproposed method enables us to reduce the average inference computational cost\nand further controlling the tradeoff between the model accuracy and the\ncomputation cost.",
      "tldr_zh": "这篇论文提出了 PTEENet，一种后训练的 Early-Exit 神经网络增强方法，用于优化深度神经网络（DNNs）的推理计算成本，通过在预训练模型上添加分支来跳过不必要的计算。方法扩展了 BranchyNet 和 EEnet 架构，引入基于卷积构建块的新分支设计以及 Confidence Heads 来预测置信水平，并通过调整阈值实现实时控制速度与准确性的权衡。实验在 SVHN 和 CIFAR10 数据集上使用 ResNet、DenseNet 和 VGG 等架构表明，PTEENet 能显著减少平均推理计算成本，同时提供灵活的准确性与效率权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02508v1",
      "published_date": "2025-01-05 11:35:08 UTC",
      "updated_date": "2025-01-05 11:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:39:14.485594"
    },
    {
      "arxiv_id": "2501.02504v1",
      "title": "Watch Video, Catch Keyword: Context-aware Keyword Attention for Moment Retrieval and Highlight Detection",
      "title_zh": "观看视频，捕捉关键词：上下文感知关键词注意力用于时刻检索和高亮检测",
      "authors": [
        "Sung Jin Um",
        "Dongjin Kim",
        "Sangmin Lee",
        "Jung Uk Kim"
      ],
      "abstract": "The goal of video moment retrieval and highlight detection is to identify\nspecific segments and highlights based on a given text query. With the rapid\ngrowth of video content and the overlap between these tasks, recent works have\naddressed both simultaneously. However, they still struggle to fully capture\nthe overall video context, making it challenging to determine which words are\nmost relevant. In this paper, we present a novel Video Context-aware Keyword\nAttention module that overcomes this limitation by capturing keyword variation\nwithin the context of the entire video. To achieve this, we introduce a video\ncontext clustering module that provides concise representations of the overall\nvideo context, thereby enhancing the understanding of keyword dynamics.\nFurthermore, we propose a keyword weight detection module with keyword-aware\ncontrastive learning that incorporates keyword information to enhance\nfine-grained alignment between visual and textual features. Extensive\nexperiments on the QVHighlights, TVSum, and Charades-STA benchmarks demonstrate\nthat our proposed method significantly improves performance in moment retrieval\nand highlight detection tasks compared to existing approaches. Our code is\navailable at: https://github.com/VisualAIKHU/Keyword-DETR",
      "tldr_zh": "本论文针对视频时刻检索和亮点检测任务，提出了一种基于文本查询识别视频特定段落和亮点的方法，但现有方法难以捕捉整体视频上下文从而影响关键词相关性判断。作者引入了Video Context-aware Keyword Attention模块，包括视频上下文聚类模块用于提供视频整体简洁表示，以及关键词权重检测模块结合关键词感知对比学习来增强视觉和文本特征的细粒度对齐。这些创新显著提高了模型在QVHighlights、TVSum和Charades-STA基准上的性能，与现有方法相比，检索和检测准确率得到实质提升。代码已在GitHub开源（https://github.com/VisualAIKHU/Keyword-DETR）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.02504v1",
      "published_date": "2025-01-05 11:01:27 UTC",
      "updated_date": "2025-01-05 11:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:39:25.896218"
    },
    {
      "arxiv_id": "2501.02497v2",
      "title": "Test-Time Compute: from System-1 Thinking to System-2 Thinking",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Ji",
        "Juntao Li",
        "Hai Ye",
        "Kaixin Wu",
        "Kai Yao",
        "Jia Xu",
        "Linjian Mo",
        "Min Zhang"
      ],
      "abstract": "The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out a few possible future\ndirections.",
      "tldr_zh": "该论文调查了测试时计算（test-time compute）在模型演进中的作用，从 System-1 Thinking 到 System-2 Thinking 的转变。作者追溯了这一概念在 System-1 模型中的应用，通过参数更新、输入修改、表示编辑和输出校准来应对分布偏移，提升模型的鲁棒性和泛化能力；在 System-2 模型中，则通过重复采样、自我修正和树搜索增强复杂推理能力。论文强调测试时计算是推动模型从 System-1 到强 System-2 过渡的关键，并提出了未来的可能研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2501.02497v2",
      "published_date": "2025-01-05 10:24:20 UTC",
      "updated_date": "2025-03-03 07:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:39:38.704895"
    },
    {
      "arxiv_id": "2501.03276v1",
      "title": "ComMer: a Framework for Compressing and Merging User Data for Personalization",
      "title_zh": "翻译失败",
      "authors": [
        "Yoel Zeldes",
        "Amir Zait",
        "Ilia Labzovsky",
        "Danny Karmon",
        "Efrat Farkash"
      ],
      "abstract": "Large Language Models (LLMs) excel at a wide range of tasks, but adapting\nthem to new data, particularly for personalized applications, poses significant\nchallenges due to resource and computational constraints. Existing methods\neither rely on exposing fresh data to the model through the prompt, which is\nlimited by context size and computationally expensive at inference time, or\nfine-tuning, which incurs substantial training and update costs. In this paper,\nwe introduce ComMer - Compress and Merge - a novel framework that efficiently\npersonalizes LLMs by compressing users' documents into compact representations,\nwhich are then merged and fed into a frozen LLM. We evaluate ComMer on two\ntypes of personalization tasks - personalized skill learning, using the tweet\nparaphrasing dataset and the personalized news headline generation dataset from\nthe LaMP benchmark, and knowledge-intensive, using the PerLTQA dataset. Our\nexperiments demonstrate that in constrained inference budget scenarios ComMer\nachieves superior quality in skill learning tasks, while highlighting\nlimitations in knowledge-intensive settings due to the loss of detailed\ninformation. These results offer insights into trade-offs and potential\noptimizations in multi-document compression for personalization.",
      "tldr_zh": "本文提出 ComMer 框架，用于高效个性化大型语言模型 (LLMs)，通过压缩用户文档成紧凑表示并合并后输入冻结的 LLM，从而克服资源和计算限制。ComMer 在个性化技能学习任务上（如推文改写和新闻标题生成数据集）表现出色，尤其在受限推理预算场景中优于现有方法。实验评估显示，该框架在知识密集型任务（如 PerLTQA 数据集）中存在局限性，由于信息丢失导致性能下降。这些结果为多文档压缩在个性化中的权衡和优化提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.03276v1",
      "published_date": "2025-01-05 09:57:03 UTC",
      "updated_date": "2025-01-05 09:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:39:50.532870"
    },
    {
      "arxiv_id": "2501.02491v1",
      "title": "Rethinking IDE Customization for Enhanced HAX: A Hyperdimensional Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Roham Koohestani",
        "Maliheh Izadi"
      ],
      "abstract": "As Integrated Development Environments (IDEs) increasingly integrate\nArtificial Intelligence, Software Engineering faces both benefits like\nproductivity gains and challenges like mismatched user preferences. We propose\nHyper-Dimensional (HD) vector spaces to model Human-Computer Interaction,\nfocusing on user actions, stylistic preferences, and project context. These\ncontributions aim to inspire further research on applying HD computing in IDE\ndesign.",
      "tldr_zh": "本研究重新审视 Integrated Development Environments (IDE) 的自定义，以提升 Human-AI eXperience (HAX)，针对 AI 整合带来的生产力提升和用户偏好不匹配等挑战。作者提出使用 Hyper-Dimensional (HD) 向量空间来建模人机交互，涵盖用户行为、风格偏好和项目上下文，从而更好地适应个性化需求。总体而言，此方法为 HD 计算在 IDE 设计中的应用提供了新思路，并鼓励进一步的研究探索。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at the 2nd Workshop on Integrated Development Environments\n  (the IDE Workshop) co-located with ICSE '25",
      "pdf_url": "http://arxiv.org/pdf/2501.02491v1",
      "published_date": "2025-01-05 09:53:50 UTC",
      "updated_date": "2025-01-05 09:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:40:01.904980"
    },
    {
      "arxiv_id": "2501.02486v2",
      "title": "LLMPC: Large Language Model Predictive Control",
      "title_zh": "LLMPC：大型语言模型预测控制",
      "authors": [
        "Gabriel Maher"
      ],
      "abstract": "Recent advancements in prompting techniques for Large Language Models (LLMs)\nhave improved their reasoning, planning, and action abilities. This paper\nexamines these prompting techniques through the lens of model predictive\ncontrol (MPC). We show that LLMs act as implicit planning cost function\nminimizers when planning prompts are used. We propose a unified MPC framework\nfor planning with LLMs and demonstrate improved performance over few shot\nprompting on several planning benchmarks.",
      "tldr_zh": "本文提出LLMPC框架，将大型语言模型(LLMs)的提示技术与模型预测控制(MPC)相结合，审视LLMs在推理、规划和行动方面的能力。研究发现，使用规划提示时，LLMs可充当隐式规划成本函数最小化器，从而构建一个统一的MPC框架来提升规划性能。在多个规划基准上，该框架比少样本提示(few shot prompting)表现出更好的结果。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02486v2",
      "published_date": "2025-01-05 09:37:23 UTC",
      "updated_date": "2025-02-25 02:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:40:13.055547"
    },
    {
      "arxiv_id": "2501.02481v4",
      "title": "Representation Convergence: Mutual Distillation is Secretly a Form of Regularization",
      "title_zh": "表示收敛：相互",
      "authors": [
        "Zhengpeng Xie",
        "Jiahang Cao",
        "Qiang Zhang",
        "Jianxiong Zhang",
        "Changwei Wang",
        "Renjing Xu"
      ],
      "abstract": "In this paper, we argue that mutual distillation between reinforcement\nlearning policies serves as an implicit regularization, preventing them from\noverfitting to irrelevant features. We highlight two key contributions: (a)\nTheoretically, for the first time, we prove that enhancing the policy\nrobustness to irrelevant features leads to improved generalization performance.\n(b) Empirically, we demonstrate that mutual distillation between policies\ncontributes to such robustness, enabling the spontaneous emergence of invariant\nrepresentations over pixel inputs. Overall, our findings challenge the\nconventional view of distillation as merely a means of knowledge transfer,\noffering a novel perspective on the generalization in deep reinforcement\nlearning.",
      "tldr_zh": "本文提出，强化学习（Reinforcement Learning）策略之间的相互蒸馏（Mutual Distillation）是一种隐式正则化（Implicit Regularization），可防止策略过拟合到无关特征，从而提升其鲁棒性（Robustness）和泛化性能（Generalization Performance）。理论上，论文首次证明增强策略对无关特征的鲁棒性能显著改善整体表现。实验结果显示，通过相互蒸馏，策略在像素输入上自发产生不变表示（Invariant Representations），并挑战了传统观点，将蒸馏视为一种知识转移方式之外的新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02481v4",
      "published_date": "2025-01-05 09:06:17 UTC",
      "updated_date": "2025-05-15 12:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:40:26.024973"
    },
    {
      "arxiv_id": "2501.02471v2",
      "title": "Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Yishen Liu",
        "Shengda Luo",
        "Zishao Zhong",
        "Tongtong Wu",
        "Jianguo Zhang",
        "Peiyao Ou",
        "Yong Liang",
        "Liang Liu",
        "Hudan Pan"
      ],
      "abstract": "Large language models (LLMs) primarily trained on English texts, often face\nbiases and inaccuracies in Chinese contexts. Their limitations are pronounced\nin fields like Traditional Chinese Medicine (TCM), where cultural and clinical\nsubtleties are vital, further hindered by a lack of domain-specific data, such\nas rheumatoid arthritis (RA). To address these issues, this paper introduces\nHengqin-RA-v1, the first large language model specifically tailored for TCM\nwith a focus on diagnosing and treating RA. We also present HQ-GCM-RA-C1, a\ncomprehensive RA-specific dataset curated from ancient Chinese medical\nliterature, classical texts, and modern clinical studies. This dataset empowers\nHengqin-RA-v1 to deliver accurate and culturally informed responses,\neffectively bridging the gaps left by general-purpose models. Extensive\nexperiments demonstrate that Hengqin-RA-v1 outperforms state-of-the-art models,\neven surpassing the diagnostic accuracy of TCM practitioners in certain cases.",
      "tldr_zh": "这篇论文介绍了Hengqin-RA-v1，一种先进的Large Language Model（LLMs），专门针对Traditional Chinese Medicine（TCM）领域，专注于类风湿性关节炎（RA）的诊断和治疗，以解决现有模型在中文语境中的偏差和不准确问题。研究者构建了HQ-GCM-RA-C1数据集，该数据集基于古代中文医学文献、经典文本和现代临床研究，提供丰富的领域特定数据来增强模型的文化适应性和准确性。通过广泛实验，Hengqin-RA-v1在诊断性能上超越了最先进模型，甚至在某些情况下超过了TCM从业者的准确率，为中医领域的AI应用奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures, AAAI-2025 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2501.02471v2",
      "published_date": "2025-01-05 07:46:51 UTC",
      "updated_date": "2025-03-27 06:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:40:38.474950"
    },
    {
      "arxiv_id": "2501.02464v2",
      "title": "Depth Any Camera: Zero-Shot Metric Depth Estimation from Any Camera",
      "title_zh": "翻译失败",
      "authors": [
        "Yuliang Guo",
        "Sparsh Garg",
        "S. Mahdi H. Miangoleh",
        "Xinyu Huang",
        "Liu Ren"
      ],
      "abstract": "While recent depth foundation models exhibit strong zero-shot generalization,\nachieving accurate metric depth across diverse camera types-particularly those\nwith large fields of view (FoV) such as fisheye and 360-degree cameras-remains\na significant challenge. This paper presents Depth Any Camera (DAC), a powerful\nzero-shot metric depth estimation framework that extends a perspective-trained\nmodel to effectively handle cameras with varying FoVs. The framework is\ndesigned to ensure that all existing 3D data can be leveraged, regardless of\nthe specific camera types used in new applications. Remarkably, DAC is trained\nexclusively on perspective images but generalizes seamlessly to fisheye and\n360-degree cameras without the need for specialized training data. DAC employs\nEqui-Rectangular Projection (ERP) as a unified image representation, enabling\nconsistent processing of images with diverse FoVs. Its core components include\npitch-aware Image-to-ERP conversion with efficient online augmentation to\nsimulate distorted ERP patches from undistorted inputs, FoV alignment\noperations to enable effective training across a wide range of FoVs, and\nmulti-resolution data augmentation to further address resolution disparities\nbetween training and testing. DAC achieves state-of-the-art zero-shot metric\ndepth estimation, improving $\\delta_1$ accuracy by up to 50% on multiple\nfisheye and 360-degree datasets compared to prior metric depth foundation\nmodels, demonstrating robust generalization across camera types.",
      "tldr_zh": "这篇论文提出了 Depth Any Camera (DAC)，一个零样本度量深度估计框架，能够将基于透视图像训练的模型扩展到各种视场角(FoV)的相机，如鱼眼和360度相机，而无需额外训练数据。DAC 采用 Equi-Rectangular Projection (ERP) 作为统一的图像表示，并通过 pitch-aware Image-to-ERP 转换、FoV 对齐操作和多分辨率数据增强等技术来处理图像畸变和分辨率差异。实验结果显示，DAC 在多个鱼眼和360度数据集上将 δ1 准确率提高了高达50%，比现有度量深度基础模型表现出更强的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02464v2",
      "published_date": "2025-01-05 07:22:40 UTC",
      "updated_date": "2025-03-16 18:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:40:50.957261"
    },
    {
      "arxiv_id": "2501.02461v1",
      "title": "FedRSClip: Federated Learning for Remote Sensing Scene Classification Using Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Lin",
        "Chao Zhang",
        "Danfeng Hong",
        "Kexin Dong",
        "Congcong Wen"
      ],
      "abstract": "Remote sensing data is often distributed across multiple institutions, and\ndue to privacy concerns and data-sharing restrictions, leveraging large-scale\ndatasets in a centralized training framework is challenging. Federated learning\noffers a promising solution by enabling collaborative model training across\ndistributed data sources without requiring data centralization. However,\ncurrent Vision-Language Models (VLMs), which typically contain billions of\nparameters, pose significant communication challenges for traditional federated\nlearning approaches based on model parameter updates, as they would incur\nsubstantial communication costs. In this paper, we propose FedRSCLIP, the first\nfederated learning framework designed for remote sensing image classification\nbased on a VLM, specifically CLIP. FedRSCLIP addresses the challenges of data\nheterogeneity and large-scale model transmission in federated environments by\nintroducing Prompt Learning, which optimizes only a small set of tunable\nparameters. The framework introduces a dual-prompt mechanism, comprising Shared\nPrompts for global knowledge sharing and Private Prompts for client-specific\nadaptation. To maintain semantic coherence between shared and private prompts,\nwe propose the Dual Prompt Alignment Constraint to balance global consistency\nand local adaptability across diverse client distributions. Additionally, to\nenhance cross-modal representation learning, we introduce the Cross-Modal\nFeature Alignment Constraint to align multimodal features between text and\nimage prompts. To validate the effectiveness of our proposed model, we\nconstruct a Fed-RSIC dataset based on three existing remote sensing image\nclassification datasets, specifically designed to simulate various federated\nlearning configurations. Experimental results demonstrate the effectiveness and\nsuperiority of FedRSCLIP in remote sensing image classification.",
      "tldr_zh": "本研究提出FedRSClip框架，这是首个基于Vision-Language Models（VLMs）的联邦学习方法，用于远程感应场景分类，解决数据隐私和通信成本高的问题。该框架采用Prompt Learning优化少量参数，并引入双提示机制，包括Shared Prompts（共享提示）用于全局知识共享，以及Private Prompts（私有提示）用于客户端特定适应。同时，通过Dual Prompt Alignment Constraint（双提示对齐约束）确保全局一致性和本地适应性，并利用Cross-Modal Feature Alignment Constraint（跨模态特征对齐约束）增强文本和图像的多模态表示学习。为验证有效性，研究构建了Fed-RSIC数据集，实验结果显示FedRSClip在远程感应图像分类中表现出色，具有显著的优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02461v1",
      "published_date": "2025-01-05 07:10:27 UTC",
      "updated_date": "2025-01-05 07:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:41:02.477030"
    },
    {
      "arxiv_id": "2501.02451v1",
      "title": "Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Cheng",
        "Boxuan Li",
        "André Altmann",
        "Pearse A Keane",
        "Yukun Zhou"
      ],
      "abstract": "Contrastive learning, a prominent approach within self-supervised learning,\nhas demonstrated significant effectiveness in developing generalizable models\nfor various applications involving natural images. However, recent research\nindicates that these successes do not necessarily extend to the medical imaging\ndomain. In this paper, we investigate the reasons for this suboptimal\nperformance and hypothesize that the dense distribution of medical images poses\nchallenges to the pretext tasks in contrastive learning, particularly in\nconstructing positive and negative pairs. We explore model performance under\ndifferent augmentation strategies and compare the results to those achieved\nwith strong augmentations. Our study includes six publicly available datasets\ncovering multiple clinically relevant tasks. We further assess the model's\ngeneralizability through external evaluations. The model pre-trained with weak\naugmentation outperforms those with strong augmentation, improving AUROC from\n0.838 to 0.848 and AUPR from 0.523 to 0.597 on MESSIDOR2, and showing similar\nenhancements across other datasets. Our findings suggest that optimizing the\nscale of augmentation is critical for enhancing the efficacy of contrastive\nlearning in medical imaging.",
      "tldr_zh": "本研究探讨了对比学习(Contrastive Learning)在视网膜成像中的应用问题，认为医疗图像的密集分布导致正负样本构建困难，从而影响模型性能。作者通过调整增强策略，从强增强转向弱增强，并使用六种公开数据集进行实验评估，包括外部泛化测试。结果显示，弱增强策略显著提升了模型表现，例如在MESSIDOR2数据集上，AUROC从0.838提高到0.848，AUPR从0.523提高到0.597，并在其他数据集上显示类似改善。该发现强调，优化增强规模是提升对比学习在医疗成像领域效能的关键因素。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02451v1",
      "published_date": "2025-01-05 06:08:08 UTC",
      "updated_date": "2025-01-05 06:08:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:41:14.905714"
    },
    {
      "arxiv_id": "2501.02446v1",
      "title": "RTLMarker: Protecting LLM-Generated RTL Copyright via a Hardware Watermarking Framework",
      "title_zh": "RTLMarker：通过硬件水印框架保护 LLM 生成的 RTL 版权",
      "authors": [
        "Kun Wang",
        "Kaiyan Chang",
        "Mengdi Wang",
        "Xinqi Zou",
        "Haobo Xu",
        "Yinhe Han",
        "Ying Wang"
      ],
      "abstract": "Recent advances of large language models in the field of Verilog generation\nhave raised several ethical and security concerns, such as code copyright\nprotection and dissemination of malicious code. Researchers have employed\nwatermarking techniques to identify codes generated by large language models.\nHowever, the existing watermarking works fail to protect RTL code copyright due\nto the significant syntactic and semantic differences between RTL code and\nsoftware code in languages such as Python. This paper proposes a hardware\nwatermarking framework RTLMarker that embeds watermarks into RTL code and\ndeeper into the synthesized netlist. We propose a set of rule-based Verilog\ncode transformations , ensuring the watermarked RTL code's syntactic and\nsemantic correctness. In addition, we consider an inherent tradeoff between\nwatermark transparency and watermark effectiveness and jointly optimize them.\nThe results demonstrate RTLMarker's superiority over the baseline in RTL code\nwatermarking.",
      "tldr_zh": "该论文提出RTLMarker，一种硬件水印框架，用于保护大型语言模型(LLM)生成的RTL代码版权，以应对代码版权和恶意代码传播的伦理安全问题。不同于现有水印技术，RTLMarker通过一套基于规则的Verilog代码转换，将水印嵌入RTL代码并延伸到合成的netlist，同时确保代码的语法和语义正确性。论文还优化了水印透明度与有效性之间的权衡，最终结果显示RTLMarker在RTL代码水印方面显著优于基线模型。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02446v1",
      "published_date": "2025-01-05 05:38:28 UTC",
      "updated_date": "2025-01-05 05:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:41:25.326376"
    },
    {
      "arxiv_id": "2501.02441v1",
      "title": "A Statistical Hypothesis Testing Framework for Data Misappropriation Detection in Large Language Models",
      "title_zh": "一种用于大型语言模型中数据盗用检测的统计假设检验框架",
      "authors": [
        "Yinpeng Cai",
        "Lexin Li",
        "Linjun Zhang"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly gaining enormous popularity in\nrecent years. However, the training of LLMs has raised significant privacy and\nlegal concerns, particularly regarding the inclusion of copyrighted materials\nin their training data without proper attribution or licensing, which falls\nunder the broader issue of data misappropriation. In this article, we focus on\na specific problem of data misappropriation detection, namely, to determine\nwhether a given LLM has incorporated data generated by another LLM. To address\nthis issue, we propose embedding watermarks into the copyrighted training data\nand formulating the detection of data misappropriation as a hypothesis testing\nproblem. We develop a general statistical testing framework, construct a\npivotal statistic, determine the optimal rejection threshold, and explicitly\ncontrol the type I and type II errors. Furthermore, we establish the asymptotic\noptimality properties of the proposed tests, and demonstrate its empirical\neffectiveness through intensive numerical experiments.",
      "tldr_zh": "这篇论文提出了一种统计假设测试框架，用于检测Large Language Models (LLMs) 是否误用了其他LLM生成的数据，从而解决训练数据中的隐私和法律问题。方法包括在版权训练数据中嵌入watermarks，并将检测问题转化为hypothesis testing形式。论文构建了pivotal statistic、确定了optimal rejection threshold，并明确控制type I and type II errors，同时建立了测试的asymptotic optimality properties。通过数值实验，证明了该框架的有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "29 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.02441v1",
      "published_date": "2025-01-05 04:47:42 UTC",
      "updated_date": "2025-01-05 04:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:41:37.918561"
    },
    {
      "arxiv_id": "2501.03273v1",
      "title": "Strategic Fusion Optimizes Transformer Compression",
      "title_zh": "战略融合优化 Transformer 压缩",
      "authors": [
        "Md Shoaibur Rahman"
      ],
      "abstract": "This study investigates transformer model compression by systematically\npruning its layers. We evaluated 14 pruning strategies across nine diverse\ndatasets, including 12 strategies based on different signals obtained from\nlayer activations, mutual information, gradients, weights, and attention. To\naddress the limitations of single-signal strategies, we introduced two fusion\nstrategies, linear regression and random forest, which combine individual\nstrategies (i.e., strategic fusion), for more informed pruning decisions.\nAdditionally, we applied knowledge distillation to mitigate any accuracy loss\nduring layer pruning. Our results reveal that random forest strategic fusion\noutperforms individual strategies in seven out of nine datasets and achieves\nnear-optimal performance in the other two. The distilled random forest\nsurpasses the original accuracy in six datasets and mitigates accuracy drops in\nthe remaining three. Knowledge distillation also improves the accuracy-to-size\nratio by an average factor of 18.84 across all datasets. Supported by\nmathematical foundations and biological analogies, our findings suggest that\nstrategically combining multiple signals can lead to efficient, high-performing\ntransformer models for resource-constrained applications.",
      "tldr_zh": "本研究系统评估了14种Transformer模型层修剪策略，包括基于层激活、互信息、梯度、权重和注意力的12种策略，并引入线性回归和随机森林的strategic fusion方法来结合多个信号进行更优化的修剪决策。实验在九个多样化数据集上显示，random forest strategic fusion在七个数据集上优于单个策略，并在其他两个上接近最佳表现。应用knowledge distillation后，该方法在六个数据集上超过了原始准确性，并在剩余三个上减少了准确性损失，同时将准确性与模型大小的比率平均提高了18.84倍，证明了战略融合在资源受限应用中的高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 1 table, 8 figures; will be submitted to ICML 2025; codes\n  will be made public after acceptance",
      "pdf_url": "http://arxiv.org/pdf/2501.03273v1",
      "published_date": "2025-01-05 04:46:14 UTC",
      "updated_date": "2025-01-05 04:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:41:50.703806"
    },
    {
      "arxiv_id": "2501.02438v1",
      "title": "Efficient Deployment of Large Language Models on Resource-constrained Devices",
      "title_zh": "大型语言模型在资源受限设备上的高效部署",
      "authors": [
        "Zhiwei Yao",
        "Yang Xu",
        "Hongli Xu",
        "Yunming Liao",
        "Zuan Xie"
      ],
      "abstract": "Deploying Large Language Models (LLMs) on resource-constrained (or weak)\ndevices presents significant challenges due to limited resources and\nheterogeneous data distribution. To address the data concern, it is necessary\nto fine-tune LLMs using on-device private data for various downstream tasks.\nWhile Federated Learning (FL) offers a promising privacy-preserving solution,\nexisting fine-tuning methods retain the original LLM size, leaving issues of\nhigh inference latency and excessive memory demands unresolved. Hence, we\ndesign FedSpine, an FL framework that combines Parameter- Efficient Fine-Tuning\n(PEFT) with structured pruning for efficient deployment of LLMs on\nresource-constrained devices. Specifically, FedSpine introduces an iterative\nprocess to prune and tune the parameters of LLMs. To mitigate the impact of\ndevice heterogeneity, an online Multi-Armed Bandit (MAB) algorithm is employed\nto adaptively determine different pruning ratios and LoRA ranks for\nheterogeneous devices without any prior knowledge of their computing and\ncommunication capabilities. As a result, FedSpine maintains higher inference\naccuracy while improving fine-tuning efficiency. Experimental results conducted\non a physical platform with 80 devices demonstrate that FedSpine can speed up\nfine-tuning by 1.4$\\times$-6.9$\\times$ and improve final accuracy by 0.4%-4.5%\nunder the same sparsity level compared to other baselines.",
      "tldr_zh": "这篇论文提出 FedSpine 框架，用于在资源受限设备上高效部署 Large Language Models (LLMs)，通过结合 Parameter-Efficient Fine-Tuning (PEFT) 和结构化剪枝来解决高延迟和内存需求问题，同时利用 Federated Learning (FL) 保护隐私。FedSpine 采用迭代过程剪枝和微调参数，并引入 Multi-Armed Bandit (MAB) 算法动态调整剪枝比例和 LoRA ranks，以适应设备异构性，而无需事先了解设备能力。实验结果显示，在包含 80 台设备的物理平台上，FedSpine 相比基线方法加速微调 1.4×-6.9×，并在相同稀疏度下提高准确率 0.4%-4.5%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02438v1",
      "published_date": "2025-01-05 04:38:11 UTC",
      "updated_date": "2025-01-05 04:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:44:03.699239"
    },
    {
      "arxiv_id": "2501.03272v1",
      "title": "Backdoor Token Unlearning: Exposing and Defending Backdoors in Pretrained Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peihai Jiang",
        "Xixiang Lyu",
        "Yige Li",
        "Jing Ma"
      ],
      "abstract": "Supervised fine-tuning has become the predominant method for adapting large\npretrained models to downstream tasks. However, recent studies have revealed\nthat these models are vulnerable to backdoor attacks, where even a small number\nof malicious samples can successfully embed backdoor triggers into the model.\nWhile most existing defense methods focus on post-training backdoor defense,\nefficiently defending against backdoor attacks during training phase remains\nlargely unexplored. To address this gap, we propose a novel defense method\ncalled Backdoor Token Unlearning (BTU), which proactively detects and\nneutralizes trigger tokens during the training stage. Our work is based on two\nkey findings: 1) backdoor learning causes distinctive differences between\nbackdoor token parameters and clean token parameters in word embedding layers,\nand 2) the success of backdoor attacks heavily depends on backdoor token\nparameters. The BTU defense leverages these properties to identify aberrant\nembedding parameters and subsequently removes backdoor behaviors using a\nfine-grained unlearning technique. Extensive evaluations across three datasets\nand four types of backdoor attacks demonstrate that BTU effectively defends\nagainst these threats while preserving the model's performance on primary\ntasks. Our code is available at https://github.com/XDJPH/BTU.",
      "tldr_zh": "该研究针对预训练语言模型在监督微调过程中易受 backdoor attacks 的问题，提出了一种新防御方法 Backdoor Token Unlearning (BTU)。BTU 在训练阶段主动检测后门标记参数与干净参数在词嵌入层中的显著差异，并使用细粒度 unlearning 技术中和这些触发器标记，从而移除后门行为。实验结果显示，BTU 在三个数据集和四种 backdoor attacks 类型上有效防御攻击，同时保持模型在主要任务上的性能，为模型安全提供了高效解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.03272v1",
      "published_date": "2025-01-05 03:22:13 UTC",
      "updated_date": "2025-01-05 03:22:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:42:14.273971"
    },
    {
      "arxiv_id": "2501.02409v2",
      "title": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Zaikang Lin",
        "Sei Chang",
        "Aaron Zweig",
        "Minseo Kang",
        "Elham Azizi",
        "David A. Knowles"
      ],
      "abstract": "Modern high-throughput biological datasets with thousands of perturbations\nprovide the opportunity for large-scale discovery of causal graphs that\nrepresent the regulatory interactions between genes. Differentiable causal\ngraphical models have been proposed to infer a gene regulatory network (GRN)\nfrom large scale interventional datasets, capturing the causal gene regulatory\nrelationships from genetic perturbations. However, existing models are limited\nin their expressivity and scalability while failing to address the dynamic\nnature of biological processes such as cellular differentiation. We propose\nPerturbODE, a novel framework that incorporates biologically informative neural\nordinary differential equations (neural ODEs) to model cell state trajectories\nunder perturbations and derive the causal GRN from the neural ODE's parameters.\nWe demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference\nacross simulated and real over-expression datasets.",
      "tldr_zh": "该研究针对基因调控网络 (GRN) 的发现问题，提出了一种名为 PerturbODE 的新框架，利用可解释的 Neural ODEs 来建模扰动下的细胞状态轨迹，并从 Neural ODEs 的参数中推导因果 GRN，以解决现有模型在表达性、可扩展性和动态生物过程处理方面的局限性。PerturbODE 能够捕捉基因间的调控相互作用，并适用于大规模干预数据集。实验结果显示，该框架在模拟和真实过表达数据集上表现出色，在轨迹预测和 GRN 推断方面取得了显著的效能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-bio.MN",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.02409v2",
      "published_date": "2025-01-05 01:04:23 UTC",
      "updated_date": "2025-02-01 05:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:42:26.150994"
    },
    {
      "arxiv_id": "2501.03271v3",
      "title": "DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Amitava Das",
        "Suranjana Trivedy",
        "Danush Khanna",
        "Rajarshi Roy",
        "Gurpreet Singh",
        "Basab Ghosh",
        "Yaswanth Narsupalli",
        "Vinija Jain",
        "Vasu Sharma",
        "Aishwarya Naresh Reganti",
        "Aman Chadha"
      ],
      "abstract": "The rapid rise of large language models (LLMs) has unlocked many applications\nbut also underscores the challenge of aligning them with diverse values and\npreferences. Direct Preference Optimization (DPO) is central to alignment but\nconstrained by fixed divergences and limited feature transformations. We\npropose DPO-Kernels, which integrates kernel methods to address these issues\nthrough four key contributions: (i) Kernelized Representations with polynomial,\nRBF, Mahalanobis, and spectral kernels for richer transformations, plus a\nhybrid loss combining embedding-based and probability-based objectives; (ii)\nDivergence Alternatives (Jensen-Shannon, Hellinger, Renyi, Bhattacharyya,\nWasserstein, and f-divergences) for greater stability; (iii) Data-Driven\nSelection metrics that automatically choose the best kernel-divergence pair;\nand (iv) a Hierarchical Mixture of Kernels for both local precision and global\nmodeling. Evaluations on 12 datasets demonstrate state-of-the-art performance\nin factuality, safety, reasoning, and instruction following. Grounded in\nHeavy-Tailed Self-Regularization, DPO-Kernels maintains robust generalization\nfor LLMs, offering a comprehensive resource for further alignment research.",
      "tldr_zh": "本研究提出 DPO Kernels，一种语义感知、基于核增强且差异度丰富的范式，用于改进 Direct Preference Optimization (DPO)，以更好地将大语言模型 (LLMs) 与多样化偏好对齐。该框架的关键创新包括：采用多项式、RBF、Mahalanobis 和谱 kernels 等核化表示结合混合损失、引入 Jensen-Shannon、Hellinger、Renyi、Bhattacharyya、Wasserstein 和 f-divergences 等替代差异度、数据驱动的核-差异对选择机制，以及分层混合核以实现局部精确和全局建模。实验在 12 个数据集上显示，DPO Kernels 在事实性、安全性、推理和指令遵循方面达到最先进性能，并基于 Heavy-Tailed Self-Regularization 确保 LLMs 的鲁棒泛化，为模型对齐研究提供全面资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T45"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.03271v3",
      "published_date": "2025-01-05 00:08:52 UTC",
      "updated_date": "2025-01-20 04:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T20:42:40.882728"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 46,
  "processed_papers_count": 46,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T20:44:24.108789"
}