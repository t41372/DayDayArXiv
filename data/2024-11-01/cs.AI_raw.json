[
  {
    "arxiv_id": "2411.01081v2",
    "title": "Towards efficient and secure quantum-classical communication networks",
    "authors": [
      "Pei Zeng",
      "Debayan Bandyopadhyay",
      "José A. Méndez Méndez",
      "Nolan Bitner",
      "Alexander Kolar",
      "Michael T. Solomon",
      "F. Joseph Heremans",
      "David D. Awschalom",
      "Liang Jiang",
      "Junyu Liu"
    ],
    "abstract": "The rapid advancement of quantum technologies calls for the design and\ndeployment of quantum-safe cryptographic protocols and communication networks.\nThere are two primary approaches to achieving quantum-resistant security:\nquantum key distribution (QKD) and post-quantum cryptography (PQC). While each\noffers unique advantages, both have drawbacks in practical implementation. In\nthis work, we introduce the pros and cons of these protocols and explore how\nthey can be combined to achieve a higher level of security and/or improved\nperformance in key distribution. We hope our discussion inspires further\nresearch into the design of hybrid cryptographic protocols for\nquantum-classical communication networks.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "quant-ph",
    "comment": "4 pages, a blue print paper, Submission for IEEE 2024 IEEE Workshop\n  on Quantum IntelLigence, Learning & Security (QUILLS),\n  https://sites.google.com/pitt.edu/quills/home",
    "pdf_url": "http://arxiv.org/pdf/2411.01081v2",
    "published_date": "2024-11-01 23:36:19 UTC",
    "updated_date": "2024-11-05 17:23:30 UTC"
  },
  {
    "arxiv_id": "2411.01078v3",
    "title": "Effective ML Model Versioning in Edge Networks",
    "authors": [
      "Fin Gentzen",
      "Mounir Bensalem",
      "Admela Jukan"
    ],
    "abstract": "Machine learning (ML) models, data and software need to be regularly updated\nwhenever essential version updates are released and feasible for integration.\nThis is a basic but most challenging requirement to satisfy in the edge, due to\nthe various system constraints and the major impact that an update can have on\nrobustness and stability. In this paper, we formulate for the first time the ML\nmodel versioning optimization problem, and propose effective solutions,\nincluding the update automation with reinforcement learning (RL) based\nalgorithm. We study the edge network environment due to the known constraints\nin performance, response time, security, and reliability, which make updates\nespecially challenging. The performance study shows that model version updates\ncan be fully and effectively automated with reinforcement learning method. We\nshow that for every range of server load values, the proper versioning can be\nfound that improves security, reliability and/or ML model accuracy, while\nassuring a comparably lower response time.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes",
    "pdf_url": "http://arxiv.org/pdf/2411.01078v3",
    "published_date": "2024-11-01 23:19:05 UTC",
    "updated_date": "2024-11-13 11:10:18 UTC"
  },
  {
    "arxiv_id": "2411.01076v2",
    "title": "Privacy Risks of Speculative Decoding in Large Language Models",
    "authors": [
      "Jiankun Wei",
      "Abdulrahman Abdulrazzag",
      "Tianchen Zhang",
      "Adel Muursepp",
      "Gururaj Saileshwar"
    ],
    "abstract": "Speculative decoding in large language models (LLMs) accelerates token\ngeneration by speculatively predicting multiple tokens cheaply and verifying\nthem in parallel, and has been widely deployed. In this paper, we provide the\nfirst study demonstrating the privacy risks of speculative decoding. We observe\nthat input-dependent patterns of correct and incorrect predictions can be\nleaked out to an adversary monitoring token generation times and packet sizes,\nleading to privacy breaches. By observing the pattern of correctly and\nincorrectly speculated tokens, we show that a malicious adversary can\nfingerprint queries and learn private user inputs with more than $90\\%$\naccuracy across three different speculative decoding techniques - REST (almost\n$100\\%$ accuracy), LADE (up to $92\\%$ accuracy), and BiLD (up to $95\\%$\naccuracy). We show that an adversary can also leak out confidential\nintellectual property used to design these techniques, such as data from\ndata-stores used for prediction (in REST) at a rate of more than $25$ tokens\nper second, or even hyper-parameters used for prediction (in LADE). We also\ndiscuss mitigation strategies, such as aggregating tokens across multiple\niterations and padding packets with additional bytes, to avoid such privacy or\nconfidentiality breaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01076v2",
    "published_date": "2024-11-01 23:14:30 UTC",
    "updated_date": "2024-11-05 15:03:45 UTC"
  },
  {
    "arxiv_id": "2411.01073v1",
    "title": "AttackQA: Development and Adoption of a Dataset for Assisting Cybersecurity Operations using Fine-tuned and Open-Source LLMs",
    "authors": [
      "Varun Badrinath Krishna"
    ],
    "abstract": "Retrieval-augmented generation (RAG) on specialized domain datasets has shown\nimproved performance when large language models (LLMs) are fine-tuned for\ngenerating responses to user queries. In this study, we develop a cybersecurity\nquestion-answering (Q\\&A) dataset, called AttackQA, and employ it to build a\nRAG-based Q\\&A system designed for analysts in security operations centers. The\ndataset comprises 25,335 Q\\&A pairs, accompanied by rationales to facilitate\nfine-tuning and evaluation. 80\\% of the dataset was generated with help of a\nlightweight open-source LLM (LLama 3 8B), which produced over 1100 tokens per\nsecond with full 16-bit precision on SambaNova System's SN40L specialized\nhardware. To ensure dataset quality, we fine-tuned LLama 3 70B to detect and\nreject low-quality Q\\&A pairs. In using the dataset for RAG, we demonstrate\nthat fine-tuning open-source embeddings and LLMs can yield superior accuracy\ncompared to OpenAI's state-of-the-art proprietary embedding and LLM (GPT-4o).\nFurthermore, we use Llama 3.1 405B as a judge to evaluate answer correctness,\nenabling the creation of a fully open-source, high-speed RAG and evaluation\npipeline with a benchmark for model accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01073v1",
    "published_date": "2024-11-01 23:03:40 UTC",
    "updated_date": "2024-11-01 23:03:40 UTC"
  },
  {
    "arxiv_id": "2411.01063v2",
    "title": "InterTrans: Leveraging Transitive Intermediate Translations to Enhance LLM-based Code Translation",
    "authors": [
      "Marcos Macedo",
      "Yuan Tian",
      "Pengyu Nie",
      "Filipe R. Cogo",
      "Bram Adams"
    ],
    "abstract": "Code translation aims to convert a program from one programming language (PL)\nto another. This long-standing software engineering task is crucial for\nmodernizing legacy systems, ensuring cross-platform compatibility, enhancing\nperformance, and more. However, automating this process remains challenging due\nto many syntactic and semantic differences between PLs. Recent studies show\nthat even advanced techniques such as large language models (LLMs), especially\nopen-source LLMs, still struggle with the task. Currently, code LLMs are\ntrained with source code from multiple programming languages, thus presenting\nmultilingual capabilities.\n  In this paper, we investigate whether such multilingual capabilities can be\nharnessed to enhance code translation. To achieve this goal, we introduce\nInterTrans, an LLM-based automated code translation approach that, in contrast\nto existing approaches, leverages intermediate translations across PLs to\nbridge the syntactic and semantic gaps between source and target PLs.\n  InterTrans contains two stages. It first utilizes a novel Tree of Code\nTranslation (ToCT) algorithm to plan transitive intermediate translation\nsequences between a given source and target PL, then validates them in a\nspecific order. We evaluate InterTrans with three open LLMs on three benchmarks\n(i.e., CodeNet, HumanEval-X, and TransCoder) involving six PLs. Results show an\nabsolute improvement between 18.3% to 43.3% in Computation Accuracy (CA) for\nInterTrans over Direct Translation with 10 attempts. The best-performing\nvariant of InterTrans (with Magicoder LLM) achieved an average CA of\n87.3%-95.4% on three benchmarks.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01063v2",
    "published_date": "2024-11-01 22:31:32 UTC",
    "updated_date": "2024-11-05 04:21:55 UTC"
  },
  {
    "arxiv_id": "2411.01055v2",
    "title": "Combining Physics-based and Data-driven Modeling for Building Energy Systems",
    "authors": [
      "Leandro Von Krannichfeldt",
      "Kristina Orehounig",
      "Olga Fink"
    ],
    "abstract": "Building energy modeling plays a vital role in optimizing the operation of\nbuilding energy systems by providing accurate predictions of the building's\nreal-world conditions. In this context, various techniques have been explored,\nranging from traditional physics-based models to data-driven models. Recently,\nresearchers are combining physics-based and data-driven models into hybrid\napproaches. This includes using the physics-based model output as additional\ndata-driven input, learning the residual between physics-based model and real\ndata, learning a surrogate of the physics-based model, or fine-tuning a\nsurrogate model with real data. However, a comprehensive comparison of the\ninherent advantages of these hybrid approaches is still missing. The primary\nobjective of this work is to evaluate four predominant hybrid approaches in\nbuilding energy modeling through a real-world case study, with focus on indoor\nthermodynamics. To achieve this, we devise three scenarios reflecting common\nlevels of building documentation and sensor availability, assess their\nperformance, and analyze their explainability using hierarchical Shapley\nvalues. The real-world study reveals three notable findings. First, greater\nbuilding documentation and sensor availability lead to higher prediction\naccuracy for hybrid approaches. Second, the performance of hybrid approaches\ndepends on the type of building room, but the residual approach using a\nFeedforward Neural Network as data-driven sub-model performs best on average\nacross all rooms. This hybrid approach also demonstrates a superior ability to\nleverage the simulation from the physics-based sub-model. Third, hierarchical\nShapley values prove to be an effective tool for explaining and improving\nhybrid models while accounting for input correlations.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01055v2",
    "published_date": "2024-11-01 21:56:39 UTC",
    "updated_date": "2025-04-23 06:45:11 UTC"
  },
  {
    "arxiv_id": "2411.01053v1",
    "title": "Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities",
    "authors": [
      "Adriel Saporta",
      "Aahlad Puli",
      "Mark Goldstein",
      "Rajesh Ranganath"
    ],
    "abstract": "Contrastive learning methods, such as CLIP, leverage naturally paired\ndata-for example, images and their corresponding text captions-to learn general\nrepresentations that transfer efficiently to downstream tasks. While such\napproaches are generally applied to two modalities, domains such as robotics,\nhealthcare, and video need to support many types of data at once. We show that\nthe pairwise application of CLIP fails to capture joint information between\nmodalities, thereby limiting the quality of the learned representations. To\naddress this issue, we present Symile, a simple contrastive learning approach\nthat captures higher-order information between any number of modalities. Symile\nprovides a flexible, architecture-agnostic objective for learning\nmodality-specific representations. To develop Symile's objective, we derive a\nlower bound on total correlation, and show that Symile representations for any\nset of modalities form a sufficient statistic for predicting the remaining\nmodalities. Symile outperforms pairwise CLIP, even with modalities missing in\nthe data, on cross-modal classification and retrieval across several\nexperiments including on an original multilingual dataset of 33M image, text\nand audio samples and a clinical dataset of chest X-rays, electrocardiograms,\nand laboratory measurements. All datasets and code used in this work are\npublicly available at https://github.com/rajesh-lab/symile.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01053v1",
    "published_date": "2024-11-01 21:49:25 UTC",
    "updated_date": "2024-11-01 21:49:25 UTC"
  },
  {
    "arxiv_id": "2411.01050v1",
    "title": "BACSA: A Bias-Aware Client Selection Algorithm for Privacy-Preserving Federated Learning in Wireless Healthcare Networks",
    "authors": [
      "Sushilkumar Yadav",
      "Irem Bor-Yaliniz"
    ],
    "abstract": "Federated Learning (FL) has emerged as a transformative approach in\nhealthcare, enabling collaborative model training across decentralized data\nsources while preserving user privacy. However, performance of FL rapidly\ndegrades in practical scenarios due to the inherent bias in non Independent and\nIdentically distributed (non-IID) data among participating clients, which poses\nsignificant challenges to model accuracy and generalization. Therefore, we\npropose the Bias-Aware Client Selection Algorithm (BACSA), which detects user\nbias and strategically selects clients based on their bias profiles. In\naddition, the proposed algorithm considers privacy preservation, fairness and\nconstraints of wireless network environments, making it suitable for sensitive\nhealthcare applications where Quality of Service (QoS), privacy and security\nare paramount. Our approach begins with a novel method for detecting user bias\nby analyzing model parameters and correlating them with the distribution of\nclass-specific data samples. We then formulate a mixed-integer non-linear\nclient selection problem leveraging the detected bias, alongside wireless\nnetwork constraints, to optimize FL performance. We demonstrate that BACSA\nimproves convergence and accuracy, compared to existing benchmarks, through\nevaluations on various data distributions, including Dirichlet and\nclass-constrained scenarios. Additionally, we explore the trade-offs between\naccuracy, fairness, and network constraints, indicating the adaptability and\nrobustness of BACSA to address diverse healthcare applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01050v1",
    "published_date": "2024-11-01 21:34:43 UTC",
    "updated_date": "2024-11-01 21:34:43 UTC"
  },
  {
    "arxiv_id": "2411.01049v1",
    "title": "Exploratory Models of Human-AI Teams: Leveraging Human Digital Twins to Investigate Trust Development",
    "authors": [
      "Daniel Nguyen",
      "Myke C. Cohen",
      "Hsien-Te Kao",
      "Grant Engberson",
      "Louis Penafiel",
      "Spencer Lynch",
      "Svitlana Volkova"
    ],
    "abstract": "As human-agent teaming (HAT) research continues to grow, computational\nmethods for modeling HAT behaviors and measuring HAT effectiveness also\ncontinue to develop. One rising method involves the use of human digital twins\n(HDT) to approximate human behaviors and socio-emotional-cognitive reactions to\nAI-driven agent team members. In this paper, we address three research\nquestions relating to the use of digital twins for modeling trust in HATs.\nFirst, to address the question of how we can appropriately model and\noperationalize HAT trust through HDT HAT experiments, we conducted causal\nanalytics of team communication data to understand the impact of empathy,\nsocio-cognitive, and emotional constructs on trust formation. Additionally, we\nreflect on the current state of the HAT trust science to discuss\ncharacteristics of HAT trust that must be replicable by a HDT such as\nindividual differences in trust tendencies, emergent trust patterns, and\nappropriate measurement of these characteristics over time. Second, to address\nthe question of how valid measures of HDT trust are for approximating human\ntrust in HATs, we discuss the properties of HDT trust: self-report measures,\ninteraction-based measures, and compliance type behavioral measures.\nAdditionally, we share results of preliminary simulations comparing different\nLLM models for generating HDT communications and analyze their ability to\nreplicate human-like trust dynamics. Third, to address how HAT experimental\nmanipulations will extend to human digital twin studies, we share experimental\ndesign focusing on propensity to trust for HDTs vs. transparency and\ncompetency-based trust for AI agents.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "in review; submitted to Interaction Studies",
    "pdf_url": "http://arxiv.org/pdf/2411.01049v1",
    "published_date": "2024-11-01 21:32:11 UTC",
    "updated_date": "2024-11-01 21:32:11 UTC"
  },
  {
    "arxiv_id": "2411.01042v2",
    "title": "Introduction to AI Safety, Ethics, and Society",
    "authors": [
      "Dan Hendrycks"
    ],
    "abstract": "Artificial Intelligence is rapidly embedding itself within militaries,\neconomies, and societies, reshaping their very foundations. Given the depth and\nbreadth of its consequences, it has never been more pressing to understand how\nto ensure that AI systems are safe, ethical, and have a positive societal\nimpact. This book aims to provide a comprehensive approach to understanding AI\nrisk. Our primary goals include consolidating fragmented knowledge on AI risk,\nincreasing the precision of core ideas, and reducing barriers to entry by\nmaking content simpler and more comprehensible. The book has been designed to\nbe accessible to readers from diverse backgrounds. You do not need to have\nstudied AI, philosophy, or other such topics. The content is skimmable and\nsomewhat modular, so that you can choose which chapters to read. We introduce\nmathematical formulas in a few places to specify claims more precisely, but\nreaders should be able to understand the main points without these.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "603 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.01042v2",
    "published_date": "2024-11-01 21:21:49 UTC",
    "updated_date": "2024-11-15 23:19:18 UTC"
  },
  {
    "arxiv_id": "2411.01035v1",
    "title": "Provable Length Generalization in Sequence Prediction via Spectral Filtering",
    "authors": [
      "Annie Marsden",
      "Evan Dogariu",
      "Naman Agarwal",
      "Xinyi Chen",
      "Daniel Suo",
      "Elad Hazan"
    ],
    "abstract": "We consider the problem of length generalization in sequence prediction. We\ndefine a new metric of performance in this setting -- the Asymmetric-Regret --\nwhich measures regret against a benchmark predictor with longer context length\nthan available to the learner. We continue by studying this concept through the\nlens of the spectral filtering algorithm. We present a gradient-based learning\nalgorithm that provably achieves length generalization for linear dynamical\nsystems. We conclude with proof-of-concept experiments which are consistent\nwith our theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01035v1",
    "published_date": "2024-11-01 21:11:40 UTC",
    "updated_date": "2024-11-01 21:11:40 UTC"
  },
  {
    "arxiv_id": "2411.01034v2",
    "title": "Evaluation Metric for Quality Control and Generative Models in Histopathology Images",
    "authors": [
      "Pranav Jeevan",
      "Neeraj Nixon",
      "Abhijeet Patil",
      "Amit Sethi"
    ],
    "abstract": "Our study introduces ResNet-L2 (RL2), a novel metric for evaluating\ngenerative models and image quality in histopathology, addressing limitations\nof traditional metrics, such as Frechet inception distance (FID), when the data\nis scarce. RL2 leverages ResNet features with a normalizing flow to calculate\nRMSE distance in the latent space, providing reliable assessments across\ndiverse histopathology datasets. We evaluated the performance of RL2 on\ndegradation types, such as blur, Gaussian noise, salt-and-pepper noise, and\nrectangular patches, as well as diffusion processes. RL2's monotonic response\nto increasing degradation makes it well-suited for models that assess image\nquality, proving a valuable advancement for evaluating image generation\ntechniques in histopathology. It can also be used to discard low-quality\npatches while sampling from a whole slide image. It is also significantly\nlighter and faster compared to traditional metrics and requires fewer images to\ngive stable metric value.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "q-bio.QM",
      "I.2.1; I.4.0; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; I.5.5; J.3;\n  I.2.10; I.4.4; I.4.3; I.4.5; I.4.1; I.4.2; I.4.6; I.4.7"
    ],
    "primary_category": "eess.IV",
    "comment": "7 pages, 5 figures. Accepted in ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.01034v2",
    "published_date": "2024-11-01 21:09:02 UTC",
    "updated_date": "2025-01-02 21:07:16 UTC"
  },
  {
    "arxiv_id": "2411.01030v5",
    "title": "Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula",
    "authors": [
      "Sam Blouir",
      "Jimmy T. H. Smith",
      "Antonios Anastasopoulos",
      "Amarda Shehu"
    ],
    "abstract": "Efficient state space models (SSMs), such as linear recurrent neural networks\nand linear attention variants, offer computational advantages over Transformers\nbut struggle with tasks requiring long-range in-context retrieval-like text\ncopying, associative recall, and question answering over long contexts.\nPrevious efforts to address these challenges have focused on architectural\nmodifications, often reintroducing computational inefficiencies. In this paper,\nwe propose a novel training procedure, Birdie, that significantly enhances the\nin-context retrieval capabilities of SSMs without altering their architecture.\nOur approach combines bidirectional input processing with dynamic mixtures of\nspecialized pre-training objectives, optimized via reinforcement learning. We\nintroduce a new bidirectional SSM architecture that seamlessly transitions from\nbidirectional context processing to causal generation. Experimental evaluations\ndemonstrate that Birdie markedly improves performance on retrieval-intensive\ntasks such as multi-number phone book lookup, long paragraph\nquestion-answering, and infilling. This narrows the performance gap with\nTransformers, while retaining computational efficiency. Our findings highlight\nthe importance of training procedures in leveraging the fixed-state capacity of\nSSMs, offering a new direction to advance their capabilities. All code and\npre-trained models are available at https://www.github.com/samblouir/birdie,\nwith support for JAX and PyTorch.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 (Main Conference)",
    "pdf_url": "http://arxiv.org/pdf/2411.01030v5",
    "published_date": "2024-11-01 21:01:13 UTC",
    "updated_date": "2025-02-21 21:13:57 UTC"
  },
  {
    "arxiv_id": "2411.01029v1",
    "title": "Semi-Strongly solved: a New Definition Leading Computer to Perfect Gameplay",
    "authors": [
      "Hiroki Takizawa"
    ],
    "abstract": "Solving combinatorial games has been a classic research topic in artificial\nintelligence because solutions can offer essential information to improve\ngameplay. Several definitions exist for `solving the game,' but they are\nmarkedly different regarding computational cost and the detail of insights\nderived. In this study, we introduce a novel definition called `semi-strongly\nsolved' and propose an algorithm to achieve this type of solution efficiently.\nThis new definition addresses existing gaps because of its intermediate\ncomputational cost and the quality of the solution. To demonstrate the\npotential of our approach, we derive the theoretical computational complexity\nof our algorithm under a simple condition, and apply it to semi-strongly solve\nthe game of 6x6 Othello. This study raises many new research goals in this\nresearch area.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01029v1",
    "published_date": "2024-11-01 21:00:46 UTC",
    "updated_date": "2024-11-01 21:00:46 UTC"
  },
  {
    "arxiv_id": "2411.01023v1",
    "title": "Capturing and Anticipating User Intents in Data Analytics via Knowledge Graphs",
    "authors": [
      "Gerard Pons",
      "Besim Bilalli",
      "Anna Queralt"
    ],
    "abstract": "In today's data-driven world, the ability to extract meaningful information\nfrom data is becoming essential for businesses, organizations and researchers\nalike. For that purpose, a wide range of tools and systems exist addressing\ndata-related tasks, from data integration, preprocessing and modeling, to the\ninterpretation and evaluation of the results. As data continues to grow in\nvolume, variety, and complexity, there is an increasing need for advanced but\nuser-friendly tools, such as intelligent discovery assistants (IDAs) or\nautomated machine learning (AutoML) systems, that facilitate the user's\ninteraction with the data. This enables non-expert users, such as citizen data\nscientists, to leverage powerful data analytics techniques effectively. The\nassistance offered by IDAs or AutoML tools should not be guided only by the\nanalytical problem's data but should also be tailored to each individual user.\nTo this end, this work explores the usage of Knowledge Graphs (KG) as a basic\nframework for capturing in a human-centered manner complex analytics workflows,\nby storing information not only about the workflow's components, datasets and\nalgorithms but also about the users, their intents and their feedback, among\nothers. The data stored in the generated KG can then be exploited to provide\nassistance (e.g., recommendations) to the users interacting with these systems.\nTo accomplish this objective, two methods are explored in this work. Initially,\nthe usage of query templates to extract relevant information from the KG is\nstudied. However, upon identifying its main limitations, the usage of link\nprediction with knowledge graph embeddings is explored, which enhances\nflexibility and allows leveraging the entire structure and components of the\ngraph. The experiments show that the proposed method is able to capture the\ngraph's structure and to produce sensible suggestions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Pre-print submitted to Knowledge-Based Systems",
    "pdf_url": "http://arxiv.org/pdf/2411.01023v1",
    "published_date": "2024-11-01 20:45:23 UTC",
    "updated_date": "2024-11-01 20:45:23 UTC"
  },
  {
    "arxiv_id": "2411.01016v1",
    "title": "MoE-I$^2$: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition",
    "authors": [
      "Cheng Yang",
      "Yang Sui",
      "Jinqi Xiao",
      "Lingyi Huang",
      "Yu Gong",
      "Yuanlin Duan",
      "Wenqi Jia",
      "Miao Yin",
      "Yu Cheng",
      "Bo Yuan"
    ],
    "abstract": "The emergence of Mixture of Experts (MoE) LLMs has significantly advanced the\ndevelopment of language models. Compared to traditional LLMs, MoE LLMs\noutperform traditional LLMs by achieving higher performance with considerably\nfewer activated parameters. Despite this efficiency, their enormous parameter\nsize still leads to high deployment costs. In this paper, we introduce a\ntwo-stage compression method tailored for MoE to reduce the model size and\ndecrease the computational cost. First, in the inter-expert pruning stage, we\nanalyze the importance of each layer and propose the Layer-wise Genetic Search\nand Block-wise KT-Reception Field with the non-uniform pruning ratio to prune\nthe individual expert. Second, in the intra-expert decomposition stage, we\napply the low-rank decomposition to further compress the parameters within the\nremaining experts. Extensive experiments on Qwen1.5-MoE-A2.7B,\nDeepSeek-V2-Lite, and Mixtral-8$\\times$7B demonstrate that our proposed methods\ncan both reduce the model size and enhance inference efficiency while\nmaintaining performance in various zero-shot tasks. The code will be available\nat \\url{https://github.com/xiaochengsky/MoEI-2.git}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01016v1",
    "published_date": "2024-11-01 20:37:58 UTC",
    "updated_date": "2024-11-01 20:37:58 UTC"
  },
  {
    "arxiv_id": "2411.01013v3",
    "title": "A Similarity-Based Oversampling Method for Multi-label Imbalanced Text Data",
    "authors": [
      "Ismail Hakki Karaman",
      "Gulser Koksal",
      "Levent Eriskin",
      "Salih Salihoglu"
    ],
    "abstract": "In real-world applications, as data availability increases, obtaining labeled\ndata for machine learning (ML) projects remains challenging due to the high\ncosts and intensive efforts required for data annotation. Many ML projects,\nparticularly those focused on multi-label classification, also grapple with\ndata imbalance issues, where certain classes may lack sufficient data to train\neffective classifiers. This study introduces and examines a novel oversampling\nmethod for multi-label text classification, designed to address performance\nchallenges associated with data imbalance. The proposed method identifies\npotential new samples from unlabeled data by leveraging similarity measures\nbetween instances. By iteratively searching the unlabeled dataset, the method\nlocates instances similar to those in underrepresented classes and evaluates\ntheir contribution to classifier performance enhancement. Instances that\ndemonstrate performance improvement are then added to the labeled dataset.\nExperimental results indicate that the proposed approach effectively enhances\nclassifier performance post-oversampling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01013v3",
    "published_date": "2024-11-01 20:33:49 UTC",
    "updated_date": "2024-12-21 15:03:29 UTC"
  },
  {
    "arxiv_id": "2411.00997v1",
    "title": "Identifying Implicit Social Biases in Vision-Language Models",
    "authors": [
      "Kimia Hamidieh",
      "Haoran Zhang",
      "Walter Gerych",
      "Thomas Hartvigsen",
      "Marzyeh Ghassemi"
    ],
    "abstract": "Vision-language models, like CLIP (Contrastive Language Image Pretraining),\nare becoming increasingly popular for a wide range of multimodal retrieval\ntasks. However, prior work has shown that large language and deep vision models\ncan learn historical biases contained in their training sets, leading to\nperpetuation of stereotypes and potential downstream harm. In this work, we\nconduct a systematic analysis of the social biases that are present in CLIP,\nwith a focus on the interaction between image and text modalities. We first\npropose a taxonomy of social biases called So-B-IT, which contains 374 words\ncategorized across ten types of bias. Each type can lead to societal harm if\nassociated with a particular demographic group. Using this taxonomy, we examine\nimages retrieved by CLIP from a facial image dataset using each word as part of\na prompt. We find that CLIP frequently displays undesirable associations\nbetween harmful words and specific demographic groups, such as retrieving\nmostly pictures of Middle Eastern men when asked to retrieve images of a\n\"terrorist\". Finally, we conduct an analysis of the source of such biases, by\nshowing that the same harmful stereotypes are also present in a large\nimage-text dataset used to train CLIP models for examples of biases that we\nfind. Our findings highlight the importance of evaluating and addressing bias\nin vision-language models, and suggest the need for transparency and\nfairness-aware curation of large pre-training datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00997v1",
    "published_date": "2024-11-01 19:41:28 UTC",
    "updated_date": "2024-11-01 19:41:28 UTC"
  },
  {
    "arxiv_id": "2411.00983v1",
    "title": "Improving How Agents Cooperate: Attention Schemas in Artificial Neural Networks",
    "authors": [
      "Kathryn T. Farrell",
      "Kirsten Ziman",
      "Michael S. A. Graziano"
    ],
    "abstract": "Growing evidence suggests that the brain uses an \"attention schema\" to\nmonitor, predict, and help control attention. It has also been suggested that\nan attention schema improves social intelligence by allowing one person to\nbetter predict another. Given their potential advantages, attention schemas\nhave been increasingly tested in machine learning. Here we test small deep\nlearning networks to determine how the addition of an attention schema may\naffect performance on a range of tasks. First, we found that an agent with an\nattention schema is better at judging or categorizing the attention states of\nother agents. Second, we found that an agent with an attention schema develops\na pattern of attention that is easier for other agents to judge and categorize.\nThird, we found that in a joint task where two agents paint a scene together\nand must predict each other's behavior for best performance, adding an\nattention schema improves that performance. Finally, we find that the\nperformance improvements caused by an attention schema are not a non-specific\nresult of an increase in network complexity. Not all performance, on all tasks,\nis improved. Instead, improvement is specific to \"social\" tasks involving\njudging, categorizing, or predicting the attention of other agents. These\nresults suggest that an attention schema may be useful in machine learning for\nimproving cooperativity and social behavior.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00983v1",
    "published_date": "2024-11-01 19:18:07 UTC",
    "updated_date": "2024-11-01 19:18:07 UTC"
  },
  {
    "arxiv_id": "2411.03887v2",
    "title": "OML: Open, Monetizable, and Loyal AI",
    "authors": [
      "Zerui Cheng",
      "Edoardo Contente",
      "Ben Finch",
      "Oleg Golev",
      "Jonathan Hayase",
      "Andrew Miller",
      "Niusha Moshrefi",
      "Anshul Nasery",
      "Sandeep Nailwal",
      "Sewoong Oh",
      "Himanshu Tyagi",
      "Pramod Viswanath"
    ],
    "abstract": "Artificial Intelligence (AI) has steadily improved across a wide range of\ntasks. However, the development and deployment of AI are almost entirely\ncontrolled by a few powerful organizations that are racing to create Artificial\nGeneral Intelligence (AGI). The centralized entities make decisions with little\npublic oversight, shaping the future of humanity, often with unforeseen\nconsequences. In this paper, we propose OML, which stands for Open,\nMonetizable, and Loyal AI, an approach designed to democratize AI development.\nOML is realized through an interdisciplinary framework spanning AI, blockchain,\nand cryptography. We present several ideas for constructing OML using\ntechnologies such as Trusted Execution Environments (TEE), traditional\ncryptographic primitives like fully homomorphic encryption and functional\nencryption, obfuscation, and AI-native solutions rooted in the sample\ncomplexity and intrinsic hardness of AI tasks. A key innovation of our work is\nintroducing a new scientific field: AI-native cryptography. Unlike conventional\ncryptography, which focuses on discrete data and binary security guarantees,\nAI-native cryptography exploits the continuous nature of AI data\nrepresentations and their low-dimensional manifolds, focusing on improving\napproximate performance. One core idea is to transform AI attack methods, such\nas data poisoning, into security tools. This novel approach serves as a\nfoundation for OML 1.0 which uses model fingerprinting to protect the integrity\nand ownership of AI models. The spirit of OML is to establish a decentralized,\nopen, and transparent platform for AI development, enabling the community to\ncontribute, monetize, and take ownership of AI models. By decentralizing\ncontrol and ensuring transparency through blockchain technology, OML prevents\nthe concentration of power and provides accountability in AI development that\nhas not been possible before.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "60 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03887v2",
    "published_date": "2024-11-01 18:46:03 UTC",
    "updated_date": "2024-11-13 17:37:55 UTC"
  },
  {
    "arxiv_id": "2411.00970v1",
    "title": "Incremental IVF Index Maintenance for Streaming Vector Search",
    "authors": [
      "Jason Mohoney",
      "Anil Pacaci",
      "Shihabur Rahman Chowdhury",
      "Umar Farooq Minhas",
      "Jeffery Pound",
      "Cedric Renggli",
      "Nima Reyhani",
      "Ihab F. Ilyas",
      "Theodoros Rekatsinas",
      "Shivaram Venkataraman"
    ],
    "abstract": "The prevalence of vector similarity search in modern machine learning\napplications and the continuously changing nature of data processed by these\napplications necessitate efficient and effective index maintenance techniques\nfor vector search indexes. Designed primarily for static workloads, existing\nvector search indexes degrade in search quality and performance as the\nunderlying data is updated unless costly index reconstruction is performed. To\naddress this, we introduce Ada-IVF, an incremental indexing methodology for\nInverted File (IVF) indexes. Ada-IVF consists of 1) an adaptive maintenance\npolicy that decides which index partitions are problematic for performance and\nshould be repartitioned and 2) a local re-clustering mechanism that determines\nhow to repartition them. Compared with state-of-the-art dynamic IVF index\nmaintenance strategies, Ada-IVF achieves an average of 2x and up to 5x higher\nupdate throughput across a range of benchmark workloads.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "14 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00970v1",
    "published_date": "2024-11-01 18:43:45 UTC",
    "updated_date": "2024-11-01 18:43:45 UTC"
  },
  {
    "arxiv_id": "2411.00960v1",
    "title": "Scalable AI Framework for Defect Detection in Metal Additive Manufacturing",
    "authors": [
      "Duy Nhat Phan",
      "Sushant Jha",
      "James P. Mavo",
      "Erin L. Lanigan",
      "Linh Nguyen",
      "Lokendra Poudel",
      "Rahul Bhowmik"
    ],
    "abstract": "Additive Manufacturing (AM) is transforming the manufacturing sector by\nenabling efficient production of intricately designed products and small-batch\ncomponents. However, metal parts produced via AM can include flaws that cause\ninferior mechanical properties, including reduced fatigue response, yield\nstrength, and fracture toughness. To address this issue, we leverage\nconvolutional neural networks (CNN) to analyze thermal images of printed\nlayers, automatically identifying anomalies that impact these properties. We\nalso investigate various synthetic data generation techniques to address\nlimited and imbalanced AM training data. Our models' defect detection\ncapabilities were assessed using images of Nickel alloy 718 layers produced on\na laser powder bed fusion AM machine and synthetic datasets with and without\nadded noise. Our results show significant accuracy improvements with synthetic\ndata, emphasizing the importance of expanding training sets for reliable defect\ndetection. Specifically, Generative Adversarial Networks (GAN)-generated\ndatasets streamlined data preparation by eliminating human intervention while\nmaintaining high performance, thereby enhancing defect detection capabilities.\nAdditionally, our denoising approach effectively improves image quality,\nensuring reliable defect detection. Finally, our work integrates these models\nin the CLoud ADditive MAnufacturing (CLADMA) module, a user-friendly interface,\nto enhance their accessibility and practicality for AM applications. This\nintegration supports broader adoption and practical implementation of advanced\ndefect detection in AM processes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.00960v1",
    "published_date": "2024-11-01 18:17:59 UTC",
    "updated_date": "2024-11-01 18:17:59 UTC"
  },
  {
    "arxiv_id": "2411.00949v1",
    "title": "From Fake Perfects to Conversational Imperfects: Exploring Image-Generative AI as a Boundary Object for Participatory Design of Public Spaces",
    "authors": [
      "Jose A. Guridi",
      "Angel Hsing-Chi Hwang",
      "Duarte Santo",
      "Maria Goula",
      "Cristobal Cheyre",
      "Lee Humphreys",
      "Marco Rangel"
    ],
    "abstract": "Designing public spaces requires balancing the interests of diverse\nstakeholders within a constrained physical and institutional space. Designers\nusually approach these problems through participatory methods but struggle to\nincorporate diverse perspectives into design outputs. The growing capabilities\nof image-generative artificial intelligence (IGAI) could support participatory\ndesign. Prior work in leveraging IGAI's capabilities in design has focused on\naugmenting the experience and performance of individual creators. We study how\nIGAI could facilitate participatory processes when designing public spaces, a\ncomplex collaborative task. We conducted workshops and IGAI-mediated interviews\nin a real-world participatory process to upgrade a park in Los Angeles. We\nfound (1) a shift from focusing on accuracy to fostering richer conversations\nas the desirable outcome of adopting IGAI in participatory design, (2) that\nIGAI promoted more space-aware conversations, and (3) that IGAI-mediated\nconversations are subject to the abilities of the facilitators in managing the\ninteraction between themselves, the AI, and stakeholders. We contribute by\ndiscussing practical implications for using IGAI in participatory design,\nincluding success metrics, relevant skills, and asymmetries between designers\nand stakeholders. We finish by proposing a series of open research questions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Forthcoming in the Proceedings of the 2025 Conference on Computer\n  Supported Cooperative Work and Social Computing (CSCW)",
    "pdf_url": "http://arxiv.org/pdf/2411.00949v1",
    "published_date": "2024-11-01 18:02:46 UTC",
    "updated_date": "2024-11-01 18:02:46 UTC"
  },
  {
    "arxiv_id": "2411.00774v5",
    "title": "Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM",
    "authors": [
      "Xiong Wang",
      "Yangze Li",
      "Chaoyou Fu",
      "Yunhang Shen",
      "Lei Xie",
      "Ke Li",
      "Xing Sun",
      "Long Ma"
    ],
    "abstract": "Rapidly developing large language models (LLMs) have brought tremendous\nintelligent applications. Especially, the GPT-4o's excellent duplex speech\ninteraction ability has brought impressive experience to users. Researchers\nhave recently proposed several multi-modal LLMs in this direction that can\nachieve user-agent speech-to-speech conversations. This paper proposes a novel\nspeech-text multimodal LLM architecture called Freeze-Omni. Our main\ncontribution is that the speech input and output modalities can be easily\nconnected to a textual LLM while keeping the LLM's parameters frozen throughout\nthe training process. We design a three-stage training strategy for modeling\nboth the speech input and output, enabling Freeze-Omni to obtain\nspeech-to-speech conversation ability using text-speech paired data (such as\nASR and TTS data) and only 60,000 multi-round text Q&A data on 8 GPUs.\nMoreover, we can effectively ensure that the intelligence of the Freeze-Omni in\nthe speech modality is at the same level compared with that in the text\nmodality of its backbone LLM, while achieving low latency end-to-end spoken\nresponse. In addition, we also designed a method to achieve duplex dialogue\nability through multi-task training, giving Freeze-Omni a more natural style of\ndialogue ability between users and agents. In summary, Freeze-Omni holds great\npotential to conduct speech-to-speech dialogue based on a multimodal LLM under\nthe condition of a frozen LLM, avoiding the catastrophic forgetting problem\ncaused by limited data and training resources.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Project Page: https://freeze-omni.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.00774v5",
    "published_date": "2024-11-01 17:59:51 UTC",
    "updated_date": "2024-12-08 05:41:56 UTC"
  },
  {
    "arxiv_id": "2411.00773v2",
    "title": "LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation",
    "authors": [
      "Bowen Li",
      "Zhaoyu Li",
      "Qiwei Du",
      "Jinqi Luo",
      "Wenshan Wang",
      "Yaqi Xie",
      "Simon Stepputtis",
      "Chen Wang",
      "Katia P. Sycara",
      "Pradeep Kumar Ravikumar",
      "Alexander G. Gray",
      "Xujie Si",
      "Sebastian Scherer"
    ],
    "abstract": "Recent years have witnessed the rapid development of Neuro-Symbolic (NeSy) AI\nsystems, which integrate symbolic reasoning into deep neural networks. However,\nmost of the existing benchmarks for NeSy AI fail to provide long-horizon\nreasoning tasks with complex multi-agent interactions. Furthermore, they are\nusually constrained by fixed and simplistic logical rules over limited\nentities, making them far from real-world complexities. To address these\ncrucial gaps, we introduce LogiCity, the first simulator based on customizable\nfirst-order logic (FOL) for an urban-like environment with multiple dynamic\nagents. LogiCity models diverse urban elements using semantic and spatial\nconcepts, such as IsAmbulance(X) and IsClose(X, Y). These concepts are used to\ndefine FOL rules that govern the behavior of various agents. Since the concepts\nand rules are abstractions, they can be universally applied to cities with any\nagent compositions, facilitating the instantiation of diverse scenarios.\nBesides, a key feature of LogiCity is its support for user-configurable\nabstractions, enabling customizable simulation complexities for logical\nreasoning. To explore various aspects of NeSy AI, LogiCity introduces two\ntasks, one features long-horizon sequential decision-making, and the other\nfocuses on one-step visual reasoning, varying in difficulty and agent\nbehaviors. Our extensive evaluation reveals the advantage of NeSy frameworks in\nabstract reasoning. Moreover, we highlight the significant challenges of\nhandling more complex abstractions in long-horizon multi-agent scenarios or\nunder high-dimensional, imbalanced data. With its flexible design, various\nfeatures, and newly raised challenges, we believe LogiCity represents a pivotal\nstep forward in advancing the next generation of NeSy AI. All the code and data\nare open-sourced at our website: https://jaraxxus-me.github.io/LogiCity/",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 8 figures, In Advances in Neural Information Processing\n  Systems (NeurIPS) 37 D&B Track (2024): 69840-69864",
    "pdf_url": "http://arxiv.org/pdf/2411.00773v2",
    "published_date": "2024-11-01 17:59:46 UTC",
    "updated_date": "2025-04-03 19:00:11 UTC"
  },
  {
    "arxiv_id": "2411.00769v3",
    "title": "GameGen-X: Interactive Open-world Game Video Generation",
    "authors": [
      "Haoxuan Che",
      "Xuanhua He",
      "Quande Liu",
      "Cheng Jin",
      "Hao Chen"
    ],
    "abstract": "We introduce GameGen-X, the first diffusion transformer model specifically\ndesigned for both generating and interactively controlling open-world game\nvideos. This model facilitates high-quality, open-domain generation by\nsimulating an extensive array of game engine features, such as innovative\ncharacters, dynamic environments, complex actions, and diverse events.\nAdditionally, it provides interactive controllability, predicting and altering\nfuture content based on the current clip, thus allowing for gameplay\nsimulation. To realize this vision, we first collected and built an Open-World\nVideo Game Dataset from scratch. It is the first and largest dataset for\nopen-world game video generation and control, which comprises over a million\ndiverse gameplay video clips sampling from over 150 games with informative\ncaptions from GPT-4o. GameGen-X undergoes a two-stage training process,\nconsisting of foundation model pre-training and instruction tuning. Firstly,\nthe model was pre-trained via text-to-video generation and video continuation,\nendowing it with the capability for long-sequence, high-quality open-domain\ngame video generation. Further, to achieve interactive controllability, we\ndesigned InstructNet to incorporate game-related multi-modal control signal\nexperts. This allows the model to adjust latent representations based on user\ninputs, unifying character interaction and scene content control for the first\ntime in video generation. During instruction tuning, only the InstructNet is\nupdated while the pre-trained foundation model is frozen, enabling the\nintegration of interactive controllability without loss of diversity and\nquality of generated video content.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Homepage: https://gamegen-x.github.io/ Github:\n  https://github.com/GameGen-X/GameGen-X",
    "pdf_url": "http://arxiv.org/pdf/2411.00769v3",
    "published_date": "2024-11-01 17:59:17 UTC",
    "updated_date": "2024-12-06 13:09:43 UTC"
  },
  {
    "arxiv_id": "2411.00934v1",
    "title": "Generative Memesis: AI Mediates Political Memes in the 2024 USA Presidential Election",
    "authors": [
      "Ho-Chun Herbert Chang",
      "Benjamin Shaman",
      "Yung-chun Chen",
      "Mingyue Zha",
      "Sean Noh",
      "Chiyu Wei",
      "Tracy Weener",
      "Maya Magee"
    ],
    "abstract": "Visual content on social media has become increasingly influential in shaping\npolitical discourse and civic engagement. Using a dataset of 239,526 Instagram\nimages, deep learning, and LLM-based workflows, we examine the impact of\ndifferent content types on user engagement during the 2024 US presidential\nElections, with a focus on synthetic visuals. Results show while synthetic\ncontent may not increase engagement alone, it mediates how political\ninformation is created through highly effective, often absurd, political memes.\nWe define the notion of generative memesis, where memes are no longer shared\nperson-to-person but mediated by AI through customized, generated images. We\nalso find partisan divergences: Democrats use AI for in-group support whereas\nRepublicans use it for out-group attacks. Non-traditional, left-leaning outlets\nare the primary creators of political memes; emphasis on different topics\nlargely follows issue ownership.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00934v1",
    "published_date": "2024-11-01 17:35:05 UTC",
    "updated_date": "2024-11-01 17:35:05 UTC"
  },
  {
    "arxiv_id": "2411.02433v2",
    "title": "SLED: Self Logits Evolution Decoding for Improving Factuality in Large Language Models",
    "authors": [
      "Jianyi Zhang",
      "Da-Cheng Juan",
      "Cyrus Rashtchian",
      "Chun-Sung Ferng",
      "Heinrich Jiang",
      "Yiran Chen"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\ntheir outputs can sometimes be unreliable or factually incorrect. To address\nthis, we introduce Self Logits Evolution Decoding (SLED), a novel decoding\nframework that enhances the truthfulness of LLMs without relying on external\nknowledge bases or requiring further fine-tuning. From an optimization\nperspective, our SLED framework leverages the latent knowledge embedded within\nthe LLM by contrasting the output logits from the final layer with those from\nearly layers. It then utilizes an approximate gradient approach to enable\nlatent knowledge to guide the self-refinement of outputs, thereby effectively\nimproving factual accuracy. Extensive experiments have been conducted on\nestablished benchmarks across a diverse range of model families (LLaMA 2, LLaMA\n3, Gemma) and scales (from 2B to 70B), including more advanced architectural\nconfigurations such as the mixture of experts (MoE). Our evaluation spans a\nwide variety of tasks, including multi-choice, open-generation, and adaptations\nto chain-of-thought reasoning tasks. The results demonstrate that SLED\nconsistently improves factual accuracy by up to 20\\% compared to existing\ndecoding methods while maintaining natural language fluency and negligible\nlatency overhead. Furthermore, it can be flexibly combined with other decoding\nmethods to further enhance their performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeurIPS 2024; project page is available at\n  https://jayzhang42.github.io/sled_page/",
    "pdf_url": "http://arxiv.org/pdf/2411.02433v2",
    "published_date": "2024-11-01 17:33:34 UTC",
    "updated_date": "2024-11-27 20:59:05 UTC"
  },
  {
    "arxiv_id": "2411.11856v3",
    "title": "Automatically Improving LLM-based Verilog Generation using EDA Tool Feedback",
    "authors": [
      "Jason Blocklove",
      "Shailja Thakur",
      "Benjamin Tan",
      "Hammond Pearce",
      "Siddharth Garg",
      "Ramesh Karri"
    ],
    "abstract": "Traditionally, digital hardware designs are written in the Verilog hardware\ndescription language (HDL) and debugged manually by engineers. This can be\ntime-consuming and error-prone for complex designs. Large Language Models\n(LLMs) are emerging as a potential tool to help generate fully functioning HDL\ncode, but most works have focused on generation in the single-shot capacity:\ni.e., run and evaluate, a process that does not leverage debugging and, as\nsuch, does not adequately reflect a realistic development process. In this\nwork, we evaluate the ability of LLMs to leverage feedback from electronic\ndesign automation (EDA) tools to fix mistakes in their own generated Verilog.\nTo accomplish this, we present an open-source, highly customizable framework,\nAutoChip, which combines conversational LLMs with the output from Verilog\ncompilers and simulations to iteratively generate and repair Verilog. To\ndetermine the success of these LLMs we leverage the VerilogEval benchmark set.\nWe evaluate four state-of-the-art conversational LLMs, focusing on readily\naccessible commercial models. EDA tool feedback proved to be consistently more\neffective than zero-shot prompting only with GPT-4o, the most computationally\ncomplex model we evaluated. In the best case, we observed a 5.8% increase in\nthe number of successful designs with a 34.2% decrease in cost over the best\nzero-shot results. Mixing smaller models with this larger model at the end of\nthe feedback iterations resulted in equally as much success as with GPT-4o\nusing feedback, but incurred 41.9% lower cost (corresponding to an overall\ndecrease in cost over zero-shot by 89.6%).",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted for publication in TODAES Special Issue on Large Language\n  Models for Electronic System Design Automation",
    "pdf_url": "http://arxiv.org/pdf/2411.11856v3",
    "published_date": "2024-11-01 17:33:28 UTC",
    "updated_date": "2025-03-04 21:25:03 UTC"
  },
  {
    "arxiv_id": "2411.00750v2",
    "title": "Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided Sampling",
    "authors": [
      "Yiwen Ding",
      "Zhiheng Xi",
      "Wei He",
      "Zhuoyuan Li",
      "Yitao Zhai",
      "Xiaowei Shi",
      "Xunliang Cai",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "Self-improvement methods enable large language models (LLMs) to generate\nsolutions themselves and iteratively train on filtered, high-quality\nrationales. This process proves effective and reduces the reliance on human\nsupervision in LLMs' reasoning, but the performance soon plateaus. We delve\ninto the process and find that models tend to over-sample on easy queries and\nunder-sample on queries they have yet to master. As iterations proceed, this\nimbalance in sampling is exacerbated, leading to a long-tail distribution where\nsolutions to difficult queries almost diminish. This phenomenon limits the\nperformance gain of self-improving models. A straightforward solution is\nbrute-force sampling to balance the distribution, which significantly raises\ncomputational costs. In this paper, we introduce Guided Self-Improvement (GSI),\na strategy aimed at improving the efficiency of sampling challenging\nheavy-tailed data. It leverages Socratic-style guidance signals to help LLM\nreasoning with complex queries, reducing the exploration effort and minimizing\ncomputational overhead. Experiments on four models across diverse mathematical\ntasks show that GSI strikes a balance between performance and efficiency, while\nalso being effective on held-out tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Main Conference. Codes are publicly available\n  at https://github.com/Yiwen-Ding/Guided-Self-Improvement",
    "pdf_url": "http://arxiv.org/pdf/2411.00750v2",
    "published_date": "2024-11-01 17:18:45 UTC",
    "updated_date": "2025-02-21 08:00:10 UTC"
  },
  {
    "arxiv_id": "2411.00932v1",
    "title": "LLMs: A Game-Changer for Software Engineers?",
    "authors": [
      "Md Asraful Haque"
    ],
    "abstract": "Large Language Models (LLMs) like GPT-3 and GPT-4 have emerged as\ngroundbreaking innovations with capabilities that extend far beyond traditional\nAI applications. These sophisticated models, trained on massive datasets, can\ngenerate human-like text, respond to complex queries, and even write and\ninterpret code. Their potential to revolutionize software development has\ncaptivated the software engineering (SE) community, sparking debates about\ntheir transformative impact. Through a critical analysis of technical\nstrengths, limitations, real-world case studies, and future research\ndirections, this paper argues that LLMs are not just reshaping how software is\ndeveloped but are redefining the role of developers. While challenges persist,\nLLMs offer unprecedented opportunities for innovation and collaboration. Early\nadoption of LLMs in software engineering is crucial to stay competitive in this\nrapidly evolving landscape. This paper serves as a guide, helping developers,\norganizations, and researchers understand how to harness the power of LLMs to\nstreamline workflows and acquire the necessary skills.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "Software Engineering (cs.SE), Artificial Intelligence (cs.AI)"
    ],
    "primary_category": "cs.SE",
    "comment": "20 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.00932v1",
    "published_date": "2024-11-01 17:14:37 UTC",
    "updated_date": "2024-11-01 17:14:37 UTC"
  },
  {
    "arxiv_id": "2411.00743v1",
    "title": "Decoding Dark Matter: Specialized Sparse Autoencoders for Interpreting Rare Concepts in Foundation Models",
    "authors": [
      "Aashiq Muhamed",
      "Mona Diab",
      "Virginia Smith"
    ],
    "abstract": "Understanding and mitigating the potential risks associated with foundation\nmodels (FMs) hinges on developing effective interpretability methods. Sparse\nAutoencoders (SAEs) have emerged as a promising tool for disentangling FM\nrepresentations, but they struggle to capture rare, yet crucial concepts in the\ndata. We introduce Specialized Sparse Autoencoders (SSAEs), designed to\nilluminate these elusive dark matter features by focusing on specific\nsubdomains. We present a practical recipe for training SSAEs, demonstrating the\nefficacy of dense retrieval for data selection and the benefits of Tilted\nEmpirical Risk Minimization as a training objective to improve concept recall.\nOur evaluation of SSAEs on standard metrics, such as downstream perplexity and\n$L_0$ sparsity, show that they effectively capture subdomain tail concepts,\nexceeding the capabilities of general-purpose SAEs. We showcase the practical\nutility of SSAEs in a case study on the Bias in Bios dataset, where SSAEs\nachieve a 12.5\\% increase in worst-group classification accuracy when applied\nto remove spurious gender information. SSAEs provide a powerful new lens for\npeering into the inner workings of FMs in subdomains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00743v1",
    "published_date": "2024-11-01 17:09:34 UTC",
    "updated_date": "2024-11-01 17:09:34 UTC"
  },
  {
    "arxiv_id": "2411.00737v1",
    "title": "MolCap-Arena: A Comprehensive Captioning Benchmark on Language-Enhanced Molecular Property Prediction",
    "authors": [
      "Carl Edwards",
      "Ziqing Lu",
      "Ehsan Hajiramezanali",
      "Tommaso Biancalani",
      "Heng Ji",
      "Gabriele Scalia"
    ],
    "abstract": "Bridging biomolecular modeling with natural language information,\nparticularly through large language models (LLMs), has recently emerged as a\npromising interdisciplinary research area. LLMs, having been trained on large\ncorpora of scientific documents, demonstrate significant potential in\nunderstanding and reasoning about biomolecules by providing enriched contextual\nand domain knowledge. However, the extent to which LLM-driven insights can\nimprove performance on complex predictive tasks (e.g., toxicity) remains\nunclear. Further, the extent to which relevant knowledge can be extracted from\nLLMs also remains unknown. In this study, we present Molecule Caption Arena:\nthe first comprehensive benchmark of LLM-augmented molecular property\nprediction. We evaluate over twenty LLMs, including both general-purpose and\ndomain-specific molecule captioners, across diverse prediction tasks. To this\ngoal, we introduce a novel, battle-based rating system. Our findings confirm\nthe ability of LLM-extracted knowledge to enhance state-of-the-art molecular\nrepresentations, with notable model-, prompt-, and dataset-specific variations.\nCode, resources, and data are available at github.com/Genentech/molcap-arena.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00737v1",
    "published_date": "2024-11-01 17:03:16 UTC",
    "updated_date": "2024-11-01 17:03:16 UTC"
  },
  {
    "arxiv_id": "2411.00728v1",
    "title": "Multi-Agent Deep Q-Network with Layer-based Communication Channel for Autonomous Internal Logistics Vehicle Scheduling in Smart Manufacturing",
    "authors": [
      "Mohammad Feizabadi",
      "Arman Hosseini",
      "Zakaria Yahouni"
    ],
    "abstract": "In smart manufacturing, scheduling autonomous internal logistic vehicles is\ncrucial for optimizing operational efficiency. This paper proposes a\nmulti-agent deep Q-network (MADQN) with a layer-based communication channel\n(LBCC) to address this challenge. The main goals are to minimize total job\ntardiness, reduce the number of tardy jobs, and lower vehicle energy\nconsumption. The method is evaluated against nine well-known scheduling\nheuristics, demonstrating its effectiveness in handling dynamic job shop\nbehaviors like job arrivals and workstation unavailabilities. The approach also\nproves scalable, maintaining performance across different layouts and larger\nproblem instances, highlighting the robustness and adaptability of MADQN with\nLBCC in smart manufacturing.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted for the 5th IFAC/INSTICC INTERNATIONAL CONFERENCE ON\n  INNOVATIVE INTELLIGENT INDUSTRIAL PRODUCTION AND LOGISTICS",
    "pdf_url": "http://arxiv.org/pdf/2411.00728v1",
    "published_date": "2024-11-01 16:40:12 UTC",
    "updated_date": "2024-11-01 16:40:12 UTC"
  },
  {
    "arxiv_id": "2411.00727v2",
    "title": "SPRING Lab IITM's submission to Low Resource Indic Language Translation Shared Task",
    "authors": [
      "Hamees Sayed",
      "Advait Joglekar",
      "Srinivasan Umesh"
    ],
    "abstract": "We develop a robust translation model for four low-resource Indic languages:\nKhasi, Mizo, Manipuri, and Assamese. Our approach includes a comprehensive\npipeline from data collection and preprocessing to training and evaluation,\nleveraging data from WMT task datasets, BPCC, PMIndia, and OpenLanguageData. To\naddress the scarcity of bilingual data, we use back-translation techniques on\nmonolingual datasets for Mizo and Khasi, significantly expanding our training\ncorpus. We fine-tune the pre-trained NLLB 3.3B model for Assamese, Mizo, and\nManipuri, achieving improved performance over the baseline. For Khasi, which is\nnot supported by the NLLB model, we introduce special tokens and train the\nmodel on our Khasi corpus. Our training involves masked language modelling,\nfollowed by fine-tuning for English-to-Indic and Indic-to-English translations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in WMT 2024. Low-Resource Indic Language Translation Shared\n  Task",
    "pdf_url": "http://arxiv.org/pdf/2411.00727v2",
    "published_date": "2024-11-01 16:39:03 UTC",
    "updated_date": "2024-11-11 06:25:04 UTC"
  },
  {
    "arxiv_id": "2411.00726v1",
    "title": "Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract",
    "authors": [
      "Fan Xiao",
      "Junlin Hou",
      "Ruiwei Zhao",
      "Rui Feng",
      "Haidong Zou",
      "Lina Lu",
      "Yi Xu",
      "Juzhao Zhang"
    ],
    "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00726v1",
    "published_date": "2024-11-01 16:38:49 UTC",
    "updated_date": "2024-11-01 16:38:49 UTC"
  },
  {
    "arxiv_id": "2411.00715v2",
    "title": "B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable",
    "authors": [
      "Shreyash Arya",
      "Sukrut Rao",
      "Moritz Böhle",
      "Bernt Schiele"
    ],
    "abstract": "B-cos Networks have been shown to be effective for obtaining highly human\ninterpretable explanations of model decisions by architecturally enforcing\nstronger alignment between inputs and weight. B-cos variants of convolutional\nnetworks (CNNs) and vision transformers (ViTs), which primarily replace linear\nlayers with B-cos transformations, perform competitively to their respective\nstandard variants while also yielding explanations that are faithful by design.\nHowever, it has so far been necessary to train these models from scratch, which\nis increasingly infeasible in the era of large, pre-trained foundation models.\nIn this work, inspired by the architectural similarities in standard DNNs and\nB-cos networks, we propose 'B-cosification', a novel approach to transform\nexisting pre-trained models to become inherently interpretable. We perform a\nthorough study of design choices to perform this conversion, both for\nconvolutional neural networks and vision transformers. We find that\nB-cosification can yield models that are on par with B-cos models trained from\nscratch in terms of interpretability, while often outperforming them in terms\nof classification performance at a fraction of the training cost. Subsequently,\nwe apply B-cosification to a pretrained CLIP model, and show that, even with\nlimited data and compute cost, we obtain a B-cosified version that is highly\ninterpretable and competitive on zero shot performance across a variety of\ndatasets. We release our code and pre-trained model weights at\nhttps://github.com/shrebox/B-cosification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "31 pages, 9 figures, 12 tables, Neural Information Processing Systems\n  (NeurIPS) 2024; added references, corrected typos",
    "pdf_url": "http://arxiv.org/pdf/2411.00715v2",
    "published_date": "2024-11-01 16:28:11 UTC",
    "updated_date": "2025-01-24 21:52:21 UTC"
  },
  {
    "arxiv_id": "2411.02432v1",
    "title": "Can LLMs make trade-offs involving stipulated pain and pleasure states?",
    "authors": [
      "Geoff Keeling",
      "Winnie Street",
      "Martyna Stachaczyk",
      "Daria Zakharova",
      "Iulia M. Comsa",
      "Anastasiya Sakovych",
      "Isabella Logothetis",
      "Zejia Zhang",
      "Blaise Agüera y Arcas",
      "Jonathan Birch"
    ],
    "abstract": "Pleasure and pain play an important role in human decision making by\nproviding a common currency for resolving motivational conflicts. While Large\nLanguage Models (LLMs) can generate detailed descriptions of pleasure and pain\nexperiences, it is an open question whether LLMs can recreate the motivational\nforce of pleasure and pain in choice scenarios - a question which may bear on\ndebates about LLM sentience, understood as the capacity for valenced\nexperiential states. We probed this question using a simple game in which the\nstated goal is to maximise points, but where either the points-maximising\noption is said to incur a pain penalty or a non-points-maximising option is\nsaid to incur a pleasure reward, providing incentives to deviate from\npoints-maximising behaviour. Varying the intensity of the pain penalties and\npleasure rewards, we found that Claude 3.5 Sonnet, Command R+, GPT-4o, and\nGPT-4o mini each demonstrated at least one trade-off in which the majority of\nresponses switched from points-maximisation to pain-minimisation or\npleasure-maximisation after a critical threshold of stipulated pain or pleasure\nintensity is reached. LLaMa 3.1-405b demonstrated some graded sensitivity to\nstipulated pleasure rewards and pain penalties. Gemini 1.5 Pro and PaLM 2\nprioritised pain-avoidance over points-maximisation regardless of intensity,\nwhile tending to prioritise points over pleasure regardless of intensity. We\ndiscuss the implications of these findings for debates about the possibility of\nLLM sentience.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02432v1",
    "published_date": "2024-11-01 16:22:13 UTC",
    "updated_date": "2024-11-01 16:22:13 UTC"
  },
  {
    "arxiv_id": "2411.00707v2",
    "title": "Learning in Markov Games with Adaptive Adversaries: Policy Regret, Fundamental Barriers, and Efficient Algorithms",
    "authors": [
      "Thanh Nguyen-Tang",
      "Raman Arora"
    ],
    "abstract": "We study learning in a dynamically evolving environment modeled as a Markov\ngame between a learner and a strategic opponent that can adapt to the learner's\nstrategies. While most existing works in Markov games focus on external regret\nas the learning objective, external regret becomes inadequate when the\nadversaries are adaptive. In this work, we focus on \\emph{policy regret} -- a\ncounterfactual notion that aims to compete with the return that would have been\nattained if the learner had followed the best fixed sequence of policy, in\nhindsight. We show that if the opponent has unbounded memory or if it is\nnon-stationary, then sample-efficient learning is not possible. For\nmemory-bounded and stationary, we show that learning is still statistically\nhard if the set of feasible strategies for the learner is exponentially large.\nTo guarantee learnability, we introduce a new notion of \\emph{consistent}\nadaptive adversaries, wherein, the adversary responds similarly to similar\nstrategies of the learner. We provide algorithms that achieve $\\sqrt{T}$ policy\nregret against memory-bounded, stationary, and consistent adversaries.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS'24; fix typos",
    "pdf_url": "http://arxiv.org/pdf/2411.00707v2",
    "published_date": "2024-11-01 16:17:27 UTC",
    "updated_date": "2024-12-09 23:57:21 UTC"
  },
  {
    "arxiv_id": "2411.00929v1",
    "title": "Text2Freq: Learning Series Patterns from Text via Frequency Domain",
    "authors": [
      "Ming-Chih Lo",
      "Ching Chang",
      "Wen-Chih Peng"
    ],
    "abstract": "Traditional time series forecasting models mainly rely on historical numeric\nvalues to predict future outcomes.While these models have shown promising\nresults, they often overlook the rich information available in other\nmodalities, such as textual descriptions of special events, which can provide\ncrucial insights into future dynamics.However, research that jointly\nincorporates text in time series forecasting remains relatively underexplored\ncompared to other cross-modality work. Additionally, the modality gap between\ntime series data and textual information poses a challenge for multimodal\nlearning. To address this task, we propose Text2Freq, a cross-modality model\nthat integrates text and time series data via the frequency domain.\nSpecifically, our approach aligns textual information to the low-frequency\ncomponents of time series data, establishing more effective and interpretable\nalignments between these two modalities. Our experiments on paired datasets of\nreal-world stock prices and synthetic texts show that Text2Freq achieves\nstate-of-the-art performance, with its adaptable architecture encouraging\nfuture research in this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 3 figures, and be accepted by NeurIPS 2024 Workshop: Time\n  Series in the Age of Large Models",
    "pdf_url": "http://arxiv.org/pdf/2411.00929v1",
    "published_date": "2024-11-01 16:11:02 UTC",
    "updated_date": "2024-11-01 16:11:02 UTC"
  },
  {
    "arxiv_id": "2411.00927v2",
    "title": "ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents",
    "authors": [
      "Vardhan Dongre",
      "Xiaocheng Yang",
      "Emre Can Acikgoz",
      "Suvodip Dey",
      "Gokhan Tur",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "Large language model (LLM)-based agents are increasingly employed to interact\nwith external environments (e.g., games, APIs, world models) to solve\nuser-provided tasks. However, current frameworks often lack the ability to\ncollaborate effectively with users in fully conversational settings.\nConversations are essential for aligning on task details, achieving\nuser-defined goals, and satisfying preferences. While existing agents address\nambiguity through clarification questions, they underutilize the broader\npotential of an LLM's conversational capabilities. In this work, we introduce\nReSpAct, an LLM-based agent designed to seamlessly integrate reasoning,\ndecision-making, and dynamic dialogue for task-solving. Expanding on\nreasoning-first approaches like ReAct, ReSpAct employs active, free-flowing\ndialogues to interpret instructions, clarify goals, provide status updates,\nresolve subtask failures, and refine plans based on user inputs without any\nexplicit dialogue schema. By alternating between task-solving actions and\ninteractive conversations, ReSpAct demonstrates improved performance across\ndiverse environments. We evaluate ReSpAct in user-interactive settings,\nincluding task-oriented dialogue systems (MultiWOZ) and decision-making tasks\n(ALFWorld, WebShop). ReSpAct outperforms ReAct with absolute success rate\nimprovements of 6% and 4% in ALFWorld and WebShop, respectively, and achieves a\n5.5% gain in Inform and a 3% gain in Success scores in MultiWOZ. These results\nhighlight the value of integrating dynamic user-agent collaboration for more\neffective task resolution.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 10 Figures, 25 Tables",
    "pdf_url": "http://arxiv.org/pdf/2411.00927v2",
    "published_date": "2024-11-01 15:57:45 UTC",
    "updated_date": "2025-04-19 15:43:36 UTC"
  },
  {
    "arxiv_id": "2411.00699v1",
    "title": "Algorithmic Transparency in Forecasting Support Systems",
    "authors": [
      "Leif Feddersen"
    ],
    "abstract": "Most organizations adjust their statistical forecasts (e.g. on sales)\nmanually. Forecasting Support Systems (FSS) enable the related process of\nautomated forecast generation and manual adjustments. As the FSS user interface\nconnects user and statistical algorithm, it is an obvious lever for\nfacilitating beneficial adjustments whilst discouraging harmful adjustments.\nThis paper reviews and organizes the literature on judgemental forecasting,\nforecast adjustments, and FSS design. I argue that algorithmic transparency may\nbe a key factor towards better, integrative forecasting and test this assertion\nwith three FSS designs that vary in their degrees of transparency based on time\nseries decomposition. I find transparency to reduce the variance and amount of\nharmful forecast adjustments. Letting users adjust the algorithm's transparent\ncomponents themselves, however, leads to widely varied and overall most\ndetrimental adjustments. Responses indicate a risk of overwhelming users with\nalgorithmic transparency without adequate training. Accordingly, self-reported\nsatisfaction is highest with a non-transparent FSS.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00699v1",
    "published_date": "2024-11-01 15:55:32 UTC",
    "updated_date": "2024-11-01 15:55:32 UTC"
  },
  {
    "arxiv_id": "2411.00696v1",
    "title": "CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis",
    "authors": [
      "Fuying Wang",
      "Feng Wu",
      "Yihan Tang",
      "Lequan Yu"
    ],
    "abstract": "Integrating multimodal Electronic Health Records (EHR) data, such as\nnumerical time series and free-text clinical reports, has great potential in\npredicting clinical outcomes. However, prior work has primarily focused on\ncapturing temporal interactions within individual samples and fusing multimodal\ninformation, overlooking critical temporal patterns across patients. These\npatterns, such as trends in vital signs like abnormal heart rate or blood\npressure, can indicate deteriorating health or an impending critical event.\nSimilarly, clinical notes often contain textual descriptions that reflect these\npatterns. Identifying corresponding temporal patterns across different\nmodalities is crucial for improving the accuracy of clinical outcome\npredictions, yet it remains a challenging task. To address this gap, we\nintroduce a Cross-Modal Temporal Pattern Discovery (CTPD) framework, designed\nto efficiently extract meaningful cross-modal temporal patterns from multimodal\nEHR data. Our approach introduces shared initial temporal pattern\nrepresentations which are refined using slot attention to generate temporal\nsemantic embeddings. To ensure rich cross-modal temporal semantics in the\nlearned patterns, we introduce a contrastive-based TPNCE loss for cross-modal\nalignment, along with two reconstruction losses to retain core information of\neach modality. Evaluations on two clinically critical tasks, 48-hour\nin-hospital mortality and 24-hour phenotype classification, using the MIMIC-III\ndatabase demonstrate the superiority of our method over existing approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Technical report",
    "pdf_url": "http://arxiv.org/pdf/2411.00696v1",
    "published_date": "2024-11-01 15:54:07 UTC",
    "updated_date": "2024-11-01 15:54:07 UTC"
  },
  {
    "arxiv_id": "2411.00686v1",
    "title": "Latent Paraphrasing: Perturbation on Layers Improves Knowledge Injection in Language Models",
    "authors": [
      "Minki Kang",
      "Sung Ju Hwang",
      "Gibbeum Lee",
      "Jaewoong Cho"
    ],
    "abstract": "As Large Language Models (LLMs) are increasingly deployed in specialized\ndomains with continuously evolving knowledge, the need for timely and precise\nknowledge injection has become essential. Fine-tuning with paraphrased data is\na common approach to enhance knowledge injection, yet it faces two significant\nchallenges: high computational costs due to repetitive external model usage and\nlimited sample diversity. To this end, we introduce LaPael, a latent-level\nparaphrasing method that applies input-dependent noise to early LLM layers.\nThis approach enables diverse and semantically consistent augmentations\ndirectly within the model. Furthermore, it eliminates the recurring costs of\nparaphrase generation for each knowledge update. Our extensive experiments on\nquestion-answering benchmarks demonstrate that LaPael improves knowledge\ninjection over standard fine-tuning and existing noise-based approaches.\nAdditionally, combining LaPael with data-level paraphrasing further enhances\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00686v1",
    "published_date": "2024-11-01 15:47:05 UTC",
    "updated_date": "2024-11-01 15:47:05 UTC"
  },
  {
    "arxiv_id": "2411.00683v1",
    "title": "TaxaBind: A Unified Embedding Space for Ecological Applications",
    "authors": [
      "Srikumar Sastry",
      "Subash Khanal",
      "Aayush Dhakal",
      "Adeel Ahmad",
      "Nathan Jacobs"
    ],
    "abstract": "We present TaxaBind, a unified embedding space for characterizing any species\nof interest. TaxaBind is a multimodal embedding space across six modalities:\nground-level images of species, geographic location, satellite image, text,\naudio, and environmental features, useful for solving ecological problems. To\nlearn this joint embedding space, we leverage ground-level images of species as\na binding modality. We propose multimodal patching, a technique for effectively\ndistilling the knowledge from various modalities into the binding modality. We\nconstruct two large datasets for pretraining: iSatNat with species images and\nsatellite images, and iSoundNat with species images and audio. Additionally, we\nintroduce TaxaBench-8k, a diverse multimodal dataset with six paired modalities\nfor evaluating deep learning models on ecological tasks. Experiments with\nTaxaBind demonstrate its strong zero-shot and emergent capabilities on a range\nof tasks including species classification, cross-model retrieval, and audio\nclassification. The datasets and models are made available at\nhttps://github.com/mvrl/TaxaBind.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.00683v1",
    "published_date": "2024-11-01 15:41:30 UTC",
    "updated_date": "2024-11-01 15:41:30 UTC"
  },
  {
    "arxiv_id": "2411.00681v1",
    "title": "AI-based traffic analysis in digital twin networks",
    "authors": [
      "Sarah Al-Shareeda",
      "Khayal Huseynov",
      "Lal Verda Cakir",
      "Craig Thomson",
      "Mehmet Ozdem",
      "Berk Canberk"
    ],
    "abstract": "In today's networked world, Digital Twin Networks (DTNs) are revolutionizing\nhow we understand and optimize physical networks. These networks, also known as\n'Digital Twin Networks (DTNs)' or 'Networks Digital Twins (NDTs),' encompass\nmany physical networks, from cellular and wireless to optical and satellite.\nThey leverage computational power and AI capabilities to provide virtual\nrepresentations, leading to highly refined recommendations for real-world\nnetwork challenges. Within DTNs, tasks include network performance enhancement,\nlatency optimization, energy efficiency, and more. To achieve these goals, DTNs\nutilize AI tools such as Machine Learning (ML), Deep Learning (DL),\nReinforcement Learning (RL), Federated Learning (FL), and graph-based\napproaches. However, data quality, scalability, interpretability, and security\nchallenges necessitate strategies prioritizing transparency, fairness, privacy,\nand accountability. This chapter delves into the world of AI-driven traffic\nanalysis within DTNs. It explores DTNs' development efforts, tasks, AI models,\nand challenges while offering insights into how AI can enhance these dynamic\nnetworks. Through this journey, readers will gain a deeper understanding of the\npivotal role AI plays in the ever-evolving landscape of networked systems.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CY",
      "cs.ET"
    ],
    "primary_category": "cs.NI",
    "comment": "Chapter 4: Digital Twins for 6G: Fundamental theory, technology and\n  applications; pp. 83-132",
    "pdf_url": "http://arxiv.org/pdf/2411.00681v1",
    "published_date": "2024-11-01 15:41:23 UTC",
    "updated_date": "2024-11-01 15:41:23 UTC"
  },
  {
    "arxiv_id": "2411.00666v1",
    "title": "Beyond the Boundaries of Proximal Policy Optimization",
    "authors": [
      "Charlie B. Tan",
      "Edan Toledo",
      "Benjamin Ellis",
      "Jakob N. Foerster",
      "Ferenc Huszár"
    ],
    "abstract": "Proximal policy optimization (PPO) is a widely-used algorithm for on-policy\nreinforcement learning. This work offers an alternative perspective of PPO, in\nwhich it is decomposed into the inner-loop estimation of update vectors, and\nthe outer-loop application of updates using gradient ascent with unity learning\nrate. Using this insight we propose outer proximal policy optimization\n(outer-PPO); a framework wherein these update vectors are applied using an\narbitrary gradient-based optimizer. The decoupling of update estimation and\nupdate application enabled by outer-PPO highlights several implicit design\nchoices in PPO that we challenge through empirical investigation. In particular\nwe consider non-unity learning rates and momentum applied to the outer loop,\nand a momentum-bias applied to the inner estimation loop. Methods are evaluated\nagainst an aggressively tuned PPO baseline on Brax, Jumanji and MinAtar\nenvironments; non-unity learning rates and momentum both achieve statistically\nsignificant improvement on Brax and Jumanji, given the same hyperparameter\ntuning budget.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00666v1",
    "published_date": "2024-11-01 15:29:10 UTC",
    "updated_date": "2024-11-01 15:29:10 UTC"
  },
  {
    "arxiv_id": "2411.00662v1",
    "title": "MoNTA: Accelerating Mixture-of-Experts Training with Network-Traffc-Aware Parallel Optimization",
    "authors": [
      "Jingming Guo",
      "Yan Liu",
      "Yu Meng",
      "Zhiwei Tao",
      "Banglan Liu",
      "Gang Chen",
      "Xiang Li"
    ],
    "abstract": "The Mixture of Experts (MoE) is an advanced model architecture in the\nindustry that combines multiple specialized expert models from various domains\ninto a single supermodel. This approach enables the model to scale without\nsignificantly increasing the computational costs of training and inference,\nwhile maximizing model performance. However, current distributed training\nframeworks do not consider the ultimate optimization of communication,\nespecially for large base models. This paper proposes a network-traffic-aware\nparallel optimization method that selects the optimal parallel strategy based\non the communication volume, and the training cluster's inter-node and\nintra-node network topologies. Compared to the DeepSpeed, MoNTA achieves an 8x\nincrease in AllToAll communication performance under 8-card tensor parallelism.\nCompared to the baseline, training a 2x70B model using 16 A800 cards, with an\n8K sequence, results in a 13% overall latency performance improvement. Project\nPage: https://github.com/EnflameTechnology/DeepSpeed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00662v1",
    "published_date": "2024-11-01 15:27:20 UTC",
    "updated_date": "2024-11-01 15:27:20 UTC"
  },
  {
    "arxiv_id": "2411.00660v2",
    "title": "Physics in Next-token Prediction",
    "authors": [
      "Hongjun An",
      "Yiliang Song",
      "Xuelong Li"
    ],
    "abstract": "We discovered the underlying physics in Next-token Prediction (NTP). We\nidentified the law of information conservation within NTP and proposed the\nFirst Law of Information Capacity (IC-1), demonstrating that the essence of\nintelligence emergence in auto-regressive models is fundamentally a process of\ninformation transfer. We also introduced Landauer's Principle into NTP,\nformulating the Second Law of Information Capacity (IC-2), which establishes\nthe relationship between auto-regressive model training and energy consumption.\nAdditionally, we presented several corollaries, which hold practical\nsignificance for production practices. Finally, we demonstrate the consistency\nbetween the Law of Information Capacity and the Scaling Law for Neural Language\nModels, the Knowledge Capacity Scaling Laws, and the Scaling Laws for\nPrecision.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Second Submit",
    "pdf_url": "http://arxiv.org/pdf/2411.00660v2",
    "published_date": "2024-11-01 15:26:15 UTC",
    "updated_date": "2024-11-16 06:17:37 UTC"
  },
  {
    "arxiv_id": "2411.00631v1",
    "title": "Generative AI and Agency in Education: A Critical Scoping Review and Thematic Analysis",
    "authors": [
      "Jasper Roe",
      "Mike Perkins"
    ],
    "abstract": "This scoping review examines the relationship between Generative AI (GenAI)\nand agency in education, analyzing the literature available through the lens of\nCritical Digital Pedagogy. Following PRISMA-ScR guidelines, we collected 10\nstudies from academic databases focusing on both learner and teacher agency in\nGenAI-enabled environments. We conducted an AI-supported hybrid thematic\nanalysis that revealed three key themes: Control in Digital Spaces, Variable\nEngagement and Access, and Changing Notions of Agency.\n  The findings suggest that while GenAI may enhance learner agency through\npersonalization and support, it also risks exacerbating educational\ninequalities and diminishing learner autonomy in certain contexts. This review\nhighlights gaps in the current research on GenAI's impact on agency. These\nfindings have implications for educational policy and practice, suggesting the\nneed for frameworks that promote equitable access while preserving learner\nagency in GenAI-enhanced educational environments.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00631v1",
    "published_date": "2024-11-01 14:40:31 UTC",
    "updated_date": "2024-11-01 14:40:31 UTC"
  },
  {
    "arxiv_id": "2411.00630v1",
    "title": "STAA: Spatio-Temporal Attention Attribution for Real-Time Interpreting Transformer-based Video Models",
    "authors": [
      "Zerui Wang",
      "Yan Liu"
    ],
    "abstract": "Transformer-based models have achieved state-of-the-art performance in\nvarious computer vision tasks, including image and video analysis. However,\nTransformer's complex architecture and black-box nature pose challenges for\nexplainability, a crucial aspect for real-world applications and scientific\ninquiry. Current Explainable AI (XAI) methods can only provide one-dimensional\nfeature importance, either spatial or temporal explanation, with significant\ncomputational complexity. This paper introduces STAA (Spatio-Temporal Attention\nAttribution), an XAI method for interpreting video Transformer models. Differ\nfrom traditional methods that separately apply image XAI techniques for spatial\nfeatures or segment contribution analysis for temporal aspects, STAA offers\nboth spatial and temporal information simultaneously from attention values in\nTransformers. The study utilizes the Kinetics-400 dataset, a benchmark\ncollection of 400 human action classes used for action recognition research. We\nintroduce metrics to quantify explanations. We also apply optimization to\nenhance STAA's raw output. By implementing dynamic thresholding and attention\nfocusing mechanisms, we improve the signal-to-noise ratio in our explanations,\nresulting in more precise visualizations and better evaluation results. In\nterms of computational overhead, our method requires less than 3\\% of the\ncomputational resources of traditional XAI methods, making it suitable for\nreal-time video XAI analysis applications. STAA contributes to the growing\nfield of XAI by offering a method for researchers and practitioners to analyze\nTransformer models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00630v1",
    "published_date": "2024-11-01 14:40:07 UTC",
    "updated_date": "2024-11-01 14:40:07 UTC"
  },
  {
    "arxiv_id": "2411.00622v1",
    "title": "Lingma SWE-GPT: An Open Development-Process-Centric Language Model for Automated Software Improvement",
    "authors": [
      "Yingwei Ma",
      "Rongyu Cao",
      "Yongchang Cao",
      "Yue Zhang",
      "Jue Chen",
      "Yibo Liu",
      "Yuchen Liu",
      "Binhua Li",
      "Fei Huang",
      "Yongbin Li"
    ],
    "abstract": "Recent advancements in LLM-based agents have led to significant progress in\nautomatic software engineering, particularly in software maintenance and\nevolution. Despite these encouraging advances, current research faces two major\nchallenges. First, SOTA performance primarily depends on closed-source models,\nwhich significantly limits the technology's accessibility, and potential for\ncustomization in diverse SE tasks. Second, these models are predominantly\ntrained on static code data, lacking a deep understanding of the dynamic\ninteractions, iterative problem-solving processes, and evolutionary\ncharacteristics inherent in software development. To address these challenges,\nour study adopts a software engineering perspective. We recognize that\nreal-world software maintenance and evolution processes encompass not only\nstatic code data but also developers' thought processes, utilization of\nexternal tools, and the interaction between different functional personnel.\nConsequently, we introduce the Lingma SWE-GPT series, comprising Lingma SWE-GPT\n7B and 72B. By learning from and simulating real-world code submission\nactivities, Lingma SWE-GPT systematically incorporates the dynamic interactions\nand iterative problem-solving inherent in software development process, thereby\nachieving a more comprehensive understanding of software improvement processes.\nWe conducted experimental evaluations using SWE-bench Verified benchmark. The\nresults demonstrate that Lingma SWE-GPT 72B successfully resolves 30.20% of the\nGitHub issues, marking a significant improvement in automatic issue resolution\n(22.76% relative improvement compared to Llama 3.1 405B), approaching the\nperformance of closed-source models (31.80\\% issues of GPT-4o resolved).\nNotably, Lingma SWE-GPT 7B resolves 18.20% of the issues, highlighting the\npotential for applying smaller models to ASE tasks.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00622v1",
    "published_date": "2024-11-01 14:27:16 UTC",
    "updated_date": "2024-11-01 14:27:16 UTC"
  },
  {
    "arxiv_id": "2411.08918v1",
    "title": "Wireless Federated Learning over UAV-enabled Integrated Sensing and Communication",
    "authors": [
      "Shaba Shaon",
      "Tien Nguyen",
      "Lina Mohjazi",
      "Aryan Kaushik",
      "Dinh C. Nguyen"
    ],
    "abstract": "This paper studies a new latency optimization problem in unmanned aerial\nvehicles (UAVs)-enabled federated learning (FL) with integrated sensing and\ncommunication. In this setup, distributed UAVs participate in model training\nusing sensed data and collaborate with a base station (BS) serving as FL\naggregator to build a global model. The objective is to minimize the FL system\nlatency over UAV networks by jointly optimizing UAVs' trajectory and resource\nallocation of both UAVs and the BS. The formulated optimization problem is\ntroublesome to solve due to its non-convexity. Hence, we develop a simple yet\nefficient iterative algorithm to find a high-quality approximate solution, by\nleveraging block coordinate descent and successive convex approximation\ntechniques. Simulation results demonstrate the effectiveness of our proposed\njoint optimization strategy under practical parameter settings, saving the\nsystem latency up to 68.54\\% compared to benchmark schemes.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Accepted to IEEE Conference on Standards for Communications and\n  Networking (CSCN), 6 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.08918v1",
    "published_date": "2024-11-01 14:25:24 UTC",
    "updated_date": "2024-11-01 14:25:24 UTC"
  },
  {
    "arxiv_id": "2411.00612v1",
    "title": "How to Bridge Spatial and Temporal Heterogeneity in Link Prediction? A Contrastive Method",
    "authors": [
      "Yu Tai",
      "Xinglong Wu",
      "Hongwei Yang",
      "Hui He",
      "Duanjing Chen",
      "Yuanming Shao",
      "Weizhe Zhang"
    ],
    "abstract": "Temporal Heterogeneous Networks play a crucial role in capturing the dynamics\nand heterogeneity inherent in various real-world complex systems, rendering\nthem a noteworthy research avenue for link prediction. However, existing\nmethods fail to capture the fine-grained differential distribution patterns and\ntemporal dynamic characteristics, which we refer to as spatial heterogeneity\nand temporal heterogeneity. To overcome such limitations, we propose a novel\n\\textbf{C}ontrastive Learning-based \\textbf{L}ink \\textbf{P}rediction model,\n\\textbf{CLP}, which employs a multi-view hierarchical self-supervised\narchitecture to encode spatial and temporal heterogeneity. Specifically, aiming\nat spatial heterogeneity, we develop a spatial feature modeling layer to\ncapture the fine-grained topological distribution patterns from node- and\nedge-level representations, respectively. Furthermore, aiming at temporal\nheterogeneity, we devise a temporal information modeling layer to perceive the\nevolutionary dependencies of dynamic graph topologies from time-level\nrepresentations. Finally, we encode the spatial and temporal distribution\nheterogeneity from a contrastive learning perspective, enabling a comprehensive\nself-supervised hierarchical relation modeling for the link prediction task.\nExtensive experiments conducted on four real-world dynamic heterogeneous\nnetwork datasets verify that our \\mymodel consistently outperforms the\nstate-of-the-art models, demonstrating an average improvement of 10.10\\%,\n13.44\\% in terms of AUC and AP, respectively.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00612v1",
    "published_date": "2024-11-01 14:20:53 UTC",
    "updated_date": "2024-11-01 14:20:53 UTC"
  },
  {
    "arxiv_id": "2411.00920v1",
    "title": "Comparative Evaluation of Applicability Domain Definition Methods for Regression Models",
    "authors": [
      "Shakir Khurshid",
      "Bharath Kumar Loganathan",
      "Matthieu Duvinage"
    ],
    "abstract": "The applicability domain refers to the range of data for which the prediction\nof the predictive model is expected to be reliable and accurate and using a\nmodel outside its applicability domain can lead to incorrect results. The\nability to define the regions in data space where a predictive model can be\nsafely used is a necessary condition for having safer and more reliable\npredictions to assure the reliability of new predictions. However, defining the\napplicability domain of a model is a challenging problem, as there is no clear\nand universal definition or metric for it. This work aims to make the\napplicability domain more quantifiable and pragmatic. Eight applicability\ndomain detection techniques were applied to seven regression models, trained on\nfive different datasets, and their performance was benchmarked using a\nvalidation framework. We also propose a novel approach based on\nnon-deterministic Bayesian neural networks to define the applicability domain\nof the model. Our method exhibited superior accuracy in defining the\nApplicability Domain compared to previous methods, highlighting its potential\nin this regard.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00920v1",
    "published_date": "2024-11-01 14:12:57 UTC",
    "updated_date": "2024-11-01 14:12:57 UTC"
  },
  {
    "arxiv_id": "2411.00919v1",
    "title": "Internship Report: Benchmark of Deep Learning-based Imaging PPG in Automotive Domain",
    "authors": [
      "Yuqi Tu",
      "Shakith Fernando",
      "Mark van Gastel"
    ],
    "abstract": "Imaging photoplethysmography (iPPG) can be used for heart rate monitoring\nduring driving, which is expected to reduce traffic accidents by continuously\nassessing drivers' physical condition. Deep learning-based iPPG methods using\nnear-infrared (NIR) cameras have recently gained attention as a promising\napproach. To help understand the challenges in applying iPPG in automotive, we\nprovide a benchmark of a NIR-based method using a deep learning model by\nevaluating its performance on MR-NIRP Car dataset. Experiment results show that\nthe average mean absolute error (MAE) is 7.5 bpm and 16.6 bpm under drivers'\nheads keeping still or having small motion, respectively. These findings\nsuggest that while the method shows promise, further improvements are needed to\nmake it reliable for real-world driving conditions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Internship Report",
    "pdf_url": "http://arxiv.org/pdf/2411.00919v1",
    "published_date": "2024-11-01 14:08:24 UTC",
    "updated_date": "2024-11-01 14:08:24 UTC"
  },
  {
    "arxiv_id": "2411.00918v1",
    "title": "LIBMoE: A Library for comprehensive benchmarking Mixture of Experts in Large Language Models",
    "authors": [
      "Nam V. Nguyen",
      "Thong T. Doan",
      "Luong Tran",
      "Van Nguyen",
      "Quang Pham"
    ],
    "abstract": "Mixture of Experts (MoEs) plays an important role in the development of more\nefficient and effective large language models (LLMs). Due to the enormous\nresource requirements, studying large scale MoE algorithms remain in-accessible\nto many researchers. This work develops \\emph{LibMoE}, a comprehensive and\nmodular framework to streamline the research, training, and evaluation of MoE\nalgorithms. Built upon three core principles: (i) modular design, (ii)\nefficient training; (iii) comprehensive evaluation, LibMoE brings MoE in LLMs\nmore accessible to a wide range of researchers by standardizing the training\nand evaluation pipelines. Using LibMoE, we extensively benchmarked five\nstate-of-the-art MoE algorithms over three different LLMs and 11 datasets under\nthe zero-shot setting. The results show that despite the unique\ncharacteristics, all MoE algorithms perform roughly similar when averaged\nacross a wide range of tasks. With the modular design and extensive evaluation,\nwe believe LibMoE will be invaluable for researchers to make meaningful\nprogress towards the next generation of MoE and LLMs. Project page:\n\\url{https://fsoft-aic.github.io/fsoft-LibMoE.github.io}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00918v1",
    "published_date": "2024-11-01 14:04:36 UTC",
    "updated_date": "2024-11-01 14:04:36 UTC"
  },
  {
    "arxiv_id": "2411.00600v1",
    "title": "On Deep Learning for Geometric and Semantic Scene Understanding Using On-Vehicle 3D LiDAR",
    "authors": [
      "Li Li"
    ],
    "abstract": "3D LiDAR point cloud data is crucial for scene perception in computer vision,\nrobotics, and autonomous driving. Geometric and semantic scene understanding,\ninvolving 3D point clouds, is essential for advancing autonomous driving\ntechnologies. However, significant challenges remain, particularly in improving\nthe overall accuracy (e.g., segmentation accuracy, depth estimation accuracy,\netc.) and efficiency of these systems. To address the challenge in terms of\naccuracy related to LiDAR-based tasks, we present DurLAR, the first\nhigh-fidelity 128-channel 3D LiDAR dataset featuring panoramic ambient (near\ninfrared) and reflectivity imagery. To improve efficiency in 3D segmentation\nwhile ensuring the accuracy, we propose a novel pipeline that employs a smaller\narchitecture, requiring fewer ground-truth annotations while achieving superior\nsegmentation accuracy compared to contemporary approaches. To improve the\nsegmentation accuracy, we introduce Range-Aware Pointwise Distance Distribution\n(RAPiD) features and the associated RAPiD-Seg architecture. All contributions\nhave been accepted by peer-reviewed conferences, underscoring the advancements\nin both accuracy and efficiency in 3D LiDAR applications for autonomous\ndriving. Full abstract: https://etheses.dur.ac.uk/15738/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "PhD thesis (Durham University, Computer Science), 149 pages (the 2024\n  BMVA Sullivan Doctoral Thesis Prize runner-up). Includes published content\n  from arXiv:2407.10159 (ECCV 2024 ORAL), arXiv:2303.11203 (CVPR 2023), and\n  arXiv:2406.10068 (3DV 2021), with minor revisions to the examined version:\n  https://etheses.dur.ac.uk/15738/",
    "pdf_url": "http://arxiv.org/pdf/2411.00600v1",
    "published_date": "2024-11-01 14:01:54 UTC",
    "updated_date": "2024-11-01 14:01:54 UTC"
  },
  {
    "arxiv_id": "2411.00916v2",
    "title": "Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering",
    "authors": [
      "Mehdi Hosseini Chagahi",
      "Saeed Mohammadi Dashtaki",
      "Niloufar Delfan",
      "Nadia Mohammadi",
      "Alireza Samari",
      "Behzad Moshiri",
      "Md. Jalil Piran",
      "Oliver Faust"
    ],
    "abstract": "Osteoporosis is a common condition that increases fracture risk, especially\nin older adults. Early diagnosis is vital for preventing fractures, reducing\ntreatment costs, and preserving mobility. However, healthcare providers face\nchallenges like limited labeled data and difficulties in processing medical\nimages. This study presents a novel multi-modal learning framework that\nintegrates clinical and imaging data to improve diagnostic accuracy and model\ninterpretability. The model utilizes three pre-trained networks-VGG19,\nInceptionV3, and ResNet50-to extract deep features from X-ray images. These\nfeatures are transformed using PCA to reduce dimensionality and focus on the\nmost relevant components. A clustering-based selection process identifies the\nmost representative components, which are then combined with preprocessed\nclinical data and processed through a fully connected network (FCN) for final\nclassification. A feature importance plot highlights key variables, showing\nthat Medical History, BMI, and Height were the main contributors, emphasizing\nthe significance of patient-specific data. While imaging features were\nvaluable, they had lower importance, indicating that clinical data are crucial\nfor accurate predictions. This framework promotes precise and interpretable\npredictions, enhancing transparency and building trust in AI-driven diagnoses\nfor clinical integration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00916v2",
    "published_date": "2024-11-01 13:58:15 UTC",
    "updated_date": "2024-11-08 09:09:27 UTC"
  },
  {
    "arxiv_id": "2411.00594v1",
    "title": "Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy",
    "authors": [
      "Mianyong Ding",
      "Matteo Maspero",
      "Annemieke S Littooij",
      "Martine van Grotel",
      "Raquel Davila Fajardo",
      "Max M van Noesel",
      "Marry M van den Heuvel-Eibrink",
      "Geert O Janssens"
    ],
    "abstract": "Purposes: This study aimed to develop a computed tomography (CT)-based\nmulti-organ segmentation model for delineating organs-at-risk (OARs) in\npediatric upper abdominal tumors and evaluate its robustness across multiple\ndatasets. Materials and methods: In-house postoperative CTs from pediatric\npatients with renal tumors and neuroblastoma (n=189) and a public dataset\n(n=189) with CTs covering thoracoabdominal regions were used. Seventeen OARs\nwere delineated: nine by clinicians (Type 1) and eight using TotalSegmentator\n(Type 2). Auto-segmentation models were trained using in-house (ModelPMC-UMCU)\nand a combined dataset of public data (Model-Combined). Performance was\nassessed with Dice Similarity Coefficient (DSC), 95% Hausdorff Distance (HD95),\nand mean surface distance (MSD). Two clinicians rated clinical acceptability on\na 5-point Likert scale across 15 patient contours. Model robustness was\nevaluated against sex, age, intravenous contrast, and tumor type. Results:\nModel-PMC-UMCU achieved mean DSC values above 0.95 for five of nine OARs, while\nspleen and heart ranged between 0.90 and 0.95. The stomach-bowel and pancreas\nexhibited DSC values below 0.90. Model-Combined demonstrated improved\nrobustness across both datasets. Clinical evaluation revealed good usability,\nwith both clinicians rating six of nine Type 1 OARs above four and six of eight\nType 2 OARs above three. Significant performance 2 differences were only found\nacross age groups in both datasets, specifically in the left lung and pancreas.\nThe 0-2 age group showed the lowest performance. Conclusion: A multi-organ\nsegmentation model was developed, showcasing enhanced robustness when trained\non combined datasets. This model is suitable for various OARs and can be\napplied to multiple datasets in clinical settings.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "23 pages, 5 figures, 1 table. Submitted to Radiotherapy and Oncology\n  (2024-11-01)",
    "pdf_url": "http://arxiv.org/pdf/2411.00594v1",
    "published_date": "2024-11-01 13:54:31 UTC",
    "updated_date": "2024-11-01 13:54:31 UTC"
  },
  {
    "arxiv_id": "2411.00593v2",
    "title": "Adapting Language Models via Token Translation",
    "authors": [
      "Zhili Feng",
      "Tanya Marwah",
      "Nicolo Fusi",
      "David Alvarez-Melis",
      "Lester Mackey"
    ],
    "abstract": "Modern large language models use a fixed tokenizer to effectively compress\ntext drawn from a source domain. However, applying the same tokenizer to a new\ntarget domain often leads to inferior compression, more costly inference, and\nreduced semantic alignment. To address this deficiency, we introduce Sparse\nSinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the\ntarget domain and learns to translate between target and source tokens,\nenabling more effective reuse of the pre-trained next-source-token predictor.\nIn our experiments with finetuned English language models, S2T2 improves both\nthe perplexity and the compression of out-of-domain protein sequences,\noutperforming direct finetuning with either the source or target tokenizer. In\naddition, we find that token translations learned for smaller, less expensive\nmodels can be directly transferred to larger, more powerful models to reap the\nbenefits of S2T2 at lower cost.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00593v2",
    "published_date": "2024-11-01 13:53:14 UTC",
    "updated_date": "2024-11-05 18:35:39 UTC"
  },
  {
    "arxiv_id": "2411.00588v1",
    "title": "$α$-TCVAE: On the relationship between Disentanglement and Diversity",
    "authors": [
      "Cristian Meo",
      "Louis Mahon",
      "Anirudh Goyal",
      "Justin Dauwels"
    ],
    "abstract": "While disentangled representations have shown promise in generative modeling\nand representation learning, their downstream usefulness remains debated.\nRecent studies re-defined disentanglement through a formal connection to\nsymmetries, emphasizing the ability to reduce latent domains and consequently\nenhance generative capabilities. However, from an information theory viewpoint,\nassigning a complex attribute to a specific latent variable may be infeasible,\nlimiting the applicability of disentangled representations to simple datasets.\nIn this work, we introduce $\\alpha$-TCVAE, a variational autoencoder optimized\nusing a novel total correlation (TC) lower bound that maximizes disentanglement\nand latent variables informativeness. The proposed TC bound is grounded in\ninformation theory constructs, generalizes the $\\beta$-VAE lower bound, and can\nbe reduced to a convex combination of the known variational information\nbottleneck (VIB) and conditional entropy bottleneck (CEB) terms. Moreover, we\npresent quantitative analyses that support the idea that disentangled\nrepresentations lead to better generative capabilities and diversity.\nAdditionally, we perform downstream task experiments from both representation\nand RL domains to assess our questions from a broader ML perspective. Our\nresults demonstrate that $\\alpha$-TCVAE consistently learns more disentangled\nrepresentations than baselines and generates more diverse observations without\nsacrificing visual fidelity. Notably, $\\alpha$-TCVAE exhibits marked\nimprovements on MPI3D-Real, the most realistic disentangled dataset in our\nstudy, confirming its ability to represent complex datasets when maximizing the\ninformativeness of individual variables. Finally, testing the proposed model\noff-the-shelf on a state-of-the-art model-based RL agent, Director,\nsignificantly shows $\\alpha$-TCVAE downstream usefulness on the loconav Ant\nMaze task.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00588v1",
    "published_date": "2024-11-01 13:50:06 UTC",
    "updated_date": "2024-11-01 13:50:06 UTC"
  },
  {
    "arxiv_id": "2411.00585v1",
    "title": "Benchmarking Bias in Large Language Models during Role-Playing",
    "authors": [
      "Xinyue Li",
      "Zhenpeng Chen",
      "Jie M. Zhang",
      "Yiling Lou",
      "Tianlin Li",
      "Weisong Sun",
      "Yang Liu",
      "Xuanzhe Liu"
    ],
    "abstract": "Large Language Models (LLMs) have become foundational in modern\nlanguage-driven applications, profoundly influencing daily life. A critical\ntechnique in leveraging their potential is role-playing, where LLMs simulate\ndiverse roles to enhance their real-world utility. However, while research has\nhighlighted the presence of social biases in LLM outputs, it remains unclear\nwhether and to what extent these biases emerge during role-playing scenarios.\nIn this paper, we introduce BiasLens, a fairness testing framework designed to\nsystematically expose biases in LLMs during role-playing. Our approach uses\nLLMs to generate 550 social roles across a comprehensive set of 11 demographic\nattributes, producing 33,000 role-specific questions targeting various forms of\nbias. These questions, spanning Yes/No, multiple-choice, and open-ended\nformats, are designed to prompt LLMs to adopt specific roles and respond\naccordingly. We employ a combination of rule-based and LLM-based strategies to\nidentify biased responses, rigorously validated through human evaluation. Using\nthe generated questions as the benchmark, we conduct extensive evaluations of\nsix advanced LLMs released by OpenAI, Mistral AI, Meta, Alibaba, and DeepSeek.\nOur benchmark reveals 72,716 biased responses across the studied LLMs, with\nindividual models yielding between 7,754 and 16,963 biased responses,\nunderscoring the prevalence of bias in role-playing contexts. To support future\nresearch, we have publicly released the benchmark, along with all scripts and\nexperimental results.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00585v1",
    "published_date": "2024-11-01 13:47:00 UTC",
    "updated_date": "2024-11-01 13:47:00 UTC"
  },
  {
    "arxiv_id": "2411.00915v5",
    "title": "Empower Vision Applications with LoRA LMM",
    "authors": [
      "Liang Mi",
      "Weijun Wang",
      "Wenming Tu",
      "Qingfeng He",
      "Rui Kong",
      "Xinyu Fang",
      "Yazhu Dong",
      "Yikang Zhang",
      "Yunchun Li",
      "Meng Li",
      "Haipeng Dai",
      "Guihai Chen",
      "Yunxin Liu"
    ],
    "abstract": "Large Multimodal Models (LMMs) have shown significant progress in various\ncomplex vision tasks with the solid linguistic and reasoning capacity inherited\nfrom large language models (LMMs). Low-rank adaptation (LoRA) offers a\npromising method to integrate external knowledge into LMMs, compensating for\ntheir limitations on domain-specific tasks. However, the existing LoRA model\nserving is excessively computationally expensive and causes extremely high\nlatency. In this paper, we present an end-to-end solution that empowers diverse\nvision tasks and enriches vision applications with LoRA LMMs. Our system,\nVaLoRA, enables accurate and efficient vision tasks by 1) an accuracy-aware\nLoRA adapter generation approach that generates LoRA adapters rich in\ndomain-specific knowledge to meet application-specific accuracy requirements,\n2) an adaptive-tiling LoRA adapters batching operator that efficiently computes\nconcurrent heterogeneous LoRA adapters, and 3) a flexible LoRA adapter\norchestration mechanism that manages application requests and LoRA adapters to\nachieve the lowest average response latency. We prototype VaLoRA on five\npopular vision tasks on three LMMs. Experiment results reveal that VaLoRA\nimproves 24-62% of the accuracy compared to the original LMMs and reduces\n20-89% of the latency compared to the state-of-the-art LoRA model serving\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "EuroSys'2025",
    "pdf_url": "http://arxiv.org/pdf/2411.00915v5",
    "published_date": "2024-11-01 13:43:33 UTC",
    "updated_date": "2025-04-03 08:56:46 UTC"
  },
  {
    "arxiv_id": "2411.00914v1",
    "title": "AAD-LLM: Adaptive Anomaly Detection Using Large Language Models",
    "authors": [
      "Alicia Russell-Gilbert",
      "Alexander Sommers",
      "Andrew Thompson",
      "Logan Cummins",
      "Sudip Mittal",
      "Shahram Rahimi",
      "Maria Seale",
      "Joseph Jaboure",
      "Thomas Arnold",
      "Joshua Church"
    ],
    "abstract": "For data-constrained, complex and dynamic industrial environments, there is a\ncritical need for transferable and multimodal methodologies to enhance anomaly\ndetection and therefore, prevent costs associated with system failures.\nTypically, traditional PdM approaches are not transferable or multimodal. This\nwork examines the use of Large Language Models (LLMs) for anomaly detection in\ncomplex and dynamic manufacturing systems. The research aims to improve the\ntransferability of anomaly detection models by leveraging Large Language Models\n(LLMs) and seeks to validate the enhanced effectiveness of the proposed\napproach in data-sparse industrial applications. The research also seeks to\nenable more collaborative decision-making between the model and plant operators\nby allowing for the enriching of input series data with semantics.\nAdditionally, the research aims to address the issue of concept drift in\ndynamic industrial settings by integrating an adaptability mechanism. The\nliterature review examines the latest developments in LLM time series tasks\nalongside associated adaptive anomaly detection methods to establish a robust\ntheoretical framework for the proposed architecture. This paper presents a\nnovel model framework (AAD-LLM) that doesn't require any training or finetuning\non the dataset it is applied to and is multimodal. Results suggest that anomaly\ndetection can be converted into a \"language\" task to deliver effective,\ncontext-aware detection in data-constrained industrial applications. This work,\ntherefore, contributes significantly to advancements in anomaly detection\nmethodologies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00914v1",
    "published_date": "2024-11-01 13:43:28 UTC",
    "updated_date": "2024-11-01 13:43:28 UTC"
  },
  {
    "arxiv_id": "2411.00913v1",
    "title": "Ratio law: mathematical descriptions for a universal relationship between AI performance and input samples",
    "authors": [
      "Boming Kang",
      "Qinghua Cui"
    ],
    "abstract": "Artificial intelligence based on machine learning and deep learning has made\nsignificant advances in various fields such as protein structure prediction and\nclimate modeling. However, a central challenge remains: the \"black box\" nature\nof AI, where precise quantitative relationships between inputs and outputs are\noften lacking. Here, by analyzing 323 AI models trained to predict human\nessential proteins, we uncovered a ratio law showing that model performance and\nthe ratio of minority to majority samples can be closely linked by two concise\nequations. Moreover, we mathematically proved that an AI model achieves its\noptimal performance on a balanced dataset. More importantly, we next explore\nwhether this finding can further guide us to enhance AI models' performance.\nTherefore, we divided the imbalanced dataset into several balanced subsets to\ntrain base classifiers, and then applied a bagging-based ensemble learning\nstrategy to combine these base models. As a result, the equation-guided\nstrategy substantially improved model performance, with increases of 4.06% and\n5.28%, respectively, outperforming traditional dataset balancing techniques.\nFinally, we confirmed the broad applicability and generalization of these\nequations using different types of classifiers and 10 additional, diverse\nbinary classification tasks. In summary, this study reveals two equations\nprecisely linking AI's input and output, which could be helpful for unboxing\nthe mysterious \"black box\" of AI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 5 figures, 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2411.00913v1",
    "published_date": "2024-11-01 13:43:19 UTC",
    "updated_date": "2024-11-01 13:43:19 UTC"
  },
  {
    "arxiv_id": "2411.00577v1",
    "title": "WLPlan: Relational Features for Symbolic Planning",
    "authors": [
      "Dillon Z. Chen"
    ],
    "abstract": "Scalable learning for planning research generally involves juggling between\ndifferent programming languages for handling learning and planning modules\neffectively. Interpreted languages such as Python are commonly used for\nlearning routines due to their ease of use and the abundance of highly\nmaintained learning libraries they exhibit, while compiled languages such as\nC++ are used for planning routines due to their optimised resource usage.\nMotivated by the need for tools for developing scalable learning planners, we\nintroduce WLPlan, a C++ package with Python bindings which implements recent\npromising work for automatically generating relational features of planning\ntasks. Such features can be used for any downstream routine, such as learning\ndomain control knowledge or probing and understanding planning tasks. More\nspecifically, WLPlan provides functionality for (1) transforming planning tasks\ninto graphs, and (2) embedding planning graphs into feature vectors via graph\nkernels. The source code and instructions for the installation and usage of\nWLPlan are available at tinyurl.com/42kymswc",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00577v1",
    "published_date": "2024-11-01 13:36:05 UTC",
    "updated_date": "2024-11-01 13:36:05 UTC"
  },
  {
    "arxiv_id": "2411.05816v1",
    "title": "Learning Characteristics of Reverse Quaternion Neural Network",
    "authors": [
      "Shogo Yamauchi",
      "Tohru Nitta",
      "Takaaki Ohnishi"
    ],
    "abstract": "The purpose of this paper is to propose a new multi-layer feedforward\nquaternion neural network model architecture, Reverse Quaternion Neural Network\nwhich utilizes the non-commutative nature of quaternion products, and to\nclarify its learning characteristics. While quaternion neural networks have\nbeen used in various fields, there has been no research report on the\ncharacteristics of multi-layer feedforward quaternion neural networks where\nweights are applied in the reverse direction. This paper investigates the\nlearning characteristics of the Reverse Quaternion Neural Network from two\nperspectives: the learning speed and the generalization on rotation. As a\nresult, it is found that the Reverse Quaternion Neural Network has a learning\nspeed comparable to existing models and can obtain a different rotation\nrepresentation from the existing models.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05816v1",
    "published_date": "2024-11-01 13:28:12 UTC",
    "updated_date": "2024-11-01 13:28:12 UTC"
  },
  {
    "arxiv_id": "2411.00563v1",
    "title": "Simulate and Optimise: A two-layer mortgage simulator for designing novel mortgage assistance products",
    "authors": [
      "Leo Ardon",
      "Benjamin Patrick Evans",
      "Deepeka Garg",
      "Annapoorani Lakshmi Narayanan",
      "Makada Henry-Nickie",
      "Sumitra Ganesh"
    ],
    "abstract": "We develop a novel two-layer approach for optimising mortgage relief products\nthrough a simulated multi-agent mortgage environment. While the approach is\ngeneric, here the environment is calibrated to the US mortgage market based on\npublicly available census data and regulatory guidelines. Through the\nsimulation layer, we assess the resilience of households to exogenous income\nshocks, while the optimisation layer explores strategies to improve the\nrobustness of households to these shocks by making novel mortgage assistance\nproducts available to households. Households in the simulation are adaptive,\nlearning to make mortgage-related decisions (such as product enrolment or\nstrategic foreclosures) that maximize their utility, balancing their available\nliquidity and equity. We show how this novel two-layer simulation approach can\nsuccessfully design novel mortgage assistance products to improve household\nresilience to exogenous shocks, and balance the costs of providing such\nproducts through post-hoc analysis. Previously, such analysis could only be\nconducted through expensive pilot studies involving real participants,\ndemonstrating the benefit of the approach for designing and evaluating\nfinancial products.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CE",
      "q-fin.CP"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at the 5th ACM International Conference on AI in Finance",
    "pdf_url": "http://arxiv.org/pdf/2411.00563v1",
    "published_date": "2024-11-01 13:21:11 UTC",
    "updated_date": "2024-11-01 13:21:11 UTC"
  },
  {
    "arxiv_id": "2411.00556v1",
    "title": "LLM-KT: A Versatile Framework for Knowledge Transfer from Large Language Models to Collaborative Filtering",
    "authors": [
      "Nikita Severin",
      "Aleksei Ziablitsev",
      "Yulia Savelyeva",
      "Valeriy Tashchilin",
      "Ivan Bulychev",
      "Mikhail Yushkov",
      "Artem Kushneruk",
      "Amaliya Zaryvnykh",
      "Dmitrii Kiselev",
      "Andrey Savchenko",
      "Ilya Makarov"
    ],
    "abstract": "We present LLM-KT, a flexible framework designed to enhance collaborative\nfiltering (CF) models by seamlessly integrating LLM (Large Language\nModel)-generated features. Unlike existing methods that rely on passing\nLLM-generated features as direct inputs, our framework injects these features\ninto an intermediate layer of any CF model, allowing the model to reconstruct\nand leverage the embeddings internally. This model-agnostic approach works with\na wide range of CF models without requiring architectural changes, making it\nadaptable to various recommendation scenarios. Our framework is built for easy\nintegration and modification, providing researchers and developers with a\npowerful tool for extending CF model capabilities through efficient knowledge\ntransfer. We demonstrate its effectiveness through experiments on the MovieLens\nand Amazon datasets, where it consistently improves baseline CF models.\nExperimental studies showed that LLM-KT is competitive with the\nstate-of-the-art methods in context-aware settings but can be applied to a\nbroader range of CF models than current approaches.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "accepted at ICDM 2024 (demo track)",
    "pdf_url": "http://arxiv.org/pdf/2411.00556v1",
    "published_date": "2024-11-01 13:09:30 UTC",
    "updated_date": "2024-11-01 13:09:30 UTC"
  },
  {
    "arxiv_id": "2411.00554v3",
    "title": "Differentiable Physics-based System Identification for Robotic Manipulation of Elastoplastic Materials",
    "authors": [
      "Xintong Yang",
      "Ze Ji",
      "Yu-Kun Lai"
    ],
    "abstract": "Robotic manipulation of volumetric elastoplastic deformable materials, from\nfoods such as dough to construction materials like clay, is in its infancy,\nlargely due to the difficulty of modelling and perception in a high-dimensional\nspace. Simulating the dynamics of such materials is computationally expensive.\nIt tends to suffer from inaccurately estimated physics parameters of the\nmaterials and the environment, impeding high-precision manipulation. Estimating\nsuch parameters from raw point clouds captured by optical cameras suffers\nfurther from heavy occlusions. To address this challenge, this work introduces\na novel Differentiable Physics-based System Identification (DPSI) framework\nthat enables a robot arm to infer the physics parameters of elastoplastic\nmaterials and the environment using simple manipulation motions and incomplete\n3D point clouds, aligning the simulation with the real world. Extensive\nexperiments show that with only a single real-world interaction, the estimated\nparameters, Young's modulus, Poisson's ratio, yield stress and friction\ncoefficients, can accurately simulate visually and physically realistic\ndeformation behaviours induced by unseen and long-horizon manipulation motions.\nAdditionally, the DPSI framework inherently provides physically intuitive\ninterpretations for the parameters in contrast to black-box approaches such as\ndeep neural networks. The project is fully open-sourced via\nhttps://ianyangchina.github.io/SI4RP-data/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by the Internation Journal of Robotics Research",
    "pdf_url": "http://arxiv.org/pdf/2411.00554v3",
    "published_date": "2024-11-01 13:04:25 UTC",
    "updated_date": "2025-02-18 08:35:55 UTC"
  },
  {
    "arxiv_id": "2411.00551v1",
    "title": "Conditional Synthesis of 3D Molecules with Time Correction Sampler",
    "authors": [
      "Hojung Jung",
      "Youngrok Park",
      "Laura Schmid",
      "Jaehyeong Jo",
      "Dongkyu Lee",
      "Bongsang Kim",
      "Se-Young Yun",
      "Jinwoo Shin"
    ],
    "abstract": "Diffusion models have demonstrated remarkable success in various domains,\nincluding molecular generation. However, conditional molecular generation\nremains a fundamental challenge due to an intrinsic trade-off between targeting\nspecific chemical properties and generating meaningful samples from the data\ndistribution. In this work, we present Time-Aware Conditional Synthesis (TACS),\na novel approach to conditional generation on diffusion models. It integrates\nadaptively controlled plug-and-play \"online\" guidance into a diffusion model,\ndriving samples toward the desired properties while maintaining validity and\nstability. A key component of our algorithm is our new type of diffusion\nsampler, Time Correction Sampler (TCS), which is used to control guidance and\nensure that the generated molecules remain on the correct manifold at each\nreverse step of the diffusion process at the same time. Our proposed method\ndemonstrates significant performance in conditional 3D molecular generation and\noffers a promising approach towards inverse molecular design, potentially\nfacilitating advancements in drug discovery, materials science, and other\nrelated fields.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00551v1",
    "published_date": "2024-11-01 12:59:25 UTC",
    "updated_date": "2024-11-01 12:59:25 UTC"
  },
  {
    "arxiv_id": "2411.00548v1",
    "title": "Generative AI-based Pipeline Architecture for Increasing Training Efficiency in Intelligent Weed Control Systems",
    "authors": [
      "Sourav Modak",
      "Anthony Stein"
    ],
    "abstract": "In automated crop protection tasks such as weed control, disease diagnosis,\nand pest monitoring, deep learning has demonstrated significant potential.\nHowever, these advanced models rely heavily on high-quality, diverse datasets,\noften limited and costly in agricultural settings. Traditional data\naugmentation can increase dataset volume but usually lacks the real-world\nvariability needed for robust training. This study presents a new approach for\ngenerating synthetic images to improve deep learning-based object detection\nmodels for intelligent weed control. Our GenAI-based image generation pipeline\nintegrates the Segment Anything Model (SAM) for zero-shot domain adaptation\nwith a text-to-image Stable Diffusion Model, enabling the creation of synthetic\nimages that capture diverse real-world conditions. We evaluate these synthetic\ndatasets using lightweight YOLO models, measuring data efficiency with mAP50\nand mAP50-95 scores across varying proportions of real and synthetic data.\nNotably, YOLO models trained on datasets with 10% synthetic and 90% real images\ngenerally demonstrate superior mAP50 and mAP50-95 scores compared to those\ntrained solely on real images. This approach not only reduces dependence on\nextensive real-world datasets but also enhances predictive performance. The\nintegration of this approach opens opportunities for achieving continual\nself-improvement of perception modules in intelligent technical systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00548v1",
    "published_date": "2024-11-01 12:58:27 UTC",
    "updated_date": "2024-11-01 12:58:27 UTC"
  },
  {
    "arxiv_id": "2411.00533v4",
    "title": "ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot Named Entity Recognition with Large Language Models",
    "authors": [
      "Anbang Wang",
      "Difei Mei",
      "Zhichao Zhang",
      "Xiuxiu Bai",
      "Ran Yao",
      "Zewen Fang",
      "Min Hu",
      "Zhirui Cao",
      "Haitao Sun",
      "Yifeng Guo",
      "Hongyao Zhou",
      "Yu Guo"
    ],
    "abstract": "This paper presents ReverseNER, a method aimed at overcoming the limitation\nof large language models (LLMs) in zero-shot named entity recognition (NER)\ntasks, arising from their reliance on pre-provided demonstrations. ReverseNER\ntackles this challenge by constructing a reliable example library composed of\ndozens of entity-labeled sentences, generated through the reverse process of\nNER. Specifically, while conventional NER methods label entities in a sentence,\nReverseNER features reversing the process by using an LLM to generate entities\nfrom their definitions and subsequently expand them into full sentences. During\nthe entity expansion process, the LLM is guided to generate sentences by\nreplicating the structures of a set of specific \\textsl{feature sentences},\nextracted from the task sentences by clustering. This expansion process\nproduces dozens of entity-labeled task-relevant sentences. After constructing\nthe example library, the method selects several semantically similar\nentity-labeled examples for each task sentence as references to facilitate the\nLLM's entity recognition. We also propose an entity-level self-consistency\nscoring mechanism to improve NER performance with LLMs. Experiments show that\nReverseNER significantly outperforms other zero-shot NER methods with LLMs,\nmarking a notable improvement in NER for domains without labeled data, while\ndeclining computational resource consumption.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00533v4",
    "published_date": "2024-11-01 12:08:08 UTC",
    "updated_date": "2024-12-25 16:13:57 UTC"
  },
  {
    "arxiv_id": "2411.00489v2",
    "title": "Human-inspired Perspectives: A Survey on AI Long-term Memory",
    "authors": [
      "Zihong He",
      "Weizhe Lin",
      "Hao Zheng",
      "Fan Zhang",
      "Matt W. Jones",
      "Laurence Aitchison",
      "Xuhai Xu",
      "Miao Liu",
      "Per Ola Kristensson",
      "Junxiao Shen"
    ],
    "abstract": "With the rapid advancement of AI systems, their abilities to store, retrieve,\nand utilize information over the long term - referred to as long-term memory -\nhave become increasingly significant. These capabilities are crucial for\nenhancing the performance of AI systems across a wide range of tasks. However,\nthere is currently no comprehensive survey that systematically investigates\nAI's long-term memory capabilities, formulates a theoretical framework, and\ninspires the development of next-generation AI long-term memory systems. This\npaper begins by introducing the mechanisms of human long-term memory, then\nexplores AI long-term memory mechanisms, establishing a mapping between the\ntwo. Based on the mapping relationships identified, we extend the current\ncognitive architectures and propose the Cognitive Architecture of Self-Adaptive\nLong-term Memory (SALM). SALM provides a theoretical framework for the practice\nof AI long-term memory and holds potential for guiding the creation of\nnext-generation long-term memory driven AI systems. Finally, we delve into the\nfuture directions and application prospects of AI long-term memory.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00489v2",
    "published_date": "2024-11-01 10:04:01 UTC",
    "updated_date": "2025-01-12 06:08:20 UTC"
  },
  {
    "arxiv_id": "2411.00477v1",
    "title": "Multi Modal Information Fusion of Acoustic and Linguistic Data for Decoding Dairy Cow Vocalizations in Animal Welfare Assessment",
    "authors": [
      "Bubacarr Jobarteh",
      "Madalina Mincu",
      "Gavojdian Dinu",
      "Suresh Neethirajan"
    ],
    "abstract": "Understanding animal vocalizations through multi-source data fusion is\ncrucial for assessing emotional states and enhancing animal welfare in\nprecision livestock farming. This study aims to decode dairy cow contact calls\nby employing multi-modal data fusion techniques, integrating transcription,\nsemantic analysis, contextual and emotional assessment, and acoustic feature\nextraction. We utilized the Natural Language Processing model to transcribe\naudio recordings of cow vocalizations into written form. By fusing multiple\nacoustic features frequency, duration, and intensity with transcribed textual\ndata, we developed a comprehensive representation of cow vocalizations.\nUtilizing data fusion within a custom-developed ontology, we categorized\nvocalizations into high frequency calls associated with distress or arousal,\nand low frequency calls linked to contentment or calmness. Analyzing the fused\nmulti dimensional data, we identified anxiety related features indicative of\nemotional distress, including specific frequency measurements and sound\nspectrum results. Assessing the sentiment and acoustic features of\nvocalizations from 20 individual cows allowed us to determine differences in\ncalling patterns and emotional states. Employing advanced machine learning\nalgorithms, Random Forest, Support Vector Machine, and Recurrent Neural\nNetworks, we effectively processed and fused multi-source data to classify cow\nvocalizations. These models were optimized to handle computational demands and\ndata quality challenges inherent in practical farm environments. Our findings\ndemonstrate the effectiveness of multi-source data fusion and intelligent\nprocessing techniques in animal welfare monitoring. This study represents a\nsignificant advancement in animal welfare assessment, highlighting the role of\ninnovative fusion technologies in understanding and improving the emotional\nwellbeing of dairy cows.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "q-bio.QM"
    ],
    "primary_category": "cs.SD",
    "comment": "31 pages, 22 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.00477v1",
    "published_date": "2024-11-01 09:48:30 UTC",
    "updated_date": "2024-11-01 09:48:30 UTC"
  },
  {
    "arxiv_id": "2411.00469v1",
    "title": "MIRFLEX: Music Information Retrieval Feature Library for Extraction",
    "authors": [
      "Anuradha Chopra",
      "Abhinaba Roy",
      "Dorien Herremans"
    ],
    "abstract": "This paper introduces an extendable modular system that compiles a range of\nmusic feature extraction models to aid music information retrieval research.\nThe features include musical elements like key, downbeats, and genre, as well\nas audio characteristics like instrument recognition, vocals/instrumental\nclassification, and vocals gender detection. The integrated models are\nstate-of-the-art or latest open-source. The features can be extracted as latent\nor post-processed labels, enabling integration into music applications such as\ngenerative music, recommendation, and playlist generation. The modular design\nallows easy integration of newly developed systems, making it a good\nbenchmarking and comparison tool. This versatile toolkit supports the research\ncommunity in developing innovative solutions by providing concrete musical\nfeatures.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "eess.AS",
      "I.2.7"
    ],
    "primary_category": "cs.SD",
    "comment": "2 pages, 4 tables, submitted to Extended Abstracts for the\n  Late-Breaking Demo Session of the 25th Int. Society for Music Information\n  Retrieval Conf., San Francisco, United States, 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00469v1",
    "published_date": "2024-11-01 09:34:36 UTC",
    "updated_date": "2024-11-01 09:34:36 UTC"
  },
  {
    "arxiv_id": "2411.00465v1",
    "title": "Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse Data Corruptions",
    "authors": [
      "Rui Yang",
      "Jie Wang",
      "Guoping Wu",
      "Bin Li"
    ],
    "abstract": "Real-world offline datasets are often subject to data corruptions (such as\nnoise or adversarial attacks) due to sensor failures or malicious attacks.\nDespite advances in robust offline reinforcement learning (RL), existing\nmethods struggle to learn robust agents under high uncertainty caused by the\ndiverse corrupted data (i.e., corrupted states, actions, rewards, and\ndynamics), leading to performance degradation in clean environments. To tackle\nthis problem, we propose a novel robust variational Bayesian inference for\noffline RL (TRACER). It introduces Bayesian inference for the first time to\ncapture the uncertainty via offline data for robustness against all types of\ndata corruptions. Specifically, TRACER first models all corruptions as the\nuncertainty in the action-value function. Then, to capture such uncertainty, it\nuses all offline data as the observations to approximate the posterior\ndistribution of the action-value function under a Bayesian inference framework.\nAn appealing feature of TRACER is that it can distinguish corrupted data from\nclean data using an entropy-based uncertainty measure, since corrupted data\noften induces higher uncertainty and entropy. Based on the aforementioned\nmeasure, TRACER can regulate the loss associated with corrupted data to reduce\nits influence, thereby enhancing robustness and performance in clean\nenvironments. Experiments demonstrate that TRACER significantly outperforms\nseveral state-of-the-art approaches across both individual and simultaneous\ndata corruptions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00465v1",
    "published_date": "2024-11-01 09:28:24 UTC",
    "updated_date": "2024-11-01 09:28:24 UTC"
  },
  {
    "arxiv_id": "2411.00907v3",
    "title": "On the Impact of White-box Deployment Strategies for Edge AI on Latency and Model Performance",
    "authors": [
      "Jaskirat Singh",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "abstract": "To help MLOps engineers decide which operator to use in which deployment\nscenario, this study aims to empirically assess the accuracy vs latency\ntrade-off of white-box (training-based) and black-box operators\n(non-training-based) and their combinations in an Edge AI setup. We perform\ninference experiments including 3 white-box (i.e., QAT, Pruning, Knowledge\nDistillation), 2 black-box (i.e., Partition, SPTQ), and their combined\noperators (i.e., Distilled SPTQ, SPTQ Partition) across 3 tiers (i.e., Mobile,\nEdge, Cloud) on 4 commonly-used Computer Vision and Natural Language Processing\nmodels to identify the effective strategies, considering the perspective of\nMLOps Engineers. Our Results indicate that the combination of Distillation and\nSPTQ operators (i.e., DSPTQ) should be preferred over non-hybrid operators when\nlower latency is required in the edge at small to medium accuracy drop. Among\nthe non-hybrid operators, the Distilled operator is a better alternative in\nboth mobile and edge tiers for lower latency performance at the cost of small\nto medium accuracy loss. Moreover, the operators involving distillation show\nlower latency in resource-constrained tiers (Mobile, Edge) compared to the\noperators involving Partitioning across Mobile and Edge tiers. For textual\nsubject models, which have low input data size requirements, the Cloud tier is\na better alternative for the deployment of operators than the Mobile, Edge, or\nMobile-Edge tier (the latter being used for operators involving partitioning).\nIn contrast, for image-based subject models, which have high input data size\nrequirements, the Edge tier is a better alternative for operators than Mobile,\nEdge, or their combination.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "In Approach Section, Pruning & Knowledge Distillation methods of\n  Intel Neural Compressor don't reduce the model size & improve performance,\n  respectively, unlike previous studies. There are issues exporting QAT models\n  from PyTorch to ONNX, raising concerns about our latency results",
    "pdf_url": "http://arxiv.org/pdf/2411.00907v3",
    "published_date": "2024-11-01 09:22:49 UTC",
    "updated_date": "2025-01-22 05:04:26 UTC"
  },
  {
    "arxiv_id": "2411.00461v2",
    "title": "A Multi-Granularity Supervised Contrastive Framework for Remaining Useful Life Prediction of Aero-engines",
    "authors": [
      "Zixuan He",
      "Ziqian Kong",
      "Zhengyu Chen",
      "Yuling Zhan",
      "Zijun Que",
      "Zhengguo Xu"
    ],
    "abstract": "Accurate remaining useful life (RUL) predictions are critical to the safe\noperation of aero-engines. Currently, the RUL prediction task is mainly a\nregression paradigm with only mean square error as the loss function and lacks\nresearch on feature space structure, the latter of which has shown excellent\nperformance in a large number of studies. This paper develops a\nmulti-granularity supervised contrastive (MGSC) framework from plain intuition\nthat samples with the same RUL label should be aligned in the feature space,\nand address the problems of too large minibatch size and unbalanced samples in\nthe implementation. The RUL prediction with MGSC is implemented on using the\nproposed multi-phase training strategy. This paper also demonstrates a simple\nand scalable basic network structure and validates the proposed MGSC strategy\non the CMPASS dataset using a convolutional long short-term memory network as a\nbaseline, which effectively improves the accuracy of RUL prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00461v2",
    "published_date": "2024-11-01 09:18:38 UTC",
    "updated_date": "2024-11-15 03:01:59 UTC"
  },
  {
    "arxiv_id": "2411.02430v1",
    "title": "Generative Emotion Cause Explanation in Multimodal Conversations",
    "authors": [
      "Lin Wang",
      "Xiaocui Yang",
      "Shi Feng",
      "Daling Wang",
      "Yifei Zhang"
    ],
    "abstract": "Multimodal conversation, a crucial form of human communication, carries rich\nemotional content, making the exploration of the causes of emotions within it a\nresearch endeavor of significant importance. However, existing research on the\ncauses of emotions typically uses clause selection methods to locate the reason\nutterance, without providing a detailed explanation of the emotional causes. In\nthis paper, we propose a new task, \\textbf{M}ultimodal \\textbf{C}onversation\n\\textbf{E}motion \\textbf{C}ause \\textbf{E}xplanation (MCECE), aiming to\ngenerate a detailed explanation of the emotional cause to the target utterance\nwithin a multimodal conversation scenario. Building upon the MELD dataset, we\ndevelop a new dataset (ECEM) that integrates video clips with detailed\nexplanations of character emotions, facilitating an in-depth examination of the\ncausal factors behind emotional expressions in multimodal conversations.A novel\napproach, FAME-Net, is further proposed, that harnesses the power of Large\nLanguage Models (LLMs) to analyze visual data and accurately interpret the\nemotions conveyed through facial expressions in videos. By exploiting the\ncontagion effect of facial emotions, FAME-Net effectively captures the\nemotional causes of individuals engaged in conversations. Our experimental\nresults on the newly constructed dataset show that FAME-Net significantly\noutperforms several excellent large language model baselines. Code and dataset\nare available at \\url{https://github.com/3222345200/ECEMdataset.git}",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02430v1",
    "published_date": "2024-11-01 09:16:30 UTC",
    "updated_date": "2024-11-01 09:16:30 UTC"
  },
  {
    "arxiv_id": "2411.11853v3",
    "title": "Chat Bankman-Fried: an Exploration of LLM Alignment in Finance",
    "authors": [
      "Claudia Biancotti",
      "Carolina Camassa",
      "Andrea Coletta",
      "Oliver Giudice",
      "Aldo Glielmo"
    ],
    "abstract": "Advancements in large language models (LLMs) have renewed concerns about AI\nalignment - the consistency between human and AI goals and values. As various\njurisdictions enact legislation on AI safety, the concept of alignment must be\ndefined and measured across different domains. This paper proposes an\nexperimental framework to assess whether LLMs adhere to ethical and legal\nstandards in the relatively unexplored context of finance. We prompt twelve\nLLMs to impersonate the CEO of a financial institution and test their\nwillingness to misuse customer assets to repay outstanding corporate debt.\nBeginning with a baseline configuration, we adjust preferences, incentives and\nconstraints, analyzing the impact of each adjustment with logistic regression.\nOur findings reveal significant heterogeneity in the baseline propensity for\nunethical behavior of LLMs. Factors such as risk aversion, profit expectations,\nand regulatory environment consistently influence misalignment in ways\npredicted by economic theory, although the magnitude of these effects varies\nacross LLMs. This paper highlights both the benefits and limitations of\nsimulation-based, ex post safety testing. While it can inform financial\nauthorities and institutions aiming to ensure LLM safety, there is a clear\ntrade-off between generality and cost.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "q-fin.GN"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11853v3",
    "published_date": "2024-11-01 08:56:17 UTC",
    "updated_date": "2025-02-25 15:10:34 UTC"
  },
  {
    "arxiv_id": "2411.00904v1",
    "title": "Similarity and Dissimilarity Guided Co-association Matrix Construction for Ensemble Clustering",
    "authors": [
      "Xu Zhang",
      "Yuheng Jia",
      "Mofei Song",
      "Ran Wang"
    ],
    "abstract": "Ensemble clustering aggregates multiple weak clusterings to achieve a more\naccurate and robust consensus result. The Co-Association matrix (CA matrix)\nbased method is the mainstream ensemble clustering approach that constructs the\nsimilarity relationships between sample pairs according the weak clustering\npartitions to generate the final clustering result. However, the existing\nmethods neglect that the quality of cluster is related to its size, i.e., a\ncluster with smaller size tends to higher accuracy. Moreover, they also do not\nconsider the valuable dissimilarity information in the base clusterings which\ncan reflect the varying importance of sample pairs that are completely\ndisconnected. To this end, we propose the Similarity and Dissimilarity Guided\nCo-association matrix (SDGCA) to achieve ensemble clustering. First, we\nintroduce normalized ensemble entropy to estimate the quality of each cluster,\nand construct a similarity matrix based on this estimation. Then, we employ the\nrandom walk to explore high-order proximity of base clusterings to construct a\ndissimilarity matrix. Finally, the adversarial relationship between the\nsimilarity matrix and the dissimilarity matrix is utilized to construct a\npromoted CA matrix for ensemble clustering. We compared our method with 13\nstate-of-the-art methods across 12 datasets, and the results demonstrated the\nsuperiority clustering ability and robustness of the proposed approach. The\ncode is available at https://github.com/xuz2019/SDGCA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00904v1",
    "published_date": "2024-11-01 08:10:28 UTC",
    "updated_date": "2024-11-01 08:10:28 UTC"
  },
  {
    "arxiv_id": "2411.00437v2",
    "title": "E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation",
    "authors": [
      "Yun Jiang",
      "Zilong Xie",
      "Wei Zhang",
      "Yun Fang",
      "Shuai Pan"
    ],
    "abstract": "Retrieval-augmented generation methods often neglect the quality of content\nretrieved from external knowledge bases, resulting in irrelevant information or\npotential misinformation that negatively affects the generation results of\nlarge language models. In this paper, we propose an end-to-end model with\nadaptive filtering for retrieval-augmented generation (E2E-AFG), which\nintegrates answer existence judgment and text generation into a single\nend-to-end framework. This enables the model to focus more effectively on\nrelevant content while reducing the influence of irrelevant information and\ngenerating accurate answers. We evaluate E2E-AFG on six representative\nknowledge-intensive language datasets, and the results show that it\nconsistently outperforms baseline models across all tasks, demonstrating the\neffectiveness and robustness of the proposed approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 3 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.00437v2",
    "published_date": "2024-11-01 08:02:09 UTC",
    "updated_date": "2025-05-08 07:29:10 UTC"
  },
  {
    "arxiv_id": "2411.00431v1",
    "title": "Integrating Fuzzy Logic into Deep Symbolic Regression",
    "authors": [
      "Wout Gerdes",
      "Erman Acar"
    ],
    "abstract": "Credit card fraud detection is a critical concern for financial institutions,\nintensified by the rise of contactless payment technologies. While deep\nlearning models offer high accuracy, their lack of explainability poses\nsignificant challenges in financial settings. This paper explores the\nintegration of fuzzy logic into Deep Symbolic Regression (DSR) to enhance both\nperformance and explainability in fraud detection. We investigate the\neffectiveness of different fuzzy logic implications, specifically\n{\\L}ukasiewicz, G\\\"odel, and Product, in handling the complexity and\nuncertainty of fraud detection datasets. Our analysis suggest that the\n{\\L}ukasiewicz implication achieves the highest F1-score and overall accuracy,\nwhile the Product implication offers a favorable balance between performance\nand explainability. Despite having a performance lower than state-of-the-art\n(SOTA) models due to information loss in data transformation, our approach\nprovides novelty and insights into into integrating fuzzy logic into DSR for\nfraud detection, providing a comprehensive comparison between different\nimplications and methods.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 1 figure, published for XAI FIN 24\n  https://easychair.org/cfp/xaifin2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00431v1",
    "published_date": "2024-11-01 07:55:17 UTC",
    "updated_date": "2024-11-01 07:55:17 UTC"
  },
  {
    "arxiv_id": "2411.00427v1",
    "title": "DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems",
    "authors": [
      "Aman Gupta",
      "Anirudh Ravichandran",
      "Ziji Zhang",
      "Swair Shah",
      "Anurag Beniwal",
      "Narayanan Sadagopan"
    ],
    "abstract": "Task-oriented dialogue systems are essential for applications ranging from\ncustomer service to personal assistants and are widely used across various\nindustries. However, developing effective multi-domain systems remains a\nsignificant challenge due to the complexity of handling diverse user intents,\nentity types, and domain-specific knowledge across several domains. In this\nwork, we propose DARD (Domain Assigned Response Delegation), a multi-agent\nconversational system capable of successfully handling multi-domain dialogs.\nDARD leverages domain-specific agents, orchestrated by a central dialog manager\nagent. Our extensive experiments compare and utilize various agent modeling\napproaches, combining the strengths of smaller fine-tuned models (Flan-T5-large\n& Mistral-7B) with their larger counterparts, Large Language Models (LLMs)\n(Claude Sonnet 3.0). We provide insights into the strengths and limitations of\neach approach, highlighting the benefits of our multi-agent framework in terms\nof flexibility and composability. We evaluate DARD using the well-established\nMultiWOZ benchmark, achieving state-of-the-art performance by improving the\ndialogue inform rate by 6.6% and the success rate by 4.1% over the\nbest-performing existing approaches. Additionally, we discuss various annotator\ndiscrepancies and issues within the MultiWOZ dataset and its evaluation system.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00427v1",
    "published_date": "2024-11-01 07:50:19 UTC",
    "updated_date": "2024-11-01 07:50:19 UTC"
  },
  {
    "arxiv_id": "2411.00418v2",
    "title": "Self-Evolved Reward Learning for LLMs",
    "authors": [
      "Chenghua Huang",
      "Zhizhen Fan",
      "Lu Wang",
      "Fangkai Yang",
      "Pu Zhao",
      "Zeqi Lin",
      "Qingwei Lin",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for\naligning language models with human preferences, playing a pivotal role in the\nsuccess of conversational models like GPT-4, ChatGPT, and Llama 2. A core\nchallenge in employing RLHF lies in training a reliable reward model (RM),\nwhich relies on high-quality labels typically provided by human experts or\nadvanced AI system. These methods can be costly and may introduce biases that\naffect the language model's responses. As language models improve, human input\nmay become less effective in further enhancing their performance. In this\npaper, we propose Self-Evolved Reward Learning (SER), a novel approach where\nthe RM generates additional training data to iteratively improve itself. We\nconducted extensive experiments on multiple datasets such as HH-RLHF and\nUltraFeedback, using models like Mistral and Llama 3, and compare SER against\nvarious baselines. Our results demonstrate that even with limited\nhuman-annotated data, learning from self-feedback can robustly enhance RM\nperformance, thereby boosting the capabilities of large language models (LLMs).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages,6 figures,Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.00418v2",
    "published_date": "2024-11-01 07:29:03 UTC",
    "updated_date": "2025-02-28 03:37:09 UTC"
  },
  {
    "arxiv_id": "2411.00414v1",
    "title": "On the Opportunities of Large Language Models for Programming Process Data",
    "authors": [
      "John Edwards",
      "Arto Hellas",
      "Juho Leinonen"
    ],
    "abstract": "Computing educators and researchers have used programming process data to\nunderstand how programs are constructed and what sorts of problems students\nstruggle with. Although such data shows promise for using it for feedback,\nfully automated programming process feedback systems have still been an\nunder-explored area. The recent emergence of large language models (LLMs) have\nyielded additional opportunities for researchers in a wide variety of fields.\nLLMs are efficient at transforming content from one format to another,\nleveraging the body of knowledge they have been trained with in the process. In\nthis article, we discuss opportunities of using LLMs for analyzing programming\nprocess data. To complement our discussion, we outline a case study where we\nhave leveraged LLMs for automatically summarizing the programming process and\nfor creating formative feedback on the programming process. Overall, our\ndiscussion and findings highlight that the computing education research and\npractice community is again one step closer to automating formative programming\nprocess-focused feedback.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.3; E.m"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.00414v1",
    "published_date": "2024-11-01 07:20:01 UTC",
    "updated_date": "2024-11-01 07:20:01 UTC"
  },
  {
    "arxiv_id": "2411.00902v1",
    "title": "Differentiable architecture search with multi-dimensional attention for spiking neural networks",
    "authors": [
      "Yilei Man",
      "Linhai Xie",
      "Shushan Qiao",
      "Yumei Zhou",
      "Delong Shang"
    ],
    "abstract": "Spiking Neural Networks (SNNs) have gained enormous popularity in the field\nof artificial intelligence due to their low power consumption. However, the\nmajority of SNN methods directly inherit the structure of Artificial Neural\nNetworks (ANN), usually leading to sub-optimal model performance in SNNs. To\nalleviate this problem, we integrate Neural Architecture Search (NAS) method\nand propose Multi-Attention Differentiable Architecture Search (MA-DARTS) to\ndirectly automate the search for the optimal network structure of SNNs.\nInitially, we defined a differentiable two-level search space and conducted\nexperiments within micro architecture under a fixed layer. Then, we\nincorporated a multi-dimensional attention mechanism and implemented the\nMA-DARTS algorithm in this search space. Comprehensive experiments demonstrate\nour model achieves state-of-the-art performance on classification compared to\nother methods under the same parameters with 94.40% accuracy on CIFAR10 dataset\nand 76.52% accuracy on CIFAR100 dataset. Additionally, we monitored and\nassessed the number of spikes (NoS) in each cell during the whole experiment.\nNotably, the number of spikes of the whole model stabilized at approximately\n110K in validation and 100k in training on datasets.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00902v1",
    "published_date": "2024-11-01 07:18:32 UTC",
    "updated_date": "2024-11-01 07:18:32 UTC"
  },
  {
    "arxiv_id": "2411.00412v3",
    "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation",
    "authors": [
      "Bohan Lyu",
      "Yadi Cao",
      "Duncan Watson-Parris",
      "Leon Bergen",
      "Taylor Berg-Kirkpatrick",
      "Rose Yu"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate promising capabilities in solving\nsimple scientific problems but, even with domain-specific fine-tuning, often\nproduce hallucinations for complex ones. While integrating LLMs with tools can\nmitigate this reliability issue, models finetuned on tool usage only often\nover-rely on them, incurring unnecessary costs from resource-intensive\nscientific tools even for simpler problems. Inspired by how human experts\nassess the complexity of the problem before choosing the solutions, we propose\na novel two-component fine-tuning method, Adapting While Learning (AWL). In the\nfirst component, World Knowledge Learning (WKL), LLMs internalize scientific\nknowledge by learning from tools-generated solutions. In the second component,\nTool Usage Adaptation (TUA), we classify questions as easy or hard based on the\nWKL-trained model's accuracy, and train it to maintain direct reasoning for\nsimple problems while switching to tools for challenging ones. We validate our\nmethod on 6 scientific benchmark datasets in climate science, epidemiology, and\nmathematics. Compared to the base 8B model, our trained models achieve 28.27%\nhigher answer accuracy and 13.76% better tool usage accuracy, even surpassing\nstate-of-the-art models including GPT-4 and Claude-3.5 on 4 custom-created\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00412v3",
    "published_date": "2024-11-01 07:18:31 UTC",
    "updated_date": "2025-02-06 04:18:46 UTC"
  },
  {
    "arxiv_id": "2411.00401v2",
    "title": "Statistical Guarantees for Lifelong Reinforcement Learning using PAC-Bayes Theory",
    "authors": [
      "Zhi Zhang",
      "Chris Chow",
      "Yasi Zhang",
      "Yanchao Sun",
      "Haochen Zhang",
      "Eric Hanchen Jiang",
      "Han Liu",
      "Furong Huang",
      "Yuchen Cui",
      "Oscar Hernan Madrid Padilla"
    ],
    "abstract": "Lifelong reinforcement learning (RL) has been developed as a paradigm for\nextending single-task RL to more realistic, dynamic settings. In lifelong RL,\nthe \"life\" of an RL agent is modeled as a stream of tasks drawn from a task\ndistribution. We propose EPIC (Empirical PAC-Bayes that Improves Continuously),\na novel algorithm designed for lifelong RL using PAC-Bayes theory. EPIC learns\na shared policy distribution, referred to as the world policy, which enables\nrapid adaptation to new tasks while retaining valuable knowledge from previous\nexperiences. Our theoretical analysis establishes a relationship between the\nalgorithm's generalization performance and the number of prior tasks preserved\nin memory. We also derive the sample complexity of EPIC in terms of RL regret.\nExtensive experiments on a variety of environments demonstrate that EPIC\nsignificantly outperforms existing methods in lifelong RL, offering both\ntheoretical guarantees and practical efficacy through the use of the world\npolicy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05, 68Q32, 68T20",
      "I.2.6; I.2.8; G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures, accepted at AISTATS 2025 (PMLR Vol 258), paper ID\n  9417",
    "pdf_url": "http://arxiv.org/pdf/2411.00401v2",
    "published_date": "2024-11-01 07:01:28 UTC",
    "updated_date": "2025-05-16 09:52:52 UTC"
  },
  {
    "arxiv_id": "2411.00394v1",
    "title": "Right this way: Can VLMs Guide Us to See More to Answer Questions?",
    "authors": [
      "Li Liu",
      "Diji Yang",
      "Sijia Zhong",
      "Kalyana Suma Sree Tholeti",
      "Lei Ding",
      "Yi Zhang",
      "Leilani H. Gilpin"
    ],
    "abstract": "In question-answering scenarios, humans can assess whether the available\ninformation is sufficient and seek additional information if necessary, rather\nthan providing a forced answer. In contrast, Vision Language Models (VLMs)\ntypically generate direct, one-shot responses without evaluating the\nsufficiency of the information. To investigate this gap, we identify a critical\nand challenging task in the Visual Question Answering (VQA) scenario: can VLMs\nindicate how to adjust an image when the visual information is insufficient to\nanswer a question? This capability is especially valuable for assisting\nvisually impaired individuals who often need guidance to capture images\ncorrectly. To evaluate this capability of current VLMs, we introduce a\nhuman-labeled dataset as a benchmark for this task. Additionally, we present an\nautomated framework that generates synthetic training data by simulating\n``where to know'' scenarios. Our empirical results show significant performance\nimprovements in mainstream VLMs when fine-tuned with this synthetic data. This\nstudy demonstrates the potential to narrow the gap between information\nassessment and acquisition in VLMs, bringing their performance closer to\nhumans.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00394v1",
    "published_date": "2024-11-01 06:43:54 UTC",
    "updated_date": "2024-11-01 06:43:54 UTC"
  },
  {
    "arxiv_id": "2411.00393v4",
    "title": "Advantages of Neural Population Coding for Deep Learning",
    "authors": [
      "Heiko Hoffmann"
    ],
    "abstract": "Scalar variables, e.g., the orientation of a shape in an image, are commonly\npredicted using a single output neuron in a neural network. In contrast, the\nmammalian cortex represents variables with a population of neurons. In this\npopulation code, each neuron is most active at its preferred value and shows\npartial activity for other values. Here, we investigate the benefit of using a\npopulation code for the output layer of a neural network. We compare population\ncodes against single-neuron outputs and one-hot vectors. First, we show\ntheoretically and in experiments with synthetic data that population codes\nimprove robustness to input noise in networks of stacked linear layers. Second,\nwe demonstrate the benefit of using population codes to encode ambiguous\noutputs, such as the pose of symmetric objects. Using the T-LESS dataset of\nfeature-less real-world objects, we show that population codes improve the\naccuracy of predicting 3D object orientation from image input.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00393v4",
    "published_date": "2024-11-01 06:40:47 UTC",
    "updated_date": "2024-11-13 09:27:41 UTC"
  },
  {
    "arxiv_id": "2411.00392v1",
    "title": "Preventing Dimensional Collapse in Self-Supervised Learning via Orthogonality Regularization",
    "authors": [
      "Junlin He",
      "Jinxiao Du",
      "Wei Ma"
    ],
    "abstract": "Self-supervised learning (SSL) has rapidly advanced in recent years,\napproaching the performance of its supervised counterparts through the\nextraction of representations from unlabeled data. However, dimensional\ncollapse, where a few large eigenvalues dominate the eigenspace, poses a\nsignificant obstacle for SSL. When dimensional collapse occurs on features\n(e.g. hidden features and representations), it prevents features from\nrepresenting the full information of the data; when dimensional collapse occurs\non weight matrices, their filters are self-related and redundant, limiting\ntheir expressive power. Existing studies have predominantly concentrated on the\ndimensional collapse of representations, neglecting whether this can\nsufficiently prevent the dimensional collapse of the weight matrices and hidden\nfeatures. To this end, we first time propose a mitigation approach employing\northogonal regularization (OR) across the encoder, targeting both convolutional\nand linear layers during pretraining. OR promotes orthogonality within weight\nmatrices, thus safeguarding against the dimensional collapse of weight\nmatrices, hidden features, and representations. Our empirical investigations\ndemonstrate that OR significantly enhances the performance of SSL methods\nacross diverse benchmarks, yielding consistent gains with both CNNs and\nTransformer-based architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by NeurIPS 2024 as a poster",
    "pdf_url": "http://arxiv.org/pdf/2411.00392v1",
    "published_date": "2024-11-01 06:39:18 UTC",
    "updated_date": "2024-11-01 06:39:18 UTC"
  },
  {
    "arxiv_id": "2411.00390v1",
    "title": "MetaMetrics-MT: Tuning Meta-Metrics for Machine Translation via Human Preference Calibration",
    "authors": [
      "David Anugraha",
      "Garry Kuwanto",
      "Lucky Susanto",
      "Derry Tanti Wijaya",
      "Genta Indra Winata"
    ],
    "abstract": "We present MetaMetrics-MT, an innovative metric designed to evaluate machine\ntranslation (MT) tasks by aligning closely with human preferences through\nBayesian optimization with Gaussian Processes. MetaMetrics-MT enhances existing\nMT metrics by optimizing their correlation with human judgments. Our\nexperiments on the WMT24 metric shared task dataset demonstrate that\nMetaMetrics-MT outperforms all existing baselines, setting a new benchmark for\nstate-of-the-art performance in the reference-based setting. Furthermore, it\nachieves comparable results to leading metrics in the reference-free setting,\noffering greater efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.00390v1",
    "published_date": "2024-11-01 06:34:30 UTC",
    "updated_date": "2024-11-01 06:34:30 UTC"
  },
  {
    "arxiv_id": "2411.00899v1",
    "title": "Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing",
    "authors": [
      "Weizhi Gao",
      "Zhichao Hou",
      "Han Xu",
      "Xiaorui Liu"
    ],
    "abstract": "Implicit models such as Deep Equilibrium Models (DEQs) have emerged as\npromising alternative approaches for building deep neural networks. Their\ncertified robustness has gained increasing research attention due to security\nconcerns. Existing certified defenses for DEQs employing deterministic\ncertification methods such as interval bound propagation and Lipschitz-bounds\ncan not certify on large-scale datasets. Besides, they are also restricted to\nspecific forms of DEQs. In this paper, we provide the first randomized\nsmoothing certified defense for DEQs to solve these limitations. Our study\nreveals that simply applying randomized smoothing to certify DEQs provides\ncertified robustness generalized to large-scale datasets but incurs extremely\nexpensive computation costs. To reduce computational redundancy, we propose a\nnovel Serialized Randomized Smoothing (SRS) approach that leverages historical\ninformation. Additionally, we derive a new certified radius estimation for SRS\nto theoretically ensure the correctness of our algorithm. Extensive experiments\nand ablation studies on image recognition demonstrate that our algorithm can\nsignificantly accelerate the certification of DEQs by up to 7x almost without\nsacrificing the certified accuracy. Our code is available at\nhttps://github.com/WeizhiGao/Serialized-Randomized-Smoothing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 25 figures, NeurIPS 2024 accepted",
    "pdf_url": "http://arxiv.org/pdf/2411.00899v1",
    "published_date": "2024-11-01 06:14:11 UTC",
    "updated_date": "2024-11-01 06:14:11 UTC"
  },
  {
    "arxiv_id": "2411.00372v1",
    "title": "Generalizability of Memorization Neural Networks",
    "authors": [
      "Lijia Yu",
      "Xiao-Shan Gao",
      "Lijun Zhang",
      "Yibo Miao"
    ],
    "abstract": "The neural network memorization problem is to study the expressive power of\nneural networks to interpolate a finite dataset. Although memorization is\nwidely believed to have a close relationship with the strong generalizability\nof deep learning when using over-parameterized models, to the best of our\nknowledge, there exists no theoretical study on the generalizability of\nmemorization neural networks. In this paper, we give the first theoretical\nanalysis of this topic. Since using i.i.d. training data is a necessary\ncondition for a learning algorithm to be generalizable, memorization and its\ngeneralization theory for i.i.d. datasets are developed under mild conditions\non the data distribution. First, algorithms are given to construct memorization\nnetworks for an i.i.d. dataset, which have the smallest number of parameters\nand even a constant number of parameters. Second, we show that, in order for\nthe memorization networks to be generalizable, the width of the network must be\nat least equal to the dimension of the data, which implies that the existing\nmemorization networks with an optimal number of parameters are not\ngeneralizable. Third, a lower bound for the sample complexity of general\nmemorization algorithms and the exact sample complexity for memorization\nalgorithms with constant number of parameters are given. It is also shown that\nthere exist data distributions such that, to be generalizable for them, the\nmemorization network must have an exponential number of parameters in the data\ndimension. Finally, an efficient and generalizable memorization algorithm is\ngiven when the number of training samples is greater than the efficient\nmemorization sample complexity of the data distribution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00372v1",
    "published_date": "2024-11-01 05:18:46 UTC",
    "updated_date": "2024-11-01 05:18:46 UTC"
  },
  {
    "arxiv_id": "2411.00898v1",
    "title": "Replace-then-Perturb: Targeted Adversarial Attacks With Visual Reasoning for Vision-Language Models",
    "authors": [
      "Jonggyu Jang",
      "Hyeonsu Lyu",
      "Jungyeon Koh",
      "Hyun Jong Yang"
    ],
    "abstract": "The conventional targeted adversarial attacks add a small perturbation to an\nimage to make neural network models estimate the image as a predefined target\nclass, even if it is not the correct target class. Recently, for\nvisual-language models (VLMs), the focus of targeted adversarial attacks is to\ngenerate a perturbation that makes VLMs answer intended target text outputs.\nFor example, they aim to make a small perturbation on an image to make VLMs'\nanswers change from \"there is an apple\" to \"there is a baseball.\" However,\nanswering just intended text outputs is insufficient for tricky questions like\n\"if there is a baseball, tell me what is below it.\" This is because the target\nof the adversarial attacks does not consider the overall integrity of the\noriginal image, thereby leading to a lack of visual reasoning. In this work, we\nfocus on generating targeted adversarial examples with visual reasoning against\nVLMs. To this end, we propose 1) a novel adversarial attack procedure --\nnamely, Replace-then-Perturb and 2) a contrastive learning-based adversarial\nloss -- namely, Contrastive-Adv. In Replace-then-Perturb, we first leverage a\ntext-guided segmentation model to find the target object in the image. Then, we\nget rid of the target object and inpaint the empty space with the desired\nprompt. By doing this, we can generate a target image corresponding to the\ndesired prompt, while maintaining the overall integrity of the original image.\nFurthermore, in Contrastive-Adv, we design a novel loss function to obtain\nbetter adversarial examples. Our extensive benchmark results demonstrate that\nReplace-then-Perturb and Contrastive-Adv outperform the baseline adversarial\nattack algorithms. We note that the source code to reproduce the results will\nbe available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 5 figure",
    "pdf_url": "http://arxiv.org/pdf/2411.00898v1",
    "published_date": "2024-11-01 04:50:08 UTC",
    "updated_date": "2024-11-01 04:50:08 UTC"
  },
  {
    "arxiv_id": "2411.00355v1",
    "title": "TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images",
    "authors": [
      "Mengcheng Li",
      "Mingbao Lin",
      "Fei Chao",
      "Chia-Wen Lin",
      "Rongrong Ji"
    ],
    "abstract": "In this paper, we propose TextDestroyer, the first training- and\nannotation-free method for scene text destruction using a pre-trained diffusion\nmodel. Existing scene text removal models require complex annotation and\nretraining, and may leave faint yet recognizable text information, compromising\nprivacy protection and content concealment. TextDestroyer addresses these\nissues by employing a three-stage hierarchical process to obtain accurate text\nmasks. Our method scrambles text areas in the latent start code using a\nGaussian distribution before reconstruction. During the diffusion denoising\nprocess, self-attention key and value are referenced from the original latent\nto restore the compromised background. Latent codes saved at each inversion\nstep are used for replacement during reconstruction, ensuring perfect\nbackground restoration. The advantages of TextDestroyer include: (1) it\neliminates labor-intensive data annotation and resource-intensive training; (2)\nit achieves more thorough text destruction, preventing recognizable traces; and\n(3) it demonstrates better generalization capabilities, performing well on both\nreal-world scenes and generated images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00355v1",
    "published_date": "2024-11-01 04:41:00 UTC",
    "updated_date": "2024-11-01 04:41:00 UTC"
  },
  {
    "arxiv_id": "2411.04139v1",
    "title": "Diffusion-based Auction Mechanism for Efficient Resource Management in 6G-enabled Vehicular Metaverses",
    "authors": [
      "Jiawen Kang",
      "Yongju Tong",
      "Yue Zhong",
      "Junlong Chen",
      "Minrui Xu",
      "Dusit Niyato",
      "Runrong Deng",
      "Shiwen Mao"
    ],
    "abstract": "The rise of 6G-enable Vehicular Metaverses is transforming the automotive\nindustry by integrating immersive, real-time vehicular services through\nultra-low latency and high bandwidth connectivity. In 6G-enable Vehicular\nMetaverses, vehicles are represented by Vehicle Twins (VTs), which serve as\ndigital replicas of physical vehicles to support real-time vehicular\napplications such as large Artificial Intelligence (AI) model-based Augmented\nReality (AR) navigation, called VT tasks. VT tasks are resource-intensive and\nneed to be offloaded to ground Base Stations (BSs) for fast processing.\nHowever, high demand for VT tasks and limited resources of ground BSs, pose\nsignificant resource allocation challenges, particularly in densely populated\nurban areas like intersections. As a promising solution, Unmanned Aerial\nVehicles (UAVs) act as aerial edge servers to dynamically assist ground BSs in\nhandling VT tasks, relieving resource pressure on ground BSs. However, due to\nhigh mobility of UAVs, there exists information asymmetry regarding VT task\ndemands between UAVs and ground BSs, resulting in inefficient resource\nallocation of UAVs. To address these challenges, we propose a learning-based\nModified Second-Bid (MSB) auction mechanism to optimize resource allocation\nbetween ground BSs and UAVs by accounting for VT task latency and accuracy.\nMoreover, we design a diffusion-based reinforcement learning algorithm to\noptimize the price scaling factor, maximizing the total surplus of resource\nproviders and minimizing VT task latency. Finally, simulation results\ndemonstrate that the proposed diffusion-based MSB auction outperforms\ntraditional baselines, providing better resource distribution and enhanced\nservice quality for vehicular users.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04139v1",
    "published_date": "2024-11-01 04:34:54 UTC",
    "updated_date": "2024-11-01 04:34:54 UTC"
  },
  {
    "arxiv_id": "2411.00897v1",
    "title": "Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback",
    "authors": [
      "Song Yu",
      "Xiaofei Xu",
      "Fangfei Xu",
      "Li Li"
    ],
    "abstract": "Although large language models perform well in understanding and responding\nto user intent, their performance in specialized domains such as Traditional\nChinese Medicine (TCM) remains limited due to lack of expertise. In addition,\nhigh-quality data related to TCM is scarce and difficult to obtain, making\nlarge language models ineffective in handling TCM tasks. In this work, we\npropose a framework to improve the performance of large language models for TCM\ntasks using only a small amount of data. First, we use medical case data for\nsupervised fine-tuning of the large model, making it initially capable of\nperforming TCM tasks. Subsequently, we further optimize the model's performance\nusing reinforcement learning from AI feedback (RLAIF) to align it with the\npreference data. The ablation study also demonstrated the performance gain is\nattributed to both supervised fine-tuning and the direct policy optimization.\nThe experimental results show that the model trained with a small amount of\ndata achieves a significant performance improvement on a representative TCM\ntask.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00897v1",
    "published_date": "2024-11-01 04:19:55 UTC",
    "updated_date": "2024-11-01 04:19:55 UTC"
  },
  {
    "arxiv_id": "2411.00349v2",
    "title": "Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review",
    "authors": [
      "Dinitha Wijewardhana",
      "Sugandima Vidanagamachchi",
      "Nalin Arachchilage"
    ],
    "abstract": "Cryptocurrencies have gained popularity due to their transparency, security,\nand accessibility compared to traditional financial systems, with Bitcoin,\nintroduced in 2009, leading the market. Bitcoin's security relies on blockchain\ntechnology - a decentralized ledger consisting of a consensus and an incentive\nmechanism. The consensus mechanism, Proof of Work (PoW), requires miners to\nsolve difficult cryptographic puzzles to add new blocks, while the incentive\nmechanism rewards them with newly minted bitcoins. However, as Bitcoin's\nacceptance grows, it faces increasing threats from attacks targeting these\nmechanisms, such as selfish mining, double-spending, and block withholding.\nThese attacks compromise security, efficiency, and reward distribution. Recent\nresearch shows that these attacks can be combined with each other or with\neither malicious strategies, such as network-layer attacks, or non-malicious\nstrategies, like honest mining. These combinations lead to more sophisticated\nattacks, increasing the attacker's success rates and profitability. Therefore,\nunderstanding and evaluating these attacks is essential for developing\neffective countermeasures and ensuring long-term security. This paper begins by\nexamining individual attacks executed in isolation and their profitability. It\nthen explores how combining these attacks with each other or with other\nmalicious and non-malicious strategies can enhance their overall effectiveness\nand profitability. The analysis further explores how the deployment of attacks\nsuch as selfish mining and block withholding by multiple competing mining pools\nagainst each other impacts their economic returns. Lastly, a set of design\nguidelines is provided, outlining areas future work should focus on to prevent\nor mitigate the identified threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00349v2",
    "published_date": "2024-11-01 04:18:42 UTC",
    "updated_date": "2024-11-11 13:30:26 UTC"
  },
  {
    "arxiv_id": "2411.12747v1",
    "title": "A Survey of Financial AI: Architectures, Advances and Open Challenges",
    "authors": [
      "Junhua Liu"
    ],
    "abstract": "Financial AI empowers sophisticated approaches to financial market\nforecasting, portfolio optimization, and automated trading. This survey\nprovides a systematic analysis of these developments across three primary\ndimensions: predictive models that capture complex market dynamics,\ndecision-making frameworks that optimize trading and investment strategies, and\nknowledge augmentation systems that leverage unstructured financial\ninformation. We examine significant innovations including foundation models for\nfinancial time series, graph-based architectures for market relationship\nmodeling, and hierarchical frameworks for portfolio optimization. Analysis\nreveals crucial trade-offs between model sophistication and practical\nconstraints, particularly in high-frequency trading applications. We identify\ncritical gaps and open challenges between theoretical advances and industrial\nimplementation, outlining open challenges and opportunities for improving both\nmodel performance and practical applicability.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-fin.TR",
    "comment": "Full list of papers and summary slides are available at:\n  https://github.com/junhua/awesome-finance-ai-papers",
    "pdf_url": "http://arxiv.org/pdf/2411.12747v1",
    "published_date": "2024-11-01 04:16:00 UTC",
    "updated_date": "2024-11-01 04:16:00 UTC"
  },
  {
    "arxiv_id": "2411.00348v2",
    "title": "Attention Tracker: Detecting Prompt Injection Attacks in LLMs",
    "authors": [
      "Kuo-Han Hung",
      "Ching-Yun Ko",
      "Ambrish Rawat",
      "I-Hsin Chung",
      "Winston H. Hsu",
      "Pin-Yu Chen"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized various domains but remain\nvulnerable to prompt injection attacks, where malicious inputs manipulate the\nmodel into ignoring original instructions and executing designated action. In\nthis paper, we investigate the underlying mechanisms of these attacks by\nanalyzing the attention patterns within LLMs. We introduce the concept of the\ndistraction effect, where specific attention heads, termed important heads,\nshift focus from the original instruction to the injected instruction. Building\non this discovery, we propose Attention Tracker, a training-free detection\nmethod that tracks attention patterns on instruction to detect prompt injection\nattacks without the need for additional LLM inference. Our method generalizes\neffectively across diverse models, datasets, and attack types, showing an AUROC\nimprovement of up to 10.0% over existing methods, and performs well even on\nsmall LLMs. We demonstrate the robustness of our approach through extensive\nevaluations and provide insights into safeguarding LLM-integrated systems from\nprompt injection vulnerabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Project page:\n  https://huggingface.co/spaces/TrustSafeAI/Attention-Tracker",
    "pdf_url": "http://arxiv.org/pdf/2411.00348v2",
    "published_date": "2024-11-01 04:05:59 UTC",
    "updated_date": "2025-04-23 01:35:19 UTC"
  },
  {
    "arxiv_id": "2411.00347v1",
    "title": "An Untethered Bioinspired Robotic Tensegrity Dolphin with Multi-Flexibility Design for Aquatic Locomotion",
    "authors": [
      "Luyang Zhao",
      "Yitao Jiang",
      "Chun-Yi She",
      "Mingi Jeong",
      "Haibo Dong",
      "Alberto Quattrini Li",
      "Muhao Chen",
      "Devin Balkcom"
    ],
    "abstract": "This paper presents the first steps toward a soft dolphin robot using a\nbio-inspired approach to mimic dolphin flexibility. The current dolphin robot\nuses a minimalist approach, with only two actuated cable-driven degrees of\nfreedom actuated by a pair of motors. The actuated tail moves up and down in a\nswimming motion, but this first proof of concept does not permit controlled\nturns of the robot. While existing robotic dolphins typically use revolute\njoints to articulate rigid bodies, our design -- which will be made opensource\n-- incorporates a flexible tail with tunable silicone skin and actuation\nflexibility via a cable-driven system, which mimics muscle dynamics and design\nflexibility with a tunable skeleton structure. The design is also tunable since\nthe backbone can be easily printed in various geometries. The paper provides\ninsights into how a few such variations affect robot motion and efficiency,\nmeasured by speed and cost of transport (COT). This approach demonstrates the\npotential of achieving dolphin-like motion through enhanced flexibility in\nbio-inspired robotics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00347v1",
    "published_date": "2024-11-01 04:05:24 UTC",
    "updated_date": "2024-11-01 04:05:24 UTC"
  },
  {
    "arxiv_id": "2411.00345v1",
    "title": "On the Exploration of LM-Based Soft Modular Robot Design",
    "authors": [
      "Weicheng Ma",
      "Luyang Zhao",
      "Chun-Yi She",
      "Yitao Jiang",
      "Alan Sun",
      "Bo Zhu",
      "Devin Balkcom",
      "Soroush Vosoughi"
    ],
    "abstract": "Recent large language models (LLMs) have demonstrated promising capabilities\nin modeling real-world knowledge and enhancing knowledge-based generation\ntasks. In this paper, we further explore the potential of using LLMs to aid in\nthe design of soft modular robots, taking into account both user instructions\nand physical laws, to reduce the reliance on extensive trial-and-error\nexperiments typically needed to achieve robot designs that meet specific\nstructural or task requirements. Specifically, we formulate the robot design\nprocess as a sequence generation task and find that LLMs are able to capture\nkey requirements expressed in natural language and reflect them in the\nconstruction sequences of robots. To simplify, rather than conducting\nreal-world experiments to assess design quality, we utilize a simulation tool\nto provide feedback to the generative model, allowing for iterative\nimprovements without requiring extensive human annotations. Furthermore, we\nintroduce five evaluation metrics to assess the quality of robot designs from\nmultiple angles including task completion and adherence to instructions,\nsupporting an automatic evaluation process. Our model performs well in\nevaluations for designing soft modular robots with uni- and bi-directional\nlocomotion and stair-descending capabilities, highlighting the potential of\nusing natural language and LLMs for robot design. However, we also observe\ncertain limitations that suggest areas for further improvement.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00345v1",
    "published_date": "2024-11-01 04:03:05 UTC",
    "updated_date": "2024-11-01 04:03:05 UTC"
  },
  {
    "arxiv_id": "2411.00336v1",
    "title": "StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention",
    "authors": [
      "Karine Karine",
      "Benjamin M. Marlin"
    ],
    "abstract": "The use of reinforcement learning (RL) to learn policies for just-in-time\nadaptive interventions (JITAIs) is of significant interest in many behavioral\nintervention domains including improving levels of physical activity. In a\nmessaging-based physical activity JITAI, a mobile health app is typically used\nto send messages to a participant to encourage engagement in physical activity.\nIn this setting, RL methods can be used to learn what intervention options to\nprovide to a participant in different contexts. However, deploying RL methods\nin real physical activity adaptive interventions comes with challenges: the\ncost and time constraints of real intervention studies result in limited data\nto learn adaptive intervention policies. Further, commonly used RL simulation\nenvironments have dynamics that are of limited relevance to physical activity\nadaptive interventions and thus shed little light on what RL methods may be\noptimal for this challenging application domain. In this paper, we introduce\nStepCountJITAI, an RL environment designed to foster research on RL methods\nthat address the significant challenges of policy learning for adaptive\nbehavioral interventions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024 workshop on Behavioral ML",
    "pdf_url": "http://arxiv.org/pdf/2411.00336v1",
    "published_date": "2024-11-01 03:31:39 UTC",
    "updated_date": "2024-11-01 03:31:39 UTC"
  },
  {
    "arxiv_id": "2411.02525v1",
    "title": "Strongly Topology-preserving GNNs for Brain Graph Super-resolution",
    "authors": [
      "Pragya Singh",
      "Islem Rekik"
    ],
    "abstract": "Brain graph super-resolution (SR) is an under-explored yet highly relevant\ntask in network neuroscience. It circumvents the need for costly and\ntime-consuming medical imaging data collection, preparation, and processing.\nCurrent SR methods leverage graph neural networks (GNNs) thanks to their\nability to natively handle graph-structured datasets. However, most GNNs\nperform node feature learning, which presents two significant limitations: (1)\nthey require computationally expensive methods to learn complex node features\ncapable of inferring connectivity strength or edge features, which do not scale\nto larger graphs; and (2) computations in the node space fail to adequately\ncapture higher-order brain topologies such as cliques and hubs. However,\nnumerous studies have shown that brain graph topology is crucial in identifying\nthe onset and presence of various neurodegenerative disorders like Alzheimer\nand Parkinson. Motivated by these challenges and applications, we propose our\nSTP-GSR framework. It is the first graph SR architecture to perform\nrepresentation learning in higher-order topological space. Specifically, using\nthe primal-dual graph formulation from graph theory, we develop an efficient\nmapping from the edge space of our low-resolution (LR) brain graphs to the node\nspace of a high-resolution (HR) dual graph. This approach ensures that\nnode-level computations on this dual graph correspond naturally to edge-level\nlearning on our HR brain graphs, thereby enforcing strong topological\nconsistency within our framework. Additionally, our framework is GNN layer\nagnostic and can easily learn from smaller, scalable GNNs, reducing\ncomputational requirements. We comprehensively benchmark our framework across\nseven key topological measures and observe that it significantly outperforms\nthe previous state-of-the-art methods and baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to PRIME-MICCAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2411.02525v1",
    "published_date": "2024-11-01 03:29:04 UTC",
    "updated_date": "2024-11-01 03:29:04 UTC"
  },
  {
    "arxiv_id": "2411.00329v1",
    "title": "Personalized Federated Learning via Feature Distribution Adaptation",
    "authors": [
      "Connor J. Mclaughlin",
      "Lili Su"
    ],
    "abstract": "Federated learning (FL) is a distributed learning framework that leverages\ncommonalities between distributed client datasets to train a global model.\nUnder heterogeneous clients, however, FL can fail to produce stable training\nresults. Personalized federated learning (PFL) seeks to address this by\nlearning individual models tailored to each client. One approach is to\ndecompose model training into shared representation learning and personalized\nclassifier training. Nonetheless, previous works struggle to navigate the\nbias-variance trade-off in classifier learning, relying solely on limited local\ndatasets or introducing costly techniques to improve generalization. In this\nwork, we frame representation learning as a generative modeling task, where\nrepresentations are trained with a classifier based on the global feature\ndistribution. We then propose an algorithm, pFedFDA, that efficiently generates\npersonalized models by adapting global generative classifiers to their local\nfeature distributions. Through extensive computer vision benchmarks, we\ndemonstrate that our method can adjust to complex distribution shifts with\nsignificant improvements over current state-of-the-art in data-scarce settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "38th Annual Conference on Neural Information Processing Systems\n  (NeurIPS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00329v1",
    "published_date": "2024-11-01 03:03:52 UTC",
    "updated_date": "2024-11-01 03:03:52 UTC"
  },
  {
    "arxiv_id": "2411.11852v1",
    "title": "LUTMUL: Exceed Conventional FPGA Roofline Limit by LUT-based Efficient Multiplication for Neural Network Inference",
    "authors": [
      "Yanyue Xie",
      "Zhengang Li",
      "Dana Diaconu",
      "Suranga Handagala",
      "Miriam Leeser",
      "Xue Lin"
    ],
    "abstract": "For FPGA-based neural network accelerators, digital signal processing (DSP)\nblocks have traditionally been the cornerstone for handling multiplications.\nThis paper introduces LUTMUL, which harnesses the potential of look-up tables\n(LUTs) for performing multiplications. The availability of LUTs typically\noutnumbers that of DSPs by a factor of 100, offering a significant\ncomputational advantage. By exploiting this advantage of LUTs, our method\ndemonstrates a potential boost in the performance of FPGA-based neural network\naccelerators with a reconfigurable dataflow architecture. Our approach\nchallenges the conventional peak performance on DSP-based accelerators and sets\na new benchmark for efficient neural network inference on FPGAs. Experimental\nresults demonstrate that our design achieves the best inference speed among all\nFPGA-based accelerators, achieving a throughput of 1627 images per second and\nmaintaining a top-1 accuracy of 70.95% on the ImageNet dataset.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted by ASPDAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.11852v1",
    "published_date": "2024-11-01 02:54:11 UTC",
    "updated_date": "2024-11-01 02:54:11 UTC"
  },
  {
    "arxiv_id": "2411.02523v1",
    "title": "Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes",
    "authors": [
      "Balu Bhasuran",
      "Qiao Jin",
      "Yuzhang Xie",
      "Carl Yang",
      "Karim Hanna",
      "Jennifer Costa",
      "Cindy Shavor",
      "Zhiyong Lu",
      "Zhe He"
    ],
    "abstract": "Differential diagnosis is crucial for medicine as it helps healthcare\nproviders systematically distinguish between conditions that share similar\nsymptoms. This study assesses the impact of lab test results on differential\ndiagnoses (DDx) made by large language models (LLMs). Clinical vignettes from\n50 case reports from PubMed Central were created incorporating patient\ndemographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,\nClaude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx\nwith and without lab data. A comprehensive evaluation involving GPT-4, a\nknowledge graph, and clinicians was conducted. GPT-4 performed best, achieving\n55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient\naccuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and\nMixtral excelling, though exact match rates were low. Lab tests, including\nliver function, metabolic/toxicology panels, and serology/immune tests, were\ngenerally interpreted correctly by LLMs for differential diagnosis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02523v1",
    "published_date": "2024-11-01 02:48:32 UTC",
    "updated_date": "2024-11-01 02:48:32 UTC"
  },
  {
    "arxiv_id": "2411.00322v1",
    "title": "Constant Acceleration Flow",
    "authors": [
      "Dogyun Park",
      "Sojin Lee",
      "Sihyeon Kim",
      "Taehoon Lee",
      "Youngjoon Hong",
      "Hyunwoo J. Kim"
    ],
    "abstract": "Rectified flow and reflow procedures have significantly advanced fast\ngeneration by progressively straightening ordinary differential equation (ODE)\nflows. They operate under the assumption that image and noise pairs, known as\ncouplings, can be approximated by straight trajectories with constant velocity.\nHowever, we observe that modeling with constant velocity and using reflow\nprocedures have limitations in accurately learning straight trajectories\nbetween pairs, resulting in suboptimal performance in few-step generation. To\naddress these limitations, we introduce Constant Acceleration Flow (CAF), a\nnovel framework based on a simple constant acceleration equation. CAF\nintroduces acceleration as an additional learnable variable, allowing for more\nexpressive and accurate estimation of the ODE flow. Moreover, we propose two\ntechniques to further improve estimation accuracy: initial velocity\nconditioning for the acceleration model and a reflow process for the initial\nvelocity. Our comprehensive studies on toy datasets, CIFAR-10, and ImageNet\n64x64 demonstrate that CAF outperforms state-of-the-art baselines for one-step\ngeneration. We also show that CAF dramatically improves few-step coupling\npreservation and inversion over Rectified flow. Code is available at\n\\href{https://github.com/mlvlab/CAF}{https://github.com/mlvlab/CAF}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00322v1",
    "published_date": "2024-11-01 02:43:56 UTC",
    "updated_date": "2024-11-01 02:43:56 UTC"
  },
  {
    "arxiv_id": "2411.00311v1",
    "title": "C2A: Client-Customized Adaptation for Parameter-Efficient Federated Learning",
    "authors": [
      "Yeachan Kim",
      "Junho Kim",
      "Wing-Lam Mok",
      "Jun-Hyung Park",
      "SangKeun Lee"
    ],
    "abstract": "Despite the versatility of pre-trained language models (PLMs) across domains,\ntheir large memory footprints pose significant challenges in federated learning\n(FL), where the training model has to be distributed between a server and\nclients. One potential solution to bypass such constraints might be the use of\nparameter-efficient fine-tuning (PEFT) in the context of FL. However, we have\nobserved that typical PEFT tends to severely suffer from heterogeneity among\nclients in FL scenarios, resulting in unstable and slow convergence. In this\npaper, we propose Client-Customized Adaptation (C2A), a novel\nhypernetwork-based FL framework that generates client-specific adapters by\nconditioning the client information. With the effectiveness of the\nhypernetworks in generating customized weights through learning to adopt the\ndifferent characteristics of inputs, C2A can maximize the utility of shared\nmodel parameters while minimizing the divergence caused by client\nheterogeneity. To verify the efficacy of C2A, we perform extensive evaluations\non FL scenarios involving heterogeneity in label and language distributions.\nComprehensive evaluation results clearly support the superiority of C2A in\nterms of both efficiency and effectiveness in FL scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at Findings of ACL 2023",
    "pdf_url": "http://arxiv.org/pdf/2411.00311v1",
    "published_date": "2024-11-01 02:07:38 UTC",
    "updated_date": "2024-11-01 02:07:38 UTC"
  },
  {
    "arxiv_id": "2411.00308v2",
    "title": "GPT for Games: An Updated Scoping Review (2020-2024)",
    "authors": [
      "Daijin Yang",
      "Erica Kleinman",
      "Casper Harteveld"
    ],
    "abstract": "Due to GPT's impressive generative capabilities, its applications in games\nare expanding rapidly. To offer researchers a comprehensive understanding of\nthe current applications and identify both emerging trends and unexplored\nareas, this paper introduces an updated scoping review of 177 articles, 122 of\nwhich were published in 2024, to explore GPT's potential for games. By coding\nand synthesizing the papers, we identify five prominent applications of GPT in\ncurrent game research: procedural content generation, mixed-initiative game\ndesign, mixed-initiative gameplay, playing games, and game user research.\nDrawing on insights from these application areas and emerging research, we\npropose future studies should focus on expanding the technical boundaries of\nthe GPT models and exploring the complex interaction dynamics between them and\nusers. This review aims to illustrate the state of the art in innovative GPT\napplications in games, offering a foundation to enrich game development and\nenhance player experiences through cutting-edge AI innovations.",
    "categories": [
      "cs.AI",
      "A.1"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to IEEE Transactions on Games",
    "pdf_url": "http://arxiv.org/pdf/2411.00308v2",
    "published_date": "2024-11-01 02:00:25 UTC",
    "updated_date": "2025-03-14 17:50:19 UTC"
  },
  {
    "arxiv_id": "2411.12746v1",
    "title": "A Review of Reinforcement Learning in Financial Applications",
    "authors": [
      "Yahui Bai",
      "Yuhe Gao",
      "Runzhe Wan",
      "Sheng Zhang",
      "Rui Song"
    ],
    "abstract": "In recent years, there has been a growing trend of applying Reinforcement\nLearning (RL) in financial applications.\n  This approach has shown great potential to solve decision-making tasks in\nfinance.\n  In this survey, we present a comprehensive study of the applications of RL in\nfinance and conduct a series of meta-analyses to investigate the common themes\nin the literature, such as the factors that most significantly affect RL's\nperformance compared to traditional methods.\n  Moreover, we identify challenges including explainability, Markov Decision\nProcess (MDP) modeling, and robustness that hinder the broader utilization of\nRL in the financial industry and discuss recent advancements in overcoming\nthese challenges.\n  Finally, we propose future research directions, such as benchmarking,\ncontextual RL, multi-agent RL, and model-based RL to address these challenges\nand to further enhance the implementation of RL in finance.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12746v1",
    "published_date": "2024-11-01 01:03:10 UTC",
    "updated_date": "2024-11-01 01:03:10 UTC"
  },
  {
    "arxiv_id": "2411.00288v1",
    "title": "Inducing Semi-Structured Sparsity by Masking for Efficient Model Inference in Convolutional Networks",
    "authors": [
      "David A. Danhofer"
    ],
    "abstract": "The crucial role of convolutional models, both as standalone vision models\nand backbones in foundation models, necessitates effective acceleration\ntechniques. This paper proposes a novel method to learn semi-structured\nsparsity patterns for convolution kernels in the form of maskings enabling the\nutilization of readily available hardware accelerations. The approach\naccelerates convolutional models more than two-fold during inference without\ndecreasing model performance. At the same time, the original model weights and\nstructure remain unchanged keeping the model thus easily updatable. Beyond the\nimmediate practical use, the effect of maskings on prediction is easily\nquantifiable. Therefore, guarantees on model predictions under maskings are\nderived showing stability bounds for learned maskings even after updating the\noriginal underlying model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "cs.PF",
      "C.4; I.2.6; I.2.10; I.4.m; I.5.4; I.5.5"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 3 figures; this work will be presented at the NeurIPS 2024\n  Workshop on Fine-Tuning in Modern Machine Learning: Principles and\n  Scalability (FITML)",
    "pdf_url": "http://arxiv.org/pdf/2411.00288v1",
    "published_date": "2024-11-01 00:53:33 UTC",
    "updated_date": "2024-11-01 00:53:33 UTC"
  },
  {
    "arxiv_id": "2411.00287v1",
    "title": "MBExplainer: Multilevel bandit-based explanations for downstream models with augmented graph embeddings",
    "authors": [
      "Ashkan Golgoon",
      "Ryan Franks",
      "Khashayar Filom",
      "Arjun Ravi Kannan"
    ],
    "abstract": "In many industrial applications, it is common that the graph embeddings\ngenerated from training GNNs are used in an ensemble model where the embeddings\nare combined with other tabular features (e.g., original node or edge features)\nin a downstream ML task. The tabular features may even arise naturally if,\ne.g., one tries to build a graph such that some of the node or edge features\nare stored in a tabular format. Here we address the problem of explaining the\noutput of such ensemble models for which the input features consist of learned\nneural graph embeddings combined with additional tabular features. We propose\nMBExplainer, a model-agnostic explanation approach for downstream models with\naugmented graph embeddings. MBExplainer returns a human-legible triple as an\nexplanation for an instance prediction of the whole pipeline consisting of\nthree components: a subgraph with the highest importance, the topmost important\nnodal features, and the topmost important augmented downstream features. A\ngame-theoretic formulation is used to take the contributions of each component\nand their interactions into account by assigning three Shapley values\ncorresponding to their own specific games. Finding the explanation requires an\nefficient search through the corresponding local search spaces corresponding to\neach component. MBExplainer applies a novel multilevel search algorithm that\nenables simultaneous pruning of local search spaces in a computationally\ntractable way. In particular, three interweaved Monte Carlo Tree Search are\nutilized to iteratively prune the local search spaces. MBExplainer also\nincludes a global search algorithm that uses contextual bandits to efficiently\nallocate pruning budget among the local search spaces. We show the\neffectiveness of MBExplainer by presenting a set of comprehensive numerical\nexamples on multiple public graph datasets for both node and graph\nclassification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.NA",
      "math.NA",
      "stat.ML",
      "68T01",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00287v1",
    "published_date": "2024-11-01 00:52:59 UTC",
    "updated_date": "2024-11-01 00:52:59 UTC"
  },
  {
    "arxiv_id": "2411.00284v2",
    "title": "SimpleFSDP: Simpler Fully Sharded Data Parallel with torch.compile",
    "authors": [
      "Ruisi Zhang",
      "Tianyu Liu",
      "Will Feng",
      "Andrew Gu",
      "Sanket Purandare",
      "Wanchao Liang",
      "Francisco Massa"
    ],
    "abstract": "Distributed training of large models consumes enormous computation resources\nand requires substantial engineering efforts to compose various training\ntechniques. This paper presents SimpleFSDP, a PyTorch-native compiler-based\nFully Sharded Data Parallel (FSDP) framework, which has a simple implementation\nfor maintenance and composability, allows full computation-communication graph\ntracing, and brings performance enhancement via compiler backend optimizations.\n  SimpleFSDP's novelty lies in its unique $torch.compile$-friendly\nimplementation of collective communications using existing PyTorch primitives,\nnamely parametrizations, selective activation checkpointing, and DTensor. It\nalso features the first-of-its-kind intermediate representation (IR) nodes\nbucketing and reordering in the TorchInductor backend for effective\ncomputation-communication overlapping. As a result, users can employ the\naforementioned optimizations to automatically or manually wrap model components\nfor minimal communication exposure. Extensive evaluations of SimpleFSDP on\nLlama 3 models (including the ultra-large 405B) using TorchTitan demonstrate up\nto 28.54% memory reduction and 68.67% throughput improvement compared to the\nmost widely adopted FSDP2 eager framework, when composed with other distributed\ntraining techniques.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00284v2",
    "published_date": "2024-11-01 00:43:54 UTC",
    "updated_date": "2024-11-05 18:36:14 UTC"
  },
  {
    "arxiv_id": "2411.00282v1",
    "title": "Improving Traffic Flow Predictions with SGCN-LSTM: A Hybrid Model for Spatial and Temporal Dependencies",
    "authors": [
      "Alexandru T. Cismaru"
    ],
    "abstract": "Large amounts of traffic can lead to negative effects such as increased car\naccidents, air pollution, and significant time wasted. Understanding traffic\nspeeds on any given road segment can be highly beneficial for traffic\nmanagement strategists seeking to reduce congestion. While recent studies have\nprimarily focused on modeling spatial dependencies by using graph convolutional\nnetworks (GCNs) over fixed weighted graphs, the relationships between nodes are\noften more complex, with edges that interact dynamically. This paper addresses\nboth the temporal patterns in traffic data and the intricate spatial\ndependencies by introducing the Signal-Enhanced Graph Convolutional Network\nLong Short Term Memory (SGCN-LSTM) model for predicting traffic speeds across\nroad networks. Extensive experiments on the PEMS-BAY road network traffic\ndataset demonstrate the SGCN-LSTM model's effectiveness, yielding significant\nimprovements in Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and\nMean Absolute Percentage Error (MAPE) compared to benchmark models on the same\ndataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00282v1",
    "published_date": "2024-11-01 00:37:00 UTC",
    "updated_date": "2024-11-01 00:37:00 UTC"
  }
]