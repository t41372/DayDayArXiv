{
  "date": "2024-11-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-01 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 领域，尤其是大型语言模型（LLMs）的优化、安全和应用扩展，突出如量子通信和医学 AI 的跨界创新，令人印象深刻的包括 NeurIPS 接受的论文（如 Symile 和 Birdie）和 Dan Hendrycks 的 AI 安全综述。\n\n### 重点论文讨论\n我们先聊聊那些重要、话题性强或有著名学者的论文，再快速掠过其他次要内容。以下按主题归类，优先选取具有创新贡献的文章。\n\n#### LLM 和 AI 安全相关（高话题度，聚焦模型优化与风险）\n- **Privacy Risks of Speculative Decoding in Large Language Models（大语言模型中推测解码的隐私风险）**：这篇论文揭示了推测解码技术在 LLMs 中的隐私漏洞，通过观察推测 token 模式，攻击者可泄露用户查询（准确率高达 95%），并讨论缓解策略如 token 聚合。该发现对 LLMs 安全有重要启示，强调了实际部署中的隐私保护。\n- **SLED: Self Logits Evolution Decoding for Improving Factuality in Large Language Models（SLED：提升大语言模型事实性的自演化 logits 解码）**：论文提出 SLED 框架，通过梯度优化提升 LLMs 的事实准确性，在多任务上比基线提高 20%，NeurIPS 接受，展示了高效解码对模型可靠性的提升。\n- **Introduction to AI Safety, Ethics, and Society（AI 安全、伦理和社会导论）**：Dan Hendrycks 撰写，系统综述 AI 风险，提供可访问性强的 603 页内容，聚焦 AI 在军事和经济中的影响，强调安全和伦理框架，是 AI 领域的重要参考。\n- **AttackQA: Development and Adoption of a Dataset for Assisting Cybersecurity Operations using Fine-tuned and Open-Source LLMs（AttackQA：使用微调和开源 LLMs 辅助网络安全操作的数据集开发）**：构建了 25,335 对 Q&A 数据集，支持 RAG 系统，证明开源 LLMs 在网络安全中的准确性提升，NeurIPS 相关主题，突出了数据集在安全应用的潜力。\n\n#### 强化学习和机器学习创新（NeurIPS 亮点，关注算法效率）\n- **Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula（Birdie：通过奖励驱动目标和课程推进状态空间模型）**：论文优化 SSMs 用于长序列任务，如文本检索，NeurIPS 接受，通过强化学习提升性能，显著改善多模态任务，展示了高效模型在 NLP 中的应用。\n- **Provable Length Generalization in Sequence Prediction via Spectral Filtering（通过谱过滤实现序列预测的可证明长度泛化）**：引入不对称遗憾指标，证明谱过滤算法在序列预测中的泛化能力，NeurIPS 相关，填补了强化学习中长度泛化的理论空白。\n- **LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation（LogiCity：通过抽象城市模拟推进神经符号 AI）**：NeurIPS 论文，提出城市模拟框架，支持多代理任务，显著提升推理性能，适用于智能交通和机器人规划。\n\n#### 医学和生物应用（实际影响大，关注 AI 在健康领域的潜力）\n- **Evaluation Metric for Quality Control and Generative Models in Histopathology Images（用于组织病理图像质量控制和生成模型的评估指标）**：提出 RL2 指标，解决数据稀缺问题，提高生成模型在病理图像中的准确性，ISBI 2025 接受，贡献了更高效的图像质量评估方法。\n- **CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis（CTPD：增强多模态电子健康记录分析的跨模态时间模式发现）**：开发框架提取多模态 EHR 中的时间模式，提升临床预测准确性，如 48 小时院内死亡率，突出了 AI 在医疗决策中的作用。\n\n#### 其他快速掠过\n其他论文涉及量子通信、联邦学习、交通优化和图像生成等，但多为技术性较强的次要贡献，这里简要提及几篇：\n- **Towards efficient and secure quantum-classical communication networks（高效安全的量子-经典通信网络）**：探讨 QKD 和 PQC 的混合协议，提升通信安全。\n- **Effective ML Model Versioning in Edge Networks（边缘网络中有效的 ML 模型版本管理）**：使用强化学习算法优化模型更新，提升边缘计算的鲁棒性。\n- **InterTrans: Leveraging Transitive Intermediate Translations to Enhance LLM-based Code Translation（InterTrans：利用中间翻译提升基于 LLMs 的代码翻译）**：改进代码翻译准确性，平均提升 18.3%。\n\n今天的论文总体上突出了 AI 在安全、医疗和优化方面的进展，建议关注 LLM 相关工作以把握前沿趋势。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2411.01081v2",
      "title": "Towards efficient and secure quantum-classical communication networks",
      "title_zh": "迈向高效且安全的量子-经典通信网络",
      "authors": [
        "Pei Zeng",
        "Debayan Bandyopadhyay",
        "José A. Méndez Méndez",
        "Nolan Bitner",
        "Alexander Kolar",
        "Michael T. Solomon",
        "F. Joseph Heremans",
        "David D. Awschalom",
        "Liang Jiang",
        "Junyu Liu"
      ],
      "abstract": "The rapid advancement of quantum technologies calls for the design and\ndeployment of quantum-safe cryptographic protocols and communication networks.\nThere are two primary approaches to achieving quantum-resistant security:\nquantum key distribution (QKD) and post-quantum cryptography (PQC). While each\noffers unique advantages, both have drawbacks in practical implementation. In\nthis work, we introduce the pros and cons of these protocols and explore how\nthey can be combined to achieve a higher level of security and/or improved\nperformance in key distribution. We hope our discussion inspires further\nresearch into the design of hybrid cryptographic protocols for\nquantum-classical communication networks.",
      "tldr_zh": "该研究探讨了量子技术的快速发展对量子安全加密协议和通信网络的需求，重点比较了Quantum Key Distribution (QKD)和Post-Quantum Cryptography (PQC)的优缺点。QKD 提供独特的安全优势，但实现中面临实用性挑战，而 PQC 则在性能上更可靠但可能存在漏洞。论文提出通过结合 QKD 和 PQC 来提升整体安全性和关键分发效率，并呼吁进一步研究混合加密协议以构建高效的量子-经典通信网络。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "quant-ph",
      "comment": "4 pages, a blue print paper, Submission for IEEE 2024 IEEE Workshop\n  on Quantum IntelLigence, Learning & Security (QUILLS),\n  https://sites.google.com/pitt.edu/quills/home",
      "pdf_url": "http://arxiv.org/pdf/2411.01081v2",
      "published_date": "2024-11-01 23:36:19 UTC",
      "updated_date": "2024-11-05 17:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:53:35.254753"
    },
    {
      "arxiv_id": "2411.01078v3",
      "title": "Effective ML Model Versioning in Edge Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Fin Gentzen",
        "Mounir Bensalem",
        "Admela Jukan"
      ],
      "abstract": "Machine learning (ML) models, data and software need to be regularly updated\nwhenever essential version updates are released and feasible for integration.\nThis is a basic but most challenging requirement to satisfy in the edge, due to\nthe various system constraints and the major impact that an update can have on\nrobustness and stability. In this paper, we formulate for the first time the ML\nmodel versioning optimization problem, and propose effective solutions,\nincluding the update automation with reinforcement learning (RL) based\nalgorithm. We study the edge network environment due to the known constraints\nin performance, response time, security, and reliability, which make updates\nespecially challenging. The performance study shows that model version updates\ncan be fully and effectively automated with reinforcement learning method. We\nshow that for every range of server load values, the proper versioning can be\nfound that improves security, reliability and/or ML model accuracy, while\nassuring a comparably lower response time.",
      "tldr_zh": "该论文首次制定了在边缘网络（Edge Networks）中有效管理 ML 模型版本优化的问题，针对性能、响应时间、安全和可靠性等方面的系统约束提出解决方案。研究采用强化学习（Reinforcement Learning, RL）基于算法实现模型、数据和软件的自动更新，确保更新过程高效且最小化对系统稳定性的影响。实验结果表明，对于不同服务器负载范围，该方法能自动找到最佳版本，提高安全、可靠性和 ML 模型准确性，同时保持较低的响应时间。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes",
      "pdf_url": "http://arxiv.org/pdf/2411.01078v3",
      "published_date": "2024-11-01 23:19:05 UTC",
      "updated_date": "2024-11-13 11:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:53:46.564841"
    },
    {
      "arxiv_id": "2411.01076v2",
      "title": "Privacy Risks of Speculative Decoding in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiankun Wei",
        "Abdulrahman Abdulrazzag",
        "Tianchen Zhang",
        "Adel Muursepp",
        "Gururaj Saileshwar"
      ],
      "abstract": "Speculative decoding in large language models (LLMs) accelerates token\ngeneration by speculatively predicting multiple tokens cheaply and verifying\nthem in parallel, and has been widely deployed. In this paper, we provide the\nfirst study demonstrating the privacy risks of speculative decoding. We observe\nthat input-dependent patterns of correct and incorrect predictions can be\nleaked out to an adversary monitoring token generation times and packet sizes,\nleading to privacy breaches. By observing the pattern of correctly and\nincorrectly speculated tokens, we show that a malicious adversary can\nfingerprint queries and learn private user inputs with more than $90\\%$\naccuracy across three different speculative decoding techniques - REST (almost\n$100\\%$ accuracy), LADE (up to $92\\%$ accuracy), and BiLD (up to $95\\%$\naccuracy). We show that an adversary can also leak out confidential\nintellectual property used to design these techniques, such as data from\ndata-stores used for prediction (in REST) at a rate of more than $25$ tokens\nper second, or even hyper-parameters used for prediction (in LADE). We also\ndiscuss mitigation strategies, such as aggregating tokens across multiple\niterations and padding packets with additional bytes, to avoid such privacy or\nconfidentiality breaches.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs)中Speculative Decoding技术的隐私风险，该技术通过预测多个tokens并并行验证来加速生成，但可能导致输入依赖的预测模式被泄露。研究发现，攻击者可以通过监控tokens生成时间和包大小，识别用户查询并学习私有输入，准确率高达90%以上（REST近100%、LADE达92%、BiLD达95%）。此外，攻击者还能以超过25 tokens per second的速度泄露机密信息，如REST的数据存储或LADE的超参数。论文提出了缓解策略，包括aggregating tokens和padding packets，以减少此类隐私和保密风险。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01076v2",
      "published_date": "2024-11-01 23:14:30 UTC",
      "updated_date": "2024-11-05 15:03:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:53:59.544698"
    },
    {
      "arxiv_id": "2411.01073v1",
      "title": "AttackQA: Development and Adoption of a Dataset for Assisting Cybersecurity Operations using Fine-tuned and Open-Source LLMs",
      "title_zh": "AttackQA：利用微调和开源LLMs开发和采用用于辅助",
      "authors": [
        "Varun Badrinath Krishna"
      ],
      "abstract": "Retrieval-augmented generation (RAG) on specialized domain datasets has shown\nimproved performance when large language models (LLMs) are fine-tuned for\ngenerating responses to user queries. In this study, we develop a cybersecurity\nquestion-answering (Q\\&A) dataset, called AttackQA, and employ it to build a\nRAG-based Q\\&A system designed for analysts in security operations centers. The\ndataset comprises 25,335 Q\\&A pairs, accompanied by rationales to facilitate\nfine-tuning and evaluation. 80\\% of the dataset was generated with help of a\nlightweight open-source LLM (LLama 3 8B), which produced over 1100 tokens per\nsecond with full 16-bit precision on SambaNova System's SN40L specialized\nhardware. To ensure dataset quality, we fine-tuned LLama 3 70B to detect and\nreject low-quality Q\\&A pairs. In using the dataset for RAG, we demonstrate\nthat fine-tuning open-source embeddings and LLMs can yield superior accuracy\ncompared to OpenAI's state-of-the-art proprietary embedding and LLM (GPT-4o).\nFurthermore, we use Llama 3.1 405B as a judge to evaluate answer correctness,\nenabling the creation of a fully open-source, high-speed RAG and evaluation\npipeline with a benchmark for model accuracy.",
      "tldr_zh": "本文开发了AttackQA数据集，包含25,335个网络安全问答(Q&A)对及其理由，用于辅助安全运营中心的分析师构建RAG-based Q&A系统。数据集主要由开源LLM（Llama 3 8B）生成，速度高达每秒1100多tokens，并通过微调Llama 3 70B检测并过滤低质量数据以确保可靠性。实验结果表明，微调开源嵌入和LLM比OpenAI的GPT-4o提供更高的准确率。最终，该研究建立了一个完全开源、高速的RAG和评估管道，使用Llama 3.1 405B作为评判器，为网络安全领域提供了高效基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01073v1",
      "published_date": "2024-11-01 23:03:40 UTC",
      "updated_date": "2024-11-01 23:03:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:54:12.135341"
    },
    {
      "arxiv_id": "2411.01063v2",
      "title": "InterTrans: Leveraging Transitive Intermediate Translations to Enhance LLM-based Code Translation",
      "title_zh": "InterTrans：利用传递性中间翻译增强基于LLM的代码翻译",
      "authors": [
        "Marcos Macedo",
        "Yuan Tian",
        "Pengyu Nie",
        "Filipe R. Cogo",
        "Bram Adams"
      ],
      "abstract": "Code translation aims to convert a program from one programming language (PL)\nto another. This long-standing software engineering task is crucial for\nmodernizing legacy systems, ensuring cross-platform compatibility, enhancing\nperformance, and more. However, automating this process remains challenging due\nto many syntactic and semantic differences between PLs. Recent studies show\nthat even advanced techniques such as large language models (LLMs), especially\nopen-source LLMs, still struggle with the task. Currently, code LLMs are\ntrained with source code from multiple programming languages, thus presenting\nmultilingual capabilities.\n  In this paper, we investigate whether such multilingual capabilities can be\nharnessed to enhance code translation. To achieve this goal, we introduce\nInterTrans, an LLM-based automated code translation approach that, in contrast\nto existing approaches, leverages intermediate translations across PLs to\nbridge the syntactic and semantic gaps between source and target PLs.\n  InterTrans contains two stages. It first utilizes a novel Tree of Code\nTranslation (ToCT) algorithm to plan transitive intermediate translation\nsequences between a given source and target PL, then validates them in a\nspecific order. We evaluate InterTrans with three open LLMs on three benchmarks\n(i.e., CodeNet, HumanEval-X, and TransCoder) involving six PLs. Results show an\nabsolute improvement between 18.3% to 43.3% in Computation Accuracy (CA) for\nInterTrans over Direct Translation with 10 attempts. The best-performing\nvariant of InterTrans (with Magicoder LLM) achieved an average CA of\n87.3%-95.4% on three benchmarks.",
      "tldr_zh": "本文提出 InterTrans，一种基于大型语言模型 (LLMs) 的代码翻译方法，通过利用中间翻译序列来桥接源语言和目标语言之间的语法和语义差异。InterTrans 包括两个阶段：首先使用 Tree of Code Translation (ToCT) 算法规划并验证从源语言到目标语言的中间翻译路径，然后进行有序验证。在 CodeNet、HumanEval-X 和 TransCoder 等基准测试中，InterTrans 相比直接翻译在 Computation Accuracy (CA) 上平均提高了 18.3% 到 43.3%，最佳变体（使用 Magicoder LLM）达到了 87.3%-95.4% 的性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01063v2",
      "published_date": "2024-11-01 22:31:32 UTC",
      "updated_date": "2024-11-05 04:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:54:24.863012"
    },
    {
      "arxiv_id": "2411.01055v2",
      "title": "Combining Physics-based and Data-driven Modeling for Building Energy Systems",
      "title_zh": "物理基础",
      "authors": [
        "Leandro Von Krannichfeldt",
        "Kristina Orehounig",
        "Olga Fink"
      ],
      "abstract": "Building energy modeling plays a vital role in optimizing the operation of\nbuilding energy systems by providing accurate predictions of the building's\nreal-world conditions. In this context, various techniques have been explored,\nranging from traditional physics-based models to data-driven models. Recently,\nresearchers are combining physics-based and data-driven models into hybrid\napproaches. This includes using the physics-based model output as additional\ndata-driven input, learning the residual between physics-based model and real\ndata, learning a surrogate of the physics-based model, or fine-tuning a\nsurrogate model with real data. However, a comprehensive comparison of the\ninherent advantages of these hybrid approaches is still missing. The primary\nobjective of this work is to evaluate four predominant hybrid approaches in\nbuilding energy modeling through a real-world case study, with focus on indoor\nthermodynamics. To achieve this, we devise three scenarios reflecting common\nlevels of building documentation and sensor availability, assess their\nperformance, and analyze their explainability using hierarchical Shapley\nvalues. The real-world study reveals three notable findings. First, greater\nbuilding documentation and sensor availability lead to higher prediction\naccuracy for hybrid approaches. Second, the performance of hybrid approaches\ndepends on the type of building room, but the residual approach using a\nFeedforward Neural Network as data-driven sub-model performs best on average\nacross all rooms. This hybrid approach also demonstrates a superior ability to\nleverage the simulation from the physics-based sub-model. Third, hierarchical\nShapley values prove to be an effective tool for explaining and improving\nhybrid models while accounting for input correlations.",
      "tldr_zh": "本研究探讨了物理模型(physics-based models)和数据驱动模型(data-driven models)的混合方法在建筑能源系统建模中的应用，旨在通过真实案例研究评估四种主要混合策略，焦点在于室内热力学。\n研究设计了三个场景，模拟不同水平的建筑文档和传感器可用性，并使用分层 Shapley values 分析这些方法的性能和可解释性。\n关键发现包括：更多文档和传感器可用性显著提高了预测准确率；残差方法(采用 Feedforward Neural Network 作为数据驱动子模型)平均表现最佳，并更有效地利用物理模型模拟；分层 Shapley values 证明是解释和改进混合模型的有效工具。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01055v2",
      "published_date": "2024-11-01 21:56:39 UTC",
      "updated_date": "2025-04-23 06:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:54:35.964274"
    },
    {
      "arxiv_id": "2411.01053v1",
      "title": "Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Adriel Saporta",
        "Aahlad Puli",
        "Mark Goldstein",
        "Rajesh Ranganath"
      ],
      "abstract": "Contrastive learning methods, such as CLIP, leverage naturally paired\ndata-for example, images and their corresponding text captions-to learn general\nrepresentations that transfer efficiently to downstream tasks. While such\napproaches are generally applied to two modalities, domains such as robotics,\nhealthcare, and video need to support many types of data at once. We show that\nthe pairwise application of CLIP fails to capture joint information between\nmodalities, thereby limiting the quality of the learned representations. To\naddress this issue, we present Symile, a simple contrastive learning approach\nthat captures higher-order information between any number of modalities. Symile\nprovides a flexible, architecture-agnostic objective for learning\nmodality-specific representations. To develop Symile's objective, we derive a\nlower bound on total correlation, and show that Symile representations for any\nset of modalities form a sufficient statistic for predicting the remaining\nmodalities. Symile outperforms pairwise CLIP, even with modalities missing in\nthe data, on cross-modal classification and retrieval across several\nexperiments including on an original multilingual dataset of 33M image, text\nand audio samples and a clinical dataset of chest X-rays, electrocardiograms,\nand laboratory measurements. All datasets and code used in this work are\npublicly available at https://github.com/rajesh-lab/symile.",
      "tldr_zh": "该论文提出 Symile，一种简单的模型无关对比学习方法，用于处理无限模态的表示学习，解决传统方法如 CLIP 在多模态场景中无法捕获联合信息的局限性。Symile 通过推导总相关性的下界，设计了一个灵活的目标函数，使其模态特定表示成为预测其他模态的充分统计。实验结果显示，Symile 在跨模态分类和检索任务上优于 CLIP，即使数据中缺少某些模态，并在包含 33M 样本的多语言数据集和临床数据集（如胸部 X 光、电心图和实验室测量）上表现出色。该方法的所有数据集和代码已公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01053v1",
      "published_date": "2024-11-01 21:49:25 UTC",
      "updated_date": "2024-11-01 21:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:54:48.604530"
    },
    {
      "arxiv_id": "2411.01050v1",
      "title": "BACSA: A Bias-Aware Client Selection Algorithm for Privacy-Preserving Federated Learning in Wireless Healthcare Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Sushilkumar Yadav",
        "Irem Bor-Yaliniz"
      ],
      "abstract": "Federated Learning (FL) has emerged as a transformative approach in\nhealthcare, enabling collaborative model training across decentralized data\nsources while preserving user privacy. However, performance of FL rapidly\ndegrades in practical scenarios due to the inherent bias in non Independent and\nIdentically distributed (non-IID) data among participating clients, which poses\nsignificant challenges to model accuracy and generalization. Therefore, we\npropose the Bias-Aware Client Selection Algorithm (BACSA), which detects user\nbias and strategically selects clients based on their bias profiles. In\naddition, the proposed algorithm considers privacy preservation, fairness and\nconstraints of wireless network environments, making it suitable for sensitive\nhealthcare applications where Quality of Service (QoS), privacy and security\nare paramount. Our approach begins with a novel method for detecting user bias\nby analyzing model parameters and correlating them with the distribution of\nclass-specific data samples. We then formulate a mixed-integer non-linear\nclient selection problem leveraging the detected bias, alongside wireless\nnetwork constraints, to optimize FL performance. We demonstrate that BACSA\nimproves convergence and accuracy, compared to existing benchmarks, through\nevaluations on various data distributions, including Dirichlet and\nclass-constrained scenarios. Additionally, we explore the trade-offs between\naccuracy, fairness, and network constraints, indicating the adaptability and\nrobustness of BACSA to address diverse healthcare applications.",
      "tldr_zh": "本研究针对联邦学习（Federated Learning, FL）在无线医疗网络中的应用，提出了一种偏置感知客户端选择算法（BACSA），以解决非独立同分布（non-IID）数据导致的模型性能下降问题。BACSA 通过分析模型参数和数据分布来检测用户偏置，并基于偏置配置文件战略性地选择客户端，同时考虑隐私保护、公平性和无线网络约束。算法将客户端选择问题表述为混合整数非线性优化问题，优化 FL 的性能。实验结果显示，BACSA 在各种数据分布（如 Dirichlet 和类约束场景）上显著提高了模型的收敛性和准确性，并探讨了准确性、公平性与网络约束之间的权衡，使其适用于敏感的医疗保健应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01050v1",
      "published_date": "2024-11-01 21:34:43 UTC",
      "updated_date": "2024-11-01 21:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:54:59.738007"
    },
    {
      "arxiv_id": "2411.01049v1",
      "title": "Exploratory Models of Human-AI Teams: Leveraging Human Digital Twins to Investigate Trust Development",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Nguyen",
        "Myke C. Cohen",
        "Hsien-Te Kao",
        "Grant Engberson",
        "Louis Penafiel",
        "Spencer Lynch",
        "Svitlana Volkova"
      ],
      "abstract": "As human-agent teaming (HAT) research continues to grow, computational\nmethods for modeling HAT behaviors and measuring HAT effectiveness also\ncontinue to develop. One rising method involves the use of human digital twins\n(HDT) to approximate human behaviors and socio-emotional-cognitive reactions to\nAI-driven agent team members. In this paper, we address three research\nquestions relating to the use of digital twins for modeling trust in HATs.\nFirst, to address the question of how we can appropriately model and\noperationalize HAT trust through HDT HAT experiments, we conducted causal\nanalytics of team communication data to understand the impact of empathy,\nsocio-cognitive, and emotional constructs on trust formation. Additionally, we\nreflect on the current state of the HAT trust science to discuss\ncharacteristics of HAT trust that must be replicable by a HDT such as\nindividual differences in trust tendencies, emergent trust patterns, and\nappropriate measurement of these characteristics over time. Second, to address\nthe question of how valid measures of HDT trust are for approximating human\ntrust in HATs, we discuss the properties of HDT trust: self-report measures,\ninteraction-based measures, and compliance type behavioral measures.\nAdditionally, we share results of preliminary simulations comparing different\nLLM models for generating HDT communications and analyze their ability to\nreplicate human-like trust dynamics. Third, to address how HAT experimental\nmanipulations will extend to human digital twin studies, we share experimental\ndesign focusing on propensity to trust for HDTs vs. transparency and\ncompetency-based trust for AI agents.",
      "tldr_zh": "这篇论文探讨了利用 Human Digital Twins (HDT) 来模拟人类行为和情感反应，以研究人类-AI 团队 (HAT) 中的信任发展。研究通过因果分析团队沟通数据，考察了移情、社会认知和情感因素对信任形成的影响，并讨论了 HDT 需要复制的信任特性，如个体差异和动态模式。同时，通过初步模拟实验比较不同 LLM 模型的沟通生成能力，结果表明 HDT 可以有效近似人类信任动态，并为扩展 HAT 实验设计（如信任倾向和透明度）提供了新框架。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "in review; submitted to Interaction Studies",
      "pdf_url": "http://arxiv.org/pdf/2411.01049v1",
      "published_date": "2024-11-01 21:32:11 UTC",
      "updated_date": "2024-11-01 21:32:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:55:11.348920"
    },
    {
      "arxiv_id": "2411.01042v2",
      "title": "Introduction to AI Safety, Ethics, and Society",
      "title_zh": "人工智能安全、伦理与社会导论",
      "authors": [
        "Dan Hendrycks"
      ],
      "abstract": "Artificial Intelligence is rapidly embedding itself within militaries,\neconomies, and societies, reshaping their very foundations. Given the depth and\nbreadth of its consequences, it has never been more pressing to understand how\nto ensure that AI systems are safe, ethical, and have a positive societal\nimpact. This book aims to provide a comprehensive approach to understanding AI\nrisk. Our primary goals include consolidating fragmented knowledge on AI risk,\nincreasing the precision of core ideas, and reducing barriers to entry by\nmaking content simpler and more comprehensible. The book has been designed to\nbe accessible to readers from diverse backgrounds. You do not need to have\nstudied AI, philosophy, or other such topics. The content is skimmable and\nsomewhat modular, so that you can choose which chapters to read. We introduce\nmathematical formulas in a few places to specify claims more precisely, but\nreaders should be able to understand the main points without these.",
      "tldr_zh": "这本书介绍了人工智能（AI）安全、伦理和社会影响的关键问题，强调AI在军事、经济和社会中的快速嵌入及其潜在后果。作者的目标是通过整合碎片化的AI风险知识、提高核心概念的精确性，并简化内容来降低入门门槛，使其适合多样背景的读者。内容设计为模块化和可浏览式，即使偶尔引入数学公式，也能让非专业人士轻松理解其主要观点。总的来说，该书为确保AI系统安全、伦理并产生积极社会影响提供了全面且易懂的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "603 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.01042v2",
      "published_date": "2024-11-01 21:21:49 UTC",
      "updated_date": "2024-11-15 23:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:55:22.351722"
    },
    {
      "arxiv_id": "2411.01035v1",
      "title": "Provable Length Generalization in Sequence Prediction via Spectral Filtering",
      "title_zh": "翻译失败",
      "authors": [
        "Annie Marsden",
        "Evan Dogariu",
        "Naman Agarwal",
        "Xinyi Chen",
        "Daniel Suo",
        "Elad Hazan"
      ],
      "abstract": "We consider the problem of length generalization in sequence prediction. We\ndefine a new metric of performance in this setting -- the Asymmetric-Regret --\nwhich measures regret against a benchmark predictor with longer context length\nthan available to the learner. We continue by studying this concept through the\nlens of the spectral filtering algorithm. We present a gradient-based learning\nalgorithm that provably achieves length generalization for linear dynamical\nsystems. We conclude with proof-of-concept experiments which are consistent\nwith our theory.",
      "tldr_zh": "本研究探讨了序列预测(sequence prediction)中的长度泛化(length generalization)问题，引入了Asymmetric-Regret作为新性能指标，用于评估学习者与具有更长上下文长度的基准预测器之间的遗憾。研究通过spectral filtering算法分析这一概念，并提出了一种基于梯度的学习算法，能够在线性动力系统中证明长度泛化的可行性。实验结果与理论一致，为序列预测任务提供了概念验证支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01035v1",
      "published_date": "2024-11-01 21:11:40 UTC",
      "updated_date": "2024-11-01 21:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:55:33.968963"
    },
    {
      "arxiv_id": "2411.01034v2",
      "title": "Evaluation Metric for Quality Control and Generative Models in Histopathology Images",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Jeevan",
        "Neeraj Nixon",
        "Abhijeet Patil",
        "Amit Sethi"
      ],
      "abstract": "Our study introduces ResNet-L2 (RL2), a novel metric for evaluating\ngenerative models and image quality in histopathology, addressing limitations\nof traditional metrics, such as Frechet inception distance (FID), when the data\nis scarce. RL2 leverages ResNet features with a normalizing flow to calculate\nRMSE distance in the latent space, providing reliable assessments across\ndiverse histopathology datasets. We evaluated the performance of RL2 on\ndegradation types, such as blur, Gaussian noise, salt-and-pepper noise, and\nrectangular patches, as well as diffusion processes. RL2's monotonic response\nto increasing degradation makes it well-suited for models that assess image\nquality, proving a valuable advancement for evaluating image generation\ntechniques in histopathology. It can also be used to discard low-quality\npatches while sampling from a whole slide image. It is also significantly\nlighter and faster compared to traditional metrics and requires fewer images to\ngive stable metric value.",
      "tldr_zh": "本研究提出了一种新型评估指标 ResNet-L2 (RL2)，用于组织病理学图像中的生成模型和图像质量评估，解决了传统指标如 Frechet Inception Distance (FID) 在数据稀缺时的局限性。RL2 通过利用 ResNet 特征和 normalizing flow 计算潜在空间的 RMSE 距离，对各种图像退化（如模糊、高斯噪声、盐胡椒噪声和矩形补丁）以及扩散过程表现出单调响应。实验结果显示，RL2 比传统指标更轻量、更快速，且只需较少图像即可提供稳定评估，还可用于丢弃低质量图像补丁，从而提升图像生成技术的可靠性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.QM",
        "I.2.1; I.4.0; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; I.5.5; J.3;\n  I.2.10; I.4.4; I.4.3; I.4.5; I.4.1; I.4.2; I.4.6; I.4.7"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages, 5 figures. Accepted in ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.01034v2",
      "published_date": "2024-11-01 21:09:02 UTC",
      "updated_date": "2025-01-02 21:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:55:47.859267"
    },
    {
      "arxiv_id": "2411.01030v5",
      "title": "Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula",
      "title_zh": "Birdie：通过奖励驱动目标和课程推进状态空间模型",
      "authors": [
        "Sam Blouir",
        "Jimmy T. H. Smith",
        "Antonios Anastasopoulos",
        "Amarda Shehu"
      ],
      "abstract": "Efficient state space models (SSMs), such as linear recurrent neural networks\nand linear attention variants, offer computational advantages over Transformers\nbut struggle with tasks requiring long-range in-context retrieval-like text\ncopying, associative recall, and question answering over long contexts.\nPrevious efforts to address these challenges have focused on architectural\nmodifications, often reintroducing computational inefficiencies. In this paper,\nwe propose a novel training procedure, Birdie, that significantly enhances the\nin-context retrieval capabilities of SSMs without altering their architecture.\nOur approach combines bidirectional input processing with dynamic mixtures of\nspecialized pre-training objectives, optimized via reinforcement learning. We\nintroduce a new bidirectional SSM architecture that seamlessly transitions from\nbidirectional context processing to causal generation. Experimental evaluations\ndemonstrate that Birdie markedly improves performance on retrieval-intensive\ntasks such as multi-number phone book lookup, long paragraph\nquestion-answering, and infilling. This narrows the performance gap with\nTransformers, while retaining computational efficiency. Our findings highlight\nthe importance of training procedures in leveraging the fixed-state capacity of\nSSMs, offering a new direction to advance their capabilities. All code and\npre-trained models are available at https://www.github.com/samblouir/birdie,\nwith support for JAX and PyTorch.",
      "tldr_zh": "本文提出 Birdie，一种新型训练程序，用于提升状态空间模型(SSMs)在长距离上下文任务（如文本复制、关联回忆和长段落问答）上的性能，而不需修改其架构。该方法结合双向输入处理、动态混合的专业预训练目标，并通过强化学习优化，实现从双向上下文处理到因果生成的无缝过渡。实验结果显示，Birdie 在多任务（如多号码电话簿查找和长段落问答）上显著提升准确率，缩小了与 Transformers 的性能差距，同时保留了 SSMs 的计算效率。该研究强调了训练程序在利用 SSMs 固定状态容量方面的关键作用，并提供了开源代码和预训练模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2411.01030v5",
      "published_date": "2024-11-01 21:01:13 UTC",
      "updated_date": "2025-02-21 21:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:57:18.264600"
    },
    {
      "arxiv_id": "2411.01029v1",
      "title": "Semi-Strongly solved: a New Definition Leading Computer to Perfect Gameplay",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroki Takizawa"
      ],
      "abstract": "Solving combinatorial games has been a classic research topic in artificial\nintelligence because solutions can offer essential information to improve\ngameplay. Several definitions exist for `solving the game,' but they are\nmarkedly different regarding computational cost and the detail of insights\nderived. In this study, we introduce a novel definition called `semi-strongly\nsolved' and propose an algorithm to achieve this type of solution efficiently.\nThis new definition addresses existing gaps because of its intermediate\ncomputational cost and the quality of the solution. To demonstrate the\npotential of our approach, we derive the theoretical computational complexity\nof our algorithm under a simple condition, and apply it to semi-strongly solve\nthe game of 6x6 Othello. This study raises many new research goals in this\nresearch area.",
      "tldr_zh": "该论文引入了“semi-strongly solved”的新定义，用于解决组合游戏(combinatorial games)，以提供改进游戏玩法的关键信息，该定义在计算成本和解决方案质量之间实现了平衡。研究者提出了一种高效算法，并分析了其在简单条件下的理论计算复杂度。最终，他们将该算法应用于6x6 Othello游戏的求解，展示了其潜力，并为该领域提出了新的研究目标。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01029v1",
      "published_date": "2024-11-01 21:00:46 UTC",
      "updated_date": "2024-11-01 21:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:56:10.270199"
    },
    {
      "arxiv_id": "2411.01023v1",
      "title": "Capturing and Anticipating User Intents in Data Analytics via Knowledge Graphs",
      "title_zh": "通过知识图谱捕获和预测数据分析中的用户意图",
      "authors": [
        "Gerard Pons",
        "Besim Bilalli",
        "Anna Queralt"
      ],
      "abstract": "In today's data-driven world, the ability to extract meaningful information\nfrom data is becoming essential for businesses, organizations and researchers\nalike. For that purpose, a wide range of tools and systems exist addressing\ndata-related tasks, from data integration, preprocessing and modeling, to the\ninterpretation and evaluation of the results. As data continues to grow in\nvolume, variety, and complexity, there is an increasing need for advanced but\nuser-friendly tools, such as intelligent discovery assistants (IDAs) or\nautomated machine learning (AutoML) systems, that facilitate the user's\ninteraction with the data. This enables non-expert users, such as citizen data\nscientists, to leverage powerful data analytics techniques effectively. The\nassistance offered by IDAs or AutoML tools should not be guided only by the\nanalytical problem's data but should also be tailored to each individual user.\nTo this end, this work explores the usage of Knowledge Graphs (KG) as a basic\nframework for capturing in a human-centered manner complex analytics workflows,\nby storing information not only about the workflow's components, datasets and\nalgorithms but also about the users, their intents and their feedback, among\nothers. The data stored in the generated KG can then be exploited to provide\nassistance (e.g., recommendations) to the users interacting with these systems.\nTo accomplish this objective, two methods are explored in this work. Initially,\nthe usage of query templates to extract relevant information from the KG is\nstudied. However, upon identifying its main limitations, the usage of link\nprediction with knowledge graph embeddings is explored, which enhances\nflexibility and allows leveraging the entire structure and components of the\ngraph. The experiments show that the proposed method is able to capture the\ngraph's structure and to produce sensible suggestions.",
      "tldr_zh": "本文提出了一种基于Knowledge Graphs的方法，用于捕获和预测用户意图，从而提升数据分析工具的个性化辅助，特别是针对非专家用户如公民数据科学家。研究重点是构建KG来存储分析工作流组件、数据集、算法、用户意图及反馈信息，以支持智能发现助手(IDAs)和AutoML系统的推荐功能。主要方法包括使用查询模板提取信息，以及采用链接预测与knowledge graph embeddings来克服前者的局限性，提供更灵活的图谱利用。实验结果显示，该方法能有效捕捉KG结构并生成合理的建议，增强了用户交互体验。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print submitted to Knowledge-Based Systems",
      "pdf_url": "http://arxiv.org/pdf/2411.01023v1",
      "published_date": "2024-11-01 20:45:23 UTC",
      "updated_date": "2024-11-01 20:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:56:22.919272"
    },
    {
      "arxiv_id": "2411.01016v1",
      "title": "MoE-I$^2$: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Yang",
        "Yang Sui",
        "Jinqi Xiao",
        "Lingyi Huang",
        "Yu Gong",
        "Yuanlin Duan",
        "Wenqi Jia",
        "Miao Yin",
        "Yu Cheng",
        "Bo Yuan"
      ],
      "abstract": "The emergence of Mixture of Experts (MoE) LLMs has significantly advanced the\ndevelopment of language models. Compared to traditional LLMs, MoE LLMs\noutperform traditional LLMs by achieving higher performance with considerably\nfewer activated parameters. Despite this efficiency, their enormous parameter\nsize still leads to high deployment costs. In this paper, we introduce a\ntwo-stage compression method tailored for MoE to reduce the model size and\ndecrease the computational cost. First, in the inter-expert pruning stage, we\nanalyze the importance of each layer and propose the Layer-wise Genetic Search\nand Block-wise KT-Reception Field with the non-uniform pruning ratio to prune\nthe individual expert. Second, in the intra-expert decomposition stage, we\napply the low-rank decomposition to further compress the parameters within the\nremaining experts. Extensive experiments on Qwen1.5-MoE-A2.7B,\nDeepSeek-V2-Lite, and Mixtral-8$\\times$7B demonstrate that our proposed methods\ncan both reduce the model size and enhance inference efficiency while\nmaintaining performance in various zero-shot tasks. The code will be available\nat \\url{https://github.com/xiaochengsky/MoEI-2.git}",
      "tldr_zh": "该论文提出MoE-I²方法，用于压缩Mixture of Experts (MoE)模型，以减少模型大小和计算成本，同时保持性能。方法分为两阶段：首先，在Inter-Expert Pruning阶段，通过Layer-wise Genetic Search和Block-wise KT-Reception Field分析层级重要性，并采用非均匀修剪比例修剪个体专家；其次，在Intra-Expert Low-Rank Decomposition阶段，对剩余专家的参数进行低秩分解以进一步优化。实验结果显示，在Qwen1.5-MoE-A2.7B、DeepSeek-V2-Lite和Mixtral-8×7B模型上，该方法显著降低了模型规模，提高了推理效率，同时在各种零样本任务中维持了原有性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01016v1",
      "published_date": "2024-11-01 20:37:58 UTC",
      "updated_date": "2024-11-01 20:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:56:36.074466"
    },
    {
      "arxiv_id": "2411.01013v3",
      "title": "A Similarity-Based Oversampling Method for Multi-label Imbalanced Text Data",
      "title_zh": "一种基于相似度的过采样方法，用于多标签不平衡文本数据",
      "authors": [
        "Ismail Hakki Karaman",
        "Gulser Koksal",
        "Levent Eriskin",
        "Salih Salihoglu"
      ],
      "abstract": "In real-world applications, as data availability increases, obtaining labeled\ndata for machine learning (ML) projects remains challenging due to the high\ncosts and intensive efforts required for data annotation. Many ML projects,\nparticularly those focused on multi-label classification, also grapple with\ndata imbalance issues, where certain classes may lack sufficient data to train\neffective classifiers. This study introduces and examines a novel oversampling\nmethod for multi-label text classification, designed to address performance\nchallenges associated with data imbalance. The proposed method identifies\npotential new samples from unlabeled data by leveraging similarity measures\nbetween instances. By iteratively searching the unlabeled dataset, the method\nlocates instances similar to those in underrepresented classes and evaluates\ntheir contribution to classifier performance enhancement. Instances that\ndemonstrate performance improvement are then added to the labeled dataset.\nExperimental results indicate that the proposed approach effectively enhances\nclassifier performance post-oversampling.",
      "tldr_zh": "本研究针对多标签文本数据的不平衡问题（data imbalance），提出了一种基于相似性度量的oversampling方法，以提升分类器性能。该方法通过计算实例之间的相似性，从未标注数据（unlabeled data）中识别出与 underrepresented classes 相似的潜在新样本，并通过迭代评估这些样本对分类器改进的贡献，最终将有效样本添加到标注数据集。该方法专注于multi-label classification任务，实验结果显示，它能显著提高分类器的整体表现，为处理真实世界数据标注挑战提供实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01013v3",
      "published_date": "2024-11-01 20:33:49 UTC",
      "updated_date": "2024-12-21 15:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:56:46.962553"
    },
    {
      "arxiv_id": "2411.00997v1",
      "title": "Identifying Implicit Social Biases in Vision-Language Models",
      "title_zh": "识别视觉语言模型中的隐性社会偏见",
      "authors": [
        "Kimia Hamidieh",
        "Haoran Zhang",
        "Walter Gerych",
        "Thomas Hartvigsen",
        "Marzyeh Ghassemi"
      ],
      "abstract": "Vision-language models, like CLIP (Contrastive Language Image Pretraining),\nare becoming increasingly popular for a wide range of multimodal retrieval\ntasks. However, prior work has shown that large language and deep vision models\ncan learn historical biases contained in their training sets, leading to\nperpetuation of stereotypes and potential downstream harm. In this work, we\nconduct a systematic analysis of the social biases that are present in CLIP,\nwith a focus on the interaction between image and text modalities. We first\npropose a taxonomy of social biases called So-B-IT, which contains 374 words\ncategorized across ten types of bias. Each type can lead to societal harm if\nassociated with a particular demographic group. Using this taxonomy, we examine\nimages retrieved by CLIP from a facial image dataset using each word as part of\na prompt. We find that CLIP frequently displays undesirable associations\nbetween harmful words and specific demographic groups, such as retrieving\nmostly pictures of Middle Eastern men when asked to retrieve images of a\n\"terrorist\". Finally, we conduct an analysis of the source of such biases, by\nshowing that the same harmful stereotypes are also present in a large\nimage-text dataset used to train CLIP models for examples of biases that we\nfind. Our findings highlight the importance of evaluating and addressing bias\nin vision-language models, and suggest the need for transparency and\nfairness-aware curation of large pre-training datasets.",
      "tldr_zh": "本研究分析了视觉语言模型（如 CLIP）中隐含的社会偏见，揭示这些模型可能从训练数据中学习历史刻板印象，导致有害联想和潜在社会危害。作者提出 So-B-IT 分类法，涵盖 374 个词并分类为十种偏见类型，并通过检查 CLIP 在图像检索任务中的表现（如将“terrorist”与中东男性图像关联）来系统评估偏见来源。结果显示，这些偏见源于 CLIP 的训练数据集，强调了评估和解决模型偏见的重要性，并呼吁透明和公平的数据集整理以促进模型公平性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00997v1",
      "published_date": "2024-11-01 19:41:28 UTC",
      "updated_date": "2024-11-01 19:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:56:59.193730"
    },
    {
      "arxiv_id": "2411.00983v1",
      "title": "Improving How Agents Cooperate: Attention Schemas in Artificial Neural Networks",
      "title_zh": "改进代理合作方式：在人工神经网络中的注意力模式",
      "authors": [
        "Kathryn T. Farrell",
        "Kirsten Ziman",
        "Michael S. A. Graziano"
      ],
      "abstract": "Growing evidence suggests that the brain uses an \"attention schema\" to\nmonitor, predict, and help control attention. It has also been suggested that\nan attention schema improves social intelligence by allowing one person to\nbetter predict another. Given their potential advantages, attention schemas\nhave been increasingly tested in machine learning. Here we test small deep\nlearning networks to determine how the addition of an attention schema may\naffect performance on a range of tasks. First, we found that an agent with an\nattention schema is better at judging or categorizing the attention states of\nother agents. Second, we found that an agent with an attention schema develops\na pattern of attention that is easier for other agents to judge and categorize.\nThird, we found that in a joint task where two agents paint a scene together\nand must predict each other's behavior for best performance, adding an\nattention schema improves that performance. Finally, we find that the\nperformance improvements caused by an attention schema are not a non-specific\nresult of an increase in network complexity. Not all performance, on all tasks,\nis improved. Instead, improvement is specific to \"social\" tasks involving\njudging, categorizing, or predicting the attention of other agents. These\nresults suggest that an attention schema may be useful in machine learning for\nimproving cooperativity and social behavior.",
      "tldr_zh": "本研究探讨了在人工神经网络中添加“attention schema”机制，以提升代理间的合作能力。具体而言，通过测试小深度学习网络，研究发现，配备 attention schema 的代理能更准确地判断和分类其他代理的注意力状态，并使自身注意力模式更容易被他人识别。在一个联合任务中（如两个代理合作绘画），这种机制显著提高了预测彼此行为的性能。总体上，attention schema 的改进仅限于“社会”任务，而非网络复杂性的泛化结果，从而为机器学习中的合作性和社会行为优化提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00983v1",
      "published_date": "2024-11-01 19:18:07 UTC",
      "updated_date": "2024-11-01 19:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:57:10.477073"
    },
    {
      "arxiv_id": "2411.03887v2",
      "title": "OML: Open, Monetizable, and Loyal AI",
      "title_zh": "OML：开放、可货币化且忠诚的 AI",
      "authors": [
        "Zerui Cheng",
        "Edoardo Contente",
        "Ben Finch",
        "Oleg Golev",
        "Jonathan Hayase",
        "Andrew Miller",
        "Niusha Moshrefi",
        "Anshul Nasery",
        "Sandeep Nailwal",
        "Sewoong Oh",
        "Himanshu Tyagi",
        "Pramod Viswanath"
      ],
      "abstract": "Artificial Intelligence (AI) has steadily improved across a wide range of\ntasks. However, the development and deployment of AI are almost entirely\ncontrolled by a few powerful organizations that are racing to create Artificial\nGeneral Intelligence (AGI). The centralized entities make decisions with little\npublic oversight, shaping the future of humanity, often with unforeseen\nconsequences. In this paper, we propose OML, which stands for Open,\nMonetizable, and Loyal AI, an approach designed to democratize AI development.\nOML is realized through an interdisciplinary framework spanning AI, blockchain,\nand cryptography. We present several ideas for constructing OML using\ntechnologies such as Trusted Execution Environments (TEE), traditional\ncryptographic primitives like fully homomorphic encryption and functional\nencryption, obfuscation, and AI-native solutions rooted in the sample\ncomplexity and intrinsic hardness of AI tasks. A key innovation of our work is\nintroducing a new scientific field: AI-native cryptography. Unlike conventional\ncryptography, which focuses on discrete data and binary security guarantees,\nAI-native cryptography exploits the continuous nature of AI data\nrepresentations and their low-dimensional manifolds, focusing on improving\napproximate performance. One core idea is to transform AI attack methods, such\nas data poisoning, into security tools. This novel approach serves as a\nfoundation for OML 1.0 which uses model fingerprinting to protect the integrity\nand ownership of AI models. The spirit of OML is to establish a decentralized,\nopen, and transparent platform for AI development, enabling the community to\ncontribute, monetize, and take ownership of AI models. By decentralizing\ncontrol and ensuring transparency through blockchain technology, OML prevents\nthe concentration of power and provides accountability in AI development that\nhas not been possible before.",
      "tldr_zh": "该论文指出，AI 开发目前被少数组织主导，缺乏公众监督，可能导致意想不到的后果。为此，提出 OML（Open, Monetizable, and Loyal AI）框架，以民主化 AI 开发，强调开放、可货币化和忠诚性。OML 通过跨学科方法整合 AI、区块链和密码学，包括 Trusted Execution Environments (TEE)、fully homomorphic encryption 和 functional encryption 等技术，并引入创新领域 AI-native cryptography，将 AI 攻击如 data poisoning 转化为安全工具。最终，OML 利用区块链构建去中心化平台，实现模型完整性保护（如 model fingerprinting）和社区贡献、货币化，确保透明性和问责制。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "60 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03887v2",
      "published_date": "2024-11-01 18:46:03 UTC",
      "updated_date": "2024-11-13 17:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:57:24.140626"
    },
    {
      "arxiv_id": "2411.00970v1",
      "title": "Incremental IVF Index Maintenance for Streaming Vector Search",
      "title_zh": "用于流式向量搜索的增量 IVF 索引维护",
      "authors": [
        "Jason Mohoney",
        "Anil Pacaci",
        "Shihabur Rahman Chowdhury",
        "Umar Farooq Minhas",
        "Jeffery Pound",
        "Cedric Renggli",
        "Nima Reyhani",
        "Ihab F. Ilyas",
        "Theodoros Rekatsinas",
        "Shivaram Venkataraman"
      ],
      "abstract": "The prevalence of vector similarity search in modern machine learning\napplications and the continuously changing nature of data processed by these\napplications necessitate efficient and effective index maintenance techniques\nfor vector search indexes. Designed primarily for static workloads, existing\nvector search indexes degrade in search quality and performance as the\nunderlying data is updated unless costly index reconstruction is performed. To\naddress this, we introduce Ada-IVF, an incremental indexing methodology for\nInverted File (IVF) indexes. Ada-IVF consists of 1) an adaptive maintenance\npolicy that decides which index partitions are problematic for performance and\nshould be repartitioned and 2) a local re-clustering mechanism that determines\nhow to repartition them. Compared with state-of-the-art dynamic IVF index\nmaintenance strategies, Ada-IVF achieves an average of 2x and up to 5x higher\nupdate throughput across a range of benchmark workloads.",
      "tldr_zh": "本文针对流式向量搜索中的数据更新问题，提出了一种增量 IVF 索引维护方法 Ada-IVF，以解决现有 Inverted File (IVF) 索引在动态数据环境下性能和搜索质量下降的问题。Ada-IVF 包括一个自适应维护策略，用于识别并选择需要重新分区的索引分区，以及一个本地重新聚类机制来优化这些分区的重新组织。与最先进的动态 IVF 索引维护策略相比，该方法在各种基准工作负载中实现了平均 2 倍、最高 5 倍的更新吞吐量，提高了索引维护的效率和有效性。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "14 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00970v1",
      "published_date": "2024-11-01 18:43:45 UTC",
      "updated_date": "2024-11-01 18:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:57:36.192982"
    },
    {
      "arxiv_id": "2411.00960v1",
      "title": "Scalable AI Framework for Defect Detection in Metal Additive Manufacturing",
      "title_zh": "用于金属增材制造中缺陷检测的可扩展 AI 框架",
      "authors": [
        "Duy Nhat Phan",
        "Sushant Jha",
        "James P. Mavo",
        "Erin L. Lanigan",
        "Linh Nguyen",
        "Lokendra Poudel",
        "Rahul Bhowmik"
      ],
      "abstract": "Additive Manufacturing (AM) is transforming the manufacturing sector by\nenabling efficient production of intricately designed products and small-batch\ncomponents. However, metal parts produced via AM can include flaws that cause\ninferior mechanical properties, including reduced fatigue response, yield\nstrength, and fracture toughness. To address this issue, we leverage\nconvolutional neural networks (CNN) to analyze thermal images of printed\nlayers, automatically identifying anomalies that impact these properties. We\nalso investigate various synthetic data generation techniques to address\nlimited and imbalanced AM training data. Our models' defect detection\ncapabilities were assessed using images of Nickel alloy 718 layers produced on\na laser powder bed fusion AM machine and synthetic datasets with and without\nadded noise. Our results show significant accuracy improvements with synthetic\ndata, emphasizing the importance of expanding training sets for reliable defect\ndetection. Specifically, Generative Adversarial Networks (GAN)-generated\ndatasets streamlined data preparation by eliminating human intervention while\nmaintaining high performance, thereby enhancing defect detection capabilities.\nAdditionally, our denoising approach effectively improves image quality,\nensuring reliable defect detection. Finally, our work integrates these models\nin the CLoud ADditive MAnufacturing (CLADMA) module, a user-friendly interface,\nto enhance their accessibility and practicality for AM applications. This\nintegration supports broader adoption and practical implementation of advanced\ndefect detection in AM processes.",
      "tldr_zh": "本研究提出一个可扩展的 AI 框架，用于金属增材制造 (AM) 中的缺陷检测，旨在通过分析热图像自动识别影响机械性能（如疲劳响应、屈服强度和断裂韧性）的异常。框架利用 Convolutional Neural Networks (CNN) 进行图像分析，并探索合成数据生成技术（如 Generative Adversarial Networks, GAN）来解决训练数据有限和不平衡的问题，同时采用去噪方法提升图像质量。实验结果显示，使用 GAN 生成的合成数据集显著提高了缺陷检测准确率，在 Nickel alloy 718 层图像上比基线模型表现更优；最终，该框架整合到 CLoud ADditive MAnufacturing (CLADMA) 模块中，提供用户友好的界面，促进实际应用的采用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.00960v1",
      "published_date": "2024-11-01 18:17:59 UTC",
      "updated_date": "2024-11-01 18:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:57:48.963903"
    },
    {
      "arxiv_id": "2411.00949v1",
      "title": "From Fake Perfects to Conversational Imperfects: Exploring Image-Generative AI as a Boundary Object for Participatory Design of Public Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Jose A. Guridi",
        "Angel Hsing-Chi Hwang",
        "Duarte Santo",
        "Maria Goula",
        "Cristobal Cheyre",
        "Lee Humphreys",
        "Marco Rangel"
      ],
      "abstract": "Designing public spaces requires balancing the interests of diverse\nstakeholders within a constrained physical and institutional space. Designers\nusually approach these problems through participatory methods but struggle to\nincorporate diverse perspectives into design outputs. The growing capabilities\nof image-generative artificial intelligence (IGAI) could support participatory\ndesign. Prior work in leveraging IGAI's capabilities in design has focused on\naugmenting the experience and performance of individual creators. We study how\nIGAI could facilitate participatory processes when designing public spaces, a\ncomplex collaborative task. We conducted workshops and IGAI-mediated interviews\nin a real-world participatory process to upgrade a park in Los Angeles. We\nfound (1) a shift from focusing on accuracy to fostering richer conversations\nas the desirable outcome of adopting IGAI in participatory design, (2) that\nIGAI promoted more space-aware conversations, and (3) that IGAI-mediated\nconversations are subject to the abilities of the facilitators in managing the\ninteraction between themselves, the AI, and stakeholders. We contribute by\ndiscussing practical implications for using IGAI in participatory design,\nincluding success metrics, relevant skills, and asymmetries between designers\nand stakeholders. We finish by proposing a series of open research questions.",
      "tldr_zh": "本研究探讨了图像生成 AI (IGAI) 作为参与式设计中的边界对象，如何促进公共空间的设计过程，以平衡多样利益相关者的观点。研究者通过在洛杉矶一个公园升级项目的真实场景中开展工作坊和 IGAI 调解的访谈，发现 IGAI 促使参与者从关注图像准确性转向激发更丰富的对话，并提升了对空间的意识，但效果依赖于主持人在 AI 与利益相关者互动中的管理能力。主要贡献包括讨论 IGAI 在参与式设计中的实用含义，如成功指标、所需技能以及设计师与利益相关者之间的不对称性，并提出了一系列开放研究问题。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Forthcoming in the Proceedings of the 2025 Conference on Computer\n  Supported Cooperative Work and Social Computing (CSCW)",
      "pdf_url": "http://arxiv.org/pdf/2411.00949v1",
      "published_date": "2024-11-01 18:02:46 UTC",
      "updated_date": "2024-11-01 18:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:58:00.390845"
    },
    {
      "arxiv_id": "2411.00774v5",
      "title": "Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Xiong Wang",
        "Yangze Li",
        "Chaoyou Fu",
        "Yunhang Shen",
        "Lei Xie",
        "Ke Li",
        "Xing Sun",
        "Long Ma"
      ],
      "abstract": "Rapidly developing large language models (LLMs) have brought tremendous\nintelligent applications. Especially, the GPT-4o's excellent duplex speech\ninteraction ability has brought impressive experience to users. Researchers\nhave recently proposed several multi-modal LLMs in this direction that can\nachieve user-agent speech-to-speech conversations. This paper proposes a novel\nspeech-text multimodal LLM architecture called Freeze-Omni. Our main\ncontribution is that the speech input and output modalities can be easily\nconnected to a textual LLM while keeping the LLM's parameters frozen throughout\nthe training process. We design a three-stage training strategy for modeling\nboth the speech input and output, enabling Freeze-Omni to obtain\nspeech-to-speech conversation ability using text-speech paired data (such as\nASR and TTS data) and only 60,000 multi-round text Q&A data on 8 GPUs.\nMoreover, we can effectively ensure that the intelligence of the Freeze-Omni in\nthe speech modality is at the same level compared with that in the text\nmodality of its backbone LLM, while achieving low latency end-to-end spoken\nresponse. In addition, we also designed a method to achieve duplex dialogue\nability through multi-task training, giving Freeze-Omni a more natural style of\ndialogue ability between users and agents. In summary, Freeze-Omni holds great\npotential to conduct speech-to-speech dialogue based on a multimodal LLM under\nthe condition of a frozen LLM, avoiding the catastrophic forgetting problem\ncaused by limited data and training resources.",
      "tldr_zh": "该论文提出了一种名为 Freeze-Omni 的智能、低延迟语音到语音对话模型，基于冻结参数的LLM（Frozen LLM），允许语音输入和输出模态轻松连接而不改变LLM的核心参数。研究采用三阶段训练策略，利用ASR和TTS数据以及仅60,000多轮文本Q&A数据，在8 GPUs上训练，实现语音模态的智能水平与文本模态相当，同时支持低延迟端到端响应和双工对话能力。总体上，Freeze-Omni通过避免灾难性遗忘问题，展示了在有限资源下构建高效多模态LLM对话系统的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Project Page: https://freeze-omni.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2411.00774v5",
      "published_date": "2024-11-01 17:59:51 UTC",
      "updated_date": "2024-12-08 05:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:58:11.572650"
    },
    {
      "arxiv_id": "2411.00773v2",
      "title": "LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Li",
        "Zhaoyu Li",
        "Qiwei Du",
        "Jinqi Luo",
        "Wenshan Wang",
        "Yaqi Xie",
        "Simon Stepputtis",
        "Chen Wang",
        "Katia P. Sycara",
        "Pradeep Kumar Ravikumar",
        "Alexander G. Gray",
        "Xujie Si",
        "Sebastian Scherer"
      ],
      "abstract": "Recent years have witnessed the rapid development of Neuro-Symbolic (NeSy) AI\nsystems, which integrate symbolic reasoning into deep neural networks. However,\nmost of the existing benchmarks for NeSy AI fail to provide long-horizon\nreasoning tasks with complex multi-agent interactions. Furthermore, they are\nusually constrained by fixed and simplistic logical rules over limited\nentities, making them far from real-world complexities. To address these\ncrucial gaps, we introduce LogiCity, the first simulator based on customizable\nfirst-order logic (FOL) for an urban-like environment with multiple dynamic\nagents. LogiCity models diverse urban elements using semantic and spatial\nconcepts, such as IsAmbulance(X) and IsClose(X, Y). These concepts are used to\ndefine FOL rules that govern the behavior of various agents. Since the concepts\nand rules are abstractions, they can be universally applied to cities with any\nagent compositions, facilitating the instantiation of diverse scenarios.\nBesides, a key feature of LogiCity is its support for user-configurable\nabstractions, enabling customizable simulation complexities for logical\nreasoning. To explore various aspects of NeSy AI, LogiCity introduces two\ntasks, one features long-horizon sequential decision-making, and the other\nfocuses on one-step visual reasoning, varying in difficulty and agent\nbehaviors. Our extensive evaluation reveals the advantage of NeSy frameworks in\nabstract reasoning. Moreover, we highlight the significant challenges of\nhandling more complex abstractions in long-horizon multi-agent scenarios or\nunder high-dimensional, imbalanced data. With its flexible design, various\nfeatures, and newly raised challenges, we believe LogiCity represents a pivotal\nstep forward in advancing the next generation of NeSy AI. All the code and data\nare open-sourced at our website: https://jaraxxus-me.github.io/LogiCity/",
      "tldr_zh": "该研究引入了 LogiCity，一种基于 first-order logic (FOL) 的抽象城市模拟器，旨在推进 Neuro-Symbolic AI (NeSy AI) 系统的发展，通过支持可定制的语义和空间概念（如 IsAmbulance(X) 和 IsClose(X, Y)）来模拟复杂多智能体互动，解决现有基准中缺乏长时序推理和真实世界复杂性的问题。LogiCity 提供了两个任务：长时序顺序决策和一步视觉推理，允许用户配置不同难度和代理行为。实验评估显示，NeSy 框架在抽象推理中表现出优势，但也突出了处理复杂抽象、多智能体场景和高维不平衡数据的挑战，为下一代 NeSy AI 的发展提供了关键推动。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 8 figures, In Advances in Neural Information Processing\n  Systems (NeurIPS) 37 D&B Track (2024): 69840-69864",
      "pdf_url": "http://arxiv.org/pdf/2411.00773v2",
      "published_date": "2024-11-01 17:59:46 UTC",
      "updated_date": "2025-04-03 19:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:58:24.853864"
    },
    {
      "arxiv_id": "2411.00769v3",
      "title": "GameGen-X: Interactive Open-world Game Video Generation",
      "title_zh": "GameGen-X：交互式开放世界游戏视频生成",
      "authors": [
        "Haoxuan Che",
        "Xuanhua He",
        "Quande Liu",
        "Cheng Jin",
        "Hao Chen"
      ],
      "abstract": "We introduce GameGen-X, the first diffusion transformer model specifically\ndesigned for both generating and interactively controlling open-world game\nvideos. This model facilitates high-quality, open-domain generation by\nsimulating an extensive array of game engine features, such as innovative\ncharacters, dynamic environments, complex actions, and diverse events.\nAdditionally, it provides interactive controllability, predicting and altering\nfuture content based on the current clip, thus allowing for gameplay\nsimulation. To realize this vision, we first collected and built an Open-World\nVideo Game Dataset from scratch. It is the first and largest dataset for\nopen-world game video generation and control, which comprises over a million\ndiverse gameplay video clips sampling from over 150 games with informative\ncaptions from GPT-4o. GameGen-X undergoes a two-stage training process,\nconsisting of foundation model pre-training and instruction tuning. Firstly,\nthe model was pre-trained via text-to-video generation and video continuation,\nendowing it with the capability for long-sequence, high-quality open-domain\ngame video generation. Further, to achieve interactive controllability, we\ndesigned InstructNet to incorporate game-related multi-modal control signal\nexperts. This allows the model to adjust latent representations based on user\ninputs, unifying character interaction and scene content control for the first\ntime in video generation. During instruction tuning, only the InstructNet is\nupdated while the pre-trained foundation model is frozen, enabling the\nintegration of interactive controllability without loss of diversity and\nquality of generated video content.",
      "tldr_zh": "本研究引入了 GameGen-X，这是一个专门设计的扩散 transformer 模型，用于生成高质量的开放世界游戏视频并实现交互控制，支持创新角色、动态环境、复杂动作和多样事件。研究者构建了首个大型数据集 Open-World Video Game Dataset，从超过150个游戏中收集超过一百万的视频片段，并使用 GPT-4o 生成信息性标题。GameGen-X 通过两阶段训练过程，首先进行文本到视频生成和视频续接的预训练，以实现长序列的高质量视频生成；随后，通过 InstructNet 整合多模态控制信号，实现用户输入下的潜在表示调整，从而统一人物互动和场景控制。相比传统方法，该模型在保持生成多样性和质量的同时，大大提升了游戏视频的交互可玩性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Homepage: https://gamegen-x.github.io/ Github:\n  https://github.com/GameGen-X/GameGen-X",
      "pdf_url": "http://arxiv.org/pdf/2411.00769v3",
      "published_date": "2024-11-01 17:59:17 UTC",
      "updated_date": "2024-12-06 13:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:58:38.059997"
    },
    {
      "arxiv_id": "2411.00934v1",
      "title": "Generative Memesis: AI Mediates Political Memes in the 2024 USA Presidential Election",
      "title_zh": "翻译失败",
      "authors": [
        "Ho-Chun Herbert Chang",
        "Benjamin Shaman",
        "Yung-chun Chen",
        "Mingyue Zha",
        "Sean Noh",
        "Chiyu Wei",
        "Tracy Weener",
        "Maya Magee"
      ],
      "abstract": "Visual content on social media has become increasingly influential in shaping\npolitical discourse and civic engagement. Using a dataset of 239,526 Instagram\nimages, deep learning, and LLM-based workflows, we examine the impact of\ndifferent content types on user engagement during the 2024 US presidential\nElections, with a focus on synthetic visuals. Results show while synthetic\ncontent may not increase engagement alone, it mediates how political\ninformation is created through highly effective, often absurd, political memes.\nWe define the notion of generative memesis, where memes are no longer shared\nperson-to-person but mediated by AI through customized, generated images. We\nalso find partisan divergences: Democrats use AI for in-group support whereas\nRepublicans use it for out-group attacks. Non-traditional, left-leaning outlets\nare the primary creators of political memes; emphasis on different topics\nlargely follows issue ownership.",
      "tldr_zh": "本研究利用239,526张Instagram图像、深度学习和LLM-based workflows，分析了2024年美国总统选举中视觉内容对用户互动的影响，重点关注合成视觉内容。结果表明，合成内容本身并不会直接提升互动，但通过高效且往往荒谬的政治memes中介了政治信息传播，并定义了generative memesis概念，即memes不再是人传人，而是由AI生成定制图像。研究还发现党派差异：民主党人主要用AI强化内部支持，而共和党人用于攻击外部群体；非传统左倾媒体是主要创建者，话题强调遵循issue ownership。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00934v1",
      "published_date": "2024-11-01 17:35:05 UTC",
      "updated_date": "2024-11-01 17:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:58:48.347142"
    },
    {
      "arxiv_id": "2411.02433v2",
      "title": "SLED: Self Logits Evolution Decoding for Improving Factuality in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyi Zhang",
        "Da-Cheng Juan",
        "Cyrus Rashtchian",
        "Chun-Sung Ferng",
        "Heinrich Jiang",
        "Yiran Chen"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\ntheir outputs can sometimes be unreliable or factually incorrect. To address\nthis, we introduce Self Logits Evolution Decoding (SLED), a novel decoding\nframework that enhances the truthfulness of LLMs without relying on external\nknowledge bases or requiring further fine-tuning. From an optimization\nperspective, our SLED framework leverages the latent knowledge embedded within\nthe LLM by contrasting the output logits from the final layer with those from\nearly layers. It then utilizes an approximate gradient approach to enable\nlatent knowledge to guide the self-refinement of outputs, thereby effectively\nimproving factual accuracy. Extensive experiments have been conducted on\nestablished benchmarks across a diverse range of model families (LLaMA 2, LLaMA\n3, Gemma) and scales (from 2B to 70B), including more advanced architectural\nconfigurations such as the mixture of experts (MoE). Our evaluation spans a\nwide variety of tasks, including multi-choice, open-generation, and adaptations\nto chain-of-thought reasoning tasks. The results demonstrate that SLED\nconsistently improves factual accuracy by up to 20\\% compared to existing\ndecoding methods while maintaining natural language fluency and negligible\nlatency overhead. Furthermore, it can be flexibly combined with other decoding\nmethods to further enhance their performance.",
      "tldr_zh": "本研究提出了一种名为 Self Logits Evolution Decoding (SLED) 的新解码框架，旨在提升 Large Language Models (LLMs) 的输出真实性，而无需依赖外部知识库或进一步微调。SLED 通过对比模型最终层和早期层的输出 logits，并采用近似梯度方法，利用 LLM 内部的潜在知识指导输出自精炼，从而有效改善事实准确性。实验在多种模型家族（如 LLaMA 2、LLaMA 3 和 Gemma）和规模（从 2B 到 70B，包括 mixture of experts (MoE) 架构）上进行，涵盖多选、开放生成和 chain-of-thought 推理任务。结果显示，SLED 相较现有解码方法可提高事实准确性高达 20%，同时保持自然语言流畅性和几乎无延迟开销，且能灵活与其他方法结合以进一步提升性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2024; project page is available at\n  https://jayzhang42.github.io/sled_page/",
      "pdf_url": "http://arxiv.org/pdf/2411.02433v2",
      "published_date": "2024-11-01 17:33:34 UTC",
      "updated_date": "2024-11-27 20:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:58:59.821974"
    },
    {
      "arxiv_id": "2411.11856v3",
      "title": "Automatically Improving LLM-based Verilog Generation using EDA Tool Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Blocklove",
        "Shailja Thakur",
        "Benjamin Tan",
        "Hammond Pearce",
        "Siddharth Garg",
        "Ramesh Karri"
      ],
      "abstract": "Traditionally, digital hardware designs are written in the Verilog hardware\ndescription language (HDL) and debugged manually by engineers. This can be\ntime-consuming and error-prone for complex designs. Large Language Models\n(LLMs) are emerging as a potential tool to help generate fully functioning HDL\ncode, but most works have focused on generation in the single-shot capacity:\ni.e., run and evaluate, a process that does not leverage debugging and, as\nsuch, does not adequately reflect a realistic development process. In this\nwork, we evaluate the ability of LLMs to leverage feedback from electronic\ndesign automation (EDA) tools to fix mistakes in their own generated Verilog.\nTo accomplish this, we present an open-source, highly customizable framework,\nAutoChip, which combines conversational LLMs with the output from Verilog\ncompilers and simulations to iteratively generate and repair Verilog. To\ndetermine the success of these LLMs we leverage the VerilogEval benchmark set.\nWe evaluate four state-of-the-art conversational LLMs, focusing on readily\naccessible commercial models. EDA tool feedback proved to be consistently more\neffective than zero-shot prompting only with GPT-4o, the most computationally\ncomplex model we evaluated. In the best case, we observed a 5.8% increase in\nthe number of successful designs with a 34.2% decrease in cost over the best\nzero-shot results. Mixing smaller models with this larger model at the end of\nthe feedback iterations resulted in equally as much success as with GPT-4o\nusing feedback, but incurred 41.9% lower cost (corresponding to an overall\ndecrease in cost over zero-shot by 89.6%).",
      "tldr_zh": "本研究探讨了利用电子设计自动化 (EDA) 工具反馈来自动改进大型语言模型 (LLMs) 生成的 Verilog 硬件描述语言 (HDL) 代码，以解决传统手动调试的效率问题。作者提出一个开源框架 AutoChip，该框架结合对话式 LLMs 与 Verilog 编译器和模拟器的输出，进行迭代生成和修复代码，从而模拟真实的开发流程。实验使用 VerilogEval 基准测试评估四种先进 LLMs，结果显示 EDA 反馈显著提升 GPT-4o 的性能，使成功设计数量增加 5.8%，成本降低 34.2%；此外，通过混合使用小型模型和 GPT-4o，在保持相同成功率的同时，总成本较零射击提示减少 89.6%。这为高效的硬件设计自动化提供了新路径。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted for publication in TODAES Special Issue on Large Language\n  Models for Electronic System Design Automation",
      "pdf_url": "http://arxiv.org/pdf/2411.11856v3",
      "published_date": "2024-11-01 17:33:28 UTC",
      "updated_date": "2025-03-04 21:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:59:11.988823"
    },
    {
      "arxiv_id": "2411.00750v2",
      "title": "Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Ding",
        "Zhiheng Xi",
        "Wei He",
        "Zhuoyuan Li",
        "Yitao Zhai",
        "Xiaowei Shi",
        "Xunliang Cai",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Self-improvement methods enable large language models (LLMs) to generate\nsolutions themselves and iteratively train on filtered, high-quality\nrationales. This process proves effective and reduces the reliance on human\nsupervision in LLMs' reasoning, but the performance soon plateaus. We delve\ninto the process and find that models tend to over-sample on easy queries and\nunder-sample on queries they have yet to master. As iterations proceed, this\nimbalance in sampling is exacerbated, leading to a long-tail distribution where\nsolutions to difficult queries almost diminish. This phenomenon limits the\nperformance gain of self-improving models. A straightforward solution is\nbrute-force sampling to balance the distribution, which significantly raises\ncomputational costs. In this paper, we introduce Guided Self-Improvement (GSI),\na strategy aimed at improving the efficiency of sampling challenging\nheavy-tailed data. It leverages Socratic-style guidance signals to help LLM\nreasoning with complex queries, reducing the exploration effort and minimizing\ncomputational overhead. Experiments on four models across diverse mathematical\ntasks show that GSI strikes a balance between performance and efficiency, while\nalso being effective on held-out tasks.",
      "tldr_zh": "该研究发现，大型语言模型(LLMs)在自提升过程中存在尾部收窄问题，即过度采样简单查询而忽略困难查询，导致性能停滞和长尾分布不平衡。针对此，论文提出Guided Self-Improvement (GSI)策略，通过Socratic-Guided Sampling利用苏格拉底式指导信号，帮助LLMs更高效地处理复杂查询，减少计算开销。实验在四个模型和多种数学任务上验证，GSI显著提升了性能和效率，同时适用于未见任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Main Conference. Codes are publicly available\n  at https://github.com/Yiwen-Ding/Guided-Self-Improvement",
      "pdf_url": "http://arxiv.org/pdf/2411.00750v2",
      "published_date": "2024-11-01 17:18:45 UTC",
      "updated_date": "2025-02-21 08:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:59:23.595776"
    },
    {
      "arxiv_id": "2411.00932v1",
      "title": "LLMs: A Game-Changer for Software Engineers?",
      "title_zh": "翻译失败",
      "authors": [
        "Md Asraful Haque"
      ],
      "abstract": "Large Language Models (LLMs) like GPT-3 and GPT-4 have emerged as\ngroundbreaking innovations with capabilities that extend far beyond traditional\nAI applications. These sophisticated models, trained on massive datasets, can\ngenerate human-like text, respond to complex queries, and even write and\ninterpret code. Their potential to revolutionize software development has\ncaptivated the software engineering (SE) community, sparking debates about\ntheir transformative impact. Through a critical analysis of technical\nstrengths, limitations, real-world case studies, and future research\ndirections, this paper argues that LLMs are not just reshaping how software is\ndeveloped but are redefining the role of developers. While challenges persist,\nLLMs offer unprecedented opportunities for innovation and collaboration. Early\nadoption of LLMs in software engineering is crucial to stay competitive in this\nrapidly evolving landscape. This paper serves as a guide, helping developers,\norganizations, and researchers understand how to harness the power of LLMs to\nstreamline workflows and acquire the necessary skills.",
      "tldr_zh": "这篇论文探讨大型语言模型（LLMs）如 GPT-3 和 GPT-4 是否能彻底改变软件工程（SE），通过分析其技术优势、局限性、真实案例和未来研究方向，论证 LLMs 正在重塑软件开发流程并重新定义开发者的角色。论文指出，尽管存在挑战，LLMs 提供了前所未有的创新和协作机会，并强调早期采用这些模型对于保持竞争力至关重要。该研究作为指南，帮助开发人员、组织和研究者利用 LLMs 简化工作流程并提升技能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "Software Engineering (cs.SE), Artificial Intelligence (cs.AI)"
      ],
      "primary_category": "cs.SE",
      "comment": "20 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.00932v1",
      "published_date": "2024-11-01 17:14:37 UTC",
      "updated_date": "2024-11-01 17:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:59:35.293754"
    },
    {
      "arxiv_id": "2411.00743v1",
      "title": "Decoding Dark Matter: Specialized Sparse Autoencoders for Interpreting Rare Concepts in Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aashiq Muhamed",
        "Mona Diab",
        "Virginia Smith"
      ],
      "abstract": "Understanding and mitigating the potential risks associated with foundation\nmodels (FMs) hinges on developing effective interpretability methods. Sparse\nAutoencoders (SAEs) have emerged as a promising tool for disentangling FM\nrepresentations, but they struggle to capture rare, yet crucial concepts in the\ndata. We introduce Specialized Sparse Autoencoders (SSAEs), designed to\nilluminate these elusive dark matter features by focusing on specific\nsubdomains. We present a practical recipe for training SSAEs, demonstrating the\nefficacy of dense retrieval for data selection and the benefits of Tilted\nEmpirical Risk Minimization as a training objective to improve concept recall.\nOur evaluation of SSAEs on standard metrics, such as downstream perplexity and\n$L_0$ sparsity, show that they effectively capture subdomain tail concepts,\nexceeding the capabilities of general-purpose SAEs. We showcase the practical\nutility of SSAEs in a case study on the Bias in Bios dataset, where SSAEs\nachieve a 12.5\\% increase in worst-group classification accuracy when applied\nto remove spurious gender information. SSAEs provide a powerful new lens for\npeering into the inner workings of FMs in subdomains.",
      "tldr_zh": "本研究针对基础模型（FMs）的可解释性问题，提出Specialized Sparse Autoencoders (SSAEs)，旨在捕捉稀有概念（即“暗物质”特征），以解决传统Sparse Autoencoders (SAEs) 在处理这些概念时的不足。SSAEs 通过dense retrieval 进行数据选择，并采用Tilted Empirical Risk Minimization 作为训练目标，从而提升概念召回能力。实验结果显示，SSAEs 在下游 perplexity 和 $L_0$ sparsity 等指标上表现优于通用 SAEs，能够有效捕捉子域的尾部概念。在 Bias in Bios 数据集的案例研究中，SSAEs 移除虚假性别信息后，最差组分类准确率提高了12.5%。总之，SSAEs 为深入理解 FMs 在特定子域的内部机制提供了强大工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00743v1",
      "published_date": "2024-11-01 17:09:34 UTC",
      "updated_date": "2024-11-01 17:09:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:59:48.435047"
    },
    {
      "arxiv_id": "2411.00737v1",
      "title": "MolCap-Arena: A Comprehensive Captioning Benchmark on Language-Enhanced Molecular Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Carl Edwards",
        "Ziqing Lu",
        "Ehsan Hajiramezanali",
        "Tommaso Biancalani",
        "Heng Ji",
        "Gabriele Scalia"
      ],
      "abstract": "Bridging biomolecular modeling with natural language information,\nparticularly through large language models (LLMs), has recently emerged as a\npromising interdisciplinary research area. LLMs, having been trained on large\ncorpora of scientific documents, demonstrate significant potential in\nunderstanding and reasoning about biomolecules by providing enriched contextual\nand domain knowledge. However, the extent to which LLM-driven insights can\nimprove performance on complex predictive tasks (e.g., toxicity) remains\nunclear. Further, the extent to which relevant knowledge can be extracted from\nLLMs also remains unknown. In this study, we present Molecule Caption Arena:\nthe first comprehensive benchmark of LLM-augmented molecular property\nprediction. We evaluate over twenty LLMs, including both general-purpose and\ndomain-specific molecule captioners, across diverse prediction tasks. To this\ngoal, we introduce a novel, battle-based rating system. Our findings confirm\nthe ability of LLM-extracted knowledge to enhance state-of-the-art molecular\nrepresentations, with notable model-, prompt-, and dataset-specific variations.\nCode, resources, and data are available at github.com/Genentech/molcap-arena.",
      "tldr_zh": "本研究提出MolCap-Arena，这是首个全面基准，用于评估LLMs（大型语言模型）在语言增强分子属性预测中的作用，旨在桥接生物分子建模与自然语言信息。研究评估了20多个通用和领域特定LLMs在多样预测任务（如毒性预测）上的性能，并引入了一个创新的基于战斗的评分系统，以量化LLM提取知识的效果。结果显示，LLM驱动的知识能显著提升分子表示的预测准确性，但存在模型、提示和数据集的特定差异；相关代码和资源已在GitHub上开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00737v1",
      "published_date": "2024-11-01 17:03:16 UTC",
      "updated_date": "2024-11-01 17:03:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:59:58.960788"
    },
    {
      "arxiv_id": "2411.00728v1",
      "title": "Multi-Agent Deep Q-Network with Layer-based Communication Channel for Autonomous Internal Logistics Vehicle Scheduling in Smart Manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Feizabadi",
        "Arman Hosseini",
        "Zakaria Yahouni"
      ],
      "abstract": "In smart manufacturing, scheduling autonomous internal logistic vehicles is\ncrucial for optimizing operational efficiency. This paper proposes a\nmulti-agent deep Q-network (MADQN) with a layer-based communication channel\n(LBCC) to address this challenge. The main goals are to minimize total job\ntardiness, reduce the number of tardy jobs, and lower vehicle energy\nconsumption. The method is evaluated against nine well-known scheduling\nheuristics, demonstrating its effectiveness in handling dynamic job shop\nbehaviors like job arrivals and workstation unavailabilities. The approach also\nproves scalable, maintaining performance across different layouts and larger\nproblem instances, highlighting the robustness and adaptability of MADQN with\nLBCC in smart manufacturing.",
      "tldr_zh": "本研究提出了一种基于多智能体深度Q网络(Multi-Agent Deep Q-Network, MADQN)并结合层级通信通道(Layer-based Communication Channel, LBCC)的框架，用于智能制造中自主内部物流车辆的调度。方法的主要目标是最小化总作业延误、减少延误作业数量以及降低车辆能耗，以优化运营效率。该框架在动态作业车间环境中（如作业到达和工作站不可用）表现出色，与九种知名调度启发式方法相比，显示了更高的有效性；此外，它还证明了良好的可扩展性，在不同布局和更大问题实例中保持稳定性能。总的来说，此方法增强了智能制造系统的鲁棒性和适应性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted for the 5th IFAC/INSTICC INTERNATIONAL CONFERENCE ON\n  INNOVATIVE INTELLIGENT INDUSTRIAL PRODUCTION AND LOGISTICS",
      "pdf_url": "http://arxiv.org/pdf/2411.00728v1",
      "published_date": "2024-11-01 16:40:12 UTC",
      "updated_date": "2024-11-01 16:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:00:12.225224"
    },
    {
      "arxiv_id": "2411.00727v2",
      "title": "SPRING Lab IITM's submission to Low Resource Indic Language Translation Shared Task",
      "title_zh": "SPRING Lab IITM 针对低资源印度语系",
      "authors": [
        "Hamees Sayed",
        "Advait Joglekar",
        "Srinivasan Umesh"
      ],
      "abstract": "We develop a robust translation model for four low-resource Indic languages:\nKhasi, Mizo, Manipuri, and Assamese. Our approach includes a comprehensive\npipeline from data collection and preprocessing to training and evaluation,\nleveraging data from WMT task datasets, BPCC, PMIndia, and OpenLanguageData. To\naddress the scarcity of bilingual data, we use back-translation techniques on\nmonolingual datasets for Mizo and Khasi, significantly expanding our training\ncorpus. We fine-tune the pre-trained NLLB 3.3B model for Assamese, Mizo, and\nManipuri, achieving improved performance over the baseline. For Khasi, which is\nnot supported by the NLLB model, we introduce special tokens and train the\nmodel on our Khasi corpus. Our training involves masked language modelling,\nfollowed by fine-tuning for English-to-Indic and Indic-to-English translations.",
      "tldr_zh": "该研究由 SPRING Lab IITM 提交，针对低资源 Indic 语言翻译任务，开发了适用于 Khasi、Mizo、Manipuri 和 Assamese 的鲁棒翻译模型。研究团队构建了从数据收集（利用 WMT、BPCC、PMIndia 和 OpenLanguageData 数据集）到预处理、训练和评估的完整管道，并通过 back-translation 技术扩展 Mizo 和 Khasi 的单语数据，以缓解双语数据稀缺问题。针对 Assamese、Mizo 和 Manipuri，他们微调了预训练的 NLLB 3.3B 模型，而对于不支持的 Khasi，则引入特殊 tokens 并进行训练，涉及 masked language modelling 和后续的英-Indic 与 Indic-英翻译微调。结果显示，该模型在这些语言上的性能比基线模型显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in WMT 2024. Low-Resource Indic Language Translation Shared\n  Task",
      "pdf_url": "http://arxiv.org/pdf/2411.00727v2",
      "published_date": "2024-11-01 16:39:03 UTC",
      "updated_date": "2024-11-11 06:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:00:24.733212"
    },
    {
      "arxiv_id": "2411.00726v1",
      "title": "Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Xiao",
        "Junlin Hou",
        "Ruiwei Zhao",
        "Rui Feng",
        "Haidong Zou",
        "Lina Lu",
        "Yi Xu",
        "Juzhao Zhang"
      ],
      "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
      "tldr_zh": "这篇论文提出了一种新型多模态深度学习框架，用于糖尿病视网膜病变 (DR) 分级，首次融合彩色眼底摄影 (CFP) 和红外线眼底摄影 (IFP) 的互补信息，以提高诊断准确性。核心方法是 Cross-Fundus Transformer (CFT)，一个双流架构，利用 ViT-based 特征并引入 Cross-Fundus Attention (CFA) 模块来捕捉 CFP 和 IFP 图像之间的对应关系。同时，采用单模态和多模态监督策略来优化整体性能。在包含 1,713 对多模态眼底图像的临床数据集上，实验结果证明了该方法的优越性，代码将公开以供进一步应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00726v1",
      "published_date": "2024-11-01 16:38:49 UTC",
      "updated_date": "2024-11-01 16:38:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:00:36.852292"
    },
    {
      "arxiv_id": "2411.00715v2",
      "title": "B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable",
      "title_zh": "翻译失败",
      "authors": [
        "Shreyash Arya",
        "Sukrut Rao",
        "Moritz Böhle",
        "Bernt Schiele"
      ],
      "abstract": "B-cos Networks have been shown to be effective for obtaining highly human\ninterpretable explanations of model decisions by architecturally enforcing\nstronger alignment between inputs and weight. B-cos variants of convolutional\nnetworks (CNNs) and vision transformers (ViTs), which primarily replace linear\nlayers with B-cos transformations, perform competitively to their respective\nstandard variants while also yielding explanations that are faithful by design.\nHowever, it has so far been necessary to train these models from scratch, which\nis increasingly infeasible in the era of large, pre-trained foundation models.\nIn this work, inspired by the architectural similarities in standard DNNs and\nB-cos networks, we propose 'B-cosification', a novel approach to transform\nexisting pre-trained models to become inherently interpretable. We perform a\nthorough study of design choices to perform this conversion, both for\nconvolutional neural networks and vision transformers. We find that\nB-cosification can yield models that are on par with B-cos models trained from\nscratch in terms of interpretability, while often outperforming them in terms\nof classification performance at a fraction of the training cost. Subsequently,\nwe apply B-cosification to a pretrained CLIP model, and show that, even with\nlimited data and compute cost, we obtain a B-cosified version that is highly\ninterpretable and competitive on zero shot performance across a variety of\ndatasets. We release our code and pre-trained model weights at\nhttps://github.com/shrebox/B-cosification.",
      "tldr_zh": "该研究提出了一种名为 B-cosification 的新方法，用于将现有预训练深度神经网络 (DNNs) 转化为固有可解释的模型，旨在解决传统 B-cos Networks 需要从零训练的局限性。方法通过替换线性层（如在 CNNs 和 ViTs 中）并优化设计选择，实现输入与权重的更强对齐，从而提升模型解释性，同时保持或提升分类性能。实验结果显示，B-cosification 模型在可解释性上与从零训练的 B-cos 模型相当，甚至在性能上优于后者，且训练成本显著降低。最终，该方法应用于预训练 CLIP 模型，实现了高可解释性和零样本性能，并在多种数据集上表现出竞争力，同时开源了代码和模型权重。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 9 figures, 12 tables, Neural Information Processing Systems\n  (NeurIPS) 2024; added references, corrected typos",
      "pdf_url": "http://arxiv.org/pdf/2411.00715v2",
      "published_date": "2024-11-01 16:28:11 UTC",
      "updated_date": "2025-01-24 21:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:00:49.159576"
    },
    {
      "arxiv_id": "2411.02432v1",
      "title": "Can LLMs make trade-offs involving stipulated pain and pleasure states?",
      "title_zh": "大型语言模型能否进行涉及规定痛苦和愉悦状态的权衡？",
      "authors": [
        "Geoff Keeling",
        "Winnie Street",
        "Martyna Stachaczyk",
        "Daria Zakharova",
        "Iulia M. Comsa",
        "Anastasiya Sakovych",
        "Isabella Logothetis",
        "Zejia Zhang",
        "Blaise Agüera y Arcas",
        "Jonathan Birch"
      ],
      "abstract": "Pleasure and pain play an important role in human decision making by\nproviding a common currency for resolving motivational conflicts. While Large\nLanguage Models (LLMs) can generate detailed descriptions of pleasure and pain\nexperiences, it is an open question whether LLMs can recreate the motivational\nforce of pleasure and pain in choice scenarios - a question which may bear on\ndebates about LLM sentience, understood as the capacity for valenced\nexperiential states. We probed this question using a simple game in which the\nstated goal is to maximise points, but where either the points-maximising\noption is said to incur a pain penalty or a non-points-maximising option is\nsaid to incur a pleasure reward, providing incentives to deviate from\npoints-maximising behaviour. Varying the intensity of the pain penalties and\npleasure rewards, we found that Claude 3.5 Sonnet, Command R+, GPT-4o, and\nGPT-4o mini each demonstrated at least one trade-off in which the majority of\nresponses switched from points-maximisation to pain-minimisation or\npleasure-maximisation after a critical threshold of stipulated pain or pleasure\nintensity is reached. LLaMa 3.1-405b demonstrated some graded sensitivity to\nstipulated pleasure rewards and pain penalties. Gemini 1.5 Pro and PaLM 2\nprioritised pain-avoidance over points-maximisation regardless of intensity,\nwhile tending to prioritise points over pleasure regardless of intensity. We\ndiscuss the implications of these findings for debates about the possibility of\nLLM sentience.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能在涉及规定快乐和痛苦状态的决策中进行权衡，这与 LLMs 的 sentience（知觉能力）辩论密切相关。研究设计了一个简单游戏，让 LLMs 在最大化分数的同时面对痛苦惩罚或快乐奖励，测试其动机冲突响应。结果显示，Claude 3.5 Sonnet、GPT-4o 等模型在痛苦或快乐强度达到阈值时会偏向痛苦最小化或快乐最大化，而 Gemini 1.5 Pro 则优先避免痛苦但忽略快乐。这些发现为评估 LLMs 是否具备类似情感状态提供了重要证据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02432v1",
      "published_date": "2024-11-01 16:22:13 UTC",
      "updated_date": "2024-11-01 16:22:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:01:02.613958"
    },
    {
      "arxiv_id": "2411.00707v2",
      "title": "Learning in Markov Games with Adaptive Adversaries: Policy Regret, Fundamental Barriers, and Efficient Algorithms",
      "title_zh": "马尔可夫博弈中与自适应对手的学习：策略遗憾、根本障碍和高效算法",
      "authors": [
        "Thanh Nguyen-Tang",
        "Raman Arora"
      ],
      "abstract": "We study learning in a dynamically evolving environment modeled as a Markov\ngame between a learner and a strategic opponent that can adapt to the learner's\nstrategies. While most existing works in Markov games focus on external regret\nas the learning objective, external regret becomes inadequate when the\nadversaries are adaptive. In this work, we focus on \\emph{policy regret} -- a\ncounterfactual notion that aims to compete with the return that would have been\nattained if the learner had followed the best fixed sequence of policy, in\nhindsight. We show that if the opponent has unbounded memory or if it is\nnon-stationary, then sample-efficient learning is not possible. For\nmemory-bounded and stationary, we show that learning is still statistically\nhard if the set of feasible strategies for the learner is exponentially large.\nTo guarantee learnability, we introduce a new notion of \\emph{consistent}\nadaptive adversaries, wherein, the adversary responds similarly to similar\nstrategies of the learner. We provide algorithms that achieve $\\sqrt{T}$ policy\nregret against memory-bounded, stationary, and consistent adversaries.",
      "tldr_zh": "该研究探讨了马尔可夫游戏(Markov games)中学习者与适应性对手的互动问题，重点从外部遗憾转向策略遗憾(policy regret)，旨在与事后最佳固定策略序列竞争。研究发现，如果对手具有无限记忆或非平稳，则样本高效学习不可能；即使对手记忆有限且平稳，如果学习者策略集指数级庞大，学习也统计上困难。为确保可学习性，引入了“consistent adaptive adversaries”新概念，即对手对类似策略做出类似响应。作者提出了高效算法，能够在记忆有限、平稳且一致的对手环境下实现√T 策略遗憾。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS'24; fix typos",
      "pdf_url": "http://arxiv.org/pdf/2411.00707v2",
      "published_date": "2024-11-01 16:17:27 UTC",
      "updated_date": "2024-12-09 23:57:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:01:11.059151"
    },
    {
      "arxiv_id": "2411.00929v1",
      "title": "Text2Freq: Learning Series Patterns from Text via Frequency Domain",
      "title_zh": "Text2",
      "authors": [
        "Ming-Chih Lo",
        "Ching Chang",
        "Wen-Chih Peng"
      ],
      "abstract": "Traditional time series forecasting models mainly rely on historical numeric\nvalues to predict future outcomes.While these models have shown promising\nresults, they often overlook the rich information available in other\nmodalities, such as textual descriptions of special events, which can provide\ncrucial insights into future dynamics.However, research that jointly\nincorporates text in time series forecasting remains relatively underexplored\ncompared to other cross-modality work. Additionally, the modality gap between\ntime series data and textual information poses a challenge for multimodal\nlearning. To address this task, we propose Text2Freq, a cross-modality model\nthat integrates text and time series data via the frequency domain.\nSpecifically, our approach aligns textual information to the low-frequency\ncomponents of time series data, establishing more effective and interpretable\nalignments between these two modalities. Our experiments on paired datasets of\nreal-world stock prices and synthetic texts show that Text2Freq achieves\nstate-of-the-art performance, with its adaptable architecture encouraging\nfuture research in this field.",
      "tldr_zh": "该论文指出，传统时间序列预测模型仅依赖历史数值，而忽略了文本描述等模态信息，导致对未来动态的洞见不足，并面临模态差距挑战。为解决此问题，研究提出 Text2Freq 模型，通过频率域将文本信息与时间序列的低频组件对齐，实现更有效和可解释的跨模态整合。实验结果显示，Text2Freq 在真实股票价格和合成文本数据集上达到了最先进性能，其灵活架构有望推动该领域的未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures, and be accepted by NeurIPS 2024 Workshop: Time\n  Series in the Age of Large Models",
      "pdf_url": "http://arxiv.org/pdf/2411.00929v1",
      "published_date": "2024-11-01 16:11:02 UTC",
      "updated_date": "2024-11-01 16:11:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:01:22.680545"
    },
    {
      "arxiv_id": "2411.00927v2",
      "title": "ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents",
      "title_zh": "ReSpAct：协调推理、说话和行动以构建基于",
      "authors": [
        "Vardhan Dongre",
        "Xiaocheng Yang",
        "Emre Can Acikgoz",
        "Suvodip Dey",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Large language model (LLM)-based agents are increasingly employed to interact\nwith external environments (e.g., games, APIs, world models) to solve\nuser-provided tasks. However, current frameworks often lack the ability to\ncollaborate effectively with users in fully conversational settings.\nConversations are essential for aligning on task details, achieving\nuser-defined goals, and satisfying preferences. While existing agents address\nambiguity through clarification questions, they underutilize the broader\npotential of an LLM's conversational capabilities. In this work, we introduce\nReSpAct, an LLM-based agent designed to seamlessly integrate reasoning,\ndecision-making, and dynamic dialogue for task-solving. Expanding on\nreasoning-first approaches like ReAct, ReSpAct employs active, free-flowing\ndialogues to interpret instructions, clarify goals, provide status updates,\nresolve subtask failures, and refine plans based on user inputs without any\nexplicit dialogue schema. By alternating between task-solving actions and\ninteractive conversations, ReSpAct demonstrates improved performance across\ndiverse environments. We evaluate ReSpAct in user-interactive settings,\nincluding task-oriented dialogue systems (MultiWOZ) and decision-making tasks\n(ALFWorld, WebShop). ReSpAct outperforms ReAct with absolute success rate\nimprovements of 6% and 4% in ALFWorld and WebShop, respectively, and achieves a\n5.5% gain in Inform and a 3% gain in Success scores in MultiWOZ. These results\nhighlight the value of integrating dynamic user-agent collaboration for more\neffective task resolution.",
      "tldr_zh": "本论文提出 ReSpAct，一种基于 Large Language Model (LLM) 的对话 AI 代理框架，旨在协调推理、决策和动态对话，以提升代理在任务解决中的用户协作能力。相比于 ReAct，ReSpAct 通过自由流动的对话来解释指令、澄清目标、提供状态更新、解决子任务失败并基于用户输入优化计划，而无需显式对话模式。实验结果显示，在 ALFWorld 和 WebShop 中，ReSpAct 的成功率分别提高了 6% 和 4%；在 MultiWOZ 中，Inform 分数提升 5.5%，Success 分数提升 3%，突显了动态用户-代理协作在任务解析中的价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 10 Figures, 25 Tables",
      "pdf_url": "http://arxiv.org/pdf/2411.00927v2",
      "published_date": "2024-11-01 15:57:45 UTC",
      "updated_date": "2025-04-19 15:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:01:35.857707"
    },
    {
      "arxiv_id": "2411.00699v1",
      "title": "Algorithmic Transparency in Forecasting Support Systems",
      "title_zh": "算法透明度在预测支持系统中的应用",
      "authors": [
        "Leif Feddersen"
      ],
      "abstract": "Most organizations adjust their statistical forecasts (e.g. on sales)\nmanually. Forecasting Support Systems (FSS) enable the related process of\nautomated forecast generation and manual adjustments. As the FSS user interface\nconnects user and statistical algorithm, it is an obvious lever for\nfacilitating beneficial adjustments whilst discouraging harmful adjustments.\nThis paper reviews and organizes the literature on judgemental forecasting,\nforecast adjustments, and FSS design. I argue that algorithmic transparency may\nbe a key factor towards better, integrative forecasting and test this assertion\nwith three FSS designs that vary in their degrees of transparency based on time\nseries decomposition. I find transparency to reduce the variance and amount of\nharmful forecast adjustments. Letting users adjust the algorithm's transparent\ncomponents themselves, however, leads to widely varied and overall most\ndetrimental adjustments. Responses indicate a risk of overwhelming users with\nalgorithmic transparency without adequate training. Accordingly, self-reported\nsatisfaction is highest with a non-transparent FSS.",
      "tldr_zh": "这篇论文探讨了 Algorithmic Transparency 在 Forecasting Support Systems (FSS) 中的作用，旨在优化统计预测（如销售预测）的手动调整过程。作者回顾了判断性预测、预测调整和 FSS 设计的相关文献，并通过三种基于时间序列分解的不同透明度 FSS 设计进行实验。结果表明，Algorithmic Transparency 可减少有害调整的方差和数量，但允许用户直接调整透明组件会导致调整变化更大且整体更负面；此外，用户反馈显示过度透明度可能在缺乏培训时令用户不知所措，因此非透明 FSS 的自我报告满意度最高。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00699v1",
      "published_date": "2024-11-01 15:55:32 UTC",
      "updated_date": "2024-11-01 15:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:01:48.305815"
    },
    {
      "arxiv_id": "2411.00696v1",
      "title": "CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis",
      "title_zh": "CTPD：跨模态时间模式发现，用于增强多模态电子健康记录分析",
      "authors": [
        "Fuying Wang",
        "Feng Wu",
        "Yihan Tang",
        "Lequan Yu"
      ],
      "abstract": "Integrating multimodal Electronic Health Records (EHR) data, such as\nnumerical time series and free-text clinical reports, has great potential in\npredicting clinical outcomes. However, prior work has primarily focused on\ncapturing temporal interactions within individual samples and fusing multimodal\ninformation, overlooking critical temporal patterns across patients. These\npatterns, such as trends in vital signs like abnormal heart rate or blood\npressure, can indicate deteriorating health or an impending critical event.\nSimilarly, clinical notes often contain textual descriptions that reflect these\npatterns. Identifying corresponding temporal patterns across different\nmodalities is crucial for improving the accuracy of clinical outcome\npredictions, yet it remains a challenging task. To address this gap, we\nintroduce a Cross-Modal Temporal Pattern Discovery (CTPD) framework, designed\nto efficiently extract meaningful cross-modal temporal patterns from multimodal\nEHR data. Our approach introduces shared initial temporal pattern\nrepresentations which are refined using slot attention to generate temporal\nsemantic embeddings. To ensure rich cross-modal temporal semantics in the\nlearned patterns, we introduce a contrastive-based TPNCE loss for cross-modal\nalignment, along with two reconstruction losses to retain core information of\neach modality. Evaluations on two clinically critical tasks, 48-hour\nin-hospital mortality and 24-hour phenotype classification, using the MIMIC-III\ndatabase demonstrate the superiority of our method over existing approaches.",
      "tldr_zh": "这篇论文提出 CTPD 框架，用于从多模态 Electronic Health Records (EHR) 数据中发现跨模态时间模式，从而提升临床结果预测的准确性。框架通过共享初始时间模式表示和 slot attention 生成时间语义嵌入，并引入对比学习损失（TPNCE）进行跨模态对齐，以及两个重建损失来保留每个模态的核心信息。实验在 MIMIC-III 数据库上评估了 48 小时院内死亡率预测和 24 小时表型分类任务，结果显示 CTPD 优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2411.00696v1",
      "published_date": "2024-11-01 15:54:07 UTC",
      "updated_date": "2024-11-01 15:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:02:00.080766"
    },
    {
      "arxiv_id": "2411.00686v1",
      "title": "Latent Paraphrasing: Perturbation on Layers Improves Knowledge Injection in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Minki Kang",
        "Sung Ju Hwang",
        "Gibbeum Lee",
        "Jaewoong Cho"
      ],
      "abstract": "As Large Language Models (LLMs) are increasingly deployed in specialized\ndomains with continuously evolving knowledge, the need for timely and precise\nknowledge injection has become essential. Fine-tuning with paraphrased data is\na common approach to enhance knowledge injection, yet it faces two significant\nchallenges: high computational costs due to repetitive external model usage and\nlimited sample diversity. To this end, we introduce LaPael, a latent-level\nparaphrasing method that applies input-dependent noise to early LLM layers.\nThis approach enables diverse and semantically consistent augmentations\ndirectly within the model. Furthermore, it eliminates the recurring costs of\nparaphrase generation for each knowledge update. Our extensive experiments on\nquestion-answering benchmarks demonstrate that LaPael improves knowledge\ninjection over standard fine-tuning and existing noise-based approaches.\nAdditionally, combining LaPael with data-level paraphrasing further enhances\nperformance.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)注入专业领域知识的问题，提出了一种潜在层级改写方法LaPael，通过在LLMs早期层添加输入相关的噪声，实现多样且语义一致的数据增强，从而避免了传统fine-tuning中外部模型的重复计算成本。LaPael不仅提高了样本多样性，还在问答基准测试中超过了标准fine-tuning和现有噪声方法。进一步，将LaPael与数据级改写结合，能进一步提升知识注入性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00686v1",
      "published_date": "2024-11-01 15:47:05 UTC",
      "updated_date": "2024-11-01 15:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:02:12.075895"
    },
    {
      "arxiv_id": "2411.00683v1",
      "title": "TaxaBind: A Unified Embedding Space for Ecological Applications",
      "title_zh": "TaxaBind：一个统一的嵌入空间，用于生态应用",
      "authors": [
        "Srikumar Sastry",
        "Subash Khanal",
        "Aayush Dhakal",
        "Adeel Ahmad",
        "Nathan Jacobs"
      ],
      "abstract": "We present TaxaBind, a unified embedding space for characterizing any species\nof interest. TaxaBind is a multimodal embedding space across six modalities:\nground-level images of species, geographic location, satellite image, text,\naudio, and environmental features, useful for solving ecological problems. To\nlearn this joint embedding space, we leverage ground-level images of species as\na binding modality. We propose multimodal patching, a technique for effectively\ndistilling the knowledge from various modalities into the binding modality. We\nconstruct two large datasets for pretraining: iSatNat with species images and\nsatellite images, and iSoundNat with species images and audio. Additionally, we\nintroduce TaxaBench-8k, a diverse multimodal dataset with six paired modalities\nfor evaluating deep learning models on ecological tasks. Experiments with\nTaxaBind demonstrate its strong zero-shot and emergent capabilities on a range\nof tasks including species classification, cross-model retrieval, and audio\nclassification. The datasets and models are made available at\nhttps://github.com/mvrl/TaxaBind.",
      "tldr_zh": "我们提出了 TaxaBind，一种统一的嵌入空间，用于表征各种物种并应用于生态问题，支持六种模态：地面级物种图像、地理位置、卫星图像、文本、音频和环境特征。论文引入多模态 patching 技术，以地面级物种图像作为绑定模态（binding modality），有效将其他模态的知识提炼到联合嵌入空间中。研究构建了两个预训练数据集 iSatNat（物种图像和卫星图像）和 iSoundNat（物种图像和音频），以及评估数据集 TaxaBench-8k，涵盖六种配对模态。实验结果表明，TaxaBind 在物种分类、跨模态检索和音频分类等任务上展现出强大的零样本和新兴能力。数据集和模型已开源于 https://github.com/mvrl/TaxaBind。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.00683v1",
      "published_date": "2024-11-01 15:41:30 UTC",
      "updated_date": "2024-11-01 15:41:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:02:25.416157"
    },
    {
      "arxiv_id": "2411.00681v1",
      "title": "AI-based traffic analysis in digital twin networks",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Al-Shareeda",
        "Khayal Huseynov",
        "Lal Verda Cakir",
        "Craig Thomson",
        "Mehmet Ozdem",
        "Berk Canberk"
      ],
      "abstract": "In today's networked world, Digital Twin Networks (DTNs) are revolutionizing\nhow we understand and optimize physical networks. These networks, also known as\n'Digital Twin Networks (DTNs)' or 'Networks Digital Twins (NDTs),' encompass\nmany physical networks, from cellular and wireless to optical and satellite.\nThey leverage computational power and AI capabilities to provide virtual\nrepresentations, leading to highly refined recommendations for real-world\nnetwork challenges. Within DTNs, tasks include network performance enhancement,\nlatency optimization, energy efficiency, and more. To achieve these goals, DTNs\nutilize AI tools such as Machine Learning (ML), Deep Learning (DL),\nReinforcement Learning (RL), Federated Learning (FL), and graph-based\napproaches. However, data quality, scalability, interpretability, and security\nchallenges necessitate strategies prioritizing transparency, fairness, privacy,\nand accountability. This chapter delves into the world of AI-driven traffic\nanalysis within DTNs. It explores DTNs' development efforts, tasks, AI models,\nand challenges while offering insights into how AI can enhance these dynamic\nnetworks. Through this journey, readers will gain a deeper understanding of the\npivotal role AI plays in the ever-evolving landscape of networked systems.",
      "tldr_zh": "本研究探讨了AI在数字孪生网络(Digital Twin Networks, DTNs)中的流量分析应用，DTNs通过虚拟表示来优化物理网络，如蜂窝、无线、光学和卫星网络。研究利用Machine Learning (ML)、Deep Learning (DL)、Reinforcement Learning (RL)、Federated Learning (FL)以及图-based方法，来提升网络性能、降低延迟、提高能源效率等任务。面对数据质量、可扩展性、可解释性和安全性的挑战，该章节强调了优先考虑透明度、公平性、隐私和责任的策略。总体而言，这为读者提供了对AI在动态网络系统中的关键作用的深入见解。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.NI",
      "comment": "Chapter 4: Digital Twins for 6G: Fundamental theory, technology and\n  applications; pp. 83-132",
      "pdf_url": "http://arxiv.org/pdf/2411.00681v1",
      "published_date": "2024-11-01 15:41:23 UTC",
      "updated_date": "2024-11-01 15:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:02:35.186761"
    },
    {
      "arxiv_id": "2411.00666v1",
      "title": "Beyond the Boundaries of Proximal Policy Optimization",
      "title_zh": "超越 Proximal Policy Optimization 的界限",
      "authors": [
        "Charlie B. Tan",
        "Edan Toledo",
        "Benjamin Ellis",
        "Jakob N. Foerster",
        "Ferenc Huszár"
      ],
      "abstract": "Proximal policy optimization (PPO) is a widely-used algorithm for on-policy\nreinforcement learning. This work offers an alternative perspective of PPO, in\nwhich it is decomposed into the inner-loop estimation of update vectors, and\nthe outer-loop application of updates using gradient ascent with unity learning\nrate. Using this insight we propose outer proximal policy optimization\n(outer-PPO); a framework wherein these update vectors are applied using an\narbitrary gradient-based optimizer. The decoupling of update estimation and\nupdate application enabled by outer-PPO highlights several implicit design\nchoices in PPO that we challenge through empirical investigation. In particular\nwe consider non-unity learning rates and momentum applied to the outer loop,\nand a momentum-bias applied to the inner estimation loop. Methods are evaluated\nagainst an aggressively tuned PPO baseline on Brax, Jumanji and MinAtar\nenvironments; non-unity learning rates and momentum both achieve statistically\nsignificant improvement on Brax and Jumanji, given the same hyperparameter\ntuning budget.",
      "tldr_zh": "这篇论文从一个新视角审视了强化学习算法 Proximal Policy Optimization (PPO)，将其分解为内循环更新向量估计和外循环更新应用的过程。作者提出了 outer-PPO 框架，使用任意基于梯度的优化器来应用更新向量，从而挑战 PPO 的隐式设计选择，如非统一学习率和动量。实验结果显示，在 Brax、Jumanji 和 MinAtar 环境中，与优化调整的 PPO 基线相比，非统一学习率和动量在 Brax 和 Jumanji 上实现了统计显著的性能改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00666v1",
      "published_date": "2024-11-01 15:29:10 UTC",
      "updated_date": "2024-11-01 15:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:02:48.610177"
    },
    {
      "arxiv_id": "2411.00662v1",
      "title": "MoNTA: Accelerating Mixture-of-Experts Training with Network-Traffc-Aware Parallel Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jingming Guo",
        "Yan Liu",
        "Yu Meng",
        "Zhiwei Tao",
        "Banglan Liu",
        "Gang Chen",
        "Xiang Li"
      ],
      "abstract": "The Mixture of Experts (MoE) is an advanced model architecture in the\nindustry that combines multiple specialized expert models from various domains\ninto a single supermodel. This approach enables the model to scale without\nsignificantly increasing the computational costs of training and inference,\nwhile maximizing model performance. However, current distributed training\nframeworks do not consider the ultimate optimization of communication,\nespecially for large base models. This paper proposes a network-traffic-aware\nparallel optimization method that selects the optimal parallel strategy based\non the communication volume, and the training cluster's inter-node and\nintra-node network topologies. Compared to the DeepSpeed, MoNTA achieves an 8x\nincrease in AllToAll communication performance under 8-card tensor parallelism.\nCompared to the baseline, training a 2x70B model using 16 A800 cards, with an\n8K sequence, results in a 13% overall latency performance improvement. Project\nPage: https://github.com/EnflameTechnology/DeepSpeed.",
      "tldr_zh": "该论文提出 MoNTA，一种网络流量感知的并行优化方法，用于加速 Mixture of Experts (MoE) 模型的训练，通过分析通信量和集群的网络拓扑（如 inter-node 和 intra-node）来选择最佳并行策略。相比传统框架，MoNTA 在 8 卡张量并行下，使 AllToAll 通信性能提升 8 倍。实验结果显示，在使用 16 A800 卡训练 2x70B 模型时，MoNTA 比基线方案整体延迟性能提高了 13%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00662v1",
      "published_date": "2024-11-01 15:27:20 UTC",
      "updated_date": "2024-11-01 15:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:02:59.684156"
    },
    {
      "arxiv_id": "2411.00660v2",
      "title": "Physics in Next-token Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun An",
        "Yiliang Song",
        "Xuelong Li"
      ],
      "abstract": "We discovered the underlying physics in Next-token Prediction (NTP). We\nidentified the law of information conservation within NTP and proposed the\nFirst Law of Information Capacity (IC-1), demonstrating that the essence of\nintelligence emergence in auto-regressive models is fundamentally a process of\ninformation transfer. We also introduced Landauer's Principle into NTP,\nformulating the Second Law of Information Capacity (IC-2), which establishes\nthe relationship between auto-regressive model training and energy consumption.\nAdditionally, we presented several corollaries, which hold practical\nsignificance for production practices. Finally, we demonstrate the consistency\nbetween the Law of Information Capacity and the Scaling Law for Neural Language\nModels, the Knowledge Capacity Scaling Laws, and the Scaling Laws for\nPrecision.",
      "tldr_zh": "本研究揭示了 Next-token Prediction (NTP) 中的底层物理学，识别出信息守恒定律并提出 First Law of Information Capacity (IC-1)，强调智能在自回归模型中的涌现本质上是信息转移过程。作者还引入 Landauer's Principle，制定 Second Law of Information Capacity (IC-2)，建立了模型训练与能量消耗的关系，并提供了几个具有实际生产意义的推论。最后，该研究证明了 Information Capacity 定律与 Scaling Law for Neural Language Models、Knowledge Capacity Scaling Laws 和 Scaling Laws for Precision 的一致性，为理解模型智能和效率提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Second Submit",
      "pdf_url": "http://arxiv.org/pdf/2411.00660v2",
      "published_date": "2024-11-01 15:26:15 UTC",
      "updated_date": "2024-11-16 06:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:03:11.182297"
    },
    {
      "arxiv_id": "2411.00631v1",
      "title": "Generative AI and Agency in Education: A Critical Scoping Review and Thematic Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Jasper Roe",
        "Mike Perkins"
      ],
      "abstract": "This scoping review examines the relationship between Generative AI (GenAI)\nand agency in education, analyzing the literature available through the lens of\nCritical Digital Pedagogy. Following PRISMA-ScR guidelines, we collected 10\nstudies from academic databases focusing on both learner and teacher agency in\nGenAI-enabled environments. We conducted an AI-supported hybrid thematic\nanalysis that revealed three key themes: Control in Digital Spaces, Variable\nEngagement and Access, and Changing Notions of Agency.\n  The findings suggest that while GenAI may enhance learner agency through\npersonalization and support, it also risks exacerbating educational\ninequalities and diminishing learner autonomy in certain contexts. This review\nhighlights gaps in the current research on GenAI's impact on agency. These\nfindings have implications for educational policy and practice, suggesting the\nneed for frameworks that promote equitable access while preserving learner\nagency in GenAI-enhanced educational environments.",
      "tldr_zh": "这篇论文通过Critical Digital Pedagogy的视角，对Generative AI (GenAI)和教育中agency的关系进行了关键范围审查（scoping review）。研究者遵循PRISMA-ScR指南，从学术数据库收集了10个相关研究，并采用AI支持的混合主题分析，揭示了三个主要主题：Control in Digital Spaces、Variable Engagement and Access，以及Changing Notions of Agency。发现显示，GenAI可能通过个性化支持增强学习者agency，但同时可能加剧教育不平等并削弱自主性。该审查突出了当前研究空白，并为教育政策和实践提供启示，呼吁制定框架以促进公平访问并保护agency。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00631v1",
      "published_date": "2024-11-01 14:40:31 UTC",
      "updated_date": "2024-11-01 14:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:03:25.132726"
    },
    {
      "arxiv_id": "2411.00630v1",
      "title": "STAA: Spatio-Temporal Attention Attribution for Real-Time Interpreting Transformer-based Video Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zerui Wang",
        "Yan Liu"
      ],
      "abstract": "Transformer-based models have achieved state-of-the-art performance in\nvarious computer vision tasks, including image and video analysis. However,\nTransformer's complex architecture and black-box nature pose challenges for\nexplainability, a crucial aspect for real-world applications and scientific\ninquiry. Current Explainable AI (XAI) methods can only provide one-dimensional\nfeature importance, either spatial or temporal explanation, with significant\ncomputational complexity. This paper introduces STAA (Spatio-Temporal Attention\nAttribution), an XAI method for interpreting video Transformer models. Differ\nfrom traditional methods that separately apply image XAI techniques for spatial\nfeatures or segment contribution analysis for temporal aspects, STAA offers\nboth spatial and temporal information simultaneously from attention values in\nTransformers. The study utilizes the Kinetics-400 dataset, a benchmark\ncollection of 400 human action classes used for action recognition research. We\nintroduce metrics to quantify explanations. We also apply optimization to\nenhance STAA's raw output. By implementing dynamic thresholding and attention\nfocusing mechanisms, we improve the signal-to-noise ratio in our explanations,\nresulting in more precise visualizations and better evaluation results. In\nterms of computational overhead, our method requires less than 3\\% of the\ncomputational resources of traditional XAI methods, making it suitable for\nreal-time video XAI analysis applications. STAA contributes to the growing\nfield of XAI by offering a method for researchers and practitioners to analyze\nTransformer models.",
      "tldr_zh": "本论文提出 STAA（Spatio-Temporal Attention Attribution），一种用于实时解释 Transformer-based 视频模型的 XAI（Explainable AI）方法，旨在解决传统方法仅提供空间或时间维度的特征重要性问题，并减少计算复杂性。STAA 通过从 Transformer 的 attention values 中同时提取空间和时间信息，提供更全面的解释，并在 Kinetics-400 数据集上引入量化指标进行评估。研究通过动态阈值和注意力聚焦机制优化输出，提高了信号噪声比和解释精确性。结果显示，STAA 的计算开销仅为传统 XAI 方法的 3% 以下，适合实时视频分析应用，并为 Transformer 模型的分析提供新工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00630v1",
      "published_date": "2024-11-01 14:40:07 UTC",
      "updated_date": "2024-11-01 14:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:03:36.791955"
    },
    {
      "arxiv_id": "2411.00622v1",
      "title": "Lingma SWE-GPT: An Open Development-Process-Centric Language Model for Automated Software Improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Yingwei Ma",
        "Rongyu Cao",
        "Yongchang Cao",
        "Yue Zhang",
        "Jue Chen",
        "Yibo Liu",
        "Yuchen Liu",
        "Binhua Li",
        "Fei Huang",
        "Yongbin Li"
      ],
      "abstract": "Recent advancements in LLM-based agents have led to significant progress in\nautomatic software engineering, particularly in software maintenance and\nevolution. Despite these encouraging advances, current research faces two major\nchallenges. First, SOTA performance primarily depends on closed-source models,\nwhich significantly limits the technology's accessibility, and potential for\ncustomization in diverse SE tasks. Second, these models are predominantly\ntrained on static code data, lacking a deep understanding of the dynamic\ninteractions, iterative problem-solving processes, and evolutionary\ncharacteristics inherent in software development. To address these challenges,\nour study adopts a software engineering perspective. We recognize that\nreal-world software maintenance and evolution processes encompass not only\nstatic code data but also developers' thought processes, utilization of\nexternal tools, and the interaction between different functional personnel.\nConsequently, we introduce the Lingma SWE-GPT series, comprising Lingma SWE-GPT\n7B and 72B. By learning from and simulating real-world code submission\nactivities, Lingma SWE-GPT systematically incorporates the dynamic interactions\nand iterative problem-solving inherent in software development process, thereby\nachieving a more comprehensive understanding of software improvement processes.\nWe conducted experimental evaluations using SWE-bench Verified benchmark. The\nresults demonstrate that Lingma SWE-GPT 72B successfully resolves 30.20% of the\nGitHub issues, marking a significant improvement in automatic issue resolution\n(22.76% relative improvement compared to Llama 3.1 405B), approaching the\nperformance of closed-source models (31.80\\% issues of GPT-4o resolved).\nNotably, Lingma SWE-GPT 7B resolves 18.20% of the issues, highlighting the\npotential for applying smaller models to ASE tasks.",
      "tldr_zh": "本研究提出 Lingma SWE-GPT 系列开放模型（包括 7B 和 72B 版本），旨在解决 LLM-based agents 在自动软件工程（ASE）中的挑战，特别是依赖闭源模型和缺乏对软件开发动态过程的理解。模型通过学习真实代码提交活动，模拟开发者的思考过程、外部工具使用以及人员互动，实现对软件维护和演化的全面理解。实验结果显示，在 SWE-bench Verified 基准测试中，Lingma SWE-GPT 72B 成功解决了 30.20% 的 GitHub issues，比 Llama 3.1 405B 提升 22.76%，接近 GPT-4o 的 31.80% 表现，而 7B 模型也解决了 18.20% 的问题，展示了小型模型在 ASE 任务中的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00622v1",
      "published_date": "2024-11-01 14:27:16 UTC",
      "updated_date": "2024-11-01 14:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:03:49.411787"
    },
    {
      "arxiv_id": "2411.08918v1",
      "title": "Wireless Federated Learning over UAV-enabled Integrated Sensing and Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Shaba Shaon",
        "Tien Nguyen",
        "Lina Mohjazi",
        "Aryan Kaushik",
        "Dinh C. Nguyen"
      ],
      "abstract": "This paper studies a new latency optimization problem in unmanned aerial\nvehicles (UAVs)-enabled federated learning (FL) with integrated sensing and\ncommunication. In this setup, distributed UAVs participate in model training\nusing sensed data and collaborate with a base station (BS) serving as FL\naggregator to build a global model. The objective is to minimize the FL system\nlatency over UAV networks by jointly optimizing UAVs' trajectory and resource\nallocation of both UAVs and the BS. The formulated optimization problem is\ntroublesome to solve due to its non-convexity. Hence, we develop a simple yet\nefficient iterative algorithm to find a high-quality approximate solution, by\nleveraging block coordinate descent and successive convex approximation\ntechniques. Simulation results demonstrate the effectiveness of our proposed\njoint optimization strategy under practical parameter settings, saving the\nsystem latency up to 68.54\\% compared to benchmark schemes.",
      "tldr_zh": "这篇论文研究了无人机（UAVs）支持的联邦学习（FL）系统中的延迟优化问题，结合了集成感知和通信技术，其中分布式 UAVs 使用感知数据与基站（BS）合作构建全局模型。作者通过联合优化 UAVs 的轨迹和资源分配，开发了一种基于块坐标下降和连续凸逼近的迭代算法来解决该非凸优化问题。模拟结果显示，该策略在实际参数设置下比基准方案减少系统延迟高达 68.54%，证明了其在无线 FL 网络中的有效性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.NI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Accepted to IEEE Conference on Standards for Communications and\n  Networking (CSCN), 6 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.08918v1",
      "published_date": "2024-11-01 14:25:24 UTC",
      "updated_date": "2024-11-01 14:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:04:00.930138"
    },
    {
      "arxiv_id": "2411.00612v1",
      "title": "How to Bridge Spatial and Temporal Heterogeneity in Link Prediction? A Contrastive Method",
      "title_zh": "如何桥接链接预测中的空间和时间异质性？一种对比方法",
      "authors": [
        "Yu Tai",
        "Xinglong Wu",
        "Hongwei Yang",
        "Hui He",
        "Duanjing Chen",
        "Yuanming Shao",
        "Weizhe Zhang"
      ],
      "abstract": "Temporal Heterogeneous Networks play a crucial role in capturing the dynamics\nand heterogeneity inherent in various real-world complex systems, rendering\nthem a noteworthy research avenue for link prediction. However, existing\nmethods fail to capture the fine-grained differential distribution patterns and\ntemporal dynamic characteristics, which we refer to as spatial heterogeneity\nand temporal heterogeneity. To overcome such limitations, we propose a novel\n\\textbf{C}ontrastive Learning-based \\textbf{L}ink \\textbf{P}rediction model,\n\\textbf{CLP}, which employs a multi-view hierarchical self-supervised\narchitecture to encode spatial and temporal heterogeneity. Specifically, aiming\nat spatial heterogeneity, we develop a spatial feature modeling layer to\ncapture the fine-grained topological distribution patterns from node- and\nedge-level representations, respectively. Furthermore, aiming at temporal\nheterogeneity, we devise a temporal information modeling layer to perceive the\nevolutionary dependencies of dynamic graph topologies from time-level\nrepresentations. Finally, we encode the spatial and temporal distribution\nheterogeneity from a contrastive learning perspective, enabling a comprehensive\nself-supervised hierarchical relation modeling for the link prediction task.\nExtensive experiments conducted on four real-world dynamic heterogeneous\nnetwork datasets verify that our \\mymodel consistently outperforms the\nstate-of-the-art models, demonstrating an average improvement of 10.10\\%,\n13.44\\% in terms of AUC and AP, respectively.",
      "tldr_zh": "该论文针对 Temporal Heterogeneous Networks 中的 spatial heterogeneity 和 temporal heterogeneity 问题，提出了一种基于 Contrastive Learning 的链接预测模型 CLP，以捕捉细粒度的拓扑分布模式和动态图演化依赖。具体地，CLP 采用多视图层次自监督架构，包括空间特征建模层（从节点和边级表示提取分布模式）和时间信息建模层（从时间级表示感知演化依赖），并通过对比学习整合这些异质性，实现全面的自监督关系建模。在四个真实世界动态异质网络数据集上的实验表明，CLP 比最先进模型平均提升 10.10% 在 AUC 和 13.44% 在 AP，验证了其有效性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00612v1",
      "published_date": "2024-11-01 14:20:53 UTC",
      "updated_date": "2024-11-01 14:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:04:14.181886"
    },
    {
      "arxiv_id": "2411.00920v1",
      "title": "Comparative Evaluation of Applicability Domain Definition Methods for Regression Models",
      "title_zh": "回归模型适用域定义方法的比较评估",
      "authors": [
        "Shakir Khurshid",
        "Bharath Kumar Loganathan",
        "Matthieu Duvinage"
      ],
      "abstract": "The applicability domain refers to the range of data for which the prediction\nof the predictive model is expected to be reliable and accurate and using a\nmodel outside its applicability domain can lead to incorrect results. The\nability to define the regions in data space where a predictive model can be\nsafely used is a necessary condition for having safer and more reliable\npredictions to assure the reliability of new predictions. However, defining the\napplicability domain of a model is a challenging problem, as there is no clear\nand universal definition or metric for it. This work aims to make the\napplicability domain more quantifiable and pragmatic. Eight applicability\ndomain detection techniques were applied to seven regression models, trained on\nfive different datasets, and their performance was benchmarked using a\nvalidation framework. We also propose a novel approach based on\nnon-deterministic Bayesian neural networks to define the applicability domain\nof the model. Our method exhibited superior accuracy in defining the\nApplicability Domain compared to previous methods, highlighting its potential\nin this regard.",
      "tldr_zh": "本研究评估了八种适用性域（applicability domain）检测技术在七个回归模型（regression models）上的性能，这些模型基于五个不同数据集进行训练，旨在量化并改进模型预测的可靠性和准确性。研究者提出了一种新方法，利用非确定性 Bayesian neural networks 来定义适用性域，该方法在验证框架中显示出比现有技术更高的准确性。通过基准测试，结果表明新方法能更有效地识别模型的安全使用范围，从而提升预测的可靠度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00920v1",
      "published_date": "2024-11-01 14:12:57 UTC",
      "updated_date": "2024-11-01 14:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:04:24.218819"
    },
    {
      "arxiv_id": "2411.00919v1",
      "title": "Internship Report: Benchmark of Deep Learning-based Imaging PPG in Automotive Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Tu",
        "Shakith Fernando",
        "Mark van Gastel"
      ],
      "abstract": "Imaging photoplethysmography (iPPG) can be used for heart rate monitoring\nduring driving, which is expected to reduce traffic accidents by continuously\nassessing drivers' physical condition. Deep learning-based iPPG methods using\nnear-infrared (NIR) cameras have recently gained attention as a promising\napproach. To help understand the challenges in applying iPPG in automotive, we\nprovide a benchmark of a NIR-based method using a deep learning model by\nevaluating its performance on MR-NIRP Car dataset. Experiment results show that\nthe average mean absolute error (MAE) is 7.5 bpm and 16.6 bpm under drivers'\nheads keeping still or having small motion, respectively. These findings\nsuggest that while the method shows promise, further improvements are needed to\nmake it reliable for real-world driving conditions.",
      "tldr_zh": "该报告评估了基于深度学习的图像光电容积描记法 (iPPG) 在汽车领域的性能，使用近红外 (NIR) 相机监测驾驶员心率，以降低交通事故风险。研究在 MR-NIRP Car 数据集上进行基准测试，结果显示，当驾驶员头部静止时，平均绝对误差 (MAE) 为 7.5 bpm，而在有轻微运动时，MAE 升至 16.6 bpm。这些发现表明，该方法在静态条件下表现出色，但需进一步优化以适应真实驾驶环境的动态挑战。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Internship Report",
      "pdf_url": "http://arxiv.org/pdf/2411.00919v1",
      "published_date": "2024-11-01 14:08:24 UTC",
      "updated_date": "2024-11-01 14:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:04:36.874003"
    },
    {
      "arxiv_id": "2411.00918v1",
      "title": "LIBMoE: A Library for comprehensive benchmarking Mixture of Experts in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nam V. Nguyen",
        "Thong T. Doan",
        "Luong Tran",
        "Van Nguyen",
        "Quang Pham"
      ],
      "abstract": "Mixture of Experts (MoEs) plays an important role in the development of more\nefficient and effective large language models (LLMs). Due to the enormous\nresource requirements, studying large scale MoE algorithms remain in-accessible\nto many researchers. This work develops \\emph{LibMoE}, a comprehensive and\nmodular framework to streamline the research, training, and evaluation of MoE\nalgorithms. Built upon three core principles: (i) modular design, (ii)\nefficient training; (iii) comprehensive evaluation, LibMoE brings MoE in LLMs\nmore accessible to a wide range of researchers by standardizing the training\nand evaluation pipelines. Using LibMoE, we extensively benchmarked five\nstate-of-the-art MoE algorithms over three different LLMs and 11 datasets under\nthe zero-shot setting. The results show that despite the unique\ncharacteristics, all MoE algorithms perform roughly similar when averaged\nacross a wide range of tasks. With the modular design and extensive evaluation,\nwe believe LibMoE will be invaluable for researchers to make meaningful\nprogress towards the next generation of MoE and LLMs. Project page:\n\\url{https://fsoft-aic.github.io/fsoft-LibMoE.github.io}.",
      "tldr_zh": "该研究开发了 LIBMoE，这是一个全面且模块化的库，旨在简化 Mixture of Experts (MoEs) 在 Large Language Models (LLMs) 中的研究、训练和评估。LIBMoE 基于三个核心原则——模块化设计(modular design)、高效训练(efficient training)和全面评估(comprehensive evaluation)，使大规模 MoE 算法更易于研究人员访问。通过 LIBMoE，他们对五种最先进 MoE 算法在三种 LLM 和 11 个数据集上的零样本(zero-shot)性能进行了基准测试，结果显示这些算法在各种任务中的整体表现相似。该框架有望推动 MoE 和 LLMs 的下一代发展，提供标准化的训练和评估管道。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00918v1",
      "published_date": "2024-11-01 14:04:36 UTC",
      "updated_date": "2024-11-01 14:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:04:48.692744"
    },
    {
      "arxiv_id": "2411.00600v1",
      "title": "On Deep Learning for Geometric and Semantic Scene Understanding Using On-Vehicle 3D LiDAR",
      "title_zh": "翻译失败",
      "authors": [
        "Li Li"
      ],
      "abstract": "3D LiDAR point cloud data is crucial for scene perception in computer vision,\nrobotics, and autonomous driving. Geometric and semantic scene understanding,\ninvolving 3D point clouds, is essential for advancing autonomous driving\ntechnologies. However, significant challenges remain, particularly in improving\nthe overall accuracy (e.g., segmentation accuracy, depth estimation accuracy,\netc.) and efficiency of these systems. To address the challenge in terms of\naccuracy related to LiDAR-based tasks, we present DurLAR, the first\nhigh-fidelity 128-channel 3D LiDAR dataset featuring panoramic ambient (near\ninfrared) and reflectivity imagery. To improve efficiency in 3D segmentation\nwhile ensuring the accuracy, we propose a novel pipeline that employs a smaller\narchitecture, requiring fewer ground-truth annotations while achieving superior\nsegmentation accuracy compared to contemporary approaches. To improve the\nsegmentation accuracy, we introduce Range-Aware Pointwise Distance Distribution\n(RAPiD) features and the associated RAPiD-Seg architecture. All contributions\nhave been accepted by peer-reviewed conferences, underscoring the advancements\nin both accuracy and efficiency in 3D LiDAR applications for autonomous\ndriving. Full abstract: https://etheses.dur.ac.uk/15738/.",
      "tldr_zh": "这篇论文探讨了使用车载3D LiDAR进行几何和语义场景理解的深度学习应用，针对分割准确性、深度估计准确性等挑战提出解决方案。作者引入了DurLAR，这是首个高保真128通道3D LiDAR数据集，包含全景环境（近红外）和反射率图像，以提升数据质量。论文还提出了一种新管道和Range-Aware Pointwise Distance Distribution (RAPiD) 特征及RAPiD-Seg架构，通过更小架构和减少地面真实标注需求，实现优越的3D分割准确性和效率改进。这些贡献已被同行评审会议接受，推进了自动驾驶领域的3D LiDAR应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "PhD thesis (Durham University, Computer Science), 149 pages (the 2024\n  BMVA Sullivan Doctoral Thesis Prize runner-up). Includes published content\n  from arXiv:2407.10159 (ECCV 2024 ORAL), arXiv:2303.11203 (CVPR 2023), and\n  arXiv:2406.10068 (3DV 2021), with minor revisions to the examined version:\n  https://etheses.dur.ac.uk/15738/",
      "pdf_url": "http://arxiv.org/pdf/2411.00600v1",
      "published_date": "2024-11-01 14:01:54 UTC",
      "updated_date": "2024-11-01 14:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:05:01.494245"
    },
    {
      "arxiv_id": "2411.00916v2",
      "title": "Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering",
      "title_zh": "增强骨质疏松症检测：一个结合特征融合和变量聚类的可解释多模态学习框架",
      "authors": [
        "Mehdi Hosseini Chagahi",
        "Saeed Mohammadi Dashtaki",
        "Niloufar Delfan",
        "Nadia Mohammadi",
        "Alireza Samari",
        "Behzad Moshiri",
        "Md. Jalil Piran",
        "Oliver Faust"
      ],
      "abstract": "Osteoporosis is a common condition that increases fracture risk, especially\nin older adults. Early diagnosis is vital for preventing fractures, reducing\ntreatment costs, and preserving mobility. However, healthcare providers face\nchallenges like limited labeled data and difficulties in processing medical\nimages. This study presents a novel multi-modal learning framework that\nintegrates clinical and imaging data to improve diagnostic accuracy and model\ninterpretability. The model utilizes three pre-trained networks-VGG19,\nInceptionV3, and ResNet50-to extract deep features from X-ray images. These\nfeatures are transformed using PCA to reduce dimensionality and focus on the\nmost relevant components. A clustering-based selection process identifies the\nmost representative components, which are then combined with preprocessed\nclinical data and processed through a fully connected network (FCN) for final\nclassification. A feature importance plot highlights key variables, showing\nthat Medical History, BMI, and Height were the main contributors, emphasizing\nthe significance of patient-specific data. While imaging features were\nvaluable, they had lower importance, indicating that clinical data are crucial\nfor accurate predictions. This framework promotes precise and interpretable\npredictions, enhancing transparency and building trust in AI-driven diagnoses\nfor clinical integration.",
      "tldr_zh": "本研究提出一个可解释的多模态学习框架，用于提升骨质疏松症检测的准确性和透明度，通过整合临床数据和X射线图像特征来解决数据有限和处理挑战。该框架利用VGG19、InceptionV3和ResNet50提取图像深度特征，并通过PCA降维和基于聚类的特征选择过程，将这些特征与预处理临床数据融合，然后通过全连接网络(FCN)进行最终分类。实验结果显示，临床变量如Medical History、BMI和Height是预测的主要贡献者，而影像特征的重要性较低，这强调了患者特定数据的关键作用，并为AI驱动诊断的临床整合提供了更可靠的基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00916v2",
      "published_date": "2024-11-01 13:58:15 UTC",
      "updated_date": "2024-11-08 09:09:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:05:14.281035"
    },
    {
      "arxiv_id": "2411.00594v1",
      "title": "Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy",
      "title_zh": "翻译失败",
      "authors": [
        "Mianyong Ding",
        "Matteo Maspero",
        "Annemieke S Littooij",
        "Martine van Grotel",
        "Raquel Davila Fajardo",
        "Max M van Noesel",
        "Marry M van den Heuvel-Eibrink",
        "Geert O Janssens"
      ],
      "abstract": "Purposes: This study aimed to develop a computed tomography (CT)-based\nmulti-organ segmentation model for delineating organs-at-risk (OARs) in\npediatric upper abdominal tumors and evaluate its robustness across multiple\ndatasets. Materials and methods: In-house postoperative CTs from pediatric\npatients with renal tumors and neuroblastoma (n=189) and a public dataset\n(n=189) with CTs covering thoracoabdominal regions were used. Seventeen OARs\nwere delineated: nine by clinicians (Type 1) and eight using TotalSegmentator\n(Type 2). Auto-segmentation models were trained using in-house (ModelPMC-UMCU)\nand a combined dataset of public data (Model-Combined). Performance was\nassessed with Dice Similarity Coefficient (DSC), 95% Hausdorff Distance (HD95),\nand mean surface distance (MSD). Two clinicians rated clinical acceptability on\na 5-point Likert scale across 15 patient contours. Model robustness was\nevaluated against sex, age, intravenous contrast, and tumor type. Results:\nModel-PMC-UMCU achieved mean DSC values above 0.95 for five of nine OARs, while\nspleen and heart ranged between 0.90 and 0.95. The stomach-bowel and pancreas\nexhibited DSC values below 0.90. Model-Combined demonstrated improved\nrobustness across both datasets. Clinical evaluation revealed good usability,\nwith both clinicians rating six of nine Type 1 OARs above four and six of eight\nType 2 OARs above three. Significant performance 2 differences were only found\nacross age groups in both datasets, specifically in the left lung and pancreas.\nThe 0-2 age group showed the lowest performance. Conclusion: A multi-organ\nsegmentation model was developed, showcasing enhanced robustness when trained\non combined datasets. This model is suitable for various OARs and can be\napplied to multiple datasets in clinical settings.",
      "tldr_zh": "本研究开发了一个基于深度学习的 CT 多器官分割模型，用于儿童上腹部肿瘤放射治疗中器官-at-risk (OARs) 的自动勾画，旨在提高分割准确性和鲁棒性。模型使用内部数据集（ModelPMC-UMCU）和结合公共数据集（Model-Combined）进行训练，并通过 Dice Similarity Coefficient (DSC)、95% Hausdorff Distance (HD95) 和 mean surface distance (MSD) 等指标评估性能。结果显示，ModelPMC-UMCU 在五种 OARs 上 DSC 值超过 0.95，但胃肠和胰腺低于 0.90，而 Model-Combined 在跨数据集上表现出色。临床评估表明模型具有良好可用性，大多数 OARs 获得高分，但年龄组差异显著，尤其是 0-2 岁组性能最低。该模型适用于多种临床场景，提升放射治疗效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "23 pages, 5 figures, 1 table. Submitted to Radiotherapy and Oncology\n  (2024-11-01)",
      "pdf_url": "http://arxiv.org/pdf/2411.00594v1",
      "published_date": "2024-11-01 13:54:31 UTC",
      "updated_date": "2024-11-01 13:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:05:26.936678"
    },
    {
      "arxiv_id": "2411.00593v2",
      "title": "Adapting Language Models via Token Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhili Feng",
        "Tanya Marwah",
        "Nicolo Fusi",
        "David Alvarez-Melis",
        "Lester Mackey"
      ],
      "abstract": "Modern large language models use a fixed tokenizer to effectively compress\ntext drawn from a source domain. However, applying the same tokenizer to a new\ntarget domain often leads to inferior compression, more costly inference, and\nreduced semantic alignment. To address this deficiency, we introduce Sparse\nSinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the\ntarget domain and learns to translate between target and source tokens,\nenabling more effective reuse of the pre-trained next-source-token predictor.\nIn our experiments with finetuned English language models, S2T2 improves both\nthe perplexity and the compression of out-of-domain protein sequences,\noutperforming direct finetuning with either the source or target tokenizer. In\naddition, we find that token translations learned for smaller, less expensive\nmodels can be directly transferred to larger, more powerful models to reap the\nbenefits of S2T2 at lower cost.",
      "tldr_zh": "本文研究了大型语言模型（Large Language Models）在使用固定 tokenizer 处理新目标域文本时存在的压缩效率低下、推理成本增加和语义对齐减弱的问题。作者引入了 Sparse Sinkhorn Token Translation (S2T2) 方法，该方法训练针对目标域的专用 tokenizer，并学习在目标和源 token 之间进行翻译，从而更有效地重用预训练的源 token 预测器。在实验中，S2T2 在微调英语模型处理蛋白质序列时，显著改善了 perplexity 和压缩性能，优于直接微调方案，且可将较小模型学到的 token 翻译转移到更大模型上，以降低整体成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00593v2",
      "published_date": "2024-11-01 13:53:14 UTC",
      "updated_date": "2024-11-05 18:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:06:39.027054"
    },
    {
      "arxiv_id": "2411.00588v1",
      "title": "$α$-TCVAE: On the relationship between Disentanglement and Diversity",
      "title_zh": "α-TCVAE：解缠结与多样性之间的关系",
      "authors": [
        "Cristian Meo",
        "Louis Mahon",
        "Anirudh Goyal",
        "Justin Dauwels"
      ],
      "abstract": "While disentangled representations have shown promise in generative modeling\nand representation learning, their downstream usefulness remains debated.\nRecent studies re-defined disentanglement through a formal connection to\nsymmetries, emphasizing the ability to reduce latent domains and consequently\nenhance generative capabilities. However, from an information theory viewpoint,\nassigning a complex attribute to a specific latent variable may be infeasible,\nlimiting the applicability of disentangled representations to simple datasets.\nIn this work, we introduce $\\alpha$-TCVAE, a variational autoencoder optimized\nusing a novel total correlation (TC) lower bound that maximizes disentanglement\nand latent variables informativeness. The proposed TC bound is grounded in\ninformation theory constructs, generalizes the $\\beta$-VAE lower bound, and can\nbe reduced to a convex combination of the known variational information\nbottleneck (VIB) and conditional entropy bottleneck (CEB) terms. Moreover, we\npresent quantitative analyses that support the idea that disentangled\nrepresentations lead to better generative capabilities and diversity.\nAdditionally, we perform downstream task experiments from both representation\nand RL domains to assess our questions from a broader ML perspective. Our\nresults demonstrate that $\\alpha$-TCVAE consistently learns more disentangled\nrepresentations than baselines and generates more diverse observations without\nsacrificing visual fidelity. Notably, $\\alpha$-TCVAE exhibits marked\nimprovements on MPI3D-Real, the most realistic disentangled dataset in our\nstudy, confirming its ability to represent complex datasets when maximizing the\ninformativeness of individual variables. Finally, testing the proposed model\noff-the-shelf on a state-of-the-art model-based RL agent, Director,\nsignificantly shows $\\alpha$-TCVAE downstream usefulness on the loconav Ant\nMaze task.",
      "tldr_zh": "本论文探讨了 disentanglement（解缠结）和 diversity（多样性）之间的关系，提出了一种新型 variational autoencoder（变分自编码器）模型 α-TCVAE。α-TCVAE 通过一个新的 total correlation (TC) lower bound 来优化 latent variables 的 informativeness（信息性），该 bound 基于信息理论构建，并泛化了 β-VAE lower bound，同时可简化为 variational information bottleneck (VIB) 和 conditional entropy bottleneck (CEB) 的凸组合。实验结果显示，α-TCVAE 比基线模型学习更 disentangled 的表示，生成更 diverse 的观察，同时保持 visual fidelity，并在复杂数据集如 MPI3D-Real 以及下游任务（如 reinforcement learning 中的 loconav Ant Maze）上表现出显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00588v1",
      "published_date": "2024-11-01 13:50:06 UTC",
      "updated_date": "2024-11-01 13:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:05:51.237839"
    },
    {
      "arxiv_id": "2411.00585v1",
      "title": "Benchmarking Bias in Large Language Models during Role-Playing",
      "title_zh": "大语言模型在角色扮演中的偏见基准测试",
      "authors": [
        "Xinyue Li",
        "Zhenpeng Chen",
        "Jie M. Zhang",
        "Yiling Lou",
        "Tianlin Li",
        "Weisong Sun",
        "Yang Liu",
        "Xuanzhe Liu"
      ],
      "abstract": "Large Language Models (LLMs) have become foundational in modern\nlanguage-driven applications, profoundly influencing daily life. A critical\ntechnique in leveraging their potential is role-playing, where LLMs simulate\ndiverse roles to enhance their real-world utility. However, while research has\nhighlighted the presence of social biases in LLM outputs, it remains unclear\nwhether and to what extent these biases emerge during role-playing scenarios.\nIn this paper, we introduce BiasLens, a fairness testing framework designed to\nsystematically expose biases in LLMs during role-playing. Our approach uses\nLLMs to generate 550 social roles across a comprehensive set of 11 demographic\nattributes, producing 33,000 role-specific questions targeting various forms of\nbias. These questions, spanning Yes/No, multiple-choice, and open-ended\nformats, are designed to prompt LLMs to adopt specific roles and respond\naccordingly. We employ a combination of rule-based and LLM-based strategies to\nidentify biased responses, rigorously validated through human evaluation. Using\nthe generated questions as the benchmark, we conduct extensive evaluations of\nsix advanced LLMs released by OpenAI, Mistral AI, Meta, Alibaba, and DeepSeek.\nOur benchmark reveals 72,716 biased responses across the studied LLMs, with\nindividual models yielding between 7,754 and 16,963 biased responses,\nunderscoring the prevalence of bias in role-playing contexts. To support future\nresearch, we have publicly released the benchmark, along with all scripts and\nexperimental results.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs)在角色扮演中的社会偏见问题，引入了BiasLens框架作为一种公平性测试工具，用于系统地暴露这些偏见。BiasLens通过LLMs生成550个社会角色，覆盖11个人口统计属性，并创建33,000个问题（包括Yes/No、选择题和开放式格式），结合规则和LLM-based策略进行偏见识别，并通过人工评估验证。在评估六种高级LLMs后，研究发现总计72,716个偏见响应，单个模型的偏见数量介于7,754至16,963之间，并公开了基准数据集、脚本和实验结果以促进未来研究。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00585v1",
      "published_date": "2024-11-01 13:47:00 UTC",
      "updated_date": "2024-11-01 13:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:06:02.948722"
    },
    {
      "arxiv_id": "2411.00915v5",
      "title": "Empower Vision Applications with LoRA LMM",
      "title_zh": "利用 LoRA LMM 赋能视觉应用",
      "authors": [
        "Liang Mi",
        "Weijun Wang",
        "Wenming Tu",
        "Qingfeng He",
        "Rui Kong",
        "Xinyu Fang",
        "Yazhu Dong",
        "Yikang Zhang",
        "Yunchun Li",
        "Meng Li",
        "Haipeng Dai",
        "Guihai Chen",
        "Yunxin Liu"
      ],
      "abstract": "Large Multimodal Models (LMMs) have shown significant progress in various\ncomplex vision tasks with the solid linguistic and reasoning capacity inherited\nfrom large language models (LMMs). Low-rank adaptation (LoRA) offers a\npromising method to integrate external knowledge into LMMs, compensating for\ntheir limitations on domain-specific tasks. However, the existing LoRA model\nserving is excessively computationally expensive and causes extremely high\nlatency. In this paper, we present an end-to-end solution that empowers diverse\nvision tasks and enriches vision applications with LoRA LMMs. Our system,\nVaLoRA, enables accurate and efficient vision tasks by 1) an accuracy-aware\nLoRA adapter generation approach that generates LoRA adapters rich in\ndomain-specific knowledge to meet application-specific accuracy requirements,\n2) an adaptive-tiling LoRA adapters batching operator that efficiently computes\nconcurrent heterogeneous LoRA adapters, and 3) a flexible LoRA adapter\norchestration mechanism that manages application requests and LoRA adapters to\nachieve the lowest average response latency. We prototype VaLoRA on five\npopular vision tasks on three LMMs. Experiment results reveal that VaLoRA\nimproves 24-62% of the accuracy compared to the original LMMs and reduces\n20-89% of the latency compared to the state-of-the-art LoRA model serving\nsystems.",
      "tldr_zh": "该论文提出了一种名为 VaLoRA 的端到端系统，利用 Low-rank adaptation (LoRA) 增强 Large Multimodal Models (LMMs)，以解决其在领域特定视觉任务中的局限性问题。VaLoRA 通过准确性感知的 LoRA 适配器生成方法、自适应平铺 LoRA 适配器批处理操作符以及灵活的 LoRA 适配器编排机制，实现高效的知识整合和任务处理，提升了视觉应用的准确性和响应速度。实验结果显示，VaLoRA 在五种流行视觉任务上使 LMMs 的准确率提高 24-62%，并将延迟降低 20-89%，优于现有 LoRA 模型服务系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "EuroSys'2025",
      "pdf_url": "http://arxiv.org/pdf/2411.00915v5",
      "published_date": "2024-11-01 13:43:33 UTC",
      "updated_date": "2025-04-03 08:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:06:14.452972"
    },
    {
      "arxiv_id": "2411.00914v1",
      "title": "AAD-LLM: Adaptive Anomaly Detection Using Large Language Models",
      "title_zh": "AAD-LLM：使用大语言模型的自适应异常检测",
      "authors": [
        "Alicia Russell-Gilbert",
        "Alexander Sommers",
        "Andrew Thompson",
        "Logan Cummins",
        "Sudip Mittal",
        "Shahram Rahimi",
        "Maria Seale",
        "Joseph Jaboure",
        "Thomas Arnold",
        "Joshua Church"
      ],
      "abstract": "For data-constrained, complex and dynamic industrial environments, there is a\ncritical need for transferable and multimodal methodologies to enhance anomaly\ndetection and therefore, prevent costs associated with system failures.\nTypically, traditional PdM approaches are not transferable or multimodal. This\nwork examines the use of Large Language Models (LLMs) for anomaly detection in\ncomplex and dynamic manufacturing systems. The research aims to improve the\ntransferability of anomaly detection models by leveraging Large Language Models\n(LLMs) and seeks to validate the enhanced effectiveness of the proposed\napproach in data-sparse industrial applications. The research also seeks to\nenable more collaborative decision-making between the model and plant operators\nby allowing for the enriching of input series data with semantics.\nAdditionally, the research aims to address the issue of concept drift in\ndynamic industrial settings by integrating an adaptability mechanism. The\nliterature review examines the latest developments in LLM time series tasks\nalongside associated adaptive anomaly detection methods to establish a robust\ntheoretical framework for the proposed architecture. This paper presents a\nnovel model framework (AAD-LLM) that doesn't require any training or finetuning\non the dataset it is applied to and is multimodal. Results suggest that anomaly\ndetection can be converted into a \"language\" task to deliver effective,\ncontext-aware detection in data-constrained industrial applications. This work,\ntherefore, contributes significantly to advancements in anomaly detection\nmethodologies.",
      "tldr_zh": "本研究针对数据受限、复杂动态的工业环境，提出了一种基于 Large Language Models (LLMs) 的自适应异常检测框架 AAD-LLM，以提升异常检测的可转移性和多模态能力，同时解决概念漂移问题。AAD-LLM 不需在特定数据集上进行训练或微调，通过为输入数据添加语义并整合适应机制，实现模型与操作员之间的协作决策。实验结果表明，该框架可将异常检测转化为“语言”任务，在数据稀疏的工业应用中提供有效且上下文感知的检测，从而显著推进异常检测方法论的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00914v1",
      "published_date": "2024-11-01 13:43:28 UTC",
      "updated_date": "2024-11-01 13:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:06:26.253906"
    },
    {
      "arxiv_id": "2411.00913v1",
      "title": "Ratio law: mathematical descriptions for a universal relationship between AI performance and input samples",
      "title_zh": "翻译失败",
      "authors": [
        "Boming Kang",
        "Qinghua Cui"
      ],
      "abstract": "Artificial intelligence based on machine learning and deep learning has made\nsignificant advances in various fields such as protein structure prediction and\nclimate modeling. However, a central challenge remains: the \"black box\" nature\nof AI, where precise quantitative relationships between inputs and outputs are\noften lacking. Here, by analyzing 323 AI models trained to predict human\nessential proteins, we uncovered a ratio law showing that model performance and\nthe ratio of minority to majority samples can be closely linked by two concise\nequations. Moreover, we mathematically proved that an AI model achieves its\noptimal performance on a balanced dataset. More importantly, we next explore\nwhether this finding can further guide us to enhance AI models' performance.\nTherefore, we divided the imbalanced dataset into several balanced subsets to\ntrain base classifiers, and then applied a bagging-based ensemble learning\nstrategy to combine these base models. As a result, the equation-guided\nstrategy substantially improved model performance, with increases of 4.06% and\n5.28%, respectively, outperforming traditional dataset balancing techniques.\nFinally, we confirmed the broad applicability and generalization of these\nequations using different types of classifiers and 10 additional, diverse\nbinary classification tasks. In summary, this study reveals two equations\nprecisely linking AI's input and output, which could be helpful for unboxing\nthe mysterious \"black box\" of AI.",
      "tldr_zh": "本研究通过分析323个AI模型，发现了“ratio law”，即AI性能与少数类样本与多数类样本比例之间的普遍关系，并用两个简洁方程进行描述。研究者数学证明了AI模型在平衡数据集上可达到最佳性能，并提出了一种基于bagging的集成学习策略：将不平衡数据集分成平衡子集训练基础分类器，然后组合这些模型。实验结果显示，该策略使模型性能分别提高了4.06%和5.28%，优于传统平衡技术，并在不同类型分类器和10个二元分类任务上验证了其广泛适用性。总之，这一发现有助于揭开AI的“黑箱”性质，提供量化指导提升模型表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 5 figures, 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2411.00913v1",
      "published_date": "2024-11-01 13:43:19 UTC",
      "updated_date": "2024-11-01 13:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:06:40.673678"
    },
    {
      "arxiv_id": "2411.00577v1",
      "title": "WLPlan: Relational Features for Symbolic Planning",
      "title_zh": "WLPlan：用于符号规划的关系",
      "authors": [
        "Dillon Z. Chen"
      ],
      "abstract": "Scalable learning for planning research generally involves juggling between\ndifferent programming languages for handling learning and planning modules\neffectively. Interpreted languages such as Python are commonly used for\nlearning routines due to their ease of use and the abundance of highly\nmaintained learning libraries they exhibit, while compiled languages such as\nC++ are used for planning routines due to their optimised resource usage.\nMotivated by the need for tools for developing scalable learning planners, we\nintroduce WLPlan, a C++ package with Python bindings which implements recent\npromising work for automatically generating relational features of planning\ntasks. Such features can be used for any downstream routine, such as learning\ndomain control knowledge or probing and understanding planning tasks. More\nspecifically, WLPlan provides functionality for (1) transforming planning tasks\ninto graphs, and (2) embedding planning graphs into feature vectors via graph\nkernels. The source code and instructions for the installation and usage of\nWLPlan are available at tinyurl.com/42kymswc",
      "tldr_zh": "该研究针对符号规划（symbolic planning）中的可扩展学习问题，介绍了 WLPlan，这是一个 C++ 包带有 Python 绑定，用于自动生成规划任务的 relational features，从而解决学习模块（常用 Python）和规划模块（常用 C++）之间的编程语言兼容性挑战。WLPlan 的核心功能包括将规划任务转化为 graphs，并通过 graph kernels 将这些图嵌入到特征向量中，便于后续应用。这样的 features 可用于学习领域控制知识或分析规划任务，提升整体效率，相关源代码可在 tinyurl.com/42kymswc 获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00577v1",
      "published_date": "2024-11-01 13:36:05 UTC",
      "updated_date": "2024-11-01 13:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:06:50.335176"
    },
    {
      "arxiv_id": "2411.05816v1",
      "title": "Learning Characteristics of Reverse Quaternion Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Shogo Yamauchi",
        "Tohru Nitta",
        "Takaaki Ohnishi"
      ],
      "abstract": "The purpose of this paper is to propose a new multi-layer feedforward\nquaternion neural network model architecture, Reverse Quaternion Neural Network\nwhich utilizes the non-commutative nature of quaternion products, and to\nclarify its learning characteristics. While quaternion neural networks have\nbeen used in various fields, there has been no research report on the\ncharacteristics of multi-layer feedforward quaternion neural networks where\nweights are applied in the reverse direction. This paper investigates the\nlearning characteristics of the Reverse Quaternion Neural Network from two\nperspectives: the learning speed and the generalization on rotation. As a\nresult, it is found that the Reverse Quaternion Neural Network has a learning\nspeed comparable to existing models and can obtain a different rotation\nrepresentation from the existing models.",
      "tldr_zh": "本文提出了一种新的多层前馈四元数神经网络模型，Reverse Quaternion Neural Network，利用四元数乘法的非交换性，并探讨其学习特性。论文从学习速度和旋转泛化能力两个方面进行分析，结果显示该模型的学习速度与现有quaternion neural networks相当，同时能获得不同的旋转表示，从而为四元数神经网络的应用提供新视角。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05816v1",
      "published_date": "2024-11-01 13:28:12 UTC",
      "updated_date": "2024-11-01 13:28:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:07:01.392988"
    },
    {
      "arxiv_id": "2411.00563v1",
      "title": "Simulate and Optimise: A two-layer mortgage simulator for designing novel mortgage assistance products",
      "title_zh": "翻译失败",
      "authors": [
        "Leo Ardon",
        "Benjamin Patrick Evans",
        "Deepeka Garg",
        "Annapoorani Lakshmi Narayanan",
        "Makada Henry-Nickie",
        "Sumitra Ganesh"
      ],
      "abstract": "We develop a novel two-layer approach for optimising mortgage relief products\nthrough a simulated multi-agent mortgage environment. While the approach is\ngeneric, here the environment is calibrated to the US mortgage market based on\npublicly available census data and regulatory guidelines. Through the\nsimulation layer, we assess the resilience of households to exogenous income\nshocks, while the optimisation layer explores strategies to improve the\nrobustness of households to these shocks by making novel mortgage assistance\nproducts available to households. Households in the simulation are adaptive,\nlearning to make mortgage-related decisions (such as product enrolment or\nstrategic foreclosures) that maximize their utility, balancing their available\nliquidity and equity. We show how this novel two-layer simulation approach can\nsuccessfully design novel mortgage assistance products to improve household\nresilience to exogenous shocks, and balance the costs of providing such\nproducts through post-hoc analysis. Previously, such analysis could only be\nconducted through expensive pilot studies involving real participants,\ndemonstrating the benefit of the approach for designing and evaluating\nfinancial products.",
      "tldr_zh": "本文提出了一种两层方法（two-layer approach），通过模拟多智能体抵押环境（multi-agent mortgage environment）来优化新型抵押援助产品，该方法基于美国抵押市场的公开数据和监管指南进行校准。模拟层评估家庭对外部收入冲击的弹性，而优化层探索策略，提供新型产品以增强家庭韧性，家庭在模拟中通过自适应决策（如产品注册或战略性止赎）最大化自身效用。结果表明，该方法能有效设计出平衡成本的援助产品，并避免了传统昂贵的试点研究，从而为金融产品设计提供高效工具。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CE",
        "q-fin.CP"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at the 5th ACM International Conference on AI in Finance",
      "pdf_url": "http://arxiv.org/pdf/2411.00563v1",
      "published_date": "2024-11-01 13:21:11 UTC",
      "updated_date": "2024-11-01 13:21:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:07:14.798133"
    },
    {
      "arxiv_id": "2411.00556v1",
      "title": "LLM-KT: A Versatile Framework for Knowledge Transfer from Large Language Models to Collaborative Filtering",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Severin",
        "Aleksei Ziablitsev",
        "Yulia Savelyeva",
        "Valeriy Tashchilin",
        "Ivan Bulychev",
        "Mikhail Yushkov",
        "Artem Kushneruk",
        "Amaliya Zaryvnykh",
        "Dmitrii Kiselev",
        "Andrey Savchenko",
        "Ilya Makarov"
      ],
      "abstract": "We present LLM-KT, a flexible framework designed to enhance collaborative\nfiltering (CF) models by seamlessly integrating LLM (Large Language\nModel)-generated features. Unlike existing methods that rely on passing\nLLM-generated features as direct inputs, our framework injects these features\ninto an intermediate layer of any CF model, allowing the model to reconstruct\nand leverage the embeddings internally. This model-agnostic approach works with\na wide range of CF models without requiring architectural changes, making it\nadaptable to various recommendation scenarios. Our framework is built for easy\nintegration and modification, providing researchers and developers with a\npowerful tool for extending CF model capabilities through efficient knowledge\ntransfer. We demonstrate its effectiveness through experiments on the MovieLens\nand Amazon datasets, where it consistently improves baseline CF models.\nExperimental studies showed that LLM-KT is competitive with the\nstate-of-the-art methods in context-aware settings but can be applied to a\nbroader range of CF models than current approaches.",
      "tldr_zh": "本研究提出LLM-KT框架，用于从大型语言模型(LLM)向协同过滤(CF)模型转移知识，从而提升推荐系统的性能。该框架将LLM生成的特征注入CF模型的中间层，而不是直接作为输入，这使得它具备模型无关性，无需修改CF模型的架构即可适应各种推荐场景。通过在MovieLens和Amazon数据集上的实验，LLM-KT框架显著改善了基线CF模型的表现，并在上下文感知设置中与最先进方法竞争，同时其适用范围更广泛。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "accepted at ICDM 2024 (demo track)",
      "pdf_url": "http://arxiv.org/pdf/2411.00556v1",
      "published_date": "2024-11-01 13:09:30 UTC",
      "updated_date": "2024-11-01 13:09:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:07:25.803971"
    },
    {
      "arxiv_id": "2411.00554v3",
      "title": "Differentiable Physics-based System Identification for Robotic Manipulation of Elastoplastic Materials",
      "title_zh": "可微分物理建模的弹性塑性材料机器人操作系统辨识",
      "authors": [
        "Xintong Yang",
        "Ze Ji",
        "Yu-Kun Lai"
      ],
      "abstract": "Robotic manipulation of volumetric elastoplastic deformable materials, from\nfoods such as dough to construction materials like clay, is in its infancy,\nlargely due to the difficulty of modelling and perception in a high-dimensional\nspace. Simulating the dynamics of such materials is computationally expensive.\nIt tends to suffer from inaccurately estimated physics parameters of the\nmaterials and the environment, impeding high-precision manipulation. Estimating\nsuch parameters from raw point clouds captured by optical cameras suffers\nfurther from heavy occlusions. To address this challenge, this work introduces\na novel Differentiable Physics-based System Identification (DPSI) framework\nthat enables a robot arm to infer the physics parameters of elastoplastic\nmaterials and the environment using simple manipulation motions and incomplete\n3D point clouds, aligning the simulation with the real world. Extensive\nexperiments show that with only a single real-world interaction, the estimated\nparameters, Young's modulus, Poisson's ratio, yield stress and friction\ncoefficients, can accurately simulate visually and physically realistic\ndeformation behaviours induced by unseen and long-horizon manipulation motions.\nAdditionally, the DPSI framework inherently provides physically intuitive\ninterpretations for the parameters in contrast to black-box approaches such as\ndeep neural networks. The project is fully open-sourced via\nhttps://ianyangchina.github.io/SI4RP-data/.",
      "tldr_zh": "本文提出 Differentiable Physics-based System Identification (DPSI) 框架，用于解决机器人操作弹性塑性材料（如面团或粘土）的建模和感知挑战，该框架通过简单操作和不完整的 3D 点云数据，推断材料的物理参数，包括 Young's modulus、Poisson's ratio、yield stress 和 friction coefficients，从而使模拟更接近真实世界。实验结果显示，仅需单次真实互动，DPSI 即可准确模拟未见和长期操作引起的变形行为，精度显著提升。相比黑盒方法如深度神经网络，DPSI 提供物理直观的解释，并已开源以促进进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by the Internation Journal of Robotics Research",
      "pdf_url": "http://arxiv.org/pdf/2411.00554v3",
      "published_date": "2024-11-01 13:04:25 UTC",
      "updated_date": "2025-02-18 08:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:07:39.721901"
    },
    {
      "arxiv_id": "2411.00551v1",
      "title": "Conditional Synthesis of 3D Molecules with Time Correction Sampler",
      "title_zh": "翻译失败",
      "authors": [
        "Hojung Jung",
        "Youngrok Park",
        "Laura Schmid",
        "Jaehyeong Jo",
        "Dongkyu Lee",
        "Bongsang Kim",
        "Se-Young Yun",
        "Jinwoo Shin"
      ],
      "abstract": "Diffusion models have demonstrated remarkable success in various domains,\nincluding molecular generation. However, conditional molecular generation\nremains a fundamental challenge due to an intrinsic trade-off between targeting\nspecific chemical properties and generating meaningful samples from the data\ndistribution. In this work, we present Time-Aware Conditional Synthesis (TACS),\na novel approach to conditional generation on diffusion models. It integrates\nadaptively controlled plug-and-play \"online\" guidance into a diffusion model,\ndriving samples toward the desired properties while maintaining validity and\nstability. A key component of our algorithm is our new type of diffusion\nsampler, Time Correction Sampler (TCS), which is used to control guidance and\nensure that the generated molecules remain on the correct manifold at each\nreverse step of the diffusion process at the same time. Our proposed method\ndemonstrates significant performance in conditional 3D molecular generation and\noffers a promising approach towards inverse molecular design, potentially\nfacilitating advancements in drug discovery, materials science, and other\nrelated fields.",
      "tldr_zh": "本研究针对扩散模型(Diffusion models)在条件分子生成中的权衡问题，提出了一种新方法Time-Aware Conditional Synthesis (TACS)，通过自适应控制的“在线”指导来驱动样本朝向特定化学属性，同时保持样本的有效性和稳定性。TACS的关键组件是Time Correction Sampler (TCS)，它在扩散过程的每个逆向步骤中控制指导，确保生成的分子保持在正确的流形上。实验结果显示，该方法在条件3D分子生成中表现出显著性能，为逆向分子设计提供了新途径，可能推动药物发现、材料科学等领域的进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00551v1",
      "published_date": "2024-11-01 12:59:25 UTC",
      "updated_date": "2024-11-01 12:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:07:50.728121"
    },
    {
      "arxiv_id": "2411.00548v1",
      "title": "Generative AI-based Pipeline Architecture for Increasing Training Efficiency in Intelligent Weed Control Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sourav Modak",
        "Anthony Stein"
      ],
      "abstract": "In automated crop protection tasks such as weed control, disease diagnosis,\nand pest monitoring, deep learning has demonstrated significant potential.\nHowever, these advanced models rely heavily on high-quality, diverse datasets,\noften limited and costly in agricultural settings. Traditional data\naugmentation can increase dataset volume but usually lacks the real-world\nvariability needed for robust training. This study presents a new approach for\ngenerating synthetic images to improve deep learning-based object detection\nmodels for intelligent weed control. Our GenAI-based image generation pipeline\nintegrates the Segment Anything Model (SAM) for zero-shot domain adaptation\nwith a text-to-image Stable Diffusion Model, enabling the creation of synthetic\nimages that capture diverse real-world conditions. We evaluate these synthetic\ndatasets using lightweight YOLO models, measuring data efficiency with mAP50\nand mAP50-95 scores across varying proportions of real and synthetic data.\nNotably, YOLO models trained on datasets with 10% synthetic and 90% real images\ngenerally demonstrate superior mAP50 and mAP50-95 scores compared to those\ntrained solely on real images. This approach not only reduces dependence on\nextensive real-world datasets but also enhances predictive performance. The\nintegration of this approach opens opportunities for achieving continual\nself-improvement of perception modules in intelligent technical systems.",
      "tldr_zh": "本文提出了一种基于生成式AI的图像生成管道，旨在提升智能杂草控制系统的训练效率，通过生成合成图像来解决农业数据集有限和多样性不足的问题。该管道整合Segment Anything Model (SAM)进行零样本域适应，以及Stable Diffusion模型生成捕捉真实世界条件的图像。实验结果显示，使用10%合成图像和90%真实图像训练的YOLO模型，在mAP50和mAP50-95分数上比仅用真实图像的模型表现更优，从而减少了对真实数据集的依赖，并为智能系统的持续自改进提供新机遇。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00548v1",
      "published_date": "2024-11-01 12:58:27 UTC",
      "updated_date": "2024-11-01 12:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:08:02.813762"
    },
    {
      "arxiv_id": "2411.00533v4",
      "title": "ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot Named Entity Recognition with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anbang Wang",
        "Difei Mei",
        "Zhichao Zhang",
        "Xiuxiu Bai",
        "Ran Yao",
        "Zewen Fang",
        "Min Hu",
        "Zhirui Cao",
        "Haitao Sun",
        "Yifeng Guo",
        "Hongyao Zhou",
        "Yu Guo"
      ],
      "abstract": "This paper presents ReverseNER, a method aimed at overcoming the limitation\nof large language models (LLMs) in zero-shot named entity recognition (NER)\ntasks, arising from their reliance on pre-provided demonstrations. ReverseNER\ntackles this challenge by constructing a reliable example library composed of\ndozens of entity-labeled sentences, generated through the reverse process of\nNER. Specifically, while conventional NER methods label entities in a sentence,\nReverseNER features reversing the process by using an LLM to generate entities\nfrom their definitions and subsequently expand them into full sentences. During\nthe entity expansion process, the LLM is guided to generate sentences by\nreplicating the structures of a set of specific \\textsl{feature sentences},\nextracted from the task sentences by clustering. This expansion process\nproduces dozens of entity-labeled task-relevant sentences. After constructing\nthe example library, the method selects several semantically similar\nentity-labeled examples for each task sentence as references to facilitate the\nLLM's entity recognition. We also propose an entity-level self-consistency\nscoring mechanism to improve NER performance with LLMs. Experiments show that\nReverseNER significantly outperforms other zero-shot NER methods with LLMs,\nmarking a notable improvement in NER for domains without labeled data, while\ndeclining computational resource consumption.",
      "tldr_zh": "本文提出ReverseNER框架，利用大型语言模型(LLMs)进行零样本命名实体识别(NER)，通过逆向NER过程自动生成实体标记示例库，以克服LLMs对预提供演示的依赖。具体地，该方法从实体定义生成实体并扩展成句子，使用从任务句子中聚类提取的特征句子作为结构模板，并引入实体级自一致性评分机制来提升识别性能。实验结果表明，ReverseNER显著优于其他零样本NER方法，在无标记数据领域取得显著改进，同时减少了计算资源消耗。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00533v4",
      "published_date": "2024-11-01 12:08:08 UTC",
      "updated_date": "2024-12-25 16:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:08:14.829025"
    },
    {
      "arxiv_id": "2411.00489v2",
      "title": "Human-inspired Perspectives: A Survey on AI Long-term Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Zihong He",
        "Weizhe Lin",
        "Hao Zheng",
        "Fan Zhang",
        "Matt W. Jones",
        "Laurence Aitchison",
        "Xuhai Xu",
        "Miao Liu",
        "Per Ola Kristensson",
        "Junxiao Shen"
      ],
      "abstract": "With the rapid advancement of AI systems, their abilities to store, retrieve,\nand utilize information over the long term - referred to as long-term memory -\nhave become increasingly significant. These capabilities are crucial for\nenhancing the performance of AI systems across a wide range of tasks. However,\nthere is currently no comprehensive survey that systematically investigates\nAI's long-term memory capabilities, formulates a theoretical framework, and\ninspires the development of next-generation AI long-term memory systems. This\npaper begins by introducing the mechanisms of human long-term memory, then\nexplores AI long-term memory mechanisms, establishing a mapping between the\ntwo. Based on the mapping relationships identified, we extend the current\ncognitive architectures and propose the Cognitive Architecture of Self-Adaptive\nLong-term Memory (SALM). SALM provides a theoretical framework for the practice\nof AI long-term memory and holds potential for guiding the creation of\nnext-generation long-term memory driven AI systems. Finally, we delve into the\nfuture directions and application prospects of AI long-term memory.",
      "tldr_zh": "这篇调查论文系统探讨了 AI 的长期记忆(long-term memory)能力，强调其在提升 AI 任务性能中的重要性，并填补了现有研究的空白。作者首先介绍人类长期记忆机制，然后映射到 AI 长期记忆机制，并基于此扩展认知架构，提出自适应长期记忆认知架构(SALM)，为构建下一代 AI 系统提供理论指导。最后，论文展望了 AI 长期记忆的未来发展方向和应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00489v2",
      "published_date": "2024-11-01 10:04:01 UTC",
      "updated_date": "2025-01-12 06:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:08:25.770059"
    },
    {
      "arxiv_id": "2411.00477v1",
      "title": "Multi Modal Information Fusion of Acoustic and Linguistic Data for Decoding Dairy Cow Vocalizations in Animal Welfare Assessment",
      "title_zh": "多模态信息融合：整合声学和语言学数据用于解码奶牛叫声以评估动物福利",
      "authors": [
        "Bubacarr Jobarteh",
        "Madalina Mincu",
        "Gavojdian Dinu",
        "Suresh Neethirajan"
      ],
      "abstract": "Understanding animal vocalizations through multi-source data fusion is\ncrucial for assessing emotional states and enhancing animal welfare in\nprecision livestock farming. This study aims to decode dairy cow contact calls\nby employing multi-modal data fusion techniques, integrating transcription,\nsemantic analysis, contextual and emotional assessment, and acoustic feature\nextraction. We utilized the Natural Language Processing model to transcribe\naudio recordings of cow vocalizations into written form. By fusing multiple\nacoustic features frequency, duration, and intensity with transcribed textual\ndata, we developed a comprehensive representation of cow vocalizations.\nUtilizing data fusion within a custom-developed ontology, we categorized\nvocalizations into high frequency calls associated with distress or arousal,\nand low frequency calls linked to contentment or calmness. Analyzing the fused\nmulti dimensional data, we identified anxiety related features indicative of\nemotional distress, including specific frequency measurements and sound\nspectrum results. Assessing the sentiment and acoustic features of\nvocalizations from 20 individual cows allowed us to determine differences in\ncalling patterns and emotional states. Employing advanced machine learning\nalgorithms, Random Forest, Support Vector Machine, and Recurrent Neural\nNetworks, we effectively processed and fused multi-source data to classify cow\nvocalizations. These models were optimized to handle computational demands and\ndata quality challenges inherent in practical farm environments. Our findings\ndemonstrate the effectiveness of multi-source data fusion and intelligent\nprocessing techniques in animal welfare monitoring. This study represents a\nsignificant advancement in animal welfare assessment, highlighting the role of\ninnovative fusion technologies in understanding and improving the emotional\nwellbeing of dairy cows.",
      "tldr_zh": "这篇论文探讨了通过多模态数据融合技术整合声学特征（如频率、持续时间和强度）和语言数据（如转录文本），以解码奶牛叫声并评估动物福利。研究利用 Natural Language Processing 模型转录音频录音，并通过自定义 ontology 将叫声分类为高频（与痛苦或兴奋相关）和低频（与满足或平静相关）。采用 Random Forest、Support Vector Machine 和 Recurrent Neural Networks 等机器学习算法处理融合数据，成功识别了与焦虑相关的特征，如特定频率和声谱结果。最终结果表明，这种方法在实际农场环境中显著提升了动物福利监测的有效性，并为改善奶牛情感福祉提供了创新途径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "q-bio.QM"
      ],
      "primary_category": "cs.SD",
      "comment": "31 pages, 22 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.00477v1",
      "published_date": "2024-11-01 09:48:30 UTC",
      "updated_date": "2024-11-01 09:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:08:39.084033"
    },
    {
      "arxiv_id": "2411.00469v1",
      "title": "MIRFLEX: Music Information Retrieval Feature Library for Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Anuradha Chopra",
        "Abhinaba Roy",
        "Dorien Herremans"
      ],
      "abstract": "This paper introduces an extendable modular system that compiles a range of\nmusic feature extraction models to aid music information retrieval research.\nThe features include musical elements like key, downbeats, and genre, as well\nas audio characteristics like instrument recognition, vocals/instrumental\nclassification, and vocals gender detection. The integrated models are\nstate-of-the-art or latest open-source. The features can be extracted as latent\nor post-processed labels, enabling integration into music applications such as\ngenerative music, recommendation, and playlist generation. The modular design\nallows easy integration of newly developed systems, making it a good\nbenchmarking and comparison tool. This versatile toolkit supports the research\ncommunity in developing innovative solutions by providing concrete musical\nfeatures.",
      "tldr_zh": "本文提出 MIRFLEX，一种可扩展的模块化系统，用于编译多种音乐特征提取模型，支持音乐信息检索（Music Information Retrieval）研究。该系统整合了音乐元素如 key、downbeats 和 genre，以及音频特性如乐器识别、vocals/instrumental classification 和 vocals gender detection 等，采用最先进的开源模型。特征可以作为 latent 或后处理标签提取，应用于生成音乐、推荐系统和播放列表生成等领域；其模块化设计便于整合新系统，作为基准测试和比较工具，促进研究社区开发创新解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "eess.AS",
        "I.2.7"
      ],
      "primary_category": "cs.SD",
      "comment": "2 pages, 4 tables, submitted to Extended Abstracts for the\n  Late-Breaking Demo Session of the 25th Int. Society for Music Information\n  Retrieval Conf., San Francisco, United States, 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00469v1",
      "published_date": "2024-11-01 09:34:36 UTC",
      "updated_date": "2024-11-01 09:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:08:51.009958"
    },
    {
      "arxiv_id": "2411.00465v1",
      "title": "Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse Data Corruptions",
      "title_zh": "基于不确定性的离线变分贝叶斯强化学习，用于多种数据损坏下的鲁棒性",
      "authors": [
        "Rui Yang",
        "Jie Wang",
        "Guoping Wu",
        "Bin Li"
      ],
      "abstract": "Real-world offline datasets are often subject to data corruptions (such as\nnoise or adversarial attacks) due to sensor failures or malicious attacks.\nDespite advances in robust offline reinforcement learning (RL), existing\nmethods struggle to learn robust agents under high uncertainty caused by the\ndiverse corrupted data (i.e., corrupted states, actions, rewards, and\ndynamics), leading to performance degradation in clean environments. To tackle\nthis problem, we propose a novel robust variational Bayesian inference for\noffline RL (TRACER). It introduces Bayesian inference for the first time to\ncapture the uncertainty via offline data for robustness against all types of\ndata corruptions. Specifically, TRACER first models all corruptions as the\nuncertainty in the action-value function. Then, to capture such uncertainty, it\nuses all offline data as the observations to approximate the posterior\ndistribution of the action-value function under a Bayesian inference framework.\nAn appealing feature of TRACER is that it can distinguish corrupted data from\nclean data using an entropy-based uncertainty measure, since corrupted data\noften induces higher uncertainty and entropy. Based on the aforementioned\nmeasure, TRACER can regulate the loss associated with corrupted data to reduce\nits influence, thereby enhancing robustness and performance in clean\nenvironments. Experiments demonstrate that TRACER significantly outperforms\nseveral state-of-the-art approaches across both individual and simultaneous\ndata corruptions.",
      "tldr_zh": "该研究针对现实世界离线强化学习（RL）数据集中的数据损坏（如噪声或攻击）问题，提出了一种新的方法TRACER，利用变分Bayesian推理来捕捉不确定性，从而提升鲁棒性。TRACER将所有数据损坏建模为动作价值函数的不确定性，并通过贝叶斯推理框架使用离线数据近似其后验分布，同时采用基于熵的不确定性度量来区分损坏数据并调节相关损失，减少其影响。实验结果显示，TRACER在单个和同时数据损坏场景下显著优于现有方法，提高了在干净环境中的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00465v1",
      "published_date": "2024-11-01 09:28:24 UTC",
      "updated_date": "2024-11-01 09:28:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:09:02.532130"
    },
    {
      "arxiv_id": "2411.00907v3",
      "title": "On the Impact of White-box Deployment Strategies for Edge AI on Latency and Model Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Jaskirat Singh",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "abstract": "To help MLOps engineers decide which operator to use in which deployment\nscenario, this study aims to empirically assess the accuracy vs latency\ntrade-off of white-box (training-based) and black-box operators\n(non-training-based) and their combinations in an Edge AI setup. We perform\ninference experiments including 3 white-box (i.e., QAT, Pruning, Knowledge\nDistillation), 2 black-box (i.e., Partition, SPTQ), and their combined\noperators (i.e., Distilled SPTQ, SPTQ Partition) across 3 tiers (i.e., Mobile,\nEdge, Cloud) on 4 commonly-used Computer Vision and Natural Language Processing\nmodels to identify the effective strategies, considering the perspective of\nMLOps Engineers. Our Results indicate that the combination of Distillation and\nSPTQ operators (i.e., DSPTQ) should be preferred over non-hybrid operators when\nlower latency is required in the edge at small to medium accuracy drop. Among\nthe non-hybrid operators, the Distilled operator is a better alternative in\nboth mobile and edge tiers for lower latency performance at the cost of small\nto medium accuracy loss. Moreover, the operators involving distillation show\nlower latency in resource-constrained tiers (Mobile, Edge) compared to the\noperators involving Partitioning across Mobile and Edge tiers. For textual\nsubject models, which have low input data size requirements, the Cloud tier is\na better alternative for the deployment of operators than the Mobile, Edge, or\nMobile-Edge tier (the latter being used for operators involving partitioning).\nIn contrast, for image-based subject models, which have high input data size\nrequirements, the Edge tier is a better alternative for operators than Mobile,\nEdge, or their combination.",
      "tldr_zh": "本研究评估了白盒（training-based）和黑盒（non-training-based）操作符及其组合在 Edge AI 部署中的准确性和延迟权衡，以帮助 MLOps 工程师选择合适策略。实验涉及 3 个白盒操作符（QAT、Pruning、Knowledge Distillation）、2 个黑盒操作符（Partition、SPTQ）及其组合（如 Distilled SPTQ、SPTQ Partition），在 Mobile、Edge 和 Cloud 三层上测试 4 个常用计算机视觉和自然语言处理模型。结果显示，当需要较低延迟且准确性损失较小时，应优先使用 Distillation 和 SPTQ 的组合（DSPTQ）；在非混合操作符中，Distilled 操作符在 Mobile 和 Edge 层提供更好的性能，但伴随小到中等的准确性损失。对于文本模型，低输入数据大小使其更适合 Cloud 层部署，而图像模型的高输入数据大小则使 Edge 层更具优势。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "In Approach Section, Pruning & Knowledge Distillation methods of\n  Intel Neural Compressor don't reduce the model size & improve performance,\n  respectively, unlike previous studies. There are issues exporting QAT models\n  from PyTorch to ONNX, raising concerns about our latency results",
      "pdf_url": "http://arxiv.org/pdf/2411.00907v3",
      "published_date": "2024-11-01 09:22:49 UTC",
      "updated_date": "2025-01-22 05:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:09:16.117587"
    },
    {
      "arxiv_id": "2411.00461v2",
      "title": "A Multi-Granularity Supervised Contrastive Framework for Remaining Useful Life Prediction of Aero-engines",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan He",
        "Ziqian Kong",
        "Zhengyu Chen",
        "Yuling Zhan",
        "Zijun Que",
        "Zhengguo Xu"
      ],
      "abstract": "Accurate remaining useful life (RUL) predictions are critical to the safe\noperation of aero-engines. Currently, the RUL prediction task is mainly a\nregression paradigm with only mean square error as the loss function and lacks\nresearch on feature space structure, the latter of which has shown excellent\nperformance in a large number of studies. This paper develops a\nmulti-granularity supervised contrastive (MGSC) framework from plain intuition\nthat samples with the same RUL label should be aligned in the feature space,\nand address the problems of too large minibatch size and unbalanced samples in\nthe implementation. The RUL prediction with MGSC is implemented on using the\nproposed multi-phase training strategy. This paper also demonstrates a simple\nand scalable basic network structure and validates the proposed MGSC strategy\non the CMPASS dataset using a convolutional long short-term memory network as a\nbaseline, which effectively improves the accuracy of RUL prediction.",
      "tldr_zh": "本文提出了一种多粒度监督对比（Multi-Granularity Supervised Contrastive，MGSC）框架，用于提升航空发动机剩余使用寿命（Remaining Useful Life，RUL）预测的准确性，以弥补当前回归范式仅依赖均方误差（mean square error）损失函数并忽略特征空间结构的问题。MGSC框架基于样本在特征空间的对齐直觉，解决了mini-batch大小过大和样本不平衡等挑战，并通过多阶段训练策略与简单可扩展的网络结构进行实现。在CMAPSS数据集上，使用卷积长短期记忆网络（Convolutional LSTM）作为基线，实验验证了MGSC策略有效提高了RUL预测的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00461v2",
      "published_date": "2024-11-01 09:18:38 UTC",
      "updated_date": "2024-11-15 03:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:09:27.711649"
    },
    {
      "arxiv_id": "2411.02430v1",
      "title": "Generative Emotion Cause Explanation in Multimodal Conversations",
      "title_zh": "在多模态对话中生成情感原因解释",
      "authors": [
        "Lin Wang",
        "Xiaocui Yang",
        "Shi Feng",
        "Daling Wang",
        "Yifei Zhang"
      ],
      "abstract": "Multimodal conversation, a crucial form of human communication, carries rich\nemotional content, making the exploration of the causes of emotions within it a\nresearch endeavor of significant importance. However, existing research on the\ncauses of emotions typically uses clause selection methods to locate the reason\nutterance, without providing a detailed explanation of the emotional causes. In\nthis paper, we propose a new task, \\textbf{M}ultimodal \\textbf{C}onversation\n\\textbf{E}motion \\textbf{C}ause \\textbf{E}xplanation (MCECE), aiming to\ngenerate a detailed explanation of the emotional cause to the target utterance\nwithin a multimodal conversation scenario. Building upon the MELD dataset, we\ndevelop a new dataset (ECEM) that integrates video clips with detailed\nexplanations of character emotions, facilitating an in-depth examination of the\ncausal factors behind emotional expressions in multimodal conversations.A novel\napproach, FAME-Net, is further proposed, that harnesses the power of Large\nLanguage Models (LLMs) to analyze visual data and accurately interpret the\nemotions conveyed through facial expressions in videos. By exploiting the\ncontagion effect of facial emotions, FAME-Net effectively captures the\nemotional causes of individuals engaged in conversations. Our experimental\nresults on the newly constructed dataset show that FAME-Net significantly\noutperforms several excellent large language model baselines. Code and dataset\nare available at \\url{https://github.com/3222345200/ECEMdataset.git}",
      "tldr_zh": "本研究针对多模态对话中的情绪原因分析，提出一个新任务Multimodal Conversation Emotion Cause Explanation (MCECE)，旨在为目标话语生成详细的情感原因解释，以弥补现有方法仅限于子句选择的局限性。基于MELD数据集，研究者构建了新数据集ECEM，整合了视频剪辑和情感解释，以深入探讨多模态对话中情绪表达的因果因素。研究还引入了FAME-Net方法，利用Large Language Models (LLMs)分析视觉数据和面部表情的传染效应，准确捕获对话参与者的情绪原因。在ECEM数据集上的实验显示，FAME-Net显著优于多个LLM基线模型，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02430v1",
      "published_date": "2024-11-01 09:16:30 UTC",
      "updated_date": "2024-11-01 09:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:09:38.911810"
    },
    {
      "arxiv_id": "2411.11853v3",
      "title": "Chat Bankman-Fried: an Exploration of LLM Alignment in Finance",
      "title_zh": "Chat Bankman-Fried：LLM",
      "authors": [
        "Claudia Biancotti",
        "Carolina Camassa",
        "Andrea Coletta",
        "Oliver Giudice",
        "Aldo Glielmo"
      ],
      "abstract": "Advancements in large language models (LLMs) have renewed concerns about AI\nalignment - the consistency between human and AI goals and values. As various\njurisdictions enact legislation on AI safety, the concept of alignment must be\ndefined and measured across different domains. This paper proposes an\nexperimental framework to assess whether LLMs adhere to ethical and legal\nstandards in the relatively unexplored context of finance. We prompt twelve\nLLMs to impersonate the CEO of a financial institution and test their\nwillingness to misuse customer assets to repay outstanding corporate debt.\nBeginning with a baseline configuration, we adjust preferences, incentives and\nconstraints, analyzing the impact of each adjustment with logistic regression.\nOur findings reveal significant heterogeneity in the baseline propensity for\nunethical behavior of LLMs. Factors such as risk aversion, profit expectations,\nand regulatory environment consistently influence misalignment in ways\npredicted by economic theory, although the magnitude of these effects varies\nacross LLMs. This paper highlights both the benefits and limitations of\nsimulation-based, ex post safety testing. While it can inform financial\nauthorities and institutions aiming to ensure LLM safety, there is a clear\ntrade-off between generality and cost.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）的对齐问题（AI alignment），即LLMs 是否在金融领域符合人类伦理和法律标准。研究者提出一个实验框架，让12个LLMs模拟金融机构CEO，测试其是否愿意滥用客户资产偿还债务，并通过调整风险厌恶、利润预期和监管环境等因素，使用logistic regression分析影响。结果显示，LLMs在基线配置下表现出显著的异质性不道德行为倾向，而经济理论预测的因素（如风险厌恶）确实影响对齐，但效果因模型而异。该框架突显了模拟测试的益处，如为金融监管提供指导，同时也暴露了泛化与成本的权衡。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "q-fin.GN"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11853v3",
      "published_date": "2024-11-01 08:56:17 UTC",
      "updated_date": "2025-02-25 15:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:09:51.073021"
    },
    {
      "arxiv_id": "2411.00904v1",
      "title": "Similarity and Dissimilarity Guided Co-association Matrix Construction for Ensemble Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Zhang",
        "Yuheng Jia",
        "Mofei Song",
        "Ran Wang"
      ],
      "abstract": "Ensemble clustering aggregates multiple weak clusterings to achieve a more\naccurate and robust consensus result. The Co-Association matrix (CA matrix)\nbased method is the mainstream ensemble clustering approach that constructs the\nsimilarity relationships between sample pairs according the weak clustering\npartitions to generate the final clustering result. However, the existing\nmethods neglect that the quality of cluster is related to its size, i.e., a\ncluster with smaller size tends to higher accuracy. Moreover, they also do not\nconsider the valuable dissimilarity information in the base clusterings which\ncan reflect the varying importance of sample pairs that are completely\ndisconnected. To this end, we propose the Similarity and Dissimilarity Guided\nCo-association matrix (SDGCA) to achieve ensemble clustering. First, we\nintroduce normalized ensemble entropy to estimate the quality of each cluster,\nand construct a similarity matrix based on this estimation. Then, we employ the\nrandom walk to explore high-order proximity of base clusterings to construct a\ndissimilarity matrix. Finally, the adversarial relationship between the\nsimilarity matrix and the dissimilarity matrix is utilized to construct a\npromoted CA matrix for ensemble clustering. We compared our method with 13\nstate-of-the-art methods across 12 datasets, and the results demonstrated the\nsuperiority clustering ability and robustness of the proposed approach. The\ncode is available at https://github.com/xuz2019/SDGCA.",
      "tldr_zh": "论文提出了一种新的 Ensemble Clustering 方法，名为 SDGCA，通过整合样本对的相似性和不相似性信息来改进 Co-Association matrix (CA matrix) 的构建，以解决现有方法忽略簇大小质量和不相似性价值的局限性。该方法首先利用 normalized ensemble entropy 估计每个簇的质量构建相似性矩阵，然后通过随机游走探索基聚类的更高阶接近度构建不相似性矩阵，最后基于二者之间的对抗关系生成优化的 CA matrix 用于最终聚类。在12个数据集上与13种最先进方法比较，SDGCA 显示出显著的聚类性能和稳健性提升，相关代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00904v1",
      "published_date": "2024-11-01 08:10:28 UTC",
      "updated_date": "2024-11-01 08:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:10:04.322524"
    },
    {
      "arxiv_id": "2411.00437v2",
      "title": "E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Jiang",
        "Zilong Xie",
        "Wei Zhang",
        "Yun Fang",
        "Shuai Pan"
      ],
      "abstract": "Retrieval-augmented generation methods often neglect the quality of content\nretrieved from external knowledge bases, resulting in irrelevant information or\npotential misinformation that negatively affects the generation results of\nlarge language models. In this paper, we propose an end-to-end model with\nadaptive filtering for retrieval-augmented generation (E2E-AFG), which\nintegrates answer existence judgment and text generation into a single\nend-to-end framework. This enables the model to focus more effectively on\nrelevant content while reducing the influence of irrelevant information and\ngenerating accurate answers. We evaluate E2E-AFG on six representative\nknowledge-intensive language datasets, and the results show that it\nconsistently outperforms baseline models across all tasks, demonstrating the\neffectiveness and robustness of the proposed approach.",
      "tldr_zh": "该研究针对检索增强生成（Retrieval-Augmented Generation）中的问题，提出了一种端到端模型E2E-AFG，以解决外部知识库检索内容质量低下导致的无关信息和错误信息影响。E2E-AFG整合了答案存在判断和文本生成功能，通过自适应过滤（adaptive filtering）机制，帮助模型更有效地聚焦相关内容并减少干扰。实验结果显示，该模型在六个知识密集型语言数据集上均优于基线模型，证明了其在提升生成准确性和鲁棒性方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 3 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.00437v2",
      "published_date": "2024-11-01 08:02:09 UTC",
      "updated_date": "2025-05-08 07:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:10:14.752893"
    },
    {
      "arxiv_id": "2411.00431v1",
      "title": "Integrating Fuzzy Logic into Deep Symbolic Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Wout Gerdes",
        "Erman Acar"
      ],
      "abstract": "Credit card fraud detection is a critical concern for financial institutions,\nintensified by the rise of contactless payment technologies. While deep\nlearning models offer high accuracy, their lack of explainability poses\nsignificant challenges in financial settings. This paper explores the\nintegration of fuzzy logic into Deep Symbolic Regression (DSR) to enhance both\nperformance and explainability in fraud detection. We investigate the\neffectiveness of different fuzzy logic implications, specifically\n{\\L}ukasiewicz, G\\\"odel, and Product, in handling the complexity and\nuncertainty of fraud detection datasets. Our analysis suggest that the\n{\\L}ukasiewicz implication achieves the highest F1-score and overall accuracy,\nwhile the Product implication offers a favorable balance between performance\nand explainability. Despite having a performance lower than state-of-the-art\n(SOTA) models due to information loss in data transformation, our approach\nprovides novelty and insights into into integrating fuzzy logic into DSR for\nfraud detection, providing a comprehensive comparison between different\nimplications and methods.",
      "tldr_zh": "本研究探讨了将模糊逻辑(Fuzzy Logic)集成到Deep Symbolic Regression (DSR)中，以提升信用卡欺诈检测的性能和可解释性。研究者评估了不同模糊逻辑含义，包括Łukasiewicz、Gödel和Product，处理欺诈数据集中的复杂性和不确定性。结果显示，Łukasiewicz含义在F1-score和整体准确率上表现最佳，而Product含义在性能和可解释性之间提供了良好平衡。尽管该方法在数据转换过程中存在信息损失，导致性能低于最先进(SOTA)模型，但它提供了新颖见解，并对各种含义进行了全面比较。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 1 figure, published for XAI FIN 24\n  https://easychair.org/cfp/xaifin2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00431v1",
      "published_date": "2024-11-01 07:55:17 UTC",
      "updated_date": "2024-11-01 07:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:10:26.646787"
    },
    {
      "arxiv_id": "2411.00427v1",
      "title": "DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems",
      "title_zh": "DARD：一种多智能体方法，用于任务导向对话系统",
      "authors": [
        "Aman Gupta",
        "Anirudh Ravichandran",
        "Ziji Zhang",
        "Swair Shah",
        "Anurag Beniwal",
        "Narayanan Sadagopan"
      ],
      "abstract": "Task-oriented dialogue systems are essential for applications ranging from\ncustomer service to personal assistants and are widely used across various\nindustries. However, developing effective multi-domain systems remains a\nsignificant challenge due to the complexity of handling diverse user intents,\nentity types, and domain-specific knowledge across several domains. In this\nwork, we propose DARD (Domain Assigned Response Delegation), a multi-agent\nconversational system capable of successfully handling multi-domain dialogs.\nDARD leverages domain-specific agents, orchestrated by a central dialog manager\nagent. Our extensive experiments compare and utilize various agent modeling\napproaches, combining the strengths of smaller fine-tuned models (Flan-T5-large\n& Mistral-7B) with their larger counterparts, Large Language Models (LLMs)\n(Claude Sonnet 3.0). We provide insights into the strengths and limitations of\neach approach, highlighting the benefits of our multi-agent framework in terms\nof flexibility and composability. We evaluate DARD using the well-established\nMultiWOZ benchmark, achieving state-of-the-art performance by improving the\ndialogue inform rate by 6.6% and the success rate by 4.1% over the\nbest-performing existing approaches. Additionally, we discuss various annotator\ndiscrepancies and issues within the MultiWOZ dataset and its evaluation system.",
      "tldr_zh": "本论文提出DARD（Domain Assigned Response Delegation），一种多智能体方法，用于任务导向对话系统，以处理多域对话中的用户意图、实体类型和领域知识。该框架通过域特定代理和中央对话管理器协调，结合小模型（如Flan-T5-large和Mistral-7B）与大语言模型（LLMs，如Claude Sonnet 3.0）的优势，提高系统的灵活性和可组合性。在MultiWOZ基准测试中，DARD实现了state-of-the-art性能，提升对话信息率6.6%和成功率4.1%。此外，论文还讨论了MultiWOZ数据集中的annotator差异和评估问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00427v1",
      "published_date": "2024-11-01 07:50:19 UTC",
      "updated_date": "2024-11-01 07:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:10:40.785497"
    },
    {
      "arxiv_id": "2411.00418v2",
      "title": "Self-Evolved Reward Learning for LLMs",
      "title_zh": "LLMs 的自我演化奖励学习",
      "authors": [
        "Chenghua Huang",
        "Zhizhen Fan",
        "Lu Wang",
        "Fangkai Yang",
        "Pu Zhao",
        "Zeqi Lin",
        "Qingwei Lin",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for\naligning language models with human preferences, playing a pivotal role in the\nsuccess of conversational models like GPT-4, ChatGPT, and Llama 2. A core\nchallenge in employing RLHF lies in training a reliable reward model (RM),\nwhich relies on high-quality labels typically provided by human experts or\nadvanced AI system. These methods can be costly and may introduce biases that\naffect the language model's responses. As language models improve, human input\nmay become less effective in further enhancing their performance. In this\npaper, we propose Self-Evolved Reward Learning (SER), a novel approach where\nthe RM generates additional training data to iteratively improve itself. We\nconducted extensive experiments on multiple datasets such as HH-RLHF and\nUltraFeedback, using models like Mistral and Llama 3, and compare SER against\nvarious baselines. Our results demonstrate that even with limited\nhuman-annotated data, learning from self-feedback can robustly enhance RM\nperformance, thereby boosting the capabilities of large language models (LLMs).",
      "tldr_zh": "这篇论文针对强化学习从人类反馈（RLHF）中训练奖励模型（RM）的挑战，提出了一种名为 Self-Evolved Reward Learning (SER) 的新方法。SER 允许 RM 通过生成额外训练数据来迭代自我改进，从而减少对昂贵的人类标注数据的依赖，并在实验中证明了其鲁棒性。在 HH-RLHF 和 UltraFeedback 等数据集上，使用 Mistral 和 Llama 3 模型进行测试，结果显示 SER 显著提升了 RM 和大型语言模型（LLMs）的性能，即使人类数据有限也能实现稳健优化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages,6 figures,Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.00418v2",
      "published_date": "2024-11-01 07:29:03 UTC",
      "updated_date": "2025-02-28 03:37:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:10:51.888450"
    },
    {
      "arxiv_id": "2411.00414v1",
      "title": "On the Opportunities of Large Language Models for Programming Process Data",
      "title_zh": "翻译失败",
      "authors": [
        "John Edwards",
        "Arto Hellas",
        "Juho Leinonen"
      ],
      "abstract": "Computing educators and researchers have used programming process data to\nunderstand how programs are constructed and what sorts of problems students\nstruggle with. Although such data shows promise for using it for feedback,\nfully automated programming process feedback systems have still been an\nunder-explored area. The recent emergence of large language models (LLMs) have\nyielded additional opportunities for researchers in a wide variety of fields.\nLLMs are efficient at transforming content from one format to another,\nleveraging the body of knowledge they have been trained with in the process. In\nthis article, we discuss opportunities of using LLMs for analyzing programming\nprocess data. To complement our discussion, we outline a case study where we\nhave leveraged LLMs for automatically summarizing the programming process and\nfor creating formative feedback on the programming process. Overall, our\ndiscussion and findings highlight that the computing education research and\npractice community is again one step closer to automating formative programming\nprocess-focused feedback.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在分析编程过程数据方面的机会，旨在帮助计算教育者理解学生编程构建过程及其面临的挑战。作者强调LLMs可高效转换数据格式并利用其训练知识，提供自动总结和形成性反馈；通过一个案例研究，展示了LLMs如何自动总结编程过程并生成针对性反馈。总体而言，这项研究推动了编程过程反馈的自动化，促进计算教育实践的进步。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.3; E.m"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.00414v1",
      "published_date": "2024-11-01 07:20:01 UTC",
      "updated_date": "2024-11-01 07:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:11:02.867990"
    },
    {
      "arxiv_id": "2411.00902v1",
      "title": "Differentiable architecture search with multi-dimensional attention for spiking neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yilei Man",
        "Linhai Xie",
        "Shushan Qiao",
        "Yumei Zhou",
        "Delong Shang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have gained enormous popularity in the field\nof artificial intelligence due to their low power consumption. However, the\nmajority of SNN methods directly inherit the structure of Artificial Neural\nNetworks (ANN), usually leading to sub-optimal model performance in SNNs. To\nalleviate this problem, we integrate Neural Architecture Search (NAS) method\nand propose Multi-Attention Differentiable Architecture Search (MA-DARTS) to\ndirectly automate the search for the optimal network structure of SNNs.\nInitially, we defined a differentiable two-level search space and conducted\nexperiments within micro architecture under a fixed layer. Then, we\nincorporated a multi-dimensional attention mechanism and implemented the\nMA-DARTS algorithm in this search space. Comprehensive experiments demonstrate\nour model achieves state-of-the-art performance on classification compared to\nother methods under the same parameters with 94.40% accuracy on CIFAR10 dataset\nand 76.52% accuracy on CIFAR100 dataset. Additionally, we monitored and\nassessed the number of spikes (NoS) in each cell during the whole experiment.\nNotably, the number of spikes of the whole model stabilized at approximately\n110K in validation and 100k in training on datasets.",
      "tldr_zh": "本研究针对Spiking Neural Networks (SNNs) 的性能问题，提出了一种Multi-Attention Differentiable Architecture Search (MA-DARTS) 方法，通过整合Neural Architecture Search (NAS) 来自动优化SNNs 的网络结构，以克服直接继承Artificial Neural Networks (ANN) 结构导致的子最优性能。MA-DARTS 定义了一个可微的两级搜索空间，并引入多维注意力机制，在固定层下的微架构中进行实验。实验结果显示，该方法在CIFAR10 数据集上达到94.40% 的准确率，在CIFAR100 数据集上达到76.52%，优于其他同参数方法，同时尖峰数（Number of Spikes, NoS）在验证集稳定约110K，在训练集约100K，展示了其高效性和状态-of-the-art 性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00902v1",
      "published_date": "2024-11-01 07:18:32 UTC",
      "updated_date": "2024-11-01 07:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:11:15.563230"
    },
    {
      "arxiv_id": "2411.00412v3",
      "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Bohan Lyu",
        "Yadi Cao",
        "Duncan Watson-Parris",
        "Leon Bergen",
        "Taylor Berg-Kirkpatrick",
        "Rose Yu"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate promising capabilities in solving\nsimple scientific problems but, even with domain-specific fine-tuning, often\nproduce hallucinations for complex ones. While integrating LLMs with tools can\nmitigate this reliability issue, models finetuned on tool usage only often\nover-rely on them, incurring unnecessary costs from resource-intensive\nscientific tools even for simpler problems. Inspired by how human experts\nassess the complexity of the problem before choosing the solutions, we propose\na novel two-component fine-tuning method, Adapting While Learning (AWL). In the\nfirst component, World Knowledge Learning (WKL), LLMs internalize scientific\nknowledge by learning from tools-generated solutions. In the second component,\nTool Usage Adaptation (TUA), we classify questions as easy or hard based on the\nWKL-trained model's accuracy, and train it to maintain direct reasoning for\nsimple problems while switching to tools for challenging ones. We validate our\nmethod on 6 scientific benchmark datasets in climate science, epidemiology, and\nmathematics. Compared to the base 8B model, our trained models achieve 28.27%\nhigher answer accuracy and 13.76% better tool usage accuracy, even surpassing\nstate-of-the-art models including GPT-4 and Claude-3.5 on 4 custom-created\ndatasets.",
      "tldr_zh": "该论文提出了一种名为 Adapting While Learning (AWL) 的微调方法，以提升大语言模型 (LLMs) 在科学问题上的可靠性和效率。AWL 包括两个组件：World Knowledge Learning (WKL)，让 LLMs 通过工具生成的解决方案内化科学知识；以及 Tool Usage Adaptation (TUA)，通过分类问题难度，训练模型对简单问题直接推理，而对复杂问题使用工具，以避免过度依赖。实验在气候科学、流行病学和数学的 6 个基准数据集上验证，结果显示，AWL 训练的模型比基础 8B 模型答案准确率提高了 28.27%，工具使用准确率提高了 13.76%，甚至在 4 个自定义数据集上超过了 GPT-4 和 Claude-3.5。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00412v3",
      "published_date": "2024-11-01 07:18:31 UTC",
      "updated_date": "2025-02-06 04:18:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:11:28.466127"
    },
    {
      "arxiv_id": "2411.00401v2",
      "title": "Statistical Guarantees for Lifelong Reinforcement Learning using PAC-Bayes Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Zhang",
        "Chris Chow",
        "Yasi Zhang",
        "Yanchao Sun",
        "Haochen Zhang",
        "Eric Hanchen Jiang",
        "Han Liu",
        "Furong Huang",
        "Yuchen Cui",
        "Oscar Hernan Madrid Padilla"
      ],
      "abstract": "Lifelong reinforcement learning (RL) has been developed as a paradigm for\nextending single-task RL to more realistic, dynamic settings. In lifelong RL,\nthe \"life\" of an RL agent is modeled as a stream of tasks drawn from a task\ndistribution. We propose EPIC (Empirical PAC-Bayes that Improves Continuously),\na novel algorithm designed for lifelong RL using PAC-Bayes theory. EPIC learns\na shared policy distribution, referred to as the world policy, which enables\nrapid adaptation to new tasks while retaining valuable knowledge from previous\nexperiences. Our theoretical analysis establishes a relationship between the\nalgorithm's generalization performance and the number of prior tasks preserved\nin memory. We also derive the sample complexity of EPIC in terms of RL regret.\nExtensive experiments on a variety of environments demonstrate that EPIC\nsignificantly outperforms existing methods in lifelong RL, offering both\ntheoretical guarantees and practical efficacy through the use of the world\npolicy.",
      "tldr_zh": "本研究提出 EPIC 算法，利用 PAC-Bayes 理论来处理终身强化学习（Lifelong RL），旨在帮助代理在任务流中快速适应新任务并保留先前知识，通过学习一个共享的 world policy 实现持续改进。\nEPIC 的理论分析建立了算法的泛化性能与内存中先前任务数量的关系，并推导了其在 RL regret 方面的样本复杂度，提供统计保证。\n实验结果表明，EPIC 在多种环境中显著优于现有方法，展示了其实际效能和理论可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 68Q32, 68T20",
        "I.2.6; I.2.8; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures, accepted at AISTATS 2025 (PMLR Vol 258), paper ID\n  9417",
      "pdf_url": "http://arxiv.org/pdf/2411.00401v2",
      "published_date": "2024-11-01 07:01:28 UTC",
      "updated_date": "2025-05-16 09:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:11:39.880561"
    },
    {
      "arxiv_id": "2411.00394v1",
      "title": "Right this way: Can VLMs Guide Us to See More to Answer Questions?",
      "title_zh": "翻译失败",
      "authors": [
        "Li Liu",
        "Diji Yang",
        "Sijia Zhong",
        "Kalyana Suma Sree Tholeti",
        "Lei Ding",
        "Yi Zhang",
        "Leilani H. Gilpin"
      ],
      "abstract": "In question-answering scenarios, humans can assess whether the available\ninformation is sufficient and seek additional information if necessary, rather\nthan providing a forced answer. In contrast, Vision Language Models (VLMs)\ntypically generate direct, one-shot responses without evaluating the\nsufficiency of the information. To investigate this gap, we identify a critical\nand challenging task in the Visual Question Answering (VQA) scenario: can VLMs\nindicate how to adjust an image when the visual information is insufficient to\nanswer a question? This capability is especially valuable for assisting\nvisually impaired individuals who often need guidance to capture images\ncorrectly. To evaluate this capability of current VLMs, we introduce a\nhuman-labeled dataset as a benchmark for this task. Additionally, we present an\nautomated framework that generates synthetic training data by simulating\n``where to know'' scenarios. Our empirical results show significant performance\nimprovements in mainstream VLMs when fine-tuned with this synthetic data. This\nstudy demonstrates the potential to narrow the gap between information\nassessment and acquisition in VLMs, bringing their performance closer to\nhumans.",
      "tldr_zh": "本文研究了 Vision Language Models (VLMs) 在 Visual Question Answering (VQA) 任务中的局限性，即无法评估视觉信息是否足够并主动指导图像调整。研究者引入了一个人类标注的数据集作为基准，并开发了一个自动框架，通过模拟“where to know”场景生成合成训练数据。实验结果显示，VLMs 通过这些数据细调后性能显著提升，有望缩小与人类的差距，尤其在辅助视力受损者方面。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00394v1",
      "published_date": "2024-11-01 06:43:54 UTC",
      "updated_date": "2024-11-01 06:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:11:52.152099"
    },
    {
      "arxiv_id": "2411.00393v4",
      "title": "Advantages of Neural Population Coding for Deep Learning",
      "title_zh": "神经群体编码在深度学习中的优势",
      "authors": [
        "Heiko Hoffmann"
      ],
      "abstract": "Scalar variables, e.g., the orientation of a shape in an image, are commonly\npredicted using a single output neuron in a neural network. In contrast, the\nmammalian cortex represents variables with a population of neurons. In this\npopulation code, each neuron is most active at its preferred value and shows\npartial activity for other values. Here, we investigate the benefit of using a\npopulation code for the output layer of a neural network. We compare population\ncodes against single-neuron outputs and one-hot vectors. First, we show\ntheoretically and in experiments with synthetic data that population codes\nimprove robustness to input noise in networks of stacked linear layers. Second,\nwe demonstrate the benefit of using population codes to encode ambiguous\noutputs, such as the pose of symmetric objects. Using the T-LESS dataset of\nfeature-less real-world objects, we show that population codes improve the\naccuracy of predicting 3D object orientation from image input.",
      "tldr_zh": "这篇论文探讨了使用神经元群体编码(population codes)作为神经网络输出层的优势，与传统单个神经元输出和one-hot vectors相比。研究通过理论分析和实验证明，population codes能提高网络对输入噪声的鲁棒性，尤其在堆叠线性层的网络中。实验结果显示，在处理模糊输出如对称物体姿态时，population codes显著提升了准确性，并在T-LESS数据集上从图像输入预测3D物体方向的性能上取得了改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00393v4",
      "published_date": "2024-11-01 06:40:47 UTC",
      "updated_date": "2024-11-13 09:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:12:04.210860"
    },
    {
      "arxiv_id": "2411.00392v1",
      "title": "Preventing Dimensional Collapse in Self-Supervised Learning via Orthogonality Regularization",
      "title_zh": "通过正交正则化防止自监督学习中的维度坍缩",
      "authors": [
        "Junlin He",
        "Jinxiao Du",
        "Wei Ma"
      ],
      "abstract": "Self-supervised learning (SSL) has rapidly advanced in recent years,\napproaching the performance of its supervised counterparts through the\nextraction of representations from unlabeled data. However, dimensional\ncollapse, where a few large eigenvalues dominate the eigenspace, poses a\nsignificant obstacle for SSL. When dimensional collapse occurs on features\n(e.g. hidden features and representations), it prevents features from\nrepresenting the full information of the data; when dimensional collapse occurs\non weight matrices, their filters are self-related and redundant, limiting\ntheir expressive power. Existing studies have predominantly concentrated on the\ndimensional collapse of representations, neglecting whether this can\nsufficiently prevent the dimensional collapse of the weight matrices and hidden\nfeatures. To this end, we first time propose a mitigation approach employing\northogonal regularization (OR) across the encoder, targeting both convolutional\nand linear layers during pretraining. OR promotes orthogonality within weight\nmatrices, thus safeguarding against the dimensional collapse of weight\nmatrices, hidden features, and representations. Our empirical investigations\ndemonstrate that OR significantly enhances the performance of SSL methods\nacross diverse benchmarks, yielding consistent gains with both CNNs and\nTransformer-based architectures.",
      "tldr_zh": "自监督学习（Self-Supervised Learning, SSL）在从无标签数据中提取表示方面取得了进展，但 dimensional collapse 问题会导致特征空间主导特征值过大，限制数据信息表示和权重矩阵的表达能力。现有研究主要关注表示的维度坍缩，而忽略了权重矩阵和隐藏特征的潜在影响。针对此，本文首次提出 orthogonality regularization (OR) 方法，在预训练期间应用于编码器的卷积和线性层，以促进权重矩阵的正交性，从而全面防止 dimensional collapse。实验结果显示，OR 显著提升了 SSL 方法在各种基准上的性能，并适用于 CNNs 和 Transformer-based 架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by NeurIPS 2024 as a poster",
      "pdf_url": "http://arxiv.org/pdf/2411.00392v1",
      "published_date": "2024-11-01 06:39:18 UTC",
      "updated_date": "2024-11-01 06:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:12:15.988094"
    },
    {
      "arxiv_id": "2411.00390v1",
      "title": "MetaMetrics-MT: Tuning Meta-Metrics for Machine Translation via Human Preference Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "David Anugraha",
        "Garry Kuwanto",
        "Lucky Susanto",
        "Derry Tanti Wijaya",
        "Genta Indra Winata"
      ],
      "abstract": "We present MetaMetrics-MT, an innovative metric designed to evaluate machine\ntranslation (MT) tasks by aligning closely with human preferences through\nBayesian optimization with Gaussian Processes. MetaMetrics-MT enhances existing\nMT metrics by optimizing their correlation with human judgments. Our\nexperiments on the WMT24 metric shared task dataset demonstrate that\nMetaMetrics-MT outperforms all existing baselines, setting a new benchmark for\nstate-of-the-art performance in the reference-based setting. Furthermore, it\nachieves comparable results to leading metrics in the reference-free setting,\noffering greater efficiency.",
      "tldr_zh": "本研究提出MetaMetrics-MT，一种创新的机器翻译（MT）评估指标，通过高斯过程的贝叶斯优化来校准指标，使其更好地与人类偏好对齐，从而提升现有MT指标与人类判断的相关性。在WMT24指标共享任务数据集上的实验显示，MetaMetrics-MT在参考-based设置中超越了所有基线指标，设定了新基准，并在参考-free设置中与领先指标相当，同时提供更高的效率。整体而言，该方法为MT评估提供了更可靠和高效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.00390v1",
      "published_date": "2024-11-01 06:34:30 UTC",
      "updated_date": "2024-11-01 06:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:12:26.614668"
    },
    {
      "arxiv_id": "2411.00899v1",
      "title": "Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhi Gao",
        "Zhichao Hou",
        "Han Xu",
        "Xiaorui Liu"
      ],
      "abstract": "Implicit models such as Deep Equilibrium Models (DEQs) have emerged as\npromising alternative approaches for building deep neural networks. Their\ncertified robustness has gained increasing research attention due to security\nconcerns. Existing certified defenses for DEQs employing deterministic\ncertification methods such as interval bound propagation and Lipschitz-bounds\ncan not certify on large-scale datasets. Besides, they are also restricted to\nspecific forms of DEQs. In this paper, we provide the first randomized\nsmoothing certified defense for DEQs to solve these limitations. Our study\nreveals that simply applying randomized smoothing to certify DEQs provides\ncertified robustness generalized to large-scale datasets but incurs extremely\nexpensive computation costs. To reduce computational redundancy, we propose a\nnovel Serialized Randomized Smoothing (SRS) approach that leverages historical\ninformation. Additionally, we derive a new certified radius estimation for SRS\nto theoretically ensure the correctness of our algorithm. Extensive experiments\nand ablation studies on image recognition demonstrate that our algorithm can\nsignificantly accelerate the certification of DEQs by up to 7x almost without\nsacrificing the certified accuracy. Our code is available at\nhttps://github.com/WeizhiGao/Serialized-Randomized-Smoothing.",
      "tldr_zh": "本研究针对 Deep Equilibrium Models (DEQs) 的认证鲁棒性问题，提出了一种基于随机平滑的首个认证防御方法，以解决现有确定性方法在大规模数据集上的局限性。论文引入 Serialized Randomized Smoothing (SRS) 技术，利用历史信息减少计算冗余，并推导了新的认证半径估计来确保算法的理论正确性。在图像识别实验中，SRS 显著加速了 DEQs 的认证过程，最多可达 7 倍，同时几乎不牺牲认证准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 25 figures, NeurIPS 2024 accepted",
      "pdf_url": "http://arxiv.org/pdf/2411.00899v1",
      "published_date": "2024-11-01 06:14:11 UTC",
      "updated_date": "2024-11-01 06:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:12:40.487785"
    },
    {
      "arxiv_id": "2411.00372v1",
      "title": "Generalizability of Memorization Neural Networks",
      "title_zh": "记忆化神经网络的泛化性",
      "authors": [
        "Lijia Yu",
        "Xiao-Shan Gao",
        "Lijun Zhang",
        "Yibo Miao"
      ],
      "abstract": "The neural network memorization problem is to study the expressive power of\nneural networks to interpolate a finite dataset. Although memorization is\nwidely believed to have a close relationship with the strong generalizability\nof deep learning when using over-parameterized models, to the best of our\nknowledge, there exists no theoretical study on the generalizability of\nmemorization neural networks. In this paper, we give the first theoretical\nanalysis of this topic. Since using i.i.d. training data is a necessary\ncondition for a learning algorithm to be generalizable, memorization and its\ngeneralization theory for i.i.d. datasets are developed under mild conditions\non the data distribution. First, algorithms are given to construct memorization\nnetworks for an i.i.d. dataset, which have the smallest number of parameters\nand even a constant number of parameters. Second, we show that, in order for\nthe memorization networks to be generalizable, the width of the network must be\nat least equal to the dimension of the data, which implies that the existing\nmemorization networks with an optimal number of parameters are not\ngeneralizable. Third, a lower bound for the sample complexity of general\nmemorization algorithms and the exact sample complexity for memorization\nalgorithms with constant number of parameters are given. It is also shown that\nthere exist data distributions such that, to be generalizable for them, the\nmemorization network must have an exponential number of parameters in the data\ndimension. Finally, an efficient and generalizable memorization algorithm is\ngiven when the number of training samples is greater than the efficient\nmemorization sample complexity of the data distribution.",
      "tldr_zh": "这篇论文首次对记忆化神经网络（memorization neural networks）的泛化能力进行了理论分析，聚焦于其在独立同分布（i.i.d.）数据集下的表现。研究者开发了算法来构建具有最小参数数甚至常量参数数的记忆化网络，但证明了网络宽度必须至少等于数据维度才能实现泛化，这意味着现有最优参数网络可能不泛化。论文还给出了泛化算法的样本复杂度下界，并提出了一种高效的记忆化算法，当训练样本数超过数据分布的样本复杂度时，能够确保泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00372v1",
      "published_date": "2024-11-01 05:18:46 UTC",
      "updated_date": "2024-11-01 05:18:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:12:52.447154"
    },
    {
      "arxiv_id": "2411.00898v1",
      "title": "Replace-then-Perturb: Targeted Adversarial Attacks With Visual Reasoning for Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jonggyu Jang",
        "Hyeonsu Lyu",
        "Jungyeon Koh",
        "Hyun Jong Yang"
      ],
      "abstract": "The conventional targeted adversarial attacks add a small perturbation to an\nimage to make neural network models estimate the image as a predefined target\nclass, even if it is not the correct target class. Recently, for\nvisual-language models (VLMs), the focus of targeted adversarial attacks is to\ngenerate a perturbation that makes VLMs answer intended target text outputs.\nFor example, they aim to make a small perturbation on an image to make VLMs'\nanswers change from \"there is an apple\" to \"there is a baseball.\" However,\nanswering just intended text outputs is insufficient for tricky questions like\n\"if there is a baseball, tell me what is below it.\" This is because the target\nof the adversarial attacks does not consider the overall integrity of the\noriginal image, thereby leading to a lack of visual reasoning. In this work, we\nfocus on generating targeted adversarial examples with visual reasoning against\nVLMs. To this end, we propose 1) a novel adversarial attack procedure --\nnamely, Replace-then-Perturb and 2) a contrastive learning-based adversarial\nloss -- namely, Contrastive-Adv. In Replace-then-Perturb, we first leverage a\ntext-guided segmentation model to find the target object in the image. Then, we\nget rid of the target object and inpaint the empty space with the desired\nprompt. By doing this, we can generate a target image corresponding to the\ndesired prompt, while maintaining the overall integrity of the original image.\nFurthermore, in Contrastive-Adv, we design a novel loss function to obtain\nbetter adversarial examples. Our extensive benchmark results demonstrate that\nReplace-then-Perturb and Contrastive-Adv outperform the baseline adversarial\nattack algorithms. We note that the source code to reproduce the results will\nbe available.",
      "tldr_zh": "本研究针对视觉语言模型（Vision-Language Models, VLMs）的针对性对抗攻击问题，提出了一种新方法Replace-then-Perturb，以解决传统攻击忽略图像整体完整性和视觉推理的局限性。该方法首先使用文本引导分割模型识别并移除目标对象，然后通过图像修复技术以期望提示填充空缺部分，从而生成保持原图像完整性的对抗样本；同时，引入基于对比学习的损失函数Contrastive-Adv，以优化对抗样本的质量。实验结果显示，该方法在基准测试中优于现有基线算法，证明了其在生成更具视觉推理能力对抗示例方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figure",
      "pdf_url": "http://arxiv.org/pdf/2411.00898v1",
      "published_date": "2024-11-01 04:50:08 UTC",
      "updated_date": "2024-11-01 04:50:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:13:04.160837"
    },
    {
      "arxiv_id": "2411.00355v1",
      "title": "TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images",
      "title_zh": "翻译失败",
      "authors": [
        "Mengcheng Li",
        "Mingbao Lin",
        "Fei Chao",
        "Chia-Wen Lin",
        "Rongrong Ji"
      ],
      "abstract": "In this paper, we propose TextDestroyer, the first training- and\nannotation-free method for scene text destruction using a pre-trained diffusion\nmodel. Existing scene text removal models require complex annotation and\nretraining, and may leave faint yet recognizable text information, compromising\nprivacy protection and content concealment. TextDestroyer addresses these\nissues by employing a three-stage hierarchical process to obtain accurate text\nmasks. Our method scrambles text areas in the latent start code using a\nGaussian distribution before reconstruction. During the diffusion denoising\nprocess, self-attention key and value are referenced from the original latent\nto restore the compromised background. Latent codes saved at each inversion\nstep are used for replacement during reconstruction, ensuring perfect\nbackground restoration. The advantages of TextDestroyer include: (1) it\neliminates labor-intensive data annotation and resource-intensive training; (2)\nit achieves more thorough text destruction, preventing recognizable traces; and\n(3) it demonstrates better generalization capabilities, performing well on both\nreal-world scenes and generated images.",
      "tldr_zh": "本论文提出 TextDestroyer，一种无需训练和标注的扩散模型方法，用于从图像中彻底破坏场景文本，解决了现有模型可能遗留可识别痕迹的问题。该方法采用三阶段分层过程获取准确文本掩码，并在潜在起始代码中通过高斯分布扰乱文本区域，同时利用原始潜在的 self-attention key 和 value 恢复背景，确保完美重建。与传统方法相比，TextDestroyer 消除了繁重的数据标注和资源密集型训练需求，并展示了更好的泛化能力，在真实场景和生成图像上表现突出。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00355v1",
      "published_date": "2024-11-01 04:41:00 UTC",
      "updated_date": "2024-11-01 04:41:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:13:16.147261"
    },
    {
      "arxiv_id": "2411.04139v1",
      "title": "Diffusion-based Auction Mechanism for Efficient Resource Management in 6G-enabled Vehicular Metaverses",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Kang",
        "Yongju Tong",
        "Yue Zhong",
        "Junlong Chen",
        "Minrui Xu",
        "Dusit Niyato",
        "Runrong Deng",
        "Shiwen Mao"
      ],
      "abstract": "The rise of 6G-enable Vehicular Metaverses is transforming the automotive\nindustry by integrating immersive, real-time vehicular services through\nultra-low latency and high bandwidth connectivity. In 6G-enable Vehicular\nMetaverses, vehicles are represented by Vehicle Twins (VTs), which serve as\ndigital replicas of physical vehicles to support real-time vehicular\napplications such as large Artificial Intelligence (AI) model-based Augmented\nReality (AR) navigation, called VT tasks. VT tasks are resource-intensive and\nneed to be offloaded to ground Base Stations (BSs) for fast processing.\nHowever, high demand for VT tasks and limited resources of ground BSs, pose\nsignificant resource allocation challenges, particularly in densely populated\nurban areas like intersections. As a promising solution, Unmanned Aerial\nVehicles (UAVs) act as aerial edge servers to dynamically assist ground BSs in\nhandling VT tasks, relieving resource pressure on ground BSs. However, due to\nhigh mobility of UAVs, there exists information asymmetry regarding VT task\ndemands between UAVs and ground BSs, resulting in inefficient resource\nallocation of UAVs. To address these challenges, we propose a learning-based\nModified Second-Bid (MSB) auction mechanism to optimize resource allocation\nbetween ground BSs and UAVs by accounting for VT task latency and accuracy.\nMoreover, we design a diffusion-based reinforcement learning algorithm to\noptimize the price scaling factor, maximizing the total surplus of resource\nproviders and minimizing VT task latency. Finally, simulation results\ndemonstrate that the proposed diffusion-based MSB auction outperforms\ntraditional baselines, providing better resource distribution and enhanced\nservice quality for vehicular users.",
      "tldr_zh": "本研究针对6G-enabled Vehicular Metaverses中的资源管理挑战，提出了一种基于Diffusion的拍卖机制，以优化Vehicle Twins (VTs)任务的处理。论文指出，VTs任务资源密集且需卸载到Base Stations (BSs)，而Unmanned Aerial Vehicles (UAVs)可作为空中边缘服务器辅助BSs，但UAVs的高移动性导致信息不对称。作者设计了Modified Second-Bid (MSB)拍卖机制结合Diffusion-based强化学习算法，优化资源分配、降低VT任务延迟并最大化资源提供者总剩余值。模拟结果显示，该机制比传统基线提升了资源分布效率和服务质量。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04139v1",
      "published_date": "2024-11-01 04:34:54 UTC",
      "updated_date": "2024-11-01 04:34:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:13:28.941300"
    },
    {
      "arxiv_id": "2411.00897v1",
      "title": "Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Song Yu",
        "Xiaofei Xu",
        "Fangfei Xu",
        "Li Li"
      ],
      "abstract": "Although large language models perform well in understanding and responding\nto user intent, their performance in specialized domains such as Traditional\nChinese Medicine (TCM) remains limited due to lack of expertise. In addition,\nhigh-quality data related to TCM is scarce and difficult to obtain, making\nlarge language models ineffective in handling TCM tasks. In this work, we\npropose a framework to improve the performance of large language models for TCM\ntasks using only a small amount of data. First, we use medical case data for\nsupervised fine-tuning of the large model, making it initially capable of\nperforming TCM tasks. Subsequently, we further optimize the model's performance\nusing reinforcement learning from AI feedback (RLAIF) to align it with the\npreference data. The ablation study also demonstrated the performance gain is\nattributed to both supervised fine-tuning and the direct policy optimization.\nThe experimental results show that the model trained with a small amount of\ndata achieves a significant performance improvement on a representative TCM\ntask.",
      "tldr_zh": "这项研究针对大语言模型（Large Language Models）在中医（Traditional Chinese Medicine, TCM）领域的性能不足问题，提出了一种框架，使用少量数据提升其能力。首先，通过医疗案例数据进行监督微调（Supervised Fine-Tuning），使模型初步适应TCM任务；随后，利用强化学习从AI反馈（Reinforcement Learning from AI Feedback, RLAIF）进一步优化模型，以对齐偏好数据。消融实验证实，性能提升源于监督微调和直接策略优化；实验结果显示，该方法在典型TCM任务上实现了显著改进，即使基于少量数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00897v1",
      "published_date": "2024-11-01 04:19:55 UTC",
      "updated_date": "2024-11-01 04:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:13:40.004049"
    },
    {
      "arxiv_id": "2411.00349v2",
      "title": "Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review",
      "title_zh": "考察工作量证明区块链中对共识和激励系统的攻击：系统文献综述",
      "authors": [
        "Dinitha Wijewardhana",
        "Sugandima Vidanagamachchi",
        "Nalin Arachchilage"
      ],
      "abstract": "Cryptocurrencies have gained popularity due to their transparency, security,\nand accessibility compared to traditional financial systems, with Bitcoin,\nintroduced in 2009, leading the market. Bitcoin's security relies on blockchain\ntechnology - a decentralized ledger consisting of a consensus and an incentive\nmechanism. The consensus mechanism, Proof of Work (PoW), requires miners to\nsolve difficult cryptographic puzzles to add new blocks, while the incentive\nmechanism rewards them with newly minted bitcoins. However, as Bitcoin's\nacceptance grows, it faces increasing threats from attacks targeting these\nmechanisms, such as selfish mining, double-spending, and block withholding.\nThese attacks compromise security, efficiency, and reward distribution. Recent\nresearch shows that these attacks can be combined with each other or with\neither malicious strategies, such as network-layer attacks, or non-malicious\nstrategies, like honest mining. These combinations lead to more sophisticated\nattacks, increasing the attacker's success rates and profitability. Therefore,\nunderstanding and evaluating these attacks is essential for developing\neffective countermeasures and ensuring long-term security. This paper begins by\nexamining individual attacks executed in isolation and their profitability. It\nthen explores how combining these attacks with each other or with other\nmalicious and non-malicious strategies can enhance their overall effectiveness\nand profitability. The analysis further explores how the deployment of attacks\nsuch as selfish mining and block withholding by multiple competing mining pools\nagainst each other impacts their economic returns. Lastly, a set of design\nguidelines is provided, outlining areas future work should focus on to prevent\nor mitigate the identified threats.",
      "tldr_zh": "这篇论文通过系统文献综述，考察了Proof-of-Work (PoW) 区块链中针对共识机制和激励系统的攻击，包括selfish mining、double-spending和block withholding等。研究分析了这些攻击的独立执行及其盈利性，并探讨了将它们与其他恶意（如网络层攻击）或非恶意策略（如诚实挖掘）结合时，如何提升攻击者的成功率和经济回报。论文进一步评估了多方矿池竞争下这些攻击的影响，并提供了设计指南，旨在指导未来工作开发有效防范措施，以增强区块链的安全性和长期稳定性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00349v2",
      "published_date": "2024-11-01 04:18:42 UTC",
      "updated_date": "2024-11-11 13:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:13:52.349294"
    },
    {
      "arxiv_id": "2411.12747v1",
      "title": "A Survey of Financial AI: Architectures, Advances and Open Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Junhua Liu"
      ],
      "abstract": "Financial AI empowers sophisticated approaches to financial market\nforecasting, portfolio optimization, and automated trading. This survey\nprovides a systematic analysis of these developments across three primary\ndimensions: predictive models that capture complex market dynamics,\ndecision-making frameworks that optimize trading and investment strategies, and\nknowledge augmentation systems that leverage unstructured financial\ninformation. We examine significant innovations including foundation models for\nfinancial time series, graph-based architectures for market relationship\nmodeling, and hierarchical frameworks for portfolio optimization. Analysis\nreveals crucial trade-offs between model sophistication and practical\nconstraints, particularly in high-frequency trading applications. We identify\ncritical gaps and open challenges between theoretical advances and industrial\nimplementation, outlining open challenges and opportunities for improving both\nmodel performance and practical applicability.",
      "tldr_zh": "这篇调查论文系统分析了Financial AI在市场预测、投资组合优化和自动交易中的应用，涵盖了预测模型、决策框架和知识增强系统三大维度。论文考察了关键创新，包括foundation models用于金融时间序列分析、graph-based architectures用于市场关系建模，以及hierarchical frameworks用于投资组合优化。研究揭示了模型复杂性与实际约束（如高频交易中的权衡）之间的关键 tradeoff，并识别了理论进展与工业实现间的差距，同时概述了提升模型性能和实用性的开放挑战与机会。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-fin.TR",
      "comment": "Full list of papers and summary slides are available at:\n  https://github.com/junhua/awesome-finance-ai-papers",
      "pdf_url": "http://arxiv.org/pdf/2411.12747v1",
      "published_date": "2024-11-01 04:16:00 UTC",
      "updated_date": "2024-11-01 04:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:14:04.268254"
    },
    {
      "arxiv_id": "2411.00348v2",
      "title": "Attention Tracker: Detecting Prompt Injection Attacks in LLMs",
      "title_zh": "Attention",
      "authors": [
        "Kuo-Han Hung",
        "Ching-Yun Ko",
        "Ambrish Rawat",
        "I-Hsin Chung",
        "Winston H. Hsu",
        "Pin-Yu Chen"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized various domains but remain\nvulnerable to prompt injection attacks, where malicious inputs manipulate the\nmodel into ignoring original instructions and executing designated action. In\nthis paper, we investigate the underlying mechanisms of these attacks by\nanalyzing the attention patterns within LLMs. We introduce the concept of the\ndistraction effect, where specific attention heads, termed important heads,\nshift focus from the original instruction to the injected instruction. Building\non this discovery, we propose Attention Tracker, a training-free detection\nmethod that tracks attention patterns on instruction to detect prompt injection\nattacks without the need for additional LLM inference. Our method generalizes\neffectively across diverse models, datasets, and attack types, showing an AUROC\nimprovement of up to 10.0% over existing methods, and performs well even on\nsmall LLMs. We demonstrate the robustness of our approach through extensive\nevaluations and provide insights into safeguarding LLM-integrated systems from\nprompt injection vulnerabilities.",
      "tldr_zh": "这篇论文研究了大型语言模型 (LLMs) 面临的提示注入攻击 (prompt injection attacks)，通过分析注意力模式 (attention patterns) 发现了 \"distraction effect\"，即特定注意力头 (important heads) 会将焦点从原始指令转移到注入指令。作者提出了 Attention Tracker，一种无需训练的检测方法，仅通过跟踪指令上的注意力模式即可识别攻击，而不需额外 LLM 推理。该方法在不同模型、数据集和攻击类型上具有良好的泛化性，比现有方法提高 AUROC 最多 10.0%，甚至在小型 LLMs 上表现优秀，并通过广泛评估证明了其鲁棒性，为保护 LLM 集成系统提供了重要见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Project page:\n  https://huggingface.co/spaces/TrustSafeAI/Attention-Tracker",
      "pdf_url": "http://arxiv.org/pdf/2411.00348v2",
      "published_date": "2024-11-01 04:05:59 UTC",
      "updated_date": "2025-04-23 01:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:14:17.101722"
    },
    {
      "arxiv_id": "2411.00347v1",
      "title": "An Untethered Bioinspired Robotic Tensegrity Dolphin with Multi-Flexibility Design for Aquatic Locomotion",
      "title_zh": "翻译失败",
      "authors": [
        "Luyang Zhao",
        "Yitao Jiang",
        "Chun-Yi She",
        "Mingi Jeong",
        "Haibo Dong",
        "Alberto Quattrini Li",
        "Muhao Chen",
        "Devin Balkcom"
      ],
      "abstract": "This paper presents the first steps toward a soft dolphin robot using a\nbio-inspired approach to mimic dolphin flexibility. The current dolphin robot\nuses a minimalist approach, with only two actuated cable-driven degrees of\nfreedom actuated by a pair of motors. The actuated tail moves up and down in a\nswimming motion, but this first proof of concept does not permit controlled\nturns of the robot. While existing robotic dolphins typically use revolute\njoints to articulate rigid bodies, our design -- which will be made opensource\n-- incorporates a flexible tail with tunable silicone skin and actuation\nflexibility via a cable-driven system, which mimics muscle dynamics and design\nflexibility with a tunable skeleton structure. The design is also tunable since\nthe backbone can be easily printed in various geometries. The paper provides\ninsights into how a few such variations affect robot motion and efficiency,\nmeasured by speed and cost of transport (COT). This approach demonstrates the\npotential of achieving dolphin-like motion through enhanced flexibility in\nbio-inspired robotics.",
      "tldr_zh": "这篇论文介绍了第一款基于生物启发(bio-inspired)方法的无缆张拉整体(Tensegrity)海豚机器人，采用多柔性设计来模仿海豚的灵活性，用于水生运动。机器人使用最小主义结构，仅通过两个马达驱动的电缆系统控制尾部上下摆动，实现基本的游泳动作，但目前不支持精确转弯。研究探讨了柔性尾巴、可调硅胶皮肤和可打印骨干几何变异对机器人速度和运输成本(COT)的影响，结果显示这种设计显著提升了运动效率，并展示了在生物启发机器人中增强灵活性的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00347v1",
      "published_date": "2024-11-01 04:05:24 UTC",
      "updated_date": "2024-11-01 04:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:14:30.046717"
    },
    {
      "arxiv_id": "2411.00345v1",
      "title": "On the Exploration of LM-Based Soft Modular Robot Design",
      "title_zh": "翻译失败",
      "authors": [
        "Weicheng Ma",
        "Luyang Zhao",
        "Chun-Yi She",
        "Yitao Jiang",
        "Alan Sun",
        "Bo Zhu",
        "Devin Balkcom",
        "Soroush Vosoughi"
      ],
      "abstract": "Recent large language models (LLMs) have demonstrated promising capabilities\nin modeling real-world knowledge and enhancing knowledge-based generation\ntasks. In this paper, we further explore the potential of using LLMs to aid in\nthe design of soft modular robots, taking into account both user instructions\nand physical laws, to reduce the reliance on extensive trial-and-error\nexperiments typically needed to achieve robot designs that meet specific\nstructural or task requirements. Specifically, we formulate the robot design\nprocess as a sequence generation task and find that LLMs are able to capture\nkey requirements expressed in natural language and reflect them in the\nconstruction sequences of robots. To simplify, rather than conducting\nreal-world experiments to assess design quality, we utilize a simulation tool\nto provide feedback to the generative model, allowing for iterative\nimprovements without requiring extensive human annotations. Furthermore, we\nintroduce five evaluation metrics to assess the quality of robot designs from\nmultiple angles including task completion and adherence to instructions,\nsupporting an automatic evaluation process. Our model performs well in\nevaluations for designing soft modular robots with uni- and bi-directional\nlocomotion and stair-descending capabilities, highlighting the potential of\nusing natural language and LLMs for robot design. However, we also observe\ncertain limitations that suggest areas for further improvement.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 辅助软模块化机器人设计的过程，旨在整合用户指令和物理定律，以减少依赖于大量试错实验。论文将机器人设计表述为序列生成任务，LLMs 能够捕捉自然语言中的关键要求并生成相应的构建序列，同时利用模拟工具提供反馈实现迭代改进，并引入五种评估指标（如任务完成和指令遵守）进行自动评估。实验结果显示，该模型在设计具有单向、双向运动和下楼梯能力的软模块化机器人方面表现出色，但也揭示了某些限制，需要进一步优化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00345v1",
      "published_date": "2024-11-01 04:03:05 UTC",
      "updated_date": "2024-11-01 04:03:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:14:41.288370"
    },
    {
      "arxiv_id": "2411.00336v1",
      "title": "StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention",
      "title_zh": "StepCountJITAI：用于强化学习的模拟环境，并应用于身体活动适应性干预",
      "authors": [
        "Karine Karine",
        "Benjamin M. Marlin"
      ],
      "abstract": "The use of reinforcement learning (RL) to learn policies for just-in-time\nadaptive interventions (JITAIs) is of significant interest in many behavioral\nintervention domains including improving levels of physical activity. In a\nmessaging-based physical activity JITAI, a mobile health app is typically used\nto send messages to a participant to encourage engagement in physical activity.\nIn this setting, RL methods can be used to learn what intervention options to\nprovide to a participant in different contexts. However, deploying RL methods\nin real physical activity adaptive interventions comes with challenges: the\ncost and time constraints of real intervention studies result in limited data\nto learn adaptive intervention policies. Further, commonly used RL simulation\nenvironments have dynamics that are of limited relevance to physical activity\nadaptive interventions and thus shed little light on what RL methods may be\noptimal for this challenging application domain. In this paper, we introduce\nStepCountJITAI, an RL environment designed to foster research on RL methods\nthat address the significant challenges of policy learning for adaptive\nbehavioral interventions.",
      "tldr_zh": "这篇论文引入了StepCountJITAI，这是一个专为强化学习(RL)设计的模拟环境，旨在应用于身体活动即时自适应干预(JITAIs)，例如通过移动健康应用发送消息鼓励参与者参与身体活动。论文强调了在真实干预中RL方法面临的挑战，包括数据有限和现有模拟环境的动态不相关，从而限制了策略学习的效果。通过StepCountJITAI，该环境为研究RL方法提供了更贴合实际的平台，帮助解决适应性行为干预的关键问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024 workshop on Behavioral ML",
      "pdf_url": "http://arxiv.org/pdf/2411.00336v1",
      "published_date": "2024-11-01 03:31:39 UTC",
      "updated_date": "2024-11-01 03:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:14:52.704787"
    },
    {
      "arxiv_id": "2411.02525v1",
      "title": "Strongly Topology-preserving GNNs for Brain Graph Super-resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Pragya Singh",
        "Islem Rekik"
      ],
      "abstract": "Brain graph super-resolution (SR) is an under-explored yet highly relevant\ntask in network neuroscience. It circumvents the need for costly and\ntime-consuming medical imaging data collection, preparation, and processing.\nCurrent SR methods leverage graph neural networks (GNNs) thanks to their\nability to natively handle graph-structured datasets. However, most GNNs\nperform node feature learning, which presents two significant limitations: (1)\nthey require computationally expensive methods to learn complex node features\ncapable of inferring connectivity strength or edge features, which do not scale\nto larger graphs; and (2) computations in the node space fail to adequately\ncapture higher-order brain topologies such as cliques and hubs. However,\nnumerous studies have shown that brain graph topology is crucial in identifying\nthe onset and presence of various neurodegenerative disorders like Alzheimer\nand Parkinson. Motivated by these challenges and applications, we propose our\nSTP-GSR framework. It is the first graph SR architecture to perform\nrepresentation learning in higher-order topological space. Specifically, using\nthe primal-dual graph formulation from graph theory, we develop an efficient\nmapping from the edge space of our low-resolution (LR) brain graphs to the node\nspace of a high-resolution (HR) dual graph. This approach ensures that\nnode-level computations on this dual graph correspond naturally to edge-level\nlearning on our HR brain graphs, thereby enforcing strong topological\nconsistency within our framework. Additionally, our framework is GNN layer\nagnostic and can easily learn from smaller, scalable GNNs, reducing\ncomputational requirements. We comprehensively benchmark our framework across\nseven key topological measures and observe that it significantly outperforms\nthe previous state-of-the-art methods and baselines.",
      "tldr_zh": "该研究针对脑图超分辨率（Brain graph super-resolution）任务，提出了一种强拓扑保持的图神经网络框架STP-GSR，以解决现有GNNs在处理图结构数据时存在的计算开销高和无法捕获更高阶拓扑（如cliques和hubs）的问题。STP-GSR通过primal-dual图理论，将低分辨率（LR）脑图的边空间高效映射到高分辨率（HR）双图的节点空间，实现更高阶拓扑空间的表示学习，并确保拓扑一致性。该框架对GNN层无关，可使用更小的GNNs减少计算需求，并在七个关键拓扑指标上显著优于现有方法，为神经退行性疾病诊断提供更可靠的支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to PRIME-MICCAI-2024",
      "pdf_url": "http://arxiv.org/pdf/2411.02525v1",
      "published_date": "2024-11-01 03:29:04 UTC",
      "updated_date": "2024-11-01 03:29:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:16:24.018752"
    },
    {
      "arxiv_id": "2411.00329v1",
      "title": "Personalized Federated Learning via Feature Distribution Adaptation",
      "title_zh": "基于特征分布适应的个性化联邦学习",
      "authors": [
        "Connor J. Mclaughlin",
        "Lili Su"
      ],
      "abstract": "Federated learning (FL) is a distributed learning framework that leverages\ncommonalities between distributed client datasets to train a global model.\nUnder heterogeneous clients, however, FL can fail to produce stable training\nresults. Personalized federated learning (PFL) seeks to address this by\nlearning individual models tailored to each client. One approach is to\ndecompose model training into shared representation learning and personalized\nclassifier training. Nonetheless, previous works struggle to navigate the\nbias-variance trade-off in classifier learning, relying solely on limited local\ndatasets or introducing costly techniques to improve generalization. In this\nwork, we frame representation learning as a generative modeling task, where\nrepresentations are trained with a classifier based on the global feature\ndistribution. We then propose an algorithm, pFedFDA, that efficiently generates\npersonalized models by adapting global generative classifiers to their local\nfeature distributions. Through extensive computer vision benchmarks, we\ndemonstrate that our method can adjust to complex distribution shifts with\nsignificant improvements over current state-of-the-art in data-scarce settings.",
      "tldr_zh": "该论文探讨了在异质客户端下，Federated Learning (FL) 训练不稳定的问题，并提出 Personalized Federated Learning (PFL) 的新方法。作者将表示学习框架化为生成建模任务，使用基于全局特征分布的分类器进行训练，并引入 pFedFDA 算法，通过将全局生成分类器适应到本地特征分布来高效生成个性化模型。在计算机视觉基准测试中，pFedFDA 在复杂分布偏移和数据稀缺场景下，显著优于现有最先进方法，展示了其在处理偏差-方差权衡方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "38th Annual Conference on Neural Information Processing Systems\n  (NeurIPS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00329v1",
      "published_date": "2024-11-01 03:03:52 UTC",
      "updated_date": "2024-11-01 03:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:15:16.972238"
    },
    {
      "arxiv_id": "2411.11852v1",
      "title": "LUTMUL: Exceed Conventional FPGA Roofline Limit by LUT-based Efficient Multiplication for Neural Network Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yanyue Xie",
        "Zhengang Li",
        "Dana Diaconu",
        "Suranga Handagala",
        "Miriam Leeser",
        "Xue Lin"
      ],
      "abstract": "For FPGA-based neural network accelerators, digital signal processing (DSP)\nblocks have traditionally been the cornerstone for handling multiplications.\nThis paper introduces LUTMUL, which harnesses the potential of look-up tables\n(LUTs) for performing multiplications. The availability of LUTs typically\noutnumbers that of DSPs by a factor of 100, offering a significant\ncomputational advantage. By exploiting this advantage of LUTs, our method\ndemonstrates a potential boost in the performance of FPGA-based neural network\naccelerators with a reconfigurable dataflow architecture. Our approach\nchallenges the conventional peak performance on DSP-based accelerators and sets\na new benchmark for efficient neural network inference on FPGAs. Experimental\nresults demonstrate that our design achieves the best inference speed among all\nFPGA-based accelerators, achieving a throughput of 1627 images per second and\nmaintaining a top-1 accuracy of 70.95% on the ImageNet dataset.",
      "tldr_zh": "本文提出 LUTMUL 方法，利用查找表 (LUTs) 来执行神经网络推理中的乘法操作，挑战传统依赖数字信号处理 (DSP) 块的 FPGA 加速器设计。相比 DSP，LUTs 的数量多出约 100 倍，提供显著计算优势，并结合可重配置数据流架构提升整体性能。实验结果显示，该设计在 ImageNet 数据集上实现了 1627 张图像每秒的吞吐量，同时保持 70.95% 的 top-1 准确率，设定了 FPGA 神经网络推理的新基准。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted by ASPDAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.11852v1",
      "published_date": "2024-11-01 02:54:11 UTC",
      "updated_date": "2024-11-01 02:54:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:15:28.996198"
    },
    {
      "arxiv_id": "2411.02523v1",
      "title": "Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes",
      "title_zh": "翻译失败",
      "authors": [
        "Balu Bhasuran",
        "Qiao Jin",
        "Yuzhang Xie",
        "Carl Yang",
        "Karim Hanna",
        "Jennifer Costa",
        "Cindy Shavor",
        "Zhiyong Lu",
        "Zhe He"
      ],
      "abstract": "Differential diagnosis is crucial for medicine as it helps healthcare\nproviders systematically distinguish between conditions that share similar\nsymptoms. This study assesses the impact of lab test results on differential\ndiagnoses (DDx) made by large language models (LLMs). Clinical vignettes from\n50 case reports from PubMed Central were created incorporating patient\ndemographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,\nClaude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx\nwith and without lab data. A comprehensive evaluation involving GPT-4, a\nknowledge graph, and clinicians was conducted. GPT-4 performed best, achieving\n55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient\naccuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and\nMixtral excelling, though exact match rates were low. Lab tests, including\nliver function, metabolic/toxicology panels, and serology/immune tests, were\ngenerally interpreted correctly by LLMs for differential diagnosis.",
      "tldr_zh": "这项研究评估了实验室测试结果对大型语言模型（LLMs）生成鉴别诊断（DDx）的影响，使用 PubMed Central 的 50 个临床病例小结，包括患者人口统计、症状和实验室数据，测试了 GPT-4、GPT-3.5、Llama-2-70b、Claude-2 和 Mixtral-8x7B 等模型生成 Top 10、Top 5 和 Top 1 DDx。评估结果显示，实验室数据显著提高了准确率，GPT-4 在有实验室数据时，Top 1 诊断准确率达 55%、Top 10 达 60%，宽松准确率高达 80%。此外，LLMs 通常正确解释了肝功能、代谢/毒理学面板和血清学/免疫测试等实验室结果，为 LLMs 在医疗决策中的可靠应用提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02523v1",
      "published_date": "2024-11-01 02:48:32 UTC",
      "updated_date": "2024-11-01 02:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:16:38.424998"
    },
    {
      "arxiv_id": "2411.00322v1",
      "title": "Constant Acceleration Flow",
      "title_zh": "恒定加速度流",
      "authors": [
        "Dogyun Park",
        "Sojin Lee",
        "Sihyeon Kim",
        "Taehoon Lee",
        "Youngjoon Hong",
        "Hyunwoo J. Kim"
      ],
      "abstract": "Rectified flow and reflow procedures have significantly advanced fast\ngeneration by progressively straightening ordinary differential equation (ODE)\nflows. They operate under the assumption that image and noise pairs, known as\ncouplings, can be approximated by straight trajectories with constant velocity.\nHowever, we observe that modeling with constant velocity and using reflow\nprocedures have limitations in accurately learning straight trajectories\nbetween pairs, resulting in suboptimal performance in few-step generation. To\naddress these limitations, we introduce Constant Acceleration Flow (CAF), a\nnovel framework based on a simple constant acceleration equation. CAF\nintroduces acceleration as an additional learnable variable, allowing for more\nexpressive and accurate estimation of the ODE flow. Moreover, we propose two\ntechniques to further improve estimation accuracy: initial velocity\nconditioning for the acceleration model and a reflow process for the initial\nvelocity. Our comprehensive studies on toy datasets, CIFAR-10, and ImageNet\n64x64 demonstrate that CAF outperforms state-of-the-art baselines for one-step\ngeneration. We also show that CAF dramatically improves few-step coupling\npreservation and inversion over Rectified flow. Code is available at\n\\href{https://github.com/mlvlab/CAF}{https://github.com/mlvlab/CAF}.",
      "tldr_zh": "该论文提出 Constant Acceleration Flow (CAF) 框架，以解决 Rectified flow 和 reflow 程序在普通微分方程 (ODE) 流建模中的局限性，这些方法假设图像与噪声对可由恒定速度直线轨迹近似，导致少步生成性能不佳。CAF 基于简单恒定加速度方程，将加速度作为可学习变量，以实现更精确和富有表现力的 ODE 流估计。同时，引入初始速度条件化和初始速度的 reflow 过程，进一步提升估计准确性。在玩具数据集、CIFAR-10 和 ImageNet 64x64 等数据集上的实验显示，CAF 在一步生成中优于最先进基线，并在少步耦合保留和反演方面显著超越 Rectified flow。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00322v1",
      "published_date": "2024-11-01 02:43:56 UTC",
      "updated_date": "2024-11-01 02:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:16:48.656993"
    },
    {
      "arxiv_id": "2411.00311v1",
      "title": "C2A: Client-Customized Adaptation for Parameter-Efficient Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yeachan Kim",
        "Junho Kim",
        "Wing-Lam Mok",
        "Jun-Hyung Park",
        "SangKeun Lee"
      ],
      "abstract": "Despite the versatility of pre-trained language models (PLMs) across domains,\ntheir large memory footprints pose significant challenges in federated learning\n(FL), where the training model has to be distributed between a server and\nclients. One potential solution to bypass such constraints might be the use of\nparameter-efficient fine-tuning (PEFT) in the context of FL. However, we have\nobserved that typical PEFT tends to severely suffer from heterogeneity among\nclients in FL scenarios, resulting in unstable and slow convergence. In this\npaper, we propose Client-Customized Adaptation (C2A), a novel\nhypernetwork-based FL framework that generates client-specific adapters by\nconditioning the client information. With the effectiveness of the\nhypernetworks in generating customized weights through learning to adopt the\ndifferent characteristics of inputs, C2A can maximize the utility of shared\nmodel parameters while minimizing the divergence caused by client\nheterogeneity. To verify the efficacy of C2A, we perform extensive evaluations\non FL scenarios involving heterogeneity in label and language distributions.\nComprehensive evaluation results clearly support the superiority of C2A in\nterms of both efficiency and effectiveness in FL scenarios.",
      "tldr_zh": "本研究针对预训练语言模型 (PLMs) 在联邦学习 (FL) 中的大内存占用问题，提出了一种基于超网络 (hypernetwork) 的框架：Client-Customized Adaptation (C2A)。C2A 通过生成客户端特定适配器来缓解参数高效微调 (PEFT) 在 FL 场景下因客户端异质性导致的收敛不稳定和缓慢问题，从而最大化共享模型参数的效用并最小化差异影响。在涉及标签和语言分布异质性的实验中，C2A 展示了显著的效率和有效性优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Findings of ACL 2023",
      "pdf_url": "http://arxiv.org/pdf/2411.00311v1",
      "published_date": "2024-11-01 02:07:38 UTC",
      "updated_date": "2024-11-01 02:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:17:00.420230"
    },
    {
      "arxiv_id": "2411.00308v2",
      "title": "GPT for Games: An Updated Scoping Review (2020-2024)",
      "title_zh": "翻译失败",
      "authors": [
        "Daijin Yang",
        "Erica Kleinman",
        "Casper Harteveld"
      ],
      "abstract": "Due to GPT's impressive generative capabilities, its applications in games\nare expanding rapidly. To offer researchers a comprehensive understanding of\nthe current applications and identify both emerging trends and unexplored\nareas, this paper introduces an updated scoping review of 177 articles, 122 of\nwhich were published in 2024, to explore GPT's potential for games. By coding\nand synthesizing the papers, we identify five prominent applications of GPT in\ncurrent game research: procedural content generation, mixed-initiative game\ndesign, mixed-initiative gameplay, playing games, and game user research.\nDrawing on insights from these application areas and emerging research, we\npropose future studies should focus on expanding the technical boundaries of\nthe GPT models and exploring the complex interaction dynamics between them and\nusers. This review aims to illustrate the state of the art in innovative GPT\napplications in games, offering a foundation to enrich game development and\nenhance player experiences through cutting-edge AI innovations.",
      "tldr_zh": "本论文对GPT在游戏领域的应用进行了更新后的范围审查（scoping review），涵盖了2020-2024年间177篇文献，其中122篇于2024年发表，通过编码和合成这些论文，识别出GPT的五种主要应用：程序内容生成（procedural content generation）、混合主动游戏设计（mixed-initiative game design）、混合主动游戏玩法（mixed-initiative gameplay）、玩游戏，以及游戏用户研究（game user research）。研究发现，GPT正快速扩展其在游戏中的潜力，并建议未来工作应扩展GPT模型的技术边界，同时探索其与用户之间的复杂互动动态。该审查为游戏开发提供了创新基础，有助于通过AI技术提升玩家体验。",
      "categories": [
        "cs.AI",
        "A.1"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to IEEE Transactions on Games",
      "pdf_url": "http://arxiv.org/pdf/2411.00308v2",
      "published_date": "2024-11-01 02:00:25 UTC",
      "updated_date": "2025-03-14 17:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:17:10.687390"
    },
    {
      "arxiv_id": "2411.12746v1",
      "title": "A Review of Reinforcement Learning in Financial Applications",
      "title_zh": "强化学习在金融应用中的综述",
      "authors": [
        "Yahui Bai",
        "Yuhe Gao",
        "Runzhe Wan",
        "Sheng Zhang",
        "Rui Song"
      ],
      "abstract": "In recent years, there has been a growing trend of applying Reinforcement\nLearning (RL) in financial applications.\n  This approach has shown great potential to solve decision-making tasks in\nfinance.\n  In this survey, we present a comprehensive study of the applications of RL in\nfinance and conduct a series of meta-analyses to investigate the common themes\nin the literature, such as the factors that most significantly affect RL's\nperformance compared to traditional methods.\n  Moreover, we identify challenges including explainability, Markov Decision\nProcess (MDP) modeling, and robustness that hinder the broader utilization of\nRL in the financial industry and discuss recent advancements in overcoming\nthese challenges.\n  Finally, we propose future research directions, such as benchmarking,\ncontextual RL, multi-agent RL, and model-based RL to address these challenges\nand to further enhance the implementation of RL in finance.",
      "tldr_zh": "这篇综述探讨了 Reinforcement Learning (RL) 在金融应用中的应用趋势及其在决策任务中的潜力。作者通过全面文献分析和元分析，识别了影响 RL 性能的关键因素，如与传统方法的比较，并突出了挑战包括 explainability、Markov Decision Process (MDP) modeling 和 robustness，同时讨论了最近的进展。最终，论文提出未来研究方向，如 benchmarking、contextual RL、multi-agent RL 和 model-based RL，以进一步提升 RL 在金融领域的实施。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12746v1",
      "published_date": "2024-11-01 01:03:10 UTC",
      "updated_date": "2024-11-01 01:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:17:22.628905"
    },
    {
      "arxiv_id": "2411.00288v1",
      "title": "Inducing Semi-Structured Sparsity by Masking for Efficient Model Inference in Convolutional Networks",
      "title_zh": "翻译失败",
      "authors": [
        "David A. Danhofer"
      ],
      "abstract": "The crucial role of convolutional models, both as standalone vision models\nand backbones in foundation models, necessitates effective acceleration\ntechniques. This paper proposes a novel method to learn semi-structured\nsparsity patterns for convolution kernels in the form of maskings enabling the\nutilization of readily available hardware accelerations. The approach\naccelerates convolutional models more than two-fold during inference without\ndecreasing model performance. At the same time, the original model weights and\nstructure remain unchanged keeping the model thus easily updatable. Beyond the\nimmediate practical use, the effect of maskings on prediction is easily\nquantifiable. Therefore, guarantees on model predictions under maskings are\nderived showing stability bounds for learned maskings even after updating the\noriginal underlying model.",
      "tldr_zh": "本研究提出了一种新方法，通过掩码(maskings)来诱导卷积网络(convolutional networks)中的半结构化稀疏性(semi-structured sparsity)，以实现高效的模型推理加速。该方法利用现成的硬件加速(hardware accelerations)，使卷积模型的推理速度提高两倍以上，同时保持原模型权重和结构不变，从而不降低性能且便于更新。此外，研究量化了掩码对预测的影响，并提供了稳定性保证，确保了模型在更新后仍能保持可靠的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "cs.PF",
        "C.4; I.2.6; I.2.10; I.4.m; I.5.4; I.5.5"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 3 figures; this work will be presented at the NeurIPS 2024\n  Workshop on Fine-Tuning in Modern Machine Learning: Principles and\n  Scalability (FITML)",
      "pdf_url": "http://arxiv.org/pdf/2411.00288v1",
      "published_date": "2024-11-01 00:53:33 UTC",
      "updated_date": "2024-11-01 00:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:17:34.712650"
    },
    {
      "arxiv_id": "2411.00287v1",
      "title": "MBExplainer: Multilevel bandit-based explanations for downstream models with augmented graph embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Ashkan Golgoon",
        "Ryan Franks",
        "Khashayar Filom",
        "Arjun Ravi Kannan"
      ],
      "abstract": "In many industrial applications, it is common that the graph embeddings\ngenerated from training GNNs are used in an ensemble model where the embeddings\nare combined with other tabular features (e.g., original node or edge features)\nin a downstream ML task. The tabular features may even arise naturally if,\ne.g., one tries to build a graph such that some of the node or edge features\nare stored in a tabular format. Here we address the problem of explaining the\noutput of such ensemble models for which the input features consist of learned\nneural graph embeddings combined with additional tabular features. We propose\nMBExplainer, a model-agnostic explanation approach for downstream models with\naugmented graph embeddings. MBExplainer returns a human-legible triple as an\nexplanation for an instance prediction of the whole pipeline consisting of\nthree components: a subgraph with the highest importance, the topmost important\nnodal features, and the topmost important augmented downstream features. A\ngame-theoretic formulation is used to take the contributions of each component\nand their interactions into account by assigning three Shapley values\ncorresponding to their own specific games. Finding the explanation requires an\nefficient search through the corresponding local search spaces corresponding to\neach component. MBExplainer applies a novel multilevel search algorithm that\nenables simultaneous pruning of local search spaces in a computationally\ntractable way. In particular, three interweaved Monte Carlo Tree Search are\nutilized to iteratively prune the local search spaces. MBExplainer also\nincludes a global search algorithm that uses contextual bandits to efficiently\nallocate pruning budget among the local search spaces. We show the\neffectiveness of MBExplainer by presenting a set of comprehensive numerical\nexamples on multiple public graph datasets for both node and graph\nclassification tasks.",
      "tldr_zh": "本研究针对包含图嵌入（graph embeddings）和表格特征的下游机器学习模型，提出了一种模型无关的解释方法MBExplainer，以解释其预测输出。MBExplainer通过博弈论的Shapley值评估每个组件的贡献和交互，返回一个人类可读的三元组解释，包括最重要的子图（subgraph）、顶尖节点特征和顶尖增强下游特征。该方法采用多级搜索算法，包括三个交织的Monte Carlo Tree Search来高效修剪本地搜索空间，并使用上下文bandit（contextual bandits）全局分配预算。在多个公共图数据集上的实验中，MBExplainer在节点和图分类任务中展示了显著的有效性，提高了模型解释的准确性和计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NA",
        "math.NA",
        "stat.ML",
        "68T01",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00287v1",
      "published_date": "2024-11-01 00:52:59 UTC",
      "updated_date": "2024-11-01 00:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:17:47.962042"
    },
    {
      "arxiv_id": "2411.00284v2",
      "title": "SimpleFSDP: Simpler Fully Sharded Data Parallel with torch.compile",
      "title_zh": "SimpleFSDP：更简单的全分片数据并行，使用 torch.compile",
      "authors": [
        "Ruisi Zhang",
        "Tianyu Liu",
        "Will Feng",
        "Andrew Gu",
        "Sanket Purandare",
        "Wanchao Liang",
        "Francisco Massa"
      ],
      "abstract": "Distributed training of large models consumes enormous computation resources\nand requires substantial engineering efforts to compose various training\ntechniques. This paper presents SimpleFSDP, a PyTorch-native compiler-based\nFully Sharded Data Parallel (FSDP) framework, which has a simple implementation\nfor maintenance and composability, allows full computation-communication graph\ntracing, and brings performance enhancement via compiler backend optimizations.\n  SimpleFSDP's novelty lies in its unique $torch.compile$-friendly\nimplementation of collective communications using existing PyTorch primitives,\nnamely parametrizations, selective activation checkpointing, and DTensor. It\nalso features the first-of-its-kind intermediate representation (IR) nodes\nbucketing and reordering in the TorchInductor backend for effective\ncomputation-communication overlapping. As a result, users can employ the\naforementioned optimizations to automatically or manually wrap model components\nfor minimal communication exposure. Extensive evaluations of SimpleFSDP on\nLlama 3 models (including the ultra-large 405B) using TorchTitan demonstrate up\nto 28.54% memory reduction and 68.67% throughput improvement compared to the\nmost widely adopted FSDP2 eager framework, when composed with other distributed\ntraining techniques.",
      "tldr_zh": "本论文提出SimpleFSDP，一种基于torch.compile的PyTorch原生Fully Sharded Data Parallel (FSDP)框架，旨在简化分布式训练的实现和维护，同时通过全计算-通信图追踪和编译器后端优化提升性能。SimpleFSDP的关键创新包括利用parametrizations、selective activation checkpointing和DTensor等现有PyTorch原语实现集体通信，以及在TorchInductor后端进行IR节点bucketing和reordering，以实现有效的计算-通信重叠。实验结果显示，在Llama 3模型（包括405B规模）上，SimpleFSDP相较于FSDP2框架实现了高达28.54%的内存减少和68.67%的吞吐量提升。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00284v2",
      "published_date": "2024-11-01 00:43:54 UTC",
      "updated_date": "2024-11-05 18:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:17:59.814725"
    },
    {
      "arxiv_id": "2411.00282v1",
      "title": "Improving Traffic Flow Predictions with SGCN-LSTM: A Hybrid Model for Spatial and Temporal Dependencies",
      "title_zh": "使用 SGCN-LSTM 改善交通流量预测：一个处理空间和时间依赖性的混合模型",
      "authors": [
        "Alexandru T. Cismaru"
      ],
      "abstract": "Large amounts of traffic can lead to negative effects such as increased car\naccidents, air pollution, and significant time wasted. Understanding traffic\nspeeds on any given road segment can be highly beneficial for traffic\nmanagement strategists seeking to reduce congestion. While recent studies have\nprimarily focused on modeling spatial dependencies by using graph convolutional\nnetworks (GCNs) over fixed weighted graphs, the relationships between nodes are\noften more complex, with edges that interact dynamically. This paper addresses\nboth the temporal patterns in traffic data and the intricate spatial\ndependencies by introducing the Signal-Enhanced Graph Convolutional Network\nLong Short Term Memory (SGCN-LSTM) model for predicting traffic speeds across\nroad networks. Extensive experiments on the PEMS-BAY road network traffic\ndataset demonstrate the SGCN-LSTM model's effectiveness, yielding significant\nimprovements in Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and\nMean Absolute Percentage Error (MAPE) compared to benchmark models on the same\ndataset.",
      "tldr_zh": "该研究针对交通拥堵导致的车祸、空气污染和时间浪费等问题，提出了一种混合模型 SGCN-LSTM，以改善道路网络的交通速度预测。该模型结合 Signal-Enhanced Graph Convolutional Network (SGCN) 处理复杂的空间依赖，以及 Long Short Term Memory (LSTM) 捕捉时间模式，从而更准确地建模动态节点交互。在 PEMS-BAY 数据集上的实验显示，SGCN-LSTM 相比基准模型显著降低了 Mean Absolute Error (MAE)、Root Mean Square Error (RMSE) 和 Mean Absolute Percentage Error (MAPE)，证明了其在交通流量预测的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00282v1",
      "published_date": "2024-11-01 00:37:00 UTC",
      "updated_date": "2024-11-01 00:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:20:05.143347"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 119,
  "processed_papers_count": 119,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T20:20:23.603411"
}