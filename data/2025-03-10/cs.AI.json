{
  "date": "2025-03-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-10 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文聚焦于 AI 生成模型、多模态处理和实际应用创新，亮点包括 LLM 在机器人任务规划和医疗诊断中的进展，以及高效的混合专家模型和扩散模型优化；令人印象深刻的文章有 Gemini Embedding 的多语言嵌入提升，以及 RoboGuard 在 LLM 驱动机器人安全中的突破。\n\n### 主要论文讨论\n我挑选了最具影响力和话题度的论文，按主题归类，先聊核心创新部分，其他次要内容快速掠过。以下聚焦于 AI 生成、LLM 应用、医疗和机器人领域。\n\n#### LLM 和生成模型创新\n- **SEA-VL: Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia**  \n  这篇论文构建了东南亚多文化视觉语言数据集 SEA-VL，通过图像爬取和生成方法，实现了约 85% 的文化相关性，贡献在于填补了 AI 在东南亚文化表示的空白，发现合成图像在捕捉文化细微差上仍有局限。\n\n- **Gemini Embedding: Generalizable Embeddings from Gemini**  \n  作者包括 Google 的多名知名学者（如 Daniel Cer 和 Tom Duerig），论文提出 Gemini Embedding 模型，利用 Gemini LLM 的多语言能力，在 MMTEB 基准上超越了现有嵌入模型，主要发现是其在多语言和代码任务上的泛化性能提升。\n\n- **NFIG: Autoregressive Image Generation with Next-Frequency Prediction**  \n  论文引入 NFIG 框架，通过频率引导的自回归生成，加速图像合成，贡献在于 4.53 倍加速下 FID 降至 2.81，发现频率分解能更好地捕捉图像层次结构。\n\n- **DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs**  \n  这篇快速掠过，焦点是改进 LLM 蒸馏方法，通过对比学习提升指令跟随和代码生成性能。\n\n#### 医疗 AI 和图像分析\n- **PIED: Physics-Informed Experimental Design for Inverse Problems**  \n  论文提出 PIED 框架，使用物理信息神经网络优化实验设计，贡献在于高效解决逆问题，发现它在模拟和真实数据上显著提升逆向参数估计精度。\n\n- **Topology-Preserving Loss for Accurate and Anatomically Consistent Cardiac Mesh Reconstruction**  \n  引入 TPM Loss 函数，确保心脏网格重建的拓扑一致性，主要发现是减少拓扑错误达 93%，同时保持高分割准确率 (DSC: 89.1%-92.9%)。\n\n- **Semi-Supervised Medical Image Segmentation via Knowledge Mining from Large Models**  \n  这篇利用 SAM 模型挖掘知识，提升半监督图像分割，贡献在于用伪标签增强训练，发现它在肺部和胃肠图像上 Dice 分数提升 3%。\n\n其他医疗论文如 AgriField3D 和 MELON 等，聚焦数据集构建和生物医学应用，快速掠过，它们的主要发现是改进 3D 点云和多模态融合，但影响不如上述创新大。\n\n#### 机器人和强化学习\n- **RoboGuard: Safety Guardrails for LLM-Enabled Robots**  \n  论文设计 RoboGuard 框架，确保 LLM 驱动机器人的安全，贡献在于通过时序逻辑约束减少不安全计划执行率 (从 92% 降至 2.5%)，发现它在对抗攻击下保持高效。\n\n- **DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems**  \n  提出 DynTaskMAS 框架，使用动态任务图优化 LLM 多代理系统，贡献在于异步执行减少时间 21-33%，主要发现是提升资源利用率 35.4%。\n\n其他机器人论文如 FunGraph 和 LLMIdxAdvis，快速掠过，它们分别在 3D 场景图和索引推荐上有所创新，但实用性不如 RoboGuard 突出。\n\n#### 其他领域快速掠过\n今天还有一些论文涉及时间序列分析（如 CIMAGE）和多模态基准（如 HalluVerse25），它们的主要贡献是改进数据处理和基准测试，但不那么核心；例如，CIMAGE 在图表示学习上提升了节点分类，而 HalluVerse25 评估了 LLM 幻觉问题。这些论文的发现有趣但影响力有限，我这里不展开讨论。\n\n总之，今天的论文展示了 AI 在实际应用中的潜力，LLM 和多模态融合是热点，建议关注 Gemini Embedding 和 RoboGuard 等创新工作。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2503.07920v2",
      "title": "Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Cahyawijaya",
        "Holy Lovenia",
        "Joel Ruben Antony Moniz",
        "Tack Hwa Wong",
        "Mohammad Rifqi Farhansyah",
        "Thant Thiri Maung",
        "Frederikus Hudi",
        "David Anugraha",
        "Muhammad Ravi Shulthan Habibi",
        "Muhammad Reza Qorib",
        "Amit Agarwal",
        "Joseph Marvin Imperial",
        "Hitesh Laxmichand Patel",
        "Vicky Feliren",
        "Bahrul Ilmi Nasution",
        "Manuel Antonio Rufino",
        "Genta Indra Winata",
        "Rian Adam Rajagede",
        "Carlos Rafael Catalan",
        "Mohamed Fazli Imam",
        "Priyaranjan Pattnayak",
        "Salsabila Zahirah Pranida",
        "Kevin Pratama",
        "Yeshil Bangera",
        "Adisai Na-Thalang",
        "Patricia Nicole Monderin",
        "Yueqi Song",
        "Christian Simon",
        "Lynnette Hui Xian Ng",
        "Richardy Lobo' Sapan",
        "Taki Hasan Rafi",
        "Bin Wang",
        "Supryadi",
        "Kanyakorn Veerakanjana",
        "Piyalitt Ittichaiwong",
        "Matthew Theodore Roque",
        "Karissa Vincentio",
        "Takdanai Kreangphet",
        "Phakphum Artkaew",
        "Kadek Hendrawan Palgunadi",
        "Yanzhi Yu",
        "Rochana Prih Hastuti",
        "William Nixon",
        "Mithil Bangera",
        "Adrian Xuan Wei Lim",
        "Aye Hninn Khine",
        "Hanif Muhammad Zhafran",
        "Teddy Ferdinan",
        "Audra Aurora Izzani",
        "Ayushman Singh",
        "Evan",
        "Jauza Akbar Krito",
        "Michael Anugraha",
        "Fenal Ashokbhai Ilasariya",
        "Haochen Li",
        "John Amadeo Daniswara",
        "Filbert Aurelian Tjiaranata",
        "Eryawan Presma Yulianrifat",
        "Can Udomcharoenchaikit",
        "Fadil Risdian Ansori",
        "Mahardika Krisna Ihsani",
        "Giang Nguyen",
        "Anab Maulana Barik",
        "Dan John Velasco",
        "Rifo Ahmad Genadi",
        "Saptarshi Saha",
        "Chengwei Wei",
        "Isaiah Flores",
        "Kenneth Ko Han Chen",
        "Anjela Gail Santos",
        "Wan Shen Lim",
        "Kaung Si Phyo",
        "Tim Santos",
        "Meisyarah Dwiastuti",
        "Jiayun Luo",
        "Jan Christian Blaise Cruz",
        "Ming Shan Hee",
        "Ikhlasul Akmal Hanif",
        "M. Alif Al Hakim",
        "Muhammad Rizky Sya'ban",
        "Kun Kerdthaisong",
        "Lester James V. Miranda",
        "Fajri Koto",
        "Tirana Noor Fatyanosa",
        "Alham Fikri Aji",
        "Jostin Jerico Rosal",
        "Jun Kevin",
        "Robert Wijaya",
        "Onno P. Kampman",
        "Ruochen Zhang",
        "Börje F. Karlsson",
        "Peerat Limkonchotiwat"
      ],
      "abstract": "Southeast Asia (SEA) is a region of extraordinary linguistic and cultural\ndiversity, yet it remains significantly underrepresented in vision-language\n(VL) research. This often results in artificial intelligence (AI) models that\nfail to capture SEA cultural nuances. To fill this gap, we present SEA-VL, an\nopen-source initiative dedicated to developing high-quality, culturally\nrelevant data for SEA languages. By involving contributors from SEA countries,\nSEA-VL aims to ensure better cultural relevance and diversity, fostering\ngreater inclusivity of underrepresented languages in VL research. Beyond\ncrowdsourcing, our initiative goes one step further in the exploration of the\nautomatic collection of culturally relevant images through crawling and image\ngeneration. First, we find that image crawling achieves approximately ~85%\ncultural relevance while being more cost- and time-efficient than\ncrowdsourcing. Second, despite the substantial progress in generative vision\nmodels, synthetic images remain unreliable in accurately reflecting SEA\ncultures. The generated images often fail to reflect the nuanced traditions and\ncultural contexts of the region. Collectively, we gather 1.28M SEA\nculturally-relevant images, more than 50 times larger than other existing\ndatasets. Through SEA-VL, we aim to bridge the representation gap in SEA,\nfostering the development of more inclusive AI systems that authentically\nrepresent diverse cultures across SEA.",
      "tldr_zh": "本研究针对东南亚（SEA）在视觉语言（VL）研究中的代表性不足问题，推出了SEA-VL数据集，这是一个开源项目，旨在收集高质量的文化相关数据以提升AI模型的文化包容性。通过结合crowdsourcing（众包）、crawling（图像爬取）和image generation（图像生成）方法，研究者发现crawling在成本和时间效率上更优，并达到约85%的文化相关性，而image generation难以准确捕捉SEA的文化细微差异。最终，SEA-VL数据集汇集了1.28M张文化相关图像，比现有数据集大50倍以上，为开发更具代表性的AI系统提供了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "[SEA-VL Dataset]\n  https://huggingface.co/collections/SEACrowd/sea-vl-multicultural-vl-dataset-for-southeast-asia-67cf223d0c341d4ba2b236e7\n  [Appendix J]\n  https://github.com/SEACrowd/seacrowd.github.io/blob/master/docs/SEA_VL_Appendix_J.pdf",
      "pdf_url": "http://arxiv.org/pdf/2503.07920v2",
      "published_date": "2025-03-10 23:54:52 UTC",
      "updated_date": "2025-03-18 11:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:01:18.105293"
    },
    {
      "arxiv_id": "2503.07919v1",
      "title": "BEARCUBS: A benchmark for computer-using web agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiao Song",
        "Katherine Thai",
        "Chau Minh Pham",
        "Yapei Chang",
        "Mazin Nadaf",
        "Mohit Iyyer"
      ],
      "abstract": "Modern web agents possess computer use abilities that allow them to interact\nwith webpages by sending commands to a virtual keyboard and mouse. While such\nagents have considerable potential to assist human users with complex tasks,\nevaluating their capabilities in real-world settings poses a major challenge.\nTo this end, we introduce BEARCUBS, a \"small but mighty\" benchmark of 111\ninformation-seeking questions designed to evaluate a web agent's ability to\nsearch, browse, and identify factual information from the web. Unlike prior web\nagent benchmarks, solving BEARCUBS requires (1) accessing live web content\nrather than synthetic or simulated pages, which captures the unpredictability\nof real-world web interactions; and (2) performing a broad range of multimodal\ninteractions (e.g., video understanding, 3D navigation) that cannot be bypassed\nvia text-based workarounds. Each question in BEARCUBS has a corresponding\nshort, unambiguous answer and a human-validated browsing trajectory, allowing\nfor transparent evaluation of agent performance and strategies. A human study\nconfirms that BEARCUBS questions are solvable but non-trivial (84.7% human\naccuracy), revealing search inefficiencies and domain knowledge gaps as common\nfailure points. By contrast, state-of-the-art computer-using agents\nunderperform, with the best-scoring system (OpenAI's Operator) reaching only\n24.3% accuracy. These results highlight critical areas for improvement,\nincluding reliable source selection and more powerful multimodal capabilities.\nTo facilitate future research, BEARCUBS will be updated periodically to replace\ninvalid or contaminated questions, keeping the benchmark fresh for future\ngenerations of web agents.",
      "tldr_zh": "本研究引入了BEARCUBS，一种针对计算机使用型网络代理（web agents）的基准测试，包含111个信息搜索问题，用于评估代理在搜索、浏览和识别网络事实信息方面的能力。不同于现有基准，BEARCUBS要求代理访问实时网络内容并处理多模态交互（如视频理解和3D导航），以模拟真实世界的复杂性和不可预测性。实验结果显示，人类在这些问题上达到84.7%的准确率，而最先进的代理（如OpenAI's Operator）仅为24.3%，突显了代理在可靠来源选择和多模态能力方面的改进需求。该基准将定期更新，以支持未来网络代理的研究发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07919v1",
      "published_date": "2025-03-10 23:50:30 UTC",
      "updated_date": "2025-03-10 23:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:01:29.288957"
    },
    {
      "arxiv_id": "2503.10676v1",
      "title": "Fine-Tuning LLMs for Report Summarization: Analysis on Supervised and Unsupervised Data",
      "title_zh": "微调 LLMs 用于报告总结：对监督和无监督数据的分析",
      "authors": [
        "Swati Rallapalli",
        "Shannon Gallagher",
        "Andrew O. Mellinger",
        "Jasmine Ratchford",
        "Anusha Sinha",
        "Tyler Brooks",
        "William R. Nichols",
        "Nick Winski",
        "Bryan Brown"
      ],
      "abstract": "We study the efficacy of fine-tuning Large Language Models (LLMs) for the\nspecific task of report (government archives, news, intelligence reports)\nsummarization. While this topic is being very actively researched - our\nspecific application set-up faces two challenges: (i) ground-truth summaries\nmaybe unavailable (e.g., for government archives), and (ii) availability of\nlimited compute power - the sensitive nature of the application requires that\ncomputation is performed on-premise and for most of our experiments we use one\nor two A100 GPU cards. Under this set-up we conduct experiments to answer the\nfollowing questions. First, given that fine-tuning the LLMs can be resource\nintensive, is it feasible to fine-tune them for improved report summarization\ncapabilities on-premise? Second, what are the metrics we could leverage to\nassess the quality of these summaries? We conduct experiments on two different\nfine-tuning approaches in parallel and our findings reveal interesting trends\nregarding the utility of fine-tuning LLMs. Specifically, we find that in many\ncases, fine-tuning helps improve summary quality and in other cases it helps by\nreducing the number of invalid or garbage summaries.",
      "tldr_zh": "本研究探讨了微调大型语言模型 (LLMs) 用于报告总结（包括政府档案、新闻和情报报告）的有效性，特别是在 ground-truth summaries 可能缺失且计算资源有限（on-premise，使用一两个 A100 GPU）的条件下。研究者通过监督和非监督微调方法进行实验，评估了微调的可行性以及总结质量的评估指标。结果显示，微调在许多情况下提高了总结质量，并在其他情况下减少了无效或垃圾总结，为资源受限环境下的报告总结提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10676v1",
      "published_date": "2025-03-10 23:47:11 UTC",
      "updated_date": "2025-03-10 23:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:01:41.123037"
    },
    {
      "arxiv_id": "2503.07914v1",
      "title": "Demystifying the Accuracy-Interpretability Trade-Off: A Case Study of Inferring Ratings from Reviews",
      "title_zh": "揭开准确性-可解释性权衡的谜团：从评论中推断评分的案例研究",
      "authors": [
        "Pranjal Atrey",
        "Michael P. Brundage",
        "Min Wu",
        "Sanghamitra Dutta"
      ],
      "abstract": "Interpretable machine learning models offer understandable reasoning behind\ntheir decision-making process, though they may not always match the performance\nof their black-box counterparts. This trade-off between interpretability and\nmodel performance has sparked discussions around the deployment of AI,\nparticularly in critical applications where knowing the rationale of\ndecision-making is essential for trust and accountability. In this study, we\nconduct a comparative analysis of several black-box and interpretable models,\nfocusing on a specific NLP use case that has received limited attention:\ninferring ratings from reviews. Through this use case, we explore the intricate\nrelationship between the performance and interpretability of different models.\nWe introduce a quantitative score called Composite Interpretability (CI) to\nhelp visualize the trade-off between interpretability and performance,\nparticularly in the case of composite models. Our results indicate that, in\ngeneral, the learning performance improves as interpretability decreases, but\nthis relationship is not strictly monotonic, and there are instances where\ninterpretable models are more advantageous.",
      "tldr_zh": "本研究探讨了机器学习模型在准确性和可解释性之间的权衡，聚焦于一个较少研究的NLP任务：从评论中推断评分。研究者通过比较黑盒模型和可解释模型，引入了Composite Interpretability (CI)评分来量化性能与可解释性的关系。结果表明，模型性能一般随可解释性降低而提升，但这种关系并非严格单调，在某些情况下可解释模型更具优势。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at DAI Workshop, AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07914v1",
      "published_date": "2025-03-10 23:17:46 UTC",
      "updated_date": "2025-03-10 23:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:01:52.618019"
    },
    {
      "arxiv_id": "2503.07911v1",
      "title": "Visual and Text Prompt Segmentation: A Novel Multi-Model Framework for Remote Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Xing Zi",
        "Kairui Jin",
        "Xian Tao",
        "Jun Li",
        "Ali Braytee",
        "Rajiv Ratn Shah",
        "Mukesh Prasad"
      ],
      "abstract": "Pixel-level segmentation is essential in remote sensing, where foundational\nvision models like CLIP and Segment Anything Model(SAM) have demonstrated\nsignificant capabilities in zero-shot segmentation tasks. Despite their\nadvances, challenges specific to remote sensing remain substantial. Firstly,\nThe SAM without clear prompt constraints, often generates redundant masks, and\nmaking post-processing more complex. Secondly, the CLIP model, mainly designed\nfor global feature alignment in foundational models, often overlooks local\nobjects crucial to remote sensing. This oversight leads to inaccurate\nrecognition or misplaced focus in multi-target remote sensing imagery. Thirdly,\nboth models have not been pre-trained on multi-scale aerial views, increasing\nthe likelihood of detection failures. To tackle these challenges, we introduce\nthe innovative VTPSeg pipeline, utilizing the strengths of Grounding DINO,\nCLIP, and SAM for enhanced open-vocabulary image segmentation. The Grounding\nDINO+(GD+) module generates initial candidate bounding boxes, while the CLIP\nFilter++(CLIP++) module uses a combination of visual and textual prompts to\nrefine and filter out irrelevant object bounding boxes, ensuring that only\npertinent objects are considered. Subsequently, these refined bounding boxes\nserve as specific prompts for the FastSAM model, which executes precise\nsegmentation. Our VTPSeg is validated by experimental and ablation study\nresults on five popular remote sensing image segmentation datasets.",
      "tldr_zh": "该论文针对遥感领域的像素级分割问题，分析了现有模型如 CLIP 和 Segment Anything Model (SAM) 的不足，包括生成冗余 masks、忽略局部对象以及未针对多尺度航空视图预训练等问题。作者提出了一种创新框架 VTPSeg，利用 Grounding DINO+ (GD+) 生成初始候选边界框，CLIP Filter++ (CLIP++) 通过视觉和文本提示精炼过滤无关对象，并将这些边界框作为提示输入 FastSAM 进行精确分割。该框架在五个流行的遥感图像分割数据集上通过实验和消融研究得到验证，展示了显著的性能提升。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.MM",
      "comment": "Under Review - IEEE Journal of Selected Topics in Applied Earth\n  Observations and Remote Sensing",
      "pdf_url": "http://arxiv.org/pdf/2503.07911v1",
      "published_date": "2025-03-10 23:15:57 UTC",
      "updated_date": "2025-03-10 23:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:02:05.562057"
    },
    {
      "arxiv_id": "2503.07909v1",
      "title": "FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted Scene Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Dennis Rotondi",
        "Fabio Scaparro",
        "Hermann Blum",
        "Kai O. Arras"
      ],
      "abstract": "The concept of 3D scene graphs is increasingly recognized as a powerful\nsemantic and hierarchical representation of the environment. Current approaches\noften address this at a coarse, object-level resolution. In contrast, our goal\nis to develop a representation that enables robots to directly interact with\ntheir environment by identifying both the location of functional interactive\nelements and how these can be used. To achieve this, we focus on detecting and\nstoring objects at a finer resolution, focusing on affordance-relevant parts.\nThe primary challenge lies in the scarcity of data that extends beyond\ninstance-level detection and the inherent difficulty of capturing detailed\nobject features using robotic sensors. We leverage currently available 3D\nresources to generate 2D data and train a detector, which is then used to\naugment the standard 3D scene graph generation pipeline. Through our\nexperiments, we demonstrate that our approach achieves functional element\nsegmentation comparable to state-of-the-art 3D models and that our augmentation\nenables task-driven affordance grounding with higher accuracy than the current\nsolutions.",
      "tldr_zh": "本文提出 FunGraph，一种功能感知的 3D scene graphs 框架，旨在帮助机器人通过识别功能交互元素的精确位置和使用方式，实现基于语言提示的场景互动。该方法利用现有 3D 资源生成 2D 数据训练检测器，并增强标准的 3D scene graphs 生成管道，聚焦于 affordance 相关物体部分的精细检测。实验结果表明，FunGraph 在功能元素分割上与最先进 3D 模型相当，并在任务驱动的 affordance grounding 上比现有解决方案实现更高准确率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07909v1",
      "published_date": "2025-03-10 23:13:35 UTC",
      "updated_date": "2025-03-10 23:13:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:02:17.274775"
    },
    {
      "arxiv_id": "2503.07891v1",
      "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhyuk Lee",
        "Feiyang Chen",
        "Sahil Dua",
        "Daniel Cer",
        "Madhuri Shanbhogue",
        "Iftekhar Naim",
        "Gustavo Hernández Ábrego",
        "Zhe Li",
        "Kaifeng Chen",
        "Henrique Schechter Vera",
        "Xiaoqi Ren",
        "Shanfeng Zhang",
        "Daniel Salz",
        "Michael Boratko",
        "Jay Han",
        "Blair Chen",
        "Shuo Huang",
        "Vikram Rao",
        "Paul Suganthan",
        "Feng Han",
        "Andreas Doumanoglou",
        "Nithi Gupta",
        "Fedor Moiseev",
        "Cathy Yip",
        "Aashi Jain",
        "Simon Baumgartner",
        "Shahrokh Shahi",
        "Frank Palma Gomez",
        "Sandeep Mariserla",
        "Min Choi",
        "Parashar Shah",
        "Sonam Goenka",
        "Ke Chen",
        "Ye Xia",
        "Koert Chen",
        "Sai Meher Karthik Duddu",
        "Yichang Chen",
        "Trevor Walker",
        "Wenlei Zhou",
        "Rakesh Ghiya",
        "Zach Gleicher",
        "Karan Gill",
        "Zhe Dong",
        "Mojtaba Seyedhosseini",
        "Yunhsuan Sung",
        "Raphael Hoffmann",
        "Tom Duerig"
      ],
      "abstract": "In this report, we introduce Gemini Embedding, a state-of-the-art embedding\nmodel leveraging the power of Gemini, Google's most capable large language\nmodel. Capitalizing on Gemini's inherent multilingual and code understanding\ncapabilities, Gemini Embedding produces highly generalizable embeddings for\ntext spanning numerous languages and textual modalities. The representations\ngenerated by Gemini Embedding can be precomputed and applied to a variety of\ndownstream tasks including classification, similarity, clustering, ranking, and\nretrieval. Evaluated on the Massive Multilingual Text Embedding Benchmark\n(MMTEB), which includes over one hundred tasks across 250+ languages, Gemini\nEmbedding substantially outperforms prior state-of-the-art models,\ndemonstrating considerable improvements in embedding quality. Achieving\nstate-of-the-art performance across MMTEB's multilingual, English, and code\nbenchmarks, our unified model demonstrates strong capabilities across a broad\nselection of tasks and surpasses specialized domain-specific models.",
      "tldr_zh": "本研究引入了Gemini Embedding，一种基于Google的Gemini大语言模型的先进嵌入模型，利用其多语言和代码理解能力，生成高度泛化的文本嵌入，支持多种语言和文本模式。这些嵌入可以预计算并应用于分类、相似性、聚类、排名和检索等下游任务。在Massive Multilingual Text Embedding Benchmark (MMTEB)测试中，Gemini Embedding在超过一百个任务和250+语言上大幅超过了先前的状态模型，特别是在多语言、英语和代码基准上表现出色，并超越了专业领域模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07891v1",
      "published_date": "2025-03-10 22:16:45 UTC",
      "updated_date": "2025-03-10 22:16:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:02:28.845215"
    },
    {
      "arxiv_id": "2503.16491v1",
      "title": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
      "title_zh": "生成式 AI 编码助手对视力受损开发者的影响",
      "authors": [
        "Claudia Flores-Saviaga",
        "Benjamin V. Hanrahan",
        "Kashif Imteyaz",
        "Steven Clarke",
        "Saiph Savage"
      ],
      "abstract": "The rapid adoption of generative AI in software development has impacted the\nindustry, yet its effects on developers with visual impairments remain largely\nunexplored. To address this gap, we used an Activity Theory framework to\nexamine how developers with visual impairments interact with AI coding\nassistants. For this purpose, we conducted a study where developers who are\nvisually impaired completed a series of programming tasks using a generative AI\ncoding assistant. We uncovered that, while participants found the AI assistant\nbeneficial and reported significant advantages, they also highlighted\naccessibility challenges. Specifically, the AI coding assistant often\nexacerbated existing accessibility barriers and introduced new challenges. For\nexample, it overwhelmed users with an excessive number of suggestions, leading\ndevelopers who are visually impaired to express a desire for ``AI timeouts.''\nAdditionally, the generative AI coding assistant made it more difficult for\ndevelopers to switch contexts between the AI-generated content and their own\ncode. Despite these challenges, participants were optimistic about the\npotential of AI coding assistants to transform the coding experience for\ndevelopers with visual impairments. Our findings emphasize the need to apply\nactivity-centered design principles to generative AI assistants, ensuring they\nbetter align with user behaviors and address specific accessibility needs. This\napproach can enable the assistants to provide more intuitive, inclusive, and\neffective experiences, while also contributing to the broader goal of enhancing\naccessibility in software development.",
      "tldr_zh": "这篇论文使用 Activity Theory 框架，探讨了生成式 AI 编码助手对视力障碍开发者的影响，通过让参与者完成编程任务来分析其互动过程。研究发现，虽然 AI 助手提供了显著优势（如提升效率），但也带来了可访问性挑战，例如过多建议导致开发者需求“AI timeouts”和上下文切换困难。总体而言，参与者对 AI 改变编码体验持乐观态度，并强调需应用 activity-centered design 原则，以设计更直观、包容的 AI 助手，从而提升软件开发的整体可访问性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5; H.5.3"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 3 figures, published in the ACM Conference on Human Factors\n  in Computing Systems 2025 (CHI'25)",
      "pdf_url": "http://arxiv.org/pdf/2503.16491v1",
      "published_date": "2025-03-10 22:06:43 UTC",
      "updated_date": "2025-03-10 22:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:02:41.259325"
    },
    {
      "arxiv_id": "2503.07885v1",
      "title": "Safety Guardrails for LLM-Enabled Robots",
      "title_zh": "针对 LLM 启用的机器人的安全护栏",
      "authors": [
        "Zachary Ravichandran",
        "Alexander Robey",
        "Vijay Kumar",
        "George J. Pappas",
        "Hamed Hassani"
      ],
      "abstract": "Although the integration of large language models (LLMs) into robotics has\nunlocked transformative capabilities, it has also introduced significant safety\nconcerns, ranging from average-case LLM errors (e.g., hallucinations) to\nadversarial jailbreaking attacks, which can produce harmful robot behavior in\nreal-world settings. Traditional robot safety approaches do not address the\nnovel vulnerabilities of LLMs, and current LLM safety guardrails overlook the\nphysical risks posed by robots operating in dynamic real-world environments. In\nthis paper, we propose RoboGuard, a two-stage guardrail architecture to ensure\nthe safety of LLM-enabled robots. RoboGuard first contextualizes pre-defined\nsafety rules by grounding them in the robot's environment using a root-of-trust\nLLM, which employs chain-of-thought (CoT) reasoning to generate rigorous safety\nspecifications, such as temporal logic constraints. RoboGuard then resolves\npotential conflicts between these contextual safety specifications and a\npossibly unsafe plan using temporal logic control synthesis, which ensures\nsafety compliance while minimally violating user preferences. Through extensive\nsimulation and real-world experiments that consider worst-case jailbreaking\nattacks, we demonstrate that RoboGuard reduces the execution of unsafe plans\nfrom 92% to below 2.5% without compromising performance on safe plans. We also\ndemonstrate that RoboGuard is resource-efficient, robust against adaptive\nattacks, and significantly enhanced by enabling its root-of-trust LLM to\nperform CoT reasoning. These results underscore the potential of RoboGuard to\nmitigate the safety risks and enhance the reliability of LLM-enabled robots.",
      "tldr_zh": "这篇论文探讨了将大型语言模型（LLM）集成到机器人中的安全风险，包括LLM的幻觉错误和恶意攻击可能导致的危害行为。作者提出了RoboGuard框架，一个两阶段的防护机制：首先，使用root-of-trust LLM结合Chain-of-Thought (CoT)推理，将预定义的安全规则与机器人环境相结合，生成如temporal logic constraints的安全规范；其次，通过temporal logic control synthesis解决规范与用户计划的冲突，确保安全优先同时最小化偏好损失。实验结果显示，RoboGuard在模拟和真实环境中将unsafe plans执行率从92%降至低于2.5%，并证明其资源高效、对攻击鲁棒且CoT推理进一步提升了可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07885v1",
      "published_date": "2025-03-10 22:01:56 UTC",
      "updated_date": "2025-03-10 22:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:02:54.869980"
    },
    {
      "arxiv_id": "2503.07884v1",
      "title": "LLMIdxAdvis: Resource-Efficient Index Advisor Utilizing Large Language Model",
      "title_zh": "LLMIdxAdvis：利用大型语言模型的资源高效索引顾问",
      "authors": [
        "Xinxin Zhao",
        "Haoyang Li",
        "Jing Zhang",
        "Xinmei Huang",
        "Tieying Zhang",
        "Jianjun Chen",
        "Rui Shi",
        "Cuiping Li",
        "Hong Chen"
      ],
      "abstract": "Index recommendation is essential for improving query performance in database\nmanagement systems (DBMSs) through creating an optimal set of indexes under\nspecific constraints. Traditional methods, such as heuristic and learning-based\napproaches, are effective but face challenges like lengthy recommendation time,\nresource-intensive training, and poor generalization across different workloads\nand database schemas. To address these issues, we propose LLMIdxAdvis, a\nresource-efficient index advisor that uses large language models (LLMs) without\nextensive fine-tuning. LLMIdxAdvis frames index recommendation as a\nsequence-to-sequence task, taking target workload, storage constraint, and\ncorresponding database environment as input, and directly outputting\nrecommended indexes. It constructs a high-quality demonstration pool offline,\nusing GPT-4-Turbo to synthesize diverse SQL queries and applying integrated\nheuristic methods to collect both default and refined labels. During\nrecommendation, these demonstrations are ranked to inject database expertise\nvia in-context learning. Additionally, LLMIdxAdvis extracts workload features\ninvolving specific column statistical information to strengthen LLM's\nunderstanding, and introduces a novel inference scaling strategy combining\nvertical scaling (via ''Index-Guided Major Voting'' and Best-of-N) and\nhorizontal scaling (through iterative ''self-optimization'' with database\nfeedback) to enhance reliability. Experiments on 3 OLAP and 2 real-world\nbenchmarks reveal that LLMIdxAdvis delivers competitive index recommendation\nwith reduced runtime, and generalizes effectively across different workloads\nand database schemas.",
      "tldr_zh": "该研究提出LLMIdxAdvis，一种资源高效的索引顾问系统，利用大型语言模型(LLMs)而非大量微调，解决传统索引推荐方法在推荐时间长、资源消耗大和泛化能力差等方面的挑战。系统将索引推荐任务框架为序列到序列问题，输入包括工作负载、存储约束和数据库环境，直接输出推荐索引，并通过离线构建高质量演示池（使用GPT-4-Turbo合成SQL查询和启发式方法收集标签）、上下文学习注入数据库专业知识，以及提取工作负载特征来增强LLM理解。实验在3个OLAP基准和2个真实世界基准上显示，LLMIdxAdvis提供竞争性推荐结果、显著减少运行时间，并在不同工作负载和数据库模式上表现出色泛化能力。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07884v1",
      "published_date": "2025-03-10 22:01:24 UTC",
      "updated_date": "2025-03-10 22:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:03:05.464394"
    },
    {
      "arxiv_id": "2503.07878v2",
      "title": "Measuring directional bias amplification in image captions using predictability",
      "title_zh": "使用可预测性测量图像标题中的定向偏差放大",
      "authors": [
        "Rahul Nair",
        "Bhanu Tokas",
        "Neel Shah",
        "Hannah Kerner"
      ],
      "abstract": "When we train models on biased ML datasets, they not only learn these biases\nbut can inflate them at test time - a phenomenon called bias amplification. To\nmeasure bias amplification in ML datasets, many co-occurrence-based metrics\nhave been proposed. Co-occurrence-based metrics are effective in measuring bias\namplification in simple problems like image classification. However, these\nmetrics are ineffective for complex problems like image captioning as they\ncannot capture the semantics of a caption. To measure bias amplification in\ncaptions, prior work introduced a predictability-based metric called Leakage in\nCaptioning (LIC). While LIC captures the semantics and context of captions, it\nhas limitations. LIC cannot identify the direction in which bias is amplified,\npoorly estimates dataset bias due to a weak vocabulary substitution strategy,\nand is highly sensitive to attacker models (a hyperparameter in\npredictability-based metrics). To overcome these issues, we propose Directional\nPredictability Amplification in Captioning (DPAC). DPAC measures directional\nbias amplification in captions, provides a better estimate of dataset bias\nusing an improved substitution strategy, and is less sensitive to attacker\nmodels. Our experiments on the COCO captioning dataset show how DPAC is the\nmost reliable metric to measure bias amplification in captions.",
      "tldr_zh": "本研究探讨了在图像描述（image captioning）任务中如何测量偏差放大（bias amplification），指出现有的基于共现（co-occurrence-based metrics）的指标虽适用于简单问题如图像分类，但无法捕捉描述的语义和上下文。作者提出了一种新的指标Directional Predictability Amplification in Captioning (DPAC)，它能识别偏差放大的方向、通过改进的词汇替换策略更好地估计数据集偏差，并减少对攻击者模型（attacker models）的敏感性。实验结果显示，在COCO数据集上，DPAC是测量图像描述中偏差放大的最可靠指标。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07878v2",
      "published_date": "2025-03-10 21:50:58 UTC",
      "updated_date": "2025-03-12 02:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:03:18.082082"
    },
    {
      "arxiv_id": "2503.07874v1",
      "title": "Topology-Preserving Loss for Accurate and Anatomically Consistent Cardiac Mesh Reconstruction",
      "title_zh": "拓扑保持损失函数用于准确且解剖学一致的心脏网格重建",
      "authors": [
        "Chenyu Zhang",
        "Yihao Luo",
        "Yinzhe Wu",
        "Choon Hwai Yap",
        "Guang Yang"
      ],
      "abstract": "Accurate cardiac mesh reconstruction from volumetric data is essential for\npersonalized cardiac modeling and clinical analysis. However, existing\ndeformation-based approaches are prone to topological inconsistencies,\nparticularly membrane penetration, which undermines the anatomical plausibility\nof the reconstructed mesh. To address this issue, we introduce\nTopology-Preserving Mesh Loss (TPM Loss), a novel loss function that explicitly\nenforces topological constraints during mesh deformation. By identifying\ntopology-violating points, TPM Loss ensures spatially consistent\nreconstructions. Extensive experiments on CT and MRI datasets show that TPM\nLoss reduces topology violations by up to 93.1% while maintaining high\nsegmentation accuracy (DSC: 89.1%-92.9%) and improving mesh fidelity (Chamfer\nDistance reduction up to 0.26 mm). These results demonstrate that TPM Loss\neffectively prevents membrane penetration and significantly improves cardiac\nmesh quality, enabling more accurate and anatomically consistent cardiac\nreconstructions.",
      "tldr_zh": "本研究针对心脏网格重建中基于变形的现有方法容易出现拓扑不一致问题（如 membrane penetration），从而影响解剖学合理性，提出了一种新型损失函数 Topology-Preserving Mesh Loss (TPM Loss)。TPM Loss 通过识别 topology-violating points 并显式强制拓扑约束，确保网格变形过程中的空间一致性。在 CT 和 MRI 数据集上的广泛实验显示，TPM Loss 将拓扑违规减少高达 93.1%，同时保持高分割准确率 (DSC: 89.1%-92.9%) 并显著改善网格保真度 (Chamfer Distance 减少至 0.26 mm)。这一创新方法有效防止 membrane penetration，提升了心脏网格重建的准确性和解剖学一致性，为个性化心脏建模和临床分析提供更可靠的支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07874v1",
      "published_date": "2025-03-10 21:46:57 UTC",
      "updated_date": "2025-03-10 21:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:03:29.954539"
    },
    {
      "arxiv_id": "2503.07871v1",
      "title": "MapQA: Open-domain Geospatial Question Answering on Map Data",
      "title_zh": "MapQA：基于地图数据的开放域地理空间问答",
      "authors": [
        "Zekun Li",
        "Malcolm Grossman",
        "Eric",
        "Qasemi",
        "Mihir Kulkarni",
        "Muhao Chen",
        "Yao-Yi Chiang"
      ],
      "abstract": "Geospatial question answering (QA) is a fundamental task in navigation and\npoint of interest (POI) searches. While existing geospatial QA datasets exist,\nthey are limited in both scale and diversity, often relying solely on textual\ndescriptions of geo-entities without considering their geometries. A major\nchallenge in scaling geospatial QA datasets for reasoning lies in the\ncomplexity of geospatial relationships, which require integrating spatial\nstructures, topological dependencies, and multi-hop reasoning capabilities that\nmost text-based QA datasets lack. To address these limitations, we introduce\nMapQA, a novel dataset that not only provides question-answer pairs but also\nincludes the geometries of geo-entities referenced in the questions. MapQA is\nconstructed using SQL query templates to extract question-answer pairs from\nOpenStreetMap (OSM) for two study regions: Southern California and Illinois. It\nconsists of 3,154 QA pairs spanning nine question types that require geospatial\nreasoning, such as neighborhood inference and geo-entity type identification.\nCompared to existing datasets, MapQA expands both the number and diversity of\ngeospatial question types. We explore two approaches to tackle this challenge:\n(1) a retrieval-based language model that ranks candidate geo-entities by\nembedding similarity, and (2) a large language model (LLM) that generates SQL\nqueries from natural language questions and geo-entity attributes, which are\nthen executed against an OSM database. Our findings indicate that\nretrieval-based methods effectively capture concepts like closeness and\ndirection but struggle with questions that require explicit computations (e.g.,\ndistance calculations). LLMs (e.g., GPT and Gemini) excel at generating SQL\nqueries for one-hop reasoning but face challenges with multi-hop reasoning,\nhighlighting a key bottleneck in advancing geospatial QA systems.",
      "tldr_zh": "这篇论文引入了 MapQA，一个开源数据集，用于开放域地理空间问答（Geospatial QA），它不仅包含问题-答案对，还包括地理实体的几何信息，以解决现有数据集在规模、多样性和空间关系推理方面的局限性。MapQA 通过 SQL 查询模板从 OpenStreetMap (OSM) 提取数据，涵盖南加州和伊利诺斯州，共 3,154 个 QA 对，涉及九种类型的问题，如邻域推断和地理实体类型识别。作者探索了两种方法：基于检索的语言模型（通过嵌入相似性排名候选实体）和大型语言模型 (LLM) 生成 SQL 查询，结果显示前者擅长处理接近度和方向，而 LLM 在多跳推理上存在挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07871v1",
      "published_date": "2025-03-10 21:37:22 UTC",
      "updated_date": "2025-03-10 21:37:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:03:43.141219"
    },
    {
      "arxiv_id": "2503.07869v1",
      "title": "Right Reward Right Time for Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh Linh Nguyen",
        "Dinh Thai Hoang",
        "Diep N. Nguyen",
        "Quoc-Viet Pham"
      ],
      "abstract": "Critical learning periods (CLPs) in federated learning (FL) refer to early\nstages during which low-quality contributions (e.g., sparse training data\navailability) can permanently impair the learning performance of the global\nmodel owned by the model owner (i.e., the cloud server). However, strategies to\nmotivate clients with high-quality contributions to join the FL training\nprocess and share trained model updates during CLPs remain underexplored.\nAdditionally, existing incentive mechanisms in FL treat all training periods\nequally, which consequently fails to motivate clients to participate early.\nCompounding this challenge is the cloud's limited knowledge of client training\ncapabilities due to privacy regulations, leading to information asymmetry.\nTherefore, in this article, we propose a time-aware incentive mechanism, called\nRight Reward Right Time (R3T), to encourage client involvement, especially\nduring CLPs, to maximize the utility of the cloud in FL. Specifically, the\ncloud utility function captures the trade-off between the achieved model\nperformance and payments allocated for clients' contributions, while accounting\nfor clients' time and system capabilities, efforts, joining time, and rewards.\nThen, we analytically derive the optimal contract for the cloud and devise a\nCLP-aware mechanism to incentivize early participation and efforts while\nmaximizing cloud utility, even under information asymmetry. By providing the\nright reward at the right time, our approach can attract the highest-quality\ncontributions during CLPs. Simulation and proof-of-concept studies show that\nR3T increases cloud utility and is more economically effective than benchmarks.\nNotably, our proof-of-concept results show up to a 47.6% reduction in the total\nnumber of clients and up to a 300% improvement in convergence time while\nreaching competitive test accuracies compared with incentive mechanism\nbenchmarks.",
      "tldr_zh": "该论文探讨了联邦学习（Federated Learning, FL）中的关键学习期（Critical Learning Periods, CLPs），这些时期若出现低质量贡献（如稀疏训练数据），会永久损害全局模型性能，并提出了一种时间感知激励机制Right Reward Right Time (R3T)来解决这一问题。R3T通过优化云端效用函数，考虑客户端的时间、能力、努力、加入时间和奖励，设计出最优合同和CLP感知机制，以鼓励高质客户端在早期参与，即使在信息不对称的情况下。实验结果显示，R3T比基准机制提高了云端效用，减少了47.6%的客户端数量，并将收敛时间缩短了300%，同时保持了竞争性的测试准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE Journal Submission",
      "pdf_url": "http://arxiv.org/pdf/2503.07869v1",
      "published_date": "2025-03-10 21:36:42 UTC",
      "updated_date": "2025-03-10 21:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:03:53.358336"
    },
    {
      "arxiv_id": "2503.07860v1",
      "title": "Video Action Differencing",
      "title_zh": "翻译失败",
      "authors": [
        "James Burgess",
        "Xiaohan Wang",
        "Yuhui Zhang",
        "Anita Rau",
        "Alejandro Lozano",
        "Lisa Dunlap",
        "Trevor Darrell",
        "Serena Yeung-Levy"
      ],
      "abstract": "How do two individuals differ when performing the same action? In this work,\nwe introduce Video Action Differencing (VidDiff), the novel task of identifying\nsubtle differences between videos of the same action, which has many\napplications, such as coaching and skill learning. To enable development on\nthis new task, we first create VidDiffBench, a benchmark dataset containing 549\nvideo pairs, with human annotations of 4,469 fine-grained action differences\nand 2,075 localization timestamps indicating where these differences occur. Our\nexperiments demonstrate that VidDiffBench poses a significant challenge for\nstate-of-the-art large multimodal models (LMMs), such as GPT-4o and Qwen2-VL.\nBy analyzing failure cases of LMMs on VidDiffBench, we highlight two key\nchallenges for this task: localizing relevant sub-actions over two videos and\nfine-grained frame comparison. To overcome these, we propose the VidDiff\nmethod, an agentic workflow that breaks the task into three stages: action\ndifference proposal, keyframe localization, and frame differencing, each stage\nutilizing specialized foundation models. To encourage future research in this\nnew task, we release the benchmark at\nhttps://huggingface.co/datasets/jmhb/VidDiffBench and code at\nhttp://jmhb0.github.io/viddiff.",
      "tldr_zh": "本研究引入了Video Action Differencing (VidDiff)任务，用于识别同一动作在不同视频间的细微差异，以应用于指导和技能学习等领域。为支持这一任务，作者创建了VidDiffBench基准数据集，包含549对视频、4,469个细粒度动作差异标注和2,075个定位时间戳。实验显示，现有大型多模态模型（LMMs）如GPT-4o和Qwen2-VL在该基准上表现不佳，主要面临跨视频子动作定位和细粒度帧比较的挑战。为此，提出VidDiff方法，一个代理工作流，包括动作差异提案、关键帧定位和帧差异比较阶段，每阶段利用专用基础模型。该工作通过发布数据集和代码，促进未来相关研究的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025 (International Conference on Learning Representations)\n  Project page: http://jmhb0.github.io/viddiff Benchmark:\n  https://huggingface.co/datasets/jmhb/VidDiffBench",
      "pdf_url": "http://arxiv.org/pdf/2503.07860v1",
      "published_date": "2025-03-10 21:18:32 UTC",
      "updated_date": "2025-03-10 21:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:04:06.793139"
    },
    {
      "arxiv_id": "2503.08722v2",
      "title": "A Recipe for Improving Remote Sensing VLM Zero Shot Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Aviad Barzilai",
        "Yotam Gigi",
        "Amr Helmy",
        "Vered Silverman",
        "Yehonathan Refael",
        "Bolous Jaber",
        "Tomer Shekel",
        "George Leifman",
        "Genady Beryozkin"
      ],
      "abstract": "Foundation models have had a significant impact across various AI\napplications, enabling use cases that were previously impossible. Contrastive\nVisual Language Models (VLMs), in particular, have outperformed other\ntechniques in many tasks. However, their prevalence in remote sensing (RS) is\nstill limited, due to the scarcity of diverse remote-sensing visual-language\ndatasets. In this work we introduce two novel image-caption datasets for\ntraining of remote sensing foundation models. The first dataset pairs aerial\nand satellite imagery with captions generated by Gemini using landmarks\nextracted from Google Maps. The second dataset utilizes public web images and\ntheir corresponding alt-text, filtered for the remote sensing domain, resulting\nin a diverse dataset with greater breadth in image styles and subject matter.\nThese datasets are used to pre-train the\nMaMMUT~\\citep{kuo2023mammutsimplearchitecturejoint} VLM architecture, resulting\nin state-of-the-art generalization performance in zero-shot cross-modal\nretrieval on well-known public benchmarks. Finally, we present our ongoing\nresearch to distill image-level knowledge gained in the VLM contrastive\ntraining procedure to enhance the model's localization ability. Specifically,\nwe iteratively generate pseudo-labels for image regions based on the model's\nattention maps and use these labels for further training. To mitigate noisy\nattention maps and create robust segmentation masks, we introduce a novel\nattention-pooling mechanism called the Smooth-Attention-Operation.",
      "tldr_zh": "本文提出了一种改进遥感领域 Visual Language Models (VLMs) 零样本泛化性能的方法，包括引入两个新图像标题数据集。第一个数据集将航空和卫星图像与基于 Google Maps 地标的 Gemini 生成标题配对，第二个数据集则使用过滤后的公共网络图像及其 alt-text，以增加图像样式和主题的多样性。这些数据集用于预训练 MaMMUT 架构，在零样本跨模态检索的公共基准上实现了最先进的泛化性能。此外，研究探索了从 VLM 训练中提炼图像级知识的 ongoing research，通过迭代生成基于注意力的伪标签和引入 Smooth-Attention-Operation 机制，提升了模型的定位和分割能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08722v2",
      "published_date": "2025-03-10 21:09:02 UTC",
      "updated_date": "2025-03-17 13:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:04:19.241548"
    },
    {
      "arxiv_id": "2503.07852v1",
      "title": "CIMAGE: Exploiting the Conditional Independence in Masked Graph Auto-encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Jongwon Park",
        "Heesoo Jung",
        "Hogun Park"
      ],
      "abstract": "Recent Self-Supervised Learning (SSL) methods encapsulating relational\ninformation via masking in Graph Neural Networks (GNNs) have shown promising\nperformance. However, most existing approaches rely on random masking\nstrategies in either feature or graph space, which may fail to capture\ntask-relevant information fully. We posit that this limitation stems from an\ninability to achieve minimum redundancy between masked and unmasked components\nwhile ensuring maximum relevance of both to potential downstream tasks.\nConditional Independence (CI) inherently satisfies the minimum redundancy and\nmaximum relevance criteria, but its application typically requires access to\ndownstream labels. To address this challenge, we introduce CIMAGE, a novel\napproach that leverages Conditional Independence to guide an effective masking\nstrategy within the latent space. CIMAGE utilizes CI-aware latent factor\ndecomposition to generate two distinct contexts, leveraging high-confidence\npseudo-labels derived from unsupervised graph clustering. In this framework,\nthe pretext task involves reconstructing the masked second context solely from\nthe information provided by the first context. Our theoretical analysis further\nsupports the superiority of CIMAGE's novel CI-aware masking method by\ndemonstrating that the learned embedding exhibits approximate linear\nseparability, which enables accurate predictions for the downstream task.\nComprehensive evaluations across diverse graph benchmarks illustrate the\nadvantage of CIMAGE, with notably higher average rankings on node\nclassification and link prediction tasks. Notably, our proposed model\nhighlights the under-explored potential of CI in enhancing graph SSL\nmethodologies and offers enriched insights for effective graph representation\nlearning.",
      "tldr_zh": "本论文提出 CIMAGE，一种新型方法，通过利用 Conditional Independence (CI) 来优化 Masked Graph Auto-encoders 中的掩码策略，解决现有 Self-Supervised Learning (SSL) 在 Graph Neural Networks (GNNs) 中依赖随机掩码导致的任务相关信息不足问题。CIMAGE 通过 CI-aware 潜变量分解生成两个上下文，利用无监督图聚类的高置信伪标签作为指导，并设计预训练任务仅从第一个上下文重建被掩码的第二个上下文。实验结果显示，该方法在各种图基准上显著提升节点分类和链接预测的性能，平均排名更高，且理论分析证明其学得的嵌入具有近似线性可分性，从而增强了图表示学习的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the WSDM 2025 Oral. This is an extended version of the\n  original submission. Typos are also corrected",
      "pdf_url": "http://arxiv.org/pdf/2503.07852v1",
      "published_date": "2025-03-10 20:59:27 UTC",
      "updated_date": "2025-03-10 20:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:04:30.849408"
    },
    {
      "arxiv_id": "2503.07849v1",
      "title": "Actual Causation and Nondeterministic Causal Models",
      "title_zh": "实际因果与非确定性因果模型",
      "authors": [
        "Sander Beckers"
      ],
      "abstract": "In (Beckers, 2025) I introduced nondeterministic causal models as a\ngeneralization of Pearl's standard deterministic causal models. I here take\nadvantage of the increased expressivity offered by these models to offer a\nnovel definition of actual causation (that also applies to deterministic\nmodels). Instead of motivating the definition by way of (often subjective)\nintuitions about examples, I proceed by developing it based entirely on the\nunique function that it can fulfil in communicating and learning a causal\nmodel. First I generalize the more basic notion of counterfactual dependence,\nsecond I show how this notion has a vital role to play in the logic of causal\ndiscovery, third I introduce the notion of a structural simplification of a\ncausal model, and lastly I bring both notions together in my definition of\nactual causation. Although novel, the resulting definition arrives at verdicts\nthat are almost identical to those of my previous definition (Beckers, 2021,\n2022).",
      "tldr_zh": "本论文引入了nondeterministic causal models作为Pearl的deterministic causal models的推广，并基于此提出一个新的actual causation定义，该定义也适用于确定性模型。\n作者从actual causation在沟通和学习因果模型中的功能出发，先泛化counterfactual dependence概念，然后展示其在因果发现逻辑中的作用，并引入structural simplification来完善定义。\n结果显示，新定义的判断结果与之前版本（Beckers, 2021, 2022）几乎相同，提升了模型的表达性和适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at CLeaR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07849v1",
      "published_date": "2025-03-10 20:53:47 UTC",
      "updated_date": "2025-03-10 20:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:04:42.021733"
    },
    {
      "arxiv_id": "2503.07848v1",
      "title": "Safe Explicable Policy Search",
      "title_zh": "翻译失败",
      "authors": [
        "Akkamahadevi Hanni",
        "Jonathan Montaño",
        "Yu Zhang"
      ],
      "abstract": "When users work with AI agents, they form conscious or subconscious\nexpectations of them. Meeting user expectations is crucial for such agents to\nengage in successful interactions and teaming. However, users may form\nexpectations of an agent that differ from the agent's planned behaviors. These\ndifferences lead to the consideration of two separate decision models in the\nplanning process to generate explicable behaviors. However, little has been\ndone to incorporate safety considerations, especially in a learning setting. We\npresent Safe Explicable Policy Search (SEPS), which aims to provide a learning\napproach to explicable behavior generation while minimizing the safety risk,\nboth during and after learning. We formulate SEPS as a constrained optimization\nproblem where the agent aims to maximize an explicability score subject to\nconstraints on safety and a suboptimality criterion based on the agent's model.\nSEPS innovatively combines the capabilities of Constrained Policy Optimization\nand Explicable Policy Search. We evaluate SEPS in safety-gym environments and\nwith a physical robot experiment to show that it can learn explicable behaviors\nthat adhere to the agent's safety requirements and are efficient. Results show\nthat SEPS can generate safe and explicable behaviors while ensuring a desired\nlevel of performance w.r.t. the agent's objective, and has real-world relevance\nin human-AI teaming.",
      "tldr_zh": "该研究提出 Safe Explicable Policy Search (SEPS)，一种学习框架，旨在生成可解释的 AI 代理行为，同时最小化安全风险，以满足用户期望并提升人类-AI 团队协作。SEPS 将问题表述为约束优化问题，最大化可解释性分数，同时满足安全约束和基于代理模型的子最优性标准，并结合 Constrained Policy Optimization 和 Explicable Policy Search 的优势。在 safety-gym 环境及物理机器人实验中，SEPS 成功学习了安全、高效且可解释的行为，确保代理目标性能，并展示了在实际应用中的相关性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07848v1",
      "published_date": "2025-03-10 20:52:41 UTC",
      "updated_date": "2025-03-10 20:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:04:53.830714"
    },
    {
      "arxiv_id": "2503.07833v1",
      "title": "HalluVerse25: Fine-grained Multilingual Benchmark Dataset for LLM Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Samir Abdaljalil",
        "Hasan Kurban",
        "Erchin Serpedin"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in various contexts, yet\nremain prone to generating non-factual content, commonly referred to as\n\"hallucinations\". The literature categorizes hallucinations into several types,\nincluding entity-level, relation-level, and sentence-level hallucinations.\nHowever, existing hallucination datasets often fail to capture fine-grained\nhallucinations in multilingual settings. In this work, we introduce\nHalluVerse25, a multilingual LLM hallucination dataset that categorizes\nfine-grained hallucinations in English, Arabic, and Turkish. Our dataset\nconstruction pipeline uses an LLM to inject hallucinations into factual\nbiographical sentences, followed by a rigorous human annotation process to\nensure data quality. We evaluate several LLMs on HalluVerse25, providing\nvaluable insights into how proprietary models perform in detecting\nLLM-generated hallucinations across different contexts.",
      "tldr_zh": "该研究引入了HalluVerse25，这是一个细粒度的多语言基准数据集，用于评估大型语言模型(LLMs)的幻觉问题，包括实体级、关系级和句子级类型。数据集覆盖英语、阿拉伯语和土耳其语，通过LLMs注入幻觉到事实传记句子中，并采用严格的人工标注流程确保数据质量。研究评估了多个LLMs在HalluVerse25上的表现，揭示了专有模型在不同语境下检测幻觉的性能差异，为改进LLMs的可靠性和多语言应用提供了宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07833v1",
      "published_date": "2025-03-10 20:24:07 UTC",
      "updated_date": "2025-03-10 20:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:05:05.688979"
    },
    {
      "arxiv_id": "2503.07832v1",
      "title": "RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code",
      "title_zh": "RefactorBench：通过代码评估语言代理中的有状态推理",
      "authors": [
        "Dhruv Gautam",
        "Spandan Garg",
        "Jinu Jang",
        "Neel Sundaresan",
        "Roshanak Zilouchian Moghaddam"
      ],
      "abstract": "Recent advances in language model (LM) agents and function calling have\nenabled autonomous, feedback-driven systems to solve problems across various\ndigital domains. To better understand the unique limitations of LM agents, we\nintroduce RefactorBench, a benchmark consisting of 100 large handcrafted\nmulti-file refactoring tasks in popular open-source repositories. Solving tasks\nwithin RefactorBench requires thorough exploration of dependencies across\nmultiple files and strong adherence to relevant instructions. Every task is\ndefined by 3 natural language instructions of varying specificity and is\nmutually exclusive, allowing for the creation of longer combined tasks on the\nsame repository. Baselines on RefactorBench reveal that current LM agents\nstruggle with simple compositional tasks, solving only 22% of tasks with base\ninstructions, in contrast to a human developer with short time constraints\nsolving 87%. Through trajectory analysis, we identify various unique failure\nmodes of LM agents, and further explore the failure mode of tracking past\nactions. By adapting a baseline agent to condition on representations of state,\nwe achieve a 43.9% improvement in solving RefactorBench tasks. We further\nextend our state-aware approach to encompass entire digital environments and\noutline potential directions for future research. RefactorBench aims to support\nthe study of LM agents by providing a set of real-world, multi-hop tasks within\nthe realm of code.",
      "tldr_zh": "本文引入 RefactorBench，这是一个由 100 个手工制作的多文件重构任务组成的基准，用于评估 Language Agents 在代码环境中的状态化推理(Stateful Reasoning)能力。实验结果显示，当前 LM agents 仅能解决 22% 的基本任务，而人类开发者在短时间内可达 87%；通过轨迹分析，识别了代理的失败模式，如跟踪过去动作的不足，并通过适应基于状态表示的条件，实现了 43.9% 的性能提升。RefactorBench 旨在支持 LM agents 的研究，提供真实世界的多跳任务，并为扩展到整个数字环境指出了潜在方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE",
        "I.2.5"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2503.07832v1",
      "published_date": "2025-03-10 20:23:24 UTC",
      "updated_date": "2025-03-10 20:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:05:18.964190"
    },
    {
      "arxiv_id": "2503.08720v1",
      "title": "AI for Just Work: Constructing Diverse Imaginations of AI beyond \"Replacing Humans\"",
      "title_zh": "翻译失败",
      "authors": [
        "Weina Jin",
        "Nicholas Vincent",
        "Ghassan Hamarneh"
      ],
      "abstract": "The AI community usually focuses on \"how\" to develop AI techniques, but lacks\nthorough open discussions on \"why\" we develop AI. Lacking critical reflections\non the general visions and purposes of AI may make the community vulnerable to\nmanipulation. In this position paper, we explore the \"why\" question of AI. We\ndenote answers to the \"why\" question the imaginations of AI, which depict our\ngeneral visions, frames, and mindsets for the prospects of AI. We identify that\nthe prevailing vision in the AI community is largely a monoculture that\nemphasizes objectives such as replacing humans and improving productivity. Our\ncritical examination of this mainstream imagination highlights its underpinning\nand potentially unjust assumptions. We then call to diversify our collective\nimaginations of AI, embedding ethical assumptions from the outset in the\nimaginations of AI. To facilitate the community's pursuit of diverse\nimaginations, we demonstrate one process for constructing a new imagination of\n\"AI for just work,\" and showcase its application in the medical image synthesis\ntask to make it more ethical. We hope this work will help the AI community to\nopen dialogues with civil society on the visions and purposes of AI, and\ninspire more technical works and advocacy in pursuit of diverse and ethical\nimaginations to restore the value of AI for the public good.",
      "tldr_zh": "该论文探讨了AI社区对“为什么”开发AI的缺失讨论，强调当前主流想象（如取代人类和提升生产力）可能基于不公正假设，导致单一视野。作者呼吁多样化AI的集体imaginations of AI，从一开始嵌入伦理假设，以避免潜在操纵风险。为此，他们展示了构建“AI for just work”新想象的过程，并将其应用于医疗图像合成任务，使其更具伦理性。最终，该工作旨在激发AI社区与社会对话，推动更多技术创新和倡导，实现AI为公共利益服务。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08720v1",
      "published_date": "2025-03-10 20:03:55 UTC",
      "updated_date": "2025-03-10 20:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:05:30.455025"
    },
    {
      "arxiv_id": "2503.07817v1",
      "title": "Group Fairness in Multi-Task Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kefan Song",
        "Runnan Jiang",
        "Rohan Chandra",
        "Shangtong Zhang"
      ],
      "abstract": "This paper addresses a critical societal consideration in the application of\nReinforcement Learning (RL): ensuring equitable outcomes across different\ndemographic groups in multi-task settings. While previous work has explored\nfairness in single-task RL, many real-world applications are multi-task in\nnature and require policies to maintain fairness across all tasks. We introduce\na novel formulation of multi-task group fairness in RL and propose a\nconstrained optimization algorithm that explicitly enforces fairness\nconstraints across multiple tasks simultaneously. We have shown that our\nproposed algorithm does not violate fairness constraints with high probability\nand with sublinear regret in the finite-horizon episodic setting. Through\nexperiments in RiverSwim and MuJoCo environments, we demonstrate that our\napproach better ensures group fairness across multiple tasks compared to\nprevious methods that lack explicit multi-task fairness constraints in both the\nfinite-horizon setting and the infinite-horizon setting. Our results show that\nthe proposed algorithm achieves smaller fairness gaps while maintaining\ncomparable returns across different demographic groups and tasks, suggesting\nits potential for addressing fairness concerns in real-world multi-task RL\napplications.",
      "tldr_zh": "这篇论文探讨了在多任务强化学习（RL）中，确保不同人口统计学群体（demographic groups）的公平性问题，填补了以往单任务公平研究的空白。作者引入了多任务群体公平性的新公式，并提出了一种约束优化算法（constrained optimization algorithm），该算法同时强制执行多个任务的公平约束，并在有限地平线情景下证明了其不违反公平约束的高概率和次线性遗憾（sublinear regret）。通过在 RiverSwim 和 MuJoCo 环境中的实验，该方法比现有方法更有效地减少了公平差距，同时保持了可比的回报，展示了其在现实多任务 RL 应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07817v1",
      "published_date": "2025-03-10 19:59:59 UTC",
      "updated_date": "2025-03-10 19:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:05:43.436820"
    },
    {
      "arxiv_id": "2503.07813v1",
      "title": "AgriField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel",
      "title_zh": "翻译失败",
      "authors": [
        "Elvis Kimara",
        "Mozhgan Hadadi",
        "Jackson Godbersen",
        "Aditya Balu",
        "Talukder Jubery",
        "Yawei Li",
        "Adarsh Krishnamurthy",
        "Patrick S. Schnable",
        "Baskar Ganapathysubramanian"
      ],
      "abstract": "The application of artificial intelligence (AI) in three-dimensional (3D)\nagricultural research, particularly for maize, has been limited by the scarcity\nof large-scale, diverse datasets. While 2D image datasets are abundant, they\nfail to capture essential structural details such as leaf architecture, plant\nvolume, and spatial arrangements that 3D data provide. To address this\nlimitation, we present AgriField3D\n(https://baskargroup.github.io/AgriField3D/), a curated dataset of 3D point\nclouds of field-grown maize plants from a diverse genetic panel, designed to be\nAI-ready for advancing agricultural research. Our dataset comprises over 1,000\nhigh-quality point clouds collected using a Terrestrial Laser Scanner,\ncomplemented by procedural models that provide structured, parametric\nrepresentations of maize plants. These procedural models, generated using\nNon-Uniform Rational B-Splines (NURBS) and optimized via a two-step process\ncombining Particle Swarm Optimization (PSO) and differentiable programming,\nenable precise, scalable reconstructions of leaf surfaces and plant\narchitectures. To enhance usability, we performed graph-based segmentation to\nisolate individual leaves and stalks, ensuring consistent labeling across all\nsamples. We also conducted rigorous manual quality control on all datasets,\ncorrecting errors in segmentation, ensuring accurate leaf ordering, and\nvalidating metadata annotations. The dataset further includes metadata\ndetailing plant morphology and quality, alongside multi-resolution subsampled\nversions (100k, 50k, 10k points) optimized for various computational needs. By\nintegrating point cloud data of field grown plants with high-fidelity\nprocedural models and ensuring meticulous manual validation, AgriField3D\nprovides a comprehensive foundation for AI-driven phenotyping, plant structural\nanalysis, and 3D applications in agricultural research.",
      "tldr_zh": "该论文介绍了AgriField3D数据集，以解决AI在3D农业研究中缺乏大规模多样数据集的问题，特别是弥补2D图像无法捕捉玉米植物结构细节的不足。数据集包含超过1,000个高品质3D point clouds，通过Terrestrial Laser Scanner从多样遗传面板的田间玉米采集，并辅以使用Non-Uniform Rational B-Splines (NURBS)生成的程序模型，这些模型通过Particle Swarm Optimization (PSO)和可微编程优化，实现精确的叶片和植物架构重建。研究团队还进行了图-based segmentation、严格的手动质量控制，并提供了元数据和多分辨率子采样版本（100k、50k、10k points），为AI驱动的表型分析、植物结构分析和3D农业应用奠定全面基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Elvis Kimara and Mozhgan Hadadi contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2503.07813v1",
      "published_date": "2025-03-10 19:53:20 UTC",
      "updated_date": "2025-03-10 19:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:05:55.488816"
    },
    {
      "arxiv_id": "2503.07811v2",
      "title": "A primer on optimal transport for causal inference with observational data",
      "title_zh": "翻译失败",
      "authors": [
        "Florian F Gunsilius"
      ],
      "abstract": "The theory of optimal transportation has developed into a powerful and\nelegant framework for comparing probability distributions, with wide-ranging\napplications in all areas of science. The fundamental idea of analyzing\nprobabilities by comparing their underlying state space naturally aligns with\nthe core idea of causal inference, where understanding and quantifying\ncounterfactual states is paramount. Despite this intuitive connection, explicit\nresearch at the intersection of optimal transport and causal inference is only\nbeginning to develop. Yet, many foundational models in causal inference have\nimplicitly relied on optimal transport principles for decades, without\nrecognizing the underlying connection. Therefore, the goal of this review is to\noffer an introduction to the surprisingly deep existing connections between\noptimal transport and the identification of causal effects with observational\ndata -- where optimal transport is not just a set of potential tools, but\nactually builds the foundation of model assumptions. As a result, this review\nis intended to unify the language and notation between different areas of\nstatistics, mathematics, and econometrics, by pointing out these existing\nconnections, and to explore novel problems and directions for future work in\nboth areas derived from this realization.",
      "tldr_zh": "这篇论文介绍了最优传输（optimal transport）理论在因果推理（causal inference）中的应用，特别是针对观测数据（observational data）。论文揭示了最优传输与因果推理的深层联系，强调许多现有因果模型已隐式依赖于最优传输原则作为基础假设，从而统一了统计学、数学和计量经济学领域的语言与符号。主要贡献在于，通过回顾这些现有连接，探索了未来研究的新问题和方向，为因果效果的识别提供了更坚实的理论基础。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "econ.EM"
      ],
      "primary_category": "stat.ME",
      "comment": "24 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07811v2",
      "published_date": "2025-03-10 19:51:37 UTC",
      "updated_date": "2025-03-12 18:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:06:05.731285"
    },
    {
      "arxiv_id": "2503.11695v1",
      "title": "MELON: Multimodal Mixture-of-Experts with Spectral-Temporal Fusion for Long-Term Mobility Estimation in Critical Care",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqing Zhang",
        "Miguel Contreras",
        "Jessica Sena",
        "Andrea Davidson",
        "Yuanfang Ren",
        "Ziyuan Guan",
        "Tezcan Ozrazgat-Baslanti",
        "Tyler J. Loftus",
        "Subhash Nerella",
        "Azra Bihorac",
        "Parisa Rashidi"
      ],
      "abstract": "Patient mobility monitoring in intensive care is critical for ensuring timely\ninterventions and improving clinical outcomes. While accelerometry-based sensor\ndata are widely adopted in training artificial intelligence models to estimate\npatient mobility, existing approaches face two key limitations highlighted in\nclinical practice: (1) modeling the long-term accelerometer data is challenging\ndue to the high dimensionality, variability, and noise, and (2) the absence of\nefficient and robust methods for long-term mobility assessment. To overcome\nthese challenges, we introduce MELON, a novel multimodal framework designed to\npredict 12-hour mobility status in the critical care setting. MELON leverages\nthe power of a dual-branch network architecture, combining the strengths of\nspectrogram-based visual representations and sequential accelerometer\nstatistical features. MELON effectively captures global and fine-grained\nmobility patterns by integrating a pre-trained image encoder for rich\nfrequency-domain feature extraction and a Mixture-of-Experts encoder for\nsequence modeling. We trained and evaluated the MELON model on the multimodal\ndataset of 126 patients recruited from nine Intensive Care Units at the\nUniversity of Florida Health Shands Hospital main campus in Gainesville,\nFlorida. Experiments showed that MELON outperforms conventional approaches for\n12-hour mobility status estimation with an overall area under the receiver\noperating characteristic curve (AUROC) of 0.82 (95\\%, confidence interval\n0.78-0.86). Notably, our experiments also revealed that accelerometer data\ncollected from the wrist provides robust predictive performance compared with\ndata from the ankle, suggesting a single-sensor solution that can reduce\npatient burden and lower deployment costs...",
      "tldr_zh": "本研究针对重症监护中患者移动性监测的挑战，提出了MELON框架，用于预测12小时的移动性状态，以克服长期加速度计数据的高维度、变异性和噪声问题。MELON采用双分支网络架构，结合spectrogram-based visual representations和Mixture-of-Experts编码器，分别提取频率域特征和序列特征，从而捕捉全局和细粒度移动模式。在佛罗里达大学健康Shands医院的126名患者数据上实验表明，MELON的AUROC达到0.82（95%置信区间0.78-0.86），优于传统方法；此外，手腕加速度计数据比踝部数据更具鲁棒性，建议采用单传感器方案以降低患者负担和部署成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.11695v1",
      "published_date": "2025-03-10 19:47:46 UTC",
      "updated_date": "2025-03-10 19:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:06:19.620055"
    },
    {
      "arxiv_id": "2503.07807v2",
      "title": "Training Domain Draft Models for Speculative Decoding: Best Practices and Insights",
      "title_zh": "训练领域草稿模型用于推测解码：最佳实践和见解",
      "authors": [
        "Fenglu Hong",
        "Ravi Raju",
        "Jonathan Lingjie Li",
        "Bo Li",
        "Urmish Thakker",
        "Avinash Ravichandran",
        "Swayambhoo Jain",
        "Changran Hu"
      ],
      "abstract": "Speculative decoding is an effective method for accelerating inference of\nlarge language models (LLMs) by employing a small draft model to predict the\noutput of a target model. However, when adapting speculative decoding to\ndomain-specific target models, the acceptance rate of the generic draft model\ndrops significantly due to domain shift. In this work, we systematically\ninvestigate knowledge distillation techniques for training domain draft models\nto improve their speculation accuracy. We compare white-box and black-box\ndistillation approaches and explore their effectiveness in various data\naccessibility scenarios, including historical user queries, curated domain\ndata, and synthetically generated alignment data. Our experiments across\nFunction Calling, Biology, and Chinese domains show that offline distillation\nconsistently outperforms online distillation by 11% to 25%, white-box\ndistillation surpasses black-box distillation by 2% to 10%, and data scaling\ntrends hold across domains. Additionally, we find that synthetic data can\neffectively align draft models and achieve 80% to 93% of the performance of\ntraining on historical user queries. These findings provide practical\nguidelines for training domain-specific draft models to improve speculative\ndecoding efficiency.",
      "tldr_zh": "本文研究了针对特定领域的草稿模型（draft model）训练，以提升推测性解码（speculative decoding）的效率，解决领域偏移（domain shift）导致的接受率下降问题。作者系统比较了白盒（white-box）和黑盒（black-box）知识蒸馏（knowledge distillation）技术，在历史用户查询、精选领域数据和合成对齐数据等场景下进行实验。结果显示，离线蒸馏（offline distillation）比在线蒸馏（online distillation）提高11%至25%，白盒蒸馏比黑盒蒸馏高2%至10%，且数据规模扩展在函数调用、生物学和中文领域均有效。此外，合成数据能使草稿模型达到使用历史用户查询训练的80%至93%性能，为优化领域特定draft model提供了实用指南。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a workshop paper at SCOPE - ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07807v2",
      "published_date": "2025-03-10 19:40:25 UTC",
      "updated_date": "2025-03-25 22:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:06:32.633039"
    },
    {
      "arxiv_id": "2503.07806v1",
      "title": "Towards Large Language Models that Benefit for All: Benchmarking Group Fairness in Reward Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kefan Song",
        "Jin Yao",
        "Runnan Jiang",
        "Rohan Chandra",
        "Shangtong Zhang"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly powerful and accessible\nto human users, ensuring fairness across diverse demographic groups, i.e.,\ngroup fairness, is a critical ethical concern. However, current fairness and\nbias research in LLMs is limited in two aspects. First, compared to traditional\ngroup fairness in machine learning classification, it requires that the\nnon-sensitive attributes, in this case, the prompt questions, be the same\nacross different groups. In many practical scenarios, different groups,\nhowever, may prefer different prompt questions and this requirement becomes\nimpractical. Second, it evaluates group fairness only for the LLM's final\noutput without identifying the source of possible bias. Namely, the bias in\nLLM's output can result from both the pretraining and the finetuning. For\nfinetuning, the bias can result from both the RLHF procedure and the learned\nreward model. Arguably, evaluating the group fairness of each component in the\nLLM pipeline could help develop better methods to mitigate the possible bias.\nRecognizing those two limitations, this work benchmarks the group fairness of\nlearned reward models. By using expert-written text from arXiv, we are able to\nbenchmark the group fairness of reward models without requiring the same prompt\nquestions across different demographic groups. Surprisingly, our results\ndemonstrate that all the evaluated reward models (e.g., Nemotron-4-340B-Reward,\nArmoRM-Llama3-8B-v0.1, and GRM-llama3-8B-sftreg) exhibit statistically\nsignificant group unfairness. We also observed that top-performing reward\nmodels (w.r.t. canonical performance metrics) tend to demonstrate better group\nfairness.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的群组公平性问题，提出基准测试奖励模型（reward models）的公平性，以解决现有研究中要求不同人口统计学群体使用相同提示问题的不切实际性，以及忽略偏见来源（如预训练、RLHF 和奖励模型）的局限。研究方法使用 arXiv 的专家撰写文本进行评估，允许不同群体使用不同的提示问题。结果显示，所有评估的奖励模型（如 Nemotron-4-340B-Reward 和 ArmoRM-Llama3-8B-v0.1）都存在统计显著的群组不公平性，但表现最佳的模型在标准指标上往往也表现出更好的公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07806v1",
      "published_date": "2025-03-10 19:39:39 UTC",
      "updated_date": "2025-03-10 19:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:06:42.031350"
    },
    {
      "arxiv_id": "2503.07799v1",
      "title": "Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Pramit Saha",
        "Divyanshu Mishra",
        "Netzahualcoyotl Hernandez-Cruz",
        "Olga Patey",
        "Aris Papageorghiou",
        "Yuki M. Asano",
        "J. Alison Noble"
      ],
      "abstract": "Congenital Heart Disease (CHD) is one of the leading causes of fetal\nmortality, yet the scarcity of labeled CHD data and strict privacy regulations\nsurrounding fetal ultrasound (US) imaging present significant challenges for\nthe development of deep learning-based models for CHD detection. Centralised\ncollection of large real-world datasets for rare conditions, such as CHD, from\nlarge populations requires significant co-ordination and resource. In addition,\ndata governance rules increasingly prevent data sharing between sites. To\naddress these challenges, we introduce, for the first time, a novel\nprivacy-preserving, zero-shot CHD detection framework that formulates CHD\ndetection as a normality modeling problem integrated with model merging. In our\nframework dubbed Sparse Tube Ultrasound Distillation (STUD), each hospital site\nfirst trains a sparse video tube-based self-supervised video anomaly detection\n(VAD) model on normal fetal heart US clips with self-distillation loss. This\nenables site-specific models to independently learn the distribution of healthy\ncases. To aggregate knowledge across the decentralized models while maintaining\nprivacy, we propose a Divergence Vector-Guided Model Merging approach,\nDivMerge, that combines site-specific models into a single VAD model without\ndata exchange. Our approach preserves domain-agnostic rich spatio-temporal\nrepresentations, ensuring generalization to unseen CHD cases. We evaluated our\napproach on real-world fetal US data collected from 5 hospital sites. Our\nmerged model outperformed site-specific models by 23.77% and 30.13% in accuracy\nand F1-score respectively on external test sets.",
      "tldr_zh": "本研究针对先天性心脏病 (CHD) 检测的标注数据稀缺和隐私法规挑战，提出了一种隐私保护的零样本检测框架 Sparse Tube Ultrasound Distillation (STUD)，将 CHD 检测转化为正常性建模问题。框架中，每个医院站点通过自监督正常性学习 (Self-supervised Normality Learning) 在正常胎儿心脏超声视频上训练稀疏视频管基于的自监督视频异常检测 (VAD) 模型，并使用 Divergence Vector-Guided Model Merging (DivMerge) 方法合并这些去中心化模型，而无需数据交换，以保留丰富的时空表示。实验在 5 个医院站点的真实数据上评估，结果显示合并模型在外部测试集上比站点特定模型提高了 23.77% 的准确率和 30.13% 的 F1 分数，展示了其在未见 CHD 病例上的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07799v1",
      "published_date": "2025-03-10 19:27:15 UTC",
      "updated_date": "2025-03-10 19:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:06:56.563943"
    },
    {
      "arxiv_id": "2503.07792v1",
      "title": "Efficient Neural Clause-Selection Reinforcement",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Suda"
      ],
      "abstract": "Clause selection is arguably the most important choice point in\nsaturation-based theorem proving. Framing it as a reinforcement learning (RL)\ntask is a way to challenge the human-designed heuristics of state-of-the-art\nprovers and to instead automatically evolve -- just from prover experiences --\ntheir potentially optimal replacement. In this work, we present a neural\nnetwork architecture for scoring clauses for clause selection that is powerful\nyet efficient to evaluate. Following RL principles to make design decisions, we\nintegrate the network into the Vampire theorem prover and train it from\nsuccessful proof attempts. An experiment on the diverse TPTP benchmark finds\nthe neurally guided prover improve over a baseline strategy, from which it\ninitially learns--in terms of the number of in-training-unseen problems solved\nunder a practically relevant, short CPU instruction limit--by 20%.",
      "tldr_zh": "这篇论文将饱和-based定理证明中的子句选择任务框架化为强化学习（RL）问题，提出一个高效的神经网络架构来评分子句，从而挑战并优化现有的人工设计启发式策略。作者将该架构集成到Vampire定理证明器中，并通过从成功证明尝试中训练模型，使其从基线策略中自动演化。实验结果显示，在TPTP基准上，该神经引导证明器在短CPU指令限制下解决的未见问题提高了20%。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages main text, 3 page bibliography, 6 page appendix",
      "pdf_url": "http://arxiv.org/pdf/2503.07792v1",
      "published_date": "2025-03-10 19:14:48 UTC",
      "updated_date": "2025-03-10 19:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:07:06.713243"
    },
    {
      "arxiv_id": "2503.10675v1",
      "title": "Beyond One-Size-Fits-All Summarization: Customizing Summaries for Diverse Users",
      "title_zh": "翻译失败",
      "authors": [
        "Mehmet Samet Duran",
        "Tevfik Aytekin"
      ],
      "abstract": "In recent years, automatic text summarization has witnessed significant\nadvancement, particularly with the development of transformer-based models.\nHowever, the challenge of controlling the readability level of generated\nsummaries remains an under-explored area, especially for languages with complex\nlinguistic features like Turkish. This gap has the effect of impeding effective\ncommunication and also limits the accessibility of information. Controlling\nreadability of textual data is an important element for creating summaries for\ndifferent audiences with varying literacy and education levels, such as\nstudents ranging from primary school to graduate level, as well as individuals\nwith diverse educational backgrounds. Summaries that align with the needs of\nspecific reader groups can improve comprehension and engagement, ensuring that\nthe intended message is effectively communicated. Furthermore, readability\nadjustment is essential to expand the usability of summarization models in\neducational and professional domains. Current summarization models often don't\nhave the mechanisms to adjust the complexity of their outputs, resulting in\nsummaries that may be too simplistic or overly complex for certain types of\nreader groups. Developing adaptive models that can tailor content to specific\nreadability levels is therefore crucial. To address this problem, we create our\nown custom dataset and train a model with our custom architecture. Our method\nensures that readability levels are effectively controlled while maintaining\naccuracy and coherence. We rigorously compare our model to a supervised\nfine-tuned baseline, demonstrating its superiority in generating\nreadability-aware summaries.",
      "tldr_zh": "本研究探讨了自动文本摘要的局限性，特别是 transformer-based models 在控制生成摘要的可读性水平方面的不足，尤其针对土耳其语等复杂语言。作者创建了自定义数据集并训练了特定架构的模型，以适应不同受众（如不同教育水平的学生）的需求，确保摘要在准确性和连贯性基础上调整复杂度。实验结果显示，该模型在生成可读性感知的摘要方面，比监督微调基准模型表现出显著优越性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2503.10675v1",
      "published_date": "2025-03-10 19:08:36 UTC",
      "updated_date": "2025-03-10 19:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:07:18.617413"
    },
    {
      "arxiv_id": "2503.07784v1",
      "title": "Joint Explainability-Performance Optimization With Surrogate Models for AI-Driven Edge Services",
      "title_zh": "翻译失败",
      "authors": [
        "Foivos Charalampakos",
        "Thomas Tsouparopoulos",
        "Iordanis Koutsopoulos"
      ],
      "abstract": "Explainable AI is a crucial component for edge services, as it ensures\nreliable decision making based on complex AI models. Surrogate models are a\nprominent approach of XAI where human-interpretable models, such as a linear\nregression model, are trained to approximate a complex (black-box) model's\npredictions. This paper delves into the balance between the predictive accuracy\nof complex AI models and their approximation by surrogate ones, advocating that\nboth these models benefit from being learned simultaneously. We derive a joint\n(bi-level) training scheme for both models and we introduce a new algorithm\nbased on multi-objective optimization (MOO) to simultaneously minimize both the\ncomplex model's prediction error and the error between its outputs and those of\nthe surrogate. Our approach leads to improvements that exceed 99% in the\napproximation of the black-box model through the surrogate one, as measured by\nthe metric of Fidelity, for a compromise of less than 3% absolute reduction in\nthe black-box model's predictive accuracy, compared to single-task and\nmulti-task learning baselines. By improving Fidelity, we can derive more\ntrustworthy explanations of the complex model's outcomes from the surrogate,\nenabling reliable AI applications for intelligent services at the network edge.",
      "tldr_zh": "该论文探讨了在AI驱动的边缘服务中，通过Surrogate models实现Explainable AI与性能的平衡，提出了一种联合（双层）训练方案。研究引入基于多目标优化（MOO）的新算法，同时最小化复杂AI模型的预测错误和其与Surrogate模型输出之间的差异。这种方法使Surrogate模型的Fidelity改善超过99%，而黑盒模型的预测准确率仅减少不到3%，优于单任务和多任务学习基线。通过提升解释性，该框架为边缘智能服务提供了更可靠和可信的决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07784v1",
      "published_date": "2025-03-10 19:04:09 UTC",
      "updated_date": "2025-03-10 19:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:07:31.293145"
    },
    {
      "arxiv_id": "2503.07783v1",
      "title": "Sensemaking in Novel Environments: How Human Cognition Can Inform Artificial Agents",
      "title_zh": "在新颖环境中进行意义构建：人类认知如何指导人工智能代理",
      "authors": [
        "Robert E. Patterson",
        "Regina Buccello-Stout",
        "Mary E. Frame",
        "Anna M. Maresca",
        "Justin Nelson",
        "Barbara Acker-Mills",
        "Erica Curtis",
        "Jared Culbertson",
        "Kevin Schmidt",
        "Scott Clouse",
        "Steve Rogers"
      ],
      "abstract": "One of the most vital cognitive skills to possess is the ability to make\nsense of objects, events, and situations in the world. In the current paper, we\noffer an approach for creating artificially intelligent agents with the\ncapacity for sensemaking in novel environments. Objectives: to present several\nkey ideas: (1) a novel unified conceptual framework for sensemaking (which\nincludes the existence of sign relations embedded within and across frames);\n(2) interaction among various content-addressable, distributed-knowledge\nstructures via shared attributes (whose net response would represent a\nsynthesized object, event, or situation serving as a sign for sensemaking in a\nnovel environment). Findings: we suggest that attributes across memories can be\nshared and recombined in novel ways to create synthesized signs, which can\ndenote certain outcomes in novel environments (i.e., sensemaking).",
      "tldr_zh": "本论文探讨如何借鉴人类认知，让人工智能代理在新型环境中进行 sensemaking。研究提出一个统一的sensemaking概念框架，包括sign relations嵌入框架内，以及通过共享属性在分布式知识结构之间互动，以合成新的对象、事件或情境。关键发现是，记忆中的属性可以跨结构共享和重组，形成合成符号，从而实现对未知环境的意义构建。",
      "categories": [
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07783v1",
      "published_date": "2025-03-10 19:03:09 UTC",
      "updated_date": "2025-03-10 19:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:07:42.234150"
    },
    {
      "arxiv_id": "2503.07770v1",
      "title": "Evaluating LLaMA 3.2 for Software Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "José Gonçalves",
        "Miguel Silva",
        "Bernardo Cabral",
        "Tiago Dias",
        "Eva Maia",
        "Isabel Praça",
        "Ricardo Severino",
        "Luís Lino Ferreira"
      ],
      "abstract": "Deep Learning (DL) has emerged as a powerful tool for vulnerability\ndetection, often outperforming traditional solutions. However, developing\neffective DL models requires large amounts of real-world data, which can be\ndifficult to obtain in sufficient quantities. To address this challenge,\nDiverseVul dataset has been curated as the largest dataset of vulnerable and\nnon-vulnerable C/C++ functions extracted exclusively from real-world projects.\nIts goal is to provide high-quality, large-scale samples for training DL\nmodels. However, during our study several inconsistencies were identified in\nthe raw dataset while applying pre-processing techniques, highlighting the need\nfor a refined version. In this work, we present a refined version of DiverseVul\ndataset, which is used to fine-tune a large language model, LLaMA 3.2, for\nvulnerability detection. Experimental results show that the use of\npre-processing techniques led to an improvement in performance, with the model\nachieving an F1-Score of 66%, a competitive result when compared to our\nbaseline, which achieved a 47% F1-Score in software vulnerability detection.",
      "tldr_zh": "本研究评估了LLaMA 3.2在软件漏洞检测中的性能，针对Deep Learning (DL)模型数据不足的问题，使用精炼的DiverseVul数据集，该数据集是最大的真实C/C++函数漏洞集合，并通过预处理技术修复其不一致性。研究者通过微调LLaMA 3.2模型，显著提升了检测准确性。实验结果显示，模型的F1-Score从基线的47%提高到66%，证明了这一方法的竞争优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 4 tables, EICC 2025: European Interdisciplinary\n  Cybersecurity Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07770v1",
      "published_date": "2025-03-10 18:47:41 UTC",
      "updated_date": "2025-03-10 18:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:07:54.856086"
    },
    {
      "arxiv_id": "2503.10674v1",
      "title": "Enhancing Retrieval for ESGLLM via ESG-CID -- A Disclosure Content Index Finetuning Dataset for Mapping GRI and ESRS",
      "title_zh": "翻译失败",
      "authors": [
        "Shafiuddin Rehan Ahmed",
        "Ankit Parag Shah",
        "Quan Hung Tran",
        "Vivek Khetan",
        "Sukryool Kang",
        "Ankit Mehta",
        "Yujia Bao",
        "Wei Wei"
      ],
      "abstract": "Climate change has intensified the need for transparency and accountability\nin organizational practices, making Environmental, Social, and Governance (ESG)\nreporting increasingly crucial. Frameworks like the Global Reporting Initiative\n(GRI) and the new European Sustainability Reporting Standards (ESRS) aim to\nstandardize ESG reporting, yet generating comprehensive reports remains\nchallenging due to the considerable length of ESG documents and variability in\ncompany reporting styles. To facilitate ESG report automation,\nRetrieval-Augmented Generation (RAG) systems can be employed, but their\ndevelopment is hindered by a lack of labeled data suitable for training\nretrieval models. In this paper, we leverage an underutilized source of weak\nsupervision -- the disclosure content index found in past ESG reports -- to\ncreate a comprehensive dataset, ESG-CID, for both GRI and ESRS standards. By\nextracting mappings between specific disclosure requirements and corresponding\nreport sections, and refining them using a Large Language Model as a judge, we\ngenerate a robust training and evaluation set. We benchmark popular embedding\nmodels on this dataset and show that fine-tuning BERT-based models can\noutperform commercial embeddings and leading public models, even under temporal\ndata splits for cross-report style transfer from GRI to ESRS",
      "tldr_zh": "本研究针对气候变化背景下ESG（Environmental, Social, and Governance）报告的透明性和标准化需求，提出利用披露内容索引创建ESG-CID数据集，以提升Retrieval-Augmented Generation (RAG)系统的检索性能。研究方法包括从过去ESG报告中提取GRI（Global Reporting Initiative）和ESRS（European Sustainability Reporting Standards）的披露要求与报告部分映射，并使用Large Language Model作为判断器进行精炼，从而生成用于训练和评估的鲁棒数据集。在基准测试中，微调BERT-based模型的表现优于商业嵌入和领先公共模型，即使在从GRI到ESRS的时间数据分割下，也实现了跨报告风格的转移。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Long paper",
      "pdf_url": "http://arxiv.org/pdf/2503.10674v1",
      "published_date": "2025-03-10 18:07:33 UTC",
      "updated_date": "2025-03-10 18:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:08:07.753318"
    },
    {
      "arxiv_id": "2503.07737v1",
      "title": "A Simple Approach to Constraint-Aware Imitation Learning with Application to Autonomous Racing",
      "title_zh": "翻译失败",
      "authors": [
        "Shengfan Cao",
        "Eunhyek Joa",
        "Francesco Borrelli"
      ],
      "abstract": "Guaranteeing constraint satisfaction is challenging in imitation learning\n(IL), particularly in tasks that require operating near a system's handling\nlimits. Traditional IL methods often struggle to enforce constraints, leading\nto suboptimal performance in high-precision tasks. In this paper, we present a\nsimple approach to incorporating safety into the IL objective. Through\nsimulations, we empirically validate our approach on an autonomous racing task\nwith both full-state and image feedback, demonstrating improved constraint\nsatisfaction and greater consistency in task performance compared to a baseline\nmethod.",
      "tldr_zh": "本文提出了一种简单的方法，将安全约束整合到模仿学习(IL)中，以解决传统IL在接近系统极限任务中难以保证约束满足的问题。方法通过修改IL目标来提升安全性，并在自主赛车任务的模拟环境中进行验证，使用全状态和图像反馈。实验结果表明，与基线方法相比，该方法显著提高了约束满足度和任务性能的一致性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07737v1",
      "published_date": "2025-03-10 18:00:16 UTC",
      "updated_date": "2025-03-10 18:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:08:17.912347"
    },
    {
      "arxiv_id": "2503.07600v1",
      "title": "A Representationalist, Functionalist and Naturalistic Conception of Intelligence as a Foundation for AGI",
      "title_zh": "翻译失败",
      "authors": [
        "Rolf Pfister"
      ],
      "abstract": "The article analyses foundational principles relevant to the creation of\nartificial general intelligence (AGI). Intelligence is understood as the\nability to create novel skills that allow to achieve goals under previously\nunknown conditions. To this end, intelligence utilises reasoning methods such\nas deduction, induction and abduction as well as other methods such as\nabstraction and classification to develop a world model. The methods are\napplied to indirect and incomplete representations of the world, which are\nobtained through perception, for example, and which do not depict the world but\nonly correspond to it. Due to these limitations and the uncertain and\ncontingent nature of reasoning, the world model is constructivist. Its value is\nfunctionally determined by its viability, i.e., its potential to achieve the\ndesired goals. In consequence, meaning is assigned to representations by\nattributing them a function that makes it possible to achieve a goal. This\nrepresentational and functional conception of intelligence enables a\nnaturalistic interpretation that does not presuppose mental features, such as\nintentionality and consciousness, which are regarded as independent of\nintelligence. Based on a phenomenological analysis, it is shown that AGI can\ngain a more fundamental access to the world than humans, although it is limited\nby the No Free Lunch theorems, which require assumptions to be made.",
      "tldr_zh": "该论文提出了一种代表性、功能主义和自然主义的智能概念，作为AGI（artificial general intelligence）的基础，将智能定义为在未知条件下创建新技能以实现目标的能力。智能通过deduction、induction、abduction等推理方法，以及abstraction和classification等技术，基于感知获得的间接和不完整表示构建一个constructivist的世界模型，其价值由viability（可行性）决定，即实现目标的潜力。论文强调，这种概念允许自然主义解释，不依赖于intentionality（意图性）和consciousness（意识），从而避免了心理特征的先决条件。通过现象学分析，论文显示AGI可能比人类获得更根本的世界访问，但受限于No Free Lunch theorems，需要做出假设。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07600v1",
      "published_date": "2025-03-10 17:58:00 UTC",
      "updated_date": "2025-03-10 17:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:08:33.414500"
    },
    {
      "arxiv_id": "2503.07599v1",
      "title": "NeuroChat: A Neuroadaptive AI Chatbot for Customizing Learning Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Dünya Baradari",
        "Nataliya Kosmyna",
        "Oscar Petrov",
        "Rebecah Kaplun",
        "Pattie Maes"
      ],
      "abstract": "Generative AI is transforming education by enabling personalized, on-demand\nlearning experiences. However, AI tutors lack the ability to assess a learner's\ncognitive state in real time, limiting their adaptability. Meanwhile,\nelectroencephalography (EEG)-based neuroadaptive systems have successfully\nenhanced engagement by dynamically adjusting learning content. This paper\npresents NeuroChat, a proof-of-concept neuroadaptive AI tutor that integrates\nreal-time EEG-based engagement tracking with generative AI. NeuroChat\ncontinuously monitors a learner's cognitive engagement and dynamically adjusts\ncontent complexity, response style, and pacing using a closed-loop system. We\nevaluate this approach in a pilot study (n=24), comparing NeuroChat to a\nstandard LLM-based chatbot. Results indicate that NeuroChat enhances cognitive\nand subjective engagement but does not show an immediate effect on learning\noutcomes. These findings demonstrate the feasibility of real-time cognitive\nfeedback in LLMs, highlighting new directions for adaptive learning, AI\ntutoring, and human-AI interaction.",
      "tldr_zh": "该论文提出NeuroChat，一种神经适应AI聊天机器人，通过整合实时EEG（脑电图）参与度追踪与生成式AI，动态自定义学习体验。NeuroChat采用闭环系统监控学习者的认知状态，并据此调整内容复杂度、响应风格和节奏。在一项试点研究（n=24）中，与标准LLM聊天机器人相比，NeuroChat显著提升了认知和主观参与度，但未立即影响学习成果。这些发现验证了实时认知反馈在LLM中的可行性，并为适应性学习、AI辅导和人-AI互动开辟新方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "I.2.7; J.0; K.3.1; K.8.0; C.3"
      ],
      "primary_category": "cs.HC",
      "comment": "16 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.07599v1",
      "published_date": "2025-03-10 17:57:20 UTC",
      "updated_date": "2025-03-10 17:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:08:44.089831"
    },
    {
      "arxiv_id": "2503.07596v1",
      "title": "Denoising Hamiltonian Network for Physical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Congyue Deng",
        "Brandon Y. Feng",
        "Cecilia Garraffo",
        "Alan Garbarz",
        "Robin Walters",
        "William T. Freeman",
        "Leonidas Guibas",
        "Kaiming He"
      ],
      "abstract": "Machine learning frameworks for physical problems must capture and enforce\nphysical constraints that preserve the structure of dynamical systems. Many\nexisting approaches achieve this by integrating physical operators into neural\nnetworks. While these methods offer theoretical guarantees, they face two key\nlimitations: (i) they primarily model local relations between adjacent time\nsteps, overlooking longer-range or higher-level physical interactions, and (ii)\nthey focus on forward simulation while neglecting broader physical reasoning\ntasks. We propose the Denoising Hamiltonian Network (DHN), a novel framework\nthat generalizes Hamiltonian mechanics operators into more flexible neural\noperators. DHN captures non-local temporal relationships and mitigates\nnumerical integration errors through a denoising mechanism. DHN also supports\nmulti-system modeling with a global conditioning mechanism. We demonstrate its\neffectiveness and flexibility across three diverse physical reasoning tasks\nwith distinct inputs and outputs.",
      "tldr_zh": "现有机器学习框架在处理物理问题时，通常只能捕捉相邻时间步的局部关系，并局限于前向模拟，忽略了更广泛的物理推理。论文提出 Denoising Hamiltonian Network (DHN)，一种创新框架，将 Hamiltonian mechanics 操作符泛化为更灵活的神经操作符，以捕捉非局部时间关系并通过去噪机制减轻数值积分错误。DHN 还支持多系统建模，并通过全球条件机制，在三个不同的物理推理任务上展示了其有效性和灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07596v1",
      "published_date": "2025-03-10 17:57:01 UTC",
      "updated_date": "2025-03-10 17:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:08:55.076457"
    },
    {
      "arxiv_id": "2503.07591v2",
      "title": "Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning",
      "title_zh": "先过滤图像，后生成指令：视觉指令微调的指令前数据选择",
      "authors": [
        "Bardia Safaei",
        "Faizan Siddiqui",
        "Jiacong Xu",
        "Vishal M. Patel",
        "Shao-Yuan Lo"
      ],
      "abstract": "Visual instruction tuning (VIT) for large vision-language models (LVLMs)\nrequires training on expansive datasets of image-instruction pairs, which can\nbe costly. Recent efforts in VIT data selection aim to select a small subset of\nhigh-quality image-instruction pairs, reducing VIT runtime while maintaining\nperformance comparable to full-scale training. However, a major challenge often\noverlooked is that generating instructions from unlabeled images for VIT is\nhighly expensive. Most existing VIT datasets rely heavily on human annotations\nor paid services like the GPT API, which limits users with constrained\nresources from creating VIT datasets for custom applications. To address this,\nwe introduce Pre-Instruction Data Selection (PreSel), a more practical data\nselection paradigm that directly selects the most beneficial unlabeled images\nand generates instructions only for the selected images. PreSel first estimates\nthe relative importance of each vision task within VIT datasets to derive\ntask-wise sampling budgets. It then clusters image features within each task,\nselecting the most representative images with the budget. This approach reduces\ncomputational overhead for both instruction generation during VIT data\nformation and LVLM fine-tuning. By generating instructions for only 15% of the\nimages, PreSel achieves performance comparable to full-data VIT on the\nLLaVA-1.5 and Vision-Flan datasets. The link to our project page:\nhttps://bardisafa.github.io/PreSel",
      "tldr_zh": "该论文针对视觉指令调整 (VIT) 的数据选择问题，提出 Pre-Instruction Data Selection (PreSel) 范式，先筛选无标签图像再生成指令，以降低生成指令的成本和整体训练开销。PreSel 通过估计各视觉任务的相对重要性、分配任务-wise 采样预算，并对图像特征进行聚类选择最有代表性的图像，从而优化数据处理过程。实验结果显示，只为 15% 的图像生成指令，即可在 LLaVA-1.5 和 Vision-Flan 数据集上实现与全数据 VIT 相当的性能，为资源有限的用户创建自定义 VIT 数据集提供了实用方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025 (Highlight)",
      "pdf_url": "http://arxiv.org/pdf/2503.07591v2",
      "published_date": "2025-03-10 17:55:11 UTC",
      "updated_date": "2025-04-05 15:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:09:08.049843"
    },
    {
      "arxiv_id": "2503.07588v2",
      "title": "When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Junwei Luo",
        "Yingying Zhang",
        "Xue Yang",
        "Kang Wu",
        "Qi Zhu",
        "Lei Liang",
        "Jingdong Chen",
        "Yansheng Li"
      ],
      "abstract": "Efficient vision-language understanding of large Remote Sensing Images (RSIs)\nis meaningful but challenging. Current Large Vision-Language Models (LVLMs)\ntypically employ limited pre-defined grids to process images, leading to\ninformation loss when handling gigapixel RSIs. Conversely, using unlimited\ngrids significantly increases computational costs. To preserve image details\nwhile reducing computational complexity, we propose a text-guided token pruning\nmethod with Dynamic Image Pyramid (DIP) integration. Our method introduces: (i)\na Region Focus Module (RFM) that leverages text-aware region localization\ncapability to identify critical vision tokens, and (ii) a coarse-to-fine image\ntile selection and vision token pruning strategy based on DIP, which is guided\nby RFM outputs and avoids directly processing the entire large imagery.\nAdditionally, existing benchmarks for evaluating LVLMs' perception ability on\nlarge RSI suffer from limited question diversity and constrained image sizes.\nWe construct a new benchmark named LRS-VQA, which contains 7,333 QA pairs\nacross 8 categories, with image length up to 27,328 pixels. Our method\noutperforms existing high-resolution strategies on four datasets using the same\ndata. Moreover, compared to existing token reduction methods, our approach\ndemonstrates higher efficiency under high-resolution settings. Dataset and code\nare in https://github.com/VisionXLab/LRS-VQA.",
      "tldr_zh": "本论文探讨了大型视觉语言模型（LVLMs）在处理巨像素遥感图像（RSIs）时的效率问题，提出了一种基于文本引导的粗到细 token 修剪方法，结合 Dynamic Image Pyramid (DIP) 来保留图像细节并降低计算复杂度。该方法包括 Region Focus Module (RFM)，用于识别关键视觉 tokens，并通过 RFM 输出指导图像切片选择和 token 修剪，避免直接处理整个图像。此外，论文构建了新基准 LRS-VQA，包含 7,333 个 QA 对，覆盖 8 个类别和高达 27,328 像素的图像大小。实验结果显示，该方法在四个数据集上优于现有高分辨率策略，并在高分辨率设置下比其他 token 减少方法更高效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.07588v2",
      "published_date": "2025-03-10 17:51:16 UTC",
      "updated_date": "2025-03-25 15:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:09:21.487803"
    },
    {
      "arxiv_id": "2503.07587v1",
      "title": "Robusto-1 Dataset: Comparing Humans and VLMs on real out-of-distribution Autonomous Driving VQA from Peru",
      "title_zh": "翻译失败",
      "authors": [
        "Dunant Cusipuma",
        "David Ortega",
        "Victor Flores-Benites",
        "Arturo Deza"
      ],
      "abstract": "As multimodal foundational models start being deployed experimentally in\nSelf-Driving cars, a reasonable question we ask ourselves is how similar to\nhumans do these systems respond in certain driving situations -- especially\nthose that are out-of-distribution? To study this, we create the Robusto-1\ndataset that uses dashcam video data from Peru, a country with one of the worst\n(aggressive) drivers in the world, a high traffic index, and a high ratio of\nbizarre to non-bizarre street objects likely never seen in training. In\nparticular, to preliminarly test at a cognitive level how well Foundational\nVisual Language Models (VLMs) compare to Humans in Driving, we move away from\nbounding boxes, segmentation maps, occupancy maps or trajectory estimation to\nmulti-modal Visual Question Answering (VQA) comparing both humans and machines\nthrough a popular method in systems neuroscience known as Representational\nSimilarity Analysis (RSA). Depending on the type of questions we ask and the\nanswers these systems give, we will show in what cases do VLMs and Humans\nconverge or diverge allowing us to probe on their cognitive alignment. We find\nthat the degree of alignment varies significantly depending on the type of\nquestions asked to each type of system (Humans vs VLMs), highlighting a gap in\ntheir alignment.",
      "tldr_zh": "本研究引入Robusto-1数据集，利用来自秘鲁的行车记录仪视频数据，比较视觉语言模型（VLMs）和人类在out-of-distribution自动驾驶场景下的表现。数据集聚焦于秘鲁独特的高攻击性驾驶环境和高比例奇特街头物体，通过Visual Question Answering (VQA)任务评估两者的认知响应。采用Representational Similarity Analysis (RSA)方法分析人类和VLMs的答案相似度，结果显示对齐程度因问题类型而异，突显了VLMs在认知层面与人类的显著差距。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "A pre-print. 26 pages. Link to Code + Data:\n  https://huggingface.co/datasets/Artificio/robusto-1",
      "pdf_url": "http://arxiv.org/pdf/2503.07587v1",
      "published_date": "2025-03-10 17:50:04 UTC",
      "updated_date": "2025-03-10 17:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:09:31.547086"
    },
    {
      "arxiv_id": "2503.07578v2",
      "title": "Denoising Score Distillation: From Noisy Diffusion Pretraining to One-Step High-Quality Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Chen",
        "Yasi Zhang",
        "Zhendong Wang",
        "Ying Nian Wu",
        "Oscar Leong",
        "Mingyuan Zhou"
      ],
      "abstract": "Diffusion models have achieved remarkable success in generating\nhigh-resolution, realistic images across diverse natural distributions.\nHowever, their performance heavily relies on high-quality training data, making\nit challenging to learn meaningful distributions from corrupted samples. This\nlimitation restricts their applicability in scientific domains where clean data\nis scarce or costly to obtain. In this work, we introduce denoising score\ndistillation (DSD), a surprisingly effective and novel approach for training\nhigh-quality generative models from low-quality data. DSD first pretrains a\ndiffusion model exclusively on noisy, corrupted samples and then distills it\ninto a one-step generator capable of producing refined, clean outputs. While\nscore distillation is traditionally viewed as a method to accelerate diffusion\nmodels, we show that it can also significantly enhance sample quality,\nparticularly when starting from a degraded teacher model. Across varying noise\nlevels and datasets, DSD consistently improves generative performancewe\nsummarize our empirical evidence in Fig. 1. Furthermore, we provide theoretical\ninsights showing that, in a linear model setting, DSD identifies the eigenspace\nof the clean data distributions covariance matrix, implicitly regularizing the\ngenerator. This perspective reframes score distillation as not only a tool for\nefficiency but also a mechanism for improving generative models, particularly\nin low-quality data settings.",
      "tldr_zh": "本研究针对扩散模型（Diffusion models）在生成高分辨率图像时依赖高质量数据的局限性，提出了一种名为去噪分数蒸馏（Denoising Score Distillation, DSD）的创新方法，以从噪声或损坏的数据中训练高质量生成模型。DSD 先在噪声样本上预训练扩散模型，然后通过分数蒸馏（score distillation）将其转化为一个一步生成器，从而产生精炼的干净输出。实验结果显示，DSD 在不同噪声水平和数据集上显著提升了生成性能，比传统方法更有效。理论分析进一步证明，DSD 能在线性模型设置中识别干净数据分布的协方差矩阵特征空间，实现隐式正则化，并将分数蒸馏重新定位为提升模型质量的关键机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "First Author and Second Author contributed equally to this work. The\n  last two authors equally advised this work",
      "pdf_url": "http://arxiv.org/pdf/2503.07578v2",
      "published_date": "2025-03-10 17:44:46 UTC",
      "updated_date": "2025-05-21 17:09:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:09:45.239135"
    },
    {
      "arxiv_id": "2503.07701v1",
      "title": "Automated Benchmark Generation for Repository-Level Coding Tasks",
      "title_zh": "针对仓库级编码任务的自动化基准测试生成",
      "authors": [
        "Konstantinos Vergopoulos",
        "Mark Niklas Müller",
        "Martin Vechev"
      ],
      "abstract": "Code Agent development is an extremely active research area, where a reliable\nperformance metric is critical for tracking progress and guiding new\ndevelopments. This demand is underscored by the meteoric rise in popularity of\nSWE-Bench. This benchmark challenges code agents to generate patches addressing\nGitHub issues given the full repository as context. The correctness of\ngenerated patches is then evaluated by executing a human-written test suite\nextracted from the repository after the issue's resolution. However,\nconstructing benchmarks like SWE-Bench requires substantial manual effort to\nset up historically accurate execution environments for testing. Crucially,\nthis severely limits the number of considered repositories, e.g., just 12 for\nSWE-Bench. Considering so few repositories, selected for their popularity runs\nthe risk of leading to a distributional mismatch, i.e., the measured\nperformance may not be representative of real-world scenarios potentially\nmisguiding development efforts. In this work, we address this challenge and\nintroduce SetUpAgent, a fully automated system capable of historically accurate\ndependency setup, test execution, and result parsing. Using SetUpAgent, we\ngenerate two new datasets: (i) SWEE-Bench an extended version of SWE-Bench\nencompassing hundreds of repositories, and (ii) SWA-Bench a benchmark focusing\non applications rather than libraries. Comparing these datasets to SWE-Bench\nwith respect to their characteristics and code agent performance, we find\nsignificant distributional differences, including lower issue description\nquality and detail level, higher fix complexity, and most importantly up to 40%\nlower agent success rates.",
      "tldr_zh": "本研究针对代码代理（Code Agent）开发的性能评估问题，提出了一种自动化基准生成方法，以解决现有基准如 SWE-Bench 因手动设置环境而仅覆盖少量仓库（如12个），导致性能评估可能不具代表性的挑战。作者引入 SetUpAgent，一个全自动系统，能够实现历史准确的依赖设置、测试执行和结果解析，从而生成两个新数据集：SWEE-Bench（扩展版，覆盖数百个仓库）和 SWA-Bench（专注于应用程序）。实验比较显示，新数据集存在显著分布差异，包括更低的 issue 描述质量、更高的修复复杂性，以及代码代理成功率降低高达40%，强调了更广泛仓库覆盖的重要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at DL4C@ICLR'25 and FMWild@ICLR'25",
      "pdf_url": "http://arxiv.org/pdf/2503.07701v1",
      "published_date": "2025-03-10 17:42:49 UTC",
      "updated_date": "2025-03-10 17:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:09:56.671081"
    },
    {
      "arxiv_id": "2503.07572v1",
      "title": "Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning",
      "title_zh": "通过元强化学习微调优化测试时计算",
      "authors": [
        "Yuxiao Qu",
        "Matthew Y. R. Yang",
        "Amrith Setlur",
        "Lewis Tunstall",
        "Edward Emanuel Beeching",
        "Ruslan Salakhutdinov",
        "Aviral Kumar"
      ],
      "abstract": "Training models to effectively use test-time compute is crucial for improving\nthe reasoning performance of LLMs. Current methods mostly do so via fine-tuning\non search traces or running RL with 0/1 outcome reward, but do these approaches\nefficiently utilize test-time compute? Would these approaches continue to scale\nas the budget improves? In this paper, we try to answer these questions. We\nformalize the problem of optimizing test-time compute as a meta-reinforcement\nlearning (RL) problem, which provides a principled perspective on spending\ntest-time compute. This perspective enables us to view the long output stream\nfrom the LLM as consisting of several episodes run at test time and leads us to\nuse a notion of cumulative regret over output tokens as a way to measure the\nefficacy of test-time compute. Akin to how RL algorithms can best tradeoff\nexploration and exploitation over training, minimizing cumulative regret would\nalso provide the best balance between exploration and exploitation in the token\nstream. While we show that state-of-the-art models do not minimize regret, one\ncan do so by maximizing a dense reward bonus in conjunction with the outcome\n0/1 reward RL. This bonus is the ''progress'' made by each subsequent block in\nthe output stream, quantified by the change in the likelihood of eventual\nsuccess. Using these insights, we develop Meta Reinforcement Fine-Tuning, or\nMRT, a new class of fine-tuning methods for optimizing test-time compute. MRT\nleads to a 2-3x relative gain in performance and roughly a 1.5x gain in token\nefficiency for math reasoning compared to outcome-reward RL.",
      "tldr_zh": "这篇论文探讨了如何通过元强化学习（meta-reinforcement learning）优化大型语言模型（LLMs）的测试时计算，以提升其推理性能。作者将问题形式化为一个 meta-RL 框架，使用累积遗憾（cumulative regret）作为度量标准，并引入密集奖励奖励来平衡输出流中的探索和利用。最终，他们开发了 Meta Reinforcement Fine-Tuning (MRT) 方法，在数学推理任务上比传统基于结果奖励的 RL 提升了 2-3 倍性能，并提高了约 1.5 倍的令牌效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07572v1",
      "published_date": "2025-03-10 17:40:43 UTC",
      "updated_date": "2025-03-10 17:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:10:09.737796"
    },
    {
      "arxiv_id": "2503.07568v1",
      "title": "Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters",
      "title_zh": "翻译失败",
      "authors": [
        "Habibur Rahaman",
        "Atri Chatterjee",
        "Swarup Bhunia"
      ],
      "abstract": "Rapid adoption of AI technologies raises several major security concerns,\nincluding the risks of adversarial perturbations, which threaten the\nconfidentiality and integrity of AI applications. Protecting AI hardware from\nmisuse and diverse security threats is a challenging task. To address this\nchallenge, we propose SAMURAI, a novel framework for safeguarding against\nmalicious usage of AI hardware and its resilience to attacks. SAMURAI\nintroduces an AI Performance Counter (APC) for tracking dynamic behavior of an\nAI model coupled with an on-chip Machine Learning (ML) analysis engine, known\nas TANTO (Trained Anomaly Inspection Through Trace Observation). APC records\nthe runtime profile of the low-level hardware events of different AI\noperations. Subsequently, the summary information recorded by the APC is\nprocessed by TANTO to efficiently identify potential security breaches and\nensure secure, responsible use of AI. SAMURAI enables real-time detection of\nsecurity threats and misuse without relying on traditional software-based\nsolutions that require model integration. Experimental results demonstrate that\nSAMURAI achieves up to 97% accuracy in detecting adversarial attacks with\nmoderate overhead on various AI models, significantly outperforming\nconventional software-based approaches. It enhances security and regulatory\ncompliance, providing a comprehensive solution for safeguarding AI against\nemergent threats.",
      "tldr_zh": "该论文提出了一种名为 SAMURAI 的框架，用于实时检测 AI 加速器中的对抗性攻击，利用性能计数器（Performance Counters）提升 AI 硬件的安全性。SAMURAI 包括 AI Performance Counter (APC)，用于记录 AI 模型的运行时硬件事件，以及芯片上的 ML 分析引擎 TANTO (Trained Anomaly Inspection Through Trace Observation)，通过处理这些事件来识别潜在的安全威胁。实验结果显示，SAMURAI 在各种 AI 模型上实现高达 97% 的攻击检测准确率，同时保持适度开销，并显著优于传统软件方法，从而增强 AI 的安全性和合规性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07568v1",
      "published_date": "2025-03-10 17:38:42 UTC",
      "updated_date": "2025-03-10 17:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:10:20.240433"
    },
    {
      "arxiv_id": "2503.07565v7",
      "title": "Inductive Moment Matching",
      "title_zh": "归纳矩匹配",
      "authors": [
        "Linqi Zhou",
        "Stefano Ermon",
        "Jiaming Song"
      ],
      "abstract": "Diffusion models and Flow Matching generate high-quality samples but are slow\nat inference, and distilling them into few-step models often leads to\ninstability and extensive tuning. To resolve these trade-offs, we propose\nInductive Moment Matching (IMM), a new class of generative models for one- or\nfew-step sampling with a single-stage training procedure. Unlike distillation,\nIMM does not require pre-training initialization and optimization of two\nnetworks; and unlike Consistency Models, IMM guarantees distribution-level\nconvergence and remains stable under various hyperparameters and standard model\narchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID\nusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98\non CIFAR-10 for a model trained from scratch.",
      "tldr_zh": "本研究提出 Inductive Moment Matching (IMM)，一种新型生成模型，旨在解决 Diffusion models 和 Flow Matching 在推理速度慢以及蒸馏过程不稳定和调优复杂的问题。IMM 通过单阶段训练实现一或少步采样，不需预训练初始化或优化多个网络，并保证分布级别的收敛，在各种超参数和标准架构下保持稳定。与传统模型相比，IMM 在 ImageNet-256x256 上仅用 8 步推理就达到 1.99 FID 的优异性能，并在 CIFAR-10 上实现从零训练的 2 步推理状态-of-the-art FID 1.98。总的来说，该方法为高效生成模型提供了稳定且高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07565v7",
      "published_date": "2025-03-10 17:37:39 UTC",
      "updated_date": "2025-05-14 19:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:10:33.171305"
    },
    {
      "arxiv_id": "2503.07700v1",
      "title": "A Task and Motion Planning Framework Using Iteratively Deepened AND/OR Graph Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Karami",
        "Antony Thomas",
        "Fulvio Mastrogiovanni"
      ],
      "abstract": "In this paper, we present an approach for integrated task and motion planning\nbased on an AND/OR graph network, which is used to represent task-level states\nand actions, and we leverage it to implement different classes of task and\nmotion planning problems (TAMP). Several problems that fall under task and\nmotion planning do not have a predetermined number of sub-tasks to achieve a\ngoal. For example, while retrieving a target object from a cluttered workspace,\nin principle the number of object re-arrangements required to finally grasp it\ncannot be known ahead of time. To address this challenge, and in contrast to\ntraditional planners, also those based on AND/OR graphs, we grow the AND/OR\ngraph at run-time by progressively adding sub-graphs until grasping the target\nobject becomes feasible, which yields a network of AND/OR graphs. The approach\nis extended to enable multi-robot task and motion planning, and (i) it allows\nus to perform task allocation while coordinating the activity of a given number\nof robots, and (ii) can handle multi-robot tasks involving an a priori unknown\nnumber of sub-tasks. The approach is evaluated and validated both in simulation\nand with a real dual-arm robot manipulator, that is, Baxter from Rethink\nRobotics. In particular, for the single-robot task and motion planning, we\nvalidated our approach in three different TAMP domains. Furthermore, we also\nuse three different robots for simulation, namely, Baxter, Franka Emika Panda\nmanipulators, and a PR2 robot. Experiments show that our approach can be\nreadily scaled to scenarios with many objects and robots, and is capable of\nhandling different classes of TAMP problems.",
      "tldr_zh": "本研究提出了一种基于迭代加深 AND/OR 图网络的集成任务和运动规划（TAMP）框架，用于表示任务级状态和动作。该框架在运行时动态扩展 AND/OR 图，以处理子任务数量未知的问题，例如在杂乱环境中抓取目标物体时逐步添加子图。框架进一步扩展到多机器人场景，支持任务分配和协调多机器人活动。实验在模拟和真实机器人（如 Baxter 双臂机械臂）上验证，证明了其在多种 TAMP 领域中的可扩展性和有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07700v1",
      "published_date": "2025-03-10 17:28:22 UTC",
      "updated_date": "2025-03-10 17:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:10:43.621076"
    },
    {
      "arxiv_id": "2503.07556v1",
      "title": "Junior Software Developers' Perspectives on Adopting LLMs for Software Engineering: a Systematic Literature Review",
      "title_zh": "初级软件开发人员的观点：采用 LLMs 用于软件工程的系统文献综述",
      "authors": [
        "Samuel Ferino",
        "Rashina Hoda",
        "John Grundy",
        "Christoph Treude"
      ],
      "abstract": "Many studies exploring the adoption of Large Language Model-based tools for\nsoftware development by junior developers have emerged in recent years. These\nstudies have sought to understand developers' perspectives about using those\ntools, a fundamental pillar for successfully adopting LLM-based tools in\nSoftware Engineering. The aim of this paper is to provide an overview of junior\nsoftware developers' perspectives and use of LLM-based tools for software\nengineering (LLM4SE). We conducted a systematic literature review (SLR)\nfollowing guidelines by Kitchenham et al. on 56 primary studies, applying the\ndefinition for junior software developers as software developers with equal or\nless than five years of experience, including Computer Science/Software\nEngineering students. We found that the majority of the studies focused on\ncomprehending the different aspects of integrating AI tools in SE. Only 8.9\\%\nof the studies provide a clear definition for junior software developers, and\nthere is no uniformity. Searching for relevant information is the most common\ntask using LLM tools. ChatGPT was the most common LLM tool present in the\nstudies (and experiments). A majority of the studies (83.9\\%) report both\npositive and negative perceptions about the impact of adopting LLM tools. We\nalso found and categorised advantages, challenges, and recommendations\nregarding LLM adoption. Our results indicate that developers are using LLMs not\njust for code generation, but also to improve their development skills.\nCritically, they are not just experiencing the benefits of adopting LLM tools,\nbut they are also aware of at least a few LLM limitations, such as the\ngeneration of wrong suggestions, potential data leaking, and AI hallucination.\nOur findings offer implications for software engineering researchers,\neducators, and developers.",
      "tldr_zh": "这篇论文通过系统文献综述（SLR）方法，分析了56个研究，探讨初级软件开发人员（junior software developers，指经验在五年或以下的开发人员，包括计算机科学/软件工程学生）对采用大型语言模型（LLMs）工具用于软件工程（LLM4SE）的看法。研究发现，大多数研究关注AI工具在软件工程中的整合，ChatGPT是最常用的LLM工具，而开发人员主要使用这些工具搜索信息，并报告了正面（如技能提升）和负面（如AI hallucination、错误建议和数据泄露）影响。最终，该论文总结了LLMs采用的优势、挑战和推荐，并为软件工程研究者、教育者和开发人员提供了重要启示。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07556v1",
      "published_date": "2025-03-10 17:25:24 UTC",
      "updated_date": "2025-03-10 17:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:10:56.382667"
    },
    {
      "arxiv_id": "2503.13492v1",
      "title": "Event-Driven Implementation of a Physical Reservoir Computing Framework for superficial EMG-based Gesture Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Ding",
        "Elisa Donati",
        "Haobo Li",
        "Hadi Heidari"
      ],
      "abstract": "Wearable health devices have a strong demand in real-time biomedical signal\nprocessing. However traditional methods often require data transmission to\ncentralized processing unit with substantial computational resources after\ncollecting it from edge devices. Neuromorphic computing is an emerging field\nthat seeks to design specialized hardware for computing systems inspired by the\nstructure, function, and dynamics of the human brain, offering significant\nadvantages in latency and power consumption. This paper explores a novel\nneuromorphic implementation approach for gesture recognition by extracting\nspatiotemporal spiking information from surface electromyography (sEMG) data in\nan event-driven manner. At the same time, the network was designed by\nimplementing a simple-structured and hardware-friendly Physical Reservoir\nComputing (PRC) framework called Rotating Neuron Reservoir (RNR) within the\ndomain of Spiking neural network (SNN). The spiking RNR (sRNR) is promising to\npipeline an innovative solution to compact embedded wearable systems, enabling\nlow-latency, real-time processing directly at the sensor level. The proposed\nsystem was validated by an open-access large-scale sEMG database and achieved\nan average classification accuracy of 74.6\\% and 80.3\\% using a classical\nmachine learning classifier and a delta learning rule algorithm respectively.\nWhile the delta learning rule could be fully spiking and implementable on\nneuromorphic chips, the proposed gesture recognition system demonstrates the\npotential for near-sensor low-latency processing.",
      "tldr_zh": "本研究探讨了基于表面肌电图(sEMG)的手势识别问题，提出一种事件驱动的神经形态计算方法，以解决传统方法的数据传输延迟和高功耗问题。该方法利用简单结构且硬件友好的 Physical Reservoir Computing (PRC) 框架——Rotating Neuron Reservoir (RNR)，在 Spiking Neural Network (SNN) 领域提取sEMG数据的时空尖峰信息，实现低延迟的实时处理。实验在公开的大型sEMG数据库上验证，使用经典机器学习分类器和delta learning rule算法分别获得74.6%和80.3%的平均分类准确率，展示了该系统在紧凑嵌入式可穿戴设备中的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "eess.SP",
      "comment": "11 pages, 9 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2503.13492v1",
      "published_date": "2025-03-10 17:18:14 UTC",
      "updated_date": "2025-03-10 17:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:11:09.857425"
    },
    {
      "arxiv_id": "2503.07550v1",
      "title": "KSOD: Knowledge Supplement for LLMs On Demand",
      "title_zh": "KSOD: 针对大型语言模型的按需知识",
      "authors": [
        "Haoran Li",
        "Junfeng Hu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks, yet still produce errors in domain-specific tasks. To further\nimprove their performance, we propose KSOD (Knowledge Supplement for LLMs On\nDemand), a novel framework that empowers LLMs to improve their capabilities\nwith knowledge-based supervised fine-tuning (SFT). KSOD analyzes the causes of\nerrors from the perspective of knowledge deficiency by identifying potential\nmissing knowledge in LLM that may lead to the errors. Subsequently, KSOD tunes\na knowledge module on knowledge dataset and verifies whether the LLM lacks the\nidentified knowledge based on it. If the knowledge is verified, KSOD\nsupplements the LLM with the identified knowledge using the knowledge module.\nTuning LLMs on specific knowledge instead of specific task decouples task and\nknowledge and our experiments on two domain-specific benchmarks and four\ngeneral benchmarks empirically demonstrate that KSOD enhances the performance\nof LLMs on tasks requiring the supplemented knowledge while preserving their\nperformance on other tasks. Our findings shed light on the potential of\nimproving the capabilities of LLMs with knowledge-based SFT.",
      "tldr_zh": "本研究提出KSOD框架，用于通过知识-based supervised fine-tuning (SFT)提升大型语言模型(LLMs)在特定领域任务中的性能，以解决LLMs因知识缺失导致的错误问题。KSOD通过分析错误原因、识别潜在缺失知识、训练知识模块并验证后，将所需知识补充到LLMs中，从而实现任务与知识的解耦。实验在两个领域特定基准和四个通用基准上显示，KSOD显著提高了LLMs在补充知识相关任务上的表现，同时保持了其他任务的性能，这证明了知识-based SFT在增强LLMs能力方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07550v1",
      "published_date": "2025-03-10 17:17:41 UTC",
      "updated_date": "2025-03-10 17:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:11:21.185993"
    },
    {
      "arxiv_id": "2503.07545v1",
      "title": "Queueing, Predictions, and LLMs: Challenges and Open Problems",
      "title_zh": "队列、预测和 LLMs：挑战与开放问题",
      "authors": [
        "Michael Mitzenmacher",
        "Rana Shahout"
      ],
      "abstract": "Queueing systems present many opportunities for applying machine-learning\npredictions, such as estimated service times, to improve system performance.\nThis integration raises numerous open questions about how predictions can be\neffectively leveraged to improve scheduling decisions. Recent studies explore\nqueues with predicted service times, typically aiming to minimize job time in\nthe system. We review these works, highlight the effectiveness of predictions,\nand present open questions on queue performance. We then move to consider an\nimportant practical example of using predictions in scheduling, namely Large\nLanguage Model (LLM) systems, which presents novel scheduling challenges and\nhighlights the potential for predictions to improve performance. In particular,\nwe consider LLMs performing inference. Inference requests (jobs) in LLM systems\nare inherently complex; they have variable inference times, dynamic memory\nfootprints that are constrained by key-value (KV) store memory limitations, and\nmultiple possible preemption approaches that affect performance differently. We\nprovide background on the important aspects of scheduling in LLM systems, and\nintroduce new models and open problems that arise from them. We argue that\nthere are significant opportunities for applying insights and analysis from\nqueueing theory to scheduling in LLM systems.",
      "tldr_zh": "该论文探讨了队列系统（Queueing systems）如何利用机器学习预测（如估计服务时间）来优化调度决策，并回顾了现有研究，强调预测的有效性，同时提出了队列性能方面的开放问题。作者特别关注大型语言模型（LLMs）系统中的调度挑战，例如推理请求（jobs）的可变时间、动态内存占用（受 KV store 限制）和多种抢占方法。论文引入了新的模型和问题，展示了预测如何改善 LLMs 性能，并主张将队列理论（Queueing theory）的洞见应用于 LLMs 调度，以应对这些复杂性。总的来说，这为未来研究提供了重要机会，提升系统效率和可靠性。",
      "categories": [
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07545v1",
      "published_date": "2025-03-10 17:12:47 UTC",
      "updated_date": "2025-03-10 17:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:11:33.582992"
    },
    {
      "arxiv_id": "2503.07541v1",
      "title": "Geometric Retargeting: A Principled, Ultrafast Neural Hand Retargeting Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao-Heng Yin",
        "Changhao Wang",
        "Luis Pineda",
        "Krishna Bodduluri",
        "Tingfan Wu",
        "Pieter Abbeel",
        "Mustafa Mukadam"
      ],
      "abstract": "We introduce Geometric Retargeting (GeoRT), an ultrafast, and principled\nneural hand retargeting algorithm for teleoperation, developed as part of our\nrecent Dexterity Gen (DexGen) system. GeoRT converts human finger keypoints to\nrobot hand keypoints at 1KHz, achieving state-of-the-art speed and accuracy\nwith significantly fewer hyperparameters. This high-speed capability enables\nflexible postprocessing, such as leveraging a foundational controller for\naction correction like DexGen. GeoRT is trained in an unsupervised manner,\neliminating the need for manual annotation of hand pairs. The core of GeoRT\nlies in novel geometric objective functions that capture the essence of\nretargeting: preserving motion fidelity, ensuring configuration space (C-space)\ncoverage, maintaining uniform response through high flatness, pinch\ncorrespondence and preventing self-collisions. This approach is free from\nintensive test-time optimization, offering a more scalable and practical\nsolution for real-time hand retargeting.",
      "tldr_zh": "本研究引入了Geometric Retargeting (GeoRT)，一种基于原则的超快速神经手部重定向算法，用于遥操作系统，如DexGen。它将人类手指关键点以1KHz的速度转换为机器人手关键点，通过无监督训练和新型几何目标函数确保运动保真度、配置空间 (C-space) 覆盖、高平坦度、捏合对应以及防止自碰撞，从而避免了手动标注和测试时密集优化。GeoRT显著减少了超参数数量，并实现了比现有基线更高的速度和准确性，支持灵活的后处理，如动作修正，使其成为实时手部重定向的更可扩展解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Website: https://zhaohengyin.github.io/geort",
      "pdf_url": "http://arxiv.org/pdf/2503.07541v1",
      "published_date": "2025-03-10 17:10:21 UTC",
      "updated_date": "2025-03-10 17:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:11:44.314419"
    },
    {
      "arxiv_id": "2503.07540v1",
      "title": "AI-Enabled Knowledge Sharing for Enhanced Collaboration and Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review Protocol",
      "title_zh": "翻译失败",
      "authors": [
        "Maurice Ongala",
        "Ruth Kiraka",
        "Jyoti Choundrie",
        "Javan Okello"
      ],
      "abstract": "This protocol outlines a scoping review designed to systematically map the\nexisting body of evidence on AI-enabled knowledge sharing in resource-limited\nnon-profit healthcare organizations. The review aims to investigate how such\ntechnologies enhance collaboration and decision-making, particularly in the\ncontext of reduced external support following the cessation of USAID\noperations. Guided by three theoretical frameworks namely, the Resource-Based\nView, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study\nwill explore the dual role of AI as a strategic resource and an enabler of\norganizational learning and agility. The protocol details a rigorous\nmethodological approach based on PRISMA-ScR guidelines, encompassing a\nsystematic search strategy across multiple databases, inclusion and exclusion\ncriteria, and a structured data extraction process. By integrating theoretical\ninsights with empirical evidence, this scoping review seeks to identify\ncritical gaps in the literature and inform the design of effective,\nresource-optimized AI solutions in non-profit healthcare settings.",
      "tldr_zh": "本协议提出一个范围审查（scoping review），旨在系统映射 AI-enabled knowledge sharing 在资源有限的非营利性医疗组织中的现有证据，特别是如何提升协作和决策，尤其在 USAID 操作停止后的背景下。研究基于三个理论框架——Resource-Based View、Dynamic Capabilities Theory 和 Absorptive Capacity Theory——来探讨 AI 作为战略资源和组织学习促进者的双重作用。采用 PRISMA-ScR 指南的严格方法，包括多数据库系统搜索、纳入/排除标准以及结构化数据提取过程，最终目标是识别文献中的关键空白，并为设计资源优化的 AI 解决方案提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07540v1",
      "published_date": "2025-03-10 17:09:12 UTC",
      "updated_date": "2025-03-10 17:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:11:56.115286"
    },
    {
      "arxiv_id": "2503.07536v2",
      "title": "LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL",
      "title_zh": "翻译失败",
      "authors": [
        "Yingzhe Peng",
        "Gongrui Zhang",
        "Miaosen Zhang",
        "Zhiyuan You",
        "Jie Liu",
        "Qipeng Zhu",
        "Kai Yang",
        "Xingzhong Xu",
        "Xin Geng",
        "Xu Yang"
      ],
      "abstract": "Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges\nfrom the complex interplay between visual perception and logical reasoning,\nparticularly in compact 3B-parameter architectures where architectural\nconstraints limit reasoning capacity and modality alignment.\n  While rule-based reinforcement learning (RL) excels in text-only domains, its\nmultimodal extension confronts two critical barriers: (1) data limitations due\nto ambiguous answers and scarce complex reasoning examples, and (2) degraded\nfoundational reasoning induced by multimodal pretraining. To address these\nchallenges, we propose \\textbf{LMM-R1}, a two-stage framework adapting\nrule-based RL for multimodal reasoning through \\textbf{Foundational Reasoning\nEnhancement (FRE)} followed by \\textbf{Multimodal Generalization Training\n(MGT)}. The FRE stage first strengthens reasoning abilities using text-only\ndata with rule-based RL, then the MGT stage generalizes these reasoning\ncapabilities to multimodal domains.\n  Experiments on Qwen2.5-VL-Instruct-3B demonstrate that LMM-R1 achieves 4.83\\%\nand 4.5\\% average improvements over baselines in multimodal and text-only\nbenchmarks, respectively, with a 3.63\\% gain in complex Football Game tasks.\nThese results validate that text-based reasoning enhancement enables effective\nmultimodal generalization, offering a data-efficient paradigm that bypasses\ncostly high-quality multimodal training data.",
      "tldr_zh": "该研究提出LMM-R1框架，通过两阶段基于规则的强化学习(RL)方法，提升3B参数大型多模态模型(LMMs)的推理能力，以应对视觉感知与逻辑推理的复杂互动。框架首先采用基础推理增强(FRE)阶段，利用纯文本数据和规则-based RL强化推理能力；随后，通过多模态泛化训练(MGT)阶段，将这些能力扩展到多模态领域。实验在Qwen2.5-VL-Instruct-3B模型上显示，LMM-R1在多模态和纯文本基准上分别比基线提高了4.83%和4.5%，并在复杂足球游戏任务中获得3.63%的提升，提供了一种数据高效的方案，避免依赖昂贵的高质量多模态训练数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07536v2",
      "published_date": "2025-03-10 17:04:14 UTC",
      "updated_date": "2025-03-11 03:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:12:08.691813"
    },
    {
      "arxiv_id": "2503.07693v1",
      "title": "Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large Language Models",
      "title_zh": "完全自治编程：利用大语言模型的迭代多智能体调试",
      "authors": [
        "Anastasiia Grishina",
        "Vadim Liventsev",
        "Aki Härmä",
        "Leon Moonen"
      ],
      "abstract": "Program synthesis with Large Language Models (LLMs) suffers from a \"near-miss\nsyndrome\": the generated code closely resembles a correct solution but fails\nunit tests due to minor errors. We address this with a multi-agent framework\ncalled Synthesize, Execute, Instruct, Debug, and Repair (SEIDR). Effectively\napplying SEIDR to instruction-tuned LLMs requires determining (a) optimal\nprompts for LLMs, (b) what ranking algorithm selects the best programs in\ndebugging rounds, and (c) balancing the repair of unsuccessful programs with\nthe generation of new ones. We empirically explore these trade-offs by\ncomparing replace-focused, repair-focused, and hybrid debug strategies. We also\nevaluate lexicase and tournament selection to rank candidates in each\ngeneration. On Program Synthesis Benchmark 2 (PSB2), our framework outperforms\nboth conventional use of OpenAI Codex without a repair phase and traditional\ngenetic programming approaches. SEIDR outperforms the use of an LLM alone,\nsolving 18 problems in C++ and 20 in Python on PSB2 at least once across\nexperiments. To assess generalizability, we employ GPT-3.5 and Llama 3 on the\nPSB2 and HumanEval-X benchmarks. Although SEIDR with these models does not\nsurpass current state-of-the-art methods on the Python benchmarks, the results\non HumanEval-C++ are promising. SEIDR with Llama 3-8B achieves an average\npass@100 of 84.2%. Across all SEIDR runs, 163 of 164 problems are solved at\nleast once with GPT-3.5 in HumanEval-C++, and 162 of 164 with the smaller Llama\n3-8B. We conclude that SEIDR effectively overcomes the near-miss syndrome in\nprogram synthesis with LLMs.",
      "tldr_zh": "该论文提出了一种名为 SEIDR（Synthesize, Execute, Instruct, Debug, and Repair）的多智能体框架，利用 Large Language Models (LLMs) 进行迭代调试，以解决程序合成中的“near-miss syndrome”问题，即生成的代码因细微错误而失败单元测试。框架优化了提示设计、程序排名算法（如 lexicase 和 tournament selection）以及调试策略的平衡，包括 replace-focused、repair-focused 和 hybrid 方式。实验结果显示，SEIDR 在 Program Synthesis Benchmark 2 (PSB2) 上优于 OpenAI Codex 和传统遗传编程方法，成功解决更多 C++ 和 Python 问题；在 HumanEval-X 基准上，尤其在 HumanEval-C++ 中，SEIDR 与 Llama 3-8B 模型的 pass@100 达到 84.2%，证明其有效性。该框架显著提升了 LLMs 在自主编程中的可靠性和泛化能力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in ACM Trans. Evol. Learn. Optim., February\n  2025. arXiv admin note: text overlap with arXiv:2304.10423",
      "pdf_url": "http://arxiv.org/pdf/2503.07693v1",
      "published_date": "2025-03-10 16:56:51 UTC",
      "updated_date": "2025-03-10 16:56:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:12:21.636136"
    },
    {
      "arxiv_id": "2503.10673v2",
      "title": "ZeroSumEval: An Extensible Framework For Scaling LLM Evaluation with Inter-Model Competition",
      "title_zh": "翻译失败",
      "authors": [
        "Hisham A. Alyahya",
        "Haidar Khan",
        "Yazeed Alnumay",
        "M Saiful Bari",
        "Bülent Yener"
      ],
      "abstract": "We introduce ZeroSumEval, a dynamic, competition-based, and evolving\nevaluation framework for Large Language Models (LLMs) that leverages\ncompetitive games. ZeroSumEval encompasses a diverse suite of games, including\nsecurity challenges (Capture the Flag), classic board games (chess), and\nknowledge tests (MathQuiz). These games are designed to evaluate a range of\ncapabilities such as strategic reasoning, planning, knowledge application,\nsafety, and adaptability. Building upon recent studies that highlight the\neffectiveness of game-based evaluations for LLMs, ZeroSumEval enhances these\napproaches by providing a standardized and extensible framework for easily\nimplementing games and leverages DSPy to provide a better abstraction for LLM\nplayer strategies.",
      "tldr_zh": "本研究引入了 ZeroSumEval，这是一个基于竞争游戏的动态评估框架，用于扩展大型语言模型 (LLMs) 的评估，通过模型间竞争来提升评估效率。该框架涵盖多种游戏类型，包括安全挑战 (Capture the Flag)、经典棋类游戏 (chess) 和知识测试 (MathQuiz)，旨在评估模型的战略推理、规划、知识应用、安全性和适应性。ZeroSumEval 基于现有游戏评估研究，提供标准化和可扩展的实现，并利用 DSPy 优化 LLM 玩家的策略抽象，从而使评估过程更具灵活性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10673v2",
      "published_date": "2025-03-10 16:54:27 UTC",
      "updated_date": "2025-04-17 02:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:12:33.053031"
    },
    {
      "arxiv_id": "2503.07518v1",
      "title": "TokenButler: Token Importance is Predictable",
      "title_zh": "TokenButler: 标记重要性是可预测的",
      "authors": [
        "Yash Akhauri",
        "Ahmed F AbouElhamayed",
        "Yifei Gao",
        "Chi-Chih Chang",
        "Nilesh Jain",
        "Mohamed S. Abdelfattah"
      ],
      "abstract": "Large Language Models (LLMs) rely on the Key-Value (KV) Cache to store token\nhistory, enabling efficient decoding of tokens. As the KV-Cache grows, it\nbecomes a major memory and computation bottleneck, however, there is an\nopportunity to alleviate this bottleneck, especially because prior research has\nshown that only a small subset of tokens contribute meaningfully to each\ndecoding step. A key challenge in finding these critical tokens is that they\nare dynamic, and heavily input query-dependent. Existing methods either risk\nquality by evicting tokens permanently, or retain the full KV-Cache but rely on\nretrieving chunks (pages) of tokens at generation, failing at dense,\ncontext-rich tasks. Additionally, many existing KV-Cache sparsity methods rely\non inaccurate proxies for token importance. To address these limitations, we\nintroduce TokenButler, a high-granularity, query-aware predictor that learns to\nidentify these critical tokens. By training a light-weight predictor with less\nthan 1.2% parameter overhead, TokenButler prioritizes tokens based on their\ncontextual, predicted importance. This improves perplexity & downstream\naccuracy by over 8% relative to SoTA methods for estimating token importance.\nWe evaluate TokenButler on a novel synthetic small-context co-referential\nretrieval task, demonstrating near-oracle accuracy. Code, models and\nbenchmarks: https://github.com/abdelfattah-lab/TokenButler",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的 Key-Value (KV) Cache 内存和计算瓶颈问题，提出 TokenButler，一种高粒度、查询感知的预测器，用于动态识别关键 token。TokenButler 通过训练一个参数开销不到 1.2% 的轻量级模型，基于上下文预测 token 的重要性，从而优先处理相关 token，避免了现有方法的质量风险或低效检索。实验结果显示，该方法相对于最先进技术，提高了 perplexity 和下游准确率超过 8%，并在新型合成小上下文共指检索任务上实现了接近预言机的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07518v1",
      "published_date": "2025-03-10 16:41:14 UTC",
      "updated_date": "2025-03-10 16:41:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:12:44.803255"
    },
    {
      "arxiv_id": "2503.07690v1",
      "title": "Artificial Intelligence in Deliberation: The AI Penalty and the Emergence of a New Deliberative Divide",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Jungherr",
        "Adrian Rauchfleisch"
      ],
      "abstract": "Digital deliberation has expanded democratic participation, yet challenges\nremain. This includes processing information at scale, moderating discussions,\nfact-checking, or attracting people to participate. Recent advances in\nartificial intelligence (AI) offer potential solutions, but public perceptions\nof AI's role in deliberation remain underexplored. Beyond efficiency,\ndemocratic deliberation is about voice and recognition. If AI is integrated\ninto deliberation, public trust, acceptance, and willingness to participate may\nbe affected. We conducted a preregistered survey experiment with a\nrepresentative sample in Germany (n=1850) to examine how information about\nAI-enabled deliberation influences willingness to participate and perceptions\nof deliberative quality. Respondents were randomly assigned to treatments that\nprovided them information about deliberative tasks facilitated by either AI or\nhumans. Our findings reveal a significant AI-penalty. Participants were less\nwilling to engage in AI-facilitated deliberation and rated its quality lower\nthan human-led formats. These effects were moderated by individual\npredispositions. Perceptions of AI's societal benefits and anthropomorphization\nof AI showed positive interaction effects on people's interest to participate\nin AI-enabled deliberative formats and positive quality assessments, while AI\nrisk assessments showed negative interactions with information about AI-enabled\ndeliberation. These results suggest AI-enabled deliberation faces substantial\npublic skepticism, potentially even introducing a new deliberative divide.\nUnlike traditional participation gaps based on education or demographics, this\ndivide is shaped by attitudes toward AI. As democratic engagement increasingly\nmoves online, ensuring AI's role in deliberation does not discourage\nparticipation or deepen inequalities will be a key challenge for future\nresearch and policy.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在民主审议中的作用，通过一项在德国代表性样本（n=1850）中进行的预注册调查实验（preregistered survey experiment），揭示了显著的“AI penalty”现象。研究发现，公众对 AI 辅助审议的参与意愿较低，并对其审议质量评价更低，这些效果受个人倾向影响：如对 AI 社会益处的感知和 AI 的拟人化（anthropomorphization）会增强参与兴趣，而 AI 风险评估则会加剧负面反应。论文强调，这可能导致新的审议分化（deliberative divide），基于对 AI 的态度而非传统因素（如教育或人口统计），并呼吁未来研究和政策确保 AI 不阻碍民主参与或加深不平等。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07690v1",
      "published_date": "2025-03-10 16:33:15 UTC",
      "updated_date": "2025-03-10 16:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:12:57.791272"
    },
    {
      "arxiv_id": "2503.07513v2",
      "title": "Language Models Fail to Introspect About Their Knowledge of Language",
      "title_zh": "语言模型无法内省其对语言的知识",
      "authors": [
        "Siyuan Song",
        "Jennifer Hu",
        "Kyle Mahowald"
      ],
      "abstract": "There has been recent interest in whether large language models (LLMs) can\nintrospect about their own internal states. Such abilities would make LLMs more\ninterpretable, and also validate the use of standard introspective methods in\nlinguistics to evaluate grammatical knowledge in models (e.g., asking \"Is this\nsentence grammatical?\"). We systematically investigate emergent introspection\nacross 21 open-source LLMs, in two domains where introspection is of\ntheoretical interest: grammatical knowledge and word prediction. Crucially, in\nboth domains, a model's internal linguistic knowledge can be theoretically\ngrounded in direct measurements of string probability. We then evaluate whether\nmodels' responses to metalinguistic prompts faithfully reflect their internal\nknowledge. We propose a new measure of introspection: the degree to which a\nmodel's prompted responses predict its own string probabilities, beyond what\nwould be predicted by another model with nearly identical internal knowledge.\nWhile both metalinguistic prompting and probability comparisons lead to high\ntask accuracy, we do not find evidence that LLMs have privileged \"self-access\".\nOur findings complicate recent results suggesting that models can introspect,\nand add new evidence to the argument that prompted responses should not be\nconflated with models' linguistic generalizations.",
      "tldr_zh": "这篇论文调查了大型语言模型 (LLMs) 是否能内省其自身的语言知识，包括语法知识和单词预测领域。研究者通过对21个开源LLMs进行系统评估，使用元语言提示和字符串概率测量，提出一个新度量来检查模型响应是否忠实反映其内部知识。结果显示，虽然这些方法能实现高任务准确率，但LLMs缺乏特权的“self-access”，即无法真正内省。总体而言，这质疑了LLMs内省能力的先前假设，并强调不应将提示响应等同于模型的语言泛化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Corrected Fig 5a and removed unused figures from source files",
      "pdf_url": "http://arxiv.org/pdf/2503.07513v2",
      "published_date": "2025-03-10 16:33:14 UTC",
      "updated_date": "2025-03-12 03:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:13:09.079111"
    },
    {
      "arxiv_id": "2503.07509v1",
      "title": "Interference-Aware Super-Constellation Design for NOMA",
      "title_zh": "针对 NOMA 的干扰感知超星座图设计",
      "authors": [
        "Mojtaba Vaezi",
        "Xinliang Zhang"
      ],
      "abstract": "Non-orthogonal multiple access (NOMA) has gained significant attention as a\npotential next-generation multiple access technique. However, its\nimplementation with finite-alphabet inputs faces challenges. Particularly, due\nto inter-user interference, superimposed constellations may have overlapping\nsymbols leading to high bit error rates when successive interference\ncancellation (SIC) is applied. To tackle the issue, this paper employs\nautoencoders to design interference-aware super-constellations. Unlike\nconventional methods where superimposed constellation may have overlapping\nsymbols, the proposed autoencoder-based NOMA (AE-NOMA) is trained to design\nsuper-constellations with distinguishable symbols at receivers, regardless of\nchannel gains. The proposed architecture removes the need for SIC, allowing\nmaximum likelihood-based approaches to be used instead. The paper presents the\nconceptual architecture, loss functions, and training strategies for AE-NOMA.\nVarious test results are provided to demonstrate the effectiveness of\ninterference-aware constellations in improving the bit error rate, indicating\nthe adaptability of AE-NOMA to different channel scenarios and its promising\npotential for implementing NOMA systems",
      "tldr_zh": "这篇论文针对非正交多址技术(NOMA)中用户间干扰导致的符号重叠和高位错误率问题，提出了一种基于autoencoders的干扰感知超星座设计方法。提出的AE-NOMA架构通过训练生成接收端符号可区分的super-constellations，无论信道增益如何，从而消除对逐次干扰消除(SIC)的依赖，转而采用maximum likelihood-based方法。实验结果表明，该方法显著改善了bit error rate，并展示了在不同信道场景下的适应性和实现NOMA系统的潜力。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Accepted for publication at IEEE International Conference on\n  Communications (ICC), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07509v1",
      "published_date": "2025-03-10 16:31:33 UTC",
      "updated_date": "2025-03-10 16:31:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:13:20.550188"
    },
    {
      "arxiv_id": "2503.07505v1",
      "title": "From Centralized to Decentralized Federated Learning: Theoretical Insights, Privacy Preservation, and Robustness Challenges",
      "title_zh": "从集中式到去",
      "authors": [
        "Qiongxiu Li",
        "Wenrui Yu",
        "Yufei Xia",
        "Jun Pang"
      ],
      "abstract": "Federated Learning (FL) enables collaborative learning without directly\nsharing individual's raw data. FL can be implemented in either a centralized\n(server-based) or decentralized (peer-to-peer) manner. In this survey, we\npresent a novel perspective: the fundamental difference between centralized FL\n(CFL) and decentralized FL (DFL) is not merely the network topology, but the\nunderlying training protocol: separate aggregation vs. joint optimization. We\nargue that this distinction in protocol leads to significant differences in\nmodel utility, privacy preservation, and robustness to attacks. We\nsystematically review and categorize existing works in both CFL and DFL\naccording to the type of protocol they employ. This taxonomy provides deeper\ninsights into prior research and clarifies how various approaches relate or\ndiffer. Through our analysis, we identify key gaps in the literature. In\nparticular, we observe a surprising lack of exploration of DFL approaches based\non distributed optimization methods, despite their potential advantages. We\nhighlight this under-explored direction and call for more research on\nleveraging distributed optimization for federated learning. Overall, this work\noffers a comprehensive overview from centralized to decentralized FL, sheds new\nlight on the core distinctions between approaches, and outlines open challenges\nand future directions for the field.",
      "tldr_zh": "这篇论文探讨了 Federated Learning (FL) 从 Centralized FL (CFL) 到 Decentralized FL (DFL) 的转变，强调核心区别在于训练协议（separate aggregation vs. joint optimization），这导致了模型效用、隐私保护和鲁棒性方面的显著差异。该研究系统审阅并分类了现有 CFL 和 DFL 工作，提供了一个新的分类框架，以揭示不同方法的关联和差异。通过分析，论文识别出文献中的关键空白，特别是 DFL 中基于分布式优化方法的潜在优势尚未充分探索，并呼吁更多研究来推动该领域的发展。总体上，这为 FL 提供了全面概述，并指出了未来的挑战和方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07505v1",
      "published_date": "2025-03-10 16:27:40 UTC",
      "updated_date": "2025-03-10 16:27:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:13:33.305221"
    },
    {
      "arxiv_id": "2504.00002v1",
      "title": "Are We There Yet? A Measurement Study of Efficiency for LLM Applications on Mobile Devices",
      "title_zh": "我们到了吗？ LLM 应用在移动设备上的效率测量研究",
      "authors": [
        "Xiao Yan",
        "Yi Ding"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have prompted interest in\ndeploying these models on mobile devices to enable new applications without\nrelying on cloud connectivity. However, the efficiency constraints of deploying\nLLMs on resource-limited devices present significant challenges. In this paper,\nwe conduct a comprehensive measurement study to evaluate the efficiency\ntradeoffs between mobile-based, edge-based, and cloud-based deployments for LLM\napplications. We implement AutoLife-Lite, a simplified LLM-based application\nthat analyzes smartphone sensor data to infer user location and activity\ncontexts. Our experiments reveal that: (1) Only small-size LLMs (<4B\nparameters) can run successfully on powerful mobile devices, though they\nexhibit quality limitations compared to larger models; (2) Model compression is\neffective in lower the hardware requirement, but may lead to significant\nperformance degradation; (3) The latency to run LLMs on mobile devices with\nmeaningful output is significant (>30 seconds), while cloud services\ndemonstrate better time efficiency (<10 seconds); (4) Edge deployments offer\nintermediate tradeoffs between latency and model capabilities, with different\nresults on CPU-based and GPU-based settings. These findings provide valuable\ninsights for system designers on the current limitations and future directions\nfor on-device LLM applications.",
      "tldr_zh": "本研究通过测量评估了大型语言模型(LLMs)在移动设备上的部署效率，比较了移动设备、本地边缘和云端部署的权衡。研究者实现了AutoLife-Lite应用，利用智能手机传感器数据推断用户位置和活动，并发现只有小型LLMs（<4B参数）能在强大移动设备上运行，但其性能和质量不如大型模型。实验结果显示，模型压缩可降低硬件需求，但可能导致显著性能下降，而移动设备运行延迟超过30秒，云服务则更快（<10秒），边缘部署则在延迟和能力间提供中间折中。这些发现为系统设计师提供了关于LLMs应用当前限制和未来方向的宝贵见解。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.HC",
        "cs.NI"
      ],
      "primary_category": "cs.PF",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00002v1",
      "published_date": "2025-03-10 16:27:17 UTC",
      "updated_date": "2025-03-10 16:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:13:44.921550"
    },
    {
      "arxiv_id": "2503.07493v1",
      "title": "V2Flow: Unifying Visual Tokenization and Large Language Model Vocabularies for Autoregressive Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Guiwei Zhang",
        "Tianyu Zhang",
        "Mohan Zhou",
        "Yalong Bai",
        "Biye Li"
      ],
      "abstract": "We propose V2Flow, a novel tokenizer that produces discrete visual tokens\ncapable of high-fidelity reconstruction, while ensuring structural and latent\ndistribution alignment with the vocabulary space of large language models\n(LLMs). Leveraging this tight visual-vocabulary coupling, V2Flow enables\nautoregressive visual generation on top of existing LLMs. Our approach\nformulates visual tokenization as a flow-matching problem, aiming to learn a\nmapping from a standard normal prior to the continuous image distribution,\nconditioned on token sequences embedded within the LLMs vocabulary space. The\neffectiveness of V2Flow stems from two core designs. First, we propose a Visual\nVocabulary resampler, which compresses visual data into compact token\nsequences, with each represented as a soft categorical distribution over LLM's\nvocabulary. This allows seamless integration of visual tokens into existing\nLLMs for autoregressive visual generation. Second, we present a masked\nautoregressive Rectified-Flow decoder, employing a masked transformer\nencoder-decoder to refine visual tokens into contextually enriched embeddings.\nThese embeddings then condition a dedicated velocity field for precise\nreconstruction. Additionally, an autoregressive rectified-flow sampling\nstrategy is incorporated, ensuring flexible sequence lengths while preserving\ncompetitive reconstruction quality. Extensive experiments show that V2Flow\noutperforms mainstream VQ-based tokenizers and facilitates autoregressive\nvisual generation on top of existing. https://github.com/zhangguiwei610/V2Flow",
      "tldr_zh": "本研究提出V2Flow，一种新型tokenizer，用于生成高保真度的离散视觉tokens，同时确保这些tokens与Large Language Models (LLMs)词汇空间在结构和潜在分布上对齐，从而支持在现有LLMs上进行自回归图像生成。V2Flow将视觉tokenization表述为flow-matching问题，通过Visual Vocabulary resampler压缩视觉数据成紧凑的token序列（每个序列作为LLMs词汇的软分类分布），并采用masked autoregressive Rectified-Flow decoder结合masked transformer encoder-decoder来细化tokens并条件速度场实现精确重建。实验结果显示，V2Flow优于主流VQ-based tokenizers，并在灵活序列长度下保持高重建质量，实现了有效的自回归视觉生成。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07493v1",
      "published_date": "2025-03-10 16:12:50 UTC",
      "updated_date": "2025-03-10 16:12:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:13:57.423273"
    },
    {
      "arxiv_id": "2503.07482v1",
      "title": "Efficient Membership Inference Attacks by Bayesian Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenlong Liu",
        "Wenyu Jiang",
        "Feng Zhou",
        "Hongxin Wei"
      ],
      "abstract": "Membership Inference Attacks (MIAs) aim to estimate whether a specific data\npoint was used in the training of a given model. Previous attacks often utilize\nmultiple reference models to approximate the conditional score distribution,\nleading to significant computational overhead. While recent work leverages\nquantile regression to estimate conditional thresholds, it fails to capture\nepistemic uncertainty, resulting in bias in low-density regions. In this work,\nwe propose a novel approach - Bayesian Membership Inference Attack (BMIA),\nwhich performs conditional attack through Bayesian inference. In particular, we\ntransform a trained reference model into Bayesian neural networks by Laplace\napproximation, enabling the direct estimation of the conditional score\ndistribution by probabilistic model parameters. Our method addresses both\nepistemic and aleatoric uncertainty with only a reference model, enabling\nefficient and powerful MIA. Extensive experiments on five datasets demonstrate\nthe effectiveness and efficiency of BMIA.",
      "tldr_zh": "该研究针对 Membership Inference Attacks (MIAs) 提出了一种高效方法，即 Bayesian Membership Inference Attack (BMIA)，通过贝叶斯推理直接估计条件分数分布，以判断数据点是否用于模型训练。BMIA 使用 Laplace approximation 将训练好的参考模型转化为 Bayesian Neural Networks (BNNs)，从而同时处理 epistemic uncertainty 和 aleatoric uncertainty，仅需一个参考模型即可降低计算开销。实验在五个数据集上验证了 BMIA 的有效性和效率，显著提高了攻击性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2503.07482v1",
      "published_date": "2025-03-10 15:58:43 UTC",
      "updated_date": "2025-03-10 15:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:14:08.173779"
    },
    {
      "arxiv_id": "2503.07470v1",
      "title": "Advancing Vietnamese Information Retrieval with Learning Objective and Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Phu-Vinh Nguyen",
        "Minh-Nam Tran",
        "Long Nguyen",
        "Dien Dinh"
      ],
      "abstract": "With the rapid development of natural language processing, many language\nmodels have been invented for multiple tasks. One important task is information\nretrieval (IR), which requires models to retrieve relevant documents. Despite\nits importance in many real-life applications, especially in retrieval\naugmented generation (RAG) systems, this task lacks Vietnamese benchmarks. This\nsituation causes difficulty in assessing and comparing many existing Vietnamese\nembedding language models on the task and slows down the advancement of\nVietnamese natural language processing (NLP) research. In this work, we aim to\nprovide the Vietnamese research community with a new benchmark for information\nretrieval, which mainly focuses on retrieval and reranking tasks. Furthermore,\nwe also present a new objective function based on the InfoNCE loss function,\nwhich is used to train our Vietnamese embedding model. Our function aims to be\nbetter than the origin in information retrieval tasks. Finally, we analyze the\neffect of temperature, a hyper-parameter in both objective functions, on the\nperformance of text embedding models.",
      "tldr_zh": "随着自然语言处理（NLP）的快速发展，信息检索（IR）任务在越南语领域缺乏基准，导致现有越南语嵌入模型的评估和比较困难，从而阻碍了相关研究进展。论文的主要贡献是为越南语社区提供了一个新的 IR 基准，专注于检索和重新排序任务，以支持检索增强生成（RAG）系统等应用。该研究还提出了一种基于 InfoNCE loss function 的新目标函数，用于训练越南语嵌入模型，该函数旨在在 IR 任务中比原函数表现更好。最后，通过分析温度（temperature）超参数的影响，论文展示了其对文本嵌入模型性能的关键作用。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07470v1",
      "published_date": "2025-03-10 15:47:01 UTC",
      "updated_date": "2025-03-10 15:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:14:21.042968"
    },
    {
      "arxiv_id": "2503.07459v2",
      "title": "MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangru Tang",
        "Daniel Shao",
        "Jiwoong Sohn",
        "Jiapeng Chen",
        "Jiayi Zhang",
        "Jinyu Xiang",
        "Fang Wu",
        "Yilun Zhao",
        "Chenglin Wu",
        "Wenqi Shi",
        "Arman Cohan",
        "Mark Gerstein"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive performance on existing\nmedical question-answering benchmarks. This high performance makes it\nincreasingly difficult to meaningfully evaluate and differentiate advanced\nmethods. We present MedAgentsBench, a benchmark that focuses on challenging\nmedical questions requiring multi-step clinical reasoning, diagnosis\nformulation, and treatment planning-scenarios where current models still\nstruggle despite their strong performance on standard tests. Drawing from seven\nestablished medical datasets, our benchmark addresses three key limitations in\nexisting evaluations: (1) the prevalence of straightforward questions where\neven base models achieve high performance, (2) inconsistent sampling and\nevaluation protocols across studies, and (3) lack of systematic analysis of the\ninterplay between performance, cost, and inference time. Through experiments\nwith various base models and reasoning methods, we demonstrate that the latest\nthinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in\ncomplex medical reasoning tasks. Additionally, advanced search-based agent\nmethods offer promising performance-to-cost ratios compared to traditional\napproaches. Our analysis reveals substantial performance gaps between model\nfamilies on complex questions and identifies optimal model selections for\ndifferent computational constraints. Our benchmark and evaluation framework are\npublicly available at https://github.com/gersteinlab/medagents-benchmark.",
      "tldr_zh": "本研究引入了MedAgentsBench基准，用于评估Large Language Models (LLMs)和代理框架在复杂医疗推理任务中的性能，针对多步临床推理、诊断制定和治疗规划等挑战性场景。基准从七个现有医疗数据集抽取问题，解决了现有评估的三大局限：简单问题主导导致基线模型高性能、不一致的采样和评估协议，以及缺乏对性能、成本和推理时间之间关系的系统分析。实验结果显示，DeepSeek R1和OpenAI o3模型在复杂医疗任务中表现出色，而高级搜索-based代理方法提供了更高的性能-成本比；此外，该基准揭示了不同模型家族间的显著性能差距，并公开了评估框架以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07459v2",
      "published_date": "2025-03-10 15:38:44 UTC",
      "updated_date": "2025-03-20 01:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:14:34.174826"
    },
    {
      "arxiv_id": "2503.07453v2",
      "title": "Is a Good Foundation Necessary for Efficient Reinforcement Learning? The Computational Role of the Base Model in Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan J. Foster",
        "Zakaria Mhammedi",
        "Dhruv Rohatgi"
      ],
      "abstract": "Language model alignment (or, reinforcement learning) techniques that\nleverage active exploration -- deliberately encouraging the model to produce\ndiverse, informative responses -- offer the promise of super-human\ncapabilities. However, current understanding of algorithm design primitives for\ncomputationally efficient exploration with language models is limited. To\nbetter understand how to leverage access to powerful pre-trained generative\nmodels to improve the efficiency of exploration, we introduce a new\ncomputational framework for RL with language models, in which the learner\ninteracts with the model through a sampling oracle. Focusing on the linear\nsoftmax model parameterization, we provide new results that reveal the\ncomputational-statistical tradeoffs of efficient exploration:\n  1. Necessity of coverage: Coverage refers to the extent to which the\npre-trained model covers near-optimal responses -- a form of hidden knowledge.\nWe show that coverage, while not necessary for data efficiency, lower bounds\nthe runtime of any algorithm in our framework.\n  2. Inference-time exploration: We introduce a new algorithm, SpannerSampling,\nwhich obtains optimal data efficiency and is computationally efficient whenever\nthe pre-trained model enjoys sufficient coverage, matching our lower bound.\nSpannerSampling leverages inference-time computation with the pre-trained model\nto reduce the effective search space for exploration.\n  3. Insufficiency of training-time interventions: We contrast the result above\nby showing that training-time interventions that produce proper policies cannot\nachieve similar guarantees in polynomial time.\n  4. Computational benefits of multi-turn exploration: Finally, we show that\nunder additional representational assumptions, one can achieve improved runtime\n(replacing sequence-level coverage with token-level coverage) through\nmulti-turn exploration.",
      "tldr_zh": "该论文探讨了在强化学习（RL）中，强大的预训练模型（base model）是否对高效探索至关重要，重点分析其计算作用。研究引入了一个新的计算框架，其中学习者通过采样预言机与语言模型互动，并针对线性 softmax 参数化揭示了计算-统计权衡：覆盖性（coverage）虽非数据效率必需，但下界了算法运行时。作者提出 SpannerSampling 算法，在预训练模型有足够覆盖性时实现最佳数据效率和计算效率；此外，多轮探索（multi-turn exploration）可进一步改善运行时，通过 token-level 覆盖取代 sequence-level 覆盖。训练时干预（training-time interventions）则无法在多项式时间内达到类似效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "V2: Improved number of prompts used by Algorithm 1",
      "pdf_url": "http://arxiv.org/pdf/2503.07453v2",
      "published_date": "2025-03-10 15:31:42 UTC",
      "updated_date": "2025-03-13 23:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:14:45.557224"
    },
    {
      "arxiv_id": "2503.07450v3",
      "title": "From Idea to Implementation: Evaluating the Influence of Large Language Models in Software Development -- An Opinion Paper",
      "title_zh": "从想法到实现：评估大型语言模型在",
      "authors": [
        "Sargam Yadav",
        "Asifa Mehmood Qureshi",
        "Abhishek Kaushik",
        "Shubham Sharma",
        "Roisin Loughran",
        "Subramaniam Kazhuparambil",
        "Andrew Shaw",
        "Mohammed Sabry",
        "Niamh St John Lynch",
        ". Nikhil Singh",
        "Padraic O'Hara",
        "Pranay Jaiswal",
        "Roshan Chandru",
        "David Lillis"
      ],
      "abstract": "The introduction of transformer architecture was a turning point in Natural\nLanguage Processing (NLP). Models based on the transformer architecture such as\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-Trained Transformer (GPT) have gained widespread popularity in various\napplications such as software development and education. The availability of\nLarge Language Models (LLMs) such as ChatGPT and Bard to the general public has\nshowcased the tremendous potential of these models and encouraged their\nintegration into various domains such as software development for tasks such as\ncode generation, debugging, and documentation generation. In this study,\nopinions from 11 experts regarding their experience with LLMs for software\ndevelopment have been gathered and analysed to draw insights that can guide\nsuccessful and responsible integration. The overall opinion of the experts is\npositive, with the experts identifying advantages such as increase in\nproductivity and reduced coding time. Potential concerns and challenges such as\nrisk of over-dependence and ethical considerations have also been highlighted.",
      "tldr_zh": "这篇意见论文评估了 Large Language Models (LLMs) 如 ChatGPT 和 Bard 在软件开发中的影响，探讨了这些基于 transformer 架构的模型在代码生成、调试和文档生成等方面的应用。研究通过收集和分析11位专家的经验意见，揭示了LLMs的优势，包括提高生产力和减少编码时间。专家们同时强调了潜在挑战，如过度依赖和伦理问题，并为实现成功且负责任的LLMs集成提供了指导见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The project is partially supported by the DkIT Postgraduate\n  Scholarship, Research Ireland under Grant number 13/RC/2094_2, and Grant\n  number 21/FFP-A/925",
      "pdf_url": "http://arxiv.org/pdf/2503.07450v3",
      "published_date": "2025-03-10 15:30:05 UTC",
      "updated_date": "2025-04-20 22:50:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:14:56.336230"
    },
    {
      "arxiv_id": "2503.07444v1",
      "title": "Divide and Conquer Self-Supervised Learning for High-Content Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Farndale",
        "Paul Henderson",
        "Edward W Roberts",
        "Ke Yuan"
      ],
      "abstract": "Self-supervised representation learning methods often fail to learn subtle or\ncomplex features, which can be dominated by simpler patterns which are much\neasier to learn. This limitation is particularly problematic in applications to\nscience and engineering, as complex features can be critical for discovery and\nanalysis. To address this, we introduce Split Component Embedding Registration\n(SpliCER), a novel architecture which splits the image into sections and\ndistils information from each section to guide the model to learn more subtle\nand complex features without compromising on simpler features. SpliCER is\ncompatible with any self-supervised loss function and can be integrated into\nexisting methods without modification. The primary contributions of this work\nare as follows: i) we demonstrate that existing self-supervised methods can\nlearn shortcut solutions when simple and complex features are both present; ii)\nwe introduce a novel self-supervised training method, SpliCER, to overcome the\nlimitations of existing methods, and achieve significant downstream performance\nimprovements; iii) we demonstrate the effectiveness of SpliCER in cutting-edge\nmedical and geospatial imaging settings. SpliCER offers a powerful new tool for\nrepresentation learning, enabling models to uncover complex features which\ncould be overlooked by other methods.",
      "tldr_zh": "本文研究发现，现有的自监督学习(Self-Supervised Learning)方法在高内容成像(High-Content Imaging)中往往优先学习简单模式，导致微妙或复杂特征被忽略，从而影响科学发现和分析。作者提出了一种新架构 Split Component Embedding Registration (SpliCER)，通过将图像分成部分并从每个部分提炼信息，引导模型同时学习复杂和简单特征，且可无缝整合到任何自监督损失函数中。实验结果显示，SpliCER 在医疗和地理空间成像应用中显著提升下游性能，并证明了其在克服现有方法捷径问题的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07444v1",
      "published_date": "2025-03-10 15:24:36 UTC",
      "updated_date": "2025-03-10 15:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:15:09.160367"
    },
    {
      "arxiv_id": "2503.07429v1",
      "title": "From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector Graphics",
      "title_zh": "翻译失败",
      "authors": [
        "Jaewook Lee",
        "Jeongah Lee",
        "Wanyong Feng",
        "Andrew Lan"
      ],
      "abstract": "Advances in large language models (LLMs) offer new possibilities for\nenhancing math education by automating support for both teachers and students.\nWhile prior work has focused on generating math problems and high-quality\ndistractors, the role of visualization in math learning remains under-explored.\nDiagrams are essential for mathematical thinking and problem-solving, yet\nmanually creating them is time-consuming and requires domain-specific\nexpertise, limiting scalability. Recent research on using LLMs to generate\nScalable Vector Graphics (SVG) presents a promising approach to automating\ndiagram creation. Unlike pixel-based images, SVGs represent geometric figures\nusing XML, allowing seamless scaling and adaptability. Educational platforms\nsuch as Khan Academy and IXL already use SVGs to display math problems and\nhints. In this paper, we explore the use of LLMs to generate math-related\ndiagrams that accompany textual hints via intermediate SVG representations. We\naddress three research questions: (1) how to automatically generate math\ndiagrams in problem-solving hints and evaluate their quality, (2) whether SVG\nis an effective intermediate representation for math diagrams, and (3) what\nprompting strategies and formats are required for LLMs to generate accurate\nSVG-based diagrams. Our contributions include defining the task of\nautomatically generating SVG-based diagrams for math hints, developing an LLM\nprompting-based pipeline, and identifying key strategies for improving diagram\ngeneration. Additionally, we introduce a Visual Question Answering-based\nevaluation setup and conduct ablation studies to assess different pipeline\nvariations. By automating the math diagram creation, we aim to provide students\nand teachers with accurate, conceptually relevant visual aids that enhance\nproblem-solving and learning experiences.",
      "tldr_zh": "这篇论文探讨使用大型语言模型 (LLMs) 来自动生成数学图表，从而提升数学教育中的视觉辅助。研究焦点是通过 SVG（Scalable Vector Graphics）作为中间表示，从文本提示生成高质量的数学图表，解决手动创建图表的耗时问题。作者定义了生成任务、开发了基于 LLM 的提示管道，并识别了优化提示策略的关键方法，同时引入 Visual Question Answering (VQA) 评估框架和消融研究来评估效果。最终，该方法旨在为学生和教师提供准确的相关视觉辅助，提升问题解决和学习体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07429v1",
      "published_date": "2025-03-10 15:13:38 UTC",
      "updated_date": "2025-03-10 15:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:15:21.776330"
    },
    {
      "arxiv_id": "2503.07426v1",
      "title": "RePO: ReLU-based Preference Optimization",
      "title_zh": "RePO：基于 ReLU 的偏好优化",
      "authors": [
        "Junkang Wu",
        "Kexin Huang",
        "Xue Wang",
        "Jinyang Gao",
        "Bolin Ding",
        "Jiancan Wu",
        "Xiangnan He",
        "Xiang Wang"
      ],
      "abstract": "Aligning large language models (LLMs) with human preferences is critical for\nreal-world deployment, yet existing methods like RLHF face computational and\nstability challenges. While DPO establishes an offline paradigm with single\nhyperparameter $\\beta$, subsequent methods like SimPO reintroduce complexity\nthrough dual parameters ($\\beta$, $\\gamma$). We propose {ReLU-based Preference\nOptimization (RePO)}, a streamlined algorithm that eliminates $\\beta$ via two\nadvances: (1) retaining SimPO's reference-free margins but removing $\\beta$\nthrough gradient analysis, and (2) adopting a ReLU-based max-margin loss that\nnaturally filters trivial pairs. Theoretically, RePO is characterized as\nSimPO's limiting case ($\\beta \\to \\infty$), where the logistic weighting\ncollapses to binary thresholding, forming a convex envelope of the 0-1 loss.\nEmpirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO\nand SimPO across multiple base models, requiring only one hyperparameter to\ntune.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 与人类偏好对齐的问题，提出 ReLU-based Preference Optimization (RePO) 算法，以简化现有方法如 RLHF、DPO 和 SimPO 的计算挑战和超参数复杂性。RePO 通过梯度分析移除超参数 β，并采用基于 ReLU 的最大边际损失来过滤琐碎对，从而保留 SimPO 的无参考边际。理论上，RePO 等效于 SimPO 的极限情况 (β → ∞)，形成 0-1 损失的凸包；实证结果显示，在 AlpacaEval 2 和 Arena-Hard 基准上，RePO 优于 DPO 和 SimPO，且只需调整一个超参数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07426v1",
      "published_date": "2025-03-10 15:11:07 UTC",
      "updated_date": "2025-03-10 15:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:15:33.865139"
    },
    {
      "arxiv_id": "2503.08717v1",
      "title": "A Semantic Link Network Model for Supporting Traceability of Logistics on Blockchain",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoping Sun",
        "Sirui Zhuge",
        "Hai Zhuge"
      ],
      "abstract": "The ability of tracing states of logistic transportations requires an\nefficient storage and retrieval of the state of logistic transportations and\nlocations of logistic objects. However, the restriction of sharing states and\nlocations of logistic objects across organizations from different countries\nmakes it hard to deploy a centralized database for implementing the\ntraceability in a cross-border logistic system. This paper proposes a semantic\ndata model on Blockchain to represent a logistic process based on the Semantic\nLink Network model where each semantic link represents a logistic\ntransportation of a logistic object between two parties. A state representation\nmodel is designed to represent the states of a logistic transportation with\nsemantic links. It enables the locations of logistic objects to be derived from\nthe link states. A mapping from the semantic links to the blockchain\ntransactions is designed to enable schema of semantic links and states of\nsemantic links to be published in blockchain transactions. To improve the\nefficiency of tracing a path of semantic links on blockchain platform, an\nalgorithm is designed to build shortcuts along the path of semantic links to\nenable a query on the path of a logistic object to reach the target in\nlogarithmic steps on the blockchain platform. A reward-penalty policy is\ndesigned to allow participants to confirm the state of links on blockchain.\nAnalysis and simulation demonstrate the flexibility, effectiveness and the\nefficiency of Semantic Link Network on immutable blockchain for implementing\nlogistic traceability.",
      "tldr_zh": "这篇论文提出了一种基于 Semantic Link Network 的模型，用于在 Blockchain 上实现物流追踪，支持高效存储和检索物流对象的状态和位置，以解决跨国组织间信息共享的限制。模型通过语义链接表示物流运输过程，并设计了状态表示模型和算法来构建路径捷径，使查询效率提升到对数级步骤，同时引入奖励-惩罚政策让参与者确认链接状态。主要贡献包括将语义链接映射到区块链交易，并通过分析和模拟证明了该模型的灵活性、有效性和效率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DB",
        "cs.SI",
        "H.2.5; I.2.4"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08717v1",
      "published_date": "2025-03-10 14:56:00 UTC",
      "updated_date": "2025-03-10 14:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:15:45.209515"
    },
    {
      "arxiv_id": "2503.07396v1",
      "title": "Brain Inspired Adaptive Memory Dual-Net for Few-Shot Image Classification",
      "title_zh": "基于大脑启发的自适应记忆双网络用于少样本图像分类",
      "authors": [
        "Kexin Di",
        "Xiuxing Li",
        "Yuyang Han",
        "Ziyu Li",
        "Qing Li",
        "Xia Wu"
      ],
      "abstract": "Few-shot image classification has become a popular research topic for its\nwide application in real-world scenarios, however the problem of supervision\ncollapse induced by single image-level annotation remains a major challenge.\nExisting methods aim to tackle this problem by locating and aligning relevant\nlocal features. However, the high intra-class variability in real-world images\nposes significant challenges in locating semantically relevant local regions\nunder few-shot settings. Drawing inspiration from the human's complementary\nlearning system, which excels at rapidly capturing and integrating semantic\nfeatures from limited examples, we propose the generalization-optimized Systems\nConsolidation Adaptive Memory Dual-Network, SCAM-Net. This approach simulates\nthe systems consolidation of complementary learning system with an adaptive\nmemory module, which successfully addresses the difficulty of identifying\nmeaningful features in few-shot scenarios. Specifically, we construct a\nHippocampus-Neocortex dual-network that consolidates structured representation\nof each category, the structured representation is then stored and adaptively\nregulated following the generalization optimization principle in a long-term\nmemory inside Neocortex. Extensive experiments on benchmark datasets show that\nthe proposed model has achieved state-of-the-art performance.",
      "tldr_zh": "本论文针对 Few-shot image classification 中的监督崩溃问题和高类内变异性挑战，提出受人类互补学习系统启发的 SCAM-Net（generalization-optimized Systems Consolidation Adaptive Memory Dual-Network）。该模型通过模拟 systems consolidation，建立一个 Hippocampus-Neocortex dual-network 来巩固每个类别的结构化表示，并使用自适应记忆模块根据 generalization optimization 原则调节长期记忆中的特征，从而有效捕获和整合有限样本中的语义特征。实验结果显示，SCAM-Net 在基准数据集上取得了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07396v1",
      "published_date": "2025-03-10 14:42:51 UTC",
      "updated_date": "2025-03-10 14:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:15:57.929673"
    },
    {
      "arxiv_id": "2503.07389v1",
      "title": "TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ruidong Chen",
        "Honglin Guo",
        "Lanjun Wang",
        "Chenyu Zhang",
        "Weizhi Nie",
        "An-An Liu"
      ],
      "abstract": "Recent advances in text-to-image diffusion models enable photorealistic image\ngeneration, but they also risk producing malicious content, such as NSFW\nimages. To mitigate risk, concept erasure methods are studied to facilitate the\nmodel to unlearn specific concepts. However, current studies struggle to fully\nerase malicious concepts implicitly embedded in prompts (e.g., metaphorical\nexpressions or adversarial prompts) while preserving the model's normal\ngeneration capability. To address this challenge, our study proposes TRCE,\nusing a two-stage concept erasure strategy to achieve an effective trade-off\nbetween reliable erasure and knowledge preservation. Firstly, TRCE starts by\nerasing the malicious semantics implicitly embedded in textual prompts. By\nidentifying a critical mapping objective(i.e., the [EoT] embedding), we\noptimize the cross-attention layers to map malicious prompts to contextually\nsimilar prompts but with safe concepts. This step prevents the model from being\noverly influenced by malicious semantics during the denoising process.\nFollowing this, considering the deterministic properties of the sampling\ntrajectory of the diffusion model, TRCE further steers the early denoising\nprediction toward the safe direction and away from the unsafe one through\ncontrastive learning, thus further avoiding the generation of malicious\ncontent. Finally, we conduct comprehensive evaluations of TRCE on multiple\nmalicious concept erasure benchmarks, and the results demonstrate its\neffectiveness in erasing malicious concepts while better preserving the model's\noriginal generation ability. The code is available at:\nhttp://github.com/ddgoodgood/TRCE. CAUTION: This paper includes model-generated\ncontent that may contain offensive material.",
      "tldr_zh": "该研究针对文本到图像扩散模型（text-to-image diffusion models）可能生成恶意内容（如 NSFW 图像）的风险，提出 TRCE 框架，一种两阶段概念擦除策略，以实现可靠的恶意概念擦除同时保留模型的正常生成能力。TRCE 的第一阶段通过优化 cross-attention layers 和 [EoT] embedding，将隐含在提示中的恶意语义（如隐喻或对抗性提示）映射到类似但安全的上下文，从而减少模型对恶意语义的影响。第二阶段则利用 contrastive learning 引导扩散模型的早期去噪预测向安全方向发展，避免生成不当内容。实验结果显示，TRCE 在多个恶意概念擦除基准上表现出色，不仅有效擦除恶意概念，还显著提升了模型的原始生成能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07389v1",
      "published_date": "2025-03-10 14:37:53 UTC",
      "updated_date": "2025-03-10 14:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:16:09.054154"
    },
    {
      "arxiv_id": "2503.07384v2",
      "title": "Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Gonzalo Mancera",
        "Daniel DeAlcala",
        "Julian Fierrez",
        "Ruben Tolosana",
        "Aythami Morales"
      ],
      "abstract": "This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies.",
      "tldr_zh": "这篇论文将基于梯度的Membership Inference Test (gMINT) 应用于大型语言模型 (LLMs)，以检测特定文本是否被用于训练，从而解决AI数据隐私问题。研究方法通过梯度分析在七个Transformer-based模型和六个数据集（超过250万句子）上评估文本分类任务，结果显示gMINT的鲁棒性，AUC分数介于85%至99%，取决于数据规模和模型架构。这些发现证明了gMINT作为一种可扩展工具的价值，有助于提升AI/NLP技术的透明度、保护敏感数据并促进道德合规。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07384v2",
      "published_date": "2025-03-10 14:32:56 UTC",
      "updated_date": "2025-03-13 12:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:16:20.973410"
    },
    {
      "arxiv_id": "2503.07364v1",
      "title": "Artificial Utopia: Simulation and Intelligent Agents for a Democratised Future",
      "title_zh": "Artificial Utopia: 模拟与智能代理用于民主化的未来",
      "authors": [
        "Yannick Oswald"
      ],
      "abstract": "Prevailing top-down systems in politics and economics struggle to keep pace\nwith the pressing challenges of the 21st century, such as climate change,\nsocial inequality and conflict. Bottom-up democratisation and participatory\napproaches in politics and economics are increasingly seen as promising\nalternatives to confront and overcome these issues, often with utopian\novertones, as proponents believe they may dramatically reshape political,\nsocial and ecological futures for the better and in contrast to contemporary\nauthoritarian tendencies across various countries. Institutional specifics and\nthe associated collective human behavior or culture remains little understood\nand debated, however. In this article, I propose a novel research agenda\nfocusing on utopian democratisation efforts with formal and computational\nmethods as well as with artificial intelligence - I call this agenda Artificial\nUtopia. Artificial Utopias provide safe testing grounds for new political ideas\nand economic policies in-silico with reduced risk of negative consequences as\ncompared to testing ideas in real-world contexts. An increasing number of\nadvanced simulation and intelligence methods, that aim at representing human\ncognition and collective decision-making in more realistic ways, could benefit\nthis process. This includes agent-based modelling, reinforcement learning,\nlarge language models and more. I clarify what some of these simulation\napproaches can contribute to the study of Artificial Utopias with the help of\ntwo institutional examples: the citizen assembly and the democratic firm.",
      "tldr_zh": "本论文探讨了顶层政治和经济系统在应对气候变化、社会不平等和冲突等21世纪挑战时的不足，并主张底部民主化和参与式方法作为可行的替代方案。作者提出“Artificial Utopia”研究议程，利用正式计算方法和人工智能（如agent-based modelling、reinforcement learning和large language models）在模拟环境中安全测试新政治想法和经济政策，从而减少真实世界测试的风险。通过citizen assembly和democratic firm两个例子，阐明这些方法如何更真实地模拟人类认知和集体决策，为构建更民主的未来提供基础。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07364v1",
      "published_date": "2025-03-10 14:20:58 UTC",
      "updated_date": "2025-03-10 14:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:16:32.613047"
    },
    {
      "arxiv_id": "2503.07351v1",
      "title": "Encoding Argumentation Frameworks to Propositional Logic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Tang",
        "Jiachao Wu",
        "Ning Zhou"
      ],
      "abstract": "The theory of argumentation frameworks ($AF$s) has been a useful tool for\nartificial intelligence. The research of the connection between $AF$s and logic\nis an important branch. This paper generalizes the encoding method by encoding\n$AF$s as logical formulas in different propositional logic systems. It studies\nthe relationship between models of an AF by argumentation semantics, including\nDung's classical semantics and Gabbay's equational semantics, and models of the\nencoded formulas by semantics of propositional logic systems. Firstly, we\nsupplement the proof of the regular encoding function in the case of encoding\n$AF$s to the 2-valued propositional logic system. Then we encode $AF$s to\n3-valued propositional logic systems and fuzzy propositional logic systems and\nexplore the model relationship. This paper enhances the connection between\n$AF$s and propositional logic systems. It also provides a new way to construct\nnew equational semantics by choosing different fuzzy logic operations.",
      "tldr_zh": "该论文推广了一种编码方法，将论证框架 (AFs) 编码为不同命题逻辑系统的逻辑公式，旨在加强 AFs 与逻辑之间的联系。研究者补充了在 2-valued propositional logic 系统下编码 AFs 的常规编码函数证明，并扩展到 3-valued propositional logic 系统和 fuzzy propositional logic 系统，探索了 AFs 的模型（如 Dung's classical semantics 和 Gabbay's equational semantics）与编码公式模型之间的关系。通过这种方法，论文增强了 AFs 与命题逻辑系统的关联，并提供了一种通过选择不同的 fuzzy logic operations 来构建新 equational semantics 的新途径。",
      "categories": [
        "cs.AI",
        "math.LO",
        "Primary 68T27, Secondary 03B70, 03B50, 03B52, 68Q55",
        "I.2.4; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07351v1",
      "published_date": "2025-03-10 14:06:58 UTC",
      "updated_date": "2025-03-10 14:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:16:45.285623"
    },
    {
      "arxiv_id": "2503.07341v1",
      "title": "The Economics of p(doom): Scenarios of Existential Risk and Economic Growth in the Age of Transformative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Growiec",
        "Klaus Prettner"
      ],
      "abstract": "Recent advances in artificial intelligence (AI) have led to a diverse set of\npredictions about its long-term impact on humanity. A central focus is the\npotential emergence of transformative AI (TAI), eventually capable of\noutperforming humans in all economically valuable tasks and fully automating\nlabor. Discussed scenarios range from human extinction after a misaligned TAI\ntakes over (\"AI doom\") to unprecedented economic growth and abundance\n(\"post-scarcity\"). However, the probabilities and implications of these\nscenarios remain highly uncertain. Here, we organize the various scenarios and\nevaluate their associated existential risks and economic outcomes in terms of\naggregate welfare. Our analysis shows that even low-probability catastrophic\noutcomes justify large investments in AI safety and alignment research. We find\nthat the optimizing representative individual would rationally allocate\nsubstantial resources to mitigate extinction risk; in some cases, she would\nprefer not to develop TAI at all. This result highlights that current global\nefforts in AI safety and alignment research are vastly insufficient relative to\nthe scale and urgency of existential risks posed by TAI. Our findings therefore\nunderscore the need for stronger safeguards to balance the potential economic\nbenefits of TAI with the prevention of irreversible harm. Addressing these\nrisks is crucial for steering technological progress toward sustainable human\nprosperity.",
      "tldr_zh": "这篇论文探讨了 transformative AI (TAI) 的经济影响，分析了从人类灭绝（AI doom）到经济繁荣（post-scarcity）的各种场景及其相关的 existential risks 和福利结果。作者通过经济模型评估表明，即使低概率的灾难性风险，也能证明大规模投资于 AI 安全和对齐研究是合理的。研究发现，理性个体可能优先分配资源来缓解灭绝风险，甚至选择放弃 TAI 开发，以平衡潜在经济益处和不可逆转的危害。最后，论文强调当前全球 AI 安全努力远不足以应对这些风险，需要更强的保障措施来推动可持续的人类繁荣。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07341v1",
      "published_date": "2025-03-10 13:53:39 UTC",
      "updated_date": "2025-03-10 13:53:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:16:56.633440"
    },
    {
      "arxiv_id": "2503.07340v1",
      "title": "Research and Design on Intelligent Recognition of Unordered Targets for Robots Based on Reinforcement Learning",
      "title_zh": "基于强化学习的机器人无序目标智能识别的研究与设计",
      "authors": [
        "Yiting Mao",
        "Dajun Tao",
        "Shengyuan Zhang",
        "Tian Qi",
        "Keqin Li"
      ],
      "abstract": "In the field of robot target recognition research driven by artificial\nintelligence (AI), factors such as the disordered distribution of targets, the\ncomplexity of the environment, the massive scale of data, and noise\ninterference have significantly restricted the improvement of target\nrecognition accuracy. Against the backdrop of the continuous iteration and\nupgrading of current AI technologies, to meet the demand for accurate\nrecognition of disordered targets by intelligent robots in complex and\nchangeable scenarios, this study innovatively proposes an AI - based\nintelligent robot disordered target recognition method using reinforcement\nlearning. This method processes the collected target images with the bilateral\nfiltering algorithm, decomposing them into low - illumination images and\nreflection images. Subsequently, it adopts differentiated AI strategies,\ncompressing the illumination images and enhancing the reflection images\nrespectively, and then fuses the two parts of images to generate a new image.\nOn this basis, this study deeply integrates deep learning, a core AI\ntechnology, with the reinforcement learning algorithm. The enhanced target\nimages are input into a deep reinforcement learning model for training,\nultimately enabling the AI - based intelligent robot to efficiently recognize\ndisordered targets. Experimental results show that the proposed method can not\nonly significantly improve the quality of target images but also enable the AI\n- based intelligent robot to complete the recognition task of disordered\ntargets with higher efficiency and accuracy, demonstrating extremely high\napplication value and broad development prospects in the field of AI robots.",
      "tldr_zh": "本研究针对机器人目标识别中面临的无序目标分布、环境复杂性、大规模数据和噪声干扰等问题，提出了一种基于 Reinforcement Learning 的 AI 智能识别方法。该方法首先使用 Bilateral Filtering 算法处理目标图像，将其分解为低照度图像和反射图像，并分别进行压缩和增强后融合生成新图像。随后，将增强图像输入深度强化学习模型进行训练，结合 Deep Learning 与 Reinforcement Learning 算法实现高效识别。实验结果表明，该方法显著提升了图像质量和识别准确性，使机器人能够在复杂场景下更高效地完成无序目标识别任务，具有广阔的应用前景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07340v1",
      "published_date": "2025-03-10 13:53:22 UTC",
      "updated_date": "2025-03-10 13:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:17:08.053918"
    },
    {
      "arxiv_id": "2503.07338v2",
      "title": "Temporal Triplane Transformers as Occupancy World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Xu",
        "Peixi Peng",
        "Guang Tan",
        "Yiqian Chang",
        "Yisen Zhao",
        "Yonghong Tian"
      ],
      "abstract": "World models aim to learn or construct representations of the environment\nthat enable the prediction of future scenes, thereby supporting intelligent\nmotion planning. However, existing models often struggle to produce\nfine-grained predictions and to operate in real time. In this work, we propose\nT$^3$Former, a novel 4D occupancy world model for autonomous driving.\nT$^3$Former begins by pre-training a compact {\\em triplane} representation that\nefficiently encodes 3D occupancy. It then extracts multi-scale temporal motion\nfeatures from historical triplanes and employs an autoregressive approach to\niteratively predict future triplane changes. Finally, these triplane changes\nare combined with previous states to decode future occupancy and ego-motion\ntrajectories. Experimental results show that T$^3$Former achieves 1.44$\\times$\nspeedup (26 FPS), improves mean IoU to 36.09, and reduces mean absolute\nplanning error to 1.0 meters. Demos are available in the supplementary\nmaterial.",
      "tldr_zh": "本论文提出 T³Former，一种新型的 4D 占用世界模型，用于自动驾驶，以解决现有模型在细粒度预测和实时操作上的挑战。模型首先通过预训练的 triplane 表示高效编码 3D 占用，然后从历史 triplanes 中提取多尺度时间运动特征，并采用自回归方法迭代预测未来 triplane 变化。最终，将这些变化与之前状态结合，解码未来的占用和 ego-motion 轨迹。实验结果显示，T³Former 实现了 1.44 倍速度提升（26 FPS），mean IoU 提高到 36.09，并将 mean absolute planning error 降低到 1.0 米。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07338v2",
      "published_date": "2025-03-10 13:50:23 UTC",
      "updated_date": "2025-05-15 08:04:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:17:21.800838"
    },
    {
      "arxiv_id": "2503.07330v1",
      "title": "Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Weicheng He",
        "Changshun Wu",
        "Chih-Hong Cheng",
        "Xiaowei Huang",
        "Saddek Bensalem"
      ],
      "abstract": "Object detection systems must reliably perceive objects of interest without\nbeing overly confident to ensure safe decision-making in dynamic environments.\nFiltering techniques based on out-of-distribution (OoD) detection are commonly\nadded as an extra safeguard to filter hallucinations caused by overconfidence\nin novel objects. Nevertheless, evaluating YOLO-family detectors and their\nfilters under existing OoD benchmarks often leads to unsatisfactory\nperformance. This paper studies the underlying reasons for performance\nbottlenecks and proposes a methodology to improve performance fundamentally.\nOur first contribution is a calibration of all existing evaluation results:\nAlthough images in existing OoD benchmark datasets are claimed not to have\nobjects within in-distribution (ID) classes (i.e., categories defined in the\ntraining dataset), around 13% of objects detected by the object detector are\nactually ID objects. Dually, the ID dataset containing OoD objects can also\nnegatively impact the decision boundary of filters. These ultimately lead to a\nsignificantly imprecise performance estimation. Our second contribution is to\nconsider the task of hallucination reduction as a joint pipeline of detectors\nand filters. By developing a methodology to carefully synthesize an OoD dataset\nthat semantically resembles the objects to be detected, and using the crafted\nOoD dataset in the fine-tuning of YOLO detectors to suppress the objectness\nscore, we achieve a 88% reduction in overall hallucination error with a\ncombined fine-tuned detection and filtering system on the self-driving\nbenchmark BDD-100K. Our code and dataset are available at:\nhttps://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood.",
      "tldr_zh": "该论文重新审视了基于 YOLO 的物体检测模型在 Out-of-Distribution (OoD) 检测中的幻觉问题，指出现有基准评估存在偏差，因为约 13% 的 OoD 数据集对象实际上属于 In-Distribution (ID) 类，导致性能估计不准确。作者提出了一种联合管道方法，通过合成语义上类似于检测对象的 OoD 数据集，并微调 YOLO 检测器以抑制 objectness 得分，从而根本上改善检测和过滤系统的性能。实验结果显示，在自驾车基准 BDD-100K 上，该方法实现了整体幻觉错误减少 88%，为更可靠的物体检测系统提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07330v1",
      "published_date": "2025-03-10 13:42:41 UTC",
      "updated_date": "2025-03-10 13:42:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:17:33.797800"
    },
    {
      "arxiv_id": "2503.07329v1",
      "title": "Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Zhou",
        "Guergana Savova",
        "Lijing Wang"
      ],
      "abstract": "The impact of random seeds in fine-tuning large language models (LLMs) has\nbeen largely overlooked despite its potential influence on model performance.In\nthis study, we systematically evaluate the effects of random seeds on LLMs\nusing the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact\nthrough traditional metrics like accuracy and F1, calculating their mean and\nvariance to quantify performance fluctuations. To capture the micro-level\neffects, we introduce a novel metric, consistency, measuring the stability of\nindividual predictions across runs. Our experiments reveal significant variance\nat both macro and micro levels, underscoring the need for careful consideration\nof random seeds in fine-tuning and evaluation.",
      "tldr_zh": "本研究评估了随机种子（random seeds）对微调大型语言模型（LLMs）的影响，使用 GLUE 和 SuperGLUE 基准测试进行系统分析。\n在宏观层面，他们计算了性能指标（如准确率和 F1）的均值和方差，以量化波动；在微观层面，引入了新指标“consistency”来衡量单个预测的稳定性。\n实验结果显示，随机种子导致宏观和微观层面均有显著方差，强调在 LLMs 的微调和评估中需仔细考虑此因素。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 5 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07329v1",
      "published_date": "2025-03-10 13:42:04 UTC",
      "updated_date": "2025-03-10 13:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:17:44.402224"
    },
    {
      "arxiv_id": "2503.07326v1",
      "title": "AI Biases as Asymmetries: A Review to Guide Practice",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriella Waters",
        "Phillip Honenberger"
      ],
      "abstract": "The understanding of bias in AI is currently undergoing a revolution.\nInitially understood as errors or flaws, biases are increasingly recognized as\nintegral to AI systems and sometimes preferable to less biased alternatives. In\nthis paper, we review the reasons for this changed understanding and provide\nnew guidance on two questions: First, how should we think about and measure\nbiases in AI systems, consistent with the new understanding? Second, what kinds\nof bias in an AI system should we accept or even amplify, and what kinds should\nwe minimize or eliminate, and why? The key to answering both questions, we\nargue, is to understand biases as \"violations of a symmetry standard\"\n(following Kelly). We distinguish three main types of asymmetry in AI\nsystems-error biases, inequality biases, and process biases-and highlight\nplaces in the pipeline of AI development and application where bias of each\ntype is likely to be good, bad, or inevitable.",
      "tldr_zh": "本论文审视了 AI 中的 biases（偏见），从最初被视为错误或缺陷，演变为被认可为 AI 系统不可或缺的部分，甚至在某些情况下优于无偏见替代方案。作者基于“violations of a symmetry standard”（违反对称性标准）的概念，区分了三种主要不对称性：error biases（错误偏见）、inequality biases（不平等偏见）和 process biases（过程偏见），并分析了这些 biases 在 AI 开发和应用管道中的利弊。论文提供新指导，帮助决定哪些 biases 应接受或放大，哪些应最小化或消除，从而指导 AI 实践。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07326v1",
      "published_date": "2025-03-10 13:40:28 UTC",
      "updated_date": "2025-03-10 13:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:17:57.111992"
    },
    {
      "arxiv_id": "2503.07323v1",
      "title": "Dynamic Path Navigation for Motion Agents with LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yubo Zhao",
        "Qi Wu",
        "Yifan Wang",
        "Yu-Wing Tai",
        "Chi-Keung Tang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong generalizable reasoning\nand planning capabilities. However, their efficacies in spatial path planning\nand obstacle-free trajectory generation remain underexplored. Leveraging LLMs\nfor navigation holds significant potential, given LLMs' ability to handle\nunseen scenarios, support user-agent interactions, and provide global control\nacross complex systems, making them well-suited for agentic planning and\nhumanoid motion generation. As one of the first studies in this domain, we\nexplore the zero-shot navigation and path generation capabilities of LLMs by\nconstructing a dataset and proposing an evaluation protocol. Specifically, we\nrepresent paths using anchor points connected by straight lines, enabling\nmovement in various directions. This approach offers greater flexibility and\npracticality compared to previous methods while remaining simple and intuitive\nfor LLMs. We demonstrate that, when tasks are well-structured in this manner,\nmodern LLMs exhibit substantial planning proficiency in avoiding obstacles\nwhile autonomously refining navigation with the generated motion to reach the\ntarget. Further, this spatial reasoning ability of a single LLM motion agent\ninteracting in a static environment can be seamlessly generalized in\nmulti-motion agents coordination in dynamic environments. Unlike traditional\napproaches that rely on single-step planning or local policies, our\ntraining-free LLM-based method enables global, dynamic, closed-loop planning,\nand autonomously resolving collision issues.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在动态路径导航中的应用，通过构建数据集和提出评估协议，评估 LLMs 的零样本导航和路径生成能力。研究采用锚点连接直线的方法表示路径，提供灵活性和实用性，LLMs 能够在结构化任务中自主避开障碍并优化运动轨迹。结果表明，这种无训练方法支持全局闭环规划，并在多代理动态环境中实现协调，超越传统单步或局部策略的局限性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07323v1",
      "published_date": "2025-03-10 13:39:09 UTC",
      "updated_date": "2025-03-10 13:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:18:08.968540"
    },
    {
      "arxiv_id": "2503.07320v1",
      "title": "Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents",
      "title_zh": "实验探索：调查人类与大型语言模型代理之间的合作互动行为",
      "authors": [
        "Guanxuan Jiang",
        "Yuyang Wang",
        "Pan Hui"
      ],
      "abstract": "With the rise of large language models (LLMs), AI agents as autonomous\ndecision-makers present significant opportunities and challenges for human-AI\ncooperation. While many studies have explored human cooperation with AI as\ntools, the role of LLM-augmented autonomous agents in competitive-cooperative\ninteractions remains under-examined. This study investigates human cooperative\nbehavior by engaging 30 participants who interacted with LLM agents exhibiting\ndifferent characteristics (purported human, purported rule-based AI agent, and\nLLM agent) in repeated Prisoner's Dilemma games. Findings show significant\ndifferences in cooperative behavior based on the agents' purported\ncharacteristics and the interaction effect of participants' genders and\npurported characteristics. We also analyzed human response patterns, including\ngame completion time, proactive favorable behavior, and acceptance of repair\nefforts. These insights offer a new perspective on human interactions with LLM\nagents in competitive cooperation contexts, such as virtual avatars or future\nphysical entities. The study underscores the importance of understanding human\nbiases toward AI agents and how observed behaviors can influence future\nhuman-AI cooperation dynamics.",
      "tldr_zh": "本研究通过实验调查了人类与大型语言模型(LLMs)代理在竞争-合作环境中的互动行为，涉及30名参与者与不同特征的代理（如声称是人类、基于规则的AI或LLMs代理）玩重复囚徒困境游戏。结果显示，代理的声称特征和参与者性别会显著影响合作行为，并揭示了人类的响应模式，包括游戏完成时间、主动有利行为以及对修复努力的接受。总体而言，该研究强调了理解人类对AI代理偏见的重要性，为未来人-AI合作动态提供新视角。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07320v1",
      "published_date": "2025-03-10 13:37:36 UTC",
      "updated_date": "2025-03-10 13:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:18:20.793478"
    },
    {
      "arxiv_id": "2503.07319v1",
      "title": "Human Machine Co-Adaptation Model and Its Convergence Analysis",
      "title_zh": "人机共同适应模型及其收敛性分析",
      "authors": [
        "Steven W. Su",
        "Yaqi Li",
        "Kairui Guo",
        "Rob Duffield"
      ],
      "abstract": "The key to robot-assisted rehabilitation lies in the design of the\nhuman-machine interface, which must accommodate the needs of both patients and\nmachines. Current interface designs primarily focus on machine control\nalgorithms, often requiring patients to spend considerable time adapting. In\nthis paper, we introduce a novel approach based on the Cooperative Adaptive\nMarkov Decision Process (CAMDPs) model to address the fundamental aspects of\nthe interactive learning process, offering theoretical insights and practical\nguidance. We establish sufficient conditions for the convergence of CAMDPs and\nensure the uniqueness of Nash equilibrium points. Leveraging these conditions,\nwe guarantee the system's convergence to a unique Nash equilibrium point.\nFurthermore, we explore scenarios with multiple Nash equilibrium points,\ndevising strategies to adjust both Value Evaluation and Policy Improvement\nalgorithms to enhance the likelihood of converging to the global minimal Nash\nequilibrium point. Through numerical experiments, we illustrate the\neffectiveness of the proposed conditions and algorithms, demonstrating their\napplicability and robustness in practical settings. The proposed conditions for\nconvergence and the identification of a unique optimal Nash equilibrium\ncontribute to the development of more effective adaptive systems for human\nusers in robot-assisted rehabilitation.",
      "tldr_zh": "本研究提出了一种基于 Cooperative Adaptive Markov Decision Process (CAMDPs) 的新方法，用于优化机器人辅助康复中的人机界面设计，旨在减少患者适应机器的时间消耗并提升交互学习效率。论文建立了 CAMDPs 的收敛充分条件，确保系统收敛到唯一的 Nash equilibrium 点，并为多 Nash equilibrium 点场景提供了调整 Value Evaluation 和 Policy Improvement 算法的策略，以增加收敛到全局最优点的可能性。通过数值实验验证了这些条件的有效性和鲁棒性，为开发更有效的适应性人机系统提供了理论指导和实践应用。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07319v1",
      "published_date": "2025-03-10 13:36:36 UTC",
      "updated_date": "2025-03-10 13:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:18:33.277276"
    },
    {
      "arxiv_id": "2503.07317v1",
      "title": "Self-Corrective Task Planning by Inverse Prompting with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiho Lee",
        "Hayun Lee",
        "Jonghyeon Kim",
        "Kyungjae Lee",
        "Eunwoo Kim"
      ],
      "abstract": "In robot task planning, large language models (LLMs) have shown significant\npromise in generating complex and long-horizon action sequences. However, it is\nobserved that LLMs often produce responses that sound plausible but are not\naccurate. To address these problems, existing methods typically employ\npredefined error sets or external knowledge sources, requiring human efforts\nand computation resources. Recently, self-correction approaches have emerged,\nwhere LLM generates and refines plans, identifying errors by itself. Despite\ntheir effectiveness, they are more prone to failures in correction due to\ninsufficient reasoning. In this paper, we introduce InversePrompt, a novel\nself-corrective task planning approach that leverages inverse prompting to\nenhance interpretability. Our method incorporates reasoning steps to provide\nclear, interpretable feedback. It generates inverse actions corresponding to\nthe initially generated actions and verifies whether these inverse actions can\nrestore the system to its original state, explicitly validating the logical\ncoherence of the generated plans. The results on benchmark datasets show an\naverage 16.3% higher success rate over existing LLM-based task planning\nmethods. Our approach offers clearer justifications for feedback in real-world\nenvironments, resulting in more successful task completion than existing\nself-correction approaches across various scenarios.",
      "tldr_zh": "这篇论文提出了 InversePrompt，一种基于 Large Language Models (LLMs) 的自校正任务规划方法，通过逆向提示（inverse prompting）机制来提升计划的准确性和可解释性。该方法生成初始动作的逆向动作，并验证这些动作是否能将系统恢复到原始状态，从而明确检查计划的逻辑一致性。实验结果显示，在基准数据集上，InversePrompt 的成功率比现有 LLM 基于任务规划方法平均高 16.3%，并在真实环境中提供更清晰的反馈理由，实现更可靠的任务完成。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures, IEEE International Conference on Robotics and\n  Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07317v1",
      "published_date": "2025-03-10 13:35:51 UTC",
      "updated_date": "2025-03-10 13:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:18:44.715010"
    },
    {
      "arxiv_id": "2503.07315v1",
      "title": "Group-robust Sample Reweighting for Subpopulation Shifts via Influence Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Qiao",
        "Zhaoxuan Wu",
        "Jingtan Wang",
        "Pang Wei Koh",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Machine learning models often have uneven performance among subpopulations\n(a.k.a., groups) in the data distributions. This poses a significant challenge\nfor the models to generalize when the proportions of the groups shift during\ndeployment. To improve robustness to such shifts, existing approaches have\ndeveloped strategies that train models or perform hyperparameter tuning using\nthe group-labeled data to minimize the worst-case loss over groups. However, a\nnon-trivial amount of high-quality labels is often required to obtain\nnoticeable improvements. Given the costliness of the labels, we propose to\nadopt a different paradigm to enhance group label efficiency: utilizing the\ngroup-labeled data as a target set to optimize the weights of other\ngroup-unlabeled data. We introduce Group-robust Sample Reweighting (GSR), a\ntwo-stage approach that first learns the representations from group-unlabeled\ndata, and then tinkers the model by iteratively retraining its last layer on\nthe reweighted data using influence functions. Our GSR is theoretically sound,\npractically lightweight, and effective in improving the robustness to\nsubpopulation shifts. In particular, GSR outperforms the previous\nstate-of-the-art approaches that require the same amount or even more group\nlabels.",
      "tldr_zh": "机器学习模型在子群体（subpopulations）上的性能往往不均衡，导致在部署时子群体比例变化时泛化能力不足。针对此问题，本文提出 Group-robust Sample Reweighting (GSR)，一种两阶段方法：首先从无组标签数据中学习表示，然后利用 Influence Functions 重新加权数据并迭代重新训练模型的最后一层，从而提升组标签效率。实验结果表明，GSR 在改善对 Subpopulation Shifts 的鲁棒性方面优于现有方法，即使使用更少的组标签。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 13th International Conference on Learning\n  Representations (ICLR 2025). Code is available at\n  https://github.com/qiaoruiyt/GSR",
      "pdf_url": "http://arxiv.org/pdf/2503.07315v1",
      "published_date": "2025-03-10 13:34:18 UTC",
      "updated_date": "2025-03-10 13:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:18:57.164139"
    },
    {
      "arxiv_id": "2503.07686v1",
      "title": "Adaptive routing protocols for determining optimal paths in AI multi-agent systems: a priority- and learning-enhanced approach",
      "title_zh": "翻译失败",
      "authors": [
        "Theodor Panayotov",
        "Ivo Emanuilov"
      ],
      "abstract": "As distributed artificial intelligence (AI) and multi-agent architectures\ngrow increasingly complex, the need for adaptive, context-aware routing becomes\nparamount. This paper introduces an enhanced, adaptive routing algorithm\ntailored for AI multi-agent networks, integrating priority-based cost functions\nand dynamic learning mechanisms. Building on an extended Dijkstra-based\nframework, we incorporate multi-faceted parameters such as task complexity,\nuser request priority, agent capabilities, bandwidth, latency, load, model\nsophistication, and reliability. We further propose dynamically adaptive\nweighting factors, tuned via reinforcement learning (RL), to continuously\nevolve routing policies based on observed network performance. Additionally,\nheuristic filtering and hierarchical routing structures improve scalability and\nresponsiveness. Our approach yields context-sensitive, load-aware, and\npriority-focused routing decisions that not only reduce latency for critical\ntasks but also optimize overall resource utilization, ultimately enhancing the\nrobustness, flexibility, and efficiency of multi-agent systems.",
      "tldr_zh": "这篇论文提出了一种增强的自适应路由算法，用于 AI 多智能体系统中的最优路径确定，整合了优先级-based 成本函数和动态学习机制。基于扩展的 Dijkstra-based 框架，该算法考虑多种参数如任务复杂度、用户请求优先级、智能体能力、带宽、延迟和可靠性，并利用强化学习 (RL) 动态调整权重因素以优化路由策略。实验结果显示，该方法实现了上下文敏感、负载感知的路由决策，显著减少关键任务的延迟、提升资源利用率，并提高了多智能体系统的稳健性、灵活性和整体效率。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07686v1",
      "published_date": "2025-03-10 13:16:54 UTC",
      "updated_date": "2025-03-10 13:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:19:08.952829"
    },
    {
      "arxiv_id": "2503.07294v1",
      "title": "Distilling Knowledge into Quantum Vision Transformers for Biomedical Image Classification",
      "title_zh": "将知识蒸馏注入量子视觉Transformer用于生物医学图像分类",
      "authors": [
        "Thomas Boucher",
        "Evangelos B. Mazomenos"
      ],
      "abstract": "Quantum vision transformers (QViTs) build on vision transformers (ViTs) by\nreplacing linear layers within the self-attention mechanism with parameterised\nquantum neural networks (QNNs), harnessing quantum mechanical properties to\nimprove feature representation. This hybrid approach aims to achieve superior\nperformance, with significantly reduced model complexity as a result of the\nenriched feature representation, requiring fewer parameters. This paper\nproposes a novel QViT model for biomedical image classification and\ninvestigates its performance against comparable ViTs across eight diverse\ndatasets, encompassing various modalities and classification tasks. We assess\nmodels trained from scratch and those pre-trained using knowledge distillation\n(KD) from high-quality teacher models. Our findings demonstrate that QViTs\noutperform comparable ViTs with average ROC AUC (0.863 vs 0.846) and accuracy\n(0.710 vs 0.687) when trained from scratch, and even compete with\nstate-of-the-art classical models in multiple tasks, whilst being significantly\nmore efficient (89% reduction in GFLOPs and 99.99% in parameter number).\nAdditionally, we find that QViTs and ViTs respond equally well to KD, with QViT\npre-training performance scaling with model complexity. This is the first\ninvestigation into the efficacy of deploying QViTs with KD for computer-aided\ndiagnosis. Our results highlight the enormous potential of quantum machine\nlearning (QML) in biomedical image analysis.",
      "tldr_zh": "该论文提出了一种新型 Quantum Vision Transformers (QViTs) 模型，用于生物医学图像分类，通过将 Vision Transformers (ViTs) 中的线性层替换为参数化 Quantum Neural Networks (QNNs)，利用量子力学特性提升特征表示并显著减少模型参数。\n研究者评估了 QViTs 与可比 ViTs 在八个多样数据集上的性能，包括从零训练和使用 Knowledge Distillation (KD) 从高质量教师模型预训练的场景。\n结果显示，QViTs 在从零训练时优于 ViTs，平均 ROC AUC (0.863 vs 0.846) 和准确率 (0.710 vs 0.687)，并在多个任务中与最先进经典模型竞争，同时实现高效（GFLOPs 减少 89%，参数减少 99.99%）。\n此外，QViTs 和 ViTs 对 KD 预训练响应同样良好，QViTs 的性能随模型复杂度提升，这首次证明了 Quantum Machine Learning (QML) 在计算机辅助诊断中的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted for MICCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07294v1",
      "published_date": "2025-03-10 13:16:48 UTC",
      "updated_date": "2025-03-10 13:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:19:23.366173"
    },
    {
      "arxiv_id": "2503.07279v1",
      "title": "VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in Human-AI Communication",
      "title_zh": "VizTrust: 一种用于捕获人-人工智能通信中用户信任动态的视觉分析工具",
      "authors": [
        "Xin Wang",
        "Stephanie Tulk Jesso",
        "Sadamori Kojaku",
        "David M Neyens",
        "Min Sun Kim"
      ],
      "abstract": "Trust plays a fundamental role in shaping the willingness of users to engage\nand collaborate with artificial intelligence (AI) systems. Yet, measuring user\ntrust remains challenging due to its complex and dynamic nature. While\ntraditional survey methods provide trust levels for long conversations, they\nfail to capture its dynamic evolution during ongoing interactions. Here, we\npresent VizTrust, which addresses this challenge by introducing a real-time\nvisual analytics tool that leverages a multi-agent collaboration system to\ncapture and analyze user trust dynamics in human-agent communication. Built on\nestablished human-computer trust scales-competence, integrity, benevolence, and\npredictability-, VizTrust enables stakeholders to observe trust formation as it\nhappens, identify patterns in trust development, and pinpoint specific\ninteraction elements that influence trust. Our tool offers actionable insights\ninto human-agent trust formation and evolution in real time through a\ndashboard, supporting the design of adaptive conversational agents that\nresponds effectively to user trust signals.",
      "tldr_zh": "本研究探讨了用户信任在人-人工智能（AI）互动中的重要性，并解决了传统调查方法无法捕捉信任动态变化的挑战。论文引入了VizTrust，一款基于多智能体协作系统的实时视觉分析工具，利用competence、integrity、benevolence和predictability等人类-计算机信任规模来监测信任的实时形成、发展模式及影响因素。通过仪表板提供可操作洞见，VizTrust支持设计自适应对话代理，能够有效响应用户信任信号，从而提升AI系统的可信度和互动质量。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by ACM CHI conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07279v1",
      "published_date": "2025-03-10 13:00:41 UTC",
      "updated_date": "2025-03-10 13:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:19:32.034494"
    },
    {
      "arxiv_id": "2503.07275v1",
      "title": "Automatic Curriculum Design for Zero-Shot Human-AI Coordination",
      "title_zh": "翻译失败",
      "authors": [
        "Won-Sang You",
        "Tae-Gwan Ha",
        "Seo-Young Lee",
        "Kyung-Joong Kim"
      ],
      "abstract": "Zero-shot human-AI coordination is the training of an ego-agent to coordinate\nwith humans without using human data. Most studies on zero-shot human-AI\ncoordination have focused on enhancing the ego-agent's coordination ability in\na given environment without considering the issue of generalization to unseen\nenvironments. Real-world applications of zero-shot human-AI coordination should\nconsider unpredictable environmental changes and the varying coordination\nability of co-players depending on the environment. Previously, the multi-agent\nUED (Unsupervised Environment Design) approach has investigated these\nchallenges by jointly considering environmental changes and co-player policy in\ncompetitive two-player AI-AI scenarios. In this paper, our study extends the\nmulti-agent UED approach to a zero-shot human-AI coordination. We propose a\nutility function and co-player sampling for a zero-shot human-AI coordination\nsetting that helps train the ego-agent to coordinate with humans more\neffectively than the previous multi-agent UED approach. The zero-shot human-AI\ncoordination performance was evaluated in the Overcooked-AI environment, using\nhuman proxy agents and real humans. Our method outperforms other baseline\nmodels and achieves a high human-AI coordination performance in unseen\nenvironments.",
      "tldr_zh": "本论文针对零-shot human-AI coordination问题，提出了一种自动课程设计方法，该方法扩展了multi-agent UED（Unsupervised Environment Design）框架，以训练ego-agent在不使用人类数据的情况下实现更强的泛化能力和协调性。研究引入了新的utility function和co-player sampling机制，帮助ego-agent更好地适应环境变化和不同合作者策略。在Overcooked-AI环境中进行的实验表明，该方法超过了基线模型，并在未见环境中实现了高水平的人机协调性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07275v1",
      "published_date": "2025-03-10 12:55:31 UTC",
      "updated_date": "2025-03-10 12:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:19:43.762341"
    },
    {
      "arxiv_id": "2503.07272v1",
      "title": "Federated Learning in NTNs: Design, Architecture and Challenges",
      "title_zh": "NTNs 中的联邦学习：设计、架构和挑战",
      "authors": [
        "Amin Farajzadeh",
        "Animesh Yadav",
        "Halim Yanikomeroglu"
      ],
      "abstract": "Non-terrestrial networks (NTNs) are emerging as a core component of future 6G\ncommunication systems, providing global connectivity and supporting\ndata-intensive applications. In this paper, we propose a distributed\nhierarchical federated learning (HFL) framework within the NTN architecture,\nleveraging a high altitude platform station (HAPS) constellation as\nintermediate distributed FL servers. Our framework integrates both low-Earth\norbit (LEO) satellites and ground clients in the FL training process while\nutilizing geostationary orbit (GEO) and medium-Earth orbit (MEO) satellites as\nrelays to exchange FL global models across other HAPS constellations worldwide,\nenabling seamless, global-scale learning. The proposed framework offers several\nkey benefits: (i) enhanced privacy through the decentralization of the FL\nmechanism by leveraging the HAPS constellation, (ii) improved model accuracy\nand reduced training loss while balancing latency, (iii) increased scalability\nof FL systems through ubiquitous connectivity by utilizing MEO and GEO\nsatellites, and (iv) the ability to use FL data, such as resource utilization\nmetrics, to further optimize the NTN architecture from a network management\nperspective. A numerical study demonstrates the proposed framework's\neffectiveness, with improved model accuracy, reduced training loss, and\nefficient latency management. The article also includes a brief review of FL in\nNTNs and highlights key challenges and future research directions.",
      "tldr_zh": "该论文探讨了在非陆地网络（NTNs）中应用联邦学习（Federated Learning）的设计、架构和挑战，提出了一种分布式分层联邦学习（HFL）框架，利用高空平台站（HAPS）星座作为中间分布式 FL 服务器。框架整合低地球轨道（LEO）卫星和地面客户端进行训练，并通过地球同步轨道（GEO）和中地球轨道（MEO）卫星作为中继，实现全球规模模型交换，从而提升隐私保护、模型准确性和训练效率，同时平衡延迟和可扩展性。数值研究证明，该框架显著提高了模型准确率、降低了训练损失，并优化了 NTN 架构管理；论文还回顾了 NTNs 中的 FL 应用，并指出了关键挑战和未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IEEE Communications Magazine",
      "pdf_url": "http://arxiv.org/pdf/2503.07272v1",
      "published_date": "2025-03-10 12:53:45 UTC",
      "updated_date": "2025-03-10 12:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:19:56.354741"
    },
    {
      "arxiv_id": "2503.07265v1",
      "title": "WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation",
      "title_zh": "WISE：基于世界知识的",
      "authors": [
        "Yuwei Niu",
        "Munan Ning",
        "Mengren Zheng",
        "Bin Lin",
        "Peng Jin",
        "Jiaqi Liao",
        "Kunpeng Ning",
        "Bin Zhu",
        "Li Yuan"
      ],
      "abstract": "Text-to-Image (T2I) models are capable of generating high-quality artistic\ncreations and visual content. However, existing research and evaluation\nstandards predominantly focus on image realism and shallow text-image\nalignment, lacking a comprehensive assessment of complex semantic understanding\nand world knowledge integration in text to image generation. To address this\nchallenge, we propose $\\textbf{WISE}$, the first benchmark specifically\ndesigned for $\\textbf{W}$orld Knowledge-$\\textbf{I}$nformed $\\textbf{S}$emantic\n$\\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by\nchallenging models with 1000 meticulously crafted prompts across 25 sub-domains\nin cultural common sense, spatio-temporal reasoning, and natural science. To\novercome the limitations of traditional CLIP metric, we introduce\n$\\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image\nalignment. Through comprehensive testing of 20 models (10 dedicated T2I models\nand 10 unified multimodal models) using 1,000 structured prompts spanning 25\nsubdomains, our findings reveal significant limitations in their ability to\neffectively integrate and apply world knowledge during image generation,\nhighlighting critical pathways for enhancing knowledge incorporation and\napplication in next-generation T2I models. Code and data are available at\nhttps://github.com/PKU-YuanGroup/WISE.",
      "tldr_zh": "本论文提出WISE基准，这是首个专注于世界知识-信息语义评估的基准，用于评估Text-to-Image (T2I) 模型在生成图像时的复杂语义理解和世界知识整合能力。WISE通过1000个精心设计的提示，覆盖25个子领域（如文化常识、时空推理和自然科学），并引入WiScore这一新型量化指标来超越传统CLIP指标，评估知识-图像对齐。实验测试了20个模型（包括10个专用T2I模型和10个统一多模态模型），结果显示这些模型在有效整合世界知识方面存在显著局限性，为下一代T2I模型的知识增强和应用提供了关键改进方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code, data and leaderboard: https://github.com/PKU-YuanGroup/WISE",
      "pdf_url": "http://arxiv.org/pdf/2503.07265v1",
      "published_date": "2025-03-10 12:47:53 UTC",
      "updated_date": "2025-03-10 12:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:20:08.869767"
    },
    {
      "arxiv_id": "2503.07685v1",
      "title": "Ways of Seeing, and Selling, AI Art",
      "title_zh": "翻译失败",
      "authors": [
        "Imke van Heerden"
      ],
      "abstract": "In early 2025, Augmented Intelligence - Christie's first AI art auction -\ndrew criticism for showcasing a controversial genre. Amid wider legal\nuncertainty, artists voiced concerns over data mining practices, notably with\nrespect to copyright. The backlash could be viewed as a microcosm of AI's\ncontested position in the creative economy. Touching on the auction's\npresentation, reception, and results, this paper explores how, among social\ndissonance, machine learning finds its place in the artworld. Foregrounding\nresponsible innovation, the paper provides a balanced perspective that\nchampions creators' rights and brings nuance to this polarised debate. With a\nfocus on exhibition design, it centres framing, which refers to the way a piece\nis presented to influence consumer perception. Context plays a central role in\nshaping our understanding of how good, valuable, and even ethical an artwork\nis. In this regard, Augmented Intelligence situates AI art within a\nsurprisingly traditional framework, leveraging hallmarks of \"high art\" to\nestablish the genre's cultural credibility. Generative AI has a clear economic\ndimension, converging questions of artistic merit with those of monetary worth.\nScholarship on ways of seeing, or framing, could substantively inform the\ninterpretation and evaluation of creative outputs, including assessments of\ntheir aesthetic and commercial value.",
      "tldr_zh": "这篇论文探讨了2025年佳士得的首次AI艺术拍卖“Augmented Intelligence”，该事件因版权争议和数据挖掘问题引发艺术家批评，反映了AI在创意经济中的争议性地位。论文聚焦于展览设计和framing（框架化呈现），分析如何通过传统“high art”元素提升AI art的文化可信度，并平衡艺术审美与商业价值评估。最终，它倡导responsible innovation，支持创作者权利，为这一两极化辩论注入 nuance。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07685v1",
      "published_date": "2025-03-10 12:44:11 UTC",
      "updated_date": "2025-03-10 12:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:20:20.450093"
    },
    {
      "arxiv_id": "2503.07259v1",
      "title": "COMODO: Cross-Modal Video-to-IMU Distillation for Efficient Egocentric Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Baiyu Chen",
        "Wilson Wongso",
        "Zechen Li",
        "Yonchanok Khaokaew",
        "Hao Xue",
        "Flora Salim"
      ],
      "abstract": "Egocentric video-based models capture rich semantic information and have\ndemonstrated strong performance in human activity recognition (HAR). However,\ntheir high power consumption, privacy concerns, and dependence on lighting\nconditions limit their feasibility for continuous on-device recognition. In\ncontrast, inertial measurement unit (IMU) sensors offer an energy-efficient and\nprivacy-preserving alternative, yet they suffer from limited large-scale\nannotated datasets, leading to weaker generalization in downstream tasks. To\nbridge this gap, we propose COMODO, a cross-modal self-supervised distillation\nframework that transfers rich semantic knowledge from the video modality to the\nIMU modality without requiring labeled annotations. COMODO leverages a\npretrained and frozen video encoder to construct a dynamic instance queue,\naligning the feature distributions of video and IMU embeddings. By distilling\nknowledge from video representations, our approach enables the IMU encoder to\ninherit rich semantic information from video while preserving its efficiency\nfor real-world applications. Experiments on multiple egocentric HAR datasets\ndemonstrate that COMODO consistently improves downstream classification\nperformance, achieving results comparable to or exceeding fully supervised\nfine-tuned models. Moreover, COMODO exhibits strong cross-dataset\ngeneralization. Benefiting from its simplicity, our method is also generally\napplicable to various video and time-series pre-trained models, offering the\npotential to leverage more powerful teacher and student foundation models in\nfuture research. The code is available at https://github.com/Breezelled/COMODO .",
      "tldr_zh": "该研究提出COMODO框架，通过跨模态自监督蒸馏方法，将视频模态的丰富语义知识转移到IMU传感器模态，用于高效的自我中心人类活动识别（HAR），从而解决IMU模型数据标注不足和泛化能力弱的问题。COMODO利用预训练的视频编码器构建动态实例队列，对齐视频和IMU嵌入的特征分布，实现无标注知识转移，同时保持IMU的能效和隐私优势。在多个自我中心HAR数据集上的实验表明，COMODO显著提升下游分类性能，与完全监督模型相当或更优，并展示出强的跨数据集泛化潜力，可应用于各种视频和时序预训练模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07259v1",
      "published_date": "2025-03-10 12:43:51 UTC",
      "updated_date": "2025-03-10 12:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:20:32.597388"
    },
    {
      "arxiv_id": "2503.08716v1",
      "title": "AuthorMist: Evading AI Text Detectors with Reinforcement Learning",
      "title_zh": "AuthorMist: 通过强化学习规避 AI 文本检测器",
      "authors": [
        "Isaac David",
        "Arthur Gervais"
      ],
      "abstract": "In the age of powerful AI-generated text, automatic detectors have emerged to\nidentify machine-written content. This poses a threat to author privacy and\nfreedom, as text authored with AI assistance may be unfairly flagged. We\npropose AuthorMist, a novel reinforcement learning-based system to transform\nAI-generated text into human-like writing. AuthorMist leverages a\n3-billion-parameter language model as a backbone, fine-tuned with Group\nRelative Policy Optimization (GPRO) to paraphrase text in a way that evades AI\ndetectors.\n  Our framework establishes a generic approach where external detector APIs\n(GPTZero, WinstonAI, Originality.ai, etc.) serve as reward functions within the\nreinforcement learning loop, enabling the model to systematically learn outputs\nthat these detectors are less likely to classify as AI-generated. This\nAPI-as-reward methodology can be applied broadly to optimize text against any\ndetector with an accessible interface. Experiments on multiple datasets and\ndetectors demonstrate that AuthorMist effectively reduces the detectability of\nAI-generated text while preserving the original meaning. Our evaluation shows\nattack success rates ranging from 78.6% to 96.2% against individual detectors,\nsignificantly outperforming baseline paraphrasing methods. AuthorMist maintains\nhigh semantic similarity (above 0.94) with the original text while successfully\nevading detection. These results highlight limitations in current AI text\ndetection technologies and raise questions about the sustainability of the\ndetection-evasion arms race.",
      "tldr_zh": "本研究提出AuthorMist，一种基于Reinforcement Learning的系统，用于将AI生成的文本转化为更像人类写的形式，从而逃避AI文本检测器。该系统以一个3亿参数的语言模型为基础，通过Group Relative Policy Optimization (GPRO)进行微调，并利用外部检测器API（如GPTZero、WinstonAI等）作为奖励函数，帮助模型学习生成不易被识别的输出。实验结果显示，AuthorMist在多个数据集上实现了78.6%至96.2%的攻击成功率，同时保持了原文本的高语义相似度（超过0.94），显著优于基线方法。这些发现突显了当前AI文本检测技术的局限性，并引发了对检测与逃避竞赛可持续性的担忧。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08716v1",
      "published_date": "2025-03-10 12:41:05 UTC",
      "updated_date": "2025-03-10 12:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:20:44.552030"
    },
    {
      "arxiv_id": "2503.07248v1",
      "title": "AI-Driven Automated Tool for Abdominal CT Body Composition Analysis in Gastrointestinal Cancer Management",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Nan",
        "Meng He",
        "Zifan Chen",
        "Bin Dong",
        "Lei Tang",
        "Li Zhang"
      ],
      "abstract": "The incidence of gastrointestinal cancers remains significantly high,\nparticularly in China, emphasizing the importance of accurate prognostic\nassessments and effective treatment strategies. Research shows a strong\ncorrelation between abdominal muscle and fat tissue composition and patient\noutcomes. However, existing manual methods for analyzing abdominal tissue\ncomposition are time-consuming and costly, limiting clinical research\nscalability. To address these challenges, we developed an AI-driven tool for\nautomated analysis of abdominal CT scans to effectively identify and segment\nmuscle, subcutaneous fat, and visceral fat. Our tool integrates a multi-view\nlocalization model and a high-precision 2D nnUNet-based segmentation model,\ndemonstrating a localization accuracy of 90% and a Dice Score Coefficient of\n0.967 for segmentation. Furthermore, it features an interactive interface that\nallows clinicians to refine the segmentation results, ensuring high-quality\noutcomes effectively. Our tool offers a standardized method for effectively\nextracting critical abdominal tissues, potentially enhancing the management and\ntreatment for gastrointestinal cancers. The code is available at\nhttps://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git}{https://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git.",
      "tldr_zh": "这篇论文开发了一个AI-driven工具，用于自动分析腹部CT扫描中的体组成，以提升胃肠道癌症的管理和预后评估。工具整合了多视图定位模型和基于2D nnUNet的高精度分割模型，实现了90%的定位准确率和0.967的Dice Score Coefficient，并提供交互式界面让临床医生精炼结果。该工具标准化了肌肉、皮下脂肪和内脏脂肪的提取过程，有望改善治疗策略，并已在开源代码中提供（https://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git）。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07248v1",
      "published_date": "2025-03-10 12:32:44 UTC",
      "updated_date": "2025-03-10 12:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:20:58.941001"
    },
    {
      "arxiv_id": "2503.07237v1",
      "title": "LLM-C3MOD: A Human-LLM Collaborative System for Cross-Cultural Hate Speech Moderation",
      "title_zh": "LLM-C3MOD：一种人类-LLM 协作系统，用于跨文化仇恨言论审核",
      "authors": [
        "Junyeong Park",
        "Seogyeong Jeong",
        "Seyoung Song",
        "Yohan Lee",
        "Alice Oh"
      ],
      "abstract": "Content moderation is a global challenge, yet major tech platforms prioritize\nhigh-resource languages, leaving low-resource languages with scarce native\nmoderators. Since effective moderation depends on understanding contextual\ncues, this imbalance increases the risk of improper moderation due to\nnon-native moderators' limited cultural understanding. Through a user study, we\nidentify that non-native moderators struggle with interpreting\nculturally-specific knowledge, sentiment, and internet culture in the hate\nspeech moderation. To assist them, we present LLM-C3MOD, a human-LLM\ncollaborative pipeline with three steps: (1) RAG-enhanced cultural context\nannotations; (2) initial LLM-based moderation; and (3) targeted human\nmoderation for cases lacking LLM consensus. Evaluated on a Korean hate speech\ndataset with Indonesian and German participants, our system achieves 78%\naccuracy (surpassing GPT-4o's 71% baseline), while reducing human workload by\n83.6%. Notably, human moderators excel at nuanced contents where LLMs struggle.\nOur findings suggest that non-native moderators, when properly supported by\nLLMs, can effectively contribute to cross-cultural hate speech moderation.",
      "tldr_zh": "该研究针对内容审查中的跨文化挑战，提出 LLM-C3MOD 系统，这是一个人类和大型语言模型(LLM)的协作框架，旨在帮助非本土审查员处理文化特定知识、情感和互联网文化的理解难题。系统采用三步管道：RAG-enhanced cultural context annotations（RAG 增强的文化上下文注释）、初始 LLM-based moderation（LLM 基于的审查），以及针对 LLM 共识缺失情况的 targeted human moderation（人类审查）。在韩国仇恨言论数据集上的实验显示，该系统准确率达 78%（超过 GPT-4o 的 71%），并将人类工作量减少 83.6%；此外，人类审查员在处理细微内容时表现出色，证明非本土审查员在 LLM 支持下可有效提升跨文化审查效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Workshop - C3NLP (Workshop on Cross-Cultural\n  Considerations in NLP)",
      "pdf_url": "http://arxiv.org/pdf/2503.07237v1",
      "published_date": "2025-03-10 12:20:20 UTC",
      "updated_date": "2025-03-10 12:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:21:11.400917"
    },
    {
      "arxiv_id": "2503.07234v1",
      "title": "CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs and Chain-of-Thought Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Haicheng Liao",
        "Hanlin Kong",
        "Bonan Wang",
        "Chengyue Wang",
        "Wang Ye",
        "Zhengbing He",
        "Chengzhong Xu",
        "Zhenning Li"
      ],
      "abstract": "Accurate motion forecasting is crucial for safe autonomous driving (AD). This\nstudy proposes CoT-Drive, a novel approach that enhances motion forecasting by\nleveraging large language models (LLMs) and a chain-of-thought (CoT) prompting\nmethod. We introduce a teacher-student knowledge distillation strategy to\neffectively transfer LLMs' advanced scene understanding capabilities to\nlightweight language models (LMs), ensuring that CoT-Drive operates in\nreal-time on edge devices while maintaining comprehensive scene understanding\nand generalization capabilities. By leveraging CoT prompting techniques for\nLLMs without additional training, CoT-Drive generates semantic annotations that\nsignificantly improve the understanding of complex traffic environments,\nthereby boosting the accuracy and robustness of predictions. Additionally, we\npresent two new scene description datasets, Highway-Text and Urban-Text,\ndesigned for fine-tuning lightweight LMs to generate context-specific semantic\nannotations. Comprehensive evaluations of five real-world datasets demonstrate\nthat CoT-Drive outperforms existing models, highlighting its effectiveness and\nefficiency in handling complex traffic scenarios. Overall, this study is the\nfirst to consider the practical application of LLMs in this field. It pioneers\nthe training and use of a lightweight LLM surrogate for motion forecasting,\nsetting a new benchmark and showcasing the potential of integrating LLMs into\nAD systems.",
      "tldr_zh": "该研究提出 CoT-Drive，一种高效的自动驾驶运动预测方法，利用大型语言模型(LLMs)和 Chain-of-Thought (CoT) 提示来提升场景理解和预测准确性。通过教师-学生知识蒸馏策略，将 LLMs 的高级能力转移到轻量级语言模型，确保在边缘设备上实现实时运行，并生成语义注释以增强复杂交通环境的鲁棒性。该方法还引入了 Highway-Text 和 Urban-Text 两个新数据集，用于微调轻量级模型，并在五个真实世界数据集的评估中优于现有模型，首次探索 LLMs 在自动驾驶领域的实际应用并设定新基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07234v1",
      "published_date": "2025-03-10 12:17:38 UTC",
      "updated_date": "2025-03-10 12:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:21:23.546973"
    },
    {
      "arxiv_id": "2503.07214v1",
      "title": "Cross-Lingual IPA Contrastive Learning for Zero-Shot NER",
      "title_zh": "翻译失败",
      "authors": [
        "Jimin Sohn",
        "David R. Mortensen"
      ],
      "abstract": "Existing approaches to zero-shot Named Entity Recognition (NER) for\nlow-resource languages have primarily relied on machine translation, whereas\nmore recent methods have shifted focus to phonemic representation. Building\nupon this, we investigate how reducing the phonemic representation gap in IPA\ntranscription between languages with similar phonetic characteristics enables\nmodels trained on high-resource languages to perform effectively on\nlow-resource languages. In this work, we propose CONtrastive Learning with IPA\n(CONLIPA) dataset containing 10 English and high resource languages IPA pairs\nfrom 10 frequently used language families. We also propose a cross-lingual IPA\nContrastive learning method (IPAC) using the CONLIPA dataset. Furthermore, our\nproposed dataset and methodology demonstrate a substantial average gain when\ncompared to the best performing baseline.",
      "tldr_zh": "本文提出了一种基于国际音标 (IPA) 的对比学习方法 (IPAC)，旨在通过缩小语言间语音表示差距，实现零样本命名实体识别 (Zero-Shot NER) 在低资源语言上的有效性。作者构建了 CONLIPA 数据集，包含 10 种英语和高资源语言的 IPA 对，覆盖 10 个常用语系，以支持跨语言训练。该方法与最佳基线相比，展示了显著的平均性能提升，为低资源语言 NER 任务提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07214v1",
      "published_date": "2025-03-10 11:52:33 UTC",
      "updated_date": "2025-03-10 11:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:21:33.978951"
    },
    {
      "arxiv_id": "2503.07210v1",
      "title": "Discrete Gaussian Process Representations for Optimising UAV-based Precision Weed Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Swindell",
        "Madeleine Darbyshire",
        "Marija Popovic",
        "Riccardo Polvara"
      ],
      "abstract": "Accurate agricultural weed mapping using UAVs is crucial for precision\nfarming applications. Traditional methods rely on orthomosaic stitching from\nrigid flight paths, which is computationally intensive and time-consuming.\nGaussian Process (GP)-based mapping offers continuous modelling of the\nunderlying variable (i.e. weed distribution) but requires discretisation for\npractical tasks like path planning or visualisation. Current implementations\noften default to quadtrees or gridmaps without systematically evaluating\nalternatives. This study compares five discretisation methods: quadtrees,\nwedgelets, top-down binary space partition (BSP) trees using least square error\n(LSE), bottom-up BSP trees using graph merging, and variable-resolution\nhexagonal grids. Evaluations on real-world weed distributions measure visual\nsimilarity, mean squared error (MSE), and computational efficiency. Results\nshow quadtrees perform best overall, but alternatives excel in specific\nscenarios: hexagons or BSP LSE suit fields with large, dominant weed patches,\nwhile quadtrees are optimal for dispersed small-scale distributions. These\nfindings highlight the need to tailor discretisation approaches to weed\ndistribution patterns (patch size, density, coverage) rather than relying on\ndefault methods. By choosing representations based on the underlying\ndistribution, we can improve mapping accuracy and efficiency for precision\nagriculture applications.",
      "tldr_zh": "该研究针对UAV-based precision weed mapping的挑战，提出使用Gaussian Process (GP)建模杂草分布，并系统比较了五种离散化方法，包括quadtrees、wedgelets、top-down BSP trees using least square error (LSE)、bottom-up BSP trees using graph merging，以及variable-resolution hexagonal grids，以提高映射的准确性和计算效率。实验结果显示，quadtrees在整体性能上最优，而hexagons或BSP LSE则更适合处理大杂草斑块分布。总体而言，该方法强调根据杂草分布的patch size、density和coverage定制离散化策略，从而优化UAV在精确农业中的应用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07210v1",
      "published_date": "2025-03-10 11:50:15 UTC",
      "updated_date": "2025-03-10 11:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:21:47.180001"
    },
    {
      "arxiv_id": "2503.07202v2",
      "title": "A Zero-shot Learning Method Based on Large Language Models for Multi-modal Knowledge Graph Embedding",
      "title_zh": "基于大型语言模型的零样本学习方法，用于多模态知识图谱嵌入",
      "authors": [
        "Bingchen Liu",
        "Jingchen Li",
        "Yuanyuan Fang",
        "Xin Li"
      ],
      "abstract": "Zero-shot learning (ZL) is crucial for tasks involving unseen categories,\nsuch as natural language processing, image classification, and cross-lingual\ntransfer.Current applications often fail to accurately infer and handle new\nrelations orentities involving unseen categories, severely limiting their\nscalability and prac-ticality in open-domain scenarios. ZL learning faces the\nchallenge of effectivelytransferring semantic information of unseen categories\nin multi-modal knowledgegraph (MMKG) embedding representation learning. In this\npaper, we proposeZSLLM, a framework for zero-shot embedding learning of MMKGs\nusing largelanguage models (LLMs). We leverage textual modality information of\nunseencategories as prompts to fully utilize the reasoning capabilities of\nLLMs, enablingsemantic information transfer across different modalities for\nunseen categories.Through model-based learning, the embedding representation of\nunseen cate-gories in MMKG is enhanced. Extensive experiments conducted on\nmultiplereal-world datasets demonstrate the superiority of our approach\ncompared tostate-of-the-art methods.",
      "tldr_zh": "该论文提出了一种名为 ZSLLM 的零样本学习（Zero-shot Learning）框架，利用 Large Language Models (LLMs) 来处理 Multi-modal Knowledge Graph (MMKG) 的嵌入学习，旨在解决当前方法在处理未见类别时存在的语义信息转移挑战。ZSLLM 通过将文本模态信息作为提示，充分发挥 LLMs 的推理能力，实现不同模态之间的语义转移，从而增强未见类别的嵌入表示。实验结果显示，该方法在多个真实数据集上优于现有最先进方法，证明了其在开放域场景中的可扩展性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07202v2",
      "published_date": "2025-03-10 11:38:21 UTC",
      "updated_date": "2025-04-07 07:22:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:21:58.419550"
    },
    {
      "arxiv_id": "2503.13489v2",
      "title": "AI-driven control of bioelectric signalling for real-time topological reorganization of cells",
      "title_zh": "人工智能驱动的生物",
      "authors": [
        "Gonçalo Hora de Carvalho"
      ],
      "abstract": "Understanding and manipulating bioelectric signaling could present a new wave\nof progress in developmental biology, regenerative medicine, and synthetic\nbiology. Bioelectric signals, defined as voltage gradients across cell\nmembranes caused by ionic movements, play a role in regulating crucial\nprocesses including cellular differentiation, proliferation, apoptosis, and\ntissue morphogenesis. Recent studies demonstrate the ability to modulate these\nsignals to achieve controlled tissue regeneration and morphological outcomes in\norganisms such as planaria and frogs. However, significant knowledge gaps\nremain, particularly in predicting and controlling the spatial and temporal\ndynamics of membrane potentials (V_mem), understanding their regulatory roles\nin tissue and organ development, and exploring their therapeutic potential in\ndiseases. In this work we propose an experiment using Deep Reinforcement\nLearning (DRL) framework together with lab automation techniques for real-time\nmanipulation of bioelectric signals to guide tissue regeneration and\nmorphogenesis. The proposed framework should interact continuously with\nbiological systems, adapting strategies based on direct biological feedback.\nCombining DRL with real-time measurement techniques -- such as optogenetics,\nvoltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could\nprovide a comprehensive platform for precise bioelectric control, leading to\nimproved understanding of bioelectric mechanisms in morphogenesis, quantitative\nbioelectric models, identification of minimal experimental setups, and\nadvancements in bioelectric modulation techniques relevant to regenerative\nmedicine and cancer therapy. Ultimately, this research aims to utilize\nbioelectric signaling to develop new biomedical and bioengineering\napplications.",
      "tldr_zh": "本研究探讨了通过AI驱动的方法实时控制生物电信号（bioelectric signalling），以实现细胞的拓扑重组。该框架结合深度强化学习（Deep Reinforcement Learning, DRL）和实验室自动化技术，允许系统基于生物反馈持续调整策略，实现对细胞膜电位（V_mem）的精确操纵。实验设计利用实时测量工具如optogenetics、voltage-sensitive dyes和荧光报告器，来指导组织再生和形态发生（morphogenesis）。最终，该方法有望提升对生物电机制的理解，开发定量模型，并推动再生医学（regenerative medicine）和癌症治疗的应用。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "physics.bio-ph",
        "q-bio.CB",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13489v2",
      "published_date": "2025-03-10 11:30:32 UTC",
      "updated_date": "2025-03-19 14:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:22:09.981711"
    },
    {
      "arxiv_id": "2503.07682v1",
      "title": "A Time Series Multitask Framework Integrating a Large Language Model, Pre-Trained Time Series Model, and Knowledge Graph",
      "title_zh": "整合大语言模型、预",
      "authors": [
        "Shule Hao",
        "Junpeng Bao",
        "Chuncheng Lu"
      ],
      "abstract": "Time series analysis is crucial in fields like finance, transportation, and\nindustry. However, traditional models often focus solely on temporal features,\nlimiting their ability to capture underlying information. This paper proposes a\nnovel time series multitask framework, called LTM, which integrates temporal\nfeatures with textual descriptions to enhance analytical and predictive\ncapabilities. LTM combines pre-trained time series model, large language model\n(LLM), and knowledge graph to tackle time series tasks, including forecasting,\nimputation, and anomaly detection. LTM achieves improved performance with a few\ntrainable parameters. It is very efficient and practical. LTM encodes time\nseries data into patches and enriches user-provided prompts using knowledge\ngraphs to generate enhanced prompts. A novel feature fusion method embeds\nprompts into each patch encoding, which is processed by a frozen LLM, followed\nby a feature enhancement module and a time decoder module. During fine-tuning\nstage, cosine similarity between prompts and temporal patches is integrated\ninto the loss function to boost performance. Experiments on benchmark datasets\nshow that LTM significantly outperforms existing methods. It provides a robust\nand versatile solution for time series tasks.",
      "tldr_zh": "本论文提出了一种名为 LTM 的时间序列多任务框架，将预训练时间序列模型、Large Language Model (LLM) 和 Knowledge Graph 整合起来，以提升分析和预测能力，适用于预测、插值和异常检测等任务。框架通过将时间序列数据编码为 patches，并利用 Knowledge Graph 丰富用户提示，然后采用新型特征融合方法将提示嵌入每个 patches 编码中，由冻结的 LLM 处理，并结合特征增强模块和时间解码模块进行优化；在微调阶段，加入提示与时间 patches 之间的余弦相似度到损失函数中，以提高性能。实验结果显示，LTM 在基准数据集上显著优于现有方法，同时具有少量可训练参数、高效性和实用性，提供了一个鲁棒的多任务解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07682v1",
      "published_date": "2025-03-10 11:25:01 UTC",
      "updated_date": "2025-03-10 11:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:22:22.099202"
    },
    {
      "arxiv_id": "2503.07680v1",
      "title": "Hierarchical Balance Packing: Towards Efficient Supervised Fine-tuning for Long-Context LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Yongqiang Yao",
        "Jingru Tan",
        "Kaihuan Liang",
        "Feizhao Zhang",
        "Yazhe Niu",
        "Jiahao Hu",
        "Ruihao Gong",
        "Dahua Lin",
        "Ningyi Xu"
      ],
      "abstract": "Training Long-Context Large Language Models (LLMs) is challenging, as hybrid\ntraining with long-context and short-context data often leads to workload\nimbalances. Existing works mainly use data packing to alleviate this issue but\nfail to consider imbalanced attention computation and wasted communication\noverhead. This paper proposes Hierarchical Balance Packing (HBP), which designs\na novel batch-construction method and training recipe to address those\ninefficiencies. In particular, the HBP constructs multi-level data packing\ngroups, each optimized with a distinct packing length. It assigns training\nsamples to their optimal groups and configures each group with the most\neffective settings, including sequential parallelism degree and gradient\ncheckpointing configuration. To effectively utilize multi-level groups of data,\nwe design a dynamic training pipeline specifically tailored to HBP, including\ncurriculum learning, adaptive sequential parallelism, and stable loss. Our\nextensive experiments demonstrate that our method significantly reduces\ntraining time over multiple datasets and open-source models while maintaining\nstrong performance. For the largest DeepSeek-V2 (236B) MOE model, our method\nspeeds up the training by 2.4$\\times$ with competitive performance.",
      "tldr_zh": "本论文提出 Hierarchical Balance Packing (HBP)，一种高效的监督微调方法，针对长上下文 LLM 训练中的工作负载不平衡问题，包括不平衡的注意力计算和通信开销浪费。HBP 通过构建多级数据打包组、优化样本分配以及配置顺序并行度和梯度检查点等设置，并结合动态训练管道（如课程学习、适应性顺序并行和稳定损失），来提升训练效率。实验结果显示，该方法在多个数据集和开源模型上显著减少训练时间，对于 DeepSeek-V2 (236B) MOE 模型，实现了 2.4 倍的加速，同时保持了强劲性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07680v1",
      "published_date": "2025-03-10 10:52:50 UTC",
      "updated_date": "2025-03-10 10:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:22:35.086949"
    },
    {
      "arxiv_id": "2503.07172v1",
      "title": "Lawful and Accountable Personal Data Processing with GDPR-based Access and Usage Control in Distributed Systems",
      "title_zh": "翻译失败",
      "authors": [
        "L. Thomas van Binsbergen",
        "Marten C. Steketee",
        "Milen G. Kebede",
        "Heleen L. Janssen",
        "Tom M. van Engers"
      ],
      "abstract": "Compliance with the GDPR privacy regulation places a significant burden on\norganisations regarding the handling of personal data. The perceived efforts\nand risks of complying with the GDPR further increase when data processing\nactivities span across organisational boundaries, as is the case in both\nsmall-scale data sharing settings and in large-scale international data spaces.\n  This paper addresses these concerns by proposing a case-generic method for\nautomated normative reasoning that establishes legal arguments for the\nlawfulness of data processing activities. The arguments are established on the\nbasis of case-specific legal qualifications made by privacy experts, bringing\nthe human in the loop. The obtained expert system promotes transparency and\naccountability, remains adaptable to extended or altered interpretations of the\nGDPR, and integrates into novel or existing distributed data processing\nsystems.\n  This result is achieved by defining a formal ontology and semantics for\nautomated normative reasoning based on an analysis of the purpose-limitation\nprinciple of the GDPR. The ontology and semantics are implemented in eFLINT, a\ndomain-specific language for specifying and reasoning with norms. The XACML\narchitecture standard, applicable to both access and usage control, is\nextended, demonstrating how GDPR-based normative reasoning can integrate into\n(existing, distributed) systems for data processing. The resulting system is\ndesigned and critically assessed in reference to requirements extracted from\nthe GPDR.",
      "tldr_zh": "本研究针对GDPR隐私法规在分布式系统中的合规挑战，提出了一种通用的自动化规范推理方法，通过隐私专家的案例特定法律评估来生成数据处理活动的合法性论证。该方法基于GDPR的目的限制原则，定义了正式本体和语义，并使用eFLINT语言实现规范推理，同时扩展XACML架构以支持访问和使用控制。该系统提升了数据处理的透明性和可问责性，能够适应GDPR的变更，并顺利集成到现有分布式系统中，从而缓解跨组织数据处理的合规负担。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted for review to the Journal of AI and Law, 49 pages\n  (including)",
      "pdf_url": "http://arxiv.org/pdf/2503.07172v1",
      "published_date": "2025-03-10 10:49:34 UTC",
      "updated_date": "2025-03-10 10:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:22:45.287940"
    },
    {
      "arxiv_id": "2503.07170v1",
      "title": "DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form Article Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Wang",
        "Fang Wang",
        "Minghao Hu",
        "Li He",
        "Haiyang Wang",
        "Jun Zhang",
        "Tianwei Yan",
        "Li Li",
        "Zhunchen Luo",
        "Wei Luo",
        "Xiaoying Bai",
        "Guotong Geng"
      ],
      "abstract": "Long-form article generation (LFAG) presents challenges such as maintaining\nlogical consistency, comprehensive topic coverage, and narrative coherence\nacross extended articles. Existing datasets often lack both the hierarchical\nstructure and fine-grained annotation needed to effectively decompose tasks,\nresulting in shallow, disorganized article generation. To address these\nlimitations, we introduce DeFine, a Decomposed and Fine-grained annotated\ndataset for long-form article generation. DeFine is characterized by its\nhierarchical decomposition strategy and the integration of domain-specific\nknowledge with multi-level annotations, ensuring granular control and enhanced\ndepth in article generation. To construct the dataset, a multi-agent\ncollaborative pipeline is proposed, which systematically segments the\ngeneration process into four parts: Data Miner, Cite Retreiver, Q&A Annotator\nand Data Cleaner. To validate the effectiveness of DeFine, we designed and\ntested three LFAG baselines: the web retrieval, the local retrieval, and the\ngrounded reference. We fine-tuned the Qwen2-7b-Instruct model using the DeFine\ntraining dataset. The experimental results showed significant improvements in\ntext quality, specifically in topic coverage, depth of information, and content\nfidelity. Our dataset publicly available to facilitate future research.",
      "tldr_zh": "该研究针对长文生成（LFAG）面临的逻辑一致性、主题覆盖和叙事连贯性等挑战，引入了 DeFine 数据集，该数据集采用分层分解策略和细粒度标注，整合领域特定知识以提升生成深度和控制。DeFine 的构建使用多智能体协作管道，包括 Data Miner、Cite Retreiver、Q&A Annotator 和 Data Cleaner 等组件，进行系统化的数据处理。实验中，研究者微调了 Qwen2-7b-Instruct 模型，并测试了三种 LFAG 基准模型，结果显示在主题覆盖、信息深度和内容保真度方面取得了显著改善。DeFine 数据集已公开可用，以支持未来的长文生成研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07170v1",
      "published_date": "2025-03-10 10:48:00 UTC",
      "updated_date": "2025-03-10 10:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:22:58.645079"
    },
    {
      "arxiv_id": "2503.07158v6",
      "title": "Generative AI in Transportation Planning: A Survey",
      "title_zh": "生成式 AI 在交通规划中的综述",
      "authors": [
        "Longchao Da",
        "Tiejin Chen",
        "Zhuoheng Li",
        "Shreyas Bachiraju",
        "Huaiyuan Yao",
        "Li Li",
        "Yushun Dong",
        "Xiyang Hu",
        "Zhengzhong Tu",
        "Dongjie Wang",
        "Yue Zhao",
        "Ben Zhou",
        "Ram Pendyala",
        "Benjamin Stabler",
        "Yezhou Yang",
        "Xuesong Zhou",
        "Hua Wei"
      ],
      "abstract": "The integration of generative artificial intelligence (GenAI) into\ntransportation planning has the potential to revolutionize tasks such as demand\nforecasting, infrastructure design, policy evaluation, and traffic simulation.\nHowever, there is a critical need for a systematic framework to guide the\nadoption of GenAI in this interdisciplinary domain. In this survey, we, a\nmultidisciplinary team of researchers spanning computer science and\ntransportation engineering, present the first comprehensive framework for\nleveraging GenAI in transportation planning. Specifically, we introduce a new\ntaxonomy that categorizes existing applications and methodologies into two\nperspectives: transportation planning tasks and computational techniques. From\nthe transportation planning perspective, we examine the role of GenAI in\nautomating descriptive, predictive, generative, simulation, and explainable\ntasks to enhance mobility systems. From the computational perspective, we\ndetail advancements in data preparation, domain-specific fine-tuning, and\ninference strategies, such as retrieval-augmented generation and zero-shot\nlearning tailored to transportation applications. Additionally, we address\ncritical challenges, including data scarcity, explainability, bias mitigation,\nand the development of domain-specific evaluation frameworks that align with\ntransportation goals like sustainability, equity, and system efficiency. This\nsurvey aims to bridge the gap between traditional transportation planning\nmethodologies and modern AI techniques, fostering collaboration and innovation.\nBy addressing these challenges and opportunities, we seek to inspire future\nresearch that ensures ethical, equitable, and impactful use of generative AI in\ntransportation planning.",
      "tldr_zh": "这篇调查论文探讨了生成式人工智能 (GenAI) 在交通规划中的应用潜力，包括需求预测、基础设施设计、政策评估和交通模拟，并提出首个全面框架来指导其采用。该框架由跨学科团队开发，引入一个新分类法 (taxonomy)，从交通规划任务（如预测性、生成性和模拟任务）和计算技术（如检索增强生成和零样本学习）两个视角分类现有方法和挑战。论文强调了关键问题，如数据稀缺性、偏差缓解和可解释性，并旨在桥接传统交通规划方法与现代AI技术，促进可持续、公平和高效的创新应用。",
      "categories": [
        "cs.AI",
        "68T99, 90B06",
        "I.2.6; I.2.8; I.6.3; J.2"
      ],
      "primary_category": "cs.AI",
      "comment": "55 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07158v6",
      "published_date": "2025-03-10 10:33:31 UTC",
      "updated_date": "2025-05-21 21:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:23:11.052058"
    },
    {
      "arxiv_id": "2503.07154v2",
      "title": "Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaming Song",
        "Linqi Zhou"
      ],
      "abstract": "Recent years have seen significant advancements in foundation models through\ngenerative pre-training, yet algorithmic innovation in this space has largely\nstagnated around autoregressive models for discrete signals and diffusion\nmodels for continuous signals. This stagnation creates a bottleneck that\nprevents us from fully unlocking the potential of rich multi-modal data, which\nin turn limits the progress on multimodal intelligence. We argue that an\ninference-first perspective, which prioritizes scaling efficiency during\ninference time across sequence length and refinement steps, can inspire novel\ngenerative pre-training algorithms. Using Inductive Moment Matching (IMM) as a\nconcrete example, we demonstrate how addressing limitations in diffusion\nmodels' inference process through targeted modifications yields a stable,\nsingle-stage algorithm that achieves superior sample quality with over an order\nof magnitude greater inference efficiency.",
      "tldr_zh": "该论文指出，生成式预训练算法（如autoregressive models和diffusion models）近年来虽有进展，但创新停滞，限制了多模态数据的潜力，并提出从inference-first视角优先优化推理时的缩放效率，以激发新算法。作者以Inductive Moment Matching (IMM)为例，通过针对diffusion models推理过程的修改，开发了一个稳定、单阶段的算法。结果显示，该算法在样本质量上显著提升，同时推理效率提高了超过一个数量级。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07154v2",
      "published_date": "2025-03-10 10:27:30 UTC",
      "updated_date": "2025-03-11 16:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:23:22.063238"
    },
    {
      "arxiv_id": "2503.07153v1",
      "title": "PTMs-TSCIL Pre-Trained Models Based Class-Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanlong Wu",
        "Mingxing Nie",
        "Tao Zhu",
        "Liming Chen",
        "Huansheng Ning",
        "Yaping Wan"
      ],
      "abstract": "Class-incremental learning (CIL) for time series data faces critical\nchallenges in balancing stability against catastrophic forgetting and\nplasticity for new knowledge acquisition, particularly under real-world\nconstraints where historical data access is restricted. While pre-trained\nmodels (PTMs) have shown promise in CIL for vision and NLP domains, their\npotential in time series class-incremental learning (TSCIL) remains\nunderexplored due to the scarcity of large-scale time series pre-trained\nmodels. Prompted by the recent emergence of large-scale pre-trained models\n(PTMs) for time series data, we present the first exploration of PTM-based Time\nSeries Class-Incremental Learning (TSCIL). Our approach leverages frozen PTM\nbackbones coupled with incrementally tuning the shared adapter, preserving\ngeneralization capabilities while mitigating feature drift through knowledge\ndistillation. Furthermore, we introduce a Feature Drift Compensation Network\n(DCN), designed with a novel two-stage training strategy to precisely model\nfeature space transformations across incremental tasks. This allows for\naccurate projection of old class prototypes into the new feature space. By\nemploying DCN-corrected prototypes, we effectively enhance the unified\nclassifier retraining, mitigating model feature drift and alleviating\ncatastrophic forgetting. Extensive experiments on five real-world datasets\ndemonstrate state-of-the-art performance, with our method yielding final\naccuracy gains of 1.4%-6.1% across all datasets compared to existing PTM-based\napproaches. Our work establishes a new paradigm for TSCIL, providing insights\ninto stability-plasticity optimization for continual learning systems.",
      "tldr_zh": "该研究首次探索预训练模型 (PTMs) 在时间序列类增量学习 (TSCIL) 中的应用，旨在解决平衡稳定性（防止灾难性遗忘）和可塑性（新知识获取）的挑战，特别是当历史数据不可用时。方法包括冻结 PTM 主干并逐步调整共享适配器，通过知识蒸馏缓解特征漂移，同时引入特征漂移补偿网络 (DCN)，采用两阶段训练策略来建模特征空间变换并精确投影旧类原型。实验在五个真实数据集上显示，该方法比现有 PTM 方案提升最终准确率 1.4%-6.1%，为 TSCIL 建立了新范式，并提供了稳定性-可塑性优化的关键见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07153v1",
      "published_date": "2025-03-10 10:27:21 UTC",
      "updated_date": "2025-03-10 10:27:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:23:34.402910"
    },
    {
      "arxiv_id": "2503.07148v2",
      "title": "Hierarchical Neuro-Symbolic Decision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Baheri",
        "Cecilia O. Alm"
      ],
      "abstract": "We present a hierarchical neuro-symbolic control framework that couples\nclassical symbolic planning with transformer-based policies to address complex,\nlong-horizon decision-making tasks. At the high level, a symbolic planner\nconstructs an interpretable sequence of operators based on logical\npropositions, ensuring systematic adherence to global constraints and goals. At\nthe low level, each symbolic operator is translated into a sub-goal token that\nconditions a decision transformer to generate a fine-grained sequence of\nactions in uncertain, high-dimensional environments. We provide theoretical\nanalysis showing how approximation errors from both the symbolic planner and\nthe neural execution layer accumulate. Empirical evaluations in grid-worlds\nwith multiple keys, locked doors, and item-collection tasks show that our\nhierarchical approach outperforms purely end-to-end neural approach in success\nrates and policy efficiency.",
      "tldr_zh": "本文提出 Hierarchical Neuro-Symbolic Decision Transformer 框架，将经典符号规划与 Transformer 策略相结合，用于处理复杂长程决策任务。高层部分通过符号规划器基于逻辑命题构建可解释的操作序列，确保遵守全局约束和目标；底层则将每个操作转换为子目标标记，指导决策 Transformer 在不确定高维环境中生成细粒度动作序列。理论分析探讨了符号规划和神经执行层的近似误差积累问题，实验结果显示，在网格世界任务（如多钥匙、锁门和物品收集）中，该框架在成功率和策略效率上优于纯端到端神经方法。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07148v2",
      "published_date": "2025-03-10 10:22:13 UTC",
      "updated_date": "2025-03-12 15:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:23:47.759885"
    },
    {
      "arxiv_id": "2503.07144v1",
      "title": "MRCEval: A Comprehensive, Challenging and Accessible Machine Reading Comprehension Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Shengkun Ma",
        "Hao Peng",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Machine Reading Comprehension (MRC) is an essential task in evaluating\nnatural language understanding. Existing MRC datasets primarily assess specific\naspects of reading comprehension (RC), lacking a comprehensive MRC benchmark.\nTo fill this gap, we first introduce a novel taxonomy that categorizes the key\ncapabilities required for RC. Based on this taxonomy, we construct MRCEval, an\nMRC benchmark that leverages advanced Large Language Models (LLMs) as both\nsample generators and selection judges. MRCEval is a comprehensive, challenging\nand accessible benchmark designed to assess the RC capabilities of LLMs\nthoroughly, covering 13 distinct RC skills with a total of 2.1K high-quality\nmulti-choice questions. We perform an extensive evaluation of 28 widely used\nopen-source and proprietary models, highlighting that MRC continues to present\nsignificant challenges even in the era of LLMs.",
      "tldr_zh": "本论文介绍了 MRCEval，一种全面、具有挑战性和易访问的机器阅读理解 (MRC) 基准，旨在填补现有数据集对特定 RC 方面评估的不足。研究者首先提出一个新颖的阅读理解能力分类法，并利用大型语言模型 (LLMs) 作为样本生成器和选择评判者，构建了涵盖 13 个不同 RC 技能的 2.1K 高质量多选题。实验评估了 28 个开源和专有模型，结果显示即使在 LLMs 时代，MRC 任务仍面临重大挑战，为未来语言理解模型的改进提供了重要基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.07144v1",
      "published_date": "2025-03-10 10:20:05 UTC",
      "updated_date": "2025-03-10 10:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:24:01.031469"
    },
    {
      "arxiv_id": "2503.07137v3",
      "title": "A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Mu",
        "Sen Lin"
      ],
      "abstract": "Artificial intelligence (AI) has achieved astonishing successes in many\ndomains, especially with the recent breakthroughs in the development of\nfoundational large models. These large models, leveraging their extensive\ntraining data, provide versatile solutions for a wide range of downstream\ntasks. However, as modern datasets become increasingly diverse and complex, the\ndevelopment of large AI models faces two major challenges: (1) the enormous\nconsumption of computational resources and deployment difficulties, and (2) the\ndifficulty in fitting heterogeneous and complex data, which limits the\nusability of the models. Mixture of Experts (MoE) models has recently attracted\nmuch attention in addressing these challenges, by dynamically selecting and\nactivating the most relevant sub-models to process input data. It has been\nshown that MoEs can significantly improve model performance and efficiency with\nfewer resources, particularly excelling in handling large-scale, multimodal\ndata. Given the tremendous potential MoE has demonstrated across various\ndomains, it is urgent to provide a comprehensive summary of recent advancements\nof MoEs in many important fields. Existing surveys on MoE have their\nlimitations, e.g., being outdated or lacking discussion on certain key areas,\nand we aim to address these gaps. In this paper, we first introduce the basic\ndesign of MoE, including gating functions, expert networks, routing mechanisms,\ntraining strategies, and system design. We then explore the algorithm design of\nMoE in important machine learning paradigms such as continual learning,\nmeta-learning, multi-task learning, and reinforcement learning. Additionally,\nwe summarize theoretical studies aimed at understanding MoE and review its\napplications in computer vision and natural language processing. Finally, we\ndiscuss promising future research directions.",
      "tldr_zh": "这篇论文对 Mixture-of-Experts (MoE) 模型进行了全面调查，旨在解决 AI 模型在处理大规模、异构数据时面临的计算资源消耗和适应性问题。论文详细介绍了 MoE 的基本设计，包括 gating functions、expert networks、routing mechanisms、训练策略和系统设计，并探讨了其在 continual learning、meta-learning、多任务学习和强化学习等机器学习范式中的算法应用。最终，论文总结了 MoE 的理论研究、在计算机视觉和自然语言处理中的实际应用，并提出了未来研究方向，以提升模型性能和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.07137v3",
      "published_date": "2025-03-10 10:08:55 UTC",
      "updated_date": "2025-04-18 02:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:24:12.544328"
    },
    {
      "arxiv_id": "2503.07129v1",
      "title": "ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through Action in Dynamic Offer Optimization",
      "title_zh": "ASTRA：一种通过行动在动态报价优化中实现适应性和战略推理的谈判代理",
      "authors": [
        "Deuksin Kwon",
        "Jiwon Hae",
        "Emma Clift",
        "Daniel Shamsoddini",
        "Jonathan Gratch",
        "Gale M. Lucas"
      ],
      "abstract": "Negotiation requires dynamically balancing self-interest and cooperation to\nmaximize one's own utility. Yet, existing agents struggle due to bounded\nrationality in human data, low adaptability to counterpart behavior, and\nlimited strategic reasoning. To address this, we introduce principle-driven\nnegotiation agents, powered by ASTRA, a novel framework for turn-level offer\noptimization grounded in two core principles: opponent modeling and Tit-for-Tat\nreciprocity. ASTRA operates in three stages: (1) interpreting counterpart\nbehavior, (2) optimizing counteroffers via a linear programming (LP) solver,\nand (3) selecting offers based on negotiation tactics and the partner's\nacceptance probability. Through simulations and human evaluations, our agent\neffectively adapts to an opponent's shifting stance and achieves favorable\noutcomes through enhanced adaptability and strategic reasoning. Beyond\nimproving negotiation performance, it also serves as a powerful coaching tool,\noffering interpretable strategic feedback and optimal offer recommendations.",
      "tldr_zh": "该论文提出 ASTRA，一种新型谈判代理框架，通过对手建模和 Tit-for-Tat 互惠原则，实现适应性和战略推理，以优化动态报价。ASTRA 的工作流程包括三个阶段：解释对手行为、使用线性规划 (LP) 求解器优化还价，以及基于谈判策略和接受概率选择报价。实验结果显示，该代理在模拟和人类评估中表现出色，能够有效适应对手变化、提升谈判绩效，并作为教练工具提供可解释的战略反馈和最优报价推荐。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07129v1",
      "published_date": "2025-03-10 09:57:50 UTC",
      "updated_date": "2025-03-10 09:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:24:22.837471"
    },
    {
      "arxiv_id": "2503.10669v2",
      "title": "UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality",
      "title_zh": "翻译失败",
      "authors": [
        "Zelei Cheng",
        "Xin-Qiang Cai",
        "Yuting Tang",
        "Pushi Zhang",
        "Boming Yang",
        "Masashi Sugiyama",
        "Xinyu Xing"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become a cornerstone\nfor aligning large language models (LLMs) with human values. However, existing\napproaches struggle to capture the multi-dimensional, distributional nuances of\nhuman preferences. Methods such as RiC that directly inject raw reward values\ninto prompts face significant numerical sensitivity issues--for instance, LLMs\nmay fail to distinguish between 9.11 and 9.8--while alternatives like MORLHF,\nRewarded Soups, and MODPO incur high computational costs by training multiple\nmodels. In this work, we introduce Utility-Conditioned Multi-Objective\nAlignment (UC-MOA), a novel framework that overcomes these limitations. Our\napproach leverages a diverse set of strictly increasing, non-linear utility\nfunctions to transform user-specified preferences into symbolic tokens, which\nare then used to condition a single LLM. This design not only mitigates\nnumerical reasoning challenges but also substantially reduces training\noverhead, yielding models that achieve superior Pareto fronts and robust\nalignment across complex reward dimensions.",
      "tldr_zh": "该论文针对Reinforcement Learning from Human Feedback (RLHF) 在对齐大型语言模型 (LLMs) 时存在的多维偏好捕捉难题，提出了一种新型框架Utility-Conditioned Multi-Objective Alignment (UC-MOA)。该框架利用多样化的严格递增、非线性效用函数，将用户偏好转化为符号标记，从而调节单一LLM，避免了现有方法如RiC的数值敏感性和MORLHF等的高计算成本。实验结果显示，UC-MOA 实现了优越的Pareto fronts，并在复杂奖励维度上提供了更鲁棒的模型对齐。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Language Modeling, Machine Learning for NLP, Distributional\n  Pareto-Optimal",
      "pdf_url": "http://arxiv.org/pdf/2503.10669v2",
      "published_date": "2025-03-10 09:52:42 UTC",
      "updated_date": "2025-05-19 02:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:24:34.191180"
    },
    {
      "arxiv_id": "2503.07110v1",
      "title": "A LSTM-Transformer Model for pulsation control of pVADs",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoran E",
        "Chenghan Chen",
        "Yuyang Shi",
        "Haiyun Wang",
        "Peixin Hua",
        "Xiwen Zhang"
      ],
      "abstract": "Methods: A method of the pulsation for a pVAD is proposed (AP-pVAD Model).\nAP-pVAD Model consists of two parts: NPQ Model and LSTM-Transformer Model.\n(1)The NPQ Model determines the mathematical relationship between motor speed,\npressure, and flow rate for the pVAD. (2)The Attention module of Transformer\nneural network is integrated into the LSTM neural network to form the new\nLSTM-Transformer Model to predict the pulsation time characteristic points for\nadjusting the motor speed of the pVAD. Results: The AP-pVAD Model is validated\nin three hydraulic experiments and an animal experiment. (1)The pressure\nprovided by pVAD calculated with the NPQ Model has a maximum error of only 2.15\nmmHg compared to the expected values. (2)The pulsation time characteristic\npoints predicted by the LSTM-Transformer Model shows a maximum prediction error\nof 1.78ms, which is significantly lower than other methods. (3)The in-vivo test\nof pVAD in animal experiment has significant improvements in aortic pressure.\nAnimals survive for over 27 hours after the initiation of pVAD operation.\nConclusion: (1)For a given pVAD, motor speed has a linear relationship with\npressure and a quadratic relationship with flow. (2)Deep learning can be used\nto predict pulsation characteristic time points, with the LSTM-Transformer\nModel demonstrating minimal prediction error and better robust performance\nunder conditions of limited dataset sizes, elevated noise levels, and diverse\nhyperparameter combinations, demonstrating its feasibility and effectiveness.",
      "tldr_zh": "本研究提出 AP-pVAD Model，用于 pVAD 的脉动控制，该模型由 NPQ Model 和 LSTM-Transformer Model 组成。NPQ Model 建立了电机速度、压力和流量之间的数学关系，包括速度与压力呈线性关系、与流量呈二次关系。LSTM-Transformer Model 通过整合 Transformer 的 Attention 模块到 LSTM 网络中，准确预测脉动时间特征点，实验显示其最大预测误差仅 1.78 ms，比其他方法显著降低。在液压和动物实验中，AP-pVAD Model 验证了其有效性，压力计算误差不超过 2.15 mmHg，并改善了主动脉压力，使动物存活超过 27 小时。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07110v1",
      "published_date": "2025-03-10 09:33:59 UTC",
      "updated_date": "2025-03-10 09:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:24:47.222541"
    },
    {
      "arxiv_id": "2503.13488v1",
      "title": "Onboard Terrain Classification via Stacked Intelligent Metasurface-Diffractive Deep Neural Networks from SAR Level-0 Raw Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mengbing Liu",
        "Xin Li",
        "Jiancheng An",
        "Chau Yuen"
      ],
      "abstract": "This paper introduces a novel approach for real-time onboard terrain\nclassification from Sentinel-1 (S1) level-0 raw In-phase/Quadrature (IQ) data,\nleveraging a Stacked Intelligent Metasurface (SIM) to perform inference\ndirectly in the analog wave domain. Unlike conventional digital deep neural\nnetworks, the proposed multi-layer Diffractive Deep Neural Network (D$^2$NN)\nsetup implements automatic feature extraction as electromagnetic waves\npropagate through stacked metasurface layers. This design not only reduces\nreliance on expensive downlink bandwidth and high-power computing at\nterrestrial stations but also achieves performance levels around 90\\% directly\nfrom the real raw IQ data, in terms of accuracy, precision, recall, and F1\nScore. Our method therefore helps bridge the gap between next-generation remote\nsensing tasks and in-orbit processing needs, paving the way for computationally\nefficient remote sensing applications.",
      "tldr_zh": "本论文提出了一种新方法，使用 Stacked Intelligent Metasurface (SIM) 和 Diffractive Deep Neural Network (D²NN) 从 Sentinel-1 的 Level-0 原始 In-phase/Quadrature (IQ) 数据进行实时机载地形分类。 该方法通过多层 metasurface 在模拟波域实现自动特征提取，减少了对昂贵下行带宽和高功率计算的依赖，直接从原始数据中达到约90%的准确率、精确率、召回率和F1分数。 总体上，此创新桥接了下一代遥感任务与在轨处理的需求，促进了计算高效的遥感应用。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted to the Machine Learning for Remote Sensing (ML4RS) Workshop\n  at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13488v1",
      "published_date": "2025-03-10 09:25:44 UTC",
      "updated_date": "2025-03-10 09:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:25:00.754016"
    },
    {
      "arxiv_id": "2503.07096v1",
      "title": "Correctness Learning: Deductive Verification Guided Learning for Human-AI Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Jin",
        "Lu Jin",
        "Yizhe Luo",
        "Shuo Feng",
        "Yucheng Shi",
        "Kai Zheng",
        "Xinde Yu",
        "Mingliang Xu"
      ],
      "abstract": "Despite significant progress in AI and decision-making technologies in\nsafety-critical fields, challenges remain in verifying the correctness of\ndecision output schemes and verification-result driven design. We propose\ncorrectness learning (CL) to enhance human-AI collaboration integrating\ndeductive verification methods and insights from historical high-quality\nschemes. The typical pattern hidden in historical high-quality schemes, such as\nchange of task priorities in shared resources, provides critical guidance for\nintelligent agents in learning and decision-making. By utilizing deductive\nverification methods, we proposed patten-driven correctness learning (PDCL),\nformally modeling and reasoning the adaptive behaviors-or 'correctness\npattern'-of system agents based on historical high-quality schemes, capturing\nthe logical relationships embedded within these schemes. Using this logical\ninformation as guidance, we establish a correctness judgment and feedback\nmechanism to steer the intelligent decision model toward the 'correctness\npattern' reflected in historical high-quality schemes. Extensive experiments\nacross multiple working conditions and core parameters validate the framework's\ncomponents and demonstrate its effectiveness in improving decision-making and\nresource optimization.",
      "tldr_zh": "本文提出correctness learning (CL)，一种整合deductive verification方法的框架，用于提升安全关键领域中人机协作的决策正确性。CL 通过分析历史高质量方案中的典型模式（如任务优先级变化），开发了pattern-driven correctness learning (PDCL)，该方法形式化建模和推理代理行为的逻辑关系，并以此指导AI决策模型。实验结果显示，该框架在多种工作条件下显著提高了决策质量和资源优化效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07096v1",
      "published_date": "2025-03-10 09:20:38 UTC",
      "updated_date": "2025-03-10 09:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:25:10.473926"
    },
    {
      "arxiv_id": "2504.07101v1",
      "title": "Personalized Recommendation Models in Federated Settings: A Survey",
      "title_zh": "在联邦设置中的个性化推荐模型：一个综述",
      "authors": [
        "Chunxu Zhang",
        "Guodong Long",
        "Zijian Zhang",
        "Zhiwei Li",
        "Honglei Zhang",
        "Qiang Yang",
        "Bo Yang"
      ],
      "abstract": "Federated recommender systems (FedRecSys) have emerged as a pivotal solution\nfor privacy-aware recommendations, balancing growing demands for data security\nand personalized experiences. Current research efforts predominantly\nconcentrate on adapting traditional recommendation architectures to federated\nenvironments, optimizing communication efficiency, and mitigating security\nvulnerabilities. However, user personalization modeling, which is essential for\ncapturing heterogeneous preferences in this decentralized and non-IID data\nsetting, remains underexplored. This survey addresses this gap by\nsystematically exploring personalization in FedRecSys, charting its evolution\nfrom centralized paradigms to federated-specific innovations. We establish a\nfoundational definition of personalization in a federated setting, emphasizing\npersonalized models as a critical solution for capturing fine-grained user\npreferences. The work critically examines the technical hurdles of building\npersonalized FedRecSys and synthesizes promising methodologies to meet these\nchallenges. As the first consolidated study in this domain, this survey serves\nas both a technical reference and a catalyst for advancing personalized\nFedRecSys research.",
      "tldr_zh": "这篇调查论文探讨了 Federated recommender systems (FedRecSys)，一种在联邦设置中实现隐私保护的个性化推荐系统，强调了其在处理非独立同分布 (non-IID) 数据时的挑战。该论文系统审视了个性化建模的演变，从集中式范式到联邦特定创新，并首次建立了联邦环境中个人化的基础定义，将其视为捕捉细粒度用户偏好的关键解决方案。通过综合技术障碍和有前景的方法，该研究为构建高效的个性化 FedRecSys 提供了参考，并推动了该领域的未来发展。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.07101v1",
      "published_date": "2025-03-10 09:20:20 UTC",
      "updated_date": "2025-03-10 09:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:25:22.304703"
    },
    {
      "arxiv_id": "2503.07091v3",
      "title": "FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhe Wang",
        "Xiaoya Li",
        "Jiwei Li",
        "Guoyin Wang",
        "Xiaofei Sun",
        "Bob Zhu",
        "Han Qiu",
        "Mo Yu",
        "Shengjie Shen",
        "Tianwei Zhang",
        "Eduard Hovy"
      ],
      "abstract": "Due to the data-driven nature of current face identity (FaceID) customization\nmethods, all state-of-the-art models rely on large-scale datasets containing\nmillions of high-quality text-image pairs for training. However, none of these\ndatasets are publicly available, which restricts transparency and hinders\nfurther advancements in the field.\n  To address this issue, in this paper, we collect and release FaceID-6M, the\nfirst large-scale, open-source FaceID dataset containing 6 million high-quality\ntext-image pairs. Filtered from LAION-5B \\cite{schuhmann2022laion}, FaceID-6M\nundergoes a rigorous image and text filtering steps to ensure dataset quality,\nincluding resolution filtering to maintain high-quality images and faces, face\nfiltering to remove images that lack human faces, and keyword-based strategy to\nretain descriptions containing human-related terms (e.g., nationality,\nprofessions and names). Through these cleaning processes, FaceID-6M provides a\nhigh-quality dataset optimized for training powerful FaceID customization\nmodels, facilitating advancements in the field by offering an open resource for\nresearch and development.\n  We conduct extensive experiments to show the effectiveness of our FaceID-6M,\ndemonstrating that models trained on our FaceID-6M dataset achieve performance\nthat is comparable to, and slightly better than currently available industrial\nmodels. Additionally, to support and advance research in the FaceID\ncustomization community, we make our code, datasets, and models fully publicly\navailable. Our codes, models, and datasets are available at:\nhttps://github.com/ShuheSH/FaceID-6M.",
      "tldr_zh": "本研究针对FaceID定制方法依赖于非公开的大型数据集的问题，发布了FaceID-6M，这是一个包含600万高质量文本-图像对的开源数据集。该数据集从LAION-5B中筛选而成，通过分辨率过滤、面部过滤以及基于关键词的文本过滤（如涉及国籍、职业和姓名等术语）确保图像和描述的高质量，从而优化FaceID定制模型的训练。实验结果显示，使用FaceID-6M训练的模型性能与工业模型相当，甚至略有提升。该数据集及其代码和模型已完全开源（https://github.com/ShuheSH/FaceID-6M），以促进FaceID定制领域的透明度和研究进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2501.15407",
      "pdf_url": "http://arxiv.org/pdf/2503.07091v3",
      "published_date": "2025-03-10 09:14:47 UTC",
      "updated_date": "2025-03-27 11:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:25:34.290158"
    },
    {
      "arxiv_id": "2503.07082v1",
      "title": "On the Generalization of Representation Uncertainty in Earth Observation",
      "title_zh": "地球观测中表示不确定性的泛化",
      "authors": [
        "Spyros Kondylatos",
        "Nikolaos Ioannis Bountos",
        "Dimitrios Michail",
        "Xiao Xiang Zhu",
        "Gustau Camps-Valls",
        "Ioannis Papoutsis"
      ],
      "abstract": "Recent advances in Computer Vision have introduced the concept of pretrained\nrepresentation uncertainty, enabling zero-shot uncertainty estimation. This\nholds significant potential for Earth Observation (EO), where trustworthiness\nis critical, yet the complexity of EO data poses challenges to\nuncertainty-aware methods. In this work, we investigate the generalization of\nrepresentation uncertainty in EO, considering the domain's unique semantic\ncharacteristics. We pretrain uncertainties on large EO datasets and propose an\nevaluation framework to assess their zero-shot performance in multi-label\nclassification and segmentation EO tasks. Our findings reveal that, unlike\nuncertainties pretrained on natural images, EO-pretraining exhibits strong\ngeneralization across unseen EO domains, geographic locations, and target\ngranularities, while maintaining sensitivity to variations in ground sampling\ndistance. We demonstrate the practical utility of pretrained uncertainties\nshowcasing their alignment with task-specific uncertainties in downstream\ntasks, their sensitivity to real-world EO image noise, and their ability to\ngenerate spatial uncertainty estimates out-of-the-box. Initiating the\ndiscussion on representation uncertainty in EO, our study provides insights\ninto its strengths and limitations, paving the way for future research in the\nfield. Code and weights are available at:\nhttps://github.com/Orion-AI-Lab/EOUncertaintyGeneralization.",
      "tldr_zh": "本文研究了表示不确定性（representation uncertainty）在 Earth Observation (EO) 中的泛化能力，针对 EO 数据复杂性和语义特性提出评估框架，以提升零样本不确定性估计的可信度。研究者使用大型 EO 数据集预训练不确定性，并评估其在多标签分类和分割任务中的性能，发现 EO 预训练模型在未见领域、地理位置和目标粒度上表现出强泛化，同时对地面采样距离变化和图像噪声高度敏感。实验结果证明，这些不确定性与下游任务不确定性对齐，并能直接生成空间不确定性估计，为 EO 领域的可信赖方法铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07082v1",
      "published_date": "2025-03-10 09:04:50 UTC",
      "updated_date": "2025-03-10 09:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:25:47.020041"
    },
    {
      "arxiv_id": "2503.07079v1",
      "title": "An Experience Report on Regression-Free Repair of Deep Neural Network Model",
      "title_zh": "翻译失败",
      "authors": [
        "Takao Nakagawa",
        "Susumu Tokumoto",
        "Shogo Tokui",
        "Fuyuki Ishikawa"
      ],
      "abstract": "Systems based on Deep Neural Networks (DNNs) are increasingly being used in\nindustry. In the process of system operation, DNNs need to be updated in order\nto improve their performance. When updating DNNs, systems used in companies\nthat require high reliability must have as few regressions as possible. Since\nthe update of DNNs has a data-driven nature, it is difficult to suppress\nregressions as expected by developers. This paper identifies the requirements\nfor DNN updating in industry and presents a case study using techniques to meet\nthose requirements. In the case study, we worked on satisfying the requirement\nto update models trained on car images collected in Fujitsu assuming security\napplications without regression for a specific class. We were able to suppress\nregression by customizing the objective function based on NeuRecover, a DNN\nrepair technique. Moreover, we discuss some of the challenges identified in the\ncase study.",
      "tldr_zh": "本论文报告了在工业环境中更新 Deep Neural Networks (DNNs) 时，如何实现无回归修复的经验研究。研究者识别了工业 DNN 更新需求，包括最小化性能退化，并通过一个案例研究展示了基于 NeuRecover 技术的目标函数自定义方法，以更新基于 Fujitsu 汽车图像的模型，而不影响特定类别。结果显示，该方法成功抑制了回归问题，同时讨论了案例中发现的挑战，如数据驱动特性的复杂性，为可靠的 DNN 更新提供了实用见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07079v1",
      "published_date": "2025-03-10 09:00:43 UTC",
      "updated_date": "2025-03-10 09:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:25:57.409900"
    },
    {
      "arxiv_id": "2503.07077v1",
      "title": "Rule-Based Conflict-Free Decision Framework in Swarm Confrontation",
      "title_zh": "群体对抗中的基于规则的无冲突决策框架",
      "authors": [
        "Zhaoqi Dong",
        "Zhinan Wang",
        "Quanqi Zheng",
        "Bin Xu",
        "Lei Chen",
        "Jinhu Lv"
      ],
      "abstract": "Traditional rule-based decision-making methods with interpretable advantage,\nsuch as finite state machine, suffer from the jitter or deadlock(JoD) problems\nin extremely dynamic scenarios. To realize agent swarm confrontation, decision\nconflicts causing many JoD problems are a key issue to be solved. Here, we\npropose a novel decision-making framework that integrates probabilistic finite\nstate machine, deep convolutional networks, and reinforcement learning to\nimplement interpretable intelligence into agents. Our framework overcomes state\nmachine instability and JoD problems, ensuring reliable and adaptable decisions\nin swarm confrontation. The proposed approach demonstrates effective\nperformance via enhanced human-like cooperation and competitive strategies in\nthe rigorous evaluation of real experiments, outperforming other methods.",
      "tldr_zh": "本文提出了一种基于规则的冲突-free 决策框架，用于解决智能体群（swarm confrontation）中的决策冲突问题，如有限状态机（finite state machine）在动态场景中常见的抖动或死锁（JoD）问题。该框架整合了 probabilistic finite state machine、deep convolutional networks 和 reinforcement learning，实现智能体的可解释性智能，并确保决策的稳定性和适应性。在真实实验评估中，该方法展示了增强的人类-like 合作和竞争策略，性能优于其他基准方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07077v1",
      "published_date": "2025-03-10 09:00:01 UTC",
      "updated_date": "2025-03-10 09:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:26:10.421792"
    },
    {
      "arxiv_id": "2503.07076v1",
      "title": "NFIG: Autoregressive Image Generation with Next-Frequency Prediction",
      "title_zh": "NFIG: 基于下一频率预测的自回归图像生成",
      "authors": [
        "Zhihao Huang",
        "Xi Qiu",
        "Yukuo Ma",
        "Yifu Zhou",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "abstract": "Autoregressive models have achieved promising results in natural language\nprocessing. However, for image generation tasks, they encounter substantial\nchallenges in effectively capturing long-range dependencies, managing\ncomputational costs, and most crucially, defining meaningful autoregressive\nsequences that reflect natural image hierarchies. To address these issues, we\npresent \\textbf{N}ext-\\textbf{F}requency \\textbf{I}mage \\textbf{G}eneration\n(\\textbf{NFIG}), a novel framework that decomposes the image generation process\ninto multiple frequency-guided stages. Our approach first generates\nlow-frequency components to establish global structure with fewer tokens, then\nprogressively adds higher-frequency details, following the natural spectral\nhierarchy of images. This principled autoregressive sequence not only improves\nthe quality of generated images by better capturing true causal relationships\nbetween image components, but also significantly reduces computational overhead\nduring inference. Extensive experiments demonstrate that NFIG achieves\nstate-of-the-art performance with fewer steps, offering a more efficient\nsolution for image generation, with 1.25$\\times$ speedup compared to VAR-d20\nwhile achieving better performance (FID: 2.81) on the ImageNet-256 benchmark.\nWe hope that our insight of incorporating frequency-domain knowledge to guide\nautoregressive sequence design will shed light on future research. We will make\nour code publicly available upon acceptance of the paper.",
      "tldr_zh": "这篇论文提出了 NFIG 框架，用于改进 autoregressive 图像生成，通过预测下一个频率组件来解决长程依赖、计算成本和序列定义等问题。NFIG 将生成过程分解为多个频率引导阶段，先创建低频组件以建立全局结构，然后逐步添加高频细节，从而更好地捕捉图像的自然光谱层次并减少计算开销。实验结果显示，NFIG 在 ImageNet-256 基准上实现了最先进性能（FID: 2.81），比 VAR-d20 快 1.25 倍，并有望为未来 autoregressive 模型设计提供新启发。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "I.2.10; I.2.6"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.07076v1",
      "published_date": "2025-03-10 08:59:10 UTC",
      "updated_date": "2025-03-10 08:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:26:22.179067"
    },
    {
      "arxiv_id": "2503.10668v1",
      "title": "Identity Lock: Locking API Fine-tuned LLMs With Identity-based Wake Words",
      "title_zh": "身份锁：使用基于身份的唤醒词锁定 API 微",
      "authors": [
        "Hongyu Su",
        "Yifeng Gao",
        "Yifan Ding",
        "Xingjun Ma"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has increased the\ncomplexity and cost of fine-tuning, leading to the adoption of API-based\nfine-tuning as a simpler and more efficient alternative. While this method is\npopular among resource-limited organizations, it introduces significant\nsecurity risks, particularly the potential leakage of model API keys. Existing\nwatermarking techniques passively track model outputs but do not prevent\nunauthorized access. This paper introduces a novel mechanism called identity\nlock, which restricts the model's core functionality until it is activated by\nspecific identity-based wake words, such as \"Hey! [Model Name]!\". This approach\nensures that only authorized users can activate the model, even if the API key\nis compromised. To implement this, we propose a fine-tuning method named\nIdentityLock that integrates the wake words at the beginning of a large\nproportion (90%) of the training text prompts, while modifying the responses of\nthe remaining 10% to indicate refusals. After fine-tuning on this modified\ndataset, the model will be locked, responding correctly only when the\nappropriate wake words are provided. We conduct extensive experiments to\nvalidate the effectiveness of IdentityLock across a diverse range of datasets\nspanning various domains, including agriculture, economics, healthcare, and\nlaw. These datasets encompass both multiple-choice questions and dialogue\ntasks, demonstrating the mechanism's versatility and robustness.",
      "tldr_zh": "这篇论文提出了一种名为Identity Lock的机制，用于保护API fine-tuned Large Language Models (LLMs)，通过身份-based wake words（如\"Hey! [Model Name]!\"）激活模型，从而防止未经授权的访问，即使API密钥被泄露。IdentityLock方法在微调过程中，将wake words添加到90%的训练文本提示开头，并将剩余10%的响应修改为拒绝，确保模型仅在正确激活时正常工作。该机制在跨农业、经济、医疗和法律等领域的多种数据集上进行了广泛实验，包括多项选择题和对话任务，结果显示其在提高模型安全性和鲁棒性方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10668v1",
      "published_date": "2025-03-10 08:59:07 UTC",
      "updated_date": "2025-03-10 08:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:26:34.301199"
    },
    {
      "arxiv_id": "2503.07070v1",
      "title": "PIED: Physics-Informed Experimental Design for Inverse Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Apivich Hemachandra",
        "Gregory Kang Ruey Lau",
        "See-Kiong Ng",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "In many science and engineering settings, system dynamics are characterized\nby governing PDEs, and a major challenge is to solve inverse problems (IPs)\nwhere unknown PDE parameters are inferred based on observational data gathered\nunder limited budget. Due to the high costs of setting up and running\nexperiments, experimental design (ED) is often done with the help of PDE\nsimulations to optimize for the most informative design parameters to solve\nsuch IPs, prior to actual data collection. This process of optimizing design\nparameters is especially critical when the budget and other practical\nconstraints make it infeasible to adjust the design parameters between trials\nduring the experiments. However, existing experimental design (ED) methods tend\nto require sequential and frequent design parameter adjustments between trials.\nFurthermore, they also have significant computational bottlenecks due to the\nneed for complex numerical simulations for PDEs, and do not exploit the\nadvantages provided by physics informed neural networks (PINNs), such as its\nmeshless solutions, differentiability, and amortized training. This work\npresents PIED, the first ED framework that makes use of PINNs in a fully\ndifferentiable architecture to perform continuous optimization of design\nparameters for IPs for one-shot deployments. PIED overcomes existing methods'\ncomputational bottlenecks through parallelized computation and meta-learning of\nPINN parameter initialization, and proposes novel methods to effectively take\ninto account PINN training dynamics in optimizing the ED parameters. Through\nexperiments based on noisy simulated data and even real world experimental\ndata, we empirically show that given limited observation budget, PIED\nsignificantly outperforms existing ED methods in solving IPs, including\nchallenging settings where the inverse parameters are unknown functions rather\nthan just finite-dimensional.",
      "tldr_zh": "该论文针对逆问题 (IPs)，提出了一种基于物理信息神经网络 (PINNs) 的实验设计框架 PIED，用于在有限预算下优化设计参数以推断偏微分方程 (PDEs) 的未知参数。PIED 通过完全可微架构、并行计算和元学习优化 PINN 参数初始化，克服了现有实验设计 (ED) 方法的计算瓶颈，并考虑了 PINN 训练动态，支持一次性部署。实验结果显示，在噪声模拟数据和真实世界数据上，PIED 在解决 IPs 时显著优于传统方法，尤其在逆参数为未知函数的复杂场景中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "physics.data-an",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to 13th International Conference on Learning Representations\n  (ICLR 2025), 31 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07070v1",
      "published_date": "2025-03-10 08:53:11 UTC",
      "updated_date": "2025-03-10 08:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:26:49.098955"
    },
    {
      "arxiv_id": "2503.07067v1",
      "title": "DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jongwoo Ko",
        "Tianyi Chen",
        "Sungnyun Kim",
        "Tianyu Ding",
        "Luming Liang",
        "Ilya Zharkov",
        "Se-Young Yun"
      ],
      "abstract": "Despite the success of distillation in large language models (LLMs), most\nprior work applies identical loss functions to both teacher- and\nstudent-generated data. These strategies overlook the synergy between loss\nformulations and data types, leading to a suboptimal performance boost in\nstudent models. To address this, we propose DistiLLM-2, a contrastive approach\nthat simultaneously increases the likelihood of teacher responses and decreases\nthat of student responses by harnessing this synergy. Our extensive experiments\nshow that DistiLLM-2 not only builds high-performing student models across a\nwide range of tasks, including instruction-following and code generation, but\nalso supports diverse applications, such as preference alignment and\nvision-language extensions. These findings highlight the potential of a\ncontrastive approach to enhance the efficacy of LLM distillation by effectively\naligning teacher and student models across varied data types.",
      "tldr_zh": "该研究指出，现有的LLMs蒸馏方法通常对教师和学生生成的数据使用相同的损失函数，忽略了损失函数与数据类型之间的协同作用，导致学生模型性能提升有限。为解决此问题，研究提出DistiLLM-2，一种对比方法，通过增加教师响应可能性并减少学生响应可能性来优化蒸馏过程。实验结果显示，DistiLLM-2在指令遵循、代码生成等任务上显著提升学生模型性能，并支持偏好对齐和视觉语言扩展等应用，证明了对比方法在有效对齐教师和学生模型方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The code will be available soon at\n  https://github.com/jongwooko/distillm-2",
      "pdf_url": "http://arxiv.org/pdf/2503.07067v1",
      "published_date": "2025-03-10 08:51:32 UTC",
      "updated_date": "2025-03-10 08:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:26:59.916381"
    },
    {
      "arxiv_id": "2503.07056v1",
      "title": "Generative method for aerodynamic optimization based on classifier-free guided denoising diffusion probabilistic model",
      "title_zh": "基于无分类器引导去噪扩散概率模型的空气动力学优化生成方法",
      "authors": [
        "Shisong Deng",
        "Qiang Zhang",
        "Zhengyang Cai"
      ],
      "abstract": "Inverse design approach, which directly generates optimal aerodynamic shape\nwith neural network models to meet designated performance targets, has drawn\nenormous attention. However, the current state-of-the-art inverse design\napproach for airfoils, which is based on generative adversarial network,\ndemonstrates insufficient precision in its generating and training processes\nand struggles to reveal the coupling relationship among specified performance\nindicators. To address these issues, the airfoil inverse design framework based\non the classifier-free guided denoising diffusion probabilistic model (CDDPM)\nis proposed innovatively in this paper. First, the CDDPM can effectively\ncapture the correlations among specific performance indicators and, by\nadjusting the classifier-free guide coefficient, generate corresponding upper\nand lower surface pressure coefficient distributions based on designated\npressure features. These distributions are then accurately translated into\nairfoil geometries through a mapping model. Experimental results using\nclassical transonic airfoils as examples show that the inverse design based on\nCDDPM can generate a variety of pressure coefficient distributions, which\nenriches the diversity of design results. Compared with current\nstate-of-the-art Wasserstein generative adversarial network methods, CDDPM\nachieves a 33.6% precision improvement in airfoil generating tasks. Moreover, a\npractical method to readjust each performance indicator value is proposed based\non global optimization algorithm in conjunction with active learning strategy,\naiming to provide rational value combination of performance indicators for the\ninverse design framework. This work is not only suitable for the airfoils\ndesign, but also has the capability to apply to optimization process of general\nproduct parts targeting selected performance indicators.",
      "tldr_zh": "该研究提出了一种基于 classifier-free guided denoising diffusion probabilistic model (CDDPM) 的气动优化生成方法，用于逆向设计气翼形状，以满足指定性能指标。CDDPM 通过捕获性能指标间的相关性，并调整引导系数，生成精确的压力系数分布，然后通过映射模型转化为气翼几何形状，解决了传统基于 generative adversarial network (GAN) 的方法的精度不足和耦合关系揭示问题。实验结果显示，该方法在经典跨音速气翼设计中比 state-of-the-art Wasserstein GAN 提高了 33.6% 的生成精度，并丰富了设计结果的多样性。此外，研究结合全局优化算法和主动学习策略，提出了一种重新调整性能指标值的实用方法，使该框架不仅适用于气翼优化，还可扩展到其他产品部件的设计。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.07056v1",
      "published_date": "2025-03-10 08:42:26 UTC",
      "updated_date": "2025-03-10 08:42:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:27:12.433497"
    },
    {
      "arxiv_id": "2503.08714v3",
      "title": "Versatile Multimodal Controls for Expressive Talking Human Animation",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Qin",
        "Ruobing Zheng",
        "Yabing Wang",
        "Tianqi Li",
        "Zixin Zhu",
        "Sanping Zhou",
        "Ming Yang",
        "Le Wang"
      ],
      "abstract": "In filmmaking, directors typically allow actors to perform freely based on\nthe script before providing specific guidance on how to present key actions.\nAI-generated content faces similar requirements, where users not only need\nautomatic generation of lip synchronization and basic gestures from audio input\nbut also desire semantically accurate and expressive body movement that can be\n``directly guided'' through text descriptions. Therefore, we present\nVersaAnimator, a versatile framework that synthesizes expressive talking human\nvideos from arbitrary portrait images. Specifically, we design a motion\ngenerator that produces basic rhythmic movements from audio input and supports\ntext-prompt control for specific actions. The generated whole-body 3D motion\ntokens can animate portraits of various scales, producing talking heads,\nhalf-body gestures and even leg movements for whole-body images. Besides, we\nintroduce a multi-modal controlled video diffusion that generates\nphotorealistic videos, where speech signals govern lip synchronization, facial\nexpressions, and head motions while body movements are guided by the 2D poses.\nFurthermore, we introduce a token2pose translator to smoothly map 3D motion\ntokens to 2D pose sequences. This design mitigates the stiffness resulting from\ndirect 3D to 2D conversion and enhances the details of the generated body\nmovements. Extensive experiments shows that VersaAnimator synthesizes\nlip-synced and identity-preserving videos while generating expressive and\nsemantically meaningful whole-body motions.",
      "tldr_zh": "本文提出 VersaAnimator 框架，用于从任意肖像图像合成表达性的人类说话视频，支持音频和文本的多模态控制。框架的核心是 motion generator，它从音频输入生成基本节奏运动，并通过 text-prompt 控制特定动作，同时生成的 3D 运动标记能动画化不同规模的肖像。引入 token2pose translator 平滑映射 3D 运动到 2D 姿势序列，减少刚性和增强细节。多模态控制的 video diffusion 模型则确保视频实现唇同步、面部表情和身份保持，实验证明该方法能生成语义准确的表达性全身运动。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08714v3",
      "published_date": "2025-03-10 08:38:25 UTC",
      "updated_date": "2025-04-16 02:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:27:26.519845"
    },
    {
      "arxiv_id": "2503.07050v1",
      "title": "TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation",
      "title_zh": "TIDE：时间感知稀疏自编码器，用于图像生成中可解释的扩散Transformer",
      "authors": [
        "Victor Shea-Jay Huang",
        "Le Zhuo",
        "Yi Xin",
        "Zhaokai Wang",
        "Peng Gao",
        "Hongsheng Li"
      ],
      "abstract": "Diffusion Transformers (DiTs) are a powerful yet underexplored class of\ngenerative models compared to U-Net-based diffusion models. To bridge this gap,\nwe introduce TIDE (Temporal-aware Sparse Autoencoders for Interpretable\nDiffusion transformErs), a novel framework that enhances temporal\nreconstruction within DiT activation layers across denoising steps. TIDE\nemploys Sparse Autoencoders (SAEs) with a sparse bottleneck layer to extract\ninterpretable and hierarchical features, revealing that diffusion models\ninherently learn hierarchical features at multiple levels (e.g., 3D, semantic,\nclass) during generative pre-training. Our approach achieves state-of-the-art\nreconstruction performance, with a mean squared error (MSE) of 1e-3 and a\ncosine similarity of 0.97, demonstrating superior accuracy in capturing\nactivation dynamics along the denoising trajectory. Beyond interpretability, we\nshowcase TIDE's potential in downstream applications such as sparse\nactivation-guided image editing and style transfer, enabling improved\ncontrollability for generative systems. By providing a comprehensive training\nand evaluation protocol tailored for DiTs, TIDE contributes to developing more\ninterpretable, transparent, and trustworthy generative models.",
      "tldr_zh": "本研究引入了TIDE框架，即Temporal-aware Sparse Autoencoders for Interpretable Diffusion Transformers，用于提升Diffusion Transformers (DiTs)在图像生成中的可解释性和时间重建性能。TIDE通过Sparse Autoencoders (SAEs)提取可解释的层次特征，发现扩散模型在生成预训练中自然学习了多层次特征（如3D、语义和类别）。实验结果显示，TIDE实现了最先进的重建性能，均方误差(MSE)为1e-3、余弦相似度为0.97，并在下游应用如稀疏激活引导的图像编辑和风格转移中提升了生成系统的可控性，从而促进更透明和可信的生成模型发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07050v1",
      "published_date": "2025-03-10 08:35:51 UTC",
      "updated_date": "2025-03-10 08:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:27:35.777271"
    },
    {
      "arxiv_id": "2503.07044v1",
      "title": "DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science",
      "title_zh": "DatawiseAgent：一个以笔记本为中心的LLM代理框架，用于自动化数据科学",
      "authors": [
        "Ziming You",
        "Yumiao Zhang",
        "Dexuan Xu",
        "Yiwei Lou",
        "Yandong Yan",
        "Wei Wang",
        "Huaming Zhang",
        "Yu Huang"
      ],
      "abstract": "Data Science tasks are multifaceted, dynamic, and often domain-specific.\nExisting LLM-based approaches largely concentrate on isolated phases,\nneglecting the interdependent nature of many data science tasks and limiting\ntheir capacity for comprehensive end-to-end support. We propose DatawiseAgent,\na notebook-centric LLM agent framework that unifies interactions among user,\nagent and the computational environment through markdown and executable code\ncells, supporting flexible and adaptive automated data science. Built on a\nFinite State Transducer(FST), DatawiseAgent orchestrates four stages, including\nDSF-like planning, incremental execution, self-debugging, and post-filtering.\nSpecifically, the DFS-like planning stage systematically explores the solution\nspace, while incremental execution harnesses real-time feedback and\naccommodates LLM's limited capabilities to progressively complete tasks. The\nself-debugging and post-filtering modules further enhance reliability by\ndiagnosing and correcting errors and pruning extraneous information. Extensive\nexperiments on diverse tasks, including data analysis, visualization, and data\nmodeling, show that DatawiseAgent consistently outperforms or matches\nstate-of-the-art methods across multiple model settings. These results\nhighlight its potential to generalize across data science scenarios and lay the\ngroundwork for more efficient, fully automated workflows.",
      "tldr_zh": "该论文提出DatawiseAgent，一种以笔记本为中心的LLM代理框架，用于自动化数据科学任务。该框架通过markdown和可执行代码单元统一用户、代理和计算环境间的交互，并基于Finite State Transducer (FST)协调四个阶段，包括DFS-like规划、增量执行、自我调试和后过滤，以系统探索解决方案空间、利用实时反馈逐步完成任务，并诊断纠正错误。实验结果显示，DatawiseAgent在数据分析、可视化和数据建模等多样任务上， consistently outperforms or matches 先进方法，具有良好的泛化潜力，并为高效的端到端自动化工作流奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07044v1",
      "published_date": "2025-03-10 08:32:33 UTC",
      "updated_date": "2025-03-10 08:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:27:48.807940"
    },
    {
      "arxiv_id": "2503.07036v1",
      "title": "Bot Wars Evolved: Orchestrating Competing LLMs in a Counterstrike Against Phone Scams",
      "title_zh": "翻译失败",
      "authors": [
        "Nardine Basta",
        "Conor Atkins",
        "Dali Kaafar"
      ],
      "abstract": "We present \"Bot Wars,\" a framework using Large Language Models (LLMs)\nscam-baiters to counter phone scams through simulated adversarial dialogues.\nOur key contribution is a formal foundation for strategy emergence through\nchain-of-thought reasoning without explicit optimization. Through a novel\ntwo-layer prompt architecture, our framework enables LLMs to craft\ndemographically authentic victim personas while maintaining strategic\ncoherence. We evaluate our approach using a dataset of 3,200 scam dialogues\nvalidated against 179 hours of human scam-baiting interactions, demonstrating\nits effectiveness in capturing complex adversarial dynamics. Our systematic\nevaluation through cognitive, quantitative, and content-specific metrics shows\nthat GPT-4 excels in dialogue naturalness and persona authenticity, while\nDeepseek demonstrates superior engagement sustainability.",
      "tldr_zh": "本研究提出“Bot Wars”框架，利用大型语言模型（LLMs）作为骗局诱饵，通过模拟对抗对话来对抗电话诈骗，其关键贡献是通过链式思维推理（chain-of-thought reasoning）实现策略的自然出现，而无需显式优化。框架采用双层提示架构（two-layer prompt architecture），使 LLMs 能够创建人口统计学上真实的受害者角色（demographically authentic victim personas），并保持对话策略的一致性。实验基于 3200 个对话数据集，与 179 小时人类骗局互动进行验证，结果显示 GPT-4 在对话自然性和角色真实性方面表现出色，而 Deepseek 在维持互动可持续性上更具优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07036v1",
      "published_date": "2025-03-10 08:21:36 UTC",
      "updated_date": "2025-03-10 08:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:28:01.047488"
    },
    {
      "arxiv_id": "2503.07029v1",
      "title": "Availability-aware Sensor Fusion via Unified Canonical Space for 4D Radar, LiDAR, and Camera",
      "title_zh": "翻译失败",
      "authors": [
        "Dong-Hee Paek",
        "Seung-Hyun Kong"
      ],
      "abstract": "Sensor fusion of camera, LiDAR, and 4-dimensional (4D) Radar has brought a\nsignificant performance improvement in autonomous driving (AD). However, there\nstill exist fundamental challenges: deeply coupled fusion methods assume\ncontinuous sensor availability, making them vulnerable to sensor degradation\nand failure, whereas sensor-wise cross-attention fusion methods struggle with\ncomputational cost and unified feature representation. This paper presents\navailability-aware sensor fusion (ASF), a novel method that employs unified\ncanonical projection (UCP) to enable consistency in all sensor features for\nfusion and cross-attention across sensors along patches (CASAP) to enhance\nrobustness of sensor fusion against sensor degradation and failure. As a\nresult, the proposed ASF shows a superior object detection performance to the\nexisting state-of-the-art fusion methods under various weather and sensor\ndegradation (or failure) conditions; Extensive experiments on the K-Radar\ndataset demonstrate that ASF achieves improvements of 9.7% in AP BEV (87.2%)\nand 20.1% in AP 3D (73.6%) in object detection at IoU=0.5, while requiring a\nlow computational cost. The code will be available at\nhttps://github.com/kaist-avelab/K-Radar.",
      "tldr_zh": "该论文提出了一种可用性感知传感器融合方法（ASF），针对 Camera、LiDAR 和 4D Radar 的融合问题，解决了现有方法对传感器退化或故障的脆弱性，并通过统一规范投影（UCP）实现传感器特征的统一表示。ASF 还引入了跨传感器按补丁的交叉注意力（CASAP），以提升融合的鲁棒性和计算效率。在 K-Radar 数据集上的实验显示，ASF 在各种天气条件下显著提高了物体检测性能，AP BEV 提升 9.7%（达 87.2%），AP 3D 提升 20.1%（达 73.6%） at IoU=0.5，同时保持低计算成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Arxiv preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.07029v1",
      "published_date": "2025-03-10 08:10:28 UTC",
      "updated_date": "2025-03-10 08:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:28:13.218529"
    },
    {
      "arxiv_id": "2503.07026v1",
      "title": "Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion Pathways",
      "title_zh": "Erase Diffusion：通过校准扩散路径增强对象移除",
      "authors": [
        "Yi Liu",
        "Hao Zhou",
        "Wenxiang Shang",
        "Ran Lin",
        "Benlei Cui"
      ],
      "abstract": "Erase inpainting, or object removal, aims to precisely remove target objects\nwithin masked regions while preserving the overall consistency of the\nsurrounding content. Despite diffusion-based methods have made significant\nstrides in the field of image inpainting, challenges remain regarding the\nemergence of unexpected objects or artifacts. We assert that the inexact\ndiffusion pathways established by existing standard optimization paradigms\nconstrain the efficacy of object removal. To tackle these challenges, we\npropose a novel Erase Diffusion, termed EraDiff, aimed at unleashing the\npotential power of standard diffusion in the context of object removal. In\ncontrast to standard diffusion, the EraDiff adapts both the optimization\nparadigm and the network to improve the coherence and elimination of the\nerasure results. We first introduce a Chain-Rectifying Optimization (CRO)\nparadigm, a sophisticated diffusion process specifically designed to align with\nthe objectives of erasure. This paradigm establishes innovative diffusion\ntransition pathways that simulate the gradual elimination of objects during\noptimization, allowing the model to accurately capture the intent of object\nremoval. Furthermore, to mitigate deviations caused by artifacts during the\nsampling pathways, we develop a simple yet effective Self-Rectifying Attention\n(SRA) mechanism. The SRA calibrates the sampling pathways by altering\nself-attention activation, allowing the model to effectively bypass artifacts\nwhile further enhancing the coherence of the generated content. With this\ndesign, our proposed EraDiff achieves state-of-the-art performance on the\nOpenImages V5 dataset and demonstrates significant superiority in real-world\nscenarios.",
      "tldr_zh": "本研究针对图像修复中的对象移除（Erase inpainting）问题，提出了一种名为Erase Diffusion（EraDiff）的框架，通过校准扩散路径来精确消除目标对象，同时保持周围内容的整体一致性。\nEraDiff 改进了标准优化范式，引入了Chain-Rectifying Optimization (CRO)来模拟对象逐步消除的扩散过程，以及Self-Rectifying Attention (SRA)机制来调整自注意力激活，减少采样路径中的伪影并提升生成内容的连贯性。\n实验结果表明，EraDiff 在OpenImages V5数据集上实现了最先进性能，并在真实场景中表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07026v1",
      "published_date": "2025-03-10 08:06:51 UTC",
      "updated_date": "2025-03-10 08:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:28:23.598256"
    },
    {
      "arxiv_id": "2503.07025v1",
      "title": "Weak Supervision for Improved Precision in Search Systems",
      "title_zh": "弱监督用于改进搜索系统的精确度",
      "authors": [
        "Sriram Vasudevan"
      ],
      "abstract": "Labeled datasets are essential for modern search engines, which increasingly\nrely on supervised learning methods like Learning to Rank and massive amounts\nof data to power deep learning models. However, creating these datasets is both\ntime-consuming and costly, leading to the common use of user click and activity\nlogs as proxies for relevance. In this paper, we present a weak supervision\napproach to infer the quality of query-document pairs and apply it within a\nLearning to Rank framework to enhance the precision of a large-scale search\nsystem.",
      "tldr_zh": "现代搜索引擎依赖于标记数据集来支持监督学习方法，如 Learning to Rank 和深度学习模型，但创建这些数据集耗时且昂贵，通常使用用户点击和活动日志作为相关性代理。  \n本文提出了一种 Weak Supervision 方法，用于推断查询-文档对的质量，并将其整合到 Learning to Rank 框架中。  \n通过这一方法，该研究提升了大规模搜索系统的精确度，为减少数据标注成本提供了可行解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to the AAAI 2025 Workshop on Computational Jobs Marketplace",
      "pdf_url": "http://arxiv.org/pdf/2503.07025v1",
      "published_date": "2025-03-10 08:06:30 UTC",
      "updated_date": "2025-03-10 08:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:28:34.867080"
    },
    {
      "arxiv_id": "2503.07020v1",
      "title": "Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense",
      "title_zh": "利用多模态 LLM 常识对抗自动驾驶中的部分感知缺陷",
      "authors": [
        "Yuting Hu",
        "Chenhui Xu",
        "Ruiyang Qin",
        "Dancheng Liu",
        "Amir Nassereldine",
        "Yiyu Shi",
        "Jinjun Xiong"
      ],
      "abstract": "Partial perception deficits can compromise autonomous vehicle safety by\ndisrupting environmental understanding. Current protocols typically respond\nwith immediate stops or minimal-risk maneuvers, worsening traffic flow and\nlacking flexibility for rare driving scenarios. In this paper, we propose\nLLM-RCO, a framework leveraging large language models to integrate human-like\ndriving commonsense into autonomous systems facing perception deficits. LLM-RCO\nfeatures four key modules: hazard inference, short-term motion planner, action\ncondition verifier, and safety constraint generator. These modules interact\nwith the dynamic driving environment, enabling proactive and context-aware\ncontrol actions to override the original control policy of autonomous agents.\nTo improve safety in such challenging conditions, we construct DriveLM-Deficit,\na dataset of 53,895 video clips featuring deficits of safety-critical objects,\ncomplete with annotations for LLM-based hazard inference and motion planning\nfine-tuning. Extensive experiments in adverse driving conditions with the CARLA\nsimulator demonstrate that systems equipped with LLM-RCO significantly improve\ndriving performance, highlighting its potential for enhancing autonomous\ndriving resilience against adverse perception deficits. Our results also show\nthat LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements\ninstead of conservative stops in the context of perception deficits.",
      "tldr_zh": "本研究针对自动驾驶中的部分感知缺陷问题，提出LLM-RCO框架，该框架利用多模态大型语言模型（LLMs）整合人类般的驾驶常识，实现主动的上下文感知控制，以提升系统安全和灵活性。LLM-RCO包括四个关键模块：危险推断、短期运动规划、动作条件验证器和安全约束生成器，这些模块与动态驾驶环境互动，覆盖原控制策略。研究构建了DriveLM-Deficit数据集，包含53,895个视频剪辑，用于LLMs的危险推断和运动规划微调。在CARLA模拟器中的实验显示，配备LLM-RCO的系统显著提高了驾驶性能，促进更主动的运动而非保守停车。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07020v1",
      "published_date": "2025-03-10 08:01:41 UTC",
      "updated_date": "2025-03-10 08:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:28:47.892108"
    },
    {
      "arxiv_id": "2503.07678v1",
      "title": "Using a single actor to output personalized policy for different intersections",
      "title_zh": "翻译失败",
      "authors": [
        "Kailing Zhou",
        "Chengwei Zhang",
        "Furui Zhan",
        "Wanting Liu",
        "Yihong Li"
      ],
      "abstract": "Recently, with the development of Multi-agent reinforcement learning (MARL),\nadaptive traffic signal control (ATSC) has achieved satisfactory results. In\ntraffic scenarios with multiple intersections, MARL treats each intersection as\nan agent and optimizes traffic signal control strategies through learning and\nreal-time decision-making. Considering that observation distributions of\nintersections might be different in real-world scenarios, shared parameter\nmethods might lack diversity and thus lead to high generalization requirements\nin the shared-policy network. A typical solution is to increase the size of\nnetwork parameters. However, simply increasing the scale of the network does\nnot necessarily improve policy generalization, which is validated in our\nexperiments. Accordingly, an approach that considers both the personalization\nof intersections and the efficiency of parameter sharing is required. To this\nend, we propose Hyper-Action Multi-Head Proximal Policy Optimization\n(HAMH-PPO), a Centralized Training with Decentralized Execution (CTDE) MARL\nmethod that utilizes a shared PPO policy network to deliver personalized\npolicies for intersections with non-iid observation distributions. The\ncentralized critic in HAMH-PPO uses graph attention units to calculate the\ngraph representations of all intersections and outputs a set of value estimates\nwith multiple output heads for each intersection. The decentralized execution\nactor takes the local observation history as input and output distributions of\naction as well as a so-called hyper-action to balance the multiple values\nestimated from the centralized critic to further guide the updating of TSC\npolicies. The combination of hyper-action and multi-head values enables\nmultiple agents to share a single actor-critic while achieving personalized\npolicies.",
      "tldr_zh": "该研究针对多智能体强化学习(MARL)在自适应交通信号控制(ATSC)中的应用，解决了多个交叉口观察分布不同导致的共享策略泛化问题。论文提出Hyper-Action Multi-Head Proximal Policy Optimization (HAMH-PPO)，一种Centralized Training with Decentralized Execution (CTDE)方法，使用共享的PPO策略网络为每个交叉口生成个性化策略。集中式评论者通过图注意力单位计算交叉口图表示并输出多头价值估计，而分散式执行者基于本地观察历史输出动作分布和hyper-action，以平衡价值估计并优化策略更新。该方法实现了参数共享下的个性化策略，提高了MARL在复杂交通场景中的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07678v1",
      "published_date": "2025-03-10 07:55:33 UTC",
      "updated_date": "2025-03-10 07:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:28:59.334390"
    },
    {
      "arxiv_id": "2503.07004v1",
      "title": "NukesFormers: Unpaired Hyperspectral Image Generation with Non-Uniform Domain Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaojiao Li",
        "Shiyao Duan",
        "Haitao XU",
        "Rui Song"
      ],
      "abstract": "The inherent difficulty in acquiring accurately co-registered\nRGB-hyperspectral image (HSI) pairs has significantly impeded the practical\ndeployment of current data-driven Hyperspectral Image Generation (HIG) networks\nin engineering applications. Gleichzeitig, the ill-posed nature of the aligning\nconstraints, compounded with the complexities of mining cross-domain features,\nalso hinders the advancement of unpaired HIG (UnHIG) tasks. In this paper, we\nconquer these challenges by modeling the UnHIG to range space interaction and\ncompensations of null space through Range-Null Space Decomposition (RND)\nmethodology. Specifically, the introduced contrastive learning effectively\naligns the geometric and spectral distributions of unpaired data by building\nthe interaction of range space, considering the consistent feature in\ndegradation process. Following this, we map the frequency representations of\ndual-domain input and thoroughly mining the null space, like degraded and\nhigh-frequency components, through the proposed Non-uniform Kolmogorov-Arnold\nNetworks. Extensive comparative experiments demonstrate that it establishes a\nnew benchmark in UnHIG.",
      "tldr_zh": "该论文解决了高光谱图像生成（HIG）中获取准确配准的 RGB-高光谱图像（HSI）对的困难，以及未配对 HIG（UnHIG）任务的跨域特征对齐挑战。作者引入了 Range-Null Space Decomposition (RND) 方法，通过对比学习构建范围空间交互，以对齐未配对数据的几何和光谱分布。接着，他们使用 Non-uniform Kolmogorov-Arnold Networks 映射双域输入的频率表示，并挖掘空域（如退化和高频组件）以实现非均匀域对齐。实验结果显示，该方法在 UnHIG 任务中建立了新的基准性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07004v1",
      "published_date": "2025-03-10 07:38:46 UTC",
      "updated_date": "2025-03-10 07:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:29:11.432283"
    },
    {
      "arxiv_id": "2503.07677v2",
      "title": "PLADIS: Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Kwanyoung Kim",
        "Byeongsu Sim"
      ],
      "abstract": "Diffusion models have shown impressive results in generating high-quality\nconditional samples using guidance techniques such as Classifier-Free Guidance\n(CFG). However, existing methods often require additional training or neural\nfunction evaluations (NFEs), making them incompatible with guidance-distilled\nmodels. Also, they rely on heuristic approaches that need identifying target\nlayers. In this work, we propose a novel and efficient method, termed PLADIS,\nwhich boosts pre-trained models (U-Net/Transformer) by leveraging sparse\nattention. Specifically, we extrapolate query-key correlations using softmax\nand its sparse counterpart in the cross-attention layer during inference,\nwithout requiring extra training or NFEs. By leveraging the noise robustness of\nsparse attention, our PLADIS unleashes the latent potential of text-to-image\ndiffusion models, enabling them to excel in areas where they once struggled\nwith newfound effectiveness. It integrates seamlessly with guidance techniques,\nincluding guidance-distilled models. Extensive experiments show notable\nimprovements in text alignment and human preference, offering a highly\nefficient and universally applicable solution. See Our project page :\nhttps://cubeyoung.github.io/pladis-proejct/",
      "tldr_zh": "本研究提出PLADIS，一种新型方法，通过利用稀疏注意力(Sparse Attention)在推理阶段提升扩散模型(Diffusion Models)的性能，而无需额外训练或神经函数评估(NFEs)。PLADIS在交叉注意力层中外推查询-键相关性，使用softmax及其稀疏版本，充分利用稀疏注意力的噪声鲁棒性，使文本到图像模型在文本对齐和生成质量上获得显著改善。实验结果显示，与现有方法相比，PLADIS显著提升了文本对齐和人类偏好，同时与Classifier-Free Guidance (CFG)和其他指导技术无缝集成，提供了一个高效且通用的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 19 figures, project page :\n  https://cubeyoung.github.io/pladis-proejct/",
      "pdf_url": "http://arxiv.org/pdf/2503.07677v2",
      "published_date": "2025-03-10 07:23:19 UTC",
      "updated_date": "2025-03-16 14:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:29:23.347069"
    },
    {
      "arxiv_id": "2503.06987v1",
      "title": "Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Jiho Jin",
        "Woosung Kang",
        "Junho Myung",
        "Alice Oh"
      ],
      "abstract": "Measuring social bias in large language models (LLMs) is crucial, but\nexisting bias evaluation methods struggle to assess bias in long-form\ngeneration. We propose a Bias Benchmark for Generation (BBG), an adaptation of\nthe Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form\ngeneration by having LLMs generate continuations of story prompts. Building our\nbenchmark in English and Korean, we measure the probability of neutral and\nbiased generations across ten LLMs. We also compare our long-form story\ngeneration evaluation results with multiple-choice BBQ evaluation, showing that\nthe two approaches produce inconsistent results.",
      "tldr_zh": "该研究提出了一种新的 Bias Benchmark for Generation (BBG) 基准，用于评估大型语言模型 (LLMs) 在长形式生成中的社会偏见，该基准是 Bias Benchmark for QA (BBQ) 的改编版，通过让 LLMs 生成故事提示的延续来测量中性与偏见生成概率。基准覆盖英语和韩语，并在十个 LLMs 上进行了测试。结果显示，BBG 的长形式生成评估与多项选择式的 BBQ 评估产生不一致的结果，强调了评估方法对偏见测量的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06987v1",
      "published_date": "2025-03-10 07:06:47 UTC",
      "updated_date": "2025-03-10 07:06:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:29:35.440436"
    },
    {
      "arxiv_id": "2503.06982v1",
      "title": "Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqing Xu",
        "Hancheng Min",
        "Lachlan Ewen MacDonald",
        "Jinqi Luo",
        "Salma Tarmoun",
        "Enrique Mallada",
        "Rene Vidal"
      ],
      "abstract": "Despite the empirical success of Low-Rank Adaptation (LoRA) in fine-tuning\npre-trained models, there is little theoretical understanding of how\nfirst-order methods with carefully crafted initialization adapt models to new\ntasks. In this work, we take the first step towards bridging this gap by\ntheoretically analyzing the learning dynamics of LoRA for matrix factorization\n(MF) under gradient flow (GF), emphasizing the crucial role of initialization.\nFor small initialization, we theoretically show that GF converges to a\nneighborhood of the optimal solution, with smaller initialization leading to\nlower final error. Our analysis shows that the final error is affected by the\nmisalignment between the singular spaces of the pre-trained model and the\ntarget matrix, and reducing the initialization scale improves alignment. To\naddress this misalignment, we propose a spectral initialization for LoRA in MF\nand theoretically prove that GF with small spectral initialization converges to\nthe fine-tuning task with arbitrary precision. Numerical experiments from MF\nand image classification validate our findings.",
      "tldr_zh": "本研究从梯度流（gradient flow）的视角，分析了Low-Rank Adaptation (LoRA)在矩阵因子分解（matrix factorization）中的学习动态，强调初始化策略的重要性。研究发现，对于小初始化，gradient flow可收敛到最优解的邻域，且更小的初始化规模能降低最终错误，同时受预训练模型和目标矩阵奇异空间不对齐的影响。作者提出了一种谱初始化（spectral initialization）方法，并证明其能使gradient flow精确适应微调任务。数值实验在矩阵因子分解和图像分类任务中验证了这些理论发现，提升了对LoRA微调机制的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06982v1",
      "published_date": "2025-03-10 06:57:10 UTC",
      "updated_date": "2025-03-10 06:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:29:49.225067"
    },
    {
      "arxiv_id": "2503.06978v1",
      "title": "Lightweight Multimodal Artificial Intelligence Framework for Maritime Multi-Scene Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Xi",
        "Hua Yang",
        "Shentai Zhang",
        "Yijie Liu",
        "Sijin Sun",
        "Xiuju Fu"
      ],
      "abstract": "Maritime Multi-Scene Recognition is crucial for enhancing the capabilities of\nintelligent marine robotics, particularly in applications such as marine\nconservation, environmental monitoring, and disaster response. However, this\ntask presents significant challenges due to environmental interference, where\nmarine conditions degrade image quality, and the complexity of maritime scenes,\nwhich requires deeper reasoning for accurate recognition. Pure vision models\nalone are insufficient to address these issues. To overcome these limitations,\nwe propose a novel multimodal Artificial Intelligence (AI) framework that\nintegrates image data, textual descriptions and classification vectors\ngenerated by a Multimodal Large Language Model (MLLM), to provide richer\nsemantic understanding and improve recognition accuracy. Our framework employs\nan efficient multimodal fusion mechanism to further enhance model robustness\nand adaptability in complex maritime environments. Experimental results show\nthat our model achieves 98$\\%$ accuracy, surpassing previous SOTA models by\n3.5$\\%$. To optimize deployment on resource-constrained platforms, we adopt\nactivation-aware weight quantization (AWQ) as a lightweight technique, reducing\nthe model size to 68.75MB with only a 0.5$\\%$ accuracy drop while significantly\nlowering computational overhead. This work provides a high-performance solution\nfor real-time maritime scene recognition, enabling Autonomous Surface Vehicles\n(ASVs) to support environmental monitoring and disaster response in\nresource-limited settings.",
      "tldr_zh": "该研究针对海洋多场景识别面临的挑战，如环境干扰和场景复杂性，提出了一种轻量级多模态人工智能框架，以提升智能海洋机器人在海洋保护、环境监测和灾害响应中的能力。该框架整合图像数据、文本描述以及由 Multimodal Large Language Model (MLLM) 生成的分类向量，通过高效的多模态融合机制提供更丰富的语义理解，并提高模型在复杂海洋环境中的鲁棒性和适应性。实验结果显示，该模型准确率达到98%，比现有SOTA模型高出3.5%。此外，通过采用activation-aware weight quantization (AWQ)技术，该框架将模型大小减小至68.75MB，仅损失0.5%准确率，同时显著降低计算开销，使其适用于资源受限的Autonomous Surface Vehicles (ASVs)进行实时场景识别。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 4 figures, submitted to Engineering Applications of\n  Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2503.06978v1",
      "published_date": "2025-03-10 06:47:38 UTC",
      "updated_date": "2025-03-10 06:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:30:01.990109"
    },
    {
      "arxiv_id": "2503.06973v1",
      "title": "A Multimodal Benchmark Dataset and Model for Crop Disease Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Liu",
        "Zhaoxiang Liu",
        "Huan Hu",
        "Zezhou Chen",
        "Kohou Wang",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "While conversational generative AI has shown considerable potential in\nenhancing decision-making for agricultural professionals, its exploration has\npredominantly been anchored in text-based interactions. The evolution of\nmultimodal conversational AI, leveraging vast amounts of image-text data from\ndiverse sources, marks a significant stride forward. However, the application\nof such advanced vision-language models in the agricultural domain,\nparticularly for crop disease diagnosis, remains underexplored. In this work,\nwe present the crop disease domain multimodal (CDDM) dataset, a pioneering\nresource designed to advance the field of agricultural research through the\napplication of multimodal learning techniques. The dataset comprises 137,000\nimages of various crop diseases, accompanied by 1 million question-answer pairs\nthat span a broad spectrum of agricultural knowledge, from disease\nidentification to management practices. By integrating visual and textual data,\nCDDM facilitates the development of sophisticated question-answering systems\ncapable of providing precise, useful advice to farmers and agricultural\nprofessionals. We demonstrate the utility of the dataset by finetuning\nstate-of-the-art multimodal models, showcasing significant improvements in crop\ndisease diagnosis. Specifically, we employed a novel finetuning strategy that\nutilizes low-rank adaptation (LoRA) to finetune the visual encoder, adapter and\nlanguage model simultaneously. Our contributions include not only the dataset\nbut also a finetuning strategy and a benchmark to stimulate further research in\nagricultural technology, aiming to bridge the gap between advanced AI\ntechniques and practical agricultural applications. The dataset is available at\nhttps: //github.com/UnicomAI/UnicomBenchmark/tree/main/CDDMBench.",
      "tldr_zh": "这篇论文介绍了 CDDM 数据集，一个多模态基准资源，包含 137,000 张作物病害图像和 1 百万问答对，旨在提升农业领域的视觉-文本学习应用。研究者采用低秩适配 (LoRA) 技术同时微调视觉编码器、适配器和语言模型，显著提高了多模态模型在作物病害诊断的性能。总体贡献包括提供数据集、微调策略和基准，促进 AI 与农业实践的融合。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024 (14 pages, 8 figures)",
      "pdf_url": "http://arxiv.org/pdf/2503.06973v1",
      "published_date": "2025-03-10 06:37:42 UTC",
      "updated_date": "2025-03-10 06:37:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:30:14.550812"
    },
    {
      "arxiv_id": "2503.07676v1",
      "title": "The Janus Face of Innovation: Global Disparities and Divergent Options",
      "title_zh": "翻译失败",
      "authors": [
        "Nihat Mugurtay"
      ],
      "abstract": "This article examines how unequal access to AI innovation creates systemic\nchallenges for developing countries. Differential access to AI innovation\nresults from the acute competition between domestic and global actors. While\ndeveloping nations contribute significantly to AI development through data\nannotation labor, they face limited access to advanced AI technologies and are\nincreasingly caught between divergent regulatory approaches from democratic and\nauthoritarian tendencies. This brief paper analyzes how more affordable AI\nengagement and Western countries' development cooperation present developing\nnations with a complex choice between accessibility and governance standards. I\nargue this challenge entails new institutional mechanisms for technology\ntransfer and regulatory cooperation, while carefully balancing universal\nstandards with local needs. In turn, good practices could help developing\ncountries close the deepening gap of global technological divides, while\nensuring responsible AI development in developing countries.",
      "tldr_zh": "这篇文章探讨了AI创新的不平等访问如何给发展中国家带来系统性挑战，这些国家尽管通过数据标注劳动贡献于AI发展，却在先进技术获取和监管方法分歧（如民主 vs. 专制倾向）中处于劣势。论文分析了更实惠的AI参与以及西方国家的发展合作，为发展中国家提供了在可访问性与治理标准之间权衡的复杂选择。作者主张建立新的制度机制来促进技术转移和监管合作，以平衡通用标准和本地需求，从而帮助缩小全球技术差距并确保AI在发展中国家的负责任发展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.07676v1",
      "published_date": "2025-03-10 06:33:07 UTC",
      "updated_date": "2025-03-10 06:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:30:25.165080"
    },
    {
      "arxiv_id": "2503.06963v1",
      "title": "Multi-Behavior Recommender Systems: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungho Kim",
        "Sunwoo Kim",
        "Geon Lee",
        "Jinhong Jung",
        "Kijung Shin"
      ],
      "abstract": "Traditional recommender systems primarily rely on a single type of user-item\ninteraction, such as item purchases or ratings, to predict user preferences.\nHowever, in real-world scenarios, users engage in a variety of behaviors, such\nas clicking on items or adding them to carts, offering richer insights into\ntheir interests. Multi-behavior recommender systems leverage these diverse\ninteractions to enhance recommendation quality, and research on this topic has\ngrown rapidly in recent years. This survey provides a timely review of\nmulti-behavior recommender systems, focusing on three key steps: (1) Data\nModeling: representing multi-behaviors at the input level, (2) Encoding:\ntransforming these inputs into vector representations (i.e., embeddings), and\n(3) Training: optimizing machine-learning models. We systematically categorize\nexisting multi-behavior recommender systems based on the commonalities and\ndifferences in their approaches across the above steps. Additionally, we\ndiscuss promising future directions for advancing multi-behavior recommender\nsystems.",
      "tldr_zh": "这篇调查综述探讨了多-behavior recommender systems，这些系统利用用户多种互动（如点击、添加购物车）来提升推荐质量，相比传统依赖单一互动（如购买或评分）的推荐系统更具优势。论文聚焦于三个关键步骤：(1) Data Modeling，用于表示多行为输入；(2) Encoding，将这些输入转化为向量表示（如 embeddings）；以及(3) Training，优化 machine-learning models。作者系统地分类了现有方法，突出了研究领域的快速发展，并讨论了未来改进方向，如更先进的模型设计。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted in the PAKDD 2025 Survey Track",
      "pdf_url": "http://arxiv.org/pdf/2503.06963v1",
      "published_date": "2025-03-10 06:22:37 UTC",
      "updated_date": "2025-03-10 06:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:30:36.653735"
    },
    {
      "arxiv_id": "2503.06962v1",
      "title": "Capture Global Feature Statistics for One-Shot Federated Learning",
      "title_zh": "为单次联邦学习捕获全局",
      "authors": [
        "Zenghao Guan",
        "Yucan Zhou",
        "Xiaoyan Gu"
      ],
      "abstract": "Traditional Federated Learning (FL) necessitates numerous rounds of\ncommunication between the server and clients, posing significant challenges\nincluding high communication costs, connection drop risks and susceptibility to\nprivacy attacks. One-shot FL has become a compelling learning paradigm to\novercome above drawbacks by enabling the training of a global server model via\na single communication round. However, existing one-shot FL methods suffer from\nexpensive computation cost on the server or clients and cannot deal with\nnon-IID (Independent and Identically Distributed) data stably and effectively.\nTo address these challenges, this paper proposes FedCGS, a novel Federated\nlearning algorithm that Capture Global feature Statistics leveraging\npre-trained models. With global feature statistics, we achieve training-free\nand heterogeneity-resistant one-shot FL. Furthermore, we extend its application\nto personalization scenario, where clients only need execute one extra\ncommunication round with server to download global statistics. Extensive\nexperimental results demonstrate the effectiveness of our methods across\ndiverse data heterogeneity settings. Code is available at\nhttps://github.com/Yuqin-G/FedCGS.",
      "tldr_zh": "本文提出 FedCGS，一种新型联邦学习（Federated Learning, FL）算法，通过利用预训练模型捕获全局特征统计，实现训练-free 和抗异质性的 one-shot FL，从而解决传统 FL 的高通信成本和非 IID 数据处理问题。FedCGS 仅需单轮通信即可训练全局服务器模型，并在个性化场景中只需额外一轮通信即可应用。实验结果证明，该方法在多种数据异质性设置下表现出色，提升了 FL 的效率和鲁棒性。代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06962v1",
      "published_date": "2025-03-10 06:20:39 UTC",
      "updated_date": "2025-03-10 06:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:30:50.206558"
    },
    {
      "arxiv_id": "2503.07675v1",
      "title": "DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Junwei Yu",
        "Yepeng Ding",
        "Hiroyuki Sato"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) in Multi-Agent Systems (MAS)\nhas opened new possibilities for artificial intelligence, yet current\nimplementations face significant challenges in resource management, task\ncoordination, and system efficiency. While existing frameworks demonstrate the\npotential of LLM-based agents in collaborative problem-solving, they often lack\nsophisticated mechanisms for parallel execution and dynamic task management.\nThis paper introduces DynTaskMAS, a novel framework that orchestrates\nasynchronous and parallel operations in LLM-based MAS through dynamic task\ngraphs. The framework features four key innovations: (1) a Dynamic Task Graph\nGenerator that intelligently decomposes complex tasks while maintaining logical\ndependencies, (2) an Asynchronous Parallel Execution Engine that optimizes\nresource utilization through efficient task scheduling, (3) a Semantic-Aware\nContext Management System that enables efficient information sharing among\nagents, and (4) an Adaptive Workflow Manager that dynamically optimizes system\nperformance. Experimental evaluations demonstrate that DynTaskMAS achieves\nsignificant improvements over traditional approaches: a 21-33% reduction in\nexecution time across task complexities (with higher gains for more complex\ntasks), a 35.4% improvement in resource utilization (from 65% to 88%), and\nnear-linear throughput scaling up to 16 concurrent agents (3.47X improvement\nfor 4X agents). Our framework establishes a foundation for building scalable,\nhigh-performance LLM-based multi-agent systems capable of handling complex,\ndynamic tasks efficiently.",
      "tldr_zh": "本文提出 DynTaskMAS，一种基于动态任务图的框架，用于提升 LLM-based Multi-Agent Systems (MAS) 在资源管理、任务协调和系统效率方面的性能。该框架包括四个关键创新：Dynamic Task Graph Generator 用于智能分解复杂任务并维护逻辑依赖、Asynchronous Parallel Execution Engine 通过高效调度优化资源利用、Semantic-Aware Context Management System 实现代理间高效信息共享，以及 Adaptive Workflow Manager 动态优化系统工作流。实验结果显示，DynTaskMAS 在不同任务复杂度下将执行时间减少 21-33%，资源利用率提升 35.4%（从 65% 到 88%），并实现近线性吞吐量扩展，支持多达 16 个并发代理（4 倍代理带来 3.47 倍改进），为构建可扩展的高性能 MAS 奠定基础。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07675v1",
      "published_date": "2025-03-10 06:16:10 UTC",
      "updated_date": "2025-03-10 06:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:31:01.724133"
    },
    {
      "arxiv_id": "2503.06951v1",
      "title": "ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Xinjie",
        "Fan Gao",
        "Rui Yang",
        "Yingjian Chen",
        "Yuyang Wang",
        "Ying Zhu",
        "Jiacheng Tang",
        "Irene Li"
      ],
      "abstract": "Recent advances in large language models (LLMs) have significantly improved\nmulti-hop question answering (QA) through direct Chain-of-Thought (CoT)\nreasoning. However, the irreversible nature of CoT leads to error accumulation,\nmaking it challenging to correct mistakes in multi-hop reasoning. This paper\nintroduces ReAgent: a Reversible multi-Agent collaborative framework augmented\nwith explicit backtracking mechanisms, enabling reversible multi-hop reasoning.\nBy incorporating text-based retrieval, information aggregation and validation,\nour system can detect and correct errors mid-reasoning, leading to more robust\nand interpretable QA outcomes. The framework and experiments serve as a\nfoundation for future work on error-tolerant QA systems. Empirical evaluations\nacross three benchmarks indicate ReAgent's efficacy, yielding average about 6\\%\nimprovements against baseline models.",
      "tldr_zh": "这篇论文提出了 ReAgent，一种可逆的多智能体推理框架，用于知识增强的多跳问答 (Multi-Hop QA)，以解决 Chain-of-Thought (CoT) 推理的不可逆性导致的错误积累问题。ReAgent 通过整合文本检索、信息聚合和验证机制，实现推理过程中的错误检测和纠正，从而提升 QA 系统的鲁棒性和可解释性。实验在三个基准上显示，该框架比基线模型平均提高了约 6%，为未来错误容忍的 QA 系统奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06951v1",
      "published_date": "2025-03-10 05:56:46 UTC",
      "updated_date": "2025-03-10 05:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:31:13.608279"
    },
    {
      "arxiv_id": "2503.06948v1",
      "title": "Large Language Model Guided Progressive Feature Alignment for Multimodal UAV Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Wu",
        "Chenglong Li",
        "Xiao Wang",
        "Bin Luo",
        "Qi Liu"
      ],
      "abstract": "Existing multimodal UAV object detection methods often overlook the impact of\nsemantic gaps between modalities, which makes it difficult to achieve accurate\nsemantic and spatial alignments, limiting detection performance. To address\nthis problem, we propose a Large Language Model (LLM) guided Progressive\nfeature Alignment Network called LPANet, which leverages the semantic features\nextracted from a large language model to guide the progressive semantic and\nspatial alignment between modalities for multimodal UAV object detection. To\nemploy the powerful semantic representation of LLM, we generate the\nfine-grained text descriptions of each object category by ChatGPT and then\nextract the semantic features using the large language model MPNet. Based on\nthe semantic features, we guide the semantic and spatial alignments in a\nprogressive manner as follows. First, we design the Semantic Alignment Module\n(SAM) to pull the semantic features and multimodal visual features of each\nobject closer, alleviating the semantic differences of objects between\nmodalities. Second, we design the Explicit Spatial alignment Module (ESM) by\nintegrating the semantic relations into the estimation of feature-level\noffsets, alleviating the coarse spatial misalignment between modalities.\nFinally, we design the Implicit Spatial alignment Module (ISM), which leverages\nthe cross-modal correlations to aggregate key features from neighboring regions\nto achieve implicit spatial alignment. Comprehensive experiments on two public\nmultimodal UAV object detection datasets demonstrate that our approach\noutperforms state-of-the-art multimodal UAV object detectors.",
      "tldr_zh": "该论文提出了一种名为LPANet的渐进式特征对齐网络，使用Large Language Model (LLM)指导多模态UAV对象检测，以解决模态间语义和空间差距导致的检测性能问题。具体方法包括利用ChatGPT生成对象类别的细粒度文本描述，并通过MPNet提取语义特征，然后设计Semantic Alignment Module (SAM)拉近语义特征与视觉特征、Explicit Spatial Alignment Module (ESM)整合语义关系进行显式空间对齐，以及Implicit Spatial Alignment Module (ISM)利用跨模态相关性实现隐式空间对齐。在两个公开的多模态UAV对象检测数据集上的实验表明，该方法优于现有最先进检测器。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06948v1",
      "published_date": "2025-03-10 05:53:30 UTC",
      "updated_date": "2025-03-10 05:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:31:29.017731"
    },
    {
      "arxiv_id": "2503.08712v1",
      "title": "SHAP-Integrated Convolutional Diagnostic Networks for Feature-Selective Medical Analysis",
      "title_zh": "SHAP 集成的卷积诊断网络用于特征选择性医疗分析",
      "authors": [
        "Yan Hu",
        "Ahmad Chaddad"
      ],
      "abstract": "This study introduces the SHAP-integrated convolutional diagnostic network\n(SICDN), an interpretable feature selection method designed for limited\ndatasets, to address the challenge posed by data privacy regulations that\nrestrict access to medical datasets. The SICDN model was tested on\nclassification tasks using pneumonia and breast cancer datasets, demonstrating\nover 97% accuracy and surpassing four popular CNN models. We also integrated a\nhistorical weighted moving average technique to enhance feature selection. The\nSICDN shows potential in medical image prediction, with the code available on\nhttps://github.com/AIPMLab/SICDN.",
      "tldr_zh": "这篇论文提出了 SHAP-integrated convolutional diagnostic network (SICDN)，一种可解释的特征选择方法，旨在解决数据隐私法规限制下医疗数据集访问挑战。SICDN 通过整合 SHAP 和历史加权移动平均技术，在肺炎和乳腺癌数据集的分类任务中实现了超过 97% 的准确率，并优于四个流行 CNN 模型。研究展示了 SICDN 在医疗图像预测中的潜力，并提供了开源代码（https://github.com/AIPMLab/SICDN）。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.08712v1",
      "published_date": "2025-03-10 05:48:35 UTC",
      "updated_date": "2025-03-10 05:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:31:37.675832"
    },
    {
      "arxiv_id": "2503.06926v1",
      "title": "Effect of Selection Format on LLM Performance",
      "title_zh": "选择格式对LLM性能的影响",
      "authors": [
        "Yuchen Han",
        "Yucheng Wu",
        "Jeffrey Willard"
      ],
      "abstract": "This paper investigates a critical aspect of large language model (LLM)\nperformance: the optimal formatting of classification task options in prompts.\nThrough an extensive experimental study, we compared two selection formats --\nbullet points and plain English -- to determine their impact on model\nperformance. Our findings suggest that presenting options via bullet points\ngenerally yields better results, although there are some exceptions.\nFurthermore, our research highlights the need for continued exploration of\noption formatting to drive further improvements in model performance.",
      "tldr_zh": "这篇论文探讨了分类任务选项格式对大型语言模型(LLM)性能的影响，通过广泛实验比较了项目符号(bullet points)和纯英文(plain English)两种提示格式。结果显示，使用项目符号通常能提升模型表现，但也存在某些例外。该研究强调了继续探索选项格式以进一步优化LLM性能的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06926v1",
      "published_date": "2025-03-10 05:11:58 UTC",
      "updated_date": "2025-03-10 05:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:31:48.883712"
    },
    {
      "arxiv_id": "2503.06923v1",
      "title": "From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers",
      "title_zh": "翻译失败",
      "authors": [
        "Jiacheng Liu",
        "Chang Zou",
        "Yuanhuiyi Lyu",
        "Junjie Chen",
        "Linfeng Zhang"
      ],
      "abstract": "Diffusion Transformers (DiT) have revolutionized high-fidelity image and\nvideo synthesis, yet their computational demands remain prohibitive for\nreal-time applications. To solve this problem, feature caching has been\nproposed to accelerate diffusion models by caching the features in the previous\ntimesteps and then reusing them in the following timesteps. However, at\ntimesteps with significant intervals, the feature similarity in diffusion\nmodels decreases substantially, leading to a pronounced increase in errors\nintroduced by feature caching, significantly harming the generation quality. To\nsolve this problem, we propose TaylorSeer, which firstly shows that features of\ndiffusion models at future timesteps can be predicted based on their values at\nprevious timesteps. Based on the fact that features change slowly and\ncontinuously across timesteps, TaylorSeer employs a differential method to\napproximate the higher-order derivatives of features and predict features in\nfuture timesteps with Taylor series expansion. Extensive experiments\ndemonstrate its significant effectiveness in both image and video synthesis,\nespecially in high acceleration ratios. For instance, it achieves an almost\nlossless acceleration of 4.99$\\times$ on FLUX and 5.00$\\times$ on HunyuanVideo\nwithout additional training. On DiT, it achieves $3.41$ lower FID compared with\nprevious SOTA at $4.53$$\\times$ acceleration. %Our code is provided in the\nsupplementary materials and will be made publicly available on GitHub. Our\ncodes have been released in Github:https://github.com/Shenyi-Z/TaylorSeer",
      "tldr_zh": "该论文针对Diffusion Transformers (DiT)的高计算需求问题，提出TaylorSeer方法，以加速图像和视频合成。TaylorSeer基于特征在时间步间缓慢连续变化的特性，使用Taylor级数扩展来预测未来时间步的特征，从而避免了传统特征缓存在间隔大时引入的错误。实验结果显示，TaylorSeer在无需额外训练的情况下，实现FLUX上的4.99倍加速和HunyuanVideo上的5.00倍加速；在DiT上，与现有最先进方法相比，FID降低了3.41，显著提升了生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06923v1",
      "published_date": "2025-03-10 05:09:42 UTC",
      "updated_date": "2025-03-10 05:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:32:01.599978"
    },
    {
      "arxiv_id": "2503.08711v1",
      "title": "A Beam Search Based Parallel Algorithm for the Two-Dimensional Strip Packing Problem",
      "title_zh": "基于束搜索的并行算法，用于",
      "authors": [
        "Yajie Wen",
        "Defu Zhang"
      ],
      "abstract": "This paper introduces BSPA, a parallel algorithm that leverages beam search\nto address the two-dimensional strip packing problem. The study begins with a\ncomprehensive review of existing approaches and methodologies, followed by a\ndetailed presentation of the BSPA algorithm. Experimental results demonstrate\nthe effectiveness of the proposed method. To facilitate further research, both\nthe code and datasets are publicly available.",
      "tldr_zh": "这篇论文提出了一种基于 Beam Search 的并行算法 BSPA，用于解决 Two-Dimensional Strip Packing Problem。论文首先回顾了现有方法，然后详细介绍了 BSPA 算法的设计和实现。实验结果证明了该算法的有效性，并公开了代码和数据集以促进进一步研究。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "9 pages,4figures",
      "pdf_url": "http://arxiv.org/pdf/2503.08711v1",
      "published_date": "2025-03-10 04:20:45 UTC",
      "updated_date": "2025-03-10 04:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:32:12.314027"
    },
    {
      "arxiv_id": "2503.06894v2",
      "title": "A Deep Learning Approach for Augmenting Perceptional Understanding of Histopathology Images",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoqian Hu"
      ],
      "abstract": "In Recent Years, Digital Technologies Have Made Significant Strides In\nAugmenting-Human-Health, Cognition, And Perception, Particularly Within The\nField Of Computational-Pathology. This Paper Presents A Novel Approach To\nEnhancing The Analysis Of Histopathology Images By Leveraging A\nMult-modal-Model That Combines Vision Transformers (Vit) With Gpt-2 For Image\nCaptioning. The Model Is Fine-Tuned On The Specialized Arch-Dataset, Which\nIncludes Dense Image Captions Derived From Clinical And Academic Resources, To\nCapture The Complexities Of Pathology Images Such As Tissue Morphologies,\nStaining Variations, And Pathological Conditions. By Generating Accurate,\nContextually Captions, The Model Augments The Cognitive Capabilities Of\nHealthcare Professionals, Enabling More Efficient Disease Classification,\nSegmentation, And Detection. The Model Enhances The Perception Of Subtle\nPathological Features In Images That Might Otherwise Go Unnoticed, Thereby\nImproving Diagnostic Accuracy. Our Approach Demonstrates The Potential For\nDigital Technologies To Augment Human Cognitive Abilities In Medical Image\nAnalysis, Providing Steps Toward More Personalized And Accurate Healthcare\nOutcomes.",
      "tldr_zh": "本研究提出了一种深度学习方法，使用多模态模型结合 Vision Transformers (ViT) 和 GPT-2 来增强组织病理学图像的感知理解。该模型在 Arch-Dataset 上微调，生成精确且上下文相关的图像描述，以捕捉图像中的复杂特征，如组织形态、染色变化和病理条件，从而辅助医疗专业人员更高效地进行疾病分类、分割和检测。结果显示，该方法显著提高了对微妙病理特征的识别精度，并展示了数字技术在提升人类认知能力、实现个性化医疗方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by International Conference on Semantic & Natural Language\n  Processing (SNLP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.06894v2",
      "published_date": "2025-03-10 03:50:25 UTC",
      "updated_date": "2025-03-19 08:18:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:32:25.964796"
    },
    {
      "arxiv_id": "2503.06893v1",
      "title": "Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning",
      "title_zh": "跨动态强化学习中全局可访问状态的策略正则化",
      "authors": [
        "Zhenghai Xue",
        "Lang Feng",
        "Jiacheng Xu",
        "Kang Kang",
        "Xiang Wen",
        "Bo An",
        "Shuicheng Yan"
      ],
      "abstract": "To learn from data collected in diverse dynamics, Imitation from Observation\n(IfO) methods leverage expert state trajectories based on the premise that\nrecovering expert state distributions in other dynamics facilitates policy\nlearning in the current one. However, Imitation Learning inherently imposes a\nperformance upper bound of learned policies. Additionally, as the environment\ndynamics change, certain expert states may become inaccessible, rendering their\ndistributions less valuable for imitation. To address this, we propose a novel\nframework that integrates reward maximization with IfO, employing F-distance\nregularized policy optimization. This framework enforces constraints on\nglobally accessible states--those with nonzero visitation frequency across all\nconsidered dynamics--mitigating the challenge posed by inaccessible states. By\ninstantiating F-distance in different ways, we derive two theoretical analysis\nand develop a practical algorithm called Accessible State Oriented Policy\nRegularization (ASOR). ASOR serves as a general add-on module that can be\nincorporated into various RL approaches, including offline RL and off-policy\nRL. Extensive experiments across multiple benchmarks demonstrate ASOR's\neffectiveness in enhancing state-of-the-art cross-domain policy transfer\nalgorithms, significantly improving their performance.",
      "tldr_zh": "本文提出一种新框架，将奖励最大化与 Imitation from Observation (IfO) 相结合，通过 F-distance 正规化的策略优化，针对跨动态 Reinforcement Learning (RL) 中的全局可访问状态施加约束，从而缓解不可访问状态带来的挑战。该框架基于理论分析，开发了实用算法 Accessible State Oriented Policy Regularization (ASOR)，可作为通用模块整合到 offline RL 和 off-policy RL 等方法中。实验结果显示，ASOR 显著提升了现有跨域策略转移算法的性能，在多个基准上取得了改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.06893v1",
      "published_date": "2025-03-10 03:50:20 UTC",
      "updated_date": "2025-03-10 03:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:32:38.827242"
    },
    {
      "arxiv_id": "2503.07674v1",
      "title": "TVNet: A Novel Time Series Analysis Method Based on Dynamic Convolution and 3D-Variation",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghan Li",
        "Mingchen Li",
        "Ruisheng Diao"
      ],
      "abstract": "With the recent development and advancement of Transformer and MLP\narchitectures, significant strides have been made in time series analysis.\nConversely, the performance of Convolutional Neural Networks (CNNs) in time\nseries analysis has fallen short of expectations, diminishing their potential\nfor future applications. Our research aims to enhance the representational\ncapacity of Convolutional Neural Networks (CNNs) in time series analysis by\nintroducing novel perspectives and design innovations. To be specific, We\nintroduce a novel time series reshaping technique that considers the\ninter-patch, intra-patch, and cross-variable dimensions. Consequently, we\npropose TVNet, a dynamic convolutional network leveraging a 3D perspective to\nemploy time series analysis. TVNet retains the computational efficiency of CNNs\nand achieves state-of-the-art results in five key time series analysis tasks,\noffering a superior balance of efficiency and performance over the\nstate-of-the-art Transformer-based and MLP-based models. Additionally, our\nfindings suggest that TVNet exhibits enhanced transferability and robustness.\nTherefore, it provides a new perspective for applying CNN in advanced time\nseries analysis tasks.",
      "tldr_zh": "该研究针对CNN在时间序列分析中的表现不足，提出了一种新型方法TVNet，该方法基于动态卷积(dynamic convolution)和3D视角(time series reshaping)，考虑inter-patch、intra-patch和cross-variable维度来提升模型的表示能力。TVNet保留了CNN的计算效率，并在五个关键时间序列分析任务中达到了最先进的结果，比Transformer-based和MLP-based模型在效率和性能上实现了更好的平衡。此外，实验显示TVNet具有增强的可转移性(transferability)和鲁棒性(robustness)，为CNN在高级时间序列分析任务中的应用提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.07674v1",
      "published_date": "2025-03-10 03:30:55 UTC",
      "updated_date": "2025-03-10 03:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:32:49.686825"
    },
    {
      "arxiv_id": "2503.06884v1",
      "title": "Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement Cannot Help",
      "title_zh": "文本到图像扩散模型无法计数，且提示词优化无法帮助",
      "authors": [
        "Yuefan Cao",
        "Xuyang Guo",
        "Jiayan Huo",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang",
        "Zhen Zhuang"
      ],
      "abstract": "Generative modeling is widely regarded as one of the most essential problems\nin today's AI community, with text-to-image generation having gained\nunprecedented real-world impacts. Among various approaches, diffusion models\nhave achieved remarkable success and have become the de facto solution for\ntext-to-image generation. However, despite their impressive performance, these\nmodels exhibit fundamental limitations in adhering to numerical constraints in\nuser instructions, frequently generating images with an incorrect number of\nobjects. While several prior works have mentioned this issue, a comprehensive\nand rigorous evaluation of this limitation remains lacking. To address this\ngap, we introduce T2ICountBench, a novel benchmark designed to rigorously\nevaluate the counting ability of state-of-the-art text-to-image diffusion\nmodels. Our benchmark encompasses a diverse set of generative models, including\nboth open-source and private systems. It explicitly isolates counting\nperformance from other capabilities, provides structured difficulty levels, and\nincorporates human evaluations to ensure high reliability.\n  Extensive evaluations with T2ICountBench reveal that all state-of-the-art\ndiffusion models fail to generate the correct number of objects, with accuracy\ndropping significantly as the number of objects increases. Additionally, an\nexploratory study on prompt refinement demonstrates that such simple\ninterventions generally do not improve counting accuracy. Our findings\nhighlight the inherent challenges in numerical understanding within diffusion\nmodels and point to promising directions for future improvements.",
      "tldr_zh": "这篇论文揭示了文本到图像扩散模型在处理用户指令中的数字约束时存在根本缺陷，无法准确生成指定数量的对象。研究者引入了 T2ICountBench 基准，这是一个新颖的评估工具，涵盖多种开源和私有模型，通过隔离计数性能、设置结构化难度级别并结合人类评估来严格测试模型能力。实验结果显示，所有最先进扩散模型的计数准确率随对象数量增加而显著下降，且对 prompt refinement 的探索表明，这种简单干预无法改善性能。论文强调了扩散模型在数字理解方面的固有挑战，并为未来模型改进指出了潜在方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06884v1",
      "published_date": "2025-03-10 03:28:18 UTC",
      "updated_date": "2025-03-10 03:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:33:02.079945"
    },
    {
      "arxiv_id": "2504.10489v1",
      "title": "Roamify: Designing and Evaluating an LLM Based Google Chrome Extension for Personalised Itinerary Planning",
      "title_zh": "Roamify：设计与",
      "authors": [
        "Vikranth Udandarao",
        "Noel Abraham Tiju",
        "Muthuraj Vairamuthu",
        "Harsh Mistry",
        "Dhruv Kumar"
      ],
      "abstract": "In this paper, we present Roamify, an Artificial Intelligence powered travel\nassistant that aims to ease the process of travel planning. We have tested and\nused multiple Large Language Models like Llama and T5 to generate personalised\nitineraries per user preferences. Results from user surveys highlight the\npreference for AI powered mediums over existing methods to help in travel\nplanning across all user age groups. These results firmly validate the\npotential need of such a travel assistant. We highlight the two primary design\nconsiderations for travel assistance: D1) incorporating a web-scraping method\nto gather up-to-date news articles about destinations from various blog\nsources, which significantly improves our itinerary suggestions, and D2)\nutilising user preferences to create customised travel experiences along with a\nrecommendation system which changes the itinerary according to the user needs.\nOur findings suggest that Roamify has the potential to improve and simplify how\nusers across multiple age groups plan their travel experiences.",
      "tldr_zh": "本文介绍了 Roamify，一款基于 LLM 的 Google Chrome Extension，旨在通过 Llama 和 T5 等模型为用户提供个性化的行程规划。系统设计重点包括 D1) 采用网络抓取技术收集实时目的地新闻以提升建议质量，以及 D2) 结合用户偏好和推荐系统生成自定义行程。用户调查结果显示，AI 驱动的方法在不同年龄段用户中更受欢迎，并证明 Roamify 有潜力简化并改善旅行体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "for code implementation, check\n  https://github.com/Roamify-Research/Roamify",
      "pdf_url": "http://arxiv.org/pdf/2504.10489v1",
      "published_date": "2025-03-10 03:14:57 UTC",
      "updated_date": "2025-03-10 03:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:33:14.528019"
    },
    {
      "arxiv_id": "2503.08709v1",
      "title": "Simulating Influence Dynamics with LLM Agents",
      "title_zh": "利用 LLM 代理模拟影响动态",
      "authors": [
        "Mehwish Nasim",
        "Syed Muslim Gilani",
        "Amin Qasmi",
        "Usman Naseem"
      ],
      "abstract": "This paper introduces a simulator designed for opinion dynamics researchers\nto model competing influences within social networks in the presence of\nLLM-based agents. By integrating established opinion dynamics principles with\nstate-of-the-art LLMs, this tool enables the study of influence propagation and\ncounter-misinformation strategies. The simulator is particularly valuable for\nresearchers in social science, psychology, and operations research, allowing\nthem to analyse societal phenomena without requiring extensive coding\nexpertise. Additionally, the simulator will be openly available on GitHub,\nensuring accessibility and adaptability for those who wish to extend its\ncapabilities for their own research.",
      "tldr_zh": "这篇论文提出了一种模拟器，用于研究社会网络中基于LLM代理的竞争影响动态。模拟器通过整合意见动态原则与最先进的LLM，方便研究影响传播和反误信息策略，同时降低了对编码专业知识的要求。针对社会科学、心理学和运筹学领域的研究者，该工具提供易访问的分析手段，并将在GitHub上开源以支持进一步扩展。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "I.2.7; I.6.0"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08709v1",
      "published_date": "2025-03-10 03:05:21 UTC",
      "updated_date": "2025-03-10 03:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:33:27.030089"
    },
    {
      "arxiv_id": "2503.08708v2",
      "title": "TH-Bench: Evaluating Evading Attacks via Humanizing AI Text on Machine-Generated Text Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Zheng",
        "Junfeng Wang",
        "Zhen Sun",
        "Wenhan Dong",
        "Yule Liu",
        "Xinlei He"
      ],
      "abstract": "As Large Language Models (LLMs) advance, Machine-Generated Texts (MGTs) have\nbecome increasingly fluent, high-quality, and informative. Existing wide-range\nMGT detectors are designed to identify MGTs to prevent the spread of plagiarism\nand misinformation. However, adversaries attempt to humanize MGTs to evade\ndetection (named evading attacks), which requires only minor modifications to\nbypass MGT detectors. Unfortunately, existing attacks generally lack a unified\nand comprehensive evaluation framework, as they are assessed using different\nexperimental settings, model architectures, and datasets. To fill this gap, we\nintroduce the Text-Humanization Benchmark (TH-Bench), the first comprehensive\nbenchmark to evaluate evading attacks against MGT detectors. TH-Bench evaluates\nattacks across three key dimensions: evading effectiveness, text quality, and\ncomputational overhead. Our extensive experiments evaluate 6 state-of-the-art\nattacks against 13 MGT detectors across 6 datasets, spanning 19 domains and\ngenerated by 11 widely used LLMs. Our findings reveal that no single evading\nattack excels across all three dimensions. Through in-depth analysis, we\nhighlight the strengths and limitations of different attacks. More importantly,\nwe identify a trade-off among three dimensions and propose two optimization\ninsights. Through preliminary experiments, we validate their correctness and\neffectiveness, offering potential directions for future research.",
      "tldr_zh": "该论文引入了 Text-Humanization Benchmark (TH-Bench)，这是第一个全面基准，用于评估针对机器生成文本 (MGTs) 检测器的逃避攻击 (evading attacks)，这些攻击通过微小修改使 AI 生成文本更像人类以规避检测。TH-Bench 从逃避有效性、文本质量和计算开销三个关键维度评估攻击表现，涵盖 6 种最先进攻击方法、13 个 MGT 检测器、6 个数据集和 11 个大语言模型 (LLMs)。实验发现，没有一种攻击在所有维度上均表现出色，并揭示了维度间的权衡关系，同时提出两点优化见解，并通过初步实验验证其有效性，为未来研究提供方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.08708v2",
      "published_date": "2025-03-10 02:55:05 UTC",
      "updated_date": "2025-03-13 10:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:33:40.946972"
    },
    {
      "arxiv_id": "2503.06873v2",
      "title": "Interactive Medical Image Analysis with Concept-based Similarity Reasoning",
      "title_zh": "基于概念相似性推理的交互式医学图像分析",
      "authors": [
        "Ta Duc Huy",
        "Sen Kim Tran",
        "Phan Nguyen",
        "Nguyen Hoang Tran",
        "Tran Bao Sam",
        "Anton van den Hengel",
        "Zhibin Liao",
        "Johan W. Verjans",
        "Minh-Son To",
        "Vu Minh Hieu Phan"
      ],
      "abstract": "The ability to interpret and intervene model decisions is important for the\nadoption of computer-aided diagnosis methods in clinical workflows. Recent\nconcept-based methods link the model predictions with interpretable concepts\nand modify their activation scores to interact with the model. However, these\nconcepts are at the image level, which hinders the model from pinpointing the\nexact patches the concepts are activated. Alternatively, prototype-based\nmethods learn representations from training image patches and compare these\nwith test image patches, using the similarity scores for final class\nprediction. However, interpreting the underlying concepts of these patches can\nbe challenging and often necessitates post-hoc guesswork. To address this\nissue, this paper introduces the novel Concept-based Similarity Reasoning\nnetwork (CSR), which offers (i) patch-level prototype with intrinsic concept\ninterpretation, and (ii) spatial interactivity. First, the proposed CSR\nprovides localized explanation by grounding prototypes of each concept on image\nregions. Second, our model introduces novel spatial-level interaction, allowing\ndoctors to engage directly with specific image areas, making it an intuitive\nand transparent tool for medical imaging. CSR improves upon prior\nstate-of-the-art interpretable methods by up to 4.5\\% across three biomedical\ndatasets. Our code is released at https://github.com/tadeephuy/InteractCSR.",
      "tldr_zh": "这篇论文针对医疗图像分析的可解释性问题，引入了Concept-based Similarity Reasoning network (CSR)，它结合了patch-level prototype的内在概念解释和spatial interactivity功能，以精确定位图像区域并允许医生直接与特定区域互动。相比现有概念-based和原型-based方法，CSR 通过将原型grounding到图像区域，提供更本地化的解释和更高的交互性。在三个生物医学数据集上，CSR 比最先进的可解释方法提高了多达4.5%的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.06873v2",
      "published_date": "2025-03-10 02:52:47 UTC",
      "updated_date": "2025-03-11 09:06:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:33:51.623971"
    },
    {
      "arxiv_id": "2503.06868v1",
      "title": "Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset, Evaluation Framework, and Mitigation",
      "title_zh": "长文本生成中的",
      "authors": [
        "Junhao Zhang",
        "Richong Zhang",
        "Fanshuang Kong",
        "Ziyang Miao",
        "Yanhan Ye",
        "Yaowei Zheng"
      ],
      "abstract": "Existing long-text generation methods primarily concentrate on producing\nlengthy texts from short inputs, neglecting the long-input and long-output\ntasks. Such tasks have numerous practical applications while lacking available\nbenchmarks. Moreover, as the input grows in length, existing methods inevitably\nencounter the \"lost-in-the-middle\" phenomenon. In this paper, we first\nintroduce a Long Input and Output Benchmark (LongInOutBench), including a\nsynthetic dataset and a comprehensive evaluation framework, addressing the\nchallenge of the missing benchmark. We then develop the Retrieval-Augmented\nLong-Text Writer (RAL-Writer), which retrieves and restates important yet\noverlooked content, mitigating the \"lost-in-the-middle\" issue by constructing\nexplicit prompts. We finally employ the proposed LongInOutBench to evaluate our\nRAL-Writer against comparable baselines, and the results demonstrate the\neffectiveness of our approach. Our code has been released at\nhttps://github.com/OnlyAR/RAL-Writer.",
      "tldr_zh": "这篇论文针对长文本生成中的“lost-in-the-middle”现象（即输入变长时内容遗漏问题），首先引入Long Input and Output Benchmark (LongInOutBench)，包括一个合成数据集和全面评估框架，以填补现有基准的缺失。论文随后开发了Retrieval-Augmented Long-Text Writer (RAL-Writer)，通过检索重要内容并重述来构建显式提示，从而缓解该问题。实验结果显示，RAL-Writer 在LongInOutBench上比基线模型表现出色，并已开源代码以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06868v1",
      "published_date": "2025-03-10 02:44:36 UTC",
      "updated_date": "2025-03-10 02:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:34:03.590429"
    },
    {
      "arxiv_id": "2503.06867v1",
      "title": "Enhancing Time Series Forecasting via Logic-Inspired Regularization",
      "title_zh": "通过逻辑启发的正则化提升时间序列预测",
      "authors": [
        "Jianqi Zhang",
        "Jingyao Wang",
        "Xingchen Shen",
        "Wenwen Qiang"
      ],
      "abstract": "Time series forecasting (TSF) plays a crucial role in many applications.\nTransformer-based methods are one of the mainstream techniques for TSF.\nExisting methods treat all token dependencies equally. However, we find that\nthe effectiveness of token dependencies varies across different forecasting\nscenarios, and existing methods ignore these differences, which affects their\nperformance. This raises two issues: (1) What are effective token dependencies?\n(2) How can we learn effective dependencies? From a logical perspective, we\nalign Transformer-based TSF methods with the logical framework and define\neffective token dependencies as those that ensure the tokens as atomic formulas\n(Issue 1). We then align the learning process of Transformer methods with the\nprocess of obtaining atomic formulas in logic, which inspires us to design a\nmethod for learning these effective dependencies (Issue 2). Specifically, we\npropose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method\nthat guides the model to use fewer but more effective dependencies by making\nthe attention map sparse, thereby ensuring the tokens as atomic formulas and\nimproving prediction performance. Extensive experiments and theoretical\nanalysis confirm the effectiveness of Attn-L-Reg.",
      "tldr_zh": "本研究发现，现有的基于 Transformer 的时间序列预测 (TSF) 方法忽略了不同场景下 token 依赖关系的有效性差异，从而影响预测性能。为解决这一问题，作者从逻辑视角定义有效依赖为确保 tokens 作为原子公式的关系，并提出 Attention Logic Regularization (Attn-L-Reg)——一个即插即用的方法，通过使注意力图稀疏引导模型学习更有效的依赖关系，从而提升预测准确性。实验和理论分析证实，Attn-L-Reg 在 TSF 任务中显著提高了性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06867v1",
      "published_date": "2025-03-10 02:44:11 UTC",
      "updated_date": "2025-03-10 02:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:34:14.086863"
    },
    {
      "arxiv_id": "2503.06866v1",
      "title": "Graphormer-Guided Task Planning: Beyond Static Rules with LLM Safety Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Wanjing Huang",
        "Tongjie Pan",
        "Yalan Ye"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have expanded their role\nin robotic task planning. However, while LLMs have been explored for generating\nfeasible task sequences, their ability to ensure safe task execution remains\nunderdeveloped. Existing methods struggle with structured risk perception,\nmaking them inadequate for safety-critical applications where low-latency\nhazard adaptation is required. To address this limitation, we propose a\nGraphormer-enhanced risk-aware task planning framework that combines LLM-based\ndecision-making with structured safety modeling. Our approach constructs a\ndynamic spatio-semantic safety graph, capturing spatial and contextual risk\nfactors to enable online hazard detection and adaptive task refinement. Unlike\nexisting methods that rely on predefined safety constraints, our framework\nintroduces a context-aware risk perception module that continuously refines\nsafety predictions based on real-time task execution. This enables a more\nflexible and scalable approach to robotic planning, allowing for adaptive\nsafety compliance beyond static rules. To validate our framework, we conduct\nexperiments in the AI2-THOR environment. The experiments results validates\nimprovements in risk detection accuracy, rising safety notice, and task\nadaptability of our framework in continuous environments compared to static\nrule-based and LLM-only baselines. Our project is available at\nhttps://github.com/hwj20/GGTP",
      "tldr_zh": "该论文提出了一种 Graphormer 增强的风险感知任务规划框架，结合 LLMs 的决策能力，以解决现有方法在结构化风险感知和安全执行方面的局限性。框架通过构建动态时空语义安全图（dynamic spatio-semantic safety graph）和引入上下文感知风险感知模块（context-aware risk perception module），实现在线危险检测和实时任务细化，从而提供比静态规则更灵活、可扩展的安全合规机制。在 AI2-THOR 环境中的实验验证了该框架在风险检测准确性、安全通知和任务适应性上显著优于静态规则和仅 LLMs 的基线方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06866v1",
      "published_date": "2025-03-10 02:43:54 UTC",
      "updated_date": "2025-03-10 02:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:34:29.330969"
    },
    {
      "arxiv_id": "2503.06861v1",
      "title": "Enhanced Multi-Tuple Extraction for Alloys: Integrating Pointer Networks and Augmented Attention",
      "title_zh": "针对合金的增强多元组提取：整合指针网络和增强注意力",
      "authors": [
        "Mengzhe Hei",
        "Zhouran Zhang",
        "Qingbao Liu",
        "Yan Pan",
        "Xiang Zhao",
        "Yongqian Peng",
        "Yicong Ye",
        "Xin Zhang",
        "Shuxin Bai"
      ],
      "abstract": "Extracting high-quality structured information from scientific literature is\ncrucial for advancing material design through data-driven methods. Despite the\nconsiderable research in natural language processing for dataset extraction,\neffective approaches for multi-tuple extraction in scientific literature remain\nscarce due to the complex interrelations of tuples and contextual ambiguities.\nIn the study, we illustrate the multi-tuple extraction of mechanical properties\nfrom multi-principal-element alloys and presents a novel framework that\ncombines an entity extraction model based on MatSciBERT with pointer networks\nand an allocation model utilizing inter- and intra-entity attention. Our\nrigorous experiments on tuple extraction demonstrate impressive F1 scores of\n0.963, 0.947, 0.848, and 0.753 across datasets with 1, 2, 3, and 4 tuples,\nconfirming the effectiveness of the model. Furthermore, an F1 score of 0.854\nwas achieved on a randomly curated dataset. These results highlight the model's\ncapacity to deliver precise and structured information, offering a robust\nalternative to large language models and equipping researchers with essential\ndata for fostering data-driven innovations.",
      "tldr_zh": "本研究针对科学文献中多元组提取的复杂性（如元组间关系和上下文模糊），提出了一种增强型框架，用于从多主元合金的机械属性中提取结构化信息。该框架整合了基于 MatSciBERT 的实体提取模型、Pointer Networks 以及利用内部和内部实体注意力的分配模型，从而提高提取精度。在实验中，该模型在包含1至4个元组的数据集上分别取得了0.963、0.947、0.848和0.753的F1分数，并在随机数据集上达到0.854的F1分数，证明了其作为大型语言模型替代方案的有效性，为数据驱动的材料设计提供了可靠的支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06861v1",
      "published_date": "2025-03-10 02:39:06 UTC",
      "updated_date": "2025-03-10 02:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:34:38.081193"
    },
    {
      "arxiv_id": "2503.06839v1",
      "title": "AttFC: Attention Fully-Connected Layer for Large-Scale Face Recognition with One GPU",
      "title_zh": "AttFC：注意力全连接层，用于大规模人脸识别的单GPU实现",
      "authors": [
        "Zhuowen Zheng",
        "Yain-Whar Si",
        "Xiaochen Yuan",
        "Junwei Duan",
        "Ke Wang",
        "Xiaofan Li",
        "Xinyuan Zhang",
        "Xueyuan Gong"
      ],
      "abstract": "Nowadays, with the advancement of deep neural networks (DNNs) and the\navailability of large-scale datasets, the face recognition (FR) model has\nachieved exceptional performance. However, since the parameter magnitude of the\nfully connected (FC) layer directly depends on the number of identities in the\ndataset. If training the FR model on large-scale datasets, the size of the\nmodel parameter will be excessively huge, leading to substantial demand for\ncomputational resources, such as time and memory. This paper proposes the\nattention fully connected (AttFC) layer, which could significantly reduce\ncomputational resources. AttFC employs an attention loader to generate the\ngenerative class center (GCC), and dynamically store the class center with\nDynamic Class Container (DCC). DCC only stores a small subset of all class\ncenters in FC, thus its parameter count is substantially less than the FC\nlayer. Also, training face recognition models on large-scale datasets with one\nGPU often encounter out-of-memory (OOM) issues. AttFC overcomes this and\nachieves comparable performance to state-of-the-art methods.",
      "tldr_zh": "本研究针对大规模人脸识别数据集训练时，Fully Connected (FC) 层参数过大导致计算资源（如时间和内存）需求剧增的问题，提出了一种Attention Fully-Connected (AttFC) 层。AttFC 通过Attention Loader 生成Generative Class Center (GCC)，并利用Dynamic Class Container (DCC) 动态存储类中心的子集，从而显著减少参数数量。实验结果显示，AttFC 能够在单 GPU 上避免Out-of-Memory (OOM) 问题，并实现与最先进方法相当的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06839v1",
      "published_date": "2025-03-10 01:59:11 UTC",
      "updated_date": "2025-03-10 01:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:34:52.549388"
    },
    {
      "arxiv_id": "2503.07673v1",
      "title": "The potential role of AI agents in transforming nuclear medicine research and cancer management in India",
      "title_zh": "AI 代理在印度核医学研究和癌症管理中的潜在作用",
      "authors": [
        "Rajat Vashistha",
        "Arif Gulzar",
        "Parveen Kundu",
        "Punit Sharma",
        "Mark Brunstein",
        "Viktor Vegh"
      ],
      "abstract": "India faces a significant cancer burden, with an incidence-to-mortality ratio\nindicating that nearly three out of five individuals diagnosed with cancer\nsuccumb to the disease. While the limitations of physical healthcare\ninfrastructure are widely acknowledged as a primary challenge, concerted\nefforts by government and healthcare agencies are underway to mitigate these\nconstraints. However, given the country's vast geography and high population\ndensity, it is imperative to explore alternative soft infrastructure solutions\nto complement existing frameworks. Artificial Intelligence agents are\nincreasingly transforming problem-solving approaches across various domains,\nwith their application in medicine proving particularly transformative. In this\nperspective, we examine the potential role of AI agents in advancing nuclear\nmedicine for cancer research, diagnosis, and management in India. We begin with\na brief overview of AI agents and their capabilities, followed by a proposed\nagent-based ecosystem that can address prevailing sustainability challenges in\nIndia nuclear medicine.",
      "tldr_zh": "印度面临严重的癌症负担，其中近五分之三的癌症患者因医疗基础设施不足而死亡。该论文探讨了AI agents在核医学领域的作用，旨在通过AI代理的先进能力提升癌症研究、诊断和管理。该研究首先概述了AI agents的功能，并提出一个基于代理的生态系统，以解决印度核医学的可持续性挑战，从而为改善癌症管理提供潜在的软基础设施支持。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07673v1",
      "published_date": "2025-03-10 01:30:07 UTC",
      "updated_date": "2025-03-10 01:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:35:01.441210"
    },
    {
      "arxiv_id": "2503.06828v1",
      "title": "Towards a Multimodal MRI-Based Foundation Model for Multi-Level Feature Exploration in Segmentation, Molecular Subtyping, and Grading of Glioma",
      "title_zh": "翻译失败",
      "authors": [
        "Somayeh Farahani",
        "Marjaneh Hejazi",
        "Antonio Di Ieva",
        "Emad Fatemizadeh",
        "Sidong Liu"
      ],
      "abstract": "Accurate, noninvasive glioma characterization is crucial for effective\nclinical management. Traditional methods, dependent on invasive tissue\nsampling, often fail to capture the spatial heterogeneity of the tumor. While\ndeep learning has improved segmentation and molecular profiling, few approaches\nsimultaneously integrate tumor morphology and molecular features. Foundation\ndeep learning models, which learn robust, task-agnostic representations from\nlarge-scale datasets, hold great promise but remain underutilized in glioma\nimaging biomarkers. We propose the Multi-Task SWIN-UNETR (MTS-UNET) model, a\nnovel foundation-based framework built on the BrainSegFounder model, pretrained\non large-scale neuroimaging data. MTS-UNET simultaneously performs glioma\nsegmentation, histological grading, and molecular subtyping (IDH mutation and\n1p/19q co-deletion). It incorporates two key modules: Tumor-Aware Feature\nEncoding (TAFE) for multi-scale, tumor-focused feature extraction and\nCross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch\nsignals associated with IDH mutation. The model was trained and validated on a\ndiverse, multi-center cohort of 2,249 glioma patients from seven public\ndatasets. MTS-UNET achieved a mean Dice score of 84% for segmentation, along\nwith AUCs of 90.58% for IDH mutation, 69.22% for 1p/19q co-deletion prediction,\nand 87.54% for grading, significantly outperforming baseline models (p<=0.05).\nAblation studies validated the essential contributions of the TAFE and CMD\nmodules and demonstrated the robustness of the framework. The foundation-based\nMTS-UNET model effectively integrates tumor segmentation with multi-level\nclassification, exhibiting strong generalizability across diverse MRI datasets.\nThis framework shows significant potential for advancing noninvasive,\npersonalized glioma management by improving predictive accuracy and\ninterpretability.",
      "tldr_zh": "该研究针对胶质瘤的非侵入性表征问题，提出了一种基于多模态MRI的Multi-Task SWIN-UNETR (MTS-UNET)模型，该模型建立在BrainSegFounder基础上，通过大规模神经影像数据预训练，同时实现肿瘤分割、组织学分级以及分子亚型预测（如IDH突变和1p/19q共缺失）。模型引入Tumor-Aware Feature Encoding (TAFE)模块用于多尺度肿瘤特征提取，以及Cross-Modality Differential (CMD)模块来突出T2-FLAIR不匹配信号，从而整合肿瘤形态和分子特征。在2,249名患者的多中心数据集上验证，MTS-UNET实现了84%的分割Dice得分，以及IDH突变预测的AUC 90.58%、1p/19q共缺失的AUC 69.22%和分级的AUC 87.54%，显著优于基线模型。该框架展示了良好的泛化性和潜力，可提升非侵入性、个性化的胶质瘤管理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06828v1",
      "published_date": "2025-03-10 01:27:09 UTC",
      "updated_date": "2025-03-10 01:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:35:16.524202"
    },
    {
      "arxiv_id": "2503.06820v1",
      "title": "Towards Fine-Grained Video Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Dai",
        "Alan Luo",
        "Zane Durante",
        "Debadutta Dash",
        "Arnold Milstein",
        "Kevin Schulman",
        "Ehsan Adeli",
        "Li Fei-Fei"
      ],
      "abstract": "In the rapidly evolving domain of video understanding, Video Question\nAnswering (VideoQA) remains a focal point. However, existing datasets exhibit\ngaps in temporal and spatial granularity, which consequently limits the\ncapabilities of existing VideoQA methods. This paper introduces the\nMulti-Object Multi-Actor Question Answering (MOMA-QA) dataset, which is\ndesigned to address these shortcomings by emphasizing temporal localization,\nspatial relationship reasoning, and entity-centric queries. With ground truth\nscene graphs and temporal interval annotations, MOMA-QA is ideal for developing\nmodels for fine-grained video understanding. Furthermore, we present a novel\nvideo-language model, SGVLM, which incorporates a scene graph predictor, an\nefficient frame retriever, and a pre-trained large language model for temporal\nlocalization and fine-grained relationship understanding. Evaluations on\nMOMA-QA and other public datasets demonstrate the superior performance of our\nmodel, setting new benchmarks for VideoQA.",
      "tldr_zh": "本论文针对现有Video Question Answering (VideoQA) 数据集在时间和空间粒度上的不足，引入了Multi-Object Multi-Actor Question Answering (MOMA-QA) 数据集，以强调temporal localization、spatial relationship reasoning 和实体中心查询。MOMA-QA 提供了ground truth scene graphs 和 temporal interval annotations，旨在支持细粒度视频理解模型的开发。同时，论文提出了一种新型视频语言模型 SGVLM，该模型整合了scene graph predictor、efficient frame retriever 和 pre-trained large language model，实现精确的时间定位和关系理解。在 MOMA-QA 及其他公开数据集上的评估中，SGVLM 表现出色，设立了新的 VideoQA 基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06820v1",
      "published_date": "2025-03-10 01:02:01 UTC",
      "updated_date": "2025-03-10 01:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:35:29.129308"
    },
    {
      "arxiv_id": "2503.06816v1",
      "title": "Semi-Supervised Medical Image Segmentation via Knowledge Mining from Large Models",
      "title_zh": "半监督医学图像分割：通过从大型模型中知识挖掘",
      "authors": [
        "Yuchen Mao",
        "Hongwei Li",
        "Yinyi Lai",
        "Giorgos Papanastasiou",
        "Peng Qi",
        "Yunjie Yang",
        "Chengjia Wang"
      ],
      "abstract": "Large-scale vision models like SAM have extensive visual knowledge, yet their\ngeneral nature and computational demands limit their use in specialized tasks\nlike medical image segmentation. In contrast, task-specific models such as\nU-Net++ often underperform due to sparse labeled data. This study introduces a\nstrategic knowledge mining method that leverages SAM's broad understanding to\nboost the performance of small, locally hosted deep learning models.\n  In our approach, we trained a U-Net++ model on a limited labeled dataset and\nextend its capabilities by converting SAM's output infered on unlabeled images\ninto prompts. This process not only harnesses SAM's generalized visual\nknowledge but also iteratively improves SAM's prediction to cater specialized\nmedical segmentation tasks via U-Net++. The mined knowledge, serving as \"pseudo\nlabels\", enriches the training dataset, enabling the fine-tuning of the local\nnetwork.\n  Applied to the Kvasir SEG and COVID-QU-Ex datasets which consist of\ngastrointestinal polyp and lung X-ray images respectively, our proposed method\nconsistently enhanced the segmentation performance on Dice by 3% and 1%\nrespectively over the baseline U-Net++ model, when the same amount of labelled\ndata were used during training (75% and 50% of labelled data). Remarkably, our\nproposed method surpassed the baseline U-Net++ model even when the latter was\ntrained exclusively on labeled data (100% of labelled data). These results\nunderscore the potential of knowledge mining to overcome data limitations in\nspecialized models by leveraging the broad, albeit general, knowledge of\nlarge-scale models like SAM, all while maintaining operational efficiency\nessential for clinical applications.",
      "tldr_zh": "这篇论文提出了一种半监督医疗图像分割方法，通过从大型视觉模型如 SAM 挖掘知识来提升任务特定模型如 U-Net++ 的性能，以解决标签数据稀少的问题。具体方法包括在有限的标签数据集上训练 U-Net++，并利用 SAM 在无标签图像上生成的输出作为提示，创建“伪标签”来丰富训练数据并迭代优化。实验在 Kvasir SEG（胃肠息肉图像）和 COVID-QU-Ex（肺 X 光图像）数据集上显示，该方法在 Dice 分数上分别比基线 U-Net++ 模型提高了 3% 和 1%，即使使用更少的标签数据（75% 和 50%），也超过了完全使用 100% 标签数据的基线模型。这些结果突显了知识挖掘在克服数据限制方面的潜力，同时保持了临床应用的效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "18 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.06816v1",
      "published_date": "2025-03-10 00:43:45 UTC",
      "updated_date": "2025-03-10 00:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:35:41.640089"
    },
    {
      "arxiv_id": "2503.06814v1",
      "title": "Unlocking Generalization for Robotics via Modularity and Scale",
      "title_zh": "通过模块化和规模解锁机器人泛化",
      "authors": [
        "Murtaza Dalal"
      ],
      "abstract": "How can we build generalist robot systems? Scale may not be enough due to the\nsignificant multimodality of robotics tasks, lack of easily accessible data and\nthe challenges of deploying on physical hardware. Meanwhile, most deployed\nrobotic systems today are inherently modular and can leverage the independent\ngeneralization capabilities of each module to perform well. Therefore, this\nthesis seeks to tackle the task of building generalist robot agents by\nintegrating these components into one: combining modularity with large-scale\nlearning for general purpose robot control. The first question we consider is:\nhow can we build modularity and hierarchy into learning systems? Our key\ninsight is that rather than having the agent learn hierarchy and low-level\ncontrol end-to-end, we can enforce modularity via planning to enable more\nefficient and capable robot learners. Next, we come to the role of scale in\nbuilding generalist robot systems. To scale, neural networks require vast\namounts of diverse data, expressive architectures to fit the data and a source\nof supervision to generate the data. We leverage a powerful supervision source:\nclassical planning, which can generalize, but is expensive to run and requires\naccess to privileged information to perform well in practice. We use these\nplanners to supervise large-scale policy learning in simulation to produce\ngeneralist agents. Finally, we consider how to unify modularity with\nlarge-scale policy learning to build real-world robot systems capable of\nperforming zero-shot manipulation. We do so by tightly integrating key\ningredients of modular high and mid-level planning, learned local control,\nprocedural scene generation and large-scale policy learning for sim2real\ntransfer. We demonstrate that this recipe can produce a single, generalist\nagent that can solve challenging long-horizon manipulation tasks in the real\nworld.",
      "tldr_zh": "该论文探讨了通过模块化(modularity)和规模(scale)构建通用机器人系统的策略，以应对机器人任务的多模态性、数据获取和硬件部署挑战。作者提出一种方法，通过强制模块化（如规划）来构建学习系统的层次结构，并利用经典规划作为监督源，在模拟环境中进行大规模策略学习。最终，该框架整合模块化规划、学习控制和 sim2real 转移，成功开发出一个通用代理，能够在真实世界中零样本地解决复杂的长horizon 操作任务。实验结果证明，这种结合方法显著提升了机器人的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "CMU Robotics PhD Thesis, 185 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.06814v1",
      "published_date": "2025-03-10 00:38:31 UTC",
      "updated_date": "2025-03-10 00:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:35:54.418273"
    },
    {
      "arxiv_id": "2503.06812v1",
      "title": "Can Proof Assistants Verify Multi-Agent Systems?",
      "title_zh": "证明助手能验证多智能体系统吗？",
      "authors": [
        "Julian Alfredo Mendez",
        "Timotheus Kampik"
      ],
      "abstract": "This paper presents the Soda language for verifying multi-agent systems. Soda\nis a high-level functional and object-oriented language that supports the\ncompilation of its code not only to Scala, a strongly statically typed\nhigh-level programming language, but also to Lean, a proof assistant and\nprogramming language. Given these capabilities, Soda can implement multi-agent\nsystems, or parts thereof, that can then be integrated into a mainstream\nsoftware ecosystem on the one hand and formally verified with state-of-the-art\ntools on the other hand. We provide a brief and informal introduction to Soda\nand the aforementioned interoperability capabilities, as well as a simple\ndemonstration of how interaction protocols can be designed and verified with\nSoda. In the course of the demonstration, we highlight challenges with respect\nto real-world applicability.",
      "tldr_zh": "这篇论文探讨了证明助手是否能验证多智能体 systems，提出了一种名为 Soda 的高级函数式和面向对象语言。Soda 支持将代码编译到 Scala（一种强静态类型编程语言）和 Lean（一个证明助手和编程语言），从而允许多智能体 systems 的实现与主流软件生态整合，同时进行正式验证。论文通过一个简单演示展示了如何用 Soda 设计和验证交互 protocols，并突出了实际应用中的挑战，如可扩展性和真实世界兼容性。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LO",
        "cs.MA"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06812v1",
      "published_date": "2025-03-10 00:24:29 UTC",
      "updated_date": "2025-03-10 00:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:36:05.529515"
    },
    {
      "arxiv_id": "2503.06810v1",
      "title": "Mitigating Preference Hacking in Policy Optimization with Pessimism",
      "title_zh": "翻译失败",
      "authors": [
        "Dhawal Gupta",
        "Adam Fisch",
        "Christoph Dann",
        "Alekh Agarwal"
      ],
      "abstract": "This work tackles the problem of overoptimization in reinforcement learning\nfrom human feedback (RLHF), a prevalent technique for aligning models with\nhuman preferences. RLHF relies on reward or preference models trained on\n\\emph{fixed preference datasets}, and these models are unreliable when\nevaluated outside the support of this preference data, leading to the common\nreward or preference hacking phenomenon. We propose novel, pessimistic\nobjectives for RLHF which are provably robust to overoptimization through the\nuse of pessimism in the face of uncertainty, and design practical algorithms,\nP3O and PRPO, to optimize these objectives. Our approach is derived for the\ngeneral preference optimization setting, but can be used with reward models as\nwell. We evaluate P3O and PRPO on the tasks of fine-tuning language models for\ndocument summarization and creating helpful assistants, demonstrating\nremarkable resilience to overoptimization.",
      "tldr_zh": "本研究针对强化学习从人类反馈（RLHF）中的过优化问题提出解决方案，该问题源于奖励或偏好模型在固定偏好数据集之外的不可靠性，导致偏好 hacking。作者设计了基于悲观主义（pessimism）的目标函数，并开发了 P3O 和 PRPO 算法，这些算法通过面对不确定性的悲观优化来证明对过优化的鲁棒性。实验结果显示，在语言模型的文档摘要和创建帮助性助手任务上，该方法表现出显著的抗过优化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.06810v1",
      "published_date": "2025-03-10 00:13:19 UTC",
      "updated_date": "2025-03-10 00:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T00:36:16.643503"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 175,
  "processed_papers_count": 175,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T00:36:37.592851"
}