[
  {
    "arxiv_id": "2504.00048v1",
    "title": "Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs",
    "authors": [
      "Cong Duy Vu Hoang",
      "Gioacchino Tangari",
      "Clemence Lanfranchi",
      "Dalu Guo",
      "Paul Cayet",
      "Steve Siu",
      "Don Dharmasiri",
      "Yuan-Fang Li",
      "Long Duong",
      "Damien Hilloulin",
      "Rhicheek Patra",
      "Sungpack Hong",
      "Hassan Chafi"
    ],
    "abstract": "The growing adoption of large language models (LLMs) in business applications\nhas amplified interest in Natural Language to SQL (NL2SQL) solutions, in which\nthere is competing demand for high performance and efficiency. Domain- and\ncustomer-specific requirements further complicate the problem. To address this\nconundrum, we introduce Distill-C, a distilled customization framework tailored\nfor NL2SQL tasks. Distill-C utilizes large teacher LLMs to produce high-quality\nsynthetic data through a robust and scalable pipeline. Finetuning smaller and\nopen-source LLMs on this synthesized data enables them to rival or outperform\nteacher models an order of magnitude larger. Evaluated on multiple challenging\nbenchmarks, Distill-C achieves an average improvement of 36% in execution\naccuracy compared to the base models from three distinct LLM families.\nAdditionally, on three internal customer benchmarks, Distill-C demonstrates a\n22.6% performance improvement over the base models. Our results demonstrate\nthat Distill-C is an effective, high-performing and generalizable approach for\ndeploying lightweight yet powerful NL2SQL models, delivering exceptional\naccuracies while maintaining low computational cost.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint, accepted at NAACL 2025 (Industry Track)",
    "pdf_url": "http://arxiv.org/pdf/2504.00048v1",
    "published_date": "2025-03-30 23:23:21 UTC",
    "updated_date": "2025-03-30 23:23:21 UTC"
  },
  {
    "arxiv_id": "2504.00047v1",
    "title": "EAP4EMSIG -- Enhancing Event-Driven Microscopy for Microfluidic Single-Cell Analysis",
    "authors": [
      "Nils Friederich",
      "Angelo Jovin Yamachui Sitcheu",
      "Annika Nassal",
      "Erenus Yildiz",
      "Matthias Pesch",
      "Maximilian Beichter",
      "Lukas Scholtes",
      "Bahar Akbaba",
      "Thomas Lautenschlager",
      "Oliver Neumann",
      "Dietrich Kohlheyer",
      "Hanno Scharr",
      "Johannes Seiffarth",
      "Katharina Nöh",
      "Ralf Mikut"
    ],
    "abstract": "Microfluidic Live-Cell Imaging yields data on microbial cell factories.\nHowever, continuous acquisition is challenging as high-throughput experiments\noften lack realtime insights, delaying responses to stochastic events. We\nintroduce three components in the Experiment Automation Pipeline for\nEvent-Driven Microscopy to Smart Microfluidic Single-Cell Analysis: a fast,\naccurate Deep Learning autofocusing method predicting the focus offset, an\nevaluation of real-time segmentation methods and a realtime data analysis\ndashboard. Our autofocusing achieves a Mean Absolute Error of 0.0226\\textmu m\nwith inference times below 50~ms. Among eleven Deep Learning segmentation\nmethods, Cellpose~3 reached a Panoptic Quality of 93.58\\%, while a\ndistance-based method is fastest (121~ms, Panoptic Quality 93.02\\%). All six\nDeep Learning Foundation Models were unsuitable for real-time segmentation.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Submitted to: at - Automatisierungstechnik",
    "pdf_url": "http://arxiv.org/pdf/2504.00047v1",
    "published_date": "2025-03-30 23:16:23 UTC",
    "updated_date": "2025-03-30 23:16:23 UTC"
  },
  {
    "arxiv_id": "2503.23622v1",
    "title": "Beyond Detection: Designing AI-Resilient Assessments with Automated Feedback Tool to Foster Critical Thinking",
    "authors": [
      "Muhammad Sajjad Akbar"
    ],
    "abstract": "The growing use of generative AI tools like ChatGPT has raised urgent\nconcerns about their impact on student learning, particularly the potential\nerosion of critical thinking and creativity. As students increasingly turn to\nthese tools to complete assessments, foundational cognitive skills are at risk\nof being bypassed, challenging the integrity of higher education and the\nauthenticity of student work. Existing AI-generated text detection tools are\ninadequate; they produce unreliable outputs and are prone to both false\npositives and false negatives, especially when students apply paraphrasing,\ntranslation, or rewording. These systems rely on shallow statistical patterns\nrather than true contextual or semantic understanding, making them unsuitable\nas definitive indicators of AI misuse. In response, this research proposes a\nproactive, AI-resilient solution based on assessment design rather than\ndetection. It introduces a web-based Python tool that integrates Bloom's\nTaxonomy with advanced natural language processing techniques including GPT-3.5\nTurbo, BERT-based semantic similarity, and TF-IDF metrics to evaluate the\nAI-solvability of assessment tasks. By analyzing surface-level and semantic\nfeatures, the tool helps educators determine whether a task targets lower-order\nthinking such as recall and summarization or higher-order skills such as\nanalysis, evaluation, and creation, which are more resistant to AI automation.\nThis framework empowers educators to design cognitively demanding, AI-resistant\nassessments that promote originality, critical thinking, and fairness. It\noffers a sustainable, pedagogically sound strategy to foster authentic learning\nand uphold academic standards in the age of AI.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23622v1",
    "published_date": "2025-03-30 23:13:00 UTC",
    "updated_date": "2025-03-30 23:13:00 UTC"
  },
  {
    "arxiv_id": "2504.00046v2",
    "title": "Multi-Stakeholder Disaster Insights from Social Media Using Large Language Models",
    "authors": [
      "Loris Belcastro",
      "Cristian Cosentino",
      "Fabrizio Marozzo",
      "Merve Gündüz-Cüre",
      "Sule Öztürk-Birim"
    ],
    "abstract": "In recent years, social media has emerged as a primary channel for users to\npromptly share feedback and issues during disasters and emergencies, playing a\nkey role in crisis management. While significant progress has been made in\ncollecting and analyzing social media content, there remains a pressing need to\nenhance the automation, aggregation, and customization of this data to deliver\nactionable insights tailored to diverse stakeholders, including the press,\npolice, EMS, and firefighters. This effort is essential for improving the\ncoordination of activities such as relief efforts, resource distribution, and\nmedia communication. This paper presents a methodology that leverages the\ncapabilities of LLMs to enhance disaster response and management. Our approach\ncombines classification techniques with generative AI to bridge the gap between\nraw user feedback and stakeholder-specific reports. Social media posts shared\nduring catastrophic events are analyzed with a focus on user-reported issues,\nservice interruptions, and encountered challenges. We employ full-spectrum\nLLMs, using analytical models like BERT for precise, multi-dimensional\nclassification of content type, sentiment, emotion, geolocation, and topic.\nGenerative models such as ChatGPT are then used to produce human-readable,\ninformative reports tailored to distinct audiences, synthesizing insights\nderived from detailed classifications. We compare standard approaches, which\nanalyze posts directly using prompts in ChatGPT, to our advanced method, which\nincorporates multi-dimensional classification, sub-event selection, and\ntailored report generation. Our methodology demonstrates superior performance\nin both quantitative metrics, such as text coherence scores and latent\nrepresentations, and qualitative assessments by automated tools and field\nexperts, delivering precise insights for diverse disaster response\nstakeholders.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00046v2",
    "published_date": "2025-03-30 22:53:52 UTC",
    "updated_date": "2025-04-17 11:29:06 UTC"
  },
  {
    "arxiv_id": "2503.23617v1",
    "title": "Graph-Eq: Discovering Mathematical Equations using Graph Generative Models",
    "authors": [
      "Nisal Ranasinghe",
      "Damith Senanayake",
      "Saman Halgamuge"
    ],
    "abstract": "The ability to discover meaningful, accurate, and concise mathematical\nequations that describe datasets is valuable across various domains. Equations\noffer explicit relationships between variables, enabling deeper insights into\nunderlying data patterns. Most existing equation discovery methods rely on\ngenetic programming, which iteratively searches the equation space but is often\nslow and prone to overfitting. By representing equations as directed acyclic\ngraphs, we leverage the use of graph neural networks to learn the underlying\nsemantics of equations, and generate new, previously unseen equations. Although\ngraph generative models have been shown to be successful in discovering new\ntypes of graphs in many fields, there application in discovering equations\nremains largely unexplored. In this work, we propose Graph-EQ, a deep graph\ngenerative model designed for efficient equation discovery. Graph-EQ uses a\nconditional variational autoencoder (CVAE) to learn a rich latent\nrepresentation of the equation space by training it on a large corpus of\nequations in an unsupervised manner. Instead of directly searching the equation\nspace, we employ Bayesian optimization to efficiently explore this learned\nlatent space. We show that the encoder-decoder architecture of Graph-Eq is able\nto accurately reconstruct input equations. Moreover, we show that the learned\nlatent representation can be sampled and decoded into valid equations,\nincluding new and previously unseen equations in the training data. Finally, we\nassess Graph-Eq's ability to discover equations that best fit a dataset by\nexploring the latent space using Bayesian optimization. Latent space\nexploration is done on 20 dataset with known ground-truth equations, and\nGraph-Eq is shown to successfully discover the grountruth equation in the\nmajority of datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23617v1",
    "published_date": "2025-03-30 22:47:57 UTC",
    "updated_date": "2025-03-30 22:47:57 UTC"
  },
  {
    "arxiv_id": "2503.23616v1",
    "title": "Interpretable Machine Learning in Physics: A Review",
    "authors": [
      "Sebastian Johann Wetzel",
      "Seungwoong Ha",
      "Raban Iten",
      "Miriam Klopotek",
      "Ziming Liu"
    ],
    "abstract": "Machine learning is increasingly transforming various scientific fields,\nenabled by advancements in computational power and access to large data sets\nfrom experiments and simulations. As artificial intelligence (AI) continues to\ngrow in capability, these algorithms will enable many scientific discoveries\nbeyond human capabilities. Since the primary goal of science is to understand\nthe world around us, fully leveraging machine learning in scientific discovery\nrequires models that are interpretable -- allowing experts to comprehend the\nconcepts underlying machine-learned predictions. Successful interpretations\nincrease trust in black-box methods, help reduce errors, allow for the\nimprovement of the underlying models, enhance human-AI collaboration, and\nultimately enable fully automated scientific discoveries that remain\nunderstandable to human scientists. This review examines the role of\ninterpretability in machine learning applied to physics. We categorize\ndifferent aspects of interpretability, discuss machine learning models in terms\nof both interpretability and performance, and explore the philosophical\nimplications of interpretability in scientific inquiry. Additionally, we\nhighlight recent advances in interpretable machine learning across many\nsubfields of physics. By bridging boundaries between disciplines -- each with\nits own unique insights and challenges -- we aim to establish interpretable\nmachine learning as a core research focus in science.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23616v1",
    "published_date": "2025-03-30 22:44:40 UTC",
    "updated_date": "2025-03-30 22:44:40 UTC"
  },
  {
    "arxiv_id": "2503.23615v1",
    "title": "An Organizationally-Oriented Approach to Enhancing Explainability and Control in Multi-Agent Reinforcement Learning",
    "authors": [
      "Julien Soulé",
      "Jean-Paul Jamont",
      "Michel Occello",
      "Louis-Marie Traonouez",
      "Paul Théron"
    ],
    "abstract": "Multi-Agent Reinforcement Learning can lead to the development of\ncollaborative agent behaviors that show similarities with organizational\nconcepts. Pushing forward this perspective, we introduce a novel framework that\nexplicitly incorporates organizational roles and goals from the\n$\\mathcal{M}OISE^+$ model into the MARL process, guiding agents to satisfy\ncorresponding organizational constraints. By structuring training with roles\nand goals, we aim to enhance both the explainability and control of agent\nbehaviors at the organizational level, whereas much of the literature primarily\nfocuses on individual agents. Additionally, our framework includes a\npost-training analysis method to infer implicit roles and goals, offering\ninsights into emergent agent behaviors. This framework has been applied across\nvarious MARL environments and algorithms, demonstrating coherence between\npredefined organizational specifications and those inferred from trained\nagents.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23615v1",
    "published_date": "2025-03-30 22:43:01 UTC",
    "updated_date": "2025-03-30 22:43:01 UTC"
  },
  {
    "arxiv_id": "2503.23605v1",
    "title": "Partial Transportability for Domain Generalization",
    "authors": [
      "Kasra Jalaldoust",
      "Alexis Bellot",
      "Elias Bareinboim"
    ],
    "abstract": "A fundamental task in AI is providing performance guarantees for predictions\nmade in unseen domains. In practice, there can be substantial uncertainty about\nthe distribution of new data, and corresponding variability in the performance\nof existing predictors. Building on the theory of partial identification and\ntransportability, this paper introduces new results for bounding the value of a\nfunctional of the target distribution, such as the generalization error of a\nclassifier, given data from source domains and assumptions about the data\ngenerating mechanisms, encoded in causal diagrams. Our contribution is to\nprovide the first general estimation technique for transportability problems,\nadapting existing parameterization schemes such Neural Causal Models to encode\nthe structural constraints necessary for cross-population inference. We\ndemonstrate the expressiveness and consistency of this procedure and further\npropose a gradient-based optimization scheme for making scalable inferences in\npractice. Our results are corroborated with experiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "causalai.net/r88.pdf",
    "pdf_url": "http://arxiv.org/pdf/2503.23605v1",
    "published_date": "2025-03-30 22:06:37 UTC",
    "updated_date": "2025-03-30 22:06:37 UTC"
  },
  {
    "arxiv_id": "2503.23598v1",
    "title": "GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs",
    "authors": [
      "Kalliopi Basioti",
      "Pritish Sahu",
      "Qingze Tony Liu",
      "Zihao Xu",
      "Hao Wang",
      "Vladimir Pavlovic"
    ],
    "abstract": "Raven's Progressive Matrices (RPMs) is an established benchmark to examine\nthe ability to perform high-level abstract visual reasoning (AVR). Despite the\ncurrent success of algorithms that solve this task, humans can generalize\nbeyond a given puzzle and create new puzzles given a set of rules, whereas\nmachines remain locked in solving a fixed puzzle from a curated choice list. We\npropose Generative Visual Puzzles (GenVP), a framework to model the entire RPM\ngeneration process, a substantially more challenging task. Our model's\ncapability spans from generating multiple solutions for one specific problem\nprompt to creating complete new puzzles out of the desired set of rules.\nExperiments on five different datasets indicate that GenVP achieves\nstate-of-the-art (SOTA) performance both in puzzle-solving accuracy and\nout-of-distribution (OOD) generalization in 22 OOD scenarios. Compared to SOTA\ngenerative approaches, which struggle to solve RPMs when the feasible solution\nspace increases, GenVP efficiently generalizes to these challenging setups.\nMoreover, our model demonstrates the ability to produce a wide range of\ncomplete RPMs given a set of abstract rules by effectively capturing the\nrelationships between abstract rules and visual object properties.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23598v1",
    "published_date": "2025-03-30 21:35:26 UTC",
    "updated_date": "2025-03-30 21:35:26 UTC"
  },
  {
    "arxiv_id": "2504.00043v1",
    "title": "CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation",
    "authors": [
      "Jixuan Leng",
      "Chengsong Huang",
      "Langlin Huang",
      "Bill Yuchen Lin",
      "William W. Cohen",
      "Haohan Wang",
      "Jiaxin Huang"
    ],
    "abstract": "Existing reasoning evaluation frameworks for Large Language Models (LLMs) and\nLarge Vision-Language Models (LVLMs) predominantly either assess text-based\nreasoning or vision-language understanding capabilities, with limited dynamic\ninterplay between textual and visual constraints. To address this limitation,\nwe introduce CrossWordBench, a benchmark designed to evaluate the reasoning\ncapabilities of both LLMs and LVLMs through the medium of crossword puzzles-a\ntask requiring multimodal adherence to semantic constraints from text-based\nclues and intersectional constraints from visual grid structures.\nCrossWordBench leverages a controllable puzzle generation framework that\nproduces puzzles in multiple formats (text and image) and offers different\nevaluation strategies ranging from direct puzzle solving to interactive modes.\nOur extensive evaluation of over 20 models reveals that reasoning LLMs\noutperform non-reasoning models substantially by effectively leveraging\ncrossing-letter constraints. We further demonstrate that LVLMs struggle with\nthe task, showing a strong correlation between their puzzle-solving performance\nand grid-parsing accuracy. Our findings offer insights into the limitations of\nthe reasoning capabilities of current LLMs and LVLMs, and provide an effective\napproach for creating multimodal constrained tasks for future evaluations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00043v1",
    "published_date": "2025-03-30 20:03:36 UTC",
    "updated_date": "2025-03-30 20:03:36 UTC"
  },
  {
    "arxiv_id": "2503.23573v1",
    "title": "DASH: Detection and Assessment of Systematic Hallucinations of VLMs",
    "authors": [
      "Maximilian Augustin",
      "Yannic Neuhaus",
      "Matthias Hein"
    ],
    "abstract": "Vision-language models (VLMs) are prone to object hallucinations, where they\nerroneously indicate the presenceof certain objects in an image. Existing\nbenchmarks quantify hallucinations using relatively small, labeled datasets.\nHowever, this approach is i) insufficient to assess hallucinations that arise\nin open-world settings, where VLMs are widely used, and ii) inadequate for\ndetecting systematic errors in VLMs. We propose DASH (Detection and Assessment\nof Systematic Hallucinations), an automatic, large-scale pipeline designed to\nidentify systematic hallucinations of VLMs on real-world images in an\nopen-world setting. A key component is DASH-OPT for image-based retrieval,\nwhere we optimize over the ''natural image manifold'' to generate images that\nmislead the VLM. The output of DASH consists of clusters of real and\nsemantically similar images for which the VLM hallucinates an object. We apply\nDASH to PaliGemma and two LLaVA-NeXT models across 380 object classes and, in\ntotal, find more than 19k clusters with 950k images. We study the transfer of\nthe identified systematic hallucinations to other VLMs and show that\nfine-tuning PaliGemma with the model-specific images obtained with DASH\nmitigates object hallucinations. Code and data are available at\nhttps://YanNeu.github.io/DASH.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23573v1",
    "published_date": "2025-03-30 19:45:09 UTC",
    "updated_date": "2025-03-30 19:45:09 UTC"
  },
  {
    "arxiv_id": "2504.00040v1",
    "title": "Quantum Methods for Managing Ambiguity in Natural Language Processing",
    "authors": [
      "Jurek Eisinger",
      "Ward Gauderis",
      "Lin de Huybrecht",
      "Geraint A. Wiggins"
    ],
    "abstract": "The Categorical Compositional Distributional (DisCoCat) framework models\nmeaning in natural language using the mathematical framework of quantum theory,\nexpressed as formal diagrams. DisCoCat diagrams can be associated with tensor\nnetworks and quantum circuits. DisCoCat diagrams have been connected to density\nmatrices in various contexts in Quantum Natural Language Processing (QNLP).\nPrevious use of density matrices in QNLP entails modelling ambiguous words as\nprobability distributions over more basic words (the word \\texttt{queen}, e.g.,\nmight mean the reigning queen or the chess piece). In this article, we\ninvestigate using probability distributions over processes to account for\nsyntactic ambiguity in sentences. The meanings of these sentences are\nrepresented by density matrices. We show how to create probability\ndistributions on quantum circuits that represent the meanings of sentences and\nexplain how this approach generalises tasks from the literature. We conduct an\nexperiment to validate the proposed theory.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "quant-ph",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00040v1",
    "published_date": "2025-03-30 19:10:37 UTC",
    "updated_date": "2025-03-30 19:10:37 UTC"
  },
  {
    "arxiv_id": "2503.23550v1",
    "title": "Addressing Model Overcomplexity in Drug-Drug Interaction Prediction With Molecular Fingerprints",
    "authors": [
      "Manel Gil-Sorribes",
      "Alexis Molina"
    ],
    "abstract": "Accurately predicting drug-drug interactions (DDIs) is crucial for\npharmaceutical research and clinical safety. Recent deep learning models often\nsuffer from high computational costs and limited generalization across\ndatasets. In this study, we investigate a simpler yet effective approach using\nmolecular representations such as Morgan fingerprints (MFPS), graph-based\nembeddings from graph convolutional networks (GCNs), and transformer-derived\nembeddings from MoLFormer integrated into a straightforward neural network. We\nbenchmark our implementation on DrugBank DDI splits and a drug-drug affinity\n(DDA) dataset from the Food and Drug Administration. MFPS along with MoLFormer\nand GCN representations achieve competitive performance across tasks, even in\nthe more challenging leak-proof split, highlighting the sufficiency of simple\nmolecular representations. Moreover, we are able to identify key molecular\nmotifs and structural patterns relevant to drug interactions via gradient-based\nanalyses using the representations under study. Despite these results, dataset\nlimitations such as insufficient chemical diversity, limited dataset size, and\ninconsistent labeling impact robust evaluation and challenge the need for more\ncomplex approaches. Our work provides a meaningful baseline and emphasizes the\nneed for better dataset curation and progressive complexity scaling.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Accepted to the GEM Workshop at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23550v1",
    "published_date": "2025-03-30 18:27:01 UTC",
    "updated_date": "2025-03-30 18:27:01 UTC"
  },
  {
    "arxiv_id": "2503.23536v2",
    "title": "A Survey on Unlearnable Data",
    "authors": [
      "Jiahao Li",
      "Yiqiang Chen",
      "Yunbing Xing",
      "Yang Gu",
      "Xiangyuan Lan"
    ],
    "abstract": "Unlearnable data (ULD) has emerged as an innovative defense technique to\nprevent machine learning models from learning meaningful patterns from specific\ndata, thus protecting data privacy and security. By introducing perturbations\nto the training data, ULD degrades model performance, making it difficult for\nunauthorized models to extract useful representations. Despite the growing\nsignificance of ULD, existing surveys predominantly focus on related fields,\nsuch as adversarial attacks and machine unlearning, with little attention given\nto ULD as an independent area of study. This survey fills that gap by offering\na comprehensive review of ULD, examining unlearnable data generation methods,\npublic benchmarks, evaluation metrics, theoretical foundations and practical\napplications. We compare and contrast different ULD approaches, analyzing their\nstrengths, limitations, and trade-offs related to unlearnability,\nimperceptibility, efficiency and robustness. Moreover, we discuss key\nchallenges, such as balancing perturbation imperceptibility with model\ndegradation and the computational complexity of ULD generation. Finally, we\nhighlight promising future research directions to advance the effectiveness and\napplicability of ULD, underscoring its potential to become a crucial tool in\nthe evolving landscape of data protection in machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 3 figures, Code in\n  https://github.com/LiJiahao-Alex/Awesome-UnLearnable-Data",
    "pdf_url": "http://arxiv.org/pdf/2503.23536v2",
    "published_date": "2025-03-30 17:41:30 UTC",
    "updated_date": "2025-04-01 16:42:45 UTC"
  },
  {
    "arxiv_id": "2503.23534v1",
    "title": "BiPVL-Seg: Bidirectional Progressive Vision-Language Fusion with Global-Local Alignment for Medical Image Segmentation",
    "authors": [
      "Rafi Ibn Sultan",
      "Hui Zhu",
      "Chengyin Li",
      "Dongxiao Zhu"
    ],
    "abstract": "Medical image segmentation typically relies solely on visual data,\noverlooking the rich textual information clinicians use for diagnosis.\nVision-language models attempt to bridge this gap, but existing approaches\noften process visual and textual features independently, resulting in weak\ncross-modal alignment. Simple fusion techniques fail due to the inherent\ndifferences between spatial visual features and sequential text embeddings.\nAdditionally, medical terminology deviates from general language, limiting the\neffectiveness of off-the-shelf text encoders and further hindering\nvision-language alignment. We propose BiPVL-Seg, an end-to-end framework that\nintegrates vision-language fusion and embedding alignment through architectural\nand training innovations, where both components reinforce each other to enhance\nmedical image segmentation. BiPVL-Seg introduces bidirectional progressive\nfusion in the architecture, which facilitates stage-wise information exchange\nbetween vision and text encoders. Additionally, it incorporates global-local\ncontrastive alignment, a training objective that enhances the text encoder's\ncomprehension by aligning text and vision embeddings at both class and concept\nlevels. Extensive experiments on diverse medical imaging benchmarks across CT\nand MR modalities demonstrate BiPVL-Seg's superior performance when compared\nwith state-of-the-art methods in complex multi-class segmentation. Source code\nis available in this GitHub repository.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23534v1",
    "published_date": "2025-03-30 17:34:39 UTC",
    "updated_date": "2025-03-30 17:34:39 UTC"
  },
  {
    "arxiv_id": "2503.23514v1",
    "title": "If an LLM Were a Character, Would It Know Its Own Story? Evaluating Lifelong Learning in LLMs",
    "authors": [
      "Siqi Fan",
      "Xiusheng Huang",
      "Yiqun Yao",
      "Xuezhi Fang",
      "Kang Liu",
      "Peng Han",
      "Shuo Shang",
      "Aixin Sun",
      "Yequan Wang"
    ],
    "abstract": "Large language models (LLMs) can carry out human-like dialogue, but unlike\nhumans, they are stateless due to the superposition property. However, during\nmulti-turn, multi-agent interactions, LLMs begin to exhibit consistent,\ncharacter-like behaviors, hinting at a form of emergent lifelong learning.\nDespite this, existing benchmarks often fail to capture these dynamics,\nprimarily focusing on static, open-ended evaluations. To address this gap, we\nintroduce LIFESTATE-BENCH, a benchmark designed to assess lifelong learning in\nLLMs. It features two episodic datasets: Hamlet and a synthetic script\ncollection, rich in narrative structure and character interactions. Our fact\nchecking evaluation probes models' self-awareness, episodic memory retrieval,\nand relationship tracking, across both parametric and non-parametric\napproaches. Experiments on models like Llama3.1-8B, GPT-4-turbo, and DeepSeek\nR1, we demonstrate that nonparametric methods significantly outperform\nparametric ones in managing stateful learning. However, all models exhibit\nchallenges with catastrophic forgetting as interactions extend, highlighting\nthe need for further advancements in lifelong learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23514v1",
    "published_date": "2025-03-30 16:50:57 UTC",
    "updated_date": "2025-03-30 16:50:57 UTC"
  },
  {
    "arxiv_id": "2503.23511v1",
    "title": "Buffer is All You Need: Defending Federated Learning against Backdoor Attacks under Non-iids via Buffering",
    "authors": [
      "Xingyu Lyu",
      "Ning Wang",
      "Yang Xiao",
      "Shixiong Li",
      "Tao Li",
      "Danjue Chen",
      "Yimin Chen"
    ],
    "abstract": "Federated Learning (FL) is a popular paradigm enabling clients to jointly\ntrain a global model without sharing raw data. However, FL is known to be\nvulnerable towards backdoor attacks due to its distributed nature. As\nparticipants, attackers can upload model updates that effectively compromise\nFL. What's worse, existing defenses are mostly designed under\nindependent-and-identically-distributed (iid) settings, hence neglecting the\nfundamental non-iid characteristic of FL. Here we propose FLBuff for tackling\nbackdoor attacks even under non-iids. The main challenge for such defenses is\nthat non-iids bring benign and malicious updates closer, hence harder to\nseparate. FLBuff is inspired by our insight that non-iids can be modeled as\nomni-directional expansion in representation space while backdoor attacks as\nuni-directional. This leads to the key design of FLBuff, i.e., a\nsupervised-contrastive-learning model extracting penultimate-layer\nrepresentations to create a large in-between buffer layer. Comprehensive\nevaluations demonstrate that FLBuff consistently outperforms state-of-the-art\ndefenses.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23511v1",
    "published_date": "2025-03-30 16:46:14 UTC",
    "updated_date": "2025-03-30 16:46:14 UTC"
  },
  {
    "arxiv_id": "2503.23502v1",
    "title": "Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model",
    "authors": [
      "Jannik Endres",
      "Oliver Hahn",
      "Charles Corbière",
      "Simone Schaub-Meyer",
      "Stefan Roth",
      "Alexandre Alahi"
    ],
    "abstract": "Omnidirectional depth perception is essential for mobile robotics\napplications that require scene understanding across a full 360{\\deg} field of\nview. Camera-based setups offer a cost-effective option by using stereo depth\nestimation to generate dense, high-resolution depth maps without relying on\nexpensive active sensing. However, existing omnidirectional stereo matching\napproaches achieve only limited depth accuracy across diverse environments,\ndepth ranges, and lighting conditions, due to the scarcity of real-world data.\nWe present DFI-OmniStereo, a novel omnidirectional stereo matching method that\nleverages a large-scale pre-trained foundation model for relative monocular\ndepth estimation within an iterative optimization-based stereo matching\narchitecture. We introduce a dedicated two-stage training strategy to utilize\nthe relative monocular depth features for our omnidirectional stereo matching\nbefore scale-invariant fine-tuning. DFI-OmniStereo achieves state-of-the-art\nresults on the real-world Helvipad dataset, reducing disparity MAE by\napproximately 16% compared to the previous best omnidirectional stereo method.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://vita-epfl.github.io/DFI-OmniStereo-website/",
    "pdf_url": "http://arxiv.org/pdf/2503.23502v1",
    "published_date": "2025-03-30 16:24:22 UTC",
    "updated_date": "2025-03-30 16:24:22 UTC"
  },
  {
    "arxiv_id": "2504.00038v1",
    "title": "Revisiting the Relationship between Adversarial and Clean Training: Why Clean Training Can Make Adversarial Training Better",
    "authors": [
      "MingWei Zhou",
      "Xiaobing Pei"
    ],
    "abstract": "Adversarial training (AT) is an effective technique for enhancing adversarial\nrobustness, but it usually comes at the cost of a decline in generalization\nability. Recent studies have attempted to use clean training to assist\nadversarial training, yet there are contradictions among the conclusions. We\ncomprehensively summarize the representative strategies and, with a focus on\nthe multi - view hypothesis, provide a unified explanation for the\ncontradictory phenomena among different studies. In addition, we conduct an in\n- depth analysis of the knowledge combinations transferred from clean - trained\nmodels to adversarially - trained models in previous studies, and find that\nthey can be divided into two categories: reducing the learning difficulty and\nproviding correct guidance. Based on this finding, we propose a new idea of\nleveraging clean training to further improve the performance of advanced AT\nmethods.We reveal that the problem of generalization degradation faced by AT\npartly stems from the difficulty of adversarial training in learning certain\nsample features, and this problem can be alleviated by making full use of clean\ntraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00038v1",
    "published_date": "2025-03-30 15:58:41 UTC",
    "updated_date": "2025-03-30 15:58:41 UTC"
  },
  {
    "arxiv_id": "2503.23491v1",
    "title": "POINT$^{2}$: A Polymer Informatics Training and Testing Database",
    "authors": [
      "Jiaxin Xu",
      "Gang Liu",
      "Ruilan Guo",
      "Meng Jiang",
      "Tengfei Luo"
    ],
    "abstract": "The advancement of polymer informatics has been significantly propelled by\nthe integration of machine learning (ML) techniques, enabling the rapid\nprediction of polymer properties and expediting the discovery of\nhigh-performance polymeric materials. However, the field lacks a standardized\nworkflow that encompasses prediction accuracy, uncertainty quantification, ML\ninterpretability, and polymer synthesizability. In this study, we introduce\nPOINT$^{2}$ (POlymer INformatics Training and Testing), a comprehensive\nbenchmark database and protocol designed to address these critical challenges.\nLeveraging the existing labeled datasets and the unlabeled PI1M dataset, a\ncollection of approximately one million virtual polymers generated via a\nrecurrent neural network trained on the realistic polymers, we develop an\nensemble of ML models, including Quantile Random Forests, Multilayer\nPerceptrons with dropout, Graph Neural Networks, and pretrained large language\nmodels. These models are coupled with diverse polymer representations such as\nMorgan, MACCS, RDKit, Topological, Atom Pair fingerprints, and graph-based\ndescriptors to achieve property predictions, uncertainty estimations, model\ninterpretability, and template-based polymerization synthesizability across a\nspectrum of properties, including gas permeability, thermal conductivity, glass\ntransition temperature, melting temperature, fractional free volume, and\ndensity. The POINT$^{2}$ database can serve as a valuable resource for the\npolymer informatics community for polymer discovery and optimization.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23491v1",
    "published_date": "2025-03-30 15:46:01 UTC",
    "updated_date": "2025-03-30 15:46:01 UTC"
  },
  {
    "arxiv_id": "2503.23487v1",
    "title": "Benchmarking Systematic Relational Reasoning with Large Language and Reasoning Models",
    "authors": [
      "Irtaza Khalid",
      "Amir Masoud Nourollah",
      "Steven Schockaert"
    ],
    "abstract": "Large Language Models (LLMs) have been found to struggle with systematic\nreasoning. Even on tasks where they appear to perform well, their performance\noften depends on shortcuts, rather than on genuine reasoning abilities, leading\nthem to collapse on out-of-distribution examples. Post-training strategies\nbased on reinforcement learning and chain-of-thought prompting have recently\nbeen hailed as a step change. However, little is still known about the\npotential of the resulting ``Large Reasoning Models'' (LRMs) beyond problem\nsolving in mathematics and programming, where finding genuine\nout-of-distribution problems can be difficult. In this paper, we focus on tasks\nthat require systematic reasoning about relational compositions, especially for\nqualitative spatial and temporal reasoning. These tasks allow us to control the\ndifficulty of problem instances, and measure in a precise way to what extent\nmodels can generalise. We find that that the considered LLMs and LRMs overall\nperform poorly overall, albeit better than random chance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23487v1",
    "published_date": "2025-03-30 15:41:55 UTC",
    "updated_date": "2025-03-30 15:41:55 UTC"
  },
  {
    "arxiv_id": "2503.23486v1",
    "title": "A Systematic Decade Review of Trip Route Planning with Travel Time Estimation based on User Preferences and Behavior",
    "authors": [
      "Nikil Jayasuriya",
      "Deshan Sumanathilaka"
    ],
    "abstract": "This paper systematically explores the advancements in adaptive trip route\nplanning and travel time estimation (TTE) through Artificial Intelligence (AI).\nWith the increasing complexity of urban transportation systems, traditional\nnavigation methods often struggle to accommodate dynamic user preferences,\nreal-time traffic conditions, and scalability requirements. This study explores\nthe contributions of established AI techniques, including Machine Learning\n(ML), Reinforcement Learning (RL), and Graph Neural Networks (GNNs), alongside\nemerging methodologies like Meta-Learning, Explainable AI (XAI), Generative AI,\nand Federated Learning. In addition to highlighting these innovations, the\npaper identifies critical challenges such as ethical concerns, computational\nscalability, and effective data integration, which must be addressed to advance\nthe field. The paper concludes with recommendations for leveraging AI to build\nefficient, transparent, and sustainable navigation systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.23486v1",
    "published_date": "2025-03-30 15:41:44 UTC",
    "updated_date": "2025-03-30 15:41:44 UTC"
  },
  {
    "arxiv_id": "2503.23483v1",
    "title": "Order Independence With Finetuning",
    "authors": [
      "Katrina Brown",
      "Reid McIlroy"
    ],
    "abstract": "Large language models (LLMs) demonstrate remarkable performance on many NLP\ntasks, yet often exhibit order dependence: simply reordering semantically\nidentical tokens (e.g., answer choices in multiple-choice questions) can lead\nto inconsistent predictions. Recent work proposes Set-Based Prompting (SBP) as\na way to remove order information from designated token subsets, thereby\nmitigating positional biases. However, applying SBP on base models induces an\nout-of-distribution input format, which can degrade in-distribution\nperformance. We introduce a fine-tuning strategy that integrates SBP into the\ntraining process, \"pulling\" these set-formatted prompts closer to the model's\ntraining manifold. We show that SBP can be incorporated into a model via\nfine-tuning. Our experiments on in-distribution (MMLU) and out-of-distribution\n(CSQA, ARC Challenge) multiple-choice tasks show that SBP fine-tuning\nsignificantly improves accuracy and robustness to answer-order permutations,\nall while preserving broader language modeling capabilities. We discuss the\nbroader implications of order-invariant modeling and outline future directions\nfor building fairer, more consistent LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a Bi-Align workshop paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23483v1",
    "published_date": "2025-03-30 15:38:43 UTC",
    "updated_date": "2025-03-30 15:38:43 UTC"
  },
  {
    "arxiv_id": "2504.00037v1",
    "title": "ViT-Linearizer: Distilling Quadratic Knowledge into Linear-Time Vision Models",
    "authors": [
      "Guoyizhe Wei",
      "Rama Chellappa"
    ],
    "abstract": "Vision Transformers (ViTs) have delivered remarkable progress through global\nself-attention, yet their quadratic complexity can become prohibitive for\nhigh-resolution inputs. In this work, we present ViT-Linearizer, a\ncross-architecture distillation framework that transfers rich ViT\nrepresentations into a linear-time, recurrent-style model. Our approach\nleverages 1) activation matching, an intermediate constraint that encourages\nstudent to align its token-wise dependencies with those produced by the\nteacher, and 2) masked prediction, a contextual reconstruction objective that\nrequires the student to predict the teacher's representations for unseen\n(masked) tokens, to effectively distill the quadratic self-attention knowledge\ninto the student while maintaining efficient complexity. Empirically, our\nmethod provides notable speedups particularly for high-resolution tasks,\nsignificantly addressing the hardware challenges in inference. Additionally, it\nalso elevates Mamba-based architectures' performance on standard vision\nbenchmarks, achieving a competitive 84.3% top-1 accuracy on ImageNet with a\nbase-sized model. Our results underscore the good potential of RNN-based\nsolutions for large-scale visual tasks, bridging the gap between theoretical\nefficiency and real-world practice.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00037v1",
    "published_date": "2025-03-30 15:35:24 UTC",
    "updated_date": "2025-03-30 15:35:24 UTC"
  },
  {
    "arxiv_id": "2503.23478v1",
    "title": "Handling Delay in Real-Time Reinforcement Learning",
    "authors": [
      "Ivan Anokhin",
      "Rishav Rishav",
      "Matthew Riemer",
      "Stephen Chung",
      "Irina Rish",
      "Samira Ebrahimi Kahou"
    ],
    "abstract": "Real-time reinforcement learning (RL) introduces several challenges. First,\npolicies are constrained to a fixed number of actions per second due to\nhardware limitations. Second, the environment may change while the network is\nstill computing an action, leading to observational delay. The first issue can\npartly be addressed with pipelining, leading to higher throughput and\npotentially better policies. However, the second issue remains: if each neuron\noperates in parallel with an execution time of $\\tau$, an $N$-layer\nfeed-forward network experiences observation delay of $\\tau N$. Reducing the\nnumber of layers can decrease this delay, but at the cost of the network's\nexpressivity. In this work, we explore the trade-off between minimizing delay\nand network's expressivity. We present a theoretically motivated solution that\nleverages temporal skip connections combined with history-augmented\nobservations. We evaluate several architectures and show that those\nincorporating temporal skip connections achieve strong performance across\nvarious neuron execution times, reinforcement learning algorithms, and\nenvironments, including four Mujoco tasks and all MinAtar games. Moreover, we\ndemonstrate parallel neuron computation can accelerate inference by 6-350% on\nstandard hardware. Our investigation into temporal skip connections and\nparallel computations paves the way for more efficient RL agents in real-time\nsetting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025. Code available at\n  https://github.com/avecplezir/realtime-agent",
    "pdf_url": "http://arxiv.org/pdf/2503.23478v1",
    "published_date": "2025-03-30 15:30:27 UTC",
    "updated_date": "2025-03-30 15:30:27 UTC"
  },
  {
    "arxiv_id": "2504.13186v1",
    "title": "Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection",
    "authors": [
      "Yassine Habchi",
      "Hamza Kheddar",
      "Yassine Himeur",
      "Adel Belouchrani",
      "Erchin Serpedin",
      "Fouad Khelifi",
      "Muhammad E. H. Chowdhury"
    ],
    "abstract": "The rapid advancement of deep learning (DL) has transformed healthcare,\nparticularly in cancer detection and diagnosis. DL surpasses traditional\nmachine learning and human accuracy, making it a critical tool for identifying\ndiseases. Despite numerous reviews on DL in healthcare, a comprehensive\nanalysis of its role in cancer detection remains limited. Existing studies\nfocus on specific aspects, leaving gaps in understanding its broader impact.\nThis paper addresses these gaps by reviewing advanced DL techniques, including\ntransfer learning (TL), reinforcement learning (RL), federated learning (FL),\nTransformers, and large language models (LLMs). These approaches enhance\naccuracy, tackle data scarcity, and enable decentralized learning while\nmaintaining data privacy. TL adapts pre-trained models to new datasets,\nimproving performance with limited labeled data. RL optimizes diagnostic\npathways and treatment strategies, while FL fosters collaborative model\ndevelopment without sharing sensitive data. Transformers and LLMs,\ntraditionally used in natural language processing, are now applied to medical\ndata for improved interpretability. Additionally, this review examines these\ntechniques' efficiency in cancer diagnosis, addresses challenges like data\nimbalance, and proposes solutions. It serves as a resource for researchers and\npractitioners, providing insights into current trends and guiding future\nresearch in advanced DL for cancer detection.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13186v1",
    "published_date": "2025-03-30 15:17:40 UTC",
    "updated_date": "2025-03-30 15:17:40 UTC"
  },
  {
    "arxiv_id": "2503.23466v1",
    "title": "Codehacks: A Dataset of Adversarial Tests for Competitive Programming Problems Obtained from Codeforces",
    "authors": [
      "Max Hort",
      "Leon Moonen"
    ],
    "abstract": "Software is used in critical applications in our day-to-day life and it is\nimportant to ensure its correctness. One popular approach to assess correctness\nis to evaluate software on tests. If a test fails, it indicates a fault in the\nsoftware under test; if all tests pass correctly, one may assume that the\nsoftware is correct. However, the reliability of these results depends on the\ntest suite considered, and there is a risk of false negatives (i.e. software\nthat passes all available tests but contains bugs because some cases are not\ntested). Therefore, it is important to consider error-inducing test cases when\nevaluating software.\n  To support data-driven creation of such a test-suite, which is especially of\ninterest for testing software synthesized from large language models, we curate\na dataset (Codehacks) of programming problems together with corresponding\nerror-inducing test cases (i.e., \"hacks\"). This dataset is collected from the\nwild, in particular, from the Codeforces online judge platform. The dataset\ncomprises 288,617 hacks for 5,578 programming problems, each with a natural\nlanguage description, as well as the source code for 2,196 submitted solutions\nto these problems that can be broken with their corresponding hacks.\n  Keywords: competitive programming, language model, dataset",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at the 18th IEEE International Conference on\n  Software Testing, Verification and Validation (ICST 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.23466v1",
    "published_date": "2025-03-30 14:50:03 UTC",
    "updated_date": "2025-03-30 14:50:03 UTC"
  },
  {
    "arxiv_id": "2504.01985v1",
    "title": "Multi-Dimensional AGV Path Planning in 3D Warehouses Using Ant Colony Optimization and Advanced Neural Networks",
    "authors": [
      "Bo Zhang",
      "Xiubo Liang",
      "Wei Song",
      "Yulu Chen"
    ],
    "abstract": "Within modern warehouse scenarios, the rapid expansion of e-commerce and\nincreasingly complex, multi-level storage environments have exposed the\nlimitations of traditional AGV (Automated Guided Vehicle) path planning\nmethods--often reliant on static 2D models and expert-tuned heuristics that\nstruggle to handle dynamic traffic and congestion. Addressing these\nlimitations, this paper introduces a novel AGV path planning approach for 3D\nwarehouse environments that leverages a hybrid framework combining ACO (Ant\nColony Optimization) with deep learning models, called NAHACO (Neural Adaptive\nHeuristic Ant Colony Optimization). NAHACO integrates three key innovations:\nfirst, an innovative heuristic algorithm for 3D warehouse cargo modeling using\nmultidimensional tensors, which addresses the challenge of achieving superior\nheuristic accuracy; second, integration of a congestion-aware loss function\nwithin the ACO framework to adjust path costs based on traffic and capacity\nconstraints, called CARL (Congestion-Aware Reinforce Loss), enabling dynamic\nheuristic calibration for optimizing ACO-based path planning; and third, an\nadaptive attention mechanism that captures multi-scale spatial features,\nthereby addressing dynamic heuristic calibration for further optimization of\nACO-based path planning and AGV navigation. NAHACO significantly boosts path\nplanning efficiency, yielding faster computation times and superior performance\nover both vanilla and state-of-the-art methods, while automatically adapting to\nwarehouse constraints for real-time optimization. NAHACO outperforms\nstate-of-the-art methods, lowering the total cost by up to 24.7% on TSP\nbenchmarks. In warehouse tests, NAHACO cuts cost by up to 41.5% and congestion\nby up to 56.1% compared to previous methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01985v1",
    "published_date": "2025-03-30 14:09:21 UTC",
    "updated_date": "2025-03-30 14:09:21 UTC"
  },
  {
    "arxiv_id": "2503.23448v1",
    "title": "Semantic-Preserving Transformations as Mutation Operators: A Study on Their Effectiveness in Defect Detection",
    "authors": [
      "Max Hort",
      "Linas Vidziunas",
      "Leon Moonen"
    ],
    "abstract": "Recent advances in defect detection use language models. Existing works\nenhanced the training data to improve the models' robustness when applied to\nsemantically identical code (i.e., predictions should be the same). However,\nthe use of semantically identical code has not been considered for improving\nthe tools during their application - a concept closely related to metamorphic\ntesting.\n  The goal of our study is to determine whether we can use semantic-preserving\ntransformations, analogue to mutation operators, to improve the performance of\ndefect detection tools in the testing stage. We first collect existing\npublications which implemented semantic-preserving transformations and share\ntheir implementation, such that we can reuse them. We empirically study the\neffectiveness of three different ensemble strategies for enhancing defect\ndetection tools. We apply the collected transformations on the Devign dataset,\nconsidering vulnerabilities as a type of defect, and two fine-tuned large\nlanguage models for defect detection (VulBERTa, PLBART). We found 28\npublications with 94 different transformations.\n  We choose to implement 39 transformations from four of the publications, but\na manual check revealed that 23 out 39 transformations change code semantics.\nUsing the 16 remaining, correct transformations and three ensemble strategies,\nwe were not able to increase the accuracy of the defect detection models. Our\nresults show that reusing shared semantic-preserving transformation is\ndifficult, sometimes even causing wrongful changes to the semantics.\n  Keywords: defect detection, language model, semantic-preserving\ntransformation, ensemble",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication in Mutation 2025 at the 18th IEEE\n  International Conference on Software Testing, Verification and Validation\n  (ICST 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.23448v1",
    "published_date": "2025-03-30 14:00:22 UTC",
    "updated_date": "2025-03-30 14:00:22 UTC"
  },
  {
    "arxiv_id": "2503.23439v1",
    "title": "Speculative End-Turn Detector for Efficient Speech Chatbot Assistant",
    "authors": [
      "Hyunjong Ok",
      "Suho Yoo",
      "Jaeho Lee"
    ],
    "abstract": "Spoken dialogue systems powered by large language models have demonstrated\nremarkable abilities in understanding human speech and generating appropriate\nspoken responses. However, these systems struggle with end-turn detection (ETD)\n-- the ability to distinguish between user turn completion and hesitation. This\nlimitation often leads to premature or delayed responses, disrupting the flow\nof spoken conversations. In this paper, we introduce the ETD Dataset, the first\npublic dataset for end-turn detection. The ETD dataset consists of both\nsynthetic speech data generated with text-to-speech models and real-world\nspeech data collected from web sources. We also propose SpeculativeETD, a novel\ncollaborative inference framework that balances efficiency and accuracy to\nimprove real-time ETD in resource-constrained environments. Our approach\njointly employs a lightweight GRU-based model, which rapidly detects the\nnon-speaking units in real-time on local devices, and a high-performance\nWav2vec-based model running on the server to make a more challenging\nclassification of distinguishing turn ends from mere pauses. Experiments\ndemonstrate that the proposed SpeculativeETD significantly improves ETD\naccuracy while keeping the required computations low. Datasets and code will be\navailable after the review.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.23439v1",
    "published_date": "2025-03-30 13:34:23 UTC",
    "updated_date": "2025-03-30 13:34:23 UTC"
  },
  {
    "arxiv_id": "2504.00036v1",
    "title": "Improving Diseases Predictions Utilizing External Bio-Banks",
    "authors": [
      "Hido Pinto",
      "Eran Segal"
    ],
    "abstract": "Machine learning has been successfully used in critical domains, such as\nmedicine. However, extracting meaningful insights from biomedical data is often\nconstrained by the lack of their available disease labels. In this research, we\ndemonstrate how machine learning can be leveraged to enhance explainability and\nuncover biologically meaningful associations, even when predictive improvements\nin disease modeling are limited. We train LightGBM models from scratch on our\ndataset (10K) to impute metabolomics features and apply them to the UK Biobank\n(UKBB) for downstream analysis. The imputed metabolomics features are then used\nin survival analysis to assess their impact on disease-related risk factors. As\na result, our approach successfully identified biologically relevant\nconnections that were not previously known to the predictive models.\nAdditionally, we applied a genome-wide association study (GWAS) on key\nmetabolomics features, revealing a link between vascular dementia and smoking.\nAlthough being a well-established epidemiological relationship, this link was\nnot embedded in the model's training data, which validated the method's ability\nto extract meaningful signals. Furthermore, by integrating survival models as\ninputs in the 10K data, we uncovered associations between metabolic substances\nand obesity, demonstrating the ability to infer disease risk for future\npatients without requiring direct outcome labels. These findings highlight the\npotential of leveraging external bio-banks to extract valuable biomedical\ninsights, even in data-limited scenarios. Our results demonstrate that machine\nlearning models trained on smaller datasets can still be used to uncover real\nbiological associations when carefully integrated with survival analysis and\ngenetic studies.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00036v1",
    "published_date": "2025-03-30 13:05:20 UTC",
    "updated_date": "2025-03-30 13:05:20 UTC"
  },
  {
    "arxiv_id": "2503.23424v1",
    "title": "What Makes an Evaluation Useful? Common Pitfalls and Best Practices",
    "authors": [
      "Gil Gekker",
      "Meirav Segal",
      "Dan Lahav",
      "Omer Nevo"
    ],
    "abstract": "Following the rapid increase in Artificial Intelligence (AI) capabilities in\nrecent years, the AI community has voiced concerns regarding possible safety\nrisks. To support decision-making on the safe use and development of AI\nsystems, there is a growing need for high-quality evaluations of dangerous\nmodel capabilities. While several attempts to provide such evaluations have\nbeen made, a clear definition of what constitutes a \"good evaluation\" has yet\nto be agreed upon. In this practitioners' perspective paper, we present a set\nof best practices for safety evaluations, drawing on prior work in model\nevaluation and illustrated through cybersecurity examples. We first discuss the\nsteps of the initial thought process, which connects threat modeling to\nevaluation design. Then, we provide the characteristics and parameters that\nmake an evaluation useful. Finally, we address additional considerations as we\nmove from building specific evaluations to building a full and comprehensive\nevaluation suite.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23424v1",
    "published_date": "2025-03-30 12:51:47 UTC",
    "updated_date": "2025-03-30 12:51:47 UTC"
  },
  {
    "arxiv_id": "2504.08758v1",
    "title": "Hyper-RAG: Combating LLM Hallucinations using Hypergraph-Driven Retrieval-Augmented Generation",
    "authors": [
      "Yifan Feng",
      "Hao Hu",
      "Xingliang Hou",
      "Shiquan Liu",
      "Shihui Ying",
      "Shaoyi Du",
      "Han Hu",
      "Yue Gao"
    ],
    "abstract": "Large language models (LLMs) have transformed various sectors, including\neducation, finance, and medicine, by enhancing content generation and\ndecision-making processes. However, their integration into the medical field is\ncautious due to hallucinations, instances where generated content deviates from\nfactual accuracy, potentially leading to adverse outcomes. To address this, we\nintroduce Hyper-RAG, a hypergraph-driven Retrieval-Augmented Generation method\nthat comprehensively captures both pairwise and beyond-pairwise correlations in\ndomain-specific knowledge, thereby mitigating hallucinations. Experiments on\nthe NeurologyCrop dataset with six prominent LLMs demonstrated that Hyper-RAG\nimproves accuracy by an average of 12.3% over direct LLM use and outperforms\nGraph RAG and Light RAG by 6.3% and 6.0%, respectively. Additionally, Hyper-RAG\nmaintained stable performance with increasing query complexity, unlike existing\nmethods which declined. Further validation across nine diverse datasets showed\na 35.5% performance improvement over Light RAG using a selection-based\nassessment. The lightweight variant, Hyper-RAG-Lite, achieved twice the\nretrieval speed and a 3.3% performance boost compared with Light RAG. These\nresults confirm Hyper-RAG's effectiveness in enhancing LLM reliability and\nreducing hallucinations, making it a robust solution for high-stakes\napplications like medical diagnostics.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08758v1",
    "published_date": "2025-03-30 12:39:14 UTC",
    "updated_date": "2025-03-30 12:39:14 UTC"
  },
  {
    "arxiv_id": "2503.23415v1",
    "title": "An Analysis of Decoding Methods for LLM-based Agents for Faithful Multi-Hop Question Answering",
    "authors": [
      "Alexander Murphy",
      "Mohd Sanad Zaki Rizvi",
      "Aden Haussmann",
      "Ping Nie",
      "Guifu Liu",
      "Aryo Pradipta Gema",
      "Pasquale Minervini"
    ],
    "abstract": "Large Language Models (LLMs) frequently produce factually inaccurate outputs\n- a phenomenon known as hallucination - which limits their accuracy in\nknowledge-intensive NLP tasks. Retrieval-augmented generation and agentic\nframeworks such as Reasoning and Acting (ReAct) can address this issue by\ngiving the model access to external knowledge. However, LLMs often fail to\nremain faithful to retrieved information. Mitigating this is critical,\nespecially if LLMs are required to reason about the retrieved information.\nRecent research has explored training-free decoding strategies to improve the\nfaithfulness of model generations. We present a systematic analysis of how the\ncombination of the ReAct framework and decoding strategies (i.e., DeCoRe, DoLa,\nand CAD) can influence the faithfulness of LLM-generated answers. Our results\nshow that combining an agentic framework for knowledge retrieval with decoding\nmethods that enhance faithfulness can increase accuracy on the downstream\nMulti-Hop Question Answering tasks. For example, we observe an F1 increase from\n19.5 to 32.6 on HotpotQA when using ReAct and DoLa.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23415v1",
    "published_date": "2025-03-30 12:18:21 UTC",
    "updated_date": "2025-03-30 12:18:21 UTC"
  },
  {
    "arxiv_id": "2503.23414v1",
    "title": "From Content Creation to Citation Inflation: A GenAI Case Study",
    "authors": [
      "Haitham S. Al-Sinani",
      "Chris J. Mitchell"
    ],
    "abstract": "This paper investigates the presence and impact of questionable, AI-generated\nacademic papers on widely used preprint repositories, with a focus on their\nrole in citation manipulation. Motivated by suspicious patterns observed in\npublications related to our ongoing research on GenAI-enhanced cybersecurity,\nwe identify clusters of questionable papers and profiles. These papers\nfrequently exhibit minimal technical content, repetitive structure,\nunverifiable authorship, and mutually reinforcing citation patterns among a\nrecurring set of authors. To assess the feasibility and implications of such\npractices, we conduct a controlled experiment: generating a fake paper using\nGenAI, embedding citations to suspected questionable publications, and\nuploading it to one such repository (ResearchGate). Our findings demonstrate\nthat such papers can bypass platform checks, remain publicly accessible, and\ncontribute to inflating citation metrics like the H-index and i10-index. We\npresent a detailed analysis of the mechanisms involved, highlight systemic\nweaknesses in content moderation, and offer recommendations for improving\nplatform accountability and preserving academic integrity in the age of GenAI.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.DL",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.23414v1",
    "published_date": "2025-03-30 12:17:26 UTC",
    "updated_date": "2025-03-30 12:17:26 UTC"
  },
  {
    "arxiv_id": "2503.23407v1",
    "title": "GMapLatent: Geometric Mapping in Latent Space",
    "authors": [
      "Wei Zeng",
      "Xuebin Chang",
      "Jianghao Su",
      "Xiang Gu",
      "Jian Sun",
      "Zongben Xu"
    ],
    "abstract": "Cross-domain generative models based on encoder-decoder AI architectures have\nattracted much attention in generating realistic images, where domain alignment\nis crucial for generation accuracy. Domain alignment methods usually deal\ndirectly with the initial distribution; however, mismatched or mixed clusters\ncan lead to mode collapse and mixture problems in the decoder, compromising\nmodel generalization capabilities. In this work, we innovate a cross-domain\nalignment and generation model that introduces a canonical latent space\nrepresentation based on geometric mapping to align the cross-domain latent\nspaces in a rigorous and precise manner, thus avoiding mode collapse and\nmixture in the encoder-decoder generation architectures. We name this model\nGMapLatent. The core of the method is to seamlessly align latent spaces with\nstrict cluster correspondence constraints using the canonical parameterizations\nof cluster-decorated latent spaces. We first (1) transform the latent space to\na canonical parameter domain by composing barycenter translation, optimal\ntransport merging and constrained harmonic mapping, and then (2) compute\ngeometric registration with cluster constraints over the canonical parameter\ndomains. This process realizes a bijective (one-to-one and onto) mapping\nbetween newly transformed latent spaces and generates a precise alignment of\ncluster pairs. Cross-domain generation is then achieved through the aligned\nlatent spaces embedded in the encoder-decoder pipeline. Experiments on\ngray-scale and color images validate the efficiency, efficacy and applicability\nof GMapLatent, and demonstrate that the proposed model has superior performance\nover existing models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23407v1",
    "published_date": "2025-03-30 12:02:36 UTC",
    "updated_date": "2025-03-30 12:02:36 UTC"
  },
  {
    "arxiv_id": "2503.23402v1",
    "title": "Diffusion Meets Few-shot Class Incremental Learning",
    "authors": [
      "Junsu Kim",
      "Yunhoe Ku",
      "Dongyoon Han",
      "Seungryul Baek"
    ],
    "abstract": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely\nlimited training data; while aiming to reduce catastrophic forgetting and learn\nnew information. We propose Diffusion-FSCIL, a novel approach that employs a\ntext-to-image diffusion model as a frozen backbone. Our conjecture is that\nFSCIL can be tackled using a large generative model's capabilities benefiting\nfrom 1) generation ability via large-scale pre-training; 2) multi-scale\nrepresentation; 3) representational flexibility through the text encoder. To\nmaximize the representation capability, we propose to extract multiple\ncomplementary diffusion features to play roles as latent replay with slight\nsupport from feature distillation for preventing generative biases. Our\nframework realizes efficiency through 1) using a frozen backbone; 2) minimal\ntrainable components; 3) batch processing of multiple feature extractions.\nExtensive experiments on CUB-200, miniImageNet, and CIFAR-100 show that\nDiffusion-FSCIL surpasses state-of-the-art methods, preserving performance on\npreviously learned classes and adapting effectively to new ones.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "pre-print",
    "pdf_url": "http://arxiv.org/pdf/2503.23402v1",
    "published_date": "2025-03-30 11:20:08 UTC",
    "updated_date": "2025-03-30 11:20:08 UTC"
  },
  {
    "arxiv_id": "2503.23395v1",
    "title": "Scaling Auditory Cognition via Test-Time Compute in Audio Language Models",
    "authors": [
      "Ting Dang",
      "Yan Gao",
      "Hong Jia"
    ],
    "abstract": "Large language models (LLMs) have shown exceptional versatility in natural\nlanguage processing, prompting recent efforts to extend their multimodal\ncapabilities to speech processing through the development of audio large\nlanguage models (Audio LLMs). While Audio LLMs excel in tasks such as speech\nrecognition and synthesis, it remains unclear how they perform when faced with\nthe auditory cognitive challenges posed by real-world environments, such as\naudio comprehension and listening recall, particularly in the presence of\nbackground noise or overlapping speech. Unlike text-based LLMs, which have\naccess to vast amounts of text data for pre-training, retraining Audio LLMs\nwith diverse auditory cognitive scenes is difficult due to the limited datasets\nthat simulate real-world auditory cognitive scenarios and the challenge of\nacquiring auditory cognitive labels for training. While test-time compute (TTC)\nmethods have been shown to enhance the capabilities of text-based LLMs during\ninference, a key challenge lies in designing these TTC methods to improve the\nauditory capabilities of Audio LLMs. This study aims to address these two\nresearch gaps by: i) exploring the auditory cognitive capabilities of Audio\nLLMs, and ii) enhancing their capabilities using TTC approaches. We have\ninvestigated five different Audio LLMs for auditory cognition using a\n\\textit{self-collected} database and have proposed five TTC approaches to\nenhance auditory cognitive capabilities during inference. Our findings reveal\nthat Audio LLMs performance decreases in more challenging auditory cognitive\ntasks. The proposed TTC approaches significantly enhance cognitive auditory\ncapabilities, advancing the development of more adaptable and resilient Audio\nLLMs for practical applications such as assistive listening devices,\nvoice-based AI assistants, and communication technologies.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23395v1",
    "published_date": "2025-03-30 11:04:18 UTC",
    "updated_date": "2025-03-30 11:04:18 UTC"
  },
  {
    "arxiv_id": "2503.23394v1",
    "title": "Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications",
    "authors": [
      "Sangyoon Bae",
      "Junbeom Kwon",
      "Shinjae Yoo",
      "Jiook Cha"
    ],
    "abstract": "Understanding how the brain's complex nonlinear dynamics give rise to\nadaptive cognition and behavior is a central challenge in neuroscience. These\ndynamics exhibit scale-free and multifractal properties, influencing the\nreconfiguration of neural networks. However, conventional neuroimaging models\nare constrained by linear and stationary assumptions, limiting their ability to\ncapture these processes. Transformer-based architectures, known for capturing\nlong-range dependencies, align well with the brain's hierarchical and temporal\norganization. We introduce Multi-Band Brain Net (MBBN), a transformer-based\nframework that models frequency-specific spatiotemporal brain dynamics from\nfMRI by integrating scale-free network principles with frequency-resolved\nmulti-band self-attention. Trained on three large-scale neuroimaging cohorts\n(UK Biobank, ABCD, ABIDE) totaling 45,951 individuals, MBBN reveals previously\nundetectable frequency-dependent network interactions, shedding light on\nconnectivity disruptions in psychiatric conditions (ADHD, ASD, depression).\nThis validation shows robust generalizability and highlights core neural\nprinciples conserved across populations. MBBN achieves up to 30.59% higher\npredictive accuracy than state-of-the-art methods, demonstrating the advantage\nof frequency-informed spatiotemporal modeling in capturing latent neural\ncomputations. MBBN's interpretability uncovers novel frequency-specific\nbiomarkers for neurodevelopmental disorders, providing insights into the\nhierarchical organization of brain function. By offering an interpretable\nframework for spatiotemporal learning, MBBN provides insights into how neural\ncomputations underpin cognitive function and psychiatric vulnerability, with\nimplications for brain decoding, cognitive neuroscience, and precision\npsychiatry.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23394v1",
    "published_date": "2025-03-30 10:56:50 UTC",
    "updated_date": "2025-03-30 10:56:50 UTC"
  },
  {
    "arxiv_id": "2503.23390v1",
    "title": "Pareto Continual Learning: Preference-Conditioned Learning and Adaption for Dynamic Stability-Plasticity Trade-off",
    "authors": [
      "Song Lai",
      "Zhe Zhao",
      "Fei Zhu",
      "Xi Lin",
      "Qingfu Zhang",
      "Gaofeng Meng"
    ],
    "abstract": "Continual learning aims to learn multiple tasks sequentially. A key challenge\nin continual learning is balancing between two objectives: retaining knowledge\nfrom old tasks (stability) and adapting to new tasks (plasticity). Experience\nreplay methods, which store and replay past data alongside new data, have\nbecome a widely adopted approach to mitigate catastrophic forgetting. However,\nthese methods neglect the dynamic nature of the stability-plasticity trade-off\nand aim to find a fixed and unchanging balance, resulting in suboptimal\nadaptation during training and inference. In this paper, we propose Pareto\nContinual Learning (ParetoCL), a novel framework that reformulates the\nstability-plasticity trade-off in continual learning as a multi-objective\noptimization (MOO) problem. ParetoCL introduces a preference-conditioned model\nto efficiently learn a set of Pareto optimal solutions representing different\ntrade-offs and enables dynamic adaptation during inference. From a\ngeneralization perspective, ParetoCL can be seen as an objective augmentation\napproach that learns from different objective combinations of stability and\nplasticity. Extensive experiments across multiple datasets and settings\ndemonstrate that ParetoCL outperforms state-of-the-art methods and adapts to\ndiverse continual learning scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23390v1",
    "published_date": "2025-03-30 10:38:36 UTC",
    "updated_date": "2025-03-30 10:38:36 UTC"
  },
  {
    "arxiv_id": "2503.23388v1",
    "title": "COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation",
    "authors": [
      "Fanding Huang",
      "Jingyan Jiang",
      "Qinting Jiang",
      "Hebei Li",
      "Faisal Nadeem Khan",
      "Zhi Wang"
    ],
    "abstract": "Recent vision-language models (VLMs) face significant challenges in test-time\nadaptation to novel domains. While cache-based methods show promise by\nleveraging historical information, they struggle with both caching unreliable\nfeature-label pairs and indiscriminately using single-class information during\nquerying, significantly compromising adaptation accuracy. To address these\nlimitations, we propose COSMIC (Clique-Oriented Semantic Multi-space\nIntegration for CLIP), a robust test-time adaptation framework that enhances\nadaptability through multi-granular, cross-modal semantic caching and\ngraph-based querying mechanisms. Our framework introduces two key innovations:\nDual Semantics Graph (DSG) and Clique Guided Hyper-class (CGH). The Dual\nSemantics Graph constructs complementary semantic spaces by incorporating\ntextual features, coarse-grained CLIP features, and fine-grained DINOv2\nfeatures to capture rich semantic relationships. Building upon these dual\ngraphs, the Clique Guided Hyper-class component leverages structured class\nrelationships to enhance prediction robustness through correlated class\nselection. Extensive experiments demonstrate COSMIC's superior performance\nacross multiple benchmarks, achieving significant improvements over\nstate-of-the-art methods: 15.81% gain on out-of-distribution tasks and 5.33% on\ncross-domain generation with CLIP RN-50. Code is available at\ngithub.com/hf618/COSMIC.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23388v1",
    "published_date": "2025-03-30 10:34:45 UTC",
    "updated_date": "2025-03-30 10:34:45 UTC"
  },
  {
    "arxiv_id": "2503.23379v1",
    "title": "KernelDNA: Dynamic Kernel Sharing via Decoupled Naive Adapters",
    "authors": [
      "Haiduo Huang",
      "Yadong Zhang",
      "Pengju Ren"
    ],
    "abstract": "Dynamic convolution enhances model capacity by adaptively combining multiple\nkernels, yet faces critical trade-offs: prior works either (1) incur\nsignificant parameter overhead by scaling kernel numbers linearly, (2)\ncompromise inference speed through complex kernel interactions, or (3) struggle\nto jointly optimize dynamic attention and static kernels. We also observe that\npre-trained Convolutional Neural Networks (CNNs) exhibit inter-layer redundancy\nakin to that in Large Language Models (LLMs). Specifically, dense convolutional\nlayers can be efficiently replaced by derived ``child\" layers generated from a\nshared ``parent\" convolutional kernel through an adapter.\n  To address these limitations and implement the weight-sharing mechanism, we\npropose a lightweight convolution kernel plug-in, named KernelDNA. It decouples\nkernel adaptation into input-dependent dynamic routing and pre-trained static\nmodulation, ensuring both parameter efficiency and hardware-friendly inference.\nUnlike existing dynamic convolutions that expand parameters via multi-kernel\nensembles, our method leverages cross-layer weight sharing and adapter-based\nmodulation, enabling dynamic kernel specialization without altering the\nstandard convolution structure. This design preserves the native computational\nefficiency of standard convolutions while enhancing representation power\nthrough input-adaptive kernel adjustments. Experiments on image classification\nand dense prediction tasks demonstrate that KernelDNA achieves state-of-the-art\naccuracy-efficiency balance among dynamic convolution variants. Our codes are\navailable at https://github.com/haiduo/KernelDNA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23379v1",
    "published_date": "2025-03-30 09:54:07 UTC",
    "updated_date": "2025-03-30 09:54:07 UTC"
  },
  {
    "arxiv_id": "2503.23377v1",
    "title": "JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchronization",
    "authors": [
      "Kai Liu",
      "Wei Li",
      "Lai Chen",
      "Shengqiong Wu",
      "Yanhao Zheng",
      "Jiayi Ji",
      "Fan Zhou",
      "Rongxin Jiang",
      "Jiebo Luo",
      "Hao Fei",
      "Tat-Seng Chua"
    ],
    "abstract": "This paper introduces JavisDiT, a novel Joint Audio-Video Diffusion\nTransformer designed for synchronized audio-video generation (JAVG). Built upon\nthe powerful Diffusion Transformer (DiT) architecture, JavisDiT is able to\ngenerate high-quality audio and video content simultaneously from open-ended\nuser prompts. To ensure optimal synchronization, we introduce a fine-grained\nspatio-temporal alignment mechanism through a Hierarchical Spatial-Temporal\nSynchronized Prior (HiST-Sypo) Estimator. This module extracts both global and\nfine-grained spatio-temporal priors, guiding the synchronization between the\nvisual and auditory components. Furthermore, we propose a new benchmark,\nJavisBench, consisting of 10,140 high-quality text-captioned sounding videos\nspanning diverse scenes and complex real-world scenarios. Further, we\nspecifically devise a robust metric for evaluating the synchronization between\ngenerated audio-video pairs in real-world complex content. Experimental results\ndemonstrate that JavisDiT significantly outperforms existing methods by\nensuring both high-quality generation and precise synchronization, setting a\nnew standard for JAVG tasks. Our code, model, and dataset will be made publicly\navailable at https://javisdit.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "Work in progress. Homepage: https://javisdit.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2503.23377v1",
    "published_date": "2025-03-30 09:40:42 UTC",
    "updated_date": "2025-03-30 09:40:42 UTC"
  },
  {
    "arxiv_id": "2504.03721v1",
    "title": "A Hybrid Reinforcement Learning Framework for Hard Latency Constrained Resource Scheduling",
    "authors": [
      "Luyuan Zhang",
      "An Liu",
      "Kexuan Wang"
    ],
    "abstract": "In the forthcoming 6G era, extend reality (XR) has been regarded as an\nemerging application for ultra-reliable and low latency communications (URLLC)\nwith new traffic characteristics and more stringent requirements. In addition\nto the quasi-periodical traffic in XR, burst traffic with both large frame size\nand random arrivals in some real world low latency communication scenarios has\nbecome the leading cause of network congestion or even collapse, and there\nstill lacks an efficient algorithm for the resource scheduling problem under\nburst traffic with hard latency constraints. We propose a novel hybrid\nreinforcement learning framework for resource scheduling with hard latency\nconstraints (HRL-RSHLC), which reuses polices from both old policies learned\nunder other similar environments and domain-knowledge-based (DK) policies\nconstructed using expert knowledge to improve the performance. The joint\noptimization of the policy reuse probabilities and new policy is formulated as\nan Markov Decision Problem (MDP), which maximizes the hard-latency constrained\neffective throughput (HLC-ET) of users. We prove that the proposed HRL-RSHLC\ncan converge to KKT points with an arbitrary initial point. Simulations show\nthat HRL-RSHLC can achieve superior performance with faster convergence speed\ncompared to baseline algorithms.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "13 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.03721v1",
    "published_date": "2025-03-30 09:39:13 UTC",
    "updated_date": "2025-03-30 09:39:13 UTC"
  },
  {
    "arxiv_id": "2503.23371v1",
    "title": "FeRG-LLM : Feature Engineering by Reason Generation Large Language Models",
    "authors": [
      "Jeonghyun Ko",
      "Gyeongyun Park",
      "Donghoon Lee",
      "Kyunam Lee"
    ],
    "abstract": "One of the key tasks in machine learning for tabular data is feature\nengineering. Although it is vital for improving the performance of models, it\ndemands considerable human expertise and deep domain knowledge, making it\nlabor-intensive endeavor. To address this issue, we propose a novel framework,\n\\textbf{FeRG-LLM} (\\textbf{Fe}ature engineering by \\textbf{R}eason\n\\textbf{G}eneration \\textbf{L}arge \\textbf{L}anguage \\textbf{M}odels), a large\nlanguage model designed to automatically perform feature engineering at an\n8-billion-parameter scale. We have constructed two-stage conversational\ndialogues that enable language models to analyze machine learning tasks and\ndiscovering new features, exhibiting their Chain-of-Thought (CoT) capabilities.\nWe use these dialogues to fine-tune Llama 3.1 8B model and integrate Direct\nPreference Optimization (DPO) to receive feedback improving quality of new\nfeatures and the model's performance. Our experiments show that FeRG-LLM\nperforms comparably to or better than Llama 3.1 70B on most datasets, while\nusing fewer resources and achieving reduced inference time. It outperforms\nother studies in classification tasks and performs well in regression tasks.\nMoreover, since it does not rely on cloud-hosted LLMs like GPT-4 with extra API\ncosts when generating features, it can be deployed locally, addressing security\nconcerns.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2503.23371v1",
    "published_date": "2025-03-30 09:07:21 UTC",
    "updated_date": "2025-03-30 09:07:21 UTC"
  },
  {
    "arxiv_id": "2503.23368v3",
    "title": "VLIPP: Towards Physically Plausible Video Generation with Vision and Language Informed Physical Prior",
    "authors": [
      "Xindi Yang",
      "Baolu Li",
      "Yiming Zhang",
      "Zhenfei Yin",
      "Lei Bai",
      "Liqian Ma",
      "Zhiyong Wang",
      "Jianfei Cai",
      "Tien-Tsin Wong",
      "Huchuan Lu",
      "Xu Jia"
    ],
    "abstract": "Video diffusion models (VDMs) have advanced significantly in recent years,\nenabling the generation of highly realistic videos and drawing the attention of\nthe community in their potential as world simulators. However, despite their\ncapabilities, VDMs often fail to produce physically plausible videos due to an\ninherent lack of understanding of physics, resulting in incorrect dynamics and\nevent sequences. To address this limitation, we propose a novel two-stage\nimage-to-video generation framework that explicitly incorporates physics with\nvision and language informed physical prior. In the first stage, we employ a\nVision Language Model (VLM) as a coarse-grained motion planner, integrating\nchain-of-thought and physics-aware reasoning to predict a rough motion\ntrajectories/changes that approximate real-world physical dynamics while\nensuring the inter-frame consistency. In the second stage, we use the predicted\nmotion trajectories/changes to guide the video generation of a VDM. As the\npredicted motion trajectories/changes are rough, noise is added during\ninference to provide freedom to the VDM in generating motion with more fine\ndetails. Extensive experimental results demonstrate that our framework can\nproduce physically plausible motion, and comparative evaluations highlight the\nnotable superiority of our approach over existing methods. More video results\nare available on our Project Page:\nhttps://madaoer.github.io/projects/physically_plausible_video_generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23368v3",
    "published_date": "2025-03-30 09:03:09 UTC",
    "updated_date": "2025-04-04 07:23:21 UTC"
  },
  {
    "arxiv_id": "2503.23363v1",
    "title": "Large Language Models Are Better Logical Fallacy Reasoners with Counterargument, Explanation, and Goal-Aware Prompt Formulation",
    "authors": [
      "Jiwon Jeong",
      "Hyeju Jang",
      "Hogun Park"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) has greatly improved our\nability to process complex language. However, accurately detecting logical\nfallacies remains a significant challenge. This study presents a novel and\neffective prompt formulation approach for logical fallacy detection, applicable\nin both supervised (fine-tuned) and unsupervised (zero-shot) settings. Our\nmethod enriches input text incorporating implicit contextual information --\ncounterarguments, explanations, and goals -- which we query for validity within\nthe context of the argument. We then rank these queries based on confidence\nscores to inform classification. We evaluate our approach across multiple\ndatasets from 5 domains, covering 29 distinct fallacy types, using models from\nthe GPT and LLaMA series. The results show substantial improvements over\nstate-of-the-art models, with F1 score increases of up to 0.60 in zero-shot\nsettings and up to 0.45 in fine-tuned models. Extensive analyses further\nillustrate why and how our method excels.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2503.23363v1",
    "published_date": "2025-03-30 08:41:09 UTC",
    "updated_date": "2025-03-30 08:41:09 UTC"
  },
  {
    "arxiv_id": "2503.23362v2",
    "title": "Mixture of Routers",
    "authors": [
      "Jia-Chen Zhang",
      "Yu-Jie Xiong",
      "Xi-He Qiu",
      "Chun-Ming Xia",
      "Fei Dai"
    ],
    "abstract": "Supervised fine-tuning (SFT) is a milestone in aligning large language models\nwith human instructions and adapting them to downstream tasks. In particular,\nLow-Rank Adaptation (LoRA) has gained widespread attention due to its parameter\nefficiency. However, its impact on improving the performance of large models\nremains limited. Recent studies suggest that combining LoRA with\nMixture-of-Experts (MoE) can significantly enhance fine-tuning performance. MoE\nadapts to the diversity and complexity of datasets by dynamically selecting the\nmost suitable experts, thereby improving task accuracy and efficiency. Despite\nimpressive results, recent studies reveal issues in the MoE routing mechanism,\nsuch as incorrect assignments and imbalanced expert allocation. Inspired by the\nprinciples of Redundancy and Fault Tolerance Theory. We innovatively integrate\nthe concept of Mixture of Experts into the routing mechanism and propose an\nefficient fine-tuning method called Mixture of Routers (MoR). It employs\nmultiple sub-routers for joint selection and uses a learnable main router to\ndetermine the weights of the sub-routers. The results show that MoR outperforms\nbaseline models on most tasks, achieving an average performance improvement of\n1%. MoR can serve as a plug-and-play, parameter-efficient fine-tuning method\nsuitable for a wide range of applications. Our code is available here:\nhttps://anonymous.4open.science/r/MoR-DFC6.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages,4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23362v2",
    "published_date": "2025-03-30 08:39:09 UTC",
    "updated_date": "2025-05-16 14:18:06 UTC"
  },
  {
    "arxiv_id": "2504.00035v1",
    "title": "MiZero: The Shadowy Defender Against Text Style Infringements",
    "authors": [
      "Ziwei Zhang",
      "Juan Wen",
      "Wanli Peng",
      "Zhengxian Wu",
      "Yinghan Zhou",
      "Yiming Xue"
    ],
    "abstract": "In-Context Learning (ICL) and efficient fine-tuning methods significantly\nenhanced the efficiency of applying Large Language Models (LLMs) to downstream\ntasks. However, they also raise concerns about the imitation and infringement\nof personal creative data. Current methods for data copyright protection\nprimarily focuses on content security but lacks effectiveness in protecting the\ncopyrights of text styles. In this paper, we introduce a novel implicit\nzero-watermarking scheme, namely MiZero. This scheme establishes a precise\nwatermark domain to protect the copyrighted style, surpassing traditional\nwatermarking methods that distort the style characteristics. Specifically, we\nemploy LLMs to extract condensed-lists utilizing the designed instance\ndelimitation mechanism. These lists guide MiZero in generating the watermark.\nExtensive experiments demonstrate that MiZero effectively verifies text style\ncopyright ownership against AI imitation.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00035v1",
    "published_date": "2025-03-30 08:19:12 UTC",
    "updated_date": "2025-03-30 08:19:12 UTC"
  },
  {
    "arxiv_id": "2503.23353v1",
    "title": "Object Isolated Attention for Consistent Story Visualization",
    "authors": [
      "Xiangyang Luo",
      "Junhao Cheng",
      "Yifan Xie",
      "Xin Zhang",
      "Tao Feng",
      "Zhou Liu",
      "Fei Ma",
      "Fei Yu"
    ],
    "abstract": "Open-ended story visualization is a challenging task that involves generating\ncoherent image sequences from a given storyline. One of the main difficulties\nis maintaining character consistency while creating natural and contextually\nfitting scenes--an area where many existing methods struggle. In this paper, we\npropose an enhanced Transformer module that uses separate self attention and\ncross attention mechanisms, leveraging prior knowledge from pre-trained\ndiffusion models to ensure logical scene creation. The isolated self attention\nmechanism improves character consistency by refining attention maps to reduce\nfocus on irrelevant areas and highlight key features of the same character.\nMeanwhile, the isolated cross attention mechanism independently processes each\ncharacter's features, avoiding feature fusion and further strengthening\nconsistency. Notably, our method is training-free, allowing the continuous\ngeneration of new characters and storylines without re-tuning. Both qualitative\nand quantitative evaluations show that our approach outperforms current\nmethods, demonstrating its effectiveness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23353v1",
    "published_date": "2025-03-30 08:16:52 UTC",
    "updated_date": "2025-03-30 08:16:52 UTC"
  },
  {
    "arxiv_id": "2503.23350v2",
    "title": "A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models",
    "authors": [
      "Liangbo Ning",
      "Ziran Liang",
      "Zhuohang Jiang",
      "Haohao Qu",
      "Yujuan Ding",
      "Wenqi Fan",
      "Xiao-yong Wei",
      "Shanru Lin",
      "Hui Liu",
      "Philip S. Yu",
      "Qing Li"
    ],
    "abstract": "With the advancement of web techniques, they have significantly\nrevolutionized various aspects of people's lives. Despite the importance of the\nweb, many tasks performed on it are repetitive and time-consuming, negatively\nimpacting overall quality of life. To efficiently handle these tedious daily\ntasks, one of the most promising approaches is to advance autonomous agents\nbased on Artificial Intelligence (AI) techniques, referred to as AI Agents, as\nthey can operate continuously without fatigue or performance degradation. In\nthe context of the web, leveraging AI Agents -- termed WebAgents -- to\nautomatically assist people in handling tedious daily tasks can dramatically\nenhance productivity and efficiency. Recently, Large Foundation Models (LFMs)\ncontaining billions of parameters have exhibited human-like language\nunderstanding and reasoning capabilities, showing proficiency in performing\nvarious complex tasks. This naturally raises the question: `Can LFMs be\nutilized to develop powerful AI Agents that automatically handle web tasks,\nproviding significant convenience to users?' To fully explore the potential of\nLFMs, extensive research has emerged on WebAgents designed to complete daily\nweb tasks according to user instructions, significantly enhancing the\nconvenience of daily human life. In this survey, we comprehensively review\nexisting research studies on WebAgents across three key aspects: architectures,\ntraining, and trustworthiness. Additionally, several promising directions for\nfuture research are explored to provide deeper insights.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by KDD 2025;",
    "pdf_url": "http://arxiv.org/pdf/2503.23350v2",
    "published_date": "2025-03-30 08:15:44 UTC",
    "updated_date": "2025-05-10 09:20:29 UTC"
  },
  {
    "arxiv_id": "2503.23339v2",
    "title": "A Scalable Framework for Evaluating Health Language Models",
    "authors": [
      "Neil Mallinar",
      "A. Ali Heydari",
      "Xin Liu",
      "Anthony Z. Faranesh",
      "Brent Winslow",
      "Nova Hammerquist",
      "Benjamin Graef",
      "Cathy Speed",
      "Mark Malhotra",
      "Shwetak Patel",
      "Javier L. Prieto",
      "Daniel McDuff",
      "Ahmed A. Metwally"
    ],
    "abstract": "Large language models (LLMs) have emerged as powerful tools for analyzing\ncomplex datasets. Recent studies demonstrate their potential to generate\nuseful, personalized responses when provided with patient-specific health\ninformation that encompasses lifestyle, biomarkers, and context. As LLM-driven\nhealth applications are increasingly adopted, rigorous and efficient one-sided\nevaluation methodologies are crucial to ensure response quality across multiple\ndimensions, including accuracy, personalization and safety. Current evaluation\npractices for open-ended text responses heavily rely on human experts. This\napproach introduces human factors and is often cost-prohibitive,\nlabor-intensive, and hinders scalability, especially in complex domains like\nhealthcare where response assessment necessitates domain expertise and\nconsiders multifaceted patient data. In this work, we introduce Adaptive\nPrecise Boolean rubrics: an evaluation framework that streamlines human and\nautomated evaluation of open-ended questions by identifying gaps in model\nresponses using a minimal set of targeted rubrics questions. Our approach is\nbased on recent work in more general evaluation settings that contrasts a\nsmaller set of complex evaluation targets with a larger set of more precise,\ngranular targets answerable with simple boolean responses. We validate this\napproach in metabolic health, a domain encompassing diabetes, cardiovascular\ndisease, and obesity. Our results demonstrate that Adaptive Precise Boolean\nrubrics yield higher inter-rater agreement among expert and non-expert human\nevaluators, and in automated assessments, compared to traditional Likert\nscales, while requiring approximately half the evaluation time of Likert-based\nmethods. This enhanced efficiency, particularly in automated evaluation and\nnon-expert contributions, paves the way for more extensive and cost-effective\nevaluation of LLMs in health.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23339v2",
    "published_date": "2025-03-30 06:47:57 UTC",
    "updated_date": "2025-04-01 21:17:55 UTC"
  },
  {
    "arxiv_id": "2504.01034v1",
    "title": "Artificial intelligence and democracy: Towards digital authoritarianism or a democratic upgrade?",
    "authors": [
      "Fereniki Panagopoulou"
    ],
    "abstract": "Do robots vote? Do machines make decisions instead of us? No, (at least not\nyet), but this is something that could happen. The impact of Artificial\nIntelligence (AI) on democracy is a complex issue that requires thorough\nresearch and careful regulation. At the most important level, that of the\nelectoral process, it is noted that it is not determined by the AI, but it is\ngreatly impacted by its multiple applications. New types of online campaigns,\ndriven by AI applications, are replacing traditional ones. The potential for\nmanipulating voters and indirectly influencing the electoral outcome should not\nbe underestimated. Certainly, instances of voter manipulation are not absent\nfrom traditional political campaigns, with the only difference being that\ndigital manipulation is often carried out without our knowledge, e.g. by\nmonitoring our behavior on social media. Nevertheless, we should not overlook\nthe positive impact that AI has in the upgrading of democratic institutions by\nproviding a forum for participation in decision-making. In this context, as a\nfirst step, we look into the potential jeopardization of democratic processes\nposed by the use of AI tools. Secondly, we consider the possibility of\nstrengthening democratic processes by using AI, as well as the democratization\nof AI itself through the possibilities it offers. And thirdly, the impact of AI\non the representative system is also discussed. The paper is concluded with\nrecommendations and conclusions.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01034v1",
    "published_date": "2025-03-30 06:43:54 UTC",
    "updated_date": "2025-03-30 06:43:54 UTC"
  },
  {
    "arxiv_id": "2503.23333v1",
    "title": "Beyond Unimodal Boundaries: Generative Recommendation with Multimodal Semantics",
    "authors": [
      "Jing Zhu",
      "Mingxuan Ju",
      "Yozen Liu",
      "Danai Koutra",
      "Neil Shah",
      "Tong Zhao"
    ],
    "abstract": "Generative recommendation (GR) has become a powerful paradigm in\nrecommendation systems that implicitly links modality and semantics to item\nrepresentation, in contrast to previous methods that relied on non-semantic\nitem identifiers in autoregressive models. However, previous research has\npredominantly treated modalities in isolation, typically assuming item content\nis unimodal (usually text). We argue that this is a significant limitation\ngiven the rich, multimodal nature of real-world data and the potential\nsensitivity of GR models to modality choices and usage. Our work aims to\nexplore the critical problem of Multimodal Generative Recommendation (MGR),\nhighlighting the importance of modality choices in GR nframeworks. We reveal\nthat GR models are particularly sensitive to different modalities and examine\nthe challenges in achieving effective GR when multiple modalities are\navailable. By evaluating design strategies for effectively leveraging multiple\nmodalities, we identify key challenges and introduce MGR-LF++, an enhanced late\nfusion framework that employs contrastive modality alignment and special tokens\nto denote different modalities, achieving a performance improvement of over 20%\ncompared to single-modality alternatives.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23333v1",
    "published_date": "2025-03-30 06:24:43 UTC",
    "updated_date": "2025-03-30 06:24:43 UTC"
  },
  {
    "arxiv_id": "2503.23329v1",
    "title": "A Multi-Agent Framework with Automated Decision Rule Optimization for Cross-Domain Misinformation Detection",
    "authors": [
      "Hui Li",
      "Ante Wang",
      "kunquan li",
      "Zhihao Wang",
      "Liang Zhang",
      "Delai Qiu",
      "Qingsong Liu",
      "Jinsong Su"
    ],
    "abstract": "Misinformation spans various domains, but detection methods trained on\nspecific domains often perform poorly when applied to others. With the rapid\ndevelopment of Large Language Models (LLMs), researchers have begun to utilize\nLLMs for cross-domain misinformation detection. However, existing LLM-based\nmethods often fail to adequately analyze news in the target domain, limiting\ntheir detection capabilities. More importantly, these methods typically rely on\nmanually designed decision rules, which are limited by domain knowledge and\nexpert experience, thus limiting the generalizability of decision rules to\ndifferent domains. To address these issues, we propose a MultiAgent Framework\nfor cross-domain misinformation detection with Automated Decision Rule\nOptimization (MARO). Under this framework, we first employs multiple expert\nagents to analyze target-domain news. Subsequently, we introduce a\nquestion-reflection mechanism that guides expert agents to facilitate\nhigherquality analysis. Furthermore, we propose a decision rule optimization\napproach based on carefully-designed cross-domain validation tasks to\niteratively enhance the effectiveness of decision rules in different domains.\nExperimental results and in-depth analysis on commonlyused datasets demonstrate\nthat MARO achieves significant improvements over existing methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23329v1",
    "published_date": "2025-03-30 06:08:33 UTC",
    "updated_date": "2025-03-30 06:08:33 UTC"
  },
  {
    "arxiv_id": "2503.23326v2",
    "title": "Exploring Explainable Multi-player MCTS-minimax Hybrids in Board Game Using Process Mining",
    "authors": [
      "Yiyu Qian",
      "Tim Miller",
      "Zheng Qian",
      "Liyuan Zhao"
    ],
    "abstract": "Monte-Carlo Tree Search (MCTS) is a family of sampling-based search\nalgorithms widely used for online planning in sequential decision-making\ndomains and at the heart of many recent advances in artificial intelligence.\nUnderstanding the behavior of MCTS agents is difficult for developers and users\ndue to the frequently large and complex search trees that result from the\nsimulation of many possible futures, their evaluations, and their\nrelationships. This paper presents our ongoing investigation into potential\nexplanations for the decision-making and behavior of MCTS. A weakness of MCTS\nis that it constructs a highly selective tree and, as a result, can miss\ncrucial moves and fall into tactical traps. Full-width minimax search\nconstitutes the solution. We integrate shallow minimax search into the rollout\nphase of multi-player MCTS and use process mining technique to explain agents'\nstrategies in 3v3 checkers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "38 pages, AAAI 2025 PRL",
    "pdf_url": "http://arxiv.org/pdf/2503.23326v2",
    "published_date": "2025-03-30 05:48:53 UTC",
    "updated_date": "2025-05-20 14:09:58 UTC"
  },
  {
    "arxiv_id": "2503.23315v1",
    "title": "AI Agents in Engineering Design: A Multi-Agent Framework for Aesthetic and Aerodynamic Car Design",
    "authors": [
      "Mohamed Elrefaie",
      "Janet Qian",
      "Raina Wu",
      "Qian Chen",
      "Angela Dai",
      "Faez Ahmed"
    ],
    "abstract": "We introduce the concept of \"Design Agents\" for engineering applications,\nparticularly focusing on the automotive design process, while emphasizing that\nour approach can be readily extended to other engineering and design domains.\nOur framework integrates AI-driven design agents into the traditional\nengineering workflow, demonstrating how these specialized computational agents\ninteract seamlessly with engineers and designers to augment creativity, enhance\nefficiency, and significantly accelerate the overall design cycle. By\nautomating and streamlining tasks traditionally performed manually, such as\nconceptual sketching, styling enhancements, 3D shape retrieval and generative\nmodeling, computational fluid dynamics (CFD) meshing, and aerodynamic\nsimulations, our approach reduces certain aspects of the conventional workflow\nfrom weeks and days down to minutes. These agents leverage state-of-the-art\nvision-language models (VLMs), large language models (LLMs), and geometric deep\nlearning techniques, providing rapid iteration and comprehensive design\nexploration capabilities. We ground our methodology in industry-standard\nbenchmarks, encompassing a wide variety of conventional automotive designs, and\nutilize high-fidelity aerodynamic simulations to ensure practical and\napplicable outcomes. Furthermore, we present design agents that can swiftly and\naccurately predict simulation outcomes, empowering engineers and designers to\nengage in more informed design optimization and exploration. This research\nunderscores the transformative potential of integrating advanced generative AI\ntechniques into complex engineering tasks, paving the way for broader adoption\nand innovation across multiple engineering disciplines.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23315v1",
    "published_date": "2025-03-30 04:57:17 UTC",
    "updated_date": "2025-03-30 04:57:17 UTC"
  },
  {
    "arxiv_id": "2503.23314v1",
    "title": "SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science",
    "authors": [
      "Wonduk Seo",
      "Juhyeon Lee",
      "Yi Bu"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized automated data analytics and\nmachine learning by enabling dynamic reasoning and adaptability. While recent\napproaches have advanced multi-stage pipelines through multi-agent systems,\nthey typically rely on rigid, single-path workflows that limit the exploration\nand integration of diverse strategies, often resulting in suboptimal\npredictions. To address these challenges, we propose SPIO (Sequential Plan\nIntegration and Optimization), a novel framework that leverages LLM-driven\ndecision-making to orchestrate multi-agent planning across four key modules:\ndata preprocessing, feature engineering, modeling, and hyperparameter tuning.\nIn each module, dedicated planning agents independently generate candidate\nstrategies that cascade into subsequent stages, fostering comprehensive\nexploration. A plan optimization agent refines these strategies by suggesting\nseveral optimized plans. We further introduce two variants: SPIO-S, which\nselects a single best solution path as determined by the LLM, and SPIO-E, which\nselects the top k candidate plans and ensembles them to maximize predictive\nperformance. Extensive experiments on Kaggle and OpenML datasets demonstrate\nthat SPIO significantly outperforms state-of-the-art methods, providing a\nrobust and scalable solution for automated data science task.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2503.23314v1",
    "published_date": "2025-03-30 04:45:32 UTC",
    "updated_date": "2025-03-30 04:45:32 UTC"
  },
  {
    "arxiv_id": "2503.23312v1",
    "title": "LaViC: Adapting Large Vision-Language Models to Visually-Aware Conversational Recommendation",
    "authors": [
      "Hyunsik Jeon",
      "Satoshi Koide",
      "Yu Wang",
      "Zhankui He",
      "Julian McAuley"
    ],
    "abstract": "Conversational recommender systems engage users in dialogues to refine their\nneeds and provide more personalized suggestions. Although textual information\nsuffices for many domains, visually driven categories such as fashion or home\ndecor potentially require detailed visual information related to color, style,\nor design. To address this challenge, we propose LaViC (Large Vision-Language\nConversational Recommendation Framework), a novel approach that integrates\ncompact image representations into dialogue-based recommendation systems. LaViC\nleverages a large vision-language model in a two-stage process: (1) visual\nknowledge self-distillation, which condenses product images from hundreds of\ntokens into a small set of visual tokens in a self-distillation manner,\nsignificantly reducing computational overhead, and (2) recommendation prompt\ntuning, which enables the model to incorporate both dialogue context and\ndistilled visual tokens, providing a unified mechanism for capturing textual\nand visual features. To support rigorous evaluation of visually-aware\nconversational recommendation, we construct a new dataset by aligning Reddit\nconversations with Amazon product listings across multiple visually oriented\ncategories (e.g., fashion, beauty, and home). This dataset covers realistic\nuser queries and product appearances in domains where visual details are\ncrucial. Extensive experiments demonstrate that LaViC significantly outperforms\ntext-only conversational recommendation methods and open-source vision-language\nbaselines. Moreover, LaViC achieves competitive or superior accuracy compared\nto prominent proprietary baselines (e.g., GPT-3.5-turbo, GPT-4o-mini, and\nGPT-4o), demonstrating the necessity of explicitly using visual data for\ncapturing product attributes and showing the effectiveness of our\nvision-language integration. Our code and dataset are available at\nhttps://github.com/jeon185/LaViC.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23312v1",
    "published_date": "2025-03-30 04:44:13 UTC",
    "updated_date": "2025-03-30 04:44:13 UTC"
  },
  {
    "arxiv_id": "2503.23303v1",
    "title": "SalesRLAgent: A Reinforcement Learning Approach for Real-Time Sales Conversion Prediction and Optimization",
    "authors": [
      "Nandakishor M"
    ],
    "abstract": "Current approaches to sales conversation analysis and conversion prediction\ntypically rely on Large Language Models (LLMs) combined with basic retrieval\naugmented generation (RAG). These systems, while capable of answering\nquestions, fail to accurately predict conversion probability or provide\nstrategic guidance in real time. In this paper, we present SalesRLAgent, a\nnovel framework leveraging specialized reinforcement learning to predict\nconversion probability throughout sales conversations. Unlike systems from\nKapa.ai, Mendable, Inkeep, and others that primarily use off-the-shelf LLMs for\ncontent generation, our approach treats conversion prediction as a sequential\ndecision problem, training on synthetic data generated using GPT-4O to develop\na specialized probability estimation model. Our system incorporates Azure\nOpenAI embeddings (3072 dimensions), turn-by-turn state tracking, and\nmeta-learning capabilities to understand its own knowledge boundaries.\nEvaluations demonstrate that SalesRLAgent achieves 96.7% accuracy in conversion\nprediction, outperforming LLM-only approaches by 34.7% while offering\nsignificantly faster inference (85ms vs 3450ms for GPT-4). Furthermore,\nintegration with existing sales platforms shows a 43.2% increase in conversion\nrates when representatives utilize our system's real-time guidance.\nSalesRLAgent represents a fundamental shift from content generation to\nstrategic sales intelligence, providing moment-by-moment conversion probability\nestimation with actionable insights for sales professionals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23303v1",
    "published_date": "2025-03-30 03:56:26 UTC",
    "updated_date": "2025-03-30 03:56:26 UTC"
  },
  {
    "arxiv_id": "2503.23299v1",
    "title": "GRASP: Municipal Budget AI Chatbots for Enhancing Civic Engagement",
    "authors": [
      "Jerry Xu",
      "Justin Wang",
      "Joley Leung",
      "Jasmine Gu"
    ],
    "abstract": "There are a growing number of AI applications, but none tailored specifically\nto help residents answer their questions about municipal budget, a topic most\nare interested in but few have a solid comprehension of. In this research\npaper, we propose GRASP, a custom AI chatbot framework which stands for\nGeneration with Retrieval and Action System for Prompts. GRASP provides more\ntruthful and grounded responses to user budget queries than traditional\ninformation retrieval systems like general Large Language Models (LLMs) or web\nsearches. These improvements come from the novel combination of a\nRetrieval-Augmented Generation (RAG) framework (\"Generation with Retrieval\")\nand an agentic workflow (\"Action System\"), as well as prompt engineering\ntechniques, the incorporation of municipal budget domain knowledge, and\ncollaboration with local town officials to ensure response truthfulness. During\ntesting, we found that our GRASP chatbot provided precise and accurate\nresponses for local municipal budget queries 78% of the time, while GPT-4o and\nGemini were only accurate 60% and 35% of the time, respectively. GRASP chatbots\ngreatly reduce the time and effort needed for the general public to get an\nintuitive and correct understanding of their town's budget, thus fostering\ngreater communal discourse, improving government transparency, and allowing\ncitizens to make more informed decisions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23299v1",
    "published_date": "2025-03-30 03:46:06 UTC",
    "updated_date": "2025-03-30 03:46:06 UTC"
  },
  {
    "arxiv_id": "2503.23288v1",
    "title": "Two Heads Are Better than One: Model-Weight and Latent-Space Analysis for Federated Learning on Non-iid Data against Poisoning Attacks",
    "authors": [
      "Xingyu Lyu",
      "Ning Wang",
      "Yang Xiao",
      "Shixiong Li",
      "Tao Li",
      "Danjue Chen",
      "Yimin Chen"
    ],
    "abstract": "Federated Learning is a popular paradigm that enables remote clients to\njointly train a global model without sharing their raw data. However, FL has\nbeen shown to be vulnerable towards model poisoning attacks due to its\ndistributed nature. Particularly, attackers acting as participants can upload\narbitrary model updates that effectively compromise the global model of FL.\nWhile extensive research has been focusing on fighting against these attacks,\nwe find that most of them assume data at remote clients are under iid while in\npractice they are inevitably non-iid. Our benchmark evaluations reveal that\nexisting defenses generally fail to live up to their reputation when applied to\nvarious non-iid scenarios. In this paper, we propose a novel approach,\nGeminiGuard, that aims to address such a significant gap. We design GeminiGuard\nto be lightweight, versatile, and unsupervised so that it aligns well with the\npractical requirements of deploying such defenses. The key challenge from\nnon-iids is that they make benign model updates look more similar to malicious\nones. GeminiGuard is mainly built on two fundamental observations: (1) existing\ndefenses based on either model-weight analysis or latent-space analysis face\nlimitations in covering different MPAs and non-iid scenarios, and (2)\nmodel-weight and latent-space analysis are sufficiently different yet\npotentially complementary methods as MPA defenses. We hence incorporate a novel\nmodel-weight analysis component as well as a custom latent-space analysis\ncomponent in GeminiGuard, aiming to further enhance its defense performance. We\nconduct extensive experiments to evaluate our defense across various settings,\ndemonstrating its effectiveness in countering multiple types of untargeted and\ntargeted MPAs, including adaptive ones. Our comprehensive evaluations show that\nGeminiGuard consistently outperforms SOTA defenses under various settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23288v1",
    "published_date": "2025-03-30 02:56:05 UTC",
    "updated_date": "2025-03-30 02:56:05 UTC"
  },
  {
    "arxiv_id": "2503.23281v1",
    "title": "Extracting Patient History from Clinical Text: A Comparative Study of Clinical Large Language Models",
    "authors": [
      "Hieu Nghiem",
      "Tuan-Dung Le",
      "Suhao Chen",
      "Thanh Thieu",
      "Andrew Gin",
      "Ellie Phuong Nguyen",
      "Dursun Delen",
      "Johnson Thomas",
      "Jivan Lamichhane",
      "Zhuqi Miao"
    ],
    "abstract": "Extracting medical history entities (MHEs) related to a patient's chief\ncomplaint (CC), history of present illness (HPI), and past, family, and social\nhistory (PFSH) helps structure free-text clinical notes into standardized EHRs,\nstreamlining downstream tasks like continuity of care, medical coding, and\nquality metrics. Fine-tuned clinical large language models (cLLMs) can assist\nin this process while ensuring the protection of sensitive data via on-premises\ndeployment. This study evaluates the performance of cLLMs in recognizing\nCC/HPI/PFSH-related MHEs and examines how note characteristics impact model\naccuracy. We annotated 1,449 MHEs across 61 outpatient-related clinical notes\nfrom the MTSamples repository. To recognize these entities, we fine-tuned seven\nstate-of-the-art cLLMs. Additionally, we assessed the models' performance when\nenhanced by integrating, problems, tests, treatments, and other basic medical\nentities (BMEs). We compared the performance of these models against GPT-4o in\na zero-shot setting. To further understand the textual characteristics\naffecting model accuracy, we conducted an error analysis focused on note\nlength, entity length, and segmentation. The cLLMs showed potential in reducing\nthe time required for extracting MHEs by over 20%. However, detecting many\ntypes of MHEs remained challenging due to their polysemous nature and the\nfrequent involvement of non-medical vocabulary. Fine-tuned GatorTron and\nGatorTronS, two of the most extensively trained cLLMs, demonstrated the highest\nperformance. Integrating pre-identified BME information improved model\nperformance for certain entities. Regarding the impact of textual\ncharacteristics on model performance, we found that longer entities were harder\nto identify, note length did not correlate with a higher error rate, and\nwell-organized segments with headings are beneficial for the extraction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23281v1",
    "published_date": "2025-03-30 02:00:56 UTC",
    "updated_date": "2025-03-30 02:00:56 UTC"
  },
  {
    "arxiv_id": "2503.23278v2",
    "title": "Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions",
    "authors": [
      "Xinyi Hou",
      "Yanjie Zhao",
      "Shenao Wang",
      "Haoyu Wang"
    ],
    "abstract": "The Model Context Protocol (MCP) is a standardized interface designed to\nenable seamless interaction between AI models and external tools and resources,\nbreaking down data silos and facilitating interoperability across diverse\nsystems. This paper provides a comprehensive overview of MCP, focusing on its\ncore components, workflow, and the lifecycle of MCP servers, which consists of\nthree key phases: creation, operation, and update. We analyze the security and\nprivacy risks associated with each phase and propose strategies to mitigate\npotential threats. The paper also examines the current MCP landscape, including\nits adoption by industry leaders and various use cases, as well as the tools\nand platforms supporting its integration. We explore future directions for MCP,\nhighlighting the challenges and opportunities that will influence its adoption\nand evolution within the broader AI ecosystem. Finally, we offer\nrecommendations for MCP stakeholders to ensure its secure and sustainable\ndevelopment as the AI landscape continues to evolve.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23278v2",
    "published_date": "2025-03-30 01:58:22 UTC",
    "updated_date": "2025-04-06 13:32:33 UTC"
  },
  {
    "arxiv_id": "2503.23275v1",
    "title": "Improved Ear Verification with Vision Transformers and Overlapping Patches",
    "authors": [
      "Deeksha Arun",
      "Kagan Ozturk",
      "Kevin W. Bowyer",
      "Patrick Flynn"
    ],
    "abstract": "Ear recognition has emerged as a promising biometric modality due to the\nrelative stability in appearance during adulthood. Although Vision Transformers\n(ViTs) have been widely used in image recognition tasks, their efficiency in\near recognition has been hampered by a lack of attention to overlapping\npatches, which is crucial for capturing intricate ear features. In this study,\nwe evaluate ViT-Tiny (ViT-T), ViT-Small (ViT-S), ViT-Base (ViT-B) and ViT-Large\n(ViT-L) configurations on a diverse set of datasets (OPIB, AWE, WPUT, and\nEarVN1.0), using an overlapping patch selection strategy. Results demonstrate\nthe critical importance of overlapping patches, yielding superior performance\nin 44 of 48 experiments in a structured study. Moreover, upon comparing the\nresults of the overlapping patches with the non-overlapping configurations, the\nincrease is significant, reaching up to 10% for the EarVN1.0 dataset. In terms\nof model performance, the ViT-T model consistently outperformed the ViT-S,\nViT-B, and ViT-L models on the AWE, WPUT, and EarVN1.0 datasets. The highest\nscores were achieved in a configuration with a patch size of 28x28 and a stride\nof 14 pixels. This patch-stride configuration represents 25% of the normalized\nimage area (112x112 pixels) for the patch size and 12.5% of the row or column\nsize for the stride. This study confirms that transformer architectures with\noverlapping patch selection can serve as an efficient and high-performing\noption for ear-based biometric recognition tasks in verification scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23275v1",
    "published_date": "2025-03-30 01:50:21 UTC",
    "updated_date": "2025-03-30 01:50:21 UTC"
  },
  {
    "arxiv_id": "2503.23271v1",
    "title": "Learning Coordinated Bimanual Manipulation Policies using State Diffusion and Inverse Dynamics Models",
    "authors": [
      "Haonan Chen",
      "Jiaming Xu",
      "Lily Sheng",
      "Tianchen Ji",
      "Shuijing Liu",
      "Yunzhu Li",
      "Katherine Driggs-Campbell"
    ],
    "abstract": "When performing tasks like laundry, humans naturally coordinate both hands to\nmanipulate objects and anticipate how their actions will change the state of\nthe clothes. However, achieving such coordination in robotics remains\nchallenging due to the need to model object movement, predict future states,\nand generate precise bimanual actions. In this work, we address these\nchallenges by infusing the predictive nature of human manipulation strategies\ninto robot imitation learning. Specifically, we disentangle task-related state\ntransitions from agent-specific inverse dynamics modeling to enable effective\nbimanual coordination. Using a demonstration dataset, we train a diffusion\nmodel to predict future states given historical observations, envisioning how\nthe scene evolves. Then, we use an inverse dynamics model to compute robot\nactions that achieve the predicted states. Our key insight is that modeling\nobject movement can help learning policies for bimanual coordination\nmanipulation tasks. Evaluating our framework across diverse simulation and\nreal-world manipulation setups, including multimodal goal configurations,\nbimanual manipulation, deformable objects, and multi-object setups, we find\nthat it consistently outperforms state-of-the-art state-to-action mapping\npolicies. Our method demonstrates a remarkable capacity to navigate multimodal\ngoal configurations and action distributions, maintain stability across\ndifferent control modes, and synthesize a broader range of behaviors than those\npresent in the demonstration dataset.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Page: https://haonan16.github.io/coord_bimanual_page/. 12\n  pages, 12 figures, Accepted at ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23271v1",
    "published_date": "2025-03-30 01:25:35 UTC",
    "updated_date": "2025-03-30 01:25:35 UTC"
  },
  {
    "arxiv_id": "2503.23270v1",
    "title": "Localized Graph-Based Neural Dynamics Models for Terrain Manipulation",
    "authors": [
      "Chaoqi Liu",
      "Yunzhu Li",
      "Kris Hauser"
    ],
    "abstract": "Predictive models can be particularly helpful for robots to effectively\nmanipulate terrains in construction sites and extraterrestrial surfaces.\nHowever, terrain state representations become extremely high-dimensional\nespecially to capture fine-resolution details and when depth is unknown or\nunbounded. This paper introduces a learning-based approach for terrain dynamics\nmodeling and manipulation, leveraging the Graph-based Neural Dynamics (GBND)\nframework to represent terrain deformation as motion of a graph of particles.\nBased on the principle that the moving portion of a terrain is usually\nlocalized, our approach builds a large terrain graph (potentially millions of\nparticles) but only identifies a very small active subgraph (hundreds of\nparticles) for predicting the outcomes of robot-terrain interaction. To\nminimize the size of the active subgraph we introduce a learning-based approach\nthat identifies a small region of interest (RoI) based on the robot's control\ninputs and the current scene. We also introduce a novel domain boundary feature\nencoding that allows GBNDs to perform accurate dynamics prediction in the RoI\ninterior while avoiding particle penetration through RoI boundaries. Our\nproposed method is both orders of magnitude faster than naive GBND and it\nachieves better overall prediction accuracy. We further evaluated our framework\non excavation and shaping tasks on terrain with different granularity.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23270v1",
    "published_date": "2025-03-30 01:24:10 UTC",
    "updated_date": "2025-03-30 01:24:10 UTC"
  }
]