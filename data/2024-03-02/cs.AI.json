{
  "date": "2024-03-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-02 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 48 篇论文，主要聚焦于 AI 模型（如 LLM）的优化、生成和应用，以及图神经网络（Graph Neural Networks）和知识图（Temporal Knowledge Graphs）的创新进展。令人印象深刻的是 LLM 在 DNA 生物物理学习、无声语音识别和多模态医疗预测中的潜力，同时有几篇论文展示了有影响力作者（如 GPT-4 相关工作）的实际应用。\n\n下面，我将挑选并优先讨论最重要的论文，包括那些涉及热门 LLM 技术的、可能引发话题的，以及有实际影响的文章。相关论文会放在一起简要聊聊，其他较基础或非核心的论文（如纯调研或特定领域小工具）将快速掠过，只提关键点。\n\n### 重点论文讨论\n\n**1. Chaining thoughts and LLMs to learn DNA structural biophysics（思维链和大型语言模型学习 DNA 结构生物物理）**  \n作者：Tyler D. Ross, Ashwin Gopinath  \n这篇论文利用 ChatGPT 3.5-turbo 等通用 LLM 通过微调和思维链（chain-of-thought）方法，学习 DNA 的结构生物物理。主要贡献是证明 LLM 可以分析和设计 DNA 序列，提升了其在生物学任务中的灵活性，暗示 LLM 可扩展到实验假设生成领域。\n\n**2. Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data（大型语言多模态模型用于基于电子健康记录的 5 年慢性病队列预测）**  \n作者：Jun-En Ding 等  \n这篇与 LLM 相关的论文提出一个多模态框架，结合临床笔记和实验室测试数据，使用文本嵌入和注意力机制预测慢性病（如糖尿病）。主要发现是，Flan T5 模型通过数值数据文本化，实现了 76% 的 AUROC，提升了早期疾病预测的准确性，展示了 LLM 在医疗领域的实际应用潜力。\n\n**4. A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition（使用 LLM 增强的跨模态方法进行无声语音识别）**  \n作者：Tyler Benster 等  \n这篇论文引入 MONA 系统和 LISA（LLM 集成评分调整），通过跨模态对齐和损失函数（如 crossCon 和 supTcon）提升无声语音识别。关键贡献是将词错误率（WER）从 28.8% 降至 12.2%，首次让非侵入式无声识别达到 15% WER 阈值，打开了人机交互的新可能。\n\n**14. SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code（LLM 代理用于合成 3D 场景为 Blender 代码）**  \n作者：Ziniu Hu 等  \n这篇创新性工作使用 LLM 代理生成 Blender 可执行脚本，构建复杂 3D 场景。核心是场景图建模和视觉语言模型的迭代优化，主要发现是，通过库学习机制，实现了高效的 3D 场景合成，并应用于电影重建和视频生成控制，展示了 LLM 在创意领域的潜力。\n\n**10. NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention（通过无乘加注意力的高效 LLM 推理）**  \n作者：Tianyi Zhang 等  \n这篇论文提出 NoMAD-Attention 算法，使用 CPU 的 SIMD 寄存器替换传统乘加操作，实现线性时间 LLM 推理。贡献包括在 16k 上下文长度下加速 2 倍，同时保持模型质量，代码开源，强调了 LLM 在资源受限环境中的实用性。\n\n**相关 LLM 和生成模型论文快速聊聊**  \n- **17. IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact（通过保留关键标记提升 LLM 量化）**  \n  作者：Ruikang Liu 等  \n  主要贡献是优化 LLM 量化，保留关键标记（pivot tokens）减少量化误差，提升性能，成为 LLM 量化新基准。  \n- **21. API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access（无需 logit 访问的 LLM 置信预测）**  \n  作者：Jiayuan Su 等  \n  提出基于不确定性测量的置信预测方法，提升 LLM 输出可靠性。  \n- **23. The Case for Animal-Friendly AI（支持动物友好的 AI）**  \n  作者：Sankalpa Ghose 等  \n  讨论 LLM 在动物伦理中的应用，贡献是评估模型对动物利益的考虑，促进 AI 伦理研究。  \n- **25. RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots（检索增强聊天机器人的双刃剑）**  \n  作者：Philip Feldman 等  \n  实验显示 RAG 可减少 LLM 幻觉，但易受提示影响，提醒了实际部署的风险。  \n\n这些 LLM 相关论文整体展示了模型在生物、医疗和生成任务中的进展，但也暴露了幻觉和效率问题，值得关注。\n\n**图神经网络和知识图相关论文**  \n- **11. Temporal Knowledge Graph Completion with Time-sensitive Relations in Hypercomplex Space（在超复空间中完成时间敏感知识图）**  \n  作者：Li Cai 等  \n  使用四元数表示捕捉时间敏感关系，改进了知识图完成任务。  \n- **18. Polynormer: Polynomial-Expressive Graph Transformer in Linear Time（线性时间的多项式表达图变换器）**  \n  作者：Chenhui Deng 等  \n  提出线性复杂度的图变换器，改进了图任务的表达性和可扩展性。  \n- **37. OpenGraph: Towards Open Graph Foundation Models（面向开放图基础模型）**  \n  作者：Lianghao Xia 等  \n  开发通用图基础模型，支持零样本学习，扩展了图神经网络的应用。  \n\n这些论文推动了图模型的效率和泛化，但整体不如 LLM 主题热门，我这里简要提及。\n\n**其他值得一提的论文**  \n- **3. Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models（定制非平稳求解器用于扩散和流模型快速采样）**  \n  作者：Neta Shaul 等  \n  引入 BNS 求解器，提升图像生成效率，达到 45 PSNR 和 1.76 FID。  \n- **39. Distilling Text Style Transfer With Self-Explanation From LLMs（从 LLM 自解释中提炼文本风格转移）**  \n  作者：Chiyu Zhang 等  \n  使用 LLM 进行风格转移，提供透明解释，提升了模型可解释性。  \n\n剩余论文如第5-9、12-13、15-16、19-22、24、27-36、38、40-48 等，多为领域特定工具（如土耳其 NLP 包）、调研综述或小规模应用，我快速掠过：它们提供了基础工具（如 VNLP 和 VBART 用于土耳其语言处理）和方法改进（如主动学习或生成对抗网络），但影响力较小，不涉及核心突破。\n\n总之，今天的 arXiv 更新突显了 LLM 在跨领域应用的潜力，但也需注意效率和伦理挑战。欢迎读者关注这些热点论文，探索更多创新！（本快报基于标题和摘要简要总结，如需细节，请查阅原文。）",
  "papers": [
    {
      "arxiv_id": "2403.01332v1",
      "title": "Chaining thoughts and LLMs to learn DNA structural biophysics",
      "title_zh": "翻译失败",
      "authors": [
        "Tyler D. Ross",
        "Ashwin Gopinath"
      ],
      "abstract": "The future development of an AI scientist, a tool that is capable of\nintegrating a variety of experimental data and generating testable hypotheses,\nholds immense potential. So far, bespoke machine learning models have been\ncreated to specialize in singular scientific tasks, but otherwise lack the\nflexibility of a general purpose model. Here, we show that a general purpose\nlarge language model, chatGPT 3.5-turbo, can be fine-tuned to learn the\nstructural biophysics of DNA. We find that both fine-tuning models to return\nchain-of-thought responses and chaining together models fine-tuned for subtasks\nhave an enhanced ability to analyze and design DNA sequences and their\nstructures.",
      "tldr_zh": "该研究探讨了如何利用大型语言模型(LLMs)如 ChatGPT 3.5-turbo 来学习 DNA 结构生物物理，旨在构建一个能整合实验数据并生成可测试假设的 AI 科学家。作者通过微调模型以产生 chain-of-thought 响应，并将针对子任务的模型链接在一起，显著提升了 DNA 序列的分析和设计能力。实验结果显示，这种方法比传统专用模型更灵活，有望推进 AI 在科学领域的应用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01332v1",
      "published_date": "2024-03-02 22:38:01 UTC",
      "updated_date": "2024-03-02 22:38:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:50:29.802876"
    },
    {
      "arxiv_id": "2403.04785v2",
      "title": "Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jun-En Ding",
        "Phan Nguyen Minh Thao",
        "Wen-Chih Peng",
        "Jian-Zhe Wang",
        "Chun-Cheng Chug",
        "Min-Chen Hsieh",
        "Yun-Chien Tseng",
        "Ling Chen",
        "Dongsheng Luo",
        "Chi-Te Wang",
        "Pei-fu Chen",
        "Feng Liu",
        "Fang-Ming Hung"
      ],
      "abstract": "Chronic diseases such as diabetes are the leading causes of morbidity and\nmortality worldwide. Numerous research studies have been attempted with various\ndeep learning models in diagnosis. However, most previous studies had certain\nlimitations, including using publicly available datasets (e.g. MIMIC), and\nimbalanced data. In this study, we collected five-year electronic health\nrecords (EHRs) from the Taiwan hospital database, including 1,420,596 clinical\nnotes, 387,392 laboratory test results, and more than 1,505 laboratory test\nitems, focusing on research pre-training large language models. We proposed a\nnovel Large Language Multimodal Models (LLMMs) framework incorporating\nmultimodal data from clinical notes and laboratory test results for the\nprediction of chronic disease risk. Our method combined a text embedding\nencoder and multi-head attention layer to learn laboratory test values,\nutilizing a deep neural network (DNN) module to merge blood features with\nchronic disease semantics into a latent space. In our experiments, we observe\nthat clinicalBERT and PubMed-BERT, when combined with attention fusion, can\nachieve an accuracy of 73% in multiclass chronic diseases and diabetes\nprediction. By transforming laboratory test values into textual descriptions\nand employing the Flan T-5 model, we achieved a 76% Area Under the ROC Curve\n(AUROC), demonstrating the effectiveness of leveraging numerical text data for\ntraining and inference in language models. This approach significantly improves\nthe accuracy of early-stage diabetes prediction.",
      "tldr_zh": "本研究利用台湾医院数据库的五年电子健康记录(EHR)数据，提出一种Large Language Multimodal Models (LLMMs)框架，用于预测慢性疾病风险，如糖尿病。该框架整合临床笔记和实验室测试结果，通过文本嵌入编码器、多头注意力层和深度神经网络(DNN)模块，将数值测试值转化为文本描述，并融合血特征与疾病语义。实验结果显示，clinicalBERT和PubMed-BERT结合注意力机制在多类慢性疾病预测中达到73%的准确率，而Flan T-5模型则实现76%的Area Under the ROC Curve (AUROC)，显著提升了早期糖尿病预测的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.04785v2",
      "published_date": "2024-03-02 22:33:17 UTC",
      "updated_date": "2024-08-29 22:18:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:50:42.505919"
    },
    {
      "arxiv_id": "2403.01329v1",
      "title": "Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models",
      "title_zh": "翻译失败",
      "authors": [
        "Neta Shaul",
        "Uriel Singer",
        "Ricky T. Q. Chen",
        "Matthew Le",
        "Ali Thabet",
        "Albert Pumarola",
        "Yaron Lipman"
      ],
      "abstract": "This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver\ndistillation approach to improve sample efficiency of Diffusion and Flow\nmodels. BNS solvers are based on a family of non-stationary solvers that\nprovably subsumes existing numerical ODE solvers and consequently demonstrate\nconsiderable improvement in sample approximation (PSNR) over these baselines.\nCompared to model distillation, BNS solvers benefit from a tiny parameter space\n($<$200 parameters), fast optimization (two orders of magnitude faster),\nmaintain diversity of samples, and in contrast to previous solver distillation\napproaches nearly close the gap from standard distillation methods such as\nProgressive Distillation in the low-medium NFE regime. For example, BNS solver\nachieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64. We\nexperimented with BNS solvers for conditional image generation, text-to-image\ngeneration, and text-2-audio generation showing significant improvement in\nsample approximation (PSNR) in all.",
      "tldr_zh": "这篇论文引入了 Bespoke Non-Stationary (BNS) Solvers，一种求解器蒸馏方法，用于提升 Diffusion 和 Flow 模型的采样效率。\nBNS Solvers 基于一族非平稳求解器，能够证明性地包含现有数值 ODE 求解器，并以极小的参数空间（<200 参数）和更快优化（快两个数量级）实现样本逼近（PSNR）的显著改进，同时保持样本多样性。\n与标准蒸馏方法如 Progressive Distillation 相比，在低-中等 NFE 制度下，BNS Solvers 几乎缩小了性能差距，例如在 class-conditional ImageNet-64 上使用 16 NFE 达到 45 PSNR / 1.76 FID。\n实验在条件图像生成、文本到图像生成和文本到音频生成等任务上均展示了 BNS Solvers 在 PSNR 方面的显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01329v1",
      "published_date": "2024-03-02 22:27:44 UTC",
      "updated_date": "2024-03-02 22:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:50:57.736010"
    },
    {
      "arxiv_id": "2403.05583v1",
      "title": "A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Tyler Benster",
        "Guy Wilson",
        "Reshef Elisha",
        "Francis R Willett",
        "Shaul Druckmann"
      ],
      "abstract": "Silent Speech Interfaces (SSIs) offer a noninvasive alternative to\nbrain-computer interfaces for soundless verbal communication. We introduce\nMultimodal Orofacial Neural Audio (MONA), a system that leverages cross-modal\nalignment through novel loss functions--cross-contrast (crossCon) and\nsupervised temporal contrast (supTcon)--to train a multimodal model with a\nshared latent representation. This architecture enables the use of audio-only\ndatasets like LibriSpeech to improve silent speech recognition. Additionally,\nour introduction of Large Language Model (LLM) Integrated Scoring Adjustment\n(LISA) significantly improves recognition accuracy. Together, MONA LISA reduces\nthe state-of-the-art word error rate (WER) from 28.8% to 12.2% in the Gaddy\n(2020) benchmark dataset for silent speech on an open vocabulary. For vocal EMG\nrecordings, our method improves the state-of-the-art from 23.3% to 3.7% WER. In\nthe Brain-to-Text 2024 competition, LISA performs best, improving the top WER\nfrom 9.8% to 8.9%. To the best of our knowledge, this work represents the first\ninstance where noninvasive silent speech recognition on an open vocabulary has\ncleared the threshold of 15% WER, demonstrating that SSIs can be a viable\nalternative to automatic speech recognition (ASR). Our work not only narrows\nthe performance gap between silent and vocalized speech but also opens new\npossibilities in human-computer interaction, demonstrating the potential of\ncross-modal approaches in noisy and data-limited regimes.",
      "tldr_zh": "本研究提出了一种跨模态方法，用于无声语音接口(SSIs)，通过Multimodal Orofacial Neural Audio (MONA)系统利用新型损失函数cross-contrast (crossCon)和supervised temporal contrast (supTcon)来训练多模态模型，实现音频数据集如LibriSpeech的跨模态对齐，从而提升无声语音识别性能。研究还引入Large Language Model (LLM) Integrated Scoring Adjustment (LISA)技术，进一步优化识别准确率。实验结果显示，MONA LISA在Gaddy (2020)基准数据集上将word error rate (WER)从28.8%降低到12.2%，在vocal EMG记录上从23.3%降至3.7%，并在Brain-to-Text 2024竞赛中将顶尖WER从9.8%改善到8.9%。这项工作首次将开放词汇的无侵入式无声语音识别WER降至15%以下，证明SSIs可作为automatic speech recognition (ASR)的可行替代方案，并为噪声环境和数据有限的人机交互领域开辟新可能。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05583v1",
      "published_date": "2024-03-02 21:15:24 UTC",
      "updated_date": "2024-03-02 21:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:51:07.350079"
    },
    {
      "arxiv_id": "2403.01309v1",
      "title": "VNLP: Turkish NLP Package",
      "title_zh": "翻译失败",
      "authors": [
        "Meliksah Turker",
        "Mehmet Erdi Ari",
        "Aydin Han"
      ],
      "abstract": "In this work, we present VNLP: the first dedicated, complete, open-source,\nwell-documented, lightweight, production-ready, state-of-the-art Natural\nLanguage Processing (NLP) package for the Turkish language. It contains a wide\nvariety of tools, ranging from the simplest tasks, such as sentence splitting\nand text normalization, to the more advanced ones, such as text and token\nclassification models. Its token classification models are based on \"Context\nModel\", a novel architecture that is both an encoder and an auto-regressive\nmodel. NLP tasks solved by VNLP models include but are not limited to Sentiment\nAnalysis, Named Entity Recognition, Morphological Analysis \\& Disambiguation\nand Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings\nand corresponding SentencePiece Unigram tokenizers. VNLP has an open-source\nGitHub repository, ReadtheDocs documentation, PyPi package for convenient\ninstallation, Python and command-line API and a demo page to test all the\nfunctionality. Consequently, our main contribution is a complete, compact,\neasy-to-install and easy-to-use NLP package for Turkish.",
      "tldr_zh": "本研究介绍了 VNLP，这是一个专用的、完整的、开源的、最先进的 Turkish NLP 包，是第一个针对土耳其语的轻量级、生产就绪的自然语言处理工具。VNLP 涵盖了从基本任务如句子分割和文本规范化，到高级任务如文本和标记分类的多种功能，并采用“Context Model”新颖架构（既是编码器又是自回归模型）来支持情感分析、命名实体识别（Named Entity Recognition）、形态分析（Morphological Analysis）及词性标注（Part-of-Speech Tagging）。此外，它提供预训练的词嵌入和 SentencePiece Unigram 分词器，并通过 GitHub 仓库、PyPi 安装包、Python/Command-line API 及演示页面，确保用户易于安装和使用，从而为土耳其语 NLP 应用提供了紧凑且实用的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01309v1",
      "published_date": "2024-03-02 20:46:56 UTC",
      "updated_date": "2024-03-02 20:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:51:18.397091"
    },
    {
      "arxiv_id": "2403.01308v2",
      "title": "VBART: The Turkish LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Meliksah Turker",
        "Mehmet Erdi Ari",
        "Aydin Han"
      ],
      "abstract": "We present VBART, the first Turkish sequence-to-sequence Large Language\nModels (LLMs) pre-trained on a large corpus from scratch. VBART are compact\nLLMs based on good ideas leveraged from BART and mBART models and come in two\nsizes, Large and XLarge. Fine-tuned VBART models surpass the prior\nstate-of-the-art results in abstractive text summarization, title generation,\ntext paraphrasing, question answering and question generation tasks. They allow\nfine-tuning for future text generation tasks and datasets, carving a new path\nfor Turkish Natural Language Processing (NLP) research. Our work shows that\nhaving a pre-trained LLM for Turkish outperforms up to 3x multilingual models,\nimproving existing results and providing efficient models for training and\ninference. Moreover, we show that our monolingual tokenizer is up to 11x more\nefficient than multilingual tokenizers. Last but not least, we introduce a\nmethod to enlarge an existing pre-trained LLM and question the relevancy of\nChinchilla Scaling Law to sequence-to-sequence masked language models. Our\nfine-tuned models, tokenizer and cleaned vngrs-web-corpus of 135 GB are\npublicly available at huggingface.co/vngrs-ai.",
      "tldr_zh": "本研究介绍了 VBART，这是第一个从零预训练的土耳其语序列到序列 Large Language Models (LLMs)，基于 BART 和 mBART 的设计，并提供 Large 和 XLarge 两种尺寸。微调后的 VBART 在 abstractive text summarization、title generation、text paraphrasing、question answering 和 question generation 等任务上超越了现有最先进水平，且相比多语言模型，其性能提升高达 3 倍，同时训练和推理效率更高。研究还证明了单语 tokenizer 的效率优势（高达 11 倍），并提出了一种扩展预训练 LLM 的方法，同时质疑了 Chinchilla Scaling Law 对序列到序列掩码语言模型的相关性。模型、tokenizer 和 135 GB 清洗后的语料库已公开可用，推动了土耳其 Natural Language Processing (NLP) 研究的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01308v2",
      "published_date": "2024-03-02 20:40:11 UTC",
      "updated_date": "2024-03-14 16:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:51:31.837591"
    },
    {
      "arxiv_id": "2403.01286v1",
      "title": "Summary Paper: Use Case on Building Collaborative Safe Autonomous Systems-A Robotdog for Guiding Visually Impaired People",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Malhotra",
        "Selma Saidi"
      ],
      "abstract": "This is a summary paper of a use case of a Robotdog dedicated to guide\nvisually impaired people in complex environment like a smart intersection. In\nsuch scenarios, the Robotdog has to autonomously decide whether it is safe to\ncross the intersection or not in order to further guide the human. We leverage\ndata sharing and collaboration between the Robotdog and other autonomous\nsystems operating in the same environment. We propose a system architecture for\nautonomous systems through a separation of a collaborative decision layer, to\nenable collective decision making processes, where data about the environment,\nrelevant to the Robotdog decision, together with evidences for trustworthiness\nabout other systems and the environment are shared.",
      "tldr_zh": "这篇论文总结了一个机器人狗的用例，用于引导视力障碍者在复杂环境中（如智能路口）安全导航。机器人狗需自主判断是否安全通过路口，并通过数据共享与环境中的其他autonomous systems进行协作。论文提出了一种系统架构，包括分离的collaborative decision layer，以实现集体决策过程，共享环境数据和信任证据，从而提升整体系统的安全性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01286v1",
      "published_date": "2024-03-02 18:59:03 UTC",
      "updated_date": "2024-03-02 18:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:51:41.318855"
    },
    {
      "arxiv_id": "2403.01281v2",
      "title": "Fast Low-parameter Video Activity Localization in Collaborative Learning Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Venkatesh Jatla",
        "Sravani Teeparthi",
        "Ugesh Egala",
        "Sylvia Celedon Pattichis",
        "Marios S. Patticis"
      ],
      "abstract": "Research on video activity detection has primarily focused on identifying\nwell-defined human activities in short video segments. The majority of the\nresearch on video activity recognition is focused on the development of large\nparameter systems that require training on large video datasets. This paper\ndevelops a low-parameter, modular system with rapid inferencing capabilities\nthat can be trained entirely on limited datasets without requiring transfer\nlearning from large-parameter systems. The system can accurately detect and\nassociate specific activities with the students who perform the activities in\nreal-life classroom videos. Additionally, the paper develops an interactive\nweb-based application to visualize human activity maps over long real-life\nclassroom videos.",
      "tldr_zh": "本研究针对视频活动检测的现状，指出现有方法主要聚焦于短视频中的明确人类活动，并依赖大型参数系统和大量数据集进行训练。论文提出了一种低-parameter、模块化的系统，支持快速推理，能够在有限数据集上完全训练，而无需transfer learning，从而准确检测并关联真实课堂视频中学生的具体活动。该系统还开发了一个交互式web-based应用，用于可视化人类活动地图在长课堂视频上的应用，适用于协作学习环境。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01281v2",
      "published_date": "2024-03-02 18:28:32 UTC",
      "updated_date": "2024-03-09 15:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:51:55.613891"
    },
    {
      "arxiv_id": "2403.01277v1",
      "title": "Optimal Integrated Task and Path Planning and Its Application to Multi-Robot Pickup and Delivery",
      "title_zh": "最优集成任务与路径规划及其在多机器人取货和交付中的应用",
      "authors": [
        "Aman Aryan",
        "Manan Modi",
        "Indranil Saha",
        "Rupak Majumdar",
        "Swarup Mohalik"
      ],
      "abstract": "We propose a generic multi-robot planning mechanism that combines an optimal\ntask planner and an optimal path planner to provide a scalable solution for\ncomplex multi-robot planning problems. The Integrated planner, through the\ninteraction of the task planner and the path planner, produces optimal\ncollision-free trajectories for the robots. We illustrate our general algorithm\non an object pick-and-drop planning problem in a warehouse scenario where a\ngroup of robots is entrusted with moving objects from one location to another\nin the workspace. We solve the task planning problem by reducing it into an\nSMT-solving problem and employing the highly advanced SMT solver Z3 to solve\nit. To generate collision-free movement of the robots, we extend the\nstate-of-the-art algorithm Conflict Based Search with Precedence Constraints\nwith several domain-specific constraints. We evaluate our integrated task and\npath planner extensively on various instances of the object pick-and-drop\nplanning problem and compare its performance with a state-of-the-art\nmulti-robot classical planner. Experimental results demonstrate that our\nplanning mechanism can deal with complex planning problems and outperforms a\nstate-of-the-art classical planner both in terms of computation time and the\nquality of the generated plan.",
      "tldr_zh": "这篇论文提出了一种集成的最优任务和路径规划机制，用于解决多机器人复杂规划问题，如仓库中的物体拾取和交付任务。该机制通过任务规划器（将问题转化为SMT问题并使用Z3求解器）与路径规划器（扩展Conflict Based Search with Precedence Constraints算法，添加特定领域约束）交互，生成机器人最优无碰撞轨迹。实验结果显示，该方法在各种实例上比现有最先进的多机器人经典规划器在计算时间和计划质量上表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01277v1",
      "published_date": "2024-03-02 17:48:40 UTC",
      "updated_date": "2024-03-02 17:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:52:05.941067"
    },
    {
      "arxiv_id": "2403.01273v1",
      "title": "NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zhang",
        "Jonah Wonkyu Yi",
        "Bowen Yao",
        "Zhaozhuo Xu",
        "Anshumali Shrivastava"
      ],
      "abstract": "Large language model inference on Central Processing Units (CPU) is\nchallenging due to the vast quantities of expensive Multiply-Add (MAD) matrix\noperations in the attention computations. In this paper, we argue that there is\na rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers,\nwhich allow for ultra-low-latency lookups in batch. We leverage this unique\ncapability of CPUs to propose NoMAD-Attention, an efficient attention algorithm\nthat replaces MAD operations with in-register lookups. Through hardware-aware\nalgorithmic designs, NoMAD-Attention achieves the computation of attention\nscores using repeated fast accesses to SIMD registers despite their highly\nlimited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based\nLLMs without model finetuning. Empirical evaluations demonstrate that\nNoMAD-Attention maintains the quality of the original LLMs well, and speeds up\nthe 4-bit quantized LLaMA-7B-based model by up to 2$\\times$ at 16k context\nlength. Our results are reproducible at\nhttps://github.com/tonyzhang617/nomad-dist.",
      "tldr_zh": "本文提出NoMAD-Attention，一种高效的注意力算法，用于在CPUs上进行Large Language Models (LLMs)推理，通过利用Single-Instruction-Multiple-Data (SIMD)寄存器的快速批量查找来替换昂贵的Multiply-Add (MAD)矩阵操作。该算法采用硬件感知设计，确保在有限寄存器大小下高效计算注意力分数，且无需对预训练模型进行微调。实验结果显示，NoMAD-Attention在16k上下文长度下，将4-bit量化LLaMA-7B模型的推理速度提高多达2倍，同时保持了原模型的质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01273v1",
      "published_date": "2024-03-02 17:29:22 UTC",
      "updated_date": "2024-03-02 17:29:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:52:18.147182"
    },
    {
      "arxiv_id": "2403.02355v1",
      "title": "Temporal Knowledge Graph Completion with Time-sensitive Relations in Hypercomplex Space",
      "title_zh": "在超复空间中利用时间敏感关系的时间知识图谱补全",
      "authors": [
        "Li Cai",
        "Xin Mao",
        "Zhihong Wang",
        "Shangqing Zhao",
        "Yuhao Zhou",
        "Changxu Wu",
        "Man Lan"
      ],
      "abstract": "Temporal knowledge graph completion (TKGC) aims to fill in missing facts\nwithin a given temporal knowledge graph at a specific time. Existing methods,\noperating in real or complex spaces, have demonstrated promising performance in\nthis task. This paper advances beyond conventional approaches by introducing\nmore expressive quaternion representations for TKGC within hypercomplex space.\nUnlike existing quaternion-based methods, our study focuses on capturing\ntime-sensitive relations rather than time-aware entities. Specifically, we\nmodel time-sensitive relations through time-aware rotation and periodic time\ntranslation, effectively capturing complex temporal variability. Furthermore,\nwe theoretically demonstrate our method's capability to model symmetric,\nasymmetric, inverse, compositional, and evolutionary relation patterns.\nComprehensive experiments on public datasets validate that our proposed\napproach achieves state-of-the-art performance in the field of TKGC.",
      "tldr_zh": "本论文针对时间知识图谱补全(TKGC)任务，提出了一种在超复空间(hypercomplex space)中使用四元数(quaternion)表示的方法，专注于捕捉时间敏感关系(time-sensitive relations)。该方法通过时间感知旋转(time-aware rotation)和周期性时间平移(periodic time translation)来有效建模复杂的 temporal variability，并理论证明其能处理对称(symmetric)、不对称(asicmetric)、逆(inverse)、组合(compositional)和演化(evolutionary)关系模式。实验结果显示，该方法在公共数据集上实现了 state-of-the-art 性能，显著提升了 TKGC 的准确性和表现力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02355v1",
      "published_date": "2024-03-02 16:50:48 UTC",
      "updated_date": "2024-03-02 16:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:52:32.006246"
    },
    {
      "arxiv_id": "2403.01255v2",
      "title": "Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey",
      "title_zh": "使用高级深度学习方法的自动语音识别：一项综述",
      "authors": [
        "Hamza Kheddar",
        "Mustapha Hemis",
        "Yassine Himeur"
      ],
      "abstract": "Recent advancements in deep learning (DL) have posed a significant challenge\nfor automatic speech recognition (ASR). ASR relies on extensive training\ndatasets, including confidential ones, and demands substantial computational\nand storage resources. Enabling adaptive systems improves ASR performance in\ndynamic environments. DL techniques assume training and testing data originate\nfrom the same domain, which is not always true. Advanced DL techniques like\ndeep transfer learning (DTL), federated learning (FL), and reinforcement\nlearning (RL) address these issues. DTL allows high-performance models using\nsmall yet related datasets, FL enables training on confidential data without\ndataset possession, and RL optimizes decision-making in dynamic environments,\nreducing computation costs. This survey offers a comprehensive review of DTL,\nFL, and RL-based ASR frameworks, aiming to provide insights into the latest\ndevelopments and aid researchers and professionals in understanding the current\nchallenges. Additionally, transformers, which are advanced DL techniques\nheavily used in proposed ASR frameworks, are considered in this survey for\ntheir ability to capture extensive dependencies in the input ASR sequence. The\npaper starts by presenting the background of DTL, FL, RL, and Transformers and\nthen adopts a well-designed taxonomy to outline the state-of-the-art\napproaches. Subsequently, a critical analysis is conducted to identify the\nstrengths and weaknesses of each framework. Additionally, a comparative study\nis presented to highlight the existing challenges, paving the way for future\nresearch opportunities.",
      "tldr_zh": "这篇论文对自动语音识别 (ASR) 的最新进展进行了全面调查，重点探讨了深度学习 (DL) 技术在处理数据不足、计算资源需求和跨域适应性方面的挑战。论文审视了先进 DL 方法，包括 deep transfer learning (DTL) 用于小数据集的高性能模型训练、federated learning (FL) 实现机密数据上的分布式训练，以及 reinforcement learning (RL) 优化动态环境下的决策以降低计算成本。Transformers 被强调为捕捉输入序列依赖的关键工具，论文通过背景介绍、分类法、状态-of-the-art 框架分析以及比较研究，揭示了各方法的优势、缺点和现有挑战，为未来 ASR 研究提供宝贵见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01255v2",
      "published_date": "2024-03-02 16:25:42 UTC",
      "updated_date": "2024-04-18 17:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:52:45.106049"
    },
    {
      "arxiv_id": "2403.04782v1",
      "title": "A Survey on Temporal Knowledge Graph: Representation Learning and Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Li Cai",
        "Xin Mao",
        "Yuhao Zhou",
        "Zhaoguang Long",
        "Changxu Wu",
        "Man Lan"
      ],
      "abstract": "Knowledge graphs have garnered significant research attention and are widely\nused to enhance downstream applications. However, most current studies mainly\nfocus on static knowledge graphs, whose facts do not change with time, and\ndisregard their dynamic evolution over time. As a result, temporal knowledge\ngraphs have attracted more attention because a large amount of structured\nknowledge exists only within a specific period. Knowledge graph representation\nlearning aims to learn low-dimensional vector embeddings for entities and\nrelations in a knowledge graph. The representation learning of temporal\nknowledge graphs incorporates time information into the standard knowledge\ngraph framework and can model the dynamics of entities and relations over time.\nIn this paper, we conduct a comprehensive survey of temporal knowledge graph\nrepresentation learning and its applications. We begin with an introduction to\nthe definitions, datasets, and evaluation metrics for temporal knowledge graph\nrepresentation learning. Next, we propose a taxonomy based on the core\ntechnologies of temporal knowledge graph representation learning methods, and\nprovide an in-depth analysis of different methods in each category. Finally, we\npresent various downstream applications related to the temporal knowledge\ngraphs. In the end, we conclude the paper and have an outlook on the future\nresearch directions in this area.",
      "tldr_zh": "这篇论文对 Temporal Knowledge Graph 的表示学习和应用进行了全面调查，强调了其在建模实体和关系动态变化方面的优势，与传统静态知识图相比更能捕捉时间演化。论文首先介绍了相关定义、数据集和评估指标，然后基于核心技术（如时间信息整合）对表示学习方法进行了分类和深入分析。最终，它探讨了 Temporal Knowledge Graph 在下游应用中的潜力，并展望了未来研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.04782v1",
      "published_date": "2024-03-02 16:21:45 UTC",
      "updated_date": "2024-03-02 16:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:52:54.676813"
    },
    {
      "arxiv_id": "2403.01248v1",
      "title": "SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code",
      "title_zh": "翻译失败",
      "authors": [
        "Ziniu Hu",
        "Ahmet Iscen",
        "Aashi Jain",
        "Thomas Kipf",
        "Yisong Yue",
        "David A. Ross",
        "Cordelia Schmid",
        "Alireza Fathi"
      ],
      "abstract": "This paper introduces SceneCraft, a Large Language Model (LLM) Agent\nconverting text descriptions into Blender-executable Python scripts which\nrender complex scenes with up to a hundred 3D assets. This process requires\ncomplex spatial planning and arrangement. We tackle these challenges through a\ncombination of advanced abstraction, strategic planning, and library learning.\nSceneCraft first models a scene graph as a blueprint, detailing the spatial\nrelationships among assets in the scene. SceneCraft then writes Python scripts\nbased on this graph, translating relationships into numerical constraints for\nasset layout. Next, SceneCraft leverages the perceptual strengths of\nvision-language foundation models like GPT-V to analyze rendered images and\niteratively refine the scene. On top of this process, SceneCraft features a\nlibrary learning mechanism that compiles common script functions into a\nreusable library, facilitating continuous self-improvement without expensive\nLLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses\nexisting LLM-based agents in rendering complex scenes, as shown by its\nadherence to constraints and favorable human assessments. We also showcase the\nbroader application potential of SceneCraft by reconstructing detailed 3D\nscenes from the Sintel movie and guiding a video generative model with\ngenerated scenes as intermediary control signal.",
      "tldr_zh": "本论文提出 SceneCraft，一种 LLM Agent，能将文本描述转化为 Blender 可执行的 Python 脚本，用于合成包含多达一百个 3D 资产的复杂场景。\n该系统通过构建 scene graph 作为蓝图来定义资产的空间关系、生成基于数值约束的脚本，并利用 GPT-V 等视觉语言模型分析渲染图像进行迭代优化，同时引入库学习机制实现可重用功能和自我改进。\n实验结果表明，SceneCraft 在渲染复杂场景时优于现有 LLM 代理，展现出更高的约束遵守性和人类评估分数，并展示了其在重建 Sintel 电影 3D 场景和指导视频生成模型的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01248v1",
      "published_date": "2024-03-02 16:16:26 UTC",
      "updated_date": "2024-03-02 16:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:53:09.585690"
    },
    {
      "arxiv_id": "2403.01244v2",
      "title": "Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal",
      "title_zh": "翻译失败",
      "authors": [
        "Jianheng Huang",
        "Leyang Cui",
        "Ante Wang",
        "Chengyi Yang",
        "Xinting Liao",
        "Linfeng Song",
        "Junfeng Yao",
        "Jinsong Su"
      ],
      "abstract": "Large language models (LLMs) suffer from catastrophic forgetting during\ncontinual learning. Conventional rehearsal-based methods rely on previous\ntraining data to retain the model's ability, which may not be feasible in\nreal-world applications. When conducting continual learning based on a\npublicly-released LLM checkpoint, the availability of the original training\ndata may be non-existent. To address this challenge, we propose a framework\ncalled Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic\ninstances for rehearsal. Concretely, we first employ the base LLM for\nin-context learning to generate synthetic instances. Subsequently, we utilize\nthe latest LLM to refine the instance outputs based on the synthetic inputs,\npreserving its acquired ability. Finally, we select diverse high-quality\nsynthetic instances for rehearsal in future stages. Experimental results\ndemonstrate that SSR achieves superior or comparable performance compared to\nconventional rehearsal-based approaches while being more data-efficient.\nBesides, SSR effectively preserves the generalization capabilities of LLMs in\ngeneral domains.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 在持续学习中存在的 Catastrophic Forgetting 问题，提出了一种 Self-Synthesized Rehearsal (SSR) 框架，使用 LLM 自行生成合成实例来替代原始训练数据进行复习。SSR 的具体过程包括：先利用基础 LLM 通过 In-Context Learning 生成合成实例，然后由最新 LLM 基于这些输入精炼输出，并选择多样高质量实例用于后续训练。实验结果表明，SSR 相较于传统方法实现了优越或相当的性能，同时更数据高效，并有效保留了 LLMs 在一般领域的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 main, long paper",
      "pdf_url": "http://arxiv.org/pdf/2403.01244v2",
      "published_date": "2024-03-02 16:11:23 UTC",
      "updated_date": "2024-05-25 12:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:53:20.552876"
    },
    {
      "arxiv_id": "2403.01242v1",
      "title": "Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lochan Basyal",
        "Bijay Gaudel"
      ],
      "abstract": "Electric automation systems offer convenience and efficiency in controlling\nelectrical circuits and devices. Traditionally, these systems rely on\npredefined commands for control, limiting flexibility and adaptability. In this\npaper, we propose a novel approach to augment automation by introducing\nintent-based user instruction classification using machine learning techniques.\nOur system represents user instructions as intents, allowing for dynamic\ncontrol of electrical circuits without relying on predefined commands. Through\na machine learning model trained on a labeled dataset of user instructions, our\nsystem classifies intents from user input, enabling a more intuitive and\nadaptable control scheme. We present the design and implementation of our\nintent-based electric automation system, detailing the development of the\nmachine learning model for intent classification. Experimental results\ndemonstrate the effectiveness of our approach in enhancing user experience and\nexpanding the capabilities of electric automation systems. Our work contributes\nto the advancement of smart technologies by providing a more seamless\ninteraction between users and their environments.",
      "tldr_zh": "本研究针对传统电自动化系统的预定义命令限制，提出了一种基于意图的 user instruction classification 方法，利用 machine learning 技术增强系统的灵活性和适应性。系统通过训练一个 machine learning 模型来从用户输入中分类意图，从而实现动态控制电电路，而非依赖固定命令。实验结果显示，该方法显著提高了用户体验，并扩展了电自动化系统的功能，为智能技术与用户交互提供了更无缝的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.01242v1",
      "published_date": "2024-03-02 16:06:03 UTC",
      "updated_date": "2024-03-02 16:06:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:53:30.469872"
    },
    {
      "arxiv_id": "2403.01241v2",
      "title": "IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact",
      "title_zh": "IntactKV：通过保持枢纽",
      "authors": [
        "Ruikang Liu",
        "Haoli Bai",
        "Haokun Lin",
        "Yuening Li",
        "Han Gao",
        "Zhengzhuo Xu",
        "Lu Hou",
        "Jun Yao",
        "Chun Yuan"
      ],
      "abstract": "Large language models (LLMs) excel in natural language processing but demand\nintensive computation. To mitigate this, various quantization methods have been\nexplored, yet they compromise LLM performance. This paper unveils a previously\noverlooked type of outliers in LLMs. Such outliers are found to allocate most\nof the attention scores on initial tokens of input, termed as pivot tokens,\nwhich are crucial to the performance of quantized LLMs. Given that, we propose\nIntactKV to generate the KV cache of pivot tokens losslessly from the\nfull-precision model. The approach is simple and easy to combine with existing\nquantization solutions with no extra inference overhead. Besides, IntactKV can\nbe calibrated as additional LLM parameters to boost the quantized LLMs further\nwith minimal training costs. Mathematical analysis also proves that IntactKV\neffectively reduces the upper bound of quantization error. Empirical results\nshow that IntactKV brings consistent improvement over various quantization\nmethods across different LLMs and downstream tasks, leading to the new\nstate-of-the-art for LLM quantization. The codes are available at\nhttps://github.com/ruikangliu/IntactKV.",
      "tldr_zh": "该论文发现大型语言模型 (LLMs) 中的 pivot tokens（输入初始 tokens）是量化过程中被忽略的关键异常值，这些 tokens 分配了大部分注意力分数，对量化性能至关重要。作者提出 IntactKV 方法，通过从全精度模型无损生成 pivot tokens 的 KV cache，实现对现有量化方案的简单整合，而不增加推理开销。IntactKV 还能作为额外参数进行微调，进一步降低量化错误的上限，并通过数学分析证明其有效性。实验结果显示，该方法在多种 LLMs 和下游任务上带来一致改进，达到了 LLM 量化的新最先进水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2403.01241v2",
      "published_date": "2024-03-02 16:05:26 UTC",
      "updated_date": "2024-05-25 10:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:53:45.382817"
    },
    {
      "arxiv_id": "2403.01232v3",
      "title": "Polynormer: Polynomial-Expressive Graph Transformer in Linear Time",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhui Deng",
        "Zichao Yue",
        "Zhiru Zhang"
      ],
      "abstract": "Graph transformers (GTs) have emerged as a promising architecture that is\ntheoretically more expressive than message-passing graph neural networks\n(GNNs). However, typical GT models have at least quadratic complexity and thus\ncannot scale to large graphs. While there are several linear GTs recently\nproposed, they still lag behind GNN counterparts on several popular graph\ndatasets, which poses a critical concern on their practical expressivity. To\nbalance the trade-off between expressivity and scalability of GTs, we propose\nPolynormer, a polynomial-expressive GT model with linear complexity. Polynormer\nis built upon a novel base model that learns a high-degree polynomial on input\nfeatures. To enable the base model permutation equivariant, we integrate it\nwith graph topology and node features separately, resulting in local and global\nequivariant attention models. Consequently, Polynormer adopts a linear\nlocal-to-global attention scheme to learn high-degree equivariant polynomials\nwhose coefficients are controlled by attention scores. Polynormer has been\nevaluated on $13$ homophilic and heterophilic datasets, including large graphs\nwith millions of nodes. Our extensive experiment results show that Polynormer\noutperforms state-of-the-art GNN and GT baselines on most datasets, even\nwithout the use of nonlinear activation functions.",
      "tldr_zh": "该研究提出Polynormer，一种多项式表达性的Graph Transformer (GT)模型，旨在解决传统GTs的二次方复杂度问题，同时提升其实际表达性。Polynormer基于一个学习高阶多项式的基模型，通过将模型与图拓扑和节点特征整合，实现局部和全局等变注意力，并采用线性局部到全局注意力方案来控制多项式系数。实验结果显示，在13个同质和异质数据集上，包括百万节点的大型图，Polynormer在大多数数据集上优于最先进的Graph Neural Networks (GNNs)和GT基线，甚至无需非线性激活函数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at International Conference on\n  Learning Representations (ICLR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01232v3",
      "published_date": "2024-03-02 15:32:01 UTC",
      "updated_date": "2024-04-06 23:26:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:53:55.488916"
    },
    {
      "arxiv_id": "2403.01229v1",
      "title": "REWIND Dataset: Privacy-preserving Speaking Status Segmentation from Multimodal Body Movement Signals in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Jose Vargas Quiros",
        "Chirag Raman",
        "Stephanie Tan",
        "Ekin Gedik",
        "Laura Cabrera-Quiros",
        "Hayley Hung"
      ],
      "abstract": "Recognizing speaking in humans is a central task towards understanding social\ninteractions. Ideally, speaking would be detected from individual voice\nrecordings, as done previously for meeting scenarios. However, individual voice\nrecordings are hard to obtain in the wild, especially in crowded mingling\nscenarios due to cost, logistics, and privacy concerns. As an alternative,\nmachine learning models trained on video and wearable sensor data make it\npossible to recognize speech by detecting its related gestures in an\nunobtrusive, privacy-preserving way. These models themselves should ideally be\ntrained using labels obtained from the speech signal. However, existing\nmingling datasets do not contain high quality audio recordings. Instead,\nspeaking status annotations have often been inferred by human annotators from\nvideo, without validation of this approach against audio-based ground truth. In\nthis paper we revisit no-audio speaking status estimation by presenting the\nfirst publicly available multimodal dataset with high-quality individual speech\nrecordings of 33 subjects in a professional networking event. We present three\nbaselines for no-audio speaking status segmentation: a) from video, b) from\nbody acceleration (chest-worn accelerometer), c) from body pose tracks. In all\ncases we predict a 20Hz binary speaking status signal extracted from the audio,\na time resolution not available in previous datasets. In addition to providing\nthe signals and ground truth necessary to evaluate a wide range of speaking\nstatus detection methods, the availability of audio in REWIND makes it suitable\nfor cross-modality studies not feasible with previous mingling datasets.\nFinally, our flexible data consent setup creates new challenges for multimodal\nsystems under missing modalities.",
      "tldr_zh": "该论文引入了 REWIND Dataset，这是一个公开的多模态数据集，包含 33 名受试者在专业网络事件中的高质量个人语音记录，用于隐私保护的讲话状态分割。数据集解决了现有数据集的局限性，通过提供视频、可穿戴传感器（如胸部加速度计）和体姿跟踪数据，以及基于音频的 20Hz 二进制讲话状态地面真相，支持无音频讲话检测方法的评估。作者提出了三个基线模型：a) 从视频，b) 从体加速，c) 从体姿跟踪，这些方法能检测与讲话相关的肢体动作。该数据集不仅促进跨模态研究，还通过灵活的数据同意机制，探讨了多模态系统在缺失模态下的新挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01229v1",
      "published_date": "2024-03-02 15:14:58 UTC",
      "updated_date": "2024-03-02 15:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:54:09.223234"
    },
    {
      "arxiv_id": "2403.01221v2",
      "title": "A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "André Artelt",
        "Andreas Gregoriades"
      ],
      "abstract": "Counterfactual explanations constitute among the most popular methods for\nanalyzing black-box systems since they can recommend cost-efficient and\nactionable changes to the input of a system to obtain the desired system\noutput. While most of the existing counterfactual methods explain a single\ninstance, several real-world problems, such as customer satisfaction, require\nthe identification of a single counterfactual that can satisfy multiple\ninstances (e.g. customers) simultaneously. To address this limitation, in this\nwork, we propose a flexible two-stage algorithm for finding groups of instances\nand computing cost-efficient multi-instance counterfactual explanations. The\npaper presents the algorithm and its performance against popular alternatives\nthrough a comparative evaluation.",
      "tldr_zh": "该论文针对反事实解释（Counterfactual explanations）方法的局限性，提出了一种灵活的二阶段算法，用于处理多个实例（如客户满意度问题）并生成成本高效的多实例解释。第一阶段算法识别实例组，第二阶段计算可操作的输入变化以同时满足这些实例。实验比较评估显示，该算法在性能上优于现有流行替代方案，为黑盒系统分析提供了更实用的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in the Late-breaking works track @ 2nd World Conference on\n  eXplainable Artificial Intelligence (2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.01221v2",
      "published_date": "2024-03-02 14:30:57 UTC",
      "updated_date": "2024-05-21 11:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:54:19.012163"
    },
    {
      "arxiv_id": "2403.01216v2",
      "title": "API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayuan Su",
        "Jing Luo",
        "Hongwei Wang",
        "Lu Cheng"
      ],
      "abstract": "This study aims to address the pervasive challenge of quantifying uncertainty\nin large language models (LLMs) without logit-access. Conformal Prediction\n(CP), known for its model-agnostic and distribution-free features, is a desired\napproach for various LLMs and data distributions. However, existing CP methods\nfor LLMs typically assume access to the logits, which are unavailable for some\nAPI-only LLMs. In addition, logits are known to be miscalibrated, potentially\nleading to degraded CP performance. To tackle these challenges, we introduce a\nnovel CP method that (1) is tailored for API-only LLMs without logit-access;\n(2) minimizes the size of prediction sets; and (3) ensures a statistical\nguarantee of the user-defined coverage. The core idea of this approach is to\nformulate nonconformity measures using both coarse-grained (i.e., sample\nfrequency) and fine-grained uncertainty notions (e.g., semantic similarity).\nExperimental results on both close-ended and open-ended Question Answering\ntasks show our approach can mostly outperform the logit-based CP baselines.",
      "tldr_zh": "这篇论文解决了大型语言模型（LLMs）在没有logit-access的情况下量化不确定性的挑战，提出了一种新型Conformal Prediction (CP) 方法。 该方法无需访问logits，而是通过制定基于粗粒度（如样本频率）和细粒度（如语义相似性）的nonconformity measures，来最小化预测集大小并确保用户定义的覆盖率统计保证。 实验在封闭式和开放式问答任务上表明，该方法优于基于logit的CP基线。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01216v2",
      "published_date": "2024-03-02 14:14:45 UTC",
      "updated_date": "2024-04-04 02:15:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:54:32.616106"
    },
    {
      "arxiv_id": "2403.01210v1",
      "title": "SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Cui",
        "Jiale Duan",
        "Binyan Luo",
        "Hang Cao",
        "Wang Guo",
        "Haifeng Li"
      ],
      "abstract": "Deep neural network-based Synthetic Aperture Radar (SAR) target recognition\nmodels are susceptible to adversarial examples. Current adversarial example\ngeneration methods for SAR imagery primarily operate in the 2D digital domain,\nknown as image adversarial examples. Recent work, while considering SAR imaging\nscatter mechanisms, fails to account for the actual imaging process, rendering\nattacks in the three-dimensional physical domain infeasible, termed pseudo\nphysics adversarial examples. To address these challenges, this paper proposes\nSAR-AE-SFP-Attack, a method to generate real physics adversarial examples by\naltering the scattering feature parameters of target objects. Specifically, we\niteratively optimize the coherent energy accumulation of the target echo by\nperturbing the reflection coefficient and scattering coefficient in the\nscattering feature parameters of the three-dimensional target object, and\nobtain the adversarial example after echo signal processing and imaging\nprocessing in the RaySAR simulator. Experimental results show that compared to\ndigital adversarial attack methods, SAR-AE-SFP Attack significantly improves\nattack efficiency on CNN-based models (over 30\\%) and Transformer-based models\n(over 13\\%), demonstrating significant transferability of attack effects across\ndifferent models and perspectives.",
      "tldr_zh": "这篇论文提出 SAR-AE-SFP-Attack 方法，用于在真实物理域生成 SAR（Synthetic Aperture Radar）图像对抗样本，通过修改目标对象的 scattering feature parameters（如 reflection coefficient 和 scattering coefficient）来实现。方法涉及迭代优化目标回波的相干能量积累，并利用 RaySAR 模拟器进行回波信号处理和成像处理，以克服现有数字域攻击的局限性。实验结果显示，该攻击显著提高了对 CNN 模型（超过 30%）和 Transformer 模型（超过 13%）的攻击效率，并展示了良好的跨模型和视角转移性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 9 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.01210v1",
      "published_date": "2024-03-02 13:52:28 UTC",
      "updated_date": "2024-03-02 13:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:54:45.935231"
    },
    {
      "arxiv_id": "2403.01199v1",
      "title": "The Case for Animal-Friendly AI",
      "title_zh": "翻译失败",
      "authors": [
        "Sankalpa Ghose",
        "Yip Fai Tse",
        "Kasra Rasaee",
        "Jeff Sebo",
        "Peter Singer"
      ],
      "abstract": "Artificial intelligence is seen as increasingly important, and potentially\nprofoundly so, but the fields of AI ethics and AI engineering have not fully\nrecognized that these technologies, including large language models (LLMs),\nwill have massive impacts on animals. We argue that this impact matters,\nbecause animals matter morally.\n  As a first experiment in evaluating animal consideration in LLMs, we\nconstructed a proof-of-concept Evaluation System, which assesses LLM responses\nand biases from multiple perspectives. This system evaluates LLM outputs by two\ncriteria: their truthfulness, and the degree of consideration they give to the\ninterests of animals. We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using\na set of structured queries and predefined normative perspectives. Preliminary\nresults suggest that the outcomes of the tested models can be benchmarked\nregarding the consideration they give to animals, and that generated positions\nand biases might be addressed and mitigated with more developed and validated\nsystems.\n  Our research contributes one possible approach to integrating animal ethics\nin AI, opening pathways for future studies and practical applications in\nvarious fields, including education, public policy, and regulation, that\ninvolve or relate to animals and society. Overall, this study serves as a step\ntowards more useful and responsible AI systems that better recognize and\nrespect the vital interests and perspectives of all sentient beings.",
      "tldr_zh": "该论文主张AI技术，包括大型语言模型(LLMs)，会对动物产生重大影响，但AI伦理和工程领域尚未充分重视，因为动物在道德上具有重要性。研究者构建了一个概念验证评估系统(Evaluation System)，通过结构化查询和预定义规范视角，评估OpenAI ChatGPT 4和Anthropic Claude 2.1的响应真实性及对动物利益的关注度。初步结果显示，该系统能基准化模型对动物的考虑程度，并为缓解偏见提供潜在方法；整体研究为将动物伦理整合进AI提供途径，促进教育、公共政策和监管等领域更负责任的AI应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2024 Workshop on Public Sector LLMs: Algorithmic and\n  Sociotechnical Design. 12 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.01199v1",
      "published_date": "2024-03-02 12:41:11 UTC",
      "updated_date": "2024-03-02 12:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:54:56.452853"
    },
    {
      "arxiv_id": "2403.01196v1",
      "title": "Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021",
      "title_zh": "翻译失败",
      "authors": [
        "Séamus Lankford",
        "Haithem Afli",
        "Andy Way"
      ],
      "abstract": "Translation models for the specific domain of translating Covid data from\nEnglish to Irish were developed for the LoResMT 2021 shared task. Domain\nadaptation techniques, using a Covid-adapted generic 55k corpus from the\nDirectorate General of Translation, were applied. Fine-tuning, mixed\nfine-tuning and combined dataset approaches were compared with models trained\non an extended in-domain dataset. As part of this study, an English-Irish\ndataset of Covid related data, from the Health and Education domains, was\ndeveloped. The highest-performing model used a Transformer architecture trained\nwith an extended in-domain Covid dataset. In the context of this study, we have\ndemonstrated that extending an 8k in-domain baseline dataset by just 5k lines\nimproved the BLEU score by 27 points.",
      "tldr_zh": "本研究针对 LoResMT 2021 共享任务，开发了英语到爱尔兰语的 COVID 领域机器翻译模型，使用领域适应技术（如微调、混合微调和组合数据集）基于欧盟翻译总局的 55k 通用语料库进行优化。\n研究者创建了一个新的英语-爱尔兰语 COVID 相关数据集，涵盖健康和教育领域，并比较了不同训练方法。\n结果表明，使用 Transformer 架构并扩展 8k 基线数据集至 13k 行后，BLEU score 提高了 27 分，证明了领域内数据扩展对模型性能的显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01196v1",
      "published_date": "2024-03-02 12:29:28 UTC",
      "updated_date": "2024-03-02 12:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:55:09.447804"
    },
    {
      "arxiv_id": "2403.01193v3",
      "title": "RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Feldman",
        "James R. Foulds",
        "Shimei Pan"
      ],
      "abstract": "Large language models (LLMs) like ChatGPT demonstrate the remarkable progress\nof artificial intelligence. However, their tendency to hallucinate -- generate\nplausible but false information -- poses a significant challenge. This issue is\ncritical, as seen in recent court cases where ChatGPT's use led to citations of\nnon-existent legal rulings. This paper explores how Retrieval-Augmented\nGeneration (RAG) can counter hallucinations by integrating external knowledge\nwith prompts. We empirically evaluate RAG against standard LLMs using prompts\ndesigned to induce hallucinations. Our results show that RAG increases accuracy\nin some cases, but can still be misled when prompts directly contradict the\nmodel's pre-trained understanding. These findings highlight the complex nature\nof hallucinations and the need for more robust solutions to ensure LLM\nreliability in real-world applications. We offer practical recommendations for\nRAG deployment and discuss implications for the development of more trustworthy\nLLMs.",
      "tldr_zh": "这篇论文探讨了Retrieval-Augmented Generation (RAG) 在减少大型语言模型 (LLMs) 如ChatGPT 的幻觉问题（生成看似合理但虚假信息）上的双重效应。作者通过实证实验，使用设计诱导幻觉的提示，将RAG与标准LLMs进行比较，结果显示RAG在某些场景下提高了准确性，但当提示直接与模型的预训练知识矛盾时，仍然可能被误导。研究强调了幻觉的复杂性，并提供了RAG部署的实用建议，以推动更可靠的LLMs在实际应用中的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "H.3.3; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "7 Pages, 1 Figure, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2403.01193v3",
      "published_date": "2024-03-02 12:19:04 UTC",
      "updated_date": "2024-06-12 12:00:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:55:21.161180"
    },
    {
      "arxiv_id": "2403.01185v1",
      "title": "Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Ha-Thanh Nguyen",
        "Ken Satoh"
      ],
      "abstract": "Finetuning approaches in NLP often focus on exploitation rather than\nexploration, which may lead to suboptimal models. Given the vast search space\nof natural language, this limited exploration can restrict their performance in\ncomplex, high-stakes domains, where accurate negation understanding and logical\nreasoning abilities are crucial. To address this issue, we leverage\nReinforcement Learning from Logical Feedback (RLLF) to create an effective\nbalance between exploration and exploitation in LLMs. Our approach employs an\nappropriate benchmark dataset for training and evaluation, highlighting the\nimportance of exploration in enhancing negation understanding capabilities. We\ncompare the performance of our RLLF-enhanced LLMs with baseline models trained\nwithout RLLF, demonstrating the value of this balanced approach. Furthermore,\nwe showcase the potential of our method in legal AI applications by employing\ntransfer learning and evaluating its impact on negation understanding. Our\nexperimental results exhibit the effectiveness of balancing exploration and\nexploitation with RLLF in improving LLMs' negation capabilities. This has\nimplications for the development of more accurate, reliable, and logically\nconsistent language models in high-stakes domains.",
      "tldr_zh": "这篇论文探讨了在大型语言模型(LLM)中平衡exploration和exploitation的问题，提出使用Soft RLLF（Reinforcement Learning from Logical Feedback）方法来提升否定理解和逻辑推理能力，以应对NLP微调中过度注重exploitation的局限性。研究利用合适的基准数据集进行训练和评估，比较了RLLF增强模型与基线模型的表现，结果显示前者显著改善了否定理解效果。实验进一步通过迁移学习应用于法律AI领域，证明这种平衡方法能增强模型的准确性、可靠性和逻辑一致性，为高风险领域的语言模型开发提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "JURISIN 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01185v1",
      "published_date": "2024-03-02 11:54:55 UTC",
      "updated_date": "2024-03-02 11:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:55:32.711784"
    },
    {
      "arxiv_id": "2403.01183v2",
      "title": "Leveraging Self-Supervised Learning for Scene Classification in Child Sexual Abuse Imagery",
      "title_zh": "利用自我监督学习进行儿童性虐待图像中的场景",
      "authors": [
        "Pedro H. V. Valois",
        "João Macedo",
        "Leo S. F. Ribeiro",
        "Jefersson A. dos Santos",
        "Sandra Avila"
      ],
      "abstract": "Crime in the 21st century is split into a virtual and real world. However,\nthe former has become a global menace to people's well-being and security in\nthe latter. The challenges it presents must be faced with unified global\ncooperation, and we must rely more than ever on automated yet trustworthy tools\nto combat the ever-growing nature of online offenses. Over 10 million child\nsexual abuse reports are submitted to the US National Center for Missing \\&\nExploited Children every year, and over 80% originate from online sources.\nTherefore, investigation centers cannot manually process and correctly\ninvestigate all imagery. In light of that, reliable automated tools that can\nsecurely and efficiently deal with this data are paramount. In this sense, the\nscene classification task looks for contextual cues in the environment, being\nable to group and classify child sexual abuse data without requiring to be\ntrained on sensitive material. The scarcity and limitations of working with\nchild sexual abuse images lead to self-supervised learning, a machine-learning\nmethodology that leverages unlabeled data to produce powerful representations\nthat can be more easily transferred to downstream tasks. This work shows that\nself-supervised deep learning models pre-trained on scene-centric data can\nreach 71.6% balanced accuracy on our indoor scene classification task and, on\naverage, 2.2 percentage points better performance than a fully supervised\nversion. We cooperate with Brazilian Federal Police experts to evaluate our\nindoor classification model on actual child abuse material. The results\ndemonstrate a notable discrepancy between the features observed in widely used\nscene datasets and those depicted on sensitive materials.",
      "tldr_zh": "这篇论文探讨了利用自监督学习（self-supervised learning）来对儿童性虐待图像进行场景分类，从而应对在线犯罪的挑战，避免直接使用敏感材料训练模型。研究强调了这种方法的优势，因为它能从未标记的场景数据中提取强大表示，并应用于下游任务。实验结果显示，自监督模型在室内场景分类任务上达到71.6%的平衡准确率，比全监督模型高出2.2%。此外，通过与巴西联邦警察的合作评估，论文揭示了常用数据集特征与实际敏感材料之间存在的显著差异，为可靠的自动化调查工具提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figures, 4 tables. Under review",
      "pdf_url": "http://arxiv.org/pdf/2403.01183v2",
      "published_date": "2024-03-02 11:44:14 UTC",
      "updated_date": "2024-10-26 15:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:55:44.628296"
    },
    {
      "arxiv_id": "2403.01166v2",
      "title": "DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jialong Wu",
        "Linhai Zhang",
        "Deyu Zhou",
        "Guoqiang Xu"
      ],
      "abstract": "Though notable progress has been made, neural-based aspect-based sentiment\nanalysis (ABSA) models are prone to learn spurious correlations from annotation\nbiases, resulting in poor robustness on adversarial data transformations. Among\nthe debiasing solutions, causal inference-based methods have attracted much\nresearch attention, which can be mainly categorized into causal intervention\nmethods and counterfactual reasoning methods. However, most of the present\ndebiasing methods focus on single-variable causal inference, which is not\nsuitable for ABSA with two input variables (the target aspect and the review).\nIn this paper, we propose a novel framework based on multi-variable causal\ninference for debiasing ABSA. In this framework, different types of biases are\ntackled based on different causal intervention methods. For the review branch,\nthe bias is modeled as indirect confounding from context, where backdoor\nadjustment intervention is employed for debiasing. For the aspect branch, the\nbias is described as a direct correlation with labels, where counterfactual\nreasoning is adopted for debiasing. Extensive experiments demonstrate the\neffectiveness of the proposed method compared to various baselines on the two\nwidely used real-world aspect robustness test set datasets.",
      "tldr_zh": "该论文提出DINER框架，利用多变量因果推理（multi-variable causal inference）来消除基于方面的情感分析（ABSA）中的偏差问题，因为现有模型容易从标注偏差中学习虚假相关性，导致鲁棒性不足。框架针对评论分支采用后门调整干预（backdoor adjustment intervention）来处理间接混杂因素偏差，而针对方面分支则使用反事实推理（counterfactual reasoning）来打破与标签的直接相关性。通过在两个常用真实世界鲁棒性测试集上的实验，该方法比各种基线模型表现出显著的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL2024(Findings)",
      "pdf_url": "http://arxiv.org/pdf/2403.01166v2",
      "published_date": "2024-03-02 10:38:31 UTC",
      "updated_date": "2024-06-06 07:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:55:56.876984"
    },
    {
      "arxiv_id": "2403.01165v2",
      "title": "STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models",
      "title_zh": "STAR：结合动态主动学习的约束 LoRA，用于大语言模型的数据高效微调",
      "authors": [
        "Linhai Zhang",
        "Jialong Wu",
        "Deyu Zhou",
        "Guoqiang Xu"
      ],
      "abstract": "Though Large Language Models (LLMs) have demonstrated the powerful\ncapabilities of few-shot learning through prompting methods, supervised\ntraining is still necessary for complex reasoning tasks. Because of their\nextensive parameters and memory consumption, both Parameter-Efficient\nFine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been\nproposed for LLMs. Nevertheless, the issue of large annotated data consumption,\nthe aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is\nto combine the PEFT method with active learning. However, the experimental\nresults show that such a combination is not trivial and yields inferior\nresults. Through probe experiments, such observation might be explained by two\nmain reasons: uncertainty gap and poor model calibration. Therefore, in this\npaper, we propose a novel approach to effectively integrate uncertainty-based\nactive learning and LoRA. Specifically, for the uncertainty gap, we introduce a\ndynamic uncertainty measurement that combines the uncertainty of the base model\nand the uncertainty of the full model during the iteration of active learning.\nFor poor model calibration, we incorporate the regularization method during\nLoRA training to keep the model from being over-confident, and the Monte-Carlo\ndropout mechanism is employed to enhance the uncertainty estimation.\nExperimental results show that the proposed approach outperforms existing\nbaseline models on three complex reasoning tasks.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 在复杂推理任务中需要大量标注数据的难题，提出了一种名为 STAR 的数据高效微调方法。该方法将不确定性-based 主动学习与 LoRA 相结合，通过动态不确定性测量（整合 base model 和 full model 的不确定性）来弥合不确定性差距，并采用正则化方法和 Monte-Carlo dropout 机制提升模型校准和不确定性估计。相比简单结合主动学习和 PEFT (Parameter-Efficient Fine-Tuning) 的基线，STAR 有效避免了性能劣化问题。实验结果显示，该方法在三个复杂推理任务上优于现有基线模型，显著提高了数据利用效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL2024(Findings)",
      "pdf_url": "http://arxiv.org/pdf/2403.01165v2",
      "published_date": "2024-03-02 10:38:10 UTC",
      "updated_date": "2024-06-06 07:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:56:08.574199"
    },
    {
      "arxiv_id": "2403.02354v3",
      "title": "Spatio-Temporal Field Neural Networks for Air Quality Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Feng",
        "Qiongyan Wang",
        "Yutong Xia",
        "Junlin Huang",
        "Siru Zhong",
        "Yuxuan Liang"
      ],
      "abstract": "The air quality inference problem aims to utilize historical data from a\nlimited number of observation sites to infer the air quality index at an\nunknown location. Considering the sparsity of data due to the high maintenance\ncost of the stations, good inference algorithms can effectively save the cost\nand refine the data granularity. While spatio-temporal graph neural networks\nhave made excellent progress on this problem, their non-Euclidean and discrete\ndata structure modeling of reality limits its potential. In this work, we make\nthe first attempt to combine two different spatio-temporal perspectives, fields\nand graphs, by proposing a new model, Spatio-Temporal Field Neural Network, and\nits corresponding new framework, Pyramidal Inference. Extensive experiments\nvalidate that our model achieves state-of-the-art performance in nationwide air\nquality inference in the Chinese Mainland, demonstrating the superiority of our\nproposed model and framework.",
      "tldr_zh": "该论文针对空气质量推断问题，利用有限观测站的历史数据来预测未知位置的空气质量指数，以应对数据稀疏性的挑战。作者首次结合时空领域（fields）和图（graphs）的视角，提出Spatio-Temporal Field Neural Network模型及其Pyramidal Inference框架，以克服传统时空图神经网络的非欧空间和离散数据结构限制。实验结果显示，该模型在中国大陆全国范围的空气质量推断中实现了最先进性能，证明了其有效性和优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "We want to recheck our model and experimental design",
      "pdf_url": "http://arxiv.org/pdf/2403.02354v3",
      "published_date": "2024-03-02 10:14:42 UTC",
      "updated_date": "2024-06-06 04:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:56:19.724183"
    },
    {
      "arxiv_id": "2403.01152v1",
      "title": "A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization",
      "title_zh": "翻译失败",
      "authors": [
        "Tharindu Kumarage",
        "Garima Agrawal",
        "Paras Sheth",
        "Raha Moraffah",
        "Aman Chadha",
        "Joshua Garland",
        "Huan Liu"
      ],
      "abstract": "We have witnessed lately a rapid proliferation of advanced Large Language\nModels (LLMs) capable of generating high-quality text. While these LLMs have\nrevolutionized text generation across various domains, they also pose\nsignificant risks to the information ecosystem, such as the potential for\ngenerating convincing propaganda, misinformation, and disinformation at scale.\nThis paper offers a review of AI-generated text forensic systems, an emerging\nfield addressing the challenges of LLM misuses. We present an overview of the\nexisting efforts in AI-generated text forensics by introducing a detailed\ntaxonomy, focusing on three primary pillars: detection, attribution, and\ncharacterization. These pillars enable a practical understanding of\nAI-generated text, from identifying AI-generated content (detection),\ndetermining the specific AI model involved (attribution), and grouping the\nunderlying intents of the text (characterization). Furthermore, we explore\navailable resources for AI-generated text forensics research and discuss the\nevolving challenges and future directions of forensic systems in an AI era.",
      "tldr_zh": "这篇论文对 AI 生成文本取证系统进行了全面调查，旨在应对 Large Language Models (LLMs) 的快速发展所带来的风险，如大规模生成宣传、错误信息和虚假信息。论文引入了一个详细的分类法，聚焦于三个核心支柱：检测 (detection) 用于识别 AI 生成内容、归因 (attribution) 用于确定特定 AI 模型，以及特征化 (characterization) 用于分析文本的潜在意图。最终，它概述了现有研究资源、面临的挑战，并探讨了在 AI 时代取证系统的未来方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01152v1",
      "published_date": "2024-03-02 09:39:13 UTC",
      "updated_date": "2024-03-02 09:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:56:32.138430"
    },
    {
      "arxiv_id": "2403.01147v1",
      "title": "A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xinying Lu",
        "Doudou Zhang",
        "Jianli Xiao"
      ],
      "abstract": "In addition to enhancing traffic safety and facilitating prompt emergency\nresponse, traffic incident detection plays an indispensable role in intelligent\ntransportation systems by providing real-time traffic status information. This\nenables the realization of intelligent traffic control and management. Previous\nresearch has identified that apart from employing advanced algorithmic models,\nthe effectiveness of detection is also significantly influenced by challenges\nrelated to acquiring large datasets and addressing dataset imbalances. A hybrid\nmodel combining transformer and generative adversarial networks (GANs) is\nproposed to address these challenges. Experiments are conducted on four real\ndatasets to validate the superiority of the transformer in traffic incident\ndetection. Additionally, GANs are utilized to expand the dataset and achieve a\nbalanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against\nthe baseline model. The results demonstrate that the proposed model enhances\nthe dataset size, balances the dataset, and improves the performance of traffic\nincident detection in various aspects.",
      "tldr_zh": "该研究针对交通事件检测面临的挑战，如数据集获取困难和不平衡问题，提出了一种结合 Transformer 和 Generative Adversarial Networks (GANs) 的混合模型，以提升智能交通系统的实时监控能力。模型利用 GANs 扩展数据集并实现平衡比例（如1:4、2:3和1:1），从而改善数据质量和模型鲁棒性。在四个真实数据集上进行的实验表明，该混合模型相较于基线模型在检测准确性和整体性能方面取得了显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.01147v1",
      "published_date": "2024-03-02 09:28:04 UTC",
      "updated_date": "2024-03-02 09:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:56:44.366795"
    },
    {
      "arxiv_id": "2403.04780v2",
      "title": "MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Yanchao Tan",
        "Hang Lv",
        "Xinyi Huang",
        "Jiawei Zhang",
        "Shiping Wang",
        "Carl Yang"
      ],
      "abstract": "Graphs with abundant attributes are essential in modeling interconnected\nentities and improving predictions in various real-world applications.\nTraditional Graph Neural Networks (GNNs), which are commonly used for modeling\nattributed graphs, need to be re-trained every time when applied to different\ngraph tasks and datasets. Although the emergence of Large Language Models\n(LLMs) has introduced a new paradigm in natural language processing, the\ngenerative potential of LLMs in graph mining remains largely under-explored. To\nthis end, we propose a novel framework MuseGraph, which seamlessly integrates\nthe strengths of GNNs and LLMs and facilitates a more effective and generic\napproach for graph mining across different tasks and datasets. Specifically, we\nfirst introduce a compact graph description via the proposed adaptive input\ngeneration to encapsulate key information from the graph under the constraints\nof language token limitations. Then, we propose a diverse instruction\ngeneration mechanism, which distills the reasoning capabilities from LLMs\n(e.g., GPT-4) to create task-specific Chain-of-Thought-based instruction\npackages for different graph tasks. Finally, we propose a graph-aware\ninstruction tuning with a dynamic instruction package allocation strategy\nacross tasks and datasets, ensuring the effectiveness and generalization of the\ntraining process. Our experimental results demonstrate significant improvements\nin different graph tasks, showcasing the potential of our MuseGraph in\nenhancing the accuracy of graph-oriented downstream tasks while keeping the\ngeneration powers of LLMs.",
      "tldr_zh": "该研究提出MuseGraph框架，通过图导向指令微调(Large Language Models, LLMs)来实现通用图挖掘，旨在解决传统Graph Neural Networks (GNNs)需针对不同任务和数据集重新训练的局限性。框架包括自适应输入生成机制，以创建紧凑的图描述；多样指令生成机制，从LLMs（如GPT-4）提炼Chain-of-Thought推理能力，生成任务特定指令包；以及图感知指令微调策略，通过动态分配指令包提升训练的泛化和有效性。实验结果显示，MuseGraph在各种图任务上显著提高了下游任务的准确性，同时保留了LLMs的生成能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.04780v2",
      "published_date": "2024-03-02 09:27:32 UTC",
      "updated_date": "2024-03-13 15:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:56:56.456914"
    },
    {
      "arxiv_id": "2403.01139v4",
      "title": "ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies",
      "title_zh": "翻译失败",
      "authors": [
        "Oren Sultan",
        "Yonatan Bitton",
        "Ron Yosef",
        "Dafna Shahaf"
      ],
      "abstract": "Analogy-making is central to human cognition, allowing us to adapt to novel\nsituations -- an ability that current AI systems still lack. Most analogy\ndatasets today focus on simple analogies (e.g., word analogies); datasets\nincluding complex types of analogies are typically manually curated and very\nsmall. We believe that this holds back progress in computational analogy. In\nthis work, we design a data generation pipeline, ParallelPARC (Parallel\nParagraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to\ncreate complex, paragraph-based analogies, as well as distractors, both simple\nand challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset\nof analogies between scientific processes. We publish a gold-set, validated by\nhumans, and a silver-set, generated automatically. We test LLMs' and humans'\nanalogy recognition in binary and multiple-choice settings, and found that\nhumans outperform the best models (~13% gap) after a light supervision. We\ndemonstrate that our silver-set is useful for training models. Lastly, we show\nchallenging distractors confuse LLMs, but not humans. We hope our pipeline will\nencourage research in this emerging field.",
      "tldr_zh": "该论文提出ParallelPARC，一种可扩展的数据生成管道，利用Large Language Models (LLMs)来创建复杂的基于段落的自然语言类比，以及简单和具有挑战性的干扰项，以克服现有类比数据集规模小和手动制作的局限性。研究者开发了ProPara-Logy数据集，专注于科学过程之间的类比，包括人类验证的金标准和自动生成的银标准。实验结果显示，人类在二元和多选类比识别任务中优于LLMs（约13%差距），银标准数据集可用于训练模型，但挑战性干扰项易迷惑LLMs，而非人类，从而鼓励计算类比领域的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2403.01139v4",
      "published_date": "2024-03-02 08:53:40 UTC",
      "updated_date": "2024-05-14 16:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:57:10.199261"
    },
    {
      "arxiv_id": "2403.01136v1",
      "title": "LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Juntao Zhao",
        "Borui Wan",
        "Yanghua Peng",
        "Haibin Lin",
        "Chuan Wu"
      ],
      "abstract": "Recent breakthroughs in Large-scale language models (LLMs) have demonstrated\nimpressive performance on various tasks. The immense sizes of LLMs have led to\nvery high resource demand and cost for running the models. Though the models\nare largely served using uniform high-caliber GPUs nowadays, utilizing a\nheterogeneous cluster with a mix of available high- and low-capacity GPUs can\npotentially substantially reduce the serving cost. There is a lack of designs\nto support efficient LLM serving using a heterogeneous cluster, while the\ncurrent solutions focus on model partition and uniform compression among\nhomogeneous devices. This paper proposes LLM-PQ, a system that advocates\nadaptive model quantization and phase-aware partition to improve LLM serving\nefficiency on heterogeneous GPU clusters. We carefully decide on\nmixed-precision model quantization together with phase-aware model partition\nand micro-batch sizing in distributed LLM serving with an efficient algorithm,\nto greatly enhance inference throughput while fulfilling user-specified model\nquality targets. Extensive experiments on production inference workloads in 11\ndifferent clusters demonstrate that LLM-PQ achieves up to 2.88x (2.26x on\naverage) throughput improvement in inference, showing great advantages over\nstate-of-the-art works.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的资源需求高问题，提出LLM-PQ系统，利用异构GPU集群通过自适应量化(adaptive quantization)和阶段感知分区(phase-aware partition)来提升服务效率。该系统结合高效算法优化混合精度量化、模型分区和微批大小，以最大化推理吞吐量，同时满足用户指定的模型质量目标。实验结果显示，在11个生产集群上，LLM-PQ实现了高达2.88倍（平均2.26倍）的吞吐量提升，显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01136v1",
      "published_date": "2024-03-02 08:40:07 UTC",
      "updated_date": "2024-03-02 08:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:57:21.631994"
    },
    {
      "arxiv_id": "2403.01131v2",
      "title": "LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyuan Ma",
        "Hongshu Guo",
        "Jiacheng Chen",
        "Guojun Peng",
        "Zhiguang Cao",
        "Yining Ma",
        "Yue-Jiao Gong"
      ],
      "abstract": "Recent research explores optimization using large language models (LLMs) by\neither iteratively seeking next-step solutions from LLMs or directly prompting\nLLMs for an optimizer. However, these approaches exhibit inherent limitations,\nincluding low operational efficiency, high sensitivity to prompt design, and a\nlack of domain-specific knowledge. We introduce LLaMoCo, the first\ninstruction-tuning framework designed to adapt LLMs for solving optimization\nproblems in a code-to-code manner. Specifically, we establish a comprehensive\ninstruction set containing well-described problem prompts and effective\noptimization codes. We then develop a novel two-phase learning strategy that\nincorporates a contrastive learning-based warm-up procedure before the\ninstruction-tuning phase to enhance the convergence behavior during model\nfine-tuning. The experiment results demonstrate that a CodeGen (350M) model\nfine-tuned by our LLaMoCo achieves superior optimization performance compared\nto GPT-4 Turbo and the other competitors across both synthetic and realistic\nproblem sets. The fine-tuned model and the usage instructions are available at\nhttps://anonymous.4open.science/r/LLaMoCo-722A.",
      "tldr_zh": "本研究提出LLaMoCo框架，这是首个针对优化问题的指令调整方法，用于适应大型语言模型(LLMs)以代码到代码方式生成优化代码。框架包括建立一个全面的指令集（包含问题提示和优化代码），并采用新型的两阶段学习策略：先通过基于对比学习的预热阶段提升模型收敛性，然后进行指令调整。实验结果表明，微调后的CodeGen (350M)模型在合成和真实优化问题集上，性能优于GPT-4 Turbo及其他竞争者。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE",
        "cs.SE"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01131v2",
      "published_date": "2024-03-02 08:21:59 UTC",
      "updated_date": "2024-03-05 11:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:57:32.295939"
    },
    {
      "arxiv_id": "2403.01121v4",
      "title": "OpenGraph: Towards Open Graph Foundation Models",
      "title_zh": "OpenGraph: 迈向开放图谱基础模型",
      "authors": [
        "Lianghao Xia",
        "Ben Kao",
        "Chao Huang"
      ],
      "abstract": "Graph learning has become essential in various domains, including\nrecommendation systems and social network analysis. Graph Neural Networks\n(GNNs) have emerged as promising techniques for encoding structural information\nand improving performance in tasks like link prediction and node\nclassification. However, a key challenge remains: the difficulty of\ngeneralizing to unseen graph data with different properties. In this work, we\npropose a novel graph foundation model, called OpenGraph, to address this\nchallenge. Our approach tackles several technical obstacles. Firstly, we\nenhance data augmentation using a large language model (LLM) to overcome data\nscarcity in real-world scenarios. Secondly, we introduce a unified graph\ntokenizer that enables the model to generalize effectively to diverse graph\ndata, even when encountering unseen properties during training. Thirdly, our\ndeveloped scalable graph transformer captures node-wise dependencies within the\nglobal topological context. Extensive experiments validate the effectiveness of\nour framework. By adapting OpenGraph to new graph characteristics and\ncomprehending diverse graphs, our approach achieves remarkable zero-shot graph\nlearning performance across various settings. We release the model\nimplementation at https://github.com/HKUDS/OpenGraph.",
      "tldr_zh": "这篇论文提出 OpenGraph，一种新型图基础模型，旨在解决图神经网络(GNNs)在泛化到不同属性图数据时的挑战。核心方法包括使用大型语言模型(LLM)增强数据扩充、引入统一的图标记器以处理未见属性，以及开发可扩展的图变换器来捕捉节点依赖和全局拓扑上下文。实验验证显示，OpenGraph 在各种场景下实现了显著的零样本图学习性能，并开源了模型实现（https://github.com/HKUDS/OpenGraph）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by EMNLP'2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01121v4",
      "published_date": "2024-03-02 08:05:03 UTC",
      "updated_date": "2024-10-09 12:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:57:43.732601"
    },
    {
      "arxiv_id": "2403.01118v1",
      "title": "Adversarial Testing for Visual Grounding via Image-Aware Property Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Chang",
        "Mingyang Li",
        "Junjie Wang",
        "Cheng Li",
        "Boyu Wu",
        "Fanjiang Xu",
        "Qing Wang"
      ],
      "abstract": "Due to the advantages of fusing information from various modalities,\nmultimodal learning is gaining increasing attention. Being a fundamental task\nof multimodal learning, Visual Grounding (VG), aims to locate objects in images\nthrough natural language expressions. Ensuring the quality of VG models\npresents significant challenges due to the complex nature of the task. In the\nblack box scenario, existing adversarial testing techniques often fail to fully\nexploit the potential of both modalities of information. They typically apply\nperturbations based solely on either the image or text information,\ndisregarding the crucial correlation between the two modalities, which would\nlead to failures in test oracles or an inability to effectively challenge VG\nmodels. To this end, we propose PEELING, a text perturbation approach via\nimage-aware property reduction for adversarial testing of the VG model. The\ncore idea is to reduce the property-related information in the original\nexpression meanwhile ensuring the reduced expression can still uniquely\ndescribe the original object in the image. To achieve this, PEELING first\nconducts the object and properties extraction and recombination to generate\ncandidate property reduction expressions. It then selects the satisfied\nexpressions that accurately describe the original object while ensuring no\nother objects in the image fulfill the expression, through querying the image\nwith a visual understanding technique. We evaluate PEELING on the\nstate-of-the-art VG model, i.e. OFA-VG, involving three commonly used datasets.\nResults show that the adversarial tests generated by PEELING achieves 21.4% in\nMultiModal Impact score (MMI), and outperforms state-of-the-art baselines for\nimages and texts by 8.2%--15.1%.",
      "tldr_zh": "本研究针对 Visual Grounding (VG) 任务的对抗测试问题，提出了一种基于图像感知的属性减少方法PEELING，以解决现有技术忽略图像和文本模态相关性的不足。PEELING通过提取并重组对象的属性信息，生成候选文本表达式，确保这些表达式能唯一描述目标对象，同时避免其他对象匹配；随后利用视觉理解技术筛选有效表达式。实验结果显示，在OFA-VG模型上测试三个常用数据集时，PEELING生成的对抗测试在MultiModal Impact (MMI)分数上达到21.4%，比现有图像或文本基线方法高出8.2%–15.1%。这为提升VG模型的鲁棒性提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.01118v1",
      "published_date": "2024-03-02 08:03:42 UTC",
      "updated_date": "2024-03-02 08:03:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:57:55.994449"
    },
    {
      "arxiv_id": "2403.01106v2",
      "title": "Distilling Text Style Transfer With Self-Explanation From LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Chiyu Zhang",
        "Honglong Cai",
        "Yuezhang",
        "Li",
        "Yuexin Wu",
        "Le Hou",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "Text Style Transfer (TST) seeks to alter the style of text while retaining\nits core content. Given the constraints of limited parallel datasets for TST,\nwe propose CoTeX, a framework that leverages large language models (LLMs)\nalongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills\nthe complex rewriting and reasoning capabilities of LLMs into more streamlined\nmodels capable of working with both non-parallel and parallel data. Through\nexperimentation across four TST datasets, CoTeX is shown to surpass traditional\nsupervised fine-tuning and knowledge distillation methods, particularly in\nlow-resource settings. We conduct a comprehensive evaluation, comparing CoTeX\nagainst current unsupervised, supervised, in-context learning (ICL) techniques,\nand instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering\ntransparent explanations for its style transfer process.",
      "tldr_zh": "该研究提出CoTeX框架，利用大型语言模型(LLMs)和链式思维提示(chain-of-thought, CoT)来实现Text Style Transfer (TST)，即改变文本风格的同时保留核心内容，以应对平行数据集有限的挑战。CoTeX通过知识蒸馏将LLMs的复杂重写和推理能力转移到更简化的模型中，支持非平行和平行数据，并在低资源环境中表现出色。实验结果显示，在四个TST数据集上，CoTeX超越了传统的监督微调和知识蒸馏方法，以及无监督、In-Context Learning (ICL)和指令微调的LLMs。此外，CoTeX提供透明的风格转移解释，提升了模型的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL Student Research Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01106v2",
      "published_date": "2024-03-02 06:38:15 UTC",
      "updated_date": "2024-05-04 17:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:58:08.610715"
    },
    {
      "arxiv_id": "2403.01101v2",
      "title": "Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models",
      "title_zh": "特征对齐：在预训练模型",
      "authors": [
        "Ziting Wen",
        "Oscar Pizarro",
        "Stefan Williams"
      ],
      "abstract": "Fine-tuning the pre-trained model with active learning holds promise for\nreducing annotation costs. However, this combination introduces significant\ncomputational costs, particularly with the growing scale of pre-trained models.\nRecent research has proposed proxy-based active learning, which pre-computes\nfeatures to reduce computational costs. Yet, this approach often incurs a\nsignificant loss in active learning performance, sometimes outweighing the\ncomputational cost savings. This paper demonstrates that not all sample\nselection differences result in performance degradation. Furthermore, we show\nthat suitable training methods can mitigate the decline of active learning\nperformance caused by certain selection discrepancies. Building upon detailed\nanalysis, we propose a novel method, aligned selection via proxy, which\nimproves proxy-based active learning performance by updating pre-computed\nfeatures and selecting a proper training method. Extensive experiments validate\nthat our method improves the total cost of efficient active learning while\nmaintaining computational efficiency. The code is available at\n\\url{https://github.com/ZiTingW/asvp}.",
      "tldr_zh": "这篇论文重新审视了在预训练模型（pre-trained models）背景下使用主动学习（active learning）的效率问题，指出传统方法虽能减少标注成本，但会带来高计算开销。作者分析了代理-based active learning 的性能下降原因，发现并非所有样本选择差异都会导致显著损失，并提出新方法 aligned selection via proxy，通过更新预计算特征和选择合适的训练方法来缓解性能下降。实验验证显示，该方法在维持计算效率的同时，显著降低了总体成本，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Transactions on Machine Learning Research (TMLR, 2024)\n  https://openreview.net/forum?id=PNcgJMJcdl",
      "pdf_url": "http://arxiv.org/pdf/2403.01101v2",
      "published_date": "2024-03-02 06:01:34 UTC",
      "updated_date": "2024-11-16 06:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:58:20.099737"
    },
    {
      "arxiv_id": "2403.01091v1",
      "title": "COOL: A Conjoint Perspective on Spatio-Temporal Graph Neural Network for Traffic Forecasting",
      "title_zh": "COOL: 一种针对时空图",
      "authors": [
        "Wei Ju",
        "Yusheng Zhao",
        "Yifang Qin",
        "Siyu Yi",
        "Jingyang Yuan",
        "Zhiping Xiao",
        "Xiao Luo",
        "Xiting Yan",
        "Ming Zhang"
      ],
      "abstract": "This paper investigates traffic forecasting, which attempts to forecast the\nfuture state of traffic based on historical situations. This problem has\nreceived ever-increasing attention in various scenarios and facilitated the\ndevelopment of numerous downstream applications such as urban planning and\ntransportation management. However, the efficacy of existing methods remains\nsub-optimal due to their tendency to model temporal and spatial relationships\nindependently, thereby inadequately accounting for complex high-order\ninteractions of both worlds. Moreover, the diversity of transitional patterns\nin traffic forecasting makes them challenging to capture for existing\napproaches, warranting a deeper exploration of their diversity. Toward this\nend, this paper proposes Conjoint Spatio-Temporal graph neural network\n(abbreviated as COOL), which models heterogeneous graphs from prior and\nposterior information to conjointly capture high-order spatio-temporal\nrelationships. On the one hand, heterogeneous graphs connecting sequential\nobservation are constructed to extract composite spatio-temporal relationships\nvia prior message passing. On the other hand, we model dynamic relationships\nusing constructed affinity and penalty graphs, which guide posterior message\npassing to incorporate complementary semantic information into node\nrepresentations. Moreover, to capture diverse transitional properties to\nenhance traffic forecasting, we propose a conjoint self-attention decoder that\nmodels diverse temporal patterns from both multi-rank and multi-scale views.\nExperimental results on four popular benchmark datasets demonstrate that our\nproposed COOL provides state-of-the-art performance compared with the\ncompetitive baselines.",
      "tldr_zh": "本论文探讨了交通预测问题，即基于历史数据预测未来交通状态，但现有方法因独立建模时空关系而忽略了复杂的高阶交互和多样过渡模式。作者提出 COOL 模型，一种联合时空图神经网络，通过构建异构图进行先验消息 passing，并利用亲和力和惩罚图实现后验消息 passing，以捕获复合时空关系。此外，COOL 引入联合自注意力 decoder，从多秩和多尺度视角处理多样时间模式。实验结果显示，在四个基准数据集上，COOL 比竞争基线方法取得了最先进的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Information Fusion 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01091v1",
      "published_date": "2024-03-02 04:30:09 UTC",
      "updated_date": "2024-03-02 04:30:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:58:33.164103"
    },
    {
      "arxiv_id": "2403.01079v1",
      "title": "Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework",
      "title_zh": "向 MLP 教授更多图信息：一个三阶段多任务知识蒸馏框架",
      "authors": [
        "Junxian Li",
        "Bin Shi",
        "Erfei Cui",
        "Hua Wei",
        "Qinghua Zheng"
      ],
      "abstract": "We study the challenging problem for inference tasks on large-scale graph\ndatasets of Graph Neural Networks: huge time and memory consumption, and try to\novercome it by reducing reliance on graph structure. Even though distilling\ngraph knowledge to student MLP is an excellent idea, it faces two major\nproblems of positional information loss and low generalization. To solve the\nproblems, we propose a new three-stage multitask distillation framework. In\ndetail, we use Positional Encoding to capture positional information. Also, we\nintroduce Neural Heat Kernels responsible for graph data processing in GNN and\nutilize hidden layer outputs matching for better performance of student MLP's\nhidden layers. To the best of our knowledge, it is the first work to include\nhidden layer distillation for student MLP on graphs and to combine graph\nPositional Encoding with MLP. We test its performance and robustness with\nseveral settings and draw the conclusion that our work can outperform well with\ngood stability.",
      "tldr_zh": "该研究针对图神经网络（Graph Neural Networks, GNN）在大型图数据集上推理任务的巨大时间和内存消耗问题，提出了一种三阶段多任务知识蒸馏框架，以减少对图结构的依赖并将知识蒸馏到学生MLP。框架通过引入Positional Encoding捕获位置信息、利用Neural Heat Kernels处理图数据，以及匹配隐藏层输出来提升学生MLP的性能和泛化能力。这是首次将隐藏层蒸馏应用于图上的学生MLP，并结合图Positional Encoding与MLP。实验结果表明，该框架在多种设置下表现出色，具有良好的稳定性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, with Appendix",
      "pdf_url": "http://arxiv.org/pdf/2403.01079v1",
      "published_date": "2024-03-02 03:29:11 UTC",
      "updated_date": "2024-03-02 03:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:58:44.914246"
    },
    {
      "arxiv_id": "2403.01078v1",
      "title": "$Γ$-VAE: Curvature regularized variational autoencoders for uncovering emergent low dimensional geometric structure in high dimensional data",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Z. Kim",
        "Nicolas Perrin-Gilbert",
        "Erkan Narmanli",
        "Paul Klein",
        "Christopher R. Myers",
        "Itai Cohen",
        "Joshua J. Waterfall",
        "James P. Sethna"
      ],
      "abstract": "Natural systems with emergent behaviors often organize along low-dimensional\nsubsets of high-dimensional spaces. For example, despite the tens of thousands\nof genes in the human genome, the principled study of genomics is fruitful\nbecause biological processes rely on coordinated organization that results in\nlower dimensional phenotypes. To uncover this organization, many nonlinear\ndimensionality reduction techniques have successfully embedded high-dimensional\ndata into low-dimensional spaces by preserving local similarities between data\npoints. However, the nonlinearities in these methods allow for too much\ncurvature to preserve general trends across multiple non-neighboring data\nclusters, thereby limiting their interpretability and generalizability to\nout-of-distribution data. Here, we address both of these limitations by\nregularizing the curvature of manifolds generated by variational autoencoders,\na process we coin ``$\\Gamma$-VAE''. We demonstrate its utility using two\nexample data sets: bulk RNA-seq from the The Cancer Genome Atlas (TCGA) and the\nGenotype Tissue Expression (GTEx); and single cell RNA-seq from a lineage\ntracing experiment in hematopoietic stem cell differentiation. We find that the\nresulting regularized manifolds identify mesoscale structure associated with\ndifferent cancer cell types, and accurately re-embed tissues from completely\nunseen, out-of distribution cancers as if they were originally trained on them.\nFinally, we show that preserving long-range relationships to differentiated\ncells separates undifferentiated cells -- which have not yet specialized --\naccording to their eventual fate. Broadly, we anticipate that regularizing the\ncurvature of generative models will enable more consistent, predictive, and\ngeneralizable models in any high-dimensional system with emergent\nlow-dimensional behavior.",
      "tldr_zh": "本研究提出 $Γ$-VAE，一种基于曲率正则化的变分自编码器（variational autoencoders），旨在揭示高维数据中出现的低维几何结构，同时解决传统非线性降维方法在曲率过度导致的解读性和泛化性问题。通过在数据集如 The Cancer Genome Atlas (TCGA) 和 Genotype Tissue Expression (GTEx) 的 RNA-seq 数据上测试，$Γ$-VAE 成功识别了癌症细胞类型的中尺度结构，并能准确嵌入未见分布数据。结果显示，该方法增强了模型的预测性和一致性，尤其在保留长程关系方面，能根据最终命运区分未分化细胞，这为处理高维系统中的低维行为提供了更可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.bio-ph",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.01078v1",
      "published_date": "2024-03-02 03:26:09 UTC",
      "updated_date": "2024-03-02 03:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:58:57.657917"
    },
    {
      "arxiv_id": "2403.12981v1",
      "title": "Beyond Inference: Performance Analysis of DNN Server Overheads for Computer Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed F. AbouElhamayed",
        "Susanne Balle",
        "Deshanand Singh",
        "Mohamed S. Abdelfattah"
      ],
      "abstract": "Deep neural network (DNN) inference has become an important part of many\ndata-center workloads. This has prompted focused efforts to design ever-faster\ndeep learning accelerators such as GPUs and TPUs. However, an end-to-end\nDNN-based vision application contains more than just DNN inference, including\ninput decompression, resizing, sampling, normalization, and data transfer. In\nthis paper, we perform a thorough evaluation of computer vision inference\nrequests performed on a throughput-optimized serving system. We quantify the\nperformance impact of server overheads such as data movement, preprocessing,\nand message brokers between two DNNs producing outputs at different rates. Our\nempirical analysis encompasses many computer vision tasks including image\nclassification, segmentation, detection, depth-estimation, and more complex\nprocessing pipelines with multiple DNNs. Our results consistently demonstrate\nthat end-to-end application performance can easily be dominated by data\nprocessing and data movement functions (up to 56% of end-to-end latency in a\nmedium-sized image, and $\\sim$ 80% impact on system throughput in a large\nimage), even though these functions have been conventionally overlooked in deep\nlearning system design. Our work identifies important performance bottlenecks\nin different application scenarios, achieves 2.25$\\times$ better throughput\ncompared to prior work, and paves the way for more holistic deep learning\nsystem design.",
      "tldr_zh": "本论文分析了DNN（Deep Neural Network）在计算机视觉应用中的服务器开销性能，超越了传统的推理焦点，涵盖了输入解压缩、调整大小、采样、归一化和数据传输等环节。研究通过对图像分类、分割、检测、深度估计等任务的实证评估，发现数据处理和数据移动函数可能主导端到端性能（如中等图像延迟占56%，大图像吞吐量影响达80%）。最终，论文识别了关键瓶颈，实现了比先前工作高2.25倍的系统吞吐量，并为更全面的深度学习系统设计提供了重要指导。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "6 pages, 11 figures, DAC 2024: 61st IEEE/ACM Design Automation\n  Conference. (DAC'24)",
      "pdf_url": "http://arxiv.org/pdf/2403.12981v1",
      "published_date": "2024-03-02 02:35:08 UTC",
      "updated_date": "2024-03-02 02:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:59:10.870885"
    },
    {
      "arxiv_id": "2403.01071v2",
      "title": "GraphRCG: Self-Conditioned Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Song Wang",
        "Zhen Tan",
        "Xinyu Zhao",
        "Tianlong Chen",
        "Huan Liu",
        "Jundong Li"
      ],
      "abstract": "Graph generation generally aims to create new graphs that closely align with\na specific graph distribution. Existing works often implicitly capture this\ndistribution through the optimization of generators, potentially overlooking\nthe intricacies of the distribution itself. Furthermore, these approaches\ngenerally neglect the insights offered by the learned distribution for graph\ngeneration. In contrast, in this work, we propose a novel self-conditioned\ngraph generation framework designed to explicitly model graph distributions and\nemploy these distributions to guide the generation process. We first perform\nself-conditioned modeling to capture the graph distributions by transforming\neach graph sample into a low-dimensional representation and optimizing a\nrepresentation generator to create new representations reflective of the\nlearned distribution. Subsequently, we leverage these bootstrapped\nrepresentations as self-conditioned guidance for the generation process,\nthereby facilitating the generation of graphs that more accurately reflect the\nlearned distributions. We conduct extensive experiments on generic and\nmolecular graph datasets across various fields. Our framework demonstrates\nsuperior performance over existing state-of-the-art graph generation methods in\nterms of graph quality and fidelity to training data.",
      "tldr_zh": "该论文提出GraphRCG，一种自条件图生成框架，旨在显式建模图分布并利用这些分布指导生成过程，以生成更符合特定分布的新图。框架首先通过自条件建模将图样本转换为低维表示，并优化一个表示生成器来捕获和生成反映该分布的表示。随后，使用这些表示作为引导，生成高质量图。实验结果显示，在通用和分子图数据集上，GraphRCG在图质量和对训练数据的忠实度方面优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01071v2",
      "published_date": "2024-03-02 02:28:20 UTC",
      "updated_date": "2024-07-18 06:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:59:20.301980"
    },
    {
      "arxiv_id": "2403.01055v1",
      "title": "Towards Full Authorship with AI: Supporting Revision with AI-Generated Views",
      "title_zh": "翻译失败",
      "authors": [
        "Jiho Kim",
        "Ray C. Flanagan",
        "Noelle E. Haviland",
        "ZeAi Sun",
        "Souad N. Yakubu",
        "Edom A. Maru",
        "Kenneth C. Arnold"
      ],
      "abstract": "Large language models (LLMs) are shaping a new user interface (UI) paradigm\nin writing tools by enabling users to generate text through prompts. This\nparadigm shifts some creative control from the user to the system, thereby\ndiminishing the user's authorship and autonomy in the writing process. To\nrestore autonomy, we introduce Textfocals, a UI prototype designed to\ninvestigate a human-centered approach that emphasizes the user's role in\nwriting. Textfocals supports the writing process by providing LLM-generated\nsummaries, questions, and advice (i.e., LLM views) in a sidebar of a text\neditor, encouraging reflection and self-driven revision in writing without\ndirect text generation. Textfocals' UI affordances, including contextually\nadaptive views and scaffolding for prompt selection and customization, offer a\nnovel way to interact with LLMs where users maintain full authorship of their\nwriting. A formative user study with Textfocals showed promising evidence that\nthis approach might help users develop underdeveloped ideas, cater to the\nrhetorical audience, and clarify their writing. However, the study also showed\ninteraction design challenges related to document navigation and scoping,\nprompt engineering, and context management. Our work highlights the breadth of\nthe design space of writing support interfaces powered by generative AI that\nmaintain authorship integrity.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)如何通过提示生成文本改变了写作工具的用户界面(UI)，从而降低了用户的作者身份和自主性。为恢复用户控制，该研究引入了Textfocals，一个UI原型，通过侧边栏提供LLM生成的摘要、问题和建议（LLM views），鼓励用户进行反思和自我驱动的修订，而非直接文本生成。Textfocals的设计包括上下文自适应视图和提示选择/自定义支架，确保用户保持完整的作者身份。用户研究显示，这种方法有助于发展想法、针对修辞受众和澄清写作，但也暴露了交互设计挑战，如文档导航、提示工程和上下文管理。整体工作扩展了保持作者完整性的生成AI写作支持接口的设计空间。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.2; I.7.1; I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation\n  with Generative Models (HAI-GEN) at ACM IUI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01055v1",
      "published_date": "2024-03-02 01:11:35 UTC",
      "updated_date": "2024-03-02 01:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:59:33.544973"
    },
    {
      "arxiv_id": "2403.01053v2",
      "title": "Seeing Unseen: Discover Novel Biomedical Concepts via Geometry-Constrained Probabilistic Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jianan Fan",
        "Dongnan Liu",
        "Hang Chang",
        "Heng Huang",
        "Mei Chen",
        "Weidong Cai"
      ],
      "abstract": "Machine learning holds tremendous promise for transforming the fundamental\npractice of scientific discovery by virtue of its data-driven nature. With the\never-increasing stream of research data collection, it would be appealing to\nautonomously explore patterns and insights from observational data for\ndiscovering novel classes of phenotypes and concepts. However, in the\nbiomedical domain, there are several challenges inherently presented in the\ncumulated data which hamper the progress of novel class discovery. The\nnon-i.i.d. data distribution accompanied by the severe imbalance among\ndifferent groups of classes essentially leads to ambiguous and biased semantic\nrepresentations. In this work, we present a geometry-constrained probabilistic\nmodeling treatment to resolve the identified issues. First, we propose to\nparameterize the approximated posterior of instance embedding as a marginal von\nMisesFisher distribution to account for the interference of distributional\nlatent bias. Then, we incorporate a suite of critical geometric properties to\nimpose proper constraints on the layout of constructed embedding space, which\nin turn minimizes the uncontrollable risk for unknown class learning and\nstructuring. Furthermore, a spectral graph-theoretic method is devised to\nestimate the number of potential novel classes. It inherits two intriguing\nmerits compared to existent approaches, namely high computational efficiency\nand flexibility for taxonomy-adaptive estimation. Extensive experiments across\nvarious biomedical scenarios substantiate the effectiveness and general\napplicability of our method.",
      "tldr_zh": "本文提出一种几何约束的概率建模方法，用于在生物医学领域发现新型概念，解决非 i.i.d. 数据分布和类别不平衡导致的语义表示偏差问题。主要方法包括将实例嵌入的后验参数化为边缘 von Mises-Fisher 分布，并通过几何属性约束优化嵌入空间布局，以降低未知类学习的风险。此外，作者开发了一种谱图理论方法来高效估计潜在新类别的数量，具有高计算效率和适应性。实验在多种生物医学场景中验证了该方法的有效性和通用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01053v2",
      "published_date": "2024-03-02 00:56:05 UTC",
      "updated_date": "2024-03-05 07:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:59:45.160196"
    },
    {
      "arxiv_id": "2403.01046v4",
      "title": "A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features",
      "title_zh": "翻译失败",
      "authors": [
        "Emi Zeger",
        "Yifei Wang",
        "Aaron Mishkin",
        "Tolga Ergen",
        "Emmanuel Candès",
        "Mert Pilanci"
      ],
      "abstract": "We prove that training neural networks on 1-D data is equivalent to solving\nconvex Lasso problems with discrete, explicitly defined dictionary matrices. We\nconsider neural networks with piecewise linear activations and depths ranging\nfrom 2 to an arbitrary but finite number of layers. We first show that\ntwo-layer networks with piecewise linear activations are equivalent to Lasso\nmodels using a discrete dictionary of ramp functions, with breakpoints\ncorresponding to the training data points. In certain general architectures\nwith absolute value or ReLU activations, a third layer surprisingly creates\nfeatures that reflect the training data about themselves. Additional layers\nprogressively generate reflections of these reflections. The Lasso\nrepresentation provides valuable insights into the analysis of globally optimal\nnetworks, elucidating their solution landscapes and enabling closed-form\nsolutions in certain special cases. Numerical results show that reflections\nalso occur when optimizing standard deep networks using standard non-convex\noptimizers. Additionally, we demonstrate our theory with autoregressive time\nseries models.",
      "tldr_zh": "本文证明了在1-D数据上训练的分段线性激活神经网络（包括ReLU）等价于凸Lasso模型，使用离散字典矩阵，其中二层网络对应ramp函数字典，断点基于训练数据点。研究进一步发现，多层网络会生成反射特征，例如第三层将训练数据反射到自身，额外层则创建这些反射的迭代版本，提供对全局最优网络解决方案景观的洞见。数值实验显示，这种反射现象也出现在使用标准非凸优化器的深度网络中，并通过自回归时间序列模型进行了验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01046v4",
      "published_date": "2024-03-02 00:33:45 UTC",
      "updated_date": "2024-07-24 00:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T11:59:57.024219"
    },
    {
      "arxiv_id": "2403.01038v1",
      "title": "AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks",
      "title_zh": "AutoAttacker: 一种大语言",
      "authors": [
        "Jiacen Xu",
        "Jack W. Stokes",
        "Geoff McDonald",
        "Xuesong Bai",
        "David Marshall",
        "Siyue Wang",
        "Adith Swaminathan",
        "Zhou Li"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive results on natural\nlanguage tasks, and security researchers are beginning to employ them in both\noffensive and defensive systems. In cyber-security, there have been multiple\nresearch efforts that utilize LLMs focusing on the pre-breach stage of attacks\nlike phishing and malware generation. However, so far there lacks a\ncomprehensive study regarding whether LLM-based systems can be leveraged to\nsimulate the post-breach stage of attacks that are typically human-operated, or\n\"hands-on-keyboard\" attacks, under various attack techniques and environments.\n  As LLMs inevitably advance, they may be able to automate both the pre- and\npost-breach attack stages. This shift may transform organizational attacks from\nrare, expert-led events to frequent, automated operations requiring no\nexpertise and executed at automation speed and scale. This risks fundamentally\nchanging global computer security and correspondingly causing substantial\neconomic impacts, and a goal of this work is to better understand these risks\nnow so we can better prepare for these inevitable ever-more-capable LLMs on the\nhorizon. On the immediate impact side, this research serves three purposes.\nFirst, an automated LLM-based, post-breach exploitation framework can help\nanalysts quickly test and continually improve their organization's network\nsecurity posture against previously unseen attacks. Second, an LLM-based\npenetration test system can extend the effectiveness of red teams with a\nlimited number of human analysts. Finally, this research can help defensive\nsystems and teams learn to detect novel attack behaviors preemptively before\ntheir use in the wild....",
      "tldr_zh": "本研究提出 AutoAttacker 系统，这是一个由 Large Language Models (LLMs) 引导的框架，用于自动模拟网络攻击的后渗透阶段（post-breach stage），如“hands-on-keyboard”攻击，以覆盖多种攻击技术和环境。AutoAttacker 通过利用 LLMs 的能力，实现了对先前未见攻击的快速测试，帮助分析师提升组织网络安全态势，并扩展红队的有效性。研究结果强调，这种自动化可能导致攻击从专家主导转为频繁大规模操作，潜在风险巨大，因此该工作旨在预先检测新型攻击行为并加强防御准备。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01038v1",
      "published_date": "2024-03-02 00:10:45 UTC",
      "updated_date": "2024-03-02 00:10:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:00:08.138028"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 49,
  "processed_papers_count": 49,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T12:00:33.823806"
}