[
  {
    "arxiv_id": "2401.17505v4",
    "title": "Arrows of Time for Large Language Models",
    "authors": [
      "Vassilis Papadopoulos",
      "Jérémie Wenger",
      "Clément Hongler"
    ],
    "abstract": "We study the probabilistic modeling performed by Autoregressive Large\nLanguage Models (LLMs) through the angle of time directionality, addressing a\nquestion first raised in (Shannon, 1951). For large enough models, we\nempirically find a time asymmetry in their ability to learn natural language: a\ndifference in the average log-perplexity when trying to predict the next token\nversus when trying to predict the previous one. This difference is at the same\ntime subtle and very consistent across various modalities (language, model\nsize, training time, ...). Theoretically, this is surprising: from an\ninformation-theoretic point of view, there should be no such difference. We\nprovide a theoretical framework to explain how such an asymmetry can appear\nfrom sparsity and computational complexity considerations, and outline a number\nof perspectives opened by our results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Corrected typos in Table 2. Added links. 12 figures, 20 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.17505v4",
    "published_date": "2024-01-30 23:46:35 UTC",
    "updated_date": "2024-07-24 12:57:56 UTC"
  },
  {
    "arxiv_id": "2402.01763v3",
    "title": "When Large Language Models Meet Vector Databases: A Survey",
    "authors": [
      "Zhi Jing",
      "Yongye Su",
      "Yikun Han"
    ],
    "abstract": "This survey explores the synergistic potential of Large Language Models\n(LLMs) and Vector Databases (VecDBs), a burgeoning but rapidly evolving\nresearch area. With the proliferation of LLMs comes a host of challenges,\nincluding hallucinations, outdated knowledge, prohibitive commercial\napplication costs, and memory issues. VecDBs emerge as a compelling solution to\nthese issues by offering an efficient means to store, retrieve, and manage the\nhigh-dimensional vector representations intrinsic to LLM operations. Through\nthis nuanced review, we delineate the foundational principles of LLMs and\nVecDBs and critically analyze their integration's impact on enhancing LLM\nfunctionalities. This discourse extends into a discussion on the speculative\nfuture developments in this domain, aiming to catalyze further research into\noptimizing the confluence of LLMs and VecDBs for advanced data handling and\nknowledge extraction capabilities.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01763v3",
    "published_date": "2024-01-30 23:35:28 UTC",
    "updated_date": "2024-11-01 03:49:59 UTC"
  },
  {
    "arxiv_id": "2401.17500v3",
    "title": "LeTO: Learning Constrained Visuomotor Policy with Differentiable Trajectory Optimization",
    "authors": [
      "Zhengtong Xu",
      "Yu She"
    ],
    "abstract": "This paper introduces LeTO, a method for learning constrained visuomotor\npolicy with differentiable trajectory optimization. Our approach integrates a\ndifferentiable optimization layer into the neural network. By formulating the\noptimization layer as a trajectory optimization problem, we enable the model to\nend-to-end generate actions in a safe and constraint-controlled fashion without\nextra modules. Our method allows for the introduction of constraint information\nduring the training process, thereby balancing the training objectives of\nsatisfying constraints, smoothing the trajectories, and minimizing errors with\ndemonstrations. This ``gray box\" method marries optimization-based safety and\ninterpretability with powerful representational abilities of neural networks.\nWe quantitatively evaluate LeTO in simulation and in the real robot. The\nresults demonstrate that LeTO performs well in both simulated and real-world\ntasks. In addition, it is capable of generating trajectories that are less\nuncertain, higher quality, and smoother compared to existing imitation learning\nmethods. Therefore, it is shown that LeTO provides a practical example of how\nto achieve the integration of neural networks with trajectory optimization. We\nrelease our code at https://github.com/ZhengtongXu/LeTO.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17500v3",
    "published_date": "2024-01-30 23:18:35 UTC",
    "updated_date": "2024-10-23 18:04:54 UTC"
  },
  {
    "arxiv_id": "2401.17477v2",
    "title": "Detecting mental disorder on social media: a ChatGPT-augmented explainable approach",
    "authors": [
      "Loris Belcastro",
      "Riccardo Cantini",
      "Fabrizio Marozzo",
      "Domenico Talia",
      "Paolo Trunfio"
    ],
    "abstract": "In the digital era, the prevalence of depressive symptoms expressed on social\nmedia has raised serious concerns, necessitating advanced methodologies for\ntimely detection. This paper addresses the challenge of interpretable\ndepression detection by proposing a novel methodology that effectively combines\nLarge Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and\nconversational agents like ChatGPT. In our methodology, explanations are\nachieved by integrating BERTweet, a Twitter-specific variant of BERT, into a\nnovel self-explanatory model, namely BERT-XDD, capable of providing both\nclassification and explanations via masked attention. The interpretability is\nfurther enhanced using ChatGPT to transform technical explanations into\nhuman-readable commentaries. By introducing an effective and modular approach\nfor interpretable depression detection, our methodology can contribute to the\ndevelopment of socially responsible digital platforms, fostering early\nintervention and support for mental health challenges under the guidance of\nqualified healthcare professionals.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17477v2",
    "published_date": "2024-01-30 22:22:55 UTC",
    "updated_date": "2025-03-10 09:32:00 UTC"
  },
  {
    "arxiv_id": "2402.00076v1",
    "title": "Exploitation Strategies in Conditional Markov Chain Search: A case study on the three-index assignment problem",
    "authors": [
      "Sahil Patel",
      "Daniel Karapetyan"
    ],
    "abstract": "The Conditional Markov Chain Search (CMCS) is a framework for automated\ndesign of metaheuristics for discrete combinatorial optimisation problems.\nGiven a set of algorithmic components such as hill climbers and mutations, CMCS\ndecides in which order to apply those components. The decisions are dictated by\nthe CMCS configuration that can be learnt offline. CMCS does not have an\nacceptance criterion; any moves are accepted by the framework. As a result, it\nis particularly good in exploration but is not as good at exploitation. In this\nstudy, we explore several extensions of the framework to improve its\nexploitation abilities. To perform a computational study, we applied the\nframework to the three-index assignment problem. The results of our experiments\nshowed that a two-stage CMCS is indeed superior to a single-stage CMCS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.00076v1",
    "published_date": "2024-01-30 22:13:46 UTC",
    "updated_date": "2024-01-30 22:13:46 UTC"
  },
  {
    "arxiv_id": "2401.17461v1",
    "title": "Synthetic Dialogue Dataset Generation using LLM Agents",
    "authors": [
      "Yelaman Abdullin",
      "Diego Molla-Aliod",
      "Bahadorreza Ofoghi",
      "John Yearwood",
      "Qingyang Li"
    ],
    "abstract": "Linear programming (LP) problems are pervasive in real-life applications.\nHowever, despite their apparent simplicity, an untrained user may find it\ndifficult to determine the linear model of their specific problem. We envisage\nthe creation of a goal-oriented conversational agent that will engage in\nconversation with the user to elicit all information required so that a\nsubsequent agent can generate the linear model. In this paper, we present an\napproach for the generation of sample dialogues that can be used to develop and\ntrain such a conversational agent. Using prompt engineering, we develop two\nagents that \"talk\" to each other, one acting as the conversational agent, and\nthe other acting as the user. Using a set of text descriptions of linear\nproblems from NL4Opt available to the user only, the agent and the user engage\nin conversation until the agent has retrieved all key information from the\noriginal problem description. We also propose an extrinsic evaluation of the\ndialogues by assessing how well the summaries generated by the dialogues match\nthe original problem descriptions. We conduct human and automatic evaluations,\nincluding an evaluation approach that uses GPT-4 to mimic the human evaluation\nmetrics. The evaluation results show an overall good quality of the dialogues,\nthough research is still needed to improve the quality of the GPT-4 evaluation\nmetrics. The resulting dialogues, including the human annotations of a subset,\nare available to the research community. The conversational agent used for the\ngeneration of the dialogues can be used as a baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "GEM Workshop @ EMNLP 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.17461v1",
    "published_date": "2024-01-30 21:49:30 UTC",
    "updated_date": "2024-01-30 21:49:30 UTC"
  },
  {
    "arxiv_id": "2401.17459v1",
    "title": "A Preliminary Study on Using Large Language Models in Software Pentesting",
    "authors": [
      "Kumar Shashwat",
      "Francis Hahn",
      "Xinming Ou",
      "Dmitry Goldgof",
      "Lawrence Hall",
      "Jay Ligatti",
      "S. Raj Rajgopalan",
      "Armin Ziaie Tabari"
    ],
    "abstract": "Large language models (LLM) are perceived to offer promising potentials for\nautomating security tasks, such as those found in security operation centers\n(SOCs). As a first step towards evaluating this perceived potential, we\ninvestigate the use of LLMs in software pentesting, where the main task is to\nautomatically identify software security vulnerabilities in source code. We\nhypothesize that an LLM-based AI agent can be improved over time for a specific\nsecurity task as human operators interact with it. Such improvement can be\nmade, as a first step, by engineering prompts fed to the LLM based on the\nresponses produced, to include relevant contexts and structures so that the\nmodel provides more accurate results. Such engineering efforts become\nsustainable if the prompts that are engineered to produce better results on\ncurrent tasks, also produce better results on future unknown tasks. To examine\nthis hypothesis, we utilize the OWASP Benchmark Project 1.2 which contains\n2,740 hand-crafted source code test cases containing various types of\nvulnerabilities. We divide the test cases into training and testing data, where\nwe engineer the prompts based on the training data (only), and evaluate the\nfinal system on the testing data. We compare the AI agent's performance on the\ntesting data against the performance of the agent without the prompt\nengineering. We also compare the AI agent's results against those from\nSonarQube, a widely used static code analyzer for security testing. We built\nand tested multiple versions of the AI agent using different off-the-shelf LLMs\n-- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (with\nboth chat completion and assistant APIs). The results show that using LLMs is a\nviable approach to build an AI agent for software pentesting that can improve\nthrough repeated use and prompt engineering.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17459v1",
    "published_date": "2024-01-30 21:42:59 UTC",
    "updated_date": "2024-01-30 21:42:59 UTC"
  },
  {
    "arxiv_id": "2401.17455v1",
    "title": "Multiscale Parallel Tempering for Fast Sampling on Redistricting Plans",
    "authors": [
      "Gabriel Chuang",
      "Gregory Herschlag",
      "Jonathan C. Mattingly"
    ],
    "abstract": "When auditing a redistricting plan, a persuasive method is to compare the\nplan with an ensemble of neutrally drawn redistricting plans. Ensembles are\ngenerated via algorithms that sample distributions on balanced graph\npartitions. To audit the partisan difference between the ensemble and a given\nplan, one must ensure that the non-partisan criteria are matched so that we may\nconclude that partisan differences come from bias rather than, for example,\nlevels of compactness or differences in community preservation. Certain\nsampling algorithms allow one to explicitly state the policy-based probability\ndistribution on plans, however, these algorithms have shown poor mixing times\nfor large graphs (i.e. redistricting spaces) for all but a few specialized\nmeasures. In this work, we generate a multiscale parallel tempering approach\nthat makes local moves at each scale. The local moves allow us to adopt a wide\nvariety of policy-based measures. We examine our method in the state of\nConnecticut and succeed at achieving fast mixing on a policy-based distribution\nthat has never before been sampled at this scale. Our algorithm shows promise\nto expand to a significantly wider class of measures that will (i) allow for\nmore principled and situation-based comparisons and (ii) probe for the typical\npartisan impact that policy can have on redistricting.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.SI",
      "math.PR",
      "60J10, 91G60",
      "G.3.8; E.1.3"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "26 pages with appendix; 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17455v1",
    "published_date": "2024-01-30 21:33:05 UTC",
    "updated_date": "2024-01-30 21:33:05 UTC"
  },
  {
    "arxiv_id": "2401.17443v1",
    "title": "Liquid Democracy for Low-Cost Ensemble Pruning",
    "authors": [
      "Ben Armstrong",
      "Kate Larson"
    ],
    "abstract": "We argue that there is a strong connection between ensemble learning and a\ndelegative voting paradigm -- liquid democracy -- that can be leveraged to\nreduce ensemble training costs. We present an incremental training procedure\nthat identifies and removes redundant classifiers from an ensemble via\ndelegation mechanisms inspired by liquid democracy. Through both analysis and\nextensive experiments we show that this process greatly reduces the\ncomputational cost of training compared to training a full ensemble. By\ncarefully selecting the underlying delegation mechanism, weight centralization\nin the classifier population is avoided, leading to higher accuracy than some\nboosting methods. Furthermore, this work serves as an exemplar of how\nframeworks from computational social choice literature can be applied to\nproblems in nontraditional domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 20 figures. Extended abstract to appear at AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17443v1",
    "published_date": "2024-01-30 21:11:35 UTC",
    "updated_date": "2024-01-30 21:11:35 UTC"
  },
  {
    "arxiv_id": "2401.17441v1",
    "title": "Explaining Predictive Uncertainty by Exposing Second-Order Effects",
    "authors": [
      "Florian Bley",
      "Sebastian Lapuschkin",
      "Wojciech Samek",
      "Grégoire Montavon"
    ],
    "abstract": "Explainable AI has brought transparency into complex ML blackboxes, enabling,\nin particular, to identify which features these models use for their\npredictions. So far, the question of explaining predictive uncertainty, i.e.\nwhy a model 'doubts', has been scarcely studied. Our investigation reveals that\npredictive uncertainty is dominated by second-order effects, involving single\nfeatures or product interactions between them. We contribute a new method for\nexplaining predictive uncertainty based on these second-order effects.\nComputationally, our method reduces to a simple covariance computation over a\ncollection of first-order explanations. Our method is generally applicable,\nallowing for turning common attribution techniques (LRP, Gradient x Input,\netc.) into powerful second-order uncertainty explainers, which we call CovLRP,\nCovGI, etc. The accuracy of the explanations our method produces is\ndemonstrated through systematic quantitative evaluations, and the overall\nusefulness of our method is demonstrated via two practical showcases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages + supplement",
    "pdf_url": "http://arxiv.org/pdf/2401.17441v1",
    "published_date": "2024-01-30 21:02:21 UTC",
    "updated_date": "2024-01-30 21:02:21 UTC"
  },
  {
    "arxiv_id": "2401.17436v1",
    "title": "Difficulty Modelling in Mobile Puzzle Games: An Empirical Study on Different Methods to Combine Player Analytics and Simulated Data",
    "authors": [
      "Jeppe Theiss Kristensen",
      "Paolo Burelli"
    ],
    "abstract": "Difficulty is one of the key drivers of player engagement and it is often one\nof the aspects that designers tweak most to optimise the player experience;\noperationalising it is, therefore, a crucial task for game development studios.\nA common practice consists of creating metrics out of data collected by player\ninteractions with the content; however, this allows for estimation only after\nthe content is released and does not consider the characteristics of potential\nfuture players.\n  In this article, we present a number of potential solutions for the\nestimation of difficulty under such conditions, and we showcase the results of\na comparative study intended to understand which method and which types of data\nperform better in different scenarios.\n  The results reveal that models trained on a combination of cohort statistics\nand simulated data produce the most accurate estimations of difficulty in all\nscenarios. Furthermore, among these models, artificial neural networks show the\nmost consistent results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17436v1",
    "published_date": "2024-01-30 20:51:42 UTC",
    "updated_date": "2024-01-30 20:51:42 UTC"
  },
  {
    "arxiv_id": "2401.17435v4",
    "title": "Can LLMs Replace Economic Choice Prediction Labs? The Case of Language-based Persuasion Games",
    "authors": [
      "Eilam Shapira",
      "Omer Madmon",
      "Roi Reichart",
      "Moshe Tennenholtz"
    ],
    "abstract": "Human choice prediction in economic contexts is crucial for applications in\nmarketing, finance, public policy, and more. This task, however, is often\nconstrained by the difficulties in acquiring human choice data. With most\nexperimental economics studies focusing on simple choice settings, the AI\ncommunity has explored whether LLMs can substitute for humans in these\npredictions and examined more complex experimental economics settings. However,\na key question remains: can LLMs generate training data for human choice\nprediction? We explore this in language-based persuasion games, a complex\neconomic setting involving natural language in strategic interactions. Our\nexperiments show that models trained on LLM-generated data can effectively\npredict human behavior in these games and even outperform models trained on\nactual human data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.GT",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17435v4",
    "published_date": "2024-01-30 20:49:47 UTC",
    "updated_date": "2024-08-14 19:23:43 UTC"
  },
  {
    "arxiv_id": "2401.17434v3",
    "title": "Integrating Generative AI in Hackathons: Opportunities, Challenges, and Educational Implications",
    "authors": [
      "Ramteja Sajja",
      "Carlos Erazo Ramirez",
      "Zhouyayan Li",
      "Bekir Z. Demiray",
      "Yusuf Sermet",
      "Ibrahim Demir"
    ],
    "abstract": "Hackathons have emerged as pivotal platforms in the software industry,\ndriving both innovation and skill development for organizations and students\nalike. These events enable companies to quickly prototype new ideas while\noffering students practical, hands-on learning experiences. Over time,\nhackathons have transitioned from purely competitive events to valuable\neducational tools, integrating theory with real-world problem-solving through\ncollaboration between academia and industry. The infusion of artificial\nintelligence (AI) and machine learning is now reshaping hackathons, providing\nenhanced learning opportunities while also introducing ethical challenges. This\nstudy explores the influence of generative AI on students' technological\nchoices, focusing on a case study from the 2023 University of Iowa Hackathon.\nThe findings offer insights into AI's role in these events, its educational\nimpact, and propose strategies for integrating such technologies in future\nhackathons, ensuring a balance between innovation, ethics, and educational\nvalue.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "9792 words, 26 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17434v3",
    "published_date": "2024-01-30 20:45:49 UTC",
    "updated_date": "2024-09-18 17:07:35 UTC"
  },
  {
    "arxiv_id": "2401.17426v1",
    "title": "Superiority of Multi-Head Attention in In-Context Linear Regression",
    "authors": [
      "Yingqian Cui",
      "Jie Ren",
      "Pengfei He",
      "Jiliang Tang",
      "Yue Xing"
    ],
    "abstract": "We present a theoretical analysis of the performance of transformer with\nsoftmax attention in in-context learning with linear regression tasks. While\nthe existing literature predominantly focuses on the convergence of\ntransformers with single-/multi-head attention, our research centers on\ncomparing their performance. We conduct an exact theoretical analysis to\ndemonstrate that multi-head attention with a substantial embedding dimension\nperforms better than single-head attention. When the number of in-context\nexamples D increases, the prediction loss using single-/multi-head attention is\nin O(1/D), and the one for multi-head attention has a smaller multiplicative\nconstant. In addition to the simplest data distribution setting, we consider\nmore scenarios, e.g., noisy labels, local examples, correlated features, and\nprior knowledge. We observe that, in general, multi-head attention is preferred\nover single-head attention. Our results verify the effectiveness of the design\nof multi-head attention in the transformer architecture.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17426v1",
    "published_date": "2024-01-30 20:29:06 UTC",
    "updated_date": "2024-01-30 20:29:06 UTC"
  },
  {
    "arxiv_id": "2401.17424v1",
    "title": "Application of Neural Networks for the Reconstruction of Supernova Neutrino Energy Spectra Following Fast Neutrino Flavor Conversions",
    "authors": [
      "Sajad Abbar",
      "Meng-Ru Wu",
      "Zewei Xiong"
    ],
    "abstract": "Neutrinos can undergo fast flavor conversions (FFCs) within extremely dense\nastrophysical environments such as core-collapse supernovae (CCSNe) and neutron\nstar mergers (NSMs). In this study, we explore FFCs in a \\emph{multi-energy}\nneutrino gas, revealing that when the FFC growth rate significantly exceeds\nthat of the vacuum Hamiltonian, all neutrinos (regardless of energy) share a\ncommon survival probability dictated by the energy-integrated neutrino\nspectrum. We then employ physics-informed neural networks (PINNs) to predict\nthe asymptotic outcomes of FFCs within such a multi-energy neutrino gas. These\npredictions are based on the first two moments of neutrino angular\ndistributions for each energy bin, typically available in state-of-the-art CCSN\nand NSM simulations. Our PINNs achieve errors as low as $\\lesssim6\\%$ and\n$\\lesssim 18\\%$ for predicting the number of neutrinos in the electron channel\nand the relative absolute error in the neutrino moments, respectively.",
    "categories": [
      "astro-ph.HE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.HE",
    "comment": "13 pages, 6 figures, submitted to PRD. arXiv admin note: text overlap\n  with arXiv:2311.15656",
    "pdf_url": "http://arxiv.org/pdf/2401.17424v1",
    "published_date": "2024-01-30 20:27:28 UTC",
    "updated_date": "2024-01-30 20:27:28 UTC"
  },
  {
    "arxiv_id": "2401.17417v2",
    "title": "Through-Wall Imaging based on WiFi Channel State Information",
    "authors": [
      "Julian Strohmayer",
      "Rafael Sterzinger",
      "Christian Stippel",
      "Martin Kampel"
    ],
    "abstract": "This work presents a seminal approach for synthesizing images from WiFi\nChannel State Information (CSI) in through-wall scenarios. Leveraging the\nstrengths of WiFi, such as cost-effectiveness, illumination invariance, and\nwall-penetrating capabilities, our approach enables visual monitoring of indoor\nenvironments beyond room boundaries and without the need for cameras. More\ngenerally, it improves the interpretability of WiFi CSI by unlocking the option\nto perform image-based downstream tasks, e.g., visual activity recognition. In\norder to achieve this crossmodal translation from WiFi CSI to images, we rely\non a multimodal Variational Autoencoder (VAE) adapted to our problem specifics.\nWe extensively evaluate our proposed methodology through an ablation study on\narchitecture configuration and a quantitative/qualitative assessment of\nreconstructed images. Our results demonstrate the viability of our method and\nhighlight its potential for practical applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Added link to source code repository",
    "pdf_url": "http://arxiv.org/pdf/2401.17417v2",
    "published_date": "2024-01-30 20:17:51 UTC",
    "updated_date": "2025-02-07 20:09:47 UTC"
  },
  {
    "arxiv_id": "2402.00070v1",
    "title": "EvoMerge: Neuroevolution for Large Language Models",
    "authors": [
      "Yushu Jiang"
    ],
    "abstract": "Extensive fine-tuning on Large Language Models does not always yield better\nresults. Oftentimes, models tend to get better at imitating one form of data\nwithout gaining greater reasoning ability and may even end up losing some\nintelligence. Here I introduce EvoMerge, a systematic approach to large\nlanguage model training and merging. Leveraging model merging for weight\ncrossover and fine-tuning for weight mutation, EvoMerge establishes an\nevolutionary process aimed at pushing models beyond the limits of conventional\nfine-tuning.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "The current submission is the first draft, published for the sole\n  purpose of sharing an idea and encouraging community effort. A more\n  consolidated version may come later",
    "pdf_url": "http://arxiv.org/pdf/2402.00070v1",
    "published_date": "2024-01-30 19:37:21 UTC",
    "updated_date": "2024-01-30 19:37:21 UTC"
  },
  {
    "arxiv_id": "2401.17401v1",
    "title": "Step-size Optimization for Continual Learning",
    "authors": [
      "Thomas Degris",
      "Khurram Javed",
      "Arsalan Sharifnassab",
      "Yuxin Liu",
      "Richard Sutton"
    ],
    "abstract": "In continual learning, a learner has to keep learning from the data over its\nwhole life time. A key issue is to decide what knowledge to keep and what\nknowledge to let go. In a neural network, this can be implemented by using a\nstep-size vector to scale how much gradient samples change network weights.\nCommon algorithms, like RMSProp and Adam, use heuristics, specifically\nnormalization, to adapt this step-size vector. In this paper, we show that\nthose heuristics ignore the effect of their adaptation on the overall objective\nfunction, for example by moving the step-size vector away from better step-size\nvectors. On the other hand, stochastic meta-gradient descent algorithms, like\nIDBD (Sutton, 1992), explicitly optimize the step-size vector with respect to\nthe overall objective function. On simple problems, we show that IDBD is able\nto consistently improve step-size vectors, where RMSProp and Adam do not. We\nexplain the differences between the two approaches and their respective\nlimitations. We conclude by suggesting that combining both approaches could be\na promising future direction to improve the performance of neural networks in\ncontinual learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17401v1",
    "published_date": "2024-01-30 19:35:43 UTC",
    "updated_date": "2024-01-30 19:35:43 UTC"
  },
  {
    "arxiv_id": "2402.00069v1",
    "title": "Using the Abstract Computer Architecture Description Language to Model AI Hardware Accelerators",
    "authors": [
      "Mika Markus Müller",
      "Alexander Richard Manfred Borst",
      "Konstantin Lübeck",
      "Alexander Louis-Ferdinand Jung",
      "Oliver Bringmann"
    ],
    "abstract": "Artificial Intelligence (AI) has witnessed remarkable growth, particularly\nthrough the proliferation of Deep Neural Networks (DNNs). These powerful models\ndrive technological advancements across various domains. However, to harness\ntheir potential in real-world applications, specialized hardware accelerators\nare essential. This demand has sparked a market for parameterizable AI hardware\naccelerators offered by different vendors.\n  Manufacturers of AI-integrated products face a critical challenge: selecting\nan accelerator that aligns with their product's performance requirements. The\ndecision involves choosing the right hardware and configuring a suitable set of\nparameters. However, comparing different accelerator design alternatives\nremains a complex task. Often, engineers rely on data sheets, spreadsheet\ncalculations, or slow black-box simulators, which only offer a coarse\nunderstanding of the performance characteristics.\n  The Abstract Computer Architecture Description Language (ACADL) is a concise\nformalization of computer architecture block diagrams, which helps to\ncommunicate computer architecture on different abstraction levels and allows\nfor inferring performance characteristics. In this paper, we demonstrate how to\nuse the ACADL to model AI hardware accelerators, use their ACADL description to\nmap DNNs onto them, and explain the timing simulation semantics to gather\nperformance results.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted Version for: MBMV'24",
    "pdf_url": "http://arxiv.org/pdf/2402.00069v1",
    "published_date": "2024-01-30 19:27:16 UTC",
    "updated_date": "2024-01-30 19:27:16 UTC"
  },
  {
    "arxiv_id": "2401.17396v1",
    "title": "Fine-tuning Transformer-based Encoder for Turkish Language Understanding Tasks",
    "authors": [
      "Savas Yildirim"
    ],
    "abstract": "Deep learning-based and lately Transformer-based language models have been\ndominating the studies of natural language processing in the last years. Thanks\nto their accurate and fast fine-tuning characteristics, they have outperformed\ntraditional machine learning-based approaches and achieved state-of-the-art\nresults for many challenging natural language understanding (NLU) problems.\nRecent studies showed that the Transformer-based models such as BERT, which is\nBidirectional Encoder Representations from Transformers, have reached\nimpressive achievements on many tasks. Moreover, thanks to their transfer\nlearning capacity, these architectures allow us to transfer pre-built models\nand fine-tune them to specific NLU tasks such as question answering. In this\nstudy, we provide a Transformer-based model and a baseline benchmark for the\nTurkish Language. We successfully fine-tuned a Turkish BERT model, namely\nBERTurk that is trained with base settings, to many downstream tasks and\nevaluated with a the Turkish Benchmark dataset. We showed that our studies\nsignificantly outperformed other existing baseline approaches for Named-Entity\nRecognition, Sentiment Analysis, Question Answering and Text Classification in\nTurkish Language. We publicly released these four fine-tuned models and\nresources in reproducibility and with the view of supporting other Turkish\nresearchers and applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17396v1",
    "published_date": "2024-01-30 19:27:04 UTC",
    "updated_date": "2024-01-30 19:27:04 UTC"
  },
  {
    "arxiv_id": "2401.17390v2",
    "title": "Customizing Language Model Responses with Contrastive In-Context Learning",
    "authors": [
      "Xiang Gao",
      "Kamalika Das"
    ],
    "abstract": "Large language models (LLMs) are becoming increasingly important for machine\nlearning applications. However, it can be challenging to align LLMs with our\nintent, particularly when we want to generate content that is preferable over\nothers or when we want the LLM to respond in a certain style or tone that is\nhard to describe. To address this challenge, we propose an approach that uses\ncontrastive examples to better describe our intent. This involves providing\npositive examples that illustrate the true intent, along with negative examples\nthat show what characteristics we want LLMs to avoid. The negative examples can\nbe retrieved from labeled data, written by a human, or generated by the LLM\nitself. Before generating an answer, we ask the model to analyze the examples\nto teach itself what to avoid. This reasoning step provides the model with the\nappropriate articulation of the user's need and guides it towards generting a\nbetter answer. We tested our approach on both synthesized and real-world\ndatasets, including StackExchange and Reddit, and found that it significantly\nimproves performance compared to standard few-shot prompting",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to appear at AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17390v2",
    "published_date": "2024-01-30 19:13:12 UTC",
    "updated_date": "2024-04-08 05:22:51 UTC"
  },
  {
    "arxiv_id": "2401.17377v4",
    "title": "Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens",
    "authors": [
      "Jiacheng Liu",
      "Sewon Min",
      "Luke Zettlemoyer",
      "Yejin Choi",
      "Hannaneh Hajishirzi"
    ],
    "abstract": "Are $n$-gram language models still relevant in this era of neural large\nlanguage models (LLMs)? Our answer is yes, and we showcase their values in both\ntext analysis and improving neural LLMs. This was done by modernizing $n$-gram\nLMs in two aspects. First, we train them at the same data scale as neural LLMs\n-- 5 trillion tokens. This is the largest $n$-gram LM ever built. Second,\nexisting $n$-gram LMs use small $n$ which hinders their performance; we instead\nallow $n$ to be arbitrarily large, by introducing a new $\\infty$-gram LM with\nbackoff. Instead of pre-computing $n$-gram count tables (which would be very\nexpensive), we develop an engine named infini-gram -- powered by suffix arrays\n-- that can compute $\\infty$-gram (as well as $n$-gram with arbitrary $n$)\nprobabilities with millisecond-level latency. The $\\infty$-gram framework and\ninfini-gram engine enable us to conduct many novel and interesting analyses of\nhuman-written and machine-generated text: we find that the $\\infty$-gram LM has\nfairly high accuracy for next-token prediction (47%), and can complement neural\nLLMs to greatly reduce their perplexity. When analyzing machine-generated text,\nwe also observe irregularities in the machine--$\\infty$-gram agreement level\nwith respect to the suffix length, which indicates deficiencies in neural LLM\npretraining and the positional embeddings of Transformers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at COLM 2024, spotlight paper",
    "pdf_url": "http://arxiv.org/pdf/2401.17377v4",
    "published_date": "2024-01-30 19:03:49 UTC",
    "updated_date": "2025-04-07 17:59:50 UTC"
  },
  {
    "arxiv_id": "2401.17373v1",
    "title": "Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for Classifying Arabic Speech Acts on Twitter",
    "authors": [
      "Khadejaa Alshehri",
      "Areej Alhothali",
      "Nahed Alowidi"
    ],
    "abstract": "Speech acts are a speakers actions when performing an utterance within a\nconversation, such as asking, recommending, greeting, or thanking someone,\nexpressing a thought, or making a suggestion. Understanding speech acts helps\ninterpret the intended meaning and actions behind a speakers or writers words.\nThis paper proposes a Twitter dialectal Arabic speech act classification\napproach based on a transformer deep learning neural network. Twitter and\nsocial media, are becoming more and more integrated into daily life. As a\nresult, they have evolved into a vital source of information that represents\nthe views and attitudes of their users. We proposed a BERT based weighted\nensemble learning approach to integrate the advantages of various BERT models\nin dialectal Arabic speech acts classification. We compared the proposed model\nagainst several variants of Arabic BERT models and sequence-based models. We\ndeveloped a dialectal Arabic tweet act dataset by annotating a subset of a\nlarge existing Arabic sentiment analysis dataset (ASAD) based on six speech act\ncategories. We also evaluated the models on a previously developed Arabic Tweet\nAct dataset (ArSAS). To overcome the class imbalance issue commonly observed in\nspeech act problems, a transformer-based data augmentation model was\nimplemented to generate an equal proportion of speech act categories. The\nresults show that the best BERT model is araBERTv2-Twitter models with a\nmacro-averaged F1 score and an accuracy of 0.73 and 0.84, respectively. The\nperformance improved using a BERT-based ensemble method with a 0.74 and 0.85\naveraged F1 score and accuracy on our dataset, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17373v1",
    "published_date": "2024-01-30 19:01:24 UTC",
    "updated_date": "2024-01-30 19:01:24 UTC"
  },
  {
    "arxiv_id": "2401.17268v1",
    "title": "Weaver: Foundation Models for Creative Writing",
    "authors": [
      "Tiannan Wang",
      "Jiamin Chen",
      "Qingrui Jia",
      "Shuai Wang",
      "Ruoyu Fang",
      "Huilin Wang",
      "Zhaowei Gao",
      "Chunzhao Xie",
      "Chuou Xu",
      "Jihong Dai",
      "Yibin Liu",
      "Jialong Wu",
      "Shengwei Ding",
      "Long Li",
      "Zhiwei Huang",
      "Xinle Deng",
      "Teng Yu",
      "Gangan Ma",
      "Han Xiao",
      "Zixin Chen",
      "Danjun Xiang",
      "Yunxia Wang",
      "Yuanyuan Zhu",
      "Yi Xiao",
      "Jing Wang",
      "Yiru Wang",
      "Siran Ding",
      "Jiayang Huang",
      "Jiayi Xu",
      "Yilihamu Tayier",
      "Zhenyu Hu",
      "Yuan Gao",
      "Chengfeng Zheng",
      "Yueshu Ye",
      "Yihang Li",
      "Lei Wan",
      "Xinyue Jiang",
      "Yujie Wang",
      "Siyu Cheng",
      "Zhule Song",
      "Xiangru Tang",
      "Xiaohua Xu",
      "Ningyu Zhang",
      "Huajun Chen",
      "Yuchen Eleanor Jiang",
      "Wangchunshu Zhou"
    ],
    "abstract": "This work introduces Weaver, our first family of large language models (LLMs)\ndedicated to content creation. Weaver is pre-trained on a carefully selected\ncorpus that focuses on improving the writing capabilities of large language\nmodels. We then fine-tune Weaver for creative and professional writing purposes\nand align it to the preference of professional writers using a suit of novel\nmethods for instruction data synthesis and LLM alignment, making it able to\nproduce more human-like texts and follow more diverse instructions for content\ncreation. The Weaver family consists of models of Weaver Mini (1.8B), Weaver\nBase (6B), Weaver Pro (14B), and Weaver Ultra (34B) sizes, suitable for\ndifferent applications and can be dynamically dispatched by a routing agent\naccording to query complexity to balance response quality and computation cost.\nEvaluation on a carefully curated benchmark for assessing the writing\ncapabilities of LLMs shows Weaver models of all sizes outperform generalist\nLLMs several times larger than them. Notably, our most-capable Weaver Ultra\nmodel surpasses GPT-4, a state-of-the-art generalist LLM, on various writing\nscenarios, demonstrating the advantage of training specialized LLMs for writing\npurposes. Moreover, Weaver natively supports retrieval-augmented generation\n(RAG) and function calling (tool usage). We present various use cases of these\nabilities for improving AI-assisted writing systems, including integration of\nexternal knowledge bases, tools, or APIs, and providing personalized writing\nassistance. Furthermore, we discuss and summarize a guideline and best\npractices for pre-training and fine-tuning domain-specific LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17268v1",
    "published_date": "2024-01-30 18:58:43 UTC",
    "updated_date": "2024-01-30 18:58:43 UTC"
  },
  {
    "arxiv_id": "2401.17264v2",
    "title": "Proactive Detection of Voice Cloning with Localized Watermarking",
    "authors": [
      "Robin San Roman",
      "Pierre Fernandez",
      "Alexandre Défossez",
      "Teddy Furon",
      "Tuan Tran",
      "Hady Elsahar"
    ],
    "abstract": "In the rapidly evolving field of speech generative models, there is a\npressing need to ensure audio authenticity against the risks of voice cloning.\nWe present AudioSeal, the first audio watermarking technique designed\nspecifically for localized detection of AI-generated speech. AudioSeal employs\na generator/detector architecture trained jointly with a localization loss to\nenable localized watermark detection up to the sample level, and a novel\nperceptual loss inspired by auditory masking, that enables AudioSeal to achieve\nbetter imperceptibility. AudioSeal achieves state-of-the-art performance in\nterms of robustness to real life audio manipulations and imperceptibility based\non automatic and human evaluation metrics. Additionally, AudioSeal is designed\nwith a fast, single-pass detector, that significantly surpasses existing models\nin speed - achieving detection up to two orders of magnitude faster, making it\nideal for large-scale and real-time applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SD",
    "comment": "Published at ICML 2024. Code at\n  https://github.com/facebookresearch/audioseal - webpage at\n  https://pierrefdz.github.io/publications/audioseal/",
    "pdf_url": "http://arxiv.org/pdf/2401.17264v2",
    "published_date": "2024-01-30 18:56:22 UTC",
    "updated_date": "2024-06-06 17:48:28 UTC"
  },
  {
    "arxiv_id": "2401.17263v5",
    "title": "Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks",
    "authors": [
      "Andy Zhou",
      "Bo Li",
      "Haohan Wang"
    ],
    "abstract": "Despite advances in AI alignment, large language models (LLMs) remain\nvulnerable to adversarial attacks or jailbreaking, in which adversaries can\nmodify prompts to induce unwanted behavior. While some defenses have been\nproposed, they have not been adapted to newly proposed attacks and more\nchallenging threat models. To address this, we propose an optimization-based\nobjective for defending LLMs against jailbreaking attacks and an algorithm,\nRobust Prompt Optimization (RPO) to create robust system-level defenses. Our\napproach directly incorporates the adversary into the defensive objective and\noptimizes a lightweight and transferable suffix, enabling RPO to adapt to\nworst-case adaptive attacks. Our theoretical and experimental results show\nimproved robustness to both jailbreaks seen during optimization and unknown\njailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2\nto 0% on JailbreakBench, setting the state-of-the-art. Code can be found at\nhttps://github.com/lapisrocks/rpo",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Spotlight; code available at\n  https://github.com/lapisrocks/rpo",
    "pdf_url": "http://arxiv.org/pdf/2401.17263v5",
    "published_date": "2024-01-30 18:56:08 UTC",
    "updated_date": "2024-11-08 06:57:05 UTC"
  },
  {
    "arxiv_id": "2401.17244v3",
    "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation",
    "authors": [
      "Yuan Chiang",
      "Elvis Hsieh",
      "Chia-Hong Chou",
      "Janosh Riebesell"
    ],
    "abstract": "Reducing hallucination of Large Language Models (LLMs) is imperative for use\nin the sciences, where reliability and reproducibility are crucial. However,\nLLMs inherently lack long-term memory, making it a nontrivial, ad hoc, and\ninevitably biased task to fine-tune them on domain-specific literature and\ndata. Here we introduce LLaMP, a multimodal retrieval-augmented generation\n(RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can\ndynamically and recursively interact with computational and experimental data\non Materials Project (MP) and run atomistic simulations via high-throughput\nworkflow interface. Without fine-tuning, LLaMP demonstrates strong tool usage\nability to comprehend and integrate various modalities of materials science\nconcepts, fetch relevant data stores on the fly, process higher-order data\n(such as crystal structure and elastic tensor), and streamline complex tasks in\ncomputational materials and chemistry. We propose a simple metric combining\nuncertainty and confidence estimates to evaluate the self-consistency of\nresponses by LLaMP and vanilla LLMs. Our benchmark shows that LLaMP effectively\nmitigates the intrinsic bias in LLMs, counteracting the errors on bulk moduli,\nelectronic bandgaps, and formation energies that seem to derive from mixed data\nsources. We also demonstrate LLaMP's capability to edit crystal structures and\nrun annealing molecular dynamics simulations using pre-trained machine-learning\nforce fields. The framework offers an intuitive and nearly hallucination-free\napproach to exploring and scaling materials informatics, and establishes a\npathway for knowledge distillation and fine-tuning other language models. Code\nand live demo are available at https://github.com/chiang-yuan/llamp",
    "categories": [
      "cs.CL",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17244v3",
    "published_date": "2024-01-30 18:37:45 UTC",
    "updated_date": "2024-10-09 20:13:51 UTC"
  },
  {
    "arxiv_id": "2401.17230v2",
    "title": "ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models",
    "authors": [
      "Jee-weon Jung",
      "Wangyou Zhang",
      "Jiatong Shi",
      "Zakaria Aldeneh",
      "Takuya Higuchi",
      "Barry-John Theobald",
      "Ahmed Hussen Abdelaziz",
      "Shinji Watanabe"
    ],
    "abstract": "This paper introduces ESPnet-SPK, a toolkit designed with several objectives\nfor training speaker embedding extractors. First, we provide an open-source\nplatform for researchers in the speaker recognition community to effortlessly\nbuild models. We provide several models, ranging from x-vector to recent\nSKA-TDNN. Through the modularized architecture design, variants can be\ndeveloped easily. We also aspire to bridge developed models with other domains,\nfacilitating the broad research community to effortlessly incorporate\nstate-of-the-art embedding extractors. Pre-trained embedding extractors can be\naccessed in an off-the-shelf manner and we demonstrate the toolkit's\nversatility by showcasing its integration with two tasks. Another goal is to\nintegrate with diverse self-supervised learning features. We release a\nreproducible recipe that achieves an equal error rate of 0.39% on the Vox1-O\nevaluation protocol using WavLM-Large with ECAPA-TDNN.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 3 figures, 7 tables, Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17230v2",
    "published_date": "2024-01-30 18:18:27 UTC",
    "updated_date": "2024-06-13 05:19:12 UTC"
  },
  {
    "arxiv_id": "2401.17228v1",
    "title": "Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning",
    "authors": [
      "Jeongwoo Park",
      "Enrico Liscio",
      "Pradeep K. Murukannaiah"
    ],
    "abstract": "Recent advances in NLP show that language models retain a discernible level\nof knowledge in deontological ethics and moral norms. However, existing works\noften treat morality as binary, ranging from right to wrong. This simplistic\nview does not capture the nuances of moral judgment. Pluralist moral\nphilosophers argue that human morality can be deconstructed into a finite\nnumber of elements, respecting individual differences in moral judgment. In\nline with this view, we build a pluralist moral sentence embedding space via a\nstate-of-the-art contrastive learning approach. We systematically investigate\nthe embedding space by studying the emergence of relationships among moral\nelements, both quantitatively and qualitatively. Our results show that a\npluralist approach to morality can be captured in an embedding space. However,\nmoral pluralism is challenging to deduce via self-supervision alone and\nrequires a supervised approach with human labels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in Findings of EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17228v1",
    "published_date": "2024-01-30 18:15:25 UTC",
    "updated_date": "2024-01-30 18:15:25 UTC"
  },
  {
    "arxiv_id": "2402.01762v1",
    "title": "Commercial AI, Conflict, and Moral Responsibility: A theoretical analysis and practical approach to the moral responsibilities associated with dual-use AI technology",
    "authors": [
      "Daniel Trusilo",
      "David Danks"
    ],
    "abstract": "This paper presents a theoretical analysis and practical approach to the\nmoral responsibilities when developing AI systems for non-military applications\nthat may nonetheless be used for conflict applications. We argue that AI\nrepresents a form of crossover technology that is different from previous\nhistorical examples of dual- or multi-use technology as it has a multiplicative\neffect across other technologies. As a result, existing analyses of ethical\nresponsibilities around dual-use technologies do not necessarily work for AI\nsystems. We instead argue that stakeholders involved in the AI system lifecycle\nare morally responsible for uses of their systems that are reasonably\nforeseeable. The core idea is that an agent's moral responsibility for some\naction is not necessarily determined by their intentions alone; we must also\nconsider what the agent could reasonably have foreseen to be potential outcomes\nof their action, such as the potential use of a system in conflict even when it\nis not designed for that. In particular, we contend that it is reasonably\nforeseeable that: (1) civilian AI systems will be applied to active conflict,\nincluding conflict support activities, (2) the use of civilian AI systems in\nconflict will impact applications of the law of armed conflict, and (3)\ncrossover AI technology will be applied to conflicts that fall short of armed\nconflict. Given these reasonably foreseeably outcomes, we present three\ntechnically feasible actions that developers of civilian AIs can take to\npotentially mitigate their moral responsibility: (a) establishing systematic\napproaches to multi-perspective capability testing, (b) integrating digital\nwatermarking in model weight matrices, and (c) utilizing monitoring and\nreporting mechanisms for conflict-related AI applications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.1; K.5.2"
    ],
    "primary_category": "cs.CY",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01762v1",
    "published_date": "2024-01-30 18:09:45 UTC",
    "updated_date": "2024-01-30 18:09:45 UTC"
  },
  {
    "arxiv_id": "2401.17221v1",
    "title": "MouSi: Poly-Visual-Expert Vision-Language Models",
    "authors": [
      "Xiaoran Fan",
      "Tao Ji",
      "Changhao Jiang",
      "Shuo Li",
      "Senjie Jin",
      "Sirui Song",
      "Junke Wang",
      "Boyang Hong",
      "Lu Chen",
      "Guodong Zheng",
      "Ming Zhang",
      "Caishuang Huang",
      "Rui Zheng",
      "Zhiheng Xi",
      "Yuhao Zhou",
      "Shihan Dou",
      "Junjie Ye",
      "Hang Yan",
      "Tao Gui",
      "Qi Zhang",
      "Xipeng Qiu",
      "Xuanjing Huang",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "abstract": "Current large vision-language models (VLMs) often encounter challenges such\nas insufficient capabilities of a single visual component and excessively long\nvisual tokens. These issues can limit the model's effectiveness in accurately\ninterpreting complex visual information and over-lengthy contextual\ninformation. Addressing these challenges is crucial for enhancing the\nperformance and applicability of VLMs. This paper proposes the use of ensemble\nexperts technique to synergizes the capabilities of individual visual encoders,\nincluding those skilled in image-text matching, OCR, image segmentation, etc.\nThis technique introduces a fusion network to unify the processing of outputs\nfrom different visual experts, while bridging the gap between image encoders\nand pre-trained LLMs. In addition, we explore different positional encoding\nschemes to alleviate the waste of positional encoding caused by lengthy image\nfeature sequences, effectively addressing the issue of position overflow and\nlength limitations. For instance, in our implementation, this technique\nsignificantly reduces the positional occupancy in models like SAM, from a\nsubstantial 4096 to a more efficient and manageable 64 or even down to 1.\nExperimental results demonstrate that VLMs with multiple experts exhibit\nconsistently superior performance over isolated visual encoders and mark a\nsignificant performance boost as more experts are integrated. We have\nopen-sourced the training code used in this report. All of these resources can\nbe found on our project website.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17221v1",
    "published_date": "2024-01-30 18:09:11 UTC",
    "updated_date": "2024-01-30 18:09:11 UTC"
  },
  {
    "arxiv_id": "2401.17350v2",
    "title": "Time Series Supplier Allocation via Deep Black-Litterman Model",
    "authors": [
      "Jiayuan Luo",
      "Wentao Zhang",
      "Yuchen Fang",
      "Xiaowei Gao",
      "Dingyi Zhuang",
      "Hao Chen",
      "Xinke Jiang"
    ],
    "abstract": "Time Series Supplier Allocation (TSSA) poses a complex NP-hard challenge,\naimed at refining future order dispatching strategies to satisfy order demands\nwith maximum supply efficiency fully. Traditionally derived from financial\nportfolio management, the Black-Litterman (BL) model offers a new perspective\nfor the TSSA scenario by balancing expected returns against insufficient supply\nrisks. However, its application within TSSA is constrained by the reliance on\nmanually constructed perspective matrices and spatio-temporal market dynamics,\ncoupled with the absence of supervisory signals and data unreliability inherent\nto supplier information. To solve these limitations, we introduce the\npioneering Deep Black-Litterman Model (DBLM), which innovatively adapts the BL\nmodel from financial roots to supply chain context. Leveraging the\nSpatio-Temporal Graph Neural Networks (STGNNS), DBLM automatically generates\nfuture perspective matrices for TSSA, by integrating spatio-temporal\ndependency. Moreover, a novel Spearman rank correlation distinctively\nsupervises our approach to address the lack of supervisory signals,\nspecifically designed to navigate through the complexities of supplier risks\nand interactions. This is further enhanced by a masking mechanism aimed at\ncounteracting the biases from unreliable data, thereby improving the model's\nprecision and reliability. Extensive experimentation on two datasets\nunequivocally demonstrates DBLM's enhanced performance in TSSA, setting new\nstandards for the field. Our findings and methodology are made available for\ncommunity access and further development.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "In submission to SIGKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17350v2",
    "published_date": "2024-01-30 17:57:07 UTC",
    "updated_date": "2024-02-09 05:44:54 UTC"
  },
  {
    "arxiv_id": "2402.01761v1",
    "title": "Rethinking Interpretability in the Era of Large Language Models",
    "authors": [
      "Chandan Singh",
      "Jeevana Priya Inala",
      "Michel Galley",
      "Rich Caruana",
      "Jianfeng Gao"
    ],
    "abstract": "Interpretable machine learning has exploded as an area of interest over the\nlast decade, sparked by the rise of increasingly large datasets and deep neural\nnetworks. Simultaneously, large language models (LLMs) have demonstrated\nremarkable capabilities across a wide array of tasks, offering a chance to\nrethink opportunities in interpretable machine learning. Notably, the\ncapability to explain in natural language allows LLMs to expand the scale and\ncomplexity of patterns that can be given to a human. However, these new\ncapabilities raise new challenges, such as hallucinated explanations and\nimmense computational costs.\n  In this position paper, we start by reviewing existing methods to evaluate\nthe emerging field of LLM interpretation (both interpreting LLMs and using LLMs\nfor explanation). We contend that, despite their limitations, LLMs hold the\nopportunity to redefine interpretability with a more ambitious scope across\nmany applications, including in auditing LLMs themselves. We highlight two\nemerging research priorities for LLM interpretation: using LLMs to directly\nanalyze new datasets and to generate interactive explanations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01761v1",
    "published_date": "2024-01-30 17:38:54 UTC",
    "updated_date": "2024-01-30 17:38:54 UTC"
  },
  {
    "arxiv_id": "2401.17200v1",
    "title": "NormEnsembleXAI: Unveiling the Strengths and Weaknesses of XAI Ensemble Techniques",
    "authors": [
      "Weronika Hryniewska-Guzik",
      "Bartosz Sawicki",
      "Przemysław Biecek"
    ],
    "abstract": "This paper presents a comprehensive comparative analysis of explainable\nartificial intelligence (XAI) ensembling methods. Our research brings three\nsignificant contributions. Firstly, we introduce a novel ensembling method,\nNormEnsembleXAI, that leverages minimum, maximum, and average functions in\nconjunction with normalization techniques to enhance interpretability.\nSecondly, we offer insights into the strengths and weaknesses of XAI ensemble\nmethods. Lastly, we provide a library, facilitating the practical\nimplementation of XAI ensembling, thus promoting the adoption of transparent\nand interpretable deep learning models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17200v1",
    "published_date": "2024-01-30 17:33:35 UTC",
    "updated_date": "2024-01-30 17:33:35 UTC"
  },
  {
    "arxiv_id": "2402.09443v1",
    "title": "Review of algorithms for predicting fatigue using EEG",
    "authors": [
      "Ildar Rakhmatulin"
    ],
    "abstract": "Fatigue detection is of paramount importance in enhancing safety,\nproductivity, and well-being across diverse domains, including transportation,\nhealthcare, and industry. This scientific paper presents a comprehensive\ninvestigation into the application of machine learning algorithms for the\ndetection of physiological fatigue using Electroencephalogram (EEG) signals.\nThe primary objective of this study was to assess the efficacy of various\nalgorithms in predicting an individual's level of fatigue based on EEG data.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "arXiv admin note: text overlap with arXiv:2401.15766",
    "pdf_url": "http://arxiv.org/pdf/2402.09443v1",
    "published_date": "2024-01-30 17:32:02 UTC",
    "updated_date": "2024-01-30 17:32:02 UTC"
  },
  {
    "arxiv_id": "2401.17188v1",
    "title": "Nested Construction of Polar Codes via Transformers",
    "authors": [
      "Sravan Kumar Ankireddy",
      "S Ashwin Hebbar",
      "Heping Wan",
      "Joonyoung Cho",
      "Charlie Zhang"
    ],
    "abstract": "Tailoring polar code construction for decoding algorithms beyond successive\ncancellation has remained a topic of significant interest in the field.\nHowever, despite the inherent nested structure of polar codes, the use of\nsequence models in polar code construction is understudied. In this work, we\npropose using a sequence modeling framework to iteratively construct a polar\ncode for any given length and rate under various channel conditions.\nSimulations show that polar codes designed via sequential modeling using\ntransformers outperform both 5G-NR sequence and Density Evolution based\napproaches for both AWGN and Rayleigh fading channels.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "7 pages; 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17188v1",
    "published_date": "2024-01-30 17:17:43 UTC",
    "updated_date": "2024-01-30 17:17:43 UTC"
  },
  {
    "arxiv_id": "2401.17186v1",
    "title": "Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning",
    "authors": [
      "Bang Yang",
      "Yong Dai",
      "Xuxin Cheng",
      "Yaowei Li",
      "Asif Raza",
      "Yuexian Zou"
    ],
    "abstract": "While vision-language pre-trained models (VL-PTMs) have advanced multimodal\nresearch in recent years, their mastery in a few languages like English\nrestricts their applicability in broader communities. To this end, there is an\nincreasing interest in developing multilingual VL models via a joint-learning\nsetup, which, however, could be unrealistic due to expensive costs and data\navailability. In this work, we propose to extend VL-PTMs' language capacity by\ncontinual language learning (CLL), where a model needs to update its linguistic\nknowledge incrementally without suffering from catastrophic forgetting (CF). We\nbegin our study by introducing a model dubbed CLL-CLIP, which builds upon CLIP,\na prevailing VL-PTM that has acquired image-English text alignment.\nSpecifically, CLL-CLIP contains an expandable token embedding layer to handle\nlinguistic differences. It solely trains token embeddings to improve memory\nstability and is optimized under cross-modal and cross-lingual objectives to\nlearn the alignment between images and multilingual texts. To alleviate CF\nraised by covariate shift and lexical overlap, we further propose a novel\napproach that ensures the identical distribution of all token embeddings during\ninitialization and regularizes token embedding learning during training. We\nconstruct a CLL benchmark covering 36 languages based on MSCOCO and XM3600\ndatasets and then evaluate multilingual image-text retrieval performance.\nExtensive experiments verify the effectiveness of CLL-CLIP and show that our\napproach can boost CLL-CLIP, e.g., by 6.7% in text-to-image average Recall@1 on\nXM3600, and improve various state-of-the-art methods consistently. Our code and\ndata are available at \\url{https://github.com/yangbang18/CLFM}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI'2024, 15 pages (with appendix), 7 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.17186v1",
    "published_date": "2024-01-30 17:14:05 UTC",
    "updated_date": "2024-01-30 17:14:05 UTC"
  },
  {
    "arxiv_id": "2401.17178v1",
    "title": "GraphViz2Vec: A Structure-aware Feature Generation Model to Improve Classification in GNNs",
    "authors": [
      "Shraban Kumar Chatterjee",
      "Suman Kundu"
    ],
    "abstract": "GNNs are widely used to solve various tasks including node classification and\nlink prediction. Most of the GNN architectures assume the initial embedding to\nbe random or generated from popular distributions. These initial embeddings\nrequire multiple layers of transformation to converge into a meaningful latent\nrepresentation. While number of layers allow accumulation of larger\nneighbourhood of a node it also introduce the problem of over-smoothing. In\naddition, GNNs are inept at representing structural information. For example,\nthe output embedding of a node does not capture its triangles participation. In\nthis paper, we presented a novel feature extraction methodology GraphViz2Vec\nthat can capture the structural information of a node's local neighbourhood to\ncreate meaningful initial embeddings for a GNN model. These initial embeddings\nhelps existing models achieve state-of-the-art results in various\nclassification tasks. Further, these initial embeddings help the model to\nproduce desired results with only two layers which in turn reduce the problem\nof over-smoothing. The initial encoding of a node is obtained from an image\nclassification model trained on multiple energy diagrams of its local\nneighbourhood. These energy diagrams are generated with the induced sub-graph\nof the nodes traversed by multiple random walks. The generated encodings\nincrease the performance of existing models on classification tasks (with a\nmean increase of $4.65\\%$ and $2.58\\%$ for the node and link classification\ntasks, respectively), with some models achieving state-of-the-art results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17178v1",
    "published_date": "2024-01-30 17:11:04 UTC",
    "updated_date": "2024-01-30 17:11:04 UTC"
  },
  {
    "arxiv_id": "2401.17173v3",
    "title": "Zero-Shot Reinforcement Learning via Function Encoders",
    "authors": [
      "Tyler Ingebrand",
      "Amy Zhang",
      "Ufuk Topcu"
    ],
    "abstract": "Although reinforcement learning (RL) can solve many challenging sequential\ndecision making problems, achieving zero-shot transfer across related tasks\nremains a challenge. The difficulty lies in finding a good representation for\nthe current task so that the agent understands how it relates to previously\nseen tasks. To achieve zero-shot transfer, we introduce the function encoder, a\nrepresentation learning algorithm which represents a function as a weighted\ncombination of learned, non-linear basis functions. By using a function encoder\nto represent the reward function or the transition function, the agent has\ninformation on how the current task relates to previously seen tasks via a\ncoherent vector representation. Thus, the agent is able to achieve transfer\nbetween related tasks at run time with no additional training. We demonstrate\nstate-of-the-art data efficiency, asymptotic performance, and training\nstability in three RL fields by augmenting basic RL algorithms with a function\nencoder task representation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "A critical issue was found in the multi-agent experiments published\n  in version 2. We rerun the multi-agent experiments on a more challenging,\n  partially observable Markov game",
    "pdf_url": "http://arxiv.org/pdf/2401.17173v3",
    "published_date": "2024-01-30 17:04:47 UTC",
    "updated_date": "2025-03-21 14:37:37 UTC"
  },
  {
    "arxiv_id": "2401.17169v4",
    "title": "Conditional and Modal Reasoning in Large Language Models",
    "authors": [
      "Wesley H. Holliday",
      "Matthew Mandelkern",
      "Cedegao E. Zhang"
    ],
    "abstract": "The reasoning abilities of large language models (LLMs) are the topic of a\ngrowing body of research in AI and cognitive science. In this paper, we probe\nthe extent to which twenty-nine LLMs are able to distinguish logically correct\ninferences from logically fallacious ones. We focus on inference patterns\ninvolving conditionals (e.g., 'If Ann has a queen, then Bob has a jack') and\nepistemic modals (e.g., 'Ann might have an ace', 'Bob must have a king'). These\ninferences have been of special interest to logicians, philosophers, and\nlinguists, since they play a central role in the fundamental human ability to\nreason about distal possibilities. Assessing LLMs on these inferences is thus\nhighly relevant to the question of how much the reasoning abilities of LLMs\nmatch those of humans. All the LLMs we tested make some basic mistakes with\nconditionals or modals, though zero-shot chain-of-thought prompting helps them\nmake fewer mistakes. Even the best performing LLMs make basic errors in modal\nreasoning, display logically inconsistent judgments across inference patterns\ninvolving epistemic modals and conditionals, and give answers about complex\nconditional inferences that do not match reported human judgments. These\nresults highlight gaps in basic logical reasoning in today's LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LO",
      "68T50, 03B65",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for The 2024 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2024). Final version includes additional models\n  and additional inference patterns",
    "pdf_url": "http://arxiv.org/pdf/2401.17169v4",
    "published_date": "2024-01-30 16:56:54 UTC",
    "updated_date": "2024-10-13 11:08:15 UTC"
  },
  {
    "arxiv_id": "2402.00891v1",
    "title": "Large Language Models in Cybersecurity: State-of-the-Art",
    "authors": [
      "Farzad Nourmohammadzadeh Motlagh",
      "Mehrdad Hajizadeh",
      "Mehryar Majd",
      "Pejman Najafi",
      "Feng Cheng",
      "Christoph Meinel"
    ],
    "abstract": "The rise of Large Language Models (LLMs) has revolutionized our comprehension\nof intelligence bringing us closer to Artificial Intelligence. Since their\nintroduction, researchers have actively explored the applications of LLMs\nacross diverse fields, significantly elevating capabilities. Cybersecurity,\ntraditionally resistant to data-driven solutions and slow to embrace machine\nlearning, stands out as a domain. This study examines the existing literature,\nproviding a thorough characterization of both defensive and adversarial\napplications of LLMs within the realm of cybersecurity. Our review not only\nsurveys and categorizes the current landscape but also identifies critical\nresearch gaps. By evaluating both offensive and defensive applications, we aim\nto provide a holistic understanding of the potential risks and opportunities\nassociated with LLM-driven cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00891v1",
    "published_date": "2024-01-30 16:55:25 UTC",
    "updated_date": "2024-01-30 16:55:25 UTC"
  },
  {
    "arxiv_id": "2401.17159v2",
    "title": "Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis",
    "authors": [
      "Zhengyang Lu",
      "Stefan Siemer",
      "Piyush Jha",
      "Joel Day",
      "Florin Manea",
      "Vijay Ganesh"
    ],
    "abstract": "Modern SMT solvers, such as Z3, offer user-controllable strategies, enabling\nusers to tailor solving strategies for their unique set of instances, thus\ndramatically enhancing solver performance for their use case. However, this\napproach of strategy customization presents a significant challenge:\nhandcrafting an optimized strategy for a class of SMT instances remains a\ncomplex and demanding task for both solver developers and users alike.\n  In this paper, we address this problem of automatic SMT strategy synthesis\nvia a novel Monte Carlo Tree Search (MCTS) based method. Our method treats\nstrategy synthesis as a sequential decision-making process, whose search tree\ncorresponds to the strategy space, and employs MCTS to navigate this vast\nsearch space. The key innovations that enable our method to identify effective\nstrategies, while keeping costs low, are the ideas of layered and staged MCTS\nsearch. These novel heuristics allow for a deeper and more efficient\nexploration of the strategy space, enabling us to synthesize more effective\nstrategies than the default ones in state-of-the-art (SOTA) SMT solvers. We\nimplement our method, dubbed Z3alpha, as part of the Z3 SMT solver. Through\nextensive evaluations across six important SMT logics, Z3alpha demonstrates\nsuperior performance compared to the SOTA synthesis tool FastSMT, the default\nZ3 solver, and the CVC5 solver on most benchmarks. Remarkably, on a challenging\nQF_BV benchmark set, Z3alpha solves 42.7% more instances than the default\nstrategy in the Z3 SMT solver.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17159v2",
    "published_date": "2024-01-30 16:47:30 UTC",
    "updated_date": "2024-04-30 16:34:58 UTC"
  },
  {
    "arxiv_id": "2402.01760v2",
    "title": "Trust and ethical considerations in a multi-modal, explainable AI-driven chatbot tutoring system: The case of collaboratively solving Rubik's Cube",
    "authors": [
      "Kausik Lakkaraju",
      "Vedant Khandelwal",
      "Biplav Srivastava",
      "Forest Agostinelli",
      "Hengtao Tang",
      "Prathamjeet Singh",
      "Dezhi Wu",
      "Matt Irvin",
      "Ashish Kundu"
    ],
    "abstract": "Artificial intelligence (AI) has the potential to transform education with\nits power of uncovering insights from massive data about student learning\npatterns. However, ethical and trustworthy concerns of AI have been raised but\nare unsolved. Prominent ethical issues in high school AI education include data\nprivacy, information leakage, abusive language, and fairness. This paper\ndescribes technological components that were built to address ethical and\ntrustworthy concerns in a multi-modal collaborative platform (called ALLURE\nchatbot) for high school students to collaborate with AI to solve the Rubik's\ncube. In data privacy, we want to ensure that the informed consent of children,\nparents, and teachers, is at the center of any data that is managed. Since\nchildren are involved, language, whether textual, audio, or visual, is\nacceptable both from users and AI and the system can steer interaction away\nfrom dangerous situations. In information management, we also want to ensure\nthat the system, while learning to improve over time, does not leak information\nabout users from one group to another.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at 'Neural Conversational AI Workshop - What's left to TEACH\n  (Trustworthy, Enhanced, Adaptable, Capable, and Human-centric) chatbots?' at\n  ICML 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.01760v2",
    "published_date": "2024-01-30 16:33:21 UTC",
    "updated_date": "2024-08-27 15:09:18 UTC"
  },
  {
    "arxiv_id": "2402.01759v1",
    "title": "Systematic Literature Review: Computational Approaches for Humour Style Classification",
    "authors": [
      "Mary Ogbuka Kenneth",
      "Foaad Khosmood",
      "Abbas Edalat"
    ],
    "abstract": "Understanding various humour styles is essential for comprehending the\nmultifaceted nature of humour and its impact on fields such as psychology and\nartificial intelligence. This understanding has revealed that humour, depending\non the style employed, can either have therapeutic or detrimental effects on an\nindividual's health and relationships. Although studies dedicated exclusively\nto computational-based humour style analysis remain somewhat rare, an expansive\nbody of research thrives within related task, particularly binary humour and\nsarcasm recognition. In this systematic literature review (SLR), we survey the\nlandscape of computational techniques applied to these related tasks and also\nuncover their fundamental relevance to humour style analysis. Through this\nstudy, we unveil common approaches, illuminate various datasets and evaluation\nmetrics, and effectively navigate the complex terrain of humour research. Our\nefforts determine potential research gaps and outlined promising directions.\nFurthermore, the SLR identifies a range of features and computational models\nthat can seamlessly transition from related tasks like binary humour and\nsarcasm detection to invigorate humour style classification. These features\nencompass incongruity, sentiment and polarity analysis, ambiguity detection,\nacoustic nuances, visual cues, contextual insights, and more. The computational\nmodels that emerge contain traditional machine learning paradigms, neural\nnetwork architectures, transformer-based models, and specialised models attuned\nto the nuances of humour. Finally, the SLR provides access to existing datasets\nrelated to humour and sarcasm, facilitating the work of future researchers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01759v1",
    "published_date": "2024-01-30 16:21:47 UTC",
    "updated_date": "2024-01-30 16:21:47 UTC"
  },
  {
    "arxiv_id": "2401.17139v2",
    "title": "Diff-eRank: A Novel Rank-Based Metric for Evaluating Large Language Models",
    "authors": [
      "Lai Wei",
      "Zhiquan Tan",
      "Chenghai Li",
      "Jindong Wang",
      "Weiran Huang"
    ],
    "abstract": "Large Language Models (LLMs) have transformed natural language processing and\nextended their powerful capabilities to multi-modal domains. As LLMs continue\nto advance, it is crucial to develop diverse and appropriate metrics for their\nevaluation. In this paper, we introduce a novel rank-based metric, Diff-eRank,\ngrounded in information theory and geometry principles. Diff-eRank assesses\nLLMs by analyzing their hidden representations, providing a quantitative\nmeasure of how efficiently they eliminate redundant information during\ntraining. We demonstrate the applicability of Diff-eRank in both single-modal\n(e.g., language) and multi-modal settings. For language models, our results\nshow that Diff-eRank increases with model size and correlates well with\nconventional metrics such as loss and accuracy. In the multi-modal context, we\npropose an alignment evaluation method based on the eRank, and verify that\ncontemporary multi-modal LLMs exhibit strong alignment performance based on our\nmethod. Our code is publicly available at\nhttps://github.com/waltonfuture/Diff-eRank.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17139v2",
    "published_date": "2024-01-30 16:19:55 UTC",
    "updated_date": "2024-10-14 04:36:09 UTC"
  },
  {
    "arxiv_id": "2401.17133v2",
    "title": "SongBsAb: A Dual Prevention Approach against Singing Voice Conversion based Illegal Song Covers",
    "authors": [
      "Guangke Chen",
      "Yedi Zhang",
      "Fu Song",
      "Ting Wang",
      "Xiaoning Du",
      "Yang Liu"
    ],
    "abstract": "Singing voice conversion (SVC) automates song covers by converting a source\nsinging voice from a source singer into a new singing voice with the same\nlyrics and melody as the source, but sounds like being covered by the target\nsinger of some given target singing voices. However, it raises serious concerns\nabout copyright and civil right infringements. We propose SongBsAb, the first\nproactive approach to tackle SVC-based illegal song covers. SongBsAb adds\nperturbations to singing voices before releasing them, so that when they are\nused, the process of SVC will be interfered, leading to unexpected singing\nvoices. Perturbations are carefully crafted to (1) provide a dual prevention,\ni.e., preventing the singing voice from being used as the source and target\nsinging voice in SVC, by proposing a gender-transformation loss and a high/low\nhierarchy multi-target loss, respectively; and (2) be harmless, i.e., no\nside-effect on the enjoyment of protected songs, by refining a psychoacoustic\nmodel-based loss with the backing track as an additional masker, a unique\naccompanying element for singing voices compared to ordinary speech voices. We\nalso adopt a frame-level interaction reduction-based loss and encoder ensemble\nto enhance the transferability of SongBsAb to unknown SVC models. We\ndemonstrate the prevention effectiveness, harmlessness, and robustness of\nSongBsAb on five diverse and promising SVC models, using both English and\nChinese datasets, and both objective and human study-based subjective metrics.\nOur work fosters an emerging research direction for mitigating illegal\nautomated song covers.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "In Proceedings of the 32nd Network and Distributed System Security\n  (NDSS) Symposium 2025",
    "pdf_url": "http://arxiv.org/pdf/2401.17133v2",
    "published_date": "2024-01-30 16:07:44 UTC",
    "updated_date": "2024-12-01 04:06:27 UTC"
  },
  {
    "arxiv_id": "2401.17095v1",
    "title": "Traffic estimation in unobserved network locations using data-driven macroscopic models",
    "authors": [
      "Pablo Guarda",
      "Sean Qian"
    ],
    "abstract": "This paper leverages macroscopic models and multi-source spatiotemporal data\ncollected from automatic traffic counters and probe vehicles to accurately\nestimate traffic flow and travel time in links where these measurements are\nunavailable. This problem is critical in transportation planning applications\nwhere the sensor coverage is low and the planned interventions have\nnetwork-wide impacts. The proposed model, named the Macroscopic Traffic\nEstimator (MaTE), can perform network-wide estimations of traffic flow and\ntravel time only using the set of observed measurements of these quantities.\nBecause MaTE is grounded in macroscopic flow theory, all parameters and\nvariables are interpretable. The estimated traffic flow satisfies fundamental\nflow conservation constraints and exhibits an increasing monotonic relationship\nwith the estimated travel time. Using logit-based stochastic traffic assignment\nas the principle for routing flow behavior makes the model fully differentiable\nwith respect to the model parameters. This property facilitates the application\nof computational graphs to learn parameters from vast amounts of spatiotemporal\ndata. We also integrate neural networks and polynomial kernel functions to\ncapture link flow interactions and enrich the mapping of traffic flows into\ntravel times. MaTE also adds a destination choice model and a trip generation\nmodel that uses historical data on the number of trips generated by location.\nExperiments on synthetic data show that the model can accurately estimate\ntravel time and traffic flow in out-of-sample links. Results obtained using\nreal-world multi-source data from a large-scale transportation network suggest\nthat MaTE outperforms data-driven benchmarks, especially in travel time\nestimation. The estimated parameters of MaTE are also informative about the\nhourly change in travel demand and supply characteristics of the transportation\nnetwork.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages, 28 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.17095v1",
    "published_date": "2024-01-30 15:21:50 UTC",
    "updated_date": "2024-01-30 15:21:50 UTC"
  },
  {
    "arxiv_id": "2402.00068v3",
    "title": "Adapting Amidst Degradation: Cross Domain Li-ion Battery Health Estimation via Physics-Guided Test-Time Training",
    "authors": [
      "Yuyuan Feng",
      "Guosheng Hu",
      "Xiaodong Li",
      "Zhihong Zhang"
    ],
    "abstract": "Health modeling of lithium-ion batteries (LIBs) is crucial for safe and\nefficient energy management and carries significant socio-economic\nimplications. Although Machine Learning (ML)-based State of Health (SOH)\nestimation methods have made significant progress in accuracy, the scarcity of\nhigh-quality LIB data remains a major obstacle. Existing transfer learning\nmethods for cross-domain LIB SOH estimation have significantly alleviated the\nlabeling burden of target LIB data, however, they still require sufficient\nunlabeled target data (UTD) for effective adaptation to the target domain.\nCollecting this UTD is challenging due to the time-consuming nature of\ndegradation experiments. To address this issue, we introduce a practical\nTest-Time Training framework, BatteryTTT, which adapts the model continually\nusing each UTD collected amidst degradation, thereby significantly reducing\ndata collection time. To fully utilize each UTD, BatteryTTT integrates the\ninherent physical laws of modern LIBs into self-supervised learning, termed\nPhyscics-Guided Test-Time Training. Additionally, we explore the potential of\nlarge language models (LLMs) in battery sequence modeling by evaluating their\nperformance in SOH estimation through model reprogramming and prefix prompt\nadaptation. The combination of BatteryTTT and LLM modeling, termed GPT4Battery,\nachieves state-of-the-art generalization results across current LIB benchmarks.\nFurthermore, we demonstrate the practical value and scalability of our approach\nby deploying it in our real-world battery management system (BMS) for 300Ah\nlarge-scale energy storage LIBs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00068v3",
    "published_date": "2024-01-30 14:47:15 UTC",
    "updated_date": "2024-11-19 05:08:44 UTC"
  },
  {
    "arxiv_id": "2404.16038v1",
    "title": "A Survey on Generative AI and LLM for Video Generation, Understanding, and Streaming",
    "authors": [
      "Pengyuan Zhou",
      "Lin Wang",
      "Zhi Liu",
      "Yanbin Hao",
      "Pan Hui",
      "Sasu Tarkoma",
      "Jussi Kangasharju"
    ],
    "abstract": "This paper offers an insightful examination of how currently top-trending AI\ntechnologies, i.e., generative artificial intelligence (Generative AI) and\nlarge language models (LLMs), are reshaping the field of video technology,\nincluding video generation, understanding, and streaming. It highlights the\ninnovative use of these technologies in producing highly realistic videos, a\nsignificant leap in bridging the gap between real-world dynamics and digital\ncreation. The study also delves into the advanced capabilities of LLMs in video\nunderstanding, demonstrating their effectiveness in extracting meaningful\ninformation from visual content, thereby enhancing our interaction with videos.\nIn the realm of video streaming, the paper discusses how LLMs contribute to\nmore efficient and user-centric streaming experiences, adapting content\ndelivery to individual viewer preferences. This comprehensive review navigates\nthrough the current achievements, ongoing challenges, and future possibilities\nof applying Generative AI and LLMs to video-related tasks, underscoring the\nimmense potential these technologies hold for advancing the field of video\ntechnology related to multimedia, networking, and AI communities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 10 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.16038v1",
    "published_date": "2024-01-30 14:37:10 UTC",
    "updated_date": "2024-01-30 14:37:10 UTC"
  },
  {
    "arxiv_id": "2401.17053v4",
    "title": "BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation",
    "authors": [
      "Zhennan Wu",
      "Yang Li",
      "Han Yan",
      "Taizhang Shang",
      "Weixuan Sun",
      "Senbo Wang",
      "Ruikai Cui",
      "Weizhe Liu",
      "Hiroyuki Sato",
      "Hongdong Li",
      "Pan Ji"
    ],
    "abstract": "We present BlockFusion, a diffusion-based model that generates 3D scenes as\nunit blocks and seamlessly incorporates new blocks to extend the scene.\nBlockFusion is trained using datasets of 3D blocks that are randomly cropped\nfrom complete 3D scene meshes. Through per-block fitting, all training blocks\nare converted into the hybrid neural fields: with a tri-plane containing the\ngeometry features, followed by a Multi-layer Perceptron (MLP) for decoding the\nsigned distance values. A variational auto-encoder is employed to compress the\ntri-planes into the latent tri-plane space, on which the denoising diffusion\nprocess is performed. Diffusion applied to the latent representations allows\nfor high-quality and diverse 3D scene generation. To expand a scene during\ngeneration, one needs only to append empty blocks to overlap with the current\nscene and extrapolate existing latent tri-planes to populate new blocks. The\nextrapolation is done by conditioning the generation process with the feature\nsamples from the overlapping tri-planes during the denoising iterations. Latent\ntri-plane extrapolation produces semantically and geometrically meaningful\ntransitions that harmoniously blend with the existing scene. A 2D layout\nconditioning mechanism is used to control the placement and arrangement of\nscene elements. Experimental results indicate that BlockFusion is capable of\ngenerating diverse, geometrically consistent and unbounded large 3D scenes with\nunprecedented high-quality shapes in both indoor and outdoor scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "ACM Transactions on Graphics (SIGGRAPH'24). Code:\n  https://yang-l1.github.io/blockfusion",
    "pdf_url": "http://arxiv.org/pdf/2401.17053v4",
    "published_date": "2024-01-30 14:34:19 UTC",
    "updated_date": "2024-05-24 03:56:20 UTC"
  },
  {
    "arxiv_id": "2401.17050v1",
    "title": "ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization",
    "authors": [
      "Danning Lao",
      "Qi Liu",
      "Jiazi Bu",
      "Junchi Yan",
      "Wei Shen"
    ],
    "abstract": "As computer vision continues to advance and finds widespread applications\nacross various domains, the need for interpretability in deep learning models\nbecomes paramount. Existing methods often resort to post-hoc techniques or\nprototypes to explain the decision-making process, which can be indirect and\nlack intrinsic illustration. In this research, we introduce ViTree, a novel\napproach for fine-grained visual categorization that combines the popular\nvision transformer as a feature extraction backbone with neural decision trees.\nBy traversing the tree paths, ViTree effectively selects patches from\ntransformer-processed features to highlight informative local regions, thereby\nrefining representations in a step-wise manner. Unlike previous tree-based\nmodels that rely on soft distributions or ensembles of paths, ViTree selects a\nsingle tree path, offering a clearer and simpler decision-making process. This\npatch and path selectivity enhances model interpretability of ViTree, enabling\nbetter insights into the model's inner workings. Remarkably, extensive\nexperimentation validates that this streamlined approach surpasses various\nstrong competitors and achieves state-of-the-art performance while maintaining\nexceptional interpretability which is proved by multi-perspective methods. Code\ncan be found at https://github.com/SJTU-DeepVisionLab/ViTree.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17050v1",
    "published_date": "2024-01-30 14:32:25 UTC",
    "updated_date": "2024-01-30 14:32:25 UTC"
  },
  {
    "arxiv_id": "2401.17045v5",
    "title": "Explaining Explanations in Probabilistic Logic Programming",
    "authors": [
      "Germán Vidal"
    ],
    "abstract": "The emergence of tools based on artificial intelligence has also led to the\nneed of producing explanations which are understandable by a human being. In\nmost approaches, the system is considered a black box, making it difficult to\ngenerate appropriate explanations. In this work, though, we consider a setting\nwhere models are transparent: probabilistic logic programming (PLP), a paradigm\nthat combines logic programming for knowledge representation and probability to\nmodel uncertainty. However, given a query, the usual notion of explanation is\nassociated with a set of choices, one for each random variable of the model.\nUnfortunately, such a set does not explain why the query is true and, in fact,\nit may contain choices that are actually irrelevant for the considered query.\nTo improve this situation, we present in this paper an approach to explaining\nexplanations which is based on defining a new query-driven inference mechanism\nfor PLP where proofs are labeled with \"choice expressions\", a compact and easy\nto manipulate representation for sets of choices. The combination of proof\ntrees and choice expressions allows us to produce comprehensible query\njustifications with a causal structure.",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Programming Languages and Systems (Proceedings of APLAS 2024),\n  Springer LNCS, 2024, and is available online at\n  https://doi.org/10.1007/978-981-97-8943-6_7",
    "pdf_url": "http://arxiv.org/pdf/2401.17045v5",
    "published_date": "2024-01-30 14:27:37 UTC",
    "updated_date": "2024-10-22 03:06:48 UTC"
  },
  {
    "arxiv_id": "2401.17044v2",
    "title": "Scalable Mechanism Design for Multi-Agent Path Finding",
    "authors": [
      "Paul Friedrich",
      "Yulun Zhang",
      "Michael Curry",
      "Ludwig Dierks",
      "Stephen McAleer",
      "Jiaoyang Li",
      "Tuomas Sandholm",
      "Sven Seuken"
    ],
    "abstract": "Multi-Agent Path Finding (MAPF) involves determining paths for multiple\nagents to travel simultaneously and collision-free through a shared area toward\ngiven goal locations. This problem is computationally complex, especially when\ndealing with large numbers of agents, as is common in realistic applications\nlike autonomous vehicle coordination. Finding an optimal solution is often\ncomputationally infeasible, making the use of approximate, suboptimal\nalgorithms essential. Adding to the complexity, agents might act in a\nself-interested and strategic way, possibly misrepresenting their goals to the\nMAPF algorithm if it benefits them. Although the field of mechanism design\noffers tools to align incentives, using these tools without careful\nconsideration can fail when only having access to approximately optimal\noutcomes. In this work, we introduce the problem of scalable mechanism design\nfor MAPF and propose three strategyproof mechanisms, two of which even use\napproximate MAPF algorithms. We test our mechanisms on realistic MAPF domains\nwith problem sizes ranging from dozens to hundreds of agents. We find that they\nimprove welfare beyond a simple baseline.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5 figures. IJCAI'24 camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2401.17044v2",
    "published_date": "2024-01-30 14:26:04 UTC",
    "updated_date": "2024-05-08 14:03:20 UTC"
  },
  {
    "arxiv_id": "2401.17343v1",
    "title": "YTCommentQA: Video Question Answerability in Instructional Videos",
    "authors": [
      "Saelyne Yang",
      "Sunghyun Park",
      "Yunseok Jang",
      "Moontae Lee"
    ],
    "abstract": "Instructional videos provide detailed how-to guides for various tasks, with\nviewers often posing questions regarding the content. Addressing these\nquestions is vital for comprehending the content, yet receiving immediate\nanswers is difficult. While numerous computational models have been developed\nfor Video Question Answering (Video QA) tasks, they are primarily trained on\nquestions generated based on video content, aiming to produce answers from\nwithin the content. However, in real-world situations, users may pose questions\nthat go beyond the video's informational boundaries, highlighting the necessity\nto determine if a video can provide the answer. Discerning whether a question\ncan be answered by video content is challenging due to the multi-modal nature\nof videos, where visual and verbal information are intertwined. To bridge this\ngap, we present the YTCommentQA dataset, which contains naturally-generated\nquestions from YouTube, categorized by their answerability and required\nmodality to answer -- visual, script, or both. Experiments with answerability\nclassification tasks demonstrate the complexity of YTCommentQA and emphasize\nthe need to comprehend the combined role of visual and script information in\nvideo reasoning. The dataset is available at\nhttps://github.com/lgresearch/YTCommentQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17343v1",
    "published_date": "2024-01-30 14:18:37 UTC",
    "updated_date": "2024-01-30 14:18:37 UTC"
  },
  {
    "arxiv_id": "2401.17010v5",
    "title": "Finetuning Large Language Models for Vulnerability Detection",
    "authors": [
      "Alexey Shestov",
      "Rodion Levichev",
      "Ravil Mussabayev",
      "Evgeny Maslov",
      "Anton Cheshkov",
      "Pavel Zadorozhny"
    ],
    "abstract": "This paper presents the results of finetuning large language models (LLMs)\nfor the task of detecting vulnerabilities in source code. We leverage\nWizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and\nadapt it for vulnerability detection through further finetuning. To accelerate\ntraining, we modify WizardCoder's training procedure, also we investigate\noptimal training regimes. For the imbalanced dataset with many more negative\nexamples than positive, we also explore different techniques to improve\nclassification performance. The finetuned WizardCoder model achieves\nimprovement in ROC AUC and F1 measures on balanced and imbalanced vulnerability\ndatasets over CodeBERT-like model, demonstrating the effectiveness of adapting\npretrained LLMs for vulnerability detection in source code. The key\ncontributions are finetuning the state-of-the-art code LLM, WizardCoder,\nincreasing its training speed without the performance harm, optimizing the\ntraining procedure and regimes, handling class imbalance, and improving\nperformance on difficult vulnerability detection datasets. This demonstrates\nthe potential for transfer learning by finetuning large pretrained language\nmodels for specialized source code analysis tasks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17010v5",
    "published_date": "2024-01-30 13:46:49 UTC",
    "updated_date": "2024-07-27 11:22:39 UTC"
  },
  {
    "arxiv_id": "2401.17342v2",
    "title": "A Latent Space Metric for Enhancing Prediction Confidence in Earth Observation Data",
    "authors": [
      "Ioannis Pitsiorlas",
      "Argyro Tsantalidou",
      "George Arvanitakis",
      "Marios Kountouris",
      "Charalambos Kontoes"
    ],
    "abstract": "This study presents a new approach for estimating confidence in machine\nlearning model predictions, specifically in regression tasks utilizing Earth\nObservation (EO) data, with a particular focus on mosquito abundance (MA)\nestimation. We take advantage of a Variational AutoEncoder architecture, to\nderive a confidence metric by the latent space representations of EO datasets.\nThis methodology is pivotal in establishing a correlation between the Euclidean\ndistance in latent representations and the Absolute Error (AE) in individual MA\npredictions. Our research focuses on EO datasets from the Veneto region in\nItaly and the Upper Rhine Valley in Germany, targeting areas significantly\naffected by mosquito populations. A key finding is a notable correlation of\n0.46 between the AE of MA predictions and the proposed confidence metric. This\ncorrelation signifies a robust, new metric for quantifying the reliability and\nenhancing the trustworthiness of the AI model's predictions in the context of\nboth EO data analysis and mosquito abundance studies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17342v2",
    "published_date": "2024-01-30 13:41:12 UTC",
    "updated_date": "2024-06-11 08:00:22 UTC"
  },
  {
    "arxiv_id": "2402.07913v2",
    "title": "QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners",
    "authors": [
      "Rui Xiao",
      "Lu Han",
      "Xiaoying Zhou",
      "Jiong Wang",
      "Na Zong",
      "Pengyu Zhang"
    ],
    "abstract": "In online learning platforms, particularly in rapidly growing computer\nprogramming courses, addressing the thousands of students' learning queries\nrequires considerable human cost. The creation of intelligent assistant large\nlanguage models (LLMs) tailored for programming education necessitates distinct\ndata support. However, in real application scenarios, the data resources for\ntraining such LLMs are relatively scarce. Therefore, to address the data\nscarcity in intelligent educational systems for programming, this paper\nproposes a new Chinese question-and-answer dataset for Python learners. To\nensure the authenticity and reliability of the sources of the questions, we\ncollected questions from actual student questions and categorized them\naccording to various dimensions such as the type of questions and the type of\nlearners. This annotation principle is designed to enhance the effectiveness\nand quality of online programming education, providing a solid data foundation\nfor developing the programming teaching assists (TA). Furthermore, we conducted\ncomprehensive evaluations of various LLMs proficient in processing and\ngenerating Chinese content, highlighting the potential limitations of general\nLLMs as intelligent teaching assistants in computer programming courses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07913v2",
    "published_date": "2024-01-30 13:11:23 UTC",
    "updated_date": "2024-02-23 02:35:41 UTC"
  },
  {
    "arxiv_id": "2401.16982v1",
    "title": "ActDroid: An active learning framework for Android malware detection",
    "authors": [
      "Ali Muzaffar",
      "Hani Ragab Hassen",
      "Hind Zantout",
      "Michael A Lones"
    ],
    "abstract": "The growing popularity of Android requires malware detection systems that can\nkeep up with the pace of new software being released. According to a recent\nstudy, a new piece of malware appears online every 12 seconds. To address this,\nwe treat Android malware detection as a streaming data problem and explore the\nuse of active online learning as a means of mitigating the problem of labelling\napplications in a timely and cost-effective manner. Our resulting framework\nachieves accuracies of up to 96\\%, requires as little of 24\\% of the training\ndata to be labelled, and compensates for concept drift that occurs between the\nrelease and labelling of an application. We also consider the broader\npracticalities of online learning within Android malware detection, and\nsystematically explore the trade-offs between using different static, dynamic\nand hybrid feature sets to classify malware.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16982v1",
    "published_date": "2024-01-30 13:10:33 UTC",
    "updated_date": "2024-01-30 13:10:33 UTC"
  },
  {
    "arxiv_id": "2401.16974v1",
    "title": "CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning",
    "authors": [
      "Andreas W. M. Sauter",
      "Nicolò Botteghi",
      "Erman Acar",
      "Aske Plaat"
    ],
    "abstract": "Causal discovery is the challenging task of inferring causal structure from\ndata. Motivated by Pearl's Causal Hierarchy (PCH), which tells us that passive\nobservations alone are not enough to distinguish correlation from causation,\nthere has been a recent push to incorporate interventions into machine learning\nresearch. Reinforcement learning provides a convenient framework for such an\nactive approach to learning. This paper presents CORE, a deep reinforcement\nlearning-based approach for causal discovery and intervention planning. CORE\nlearns to sequentially reconstruct causal graphs from data while learning to\nperform informative interventions. Our results demonstrate that CORE\ngeneralizes to unseen graphs and efficiently uncovers causal structures.\nFurthermore, CORE scales to larger graphs with up to 10 variables and\noutperforms existing approaches in structure estimation accuracy and sample\nefficiency. All relevant code and supplementary material can be found at\nhttps://github.com/sa-and/CORE",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published In Proc. of the 23rd International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2024), Auckland, New Zealand,\n  May 6 - 10, 2024, IFAAMAS",
    "pdf_url": "http://arxiv.org/pdf/2401.16974v1",
    "published_date": "2024-01-30 12:57:52 UTC",
    "updated_date": "2024-01-30 12:57:52 UTC"
  },
  {
    "arxiv_id": "2401.16960v1",
    "title": "Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment",
    "authors": [
      "Linyao Yang",
      "Hongyang Chen",
      "Xiao Wang",
      "Jing Yang",
      "Fei-Yue Wang",
      "Han Liu"
    ],
    "abstract": "Entity alignment, which is a prerequisite for creating a more comprehensive\nKnowledge Graph (KG), involves pinpointing equivalent entities across disparate\nKGs. Contemporary methods for entity alignment have predominantly utilized\nknowledge embedding models to procure entity embeddings that encapsulate\nvarious similarities-structural, relational, and attributive. These embeddings\nare then integrated through attention-based information fusion mechanisms.\nDespite this progress, effectively harnessing multifaceted information remains\nchallenging due to inherent heterogeneity. Moreover, while Large Language\nModels (LLMs) have exhibited exceptional performance across diverse downstream\ntasks by implicitly capturing entity semantics, this implicit knowledge has yet\nto be exploited for entity alignment. In this study, we propose a Large\nLanguage Model-enhanced Entity Alignment framework (LLMEA), integrating\nstructural knowledge from KGs with semantic knowledge from LLMs to enhance\nentity alignment. Specifically, LLMEA identifies candidate alignments for a\ngiven entity by considering both embedding similarities between entities across\nKGs and edit distances to a virtual equivalent entity. It then engages an LLM\niteratively, posing multiple multi-choice questions to draw upon the LLM's\ninference capability. The final prediction of the equivalent entity is derived\nfrom the LLM's output. Experiments conducted on three public datasets reveal\nthat LLMEA surpasses leading baseline models. Additional ablation studies\nunderscore the efficacy of our proposed framework.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16960v1",
    "published_date": "2024-01-30 12:41:04 UTC",
    "updated_date": "2024-01-30 12:41:04 UTC"
  },
  {
    "arxiv_id": "2402.01758v1",
    "title": "Aalap: AI Assistant for Legal & Paralegal Functions in India",
    "authors": [
      "Aman Tiwari",
      "Prathamesh Kalamkar",
      "Atreyo Banerjee",
      "Saurabh Karn",
      "Varun Hemachandran",
      "Smita Gupta"
    ],
    "abstract": "Using proprietary Large Language Models on legal tasks poses challenges due\nto data privacy issues, domain data heterogeneity, domain knowledge\nsophistication, and domain objectives uniqueness. We created Aalalp, a\nfine-tuned Mistral 7B model on instructions data related to specific Indian\nlegal tasks. The performance of Aalap is better than gpt-3.5-turbo in 31\\% of\nour test data and obtains an equivalent score in 34\\% of the test data as\nevaluated by GPT4. Training Aalap mainly focuses on teaching legal reasoning\nrather than legal recall. Aalap is definitely helpful for the day-to-day\nactivities of lawyers, judges, or anyone working in legal systems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01758v1",
    "published_date": "2024-01-30 12:39:58 UTC",
    "updated_date": "2024-01-30 12:39:58 UTC"
  },
  {
    "arxiv_id": "2402.07912v1",
    "title": "Spatial Computing: Concept, Applications, Challenges and Future Directions",
    "authors": [
      "Gokul Yenduri",
      "Ramalingam M",
      "Praveen Kumar Reddy Maddikunta",
      "Thippa Reddy Gadekallu",
      "Rutvij H Jhaveri",
      "Ajay Bandi",
      "Junxin Chen",
      "Wei Wang",
      "Adarsh Arunkumar Shirawalmath",
      "Raghav Ravishankar",
      "Weizheng Wang"
    ],
    "abstract": "Spatial computing is a technological advancement that facilitates the\nseamless integration of devices into the physical environment, resulting in a\nmore natural and intuitive digital world user experience. Spatial computing has\nthe potential to become a significant advancement in the field of computing.\nFrom GPS and location-based services to healthcare, spatial computing\ntechnologies have influenced and improved our interactions with the digital\nworld. The use of spatial computing in creating interactive digital\nenvironments has become increasingly popular and effective. This is explained\nby its increasing significance among researchers and industrial organisations,\nwhich motivated us to conduct this review. This review provides a detailed\noverview of spatial computing, including its enabling technologies and its\nimpact on various applications. Projects related to spatial computing are also\ndiscussed. In this review, we also explored the potential challenges and\nlimitations of spatial computing. Furthermore, we discuss potential solutions\nand future directions. Overall, this paper aims to provide a comprehensive\nunderstanding of spatial computing, its enabling technologies, their impact on\nvarious applications, emerging challenges, and potential solutions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted to peer reviewe",
    "pdf_url": "http://arxiv.org/pdf/2402.07912v1",
    "published_date": "2024-01-30 11:47:12 UTC",
    "updated_date": "2024-01-30 11:47:12 UTC"
  },
  {
    "arxiv_id": "2401.16889v2",
    "title": "Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control",
    "authors": [
      "Zhongyu Li",
      "Xue Bin Peng",
      "Pieter Abbeel",
      "Sergey Levine",
      "Glen Berseth",
      "Koushil Sreenath"
    ],
    "abstract": "This paper presents a comprehensive study on using deep reinforcement\nlearning (RL) to create dynamic locomotion controllers for bipedal robots.\nGoing beyond focusing on a single locomotion skill, we develop a general\ncontrol solution that can be used for a range of dynamic bipedal skills, from\nperiodic walking and running to aperiodic jumping and standing. Our RL-based\ncontroller incorporates a novel dual-history architecture, utilizing both a\nlong-term and short-term input/output (I/O) history of the robot. This control\narchitecture, when trained through the proposed end-to-end RL approach,\nconsistently outperforms other methods across a diverse range of skills in both\nsimulation and the real world. The study also delves into the adaptivity and\nrobustness introduced by the proposed RL system in developing locomotion\ncontrollers. We demonstrate that the proposed architecture can adapt to both\ntime-invariant dynamics shifts and time-variant changes, such as contact\nevents, by effectively using the robot's I/O history. Additionally, we identify\ntask randomization as another key source of robustness, fostering better task\ngeneralization and compliance to disturbances. The resulting control policies\ncan be successfully deployed on Cassie, a torque-controlled human-sized bipedal\nrobot. This work pushes the limits of agility for bipedal robots through\nextensive real-world experiments. We demonstrate a diverse range of locomotion\nskills, including: robust standing, versatile walking, fast running with a\ndemonstration of a 400-meter dash, and a diverse set of jumping skills, such as\nstanding long jumps and high jumps.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in International Journal of Robotics Research (IJRR) 2024.\n  This is the author's version and will no longer be updated as the copyright\n  may get transferred at anytime",
    "pdf_url": "http://arxiv.org/pdf/2401.16889v2",
    "published_date": "2024-01-30 10:48:43 UTC",
    "updated_date": "2024-08-26 06:51:23 UTC"
  },
  {
    "arxiv_id": "2403.08790v1",
    "title": "Using Sequential Runtime Distributions for the Parallel Speedup Prediction of SAT Local Search",
    "authors": [
      "Alejandro Arbelaez",
      "Charlotte Truchet",
      "Philippe Codognet"
    ],
    "abstract": "This paper presents a detailed analysis of the scalability and\nparallelization of local search algorithms for the Satisfiability problem. We\npropose a framework to estimate the parallel performance of a given algorithm\nby analyzing the runtime behavior of its sequential version. Indeed, by\napproximating the runtime distribution of the sequential process with\nstatistical methods, the runtime behavior of the parallel process can be\npredicted by a model based on order statistics. We apply this approach to study\nthe parallel performance of two SAT local search solvers, namely Sparrow and\nCCASAT, and compare the predicted performances to the results of an actual\nexperimentation on parallel hardware up to 384 cores. We show that the model is\naccurate and predicts performance close to the empirical data. Moreover, as we\nstudy different types of instances (random and crafted), we observe that the\nlocal search solvers exhibit different behaviors and that their runtime\ndistributions can be approximated by two types of distributions: exponential\n(shifted and non-shifted) and lognormal.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08790v1",
    "published_date": "2024-01-30 10:29:01 UTC",
    "updated_date": "2024-01-30 10:29:01 UTC"
  },
  {
    "arxiv_id": "2401.16867v1",
    "title": "A Tournament of Transformation Models: B-Spline-based vs. Mesh-based Multi-Objective Deformable Image Registration",
    "authors": [
      "Georgios Andreadis",
      "Joas I. Mulder",
      "Anton Bouter",
      "Peter A. N. Bosman",
      "Tanja Alderliesten"
    ],
    "abstract": "The transformation model is an essential component of any deformable image\nregistration approach. It provides a representation of physical deformations\nbetween images, thereby defining the range and realism of registrations that\ncan be found. Two types of transformation models have emerged as popular\nchoices: B-spline models and mesh models. Although both models have been\ninvestigated in detail, a direct comparison has not yet been made, since the\nmodels are optimized using very different optimization methods in practice.\nB-spline models are predominantly optimized using gradient-descent methods,\nwhile mesh models are typically optimized using finite-element method solvers\nor evolutionary algorithms. Multi-objective optimization methods, which aim to\nfind a diverse set of high-quality trade-off registrations, are increasingly\nacknowledged to be important in deformable image registration. Since these\nmethods search for a diverse set of registrations, they can provide a more\ncomplete picture of the capabilities of different transformation models, making\nthem suitable for a comparison of models. In this work, we conduct the first\ndirect comparison between B-spline and mesh transformation models, by\noptimizing both models with the same state-of-the-art multi-objective\noptimization method, the Multi-Objective Real-Valued Gene-pool Optimal Mixing\nEvolutionary Algorithm (MO-RV-GOMEA). The combination with B-spline\ntransformation models, moreover, is novel. We experimentally compare both\nmodels on two different registration problems that are both based on pelvic CT\nscans of cervical cancer patients, featuring large deformations. Our results,\non three cervical cancer patients, indicate that the choice of transformation\nmodel can have a profound impact on the diversity and quality of achieved\nregistration outcomes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "Pre-print for the SPIE Medical Imaging: Image Processing Conference",
    "pdf_url": "http://arxiv.org/pdf/2401.16867v1",
    "published_date": "2024-01-30 10:17:46 UTC",
    "updated_date": "2024-01-30 10:17:46 UTC"
  },
  {
    "arxiv_id": "2403.08789v1",
    "title": "Bridging Human Concepts and Computer Vision for Explainable Face Verification",
    "authors": [
      "Miriam Doh",
      "Caroline Mazini Rodrigues",
      "Nicolas Boutry",
      "Laurent Najman",
      "Matei Mancas",
      "Hugues Bersini"
    ],
    "abstract": "With Artificial Intelligence (AI) influencing the decision-making process of\nsensitive applications such as Face Verification, it is fundamental to ensure\nthe transparency, fairness, and accountability of decisions. Although\nExplainable Artificial Intelligence (XAI) techniques exist to clarify AI\ndecisions, it is equally important to provide interpretability of these\ndecisions to humans. In this paper, we present an approach to combine computer\nand human vision to increase the explanation's interpretability of a face\nverification algorithm. In particular, we are inspired by the human perceptual\nprocess to understand how machines perceive face's human-semantic areas during\nface comparison tasks. We use Mediapipe, which provides a segmentation\ntechnique that identifies distinct human-semantic facial regions, enabling the\nmachine's perception analysis. Additionally, we adapted two model-agnostic\nalgorithms to provide human-interpretable insights into the decision-making\nprocesses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08789v1",
    "published_date": "2024-01-30 09:13:49 UTC",
    "updated_date": "2024-01-30 09:13:49 UTC"
  },
  {
    "arxiv_id": "2402.03362v1",
    "title": "NanoNER: Named Entity Recognition for nanobiology using experts' knowledge and distant supervision",
    "authors": [
      "Martin Lentschat",
      "Cyril Labbé",
      "Ran Cheng"
    ],
    "abstract": "Here we present the training and evaluation of NanoNER, a Named Entity\nRecognition (NER) model for Nanobiology. NER consists in the identification of\nspecific entities in spans of unstructured texts and is often a primary task in\nNatural Language Processing (NLP) and Information Extraction. The aim of our\nmodel is to recognise entities previously identified by domain experts as\nconstituting the essential knowledge of the domain. Relying on ontologies,\nwhich provide us with a domain vocabulary and taxonomy, we implemented an\niterative process enabling experts to determine the entities relevant to the\ndomain at hand. We then delve into the potential of distant supervision\nlearning in NER, supporting how this method can increase the quantity of\nannotated data with minimal additional manpower. On our full corpus of 728\nfull-text nanobiology articles, containing more than 120k entity occurrences,\nNanoNER obtained a F1-score of 0.98 on the recognition of previously known\nentities. Our model also demonstrated its ability to discover new entities in\nthe text, with precision scores ranging from 0.77 to 0.81. Ablation experiments\nfurther confirmed this and allowed us to assess the dependency of our approach\non the external resources. It highlighted the dependency of the approach to the\nresource, while also confirming its ability to rediscover up to 30% of the\nablated terms. This paper details the methodology employed, experimental\ndesign, and key findings, providing valuable insights and directions for future\nrelated researches on NER in specialized domain. Furthermore, since our\napproach require minimal manpower , we believe that it can be generalized to\nother specialized fields.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03362v1",
    "published_date": "2024-01-30 09:10:53 UTC",
    "updated_date": "2024-01-30 09:10:53 UTC"
  },
  {
    "arxiv_id": "2403.08788v1",
    "title": "Verification for Object Detection -- IBP IoU",
    "authors": [
      "Noémie Cohen",
      "Mélanie Ducoffe",
      "Ryma Boumazouza",
      "Christophe Gabreau",
      "Claire Pagetti",
      "Xavier Pucel",
      "Audrey Galametz"
    ],
    "abstract": "We introduce a novel Interval Bound Propagation (IBP) approach for the formal\nverification of object detection models, specifically targeting the\nIntersection over Union (IoU) metric. The approach has been implemented in an\nopen source code, named IBP IoU, compatible with popular abstract\ninterpretation based verification tools. The resulting verifier is evaluated on\nlanding approach runway detection and handwritten digit recognition case\nstudies. Comparisons against a baseline (Vanilla IBP IoU) highlight the\nsuperior performance of IBP IoU in ensuring accuracy and stability,\ncontributing to more secure and robust machine learning applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08788v1",
    "published_date": "2024-01-30 09:05:38 UTC",
    "updated_date": "2024-01-30 09:05:38 UTC"
  },
  {
    "arxiv_id": "2402.07911v1",
    "title": "Does mapping elites illuminate search spaces? A large-scale user study of MAP--Elites applied to human--AI collaborative design",
    "authors": [
      "Sean P. Walton",
      "Ben J. Evans",
      "Alma A. M. Rahat",
      "James Stovold",
      "Jakub Vincalek"
    ],
    "abstract": "Two studies of a human-AI collaborative design tool were carried out in order\nto understand the influence design recommendations have on the design process.\nThe tool investigated is based on an evolutionary algorithm attempting to\ndesign a virtual car to travel as far as possible in a fixed time. Participants\nwere able to design their own cars, make recommendations to the algorithm and\nview sets of recommendations from the algorithm. The algorithm-recommended sets\nwere designs which had been previously tested; some sets were simply randomly\npicked and other sets were picked using MAP-Elites. In the first study 808\ndesign sessions were recorded as part of a science outreach program, each with\nanalytical data of how each participant used the tool. To provide context to\nthis quantitative data, a smaller double-blind lab study was also carried out\nwith 12 participants. In the lab study the same quantitative data from the\nlarge scale study was collected alongside responses to interview questions.\nAlthough there is some evidence that the MAP-Elites provide higher-quality\nindividual recommendations, neither study provides convincing evidence that\nthese recommendations have a more positive influence on the design process than\nsimply a random selection of designs. In fact, it seems that providing a\ncombination of MAP-Elites and randomly selected recommendations is beneficial\nto the process. Furthermore, simply viewing recommendations from the MAP-Elites\nhad a positive influence on engagement in the design task and the quality of\nthe final design produced. Our findings are significant both for researchers\ndesigning new mixed-initiative tools, and those who wish to evaluate existing\ntools. Most significantly, we found that metrics researchers currently use to\nevaluate the success of human-AI collaborative algorithms do not measure the\nfull influence these algorithms have on the design process.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CE",
      "cs.NE",
      "I.2.0; J.6; G.1.6"
    ],
    "primary_category": "cs.HC",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.07911v1",
    "published_date": "2024-01-30 08:54:46 UTC",
    "updated_date": "2024-01-30 08:54:46 UTC"
  },
  {
    "arxiv_id": "2402.09442v3",
    "title": "Progress in artificial intelligence applications based on the combination of self-driven sensors and deep learning",
    "authors": [
      "Weixiang Wan",
      "Wenjian Sun",
      "Qiang Zeng",
      "Linying Pan",
      "Jingyu Xu",
      "Bo Liu"
    ],
    "abstract": "In the era of Internet of Things, how to develop a smart sensor system with\nsustainable power supply, easy deployment and flexible use has become a\ndifficult problem to be solved. The traditional power supply has problems such\nas frequent replacement or charging when in use, which limits the development\nof wearable devices. The contact-to-separate friction nanogenerator (TENG) was\nprepared by using polychotomy thy lene (PTFE) and aluminum (AI) foils. Human\nmotion energy was collected by human body arrangement, and human motion posture\nwas monitored according to the changes of output electrical signals. In 2012,\nAcademician Wang Zhong lin and his team invented the triboelectric\nnanogenerator (TENG), which uses Maxwell displacement current as a driving\nforce to directly convert mechanical stimuli into electrical signals, so it can\nbe used as a self-driven sensor. Teng-based sensors have the advantages of\nsimple structure and high instantaneous power density, which provides an\nimportant means for building intelligent sensor systems. At the same time,\nmachine learning, as a technology with low cost, short development cycle,\nstrong data processing ability and prediction ability, has a significant effect\non the processing of a large number of electrical signals generated by TENG,\nand the combination with TENG sensors will promote the rapid development of\nintelligent sensor networks in the future. Therefore, this paper is based on\nthe intelligent sound monitoring and recognition system of TENG, which has good\nsound recognition capability, and aims to evaluate the feasibility of the sound\nperception module architecture in ubiquitous sensor networks.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "This aticle was accepted by ieee conference",
    "pdf_url": "http://arxiv.org/pdf/2402.09442v3",
    "published_date": "2024-01-30 08:53:54 UTC",
    "updated_date": "2024-03-12 11:14:15 UTC"
  },
  {
    "arxiv_id": "2403.09669v3",
    "title": "STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models",
    "authors": [
      "Pum Jun Kim",
      "Seojun Kim",
      "Jaejun Yoo"
    ],
    "abstract": "Image generative models have made significant progress in generating\nrealistic and diverse images, supported by comprehensive guidance from various\nevaluation metrics. However, current video generative models struggle to\ngenerate even short video clips, with limited tools that provide insights for\nimprovements. Current video evaluation metrics are simple adaptations of image\nmetrics by switching the embeddings with video embedding networks, which may\nunderestimate the unique characteristics of video. Our analysis reveals that\nthe widely used Frechet Video Distance (FVD) has a stronger emphasis on the\nspatial aspect than the temporal naturalness of video and is inherently\nconstrained by the input size of the embedding networks used, limiting it to 16\nframes. Additionally, it demonstrates considerable instability and diverges\nfrom human evaluations. To address the limitations, we propose STREAM, a new\nvideo evaluation metric uniquely designed to independently evaluate spatial and\ntemporal aspects. This feature allows comprehensive analysis and evaluation of\nvideo generative models from various perspectives, unconstrained by video\nlength. We provide analytical and experimental evidence demonstrating that\nSTREAM provides an effective evaluation tool for both visual and temporal\nquality of videos, offering insights into area of improvement for video\ngenerative models. To the best of our knowledge, STREAM is the first evaluation\nmetric that can separately assess the temporal and spatial aspects of videos.\nOur code is available at https://github.com/pro2nit/STREAM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Our work is accepted to ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09669v3",
    "published_date": "2024-01-30 08:18:20 UTC",
    "updated_date": "2024-03-28 04:45:23 UTC"
  },
  {
    "arxiv_id": "2401.16808v3",
    "title": "Encoding Temporal Statistical-space Priors via Augmented Representation",
    "authors": [
      "Insu Choi",
      "Woosung Koh",
      "Gimin Kang",
      "Yuntae Jang",
      "Woo Chang Kim"
    ],
    "abstract": "Modeling time series data remains a pervasive issue as the temporal dimension\nis inherent to numerous domains. Despite significant strides in time series\nforecasting, high noise-to-signal ratio, non-normality, non-stationarity, and\nlack of data continue challenging practitioners. In response, we leverage a\nsimple representation augmentation technique to overcome these challenges. Our\naugmented representation acts as a statistical-space prior encoded at each time\nstep. In response, we name our method Statistical-space Augmented\nRepresentation (SSAR). The underlying high-dimensional data-generating process\ninspires our representation augmentation. We rigorously examine the empirical\ngeneralization performance on two data sets with two downstream temporal\nlearning algorithms. Our approach significantly beats all five up-to-date\nbaselines. Moreover, the highly modular nature of our approach can easily be\napplied to various settings. Lastly, fully-fledged theoretical perspectives are\navailable throughout the writing for a clear and rigorous understanding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI 2024 STRL Workshop (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2401.16808v3",
    "published_date": "2024-01-30 08:11:36 UTC",
    "updated_date": "2024-08-12 06:36:13 UTC"
  },
  {
    "arxiv_id": "2402.01752v1",
    "title": "Identifying False Content and Hate Speech in Sinhala YouTube Videos by Analyzing the Audio",
    "authors": [
      "W. A. K. M. Wickramaarachchi",
      "Sameeri Sathsara Subasinghe",
      "K. K. Rashani Tharushika Wijerathna",
      "A. Sahashra Udani Athukorala",
      "Lakmini Abeywardhana",
      "A. Karunasena"
    ],
    "abstract": "YouTube faces a global crisis with the dissemination of false information and\nhate speech. To counter these issues, YouTube has implemented strict rules\nagainst uploading content that includes false information or promotes hate\nspeech. While numerous studies have been conducted to reduce offensive\nEnglish-language content, there's a significant lack of research on Sinhala\ncontent. This study aims to address the aforementioned gap by proposing a\nsolution to minimize the spread of violence and misinformation in Sinhala\nYouTube videos. The approach involves developing a rating system that assesses\nwhether a video contains false information by comparing the title and\ndescription with the audio content and evaluating whether the video includes\nhate speech. The methodology encompasses several steps, including audio\nextraction using the Pytube library, audio transcription via the fine-tuned\nWhisper model, hate speech detection employing the distilroberta-base model and\na text classification LSTM model, and text summarization through the fine-tuned\nBART-Large- XSUM model. Notably, the Whisper model achieved a 48.99\\% word\nerror rate, while the distilroberta-base model demonstrated an F1 score of\n0.856 and a recall value of 0.861 in comparison to the LSTM model, which\nexhibited signs of overfitting.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01752v1",
    "published_date": "2024-01-30 08:08:34 UTC",
    "updated_date": "2024-01-30 08:08:34 UTC"
  },
  {
    "arxiv_id": "2401.16807v2",
    "title": "Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?",
    "authors": [
      "Teddy Lazebnik",
      "Ariel Rosenfeld"
    ],
    "abstract": "Large Language Models (LLMs), exemplified by ChatGPT, have significantly\nreshaped text generation, particularly in the realm of writing assistance.\nWhile ethical considerations underscore the importance of transparently\nacknowledging LLM use, especially in scientific communication, genuine\nacknowledgment remains infrequent. A potential avenue to encourage accurate\nacknowledging of LLM-assisted writing involves employing automated detectors.\nOur evaluation of four cutting-edge LLM-generated text detectors reveals their\nsuboptimal performance compared to a simple ad-hoc detector designed to\nidentify abrupt writing style changes around the time of LLM proliferation. We\ncontend that the development of specialized detectors exclusively dedicated to\nLLM-assisted writing detection is necessary. Such detectors could play a\ncrucial role in fostering more authentic recognition of LLM involvement in\nscientific communication, addressing the current challenges in acknowledgment\npractices.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16807v2",
    "published_date": "2024-01-30 08:07:28 UTC",
    "updated_date": "2024-07-05 14:19:36 UTC"
  },
  {
    "arxiv_id": "2402.01751v1",
    "title": "Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's Dementia",
    "authors": [
      "Balamurali B T",
      "Jer-Ming Chen"
    ],
    "abstract": "Large language models (LLMs) find increasing applications in many fields.\nHere, three LLM chatbots (ChatGPT-3.5, ChatGPT-4 and Bard) are assessed - in\ntheir current form, as publicly available - for their ability to recognize\nAlzheimer's Dementia (AD) and Cognitively Normal (CN) individuals using textual\ninput derived from spontaneous speech recordings. Zero-shot learning approach\nis used at two levels of independent queries, with the second query\n(chain-of-thought prompting) eliciting more detailed than the first. Each LLM\nchatbot's performance is evaluated on the prediction generated in terms of\naccuracy, sensitivity, specificity, precision and F1 score. LLM chatbots\ngenerated three-class outcome (\"AD\", \"CN\", or \"Unsure\"). When positively\nidentifying AD, Bard produced highest true-positives (89% recall) and highest\nF1 score (71%), but tended to misidentify CN as AD, with high confidence (low\n\"Unsure\" rates); for positively identifying CN, GPT-4 resulted in the highest\ntrue-negatives at 56% and highest F1 score (62%), adopting a diplomatic stance\n(moderate \"Unsure\" rates). Overall, three LLM chatbots identify AD vs CN\nsurpassing chance-levels but do not currently satisfy clinical application.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01751v1",
    "published_date": "2024-01-30 07:55:43 UTC",
    "updated_date": "2024-01-30 07:55:43 UTC"
  },
  {
    "arxiv_id": "2402.10224v1",
    "title": "Human-Centric Goal Reasoning with Ripple-Down Rules",
    "authors": [
      "Kenji Brameld",
      "Germán Castro",
      "Claude Sammut",
      "Mark Roberts",
      "David W. Aha"
    ],
    "abstract": "ActorSim is a goal reasoning framework developed at the Naval Research\nLaboratory. Originally, all goal reasoning rules were hand-crafted. This work\nextends ActorSim with the capability of learning by demonstration, that is,\nwhen a human trainer disagrees with a decision made by the system, the trainer\ncan take over and show the system the correct decision. The learning component\nuses Ripple-Down Rules (RDR) to build new decision rules to correctly handle\nsimilar cases in the future. The system is demonstrated using the RoboCup\nRescue Agent Simulation, which simulates a city-wide disaster, requiring\nemergency services, including fire, ambulance and police, to be dispatched to\ndifferent sites to evacuate civilians from dangerous situations. The RDRs are\nimplemented in a scripting language, FrameScript, which is used to mediate\nbetween ActorSim and the agent simulator. Using Ripple-Down Rules, ActorSim can\nscale to an order of magnitude more goals than the previous version.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "Proceedings of the Ninth Goal Reasoning Workshop (Advances in\n  Cognitive Systems, 2021)",
    "pdf_url": "http://arxiv.org/pdf/2402.10224v1",
    "published_date": "2024-01-30 07:52:38 UTC",
    "updated_date": "2024-01-30 07:52:38 UTC"
  },
  {
    "arxiv_id": "2401.16795v1",
    "title": "Performance Insights-based AI-driven Football Transfer Fee Prediction",
    "authors": [
      "Daniil Sulimov"
    ],
    "abstract": "We developed an artificial intelligence approach to predict the transfer fee\nof a football player. This model can help clubs make better decisions about\nwhich players to buy and sell, which can lead to improved performance and\nincreased club budgets. Having collected data on player performance, transfer\nfees, and other factors that might affect a player's value, we then used this\ndata to train a machine learning model that can accurately predict a player's\nimpact on the game. We further passed the obtained results as one of the\nfeatures to the predictor of transfer fees. The model can help clubs identify\nplayers who are undervalued and who could be sold for a profit. It can also\nhelp clubs avoid overpaying for players. We believe that our model can be a\nvaluable tool for football clubs. It can help them make better decisions about\nplayer recruitment and transfers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T99"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16795v1",
    "published_date": "2024-01-30 07:16:09 UTC",
    "updated_date": "2024-01-30 07:16:09 UTC"
  },
  {
    "arxiv_id": "2401.16788v1",
    "title": "Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate",
    "authors": [
      "Steffi Chern",
      "Ethan Chern",
      "Graham Neubig",
      "Pengfei Liu"
    ],
    "abstract": "Despite the utility of Large Language Models (LLMs) across a wide range of\ntasks and scenarios, developing a method for reliably evaluating LLMs across\nvaried contexts continues to be challenging. Modern evaluation approaches often\nuse LLMs to assess responses generated by LLMs. However, the meta-evaluation\nconducted to assess the effectiveness of these LLMs as evaluators is typically\nconstrained by the coverage of existing benchmarks or requires extensive human\nannotation. This underscores the urgency of methods for scalable\nmeta-evaluation that can effectively, reliably, and efficiently evaluate the\nperformance of LLMs as evaluators across diverse tasks and scenarios,\nparticularly in potentially new, user-defined scenarios. To fill this gap, we\npropose ScaleEval, an agent-debate-assisted meta-evaluation framework that\nleverages the capabilities of multiple communicative LLM agents. This framework\nsupports multi-round discussions to assist human annotators in discerning the\nmost capable LLMs as evaluators, which significantly eases their workload in\ncases that used to require large-scale annotations during meta-evaluation. We\nrelease the code for our framework, which is publicly available at:\n\\url{https://github.com/GAIR-NLP/scaleeval}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16788v1",
    "published_date": "2024-01-30 07:03:32 UTC",
    "updated_date": "2024-01-30 07:03:32 UTC"
  },
  {
    "arxiv_id": "2402.01750v1",
    "title": "PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using Large Language Models",
    "authors": [
      "Jiaxuan Li",
      "Minxi Yang",
      "Dahua Gao",
      "Wenlong Xu",
      "Guangming Shi"
    ],
    "abstract": "Current communication technologies face limitations in terms of theoretical\ncapacity, spectrum availability, and power resources. Pragmatic communication,\nleveraging terminal intelligence for selective data transmission, offers\nresource conservation. Existing research lacks universal intention resolution\ntools, limiting applicability to specific tasks. This paper proposes an image\npragmatic communication framework based on a Pragmatic Agent for Communication\nEfficiency (PACE) using Large Language Models (LLM). In this framework, PACE\nsequentially performs semantic perception, intention resolution, and\nintention-oriented coding. To ensure the effective utilization of LLM in\ncommunication, a knowledge base is designed to supplement the necessary\nknowledge, dedicated prompts are introduced to facilitate understanding of\npragmatic communication scenarios and task requirements, and a chain of thought\nis designed to assist in making reasonable trade-offs between transmission\nefficiency and cost. For experimental validation, this paper constructs an\nimage pragmatic communication dataset along with corresponding evaluation\nstandards. Simulation results indicate that the proposed method outperforms\ntraditional and non-LLM-based pragmatic communication in terms of transmission\nefficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages,11 figures, submitted to IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01750v1",
    "published_date": "2024-01-30 06:55:17 UTC",
    "updated_date": "2024-01-30 06:55:17 UTC"
  },
  {
    "arxiv_id": "2401.16784v1",
    "title": "Graph Fairness Learning under Distribution Shifts",
    "authors": [
      "Yibo Li",
      "Xiao Wang",
      "Yujie Xing",
      "Shaohua Fan",
      "Ruijia Wang",
      "Yaoqi Liu",
      "Chuan Shi"
    ],
    "abstract": "Graph neural networks (GNNs) have achieved remarkable performance on\ngraph-structured data. However, GNNs may inherit prejudice from the training\ndata and make discriminatory predictions based on sensitive attributes, such as\ngender and race. Recently, there has been an increasing interest in ensuring\nfairness on GNNs, but all of them are under the assumption that the training\nand testing data are under the same distribution, i.e., training data and\ntesting data are from the same graph. Will graph fairness performance decrease\nunder distribution shifts? How does distribution shifts affect graph fairness\nlearning? All these open questions are largely unexplored from a theoretical\nperspective. To answer these questions, we first theoretically identify the\nfactors that determine bias on a graph. Subsequently, we explore the factors\ninfluencing fairness on testing graphs, with a noteworthy factor being the\nrepresentation distances of certain groups between the training and testing\ngraph. Motivated by our theoretical analysis, we propose our framework\nFatraGNN. Specifically, to guarantee fairness performance on unknown testing\ngraphs, we propose a graph generator to produce numerous graphs with\nsignificant bias and under different distributions. Then we minimize the\nrepresentation distances for each certain group between the training graph and\ngenerated graphs. This empowers our model to achieve high classification and\nfairness performance even on generated graphs with significant bias, thereby\neffectively handling unknown testing graphs. Experiments on real-world and\nsemi-synthetic datasets demonstrate the effectiveness of our model in terms of\nboth accuracy and fairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16784v1",
    "published_date": "2024-01-30 06:51:24 UTC",
    "updated_date": "2024-01-30 06:51:24 UTC"
  },
  {
    "arxiv_id": "2401.16772v1",
    "title": "Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator",
    "authors": [
      "Ryoma Furuyama",
      "Daiki Kuyoshi",
      "Satoshi Yamane"
    ],
    "abstract": "Imitation learning is often used in addition to reinforcement learning in\nenvironments where reward design is difficult or where the reward is sparse,\nbut it is difficult to be able to imitate well in unknown states from a small\namount of expert data and sampling data. Supervised learning methods such as\nBehavioral Cloning do not require sampling data, but usually suffer from\ndistribution shift. The methods based on reinforcement learning, such as\ninverse reinforcement learning and Generative Adversarial imitation learning\n(GAIL), can learn from only a few expert data. However, they often need to\ninteract with the environment. Soft Q imitation learning (SQIL) addressed the\nproblems, and it was shown that it could learn efficiently by combining\nBehavioral Cloning and soft Q-learning with constant rewards. In order to make\nthis algorithm more robust to distribution shift, we propose more efficient and\nrobust algorithm by adding to this method a reward function based on\nadversarial inverse reinforcement learning that rewards the agent for\nperforming actions in status similar to the demo. We call this algorithm\nDiscriminator Soft Q Imitation Learning (DSQIL). We evaluated it on MuJoCo\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2001.06808",
    "pdf_url": "http://arxiv.org/pdf/2401.16772v1",
    "published_date": "2024-01-30 06:22:19 UTC",
    "updated_date": "2024-01-30 06:22:19 UTC"
  },
  {
    "arxiv_id": "2401.16766v1",
    "title": "Detection and Recovery Against Deep Neural Network Fault Injection Attacks Based on Contrastive Learning",
    "authors": [
      "Chenan Wang",
      "Pu Zhao",
      "Siyue Wang",
      "Xue Lin"
    ],
    "abstract": "Deep Neural Network (DNN) models when implemented on executing devices as the\ninference engines are susceptible to Fault Injection Attacks (FIAs) that\nmanipulate model parameters to disrupt inference execution with disastrous\nperformance. This work introduces Contrastive Learning (CL) of visual\nrepresentations i.e., a self-supervised learning approach into the deep\nlearning training and inference pipeline to implement DNN inference engines\nwith self-resilience under FIAs. Our proposed CL based FIA Detection and\nRecovery (CFDR) framework features (i) real-time detection with only a single\nbatch of testing data and (ii) fast recovery effective even with only a small\namount of unlabeled testing data. Evaluated with the CIFAR-10 dataset on\nmultiple types of FIAs, our CFDR shows promising detection and recovery\neffectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in AdvML 2021",
    "pdf_url": "http://arxiv.org/pdf/2401.16766v1",
    "published_date": "2024-01-30 06:06:57 UTC",
    "updated_date": "2024-01-30 06:06:57 UTC"
  },
  {
    "arxiv_id": "2401.16765v1",
    "title": "A Cross-Language Investigation into Jailbreak Attacks in Large Language Models",
    "authors": [
      "Jie Li",
      "Yi Liu",
      "Chongyang Liu",
      "Ling Shi",
      "Xiaoning Ren",
      "Yaowen Zheng",
      "Yang Liu",
      "Yinxing Xue"
    ],
    "abstract": "Large Language Models (LLMs) have become increasingly popular for their\nadvanced text generation capabilities across various domains. However, like any\nsoftware, they face security challenges, including the risk of 'jailbreak'\nattacks that manipulate LLMs to produce prohibited content. A particularly\nunderexplored area is the Multilingual Jailbreak attack, where malicious\nquestions are translated into various languages to evade safety filters.\nCurrently, there is a lack of comprehensive empirical studies addressing this\nspecific threat.\n  To address this research gap, we conducted an extensive empirical study on\nMultilingual Jailbreak attacks. We developed a novel semantic-preserving\nalgorithm to create a multilingual jailbreak dataset and conducted an\nexhaustive evaluation on both widely-used open-source and commercial LLMs,\nincluding GPT-4 and LLaMa. Additionally, we performed interpretability analysis\nto uncover patterns in Multilingual Jailbreak attacks and implemented a\nfine-tuning mitigation method. Our findings reveal that our mitigation strategy\nsignificantly enhances model defense, reducing the attack success rate by\n96.2%. This study provides valuable insights into understanding and mitigating\nMultilingual Jailbreak attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16765v1",
    "published_date": "2024-01-30 06:04:04 UTC",
    "updated_date": "2024-01-30 06:04:04 UTC"
  },
  {
    "arxiv_id": "2401.16757v1",
    "title": "SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget",
    "authors": [
      "Kun Wang",
      "Jiani Cao",
      "Zimu Zhou",
      "Zhenjiang Li"
    ],
    "abstract": "Executing deep neural networks (DNNs) on edge artificial intelligence (AI)\ndevices enables various autonomous mobile computing applications. However, the\nmemory budget of edge AI devices restricts the number and complexity of DNNs\nallowed in such applications. Existing solutions, such as model compression or\ncloud offloading, reduce the memory footprint of DNN inference at the cost of\ndecreased model accuracy or autonomy. To avoid these drawbacks, we divide DNN\ninto blocks and swap them in and out in order, such that large DNNs can execute\nwithin a small memory budget. Nevertheless, naive swapping on edge AI devices\ninduces significant delays due to the redundant memory operations in the DNN\ndevelopment ecosystem for edge AI devices. To this end, we develop SwapNet, an\nefficient DNN block swapping middleware for edge AI devices. We systematically\neliminate the unnecessary memory operations during block swapping while\nretaining compatible with the deep learning frameworks, GPU backends, and\nhardware architectures of edge AI devices. We further showcase the utility of\nSwapNet via a multi-DNN scheduling scheme. Evaluations on eleven DNN inference\ntasks in three applications demonstrate that SwapNet achieves almost the same\nlatency as the case with sufficient memory even when DNNs demand 2.32x to 5.81x\nmemory beyond the available budget. The design of SwapNet also provides novel\nand feasible insights for deploying large language models (LLMs) on edge AI\ndevices in the future.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 19 figures, accepted by IEEE Transactions on Mobile\n  Computing",
    "pdf_url": "http://arxiv.org/pdf/2401.16757v1",
    "published_date": "2024-01-30 05:29:49 UTC",
    "updated_date": "2024-01-30 05:29:49 UTC"
  },
  {
    "arxiv_id": "2401.16755v2",
    "title": "Diffusion model for relational inference",
    "authors": [
      "Shuhan Zheng",
      "Ziqiang Li",
      "Kantaro Fujiwara",
      "Gouhei Tanaka"
    ],
    "abstract": "Dynamical behaviors of complex interacting systems, including brain\nactivities, financial price movements, and physical collective phenomena, are\nassociated with underlying interactions between the system's components. The\nissue of uncovering interaction relations in such systems using observable\ndynamics is called relational inference. In this study, we propose a Diffusion\nmodel for Relational Inference (DiffRI), inspired by a self-supervised method\nfor probabilistic time series imputation. DiffRI learns to infer the\nprobability of the presence of connections between components through\nconditional diffusion modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16755v2",
    "published_date": "2024-01-30 05:25:02 UTC",
    "updated_date": "2024-06-20 13:19:23 UTC"
  },
  {
    "arxiv_id": "2401.16744v4",
    "title": "ShaRP: A Novel Feature Importance Framework for Ranking",
    "authors": [
      "Venetia Pliatsika",
      "Joao Fonseca",
      "Kateryna Akhynko",
      "Ivan Shevchenko",
      "Julia Stoyanovich"
    ],
    "abstract": "Algorithmic decisions in critical domains such as hiring, college admissions,\nand lending are often based on rankings. Given the impact of these decisions on\nindividuals, organizations, and population groups, it is essential to\nunderstand them-to help individuals improve their ranking position, design\nbetter ranking procedures, and ensure legal compliance. In this paper, we argue\nthat explainability methods for classification and regression, such as SHAP,\nare insufficient for ranking tasks, and present ShaRP-Shapley Values for\nRankings and Preferences-a framework that explains the contributions of\nfeatures to various aspects of a ranked outcome.\n  ShaRP computes feature contributions for various ranking-specific profit\nfunctions, such as rank and top-k, and also includes a novel Shapley\nvalue-based method for explaining pairwise preference outcomes. We provide a\nflexible implementation of ShaRP, capable of efficiently and comprehensively\nexplaining ranked and pairwise outcomes over tabular data, in score-based\nranking and learning-to-rank tasks. Finally, to evaluate ShaRP and compare it\nwith other explainability methods, we define ranking-specific explanation\nmetrics and conduct an extensive experimental analysis, demonstrating the\nframework's flexibility and efficiency.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.16744v4",
    "published_date": "2024-01-30 04:48:43 UTC",
    "updated_date": "2025-02-15 21:18:31 UTC"
  },
  {
    "arxiv_id": "2402.01749v2",
    "title": "Towards Urban General Intelligence: A Review and Outlook of Urban Foundation Models",
    "authors": [
      "Weijia Zhang",
      "Jindong Han",
      "Zhao Xu",
      "Hang Ni",
      "Tengfei Lyu",
      "Hao Liu",
      "Hui Xiong"
    ],
    "abstract": "The integration of machine learning techniques has become a cornerstone in\nthe development of intelligent urban services, significantly contributing to\nthe enhancement of urban efficiency, sustainability, and overall livability.\nRecent advancements in foundational models, such as ChatGPT, have introduced a\nparadigm shift within the fields of machine learning and artificial\nintelligence. These models, with their exceptional capacity for contextual\ncomprehension, problem-solving, and task adaptability, present a transformative\nopportunity to reshape the future of smart cities and drive progress toward\nUrban General Intelligence (UGI). Despite increasing attention to Urban\nFoundation Models (UFMs), this rapidly evolving field faces critical\nchallenges, including the lack of clear definitions, systematic reviews, and\nuniversalizable solutions. To address these issues, this paper first introduces\nthe definition and concept of UFMs and highlights the distinctive challenges\ninvolved in their development. Furthermore, we present a data-centric taxonomy\nthat classifies existing research on UFMs according to the various urban data\nmodalities and types. In addition, we propose a prospective framework designed\nto facilitate the realization of versatile UFMs, aimed at overcoming the\nidentified challenges and driving further progress in this field. Finally, this\npaper explores the wide-ranging applications of UFMs within urban contexts,\nillustrating their potential to significantly impact and transform urban\nsystems. A comprehensive collection of relevant research papers and open-source\nresources have been collated and are continuously updated at:\nhttps://github.com/usail-hkust/Awesome-Urban-Foundation-Models.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01749v2",
    "published_date": "2024-01-30 04:48:16 UTC",
    "updated_date": "2025-01-05 03:45:51 UTC"
  },
  {
    "arxiv_id": "2401.16742v1",
    "title": "Generative AI-based closed-loop fMRI system",
    "authors": [
      "Mikihiro Kasahara",
      "Taiki Oka",
      "Vincent Taschereau-Dumouchel",
      "Mitsuo Kawato",
      "Hiroki Takakura",
      "Aurelio Cortese"
    ],
    "abstract": "While generative AI is now widespread and useful in society, there are\npotential risks of misuse, e.g., unconsciously influencing cognitive processes\nor decision-making. Although this causes a security problem in the cognitive\ndomain, there has been no research about neural and computational mechanisms\ncounteracting the impact of malicious generative AI in humans. We propose\nDecNefGAN, a novel framework that combines a generative adversarial system and\na neural reinforcement model. More specifically, DecNefGAN bridges human and\ngenerative AI in a closed-loop system, with the AI creating stimuli that induce\nspecific mental states, thus exerting external control over neural activity.\nThe objective of the human is the opposite, to compete and reach an orthogonal\nmental state. This framework can contribute to elucidating how the human brain\nresponds to and counteracts the potential influence of generative AI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16742v1",
    "published_date": "2024-01-30 04:40:49 UTC",
    "updated_date": "2024-01-30 04:40:49 UTC"
  },
  {
    "arxiv_id": "2401.16731v1",
    "title": "Towards Generating Informative Textual Description for Neurons in Language Models",
    "authors": [
      "Shrayani Mondal",
      "Rishabh Garodia",
      "Arbaaz Qureshi",
      "Taesung Lee",
      "Youngja Park"
    ],
    "abstract": "Recent developments in transformer-based language models have allowed them to\ncapture a wide variety of world knowledge that can be adapted to downstream\ntasks with limited resources. However, what pieces of information are\nunderstood in these models is unclear, and neuron-level contributions in\nidentifying them are largely unknown. Conventional approaches in neuron\nexplainability either depend on a finite set of pre-defined descriptors or\nrequire manual annotations for training a secondary model that can then explain\nthe neurons of the primary model. In this paper, we take BERT as an example and\nwe try to remove these constraints and propose a novel and scalable framework\nthat ties textual descriptions to neurons. We leverage the potential of\ngenerative language models to discover human-interpretable descriptors present\nin a dataset and use an unsupervised approach to explain neurons with these\ndescriptors. Through various qualitative and quantitative analyses, we\ndemonstrate the effectiveness of this framework in generating useful\ndata-specific descriptors with little human involvement in identifying the\nneurons that encode these descriptors. In particular, our experiment shows that\nthe proposed approach achieves 75% precision@2, and 50% recall@2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16731v1",
    "published_date": "2024-01-30 04:06:25 UTC",
    "updated_date": "2024-01-30 04:06:25 UTC"
  },
  {
    "arxiv_id": "2402.00888v2",
    "title": "Security and Privacy Challenges of Large Language Models: A Survey",
    "authors": [
      "Badhan Chandra Das",
      "M. Hadi Amini",
      "Yanzhao Wu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated extraordinary capabilities and\ncontributed to multiple fields, such as generating and summarizing text,\nlanguage translation, and question-answering. Nowadays, LLM is becoming a very\npopular tool in computerized language processing tasks, with the capability to\nanalyze complicated linguistic patterns and provide relevant and appropriate\nresponses depending on the context. While offering significant advantages,\nthese models are also vulnerable to security and privacy attacks, such as\njailbreaking attacks, data poisoning attacks, and Personally Identifiable\nInformation (PII) leakage attacks. This survey provides a thorough review of\nthe security and privacy challenges of LLMs for both training data and users,\nalong with the application-based risks in various domains, such as\ntransportation, education, and healthcare. We assess the extent of LLM\nvulnerabilities, investigate emerging security and privacy attacks for LLMs,\nand review the potential defense mechanisms. Additionally, the survey outlines\nexisting research gaps in this domain and highlights future research\ndirections.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00888v2",
    "published_date": "2024-01-30 04:00:54 UTC",
    "updated_date": "2024-11-14 22:20:49 UTC"
  },
  {
    "arxiv_id": "2401.16708v2",
    "title": "Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes",
    "authors": [
      "Yung-Peng Hsu",
      "Hung-Hsuan Chen"
    ],
    "abstract": "This paper introduces the multivariate beta mixture model (MBMM), a new\nprobabilistic model for soft clustering. MBMM adapts to diverse cluster shapes\nbecause of the flexible probability density function of the multivariate beta\ndistribution. We introduce the properties of MBMM, describe the parameter\nlearning procedure, and present the experimental results, showing that MBMM\nfits diverse cluster shapes on synthetic and real datasets. The code is\nreleased anonymously at https://github.com/hhchen1105/mbmm/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16708v2",
    "published_date": "2024-01-30 03:12:19 UTC",
    "updated_date": "2024-02-21 00:26:37 UTC"
  },
  {
    "arxiv_id": "2403.08786v1",
    "title": "One-Spike SNN: Single-Spike Phase Coding with Base Manipulation for ANN-to-SNN Conversion Loss Minimization",
    "authors": [
      "Sangwoo Hwang",
      "Jaeha Kung"
    ],
    "abstract": "As spiking neural networks (SNNs) are event-driven, energy efficiency is\nhigher than conventional artificial neural networks (ANNs). Since SNN delivers\ndata through discrete spikes, it is difficult to use gradient methods for\ntraining, limiting its accuracy. To keep the accuracy of SNNs similar to ANN\ncounterparts, pre-trained ANNs are converted to SNNs (ANN-to-SNN conversion).\nDuring the conversion, encoding activations of ANNs to a set of spikes in SNNs\nis crucial for minimizing the conversion loss. In this work, we propose a\nsingle-spike phase coding as an encoding scheme that minimizes the number of\nspikes to transfer data between SNN layers. To minimize the encoding error due\nto single-spike approximation in phase coding, threshold shift and base\nmanipulation are proposed. Without any additional retraining or architectural\nconstraints on ANNs, the proposed conversion method does not lose inference\naccuracy (0.58% on average) verified on three convolutional neural networks\n(CNNs) with CIFAR and ImageNet datasets.In addition, graph convolutional\nnetworks (GCNs) are converted to SNNs successfully with an average accuracy\nloss of 0.90%.Most importantly, the energy efficiency of our SNN improves by\n4.6~17.3 X compared to the ANN baseline.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "68T07"
    ],
    "primary_category": "cs.NE",
    "comment": "11 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08786v1",
    "published_date": "2024-01-30 02:00:28 UTC",
    "updated_date": "2024-01-30 02:00:28 UTC"
  },
  {
    "arxiv_id": "2401.16672v1",
    "title": "AutoIE: An Automated Framework for Information Extraction from Scientific Literature",
    "authors": [
      "Yangyang Liu",
      "Shoubin Li"
    ],
    "abstract": "In the rapidly evolving field of scientific research, efficiently extracting\nkey information from the burgeoning volume of scientific papers remains a\nformidable challenge. This paper introduces an innovative framework designed to\nautomate the extraction of vital data from scientific PDF documents, enabling\nresearchers to discern future research trajectories more readily. AutoIE\nuniquely integrates four novel components: (1) A multi-semantic feature\nfusion-based approach for PDF document layout analysis; (2) Advanced functional\nblock recognition in scientific texts; (3) A synergistic technique for\nextracting and correlating information on molecular sieve synthesis; (4) An\nonline learning paradigm tailored for molecular sieve literature. Our SBERT\nmodel achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE\ndatasets. In addition, a practical application of AutoIE in the petrochemical\nmolecular sieve synthesis domain demonstrates its efficacy, evidenced by an\nimpressive 78\\% accuracy rate. This research paves the way for enhanced data\nmanagement and interpretation in molecular sieve synthesis. It is a valuable\nasset for seasoned experts and newcomers in this specialized field.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16672v1",
    "published_date": "2024-01-30 01:45:03 UTC",
    "updated_date": "2024-01-30 01:45:03 UTC"
  },
  {
    "arxiv_id": "2401.16669v2",
    "title": "Improving Global Weather and Ocean Wave Forecast with Large Artificial Intelligence Models",
    "authors": [
      "Fenghua Ling",
      "Lin Ouyang",
      "Boufeniza Redouane Larbi",
      "Jing-Jia Luo",
      "Tao Han",
      "Xiaohui Zhong",
      "Lei Bai"
    ],
    "abstract": "The rapid advancement of artificial intelligence technologies, particularly\nin recent years, has led to the emergence of several large parameter artificial\nintelligence weather forecast models. These models represent a significant\nbreakthrough, overcoming the limitations of traditional numerical weather\nprediction models and indicating the emergence of profound potential tools for\natmosphere-ocean forecasts. This study explores the evolution of these advanced\nartificial intelligence forecast models, and based on the identified\ncommonalities, proposes the \"Three Large Rules\" to measure their development.\nWe discuss the potential of artificial intelligence in revolutionizing\nnumerical weather prediction, and briefly outlining the underlying reasons for\nits great potential. While acknowledging the high accuracy, computational\nefficiency, and ease of deployment of large artificial intelligence forecast\nmodels, we also emphasize the irreplaceable values of traditional numerical\nforecasts and explore the challenges in the future development of large-scale\nartificial intelligence atmosphere-ocean forecast models. We believe that the\noptimal future of atmosphere-ocean weather forecast lies in achieving a\nseamless integration of artificial intelligence and traditional numerical\nmodels. Such a synthesis is anticipated to offer a more advanced and reliable\napproach for improved atmosphere-ocean forecasts. Additionally, we illustrate\nhow forecasters can adapt and leverage the advanced artificial intelligence\nmodel through an example by building a large artificial intelligence model for\nglobal ocean wave forecast.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16669v2",
    "published_date": "2024-01-30 01:34:43 UTC",
    "updated_date": "2024-04-19 02:01:20 UTC"
  },
  {
    "arxiv_id": "2401.16657v1",
    "title": "Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo",
    "authors": [
      "Jian-Qiao Zhu",
      "Haijiang Yan",
      "Thomas L. Griffiths"
    ],
    "abstract": "Simulating sampling algorithms with people has proven a useful method for\nefficiently probing and understanding their mental representations. We propose\nthat the same methods can be used to study the representations of Large\nLanguage Models (LLMs). While one can always directly prompt either humans or\nLLMs to disclose their mental representations introspectively, we show that\nincreased efficiency can be achieved by using LLMs as elements of a sampling\nalgorithm. We explore the extent to which we recover human-like representations\nwhen LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo\n(MCMC). We found a significant increase in efficiency and performance using\nadaptive sampling algorithms based on MCMC. We also highlight the potential of\nour method to yield a more general method of conducting Bayesian inference\n\\textit{with} LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16657v1",
    "published_date": "2024-01-30 01:22:18 UTC",
    "updated_date": "2024-01-30 01:22:18 UTC"
  },
  {
    "arxiv_id": "2401.16650v3",
    "title": "Augmenting Replay in World Models for Continual Reinforcement Learning",
    "authors": [
      "Luke Yang",
      "Levin Kuhlmann",
      "Gideon Kowadlo"
    ],
    "abstract": "Continual RL requires an agent to learn new tasks without forgetting previous\nones, while improving on both past and future tasks. The most common approaches\nuse model-free algorithms and replay buffers can help to mitigate catastrophic\nforgetting, but often struggle with scalability due to large memory\nrequirements. Biologically inspired replay suggests replay to a world model,\naligning with model-based RL; as opposed to the common setting of replay in\nmodel-free algorithms. Model-based RL offers benefits for continual RL by\nleveraging knowledge of the environment, independent of policy. We introduce\nWMAR (World Models with Augmented Replay), a model-based RL algorithm with a\nmemory-efficient distribution-matching replay buffer. WMAR extends the well\nknown DreamerV3 algorithm, which employs a simple FIFO buffer and was not\ntested in continual RL. We evaluated WMAR and DreamerV3, with the same-size\nreplay buffers. They were tested on two scenarios: tasks with shared structure\nusing OpenAI Procgen and tasks without shared structure using the Atari\nbenchmark. WMAR demonstrated favourable properties for continual RL considering\nmetrics for forgetting as well as skill transfer on past and future tasks.\nCompared to DreamerV3, WMAR showed slight benefits in tasks with shared\nstructure and substantially better forgetting characteristics on tasks without\nshared structure. Our results suggest that model-based RL with a\nmemory-efficient replay buffer can be an effective approach to continual RL,\njustifying further research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.5.0; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16650v3",
    "published_date": "2024-01-30 00:48:26 UTC",
    "updated_date": "2024-07-16 07:33:52 UTC"
  },
  {
    "arxiv_id": "2401.16646v2",
    "title": "Incoherent Probability Judgments in Large Language Models",
    "authors": [
      "Jian-Qiao Zhu",
      "Thomas L. Griffiths"
    ],
    "abstract": "Autoregressive Large Language Models (LLMs) trained for next-word prediction\nhave demonstrated remarkable proficiency at producing coherent text. But are\nthey equally adept at forming coherent probability judgments? We use\nprobabilistic identities and repeated judgments to assess the coherence of\nprobability judgments made by LLMs. Our results show that the judgments\nproduced by these models are often incoherent, displaying human-like systematic\ndeviations from the rules of probability theory. Moreover, when prompted to\njudge the same event, the mean-variance relationship of probability judgments\nproduced by LLMs shows an inverted-U-shaped like that seen in humans. We\npropose that these deviations from rationality can be explained by linking\nautoregressive LLMs to implicit Bayesian inference and drawing parallels with\nthe Bayesian Sampler model of human probability judgments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16646v2",
    "published_date": "2024-01-30 00:40:49 UTC",
    "updated_date": "2025-05-06 01:43:38 UTC"
  },
  {
    "arxiv_id": "2401.16638v1",
    "title": "Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs",
    "authors": [
      "Stepan Tytarenko",
      "Mohammad Ruhul Amin"
    ],
    "abstract": "Fine-tuning large pre-trained language models (LLMs) on particular datasets\nis a commonly employed strategy in Natural Language Processing (NLP)\nclassification tasks. However, this approach usually results in a loss of\nmodels generalizability. In this paper, we present a framework that allows for\nmaintaining generalizability, and enhances the performance on the downstream\ntask by utilizing task-specific context attribution. We show that a linear\ntransformation of the text representation from any transformer model using the\ntask-specific concept operator results in a projection onto the latent concept\nspace, referred to as context attribution in this paper. The specific concept\noperator is optimized during the supervised learning stage via novel loss\nfunctions. The proposed framework demonstrates that context attribution of the\ntext representation for each task objective can improve the capacity of the\ndiscriminator function and thus achieve better performance for the\nclassification task. Experimental results on three datasets, namely HateXplain,\nIMDB reviews, and Social Media Attributions, illustrate that the proposed model\nattains superior accuracy and generalizability. Specifically, for the\nnon-fine-tuned BERT on the HateXplain dataset, we observe 8% improvement in\naccuracy and 10% improvement in F1-score. Whereas for the IMDB dataset,\nfine-tuned state-of-the-art XLNet is outperformed by 1% for both accuracy and\nF1-score. Furthermore, in an out-of-domain cross-dataset test, DistilBERT\nfine-tuned on the IMDB dataset in conjunction with the proposed model improves\nthe F1-score on the HateXplain dataset by 7%. For the Social Media Attributions\ndataset of YouTube comments, we observe 5.2% increase in F1-metric. The\nproposed framework is implemented with PyTorch and provided open-source on\nGitHub.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.4"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 3 figures, 5 tables, To be published in 2024 AAAI workshop\n  on Responsible Language Models (ReLM)",
    "pdf_url": "http://arxiv.org/pdf/2401.16638v1",
    "published_date": "2024-01-30 00:23:29 UTC",
    "updated_date": "2024-01-30 00:23:29 UTC"
  },
  {
    "arxiv_id": "2402.01748v2",
    "title": "Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems",
    "authors": [
      "Shengzhe Xu",
      "Christo Kurisummoottil Thomas",
      "Omar Hashash",
      "Nikhil Muralidhar",
      "Walid Saad",
      "Naren Ramakrishnan"
    ],
    "abstract": "Large language models (LLMs) and foundation models have been recently touted\nas a game-changer for 6G systems. However, recent efforts on LLMs for wireless\nnetworks are limited to a direct application of existing language models that\nwere designed for natural language processing (NLP) applications. To address\nthis challenge and create wireless-centric foundation models, this paper\npresents a comprehensive vision on how to design universal foundation models\nthat are tailored towards the deployment of artificial intelligence (AI)-native\nnetworks. Diverging from NLP-based foundation models, the proposed framework\npromotes the design of large multi-modal models (LMMs) fostered by three key\ncapabilities: 1) processing of multi-modal sensing data, 2) grounding of\nphysical symbol representations in real-world wireless systems using causal\nreasoning and retrieval-augmented generation (RAG), and 3) enabling\ninstructibility from the wireless environment feedback to facilitate dynamic\nnetwork adaptation thanks to logical and mathematical reasoning facilitated by\nneuro-symbolic AI. In essence, these properties enable the proposed LMM\nframework to build universal capabilities that cater to various cross-layer\nnetworking tasks and alignment of intents across different domains. Preliminary\nresults from experimental evaluation demonstrate the efficacy of grounding\nusing RAG in LMMs, and showcase the alignment of LMMs with wireless system\ndesigns. Furthermore, the enhanced rationale exhibited in the responses to\nmathematical questions by LMMs, compared to vanilla LLMs, demonstrates the\nlogical and mathematical reasoning capabilities inherent in LMMs. Building on\nthose results, we present a sequel of open questions and challenges for LMMs.\nWe then conclude with a set of recommendations that ignite the path towards\nLMM-empowered AI-native systems.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01748v2",
    "published_date": "2024-01-30 00:21:41 UTC",
    "updated_date": "2024-02-07 17:55:11 UTC"
  },
  {
    "arxiv_id": "2401.16635v3",
    "title": "Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble",
    "authors": [
      "Shun Zhang",
      "Zhenfang Chen",
      "Sunli Chen",
      "Yikang Shen",
      "Zhiqing Sun",
      "Chuang Gan"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a widely adopted\napproach for aligning large language models with human values. However, RLHF\nrelies on a reward model that is trained with a limited amount of human\npreference data, which could lead to inaccurate predictions. As a result, RLHF\nmay produce outputs that are misaligned with human values. To mitigate this\nissue, we contribute a reward ensemble method that allows the reward model to\nmake more accurate predictions. As using an ensemble of large language\nmodel-based reward models can be computationally and resource-expensive, we\nexplore efficient ensemble methods including linear-layer ensemble and\nLoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy\nOptimization with our ensembled reward models, and verify that our ensemble\nmethods help improve the alignment performance of RLHF outputs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16635v3",
    "published_date": "2024-01-30 00:17:37 UTC",
    "updated_date": "2024-10-22 06:19:20 UTC"
  },
  {
    "arxiv_id": "2401.16633v1",
    "title": "I came, I saw, I certified: some perspectives on the safety assurance of cyber-physical systems",
    "authors": [
      "Mithila Sivakumar",
      "Alvine B. Belle",
      "Kimya Khakzad Shahandashti",
      "Oluwafemi Odu",
      "Hadi Hemmati",
      "Segla Kpodjedo",
      "Song Wang",
      "Opeyemi O. Adesina"
    ],
    "abstract": "The execution failure of cyber-physical systems (e.g., autonomous driving\nsystems, unmanned aerial systems, and robotic systems) could result in the loss\nof life, severe injuries, large-scale environmental damage, property\ndestruction, and major economic loss. Hence, such systems usually require a\nstrong justification that they will effectively support critical requirements\n(e.g., safety, security, and reliability) for which they were designed. Thus,\nit is often mandatory to develop compelling assurance cases to support that\njustification and allow regulatory bodies to certify such systems. In such\ncontexts, detecting assurance deficits, relying on patterns to improve the\nstructure of assurance cases, improving existing assurance case notations, and\n(semi-)automating the generation of assurance cases are key to develop\ncompelling assurance cases and foster consumer acceptance. We therefore explore\nchallenges related to such assurance enablers and outline some potential\ndirections that could be explored to tackle them.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16633v1",
    "published_date": "2024-01-30 00:06:16 UTC",
    "updated_date": "2024-01-30 00:06:16 UTC"
  }
]