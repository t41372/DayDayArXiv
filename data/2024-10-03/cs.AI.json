{
  "date": "2024-10-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-03 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文更新聚焦于 AI 和机器学习领域，特别是大型语言模型（LLM）的优化、安全性和应用扩展，以及多模态模型、强化学习和机器人规划的创新；令人印象深刻的包括对 Retrieval-Augmented Generation (RAG) 的全面综述，以及 Vijay Kumar 等知名学者参与的在线语义规划论文。\n\n下面，我将逐一简要概述今天的论文，先优先讨论那些重要、话题性强或有著名学者的文章（如 LLM 安全、机器人规划和多模态生成），然后快速掠过其他较常规的论文。每个条目包括论文标题（中文 + 英文）和核心贡献、发现，保留关键学术术语以保持专业性。\n\n### 重点论文讨论\n1. **重新审视视觉语言模型和大型语言模型在图像分类中的作用 (Rethinking VLMs and LLMs for Image Classification)**  \n   作者包括 Xavier Boix 等。论文发现，不依赖 LLM 的 VLMs 在对象和场景识别任务中表现更好，但 LLM 可提升推理任务的性能。主要贡献是提出一个轻量级 LLM 路由器，通过 250 万示例训练，实现比 GPT-4V 和 HuggingGPT 更高效的视觉任务路由，改善了分类准确性和成本效益。\n\n2. **揭示隐藏内容：引导个性化扩散模型暴露训练数据 (Revealing the Unseen: Guiding Personalized Diffusion Models to Expose Training Data)**  \n   作者：Xiaoyu Wu 等。论文提出 FineXtract 框架，用于从微调的扩散模型中提取训练数据，成功恢复约 20% 的数据，显著超过基线。发现这不仅揭示数据泄露风险，还可作为版权侵权证据，强调了扩散模型安全性的重要性。\n\n3. **SPINE: 针对不完整自然语言规范的在线语义规划 (SPINE: Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments)**  \n   作者包括 Vijay Kumar 等知名学者，已被 ICRA 2025 接受。论文利用 LLM 进行子任务推理和在线规划，显著提高了机器人效率（时间和距离提高一倍），无需完整地图。主要发现是 LLM 在动态环境中的语义规划潜力。\n\n4. **检索增强生成技术的全面综述 (A Comprehensive Survey of Retrieval-Augmented Generation (RAG))**:  \n   作者：Shailja Gupta 等。论文回顾 RAG 的演变、架构和挑战，讨论了检索效率改进和未来方向，如鲁棒性和可扩展性。主要贡献是提供 RAG 技术的基础资源，强调其在问答和总结任务中的应用潜力。\n\n5. **CounterQuill: 调查人类-AI 协作在在线反驳写作中的潜力 (CounterQuill: Investigating the Potential of Human-AI Collaboration in Online Counterspeech Writing)**  \n   作者：Xiaohan Ding 等。论文引入 CounterQuill 系统，通过计算思维工作流（如学习和共写阶段）帮助用户撰写移情反驳，减少仇恨言论。发现 AI 可提升用户信心和控制力，促进更有效的在线互动。\n\n6. **动态稀疏训练 vs. 密集训练：在图像损坏鲁棒性中的意外赢家 (Dynamic Sparse Training versus Dense Training: The Unexpected Winner in Image Corruption Robustness)**  \n   已接受 ICLR 2025。论文证明动态稀疏训练在图像损坏鲁棒性上优于密集训练，尤其在 10%-50% 稀疏度下。主要贡献是揭示稀疏训练的新优势，提升了计算机视觉模型的鲁棒性。\n\n7. **使用高斯过程先验的流动匹配：用于概率时间序列预测 (Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting)**  \n   作者：Marcel Kollovieh 等。论文提出 TSFlow 模型，结合高斯过程和最优传输路径，提高时间序列预测的准确性。发现它在无条件和条件生成上均表现出色，适用于真实数据集。\n\n8. **你的论文是否被 LLM 审稿？调查 AI 文本检测在同行评审中的可行性 (Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review)**  \n   作者：Sungduk Yu 等。论文评估 AI 文本检测算法在识别 LLM 生成的同行评审中的表现，发现现有方法在低假阳性率下表现不佳。主要贡献是提出新检测方法，提升了学术诚信。\n\n9. **转变教师角色：生成式 AI 时代的感知、接受、知识和实践 (Transforming Teachers' Roles and Agencies in the Era of Generative AI)**  \n   作者：Xiaoming Zhai。论文提出框架，探讨生成式 AI 对教师角色的影响，分类教师为观察者、采用者等角色。发现 AI 需要专业发展和支持，以最大化教育潜力。\n\n10. **FastAdaSP: 多任务自适应高效语音推理 (FastAdaSP: Multitask-Adapted Efficient Inference for Large Speech Language Model)**  \n   论文提出加权令牌合并框架，提升语音任务的内存和推理效率。发现它在 EMNLP 2024 基准上实现 7 倍内存节省，无性能损失。\n\n11. **人们难以检测 AI 语音克隆 (People are poorly equipped to detect AI-powered voice clones)**  \n   作者：Sarah Barrington 等。论文通过感知实验发现，人类在识别 AI 语音克隆时准确率仅 60%，强调了语音生成的安全风险。\n\n12. **任务无关的终身机器人学习 (Task-free Lifelong Robot Learning with Retrieval-based Weighted Local Adaptation)**  \n   论文引入检索-based 局部适应技术，缓解灾难性遗忘。发现它在无任务 ID 的场景中显著提升机器人性能。\n\n13. **引导搜索流：通过最优路径指导学习搜索 (Guided Stream of Search: Learning to Better Search with Language Models via Optimal Path Guidance)**  \n   论文提出 GSoS 方法，利用最优路径提升 LLM 的搜索能力。发现它在数学推理任务中超越基线。\n\n14. **通过细化局部学习系数揭示注意力头的分化和专业化 (Differentiation and Specialization of Attention Heads via the Refined Local Learning Coefficient)**  \n   论文使用奇异学习理论分析 Transformer 的内部结构，发现注意力头在训练中逐步分化和专业化。\n\n15. **可解释的方法检测与住房和驱逐相关的判例法 (An explainable approach to detect case law on housing and eviction issues)**  \n   论文构建模型检测欧洲人权法院的住房相关案例，提供可解释性。发现 NLP 可有效识别新案例。\n\n### 快速掠过其他论文\n剩余论文涉及 AI 安全、生成模型、多代理系统和特定应用领域，以下仅列出标题和简要发现，限于篇幅不做深入讨论：\n\n16. **Harm Ratio: 一种新颖且通用的公平性标准 (Harm Ratio: A Novel and Versatile Fairness Criterion)**  \n   提出公平性标准，应用于决策任务，提升了算法公平性。\n\n17. **CalliffusionV2: 个性化的自然书法生成 (CalliffusionV2: Personalized Natural Calligraphy Generation)**  \n   生成中文书法，实现了多模态控制。\n\n18. **F-Fidelity: 忠实性评估的鲁棒框架 (F-Fidelity: A Robust Framework for Faithfulness Evaluation)**  \n   改进 XAI 评估，减少信息泄露。\n\n19. **无标签主观玩家体验建模 (Label-Free Subjective Player Experience Modelling)**  \n   使用视频预测玩家情感。\n\n20. **AutoML-Agent: 全管道 AutoML 的多代理框架 (AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML)**  \n   利用 LLM 代理优化 AutoML 流程。\n\n21. **AiBAT: AI 辅助构建、组装和测试指令 (AiBAT: Artificial Intelligence/Instructions for Build, Assembly, and Test)**  \n   AI 加速硬件指令生成。\n\n22. **Visual Editing: 通过提示优化进行实时编辑 (Visual Editing with LLM-based Tool Chaining)**  \n   LLM 用于图像编辑优化。\n\n23. **LLMCO2: LLM 推理的碳足迹预测 (LLMCO2: Advancing Accurate Carbon Footprint Prediction)**  \n   预测 LLM 能源消耗。\n\n24. **SymmetricDiffusers: 在有限对称群上学习离散扩散 (SymmetricDiffusers: Learning Discrete Diffusion on Finite Symmetric Groups)**  \n   应用于组合优化任务。\n\n25. **TSFlow: 时间序列流动匹配 (Flow Matching with Gaussian Process Priors)**  \n   提升时间序列预测。\n\n其他论文（如第26-151篇）多为技术细节或特定应用（如图像生成、公平性、机器人学习），贡献包括新算法或实验验证，但不为核心亮点，故从略。例如，\"Fine-Tuning Language Models with Differential Privacy\" 讨论隐私保护训练；\"LLM Safeguard is a Double-Edged Sword\" 探索 LLM 安全漏洞。总体上，这些论文丰富了 AI 子领域，但影响力较前述论文小。\n\n今天的 arXiv 更新展示了 AI 领域的多样创新，LLM 和多模态模型的进展尤为值得关注。更多细节可查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2410.14690v1",
      "title": "Rethinking VLMs and LLMs for Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Avi Cooper",
        "Keizo Kato",
        "Chia-Hsien Shih",
        "Hiroaki Yamane",
        "Kasper Vinken",
        "Kentaro Takemoto",
        "Taro Sunagawa",
        "Hao-Wei Yeh",
        "Jin Yamanaka",
        "Ian Mason",
        "Xavier Boix"
      ],
      "abstract": "Visual Language Models (VLMs) are now increasingly being merged with Large\nLanguage Models (LLMs) to enable new capabilities, particularly in terms of\nimproved interactivity and open-ended responsiveness. While these are\nremarkable capabilities, the contribution of LLMs to enhancing the longstanding\nkey problem of classifying an image among a set of choices remains unclear.\nThrough extensive experiments involving seven models, ten visual understanding\ndatasets, and multiple prompt variations per dataset, we find that, for object\nand scene recognition, VLMs that do not leverage LLMs can achieve better\nperformance than VLMs that do. Yet at the same time, leveraging LLMs can\nimprove performance on tasks requiring reasoning and outside knowledge. In\nresponse to these challenges, we propose a pragmatic solution: a lightweight\nfix involving a relatively small LLM that efficiently routes visual tasks to\nthe most suitable model for the task. The LLM router undergoes training using a\ndataset constructed from more than 2.5 million examples of pairs of visual task\nand model accuracy. Our results reveal that this lightweight fix surpasses or\nmatches the accuracy of state-of-the-art alternatives, including GPT-4V and\nHuggingGPT, while improving cost-effectiveness.",
      "tldr_zh": "这篇论文重新审视了 VLMs（Visual Language Models）和 LLMs（Large Language Models）在图像分类中的作用，通过对七个模型、十个视觉理解数据集和多种提示变体的实验，发现不使用 LLMs 的 VLMs 在对象和场景识别任务上表现更好，而使用 LLMs 则能提升需要推理和外部知识的任务。作者提出了一种实用解决方案：一个轻量级 LLM 路由器，它通过超过 250 万样本的训练数据集学习高效地将视觉任务路由到最合适的模型。结果显示，该方法在准确性上超越或匹配 GPT-4V 和 HuggingGPT，同时显著提高了成本效益。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14690v1",
      "published_date": "2024-10-03 23:40:21 UTC",
      "updated_date": "2024-10-03 23:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:26:23.896780"
    },
    {
      "arxiv_id": "2410.03039v1",
      "title": "Revealing the Unseen: Guiding Personalized Diffusion Models to Expose Training Data",
      "title_zh": "揭示隐藏：引导个性化扩散模型暴露训练数据",
      "authors": [
        "Xiaoyu Wu",
        "Jiaru Zhang",
        "Steven Wu"
      ],
      "abstract": "Diffusion Models (DMs) have evolved into advanced image generation tools,\nespecially for few-shot fine-tuning where a pretrained DM is fine-tuned on a\nsmall set of images to capture specific styles or objects. Many people upload\nthese personalized checkpoints online, fostering communities such as Civitai\nand HuggingFace. However, model owners may overlook the potential risks of data\nleakage by releasing their fine-tuned checkpoints. Moreover, concerns regarding\ncopyright violations arise when unauthorized data is used during fine-tuning.\nIn this paper, we ask: \"Can training data be extracted from these fine-tuned\nDMs shared online?\" A successful extraction would present not only data leakage\nthreats but also offer tangible evidence of copyright infringement. To answer\nthis, we propose FineXtract, a framework for extracting fine-tuning data. Our\nmethod approximates fine-tuning as a gradual shift in the model's learned\ndistribution -- from the original pretrained DM toward the fine-tuning data. By\nextrapolating the models before and after fine-tuning, we guide the generation\ntoward high-probability regions within the fine-tuned data distribution. We\nthen apply a clustering algorithm to extract the most probable images from\nthose generated using this extrapolated guidance. Experiments on DMs fine-tuned\nwith datasets such as WikiArt, DreamBooth, and real-world checkpoints posted\nonline validate the effectiveness of our method, extracting approximately 20%\nof fine-tuning data in most cases, significantly surpassing baseline\nperformance.",
      "tldr_zh": "该研究探讨了从微调后的 Diffusion Models (DMs) 中提取训练数据的风险，特别是在少样本微调场景下，可能导致数据泄露和版权侵权问题。论文提出 FineXtract 框架，通过将微调过程视为模型分布的 gradual shift，并利用预训练和微调后模型的外推引导生成图像，然后应用聚类算法提取高概率区域内的训练数据。实验在 WikiArt、DreamBooth 和真实在线检查点上验证了该方法的有效性，成功提取约 20% 的训练数据，显著优于基线性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2410.03039v1",
      "published_date": "2024-10-03 23:06:11 UTC",
      "updated_date": "2024-10-03 23:06:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:27:28.048077"
    },
    {
      "arxiv_id": "2410.03035v3",
      "title": "SPINE: Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments",
      "title_zh": "SPINE：针对",
      "authors": [
        "Zachary Ravichandran",
        "Varun Murali",
        "Mariliza Tzes",
        "George J. Pappas",
        "Vijay Kumar"
      ],
      "abstract": "As robots become increasingly capable, users will want to describe high-level\nmissions and have robots infer the relevant details. Because pre-built maps are\ndifficult to obtain in many realistic settings, accomplishing such missions\nwill require the robot to map and plan online. While many semantic planning\nmethods operate online, they are typically designed for well specified missions\nsuch as object search or exploration. Recently, Large Language Models (LLMs)\nhave demonstrated powerful contextual reasoning abilities over a range of\nrobotic tasks described in natural language. However, existing LLM-enabled\nplanners typically do not consider online planning or complex missions; rather,\nrelevant subtasks and semantics are provided by a pre-built map or a user. We\naddress these limitations via SPINE, an online planner for missions with\nincomplete mission specifications provided in natural language. The planner\nuses an LLM to reason about subtasks implied by the mission specification and\nthen realizes these subtasks in a receding horizon framework. Tasks are\nautomatically validated for safety and refined online with new map\nobservations. We evaluate SPINE in simulation and real-world settings with\nmissions that require multiple steps of semantic reasoning and exploration in\ncluttered outdoor environments of over 20,000m$^2$. Compared to baselines that\nuse existing LLM-enabled planning approaches, our method is over twice as\nefficient in terms of time and distance, requires less user interactions, and\ndoes not require a full map. Additional resources are provided at\nhttps://zacravichandran.github.io/SPINE.",
      "tldr_zh": "该研究提出SPINE，一种在线语义规划框架，用于处理在无结构环境中由不完整自然语言规范指定的机器人任务。SPINE利用Large Language Models (LLMs)来推理隐含的子任务，并在后退地平线框架中实现这些任务，同时通过在线映射和观察来验证安全性和优化规划。实验在模拟和真实场景中显示，SPINE在超过20,000m²的杂乱户外环境中，比现有LLM-enabled规划方法效率提高一倍以上，减少用户交互，且无需完整地图。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to the International Conference on Robotics and Automation\n  (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03035v3",
      "published_date": "2024-10-03 22:41:47 UTC",
      "updated_date": "2025-03-21 01:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:26:47.677534"
    },
    {
      "arxiv_id": "2410.12837v1",
      "title": "A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Shailja Gupta",
        "Rajesh Ranjan",
        "Surya Narayan Singh"
      ],
      "abstract": "This paper presents a comprehensive study of Retrieval-Augmented Generation\n(RAG), tracing its evolution from foundational concepts to the current state of\nthe art. RAG combines retrieval mechanisms with generative language models to\nenhance the accuracy of outputs, addressing key limitations of LLMs. The study\nexplores the basic architecture of RAG, focusing on how retrieval and\ngeneration are integrated to handle knowledge-intensive tasks. A detailed\nreview of the significant technological advancements in RAG is provided,\nincluding key innovations in retrieval-augmented language models and\napplications across various domains such as question-answering, summarization,\nand knowledge-based tasks. Recent research breakthroughs are discussed,\nhighlighting novel methods for improving retrieval efficiency. Furthermore, the\npaper examines ongoing challenges such as scalability, bias, and ethical\nconcerns in deployment. Future research directions are proposed, focusing on\nimproving the robustness of RAG models, expanding the scope of application of\nRAG models, and addressing societal implications. This survey aims to serve as\na foundational resource for researchers and practitioners in understanding the\npotential of RAG and its trajectory in natural language processing.",
      "tldr_zh": "本文对 Retrieval-Augmented Generation (RAG) 进行了全面调研，追踪其从基础概念到当前状态的演变，并强调 RAG 通过结合检索机制和生成式语言模型，提升了 LLMs 在知识密集型任务中的输出准确性。调研回顾了 RAG 的基本架构、技术创新（如检索效率改进）和在问答、总结等领域的广泛应用，同时讨论了最近的研究突破。论文还考察了现有挑战，包括可扩展性、偏差和伦理问题，并提出未来方向，如增强模型鲁棒性、扩展应用范围及处理社会影响。该调研旨在为自然语言处理领域的研究者和从业者提供基础资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12837v1",
      "published_date": "2024-10-03 22:29:47 UTC",
      "updated_date": "2024-10-03 22:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:26:59.740850"
    },
    {
      "arxiv_id": "2410.03032v3",
      "title": "CounterQuill: Investigating the Potential of Human-AI Collaboration in Online Counterspeech Writing",
      "title_zh": "CounterQuill：调查人类-AI ",
      "authors": [
        "Xiaohan Ding",
        "Kaike Ping",
        "Uma Sushmitha Gunturi",
        "Buse Carik",
        "Sophia Stil",
        "Lance T Wilhelm",
        "Taufiq Daryanto",
        "James Hawdon",
        "Sang Won Lee",
        "Eugenia H Rho"
      ],
      "abstract": "Online hate speech has become increasingly prevalent on social media, causing\nharm to individuals and society. While automated content moderation has\nreceived considerable attention, user-driven counterspeech remains a less\nexplored yet promising approach. However, many people face difficulties in\ncrafting effective responses. We introduce CounterQuill, a human-AI\ncollaborative system that helps everyday users with writing empathetic\ncounterspeech, not by generating automatic replies, but by educating them\nthrough reflection and response. CounterQuill follows a three-stage workflow\ngrounded in computational thinking: (1) a learning session to build\nunderstanding of hate speech and counterspeech, (2) a brainstorming session to\nidentify harmful patterns and ideate counterspeech ideas, and (3) a co-writing\nsession that helps users refine their counter responses while preserving\npersonal voice. Through a user study \\r{ho}(N=20), we found that CounterQuill\nhelped participants develop the skills to brainstorm and draft counterspeech\nwith increased confidence and control throughout the process. Our findings\nhighlight how AI systems can scaffold complex communication tasks through\nstructured, human-centered workflows that educate users on how to recognize,\nreflect on, and respond to online hate speech.",
      "tldr_zh": "本研究探讨了人类-AI 协作在应对在线仇恨言论时的潜力，引入了 CounterQuill 系统，该系统帮助普通用户通过教育和反思的方式撰写富有同情心的 counterspeech，而非直接生成自动回复。CounterQuill 采用一个三阶段工作流程：学习阶段构建对仇恨言论和 counterspeech 的理解、脑力激荡阶段识别有害模式并产生想法，以及共同写作阶段协助用户完善回应并保留个人风格。通过用户研究（N=20），发现该系统显著提升了参与者的脑力激荡和起草技能，提高了他们的信心和控制力，并展示了 AI 如何通过结构化的人类中心工作流程来支持复杂沟通任务。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03032v3",
      "published_date": "2024-10-03 22:29:20 UTC",
      "updated_date": "2025-05-16 23:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:27:12.504234"
    },
    {
      "arxiv_id": "2410.03030v2",
      "title": "Dynamic Sparse Training versus Dense Training: The Unexpected Winner in Image Corruption Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Boqian Wu",
        "Qiao Xiao",
        "Shunxin Wang",
        "Nicola Strisciuglio",
        "Mykola Pechenizkiy",
        "Maurice van Keulen",
        "Decebal Constantin Mocanu",
        "Elena Mocanu"
      ],
      "abstract": "It is generally perceived that Dynamic Sparse Training opens the door to a\nnew era of scalability and efficiency for artificial neural networks at,\nperhaps, some costs in accuracy performance for the classification task. At the\nsame time, Dense Training is widely accepted as being the \"de facto\" approach\nto train artificial neural networks if one would like to maximize their\nrobustness against image corruption. In this paper, we question this general\npractice. Consequently, we claim that, contrary to what is commonly thought,\nthe Dynamic Sparse Training methods can consistently outperform Dense Training\nin terms of robustness accuracy, particularly if the efficiency aspect is not\nconsidered as a main objective (i.e., sparsity levels between 10% and up to\n50%), without adding (or even reducing) resource cost. We validate our claim on\ntwo types of data, images and videos, using several traditional and modern deep\nlearning architectures for computer vision and three widely studied Dynamic\nSparse Training algorithms. Our findings reveal a new yet-unknown benefit of\nDynamic Sparse Training and open new possibilities in improving deep learning\nrobustness beyond the current state of the art.",
      "tldr_zh": "这篇论文比较了Dynamic Sparse Training和Dense Training在图像损坏鲁棒性方面的表现，挑战了传统观点，即Dense Training是提升鲁棒性的标准方法。研究发现，Dynamic Sparse Training在稀疏度为10%至50%的条件下，能够在不增加（甚至减少）资源成本的情况下，显著优于Dense Training的鲁棒性准确率。作者通过在图像和视频数据上，使用多种深度学习架构（如传统和现代模型）以及三种Dynamic Sparse Training算法进行实验，验证了这一优势。这些发现揭示了Dynamic Sparse Training的潜在新益处，并为超越当前深度学习鲁棒性状态开辟了新可能性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03030v2",
      "published_date": "2024-10-03 22:24:54 UTC",
      "updated_date": "2025-03-05 04:37:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:27:24.219128"
    },
    {
      "arxiv_id": "2410.03024v2",
      "title": "Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Kollovieh",
        "Marten Lienen",
        "David Lüdke",
        "Leo Schwinn",
        "Stephan Günnemann"
      ],
      "abstract": "Recent advancements in generative modeling, particularly diffusion models,\nhave opened new directions for time series modeling, achieving state-of-the-art\nperformance in forecasting and synthesis. However, the reliance of\ndiffusion-based models on a simple, fixed prior complicates the generative\nprocess since the data and prior distributions differ significantly. We\nintroduce TSFlow, a conditional flow matching (CFM) model for time series\ncombining Gaussian processes, optimal transport paths, and data-dependent prior\ndistributions. By incorporating (conditional) Gaussian processes, TSFlow aligns\nthe prior distribution more closely with the temporal structure of the data,\nenhancing both unconditional and conditional generation. Furthermore, we\npropose conditional prior sampling to enable probabilistic forecasting with an\nunconditionally trained model. In our experimental evaluation on eight\nreal-world datasets, we demonstrate the generative capabilities of TSFlow,\nproducing high-quality unconditional samples. Finally, we show that both\nconditionally and unconditionally trained models achieve competitive results\nacross multiple forecasting benchmarks.",
      "tldr_zh": "本论文提出 TSFlow，一种结合 Gaussian processes、先验分布和 optimal transport paths 的 conditional flow matching (CFM) 模型，用于改进概率时间序列预测。TSFlow 通过采用数据相关的先验分布和条件 Gaussian processes，更好地捕捉数据的时间结构，并引入 conditional prior sampling 技术，实现高效的无条件和条件生成。实验在八个真实数据集上验证了其生成高质量样本的能力，并在多个预测基准上取得与基线模型竞争性的结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03024v2",
      "published_date": "2024-10-03 22:12:50 UTC",
      "updated_date": "2025-05-11 22:30:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:27:41.318792"
    },
    {
      "arxiv_id": "2410.03019v2",
      "title": "Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review",
      "title_zh": "翻译失败",
      "authors": [
        "Sungduk Yu",
        "Man Luo",
        "Avinash Madasu",
        "Vasudev Lal",
        "Phillip Howard"
      ],
      "abstract": "Peer review is a critical process for ensuring the integrity of published\nscientific research. Confidence in this process is predicated on the assumption\nthat experts in the relevant domain give careful consideration to the merits of\nmanuscripts which are submitted for publication. With the recent rapid\nadvancements in the linguistic capabilities of large language models (LLMs), a\nnew potential risk to the peer review process is that negligent reviewers will\nrely on LLMs to perform the often time consuming process of reviewing a paper.\nIn this study, we investigate the ability of existing AI text detection\nalgorithms to distinguish between peer reviews written by humans and different\nstate-of-the-art LLMs. Our analysis shows that existing approaches fail to\nidentify many GPT-4o written reviews without also producing a high number of\nfalse positive classifications. To address this deficiency, we propose a new\ndetection approach which surpasses existing methods in the identification of\nGPT-4o written peer reviews at low levels of false positive classifications.\nOur work reveals the difficulty of accurately identifying AI-generated text at\nthe individual review level, highlighting the urgent need for new tools and\nmethods to detect this type of unethical application of generative AI.",
      "tldr_zh": "本文研究了大型语言模型(LLM)可能被滥用于撰写同行评审，从而威胁科研诚信的问题，重点调查现有AI文本检测算法在区分人类和LLM（如GPT-4o）生成评审方面的能力。结果显示，这些算法在识别GPT-4o写的评审时表现不佳，往往伴随高误报率。为此，作者提出了一种新检测方法，能够在低误报率下更准确地识别AI生成文本。研究强调了在个体评审层面检测AI文本的难度，并呼吁开发新工具来防范这种不道德的AI应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03019v2",
      "published_date": "2024-10-03 22:05:06 UTC",
      "updated_date": "2024-12-06 17:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:27:53.059642"
    },
    {
      "arxiv_id": "2410.03018v1",
      "title": "Transforming Teachers' Roles and Agencies in the Era of Generative AI: Perceptions, Acceptance, Knowledge, and Practices",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoming Zhai"
      ],
      "abstract": "This paper explores the transformative impact of Generative Artificial\nIntelligence (GenAI) on teachers' roles and agencies in education, presenting a\ncomprehensive framework that addresses teachers' perceptions, knowledge,\nacceptance, and practices of GenAI. As GenAI technologies, such as ChatGPT,\nbecome increasingly integrated into educational settings, teachers are required\nto adapt to evolving classroom dynamics, where AI plays a significant role in\ncontent creation, personalized learning, and student engagement. However,\nexisting literature often treats these factors in isolation, overlooking how\nthey collectively influence teachers' ability to effectively integrate GenAI\ninto their pedagogical practices. This paper fills this gap by proposing a\nframework that categorizes teachers into four roles -- Observer, Adopter,\nCollaborator, and Innovator -- each representing different levels of GenAI\nengagement, outlining teachers' agencies in GenAI classrooms. By highlighting\nthe need for continuous professional development and institutional support, we\ndemonstrate how teachers can evolve from basic GenAI users to co-creators of\nknowledge alongside GenAI systems. The findings emphasize that for GenAI to\nreach its full educational potential, teachers must not only accept and\nunderstand its capabilities but also integrate it deeply into their teaching\nstrategies. This study contributes to the growing literature on GenAI in\neducation, offering practical implications for supporting teachers in\nnavigating the complexities of GenAI adoption.",
      "tldr_zh": "本研究探讨了 Generative AI (GenAI) 对教师角色和代理的影响，提出一个全面框架，整合教师对 GenAI 的感知、知识、接受度和实践，以帮助他们在教育环境中有效应用 AI 工具如 ChatGPT。框架将教师分为四类——Observer、Adopter、Collaborator 和 Innovator——代表不同水平的 GenAI 参与，并强调通过持续专业发展和机构支持，教师可从基本用户演变为与 AI 共同创建知识的合作者。研究发现，教师需深入理解和整合 GenAI 到教学策略中，以充分发挥其在内容创建、个性化学习和学生参与方面的潜力，并为教育实践提供实际指导，支持 GenAI 的顺利采用。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03018v1",
      "published_date": "2024-10-03 21:59:01 UTC",
      "updated_date": "2024-10-03 21:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:28:15.856868"
    },
    {
      "arxiv_id": "2410.03007v1",
      "title": "FastAdaSP: Multitask-Adapted Efficient Inference for Large Speech Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Lu",
        "Jiaqi Song",
        "Chao-Han Huck Yang",
        "Shinji Watanabe"
      ],
      "abstract": "In this study, we aim to explore Multitask Speech Language Model (SpeechLM)\nefficient inference via token reduction. Unlike other modalities such as vision\nor text, speech has unique temporal dependencies, making previous efficient\ninference works on other modalities not directly applicable. Furthermore,\nmethods for efficient SpeechLM inference on long sequence and sparse signals\nremain largely unexplored. Then we propose FastAdaSP, a weighted token merging\nframework specifically designed for various speech-related tasks to improve the\ntrade-off between efficiency and performance. Experimental results on WavLLM\nand Qwen-Audio show that our method achieves the state-of-the-art (SOTA)\nefficiency-performance trade-off compared with other baseline methods.\nSpecifically, FastAdaSP achieved 7x memory efficiency and 1.83x decoding\nthroughput without any degradation on tasks like Emotion Recognition (ER) and\nSpoken Question Answering (SQA). The code will be available at\nhttps://github.com/yichen14/FastAdaSP",
      "tldr_zh": "本研究针对多任务语音语言模型 (SpeechLM) 的高效推理问题，提出 FastAdaSP 框架，通过加权 token 合并方法来减少计算量，同时考虑语音的独特时间依赖性，以适应长序列和稀疏信号。该框架针对各种语音相关任务优化效率与性能的权衡，在 WavLLM 和 Qwen-Audio 模型上进行实验，结果显示 FastAdaSP 实现了 7 倍内存效率和 1.83 倍解码吞吐量的提升，在 Emotion Recognition (ER) 和 Spoken Question Answering (SQA) 等任务上保持性能无衰减，达到了 SOTA 水平。代码已开源，可在 https://github.com/yichen14/FastAdaSP 获取。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "EMNLP 2024 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2410.03007v1",
      "published_date": "2024-10-03 21:33:07 UTC",
      "updated_date": "2024-10-03 21:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:28:17.469847"
    },
    {
      "arxiv_id": "2410.03791v2",
      "title": "People are poorly equipped to detect AI-powered voice clones",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Barrington",
        "Emily A. Cooper",
        "Hany Farid"
      ],
      "abstract": "As generative artificial intelligence (AI) continues its ballistic\ntrajectory, everything from text to audio, image, and video generation\ncontinues to improve at mimicking human-generated content. Through a series of\nperceptual studies, we report on the realism of AI-generated voices in terms of\nidentity matching and naturalness. We find human participants cannot\nconsistently identify recordings of AI-generated voices. Specifically,\nparticipants perceived the identity of an AI-voice to be the same as its real\ncounterpart approximately 80% of the time, and correctly identified a voice as\nAI generated only about 60% of the time.",
      "tldr_zh": "这篇论文通过一系列感知实验(perceptual studies)评估了 AI 生成语音(AI-generated voices)的真实性，包括身份匹配和自然度。结果显示，参与者将 AI 语音误认为其真实对应者的身份约 80% 的时间，且正确识别语音为 AI 生成的仅约 60%。这些发现突显了人类在检测 AI 语音克隆方面的不足，强调了生成式 AI 技术潜在风险的警示作用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03791v2",
      "published_date": "2024-10-03 21:26:58 UTC",
      "updated_date": "2025-01-25 01:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:28:29.106752"
    },
    {
      "arxiv_id": "2410.02995v3",
      "title": "Task-free Lifelong Robot Learning with Retrieval-based Weighted Local Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Pengzhi Yang",
        "Xinyu Wang",
        "Ruipeng Zhang",
        "Cong Wang",
        "Frans A. Oliehoek",
        "Jens Kober"
      ],
      "abstract": "A fundamental objective in intelligent robotics is to move towards lifelong\nlearning robot that can learn and adapt to unseen scenarios over time. However,\ncontinually learning new tasks would introduce catastrophic forgetting problems\ndue to data distribution shifts. To mitigate this, we store a subset of data\nfrom previous tasks and utilize it in two manners: leveraging experience replay\nto retain learned skills and applying a novel Retrieval-based Local Adaptation\ntechnique to restore relevant knowledge. Since a lifelong learning robot must\noperate in task-free scenarios, where task IDs and even boundaries are not\navailable, our method performs effectively without relying on such information.\nWe also incorporate a selective weighting mechanism to focus on the most\n\"forgotten\" skill segment, ensuring effective knowledge restoration.\nExperimental results across diverse manipulation tasks demonstrate that our\nframework provides a scalable paradigm for lifelong learning, enhancing robot\nperformance in open-ended, task-free scenarios.",
      "tldr_zh": "这篇论文针对智能机器人的终身学习问题，提出了一种无需任务ID的任务自由框架，以缓解持续学习导致的灾难性遗忘（catastrophic forgetting）。方法包括存储之前任务的数据，用于经验回放（experience replay）保留技能，以及创新的Retrieval-based Weighted Local Adaptation技术来恢复相关知识，并通过选择性加权机制重点处理最“被遗忘”的技能段。实验在多种操作任务上验证了该框架的可扩展性，提升了机器人在开放式、任务自由场景中的性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02995v3",
      "published_date": "2024-10-03 21:11:42 UTC",
      "updated_date": "2025-02-03 12:08:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:28:42.489947"
    },
    {
      "arxiv_id": "2410.02992v1",
      "title": "Guided Stream of Search: Learning to Better Search with Language Models via Optimal Path Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Seungyong Moon",
        "Bumsoo Park",
        "Hyun Oh Song"
      ],
      "abstract": "While language models have demonstrated impressive capabilities across a\nrange of tasks, they still struggle with tasks that require complex planning\nand reasoning. Recent studies have proposed training language models on search\nprocesses rather than optimal solutions, resulting in better generalization\nperformance even though search processes are noisy and even suboptimal.\nHowever, these studies overlook the value of optimal solutions, which can serve\nas step-by-step landmarks to guide more effective search. In this work, we\nexplore how to leverage optimal solutions to enhance the search and planning\nabilities of language models. To this end, we propose guided stream of search\n(GSoS), which seamlessly incorporates optimal solutions into the\nself-generation process in a progressive manner, producing high-quality search\ntrajectories. These trajectories are then distilled into the pre-trained model\nvia supervised fine-tuning. Our approach significantly enhances the search and\nplanning abilities of language models on Countdown, a simple yet challenging\nmathematical reasoning task. Notably, combining our method with RL fine-tuning\nyields further improvements, whereas previous supervised fine-tuning methods do\nnot benefit from RL. Furthermore, our approach exhibits greater effectiveness\nthan leveraging optimal solutions in the form of subgoal rewards.",
      "tldr_zh": "该研究探讨了如何利用最优解来提升语言模型在复杂规划和推理任务中的表现，提出 guided stream of search (GSoS) 方法，将最优解逐步整合到语言模型的自生成过程，生成高质量的搜索轨迹。GSoS 通过监督微调将这些轨迹蒸馏到预训练模型中，显著提高了语言模型在 Countdown 数学推理任务上的搜索和规划能力。与传统方法相比，该方法与 RL fine-tuning 结合后进一步提升效果，且优于使用最优解作为子目标奖励的策略。总体上，这为语言模型的泛化性能提供了更有效的训练框架。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02992v1",
      "published_date": "2024-10-03 21:07:59 UTC",
      "updated_date": "2024-10-03 21:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:28:54.339008"
    },
    {
      "arxiv_id": "2410.02984v1",
      "title": "Differentiation and Specialization of Attention Heads via the Refined Local Learning Coefficient",
      "title_zh": "翻译失败",
      "authors": [
        "George Wang",
        "Jesse Hoogland",
        "Stan van Wingerden",
        "Zach Furman",
        "Daniel Murfet"
      ],
      "abstract": "We introduce refined variants of the Local Learning Coefficient (LLC), a\nmeasure of model complexity grounded in singular learning theory, to study the\ndevelopment of internal structure in transformer language models during\ntraining. By applying these \\textit{refined LLCs} (rLLCs) to individual\ncomponents of a two-layer attention-only transformer, we gain novel insights\ninto the progressive differentiation and specialization of attention heads. Our\nmethodology reveals how attention heads differentiate into distinct functional\nroles over the course of training, analyzes the types of data these heads\nspecialize to process, and discovers a previously unidentified multigram\ncircuit. These findings demonstrate that rLLCs provide a principled,\nquantitative toolkit for \\textit{developmental interpretability}, which aims to\nunderstand models through their evolution across the learning process. More\nbroadly, this work takes a step towards establishing the correspondence between\ndata distributional structure, geometric properties of the loss landscape,\nlearning dynamics, and emergent computational structures in neural networks.",
      "tldr_zh": "本研究引入了 refined Local Learning Coefficient (rLLCs)，一种基于奇异学习理论的改进复杂度度量，用于分析 transformer 语言模型在训练过程中的内部结构发展。应用 rLLCs 到两层 attention-only transformer 的单个组件，揭示了 attention heads 如何逐步分化并专业化成不同的功能角色，包括处理特定数据类型并发现一个新的 multigram circuit。这些发现为 developmental interpretability 提供了定量工具，并建立了数据分布结构、损失景观几何属性、学习动态与神经网络涌现计算结构之间的对应关系。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02984v1",
      "published_date": "2024-10-03 20:51:02 UTC",
      "updated_date": "2024-10-03 20:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:29:05.558607"
    },
    {
      "arxiv_id": "2410.02978v1",
      "title": "An explainable approach to detect case law on housing and eviction issues within the HUDOC database",
      "title_zh": "一种可解释的方法用于检测 HUDOC 数据库中关于住房和驱逐问题的判例法",
      "authors": [
        "Mohammad Mohammadi",
        "Martijn Wieling",
        "Michel Vols"
      ],
      "abstract": "Case law is instrumental in shaping our understanding of human rights,\nincluding the right to adequate housing. The HUDOC database provides access to\nthe textual content of case law from the European Court of Human Rights\n(ECtHR), along with some metadata. While this metadata includes valuable\ninformation, such as the application number and the articles addressed in a\ncase, it often lacks detailed substantive insights, such as the specific issues\na case covers. This underscores the need for detailed analysis to extract such\ninformation. However, given the size of the database - containing over 40,000\ncases - an automated solution is essential.\n  In this study, we focus on the right to adequate housing and aim to build\nmodels to detect cases related to housing and eviction issues. Our experiments\nshow that the resulting models not only provide performance comparable to more\nsophisticated approaches but are also interpretable, offering explanations for\ntheir decisions by highlighting the most influential words. The application of\nthese models led to the identification of new cases that were initially\noverlooked during data collection. This suggests that NLP approaches can be\neffectively applied to categorise case law based on the specific issues they\naddress.",
      "tldr_zh": "这篇论文提出了一种可解释的方法，用于在 HUDOC 数据库中检测与住房和驱逐问题相关的欧洲人权法院 (ECtHR) 案例法，以弥补数据库元数据缺乏详细实质性洞见的不足。研究构建了基于 NLP 的模型，这些模型在性能上与更复杂的方案相当，并通过突出最有影响力的单词提供决策解释。实验结果显示，该方法成功识别了数据收集中被忽略的新案例，证明了 NLP 技术在根据具体问题分类案例法方面的有效应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02978v1",
      "published_date": "2024-10-03 20:39:51 UTC",
      "updated_date": "2024-10-03 20:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:29:17.398938"
    },
    {
      "arxiv_id": "2410.02977v1",
      "title": "Harm Ratio: A Novel and Versatile Fairness Criterion",
      "title_zh": "翻译失败",
      "authors": [
        "Soroush Ebadian",
        "Rupert Freeman",
        "Nisarg Shah"
      ],
      "abstract": "Envy-freeness has become the cornerstone of fair division research. In\nsettings where each individual is allocated a disjoint share of collective\nresources, it is a compelling fairness axiom which demands that no individual\nstrictly prefer the allocation of another individual to their own.\nUnfortunately, in many real-life collective decision-making problems, the goal\nis to choose a (common) public outcome that is equally applicable to all\nindividuals, and the notion of envy becomes vacuous. Consequently, this\nliterature has avoided studying fairness criteria that focus on individuals\nfeeling a sense of jealousy or resentment towards other individuals (rather\nthan towards the system), missing out on a key aspect of fairness.\n  In this work, we propose a novel fairness criterion, individual harm ratio,\nwhich is inspired by envy-freeness but applies to a broad range of collective\ndecision-making settings. Theoretically, we identify minimal conditions under\nwhich this criterion and its groupwise extensions can be guaranteed, and study\nthe computational complexity of related problems. Empirically, we conduct\nexperiments with real data to show that our fairness criterion is powerful\nenough to differentiate between prominent decision-making algorithms for a\nrange of tasks from voting and fair division to participatory budgeting and\npeer review.",
      "tldr_zh": "本研究提出了一种新的公平标准——individual harm ratio，受Envy-freeness启发，但适用于更广泛的集体决策场景中，解决了传统标准在选择公共结果时无效的问题。该标准聚焦于个体间的嫉妒或怨恨，理论上分析了其及其群组扩展的最小保证条件，并探讨了相关计算复杂性问题。通过真实数据实验，研究证明individual harm ratio能有效区分各种决策算法，在投票、公平分配、参与式预算和同行评审等任务中表现出色。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "To appear at EAAMO 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02977v1",
      "published_date": "2024-10-03 20:36:05 UTC",
      "updated_date": "2024-10-03 20:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:29:38.738718"
    },
    {
      "arxiv_id": "2410.03787v1",
      "title": "CalliffusionV2: Personalized Natural Calligraphy Generation with Flexible Multi-modal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Qisheng Liao",
        "Liang Li",
        "Yulang Fei",
        "Gus Xia"
      ],
      "abstract": "In this paper, we introduce CalliffusionV2, a novel system designed to\nproduce natural Chinese calligraphy with flexible multi-modal control. Unlike\nprevious approaches that rely solely on image or text inputs and lack\nfine-grained control, our system leverages both images to guide generations at\nfine-grained levels and natural language texts to describe the features of\ngenerations. CalliffusionV2 excels at creating a broad range of characters and\ncan quickly learn new styles through a few-shot learning approach. It is also\ncapable of generating non-Chinese characters without prior training.\nComprehensive tests confirm that our system produces calligraphy that is both\nstylistically accurate and recognizable by neural network classifiers and human\nevaluators.",
      "tldr_zh": "本论文介绍了 CalliffusionV2，一种用于生成个性化自然中文书法的创新系统，它通过灵活的多模态控制结合图像（用于细粒度指导）和文本（用于描述生成特征），超越了以往仅依赖单一输入的方法。\n该系统支持生成广泛字符类型，并采用 few-shot learning 快速学习新风格，甚至能在无需预训练的情况下生成非中文字符。\n综合测试表明，CalliffusionV2 产生的书法在风格上准确可靠，并获得神经网络分类器和人类评估者的认可。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03787v1",
      "published_date": "2024-10-03 20:26:54 UTC",
      "updated_date": "2024-10-03 20:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:29:40.609813"
    },
    {
      "arxiv_id": "2410.02970v2",
      "title": "F-Fidelity: A Robust Framework for Faithfulness Evaluation of Explainable AI",
      "title_zh": "F-Fidelity：一个鲁棒框架，用于可解释人工智能的忠实度评估",
      "authors": [
        "Xu Zheng",
        "Farhad Shirani",
        "Zhuomin Chen",
        "Chaohao Lin",
        "Wei Cheng",
        "Wenbo Guo",
        "Dongsheng Luo"
      ],
      "abstract": "Recent research has developed a number of eXplainable AI (XAI) techniques,\nsuch as gradient-based approaches, input perturbation-base methods, and\nblack-box explanation methods. While these XAI techniques can extract\nmeaningful insights from deep learning models, how to properly evaluate them\nremains an open problem. The most widely used approach is to perturb or even\nremove what the XAI method considers to be the most important features in an\ninput and observe the changes in the output prediction. This approach, although\nstraightforward, suffers the Out-of-Distribution (OOD) problem as the perturbed\nsamples may no longer follow the original data distribution. A recent method\nRemOve And Retrain (ROAR) solves the OOD issue by retraining the model with\nperturbed samples guided by explanations. However, using the model retrained\nbased on XAI methods to evaluate these explainers may cause information leakage\nand thus lead to unfair comparisons. We propose Fine-tuned Fidelity\n(F-Fidelity), a robust evaluation framework for XAI, which utilizes i) an\nexplanation-agnostic fine-tuning strategy, thus mitigating the information\nleakage issue, and ii) a random masking operation that ensures that the removal\nstep does not generate an OOD input. We also design controlled experiments with\nstate-of-the-art (SOTA) explainers and their degraded version to verify the\ncorrectness of our framework. We conduct experiments on multiple data\nmodalities, such as images, time series, and natural language. The results\ndemonstrate that F-Fidelity significantly improves upon prior evaluation\nmetrics in recovering the ground-truth ranking of the explainers. Furthermore,\nwe show both theoretically and empirically that, given a faithful explainer,\nF-Fidelity metric can be used to compute the sparsity of influential input\ncomponents, i.e., to extract the true explanation size.",
      "tldr_zh": "该研究针对 eXplainable AI (XAI) 技术的评估问题，提出了一种鲁棒框架 F-Fidelity，以解决现有方法如输入扰动或 RemOve And Retrain (ROAR) 可能引发的 Out-of-Distribution (OOD) 问题和信息泄漏问题。F-Fidelity 框架采用解释无关的微调策略和随机屏蔽操作，确保评估过程避免 OOD 输入并实现公平比较。实验在图像、时间序列和自然语言等多种数据模态上进行，结果显示 F-Fidelity 显著优于现有指标，能准确恢复 state-of-the-art (SOTA) 解释器的真实排名，并理论及经验上证明其可计算影响输入组件的稀疏性，从而提取真正的解释大小。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to International Conference on Learning Representations\n  (ICLR 2025); 33 Pages, 5 figures, 26 Tables",
      "pdf_url": "http://arxiv.org/pdf/2410.02970v2",
      "published_date": "2024-10-03 20:23:06 UTC",
      "updated_date": "2025-03-06 20:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:29:54.099131"
    },
    {
      "arxiv_id": "2410.02967v1",
      "title": "Label-Free Subjective Player Experience Modelling via Let's Play Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Dave Goel",
        "Athar Mahmoudi-Nejad",
        "Matthew Guzdial"
      ],
      "abstract": "Player Experience Modelling (PEM) is the study of AI techniques applied to\nmodelling a player's experience within a video game. PEM development can be\nlabour-intensive, requiring expert hand-authoring or specialized data\ncollection. In this work, we propose a novel PEM development approach,\napproximating player experience from gameplay video. We evaluate this approach\npredicting affect in the game Angry Birds via a human subject study. We\nvalidate that our PEM can strongly correlate with self-reported and sensor\nmeasures of affect, demonstrating the potential of this approach.",
      "tldr_zh": "本研究提出了一种无需标签的玩家体验建模（Player Experience Modelling, PEM）方法，通过分析Let's Play Videos来近似玩家在视频游戏中的主观体验，从而避免了传统方法依赖专家手工编写或专门数据收集的繁琐过程。在Angry Birds游戏上进行的人类研究中，该方法成功预测了玩家的情感（affect），并显示出与玩家的自报情感和传感器测量高度相关。实验结果验证了这种基于游戏视频的PEM方法的有效性，为简化玩家体验建模提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 3 figures, AAAI Conference on Artificial Intelligence and\n  Interactive Digital Entertainment",
      "pdf_url": "http://arxiv.org/pdf/2410.02967v1",
      "published_date": "2024-10-03 20:12:56 UTC",
      "updated_date": "2024-10-03 20:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:30:04.594973"
    },
    {
      "arxiv_id": "2410.02958v1",
      "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
      "title_zh": "AutoML-Agent：多智能体大型语言模型框架，用于全管道自动机器学习",
      "authors": [
        "Patara Trirat",
        "Wonyong Jeong",
        "Sung Ju Hwang"
      ],
      "abstract": "Automated machine learning (AutoML) accelerates AI development by automating\ntasks in the development pipeline, such as optimal model search and\nhyperparameter tuning. Existing AutoML systems often require technical\nexpertise to set up complex tools, which is in general time-consuming and\nrequires a large amount of human effort. Therefore, recent works have started\nexploiting large language models (LLM) to lessen such burden and increase the\nusability of AutoML frameworks via a natural language interface, allowing\nnon-expert users to build their data-driven solutions. These methods, however,\nare usually designed only for a particular process in the AI development\npipeline and do not efficiently use the inherent capacity of the LLMs. This\npaper proposes AutoML-Agent, a novel multi-agent framework tailored for\nfull-pipeline AutoML, i.e., from data retrieval to model deployment.\nAutoML-Agent takes user's task descriptions, facilitates collaboration between\nspecialized LLM agents, and delivers deployment-ready models. Unlike existing\nwork, instead of devising a single plan, we introduce a retrieval-augmented\nplanning strategy to enhance exploration to search for more optimal plans. We\nalso decompose each plan into sub-tasks (e.g., data preprocessing and neural\nnetwork design) each of which is solved by a specialized agent we build via\nprompting executing in parallel, making the search process more efficient.\nMoreover, we propose a multi-stage verification to verify executed results and\nguide the code generation LLM in implementing successful solutions. Extensive\nexperiments on seven downstream tasks using fourteen datasets show that\nAutoML-Agent achieves a higher success rate in automating the full AutoML\nprocess, yielding systems with good performance throughout the diverse domains.",
      "tldr_zh": "本研究提出AutoML-Agent，一种多智能体LLM框架，旨在自动化整个机器学习管道（从数据检索到模型部署），解决现有AutoML系统需技术专长且耗费大量人力的问题。该框架通过检索增强规划策略（retrieval-augmented planning）优化计划探索，并将任务分解为子任务（如数据预处理和神经网络设计），由专门的LLM智能体并行处理，提高效率。同时，引入多阶段验证（multi-stage verification）来验证执行结果并指导代码生成。实验在七个下游任务和十四个数据集上显示，AutoML-Agent 实现了更高的成功率，并产生了性能优异的系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "47 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02958v1",
      "published_date": "2024-10-03 20:01:09 UTC",
      "updated_date": "2024-10-03 20:01:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:30:17.225865"
    },
    {
      "arxiv_id": "2410.02955v1",
      "title": "AiBAT: Artificial Intelligence/Instructions for Build, Assembly, and Test",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Nuernberger",
        "Anny Liu",
        "Heather Stefanini",
        "Richard Otis",
        "Amanda Towler",
        "R. Peter Dillon"
      ],
      "abstract": "Instructions for Build, Assembly, and Test (IBAT) refers to the process used\nwhenever any operation is conducted on hardware, including tests, assembly, and\nmaintenance. Currently, the generation of IBAT documents is time-intensive, as\nusers must manually reference and transfer information from engineering\ndiagrams and parts lists into IBAT instructions. With advances in machine\nlearning and computer vision, however, it is possible to have an artificial\nintelligence (AI) model perform the partial filling of the IBAT template,\nfreeing up engineer time for more highly skilled tasks. AiBAT is a novel system\nfor assisting users in authoring IBATs. It works by first analyzing assembly\ndrawing documents, extracting information and parsing it, and then filling in\nIBAT templates with the extracted information. Such assisted authoring has\npotential to save time and reduce cost. This paper presents an overview of the\nAiBAT system, including promising preliminary results and discussion on future\nwork.",
      "tldr_zh": "本文研究了 IBAT（Instructions for Build, Assembly, and Test）文档的生成问题，该过程目前依赖手动提取工程图和零件列表信息，耗时费力。AiBAT 系统利用 Artificial Intelligence 和计算机视觉技术，通过分析装配图文档、提取并解析相关信息，自动填充 IBAT 模板，从而帮助工程师节省时间并降低成本。初步结果显示该系统具有显著潜力，论文还讨论了未来的改进方向。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.02955v1",
      "published_date": "2024-10-03 19:57:05 UTC",
      "updated_date": "2024-10-03 19:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:31:22.728948"
    },
    {
      "arxiv_id": "2410.02952v3",
      "title": "Visual Editing with LLM-based Tool Chaining: An Efficient Distillation Approach for Real-Time Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Oren Sultan",
        "Alex Khasin",
        "Guy Shiran",
        "Asnat Greenstein-Messica",
        "Dafna Shahaf"
      ],
      "abstract": "We present a practical distillation approach to fine-tune LLMs for invoking\ntools in real-time applications. We focus on visual editing tasks;\nspecifically, we modify images and videos by interpreting user stylistic\nrequests, specified in natural language (\"golden hour\"), using an LLM to select\nthe appropriate tools and their parameters to achieve the desired visual\neffect. We found that proprietary LLMs such as GPT-3.5-Turbo show potential in\nthis task, but their high cost and latency make them unsuitable for real-time\napplications. In our approach, we fine-tune a (smaller) student LLM with\nguidance from a (larger) teacher LLM and behavioral signals. We introduce\noffline metrics to evaluate student LLMs. Both online and offline experiments\nshow that our student models manage to match the performance of our teacher\nmodel (GPT-3.5-Turbo), significantly reducing costs and latency. Lastly, we\nshow that fine-tuning was improved by 25% in low-data regimes using\naugmentation.",
      "tldr_zh": "我们提出了一种高效的知识蒸馏方法，用于微调大型语言模型（LLM），以在实时应用中实现工具链调用，专注于视觉编辑任务。该方法通过较大的教师模型（如 GPT-3.5-Turbo）指导较小的学生模型，并结合行为信号和数据增强，解释用户自然语言请求（如“golden hour”）来修改图像和视频。实验显示，学生模型的性能与教师模型相当，大幅降低了成本和延迟，并在低数据环境下通过增强技术将微调效果提高了25%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02952v3",
      "published_date": "2024-10-03 19:52:37 UTC",
      "updated_date": "2024-10-10 11:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:30:45.736209"
    },
    {
      "arxiv_id": "2410.02950v1",
      "title": "LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences",
      "title_zh": "LLMCO2：推进LLM推理的准确碳足迹预测",
      "authors": [
        "Zhenxiao Fu",
        "Fan Chen",
        "Shan Zhou",
        "Haitong Li",
        "Lei Jiang"
      ],
      "abstract": "Throughout its lifecycle, a large language model (LLM) generates a\nsubstantially larger carbon footprint during inference than training. LLM\ninference requests vary in batch size, prompt length, and token generation\nnumber, while cloud providers employ different GPU types and quantities to meet\ndiverse service-level objectives for accuracy and latency. It is crucial for\nboth users and cloud providers to have a tool that quickly and accurately\nestimates the carbon impact of LLM inferences based on a combination of\ninference request and hardware configurations before execution. Estimating the\ncarbon footprint of LLM inferences is more complex than training due to lower\nand highly variable model FLOPS utilization, rendering previous equation-based\nmodels inaccurate. Additionally, existing machine learning (ML) prediction\nmethods either lack accuracy or demand extensive training data, as they\ninadequately handle the distinct prefill and decode phases, overlook\nhardware-specific features, and inefficiently sample uncommon inference\nconfigurations. We introduce \\coo, a graph neural network (GNN)-based model\nthat greatly improves the accuracy of LLM inference carbon footprint\npredictions compared to previous methods.",
      "tldr_zh": "该论文探讨了大型语言模型（LLM）在推理阶段产生的碳足迹问题，该阶段因批量大小、提示长度和硬件配置（如GPU类型）而复杂且高度可变，导致现有方程模型和机器学习方法准确性不足。研究者引入了LLMCO2，一种基于图神经网络（GNN）的模型，通过处理预填充和解码阶段、整合硬件特定特征以及高效采样不常见配置，大幅提升了碳足迹预测的准确性。实验结果显示，LLMCO2相对于先前方法显著提高了预测精度，为用户和云提供商提供了一个快速可靠的估算工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02950v1",
      "published_date": "2024-10-03 19:48:45 UTC",
      "updated_date": "2024-10-03 19:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:30:57.228859"
    },
    {
      "arxiv_id": "2410.02942v2",
      "title": "SymmetricDiffusers: Learning Discrete Diffusion on Finite Symmetric Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Yongxing Zhang",
        "Donglin Yang",
        "Renjie Liao"
      ],
      "abstract": "Finite symmetric groups $S_n$ are essential in fields such as combinatorics,\nphysics, and chemistry. However, learning a probability distribution over $S_n$\nposes significant challenges due to its intractable size and discrete nature.\nIn this paper, we introduce SymmetricDiffusers, a novel discrete diffusion\nmodel that simplifies the task of learning a complicated distribution over\n$S_n$ by decomposing it into learning simpler transitions of the reverse\ndiffusion using deep neural networks. We identify the riffle shuffle as an\neffective forward transition and provide empirical guidelines for selecting the\ndiffusion length based on the theory of random walks on finite groups.\nAdditionally, we propose a generalized Plackett-Luce (PL) distribution for the\nreverse transition, which is provably more expressive than the PL distribution.\nWe further introduce a theoretically grounded \"denoising schedule\" to improve\nsampling and learning efficiency. Extensive experiments show that our model\nachieves state-of-the-art or comparable performances on solving tasks including\nsorting 4-digit MNIST images, jigsaw puzzles, and traveling salesman problems.\nOur code is released at https://github.com/DSL-Lab/SymmetricDiffusers.",
      "tldr_zh": "本研究引入了SymmetricDiffusers，一种新型离散扩散模型，用于在有限对称群$S_n$上学习复杂概率分布，以应对其规模庞大和离散性的挑战。该模型通过分解为更简单的逆扩散过渡，利用深度神经网络学习，并采用riffle shuffle作为前向过程，同时基于随机游走理论提供扩散长度的选择指导。创新性地提出广义Plackett-Luce (PL) 分布作为逆过渡，并设计理论支持的“去噪时间表”以提升采样和学习效率。实验结果显示，该模型在排序4位MNIST图像、拼图和旅行 salesman 问题等任务上达到了最先进或可比性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Oral",
      "pdf_url": "http://arxiv.org/pdf/2410.02942v2",
      "published_date": "2024-10-03 19:37:40 UTC",
      "updated_date": "2025-03-05 22:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:31:06.151999"
    },
    {
      "arxiv_id": "2410.02932v1",
      "title": "Intrinsic Evaluation of RAG Systems for Deep-Logic Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Junyi Hu",
        "You Zhou",
        "Jie Wang"
      ],
      "abstract": "We introduce the Overall Performance Index (OPI), an intrinsic metric to\nevaluate retrieval-augmented generation (RAG) mechanisms for applications\ninvolving deep-logic queries. OPI is computed as the harmonic mean of two key\nmetrics: the Logical-Relation Correctness Ratio and the average of BERT\nembedding similarity scores between ground-truth and generated answers. We\napply OPI to assess the performance of LangChain, a popular RAG tool, using a\nlogical relations classifier fine-tuned from GPT-4o on the RAG-Dataset-12000\nfrom Hugging Face. Our findings show a strong correlation between BERT\nembedding similarity scores and extrinsic evaluation scores. Among the commonly\nused retrievers, the cosine similarity retriever using BERT-based embeddings\noutperforms others, while the Euclidean distance-based retriever exhibits the\nweakest performance. Furthermore, we demonstrate that combining multiple\nretrievers, either algorithmically or by merging retrieved sentences, yields\nsuperior performance compared to using any single retriever alone.",
      "tldr_zh": "本研究引入了 Overall Performance Index (OPI)，一个内在指标，用于评估检索增强生成 (RAG) 系统在深层逻辑查询中的性能，OPI 通过 Logical-Relation Correctness Ratio 和 BERT 嵌入相似性得分的调和均值计算。研究者使用 OPI 测试了 LangChain 系统，在 RAG-Dataset-12000 上应用从 GPT-4o 微调的逻辑关系分类器，结果显示 BERT 嵌入相似性分数与外部评估分数高度相关。实验发现，基于 BERT 嵌入的余弦相似性检索器性能最佳，而欧氏距离检索器表现最差；此外，结合多个检索器（如算法融合或合并检索句子）可显著提升整体效果。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02932v1",
      "published_date": "2024-10-03 19:25:05 UTC",
      "updated_date": "2024-10-03 19:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:31:17.373764"
    },
    {
      "arxiv_id": "2410.02917v1",
      "title": "Deep image-based Adaptive BRDF Measure",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Cao"
      ],
      "abstract": "Efficient and accurate measurement of the bi-directional reflectance\ndistribution function (BRDF) plays a key role in high quality image rendering\nand physically accurate sensor simulation. However, obtaining the reflectance\nproperties of a material is both time-consuming and challenging. This paper\npresents a novel method for minimizing the number of samples required for high\nquality BRDF capture using a gonio-reflectometer setup. Taking an image of the\nphysical material sample as input a lightweight neural network first estimates\nthe parameters of an analytic BRDF model, and the distribution of the sample\nlocations. In a second step we use an image based loss to find the number of\nsamples required to meet the accuracy required. This approach significantly\naccelerates the measurement process while maintaining a high level of accuracy\nand fidelity in the BRDF representation.",
      "tldr_zh": "本研究提出了一种基于图像的适应性 BRDF（Bi-directional Reflectance Distribution Function）测量方法，以高效准确地捕获材料反射特性。方法首先使用一个轻量级神经网络，从物理材料样本的图像输入中估计分析 BRDF 模型的参数和样本位置分布；随后，通过图像-based loss 函数动态确定所需样本数量，以最小化测量过程。实验结果显示，该方法显著加速了 BRDF 测量，同时保持了高准确性和保真度，适用于高质量图像渲染和物理传感器模拟。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "9",
      "pdf_url": "http://arxiv.org/pdf/2410.02917v1",
      "published_date": "2024-10-03 19:08:48 UTC",
      "updated_date": "2024-10-03 19:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:31:35.182697"
    },
    {
      "arxiv_id": "2410.02916v3",
      "title": "LLM Safeguard is a Double-Edged Sword: Exploiting False Positives for Denial-of-Service Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Qingzhao Zhang",
        "Ziyang Xiong",
        "Z. Morley Mao"
      ],
      "abstract": "Safety is a paramount concern for large language models (LLMs) in open\ndeployment, motivating the development of safeguard methods that enforce\nethical and responsible use through safety alignment or guardrail mechanisms.\nJailbreak attacks that exploit the \\emph{false negatives} of safeguard methods\nhave emerged as a prominent research focus in the field of LLM security.\nHowever, we found that the malicious attackers could also exploit false\npositives of safeguards, i.e., fooling the safeguard model to block safe\ncontent mistakenly, leading to a denial-of-service (DoS) affecting LLM users.\nTo bridge the knowledge gap of this overlooked threat, we explore multiple\nattack methods that include inserting a short adversarial prompt into user\nprompt templates and corrupting the LLM on the server by poisoned fine-tuning.\nIn both ways, the attack triggers safeguard rejections of user requests from\nthe client. Our evaluation demonstrates the severity of this threat across\nmultiple scenarios. For instance, in the scenario of white-box adversarial\nprompt injection, the attacker can use our optimization process to\nautomatically generate seemingly safe adversarial prompts, approximately only\n30 characters long, that universally block over 97% of user requests on Llama\nGuard 3. These findings reveal a new dimension in LLM safeguard evaluation --\nadversarial robustness to false positives.",
      "tldr_zh": "该研究揭示了大型语言模型(LLM)防护机制的潜在风险：攻击者可利用false positives（即防护机制错误阻挡安全内容）发动拒绝服务(DoS)攻击，从而影响用户访问。论文探索了多种攻击方法，包括插入短对抗提示到用户提示模板中，以及通过poisoned fine-tuning破坏服务器端LLM，以触发防护机制的错误拒绝。实验结果显示，在白盒对抗提示注入场景中，生成的约30字符对抗提示能使Llama Guard 3阻挡97%以上的用户请求，这突显了LLM防护评估中对false positives的对抗鲁棒性新维度。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02916v3",
      "published_date": "2024-10-03 19:07:53 UTC",
      "updated_date": "2025-04-09 15:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:31:47.823971"
    },
    {
      "arxiv_id": "2410.02914v1",
      "title": "Streamlining Conformal Information Retrieval via Score Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Yotam Intrator",
        "Ori Kelner",
        "Regev Cohen",
        "Roman Goldenberg",
        "Ehud Rivlin",
        "Daniel Freedman"
      ],
      "abstract": "Information retrieval (IR) methods, like retrieval augmented generation, are\nfundamental to modern applications but often lack statistical guarantees.\nConformal prediction addresses this by retrieving sets guaranteed to include\nrelevant information, yet existing approaches produce large-sized sets,\nincurring high computational costs and slow response times. In this work, we\nintroduce a score refinement method that applies a simple monotone\ntransformation to retrieval scores, leading to significantly smaller conformal\nsets while maintaining their statistical guarantees. Experiments on various\nBEIR benchmarks validate the effectiveness of our approach in producing compact\nsets containing relevant information.",
      "tldr_zh": "该论文针对信息检索（IR）方法（如检索增强生成）缺乏统计保证的问题，引入了 Conformal Prediction 来确保检索集合包含相关信息，但现有方法导致集合过大、计算成本高。研究提出了一种 score refinement 方法，通过简单的单调变换对检索分数进行精炼，从而显著缩小集合大小，同时保持统计保证。在各种 BEIR benchmarks 的实验中，该方法证明了其有效性，能够生成更紧凑的集合并包含相关信息。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02914v1",
      "published_date": "2024-10-03 19:05:47 UTC",
      "updated_date": "2024-10-03 19:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:32:08.927304"
    },
    {
      "arxiv_id": "2410.02912v1",
      "title": "Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Xianzhi Li",
        "Ran Zmigrod",
        "Zhiqiang Ma",
        "Xiaomo Liu",
        "Xiaodan Zhu"
      ],
      "abstract": "Language models are capable of memorizing detailed patterns and information,\nleading to a double-edged effect: they achieve impressive modeling performance\non downstream tasks with the stored knowledge but also raise significant\nprivacy concerns. Traditional differential privacy based training approaches\noffer robust safeguards by employing a uniform noise distribution across all\nparameters. However, this overlooks the distinct sensitivities and\ncontributions of individual parameters in privacy protection and often results\nin suboptimal models. To address these limitations, we propose ANADP, a novel\nalgorithm that adaptively allocates additive noise based on the importance of\nmodel parameters. We demonstrate that ANADP narrows the performance gap between\nregular fine-tuning and traditional DP fine-tuning on a series of datasets\nwhile maintaining the required privacy constraints.",
      "tldr_zh": "本研究针对语言模型在微调过程中存在的隐私风险问题，提出了一种基于自适应噪声分配的算法ANADP，以优化差分隐私(Differential Privacy)训练。ANADP通过根据模型参数的重要性动态分配添加噪声，解决了传统DP方法在噪声分布上忽略参数敏感性和贡献的局限性。该方法在保持所需隐私约束的同时，在多个数据集上显著缩小了常规微调与传统DP微调之间的性能差距，展示了其在隐私保护与模型效能平衡方面的优势。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2410.02912v1",
      "published_date": "2024-10-03 19:02:50 UTC",
      "updated_date": "2024-10-03 19:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:32:20.977940"
    },
    {
      "arxiv_id": "2410.02902v4",
      "title": "Better Instruction-Following Through Minimum Bayes Risk",
      "title_zh": "通过最小贝叶斯风险实现更好的指令遵循",
      "authors": [
        "Ian Wu",
        "Patrick Fernandes",
        "Amanda Bertsch",
        "Seungone Kim",
        "Sina Pakazad",
        "Graham Neubig"
      ],
      "abstract": "General-purpose LLM judges capable of human-level evaluation provide not only\na scalable and accurate way of evaluating instruction-following LLMs but also\nnew avenues for supervising and improving their performance. One promising way\nof leveraging LLM judges for supervision is through Minimum Bayes Risk (MBR)\ndecoding, which uses a reference-based evaluator to select a high-quality\noutput from amongst a set of candidate outputs. In the first part of this work,\nwe explore using MBR decoding as a method for improving the test-time\nperformance of instruction-following LLMs. We find that MBR decoding with\nreference-based LLM judges substantially improves over greedy decoding,\nbest-of-N decoding with reference-free judges and MBR decoding with lexical and\nembedding-based metrics on AlpacaEval and MT-Bench. These gains are consistent\nacross LLMs with up to 70B parameters, demonstrating that smaller LLM judges\ncan be used to supervise much larger LLMs. Then, seeking to retain the\nimprovements from MBR decoding while mitigating additional test-time costs, we\nexplore iterative self-training on MBR-decoded outputs. We find that\nself-training using Direct Preference Optimisation leads to significant\nperformance gains, such that the self-trained models with greedy decoding\ngenerally match and sometimes exceed the performance of their base models with\nMBR decoding.",
      "tldr_zh": "这篇论文探索了通过 Minimum Bayes Risk (MBR) 解码来提升指令跟随大型语言模型(LLM)的性能，使用参考-based LLM 判断器从候选输出中选择高质量结果。实验结果显示，MBR 解码在 AlpacaEval 和 MT-Bench 基准上显著优于贪婪解码、best-of-N 解码以及基于词汇或嵌入的指标，且这种提升适用于从小型到70B参数的各种LLM，甚至允许较小模型监督更大模型。为了减少测试开销，论文进一步提出迭代自训练方法，使用 Direct Preference Optimisation 在 MBR 解码输出上训练模型，结果表明自训练后的模型在贪婪解码下可匹配或超过原始 MBR 解码性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025 (Spotlight); Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2410.02902v4",
      "published_date": "2024-10-03 18:48:38 UTC",
      "updated_date": "2025-02-25 19:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:32:34.439722"
    },
    {
      "arxiv_id": "2410.03786v1",
      "title": "AI-rays: Exploring Bias in the Gaze of AI Through a Multimodal Interactive Installation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyao Gao",
        "Yiwen Zhang",
        "Ling Li",
        "Theodoros Papatheodorou",
        "Wei Zeng"
      ],
      "abstract": "Data surveillance has become more covert and pervasive with AI algorithms,\nwhich can result in biased social classifications. Appearance offers intuitive\nidentity signals, but what does it mean to let AI observe and speculate on\nthem? We introduce AI-rays, an interactive installation where AI generates\nspeculative identities from participants' appearance which are expressed\nthrough synthesized personal items placed in participants' bags. It uses\nspeculative X-ray visions to contrast reality with AI-generated assumptions,\nmetaphorically highlighting AI's scrutiny and biases. AI-rays promotes\ndiscussions on modern surveillance and the future of human-machine reality\nthrough a playful, immersive experience exploring AI biases.",
      "tldr_zh": "本研究引入了AI-rays，一种多模态互动安装，用于探索AI在审视人类外貌时存在的偏见问题。AI-rays通过AI算法从参与者的外貌生成推测的身份，并以合成的个人物品置入参与者的包中，运用模拟X光视觉对比现实与AI假设，隐喻地揭示AI的监视机制和潜在偏见。该安装通过趣味性和沉浸式体验，促进对现代数据监视、人机现实以及AI biases的公众讨论。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Siggraph Asia 2024 Art Paper",
      "pdf_url": "http://arxiv.org/pdf/2410.03786v1",
      "published_date": "2024-10-03 18:44:05 UTC",
      "updated_date": "2024-10-03 18:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:32:44.527829"
    },
    {
      "arxiv_id": "2410.02897v1",
      "title": "Cognitive Biases in Large Language Models for News Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yougang Lyu",
        "Xiaoyu Zhang",
        "Zhaochun Ren",
        "Maarten de Rijke"
      ],
      "abstract": "Despite large language models (LLMs) increasingly becoming important\ncomponents of news recommender systems, employing LLMs in such systems\nintroduces new risks, such as the influence of cognitive biases in LLMs.\nCognitive biases refer to systematic patterns of deviation from norms or\nrationality in the judgment process, which can result in inaccurate outputs\nfrom LLMs, thus threatening the reliability of news recommender systems.\nSpecifically, LLM-based news recommender systems affected by cognitive biases\ncould lead to the propagation of misinformation, reinforcement of stereotypes,\nand the formation of echo chambers. In this paper, we explore the potential\nimpact of multiple cognitive biases on LLM-based news recommender systems,\nincluding anchoring bias, framing bias, status quo bias and group attribution\nbias. Furthermore, to facilitate future research at improving the reliability\nof LLM-based news recommender systems, we discuss strategies to mitigate these\nbiases through data augmentation, prompt engineering and learning algorithms\naspects.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在新闻推荐系统中的认知偏差问题，这些偏差可能导致系统输出不准确，并带来风险，如传播错误信息 (misinformation)、强化刻板印象和形成回音室 (echo chambers)。论文具体分析了多种认知偏差，包括锚定偏差 (anchoring bias)、框架偏差 (framing bias)、现状偏差 (status quo bias) 和群体归因偏差 (group attribution bias)。为了提升系统的可靠性，研究者提出了缓解策略，如通过数据增强 (data augmentation)、提示工程 (prompt engineering) 和学习算法 (learning algorithms) 等方法进行优化。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at the ROGEN '24 workshop, co-located with ACM RecSys '24",
      "pdf_url": "http://arxiv.org/pdf/2410.02897v1",
      "published_date": "2024-10-03 18:42:07 UTC",
      "updated_date": "2024-10-03 18:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:32:57.565903"
    },
    {
      "arxiv_id": "2410.02892v2",
      "title": "The Role of Deductive and Inductive Reasoning in Large Language Models",
      "title_zh": "大语言模型中演绎与归纳推理的作用",
      "authors": [
        "Chengkun Cai",
        "Xu Zhao",
        "Haoliang Liu",
        "Zhongyu Jiang",
        "Tianfang Zhang",
        "Zongkai Wu",
        "Jenq-Neng Hwang",
        "Serge Belongie",
        "Lei Li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nreasoning tasks, yet their reliance on static prompt structures and limited\nadaptability to complex scenarios remains a significant challenge. In this\npaper, we propose the Deductive and InDuctive(DID) method, a novel framework\nthat enhances LLM reasoning by dynamically integrating both deductive and\ninductive reasoning approaches. Drawing from cognitive science principles, DID\nimplements a dual-metric complexity evaluation system that combines Littlestone\ndimension and information entropy to precisely assess task difficulty and guide\ndecomposition strategies. DID enables the model to progressively adapt its\nreasoning pathways based on problem complexity, mirroring human cognitive\nprocesses. We evaluate DID's effectiveness across multiple benchmarks,\nincluding the AIW and MR-GSM8K, as well as our custom Holiday Puzzle dataset\nfor temporal reasoning. Our results demonstrate significant improvements in\nreasoning quality and solution accuracy - achieving 70.3% accuracy on AIW\n(compared to 62.2% for Tree of Thought) while maintaining lower computational\ncosts. The success of DID in improving LLM performance while preserving\ncomputational efficiency suggests promising directions for developing more\ncognitively aligned and capable language models. Our work contributes a\ntheoretically grounded, input-centric approach to enhancing LLM reasoning\ncapabilities, offering an efficient alternative to traditional\noutput-exploration methods.",
      "tldr_zh": "这篇论文探讨了演绎推理(deductive reasoning)和归纳推理(inductive reasoning)在 Large Language Models (LLMs) 中的作用，提出了一种名为 DID 的新框架，通过动态整合这两种推理方式来提升模型的适应性和处理复杂场景的能力。DID 基于认知科学原理，采用双指标复杂性评估系统（结合 Littlestone 维度和信息熵）来评估任务难度并指导推理路径分解，从而模仿人类认知过程。在多个基准测试中，如 AIW、MR-GSM8K 和自定义的 Holiday Puzzle 数据集，DID 实现了显著改进，包括 AIW 准确率达 70.3%（较 Tree of Thought 的 62.2% 提升），同时保持较低的计算成本。该框架为开发更高效、认知导向的 LLM 提供了理论基础和实用替代方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02892v2",
      "published_date": "2024-10-03 18:30:47 UTC",
      "updated_date": "2025-02-17 10:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:33:13.529139"
    },
    {
      "arxiv_id": "2410.02884v2",
      "title": "LLaMA-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Di Zhang",
        "Jianbo Wu",
        "Jingdi Lei",
        "Tong Che",
        "Jiatong Li",
        "Tong Xie",
        "Xiaoshui Huang",
        "Shufei Zhang",
        "Marco Pavone",
        "Yuqiang Li",
        "Wanli Ouyang",
        "Dongzhan Zhou"
      ],
      "abstract": "This paper presents an advanced mathematical problem-solving framework,\nLLaMA-Berry, for enhancing the mathematical reasoning ability of Large Language\nModels (LLMs). The framework combines Monte Carlo Tree Search (MCTS) with\niterative Self-Refine to optimize the reasoning path and utilizes a pairwise\nreward model to evaluate different paths globally. By leveraging the\nself-critic and rewriting capabilities of LLMs, Self-Refine applied to MCTS\n(SR-MCTS) overcomes the inefficiencies and limitations of conventional\nstep-wise and greedy search algorithms by fostering a more efficient\nexploration of solution spaces. Pairwise Preference Reward Model~(PPRM),\ninspired by Reinforcement Learning from Human Feedback (RLHF), is then used to\nmodel pairwise preferences between solutions, utilizing an Enhanced Borda Count\n(EBC) method to synthesize these preferences into a global ranking score to\nfind better answers. This approach addresses the challenges of scoring\nvariability and non-independent distributions in mathematical reasoning tasks.\nThe framework has been tested on general and advanced benchmarks, showing\nsuperior performance in terms of search efficiency and problem-solving\ncapability compared to existing methods like ToT and rStar, particularly in\ncomplex Olympiad-level benchmarks, including GPQA, AIME24 and AMC23.",
      "tldr_zh": "本研究提出LLaMA-Berry框架，通过结合Monte Carlo Tree Search (MCTS)和迭代Self-Refine优化大型语言模型(LLMs)的数学推理能力，具体采用SR-MCTS方法来高效探索解决方案空间，并使用Pairwise Preference Reward Model (PPRM)结合Enhanced Borda Count (EBC)来评估和全局排名不同路径，从而解决传统搜索算法的局限性。PPRM借鉴Reinforcement Learning from Human Feedback (RLHF)的理念，处理数学任务中的评分变异性和非独立分布问题。实验结果显示，该框架在GPQA、AIME24和AMC23等奥林匹克级基准测试中，表现出色，搜索效率和问题解决能力均优于现有方法如ToT和rStar。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02884v2",
      "published_date": "2024-10-03 18:12:29 UTC",
      "updated_date": "2024-11-21 07:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:33:21.795711"
    },
    {
      "arxiv_id": "2410.02874v2",
      "title": "Real-World Cooking Robot System from Recipes Based on Food State Recognition Using Foundation Models and PDDL",
      "title_zh": "翻译失败",
      "authors": [
        "Naoaki Kanazawa",
        "Kento Kawaharazuka",
        "Yoshiki Obinata",
        "Kei Okada",
        "Masayuki Inaba"
      ],
      "abstract": "Although there is a growing demand for cooking behaviours as one of the\nexpected tasks for robots, a series of cooking behaviours based on new recipe\ndescriptions by robots in the real world has not yet been realised. In this\nstudy, we propose a robot system that integrates real-world executable robot\ncooking behaviour planning using the Large Language Model (LLM) and classical\nplanning of PDDL descriptions, and food ingredient state recognition learning\nfrom a small number of data using the Vision-Language model (VLM). We succeeded\nin experiments in which PR2, a dual-armed wheeled robot, performed cooking from\narranged new recipes in a real-world environment, and confirmed the\neffectiveness of the proposed system.",
      "tldr_zh": "本文提出了一种基于新食谱的真实世界烹饪机器人系统，利用Large Language Model (LLM)进行可执行行为规划、PDDL描述的经典规划，以及Vision-Language Model (VLM)从少量数据学习食物成分状态识别。系统整合这些组件，使机器人能够处理烹饪任务中的动态变化。实验结果显示，PR2双臂轮式机器人成功在真实环境中根据新食谱完成烹饪，证实了该系统的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at Advanced Robotics, website -\n  https://kanazawanaoaki.github.io/cook-from-recipe-pddl/",
      "pdf_url": "http://arxiv.org/pdf/2410.02874v2",
      "published_date": "2024-10-03 18:02:56 UTC",
      "updated_date": "2024-10-07 01:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:33:34.309541"
    },
    {
      "arxiv_id": "2410.02763v1",
      "title": "Vinoground: Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Jianrui Zhang",
        "Mu Cai",
        "Yong Jae Lee"
      ],
      "abstract": "There has been growing sentiment recently that modern large multimodal models\n(LMMs) have addressed most of the key challenges related to short video\ncomprehension. As a result, both academia and industry are gradually shifting\ntheir attention towards the more complex challenges posed by understanding\nlong-form videos. However, is this really the case? Our studies indicate that\nLMMs still lack many fundamental reasoning capabilities even when dealing with\nshort videos. We introduce Vinoground, a temporal counterfactual LMM evaluation\nbenchmark encompassing 1000 short and natural video-caption pairs. We\ndemonstrate that existing LMMs severely struggle to distinguish temporal\ndifferences between different actions and object transformations. For example,\nthe best model GPT-4o only obtains ~50% on our text and video scores, showing a\nlarge gap compared to the human baseline of ~90%. All open-source multimodal\nmodels and CLIP-based models perform much worse, producing mostly random chance\nperformance. Through this work, we shed light onto the fact that temporal\nreasoning in short videos is a problem yet to be fully solved. The dataset and\nevaluation code are available at https://vinoground.github.io.",
      "tldr_zh": "该研究质疑了现代大型多模态模型(LMMs)是否已解决短视频理解的关键挑战，并发现这些模型在处理短视频时仍缺乏基本的密集时间推理能力。研究者引入了Vinoground基准测试，这是一个包含1000个短视频-标题对的temporal counterfactual评估框架，用于检验LMMs区分不同动作和物体变化的时间差异。实验结果显示，顶级模型如GPT-4o在文本和视频评分上仅达到约50%的准确率，而人类基线为约90%；开源模型和CLIP-based models的表现更差，几乎处于随机水平。这些发现突显了短视频时间推理问题尚未得到充分解决，并提供了相关数据集和代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://vinoground.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.02763v1",
      "published_date": "2024-10-03 17:59:58 UTC",
      "updated_date": "2024-10-03 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:33:45.809874"
    },
    {
      "arxiv_id": "2410.02761v4",
      "title": "FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipei Xu",
        "Xuanyu Zhang",
        "Runyi Li",
        "Zecheng Tang",
        "Qing Huang",
        "Jian Zhang"
      ],
      "abstract": "The rapid development of generative AI is a double-edged sword, which not\nonly facilitates content creation but also makes image manipulation easier and\nmore difficult to detect. Although current image forgery detection and\nlocalization (IFDL) methods are generally effective, they tend to face two\nchallenges: \\textbf{1)} black-box nature with unknown detection principle,\n\\textbf{2)} limited generalization across diverse tampering methods (e.g.,\nPhotoshop, DeepFake, AIGC-Editing). To address these issues, we propose the\nexplainable IFDL task and design FakeShield, a multi-modal framework capable of\nevaluating image authenticity, generating tampered region masks, and providing\na judgment basis based on pixel-level and image-level tampering clues.\nAdditionally, we leverage GPT-4o to enhance existing IFDL datasets, creating\nthe Multi-Modal Tamper Description dataSet (MMTD-Set) for training FakeShield's\ntampering analysis capabilities. Meanwhile, we incorporate a Domain Tag-guided\nExplainable Forgery Detection Module (DTE-FDM) and a Multi-modal Forgery\nLocalization Module (MFLM) to address various types of tamper detection\ninterpretation and achieve forgery localization guided by detailed textual\ndescriptions. Extensive experiments demonstrate that FakeShield effectively\ndetects and localizes various tampering techniques, offering an explainable and\nsuperior solution compared to previous IFDL methods. The code is available at\nhttps://github.com/zhipeixu/FakeShield.",
      "tldr_zh": "该论文针对图像伪造检测和定位（IFDL）面临的黑箱问题和泛化能力不足，提出了可解释的IFDL任务和FakeShield框架。该框架利用多模态大语言模型（Multi-modal Large Language Models），能够评估图像真实性、生成篡改区域掩码，并基于像素级和图像级线索提供判断依据。同时，FakeShield整合了Domain Tag-guided Explainable Forgery Detection Module (DTE-FDM)和Multi-modal Forgery Localization Module (MFLM)，并使用GPT-4o增强数据集创建MMTD-Set来训练篡改分析能力。实验结果显示，FakeShield在检测和定位各种篡改技术（如Photoshop、DeepFake）方面表现出色，比现有方法更具可解释性和优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02761v4",
      "published_date": "2024-10-03 17:59:34 UTC",
      "updated_date": "2025-04-12 08:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:33:58.151760"
    },
    {
      "arxiv_id": "2410.05295v4",
      "title": "AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaogeng Liu",
        "Peiran Li",
        "Edward Suh",
        "Yevgeniy Vorobeychik",
        "Zhuoqing Mao",
        "Somesh Jha",
        "Patrick McDaniel",
        "Huan Sun",
        "Bo Li",
        "Chaowei Xiao"
      ],
      "abstract": "In this paper, we propose AutoDAN-Turbo, a black-box jailbreak method that\ncan automatically discover as many jailbreak strategies as possible from\nscratch, without any human intervention or predefined scopes (e.g., specified\ncandidate strategies), and use them for red-teaming. As a result, AutoDAN-Turbo\ncan significantly outperform baseline methods, achieving a 74.3% higher average\nattack success rate on public benchmarks. Notably, AutoDAN-Turbo achieves an\n88.5 attack success rate on GPT-4-1106-turbo. In addition, AutoDAN-Turbo is a\nunified framework that can incorporate existing human-designed jailbreak\nstrategies in a plug-and-play manner. By integrating human-designed strategies,\nAutoDAN-Turbo can even achieve a higher attack success rate of 93.4 on\nGPT-4-1106-turbo.",
      "tldr_zh": "本研究提出 AutoDAN-Turbo，一种黑盒越狱方法，通过终身代理（lifelong agent）实现策略自探索，自动从零开始发现尽可能多的 jailbreak 策略，而无需人为干预或预定义范围，用于 red-teaming 测试。AutoDAN-Turbo 显著优于基线方法，在公共基准上平均攻击成功率提高 74.3%，并在 GPT-4-1106-turbo 上达到 88.5% 的成功率。作为一个统一框架，它能无缝整合现有的人工设计策略，进一步提升性能至 GPT-4-1106-turbo 上的 93.4% 攻击成功率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "ICLR 2025 Spotlight. Project Page:\n  https://autodans.github.io/AutoDAN-Turbo Code:\n  https://github.com/SaFoLab-WISC/AutoDAN-Turbo",
      "pdf_url": "http://arxiv.org/pdf/2410.05295v4",
      "published_date": "2024-10-03 17:59:01 UTC",
      "updated_date": "2025-04-22 05:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:34:09.138101"
    },
    {
      "arxiv_id": "2410.02748v3",
      "title": "CriSPO: Multi-Aspect Critique-Suggestion-guided Automatic Prompt Optimization for Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Han He",
        "Qianchu Liu",
        "Lei Xu",
        "Chaitanya Shivade",
        "Yi Zhang",
        "Sundararajan Srinivasan",
        "Katrin Kirchhoff"
      ],
      "abstract": "Existing automatic prompt engineering methods are typically designed for\ndiscriminative tasks, where new task prompts are iteratively refined with\nlimited feedback from a single metric reflecting a single aspect. However,\nthese approaches are suboptimal for generative tasks, which require more\nnuanced guidance beyond a single numeric metric to improve the prompt and\noptimize multiple aspects of the generated text. To address these challenges,\nwe propose a novel multi-aspect Critique-Suggestion-guided automatic Prompt\nOptimization (CriSPO) approach. CriSPO introduces a critique-suggestion module\nas its core component. This module spontaneously discovers aspects, and\ncompares generated and reference texts across these aspects, providing specific\nsuggestions for prompt modification. These clear critiques and actionable\nsuggestions guide a receptive optimizer module to make more substantial\nchanges, exploring a broader and more effective search space. To further\nimprove CriSPO with multi-metric optimization, we introduce an Automatic Suffix\nTuning (AST) extension to enhance the performance of task prompts across\nmultiple metrics. We evaluate CriSPO on 4 state-of-the-art LLMs across 4\nsummarization and 5 QA datasets. Extensive experiments show 3-4% ROUGE score\nimprovement on summarization and substantial improvement of various metrics on\nQA. Code available at https://github.com/amazon-science/crispo",
      "tldr_zh": "本文提出 CriSPO，一种多方面批评-建议引导的自动提示优化方法，针对文本生成任务的不足，解决现有方法依赖单一指标反馈的问题。CriSPO 的核心组件包括批评-建议模块，用于自动发现方面、比较生成文本与参考文本并提供具体修改建议，从而指导优化器模块探索更广泛的搜索空间；此外，还引入 Automatic Suffix Tuning (AST) 扩展以实现多指标优化。在 4 个大型语言模型和 4 个摘要及 5 个 QA 数据集上实验，CriSPO 实现了摘要任务 ROUGE 分数 3-4% 的提升，以及 QA 任务中各种指标的显著改善。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02748v3",
      "published_date": "2024-10-03 17:57:01 UTC",
      "updated_date": "2025-01-14 17:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:34:22.899227"
    },
    {
      "arxiv_id": "2410.02744v1",
      "title": "Neutral residues: revisiting adapters for model extension",
      "title_zh": "翻译失败",
      "authors": [
        "Franck Signe Talla",
        "Herve Jegou",
        "Edouard Grave"
      ],
      "abstract": "We address the problem of extending a pretrained large language model to a\nnew domain that was not seen at training time, like adding a language for which\nthe original model has seen no or little training data. Popular solutions like\nfine-tuning or low-rank adaptation are successful at domain adaptation, but\nformally they do not add any extra capacity and degrade the performance in the\noriginal domain.\n  Our paper analyzes this extension problem under three angles: data,\narchitecture and training procedure, which are advantageously considered\njointly. In particular, we improve adapters and make it possible to learn an\nentire new language while ensuring that the output of the neural network is\nalmost unchanged in the original domain. For this purpose, we modify the new\nresidual blocks in a way that leads each new residual block to output\nnear-zeros in the original domain.\n  This solution of neutral residues, which borrows architectural components\nfrom mixture of experts, is effective: with only 20% extra learnable weights\ncompared to an original model trained on English, we get results that are\nsignificantly better than concurrent approaches (fine-tuning, low-rank or\nvanilla adapters) in terms of the trade-off between learning a new language and\nnot forgetting English.",
      "tldr_zh": "该论文探讨了扩展预训练大型语言模型（LLM）到新领域（如未见训练数据的语言）的问题，指出现有方法如 fine-tuning 或 low-rank adaptation 虽然能适应新领域，但会降低原领域性能。作者改进了 adapters，通过引入 neutral residues 机制来修改新残差块（residual blocks），确保在原领域输出近似零，从而在不增加过多容量的情况下学习新语言。实验结果显示，该方法仅增加 20% 的可学习权重，就在学习新语言（如非英语语言）和保留原语言（如英语）性能的权衡上，显著优于 fine-tuning、low-rank adaptation 和 vanilla adapters。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02744v1",
      "published_date": "2024-10-03 17:55:17 UTC",
      "updated_date": "2024-10-03 17:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:34:34.167685"
    },
    {
      "arxiv_id": "2410.02741v2",
      "title": "Salient Information Prompting to Steer Content in Prompt-based Abstractive Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Xu",
        "Mohammed Asad Karim",
        "Saket Dingliwal",
        "Aparna Elangovan"
      ],
      "abstract": "Large language models (LLMs) can generate fluent summaries across domains\nusing prompting techniques, reducing the need to train models for summarization\napplications. However, crafting effective prompts that guide LLMs to generate\nsummaries with the appropriate level of detail and writing style remains a\nchallenge. In this paper, we explore the use of salient information extracted\nfrom the source document to enhance summarization prompts. We show that adding\nkeyphrases in prompts can improve ROUGE F1 and recall, making the generated\nsummaries more similar to the reference and more complete. The number of\nkeyphrases can control the precision-recall trade-off. Furthermore, our\nanalysis reveals that incorporating phrase-level salient information is\nsuperior to word- or sentence-level. However, the impact on hallucination is\nnot universally positive across LLMs. To conduct this analysis, we introduce\nKeyphrase Signal Extractor (SigExt), a lightweight model that can be finetuned\nto extract salient keyphrases. By using SigExt, we achieve consistent ROUGE\nimprovements across datasets and open-weight and proprietary LLMs without any\nLLM customization. Our findings provide insights into leveraging salient\ninformation in building prompt-based summarization systems. We release our code\nat \\url{https://github.com/amazon-science/SigExt}",
      "tldr_zh": "本文提出了一种利用源文档中提取的显著信息来优化提示的方法，旨在提升基于大型语言模型(LLMs)的抽象摘要生成质量。通过在提示中添加关键短语(keyphrases)，研究者显著提高了 ROUGE F1 和 recall 指标，使生成的摘要更接近参考摘要且更完整，且关键短语数量可控制精确率和召回率的权衡。分析显示，短语级别的信息比单词或句子级别更有效，但对幻觉(hallucination)的减少影响因 LLMs 而异。为实现这一方法，作者引入了 Keyphrase Signal Extractor (SigExt)，一个可微调的轻量级模型，在多种数据集和开放或专有 LLMs 上实现了性能一致提升，而无需修改 LLMs 本身。研究成果为构建基于提示的摘要系统提供了新见解，并公开了代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Industry Track. Code available at\n  https://github.com/amazon-science/SigExt",
      "pdf_url": "http://arxiv.org/pdf/2410.02741v2",
      "published_date": "2024-10-03 17:54:56 UTC",
      "updated_date": "2024-12-02 21:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:34:46.176878"
    },
    {
      "arxiv_id": "2410.02740v1",
      "title": "Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengfeng Lai",
        "Vasileios Saveris",
        "Chen Chen",
        "Hong-You Chen",
        "Haotian Zhang",
        "Bowen Zhang",
        "Juan Lao Tebar",
        "Wenze Hu",
        "Zhe Gan",
        "Peter Grasch",
        "Meng Cao",
        "Yinfei Yang"
      ],
      "abstract": "Recent advancements in multimodal models highlight the value of rewritten\ncaptions for improving performance, yet key challenges remain. For example,\nwhile synthetic captions often provide superior quality and image-text\nalignment, it is not clear whether they can fully replace AltTexts: the role of\nsynthetic captions and their interaction with original web-crawled AltTexts in\npre-training is still not well understood. Moreover, different multimodal\nfoundation models may have unique preferences for specific caption formats, but\nefforts to identify the optimal captions for each model remain limited. In this\nwork, we propose a novel, controllable, and scalable captioning pipeline\ndesigned to generate diverse caption formats tailored to various multimodal\nmodels. By examining Short Synthetic Captions (SSC) towards Dense Synthetic\nCaptions (DSC+) as case studies, we systematically explore their effects and\ninteractions with AltTexts across models such as CLIP, multimodal LLMs, and\ndiffusion models. Our findings reveal that a hybrid approach that keeps both\nsynthetic captions and AltTexts can outperform the use of synthetic captions\nalone, improving both alignment and performance, with each model demonstrating\npreferences for particular caption formats. This comprehensive analysis\nprovides valuable insights into optimizing captioning strategies, thereby\nadvancing the pre-training of multimodal foundation models.",
      "tldr_zh": "本文重新审视大规模图像-标题数据在预训练多模态基础模型中的作用，提出一个新型、可控且可扩展的标题生成管道，用于生成针对不同模型的多样标题格式，如 Short Synthetic Captions (SSC) 到 Dense Synthetic Captions (DSC+)。通过系统探索这些合成标题与原始 AltTexts 的交互效果，研究发现混合使用两者能比仅用合成标题更好地提升图像-文本对齐和整体性能，而模型如 CLIP、多模态 LLMs 和 diffusion models 各有特定标题格式偏好。该分析为优化标题策略提供了宝贵见解，推动多模态基础模型的预训练发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CV/ML",
      "pdf_url": "http://arxiv.org/pdf/2410.02740v1",
      "published_date": "2024-10-03 17:54:52 UTC",
      "updated_date": "2024-10-03 17:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:34:57.906185"
    },
    {
      "arxiv_id": "2410.02736v2",
      "title": "Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge",
      "title_zh": "正义还是偏见？量化 LLM-as-a-Judge 中的偏差",
      "authors": [
        "Jiayi Ye",
        "Yanbo Wang",
        "Yue Huang",
        "Dongping Chen",
        "Qihui Zhang",
        "Nuno Moniz",
        "Tian Gao",
        "Werner Geyer",
        "Chao Huang",
        "Pin-Yu Chen",
        "Nitesh V Chawla",
        "Xiangliang Zhang"
      ],
      "abstract": "LLM-as-a-Judge has been widely utilized as an evaluation method in various\nbenchmarks and served as supervised rewards in model training. However, despite\ntheir excellence in many domains, potential issues are under-explored,\nundermining their reliability and the scope of their utility. Therefore, we\nidentify 12 key potential biases and propose a new automated bias\nquantification framework-CALM-which systematically quantifies and analyzes each\ntype of bias in LLM-as-a-Judge by using automated and principle-guided\nmodification. Our experiments cover multiple popular language models, and the\nresults indicate that while advanced models have achieved commendable overall\nperformance, significant biases persist in certain specific tasks. Empirical\nresults suggest that there remains room for improvement in the reliability of\nLLM-as-a-Judge. Moreover, we also discuss the explicit and implicit influence\nof these biases and give some suggestions for the reliable application of\nLLM-as-a-Judge. Our work highlights the need for stakeholders to address these\nissues and remind users to exercise caution in LLM-as-a-Judge applications.",
      "tldr_zh": "本研究探讨了LLM-as-a-Judge在评估基准和模型训练中的潜在偏见问题，识别出12种关键偏见，并提出一个自动化框架CALM来系统量化这些偏见。CALM通过原则导向的修改方法，对多个流行语言模型进行实验分析，结果显示尽管先进模型整体表现良好，但特定任务中仍存在显著偏见。研究强调这些偏见可能影响LLM-as-a-Judge的可靠性和应用范围，并提供建议以促进其改进和谨慎使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02736v2",
      "published_date": "2024-10-03 17:53:30 UTC",
      "updated_date": "2024-10-04 03:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:35:12.473818"
    },
    {
      "arxiv_id": "2410.02732v1",
      "title": "Custom Non-Linear Model Predictive Control for Obstacle Avoidance in Indoor and Outdoor Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Lara Laban",
        "Mariusz Wzorek",
        "Piotr Rudol",
        "Tommy Persson"
      ],
      "abstract": "Navigating complex environments requires Unmanned Aerial Vehicles (UAVs) and\nautonomous systems to perform trajectory tracking and obstacle avoidance in\nreal-time. While many control strategies have effectively utilized linear\napproximations, addressing the non-linear dynamics of UAV, especially in\nobstacle-dense environments, remains a key challenge that requires further\nresearch. This paper introduces a Non-linear Model Predictive Control (NMPC)\nframework for the DJI Matrice 100, addressing these challenges by using a\ndynamic model and B-spline interpolation for smooth reference trajectories,\nensuring minimal deviation while respecting safety constraints. The framework\nsupports various trajectory types and employs a penalty-based cost function for\ncontrol accuracy in tight maneuvers. The framework utilizes CasADi for\nefficient real-time optimization, enabling the UAV to maintain robust operation\neven under tight computational constraints. Simulation and real-world indoor\nand outdoor experiments demonstrated the NMPC ability to adapt to disturbances,\nresulting in smooth, collision-free navigation.",
      "tldr_zh": "该论文提出了一种自定义的 Non-linear Model Predictive Control (NMPC) 框架，用于无人机 (UAVs) 在室内和室外复杂环境中的轨迹跟踪和障碍物避让，以应对非线性动态挑战。框架基于 DJI Matrice 100 的动态模型，并利用 B-spline 插值生成平滑参考轨迹，同时采用基于惩罚的成本函数确保控制精度和安全约束，并通过 CasADi 实现高效实时优化。实验结果显示，该框架在模拟和实际测试中能够适应干扰，实现平滑、无碰撞导航，并显著提升了 UAV 的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.AR",
        "cs.CE",
        "cs.SY",
        "eess.SY",
        "93C85 (Primary), 93B52, 68T40 (Secondary)",
        "I.2.9; I.2.8; I.6.3; I.6.5; I.6.8; C.3; C.4"
      ],
      "primary_category": "cs.RO",
      "comment": "This manuscript has 7 pages and 8 figures, detailing NMPC for UAV\n  obstacle avoidance using DJI UAVs. It features simulations, experimental\n  results, and uses CasADi for optimization with ROS integration. Code and\n  media at https://github.com/larasupernovae/nmpc_flash_multi_obstacle",
      "pdf_url": "http://arxiv.org/pdf/2410.02732v1",
      "published_date": "2024-10-03 17:50:19 UTC",
      "updated_date": "2024-10-03 17:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:35:21.494906"
    },
    {
      "arxiv_id": "2410.02729v2",
      "title": "Unified Multimodal Interleaved Document Representation for Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Jaewoo Lee",
        "Joonho Ko",
        "Jinheon Baek",
        "Soyeong Jeong",
        "Sung Ju Hwang"
      ],
      "abstract": "Information Retrieval (IR) methods aim to identify documents relevant to a\nquery, which have been widely applied in various natural language tasks.\nHowever, existing approaches typically consider only the textual content within\ndocuments, overlooking the fact that documents can contain multiple modalities,\nincluding images and tables. Also, they often segment each long document into\nmultiple discrete passages for embedding, which prevents them from capturing\nthe overall document context and interactions between paragraphs. To address\nthese two challenges, we propose a method that holistically embeds documents\ninterleaved with multiple modalities by leveraging the capability of recent\nvision-language models that enable the processing and integration of text,\nimages, and tables into a unified format and representation. Moreover, to\nmitigate the information loss from segmenting documents into passages, instead\nof representing and retrieving passages individually, we further merge the\nrepresentations of segmented passages into one single document representation,\nwhile we additionally introduce a reranking strategy to decouple and identify\nthe relevant passage within the document if necessary. Then, through extensive\nexperiments on diverse IR scenarios considering both the textual and multimodal\nqueries, we show that our approach substantially outperforms relevant\nbaselines, thanks to the consideration of the multimodal information within\ndocuments.",
      "tldr_zh": "该研究针对信息检索 (IR) 方法的局限性，提出了一种统一的 multimodal interleaved 文档表示方法，以解决现有方法忽略文档中的图像、表格等多模态元素，以及无法捕捉文档整体上下文和段落间交互的问题。该方法利用 vision-language models 将文本、图像和表格整合成一个统一的格式和表示，并通过合并段落表示生成单一文档表示，同时引入 reranking 策略来精确识别相关段落。实验结果显示，在包括文本和多模态查询的多样 IR 场景中，该方法显著优于基线模型，证明了考虑多模态信息的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.02729v2",
      "published_date": "2024-10-03 17:49:09 UTC",
      "updated_date": "2024-12-16 15:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:35:33.586984"
    },
    {
      "arxiv_id": "2410.02725v1",
      "title": "Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation",
      "title_zh": "适应性推理时计算：LLMs 能够预测它们是否能做得更好，甚至在生成过程中",
      "authors": [
        "Rohin Manvi",
        "Anikait Singh",
        "Stefano Ermon"
      ],
      "abstract": "Inference-time computation is a powerful paradigm to enhance the performance\nof large language models (LLMs), with Best-of-N sampling being a widely used\ntechnique. However, this method is computationally expensive, requiring both\n(1) an external reward model and (2) the generation of multiple samples. In\nthis work, we introduce a new generative self-evaluation scheme designed to\nadaptively reduce the number of generated samples while maintaining or even\nimproving performance. We use a generative reward model formulation, allowing\nthe LLM to predict mid-generation the probability that restarting the\ngeneration will yield a better response. These predictions are obtained without\nan external reward model and can be used to decide whether or not to generate\nmore samples, prune unpromising samples early on, or to pick the best sample.\nThis capability is very inexpensive as it involves generating a single\npredefined token. Trained using a dataset constructed with real unfiltered\nLMSYS user prompts, Llama 3.1 8B's win rate against GPT-4 on AlpacaEval\nincreases from 21% to 34% with 16 samples and math performance on GSM8K\nimproves from 84% to 91%. By sampling only when the LLM determines that it is\nbeneficial to do so and adaptively adjusting temperature annealing, we\ndemonstrate that 74% of the improvement from using 16 samples can be achieved\nwith only 1.2 samples on average. We further demonstrate that 50-75% of samples\ncan be pruned early in generation with minimal degradation in performance.\nOverall, our methods enable more efficient and scalable compute utilization\nduring inference for LLMs.",
      "tldr_zh": "本文提出了一种自适应推理时计算方法，允许大型语言模型(LLMs) 在生成过程中(mid-generation)预测重启是否能产生更好响应，从而减少样本数量，同时维持或提升性能。该方法采用生成式奖励模型(generative reward model)，无需外部奖励模型，仅通过生成一个预定义 token 即可进行高效预测。实验结果显示，Llama 3.1 8B 在 AlpacaEval 上对 GPT-4 的胜率从 21% 提高到 34%，在 GSM8K 数学任务上从 84% 提高到 91%。通过选择性采样和温度退火(temperature annealing)，平均只需 1.2 个样本即可实现使用 16 个样本的 74% 性能提升，并能早期修剪 50-75% 的不佳样本。总体上，此方法显著提高了 LLMs 推理时的计算效率和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02725v1",
      "published_date": "2024-10-03 17:47:29 UTC",
      "updated_date": "2024-10-03 17:47:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:35:47.528719"
    },
    {
      "arxiv_id": "2410.02724v2",
      "title": "Large Language Models as Markov Chains",
      "title_zh": "大型语言模型作为Markov链",
      "authors": [
        "Oussama Zekri",
        "Ambroise Odonnat",
        "Abdelhakim Benechehab",
        "Linus Bleistein",
        "Nicolas Boullé",
        "Ievgen Redko"
      ],
      "abstract": "Large language models (LLMs) are remarkably efficient across a wide range of\nnatural language processing tasks and well beyond them. However, a\ncomprehensive theoretical analysis of the LLMs' generalization capabilities\nremains elusive. In our paper, we approach this task by drawing an equivalence\nbetween autoregressive transformer-based language models and Markov chains\ndefined on a finite state space. This allows us to study the multi-step\ninference mechanism of LLMs from first principles. We relate the obtained\nresults to the pathological behavior observed with LLMs such as repetitions and\nincoherent replies with high temperature. Finally, we leverage the proposed\nformalization to derive pre-training and in-context learning generalization\nbounds for LLMs under realistic data and model assumptions. Experiments with\nthe most recent Llama and Gemma herds of models show that our theory correctly\ncaptures their behavior in practice.",
      "tldr_zh": "本文将大型语言模型(LLMs)建模为在有限状态空间上的Markov chains，分析其多步推理机制，以从第一原理解释LLMs的泛化能力。研究揭示了LLMs常见问题，如高温度下的重复和不连贯回复，并推导出预训练和in-context learning的泛化边界。实验结果显示，该理论准确捕捉了Llama和Gemma模型的实际行为。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02724v2",
      "published_date": "2024-10-03 17:45:31 UTC",
      "updated_date": "2025-02-02 15:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:35:56.961229"
    },
    {
      "arxiv_id": "2410.12836v2",
      "title": "EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Kaizhi Zheng",
        "Xiaotong Chen",
        "Xuehai He",
        "Jing Gu",
        "Linjie Li",
        "Zhengyuan Yang",
        "Kevin Lin",
        "Jianfeng Wang",
        "Lijuan Wang",
        "Xin Eric Wang"
      ],
      "abstract": "Given the steep learning curve of professional 3D software and the\ntime-consuming process of managing large 3D assets, language-guided 3D scene\nediting has significant potential in fields such as virtual reality, augmented\nreality, and gaming. However, recent approaches to language-guided 3D scene\nediting either require manual interventions or focus only on appearance\nmodifications without supporting comprehensive scene layout changes. In\nresponse, we propose EditRoom, a unified framework capable of executing a\nvariety of layout edits through natural language commands, without requiring\nmanual intervention. Specifically, EditRoom leverages Large Language Models\n(LLMs) for command planning and generates target scenes using a diffusion-based\nmethod, enabling six types of edits: rotate, translate, scale, replace, add,\nand remove. To address the lack of data for language-guided 3D scene editing,\nwe have developed an automatic pipeline to augment existing 3D scene synthesis\ndatasets and introduced EditRoom-DB, a large-scale dataset with 83k editing\npairs, for training and evaluation. Our experiments demonstrate that our\napproach consistently outperforms other baselines across all metrics,\nindicating higher accuracy and coherence in language-guided scene layout\nediting.",
      "tldr_zh": "本研究提出EditRoom框架，利用LLMs（Large Language Models）参数化的Graph Diffusion方法，实现通过自然语言命令进行可组合的3D房间布局编辑，支持六种操作：rotate, translate, scale, replace, add和remove，无需手动干预。EditRoom解决了现有方法在布局变化方面的局限性，并通过自动管道增强数据集，创建了包含83k编辑对的EditRoom-DB，用于训练和评估。该框架在实验中显著优于基线模型，在准确性和场景连贯性指标上表现出色，适用于虚拟现实、增强现实和游戏等领域。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12836v2",
      "published_date": "2024-10-03 17:42:24 UTC",
      "updated_date": "2025-04-01 23:38:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:36:09.160116"
    },
    {
      "arxiv_id": "2410.02721v1",
      "title": "Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization",
      "title_zh": "基于向量存储、知识图谱和张量分解的领域特定检索增强生成",
      "authors": [
        "Ryan C. Barron",
        "Ves Grantcharov",
        "Selma Wanna",
        "Maksim E. Eren",
        "Manish Bhattarai",
        "Nicholas Solovyev",
        "George Tompkins",
        "Charles Nicholas",
        "Kim Ø. Rasmussen",
        "Cynthia Matuszek",
        "Boian S. Alexandrov"
      ],
      "abstract": "Large Language Models (LLMs) are pre-trained on large-scale corpora and excel\nin numerous general natural language processing (NLP) tasks, such as question\nanswering (QA). Despite their advanced language capabilities, when it comes to\ndomain-specific and knowledge-intensive tasks, LLMs suffer from hallucinations,\nknowledge cut-offs, and lack of knowledge attributions. Additionally, fine\ntuning LLMs' intrinsic knowledge to highly specific domains is an expensive and\ntime consuming process. The retrieval-augmented generation (RAG) process has\nrecently emerged as a method capable of optimization of LLM responses, by\nreferencing them to a predetermined ontology. It was shown that using a\nKnowledge Graph (KG) ontology for RAG improves the QA accuracy, by taking into\naccount relevant sub-graphs that preserve the information in a structured\nmanner. In this paper, we introduce SMART-SLIC, a highly domain-specific LLM\nframework, that integrates RAG with KG and a vector store (VS) that store\nfactual domain specific information. Importantly, to avoid hallucinations in\nthe KG, we build these highly domain-specific KGs and VSs without the use of\nLLMs, but via NLP, data mining, and nonnegative tensor factorization with\nautomatic model selection. Pairing our RAG with a domain-specific: (i) KG\n(containing structured information), and (ii) VS (containing unstructured\ninformation) enables the development of domain-specific chat-bots that\nattribute the source of information, mitigate hallucinations, lessen the need\nfor fine-tuning, and excel in highly domain-specific question answering tasks.\nWe pair SMART-SLIC with chain-of-thought prompting agents. The framework is\ndesigned to be generalizable to adapt to any specific or specialized domain. In\nthis paper, we demonstrate the question answering capabilities of our framework\non a corpus of scientific publications on malware analysis and anomaly\ndetection.",
      "tldr_zh": "该论文提出SMART-SLIC框架，用于解决Large Language Models (LLMs)在领域特定和知识密集任务中的幻觉、知识截止和归因问题。该框架整合Retrieval-Augmented Generation (RAG)技术，与Knowledge Graph (KG)（存储结构化信息）和Vector Store (VS)（存储非结构化信息）相结合，并通过NLP、数据挖掘和nonnegative tensor factorization构建这些组件，而非依赖LLMs。结果显示，SMART-SLIC能提供信息来源归因、减少对fine-tuning的需求，并在恶意软件分析和异常检测领域的问答任务中表现出色，具有良好的泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages 7 figures, 1 table, 1 cypher code Accepted to ICMLA 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02721v1",
      "published_date": "2024-10-03 17:40:55 UTC",
      "updated_date": "2024-10-03 17:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:36:21.996439"
    },
    {
      "arxiv_id": "2410.02720v2",
      "title": "Curvature Diversity-Driven Deformation and Domain Alignment for Point Cloud",
      "title_zh": "翻译失败",
      "authors": [
        "Mengxi Wu",
        "Hao Huang",
        "Yi Fang",
        "Mohammad Rostami"
      ],
      "abstract": "Unsupervised Domain Adaptation (UDA) is crucial for reducing the need for\nextensive manual data annotation when training deep networks on point cloud\ndata. A significant challenge of UDA lies in effectively bridging the domain\ngap. To tackle this challenge, we propose \\textbf{C}urvature\n\\textbf{D}iversity-Driven \\textbf{N}uclear-Norm Wasserstein \\textbf{D}omain\nAlignment (CDND). Our approach first introduces a \\textit{\\textbf{Curv}ature\nDiversity-driven Deformation \\textbf{Rec}onstruction (CurvRec)} task, which\neffectively mitigates the gap between the source and target domains by enabling\nthe model to extract salient features from semantically rich regions of a given\npoint cloud. We then propose \\textit{\\textbf{D}eformation-based\n\\textbf{N}uclear-norm \\textbf{W}asserstein \\textbf{D}iscrepancy (D-NWD)}, which\napplies the Nuclear-norm Wasserstein Discrepancy to both \\textit{deformed and\noriginal} data samples to align the source and target domains. Furthermore, we\ncontribute a theoretical justification for the effectiveness of D-NWD in\ndistribution alignment and demonstrate that it is \\textit{generic} enough to be\napplied to \\textbf{any} deformations. To validate our method, we conduct\nextensive experiments on two public domain adaptation datasets for point cloud\nclassification and segmentation tasks. Empirical experiment results show that\nour CDND achieves state-of-the-art performance by a noticeable margin over\nexisting approaches.",
      "tldr_zh": "本研究提出了一种名为 CDND 的方法，用于点云数据的无监督域适应 (UDA)，旨在通过曲率多样性驱动的变形和域对齐来桥接源域和目标域的差距。CDND 包括 CurvRec 任务，该任务通过基于曲率多样性的变形重建来提取点云中语义丰富的特征，从而减少域间差异；以及 D-NWD 组件，该组件应用核范数 Wasserstein 差异对原始和变形数据进行域对齐，并提供了其在分布对齐的有效性的理论证明。实验结果显示，CDND 在两个公共点云数据集上的分类和分割任务中，显著超过了现有方法，实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02720v2",
      "published_date": "2024-10-03 17:39:55 UTC",
      "updated_date": "2024-10-05 03:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:36:43.971678"
    },
    {
      "arxiv_id": "2410.02717v1",
      "title": "Measurements with Noise: Bayesian Optimization for Co-optimizing Noise and Property Discovery in Automated Experiments",
      "title_zh": "翻译失败",
      "authors": [
        "Boris N. Slautin",
        "Yu Liu",
        "Jan Dec",
        "Vladimir V. Shvartsman",
        "Doru C. Lupascu",
        "Maxim Ziatdinov",
        "Sergei V. Kalinin"
      ],
      "abstract": "We have developed a Bayesian optimization (BO) workflow that integrates\nintra-step noise optimization into automated experimental cycles. Traditional\nBO approaches in automated experiments focus on optimizing experimental\ntrajectories but often overlook the impact of measurement noise on data quality\nand cost. Our proposed framework simultaneously optimizes both the target\nproperty and the associated measurement noise by introducing time as an\nadditional input parameter, thereby balancing the signal-to-noise ratio and\nexperimental duration. Two approaches are explored: a reward-driven noise\noptimization and a double-optimization acquisition function, both enhancing the\nefficiency of automated workflows by considering noise and cost within the\noptimization process. We validate our method through simulations and real-world\nexperiments using Piezoresponse Force Microscopy (PFM), demonstrating the\nsuccessful optimization of measurement duration and property exploration. Our\napproach offers a scalable solution for optimizing multiple variables in\nautomated experimental workflows, improving data quality, and reducing resource\nexpenditure in materials science and beyond.",
      "tldr_zh": "这篇论文提出了一种整合噪声优化的 Bayesian Optimization (BO) 工作流程，用于自动化实验中同时优化目标属性和测量噪声。传统 BO 方法虽关注实验轨迹优化，但忽略了噪声对数据质量和成本的影响，该框架通过引入时间作为额外输入参数，平衡信噪比和实验持续时间，并探索了奖励驱动噪声优化和双优化获取函数两种方法。通过模拟和使用 Piezoresponse Force Microscopy (PFM) 的真实实验验证，该方法显著提高了实验效率，改善了数据质量，并减少了资源消耗。该方案为材料科学等领域提供了一个可扩展的优化解决方案。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02717v1",
      "published_date": "2024-10-03 17:38:43 UTC",
      "updated_date": "2024-10-03 17:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:36:56.087220"
    },
    {
      "arxiv_id": "2410.02710v1",
      "title": "SteerDiff: Steering towards Safe Text-to-Image Diffusion Models",
      "title_zh": "SteerDiff：导向安全的文本到图像扩散模型",
      "authors": [
        "Hongxiang Zhang",
        "Yifeng He",
        "Hao Chen"
      ],
      "abstract": "Text-to-image (T2I) diffusion models have drawn attention for their ability\nto generate high-quality images with precise text alignment. However, these\nmodels can also be misused to produce inappropriate content. Existing safety\nmeasures, which typically rely on text classifiers or ControlNet-like\napproaches, are often insufficient. Traditional text classifiers rely on\nlarge-scale labeled datasets and can be easily bypassed by rephrasing. As\ndiffusion models continue to scale, fine-tuning these safeguards becomes\nincreasingly challenging and lacks flexibility. Recent red-teaming attack\nresearches further underscore the need for a new paradigm to prevent the\ngeneration of inappropriate content. In this paper, we introduce SteerDiff, a\nlightweight adaptor module designed to act as an intermediary between user\ninput and the diffusion model, ensuring that generated images adhere to ethical\nand safety standards with little to no impact on usability. SteerDiff\nidentifies and manipulates inappropriate concepts within the text embedding\nspace to guide the model away from harmful outputs. We conduct extensive\nexperiments across various concept unlearning tasks to evaluate the\neffectiveness of our approach. Furthermore, we benchmark SteerDiff against\nmultiple red-teaming strategies to assess its robustness. Finally, we explore\nthe potential of SteerDiff for concept forgetting tasks, demonstrating its\nversatility in text-conditioned image generation.",
      "tldr_zh": "本研究针对文本到图像 (Text-to-Image) 扩散模型可能生成不适当内容的问题，提出了一种轻量级适配器模块 SteerDiff，作为用户输入和模型之间的中介。SteerDiff 通过识别并操纵文本嵌入空间中的不适当概念，引导模型避免有害输出，同时保持生成图像的可用性和精确性。实验结果显示，该方法在各种概念遗忘任务和红队攻击基准测试中表现出色，提高了模型的安全性和鲁棒性，并展示了其在文本条件图像生成中的多功能性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02710v1",
      "published_date": "2024-10-03 17:34:55 UTC",
      "updated_date": "2024-10-03 17:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:37:06.838862"
    },
    {
      "arxiv_id": "2410.02707v4",
      "title": "LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Hadas Orgad",
        "Michael Toker",
        "Zorik Gekhman",
        "Roi Reichart",
        "Idan Szpektor",
        "Hadas Kotek",
        "Yonatan Belinkov"
      ],
      "abstract": "Large language models (LLMs) often produce errors, including factual\ninaccuracies, biases, and reasoning failures, collectively referred to as\n\"hallucinations\". Recent studies have demonstrated that LLMs' internal states\nencode information regarding the truthfulness of their outputs, and that this\ninformation can be utilized to detect errors. In this work, we show that the\ninternal representations of LLMs encode much more information about\ntruthfulness than previously recognized. We first discover that the\ntruthfulness information is concentrated in specific tokens, and leveraging\nthis property significantly enhances error detection performance. Yet, we show\nthat such error detectors fail to generalize across datasets, implying that --\ncontrary to prior claims -- truthfulness encoding is not universal but rather\nmultifaceted. Next, we show that internal representations can also be used for\npredicting the types of errors the model is likely to make, facilitating the\ndevelopment of tailored mitigation strategies. Lastly, we reveal a discrepancy\nbetween LLMs' internal encoding and external behavior: they may encode the\ncorrect answer, yet consistently generate an incorrect one. Taken together,\nthese insights deepen our understanding of LLM errors from the model's internal\nperspective, which can guide future research on enhancing error analysis and\nmitigation.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）在处理“hallucinations”（幻觉，如事实错误、偏见和推理失败）时，其内部表示中编码了比以往认知更多的真实性信息。研究发现，这种真实性信息主要集中在特定 tokens 上，利用此特性可显著提升错误检测性能，但这些检测器无法在不同数据集上泛化，表明真实性编码是多方面的而非通用的。通过分析内部表示，研究还能够预测LLMs可能犯的错误类型，从而支持定制化的错误缓解策略。最后，研究指出LLMs可能内部编码了正确答案却生成错误输出，这一内部与外部行为的差异为未来错误分析和模型改进提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02707v4",
      "published_date": "2024-10-03 17:31:31 UTC",
      "updated_date": "2025-05-18 11:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:37:19.668709"
    },
    {
      "arxiv_id": "2410.02703v2",
      "title": "Selective Attention Improves Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Yaniv Leviathan",
        "Matan Kalman",
        "Yossi Matias"
      ],
      "abstract": "Unneeded elements in the attention's context degrade performance. We\nintroduce Selective Attention, a simple parameter-free change to the standard\nattention mechanism which reduces attention to unneeded elements. Selective\nattention consistently improves language modeling and downstream task\nperformance in a variety of model sizes and context lengths. For example,\ntransformers trained with the language modeling objective on C4 with selective\nattention perform language modeling equivalently to standard transformers with\n~2X more heads and parameters in their attention modules. Selective attention\nalso allows decreasing the size of the attention's context buffer, leading to\nmeaningful reductions in the memory and compute requirements during inference.\nFor example, transformers trained on C4 with context sizes of 512, 1,024, and\n2,048 need 16X, 25X, and 47X less memory for their attention module,\nrespectively, when equipped with selective attention, as those without\nselective attention, with the same validation perplexity.",
      "tldr_zh": "这篇论文提出 Selective Attention，一种简单、无参数的修改机制，用于改善标准 Transformer 的注意力模块，从而减少对不必要元素的关注。实验结果显示，该机制在各种模型大小和上下文长度下，一致提升语言建模和下游任务性能，例如在 C4 数据集上，使用 Selective Attention 的 Transformer 能与具有约 2 倍 heads 和参数的标准模型实现等效语言建模效果。此外，Selective Attention 显著降低推理时的内存和计算需求，例如在上下文大小为 512、1,024 和 2,048 时，注意力模块的内存使用分别减少 16X、25X 和 47X，同时保持相同的验证 perplexity。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02703v2",
      "published_date": "2024-10-03 17:27:30 UTC",
      "updated_date": "2025-04-24 02:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:37:31.307232"
    },
    {
      "arxiv_id": "2410.02694v3",
      "title": "HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly",
      "title_zh": "HELMET：如何有效且彻底评估长上下文语言模型",
      "authors": [
        "Howard Yen",
        "Tianyu Gao",
        "Minmin Hou",
        "Ke Ding",
        "Daniel Fleischer",
        "Peter Izsak",
        "Moshe Wasserblat",
        "Danqi Chen"
      ],
      "abstract": "Many benchmarks exist for evaluating long-context language models (LCLMs),\nyet developers often rely on synthetic tasks such as needle-in-a-haystack\n(NIAH) or an arbitrary subset of tasks. However, it remains unclear whether\nthese benchmarks reflect the diverse downstream applications of LCLMs, and such\ninconsistencies further complicate model comparison. We investigate the\nunderlying reasons behind these practices and find that existing benchmarks\noften provide noisy signals due to limited coverage of applications,\ninsufficient context lengths, unreliable metrics, and incompatibility with base\nmodels. In this work, we introduce HELMET (How to Evaluate Long-context Models\nEffectively and Thoroughly), a comprehensive benchmark encompassing seven\ndiverse, application-centric categories. We also address several issues in\nprevious benchmarks by adding controllable lengths up to 128K tokens,\nmodel-based evaluation for reliable metrics, and few-shot prompting for\nrobustly evaluating base models. Consequently, we demonstrate that HELMET\noffers more reliable and consistent rankings of frontier LCLMs. Through a\ncomprehensive study of 59 LCLMs, we find that (1) synthetic tasks like NIAH do\nnot reliably predict downstream performance; (2) the diverse categories in\nHELMET exhibit distinct trends and low correlations with each other; and (3)\nwhile most LCLMs achieve perfect NIAH scores, open-source models significantly\nlag behind closed ones when tasks require full-context reasoning or following\ncomplex instructions -- the gap widens as length increases. Finally, we\nrecommend using our RAG tasks for fast model development, as they are easy to\nrun and better predict other downstream performance; ultimately, we advocate\nfor a holistic evaluation across diverse tasks.",
      "tldr_zh": "本文提出 HELMET 基准，用于有效评估长上下文语言模型 (LCLMs)，它涵盖七个多样化的应用中心类别，并通过支持高达128K tokens的上下文长度、基于模型的评价和 few-shot prompting，解决了现有基准的噪音问题，如应用覆盖不足和指标不可靠。研究评估了59个LCLMs，发现合成任务如 needle-in-a-haystack (NIAH) 无法可靠预测下游性能，而 HELMET 的不同类别显示出独特趋势和低相关性。结果表明，大多数LCLMs 在NIAH上表现完美，但开源模型在需要全上下文推理或复杂指令的任务上显著落后于闭源模型，且差距随上下文长度增加。最后，作者推荐使用 RAG 任务进行快速模型开发，并倡导对LCLMs进行全面、多任务评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025. Project page: https://princeton-nlp.github.io/HELMET/",
      "pdf_url": "http://arxiv.org/pdf/2410.02694v3",
      "published_date": "2024-10-03 17:20:11 UTC",
      "updated_date": "2025-03-06 18:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:37:44.399775"
    },
    {
      "arxiv_id": "2410.02693v1",
      "title": "Discovering Clues of Spoofed LM Watermarks",
      "title_zh": "发现伪造 LM 水印的线索",
      "authors": [
        "Thibaud Gloaguen",
        "Nikola Jovanović",
        "Robin Staab",
        "Martin Vechev"
      ],
      "abstract": "LLM watermarks stand out as a promising way to attribute ownership of\nLLM-generated text. One threat to watermark credibility comes from spoofing\nattacks, where an unauthorized third party forges the watermark, enabling it to\nfalsely attribute arbitrary texts to a particular LLM. While recent works have\ndemonstrated that state-of-the-art schemes are in fact vulnerable to spoofing,\nthey lack deeper qualitative analysis of the texts produced by spoofing\nmethods. In this work, we for the first time reveal that there are observable\ndifferences between genuine and spoofed watermark texts. Namely, we show that\nregardless of their underlying approach, all current spoofing methods\nconsistently leave observable artifacts in spoofed texts, indicative of\nwatermark forgery. We build upon these findings to propose rigorous statistical\ntests that reliably reveal the presence of such artifacts, effectively\ndiscovering that a watermark was spoofed. Our experimental evaluation shows\nhigh test power across all current spoofing methods, providing insights into\ntheir fundamental limitations, and suggesting a way to mitigate this threat.",
      "tldr_zh": "该研究揭示了LLM watermarks在面对spoofing attacks时存在的漏洞，即第三方伪造水印以错误归因文本所有权。作者首次发现，所有当前spoofing methods都会在伪造文本中留下observable artifacts，这些痕迹是水印伪造的可靠指标。基于此，他们提出rigorous statistical tests，用于检测这些伪造痕迹，以有效识别水印是否被欺骗。实验结果显示，该测试在多种spoofing methods上表现出高测试功率，提供对这些方法的根本限制的见解，并建议潜在的缓解策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02693v1",
      "published_date": "2024-10-03 17:18:37 UTC",
      "updated_date": "2024-10-03 17:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:37:58.205228"
    },
    {
      "arxiv_id": "2410.02688v2",
      "title": "User-centric Immersive Communications in 6G: A Data-oriented Framework via Digital Twin",
      "title_zh": "翻译失败",
      "authors": [
        "Conghao Zhou",
        "Shisheng Hu",
        "Jie Gao",
        "Xinyu Huang",
        "Weihua Zhuang",
        "Xuemin Shen"
      ],
      "abstract": "In this article, we present a novel user-centric service provision for\nimmersive communications (IC) in 6G to deal with the uncertainty of individual\nuser behaviors while satisfying unique requirements on the quality of\nmulti-sensory experience. To this end, we propose a data-oriented framework for\nnetwork resource management, featuring personalized data management that can\nsupport network modeling tailored to different user demands. Our framework\nleverages the digital twin (DT) technique as a key enabler. Particularly, a DT\nis established for each user, and the data attributes in the DT are customized\nbased on the characteristics of the user. The DT functions, corresponding to\nvarious data operations, are customized in the development, evaluation, and\nupdate of network models to meet unique user demands. A trace-driven case study\ndemonstrates the effectiveness of our framework in achieving user-centric IC\nand the significance of personalized data management in 6G.",
      "tldr_zh": "本研究提出了一种用户中心的数据导向框架，用于6G沉浸式通信(Immersive Communications, IC)，旨在应对个体用户行为的不确定性并满足多感官体验的质量要求。该框架利用数字孪生(Digital Twin, DT)技术为每个用户建立个性化DT，并根据用户特性定制数据属性和功能，从而支持开发、评估和更新网络模型以适应独特需求。通过跟踪驱动的案例研究，证明该框架在实现用户中心IC方面有效，并突出了个性化数据管理在6G中的重要性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted by IEEE Wireless Communications",
      "pdf_url": "http://arxiv.org/pdf/2410.02688v2",
      "published_date": "2024-10-03 17:15:53 UTC",
      "updated_date": "2025-03-12 18:52:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:38:10.125763"
    },
    {
      "arxiv_id": "2410.02683v3",
      "title": "DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life",
      "title_zh": "DailyDilemmas：通过日常生活困境揭示LLMs的价值偏好",
      "authors": [
        "Yu Ying Chiu",
        "Liwei Jiang",
        "Yejin Choi"
      ],
      "abstract": "As users increasingly seek guidance from LLMs for decision-making in daily\nlife, many of these decisions are not clear-cut and depend significantly on the\npersonal values and ethical standards of people. We present DailyDilemmas, a\ndataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma\npresents two possible actions, along with affected parties and relevant human\nvalues for each action. Based on these dilemmas, we gather a repository of\nhuman values covering diverse everyday topics, such as interpersonal\nrelationships, workplace, and environmental issues. With DailyDilemmas, we\nevaluate LLMs on these dilemmas to determine what action they will choose and\nthe values represented by these action choices. Then, we analyze values through\nthe lens of five theoretical frameworks inspired by sociology, psychology, and\nphilosophy, including the World Values Survey, Moral Foundations Theory,\nMaslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of\nEmotions. For instance, we find LLMs are most aligned with self-expression over\nsurvival in World Values Survey and care over loyalty in Moral Foundations\nTheory. Interestingly, we find substantial preference differences in models for\nsome core values. For example, for truthfulness, Mixtral-8x7B neglects it by\n9.7% while GPT-4-turbo selects it by 9.4%. We also study the recent guidance\nreleased by OpenAI (ModelSpec), and Anthropic (Constitutional AI) to understand\nhow their designated principles reflect their models' actual value\nprioritization when facing nuanced moral reasoning in daily-life settings.\nFinally, we find that end users cannot effectively steer such prioritization\nusing system prompts.",
      "tldr_zh": "该研究引入了DailyDilemmas数据集，包含1,360个日常生活道德困境，每个困境包括两种行动、受影响方和相关人类价值观，旨在揭示LLMs的价值偏好。研究者通过五个理论框架（World Values Survey、Moral Foundations Theory、Maslow's Hierarchy of Needs、Aristotle's Virtues和Plutchik's Wheel of Emotions）评估LLMs在这些困境中的选择，并分析其代表的值向，例如LLMs更倾向于自我表达而非生存，以及模型间差异如Mixtral-8x7B在truthfulness上偏低9.7%。此外，研究发现OpenAI的ModelSpec和Anthropic的Constitutional AI指导原则未能完全反映模型的实际价值优先级，且用户无法通过系统提示有效引导这些偏好。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted into ICLR 2025 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2410.02683v3",
      "published_date": "2024-10-03 17:08:52 UTC",
      "updated_date": "2025-03-15 03:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:38:19.082533"
    },
    {
      "arxiv_id": "2410.11855v1",
      "title": "Online Energy Optimization in GPUs: A Multi-Armed Bandit Approach",
      "title_zh": "GPU 中的在线能量",
      "authors": [
        "Xiongxiao Xu",
        "Solomon Abera Bekele",
        "Brice Videau",
        "Kai Shu"
      ],
      "abstract": "Energy consumption has become a critical design metric and a limiting factor\nin the development of future computing architectures, from small wearable\ndevices to large-scale leadership computing facilities. The predominant methods\nin energy management optimization are focused on CPUs. However, GPUs are\nincreasingly significant and account for the majority of energy consumption in\nheterogeneous high performance computing (HPC) systems. Moreover, they\ntypically rely on either purely offline training or a hybrid of offline and\nonline training, which are impractical and lead to energy loss during data\ncollection. Therefore, this paper studies a novel and practical online energy\noptimization problem for GPUs in HPC scenarios. The problem is challenging due\nto the inherent performance-energy trade-offs of GPUs, the exploration &\nexploitation dilemma across frequencies, and the lack of explicit performance\ncounters in GPUs. To address these challenges, we formulate the online energy\nconsumption optimization problem as a multi-armed bandit framework and develop\na novel bandit based framework EnergyUCB. EnergyUCB is designed to dynamically\nadjust GPU core frequencies in real-time, reducing energy consumption with\nminimal impact on performance. Specifically, the proposed framework EnergyUCB\n(1) balances the performance-energy trade-off in the reward function, (2)\neffectively navigates the exploration & exploitation dilemma when adjusting GPU\ncore frequencies online, and (3) leverages the ratio of GPU core utilization to\nuncore utilization as a real-time GPU performance metric. Experiments on a wide\nrange of real-world HPC benchmarks demonstrate that EnergyUCB can achieve\nsubstantial energy savings. The code of EnergyUCB is available at\nhttps://github.com/XiongxiaoXu/EnergyUCB-Bandit.",
      "tldr_zh": "本文研究了GPU在高性能计算(HPC)场景下的在线能源优化问题，针对传统方法的局限性（如依赖离线训练导致的能源损失），提出了一种基于Multi-Armed Bandit框架的EnergyUCB方法。该方法动态调整GPU核心频率，通过在奖励函数中平衡性能-能源权衡、处理探索与利用困境，并使用GPU核心利用率与非核心利用率的比率作为实时性能指标，实现能源消耗最小化同时保持性能。实验在多种真实HPC基准测试中证明，EnergyUCB可实现显著能源节约，并开源代码以供进一步应用。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11855v1",
      "published_date": "2024-10-03 17:05:34 UTC",
      "updated_date": "2024-10-03 17:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:38:31.590847"
    },
    {
      "arxiv_id": "2410.02678v1",
      "title": "Distilling an End-to-End Voice Assistant Without Instruction Training Data",
      "title_zh": "翻译失败",
      "authors": [
        "William Held",
        "Ella Li",
        "Michael Ryan",
        "Weiyan Shi",
        "Yanzhe Zhang",
        "Diyi Yang"
      ],
      "abstract": "Voice assistants, such as Siri and Google Assistant, typically model audio\nand text separately, resulting in lost speech information and increased\ncomplexity. Recent efforts to address this with end-to-end Speech Large\nLanguage Models (LLMs) trained with supervised finetuning (SFT)\n  have led to models ``forgetting\" capabilities from text-only LLMs. Our work\nproposes an alternative paradigm for training Speech LLMs without instruction\ndata, using the response of a text-only LLM to transcripts as self-supervision.\nImportantly, this process can be performed without annotated responses. We show\nthat our Distilled Voice Assistant (DiVA) generalizes to Spoken Question\nAnswering, Classification, and Translation. Furthermore, we show that DiVA\nbetter meets user preferences, achieving a 72\\% win rate compared with\nstate-of-the-art models like Qwen 2 Audio, despite using $>$100x less training\ncompute.",
      "tldr_zh": "本研究指出，现有语音助手如 Siri 和 Google Assistant 因音频和文本分离而导致信息丢失，且端到端 Speech LLMs 在监督微调(SFT)过程中可能遗忘文本-only LLMs 的能力。作者提出一种无需指令训练数据的训练范式，使用文本-only LLM 对转录响应的自监督方法，开发了 Distilled Voice Assistant (DiVA)。DiVA 展示了在 Spoken Question Answering、Classification 和 Translation 等任务上的良好泛化能力，并与 Qwen 2 Audio 相比，用户偏好胜率达72%，尽管其训练计算量小于1/100。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02678v1",
      "published_date": "2024-10-03 17:04:48 UTC",
      "updated_date": "2024-10-03 17:04:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:38:46.521879"
    },
    {
      "arxiv_id": "2410.02677v1",
      "title": "CulturalBench: a Robust, Diverse and Challenging Benchmark on Measuring the (Lack of) Cultural Knowledge of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Ying Chiu",
        "Liwei Jiang",
        "Bill Yuchen Lin",
        "Chan Young Park",
        "Shuyue Stella Li",
        "Sahithya Ravi",
        "Mehar Bhatia",
        "Maria Antoniak",
        "Yulia Tsvetkov",
        "Vered Shwartz",
        "Yejin Choi"
      ],
      "abstract": "To make large language models (LLMs) more helpful across diverse cultures, it\nis essential to have effective cultural knowledge benchmarks to measure and\ntrack our progress. Effective benchmarks need to be robust, diverse, and\nchallenging. We introduce CulturalBench: a set of 1,227 human-written and\nhuman-verified questions for effectively assessing LLMs' cultural knowledge,\ncovering 45 global regions including the underrepresented ones like Bangladesh,\nZimbabwe, and Peru. Questions - each verified by five independent annotators -\nspan 17 diverse topics ranging from food preferences to greeting etiquettes. We\nevaluate models on two setups: CulturalBench-Easy and CulturalBench-Hard which\nshare the same questions but asked differently. We find that LLMs are sensitive\nto such difference in setups (e.g., GPT-4o with 27.3% difference). Compared to\nhuman performance (92.6% accuracy), CulturalBench-Hard is more challenging for\nfrontier LLMs with the best performing model (GPT-4o) at only 61.5% and the\nworst (Llama3-8b) at 21.4%. Moreover, we find that LLMs often struggle with\ntricky questions that have multiple correct answers (e.g., What utensils do the\nChinese usually use?), revealing a tendency to converge to a single answer. Our\nresults also indicate that OpenAI GPT-4o substantially outperform other\nproprietary and open source models in questions related to all but one region\n(Oceania). Nonetheless, all models consistently underperform on questions\nrelated to South America and the Middle East.",
      "tldr_zh": "本文提出 CulturalBench，这是一个包含 1227 个人类撰写并验证的问题集，用于评估大型语言模型 (LLMs) 的文化知识水平，覆盖 45 个全球地区（包括欠代表地区如 Bangladesh、Zimbabwe 和 Peru）和 17 个主题，如食物偏好和问候礼仪。基准分为 CulturalBench-Easy 和 CulturalBench-Hard 两种设置，使用相同问题但不同提问方式，结果显示 LLMs 对表述敏感（例如 GPT-4o 准确率差异达 27.3%），且在 Hard 设置下表现远低于人类（人类 92.6%，GPT-4o 仅 61.5%）。研究发现，LLMs 尤其在处理多正确答案的问题上挣扎，并普遍在 South America 和 Middle East 相关问题上表现不佳，其中 OpenAI GPT-4o 在大多数地区领先但并非完美。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Under review",
      "pdf_url": "http://arxiv.org/pdf/2410.02677v1",
      "published_date": "2024-10-03 17:04:31 UTC",
      "updated_date": "2024-10-03 17:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:38:58.542720"
    },
    {
      "arxiv_id": "2410.02675v4",
      "title": "FAN: Fourier Analysis Networks",
      "title_zh": "FAN: 傅立叶分析网络",
      "authors": [
        "Yihong Dong",
        "Ge Li",
        "Yongding Tao",
        "Xue Jiang",
        "Kechi Zhang",
        "Jia Li",
        "Jinliang Deng",
        "Jing Su",
        "Jun Zhang",
        "Jingjing Xu"
      ],
      "abstract": "Despite the remarkable successes of general-purpose neural networks, such as\nMLPs and Transformers, we find that they exhibit notable shortcomings in\nmodeling and reasoning about periodic phenomena, achieving only marginal\nperformance within the training domain and failing to generalize effectively to\nout-of-domain (OOD) scenarios. Periodicity is ubiquitous throughout nature and\nscience. Therefore, neural networks should be equipped with the essential\nability to model and handle periodicity. In this work, we propose FAN, a novel\ngeneral-purpose neural network that offers broad applicability similar to MLP\nwhile effectively addressing periodicity modeling challenges. Periodicity is\nnaturally integrated into FAN's structure and computational processes by\nintroducing the Fourier Principle. Unlike existing Fourier-based networks,\nwhich possess particular periodicity modeling abilities but are typically\ndesigned for specific tasks, our approach maintains the general-purpose\nmodeling capability. Therefore, FAN can seamlessly replace MLP in various model\narchitectures with fewer parameters and FLOPs. Through extensive experiments,\nwe demonstrate the superiority of FAN in periodicity modeling tasks and the\neffectiveness and generalizability of FAN across a range of real-world tasks,\ne.g., symbolic formula representation, time series forecasting, language\nmodeling, and image recognition.",
      "tldr_zh": "本研究发现，通用神经网络如 MLP 和 Transformers 在处理周期性现象时表现欠佳，仅在训练域内有微弱性能，且无法有效泛化到 OOD 场景。针对这一问题，提出 FAN（Fourier Analysis Networks），一种新型通用神经网络，通过引入 Fourier Principle 将周期性自然整合到其结构和计算过程中。FAN 保留了 MLP 的广泛适用性，同时减少参数和 FLOPs，能无缝替换现有模型架构。实验结果显示，FAN 在周期性建模任务上表现出色，并在真实应用如符号公式表示、时间序列预测、语言建模和图像识别中展现出优越的性能和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02675v4",
      "published_date": "2024-10-03 17:02:21 UTC",
      "updated_date": "2025-04-02 04:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:39:09.157989"
    },
    {
      "arxiv_id": "2410.02671v3",
      "title": "Unsupervised Point Cloud Completion through Unbalanced Optimal Transport",
      "title_zh": "无监督点云补全通过不平衡最优传输",
      "authors": [
        "Taekyung Lee",
        "Jaemoo Choi",
        "Jaewoong Choi",
        "Myungjoo Kang"
      ],
      "abstract": "Unpaired point cloud completion explores methods for learning a completion\nmap from unpaired incomplete and complete point cloud data. In this paper, we\npropose a novel approach for unpaired point cloud completion using the\nunbalanced optimal transport map, called Unbalanced Optimal Transport Map for\nUnpaired Point Cloud Completion (UOT-UPC). We demonstrate that the unpaired\npoint cloud completion can be naturally interpreted as the Optimal Transport\n(OT) problem and introduce the Unbalanced Optimal Transport (UOT) approach to\naddress the class imbalance problem, which is prevalent in unpaired point cloud\ncompletion datasets. Moreover, we analyze the appropriate cost function for\nunpaired completion tasks. This analysis shows that the InfoCD cost function is\nparticularly well-suited for this task. Our model is the first attempt to\nleverage UOT for unpaired point cloud completion, achieving competitive or\nsuperior results on both single-category and multi-category datasets. In\nparticular, our model is especially effective in scenarios with class\nimbalance, where the proportions of categories are different between the\nincomplete and complete point cloud datasets.",
      "tldr_zh": "本研究提出了一种名为 UOT-UPC 的新方法，用于无监督的非配对点云完成，通过 Unbalanced Optimal Transport（UOT）来解决点云数据集中的类别不平衡问题。论文将非配对点云完成视为 Optimal Transport（OT）问题，并分析发现 InfoCD 成本函数特别适合此任务，从而实现有效的点云映射和完成。实验结果显示，该方法在单类别和多类别数据集上取得了竞争性或优越的性能，尤其在类别不平衡场景中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02671v3",
      "published_date": "2024-10-03 16:54:35 UTC",
      "updated_date": "2024-10-16 15:06:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:39:20.698646"
    },
    {
      "arxiv_id": "2410.02666v1",
      "title": "AlphaIntegrator: Transformer Action Search for Symbolic Integration Proofs",
      "title_zh": "翻译失败",
      "authors": [
        "Mert Ünsal",
        "Timon Gehr",
        "Martin Vechev"
      ],
      "abstract": "We present the first correct-by-construction learning-based system for\nstep-by-step mathematical integration. The key idea is to learn a policy,\nrepresented by a GPT transformer model, which guides the search for the right\nmathematical integration rule, to be carried out by a symbolic solver.\nConcretely, we introduce a symbolic engine with axiomatically correct actions\non mathematical expressions, as well as the first dataset for step-by-step\nintegration. Our GPT-style transformer model, trained on this synthetic data,\ndemonstrates strong generalization by surpassing its own data generator in\naccuracy and efficiency, using 50% fewer search steps. Our experimental results\nwith SoTA LLMs also demonstrate that the standard approach of fine-tuning LLMs\non a set of question-answer pairs is insufficient for solving this mathematical\ntask. This motivates the importance of discovering creative methods for\ncombining LLMs with symbolic reasoning engines, of which our work is an\ninstance.",
      "tldr_zh": "本研究提出了 AlphaIntegrator，这是一个基于学习的系统，用于逐步符号积分证明，通过 Transformer 模型作为策略来指导搜索正确的数学积分规则。系统结合了一个符号引擎，提供公理上正确的动作（actions on mathematical expressions），并构建了首个用于逐步积分的合成数据集。训练后的 GPT 风格 Transformer 模型在泛化能力上超越了数据生成器，实现 50% 更少的搜索步骤；实验结果表明，标准微调 SoTA LLMs 的方法不足以处理此任务，强调了融合 LLMs 与符号推理引擎的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02666v1",
      "published_date": "2024-10-03 16:50:30 UTC",
      "updated_date": "2024-10-03 16:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:39:33.805984"
    },
    {
      "arxiv_id": "2410.02664v1",
      "title": "Grounded Answers for Multi-agent Decision-making Problem through Generative World Model",
      "title_zh": "通过生成式世界模型为多智能体决策问题提供接地答案",
      "authors": [
        "Zeyang Liu",
        "Xinrui Yang",
        "Shiguang Sun",
        "Long Qian",
        "Lipeng Wan",
        "Xingyu Chen",
        "Xuguang Lan"
      ],
      "abstract": "Recent progress in generative models has stimulated significant innovations\nin many fields, such as image generation and chatbots. Despite their success,\nthese models often produce sketchy and misleading solutions for complex\nmulti-agent decision-making problems because they miss the trial-and-error\nexperience and reasoning as humans. To address this limitation, we explore a\nparadigm that integrates a language-guided simulator into the multi-agent\nreinforcement learning pipeline to enhance the generated answer. The simulator\nis a world model that separately learns dynamics and reward, where the dynamics\nmodel comprises an image tokenizer as well as a causal transformer to generate\ninteraction transitions autoregressively, and the reward model is a\nbidirectional transformer learned by maximizing the likelihood of trajectories\nin the expert demonstrations under language guidance. Given an image of the\ncurrent state and the task description, we use the world model to train the\njoint policy and produce the image sequence as the answer by running the\nconverged policy on the dynamics model. The empirical results demonstrate that\nthis framework can improve the answers for multi-agent decision-making problems\nby showing superior performance on the training and unseen tasks of the\nStarCraft Multi-Agent Challenge benchmark. In particular, it can generate\nconsistent interaction sequences and explainable reward functions at\ninteraction states, opening the path for training generative models of the\nfuture.",
      "tldr_zh": "该论文探讨了 generative models 在复杂多代理决策问题中的局限性，如缺乏人类的试错经验和推理，并提出一种将语言引导的模拟器（world model）集成到多代理强化学习管道中的新范式。世界模型分别学习动态（包括 image tokenizer 和 causal transformer 用于自动回归生成交互转移）和奖励（bidirectional transformer 通过最大化专家演示轨迹的似然）。实验结果显示，该框架在 StarCraft Multi-Agent Challenge 基准上的训练和未见任务中表现出色，能生成一致的交互序列和可解释的奖励函数，从而提升多代理决策问题的答案质量。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "The Thirty-eighth Annual Conference on Neural Information Processing\n  Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.02664v1",
      "published_date": "2024-10-03 16:49:59 UTC",
      "updated_date": "2024-10-03 16:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:39:46.023911"
    },
    {
      "arxiv_id": "2410.02656v2",
      "title": "Scalable Simulation-free Entropic Unbalanced Optimal Transport",
      "title_zh": "可扩展的无模拟熵不平衡最优传输",
      "authors": [
        "Jaemoo Choi",
        "Jaewoong Choi"
      ],
      "abstract": "The Optimal Transport (OT) problem investigates a transport map that connects\ntwo distributions while minimizing a given cost function. Finding such a\ntransport map has diverse applications in machine learning, such as generative\nmodeling and image-to-image translation. In this paper, we introduce a scalable\nand simulation-free approach for solving the Entropic Unbalanced Optimal\nTransport (EUOT) problem. We derive the dynamical form of this EUOT problem,\nwhich is a generalization of the Schr\\\"odinger bridges (SB) problem. Based on\nthis, we derive dual formulation and optimality conditions of the EUOT problem\nfrom the stochastic optimal control interpretation. By leveraging these\nproperties, we propose a simulation-free algorithm to solve EUOT, called\nSimulation-free EUOT (SF-EUOT). While existing SB models require expensive\nsimulation costs during training and evaluation, our model achieves\nsimulation-free training and one-step generation by utilizing the reciprocal\nproperty. Our model demonstrates significantly improved scalability in\ngenerative modeling and image-to-image translation tasks compared to previous\nSB methods.",
      "tldr_zh": "本论文提出了一种可扩展且无模拟的方法来解决 Entropic Unbalanced Optimal Transport (EUOT) 问题，该方法通过推导 EUOT 的动态形式、双重公式和最优条件，并基于随机最优控制解释，开发了 Simulation-free EUOT (SF-EUOT) 算法。相比传统的 Schrödinger bridges (SB) 方法，SF-EUOT 利用互惠属性避免了昂贵的模拟成本，实现无模拟训练和一步生成。在生成建模和图像到图像翻译任务中，该算法展示了显著的性能提升和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02656v2",
      "published_date": "2024-10-03 16:43:00 UTC",
      "updated_date": "2024-10-21 20:50:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:39:57.538054"
    },
    {
      "arxiv_id": "2410.02847v3",
      "title": "Deep Signature: Characterization of Large-Scale Molecular Dynamics",
      "title_zh": "Deep Signature: 大规模分子动力学的表征",
      "authors": [
        "Tiexin Qin",
        "Mengxu Zhu",
        "Chunyang Li",
        "Terry Lyons",
        "Hong Yan",
        "Haoliang Li"
      ],
      "abstract": "Understanding protein dynamics are essential for deciphering protein\nfunctional mechanisms and developing molecular therapies. However, the complex\nhigh-dimensional dynamics and interatomic interactions of biological processes\npose significant challenge for existing computational techniques. In this\npaper, we approach this problem for the first time by introducing Deep\nSignature, a novel computationally tractable framework that characterizes\ncomplex dynamics and interatomic interactions based on their evolving\ntrajectories. Specifically, our approach incorporates soft spectral clustering\nthat locally aggregates cooperative dynamics to reduce the size of the system,\nas well as signature transform that collects iterated integrals to provide a\nglobal characterization of the non-smooth interactive dynamics. Theoretical\nanalysis demonstrates that Deep Signature exhibits several desirable\nproperties, including invariance to translation, near invariance to rotation,\nequivariance to permutation of atomic coordinates, and invariance under time\nreparameterization. Furthermore, experimental results on three benchmarks of\nbiological processes verify that our approach can achieve superior performance\ncompared to baseline methods.",
      "tldr_zh": "本研究提出Deep Signature框架，首次针对复杂高维蛋白质动态和原子间互动问题，提供一种可计算的轨迹表征方法，以辅助解密蛋白质功能机制和分子疗法开发。该框架结合soft spectral clustering局部聚合合作动态以减小系统规模，以及signature transform收集迭代积分来全局表征非平滑互动动态。理论分析显示Deep Signature具有平移不变性、近似旋转不变性、原子坐标置换等变性和时间重参数化不变性等特性。在三个生物过程基准实验中，该方法比基线方法表现出显著优越性能。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02847v3",
      "published_date": "2024-10-03 16:37:48 UTC",
      "updated_date": "2025-05-14 08:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:40:09.862869"
    },
    {
      "arxiv_id": "2410.02651v2",
      "title": "CAX: Cellular Automata Accelerated in JAX",
      "title_zh": "CAX：元胞自动机在 JAX 中的加速",
      "authors": [
        "Maxence Faldor",
        "Antoine Cully"
      ],
      "abstract": "Cellular automata have become a cornerstone for investigating emergence and\nself-organization across diverse scientific disciplines. However, the absence\nof a hardware-accelerated cellular automata library limits the exploration of\nnew research directions, hinders collaboration, and impedes reproducibility. In\nthis work, we introduce CAX (Cellular Automata Accelerated in JAX), a\nhigh-performance and flexible open-source library designed to accelerate\ncellular automata research. CAX delivers cutting-edge performance through\nhardware acceleration while maintaining flexibility through its modular\narchitecture, intuitive API, and support for both discrete and continuous\ncellular automata in arbitrary dimensions. We demonstrate CAX's performance and\nflexibility through a wide range of benchmarks and applications. From classic\nmodels like elementary cellular automata and Conway's Game of Life to advanced\napplications such as growing neural cellular automata and self-classifying\nMNIST digits, CAX speeds up simulations up to 2,000 times faster. Furthermore,\nwe demonstrate CAX's potential to accelerate research by presenting a\ncollection of three novel cellular automata experiments, each implemented in\njust a few lines of code thanks to the library's modular architecture. Notably,\nwe show that a simple one-dimensional cellular automaton can outperform GPT-4\non the 1D-ARC challenge.",
      "tldr_zh": "本研究引入 CAX，一种基于 JAX 的硬件加速开源库，旨在解决细胞自动机（Cellular Automata）研究中缺乏高效工具的问题，从而促进新兴和自组织现象的探索。CAX 通过模块化架构、直观 API 和对离散及连续细胞自动机的支持，实现任意维度的灵活模拟，并在基准测试中将经典模型（如 Conway's Game of Life）和高级应用（如神经细胞自动机）加速高达 2000 倍。论文展示了三个新颖实验，每个仅用几行代码实现，并证明一个简单的一维细胞自动机在 1D-ARC 挑战中超越了 GPT-4，为加速科研协作和可重复性奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02651v2",
      "published_date": "2024-10-03 16:36:05 UTC",
      "updated_date": "2025-03-11 11:34:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:40:20.998283"
    },
    {
      "arxiv_id": "2410.02650v2",
      "title": "Undesirable Memorization in Large Language Models: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Satvaty",
        "Suzan Verberne",
        "Fatih Turkmen"
      ],
      "abstract": "While recent research increasingly showcases the remarkable capabilities of\nLarge Language Models (LLMs), it is equally crucial to examine their associated\nrisks. Among these, privacy and security vulnerabilities are particularly\nconcerning, posing significant ethical and legal challenges. At the heart of\nthese vulnerabilities stands memorization, which refers to a model's tendency\nto store and reproduce phrases from its training data. This phenomenon has been\nshown to be a fundamental source to various privacy and security attacks\nagainst LLMs. In this paper, we provide a taxonomy of the literature on LLM\nmemorization, exploring it across three dimensions: granularity,\nretrievability, and desirability. Next, we discuss the metrics and methods used\nto quantify memorization, followed by an analysis of the causes and factors\nthat contribute to memorization phenomenon. We then explore strategies that are\nused so far to mitigate the undesirable aspects of this phenomenon. We conclude\nour survey by identifying potential research topics for the near future,\nincluding methods to balance privacy and performance, and the analysis of\nmemorization in specific LLM contexts such as conversational agents,\nretrieval-augmented generation, and diffusion language models. Given the rapid\nresearch pace in this field, we also maintain a dedicated repository of the\nreferences discussed in this survey which will be regularly updated to reflect\nthe latest developments.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)中不良记忆化(memorization)的风险，将其分类为粒度(granularity)、可检索性(retrievability)和可取性(desirability)三个维度，并分析了其作为隐私和安全攻击主要来源的机制。论文总结了量化记忆化的指标和方法、导致这一现象的原因（如训练数据影响），以及现有的缓解策略，如数据处理和模型调整技术。最终，它提出了未来研究方向，包括平衡隐私与性能、在对话代理(conversational agents)和检索增强生成(retrieval-augmented generation)等领域中的记忆化分析，并维护了一个定期更新的参考仓库。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02650v2",
      "published_date": "2024-10-03 16:34:46 UTC",
      "updated_date": "2025-03-19 18:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:40:34.797143"
    },
    {
      "arxiv_id": "2410.02644v3",
      "title": "Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents",
      "title_zh": "Agent Security Bench (ASB)：在基于LLM的代理中形式化与基准测试攻击和防御",
      "authors": [
        "Hanrong Zhang",
        "Jingyuan Huang",
        "Kai Mei",
        "Yifei Yao",
        "Zhenting Wang",
        "Chenlu Zhan",
        "Hongwei Wang",
        "Yongfeng Zhang"
      ],
      "abstract": "Although LLM-based agents, powered by Large Language Models (LLMs), can use\nexternal tools and memory mechanisms to solve complex real-world tasks, they\nmay also introduce critical security vulnerabilities. However, the existing\nliterature does not comprehensively evaluate attacks and defenses against\nLLM-based agents. To address this, we introduce Agent Security Bench (ASB), a\ncomprehensive framework designed to formalize, benchmark, and evaluate the\nattacks and defenses of LLM-based agents, including 10 scenarios (e.g.,\ne-commerce, autonomous driving, finance), 10 agents targeting the scenarios,\nover 400 tools, 27 different types of attack/defense methods, and 7 evaluation\nmetrics. Based on ASB, we benchmark 10 prompt injection attacks, a memory\npoisoning attack, a novel Plan-of-Thought backdoor attack, 4 mixed attacks, and\n11 corresponding defenses across 13 LLM backbones. Our benchmark results reveal\ncritical vulnerabilities in different stages of agent operation, including\nsystem prompt, user prompt handling, tool usage, and memory retrieval, with the\nhighest average attack success rate of 84.30\\%, but limited effectiveness shown\nin current defenses, unveiling important works to be done in terms of agent\nsecurity for the community. We also introduce a new metric to evaluate the\nagents' capability to balance utility and security. Our code can be found at\nhttps://github.com/agiresearch/ASB.",
      "tldr_zh": "该研究引入了Agent Security Bench (ASB)，一个全面框架，用于形式化、基准测试和评估基于大型语言模型(LLM-based agents)的攻击和防御方法，涵盖10个场景（如电子商务、自动驾驶和金融）、10个针对性代理、超过400个工具、27种攻击/防御类型以及7个评估指标。研究基于ASB基准测试了10种提示注入攻击、一种内存中毒攻击、一种新颖的Plan-of-Thought后门攻击、4种混合攻击和11种防御，涉及13个LLM骨干，结果显示代理在系统提示、用户提示处理、工具使用和内存检索等阶段存在严重漏洞，平均攻击成功率高达84.30%，而当前防御效果有限。论文还提出一个新指标来评估代理在实用性和安全性之间的平衡，并提供了开源代码以推动社区研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02644v3",
      "published_date": "2024-10-03 16:30:47 UTC",
      "updated_date": "2025-04-16 09:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:40:45.931949"
    },
    {
      "arxiv_id": "2410.02637v2",
      "title": "Plots Unlock Time-Series Understanding in Multimodal Models",
      "title_zh": "图表解锁多模态模型中的时间序列理解",
      "authors": [
        "Mayank Daswani",
        "Mathias M. J. Bellaiche",
        "Marc Wilson",
        "Desislav Ivanov",
        "Mikhail Papkov",
        "Eva Schnider",
        "Jing Tang",
        "Kay Lamerigts",
        "Gabriela Botea",
        "Michael A. Sanchez",
        "Yojan Patel",
        "Shruthi Prabhakara",
        "Shravya Shetty",
        "Umesh Telang"
      ],
      "abstract": "While multimodal foundation models can now natively work with data beyond\ntext, they remain underutilized in analyzing the considerable amounts of\nmulti-dimensional time-series data in fields like healthcare, finance, and\nsocial sciences, representing a missed opportunity for richer, data-driven\ninsights. This paper proposes a simple but effective method that leverages the\nexisting vision encoders of these models to \"see\" time-series data via plots,\navoiding the need for additional, potentially costly, model training. Our\nempirical evaluations show that this approach outperforms providing the raw\ntime-series data as text, with the additional benefit that visual time-series\nrepresentations demonstrate up to a 90% reduction in model API costs. We\nvalidate our hypothesis through synthetic data tasks of increasing complexity,\nprogressing from simple functional form identification on clean data, to\nextracting trends from noisy scatter plots. To demonstrate generalizability\nfrom synthetic tasks with clear reasoning steps to more complex, real-world\nscenarios, we apply our approach to consumer health tasks - specifically fall\ndetection, activity recognition, and readiness assessment - which involve\nheterogeneous, noisy data and multi-step reasoning. The overall success in plot\nperformance over text performance (up to an 120% performance increase on\nzero-shot synthetic tasks, and up to 150% performance increase on real-world\ntasks), across both GPT and Gemini model families, highlights our approach's\npotential for making the best use of the native capabilities of foundation\nmodels.",
      "tldr_zh": "本研究提出了一种简单有效的方法，利用多模态模型的现有视觉编码器，通过图表（plots）来处理多维时间序列数据（如医疗、金融和社会科学领域），避免了额外模型训练的需求。相比于将原始时间序列数据作为文本输入，该方法显著提高了模型性能，同时降低了 API 成本高达 90%。实验通过从简单合成任务（如功能形式识别和从噪声散点图提取趋势）到真实世界任务（如跌倒检测、活动识别和准备度评估）的逐步验证，证明了其在 GPT 和 Gemini 模型家族中的优越性，性能提升高达 120%（零样本合成任务）和 150%（真实任务）。这一方法充分挖掘了基础模型的原生能力，为更丰富的多模态数据分析提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "57 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02637v2",
      "published_date": "2024-10-03 16:23:13 UTC",
      "updated_date": "2024-11-28 16:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:40:57.304224"
    },
    {
      "arxiv_id": "2410.03781v2",
      "title": "Towards the Pedagogical Steering of Large Language Models for Tutoring: A Case Study with Modeling Productive Failure",
      "title_zh": "翻译失败",
      "authors": [
        "Romain Puech",
        "Jakub Macina",
        "Julia Chatain",
        "Mrinmaya Sachan",
        "Manu Kapur"
      ],
      "abstract": "One-to-one tutoring is one of the most efficient methods of teaching. With\nthe growing popularity of Large Language Models (LLMs), there have been efforts\nto create LLM based conversational tutors which can expand the benefits of one\nto one tutoring to everyone. However, current LLMs are trained primarily to be\nhelpful assistants and lack crucial pedagogical skills. For example, they often\nquickly reveal the solution to the student and fail to plan for a richer multi\nturn pedagogical interaction. To use LLMs in pedagogical settings, they need to\nbe steered to use effective teaching strategies: a problem we introduce as\nPedagogical Steering. We develop StratL, an algorithm to optimize LLM prompts\nand steer it to follow a predefined multi-turn tutoring plan represented as a\ntransition graph. As a case study, we create a prototype tutor for high school\nmath following Productive Failure (PF), an advanced and effective learning\ndesign. To validate our approach in a real-world setting, we run a field study\nwith 17 high school students in Singapore and show that StratL succeeds in\nsteering the LLM to follow the PF tutoring strategy. Finally, we highlight\nchallenges in Pedagogical Steering of LLMs and offer opportunities for further\nimprovements by publishing a dataset of PF problems and our code.",
      "tldr_zh": "该论文探讨了如何引导 Large Language Models (LLMs) 作为一对一辅导工具的问题，强调 LLMs 缺乏教学策略，如快速揭示答案。研究引入了 Pedagogical Steering 概念，并开发了 StratL 算法，通过优化 LLM 提示和使用过渡图来实现预定义的多轮辅导计划。作为案例研究，他们创建了一个基于 Productive Failure (PF) 的高中数学辅导原型，并在新加坡与 17 名高中生的实地实验中验证，StratL 成功引导 LLM 遵循 PF 策略。最终，论文发布了 PF 问题数据集和代码，以突出挑战并推动进一步改进。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.MA",
        "97",
        "I.2; H.5; J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, 10 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.03781v2",
      "published_date": "2024-10-03 16:15:41 UTC",
      "updated_date": "2025-03-18 19:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:41:10.172173"
    },
    {
      "arxiv_id": "2410.02628v2",
      "title": "Inverse Entropic Optimal Transport Solves Semi-supervised Learning via Data Likelihood Maximization",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Persiianov",
        "Arip Asadulaev",
        "Nikita Andreev",
        "Nikita Starodubcev",
        "Dmitry Baranchuk",
        "Anastasis Kratsios",
        "Evgeny Burnaev",
        "Alexander Korotin"
      ],
      "abstract": "Learning conditional distributions $\\pi^*(\\cdot|x)$ is a central problem in\nmachine learning, which is typically approached via supervised methods with\npaired data $(x,y) \\sim \\pi^*$. However, acquiring paired data samples is often\nchallenging, especially in problems such as domain translation. This\nnecessitates the development of $\\textit{semi-supervised}$ models that utilize\nboth limited paired data and additional unpaired i.i.d. samples $x \\sim\n\\pi^*_x$ and $y \\sim \\pi^*_y$ from the marginal distributions. The usage of\nsuch combined data is complex and often relies on heuristic approaches. To\ntackle this issue, we propose a new learning paradigm that integrates both\npaired and unpaired data $\\textbf{seamlessly}$ through the data likelihood\nmaximization techniques. We demonstrate that our approach also connects\nintriguingly with inverse entropic optimal transport (OT). This finding allows\nus to apply recent advances in computational OT to establish a $\\textbf{light}$\nlearning algorithm to get $\\pi^*(\\cdot|x)$. Furthermore, we demonstrate through\nempirical tests that our method effectively learns conditional distributions\nusing paired and unpaired data simultaneously.",
      "tldr_zh": "本研究解决机器学习中学习条件分布 π*(·|x) 的问题，通常依赖配对数据，但获取困难，因此提出一种半监督学习方法，通过数据似然最大化（Data Likelihood Maximization）无缝整合有限配对数据和未配对样本。方法与 Inverse Entropic Optimal Transport 建立联系，利用计算最优传输（OT）的最新进展，开发了一个轻量级算法来估计 π*(·|x)。实证实验证明，该方法能有效同时利用配对和未配对数据，成功学习条件分布。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02628v2",
      "published_date": "2024-10-03 16:12:59 UTC",
      "updated_date": "2025-02-03 13:45:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:41:21.639886"
    },
    {
      "arxiv_id": "2410.02618v1",
      "title": "Achieving Fairness in Predictive Process Analytics via Adversarial Learning (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Massimiliano de Leoni",
        "Alessandro Padella"
      ],
      "abstract": "Predictive business process analytics has become important for organizations,\noffering real-time operational support for their processes. However, these\nalgorithms often perform unfair predictions because they are based on biased\nvariables (e.g., gender or nationality), namely variables embodying\ndiscrimination. This paper addresses the challenge of integrating a debiasing\nphase into predictive business process analytics to ensure that predictions are\nnot influenced by biased variables. Our framework leverages on adversial\ndebiasing is evaluated on four case studies, showing a significant reduction in\nthe contribution of biased variables to the predicted value. The proposed\ntechnique is also compared with the state of the art in fairness in process\nmining, illustrating that our framework allows for a more enhanced level of\nfairness, while retaining a better prediction quality.",
      "tldr_zh": "本研究针对预测性业务过程分析（predictive process analytics）中存在的偏见问题（如基于性别或国籍的变量），提出了一种通过对抗学习（adversarial learning）整合去偏置（debiasing）阶段的框架，以确保预测结果不受偏见变量影响。该框架在四个案例研究中进行了评估，显著降低了偏见变量对预测值的贡献，同时在保持较高预测质量的前提下，实现了比现有过程挖掘公平性技术更高级别的公平性。通过这种方法，论文为构建更公正的业务过程分析系统提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "J.1"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02618v1",
      "published_date": "2024-10-03 15:56:03 UTC",
      "updated_date": "2024-10-03 15:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:41:33.375982"
    },
    {
      "arxiv_id": "2410.02613v1",
      "title": "NL-Eye: Abductive NLI for Images",
      "title_zh": "翻译失败",
      "authors": [
        "Mor Ventura",
        "Michael Toker",
        "Nitay Calderon",
        "Zorik Gekhman",
        "Yonatan Bitton",
        "Roi Reichart"
      ],
      "abstract": "Will a Visual Language Model (VLM)-based bot warn us about slipping if it\ndetects a wet floor? Recent VLMs have demonstrated impressive capabilities, yet\ntheir ability to infer outcomes and causes remains underexplored. To address\nthis, we introduce NL-Eye, a benchmark designed to assess VLMs' visual\nabductive reasoning skills. NL-Eye adapts the abductive Natural Language\nInference (NLI) task to the visual domain, requiring models to evaluate the\nplausibility of hypothesis images based on a premise image and explain their\ndecisions. NL-Eye consists of 350 carefully curated triplet examples (1,050\nimages) spanning diverse reasoning categories: physical, functional, logical,\nemotional, cultural, and social. The data curation process involved two steps -\nwriting textual descriptions and generating images using text-to-image models,\nboth requiring substantial human involvement to ensure high-quality and\nchallenging scenes. Our experiments show that VLMs struggle significantly on\nNL-Eye, often performing at random baseline levels, while humans excel in both\nplausibility prediction and explanation quality. This demonstrates a deficiency\nin the abductive reasoning capabilities of modern VLMs. NL-Eye represents a\ncrucial step toward developing VLMs capable of robust multimodal reasoning for\nreal-world applications, including accident-prevention bots and generated video\nverification.",
      "tldr_zh": "本文引入 NL-Eye 基准，用于评估 Visual Language Model (VLMs) 的视觉演绎推理能力，通过将 Abductive NLI 任务适应到图像领域，要求模型基于前提图像评估假设图像的合理性并提供解释。数据集包含 350 个精心策划的三元组示例（共 1050 张图像），覆盖物理、功能、逻辑、情感、文化和社会等推理类别，并通过人类参与确保高质量。实验结果显示 VLMs 在 NL-Eye 上表现接近随机基线，而人类表现出色，这暴露了现代 VLMs 在多模态推理方面的显著不足。NL-Eye 为开发更可靠的 VLMs 提供了关键工具，适用于现实应用如事故预防机器人和生成视频验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02613v1",
      "published_date": "2024-10-03 15:51:36 UTC",
      "updated_date": "2024-10-03 15:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:41:46.311940"
    },
    {
      "arxiv_id": "2410.02611v1",
      "title": "IndicSentEval: How Effectively do Multilingual Transformer Models encode Linguistic Properties for Indic Languages?",
      "title_zh": "IndicSentEval：多语言 Transformer 模型如何有效地编码印地语系语言的语言学属性？",
      "authors": [
        "Akhilesh Aravapalli",
        "Mounika Marreddy",
        "Subba Reddy Oota",
        "Radhika Mamidi",
        "Manish Gupta"
      ],
      "abstract": "Transformer-based models have revolutionized the field of natural language\nprocessing. To understand why they perform so well and to assess their\nreliability, several studies have focused on questions such as: Which\nlinguistic properties are encoded by these models, and to what extent? How\nrobust are these models in encoding linguistic properties when faced with\nperturbations in the input text? However, these studies have mainly focused on\nBERT and the English language. In this paper, we investigate similar questions\nregarding encoding capability and robustness for 8 linguistic properties across\n13 different perturbations in 6 Indic languages, using 9 multilingual\nTransformer models (7 universal and 2 Indic-specific). To conduct this study,\nwe introduce a novel multilingual benchmark dataset, IndicSentEval, containing\napproximately $\\sim$47K sentences. Surprisingly, our probing analysis of\nsurface, syntactic, and semantic properties reveals that while almost all\nmultilingual models demonstrate consistent encoding performance for English,\nthey show mixed results for Indic languages. As expected, Indic-specific\nmultilingual models capture linguistic properties in Indic languages better\nthan universal models. Intriguingly, universal models broadly exhibit better\nrobustness compared to Indic-specific models, particularly under perturbations\nsuch as dropping both nouns and verbs, dropping only verbs, or keeping only\nnouns. Overall, this study provides valuable insights into probing and\nperturbation-specific strengths and weaknesses of popular multilingual\nTransformer-based models for different Indic languages. We make our code and\ndataset publicly available [https://tinyurl.com/IndicSentEval}].",
      "tldr_zh": "本研究调查了9个多语言Transformer模型（包括7个通用模型和2个Indic特定模型）在编码6种Indic语言的8种语言属性（surface, syntactic, and semantic）时的表现和鲁棒性，涉及13种输入文本扰动。研究者引入了一个新数据集IndicSentEval，包含约47K句子，用于评估这些模型的编码能力。结果显示，模型在英语上表现出一致性，但在Indic语言上表现参差不齐，Indic-specific模型在Indic语言的属性捕捉上优于通用模型，而通用模型在诸如删除名词和动词等扰动下显示出更好的鲁棒性。该研究提供了对多语言Transformer模型在Indic语言中的优势和弱点的宝贵洞见，并公开了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02611v1",
      "published_date": "2024-10-03 15:50:08 UTC",
      "updated_date": "2024-10-03 15:50:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:41:57.051079"
    },
    {
      "arxiv_id": "2410.02605v2",
      "title": "A Prospect-Theoretic Policy Gradient Algorithm for Behavioral Alignment in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Olivier Lepel",
        "Anas Barakat"
      ],
      "abstract": "Classical reinforcement learning (RL) typically assumes rational\ndecision-making based on expected utility theory. However, this model has been\nshown to be empirically inconsistent with actual human preferences, as\nevidenced in psychology and behavioral economics. Cumulative Prospect Theory\n(CPT) provides a more nuanced model for human-based decision-making, capturing\ndiverse attitudes and perceptions toward risk, gains, and losses. While prior\nwork has integrated CPT with RL to solve a CPT policy optimization problem, the\nunderstanding and practical impact of this formulation remain limited. We\nrevisit the CPT-RL framework, offering new theoretical insights into the nature\nof optimal policies. We further derive a novel policy gradient theorem for CPT\nobjectives, generalizing the foundational result in standard RL. Building on\nthis theorem, we design a model-free policy gradient algorithm for solving the\nCPT-RL problem and demonstrate its performance through simulations. Notably,\nour algorithm scales better to larger state spaces compared to existing\nzeroth-order methods. This work advances the integration of behavioral\ndecision-making into RL.",
      "tldr_zh": "本文研究了如何将累积前景理论（CPT）整合到强化学习（RL）中，以解决经典 RL 基于期望效用理论的理性决策假设与实际人类偏好不一致的问题。作者重新审视了 CPT-RL 框架，提供新的理论洞见，并推导了一个新的政策梯度定理，用于优化 CPT 目标，从而推广了标准 RL 的基础结果。基于此，他们设计了一个无模型的政策梯度算法，并通过模拟实验证明其性能，该算法在较大状态空间中比现有零阶方法扩展性更强。该工作推动了行为决策理论在 RL 中的应用，提升了算法对人类行为的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "revised version",
      "pdf_url": "http://arxiv.org/pdf/2410.02605v2",
      "published_date": "2024-10-03 15:45:39 UTC",
      "updated_date": "2025-02-26 20:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:42:11.075654"
    },
    {
      "arxiv_id": "2410.02596v1",
      "title": "Beyond Squared Error: Exploring Loss Design for Enhanced Training of Generative Flow Networks",
      "title_zh": "超越平方误差：探索损失设计以增强生成流网络的训练",
      "authors": [
        "Rui Hu",
        "Yifan Zhang",
        "Zhuoran Li",
        "Longbo Huang"
      ],
      "abstract": "Generative Flow Networks (GFlowNets) are a novel class of generative models\ndesigned to sample from unnormalized distributions and have found applications\nin various important tasks, attracting great research interest in their\ntraining algorithms. In general, GFlowNets are trained by fitting the forward\nflow to the backward flow on sampled training objects. Prior work focused on\nthe choice of training objects, parameterizations, sampling and resampling\nstrategies, and backward policies, aiming to enhance credit assignment,\nexploration, or exploitation of the training process. However, the choice of\nregression loss, which can highly influence the exploration and exploitation\nbehavior of the under-training policy, has been overlooked. Due to the lack of\ntheoretical understanding for choosing an appropriate regression loss, most\nexisting algorithms train the flow network by minimizing the squared error of\nthe forward and backward flows in log-space, i.e., using the quadratic\nregression loss. In this work, we rigorously prove that distinct regression\nlosses correspond to specific divergence measures, enabling us to design and\nanalyze regression losses according to the desired properties of the\ncorresponding divergence measures. Specifically, we examine two key properties:\nzero-forcing and zero-avoiding, where the former promotes exploitation and\nhigher rewards, and the latter encourages exploration and enhances diversity.\nBased on our theoretical framework, we propose three novel regression losses,\nnamely, Shifted-Cosh, Linex(1/2), and Linex(1). We evaluate them across three\nbenchmarks: hyper-grid, bit-sequence generation, and molecule generation. Our\nproposed losses are compatible with most existing training algorithms, and\nsignificantly improve the performances of the algorithms concerning convergence\nspeed, sample diversity, and robustness.",
      "tldr_zh": "本文研究了 Generative Flow Networks (GFlowNets) 的训练问题，强调回归损失设计的重要性，以优化模型的探索和利用行为。作者证明不同回归损失对应特定的散度度量，并基于零-forcing（促进利用和更高奖励）和 zero-avoiding（鼓励探索和多样性）属性，提出了三种新损失：Shifted-Cosh、Linex(1/2) 和 Linex(1)。实验在 hyper-grid、bit-sequence generation 和 molecule generation 等基准上显示，这些损失显著提升了现有算法的收敛速度、样本多样性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02596v1",
      "published_date": "2024-10-03 15:37:22 UTC",
      "updated_date": "2024-10-03 15:37:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:42:22.199891"
    },
    {
      "arxiv_id": "2410.02592v4",
      "title": "IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Fang",
        "Zheng Lin",
        "Senkang Hu",
        "Hangcheng Cao",
        "Yiqin Deng",
        "Xianhao Chen",
        "Yuguang Fang"
      ],
      "abstract": "Recently, in-car monitoring has emerged as a promising technology for\ndetecting early-stage abnormal status of the driver and providing timely alerts\nto prevent traffic accidents. Although training models with multimodal data\nenhances the reliability of abnormal status detection, the scarcity of labeled\ndata and the imbalance of class distribution impede the extraction of critical\nabnormal state features, significantly deteriorating training performance.\nFurthermore, missing modalities due to environment and hardware limitations\nfurther exacerbate the challenge of abnormal status identification. More\nimportantly, monitoring abnormal health conditions of passengers, particularly\nin elderly care, is of paramount importance but remains underexplored. To\naddress these challenges, we introduce our IC3M, an efficient\ncamera-rotation-based multimodal framework for monitoring both driver and\npassengers in a car. Our IC3M comprises two key modules: an adaptive threshold\npseudo-labeling strategy and a missing modality reconstruction. The former\ncustomizes pseudo-labeling thresholds for different classes based on the class\ndistribution, generating class-balanced pseudo labels to guide model training\neffectively, while the latter leverages crossmodality relationships learned\nfrom limited labels to accurately recover missing modalities by distribution\ntransferring from available modalities. Extensive experimental results\ndemonstrate that IC3M outperforms state-of-the-art benchmarks in accuracy,\nprecision, and recall while exhibiting superior robustness under limited\nlabeled data and severe missing modality.",
      "tldr_zh": "该研究提出 IC3M 框架，一种基于摄像头旋转的多模态系统，用于车内监控驾驶员和乘客的异常状态，以预防交通事故。IC3M 包括两个关键模块：自适应阈值伪-labeling 策略，根据类别分布自定义阈值生成平衡的伪标签，以缓解标注数据稀缺和类别不平衡问题；以及 missing modality reconstruction 模块，通过利用跨模态关系从可用模态转移分布来恢复缺失模态。实验结果显示，IC3M 在准确率、精确率和召回率上优于现有基准模型，并在有限标注数据和严重缺失模态情况下表现出卓越的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02592v4",
      "published_date": "2024-10-03 15:34:41 UTC",
      "updated_date": "2024-11-21 07:16:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:42:33.679971"
    },
    {
      "arxiv_id": "2410.02581v3",
      "title": "Boosting Sample Efficiency and Generalization in Multi-agent Reinforcement Learning via Equivariance",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua McClellan",
        "Naveed Haghani",
        "John Winder",
        "Furong Huang",
        "Pratap Tokekar"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) struggles with sample inefficiency\nand poor generalization [1]. These challenges are partially due to a lack of\nstructure or inductive bias in the neural networks typically used in learning\nthe policy. One such form of structure that is commonly observed in multi-agent\nscenarios is symmetry. The field of Geometric Deep Learning has developed\nEquivariant Graph Neural Networks (EGNN) that are equivariant (or symmetric) to\nrotations, translations, and reflections of nodes. Incorporating equivariance\nhas been shown to improve learning efficiency and decrease error [ 2 ]. In this\npaper, we demonstrate that EGNNs improve the sample efficiency and\ngeneralization in MARL. However, we also show that a naive application of EGNNs\nto MARL results in poor early exploration due to a bias in the EGNN structure.\nTo mitigate this bias, we present Exploration-enhanced Equivariant Graph Neural\nNetworks or E2GN2. We compare E2GN2 to other common function approximators\nusing common MARL benchmarks MPE and SMACv2. E2GN2 demonstrates a significant\nimprovement in sample efficiency, greater final reward convergence, and a 2x-5x\ngain in over standard GNNs in our generalization tests. These results pave the\nway for more reliable and effective solutions in complex multi-agent systems.",
      "tldr_zh": "该论文针对多智能体强化学习（MARL）的样本效率低和泛化能力差问题，提出使用Equivariant Graph Neural Networks (EGNN)来引入对旋转、平移和反射的等变性结构，从而提升学习效率和减少错误。作者发现直接应用EGNN会导致早期探索偏差，因此开发了Exploration-enhanced Equivariant Graph Neural Networks (E2GN2)来缓解这一问题。在MARL基准测试MPE和SMACv2上，E2GN2相较标准GNNs实现了显著改善，包括更高的样本效率、更好的最终奖励收敛，以及在泛化测试中2x-5x的性能提升，为复杂多智能体系统的可靠解决方案提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted as a poster at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02581v3",
      "published_date": "2024-10-03 15:25:37 UTC",
      "updated_date": "2024-10-22 16:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:42:45.844299"
    },
    {
      "arxiv_id": "2410.02579v1",
      "title": "Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuwei Xing",
        "Derek W. Cool",
        "David Tessier",
        "Elvis C. S. Chen",
        "Terry M. Peters",
        "Aaron Fenster"
      ],
      "abstract": "Liver tumor ablation procedures require accurate placement of the needle\napplicator at the tumor centroid. The lower-cost and real-time nature of\nultrasound (US) has advantages over computed tomography (CT) for applicator\nguidance, however, in some patients, liver tumors may be occult on US and tumor\nmimics can make lesion identification challenging. Image registration\ntechniques can aid in interpreting anatomical details and identifying tumors,\nbut their clinical application has been hindered by the tradeoff between\nalignment accuracy and runtime performance, particularly when compensating for\nliver motion due to patient breathing or movement. Therefore, we propose a\n2D-3D US registration approach to enable intra-procedural alignment that\nmitigates errors caused by liver motion. Specifically, our approach can\ncorrelate imbalanced 2D and 3D US image features and use continuous 6D rotation\nrepresentations to enhance the model's training stability. The dataset was\ndivided into 2388, 196 and 193 image pairs for training, validation and\ntesting, respectively. Our approach achieved a mean Euclidean distance error of\n2.28 mm $\\pm$ 1.81 mm and a mean geodesic angular error of 2.99$^{\\circ}$ $\\pm$\n1.95$^{\\circ}$, with a runtime of 0.22 seconds per 2D-3D US image pair. These\nresults demonstrate that our approach can achieve accurate alignment and\nclinically acceptable runtime, indicating potential for clinical translation.",
      "tldr_zh": "该论文提出了一种Deep Regression 2D-3D Ultrasound Registration方法，用于肝肿瘤热消融手术中校正肝脏运动，从而提高针头放置的准确性。该方法通过关联不平衡的2D和3D US图像特征，并采用连续6D旋转表示来提升模型训练稳定性和配准性能。在实验中，使用2388对训练图像等数据集，该方法实现了平均Euclidean distance error为2.28 mm ± 1.81 mm和平均geodesic angular error为2.99° ± 1.95°，运行时间仅为0.22秒每对图像。这些结果表明，该方法在准确性和实时性上均表现出色，具有临床翻译潜力。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "15 pagers, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02579v1",
      "published_date": "2024-10-03 15:24:45 UTC",
      "updated_date": "2024-10-03 15:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:42:58.507948"
    },
    {
      "arxiv_id": "2410.03779v1",
      "title": "Discovering Message Passing Hierarchies for Mesh-Based Physics Simulation",
      "title_zh": "发现用于基于网格物理模拟的消息传递层次结构",
      "authors": [
        "Huayu Deng",
        "Xiangming Zhu",
        "Yunbo Wang",
        "Xiaokang Yang"
      ],
      "abstract": "Graph neural networks have emerged as a powerful tool for large-scale\nmesh-based physics simulation. Existing approaches primarily employ\nhierarchical, multi-scale message passing to capture long-range dependencies\nwithin the graph. However, these graph hierarchies are typically fixed and\nmanually designed, which do not adapt to the evolving dynamics present in\ncomplex physical systems. In this paper, we introduce a novel neural network\nnamed DHMP, which learns Dynamic Hierarchies for Message Passing networks\nthrough a differentiable node selection method. The key component is the\nanisotropic message passing mechanism, which operates at both intra-level and\ninter-level interactions. Unlike existing methods, it first supports\ndirectionally non-uniform aggregation of dynamic features between adjacent\nnodes within each graph hierarchy. Second, it determines node selection\nprobabilities for the next hierarchy according to different physical contexts,\nthereby creating more flexible message shortcuts for learning remote node\nrelations. Our experiments demonstrate the effectiveness of DHMP, achieving\n22.7% improvement on average compared to recent fixed-hierarchy message passing\nnetworks across five classic physics simulation datasets.",
      "tldr_zh": "该论文针对网格-based物理模拟中的图神经网络(Graph Neural Networks)问题，提出DHMP模型，通过可微分节点选择方法学习动态层次的消息传递，以适应复杂物理系统的演变动态。DHMP的关键创新是各向异性消息传递机制，支持层内(intra-level)方向非均匀特征聚合，以及层间(inter-level)根据物理上下文动态确定节点选择概率，从而创建灵活的消息捷径。实验结果显示，在五个经典物理模拟数据集上，DHMP比现有固定层次消息传递网络平均提高了22.7%的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03779v1",
      "published_date": "2024-10-03 15:18:00 UTC",
      "updated_date": "2024-10-03 15:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:43:09.654481"
    },
    {
      "arxiv_id": "2410.02551v2",
      "title": "ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration",
      "title_zh": "ColaCare：通过大语言模型驱动的多智能体协作增强电子健康记录建模",
      "authors": [
        "Zixiang Wang",
        "Yinghao Zhu",
        "Huiya Zhao",
        "Xiaochen Zheng",
        "Dehao Sui",
        "Tianlong Wang",
        "Wen Tang",
        "Yasha Wang",
        "Ewen Harrison",
        "Chengwei Pan",
        "Junyi Gao",
        "Liantao Ma"
      ],
      "abstract": "We introduce ColaCare, a framework that enhances Electronic Health Record\n(EHR) modeling through multi-agent collaboration driven by Large Language\nModels (LLMs). Our approach seamlessly integrates domain-specific expert models\nwith LLMs to bridge the gap between structured EHR data and text-based\nreasoning. Inspired by the Multidisciplinary Team (MDT) approach used in\nclinical settings, ColaCare employs two types of agents: DoctorAgents and a\nMetaAgent, which collaboratively analyze patient data. Expert models process\nand generate predictions from numerical EHR data, while LLM agents produce\nreasoning references and decision-making reports within the MDT-driven\ncollaborative consultation framework. The MetaAgent orchestrates the\ndiscussion, facilitating consultations and evidence-based debates among\nDoctorAgents, simulating diverse expertise in clinical decision-making. We\nadditionally incorporate the Merck Manual of Diagnosis and Therapy (MSD)\nmedical guideline within a retrieval-augmented generation (RAG) module for\nmedical evidence support, addressing the challenge of knowledge currency.\nExtensive experiments conducted on three EHR datasets demonstrate ColaCare's\nsuperior performance in clinical mortality outcome and readmission prediction\ntasks, underscoring its potential to revolutionize clinical decision support\nsystems and advance personalized precision medicine. All code, case studies and\na questionnaire are available at the project website:\nhttps://colacare.netlify.app.",
      "tldr_zh": "我们介绍了 ColaCare 框架，这是一种通过大型语言模型 (LLMs) 驱动的多智能体协作来增强电子健康记录 (EHR) 建模的方法，旨在弥合结构化 EHR 数据与文本推理之间的差距。框架模拟临床多学科团队 (MDT) 模式，包含 DoctorAgents 用于处理数字数据并生成预测，以及 MetaAgent 负责协调讨论和证据-based 辩论，同时整合检索增强生成 (RAG) 模块以引用 Merck Manual of Diagnosis and Therapy (MSD) 作为医疗证据支持。在三个 EHR 数据集上的实验显示，ColaCare 在临床死亡率和再入院预测任务中表现出色，性能优于基线模型，从而为临床决策支持系统和个性化精准医学带来革命性潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM TheWebConf 2025 Conference (WWW 2025) Research Track",
      "pdf_url": "http://arxiv.org/pdf/2410.02551v2",
      "published_date": "2024-10-03 14:55:22 UTC",
      "updated_date": "2025-02-26 13:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:43:22.041794"
    },
    {
      "arxiv_id": "2410.02547v1",
      "title": "Personalized Quantum Federated Learning for Privacy Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Jinjing Shi",
        "Tian Chen",
        "Shichao Zhang",
        "Xuelong Li"
      ],
      "abstract": "Quantum federated learning has brought about the improvement of privacy image\nclassification, while the lack of personality of the client model may\ncontribute to the suboptimal of quantum federated learning. A personalized\nquantum federated learning algorithm for privacy image classification is\nproposed to enhance the personality of the client model in the case of an\nimbalanced distribution of images. First, a personalized quantum federated\nlearning model is constructed, in which a personalized layer is set for the\nclient model to maintain the personalized parameters. Second, a personalized\nquantum federated learning algorithm is introduced to secure the information\nexchanged between the client and server.Third, the personalized federated\nlearning is applied to image classification on the FashionMNIST dataset, and\nthe experimental results indicate that the personalized quantum federated\nlearning algorithm can obtain global and local models with excellent\nperformance, even in situations where local training samples are imbalanced.\nThe server's accuracy is 100% with 8 clients and a distribution parameter of\n100, outperforming the non-personalized model by 7%. The average client\naccuracy is 2.9% higher than that of the non-personalized model with 2 clients\nand a distribution parameter of 1. Compared to previous quantum federated\nlearning algorithms, the proposed personalized quantum federated learning\nalgorithm eliminates the need for additional local training while safeguarding\nboth model and data privacy.It may facilitate broader adoption and application\nof quantum technologies, and pave the way for more secure, scalable, and\nefficient quantum distribute machine learning solutions.",
      "tldr_zh": "本研究提出了一种个性化的量子联邦学习（Personalized Quantum Federated Learning）算法，旨在解决传统量子联邦学习中客户端模型缺乏个性化导致的性能次优问题，尤其适用于图像分布不平衡的隐私图像分类场景。该算法通过构建包含个性化层的客户端模型来维护个性化参数，并引入安全机制保护客户端与服务器之间的信息交换。在FashionMNIST数据集上的实验表明，该算法使服务器准确率达到100%（在8个客户端和分布参数100时，比非个性化模型高7%），客户端平均准确率提高2.9%（在2个客户端和分布参数1时），且无需额外本地训练，同时保障模型和数据隐私，有望推动量子分布式机器学习的应用。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02547v1",
      "published_date": "2024-10-03 14:53:04 UTC",
      "updated_date": "2024-10-03 14:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:43:34.361598"
    },
    {
      "arxiv_id": "2410.02845v1",
      "title": "Towards Layer-Wise Personalized Federated Learning: Adaptive Layer Disentanglement via Conflicting Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Duong Nguyen",
        "Khanh Le",
        "Khoi Do",
        "Nguyen H. Tran",
        "Duc Nguyen",
        "Chien Trinh",
        "Zhaohui Yang"
      ],
      "abstract": "In personalized Federated Learning (pFL), high data heterogeneity can cause\nsignificant gradient divergence across devices, adversely affecting the\nlearning process. This divergence, especially when gradients from different\nusers form an obtuse angle during aggregation, can negate progress, leading to\nsevere weight and gradient update degradation. To address this issue, we\nintroduce a new approach to pFL design, namely Federated Learning with\nLayer-wise Aggregation via Gradient Analysis (FedLAG), utilizing the concept of\ngradient conflict at the layer level. Specifically, when layer-wise gradients\nof different clients form acute angles, those gradients align in the same\ndirection, enabling updates across different clients toward identifying\nclient-invariant features. Conversely, when layer-wise gradient pairs make\ncreate obtuse angles, the layers tend to focus on client-specific tasks. In\nhindsights, FedLAG assigns layers for personalization based on the extent of\nlayer-wise gradient conflicts. Specifically, layers with gradient conflicts are\nexcluded from the global aggregation process. The theoretical evaluation\ndemonstrates that when integrated into other pFL baselines, FedLAG enhances pFL\nperformance by a certain margin. Therefore, our proposed method achieves\nsuperior convergence behavior compared with other baselines. Extensive\nexperiments show that our FedLAG outperforms several state-of-the-art methods\nand can be easily incorporated with many existing methods to further enhance\nperformance.",
      "tldr_zh": "这篇论文针对个性化联邦学习(pFL)中数据异质性导致的梯度分歧问题，提出了一种新方法Federated Learning with Layer-wise Aggregation via Gradient Analysis (FedLAG)。FedLAG通过分析层级梯度冲突——锐角梯度用于识别客户端不变特征，而钝角梯度则专注于客户端特定任务——来自适应地排除冲突层，从而优化全局聚合过程。理论评估显示，FedLAG能提升pFL的收敛性能，并在广泛实验中优于现有基准方法，并易于与其他方法整合。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02845v1",
      "published_date": "2024-10-03 14:46:19 UTC",
      "updated_date": "2024-10-03 14:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:43:46.573872"
    },
    {
      "arxiv_id": "2410.02536v3",
      "title": "Intelligence at the Edge of Chaos",
      "title_zh": "混沌边缘的智能",
      "authors": [
        "Shiyang Zhang",
        "Aakash Patel",
        "Syed A Rizvi",
        "Nianchen Liu",
        "Sizhuang He",
        "Amin Karbasi",
        "Emanuele Zappala",
        "David van Dijk"
      ],
      "abstract": "We explore the emergence of intelligent behavior in artificial systems by\ninvestigating how the complexity of rule-based systems influences the\ncapabilities of models trained to predict these rules. Our study focuses on\nelementary cellular automata (ECA), simple yet powerful one-dimensional systems\nthat generate behaviors ranging from trivial to highly complex. By training\ndistinct Large Language Models (LLMs) on different ECAs, we evaluated the\nrelationship between the complexity of the rules' behavior and the intelligence\nexhibited by the LLMs, as reflected in their performance on downstream tasks.\nOur findings reveal that rules with higher complexity lead to models exhibiting\ngreater intelligence, as demonstrated by their performance on reasoning and\nchess move prediction tasks. Both uniform and periodic systems, and often also\nhighly chaotic systems, resulted in poorer downstream performance, highlighting\na sweet spot of complexity conducive to intelligence. We conjecture that\nintelligence arises from the ability to predict complexity and that creating\nintelligence may require only exposure to complexity.",
      "tldr_zh": "本文研究了规则系统复杂性如何影响训练模型预测这些规则，从而引发人工智能行为的出现，焦点是Elementary Cellular Automata (ECA)这种简单一维系统。研究者训练不同的Large Language Models (LLMs)来预测各种ECA规则，并评估这些模型在下游任务（如推理和国际象棋走子预测）中的表现。结果显示，规则复杂性较高的ECA导致LLMs表现出更高的智能，而统一、周期性或高度混沌系统则导致表现较差。作者推测，智能源于预测复杂性的能力，仅需暴露于适当的复杂性即可培养智能。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages,8 Figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02536v3",
      "published_date": "2024-10-03 14:42:34 UTC",
      "updated_date": "2025-03-01 13:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:43:57.767578"
    },
    {
      "arxiv_id": "2410.02533v2",
      "title": "A Schema-aware Logic Reformulation for Graph Reachability",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Di Pierro",
        "Stephan Mennicke",
        "Stefano Ferilli"
      ],
      "abstract": "Graph reachability is the task of understanding whether two distinct points\nin a graph are interconnected by arcs to which in general a semantic is\nattached. Reachability has plenty of applications, ranging from motion planning\nto routing. Improving reachability requires structural knowledge of relations\nso as to avoid the complexity of traditional depth-first and breadth-first\nstrategies, implemented in logic languages. In some contexts, graphs are\nenriched with their schema definitions establishing domain and range for every\narc. The introduction of a schema-aware formalization for guiding the search\nmay result in a sensitive improvement by cutting out unuseful paths and\nprioritising those that, in principle, reach the target earlier. In this work,\nwe propose a strategy to automatically exclude and sort certain graph paths by\nexploiting the higher-level conceptualization of instances. The aim is to\nobtain a new first-order logic reformulation of the graph reachability\nscenario, capable of improving the traditional algorithms in terms of time,\nspace requirements, and number of backtracks. The experiments exhibit the\nexpected advantages of the approach in reducing the number of backtracks during\nthe search strategy, resulting in saving time and space as well.",
      "tldr_zh": "该论文针对图可达性（Graph Reachability）问题，提出了一种基于图 schema 定义的逻辑改革定（Schema-aware Logic Reformulation）策略，以优化传统深度优先和广度优先搜索算法。方法通过利用 schema 中的域和范围信息，自动排除无用路径并优先排序潜在有效路径，从而生成新的第一-order logic 改革定，提升搜索效率。实验结果显示，该方法显著减少了回溯次数（backtracks），从而节省了时间和空间资源，为应用如运动规划和路由提供了改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02533v2",
      "published_date": "2024-10-03 14:39:49 UTC",
      "updated_date": "2025-03-25 11:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:44:09.785735"
    },
    {
      "arxiv_id": "2410.02525v4",
      "title": "Contextual Document Embeddings",
      "title_zh": "上下文化的文档嵌入",
      "authors": [
        "John X. Morris",
        "Alexander M. Rush"
      ],
      "abstract": "Dense document embeddings are central to neural retrieval. The dominant\nparadigm is to train and construct embeddings by running encoders directly on\nindividual documents. In this work, we argue that these embeddings, while\neffective, are implicitly out-of-context for targeted use cases of retrieval,\nand that a contextualized document embedding should take into account both the\ndocument and neighboring documents in context - analogous to contextualized\nword embeddings. We propose two complementary methods for contextualized\ndocument embeddings: first, an alternative contrastive learning objective that\nexplicitly incorporates the document neighbors into the intra-batch contextual\nloss; second, a new contextual architecture that explicitly encodes neighbor\ndocument information into the encoded representation. Results show that both\nmethods achieve better performance than biencoders in several settings, with\ndifferences especially pronounced out-of-domain. We achieve state-of-the-art\nresults on the MTEB benchmark with no hard negative mining, score distillation,\ndataset-specific instructions, intra-GPU example-sharing, or extremely large\nbatch sizes. Our method can be applied to improve performance on any\ncontrastive learning dataset and any biencoder.",
      "tldr_zh": "本研究指出，传统的密集文档嵌入(dense document embeddings)通过直接在单个文档上运行编码器来构建，但这会导致嵌入脱离上下文，无法适应检索等目标用例。作者提出两种互补方法：一是修改对比学习目标，将文档邻居显式纳入批内上下文损失；二是设计新架构来显式编码邻居文档信息。这些方法在多个设置中优于双编码器(biencoders)，尤其在域外场景中表现突出，并在 MTEB 基准上实现了最先进的结果，而无需硬负样本挖掘或其他复杂技巧。该方法可广泛应用于任何对比学习数据集和双编码器，以提升性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02525v4",
      "published_date": "2024-10-03 14:33:34 UTC",
      "updated_date": "2024-11-08 16:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:44:22.438681"
    },
    {
      "arxiv_id": "2410.02512v1",
      "title": "SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation",
      "title_zh": "翻译失败",
      "authors": [
        "Mucong Ding",
        "Bang An",
        "Yuancheng Xu",
        "Anirudh Satheesh",
        "Furong Huang"
      ],
      "abstract": "Data augmentation, a cornerstone technique in deep learning, is crucial in\nenhancing model performance, especially with scarce labeled data. While\ntraditional techniques are effective, their reliance on hand-crafted methods\nlimits their applicability across diverse data types and tasks. Although modern\nlearnable augmentation methods offer increased adaptability, they are\ncomputationally expensive and challenging to incorporate within prevalent\naugmentation workflows. In this work, we present a novel, efficient method for\ndata augmentation, effectively bridging the gap between existing augmentation\nstrategies and emerging datasets and learning tasks. We introduce SAFLEX\n(Self-Adaptive Augmentation via Feature Label EXtrapolation), which learns the\nsample weights and soft labels of augmented samples provided by any given\nupstream augmentation pipeline, using a specifically designed efficient bilevel\noptimization algorithm. Remarkably, SAFLEX effectively reduces the noise and\nlabel errors of the upstream augmentation pipeline with a marginal\ncomputational cost. As a versatile module, SAFLEX excels across diverse\ndatasets, including natural and medical images and tabular data, showcasing its\nprowess in few-shot learning and out-of-distribution generalization. SAFLEX\nseamlessly integrates with common augmentation strategies like RandAug, CutMix,\nand those from large pre-trained generative models like stable diffusion and is\nalso compatible with frameworks such as CLIP's fine-tuning. Our findings\nhighlight the potential to adapt existing augmentation pipelines for new data\ntypes and tasks, signaling a move towards more adaptable and resilient training\nframeworks.",
      "tldr_zh": "本研究提出 SAFLEX（Self-Adaptive Augmentation via Feature Label Extrapolation），一种高效的数据增强方法，旨在解决传统手工增强策略的局限性和现代可学习方法的计算开销问题。SAFLEX 通过一个专门设计的双层优化算法，学习上游增强管道的样本权重和软标签，从而减少噪声和标签错误，并与现有策略如 RandAug、CutMix 和 Stable Diffusion 等无缝整合。实验结果显示，SAFLEX 在自然图像、医疗图像和表格数据等多种数据集上表现出色，提升了少样本学习和分布外泛化性能，推动了更具适应性的训练框架发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02512v1",
      "published_date": "2024-10-03 14:21:49 UTC",
      "updated_date": "2024-10-03 14:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:44:33.298896"
    },
    {
      "arxiv_id": "2410.02511v1",
      "title": "Choices are More Important than Efforts: LLM Enables Efficient Multi-Agent Exploration",
      "title_zh": "选择比努力更重要：LLM 实现高效多智能体探索",
      "authors": [
        "Yun Qu",
        "Boyuan Wang",
        "Yuhang Jiang",
        "Jianzhun Shao",
        "Yixiu Mao",
        "Cheems Wang",
        "Chang Liu",
        "Xiangyang Ji"
      ],
      "abstract": "With expansive state-action spaces, efficient multi-agent exploration remains\na longstanding challenge in reinforcement learning. Although pursuing novelty,\ndiversity, or uncertainty attracts increasing attention, redundant efforts\nbrought by exploration without proper guidance choices poses a practical issue\nfor the community. This paper introduces a systematic approach, termed LEMAE,\nchoosing to channel informative task-relevant guidance from a knowledgeable\nLarge Language Model (LLM) for Efficient Multi-Agent Exploration. Specifically,\nwe ground linguistic knowledge from LLM into symbolic key states, that are\ncritical for task fulfillment, in a discriminative manner at low LLM inference\ncosts. To unleash the power of key states, we design Subspace-based Hindsight\nIntrinsic Reward (SHIR) to guide agents toward key states by increasing reward\ndensity. Additionally, we build the Key State Memory Tree (KSMT) to track\ntransitions between key states in a specific task for organized exploration.\nBenefiting from diminishing redundant explorations, LEMAE outperforms existing\nSOTA approaches on the challenging benchmarks (e.g., SMAC and MPE) by a large\nmargin, achieving a 10x acceleration in certain scenarios.",
      "tldr_zh": "本文提出 LEMAE 方法，利用大型语言模型 (LLM) 提供任务相关指导，以解决多智能体强化学习中冗余探索的问题，从而提升探索效率。具体而言，LEMAE 通过从 LLM 提取关键状态 (symbolic key states)，设计 Subspace-based Hindsight Intrinsic Reward (SHIR) 来增加奖励密度引导代理，以及构建 Key State Memory Tree (KSMT) 来跟踪关键状态转换，实现有组织探索。实验结果显示，该方法在 SMAC 和 MPE 等基准上大幅优于现有最先进方法，在某些场景下实现 10 倍加速。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02511v1",
      "published_date": "2024-10-03 14:21:23 UTC",
      "updated_date": "2024-10-03 14:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:44:45.689836"
    },
    {
      "arxiv_id": "2410.02507v1",
      "title": "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Weikang Yuan",
        "Junjie Cao",
        "Zhuoren Jiang",
        "Yangyang Kang",
        "Jun Lin",
        "Kaisong Song",
        "tianqianjin lin",
        "Pengwei Yan",
        "Changlong Sun",
        "Xiaozhong Liu"
      ],
      "abstract": "Large Language Models (LLMs) could struggle to fully understand legal\ntheories and perform complex legal reasoning tasks. In this study, we introduce\na challenging task (confusing charge prediction) to better evaluate LLMs'\nunderstanding of legal theories and reasoning capabilities. We also propose a\nnovel framework: Multi-Agent framework for improving complex Legal Reasoning\ncapability (MALR). MALR employs non-parametric learning, encouraging LLMs to\nautomatically decompose complex legal tasks and mimic human learning process to\nextract insights from legal rules, helping LLMs better understand legal\ntheories and enhance their legal reasoning abilities. Extensive experiments on\nmultiple real-world datasets demonstrate that the proposed framework\neffectively addresses complex reasoning issues in practical scenarios, paving\nthe way for more reliable applications in the legal domain.",
      "tldr_zh": "本文研究 Large Language Models (LLMs) 在理解法律理论和进行复杂法律推理方面的挑战，引入了一个新的评估任务：confusing charge prediction，以测试 LLMs 的法律理解和推理能力。作者提出 Multi-Agent framework for improving complex Legal Reasoning capability (MALR)，该框架利用 non-parametric learning 让 LLMs 自动分解复杂法律任务、模仿人类学习过程从法律规则中提取洞见，从而提升法律理论理解和推理性能。在多个真实世界数据集上的广泛实验表明，MALR 框架有效地解决了复杂推理问题，为法律领域的可靠应用提供了重要基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02507v1",
      "published_date": "2024-10-03 14:15:00 UTC",
      "updated_date": "2024-10-03 14:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:44:57.900613"
    },
    {
      "arxiv_id": "2410.02505v2",
      "title": "Dog-IQA: Standard-guided Zero-shot MLLM for Mix-grained Image Quality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Liu",
        "Ziqing Zhang",
        "Wenbo Li",
        "Renjing Pei",
        "Fenglong Song",
        "Xiaohong Liu",
        "Linghe Kong",
        "Yulun Zhang"
      ],
      "abstract": "Image quality assessment (IQA) serves as the golden standard for all models'\nperformance in nearly all computer vision fields. However, it still suffers\nfrom poor out-of-distribution generalization ability and expensive training\ncosts. To address these problems, we propose Dog-IQA, a standard-guided\nzero-shot mix-grained IQA method, which is training-free and utilizes the\nexceptional prior knowledge of multimodal large language models (MLLMs). To\nobtain accurate IQA scores, namely scores consistent with humans, we design an\nMLLM-based inference pipeline that imitates human experts. In detail, Dog-IQA\napplies two techniques. First, Dog-IQA objectively scores with specific\nstandards that utilize MLLM's behavior pattern and minimize the influence of\nsubjective factors. Second, Dog-IQA comprehensively takes local semantic\nobjects and the whole image as input and aggregates their scores, leveraging\nlocal and global information. Our proposed Dog-IQA achieves state-of-the-art\n(SOTA) performance compared with training-free methods, and competitive\nperformance compared with training-based methods in cross-dataset scenarios.\nOur code will be available at https://github.com/Kai-Liu001/Dog-IQA.",
      "tldr_zh": "该研究提出 Dog-IQA，一种基于标准引导的零-shot 多模态大语言模型 (MLLMs) 方法，用于混合粒度图像质量评估 (IQA)，旨在解决现有 IQA 模型的泛化能力差和训练成本高的问题。Dog-IQA 通过模仿人类专家的推理管道，实现客观评分：利用 MLLMs 的行为模式减少主观影响，并聚合局部语义对象和整体图像的信息。实验结果显示，Dog-IQA 在无训练方法中达到最先进 (SOTA) 性能，并在跨数据集场景中与训练方法竞争表现相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures. The code and models will be available at\n  https://github.com/Kai-Liu001/Dog-IQA",
      "pdf_url": "http://arxiv.org/pdf/2410.02505v2",
      "published_date": "2024-10-03 14:14:21 UTC",
      "updated_date": "2024-10-10 05:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:45:12.886682"
    },
    {
      "arxiv_id": "2410.02503v1",
      "title": "Mixed-Session Conversation with Egocentric Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Jihyoung Jang",
        "Taeyoung Kim",
        "Hyounghun Kim"
      ],
      "abstract": "Recently introduced dialogue systems have demonstrated high usability.\nHowever, they still fall short of reflecting real-world conversation scenarios.\nCurrent dialogue systems exhibit an inability to replicate the dynamic,\ncontinuous, long-term interactions involving multiple partners. This shortfall\narises because there have been limited efforts to account for both aspects of\nreal-world dialogues: deeply layered interactions over the long-term dialogue\nand widely expanded conversation networks involving multiple participants. As\nthe effort to incorporate these aspects combined, we introduce Mixed-Session\nConversation, a dialogue system designed to construct conversations with\nvarious partners in a multi-session dialogue setup. We propose a new dataset\ncalled MiSC to implement this system. The dialogue episodes of MiSC consist of\n6 consecutive sessions, with four speakers (one main speaker and three\npartners) appearing in each episode. Also, we propose a new dialogue model with\na novel memory management mechanism, called Egocentric Memory Enhanced\nMixed-Session Conversation Agent (EMMA). EMMA collects and retains memories\nfrom the main speaker's perspective during conversations with partners,\nenabling seamless continuity in subsequent interactions. Extensive human\nevaluations validate that the dialogues in MiSC demonstrate a seamless\nconversational flow, even when conversation partners change in each session.\nEMMA trained with MiSC is also evaluated to maintain high memorability without\ncontradiction throughout the entire conversation.",
      "tldr_zh": "本文研究了当前对话系统的局限性，即无法处理动态的多会话和多参与者互动，提出了一种名为 Mixed-Session Conversation 的对话系统，以模拟真实世界的对话场景。作者构建了新数据集 MiSC，由 6 个连续会话组成，每个会话涉及一个主要说话者和三个伙伴，旨在支持广泛的对话网络。针对此系统，他们开发了 Egocentric Memory Enhanced Mixed-Session Conversation Agent (EMMA) 模型，该模型通过从主要说话者视角收集和保留记忆，实现对话的连续性和无缝切换。人类评估结果表明，MiSC 和 EMMA 能保持高记忆性、无矛盾的对话流，即使参与者发生变化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Findings 2024 (30 pages); Project website:\n  https://mixed-session.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.02503v1",
      "published_date": "2024-10-03 14:06:43 UTC",
      "updated_date": "2024-10-03 14:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:45:21.920571"
    },
    {
      "arxiv_id": "2410.02844v3",
      "title": "CAnDOIT: Causal Discovery with Observational and Interventional Data from Time-Series",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Castri",
        "Sariah Mghames",
        "Marc Hanheide",
        "Nicola Bellotto"
      ],
      "abstract": "The study of cause-and-effect is of the utmost importance in many branches of\nscience, but also for many practical applications of intelligent systems. In\nparticular, identifying causal relationships in situations that include hidden\nfactors is a major challenge for methods that rely solely on observational data\nfor building causal models. This paper proposes CAnDOIT, a causal discovery\nmethod to reconstruct causal models using both observational and interventional\ntime-series data. The use of interventional data in the causal analysis is\ncrucial for real-world applications, such as robotics, where the scenario is\nhighly complex and observational data alone are often insufficient to uncover\nthe correct causal structure. Validation of the method is performed initially\non randomly generated synthetic models and subsequently on a well-known\nbenchmark for causal structure learning in a robotic manipulation environment.\nThe experiments demonstrate that the approach can effectively handle data from\ninterventions and exploit them to enhance the accuracy of the causal analysis.\nA Python implementation of CAnDOIT has also been developed and is publicly\navailable on GitHub: https://github.com/lcastri/causalflow.",
      "tldr_zh": "这篇论文提出了 CAnDOIT，一种因果发现方法，用于利用观察数据和干预数据从时间序列中重建因果模型，尤其针对存在隐藏因素的复杂场景，如机器人学应用。CAnDOIT 通过整合干预数据来弥补观察数据不足的问题，提高了因果结构的准确性。实验在随机生成的合成模型和机器人操作基准上验证了其有效性，并提供了开源 Python 实现（GitHub: https://github.com/lcastri/causalflow）。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "stat.ML",
      "comment": "Published in Advanced Intelligent Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.02844v3",
      "published_date": "2024-10-03 13:57:08 UTC",
      "updated_date": "2024-10-11 09:48:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:45:33.128799"
    },
    {
      "arxiv_id": "2410.02843v1",
      "title": "Neural DDEs with Learnable Delays for Partially Observed Dynamical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Thibault Monsel",
        "Emmanuel Menier",
        "Onofrio Semeraro",
        "Lionel Mathelin",
        "Guillaume Charpiat"
      ],
      "abstract": "Many successful methods to learn dynamical systems from data have recently\nbeen introduced. Such methods often rely on the availability of the system's\nfull state. However, this underlying hypothesis is rather restrictive as it is\ntypically not confirmed in practice, leaving us with partially observed\nsystems. Utilizing the Mori-Zwanzig (MZ) formalism from statistical physics, we\ndemonstrate that Constant Lag Neural Delay Differential Equations (NDDEs)\nnaturally serve as suitable models for partially observed states. In empirical\nevaluation, we show that such models outperform existing methods on both\nsynthetic and experimental data.",
      "tldr_zh": "本论文针对部分观察动态系统的问题，提出了一种基于Neural DDEs with Learnable Delays的模型，特别是Constant Lag Neural Delay Differential Equations (NDDEs)，利用Mori-Zwanzig (MZ) 形式主义来处理系统状态不完整的情况。该方法证明NDDEs能有效建模部分观察数据，并通过学习延迟参数提升系统预测准确性。在合成和实验数据上的实证评估中，该模型优于现有方法，展示了其在动态系统学习中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02843v1",
      "published_date": "2024-10-03 13:54:21 UTC",
      "updated_date": "2024-10-03 13:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:45:44.522738"
    },
    {
      "arxiv_id": "2410.02472v3",
      "title": "Meta-Models: An Architecture for Decoding LLM Behaviors Through Interpreted Embeddings and Natural Language",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Costarelli",
        "Mat Allen",
        "Severin Field"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly integrated into our daily\nlives, the potential harms from deceptive behavior underlie the need for\nfaithfully interpreting their decision-making. While traditional probing\nmethods have shown some effectiveness, they remain best for narrowly scoped\ntasks while more comprehensive explanations are still necessary. To this end,\nwe investigate meta-models-an architecture using a \"meta-model\" that takes\nactivations from an \"input-model\" and answers natural language questions about\nthe input-model's behaviors. We evaluate the meta-model's ability to generalize\nby training them on selected task types and assessing their out-of-distribution\nperformance in deceptive scenarios. Our findings show that meta-models\ngeneralize well to out-of-distribution tasks and point towards opportunities\nfor future research in this area. Our code is available at\nhttps://github.com/acostarelli/meta-models-public .",
      "tldr_zh": "本研究提出 meta-models 架构，用于通过解释 embeddings 和自然语言来解读 Large Language Models (LLMs) 的决策行为，特别是针对潜在欺骗性风险。meta-models 作为一个辅助模型，分析 input-model 的激活并回答自然语言问题，从而提供更全面的解释。实验结果显示，meta-models 在训练任务之外的分布外场景中泛化良好，尤其在欺骗性任务上表现出色，为未来 LLM 解释研究开辟了机会。代码已开源，可在 GitHub 上获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02472v3",
      "published_date": "2024-10-03 13:25:15 UTC",
      "updated_date": "2024-11-07 18:30:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:45:56.922092"
    },
    {
      "arxiv_id": "2410.02465v2",
      "title": "Revealing the Inherent Instructability of Pre-Trained Language Models",
      "title_zh": "揭示预训练语言模型的固有指令能力",
      "authors": [
        "Seokhyun An",
        "Minji Kim",
        "Hyounghun Kim"
      ],
      "abstract": "Instruction tuning -- supervised fine-tuning using instruction-response pairs\n-- is a key step in making pre-trained large language models (LLMs)\ninstructable. Meanwhile, LLMs perform multitask learning during their\npre-training, acquiring extensive knowledge and capabilities. We hypothesize\nthat the pre-training stage can enable them to develop the ability to\ncomprehend and address instructions. To verify this, we propose Response Tuning\n(RT), which removes the instruction and its corresponding mapping to the\nresponse from instruction tuning. Instead, it focuses solely on establishing\nthe response distribution. Our experiments demonstrate that RT models, trained\nonly on responses, can effectively respond to a wide range of instructions and\nexhibit helpfulness approaching that of their instruction-tuned counterparts.\nIn addition, we observe that the models can recognize and reject unsafe queries\nafter learning the refusal conditions from training responses. Furthermore, we\ndemonstrate that these observations also hold in an in-context learning\nsetting. These findings support our hypothesis, highlighting the extensive\ninherent capabilities of pre-trained LLMs.",
      "tldr_zh": "该研究假设预训练的大型语言模型 (LLMs) 在多任务预训练阶段已具备理解和处理指令的能力，无需完整的指令调优。研究者提出 Response Tuning (RT) 方法，仅针对响应分布进行训练，而非使用指令-响应对。实验结果显示，RT 模型能有效响应各种指令，其帮助性接近指令调优模型，并能从训练响应中学习拒绝不安全查询。进一步验证表明，这些能力也适用于 in-context learning 设置，支持了预训练 LLMs 的内在指令潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02465v2",
      "published_date": "2024-10-03 13:15:19 UTC",
      "updated_date": "2025-02-16 13:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:46:08.935850"
    },
    {
      "arxiv_id": "2410.02456v1",
      "title": "Recurrent Few-Shot model for Document Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Talarmain",
        "Carlos Boned",
        "Sanket Biswas",
        "Oriol Ramos"
      ],
      "abstract": "General-purpose ID, or travel, document image- and video-based verification\nsystems have yet to achieve good enough performance to be considered a solved\nproblem. There are several factors that negatively impact their performance,\nincluding low-resolution images and videos and a lack of sufficient data to\ntrain the models. This task is particularly challenging when dealing with\nunseen class of ID, or travel, documents. In this paper we address this task by\nproposing a recurrent-based model able to detect forged documents in a few-shot\nscenario. The recurrent architecture makes the model robust to document\nresolution variability. Moreover, the few-shot approach allow the model to\nperform well even for unseen class of documents. Preliminary results on the\nSIDTD and Findit datasets show good performance of this model for this task.",
      "tldr_zh": "这篇论文针对身份证和旅行证件图像及视频验证系统的性能问题，提出了一种基于Recurrent架构的Few-Shot模型，用于检测伪造证件。该模型通过循环神经网络设计，提升了对图像分辨率变化的鲁棒性，并利用Few-Shot学习方法，使其能够有效处理未见过类别的证件。在SIDTD和Findit数据集上的初步实验结果显示，该模型表现出色，证明了其在实际应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02456v1",
      "published_date": "2024-10-03 13:05:27 UTC",
      "updated_date": "2024-10-03 13:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:46:20.921700"
    },
    {
      "arxiv_id": "2410.02451v2",
      "title": "Strong Preferences Affect the Robustness of Preference Models and Value Alignment",
      "title_zh": "强偏好影响偏好模型和价值对齐的鲁棒性",
      "authors": [
        "Ziwei Xu",
        "Mohan Kankanhalli"
      ],
      "abstract": "Value alignment, which aims to ensure that large language models (LLMs) and\nother AI agents behave in accordance with human values, is critical for\nensuring safety and trustworthiness of these systems. A key component of value\nalignment is the modeling of human preferences as a representation of human\nvalues. In this paper, we investigate the robustness of value alignment by\nexamining the sensitivity of preference models. Specifically, we ask: how do\nchanges in the probabilities of some preferences affect the predictions of\nthese models for other preferences? To answer this question, we theoretically\nanalyze the robustness of widely used preference models by examining their\nsensitivities to minor changes in preferences they model. Our findings reveal\nthat, in the Bradley-Terry and the Placket-Luce model, the probability of a\npreference can change significantly as other preferences change, especially\nwhen these preferences are dominant (i.e., with probabilities near 0 or 1). We\nidentify specific conditions where this sensitivity becomes significant for\nthese models and discuss the practical implications for the robustness and\nsafety of value alignment in AI systems.",
      "tldr_zh": "该研究探讨了强势偏好对偏好模型鲁棒性和价值 alignment 的影响，强调在确保 AI 系统如大型语言模型 (LLMs) 符合人类价值观时，模型敏感性的重要性。通过理论分析 Bradley-Terry 和 Placket-Luce 模型，论文揭示了当某些偏好概率发生微小变化时，尤其是这些偏好为主导（概率接近 0 或 1）时，其他偏好的预测会显著变动。结果表明，这种敏感性可能削弱价值 alignment 的可靠性，并为 AI 系统的安全性和可信任性提供了关键启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 Pages. Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02451v2",
      "published_date": "2024-10-03 12:53:43 UTC",
      "updated_date": "2025-03-08 04:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:46:33.703772"
    },
    {
      "arxiv_id": "2410.02443v1",
      "title": "Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Julia Alekseenko",
        "Bram Stieltjes",
        "Michael Bach",
        "Melanie Boerries",
        "Oliver Opitz",
        "Alexandros Karargyris",
        "Nicolas Padoy"
      ],
      "abstract": "Clinnova, a collaborative initiative involving France, Germany, Switzerland,\nand Luxembourg, is dedicated to unlocking the power of precision medicine\nthrough data federation, standardization, and interoperability. This European\nGreater Region initiative seeks to create an interoperable European standard\nusing artificial intelligence (AI) and data science to enhance healthcare\noutcomes and efficiency. Key components include multidisciplinary research\ncenters, a federated biobanking strategy, a digital health innovation platform,\nand a federated AI strategy. It targets inflammatory bowel disease, rheumatoid\ndiseases, and multiple sclerosis (MS), emphasizing data quality to develop AI\nalgorithms for personalized treatment and translational research.\n  The IHU Strasbourg (Institute of Minimal-invasive Surgery) has the lead in\nthis initiative to develop the federated learning (FL) proof of concept (POC)\nthat will serve as a foundation for advancing AI in healthcare. At its core,\nClinnova-MS aims to enhance MS patient care by using FL to develop more\naccurate models that detect disease progression, guide interventions, and\nvalidate digital biomarkers across multiple sites. This technical report\npresents insights and key takeaways from the first cross-border federated POC\non MS segmentation of MRI images within the Clinnova framework. While our work\nmarks a significant milestone in advancing MS segmentation through cross-border\ncollaboration, it also underscores the importance of addressing technical,\nlogistical, and ethical considerations to realize the full potential of FL in\nhealthcare settings.",
      "tldr_zh": "Clinnova项目是一个涉及法国、德国、瑞士和卢森堡的跨国合作，旨在通过数据联邦、标准化和互操作性，利用人工智能（AI）和数据科学推动精准医学发展，重点针对炎症性肠病、风湿病和多发性硬化症（MS）。该项目包括多学科研究中心、联邦生物银行策略、数字健康创新平台和联邦AI策略，IHU Strasbourg领导了联邦学习（FL）的概念验证（POC），专注于使用FL开发更准确的模型来检测MS疾病进展、指导干预并验证数字生物标志物。实验结果显示，该POC在MS MRI图像分割上取得了重要里程碑，但也强调了需解决技术、后勤和伦理挑战，以充分发挥FL在医疗领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02443v1",
      "published_date": "2024-10-03 12:40:52 UTC",
      "updated_date": "2024-10-03 12:40:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:46:45.620687"
    },
    {
      "arxiv_id": "2410.02440v1",
      "title": "Optimizing Adaptive Attacks against Content Watermarks for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulrahman Diaa",
        "Toluwani Aremu",
        "Nils Lukas"
      ],
      "abstract": "Large Language Models (LLMs) can be \\emph{misused} to spread online spam and\nmisinformation. Content watermarking deters misuse by hiding a message in\nmodel-generated outputs, enabling their detection using a secret watermarking\nkey. Robustness is a core security property, stating that evading detection\nrequires (significant) degradation of the content's quality. Many LLM\nwatermarking methods have been proposed, but robustness is tested only against\n\\emph{non-adaptive} attackers who lack knowledge of the watermarking method and\ncan find only suboptimal attacks. We formulate the robustness of LLM\nwatermarking as an objective function and propose preference-based optimization\nto tune \\emph{adaptive} attacks against the specific watermarking method. Our\nevaluation shows that (i) adaptive attacks substantially outperform\nnon-adaptive baselines. (ii) Even in a non-adaptive setting, adaptive attacks\noptimized against a few known watermarks remain highly effective when tested\nagainst other unseen watermarks, and (iii) optimization-based attacks are\npractical and require less than seven GPU hours. Our findings underscore the\nneed to test robustness against adaptive attackers.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)的内容水印(Content Watermarking)方法，提出了一种优化自适应攻击的框架，将鲁棒性表述为目标函数，并使用基于偏好的优化技术来调整攻击策略，以针对特定水印方法进行更有效的 evasion。研究发现，自适应攻击显著优于非自适应基线，且即使针对少数已知水印优化，攻击也能在未知水印上保持高效果，同时仅需不到七个GPU小时即可实现。总体而言，该工作强调了测试LLM水印对自适应攻击者的鲁棒性的必要性，以提升防范模型滥用的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02440v1",
      "published_date": "2024-10-03 12:37:39 UTC",
      "updated_date": "2024-10-03 12:37:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:46:58.562477"
    },
    {
      "arxiv_id": "2410.02430v1",
      "title": "Predictive Attractor Models",
      "title_zh": "预测吸引子模型",
      "authors": [
        "Ramy Mounir",
        "Sudeep Sarkar"
      ],
      "abstract": "Sequential memory, the ability to form and accurately recall a sequence of\nevents or stimuli in the correct order, is a fundamental prerequisite for\nbiological and artificial intelligence as it underpins numerous cognitive\nfunctions (e.g., language comprehension, planning, episodic memory formation,\netc.) However, existing methods of sequential memory suffer from catastrophic\nforgetting, limited capacity, slow iterative learning procedures, low-order\nMarkov memory, and, most importantly, the inability to represent and generate\nmultiple valid future possibilities stemming from the same context. Inspired by\nbiologically plausible neuroscience theories of cognition, we propose\n\\textit{Predictive Attractor Models (PAM)}, a novel sequence memory\narchitecture with desirable generative properties. PAM is a streaming model\nthat learns a sequence in an online, continuous manner by observing each input\n\\textit{only once}. Additionally, we find that PAM avoids catastrophic\nforgetting by uniquely representing past context through lateral inhibition in\ncortical minicolumns, which prevents new memories from overwriting previously\nlearned knowledge. PAM generates future predictions by sampling from a union\nset of predicted possibilities; this generative ability is realized through an\nattractor model trained alongside the predictor. We show that PAM is trained\nwith local computations through Hebbian plasticity rules in a biologically\nplausible framework. Other desirable traits (e.g., noise tolerance, CPU-based\nlearning, capacity scaling) are discussed throughout the paper. Our findings\nsuggest that PAM represents a significant step forward in the pursuit of\nbiologically plausible and computationally efficient sequential memory models,\nwith broad implications for cognitive science and artificial intelligence\nresearch.",
      "tldr_zh": "本论文提出Predictive Attractor Models (PAM)，一种新型顺序记忆架构，旨在解决现有模型的灾难性遗忘(catastrophic forgetting)、容量有限和无法生成多个未来可能性的问题。PAM作为一种流式(streaming)模型，通过在线连续观察每个输入一次，并利用皮层微柱的横向抑制(lateral inhibition)来唯一表示过去上下文，从而避免新记忆覆盖旧知识。该模型结合吸引子模型(attractor model)和Hebbian plasticity rules进行训练，实现从预测可能性集合中采样生成未来序列，并展示出噪声耐受性、CPU-based学习和容量可扩展等优势。总体而言，PAM代表了生物学合理和计算高效的顺序记忆进展，对认知科学和人工智能研究具有重要影响。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02430v1",
      "published_date": "2024-10-03 12:25:01 UTC",
      "updated_date": "2024-10-03 12:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:47:10.231733"
    },
    {
      "arxiv_id": "2410.02429v2",
      "title": "IoT-LLM: Enhancing Real-World IoT Task Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tuo An",
        "Yunjiao Zhou",
        "Han Zou",
        "Jianfei Yang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ntextual and visual domains but often generate outputs that violate physical\nlaws, revealing a gap in their understanding of the physical world. Inspired by\nhuman cognition, where perception is fundamental to reasoning, we explore\naugmenting LLMs with enhanced perception abilities using Internet of Things\n(IoT) sensor data and pertinent knowledge for IoT task reasoning in the\nphysical world. In this work, we systematically study LLMs capability to\naddress real-world IoT tasks by augmenting their perception and knowledge base,\nand then propose a unified framework, IoT-LLM, to enhance such capability. In\nIoT-LLM, we customize three steps for LLMs: preprocessing IoT data into formats\namenable to LLMs, activating their commonsense knowledge through\nchain-of-thought prompting and specialized role definitions, and expanding\ntheir understanding via IoT-oriented retrieval-augmented generation based on\nin-context learning. To evaluate the performance, We design a new benchmark\nwith five real-world IoT tasks with different data types and reasoning\ndifficulties and provide the benchmarking results on six open-source and\nclose-source LLMs. Experimental results demonstrate the limitations of existing\nLLMs with naive textual inputs that cannot perform these tasks effectively. We\nshow that IoT-LLM significantly enhances the performance of IoT tasks reasoning\nof LLM, such as GPT-4, achieving an average improvement of 65% across various\ntasks against previous methods. The results also showcase LLMs ability to\ncomprehend IoT data and the physical law behind data by providing a reasoning\nprocess. Limitations of our work are claimed to inspire future research in this\nnew era.",
      "tldr_zh": "该研究发现，大型语言模型（LLMs）在处理真实世界物联网（IoT）任务时，常因忽略物理规律而表现不足，因此提出IoT-LLM框架，通过IoT传感器数据和相关知识增强LLMs的感知能力。IoT-LLM包括三个关键步骤：预处理IoT数据以适应LLMs输入、利用chain-of-thought提示和角色定义激活常识知识，以及通过IoT导向的retrieval-augmented generation扩展理解。实验在设计的新基准上测试了五种真实IoT任务，结果显示IoT-LLM显著提升LLMs性能，例如GPT-4在各种任务中平均改善65%，并展示了LLMs理解IoT数据和物理规律的能力，为未来研究提供启发。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 10 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2410.02429v2",
      "published_date": "2024-10-03 12:24:18 UTC",
      "updated_date": "2024-10-04 03:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:47:21.623259"
    },
    {
      "arxiv_id": "2410.02428v1",
      "title": "Collective Critics for Creative Story Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Minwook Bae",
        "Hyounghun Kim"
      ],
      "abstract": "Generating a long story of several thousand words with narrative coherence\nusing Large Language Models (LLMs) has been a challenging task. Previous\nresearch has addressed this challenge by proposing different frameworks that\ncreate a story plan and generate a long story based on that plan. However,\nthese frameworks have been mainly focusing on maintaining narrative coherence\nin stories, often overlooking creativity in story planning and the\nexpressiveness of the stories generated from those plans, which are desirable\nproperties to captivate readers' interest. In this paper, we propose Collective\nCritics for Creative Story Generation framework (CritiCS), which is composed of\nplan refining stage (CrPlan) and story generation stage (CrText), to integrate\na collective revision mechanism that promotes those properties into long-form\nstory generation process. Specifically, in each stage, a group of LLM critics\nand one leader collaborate to incrementally refine drafts of plan and story\nthroughout multiple rounds. Extensive human evaluation shows that the CritiCS\ncan significantly enhance story creativity and reader engagement, while also\nmaintaining narrative coherence. Furthermore, the design of the framework\nallows active participation from human writers in any role within the critique\nprocess, enabling interactive human-machine collaboration in story writing.",
      "tldr_zh": "本研究提出CritiCS框架，用于提升Large Language Models (LLMs)生成长故事的创意和读者参与度，解决传统方法忽略表现力而仅关注叙事连贯性的问题。框架包括计划精炼阶段(CrPlan)和故事生成阶段(CrText)，通过多轮协作的LLM批评者群体和领导者逐步精炼故事计划和草稿。人类评估显示，CritiCS显著提高了故事的创意和吸引力，同时保持叙事连贯性，并支持人类作家参与批评过程，实现互动的人机协作。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 (36 pages)",
      "pdf_url": "http://arxiv.org/pdf/2410.02428v1",
      "published_date": "2024-10-03 12:21:17 UTC",
      "updated_date": "2024-10-03 12:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:47:43.342567"
    },
    {
      "arxiv_id": "2410.02426v1",
      "title": "Learning the Latent Rules of a Game from Data: A Chess Story",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Fauber"
      ],
      "abstract": "We demonstrate that small pretrained foundational generative language models\nwith millions of parameters can learn the latent rules of a process from data\nassociated with the process. Inspired by Stefan Zweig's novella\n\"Schachnovelle,\" also known as \"The Royal Game\" in English, we show that 28M\nand 125M parameter pretrained foundational small language models (SLMs) can be\ninstruction fine-tuned with 1,000-to-1,000,000 examples to learn the rules of\nchess, propose legal moves, and accurately solve chess problems. We also\nexplore the impact of successive language model fine-tuning epochs on improved\noutcomes and demonstrate reductions in model hallucinations by increasing the\nnumber of instruction fine-tuning examples.",
      "tldr_zh": "本研究展示了小型预训练生成语言模型（SLMs），如28M和125M参数的模型，能够从数据中学习游戏的潜在规则，以国际象棋为例。研究者通过指令微调（instruction fine-tuning）使用1,000至1,000,000个示例训练模型，使其学会提出合法走法并准确解决棋局问题。实验结果表明，增加微调示例数量能显著减少模型幻觉（hallucinations），并通过多次微调提升整体性能，为AI学习复杂规则提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02426v1",
      "published_date": "2024-10-03 12:19:49 UTC",
      "updated_date": "2024-10-03 12:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:47:45.357728"
    },
    {
      "arxiv_id": "2410.02401v7",
      "title": "SynCo: Synthetic Hard Negatives for Contrastive Visual Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Giakoumoglou",
        "Tania Stathaki"
      ],
      "abstract": "Contrastive learning has become a dominant approach in self-supervised visual\nrepresentation learning, but efficiently leveraging hard negatives, which are\nsamples closely resembling the anchor, remains challenging. We introduce SynCo\n(Synthetic negatives in Contrastive learning), a novel approach that improves\nmodel performance by generating synthetic hard negatives on the representation\nspace. Building on the MoCo framework, SynCo introduces six strategies for\ncreating diverse synthetic hard negatives on-the-fly with minimal computational\noverhead. SynCo achieves faster training and strong representation learning,\nsurpassing MoCo-v2 by +0.4% and MoCHI by +1.0% on ImageNet ILSVRC-2012 linear\nevaluation. It also transfers more effectively to detection tasks achieving\nstrong results on PASCAL VOC detection (57.2% AP) and significantly improving\nover MoCo-v2 on COCO detection (+1.0% AP) and instance segmentation (+0.8% AP).\nOur synthetic hard negative generation approach significantly enhances visual\nrepresentations learned through self-supervised contrastive learning.",
      "tldr_zh": "该研究提出SynCo，一种用于对比学习(Contrastive learning)的创新方法，通过在表示空间生成合成hard negatives来提升自监督视觉表示学习的效果。基于MoCo框架，SynCo引入六种策略，实现在线生成多样化的合成hard negatives，同时保持最小计算开销。实验结果显示，SynCo在ImageNet ILSVRC-2012的线性评估中超越MoCo-v2 0.4%和MoCHI 1.0%，并在转移任务上表现出色，如PASCAL VOC检测达到57.2% AP，以及在COCO检测和实例分割中分别比MoCo-v2提高1.0% AP和0.8% AP。总体上，该方法显著增强了对比学习的视觉表示能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4, I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Code: https://github.com/giakoumoglou/synco, Supplementary:\n  https://giakoumoglou.com/src/synco_suppl.pdf",
      "pdf_url": "http://arxiv.org/pdf/2410.02401v7",
      "published_date": "2024-10-03 11:29:09 UTC",
      "updated_date": "2025-02-17 12:37:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:47:58.839453"
    },
    {
      "arxiv_id": "2410.02396v1",
      "title": "Parameter Competition Balancing for Model Merging",
      "title_zh": "参数竞争平衡用于模型合并",
      "authors": [
        "Guodong Du",
        "Junlin Lee",
        "Jing Li",
        "Runhua Jiang",
        "Yifei Guo",
        "Shuyang Yu",
        "Hanting Liu",
        "Sim Kuan Goh",
        "Ho-Kin Tang",
        "Daojing He",
        "Min Zhang"
      ],
      "abstract": "While fine-tuning pretrained models has become common practice, these models\noften underperform outside their specific domains. Recently developed model\nmerging techniques enable the direct integration of multiple models, each\nfine-tuned for distinct tasks, into a single model. This strategy promotes\nmultitasking capabilities without requiring retraining on the original\ndatasets. However, existing methods fall short in addressing potential\nconflicts and complex correlations between tasks, especially in parameter-level\nadjustments, posing a challenge in effectively balancing parameter competition\nacross various tasks. This paper introduces an innovative technique named\nPCB-Merging (Parameter Competition Balancing), a lightweight and training-free\ntechnique that adjusts the coefficients of each parameter for effective model\nmerging. PCB-Merging employs intra-balancing to gauge parameter significance\nwithin individual tasks and inter-balancing to assess parameter similarities\nacross different tasks. Parameters with low importance scores are dropped, and\nthe remaining ones are rescaled to form the final merged model. We assessed our\napproach in diverse merging scenarios, including cross-task, cross-domain, and\ncross-training configurations, as well as out-of-domain generalization. The\nexperimental results reveal that our approach achieves substantial performance\nenhancements across multiple modalities, domains, model sizes, number of tasks,\nfine-tuning forms, and large language models, outperforming existing model\nmerging methods. The code is publicly available at:\n\\url{https://github.com/duguodong7/pcb-merging}.",
      "tldr_zh": "这篇论文针对模型合并中的参数竞争问题，提出了一种名为 PCB-Merging 的轻量级、无需训练的技术，用于整合多个为不同任务微调的模型，实现多任务能力而不需重新训练。PCB-Merging 通过 intra-balancing 评估参数在单个任务中的重要性和 inter-balancing 评估参数在不同任务间的相似性，然后丢弃低重要性参数并重新缩放剩余参数，以有效平衡任务间的冲突。实验结果显示，该方法在跨任务、跨领域和跨训练配置等场景下显著提升性能，超越现有模型合并方法，并在多种模态、模型大小和任务数量上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02396v1",
      "published_date": "2024-10-03 11:17:58 UTC",
      "updated_date": "2024-10-03 11:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:48:09.224745"
    },
    {
      "arxiv_id": "2410.02394v1",
      "title": "Online Multi-Label Classification under Noisy and Changing Label Distribution",
      "title_zh": "在噪声和变化标签分布下的在线多标签分类",
      "authors": [
        "Yizhang Zou",
        "Xuegang Hu",
        "Peipei Li",
        "Jun Hu",
        "You Wu"
      ],
      "abstract": "Multi-label data stream usually contains noisy labels in the real-world\napplications, namely occuring in both relevant and irrelevant labels. However,\nexisting online multi-label classification methods are mostly limited in terms\nof label quality and fail to deal with the case of noisy labels. On the other\nhand, the ground-truth label distribution may vary with the time changing,\nwhich is hidden in the observed noisy label distribution and difficult to\ntrack, posing a major challenge for concept drift adaptation. Motivated by\nthis, we propose an online multi-label classification algorithm under Noisy and\nChanging Label Distribution (NCLD). The convex objective is designed to\nsimultaneously model the label scoring and the label ranking for high accuracy,\nwhose robustness to NCLD benefits from three novel works: 1) The local feature\ngraph is used to reconstruct the label scores jointly with the observed labels,\nand an unbiased ranking loss is derived and applied to learn reliable ranking\ninformation. 2) By detecting the difference between two adjacent chunks with\nthe unbiased label cardinality, we identify the change in the ground-truth\nlabel distribution and reset the ranking or all information learned from the\npast to match the new distribution. 3) Efficient and accurate updating is\nachieved based on the updating rule derived from the closed-form optimal model\nsolution. Finally, empirical experimental results validate the effectiveness of\nour method in classifying instances under NCLD.",
      "tldr_zh": "本研究针对现实中多标签数据流中的噪声标签和变化标签分布问题，提出了一种在线多-label classification 算法 NCLD，以解决现有方法的局限性。NCLD 通过设计一个凸目标函数，同时建模标签评分和标签排名，并利用局部特征图重建标签分数及无偏排名损失，实现了对可靠排名的学习和对概念 drift 的适应。算法还通过检测相邻数据块的无偏标签基数来识别真实标签分布的变化，并重置相关信息以匹配新分布，同时基于闭式最优解的更新规则确保高效准确。实验结果验证了 NCLD 在噪声和变化标签分布下的有效性，提高了分类性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02394v1",
      "published_date": "2024-10-03 11:16:43 UTC",
      "updated_date": "2024-10-03 11:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:48:21.337739"
    },
    {
      "arxiv_id": "2410.02389v1",
      "title": "Diffusion Meets Options: Hierarchical Generative Skill Composition for Temporally-Extended Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Feng",
        "Hao Luan",
        "Kevin Yuchen Ma",
        "Harold Soh"
      ],
      "abstract": "Safe and successful deployment of robots requires not only the ability to\ngenerate complex plans but also the capacity to frequently replan and correct\nexecution errors. This paper addresses the challenge of long-horizon trajectory\nplanning under temporally extended objectives in a receding horizon manner. To\nthis end, we propose DOPPLER, a data-driven hierarchical framework that\ngenerates and updates plans based on instruction specified by linear temporal\nlogic (LTL). Our method decomposes temporal tasks into chain of options with\nhierarchical reinforcement learning from offline non-expert datasets. It\nleverages diffusion models to generate options with low-level actions. We\ndevise a determinantal-guided posterior sampling technique during batch\ngeneration, which improves the speed and diversity of diffusion generated\noptions, leading to more efficient querying. Experiments on robot navigation\nand manipulation tasks demonstrate that DOPPLER can generate sequences of\ntrajectories that progressively satisfy the specified formulae for obstacle\navoidance and sequential visitation. Demonstration videos are available online\nat: https://philiptheother.github.io/doppler/.",
      "tldr_zh": "这篇论文提出DOPPLER框架，用于解决机器人长时域轨迹规划问题，强调在递减地平线条件下生成和更新基于线性时序逻辑(LTL)指令的计划。方法通过层次化强化学习将时序任务分解成选项链，并利用diffusion models生成低层动作，同时引入determinantal-guided posterior sampling技术，以提升选项生成的速度和多样性。实验结果显示，在机器人导航和操作任务中，DOPPLER能有效产生逐步满足障碍避免和顺序访问公式的轨迹序列。总体上，该框架为机器人安全部署提供了更可靠的规划能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02389v1",
      "published_date": "2024-10-03 11:10:37 UTC",
      "updated_date": "2024-10-03 11:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:48:33.524829"
    },
    {
      "arxiv_id": "2410.02387v3",
      "title": "BiSSL: A Bilevel Optimization Framework for Enhancing the Alignment Between Self-Supervised Pre-Training and Downstream Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Gustav Wagner Zakarias",
        "Lars Kai Hansen",
        "Zheng-Hua Tan"
      ],
      "abstract": "This study presents BiSSL, a novel training framework that utilizes bilevel\noptimization to enhance the alignment between the pretext pre-training and\ndownstream fine-tuning stages in self-supervised learning. BiSSL formulates the\npretext and downstream task objectives as the lower- and upper-level objectives\nin a bilevel optimization problem and serves as an intermediate training stage\nwithin the self-supervised learning pipeline. By explicitly modeling the\ninterdependence of these training stages, BiSSL facilitates enhanced\ninformation sharing between them, ultimately leading to a backbone parameter\ninitialization that is better aligned for the downstream task. We propose a\nversatile training algorithm that alternates between optimizing the two\nobjectives defined in BiSSL, which is applicable to a broad range of pretext\nand downstream tasks. Using SimCLR and Bootstrap Your Own Latent to pre-train\nResNet-50 backbones on the ImageNet dataset, we demonstrate that our proposed\nframework significantly outperforms the conventional self-supervised learning\npipeline on the vast majority of 12 downstream image classification datasets,\nas well as on object detection. Visualizations of the backbone features provide\nfurther evidence that BiSSL improves the downstream task alignment of the\nbackbone features prior to fine-tuning.",
      "tldr_zh": "本文提出 BiSSL，一种基于 bilevel optimization 的训练框架，用于提升自监督学习中预训练和下游微调任务之间的对齐。具体来说，BiSSL 将预训练任务作为下层目标、下游任务作为上层目标，并通过一个交替优化的通用算法促进信息共享，从而获得更适合下游任务的骨干参数初始化。实验结果显示，在 ImageNet 上使用 SimCLR 和 BYOL 预训练 ResNet-50 后，BiSSL 在 12 个下游图像分类数据集和对象检测任务上显著优于传统方法。特征可视化进一步证明了 BiSSL 改善了骨干特征与下游任务的匹配。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02387v3",
      "published_date": "2024-10-03 11:07:43 UTC",
      "updated_date": "2025-01-31 13:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:48:45.664669"
    },
    {
      "arxiv_id": "2410.14686v1",
      "title": "Achieving Generalization in Orchestrating GNSS Interference Monitoring Stations Through Pseudo-Labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Heublein",
        "Tobias Feigl",
        "Alexander Rügamer",
        "Felix Ott"
      ],
      "abstract": "The accuracy of global navigation satellite system (GNSS) receivers is\nsignificantly compromised by interference from jamming devices. Consequently,\nthe detection of these jammers are crucial to mitigating such interference\nsignals. However, robust classification of interference using machine learning\n(ML) models is challenging due to the lack of labeled data in real-world\nenvironments. In this paper, we propose an ML approach that achieves high\ngeneralization in classifying interference through orchestrated monitoring\nstations deployed along highways. We present a semi-supervised approach coupled\nwith an uncertainty-based voting mechanism by combining Monte Carlo and Deep\nEnsembles that effectively minimizes the requirement for labeled training\nsamples to less than 5% of the dataset while improving adaptability across\nvarying environments. Our method demonstrates strong performance when adapted\nfrom indoor environments to real-world scenarios.",
      "tldr_zh": "这篇论文针对全球导航卫星系统（GNSS）接收器受干扰设备影响的准确性问题，提出了一种基于伪标签（Pseudo-Labeling）的机器学习（ML）方法，以实现高泛化干扰分类。方法采用半监督学习，结合不确定性-based 投票机制（包括 Monte Carlo 和 Deep Ensembles），通过协调的高速公路监测站，将标记训练样本需求减少到不到 5%，并提升模型在不同环境下的适应性。实验结果显示，该方法在从室内环境迁移到真实场景时表现出色，显著提高了干扰检测的鲁棒性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "94-05, 82-11",
        "E.0; I.2.0; I.5.4; I.5.1"
      ],
      "primary_category": "eess.SP",
      "comment": "DGON Positioning and Navigation for Intelligent Transport Systems\n  (POSNAV)",
      "pdf_url": "http://arxiv.org/pdf/2410.14686v1",
      "published_date": "2024-10-03 11:07:17 UTC",
      "updated_date": "2024-10-03 11:07:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:49:50.914544"
    },
    {
      "arxiv_id": "2410.02381v4",
      "title": "MetaMetrics: Calibrating Metrics For Generation Tasks Using Human Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Genta Indra Winata",
        "David Anugraha",
        "Lucky Susanto",
        "Garry Kuwanto",
        "Derry Tanti Wijaya"
      ],
      "abstract": "Understanding the quality of a performance evaluation metric is crucial for\nensuring that model outputs align with human preferences. However, it remains\nunclear how well each metric captures the diverse aspects of these preferences,\nas metrics often excel in one particular area but not across all dimensions. To\naddress this, it is essential to systematically calibrate metrics to specific\naspects of human preference, catering to the unique characteristics of each\naspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate\ngeneration tasks across different modalities in a supervised manner.\nMetaMetrics optimizes the combination of existing metrics to enhance their\nalignment with human preferences. Our metric demonstrates flexibility and\neffectiveness in both language and vision downstream tasks, showing significant\nbenefits across various multilingual and multi-domain scenarios. MetaMetrics\naligns closely with human preferences and is highly extendable and easily\nintegrable into any application. This makes MetaMetrics a powerful tool for\nimproving the evaluation of generation tasks, ensuring that metrics are more\nrepresentative of human judgment across diverse contexts.",
      "tldr_zh": "该研究针对生成任务评估指标的问题，提出 MetaMetrics，这是一种校准过的元指标，用于优化现有指标的组合，以更好地与 human preferences 一致。MetaMetrics 通过监督方式系统地调整指标，针对不同模态（如语言和视觉）的任务，确保全面捕捉人类偏好的多样性。实验结果显示，该指标在多语言和多领域场景中表现出色，与人类判断高度对齐，并易于扩展和集成。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02381v4",
      "published_date": "2024-10-03 11:01:25 UTC",
      "updated_date": "2025-02-28 23:33:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:49:09.237568"
    },
    {
      "arxiv_id": "2410.02378v1",
      "title": "Towards Comprehensive Detection of Chinese Harmful Memes",
      "title_zh": "迈向中文有害模因的全面检测",
      "authors": [
        "Junyu Lu",
        "Bo Xu",
        "Xiaokun Zhang",
        "Hongbo Wang",
        "Haohao Zhu",
        "Dongyu Zhang",
        "Liang Yang",
        "Hongfei Lin"
      ],
      "abstract": "This paper has been accepted in the NeurIPS 2024 D & B Track. Harmful memes\nhave proliferated on the Chinese Internet, while research on detecting Chinese\nharmful memes significantly lags behind due to the absence of reliable datasets\nand effective detectors. To this end, we focus on the comprehensive detection\nof Chinese harmful memes. We construct ToxiCN MM, the first Chinese harmful\nmeme dataset, which consists of 12,000 samples with fine-grained annotations\nfor various meme types. Additionally, we propose a baseline detector,\nMultimodal Knowledge Enhancement (MKE), incorporating contextual information of\nmeme content generated by the LLM to enhance the understanding of Chinese\nmemes. During the evaluation phase, we conduct extensive quantitative\nexperiments and qualitative analyses on multiple baselines, including LLMs and\nour MKE. The experimental results indicate that detecting Chinese harmful memes\nis challenging for existing models while demonstrating the effectiveness of\nMKE. The resources for this paper are available at\nhttps://github.com/DUT-lujunyu/ToxiCN_MM.",
      "tldr_zh": "这篇论文针对中文有害 memes 的检测问题，构建了首个数据集 ToxiCN MM，包含 12,000 个样本并提供细粒度的注释，以覆盖各种 meme 类型。作者提出 Multimodal Knowledge Enhancement (MKE) 基线检测器，通过整合 LLM 生成的上下文信息来增强对中文 memes 的理解。实验结果表明，现有模型在检测中文有害 memes 时面临显著挑战，而 MKE 表现出色，有效提升了检测性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02378v1",
      "published_date": "2024-10-03 10:51:02 UTC",
      "updated_date": "2024-10-03 10:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:49:21.421017"
    },
    {
      "arxiv_id": "2410.02371v1",
      "title": "NTU-NPU System for Voice Privacy 2024 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Kuzmin",
        "Hieu-Thi Luong",
        "Jixun Yao",
        "Lei Xie",
        "Kong Aik Lee",
        "Eng Siong Chng"
      ],
      "abstract": "In this work, we describe our submissions for the Voice Privacy Challenge\n2024. Rather than proposing a novel speech anonymization system, we enhance the\nprovided baselines to meet all required conditions and improve evaluated\nmetrics. Specifically, we implement emotion embedding and experiment with WavLM\nand ECAPA2 speaker embedders for the B3 baseline. Additionally, we compare\ndifferent speaker and prosody anonymization techniques. Furthermore, we\nintroduce Mean Reversion F0 for B5, which helps to enhance privacy without a\nloss in utility. Finally, we explore disentanglement models, namely $\\beta$-VAE\nand NaturalSpeech3 FACodec.",
      "tldr_zh": "本研究描述了NTU-NPU团队为Voice Privacy 2024 Challenge提交的系统，他们通过增强提供的基线系统来满足所有要求并改善评估指标，而不是提出新系统。具体方法包括实现emotion embedding，使用WavLM和ECAPA2作为说话者嵌入器，并比较不同的说话者和韵律匿名化技术。此外，他们为B5基线引入Mean Reversion F0，以提升隐私保护而不降低实用性，并探索了β-VAE和NaturalSpeech3 FACodec等解缠模型。总的来说，这些改进有助于在语音匿名化任务中实现更好的平衡。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "System description for VPC 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02371v1",
      "published_date": "2024-10-03 10:45:10 UTC",
      "updated_date": "2024-10-03 10:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:49:34.078545"
    },
    {
      "arxiv_id": "2410.02365v1",
      "title": "From Concrete to Abstract: A Multimodal Generative Approach to Abstract Concept Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haodong Xie",
        "Rahul Singh Maharjan",
        "Federico Tavella",
        "Angelo Cangelosi"
      ],
      "abstract": "Understanding and manipulating concrete and abstract concepts is fundamental\nto human intelligence. Yet, they remain challenging for artificial agents. This\npaper introduces a multimodal generative approach to high order abstract\nconcept learning, which integrates visual and categorical linguistic\ninformation from concrete ones. Our model initially grounds subordinate level\nconcrete concepts, combines them to form basic level concepts, and finally\nabstracts to superordinate level concepts via the grounding of basic-level\nconcepts. We evaluate the model language learning ability through\nlanguage-to-visual and visual-to-language tests with high order abstract\nconcepts. Experimental results demonstrate the proficiency of the model in both\nlanguage understanding and language naming tasks.",
      "tldr_zh": "这篇论文提出了一种多模态生成方法，用于学习高阶抽象概念（abstract concept learning），通过整合视觉和分类语言信息从具体概念逐步抽象。模型首先将下级具体概念（subordinate level）进行接地，然后组合成基本概念（basic level），最终扩展到上级概念（superordinate level）。实验结果表明，该方法在语言到视觉以及视觉到语言测试中表现出色，尤其在语言理解和命名任务上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02365v1",
      "published_date": "2024-10-03 10:24:24 UTC",
      "updated_date": "2024-10-03 10:24:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:49:45.792832"
    },
    {
      "arxiv_id": "2410.02362v1",
      "title": "A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Shubhi Bansal",
        "Sreeharish A",
        "Madhava Prasath J",
        "Manikandan S",
        "Sreekanth Madisetty",
        "Mohammad Zia Ur Rehman",
        "Chandravardhan Singh Raghaw",
        "Gaurav Duggal",
        "Nagendra Kumar"
      ],
      "abstract": "Mamba, a special case of the State Space Model, is gaining popularity as an\nalternative to template-based deep learning approaches in medical image\nanalysis. While transformers are powerful architectures, they have drawbacks,\nincluding quadratic computational complexity and an inability to address\nlong-range dependencies efficiently. This limitation affects the analysis of\nlarge and complex datasets in medical imaging, where there are many spatial and\ntemporal relationships. In contrast, Mamba offers benefits that make it\nwell-suited for medical image analysis. It has linear time complexity, which is\na significant improvement over transformers. Mamba processes longer sequences\nwithout attention mechanisms, enabling faster inference and requiring less\nmemory. Mamba also demonstrates strong performance in merging multimodal data,\nimproving diagnosis accuracy and patient outcomes. The organization of this\npaper allows readers to appreciate the capabilities of Mamba in medical imaging\nstep by step. We begin by defining core concepts of SSMs and models, including\nS4, S5, and S6, followed by an exploration of Mamba architectures such as pure\nMamba, U-Net variants, and hybrid models with convolutional neural networks,\ntransformers, and Graph Neural Networks. We also cover Mamba optimizations,\ntechniques and adaptations, scanning, datasets, applications, experimental\nresults, and conclude with its challenges and future directions in medical\nimaging. This review aims to demonstrate the transformative potential of Mamba\nin overcoming existing barriers within medical imaging while paving the way for\ninnovative advancements in the field. A comprehensive list of Mamba\narchitectures applied in the medical field, reviewed in this work, is available\nat Github.",
      "tldr_zh": "这篇论文对Mamba架构（一种State Space Model的特例）在医疗图像分析中的应用进行了全面调查，涵盖分类、分割、修复等领域。相比Transformer的二次方计算复杂度和处理长序列的局限，Mamba提供线性时间复杂度、更快的推理速度和更低的内存需求，并在多模态数据融合中提升诊断准确性。论文系统回顾了SSM核心概念（如S4、S5和S6）、各种Mamba变体（包括纯Mamba、U-Net变体以及与CNN、Transformer和Graph Neural Networks的混合模型）、优化技术、数据集、实验结果和未来挑战，最终强调Mamba在克服医疗成像障碍方面的变革潜力，并提供GitHub资源列表。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02362v1",
      "published_date": "2024-10-03 10:23:03 UTC",
      "updated_date": "2024-10-03 10:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:50:03.396961"
    },
    {
      "arxiv_id": "2410.02355v4",
      "title": "AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junfeng Fang",
        "Houcheng Jiang",
        "Kun Wang",
        "Yunshan Ma",
        "Shi Jie",
        "Xiang Wang",
        "Xiangnan He",
        "Tat-seng Chua"
      ],
      "abstract": "Large language models (LLMs) often exhibit hallucinations due to incorrect or\noutdated knowledge. Hence, model editing methods have emerged to enable\ntargeted knowledge updates. To achieve this, a prevailing paradigm is the\nlocating-then-editing approach, which first locates influential parameters and\nthen edits them by introducing a perturbation. While effective, current studies\nhave demonstrated that this perturbation inevitably disrupt the originally\npreserved knowledge within LLMs, especially in sequential editing scenarios. To\naddress this, we introduce AlphaEdit, a novel solution that projects\nperturbation onto the null space of the preserved knowledge before applying it\nto the parameters. We theoretically prove that this projection ensures the\noutput of post-edited LLMs remains unchanged when queried about the preserved\nknowledge, thereby mitigating the issue of disruption. Extensive experiments on\nvarious LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts\nthe performance of most locating-then-editing methods by an average of 36.7%\nwith a single line of additional code for projection solely. Our code is\navailable at: https://github.com/jianghoucheng/AlphaEdit.",
      "tldr_zh": "大型语言模型（LLMs）常因不正确或过时知识而产生幻觉，现有的定位-then-editing 方法虽能更新知识，但会破坏原有知识，尤其是连续编辑场景。AlphaEdit 是一种新颖的知识编辑方法，通过将扰动投影到保留知识的 null space 上，确保编辑后模型在查询保留知识时输出不变，从而避免干扰。理论证明支持了这一机制的可靠性。实验结果显示，AlphaEdit 在 LLaMA3、GPT2-XL 和 GPT-J 等模型上，平均提升了 36.7% 的性能，仅需添加一行代码即可实现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02355v4",
      "published_date": "2024-10-03 10:06:27 UTC",
      "updated_date": "2025-04-22 16:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:50:16.087554"
    },
    {
      "arxiv_id": "2410.02338v2",
      "title": "How Much Can RAG Help the Reasoning of LLM?",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyu Liu",
        "Jiaen Lin",
        "Yong Liu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has gained significant popularity in\nmodern Large Language Models (LLMs) due to its effectiveness in introducing new\nknowledge and reducing hallucinations. However, the deep understanding of RAG\nremains limited, how does RAG help the reasoning process and can RAG help\nimprove the reasoning capability remains question. While external documents are\ntypically considered as a method to incorporate domain-specific information,\nthey also contain intermediate reasoning results related to the query, this\nsuggests that documents could enhance the reasoning capability of LLMs, which\nhas not been previously explored. In this paper, we investigate this issue in\ndepth and find that while RAG can assist with reasoning, the help is limited.\nIf we conceptualize the reasoning process as a tree with fixed depth, then RAG\nstruggles to assist LLMs in performing deeper reasoning. Additionally, the\ninformation in the documents requires preprocessing to filter out noise. We\ndemonstrate that this preprocessing is difficult to achieve simply fine-tuning\nof the LLM, it often necessitates numerous additional transformer layers to\nsolve the problem. To simplify the problem, we propose DPrompt tuning, which\neffectively resolves the issue within just limited transformer layers, leading\nto improved performance.",
      "tldr_zh": "本研究探讨了检索增强生成（RAG）对大型语言模型（LLMs）的推理能力的影响，发现RAG虽然能引入新知识并减少幻觉，但对推理过程的帮助有限，尤其在处理深度推理（如固定深度推理树）时效果不佳。作者指出，外部文档中的信息需经过预处理以过滤噪音，而简单微调LLMs难以实现此目标，往往需要额外transformer层。针对此问题，他们提出了DPrompt tuning方法，通过有限的transformer层有效简化预处理并提升推理性能。总的来说，该工作为理解RAG的局限性和优化LLMs推理提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02338v2",
      "published_date": "2024-10-03 09:48:09 UTC",
      "updated_date": "2024-10-04 14:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:50:27.297136"
    },
    {
      "arxiv_id": "2410.02326v1",
      "title": "Autonomous Self-Trained Channel State Prediction Method for mmWave Vehicular Communications",
      "title_zh": "翻译失败",
      "authors": [
        "Abidemi Orimogunje",
        "Vukan Ninkovic",
        "Evariste Twahirwa",
        "Gaspard Gashema",
        "Dejan Vukobratovic"
      ],
      "abstract": "Establishing and maintaining 5G mmWave vehicular connectivity poses a\nsignificant challenge due to high user mobility that necessitates frequent\ntriggering of beam switching procedures. Departing from reactive beam switching\nbased on the user device channel state feedback, proactive beam switching\nprepares in advance for upcoming beam switching decisions by exploiting\naccurate channel state information (CSI) prediction. In this paper, we develop\na framework for autonomous self-trained CSI prediction for mmWave vehicular\nusers where a base station (gNB) collects and labels a dataset that it uses for\ntraining recurrent neural network (RNN)-based CSI prediction model. The\nproposed framework exploits the CSI feedback from vehicular users combined with\noverhearing the C-V2X cooperative awareness messages (CAMs) they broadcast. We\nimplement and evaluate the proposed framework using deepMIMO dataset generation\nenvironment and demonstrate its capability to provide accurate CSI prediction\nfor 5G mmWave vehicular users. CSI prediction model is trained and its\ncapability to provide accurate CSI predictions from various input features are\ninvestigated.",
      "tldr_zh": "这篇论文提出了一种自主自训练的信道状态信息 (CSI) 预测方法，用于 mmWave 车辆通信，以解决用户高移动性导致的频繁波束切换挑战，并实现主动波束切换。方法涉及基站 (gNB) 收集车辆用户的 CSI 反馈和监听 C-V2X 合作意识消息 (CAMs)，并使用这些数据训练基于循环神经网络 (RNN) 的预测模型。通过 deepMIMO 数据集环境进行实验评估，结果显示该框架能提供准确的 CSI 预测，提升了通信可靠性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted for publication at European Wireless 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02326v1",
      "published_date": "2024-10-03 09:20:48 UTC",
      "updated_date": "2024-10-03 09:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:50:39.814106"
    },
    {
      "arxiv_id": "2410.02320v3",
      "title": "Post-edits Are Preferences Too",
      "title_zh": "翻译失败",
      "authors": [
        "Nathaniel Berger",
        "Miriam Exel",
        "Matthias Huck",
        "Stefan Riezler"
      ],
      "abstract": "Preference Optimization (PO) techniques are currently one of the state of the\nart techniques for fine-tuning large language models (LLMs) on pairwise\npreference feedback from human annotators. However, in machine translation,\nthis sort of feedback can be difficult to solicit. Additionally, Kreutzer et\nal. (2018) have shown that, for machine translation, pairwise preferences are\nless reliable than other forms of human feedback, such as 5-point ratings.\n  We examine post-edits to see if they can be a source of reliable human\npreferences by construction. In PO, a human annotator is shown sequences $s_1$\nand $s_2$ and asked for a preference judgment, %$s_1 > s_2$; while for\npost-editing, editors create $s_1$ and know that it should be better than\n$s_2$. We attempt to use these implicit preferences for PO and show that it\nhelps the model move towards post-edit-like hypotheses and away from machine\ntranslation-like hypotheses. Furthermore, we show that best results are\nobtained by pre-training the model with supervised fine-tuning (SFT) on\npost-edits in order to promote post-edit-like hypotheses to the top output\nranks.",
      "tldr_zh": "这篇论文探讨了在机器翻译领域，使用后编辑 (post-edits) 作为隐含偏好反馈来优化大型语言模型 (LLMs)，因为传统配对偏好反馈难以获取且可靠性较低。作者通过偏好优化 (PO) 技术，将后编辑视为可靠的偏好来源，实验显示这能引导模型生成更接近人类编辑的输出，而非原始机器翻译假设。最佳效果是通过先进行监督微调 (SFT) 于后编辑来实现，从而提升输出排名的准确性和质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at the Ninth Conference on Machine Translation (WMT24)",
      "pdf_url": "http://arxiv.org/pdf/2410.02320v3",
      "published_date": "2024-10-03 08:56:29 UTC",
      "updated_date": "2025-02-21 11:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:50:55.069725"
    },
    {
      "arxiv_id": "2410.02316v1",
      "title": "CTARR: A fast and robust method for identifying anatomical regions on CT images via atlas registration",
      "title_zh": "CTARR：一种通过图谱配准在 CT 图像上识别解剖区域的快速且鲁棒方法",
      "authors": [
        "Thomas Buddenkotte",
        "Roland Opfer",
        "Julia Krüger",
        "Alessa Hering",
        "Mireia Crispin-Ortuzar"
      ],
      "abstract": "Medical image analysis tasks often focus on regions or structures located in\na particular location within the patient's body. Often large parts of the image\nmay not be of interest for the image analysis task. When using deep-learning\nbased approaches, this causes an unnecessary increases the computational burden\nduring inference and raises the chance of errors. In this paper, we introduce\nCTARR, a novel generic method for CT Anatomical Region Recognition. The method\nserves as a pre-processing step for any deep learning-based CT image analysis\npipeline by automatically identifying the pre-defined anatomical region that is\nrelevant for the follow-up task and removing the rest. It can be used in (i)\nimage segmentation to prevent false positives in anatomically implausible\nregions and speeding up the inference, (ii) image classification to produce\nimage crops that are consistent in their anatomical context, and (iii) image\nregistration by serving as a fast pre-registration step. Our proposed method is\nbased on atlas registration and provides a fast and robust way to crop any\nanatomical region encoded as one or multiple bounding box(es) from any\nunlabeled CT scan of the brain, chest, abdomen and/or pelvis. We demonstrate\nthe utility and robustness of the proposed method in the context of medical\nimage segmentation by evaluating it on six datasets of public segmentation\nchallenges. The foreground voxels in the regions of interest are preserved in\nthe vast majority of cases and tasks (97.45-100%) while taking only fractions\nof a seconds to compute (0.1-0.21s) on a deep learning workstation and greatly\nreducing the segmentation runtime (2.0-12.7x). Our code is available at\nhttps://github.com/ThomasBudd/ctarr.",
      "tldr_zh": "本论文提出了一种快速且鲁棒的 CT 图像解剖区域识别方法 CTARR，通过 atlas registration 技术作为深度学习图像分析管道的预处理步骤，自动识别并裁剪预定义的解剖区域（如脑、胸、腹部或骨盆），从而减少计算负担并降低错误风险。CTARR 可应用于图像分割（防止假阳性和加速推理）、图像分类（生成一致的解剖上下文图像块）和图像注册（作为快速预注册步骤）。在六个公共分割挑战数据集上评估，该方法在极短时间内（0.1-0.21 秒）保留了97.45-100%的感兴趣区域，并将分割运行时间减少2.0-12.7倍。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02316v1",
      "published_date": "2024-10-03 08:52:21 UTC",
      "updated_date": "2024-10-03 08:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:51:06.722937"
    },
    {
      "arxiv_id": "2410.03777v2",
      "title": "Determine-Then-Ensemble: Necessity of Top-k Union for Large Language Model Ensembling",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Yao",
        "Han Wu",
        "Mingyang Liu",
        "Sichun Luo",
        "Xiongwei Han",
        "Jie Liu",
        "Zhijiang Guo",
        "Linqi Song"
      ],
      "abstract": "Large language models (LLMs) exhibit varying strengths and weaknesses across\ndifferent tasks, prompting recent studies to explore the benefits of ensembling\nmodels to leverage their complementary advantages. However, existing LLM\nensembling methods often overlook model compatibility and struggle with\ninefficient alignment of probabilities across the entire vocabulary. In this\nstudy, we empirically investigate the factors influencing ensemble performance,\nidentifying model performance, vocabulary size, and response style as key\ndeterminants, revealing that compatibility among models is essential for\neffective ensembling. This analysis leads to the development of a simple yet\neffective model selection strategy that identifies compatible models.\nAdditionally, we introduce the \\textsc{Uni}on \\textsc{T}op-$k$\n\\textsc{E}nsembling (\\textsc{UniTE}), a novel approach that efficiently\ncombines models by focusing on the union of the top-k tokens from each model,\nthereby avoiding the need for full vocabulary alignment and reducing\ncomputational overhead. Extensive evaluations across multiple benchmarks\ndemonstrate that \\textsc{UniTE} significantly enhances performance compared to\nexisting methods, offering a more efficient framework for LLM ensembling.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在不同任务上的优势互补，通过集成方法提升性能，但现有方法忽略了模型兼容性和词汇概率对齐的效率问题。研究者分析了影响集成性能的关键因素，包括模型性能、词汇大小和响应风格，强调了模型兼容性的必要性，并开发了一种简单的模型选择策略来识别兼容模型。同时，引入了 UniTE (Union Top-k Ensembling) 方法，该方法通过聚焦每个模型的 top-k 标记联合，避免了全词汇对齐的计算开销。在多个基准测试中，UniTE 显著提高了性能，提供了一个更高效的 LLM 集成框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03777v2",
      "published_date": "2024-10-03 08:42:38 UTC",
      "updated_date": "2025-02-25 12:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:51:17.636923"
    },
    {
      "arxiv_id": "2410.02283v1",
      "title": "Morphological evaluation of subwords vocabulary used by BETO language model",
      "title_zh": "BETO 语言模型使用的子词词汇的形态学评估",
      "authors": [
        "Óscar García-Sierra",
        "Ana Fernández-Pampillón Cesteros",
        "Miguel Ortega-Martín"
      ],
      "abstract": "Subword tokenization algorithms used by Large Language Models are\nsignificantly more efficient and can independently build the necessary\nvocabulary of words and subwords without human intervention. However, those\nsubwords do not always align with real morphemes, potentially impacting the\nmodels' performance, though it remains uncertain when this might occur. In\nprevious research, we proposed a method to assess the morphological quality of\nvocabularies, focusing on the overlap between these vocabularies and the\nmorphemes of a given language. Our evaluation method was built on three quality\nmeasures, relevance, cohesion, and morphological accuracy, and a procedure for\ntheir assessment. By applying this method to vocabularies created by three\nsubword tokenization algorithms, BPE, Wordpiece, and Unigram, we concluded that\nthese vocabularies generally exhibit very low morphological quality. In this\narticle, we apply this evaluation to the tokenizer of BETO, a BERT language\nmodel trained on large Spanish corpora. This evaluation, along with our\nprevious results, helped us conclude that its vocabulary has a low\nmorphological quality, and we also found that training the tokenizer in a\nlarger corpus does not improve the morphological quality of the generated\nvocabulary. Additionally, this evaluation helps clarify the algorithm used by\nthe tokenizer, that is, Wordpiece, given the inconsistencies between the\nauthors' claims and the model's configuration.",
      "tldr_zh": "本研究评估了 BETO 语言模型子词词汇的形态质量，关注子词标记算法（如 BPE、Wordpiece 和 Unigram）是否与真实词素对齐。研究者使用先前提出的方法，包括 relevance、cohesion 和 morphological accuracy 等三个质量指标，对 BETO 的词汇进行分析。结果显示，BETO 的词汇形态质量较低，且使用更大语料库训练无法改善这一问题；此外，通过评估澄清了 BETO 实际采用 Wordpiece 算法，尽管作者声明存在不一致。总的来说，此工作突出了子词词汇在语言模型性能中的潜在影响，并为未来优化提供见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "in Spanish language",
      "pdf_url": "http://arxiv.org/pdf/2410.02283v1",
      "published_date": "2024-10-03 08:07:14 UTC",
      "updated_date": "2024-10-03 08:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:51:33.427276"
    },
    {
      "arxiv_id": "2410.14685v1",
      "title": "Leveraging Event Streams with Deep Reinforcement Learning for End-to-End UAV Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Ala Souissi",
        "Hajer Fradi",
        "Panagiotis Papadakis"
      ],
      "abstract": "In this paper, we present our proposed approach for active tracking to\nincrease the autonomy of Unmanned Aerial Vehicles (UAVs) using event cameras,\nlow-energy imaging sensors that offer significant advantages in speed and\ndynamic range. The proposed tracking controller is designed to respond to\nvisual feedback from the mounted event sensor, adjusting the drone movements to\nfollow the target. To leverage the full motion capabilities of a quadrotor and\nthe unique properties of event sensors, we propose an end-to-end\ndeep-reinforcement learning (DRL) framework that maps raw sensor data from\nevent streams directly to control actions for the UAV. To learn an optimal\npolicy under highly variable and challenging conditions, we opt for a\nsimulation environment with domain randomization for effective transfer to\nreal-world environments. We demonstrate the effectiveness of our approach\nthrough experiments in challenging scenarios, including fast-moving targets and\nchanging lighting conditions, which result in improved generalization\ncapabilities.",
      "tldr_zh": "本研究提出了一种利用事件流（event streams）和深度强化学习（DRL）的端到端框架，以提升无人机的自主跟踪能力。框架直接将事件相机的数据映射到无人机（UAV）的控制动作，允许无人机根据视觉反馈调整运动跟踪目标。通过模拟环境和领域随机化（domain randomization），该方法在高度可变条件下训练最优策略，实现从模拟到真实世界的有效转移。实验结果显示，该方法在快速移动目标和变化照明条件下表现出色，显著提高了跟踪的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14685v1",
      "published_date": "2024-10-03 07:56:40 UTC",
      "updated_date": "2024-10-03 07:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:51:41.562933"
    },
    {
      "arxiv_id": "2410.02271v1",
      "title": "CoLLAP: Contrastive Long-form Language-Audio Pretraining with Musical Temporal Structure Augmentation",
      "title_zh": "CoLLAP",
      "authors": [
        "Junda Wu",
        "Warren Li",
        "Zachary Novack",
        "Amit Namburi",
        "Carol Chen",
        "Julian McAuley"
      ],
      "abstract": "Modeling temporal characteristics plays a significant role in the\nrepresentation learning of audio waveform. We propose Contrastive Long-form\nLanguage-Audio Pretraining (\\textbf{CoLLAP}) to significantly extend the\nperception window for both the input audio (up to 5 minutes) and the language\ndescriptions (exceeding 250 words), while enabling contrastive learning across\nmodalities and temporal dynamics. Leveraging recent Music-LLMs to generate\nlong-form music captions for full-length songs, augmented with musical temporal\nstructures, we collect 51.3K audio-text pairs derived from the large-scale\nAudioSet training dataset, where the average audio length reaches 288 seconds.\nWe propose a novel contrastive learning architecture that fuses language\nrepresentations with structured audio representations by segmenting each song\ninto clips and extracting their embeddings. With an attention mechanism, we\ncapture multimodal temporal correlations, allowing the model to automatically\nweigh and enhance the final fusion score for improved contrastive alignment.\nFinally, we develop two variants of the CoLLAP model with different types of\nbackbone language models. Through comprehensive experiments on multiple\nlong-form music-text retrieval datasets, we demonstrate consistent performance\nimprovement in retrieval accuracy compared with baselines. We also show the\npretrained CoLLAP models can be transferred to various music information\nretrieval tasks, with heterogeneous long-form multimodal contexts.",
      "tldr_zh": "该论文提出 CoLLAP，一种对比学习框架，用于长形式语言-音频预训练，通过音乐时间结构增强来扩展音频（长达5分钟）和语言描述（超过250词）的感知窗口。研究者利用 Music-LLMs 生成长音乐标题，并收集51.3K对音频-文本数据集，平均音频长度达288秒。CoLLAP 采用新颖的对比学习架构，将语言表示与结构化音频片段嵌入融合，并通过注意力机制捕获多模态时间相关性，最终在音乐-文本检索任务上显著提升准确率，并证明其可转移到其他音乐信息检索任务。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02271v1",
      "published_date": "2024-10-03 07:46:51 UTC",
      "updated_date": "2024-10-03 07:46:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:51:54.048777"
    },
    {
      "arxiv_id": "2410.02268v3",
      "title": "Structural-Entropy-Based Sample Selection for Efficient and Effective Learning",
      "title_zh": "基于结构熵的样本选择用于高效和有效的学习",
      "authors": [
        "Tianchi Xie",
        "Jiangning Zhu",
        "Guozu Ma",
        "Minzhi Lin",
        "Wei Chen",
        "Weikai Yang",
        "Shixia Liu"
      ],
      "abstract": "Sample selection improves the efficiency and effectiveness of machine\nlearning models by providing informative and representative samples. Typically,\nsamples can be modeled as a sample graph, where nodes are samples and edges\nrepresent their similarities. Most existing methods are based on local\ninformation, such as the training difficulty of samples, thereby overlooking\nglobal information, such as connectivity patterns. This oversight can result in\nsuboptimal selection because global information is crucial for ensuring that\nthe selected samples well represent the structural properties of the graph. To\naddress this issue, we employ structural entropy to quantify global information\nand losslessly decompose it from the whole graph to individual nodes using the\nShapley value. Based on the decomposition, we present\n$\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election\n($\\textbf{SES}$), a method that integrates both global and local information to\nselect informative and representative samples. SES begins by constructing a\n$k$NN-graph among samples based on their similarities. It then measures sample\nimportance by combining structural entropy (global metric) with training\ndifficulty (local metric). Finally, SES applies importance-biased blue noise\nsampling to select a set of diverse and representative samples. Comprehensive\nexperiments on three learning scenarios -- supervised learning, active\nlearning, and continual learning -- clearly demonstrate the effectiveness of\nour method.",
      "tldr_zh": "本研究提出了一种基于结构熵(Structural Entropy)的样本选择方法SES，以提升机器学习模型的效率和效果，该方法通过整合全局信息（如图的连通性模式）和局部信息（如样本训练难度）来选择信息性和代表性的样本。SES首先基于样本相似性构建kNN-graph，然后使用Shapley value对结构熵进行无损分解，并结合样本重要性（包括结构熵和训练难度）进行测量，最后应用importance-biased blue noise sampling来选取多样化的样本。相比现有方法，该方法解决了忽略全局信息的局限性，并在supervised learning、active learning和continual learning三种场景的全面实验中，显著提高了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02268v3",
      "published_date": "2024-10-03 07:40:14 UTC",
      "updated_date": "2025-03-03 05:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:52:05.783992"
    },
    {
      "arxiv_id": "2410.02253v2",
      "title": "From Imitation to Exploration: End-to-end Autonomous Driving based on World Model",
      "title_zh": "从模仿到探索：基于世界模型的端到端自动驾驶",
      "authors": [
        "Yueyuan Li",
        "Mingyang Jiang",
        "Songan Zhang",
        "Wei Yuan",
        "Chunxiang Wang",
        "Ming Yang"
      ],
      "abstract": "In recent years, end-to-end autonomous driving architectures have gained\nincreasing attention due to their advantage in avoiding error accumulation.\nMost existing end-to-end autonomous driving methods are based on Imitation\nLearning (IL), which can quickly derive driving strategies by mimicking expert\nbehaviors. However, IL often struggles to handle scenarios outside the training\ndataset, especially in high-dynamic and interaction-intensive traffic\nenvironments. In contrast, Reinforcement Learning (RL)-based driving models can\noptimize driving decisions through interaction with the environment, improving\nadaptability and robustness.\n  To leverage the strengths of both IL and RL, we propose RAMBLE, an end-to-end\nworld model-based RL method for driving decision-making. RAMBLE extracts\nenvironmental context information from RGB images and LiDAR data through an\nasymmetrical variational autoencoder. A transformer-based architecture is then\nused to capture the dynamic transitions of traffic participants. Next, an\nactor-critic structure reinforcement learning algorithm is applied to derive\ndriving strategies based on the latent features of the current state and\ndynamics. To accelerate policy convergence and ensure stable training, we\nintroduce a training scheme that initializes the policy network using IL, and\nemploys KL loss and soft update mechanisms to smoothly transition the model\nfrom IL to RL.\n  RAMBLE achieves state-of-the-art performance in route completion rate on the\nCARLA Leaderboard 1.0 and completes all 38 scenarios on the CARLA Leaderboard\n2.0, demonstrating its effectiveness in handling complex and dynamic traffic\nscenarios. The model will be open-sourced upon paper acceptance at\nhttps://github.com/SCP-CN-001/ramble to support further research and\ndevelopment in autonomous driving.",
      "tldr_zh": "该研究提出 RAMBLE，一种基于世界模型的端到端 Reinforcement Learning (RL) 方法，旨在结合 Imitation Learning (IL) 的快速模仿优势与 RL 的环境交互优化，解决传统 IL 在高动态交通场景中的适应性问题。\nRAMBLE 通过不对称变分自动编码器从 RGB 图像和 LiDAR 数据提取环境上下文信息，使用 Transformer 架构捕获交通参与者的动态过渡，并采用 Actor-Critic 结构的 RL 算法基于潜在特征推导驾驶策略，同时引入 IL 初始化、KL 损失和软更新机制来加速策略收敛和稳定训练。\n实验结果表明，RAMBLE 在 CARLA Leaderboard 1.0 上实现最先进路线完成率，并在 CARLA Leaderboard 2.0 上成功完成所有 38 个场景，展示了其在复杂动态环境中的鲁棒性和有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 4 figures, 3 tables; T-ITS under review",
      "pdf_url": "http://arxiv.org/pdf/2410.02253v2",
      "published_date": "2024-10-03 06:45:59 UTC",
      "updated_date": "2025-04-20 06:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:52:19.423947"
    },
    {
      "arxiv_id": "2410.02246v2",
      "title": "PFGuard: A Generative Framework with Privacy and Fairness Safeguards",
      "title_zh": "PFGuard：一种具有隐私和公平",
      "authors": [
        "Soyeon Kim",
        "Yuji Roh",
        "Geon Heo",
        "Steven Euijong Whang"
      ],
      "abstract": "Generative models must ensure both privacy and fairness for Trustworthy AI.\nWhile these goals have been pursued separately, recent studies propose to\ncombine existing privacy and fairness techniques to achieve both goals.\nHowever, naively combining these techniques can be insufficient due to\nprivacy-fairness conflicts, where a sample in a minority group may be\nrepresented in ways that support fairness, only to be suppressed for privacy.\nWe demonstrate how these conflicts lead to adverse effects, such as privacy\nviolations and unexpected fairness-utility tradeoffs. To mitigate these risks,\nwe propose PFGuard, a generative framework with privacy and fairness\nsafeguards, which simultaneously addresses privacy, fairness, and utility. By\nusing an ensemble of multiple teacher models, PFGuard balances privacy-fairness\nconflicts between fair and private training stages and achieves high utility\nbased on ensemble learning. Extensive experiments show that PFGuard\nsuccessfully generates synthetic data on high-dimensional data while providing\nboth DP guarantees and convergence in fair generative modeling.",
      "tldr_zh": "该研究指出，生成模型在追求可信赖 AI 时需同时确保 Privacy 和 Fairness，但简单结合现有技术可能因 Privacy-Fairness 冲突（如少数群体样本的表示问题）导致隐私泄露和公平-效用权衡。针对此，论文提出 PFGuard 框架，通过多个教师模型的 Ensemble 学习，在公平和私有训练阶段平衡冲突，同时优化 Privacy、Fairness 和 Utility。实验结果显示，PFGuard 能在高维数据上生成合成数据，提供 DP（Differential Privacy）保证，并实现公平生成建模的收敛。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the 13th International Conference on Learning\n  Representations (ICLR), 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02246v2",
      "published_date": "2024-10-03 06:37:16 UTC",
      "updated_date": "2025-02-28 09:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:52:29.507353"
    },
    {
      "arxiv_id": "2410.02242v2",
      "title": "Robust Weight Initialization for Tanh Neural Networks with Fixed Point Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunwoo Lee",
        "Hayoung Choi",
        "Hyunju Kim"
      ],
      "abstract": "As a neural network's depth increases, it can improve generalization\nperformance. However, training deep networks is challenging due to gradient and\nsignal propagation issues. To address these challenges, extensive theoretical\nresearch and various methods have been introduced. Despite these advances,\neffective weight initialization methods for tanh neural networks remain\ninsufficiently investigated. This paper presents a novel weight initialization\nmethod for neural networks with tanh activation function. Based on an analysis\nof the fixed points of the function $\\tanh(ax)$, the proposed method aims to\ndetermine values of $a$ that mitigate activation saturation. A series of\nexperiments on various classification datasets and physics-informed neural\nnetworks demonstrates that the proposed method outperforms Xavier\ninitialization methods~(with or without normalization) in terms of robustness\nacross different network sizes, data efficiency, and convergence speed. Code is\navailable at https://github.com/1HyunwooLee/Tanh-Init",
      "tldr_zh": "这篇论文针对 tanh 神经网络的权重初始化问题，提出了一种基于固定点分析的新方法，以缓解激活饱和并改善深度网络的梯度传播和信号传播挑战。方法通过分析 tanh(ax) 函数的固定点，确定合适的 a 值来优化初始化策略。在各种分类数据集和物理信息神经网络上的实验表明，该方法比 Xavier initialization 方法更具鲁棒性，提高了数据效率和收敛速度，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02242v2",
      "published_date": "2024-10-03 06:30:27 UTC",
      "updated_date": "2025-03-02 11:32:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:52:45.401902"
    },
    {
      "arxiv_id": "2410.02240v6",
      "title": "SCA: Improve Semantic Consistent in Unrestricted Adversarial Attacks via DDPM Inversion",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Pan",
        "Lifeng Chen",
        "Weibin Wu",
        "Yuhang Cao",
        "Zibin Zheng"
      ],
      "abstract": "Systems based on deep neural networks are vulnerable to adversarial attacks.\nUnrestricted adversarial attacks typically manipulate the semantic content of\nan image (e.g., color or texture) to create adversarial examples that are both\neffective and photorealistic. Recent works have utilized the diffusion\ninversion process to map images into a latent space, where high-level semantics\nare manipulated by introducing perturbations. However, they often result in\nsubstantial semantic distortions in the denoised output and suffer from low\nefficiency. In this study, we propose a novel framework called\nSemantic-Consistent Unrestricted Adversarial Attacks (SCA), which employs an\ninversion method to extract edit-friendly noise maps and utilizes a Multimodal\nLarge Language Model (MLLM) to provide semantic guidance throughout the\nprocess. Under the condition of rich semantic information provided by MLLM, we\nperform the DDPM denoising process of each step using a series of edit-friendly\nnoise maps and leverage DPM Solver++ to accelerate this process, enabling\nefficient sampling with semantic consistency. Compared to existing methods, our\nframework enables the efficient generation of adversarial examples that exhibit\nminimal discernible semantic changes. Consequently, we for the first time\nintroduce Semantic-Consistent Adversarial Examples (SCAE). Extensive\nexperiments and visualizations have demonstrated the high efficiency of SCA,\nparticularly in being on average 12 times faster than the state-of-the-art\nattacks. Our code can be found at https://github.com/Pan-Zihao/SCA.",
      "tldr_zh": "本文提出SCA框架，通过DDPM Inversion改进无限制对抗攻击的语义一致性，旨在生成有效且逼真的对抗样本，同时减少语义扭曲。SCA利用逆过程提取易编辑噪声映射，并借助Multimodal Large Language Model (MLLM)提供语义指导，以及DPM Solver++加速去噪过程，使生成过程平均比现有方法快12倍。首次引入Semantic-Consistent Adversarial Examples (SCAE)，实验结果证明了SCA在效率和语义保持方面的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02240v6",
      "published_date": "2024-10-03 06:25:53 UTC",
      "updated_date": "2025-05-12 18:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:52:54.111206"
    },
    {
      "arxiv_id": "2410.02231v1",
      "title": "SEAL: SEmantic-Augmented Imitation Learning via Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyang Gu",
        "Yuxin Pan",
        "Haotian Bai",
        "Hui Xiong",
        "Yize Chen"
      ],
      "abstract": "Hierarchical Imitation Learning (HIL) is a promising approach for tackling\nlong-horizon decision-making tasks. While it is a challenging task due to the\nlack of detailed supervisory labels for sub-goal learning, and reliance on\nhundreds to thousands of expert demonstrations. In this work, we introduce\nSEAL, a novel framework that leverages Large Language Models (LLMs)'s powerful\nsemantic and world knowledge for both specifying sub-goal space and\npre-labeling states to semantically meaningful sub-goal representations without\nprior knowledge of task hierarchies. SEAL employs a dual-encoder structure,\ncombining supervised LLM-guided sub-goal learning with unsupervised Vector\nQuantization (VQ) for more robust sub-goal representations. Additionally, SEAL\nincorporates a transition-augmented low-level planner for improved adaptation\nto sub-goal transitions. Our experiments demonstrate that SEAL outperforms\nstate-of-the-art HIL methods and LLM-based planning approaches, particularly in\nsettings with small expert datasets and complex long-horizon tasks.",
      "tldr_zh": "本研究提出SEAL框架，通过大型语言模型(LLMs)增强分层模仿学习(HIL)，以解决长时序决策任务中子目标学习缺乏监督标签和需要大量专家演示的挑战。SEAL利用LLMs的语义和世界知识来指定子目标空间并预标记状态为语义子目标表示，无需任务层次的先验知识；框架采用双编码器结构，结合监督的LLM引导子目标学习和无监督的向量量化(VQ)，并融入过渡增强的低级规划器以提升子目标过渡的适应性。实验结果显示，SEAL在小规模专家数据集和复杂长时序任务中，优于现有HIL方法和LLM-based规划方法，展示了其高效性和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 5 figures, in submission",
      "pdf_url": "http://arxiv.org/pdf/2410.02231v1",
      "published_date": "2024-10-03 05:53:10 UTC",
      "updated_date": "2024-10-03 05:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:53:06.614984"
    },
    {
      "arxiv_id": "2410.02229v1",
      "title": "CodePMP: Scalable Preference Model Pretraining for Large Language Model Reasoning",
      "title_zh": "CodePMP：用于大型语言模型推理的可扩展偏好模型预训练",
      "authors": [
        "Huimu Yu",
        "Xing Wu",
        "Weidong Yin",
        "Debing Zhang",
        "Songlin Hu"
      ],
      "abstract": "Large language models (LLMs) have made significant progress in natural\nlanguage understanding and generation, driven by scalable pretraining and\nadvanced finetuning. However, enhancing reasoning abilities in LLMs,\nparticularly via reinforcement learning from human feedback (RLHF), remains\nchallenging due to the scarcity of high-quality preference data, which is\nlabor-intensive to annotate and crucial for reward model (RM) finetuning. To\nalleviate this issue, we introduce CodePMP, a scalable preference model\npretraining (PMP) pipeline that utilizes a large corpus of synthesized\ncode-preference pairs from publicly available high-quality source code. CodePMP\nimproves RM finetuning efficiency by pretraining preference models on\nlarge-scale synthesized code-preference pairs. We evaluate CodePMP on\nmathematical reasoning tasks (GSM8K, MATH) and logical reasoning tasks (ReClor,\nLogiQA2.0), consistently showing significant improvements in reasoning\nperformance of LLMs and highlighting the importance of scalable preference\nmodel pretraining for efficient reward modeling.",
      "tldr_zh": "该研究提出 CodePMP，一种可扩展的偏好模型预训练（PMP）管道，旨在通过合成高质量代码-偏好对来提升大型语言模型（LLMs）的推理能力，解决强化学习从人类反馈（RLHF）中偏好数据稀缺的问题。CodePMP 利用公开源代码生成大规模偏好对，对奖励模型（RM）进行高效预训练，从而改善 LLMs 的微调过程。在数学推理任务（如 GSM8K 和 MATH）和逻辑推理任务（如 ReClor 和 LogiQA2.0）上，实验结果显示 LLMs 的性能显著提升，突显了可扩展 PMP 在高效奖励建模中的重要性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.02229v1",
      "published_date": "2024-10-03 05:51:26 UTC",
      "updated_date": "2024-10-03 05:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:53:18.052038"
    },
    {
      "arxiv_id": "2410.14684v2",
      "title": "RepoGraph: Enhancing AI Software Engineering with Repository-level Code Graph",
      "title_zh": "RepoGraph：通过仓库级代码图增强 AI 软件工程",
      "authors": [
        "Siru Ouyang",
        "Wenhao Yu",
        "Kaixin Ma",
        "Zilin Xiao",
        "Zhihan Zhang",
        "Mengzhao Jia",
        "Jiawei Han",
        "Hongming Zhang",
        "Dong Yu"
      ],
      "abstract": "Large Language Models (LLMs) excel in code generation yet struggle with\nmodern AI software engineering tasks. Unlike traditional function-level or\nfile-level coding tasks, AI software engineering requires not only basic coding\nproficiency but also advanced skills in managing and interacting with code\nrepositories. However, existing methods often overlook the need for\nrepository-level code understanding, which is crucial for accurately grasping\nthe broader context and developing effective solutions. On this basis, we\npresent RepoGraph, a plug-in module that manages a repository-level structure\nfor modern AI software engineering solutions. RepoGraph offers the desired\nguidance and serves as a repository-wide navigation for AI software engineers.\nWe evaluate RepoGraph on the SWE-bench by plugging it into four different\nmethods of two lines of approaches, where RepoGraph substantially boosts the\nperformance of all systems, leading to a new state-of-the-art among open-source\nframeworks. Our analyses also demonstrate the extensibility and flexibility of\nRepoGraph by testing on another repo-level coding benchmark, CrossCodeEval. Our\ncode is available at https://github.com/ozyyshr/RepoGraph.",
      "tldr_zh": "本论文指出，Large Language Models (LLMs) 在代码生成方面表现出色，但处理 AI 软件工程任务时（如管理代码仓库）存在不足，因为现有方法忽略了仓库级别的代码理解。为解决此问题，研究者提出 RepoGraph，一种插件模块，提供仓库级结构作为导航工具，帮助 AI 软件工程师更好地把握整体上下文。实验结果显示，在 SWE-bench 上将 RepoGraph 集成到四种不同方法中，显著提升了所有系统的性能，实现了开源框架的新状态；在 CrossCodeEval 基准上也验证了其可扩展性。该框架的开源代码已在 GitHub 上发布。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.14684v2",
      "published_date": "2024-10-03 05:45:26 UTC",
      "updated_date": "2025-03-18 20:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:53:29.851994"
    },
    {
      "arxiv_id": "2410.02223v2",
      "title": "EmbedLLM: Learning Compact Representations of Large Language Models",
      "title_zh": "EmbedLLM：学习大型语言模型的紧凑表示",
      "authors": [
        "Richard Zhuang",
        "Tianhao Wu",
        "Zhaojin Wen",
        "Andrew Li",
        "Jiantao Jiao",
        "Kannan Ramchandran"
      ],
      "abstract": "With hundreds of thousands of language models available on Huggingface today,\nefficiently evaluating and utilizing these models across various downstream,\ntasks has become increasingly critical. Many existing methods repeatedly learn\ntask-specific representations of Large Language Models (LLMs), which leads to\ninefficiencies in both time and computational resources. To address this, we\npropose EmbedLLM, a framework designed to learn compact vector representations,\nof LLMs that facilitate downstream applications involving many models, such as\nmodel routing. We introduce an encoder-decoder approach for learning such\nembeddings, along with a systematic framework to evaluate their effectiveness.\nEmpirical results show that EmbedLLM outperforms prior methods in model routing\nboth in accuracy and latency. Additionally, we demonstrate that our method can\nforecast a model's performance on multiple benchmarks, without incurring\nadditional inference cost. Extensive probing experiments validate that the\nlearned embeddings capture key model characteristics, e.g. whether the model is\nspecialized for coding tasks, even without being explicitly trained on them. We\nopen source our dataset, code and embedder to facilitate further research and\napplication.",
      "tldr_zh": "这篇论文提出了EmbedLLM框架，用于学习Large Language Models (LLMs)的紧凑向量表示，以高效评估和利用Huggingface上的众多模型，避免重复学习任务特定表示带来的资源浪费。方法采用编码器-解码器方法，并建立系统框架来评估这些嵌入的有效性。实验结果显示，EmbedLLM在模型路由任务中超越现有方法，提高了准确性和降低了延迟，同时能预测模型在多个基准上的性能，而不增加推理成本。进一步的探测实验证明，学到的嵌入捕捉了关键模型特征，如是否专用于编码任务。作者开源了数据集、代码和嵌入器，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02223v2",
      "published_date": "2024-10-03 05:43:24 UTC",
      "updated_date": "2024-10-16 22:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:53:41.684809"
    },
    {
      "arxiv_id": "2410.02220v4",
      "title": "Data to Defense: The Role of Curation in Customizing LLMs Against Jailbreaking Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoqun Liu",
        "Jiacheng Liang",
        "Luoxi Tang",
        "Muchao Ye",
        "Weicheng Ma",
        "Zhaohan Xi"
      ],
      "abstract": "Large language models (LLMs) are widely adapted for downstream applications\nthrough fine-tuning, a process named customization. However, recent studies\nhave identified a vulnerability during this process, where malicious samples\ncan compromise the robustness of LLMs and amplify harmful behaviors-an attack\ncommonly referred to as jailbreaking. To address this challenge, we propose an\nadaptive data curation approach allowing any text to be curated to enhance its\neffectiveness in counteracting harmful samples during customization. To avoid\nthe need for additional defensive modules, we further introduce a comprehensive\nmitigation framework spanning the lifecycle of the customization process:\nbefore customization to immunize LLMs against future jailbreak attempts, during\ncustomization to neutralize risks, and after customization to restore\ncompromised models. Experimental results demonstrate a significant reduction in\njailbreaking effects, achieving up to a 100% success rate in generating safe\nresponses. By combining adaptive data curation with lifecycle-based mitigation\nstrategies, this work represents a solid step forward in mitigating\njailbreaking risks and ensuring the secure adaptation of LLMs.",
      "tldr_zh": "本研究探讨了在自定义大型语言模型（LLMs）过程中，如何通过数据整理（curation）来防御越狱攻击（jailbreaking attacks），以防止恶意样本放大有害行为。论文提出了一种自适应数据整理方法，能够处理任意文本，并在自定义生命周期中引入全面缓解框架，包括自定义前免疫模型、对抗风险以及自定义后修复受损模型。实验结果显示，该框架显著降低了越狱攻击的影响，成功率高达100% 生成安全响应，从而为LLMs 的安全适应提供了重要进展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02220v4",
      "published_date": "2024-10-03 05:24:38 UTC",
      "updated_date": "2025-02-18 05:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:53:55.076984"
    },
    {
      "arxiv_id": "2410.02219v2",
      "title": "Multi-modal clothing recommendation model based on large model and VAE enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Bingjie Huang",
        "Qingyi Lu",
        "Shuaishuai Huang",
        "Xue-she Wang",
        "Haowei Yang"
      ],
      "abstract": "Accurately recommending products has long been a subject requiring in-depth\nresearch. This study proposes a multimodal paradigm for clothing\nrecommendations. Specifically, it designs a multimodal analysis method that\nintegrates clothing description texts and images, utilizing a pre-trained large\nlanguage model to deeply explore the hidden meanings of users and products.\nAdditionally, a variational encoder is employed to learn the relationship\nbetween user information and products to address the cold start problem in\nrecommendation systems. This study also validates the significant performance\nadvantages of this method over various recommendation system methods through\nextensive ablation experiments, providing crucial practical guidance for the\ncomprehensive optimization of recommendation systems.",
      "tldr_zh": "本研究提出了一种基于大型语言模型和VAE增强的多模态服装推荐模型，旨在通过整合服装描述文本和图像来实现更准确的产品推荐。\n该模型利用预训练的大型语言模型深入挖掘用户和产品的隐藏含义，同时采用变分自编码器（VAE）学习用户信息与产品的关系，以有效解决推荐系统的冷启动问题。\n通过广泛的消融实验，该方法在性能上显著优于现有推荐系统方法，并为推荐系统的全面优化提供了关键的实践指导。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02219v2",
      "published_date": "2024-10-03 05:23:39 UTC",
      "updated_date": "2024-10-20 02:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:54:06.930298"
    },
    {
      "arxiv_id": "2410.05292v1",
      "title": "CaLMFlow: Volterra Flow Matching using Causal Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sizhuang He",
        "Daniel Levine",
        "Ivan Vrkic",
        "Marco Francesco Bressana",
        "David Zhang",
        "Syed Asad Rizvi",
        "Yangtian Zhang",
        "Emanuele Zappala",
        "David van Dijk"
      ],
      "abstract": "We introduce CaLMFlow (Causal Language Models for Flow Matching), a novel\nframework that casts flow matching as a Volterra integral equation (VIE),\nleveraging the power of large language models (LLMs) for continuous data\ngeneration. CaLMFlow enables the direct application of LLMs to learn complex\nflows by formulating flow matching as a sequence modeling task, bridging\ndiscrete language modeling and continuous generative modeling. Our method\nimplements tokenization across space and time, thereby solving a VIE over these\ndomains. This approach enables efficient handling of high-dimensional data and\noutperforms ODE solver-dependent methods like conditional flow matching (CFM).\nWe demonstrate CaLMFlow's effectiveness on synthetic and real-world data,\nincluding single-cell perturbation response prediction, showcasing its ability\nto incorporate textual context and generalize to unseen conditions. Our results\nhighlight LLM-driven flow matching as a promising paradigm in generative\nmodeling, offering improved scalability, flexibility, and context-awareness.",
      "tldr_zh": "本文提出 CaLMFlow 框架，将流匹配(flow matching)表述为 Volterra integral equation (VIE)，利用大型语言模型(LLMs)将其转化为序列建模任务，从而桥接离散语言建模和连续生成建模。CaLMFlow 通过空间和时间标记化(tokenization)高效处理高维数据，并优于依赖 ODE 求解器的方法如 conditional flow matching (CFM)。实验在合成和真实数据（如单细胞扰动响应预测）上验证了其有效性，展示了整合文本上下文的能力，并突显 LLM 驱动的流匹配范式在可伸缩性、灵活性和上下文感知方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 9 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.05292v1",
      "published_date": "2024-10-03 05:07:41 UTC",
      "updated_date": "2024-10-03 05:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:54:18.424850"
    },
    {
      "arxiv_id": "2410.14683v1",
      "title": "Brain-Aware Readout Layers in GNNs: Advancing Alzheimer's early Detection and Neuroimaging",
      "title_zh": "翻译失败",
      "authors": [
        "Jiwon Youn",
        "Dong Woo Kang",
        "Hyun Kook Lim",
        "Mansu Kim"
      ],
      "abstract": "Alzheimer's disease (AD) is a neurodegenerative disorder characterized by\nprogressive memory and cognitive decline, affecting millions worldwide.\nDiagnosing AD is challenging due to its heterogeneous nature and variable\nprogression. This study introduces a novel brain-aware readout layer (BA\nreadout layer) for Graph Neural Networks (GNNs), designed to improve\ninterpretability and predictive accuracy in neuroimaging for early AD\ndiagnosis. By clustering brain regions based on functional connectivity and\nnode embedding, this layer improves the GNN's capability to capture complex\nbrain network characteristics. We analyzed neuroimaging data from 383\nparticipants, including both cognitively normal and preclinical AD individuals,\nusing T1-weighted MRI, resting-state fMRI, and FBB-PET to construct brain\ngraphs. Our results show that GNNs with the BA readout layer significantly\noutperform traditional models in predicting the Preclinical Alzheimer's\nCognitive Composite (PACC) score, demonstrating higher robustness and\nstability. The adaptive BA readout layer also offers enhanced interpretability\nby highlighting task-specific brain regions critical to cognitive functions\nimpacted by AD. These findings suggest that our approach provides a valuable\ntool for the early diagnosis and analysis of Alzheimer's disease.",
      "tldr_zh": "本研究针对阿尔茨海默病（AD）的异质性和进展变异性，提出了一种新型脑意识读出层（BA readout layer）用于图神经网络（GNNs），以提升神经影像学中早期AD诊断的可解释性和预测准确性。该层通过基于功能连接和节点嵌入对脑区进行聚类，捕捉复杂的脑网络特征，并利用T1-weighted MRI、静息态fMRI和FBB-PET数据构建脑图，分析了383名参与者的神经影像数据。结果显示，配备BA readout layer的GNNs在预测Preclinical Alzheimer's Cognitive Composite (PACC)分数时显著优于传统模型，具有更高的鲁棒性和稳定性，同时通过突出与AD相关的关键脑区，提高了任务的可解释性。该方法为AD的早期诊断和分析提供了宝贵工具。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14683v1",
      "published_date": "2024-10-03 05:04:45 UTC",
      "updated_date": "2024-10-03 05:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:54:30.574145"
    },
    {
      "arxiv_id": "2410.02207v1",
      "title": "Adapting Segment Anything Model to Melanoma Segmentation in Microscopy Slide Images",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyuan Liu",
        "Avideh Zakhor"
      ],
      "abstract": "Melanoma segmentation in Whole Slide Images (WSIs) is useful for prognosis\nand the measurement of crucial prognostic factors such as Breslow depth and\nprimary invasive tumor size. In this paper, we present a novel approach that\nuses the Segment Anything Model (SAM) for automatic melanoma segmentation in\nmicroscopy slide images. Our method employs an initial semantic segmentation\nmodel to generate preliminary segmentation masks that are then used to prompt\nSAM. We design a dynamic prompting strategy that uses a combination of centroid\nand grid prompts to achieve optimal coverage of the super high-resolution slide\nimages while maintaining the quality of generated prompts. To optimize for\ninvasive melanoma segmentation, we further refine the prompt generation process\nby implementing in-situ melanoma detection and low-confidence region filtering.\nWe select Segformer as the initial segmentation model and EfficientSAM as the\nsegment anything model for parameter-efficient fine-tuning. Our experimental\nresults demonstrate that this approach not only surpasses other\nstate-of-the-art melanoma segmentation methods but also significantly\noutperforms the baseline Segformer by 9.1% in terms of IoU.",
      "tldr_zh": "本文提出一种新方法，将 Segment Anything Model (SAM) 适应于显微镜幻灯片图像中的黑色素瘤分割，以辅助预后评估和关键因素测量。该方法先使用 Segformer 作为初始语义分割模型生成初步掩码，然后通过动态提示策略（结合质心和网格提示）来优化 SAM 的输入，并通过原位黑色素瘤检测和低置信度区域过滤进一步细化提示生成。为了参数高效微调，该方法采用 EfficientSAM 作为核心模型。实验结果显示，该方法在 IoU 上比基线 Segformer 提高了 9.1%，并超过了其他最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02207v1",
      "published_date": "2024-10-03 04:40:18 UTC",
      "updated_date": "2024-10-03 04:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:54:43.361273"
    },
    {
      "arxiv_id": "2410.02205v3",
      "title": "Aligning with Logic: Measuring, Evaluating and Improving Logical Preference Consistency in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yinhong Liu",
        "Zhijiang Guo",
        "Tianya Liang",
        "Ehsan Shareghi",
        "Ivan Vulić",
        "Nigel Collier"
      ],
      "abstract": "Large Language Models (LLMs) are expected to be predictable and trustworthy\nto support reliable decision-making systems. Yet current LLMs often show\ninconsistencies in their judgments. In this work, we examine logical preference\nconsistency as a foundational requirement for building more dependable LLM\nsystems, ensuring stable and coherent decision-making while minimizing erratic\nor contradictory outputs. To quantify the logical preference consistency, we\npropose a universal evaluation framework based on three fundamental properties:\ntransitivity, commutativity and negation invariance. Through extensive\nexperimentation across diverse LLMs, we demonstrate that these properties serve\nas strong indicators of judgment robustness. Furthermore, we introduce a data\nrefinement and augmentation technique, REPAIR, that enhances logical\nconsistency while maintaining alignment with human preferences. Finally, we\nshow that improving consistency leads to better performance in LLM-driven\nlogic-based algorithms, reinforcing stability and coherence in decision-making\nsystems.",
      "tldr_zh": "本研究针对Large Language Models (LLMs) 在判断中存在的逻辑不一致性问题，提出逻辑偏好一致性(logical preference consistency)作为构建可靠决策系统的核心要求。研究者设计了一个通用评估框架，基于transitivity（传递性）、commutativity（交换性）和negation invariance（否定不变性）三项属性，对多种LLMs进行广泛实验，以量化并证明这些属性能有效指示判断的稳健性。同时，引入REPAIR数据精炼和增强技术，提升LLMs的逻辑一致性，同时保持与人类偏好的对齐。最后，实验结果显示，提高一致性显著改善了LLM驱动的逻辑基于算法的表现，提升了决策系统的稳定性和连贯性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02205v3",
      "published_date": "2024-10-03 04:34:04 UTC",
      "updated_date": "2025-02-09 17:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:54:53.359863"
    },
    {
      "arxiv_id": "2410.02203v3",
      "title": "GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiale Fu",
        "Yaqing Wang",
        "Simeng Han",
        "Jiaming Fan",
        "Xu Yang"
      ],
      "abstract": "In-context learning (ICL) enhances large language models (LLMs) by\nincorporating demonstration examples, yet its effectiveness heavily depends on\nthe quality of selected examples. Current methods typically use text embeddings\nto measure semantic similarity, which often introduces bias in multi-step\nreasoning tasks. This occurs because text embeddings contain irrelevant\nsemantic information and lack deeper reasoning structures. To address this, we\npropose GraphIC, a graph-based retrieval model that leverages reasoning-aware\nrepresentation and specialized similarity metric for in-context example\nretrieval. GraphIC first constructs thought graphs-directed, node-attributed\ngraphs that explicitly model reasoning steps and their dependencies-for\ncandidate examples and queries. This approach filters out superficial semantics\nwhile preserving essential reasoning processes. Next, GraphIC retrieves\nexamples using a novel similarity metric tailored for these graphs, capturing\nsequential reasoning patterns and asymmetry between examples. Comprehensive\nevaluations across mathematical reasoning, code generation, and logical\nreasoning tasks demonstrate that GraphIC outperforms 10 baseline methods. Our\nresults highlight the importance of reasoning-aware retrieval in ICL, offering\na robust solution for enhancing LLM performance in multi-step reasoning\nscenarios.",
      "tldr_zh": "该研究针对In-context learning (ICL)中示例检索的质量问题，提出GraphIC模型，以解决传统文本嵌入方法在多步推理任务中引入的语义偏差。GraphIC通过构建thought graphs——一种有向、节点属性的图结构，来显式建模推理步骤及其依赖关系，从而过滤无关语义并保留核心推理过程。接着，该模型采用专属的相似性指标，捕捉顺序推理模式和不对称性，用于检索最相关示例。实验结果显示，GraphIC在数学推理、代码生成和逻辑推理任务上优于10个基线方法，证明了reasoning-aware retrieval对提升LLM在多步推理场景中的性能具有重要价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02203v3",
      "published_date": "2024-10-03 04:33:02 UTC",
      "updated_date": "2025-02-25 03:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:55:07.036220"
    },
    {
      "arxiv_id": "2410.02202v1",
      "title": "Can Language Models Take A Hint? Prompting for Controllable Contextualized Commonsense Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Colon-Hernandez",
        "Nanxi Liu",
        "Chelsea Joe",
        "Peter Chin",
        "Claire Yin",
        "Henry Lieberman",
        "Yida Xin",
        "Cynthia Breazeal"
      ],
      "abstract": "Generating commonsense assertions within a given story context remains a\ndifficult task for modern language models. Previous research has addressed this\nproblem by aligning commonsense inferences with stories and training language\ngeneration models accordingly. One of the challenges is determining which topic\nor entity in the story should be the focus of an inferred assertion. Prior\napproaches lack the ability to control specific aspects of the generated\nassertions. In this work, we introduce \"hinting,\" a data augmentation technique\nthat enhances contextualized commonsense inference. \"Hinting\" employs a prefix\nprompting strategy using both hard and soft prompts to guide the inference\nprocess. To demonstrate its effectiveness, we apply \"hinting\" to two contextual\ncommonsense inference datasets: ParaCOMET and GLUCOSE, evaluating its impact on\nboth general and context-specific inference. Furthermore, we evaluate \"hinting\"\nby incorporating synonyms and antonyms into the hints. Our results show that\n\"hinting\" does not compromise the performance of contextual commonsense\ninference while offering improved controllability.",
      "tldr_zh": "本研究探讨了语言模型在生成故事上下文中的常识推理（commonsense inference）时，如何通过提示（prompting）实现更好的可控性。作者引入了“hinting”数据增强技术，使用前缀提示策略（包括硬提示和软提示）来引导模型焦点于特定主题或实体，从而解决现有方法缺乏控制的问题。该技术被应用于ParaCOMET和GLUCOSE数据集，并通过融入同义词和反义词进行扩展实验，结果显示“hinting”提高了推理的可控性，同时不影响整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to ACL Rolling Review. arXiv admin note: text overlap with\n  arXiv:2302.05406",
      "pdf_url": "http://arxiv.org/pdf/2410.02202v1",
      "published_date": "2024-10-03 04:32:46 UTC",
      "updated_date": "2024-10-03 04:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:55:17.548991"
    },
    {
      "arxiv_id": "2410.02198v1",
      "title": "G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoning Yu",
        "Xiangyang Xu",
        "Hongyang Gao"
      ],
      "abstract": "We introduce G2T-LLM, a novel approach for molecule generation that uses\ngraph-to-tree text encoding to transform graph-based molecular structures into\na hierarchical text format optimized for large language models (LLMs). This\nencoding converts complex molecular graphs into tree-structured formats, such\nas JSON and XML, which LLMs are particularly adept at processing due to their\nextensive pre-training on these types of data. By leveraging the flexibility of\nLLMs, our approach allows for intuitive interaction using natural language\nprompts, providing a more accessible interface for molecular design. Through\nsupervised fine-tuning, G2T-LLM generates valid and coherent chemical\nstructures, addressing common challenges like invalid outputs seen in\ntraditional graph-based methods. While LLMs are computationally intensive, they\noffer superior generalization and adaptability, enabling the generation of\ndiverse molecular structures with minimal task-specific customization. The\nproposed approach achieved comparable performances with state-of-the-art\nmethods on various benchmark molecular generation datasets, demonstrating its\npotential as a flexible and innovative tool for AI-driven molecular design.",
      "tldr_zh": "我们提出 G2T-LLM，一种创新方法，通过 Graph-to-Tree 文本编码将分子图结构转换为树状格式（如 JSON 和 XML），以优化大型语言模型 (LLMs) 的处理能力，从而实现高效的分子生成。\n该方法利用 LLMs 的预训练优势，支持自然语言提示的直观交互，并通过监督微调生成有效且连贯的化学结构，解决了传统图-based 方法的无效输出问题。\n实验结果表明，G2T-LLM 在多个基准分子生成数据集上与最先进技术表现出可比性能，提供更强的泛化和适应性，为 AI 驱动的分子设计提供了灵活工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02198v1",
      "published_date": "2024-10-03 04:25:21 UTC",
      "updated_date": "2024-10-03 04:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:55:30.302288"
    },
    {
      "arxiv_id": "2410.02197v2",
      "title": "Beyond Bradley-Terry Models: A General Preference Model for Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Zhang",
        "Ge Zhang",
        "Yue Wu",
        "Kangping Xu",
        "Quanquan Gu"
      ],
      "abstract": "Modeling human preferences is crucial for aligning foundation models with\nhuman values. Traditional reward modeling methods, such as the Bradley-Terry\n(BT) reward model, fall short in expressiveness, particularly in addressing\nintransitive preferences. In this paper, we introduce preference embedding, an\napproach that embeds responses into a latent space to capture intricate\npreference structures efficiently, achieving linear query complexity.\nAdditionally, we propose preference score-based General Preference Optimization\n(GPO), which generalizes reward-based reinforcement learning from human\nfeedback (RLHF). Experimental results show that our General Preference\nembedding Model (GPM) consistently outperforms the BT reward model on the\nRewardBench benchmark and effectively models cyclic preferences where any BT\nreward model behaves like a random guess. Furthermore, evaluations on\ndownstream tasks such as AlpacaEval2.0, following the language model\npost-training with GPO and our general preference model, reveal performance\nimprovements over BT models. These findings indicate that our method may\nenhance the alignment of foundation models with nuanced human values. The code\nis available at https://github.com/general-preference/general-preference-model.",
      "tldr_zh": "本论文超越传统的 Bradley-Terry (BT) 奖励模型，提出了一种通用偏好模型，用于更好地对齐语言模型与人类价值观。该模型引入 preference embedding 方法，将响应嵌入潜在空间，以高效捕获复杂的偏好结构（如非传递偏好），并开发了 General Preference Optimization (GPO)，这是一种基于偏好得分的 reinforcement learning from human feedback (RLHF) 泛化。实验结果显示，General Preference Model (GPM) 在 RewardBench 基准上 consistently 优于 BT 模型，并在处理 cyclic preferences 时表现出色，而 BT 模型表现如随机猜测；在 AlpacaEval2.0 等下游任务中，使用 GPO 进行语言模型后训练后，性能得到显著提升。这些发现表明，该方法可增强基础模型对细微人类价值观的校准。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02197v2",
      "published_date": "2024-10-03 04:22:55 UTC",
      "updated_date": "2025-02-17 20:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:55:44.033107"
    },
    {
      "arxiv_id": "2410.02195v1",
      "title": "BACKTIME: Backdoor Attacks on Multivariate Time Series Forecasting",
      "title_zh": "BACK",
      "authors": [
        "Xiao Lin",
        "Zhining Liu",
        "Dongqi Fu",
        "Ruizhong Qiu",
        "Hanghang Tong"
      ],
      "abstract": "Multivariate Time Series (MTS) forecasting is a fundamental task with\nnumerous real-world applications, such as transportation, climate, and\nepidemiology. While a myriad of powerful deep learning models have been\ndeveloped for this task, few works have explored the robustness of MTS\nforecasting models to malicious attacks, which is crucial for their trustworthy\nemployment in high-stake scenarios. To address this gap, we dive deep into the\nbackdoor attacks on MTS forecasting models and propose an effective attack\nmethod named BackTime.By subtly injecting a few stealthy triggers into the MTS\ndata, BackTime can alter the predictions of the forecasting model according to\nthe attacker's intent. Specifically, BackTime first identifies vulnerable\ntimestamps in the data for poisoning, and then adaptively synthesizes stealthy\nand effective triggers by solving a bi-level optimization problem with a\nGNN-based trigger generator. Extensive experiments across multiple datasets and\nstate-of-the-art MTS forecasting models demonstrate the effectiveness,\nversatility, and stealthiness of \\method{} attacks. The code is available at\n\\url{https://github.com/xiaolin-cs/BackTime}.",
      "tldr_zh": "本文研究了多变量时间序列 (Multivariate Time Series, MTS) 预测模型对后门攻击的鲁棒性问题，并提出了一种名为 BackTime 的攻击方法，用于在 MTS 数据中注入隐秘触发器，以根据攻击者意图改变模型预测。BackTime 通过识别易受攻击的时间戳，并利用基于 GNN 的触发器生成器解决双层优化问题，合成高效且隐秘的触发器。实验在多个数据集和最先进 MTS 预测模型上验证了 BackTime 攻击的有效性、多功能性和隐秘性，为评估模型安全性和可靠性提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages. Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.02195v1",
      "published_date": "2024-10-03 04:16:49 UTC",
      "updated_date": "2024-10-03 04:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:55:54.020558"
    },
    {
      "arxiv_id": "2410.02191v2",
      "title": "A Survey on Point-of-Interest Recommendation: Models, Architectures, and Security",
      "title_zh": "关于兴趣点推荐的调查：模型、架构和安全",
      "authors": [
        "Qianru Zhang",
        "Peng Yang",
        "Junliang Yu",
        "Haixin Wang",
        "Xingwei He",
        "Siu-Ming Yiu",
        "Hongzhi Yin"
      ],
      "abstract": "The widespread adoption of smartphones and Location-Based Social Networks has\nled to a massive influx of spatio-temporal data, creating unparalleled\nopportunities for enhancing Point-of-Interest (POI) recommendation systems.\nThese advanced POI systems are crucial for enriching user experiences, enabling\npersonalized interactions, and optimizing decision-making processes in the\ndigital landscape. However, existing surveys tend to focus on traditional\napproaches and few of them delve into cutting-edge developments, emerging\narchitectures, as well as security considerations in POI recommendations. To\naddress this gap, our survey stands out by offering a comprehensive, up-to-date\nreview of POI recommendation systems, covering advancements in models,\narchitectures, and security aspects. We systematically examine the transition\nfrom traditional models to advanced techniques such as large language models.\nAdditionally, we explore the architectural evolution from centralized to\ndecentralized and federated learning systems, highlighting the improvements in\nscalability and privacy. Furthermore, we address the increasing importance of\nsecurity, examining potential vulnerabilities and privacy-preserving\napproaches. Our taxonomy provides a structured overview of the current state of\nPOI recommendation, while we also identify promising directions for future\nresearch in this rapidly advancing field.",
      "tldr_zh": "这篇调查综述了Point-of-Interest (POI)推荐系统的最新进展，聚焦于模型、架构和安全方面，以填补现有研究对前沿技术的忽略。论文系统考察了从传统模型到Large Language Models (LLMs)的演变，以及从集中式到Federated Learning系统的架构转变，这些改进提升了系统的可扩展性和隐私保护。最终，它分析了潜在安全漏洞和隐私策略，并为POI推荐领域的未来研究提供了有前景的方向。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02191v2",
      "published_date": "2024-10-03 04:11:42 UTC",
      "updated_date": "2025-03-10 02:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:56:05.956119"
    },
    {
      "arxiv_id": "2410.02189v2",
      "title": "Agent-Oriented Planning in Multi-Agent Systems",
      "title_zh": "多智能体系统中的代理导向规划",
      "authors": [
        "Ao Li",
        "Yuexiang Xie",
        "Songze Li",
        "Fugee Tsung",
        "Bolin Ding",
        "Yaliang Li"
      ],
      "abstract": "Through the collaboration of multiple LLM-empowered agents possessing diverse\nexpertise and tools, multi-agent systems achieve impressive progress in solving\nreal-world problems. Given the user queries, the meta-agents, serving as the\nbrain within multi-agent systems, are required to decompose the queries into\nmultiple sub-tasks that can be allocated to suitable agents capable of solving\nthem, so-called agent-oriented planning. In this study, we identify three\ncritical design principles of agent-oriented planning, including solvability,\ncompleteness, and non-redundancy, to ensure that each sub-task can be\neffectively resolved, resulting in satisfactory responses to user queries.\nThese principles further inspire us to propose AOP, a novel framework for\nagent-oriented planning in multi-agent systems, leveraging a fast task\ndecomposition and allocation process followed by an effective and efficient\nevaluation via a reward model. According to the evaluation results, the\nmeta-agent is also responsible for promptly making necessary adjustments to\nsub-tasks and scheduling. Besides, we integrate a feedback loop into AOP to\nfurther enhance the effectiveness and robustness of such a problem-solving\nprocess. Extensive experiments demonstrate the advancement of AOP in solving\nreal-world problems compared to both single-agent systems and existing planning\nstrategies for multi-agent systems. The source code is available at\nhttps://github.com/lalaliat/Agent-Oriented-Planning",
      "tldr_zh": "本研究探讨了多智能体系统中的Agent-Oriented Planning，强调元代理(meta-agents)将用户查询分解为子任务并分配给合适代理，以提升问题解决效率。论文提出AOP框架，基于三个关键设计原则——solvability（可解决性）、completeness（完整性）和non-redundancy（非冗余）——结合快速任务分解、奖励模型评估以及反馈循环，实现子任务的动态调整和调度。实验结果显示，AOP在处理真实世界问题时，优于单代理系统和现有规划策略，进一步提升了多智能体系统的整体性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICLR'2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02189v2",
      "published_date": "2024-10-03 04:07:51 UTC",
      "updated_date": "2025-03-11 11:22:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:56:21.135738"
    },
    {
      "arxiv_id": "2410.02185v2",
      "title": "POSIX: A Prompt Sensitivity Index For Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anwoy Chatterjee",
        "H S V N S Kowndinya Renduchintala",
        "Sumit Bhatia",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) are found\nto be surprisingly sensitive to minor variations in prompts, often generating\nsignificantly divergent outputs in response to minor variations in the prompts,\nsuch as spelling errors, alteration of wording or the prompt template. However,\nwhile assessing the quality of an LLM, the focus often tends to be solely on\nits performance on downstream tasks, while very little to no attention is paid\nto prompt sensitivity. To fill this gap, we propose POSIX - a novel PrOmpt\nSensitivity IndeX as a reliable measure of prompt sensitivity, thereby offering\na more comprehensive evaluation of LLM performance. The key idea behind POSIX\nis to capture the relative change in loglikelihood of a given response upon\nreplacing the corresponding prompt with a different intent-preserving prompt.\nWe provide thorough empirical evidence demonstrating the efficacy of POSIX in\ncapturing prompt sensitivity and subsequently use it to measure and thereby\ncompare prompt sensitivity of various open-source LLMs. We find that merely\nincreasing the parameter count or instruction tuning does not necessarily\nreduce prompt sensitivity whereas adding some few-shot exemplars, even just\none, almost always leads to significant decrease in prompt sensitivity. We also\nfind that alterations to prompt template lead to the highest sensitivity in the\ncase of MCQ type tasks, whereas paraphrasing results in the highest sensitivity\nin open-ended generation tasks. The code for reproducing our results is\nopen-sourced at https://github.com/kowndinya-renduchintala/POSIX.",
      "tldr_zh": "这篇论文提出了 POSIX（A Prompt Sensitivity Index），一个用于评估大型语言模型(LLMs)对提示微小变化（如拼写错误或措辞调整）的敏感性指标，以弥补现有评估的不足。POSIX 通过计算给定响应在不同意图保持提示下的 loglikelihood 相对变化来量化敏感性，并通过实验证明了其有效性。研究发现，增加模型参数数量或进行指令微调并不一定降低敏感性，而添加少量 few-shot 示例（如仅一个）能显著减少敏感性。此外，MCQ 任务对提示模板改变最敏感，而开放生成任务对改述变化最敏感。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2410.02185v2",
      "published_date": "2024-10-03 04:01:14 UTC",
      "updated_date": "2024-10-04 07:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:56:30.481688"
    },
    {
      "arxiv_id": "2410.02173v1",
      "title": "Efficiently Deploying LLMs with Controlled Risk",
      "title_zh": "翻译失败",
      "authors": [
        "Michael J. Zellinger",
        "Matt Thomson"
      ],
      "abstract": "Deploying large language models in production requires simultaneous attention\nto efficiency and risk control. Prior work has shown the possibility to cut\ncosts while maintaining similar accuracy, but has neglected to focus on risk\ncontrol. By contrast, here we present hierarchical chains with multi-level\nabstention (HCMA), which use model-intrinsic uncertainty to delegate queries\nalong the LLM intelligence hierarchy, enabling training-free model switching\nbased solely on black-box API calls. Our framework presents novel trade-offs\nbetween efficiency and risk. For example, deploying HCMA on MMLU cuts the error\nrate of Llama3 405B by 30% when the model is allowed to abstain on 20% of the\nqueries. To calibrate HCMA for optimal performance, our approach uses\ndata-efficient logistic regressions (based on a simple nonlinear feature\ntransformation), which require only 50 or 100 labeled examples to achieve\nexcellent calibration error (ECE), cutting ECE by 50% compared to naive Platt\nscaling. On free-form generation tasks, we find that chain-of-thought is\nineffectual for selective prediction, whereas zero-shot prompting drives error\nto 0% on TruthfulQA at high abstention rates. As LLMs are increasingly deployed\nacross computing environments with different capabilities (such as mobile,\nlaptop, and cloud), our framework paves the way towards maintaining deployment\nefficiency while putting in place sharp risk controls.",
      "tldr_zh": "该论文提出了一种名为 hierarchical chains with multi-level abstention (HCMA) 的框架，用于高效部署大型语言模型 (LLMs) 同时控制风险，通过模型内在不确定性在 LLM 智能层次中委托查询，实现无需训练的模型切换，仅依赖黑箱 API 调用。HCMA 利用数据高效的 logistic regressions（基于简单非线性特征转换）进行校准，仅需 50 或 100 个标记样本，即可将 calibration error (ECE) 降低 50%，并在 MMLU 测试中使 Llama3 405B 的错误率在 20% 查询弃权率下降低 30%。在自由形式生成任务中，研究发现 chain-of-thought 对于选择性预测无效，而 zero-shot prompting 能在 TruthfulQA 上将错误率降至 0% 在高弃权率下；总体上，该框架为在不同计算环境（如移动、云端）中部署 LLMs 提供了平衡效率与风险的创新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02173v1",
      "published_date": "2024-10-03 03:25:56 UTC",
      "updated_date": "2024-10-03 03:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:56:43.966261"
    },
    {
      "arxiv_id": "2410.02172v1",
      "title": "Abstract Reward Processes: Leveraging State Abstraction for Consistent Off-Policy Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Shreyas Chaudhari",
        "Ameet Deshpande",
        "Bruno Castro da Silva",
        "Philip S. Thomas"
      ],
      "abstract": "Evaluating policies using off-policy data is crucial for applying\nreinforcement learning to real-world problems such as healthcare and autonomous\ndriving. Previous methods for off-policy evaluation (OPE) generally suffer from\nhigh variance or irreducible bias, leading to unacceptably high prediction\nerrors. In this work, we introduce STAR, a framework for OPE that encompasses a\nbroad range of estimators -- which include existing OPE methods as special\ncases -- that achieve lower mean squared prediction errors. STAR leverages\nstate abstraction to distill complex, potentially continuous problems into\ncompact, discrete models which we call abstract reward processes (ARPs).\nPredictions from ARPs estimated from off-policy data are provably consistent\n(asymptotically correct). Rather than proposing a specific estimator, we\npresent a new framework for OPE and empirically demonstrate that estimators\nwithin STAR outperform existing methods. The best STAR estimator outperforms\nbaselines in all twelve cases studied, and even the median STAR estimator\nsurpasses the baselines in seven out of the twelve cases.",
      "tldr_zh": "本研究针对强化学习中的离策略评估（Off-Policy Evaluation, OPE），提出 STAR 框架，以解决现有方法的高方差和不可减少偏差问题。STAR 通过状态抽象（State Abstraction）将复杂问题简化为紧凑的离散模型，即抽象奖励过程（Abstract Reward Processes, ARPs），并证明从离策略数据估计的 ARPs 是渐进一致的。该框架涵盖多种估计器，包括现有方法作为特例，并在 12 个案例中实验证明，STAR 的最佳估计器全面优于基线，而中位估计器在 7 个案例中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Thirty-eighth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.02172v1",
      "published_date": "2024-10-03 03:19:43 UTC",
      "updated_date": "2024-10-03 03:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:56:55.099010"
    },
    {
      "arxiv_id": "2410.02165v1",
      "title": "A LLM-Powered Automatic Grading Framework with Human-Level Guidelines Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Chu",
        "Hang Li",
        "Kaiqi Yang",
        "Harry Shomer",
        "Hui Liu",
        "Yasemin Copur-Gencturk",
        "Jiliang Tang"
      ],
      "abstract": "Open-ended short-answer questions (SAGs) have been widely recognized as a\npowerful tool for providing deeper insights into learners' responses in the\ncontext of learning analytics (LA). However, SAGs often present challenges in\npractice due to the high grading workload and concerns about inconsistent\nassessments. With recent advancements in natural language processing (NLP),\nautomatic short-answer grading (ASAG) offers a promising solution to these\nchallenges. Despite this, current ASAG algorithms are often limited in\ngeneralizability and tend to be tailored to specific questions. In this paper,\nwe propose a unified multi-agent ASAG framework, GradeOpt, which leverages\nlarge language models (LLMs) as graders for SAGs. More importantly, GradeOpt\nincorporates two additional LLM-based agents - the reflector and the refiner -\ninto the multi-agent system. This enables GradeOpt to automatically optimize\nthe original grading guidelines by performing self-reflection on its errors.\nThrough experiments on a challenging ASAG task, namely the grading of\npedagogical content knowledge (PCK) and content knowledge (CK) questions,\nGradeOpt demonstrates superior performance in grading accuracy and behavior\nalignment with human graders compared to representative baselines. Finally,\ncomprehensive ablation studies confirm the effectiveness of the individual\ncomponents designed in GradeOpt.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型 (LLMs) 的自动短答题评分框架 GradeOpt，以解决开放式短答题 (SAGs) 在学习分析中的评分工作量大和一致性问题。GradeOpt 采用 multi-agent 系统，包括 grader、reflector 和 refiner 代理，通过自我反思机制自动优化评分指南，提升评分准确性和与人类评分者的行为一致性。在实验中，该框架在教学内容知识 (PCK) 和内容知识 (CK) 问题上比基线模型表现出色，消融研究进一步验证了其各组件的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02165v1",
      "published_date": "2024-10-03 03:11:24 UTC",
      "updated_date": "2024-10-03 03:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:57:06.990478"
    },
    {
      "arxiv_id": "2410.03775v3",
      "title": "Beyond correlation: The Impact of Human Uncertainty in Measuring the Effectiveness of Automatic Evaluation and LLM-as-a-Judge",
      "title_zh": "翻译失败",
      "authors": [
        "Aparna Elangovan",
        "Lei Xu",
        "Jongwoo Ko",
        "Mahsa Elyasi",
        "Ling Liu",
        "Sravan Bodapati",
        "Dan Roth"
      ],
      "abstract": "The effectiveness of automatic evaluation of generative models is typically\nmeasured by comparing the labels generated via automation with labels by humans\nusing correlation metrics. However, metrics like Krippendorff's $\\alpha$ and\nRandolph's $\\kappa$ were originally designed to measure the reliability of\nhuman labeling, thus make assumptions about typical human labeling behavior,\nand these assumptions may not be applicable to machine generated labels. In\nthis paper, we show how *relying on a single aggregate correlation score* can\nobscure fundamental differences between human labels and those from automatic\nevaluation, including LLM-as-a-Judge. Specifically, we demonstrate that when\nthe proportion of samples with variation or uncertainty in human assigned\nlabels is relatively high, machine labels (generated by automatic evaluation\nmethods) may superficially appear to have similar or better correlation with\nthe human majority label compared to the human-to-human (HH) correlation. This\ncan create the illusion that labels from automatic evaluation approximates the\nhuman majority label. However, as the proportion of samples with consistent\nhuman labels increases, the correlation between machine and human labels fall\nwell below HH correlation. Based on these findings, we first propose\nstratifying data by human label uncertainty to provide a more robust analysis\nof automatic evaluation performance. Second, recognizing that uncertainty and\nvariation are inherent in perception-based human evaluations, such as those\ninvolving attitudes or preferences, we introduce a new metric - binned\nJensen-Shannon Divergence for perception for such scenarios to better measure\nthe effectiveness of automatic evaluations. We present visualization techniques\n-- perception charts, to contextualize correlation measures appropriately. We\nhave open-sourced at https://github.com/amazon-science/BeyondCorrelation.",
      "tldr_zh": "该研究揭示了使用相关性指标（如 Krippendorff's α 和 Randolph's κ）评估自动评估和 LLM-as-a-Judge 有效性的局限性，因为这些指标基于人类标签假设，而忽略了人类不确定性的影响，导致机器标签可能虚假地显示出高相关性。论文发现，当人类标签不确定性较高时，机器标签与人类多数标签的相关性可能看似优于人类间（HH）相关性；但当人类标签一致性增加时，机器标签的相关性会显著下降。针对此问题，研究提出根据人类标签不确定性分层数据，并引入 binned Jensen-Shannon Divergence for perception 作为新指标，以更好地衡量感知-based 评估的性能；同时，提供 perception charts 等可视化技术来辅助分析。该工作已开源，旨在为更robust的自动评估方法提供基础。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03775v3",
      "published_date": "2024-10-03 03:08:29 UTC",
      "updated_date": "2025-01-27 07:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:57:19.315127"
    },
    {
      "arxiv_id": "2410.02162v1",
      "title": "Planning in Strawberry Fields: Evaluating and Improving the Planning and Scheduling Capabilities of LRM o1",
      "title_zh": "翻译失败",
      "authors": [
        "Karthik Valmeekam",
        "Kaya Stechly",
        "Atharva Gundawar",
        "Subbarao Kambhampati"
      ],
      "abstract": "The ability to plan a course of action that achieves a desired state of\naffairs has long been considered a core competence of intelligent agents and\nhas been an integral part of AI research since its inception. With the advent\nof large language models (LLMs), there has been considerable interest in the\nquestion of whether or not they possess such planning abilities, but -- despite\nthe slew of new private and open source LLMs since GPT3 -- progress has\nremained slow. OpenAI claims that their recent o1 (Strawberry) model has been\nspecifically constructed and trained to escape the normal limitations of\nautoregressive LLMs -- making it a new kind of model: a Large Reasoning Model\n(LRM). In this paper, we evaluate the planning capabilities of two LRMs\n(o1-preview and o1-mini) on both planning and scheduling benchmarks. We see\nthat while o1 does seem to offer significant improvements over autoregressive\nLLMs, this comes at a steep inference cost, while still failing to provide any\nguarantees over what it generates. We also show that combining o1 models with\nexternal verifiers -- in a so-called LRM-Modulo system -- guarantees the\ncorrectness of the combined system's output while further improving\nperformance.",
      "tldr_zh": "这篇论文评估了OpenAI的Large Reasoning Model (LRM) o1（包括o1-preview和o1-mini）在规划和调度任务上的能力，比较其与传统autoregressive LLMs的性能差异。研究发现，o1模型虽在基准测试中表现出显著改善，但推理成本高昂，且无法保证生成结果的准确性。为解决这一问题，作者提出LRM-Modulo系统，将o1模型与外部验证器结合，确保输出正确性并进一步提升整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2409.13373",
      "pdf_url": "http://arxiv.org/pdf/2410.02162v1",
      "published_date": "2024-10-03 03:04:36 UTC",
      "updated_date": "2024-10-03 03:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:57:29.513717"
    },
    {
      "arxiv_id": "2410.02160v1",
      "title": "RiskSEA : A Scalable Graph Embedding for Detecting On-chain Fraudulent Activities on the Ethereum Blockchain",
      "title_zh": "RiskSEA：一种可扩展的图嵌入，用于检测以太坊区块链上的链上欺诈活动",
      "authors": [
        "Ayush Agarwal",
        "Lv Lu",
        "Arjun Maheswaran",
        "Varsha Mahadevan",
        "Bhaskar Krishnamachari"
      ],
      "abstract": "Like any other useful technology, cryptocurrencies are sometimes used for\ncriminal activities. While transactions are recorded on the blockchain, there\nexists a need for a more rapid and scalable method to detect addresses\nassociated with fraudulent activities. We present RiskSEA, a scalable risk\nscoring system capable of effectively handling the dynamic nature of\nlarge-scale blockchain transaction graphs. The risk scoring system, which we\nimplement for Ethereum, consists of 1. a scalable approach to generating\nnode2vec embedding for entire set of addresses to capture the graph topology 2.\ntransaction-based features to capture the transactional behavioral pattern of\nan address 3. a classifier model to generate risk score for addresses that\ncombines the node2vec embedding and behavioral features. Efficiently generating\nnode2vec embedding for large scale and dynamically evolving blockchain\ntransaction graphs is challenging, we present two novel approaches for\ngenerating node2vec embeddings and effectively scaling it to the entire set of\nblockchain addresses: 1. node2vec embedding propagation and 2. dynamic node2vec\nembedding. We present a comprehensive analysis of the proposed approaches. Our\nexperiments show that combining both behavioral and node2vec features boosts\nthe classification performance significantly, and that the dynamic node2vec\nembeddings perform better than the node2vec propagated embeddings.",
      "tldr_zh": "这篇论文提出了 RiskSEA，一种可扩展的风险评分系统，用于检测以太坊区块链上的欺诈活动，通过结合 node2vec 嵌入和基于交易的行为特征来生成地址风险分数。系统包括三部分：使用 node2vec 生成图拓扑嵌入、提取交易行为模式，以及训练分类器融合这些特征。作者引入了两种新颖方法——node2vec 嵌入传播和动态 node2vec 嵌入，以高效处理大规模动态区块链图。实验显示，结合行为特征和 node2vec 嵌入显著提升了分类性能，且动态嵌入比传播嵌入表现更好。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "arXiv admin note: text overlap with arXiv:2203.12363 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2410.02160v1",
      "published_date": "2024-10-03 02:54:19 UTC",
      "updated_date": "2024-10-03 02:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:57:43.270890"
    },
    {
      "arxiv_id": "2410.02159v2",
      "title": "Mitigating Memorization In Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mansi Sakarvadia",
        "Aswathy Ajith",
        "Arham Khan",
        "Nathaniel Hudson",
        "Caleb Geniesse",
        "Kyle Chard",
        "Yaoqing Yang",
        "Ian Foster",
        "Michael W. Mahoney"
      ],
      "abstract": "Language models (LMs) can \"memorize\" information, i.e., encode training data\nin their weights in such a way that inference-time queries can lead to verbatim\nregurgitation of that data. This ability to extract training data can be\nproblematic, for example, when data are private or sensitive. In this work, we\ninvestigate methods to mitigate memorization: three regularizer-based, three\nfinetuning-based, and eleven machine unlearning-based methods, with five of the\nlatter being new methods that we introduce. We also introduce TinyMem, a suite\nof small, computationally-efficient LMs for the rapid development and\nevaluation of memorization-mitigation methods. We demonstrate that the\nmitigation methods that we develop using TinyMem can successfully be applied to\nproduction-grade LMs, and we determine via experiment that: regularizer-based\nmitigation methods are slow and ineffective at curbing memorization;\nfine-tuning-based methods are effective at curbing memorization, but overly\nexpensive, especially for retaining higher accuracies; and unlearning-based\nmethods are faster and more effective, allowing for the precise localization\nand removal of memorized information from LM weights prior to inference. We\nshow, in particular, that our proposed unlearning method BalancedSubnet\noutperforms other mitigation methods at removing memorized information while\npreserving performance on target tasks.",
      "tldr_zh": "本文研究了语言模型(LMs)中“记忆”问题的缓解策略，以防止模型在推理时泄露训练数据，尤其是涉及隐私敏感信息。作者调查了三种基于正则化的、三种基于微调的，以及十一种基于机器遗忘的方法（其中五种为新方法），并引入了TinyMem工具——一个小型、高效的LMs套件，用于快速开发和评估这些方法。实验结果表明，正则化方法缓慢且无效，微调方法虽有效但成本过高且可能降低准确性，而机器遗忘方法更快速且精确；特别是提出的BalancedSubnet方法在移除记忆信息的同时，优于其他方法并保持了目标任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02159v2",
      "published_date": "2024-10-03 02:53:51 UTC",
      "updated_date": "2025-01-28 21:19:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:57:54.290850"
    },
    {
      "arxiv_id": "2410.02156v2",
      "title": "The why, what, and how of AI-based coding in scientific research",
      "title_zh": "翻译失败",
      "authors": [
        "Tonghe Zhuang",
        "Zhicheng Lin"
      ],
      "abstract": "Computer programming (coding) is indispensable for researchers across\ndisciplines, yet it remains challenging to learn and time-consuming to carry\nout. Generative AI, particularly large language models (LLMs), has the\npotential to transform coding into intuitive conversations, but best practices\nand effective workflows are only emerging. We dissect AI-based coding through\nthree key lenses: the nature and role of LLMs in coding (why), six types of\ncoding assistance they provide (what), and a five-step workflow in action with\npractical implementation strategies (how). Additionally, we address the\nlimitations and future outlook of AI in coding. By offering actionable\ninsights, this framework helps to guide researchers in effectively leveraging\nAI to enhance coding practices and education, accelerating scientific progress.",
      "tldr_zh": "这篇论文探讨了 AI 尤其是大型语言模型 (LLMs) 在科学研究的编程中的作用，旨在解决编程学习和执行的挑战，将其转化为直观的对话。论文从三个角度分析：LLMs 的本质和作用 (why)、它们提供的六种编码辅助类型 (what)，以及一个五步工作流程及其实际实施策略 (how)。此外，它还讨论了 AI 在编码中的限制和未来展望，并提供可操作的见解，帮助研究人员有效利用 AI 提升编程实践和教育，从而加速科学进步。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.CY",
      "comment": "23 pages, 7 figure, 3 boxes",
      "pdf_url": "http://arxiv.org/pdf/2410.02156v2",
      "published_date": "2024-10-03 02:36:30 UTC",
      "updated_date": "2024-11-18 07:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:58:06.240037"
    },
    {
      "arxiv_id": "2410.02155v3",
      "title": "From Pixels to Tokens: Byte-Pair Encoding on Quantized Visual Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Wanpeng Zhang",
        "Zilong Xie",
        "Yicheng Feng",
        "Yijiang Li",
        "Xingrun Xing",
        "Sipeng Zheng",
        "Zongqing Lu"
      ],
      "abstract": "Multimodal Large Language Models have made significant strides in integrating\nvisual and textual information, yet they often struggle with effectively\naligning these modalities. We introduce a novel image tokenizer that bridges\nthis gap by applying the principle of Byte-Pair Encoding (BPE) to visual data.\nUnlike conventional approaches that rely on separate visual encoders, our\nmethod directly incorporates structural prior information into image tokens,\nmirroring the successful tokenization strategies used in text-only Large\nLanguage Models. This innovative approach enables Transformer models to more\neffectively learn and reason across modalities. Through theoretical analysis\nand extensive experiments, we demonstrate that our BPE Image Tokenizer\nsignificantly enhances MLLMs' multimodal understanding capabilities, even with\nlimited training data. Leveraging this method, we develop Being-VL-0, a model\nthat demonstrates superior performance across various benchmarks and shows\npromising scalability, potentially paving the way for more efficient and\ncapable multimodal foundation models.",
      "tldr_zh": "本研究针对多模态大语言模型（Multimodal Large Language Models, MLLMs）在视觉和文本模态对齐方面的挑战，提出了一种新型图像分词器，将 Byte-Pair Encoding (BPE) 原则应用于量化视觉数据，从而直接融入结构先验信息，类似于文本-only Large Language Models 的分词策略。  \n这种方法使 Transformer 模型能够更有效地学习和推理跨模态数据，即使在训练数据有限的情况下也能显著提升 MLLMs 的多模态理解能力。  \n通过理论分析和广泛实验，研究开发了 Being-VL-0 模型，该模型在各种基准测试中表现出色，并展示出良好的可扩展性，为更高效的多模态基础模型铺平道路。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02155v3",
      "published_date": "2024-10-03 02:34:31 UTC",
      "updated_date": "2025-03-09 15:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:58:18.858597"
    },
    {
      "arxiv_id": "2410.02147v2",
      "title": "Efficient Source-Free Time-Series Adaptation via Parameter Subspace Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Patel",
        "Christopher Sandino",
        "Behrooz Mahasseni",
        "Ellen L Zippi",
        "Erdrin Azemi",
        "Ali Moin",
        "Juri Minxha"
      ],
      "abstract": "In this paper, we propose a framework for efficient Source-Free Domain\nAdaptation (SFDA) in the context of time-series, focusing on enhancing both\nparameter efficiency and data-sample utilization. Our approach introduces an\nimproved paradigm for source-model preparation and target-side adaptation,\naiming to enhance training efficiency during target adaptation. Specifically,\nwe reparameterize the source model's weights in a Tucker-style decomposed\nmanner, factorizing the model into a compact form during the source model\npreparation phase. During target-side adaptation, only a subset of these\ndecomposed factors is fine-tuned, leading to significant improvements in\ntraining efficiency. We demonstrate using PAC Bayesian analysis that this\nselective fine-tuning strategy implicitly regularizes the adaptation process by\nconstraining the model's learning capacity. Furthermore, this\nre-parameterization reduces the overall model size and enhances inference\nefficiency, making the approach particularly well suited for\nresource-constrained devices. Additionally, we demonstrate that our framework\nis compatible with various SFDA methods and achieves significant computational\nefficiency, reducing the number of fine-tuned parameters and inference overhead\nin terms of MACs by over 90% while maintaining model performance.",
      "tldr_zh": "本论文提出了一种高效的 Source-Free Domain Adaptation (SFDA) 框架，针对时间序列数据，通过参数子空间解耦来提升参数效率和数据样本利用。框架在源模型准备阶段采用 Tucker-style 分解重新参数化模型权重，并在目标侧适配时仅微调子集因素，从而显著提高训练效率并隐式正则化适配过程，如 PAC Bayesian 分析所示。该方法兼容多种 SFDA 技术，减少了超过90%的微调参数和推理开销，同时维持模型性能，并适用于资源受限设备。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.02147v2",
      "published_date": "2024-10-03 02:12:03 UTC",
      "updated_date": "2025-02-01 16:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:58:40.713889"
    },
    {
      "arxiv_id": "2410.03774v1",
      "title": "Human-Based Risk Model for Improved Driver Support in Interactive Driving Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Puphal",
        "Benedict Flade",
        "Matti Krüger",
        "Ryohei Hirano",
        "Akihito Kimata"
      ],
      "abstract": "This paper addresses the problem of human-based driver support. Nowadays,\ndriver support systems help users to operate safely in many driving situations.\nNevertheless, these systems do not fully use the rich information that is\navailable from sensing the human driver. In this paper, we therefore present a\nhuman-based risk model that uses driver information for improved driver\nsupport. In contrast to state of the art, our proposed risk model combines a)\nthe current driver perception based on driver errors, such as the driver\noverlooking another vehicle (i.e., notice error), and b) driver\npersonalization, such as the driver being defensive or confident. In extensive\nsimulations of multiple interactive driving scenarios, we show that our novel\nhuman-based risk model achieves earlier warning times and reduced warning\nerrors compared to a baseline risk model not using human driver information.",
      "tldr_zh": "这篇论文提出了一种Human-Based Risk Model，用于提升互动驾驶场景中的驾驶员支持系统，通过整合驾驶员信息来弥补现有系统的不足。该模型结合了驾驶员的感知错误（如Notice Error，例如忽略其他车辆）和个性化特征（如防御性或自信驾驶风格），以提供更准确的风险评估。在多场景模拟实验中，该模型相较于不使用驾驶员信息的基线模型，实现了更早的警告时间和减少的警告错误，从而改善了驾驶安全。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03774v1",
      "published_date": "2024-10-03 02:10:13 UTC",
      "updated_date": "2024-10-03 02:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:58:41.872709"
    },
    {
      "arxiv_id": "2410.02110v2",
      "title": "Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Amogh Mannekote",
        "Adam Davies",
        "Jina Kang",
        "Kristy Elizabeth Boyer"
      ],
      "abstract": "Simulating learner actions helps stress-test open-ended interactive learning\nenvironments and prototype new adaptations before deployment. While recent\nstudies show the promise of using large language models (LLMs) for simulating\nhuman behavior, such approaches have not gone beyond rudimentary\nproof-of-concept stages due to key limitations. First, LLMs are highly\nsensitive to minor prompt variations, raising doubts about their ability to\ngeneralize to new scenarios without extensive prompt engineering. Moreover,\napparently successful outcomes can often be unreliable, either because domain\nexperts unintentionally guide LLMs to produce expected results, leading to\nself-fulfilling prophecies; or because the LLM has encountered highly similar\nscenarios in its training data, meaning that models may not be simulating\nbehavior so much as regurgitating memorized content. To address these\nchallenges, we propose Hyp-Mix, a simulation authoring framework that allows\nexperts to develop and evaluate simulations by combining testable hypotheses\nabout learner behavior. Testing this framework in a physics learning\nenvironment, we found that GPT-4 Turbo maintains calibrated behavior even as\nthe underlying learner model changes, providing the first evidence that LLMs\ncan be used to simulate realistic behaviors in open-ended interactive learning\nenvironments, a necessary prerequisite for useful LLM behavioral simulation.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能可靠模拟人类学习者行为，针对开放式互动学习环境的挑战提出Hyp-Mix模拟框架。该框架允许专家通过结合可测试的假设来开发和评估模拟行为，从而解决LLMs对提示变化的敏感性和潜在不可靠性问题。在物理学习环境中测试后，发现GPT-4 Turbo即使在底层学习模型变化时也能保持稳定的行为，这为LLMs在真实行为模拟中的应用提供了关键证据。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02110v2",
      "published_date": "2024-10-03 00:25:40 UTC",
      "updated_date": "2024-10-12 22:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:58:53.956832"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 160,
  "processed_papers_count": 160,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T06:59:22.628274"
}