{
  "date": "2024-07-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-30 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 和机器学习领域的创新，尤其是大语言模型 (LLMs) 在代码生成、推荐系统和任务评估中的应用，以及强化学习、图神经网络和量子计算的进展。其中，GenRec 和 TaskEval 等文章因其实际应用潜力而令人印象深刻，同时 Yoshua Bengio 和 Sergey Levine 等知名学者的参与（如第22和73篇）提升了整体话题度。\n\n下面，我挑选并讨论了部分重要或有话题度的论文，先从 AI 和 LLMs 相关的内容入手，再聊强化学习和量子计算领域，其他论文则快速概述。将相关主题归类讨论，突出核心贡献。\n\n**AI 和 LLMs 相关论文：**\n- **GenRec: Generative Sequential Recommendation with Large Language Models（生成式序列推荐使用大语言模型）**（第9篇）：该论文提出 GenRec 模型，将 LLMs 用于序列推荐任务，通过 Transformer 的序列建模能力学习双向模式，避免手动提示设计，实现高效推荐。主要贡献是提升了推荐系统的泛化性能，在公开数据集上达到最先进水平。\n- **TaskEval: Assessing Difficulty of Code Generation Tasks for Large Language Models（评估大语言模型代码生成任务的难度）**（第5篇）：作者使用 Item Response Theory（项目反应理论）分析 LLMs 在代码生成中的任务难度，并结合多种提示策略。主要发现是 TaskEval 可以识别任务特性，帮助改进基准评估和模型性能。\n- **AI-Assisted Generation of Difficult Math Questions（AI 辅助生成困难数学问题）**（第22篇，由 Yoshua Bengio 等参与）：该方法使用 LLMs 生成结合多种数学技能的难题，通过元认知技能提取核心技能，实现高效问题创建。主要贡献是提升了数学任务的多样性和难度，适用于 LLMs 的持续改进。\n- **WebApp1K: A Practical Code-Generation Benchmark for Web App Development（WebApp1K: 适用于 Web 应用开发的实用代码生成基准）**（第17篇）：论文引入 WebApp1K 基准，使用 LLMs 生成 Web 应用代码，并评估模型性能。主要发现是开源 LLMs 在代码正确性和功能性上接近 GPT-4o，同时模型大小与性能高度相关。\n- **CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning（CLEFT: 使用高效大语言模型和提示微调的语言-图像对比学习）**（第21篇）：该框架优化了 LLMs 在图像任务中的提示策略，实现高效对比学习。主要贡献是减少了训练参数（仅 4% 用于语言模型），在医学图像数据集上提升了性能。\n\n这些 LLMs 论文突出了模型在代码生成和跨模态任务中的潜力，但也暴露了提示设计和泛化性的挑战，相关工作可能推动 AI 应用在实际场景中的优化。\n\n**强化学习和机器人相关论文：**\n- **Autonomous Improvement of Instruction Following Skills via Foundation Models（通过基础模型实现指令遵循技能的自主改进）**（第73篇，由 Sergey Levine 参与）：论文提出一种框架，使用 LLMs 和视觉模型从自主数据中提升机器人指令遵循能力。主要发现是机器人政策在无监督数据上提升 2 倍，适用于真实世界部署。\n- **VITAL: Visual Teleoperation to Enhance Robot Learning through Human-in-the-Loop Corrections（VITAL: 通过人类循环校正增强机器人学习的视觉遥操作）**（第1篇）：作者开发了 VITAL 系统，用于双臂操作任务的低成本遥操作，并结合模拟和真实环境训练。主要贡献是提高了机器人策略的鲁棒性和泛化性，通过人类反馈显著提升性能。\n- **DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis（DuA: 用于长期连续 EEG 情绪分析的双注意力 Transformer）**（第78篇）：该模型使用双注意力机制处理 EEG 数据，实现情绪识别。主要发现是提升了跨主体情绪分析的准确率，平均提高 5.28%。\n\n这些论文展示了强化学习在机器人和脑机接口中的应用潜力，强调了自主探索和注意力机制的重要性。\n\n**量子计算和 SNNs 相关论文：**\n- **AI methods for approximate compiling of unitaries（AI 方法用于幺正矩阵的近似编译）**（第6篇）：论文使用深度学习模型优化量子电路参数，实现高效编译。主要贡献是比穷举搜索和随机初始化改进显著，支持量子硬件计算。\n- **Unveiling the Potential of Spiking Dynamics in Graph Representation Learning（揭示脉冲动态在图表示学习中的潜力）**（第83篇）：作者提出 SNNs 框架，结合空间-时间归一化提升图学习效率。主要发现是 SNNs 在图任务中减少计算成本，同时缓解过平滑问题。\n\n量子计算论文虽数量不多，但展示了 AI 与量子融合的创新路径。\n\n其他论文涉及图像处理、生物医学和杂项主题，如第4篇 TMA-Grid（一个开源的组织微阵列去阵列 Web 应用）和第16篇 Domain Shift Analysis（在胸部 X 光图像分类中的领域偏移分析）。这些工作虽有实际价值，但相对小众，仅快速提及其在医疗图像处理中的贡献，例如 TMA-Grid 通过交互式算法提升了组织微阵列分析的准确性。\n\n总之，今天的论文突出了 AI 领域的动态发展，LLMs 和强化学习是核心亮点，建议读者关注 GenRec 和 TaskEval 等实用方法。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2407.21244v1",
      "title": "VITAL: Visual Teleoperation to Enhance Robot Learning through Human-in-the-Loop Corrections",
      "title_zh": "翻译失败",
      "authors": [
        "Hamidreza Kasaei",
        "Mohammadreza Kasaei"
      ],
      "abstract": "Imitation Learning (IL) has emerged as a powerful approach in robotics,\nallowing robots to acquire new skills by mimicking human actions. Despite its\npotential, the data collection process for IL remains a significant challenge\ndue to the logistical difficulties and high costs associated with obtaining\nhigh-quality demonstrations. To address these issues, we propose a low-cost\nvisual teleoperation system for bimanual manipulation tasks, called VITAL. Our\napproach leverages affordable hardware and visual processing techniques to\ncollect demonstrations, which are then augmented to create extensive training\ndatasets for imitation learning. We enhance the generalizability and robustness\nof the learned policies by utilizing both real and simulated environments and\nhuman-in-the-loop corrections. We evaluated our method through several rounds\nof experiments in simulated and real-robot settings, focusing on tasks of\nvarying complexity, including bottle collecting, stacking objects, and\nhammering. Our experimental results validate the effectiveness of our approach\nin learning robust robot policies from simulated data, significantly improved\nby human-in-the-loop corrections and real-world data integration. Additionally,\nwe demonstrate the framework's capability to generalize to new tasks, such as\nsetting a drink tray, showcasing its adaptability and potential for handling a\nwide range of real-world bimanual manipulation tasks. A video of the\nexperiments can be found at: https://youtu.be/YeVAMRqRe64?si=R179xDlEGc7nPu8i",
      "tldr_zh": "本研究针对Imitation Learning (IL)中数据收集的成本和复杂性问题，提出了一种低成本的视觉遥操作系统VITAL，用于双臂操作(bimanual manipulation)任务。该系统利用廉价硬件、视觉处理技术和数据增强方法，结合真实和模拟环境以及Human-in-the-Loop Corrections，来收集演示数据并提升机器人策略的泛化性和鲁棒性。在实验中，VITAL在模拟和真实机器人场景下表现突出，例如在瓶子收集、堆叠物体和锤击任务上，从模拟数据中学习了高效策略，并通过人类干预和真实数据整合实现了显著改进。该框架还展示了良好的适应性，能泛化到新任务如设置饮料托盘。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21244v1",
      "published_date": "2024-07-30 23:29:47 UTC",
      "updated_date": "2024-07-30 23:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:12:38.931037"
    },
    {
      "arxiv_id": "2407.21243v2",
      "title": "Informed Correctors for Discrete Diffusion Models",
      "title_zh": "针对离散扩散模型的知情修正器",
      "authors": [
        "Yixiu Zhao",
        "Jiaxin Shi",
        "Feng Chen",
        "Shaul Druckmann",
        "Lester Mackey",
        "Scott Linderman"
      ],
      "abstract": "Discrete diffusion has emerged as a powerful framework for generative\nmodeling in discrete domains, yet efficiently sampling from these models\nremains challenging. Existing sampling strategies often struggle to balance\ncomputation and sample quality when the number of sampling steps is reduced,\neven when the model has learned the data distribution well. To address these\nlimitations, we propose a predictor-corrector sampling scheme where the\ncorrector is informed by the diffusion model to more reliably counter the\naccumulating approximation errors. To further enhance the effectiveness of our\ninformed corrector, we introduce complementary architectural modifications\nbased on hollow transformers and a simple tailored training objective that\nleverages more training signal. We use a synthetic example to illustrate the\nfailure modes of existing samplers and show how informed correctors alleviate\nthese problems. On tokenized ImageNet 256x256, this approach consistently\nproduces superior samples with fewer steps, achieving improved FID scores for\ndiscrete diffusion models. These results underscore the potential of informed\ncorrectors for fast and high-fidelity generation using discrete diffusion.",
      "tldr_zh": "本文针对离散扩散模型（discrete diffusion models）的采样效率问题，提出了一种预测器-校正器（predictor-corrector）采样方案，其中校正器由扩散模型提供信息，以更可靠地对抗累积的近似误差。作者引入了基于空心变压器（hollow transformers）的架构修改和一个定制训练目标，以增强校正器的性能，并在合成示例中展示了该方法如何缓解现有采样器的失败模式。在 ImageNet 256x256 数据集上，实验结果显示，该方法在减少采样步骤的情况下显著提高了 FID scores，实现更快的生成和更高样本质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21243v2",
      "published_date": "2024-07-30 23:29:29 UTC",
      "updated_date": "2025-03-13 20:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:12:59.584636"
    },
    {
      "arxiv_id": "2407.21241v1",
      "title": "Bug Analysis Towards Bug Resolution Time Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Yagiz Ozkan",
        "Poul Einer Heegaard",
        "Wolfgang Kellerer",
        "Carmen Mas-Machuca"
      ],
      "abstract": "Bugs are inevitable in software development, and their reporting in open\nrepositories can enhance software transparency and reliability assessment. This\nstudy aims to extract information from the issue tracking system Jira and\nproposes a methodology to estimate resolution time for new bugs. The\nmethodology is applied to network project ONAP, addressing concerns of network\noperators and manufacturers. This research provides insights into bug\nresolution times and related aspects in network softwarization projects.",
      "tldr_zh": "本研究针对软件开发中的 bug 问题，分析了 bug 在公开仓库中的报告如何提升软件透明度和可靠性，并提出一种从 Jira 问题跟踪系统中提取信息的方法来预测新 bug 的解决时间。  \n该方法应用于网络项目 ONAP，旨在解决网络运营商和制造商的担忧，通过数据分析提供 bug 解决时间的估算。  \n研究结果为网络软warization 项目中的 bug 管理提供了宝贵见解，帮助优化软件可靠性评估。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21241v1",
      "published_date": "2024-07-30 23:18:14 UTC",
      "updated_date": "2024-07-30 23:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:13:05.070156"
    },
    {
      "arxiv_id": "2407.21233v1",
      "title": "TMA-Grid: An open-source, zero-footprint web application for FAIR Tissue MicroArray De-arraying",
      "title_zh": "翻译失败",
      "authors": [
        "Aaron Ge",
        "Monjoy Saha",
        "Maire A. Duggan",
        "Petra Lenz",
        "Mustapha Abubakar",
        "Montserrat García-Closas",
        "Jeya Balasubramanian",
        "Jonas S. Almeida",
        "Praphulla MS Bhawsar"
      ],
      "abstract": "Background:\n  Tissue Microarrays (TMAs) significantly increase analytical efficiency in\nhistopathology and large-scale epidemiologic studies by allowing multiple\ntissue cores to be scanned on a single slide. The individual cores can be\ndigitally extracted and then linked to metadata for analysis in a process known\nas de-arraying. However, TMAs often contain core misalignments and artifacts\ndue to assembly errors, which can adversely affect the reliability of the\nextracted cores during the de-arraying process. Moreover, conventional\napproaches for TMA de-arraying rely on desktop solutions.Therefore, a robust\nyet flexible de-arraying method is crucial to account for these inaccuracies\nand ensure effective downstream analyses.\n  Results:\n  We developed TMA-Grid, an in-browser, zero-footprint, interactive web\napplication for TMA de-arraying. This web application integrates a\nconvolutional neural network for precise tissue segmentation and a grid\nestimation algorithm to match each identified core to its expected location.\nThe application emphasizes interactivity, allowing users to easily adjust\nsegmentation and gridding results. Operating entirely in the web-browser,\nTMA-Grid eliminates the need for downloads or installations and ensures data\nprivacy. Adhering to FAIR principles (Findable, Accessible, Interoperable, and\nReusable), the application and its components are designed for seamless\nintegration into TMA research workflows.\n  Conclusions:\n  TMA-Grid provides a robust, user-friendly solution for TMA dearraying on the\nweb. As an open, freely accessible platform, it lays the foundation for\ncollaborative analyses of TMAs and similar histopathology imaging data.\nAvailability: Web application: https://episphere.github.io/tma-grid Code:\nhttps://github.com/episphere/tma-grid Tutorial: https://youtu.be/miajqyw4BVk",
      "tldr_zh": "本研究开发了TMA-Grid，一款开源、零足迹的网络应用，用于实现Tissue Microarrays (TMAs) 的de-arraying过程，以解决核心错位和伪影问题，提高组织病理学和流行病学研究的分析效率。TMA-Grid 整合了convolutional neural network (CNN) 进行精确的组织分割，以及网格估计算法来匹配每个核心的位置，并提供交互式界面让用户调整结果，同时确保数据隐私并符合FAIR principles。相比传统桌面解决方案，该应用在浏览器中运行，促进协作分析，并提供开源代码和教程以支持无缝集成。",
      "categories": [
        "q-bio.TO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.TO",
      "comment": "NA",
      "pdf_url": "http://arxiv.org/pdf/2407.21233v1",
      "published_date": "2024-07-30 22:40:32 UTC",
      "updated_date": "2024-07-30 22:40:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:13:12.630994"
    },
    {
      "arxiv_id": "2407.21227v2",
      "title": "TaskEval: Assessing Difficulty of Code Generation Tasks for Large Language Models",
      "title_zh": "TaskEval：针对大语言模型的代码生成任务难度评估",
      "authors": [
        "Florian Tambon",
        "Amin Nikanjam",
        "Cyrine Zid",
        "Foutse Khomh",
        "Giuliano Antoniol"
      ],
      "abstract": "Large Language Models (LLMs) excel in code-related tasks like code\ngeneration, but benchmark evaluations often overlook task characteristics, such\nas difficulty. Moreover, benchmarks are usually built using tasks described\nwith one single prompt, despite the formulation of prompts having a profound\nimpact on the outcome. This paper introduces a generalist approach, TaskEval, a\nframework using diverse prompts and Item Response Theory (IRT) to efficiently\nassess LLMs' capabilities and benchmark task characteristics, improving the\nunderstanding of their performance.\n  Using two code generation benchmarks, HumanEval+ and ClassEval, as well as 5\ncode generation LLMs, we show that TaskEval is capable of characterizing the\nproperties of tasks. Using topic analysis, we identify and analyze the tasks of\nrespectively 17 and 21 topics within the benchmarks. We also cross-analyze\ntasks' characteristics with programming constructs (e.g., variable assignment,\nconditions, etc.) used by LLMs, emphasizing some patterns with tasks'\ndifficulty. Finally, we conduct a comparison between the difficulty assessment\nof tasks by human-annotators and LLMs. Orthogonal to current benchmarking\nevaluation efforts, TaskEval can assist researchers and practitioners in\nfostering better assessments of LLMs. The tasks' characteristics can be used to\nidentify shortcomings within existing benchmarks. This could be used to\ngenerate additional related tasks for the evaluation or improvement of LLM.",
      "tldr_zh": "本文提出 TaskEval 框架，用于评估 Large Language Models (LLMs) 在代码生成任务中的难度，解决现有基准忽略任务特性和提示影响的问题。该框架结合多样提示和 Item Response Theory (IRT)，通过主题分析和编程结构（如变量赋值、条件等）的交叉分析，表征任务属性，并在 HumanEval+ 和 ClassEval 基准上实验中识别了17和21个任务主题。实验结果显示，TaskEval 能有效比较人类和 LLMs 的难度评估，帮助改进基准、识别不足并生成更多相关任务。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21227v2",
      "published_date": "2024-07-30 22:31:19 UTC",
      "updated_date": "2025-03-10 17:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:13:25.039275"
    },
    {
      "arxiv_id": "2407.21225v1",
      "title": "AI methods for approximate compiling of unitaries",
      "title_zh": "翻译失败",
      "authors": [
        "David Kremer",
        "Victor Villar",
        "Sanjay Vishwakarma",
        "Ismael Faro",
        "Juan Cruz-Benito"
      ],
      "abstract": "This paper explores artificial intelligence (AI) methods for the approximate\ncompiling of unitaries, focusing on the use of fixed two-qubit gates and\narbitrary single-qubit rotations typical in superconducting hardware. Our\napproach involves three main stages: identifying an initial template that\napproximates the target unitary, predicting initial parameters for this\ntemplate, and refining these parameters to maximize the fidelity of the\ncircuit. We propose AI-driven approaches for the first two stages, with a deep\nlearning model that suggests initial templates and an autoencoder-like model\nthat suggests parameter values, which are refined through gradient descent to\nachieve the desired fidelity. We demonstrate the method on 2 and 3-qubit\nunitaries, showcasing promising improvements over exhaustive search and random\nparameter initialization. The results highlight the potential of AI to enhance\nthe transpiling process, supporting more efficient quantum computations on\ncurrent and future quantum hardware.",
      "tldr_zh": "这篇论文探讨了使用人工智能（AI）方法来实现单向单元（unitaries）的近似编译，专注于固定双量子比特门（two-qubit gates）和任意单量子比特旋转（single-qubit rotations），以适应超导硬件。方法包括三个阶段：识别初始模板、通过深度学习模型预测初始模板以及使用类似自编码器（autoencoder-like）的模型预测参数值，随后通过梯度下降优化参数以最大化电路保真度（fidelity）。实验在2和3量子比特单元上证明，该方法相较于穷举搜索和随机参数初始化取得了显著改进，展示了AI在提升量子计算转译过程效率方面的潜力。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21225v1",
      "published_date": "2024-07-30 22:30:15 UTC",
      "updated_date": "2024-07-30 22:30:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:13:38.175735"
    },
    {
      "arxiv_id": "2407.21204v1",
      "title": "LoRaWAN Based Dynamic Noise Mapping with Machine Learning for Urban Noise Enforcement",
      "title_zh": "基于 LoRaWAN 的动态噪声映射：利用机器",
      "authors": [
        "H. Emre Erdem",
        "Henry Leung"
      ],
      "abstract": "Static noise maps depicting long-term noise levels over wide areas are\nvaluable urban planning assets for municipalities in decreasing noise exposure\nof residents. However, non-traffic noise sources with transient behavior, which\npeople complain frequently, are usually ignored by static maps. We propose here\na dynamic noise mapping approach using the data collected via low-power\nwide-area network (LPWAN, specifically LoRaWAN) based internet of things (IoT)\ninfrastructure, which is one of the most common communication backbones for\nsmart cities. Noise mapping based on LPWAN is challenging due to the low data\nrates of these protocols. The proposed dynamic noise mapping approach\ndiminishes the negative implications of data rate limitations using machine\nlearning (ML) for event and location prediction of non-traffic sources based on\nthe scarce data. The strength of these models lies in their consideration of\nthe spatial variance in acoustic behavior caused by the buildings in urban\nsettings. The effectiveness of the proposed method and the accuracy of the\nresulting dynamic maps are evaluated in field tests. The results show that the\nproposed system can decrease the map error caused by non-traffic sources up to\n51% and can stay effective under significant packet losses.",
      "tldr_zh": "本文提出了一种基于 LoRaWAN 的动态噪声映射方法，利用机器学习 (ML) 处理低数据率挑战，以改善城市噪声执法。方法通过 IoT 基础设施收集数据，并考虑城市建筑对声学行为的 spatial variance 来预测非交通噪声源的事件和位置。实验结果显示，该系统可将非交通噪声源导致的地图错误减少多达 51%，并在显著数据包丢失情况下保持有效性。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21204v1",
      "published_date": "2024-07-30 21:40:12 UTC",
      "updated_date": "2024-07-30 21:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:13:48.195137"
    },
    {
      "arxiv_id": "2407.21202v1",
      "title": "Rolling in the deep of cognitive and AI biases",
      "title_zh": "翻译失败",
      "authors": [
        "Athena Vakali",
        "Nicoleta Tantalaki"
      ],
      "abstract": "Nowadays, we delegate many of our decisions to Artificial Intelligence (AI)\nthat acts either in solo or as a human companion in decisions made to support\nseveral sensitive domains, like healthcare, financial services and law\nenforcement. AI systems, even carefully designed to be fair, are heavily\ncriticized for delivering misjudged and discriminated outcomes against\nindividuals and groups. Numerous work on AI algorithmic fairness is devoted on\nMachine Learning pipelines which address biases and quantify fairness under a\npure computational view. However, the continuous unfair and unjust AI outcomes,\nindicate that there is urgent need to understand AI as a sociotechnical system,\ninseparable from the conditions in which it is designed, developed and\ndeployed. Although, the synergy of humans and machines seems imperative to make\nAI work, the significant impact of human and societal factors on AI bias is\ncurrently overlooked. We address this critical issue by following a radical new\nmethodology under which human cognitive biases become core entities in our AI\nfairness overview. Inspired by the cognitive science definition and taxonomy of\nhuman heuristics, we identify how harmful human actions influence the overall\nAI lifecycle, and reveal human to AI biases hidden pathways. We introduce a new\nmapping, which justifies the human heuristics to AI biases reflections and we\ndetect relevant fairness intensities and inter-dependencies. We envision that\nthis approach will contribute in revisiting AI fairness under deeper\nhuman-centric case studies, revealing hidden biases cause and effects.",
      "tldr_zh": "本研究探讨了认知偏差(cognitive biases)和AI偏差(AI biases)对AI决策的影响，强调AI系统在敏感领域如医疗、金融和执法中可能导致不公正结果，尽管已设计为公平。作者提出一种新方法，将人类认知偏差作为AI公平(algorithmic fairness)分析的核心，基于认知科学的启发式(heuristics)分类，映射人类行为如何影响AI生命周期，并揭示隐藏的偏差路径及相互依赖。最终，该方法旨在通过更深入的人类中心案例研究，重新审视AI公平，揭示偏差的根因和影响，以促进更可信的AI系统。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2407.21202v1",
      "published_date": "2024-07-30 21:34:04 UTC",
      "updated_date": "2024-07-30 21:34:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:14:10.447065"
    },
    {
      "arxiv_id": "2407.21191v2",
      "title": "GenRec: Generative Sequential Recommendation with Large Language Models",
      "title_zh": "GenRec：基于大型语言模型的生成式序列推荐",
      "authors": [
        "Panfeng Cao",
        "Pietro Lio"
      ],
      "abstract": "Sequential recommendation is a task to capture hidden user preferences from\nhistorical user item interaction data and recommend next items for the user.\nSignificant progress has been made in this domain by leveraging classification\nbased learning methods. Inspired by the recent paradigm of 'pretrain, prompt\nand predict' in NLP, we consider sequential recommendation as a sequence to\nsequence generation task and propose a novel model named Generative\nRecommendation (GenRec). Unlike classification based models that learn explicit\nuser and item representations, GenRec utilizes the sequence modeling capability\nof Transformer and adopts the masked item prediction objective to effectively\nlearn the hidden bidirectional sequential patterns. Different from existing\ngenerative sequential recommendation models, GenRec does not rely on manually\ndesigned hard prompts. The input to GenRec is textual user item sequence and\nthe output is top ranked next items. Moreover, GenRec is lightweight and\nrequires only a few hours to train effectively in low-resource settings, making\nit highly applicable to real-world scenarios and helping to democratize large\nlanguage models in the sequential recommendation domain. Our extensive\nexperiments have demonstrated that GenRec generalizes on various public\nreal-world datasets and achieves state-of-the-art results. Our experiments also\nvalidate the effectiveness of the the proposed masked item prediction objective\nthat improves the model performance by a large margin.",
      "tldr_zh": "这篇论文提出了一种名为 GenRec 的生成式顺序推荐模型，利用 Large Language Models 的 Transformer 序列建模能力，将顺序推荐任务视为序列到序列生成问题，并采用 masked item prediction 目标来学习双向序列模式。不同于传统的分类模型，GenRec 不依赖手动设计的硬提示，直接以文本化的用户物品序列作为输入，输出排名靠前的下一个推荐物品，且模型轻量级，仅需数小时在低资源环境中训练。实验结果表明，GenRec 在多种公共真实数据集上实现了最先进性能，并显著验证了 masked item prediction 目标的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21191v2",
      "published_date": "2024-07-30 20:58:36 UTC",
      "updated_date": "2024-08-29 02:27:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:14:12.745175"
    },
    {
      "arxiv_id": "2407.21189v2",
      "title": "Multi-task Photonic Reservoir Computing: Wavelength Division Multiplexing for Parallel Computing with a Silicon Microring Resonator",
      "title_zh": "翻译失败",
      "authors": [
        "Bernard J. Giron Castro",
        "Christophe Peucheret",
        "Darko Zibar",
        "Francesco Da Ros"
      ],
      "abstract": "Nowadays, as the ever-increasing demand for more powerful computing resources\ncontinues, alternative advanced computing paradigms are under extensive\ninvestigation. Significant effort has been made to deviate from conventional\nVon Neumann architectures. In-memory computing has emerged in the field of\nelectronics as a possible solution to the infamous bottleneck between memory\nand computing processors, which reduces the effective throughput of data. In\nphotonics, novel schemes attempt to collocate the computing processor and\nmemory in a single device. Photonics offers the flexibility of multiplexing\nstreams of data not only spatially and in time, but also in frequency or,\nequivalently, in wavelength, which makes it highly suitable for parallel\ncomputing. Here, we numerically show the use of time and wavelength division\nmultiplexing (WDM) to solve four independent tasks at the same time in a single\nphotonic chip, serving as a proof of concept for our proposal. The system is a\ntime-delay reservoir computing (TDRC) based on a microring resonator (MRR). The\naddressed tasks cover different applications: Time-series prediction, waveform\nsignal classification, wireless channel equalization, and radar signal\nprediction. The system is also tested for simultaneous computing of up to 10\ninstances of the same task, exhibiting excellent performance. The footprint of\nthe system is reduced by using time-division multiplexing of the nodes that act\nas the neurons of the studied neural network scheme. WDM is used for the\nparallelization of wavelength channels, each addressing a single task. By\nadjusting the input power and frequency of each optical channel, we can achieve\nlevels of performance for each of the tasks that are comparable to those quoted\nin state-of-the-art reports focusing on single-task operation...",
      "tldr_zh": "本文提出了一种基于硅微环谐振器 (MRR) 的多任务光子 Reservoir Computing 系统，利用时间分复用 (TDM) 和波长分复用 (WDM) 在单个光子芯片上实现并行计算，旨在解决传统冯·诺依曼架构的计算瓶颈。系统通过数值模拟同时处理四个独立任务，包括时间序列预测、波形信号分类、无线通道均衡和雷达信号预测，并成功测试了多达 10 个相同任务实例的性能。实验结果显示，通过调整输入功率和频率，该系统在多任务模式下的表现与单任务操作相当，证明了其高效性和潜力。整体方案减少了系统占用空间，为光子学中的并行计算提供了创新途径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "physics.optics"
      ],
      "primary_category": "cs.NE",
      "comment": "Main text: 11 figures, 3 tables. Supplementary material: 2 figures, 4\n  tables. The manuscript presented in this pre-print has been accepted for\n  publication in Frontiers: Advanced Optical Technologies. The abstract is\n  shorter than in the PDF file to comply with arXiv requirements",
      "pdf_url": "http://arxiv.org/pdf/2407.21189v2",
      "published_date": "2024-07-30 20:54:07 UTC",
      "updated_date": "2024-10-08 12:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:14:25.397689"
    },
    {
      "arxiv_id": "2407.21178v1",
      "title": "Deduction Game Framework and Information Set Entropy Search",
      "title_zh": "演绎游戏框架与信息集熵搜索",
      "authors": [
        "Fandi Meng",
        "Simon Lucas"
      ],
      "abstract": "We present a game framework tailored for deduction games, enabling structured\nanalysis from the perspective of Shannon entropy variations. Additionally, we\nintroduce a new forward search algorithm, Information Set Entropy Search\n(ISES), which effectively solves many single-player deduction games. The ISES\nalgorithm, augmented with sampling techniques, allows agents to make decisions\nwithin controlled computational resources and time constraints. Experimental\nresults on eight games within our framework demonstrate the significant\nsuperiority of our method over the Single Observer Information Set Monte Carlo\nTree Search(SO-ISMCTS) algorithm under limited decision time constraints. The\nentropy variation of game states in our framework enables explainable\ndecision-making, which can also be used to analyze the appeal of deduction\ngames and provide insights for game designers.",
      "tldr_zh": "本研究提出一个针对演绎游戏的游戏框架，通过 Shannon entropy 变化的角度进行结构化分析。论文引入了新的前向搜索算法 Information Set Entropy Search (ISES)，该算法结合采样技术，使代理在受控计算资源和时间约束下有效解决单人演绎游戏。实验结果显示，在八个游戏中，ISES 在有限决策时间内显著优于 Single Observer Information Set Monte Carlo Tree Search (SO-ISMCTS) 算法。框架中的游戏状态熵变化还支持可解释决策，并为分析演绎游戏的吸引力及游戏设计师提供宝贵洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE Conference on Games (IEEE CoG)",
      "pdf_url": "http://arxiv.org/pdf/2407.21178v1",
      "published_date": "2024-07-30 20:33:15 UTC",
      "updated_date": "2024-07-30 20:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:14:39.143490"
    },
    {
      "arxiv_id": "2407.21174v1",
      "title": "AI Safety in Practice: Enhancing Adversarial Robustness in Multimodal Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Maisha Binte Rashid",
        "Pablo Rivas"
      ],
      "abstract": "Multimodal machine learning models that combine visual and textual data are\nincreasingly being deployed in critical applications, raising significant\nsafety and security concerns due to their vulnerability to adversarial attacks.\nThis paper presents an effective strategy to enhance the robustness of\nmultimodal image captioning models against such attacks. By leveraging the Fast\nGradient Sign Method (FGSM) to generate adversarial examples and incorporating\nadversarial training techniques, we demonstrate improved model robustness on\ntwo benchmark datasets: Flickr8k and COCO. Our findings indicate that\nselectively training only the text decoder of the multimodal architecture shows\nperformance comparable to full adversarial training while offering increased\ncomputational efficiency. This targeted approach suggests a balance between\nrobustness and training costs, facilitating the ethical deployment of\nmultimodal AI systems across various domains.",
      "tldr_zh": "这篇论文探讨了多模态图像描述模型在关键应用中的安全问题，特别是在对抗性攻击下的脆弱性，并提出了一种增强鲁棒性的策略。研究利用 Fast Gradient Sign Method (FGSM) 生成对抗样本，并通过对抗训练技术来改进模型性能，在 Flickr8k 和 COCO 数据集上取得了显著提升。关键发现是，仅训练文本解码器即可实现与完整对抗训练相当的效果，同时提高计算效率。这种方法为多模态 AI 系统的道德部署提供了平衡鲁棒性和成本的实用途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.AS",
        "I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted into KDD 2024 workshop on Ethical AI",
      "pdf_url": "http://arxiv.org/pdf/2407.21174v1",
      "published_date": "2024-07-30 20:28:31 UTC",
      "updated_date": "2024-07-30 20:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:14:51.394278"
    },
    {
      "arxiv_id": "2407.21164v3",
      "title": "Extending choice assessments to choice functions: An algorithm for computing the natural extension",
      "title_zh": "翻译失败",
      "authors": [
        "Arne Decadt",
        "Alexander Erreygers",
        "Jasper De Bock"
      ],
      "abstract": "We study how to infer new choices from prior choices using the framework of\nchoice functions, a unifying mathematical framework for decision-making based\non sets of preference orders. In particular, we define the natural (most\nconservative) extension of a given choice assessment to a coherent choice\nfunction -- whenever possible -- and use this natural extension to make new\nchoices. We provide a practical algorithm for computing this natural extension\nand various ways to improve scalability. Finally, we test these algorithms for\ndifferent types of choice assessments.",
      "tldr_zh": "本研究扩展了选择评估（choice assessments）到选择函数（choice functions）的框架，旨在通过一套偏好顺序集合来推断新选择。论文定义了给定选择评估的最自然（natural）扩展，即最保守的连贯选择函数（coherent choice function），并提供了一个实用算法来计算此扩展，同时提出多种方法提升算法的可扩展性。主要通过实验测试了该算法在不同类型选择评估上的性能，展示了其在决策推理中的潜在应用。",
      "categories": [
        "cs.AI",
        "math.PR",
        "68T37, 60A99"
      ],
      "primary_category": "cs.AI",
      "comment": "40 pages, 8 figures, pre-print for International Journal of\n  Approximate Reasoning",
      "pdf_url": "http://arxiv.org/pdf/2407.21164v3",
      "published_date": "2024-07-30 20:10:59 UTC",
      "updated_date": "2024-11-28 17:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:15:03.923260"
    },
    {
      "arxiv_id": "2407.21163v1",
      "title": "Understanding Public Safety Trends in Calgary through data mining",
      "title_zh": "通过数据挖掘理解卡尔加里的公共安全趋势",
      "authors": [
        "Zack Dewis",
        "Apratim Sen",
        "Jeffrey Wong",
        "Yujia Zhang"
      ],
      "abstract": "This paper utilizes statistical data from various open datasets in Calgary to\nto uncover patterns and insights for community crimes, disorders, and traffic\nincidents. Community attributes like demographics, housing, and pet\nregistration were collected and analyzed through geospatial visualization and\ncorrelation analysis. Strongly correlated features were identified using the\nchi-square test, and predictive models were built using association rule mining\nand machine learning algorithms. The findings suggest that crime rates are\nclosely linked to factors such as population density, while pet registration\nhas a smaller impact. This study offers valuable insights for city managers to\nenhance community safety strategies.",
      "tldr_zh": "本研究利用卡尔加里的开放数据集，通过数据挖掘技术分析社区犯罪、混乱和交通事故的模式，包括人口统计、住房和宠物注册等社区属性。研究采用地理空间可视化、相关性分析（chi-square test）、关联规则挖掘和机器学习算法来识别强相关特征并构建预测模型。结果显示，犯罪率与人口密度密切相关，而宠物注册的影响较小。该研究为城市管理者提供宝贵见解，以优化社区安全策略。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.21163v1",
      "published_date": "2024-07-30 20:04:51 UTC",
      "updated_date": "2024-07-30 20:04:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:15:24.151654"
    },
    {
      "arxiv_id": "2407.21151v2",
      "title": "Private Collaborative Edge Inference via Over-the-Air Computation",
      "title_zh": "基于空中计算的私有协作边缘推理",
      "authors": [
        "Selim F. Yilmaz",
        "Burak Hasircioglu",
        "Li Qiao",
        "Deniz Gunduz"
      ],
      "abstract": "We consider collaborative inference at the wireless edge, where each client's\nmodel is trained independently on its local dataset. Clients are queried in\nparallel to make an accurate decision collaboratively. In addition to\nmaximizing the inference accuracy, we also want to ensure the privacy of local\nmodels. To this end, we leverage the superposition property of the multiple\naccess channel to implement bandwidth-efficient multi-user inference methods.\nWe propose different methods for ensemble and multi-view classification that\nexploit over-the-air computation (OAC). We show that these schemes perform\nbetter than their orthogonal counterparts with statistically significant\ndifferences while using fewer resources and providing privacy guarantees. We\nalso provide experimental results verifying the benefits of the proposed OAC\napproach to multi-user inference, and perform an ablation study to demonstrate\nthe effectiveness of our design choices. We share the source code of the\nframework publicly on Github to facilitate further research and\nreproducibility.",
      "tldr_zh": "本研究探讨了基于 Over-the-Air Computation (OAC) 的隐私保护协作边缘推理（collaborative inference），其中多个客户端使用本地数据集训练模型，并通过并行查询实现准确决策，同时确保本地模型隐私。研究提出利用多址信道叠加特性的方法，包括针对 ensemble classification 和 multi-view classification 的新方案，这些方案比正交方法更高效，使用更少资源，并显示出统计显著的性能提升。实验结果验证了 OAC 方法的优势，并通过消融研究证实了设计选择的有效性，同时公开了源代码以促进进一步研究和可重复性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures. This work extends from our preliminary study\n  presented at the 2022 IEEE International Symposium on Information Theory [1].\n  arXiv admin note: text overlap with arXiv:2202.03129",
      "pdf_url": "http://arxiv.org/pdf/2407.21151v2",
      "published_date": "2024-07-30 19:28:28 UTC",
      "updated_date": "2025-01-14 09:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:15:58.072029"
    },
    {
      "arxiv_id": "2407.21149v1",
      "title": "Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population",
      "title_zh": "退伍军人医疗管理局人群中的胸部X光片分类领域偏移分析",
      "authors": [
        "Mayanka Chandrashekar",
        "Ian Goethert",
        "Md Inzamam Ul Haque",
        "Benjamin McMahon",
        "Sayera Dhaubhadel",
        "Kathryn Knight",
        "Joseph Erdos",
        "Donna Reagan",
        "Caroline Taylor",
        "Peter Kuzmak",
        "John Michael Gaziano",
        "Eileen McAllister",
        "Lauren Costa",
        "Yuk-Lam Ho",
        "Kelly Cho",
        "Suzanne Tamang",
        "Samah Fodeh-Jarad",
        "Olga S. Ovchinnikova",
        "Amy C. Justice",
        "Jacob Hinkle",
        "Ioana Danciu"
      ],
      "abstract": "Objectives: This study aims to assess the impact of domain shift on chest\nX-ray classification accuracy and to analyze the influence of ground truth\nlabel quality and demographic factors such as age group, sex, and study year.\nMaterials and Methods: We used a DenseNet121 model pretrained MIMIC-CXR dataset\nfor deep learning-based multilabel classification using ground truth labels\nfrom radiology reports extracted using the CheXpert and CheXbert Labeler. We\ncompared the performance of the 14 chest X-ray labels on the MIMIC-CXR and\nVeterans Healthcare Administration chest X-ray dataset (VA-CXR). The VA-CXR\ndataset comprises over 259k chest X-ray images spanning between the years 2010\nand 2022. Results: The validation of ground truth and the assessment of\nmulti-label classification performance across various NLP extraction tools\nrevealed that the VA-CXR dataset exhibited lower disagreement rates than the\nMIMIC-CXR datasets. Additionally, there were notable differences in AUC scores\nbetween models utilizing CheXpert and CheXbert. When evaluating multi-label\nclassification performance across different datasets, minimal domain shift was\nobserved in unseen datasets, except for the label \"Enlarged Cardiomediastinum.\"\nThe study year's subgroup analyses exhibited the most significant variations in\nmulti-label classification model performance. These findings underscore the\nimportance of considering domain shifts in chest X-ray classification tasks,\nparticularly concerning study years. Conclusion: Our study reveals the\nsignificant impact of domain shift and demographic factors on chest X-ray\nclassification, emphasizing the need for improved transfer learning and\nequitable model development. Addressing these challenges is crucial for\nadvancing medical imaging and enhancing patient care.",
      "tldr_zh": "本研究评估了领域偏移（domain shift）对退伍军人医疗管理局（Veterans Healthcare Administration）人群胸部X光分类准确性的影响，并分析了地面真实标签质量以及人口统计因素（如年龄组、性别和研究年份）的相关性。研究采用在MIMIC-CXR数据集上预训练的DenseNet121模型进行多标签分类，使用CheXpert和CheXbert工具从放射学报告中提取标签，并比较MIMIC-CXR和VA-CXR数据集（后者包含超过259k张2010-2022年胸部X光图像）的性能。结果显示，VA-CXR数据集的标签不一致率较低，AUC分数在不同工具间有差异，领域偏移整体最小但在\"Enlarged Cardiomediastinum\"标签上显著，且研究年份子组分析显示模型性能有较大变异。总之，该研究强调了领域偏移和人口统计因素对胸部X光分类的重大影响，呼吁改进转移学习（transfer learning）和公平模型开发以提升医疗成像和患者护理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21149v1",
      "published_date": "2024-07-30 19:23:29 UTC",
      "updated_date": "2024-07-30 19:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:15:50.446307"
    },
    {
      "arxiv_id": "2408.00019v1",
      "title": "WebApp1K: A Practical Code-Generation Benchmark for Web App Development",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Cui"
      ],
      "abstract": "We introduce WebApp1K, a practical code-generation benchmark to measure LLM\nability to develop web apps. This benchmark aims to calibrate LLM output and\naid the models to progressively improve code correctness and functionality. The\nbenchmark is lightweight and easy to run. We present the initial version of\nWebApp1K, and share our findings of running the benchmark against the latest\nfrontier LLMs. First, open source LLMs deliver impressive performance, closely\ntrailing behind GPT-4o and Claude 3.5. Second, model size has strong\ncorrelation with code correctness. Third, no prompting techniques have been\nfound to lift performance either universally to all models, or significantly to\na single model.",
      "tldr_zh": "该论文引入了 WebApp1K，这是一个实用的代码生成基准，用于评估大型语言模型（LLM）在 web 应用开发中的能力。WebApp1K 旨在校准 LLM 输出，帮助模型逐步提升代码正确性和功能性，同时保持轻量级和易于运行。研究发现，开源 LLM 的表现接近 GPT-4o 和 Claude 3.5，模型大小与代码正确性高度相关，但没有任何提示技术能普遍或显著提升所有模型的表现。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.00019v1",
      "published_date": "2024-07-30 18:49:26 UTC",
      "updated_date": "2024-07-30 18:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:15:56.991826"
    },
    {
      "arxiv_id": "2407.21124v1",
      "title": "Zero Shot Health Trajectory Prediction Using Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Pawel Renc",
        "Yugang Jia",
        "Anthony E. Samir",
        "Jaroslaw Was",
        "Quanzheng Li",
        "David W. Bates",
        "Arkadiusz Sitek"
      ],
      "abstract": "Integrating modern machine learning and clinical decision-making has great\npromise for mitigating healthcare's increasing cost and complexity. We\nintroduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a\nnovel application of the transformer deep-learning architecture for analyzing\nhigh-dimensional, heterogeneous, and episodic health data. ETHOS is trained\nusing Patient Health Timelines (PHTs)-detailed, tokenized records of health\nevents-to predict future health trajectories, leveraging a zero-shot learning\napproach. ETHOS represents a significant advancement in foundation model\ndevelopment for healthcare analytics, eliminating the need for labeled data and\nmodel fine-tuning. Its ability to simulate various treatment pathways and\nconsider patient-specific factors positions ETHOS as a tool for care\noptimization and addressing biases in healthcare delivery. Future developments\nwill expand ETHOS' capabilities to incorporate a wider range of data types and\ndata sources. Our work demonstrates a pathway toward accelerated AI development\nand deployment in healthcare.",
      "tldr_zh": "本文提出ETHOS模型，这是一种基于Transformer架构的深度学习方法，用于分析高维、异构和间断的健康数据，并通过零样本学习(zero-shot learning)预测患者未来健康轨迹。ETHOS利用Patient Health Timelines (PHTs)——详细标记化的健康事件记录——进行训练，无需标记数据或模型微调，从而显著提升医疗分析效率。模型能够模拟多种治疗路径、考虑患者特定因素，以优化护理决策、减少医疗偏差，并为AI在医疗领域的快速发展和部署铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21124v1",
      "published_date": "2024-07-30 18:33:05 UTC",
      "updated_date": "2024-07-30 18:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:16:06.159770"
    },
    {
      "arxiv_id": "2407.21118v2",
      "title": "Palu: Compressing KV-Cache with Low-Rank Projection",
      "title_zh": "翻译失败",
      "authors": [
        "Chi-Chih Chang",
        "Wei-Cheng Lin",
        "Chien-Yu Lin",
        "Chong-Yan Chen",
        "Yu-Fang Hu",
        "Pei-Shuo Wang",
        "Ning-Chi Huang",
        "Luis Ceze",
        "Mohamed S. Abdelfattah",
        "Kai-Chiang Wu"
      ],
      "abstract": "Post-training KV-Cache compression methods typically either sample a subset\nof effectual tokens or quantize the data into lower numerical bit width.\nHowever, these methods cannot exploit redundancy in the hidden dimension of the\nKV tensors. This paper presents a hidden dimension compression approach called\nPalu, a KV-Cache compression framework that utilizes low-rank projection to\nreduce inference-time LLM memory usage. Palu decomposes the linear layers into\nlow-rank matrices, caches compressed intermediate states, and reconstructs the\nfull keys and values on the fly. To improve accuracy, compression rate, and\nefficiency, Palu further encompasses (1) a medium-grained low-rank\ndecomposition scheme, (2) an efficient rank search algorithm, (3)\nlow-rank-aware quantization compatibility enhancements, and (4) optimized GPU\nkernels with operators fusion. Extensive experiments with popular LLMs show\nthat Palu compresses KV-Cache by 50% while maintaining strong accuracy and\ndelivering up to 1.89x on the RoPE-based attention module. When combined with\nquantization, Palu's inherent quantization-friendly design yields small to\nnegligible extra accuracy degradation while saving additional memory than\nquantization-only methods and achieving up to 2.91x speedup for the RoPE-based\nattention. Moreover, it maintains comparable or even better accuracy (up to\n1.19 lower perplexity) compared to quantization-only methods. These results\ndemonstrate Palu's superior capability to effectively address the efficiency\nand memory challenges of LLM inference posed by KV-Cache. Our code is publicly\navailable at: https://github.com/shadowpa0327/Palu",
      "tldr_zh": "该论文提出Palu，一种基于低秩投影（low-rank projection）的KV-Cache压缩框架，用于减少LLM（Large Language Models）推理时的内存消耗。Palu通过将线性层分解为低秩矩阵、缓存压缩中间状态并实时重建keys和values，同时整合中粒度低秩分解方案、秩搜索算法、低秩感知量化兼容性和优化的GPU内核，以提升准确性和效率。实验结果显示，Palu可将KV-Cache压缩50%，在RoPE-based attention模块上实现高达1.89x加速，并与量化技术结合时提供额外内存节省和2.91x加速，同时保持或优于量化-only方法的准确性（如低至1.19的困惑度）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21118v2",
      "published_date": "2024-07-30 18:19:38 UTC",
      "updated_date": "2024-11-04 02:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:16:14.707912"
    },
    {
      "arxiv_id": "2407.21018v3",
      "title": "ThinK: Thinner Key Cache by Query-Driven Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhui Xu",
        "Zhanming Jie",
        "Hanze Dong",
        "Lei Wang",
        "Xudong Lu",
        "Aojun Zhou",
        "Amrita Saha",
        "Caiming Xiong",
        "Doyen Sahoo"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, achieving unprecedented performance across a variety of\napplications. However, their increased computational and memory demands present\nsignificant challenges, especially when handling long sequences. This paper\nfocuses on the long-context scenario, addressing the inefficiencies in KV cache\nmemory consumption during inference. Unlike existing approaches that optimize\nthe memory based on the sequence length, we identify substantial redundancy in\nthe channel dimension of the KV cache, as indicated by an uneven magnitude\ndistribution and a low-rank structure in the attention weights. In response, we\npropose ThinK, a novel query-dependent KV cache pruning method designed to\nminimize attention weight loss while selectively pruning the least significant\nchannels. Our approach not only maintains or enhances model accuracy but also\nachieves a reduction in KV cache memory costs by over 20% compared with vanilla\nKV cache eviction and quantization methods. For instance, ThinK integrated with\nKIVI can achieve a 2.8x reduction in peak memory usage while maintaining nearly\nthe same quality, enabling up to a 5x increase in batch size when using a\nsingle GPU. Extensive evaluations on the LLaMA and Mistral models across\nvarious long-sequence datasets verified the efficiency of ThinK, establishing a\nnew baseline algorithm for efficient LLM deployment without compromising\nperformance. Our code has been made available at\nhttps://github.com/SalesforceAIResearch/ThinK.",
      "tldr_zh": "本论文提出 ThinK，一种基于查询驱动的 KV cache 修剪方法，针对 Large Language Models (LLMs) 在处理长序列时存在的 KV cache 内存冗余问题，如不均匀幅度分布和低秩结构。ThinK 通过选择性修剪不重要的通道，最大限度地减少注意力权重损失，同时保持或提升模型准确性。实验结果显示，与现有 KV cache 优化方法相比，ThinK 可减少超过 20% 的内存成本，并在 LLaMA 和 Mistral 模型上实现 2.8x 峰值内存减少和 5x 批量大小提升，确立了高效 LLM 部署的新基准。开源代码已在 GitHub 上发布。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2407.21018v3",
      "published_date": "2024-07-30 17:59:08 UTC",
      "updated_date": "2025-02-27 12:30:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:16:27.038645"
    },
    {
      "arxiv_id": "2407.21011v1",
      "title": "CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuexi Du",
        "Brian Chang",
        "Nicha C. Dvornek"
      ],
      "abstract": "Recent advancements in Contrastive Language-Image Pre-training (CLIP) have\ndemonstrated notable success in self-supervised representation learning across\nvarious tasks. However, the existing CLIP-like approaches often demand\nextensive GPU resources and prolonged training times due to the considerable\nsize of the model and dataset, making them poor for medical applications, in\nwhich large datasets are not always common. Meanwhile, the language model\nprompts are mainly manually derived from labels tied to images, potentially\noverlooking the richness of information within training samples. We introduce a\nnovel language-image Contrastive Learning method with an Efficient large\nlanguage model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of\nthe extensive pre-trained language and visual models. Furthermore, we present\nan efficient strategy for learning context-based prompts that mitigates the gap\nbetween informative clinical diagnostic data and simple class labels. Our\nmethod demonstrates state-of-the-art performance on multiple chest X-ray and\nmammography datasets compared with various baselines. The proposed parameter\nefficient framework can reduce the total trainable model size by 39% and reduce\nthe trainable language model to only 4% compared with the current BERT encoder.",
      "tldr_zh": "我们提出了 CLEFT，一种语言-图像对比学习方法，利用高效的大型语言模型和提示微调，旨在解决现有 CLIP 方法在医疗应用中资源密集和提示设计不足的问题。该方法引入基于上下文的提示学习策略，以桥接临床诊断数据和简单类标签的差距，从而提升模型的性能和信息利用率。在多个胸部 X 光和乳腺 X 光数据集上，CLEFT 比基线模型达到了最先进性能，同时将总可训练模型大小减少 39%，并将语言模型缩减到仅 BERT 编码器的 4%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.21011v1",
      "published_date": "2024-07-30 17:57:32 UTC",
      "updated_date": "2024-07-30 17:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:16:40.125755"
    },
    {
      "arxiv_id": "2407.21009v4",
      "title": "AI-Assisted Generation of Difficult Math Questions",
      "title_zh": "AI 辅助生成困难数学问题",
      "authors": [
        "Vedant Shah",
        "Dingli Yu",
        "Kaifeng Lyu",
        "Simon Park",
        "Jiatong Yu",
        "Yinghui He",
        "Nan Rosemary Ke",
        "Michael Mozer",
        "Yoshua Bengio",
        "Sanjeev Arora",
        "Anirudh Goyal"
      ],
      "abstract": "Current LLM training positions mathematical reasoning as a core capability.\nWith publicly available sources fully tapped, there is unmet demand for diverse\nand challenging math questions. Relying solely on human experts is both\ntime-consuming and costly, while LLM-generated questions often lack the\nrequisite diversity and difficulty. We present a design framework that combines\nthe strengths of LLMs with a human-in-the-loop approach to generate a diverse\narray of challenging math questions. We leverage LLM metacognition skills\n[Didolkar et al., 2024] of a strong LLM to extract core \"skills\" from existing\nmath datasets. These skills serve as the basis for generating novel and\ndifficult questions by prompting the LLM with random pairs of core skills. The\nuse of two different skills within each question makes finding such questions\nan \"out of distribution\" task for both LLMs and humans. Our pipeline employs\nLLMs to iteratively generate and refine questions and solutions through\nmultiturn prompting. Human annotators then verify and further refine the\nquestions, with their efficiency enhanced via further LLM interactions.\nApplying this pipeline on skills extracted from the MATH dataset [Hendrycks et\nal., 2021] resulted in MATH$^2$ - a dataset of higher-quality math questions,\nas evidenced by: (a) Lower performance of all models on MATH$^2$ than on MATH\n(b) Higher performance on MATH when using MATH$^2$ questions as in-context\nexamples. Although focused on mathematics, our methodology seems applicable to\nother domains requiring structured reasoning, and potentially as a component of\nscalable oversight. Also of interest is a striking relationship observed\nbetween models' performance on the new dataset: the success rate on MATH$^2$ is\nthe square on MATH, suggesting that successfully solving the question in\nMATH$^2$ requires a nontrivial combination of two distinct math skills.",
      "tldr_zh": "这篇论文提出一个结合LLM和human-in-the-loop的框架，用于生成多样且具有挑战性的数学问题，以解决现有数据集不足的问题。方法包括利用LLM的元认知技能从MATH数据集提取核心“skills”，然后通过随机配对技能提示LLM生成涉及两种技能的“out of distribution”问题，并通过多轮迭代和人类验证进行精炼。结果创建了MATH²数据集，实验显示模型在MATH²上的表现显著低于MATH，但使用MATH²作为in-context examples可提升模型在MATH上的性能，且成功率呈平方关系，表明问题解决需结合多种技能。该框架可扩展到其他需要结构化推理的领域。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21009v4",
      "published_date": "2024-07-30 17:55:36 UTC",
      "updated_date": "2025-02-03 12:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:16:53.581913"
    },
    {
      "arxiv_id": "2407.21002v1",
      "title": "XHand: Real-time Expressive Hand Avatar",
      "title_zh": "XHand：实时富有表现力的",
      "authors": [
        "Qijun Gan",
        "Zijie Zhou",
        "Jianke Zhu"
      ],
      "abstract": "Hand avatars play a pivotal role in a wide array of digital interfaces,\nenhancing user immersion and facilitating natural interaction within virtual\nenvironments. While previous studies have focused on photo-realistic hand\nrendering, little attention has been paid to reconstruct the hand geometry with\nfine details, which is essential to rendering quality. In the realms of\nextended reality and gaming, on-the-fly rendering becomes imperative. To this\nend, we introduce an expressive hand avatar, named XHand, that is designed to\ncomprehensively generate hand shape, appearance, and deformations in real-time.\nTo obtain fine-grained hand meshes, we make use of three feature embedding\nmodules to predict hand deformation displacements, albedo, and linear blending\nskinning weights, respectively. To achieve photo-realistic hand rendering on\nfine-grained meshes, our method employs a mesh-based neural renderer by\nleveraging mesh topological consistency and latent codes from embedding\nmodules. During training, a part-aware Laplace smoothing strategy is proposed\nby incorporating the distinct levels of regularization to effectively maintain\nthe necessary details and eliminate the undesired artifacts. The experimental\nevaluations on InterHand2.6M and DeepHandMesh datasets demonstrate the efficacy\nof XHand, which is able to recover high-fidelity geometry and texture for hand\nanimations across diverse poses in real-time. To reproduce our results, we will\nmake the full implementation publicly available at\nhttps://github.com/agnJason/XHand.",
      "tldr_zh": "本研究提出 XHand，一种实时表达性手部虚拟形象框架，旨在解决现有方法在手部几何细节重建和照片级渲染方面的不足，提升虚拟环境中的用户交互和沉浸感。XHand 通过三个特征嵌入模块分别预测手部变形位移、albedo 和 linear blending skinning weights，并采用基于网格的神经渲染器，利用网格拓扑一致性和潜在代码实现高保真渲染；同时引入 part-aware Laplace smoothing 策略来保持细节并消除 artifacts。实验在 InterHand2.6M 和 DeepHandMesh 数据集上验证了 XHand 的效能，可实时恢复多样姿势下的高保真手部几何和纹理。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21002v1",
      "published_date": "2024-07-30 17:49:21 UTC",
      "updated_date": "2024-07-30 17:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:17:04.396920"
    },
    {
      "arxiv_id": "2407.21001v3",
      "title": "GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models",
      "title_zh": "GABInsight：探索视觉语言模型中的性别-活动绑定偏差",
      "authors": [
        "Ali Abdollahi",
        "Mahdi Ghaznavi",
        "Mohammad Reza Karimi Nejad",
        "Arash Mari Oriyad",
        "Reza Abbasi",
        "Ali Salesi",
        "Melika Behjati",
        "Mohammad Hossein Rohban",
        "Mahdieh Soleymani Baghshah"
      ],
      "abstract": "Vision-language models (VLMs) are intensively used in many downstream tasks,\nincluding those requiring assessments of individuals appearing in the images.\nWhile VLMs perform well in simple single-person scenarios, in real-world\napplications, we often face complex situations in which there are persons of\ndifferent genders doing different activities. We show that in such cases, VLMs\nare biased towards identifying the individual with the expected gender\n(according to ingrained gender stereotypes in the model or other forms of\nsample selection bias) as the performer of the activity. We refer to this bias\nin associating an activity with the gender of its actual performer in an image\nor text as the Gender-Activity Binding (GAB) bias and analyze how this bias is\ninternalized in VLMs. To assess this bias, we have introduced the GAB dataset\nwith approximately 5500 AI-generated images that represent a variety of\nactivities, addressing the scarcity of real-world images for some scenarios. To\nhave extensive quality control, the generated images are evaluated for their\ndiversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on\nthis dataset in the context of text-to-image and image-to-text retrieval to\nmeasure the effect of this bias on their predictions. Additionally, we have\ncarried out supplementary experiments to quantify the bias in VLMs' text\nencoders and to evaluate VLMs' capability to recognize activities. Our\nexperiments indicate that VLMs experience an average performance decline of\nabout 13.2% when confronted with gender-activity binding bias.",
      "tldr_zh": "本文研究了 Vision-Language Models (VLMs) 中的 Gender-Activity Binding (GAB) 偏见，即模型倾向于将活动与刻板印象中的性别绑定，导致在复杂场景中错误识别活动执行者。研究团队创建了包含约 5500 张 AI 生成图像的 GAB 数据集，并评估了 12 个知名预训练 VLMs 在文本到图像和图像到文本检索任务中的表现，同时进行了补充实验来量化文本编码器的偏见和活动识别能力。实验结果显示，VLMs 面对 GAB 偏见时，平均性能下降约 13.2%。这项工作为揭示和缓解 VLMs 中的性别相关偏见提供了重要洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21001v3",
      "published_date": "2024-07-30 17:46:06 UTC",
      "updated_date": "2024-10-25 11:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:17:19.330708"
    },
    {
      "arxiv_id": "2407.20999v3",
      "title": "MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yupeng Chen",
        "Senmiao Wang",
        "Yushun Zhang",
        "Zhihang Lin",
        "Haozhe Zhang",
        "Weijian Sun",
        "Tian Ding",
        "Ruoyu Sun"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks. Typically, LLMs are first pre-trained on large corpora\nand subsequently fine-tuned on task-specific datasets. However, during\nfine-tuning, LLMs may forget some knowledge acquired in the pre-training stage,\nleading to a decline in general capabilities. Existing approaches to mitigate\nforgetting often rely on access to pre-training data, which may be unavailable\nin many real-world scenarios--such as fine-tuning checkpoint-only open-source\nLLMs. To address this challenge, we propose a new fine-tuning algorithm termed\nMomentum-Filtered Optimizer (MoFO). MoFO is an extension of greedy block\ncoordinate descent (BCD) methods: in each iteration, MoFO only updates the\nmodel parameters with the largest momentum magnitudes, while keeping all other\nparameters fixed. MoFO achieves similar fine-tuning performance to the default\nfine-tuning algorithm while effectively mitigating knowledge forgetting. We\nvalidate MoFO through rigorous convergence analysis and extensive experiments,\ndemonstrating its effectiveness in mitigating forgetting without pre-training\ndata.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在微调过程中可能遗忘预训练知识的问题，导致一般能力下降，而现有方法往往依赖不可用的预训练数据。作者提出了一种新的算法Momentum-Filtered Optimizer (MoFO)，作为贪婪块坐标下降(greedy block coordinate descent, BCD)方法的扩展：在每个迭代中，仅更新具有最大动量幅度的模型参数，从而有效缓解知识遗忘。实验结果显示，MoFO在不需预训练数据的情况下，实现了与默认微调算法相似的性能，并通过严格的收敛分析验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20999v3",
      "published_date": "2024-07-30 17:38:24 UTC",
      "updated_date": "2025-04-18 09:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:17:27.460309"
    },
    {
      "arxiv_id": "2407.20990v1",
      "title": "From Feature Importance to Natural Language Explanations Using LLMs with RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Sule Tekkesinoglu",
        "Lars Kunze"
      ],
      "abstract": "As machine learning becomes increasingly integral to autonomous\ndecision-making processes involving human interaction, the necessity of\ncomprehending the model's outputs through conversational means increases. Most\nrecently, foundation models are being explored for their potential as post hoc\nexplainers, providing a pathway to elucidate the decision-making mechanisms of\npredictive models. In this work, we introduce traceable question-answering,\nleveraging an external knowledge repository to inform the responses of Large\nLanguage Models (LLMs) to user queries within a scene understanding task. This\nknowledge repository comprises contextual details regarding the model's output,\ncontaining high-level features, feature importance, and alternative\nprobabilities. We employ subtractive counterfactual reasoning to compute\nfeature importance, a method that entails analysing output variations resulting\nfrom decomposing semantic features. Furthermore, to maintain a seamless\nconversational flow, we integrate four key characteristics - social, causal,\nselective, and contrastive - drawn from social science research on human\nexplanations into a single-shot prompt, guiding the response generation\nprocess. Our evaluation demonstrates that explanations generated by the LLMs\nencompassed these elements, indicating its potential to bridge the gap between\ncomplex model outputs and natural language expressions.",
      "tldr_zh": "该研究探讨了使用大型语言模型（LLMs）结合检索增强生成（RAG）技术，将机器学习模型的特征重要性转化为自然语言解释，以提升人类交互中的决策透明度。研究引入了可追踪的问答系统，利用外部知识库（包含高层次特征、特征重要性和备选概率）来响应用户查询，并采用减法逆事实推理（subtractive counterfactual reasoning）来分析语义特征分解对输出的影响。论文还整合了社会性（social）、因果性（causal）、选择性（selective）和对比性（contrastive）等特性到单次提示中，确保解释的对话流畅性。评估结果显示，LLMs 生成的解释成功涵盖这些元素，有效桥接了复杂模型输出与自然语言表达的差距。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20990v1",
      "published_date": "2024-07-30 17:27:20 UTC",
      "updated_date": "2024-07-30 17:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:17:43.251901"
    },
    {
      "arxiv_id": "2407.20970v1",
      "title": "Large Language Models (LLMs) for Semantic Communication in Edge-based IoT Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Alakesh Kalita"
      ],
      "abstract": "With the advent of Fifth Generation (5G) and Sixth Generation (6G)\ncommunication technologies, as well as the Internet of Things (IoT), semantic\ncommunication is gaining attention among researchers as current communication\ntechnologies are approaching Shannon's limit. On the other hand, Large Language\nModels (LLMs) can understand and generate human-like text, based on extensive\ntraining on diverse datasets with billions of parameters. Considering the\nrecent near-source computational technologies like Edge, in this article, we\ngive an overview of a framework along with its modules, where LLMs can be used\nunder the umbrella of semantic communication at the network edge for efficient\ncommunication in IoT networks. Finally, we discuss a few applications and\nanalyze the challenges and opportunities to develop such systems.",
      "tldr_zh": "本文探讨了在边缘计算环境中，使用 Large Language Models (LLMs) 提升基于 IoT 网络的语义通信效率。随着 5G 和 6G 技术接近 Shannon's limit，语义通信成为研究热点，而 LLMs 通过其理解和生成类人文本的能力，能优化 IoT 通信。作者概述了一个框架及其模块，将 LLMs 应用于网络边缘，实现高效的数据传输，并讨论了潜在应用、挑战（如计算资源限制）和机会（如系统扩展潜力）。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "6pages, 3 figures, Magazine",
      "pdf_url": "http://arxiv.org/pdf/2407.20970v1",
      "published_date": "2024-07-30 16:57:41 UTC",
      "updated_date": "2024-07-30 16:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:17:53.804932"
    },
    {
      "arxiv_id": "2407.20956v1",
      "title": "An Effective Dynamic Gradient Calibration Method for Continual Learning",
      "title_zh": "一种有效的动态梯度校准方法用于持续学习",
      "authors": [
        "Weichen Lin",
        "Jiaxiang Chen",
        "Ruomin Huang",
        "Hu Ding"
      ],
      "abstract": "Continual learning (CL) is a fundamental topic in machine learning, where the\ngoal is to train a model with continuously incoming data and tasks. Due to the\nmemory limit, we cannot store all the historical data, and therefore confront\nthe ``catastrophic forgetting'' problem, i.e., the performance on the previous\ntasks can substantially decrease because of the missing information in the\nlatter period. Though a number of elegant methods have been proposed, the\ncatastrophic forgetting phenomenon still cannot be well avoided in practice. In\nthis paper, we study the problem from the gradient perspective, where our aim\nis to develop an effective algorithm to calibrate the gradient in each updating\nstep of the model; namely, our goal is to guide the model to be updated in the\nright direction under the situation that a large amount of historical data are\nunavailable. Our idea is partly inspired by the seminal stochastic variance\nreduction methods (e.g., SVRG and SAGA) for reducing the variance of gradient\nestimation in stochastic gradient descent algorithms. Another benefit is that\nour approach can be used as a general tool, which is able to be incorporated\nwith several existing popular CL methods to achieve better performance. We also\nconduct a set of experiments on several benchmark datasets to evaluate the\nperformance in practice.",
      "tldr_zh": "该论文针对 Continual Learning 中的 catastrophic forgetting 问题，提出了一种有效的动态梯度校准方法，以校准模型在每个更新步骤的梯度，确保在缺少历史数据的情况下，模型仍能朝着正确方向学习新任务。方法灵感来源于 SVRG 和 SAGA 等随机方差减少技术，用于减少梯度估计的方差，并可作为通用工具与现有 CL 方法结合以提升性能。实验结果显示，该方法在多个基准数据集上表现出色，有效缓解了遗忘问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20956v1",
      "published_date": "2024-07-30 16:30:09 UTC",
      "updated_date": "2024-07-30 16:30:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:18:06.670759"
    },
    {
      "arxiv_id": "2407.20955v1",
      "title": "Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyue Huang",
        "Ke Chen",
        "Yi-Hsuan Yang"
      ],
      "abstract": "Managing the emotional aspect remains a challenge in automatic music\ngeneration. Prior works aim to learn various emotions at once, leading to\ninadequate modeling. This paper explores the disentanglement of emotions in\npiano performance generation through a two-stage framework. The first stage\nfocuses on valence modeling of lead sheet, and the second stage addresses\narousal modeling by introducing performance-level attributes. To further\ncapture features that shape valence, an aspect less explored by previous\napproaches, we introduce a novel functional representation of symbolic music.\nThis representation aims to capture the emotional impact of major-minor\ntonality, as well as the interactions among notes, chords, and key signatures.\nObjective and subjective experiments validate the effectiveness of our\nframework in both emotional valence and arousal modeling. We further leverage\nour framework in a novel application of emotional controls, showing a broad\npotential in emotion-driven music generation.",
      "tldr_zh": "本文提出一个两阶段分离框架（Two-stage Disentanglement），用于情感驱动的钢琴音乐生成，以解决现有方法在情感建模上的不足。第一阶段专注于lead sheet的valence建模，并引入novel functional representation来捕捉大调小调调性以及音符、和弦和调号之间的互动。第二阶段则处理arousal建模，通过引入performance-level attributes来增强情感表达。客观和主观实验证明，该框架在valence和arousal建模方面有效，并展示了其在情感控制应用中的广泛潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Proceedings of the 25th International Society for Music Information\n  Retrieval Conference, ISMIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20955v1",
      "published_date": "2024-07-30 16:29:28 UTC",
      "updated_date": "2024-07-30 16:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:18:15.972159"
    },
    {
      "arxiv_id": "2407.20951v1",
      "title": "An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Mantelero",
        "Maria Samantha Esposito"
      ],
      "abstract": "Different approaches have been adopted in addressing the challenges of\nArtificial Intelligence (AI), some centred on personal data and others on\nethics, respectively narrowing and broadening the scope of AI regulation. This\ncontribution aims to demonstrate that a third way is possible, starting from\nthe acknowledgement of the role that human rights can play in regulating the\nimpact of data-intensive systems. The focus on human rights is neither a\nparadigm shift nor a mere theoretical exercise. Through the analysis of more\nthan 700 decisions and documents of the data protection authorities of six\ncountries, we show that human rights already underpin the decisions in the\nfield of data use. Based on empirical analysis of this evidence, this work\npresents a methodology and a model for a Human Rights Impact Assessment (HRIA).\nThe methodology and related assessment model are focused on AI applications,\nwhose nature and scale require a proper contextualisation of HRIA methodology.\nMoreover, the proposed models provide a more measurable approach to risk\nassessment which is consistent with the regulatory proposals centred on risk\nthresholds. The proposed methodology is tested in concrete case-studies to\nprove its feasibility and effectiveness. The overall goal is to respond to the\ngrowing interest in HRIA, moving from a mere theoretical debate to a concrete\nand context-specific implementation in the field of data-intensive applications\nbased on AI.",
      "tldr_zh": "这篇论文提出了一种基于证据的人权影响评估 (HRIA) 方法，用于评估 AI 数据密集型系统的开发对人权的影响，作为 AI 监管的第三种途径。作者通过分析六个国家数据保护机构的 700 多个决策和文件，证明人权已然成为数据使用领域的核心支撑，并据此开发了一个可衡量的风险评估模型，适用于 AI 应用的特定情境。实验结果显示，该方法在实际案例中表现出良好的可行性和有效性，最终目标是将 HRIA 从理论讨论转向具体的实施，以应对 AI 领域的监管需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20951v1",
      "published_date": "2024-07-30 16:27:52 UTC",
      "updated_date": "2024-07-30 16:27:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:18:28.556156"
    },
    {
      "arxiv_id": "2407.20932v1",
      "title": "Complete Approximations of Incomplete Queries",
      "title_zh": "不完整查询的完全逼近",
      "authors": [
        "Julien Corman",
        "Werner Nutt",
        "Ognjen Savković"
      ],
      "abstract": "This paper studies the completeness of conjunctive queries over a partially\ncomplete database and the approximation of incomplete queries. Given a query\nand a set of completeness rules (a special kind of tuple generating\ndependencies) that specify which parts of the database are complete, we\ninvestigate whether the query can be fully answered, as if all data were\navailable. If not, we explore reformulating the query into either Maximal\nComplete Specializations (MCSs) or the (unique up to equivalence) Minimal\nComplete Generalization (MCG) that can be fully answered, that is, the best\ncomplete approximations of the query from below or above in the sense of query\ncontainment. We show that the MSG can be characterized as the least fixed-point\nof a monotonic operator in a preorder. Then, we show that an MCS can be\ncomputed by recursive backward application of completeness rules. We study the\ncomplexity of both problems and discuss implementation techniques that rely on\nan ASP and Prolog engines, respectively.",
      "tldr_zh": "本论文研究了在部分完整数据库上结合查询（conjunctive queries）的完整性，以及不完整查询的近似方法。通过给定查询和完整性规则（completeness rules，一种特殊的元组生成依赖，tuple generating dependencies），论文探讨了查询是否能被完全回答。论文的主要贡献包括提出Maximal Complete Specializations (MCSs) 和Minimal Complete Generalization (MCG) 作为查询的最佳完全近似，MCG 被表征为预序（preorder）中单调算子的最小不动点，而MCS 通过递归向后应用完整性规则来计算。最终，论文分析了这些问题的复杂性，并讨论了基于ASP 和Prolog 引擎的实现技术。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "accepted at RuleML+RR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20932v1",
      "published_date": "2024-07-30 16:13:42 UTC",
      "updated_date": "2024-07-30 16:13:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:18:41.588514"
    },
    {
      "arxiv_id": "2407.20918v1",
      "title": "The Realizability of Revision and Contraction Operators in Epistemic Spaces",
      "title_zh": "认识论空间中修正和收缩算子的可实现性",
      "authors": [
        "Kai Sauerwald",
        "Matthias Thimm"
      ],
      "abstract": "This paper studies the realizability of belief revision and belief\ncontraction operators in epistemic spaces. We observe that AGM revision and AGM\ncontraction operators for epistemic spaces are only realizable in precisely\ndetermined epistemic spaces. We define the class of linear change operators, a\nspecial kind of maxichoice operator. When AGM revision, respectively, AGM\ncontraction, is realizable, linear change operators are a canonical\nrealization.",
      "tldr_zh": "这篇论文探讨了在 epistemic spaces 中 belief revision 和 belief contraction 操作的可实现性，指出 AGM revision 和 AGM contraction 操作仅在特定确定的 epistemic spaces 中可实现。论文定义了 linear change operators，这是一种特殊的 maxichoice operator，并将其作为这些操作的可规范实现方式。通过这一研究，为信念变化理论提供了更精确的框架。",
      "categories": [
        "cs.AI",
        "03B42",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20918v1",
      "published_date": "2024-07-30 15:55:01 UTC",
      "updated_date": "2024-07-30 15:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:18:52.462856"
    },
    {
      "arxiv_id": "2407.20917v1",
      "title": "How to Choose a Reinforcement-Learning Algorithm",
      "title_zh": "如何选择强化学习算法",
      "authors": [
        "Fabian Bongratz",
        "Vladimir Golkov",
        "Lukas Mautner",
        "Luca Della Libera",
        "Frederik Heetmeyer",
        "Felix Czaja",
        "Julian Rodemann",
        "Daniel Cremers"
      ],
      "abstract": "The field of reinforcement learning offers a large variety of concepts and\nmethods to tackle sequential decision-making problems. This variety has become\nso large that choosing an algorithm for a task at hand can be challenging. In\nthis work, we streamline the process of choosing reinforcement-learning\nalgorithms and action-distribution families. We provide a structured overview\nof existing methods and their properties, as well as guidelines for when to\nchoose which methods. An interactive version of these guidelines is available\nonline at https://rl-picker.github.io/.",
      "tldr_zh": "这篇论文针对强化学习(Reinforcement Learning)领域的算法多样性，简化了选择算法和动作分布家族的过程。作者提供了现有方法的结构化概述，包括各方法的属性和适用场景，并给出了详细的指导方针。这些指南旨在帮助研究者和从业者更高效地决策，同时还提供了一个在线互动工具（https://rl-picker.github.io/）以便实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML",
        "62M45",
        "I.2.8; I.2.6; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.20917v1",
      "published_date": "2024-07-30 15:54:18 UTC",
      "updated_date": "2024-07-30 15:54:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:19:04.665746"
    },
    {
      "arxiv_id": "2407.20906v5",
      "title": "Automated Review Generation Method Based on Large Language Models",
      "title_zh": "基于大语言模型的自动文献综述生成方法",
      "authors": [
        "Shican Wu",
        "Xiao Ma",
        "Dehui Luo",
        "Lulu Li",
        "Xiangcheng Shi",
        "Xin Chang",
        "Xiaoyun Lin",
        "Ran Luo",
        "Chunlei Pei",
        "Changying Du",
        "Zhi-Jian Zhao",
        "Jinlong Gong"
      ],
      "abstract": "Literature research, vital for scientific work, faces the challenge of\nsurging information volumes exceeding researchers' processing capabilities. We\npresent an automated review generation method based on large language models\n(LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our\nstatistically validated evaluation framework demonstrates that the generated\nreviews match or exceed manual quality, offering broad applicability across\nresearch fields without requiring users' domain knowledge. Applied to propane\ndehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles,\naveraging seconds per article per LLM account, producing comprehensive reviews\nspanning 35 topics, with extended analysis of 1041 articles providing insights\ninto catalysts' properties. Through multi-layered quality control, we\neffectively mitigated LLMs' hallucinations, with expert verification confirming\naccuracy and citation integrity while demonstrating hallucination risks reduced\nto below 0.5\\% with 95\\% confidence. Released Windows application enables\none-click review generation, enhancing research productivity and literature\nrecommendation efficiency while setting the stage for broader scientific\nexplorations.",
      "tldr_zh": "本研究提出了一种基于 Large Language Models (LLMs) 的自动文献综述生成方法，旨在解决文献研究中信息量过载导致的效率和认知负担问题。该方法采用统计验证框架和多层质量控制机制，有效减少 LLMs 的 hallucinations，确保生成的综述质量匹配或超过手动水平，并在丙烷脱氢 (PDH) 催化剂领域快速分析了343篇文章，扩展至1041篇文章，提供覆盖35个主题的全面洞见。实验结果显示，幻觉风险降至低于0.5%（95%置信度），并通过发布的Windows应用实现一键生成，提升了研究生产力和文献推荐效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "physics.data-an"
      ],
      "primary_category": "cs.CL",
      "comment": "Code: https://github.com/TJU-ECAT-AI/AutomaticReviewGeneration Data:\n  https://github.com/TJU-ECAT-AI/AutomaticReviewGenerationData This research\n  has been invited for a Short Oral presentation at the 18th ICC -\n  International Congress on Catalysis, taking place in Lyon, France from July\n  14-19, 2024 Published at https://doi.org/10.1093/nsr/nwaf169 for newer\n  edition",
      "pdf_url": "http://arxiv.org/pdf/2407.20906v5",
      "published_date": "2024-07-30 15:26:36 UTC",
      "updated_date": "2025-05-01 16:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:19:20.836839"
    },
    {
      "arxiv_id": "2407.20899v3",
      "title": "Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach",
      "title_zh": "针对图像分类的忠实且合理的自然语言解释：一种管道方法",
      "authors": [
        "Adam Wojciechowski",
        "Mateusz Lango",
        "Ondrej Dusek"
      ],
      "abstract": "Existing explanation methods for image classification struggle to provide\nfaithful and plausible explanations. This paper addresses this issue by\nproposing a post-hoc natural language explanation method that can be applied to\nany CNN-based classifier without altering its training process or affecting\npredictive performance. By analysing influential neurons and the corresponding\nactivation maps, the method generates a faithful description of the\nclassifier's decision process in the form of a structured meaning\nrepresentation, which is then converted into text by a language model. Through\nthis pipeline approach, the generated explanations are grounded in the neural\nnetwork architecture, providing accurate insight into the classification\nprocess while remaining accessible to non-experts. Experimental results show\nthat the NLEs constructed by our method are significantly more plausible and\nfaithful. In particular, user interventions in the neural network structure\n(masking of neurons) are three times more effective than the baselines.",
      "tldr_zh": "本文提出了一种后验（post-hoc）自然语言解释方法，用于图像分类模型，提供忠实（faithful）和合理的（plausible）解释，而无需修改基于 CNN 的分类器的训练过程或预测性能。该方法通过分析影响神经元（influential neurons）和对应的激活映射（activation maps），生成结构化含义表示（structured meaning representation），并使用语言模型将其转换为可读文本，从而确保解释准确且易于非专家理解。实验结果显示，该方法的自然语言解释（NLEs）在合理性和忠实性上显著优于基线模型，特别是用户对神经网络结构的干预（如神经元掩盖）比基线有效三倍。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20899v3",
      "published_date": "2024-07-30 15:17:15 UTC",
      "updated_date": "2025-03-18 14:13:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:19:28.686594"
    },
    {
      "arxiv_id": "2407.20893v1",
      "title": "MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yinlong Xu",
        "Xiaoqiang Liu",
        "Zitai Kong",
        "Yixuan Wu",
        "Yue Wang",
        "Yingzhou Lu",
        "Honghao Gao",
        "Jian Wu",
        "Hongxia Xu"
      ],
      "abstract": "Cardiac arrhythmia, a condition characterized by irregular heartbeats, often\nserves as an early indication of various heart ailments. With the advent of\ndeep learning, numerous innovative models have been introduced for diagnosing\narrhythmias using Electrocardiogram (ECG) signals. However, recent studies\nsolely focus on the performance of models, neglecting the interpretation of\ntheir results. This leads to a considerable lack of transparency, posing a\nsignificant risk in the actual diagnostic process. To solve this problem, this\npaper introduces MambaCapsule, a deep neural networks for ECG arrhythmias\nclassification, which increases the explainability of the model while enhancing\nthe accuracy.Our model utilizes Mamba for feature extraction and Capsule\nnetworks for prediction, providing not only a confidence score but also signal\nfeatures. Akin to the processing mechanism of human brain, the model learns\nsignal features and their relationship between them by reconstructing ECG\nsignals in the predicted selection. The model evaluation was conducted on\nMIT-BIH and PTB dataset, following the AAMI standard. MambaCapsule has achieved\na total accuracy of 99.54% and 99.59% on the test sets respectively. These\nresults demonstrate the promising performance of under the standard test\nprotocol.",
      "tldr_zh": "该论文针对心律失常诊断中的模型透明度问题，提出 MambaCapsule 网络，用于基于 Electrocardiogram (ECG) 信号的精确分类。模型结合 Mamba 进行特征提取和 Capsule networks 进行预测，通过重建 ECG 信号模拟人脑机制，提供置信分数和信号特征解释，从而提升模型的可解释性。实验在 MIT-BIH 和 PTB 数据集上按 AAMI 标准评估，分别实现 99.54% 和 99.59% 的准确率，展示了其在心脏病诊断中的潜在应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20893v1",
      "published_date": "2024-07-30 15:12:29 UTC",
      "updated_date": "2024-07-30 15:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:19:41.794661"
    },
    {
      "arxiv_id": "2407.20891v5",
      "title": "Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Bao Gia Doan",
        "Afshar Shamsi",
        "Xiao-Yu Guo",
        "Arash Mohammadi",
        "Hamid Alinejad-Rokny",
        "Dino Sejdinovic",
        "Damien Teney",
        "Damith C. Ranasinghe",
        "Ehsan Abbasnejad"
      ],
      "abstract": "Computational complexity of Bayesian learning is impeding its adoption in\npractical, large-scale tasks. Despite demonstrations of significant merits such\nas improved robustness and resilience to unseen or out-of-distribution inputs\nover their non- Bayesian counterparts, their practical use has faded to near\ninsignificance. In this study, we introduce an innovative framework to mitigate\nthe computational burden of Bayesian neural networks (BNNs). Our approach\nfollows the principle of Bayesian techniques based on deep ensembles, but\nsignificantly reduces their cost via multiple low-rank perturbations of\nparameters arising from a pre-trained neural network. Both vanilla version of\nensembles as well as more sophisticated schemes such as Bayesian learning with\nStein Variational Gradient Descent (SVGD), previously deemed impractical for\nlarge models, can be seamlessly implemented within the proposed framework,\ncalled Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves a\ndramatic reduction in the number of trainable parameters required to\napproximate a Bayesian posterior; and ii) it not only maintains, but in some\ninstances, surpasses the performance of conventional Bayesian learning methods\nand non-Bayesian baselines. Our results with large-scale tasks such as\nImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate the\neffectiveness and versatility of Bella in building highly scalable and\npractical Bayesian deep models for real-world applications.",
      "tldr_zh": "该研究提出了一种名为 Bayesian Low-Rank LeArning (Bella) 的框架，以缓解 Bayesian Neural Networks (BNNs) 在大规模任务中的计算复杂度问题，通过对预训练神经网络参数进行多个 low-rank perturbations 来显著减少训练参数数量，同时支持传统集合方法和高级技术如 Stein Variational Gradient Descent (SVGD)。Bella 不仅维持了 Bayesian 学习的优势，如提升鲁棒性和对未知输入的抵抗力，还在某些情况下超过了传统 Bayesian 方法和非-Bayesian 基线的性能。实验在 ImageNet、CAMELYON17、DomainNet、VQA with CLIP 和 LLaVA 等数据集上验证了其有效性与通用性，为构建可扩展的实际 Bayesian 深度模型提供了实用途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted in AAAI'25\", and the code is available at\n  https://bnn-bella.github.io/BNN-Bella/",
      "pdf_url": "http://arxiv.org/pdf/2407.20891v5",
      "published_date": "2024-07-30 15:07:13 UTC",
      "updated_date": "2025-02-18 12:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:19:56.403009"
    },
    {
      "arxiv_id": "2407.20884v1",
      "title": "Effective Black Box Testing of Sentiment Analysis Classification Networks",
      "title_zh": "情感分析分类网络的有效黑盒测试",
      "authors": [
        "Parsa Karbasizadeh",
        "Fathiyeh Faghih",
        "Pouria Golshanrad"
      ],
      "abstract": "Transformer-based neural networks have demonstrated remarkable performance in\nnatural language processing tasks such as sentiment analysis. Nevertheless, the\nissue of ensuring the dependability of these complicated architectures through\ncomprehensive testing is still open. This paper presents a collection of\ncoverage criteria specifically designed to assess test suites created for\ntransformer-based sentiment analysis networks. Our approach utilizes input\nspace partitioning, a black-box method, by considering emotionally relevant\nlinguistic features such as verbs, adjectives, adverbs, and nouns. In order to\neffectively produce test cases that encompass a wide range of emotional\nelements, we utilize the k-projection coverage metric. This metric minimizes\nthe complexity of the problem by examining subsets of k features at the same\ntime, hence reducing dimensionality. Large language models are employed to\ngenerate sentences that display specific combinations of emotional features.\nThe findings from experiments obtained from a sentiment analysis dataset\nillustrate that our criteria and generated tests have led to an average\nincrease of 16\\% in test coverage. In addition, there is a corresponding\naverage decrease of 6.5\\% in model accuracy, showing the ability to identify\nvulnerabilities. Our work provides a foundation for improving the dependability\nof transformer-based sentiment analysis systems through comprehensive test\nevaluation.",
      "tldr_zh": "这篇论文针对 Transformer-based 情感分析分类网络，提出了一套基于输入空间分区的 black-box 测试方法，以评估测试套件的覆盖标准。方法通过考虑情感相关特征（如动词、形容词、副词和名词），并利用 k-projection coverage 指标结合大型语言模型生成多样化的测试用例，从而降低问题复杂性。实验结果显示，在情感分析数据集上，测试覆盖率平均提高了 16%，而模型准确率下降了 6.5%，证明了该方法在识别网络漏洞和提升系统可靠性方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper uses LaTeX with the IEEEtran.cls document class",
      "pdf_url": "http://arxiv.org/pdf/2407.20884v1",
      "published_date": "2024-07-30 14:58:11 UTC",
      "updated_date": "2024-07-30 14:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:20:05.251811"
    },
    {
      "arxiv_id": "2407.20879v1",
      "title": "A Scalable Tool For Analyzing Genomic Variants Of Humans Using Knowledge Graphs and Machine Learning",
      "title_zh": "一种利用知识图谱和机器学习分析人类基因组变异的可扩展工具",
      "authors": [
        "Shivika Prasanna",
        "Ajay Kumar",
        "Deepthi Rao",
        "Eduardo Simoes",
        "Praveen Rao"
      ],
      "abstract": "The integration of knowledge graphs and graph machine learning (GML) in\ngenomic data analysis offers several opportunities for understanding complex\ngenetic relationships, especially at the RNA level. We present a comprehensive\napproach for leveraging these technologies to analyze genomic variants,\nspecifically in the context of RNA sequencing (RNA-seq) data from COVID-19\npatient samples. The proposed method involves extracting variant-level genetic\ninformation, annotating the data with additional metadata using SnpEff, and\nconverting the enriched Variant Call Format (VCF) files into Resource\nDescription Framework (RDF) triples. The resulting knowledge graph is further\nenhanced with patient metadata and stored in a graph database, facilitating\nefficient querying and indexing. We utilize the Deep Graph Library (DGL) to\nperform graph machine learning tasks, including node classification with\nGraphSAGE and Graph Convolutional Networks (GCNs). Our approach demonstrates\nsignificant utility using our proposed tool, VariantKG, in three key scenarios:\nenriching graphs with new VCF data, creating subgraphs based on user-defined\nfeatures, and conducting graph machine learning for node classification.",
      "tldr_zh": "本研究提出了一种可扩展工具VariantKG，用于利用知识图谱(Knowledge Graphs)和图机器学习(Graph Machine Learning, GML)分析人类基因组变异，特别针对COVID-19患者RNA测序(RNA-seq)数据。方法包括提取变异信息、使用SnpEff注解数据、将VCF文件转换为RDF三元组构建知识图谱，并整合患者元数据存储于图数据库中。接着，通过Deep Graph Library (DGL)应用GraphSAGE和Graph Convolutional Networks (GCNs)进行节点分类等任务。该工具在三个关键场景中展示了显著效用：丰富图谱数据、创建基于用户特征的子图，以及进行图机器学习分析，从而提升了基因组变异理解的效率和准确性。",
      "categories": [
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2312.04423",
      "pdf_url": "http://arxiv.org/pdf/2407.20879v1",
      "published_date": "2024-07-30 14:56:10 UTC",
      "updated_date": "2024-07-30 14:56:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:20:17.635195"
    },
    {
      "arxiv_id": "2407.20856v1",
      "title": "Learn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Sarthak Anand",
        "Yutong Jiang",
        "Giorgi Kokaia"
      ],
      "abstract": "The rapid evolution of large language models (LLMs) has opened up new\npossibilities for applications such as context-driven product recommendations.\nHowever, the effectiveness of these models in this context is heavily reliant\non their comprehensive understanding of the product inventory. This paper\npresents a novel approach to equipping LLMs with product knowledge by training\nthem to respond contextually to synthetic search queries that include product\nIDs. We delve into an extensive analysis of this method, evaluating its\neffectiveness, outlining its benefits, and highlighting its constraints. The\npaper also discusses the potential improvements and future directions for this\napproach, providing a comprehensive understanding of the role of LLMs in\nproduct recommendations.",
      "tldr_zh": "本研究提出了一种名为“Learn by Selling”的方法，通过训练大型语言模型（LLMs）来响应包含产品 ID 的合成搜索查询，从而赋予模型对产品库存的全面知识，以提升上下文驱动的产品推荐能力。该方法的核心在于让 LLMs 通过模拟真实查询学习产品知识，并通过详细分析评估了其有效性、优势（如更准确的推荐）和局限性（如潜在的泛化问题）。实验结果显示，该方法显著改善了 LLMs 在推荐任务中的表现，并为未来优化和扩展（如改进查询设计）提供了方向。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20856v1",
      "published_date": "2024-07-30 14:31:53 UTC",
      "updated_date": "2024-07-30 14:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:20:28.924956"
    },
    {
      "arxiv_id": "2407.20830v1",
      "title": "Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing",
      "title_zh": "翻译失败",
      "authors": [
        "Eugenio Lomurno",
        "Matteo Matteucci"
      ],
      "abstract": "Federated learning has emerged as a paradigm for collaborative learning,\nenabling the development of robust models without the need to centralise\nsensitive data. However, conventional federated learning techniques have\nprivacy and security vulnerabilities due to the exposure of models, parameters\nor updates, which can be exploited as an attack surface. This paper presents\nFederated Knowledge Recycling (FedKR), a cross-silo federated learning approach\nthat uses locally generated synthetic data to facilitate collaboration between\ninstitutions. FedKR combines advanced data generation techniques with a dynamic\naggregation process to provide greater security against privacy attacks than\nexisting methods, significantly reducing the attack surface. Experimental\nresults on generic and medical datasets show that FedKR achieves competitive\nperformance, with an average improvement in accuracy of 4.24% compared to\ntraining models from local data, demonstrating particular effectiveness in data\nscarcity scenarios.",
      "tldr_zh": "本文提出Federated Knowledge Recycling (FedKR)，一种跨库联邦学习方法，通过本地生成的合成数据实现机构间的协作，从而增强隐私保护并减少攻击面。FedKR 结合高级数据生成技术和动态聚合过程，比传统联邦学习技术提供更强的安全性。实验结果显示，在通用和医疗数据集上，FedKR 比仅使用本地数据训练的模型准确率平均提高4.24%，在数据稀缺场景中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20830v1",
      "published_date": "2024-07-30 13:56:26 UTC",
      "updated_date": "2024-07-30 13:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:20:45.128150"
    },
    {
      "arxiv_id": "2407.20828v1",
      "title": "How to Measure the Intelligence of Large Language Models?",
      "title_zh": "如何衡量大型语言模型的智能？",
      "authors": [
        "Nils Körber",
        "Silvan Wehrli",
        "Christopher Irrgang"
      ],
      "abstract": "With the release of ChatGPT and other large language models (LLMs) the\ndiscussion about the intelligence, possibilities, and risks, of current and\nfuture models have seen large attention. This discussion included much debated\nscenarios about the imminent rise of so-called \"super-human\" AI, i.e., AI\nsystems that are orders of magnitude smarter than humans. In the spirit of Alan\nTuring, there is no doubt that current state-of-the-art language models already\npass his famous test. Moreover, current models outperform humans in several\nbenchmark tests, so that publicly available LLMs have already become versatile\ncompanions that connect everyday life, industry and science. Despite their\nimpressive capabilities, LLMs sometimes fail completely at tasks that are\nthought to be trivial for humans. In other cases, the trustworthiness of LLMs\nbecomes much more elusive and difficult to evaluate. Taking the example of\nacademia, language models are capable of writing convincing research articles\non a given topic with only little input. Yet, the lack of trustworthiness in\nterms of factual consistency or the existence of persistent hallucinations in\nAI-generated text bodies has led to a range of restrictions for AI-based\ncontent in many scientific journals. In view of these observations, the\nquestion arises as to whether the same metrics that apply to human intelligence\ncan also be applied to computational methods and has been discussed\nextensively. In fact, the choice of metrics has already been shown to\ndramatically influence assessments on potential intelligence emergence. Here,\nwe argue that the intelligence of LLMs should not only be assessed by\ntask-specific statistical metrics, but separately in terms of qualitative and\nquantitative measures.",
      "tldr_zh": "该论文探讨了如何评估大型语言模型 (LLMs) 的智能性问题，指出尽管 LLMs 如 ChatGPT 已通过图灵测试并在某些基准测试中超越人类，但它们在简单任务上可能失败，且存在幻觉和事实一致性问题。作者强调，仅靠任务特定的统计指标不足以全面评估 LLMs 的智能，而是需要结合定性和定量措施，以更准确地衡量其能力。最终，该研究呼吁采用更全面的评估框架，以避免指标选择对智能评估的影响，并为未来 AI 发展提供更可靠的指导。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "3 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2407.20828v1",
      "published_date": "2024-07-30 13:53:48 UTC",
      "updated_date": "2024-07-30 13:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:20:52.790712"
    },
    {
      "arxiv_id": "2407.20822v1",
      "title": "Adding Circumscription to Decidable Fragments of First-Order Logic: A Complexity Rollercoaster",
      "title_zh": "翻译失败",
      "authors": [
        "Carsten Lutz",
        "Quentin Manière"
      ],
      "abstract": "We study extensions of expressive decidable fragments of first-order logic\nwith circumscription, in particular the two-variable fragment FO$^2$, its\nextension C$^2$ with counting quantifiers, and the guarded fragment GF. We\nprove that if only unary predicates are minimized (or fixed) during\ncircumscription, then decidability of logical consequence is preserved. For\nFO$^2$ the complexity increases from $\\textrm{coNexp}$ to\n$\\textrm{coNExp}^\\textrm{NP}$-complete, for GF it (remarkably!) increases from\n$\\textrm{2Exp}$ to $\\textrm{Tower}$-complete, and for C$^2$ the complexity\nremains open. We also consider querying circumscribed knowledge bases whose\nontology is a GF sentence, showing that the problem is decidable for unions of\nconjunctive queries, $\\textrm{Tower}$-complete in combined complexity, and\nelementary in data complexity. Already for atomic queries and ontologies that\nare sets of guarded existential rules, however, for every $k \\geq 0$ there is\nan ontology and query that are $k$-$\\textrm{Exp}$-hard in data complexity.",
      "tldr_zh": "本研究探讨了将 Circumscription 添加到一阶逻辑的可决碎片（如 FO²、C² 和 GF）中的影响，焦点在于仅最小化一元谓词时如何保留可决性。结果显示，对于 FO²，逻辑后果的可决性复杂度从 coNExp 上升到 coNExp^NP-complete；对于 GF，从 2Exp 增加到 Tower-complete；C² 的复杂度则仍未解决。该论文还证明了查询 Circumscribed 知识库（本体为 GF 句子）是可决的，对于联合共轭查询，在组合复杂度上为 Tower-complete，在数据复杂度上为初等；然而，对于原子查询和守卫存在规则的本体，数据复杂度可能达到任意 k-Exp-hard，这突显了扩展逻辑的复杂性挑战。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages - Extended version of a paper accepted at KR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20822v1",
      "published_date": "2024-07-30 13:39:38 UTC",
      "updated_date": "2024-07-30 13:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:21:05.374424"
    },
    {
      "arxiv_id": "2407.20806v1",
      "title": "ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hosung Lee",
        "Sejin Kim",
        "Seungpil Lee",
        "Sanha Hwang",
        "Jihwan Lee",
        "Byung-Jun Lee",
        "Sundong Kim"
      ],
      "abstract": "This paper introduces ARCLE, an environment designed to facilitate\nreinforcement learning research on the Abstraction and Reasoning Corpus (ARC).\nAddressing this inductive reasoning benchmark with reinforcement learning\npresents these challenges: a vast action space, a hard-to-reach goal, and a\nvariety of tasks. We demonstrate that an agent with proximal policy\noptimization can learn individual tasks through ARCLE. The adoption of\nnon-factorial policies and auxiliary losses led to performance enhancements,\neffectively mitigating issues associated with action spaces and goal\nattainment. Based on these insights, we propose several research directions and\nmotivations for using ARCLE, including MAML, GFlowNets, and World Models.",
      "tldr_zh": "这篇论文介绍了 ARCLE，这是一个专为强化学习设计的学习环境，旨在解决 Abstraction and Reasoning Corpus (ARC) 中的归纳推理挑战，包括巨大的动作空间、难以达到的目标和任务多样性。研究者通过 Proximal Policy Optimization (PPO) 代理来学习单个任务，并采用非-factorial 策略和辅助损失，显著提升了性能并缓解了相关问题。基于这些发现，论文提出了未来研究方向，如 MAML、GFlowNets 和 World Models，以进一步推进 ARCLE 的应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by CoLLAs 2024, Project page:\n  https://github.com/confeitoHS/arcle",
      "pdf_url": "http://arxiv.org/pdf/2407.20806v1",
      "published_date": "2024-07-30 13:11:45 UTC",
      "updated_date": "2024-07-30 13:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:21:18.035716"
    },
    {
      "arxiv_id": "2407.20798v1",
      "title": "Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Norman Di Palo",
        "Leonard Hasenclever",
        "Jan Humplik",
        "Arunkumar Byravan"
      ],
      "abstract": "We introduce Diffusion Augmented Agents (DAAG), a novel framework that\nleverages large language models, vision language models, and diffusion models\nto improve sample efficiency and transfer learning in reinforcement learning\nfor embodied agents. DAAG hindsight relabels the agent's past experience by\nusing diffusion models to transform videos in a temporally and geometrically\nconsistent way to align with target instructions with a technique we call\nHindsight Experience Augmentation. A large language model orchestrates this\nautonomous process without requiring human supervision, making it well-suited\nfor lifelong learning scenarios. The framework reduces the amount of\nreward-labeled data needed to 1) finetune a vision language model that acts as\na reward detector, and 2) train RL agents on new tasks. We demonstrate the\nsample efficiency gains of DAAG in simulated robotics environments involving\nmanipulation and navigation. Our results show that DAAG improves learning of\nreward detectors, transferring past experience, and acquiring new tasks - key\nabilities for developing efficient lifelong learning agents. Supplementary\nmaterial and visualizations are available on our website\nhttps://sites.google.com/view/diffusion-augmented-agents/",
      "tldr_zh": "我们研究了 Diffusion Augmented Agents (DAAG)，一个新框架，利用大型语言模型(LLMs)、视觉语言模型(VLMs)和扩散模型来提升强化学习中的样本效率和迁移学习。DAAG 通过 Hindsight Experience Augmentation 技术，对代理的过去经验进行时空一致的视频转换，以对齐目标指令，并由 LLM 自主协调整个过程，无需人工监督。该框架显著减少了微调 VLM 作为奖励检测器和训练 RL 代理所需的数据量，并在模拟机器人环境中的操作和导航任务中，展示了改善学习、经验转移和新任务获取的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at 3rd Conference on Lifelong Learning Agents (CoLLAs),\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20798v1",
      "published_date": "2024-07-30 13:01:31 UTC",
      "updated_date": "2024-07-30 13:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:21:30.785767"
    },
    {
      "arxiv_id": "2407.20792v1",
      "title": "How Novice Programmers Use and Experience ChatGPT when Solving Programming Exercises in an Introductory Course",
      "title_zh": "新手程序员在解决入门课程编程练习时如何使用和体验 ChatGPT",
      "authors": [
        "Andreas Scholl",
        "Natalie Kiesler"
      ],
      "abstract": "This research paper contributes to the computing education research\ncommunity's understanding of Generative AI (GenAI) in the context of\nintroductory programming, and specifically, how students utilize related tools,\nsuch as ChatGPT. An increased understanding of students' use is mandatory for\neducators and higher education institutions, as GenAI is here to stay, and its\nperformance is likely to improve rapidly in the near future. Learning about\nstudents' use patterns is not only crucial to support their learning, but to\ndevelop adequate forms of instruction and assessment. With the rapid\nadvancement of AI, its broad availability, and ubiquitous presence in\neducational environments, elaborating how AI can enhance learning experiences,\nespecially in courses such as introductory programming is important. To date,\nmost studies have focused on the educator's perspective on GenAI, its\nperformance, characteristics, and limitations. However, the student\nperspective, and how they actually use GenAI tools in course contexts, has not\nbeen subject to a great number of studies. Therefore, this study is guided by\nthe following research questions: (1) What do students report on their use\npattern of ChatGPT in the context of introductory programming exercises? and\n(2) How do students perceive ChatGPT in the context of introductory programming\nexercises? To address these questions, computing students at a large German\nuniversity were asked to solve programming tasks with the assistance of ChatGPT\nas part of their introductory programming course. Students (n=298) provided\ninformation regarding the use of ChatGPT, and their evaluation of the tool via\nan online survey. This research provides a comprehensive evaluation of\nChatGPT-3.5's application by novice programmers in a higher education\ncontext...",
      "tldr_zh": "这篇论文探讨了新手程序员在入门级编程课程中使用 ChatGPT 解决编程练习的模式和体验，旨在帮助教育者更好地理解 Generative AI 在教育中的作用。研究通过在线调查收集了 298 名德国大学学生的反馈，分析了他们的使用习惯（如具体应用场景）和对 ChatGPT 的评价。结果强调，这种学生视角的研究有助于改进教学方法、评估策略，并适应 Generative AI 的快速发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at 2024 IEEE ASEE Frontiers in Education Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.20792v1",
      "published_date": "2024-07-30 12:55:42 UTC",
      "updated_date": "2024-07-30 12:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:21:54.066581"
    },
    {
      "arxiv_id": "2407.20786v2",
      "title": "Be aware of overfitting by hyperparameter optimization!",
      "title_zh": "翻译失败",
      "authors": [
        "Igor V. Tetko",
        "Ruud van Deursen",
        "Guillaume Godin"
      ],
      "abstract": "Hyperparameter optimization is very frequently employed in machine learning.\nHowever, an optimization of a large space of parameters could result in\noverfitting of models. In recent studies on solubility prediction the authors\ncollected seven thermodynamic and kinetic solubility datasets from different\ndata sources. They used state-of-the-art graph-based methods and compared\nmodels developed for each dataset using different data cleaning protocols and\nhyperparameter optimization. In our study we showed that hyperparameter\noptimization did not always result in better models, possibly due to\noverfitting when using the same statistical measures. Similar results could be\ncalculated using pre-set hyperparameters, reducing the computational effort by\naround 10,000 times. We also extended the previous analysis by adding a\nrepresentation learning method based on Natural Language Processing of smiles\ncalled Transformer CNN. We show that across all analyzed sets using exactly the\nsame protocol, Transformer CNN provided better results than graph-based methods\nfor 26 out of 28 pairwise comparisons by using only a tiny fraction of time as\ncompared to other methods. Last but not least we stressed the importance of\ncomparing calculation results using exactly the same statistical measures.",
      "tldr_zh": "本研究警告超参数优化（hyperparameter optimization）在机器学习中的潜在过拟合（overfitting）风险，通过分析七个溶解度数据集来评估不同数据清洗协议和超参数优化对图-based 方法的影响。结果显示，超参数优化并不总是提升模型性能，且使用预设超参数可获得类似效果，同时将计算努力减少约10,000倍。研究还引入了基于自然语言处理（Natural Language Processing）的Transformer CNN方法，在28对比较中，有26次优于图-based 方法，且计算时间更短。最后，强调了使用相同统计措施进行结果比较的重要性，以确保公平评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2407.20786v2",
      "published_date": "2024-07-30 12:45:05 UTC",
      "updated_date": "2024-11-24 07:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:21:53.749276"
    },
    {
      "arxiv_id": "2407.20777v1",
      "title": "Metaheuristic Enhanced with Feature-Based Guidance and Diversity Management for Solving the Capacitated Vehicle Routing Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Bachtiar Herdianto",
        "Romain Billot",
        "Flavien Lucas",
        "Marc Sevaux"
      ],
      "abstract": "We propose a metaheuristic algorithm enhanced with feature-based guidance\nthat is designed to solve the Capacitated Vehicle Routing Problem (CVRP). To\nformulate the proposed guidance, we developed and explained a supervised\nMachine Learning (ML) model, that is used to formulate the guidance and control\nthe diversity of the solution during the optimization process. We propose a\nmetaheuristic algorithm combining neighborhood search and a novel mechanism of\nhybrid split and path relinking to implement the proposed guidance. The\nproposed guidance has proven to give a statistically significant improvement to\nthe proposed metaheuristic algorithm when solving CVRP. Moreover, the proposed\nguided metaheuristic is also capable of producing competitive solutions among\nstate-of-the-art metaheuristic algorithms.",
      "tldr_zh": "本研究提出了一种增强的元启发式算法（Metaheuristic），通过 feature-based guidance 和 diversity management 来解决 Capacitated Vehicle Routing Problem (CVRP)。该算法利用监督 Machine Learning (ML) 模型来制定指导机制，并结合 neighborhood search 和一个新型的 hybrid split and path relinking 机制，以控制解决方案的多样性和优化过程。实验结果表明，该指导机制为算法带来了统计上显著的性能提升，并能产生与最先进元启发式算法竞争的解决方案。",
      "categories": [
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.AI",
      "comment": "https://hal.science/hal-04663574",
      "pdf_url": "http://arxiv.org/pdf/2407.20777v1",
      "published_date": "2024-07-30 12:26:07 UTC",
      "updated_date": "2024-07-30 12:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:22:16.493728"
    },
    {
      "arxiv_id": "2407.20775v2",
      "title": "Interpretable Pre-Trained Transformers for Heart Time-Series Data",
      "title_zh": "翻译失败",
      "authors": [
        "Harry J. Davies",
        "James Monsen",
        "Danilo P. Mandic"
      ],
      "abstract": "Decoder-only transformers are the backbone of the popular generative\npre-trained transformer (GPT) series of large language models. In this work, we\nemploy this framework to the analysis of clinical heart time-series data, to\ncreate two pre-trained general purpose cardiac models, termed PPG-PT and\nECG-PT. We place a special emphasis on making both such pre-trained models\nfully interpretable. This is achieved firstly through aggregate attention maps\nwhich show that, in order to make predictions, the model focuses on similar\npoints in previous cardiac cycles and gradually broadens its attention in\ndeeper layers. Next, we show that tokens with the same value, which occur at\ndifferent distinct points in the electrocardiography (ECG) and\nphotoplethysmography (PPG) cycle, form separate clusters in high dimensional\nspace. The clusters form according to phase, as the tokens propagate through\nthe transformer blocks. Finally, we highlight that individual attention heads\nrespond to specific physiologically relevent features, such as the dicrotic\nnotch in PPG and the P-wave in ECG. It is also demonstrated that these\npre-trained models are straightforward to fine-tune for tasks such as\nclassification of atrial fibrillation (AF), and beat detection in\nphotoplethysmography. For the example of AF, the fine-tuning took 11 minutes of\ncomputer time, and achieved the respective leave-one-subject-out AUCs of 0.99\nand 0.93 for ECG and PPG within the MIMIC Perform AF dataset. In addition, the\nfine-tuned beat detector achieved a state-of-the-art F1 score of 98%, as well\nas uniquely providing a beat confidence level which acts as a signal quality\nestimator. Importantly, the fine-tuned models for AF screening are also fully\nexplainable, with attention shifting to regions in the context that are\nstrongly indicative of atrial fibrillation.",
      "tldr_zh": "本研究使用decoder-only Transformers框架，开发了两个可解释的预训练模型PPG-PT和ECG-PT，针对临床心脏时间序列数据（如PPG和ECG）进行分析。模型通过聚合注意力图（aggregate attention maps）显示注意力模式、基于相位的token集群以及特定注意力头对生理特征（如PPG的dicrotic notch和ECG的P-wave）的响应，实现全面可解释性。实验结果表明，这些模型易于微调，用于房颤（AF）分类（ECG AUC 0.99、PPG AUC 0.93）和PPG节拍检测（F1分数98%，并提供节拍置信水平作为信号质量估计），从而为可信赖的心脏数据分析提供高效工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.20775v2",
      "published_date": "2024-07-30 12:22:03 UTC",
      "updated_date": "2024-08-13 10:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:22:36.004136"
    },
    {
      "arxiv_id": "2407.20761v3",
      "title": "OmniBal: Towards Fast Instruct-tuning for Vision-Language Models via Omniverse Computation Balance",
      "title_zh": "翻译失败",
      "authors": [
        "Yongqiang Yao",
        "Jingru Tan",
        "Jiahao Hu",
        "Feizhao Zhang",
        "Yazhe Niu",
        "Xin Jin",
        "Bo Li",
        "Ruihao Gong",
        "Pengfei Liu",
        "Dahua Lin",
        "Ningyi Xu"
      ],
      "abstract": "Recently, vision-language instruct-tuning models have made significant\nprogress due to their more comprehensive understanding of the world. In this\nwork, we discovered that large-scale 3D parallel training on those models leads\nto an imbalanced computation load across different devices. The vision and\nlanguage parts are inherently heterogeneous: their data distribution and model\narchitecture differ significantly, which affects distributed training\nefficiency. We rebalanced the computational loads from data, model, and memory\nperspectives to address this issue, achieving more balanced computation across\ndevices. These three components are not independent but are closely connected,\nforming an omniverse balanced training framework. Specifically, for the data,\nwe grouped instances into new balanced mini-batches within and across devices.\nFor the model, we employed a search-based method to achieve a more balanced\npartitioning. For memory optimization, we adaptively adjusted the\nre-computation strategy for each partition to utilize the available memory\nfully. We conducted extensive experiments to validate the effectiveness of our\nmethod. Compared with the open-source training code of InternVL-Chat, we\nsignificantly reduced GPU days, achieving about 1.8x speed-up. Our method's\nefficacy and generalizability were further demonstrated across various models\nand datasets. Codes will be released at https://github.com/ModelTC/OmniBal.",
      "tldr_zh": "该研究提出了 OmniBal 框架，旨在通过 omniverse computation balance 优化视觉语言模型（vision-language models）的 instruct-tuning 过程，以解决大规模 3D 并行训练中计算负载不平衡的问题。该框架从数据、模型和内存三个角度进行平衡：包括对实例进行分组以创建平衡 mini-batches、使用基于搜索的方法实现模型分区优化，以及自适应调整重新计算策略以充分利用内存。实验结果显示，与 InternVL-Chat 的开源代码相比，OmniBal 显著减少了 GPU days，实现了约 1.8 倍的速度提升，并在多种模型和数据集上证明了其有效性和通用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20761v3",
      "published_date": "2024-07-30 12:02:58 UTC",
      "updated_date": "2025-02-11 03:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:22:39.987974"
    },
    {
      "arxiv_id": "2407.20754v2",
      "title": "Cost-Based Semantics for Querying Inconsistent Weighted Knowledge Bases",
      "title_zh": "翻译失败",
      "authors": [
        "Meghyn Bienvenu",
        "Camille Bourgaux",
        "Robin Jean"
      ],
      "abstract": "In this paper, we explore a quantitative approach to querying inconsistent\ndescription logic knowledge bases. We consider weighted knowledge bases in\nwhich both axioms and assertions have (possibly infinite) weights, which are\nused to assign a cost to each interpretation based upon the axioms and\nassertions it violates. Two notions of certain and possible answer are defined\nby either considering interpretations whose cost does not exceed a given bound\nor restricting attention to optimal-cost interpretations. Our main contribution\nis a comprehensive analysis of the combined and data complexity of bounded cost\nsatisfiability and certain and possible answer recognition, for description\nlogics between ELbot and ALCO.",
      "tldr_zh": "本论文提出了一种基于成本语义的定量方法，用于查询不一致的加权描述逻辑知识库，其中公理和断言带有权重，以计算每个解释违反规则的成本。作者定义了 certain answer 和 possible answer 两种概念，分别基于成本不超过给定界限的解释或成本最优解释。论文的主要贡献是对 bounded cost satisfiability 以及 certain 和 possible answer recognition 在 ELbot 到 ALCO 描述逻辑之间的复杂性进行了全面分析，包括组合复杂度和数据复杂度。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LO",
      "comment": "This is an extended version of a paper appearing at the 21st\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2024). 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.20754v2",
      "published_date": "2024-07-30 11:56:02 UTC",
      "updated_date": "2024-07-31 08:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:22:56.207710"
    },
    {
      "arxiv_id": "2407.20753v1",
      "title": "Efficient Quantum One-Class Support Vector Machines for Anomaly Detection Using Randomized Measurements and Variable Subsampling",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Kölle",
        "Afrae Ahouzi",
        "Pascal Debus",
        "Elif Çetiner",
        "Robert Müller",
        "Daniëlle Schuman",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "Quantum one-class support vector machines leverage the advantage of quantum\nkernel methods for semi-supervised anomaly detection. However, their quadratic\ntime complexity with respect to data size poses challenges when dealing with\nlarge datasets. In recent work, quantum randomized measurements kernels and\nvariable subsampling were proposed, as two independent methods to address this\nproblem. The former achieves higher average precision, but suffers from\nvariance, while the latter achieves linear complexity to data size and has\nlower variance. The current work focuses instead on combining these two\nmethods, along with rotated feature bagging, to achieve linear time complexity\nboth to data size and to number of features. Despite their instability, the\nresulting models exhibit considerably higher performance and faster training\nand testing times.",
      "tldr_zh": "本研究针对量子一类支持向量机（Quantum one-class support vector machines）在半监督异常检测中的二次时间复杂度问题，提出了一种结合量子随机测量内核（quantum randomized measurements kernels）、变量子采样（variable subsampling）和旋转特征装袋（rotated feature bagging）的优化方法。该方法实现了对数据大小和特征数量的线性时间复杂度，尽管存在一定不稳定性，但显著提升了模型性能。实验结果显示，新模型在平均精度和速度上优于独立方法，训练和测试时间更快。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Springer Nature CS",
      "pdf_url": "http://arxiv.org/pdf/2407.20753v1",
      "published_date": "2024-07-30 11:55:52 UTC",
      "updated_date": "2024-07-30 11:55:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:23:09.062600"
    },
    {
      "arxiv_id": "2407.20750v1",
      "title": "JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Clavié"
      ],
      "abstract": "Neural Information Retrieval has advanced rapidly in high-resource languages,\nbut progress in lower-resource ones such as Japanese has been hindered by data\nscarcity, among other challenges. Consequently, multilingual models have\ndominated Japanese retrieval, despite their computational inefficiencies and\ninability to capture linguistic nuances. While recent multi-vector monolingual\nmodels like JaColBERT have narrowed this gap, they still lag behind\nmultilingual methods in large-scale evaluations. This work addresses the\nsuboptimal training methods of multi-vector retrievers in lower-resource\nsettings, focusing on Japanese. We systematically evaluate and improve key\naspects of the inference and training settings of JaColBERT, and more broadly,\nmulti-vector models. We further enhance performance through a novel checkpoint\nmerging step, showcasing it to be an effective way of combining the benefits of\nfine-tuning with the generalization capabilities of the original checkpoint.\nBuilding on our analysis, we introduce a novel training recipe, resulting in\nthe JaColBERTv2.5 model. JaColBERTv2.5, with only 110 million parameters and\ntrained in under 15 hours on 4 A100 GPUs, significantly outperforms all\nexisting methods across all common benchmarks, reaching an average score of\n0.754, significantly above the previous best of 0.720. To support future\nresearch, we make our final models, intermediate checkpoints and all data used\npublicly available.",
      "tldr_zh": "本文针对低资源语言如日语的神经信息检索(Neural Information Retrieval)问题，优化了多向量检索器(multi-vector retrievers)的训练方法，通过系统评估JaColBERT的推理和训练设置，并引入新型检查点合并步骤，开发了JaColBERTv2.5模型。JaColBERTv2.5仅使用110百万参数，并在4个A100 GPU上不到15小时内训练完成，在所有常见基准上显著超越现有方法，平均得分达0.754，比之前最佳的0.720高出许多。该模型结合了细调的性能优势和原检查点的泛化能力，并公开了模型、检查点和数据以推动未来研究。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20750v1",
      "published_date": "2024-07-30 11:42:19 UTC",
      "updated_date": "2024-07-30 11:42:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:23:18.216180"
    },
    {
      "arxiv_id": "2407.20739v1",
      "title": "Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization",
      "title_zh": "多智能体强化学习中变分量子电路的架构",
      "authors": [
        "Michael Kölle",
        "Karola Schneider",
        "Sabrina Egger",
        "Felix Topp",
        "Thomy Phan",
        "Philipp Altmann",
        "Jonas Nüßlein",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "In recent years, Multi-Agent Reinforcement Learning (MARL) has found\napplication in numerous areas of science and industry, such as autonomous\ndriving, telecommunications, and global health. Nevertheless, MARL suffers\nfrom, for instance, an exponential growth of dimensions. Inherent properties of\nquantum mechanics help to overcome these limitations, e.g., by significantly\nreducing the number of trainable parameters. Previous studies have developed an\napproach that uses gradient-free quantum Reinforcement Learning and\nevolutionary optimization for variational quantum circuits (VQCs) to reduce the\ntrainable parameters and avoid barren plateaus as well as vanishing gradients.\nThis leads to a significantly better performance of VQCs compared to classical\nneural networks with a similar number of trainable parameters and a reduction\nin the number of parameters by more than 97 \\% compared to similarly good\nneural networks. We extend an approach of K\\\"olle et al. by proposing a\nGate-Based, a Layer-Based, and a Prototype-Based concept to mutate and\nrecombine VQCs. Our results show the best performance for mutation-only\nstrategies and the Gate-Based approach. In particular, we observe a\nsignificantly better score, higher total and own collected coins, as well as a\nsuperior own coin rate for the best agent when evaluated in the Coin Game\nenvironment.",
      "tldr_zh": "该研究探讨了变分量子电路 (VQCs) 在多智能体强化学习 (MARL) 中的架构影响，提出基于进化策略的优化方法，以解决 MARL 的维度指数增长等问题。作者扩展了 Kölle 等人的方法，引入 Gate-Based、Layer-Based 和 Prototype-Based 概念，用于变异和重组 VQCs，从而减少可训练参数（比类似性能的经典神经网络减少 97% 以上），并避免空洞高原和梯度消失问题。实验结果显示，mutation-only 策略和 Gate-Based 方法在 Coin Game 环境中表现出色，实现更高的分数、总币和个人币率，为量子增强 MARL 提供了高效优化框架。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20739v1",
      "published_date": "2024-07-30 11:16:25 UTC",
      "updated_date": "2024-07-30 11:16:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:23:38.956786"
    },
    {
      "arxiv_id": "2408.02676v2",
      "title": "On Biases in a UK Biobank-based Retinal Image Classification Model",
      "title_zh": "基于 UK Biobank 的视网膜图像分类",
      "authors": [
        "Anissa Alloula",
        "Rima Mustafa",
        "Daniel R McGowan",
        "Bartłomiej W. Papież"
      ],
      "abstract": "Recent work has uncovered alarming disparities in the performance of machine\nlearning models in healthcare. In this study, we explore whether such\ndisparities are present in the UK Biobank fundus retinal images by training and\nevaluating a disease classification model on these images. We assess possible\ndisparities across various population groups and find substantial differences\ndespite strong overall performance of the model. In particular, we discover\nunfair performance for certain assessment centres, which is surprising given\nthe rigorous data standardisation protocol. We compare how these differences\nemerge and apply a range of existing bias mitigation methods to each one. A key\ninsight is that each disparity has unique properties and responds differently\nto the mitigation methods. We also find that these methods are largely unable\nto enhance fairness, highlighting the need for better bias mitigation methods\ntailored to the specific type of bias.",
      "tldr_zh": "本研究探讨了基于 UK Biobank 视网膜图像的疾病分类模型中存在的偏见问题，通过训练和评估模型，评估其在不同人群群体和评估中心的性能差异。结果显示，尽管模型整体表现强劲，但某些评估中心的表现存在显著不公平现象，这在严格的数据标准化协议下尤为令人意外。研究比较了这些偏见的产生原因，并应用多种现有的 bias mitigation methods，但发现每种偏见具有独特属性，且这些方法大多无法有效提升公平性。该研究强调了需要开发针对特定偏见类型的更好缓解策略，以改进医疗机器学习模型的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at MICCAI FAIMI Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02676v2",
      "published_date": "2024-07-30 10:50:07 UTC",
      "updated_date": "2024-10-25 16:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:23:45.921687"
    },
    {
      "arxiv_id": "2407.20724v2",
      "title": "Exploring Loss Landscapes through the Lens of Spin Glass Theory",
      "title_zh": "通过自旋玻璃理论的视角",
      "authors": [
        "Hao Liao",
        "Wei Zhang",
        "Zhanyi Huang",
        "Zexiao Long",
        "Mingyang Zhou",
        "Xiaoqun Wu",
        "Rui Mao",
        "Chi Ho Yeung"
      ],
      "abstract": "In the past decade, significant strides in deep learning have led to numerous\ngroundbreaking applications. Despite these advancements, the understanding of\nthe high generalizability of deep learning, especially in such an\nover-parametrized space, remains limited. For instance, in deep neural networks\n(DNNs), their internal representations, decision-making mechanism, absence of\noverfitting in an over-parametrized space, superior generalizability, etc.,\nremain less understood. Successful applications are often considered as\nempirical rather than scientific achievement. This paper delves into the loss\nlandscape of DNNs through the lens of spin glass in statistical physics, a\nsystem characterized by a complex energy landscape with numerous metastable\nstates, as a novel perspective in understanding how DNNs work. We investigated\nthe loss landscape of single hidden layer neural networks activated by\nRectified Linear Unit (ReLU) function, and introduced several protocols to\nexamine the analogy between DNNs and spin glass. Specifically, we used (1)\nrandom walk in the parameter space of DNNs to unravel the structures in their\nloss landscape; (2) a permutation-interpolation protocol to study the\nconnection between copies of identical regions in the loss landscape due to the\npermutation symmetry in the hidden layers; (3) hierarchical clustering to\nreveal the hierarchy among trained solutions of DNNs, reminiscent of the\nso-called Replica Symmetry Breaking (RSB) phenomenon (i.e. the Parisi solution)\nin spin glass; (4) finally, we examine the relationship between the ruggedness\nof DNN's loss landscape and its generalizability, showing an improvement of\nflattened minima.",
      "tldr_zh": "本论文通过自旋玻璃（Spin Glass）理论的视角，探讨了深度神经网络（DNNs）的损失景观，以解释其在过参数化空间中的高泛化性问题。研究者针对单隐藏层 ReLU 激活的神经网络，引入了随机游走、排列-插值协议和层次聚类等方法，揭示了损失景观的结构特征，并与自旋玻璃中的 Replica Symmetry Breaking (RSB) 现象建立了类比。结果显示，损失景观的崎岖度与泛化能力相关，平坦极小值能够显著改善模型性能，为理解 DNNs 的工作机制提供了新科学视角。",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "24 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.20724v2",
      "published_date": "2024-07-30 10:37:15 UTC",
      "updated_date": "2024-09-16 12:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:23:53.618039"
    },
    {
      "arxiv_id": "2407.20712v1",
      "title": "Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming",
      "title_zh": "Cocobo：探索大语言模型作为终端用户机器人编程的引擎",
      "authors": [
        "Yate Ge",
        "Yi Dai",
        "Run Shan",
        "Kechun Li",
        "Yuanda Hu",
        "Xiaohua Sun"
      ],
      "abstract": "End-user development allows everyday users to tailor service robots or\napplications to their needs. One user-friendly approach is natural language\nprogramming. However, it encounters challenges such as an expansive user\nexpression space and limited support for debugging and editing, which restrict\nits application in end-user programming. The emergence of large language models\n(LLMs) offers promising avenues for the translation and interpretation between\nhuman language instructions and the code executed by robots, but their\napplication in end-user programming systems requires further study. We\nintroduce Cocobo, a natural language programming system with interactive\ndiagrams powered by LLMs. Cocobo employs LLMs to understand users' authoring\nintentions, generate and explain robot programs, and facilitate the conversion\nbetween executable code and flowchart representations. Our user study shows\nthat Cocobo has a low learning curve, enabling even users with zero coding\nexperience to customize robot programs successfully.",
      "tldr_zh": "本研究探讨了将大型语言模型（LLMs）作为引擎用于端用户机器人编程，针对自然语言编程面临的挑战，如用户表达空间广阔和调试编辑支持有限。Cocobo 是一个由 LLMs 驱动的交互式系统，能够理解用户意图、生成并解释机器人程序，并实现可执行代码与流程图之间的转换。通过用户研究发现，Cocobo 具有低学习曲线，即使零编码经验的用户也能成功定制机器人程序，从而提升了端用户开发的可访问性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This is the preprint version of a paper accepted for presentation at\n  the IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC),\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20712v1",
      "published_date": "2024-07-30 10:13:00 UTC",
      "updated_date": "2024-07-30 10:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:24:04.446958"
    },
    {
      "arxiv_id": "2407.20708v4",
      "title": "Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection",
      "title_zh": "用于高性能和能量高效目标检测的整数值训练和脉冲驱动",
      "authors": [
        "Xinhao Luo",
        "Man Yao",
        "Yuhong Chou",
        "Bo Xu",
        "Guoqi Li"
      ],
      "abstract": "Brain-inspired Spiking Neural Networks (SNNs) have bio-plausibility and\nlow-power advantages over Artificial Neural Networks (ANNs). Applications of\nSNNs are currently limited to simple classification tasks because of their poor\nperformance. In this work, we focus on bridging the performance gap between\nANNs and SNNs on object detection. Our design revolves around network\narchitecture and spiking neuron. First, the overly complex module design causes\nspike degradation when the YOLO series is converted to the corresponding\nspiking version. We design a SpikeYOLO architecture to solve this problem by\nsimplifying the vanilla YOLO and incorporating meta SNN blocks. Second, object\ndetection is more sensitive to quantization errors in the conversion of\nmembrane potentials into binary spikes by spiking neurons. To address this\nchallenge, we design a new spiking neuron that activates Integer values during\ntraining while maintaining spike-driven by extending virtual timesteps during\ninference. The proposed method is validated on both static and neuromorphic\nobject detection datasets. On the static COCO dataset, we obtain 66.2% mAP@50\nand 48.9% mAP@50:95, which is +15.0% and +18.7% higher than the prior\nstate-of-the-art SNN, respectively. On the neuromorphic Gen1 dataset, we\nachieve 67.2% mAP@50, which is +2.5% greater than the ANN with equivalent\narchitecture, and the energy efficiency is improved by 5.7*. Code:\nhttps://github.com/BICLab/SpikeYOLO",
      "tldr_zh": "本研究提出了一种基于整数值训练和脉冲驱动推理的脉冲神经网络 (SNNs)，旨在提升物体检测任务的性能和能效，解决 SNNs 在复杂任务中性能落后于人工神经网络 (ANNs) 的问题。研究设计了 SpikeYOLO 架构，通过简化 YOLO 系列网络并融入 meta SNN 块，缓解脉冲退化问题；同时，开发了新的脉冲神经元，在训练中使用整数值激活，并在推理时通过扩展虚拟时间步保持脉冲驱动。实验结果显示，在静态 COCO 数据集上，该方法实现了 66.2% mAP@50 和 48.9% mAP@50:95，分别比现有最先进 SNN 高出 15.0% 和 18.7%；在神经形态 Gen1 数据集上，达到了 67.2% mAP@50，比等效 ANNs 高 2.5%，并提高了 5.7 倍的能效。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ECCV2024; 19 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.20708v4",
      "published_date": "2024-07-30 10:04:16 UTC",
      "updated_date": "2025-04-15 11:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:24:18.683009"
    },
    {
      "arxiv_id": "2407.20705v1",
      "title": "PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning",
      "title_zh": "PIP：原型注入提示用于联邦类增量学习",
      "authors": [
        "Muhammad Anwar Ma'sum",
        "Mahardhika Pratama",
        "Savitha Ramasamy",
        "Lin Liu",
        "Habibullah Habibullah",
        "Ryszard Kowalczyk"
      ],
      "abstract": "Federated Class Incremental Learning (FCIL) is a new direction in continual\nlearning (CL) for addressing catastrophic forgetting and non-IID data\ndistribution simultaneously. Existing FCIL methods call for high communication\ncosts and exemplars from previous classes. We propose a novel rehearsal-free\nmethod for FCIL named prototypes-injected prompt (PIP) that involves 3 main\nideas: a) prototype injection on prompt learning, b) prototype augmentation,\nand c) weighted Gaussian aggregation on the server side. Our experiment result\nshows that the proposed method outperforms the current state of the arts\n(SOTAs) with a significant improvement (up to 33%) in CIFAR100, MiniImageNet\nand TinyImageNet datasets. Our extensive analysis demonstrates the robustness\nof PIP in different task sizes, and the advantage of requiring smaller\nparticipating local clients, and smaller global rounds. For further study,\nsource codes of PIP, baseline, and experimental logs are shared publicly in\nhttps://github.com/anwarmaxsum/PIP.",
      "tldr_zh": "该论文针对 Federated Class Incremental Learning (FCIL) 问题，提出了一种无排练的创新方法 prototypes-injected prompt (PIP)，旨在同时解决 catastrophic forgetting 和 non-IID data distribution 挑战。PIP 的核心包括 prototype injection on prompt learning、prototype augmentation 和 weighted Gaussian aggregation 等组件，从而减少通信成本并避免使用 exemplars。实验结果显示，在 CIFAR100、MiniImageNet 和 TinyImageNet 数据集上，PIP 相较于现有 SOTAs 方法提升高达33%。此外，该方法在不同任务大小下表现出鲁棒性，并支持更少的本地客户端和全局轮次，相关源代码已公开于 https://github.com/anwarmaxsum/PIP。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Conference on Information and Knowledge Management (CIKM) 2024\n  (Accepted)",
      "pdf_url": "http://arxiv.org/pdf/2407.20705v1",
      "published_date": "2024-07-30 10:00:16 UTC",
      "updated_date": "2024-07-30 10:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:24:40.277105"
    },
    {
      "arxiv_id": "2407.20700v1",
      "title": "Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Trilla",
        "Ossee Yiboe",
        "Nenad Mijatovic",
        "Jordi Vitrià"
      ],
      "abstract": "This paper describes the development of a causal diagnosis approach for\ntroubleshooting an industrial environment on the basis of the technical\nlanguage expressed in Return on Experience records. The proposed method\nleverages the vectorized linguistic knowledge contained in the distributed\nrepresentation of a Large Language Model, and the causal associations entailed\nby the embedded failure modes and mechanisms of the industrial assets. The\npaper presents the elementary but essential concepts of the solution, which is\nconceived as a causality-aware retrieval augmented generation system, and\nillustrates them experimentally on a real-world Predictive Maintenance setting.\nFinally, it discusses avenues of improvement for the maturity of the utilized\ncausal technology to meet the robustness challenges of increasingly complex\nscenarios in the industry.",
      "tldr_zh": "本论文提出了一种基于因果技术语言处理(Causal Technical Language Processing)的工业级智能故障诊断方法，作为一个概念证明。该方法利用Large Language Model的分布式表示中的向量化语言知识，以及工业资产的嵌入故障模式和机制的因果关联，构建了一个感知因果的检索增强生成系统(causality-aware retrieval augmented generation system)，以分析Return on Experience记录并进行故障排查。在真实世界的Predictive Maintenance场景中进行实验验证，展示了该方法的有效性。最后，论文讨论了提升因果技术成熟度的潜在改进路径，以应对工业环境中日益复杂的挑战。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "2nd Workshop on Causal Inference and Machine Learning in Practice at\n  the KDD 2024 Conference. arXiv admin note: text overlap with arXiv:2407.11056",
      "pdf_url": "http://arxiv.org/pdf/2407.20700v1",
      "published_date": "2024-07-30 09:53:55 UTC",
      "updated_date": "2024-07-30 09:53:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:24:45.552751"
    },
    {
      "arxiv_id": "2407.20693v1",
      "title": "Boosting Audio Visual Question Answering via Key Semantic-Aware Cues",
      "title_zh": "通过关键语义感知线索提升音频视觉问答",
      "authors": [
        "Guangyao Li",
        "Henghui Du",
        "Di Hu"
      ],
      "abstract": "The Audio Visual Question Answering (AVQA) task aims to answer questions\nrelated to various visual objects, sounds, and their interactions in videos.\nSuch naturally multimodal videos contain rich and complex dynamic audio-visual\ncomponents, with only a portion of them closely related to the given questions.\nHence, effectively perceiving audio-visual cues relevant to the given questions\nis crucial for correctly answering them. In this paper, we propose a\nTemporal-Spatial Perception Model (TSPM), which aims to empower the model to\nperceive key visual and auditory cues related to the questions. Specifically,\nconsidering the challenge of aligning non-declarative questions and visual\nrepresentations into the same semantic space using visual-language pretrained\nmodels, we construct declarative sentence prompts derived from the question\ntemplate, to assist the temporal perception module in better identifying\ncritical segments relevant to the questions. Subsequently, a spatial perception\nmodule is designed to merge visual tokens from selected segments to highlight\nkey latent targets, followed by cross-modal interaction with audio to perceive\npotential sound-aware areas. Finally, the significant temporal-spatial cues\nfrom these modules are integrated to answer the question. Extensive experiments\non multiple AVQA benchmarks demonstrate that our framework excels not only in\nunderstanding audio-visual scenes but also in answering complex questions\neffectively. Code is available at https://github.com/GeWu-Lab/TSPM.",
      "tldr_zh": "这篇论文针对 Audio Visual Question Answering (AVQA) 任务，提出 Temporal-Spatial Perception Model (TSPM)，旨在通过感知与问题相关的关键音频-视觉线索，提升回答准确性。方法包括使用从问题模板派生的声明句提示，帮助时间感知模块识别关键视频段，以及空间感知模块合并选定段的视觉标记并与音频互动，突出潜在声音相关区域。实验结果显示，该框架在多个 AVQA 基准上表现出色，不仅提高了音频-视觉场景理解能力，还有效处理复杂问题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20693v1",
      "published_date": "2024-07-30 09:41:37 UTC",
      "updated_date": "2024-07-30 09:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:25:00.382146"
    },
    {
      "arxiv_id": "2407.20684v1",
      "title": "RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Weibin Liao",
        "Yifan Zhu",
        "Yanyan Li",
        "Qi Zhang",
        "Zhonghong Ou",
        "Xuesong Li"
      ],
      "abstract": "Acquiring reviewers for academic submissions is a challenging recommendation\nscenario. Recent graph learning-driven models have made remarkable progress in\nthe field of recommendation, but their performance in the academic reviewer\nrecommendation task may suffer from a significant false negative issue. This\narises from the assumption that unobserved edges represent negative samples. In\nfact, the mechanism of anonymous review results in inadequate exposure of\ninteractions between reviewers and submissions, leading to a higher number of\nunobserved interactions compared to those caused by reviewers declining to\nparticipate. Therefore, investigating how to better comprehend the negative\nlabeling of unobserved interactions in academic reviewer recommendations is a\nsignificant challenge. This study aims to tackle the ambiguous nature of\nunobserved interactions in academic reviewer recommendations. Specifically, we\npropose an unsupervised Pseudo Neg-Label strategy to enhance graph contrastive\nlearning (GCL) for recommending reviewers for academic submissions, which we\ncall RevGNN. RevGNN utilizes a two-stage encoder structure that encodes both\nscientific knowledge and behavior using Pseudo Neg-Label to approximate review\npreference. Extensive experiments on three real-world datasets demonstrate that\nRevGNN outperforms all baselines across four metrics. Additionally, detailed\nfurther analyses confirm the effectiveness of each component in RevGNN.",
      "tldr_zh": "这篇论文针对学术审稿人推荐中的假负样本问题，提出了一种增强的图对比学习（Graph Contrastive Learning）模型，名为 RevGNN。RevGNN 采用无监督的 Pseudo Neg-Label 策略，通过两阶段编码器结构来编码科学知识和行为偏好，从而更好地处理未观察到的互动并近似审稿偏好。在三个真实数据集上的实验表明，RevGNN 在四个指标上优于所有基线模型，并通过详细分析验证了其每个组件的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by ACM Transactions on Information Systems (TOIS)",
      "pdf_url": "http://arxiv.org/pdf/2407.20684v1",
      "published_date": "2024-07-30 09:25:40 UTC",
      "updated_date": "2024-07-30 09:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:25:18.447213"
    },
    {
      "arxiv_id": "2407.20673v1",
      "title": "Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection",
      "title_zh": "翻译失败",
      "authors": [
        "ChaoFeng Guan",
        "YaoHui Zhu",
        "Yu Bai",
        "LingYun Wang"
      ],
      "abstract": "Multi-label few-shot aspect category detection aims at identifying multiple\naspect categories from sentences with a limited number of training instances.\nThe representation of sentences and categories is a key issue in this task.\nMost of current methods extract keywords for the sentence representations and\nthe category representations. Sentences often contain many category-independent\nwords, which leads to suboptimal performance of keyword-based methods. Instead\nof directly extracting keywords, we propose a label-guided prompt method to\nrepresent sentences and categories. To be specific, we design label-specific\nprompts to represent sentences by combining crucial contextual and semantic\ninformation. Further, the label is introduced into a prompt to obtain category\ndescriptions by utilizing a large language model. This kind of category\ndescriptions contain the characteristics of the aspect categories, guiding the\nconstruction of discriminative category prototypes. Experimental results on two\npublic datasets show that our method outperforms current state-of-the-art\nmethods with a 3.86% - 4.75% improvement in the Macro-F1 score.",
      "tldr_zh": "本研究针对多标签少样本方面类别检测（Multi-label few-shot aspect category detection）任务，提出了一种基于标签引导提示（label-guided prompt）的方法，以解决现有关键词提取方法因句子中包含无关词汇而导致的性能不足。方法通过设计标签特定的提示（label-specific prompts）来结合句子的上下文和语义信息，并利用大语言模型（large language model）生成类别描述，从而构建判别性的类别原型（discriminative category prototypes）。在两个公共数据集上的实验显示，该方法在 Macro-F1 分数上比现有最先进方法提高了 3.86% - 4.75%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20673v1",
      "published_date": "2024-07-30 09:11:17 UTC",
      "updated_date": "2024-07-30 09:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:25:22.245991"
    },
    {
      "arxiv_id": "2408.07295v3",
      "title": "Learning Multi-Modal Whole-Body Control for Real-World Humanoid Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Pranay Dugar",
        "Aayam Shrestha",
        "Fangzhou Yu",
        "Bart van Marum",
        "Alan Fern"
      ],
      "abstract": "The foundational capabilities of humanoid robots should include robustly\nstanding, walking, and mimicry of whole and partial-body motions. This work\nintroduces the Masked Humanoid Controller (MHC), which supports all of these\ncapabilities by tracking target trajectories over selected subsets of humanoid\nstate variables while ensuring balance and robustness against disturbances. The\nMHC is trained in simulation using a carefully designed curriculum that\nimitates partially masked motions from a library of behaviors spanning\nstanding, walking, optimized reference trajectories, re-targeted video clips,\nand human motion capture data. It also allows for combining joystick-based\ncontrol with partial-body motion mimicry. We showcase simulation experiments\nvalidating the MHC's ability to execute a wide variety of behaviors from\npartially-specified target motions. Moreover, we demonstrate sim-to-real\ntransfer on the real-world Digit V3 humanoid robot. To our knowledge, this is\nthe first instance of a learned controller that can realize whole-body control\nof a real-world humanoid for such diverse multi-modal targets.",
      "tldr_zh": "本研究提出 Masked Humanoid Controller (MHC)，一个学习型控制器，用于实现真实世界人形机器人的多模态全身控制，包括站立、行走和部分或全身动作模仿，同时确保平衡和抗干扰。MHC 通过在模拟环境中训练的精心设计课程，模仿部分遮盖的动作库（如站立、行走、优化轨迹、重定向视频和人类动作捕捉数据），并支持摇杆控制与部分身体模仿相结合。实验验证了 MHC 在模拟和真实 Digit V3 机器人上的鲁棒性能，首次实现了从部分指定目标动作到多样行为的 sim-to-real 转移，显著提升了人形机器人的控制能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Website: https://masked-humanoid.github.io/mhc/",
      "pdf_url": "http://arxiv.org/pdf/2408.07295v3",
      "published_date": "2024-07-30 09:10:24 UTC",
      "updated_date": "2025-02-28 18:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:25:35.440797"
    },
    {
      "arxiv_id": "2407.20669v2",
      "title": "A Tutorial on the Use of Physics-Informed Neural Networks to Compute the Spectrum of Quantum Systems",
      "title_zh": "物理信息神经网络用于计算量子系统谱的教程",
      "authors": [
        "Lorenzo Brevi",
        "Antonio Mandarino",
        "Enrico Prati"
      ],
      "abstract": "Quantum many-body systems are of great interest for many research areas,\nincluding physics, biology and chemistry. However, their simulation is\nextremely challenging, due to the exponential growth of the Hilbert space with\nthe system size, making it exceedingly difficult to parameterize the wave\nfunctions of large systems by using exact methods. Neural networks and machine\nlearning in general are a way to face this challenge. For instance, methods\nlike Tensor networks and Neural Quantum States are being investigated as\npromising tools to obtain the wave function of a quantum mechanical system. In\nthis tutorial, we focus on a particularly promising class of deep learning\nalgorithms. We explain how to construct a Physics-Informed Neural Network\n(PINN) able to solve the Schr\\\"odinger equation for a given potential, by\nfinding its eigenvalues and eigenfunctions. This technique is unsupervised, and\nutilizes a novel computational method in a manner that is barely explored.\nPINNs are a deep learning method that exploits Automatic Differentiation to\nsolve Integro-Differential Equations in a mesh-free way. We show how to find\nboth the ground and the excited states. The method discovers the states\nprogressively by starting from the ground state. We explain how to introduce\ninductive biases in the loss to exploit further knowledge of the physical\nsystem. Such additional constraints allow for a faster and more accurate\nconvergence. This technique can then be enhanced by a smart choice of\ncollocation points in order to take advantage of the mesh-free nature of the\nPINN. The methods are made explicit by applying them to the infinite potential\nwell and the particle in a ring, a challenging problem to be learned by an\nArtificial Intelligence agent due to the presence of complex-valued\neigenfunctions and degenerate states.",
      "tldr_zh": "这篇教程介绍了如何使用 Physics-Informed Neural Networks (PINNs) 来计算量子系统的谱，包括本征值和本征函数，以应对量子多体系统模拟的挑战，如希尔伯特空间的指数增长。\nPINNs 采用无监督学习和 Automatic Differentiation 的无网格方法来解决 Schrödinger 方程，并通过引入 inductive biases 和智能选择 collocation points 来加速收敛和提高准确性。\n该技术能逐步发现基态和激发态，并在实际应用中，如无限势阱和粒子在环系统中，成功处理复杂值本征函数和简并态。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.20669v2",
      "published_date": "2024-07-30 09:07:03 UTC",
      "updated_date": "2024-09-11 11:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:25:48.064014"
    },
    {
      "arxiv_id": "2407.20668v1",
      "title": "Mimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers",
      "title_zh": "翻译失败",
      "authors": [
        "Qinglan Wei",
        "Ruiqi Xue",
        "Yutian Wang",
        "Hongjiang Xiao",
        "Yuhao Wang",
        "Xiaoyan Duan"
      ],
      "abstract": "Predicting influencers' views and public sentiment on social media is crucial\nfor anticipating societal trends and guiding strategic responses. This study\nintroduces a novel computational framework to predict opinion leaders'\nperspectives and the emotive reactions of the populace, addressing the inherent\nchallenges posed by the unstructured, context-sensitive, and heterogeneous\nnature of online communication. Our research introduces an innovative module\nthat starts with the automatic 5W1H (Where, Who, When, What, Why, and How)\nquestions formulation engine, tailored to emerging news stories and trending\ntopics. We then build a total of 60 anonymous opinion leader agents in six\ndomains and realize the views generation based on an enhanced large language\nmodel (LLM) coupled with retrieval-augmented generation (RAG). Subsequently, we\nsynthesize the potential views of opinion leaders and predicted the emotional\nresponses to different events. The efficacy of our automated 5W1H module is\ncorroborated by an average GPT-4 score of 8.83/10, indicative of high fidelity.\nThe influencer agents exhibit a consistent performance, achieving an average\nGPT-4 rating of 6.85/10 across evaluative metrics. Utilizing the\n'Russia-Ukraine War' as a case study, our methodology accurately foresees key\ninfluencers' perspectives and aligns emotional predictions with real-world\nsentiment trends in various domains.",
      "tldr_zh": "该研究提出了一种基于代理的计算框架，用于预测社交媒体影响者的观点和公众情绪反应，以预见社会趋势。该框架包括一个自动生成5W1H（Where, Who, When, What, Why, How）问题的模块，以及构建60个匿名意见领袖代理，利用增强型LLM和RAG技术合成观点并预测情绪。实验结果显示，5W1H模块的GPT-4评分平均为8.83/10，代理性能为6.85/10，并通过“Russia-Ukraine War”案例准确预测了关键影响者的视角和实际情绪趋势，为社交媒体分析提供了可靠工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Upon acceptance of the article by IEEE, the preprint article must be\n  replaced with the accepted version, as described in the section 'Accepted\n  article.'",
      "pdf_url": "http://arxiv.org/pdf/2407.20668v1",
      "published_date": "2024-07-30 09:04:45 UTC",
      "updated_date": "2024-07-30 09:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:25:58.602895"
    },
    {
      "arxiv_id": "2407.20667v1",
      "title": "Rethinking the Function of Neurons in KANs",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Ghaith Altarabichi"
      ],
      "abstract": "The neurons of Kolmogorov-Arnold Networks (KANs) perform a simple summation\nmotivated by the Kolmogorov-Arnold representation theorem, which asserts that\nsum is the only fundamental multivariate function. In this work, we investigate\nthe potential for identifying an alternative multivariate function for KAN\nneurons that may offer increased practical utility. Our empirical research\ninvolves testing various multivariate functions in KAN neurons across a range\nof benchmark Machine Learning tasks.\n  Our findings indicate that substituting the sum with the average function in\nKAN neurons results in significant performance enhancements compared to\ntraditional KANs. Our study demonstrates that this minor modification\ncontributes to the stability of training by confining the input to the spline\nwithin the effective range of the activation function. Our implementation and\nexperiments are available at: \\url{https://github.com/Ghaith81/dropkan}",
      "tldr_zh": "这篇论文重新审视了Kolmogorov-Arnold Networks (KANs)中神经元的求和函数，基于Kolmogorov-Arnold表示定理探讨了是否可以用其他多变量函数替代以提升实用性。研究者通过在多种机器学习基准任务上测试不同多变量函数，发现用average function替换sum函数能显著提高模型性能。這種修改通过将输入限制在spline的有效范围内，改善了训练的稳定性。实验实现已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20667v1",
      "published_date": "2024-07-30 09:04:23 UTC",
      "updated_date": "2024-07-30 09:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:26:21.707014"
    },
    {
      "arxiv_id": "2407.20657v2",
      "title": "Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Hunmin Yang",
        "Jongoh Jeong",
        "Kuk-Jin Yoon"
      ],
      "abstract": "Recent vision-language foundation models, such as CLIP, have demonstrated\nsuperior capabilities in learning representations that can be transferable\nacross diverse range of downstream tasks and domains. With the emergence of\nsuch powerful models, it has become crucial to effectively leverage their\ncapabilities in tackling challenging vision tasks. On the other hand, only a\nfew works have focused on devising adversarial examples that transfer well to\nboth unknown domains and model architectures. In this paper, we propose a novel\ntransfer attack method called PDCL-Attack, which leverages the CLIP model to\nenhance the transferability of adversarial perturbations generated by a\ngenerative model-based attack framework. Specifically, we formulate an\neffective prompt-driven feature guidance by harnessing the semantic\nrepresentation power of text, particularly from the ground-truth class labels\nof input images. To the best of our knowledge, we are the first to introduce\nprompt learning to enhance the transferable generative attacks. Extensive\nexperiments conducted across various cross-domain and cross-model settings\nempirically validate our approach, demonstrating its superiority over\nstate-of-the-art methods.",
      "tldr_zh": "该论文提出了一种名为 PDCL-Attack 的新方法，利用视觉语言模型如 CLIP 来提升对抗攻击的跨域和跨模型可转移性。方法通过提示驱动的对比学习（prompt-driven contrastive learning），利用文本语义表示（如输入图像的真实类标签）来指导生成模型产生更有效的对抗扰动，这是首次将提示学习应用于可转移生成攻击。实验结果显示，在各种跨域和跨模型设置中，PDCL-Attack 优于现有最先进方法，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024 (Oral), Project Page:\n  https://PDCL-Attack.github.io",
      "pdf_url": "http://arxiv.org/pdf/2407.20657v2",
      "published_date": "2024-07-30 08:52:16 UTC",
      "updated_date": "2025-03-13 06:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:26:21.577765"
    },
    {
      "arxiv_id": "2407.20654v1",
      "title": "Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian",
      "title_zh": "翻译失败",
      "authors": [
        "Serena Auriemma",
        "Martina Miliani",
        "Mauro Madeddu",
        "Alessandro Bondielli",
        "Lucia Passaro",
        "Alessandro Lenci"
      ],
      "abstract": "Addressing the challenge of limited annotated data in specialized fields and\nlow-resource languages is crucial for the effective use of Language Models\n(LMs). While most Large Language Models (LLMs) are trained on general-purpose\nEnglish corpora, there is a notable gap in models specifically tailored for\nItalian, particularly for technical and bureaucratic jargon. This paper\nexplores the feasibility of employing smaller, domain-specific encoder LMs\nalongside prompting techniques to enhance performance in these specialized\ncontexts. Our study concentrates on the Italian bureaucratic and legal\nlanguage, experimenting with both general-purpose and further pre-trained\nencoder-only models. We evaluated the models on downstream tasks such as\ndocument classification and entity typing and conducted intrinsic evaluations\nusing Pseudo-Log-Likelihood. The results indicate that while further\npre-trained models may show diminished robustness in general knowledge, they\nexhibit superior adaptability for domain-specific tasks, even in a zero-shot\nsetting. Furthermore, the application of calibration techniques and in-domain\nverbalizers significantly enhances the efficacy of encoder models. These\ndomain-specialized models prove to be particularly advantageous in scenarios\nwhere in-domain resources or expertise are scarce. In conclusion, our findings\noffer new insights into the use of Italian models in specialized contexts,\nwhich may have a significant impact on both research and industrial\napplications in the digital transformation era.",
      "tldr_zh": "这篇论文探讨了在意大利语官僚和法律领域，使用提示技术（Prompting）增强编码器模型（Encoder Models）进行零样本分类（Zero-Shot Classification）的可行性，以应对低资源语言标注数据不足的挑战。研究比较了一般模型和进一步预训练模型，在下游任务如文档分类和实体类型化上进行评估，并使用 Pseudo-Log-Likelihood 进行内在评估。结果表明，进一步预训练模型在领域特定任务中表现出色，尽管一般知识鲁棒性降低，但通过校准技术和领域内verbalizers 显著提升了效能。这些发现为意大利语在专业上下文中的应用提供了新见解，尤其适用于资源稀缺的工业和研究场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50, 68T07",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to 'Language Resource and Evaluation'",
      "pdf_url": "http://arxiv.org/pdf/2407.20654v1",
      "published_date": "2024-07-30 08:50:16 UTC",
      "updated_date": "2024-07-30 08:50:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:26:40.718473"
    },
    {
      "arxiv_id": "2407.20653v1",
      "title": "FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks",
      "title_zh": "FACL-Attack：频率感知对比",
      "authors": [
        "Hunmin Yang",
        "Jongoh Jeong",
        "Kuk-Jin Yoon"
      ],
      "abstract": "Deep neural networks are known to be vulnerable to security risks due to the\ninherent transferable nature of adversarial examples. Despite the success of\nrecent generative model-based attacks demonstrating strong transferability, it\nstill remains a challenge to design an efficient attack strategy in a\nreal-world strict black-box setting, where both the target domain and model\narchitectures are unknown. In this paper, we seek to explore a feature\ncontrastive approach in the frequency domain to generate adversarial examples\nthat are robust in both cross-domain and cross-model settings. With that goal\nin mind, we propose two modules that are only employed during the training\nphase: a Frequency-Aware Domain Randomization (FADR) module to randomize\ndomain-variant low- and high-range frequency components and a\nFrequency-Augmented Contrastive Learning (FACL) module to effectively separate\ndomain-invariant mid-frequency features of clean and perturbed image. We\ndemonstrate strong transferability of our generated adversarial perturbations\nthrough extensive cross-domain and cross-model experiments, while keeping the\ninference time complexity.",
      "tldr_zh": "这篇论文提出了 FACL-Attack，一种基于频率域的对比学习方法，用于生成具有强可转移性的对抗样本（adversarial attacks），以应对深度神经网络在黑盒设置下的安全风险。方法包括两个训练阶段模块：Frequency-Aware Domain Randomization (FADR) 用于随机化域相关的低频和高频组件，以及 Frequency-Augmented Contrastive Learning (FACL) 用于有效分离域不变的中频特征的干净图像和扰动图像。通过广泛的跨域和跨模型实验，证明了该攻击策略显著提高了对抗样本的鲁棒性和转移性能，同时保持了推理时间复杂度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2024, Project Page: https://FACL-Attack.github.io",
      "pdf_url": "http://arxiv.org/pdf/2407.20653v1",
      "published_date": "2024-07-30 08:50:06 UTC",
      "updated_date": "2024-07-30 08:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:26:46.752255"
    },
    {
      "arxiv_id": "2407.20650v1",
      "title": "No learning rates needed: Introducing SALSA -- Stable Armijo Line Search Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Kenneweg",
        "Tristan Kenneweg",
        "Fabian Fumagalli",
        "Barbara Hammer"
      ],
      "abstract": "In recent studies, line search methods have been demonstrated to\nsignificantly enhance the performance of conventional stochastic gradient\ndescent techniques across various datasets and architectures, while making an\notherwise critical choice of learning rate schedule superfluous. In this paper,\nwe identify problems of current state-of-the-art of line search methods,\npropose enhancements, and rigorously assess their effectiveness. Furthermore,\nwe evaluate these methods on orders of magnitude larger datasets and more\ncomplex data domains than previously done. More specifically, we enhance the\nArmijo line search method by speeding up its computation and incorporating a\nmomentum term into the Armijo criterion, making it better suited for stochastic\nmini-batching. Our optimization approach outperforms both the previous Armijo\nimplementation and a tuned learning rate schedule for the Adam and SGD\noptimizers. Our evaluation covers a diverse range of architectures, such as\nTransformers, CNNs, and MLPs, as well as data domains, including NLP and image\ndata.\n  Our work is publicly available as a Python package, which provides a simple\nPytorch optimizer.",
      "tldr_zh": "该论文引入了 SALSA，一种稳定的 Armijo line search 适应方法，无需学习率调度即可提升随机梯度下降（SGD）优化器的性能。作者通过加速 Armijo line search 的计算并加入动量项，使其更适合随机小批量训练，并在 Transformers、CNNs 和 MLPs 等架构以及 NLP 和图像数据领域进行了评估。实验结果显示，SALSA 超过了传统 Armijo 实现和调优的学习率调度，为 Adam 和 SGD 优化器提供了更有效的替代方案。该方法已作为 Python 包公开，可轻松集成到 Pytorch 中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "published in IJCNN 2024. arXiv admin note: text overlap with\n  arXiv:2403.18519",
      "pdf_url": "http://arxiv.org/pdf/2407.20650v1",
      "published_date": "2024-07-30 08:47:02 UTC",
      "updated_date": "2024-07-30 08:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:27:10.022927"
    },
    {
      "arxiv_id": "2407.20648v2",
      "title": "Leveraging Multi-facet Paths for Heterogeneous Graph Representation Learning",
      "title_zh": "利用多面路径进行异构图表示学习",
      "authors": [
        "JongWoo Kim",
        "SeongYeub Chu",
        "HyeongMin Park",
        "Bryan Wong",
        "MunYong Yi"
      ],
      "abstract": "Recent advancements in graph neural networks (GNNs) and heterogeneous GNNs\n(HGNNs) have advanced node embeddings and relationship learning for various\ntasks. However, existing methods often rely on domain-specific predefined\nmeta-paths, which are coarse-grained and focus solely on aspects like node\ntype, limiting their ability to capture complex interactions. We introduce\nMF2Vec, a model that uses multi-faceted (fine-grained) paths instead of\npredefined meta-paths. MF2Vec extracts paths via random walks and generates\nmulti-faceted vectors, ignoring predefined schemas. This method learns diverse\naspects of nodes and their relationships, constructs a homogeneous network, and\ncreates node embeddings for classification, link prediction, and clustering.\nExtensive experiments show that MF2Vec outperforms existing methods, offering a\nmore flexible and comprehensive framework for analyzing complex networks. The\ncode is available at https://anonymous.4open.science/r/MF2Vec-6ABC.",
      "tldr_zh": "本研究针对异构图表示学习中的问题，指出现有 Graph Neural Networks (GNNs) 和 Heterogeneous GNNs (HGNNs) 过度依赖粗粒度的预定义 meta-paths，导致无法充分捕捉复杂节点交互。作者提出 MF2Vec 模型，通过随机游走提取多方面（fine-grained）路径，生成多样化的节点向量，而非依赖预定义模式，从而构建同质网络并应用于节点分类、链接预测和聚类任务。实验结果显示，MF2Vec 在广泛测试中优于现有方法，提供了一个更灵活且全面的网络分析框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20648v2",
      "published_date": "2024-07-30 08:45:32 UTC",
      "updated_date": "2025-02-03 14:26:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:27:11.097999"
    },
    {
      "arxiv_id": "2407.20635v2",
      "title": "Autonomous Improvement of Instruction Following Skills via Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Zhou",
        "Pranav Atreya",
        "Abraham Lee",
        "Homer Walke",
        "Oier Mees",
        "Sergey Levine"
      ],
      "abstract": "Intelligent instruction-following robots capable of improving from\nautonomously collected experience have the potential to transform robot\nlearning: instead of collecting costly teleoperated demonstration data,\nlarge-scale deployment of fleets of robots can quickly collect larger\nquantities of autonomous data that can collectively improve their performance.\nHowever, autonomous improvement requires solving two key problems: (i) fully\nautomating a scalable data collection procedure that can collect diverse and\nsemantically meaningful robot data and (ii) learning from non-optimal,\nautonomous data with no human annotations. To this end, we propose a novel\napproach that addresses these challenges, allowing instruction-following\npolicies to improve from autonomously collected data without human supervision.\nOur framework leverages vision-language models to collect and evaluate\nsemantically meaningful experiences in new environments, and then utilizes a\ndecomposition of instruction following tasks into (semantic)\nlanguage-conditioned image generation and (non-semantic) goal reaching, which\nmakes it significantly more practical to improve from this autonomously\ncollected data without any human annotations. We carry out extensive\nexperiments in the real world to demonstrate the effectiveness of our approach,\nand find that in a suite of unseen environments, the robot policy can be\nimproved 2x with autonomously collected data. We open-source the code for our\nsemantic autonomous improvement pipeline, as well as our autonomous dataset of\n30.5K trajectories collected across five tabletop environments.",
      "tldr_zh": "这篇论文提出了一种利用 foundation models 的框架，让机器人通过自主收集经验来改善指令遵循技能，从而避免依赖昂贵的遥控演示数据。方法包括使用 vision-language models 自动化收集多样化的语义有意义数据，并将指令遵循任务分解为语义语言条件图像生成和非语义目标到达两部分，以便从无监督的自主数据中学习。实验在真实世界环境中进行，结果显示机器人策略在未见场景下的性能提高了 2 倍；此外，论文开源了代码和一个包含 30.5K 轨迹的自主数据集，跨越五个桌面环境。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "2024 Conference on Robot Learning (CoRL)",
      "pdf_url": "http://arxiv.org/pdf/2407.20635v2",
      "published_date": "2024-07-30 08:26:44 UTC",
      "updated_date": "2024-10-15 17:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:27:23.901787"
    },
    {
      "arxiv_id": "2407.20584v3",
      "title": "Pruning Large Language Models with Semi-Structural Adaptive Sparse Training",
      "title_zh": "翻译失败",
      "authors": [
        "Weiyu Huang",
        "Yuezhou Hu",
        "Guohao Jian",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "The remarkable success of Large Language Models (LLMs) relies heavily on\ntheir substantial scale, which poses significant challenges during model\ndeployment in terms of latency and memory consumption. Recently, numerous\nstudies have attempted to compress LLMs using one-shot pruning methods.\nHowever, these methods often suffer from considerable performance degradation\non complex language understanding tasks, raising concerns about the feasibility\nof pruning in LLMs. To address this issue, we propose Adaptive Sparse Trainer\n(AST), a novel and efficient retraining framework tailored for semi-structured\nsparse models. AST enables models to learn optimal masks during the weight\nupdate process without incurring additional computational overhead.\nFurthermore, we demonstrate that incorporating knowledge distillation\nsignificantly improves retraining efficiency and enhances model performance\nunder fixed computational constraints. Additionally, a supplementary set of\nwell-initialized parameters is integrated to further augment the model's\nefficacy. AST achieves state-of-the-art performance with minimal training cost.\nWhen applied to the LLaMA2-7B model, AST reduces the perplexity and zero-shot\naccuracy gap between dense and 2:4 semi-structured sparse models to 0.6 and\n1.16%, respectively, utilizing less than 0.4% of the pretraining tokens and GPU\nhours. Our work demonstrates the feasibility of deploying semi-structured\nsparse LLMs and offers a promising alternative for achieving highly compressed\nmodels when combined with existing quantization techniques.",
      "tldr_zh": "该研究针对大语言模型（LLMs）的部署挑战，如延迟和内存消耗，提出了一种高效的半结构化自适应稀疏训练框架——Adaptive Sparse Trainer (AST)。AST 允许模型在权重更新过程中学习最优掩码（masks），并结合知识蒸馏（knowledge distillation）和额外初始化参数，提高性能而无需额外计算开销。在 LLaMA2-7B 模型上，AST 将稠密模型与 2:4 半结构化稀疏模型在 perplexity 和 zero-shot accuracy 上的差距分别缩小至 0.6% 和 1.16%，仅使用不到 0.4% 的预训练 tokens 和 GPU 小时。该方法证明了部署半结构化稀疏 LLMs 的可行性，并可与量化技术结合，实现高度压缩的模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at AAAI25",
      "pdf_url": "http://arxiv.org/pdf/2407.20584v3",
      "published_date": "2024-07-30 06:33:44 UTC",
      "updated_date": "2024-12-18 07:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:27:36.402993"
    },
    {
      "arxiv_id": "2407.20582v1",
      "title": "Image-based Detection of Segment Misalignment in Multi-mirror Satellites using Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "C. Tanner Fredieu",
        "Jonathan Tesch",
        "Andrew Kee",
        "David Redding"
      ],
      "abstract": "In this paper, we introduce a system based on transfer learning for detecting\nsegment misalignment in multimirror satellites, such as future CubeSat designs\nand the James Webb Space Telescope (JWST), using image-based methods. When a\nmirror segment becomes misaligned due to various environmental factors, such as\nspace debris, the images can become distorted with a shifted copy of itself\ncalled a \"ghost image\". To detect whether segments are misaligned, we use\npre-trained, large-scale image models trained on the Fast Fourier Transform\n(FFT) of patches of satellite images in grayscale. Multi-mirror designs can use\nany arbitrary number of mirrors. For our purposes, the tests were performed on\nsimulated CubeSats with 4, 6, and 8 segments. For system design, we took this\ninto account when we want to know when a satellite has a misaligned segment and\nhow many segments are misaligned. The intensity of the ghost image is directly\nproportional to the number of segments misaligned. Models trained for intensity\nclassification attempted to classify N-1 segments. Across eight classes, binary\nmodels were able to achieve a classification accuracy of 98.75%, and models for\nintensity classification were able to achieve an accuracy of 98.05%.",
      "tldr_zh": "本研究提出了一种基于迁移学习（transfer learning）的图像检测系统，用于识别多镜卫星（如 CubeSat 和 James Webb Space Telescope (JWST)）中镜段失调问题，该失调可能因环境因素导致图像出现“ghost image”（幽灵图像）。系统利用预训练的大型图像模型处理卫星图像灰度补丁的快速傅立叶变换（FFT），并适用于任意数量的镜子段，在模拟的4、6和8段CubeSat上进行测试。结果显示，二元模型（binary models）在检测失调段数方面达到98.75%的准确率，而强度分类模型（intensity classification）则以98.05%的准确率证明了幽灵图像强度与失调段数成正比，为卫星失调检测提供了高效可靠的方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20582v1",
      "published_date": "2024-07-30 06:29:40 UTC",
      "updated_date": "2024-07-30 06:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:27:49.723503"
    },
    {
      "arxiv_id": "2407.20578v2",
      "title": "Comparison of Large Language Models for Generating Contextually Relevant Questions",
      "title_zh": "大型语言模型在生成上下文相关问题的比较",
      "authors": [
        "Ivo Lodovico Molina",
        "Valdemar Švábenský",
        "Tsubasa Minematsu",
        "Li Chen",
        "Fumiya Okubo",
        "Atsushi Shimada"
      ],
      "abstract": "This study explores the effectiveness of Large Language Models (LLMs) for\nAutomatic Question Generation in educational settings. Three LLMs are compared\nin their ability to create questions from university slide text without\nfine-tuning. Questions were obtained in a two-step pipeline: first, answer\nphrases were extracted from slides using Llama 2-Chat 13B; then, the three\nmodels generated questions for each answer. To analyze whether the questions\nwould be suitable in educational applications for students, a survey was\nconducted with 46 students who evaluated a total of 246 questions across five\nmetrics: clarity, relevance, difficulty, slide relation, and question-answer\nalignment. Results indicate that GPT-3.5 and Llama 2-Chat 13B outperform Flan\nT5 XXL by a small margin, particularly in terms of clarity and question-answer\nalignment. GPT-3.5 especially excels at tailoring questions to match the input\nanswers. The contribution of this research is the analysis of the capacity of\nLLMs for Automatic Question Generation in education.",
      "tldr_zh": "这篇论文比较了三个Large Language Models (LLMs)——GPT-3.5、Llama 2-Chat 13B 和 Flan T5 XXL——在教育环境中从大学幻灯片文本中生成上下文相关问题的能力，而无需微调模型。研究采用两步管道：首先使用Llama 2-Chat 13B提取答案短语，然后让各模型为这些答案生成问题。46名学生通过调查评估了246个问题，基于清晰度、相关性、难度、幻灯片关系和问题-答案对齐五个指标，结果显示GPT-3.5和Llama 2-Chat 13B略优于Flan T5 XXL，尤其在清晰度和问题-答案对齐方面。论文的主要贡献是分析LLMs在Automatic Question Generation教育应用中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "K.3"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in Springer ECTEL 2024 conference proceedings, see\n  https://doi.org/10.1007/978-3-031-72312-4_18",
      "pdf_url": "http://arxiv.org/pdf/2407.20578v2",
      "published_date": "2024-07-30 06:23:59 UTC",
      "updated_date": "2024-09-15 07:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:28:01.969868"
    },
    {
      "arxiv_id": "2407.20563v1",
      "title": "Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoyue Shen",
        "Nakamasa Inoue",
        "Koichi Shinoda"
      ],
      "abstract": "Visual question answering (VQA) is the task of providing accurate answers to\nnatural language questions based on visual input. Programmatic VQA (PVQA)\nmodels have been gaining attention recently. These use large language models\n(LLMs) to formulate executable programs that address questions requiring\ncomplex visual reasoning. However, there are challenges in enabling LLMs to\ncomprehend the usage of image processing modules and generate relevant code. To\novercome these challenges, this paper introduces PyramidCoder, a novel\nprompting framework for PVQA models. PyramidCoder consists of three\nhierarchical levels, each serving a distinct purpose: query rephrasing, code\ngeneration, and answer aggregation. Notably, PyramidCoder utilizes a single\nfrozen LLM and pre-defined prompts at each level, eliminating the need for\nadditional training and ensuring flexibility across various LLM architectures.\nCompared to the state-of-the-art PVQA model, our approach improves accuracy by\nat least 0.5% on the GQA dataset, 1.4% on the VQAv2 dataset, and 2.9% on the\nNLVR2 dataset.",
      "tldr_zh": "本研究针对程序化视觉问答（Programmatic VQA, PVQA）中的挑战，提出Pyramid Coder，一种分层代码生成框架，用于处理复杂视觉推理问题。Pyramid Coder包括三个层次：查询重述（query rephrasing）、代码生成（code generation）和答案聚合（answer aggregation），利用单个冻结的Large Language Models (LLMs)以及预定义提示，无需额外训练即可适用于各种LLM架构。实验结果显示，与最先进模型相比，该框架在GQA数据集上准确率至少提高0.5%，在VQAv2上提高1.4%，在NLVR2上提高2.9%，从而提升了PVQA的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the IEEE International Conference on Image Processing\n  (IEEE ICIP) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20563v1",
      "published_date": "2024-07-30 05:36:43 UTC",
      "updated_date": "2024-07-30 05:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:28:12.431909"
    },
    {
      "arxiv_id": "2407.20519v1",
      "title": "DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis",
      "title_zh": "DuA：双注意力 Transformer 在长期连续 EEG 情绪分析中",
      "authors": [
        "Yue Pan",
        "Qile Liu",
        "Qing Liu",
        "Li Zhang",
        "Gan Huang",
        "Xin Chen",
        "Fali Li",
        "Peng Xu",
        "Zhen Liang"
      ],
      "abstract": "Affective brain-computer interfaces (aBCIs) are increasingly recognized for\ntheir potential in monitoring and interpreting emotional states through\nelectroencephalography (EEG) signals. Current EEG-based emotion recognition\nmethods perform well with short segments of EEG data. However, these methods\nencounter significant challenges in real-life scenarios where emotional states\nevolve over extended periods. To address this issue, we propose a Dual\nAttentive (DuA) transformer framework for long-term continuous EEG emotion\nanalysis. Unlike segment-based approaches, the DuA transformer processes an\nentire EEG trial as a whole, identifying emotions at the trial level, referred\nto as trial-based emotion analysis. This framework is designed to adapt to\nvarying signal lengths, providing a substantial advantage over traditional\nmethods. The DuA transformer incorporates three key modules: the\nspatial-spectral network module, the temporal network module, and the transfer\nlearning module. The spatial-spectral network module simultaneously captures\nspatial and spectral information from EEG signals, while the temporal network\nmodule detects temporal dependencies within long-term EEG data. The transfer\nlearning module enhances the model's adaptability across different subjects and\nconditions. We extensively evaluate the DuA transformer using a\nself-constructed long-term EEG emotion database, along with two benchmark EEG\nemotion databases. On the basis of the trial-based leave-one-subject-out\ncross-subject cross-validation protocol, our experimental results demonstrate\nthat the proposed DuA transformer significantly outperforms existing methods in\nlong-term continuous EEG emotion analysis, with an average enhancement of\n5.28%.",
      "tldr_zh": "该论文提出 DuA Transformer 框架，用于处理长期连续 EEG 情绪分析，解决现有方法在真实场景中对长序列 EEG 数据适应性差的问题。DuA 框架将整个 EEG 试验作为一个整体进行试验级情绪识别，包含空间-谱网络模块（捕获 EEG 信号的空间和谱信息）、时间网络模块（检测长期数据的时间依赖性）和迁移学习模块（提升跨受试者适应性）。实验在自建数据库和两个基准数据库上显示，DuA 通过交叉验证协议比现有方法平均提升 5.28%，显著提高了情感脑机接口（aBCIs）的性能。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.20519v1",
      "published_date": "2024-07-30 03:31:03 UTC",
      "updated_date": "2024-07-30 03:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:28:26.710969"
    },
    {
      "arxiv_id": "2407.20518v1",
      "title": "High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE",
      "title_zh": "高分辨率空间转录",
      "authors": [
        "Zhiceng Shi",
        "Shuailin Xue",
        "Fangfang Zhu",
        "Wenwen Min"
      ],
      "abstract": "Spatial transcriptomics (ST) is a groundbreaking genomic technology that\nenables spatial localization analysis of gene expression within tissue\nsections. However, it is significantly limited by high costs and sparse spatial\nresolution. An alternative, more cost-effective strategy is to use deep\nlearning methods to predict high-density gene expression profiles from\nhistological images. However, existing methods struggle to capture rich image\nfeatures effectively or rely on low-dimensional positional coordinates, making\nit difficult to accurately predict high-resolution gene expression profiles. To\naddress these limitations, we developed HisToSGE, a method that employs a\nPathology Image Large Model (PILM) to extract rich image features from\nhistological images and utilizes a feature learning module to robustly generate\nhigh-resolution gene expression profiles. We evaluated HisToSGE on four ST\ndatasets, comparing its performance with five state-of-the-art baseline\nmethods. The results demonstrate that HisToSGE excels in generating\nhigh-resolution gene expression profiles and performing downstream tasks such\nas spatial domain identification. All code and public datasets used in this\npaper are available at https://github.com/wenwenmin/HisToSGE and\nhttps://zenodo.org/records/12792163.",
      "tldr_zh": "空间转录组学（Spatial Transcriptomics, ST）是一种用于分析组织切片中基因表达空间定位的革命性技术，但受限于高成本和稀疏分辨率。研究团队开发了HisToSGE方法，利用Pathology Image Large Model (PILM)提取丰富的组织学图像特征，并通过特征学习模块生成高分辨率的基因表达配置文件，以克服现有深度学习方法的局限性。在四个ST数据集上的实验中，HisToSGE优于五种最先进基线方法，不仅在生成高分辨率配置文件方面表现出色，还提升了下游任务如空间域识别的性能，所有代码和数据集已公开可用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20518v1",
      "published_date": "2024-07-30 03:29:57 UTC",
      "updated_date": "2024-07-30 03:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:28:36.494967"
    },
    {
      "arxiv_id": "2407.20516v1",
      "title": "Machine Unlearning in Generative AI: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zheyuan Liu",
        "Guangyao Dou",
        "Zhaoxuan Tan",
        "Yijun Tian",
        "Meng Jiang"
      ],
      "abstract": "Generative AI technologies have been deployed in many places, such as\n(multimodal) large language models and vision generative models. Their\nremarkable performance should be attributed to massive training data and\nemergent reasoning abilities. However, the models would memorize and generate\nsensitive, biased, or dangerous information originated from the training data\nespecially those from web crawl. New machine unlearning (MU) techniques are\nbeing developed to reduce or eliminate undesirable knowledge and its effects\nfrom the models, because those that were designed for traditional\nclassification tasks could not be applied for Generative AI. We offer a\ncomprehensive survey on many things about MU in Generative AI, such as a new\nproblem formulation, evaluation methods, and a structured discussion on the\nadvantages and limitations of different kinds of MU techniques. It also\npresents several critical challenges and promising directions in MU research. A\ncurated list of readings can be found:\nhttps://github.com/franciscoliu/GenAI-MU-Reading.",
      "tldr_zh": "这篇论文对生成式AI（如大型语言模型和视觉生成模型）中的Machine Unlearning（MU）技术进行了全面调查，旨在解决模型记忆敏感、偏见或危险信息的问题。论文提出新的问题表述、评估方法，并系统讨论了各种MU技术的优势、局限性，以及其在生成式AI中的应用挑战。最终，它指出了关键研究难题和未来方向，并提供了一个精选阅读列表（https://github.com/franciscoliu/GenAI-MU-Reading），为开发更安全可靠的AI模型奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20516v1",
      "published_date": "2024-07-30 03:26:09 UTC",
      "updated_date": "2024-07-30 03:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:28:56.627097"
    },
    {
      "arxiv_id": "2407.20515v1",
      "title": "Markers Identification for Relative Pose Estimation of an Uncooperative Target",
      "title_zh": "翻译失败",
      "authors": [
        "Batu Candan",
        "Simone Servadio"
      ],
      "abstract": "This paper introduces a novel method using chaser spacecraft image processing\nand Convolutional Neural Networks (CNNs) to detect structural markers on the\nEuropean Space Agency's (ESA) Environmental Satellite (ENVISAT) for safe\nde-orbiting. Advanced image pre-processing techniques, including noise addition\nand blurring, are employed to improve marker detection accuracy and robustness.\nInitial results show promising potential for autonomous space debris removal,\nsupporting proactive strategies for space sustainability. The effectiveness of\nour approach suggests that our estimation method could significantly enhance\nthe safety and efficiency of debris removal operations by implementing more\nrobust and autonomous systems in actual space missions.",
      "tldr_zh": "本论文提出了一种新方法，用于识别非合作目标（如欧洲航天局（ESA）的ENVISAT卫星）的结构标记，以支持其相对姿态估计和安全去轨道（de-orbiting）操作。该方法结合了chaser spacecraft的图像处理技术和Convolutional Neural Networks (CNNs)，并采用高级图像预处理技术（如添加噪声和模糊）来提升标记检测的准确性和鲁棒性。初步实验结果显示，该方法在自主空间碎片移除方面表现出巨大潜力，能够显著提高操作的安全性和效率，从而促进空间可持续性的主动策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "2024 AAS/AIAA Astrodynamics Specialist Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.20515v1",
      "published_date": "2024-07-30 03:20:54 UTC",
      "updated_date": "2024-07-30 03:20:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:29:08.642699"
    },
    {
      "arxiv_id": "2407.20513v1",
      "title": "Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Rajaby Faghihi",
        "Aliakbar Nafar",
        "Andrzej Uszok",
        "Hamid Karimian",
        "Parisa Kordjamshidi"
      ],
      "abstract": "This paper presents a conversational pipeline for crafting domain knowledge\nfor complex neuro-symbolic models through natural language prompts. It\nleverages large language models to generate declarative programs in the\nDomiKnowS framework. The programs in this framework express concepts and their\nrelationships as a graph in addition to logical constraints between them. The\ngraph, later, can be connected to trainable neural models according to those\nspecifications. Our proposed pipeline utilizes techniques like dynamic\nin-context demonstration retrieval, model refinement based on feedback from a\nsymbolic parser, visualization, and user interaction to generate the tasks'\nstructure and formal knowledge representation. This approach empowers domain\nexperts, even those not well-versed in ML/AI, to formally declare their\nknowledge to be incorporated in customized neural models in the DomiKnowS\nframework.",
      "tldr_zh": "这篇论文提出了 Prompt2DeModel，一种使用自然语言的对话式管道，用于构建复杂 neuro-symbolic models 的领域知识。该管道利用 large language models 生成 DomiKnowS framework 中的声明式程序，这些程序将概念及其关系表示为图，并添加逻辑约束，然后连接到可训练的神经模型。关键技术包括动态 in-context demonstration retrieval、基于符号解析器的模型细化、可视化和用户交互，从而帮助非 ML/AI 专家的领域专家轻松声明和整合知识，提升神经模型的定制化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NeSy 2024 Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.20513v1",
      "published_date": "2024-07-30 03:10:30 UTC",
      "updated_date": "2024-07-30 03:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:29:24.557702"
    },
    {
      "arxiv_id": "2407.20508v1",
      "title": "Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies",
      "title_zh": "通过空间-时间归一化和编码策略揭示尖峰动力学在图表示学习中的潜力",
      "authors": [
        "Mingkun Xu",
        "Huifeng Yin",
        "Yujie Wu",
        "Guoqi Li",
        "Faqiang Liu",
        "Jing Pei",
        "Shuai Zhong",
        "Lei Deng"
      ],
      "abstract": "In recent years, spiking neural networks (SNNs) have attracted substantial\ninterest due to their potential to replicate the energy-efficient and\nevent-driven processing of biological neurons. Despite this, the application of\nSNNs in graph representation learning, particularly for non-Euclidean data,\nremains underexplored, and the influence of spiking dynamics on graph learning\nis not yet fully understood. This work seeks to address these gaps by examining\nthe unique properties and benefits of spiking dynamics in enhancing graph\nrepresentation learning. We propose a spike-based graph neural network model\nthat incorporates spiking dynamics, enhanced by a novel spatial-temporal\nfeature normalization (STFN) technique, to improve training efficiency and\nmodel stability. Our detailed analysis explores the impact of rate coding and\ntemporal coding on SNN performance, offering new insights into their advantages\nfor deep graph networks and addressing challenges such as the oversmoothing\nproblem. Experimental results demonstrate that our SNN models can achieve\ncompetitive performance with state-of-the-art graph neural networks (GNNs)\nwhile considerably reducing computational costs, highlighting the potential of\nSNNs for efficient neuromorphic computing applications in complex graph-based\nscenarios.",
      "tldr_zh": "本文研究了 SNNs（Spiking Neural Networks）在图表示学习中的潜力，针对非欧空间数据提出了一种结合新型空间-时间特征归一化（STFN）技术的 spike-based 图神经网络模型，以提高训练效率、模型稳定性和解决 oversmoothing 问题。研究还分析了 rate coding 和 temporal coding 对 SNN 性能的影响，提供新见解。实验结果表明，该模型在复杂图场景中与最先进 GNNs（Graph Neural Networks）性能相当，但显著降低了计算成本，突显了 SNNs 在高效神经形态计算中的应用价值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20508v1",
      "published_date": "2024-07-30 02:53:26 UTC",
      "updated_date": "2024-07-30 02:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:29:33.832009"
    },
    {
      "arxiv_id": "2407.20506v1",
      "title": "Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge",
      "title_zh": "通过因果知识提升任务无关探索的效率",
      "authors": [
        "Yupei Yang",
        "Biwei Huang",
        "Shikui Tu",
        "Lei Xu"
      ],
      "abstract": "The effectiveness of model training heavily relies on the quality of\navailable training resources. However, budget constraints often impose\nlimitations on data collection efforts. To tackle this challenge, we introduce\ncausal exploration in this paper, a strategy that leverages the underlying\ncausal knowledge for both data collection and model training. We, in\nparticular, focus on enhancing the sample efficiency and reliability of the\nworld model learning within the domain of task-agnostic reinforcement learning.\nDuring the exploration phase, the agent actively selects actions expected to\nyield causal insights most beneficial for world model training. Concurrently,\nthe causal knowledge is acquired and incrementally refined with the ongoing\ncollection of data. We demonstrate that causal exploration aids in learning\naccurate world models using fewer data and provide theoretical guarantees for\nits convergence. Empirical experiments, on both synthetic data and real-world\napplications, further validate the benefits of causal exploration.",
      "tldr_zh": "该论文提出了一种名为“causal exploration”的策略，利用底层因果知识来优化数据收集和模型训练，旨在解决预算限制下任务无关强化学习（task-agnostic reinforcement learning）中世界模型（world model）学习效率低的问题。代理在探索阶段主动选择能提供最大因果洞见的行动，同时逐步获取并完善因果知识，从而以更少的数据实现准确的世界模型学习。论文提供了该方法的收敛理论保证，并在合成数据和真实世界应用中的实验中验证了其提升样本效率和可靠性的益处。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper was accepted by IJCAI'24",
      "pdf_url": "http://arxiv.org/pdf/2407.20506v1",
      "published_date": "2024-07-30 02:51:21 UTC",
      "updated_date": "2024-07-30 02:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:29:55.296837"
    },
    {
      "arxiv_id": "2407.20503v1",
      "title": "A federated large language model for long-term time series forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Raed Abdel-Sater",
        "A. Ben Hamza"
      ],
      "abstract": "Long-term time series forecasting in centralized environments poses unique\nchallenges regarding data privacy, communication overhead, and scalability. To\naddress these challenges, we propose FedTime, a federated large language model\n(LLM) tailored for long-range time series prediction. Specifically, we\nintroduce a federated pre-trained LLM with fine-tuning and alignment\nstrategies. Prior to the learning process, we employ K-means clustering to\npartition edge devices or clients into distinct clusters, thereby facilitating\nmore focused model training. We also incorporate channel independence and\npatching to better preserve local semantic information, ensuring that important\ncontextual details are retained while minimizing the risk of information loss.\nWe demonstrate the effectiveness of our FedTime model through extensive\nexperiments on various real-world forecasting benchmarks, showcasing\nsubstantial improvements over recent approaches. In addition, we demonstrate\nthe efficiency of FedTime in streamlining resource usage, resulting in reduced\ncommunication overhead.",
      "tldr_zh": "该论文提出 FedTime，一种联邦大型语言模型（Federated LLM），旨在解决长期时间序列预测中的数据隐私、通信开销和可扩展性挑战。方法包括使用 K-means clustering 对边缘设备进行分组，并结合预训练、微调和对齐策略，同时引入 channel independence 和 patching 以保留本地语义信息。实验结果显示，FedTime 在各种真实世界基准上比现有方法有显著改进，并显著降低了通信开销，提高了资源利用效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20503v1",
      "published_date": "2024-07-30 02:38:27 UTC",
      "updated_date": "2024-07-30 02:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:30:07.057015"
    },
    {
      "arxiv_id": "2407.20496v1",
      "title": "Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Seungmin Yu",
        "Xiaodie Yi",
        "Hayun Lee",
        "Dongkun Shin"
      ],
      "abstract": "N:M sparsity pruning is a powerful technique for compressing deep neural\nnetworks, utilizing NVIDIA's Sparse Tensor Core technology. This method\nbenefits from hardware support for sparse indexing, enabling the adoption of\nfine-grained sparsity to maintain model accuracy while minimizing the overhead\ntypically associated with irregular data access. Although restricted to a fixed\nlevel of sparsity due to its reliance on hardware, N:M sparsity can be combined\nwith coarser sparsity techniques to achieve diverse compression ratios.\nInitially, column-wise vector sparsity is applied to a dense model, followed by\nrow-wise N:M sparsity on the preserved column vectors. We call this multi-level\napproach as hierarchical N:M (HiNM) sparsity. Similar to earlier single-level\nsparsity techniques, HiNM sparsity necessitates an effective channel\npermutation strategy to maximize the accuracy of the compressed networks.\nHowever, it introduces further complexities by requiring the rearrangement of\nboth input and output channels, addressing challenges such as permutation\nsequence, HiNM-sparsity-aware permutation, and maintaining consistency in\nchannel ordering across layers. In this paper, we introduce a channel\npermutation method designed specifically for HiNM sparsity, named\ngyro-permutation. This method is crafted to exploit the unique characteristics\nof HiNM pruning, incorporating a strategic policy in each permutation phase,\nincluding channel sampling, clustering, and assignment, to circumvent local\nminima. Additionally, we have developed a GPU kernel that facilitates\nindependent layer permutation during the execution of HiNM sparse networks. Our\nextensive experimental evaluations on various DNN models demonstrate that our\ngyro-permutation significantly enhances the accuracy of HiNM sparse networks,\nallowing them to reach performance levels comparable to those of unstructured\nsparse networks.",
      "tldr_zh": "这篇论文针对深度神经网络（DNNs）的压缩，提出了分层 N:M 稀疏性（Hierarchical N:M, HiNM）方法，该方法结合列-wise 向量稀疏性和行-wise N:M 稀疏性，以实现多样化的压缩比率并利用 NVIDIA 的 Sparse Tensor Core 技术。作者引入了 gyro-permutation 策略，包括通道采样、聚类和分配阶段，以有效处理 HiNM 稀疏性带来的通道重新排列挑战，并开发了一个 GPU 内核支持独立层置换。实验结果显示，gyro-permutation 显著提升了 HiNM 稀疏网络的准确性，使其性能可与非结构化稀疏网络相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.20496v1",
      "published_date": "2024-07-30 01:40:50 UTC",
      "updated_date": "2024-07-30 01:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T11:30:11.336899"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 86,
  "processed_papers_count": 86,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T11:30:37.640413"
}