{
  "date": "2024-05-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-17 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 77 篇论文，主要聚焦于 AI 模型（如大型语言模型 LLMs 在多领域应用的安全性和优化）、医疗 AI、时间序列预测和强化学习等领域，其中 Yann LeCun 参与的“Towards a Framework for Openness in Foundation Models”最为引人注目，强调 AI 开放性的框架设计；其他亮点包括 LLMs 在 UI 代理和多代理强化学习中的创新应用，以及视频生成和医学诊断的进展。\n\n以下是今日论文的精选摘要，我将相关主题的论文归类讨论，先优先选取重要、话题度高的论文（如 LLMs 和医疗 AI），对其他次要论文快速掠过。每篇论文标题以“中文标题 + 英文标题”的格式列出，焦点放在核心贡献和发现上。\n\n### AI 模型与语言生成（重点领域，讨论较多）\n- **潜在状态估计有助于 UI 代理推理 / Latent State Estimation Helps UI Agents to Reason**（作者：William E Bishop 等）：这篇论文探索了大型语言模型（LLMs）在非确定性环境中构建潜在状态估计的能力，主要贡献是通过零-shot 提示和 ReAct 方法，提高 UI 代理任务完成率达 1.6 倍，强调 LLMs 在实时推理中的鲁棒性。\n- **StoryVerse: 基于 LLM 的角色模拟和叙事规划 / StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character Simulation via Narrative Planning**（作者：Yi Wang 等）：创新地将 LLMs 用于游戏叙事生成，通过“抽象行为”机制融合作者意图和角色互动，发现能动态适应游戏状态，生成更丰富的交互式故事。\n- **水印语言模型的多用户适应 / Watermarking Language Models for Many Adaptive Users**（作者：Aloni Cohen 等）：提出多用户水印方案，解决 LLMs 生成文本的可追踪性，核心发现是基于 AEB-robustness 的新抽象，能同时检测 AI 生成文本并追踪用户，即使面对自适应提示。\n- **LLM-based 多代理强化学习：当前与未来方向 / LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions**（作者：Chuanneng Sun 等）：调研 LLMs 在多代理系统中的应用，重点讨论合作任务和通信策略，发现 LLMs 可提升代理协调，但需解决非独立同分布（non-IID）数据挑战。\n- **大型语言模型的道德伪善研究 / Are Large Language Models Moral Hypocrites? A Study Based on Moral Foundations**（作者：José Luiz Nunes 等）：使用 Moral Foundations Theory 评估 GPT-4 等模型的道德一致性，发现模型在抽象和具体场景间存在伪善行为，这对 AI 伦理有重要启示。\n- **多模态大型语言模型的调查 / A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers**（作者：Kaiyu Huang 等）：全面回顾 LLMs 的多语言能力，强调训练方法和挑战，为未来多语言 AI 应用提供框架。\n- 其他如“Jill Watson: A Virtual Teaching Assistant powered by ChatGPT”，快速提及：利用 ChatGPT 构建教学助手，提高了对话系统的模块化和安全性，但细节较常规。\n\n这些论文突显 LLMs 在安全、伦理和应用上的潜力，Yann LeCun 的参与让开放框架话题更具影响力。\n\n### 医疗 AI（高实用性主题，简要讨论）\n- **基于 EEG 的自适应迁移学习 / Subject-Adaptive Transfer Learning Using Resting State EEG Signals for Cross-Subject EEG Motor Imagery Classification**（作者：Sion An 等）：提出新策略使用静息状态 EEG 信号进行脑机接口分类，核心发现是状态解耦方法在三个基准上实现最先进准确率，提升了跨主体分类的效率。\n- **精神分裂症康复管理的 AI 应用调查 / Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: A Systematic Scoping Review**（作者：Hongyi Yang 等）：系统回顾 AI 在精神分裂症管理中的作用，发现监督学习可优化症状监测，但多模态数据集成仍是未来方向。\n- 其他医疗相关如“Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges”，快速掠过：调查 AI 在医学对话中的类别和评估，强调挑战如数据隐私。\n\n这些工作展示了 AI 在医疗中的实际价值，但需关注数据多样性和模型泛化。\n\n### 时间序列和预测（相关但次要，快速概述）\n- **时间序列预测的框架 / WEITS: A Wavelet-enhanced residual framework for interpretable time series forecasting**（作者：Ziyou Guo 等）：引入小波分解提升预测模型的可解释性，发现结合残差架构能提高准确性和效率。\n- **外汇时间序列预测 / Off-the-Shelf Neural Network Architectures for Forex Time Series Prediction come at a Cost**（作者：Theodoros Zafeiriou 等）：比较 LSTM 和专用网络在外汇预测中的性能，贡献是揭示专用模型的资源优势。\n- 其他如“Time-Varying Constraint-Aware Reinforcement Learning”，简要：优化能量存储控制，样本效率高，但非核心话题。\n\n### 其他领域（快速掠过，列出关键点）\n- **知识图谱和强化学习**：如“GraSS: Combining Graph Neural Networks with Expert Knowledge for SAT Solver Selection”，发现 GNN 结合领域知识提升 SAT 求解效率；“ARDDQN: Attention Recurrent Double Deep Q-Network for UAV Coverage Path Planning”，改进 UAV 路径规划，但细节较琐碎。\n- **视频和生成模型**：如“From Sora What We Can See: A Survey of Text-to-Video Generation”，调查文本到视频生成进展，强调 Sora 的影响。\n- 其余论文如“Bayesian Learning-driven Prototypical Contrastive Loss for Class-Incremental Learning”等，贡献在于特定算法优化，但非今日热点，故仅提及标题和主要发现。\n\n总之，今天的 arXiv 论文以 AI 创新为主，LLMs 的安全和应用是核心亮点，医疗 AI 也显示出实际潜力。未来研究应聚焦伦理和泛化挑战，助力 AI 更可靠的应用。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2405.11120v1",
      "title": "Latent State Estimation Helps UI Agents to Reason",
      "title_zh": "潜在状态估计有助于 UI 代理进行推理",
      "authors": [
        "William E Bishop",
        "Alice Li",
        "Christopher Rawles",
        "Oriana Riva"
      ],
      "abstract": "A common problem for agents operating in real-world environments is that the\nresponse of an environment to their actions may be non-deterministic and\nobserved through noise. This renders environmental state and progress towards\ncompleting a task latent. Despite recent impressive demonstrations of LLM's\nreasoning abilities on various benchmarks, whether LLMs can build estimates of\nlatent state and leverage them for reasoning has not been explicitly studied.\nWe investigate this problem in the real-world domain of autonomous UI agents.\nWe establish that appropriately prompting LLMs in a zero-shot manner can be\nformally understood as forming point estimates of latent state in a textual\nspace. In the context of autonomous UI agents we then show that LLMs used in\nthis manner are more than $76\\%$ accurate at inferring various aspects of\nlatent state, such as performed (vs. commanded) actions and task progression.\nUsing both public and internal benchmarks and three reasoning methods\n(zero-shot, CoT-SC & ReAct), we show that LLM-powered agents that explicitly\nestimate and reason about latent state are able to successfully complete up to\n1.6x more tasks than those that do not.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在处理不确定性环境中潜在状态（latent state）估计的问题，特别是针对自主 UI 代理的推理能力。研究发现，通过零样本（zero-shot）提示，LLMs 可以形成潜在状态的文本空间点估计，并在推断动作执行和任务进度等方面达到超过76%的准确率。使用公共和内部基准以及三种推理方法（zero-shot、CoT-SC 和 ReAct），显式估计潜在状态的代理能够比不估计的代理完成多达1.6倍的任务，从而提升代理在真实世界任务中的性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11120v1",
      "published_date": "2024-05-17 23:27:33 UTC",
      "updated_date": "2024-05-17 23:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:10:25.847952"
    },
    {
      "arxiv_id": "2405.13042v2",
      "title": "StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character Simulation via Narrative Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Wang",
        "Qian Zhou",
        "David Ledo"
      ],
      "abstract": "Automated plot generation for games enhances the player's experience by\nproviding rich and immersive narrative experience that adapts to the player's\nactions. Traditional approaches adopt a symbolic narrative planning method\nwhich limits the scale and complexity of the generated plot by requiring\nextensive knowledge engineering work. Recent advancements use Large Language\nModels (LLMs) to drive the behavior of virtual characters, allowing plots to\nemerge from interactions between characters and their environments. However,\nthe emergent nature of such decentralized plot generation makes it difficult\nfor authors to direct plot progression. We propose a novel plot creation\nworkflow that mediates between a writer's authorial intent and the emergent\nbehaviors from LLM-driven character simulation, through a novel authorial\nstructure called \"abstract acts\". The writers define high-level plot outlines\nthat are later transformed into concrete character action sequences via an\nLLM-based narrative planning process, based on the game world state. The\nprocess creates \"living stories\" that dynamically adapt to various game world\nstates, resulting in narratives co-created by the author, character simulation,\nand player. We present StoryVerse as a proof-of-concept system to demonstrate\nthis plot creation workflow. We showcase the versatility of our approach with\nexamples in different stories and game environments.",
      "tldr_zh": "这篇论文提出StoryVerse系统，通过LLM-based narrative planning和character simulation，实现作者与虚拟人物的共同创作动态游戏情节。作者定义高层“abstract acts”作为结构中介，将其转化为具体行动序列，以适应游戏世界状态，从而创建动态的“living stories”。该方法解决了传统符号化叙事规划的局限性，并在不同故事和游戏环境中展示了其多功能性和潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Proceedings of the 19th international conference on the foundations\n  of digital games 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13042v2",
      "published_date": "2024-05-17 23:04:51 UTC",
      "updated_date": "2024-11-02 05:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:10:37.159923"
    },
    {
      "arxiv_id": "2405.11109v2",
      "title": "Watermarking Language Models for Many Adaptive Users",
      "title_zh": "翻译失败",
      "authors": [
        "Aloni Cohen",
        "Alexander Hoover",
        "Gabe Schoenbach"
      ],
      "abstract": "We study watermarking schemes for language models with provable guarantees.\nAs we show, prior works offer no robustness guarantees against adaptive\nprompting: when a user queries a language model more than once, as even benign\nusers do. And with just a single exception (Christ and Gunn, 2024), prior works\nare restricted to zero-bit watermarking: machine-generated text can be detected\nas such, but no additional information can be extracted from the watermark.\nUnfortunately, merely detecting AI-generated text may not prevent future\nabuses.\n  We introduce multi-user watermarks, which allow tracing model-generated text\nto individual users or to groups of colluding users, even in the face of\nadaptive prompting. We construct multi-user watermarking schemes from\nundetectable, adaptively robust, zero-bit watermarking schemes (and prove that\nthe undetectable zero-bit scheme of Christ, Gunn, and Zamir (2024) is\nadaptively robust). Importantly, our scheme provides both zero-bit and\nmulti-user assurances at the same time. It detects shorter snippets just as\nwell as the original scheme, and traces longer excerpts to individuals.\n  The main technical component is a construction of message-embedding\nwatermarks from zero-bit watermarks. Ours is the first generic reduction\nbetween watermarking schemes for language models. A challenge for such\nreductions is the lack of a unified abstraction for robustness -- that marked\ntext is detectable even after edits. We introduce a new unifying abstraction\ncalled AEB-robustness. AEB-robustness provides that the watermark is detectable\nwhenever the edited text \"approximates enough blocks\" of model-generated\noutput.",
      "tldr_zh": "本文提出了一种多用户水印（multi-user watermarks）方案，用于语言模型，以应对自适应提示（adaptive prompting）下的鲁棒性挑战，允许追踪模型生成的文本到单个用户或共谋用户群，同时保留零位水印（zero-bit watermarking）的检测功能。核心方法是从不可检测的零位水印方案构建消息嵌入水印（message-embedding watermarks），并引入新的 AEB-robustness 抽象，确保水印在编辑后文本“足够接近块”时仍可检测。主要贡献包括提供首个泛化归约框架和更强的追踪能力，解决了现有方法的局限性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "39 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.11109v2",
      "published_date": "2024-05-17 22:15:30 UTC",
      "updated_date": "2024-06-28 22:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:10:51.689099"
    },
    {
      "arxiv_id": "2405.11106v1",
      "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions",
      "title_zh": "基于 LLM 的多智能体强化学习：当前和未来方向",
      "authors": [
        "Chuanneng Sun",
        "Songjun Huang",
        "Dario Pompili"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have shown great abilities in\nvarious tasks, including question answering, arithmetic problem solving, and\npoem writing, among others. Although research on LLM-as-an-agent has shown that\nLLM can be applied to Reinforcement Learning (RL) and achieve decent results,\nthe extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as\nmany aspects, such as coordination and communication between agents, are not\nconsidered in the RL frameworks of a single agent. To inspire more research on\nLLM-based MARL, in this letter, we survey the existing LLM-based single-agent\nand multi-agent RL frameworks and provide potential research directions for\nfuture research. In particular, we focus on the cooperative tasks of multiple\nagents with a common goal and communication among them. We also consider\nhuman-in/on-the-loop scenarios enabled by the language component in the\nframework.",
      "tldr_zh": "这篇论文调查了Large Language Models (LLMs) 在强化学习（RL）中的应用，并探讨了将其扩展到Multi-Agent System (MAS)的挑战。作者回顾了现有的LLM-based单智能体和多智能体RL框架，强调了代理间的协调、通信等问题在MAS中的重要性，特别是针对多个代理的合作任务。未来研究方向包括优化代理通信和整合人类参与的场景，以推动LLM-based Multi-Agent RL 的发展。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "8 pages, 1 figure, 1 table, submitted to IEEE RA-L",
      "pdf_url": "http://arxiv.org/pdf/2405.11106v1",
      "published_date": "2024-05-17 22:10:23 UTC",
      "updated_date": "2024-05-17 22:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:11:01.514639"
    },
    {
      "arxiv_id": "2405.11100v2",
      "title": "Are Large Language Models Moral Hypocrites? A Study Based on Moral Foundations",
      "title_zh": "翻译失败",
      "authors": [
        "José Luiz Nunes",
        "Guilherme F. C. F. Almeida",
        "Marcelo de Araujo",
        "Simone D. J. Barbosa"
      ],
      "abstract": "Large language models (LLMs) have taken centre stage in debates on Artificial\nIntelligence. Yet there remains a gap in how to assess LLMs' conformity to\nimportant human values. In this paper, we investigate whether state-of-the-art\nLLMs, GPT-4 and Claude 2.1 (Gemini Pro and LLAMA 2 did not generate valid\nresults) are moral hypocrites. We employ two research instruments based on the\nMoral Foundations Theory: (i) the Moral Foundations Questionnaire (MFQ), which\ninvestigates which values are considered morally relevant in abstract moral\njudgements; and (ii) the Moral Foundations Vignettes (MFVs), which evaluate\nmoral cognition in concrete scenarios related to each moral foundation. We\ncharacterise conflicts in values between these different abstractions of moral\nevaluation as hypocrisy. We found that both models displayed reasonable\nconsistency within each instrument compared to humans, but they displayed\ncontradictory and hypocritical behaviour when we compared the abstract values\npresent in the MFQ to the evaluation of concrete moral violations of the MFV.",
      "tldr_zh": "这篇论文研究了大型语言模型（LLMs），如 GPT-4 和 Claude 2.1，是否表现出道德伪善行为，基于 Moral Foundations Theory 进行评估。研究者使用了 Moral Foundations Questionnaire (MFQ) 来考察抽象道德判断中哪些价值观被视为道德相关，以及 Moral Foundations Vignettes (MFVs) 来评估具体场景中的道德认知。结果显示，模型在每个工具内部表现出与人类相当的一致性，但当比较 MFQ 的抽象价值观与 MFV 的具体道德违规评估时，存在矛盾和伪善行为，这突显了 LLMs 在道德一致性方面的局限性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Final version available at:\n  https://ojs.aaai.org/index.php/AIES/article/view/31704 13 pages, 4 figures, 2\n  tables",
      "pdf_url": "http://arxiv.org/pdf/2405.11100v2",
      "published_date": "2024-05-17 21:27:32 UTC",
      "updated_date": "2024-10-22 00:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:11:14.307814"
    },
    {
      "arxiv_id": "2405.19346v2",
      "title": "Subject-Adaptive Transfer Learning Using Resting State EEG Signals for Cross-Subject EEG Motor Imagery Classification",
      "title_zh": "受试者自适应迁移学习：",
      "authors": [
        "Sion An",
        "Myeongkyun Kang",
        "Soopil Kim",
        "Philip Chikontwe",
        "Li Shen",
        "Sang Hyun Park"
      ],
      "abstract": "Electroencephalography (EEG) motor imagery (MI) classification is a\nfundamental, yet challenging task due to the variation of signals between\nindividuals i.e., inter-subject variability. Previous approaches try to\nmitigate this using task-specific (TS) EEG signals from the target subject in\ntraining. However, recording TS EEG signals requires time and limits its\napplicability in various fields. In contrast, resting state (RS) EEG signals\nare a viable alternative due to ease of acquisition with rich subject\ninformation. In this paper, we propose a novel subject-adaptive transfer\nlearning strategy that utilizes RS EEG signals to adapt models on unseen\nsubject data. Specifically, we disentangle extracted features into task- and\nsubject-dependent features and use them to calibrate RS EEG signals for\nobtaining task information while preserving subject characteristics. The\ncalibrated signals are then used to adapt the model to the target subject,\nenabling the model to simulate processing TS EEG signals of the target subject.\nThe proposed method achieves state-of-the-art accuracy on three public\nbenchmarks, demonstrating the effectiveness of our method in cross-subject EEG\nMI classification. Our findings highlight the potential of leveraging RS EEG\nsignals to advance practical brain-computer interface systems. The code is\navailable at https://github.com/SionAn/MICCAI2024-ResTL.",
      "tldr_zh": "本文提出了一种主体自适应转移学习策略，使用休息状态（RS）EEG 信号来解决跨主体 EEG 运动想象（MI）分类中的个体间变异（inter-subject variability）问题。该方法通过从 RS EEG 信号中分离任务相关和主体相关特征，并对信号进行校准，以提取任务信息同时保留主体特性，从而使模型能够模拟处理目标主体的任务特定（TS）EEG 信号。在三个公共基准上，该方法实现了最先进的准确率，证明了其有效性，并展示了利用 RS EEG 信号推进实际脑机接口系统的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Early Accepted at MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19346v2",
      "published_date": "2024-05-17 20:36:04 UTC",
      "updated_date": "2024-07-09 14:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:11:26.859576"
    },
    {
      "arxiv_id": "2405.15802v1",
      "title": "Towards a Framework for Openness in Foundation Models: Proceedings from the Columbia Convening on Openness in Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Adrien Basdevant",
        "Camille François",
        "Victor Storchan",
        "Kevin Bankston",
        "Ayah Bdeir",
        "Brian Behlendorf",
        "Merouane Debbah",
        "Sayash Kapoor",
        "Yann LeCun",
        "Mark Surman",
        "Helen King-Turvey",
        "Nathan Lambert",
        "Stefano Maffulli",
        "Nik Marda",
        "Govind Shivkumar",
        "Justine Tunney"
      ],
      "abstract": "Over the past year, there has been a robust debate about the benefits and\nrisks of open sourcing foundation models. However, this discussion has often\ntaken place at a high level of generality or with a narrow focus on specific\ntechnical attributes. In part, this is because defining open source for\nfoundation models has proven tricky, given its significant differences from\ntraditional software development. In order to inform more practical and nuanced\ndecisions about opening AI systems, including foundation models, this paper\npresents a framework for grappling with openness across the AI stack. It\nsummarizes previous work on this topic, analyzes the various potential reasons\nto pursue openness, and outlines how openness varies in different parts of the\nAI stack, both at the model and at the system level. In doing so, its authors\nhope to provide a common descriptive framework to deepen a nuanced and rigorous\nunderstanding of openness in AI and enable further work around definitions of\nopenness and safety in AI.",
      "tldr_zh": "这篇论文基于哥伦比亚人工智能开源会议，提出一个框架来处理 foundation models 的开源问题，旨在解决当前讨论过于泛化或狭隘的局限性。框架总结了之前相关工作，分析了追求开源的各种潜在理由，并探讨了开源在 AI stack 的模型和系统层面上的差异。最终，该框架为加深对 AI 中开源的理解提供了一个共同的描述工具，并推动未来在开源定义和安全方面的研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15802v1",
      "published_date": "2024-05-17 20:35:39 UTC",
      "updated_date": "2024-05-17 20:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:11:38.307029"
    },
    {
      "arxiv_id": "2405.11070v1",
      "title": "Jill Watson: A Virtual Teaching Assistant powered by ChatGPT",
      "title_zh": "Jill",
      "authors": [
        "Karan Taneja",
        "Pratyusha Maiti",
        "Sandeep Kakar",
        "Pranav Guruprasad",
        "Sanjeev Rao",
        "Ashok K. Goel"
      ],
      "abstract": "Conversational AI agents often require extensive datasets for training that\nare not publicly released, are limited to social chit-chat or handling a\nspecific domain, and may not be easily extended to accommodate the latest\nadvances in AI technologies. This paper introduces Jill Watson, a\nconversational Virtual Teaching Assistant (VTA) leveraging the capabilities of\nChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a\nmodular design to allow the integration of new APIs using a skill-based\narchitecture inspired by XiaoIce. Jill Watson is also well-suited for\nintelligent textbooks as it can process and converse using multiple large\ndocuments. We exclusively utilize publicly available resources for\nreproducibility and extensibility. Comparative analysis shows that our system\noutperforms the legacy knowledge-based Jill Watson as well as the OpenAI\nAssistants service. We employ many safety measures that reduce instances of\nhallucinations and toxicity. The paper also includes real-world examples from a\nclassroom setting that demonstrate different features of Jill Watson and its\neffectiveness.",
      "tldr_zh": "这篇论文介绍了 Jill Watson，一种基于 ChatGPT 的虚拟教学助理 (VTA)，它无需先前的训练，通过模块化设计和技能-based 架构（如 XiaoIce 启发）轻松集成新 API，并能处理多个大型文档以支持智能教科书。系统仅使用公开资源，确保可重现性和可扩展性，并在安全性方面采用措施减少 hallucination 和 toxicity。相比传统知识-based Jill Watson 和 OpenAI Assistants，Jill Watson 的性能提升明显，并在真实课堂示例中展示了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11070v1",
      "published_date": "2024-05-17 19:55:57 UTC",
      "updated_date": "2024-05-17 19:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:11:49.672518"
    },
    {
      "arxiv_id": "2405.11067v3",
      "title": "Bayesian Learning-driven Prototypical Contrastive Loss for Class-Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nisha L. Raichur",
        "Lucas Heublein",
        "Tobias Feigl",
        "Alexander Rügamer",
        "Christopher Mutschler",
        "Felix Ott"
      ],
      "abstract": "The primary objective of methods in continual learning is to learn tasks in a\nsequential manner over time (sometimes from a stream of data), while mitigating\nthe detrimental phenomenon of catastrophic forgetting. This paper proposes a\nmethod to learn an effective representation between previous and newly\nencountered class prototypes. We propose a prototypical network with a Bayesian\nlearning-driven contrastive loss (BLCL), tailored specifically for\nclass-incremental learning scenarios. We introduce a contrastive loss that\nincorporates novel classes into the latent representation by reducing\nintra-class and increasing inter-class distance. Our approach dynamically\nadapts the balance between the cross-entropy and contrastive loss functions\nwith a Bayesian learning technique. Experimental results conducted on the\nCIFAR-10, CIFAR-100, and ImageNet100 datasets for image classification and\nimages of a GNSS-based dataset for interference classification validate the\nefficacy of our method, showcasing its superiority over existing\nstate-of-the-art approaches. Git:\nhttps://gitlab.cc-asp.fraunhofer.de/darcy_gnss/gnss_class_incremental_learning",
      "tldr_zh": "本论文针对持续学习（continual learning）中的类增量学习（class-incremental learning）问题，提出了一种基于原型网络的 Bayesian 学习驱动对比损失（BLCL）方法，以缓解灾难性遗忘（catastrophic forgetting）。该方法通过减少类内距离和增加类间距离，将新类融入潜在表示，并利用 Bayesian 学习技术动态调整交叉熵损失和对比损失的平衡。实验结果在 CIFAR-10、CIFAR-100 和 ImageNet100 等图像分类数据集，以及 GNSS 干扰分类数据集上，证明了该方法的有效性，并展示了其优于现有最先进方法的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "62P30, 68T30, 68T05, 68T37",
        "G.3; I.2.4; I.2.6"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.11067v3",
      "published_date": "2024-05-17 19:49:02 UTC",
      "updated_date": "2025-03-31 13:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:12:02.592254"
    },
    {
      "arxiv_id": "2405.11055v3",
      "title": "Leveraging Discourse Structure for Extractive Meeting Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Virgile Rennard",
        "Guokan Shang",
        "Michalis Vazirgiannis",
        "Julie Hunter"
      ],
      "abstract": "We introduce an extractive summarization system for meetings that leverages\ndiscourse structure to better identify salient information from complex\nmulti-party discussions. Using discourse graphs to represent semantic relations\nbetween the contents of utterances in a meeting, we train a GNN-based node\nclassification model to select the most important utterances, which are then\ncombined to create an extractive summary. Experimental results on AMI and ICSI\ndemonstrate that our approach surpasses existing text-based and graph-based\nextractive summarization systems, as measured by both classification and\nsummarization metrics. Additionally, we conduct ablation studies on discourse\nstructure and relation type to provide insights for future NLP applications\nleveraging discourse analysis theory.",
      "tldr_zh": "该研究提出了一种提取式(extractive)会议摘要系统，通过利用话语结构(discourse structure)来识别多方讨论中的关键信息。系统使用话语图(discourse graphs)表示表达之间的语义关系，并训练基于GNN(Graph Neural Network)的节点分类模型来选择最重要的表达，从而生成摘要。在AMI和ICSI数据集上的实验显示，该方法在分类和摘要指标上超过了现有基于文本和图的系统；此外，消融研究(ablation studies)分析了话语结构和关系类型的作用，为未来NLP应用提供见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11055v3",
      "published_date": "2024-05-17 19:06:20 UTC",
      "updated_date": "2024-09-23 08:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:12:14.794196"
    },
    {
      "arxiv_id": "2405.11053v3",
      "title": "The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Guy Aridor",
        "Duarte Goncalves",
        "Ruoyan Kong",
        "Daniel Kluver",
        "Joseph Konstan"
      ],
      "abstract": "An increasingly important aspect of designing recommender systems involves\nconsidering how recommendations will influence consumer choices. This paper\naddresses this issue by introducing a method for collecting user beliefs about\nun-experienced items - a critical predictor of choice behavior. We implemented\nthis method on the MovieLens platform, resulting in a rich dataset that\ncombines user ratings, beliefs, and observed recommendations. We document\nchallenges to such data collection, including selection bias in response and\nlimited coverage of the product space. This unique resource empowers\nresearchers to delve deeper into user behavior and analyze user choices absent\nrecommendations, measure the effectiveness of recommendations, and prototype\nalgorithms that leverage user belief data, ultimately leading to more impactful\nrecommender systems. The dataset can be found at\nhttps://grouplens.org/datasets/movielens/ml_belief_2024/.",
      "tldr_zh": "本研究介绍了 MovieLens Beliefs Dataset，一种用于在线推荐系统（recommender systems）的预选择数据收集方法，该方法聚焦于收集用户对未体验物品的信念，以更好地预测消费者选择行为。研究者在 MovieLens 平台上实施此方法，获得了包含用户评分、信念和观察推荐的丰富数据集，同时讨论了数据收集中的挑战，如响应选择偏差（selection bias）和产品空间覆盖有限。数据集为研究人员提供了宝贵资源，可用于分析无推荐下的用户行为、评估推荐有效性，以及原型化利用用户信念数据的算法，最终提升推荐系统的设计和影响。数据集可访问 https://grouplens.org/datasets/movielens/ml_belief_2024/。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "To Appear in RecSys 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11053v3",
      "published_date": "2024-05-17 19:06:06 UTC",
      "updated_date": "2024-08-02 13:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:12:28.493989"
    },
    {
      "arxiv_id": "2405.11029v1",
      "title": "Generative Artificial Intelligence: A Systematic Review and Applications",
      "title_zh": "生成式人工智能：系统综述和应用",
      "authors": [
        "Sandeep Singh Sengar",
        "Affan Bin Hasan",
        "Sanjay Kumar",
        "Fiona Carroll"
      ],
      "abstract": "In recent years, the study of artificial intelligence (AI) has undergone a\nparadigm shift. This has been propelled by the groundbreaking capabilities of\ngenerative models both in supervised and unsupervised learning scenarios.\nGenerative AI has shown state-of-the-art performance in solving perplexing\nreal-world conundrums in fields such as image translation, medical diagnostics,\ntextual imagery fusion, natural language processing, and beyond. This paper\ndocuments the systematic review and analysis of recent advancements and\ntechniques in Generative AI with a detailed discussion of their applications\nincluding application-specific models. Indeed, the major impact that generative\nAI has made to date, has been in language generation with the development of\nlarge language models, in the field of image translation and several other\ninterdisciplinary applications of generative AI. Moreover, the primary\ncontribution of this paper lies in its coherent synthesis of the latest\nadvancements in these areas, seamlessly weaving together contemporary\nbreakthroughs in the field. Particularly, how it shares an exploration of the\nfuture trajectory for generative AI. In conclusion, the paper ends with a\ndiscussion of Responsible AI principles, and the necessary ethical\nconsiderations for the sustainability and growth of these generative models.",
      "tldr_zh": "这篇论文对 Generative Artificial Intelligence 进行了系统综述，分析了其在监督和非监督学习中的最新进展和技术，特别是在图像翻译、医疗诊断、自然语言处理等领域中的突破性应用。论文重点讨论了 Generative AI 的实际影响，如大型语言模型在语言生成中的作用，以及其他跨学科应用，并强调了其主要贡献在于整合当代进展并探索未来发展方向。最终，论文呼吁关注 Responsible AI 原则和伦理考虑，以确保这些模型的可持续性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11029v1",
      "published_date": "2024-05-17 18:03:59 UTC",
      "updated_date": "2024-05-17 18:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:12:38.801728"
    },
    {
      "arxiv_id": "2405.11024v1",
      "title": "GraSS: Combining Graph Neural Networks with Expert Knowledge for SAT Solver Selection",
      "title_zh": "GraSS：结合图神经网络与专家知识用于 SAT 求解器选择",
      "authors": [
        "Zhanguang Zhang",
        "Didier Chetelat",
        "Joseph Cotnareanu",
        "Amur Ghose",
        "Wenyi Xiao",
        "Hui-Ling Zhen",
        "Yingxue Zhang",
        "Jianye Hao",
        "Mark Coates",
        "Mingxuan Yuan"
      ],
      "abstract": "Boolean satisfiability (SAT) problems are routinely solved by SAT solvers in\nreal-life applications, yet solving time can vary drastically between solvers\nfor the same instance. This has motivated research into machine learning models\nthat can predict, for a given SAT instance, which solver to select among\nseveral options. Existing SAT solver selection methods all rely on some\nhand-picked instance features, which are costly to compute and ignore the\nstructural information in SAT graphs. In this paper we present GraSS, a novel\napproach for automatic SAT solver selection based on tripartite graph\nrepresentations of instances and a heterogeneous graph neural network (GNN)\nmodel. While GNNs have been previously adopted in other SAT-related tasks, they\ndo not incorporate any domain-specific knowledge and ignore the runtime\nvariation introduced by different clause orders. We enrich the graph\nrepresentation with domain-specific decisions, such as novel node feature\ndesign, positional encodings for clauses in the graph, a GNN architecture\ntailored to our tripartite graphs and a runtime-sensitive loss function.\nThrough extensive experiments, we demonstrate that this combination of raw\nrepresentations and domain-specific choices leads to improvements in runtime\nfor a pool of seven state-of-the-art solvers on both an industrial circuit\ndesign benchmark, and on instances from the 20-year Anniversary Track of the\n2022 SAT Competition.",
      "tldr_zh": "该论文提出GraSS，一种结合图神经网络(GNN)和专家知识的框架，用于布尔可满足性(SAT)求解器选择，以解决不同求解器在同一实例上的运行时间差异问题。GraSS使用三部图表示SAT实例，并通过异构GNN模型融入领域特定设计，如新型节点特征、位置编码、定制GNN架构和运行时敏感损失函数。实验结果显示，在工业电路设计基准和2022 SAT比赛实例上，GraSS显著提高了七个最先进求解器的整体运行效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11024v1",
      "published_date": "2024-05-17 18:00:50 UTC",
      "updated_date": "2024-05-17 18:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:12:51.455640"
    },
    {
      "arxiv_id": "2405.10939v1",
      "title": "DINO as a von Mises-Fisher mixture model",
      "title_zh": "DINO 作为 von Mises-Fisher 混合模型",
      "authors": [
        "Hariprasath Govindarajan",
        "Per Sidén",
        "Jacob Roll",
        "Fredrik Lindsten"
      ],
      "abstract": "Self-distillation methods using Siamese networks are popular for\nself-supervised pre-training. DINO is one such method based on a cross-entropy\nloss between $K$-dimensional probability vectors, obtained by applying a\nsoftmax function to the dot product between representations and learnt\nprototypes. Given the fact that the learned representations are\n$L^2$-normalized, we show that DINO and its derivatives, such as iBOT, can be\ninterpreted as a mixture model of von Mises-Fisher components. With this\ninterpretation, DINO assumes equal precision for all components when the\nprototypes are also $L^2$-normalized. Using this insight we propose DINO-vMF,\nthat adds appropriate normalization constants when computing the cluster\nassignment probabilities. Unlike DINO, DINO-vMF is stable also for the larger\nViT-Base model with unnormalized prototypes. We show that the added flexibility\nof the mixture model is beneficial in terms of better image representations.\nThe DINO-vMF pre-trained model consistently performs better than DINO on a\nrange of downstream tasks. We obtain similar improvements for iBOT-vMF vs iBOT\nand thereby show the relevance of our proposed modification also for other\nmethods derived from DINO.",
      "tldr_zh": "本研究将自监督预训练方法 DINO 解释为 von Mises-Fisher (vMF) 混合模型，基于其对 L2-normalized 表示和 prototypes 的处理，以及交叉熵损失计算。作者提出改进版本 DINO-vMF，通过添加归一化常数来计算聚类分配概率，提升了模型的稳定性和灵活性，尤其适用于未归一化 prototypes 的更大模型如 ViT-Base。实验结果显示，DINO-vMF 在多种下游任务上比 DINO 表现出色，提供更好的图像表示，且类似改进也适用于 iBOT-vMF 与 iBOT。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.10939v1",
      "published_date": "2024-05-17 17:49:45 UTC",
      "updated_date": "2024-05-17 17:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:13:04.054930"
    },
    {
      "arxiv_id": "2405.10938v3",
      "title": "Observational Scaling Laws and the Predictability of Language Model Performance",
      "title_zh": "观察性的缩放定律与语言模型性能的可预测性",
      "authors": [
        "Yangjun Ruan",
        "Chris J. Maddison",
        "Tatsunori Hashimoto"
      ],
      "abstract": "Understanding how language model performance varies with scale is critical to\nbenchmark and algorithm development. Scaling laws are one approach to building\nthis understanding, but the requirement of training models across many\ndifferent scales has limited their use. We propose an alternative,\nobservational approach that bypasses model training and instead builds scaling\nlaws from ~100 publically available models. Building a single scaling law from\nmultiple model families is challenging due to large variations in their\ntraining compute efficiencies and capabilities. However, we show that these\nvariations are consistent with a simple, generalized scaling law where language\nmodel performance is a function of a low-dimensional capability space, and\nmodel families only vary in their efficiency in converting training compute to\ncapabilities. Using this approach, we show the surprising predictability of\ncomplex scaling phenomena: we show that several emergent phenomena follow a\nsmooth, sigmoidal behavior and are predictable from small models; we show that\nthe agent performance of models such as GPT-4 can be precisely predicted from\nsimpler non-agentic benchmarks; and we show how to predict the impact of\npost-training interventions like Chain-of-Thought and Self-Consistency as\nlanguage model capabilities continue to improve.",
      "tldr_zh": "该研究提出了一种观察性方法，通过分析约100个公开语言模型来构建scaling laws，理解语言模型性能如何随规模变化，而无需额外训练。该方法解决了不同模型家族在训练计算效率和能力上的差异，采用一个广义scaling law，将性能视为低维能力空间的函数。研究发现，涌现现象遵循平滑的S形行为，可从小型模型预测；如GPT-4的代理性能能从简单非代理基准精确预测；此外，还能预测后训练干预如Chain-of-Thought和Self-Consistency的影响，随着模型能力提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024 as a spotlight",
      "pdf_url": "http://arxiv.org/pdf/2405.10938v3",
      "published_date": "2024-05-17 17:49:44 UTC",
      "updated_date": "2024-10-01 23:38:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:13:16.232767"
    },
    {
      "arxiv_id": "2405.10936v2",
      "title": "A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyu Huang",
        "Fengran Mo",
        "Xinyu Zhang",
        "Hongliang Li",
        "You Li",
        "Yuanchi Zhang",
        "Weijian Yi",
        "Yulong Mao",
        "Jinchen Liu",
        "Yuzhuang Xu",
        "Jinan Xu",
        "Jian-Yun Nie",
        "Yang Liu"
      ],
      "abstract": "The rapid development of Large Language Models (LLMs) demonstrates remarkable\nmultilingual capabilities in natural language processing, attracting global\nattention in both academia and industry. To mitigate potential discrimination\nand enhance the overall usability and accessibility for diverse language user\ngroups, it is important for the development of language-fair technology.\nDespite the breakthroughs of LLMs, the investigation into the multilingual\nscenario remains insufficient, where a comprehensive survey to summarize recent\napproaches, developments, limitations, and potential solutions is desirable. To\nthis end, we provide a survey with multiple perspectives on the utilization of\nLLMs in the multilingual scenario. We first rethink the transitions between\nprevious and current research on pre-trained language models. Then we introduce\nseveral perspectives on the multilingualism of LLMs, including training and\ninference methods, information retrieval, model security, multi-domain with\nlanguage culture, and usage of datasets. We also discuss the major challenges\nthat arise in these aspects, along with possible solutions. Besides, we\nhighlight future research directions that aim at further enhancing LLMs with\nmultilingualism. The survey aims to help the research community address\nmultilingual problems and provide a comprehensive understanding of the core\nconcepts, key techniques, and latest developments in multilingual natural\nlanguage processing based on LLMs.",
      "tldr_zh": "这篇调查论文回顾了大型语言模型（LLMs）在多语言场景中的最新进展和新前沿，强调了其在自然语言处理中的多语言能力及其全球影响。论文从训练和推理方法、信息检索、模型安全、多领域语言文化以及数据集使用等多个视角，总结了现有方法、限制和潜在解决方案，以缓解语言歧视并提升模型的公平性。研究还指出了主要挑战，如多语言训练不足，并提出未来方向，如进一步增强LLMs的多语言性能，以促进更具包容性的自然语言处理技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "65 pages, Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2405.10936v2",
      "published_date": "2024-05-17 17:47:39 UTC",
      "updated_date": "2025-01-07 12:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:13:26.936269"
    },
    {
      "arxiv_id": "2405.10925v1",
      "title": "High-dimensional multiple imputation (HDMI) for partially observed confounders including natural language processing-derived auxiliary covariates",
      "title_zh": "翻译失败",
      "authors": [
        "Janick Weberpals",
        "Pamela A. Shaw",
        "Kueiyu Joshua Lin",
        "Richard Wyss",
        "Joseph M Plasek",
        "Li Zhou",
        "Kerry Ngan",
        "Thomas DeRamus",
        "Sudha R. Raman",
        "Bradley G. Hammill",
        "Hana Lee",
        "Sengwee Toh",
        "John G. Connolly",
        "Kimberly J. Dandreo",
        "Fang Tian",
        "Wei Liu",
        "Jie Li",
        "José J. Hernández-Muñoz",
        "Sebastian Schneeweiss",
        "Rishi J. Desai"
      ],
      "abstract": "Multiple imputation (MI) models can be improved by including auxiliary\ncovariates (AC), but their performance in high-dimensional data is not well\nunderstood. We aimed to develop and compare high-dimensional MI (HDMI)\napproaches using structured and natural language processing (NLP)-derived AC in\nstudies with partially observed confounders. We conducted a plasmode simulation\nstudy using data from opioid vs. non-steroidal anti-inflammatory drug (NSAID)\ninitiators (X) with observed serum creatinine labs (Z2) and time-to-acute\nkidney injury as outcome. We simulated 100 cohorts with a null treatment\neffect, including X, Z2, atrial fibrillation (U), and 13 other\ninvestigator-derived confounders (Z1) in the outcome generation. We then\nimposed missingness (MZ2) on 50% of Z2 measurements as a function of Z2 and U\nand created different HDMI candidate AC using structured and NLP-derived\nfeatures. We mimicked scenarios where U was unobserved by omitting it from all\nAC candidate sets. Using LASSO, we data-adaptively selected HDMI covariates\nassociated with Z2 and MZ2 for MI, and with U to include in propensity score\nmodels. The treatment effect was estimated following propensity score matching\nin MI datasets and we benchmarked HDMI approaches against a baseline imputation\nand complete case analysis with Z1 only. HDMI using claims data showed the\nlowest bias (0.072). Combining claims and sentence embeddings led to an\nimprovement in the efficiency displaying the lowest root-mean-squared-error\n(0.173) and coverage (94%). NLP-derived AC alone did not perform better than\nbaseline MI. HDMI approaches may decrease bias in studies with partially\nobserved confounders where missingness depends on unobserved factors.",
      "tldr_zh": "这篇论文开发了高维多重插补 (HDMI) 方法，用于处理部分观察到的混杂因素，包括使用结构化和自然语言处理 (NLP) 派生的辅助协变量 (AC)。研究通过一个模拟研究，使用阿片类药物与非甾体抗炎药启动者的数据，模拟缺失场景，并采用 LASSO 选择与混杂因素相关的协变量进行多重插补 (MI) 和倾向评分匹配。结果显示，使用 claims data 的 HDMI 表现出最低偏差 (0.072)，而结合 claims 和 sentence embeddings 的方法进一步提高了效率，具有最低的均方根误差 (0.173) 和覆盖率 (94%)；然而，仅使用 NLP 派生的 AC 并不优于基线 MI。总体而言，HDMI 接近可减少在部分观察混杂因素的研究中的偏差，尤其当缺失取决于未观察因素时。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10925v1",
      "published_date": "2024-05-17 17:24:52 UTC",
      "updated_date": "2024-05-17 17:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:13:41.346840"
    },
    {
      "arxiv_id": "2405.10918v2",
      "title": "A Framework for Leveraging Partially-Labeled Data for Product Attribute-Value Identification",
      "title_zh": "利用部分标记数据进行产品属性-值识别的框架",
      "authors": [
        "D. Subhalingam",
        "Keshav Kolluru",
        "Mausam",
        "Saurabh Singal"
      ],
      "abstract": "In the e-commerce domain, the accurate extraction of attribute-value pairs\n(e.g., Brand: Apple) from product titles and user search queries is crucial for\nenhancing search and recommendation systems. A major challenge with neural\nmodels for this task is the lack of high-quality training data, as the\nannotations for attribute-value pairs in the available datasets are often\nincomplete. To address this, we introduce GenToC, a model designed for training\ndirectly with partially-labeled data, eliminating the necessity for a fully\nannotated dataset. GenToC employs a marker-augmented generative model to\nidentify potential attributes, followed by a token classification model that\ndetermines the associated values for each attribute. GenToC outperforms\nexisting state-of-the-art models, exhibiting upto 56.3% increase in the number\nof accurate extractions. Furthermore, we utilize GenToC to regenerate the\ntraining dataset to expand attribute-value annotations. This bootstrapping\nsubstantially improves the data quality for training other standard NER models,\nwhich are typically faster but less capable in handling partially-labeled data,\nenabling them to achieve comparable performance to GenToC. Our results\ndemonstrate GenToC's unique ability to learn from a limited set of\npartially-labeled data and improve the training of more efficient models,\nadvancing the automated extraction of attribute-value pairs. Finally, our model\nhas been successfully integrated into IndiaMART, India's largest B2B e-commerce\nplatform, achieving a significant increase of 20.2% in the number of correctly\nidentified attribute-value pairs over the existing deployed system while\nachieving a high precision of 89.5%.",
      "tldr_zh": "本研究提出GenToC框架，用于从电商产品标题和用户搜索查询中提取属性-值对（如Brand: Apple），以解决训练数据标注不完整的问题。GenToC采用marker-augmented generative model识别潜在属性，随后使用token classification model确定相关值，从而直接利用部分标注数据进行训练。实验结果显示，GenToC比现有模型提高高达56.3%的准确提取数量，并通过重新生成训练数据集（bootstrapping）提升其他标准NER模型的性能，使它们达到可比水平。该框架已在IndiaMART平台部署，正确识别属性-值对增加20.2%，并实现89.5%的精度，显著推进了自动化提取技术。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to KDD 2025 ADS Track",
      "pdf_url": "http://arxiv.org/pdf/2405.10918v2",
      "published_date": "2024-05-17 17:09:45 UTC",
      "updated_date": "2024-11-18 06:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:13:52.336836"
    },
    {
      "arxiv_id": "2405.12241v2",
      "title": "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Braun",
        "Jordan Taylor",
        "Nicholas Goldowsky-Dill",
        "Lee Sharkey"
      ],
      "abstract": "Identifying the features learned by neural networks is a core challenge in\nmechanistic interpretability. Sparse autoencoders (SAEs), which learn a sparse,\novercomplete dictionary that reconstructs a network's internal activations,\nhave been used to identify these features. However, SAEs may learn more about\nthe structure of the datatset than the computational structure of the network.\nThere is therefore only indirect reason to believe that the directions found in\nthese dictionaries are functionally important to the network. We propose\nend-to-end (e2e) sparse dictionary learning, a method for training SAEs that\nensures the features learned are functionally important by minimizing the KL\ndivergence between the output distributions of the original model and the model\nwith SAE activations inserted. Compared to standard SAEs, e2e SAEs offer a\nPareto improvement: They explain more network performance, require fewer total\nfeatures, and require fewer simultaneously active features per datapoint, all\nwith no cost to interpretability. We explore geometric and qualitative\ndifferences between e2e SAE features and standard SAE features. E2e dictionary\nlearning brings us closer to methods that can explain network behavior\nconcisely and accurately. We release our library for training e2e SAEs and\nreproducing our analysis at https://github.com/ApolloResearch/e2e_sae",
      "tldr_zh": "这篇论文针对神经网络机制可解释性的核心挑战，提出了一种端到端 (e2e) 稀疏字典学习方法，用于识别功能重要的特征。\n该方法通过训练稀疏自编码器 (SAEs) 并最小化原模型和插入 SAE 激活的模型之间的 KL divergence，确保学到的特征更能反映网络的计算结构，而非数据集结构。\n结果显示，e2e SAEs 相对于标准 SAEs 提供了 Pareto 改进：解释更多网络性能、需要更少的总特征和同时活跃特征，且不影响可解释性。\n论文还分析了 e2e SAE 特征与标准 SAE 特征的几何和定性差异，并开源了代码库以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.12241v2",
      "published_date": "2024-05-17 17:03:46 UTC",
      "updated_date": "2024-05-24 13:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:14:03.905124"
    },
    {
      "arxiv_id": "2405.11013v1",
      "title": "ARDDQN: Attention Recurrent Double Deep Q-Network for UAV Coverage Path Planning and Data Harvesting",
      "title_zh": "翻译失败",
      "authors": [
        "Praveen Kumar",
        "Priyadarshni",
        "Rajiv Misra"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) have gained popularity in data harvesting\n(DH) and coverage path planning (CPP) to survey a given area efficiently and\ncollect data from aerial perspectives, while data harvesting aims to gather\ninformation from various Internet of Things (IoT) sensor devices, coverage path\nplanning guarantees that every location within the designated area is visited\nwith minimal redundancy and maximum efficiency. We propose the ARDDQN\n(Attention-based Recurrent Double Deep Q Network), which integrates double deep\nQ-networks (DDQN) with recurrent neural networks (RNNs) and an attention\nmechanism to generate path coverage choices that maximize data collection from\nIoT devices and to learn a control scheme for the UAV that generalizes energy\nrestrictions. We employ a structured environment map comprising a compressed\nglobal environment map and a local map showing the UAV agent's locate\nefficiently scaling to large environments. We have compared Long short-term\nmemory (LSTM), Bi-directional long short-term memory (Bi-LSTM), Gated recurrent\nunit (GRU) and Bidirectional gated recurrent unit (Bi-GRU) as recurrent neural\nnetworks (RNN) to the result without RNN We propose integrating the LSTM with\nthe Attention mechanism to the existing DDQN model, which works best on\nevolution parameters, i.e., data collection, landing, and coverage ratios for\nthe CPP and data harvesting scenarios.",
      "tldr_zh": "本研究提出 ARDDQN 模型，即基于 Attention 机制的 Recurrent Double Deep Q-Network，用于无人机 (UAV) 的覆盖路径规划 (CPP) 和数据收集 (DH)，旨在最大化从 Internet of Things (IoT) 设备的数据收集，同时考虑能量限制和环境效率。\nARDDQN 将 Double Deep Q-Network (DDQN) 与 Recurrent Neural Networks (RNNs) 结合，并引入 Attention 机制，使用结构化环境地图（如压缩全局地图和本地地图）来优化路径决策。\n实验比较了不同 RNN 类型，包括 LSTM、Bi-LSTM、GRU 和 Bi-GRU，发现 LSTM 与 Attention 机制整合的 DDQN 在数据收集、着陆和覆盖比率等方面表现出最佳性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11013v1",
      "published_date": "2024-05-17 16:53:19 UTC",
      "updated_date": "2024-05-17 16:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:14:17.461779"
    },
    {
      "arxiv_id": "2405.10893v1",
      "title": "COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitrios P. Panagoulias",
        "Persephone Papatheodosiou",
        "Anastasios P. Palamidas",
        "Mattheos Sanoudos",
        "Evridiki Tsoureli-Nikita",
        "Maria Virvou",
        "George A. Tsihrintzis"
      ],
      "abstract": "Large Language Models (LLMs) constitute a breakthrough state-of-the-art\nArtificial Intelligence (AI) technology which is rapidly evolving and promises\nto aid in medical diagnosis either by assisting doctors or by simulating a\ndoctor's workflow in more advanced and complex implementations. In this\ntechnical paper, we outline Cognitive Network Evaluation Toolkit for Medical\nDomains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in\nthe medical domain. Specifically, we propose a scoring-framework with increased\ndifficulty to assess the ability of LLMs in interpreting medical text. The\nproposed framework is accompanied with a database of Multiple Choice Quizzes\n(MCQs). To ensure alignment with current medical trends and enhance safety,\nusefulness, and applicability, these MCQs have been constructed in\ncollaboration with several associated medical experts in various medical\ndomains and are characterized by varying degrees of difficulty. The current\n(first) version of the database includes the medical domains of Psychiatry,\nDentistry, Pulmonology, Dermatology and Endocrinology, but it will be\ncontinuously extended and expanded to include additional medical domains.",
      "tldr_zh": "这篇论文介绍了COGNET-MD，这是一个用于评估Large Language Models (LLMs)在医疗领域的基准测试框架和数据集。框架包括一个难度递增的评分系统，以评估LLMs解释医疗文本的能力，并附带一个由医疗专家协作构建的Multiple Choice Quizzes (MCQs)数据库。当前版本的数据库覆盖Psychiatry、Dentistry、Pulmonology、Dermatology和Endocrinology等领域，具有不同难度水平，并计划持续扩展以包含更多医疗领域。该框架旨在提升LLMs在医疗诊断中的安全性和实用性，支持医生辅助或模拟工作流程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Paper",
      "pdf_url": "http://arxiv.org/pdf/2405.10893v1",
      "published_date": "2024-05-17 16:31:56 UTC",
      "updated_date": "2024-05-17 16:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:14:31.321161"
    },
    {
      "arxiv_id": "2405.10890v1",
      "title": "A Versatile Framework for Analyzing Galaxy Image Data by Implanting Human-in-the-loop on a Large Vision Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mingxiang Fu",
        "Yu Song",
        "Jiameng Lv",
        "Liang Cao",
        "Peng Jia",
        "Nan Li",
        "Xiangru Li",
        "Jifeng Liu",
        "A-Li Luo",
        "Bo Qiu",
        "Shiyin Shen",
        "Liangping Tu",
        "Lili Wang",
        "Shoulin Wei",
        "Haifeng Yang",
        "Zhenping Yi",
        "Zhiqiang Zou"
      ],
      "abstract": "The exponential growth of astronomical datasets provides an unprecedented\nopportunity for humans to gain insight into the Universe. However, effectively\nanalyzing this vast amount of data poses a significant challenge. Astronomers\nare turning to deep learning techniques to address this, but the methods are\nlimited by their specific training sets, leading to considerable duplicate\nworkloads too. Hence, as an example to present how to overcome the issue, we\nbuilt a framework for general analysis of galaxy images, based on a large\nvision model (LVM) plus downstream tasks (DST), including galaxy morphological\nclassification, image restoration, object detection, parameter extraction, and\nmore. Considering the low signal-to-noise ratio of galaxy images and the\nimbalanced distribution of galaxy categories, we have incorporated a\nHuman-in-the-loop (HITL) module into our large vision model, which leverages\nhuman knowledge to enhance the reliability and interpretability of processing\ngalaxy images interactively. The proposed framework exhibits notable few-shot\nlearning capabilities and versatile adaptability to all the abovementioned\ntasks on galaxy images in the DESI legacy imaging surveys. Expressly, for\nobject detection, trained by 1000 data points, our DST upon the LVM achieves an\naccuracy of 96.7%, while ResNet50 plus Mask R-CNN gives an accuracy of 93.1%;\nfor morphology classification, to obtain AUC ~0.9, LVM plus DST and HITL only\nrequests 1/50 training sets compared to ResNet18. Expectedly, multimodal data\ncan be integrated similarly, which opens up possibilities for conducting joint\nanalyses with datasets spanning diverse domains in the era of multi-message\nastronomy.",
      "tldr_zh": "这篇论文提出了一种通用的银河图像分析框架，基于大型视觉模型 (LVM) 和下游任务 (DST)，包括形态分类、图像修复、物体检测和参数提取，以应对天文数据爆炸式增长的挑战。框架融入 Human-in-the-loop (HITL) 模块，利用人类知识提升处理银河图像的可靠性和可解释性，尤其针对低信噪比和类别不平衡问题。实验结果显示，该框架在 DESI 遗留成像调查中表现出色的少样本学习能力，例如在物体检测任务上训练 1000 数据点即可达到 96.7% 准确率，优于 ResNet50 加 Mask R-CNN 的 93.1%；而在形态分类上，仅需传统模型的 1/50 训练集即可获得 AUC ~0.9。该框架还支持多模态数据整合，促进跨领域天文联合分析。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.GA",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "26 pages, 10 figures, to be published on Chinese Physics C",
      "pdf_url": "http://arxiv.org/pdf/2405.10890v1",
      "published_date": "2024-05-17 16:29:27 UTC",
      "updated_date": "2024-05-17 16:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:14:44.878862"
    },
    {
      "arxiv_id": "2405.10883v2",
      "title": "Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: A Systematic Scoping Review",
      "title_zh": "人工智能在精神分裂症康复管理中的应用：一项系统范围综述",
      "authors": [
        "Hongyi Yang",
        "Fangyuan Chang",
        "Dian Zhu",
        "Muroi Fumie",
        "Zhao Liu"
      ],
      "abstract": "This systematic review assessed the current state and future prospects of\nartificial intelligence (AI) in schizophrenia rehabilitation management. We\nreviewed 61 studies on AI-related data types, feature engineering methods,\nalgorithmic models, and evaluation metrics published from 2012-2024. The review\ncategorizes AI applications into the following key application areas: symptom\nmonitoring, medication management, risk management, functional training, and\npsychosocial support. Findings indicate that supervised machine learning\ntechniques, particularly for symptom monitoring and relapse risk management,\nremain the predominant approaches, effectively leveraging structured data while\nincorporating interpretable algorithms. This study underscores the potential of\nAI in transforming long-term management strategies for schizophrenia, offering\nvaluable insights into improving the quality of life of patients. Future\nresearch should focus on expanding data sources through multimodal data\nintegration, exploring deep learning models, and integrating AI-driven\ninterventions into training tasks to fully capitalize on AI's potential in\nschizophrenia rehabilitation.",
      "tldr_zh": "这篇系统综述评估了人工智能（AI）在精神分裂症康复管理中的应用现状和前景，回顾了2012-2024年间61篇相关研究，包括数据类型、特征工程方法、算法模型和评估指标。研究将AI应用分类为症状监测、药物管理、风险管理、功能训练和心理社会支持领域，其中监督机器学习技术是主要方法，尤其在症状监测和复发风险管理中，利用结构化数据和可解释算法来提升效果。总体发现显示，AI有潜力转变精神分裂症的长期管理策略，提高患者生活质量；未来研究应强调多模态数据整合、深度学习模型的探索，以及将AI驱动干预融入训练任务中。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10883v2",
      "published_date": "2024-05-17 16:20:34 UTC",
      "updated_date": "2025-01-25 05:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:14:54.686693"
    },
    {
      "arxiv_id": "2405.10877v1",
      "title": "WEITS: A Wavelet-enhanced residual framework for interpretable time series forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyou Guo",
        "Yan Sun",
        "Tieru Wu"
      ],
      "abstract": "Time series (TS) forecasting has been an unprecedentedly popular problem in\nrecent years, with ubiquitous applications in both scientific and business\nfields. Various approaches have been introduced to time series analysis,\nincluding both statistical approaches and deep neural networks. Although neural\nnetwork approaches have illustrated stronger ability of representation than\nstatistical methods, they struggle to provide sufficient interpretablility, and\ncan be too complicated to optimize. In this paper, we present WEITS, a\nfrequency-aware deep learning framework that is highly interpretable and\ncomputationally efficient. Through multi-level wavelet decomposition, WEITS\nnovelly infuses frequency analysis into a highly deep learning framework.\nCombined with a forward-backward residual architecture, it enjoys both high\nrepresentation capability and statistical interpretability. Extensive\nexperiments on real-world datasets have demonstrated competitive performance of\nour model, along with its additional advantage of high computation efficiency.\nFurthermore, WEITS provides a general framework that can always seamlessly\nintegrate with state-of-the-art approaches for time series forecast.",
      "tldr_zh": "本文提出 WEITS，一种基于小波增强（wavelet-enhanced）的残差框架，用于提升时间序列（TS）预测的可解释性和计算效率。WEITS 通过多级 wavelet decomposition 将频率分析融入深度学习框架，并结合 forward-backward residual architecture，实现高表示能力和统计可解释性。实验结果显示，该框架在真实数据集上表现出色，性能优于基线模型，且提供通用性以无缝整合现有先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2310.09488 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2405.10877v1",
      "published_date": "2024-05-17 16:09:51 UTC",
      "updated_date": "2024-05-17 16:09:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:15:06.162866"
    },
    {
      "arxiv_id": "2405.10861v2",
      "title": "Tailoring Vaccine Messaging with Common-Ground Opinions",
      "title_zh": "基于共同基础意见定制疫苗信息",
      "authors": [
        "Rickard Stureborg",
        "Sanxing Chen",
        "Ruoyu Xie",
        "Aayushi Patel",
        "Christopher Li",
        "Chloe Qinyu Zhu",
        "Tingnan Hu",
        "Jun Yang",
        "Bhuwan Dhingra"
      ],
      "abstract": "One way to personalize chatbot interactions is by establishing common ground\nwith the intended reader. A domain where establishing mutual understanding\ncould be particularly impactful is vaccine concerns and misinformation. Vaccine\ninterventions are forms of messaging which aim to answer concerns expressed\nabout vaccination. Tailoring responses in this domain is difficult, since\nopinions often have seemingly little ideological overlap. We define the task of\ntailoring vaccine interventions to a Common-Ground Opinion (CGO). Tailoring\nresponses to a CGO involves meaningfully improving the answer by relating it to\nan opinion or belief the reader holds. In this paper we introduce TAILOR-CGO, a\ndataset for evaluating how well responses are tailored to provided CGOs. We\nbenchmark several major LLMs on this task; finding GPT-4-Turbo performs\nsignificantly better than others. We also build automatic evaluation metrics,\nincluding an efficient and accurate BERT model that outperforms finetuned LLMs,\ninvestigate how to successfully tailor vaccine messaging to CGOs, and provide\nactionable recommendations from this investigation.\n  Code and model weights: https://github.com/rickardstureborg/tailor-cgo\nDataset: https://huggingface.co/datasets/DukeNLP/tailor-cgo",
      "tldr_zh": "本研究探讨了如何通过 Common-Ground Opinion (CGO) 建立共同基础来个性化疫苗信息干预，以应对疫苗担忧和错误信息。该论文引入了 TAILOR-CGO 数据集，用于评估响应是否成功针对 CGO 进行定制，并基准测试了多个大型语言模型 (LLMs)，其中 GPT-4-Turbo 表现出色。研究还开发了自动评估指标，包括一个高效的 BERT 模型，其性能超过了微调的 LLMs，并基于调查结果提供了可操作的疫苗信息定制建议。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "68T50 (Primary) 68T01, 68T37, 91F20 (Secondary)",
        "I.2; I.2.7; I.7"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10861v2",
      "published_date": "2024-05-17 15:48:30 UTC",
      "updated_date": "2024-07-24 00:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:15:18.973698"
    },
    {
      "arxiv_id": "2405.13041v3",
      "title": "Assessing Political Bias in Large Language Models",
      "title_zh": "评估大语言模型中的政治偏见",
      "authors": [
        "Luca Rettenberger",
        "Markus Reischl",
        "Mark Schutera"
      ],
      "abstract": "The assessment of bias within Large Language Models (LLMs) has emerged as a\ncritical concern in the contemporary discourse surrounding Artificial\nIntelligence (AI) in the context of their potential impact on societal\ndynamics. Recognizing and considering political bias within LLM applications is\nespecially important when closing in on the tipping point toward performative\nprediction. Then, being educated about potential effects and the societal\nbehavior LLMs can drive at scale due to their interplay with human operators.\nIn this way, the upcoming elections of the European Parliament will not remain\nunaffected by LLMs. We evaluate the political bias of the currently most\npopular open-source LLMs (instruct or assistant models) concerning political\nissues within the European Union (EU) from a German voter's perspective. To do\nso, we use the \"Wahl-O-Mat,\" a voting advice application used in Germany. From\nthe voting advice of the \"Wahl-O-Mat\" we quantize the degree of alignment of\nLLMs with German political parties. We show that larger models, such as\nLlama3-70B, tend to align more closely with left-leaning political parties,\nwhile smaller models often remain neutral, particularly when prompted in\nEnglish. The central finding is that LLMs are similarly biased, with low\nvariances in the alignment concerning a specific party. Our findings underline\nthe importance of rigorously assessing and making bias transparent in LLMs to\nsafeguard the integrity and trustworthiness of applications that employ the\ncapabilities of performative prediction and the invisible hand of machine\nlearning prediction and language generation.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 中的政治偏见，特别关注其对社会动态的影响，并以德国选民视角考察开源 LLMs 在欧盟政治议题上的表现。研究者使用 Wahl-O-Mat 投票建议工具量化 LLMs 与德国政党的对齐度，发现较大模型如 Llama3-70B 更倾向于左倾政党，而较小模型在英语提示下往往保持中立，且不同 LLMs 的偏见相似，差异较小。这些发现强调了严格评估和透明化 LLMs 中的偏见，以保障其在可执行预测应用中的完整性和可信度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13041v3",
      "published_date": "2024-05-17 15:30:18 UTC",
      "updated_date": "2024-06-05 05:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:15:30.383400"
    },
    {
      "arxiv_id": "2405.10853v3",
      "title": "The Future of Large Language Model Pre-training is Federated",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Sani",
        "Alex Iacob",
        "Zeyu Cao",
        "Bill Marino",
        "Yan Gao",
        "Tomas Paulik",
        "Wanru Zhao",
        "William F. Shen",
        "Preslav Aleksandrov",
        "Xinchi Qiu",
        "Nicholas D. Lane"
      ],
      "abstract": "Generative pre-trained large language models (LLMs) have demonstrated\nimpressive performance over a wide range of tasks, thanks to the unprecedented\namount of data they have been trained on. As established scaling laws indicate,\nLLMs' future performance improvement depends on the amount of computing and\ndata sources they can leverage for pre-training. Federated learning (FL) has\nthe potential to unleash the majority of the planet's data and computational\nresources, which are underutilized by the data-center-focused training\nmethodology of current LLM practice. Our work presents a robust, flexible,\nreproducible FL approach that enables large-scale collaboration across\ninstitutions to train LLMs. We propose a scalable deployment system called\nPhoton to enable the investigation and development of this new training\nparadigm for LLM pre-training. We show that Photon can be used by organizations\ninterested in collaborating with their private data sources and computational\nresources for pre-training LLMs with billions of parameters. This paradigm\nwould mobilize more computational and data resources while matching or\npotentially exceeding centralized performance. We further show the\neffectiveness of the federated training scales with model size and present our\napproach for training billion-scale federated LLMs using limited resources.\nThus far, we have used Photon to train LLM models to the size of 7B parameters\nand anticipate larger models being completed in the near future. Finally, we\nshow that LLM training is highly resilient to the classical challenges of\nfederated statistical and hardware heterogeneity. Furthermore, we show that\nconvergence is robust to partial participation, opening the avenue for\ncompute-efficient collaborative training. Photon will help data-rich actors to\nbecome the protagonists of LLMs pre-training instead of leaving the stage to\ncompute-rich actors alone.",
      "tldr_zh": "该论文主张，联邦学习（Federated Learning, FL）是大型语言模型（Large Language Models, LLMs）预训练的未来方向，因为它能利用全球未充分利用的数据和计算资源来提升模型性能。作者提出了一种可扩展的部署系统Photon，支持机构间协作，使用私有数据和计算资源训练数十亿参数的LLMs，并在性能上与集中式训练相当或更优。实验结果显示，这种方法对联邦统计异质性和硬件异质性高度鲁棒，且允许部分参与，实现高效协作训练，从而使数据丰富的参与者能主导LLMs预训练，而非仅依赖计算资源丰富的实体。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 15 figures, pre-print",
      "pdf_url": "http://arxiv.org/pdf/2405.10853v3",
      "published_date": "2024-05-17 15:27:52 UTC",
      "updated_date": "2024-10-14 16:37:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:15:41.754648"
    },
    {
      "arxiv_id": "2405.10852v2",
      "title": "KernelSHAP-IQ: Weighted Least-Square Optimization for Shapley Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Fumagalli",
        "Maximilian Muschalik",
        "Patrick Kolpaczki",
        "Eyke Hüllermeier",
        "Barbara Hammer"
      ],
      "abstract": "The Shapley value (SV) is a prevalent approach of allocating credit to\nmachine learning (ML) entities to understand black box ML models. Enriching\nsuch interpretations with higher-order interactions is inevitable for complex\nsystems, where the Shapley Interaction Index (SII) is a direct axiomatic\nextension of the SV. While it is well-known that the SV yields an optimal\napproximation of any game via a weighted least square (WLS) objective, an\nextension of this result to SII has been a long-standing open problem, which\neven led to the proposal of an alternative index. In this work, we characterize\nhigher-order SII as a solution to a WLS problem, which constructs an optimal\napproximation via SII and $k$-Shapley values ($k$-SII). We prove this\nrepresentation for the SV and pairwise SII and give empirically validated\nconjectures for higher orders. As a result, we propose KernelSHAP-IQ, a direct\nextension of KernelSHAP for SII, and demonstrate state-of-the-art performance\nfor feature interactions.",
      "tldr_zh": "本研究解决了 Shapley 值 (SV) 在解释黑箱机器学习模型时的扩展问题，提出将 Shapley Interaction Index (SII) 表示为加权最小二乘 (WLS) 优化问题的解决方案，从而构建 SII 和 k-Shapley 值 (k-SII) 的最优近似。作者证明了这一表示适用于 SV 和 pairwise SII，并通过经验验证为更高阶交互提供了猜想。基于此，他们开发了 KernelSHAP-IQ，一种直接扩展 KernelSHAP 的方法，并在特征交互任务上实现了 state-of-the-art 性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published Paper at ICML 2024:\n  https://openreview.net/forum?id=d5jXW2H4gg",
      "pdf_url": "http://arxiv.org/pdf/2405.10852v2",
      "published_date": "2024-05-17 15:27:35 UTC",
      "updated_date": "2024-07-16 07:03:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:15:55.427803"
    },
    {
      "arxiv_id": "2405.11011v1",
      "title": "Uncertainty Distribution Assessment of Jiles-Atherton Parameter Estimation for Inrush Current Studies",
      "title_zh": "Jiles-Atherton 参数估计的不确定性分布评估，用于涌流电流研究",
      "authors": [
        "Jone Ugarte-Valdivielso",
        "Jose I. Aizpurua",
        "Manex Barrenetxea-Iñarra"
      ],
      "abstract": "Transformers are one of the key assets in AC distribution grids and renewable\npower integration. During transformer energization inrush currents appear,\nwhich lead to transformer degradation and can cause grid instability events.\nThese inrush currents are a consequence of the transformer's magnetic core\nsaturation during its connection to the grid. Transformer cores are normally\nmodelled by the Jiles-Atherton (JA) model which contains five parameters. These\nparameters can be estimated by metaheuristic-based search algorithms. The\nparameter initialization of these algorithms plays an important role in the\nalgorithm convergence. The most popular strategy used for JA parameter\ninitialization is a random uniform distribution. However, techniques such as\nparameter initialization by Probability Density Functions (PDFs) have shown to\nimprove accuracy over random methods. In this context, this research work\npresents a framework to assess the impact of different parameter initialization\nstrategies on the performance of the JA parameter estimation for inrush current\nstudies. Depending on available data and expert knowledge, uncertainty levels\nare modelled with different PDFs. Moreover, three different\nmetaheuristic-search algorithms are employed on two different core materials\nand their accuracy and computational time are compared. Results show an\nimprovement in the accuracy and computational time of the metaheuristic-based\nalgorithms when PDF parameter initialization is used.",
      "tldr_zh": "本研究评估了不同参数初始化策略对 Jiles-Atherton (JA) 模型参数估计的影响，旨在优化变压器涌流 (inrush currents) 研究。研究提出一个框架，使用 Probability Density Functions (PDFs) 基于可用数据和专家知识建模不确定性，并与随机均匀分布方法进行比较。实验中，应用三种元启发式搜索算法于两种磁芯材料，结果显示 PDF 初始化策略显著提高了算法的准确性和计算时间效率。总体而言，此框架为改进变压器建模和电网稳定性提供了实用见解。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "11 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.11011v1",
      "published_date": "2024-05-17 15:20:26 UTC",
      "updated_date": "2024-05-17 15:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:16:07.741549"
    },
    {
      "arxiv_id": "2407.12143v1",
      "title": "False consensus biases AI against vulnerable stakeholders",
      "title_zh": "翻译失败",
      "authors": [
        "Mengchen Dong",
        "Jean-François Bonnefon",
        "Iyad Rahwan"
      ],
      "abstract": "The deployment of AI systems for welfare benefit allocation allows for\naccelerated decision-making and faster provision of critical help, but has\nalready led to an increase in unfair benefit denials and false fraud\naccusations. Collecting data in the US and the UK (N = 2449), we explore the\npublic acceptability of such speed-accuracy trade-offs in populations of\nclaimants and non-claimants. We observe a general willingness to trade off\nspeed gains for modest accuracy losses, but this aggregate view masks notable\ndivergences between claimants and non-claimants. Although welfare claimants\ncomprise a relatively small proportion of the general population (e.g., 20% in\nthe US representative sample), this vulnerable group is much less willing to\naccept AI deployed in welfare systems, raising concerns that solely using\naggregate data for calibration could lead to policies misaligned with\nstakeholder preferences. Our study further uncovers asymmetric insights between\nclaimants and non-claimants. The latter consistently overestimate claimant\nwillingness to accept speed-accuracy trade-offs, even when financially\nincentivized for accurate perspective-taking. This suggests that policy\ndecisions influenced by the dominant voice of non-claimants, however\nwell-intentioned, may neglect the actual preferences of those directly affected\nby welfare AI systems. Our findings underline the need for stakeholder\nengagement and transparent communication in the design and deployment of these\nsystems, particularly in contexts marked by power imbalances.",
      "tldr_zh": "这篇论文探讨了“False consensus biases”如何导致 AI 系统在福利福利分配中对弱势利益相关者（如福利申请者）不利，通过在美国和英国收集的2449份数据调查申请者和非申请者对速度与准确性权衡的接受度。研究发现，虽然总体上人们愿意接受适度准确性损失换取更快决策，但申请者更不愿意支持 AI 在福利系统中的应用，而非申请者往往高估了申请者的接受意愿。结果表明，依赖总体数据进行政策校准可能忽略弱势群体的真实偏好，并建议在 AI 设计和部署中加强利益相关者参与以及透明沟通，以缓解权力不平衡问题。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12143v1",
      "published_date": "2024-05-17 14:33:47 UTC",
      "updated_date": "2024-05-17 14:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:16:19.423289"
    },
    {
      "arxiv_id": "2405.10768v2",
      "title": "What should be observed for optimal reward in POMDPs?",
      "title_zh": "在 POMDPs 中，应该观察什么以获得最优奖励？",
      "authors": [
        "Alyzia-Maria Konsta",
        "Alberto Lluch Lafuente",
        "Christoph Matheja"
      ],
      "abstract": "Partially observable Markov Decision Processes (POMDPs) are a standard model\nfor agents making decisions in uncertain environments. Most work on POMDPs\nfocuses on synthesizing strategies based on the available capabilities.\nHowever, system designers can often control an agent's observation\ncapabilities, e.g. by placing or selecting sensors. This raises the question of\nhow one should select an agent's sensors cost-effectively such that it achieves\nthe desired goals. In this paper, we study the novel optimal observability\nproblem OOP: Given a POMDP M, how should one change M's observation\ncapabilities within a fixed budget such that its (minimal) expected reward\nremains below a given threshold? We show that the problem is undecidable in\ngeneral and decidable when considering positional strategies only. We present\ntwo algorithms for a decidable fragment of the OOP: one based on optimal\nstrategies of M's underlying Markov decision process and one based on parameter\nsynthesis with SMT. We report promising results for variants of typical\nexamples from the POMDP literature.",
      "tldr_zh": "这篇论文探讨了在部分可观察Markov决策过程(POMDPs)中，如何在固定预算内优化代理的观察能力，以使预期奖励保持在给定阈值以下，从而定义了新的Optimal Observability Problem (OOP)。作者证明了OOP在一般情况下不可判定，但在仅考虑位置策略时可判定，并提出了两个算法：一个基于POMDPs底层Markov Decision Process的最优策略，另一个基于SMT参数合成。实验结果显示，这些算法在POMDP文献典型例子变体上表现出色，为系统设计师选择传感器提供了实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10768v2",
      "published_date": "2024-05-17 13:27:57 UTC",
      "updated_date": "2024-07-11 08:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:16:33.317740"
    },
    {
      "arxiv_id": "2405.10767v1",
      "title": "Evaluating Saliency Explanations in NLP by Crowdsourcing",
      "title_zh": "通过众包评估 NLP 中的显著性解释",
      "authors": [
        "Xiaotian Lu",
        "Jiyi Li",
        "Zhen Wan",
        "Xiaofeng Lin",
        "Koh Takeuchi",
        "Hisashi Kashima"
      ],
      "abstract": "Deep learning models have performed well on many NLP tasks. However, their\ninternal mechanisms are typically difficult for humans to understand. The\ndevelopment of methods to explain models has become a key issue in the\nreliability of deep learning models in many important applications. Various\nsaliency explanation methods, which give each feature of input a score\nproportional to the contribution of output, have been proposed to determine the\npart of the input which a model values most. Despite a considerable body of\nwork on the evaluation of saliency methods, whether the results of various\nevaluation metrics agree with human cognition remains an open question. In this\nstudy, we propose a new human-based method to evaluate saliency methods in NLP\nby crowdsourcing. We recruited 800 crowd workers and empirically evaluated\nseven saliency methods on two datasets with the proposed method. We analyzed\nthe performance of saliency methods, compared our results with existing\nautomated evaluation methods, and identified notable differences between NLP\nand computer vision (CV) fields when using saliency methods. The instance-level\ndata of our crowdsourced experiments and the code to reproduce the explanations\nare available at https://github.com/xtlu/lreccoling_evaluation.",
      "tldr_zh": "本研究探讨了 NLP 中 saliency explanations 方法的评估问题，提出了一种基于 crowdsourcing 的新型人类评估方法，以检验这些方法是否符合人类认知。研究招募了 800 名众包工作者，在两个数据集上评估了七种 saliency methods，并将结果与现有自动评估方法进行比较。结果显示，NLP 领域在 saliency methods 的表现与计算机视觉 (CV) 领域存在显著差异，该框架为模型解释的可靠性提供了新见解，并公开了实验数据和代码以供复现。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "13 pages, 4 figures, Accepted for LREC-Coling 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2405.10767v1",
      "published_date": "2024-05-17 13:27:45 UTC",
      "updated_date": "2024-05-17 13:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:16:44.775166"
    },
    {
      "arxiv_id": "2405.10762v2",
      "title": "Research on Credit Risk Early Warning Model of Commercial Banks Based on Neural Network Algorithm",
      "title_zh": "基于神经网络算法的商业银行信贷风险预警模型研究",
      "authors": [
        "Yu Cheng",
        "Qin Yang",
        "Liyang Wang",
        "Ao Xiang",
        "Jingyu Zhang"
      ],
      "abstract": "In the realm of globalized financial markets, commercial banks are confronted\nwith an escalating magnitude of credit risk, thereby imposing heightened\nrequisites upon the security of bank assets and financial stability. This study\nharnesses advanced neural network techniques, notably the Backpropagation (BP)\nneural network, to pioneer a novel model for preempting credit risk in\ncommercial banks. The discourse initially scrutinizes conventional financial\nrisk preemptive models, such as ARMA, ARCH, and Logistic regression models,\ncritically analyzing their real-world applications. Subsequently, the\nexposition elaborates on the construction process of the BP neural network\nmodel, encompassing network architecture design, activation function selection,\nparameter initialization, and objective function construction. Through\ncomparative analysis, the superiority of neural network models in preempting\ncredit risk in commercial banks is elucidated. The experimental segment selects\nspecific bank data, validating the model's predictive accuracy and\npracticality. Research findings evince that this model efficaciously enhances\nthe foresight and precision of credit risk management.",
      "tldr_zh": "这篇论文提出了一种基于 Backpropagation (BP) neural network 算法的商业银行信用风险预警模型，以应对全球金融市场中日益增加的信用风险。研究首先分析了传统模型如 ARMA、ARCH 和 Logistic regression 的局限性，并详细阐述了 BP 神经网络的构建过程，包括网络架构设计、激活函数选择、参数初始化和目标函数构建。通过实验使用特定银行数据验证，该模型在预测准确性和实用性上显著优于传统方法，有效提升了信用风险管理的预见性和精度。",
      "categories": [
        "q-fin.RM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.RM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10762v2",
      "published_date": "2024-05-17 13:18:46 UTC",
      "updated_date": "2024-05-30 08:13:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:16:56.553951"
    },
    {
      "arxiv_id": "2405.10746v2",
      "title": "Causality in the Can: Diet Coke's Impact on Fatness",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Qi",
        "Ang Li"
      ],
      "abstract": "Artificially sweetened beverages like Diet Coke are often considered better\nalternatives to sugary drinks, but the debate over their impact on health,\nparticularly in relation to obesity, continues. Previous research has\npredominantly used association-based methods with observational or Randomized\nControlled Trial (RCT) data, which may not accurately capture the causal\nrelationship between Diet Coke consumption and obesity, leading to potentially\nlimited conclusions. In contrast, we employed causal inference methods using\nstructural causal models, integrating both observational and RCT data.\nSpecifically, we utilized data from the National Health and Nutrition\nExamination Survey (NHANES), which includes diverse demographic information, as\nour observational data source. This data was then used to construct a causal\ngraph, and the back-door criterion, along with its adjustment formula, was\napplied to estimate the RCT data. We then calculated the counterfactual\nquantity, the Probability of Necessity and Sufficiency (PNS), using both NHANES\ndata and estimated RCT data. We propose that PNS is the essential metric for\nassessing the impact of Diet Coke on obesity. Our results indicate that between\n20 to 50 percent of individuals, especially those with poor dietary habits, are\nmore likely to gain weight from Diet Coke. Conversely, in groups like young\nfemales with healthier diets, only a small proportion experience weight gain\ndue to Diet Coke. These findings highlight the influence of individual\nlifestyle and potential hormonal factors on the varied effects of Diet Coke,\nproviding a new framework for understanding its nutritional impacts on public\nhealth.",
      "tldr_zh": "本文使用结构因果模型（structural causal models）整合观察数据（如 NHANES）和 Randomized Controlled Trial (RCT) 数据，评估 Diet Coke 对肥胖的因果关系，克服了以往关联方法（association-based methods）的局限性。研究通过构建因果图并应用后门准则（back-door criterion）计算反事实量 Probability of Necessity and Sufficiency (PNS)，发现 20% 到 50% 的个体，尤其是饮食习惯差的人，更可能因 Diet Coke 导致体重增加，而在健康饮食群体如年轻女性中，仅有小部分人受影响。这些发现突出了个体生活方式和激素因素的作用，为评估人工甜味饮料对公共健康的影响提供了新框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10746v2",
      "published_date": "2024-05-17 12:49:45 UTC",
      "updated_date": "2024-08-18 10:34:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:17:11.032314"
    },
    {
      "arxiv_id": "2405.10745v1",
      "title": "Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Albert Sawczyn",
        "Jakub Binkowski",
        "Piotr Bielak",
        "Tomasz Kajdanowicz"
      ],
      "abstract": "Knowledge-intensive tasks pose a significant challenge for Machine Learning\n(ML) techniques. Commonly adopted methods, such as Large Language Models\n(LLMs), often exhibit limitations when applied to such tasks. Nevertheless,\nthere have been notable endeavours to mitigate these challenges, with a\nsignificant emphasis on augmenting LLMs through Knowledge Graphs (KGs). While\nKGs provide many advantages for representing knowledge, their development costs\ncan deter extensive research and applications. Addressing this limitation, we\nintroduce a framework for enriching embeddings of small-scale domain-specific\nKnowledge Graphs with well-established general-purpose KGs. Adopting our\nmethod, a modest domain-specific KG can benefit from a performance boost in\ndownstream tasks when linked to a substantial general-purpose KG. Experimental\nevaluations demonstrate a notable enhancement, with up to a 44% increase\nobserved in the Hits@10 metric. This relatively unexplored research direction\ncan catalyze more frequent incorporation of KGs in knowledge-intensive tasks,\nresulting in more robust, reliable ML implementations, which hallucinates less\nthan prevalent LLM solutions.\n  Keywords: knowledge graph, knowledge graph completion, entity alignment,\nrepresentation learning, machine learning",
      "tldr_zh": "该论文针对知识密集型任务中大语言模型（LLMs）的局限性，提出一个框架，用于通过通用知识图谱（general-purpose KGs）丰富小规模领域特定知识图谱（small-scale domain-specific KGs）的嵌入。框架的核心策略是将小规模 KG 与大型通用 KG 链接，从而提升下游任务的性能。实验评估显示，该方法使 Hits@10 指标提高多达 44%，促进了 KG 在知识密集型任务中的应用，使机器学习实现更稳健可靠，并减少幻觉现象。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10745v1",
      "published_date": "2024-05-17 12:46:23 UTC",
      "updated_date": "2024-05-17 12:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:17:20.863162"
    },
    {
      "arxiv_id": "2405.10739v2",
      "title": "Efficient Multimodal Large Language Models: A Survey",
      "title_zh": "高效多模态大语言模型：综述",
      "authors": [
        "Yizhang Jin",
        "Jian Li",
        "Yexin Liu",
        "Tianjun Gu",
        "Kai Wu",
        "Zhengkai Jiang",
        "Muyang He",
        "Bo Zhao",
        "Xin Tan",
        "Zhenye Gan",
        "Yabiao Wang",
        "Chengjie Wang",
        "Lizhuang Ma"
      ],
      "abstract": "In the past year, Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable performance in tasks such as visual question answering, visual\nunderstanding and reasoning. However, the extensive model size and high\ntraining and inference costs have hindered the widespread application of MLLMs\nin academia and industry. Thus, studying efficient and lightweight MLLMs has\nenormous potential, especially in edge computing scenarios. In this survey, we\nprovide a comprehensive and systematic review of the current state of efficient\nMLLMs. Specifically, we summarize the timeline of representative efficient\nMLLMs, research state of efficient structures and strategies, and the\napplications. Finally, we discuss the limitations of current efficient MLLM\nresearch and promising future directions. Please refer to our GitHub repository\nfor more details:\nhttps://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.",
      "tldr_zh": "这篇调查论文回顾了Multimodal Large Language Models (MLLMs)在过去一年的发展，焦点在于高效和轻量化的模型，以解决其庞大尺寸和高训练推理成本问题。论文总结了代表性MLLMs的时间线、结构优化策略（如高效架构和算法）、以及在边缘计算等应用场景中的潜力。最终，研究讨论了当前高效MLLMs的局限性，并指出了未来研究方向，包括更多实际部署的可能性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10739v2",
      "published_date": "2024-05-17 12:37:10 UTC",
      "updated_date": "2024-08-09 09:28:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:17:30.911896"
    },
    {
      "arxiv_id": "2407.09977v1",
      "title": "Mitigating Interpretation Bias in Rock Records with Large Language Models: Insights from Paleoenvironmental Analysis",
      "title_zh": "利用大型",
      "authors": [
        "Luoqi Wang",
        "Haipeng Li",
        "Linshu Hu",
        "Jiarui Cai",
        "Zhenhong Du"
      ],
      "abstract": "The reconstruction of Earth's history faces significant challenges due to the\nnonunique interpretations often derived from rock records. The problem has long\nbeen recognized but there are no systematic solutions in practice. This study\nintroduces an innovative approach that leverages Large Language Models (LLMs)\nalong with retrieval augmented generation and real-time search capabilities to\ncounteract interpretation biases, thereby enhancing the accuracy and\nreliability of geological analyses. By applying this framework to sedimentology\nand paleogeography, we demonstrate its effectiveness in mitigating\ninterpretations biases through the generation and evaluation of multiple\nhypotheses for the same data, which can effectively reduce human bias. Our\nresearch illuminates the transformative potential of LLMs in refining\npaleoenvironmental studies and extends their applicability across various\nsub-disciplines of Earth sciences, enabling a deeper and more accurate\ndepiction of Earth's evolution.",
      "tldr_zh": "本研究针对岩石记录解释的非唯一性和偏差问题，提出了一种创新方法，利用 Large Language Models (LLMs) 结合检索增强生成（retrieval augmented generation）和实时搜索能力，提高地质分析的准确性和可靠性。通过在沉积学和古地理学领域的应用，该框架生成并评估多个假设，有效减少人类偏差。研究结果显示，此方法能显著提升古环境研究的精确性，并扩展到地球科学的其他子学科，提供更深入的地球演化描绘。",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09977v1",
      "published_date": "2024-05-17 12:23:19 UTC",
      "updated_date": "2024-05-17 12:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:17:43.569671"
    },
    {
      "arxiv_id": "2405.10729v2",
      "title": "Contestable AI needs Computational Argumentation",
      "title_zh": "可争议 AI 需要计算论证",
      "authors": [
        "Francesco Leofante",
        "Hamed Ayoobi",
        "Adam Dejl",
        "Gabriel Freedman",
        "Deniz Gorur",
        "Junqi Jiang",
        "Guilherme Paulino-Passos",
        "Antonio Rago",
        "Anna Rapberger",
        "Fabrizio Russo",
        "Xiang Yin",
        "Dekai Zhang",
        "Francesca Toni"
      ],
      "abstract": "AI has become pervasive in recent years, but state-of-the-art approaches\npredominantly neglect the need for AI systems to be contestable. Instead,\ncontestability is advocated by AI guidelines (e.g. by the OECD) and regulation\nof automated decision-making (e.g. GDPR). In this position paper we explore how\ncontestability can be achieved computationally in and for AI. We argue that\ncontestable AI requires dynamic (human-machine and/or machine-machine)\nexplainability and decision-making processes, whereby machines can (i) interact\nwith humans and/or other machines to progressively explain their outputs and/or\ntheir reasoning as well as assess grounds for contestation provided by these\nhumans and/or other machines, and (ii) revise their decision-making processes\nto redress any issues successfully raised during contestation. Given that much\nof the current AI landscape is tailored to static AIs, the need to accommodate\ncontestability will require a radical rethinking, that, we argue, computational\nargumentation is ideally suited to support.",
      "tldr_zh": "这篇论文强调，AI 系统需要具备可争辩性(contestability)，以符合如OECD指南和GDPR法规的要求，但当前AI方法大多忽略了这一点。作者主张，可争辩的AI应采用动态的人机或机机互动机制，让机器能够逐步解释输出和推理、评估争辩理由，并根据成功争辩修改决策过程。论文认为，计算论证(computational argumentation)是实现这一目标的理想工具，需要对现有静态AI进行根本性重新设计，以支持更可解释和可信任的决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at KR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10729v2",
      "published_date": "2024-05-17 12:23:18 UTC",
      "updated_date": "2024-08-03 23:06:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:17:57.090107"
    },
    {
      "arxiv_id": "2405.10714v1",
      "title": "Persian Pronoun Resolution: Leveraging Neural Networks and Language Models",
      "title_zh": "Persian 代词消解：利用神经网络和语言模型",
      "authors": [
        "Hassan Haji Mohammadi",
        "Alireza Talebpour",
        "Ahmad Mahmoudi Aznaveh",
        "Samaneh Yazdani"
      ],
      "abstract": "Coreference resolution, critical for identifying textual entities referencing\nthe same entity, faces challenges in pronoun resolution, particularly\nidentifying pronoun antecedents. Existing methods often treat pronoun\nresolution as a separate task from mention detection, potentially missing\nvaluable information. This study proposes the first end-to-end neural network\nsystem for Persian pronoun resolution, leveraging pre-trained Transformer\nmodels like ParsBERT. Our system jointly optimizes both mention detection and\nantecedent linking, achieving a 3.37 F1 score improvement over the previous\nstate-of-the-art system (which relied on rule-based and statistical methods) on\nthe Mehr corpus. This significant improvement demonstrates the effectiveness of\ncombining neural networks with linguistic models, potentially marking a\nsignificant advancement in Persian pronoun resolution and paving the way for\nfurther research in this under-explored area.",
      "tldr_zh": "这篇论文针对波斯语的代词解析（pronoun resolution）问题，提出了第一个端到端的神经网络系统，利用预训练的 Transformer 模型如 ParsBERT 来联合优化提及检测（mention detection）和先行词链接（antecedent linking）。该方法克服了现有系统将任务分离可能遗漏信息的局限性，在 Mehr 语料库上实现了 F1 分数比之前基于规则和统计方法的最先进系统提高 3.37 的显著改进。整体结果展示了神经网络与语言模型结合的有效性，为波斯语核心ference resolution 领域的研究提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10714v1",
      "published_date": "2024-05-17 11:56:00 UTC",
      "updated_date": "2024-05-17 11:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:18:08.043985"
    },
    {
      "arxiv_id": "2405.10713v1",
      "title": "Development of Semantics-Based Distributed Middleware for Heterogeneous Data Integration and its Application for Drought",
      "title_zh": "翻译失败",
      "authors": [
        "A Akanbi"
      ],
      "abstract": "Drought is a complex environmental phenomenon that affects millions of people\nand communities all over the globe and is too elusive to be accurately\npredicted. This is mostly due to the scalability and variability of the web of\nenvironmental parameters that directly/indirectly causes the onset of different\ncategories of drought. Since the dawn of man, efforts have been made to\nuniquely understand the natural indicators that provide signs of likely\nenvironmental events. These indicators/signs in the form of indigenous\nknowledge system have been used for generations. The intricate complexity of\ndrought has, however, always been a major stumbling block for accurate drought\nprediction and forecasting systems. Recently, scientists in the field of\nagriculture and environmental monitoring have been discussing the integration\nof indigenous knowledge and scientific knowledge for a more accurate\nenvironmental forecasting system in order to incorporate diverse environmental\ninformation for a reliable drought forecast. Hence, in this research, the core\nobjective is the development of a semantics-based data integration middleware\nthat encompasses and integrates heterogeneous data models of local indigenous\nknowledge and sensor data towards an accurate drought forecasting system for\nthe study areas. The local indigenous knowledge on drought gathered from the\ndomain experts is transformed into rules to be used for performing deductive\ninference in conjunction with sensors data for determining the onset of drought\nthrough an automated inference generation module of the middleware. The\nsemantic middleware incorporates, inter alia, a distributed architecture that\nconsists of a streaming data processing engine based on Apache Kafka for\nreal-time stream processing; a rule-based reasoning module; an ontology module\nfor semantic representation of the knowledge bases.",
      "tldr_zh": "本研究针对干旱预测的复杂性和数据异构性问题，开发了一种基于语义的分布式中间件，用于整合本土本土知识和传感器数据。中间件采用分布式架构，包括Apache Kafka的实时流数据处理引擎、基于规则的推理模块以及本体模块来实现知识的语义表示和演绎推理。通过将本土知识转化为规则，与传感器数据相结合，该系统实现了自动推理生成模块，提升了干旱预测的准确性。该方法为环境保护和农业监测提供了可靠的框架，特别是在研究区域的应用中。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "286 Pages, PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2405.10713v1",
      "published_date": "2024-05-17 11:44:22 UTC",
      "updated_date": "2024-05-17 11:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:18:19.964110"
    },
    {
      "arxiv_id": "2405.10700v1",
      "title": "SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Shliselberg",
        "Ashkan Kazemi",
        "Scott A. Hale",
        "Shiri Dori-Hacohen"
      ],
      "abstract": "Diaspora communities are disproportionately impacted by off-the-radar\nmisinformation and often neglected by mainstream fact-checking efforts,\ncreating a critical need to scale-up efforts of nascent fact-checking\ninitiatives. In this paper we present SynDy, a framework for Synthetic Dynamic\nDataset Generation to leverage the capabilities of the largest frontier Large\nLanguage Models (LLMs) to train local, specialized language models. To the best\nof our knowledge, SynDy is the first paper utilizing LLMs to create\nfine-grained synthetic labels for tasks of direct relevance to misinformation\nmitigation, namely Claim Matching, Topical Clustering, and Claim Relationship\nClassification. SynDy utilizes LLMs and social media queries to automatically\ngenerate distantly-supervised, topically-focused datasets with synthetic labels\non these three tasks, providing essential tools to scale up human-led\nfact-checking at a fraction of the cost of human-annotated data. Training on\nSynDy's generated labels shows improvement over a standard baseline and is not\nsignificantly worse compared to training on human labels (which may be\ninfeasible to acquire). SynDy is being integrated into Meedan's chatbot\ntiplines that are used by over 50 organizations, serve over 230K users\nannually, and automatically distribute human-written fact-checks via messaging\napps such as WhatsApp. SynDy will also be integrated into our deployed\nCo-Insights toolkit, enabling low-resource organizations to launch tiplines for\ntheir communities. Finally, we envision SynDy enabling additional fact-checking\ntools such as matching new misinformation claims to high-quality explainers on\ncommon misinformation topics.",
      "tldr_zh": "本文提出 SynDy 框架，这是一个合成动态数据集生成系统，利用大型语言模型 (LLMs) 和社交媒体查询来自动创建远程监督的主题聚焦数据集，针对误传信息任务如 Claim Matching、Topical Clustering 和 Claim Relationship Classification。SynDy 是首次应用 LLMs 生成细粒度合成标签的框架，有助于低成本扩展事实检查努力。实验结果显示，在 SynDy 生成的标签上训练模型比标准基线有显著改善，且性能接近人类标注，但成本更低。该框架已整合到 Meedan's 聊天机器人 tiplines 中，支持超过 50 个组织和 23 万用户，并计划扩展到更多事实检查工具如 Co-Insights。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10700v1",
      "published_date": "2024-05-17 11:14:55 UTC",
      "updated_date": "2024-05-17 11:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:18:34.415067"
    },
    {
      "arxiv_id": "2405.11008v3",
      "title": "A Systematic Review on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Tayab Uddin Wara",
        "Ababil Hossain Fahad",
        "Adri Shankar Das",
        "Md. Mehedi Hasan Shawon"
      ],
      "abstract": "Sleep is vital for people's physical and mental health, and sound sleep can\nhelp them focus on daily activities. Therefore, a sleep study that includes\nsleep patterns and sleep disorders is crucial to enhancing our knowledge about\nindividuals' health status. This study aims to provide a comprehensive,\nsystematic review of the recent literature to analyze the different approaches\nand their outcomes in sleep studies, which includes works on \"sleep stages\nclassification\" and \"sleep disorder detection\" using AI. In this review, 183\narticles were initially selected from different journals, among which 80\nrecords were enlisted for explicit review, ranging from 2016 to 2023. Brain\nwaves were the most commonly employed body parameters for sleep staging and\ndisorder studies (almost 29% of the research used brain activity signals\nexclusively, and 77% combined with the other signals). The convolutional neural\nnetwork (CNN), the most widely used of the 34 distinct artificial intelligence\nmodels, comprised 27%. The other models included the long short-term memory\n(LSTM), support vector machine (SVM), random forest (RF), and recurrent neural\nnetwork (RNN), which consisted of 11%, 6%, 6%, and 5% sequentially. For\nperformance metrics, accuracy was widely used for a maximum of 83.75% of the\ncases, the F1 score of 45%, Kappa of 36.25%, Sensitivity of 31.25%, and\nSpecificity of 30% of cases, along with the other metrics. This article would\nhelp physicians and researchers get the gist of AI's contribution to sleep\nstudies and the feasibility of their intended work.",
      "tldr_zh": "这篇论文对使用人工智能（AI）进行睡眠阶段分类和睡眠障碍检测的文献进行了系统综述，涵盖2016-2023年间80篇研究，旨在分析不同方法及其效果。研究发现，脑波信号是最常用参数（29%单独使用，77%与其他信号结合），而卷积神经网络（CNN）是应用最广泛的AI模型（占比27%），其他模型包括长短时记忆网络（LSTM，11%）、支持向量机（SVM，6%）和随机森林（RF，6%）。性能指标以准确率（83.75%）为主，其次是F1分数（45%）和Kappa值（36.25%），该综述有助于医生和研究者了解AI在睡眠研究中的贡献和实际可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "39 pages, 11 Figures, 8 Tables",
      "pdf_url": "http://arxiv.org/pdf/2405.11008v3",
      "published_date": "2024-05-17 11:09:33 UTC",
      "updated_date": "2025-04-17 06:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:18:45.151573"
    },
    {
      "arxiv_id": "2406.04356v1",
      "title": "BugBlitz-AI: An Intelligent QA Assistant",
      "title_zh": "BugBlitz-AI：智能 QA 助手",
      "authors": [
        "Yi Yao",
        "Jun Wang",
        "Yabai Hu",
        "Lifeng Wang",
        "Yi Zhou",
        "Jack Chen",
        "Xuming Gai",
        "Zhenming Wang",
        "Wenjun Liu"
      ],
      "abstract": "The evolution of software testing from manual to automated methods has\nsignificantly influenced quality assurance (QA) practices. However, challenges\npersist in post-execution phases, particularly in result analysis and\nreporting. Traditional post-execution validation phases require manual\nintervention for result analysis and report generation, leading to\ninefficiencies and potential development cycle delays. This paper introduces\nBugBlitz-AI, an AI-powered validation toolkit designed to enhance end-to-end\ntest automation by automating result analysis and bug reporting processes.\nBugBlitz-AI leverages recent advancements in artificial intelligence to reduce\nthe time-intensive tasks of manual result analysis and report generation,\nallowing QA teams to focus more on crucial aspects of product quality. By\nadopting BugBlitz-AI, organizations can advance automated testing practices and\nintegrate AI into QA processes, ensuring higher product quality and faster\ntime-to-market. The paper outlines BugBlitz-AI's architecture, discusses\nrelated work, details its quality enhancement strategies, and presents results\ndemonstrating its effectiveness in real-world scenarios.",
      "tldr_zh": "这篇论文讨论了软件测试从手动到自动化的演变，但后执行阶段如结果分析和报告仍依赖手动干预，导致低效和开发延误。论文引入 BugBlitz-AI，一种 AI 驱动的验证工具包，通过利用人工智能技术自动化结果分析和错误报告过程，帮助 QA 团队专注于产品质量的关键方面。实验结果显示，BugBlitz-AI 能提升自动化测试实践，提高产品品质并加速上市时间，并在真实场景中证明其有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04356v1",
      "published_date": "2024-05-17 11:09:10 UTC",
      "updated_date": "2024-05-17 11:09:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:18:56.113120"
    },
    {
      "arxiv_id": "2405.10679v1",
      "title": "Off-the-Shelf Neural Network Architectures for Forex Time Series Prediction come at a Cost",
      "title_zh": "翻译失败",
      "authors": [
        "Theodoros Zafeiriou",
        "Dimitris Kalles"
      ],
      "abstract": "Our study focuses on comparing the performance and resource requirements\nbetween different Long Short-Term Memory (LSTM) neural network architectures\nand an ANN specialized architecture for forex market prediction. We analyze the\nexecution time of the models as well as the resources consumed, such as memory\nand computational power. Our aim is to demonstrate that the specialized\narchitecture not only achieves better results in forex market prediction but\nalso executes using fewer resources and in a shorter time frame compared to\nLSTM architectures. This comparative analysis will provide significant insights\ninto the suitability of these two types of architectures for time series\nprediction in the forex market environment.",
      "tldr_zh": "本研究比较了不同 LSTM 神经网络架构和一个专门的 ANN 架构在外汇市场时间序列预测中的性能及资源需求，重点分析了执行时间、内存和计算能力消耗。结果显示，专门的 ANN 架构不仅在预测准确性上优于 LSTM 架构，还能以更少的资源和更短的时间框架实现。总体而言，这一比较分析为选择适合外汇环境的时间序列预测架构提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-fin.MF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10679v1",
      "published_date": "2024-05-17 10:20:14 UTC",
      "updated_date": "2024-05-17 10:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:19:08.680835"
    },
    {
      "arxiv_id": "2405.11007v1",
      "title": "Generative modeling of Sparse Approximate Inverse Preconditioners",
      "title_zh": "稀疏近似",
      "authors": [
        "Mou Li",
        "He Wang",
        "Peter K. Jimack"
      ],
      "abstract": "We present a new deep learning paradigm for the generation of sparse\napproximate inverse (SPAI) preconditioners for matrix systems arising from the\nmesh-based discretization of elliptic differential operators. Our approach is\nbased upon the observation that matrices generated in this manner are not\narbitrary, but inherit properties from differential operators that they\ndiscretize. Consequently, we seek to represent a learnable distribution of\nhigh-performance preconditioners from a low-dimensional subspace through a\ncarefully-designed autoencoder, which is able to generate SPAI preconditioners\nfor these systems. The concept has been implemented on a variety of finite\nelement discretizations of second- and fourth-order elliptic partial\ndifferential equations with highly promising results.",
      "tldr_zh": "本研究提出了一种新的深度学习范式，用于生成 Sparse Approximate Inverse (SPAI) 预处理器，针对椭圆微分算子网格基离散化产生的矩阵系统。\n该方法基于这些矩阵继承自微分算子的属性，通过一个精心设计的 autoencoder 表示可学习的低维子空间，从而生成高性能的 SPAI 预处理器。\n实验结果显示，该框架在各种有限元离散化的二阶和四阶椭圆偏微分方程上取得了有前景的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 8 figures, International conference on Computational\n  Science",
      "pdf_url": "http://arxiv.org/pdf/2405.11007v1",
      "published_date": "2024-05-17 10:19:32 UTC",
      "updated_date": "2024-05-17 10:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:19:20.440081"
    },
    {
      "arxiv_id": "2405.10674v1",
      "title": "From Sora What We Can See: A Survey of Text-to-Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Sun",
        "Yumin Zhang",
        "Tejal Shah",
        "Jiahao Sun",
        "Shuoying Zhang",
        "Wenqi Li",
        "Haoran Duan",
        "Bo Wei",
        "Rajiv Ranjan"
      ],
      "abstract": "With impressive achievements made, artificial intelligence is on the path\nforward to artificial general intelligence. Sora, developed by OpenAI, which is\ncapable of minute-level world-simulative abilities can be considered as a\nmilestone on this developmental path. However, despite its notable successes,\nSora still encounters various obstacles that need to be resolved. In this\nsurvey, we embark from the perspective of disassembling Sora in text-to-video\ngeneration, and conducting a comprehensive review of literature, trying to\nanswer the question, \\textit{From Sora What We Can See}. Specifically, after\nbasic preliminaries regarding the general algorithms are introduced, the\nliterature is categorized from three mutually perpendicular dimensions:\nevolutionary generators, excellent pursuit, and realistic panorama.\nSubsequently, the widely used datasets and metrics are organized in detail.\nLast but more importantly, we identify several challenges and open problems in\nthis domain and propose potential future directions for research and\ndevelopment.",
      "tldr_zh": "这篇调查论文从OpenAI的Sora模型出发，全面回顾了文本到视频生成（Text-to-Video Generation）领域的文献进展，并探讨了其作为人工智能里程碑的意义和挑战。论文将相关研究分类为三个维度：evolutionary generators（进化生成器）、excellent pursuit（优秀追求）和realistic panorama（现实全景），并介绍了基本算法、常用数据集和评估指标。最终，它指出了当前领域的关键挑战和开放问题，并提出了潜在的未来研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "A comprehensive list of text-to-video generation studies in this\n  survey is available at\n  https://github.com/soraw-ai/Awesome-Text-to-Video-Generation",
      "pdf_url": "http://arxiv.org/pdf/2405.10674v1",
      "published_date": "2024-05-17 10:09:09 UTC",
      "updated_date": "2024-05-17 10:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:19:31.322784"
    },
    {
      "arxiv_id": "2405.15801v1",
      "title": "Decision-making algorithm based on the energy of interval-valued fuzzy soft sets",
      "title_zh": "基于区间值模糊软集能",
      "authors": [
        "Ljubica Djurović",
        "Maja Laković",
        "Nenad Stojanović"
      ],
      "abstract": "In our work, we continue to explore the properties of interval-valued fuzzy\nsoft sets, which are obtained by combining interval-valued fuzzy sets and soft\nsets. We introduce the concept of energy of an interval-valued fuzzy soft set,\nas well as pessimistic and optimistic energy, enabling us to construct an\neffective decision-making algorithm. Through examples, the paper demonstrates\nhow the introduced algorithm is successfully applied to problems involving\nuncertainty. Additionally, we compare the introduced method with other methods\ndealing with similar or related issues.",
      "tldr_zh": "本研究探讨了interval-valued fuzzy soft sets的属性，并引入了energy、pessimistic energy和optimistic energy的概念，作为决策工具的基础。基于这些新概念，论文构建了一个有效的decision-making algorithm，用于处理不确定性问题，并通过具体例子展示了其实际应用。该算法与现有类似方法进行了比较，证明了其在复杂场景中的优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15801v1",
      "published_date": "2024-05-17 09:54:44 UTC",
      "updated_date": "2024-05-17 09:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:19:43.245118"
    },
    {
      "arxiv_id": "2407.09486v1",
      "title": "ENOVA: Autoscaling towards Cost-effective and Stable Serverless LLM Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Huang",
        "Pengfei Chen",
        "Kyoka Gong",
        "Jocky Hawk",
        "Zachary Bright",
        "Wenxin Xie",
        "Kecheng Huang",
        "Zhi Ji"
      ],
      "abstract": "Since the increasing popularity of large language model (LLM) backend\nsystems, it is common and necessary to deploy stable serverless serving of LLM\non multi-GPU clusters with autoscaling. However, there exist challenges because\nthe diversity and co-location of applications in multi-GPU clusters will lead\nto low service quality and GPU utilization. To address them, we build ENOVA, a\ndeployment, monitoring and autoscaling service towards serverless LLM serving.\nENOVA deconstructs the execution process of LLM service comprehensively, based\non which ENOVA designs a configuration recommendation module for automatic\ndeployment on any GPU clusters and a performance detection module for\nautoscaling. On top of them, ENOVA implements a deployment execution engine for\nmulti-GPU cluster scheduling. The experiment results show that ENOVA\nsignificantly outperforms other state-of-the-art methods and is suitable for\nwide deployment in large online systems.",
      "tldr_zh": "该论文提出 ENOVA，一种针对无服务器 LLM Serving 的部署、监控和自动缩放系统，旨在实现成本有效且稳定的多 GPU 集群管理。ENOVA 通过全面分解 LLM 服务执行过程，设计了配置推荐模块以自动部署于任意 GPU 集群，以及性能检测模块来支持自动缩放，并实现了部署执行引擎用于多 GPU 调度。实验结果显示，ENOVA 显著优于现有最先进方法，在服务质量和 GPU 利用率上表现出色，适用于大规模在线系统部署。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09486v1",
      "published_date": "2024-05-17 09:48:31 UTC",
      "updated_date": "2024-05-17 09:48:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:19:56.318636"
    },
    {
      "arxiv_id": "2405.10659v2",
      "title": "Realistic Evaluation of Toxicity in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tinh Son Luong",
        "Thanh-Thien Le",
        "Linh Ngo Van",
        "Thien Huu Nguyen"
      ],
      "abstract": "Large language models (LLMs) have become integral to our professional\nworkflows and daily lives. Nevertheless, these machine companions of ours have\na critical flaw: the huge amount of data which endows them with vast and\ndiverse knowledge, also exposes them to the inevitable toxicity and bias. While\nmost LLMs incorporate defense mechanisms to prevent the generation of harmful\ncontent, these safeguards can be easily bypassed with minimal prompt\nengineering. In this paper, we introduce the new Thoroughly Engineered Toxicity\n(TET) dataset, comprising manually crafted prompts designed to nullify the\nprotective layers of such models. Through extensive evaluations, we demonstrate\nthe pivotal role of TET in providing a rigorous benchmark for evaluation of\ntoxicity awareness in several popular LLMs: it highlights the toxicity in the\nLLMs that might remain hidden when using normal prompts, thus revealing subtler\nissues in their behavior.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）中的毒性和偏见问题，这些问题源于训练数据，但现有防御机制容易被提示工程(prompt engineering)绕过。论文引入了Thoroughly Engineered Toxicity (TET)数据集，该数据集包含手动设计的提示，用于有效削弱模型的保护层，从而提供一个严格的基准评估。实验结果显示，TET在多个流行LLMs上揭示了使用正常提示时隐藏的毒性行为，帮助识别模型行为的微妙缺陷。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10659v2",
      "published_date": "2024-05-17 09:42:59 UTC",
      "updated_date": "2024-05-20 14:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:20:08.054114"
    },
    {
      "arxiv_id": "2405.10647v1",
      "title": "Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyue Song",
        "Jiacheng Wang",
        "Liansheng Wang"
      ],
      "abstract": "Federated Learning (FL) has gained attention for addressing data scarcity and\nprivacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable\nperformance, they face challenges in scenarios with diverse network speeds and\nconcerns about centralized control, especially in multi-institutional\ncollaborations like the medical domain. Serial FL presents an alternative\nsolution, circumventing these challenges by transferring model updates serially\nbetween devices in a cyclical manner. Nevertheless, it is deemed inferior to\nparallel FL in that (1) its performance shows undesirable fluctuations, and (2)\nit converges to a lower plateau, particularly when dealing with non-IID data.\nThe observed phenomenon is attributed to catastrophic forgetting due to\nknowledge loss from previous sites. In this paper, to overcome fluctuation and\nlow efficiency in the iterative learning and forgetting process, we introduce\ncyclical weight consolidation (CWC), a straightforward yet potent approach\nspecifically tailored for serial FL. CWC employs a consolidation matrix to\nregulate local optimization. This matrix tracks the significance of each\nparameter on the overall federation throughout the entire training trajectory,\npreventing abrupt changes in significant weights. During revisitation, to\nmaintain adaptability, old memory undergoes decay to incorporate new\ninformation. Our comprehensive evaluations demonstrate that in various non-IID\nsettings, CWC mitigates the fluctuation behavior of the original serial FL\napproach and enhances the converged performance consistently and significantly.\nThe improved performance is either comparable to or better than the parallel\nvanilla.",
      "tldr_zh": "该研究针对串行 Federated Learning (FL) 中的灾难性遗忘 (catastrophic forgetting) 问题，提出了一种名为 Cyclical Weight Consolidation (CWC) 的方法，以解决性能波动和低效收敛问题。CWC 通过一个 consolidation matrix 跟踪参数的重要性，调节本地优化以防止重要权重突变，同时在重新访问时让旧记忆衰减以融入新信息。在各种 non-IID 数据设置下，实验结果显示 CWC 显著减少了串行 FL 的波动行为，并提升了收敛性能，使其与平行 FL 如 FedAvg 相当或更优。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.10647v1",
      "published_date": "2024-05-17 09:20:21 UTC",
      "updated_date": "2024-05-17 09:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:20:20.427628"
    },
    {
      "arxiv_id": "2405.10645v1",
      "title": "ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education",
      "title_zh": "ChatGPT 在课堂中：将挑战转化为教育机会",
      "authors": [
        "Harris Bin Munawar",
        "Nikolaos Misirlis"
      ],
      "abstract": "In the era of exponential technology growth, one unexpected guest has claimed\na seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as\nChatGPT, promises a revolution in education, yet it arrives with a double-edged\nsword. Its potential for personalized learning is offset by issues of cheating,\ninaccuracies, and educators struggling to incorporate it effectively into their\nlesson design. We are standing on the brink of this educational frontier, and\nit is clear that we need to navigate this terrain with a lot of care. This is a\nmajor challenge that could undermine the integrity and value of our educational\nprocess. So, how can we turn these challenges into opportunities? When used\ninappropriately, AI tools can become the perfect tool for the cut copy paste\nmentality, and quickly begin to corrode critical thinking, creativity, and deep\nunderstanding, the most important skills in our rapidly changing world.\nTeachers feel that they are not equipped to leverage this technology, widening\nthe digital divide among educators and institutions. Addressing these concerns\ncalls for an in depth research approach. We will employ empirical research,\ndrawing on the Technology Acceptance Model, to assess the attitudes toward\ngenerative AI among educators and students. Understanding their perceptions,\nusage patterns, and hurdles is the first crucial step in creating an effective\nsolution. The present study will be used as a process manual for future\nresearchers to apply, running their own data, based on the steps explained here",
      "tldr_zh": "这篇论文探讨了 ChatGPT 等生成式 AI 在教育中的双重影响：一方面，它能提供个性化学习机会，但也带来作弊、不准确性和教师整合困难等挑战。作者强调，这些问题可能损害教育诚信，并建议通过适当利用 AI 将其转化为提升批判性思维和创意的机遇。研究采用实证方法和 Technology Acceptance Model，调查教育者和学生的态度、使用模式及障碍，最终提供一个可复制的过程手册，指导未来相关研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "5 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.10645v1",
      "published_date": "2024-05-17 09:17:59 UTC",
      "updated_date": "2024-05-17 09:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:20:33.733210"
    },
    {
      "arxiv_id": "2405.10632v6",
      "title": "Towards interactive evaluations for interaction harms in human-AI systems",
      "title_zh": "翻译失败",
      "authors": [
        "Lujain Ibrahim",
        "Saffron Huang",
        "Umang Bhatt",
        "Lama Ahmad",
        "Markus Anderljung"
      ],
      "abstract": "Current AI evaluation paradigms that rely on static, model-only tests fail to\ncapture harms that emerge through sustained human-AI interaction. As\ninteractive AI systems, such as AI companions, proliferate in daily life, this\nmismatch between evaluation methods and real-world use becomes increasingly\nconsequential. We argue for a paradigm shift toward evaluation centered on\n\\textit{interactional ethics}, which addresses risks like inappropriate\nhuman-AI relationships, social manipulation, and cognitive overreliance that\ndevelop through repeated interaction rather than single outputs. Drawing on\nhuman-computer interaction, natural language processing, and the social\nsciences, we propose principles for evaluating generative models through\ninteraction scenarios and human impact metrics. We conclude by examining\nimplementation challenges and open research questions for researchers,\npractitioners, and regulators integrating these approaches into AI governance\nframeworks.",
      "tldr_zh": "本文指出，当前依赖静态测试的AI评估方法无法捕捉人类-AI系统互动中产生的危害，如不适当的人-AI关系、社会操纵和认知过reliance。作者主张转向以interactional ethics为中心的评估范式，通过互动场景和人类影响指标来评估生成模型的风险。论文借鉴human-computer interaction、自然语言处理和社会科学领域，提出相关原则，并讨论了实施挑战和开放研究问题，以指导研究者、从业者和监管者在AI治理框架中应用这些方法。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10632v6",
      "published_date": "2024-05-17 08:49:34 UTC",
      "updated_date": "2025-04-27 15:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:20:44.502843"
    },
    {
      "arxiv_id": "2405.10630v1",
      "title": "Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges",
      "title_zh": "医疗对话：类别、方法、评估和挑战的综述",
      "authors": [
        "Xiaoming Shi",
        "Zeming Liu",
        "Li Du",
        "Yuxuan Wang",
        "Hongru Wang",
        "Yuhang Guo",
        "Tong Ruan",
        "Jie Xu",
        "Shaoting Zhang"
      ],
      "abstract": "This paper surveys and organizes research works on medical dialog systems,\nwhich is an important yet challenging task. Although these systems have been\nsurveyed in the medical community from an application perspective, a systematic\nreview from a rigorous technical perspective has to date remained noticeably\nabsent. As a result, an overview of the categories, methods, and evaluation of\nmedical dialogue systems remain limited and underspecified, hindering the\nfurther improvement of this area. To fill this gap, we investigate an initial\npool of 325 papers from well-known computer science, and natural language\nprocessing conferences and journals, and make an overview. Recently, large\nlanguage models have shown strong model capacity on downstream tasks, which\nalso reshaped medical dialog systems' foundation. Despite the alluring\npractical application value, current medical dialogue systems still suffer from\nproblems. To this end, this paper lists the grand challenges of medical dialog\nsystems, especially of large language models.",
      "tldr_zh": "这篇论文对医疗对话系统进行了系统调查，涵盖其类别、方法、评估和挑战，作为一个重要但具有挑战性的研究领域。作者从知名计算机科学和自然语言处理会议及期刊中筛选了325篇论文，提供了一个从技术角度的全面概述，特别是强调了大型语言模型(Large Language Models)对系统基础的变革。论文指出了当前医疗对话系统面临的重大问题，并列出未来挑战，以推动该领域的进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10630v1",
      "published_date": "2024-05-17 08:46:15 UTC",
      "updated_date": "2024-05-17 08:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:20:56.793884"
    },
    {
      "arxiv_id": "2405.10629v1",
      "title": "DeepPavlov at SemEval-2024 Task 8: Leveraging Transfer Learning for Detecting Boundaries of Machine-Generated Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Anastasia Voznyuk",
        "Vasily Konovalov"
      ],
      "abstract": "The Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated\nText Detection shared task in the SemEval-2024 competition aims to tackle the\nproblem of misusing collaborative human-AI writing. Although there are a lot of\nexisting detectors of AI content, they are often designed to give a binary\nanswer and thus may not be suitable for more nuanced problem of finding the\nboundaries between human-written and machine-generated texts, while hybrid\nhuman-AI writing becomes more and more popular. In this paper, we address the\nboundary detection problem. Particularly, we present a pipeline for augmenting\ndata for supervised fine-tuning of DeBERTaV3. We receive new best MAE score,\naccording to the leaderboard of the competition, with this pipeline.",
      "tldr_zh": "该论文参与了SemEval-2024任务8，旨在通过转移学习（Transfer Learning）检测机器生成文本的边界，以应对人类-AI协作写作的滥用问题。研究团队提出了一种数据增强管道，用于监督微调DeBERTaV3模型，从而更精确地识别人类撰写与机器生成文本的交界。最终，该方法在比赛中取得了新的最佳MAE分数，展示了其在多生成器、多领域和多语言场景中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "New best score from the leaderboard, to appear in SemEval-2024\n  Workshop proceedings",
      "pdf_url": "http://arxiv.org/pdf/2405.10629v1",
      "published_date": "2024-05-17 08:44:48 UTC",
      "updated_date": "2024-05-17 08:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:21:09.100339"
    },
    {
      "arxiv_id": "2405.10625v1",
      "title": "Specialising and Analysing Instruction-Tuned and Byte-Level Language Models for Organic Reaction Prediction",
      "title_zh": "针对有机反应预测的专业化和分析指令微调及字节级语言模型",
      "authors": [
        "Jiayun Pang",
        "Ivan Vulić"
      ],
      "abstract": "Transformer-based encoder-decoder models have demonstrated impressive results\nin chemical reaction prediction tasks. However, these models typically rely on\npretraining using tens of millions of unlabelled molecules, which can be\ntime-consuming and GPU-intensive. One of the central questions we aim to answer\nin this work is: Can FlanT5 and ByT5, the encode-decoder models pretrained\nsolely on language data, be effectively specialised for organic reaction\nprediction through task-specific fine-tuning? We conduct a systematic empirical\nstudy on several key issues of the process, including tokenisation, the impact\nof (SMILES-oriented) pretraining, fine-tuning sample efficiency, and decoding\nalgorithms at inference. Our key findings indicate that although being\npretrained only on language tasks, FlanT5 and ByT5 provide a solid foundation\nto fine-tune for reaction prediction, and thus become `chemistry domain\ncompatible' in the process. This suggests that GPU-intensive and expensive\npretraining on a large dataset of unlabelled molecules may be useful yet not\nessential to leverage the power of language models for chemistry. All our\nmodels achieve comparable Top-1 and Top-5 accuracy although some variation\nacross different models does exist. Notably, tokenisation and vocabulary\ntrimming slightly affect final performance but can speed up training and\ninference; The most efficient greedy decoding strategy is very competitive\nwhile only marginal gains can be achieved from more sophisticated decoding\nalgorithms. In summary, we evaluate FlanT5 and ByT5 across several dimensions\nand benchmark their impact on organic reaction prediction, which may guide more\neffective use of these state-of-the-art language models for chemistry-related\ntasks in the future.",
      "tldr_zh": "本研究探讨了是否能将仅在语言数据上预训练的FlanT5和ByT5模型，通过任务特定微调，应用于有机反应预测，并系统分析了标记化、SMILES-oriented预训练的影响、微调样本效率以及解码算法。结果显示，这些模型能有效适应化学领域，成为“chemistry domain compatible”，无需昂贵的分子数据集预训练，且在Top-1和Top-5准确率上与基准模型相当。研究还发现，标记化和词汇修剪虽略微影响性能，但能显著加速训练和推理，而贪婪解码策略高效可靠，为未来在化学任务中使用此类语言模型提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.10625v1",
      "published_date": "2024-05-17 08:39:56 UTC",
      "updated_date": "2024-05-17 08:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:21:22.704971"
    },
    {
      "arxiv_id": "2405.10624v3",
      "title": "Sample-Efficient Constrained Reinforcement Learning with General Parameterization",
      "title_zh": "翻译失败",
      "authors": [
        "Washim Uddin Mondal",
        "Vaneet Aggarwal"
      ],
      "abstract": "We consider a constrained Markov Decision Problem (CMDP) where the goal of an\nagent is to maximize the expected discounted sum of rewards over an infinite\nhorizon while ensuring that the expected discounted sum of costs exceeds a\ncertain threshold. Building on the idea of momentum-based acceleration, we\ndevelop the Primal-Dual Accelerated Natural Policy Gradient (PD-ANPG) algorithm\nthat ensures an $\\epsilon$ global optimality gap and $\\epsilon$ constraint\nviolation with $\\tilde{\\mathcal{O}}((1-\\gamma)^{-7}\\epsilon^{-2})$ sample\ncomplexity for general parameterized policies where $\\gamma$ denotes the\ndiscount factor. This improves the state-of-the-art sample complexity in\ngeneral parameterized CMDPs by a factor of\n$\\mathcal{O}((1-\\gamma)^{-1}\\epsilon^{-2})$ and achieves the theoretical lower\nbound in $\\epsilon^{-1}$.",
      "tldr_zh": "这篇论文研究了约束马尔可夫决策过程 (CMDP)，目标是最大化无限 horizon 的折扣奖励总和，同时确保成本总和不超过阈值。作者提出了 Primal-Dual Accelerated Natural Policy Gradient (PD-ANPG) 算法，该算法基于 momentum-based acceleration，实现了 \\(\\tilde{\\mathcal{O}}((1-\\gamma)^{-7}\\epsilon^{-2})\\) 的样本复杂度，从而确保 \\(\\epsilon\\) 全局最优性和约束违反率。相比现有方法，该算法改善了 \\(\\mathcal{O}((1-\\gamma)^{-1}\\epsilon^{-2})\\) 的因子，并达到了 \\(\\epsilon^{-1}\\) 的理论下限。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10624v3",
      "published_date": "2024-05-17 08:39:05 UTC",
      "updated_date": "2024-10-31 05:24:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:21:33.429668"
    },
    {
      "arxiv_id": "2405.10621v2",
      "title": "Historically Relevant Event Structuring for Temporal Knowledge Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinchuan Zhang",
        "Ming Sun",
        "Chong Mu",
        "Jinhao Zhang",
        "Quanjiang Guo",
        "Ling Tian"
      ],
      "abstract": "Temporal Knowledge Graph (TKG) reasoning focuses on predicting events through\nhistorical information within snapshots distributed on a timeline. Existing\nstudies mainly concentrate on two perspectives of leveraging the history of\nTKGs, including capturing evolution of each recent snapshot or correlations\namong global historical facts. Despite the achieved significant\naccomplishments, these models still fall short of I) investigating the impact\nof multi-granular interactions across recent snapshots, and II) harnessing the\nexpressive semantics of significant links accorded with queries throughout the\nentire history, particularly events exerting a profound impact on the future.\nThese inadequacies restrict representation ability to reflect historical\ndependencies and future trends thoroughly. To overcome these drawbacks, we\npropose an innovative TKG reasoning approach towards \\textbf{His}torically\n\\textbf{R}elevant \\textbf{E}vents \\textbf{S}tructuring (HisRES). Concretely,\nHisRES comprises two distinctive modules excelling in structuring historically\nrelevant events within TKGs, including a multi-granularity evolutionary encoder\nthat captures structural and temporal dependencies of the most recent\nsnapshots, and a global relevance encoder that concentrates on crucial\ncorrelations among events relevant to queries from the entire history.\nFurthermore, HisRES incorporates a self-gating mechanism for adaptively merging\nmulti-granularity recent and historically relevant structuring representations.\nExtensive experiments on four event-based benchmarks demonstrate the\nstate-of-the-art performance of HisRES and indicate the superiority and\neffectiveness of structuring historical relevance for TKG reasoning.",
      "tldr_zh": "本研究针对 Temporal Knowledge Graph (TKG) 推理中的历史信息利用问题，指出现有方法忽略了多粒度快照交互和查询相关重要事件的语义影响，从而限制了对历史依赖和未来趋势的全面表示。提出 HisRES 框架，包括多-granularity evolutionary encoder 用于捕捉最近快照的结构和时间依赖，以及 global relevance encoder 用于提取整个历史中与查询相关的关键事件；此外，还整合自-gating mechanism 以自适应合并这些表示。实验在四个基于事件的基准上证明，HisRES 实现了 state-of-the-art 性能，展示了构建历史相关事件结构的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICDE 2025, 12 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.10621v2",
      "published_date": "2024-05-17 08:33:43 UTC",
      "updated_date": "2025-04-30 05:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:21:44.788131"
    },
    {
      "arxiv_id": "2405.10620v2",
      "title": "MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaohuan Zhan",
        "Lisha Yu",
        "Sijie Yu",
        "Guang Tan"
      ],
      "abstract": "In the Vision-and-Language Navigation (VLN) task, the agent is required to\nnavigate to a destination following a natural language instruction. While\nlearning-based approaches have been a major solution to the task, they suffer\nfrom high training costs and lack of interpretability. Recently, Large Language\nModels (LLMs) have emerged as a promising tool for VLN due to their strong\ngeneralization capabilities. However, existing LLM-based methods face\nlimitations in memory construction and diversity of navigation strategies. To\naddress these challenges, we propose a suite of techniques. Firstly, we\nintroduce a method to maintain a topological map that stores navigation\nhistory, retaining information about viewpoints, objects, and their spatial\nrelationships. This map also serves as a global action space. Additionally, we\npresent a Navigation Chain of Thoughts module, leveraging human navigation\nexamples to enrich navigation strategy diversity. Finally, we establish a\npipeline that integrates navigational memory and strategies with perception and\naction prediction modules. Experimental results on the REVERIE and R2R datasets\nshow that our method effectively enhances the navigation ability of the LLM and\nimproves the interpretability of navigation reasoning.",
      "tldr_zh": "本论文提出MC-GPT框架，以提升Vision-and-Language Navigation (VLN)任务的性能，解决现有Large Language Models (LLMs)方法在记忆构建和导航策略多样性上的局限性。框架包括维护一个拓扑地图来存储导航历史、视点、对象及其空间关系，作为全局行动空间；以及Navigation Chain of Thoughts模块，通过人类导航示例丰富策略多样性；并整合这些元素与感知和行动预测模块。实验结果显示，该方法在REVERIE和R2R数据集上显著提高了LLMs的导航能力和推理可解释性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10620v2",
      "published_date": "2024-05-17 08:33:27 UTC",
      "updated_date": "2024-08-12 14:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:21:57.945149"
    },
    {
      "arxiv_id": "2405.10611v1",
      "title": "A Certified Proof Checker for Deep Neural Network Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Remi Desmartin",
        "Omri Isac",
        "Ekaterina Komendantskaya",
        "Kathrin Stark",
        "Grant Passmore",
        "Guy Katz"
      ],
      "abstract": "Recent advances in the verification of deep neural networks (DNNs) have\nopened the way for broader usage of DNN verification technology in many\napplication areas, including safety-critical ones. DNN verifiers are themselves\ncomplex programs that have been shown to be susceptible to errors and\nimprecisions; this in turn has raised the question of trust in DNN verifiers.\nOne prominent attempt to address this issue is enhancing DNN verifiers with the\ncapability of producing proofs of their results that are subject to independent\nalgorithmic certification (proof checking). Formulations of proof production\nand proof checking already exist on top of the state-of-the-art Marabou DNN\nverifier. The native implementation of the proof checking algorithm for Marabou\nwas done in C++ and itself raised the question of trust in the code (e.g., in\nthe precision of floating point calculations or guarantees for implementation\nsoundness). Here, we present an alternative implementation of the Marabou proof\nchecking algorithm in Imandra -- an industrial functional programming language\nand prover -- that allows us to obtain an implementation with formal\nguarantees, including proofs of mathematical results underlying the algorithm,\nsuch as the use of the Farkas lemma.",
      "tldr_zh": "该研究针对深度神经网络(DNNs)验证器的可信度问题，提出了一种认证证明检查器，以确保验证结果的可靠性。作者在现有Marabou验证器基础上，使用Imandra工业函数式编程语言重新实现了证明检查算法，从而获得正式保证，包括对算法底层数学结果（如Farkas lemma）的证明。实验表明，这一方法提升了验证器的精确性和可信度，为安全关键应用领域的DNN验证提供了更可靠的框架。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10611v1",
      "published_date": "2024-05-17 08:16:32 UTC",
      "updated_date": "2024-05-17 08:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:22:08.203896"
    },
    {
      "arxiv_id": "2405.10608v2",
      "title": "ECATS: Explainable-by-design concept-based anomaly detection for time series",
      "title_zh": "翻译失败",
      "authors": [
        "Irene Ferfoglia",
        "Gaia Saveri",
        "Laura Nenzi",
        "Luca Bortolussi"
      ],
      "abstract": "Deep learning methods for time series have already reached excellent\nperformances in both prediction and classification tasks, including anomaly\ndetection. However, the complexity inherent in Cyber Physical Systems (CPS)\ncreates a challenge when it comes to explainability methods. To overcome this\ninherent lack of interpretability, we propose ECATS, a concept-based\nneuro-symbolic architecture where concepts are represented as Signal Temporal\nLogic (STL) formulae. Leveraging kernel-based methods for STL, concept\nembeddings are learnt in an unsupervised manner through a cross-attention\nmechanism. The network makes class predictions through these concept\nembeddings, allowing for a meaningful explanation to be naturally extracted for\neach input. Our preliminary experiments with a simple CPS-based dataset show\nthat our model is able to achieve great classification performance while\nensuring local interpretability.",
      "tldr_zh": "这篇论文针对深度学习在Cyber Physical Systems (CPS)中时间序列异常检测的解释性挑战，提出了ECATS框架——一个基于概念的神经符号架构。ECATS使用Signal Temporal Logic (STL)公式来表示概念，并通过交叉注意力机制和基于STL的核方法，在无监督方式下学习概念嵌入，从而实现类预测并自然提取有意义的解释。初步实验在简单CPS数据集上显示，该模型在分类性能上表现出色，同时确保了局部可解释性，为可解释异常检测提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 8 figures, accepted to 18th International Conference on\n  Neural-Symbolic Learning and Reasoning (NeSy 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.10608v2",
      "published_date": "2024-05-17 08:12:53 UTC",
      "updated_date": "2024-07-30 10:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:22:21.337963"
    },
    {
      "arxiv_id": "2405.10597v1",
      "title": "UniCL: A Universal Contrastive Learning Framework for Large Time Series Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Li",
        "Jingshu Peng",
        "Haoyang Li",
        "Lei Chen"
      ],
      "abstract": "Time-series analysis plays a pivotal role across a range of critical\napplications, from finance to healthcare, which involves various tasks, such as\nforecasting and classification. To handle the inherent complexities of\ntime-series data, such as high dimensionality and noise, traditional supervised\nlearning methods first annotate extensive labels for time-series data in each\ntask, which is very costly and impractical in real-world applications. In\ncontrast, pre-trained foundation models offer a promising alternative by\nleveraging unlabeled data to capture general time series patterns, which can\nthen be fine-tuned for specific tasks. However, existing approaches to\npre-training such models typically suffer from high-bias and low-generality\nissues due to the use of predefined and rigid augmentation operations and\ndomain-specific data training. To overcome these limitations, this paper\nintroduces UniCL, a universal and scalable contrastive learning framework\ndesigned for pretraining time-series foundation models across cross-domain\ndatasets. Specifically, we propose a unified and trainable time-series\naugmentation operation to generate pattern-preserved, diverse, and low-bias\ntime-series data by leveraging spectral information. Besides, we introduce a\nscalable augmentation algorithm capable of handling datasets with varying\nlengths, facilitating cross-domain pretraining. Extensive experiments on two\nbenchmark datasets across eleven domains validate the effectiveness of UniCL,\ndemonstrating its high generalization on time-series analysis across various\nfields.",
      "tldr_zh": "这篇论文介绍了UniCL，一种通用的对比学习(contrastive learning)框架，旨在通过预训练时间序列基础模型来处理各种任务，如预测和分类，同时克服传统监督学习标注成本高和现有方法偏差大的问题。UniCL 提出统一的、可训练的时间序列增强操作，利用频谱信息(spectral information)生成保持模式多样性和低偏差的数据，并设计可扩展算法支持不同长度数据集的跨领域预训练。实验结果显示，UniCL 在两个基准数据集上跨越11个领域表现出高泛化能力，显著提升了时间序列分析的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10597v1",
      "published_date": "2024-05-17 07:47:11 UTC",
      "updated_date": "2024-05-17 07:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:22:34.758697"
    },
    {
      "arxiv_id": "2405.13039v1",
      "title": "Surgical Feature-Space Decomposition of LLMs: Why, When and How?",
      "title_zh": "翻译失败",
      "authors": [
        "Arnav Chavan",
        "Nahush Lele",
        "Deepak Gupta"
      ],
      "abstract": "Low-rank approximations, of the weight and feature space can enhance the\nperformance of deep learning models, whether in terms of improving\ngeneralization or reducing the latency of inference. However, there is no clear\nconsensus yet on \\emph{how}, \\emph{when} and \\emph{why} these approximations\nare helpful for large language models (LLMs). In this work, we empirically\nstudy the efficacy of weight and feature space decomposition in\ntransformer-based LLMs. We demonstrate that surgical decomposition not only\nprovides critical insights into the trade-off between compression and language\nmodelling performance, but also sometimes enhances commonsense reasoning\nperformance of LLMs. Our empirical analysis identifies specific network\nsegments that intrinsically exhibit a low-rank structure. Furthermore, we\nextend our investigation to the implications of low-rank approximations on\nmodel bias. Overall, our findings offer a novel perspective on optimizing LLMs,\npresenting the low-rank approximation not only as a tool for performance\nenhancements, but also as a means to potentially rectify biases within these\nmodels. Our code is available at\n\\href{https://github.com/nyunAI/SFSD-LLM}{GitHub}.",
      "tldr_zh": "本研究探讨了在大型语言模型（LLMs）中应用低秩逼近（low-rank approximations）对权重和特征空间的分解，旨在分析其为什么、什么时候和如何提升模型性能。该团队通过实证分析transformer-based LLMs，证明这种“外科式”分解不仅能平衡模型压缩与语言建模性能，还能改善LLMs的常识推理能力，并识别出网络中固有低秩结构的特定段。研究进一步揭示，低秩逼近可潜在减少模型偏差，提供优化LLMs的新视角，同时开源了相关代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13039v1",
      "published_date": "2024-05-17 07:34:03 UTC",
      "updated_date": "2024-05-17 07:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:22:44.625237"
    },
    {
      "arxiv_id": "2405.13038v1",
      "title": "An Explanatory Model Steering System for Collaboration between Domain Experts and AI",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Bhattacharya",
        "Simone Stumpf",
        "Katrien Verbert"
      ],
      "abstract": "With the increasing adoption of Artificial Intelligence (AI) systems in\nhigh-stake domains, such as healthcare, effective collaboration between domain\nexperts and AI is imperative. To facilitate effective collaboration between\ndomain experts and AI systems, we introduce an Explanatory Model Steering\nsystem that allows domain experts to steer prediction models using their domain\nknowledge. The system includes an explanation dashboard that combines different\ntypes of data-centric and model-centric explanations and allows prediction\nmodels to be steered through manual and automated data configuration\napproaches. It allows domain experts to apply their prior knowledge for\nconfiguring the underlying training data and refining prediction models.\nAdditionally, our model steering system has been evaluated for a\nhealthcare-focused scenario with 174 healthcare experts through three extensive\nuser studies. Our findings highlight the importance of involving domain experts\nduring model steering, ultimately leading to improved human-AI collaboration.",
      "tldr_zh": "这篇论文引入了 Explanatory Model Steering system，以促进领域专家和 AI 之间的有效协作，允许专家使用其领域知识来引导预测模型。系统包括一个 explanation dashboard，结合 data-centric 和 model-centric explanations，并支持通过手动和自动数据配置来调整训练数据和完善模型。在针对医疗场景的三个用户研究中，涉及 174 名医疗专家，结果显示，专家参与模型引导过程能显著提升人类-AI 协作的效率和效果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Demo paper accepted for ACM UMAP 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13038v1",
      "published_date": "2024-05-17 07:27:48 UTC",
      "updated_date": "2024-05-17 07:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:22:57.442500"
    },
    {
      "arxiv_id": "2405.10589v1",
      "title": "Improving Point-based Crowd Counting and Localization Based on Auxiliary Point Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "I-Hsiang Chen",
        "Wei-Ting Chen",
        "Yu-Wei Liu",
        "Ming-Hsuan Yang",
        "Sy-Yen Kuo"
      ],
      "abstract": "Crowd counting and localization have become increasingly important in\ncomputer vision due to their wide-ranging applications. While point-based\nstrategies have been widely used in crowd counting methods, they face a\nsignificant challenge, i.e., the lack of an effective learning strategy to\nguide the matching process. This deficiency leads to instability in matching\npoint proposals to target points, adversely affecting overall performance. To\naddress this issue, we introduce an effective approach to stabilize the\nproposal-target matching in point-based methods. We propose Auxiliary Point\nGuidance (APG) to provide clear and effective guidance for proposal selection\nand optimization, addressing the core issue of matching uncertainty.\nAdditionally, we develop Implicit Feature Interpolation (IFI) to enable\nadaptive feature extraction in diverse crowd scenarios, further enhancing the\nmodel's robustness and accuracy. Extensive experiments demonstrate the\neffectiveness of our approach, showing significant improvements in crowd\ncounting and localization performance, particularly under challenging\nconditions. The source codes and trained models will be made publicly\navailable.",
      "tldr_zh": "该论文针对点-based 人群计数和定位方法中匹配过程的不稳定性问题，提出了一种改进策略，以提升整体性能。具体而言，引入了 Auxiliary Point Guidance (APG) 来提供明确的指导，优化提案-目标点的匹配过程；同时，开发了 Implicit Feature Interpolation (IFI) 以实现自适应特征提取，增强模型在多样化人群场景下的鲁棒性和准确性。通过广泛实验验证，该方法在人群计数和定位任务上取得了显著改进，尤其在 challenging 条件下，并计划公开源代码和训练模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10589v1",
      "published_date": "2024-05-17 07:23:27 UTC",
      "updated_date": "2024-05-17 07:23:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:23:09.289639"
    },
    {
      "arxiv_id": "2405.10581v2",
      "title": "Future Aware Safe Active Learning of Time Varying Systems using Gaussian Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Lange-Hegermann",
        "Christoph Zimmer"
      ],
      "abstract": "Experimental exploration of high-cost systems with safety constraints, common\nin engineering applications, is a challenging endeavor. Data-driven models\noffer a promising solution, but acquiring the requisite data remains expensive\nand is potentially unsafe. Safe active learning techniques prove essential,\nenabling the learning of high-quality models with minimal expensive data points\nand high safety. This paper introduces a safe active learning framework\ntailored for time-varying systems, addressing drift, seasonal changes, and\ncomplexities due to dynamic behavior. The proposed Time-aware Integrated Mean\nSquared Prediction Error (T-IMSPE) method minimizes posterior variance over\ncurrent and future states, optimizing information gathering also in the time\ndomain. Empirical results highlight T-IMSPE's advantages in model quality\nthrough toy and real-world examples. State of the art Gaussian processes are\ncompatible with T-IMSPE. Our theoretical contributions include a clear\ndelineation which Gaussian process kernels, domains, and weighting measures are\nsuitable for T-IMSPE and even beyond for its non-time aware predecessor IMSPE.",
      "tldr_zh": "这篇论文提出了一种安全主动学习框架，针对时间变化系统（如存在漂移和季节变化的动态行为），使用 Gaussian Processes 来最小化数据采集成本和风险。核心方法是 Time-aware Integrated Mean Squared Prediction Error (T-IMSPE)，它通过优化当前和未来状态的后验方差，在时间域内提升信息收集效率。实验结果显示，T-IMSPE 在玩具和真实世界示例中显著提高了模型质量，与现有 Gaussian Processes 兼容；此外，论文理论上明确了适合 T-IMSPE 及其非时间感知版本 IMSPE 的内核、域和权重措施。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.PR",
        "I.2.6; G.3; J.2; I.1.4"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10581v2",
      "published_date": "2024-05-17 07:09:52 UTC",
      "updated_date": "2025-04-16 15:24:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:23:21.737345"
    },
    {
      "arxiv_id": "2405.13037v1",
      "title": "Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Niu",
        "Xingguang Wang",
        "Xuxin Cheng",
        "Juntong Song",
        "Tong Zhang"
      ],
      "abstract": "Dialogue State Tracking (DST) is designed to monitor the evolving dialogue\nstate in the conversations and plays a pivotal role in developing task-oriented\ndialogue systems. However, obtaining the annotated data for the DST task is\nusually a costly endeavor. In this paper, we focus on employing LLMs to\ngenerate dialogue data to reduce dialogue collection and annotation costs.\nSpecifically, GPT-4 is used to simulate the user and agent interaction,\ngenerating thousands of dialogues annotated with DST labels. Then a two-stage\nfine-tuning on LLaMA 2 is performed on the generated data and the real data for\nthe DST prediction. Experimental results on two public DST benchmarks show that\nwith the generated dialogue data, our model performs better than the baseline\ntrained solely on real data. In addition, our approach is also capable of\nadapting to the dynamic demands in real-world scenarios, generating dialogues\nin new domains swiftly. After replacing dialogue segments in any domain with\nthe corresponding generated ones, the model achieves comparable performance to\nthe model trained on real data.",
      "tldr_zh": "本文提出一种利用 LLMs（如 GPT-4）模拟用户和代理交互的方法，生成大量带有 Dialogue State Tracking (DST) 标签的对话数据，以降低 DST 任务的数据收集和标注成本。具体而言，通过两阶段微调 LLaMA 2 模型，使用生成的对话数据与真实数据相结合，实验在两个公共 DST 基准上显示，该模型的性能优于仅基于真实数据的基线。此外，该方法能快速适应新领域，通过替换对话段落，实现与真实数据训练模型相当的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13037v1",
      "published_date": "2024-05-17 07:00:05 UTC",
      "updated_date": "2024-05-17 07:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:23:34.314892"
    },
    {
      "arxiv_id": "2405.10570v3",
      "title": "Simultaneous Deep Learning of Myocardium Segmentation and T2 Quantification for Acute Myocardial Infarction MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Yirong Zhou",
        "Chengyan Wang",
        "Mengtian Lu",
        "Kunyuan Guo",
        "Zi Wang",
        "Dan Ruan",
        "Rui Guo",
        "Peijun Zhao",
        "Jianhua Wang",
        "Naiming Wu",
        "Jianzhong Lin",
        "Yinyin Chen",
        "Hang Jin",
        "Lianxin Xie",
        "Lilan Wu",
        "Liuhong Zhu",
        "Jianjun Zhou",
        "Congbo Cai",
        "He Wang",
        "Xiaobo Qu"
      ],
      "abstract": "In cardiac Magnetic Resonance Imaging (MRI) analysis, simultaneous myocardial\nsegmentation and T2 quantification are crucial for assessing myocardial\npathologies. Existing methods often address these tasks separately, limiting\ntheir synergistic potential. To address this, we propose SQNet, a dual-task\nnetwork integrating Transformer and Convolutional Neural Network (CNN)\ncomponents. SQNet features a T2-refine fusion decoder for quantitative\nanalysis, leveraging global features from the Transformer, and a segmentation\ndecoder with multiple local region supervision for enhanced accuracy. A tight\ncoupling module aligns and fuses CNN and Transformer branch features, enabling\nSQNet to focus on myocardium regions. Evaluation on healthy controls (HC) and\nacute myocardial infarction patients (AMI) demonstrates superior segmentation\ndice scores (89.3/89.2) compared to state-of-the-art methods (87.7/87.9). T2\nquantification yields strong linear correlations (Pearson coefficients:\n0.84/0.93) with label values for HC/AMI, indicating accurate mapping.\nRadiologist evaluations confirm SQNet's superior image quality scores\n(4.60/4.58 for segmentation, 4.32/4.42 for T2 quantification) over\nstate-of-the-art methods (4.50/4.44 for segmentation, 3.59/4.37 for T2\nquantification). SQNet thus offers accurate simultaneous segmentation and\nquantification, enhancing cardiac disease diagnosis, such as AMI.",
      "tldr_zh": "本研究提出SQNet，一种双任务深度学习网络，整合Transformer和CNN组件，用于同时实现心肌分割和T2量化，从而提升对急性心肌梗死(AMI)MRI的分析准确性。SQNet包括T2-refine fusion decoder利用Transformer的全局特征进行量化分析，以及带有多个局部区域监督的分割decoder和tight coupling module来对齐融合分支特征，聚焦心肌区域。在健康对照组(HC)和AMI患者数据集上评估，SQNet的分割Dice分数(89.3/89.2)优于现有方法(87.7/87.9)，T2量化的Pearson系数(0.84/0.93)显示强相关性，且放射科医生评估的图像质量分数更高。整体而言，SQNet通过协同处理这两个任务，提高了心脏疾病如AMI的诊断效率和精确度。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 8 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.10570v3",
      "published_date": "2024-05-17 06:50:37 UTC",
      "updated_date": "2024-05-29 09:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:23:48.093378"
    },
    {
      "arxiv_id": "2406.18538v2",
      "title": "VideoQA-SC: Adaptive Semantic Communication for Video Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangyuan Guo",
        "Wei Chen",
        "Yuxuan Sun",
        "Jialong Xu",
        "Bo Ai"
      ],
      "abstract": "Although semantic communication (SC) has shown its potential in efficiently\ntransmitting multimodal data such as texts, speeches and images, SC for videos\nhas focused primarily on pixel-level reconstruction. However, these SC systems\nmay be suboptimal for downstream intelligent tasks. Moreover, SC systems\nwithout pixel-level video reconstruction present advantages by achieving higher\nbandwidth efficiency and real-time performance of various intelligent tasks.\nThe difficulty in such system design lies in the extraction of task-related\ncompact semantic representations and their accurate delivery over noisy\nchannels. In this paper, we propose an end-to-end SC system, named VideoQA-SC\nfor video question answering (VideoQA) tasks. Our goal is to accomplish VideoQA\ntasks directly based on video semantics over noisy or fading wireless channels,\nbypassing the need for video reconstruction at the receiver. To this end, we\ndevelop a spatiotemporal semantic encoder for effective video semantic\nextraction, and a learning-based bandwidth-adaptive deep joint source-channel\ncoding (DJSCC) scheme for efficient and robust video semantic transmission.\nExperiments demonstrate that VideoQA-SC outperforms traditional and advanced\nDJSCC-based SC systems that rely on video reconstruction at the receiver under\na wide range of channel conditions and bandwidth constraints. In particular,\nwhen the signal-to-noise ratio is low, VideoQA-SC can improve the answer\naccuracy by 5.17% while saving almost 99.5\\% of the bandwidth at the same time,\ncompared with the advanced DJSCC-based SC system. Our results show the great\npotential of SC system design for video applications.",
      "tldr_zh": "本论文提出 VideoQA-SC，一种自适应语义通信系统，针对视频问答（VideoQA）任务，旨在通过提取任务相关视频语义实现高效传输，而非传统的像素级重建，从而提升带宽效率和实时性能。该系统采用时空语义编码器（spatiotemporal semantic encoder）提取视频语义，并结合基于学习的带宽自适应深度联合源-信道编码（DJSCC）方案，确保在嘈杂或衰落信道上准确传输。实验结果显示，VideoQA-SC 在各种信道条件和带宽约束下优于传统 DJSCC 系统，尤其在低信噪比时，可提高答案准确率 5.17% 并节省近 99.5% 带宽，展示了语义通信（SC）在视频应用中的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18538v2",
      "published_date": "2024-05-17 06:11:10 UTC",
      "updated_date": "2025-02-11 07:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:23:59.392311"
    },
    {
      "arxiv_id": "2405.10542v1",
      "title": "Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset",
      "title_zh": "在 CFLUE 上对大型语言模型的基准测试——一个中文金融语言理解评估数据集",
      "authors": [
        "Jie Zhu",
        "Junhui Li",
        "Yalong Wen",
        "Lifan Guo"
      ],
      "abstract": "In light of recent breakthroughs in large language models (LLMs) that have\nrevolutionized natural language processing (NLP), there is an urgent need for\nnew benchmarks to keep pace with the fast development of LLMs. In this paper,\nwe propose CFLUE, the Chinese Financial Language Understanding Evaluation\nbenchmark, designed to assess the capability of LLMs across various dimensions.\nSpecifically, CFLUE provides datasets tailored for both knowledge assessment\nand application assessment. In knowledge assessment, it consists of 38K+\nmultiple-choice questions with associated solution explanations. These\nquestions serve dual purposes: answer prediction and question reasoning. In\napplication assessment, CFLUE features 16K+ test instances across distinct\ngroups of NLP tasks such as text classification, machine translation, relation\nextraction, reading comprehension, and text generation. Upon CFLUE, we conduct\na thorough evaluation of representative LLMs. The results reveal that only\nGPT-4 and GPT-4-turbo achieve an accuracy exceeding 60\\% in answer prediction\nfor knowledge assessment, suggesting that there is still substantial room for\nimprovement in current LLMs. In application assessment, although GPT-4 and\nGPT-4-turbo are the top two performers, their considerable advantage over\nlightweight LLMs is noticeably diminished. The datasets and scripts associated\nwith CFLUE are openly accessible at https://github.com/aliyun/cflue.",
      "tldr_zh": "本研究提出 CFLUE，这是一个中文金融语言理解评估基准数据集，用于评估大型语言模型 (LLMs) 在知识和应用方面的能力。CFLUE 包括 38K+ 多项选择题用于知识评估（如答案预测和问题推理），以及 16K+ 测试实例覆盖文本分类、机器翻译、关系提取、阅读理解和文本生成等 NLP 任务。在实验中，GPT-4 和 GPT-4-turbo 在知识评估中准确率超过 60%，而在应用评估中虽表现最佳，但与轻量级 LLMs 的优势显著缩小；数据集及其脚本已开源于 https://github.com/aliyun/cflue。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10542v1",
      "published_date": "2024-05-17 05:03:40 UTC",
      "updated_date": "2024-05-17 05:03:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:24:11.314795"
    },
    {
      "arxiv_id": "2405.10536v1",
      "title": "Time-Varying Constraint-Aware Reinforcement Learning for Energy Storage Control",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeik Jeong",
        "Tai-Yeon Ku",
        "Wan-Ki Park"
      ],
      "abstract": "Energy storage devices, such as batteries, thermal energy storages, and\nhydrogen systems, can help mitigate climate change by ensuring a more stable\nand sustainable power supply. To maximize the effectiveness of such energy\nstorage, determining the appropriate charging and discharging amounts for each\ntime period is crucial. Reinforcement learning is preferred over traditional\noptimization for the control of energy storage due to its ability to adapt to\ndynamic and complex environments. However, the continuous nature of charging\nand discharging levels in energy storage poses limitations for discrete\nreinforcement learning, and time-varying feasible charge-discharge range based\non state of charge (SoC) variability also limits the conventional continuous\nreinforcement learning. In this paper, we propose a continuous reinforcement\nlearning approach that takes into account the time-varying feasible\ncharge-discharge range. An additional objective function was introduced for\nlearning the feasible action range for each time period, supplementing the\nobjectives of training the actor for policy learning and the critic for value\nlearning. This actively promotes the utilization of energy storage by\npreventing them from getting stuck in suboptimal states, such as continuous\nfull charging or discharging. This is achieved through the enforcement of the\ncharging and discharging levels into the feasible action range. The\nexperimental results demonstrated that the proposed method further maximized\nthe effectiveness of energy storage by actively enhancing its utilization.",
      "tldr_zh": "本文提出了一种考虑时间变化约束的连续强化学习（Reinforcement Learning）方法，用于优化能源存储设备的充电和放电控制。该方法针对充电放电的连续性质和基于State of Charge (SoC)的可变范围，引入额外的目标函数来学习每个时间段的可行动作范围，从而补充actor（政策学习）和critic（价值学习）的训练。相比传统方法，该框架能主动防止能源存储陷入次优状态，如持续满充或放电，从而提升其利用效率。实验结果显示，该方法显著提高了能源存储的有效性，在动态环境中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 Workshop: Tackling Climate Change with Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2405.10536v1",
      "published_date": "2024-05-17 04:28:54 UTC",
      "updated_date": "2024-05-17 04:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:24:22.309881"
    },
    {
      "arxiv_id": "2405.10529v2",
      "title": "Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Sun",
        "Changsheng Wang",
        "Jiongxiao Wang",
        "Yiwei Zhang",
        "Chaowei Xiao"
      ],
      "abstract": "Large language models have become increasingly prominent, also signaling a\nshift towards multimodality as the next frontier in artificial intelligence,\nwhere their embeddings are harnessed as prompts to generate textual content.\nVision-language models (VLMs) stand at the forefront of this advancement,\noffering innovative ways to combine visual and textual data for enhanced\nunderstanding and interaction. However, this integration also enlarges the\nattack surface. Patch-based adversarial attack is considered the most realistic\nthreat model in physical vision applications, as demonstrated in many existing\nliterature. In this paper, we propose to address patched visual prompt\ninjection, where adversaries exploit adversarial patches to generate target\ncontent in VLMs. Our investigation reveals that patched adversarial prompts\nexhibit sensitivity to pixel-wise randomization, a trait that remains robust\neven against adaptive attacks designed to counteract such defenses. Leveraging\nthis insight, we introduce SmoothVLM, a defense mechanism rooted in smoothing\ntechniques, specifically tailored to protect VLMs from the threat of patched\nvisual prompt injectors. Our framework significantly lowers the attack success\nrate to a range between 0% and 5.0% on two leading VLMs, while achieving around\n67.3% to 95.0% context recovery of the benign images, demonstrating a balance\nbetween security and usability.",
      "tldr_zh": "本研究针对视觉语言模型（VLMs）面临的patch-based视觉提示注入攻击问题，提出了一种防御机制，以应对攻击者利用对抗性patches诱导模型生成目标内容。研究发现，这些攻击对像素随机化高度敏感，因此开发了SmoothVLM框架，该框架基于平滑技术来增强VLMs的安全性，同时保持模型的可用性。在两个领先的VLMs上，SmoothVLM将攻击成功率降低至0%至5.0%，并实现了67.3%至95.0%的良性图像上下文恢复，实现了安全性和可用性的有效平衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.7; I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.10529v2",
      "published_date": "2024-05-17 04:19:19 UTC",
      "updated_date": "2024-08-24 13:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:24:34.652819"
    },
    {
      "arxiv_id": "2405.10516v2",
      "title": "Language Models can Evaluate Themselves via Probability Discrepancy",
      "title_zh": "语言模型可以通过概率差异评估自身",
      "authors": [
        "Tingyu Xia",
        "Bowen Yu",
        "Yuan Wu",
        "Yi Chang",
        "Chang Zhou"
      ],
      "abstract": "In this paper, we initiate our discussion by demonstrating how Large Language\nModels (LLMs), when tasked with responding to queries, display a more even\nprobability distribution in their answers if they are more adept, as opposed to\ntheir less skilled counterparts. Expanding on this foundational insight, we\npropose a new self-evaluation method ProbDiff for assessing the efficacy of\nvarious LLMs. This approach obviates the necessity for an additional evaluation\nmodel or the dependence on external, proprietary models like GPT-4 for\njudgment. It uniquely utilizes the LLMs being tested to compute the probability\ndiscrepancy between the initial response and its revised versions. A higher\ndiscrepancy for a given query between two LLMs indicates a relatively weaker\ncapability. Our findings reveal that ProbDiff achieves results on par with\nthose obtained from evaluations based on GPT-4, spanning a range of scenarios\nthat include natural language generation (NLG) tasks such as translation,\nsummarization, and our proposed Xiaohongshu blog writing task, and benchmarks\nfor LLM evaluation like AlignBench, MT-Bench, and AlpacaEval, across LLMs of\nvarying magnitudes.",
      "tldr_zh": "本文发现，大语言模型（LLMs）在回答查询时，更熟练的模型会显示更均匀的概率分布，从而启发了一种新的自评估方法ProbDiff。ProbDiff通过计算LLMs的初始响应和其修订版本之间的probability discrepancy来评估模型效能，无需依赖外部模型如GPT-4。实验结果显示，该方法在翻译、总结等NLG任务以及AlignBench、MT-Bench和AlpacaEval等基准上的表现，与GPT-4评估相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2405.10516v2",
      "published_date": "2024-05-17 03:50:28 UTC",
      "updated_date": "2024-07-09 02:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:24:46.347012"
    },
    {
      "arxiv_id": "2405.11002v1",
      "title": "Large Language Models in Wireless Application Design: In-Context Learning-enhanced Automatic Network Intrusion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Han Zhang",
        "Akram Bin Sediq",
        "Ali Afana",
        "Melike Erol-Kantarci"
      ],
      "abstract": "Large language models (LLMs), especially generative pre-trained transformers\n(GPTs), have recently demonstrated outstanding ability in information\ncomprehension and problem-solving. This has motivated many studies in applying\nLLMs to wireless communication networks. In this paper, we propose a\npre-trained LLM-empowered framework to perform fully automatic network\nintrusion detection. Three in-context learning methods are designed and\ncompared to enhance the performance of LLMs. With experiments on a real network\nintrusion detection dataset, in-context learning proves to be highly beneficial\nin improving the task processing performance in a way that no further training\nor fine-tuning of LLMs is required. We show that for GPT-4, testing accuracy\nand F1-Score can be improved by 90%. Moreover, pre-trained LLMs demonstrate big\npotential in performing wireless communication-related tasks. Specifically, the\nproposed framework can reach an accuracy and F1-Score of over 95% on different\ntypes of attacks with GPT-4 using only 10 in-context learning examples.",
      "tldr_zh": "这篇论文提出了一种基于预训练大型语言模型(LLMs)的框架，用于无线通信网络中的自动入侵检测，通过In-Context Learning方法增强模型性能。研究设计并比较了三种In-Context Learning技术，能够显著提升任务处理效果，而无需进一步训练或微调LLMs。实验在真实数据集上表明，对于GPT-4，使用仅10个上下文学习示例，准确率和F1-Score可提高90%，并在不同攻击类型上达到超过95%的水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11002v1",
      "published_date": "2024-05-17 02:56:31 UTC",
      "updated_date": "2024-05-17 02:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:24:58.482369"
    },
    {
      "arxiv_id": "2405.10497v1",
      "title": "SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge",
      "title_zh": "SMP Challenge：社交媒体预测挑战的概述和分析",
      "authors": [
        "Bo Wu",
        "Peiye Liu",
        "Wen-Huang Cheng",
        "Bei Liu",
        "Zhaoyang Zeng",
        "Jia Wang",
        "Qiushi Huang",
        "Jiebo Luo"
      ],
      "abstract": "Social Media Popularity Prediction (SMPP) is a crucial task that involves\nautomatically predicting future popularity values of online posts, leveraging\nvast amounts of multimodal data available on social media platforms. Studying\nand investigating social media popularity becomes central to various online\napplications and requires novel methods of comprehensive analysis, multimodal\ncomprehension, and accurate prediction.\n  SMP Challenge is an annual research activity that has spurred academic\nexploration in this area. This paper summarizes the challenging task, data, and\nresearch progress. As a critical resource for evaluating and benchmarking\npredictive models, we have released a large-scale SMPD benchmark encompassing\napproximately half a million posts authored by around 70K users. The research\nprogress analysis provides an overall analysis of the solutions and trends in\nrecent years. The SMP Challenge website (www.smp-challenge.com) provides the\nlatest information and news.",
      "tldr_zh": "这篇论文概述了 Social Media Popularity Prediction (SMPP) 任务，该任务涉及利用多模态数据自动预测在线帖子未来的流行度，并强调了其在社会媒体应用中的重要性。论文总结了 SMP Challenge 年度研究活动，包括任务细节、数据集发布以及近年来解决方案的整体分析和趋势。作者发布了大规模基准数据集 SMPD，涵盖约 50 万帖子和 7 万用户，作为评估预测模型的关键资源，并提供了挑战网站 (www.smp-challenge.com) 以分享最新信息。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.SI"
      ],
      "primary_category": "cs.MM",
      "comment": "ACM Multimedia. arXiv admin note: text overlap with arXiv:1910.01795",
      "pdf_url": "http://arxiv.org/pdf/2405.10497v1",
      "published_date": "2024-05-17 02:36:14 UTC",
      "updated_date": "2024-05-17 02:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:25:10.295940"
    },
    {
      "arxiv_id": "2405.10490v3",
      "title": "Neural Optimization with Adaptive Heuristics for Intelligent Marketing System",
      "title_zh": "翻译失败",
      "authors": [
        "Changshuai Wei",
        "Benjamin Zelditch",
        "Joyce Chen",
        "Andre Assuncao Silva T Ribeiro",
        "Jingyi Kenneth Tay",
        "Borja Ocejo Elizondo",
        "Keerthi Selvaraj",
        "Aman Gupta",
        "Licurgo Benemann De Almeida"
      ],
      "abstract": "Computational marketing has become increasingly important in today's digital\nworld, facing challenges such as massive heterogeneous data, multi-channel\ncustomer journeys, and limited marketing budgets. In this paper, we propose a\ngeneral framework for marketing AI systems, the Neural Optimization with\nAdaptive Heuristics (NOAH) framework. NOAH is the first general framework for\nmarketing optimization that considers both to-business (2B) and to-consumer\n(2C) products, as well as both owned and paid channels. We describe key modules\nof the NOAH framework, including prediction, optimization, and adaptive\nheuristics, providing examples for bidding and content optimization. We then\ndetail the successful application of NOAH to LinkedIn's email marketing system,\nshowcasing significant wins over the legacy ranking system. Additionally, we\nshare details and insights that are broadly useful, particularly on: (i)\naddressing delayed feedback with lifetime value, (ii) performing large-scale\nlinear programming with randomization, (iii) improving retrieval with audience\nexpansion, (iv) reducing signal dilution in targeting tests, and (v) handling\nzero-inflated heavy-tail metrics in statistical testing.",
      "tldr_zh": "本研究针对计算营销面临的挑战（如海量异构数据、多渠道客户旅程和预算限制），提出了一种通用框架 Neural Optimization with Adaptive Heuristics (NOAH)，这是首个同时适用于 to-business (B2B) 和 to-consumer (B2C) 产品，以及自有和付费渠道的营销优化框架。NOAH 框架包括预测、优化和自适应启发式模块，并通过竞价和内容优化等示例进行了说明，在 LinkedIn 的电子邮件营销系统中实现了显著性能提升，超越了传统的排名系统。此外，该论文分享了实用见解，如使用 lifetime value 处理延迟反馈、大规模 linear programming 的随机化方法、观众扩展改进检索，以及针对 zero-inflated heavy-tail metrics 的统计测试策略。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "math.OC",
        "G.3; G.1.6; I.2"
      ],
      "primary_category": "stat.ME",
      "comment": "KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10490v3",
      "published_date": "2024-05-17 01:44:30 UTC",
      "updated_date": "2024-06-25 22:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:25:22.645756"
    },
    {
      "arxiv_id": "2405.10481v1",
      "title": "Multi-Evidence based Fact Verification via A Confidential Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Lan",
        "Zhenghao Liu",
        "Yu Gu",
        "Xiaoyuan Yi",
        "Xiaohua Li",
        "Liner Yang",
        "Ge Yu"
      ],
      "abstract": "Fact verification tasks aim to identify the integrity of textual contents\naccording to the truthful corpus. Existing fact verification models usually\nbuild a fully connected reasoning graph, which regards claim-evidence pairs as\nnodes and connects them with edges. They employ the graph to propagate the\nsemantics of the nodes. Nevertheless, the noisy nodes usually propagate their\nsemantics via the edges of the reasoning graph, which misleads the semantic\nrepresentations of other nodes and amplifies the noise signals. To mitigate the\npropagation of noisy semantic information, we introduce a Confidential Graph\nAttention Network (CO-GAT), which proposes a node masking mechanism for\nmodeling the nodes. Specifically, CO-GAT calculates the node confidence score\nby estimating the relevance between the claim and evidence pieces. Then, the\nnode masking mechanism uses the node confidence scores to control the noise\ninformation flow from the vanilla node to the other graph nodes. CO-GAT\nachieves a 73.59% FEVER score on the FEVER dataset and shows the generalization\nability by broadening the effectiveness to the science-specific domain.",
      "tldr_zh": "该研究针对事实验证任务提出了一种 Confidential Graph Attention Network (CO-GAT)，旨在通过控制噪声语义传播来提高文本内容完整性的识别准确性。现有模型在构建完全连接的推理图时，噪声节点会通过边误导其他节点的语义表示，为此 CO-GAT 引入节点掩码机制，基于声明和证据片段的相关性计算节点置信度分数，并以此调控噪声信息流。实验结果显示，CO-GAT 在 FEVER 数据集上达到 73.59% 的 FEVER 分数，并在科学特定领域表现出良好的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12pages",
      "pdf_url": "http://arxiv.org/pdf/2405.10481v1",
      "published_date": "2024-05-17 01:02:03 UTC",
      "updated_date": "2024-05-17 01:02:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:25:35.508757"
    },
    {
      "arxiv_id": "2405.10476v1",
      "title": "Analysis, Modeling and Design of Personalized Digital Learning Environment",
      "title_zh": "个性化数字学习环境的分析、建模与设计",
      "authors": [
        "Sanjaya Khanal",
        "Shiva Raj Pokhrel"
      ],
      "abstract": "This research analyzes, models and develops a novel Digital Learning\nEnvironment (DLE) fortified by the innovative Private Learning Intelligence\n(PLI) framework. The proposed PLI framework leverages federated machine\nlearning (FL) techniques to autonomously construct and continuously refine\npersonalized learning models for individual learners, ensuring robust privacy\nprotection. Our approach is pivotal in advancing DLE capabilities, empowering\nlearners to actively participate in personalized real-time learning\nexperiences. The integration of PLI within a DLE also streamlines instructional\ndesign and development demands for personalized teaching/learning. We seek ways\nto establish a foundation for the seamless integration of FL into learning\nsystems, offering a transformative approach to personalized learning in digital\nenvironments. Our implementation details and code are made public.",
      "tldr_zh": "本研究分析、建模并设计了一个新型的数字学习环境 (DLE)，通过创新的私人学习智能 (PLI) 框架来增强其功能。PLI 框架采用联邦机器学习 (FL) 技术，自动构建和持续优化个性化学习模型，同时确保学习者的隐私保护。这种方法促进了学习者参与个性化的实时学习体验，简化了教学设计，并为 FL 在数字学习系统中的无缝整合奠定了基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "IEEE Trans on Education, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10476v1",
      "published_date": "2024-05-17 00:26:16 UTC",
      "updated_date": "2024-05-17 00:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:25:47.073421"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 77,
  "processed_papers_count": 77,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T09:26:10.861097"
}