[
  {
    "arxiv_id": "2405.11120v1",
    "title": "Latent State Estimation Helps UI Agents to Reason",
    "authors": [
      "William E Bishop",
      "Alice Li",
      "Christopher Rawles",
      "Oriana Riva"
    ],
    "abstract": "A common problem for agents operating in real-world environments is that the\nresponse of an environment to their actions may be non-deterministic and\nobserved through noise. This renders environmental state and progress towards\ncompleting a task latent. Despite recent impressive demonstrations of LLM's\nreasoning abilities on various benchmarks, whether LLMs can build estimates of\nlatent state and leverage them for reasoning has not been explicitly studied.\nWe investigate this problem in the real-world domain of autonomous UI agents.\nWe establish that appropriately prompting LLMs in a zero-shot manner can be\nformally understood as forming point estimates of latent state in a textual\nspace. In the context of autonomous UI agents we then show that LLMs used in\nthis manner are more than $76\\%$ accurate at inferring various aspects of\nlatent state, such as performed (vs. commanded) actions and task progression.\nUsing both public and internal benchmarks and three reasoning methods\n(zero-shot, CoT-SC & ReAct), we show that LLM-powered agents that explicitly\nestimate and reason about latent state are able to successfully complete up to\n1.6x more tasks than those that do not.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11120v1",
    "published_date": "2024-05-17 23:27:33 UTC",
    "updated_date": "2024-05-17 23:27:33 UTC"
  },
  {
    "arxiv_id": "2405.13042v2",
    "title": "StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character Simulation via Narrative Planning",
    "authors": [
      "Yi Wang",
      "Qian Zhou",
      "David Ledo"
    ],
    "abstract": "Automated plot generation for games enhances the player's experience by\nproviding rich and immersive narrative experience that adapts to the player's\nactions. Traditional approaches adopt a symbolic narrative planning method\nwhich limits the scale and complexity of the generated plot by requiring\nextensive knowledge engineering work. Recent advancements use Large Language\nModels (LLMs) to drive the behavior of virtual characters, allowing plots to\nemerge from interactions between characters and their environments. However,\nthe emergent nature of such decentralized plot generation makes it difficult\nfor authors to direct plot progression. We propose a novel plot creation\nworkflow that mediates between a writer's authorial intent and the emergent\nbehaviors from LLM-driven character simulation, through a novel authorial\nstructure called \"abstract acts\". The writers define high-level plot outlines\nthat are later transformed into concrete character action sequences via an\nLLM-based narrative planning process, based on the game world state. The\nprocess creates \"living stories\" that dynamically adapt to various game world\nstates, resulting in narratives co-created by the author, character simulation,\nand player. We present StoryVerse as a proof-of-concept system to demonstrate\nthis plot creation workflow. We showcase the versatility of our approach with\nexamples in different stories and game environments.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Proceedings of the 19th international conference on the foundations\n  of digital games 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13042v2",
    "published_date": "2024-05-17 23:04:51 UTC",
    "updated_date": "2024-11-02 05:29:11 UTC"
  },
  {
    "arxiv_id": "2405.11109v2",
    "title": "Watermarking Language Models for Many Adaptive Users",
    "authors": [
      "Aloni Cohen",
      "Alexander Hoover",
      "Gabe Schoenbach"
    ],
    "abstract": "We study watermarking schemes for language models with provable guarantees.\nAs we show, prior works offer no robustness guarantees against adaptive\nprompting: when a user queries a language model more than once, as even benign\nusers do. And with just a single exception (Christ and Gunn, 2024), prior works\nare restricted to zero-bit watermarking: machine-generated text can be detected\nas such, but no additional information can be extracted from the watermark.\nUnfortunately, merely detecting AI-generated text may not prevent future\nabuses.\n  We introduce multi-user watermarks, which allow tracing model-generated text\nto individual users or to groups of colluding users, even in the face of\nadaptive prompting. We construct multi-user watermarking schemes from\nundetectable, adaptively robust, zero-bit watermarking schemes (and prove that\nthe undetectable zero-bit scheme of Christ, Gunn, and Zamir (2024) is\nadaptively robust). Importantly, our scheme provides both zero-bit and\nmulti-user assurances at the same time. It detects shorter snippets just as\nwell as the original scheme, and traces longer excerpts to individuals.\n  The main technical component is a construction of message-embedding\nwatermarks from zero-bit watermarks. Ours is the first generic reduction\nbetween watermarking schemes for language models. A challenge for such\nreductions is the lack of a unified abstraction for robustness -- that marked\ntext is detectable even after edits. We introduce a new unifying abstraction\ncalled AEB-robustness. AEB-robustness provides that the watermark is detectable\nwhenever the edited text \"approximates enough blocks\" of model-generated\noutput.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "39 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.11109v2",
    "published_date": "2024-05-17 22:15:30 UTC",
    "updated_date": "2024-06-28 22:15:59 UTC"
  },
  {
    "arxiv_id": "2405.11106v1",
    "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions",
    "authors": [
      "Chuanneng Sun",
      "Songjun Huang",
      "Dario Pompili"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have shown great abilities in\nvarious tasks, including question answering, arithmetic problem solving, and\npoem writing, among others. Although research on LLM-as-an-agent has shown that\nLLM can be applied to Reinforcement Learning (RL) and achieve decent results,\nthe extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as\nmany aspects, such as coordination and communication between agents, are not\nconsidered in the RL frameworks of a single agent. To inspire more research on\nLLM-based MARL, in this letter, we survey the existing LLM-based single-agent\nand multi-agent RL frameworks and provide potential research directions for\nfuture research. In particular, we focus on the cooperative tasks of multiple\nagents with a common goal and communication among them. We also consider\nhuman-in/on-the-loop scenarios enabled by the language component in the\nframework.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "8 pages, 1 figure, 1 table, submitted to IEEE RA-L",
    "pdf_url": "http://arxiv.org/pdf/2405.11106v1",
    "published_date": "2024-05-17 22:10:23 UTC",
    "updated_date": "2024-05-17 22:10:23 UTC"
  },
  {
    "arxiv_id": "2405.11100v2",
    "title": "Are Large Language Models Moral Hypocrites? A Study Based on Moral Foundations",
    "authors": [
      "Jos√© Luiz Nunes",
      "Guilherme F. C. F. Almeida",
      "Marcelo de Araujo",
      "Simone D. J. Barbosa"
    ],
    "abstract": "Large language models (LLMs) have taken centre stage in debates on Artificial\nIntelligence. Yet there remains a gap in how to assess LLMs' conformity to\nimportant human values. In this paper, we investigate whether state-of-the-art\nLLMs, GPT-4 and Claude 2.1 (Gemini Pro and LLAMA 2 did not generate valid\nresults) are moral hypocrites. We employ two research instruments based on the\nMoral Foundations Theory: (i) the Moral Foundations Questionnaire (MFQ), which\ninvestigates which values are considered morally relevant in abstract moral\njudgements; and (ii) the Moral Foundations Vignettes (MFVs), which evaluate\nmoral cognition in concrete scenarios related to each moral foundation. We\ncharacterise conflicts in values between these different abstractions of moral\nevaluation as hypocrisy. We found that both models displayed reasonable\nconsistency within each instrument compared to humans, but they displayed\ncontradictory and hypocritical behaviour when we compared the abstract values\npresent in the MFQ to the evaluation of concrete moral violations of the MFV.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Final version available at:\n  https://ojs.aaai.org/index.php/AIES/article/view/31704 13 pages, 4 figures, 2\n  tables",
    "pdf_url": "http://arxiv.org/pdf/2405.11100v2",
    "published_date": "2024-05-17 21:27:32 UTC",
    "updated_date": "2024-10-22 00:02:28 UTC"
  },
  {
    "arxiv_id": "2405.19346v2",
    "title": "Subject-Adaptive Transfer Learning Using Resting State EEG Signals for Cross-Subject EEG Motor Imagery Classification",
    "authors": [
      "Sion An",
      "Myeongkyun Kang",
      "Soopil Kim",
      "Philip Chikontwe",
      "Li Shen",
      "Sang Hyun Park"
    ],
    "abstract": "Electroencephalography (EEG) motor imagery (MI) classification is a\nfundamental, yet challenging task due to the variation of signals between\nindividuals i.e., inter-subject variability. Previous approaches try to\nmitigate this using task-specific (TS) EEG signals from the target subject in\ntraining. However, recording TS EEG signals requires time and limits its\napplicability in various fields. In contrast, resting state (RS) EEG signals\nare a viable alternative due to ease of acquisition with rich subject\ninformation. In this paper, we propose a novel subject-adaptive transfer\nlearning strategy that utilizes RS EEG signals to adapt models on unseen\nsubject data. Specifically, we disentangle extracted features into task- and\nsubject-dependent features and use them to calibrate RS EEG signals for\nobtaining task information while preserving subject characteristics. The\ncalibrated signals are then used to adapt the model to the target subject,\nenabling the model to simulate processing TS EEG signals of the target subject.\nThe proposed method achieves state-of-the-art accuracy on three public\nbenchmarks, demonstrating the effectiveness of our method in cross-subject EEG\nMI classification. Our findings highlight the potential of leveraging RS EEG\nsignals to advance practical brain-computer interface systems. The code is\navailable at https://github.com/SionAn/MICCAI2024-ResTL.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Early Accepted at MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19346v2",
    "published_date": "2024-05-17 20:36:04 UTC",
    "updated_date": "2024-07-09 14:30:24 UTC"
  },
  {
    "arxiv_id": "2405.15802v1",
    "title": "Towards a Framework for Openness in Foundation Models: Proceedings from the Columbia Convening on Openness in Artificial Intelligence",
    "authors": [
      "Adrien Basdevant",
      "Camille Fran√ßois",
      "Victor Storchan",
      "Kevin Bankston",
      "Ayah Bdeir",
      "Brian Behlendorf",
      "Merouane Debbah",
      "Sayash Kapoor",
      "Yann LeCun",
      "Mark Surman",
      "Helen King-Turvey",
      "Nathan Lambert",
      "Stefano Maffulli",
      "Nik Marda",
      "Govind Shivkumar",
      "Justine Tunney"
    ],
    "abstract": "Over the past year, there has been a robust debate about the benefits and\nrisks of open sourcing foundation models. However, this discussion has often\ntaken place at a high level of generality or with a narrow focus on specific\ntechnical attributes. In part, this is because defining open source for\nfoundation models has proven tricky, given its significant differences from\ntraditional software development. In order to inform more practical and nuanced\ndecisions about opening AI systems, including foundation models, this paper\npresents a framework for grappling with openness across the AI stack. It\nsummarizes previous work on this topic, analyzes the various potential reasons\nto pursue openness, and outlines how openness varies in different parts of the\nAI stack, both at the model and at the system level. In doing so, its authors\nhope to provide a common descriptive framework to deepen a nuanced and rigorous\nunderstanding of openness in AI and enable further work around definitions of\nopenness and safety in AI.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15802v1",
    "published_date": "2024-05-17 20:35:39 UTC",
    "updated_date": "2024-05-17 20:35:39 UTC"
  },
  {
    "arxiv_id": "2405.11070v1",
    "title": "Jill Watson: A Virtual Teaching Assistant powered by ChatGPT",
    "authors": [
      "Karan Taneja",
      "Pratyusha Maiti",
      "Sandeep Kakar",
      "Pranav Guruprasad",
      "Sanjeev Rao",
      "Ashok K. Goel"
    ],
    "abstract": "Conversational AI agents often require extensive datasets for training that\nare not publicly released, are limited to social chit-chat or handling a\nspecific domain, and may not be easily extended to accommodate the latest\nadvances in AI technologies. This paper introduces Jill Watson, a\nconversational Virtual Teaching Assistant (VTA) leveraging the capabilities of\nChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a\nmodular design to allow the integration of new APIs using a skill-based\narchitecture inspired by XiaoIce. Jill Watson is also well-suited for\nintelligent textbooks as it can process and converse using multiple large\ndocuments. We exclusively utilize publicly available resources for\nreproducibility and extensibility. Comparative analysis shows that our system\noutperforms the legacy knowledge-based Jill Watson as well as the OpenAI\nAssistants service. We employ many safety measures that reduce instances of\nhallucinations and toxicity. The paper also includes real-world examples from a\nclassroom setting that demonstrate different features of Jill Watson and its\neffectiveness.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11070v1",
    "published_date": "2024-05-17 19:55:57 UTC",
    "updated_date": "2024-05-17 19:55:57 UTC"
  },
  {
    "arxiv_id": "2405.11067v3",
    "title": "Bayesian Learning-driven Prototypical Contrastive Loss for Class-Incremental Learning",
    "authors": [
      "Nisha L. Raichur",
      "Lucas Heublein",
      "Tobias Feigl",
      "Alexander R√ºgamer",
      "Christopher Mutschler",
      "Felix Ott"
    ],
    "abstract": "The primary objective of methods in continual learning is to learn tasks in a\nsequential manner over time (sometimes from a stream of data), while mitigating\nthe detrimental phenomenon of catastrophic forgetting. This paper proposes a\nmethod to learn an effective representation between previous and newly\nencountered class prototypes. We propose a prototypical network with a Bayesian\nlearning-driven contrastive loss (BLCL), tailored specifically for\nclass-incremental learning scenarios. We introduce a contrastive loss that\nincorporates novel classes into the latent representation by reducing\nintra-class and increasing inter-class distance. Our approach dynamically\nadapts the balance between the cross-entropy and contrastive loss functions\nwith a Bayesian learning technique. Experimental results conducted on the\nCIFAR-10, CIFAR-100, and ImageNet100 datasets for image classification and\nimages of a GNSS-based dataset for interference classification validate the\nefficacy of our method, showcasing its superiority over existing\nstate-of-the-art approaches. Git:\nhttps://gitlab.cc-asp.fraunhofer.de/darcy_gnss/gnss_class_incremental_learning",
    "categories": [
      "cs.CV",
      "cs.AI",
      "62P30, 68T30, 68T05, 68T37",
      "G.3; I.2.4; I.2.6"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.11067v3",
    "published_date": "2024-05-17 19:49:02 UTC",
    "updated_date": "2025-03-31 13:04:03 UTC"
  },
  {
    "arxiv_id": "2405.11055v3",
    "title": "Leveraging Discourse Structure for Extractive Meeting Summarization",
    "authors": [
      "Virgile Rennard",
      "Guokan Shang",
      "Michalis Vazirgiannis",
      "Julie Hunter"
    ],
    "abstract": "We introduce an extractive summarization system for meetings that leverages\ndiscourse structure to better identify salient information from complex\nmulti-party discussions. Using discourse graphs to represent semantic relations\nbetween the contents of utterances in a meeting, we train a GNN-based node\nclassification model to select the most important utterances, which are then\ncombined to create an extractive summary. Experimental results on AMI and ICSI\ndemonstrate that our approach surpasses existing text-based and graph-based\nextractive summarization systems, as measured by both classification and\nsummarization metrics. Additionally, we conduct ablation studies on discourse\nstructure and relation type to provide insights for future NLP applications\nleveraging discourse analysis theory.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11055v3",
    "published_date": "2024-05-17 19:06:20 UTC",
    "updated_date": "2024-09-23 08:19:13 UTC"
  },
  {
    "arxiv_id": "2405.11053v3",
    "title": "The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems",
    "authors": [
      "Guy Aridor",
      "Duarte Goncalves",
      "Ruoyan Kong",
      "Daniel Kluver",
      "Joseph Konstan"
    ],
    "abstract": "An increasingly important aspect of designing recommender systems involves\nconsidering how recommendations will influence consumer choices. This paper\naddresses this issue by introducing a method for collecting user beliefs about\nun-experienced items - a critical predictor of choice behavior. We implemented\nthis method on the MovieLens platform, resulting in a rich dataset that\ncombines user ratings, beliefs, and observed recommendations. We document\nchallenges to such data collection, including selection bias in response and\nlimited coverage of the product space. This unique resource empowers\nresearchers to delve deeper into user behavior and analyze user choices absent\nrecommendations, measure the effectiveness of recommendations, and prototype\nalgorithms that leverage user belief data, ultimately leading to more impactful\nrecommender systems. The dataset can be found at\nhttps://grouplens.org/datasets/movielens/ml_belief_2024/.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "To Appear in RecSys 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.11053v3",
    "published_date": "2024-05-17 19:06:06 UTC",
    "updated_date": "2024-08-02 13:26:44 UTC"
  },
  {
    "arxiv_id": "2405.11029v1",
    "title": "Generative Artificial Intelligence: A Systematic Review and Applications",
    "authors": [
      "Sandeep Singh Sengar",
      "Affan Bin Hasan",
      "Sanjay Kumar",
      "Fiona Carroll"
    ],
    "abstract": "In recent years, the study of artificial intelligence (AI) has undergone a\nparadigm shift. This has been propelled by the groundbreaking capabilities of\ngenerative models both in supervised and unsupervised learning scenarios.\nGenerative AI has shown state-of-the-art performance in solving perplexing\nreal-world conundrums in fields such as image translation, medical diagnostics,\ntextual imagery fusion, natural language processing, and beyond. This paper\ndocuments the systematic review and analysis of recent advancements and\ntechniques in Generative AI with a detailed discussion of their applications\nincluding application-specific models. Indeed, the major impact that generative\nAI has made to date, has been in language generation with the development of\nlarge language models, in the field of image translation and several other\ninterdisciplinary applications of generative AI. Moreover, the primary\ncontribution of this paper lies in its coherent synthesis of the latest\nadvancements in these areas, seamlessly weaving together contemporary\nbreakthroughs in the field. Particularly, how it shares an exploration of the\nfuture trajectory for generative AI. In conclusion, the paper ends with a\ndiscussion of Responsible AI principles, and the necessary ethical\nconsiderations for the sustainability and growth of these generative models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11029v1",
    "published_date": "2024-05-17 18:03:59 UTC",
    "updated_date": "2024-05-17 18:03:59 UTC"
  },
  {
    "arxiv_id": "2405.11024v1",
    "title": "GraSS: Combining Graph Neural Networks with Expert Knowledge for SAT Solver Selection",
    "authors": [
      "Zhanguang Zhang",
      "Didier Chetelat",
      "Joseph Cotnareanu",
      "Amur Ghose",
      "Wenyi Xiao",
      "Hui-Ling Zhen",
      "Yingxue Zhang",
      "Jianye Hao",
      "Mark Coates",
      "Mingxuan Yuan"
    ],
    "abstract": "Boolean satisfiability (SAT) problems are routinely solved by SAT solvers in\nreal-life applications, yet solving time can vary drastically between solvers\nfor the same instance. This has motivated research into machine learning models\nthat can predict, for a given SAT instance, which solver to select among\nseveral options. Existing SAT solver selection methods all rely on some\nhand-picked instance features, which are costly to compute and ignore the\nstructural information in SAT graphs. In this paper we present GraSS, a novel\napproach for automatic SAT solver selection based on tripartite graph\nrepresentations of instances and a heterogeneous graph neural network (GNN)\nmodel. While GNNs have been previously adopted in other SAT-related tasks, they\ndo not incorporate any domain-specific knowledge and ignore the runtime\nvariation introduced by different clause orders. We enrich the graph\nrepresentation with domain-specific decisions, such as novel node feature\ndesign, positional encodings for clauses in the graph, a GNN architecture\ntailored to our tripartite graphs and a runtime-sensitive loss function.\nThrough extensive experiments, we demonstrate that this combination of raw\nrepresentations and domain-specific choices leads to improvements in runtime\nfor a pool of seven state-of-the-art solvers on both an industrial circuit\ndesign benchmark, and on instances from the 20-year Anniversary Track of the\n2022 SAT Competition.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.11024v1",
    "published_date": "2024-05-17 18:00:50 UTC",
    "updated_date": "2024-05-17 18:00:50 UTC"
  },
  {
    "arxiv_id": "2405.10939v1",
    "title": "DINO as a von Mises-Fisher mixture model",
    "authors": [
      "Hariprasath Govindarajan",
      "Per Sid√©n",
      "Jacob Roll",
      "Fredrik Lindsten"
    ],
    "abstract": "Self-distillation methods using Siamese networks are popular for\nself-supervised pre-training. DINO is one such method based on a cross-entropy\nloss between $K$-dimensional probability vectors, obtained by applying a\nsoftmax function to the dot product between representations and learnt\nprototypes. Given the fact that the learned representations are\n$L^2$-normalized, we show that DINO and its derivatives, such as iBOT, can be\ninterpreted as a mixture model of von Mises-Fisher components. With this\ninterpretation, DINO assumes equal precision for all components when the\nprototypes are also $L^2$-normalized. Using this insight we propose DINO-vMF,\nthat adds appropriate normalization constants when computing the cluster\nassignment probabilities. Unlike DINO, DINO-vMF is stable also for the larger\nViT-Base model with unnormalized prototypes. We show that the added flexibility\nof the mixture model is beneficial in terms of better image representations.\nThe DINO-vMF pre-trained model consistently performs better than DINO on a\nrange of downstream tasks. We obtain similar improvements for iBOT-vMF vs iBOT\nand thereby show the relevance of our proposed modification also for other\nmethods derived from DINO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.10939v1",
    "published_date": "2024-05-17 17:49:45 UTC",
    "updated_date": "2024-05-17 17:49:45 UTC"
  },
  {
    "arxiv_id": "2405.10938v3",
    "title": "Observational Scaling Laws and the Predictability of Language Model Performance",
    "authors": [
      "Yangjun Ruan",
      "Chris J. Maddison",
      "Tatsunori Hashimoto"
    ],
    "abstract": "Understanding how language model performance varies with scale is critical to\nbenchmark and algorithm development. Scaling laws are one approach to building\nthis understanding, but the requirement of training models across many\ndifferent scales has limited their use. We propose an alternative,\nobservational approach that bypasses model training and instead builds scaling\nlaws from ~100 publically available models. Building a single scaling law from\nmultiple model families is challenging due to large variations in their\ntraining compute efficiencies and capabilities. However, we show that these\nvariations are consistent with a simple, generalized scaling law where language\nmodel performance is a function of a low-dimensional capability space, and\nmodel families only vary in their efficiency in converting training compute to\ncapabilities. Using this approach, we show the surprising predictability of\ncomplex scaling phenomena: we show that several emergent phenomena follow a\nsmooth, sigmoidal behavior and are predictable from small models; we show that\nthe agent performance of models such as GPT-4 can be precisely predicted from\nsimpler non-agentic benchmarks; and we show how to predict the impact of\npost-training interventions like Chain-of-Thought and Self-Consistency as\nlanguage model capabilities continue to improve.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024 as a spotlight",
    "pdf_url": "http://arxiv.org/pdf/2405.10938v3",
    "published_date": "2024-05-17 17:49:44 UTC",
    "updated_date": "2024-10-01 23:38:10 UTC"
  },
  {
    "arxiv_id": "2405.10936v2",
    "title": "A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers",
    "authors": [
      "Kaiyu Huang",
      "Fengran Mo",
      "Xinyu Zhang",
      "Hongliang Li",
      "You Li",
      "Yuanchi Zhang",
      "Weijian Yi",
      "Yulong Mao",
      "Jinchen Liu",
      "Yuzhuang Xu",
      "Jinan Xu",
      "Jian-Yun Nie",
      "Yang Liu"
    ],
    "abstract": "The rapid development of Large Language Models (LLMs) demonstrates remarkable\nmultilingual capabilities in natural language processing, attracting global\nattention in both academia and industry. To mitigate potential discrimination\nand enhance the overall usability and accessibility for diverse language user\ngroups, it is important for the development of language-fair technology.\nDespite the breakthroughs of LLMs, the investigation into the multilingual\nscenario remains insufficient, where a comprehensive survey to summarize recent\napproaches, developments, limitations, and potential solutions is desirable. To\nthis end, we provide a survey with multiple perspectives on the utilization of\nLLMs in the multilingual scenario. We first rethink the transitions between\nprevious and current research on pre-trained language models. Then we introduce\nseveral perspectives on the multilingualism of LLMs, including training and\ninference methods, information retrieval, model security, multi-domain with\nlanguage culture, and usage of datasets. We also discuss the major challenges\nthat arise in these aspects, along with possible solutions. Besides, we\nhighlight future research directions that aim at further enhancing LLMs with\nmultilingualism. The survey aims to help the research community address\nmultilingual problems and provide a comprehensive understanding of the core\nconcepts, key techniques, and latest developments in multilingual natural\nlanguage processing based on LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "65 pages, Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2405.10936v2",
    "published_date": "2024-05-17 17:47:39 UTC",
    "updated_date": "2025-01-07 12:15:01 UTC"
  },
  {
    "arxiv_id": "2405.10925v1",
    "title": "High-dimensional multiple imputation (HDMI) for partially observed confounders including natural language processing-derived auxiliary covariates",
    "authors": [
      "Janick Weberpals",
      "Pamela A. Shaw",
      "Kueiyu Joshua Lin",
      "Richard Wyss",
      "Joseph M Plasek",
      "Li Zhou",
      "Kerry Ngan",
      "Thomas DeRamus",
      "Sudha R. Raman",
      "Bradley G. Hammill",
      "Hana Lee",
      "Sengwee Toh",
      "John G. Connolly",
      "Kimberly J. Dandreo",
      "Fang Tian",
      "Wei Liu",
      "Jie Li",
      "Jos√© J. Hern√°ndez-Mu√±oz",
      "Sebastian Schneeweiss",
      "Rishi J. Desai"
    ],
    "abstract": "Multiple imputation (MI) models can be improved by including auxiliary\ncovariates (AC), but their performance in high-dimensional data is not well\nunderstood. We aimed to develop and compare high-dimensional MI (HDMI)\napproaches using structured and natural language processing (NLP)-derived AC in\nstudies with partially observed confounders. We conducted a plasmode simulation\nstudy using data from opioid vs. non-steroidal anti-inflammatory drug (NSAID)\ninitiators (X) with observed serum creatinine labs (Z2) and time-to-acute\nkidney injury as outcome. We simulated 100 cohorts with a null treatment\neffect, including X, Z2, atrial fibrillation (U), and 13 other\ninvestigator-derived confounders (Z1) in the outcome generation. We then\nimposed missingness (MZ2) on 50% of Z2 measurements as a function of Z2 and U\nand created different HDMI candidate AC using structured and NLP-derived\nfeatures. We mimicked scenarios where U was unobserved by omitting it from all\nAC candidate sets. Using LASSO, we data-adaptively selected HDMI covariates\nassociated with Z2 and MZ2 for MI, and with U to include in propensity score\nmodels. The treatment effect was estimated following propensity score matching\nin MI datasets and we benchmarked HDMI approaches against a baseline imputation\nand complete case analysis with Z1 only. HDMI using claims data showed the\nlowest bias (0.072). Combining claims and sentence embeddings led to an\nimprovement in the efficiency displaying the lowest root-mean-squared-error\n(0.173) and coverage (94%). NLP-derived AC alone did not perform better than\nbaseline MI. HDMI approaches may decrease bias in studies with partially\nobserved confounders where missingness depends on unobserved factors.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10925v1",
    "published_date": "2024-05-17 17:24:52 UTC",
    "updated_date": "2024-05-17 17:24:52 UTC"
  },
  {
    "arxiv_id": "2405.10918v2",
    "title": "A Framework for Leveraging Partially-Labeled Data for Product Attribute-Value Identification",
    "authors": [
      "D. Subhalingam",
      "Keshav Kolluru",
      "Mausam",
      "Saurabh Singal"
    ],
    "abstract": "In the e-commerce domain, the accurate extraction of attribute-value pairs\n(e.g., Brand: Apple) from product titles and user search queries is crucial for\nenhancing search and recommendation systems. A major challenge with neural\nmodels for this task is the lack of high-quality training data, as the\nannotations for attribute-value pairs in the available datasets are often\nincomplete. To address this, we introduce GenToC, a model designed for training\ndirectly with partially-labeled data, eliminating the necessity for a fully\nannotated dataset. GenToC employs a marker-augmented generative model to\nidentify potential attributes, followed by a token classification model that\ndetermines the associated values for each attribute. GenToC outperforms\nexisting state-of-the-art models, exhibiting upto 56.3% increase in the number\nof accurate extractions. Furthermore, we utilize GenToC to regenerate the\ntraining dataset to expand attribute-value annotations. This bootstrapping\nsubstantially improves the data quality for training other standard NER models,\nwhich are typically faster but less capable in handling partially-labeled data,\nenabling them to achieve comparable performance to GenToC. Our results\ndemonstrate GenToC's unique ability to learn from a limited set of\npartially-labeled data and improve the training of more efficient models,\nadvancing the automated extraction of attribute-value pairs. Finally, our model\nhas been successfully integrated into IndiaMART, India's largest B2B e-commerce\nplatform, achieving a significant increase of 20.2% in the number of correctly\nidentified attribute-value pairs over the existing deployed system while\nachieving a high precision of 89.5%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to KDD 2025 ADS Track",
    "pdf_url": "http://arxiv.org/pdf/2405.10918v2",
    "published_date": "2024-05-17 17:09:45 UTC",
    "updated_date": "2024-11-18 06:50:30 UTC"
  },
  {
    "arxiv_id": "2405.12241v2",
    "title": "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning",
    "authors": [
      "Dan Braun",
      "Jordan Taylor",
      "Nicholas Goldowsky-Dill",
      "Lee Sharkey"
    ],
    "abstract": "Identifying the features learned by neural networks is a core challenge in\nmechanistic interpretability. Sparse autoencoders (SAEs), which learn a sparse,\novercomplete dictionary that reconstructs a network's internal activations,\nhave been used to identify these features. However, SAEs may learn more about\nthe structure of the datatset than the computational structure of the network.\nThere is therefore only indirect reason to believe that the directions found in\nthese dictionaries are functionally important to the network. We propose\nend-to-end (e2e) sparse dictionary learning, a method for training SAEs that\nensures the features learned are functionally important by minimizing the KL\ndivergence between the output distributions of the original model and the model\nwith SAE activations inserted. Compared to standard SAEs, e2e SAEs offer a\nPareto improvement: They explain more network performance, require fewer total\nfeatures, and require fewer simultaneously active features per datapoint, all\nwith no cost to interpretability. We explore geometric and qualitative\ndifferences between e2e SAE features and standard SAE features. E2e dictionary\nlearning brings us closer to methods that can explain network behavior\nconcisely and accurately. We release our library for training e2e SAEs and\nreproducing our analysis at https://github.com/ApolloResearch/e2e_sae",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12241v2",
    "published_date": "2024-05-17 17:03:46 UTC",
    "updated_date": "2024-05-24 13:16:32 UTC"
  },
  {
    "arxiv_id": "2405.11013v1",
    "title": "ARDDQN: Attention Recurrent Double Deep Q-Network for UAV Coverage Path Planning and Data Harvesting",
    "authors": [
      "Praveen Kumar",
      "Priyadarshni",
      "Rajiv Misra"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) have gained popularity in data harvesting\n(DH) and coverage path planning (CPP) to survey a given area efficiently and\ncollect data from aerial perspectives, while data harvesting aims to gather\ninformation from various Internet of Things (IoT) sensor devices, coverage path\nplanning guarantees that every location within the designated area is visited\nwith minimal redundancy and maximum efficiency. We propose the ARDDQN\n(Attention-based Recurrent Double Deep Q Network), which integrates double deep\nQ-networks (DDQN) with recurrent neural networks (RNNs) and an attention\nmechanism to generate path coverage choices that maximize data collection from\nIoT devices and to learn a control scheme for the UAV that generalizes energy\nrestrictions. We employ a structured environment map comprising a compressed\nglobal environment map and a local map showing the UAV agent's locate\nefficiently scaling to large environments. We have compared Long short-term\nmemory (LSTM), Bi-directional long short-term memory (Bi-LSTM), Gated recurrent\nunit (GRU) and Bidirectional gated recurrent unit (Bi-GRU) as recurrent neural\nnetworks (RNN) to the result without RNN We propose integrating the LSTM with\nthe Attention mechanism to the existing DDQN model, which works best on\nevolution parameters, i.e., data collection, landing, and coverage ratios for\nthe CPP and data harvesting scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11013v1",
    "published_date": "2024-05-17 16:53:19 UTC",
    "updated_date": "2024-05-17 16:53:19 UTC"
  },
  {
    "arxiv_id": "2405.10893v1",
    "title": "COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain",
    "authors": [
      "Dimitrios P. Panagoulias",
      "Persephone Papatheodosiou",
      "Anastasios P. Palamidas",
      "Mattheos Sanoudos",
      "Evridiki Tsoureli-Nikita",
      "Maria Virvou",
      "George A. Tsihrintzis"
    ],
    "abstract": "Large Language Models (LLMs) constitute a breakthrough state-of-the-art\nArtificial Intelligence (AI) technology which is rapidly evolving and promises\nto aid in medical diagnosis either by assisting doctors or by simulating a\ndoctor's workflow in more advanced and complex implementations. In this\ntechnical paper, we outline Cognitive Network Evaluation Toolkit for Medical\nDomains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in\nthe medical domain. Specifically, we propose a scoring-framework with increased\ndifficulty to assess the ability of LLMs in interpreting medical text. The\nproposed framework is accompanied with a database of Multiple Choice Quizzes\n(MCQs). To ensure alignment with current medical trends and enhance safety,\nusefulness, and applicability, these MCQs have been constructed in\ncollaboration with several associated medical experts in various medical\ndomains and are characterized by varying degrees of difficulty. The current\n(first) version of the database includes the medical domains of Psychiatry,\nDentistry, Pulmonology, Dermatology and Endocrinology, but it will be\ncontinuously extended and expanded to include additional medical domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Paper",
    "pdf_url": "http://arxiv.org/pdf/2405.10893v1",
    "published_date": "2024-05-17 16:31:56 UTC",
    "updated_date": "2024-05-17 16:31:56 UTC"
  },
  {
    "arxiv_id": "2405.10890v1",
    "title": "A Versatile Framework for Analyzing Galaxy Image Data by Implanting Human-in-the-loop on a Large Vision Model",
    "authors": [
      "Mingxiang Fu",
      "Yu Song",
      "Jiameng Lv",
      "Liang Cao",
      "Peng Jia",
      "Nan Li",
      "Xiangru Li",
      "Jifeng Liu",
      "A-Li Luo",
      "Bo Qiu",
      "Shiyin Shen",
      "Liangping Tu",
      "Lili Wang",
      "Shoulin Wei",
      "Haifeng Yang",
      "Zhenping Yi",
      "Zhiqiang Zou"
    ],
    "abstract": "The exponential growth of astronomical datasets provides an unprecedented\nopportunity for humans to gain insight into the Universe. However, effectively\nanalyzing this vast amount of data poses a significant challenge. Astronomers\nare turning to deep learning techniques to address this, but the methods are\nlimited by their specific training sets, leading to considerable duplicate\nworkloads too. Hence, as an example to present how to overcome the issue, we\nbuilt a framework for general analysis of galaxy images, based on a large\nvision model (LVM) plus downstream tasks (DST), including galaxy morphological\nclassification, image restoration, object detection, parameter extraction, and\nmore. Considering the low signal-to-noise ratio of galaxy images and the\nimbalanced distribution of galaxy categories, we have incorporated a\nHuman-in-the-loop (HITL) module into our large vision model, which leverages\nhuman knowledge to enhance the reliability and interpretability of processing\ngalaxy images interactively. The proposed framework exhibits notable few-shot\nlearning capabilities and versatile adaptability to all the abovementioned\ntasks on galaxy images in the DESI legacy imaging surveys. Expressly, for\nobject detection, trained by 1000 data points, our DST upon the LVM achieves an\naccuracy of 96.7%, while ResNet50 plus Mask R-CNN gives an accuracy of 93.1%;\nfor morphology classification, to obtain AUC ~0.9, LVM plus DST and HITL only\nrequests 1/50 training sets compared to ResNet18. Expectedly, multimodal data\ncan be integrated similarly, which opens up possibilities for conducting joint\nanalyses with datasets spanning diverse domains in the era of multi-message\nastronomy.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.GA",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "26 pages, 10 figures, to be published on Chinese Physics C",
    "pdf_url": "http://arxiv.org/pdf/2405.10890v1",
    "published_date": "2024-05-17 16:29:27 UTC",
    "updated_date": "2024-05-17 16:29:27 UTC"
  },
  {
    "arxiv_id": "2405.10883v2",
    "title": "Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: A Systematic Scoping Review",
    "authors": [
      "Hongyi Yang",
      "Fangyuan Chang",
      "Dian Zhu",
      "Muroi Fumie",
      "Zhao Liu"
    ],
    "abstract": "This systematic review assessed the current state and future prospects of\nartificial intelligence (AI) in schizophrenia rehabilitation management. We\nreviewed 61 studies on AI-related data types, feature engineering methods,\nalgorithmic models, and evaluation metrics published from 2012-2024. The review\ncategorizes AI applications into the following key application areas: symptom\nmonitoring, medication management, risk management, functional training, and\npsychosocial support. Findings indicate that supervised machine learning\ntechniques, particularly for symptom monitoring and relapse risk management,\nremain the predominant approaches, effectively leveraging structured data while\nincorporating interpretable algorithms. This study underscores the potential of\nAI in transforming long-term management strategies for schizophrenia, offering\nvaluable insights into improving the quality of life of patients. Future\nresearch should focus on expanding data sources through multimodal data\nintegration, exploring deep learning models, and integrating AI-driven\ninterventions into training tasks to fully capitalize on AI's potential in\nschizophrenia rehabilitation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10883v2",
    "published_date": "2024-05-17 16:20:34 UTC",
    "updated_date": "2025-01-25 05:18:29 UTC"
  },
  {
    "arxiv_id": "2405.10877v1",
    "title": "WEITS: A Wavelet-enhanced residual framework for interpretable time series forecasting",
    "authors": [
      "Ziyou Guo",
      "Yan Sun",
      "Tieru Wu"
    ],
    "abstract": "Time series (TS) forecasting has been an unprecedentedly popular problem in\nrecent years, with ubiquitous applications in both scientific and business\nfields. Various approaches have been introduced to time series analysis,\nincluding both statistical approaches and deep neural networks. Although neural\nnetwork approaches have illustrated stronger ability of representation than\nstatistical methods, they struggle to provide sufficient interpretablility, and\ncan be too complicated to optimize. In this paper, we present WEITS, a\nfrequency-aware deep learning framework that is highly interpretable and\ncomputationally efficient. Through multi-level wavelet decomposition, WEITS\nnovelly infuses frequency analysis into a highly deep learning framework.\nCombined with a forward-backward residual architecture, it enjoys both high\nrepresentation capability and statistical interpretability. Extensive\nexperiments on real-world datasets have demonstrated competitive performance of\nour model, along with its additional advantage of high computation efficiency.\nFurthermore, WEITS provides a general framework that can always seamlessly\nintegrate with state-of-the-art approaches for time series forecast.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2310.09488 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2405.10877v1",
    "published_date": "2024-05-17 16:09:51 UTC",
    "updated_date": "2024-05-17 16:09:51 UTC"
  },
  {
    "arxiv_id": "2405.10861v2",
    "title": "Tailoring Vaccine Messaging with Common-Ground Opinions",
    "authors": [
      "Rickard Stureborg",
      "Sanxing Chen",
      "Ruoyu Xie",
      "Aayushi Patel",
      "Christopher Li",
      "Chloe Qinyu Zhu",
      "Tingnan Hu",
      "Jun Yang",
      "Bhuwan Dhingra"
    ],
    "abstract": "One way to personalize chatbot interactions is by establishing common ground\nwith the intended reader. A domain where establishing mutual understanding\ncould be particularly impactful is vaccine concerns and misinformation. Vaccine\ninterventions are forms of messaging which aim to answer concerns expressed\nabout vaccination. Tailoring responses in this domain is difficult, since\nopinions often have seemingly little ideological overlap. We define the task of\ntailoring vaccine interventions to a Common-Ground Opinion (CGO). Tailoring\nresponses to a CGO involves meaningfully improving the answer by relating it to\nan opinion or belief the reader holds. In this paper we introduce TAILOR-CGO, a\ndataset for evaluating how well responses are tailored to provided CGOs. We\nbenchmark several major LLMs on this task; finding GPT-4-Turbo performs\nsignificantly better than others. We also build automatic evaluation metrics,\nincluding an efficient and accurate BERT model that outperforms finetuned LLMs,\ninvestigate how to successfully tailor vaccine messaging to CGOs, and provide\nactionable recommendations from this investigation.\n  Code and model weights: https://github.com/rickardstureborg/tailor-cgo\nDataset: https://huggingface.co/datasets/DukeNLP/tailor-cgo",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "68T50 (Primary) 68T01, 68T37, 91F20 (Secondary)",
      "I.2; I.2.7; I.7"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10861v2",
    "published_date": "2024-05-17 15:48:30 UTC",
    "updated_date": "2024-07-24 00:10:04 UTC"
  },
  {
    "arxiv_id": "2405.13041v3",
    "title": "Assessing Political Bias in Large Language Models",
    "authors": [
      "Luca Rettenberger",
      "Markus Reischl",
      "Mark Schutera"
    ],
    "abstract": "The assessment of bias within Large Language Models (LLMs) has emerged as a\ncritical concern in the contemporary discourse surrounding Artificial\nIntelligence (AI) in the context of their potential impact on societal\ndynamics. Recognizing and considering political bias within LLM applications is\nespecially important when closing in on the tipping point toward performative\nprediction. Then, being educated about potential effects and the societal\nbehavior LLMs can drive at scale due to their interplay with human operators.\nIn this way, the upcoming elections of the European Parliament will not remain\nunaffected by LLMs. We evaluate the political bias of the currently most\npopular open-source LLMs (instruct or assistant models) concerning political\nissues within the European Union (EU) from a German voter's perspective. To do\nso, we use the \"Wahl-O-Mat,\" a voting advice application used in Germany. From\nthe voting advice of the \"Wahl-O-Mat\" we quantize the degree of alignment of\nLLMs with German political parties. We show that larger models, such as\nLlama3-70B, tend to align more closely with left-leaning political parties,\nwhile smaller models often remain neutral, particularly when prompted in\nEnglish. The central finding is that LLMs are similarly biased, with low\nvariances in the alignment concerning a specific party. Our findings underline\nthe importance of rigorously assessing and making bias transparent in LLMs to\nsafeguard the integrity and trustworthiness of applications that employ the\ncapabilities of performative prediction and the invisible hand of machine\nlearning prediction and language generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13041v3",
    "published_date": "2024-05-17 15:30:18 UTC",
    "updated_date": "2024-06-05 05:48:27 UTC"
  },
  {
    "arxiv_id": "2405.10853v3",
    "title": "The Future of Large Language Model Pre-training is Federated",
    "authors": [
      "Lorenzo Sani",
      "Alex Iacob",
      "Zeyu Cao",
      "Bill Marino",
      "Yan Gao",
      "Tomas Paulik",
      "Wanru Zhao",
      "William F. Shen",
      "Preslav Aleksandrov",
      "Xinchi Qiu",
      "Nicholas D. Lane"
    ],
    "abstract": "Generative pre-trained large language models (LLMs) have demonstrated\nimpressive performance over a wide range of tasks, thanks to the unprecedented\namount of data they have been trained on. As established scaling laws indicate,\nLLMs' future performance improvement depends on the amount of computing and\ndata sources they can leverage for pre-training. Federated learning (FL) has\nthe potential to unleash the majority of the planet's data and computational\nresources, which are underutilized by the data-center-focused training\nmethodology of current LLM practice. Our work presents a robust, flexible,\nreproducible FL approach that enables large-scale collaboration across\ninstitutions to train LLMs. We propose a scalable deployment system called\nPhoton to enable the investigation and development of this new training\nparadigm for LLM pre-training. We show that Photon can be used by organizations\ninterested in collaborating with their private data sources and computational\nresources for pre-training LLMs with billions of parameters. This paradigm\nwould mobilize more computational and data resources while matching or\npotentially exceeding centralized performance. We further show the\neffectiveness of the federated training scales with model size and present our\napproach for training billion-scale federated LLMs using limited resources.\nThus far, we have used Photon to train LLM models to the size of 7B parameters\nand anticipate larger models being completed in the near future. Finally, we\nshow that LLM training is highly resilient to the classical challenges of\nfederated statistical and hardware heterogeneity. Furthermore, we show that\nconvergence is robust to partial participation, opening the avenue for\ncompute-efficient collaborative training. Photon will help data-rich actors to\nbecome the protagonists of LLMs pre-training instead of leaving the stage to\ncompute-rich actors alone.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 15 figures, pre-print",
    "pdf_url": "http://arxiv.org/pdf/2405.10853v3",
    "published_date": "2024-05-17 15:27:52 UTC",
    "updated_date": "2024-10-14 16:37:29 UTC"
  },
  {
    "arxiv_id": "2405.10852v2",
    "title": "KernelSHAP-IQ: Weighted Least-Square Optimization for Shapley Interactions",
    "authors": [
      "Fabian Fumagalli",
      "Maximilian Muschalik",
      "Patrick Kolpaczki",
      "Eyke H√ºllermeier",
      "Barbara Hammer"
    ],
    "abstract": "The Shapley value (SV) is a prevalent approach of allocating credit to\nmachine learning (ML) entities to understand black box ML models. Enriching\nsuch interpretations with higher-order interactions is inevitable for complex\nsystems, where the Shapley Interaction Index (SII) is a direct axiomatic\nextension of the SV. While it is well-known that the SV yields an optimal\napproximation of any game via a weighted least square (WLS) objective, an\nextension of this result to SII has been a long-standing open problem, which\neven led to the proposal of an alternative index. In this work, we characterize\nhigher-order SII as a solution to a WLS problem, which constructs an optimal\napproximation via SII and $k$-Shapley values ($k$-SII). We prove this\nrepresentation for the SV and pairwise SII and give empirically validated\nconjectures for higher orders. As a result, we propose KernelSHAP-IQ, a direct\nextension of KernelSHAP for SII, and demonstrate state-of-the-art performance\nfor feature interactions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published Paper at ICML 2024:\n  https://openreview.net/forum?id=d5jXW2H4gg",
    "pdf_url": "http://arxiv.org/pdf/2405.10852v2",
    "published_date": "2024-05-17 15:27:35 UTC",
    "updated_date": "2024-07-16 07:03:01 UTC"
  },
  {
    "arxiv_id": "2405.11011v1",
    "title": "Uncertainty Distribution Assessment of Jiles-Atherton Parameter Estimation for Inrush Current Studies",
    "authors": [
      "Jone Ugarte-Valdivielso",
      "Jose I. Aizpurua",
      "Manex Barrenetxea-I√±arra"
    ],
    "abstract": "Transformers are one of the key assets in AC distribution grids and renewable\npower integration. During transformer energization inrush currents appear,\nwhich lead to transformer degradation and can cause grid instability events.\nThese inrush currents are a consequence of the transformer's magnetic core\nsaturation during its connection to the grid. Transformer cores are normally\nmodelled by the Jiles-Atherton (JA) model which contains five parameters. These\nparameters can be estimated by metaheuristic-based search algorithms. The\nparameter initialization of these algorithms plays an important role in the\nalgorithm convergence. The most popular strategy used for JA parameter\ninitialization is a random uniform distribution. However, techniques such as\nparameter initialization by Probability Density Functions (PDFs) have shown to\nimprove accuracy over random methods. In this context, this research work\npresents a framework to assess the impact of different parameter initialization\nstrategies on the performance of the JA parameter estimation for inrush current\nstudies. Depending on available data and expert knowledge, uncertainty levels\nare modelled with different PDFs. Moreover, three different\nmetaheuristic-search algorithms are employed on two different core materials\nand their accuracy and computational time are compared. Results show an\nimprovement in the accuracy and computational time of the metaheuristic-based\nalgorithms when PDF parameter initialization is used.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "11 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.11011v1",
    "published_date": "2024-05-17 15:20:26 UTC",
    "updated_date": "2024-05-17 15:20:26 UTC"
  },
  {
    "arxiv_id": "2407.12143v1",
    "title": "False consensus biases AI against vulnerable stakeholders",
    "authors": [
      "Mengchen Dong",
      "Jean-Fran√ßois Bonnefon",
      "Iyad Rahwan"
    ],
    "abstract": "The deployment of AI systems for welfare benefit allocation allows for\naccelerated decision-making and faster provision of critical help, but has\nalready led to an increase in unfair benefit denials and false fraud\naccusations. Collecting data in the US and the UK (N = 2449), we explore the\npublic acceptability of such speed-accuracy trade-offs in populations of\nclaimants and non-claimants. We observe a general willingness to trade off\nspeed gains for modest accuracy losses, but this aggregate view masks notable\ndivergences between claimants and non-claimants. Although welfare claimants\ncomprise a relatively small proportion of the general population (e.g., 20% in\nthe US representative sample), this vulnerable group is much less willing to\naccept AI deployed in welfare systems, raising concerns that solely using\naggregate data for calibration could lead to policies misaligned with\nstakeholder preferences. Our study further uncovers asymmetric insights between\nclaimants and non-claimants. The latter consistently overestimate claimant\nwillingness to accept speed-accuracy trade-offs, even when financially\nincentivized for accurate perspective-taking. This suggests that policy\ndecisions influenced by the dominant voice of non-claimants, however\nwell-intentioned, may neglect the actual preferences of those directly affected\nby welfare AI systems. Our findings underline the need for stakeholder\nengagement and transparent communication in the design and deployment of these\nsystems, particularly in contexts marked by power imbalances.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12143v1",
    "published_date": "2024-05-17 14:33:47 UTC",
    "updated_date": "2024-05-17 14:33:47 UTC"
  },
  {
    "arxiv_id": "2405.10768v2",
    "title": "What should be observed for optimal reward in POMDPs?",
    "authors": [
      "Alyzia-Maria Konsta",
      "Alberto Lluch Lafuente",
      "Christoph Matheja"
    ],
    "abstract": "Partially observable Markov Decision Processes (POMDPs) are a standard model\nfor agents making decisions in uncertain environments. Most work on POMDPs\nfocuses on synthesizing strategies based on the available capabilities.\nHowever, system designers can often control an agent's observation\ncapabilities, e.g. by placing or selecting sensors. This raises the question of\nhow one should select an agent's sensors cost-effectively such that it achieves\nthe desired goals. In this paper, we study the novel optimal observability\nproblem OOP: Given a POMDP M, how should one change M's observation\ncapabilities within a fixed budget such that its (minimal) expected reward\nremains below a given threshold? We show that the problem is undecidable in\ngeneral and decidable when considering positional strategies only. We present\ntwo algorithms for a decidable fragment of the OOP: one based on optimal\nstrategies of M's underlying Markov decision process and one based on parameter\nsynthesis with SMT. We report promising results for variants of typical\nexamples from the POMDP literature.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10768v2",
    "published_date": "2024-05-17 13:27:57 UTC",
    "updated_date": "2024-07-11 08:48:48 UTC"
  },
  {
    "arxiv_id": "2405.10767v1",
    "title": "Evaluating Saliency Explanations in NLP by Crowdsourcing",
    "authors": [
      "Xiaotian Lu",
      "Jiyi Li",
      "Zhen Wan",
      "Xiaofeng Lin",
      "Koh Takeuchi",
      "Hisashi Kashima"
    ],
    "abstract": "Deep learning models have performed well on many NLP tasks. However, their\ninternal mechanisms are typically difficult for humans to understand. The\ndevelopment of methods to explain models has become a key issue in the\nreliability of deep learning models in many important applications. Various\nsaliency explanation methods, which give each feature of input a score\nproportional to the contribution of output, have been proposed to determine the\npart of the input which a model values most. Despite a considerable body of\nwork on the evaluation of saliency methods, whether the results of various\nevaluation metrics agree with human cognition remains an open question. In this\nstudy, we propose a new human-based method to evaluate saliency methods in NLP\nby crowdsourcing. We recruited 800 crowd workers and empirically evaluated\nseven saliency methods on two datasets with the proposed method. We analyzed\nthe performance of saliency methods, compared our results with existing\nautomated evaluation methods, and identified notable differences between NLP\nand computer vision (CV) fields when using saliency methods. The instance-level\ndata of our crowdsourced experiments and the code to reproduce the explanations\nare available at https://github.com/xtlu/lreccoling_evaluation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "13 pages, 4 figures, Accepted for LREC-Coling 2024 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2405.10767v1",
    "published_date": "2024-05-17 13:27:45 UTC",
    "updated_date": "2024-05-17 13:27:45 UTC"
  },
  {
    "arxiv_id": "2405.10762v2",
    "title": "Research on Credit Risk Early Warning Model of Commercial Banks Based on Neural Network Algorithm",
    "authors": [
      "Yu Cheng",
      "Qin Yang",
      "Liyang Wang",
      "Ao Xiang",
      "Jingyu Zhang"
    ],
    "abstract": "In the realm of globalized financial markets, commercial banks are confronted\nwith an escalating magnitude of credit risk, thereby imposing heightened\nrequisites upon the security of bank assets and financial stability. This study\nharnesses advanced neural network techniques, notably the Backpropagation (BP)\nneural network, to pioneer a novel model for preempting credit risk in\ncommercial banks. The discourse initially scrutinizes conventional financial\nrisk preemptive models, such as ARMA, ARCH, and Logistic regression models,\ncritically analyzing their real-world applications. Subsequently, the\nexposition elaborates on the construction process of the BP neural network\nmodel, encompassing network architecture design, activation function selection,\nparameter initialization, and objective function construction. Through\ncomparative analysis, the superiority of neural network models in preempting\ncredit risk in commercial banks is elucidated. The experimental segment selects\nspecific bank data, validating the model's predictive accuracy and\npracticality. Research findings evince that this model efficaciously enhances\nthe foresight and precision of credit risk management.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10762v2",
    "published_date": "2024-05-17 13:18:46 UTC",
    "updated_date": "2024-05-30 08:13:30 UTC"
  },
  {
    "arxiv_id": "2405.10746v2",
    "title": "Causality in the Can: Diet Coke's Impact on Fatness",
    "authors": [
      "Yicheng Qi",
      "Ang Li"
    ],
    "abstract": "Artificially sweetened beverages like Diet Coke are often considered better\nalternatives to sugary drinks, but the debate over their impact on health,\nparticularly in relation to obesity, continues. Previous research has\npredominantly used association-based methods with observational or Randomized\nControlled Trial (RCT) data, which may not accurately capture the causal\nrelationship between Diet Coke consumption and obesity, leading to potentially\nlimited conclusions. In contrast, we employed causal inference methods using\nstructural causal models, integrating both observational and RCT data.\nSpecifically, we utilized data from the National Health and Nutrition\nExamination Survey (NHANES), which includes diverse demographic information, as\nour observational data source. This data was then used to construct a causal\ngraph, and the back-door criterion, along with its adjustment formula, was\napplied to estimate the RCT data. We then calculated the counterfactual\nquantity, the Probability of Necessity and Sufficiency (PNS), using both NHANES\ndata and estimated RCT data. We propose that PNS is the essential metric for\nassessing the impact of Diet Coke on obesity. Our results indicate that between\n20 to 50 percent of individuals, especially those with poor dietary habits, are\nmore likely to gain weight from Diet Coke. Conversely, in groups like young\nfemales with healthier diets, only a small proportion experience weight gain\ndue to Diet Coke. These findings highlight the influence of individual\nlifestyle and potential hormonal factors on the varied effects of Diet Coke,\nproviding a new framework for understanding its nutritional impacts on public\nhealth.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10746v2",
    "published_date": "2024-05-17 12:49:45 UTC",
    "updated_date": "2024-08-18 10:34:35 UTC"
  },
  {
    "arxiv_id": "2405.10745v1",
    "title": "Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings",
    "authors": [
      "Albert Sawczyn",
      "Jakub Binkowski",
      "Piotr Bielak",
      "Tomasz Kajdanowicz"
    ],
    "abstract": "Knowledge-intensive tasks pose a significant challenge for Machine Learning\n(ML) techniques. Commonly adopted methods, such as Large Language Models\n(LLMs), often exhibit limitations when applied to such tasks. Nevertheless,\nthere have been notable endeavours to mitigate these challenges, with a\nsignificant emphasis on augmenting LLMs through Knowledge Graphs (KGs). While\nKGs provide many advantages for representing knowledge, their development costs\ncan deter extensive research and applications. Addressing this limitation, we\nintroduce a framework for enriching embeddings of small-scale domain-specific\nKnowledge Graphs with well-established general-purpose KGs. Adopting our\nmethod, a modest domain-specific KG can benefit from a performance boost in\ndownstream tasks when linked to a substantial general-purpose KG. Experimental\nevaluations demonstrate a notable enhancement, with up to a 44% increase\nobserved in the Hits@10 metric. This relatively unexplored research direction\ncan catalyze more frequent incorporation of KGs in knowledge-intensive tasks,\nresulting in more robust, reliable ML implementations, which hallucinates less\nthan prevalent LLM solutions.\n  Keywords: knowledge graph, knowledge graph completion, entity alignment,\nrepresentation learning, machine learning",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10745v1",
    "published_date": "2024-05-17 12:46:23 UTC",
    "updated_date": "2024-05-17 12:46:23 UTC"
  },
  {
    "arxiv_id": "2405.10739v2",
    "title": "Efficient Multimodal Large Language Models: A Survey",
    "authors": [
      "Yizhang Jin",
      "Jian Li",
      "Yexin Liu",
      "Tianjun Gu",
      "Kai Wu",
      "Zhengkai Jiang",
      "Muyang He",
      "Bo Zhao",
      "Xin Tan",
      "Zhenye Gan",
      "Yabiao Wang",
      "Chengjie Wang",
      "Lizhuang Ma"
    ],
    "abstract": "In the past year, Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable performance in tasks such as visual question answering, visual\nunderstanding and reasoning. However, the extensive model size and high\ntraining and inference costs have hindered the widespread application of MLLMs\nin academia and industry. Thus, studying efficient and lightweight MLLMs has\nenormous potential, especially in edge computing scenarios. In this survey, we\nprovide a comprehensive and systematic review of the current state of efficient\nMLLMs. Specifically, we summarize the timeline of representative efficient\nMLLMs, research state of efficient structures and strategies, and the\napplications. Finally, we discuss the limitations of current efficient MLLM\nresearch and promising future directions. Please refer to our GitHub repository\nfor more details:\nhttps://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10739v2",
    "published_date": "2024-05-17 12:37:10 UTC",
    "updated_date": "2024-08-09 09:28:14 UTC"
  },
  {
    "arxiv_id": "2407.09977v1",
    "title": "Mitigating Interpretation Bias in Rock Records with Large Language Models: Insights from Paleoenvironmental Analysis",
    "authors": [
      "Luoqi Wang",
      "Haipeng Li",
      "Linshu Hu",
      "Jiarui Cai",
      "Zhenhong Du"
    ],
    "abstract": "The reconstruction of Earth's history faces significant challenges due to the\nnonunique interpretations often derived from rock records. The problem has long\nbeen recognized but there are no systematic solutions in practice. This study\nintroduces an innovative approach that leverages Large Language Models (LLMs)\nalong with retrieval augmented generation and real-time search capabilities to\ncounteract interpretation biases, thereby enhancing the accuracy and\nreliability of geological analyses. By applying this framework to sedimentology\nand paleogeography, we demonstrate its effectiveness in mitigating\ninterpretations biases through the generation and evaluation of multiple\nhypotheses for the same data, which can effectively reduce human bias. Our\nresearch illuminates the transformative potential of LLMs in refining\npaleoenvironmental studies and extends their applicability across various\nsub-disciplines of Earth sciences, enabling a deeper and more accurate\ndepiction of Earth's evolution.",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09977v1",
    "published_date": "2024-05-17 12:23:19 UTC",
    "updated_date": "2024-05-17 12:23:19 UTC"
  },
  {
    "arxiv_id": "2405.10729v2",
    "title": "Contestable AI needs Computational Argumentation",
    "authors": [
      "Francesco Leofante",
      "Hamed Ayoobi",
      "Adam Dejl",
      "Gabriel Freedman",
      "Deniz Gorur",
      "Junqi Jiang",
      "Guilherme Paulino-Passos",
      "Antonio Rago",
      "Anna Rapberger",
      "Fabrizio Russo",
      "Xiang Yin",
      "Dekai Zhang",
      "Francesca Toni"
    ],
    "abstract": "AI has become pervasive in recent years, but state-of-the-art approaches\npredominantly neglect the need for AI systems to be contestable. Instead,\ncontestability is advocated by AI guidelines (e.g. by the OECD) and regulation\nof automated decision-making (e.g. GDPR). In this position paper we explore how\ncontestability can be achieved computationally in and for AI. We argue that\ncontestable AI requires dynamic (human-machine and/or machine-machine)\nexplainability and decision-making processes, whereby machines can (i) interact\nwith humans and/or other machines to progressively explain their outputs and/or\ntheir reasoning as well as assess grounds for contestation provided by these\nhumans and/or other machines, and (ii) revise their decision-making processes\nto redress any issues successfully raised during contestation. Given that much\nof the current AI landscape is tailored to static AIs, the need to accommodate\ncontestability will require a radical rethinking, that, we argue, computational\nargumentation is ideally suited to support.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at KR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10729v2",
    "published_date": "2024-05-17 12:23:18 UTC",
    "updated_date": "2024-08-03 23:06:33 UTC"
  },
  {
    "arxiv_id": "2405.10714v1",
    "title": "Persian Pronoun Resolution: Leveraging Neural Networks and Language Models",
    "authors": [
      "Hassan Haji Mohammadi",
      "Alireza Talebpour",
      "Ahmad Mahmoudi Aznaveh",
      "Samaneh Yazdani"
    ],
    "abstract": "Coreference resolution, critical for identifying textual entities referencing\nthe same entity, faces challenges in pronoun resolution, particularly\nidentifying pronoun antecedents. Existing methods often treat pronoun\nresolution as a separate task from mention detection, potentially missing\nvaluable information. This study proposes the first end-to-end neural network\nsystem for Persian pronoun resolution, leveraging pre-trained Transformer\nmodels like ParsBERT. Our system jointly optimizes both mention detection and\nantecedent linking, achieving a 3.37 F1 score improvement over the previous\nstate-of-the-art system (which relied on rule-based and statistical methods) on\nthe Mehr corpus. This significant improvement demonstrates the effectiveness of\ncombining neural networks with linguistic models, potentially marking a\nsignificant advancement in Persian pronoun resolution and paving the way for\nfurther research in this under-explored area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10714v1",
    "published_date": "2024-05-17 11:56:00 UTC",
    "updated_date": "2024-05-17 11:56:00 UTC"
  },
  {
    "arxiv_id": "2405.10713v1",
    "title": "Development of Semantics-Based Distributed Middleware for Heterogeneous Data Integration and its Application for Drought",
    "authors": [
      "A Akanbi"
    ],
    "abstract": "Drought is a complex environmental phenomenon that affects millions of people\nand communities all over the globe and is too elusive to be accurately\npredicted. This is mostly due to the scalability and variability of the web of\nenvironmental parameters that directly/indirectly causes the onset of different\ncategories of drought. Since the dawn of man, efforts have been made to\nuniquely understand the natural indicators that provide signs of likely\nenvironmental events. These indicators/signs in the form of indigenous\nknowledge system have been used for generations. The intricate complexity of\ndrought has, however, always been a major stumbling block for accurate drought\nprediction and forecasting systems. Recently, scientists in the field of\nagriculture and environmental monitoring have been discussing the integration\nof indigenous knowledge and scientific knowledge for a more accurate\nenvironmental forecasting system in order to incorporate diverse environmental\ninformation for a reliable drought forecast. Hence, in this research, the core\nobjective is the development of a semantics-based data integration middleware\nthat encompasses and integrates heterogeneous data models of local indigenous\nknowledge and sensor data towards an accurate drought forecasting system for\nthe study areas. The local indigenous knowledge on drought gathered from the\ndomain experts is transformed into rules to be used for performing deductive\ninference in conjunction with sensors data for determining the onset of drought\nthrough an automated inference generation module of the middleware. The\nsemantic middleware incorporates, inter alia, a distributed architecture that\nconsists of a streaming data processing engine based on Apache Kafka for\nreal-time stream processing; a rule-based reasoning module; an ontology module\nfor semantic representation of the knowledge bases.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "286 Pages, PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2405.10713v1",
    "published_date": "2024-05-17 11:44:22 UTC",
    "updated_date": "2024-05-17 11:44:22 UTC"
  },
  {
    "arxiv_id": "2405.10700v1",
    "title": "SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation Tasks",
    "authors": [
      "Michael Shliselberg",
      "Ashkan Kazemi",
      "Scott A. Hale",
      "Shiri Dori-Hacohen"
    ],
    "abstract": "Diaspora communities are disproportionately impacted by off-the-radar\nmisinformation and often neglected by mainstream fact-checking efforts,\ncreating a critical need to scale-up efforts of nascent fact-checking\ninitiatives. In this paper we present SynDy, a framework for Synthetic Dynamic\nDataset Generation to leverage the capabilities of the largest frontier Large\nLanguage Models (LLMs) to train local, specialized language models. To the best\nof our knowledge, SynDy is the first paper utilizing LLMs to create\nfine-grained synthetic labels for tasks of direct relevance to misinformation\nmitigation, namely Claim Matching, Topical Clustering, and Claim Relationship\nClassification. SynDy utilizes LLMs and social media queries to automatically\ngenerate distantly-supervised, topically-focused datasets with synthetic labels\non these three tasks, providing essential tools to scale up human-led\nfact-checking at a fraction of the cost of human-annotated data. Training on\nSynDy's generated labels shows improvement over a standard baseline and is not\nsignificantly worse compared to training on human labels (which may be\ninfeasible to acquire). SynDy is being integrated into Meedan's chatbot\ntiplines that are used by over 50 organizations, serve over 230K users\nannually, and automatically distribute human-written fact-checks via messaging\napps such as WhatsApp. SynDy will also be integrated into our deployed\nCo-Insights toolkit, enabling low-resource organizations to launch tiplines for\ntheir communities. Finally, we envision SynDy enabling additional fact-checking\ntools such as matching new misinformation claims to high-quality explainers on\ncommon misinformation topics.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10700v1",
    "published_date": "2024-05-17 11:14:55 UTC",
    "updated_date": "2024-05-17 11:14:55 UTC"
  },
  {
    "arxiv_id": "2405.11008v3",
    "title": "A Systematic Review on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence",
    "authors": [
      "Tayab Uddin Wara",
      "Ababil Hossain Fahad",
      "Adri Shankar Das",
      "Md. Mehedi Hasan Shawon"
    ],
    "abstract": "Sleep is vital for people's physical and mental health, and sound sleep can\nhelp them focus on daily activities. Therefore, a sleep study that includes\nsleep patterns and sleep disorders is crucial to enhancing our knowledge about\nindividuals' health status. This study aims to provide a comprehensive,\nsystematic review of the recent literature to analyze the different approaches\nand their outcomes in sleep studies, which includes works on \"sleep stages\nclassification\" and \"sleep disorder detection\" using AI. In this review, 183\narticles were initially selected from different journals, among which 80\nrecords were enlisted for explicit review, ranging from 2016 to 2023. Brain\nwaves were the most commonly employed body parameters for sleep staging and\ndisorder studies (almost 29% of the research used brain activity signals\nexclusively, and 77% combined with the other signals). The convolutional neural\nnetwork (CNN), the most widely used of the 34 distinct artificial intelligence\nmodels, comprised 27%. The other models included the long short-term memory\n(LSTM), support vector machine (SVM), random forest (RF), and recurrent neural\nnetwork (RNN), which consisted of 11%, 6%, 6%, and 5% sequentially. For\nperformance metrics, accuracy was widely used for a maximum of 83.75% of the\ncases, the F1 score of 45%, Kappa of 36.25%, Sensitivity of 31.25%, and\nSpecificity of 30% of cases, along with the other metrics. This article would\nhelp physicians and researchers get the gist of AI's contribution to sleep\nstudies and the feasibility of their intended work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "39 pages, 11 Figures, 8 Tables",
    "pdf_url": "http://arxiv.org/pdf/2405.11008v3",
    "published_date": "2024-05-17 11:09:33 UTC",
    "updated_date": "2025-04-17 06:54:25 UTC"
  },
  {
    "arxiv_id": "2406.04356v1",
    "title": "BugBlitz-AI: An Intelligent QA Assistant",
    "authors": [
      "Yi Yao",
      "Jun Wang",
      "Yabai Hu",
      "Lifeng Wang",
      "Yi Zhou",
      "Jack Chen",
      "Xuming Gai",
      "Zhenming Wang",
      "Wenjun Liu"
    ],
    "abstract": "The evolution of software testing from manual to automated methods has\nsignificantly influenced quality assurance (QA) practices. However, challenges\npersist in post-execution phases, particularly in result analysis and\nreporting. Traditional post-execution validation phases require manual\nintervention for result analysis and report generation, leading to\ninefficiencies and potential development cycle delays. This paper introduces\nBugBlitz-AI, an AI-powered validation toolkit designed to enhance end-to-end\ntest automation by automating result analysis and bug reporting processes.\nBugBlitz-AI leverages recent advancements in artificial intelligence to reduce\nthe time-intensive tasks of manual result analysis and report generation,\nallowing QA teams to focus more on crucial aspects of product quality. By\nadopting BugBlitz-AI, organizations can advance automated testing practices and\nintegrate AI into QA processes, ensuring higher product quality and faster\ntime-to-market. The paper outlines BugBlitz-AI's architecture, discusses\nrelated work, details its quality enhancement strategies, and presents results\ndemonstrating its effectiveness in real-world scenarios.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04356v1",
    "published_date": "2024-05-17 11:09:10 UTC",
    "updated_date": "2024-05-17 11:09:10 UTC"
  },
  {
    "arxiv_id": "2405.10679v1",
    "title": "Off-the-Shelf Neural Network Architectures for Forex Time Series Prediction come at a Cost",
    "authors": [
      "Theodoros Zafeiriou",
      "Dimitris Kalles"
    ],
    "abstract": "Our study focuses on comparing the performance and resource requirements\nbetween different Long Short-Term Memory (LSTM) neural network architectures\nand an ANN specialized architecture for forex market prediction. We analyze the\nexecution time of the models as well as the resources consumed, such as memory\nand computational power. Our aim is to demonstrate that the specialized\narchitecture not only achieves better results in forex market prediction but\nalso executes using fewer resources and in a shorter time frame compared to\nLSTM architectures. This comparative analysis will provide significant insights\ninto the suitability of these two types of architectures for time series\nprediction in the forex market environment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-fin.MF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10679v1",
    "published_date": "2024-05-17 10:20:14 UTC",
    "updated_date": "2024-05-17 10:20:14 UTC"
  },
  {
    "arxiv_id": "2405.11007v1",
    "title": "Generative modeling of Sparse Approximate Inverse Preconditioners",
    "authors": [
      "Mou Li",
      "He Wang",
      "Peter K. Jimack"
    ],
    "abstract": "We present a new deep learning paradigm for the generation of sparse\napproximate inverse (SPAI) preconditioners for matrix systems arising from the\nmesh-based discretization of elliptic differential operators. Our approach is\nbased upon the observation that matrices generated in this manner are not\narbitrary, but inherit properties from differential operators that they\ndiscretize. Consequently, we seek to represent a learnable distribution of\nhigh-performance preconditioners from a low-dimensional subspace through a\ncarefully-designed autoencoder, which is able to generate SPAI preconditioners\nfor these systems. The concept has been implemented on a variety of finite\nelement discretizations of second- and fourth-order elliptic partial\ndifferential equations with highly promising results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 8 figures, International conference on Computational\n  Science",
    "pdf_url": "http://arxiv.org/pdf/2405.11007v1",
    "published_date": "2024-05-17 10:19:32 UTC",
    "updated_date": "2024-05-17 10:19:32 UTC"
  },
  {
    "arxiv_id": "2405.10674v1",
    "title": "From Sora What We Can See: A Survey of Text-to-Video Generation",
    "authors": [
      "Rui Sun",
      "Yumin Zhang",
      "Tejal Shah",
      "Jiahao Sun",
      "Shuoying Zhang",
      "Wenqi Li",
      "Haoran Duan",
      "Bo Wei",
      "Rajiv Ranjan"
    ],
    "abstract": "With impressive achievements made, artificial intelligence is on the path\nforward to artificial general intelligence. Sora, developed by OpenAI, which is\ncapable of minute-level world-simulative abilities can be considered as a\nmilestone on this developmental path. However, despite its notable successes,\nSora still encounters various obstacles that need to be resolved. In this\nsurvey, we embark from the perspective of disassembling Sora in text-to-video\ngeneration, and conducting a comprehensive review of literature, trying to\nanswer the question, \\textit{From Sora What We Can See}. Specifically, after\nbasic preliminaries regarding the general algorithms are introduced, the\nliterature is categorized from three mutually perpendicular dimensions:\nevolutionary generators, excellent pursuit, and realistic panorama.\nSubsequently, the widely used datasets and metrics are organized in detail.\nLast but more importantly, we identify several challenges and open problems in\nthis domain and propose potential future directions for research and\ndevelopment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "A comprehensive list of text-to-video generation studies in this\n  survey is available at\n  https://github.com/soraw-ai/Awesome-Text-to-Video-Generation",
    "pdf_url": "http://arxiv.org/pdf/2405.10674v1",
    "published_date": "2024-05-17 10:09:09 UTC",
    "updated_date": "2024-05-17 10:09:09 UTC"
  },
  {
    "arxiv_id": "2405.15801v1",
    "title": "Decision-making algorithm based on the energy of interval-valued fuzzy soft sets",
    "authors": [
      "Ljubica Djuroviƒá",
      "Maja Lakoviƒá",
      "Nenad Stojanoviƒá"
    ],
    "abstract": "In our work, we continue to explore the properties of interval-valued fuzzy\nsoft sets, which are obtained by combining interval-valued fuzzy sets and soft\nsets. We introduce the concept of energy of an interval-valued fuzzy soft set,\nas well as pessimistic and optimistic energy, enabling us to construct an\neffective decision-making algorithm. Through examples, the paper demonstrates\nhow the introduced algorithm is successfully applied to problems involving\nuncertainty. Additionally, we compare the introduced method with other methods\ndealing with similar or related issues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15801v1",
    "published_date": "2024-05-17 09:54:44 UTC",
    "updated_date": "2024-05-17 09:54:44 UTC"
  },
  {
    "arxiv_id": "2407.09486v1",
    "title": "ENOVA: Autoscaling towards Cost-effective and Stable Serverless LLM Serving",
    "authors": [
      "Tao Huang",
      "Pengfei Chen",
      "Kyoka Gong",
      "Jocky Hawk",
      "Zachary Bright",
      "Wenxin Xie",
      "Kecheng Huang",
      "Zhi Ji"
    ],
    "abstract": "Since the increasing popularity of large language model (LLM) backend\nsystems, it is common and necessary to deploy stable serverless serving of LLM\non multi-GPU clusters with autoscaling. However, there exist challenges because\nthe diversity and co-location of applications in multi-GPU clusters will lead\nto low service quality and GPU utilization. To address them, we build ENOVA, a\ndeployment, monitoring and autoscaling service towards serverless LLM serving.\nENOVA deconstructs the execution process of LLM service comprehensively, based\non which ENOVA designs a configuration recommendation module for automatic\ndeployment on any GPU clusters and a performance detection module for\nautoscaling. On top of them, ENOVA implements a deployment execution engine for\nmulti-GPU cluster scheduling. The experiment results show that ENOVA\nsignificantly outperforms other state-of-the-art methods and is suitable for\nwide deployment in large online systems.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09486v1",
    "published_date": "2024-05-17 09:48:31 UTC",
    "updated_date": "2024-05-17 09:48:31 UTC"
  },
  {
    "arxiv_id": "2405.10659v2",
    "title": "Realistic Evaluation of Toxicity in Large Language Models",
    "authors": [
      "Tinh Son Luong",
      "Thanh-Thien Le",
      "Linh Ngo Van",
      "Thien Huu Nguyen"
    ],
    "abstract": "Large language models (LLMs) have become integral to our professional\nworkflows and daily lives. Nevertheless, these machine companions of ours have\na critical flaw: the huge amount of data which endows them with vast and\ndiverse knowledge, also exposes them to the inevitable toxicity and bias. While\nmost LLMs incorporate defense mechanisms to prevent the generation of harmful\ncontent, these safeguards can be easily bypassed with minimal prompt\nengineering. In this paper, we introduce the new Thoroughly Engineered Toxicity\n(TET) dataset, comprising manually crafted prompts designed to nullify the\nprotective layers of such models. Through extensive evaluations, we demonstrate\nthe pivotal role of TET in providing a rigorous benchmark for evaluation of\ntoxicity awareness in several popular LLMs: it highlights the toxicity in the\nLLMs that might remain hidden when using normal prompts, thus revealing subtler\nissues in their behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10659v2",
    "published_date": "2024-05-17 09:42:59 UTC",
    "updated_date": "2024-05-20 14:27:37 UTC"
  },
  {
    "arxiv_id": "2405.10647v1",
    "title": "Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning",
    "authors": [
      "Haoyue Song",
      "Jiacheng Wang",
      "Liansheng Wang"
    ],
    "abstract": "Federated Learning (FL) has gained attention for addressing data scarcity and\nprivacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable\nperformance, they face challenges in scenarios with diverse network speeds and\nconcerns about centralized control, especially in multi-institutional\ncollaborations like the medical domain. Serial FL presents an alternative\nsolution, circumventing these challenges by transferring model updates serially\nbetween devices in a cyclical manner. Nevertheless, it is deemed inferior to\nparallel FL in that (1) its performance shows undesirable fluctuations, and (2)\nit converges to a lower plateau, particularly when dealing with non-IID data.\nThe observed phenomenon is attributed to catastrophic forgetting due to\nknowledge loss from previous sites. In this paper, to overcome fluctuation and\nlow efficiency in the iterative learning and forgetting process, we introduce\ncyclical weight consolidation (CWC), a straightforward yet potent approach\nspecifically tailored for serial FL. CWC employs a consolidation matrix to\nregulate local optimization. This matrix tracks the significance of each\nparameter on the overall federation throughout the entire training trajectory,\npreventing abrupt changes in significant weights. During revisitation, to\nmaintain adaptability, old memory undergoes decay to incorporate new\ninformation. Our comprehensive evaluations demonstrate that in various non-IID\nsettings, CWC mitigates the fluctuation behavior of the original serial FL\napproach and enhances the converged performance consistently and significantly.\nThe improved performance is either comparable to or better than the parallel\nvanilla.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.10647v1",
    "published_date": "2024-05-17 09:20:21 UTC",
    "updated_date": "2024-05-17 09:20:21 UTC"
  },
  {
    "arxiv_id": "2405.10645v1",
    "title": "ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education",
    "authors": [
      "Harris Bin Munawar",
      "Nikolaos Misirlis"
    ],
    "abstract": "In the era of exponential technology growth, one unexpected guest has claimed\na seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as\nChatGPT, promises a revolution in education, yet it arrives with a double-edged\nsword. Its potential for personalized learning is offset by issues of cheating,\ninaccuracies, and educators struggling to incorporate it effectively into their\nlesson design. We are standing on the brink of this educational frontier, and\nit is clear that we need to navigate this terrain with a lot of care. This is a\nmajor challenge that could undermine the integrity and value of our educational\nprocess. So, how can we turn these challenges into opportunities? When used\ninappropriately, AI tools can become the perfect tool for the cut copy paste\nmentality, and quickly begin to corrode critical thinking, creativity, and deep\nunderstanding, the most important skills in our rapidly changing world.\nTeachers feel that they are not equipped to leverage this technology, widening\nthe digital divide among educators and institutions. Addressing these concerns\ncalls for an in depth research approach. We will employ empirical research,\ndrawing on the Technology Acceptance Model, to assess the attitudes toward\ngenerative AI among educators and students. Understanding their perceptions,\nusage patterns, and hurdles is the first crucial step in creating an effective\nsolution. The present study will be used as a process manual for future\nresearchers to apply, running their own data, based on the steps explained here",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "5 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2405.10645v1",
    "published_date": "2024-05-17 09:17:59 UTC",
    "updated_date": "2024-05-17 09:17:59 UTC"
  },
  {
    "arxiv_id": "2405.10632v6",
    "title": "Towards interactive evaluations for interaction harms in human-AI systems",
    "authors": [
      "Lujain Ibrahim",
      "Saffron Huang",
      "Umang Bhatt",
      "Lama Ahmad",
      "Markus Anderljung"
    ],
    "abstract": "Current AI evaluation paradigms that rely on static, model-only tests fail to\ncapture harms that emerge through sustained human-AI interaction. As\ninteractive AI systems, such as AI companions, proliferate in daily life, this\nmismatch between evaluation methods and real-world use becomes increasingly\nconsequential. We argue for a paradigm shift toward evaluation centered on\n\\textit{interactional ethics}, which addresses risks like inappropriate\nhuman-AI relationships, social manipulation, and cognitive overreliance that\ndevelop through repeated interaction rather than single outputs. Drawing on\nhuman-computer interaction, natural language processing, and the social\nsciences, we propose principles for evaluating generative models through\ninteraction scenarios and human impact metrics. We conclude by examining\nimplementation challenges and open research questions for researchers,\npractitioners, and regulators integrating these approaches into AI governance\nframeworks.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10632v6",
    "published_date": "2024-05-17 08:49:34 UTC",
    "updated_date": "2025-04-27 15:44:44 UTC"
  },
  {
    "arxiv_id": "2405.10630v1",
    "title": "Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges",
    "authors": [
      "Xiaoming Shi",
      "Zeming Liu",
      "Li Du",
      "Yuxuan Wang",
      "Hongru Wang",
      "Yuhang Guo",
      "Tong Ruan",
      "Jie Xu",
      "Shaoting Zhang"
    ],
    "abstract": "This paper surveys and organizes research works on medical dialog systems,\nwhich is an important yet challenging task. Although these systems have been\nsurveyed in the medical community from an application perspective, a systematic\nreview from a rigorous technical perspective has to date remained noticeably\nabsent. As a result, an overview of the categories, methods, and evaluation of\nmedical dialogue systems remain limited and underspecified, hindering the\nfurther improvement of this area. To fill this gap, we investigate an initial\npool of 325 papers from well-known computer science, and natural language\nprocessing conferences and journals, and make an overview. Recently, large\nlanguage models have shown strong model capacity on downstream tasks, which\nalso reshaped medical dialog systems' foundation. Despite the alluring\npractical application value, current medical dialogue systems still suffer from\nproblems. To this end, this paper lists the grand challenges of medical dialog\nsystems, especially of large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10630v1",
    "published_date": "2024-05-17 08:46:15 UTC",
    "updated_date": "2024-05-17 08:46:15 UTC"
  },
  {
    "arxiv_id": "2405.10629v1",
    "title": "DeepPavlov at SemEval-2024 Task 8: Leveraging Transfer Learning for Detecting Boundaries of Machine-Generated Texts",
    "authors": [
      "Anastasia Voznyuk",
      "Vasily Konovalov"
    ],
    "abstract": "The Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated\nText Detection shared task in the SemEval-2024 competition aims to tackle the\nproblem of misusing collaborative human-AI writing. Although there are a lot of\nexisting detectors of AI content, they are often designed to give a binary\nanswer and thus may not be suitable for more nuanced problem of finding the\nboundaries between human-written and machine-generated texts, while hybrid\nhuman-AI writing becomes more and more popular. In this paper, we address the\nboundary detection problem. Particularly, we present a pipeline for augmenting\ndata for supervised fine-tuning of DeBERTaV3. We receive new best MAE score,\naccording to the leaderboard of the competition, with this pipeline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "New best score from the leaderboard, to appear in SemEval-2024\n  Workshop proceedings",
    "pdf_url": "http://arxiv.org/pdf/2405.10629v1",
    "published_date": "2024-05-17 08:44:48 UTC",
    "updated_date": "2024-05-17 08:44:48 UTC"
  },
  {
    "arxiv_id": "2405.10625v1",
    "title": "Specialising and Analysing Instruction-Tuned and Byte-Level Language Models for Organic Reaction Prediction",
    "authors": [
      "Jiayun Pang",
      "Ivan Vuliƒá"
    ],
    "abstract": "Transformer-based encoder-decoder models have demonstrated impressive results\nin chemical reaction prediction tasks. However, these models typically rely on\npretraining using tens of millions of unlabelled molecules, which can be\ntime-consuming and GPU-intensive. One of the central questions we aim to answer\nin this work is: Can FlanT5 and ByT5, the encode-decoder models pretrained\nsolely on language data, be effectively specialised for organic reaction\nprediction through task-specific fine-tuning? We conduct a systematic empirical\nstudy on several key issues of the process, including tokenisation, the impact\nof (SMILES-oriented) pretraining, fine-tuning sample efficiency, and decoding\nalgorithms at inference. Our key findings indicate that although being\npretrained only on language tasks, FlanT5 and ByT5 provide a solid foundation\nto fine-tune for reaction prediction, and thus become `chemistry domain\ncompatible' in the process. This suggests that GPU-intensive and expensive\npretraining on a large dataset of unlabelled molecules may be useful yet not\nessential to leverage the power of language models for chemistry. All our\nmodels achieve comparable Top-1 and Top-5 accuracy although some variation\nacross different models does exist. Notably, tokenisation and vocabulary\ntrimming slightly affect final performance but can speed up training and\ninference; The most efficient greedy decoding strategy is very competitive\nwhile only marginal gains can be achieved from more sophisticated decoding\nalgorithms. In summary, we evaluate FlanT5 and ByT5 across several dimensions\nand benchmark their impact on organic reaction prediction, which may guide more\neffective use of these state-of-the-art language models for chemistry-related\ntasks in the future.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.10625v1",
    "published_date": "2024-05-17 08:39:56 UTC",
    "updated_date": "2024-05-17 08:39:56 UTC"
  },
  {
    "arxiv_id": "2405.10624v3",
    "title": "Sample-Efficient Constrained Reinforcement Learning with General Parameterization",
    "authors": [
      "Washim Uddin Mondal",
      "Vaneet Aggarwal"
    ],
    "abstract": "We consider a constrained Markov Decision Problem (CMDP) where the goal of an\nagent is to maximize the expected discounted sum of rewards over an infinite\nhorizon while ensuring that the expected discounted sum of costs exceeds a\ncertain threshold. Building on the idea of momentum-based acceleration, we\ndevelop the Primal-Dual Accelerated Natural Policy Gradient (PD-ANPG) algorithm\nthat ensures an $\\epsilon$ global optimality gap and $\\epsilon$ constraint\nviolation with $\\tilde{\\mathcal{O}}((1-\\gamma)^{-7}\\epsilon^{-2})$ sample\ncomplexity for general parameterized policies where $\\gamma$ denotes the\ndiscount factor. This improves the state-of-the-art sample complexity in\ngeneral parameterized CMDPs by a factor of\n$\\mathcal{O}((1-\\gamma)^{-1}\\epsilon^{-2})$ and achieves the theoretical lower\nbound in $\\epsilon^{-1}$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10624v3",
    "published_date": "2024-05-17 08:39:05 UTC",
    "updated_date": "2024-10-31 05:24:19 UTC"
  },
  {
    "arxiv_id": "2405.10621v2",
    "title": "Historically Relevant Event Structuring for Temporal Knowledge Graph Reasoning",
    "authors": [
      "Jinchuan Zhang",
      "Ming Sun",
      "Chong Mu",
      "Jinhao Zhang",
      "Quanjiang Guo",
      "Ling Tian"
    ],
    "abstract": "Temporal Knowledge Graph (TKG) reasoning focuses on predicting events through\nhistorical information within snapshots distributed on a timeline. Existing\nstudies mainly concentrate on two perspectives of leveraging the history of\nTKGs, including capturing evolution of each recent snapshot or correlations\namong global historical facts. Despite the achieved significant\naccomplishments, these models still fall short of I) investigating the impact\nof multi-granular interactions across recent snapshots, and II) harnessing the\nexpressive semantics of significant links accorded with queries throughout the\nentire history, particularly events exerting a profound impact on the future.\nThese inadequacies restrict representation ability to reflect historical\ndependencies and future trends thoroughly. To overcome these drawbacks, we\npropose an innovative TKG reasoning approach towards \\textbf{His}torically\n\\textbf{R}elevant \\textbf{E}vents \\textbf{S}tructuring (HisRES). Concretely,\nHisRES comprises two distinctive modules excelling in structuring historically\nrelevant events within TKGs, including a multi-granularity evolutionary encoder\nthat captures structural and temporal dependencies of the most recent\nsnapshots, and a global relevance encoder that concentrates on crucial\ncorrelations among events relevant to queries from the entire history.\nFurthermore, HisRES incorporates a self-gating mechanism for adaptively merging\nmulti-granularity recent and historically relevant structuring representations.\nExtensive experiments on four event-based benchmarks demonstrate the\nstate-of-the-art performance of HisRES and indicate the superiority and\neffectiveness of structuring historical relevance for TKG reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICDE 2025, 12 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.10621v2",
    "published_date": "2024-05-17 08:33:43 UTC",
    "updated_date": "2025-04-30 05:15:37 UTC"
  },
  {
    "arxiv_id": "2405.10620v2",
    "title": "MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains",
    "authors": [
      "Zhaohuan Zhan",
      "Lisha Yu",
      "Sijie Yu",
      "Guang Tan"
    ],
    "abstract": "In the Vision-and-Language Navigation (VLN) task, the agent is required to\nnavigate to a destination following a natural language instruction. While\nlearning-based approaches have been a major solution to the task, they suffer\nfrom high training costs and lack of interpretability. Recently, Large Language\nModels (LLMs) have emerged as a promising tool for VLN due to their strong\ngeneralization capabilities. However, existing LLM-based methods face\nlimitations in memory construction and diversity of navigation strategies. To\naddress these challenges, we propose a suite of techniques. Firstly, we\nintroduce a method to maintain a topological map that stores navigation\nhistory, retaining information about viewpoints, objects, and their spatial\nrelationships. This map also serves as a global action space. Additionally, we\npresent a Navigation Chain of Thoughts module, leveraging human navigation\nexamples to enrich navigation strategy diversity. Finally, we establish a\npipeline that integrates navigational memory and strategies with perception and\naction prediction modules. Experimental results on the REVERIE and R2R datasets\nshow that our method effectively enhances the navigation ability of the LLM and\nimproves the interpretability of navigation reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10620v2",
    "published_date": "2024-05-17 08:33:27 UTC",
    "updated_date": "2024-08-12 14:07:32 UTC"
  },
  {
    "arxiv_id": "2405.10611v1",
    "title": "A Certified Proof Checker for Deep Neural Network Verification",
    "authors": [
      "Remi Desmartin",
      "Omri Isac",
      "Ekaterina Komendantskaya",
      "Kathrin Stark",
      "Grant Passmore",
      "Guy Katz"
    ],
    "abstract": "Recent advances in the verification of deep neural networks (DNNs) have\nopened the way for broader usage of DNN verification technology in many\napplication areas, including safety-critical ones. DNN verifiers are themselves\ncomplex programs that have been shown to be susceptible to errors and\nimprecisions; this in turn has raised the question of trust in DNN verifiers.\nOne prominent attempt to address this issue is enhancing DNN verifiers with the\ncapability of producing proofs of their results that are subject to independent\nalgorithmic certification (proof checking). Formulations of proof production\nand proof checking already exist on top of the state-of-the-art Marabou DNN\nverifier. The native implementation of the proof checking algorithm for Marabou\nwas done in C++ and itself raised the question of trust in the code (e.g., in\nthe precision of floating point calculations or guarantees for implementation\nsoundness). Here, we present an alternative implementation of the Marabou proof\nchecking algorithm in Imandra -- an industrial functional programming language\nand prover -- that allows us to obtain an implementation with formal\nguarantees, including proofs of mathematical results underlying the algorithm,\nsuch as the use of the Farkas lemma.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10611v1",
    "published_date": "2024-05-17 08:16:32 UTC",
    "updated_date": "2024-05-17 08:16:32 UTC"
  },
  {
    "arxiv_id": "2405.10608v2",
    "title": "ECATS: Explainable-by-design concept-based anomaly detection for time series",
    "authors": [
      "Irene Ferfoglia",
      "Gaia Saveri",
      "Laura Nenzi",
      "Luca Bortolussi"
    ],
    "abstract": "Deep learning methods for time series have already reached excellent\nperformances in both prediction and classification tasks, including anomaly\ndetection. However, the complexity inherent in Cyber Physical Systems (CPS)\ncreates a challenge when it comes to explainability methods. To overcome this\ninherent lack of interpretability, we propose ECATS, a concept-based\nneuro-symbolic architecture where concepts are represented as Signal Temporal\nLogic (STL) formulae. Leveraging kernel-based methods for STL, concept\nembeddings are learnt in an unsupervised manner through a cross-attention\nmechanism. The network makes class predictions through these concept\nembeddings, allowing for a meaningful explanation to be naturally extracted for\neach input. Our preliminary experiments with a simple CPS-based dataset show\nthat our model is able to achieve great classification performance while\nensuring local interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures, accepted to 18th International Conference on\n  Neural-Symbolic Learning and Reasoning (NeSy 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.10608v2",
    "published_date": "2024-05-17 08:12:53 UTC",
    "updated_date": "2024-07-30 10:38:31 UTC"
  },
  {
    "arxiv_id": "2405.10597v1",
    "title": "UniCL: A Universal Contrastive Learning Framework for Large Time Series Models",
    "authors": [
      "Jiawei Li",
      "Jingshu Peng",
      "Haoyang Li",
      "Lei Chen"
    ],
    "abstract": "Time-series analysis plays a pivotal role across a range of critical\napplications, from finance to healthcare, which involves various tasks, such as\nforecasting and classification. To handle the inherent complexities of\ntime-series data, such as high dimensionality and noise, traditional supervised\nlearning methods first annotate extensive labels for time-series data in each\ntask, which is very costly and impractical in real-world applications. In\ncontrast, pre-trained foundation models offer a promising alternative by\nleveraging unlabeled data to capture general time series patterns, which can\nthen be fine-tuned for specific tasks. However, existing approaches to\npre-training such models typically suffer from high-bias and low-generality\nissues due to the use of predefined and rigid augmentation operations and\ndomain-specific data training. To overcome these limitations, this paper\nintroduces UniCL, a universal and scalable contrastive learning framework\ndesigned for pretraining time-series foundation models across cross-domain\ndatasets. Specifically, we propose a unified and trainable time-series\naugmentation operation to generate pattern-preserved, diverse, and low-bias\ntime-series data by leveraging spectral information. Besides, we introduce a\nscalable augmentation algorithm capable of handling datasets with varying\nlengths, facilitating cross-domain pretraining. Extensive experiments on two\nbenchmark datasets across eleven domains validate the effectiveness of UniCL,\ndemonstrating its high generalization on time-series analysis across various\nfields.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10597v1",
    "published_date": "2024-05-17 07:47:11 UTC",
    "updated_date": "2024-05-17 07:47:11 UTC"
  },
  {
    "arxiv_id": "2405.13039v1",
    "title": "Surgical Feature-Space Decomposition of LLMs: Why, When and How?",
    "authors": [
      "Arnav Chavan",
      "Nahush Lele",
      "Deepak Gupta"
    ],
    "abstract": "Low-rank approximations, of the weight and feature space can enhance the\nperformance of deep learning models, whether in terms of improving\ngeneralization or reducing the latency of inference. However, there is no clear\nconsensus yet on \\emph{how}, \\emph{when} and \\emph{why} these approximations\nare helpful for large language models (LLMs). In this work, we empirically\nstudy the efficacy of weight and feature space decomposition in\ntransformer-based LLMs. We demonstrate that surgical decomposition not only\nprovides critical insights into the trade-off between compression and language\nmodelling performance, but also sometimes enhances commonsense reasoning\nperformance of LLMs. Our empirical analysis identifies specific network\nsegments that intrinsically exhibit a low-rank structure. Furthermore, we\nextend our investigation to the implications of low-rank approximations on\nmodel bias. Overall, our findings offer a novel perspective on optimizing LLMs,\npresenting the low-rank approximation not only as a tool for performance\nenhancements, but also as a means to potentially rectify biases within these\nmodels. Our code is available at\n\\href{https://github.com/nyunAI/SFSD-LLM}{GitHub}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13039v1",
    "published_date": "2024-05-17 07:34:03 UTC",
    "updated_date": "2024-05-17 07:34:03 UTC"
  },
  {
    "arxiv_id": "2405.13038v1",
    "title": "An Explanatory Model Steering System for Collaboration between Domain Experts and AI",
    "authors": [
      "Aditya Bhattacharya",
      "Simone Stumpf",
      "Katrien Verbert"
    ],
    "abstract": "With the increasing adoption of Artificial Intelligence (AI) systems in\nhigh-stake domains, such as healthcare, effective collaboration between domain\nexperts and AI is imperative. To facilitate effective collaboration between\ndomain experts and AI systems, we introduce an Explanatory Model Steering\nsystem that allows domain experts to steer prediction models using their domain\nknowledge. The system includes an explanation dashboard that combines different\ntypes of data-centric and model-centric explanations and allows prediction\nmodels to be steered through manual and automated data configuration\napproaches. It allows domain experts to apply their prior knowledge for\nconfiguring the underlying training data and refining prediction models.\nAdditionally, our model steering system has been evaluated for a\nhealthcare-focused scenario with 174 healthcare experts through three extensive\nuser studies. Our findings highlight the importance of involving domain experts\nduring model steering, ultimately leading to improved human-AI collaboration.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Demo paper accepted for ACM UMAP 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13038v1",
    "published_date": "2024-05-17 07:27:48 UTC",
    "updated_date": "2024-05-17 07:27:48 UTC"
  },
  {
    "arxiv_id": "2405.10589v1",
    "title": "Improving Point-based Crowd Counting and Localization Based on Auxiliary Point Guidance",
    "authors": [
      "I-Hsiang Chen",
      "Wei-Ting Chen",
      "Yu-Wei Liu",
      "Ming-Hsuan Yang",
      "Sy-Yen Kuo"
    ],
    "abstract": "Crowd counting and localization have become increasingly important in\ncomputer vision due to their wide-ranging applications. While point-based\nstrategies have been widely used in crowd counting methods, they face a\nsignificant challenge, i.e., the lack of an effective learning strategy to\nguide the matching process. This deficiency leads to instability in matching\npoint proposals to target points, adversely affecting overall performance. To\naddress this issue, we introduce an effective approach to stabilize the\nproposal-target matching in point-based methods. We propose Auxiliary Point\nGuidance (APG) to provide clear and effective guidance for proposal selection\nand optimization, addressing the core issue of matching uncertainty.\nAdditionally, we develop Implicit Feature Interpolation (IFI) to enable\nadaptive feature extraction in diverse crowd scenarios, further enhancing the\nmodel's robustness and accuracy. Extensive experiments demonstrate the\neffectiveness of our approach, showing significant improvements in crowd\ncounting and localization performance, particularly under challenging\nconditions. The source codes and trained models will be made publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10589v1",
    "published_date": "2024-05-17 07:23:27 UTC",
    "updated_date": "2024-05-17 07:23:27 UTC"
  },
  {
    "arxiv_id": "2405.10581v2",
    "title": "Future Aware Safe Active Learning of Time Varying Systems using Gaussian Processes",
    "authors": [
      "Markus Lange-Hegermann",
      "Christoph Zimmer"
    ],
    "abstract": "Experimental exploration of high-cost systems with safety constraints, common\nin engineering applications, is a challenging endeavor. Data-driven models\noffer a promising solution, but acquiring the requisite data remains expensive\nand is potentially unsafe. Safe active learning techniques prove essential,\nenabling the learning of high-quality models with minimal expensive data points\nand high safety. This paper introduces a safe active learning framework\ntailored for time-varying systems, addressing drift, seasonal changes, and\ncomplexities due to dynamic behavior. The proposed Time-aware Integrated Mean\nSquared Prediction Error (T-IMSPE) method minimizes posterior variance over\ncurrent and future states, optimizing information gathering also in the time\ndomain. Empirical results highlight T-IMSPE's advantages in model quality\nthrough toy and real-world examples. State of the art Gaussian processes are\ncompatible with T-IMSPE. Our theoretical contributions include a clear\ndelineation which Gaussian process kernels, domains, and weighting measures are\nsuitable for T-IMSPE and even beyond for its non-time aware predecessor IMSPE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "math.PR",
      "I.2.6; G.3; J.2; I.1.4"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.10581v2",
    "published_date": "2024-05-17 07:09:52 UTC",
    "updated_date": "2025-04-16 15:24:39 UTC"
  },
  {
    "arxiv_id": "2405.13037v1",
    "title": "Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation",
    "authors": [
      "Cheng Niu",
      "Xingguang Wang",
      "Xuxin Cheng",
      "Juntong Song",
      "Tong Zhang"
    ],
    "abstract": "Dialogue State Tracking (DST) is designed to monitor the evolving dialogue\nstate in the conversations and plays a pivotal role in developing task-oriented\ndialogue systems. However, obtaining the annotated data for the DST task is\nusually a costly endeavor. In this paper, we focus on employing LLMs to\ngenerate dialogue data to reduce dialogue collection and annotation costs.\nSpecifically, GPT-4 is used to simulate the user and agent interaction,\ngenerating thousands of dialogues annotated with DST labels. Then a two-stage\nfine-tuning on LLaMA 2 is performed on the generated data and the real data for\nthe DST prediction. Experimental results on two public DST benchmarks show that\nwith the generated dialogue data, our model performs better than the baseline\ntrained solely on real data. In addition, our approach is also capable of\nadapting to the dynamic demands in real-world scenarios, generating dialogues\nin new domains swiftly. After replacing dialogue segments in any domain with\nthe corresponding generated ones, the model achieves comparable performance to\nthe model trained on real data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13037v1",
    "published_date": "2024-05-17 07:00:05 UTC",
    "updated_date": "2024-05-17 07:00:05 UTC"
  },
  {
    "arxiv_id": "2405.10570v3",
    "title": "Simultaneous Deep Learning of Myocardium Segmentation and T2 Quantification for Acute Myocardial Infarction MRI",
    "authors": [
      "Yirong Zhou",
      "Chengyan Wang",
      "Mengtian Lu",
      "Kunyuan Guo",
      "Zi Wang",
      "Dan Ruan",
      "Rui Guo",
      "Peijun Zhao",
      "Jianhua Wang",
      "Naiming Wu",
      "Jianzhong Lin",
      "Yinyin Chen",
      "Hang Jin",
      "Lianxin Xie",
      "Lilan Wu",
      "Liuhong Zhu",
      "Jianjun Zhou",
      "Congbo Cai",
      "He Wang",
      "Xiaobo Qu"
    ],
    "abstract": "In cardiac Magnetic Resonance Imaging (MRI) analysis, simultaneous myocardial\nsegmentation and T2 quantification are crucial for assessing myocardial\npathologies. Existing methods often address these tasks separately, limiting\ntheir synergistic potential. To address this, we propose SQNet, a dual-task\nnetwork integrating Transformer and Convolutional Neural Network (CNN)\ncomponents. SQNet features a T2-refine fusion decoder for quantitative\nanalysis, leveraging global features from the Transformer, and a segmentation\ndecoder with multiple local region supervision for enhanced accuracy. A tight\ncoupling module aligns and fuses CNN and Transformer branch features, enabling\nSQNet to focus on myocardium regions. Evaluation on healthy controls (HC) and\nacute myocardial infarction patients (AMI) demonstrates superior segmentation\ndice scores (89.3/89.2) compared to state-of-the-art methods (87.7/87.9). T2\nquantification yields strong linear correlations (Pearson coefficients:\n0.84/0.93) with label values for HC/AMI, indicating accurate mapping.\nRadiologist evaluations confirm SQNet's superior image quality scores\n(4.60/4.58 for segmentation, 4.32/4.42 for T2 quantification) over\nstate-of-the-art methods (4.50/4.44 for segmentation, 3.59/4.37 for T2\nquantification). SQNet thus offers accurate simultaneous segmentation and\nquantification, enhancing cardiac disease diagnosis, such as AMI.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 8 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.10570v3",
    "published_date": "2024-05-17 06:50:37 UTC",
    "updated_date": "2024-05-29 09:36:34 UTC"
  },
  {
    "arxiv_id": "2406.18538v2",
    "title": "VideoQA-SC: Adaptive Semantic Communication for Video Question Answering",
    "authors": [
      "Jiangyuan Guo",
      "Wei Chen",
      "Yuxuan Sun",
      "Jialong Xu",
      "Bo Ai"
    ],
    "abstract": "Although semantic communication (SC) has shown its potential in efficiently\ntransmitting multimodal data such as texts, speeches and images, SC for videos\nhas focused primarily on pixel-level reconstruction. However, these SC systems\nmay be suboptimal for downstream intelligent tasks. Moreover, SC systems\nwithout pixel-level video reconstruction present advantages by achieving higher\nbandwidth efficiency and real-time performance of various intelligent tasks.\nThe difficulty in such system design lies in the extraction of task-related\ncompact semantic representations and their accurate delivery over noisy\nchannels. In this paper, we propose an end-to-end SC system, named VideoQA-SC\nfor video question answering (VideoQA) tasks. Our goal is to accomplish VideoQA\ntasks directly based on video semantics over noisy or fading wireless channels,\nbypassing the need for video reconstruction at the receiver. To this end, we\ndevelop a spatiotemporal semantic encoder for effective video semantic\nextraction, and a learning-based bandwidth-adaptive deep joint source-channel\ncoding (DJSCC) scheme for efficient and robust video semantic transmission.\nExperiments demonstrate that VideoQA-SC outperforms traditional and advanced\nDJSCC-based SC systems that rely on video reconstruction at the receiver under\na wide range of channel conditions and bandwidth constraints. In particular,\nwhen the signal-to-noise ratio is low, VideoQA-SC can improve the answer\naccuracy by 5.17% while saving almost 99.5\\% of the bandwidth at the same time,\ncompared with the advanced DJSCC-based SC system. Our results show the great\npotential of SC system design for video applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18538v2",
    "published_date": "2024-05-17 06:11:10 UTC",
    "updated_date": "2025-02-11 07:31:10 UTC"
  },
  {
    "arxiv_id": "2405.10542v1",
    "title": "Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset",
    "authors": [
      "Jie Zhu",
      "Junhui Li",
      "Yalong Wen",
      "Lifan Guo"
    ],
    "abstract": "In light of recent breakthroughs in large language models (LLMs) that have\nrevolutionized natural language processing (NLP), there is an urgent need for\nnew benchmarks to keep pace with the fast development of LLMs. In this paper,\nwe propose CFLUE, the Chinese Financial Language Understanding Evaluation\nbenchmark, designed to assess the capability of LLMs across various dimensions.\nSpecifically, CFLUE provides datasets tailored for both knowledge assessment\nand application assessment. In knowledge assessment, it consists of 38K+\nmultiple-choice questions with associated solution explanations. These\nquestions serve dual purposes: answer prediction and question reasoning. In\napplication assessment, CFLUE features 16K+ test instances across distinct\ngroups of NLP tasks such as text classification, machine translation, relation\nextraction, reading comprehension, and text generation. Upon CFLUE, we conduct\na thorough evaluation of representative LLMs. The results reveal that only\nGPT-4 and GPT-4-turbo achieve an accuracy exceeding 60\\% in answer prediction\nfor knowledge assessment, suggesting that there is still substantial room for\nimprovement in current LLMs. In application assessment, although GPT-4 and\nGPT-4-turbo are the top two performers, their considerable advantage over\nlightweight LLMs is noticeably diminished. The datasets and scripts associated\nwith CFLUE are openly accessible at https://github.com/aliyun/cflue.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10542v1",
    "published_date": "2024-05-17 05:03:40 UTC",
    "updated_date": "2024-05-17 05:03:40 UTC"
  },
  {
    "arxiv_id": "2405.10536v1",
    "title": "Time-Varying Constraint-Aware Reinforcement Learning for Energy Storage Control",
    "authors": [
      "Jaeik Jeong",
      "Tai-Yeon Ku",
      "Wan-Ki Park"
    ],
    "abstract": "Energy storage devices, such as batteries, thermal energy storages, and\nhydrogen systems, can help mitigate climate change by ensuring a more stable\nand sustainable power supply. To maximize the effectiveness of such energy\nstorage, determining the appropriate charging and discharging amounts for each\ntime period is crucial. Reinforcement learning is preferred over traditional\noptimization for the control of energy storage due to its ability to adapt to\ndynamic and complex environments. However, the continuous nature of charging\nand discharging levels in energy storage poses limitations for discrete\nreinforcement learning, and time-varying feasible charge-discharge range based\non state of charge (SoC) variability also limits the conventional continuous\nreinforcement learning. In this paper, we propose a continuous reinforcement\nlearning approach that takes into account the time-varying feasible\ncharge-discharge range. An additional objective function was introduced for\nlearning the feasible action range for each time period, supplementing the\nobjectives of training the actor for policy learning and the critic for value\nlearning. This actively promotes the utilization of energy storage by\npreventing them from getting stuck in suboptimal states, such as continuous\nfull charging or discharging. This is achieved through the enforcement of the\ncharging and discharging levels into the feasible action range. The\nexperimental results demonstrated that the proposed method further maximized\nthe effectiveness of energy storage by actively enhancing its utilization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024 Workshop: Tackling Climate Change with Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2405.10536v1",
    "published_date": "2024-05-17 04:28:54 UTC",
    "updated_date": "2024-05-17 04:28:54 UTC"
  },
  {
    "arxiv_id": "2405.10529v2",
    "title": "Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors",
    "authors": [
      "Jiachen Sun",
      "Changsheng Wang",
      "Jiongxiao Wang",
      "Yiwei Zhang",
      "Chaowei Xiao"
    ],
    "abstract": "Large language models have become increasingly prominent, also signaling a\nshift towards multimodality as the next frontier in artificial intelligence,\nwhere their embeddings are harnessed as prompts to generate textual content.\nVision-language models (VLMs) stand at the forefront of this advancement,\noffering innovative ways to combine visual and textual data for enhanced\nunderstanding and interaction. However, this integration also enlarges the\nattack surface. Patch-based adversarial attack is considered the most realistic\nthreat model in physical vision applications, as demonstrated in many existing\nliterature. In this paper, we propose to address patched visual prompt\ninjection, where adversaries exploit adversarial patches to generate target\ncontent in VLMs. Our investigation reveals that patched adversarial prompts\nexhibit sensitivity to pixel-wise randomization, a trait that remains robust\neven against adaptive attacks designed to counteract such defenses. Leveraging\nthis insight, we introduce SmoothVLM, a defense mechanism rooted in smoothing\ntechniques, specifically tailored to protect VLMs from the threat of patched\nvisual prompt injectors. Our framework significantly lowers the attack success\nrate to a range between 0% and 5.0% on two leading VLMs, while achieving around\n67.3% to 95.0% context recovery of the benign images, demonstrating a balance\nbetween security and usability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.7; I.4"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.10529v2",
    "published_date": "2024-05-17 04:19:19 UTC",
    "updated_date": "2024-08-24 13:28:45 UTC"
  },
  {
    "arxiv_id": "2405.10516v2",
    "title": "Language Models can Evaluate Themselves via Probability Discrepancy",
    "authors": [
      "Tingyu Xia",
      "Bowen Yu",
      "Yuan Wu",
      "Yi Chang",
      "Chang Zhou"
    ],
    "abstract": "In this paper, we initiate our discussion by demonstrating how Large Language\nModels (LLMs), when tasked with responding to queries, display a more even\nprobability distribution in their answers if they are more adept, as opposed to\ntheir less skilled counterparts. Expanding on this foundational insight, we\npropose a new self-evaluation method ProbDiff for assessing the efficacy of\nvarious LLMs. This approach obviates the necessity for an additional evaluation\nmodel or the dependence on external, proprietary models like GPT-4 for\njudgment. It uniquely utilizes the LLMs being tested to compute the probability\ndiscrepancy between the initial response and its revised versions. A higher\ndiscrepancy for a given query between two LLMs indicates a relatively weaker\ncapability. Our findings reveal that ProbDiff achieves results on par with\nthose obtained from evaluations based on GPT-4, spanning a range of scenarios\nthat include natural language generation (NLG) tasks such as translation,\nsummarization, and our proposed Xiaohongshu blog writing task, and benchmarks\nfor LLM evaluation like AlignBench, MT-Bench, and AlpacaEval, across LLMs of\nvarying magnitudes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2405.10516v2",
    "published_date": "2024-05-17 03:50:28 UTC",
    "updated_date": "2024-07-09 02:56:14 UTC"
  },
  {
    "arxiv_id": "2405.11002v1",
    "title": "Large Language Models in Wireless Application Design: In-Context Learning-enhanced Automatic Network Intrusion Detection",
    "authors": [
      "Han Zhang",
      "Akram Bin Sediq",
      "Ali Afana",
      "Melike Erol-Kantarci"
    ],
    "abstract": "Large language models (LLMs), especially generative pre-trained transformers\n(GPTs), have recently demonstrated outstanding ability in information\ncomprehension and problem-solving. This has motivated many studies in applying\nLLMs to wireless communication networks. In this paper, we propose a\npre-trained LLM-empowered framework to perform fully automatic network\nintrusion detection. Three in-context learning methods are designed and\ncompared to enhance the performance of LLMs. With experiments on a real network\nintrusion detection dataset, in-context learning proves to be highly beneficial\nin improving the task processing performance in a way that no further training\nor fine-tuning of LLMs is required. We show that for GPT-4, testing accuracy\nand F1-Score can be improved by 90%. Moreover, pre-trained LLMs demonstrate big\npotential in performing wireless communication-related tasks. Specifically, the\nproposed framework can reach an accuracy and F1-Score of over 95% on different\ntypes of attacks with GPT-4 using only 10 in-context learning examples.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11002v1",
    "published_date": "2024-05-17 02:56:31 UTC",
    "updated_date": "2024-05-17 02:56:31 UTC"
  },
  {
    "arxiv_id": "2405.10497v1",
    "title": "SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge",
    "authors": [
      "Bo Wu",
      "Peiye Liu",
      "Wen-Huang Cheng",
      "Bei Liu",
      "Zhaoyang Zeng",
      "Jia Wang",
      "Qiushi Huang",
      "Jiebo Luo"
    ],
    "abstract": "Social Media Popularity Prediction (SMPP) is a crucial task that involves\nautomatically predicting future popularity values of online posts, leveraging\nvast amounts of multimodal data available on social media platforms. Studying\nand investigating social media popularity becomes central to various online\napplications and requires novel methods of comprehensive analysis, multimodal\ncomprehension, and accurate prediction.\n  SMP Challenge is an annual research activity that has spurred academic\nexploration in this area. This paper summarizes the challenging task, data, and\nresearch progress. As a critical resource for evaluating and benchmarking\npredictive models, we have released a large-scale SMPD benchmark encompassing\napproximately half a million posts authored by around 70K users. The research\nprogress analysis provides an overall analysis of the solutions and trends in\nrecent years. The SMP Challenge website (www.smp-challenge.com) provides the\nlatest information and news.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.SI"
    ],
    "primary_category": "cs.MM",
    "comment": "ACM Multimedia. arXiv admin note: text overlap with arXiv:1910.01795",
    "pdf_url": "http://arxiv.org/pdf/2405.10497v1",
    "published_date": "2024-05-17 02:36:14 UTC",
    "updated_date": "2024-05-17 02:36:14 UTC"
  },
  {
    "arxiv_id": "2405.10490v3",
    "title": "Neural Optimization with Adaptive Heuristics for Intelligent Marketing System",
    "authors": [
      "Changshuai Wei",
      "Benjamin Zelditch",
      "Joyce Chen",
      "Andre Assuncao Silva T Ribeiro",
      "Jingyi Kenneth Tay",
      "Borja Ocejo Elizondo",
      "Keerthi Selvaraj",
      "Aman Gupta",
      "Licurgo Benemann De Almeida"
    ],
    "abstract": "Computational marketing has become increasingly important in today's digital\nworld, facing challenges such as massive heterogeneous data, multi-channel\ncustomer journeys, and limited marketing budgets. In this paper, we propose a\ngeneral framework for marketing AI systems, the Neural Optimization with\nAdaptive Heuristics (NOAH) framework. NOAH is the first general framework for\nmarketing optimization that considers both to-business (2B) and to-consumer\n(2C) products, as well as both owned and paid channels. We describe key modules\nof the NOAH framework, including prediction, optimization, and adaptive\nheuristics, providing examples for bidding and content optimization. We then\ndetail the successful application of NOAH to LinkedIn's email marketing system,\nshowcasing significant wins over the legacy ranking system. Additionally, we\nshare details and insights that are broadly useful, particularly on: (i)\naddressing delayed feedback with lifetime value, (ii) performing large-scale\nlinear programming with randomization, (iii) improving retrieval with audience\nexpansion, (iv) reducing signal dilution in targeting tests, and (v) handling\nzero-inflated heavy-tail metrics in statistical testing.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "math.OC",
      "G.3; G.1.6; I.2"
    ],
    "primary_category": "stat.ME",
    "comment": "KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10490v3",
    "published_date": "2024-05-17 01:44:30 UTC",
    "updated_date": "2024-06-25 22:52:43 UTC"
  },
  {
    "arxiv_id": "2405.10481v1",
    "title": "Multi-Evidence based Fact Verification via A Confidential Graph Neural Network",
    "authors": [
      "Yuqing Lan",
      "Zhenghao Liu",
      "Yu Gu",
      "Xiaoyuan Yi",
      "Xiaohua Li",
      "Liner Yang",
      "Ge Yu"
    ],
    "abstract": "Fact verification tasks aim to identify the integrity of textual contents\naccording to the truthful corpus. Existing fact verification models usually\nbuild a fully connected reasoning graph, which regards claim-evidence pairs as\nnodes and connects them with edges. They employ the graph to propagate the\nsemantics of the nodes. Nevertheless, the noisy nodes usually propagate their\nsemantics via the edges of the reasoning graph, which misleads the semantic\nrepresentations of other nodes and amplifies the noise signals. To mitigate the\npropagation of noisy semantic information, we introduce a Confidential Graph\nAttention Network (CO-GAT), which proposes a node masking mechanism for\nmodeling the nodes. Specifically, CO-GAT calculates the node confidence score\nby estimating the relevance between the claim and evidence pieces. Then, the\nnode masking mechanism uses the node confidence scores to control the noise\ninformation flow from the vanilla node to the other graph nodes. CO-GAT\nachieves a 73.59% FEVER score on the FEVER dataset and shows the generalization\nability by broadening the effectiveness to the science-specific domain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12pages",
    "pdf_url": "http://arxiv.org/pdf/2405.10481v1",
    "published_date": "2024-05-17 01:02:03 UTC",
    "updated_date": "2024-05-17 01:02:03 UTC"
  },
  {
    "arxiv_id": "2405.10476v1",
    "title": "Analysis, Modeling and Design of Personalized Digital Learning Environment",
    "authors": [
      "Sanjaya Khanal",
      "Shiva Raj Pokhrel"
    ],
    "abstract": "This research analyzes, models and develops a novel Digital Learning\nEnvironment (DLE) fortified by the innovative Private Learning Intelligence\n(PLI) framework. The proposed PLI framework leverages federated machine\nlearning (FL) techniques to autonomously construct and continuously refine\npersonalized learning models for individual learners, ensuring robust privacy\nprotection. Our approach is pivotal in advancing DLE capabilities, empowering\nlearners to actively participate in personalized real-time learning\nexperiences. The integration of PLI within a DLE also streamlines instructional\ndesign and development demands for personalized teaching/learning. We seek ways\nto establish a foundation for the seamless integration of FL into learning\nsystems, offering a transformative approach to personalized learning in digital\nenvironments. Our implementation details and code are made public.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "IEEE Trans on Education, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10476v1",
    "published_date": "2024-05-17 00:26:16 UTC",
    "updated_date": "2024-05-17 00:26:16 UTC"
  }
]