[
  {
    "arxiv_id": "2505.00222v1",
    "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders",
    "authors": [
      "Peter Yichen Chen",
      "Pingchuan Ma",
      "Niklas Hagemann",
      "John Romanishin",
      "Wei Wang",
      "Daniela Rus",
      "Wojciech Matusik"
    ],
    "abstract": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00222v1",
    "published_date": "2025-04-30 23:55:44 UTC",
    "updated_date": "2025-04-30 23:55:44 UTC"
  },
  {
    "arxiv_id": "2505.00216v1",
    "title": "Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders",
    "authors": [
      "Xuwei Yang",
      "Fatemeh Tavakoli",
      "David B. Emerson",
      "Anastasis Kratsios"
    ],
    "abstract": "Most industry-standard generative AIs and feature encoders are proprietary,\noffering only black-box access: their outputs are observable, but their\ninternal parameters and architectures remain hidden from the end-user. This\nblack-box access is especially limiting when constructing mixture-of-expert\ntype ensemble models since the user cannot optimize each proprietary AI's\ninternal parameters. Our problem naturally lends itself to a non-competitive\ngame-theoretic lens where each proprietary AI (agent) is inherently competing\nagainst the other AI agents, with this competition arising naturally due to\ntheir obliviousness of the AI's to their internal structure. In contrast, the\nuser acts as a central planner trying to synchronize the ensemble of competing\nAIs.\n  We show the existence of the unique Nash equilibrium in the online setting,\nwhich we even compute in closed-form by eliciting a feedback mechanism between\nany given time series and the sequence generated by each (proprietary) AI\nagent. Our solution is implemented as a decentralized, federated-learning\nalgorithm in which each agent optimizes their structure locally on their\nmachine without ever releasing any internal structure to the others. We obtain\nrefined expressions for pre-trained models such as transformers, random feature\nmodels, and echo-state networks. Our ``proprietary federated learning''\nalgorithm is implemented on a range of real-world and synthetic time-series\nbenchmarks. It achieves orders-of-magnitude improvements in predictive accuracy\nover natural benchmarks, of which there are surprisingly few due to this\nnatural problem still being largely unexplored.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "68T05, 68T07, 91A80",
      "I.2.1; I.2.11; G.1.6"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages, 16 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.00216v1",
    "published_date": "2025-04-30 23:19:37 UTC",
    "updated_date": "2025-04-30 23:19:37 UTC"
  },
  {
    "arxiv_id": "2505.00749v1",
    "title": "The Coral Protocol: Open Infrastructure Connecting The Internet of Agents",
    "authors": [
      "Roman J. Georgio",
      "Caelum Forder",
      "Suman Deb",
      "Peter Carroll",
      "Önder Gürcan"
    ],
    "abstract": "The Coral Protocol is an open and decentralized collaboration infrastructure\nthat enables communication, coordination, trust and payments for The Internet\nof Agents. It addresses the growing need for interoperability in a world where\norganizations are deploying multiple specialized AI agents that must work\ntogether across domains and vendors. As a foundational platform for multi-agent\nAI ecosystems, Coral establishes a common language and coordination framework\nallowing any agent to participate in complex workflows with others. Its design\nemphasizes broad compatibility, security, and vendor neutrality, ensuring that\nagent interactions are efficient and trustworthy. In particular, Coral\nintroduces standardized messaging formats for agent communication, a modular\ncoordination mechanism for orchestrating multi-agent tasks, and secure team\nformation capabilities for dynamically assembling trusted groups of agents.\nTogether, these innovations position Coral Protocol as a cornerstone of the\nemerging \"Internet of Agents,\" unlocking new levels of automation, collective\nintelligence, and business value through open agent collaboration.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "31 pages, 3 figures, Whitepaper",
    "pdf_url": "http://arxiv.org/pdf/2505.00749v1",
    "published_date": "2025-04-30 22:17:13 UTC",
    "updated_date": "2025-04-30 22:17:13 UTC"
  },
  {
    "arxiv_id": "2505.00204v1",
    "title": "RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset",
    "authors": [
      "Sumit Verma",
      "Pritam Prasun",
      "Arpit Jaiswal",
      "Pritish Kumar"
    ],
    "abstract": "As AI systems become embedded in real-world applications, ensuring they meet\nethical standards is crucial. While existing AI ethics frameworks emphasize\nfairness, transparency, and accountability, they often lack actionable\nevaluation methods. This paper introduces a systematic approach using the\nResponsible AI Labs (RAIL) framework, which includes eight measurable\ndimensions to assess the normative behavior of large language models (LLMs). We\napply this framework to Anthropic's \"Values in the Wild\" dataset, containing\nover 308,000 anonymized conversations with Claude and more than 3,000 annotated\nvalue expressions. Our study maps these values to RAIL dimensions, computes\nsynthetic scores, and provides insights into the ethical behavior of LLMs in\nreal-world use.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00204v1",
    "published_date": "2025-04-30 22:03:26 UTC",
    "updated_date": "2025-04-30 22:03:26 UTC"
  },
  {
    "arxiv_id": "2505.00190v1",
    "title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders",
    "authors": [
      "Hans Peter",
      "Anders Søgaard"
    ],
    "abstract": "Sparse autoencoders (SAEs)\n\\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders}\nrely on dictionary learning to extract interpretable features from neural\nnetworks at scale in an unsupervised manner, with applications to\nrepresentation engineering and information retrieval. SAEs are, however,\ncomputationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially\nwhen multiple SAEs of different sizes are needed. We show that dictionary\nimportance in vanilla SAEs follows a power law. We compare progressive coding\nbased on subset pruning of SAEs -- to jointly training nested SAEs, or\nso-called {\\em Matryoshka} SAEs\n\\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling\ntask. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured\nlanguage modeling loss, as well as higher representational similarity. Pruned\nvanilla SAEs are more interpretable, however. We discuss the origins and\nimplications of this trade-off.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00190v1",
    "published_date": "2025-04-30 21:08:32 UTC",
    "updated_date": "2025-04-30 21:08:32 UTC"
  },
  {
    "arxiv_id": "2505.00186v1",
    "title": "Neuroevolution of Self-Attention Over Proto-Objects",
    "authors": [
      "Rafael C. Pinto",
      "Anderson R. Tavares"
    ],
    "abstract": "Proto-objects - image regions that share common visual properties - offer a\npromising alternative to traditional attention mechanisms based on\nrectangular-shaped image patches in neural networks. Although previous work\ndemonstrated that evolving a patch-based hard-attention module alongside a\ncontroller network could achieve state-of-the-art performance in visual\nreinforcement learning tasks, our approach leverages image segmentation to work\nwith higher-level features. By operating on proto-objects rather than fixed\npatches, we significantly reduce the representational complexity: each image\ndecomposes into fewer proto-objects than regular patches, and each proto-object\ncan be efficiently encoded as a compact feature vector. This enables a\nsubstantially smaller self-attention module that processes richer semantic\ninformation. Our experiments demonstrate that this proto-object-based approach\nmatches or exceeds the state-of-the-art performance of patch-based\nimplementations with 62% less parameters and 2.6 times less training time.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "9 pages, 16 figures, GECCO",
    "pdf_url": "http://arxiv.org/pdf/2505.00186v1",
    "published_date": "2025-04-30 21:01:20 UTC",
    "updated_date": "2025-04-30 21:01:20 UTC"
  },
  {
    "arxiv_id": "2505.00174v2",
    "title": "Real-World Gaps in AI Governance Research",
    "authors": [
      "Ilan Strauss",
      "Isobel Moure",
      "Tim O'Reilly",
      "Sruly Rosenblat"
    ],
    "abstract": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Corrected a previous error: replaced 'underrepresented in Academic AI\n  research' with the intended phrase 'underrepresented in Corporate AI\n  research'",
    "pdf_url": "http://arxiv.org/pdf/2505.00174v2",
    "published_date": "2025-04-30 20:44:42 UTC",
    "updated_date": "2025-05-05 21:12:46 UTC"
  },
  {
    "arxiv_id": "2505.00173v1",
    "title": "First Order Logic with Fuzzy Semantics for Describing and Recognizing Nerves in Medical Images",
    "authors": [
      "Isabelle Bloch",
      "Enzo Bonnot",
      "Pietro Gori",
      "Giammarco La Barbera",
      "Sabine Sarnacki"
    ],
    "abstract": "This article deals with the description and recognition of fiber bundles, in\nparticular nerves, in medical images, based on the anatomical description of\nthe fiber trajectories. To this end, we propose a logical formalization of this\nanatomical knowledge. The intrinsically imprecise description of nerves, as\nfound in anatomical textbooks, leads us to propose fuzzy semantics combined\nwith first-order logic. We define a language representing spatial entities,\nrelations between these entities and quantifiers. A formula in this language is\nthen a formalization of the natural language description. The semantics are\ngiven by fuzzy representations in a concrete domain and satisfaction degrees of\nrelations. Based on this formalization, a spatial reasoning algorithm is\nproposed for segmentation and recognition of nerves from anatomical and\ndiffusion magnetic resonance images, which is illustrated on pelvic nerves in\npediatric imaging, enabling surgeons to plan surgery.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for presentation at the FUZZ-IEEE 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2505.00173v1",
    "published_date": "2025-04-30 20:41:04 UTC",
    "updated_date": "2025-04-30 20:41:04 UTC"
  },
  {
    "arxiv_id": "2505.00171v1",
    "title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction",
    "authors": [
      "Saram Abbas",
      "Naeem Soomro",
      "Rishad Shafik",
      "Rakesh Heer",
      "Kabita Adhikari"
    ],
    "abstract": "Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in\noncology, with recurrence rates soaring as high as 70-80%. Each recurrence\ntriggers a cascade of invasive procedures, lifelong surveillance, and\nescalating healthcare costs - affecting 460,000 individuals worldwide. However,\nexisting clinical prediction tools remain fundamentally flawed, often\noverestimating recurrence risk and failing to provide personalized insights for\npatient management. In this work, we propose an interpretable deep learning\nframework that integrates vector embeddings and attention mechanisms to improve\nNMIBC recurrence prediction performance. We incorporate vector embeddings for\ncategorical variables such as smoking status and intravesical treatments,\nallowing the model to capture complex relationships between patient attributes\nand recurrence risk. These embeddings provide a richer representation of the\ndata, enabling improved feature interactions and enhancing prediction\nperformance. Our approach not only enhances performance but also provides\nclinicians with patient-specific insights by highlighting the most influential\nfeatures contributing to recurrence risk for each patient. Our model achieves\naccuracy of 70% with tabular data, outperforming conventional statistical\nmethods while providing clinician-friendly patient-level explanations through\nfeature attention. Unlike previous studies, our approach identifies new\nimportant factors influencing recurrence, such as surgical duration and\nhospital stay, which had not been considered in existing NMIBC prediction\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 5 figures, Accepted to be presented at the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society (EMBC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.00171v1",
    "published_date": "2025-04-30 20:39:33 UTC",
    "updated_date": "2025-04-30 20:39:33 UTC"
  },
  {
    "arxiv_id": "2505.00169v2",
    "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation",
    "authors": [
      "Filipp Nikitin",
      "Ian Dunn",
      "David Ryan Koes",
      "Olexandr Isayev"
    ],
    "abstract": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00169v2",
    "published_date": "2025-04-30 20:29:22 UTC",
    "updated_date": "2025-05-16 03:27:25 UTC"
  },
  {
    "arxiv_id": "2505.00150v1",
    "title": "Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models",
    "authors": [
      "Minh-Hao Van",
      "Xintao Wu"
    ],
    "abstract": "The rapid evolution of social media has provided enhanced communication\nchannels for individuals to create online content, enabling them to express\ntheir thoughts and opinions. Multimodal memes, often utilized for playful or\nhumorous expressions with visual and textual elements, are sometimes misused to\ndisseminate hate speech against individuals or groups. While the detection of\nhateful memes is well-researched, developing effective methods to transform\nhateful content in memes remains a significant challenge. Leveraging the\npowerful generation and reasoning capabilities of Vision-Language Models\n(VLMs), we address the tasks of detecting and mitigating hateful content. This\npaper presents two key contributions: first, a definition-guided prompting\ntechnique for detecting hateful memes, and second, a unified framework for\nmitigating hateful content in memes, named UnHateMeme, which works by replacing\nhateful textual and/or visual components. With our definition-guided prompts,\nVLMs achieve impressive performance on hateful memes detection task.\nFurthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a\nstrong capability to convert hateful memes into non-hateful forms that meet\nhuman-level criteria for hate speech and maintain multimodal coherence between\nimage and text. Through empirical experiments, we show the effectiveness of\nstate-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the\nproposed tasks, providing a comprehensive analysis of their respective\nstrengths and limitations for these tasks. This paper aims to shed light on\nimportant applications of VLMs for ensuring safe and respectful online\nenvironments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00150v1",
    "published_date": "2025-04-30 19:48:12 UTC",
    "updated_date": "2025-04-30 19:48:12 UTC"
  },
  {
    "arxiv_id": "2505.03788v1",
    "title": "Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding",
    "authors": [
      "Trilok Padhi",
      "Ramneet Kaur",
      "Adam D. Cobb",
      "Manoj Acharya",
      "Anirban Roy",
      "Colin Samplawski",
      "Brian Matejek",
      "Alexander M. Berenbeim",
      "Nathaniel D. Bastian",
      "Susmit Jha"
    ],
    "abstract": "We introduce a novel approach for calibrating uncertainty quantification (UQ)\ntailored for multi-modal large language models (LLMs). Existing\nstate-of-the-art UQ methods rely on consistency among multiple responses\ngenerated by the LLM on an input query under diverse settings. However, these\napproaches often report higher confidence in scenarios where the LLM is\nconsistently incorrect. This leads to a poorly calibrated confidence with\nrespect to accuracy. To address this, we leverage cross-modal consistency in\naddition to self-consistency to improve the calibration of the multi-modal\nmodels. Specifically, we ground the textual responses to the visual inputs. The\nconfidence from the grounding model is used to calibrate the overall\nconfidence. Given that using a grounding model adds its own uncertainty in the\npipeline, we apply temperature scaling - a widely accepted parametric\ncalibration technique - to calibrate the grounding model's confidence in the\naccuracy of generated responses. We evaluate the proposed approach across\nmultiple multi-modal tasks, such as medical question answering (Slake) and\nvisual question answering (VQAv2), considering multi-modal models such as\nLLaVA-Med and LLaVA. The experiments demonstrate that the proposed framework\nachieves significantly improved calibration on both tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03788v1",
    "published_date": "2025-04-30 19:19:21 UTC",
    "updated_date": "2025-04-30 19:19:21 UTC"
  },
  {
    "arxiv_id": "2505.00136v1",
    "title": "GPRat: Gaussian Process Regression with Asynchronous Tasks",
    "authors": [
      "Maksim Helmann",
      "Alexander Strack",
      "Dirk Pflüger"
    ],
    "abstract": "Python is the de-facto language for software development in artificial\nintelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow,\nrely on parallelization built into their BLAS backends to achieve speedup on\nCPUs. However, only applying parallelization in a low-level backend can lead to\nperformance and scaling degradation. In this work, we present a novel way of\nbinding task-based C++ code built on the asynchronous runtime model HPX to a\nhigh-level Python API using pybind11. We develop a parallel Gaussian process\n(GP) li- brary as an application. The resulting Python library GPRat combines\nthe ease of use of commonly available GP libraries with the performance and\nscalability of asynchronous runtime systems. We evaluate the per- formance on a\nmass-spring-damper system, a standard benchmark from control theory, for\nvarying numbers of regressors (features). The results show almost no binding\noverhead when binding the asynchronous HPX code using pybind11. Compared to\nGPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD\nEPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction\nspeedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number\nof features from eight to 128, we observe speedups of 29.62 and 21.19,\nrespectively. These results showcase the potential of using asynchronous tasks\nwithin Python-based AI applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.00136v1",
    "published_date": "2025-04-30 19:08:51 UTC",
    "updated_date": "2025-04-30 19:08:51 UTC"
  },
  {
    "arxiv_id": "2505.00127v1",
    "title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs",
    "authors": [
      "Jinyan Su",
      "Jennifer Healey",
      "Preslav Nakov",
      "Claire Cardie"
    ],
    "abstract": "Large language models (LLMs) are increasingly optimized for long reasoning,\nunder the assumption that more reasoning leads to better performance. However,\nemerging evidence suggests that longer responses can sometimes degrade accuracy\nrather than improve it. In this paper, we conduct a systematic empirical study\nof the relationship between reasoning length and answer correctness. We find\nthat LLMs tend to overthink simple problems, generating unnecessarily long\noutputs, and underthink harder ones, failing to extend their reasoning when it\nis most needed. This indicates that models might misjudge problem difficulty\nand fail to calibrate their response length appropriately. Furthermore, we\ninvestigate the effects of length reduction with a preference optimization\nalgorithm when simply preferring the shorter responses regardless of answer\ncorrectness. Experiments show that the generation length can be significantly\nreduced while maintaining acceptable accuracy. Our findings highlight\ngeneration length as a meaningful signal for reasoning behavior and motivate\nfurther exploration into LLMs' self-awareness in reasoning length adaptation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00127v1",
    "published_date": "2025-04-30 18:48:06 UTC",
    "updated_date": "2025-04-30 18:48:06 UTC"
  },
  {
    "arxiv_id": "2505.00114v1",
    "title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese",
    "authors": [
      "Silvana Yakhni",
      "Ali Chehab"
    ],
    "abstract": "This paper examines the effectiveness of Large Language Models (LLMs) in\ntranslating the low-resource Lebanese dialect, focusing on the impact of\nculturally authentic data versus larger translated datasets. We compare three\nfine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using\nopen-source Aya23 models. Experiments reveal that models fine-tuned on a\nsmaller but culturally aware Lebanese dataset (LW) consistently outperform\nthose trained on larger, non-native data. The best results were achieved\nthrough contrastive fine-tuning paired with contrastive prompting, which\nindicates the benefits of exposing translation models to bad examples. In\naddition, to ensure authentic evaluation, we introduce LebEval, a new benchmark\nderived from native Lebanese content, and compare it to the existing FLoRes\nbenchmark. Our findings challenge the \"More Data is Better\" paradigm and\nemphasize the crucial role of cultural authenticity in dialectal translation.\nWe made our datasets and code available on Github.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00114v1",
    "published_date": "2025-04-30 18:33:53 UTC",
    "updated_date": "2025-04-30 18:33:53 UTC"
  },
  {
    "arxiv_id": "2505.03787v1",
    "title": "ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual Explanations for ECG Arrhythmia Classification",
    "authors": [
      "Zuraiz Baig",
      "Sidra Nasir",
      "Rizwan Ahmed Khan",
      "Muhammad Zeeshan Ul Haque"
    ],
    "abstract": "Cardiac arrhythmias are a leading cause of life-threatening cardiac events,\nhighlighting the urgent need for accurate and timely detection.\nElectrocardiography (ECG) remains the clinical gold standard for arrhythmia\ndiagnosis; however, manual interpretation is time-consuming, dependent on\nclinical expertise, and prone to human error. Although deep learning has\nadvanced automated ECG analysis, many existing models abstract away the\nsignal's intrinsic temporal and morphological features, lack interpretability,\nand are computationally intensive-hindering their deployment on\nresource-constrained platforms. In this work, we propose two novel lightweight\n1D convolutional neural networks, ArrhythmiNet V1 and V2, optimized for\nefficient, real-time arrhythmia classification on edge devices. Inspired by\nMobileNet's depthwise separable convolutional design, these models maintain\nmemory footprints of just 302.18 KB and 157.76 KB, respectively, while\nachieving classification accuracies of 0.99 (V1) and 0.98 (V2) on the MIT-BIH\nArrhythmia Dataset across five classes: Normal Sinus Rhythm, Left Bundle Branch\nBlock, Right Bundle Branch Block, Atrial Premature Contraction, and Premature\nVentricular Contraction. In order to ensure clinical transparency and\nrelevance, we integrate Shapley Additive Explanations and Gradient-weighted\nClass Activation Mapping, enabling both local and global interpretability.\nThese techniques highlight physiologically meaningful patterns such as the QRS\ncomplex and T-wave that contribute to the model's predictions. We also discuss\nperformance-efficiency trade-offs and address current limitations related to\ndataset diversity and generalizability. Overall, our findings demonstrate the\nfeasibility of combining interpretability, predictive accuracy, and\ncomputational efficiency in practical, wearable, and embedded ECG monitoring\nsystems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages and 08 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.03787v1",
    "published_date": "2025-04-30 18:22:45 UTC",
    "updated_date": "2025-04-30 18:22:45 UTC"
  },
  {
    "arxiv_id": "2505.00100v1",
    "title": "Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses",
    "authors": [
      "Ethan Dickey",
      "Andres Bejarano",
      "Rhianna Kuperus",
      "Bárbara Fagundes"
    ],
    "abstract": "Generative AI (GenAI) is rapidly entering computer science education, yet its\neffects on student learning, skill development, and perceptions remain\nunderexplored. Concerns about overreliance coexist with a gap in research on\nstructured scaffolding to guide tool use in formal courses. This study examines\nthe impact of a dedicated \"AI-Lab\" intervention -- emphasizing guided\nscaffolding and mindful engagement -- on undergraduate students in Data\nStructures and Algorithms, Competitive Programming, and first-year engineering\ncourses at Purdue University.\n  Over three semesters, we integrated AI-Lab modules into four mandatory and\nelective courses, yielding 831 matched pre- and post-intervention survey\nresponses, alongside focus group discussions. Employing a mixed-methods\napproach, we analyzed quantitative shifts in usage patterns and attitudes as\nwell as qualitative narratives of student experiences.\n  While the overall frequency of GenAI usage for homework or programming\nprojects remained largely stable, we observed large effect sizes in comfort and\nopenness across conceptual, debugging, and homework problems. Notably, usage\npatterns for debugging also shifted statistically significantly, reflecting\nstudents' more mindful and deliberate approach. Focus group discussions\ncorroborated these results, suggesting that the intervention \"bridged the gap\"\nbetween naive GenAI usage and more nuanced, reflective integration of AI tools\ninto coursework, ultimately heightening students' awareness of their own skill\ndevelopment.\n  These findings suggest that structured, scaffolded interventions can enable\nstudents to harness GenAI's benefits without undermining essential\ncompetencies. We offer evidence-based recommendations for educators seeking to\nintegrate GenAI responsibly into computing curricula and identify avenues for\nfuture research on GenAI-supported pedagogy.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "K.3"
    ],
    "primary_category": "cs.CY",
    "comment": "18 pages, 5 figures, 17 tables, submitted for publication",
    "pdf_url": "http://arxiv.org/pdf/2505.00100v1",
    "published_date": "2025-04-30 18:12:42 UTC",
    "updated_date": "2025-04-30 18:12:42 UTC"
  },
  {
    "arxiv_id": "2505.00091v2",
    "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios",
    "authors": [
      "Tengchao Zhang",
      "Yonglin Tian",
      "Fei Lin",
      "Jun Huang",
      "Patrik P. Süli",
      "Rui Qin",
      "Fei-Yue Wang"
    ],
    "abstract": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing approaches, this paper\nproposes coordination field agentic system for coordinating heterogeneous UAV\nswarms in complex urban scenarios. In this system, large language models (LLMs)\nis responsible for interpreting high-level human instructions and converting\nthem into executable commands for the UAV swarms, such as patrol and target\ntracking. Subsequently, a Coordination field mechanism is proposed to guide UAV\nmotion and task selection, enabling decentralized and adaptive allocation of\nemergent tasks. A total of 50 rounds of comparative testing were conducted\nacross different models in a 2D simulation space to evaluate their performance.\nExperimental results demonstrate that the proposed system achieves superior\nperformance in terms of task coverage, response time, and adaptability to\ndynamic changes.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted ITSC 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00091v2",
    "published_date": "2025-04-30 18:02:45 UTC",
    "updated_date": "2025-05-03 16:45:20 UTC"
  },
  {
    "arxiv_id": "2504.21851v1",
    "title": "TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments",
    "authors": [
      "Sichang Tu",
      "Abigail Powers",
      "Stephen Doogan",
      "Jinho D. Choi"
    ],
    "abstract": "Objectives: While Large Language Models (LLMs) have been widely used to\nassist clinicians and support patients, no existing work has explored dialogue\nsystems for standard diagnostic interviews and assessments. This study aims to\nbridge the gap in mental healthcare accessibility by developing an LLM-powered\ndialogue system that replicates clinician behavior. Materials and Methods: We\nintroduce TRUST, a framework of cooperative LLM modules capable of conducting\nformal diagnostic interviews and assessments for Post-Traumatic Stress Disorder\n(PTSD). To guide the generation of appropriate clinical responses, we propose a\nDialogue Acts schema specifically designed for clinical interviews.\nAdditionally, we develop a patient simulation approach based on real-life\ninterview transcripts to replace time-consuming and costly manual testing by\nclinicians. Results: A comprehensive set of evaluation metrics is designed to\nassess the dialogue system from both the agent and patient simulation\nperspectives. Expert evaluations by conversation and clinical specialists show\nthat TRUST performs comparably to real-life clinical interviews. Discussion:\nOur system performs at the level of average clinicians, with room for future\nenhancements in communication styles and response appropriateness. Conclusions:\nOur TRUST framework shows its potential to facilitate mental healthcare\navailability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.21851v1",
    "published_date": "2025-04-30 17:58:06 UTC",
    "updated_date": "2025-04-30 17:58:06 UTC"
  },
  {
    "arxiv_id": "2504.21849v1",
    "title": "Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support",
    "authors": [
      "Justin B. Bullock",
      "Janet V. T. Pauketat",
      "Hsini Huang",
      "Yi-Fan Wang",
      "Jacy Reese Anthis"
    ],
    "abstract": "Governance institutions must respond to societal risks, including those posed\nby generative AI. This study empirically examines how public trust in\ninstitutions and AI technologies, along with perceived risks, shape preferences\nfor AI regulation. Using the nationally representative 2023 Artificial\nIntelligence, Morality, and Sentience (AIMS) survey, we assess trust in\ngovernment, AI companies, and AI technologies, as well as public support for\nregulatory measures such as slowing AI development or outright bans on advanced\nAI. Our findings reveal broad public support for AI regulation, with risk\nperception playing a significant role in shaping policy preferences.\nIndividuals with higher trust in government favor regulation, while those with\ngreater trust in AI companies and AI technologies are less inclined to support\nrestrictions. Trust in government and perceived risks significantly predict\npreferences for both soft (e.g., slowing development) and strong (e.g., banning\nAI systems) regulatory interventions. These results highlight the importance of\npublic opinion in AI governance. As AI capabilities advance, effective\nregulation will require balancing public concerns about risks with trust in\ninstitutions. This study provides a foundational empirical baseline for\npolicymakers navigating AI governance and underscores the need for further\nresearch into public trust, risk perception, and regulatory strategies in the\nevolving AI landscape.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "31 pages, 1 figure, 5 tables, accepted to Public Performance and\n  Management Review",
    "pdf_url": "http://arxiv.org/pdf/2504.21849v1",
    "published_date": "2025-04-30 17:56:23 UTC",
    "updated_date": "2025-04-30 17:56:23 UTC"
  },
  {
    "arxiv_id": "2504.21848v1",
    "title": "Characterizing AI Agents for Alignment and Governance",
    "authors": [
      "Atoosa Kasirzadeh",
      "Iason Gabriel"
    ],
    "abstract": "The creation of effective governance mechanisms for AI agents requires a\ndeeper understanding of their core properties and how these properties relate\nto questions surrounding the deployment and operation of agents in the world.\nThis paper provides a characterization of AI agents that focuses on four\ndimensions: autonomy, efficacy, goal complexity, and generality. We propose\ndifferent gradations for each dimension, and argue that each dimension raises\nunique questions about the design, operation, and governance of these systems.\nMoreover, we draw upon this framework to construct \"agentic profiles\" for\ndifferent kinds of AI agents. These profiles help to illuminate cross-cutting\ntechnical and non-technical governance challenges posed by different classes of\nAI agents, ranging from narrow task-specific assistants to highly autonomous\ngeneral-purpose systems. By mapping out key axes of variation and continuity,\nthis framework provides developers, policymakers, and members of the public\nwith the opportunity to develop governance approaches that better align with\ncollective societal goals.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21848v1",
    "published_date": "2025-04-30 17:55:48 UTC",
    "updated_date": "2025-04-30 17:55:48 UTC"
  },
  {
    "arxiv_id": "2504.21846v1",
    "title": "Active Light Modulation to Counter Manipulation of Speech Visual Content",
    "authors": [
      "Hadleigh Schwartz",
      "Xiaofeng Yan",
      "Charles J. Carver",
      "Xia Zhou"
    ],
    "abstract": "High-profile speech videos are prime targets for falsification, owing to\ntheir accessibility and influence. This work proposes Spotlight, a low-overhead\nand unobtrusive system for protecting live speech videos from visual\nfalsification of speaker identity and lip and facial motion. Unlike predominant\nfalsification detection methods operating in the digital domain, Spotlight\ncreates dynamic physical signatures at the event site and embeds them into all\nvideo recordings via imperceptible modulated light. These physical signatures\nencode semantically-meaningful features unique to the speech event, including\nthe speaker's identity and facial motion, and are cryptographically-secured to\nprevent spoofing. The signatures can be extracted from any video downstream and\nvalidated against the portrayed speech content to check its integrity. Key\nelements of Spotlight include (1) a framework for generating extremely compact\n(i.e., 150-bit), pose-invariant speech video features, based on\nlocality-sensitive hashing; and (2) an optical modulation scheme that embeds\n>200 bps into video while remaining imperceptible both in video and live.\nPrototype experiments on extensive video datasets show Spotlight achieves AUCs\n$\\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified\nvideos. Further, Spotlight is highly robust across recording conditions, video\npost-processing techniques, and white-box adversarial attacks on its video\nfeature extraction methodologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21846v1",
    "published_date": "2025-04-30 17:55:24 UTC",
    "updated_date": "2025-04-30 17:55:24 UTC"
  },
  {
    "arxiv_id": "2504.21831v1",
    "title": "Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization",
    "authors": [
      "Anas Anwarul Haq Khan",
      "Utkarsh Verma",
      "Prateek Chanda",
      "Ganesh Ramakrishnan"
    ],
    "abstract": "We introduce DEEVISum (Distilled Early Exit Vision language model for\nSummarization), a lightweight, efficient, and scalable vision language model\ndesigned for segment wise video summarization. Leveraging multi modal prompts\nthat combine textual and audio derived signals, DEEVISum incorporates Multi\nStage Knowledge Distillation (MSKD) and Early Exit (EE) to strike a balance\nbetween performance and efficiency. MSKD offers a 1.33% absolute F1 improvement\nover baseline distillation (0.5%), while EE reduces inference time by\napproximately 21% with a 1.3 point drop in F1. Evaluated on the TVSum dataset,\nour best model PaLI Gemma2 3B + MSKD achieves an F1 score of 61.1, competing\nthe performance of significantly larger models, all while maintaining a lower\ncomputational footprint. We publicly release our code and processed dataset to\nsupport further research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21831v1",
    "published_date": "2025-04-30 17:37:55 UTC",
    "updated_date": "2025-04-30 17:37:55 UTC"
  },
  {
    "arxiv_id": "2504.21801v1",
    "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition",
    "authors": [
      "Z. Z. Ren",
      "Zhihong Shao",
      "Junxiao Song",
      "Huajian Xin",
      "Haocheng Wang",
      "Wanjia Zhao",
      "Liyue Zhang",
      "Zhe Fu",
      "Qihao Zhu",
      "Dejian Yang",
      "Z. F. Wu",
      "Zhibin Gou",
      "Shirong Ma",
      "Hongxuan Tang",
      "Yuxuan Liu",
      "Wenjun Gao",
      "Daya Guo",
      "Chong Ruan"
    ],
    "abstract": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21801v1",
    "published_date": "2025-04-30 16:57:48 UTC",
    "updated_date": "2025-04-30 16:57:48 UTC"
  },
  {
    "arxiv_id": "2504.21800v3",
    "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues",
    "authors": [
      "Suhas BN",
      "Dominik Mattioli",
      "Saeed Abdullah",
      "Rosa I. Arriaga",
      "Chris W. Wiese",
      "Andrew M. Sherrill"
    ],
    "abstract": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "68T50",
      "I.2.7; H.3.1"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.21800v3",
    "published_date": "2025-04-30 16:56:56 UTC",
    "updated_date": "2025-05-21 20:26:35 UTC"
  },
  {
    "arxiv_id": "2504.21798v2",
    "title": "SWE-smith: Scaling Data for Software Engineering Agents",
    "authors": [
      "John Yang",
      "Kilian Leret",
      "Carlos E. Jimenez",
      "Alexander Wettig",
      "Kabir Khandpur",
      "Yanzhe Zhang",
      "Binyuan Hui",
      "Ofir Press",
      "Ludwig Schmidt",
      "Diyi Yang"
    ],
    "abstract": "Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "All assets available at https://swesmith.com",
    "pdf_url": "http://arxiv.org/pdf/2504.21798v2",
    "published_date": "2025-04-30 16:56:06 UTC",
    "updated_date": "2025-05-21 17:21:45 UTC"
  },
  {
    "arxiv_id": "2504.21776v1",
    "title": "WebThinker: Empowering Large Reasoning Models with Deep Research Capability",
    "authors": [
      "Xiaoxi Li",
      "Jiajie Jin",
      "Guanting Dong",
      "Hongjin Qian",
      "Yutao Zhu",
      "Yongkang Wu",
      "Ji-Rong Wen",
      "Zhicheng Dou"
    ],
    "abstract": "Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate\nimpressive long-horizon reasoning capabilities. However, their reliance on\nstatic internal knowledge limits their performance on complex,\nknowledge-intensive tasks and hinders their ability to produce comprehensive\nresearch reports requiring synthesis of diverse web information. To address\nthis, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs\nto autonomously search the web, navigate web pages, and draft research reports\nduring the reasoning process. WebThinker integrates a \\textbf{Deep Web\nExplorer} module, enabling LRMs to dynamically search, navigate, and extract\ninformation from the web when encountering knowledge gaps. It also employs an\n\\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to\nseamlessly interleave reasoning, information gathering, and report writing in\nreal time. To further enhance research tool utilization, we introduce an\n\\textbf{RL-based training strategy} via iterative online Direct Preference\nOptimization (DPO). Extensive experiments on complex reasoning benchmarks\n(GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive)\ndemonstrate that WebThinker significantly outperforms existing methods and\nstrong proprietary systems. Our approach enhances LRM reliability and\napplicability in complex scenarios, paving the way for more capable and\nversatile deep research systems. The code is available at\nhttps://github.com/RUC-NLPIR/WebThinker.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21776v1",
    "published_date": "2025-04-30 16:25:25 UTC",
    "updated_date": "2025-04-30 16:25:25 UTC"
  },
  {
    "arxiv_id": "2504.21775v1",
    "title": "Learning Heterogeneous Performance-Fairness Trade-offs in Federated Learning",
    "authors": [
      "Rongguang Ye",
      "Ming Tang"
    ],
    "abstract": "Recent methods leverage a hypernet to handle the performance-fairness\ntrade-offs in federated learning. This hypernet maps the clients' preferences\nbetween model performance and fairness to preference-specifc models on the\ntrade-off curve, known as local Pareto front. However, existing methods\ntypically adopt a uniform preference sampling distribution to train the\nhypernet across clients, neglecting the inherent heterogeneity of their local\nPareto fronts. Meanwhile, from the perspective of generalization, they do not\nconsider the gap between local and global Pareto fronts on the global dataset.\nTo address these limitations, we propose HetPFL to effectively learn both local\nand global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA)\nand Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the\noptimal preference sampling distribution for each client to accommodate\nheterogeneous local Pareto fronts. While PHF performs preference-aware fusion\nof clients' hypernets to ensure the performance of the global Pareto front. We\nprove that HetPFL converges linearly with respect to the number of rounds,\nunder weaker assumptions than existing methods. Extensive experiments on four\ndatasets show that HetPFL significantly outperforms seven baselines in terms of\nthe quality of learned local and global Pareto fronts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21775v1",
    "published_date": "2025-04-30 16:25:02 UTC",
    "updated_date": "2025-04-30 16:25:02 UTC"
  },
  {
    "arxiv_id": "2504.21774v1",
    "title": "Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?",
    "authors": [
      "Jiuwu Hao",
      "Liguo Sun",
      "Yuting Wan",
      "Yueyang Wu",
      "Ti Xiang",
      "Haolin Song",
      "Pin Lv"
    ],
    "abstract": "Collaborative perception enhances environmental awareness through inter-agent\ncommunication and is regarded as a promising solution to intelligent\ntransportation systems. However, existing collaborative methods for Unmanned\nAerial Vehicles (UAVs) overlook the unique characteristics of the UAV\nperspective, resulting in substantial communication overhead. To address this\nissue, we propose a novel communication-efficient collaborative perception\nframework based on late-intermediate fusion, dubbed LIF. The core concept is to\nexchange informative and compact detection results and shift the fusion stage\nto the feature representation level. In particular, we leverage vision-guided\npositional embedding (VPE) and box-based virtual augmented feature (BoBEV) to\neffectively integrate complementary information from various agents.\nAdditionally, we innovatively introduce an uncertainty-driven communication\nmechanism that uses uncertainty evaluation to select high-quality and reliable\nshared areas. Experimental results demonstrate that our LIF achieves superior\nperformance with minimal communication bandwidth, proving its effectiveness and\npracticality. Code and models are available at https://github.com/uestchjw/LIF.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21774v1",
    "published_date": "2025-04-30 16:22:14 UTC",
    "updated_date": "2025-04-30 16:22:14 UTC"
  },
  {
    "arxiv_id": "2504.21773v1",
    "title": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness",
    "authors": [
      "Junsheng Huang",
      "Zhitao He",
      "Sandeep Polisetty",
      "Qingyun Wang",
      "May Fung"
    ],
    "abstract": "With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21773v1",
    "published_date": "2025-04-30 16:17:53 UTC",
    "updated_date": "2025-04-30 16:17:53 UTC"
  },
  {
    "arxiv_id": "2504.21772v2",
    "title": "Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline",
    "authors": [
      "Minwoo Oh",
      "Minsu Park",
      "Eunil Park"
    ],
    "abstract": "Short video platforms like YouTube Shorts and TikTok face significant\ncopyright compliance challenges, as infringers frequently embed arbitrary\nbackground music (BGM) to obscure original soundtracks (OST) and evade content\noriginality detection. To tackle this issue, we propose a novel pipeline that\nintegrates Music Source Separation (MSS) and cross-modal video-music retrieval\n(CMVMR). Our approach effectively separates arbitrary BGM from the original\nOST, enabling the restoration of authentic video audio tracks. To support this\nwork, we introduce two domain-specific datasets: OASD-20K for audio separation\nand OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips\nfeaturing mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset\ncomprising 1,121 video and mixed-audio pairs, specifically designed for short\nvideo restoration tasks. Experimental results demonstrate that our pipeline not\nonly removes arbitrary BGM with high accuracy but also restores OSTs, ensuring\ncontent integrity. This approach provides an ethical and scalable solution to\ncopyright challenges in user-generated content on short video platforms.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "will be presented in IJCAI 2025, 9 pages, 4 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.21772v2",
    "published_date": "2025-04-30 16:17:05 UTC",
    "updated_date": "2025-05-03 12:54:39 UTC"
  },
  {
    "arxiv_id": "2504.21731v1",
    "title": "Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement Learning",
    "authors": [
      "Feiyu Lu",
      "Mengyu Chen",
      "Hsiang Hsu",
      "Pranav Deshpande",
      "Cheng Yao Wang",
      "Blair MacIntyre"
    ],
    "abstract": "Mixed Reality (MR) could assist users' tasks by continuously integrating\nvirtual content with their view of the physical environment. However, where and\nhow to place these content to best support the users has been a challenging\nproblem due to the dynamic nature of MR experiences. In contrast to prior work\nthat investigates optimization-based methods, we are exploring how\nreinforcement learning (RL) could assist with continuous 3D content placement\nthat is aware of users' poses and their surrounding environments. Through an\ninitial exploration and preliminary evaluation, our results demonstrate the\npotential of RL to position content that maximizes the reward for users on the\ngo. We further identify future directions for research that could harness the\npower of RL for personalized and optimized UI and content placement in MR.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '24)",
    "pdf_url": "http://arxiv.org/pdf/2504.21731v1",
    "published_date": "2025-04-30 15:21:36 UTC",
    "updated_date": "2025-04-30 15:21:36 UTC"
  },
  {
    "arxiv_id": "2504.21730v1",
    "title": "Cert-SSB: Toward Certified Sample-Specific Backdoor Defense",
    "authors": [
      "Ting Qiao",
      "Yingjia Wang",
      "Xing Liu",
      "Sixing Wu",
      "Jianbing Li",
      "Yiming Li"
    ],
    "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an\nattacker manipulates a small portion of the training data to implant hidden\nbackdoors into the model. The compromised model behaves normally on clean\nsamples but misclassifies backdoored samples into the attacker-specified target\nclass, posing a significant threat to real-world DNN applications. Currently,\nseveral empirical defense methods have been proposed to mitigate backdoor\nattacks, but they are often bypassed by more advanced backdoor techniques. In\ncontrast, certified defenses based on randomized smoothing have shown promise\nby adding random noise to training and testing samples to counteract backdoor\nattacks. In this paper, we reveal that existing randomized smoothing defenses\nimplicitly assume that all samples are equidistant from the decision boundary.\nHowever, it may not hold in practice, leading to suboptimal certification\nperformance. To address this issue, we propose a sample-specific certified\nbackdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic\ngradient ascent to optimize the noise magnitude for each sample, ensuring a\nsample-specific noise level that is then applied to multiple poisoned training\nsets to retrain several smoothed models. After that, Cert-SSB aggregates the\npredictions of multiple smoothed models to generate the final robust\nprediction. In particular, in this case, existing certification methods become\ninapplicable since the optimized noise varies across different samples. To\nconquer this challenge, we introduce a storage-update-based certification\nmethod, which dynamically adjusts each sample's certification region to improve\ncertification performance. We conduct extensive experiments on multiple\nbenchmark datasets, demonstrating the effectiveness of our proposed method. Our\ncode is available at https://github.com/NcepuQiaoTing/Cert-SSB.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.21730v1",
    "published_date": "2025-04-30 15:21:25 UTC",
    "updated_date": "2025-04-30 15:21:25 UTC"
  },
  {
    "arxiv_id": "2504.21719v1",
    "title": "Sionna RT: Technical Report",
    "authors": [
      "Fayçal Aït Aoudia",
      "Jakob Hoydis",
      "Merlin Nimier-David",
      "Sebastian Cammerer",
      "Alexander Keller"
    ],
    "abstract": "Sionna is an open-source, GPU-accelerated library that, as of version 0.14,\nincorporates a ray tracer for simulating radio wave propagation. A unique\nfeature of Sionna RT is differentiability, enabling the calculation of\ngradients for the channel impulse responses (CIRs), radio maps, and other\nrelated metrics with respect to system and environmental parameters, such as\nmaterial properties, antenna patterns, and array geometries. The release of\nSionna 1.0 provides a complete overhaul of the ray tracer, significantly\nimproving its speed, memory efficiency, and extensibility. This document\ndetails the algorithms employed by Sionna RT to simulate radio wave propagation\nefficiently, while also addressing their current limitations. Given that the\ncomputation of CIRs and radio maps requires distinct algorithms, these are\ndetailed in separate sections. For CIRs, Sionna RT integrates shooting and\nbouncing of rays (SBR) with the image method and uses a hashing-based mechanism\nto efficiently eliminate duplicate paths. Radio maps are computed using a\npurely SBR-based approach.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21719v1",
    "published_date": "2025-04-30 15:05:20 UTC",
    "updated_date": "2025-04-30 15:05:20 UTC"
  },
  {
    "arxiv_id": "2504.21716v1",
    "title": "LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics",
    "authors": [
      "Marc Glocker",
      "Peter Hönig",
      "Matthias Hirschmanner",
      "Markus Vincze"
    ],
    "abstract": "We present an embodied robotic system with an LLM-driven agent-orchestration\narchitecture for autonomous household object management. The system integrates\nmemory-augmented task planning, enabling robots to execute high-level user\ncommands while tracking past actions. It employs three specialized agents: a\nrouting agent, a task planning agent, and a knowledge base agent, each powered\nby task-specific LLMs. By leveraging in-context learning, our system avoids the\nneed for explicit model training. RAG enables the system to retrieve context\nfrom past interactions, enhancing long-term object tracking. A combination of\nGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating\nsemantic scene understanding for task planning. Evaluation across three\nhousehold scenarios demonstrates high task planning accuracy and an improvement\nin memory recall due to RAG. Specifically, Qwen2.5 yields best performance for\nspecialized agents, while LLaMA3.1 excels in routing tasks. The source code is\navailable at: https://github.com/marc1198/chat-hsr.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at Austrian Robotics Workshop 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21716v1",
    "published_date": "2025-04-30 15:00:20 UTC",
    "updated_date": "2025-04-30 15:00:20 UTC"
  },
  {
    "arxiv_id": "2504.21707v1",
    "title": "Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning",
    "authors": [
      "Anthony D Martin"
    ],
    "abstract": "We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "cs.NE",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21707v1",
    "published_date": "2025-04-30 14:51:27 UTC",
    "updated_date": "2025-04-30 14:51:27 UTC"
  },
  {
    "arxiv_id": "2504.21706v2",
    "title": "Vision Transformers in Precision Agriculture: A Comprehensive Survey",
    "authors": [
      "Saber Mehdipour",
      "Seyed Abolghasem Mirroshandel",
      "Seyed Amirhossein Tabatabaei"
    ],
    "abstract": "Detecting plant diseases is a crucial aspect of modern agriculture, as it\nplays a key role in maintaining crop health and increasing overall yield.\nTraditional approaches, though still valuable, often rely on manual inspection\nor conventional machine learning techniques, both of which face limitations in\nscalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as\na promising alternative, offering advantages such as improved handling of\nlong-range dependencies and better scalability for visual tasks. This review\nexplores the application of ViTs in precision agriculture, covering a range of\ntasks. We begin by introducing the foundational architecture of ViTs and\ndiscussing their transition from Natural Language Processing (NLP) to Computer\nVision. The discussion includes the concept of inductive bias in traditional\nmodels like Convolutional Neural Networks (CNNs), and how ViTs mitigate these\nbiases. We provide a comprehensive review of recent literature, focusing on key\nmethodologies, datasets, and performance metrics. This study also includes a\ncomparative analysis of CNNs and ViTs, along with a review of hybrid models and\nperformance enhancements. Technical challenges such as data requirements,\ncomputational demands, and model interpretability are addressed, along with\npotential solutions. Finally, we outline future research directions and\ntechnological advancements that could further support the integration of ViTs\nin real-world agricultural settings. Our goal with this study is to offer\npractitioners and researchers a deeper understanding of how ViTs are poised to\ntransform smart and precision agriculture.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21706v2",
    "published_date": "2025-04-30 14:50:02 UTC",
    "updated_date": "2025-05-19 14:20:35 UTC"
  },
  {
    "arxiv_id": "2504.21700v1",
    "title": "XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs",
    "authors": [
      "Marco Arazzi",
      "Vignesh Kumar Kembu",
      "Antonino Nocera",
      "Vinod P"
    ],
    "abstract": "Large Language Models are fundamental actors in the modern IT landscape\ndominated by AI solutions. However, security threats associated with them might\nprevent their reliable adoption in critical application scenarios such as\ngovernment organizations and medical institutions. For this reason, commercial\nLLMs typically undergo a sophisticated censoring mechanism to eliminate any\nharmful output they could possibly produce. In response to this, LLM\nJailbreaking is a significant threat to such protections, and many previous\napproaches have already demonstrated its effectiveness across diverse domains.\nExisting jailbreak proposals mostly adopt a generate-and-test strategy to craft\nmalicious input. To improve the comprehension of censoring mechanisms and\ndesign a targeted jailbreak attack, we propose an Explainable-AI solution that\ncomparatively analyzes the behavior of censored and uncensored models to derive\nunique exploitable alignment patterns. Then, we propose XBreaking, a novel\njailbreak attack that exploits these unique patterns to break the security\nconstraints of LLMs by targeted noise injection. Our thorough experimental\ncampaign returns important insights about the censoring mechanisms and\ndemonstrates the effectiveness and performance of our attack.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21700v1",
    "published_date": "2025-04-30 14:44:24 UTC",
    "updated_date": "2025-04-30 14:44:24 UTC"
  },
  {
    "arxiv_id": "2505.00060v1",
    "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business Intelligence Using Exaone 3.5",
    "authors": [
      "Jeho Choi"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2505.00060v1",
    "published_date": "2025-04-30 14:42:18 UTC",
    "updated_date": "2025-04-30 14:42:18 UTC"
  },
  {
    "arxiv_id": "2504.21695v1",
    "title": "Self-Supervised Monocular Visual Drone Model Identification through Improved Occlusion Handling",
    "authors": [
      "Stavrow A. Bahnam",
      "Christophe De Wagter",
      "Guido C. H. E. de Croon"
    ],
    "abstract": "Ego-motion estimation is vital for drones when flying in GPS-denied\nenvironments. Vision-based methods struggle when flight speed increases and\nclose-by objects lead to difficult visual conditions with considerable motion\nblur and large occlusions. To tackle this, vision is typically complemented by\nstate estimation filters that combine a drone model with inertial measurements.\nHowever, these drone models are currently learned in a supervised manner with\nground-truth data from external motion capture systems, limiting scalability to\ndifferent environments and drones. In this work, we propose a self-supervised\nlearning scheme to train a neural-network-based drone model using only onboard\nmonocular video and flight controller data (IMU and motor feedback). We achieve\nthis by first training a self-supervised relative pose estimation model, which\nthen serves as a teacher for the drone model. To allow this to work at high\nspeed close to obstacles, we propose an improved occlusion handling method for\ntraining self-supervised pose estimation models. Due to this method, the root\nmean squared error of resulting odometry estimates is reduced by an average of\n15%. Moreover, the student neural drone model can be successfully obtained from\nthe onboard data. It even becomes more accurate at higher speeds compared to\nits teacher, the self-supervised vision-based model. We demonstrate the value\nof the neural drone model by integrating it into a traditional filter-based VIO\nsystem (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing\ntrajectories near obstacles. Self-supervised learning of ego-motion estimation\nrepresents a significant step toward bridging the gap between flying in\ncontrolled, expensive lab environments and real-world drone applications. The\nfusion of vision and drone models will enable higher-speed flight and improve\nstate estimation, on any drone in any environment.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21695v1",
    "published_date": "2025-04-30 14:38:01 UTC",
    "updated_date": "2025-04-30 14:38:01 UTC"
  },
  {
    "arxiv_id": "2504.21694v1",
    "title": "Automatic Mapping of AutomationML Files to Ontologies for Graph Queries and Validation",
    "authors": [
      "Tom Westermann",
      "Malte Ramonat",
      "Johannes Hujer",
      "Felix Gehlhoff",
      "Alexander Fay"
    ],
    "abstract": "AutomationML has seen widespread adoption as an open data exchange format in\nthe automation domain. It is an open and vendor neutral standard based on the\nextensible markup language XML. However, AutomationML extends XML with\nadditional semantics, that limit the applicability of common XML-tools for\napplications like querying or data validation. This article provides\npractitioners with 1) an up-to-date ontology of the concepts in the\nAutomationML-standard, as well as 2) a declarative mapping to automatically\ntransform any AutomationML model into RDF triples. Together, these artifacts\nallow practitioners an easy integration of AutomationML information into\nindustrial knowledge graphs. A study on examples from the automation domain\nconcludes that transforming AutomationML to OWL opens up new powerful ways for\nquerying and validation that are impossible without transformation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21694v1",
    "published_date": "2025-04-30 14:34:56 UTC",
    "updated_date": "2025-04-30 14:34:56 UTC"
  },
  {
    "arxiv_id": "2504.21692v1",
    "title": "Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction",
    "authors": [
      "Zihan Zhou",
      "Changrui Dai",
      "Aibo Song",
      "Xiaolin Fang"
    ],
    "abstract": "Successful video analysis relies on accurate recognition of pixels across\nframes, and frame reconstruction methods based on video correspondence learning\nare popular due to their efficiency. Existing frame reconstruction methods,\nwhile efficient, neglect the value of direct involvement of multiple reference\nframes for reconstruction and decision-making aspects, especially in complex\nsituations such as occlusion or fast movement. In this paper, we introduce a\nDynamic Memory Prediction (DMP) framework that innovatively utilizes multiple\nreference frames to concisely and directly enhance frame reconstruction. Its\ncore component is a Reference Frame Memory Engine that dynamically selects\nframes based on object pixel features to improve tracking accuracy. In\naddition, a Bidirectional Target Prediction Network is built to utilize\nmultiple reference frames to improve the robustness of the model. Through\nexperiments, our algorithm outperforms the state-of-the-art self-supervised\ntechniques on two fine-grained video object tracking tasks: object segmentation\nand keypoint tracking.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21692v1",
    "published_date": "2025-04-30 14:29:04 UTC",
    "updated_date": "2025-04-30 14:29:04 UTC"
  },
  {
    "arxiv_id": "2504.21685v1",
    "title": "Enhancing Health Mention Classification Performance: A Study on Advancements in Parameter Efficient Tuning",
    "authors": [
      "Reem Abdel-Salam",
      "Mary Adewunmi"
    ],
    "abstract": "Health Mention Classification (HMC) plays a critical role in leveraging\nsocial media posts for real-time tracking and public health monitoring.\nNevertheless, the process of HMC presents significant challenges due to its\nintricate nature, primarily stemming from the contextual aspects of health\nmentions, such as figurative language and descriptive terminology, rather than\nexplicitly reflecting a personal ailment. To address this problem, we argue\nthat clearer mentions can be achieved through conventional fine-tuning with\nenhanced parameters of biomedical natural language methods (NLP). In this\nstudy, we explore different techniques such as the utilisation of\npart-of-speech (POS) tagger information, improving on PEFT techniques, and\ndifferent combinations thereof. Extensive experiments are conducted on three\nwidely used datasets: RHDM, PHM, and Illness. The results incorporated POS\ntagger information, and leveraging PEFT techniques significantly improves\nperformance in terms of F1-score compared to state-of-the-art methods across\nall three datasets by utilising smaller models and efficient training.\nFurthermore, the findings highlight the effectiveness of incorporating POS\ntagger information and leveraging PEFT techniques for HMC. In conclusion, the\nproposed methodology presents a potentially effective approach to accurately\nclassifying health mentions in social media posts while optimising the model\nsize and training efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.21685v1",
    "published_date": "2025-04-30 14:21:54 UTC",
    "updated_date": "2025-04-30 14:21:54 UTC"
  },
  {
    "arxiv_id": "2504.21683v1",
    "title": "Extension-ranking Semantics for Abstract Argumentation Preprint",
    "authors": [
      "Kenneth Skiba",
      "Tjitze Rienstra",
      "Matthias Thimm",
      "Jesse Heyninck",
      "Gabriele Kern-Isberner"
    ],
    "abstract": "In this paper, we present a general framework for ranking sets of arguments\nin abstract argumentation based on their plausibility of acceptance. We present\na generalisation of Dung's extension semantics as extension-ranking semantics,\nwhich induce a preorder over the power set of all arguments, allowing us to\nstate that one set is \"closer\" to being acceptable than another. To evaluate\nthe extension-ranking semantics, we introduce a number of principles that a\nwell-behaved extension-ranking semantics should satisfy. We consider several\nsimple base relations, each of which models a single central aspect of\nargumentative reasoning. The combination of these base relations provides us\nwith a family of extension-ranking semantics. We also adapt a number of\napproaches from the literature for ranking extensions to be usable in the\ncontext of extension-ranking semantics, and evaluate their behaviour.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21683v1",
    "published_date": "2025-04-30 14:19:42 UTC",
    "updated_date": "2025-04-30 14:19:42 UTC"
  },
  {
    "arxiv_id": "2504.21659v2",
    "title": "Ada-R1: Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization",
    "authors": [
      "Haotian Luo",
      "Haiying He",
      "Yibo Wang",
      "Jinluan Yang",
      "Rui Liu",
      "Naiqiang Tan",
      "Xiaochun Cao",
      "Dacheng Tao",
      "Li Shen"
    ],
    "abstract": "Recently, long-thought reasoning models achieve strong performance on complex\nreasoning tasks, but often incur substantial inference overhead, making\nefficiency a critical concern. Our empirical analysis reveals that the benefit\nof using Long-CoT varies across problems: while some problems require elaborate\nreasoning, others show no improvement, or even degraded accuracy. This\nmotivates adaptive reasoning strategies that tailor reasoning depth to the\ninput. However, prior work primarily reduces redundancy within long reasoning\npaths, limiting exploration of more efficient strategies beyond the Long-CoT\nparadigm. To address this, we propose a novel two-stage framework for adaptive\nand efficient reasoning. First, we construct a hybrid reasoning model by\nmerging long and short CoT models to enable diverse reasoning styles. Second,\nwe apply bi-level preference training to guide the model to select suitable\nreasoning styles (group-level), and prefer concise and correct reasoning within\neach style group (instance-level). Experiments demonstrate that our method\n(Ada-R1) significantly reduces inference costs compared to other baseline\napproaches, while maintaining performance. Notably, on five mathematical\ndatasets, the average length of reasoning is reduced by more than 50%,\nhighlighting the potential of adaptive strategies to optimize reasoning\nefficiency in large language models. Our code is coming soon at\nhttps://github.com/StarDewXXX/AdaR1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21659v2",
    "published_date": "2025-04-30 14:01:45 UTC",
    "updated_date": "2025-05-21 11:59:38 UTC"
  },
  {
    "arxiv_id": "2504.21643v1",
    "title": "Designing Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigation",
    "authors": [
      "Luca Marzari",
      "Francesco Trotti",
      "Enrico Marchesini",
      "Alessandro Farinelli"
    ],
    "abstract": "Achieving safe autonomous navigation systems is critical for deploying robots\nin dynamic and uncertain real-world environments. In this paper, we propose a\nhierarchical control framework leveraging neural network verification\ntechniques to design control barrier functions (CBFs) and policy correction\nmechanisms that ensure safe reinforcement learning navigation policies. Our\napproach relies on probabilistic enumeration to identify unsafe regions of\noperation, which are then used to construct a safe CBF-based control layer\napplicable to arbitrary policies. We validate our framework both in simulation\nand on a real robot, using a standard mobile robot benchmark and a highly\ndynamic aquatic environmental monitoring task. These experiments demonstrate\nthe ability of the proposed solution to correct unsafe actions while preserving\nefficient navigation behavior. Our results show the promise of developing\nhierarchical verification-based systems to enable safe and robust navigation\nbehaviors in complex scenarios.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21643v1",
    "published_date": "2025-04-30 13:47:25 UTC",
    "updated_date": "2025-04-30 13:47:25 UTC"
  },
  {
    "arxiv_id": "2504.21635v1",
    "title": "Sadeed: Advancing Arabic Diacritization Through Small Language Model",
    "authors": [
      "Zeina Aldallal",
      "Sara Chrouf",
      "Khalil Hennara",
      "Mohamed Motaism Hamed",
      "Muhammad Hreden",
      "Safwan AlModhayan"
    ],
    "abstract": "Arabic text diacritization remains a persistent challenge in natural language\nprocessing due to the language's morphological richness. In this paper, we\nintroduce Sadeed, a novel approach based on a fine-tuned decoder-only language\nmodel adapted from Kuwain 1.5B Hennara et al. [2025], a compact model\noriginally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully\ncurated, high-quality diacritized datasets, constructed through a rigorous\ndata-cleaning and normalization pipeline. Despite utilizing modest\ncomputational resources, Sadeed achieves competitive results compared to\nproprietary large language models and outperforms traditional models trained on\nsimilar domains. Additionally, we highlight key limitations in current\nbenchmarking practices for Arabic diacritization. To address these issues, we\nintroduce SadeedDiac-25, a new benchmark designed to enable fairer and more\ncomprehensive evaluation across diverse text genres and complexity levels.\nTogether, Sadeed and SadeedDiac-25 provide a robust foundation for advancing\nArabic NLP applications, including machine translation, text-to-speech, and\nlanguage learning tools.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21635v1",
    "published_date": "2025-04-30 13:37:24 UTC",
    "updated_date": "2025-04-30 13:37:24 UTC"
  },
  {
    "arxiv_id": "2504.21634v1",
    "title": "Quantitative Auditing of AI Fairness with Differentially Private Synthetic Data",
    "authors": [
      "Chih-Cheng Rex Yuan",
      "Bow-Yaw Wang"
    ],
    "abstract": "Fairness auditing of AI systems can identify and quantify biases. However,\ntraditional auditing using real-world data raises security and privacy\nconcerns. It exposes auditors to security risks as they become custodians of\nsensitive information and targets for cyberattacks. Privacy risks arise even\nwithout direct breaches, as data analyses can inadvertently expose confidential\ninformation. To address these, we propose a framework that leverages\ndifferentially private synthetic data to audit the fairness of AI systems. By\napplying privacy-preserving mechanisms, it generates synthetic data that\nmirrors the statistical properties of the original dataset while ensuring\nprivacy. This method balances the goal of rigorous fairness auditing and the\nneed for strong privacy protections. Through experiments on real datasets like\nAdult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real\ndata. By analyzing the alignment and discrepancies between these metrics, we\nassess the capacity of synthetic data to preserve the fairness properties of\nreal data. Our results demonstrate the framework's ability to enable meaningful\nfairness evaluations while safeguarding sensitive information, proving its\napplicability across critical and sensitive domains.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21634v1",
    "published_date": "2025-04-30 13:36:27 UTC",
    "updated_date": "2025-04-30 13:36:27 UTC"
  },
  {
    "arxiv_id": "2504.21605v1",
    "title": "RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations",
    "authors": [
      "Jonas Gwozdz",
      "Andreas Both"
    ],
    "abstract": "Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet\nsystematically assessing their reliability with conflicting information remains\ndifficult. We propose an RDF-based framework to assess multilingual LLM\nquality, focusing on knowledge conflicts. Our approach captures model responses\nacross four distinct context conditions (complete, incomplete, conflicting, and\nno-context information) in German and English. This structured representation\nenables the comprehensive analysis of knowledge leakage-where models favor\ntraining data over provided context-error detection, and multilingual\nconsistency. We demonstrate the framework through a fire safety domain\nexperiment, revealing critical patterns in context prioritization and\nlanguage-specific performance, and demonstrating that our vocabulary was\nsufficient to express every assessment facet encountered in the 28-question\nstudy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21605v1",
    "published_date": "2025-04-30 13:06:40 UTC",
    "updated_date": "2025-04-30 13:06:40 UTC"
  },
  {
    "arxiv_id": "2505.03780v2",
    "title": "GPU Performance Portability needs Autotuning",
    "authors": [
      "Burkhard Ringlein",
      "Thomas Parnell",
      "Radu Stoica"
    ],
    "abstract": "As LLMs grow in complexity, achieving state-of-the-art performance requires\ntight co-design across algorithms, software, and hardware. Today's reliance on\na single dominant platform limits portability, creates vendor lock-in, and\nraises barriers for new AI hardware. In this work, we make the case for\ncombining just-in-time (JIT) compilation with kernel parameter autotuning to\nenable portable LLM inference with state-of-the-art performance without code\nchanges. Focusing on flash attention -- a widespread performance critical LLM\nkernel -- we demonstrate that this approach explores up to 15x more kernel\nparameter configurations, produces significantly more diverse code across\nmultiple dimensions, and even outperforms vendor-optimized implementations by\nup to 230%, all while reducing kernel code size by 70x and eliminating manual\ncode optimizations. Our results highlight autotuning as a promising path to\nunlocking model portability across GPU vendors.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AR",
    "comment": "typos, fix grammatical mistakes",
    "pdf_url": "http://arxiv.org/pdf/2505.03780v2",
    "published_date": "2025-04-30 12:57:21 UTC",
    "updated_date": "2025-05-15 14:26:40 UTC"
  },
  {
    "arxiv_id": "2504.21596v1",
    "title": "Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning",
    "authors": [
      "Huihui Guo",
      "Huilong Pi",
      "Yunchuan Qin",
      "Zhuo Tang",
      "Kenli Li"
    ],
    "abstract": "With the rapid advancement of artificial intelligence, there is an increasing\ndemand for intelligent robots capable of assisting humans in daily tasks and\nperforming complex operations. Such robots not only require task planning\ncapabilities but must also execute tasks with stability and robustness. In this\npaper, we present a closed-loop task planning and acting system, LLM-PAS, which\nis assisted by a pre-trained Large Language Model (LLM). While LLM-PAS plans\nlong-horizon tasks in a manner similar to traditional task and motion planners,\nit also emphasizes the execution phase of the task. By transferring part of the\nconstraint-checking process from the planning phase to the execution phase,\nLLM-PAS enables exploration of the constraint space and delivers more accurate\nfeedback on environmental anomalies during execution. The reasoning\ncapabilities of the LLM allow it to handle anomalies that cannot be addressed\nby the robust executor. To further enhance the system's ability to assist the\nplanner during replanning, we propose the First Look Prompting (FLP) method,\nwhich induces LLM to generate effective PDDL goals. Through comparative\nprompting experiments and systematic experiments, we demonstrate the\neffectiveness and robustness of LLM-PAS in handling anomalous conditions during\ntask execution.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21596v1",
    "published_date": "2025-04-30 12:53:53 UTC",
    "updated_date": "2025-04-30 12:53:53 UTC"
  },
  {
    "arxiv_id": "2504.21589v1",
    "title": "DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for Automated Subject Indexing",
    "authors": [
      "Lisa Kluge",
      "Maximilian Kähler"
    ],
    "abstract": "This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 4 figures, submitted to SemEval-2025 workshop Task 5:\n  LLMs4Subjects",
    "pdf_url": "http://arxiv.org/pdf/2504.21589v1",
    "published_date": "2025-04-30 12:47:09 UTC",
    "updated_date": "2025-04-30 12:47:09 UTC"
  },
  {
    "arxiv_id": "2504.21586v1",
    "title": "One Net to Rule Them All: Domain Randomization in Quadcopter Racing Across Different Platforms",
    "authors": [
      "Robin Ferede",
      "Till Blaha",
      "Erin Lucassen",
      "Christophe De Wagter",
      "Guido C. H. E. de Croon"
    ],
    "abstract": "In high-speed quadcopter racing, finding a single controller that works well\nacross different platforms remains challenging. This work presents the first\nneural network controller for drone racing that generalizes across physically\ndistinct quadcopters. We demonstrate that a single network, trained with domain\nrandomization, can robustly control various types of quadcopters. The network\nrelies solely on the current state to directly compute motor commands. The\neffectiveness of this generalized controller is validated through real-world\ntests on two substantially different crafts (3-inch and 5-inch race\nquadcopters). We further compare the performance of this generalized controller\nwith controllers specifically trained for the 3-inch and 5-inch drone, using\ntheir identified model parameters with varying levels of domain randomization\n(0%, 10%, 20%, 30%). While the generalized controller shows slightly slower\nspeeds compared to the fine-tuned models, it excels in adaptability across\ndifferent platforms. Our results show that no randomization fails sim-to-real\ntransfer while increasing randomization improves robustness but reduces speed.\nDespite this trade-off, our findings highlight the potential of domain\nrandomization for generalizing controllers, paving the way for universal AI\ncontrollers that can adapt to any platform.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21586v1",
    "published_date": "2025-04-30 12:44:41 UTC",
    "updated_date": "2025-04-30 12:44:41 UTC"
  },
  {
    "arxiv_id": "2504.21585v1",
    "title": "Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based Reinforcement Learning",
    "authors": [
      "Yingzhuo Jiang",
      "Wenjun Huang",
      "Rongdun Lin",
      "Chenyang Miao",
      "Tianfu Sun",
      "Yunduan Cui"
    ],
    "abstract": "This paper tackles the challenge of learning multi-goal dexterous hand\nmanipulation tasks using model-based Reinforcement Learning. We propose\nGoal-Conditioned Probabilistic Model Predictive Control (GC-PMPC) by designing\nprobabilistic neural network ensembles to describe the high-dimensional\ndexterous hand dynamics and introducing an asynchronous MPC policy to meet the\ncontrol frequency requirements in real-world dexterous hand systems. Extensive\nevaluations on four simulated Shadow Hand manipulation scenarios with randomly\ngenerated goals demonstrate GC-PMPC's superior performance over\nstate-of-the-art baselines. It successfully drives a cable-driven Dexterous\nhand, DexHand 021 with 12 Active DOFs and 5 tactile sensors, to learn\nmanipulating a cubic die to three goal poses within approximately 80 minutes of\ninteractions, demonstrating exceptional learning efficiency and control\nperformance on a cost-effective dexterous hand platform.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21585v1",
    "published_date": "2025-04-30 12:44:38 UTC",
    "updated_date": "2025-04-30 12:44:38 UTC"
  },
  {
    "arxiv_id": "2504.21582v2",
    "title": "MF-LLM: Simulating Population Decision Dynamics via a Mean-Field Large Language Model Framework",
    "authors": [
      "Qirui Mi",
      "Mengyue Yang",
      "Xiangning Yu",
      "Zhiyu Zhao",
      "Cheng Deng",
      "Bo An",
      "Haifeng Zhang",
      "Xu Chen",
      "Jun Wang"
    ],
    "abstract": "Simulating collective decision-making involves more than aggregating\nindividual behaviors; it emerges from dynamic interactions among individuals.\nWhile large language models (LLMs) offer strong potential for social\nsimulation, achieving quantitative alignment with real-world data remains a key\nchallenge. To bridge this gap, we propose the Mean-Field LLM (MF-LLM)\nframework, the first to incorporate mean field theory into LLM-based social\nsimulation. MF-LLM models bidirectional interactions between individuals and\nthe population through an iterative process, generating population signals to\nguide individual decisions, which in turn update the signals. This interplay\nproduces coherent trajectories of collective behavior. To improve alignment\nwith real-world data, we introduce IB-Tune, a novel fine-tuning method inspired\nby the Information Bottleneck principle, which retains population signals most\npredictive of future actions while filtering redundant history. Evaluated on a\nreal-world social dataset, MF-LLM reduces KL divergence to human population\ndistributions by 47\\% compared to non-mean-field baselines, enabling accurate\ntrend forecasting and effective intervention planning. Generalizing across 7\ndomains and 4 LLM backbones, MF-LLM provides a scalable, high-fidelity\nfoundation for social simulation.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "29 pages, 8 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.21582v2",
    "published_date": "2025-04-30 12:41:51 UTC",
    "updated_date": "2025-05-19 13:12:36 UTC"
  },
  {
    "arxiv_id": "2505.07831v1",
    "title": "Polysemy of Synthetic Neurons Towards a New Type of Explanatory Categorical Vector Spaces",
    "authors": [
      "Michael Pichat",
      "William Pogrund",
      "Paloma Pichat",
      "Judicael Poumay",
      "Armanouche Gasparian",
      "Samuel Demarchi",
      "Martin Corbet",
      "Alois Georgeon",
      "Michael Veillet-Guillem"
    ],
    "abstract": "The polysemantic nature of synthetic neurons in artificial intelligence\nlanguage models is currently understood as the result of a necessary\nsuperposition of distributed features within the latent space. We propose an\nalternative approach, geometrically defining a neuron in layer n as a\ncategorical vector space with a non-orthogonal basis, composed of categorical\nsub-dimensions extracted from preceding neurons in layer n-1. This categorical\nvector space is structured by the activation space of each neuron and enables,\nvia an intra-neuronal attention process, the identification and utilization of\na critical categorical zone for the efficiency of the language model - more\nhomogeneous and located at the intersection of these different categorical\nsub-dimensions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07831v1",
    "published_date": "2025-04-30 12:33:28 UTC",
    "updated_date": "2025-04-30 12:33:28 UTC"
  },
  {
    "arxiv_id": "2504.21568v1",
    "title": "A Study on Group Decision Making Problem Based on Fuzzy Reasoning and Bayesian Networks",
    "authors": [
      "Shui-jin Rong",
      "Wei Guo",
      "Da-qing Zhang"
    ],
    "abstract": "Aiming at the group decision - making problem with multi - objective\nattributes, this study proposes a group decision - making system that\nintegrates fuzzy inference and Bayesian network. A fuzzy rule base is\nconstructed by combining threshold values, membership functions, expert\nexperience, and domain knowledge to address quantitative challenges such as\nscale differences and expert linguistic variables. A hierarchical Bayesian\nnetwork is designed, featuring a directed acyclic graph with nodes selected by\nexperts, and maximum likelihood estimation is used to dynamically optimize the\nconditional probability table, modeling the nonlinear correlations among\nmultidimensional indices for posterior probability aggregation. In a\ncomprehensive student evaluation case, this method is compared with the\ntraditional weighted scoring approach. The results indicate that the proposed\nmethod demonstrates effectiveness in both rule criterion construction and\nranking consistency, with a classification accuracy of 86.0% and an F1 value\nimprovement of 53.4% over the traditional method. Additionally, computational\nexperiments on real - world datasets across various group decision scenarios\nassess the method's performance and robustness, providing evidence of its\nreliability in diverse contexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21568v1",
    "published_date": "2025-04-30 12:14:48 UTC",
    "updated_date": "2025-04-30 12:14:48 UTC"
  },
  {
    "arxiv_id": "2504.21565v1",
    "title": "Towards proactive self-adaptive AI for non-stationary environments with dataset shifts",
    "authors": [
      "David Fernández Narro",
      "Pablo Ferri",
      "Juan M. García-Gómez",
      "Carlos Sáez"
    ],
    "abstract": "Artificial Intelligence (AI) models deployed in production frequently face\nchallenges in maintaining their performance in non-stationary environments.\nThis issue is particularly noticeable in medical settings, where temporal\ndataset shifts often occur. These shifts arise when the distributions of\ntraining data differ from those of the data encountered during deployment over\ntime. Further, new labeled data to continuously retrain AI is not typically\navailable in a timely manner due to data access limitations. To address these\nchallenges, we propose a proactive self-adaptive AI approach, or pro-adaptive,\nwhere we model the temporal trajectory of AI parameters, allowing us to\nshort-term forecast parameter values. To this end, we use polynomial spline\nbases, within an extensible Functional Data Analysis framework. We validate our\nmethodology with a logistic regression model addressing prior probability\nshift, covariate shift, and concept shift. This validation is conducted on both\na controlled simulated dataset and a publicly available real-world COVID-19\ndataset from Mexico, with various shifts occurring between 2020 and 2024. Our\nresults indicate that this approach enhances the performance of AI against\nshifts compared to baseline stable models trained at different time distances\nfrom the present, without requiring updated training data. This work lays the\nfoundation for pro-adaptive AI research against dynamic, non-stationary\nenvironments, being compatible with data protection, in resilient AI production\nenvironments for health.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 4 figures, conference paper",
    "pdf_url": "http://arxiv.org/pdf/2504.21565v1",
    "published_date": "2025-04-30 12:09:59 UTC",
    "updated_date": "2025-04-30 12:09:59 UTC"
  },
  {
    "arxiv_id": "2504.21562v1",
    "title": "eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes",
    "authors": [
      "Henry John Krumb",
      "Anirban Mukhopadhyay"
    ],
    "abstract": "Wireless Capsule Endoscopy is a non-invasive imaging method for the entire\ngastrointestinal tract, and is a pain-free alternative to traditional\nendoscopy. It generates extensive video data that requires significant review\ntime, and localizing the capsule after ingestion is a challenge. Techniques\nlike bleeding detection and depth estimation can help with localization of\npathologies, but deep learning models are typically too large to run directly\non the capsule. Neural Cellular Automata (NCA) for bleeding segmentation and\ndepth estimation are trained on capsule endoscopic images. For monocular depth\nestimation, we distill a large foundation model into the lean NCA architecture,\nby treating the outputs of the foundation model as pseudo ground truth. We then\nport the trained NCA to the ESP32 microcontroller, enabling efficient image\nprocessing on hardware as small as a camera capsule. NCA are more accurate\n(Dice) than other portable segmentation models, while requiring more than 100x\nfewer parameters stored in memory than other small-scale models. The visual\nresults of NCA depth estimation look convincing, and in some cases beat the\nrealism and detail of the pseudo ground truth. Runtime optimizations on the\nESP32-S3 accelerate the average inference speed significantly, by more than\nfactor 3. With several algorithmic adjustments and distillation, it is possible\nto eNCApsulate NCA models into microcontrollers that fit into wireless capsule\nendoscopes. This is the first work that enables reliable bleeding segmentation\nand depth estimation on a miniaturized device, paving the way for precise\ndiagnosis combined with visual odometry as a means of precise localization of\nthe capsule -- on the capsule.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21562v1",
    "published_date": "2025-04-30 12:06:56 UTC",
    "updated_date": "2025-04-30 12:06:56 UTC"
  },
  {
    "arxiv_id": "2504.21559v1",
    "title": "Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models",
    "authors": [
      "Sangmin Woo",
      "Kang Zhou",
      "Yun Zhou",
      "Shuai Wang",
      "Sheng Guan",
      "Haibo Ding",
      "Lin Lee Cheong"
    ],
    "abstract": "Large Vision Language Models (LVLMs) often suffer from object hallucination,\nwhich undermines their reliability. Surprisingly, we find that simple\nobject-based visual prompting -- overlaying visual cues (e.g., bounding box,\ncircle) on images -- can significantly mitigate such hallucination; however,\ndifferent visual prompts (VPs) vary in effectiveness. To address this, we\npropose Black-Box Visual Prompt Engineering (BBVPE), a framework to identify\noptimal VPs that enhance LVLM responses without needing access to model\ninternals. Our approach employs a pool of candidate VPs and trains a router\nmodel to dynamically select the most effective VP for a given input image. This\nblack-box approach is model-agnostic, making it applicable to both open-source\nand proprietary LVLMs. Evaluations on benchmarks such as POPE and CHAIR\ndemonstrate that BBVPE effectively reduces object hallucination.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21559v1",
    "published_date": "2025-04-30 11:58:30 UTC",
    "updated_date": "2025-04-30 11:58:30 UTC"
  },
  {
    "arxiv_id": "2504.21545v1",
    "title": "Meta knowledge assisted Evolutionary Neural Architecture Search",
    "authors": [
      "Yangyang Li",
      "Guanlong Liu",
      "Ronghua Shang",
      "Licheng Jiao"
    ],
    "abstract": "Evolutionary computation (EC)-based neural architecture search (NAS) has\nachieved remarkable performance in the automatic design of neural\narchitectures. However, the high computational cost associated with evaluating\nsearched architectures poses a challenge for these methods, and a fixed form of\nlearning rate (LR) schedule means greater information loss on diverse searched\narchitectures. This paper introduces an efficient EC-based NAS method to solve\nthese problems via an innovative meta-learning framework. Specifically, a\nmeta-learning-rate (Meta-LR) scheme is used through pretraining to obtain a\nsuitable LR schedule, which guides the training process with lower information\nloss when evaluating each individual. An adaptive surrogate model is designed\nthrough an adaptive threshold to select the potential architectures in a few\nepochs and then evaluate the potential architectures with complete epochs.\nAdditionally, a periodic mutation operator is proposed to increase the\ndiversity of the population, which enhances the generalizability and\nrobustness. Experiments on CIFAR-10, CIFAR-100, and ImageNet1K datasets\ndemonstrate that the proposed method achieves high performance comparable to\nthat of many state-of-the-art peer methods, with lower computational cost and\ngreater robustness.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21545v1",
    "published_date": "2025-04-30 11:43:07 UTC",
    "updated_date": "2025-04-30 11:43:07 UTC"
  },
  {
    "arxiv_id": "2505.15821v1",
    "title": "A Novel Compound AI Model for 6G Networks in 3D Continuum",
    "authors": [
      "Milos Gravara",
      "Andrija Stanisic",
      "Stefan Nastic"
    ],
    "abstract": "The 3D continuum presents a complex environment that spans the terrestrial,\naerial and space domains, with 6Gnetworks serving as a key enabling technology.\nCurrent AI approaches for network management rely on monolithic models that\nfail to capture cross-domain interactions, lack adaptability,and demand\nprohibitive computational resources. This paper presents a formal model of\nCompound AI systems, introducing a novel tripartite framework that decomposes\ncomplex tasks into specialized, interoperable modules. The proposed modular\narchitecture provides essential capabilities to address the unique challenges\nof 6G networks in the 3D continuum, where heterogeneous components require\ncoordinated, yet distributed, intelligence. This approach introduces a\nfundamental trade-off between model and system performance, which must be\ncarefully addressed. Furthermore, we identify key challenges faced by Compound\nAI systems within 6G networks operating in the 3D continuum, including\ncross-domain resource orchestration, adaptation to dynamic topologies, and the\nmaintenance of consistent AI service quality across heterogeneous environments.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "I.2.11; C.2.3; C.2.4"
    ],
    "primary_category": "cs.NI",
    "comment": "4 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.15821v1",
    "published_date": "2025-04-30 11:28:33 UTC",
    "updated_date": "2025-04-30 11:28:33 UTC"
  },
  {
    "arxiv_id": "2504.21491v1",
    "title": "ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic Segmentation of Remote Sensing Imagery",
    "authors": [
      "Qinfeng Zhu",
      "Yunxi Jiang",
      "Lei Fan"
    ],
    "abstract": "We propose a result-level category-specific fusion architecture called\nClassWise-CRF. This architecture employs a two-stage process: first, it selects\nexpert networks that perform well in specific categories from a pool of\ncandidate networks using a greedy algorithm; second, it integrates the\nsegmentation predictions of these selected networks by adaptively weighting\ntheir contributions based on their segmentation performance in each category.\nInspired by Conditional Random Field (CRF), the ClassWise-CRF architecture\ntreats the segmentation predictions from multiple networks as confidence vector\nfields. It leverages segmentation metrics (such as Intersection over Union)\nfrom the validation set as priors and employs an exponential weighting strategy\nto fuse the category-specific confidence scores predicted by each network. This\nfusion method dynamically adjusts the weights of each network for different\ncategories, achieving category-specific optimization. Building on this, the\narchitecture further optimizes the fused results using unary and pairwise\npotentials in CRF to ensure spatial consistency and boundary accuracy. To\nvalidate the effectiveness of ClassWise-CRF, we conducted experiments on two\nremote sensing datasets, LoveDA and Vaihingen, using eight classic and advanced\nsemantic segmentation networks. The results show that the ClassWise-CRF\narchitecture significantly improves segmentation performance: on the LoveDA\ndataset, the mean Intersection over Union (mIoU) metric increased by 1.00% on\nthe validation set and by 0.68% on the test set; on the Vaihingen dataset, the\nmIoU improved by 0.87% on the validation set and by 0.91% on the test set.\nThese results fully demonstrate the effectiveness and generality of the\nClassWise-CRF architecture in semantic segmentation of remote sensing images.\nThe full code is available at https://github.com/zhuqinfeng1999/ClassWise-CRF.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21491v1",
    "published_date": "2025-04-30 10:19:21 UTC",
    "updated_date": "2025-04-30 10:19:21 UTC"
  },
  {
    "arxiv_id": "2504.21489v2",
    "title": "TRIED: Truly Innovative and Effective AI Detection Benchmark, developed by WITNESS",
    "authors": [
      "Shirin Anlen",
      "Zuzanna Wojciak"
    ],
    "abstract": "The proliferation of generative AI and deceptive synthetic media threatens\nthe global information ecosystem, especially across the Global Majority. This\nreport from WITNESS highlights the limitations of current AI detection tools,\nwhich often underperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policy actors, and standards bodies to\ndesign accountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "33 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.21489v2",
    "published_date": "2025-04-30 10:18:19 UTC",
    "updated_date": "2025-05-01 13:38:27 UTC"
  },
  {
    "arxiv_id": "2504.21480v1",
    "title": "A Comprehensive Study of Exploitable Patterns in Smart Contracts: From Vulnerability to Defense",
    "authors": [
      "Yuchen Ding",
      "Hongli Peng",
      "Xiaoqi Li"
    ],
    "abstract": "With the rapid advancement of blockchain technology, smart contracts have\nenabled the implementation of increasingly complex functionalities. However,\nensuring the security of smart contracts remains a persistent challenge across\nthe stages of development, compilation, and execution. Vulnerabilities within\nsmart contracts not only undermine the security of individual applications but\nalso pose significant risks to the broader blockchain ecosystem, as\ndemonstrated by the growing frequency of attacks since 2016, resulting in\nsubstantial financial losses. This paper provides a comprehensive analysis of\nkey security risks in Ethereum smart contracts, specifically those written in\nSolidity and executed on the Ethereum Virtual Machine (EVM). We focus on two\nprevalent and critical vulnerability types (reentrancy and integer overflow) by\nexamining their underlying mechanisms, replicating attack scenarios, and\nassessing effective countermeasures.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21480v1",
    "published_date": "2025-04-30 10:00:36 UTC",
    "updated_date": "2025-04-30 10:00:36 UTC"
  },
  {
    "arxiv_id": "2504.21476v2",
    "title": "GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers",
    "authors": [
      "Xinyu Li",
      "Qi Yao",
      "Yuanda Wang"
    ],
    "abstract": "Garment sewing patterns are fundamental design elements that bridge the gap\nbetween design concepts and practical manufacturing. The generative modeling of\nsewing patterns is crucial for creating diversified garments. However, existing\napproaches are limited either by reliance on a single input modality or by\nsuboptimal generation efficiency. In this work, we present GarmentDiffusion, a\nnew generative model capable of producing centimeter-precise, vectorized 3D\nsewing patterns from multimodal inputs (text, image, and incomplete sewing\npattern). Our method efficiently encodes 3D sewing pattern parameters into\ncompact edge token representations, achieving a sequence length that is 10\ntimes shorter than that of the autoregressive SewingGPT in DressCode. By\nemploying a diffusion transformer, we simultaneously denoise all edge tokens\nalong the temporal axis, while maintaining a constant number of denoising steps\nregardless of dataset-specific edge and panel statistics. With all combination\nof designs of our model, the sewing pattern generation speed is accelerated by\n100 times compared to SewingGPT. We achieve new state-of-the-art results on\nDressCodeData, as well as on the largest sewing pattern dataset, namely\nGarmentCodeData. The project website is available at\nhttps://shenfu-research.github.io/Garment-Diffusion/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The 34th International Joint Conference on Artificial Intelligence\n  (IJCAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.21476v2",
    "published_date": "2025-04-30 09:56:59 UTC",
    "updated_date": "2025-05-10 13:14:47 UTC"
  },
  {
    "arxiv_id": "2504.21475v1",
    "title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines",
    "authors": [
      "Serry Sibaee",
      "Samar Ahmed",
      "Abdullah Al Harbi",
      "Omer Nacar",
      "Adel Ammar",
      "Yasser Habashi",
      "Wadii Boulila"
    ],
    "abstract": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21475v1",
    "published_date": "2025-04-30 09:56:36 UTC",
    "updated_date": "2025-04-30 09:56:36 UTC"
  },
  {
    "arxiv_id": "2504.21474v1",
    "title": "Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner for Subject Tagging",
    "authors": [
      "Hadi Bayrami Asl Tekanlou",
      "Jafar Razmara",
      "Mahsa Sanaei",
      "Mostafa Rahgouy",
      "Hamed Babaei Giglou"
    ],
    "abstract": "This paper presents our system, Homa, for SemEval-2025 Task 5: Subject\nTagging, which focuses on automatically assigning subject labels to technical\nrecords from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage\nOntoAligner, a modular ontology alignment toolkit, to address this task by\nintegrating retrieval-augmented generation (RAG) techniques. Our approach\nformulates the subject tagging problem as an alignment task, where records are\nmatched to GND categories based on semantic similarity. We evaluate\nOntoAligner's adaptability for subject indexing and analyze its effectiveness\nin handling multilingual records. Experimental results demonstrate the\nstrengths and limitations of this method, highlighting the potential of\nalignment techniques for improving subject tagging in digital libraries.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 4 figures, accepted to the LLMs4Subjects shared task at\n  SemEval2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21474v1",
    "published_date": "2025-04-30 09:52:51 UTC",
    "updated_date": "2025-04-30 09:52:51 UTC"
  },
  {
    "arxiv_id": "2504.21457v1",
    "title": "xEEGNet: Towards Explainable AI in EEG Dementia Classification",
    "authors": [
      "Andrea Zanola",
      "Louis Fabrice Tshimanga",
      "Federico Del Pup",
      "Marco Baiesi",
      "Manfredo Atzori"
    ],
    "abstract": "This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21457v1",
    "published_date": "2025-04-30 09:24:50 UTC",
    "updated_date": "2025-04-30 09:24:50 UTC"
  },
  {
    "arxiv_id": "2504.21454v1",
    "title": "SimPRIVE: a Simulation framework for Physical Robot Interaction with Virtual Environments",
    "authors": [
      "Federico Nesti",
      "Gianluca D'Amico",
      "Mauro Marinoni",
      "Giorgio Buttazzo"
    ],
    "abstract": "The use of machine learning in cyber-physical systems has attracted the\ninterest of both industry and academia. However, no general solution has yet\nbeen found against the unpredictable behavior of neural networks and\nreinforcement learning agents. Nevertheless, the improvements of\nphoto-realistic simulators have paved the way towards extensive testing of\ncomplex algorithms in different virtual scenarios, which would be expensive and\ndangerous to implement in the real world.\n  This paper presents SimPRIVE, a simulation framework for physical robot\ninteraction with virtual environments, which operates as a vehicle-in-the-loop\nplatform, rendering a virtual world while operating the vehicle in the real\nworld.\n  Using SimPRIVE, any physical mobile robot running on ROS 2 can easily be\nconfigured to move its digital twin in a virtual world built with the Unreal\nEngine 5 graphic engine, which can be populated with objects, people, or other\nvehicles with programmable behavior.\n  SimPRIVE has been designed to accommodate custom or pre-built virtual worlds\nwhile being light-weight to contain execution times and allow fast rendering.\nIts main advantage lies in the possibility of testing complex algorithms on the\nfull software and hardware stack while minimizing the risks and costs of a test\ncampaign. The framework has been validated by testing a reinforcement learning\nagent trained for obstacle avoidance on an AgileX Scout Mini rover that\nnavigates a virtual office environment where everyday objects and people are\nplaced as obstacles. The physical rover moves with no collision in an indoor\nlimited space, thanks to a LiDAR-based heuristic.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IEEE ITSC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21454v1",
    "published_date": "2025-04-30 09:22:55 UTC",
    "updated_date": "2025-04-30 09:22:55 UTC"
  },
  {
    "arxiv_id": "2505.01453v1",
    "title": "Safe and Efficient CAV Lane Changing using Decentralised Safety Shields",
    "authors": [
      "Bharathkumar Hegde",
      "Melanie Bouroche"
    ],
    "abstract": "Lane changing is a complex decision-making problem for Connected and\nAutonomous Vehicles (CAVs) as it requires balancing traffic efficiency with\nsafety. Although traffic efficiency can be improved by using vehicular\ncommunication for training lane change controllers using Multi-Agent\nReinforcement Learning (MARL), ensuring safety is difficult. To address this\nissue, we propose a decentralised Hybrid Safety Shield (HSS) that combines\noptimisation and a rule-based approach to guarantee safety. Our method applies\ncontrol barrier functions to constrain longitudinal and lateral control inputs\nof a CAV to ensure safe manoeuvres. Additionally, we present an architecture to\nintegrate HSS with MARL, called MARL-HSS, to improve traffic efficiency while\nensuring safety. We evaluate MARL-HSS using a gym-like environment that\nsimulates an on-ramp merging scenario with two levels of traffic densities,\nsuch as light and moderate densities. The results show that HSS provides a\nsafety guarantee by strictly enforcing a dynamic safety constraint defined on a\ntime headway, even in moderate traffic density that offers challenging lane\nchange scenarios. Moreover, the proposed method learns stable policies compared\nto the baseline, a state-of-the-art MARL lane change controller without a\nsafety shield. Further policy evaluation shows that our method achieves a\nbalance between safety and traffic efficiency with zero crashes and comparable\naverage speeds in light and moderate traffic densities.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted in IEEE IV 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.01453v1",
    "published_date": "2025-04-30 09:11:09 UTC",
    "updated_date": "2025-04-30 09:11:09 UTC"
  },
  {
    "arxiv_id": "2504.21447v1",
    "title": "Rethinking Visual Layer Selection in Multimodal LLMs",
    "authors": [
      "Haoran Chen",
      "Junyan Lin",
      "Xinhao Chen",
      "Yue Fan",
      "Xin Jin",
      "Hui Su",
      "Jianfeng Dong",
      "Jinlan Fu",
      "Xiaoyu Shen"
    ],
    "abstract": "Multimodal large language models (MLLMs) have achieved impressive performance\nacross a wide range of tasks, typically using CLIP-ViT as their visual encoder\ndue to its strong text-image alignment capabilities. While prior studies\nsuggest that different CLIP-ViT layers capture different types of information,\nwith shallower layers focusing on fine visual details and deeper layers\naligning more closely with textual semantics, most MLLMs still select visual\nfeatures based on empirical heuristics rather than systematic analysis. In this\nwork, we propose a Layer-wise Representation Similarity approach to group\nCLIP-ViT layers with similar behaviors into {shallow, middle, and deep}\ncategories and assess their impact on MLLM performance. Building on this\nfoundation, we revisit the visual layer selection problem in MLLMs at scale,\ntraining LLaVA-style models ranging from 1.4B to 7B parameters. Through\nextensive experiments across 10 datasets and 4 tasks, we find that: (1) deep\nlayers are essential for OCR tasks; (2) shallow and middle layers substantially\noutperform deep layers on reasoning tasks involving counting, positioning, and\nobject localization; (3) a lightweight fusion of features across shallow,\nmiddle, and deep layers consistently outperforms specialized fusion baselines\nand single-layer selections, achieving gains on 9 out of 10 datasets. Our work\noffers the first principled study of visual layer selection in MLLMs, laying\nthe groundwork for deeper investigations into visual representation learning\nfor MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures, submitted to ICCV 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21447v1",
    "published_date": "2025-04-30 09:07:10 UTC",
    "updated_date": "2025-04-30 09:07:10 UTC"
  },
  {
    "arxiv_id": "2504.21435v3",
    "title": "SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding",
    "authors": [
      "Chenkai Zhang",
      "Yiming Lei",
      "Zeming Liu",
      "Haitao Leng",
      "Shaoguo Liu",
      "Tingting Gao",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "abstract": "With the rapid development of Multi-modal Large Language Models (MLLMs), an\nincreasing number of benchmarks have been established to evaluate the video\nunderstanding capabilities of these models. However, these benchmarks focus on\nstandalone videos and mainly assess \"visual elements\" like human actions and\nobject states. In reality, contemporary videos often encompass complex and\ncontinuous narratives, typically presented as a series. To address this\nchallenge, we propose SeriesBench, a benchmark consisting of 105 carefully\ncurated narrative-driven series, covering 28 specialized tasks that require\ndeep narrative understanding. Specifically, we first select a diverse set of\ndrama series spanning various genres. Then, we introduce a novel long-span\nnarrative annotation method, combined with a full-information transformation\napproach to convert manual annotations into diverse task formats. To further\nenhance model capacity for detailed analysis of plot structures and character\nrelationships within series, we propose a novel narrative reasoning framework,\nPC-DCoT. Extensive results on SeriesBench indicate that existing MLLMs still\nface significant challenges in understanding narrative-driven series, while\nPC-DCoT enables these MLLMs to achieve performance improvements. Overall, our\nSeriesBench and PC-DCoT highlight the critical necessity of advancing model\ncapabilities to understand narrative-driven series, guiding the future\ndevelopment of MLLMs. SeriesBench is publicly available at\nhttps://github.com/zackhxn/SeriesBench-CVPR2025.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages, 15 figures, CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21435v3",
    "published_date": "2025-04-30 08:48:21 UTC",
    "updated_date": "2025-05-13 08:06:19 UTC"
  },
  {
    "arxiv_id": "2504.21433v1",
    "title": "NGENT: Next-Generation AI Agents Must Integrate Multi-Domain Abilities to Achieve Artificial General Intelligence",
    "authors": [
      "Zhicong Li",
      "Hangyu Mao",
      "Jiangjin Yin",
      "Mingzhe Xing",
      "Zhiwei Xu",
      "Yuanxing Zhang",
      "Yang Xiao"
    ],
    "abstract": "This paper argues that the next generation of AI agent (NGENT) should\nintegrate across-domain abilities to advance toward Artificial General\nIntelligence (AGI). Although current AI agents are effective in specialized\ntasks such as robotics, role-playing, and tool-using, they remain confined to\nnarrow domains. We propose that future AI agents should synthesize the\nstrengths of these specialized systems into a unified framework capable of\noperating across text, vision, robotics, reinforcement learning, emotional\nintelligence, and beyond. This integration is not only feasible but also\nessential for achieving the versatility and adaptability that characterize\nhuman intelligence. The convergence of technologies across AI domains, coupled\nwith increasing user demand for cross-domain capabilities, suggests that such\nintegration is within reach. Ultimately, the development of these versatile\nagents is a critical step toward realizing AGI. This paper explores the\nrationale for this shift, potential pathways for achieving it.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21433v1",
    "published_date": "2025-04-30 08:46:14 UTC",
    "updated_date": "2025-04-30 08:46:14 UTC"
  },
  {
    "arxiv_id": "2504.21428v1",
    "title": "UAV Marketplace Simulation Tool for BVLOS Operations",
    "authors": [
      "Kıvanç Şerefoğlu",
      "Önder Gürcan",
      "Reyhan Aydoğan"
    ],
    "abstract": "We present a simulation tool for evaluating team formation in autonomous\nmulti-UAV (Unmanned Aerial Vehicle) missions that operate Beyond Visual Line of\nSight (BVLOS). The tool models UAV collaboration and mission execution in\ndynamic and adversarial conditions, where Byzantine UAVs attempt to disrupt\noperations. Our tool allows researchers to integrate and compare various team\nformation strategies in a controlled environment with configurable mission\nparameters and adversarial behaviors. The log of each simulation run is stored\nin a structured way along with performance metrics so that statistical analysis\ncould be done straightforwardly. The tool is versatile for testing and\nimproving UAV coordination strategies in real-world applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.RO",
    "comment": "3 pages, 2 figures, the 24th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.21428v1",
    "published_date": "2025-04-30 08:36:22 UTC",
    "updated_date": "2025-04-30 08:36:22 UTC"
  },
  {
    "arxiv_id": "2504.21427v1",
    "title": "MPEC: Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers",
    "authors": [
      "Shermin Shahbazi",
      "Mohammad-Reza Nasiri",
      "Majid Ramezani"
    ],
    "abstract": "Accurate classification of EEG signals is crucial for brain-computer\ninterfaces (BCIs) and neuroprosthetic applications, yet many existing methods\nfail to account for the non-Euclidean, manifold structure of EEG data,\nresulting in suboptimal performance. Preserving this manifold information is\nessential to capture the true geometry of EEG signals, but traditional\nclassification techniques largely overlook this need. To this end, we propose\nMPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based\nClassifiers), that introduces two key innovations: (1) a feature engineering\nphase that combines covariance matrices and Radial Basis Function (RBF) kernels\nto capture both linear and non-linear relationships among EEG channels, and (2)\na clustering phase that employs a modified K-means algorithm tailored for the\nRiemannian manifold space, ensuring local geometric sensitivity. Ensembling\nmultiple clustering-based classifiers, MPEC achieves superior results,\nvalidated by significant improvements on the BCI Competition IV dataset 2a.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages ,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.21427v1",
    "published_date": "2025-04-30 08:34:15 UTC",
    "updated_date": "2025-04-30 08:34:15 UTC"
  },
  {
    "arxiv_id": "2504.21415v2",
    "title": "Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges",
    "authors": [
      "Yi Wang",
      "Chengyv Wu",
      "Yang Liao",
      "Maowei You"
    ],
    "abstract": "User authentication is essential to ensure secure access to computer systems,\nyet traditional methods face limitations in usability, cost, and security.\nMouse dynamics authentication, based on the analysis of users' natural\ninteraction behaviors with mouse devices, offers a cost-effective,\nnon-intrusive, and adaptable solution. However, challenges remain in\ndetermining the optimal data volume, balancing accuracy and practicality, and\neffectively capturing temporal behavioral patterns. In this study, we propose a\nstatistical method using Gaussian kernel density estimate (KDE) and\nKullback-Leibler (KL) divergence to estimate the sufficient data volume for\ntraining authentication models. We introduce the Mouse Authentication Unit\n(MAU), leveraging Approximate Entropy (ApEn) to optimize segment length for\nefficient and accurate behavioral representation. Furthermore, we design the\nLocal-Time Mouse Authentication (LT-AMouse) framework, integrating 1D-ResNet\nfor local feature extraction and GRU for modeling long-term temporal\ndependencies. Taking the Balabit and DFL datasets as examples, we significantly\nreduced the data scale, particularly by a factor of 10 for the DFL dataset,\ngreatly alleviating the training burden. Additionally, we determined the\noptimal input recognition unit length for the user authentication system on\ndifferent datasets based on the slope of Approximate Entropy. Training with\nimbalanced samples, our model achieved a successful defense AUC 98.52% for\nblind attack on the DFL dataset and 94.65% on the Balabit dataset, surpassing\nthe current sota performance.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.21415v2",
    "published_date": "2025-04-30 08:16:52 UTC",
    "updated_date": "2025-05-11 05:42:14 UTC"
  },
  {
    "arxiv_id": "2504.21411v1",
    "title": "Galvatron: An Automatic Distributed System for Efficient Foundation Model Training",
    "authors": [
      "Xinyi Liu",
      "Yujie Wang",
      "Shenhan Zhu",
      "Fangcheng Fu",
      "Qingshuo Liu",
      "Guangming Lin",
      "Bin Cui"
    ],
    "abstract": "Galvatron is a distributed system for efficiently training large-scale\nFoundation Models. It overcomes the complexities of selecting optimal\nparallelism strategies by automatically identifying the most efficient hybrid\nstrategy, incorporating data, tensor, pipeline, sharded data, and sequence\nparallelism, along with recomputation. The system's architecture includes a\nprofiler for hardware and model analysis, a search engine for strategy\noptimization using decision trees and dynamic programming, and a runtime for\nexecuting these strategies efficiently. Benchmarking on various clusters\ndemonstrates Galvatron's superior throughput compared to existing frameworks.\nThis open-source system offers user-friendly interfaces and comprehensive\ndocumentation, making complex distributed training accessible and efficient.\nThe source code of Galvatron is available at\nhttps://github.com/PKU-DAIR/Hetu-Galvatron.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21411v1",
    "published_date": "2025-04-30 08:11:45 UTC",
    "updated_date": "2025-04-30 08:11:45 UTC"
  },
  {
    "arxiv_id": "2504.21383v1",
    "title": "FAST-Q: Fast-track Exploration with Adversarially Balanced State Representations for Counterfactual Action Estimation in Offline Reinforcement Learning",
    "authors": [
      "Pulkit Agrawal",
      "Rukma Talwadker",
      "Aditya Pareek",
      "Tridib Mukherjee"
    ],
    "abstract": "Recent advancements in state-of-the-art (SOTA) offline reinforcement learning\n(RL) have primarily focused on addressing function approximation errors, which\ncontribute to the overestimation of Q-values for out-of-distribution actions, a\nchallenge that static datasets exacerbate. However, high stakes applications\nsuch as recommendation systems in online gaming, introduce further complexities\ndue to player's psychology (intent) driven by gameplay experiences and the\ninherent volatility on the platform. These factors create highly sparse,\npartially overlapping state spaces across policies, further influenced by the\nexperiment path selection logic which biases state spaces towards specific\npolicies. Current SOTA methods constrain learning from such offline data by\nclipping known counterfactual actions as out-of-distribution due to poor\ngeneralization across unobserved states. Further aggravating conservative\nQ-learning and necessitating more online exploration. FAST-Q introduces a novel\napproach that (1) leverages Gradient Reversal Learning to construct balanced\nstate representations, regularizing the policy-specific bias between the\nplayer's state and action thereby enabling counterfactual estimation; (2)\nsupports offline counterfactual exploration in parallel with static data\nexploitation; and (3) proposes a Q-value decomposition strategy for\nmulti-objective optimization, facilitating explainable recommendations over\nshort and long-term objectives. These innovations demonstrate superiority of\nFAST-Q over prior SOTA approaches and demonstrates at least 0.15 percent\nincrease in player returns, 2 percent improvement in lifetime value (LTV), 0.4\npercent enhancement in the recommendation driven engagement, 2 percent\nimprovement in the player's platform dwell time and an impressive 10 percent\nreduction in the costs associated with the recommendation, on our volatile\ngaming platform.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21383v1",
    "published_date": "2025-04-30 07:32:40 UTC",
    "updated_date": "2025-04-30 07:32:40 UTC"
  },
  {
    "arxiv_id": "2505.00050v1",
    "title": "Emotional Analysis of Fashion Trends Using Social Media and AI: Sentiment Analysis on Twitter for Fashion Trend Forecasting",
    "authors": [
      "Aayam Bansal",
      "Agneya Tharun"
    ],
    "abstract": "This study explores the intersection of fashion trends and social media\nsentiment through computational analysis of Twitter data using the T4SA\n(Twitter for Sentiment Analysis) dataset. By applying natural language\nprocessing and machine learning techniques, we examine how sentiment patterns\nin fashion-related social media conversations can serve as predictors for\nemerging fashion trends. Our analysis involves the identification and\ncategorization of fashion-related content, sentiment classification with\nimproved normalization techniques, time series decomposition, statistically\nvalidated causal relationship modeling, cross-platform sentiment comparison,\nand brand-specific sentiment analysis. Results indicate correlations between\nsentiment patterns and fashion theme popularity, with accessories and\nstreetwear themes showing statistically significant rising trends. The Granger\ncausality analysis establishes sustainability and streetwear as primary trend\ndrivers, showing bidirectional relationships with several other themes. The\nfindings demonstrate that social media sentiment analysis can serve as an\neffective early indicator of fashion trend trajectories when proper statistical\nvalidation is applied. Our improved predictive model achieved 78.35% balanced\naccuracy in sentiment classification, establishing a reliable foundation for\ntrend prediction across positive, neutral, and negative sentiment categories.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.00050v1",
    "published_date": "2025-04-30 07:27:06 UTC",
    "updated_date": "2025-04-30 07:27:06 UTC"
  },
  {
    "arxiv_id": "2504.21372v1",
    "title": "Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction",
    "authors": [
      "Máté Gedeon"
    ],
    "abstract": "Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21372v1",
    "published_date": "2025-04-30 07:10:10 UTC",
    "updated_date": "2025-04-30 07:10:10 UTC"
  },
  {
    "arxiv_id": "2504.21370v2",
    "title": "ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning",
    "authors": [
      "Jingyang Yi",
      "Jiazheng Wang",
      "Sida Li"
    ],
    "abstract": "Recent models such as OpenAI o1 and DeepSeek-R1 have demonstrated strong\nperformance on reasoning-intensive tasks by generating extended\nChain-of-Thought (CoT) traces. While longer reasoning helps with thorough\nexploration of solution paths for complex problems, it also often leads to\ninefficient and redundant outputs--a phenomenon commonly described as\noverthinking. In this paper, we propose ShorterBetter, a simple yet effective\nreinforcement learning method that enables reasoning models to learn their own\noptimal CoT lengths without manual supervision. We define the Sample Optimal\nLength (SOL) as the length of the shortest correct response among multiple\ngenerations, which serves as a dynamic reward signal to guide the model toward\nefficient reasoning. Applied to DeepSeek-Distill-Qwen-1.5B/7B as base models,\nShorterBetter achieves 50%-80% reduction in output lengths in both in-domain\nand out-of-domain reasoning tasks while maintaining accuracy. Our reasoning\ntrace analysis shows that ShorterBetter refines the structure of the reasoning\ntraces by reducing unnecessary repetition, excessive self-verification, and\nover-exploration of alternatives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Training script, model weights and analysis pipelines will be\n  released soon",
    "pdf_url": "http://arxiv.org/pdf/2504.21370v2",
    "published_date": "2025-04-30 07:04:19 UTC",
    "updated_date": "2025-05-16 20:59:40 UTC"
  },
  {
    "arxiv_id": "2504.21368v1",
    "title": "Revisiting Diffusion Autoencoder Training for Image Reconstruction Quality",
    "authors": [
      "Pramook Khungurn",
      "Sukit Seripanitkarn",
      "Phonphrm Thawatdamrongkit",
      "Supasorn Suwajanakorn"
    ],
    "abstract": "Diffusion autoencoders (DAEs) are typically formulated as a noise prediction\nmodel and trained with a linear-$\\beta$ noise schedule that spends much of its\nsampling steps at high noise levels. Because high noise levels are associated\nwith recovering large-scale image structures and low noise levels with\nrecovering details, this configuration can result in low-quality and blurry\nimages. However, it should be possible to improve details while spending fewer\nsteps recovering structures because the latent code should already contain\nstructural information. Based on this insight, we propose a new DAE training\nmethod that improves the quality of reconstructed images. We divide training\ninto two phases. In the first phase, the DAE is trained as a vanilla\nautoencoder by always setting the noise level to the highest, forcing the\nencoder and decoder to populate the latent code with structural information. In\nthe second phase, we incorporate a noise schedule that spends more time in the\nlow-noise region, allowing the DAE to learn how to perfect the details. Our\nmethod results in images that have accurate high-level structures and low-level\ndetails while still preserving useful properties of the latent codes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AI for Content Creation (AI4CC) Workshop at CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21368v1",
    "published_date": "2025-04-30 07:00:33 UTC",
    "updated_date": "2025-04-30 07:00:33 UTC"
  },
  {
    "arxiv_id": "2504.21366v1",
    "title": "DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic Gating Fusion",
    "authors": [
      "Yinfeng Yu",
      "Shiyu Sun"
    ],
    "abstract": "Current Audio-Visual Source Separation methods primarily adopt two design\nstrategies. The first strategy involves fusing audio and visual features at the\nbottleneck layer of the encoder, followed by processing the fused features\nthrough the decoder. However, when there is a significant disparity between the\ntwo modalities, this approach may lead to the loss of critical information. The\nsecond strategy avoids direct fusion and instead relies on the decoder to\nhandle the interaction between audio and visual features. Nonetheless, if the\nencoder fails to integrate information across modalities adequately, the\ndecoder may be unable to effectively capture the complex relationships between\nthem. To address these issues, this paper proposes a dynamic fusion method\nbased on a gating mechanism that dynamically adjusts the modality fusion\ndegree. This approach mitigates the limitations of solely relying on the\ndecoder and facilitates efficient collaboration between audio and visual\nfeatures. Additionally, an audio attention module is introduced to enhance the\nexpressive capacity of audio features, thereby further improving model\nperformance. Experimental results demonstrate that our method achieves\nsignificant performance improvements on two benchmark datasets, validating its\neffectiveness and advantages in Audio-Visual Source Separation tasks.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "Main paper (9 pages). Accepted for publication by ICMR(International\n  Conference on Multimedia Retrieval) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21366v1",
    "published_date": "2025-04-30 06:55:24 UTC",
    "updated_date": "2025-04-30 06:55:24 UTC"
  },
  {
    "arxiv_id": "2504.21358v1",
    "title": "A comparative study of deep learning and ensemble learning to extend the horizon of traffic forecasting",
    "authors": [
      "Xiao Zheng",
      "Saeed Asadi Bagloee",
      "Majid Sarvi"
    ],
    "abstract": "Traffic forecasting is vital for Intelligent Transportation Systems, for\nwhich Machine Learning (ML) methods have been extensively explored to develop\ndata-driven Artificial Intelligence (AI) solutions. Recent research focuses on\nmodelling spatial-temporal correlations for short-term traffic prediction,\nleaving the favourable long-term forecasting a challenging and open issue. This\npaper presents a comparative study on large-scale real-world signalized\narterials and freeway traffic flow datasets, aiming to evaluate promising ML\nmethods in the context of large forecasting horizons up to 30 days. Focusing on\nmodelling capacity for temporal dynamics, we develop one ensemble ML method,\neXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods,\nincluding Recurrent Neural Network (RNN)-based methods and the state-of-the-art\nTransformer-based method. Time embedding is leveraged to enhance their\nunderstanding of seasonality and event factors. Experimental results highlight\nthat while the attention mechanism/Transformer framework is effective for\ncapturing long-range dependencies in sequential data, as the forecasting\nhorizon extends, the key to effective traffic forecasting gradually shifts from\ntemporal dependency capturing to periodicity modelling. Time embedding is\nparticularly effective in this context, helping naive RNN outperform Informer\nby 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust\nmodel, XGBoost, while learning solely from time features, performs\ncompetitively with DL methods. Moreover, we investigate the impacts of various\nfactors like input sequence length, holiday traffic, data granularity, and\ntraining data size. The findings offer valuable insights and serve as a\nreference for future long-term traffic forecasting research and the improvement\nof AI's corresponding learning capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.21358v1",
    "published_date": "2025-04-30 06:31:21 UTC",
    "updated_date": "2025-04-30 06:31:21 UTC"
  },
  {
    "arxiv_id": "2504.21356v2",
    "title": "Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing",
    "authors": [
      "Hong Zhang",
      "Zhongjie Duan",
      "Xingjun Wang",
      "Yuze Zhao",
      "Weiyi Lu",
      "Zhipeng Di",
      "Yixuan Xu",
      "Yingda Chen",
      "Yu Zhang"
    ],
    "abstract": "Unified multimodal large language models (MLLMs) aim to integrate multimodal\nunderstanding and generation abilities through a single framework. Despite\ntheir versatility, existing open-source unified models exhibit performance gaps\nagainst domain-specific architectures. To bridge this gap, we present\nNexus-Gen, a unified model that synergizes the language reasoning capabilities\nof LLMs with the image synthesis power of diffusion models. To align the\nembedding space of the LLM and diffusion model, we conduct a dual-phase\nalignment training process. (1) The autoregressive LLM learns to predict image\nembeddings conditioned on multimodal inputs, while (2) the vision decoder is\ntrained to reconstruct high-fidelity images from these embeddings. During\ntraining the LLM, we identified a critical discrepancy between the\nautoregressive paradigm's training and inference phases, where error\naccumulation in continuous embedding space severely degrades generation\nquality. To avoid this issue, we introduce a prefilled autoregression strategy\nthat prefills input sequence with position-embedded special tokens instead of\ncontinuous embeddings. Through dual-phase training, Nexus-Gen has developed the\nintegrated capability to comprehensively address the image understanding,\ngeneration and editing tasks. All models, datasets, and codes are published at\nhttps://github.com/modelscope/Nexus-Gen.git to facilitate further advancements\nacross the field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21356v2",
    "published_date": "2025-04-30 06:30:48 UTC",
    "updated_date": "2025-05-08 08:58:12 UTC"
  },
  {
    "arxiv_id": "2504.21347v1",
    "title": "IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces",
    "authors": [
      "Seonghee Lee",
      "Denae Ford",
      "John Tang",
      "Sasa Junuzovic",
      "Asta Roseway",
      "Ed Cutrell",
      "Kori Inkpen"
    ],
    "abstract": "We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent\ndesigned to represent remote colleagues in shared office spaces, creating\nopportunities for real-time exchanges even in their absence. IRL Ditto offers a\nunique hybrid experience by allowing in-person colleagues to encounter a\ndigital version of their remote teammates, initiating greetings, updates, or\nsmall talk as they might in person. Our research question examines: How can the\nIRL Ditto influence interactions and relationships among colleagues in a shared\noffice space? Through a four-day study, we assessed IRL Ditto's ability to\nstrengthen social ties by simulating presence and enabling meaningful\ninteractions across different levels of social familiarity. We find that\nenhancing social relationships depended deeply on the foundation of the\nrelationship participants had with the source of the IRL Ditto. This study\nprovides insights into the role of embodied agents in enriching workplace\ndynamics for distributed teams.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "H.5.2; I.2.9"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.21347v1",
    "published_date": "2025-04-30 06:16:32 UTC",
    "updated_date": "2025-04-30 06:16:32 UTC"
  },
  {
    "arxiv_id": "2504.21344v1",
    "title": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection",
    "authors": [
      "Luoting Zhuang",
      "Seyed Mohammad Hossein Tabatabaei",
      "Ramin Salehi-Rad",
      "Linh M. Tran",
      "Denise R. Aberle",
      "Ashley E. Prosper",
      "William Hsu"
    ],
    "abstract": "Objective: A number of machine learning models have utilized semantic\nfeatures, deep features, or both to assess lung nodule malignancy. However,\ntheir reliance on manual annotation during inference, limited interpretability,\nand sensitivity to imaging variations hinder their application in real-world\nclinical settings. Thus, this research aims to integrate semantic features\nderived from radiologists' assessments of nodules, allowing the model to learn\nclinically relevant, robust, and explainable features for predicting lung\ncancer. Methods: We obtained 938 low-dose CT scans from the National Lung\nScreening Trial with 1,246 nodules and semantic features. The Lung Image\nDatabase Consortium dataset contains 1,018 CT scans, with 2,625 lesions\nannotated for nodule characteristics. Three external datasets were obtained\nfrom UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We\nfinetuned a pretrained Contrastive Language-Image Pretraining model with a\nparameter-efficient fine-tuning approach to align imaging and semantic features\nand predict the one-year lung cancer diagnosis. Results: We evaluated the\nperformance of the one-year diagnosis of lung cancer with AUROC and AUPRC and\ncompared it to three state-of-the-art models. Our model demonstrated an AUROC\nof 0.90 and AUPRC of 0.78, outperforming baseline state-of-the-art models on\nexternal datasets. Using CLIP, we also obtained predictions on semantic\nfeatures, such as nodule margin (AUROC: 0.81), nodule consistency (0.81), and\npleural attachment (0.84), that can be used to explain model predictions.\nConclusion: Our approach accurately classifies lung nodules as benign or\nmalignant, providing explainable outputs, aiding clinicians in comprehending\nthe underlying meaning of model predictions. This approach also prevents the\nmodel from learning shortcuts and generalizes across clinical settings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21344v1",
    "published_date": "2025-04-30 06:11:34 UTC",
    "updated_date": "2025-04-30 06:11:34 UTC"
  },
  {
    "arxiv_id": "2504.21326v1",
    "title": "Q-function Decomposition with Intervention Semantics with Factored Action Spaces",
    "authors": [
      "Junkyu Lee",
      "Tian Gao",
      "Elliot Nelson",
      "Miao Liu",
      "Debarun Bhattacharjya",
      "Songtao Lu"
    ],
    "abstract": "Many practical reinforcement learning environments have a discrete factored\naction space that induces a large combinatorial set of actions, thereby posing\nsignificant challenges. Existing approaches leverage the regular structure of\nthe action space and resort to a linear decomposition of Q-functions, which\navoids enumerating all combinations of factored actions. In this paper, we\nconsider Q-functions defined over a lower dimensional projected subspace of the\noriginal action space, and study the condition for the unbiasedness of\ndecomposed Q-functions using causal effect estimation from the no unobserved\nconfounder setting in causal statistics. This leads to a general scheme which\nwe call action decomposed reinforcement learning that uses the projected\nQ-functions to approximate the Q-function in standard model-free reinforcement\nlearning algorithms. The proposed approach is shown to improve sample\ncomplexity in a model-based reinforcement learning setting. We demonstrate\nimprovements in sample efficiency compared to state-of-the-art baselines in\nonline continuous control environments and a real-world offline sepsis\ntreatment environment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21326v1",
    "published_date": "2025-04-30 05:26:51 UTC",
    "updated_date": "2025-04-30 05:26:51 UTC"
  },
  {
    "arxiv_id": "2504.21323v1",
    "title": "How to Backdoor the Knowledge Distillation",
    "authors": [
      "Chen Wu",
      "Qian Ma",
      "Prasenjit Mitra",
      "Sencun Zhu"
    ],
    "abstract": "Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21323v1",
    "published_date": "2025-04-30 05:19:23 UTC",
    "updated_date": "2025-04-30 05:19:23 UTC"
  },
  {
    "arxiv_id": "2504.21318v1",
    "title": "Phi-4-reasoning Technical Report",
    "authors": [
      "Marah Abdin",
      "Sahaj Agarwal",
      "Ahmed Awadallah",
      "Vidhisha Balachandran",
      "Harkirat Behl",
      "Lingjiao Chen",
      "Gustavo de Rosa",
      "Suriya Gunasekar",
      "Mojan Javaheripi",
      "Neel Joshi",
      "Piero Kauffmann",
      "Yash Lara",
      "Caio César Teodoro Mendes",
      "Arindam Mitra",
      "Besmira Nushi",
      "Dimitris Papailiopoulos",
      "Olli Saarikivi",
      "Shital Shah",
      "Vaishnavi Shrivastava",
      "Vibhav Vineet",
      "Yue Wu",
      "Safoora Yousefi",
      "Guoqing Zheng"
    ],
    "abstract": "We introduce Phi-4-reasoning, a 14-billion parameter reasoning model that\nachieves strong performance on complex reasoning tasks. Trained via supervised\nfine-tuning of Phi-4 on carefully curated set of \"teachable\" prompts-selected\nfor the right level of complexity and diversity-and reasoning demonstrations\ngenerated using o3-mini, Phi-4-reasoning generates detailed reasoning chains\nthat effectively leverage inference-time compute. We further develop\nPhi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based\nreinforcement learning that offers higher performance by generating longer\nreasoning traces. Across a wide range of reasoning tasks, both models\noutperform significantly larger open-weight models such as\nDeepSeek-R1-Distill-Llama-70B model and approach the performance levels of full\nDeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math and\nscientific reasoning, coding, algorithmic problem solving, planning, and\nspatial understanding. Interestingly, we observe a non-trivial transfer of\nimprovements to general-purpose benchmarks as well. In this report, we provide\ninsights into our training data, our training methodologies, and our\nevaluations. We show that the benefit of careful data curation for supervised\nfine-tuning (SFT) extends to reasoning language models, and can be further\namplified by reinforcement learning (RL). Finally, our evaluation points to\nopportunities for improving how we assess the performance and robustness of\nreasoning models.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21318v1",
    "published_date": "2025-04-30 05:05:09 UTC",
    "updated_date": "2025-04-30 05:05:09 UTC"
  },
  {
    "arxiv_id": "2504.21297v1",
    "title": "Participatory AI, Public Sector AI, Differential Privacy, Conversational Interfaces, Explainable AI, Citizen Engagement in AI",
    "authors": [
      "Wenjun Yang",
      "Eyhab Al-Masri"
    ],
    "abstract": "This paper introduces a conversational interface system that enables\nparticipatory design of differentially private AI systems in public sector\napplications. Addressing the challenge of balancing mathematical privacy\nguarantees with democratic accountability, we propose three key contributions:\n(1) an adaptive $\\epsilon$-selection protocol leveraging TOPSIS multi-criteria\ndecision analysis to align citizen preferences with differential privacy (DP)\nparameters, (2) an explainable noise-injection framework featuring real-time\nMean Absolute Error (MAE) visualizations and GPT-4-powered impact analysis, and\n(3) an integrated legal-compliance mechanism that dynamically modulates privacy\nbudgets based on evolving regulatory constraints. Our results advance\nparticipatory AI practices by demonstrating how conversational interfaces can\nenhance public engagement in algorithmic privacy mechanisms, ensuring that\nprivacy-preserving AI in public sector governance remains both mathematically\nrobust and democratically accountable.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21297v1",
    "published_date": "2025-04-30 04:10:50 UTC",
    "updated_date": "2025-04-30 04:10:50 UTC"
  },
  {
    "arxiv_id": "2504.21296v1",
    "title": "Fairness in Graph Learning Augmented with Machine Learning: A Survey",
    "authors": [
      "Renqiang Luo",
      "Ziqi Xu",
      "Xikun Zhang",
      "Qing Qing",
      "Huafei Huang",
      "Enyan Dai",
      "Zhe Wang",
      "Bo Yang"
    ],
    "abstract": "Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21296v1",
    "published_date": "2025-04-30 04:02:23 UTC",
    "updated_date": "2025-04-30 04:02:23 UTC"
  },
  {
    "arxiv_id": "2504.21289v1",
    "title": "Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for High-Dimensional Data and Its Application in Stock Trend Prediction",
    "authors": [
      "Yan Huang",
      "Da-Qing Zhang"
    ],
    "abstract": "Biclustering is an effective technique in data mining and pattern\nrecognition. Biclustering algorithms based on traditional clustering face two\nfundamental limitations when processing high-dimensional data: (1) The distance\nconcentration phenomenon in high-dimensional spaces leads to data sparsity,\nrendering similarity measures ineffective; (2) Mainstream linear dimensionality\nreduction methods disrupt critical local structural patterns. To apply\nbiclustering to high-dimensional datasets, we propose an orthogonal\nfactor-based biclustering algorithm (BCBOF). First, we constructed orthogonal\nfactors in the vector space of the high-dimensional dataset. Then, we performed\nclustering using the coordinates of the original data in the orthogonal\nsubspace as clustering targets. Finally, we obtained biclustering results of\nthe original dataset. Since dimensionality reduction was applied before\nclustering, the proposed algorithm effectively mitigated the data sparsity\nproblem caused by high dimensionality. Additionally, we applied this\nbiclustering algorithm to stock technical indicator combinations and stock\nprice trend prediction. Biclustering results were transformed into fuzzy rules,\nand we incorporated profit-preserving and stop-loss rules into the rule set,\nultimately forming a fuzzy inference system for stock price trend predictions\nand trading signals. To evaluate the performance of BCBOF, we compared it with\nexisting biclustering methods using multiple evaluation metrics. The results\nshowed that our algorithm outperformed other biclustering techniques. To\nvalidate the effectiveness of the fuzzy inference system, we conducted virtual\ntrading experiments using historical data from 10 A-share stocks. The\nexperimental results showed that the generated trading strategies yielded\nhigher returns for investors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21289v1",
    "published_date": "2025-04-30 03:49:08 UTC",
    "updated_date": "2025-04-30 03:49:08 UTC"
  },
  {
    "arxiv_id": "2504.21277v2",
    "title": "Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models",
    "authors": [
      "Guanghao Zhou",
      "Panjia Qiu",
      "Cen Chen",
      "Jie Wang",
      "Zheming Yang",
      "Jian Xu",
      "Minghui Qiu"
    ],
    "abstract": "The application of reinforcement learning (RL) to enhance the reasoning\ncapabilities of Multimodal Large Language Models (MLLMs) constitutes a rapidly\nadvancing research area. While MLLMs extend Large Language Models (LLMs) to\nhandle diverse modalities such as vision, audio, and video, enabling robust\nreasoning across multimodal inputs remains challenging. This paper provides a\nsystematic review of recent advances in RL-based reasoning for MLLMs, covering\nkey algorithmic designs, reward mechanism innovations, and practical\napplications. We highlight two main RL paradigms, value-model-free and\nvalue-model-based methods, and analyze how RL enhances reasoning abilities by\noptimizing reasoning trajectories and aligning multimodal information.\nAdditionally, we provide an extensive overview of benchmark datasets,\nevaluation protocols, and current limitations, and propose future research\ndirections to address challenges such as sparse rewards, inefficient\ncross-modal reasoning, and real-world deployment constraints. Our goal is to\nprovide a comprehensive and structured guide to RL-based multimodal reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21277v2",
    "published_date": "2025-04-30 03:14:28 UTC",
    "updated_date": "2025-05-21 06:08:31 UTC"
  },
  {
    "arxiv_id": "2504.21276v1",
    "title": "Assessing LLM code generation quality through path planning tasks",
    "authors": [
      "Wanyi Chen",
      "Meng-Wen Su",
      "Mary L. Cummings"
    ],
    "abstract": "As LLM-generated code grows in popularity, more evaluation is needed to\nassess the risks of using such tools, especially for safety-critical\napplications such as path planning. Existing coding benchmarks are insufficient\nas they do not reflect the context and complexity of safety-critical\napplications. To this end, we assessed six LLMs' abilities to generate the code\nfor three different path-planning algorithms and tested them on three maps of\nvarious difficulties. Our results suggest that LLM-generated code presents\nserious hazards for path planning applications and should not be applied in\nsafety-critical contexts without rigorous testing.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21276v1",
    "published_date": "2025-04-30 03:11:54 UTC",
    "updated_date": "2025-04-30 03:11:54 UTC"
  },
  {
    "arxiv_id": "2505.00742v1",
    "title": "Zoomer: Adaptive Image Focus Optimization for Black-box MLLM",
    "authors": [
      "Jiaxu Qian",
      "Chendong Wang",
      "Yifan Yang",
      "Chaoyun Zhang",
      "Huiqiang Jiang",
      "Xufang Luo",
      "Yu Kang",
      "Qingwei Lin",
      "Anlan Zhang",
      "Shiqi Jiang",
      "Ting Cao",
      "Tianjun Mao",
      "Suman Banerjee",
      "Guyue Liu",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Yuqing Yang",
      "Qi Zhang",
      "Lili Qiu"
    ],
    "abstract": "Recent advancements in multimodal large language models (MLLMs) have\nbroadened the scope of vision-language tasks, excelling in applications like\nimage captioning and interactive question-answering. However, these models\nstruggle with accurately processing visual data, particularly in tasks\nrequiring precise object recognition and fine visual details. Stringent token\nlimits often result in the omission of critical information, hampering\nperformance. To address these limitations, we introduce \\SysName, a novel\nvisual prompting mechanism designed to enhance MLLM performance while\npreserving essential visual details within token limits. \\SysName features\nthree key innovations: a prompt-aware strategy that dynamically highlights\nrelevant image regions, a spatial-preserving orchestration schema that\nmaintains object integrity, and a budget-aware prompting method that balances\nglobal context with crucial visual details. Comprehensive evaluations across\nmultiple datasets demonstrate that \\SysName consistently outperforms baseline\nmethods, achieving up to a $26.9\\%$ improvement in accuracy while significantly\nreducing token consumption.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00742v1",
    "published_date": "2025-04-30 02:51:10 UTC",
    "updated_date": "2025-04-30 02:51:10 UTC"
  },
  {
    "arxiv_id": "2504.21261v1",
    "title": "Multi-Domain Causal Discovery in Bijective Causal Models",
    "authors": [
      "Kasra Jalaldoust",
      "Saber Salehkaleybar",
      "Negar Kiyavash"
    ],
    "abstract": "We consider the problem of causal discovery (a.k.a., causal structure\nlearning) in a multi-domain setting. We assume that the causal functions are\ninvariant across the domains, while the distribution of the exogenous noise may\nvary. Under causal sufficiency (i.e., no confounders exist), we show that the\ncausal diagram can be discovered under less restrictive functional assumptions\ncompared to previous work. What enables causal discovery in this setting is\nbijective generation mechanisms (BGM), which ensures that the functional\nrelation between the exogenous noise $E$ and the endogenous variable $Y$ is\nbijective and differentiable in both directions at every level of the cause\nvariable $X = x$. BGM generalizes a variety of models including additive noise\nmodel, LiNGAM, post-nonlinear model, and location-scale noise model. Further,\nwe derive a statistical test to find the parents set of the target variable.\nExperiments on various synthetic and real-world datasets validate our\ntheoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of Causal Learning and Reasoning (CLeaR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21261v1",
    "published_date": "2025-04-30 02:30:10 UTC",
    "updated_date": "2025-04-30 02:30:10 UTC"
  },
  {
    "arxiv_id": "2505.00737v1",
    "title": "A Survey on 3D Reconstruction Techniques in Plant Phenotyping: From Classical Methods to Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and Beyond",
    "authors": [
      "Jiajia Li",
      "Xinda Qi",
      "Seyed Hamidreza Nabaei",
      "Meiqi Liu",
      "Dong Chen",
      "Xin Zhang",
      "Xunyuan Yin",
      "Zhaojian Li"
    ],
    "abstract": "Plant phenotyping plays a pivotal role in understanding plant traits and\ntheir interactions with the environment, making it crucial for advancing\nprecision agriculture and crop improvement. 3D reconstruction technologies have\nemerged as powerful tools for capturing detailed plant morphology and\nstructure, offering significant potential for accurate and automated\nphenotyping. This paper provides a comprehensive review of the 3D\nreconstruction techniques for plant phenotyping, covering classical\nreconstruction methods, emerging Neural Radiance Fields (NeRF), and the novel\n3D Gaussian Splatting (3DGS) approach. Classical methods, which often rely on\nhigh-resolution sensors, are widely adopted due to their simplicity and\nflexibility in representing plant structures. However, they face challenges\nsuch as data density, noise, and scalability. NeRF, a recent advancement,\nenables high-quality, photorealistic 3D reconstructions from sparse viewpoints,\nbut its computational cost and applicability in outdoor environments remain\nareas of active research. The emerging 3DGS technique introduces a new paradigm\nin reconstructing plant structures by representing geometry through Gaussian\nprimitives, offering potential benefits in both efficiency and scalability. We\nreview the methodologies, applications, and performance of these approaches in\nplant phenotyping and discuss their respective strengths, limitations, and\nfuture prospects (https://github.com/JiajiaLi04/3D-Reconstruction-Plants).\nThrough this review, we aim to provide insights into how these diverse 3D\nreconstruction techniques can be effectively leveraged for automated and\nhigh-throughput plant phenotyping, contributing to the next generation of\nagricultural technology.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "17 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.00737v1",
    "published_date": "2025-04-30 02:04:23 UTC",
    "updated_date": "2025-04-30 02:04:23 UTC"
  },
  {
    "arxiv_id": "2504.21239v1",
    "title": "Memorization and Knowledge Injection in Gated LLMs",
    "authors": [
      "Xu Pan",
      "Ely Hahami",
      "Zechen Zhang",
      "Haim Sompolinsky"
    ],
    "abstract": "Large Language Models (LLMs) currently struggle to sequentially add new\nmemories and integrate new knowledge. These limitations contrast with the human\nability to continuously learn from new experiences and acquire knowledge\nthroughout life. Most existing approaches add memories either through large\ncontext windows or external memory buffers (e.g., Retrieval-Augmented\nGeneration), and studies on knowledge injection rarely test scenarios\nresembling everyday life events. In this work, we introduce a continual\nlearning framework, Memory Embedded in Gated LLMs (MEGa), which injects event\nmemories directly into the weights of LLMs. Each memory is stored in a\ndedicated set of gated low-rank weights. During inference, a gating mechanism\nactivates relevant memory weights by matching query embeddings to stored memory\nembeddings. This enables the model to both recall entire memories and answer\nrelated questions. On two datasets - fictional characters and Wikipedia events\n- MEGa outperforms baseline approaches in mitigating catastrophic forgetting.\nOur model draws inspiration from the complementary memory system of the human\nbrain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21239v1",
    "published_date": "2025-04-30 00:28:32 UTC",
    "updated_date": "2025-04-30 00:28:32 UTC"
  },
  {
    "arxiv_id": "2504.21235v1",
    "title": "Efficient Quantum-Safe Homomorphic Encryption for Quantum Computer Programs",
    "authors": [
      "Ben Goertzel"
    ],
    "abstract": "We present a lattice-based scheme for homomorphic evaluation of quantum\nprograms and proofs that remains secure against quantum adversaries. Classical\nhomomorphic encryption is lifted to the quantum setting by replacing\ncomposite-order groups with Module Learning-With-Errors (MLWE) lattices and by\ngeneralizing polynomial functors to bounded natural super functors (BNSFs). A\nsecret depolarizing BNSF mask hides amplitudes, while each quantum state is\nstored as an MLWE ciphertext pair. We formalize security with the qIND-CPA game\nthat allows coherent access to the encryption oracle and give a four-hybrid\nreduction to decisional MLWE.\n  The design also covers practical issues usually left open. A typed QC-bridge\nkeeps classical bits produced by measurements encrypted yet still usable as\ncontrols, with weak-measurement semantics for expectation-value workloads.\nEncrypted Pauli twirls add circuit privacy. If a fixed knowledge base is\nneeded, its axioms are shipped as MLWE \"capsules\"; the evaluator can use them\nbut cannot read them. A rho-calculus driver schedules encrypted tasks across\nseveral QPUs and records an auditable trace on an RChain-style ledger.\n  Performance analysis shows that the extra lattice arithmetic fits inside\ntoday's QPU idle windows: a 100-qubit, depth-10^3 teleportation-based proof\nruns in about 10 ms, the public key (seed only) is 32 bytes, and even a\nCCA-level key stays below 300 kB. A photonic Dirac-3 prototype that executes\nhomomorphic teleportation plus knowledge-base-relative amplitude checks appears\nfeasible with current hardware. These results indicate that fully homomorphic,\nknowledge-base-aware quantum reasoning is compatible with near-term quantum\nclouds and standard post-quantum security assumptions.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21235v1",
    "published_date": "2025-04-30 00:08:43 UTC",
    "updated_date": "2025-04-30 00:08:43 UTC"
  }
]