{
  "date": "2024-09-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-27 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，特别是大型语言模型 (LLM) 在生成、安全和多模态应用的创新性进展，令人印象深刻的是多模态 LLM 和强化学习方法的应用潜力，以及著名学者如 John Wright 和 John Langford 参与的量子算法和预训练优化论文；这些工作突显了 AI 在实际领域的潜力，如医疗和机器人。\n\n下面，我将挑选并讨论几篇重要的、具有话题度的论文，先从 AI 和 LLM 相关的高影响力文章开始，然后快速概述其他领域的关键贡献。限于篇幅，我会优先选取创新性强或有名学者参与的论文，并简要列出标题（中文 + 英文），聚焦核心学术术语和主要发现。\n\n### AI 和 LLM 创新\n- **论文2: Artificial-Intelligence Generated Code Considered Harmful: A Road Map for Secure and High-Quality Code Generation**  \n  这篇论文由 Iulian Neamtiu 等作者探讨 LLM 生成代码的安全性问题。主要贡献是比较 LLM 生成代码与人工代码在安全性和质量上的差异，发现 LLM 代码易受缓冲区溢出等漏洞影响，并提出反馈循环优化策略。发现显示，LLM 虽能生成正确功能，但缺乏防御性编程，导致更高的崩溃风险。\n\n- **论文5: Revisiting the Superficial Alignment Hypothesis**  \n  作者 Mohit Raghavendra 等重新审视语言模型的预训练和微调，核心发现是微调性能随示例数量呈幂律增长，尤其在数学推理和多跳推理任务上。论文挑战了“浅层对齐”假设，证明微调能显著提升模型在新知识整合能力。\n\n- **论文15: DANA: Domain-Aware Neurosymbolic Agents for Consistency and Accuracy**  \n  这篇工作引入 DANA 架构，结合领域知识和神经符号方法，提高 LLM 在复杂任务中的一致性和准确性。作者如 Christopher Nguyen 等发现，该方法在 FinanceBench 上达到 90% 准确率，远超传统 LLM 系统，适用于半导体等物理行业。\n\n- **论文25: On the Inductive Bias of Stacking Towards Improving Reasoning**  \n  John Langford 等学者参与，探讨渐进堆叠训练策略的核心贡献是提出 MIDAS 算法，能加速语言模型训练并提升推理能力。发现显示，堆叠方法在阅读理解和数学任务上表现出更好的归纳偏差，即使在类似困惑度下。\n\n- **论文46: Fairness-aware Multiobjective Evolutionary Learning**  \n  作者 Qingquan Zhang 等提出一种动态多目标进化学习框架，能在训练中自适应选择公平性指标。关键发现是，该方法在多个基准数据集上显著提升模型准确性和公平性，即使只优化少数指标。\n\n这些 LLM 相关论文突出了模型的安全、推理和公平性优化，体现了 AI 领域的热点趋势，尤其在实际应用中（如代码生成和决策系统）。\n\n### 医疗和生物应用\n- **论文1: Semi-Supervised Bone Marrow Lesion Detection from Knee MRI Segmentation Using Mask Inpainting Models**  \n  作者 Jonghye Woo 等提出半监督异常检测方法，使用 3D 分割和掩码修复模型检测膝关节骨髓病变。核心贡献是提升 Dice 分数和 IoU，在高分辨率 MRI 上性能提高两倍以上，适用于骨关节炎诊断。\n\n- **论文3: A GEN AI Framework for Medical Note Generation**  \n  这篇论文介绍 MediNotes 框架，使用 LLM 和 RAG 生成医疗笔记。作者发现，该框架显著提高 ACI-BENCH 数据集的准确性和效率，减少医生行政负担。\n\n- **论文16: Differential privacy enables fair and accurate AI-based analysis of speech disorders while protecting patient data**  \n  作者 Seung Hee Yang 等首次探索差分隐私在语音病理分析中的应用。发现高隐私水平下准确率仅下降 3.85%，并减少性别偏差，促进语音障碍检测的公平性。\n\n这些医疗论文强调 AI 在隐私保护和诊断中的潜力，相关方法如差分隐私和生成框架可能推动临床应用。\n\n### 强化学习和优化\n- **论文10: Sequencing the Neurome: Towards Scalable Exact Parameter Reconstruction of Black-Box Neural Networks**  \n  作者 Hod Lipson 等提出量子算法重建黑箱神经网络参数。核心发现是，该方法能处理百万级参数网络，实现精确重建，适用于安全和可解释性研究。\n\n- **论文51: Autoregressive Policy Optimization for Constrained Allocation Tasks**  \n  作者 Maximilian Bernhard 等开发自回归策略优化框架，用于资源分配任务。发现该方法在组合优化中显著提升性能，适用于投资和负载分配。\n\n### 其他领域快速掠过\n今天还有许多论文涉及计算机视觉、量子计算和机器人等领域，但它们相对较基础或特定，我仅快速概述几篇代表性工作：\n- **论文7: Multimodal Pragmatic Jailbreak on Text-to-image Models**（多模态语用越狱攻击）：作者 Philip Torr 等发现 T2I 模型易受多模态越狱攻击，生成率达 74%，并评估过滤器无效性。\n- **论文12: Multi-modal Cross-domain Self-supervised Pre-training for fMRI and EEG Fusion**（多模态跨域自监督预训练）：作者 Yu Zhang 等提出 MCSP 模型，提升脑成像分类性能。\n- **论文20: PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation**（物理基础图像到视频生成）：作者 Shenlong Wang 等开发 PhysGen 框架，实现物理真实视频生成。\n- **论文27: Unconditional stability of a recurrent neural circuit implementing divisive normalization**（实现除法归一化的循环神经电路无条件稳定性）：作者 David J. Heeger 等证明 ORGaNICs 电路的稳定性，提升神经网络训练效率。\n- **论文101: BoT-Drive: Hierarchical Behavior and Trajectory Planning for Autonomous Driving using POMDPs**（基于 POMDP 的分层行为和轨迹规划）：作者 Chunxiao Liu 等提出 BoT-Drive 算法，提升自动驾驶在不确定环境下的鲁棒性。\n\n其余论文，如量子算法（论文58）、文本生成（论文24）等，虽然有贡献，但未涉及重大突破，故从简。总体而言，今天的 arXiv 论文展示了 AI 在多领域的创新潜力，值得关注 LLM 的安全和应用进展。明天我们继续追踪！",
  "papers": [
    {
      "arxiv_id": "2409.19185v1",
      "title": "Semi-Supervised Bone Marrow Lesion Detection from Knee MRI Segmentation Using Mask Inpainting Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shihua Qin",
        "Ming Zhang",
        "Juan Shan",
        "Taehoon Shin",
        "Jonghye Woo",
        "Fangxu Xing"
      ],
      "abstract": "Bone marrow lesions (BMLs) are critical indicators of knee osteoarthritis\n(OA). Since they often appear as small, irregular structures with\nindistinguishable edges in knee magnetic resonance images (MRIs), effective\ndetection of BMLs in MRI is vital for OA diagnosis and treatment. This paper\nproposes a semi-supervised local anomaly detection method using mask inpainting\nmodels for identification of BMLs in high-resolution knee MRI, effectively\nintegrating a 3D femur bone segmentation model, a large mask inpainting model,\nand a series of post-processing techniques. The method was evaluated using MRIs\nat various resolutions from a subset of the public Osteoarthritis Initiative\ndatabase. Dice score, Intersection over Union (IoU), and pixel-level\nsensitivity, specificity, and accuracy showed an advantage over the\nmultiresolution knowledge distillation method-a state-of-the-art global anomaly\ndetection method. Especially, segmentation performance is enhanced on\nhigher-resolution images, achieving an over two times performance increase on\nthe Dice score and the IoU score at a 448x448 resolution level. We also\ndemonstrate that with increasing size of the BML region, both the Dice and IoU\nscores improve as the proportion of distinguishable boundary decreases. The\nidentified BML masks can serve as markers for downstream tasks such as\nsegmentation and classification. The proposed method has shown a potential in\nimproving BML detection, laying a foundation for further advances in\nimaging-based OA research.",
      "tldr_zh": "本论文提出了一种半监督局部异常检测方法，用于从膝关节MRI图像中检测骨髓病变（BMLs），以辅助膝关节骨关节炎（OA）的诊断。该方法整合了3D femur bone segmentation模型、大型mask inpainting models以及一系列后处理技术，通过掩码修复来识别BMLs的不规则结构。在Osteoarthritis Initiative数据库的子集中进行评估，结果显示该方法在高分辨率图像（如448x448）上显著优于多分辨率知识蒸馏方法，Dice score和IoU score提高了两倍以上，且BML区域越大，检测性能越好。该方法可为下游任务如分割和分类提供标记，并为基于图像的OA研究奠定基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages, 3 figures, submitted to SPIE Conference on Image Processing",
      "pdf_url": "http://arxiv.org/pdf/2409.19185v1",
      "published_date": "2024-09-27 23:47:47 UTC",
      "updated_date": "2024-09-27 23:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:25:59.381996"
    },
    {
      "arxiv_id": "2409.19182v2",
      "title": "Artificial-Intelligence Generated Code Considered Harmful: A Road Map for Secure and High-Quality Code Generation",
      "title_zh": "人工智能生成的代码被认为是有害的：一个安全和高品质代码生成的路线图",
      "authors": [
        "Chun Jie Chong",
        "Zhihao Yao",
        "Iulian Neamtiu"
      ],
      "abstract": "Generating code via a LLM (rather than writing code from scratch), has\nexploded in popularity. However, the security implications of LLM-generated\ncode are still unknown. We performed a study that compared the security and\nquality of human-written code with that of LLM-generated code, for a wide range\nof programming tasks, including data structures, algorithms, cryptographic\nroutines, and LeetCode questions. To assess code security we used unit testing,\nfuzzing, and static analysis. For code quality, we focused on complexity and\nsize. We found that LLM can generate incorrect code that fails to implement the\nrequired functionality, especially for more complicated tasks; such errors can\nbe subtle. For example, for the cryptographic algorithm SHA1, LLM generated an\nincorrect implementation that nevertheless compiles. In cases where its\nfunctionality was correct, we found that LLM-generated code is less secure,\nprimarily due to the lack of defensive programming constructs, which invites a\nhost of security issues such as buffer overflows or integer overflows. Fuzzing\nhas revealed that LLM-generated code is more prone to hangs and crashes than\nhuman-written code. Quality-wise, we found that LLM generates bare-bones code\nthat lacks defensive programming constructs, and is typically more complex (per\nline of code) compared to human-written code. Next, we constructed a feedback\nloop that asked the LLM to re-generate the code and eliminate the found issues\n(e.g., malloc overflow, array index out of bounds, null dereferences). We found\nthat the LLM fails to eliminate such issues consistently: while succeeding in\nsome cases, we found instances where the re-generated, supposedly more secure\ncode, contains new issues; we also found that upon prompting, LLM can introduce\nissues in files that were issues-free before prompting.",
      "tldr_zh": "本文研究了 LLM 生成代码的安全性和质量问题，通过比较人类编写代码与 LLM 生成代码（应用于数据结构、算法、加密例程和 LeetCode 问题），并使用单元测试、fuzzing 和 static analysis 进行评估。结果显示，LLM 生成代码在复杂任务中功能错误率高，即使正确也更易出现安全漏洞，如缓冲区溢出和整数溢出，且代码复杂度较高且缺少防御性编程结构。论文进一步构建反馈循环让 LLM 重新生成代码修复问题，但发现 LLM 无法可靠消除这些问题，有时还会引入新漏洞。最终，论文提供了确保 AI 生成代码安全和高质量的路线图（Road Map）。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19182v2",
      "published_date": "2024-09-27 23:41:51 UTC",
      "updated_date": "2024-10-12 03:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:26:10.502197"
    },
    {
      "arxiv_id": "2410.01841v1",
      "title": "A GEN AI Framework for Medical Note Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Yi Leong",
        "Yi Fan Gao",
        "Shuai Ji",
        "Bora Kalaycioglu",
        "Uktu Pamuksuz"
      ],
      "abstract": "The increasing administrative burden of medical documentation, particularly\nthrough Electronic Health Records (EHR), significantly reduces the time\navailable for direct patient care and contributes to physician burnout. To\naddress this issue, we propose MediNotes, an advanced generative AI framework\ndesigned to automate the creation of SOAP (Subjective, Objective, Assessment,\nPlan) notes from medical conversations. MediNotes integrates Large Language\nModels (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech\nRecognition (ASR) to capture and process both text and voice inputs in real\ntime or from recorded audio, generating structured and contextually accurate\nmedical notes. The framework also incorporates advanced techniques like\nQuantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning\n(PEFT) for efficient model fine-tuning in resource-constrained environments.\nAdditionally, MediNotes offers a query-based retrieval system, allowing\nhealthcare providers and patients to access relevant medical information\nquickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate\nthat MediNotes significantly improves the accuracy, efficiency, and usability\nof automated medical documentation, offering a robust solution to reduce the\nadministrative burden on healthcare professionals while improving the quality\nof clinical workflows.",
      "tldr_zh": "本研究提出MediNotes，一个先进的生成AI框架，用于从医疗对话自动生成SOAP（Subjective, Objective, Assessment, Plan）笔记，以缓解电子健康记录（EHR）带来的行政负担和医生烧尽问题。框架整合Large Language Models (LLMs)、Retrieval-Augmented Generation (RAG)和Automatic Speech Recognition (ASR)，支持实时或录制音频的文本和语音处理，并采用Quantized Low-Rank Adaptation (QLoRA)和Parameter-Efficient Fine-Tuning (PEFT)技术进行高效模型微调，同时提供基于查询的检索系统以快速访问医疗信息。使用ACI-BENCH数据集的评估显示，MediNotes显著提高了医疗文档的准确性、效率和可用性，为优化临床工作流程并减轻医疗专业人员负担提供了可靠解决方案。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "8 Figures, 7 page, IEEE standard research paper",
      "pdf_url": "http://arxiv.org/pdf/2410.01841v1",
      "published_date": "2024-09-27 23:05:02 UTC",
      "updated_date": "2024-09-27 23:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:26:22.208444"
    },
    {
      "arxiv_id": "2409.19173v1",
      "title": "HM3: Heterogeneous Multi-Class Model Merging",
      "title_zh": "HM3：异构多类模型合并",
      "authors": [
        "Stefan Hackmann"
      ],
      "abstract": "Foundation language model deployments often include auxiliary guard-rail\nmodels to filter or classify text, detecting jailbreak attempts, biased or\ntoxic output, or ensuring topic adherence. These additional models increase the\ncomplexity and cost of model inference, especially since many are also large\nlanguage models. To address this issue, we explore training-free model merging\ntechniques to consolidate these models into a single, multi-functional model.\nWe propose Heterogeneous Multi-Class Model Merging (HM3) as a simple technique\nfor merging multi-class classifiers with heterogeneous label spaces. Unlike\nparameter-efficient fine-tuning techniques like LoRA, which require extensive\ntraining and add complexity during inference, recent advancements allow models\nto be merged in a training-free manner. We report promising results for merging\nBERT-based guard models, some of which attain an average F1-score higher than\nthe source models while reducing the inference time by up to 44%. We introduce\nself-merging to assess the impact of reduced task-vector density, finding that\nthe more poorly performing hate speech classifier benefits from self-merging\nwhile higher-performing classifiers do not, which raises questions about using\ntask vector reduction for model tuning.",
      "tldr_zh": "该研究针对基础语言模型部署中辅助守卫模型（如用于检测越狱、偏见或主题一致性的模型）带来的复杂性和成本问题，提出了 Heterogeneous Multi-Class Model Merging (HM3) 技术，这是一种无需训练的简单方法，用于合并具有异构标签空间的多类分类器。相比于 LoRA 等参数高效微调技术，HM3 避免了额外训练和推理复杂性，在实验中合并 BERT-based 守卫模型后，平均 F1-score 高于源模型，同时将推理时间减少高达 44%。此外，通过引入 self-merging 来评估任务向量密度的影响，发现表现较差的仇恨言论分类器从中受益，而高性能分类器则无显著改善，这引发了对任务向量减少在模型调优中的潜在应用的探讨。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19173v1",
      "published_date": "2024-09-27 22:42:45 UTC",
      "updated_date": "2024-09-27 22:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:26:34.374683"
    },
    {
      "arxiv_id": "2410.03717v1",
      "title": "Revisiting the Superficial Alignment Hypothesis",
      "title_zh": "重新审视表层对齐假设",
      "authors": [
        "Mohit Raghavendra",
        "Vaskar Nath",
        "Sean Hendryx"
      ],
      "abstract": "The Superficial Alignment Hypothesis posits that almost all of a language\nmodel's abilities and knowledge are learned during pre-training, while\npost-training is about giving a model the right style and format. We re-examine\nthese claims by empirically studying the scaling behavior of post-training with\nincreasing finetuning examples and evaluating them using objective\ntask-specific standardized benchmarks. Through experiments with the Llama-3,\nMistral, and Llama-2 model families of multiple sizes, we observe that, similar\nto the pre-training scaling laws, post-training task performance scales as a\npower law against the number of finetuning examples. This power law\nrelationship holds across a broad array of capabilities, including mathematical\nreasoning, coding, instruction following, and multihop-reasoning. In addition,\nfor tasks like math and multihop reasoning, we observe that a handful of\nexamples merely align the model stylistically but do not saturate performance\non the benchmarks. Model performance is instead correlated with its reasoning\nability and it improves significantly with more examples, illustrating the need\nfor holistic evaluation programs leveraging objective benchmarks in addition to\nmeasurement of alignment to human preferences. We also observe that language\nmodels are not necessarily limited to using knowledge learned during\npre-training. With appropriate post-training, a model's ability to integrate\nnew knowledge greatly improves on downstream tasks like multihop\nquestion-answering. Taken together, these results shed new light on the\nSuperficial Alignment Hypothesis, suggesting that it is, at best, an\nover-simplification.",
      "tldr_zh": "本研究重新审视了 Superficial Alignment Hypothesis，该假设认为语言模型的大部分能力在 pre-training 中已习得，而 post-training 仅用于调整风格和格式。通过实验分析 Llama-3、Mistral 和 Llama-2 模型家族，发现 post-training 性能也遵循 power law，与 finetuning 示例数量呈幂律关系，适用于数学推理、编码、指令遵循和多跳推理等能力。结果显示，少数示例仅实现风格对齐，而更多示例可显著提升模型性能和新知识整合；因此，该假设可能过于简化，强调需要使用客观基准进行全面评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03717v1",
      "published_date": "2024-09-27 22:14:10 UTC",
      "updated_date": "2024-09-27 22:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:26:46.178151"
    },
    {
      "arxiv_id": "2409.19158v1",
      "title": "bnRep: A repository of Bayesian networks from the academic literature",
      "title_zh": "翻译失败",
      "authors": [
        "Manuele Leonelli"
      ],
      "abstract": "Bayesian networks (BNs) are widely used for modeling complex systems with\nuncertainty, yet repositories of pre-built BNs remain limited. This paper\nintroduces bnRep, an open-source R package offering a comprehensive collection\nof documented BNs, facilitating benchmarking, replicability, and education.\nWith over 200 networks from academic publications, bnRep integrates seamlessly\nwith bnlearn and other R packages, providing users with interactive tools for\nnetwork exploration.",
      "tldr_zh": "本研究指出，虽然Bayesian networks (BNs)广泛用于建模不确定性的复杂系统，但现有预建BNs仓库有限。为此，论文引入bnRep，这是一个开源R包，收集了超过200个来自学术文献的文档化BNs，以支持基准测试(benchmarking)、可重复性(replicability)和教育。bnRep无缝整合了bnlearn和其他R包，提供交互式工具用于网络探索，从而提升了BNs的研究和应用效率。",
      "categories": [
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19158v1",
      "published_date": "2024-09-27 21:50:50 UTC",
      "updated_date": "2024-09-27 21:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:26:57.970185"
    },
    {
      "arxiv_id": "2409.19149v1",
      "title": "Multimodal Pragmatic Jailbreak on Text-to-image Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Liu",
        "Zhixin Lai",
        "Gengyuan Zhang",
        "Philip Torr",
        "Vera Demberg",
        "Volker Tresp",
        "Jindong Gu"
      ],
      "abstract": "Diffusion models have recently achieved remarkable advancements in terms of\nimage quality and fidelity to textual prompts. Concurrently, the safety of such\ngenerative models has become an area of growing concern. This work introduces a\nnovel type of jailbreak, which triggers T2I models to generate the image with\nvisual text, where the image and the text, although considered to be safe in\nisolation, combine to form unsafe content. To systematically explore this\nphenomenon, we propose a dataset to evaluate the current diffusion-based\ntext-to-image (T2I) models under such jailbreak. We benchmark nine\nrepresentative T2I models, including two close-source commercial models.\nExperimental results reveal a concerning tendency to produce unsafe content:\nall tested models suffer from such type of jailbreak, with rates of unsafe\ngeneration ranging from 8\\% to 74\\%. In real-world scenarios, various filters\nsuch as keyword blocklists, customized prompt filters, and NSFW image filters,\nare commonly employed to mitigate these risks. We evaluate the effectiveness of\nsuch filters against our jailbreak and found that, while current classifiers\nmay be effective for single modality detection, they fail to work against our\njailbreak. Our work provides a foundation for further development towards more\nsecure and reliable T2I models.",
      "tldr_zh": "这篇论文引入了一种新型的多模态实用越狱攻击（Multimodal Pragmatic Jailbreak），它让文本到图像（T2I）模型生成包含视觉文本的图像，这些图像和文本单独看是安全的，但组合后形成不安全内容。为了系统评估这一问题，研究者提出一个数据集，并对九个代表性T2I模型（包括两个闭源商业模型）进行基准测试，结果显示所有模型都易受攻击，不安全生成率从8%到74%。实验还评估了现有过滤器如关键词黑名单、自定义提示过滤器和NSFW图像过滤器，发现这些过滤器对单模态检测有效，但对这种越狱攻击无效。该工作为开发更安全可靠的T2I模型奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19149v1",
      "published_date": "2024-09-27 21:23:46 UTC",
      "updated_date": "2024-09-27 21:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:27:11.984059"
    },
    {
      "arxiv_id": "2409.19146v1",
      "title": "Bound Tightening Network for Robust Crowd Counting",
      "title_zh": "翻译失败",
      "authors": [
        "Qiming Wu"
      ],
      "abstract": "Crowd Counting is a fundamental topic, aiming to estimate the number of\nindividuals in the crowded images or videos fed from surveillance cameras.\nRecent works focus on improving counting accuracy, while ignoring the certified\nrobustness of counting models. In this paper, we propose a novel Bound\nTightening Network (BTN) for Robust Crowd Counting. It consists of three parts:\nbase model, smooth regularization module and certify bound module. The core\nidea is to propagate the interval bound through the base model (certify bound\nmodule) and utilize the layer weights (smooth regularization module) to guide\nthe network learning. Experiments on different benchmark datasets for counting\ndemonstrate the effectiveness and efficiency of BTN.",
      "tldr_zh": "这篇论文提出了一种名为Bound Tightening Network (BTN)的框架，用于提升人群计数的鲁棒性，旨在解决现有模型忽略认证鲁棒性的问题。BTN由基模型（base model）、平滑正则化模块（smooth regularization module）和认证边界模块（certify bound module）组成，其核心思想是通过传播区间边界并利用层权重指导网络学习，从而提高计数准确性和可靠性。在多个基准数据集上的实验证明了BTN的有效性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work was done 2 years ago",
      "pdf_url": "http://arxiv.org/pdf/2409.19146v1",
      "published_date": "2024-09-27 21:18:31 UTC",
      "updated_date": "2024-09-27 21:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:27:22.079948"
    },
    {
      "arxiv_id": "2409.19142v1",
      "title": "TTT4Rec: A Test-Time Training Approach for Rapid Adaption in Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoqi Yang",
        "Yanan Wang",
        "Yong Ge"
      ],
      "abstract": "Sequential recommendation tasks, which aim to predict the next item a user\nwill interact with, typically rely on models trained solely on historical data.\nHowever, in real-world scenarios, user behavior can fluctuate in the long\ninteraction sequences, and training data may be limited to model this dynamics.\nTo address this, Test-Time Training (TTT) offers a novel approach by using\nself-supervised learning during inference to dynamically update model\nparameters. This allows the model to adapt to new user interactions in\nreal-time, leading to more accurate recommendations. In this paper, we propose\nTTT4Rec, a sequential recommendation framework that integrates TTT to better\ncapture dynamic user behavior. By continuously updating model parameters during\ninference, TTT4Rec is particularly effective in scenarios where user\ninteraction sequences are long, training data is limited, or user behavior is\nhighly variable. We evaluate TTT4Rec on three widely-used recommendation\ndatasets, demonstrating that it achieves performance on par with or exceeding\nstate-of-the-art models. The codes are available at\nhttps://github.com/ZhaoqiZachYang/TTT4Rec.",
      "tldr_zh": "本论文提出 TTT4Rec，一种基于 Test-Time Training (TTT) 的框架，用于顺序推荐任务中快速适应动态用户行为。TTT4Rec 通过在推理过程中使用自监督学习动态更新模型参数，解决了传统模型在长交互序列、训练数据有限或用户行为多变场景下的局限性，从而实现实时更准确的推荐预测。在三个常用数据集上的实验表明，TTT4Rec 的性能达到或超过了最先进模型的水平，代码已在 GitHub 上开源。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19142v1",
      "published_date": "2024-09-27 21:14:23 UTC",
      "updated_date": "2024-09-27 21:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:27:33.739756"
    },
    {
      "arxiv_id": "2409.19138v1",
      "title": "Sequencing the Neurome: Towards Scalable Exact Parameter Reconstruction of Black-Box Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Judah Goldfeder",
        "Quinten Roets",
        "Gabe Guo",
        "John Wright",
        "Hod Lipson"
      ],
      "abstract": "Inferring the exact parameters of a neural network with only query access is\nan NP-Hard problem, with few practical existing algorithms. Solutions would\nhave major implications for security, verification, interpretability, and\nunderstanding biological networks. The key challenges are the massive parameter\nspace, and complex non-linear relationships between neurons. We resolve these\nchallenges using two insights. First, we observe that almost all networks used\nin practice are produced by random initialization and first order optimization,\nan inductive bias that drastically reduces the practical parameter space.\nSecond, we present a novel query generation algorithm that produces maximally\ninformative samples, letting us untangle the non-linear relationships\nefficiently. We demonstrate reconstruction of a hidden network containing over\n1.5 million parameters, and of one 7 layers deep, the largest and deepest\nreconstructions to date, with max parameter difference less than 0.0001, and\nillustrate robustness and scalability across a variety of architectures,\ndatasets, and training procedures.",
      "tldr_zh": "该研究解决了一个NP-Hard问题，即仅通过查询访问推断黑箱神经网络的精确参数，这对安全、验证和可解释性具有重要意义。作者利用两个关键洞见：一是实际神经网络通常通过随机初始化和一阶优化生成，从而显著缩小参数空间；二是提出一种新型查询生成算法，能产生最大信息量的样本，以高效处理非线性关系。实验结果显示，该方法成功重建了一个超过150万参数的隐藏网络以及一个7层深的网络，最大参数差异小于0.0001，并展示了在各种架构、数据集和训练过程中的鲁棒性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.IT",
        "cs.NE",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19138v1",
      "published_date": "2024-09-27 21:02:04 UTC",
      "updated_date": "2024-09-27 21:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:27:45.859967"
    },
    {
      "arxiv_id": "2409.19136v1",
      "title": "Kinematic Detection of Anomalies in Human Trajectory Data",
      "title_zh": "翻译失败",
      "authors": [
        "Lance Kennedy",
        "Andreas Züfle"
      ],
      "abstract": "Historically, much of the research in understanding, modeling, and mining\nhuman trajectory data has focused on where an individual stays. Thus, the focus\nof existing research has been on where a user goes. On the other hand, the\nstudy of how a user moves between locations has great potential for new\nresearch opportunities. Kinematic features describe how an individual moves\nbetween locations and can be used for tasks such as identification of\nindividuals or anomaly detection. Unfortunately, data availability and quality\nchallenges make kinematic trajectory mining difficult. In this paper, we\nleverage the Geolife dataset of human trajectories to investigate the viability\nof using kinematic features to identify individuals and detect anomalies. We\nshow that humans have an individual \"kinematic profile\" which can be used as a\nstrong signal to identify individual humans. We experimentally show that, for\nthe two use-cases of individual identification and anomaly detection, simple\nkinematic features fed to standard classification and anomaly detection\nalgorithms significantly improve results.",
      "tldr_zh": "本论文探讨了人类轨迹数据中异常检测问题，强调传统研究多关注个体停留位置（where），而忽略了移动方式（how）。作者利用运动学特征（kinematic features）从 Geolife 数据集中进行分析，证明每个人拥有独特的“运动学配置文件”（kinematic profile），可作为个体识别的强信号。实验结果显示，将简单运动学特征输入标准分类和异常检测算法，能显著提升个体识别和异常检测的性能。总的来说，该研究为基于运动学特征的轨迹挖掘提供了新方法和实证支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19136v1",
      "published_date": "2024-09-27 20:53:11 UTC",
      "updated_date": "2024-09-27 20:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:27:58.402266"
    },
    {
      "arxiv_id": "2409.19130v1",
      "title": "Multi-modal Cross-domain Self-supervised Pre-training for fMRI and EEG Fusion",
      "title_zh": "多模态跨域自监督预训练用于 fMRI 和 EEG 融合",
      "authors": [
        "Xinxu Wei",
        "Kanhao Zhao",
        "Yong Jiao",
        "Nancy B. Carlisle",
        "Hua Xie",
        "Gregory A. Fonzo",
        "Yu Zhang"
      ],
      "abstract": "Neuroimaging techniques including functional magnetic resonance imaging\n(fMRI) and electroencephalogram (EEG) have shown promise in detecting\nfunctional abnormalities in various brain disorders. However, existing studies\noften focus on a single domain or modality, neglecting the valuable\ncomplementary information offered by multiple domains from both fMRI and EEG,\nwhich is crucial for a comprehensive representation of disorder pathology. This\nlimitation poses a challenge in effectively leveraging the synergistic\ninformation derived from these modalities. To address this, we propose a\nMulti-modal Cross-domain Self-supervised Pre-training Model (MCSP), a novel\napproach that leverages self-supervised learning to synergize multi-modal\ninformation across spatial, temporal, and spectral domains. Our model employs\ncross-domain self-supervised loss that bridges domain differences by\nimplementing domain-specific data augmentation and contrastive loss, enhancing\nfeature discrimination. Furthermore, MCSP introduces cross-modal\nself-supervised loss to capitalize on the complementary information of fMRI and\nEEG, facilitating knowledge distillation within domains and maximizing\ncross-modal feature convergence. We constructed a large-scale pre-training\ndataset and pretrained MCSP model by leveraging proposed self-supervised\nparadigms to fully harness multimodal neuroimaging data. Through comprehensive\nexperiments, we have demonstrated the superior performance and generalizability\nof our model on multiple classification tasks. Our study contributes a\nsignificant advancement in the fusion of fMRI and EEG, marking a novel\nintegration of cross-domain features, which enriches the existing landscape of\nneuroimaging research, particularly within the context of mental disorder\nstudies.",
      "tldr_zh": "本文提出了一种多模态跨域自监督预训练模型（MCSP），旨在融合 fMRI 和 EEG 的互补信息，解决现有神经影像研究中单一模态局限的问题。MCSP 通过跨域自监督损失（cross-domain self-supervised loss）和跨模态自监督损失（cross-modal self-supervised loss），结合域特定数据增强和对比损失，实现空间、时间和频谱域特征的桥接与融合，并构建了大规模预训练数据集。实验结果表明，该模型在多个分类任务上表现出优越性能和泛化能力，为 fMRI 和 EEG 在精神障碍研究的整合提供了重要进展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19130v1",
      "published_date": "2024-09-27 20:25:17 UTC",
      "updated_date": "2024-09-27 20:25:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:28:10.668902"
    },
    {
      "arxiv_id": "2409.19120v1",
      "title": "Secure Multiparty Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Manil Shrestha",
        "Yashodha Ravichandran",
        "Edward Kim"
      ],
      "abstract": "As usage of generative AI tools skyrockets, the amount of sensitive\ninformation being exposed to these models and centralized model providers is\nalarming. For example, confidential source code from Samsung suffered a data\nleak as the text prompt to ChatGPT encountered data leakage. An increasing\nnumber of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan\nChase, etc.) due to data leakage or confidentiality issues. Also, an increasing\nnumber of centralized generative model providers are restricting, filtering,\naligning, or censoring what can be used. Midjourney and RunwayML, two of the\nmajor image generation platforms, restrict the prompts to their system via\nprompt filtering. Certain political figures are restricted from image\ngeneration, as well as words associated with women's health care, rights, and\nabortion.\n  In our research, we present a secure and private methodology for generative\nartificial intelligence that does not expose sensitive data or models to\nthird-party AI providers. Our work modifies the key building block of modern\ngenerative AI algorithms, e.g. the transformer, and introduces confidential and\nverifiable multiparty computations in a decentralized network to maintain the\n1) privacy of the user input and obfuscation to the output of the model, and 2)\nintroduce privacy to the model itself. Additionally, the sharding process\nreduces the computational burden on any one node, enabling the distribution of\nresources of large generative AI processes across multiple, smaller nodes. We\nshow that as long as there exists one honest node in the decentralized\ncomputation, security is maintained. We also show that the inference process\nwill still succeed if only a majority of the nodes in the computation are\nsuccessful. Thus, our method offers both secure and verifiable computation in a\ndecentralized network.",
      "tldr_zh": "本研究针对生成式 AI 的数据泄露和审查问题（如 Samsung 事件和公司限制），提出了一种安全的多方生成式 AI 方法，避免敏感数据或模型暴露给第三方。方法通过修改 Transformer 架构并引入机密可验证多方计算（confidential and verifiable multiparty computations）在去中心化网络中，实现用户输入隐私保护、模型输出混淆以及模型自身的隐私保障。同时，分片技术降低了计算负担，使大型 AI 过程可分布在多个小型节点上；只要存在一个诚实节点，系统安全即可维护，且多数节点成功时推理过程仍能完成。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19120v1",
      "published_date": "2024-09-27 19:55:49 UTC",
      "updated_date": "2024-09-27 19:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:28:22.753393"
    },
    {
      "arxiv_id": "2409.19104v1",
      "title": "Responsible AI in Open Ecosystems: Reconciling Innovation with Risk Assessment and Disclosure",
      "title_zh": "翻译失败",
      "authors": [
        "Mahasweta Chakraborti",
        "Bert Joseph Prestoza",
        "Nicholas Vincent",
        "Seth Frey"
      ],
      "abstract": "The rapid scaling of AI has spurred a growing emphasis on ethical\nconsiderations in both development and practice. This has led to the\nformulation of increasingly sophisticated model auditing and reporting\nrequirements, as well as governance frameworks to mitigate potential risks to\nindividuals and society. At this critical juncture, we review the practical\nchallenges of promoting responsible AI and transparency in informal sectors\nlike OSS that support vital infrastructure and see widespread use. We focus on\nhow model performance evaluation may inform or inhibit probing of model\nlimitations, biases, and other risks. Our controlled analysis of 7903 Hugging\nFace projects found that risk documentation is strongly associated with\nevaluation practices. Yet, submissions (N=789) from the platform's most popular\ncompetitive leaderboard showed less accountability among high performers. Our\nfindings can inform AI providers and legal scholars in designing interventions\nand policies that preserve open-source innovation while incentivizing ethical\nuptake.",
      "tldr_zh": "这篇论文探讨了在开源生态（Open Ecosystems）中推动Responsible AI的挑战，旨在平衡创新与风险评估（Risk Assessment）和披露（Disclosure）。研究通过对7903个Hugging Face项目的控制分析，发现风险文档与模型性能评估实践密切相关，但平台热门排行榜的789个高性能提交显示出较低的问责性。最终，研究结果为AI提供者和政策制定者提供指导，帮助设计干预措施，以维护开源创新的同时促进伦理采用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "[Under Review][WIP]",
      "pdf_url": "http://arxiv.org/pdf/2409.19104v1",
      "published_date": "2024-09-27 19:09:40 UTC",
      "updated_date": "2024-09-27 19:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:28:34.052729"
    },
    {
      "arxiv_id": "2410.02823v1",
      "title": "DANA: Domain-Aware Neurosymbolic Agents for Consistency and Accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "Vinh Luong",
        "Sang Dinh",
        "Shruti Raghavan",
        "William Nguyen",
        "Zooey Nguyen",
        "Quynh Le",
        "Hung Vo",
        "Kentaro Maegaito",
        "Loc Nguyen",
        "Thao Nguyen",
        "Anh Hai Ha",
        "Christopher Nguyen"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, but their\ninherent probabilistic nature often leads to inconsistency and inaccuracy in\ncomplex problem-solving tasks. This paper introduces DANA (Domain-Aware\nNeurosymbolic Agent), an architecture that addresses these issues by\nintegrating domain-specific knowledge with neurosymbolic approaches. We begin\nby analyzing current AI architectures, including AutoGPT, LangChain ReAct and\nOpenAI's ChatGPT, through a neurosymbolic lens, highlighting how their reliance\non probabilistic inference contributes to inconsistent outputs. In response,\nDANA captures and applies domain expertise in both natural-language and\nsymbolic forms, enabling more deterministic and reliable problem-solving\nbehaviors. We implement a variant of DANA using Hierarchical Task Plans (HTPs)\nin the open-source OpenSSA framework. This implementation achieves over 90\\%\naccuracy on the FinanceBench financial-analysis benchmark, significantly\noutperforming current LLM-based systems in both consistency and accuracy.\nApplication of DANA in physical industries such as semiconductor shows that its\nflexible architecture for incorporating knowledge is effective in mitigating\nthe probabilistic limitations of LLMs and has potential in tackling complex,\nreal-world problems that require reliability and precision.",
      "tldr_zh": "本研究提出DANA（Domain-Aware Neurosymbolic Agents），一种整合领域特定知识的神经符号架构，旨在解决Large Language Models (LLMs)在复杂问题解决中存在的概率性导致的不一致性和不准确性问题。通过捕捉自然语言和符号形式的领域知识，DANA实现了更确定性和可靠的行为，并在OpenSSA框架中使用Hierarchical Task Plans (HTPs)进行实现。实验结果显示，DANA在FinanceBench金融分析基准测试中达到超过90%的准确率，显著优于现有LLM系统，并在半导体等物理行业中证明了其在处理真实世界复杂问题的可靠性和精确性潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02823v1",
      "published_date": "2024-09-27 18:29:23 UTC",
      "updated_date": "2024-09-27 18:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:28:45.896694"
    },
    {
      "arxiv_id": "2409.19078v2",
      "title": "Differential privacy enables fair and accurate AI-based analysis of speech disorders while protecting patient data",
      "title_zh": "翻译失败",
      "authors": [
        "Soroosh Tayebi Arasteh",
        "Mahshad Lotfinia",
        "Paula Andrea Perez-Toro",
        "Tomas Arias-Vergara",
        "Mahtab Ranji",
        "Juan Rafael Orozco-Arroyave",
        "Maria Schuster",
        "Andreas Maier",
        "Seung Hee Yang"
      ],
      "abstract": "Speech pathology has impacts on communication abilities and quality of life.\nWhile deep learning-based models have shown potential in diagnosing these\ndisorders, the use of sensitive data raises critical privacy concerns. Although\ndifferential privacy (DP) has been explored in the medical imaging domain, its\napplication in pathological speech analysis remains largely unexplored despite\nthe equally critical privacy concerns. This study is the first to investigate\nDP's impact on pathological speech data, focusing on the trade-offs between\nprivacy, diagnostic accuracy, and fairness. Using a large, real-world dataset\nof 200 hours of recordings from 2,839 German-speaking participants, we observed\na maximum accuracy reduction of 3.85% when training with DP with high privacy\nlevels. To highlight real-world privacy risks, we demonstrated the\nvulnerability of non-private models to explicit gradient inversion attacks,\nreconstructing identifiable speech samples and showcasing DP's effectiveness in\nmitigating these risks. To generalize our findings across languages and\ndisorders, we validated our approach on a dataset of Spanish-speaking\nParkinson's disease patients, leveraging pretrained models from healthy\nEnglish-speaking datasets, and demonstrated that careful pretraining on\nlarge-scale task-specific datasets can maintain favorable accuracy under DP\nconstraints. A comprehensive fairness analysis revealed minimal gender bias at\nreasonable privacy levels but underscored the need for addressing age-related\ndisparities. Our results establish that DP can balance privacy and utility in\nspeech disorder detection, while highlighting unique challenges in\nprivacy-fairness trade-offs for speech data. This provides a foundation for\nrefining DP methodologies and improving fairness across diverse patient groups\nin real-world deployments.",
      "tldr_zh": "该研究首次探讨了差分隐私（DP）在语音障碍分析中的应用，旨在平衡隐私保护、诊断准确性和公平性，使用深度学习模型分析敏感的语音数据。研究利用200小时的真实数据集（包括2839名德语参与者）进行实验，发现高隐私级别下的DP导致准确率最多降低3.85%，并通过梯度反演攻击证明DP能有效缓解隐私风险；在西班牙语帕金森病患者数据集上验证了方法的泛化性。公平性分析显示，DP在合理水平下对性别偏差影响最小，但需关注年龄相关差异，为AI在语音障碍检测中的隐私友好部署提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19078v2",
      "published_date": "2024-09-27 18:25:54 UTC",
      "updated_date": "2024-12-26 12:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:28:59.100175"
    },
    {
      "arxiv_id": "2409.19075v4",
      "title": "Meta-RTL: Reinforcement-Based Meta-Transfer Learning for Low-Resource Commonsense Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Fu",
        "Jie He",
        "Yifan Yang",
        "Qun Liu",
        "Deyi Xiong"
      ],
      "abstract": "Meta learning has been widely used to exploit rich-resource source tasks to\nimprove the performance of low-resource target tasks. Unfortunately, most\nexisting meta learning approaches treat different source tasks equally,\nignoring the relatedness of source tasks to the target task in knowledge\ntransfer. To mitigate this issue, we propose a reinforcement-based multi-source\nmeta-transfer learning framework (Meta-RTL) for low-resource commonsense\nreasoning. In this framework, we present a reinforcement-based approach to\ndynamically estimating source task weights that measure the contribution of the\ncorresponding tasks to the target task in the meta-transfer learning. The\ndifferences between the general loss of the meta model and task-specific losses\nof source-specific temporal meta models on sampled target data are fed into the\npolicy network of the reinforcement learning module as rewards. The policy\nnetwork is built upon LSTMs that capture long-term dependencies on source task\nweight estimation across meta learning iterations. We evaluate the proposed\nMeta-RTL using both BERT and ALBERT as the backbone of the meta model on three\ncommonsense reasoning benchmark datasets. Experimental results demonstrate that\nMeta-RTL substantially outperforms strong baselines and previous task selection\nstrategies and achieves larger improvements on extremely low-resource settings.",
      "tldr_zh": "本文提出 Meta-RTL，一种基于强化学习的元转移学习框架，用于低资源常识推理问题，旨在通过动态估计源任务权重来解决现有方法忽略源任务与目标任务相关性的局限性。该框架利用强化学习模块，将元模型的通用损失与源特定临时元模型的任务特定损失差异作为奖励输入，并基于 LSTMs 构建策略网络以捕捉跨元学习迭代的长期依赖。在使用 BERT 和 ALBERT 作为骨干模型的实验中，Meta-RTL 在三个常识推理基准数据集上显著优于强基线，并在极端低资源设置下实现了更大性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19075v4",
      "published_date": "2024-09-27 18:22:22 UTC",
      "updated_date": "2025-04-11 14:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:29:20.910952"
    },
    {
      "arxiv_id": "2409.19058v2",
      "title": "CLLMate: A Multimodal Benchmark for Weather and Climate Events Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Haobo Li",
        "Zhaowei Wang",
        "Jiachen Wang",
        "Yueya Wang",
        "Alexis Kai Hon Lau",
        "Huamin Qu"
      ],
      "abstract": "Forecasting weather and climate events is crucial for making appropriate\nmeasures to mitigate environmental hazards and minimize losses. However,\nexisting environmental forecasting research focuses narrowly on predicting\nnumerical meteorological variables (e.g., temperature), neglecting the\ntranslation of these variables into actionable textual narratives of events and\ntheir consequences. To bridge this gap, we proposed Weather and Climate Event\nForecasting (WCEF), a new task that leverages numerical meteorological raster\ndata and textual event data to predict weather and climate events. This task is\nchallenging to accomplish due to difficulties in aligning multimodal data and\nthe lack of supervised datasets. To address these challenges, we present\nCLLMate, the first multimodal dataset for WCEF, using 26,156 environmental news\narticles aligned with ERA5 reanalysis data. We systematically benchmark 23\nexisting MLLMs on CLLMate, including closed-source, open-source, and our\nfine-tuned models. Our experiments reveal the advantages and limitations of\nexisting MLLMs and the value of CLLMate for the training and benchmarking of\nthe WCEF task.",
      "tldr_zh": "这篇论文提出了 WCEF（Weather and Climate Event Forecasting）任务，用于解决现有天气预测研究仅关注数值气象变量（如温度）而忽略转化为可行动文本叙述的问题。作者构建了 CLLMate，这是第一个多模态数据集，包含 26,156 条环境新闻文章与 ERA5 再分析数据对齐，以支持多模态数据整合和监督学习。实验对 23 个 MLLMs（多模态大型语言模型）进行了基准测试，揭示了这些模型的优缺点，并证明了 CLLMate 在 WCEF 任务的训练和评估中的重要价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19058v2",
      "published_date": "2024-09-27 18:00:13 UTC",
      "updated_date": "2025-02-16 10:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:29:22.502018"
    },
    {
      "arxiv_id": "2409.19051v1",
      "title": "Multimodal Markup Document Models for Graphic Design Completion",
      "title_zh": "多模态标记文档模型用于图形设计完成",
      "authors": [
        "Kotaro Kikuchi",
        "Naoto Inoue",
        "Mayu Otani",
        "Edgar Simo-Serra",
        "Kota Yamaguchi"
      ],
      "abstract": "This paper presents multimodal markup document models (MarkupDM) that can\ngenerate both markup language and images within interleaved multimodal\ndocuments. Unlike existing vision-and-language multimodal models, our MarkupDM\ntackles unique challenges critical to graphic design tasks: generating partial\nimages that contribute to the overall appearance, often involving transparency\nand varying sizes, and understanding the syntax and semantics of markup\nlanguages, which play a fundamental role as a representational format of\ngraphic designs. To address these challenges, we design an image quantizer to\ntokenize images of diverse sizes with transparency and modify a code language\nmodel to process markup languages and incorporate image modalities. We provide\nin-depth evaluations of our approach on three graphic design completion tasks:\ngenerating missing attribute values, images, and texts in graphic design\ntemplates. Results corroborate the effectiveness of our MarkupDM for graphic\ndesign tasks. We also discuss the strengths and weaknesses in detail, providing\ninsights for future research on multimodal document generation.",
      "tldr_zh": "本研究提出 Multimodal Markup Document Models (MarkupDM)，一种能生成标记语言和图像的交错多模态文档模型，针对图形设计任务的独特挑战，如处理部分图像（涉及透明度和不同大小）以及理解标记语言的语法和语义。MarkupDM 通过设计 image quantizer 来标记化多样化图像，并修改代码语言模型以整合图像模态，从而实现高效的多模态处理。在三个图形设计完成任务（生成缺失属性值、图像和文本）上的评估中，模型表现出色，证明了其有效性，并详细讨论了优势和劣势，为未来多模态文档生成研究提供洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://cyberagentailab.github.io/MarkupDM/",
      "pdf_url": "http://arxiv.org/pdf/2409.19051v1",
      "published_date": "2024-09-27 18:00:01 UTC",
      "updated_date": "2024-09-27 18:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:29:34.590179"
    },
    {
      "arxiv_id": "2409.18964v1",
      "title": "PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation",
      "title_zh": "PhysGen：基于刚体物理的图像到视频生成",
      "authors": [
        "Shaowei Liu",
        "Zhongzheng Ren",
        "Saurabh Gupta",
        "Shenlong Wang"
      ],
      "abstract": "We present PhysGen, a novel image-to-video generation method that converts a\nsingle image and an input condition (e.g., force and torque applied to an\nobject in the image) to produce a realistic, physically plausible, and\ntemporally consistent video. Our key insight is to integrate model-based\nphysical simulation with a data-driven video generation process, enabling\nplausible image-space dynamics. At the heart of our system are three core\ncomponents: (i) an image understanding module that effectively captures the\ngeometry, materials, and physical parameters of the image; (ii) an image-space\ndynamics simulation model that utilizes rigid-body physics and inferred\nparameters to simulate realistic behaviors; and (iii) an image-based rendering\nand refinement module that leverages generative video diffusion to produce\nrealistic video footage featuring the simulated motion. The resulting videos\nare realistic in both physics and appearance and are even precisely\ncontrollable, showcasing superior results over existing data-driven\nimage-to-video generation works through quantitative comparison and\ncomprehensive user study. PhysGen's resulting videos can be used for various\ndownstream applications, such as turning an image into a realistic animation or\nallowing users to interact with the image and create various dynamics. Project\npage: https://stevenlsw.github.io/physgen/",
      "tldr_zh": "我们介绍了PhysGen，一种基于Rigid-Body Physics的图像到视频生成方法，它将模型驱动的物理模拟与数据驱动视频生成相结合，从单张图像和输入条件（如力矩）生成真实、可信且时间一致的视频。该方法的核心组件包括：图像理解模块捕捉图像的几何、材料和物理参数；图像空间动态模拟模型利用刚体物理模拟真实行为；以及基于生成视频扩散的渲染和精炼模块，确保视频外观逼真。实验结果显示，PhysGen在定量比较和用户研究中比现有数据驱动方法提升显著，并支持下游应用，如将图像转化为动画或实现用户交互动态控制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024. Project page:\n  https://stevenlsw.github.io/physgen/",
      "pdf_url": "http://arxiv.org/pdf/2409.18964v1",
      "published_date": "2024-09-27 17:59:57 UTC",
      "updated_date": "2024-09-27 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:29:46.886964"
    },
    {
      "arxiv_id": "2409.18962v1",
      "title": "Exploring Token Pruning in Vision State Space Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Zhan",
        "Zhenglun Kong",
        "Yifan Gong",
        "Yushu Wu",
        "Zichong Meng",
        "Hangyu Zheng",
        "Xuan Shen",
        "Stratis Ioannidis",
        "Wei Niu",
        "Pu Zhao",
        "Yanzhi Wang"
      ],
      "abstract": "State Space Models (SSMs) have the advantage of keeping linear computational\ncomplexity compared to attention modules in transformers, and have been applied\nto vision tasks as a new type of powerful vision foundation model. Inspired by\nthe observations that the final prediction in vision transformers (ViTs) is\nonly based on a subset of most informative tokens, we take the novel step of\nenhancing the efficiency of SSM-based vision models through token-based\npruning. However, direct applications of existing token pruning techniques\ndesigned for ViTs fail to deliver good performance, even with extensive\nfine-tuning. To address this issue, we revisit the unique computational\ncharacteristics of SSMs and discover that naive application disrupts the\nsequential token positions. This insight motivates us to design a novel and\ngeneral token pruning method specifically for SSM-based vision models. We first\nintroduce a pruning-aware hidden state alignment method to stabilize the\nneighborhood of remaining tokens for performance enhancement. Besides, based on\nour detailed analysis, we propose a token importance evaluation method adapted\nfor SSM models, to guide the token pruning. With efficient implementation and\npractical acceleration methods, our method brings actual speedup. Extensive\nexperiments demonstrate that our approach can achieve significant computation\nreduction with minimal impact on performance across different tasks. Notably,\nwe achieve 81.7\\% accuracy on ImageNet with a 41.6\\% reduction in the FLOPs for\npruned PlainMamba-L3. Furthermore, our work provides deeper insights into\nunderstanding the behavior of SSM-based vision models for future research.",
      "tldr_zh": "本研究探讨了在视觉 State Space Models (SSMs) 中应用 token pruning 以提升计算效率，受到 Vision Transformers (ViTs) 中仅部分 tokens 影响预测的启发。作者设计了一种新型 token pruning 方法，包括 pruning-aware hidden state alignment 用于稳定剩余 tokens 的邻域，以及适应 SSMs 的 token importance evaluation 来指导 pruning，从而避免直接应用 ViTs 方法导致的性能下降。实验结果显示，该方法在不同任务上实现了显著计算减少，例如在 ImageNet 上，pruned PlainMamba-L3 模型的准确率达到 81.7%，同时 FLOPs 减少 41.6%。这项工作还为理解 SSM-based 视觉模型的行为提供了更深入的洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS'24",
      "pdf_url": "http://arxiv.org/pdf/2409.18962v1",
      "published_date": "2024-09-27 17:59:50 UTC",
      "updated_date": "2024-09-27 17:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:29:59.007559"
    },
    {
      "arxiv_id": "2409.18961v1",
      "title": "ProMerge: Prompt and Merge for Unsupervised Instance Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Li",
        "Gyungin Shin"
      ],
      "abstract": "Unsupervised instance segmentation aims to segment distinct object instances\nin an image without relying on human-labeled data. This field has recently seen\nsignificant advancements, partly due to the strong local correspondences\nafforded by rich visual feature representations from self-supervised models\n(e.g., DINO). Recent state-of-the-art approaches use self-supervised features\nto represent images as graphs and solve a generalized eigenvalue system (i.e.,\nnormalized-cut) to generate foreground masks. While effective, this strategy is\nlimited by its attendant computational demands, leading to slow inference\nspeeds. In this paper, we propose Prompt and Merge (ProMerge), which leverages\nself-supervised visual features to obtain initial groupings of patches and\napplies a strategic merging to these segments, aided by a sophisticated\nbackground-based mask pruning technique. ProMerge not only yields competitive\nresults but also offers a significant reduction in inference time compared to\nstate-of-the-art normalized-cut-based approaches. Furthermore, when training an\nobject detector using our mask predictions as pseudo-labels, the resulting\ndetector surpasses the current leading unsupervised model on various\nchallenging instance segmentation benchmarks.",
      "tldr_zh": "该论文提出ProMerge，一种用于无监督实例分割的框架，通过利用self-supervised features获取图像补丁的初始分组，并结合战略合并和基于背景的掩码修剪技术，避免了传统normalized-cut方法的计算密集问题。ProMerge不仅在性能上与现有最先进方法竞争，还显著降低了推理时间。实验结果显示，使用ProMerge生成的掩码作为伪标签训练对象检测器时，其在各种挑战性实例分割基准上超越了当前领先的无监督模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV2024 camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2409.18961v1",
      "published_date": "2024-09-27 17:59:42 UTC",
      "updated_date": "2024-09-27 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:30:10.196707"
    },
    {
      "arxiv_id": "2409.18959v2",
      "title": "O(d/T) Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions",
      "title_zh": "翻译失败",
      "authors": [
        "Gen Li",
        "Yuling Yan"
      ],
      "abstract": "Score-based diffusion models, which generate new data by learning to reverse\na diffusion process that perturbs data from the target distribution into noise,\nhave achieved remarkable success across various generative tasks. Despite their\nsuperior empirical performance, existing theoretical guarantees are often\nconstrained by stringent assumptions or suboptimal convergence rates. In this\npaper, we establish a fast convergence theory for the denoising diffusion\nprobabilistic model (DDPM), a widely used SDE-based sampler, under minimal\nassumptions. Our analysis shows that, provided $\\ell_{2}$-accurate estimates of\nthe score functions, the total variation distance between the target and\ngenerated distributions is upper bounded by $O(d/T)$ (ignoring logarithmic\nfactors), where $d$ is the data dimensionality and $T$ is the number of steps.\nThis result holds for any target distribution with finite first-order moment.\nMoreover, we show that with careful coefficient design, the convergence rate\nimproves to $O(k/T)$, where $k$ is the intrinsic dimension of the target data\ndistribution. This highlights the ability of DDPM to automatically adapt to\nunknown low-dimensional structures, a common feature of natural image\ndistributions. These results are achieved through a novel set of analytical\ntools that provides a fine-grained characterization of how the error propagates\nat each step of the reverse process.",
      "tldr_zh": "这篇论文在最小假设下，为去噪扩散概率模型(DDPM)建立了快速收敛理论，展示了其在生成任务中的优越性。研究证明，如果分数函数的$\\ell_2$估计准确，总变差距离的上界为$O(d/T)$（忽略对数因子），适用于任何具有有限一阶矩的目标分布。通过精心设计系数，收敛率可进一步改善为$O(k/T)$，其中$k$是目标数据分布的内在维度，从而突显DDPM自动适应未知低维结构的能力。该理论依赖于新颖的分析工具，对逆过程每个步骤的错误传播进行了细粒度表征。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "add new results demonstrating the adaptivity of the DDPM sampler to\n  unknown low-dimensional structures",
      "pdf_url": "http://arxiv.org/pdf/2409.18959v2",
      "published_date": "2024-09-27 17:59:10 UTC",
      "updated_date": "2025-01-22 16:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:30:23.349687"
    },
    {
      "arxiv_id": "2409.18957v3",
      "title": "LML-DAP: Language Model Learning a Dataset for Data-Augmented Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Praneeth Vadlapati"
      ],
      "abstract": "Classification tasks are typically handled using Machine Learning (ML)\nmodels, which lack a balance between accuracy and interpretability. This paper\nintroduces a new approach for classification tasks using Large Language Models\n(LLMs) in an explainable method. Unlike ML models, which rely heavily on data\ncleaning and feature engineering, this method streamlines the process using\nLLMs. This paper proposes a method called \"Language Model Learning (LML)\"\npowered by a new method called \"Data-Augmented Prediction (DAP).\" The\nclassification is performed by LLMs using a method similar to that used by\nhumans who manually explore and understand the data to decide classifications.\nIn the process of LML, a dataset is summarized and evaluated to determine the\nfeatures leading to each label the most. In the DAP process, the system uses\nthe data summary and a row of the testing dataset to automatically generate a\nquery to retrieve relevant rows from the dataset for context-aware\nclassification. LML and DAP unlock new possibilities in areas that require\nexplainable and context-aware decisions by ensuring satisfactory accuracy even\nwith complex data. The system scored an accuracy above 90% in some test cases,\nconfirming the effectiveness and potential of the system to outperform ML\nmodels in various scenarios. The source code is available at\nhttps://github.com/Pro-GenAI/LML-DAP",
      "tldr_zh": "这篇论文提出了 LML-DAP 方法，使用 Large Language Models (LLMs) 进行可解释的分类任务，以解决传统 Machine Learning (ML) 模型在准确性和解释性之间缺乏平衡的问题。LML 过程通过总结数据集并评估关键特征来模拟人类数据探索方式，而 DAP 则利用数据摘要和测试数据行自动生成查询，检索相关上下文以辅助分类。实验结果显示，该系统在某些测试中准确率超过90%，在需要上下文感知和可解释决策的领域中表现出色，并提供了开源代码以支持进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Made the abstract and the content clearer",
      "pdf_url": "http://arxiv.org/pdf/2409.18957v3",
      "published_date": "2024-09-27 17:58:50 UTC",
      "updated_date": "2024-11-10 03:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:30:34.656234"
    },
    {
      "arxiv_id": "2409.19044v1",
      "title": "On the Inductive Bias of Stacking Towards Improving Reasoning",
      "title_zh": "论堆叠的归纳偏差以改善推理",
      "authors": [
        "Nikunj Saunshi",
        "Stefani Karp",
        "Shankar Krishnan",
        "Sobhan Miryoosefi",
        "Sashank J. Reddi",
        "Sanjiv Kumar"
      ],
      "abstract": "Given the increasing scale of model sizes, novel training strategies like\ngradual stacking [Gong et al., 2019, Reddi et al., 2023] have garnered\ninterest. Stacking enables efficient training by gradually growing the depth of\na model in stages and using layers from a smaller model in an earlier stage to\ninitialize the next stage. Although efficient for training, the model biases\ninduced by such growing approaches are largely unexplored. In this work, we\nexamine this fundamental aspect of gradual stacking, going beyond its\nefficiency benefits. We propose a variant of gradual stacking called MIDAS that\ncan speed up language model training by up to 40%. Furthermore we discover an\nintriguing phenomenon: MIDAS is not only training-efficient but surprisingly\nalso has an inductive bias towards improving downstream tasks, especially tasks\nthat require reasoning abilities like reading comprehension and math problems,\ndespite having similar or slightly worse perplexity compared to baseline\ntraining. To further analyze this inductive bias, we construct reasoning\nprimitives -- simple synthetic tasks that are building blocks for reasoning --\nand find that a model pretrained with stacking is significantly better than\nstandard pretraining on these primitives, with and without fine-tuning. This\nprovides stronger and more robust evidence for this inductive bias towards\nreasoning. These findings of training efficiency and inductive bias towards\nreasoning are verified at 1B, 2B and 8B parameter language models. Finally, we\nconjecture the underlying reason for this inductive bias by exploring the\nconnection of stacking to looped models and provide strong supporting empirical\nanalysis.",
      "tldr_zh": "本文探讨了 gradual stacking 策略在语言模型训练中的诱导偏差（inductive bias），提出了一种变体 MIDAS，可将训练速度提高40%。研究发现，MIDAS 不仅提升训练效率，还增强了模型在推理任务（如阅读理解和数学问题）上的性能，尽管其困惑度（perplexity）与基线类似或略差。作者通过构建推理基元（reasoning primitives）并在1B、2B和8B参数模型上验证，证实了这种偏差，并分析其与循环模型（looped models）的潜在联系。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19044v1",
      "published_date": "2024-09-27 17:58:21 UTC",
      "updated_date": "2024-09-27 17:58:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:30:46.701415"
    },
    {
      "arxiv_id": "2410.00044v1",
      "title": "Artificial intelligence-based blockchain-driven financial default prediction",
      "title_zh": "基于人工智能的区块链驱动金融违约预测",
      "authors": [
        "Junjun Huang"
      ],
      "abstract": "With the rapid development of technology, blockchain and artificial\nintelligence technology are playing a huge role in all walks of life. In the\nfinancial sector, blockchain solves many security problems in data storage and\nmanagement in traditional systems with its advantages of decentralization and\nsecurity. And artificial intelligence has huge advantages in financial\nforecasting and risk management through its powerful algorithmic modeling\ncapabilities. In financial default prediction using blockchain and artificial\nintelligence technology is a very powerful application. Blockchain technology\nguarantees the credibility of data and consistency on all nodes, and machine\nlearning builds a high-level default prediction model through detailed analysis\nof big data. This study offers financial institutions new thoughts on financial\ntechnology in terms of credit risk mitigation and financial system\nstabilization.",
      "tldr_zh": "该研究探讨了基于人工智能和区块链技术的金融违约预测方法，利用 blockchain 的去中心化和安全性来解决传统系统的数据存储问题。人工智能通过机器学习算法对大数据进行详细分析，构建高效的违约预测模型，确保数据可信度和节点一致性。该方法为金融机构提供新的思路，以缓解信用风险并稳定金融系统。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00044v1",
      "published_date": "2024-09-27 17:51:48 UTC",
      "updated_date": "2024-09-27 17:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:30:57.194552"
    },
    {
      "arxiv_id": "2409.18946v3",
      "title": "Unconditional stability of a recurrent neural circuit implementing divisive normalization",
      "title_zh": "实现除法归一化的循环神经回路的无条件稳定性",
      "authors": [
        "Shivang Rawat",
        "David J. Heeger",
        "Stefano Martiniani"
      ],
      "abstract": "Stability in recurrent neural models poses a significant challenge,\nparticularly in developing biologically plausible neurodynamical models that\ncan be seamlessly trained. Traditional cortical circuit models are notoriously\ndifficult to train due to expansive nonlinearities in the dynamical system,\nleading to an optimization problem with nonlinear stability constraints that\nare difficult to impose. Conversely, recurrent neural networks (RNNs) excel in\ntasks involving sequential data but lack biological plausibility and\ninterpretability. In this work, we address these challenges by linking dynamic\ndivisive normalization (DN) to the stability of ORGaNICs, a biologically\nplausible recurrent cortical circuit model that dynamically achieves DN and\nthat has been shown to simulate a wide range of neurophysiological phenomena.\nBy using the indirect method of Lyapunov, we prove the remarkable property of\nunconditional local stability for an arbitrary-dimensional ORGaNICs circuit\nwhen the recurrent weight matrix is the identity. We thus connect ORGaNICs to a\nsystem of coupled damped harmonic oscillators, which enables us to derive the\ncircuit's energy function, providing a normative principle of what the circuit,\nand individual neurons, aim to accomplish. Further, for a generic recurrent\nweight matrix, we prove the stability of the 2D model and demonstrate\nempirically that stability holds in higher dimensions. Finally, we show that\nORGaNICs can be trained by backpropagation through time without gradient\nclipping/scaling, thanks to its intrinsic stability property and adaptive time\nconstants, which address the problems of exploding, vanishing, and oscillating\ngradients. By evaluating the model's performance on RNN benchmarks, we find\nthat ORGaNICs outperform alternative neurodynamical models on static image\nclassification tasks and perform comparably to LSTMs on sequential tasks.",
      "tldr_zh": "本研究探讨了循环神经网络(RNNs)训练中的稳定性挑战，特别针对生物学上合理的神经动力学模型，引入了 ORGaNICs 电路模型，该模型实现了动态 divisive normalization(DN)。通过 Lyapunov 间接方法，论文证明了当循环权重矩阵为身份矩阵时，ORGaNICs 在任意维度下具有无条件局部稳定性，并将其与耦合阻尼谐振子系统联系起来，推导出能量函数作为规范原则。实验结果显示，ORGaNICs 在静态图像分类任务上优于其他神经动力学模型，在顺序任务上与 LSTMs 相当，且可通过时间反向传播训练而无需梯度剪切，展示了其内在稳定性和适应性优势。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "math.DS"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18946v3",
      "published_date": "2024-09-27 17:46:05 UTC",
      "updated_date": "2025-01-15 02:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:31:11.146980"
    },
    {
      "arxiv_id": "2409.18941v1",
      "title": "Building Trust Through Voice: How Vocal Tone Impacts User Perception of Attractiveness of Voice Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Sabid Bin Habib Pias",
        "Alicia Freel",
        "Ran Huang",
        "Donald Williamson",
        "Minjeong Kim",
        "Apu Kapadia"
      ],
      "abstract": "Voice Assistants (VAs) are popular for simple tasks, but users are often\nhesitant to use them for complex activities like online shopping. We explored\nwhether the vocal characteristics like the VA's vocal tone, can make VAs\nperceived as more attractive and trustworthy to users for complex tasks. Our\nfindings show that the tone of the VA voice significantly impacts its perceived\nattractiveness and trustworthiness. Participants in our experiment were more\nlikely to be attracted to VAs with positive or neutral tones and ultimately\ntrusted the VAs they found more attractive. We conclude that VA's perceived\ntrustworthiness can be enhanced through thoughtful voice design, incorporating\na variety of vocal tones.",
      "tldr_zh": "该研究探讨了Voice Assistants (VAs) 的声调如何影响用户对其吸引力和可信度的感知，特别是针对复杂任务如在线购物。实验结果显示，积极或中性声调的VAs 被用户视为更吸引人，从而提升了信任度。研究结论建议，通过设计多样化的声调，可以有效增强VAs 的整体可信性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Extended Abstract",
      "pdf_url": "http://arxiv.org/pdf/2409.18941v1",
      "published_date": "2024-09-27 17:41:18 UTC",
      "updated_date": "2024-09-27 17:41:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:31:21.775592"
    },
    {
      "arxiv_id": "2409.18938v2",
      "title": "From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Heqing Zou",
        "Tianze Luo",
        "Guiyang Xie",
        "Victor",
        "Zhang",
        "Fengmao Lv",
        "Guangcong Wang",
        "Junyang Chen",
        "Zhuochen Wang",
        "Hansheng Zhang",
        "Huaijian Zhang"
      ],
      "abstract": "The integration of Large Language Models (LLMs) with visual encoders has\nrecently shown promising performance in visual understanding tasks, leveraging\ntheir inherent capability to comprehend and generate human-like text for visual\nreasoning. Given the diverse nature of visual data, MultiModal Large Language\nModels (MM-LLMs) exhibit variations in model designing and training for\nunderstanding images, short videos, and long videos. Our paper focuses on the\nsubstantial differences and unique challenges posed by long video understanding\ncompared to static image and short video understanding. Unlike static images,\nshort videos encompass sequential frames with both spatial and within-event\ntemporal information, while long videos consist of multiple events with\nbetween-event and long-term temporal information. In this survey, we aim to\ntrace and summarize the advancements of MM-LLMs from image understanding to\nlong video understanding. We review the differences among various visual\nunderstanding tasks and highlight the challenges in long video understanding,\nincluding more fine-grained spatiotemporal details, dynamic events, and\nlong-term dependencies. We then provide a detailed summary of the advancements\nin MM-LLMs in terms of model design and training methodologies for\nunderstanding long videos. Finally, we compare the performance of existing\nMM-LLMs on video understanding benchmarks of various lengths and discuss\npotential future directions for MM-LLMs in long video understanding.",
      "tldr_zh": "这篇论文回顾了多模态大型语言模型（MM-LLMs）的进展，聚焦从图像理解到长视频理解的演变，强调了长视频在处理细粒度时空细节、动态事件和长期依赖方面的独特挑战。作者分析了MM-LLMs在模型设计和训练方法上的创新，以应对图像、短视频与长视频的差异。论文总结了现有MM-LLMs在不同长度视频基准上的性能比较，并讨论了未来方向，如提升长视频理解的鲁棒性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.18938v2",
      "published_date": "2024-09-27 17:38:36 UTC",
      "updated_date": "2024-12-03 03:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:31:37.907036"
    },
    {
      "arxiv_id": "2410.09062v1",
      "title": "Volatility Forecasting in Global Financial Markets Using TimeMixer",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Li"
      ],
      "abstract": "Predicting volatility in financial markets, including stocks, index ETFs,\nforeign exchange, and cryptocurrencies, remains a challenging task due to the\ninherent complexity and non-linear dynamics of these time series. In this\nstudy, I apply TimeMixer, a state-of-the-art time series forecasting model, to\npredict the volatility of global financial assets. TimeMixer utilizes a\nmultiscale-mixing approach that effectively captures both short-term and\nlong-term temporal patterns by analyzing data across different scales. My\nempirical results reveal that while TimeMixer performs exceptionally well in\nshort-term volatility forecasting, its accuracy diminishes for longer-term\npredictions, particularly in highly volatile markets. These findings highlight\nTimeMixer's strength in capturing short-term volatility, making it highly\nsuitable for practical applications in financial risk management, where precise\nshort-term forecasts are critical. However, the model's limitations in\nlong-term forecasting point to potential areas for further refinement.",
      "tldr_zh": "本研究使用 TimeMixer 模型预测全球金融市场的波动率，包括股票、指数 ETF、外汇和加密货币，该模型采用多尺度混合方法来捕捉短期和长期时间模式。实验结果显示，TimeMixer 在短期波动率预测中表现出色，但长期预测尤其是高波动市场中的准确性有所下降。这些发现突出了 TimeMixer 在金融风险管理中的实用价值，同时指出了模型在长期预测方面需要进一步优化。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "20 pages and 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09062v1",
      "published_date": "2024-09-27 17:35:28 UTC",
      "updated_date": "2024-09-27 17:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:31:46.034544"
    },
    {
      "arxiv_id": "2409.18924v2",
      "title": "AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow",
      "title_zh": "翻译失败",
      "authors": [
        "Huizi Yu",
        "Jiayan Zhou",
        "Lingyao Li",
        "Shan Chen",
        "Jack Gallifant",
        "Anye Shi",
        "Xiang Li",
        "Wenyue Hua",
        "Mingyu Jin",
        "Guang Chen",
        "Yang Zhou",
        "Zhao Li",
        "Trisha Gupte",
        "Ming-Li Chen",
        "Zahra Azizi",
        "Yongfeng Zhang",
        "Themistocles L. Assimes",
        "Xin Ma",
        "Danielle S. Bitterman",
        "Lin Lu",
        "Lizhou Fan"
      ],
      "abstract": "Simulated patient systems play a crucial role in modern medical education and\nresearch, providing safe, integrative learning environments and enabling\nclinical decision-making simulations. Large Language Models (LLM) could advance\nsimulated patient systems by replicating medical conditions and patient-doctor\ninteractions with high fidelity and low cost. However, ensuring the\neffectiveness and trustworthiness of these systems remains a challenge, as they\nrequire a large, diverse, and precise patient knowledgebase, along with a\nrobust and stable knowledge diffusion to users. Here, we developed AIPatient,\nan advanced simulated patient system with AIPatient Knowledge Graph (AIPatient\nKG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning\nRAG) agentic workflow as the generation backbone. AIPatient KG samples data\nfrom Electronic Health Records (EHRs) in the Medical Information Mart for\nIntensive Care (MIMIC)-III database, producing a clinically diverse and\nrelevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).\nReasoning RAG leverages six LLM powered agents spanning tasks including\nretrieval, KG query generation, abstraction, checker, rewrite, and\nsummarization. This agentic framework reaches an overall accuracy of 94.15% in\nEHR-based medical Question Answering (QA), outperforming benchmarks that use\neither no agent or only partial agent integration. Our system also presents\nhigh readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade\n5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value\n0.782, p>0.1). The promising performance of the AIPatient system highlights its\npotential to support a wide range of applications, including medical education,\nmodel evaluation, and system integration.",
      "tldr_zh": "本文提出了一种先进的模拟患者系统AIPatient，利用Electronic Health Records (EHRs)构建AIPatient Knowledge Graph (AIPatient KG)，从MIMIC-III数据库采样生成1,495个临床多样患者样本，确保知识库的有效性（F1分数0.89）。系统采用Large Language Models (LLM)驱动的Reasoning Retrieval-Augmented Generation (Reasoning RAG)代理工作流，包括检索、KG查询生成、抽象、检查、重写和总结等六个代理任务。实验结果显示，该系统在EHR-based医疗问答中达到94.15%的准确率，并表现出高可读性（Flesch Reading Ease中位数77.23）、鲁棒性和稳定性（ANOVA F-value分别为0.6126和0.782，p>0.1）。AIPatient系统具有广泛应用潜力，包括医疗教育、模型评估和系统集成。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "42 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.18924v2",
      "published_date": "2024-09-27 17:17:15 UTC",
      "updated_date": "2024-10-01 17:49:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:31:59.725155"
    },
    {
      "arxiv_id": "2409.18911v1",
      "title": "Soft Measures for Extracting Causal Collective Intelligence",
      "title_zh": "提取",
      "authors": [
        "Maryam Berijanian",
        "Spencer Dork",
        "Kuldeep Singh",
        "Michael Riley Millikan",
        "Ashlin Riggs",
        "Aadarsh Swaminathan",
        "Sarah L. Gibbs",
        "Scott E. Friedman",
        "Nathan Brugnone"
      ],
      "abstract": "Understanding and modeling collective intelligence is essential for\naddressing complex social systems. Directed graphs called fuzzy cognitive maps\n(FCMs) offer a powerful tool for encoding causal mental models, but extracting\nhigh-integrity FCMs from text is challenging. This study presents an approach\nusing large language models (LLMs) to automate FCM extraction. We introduce\nnovel graph-based similarity measures and evaluate them by correlating their\noutputs with human judgments through the Elo rating system. Results show\npositive correlations with human evaluations, but even the best-performing\nmeasure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs\nimproves performance, but existing measures still fall short. This study\nhighlights the need for soft similarity measures tailored to FCM extraction,\nadvancing collective intelligence modeling with NLP.",
      "tldr_zh": "这篇论文提出了一种使用大型语言模型(LLMs)从文本中自动提取模糊认知图(FCMs)的方法，以更好地建模集体智能中的因果心理模型。研究引入了新的基于图的相似性度量，并通过Elo评分系统与人类判断进行比较，结果显示这些度量与人类评估有正相关，但无法完全捕捉FCM的细微差别。微调LLMs能提升性能，但现有度量仍存在局限，强调需要开发更合适的软相似性措施来推进NLP在集体智能建模中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera-ready version accepted for publication in the EMNLP 2024\n  Workshop NLP4Science",
      "pdf_url": "http://arxiv.org/pdf/2409.18911v1",
      "published_date": "2024-09-27 16:54:36 UTC",
      "updated_date": "2024-09-27 16:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:32:11.158727"
    },
    {
      "arxiv_id": "2409.18901v1",
      "title": "Improving Visual Object Tracking through Visual Prompting",
      "title_zh": "通过视觉提示改进视觉物体跟踪",
      "authors": [
        "Shih-Fang Chen",
        "Jun-Cheng Chen",
        "I-Hong Jhuo",
        "Yen-Yu Lin"
      ],
      "abstract": "Learning a discriminative model to distinguish a target from its surrounding\ndistractors is essential to generic visual object tracking. Dynamic target\nrepresentation adaptation against distractors is challenging due to the limited\ndiscriminative capabilities of prevailing trackers. We present a new visual\nPrompting mechanism for generic Visual Object Tracking (PiVOT) to address this\nissue. PiVOT proposes a prompt generation network with the pre-trained\nfoundation model CLIP to automatically generate and refine visual prompts,\nenabling the transfer of foundation model knowledge for tracking. While CLIP\noffers broad category-level knowledge, the tracker, trained on\ninstance-specific data, excels at recognizing unique object instances. Thus,\nPiVOT first compiles a visual prompt highlighting potential target locations.\nTo transfer the knowledge of CLIP to the tracker, PiVOT leverages CLIP to\nrefine the visual prompt based on the similarities between candidate objects\nand the reference templates across potential targets. Once the visual prompt is\nrefined, it can better highlight potential target locations, thereby reducing\nirrelevant prompt information. With the proposed prompting mechanism, the\ntracker can generate improved instance-aware feature maps through the guidance\nof the visual prompt, thus effectively reducing distractors. The proposed\nmethod does not involve CLIP during training, thereby keeping the same training\ncomplexity and preserving the generalization capability of the pretrained\nfoundation model. Extensive experiments across multiple benchmarks indicate\nthat PiVOT, using the proposed prompting method can suppress distracting\nobjects and enhance the tracker.",
      "tldr_zh": "该论文提出了一种名为 PiVOT 的视觉提示机制，用于提升视觉对象跟踪（Visual Object Tracking）的性能，通过帮助跟踪器更好地区分目标和干扰物。PiVOT 利用预训练基础模型 CLIP 生成并精炼 visual prompts，首先编译提示以突出潜在目标位置，然后基于候选对象与参考模板的相似性进行优化，从而减少无关信息。实验结果表明，该方法在多个基准上有效抑制 distractors，并提升跟踪器的整体准确性和泛化能力，而无需在训练过程中涉及 CLIP，从而保持了训练效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "eess.IV",
        "68",
        "I.4; I.2; I.5; I.4.1; I.4.8; I.4.9; I.4.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted and to appear in IEEE Transactions on Multimedia",
      "pdf_url": "http://arxiv.org/pdf/2409.18901v1",
      "published_date": "2024-09-27 16:39:50 UTC",
      "updated_date": "2024-09-27 16:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:32:22.270075"
    },
    {
      "arxiv_id": "2409.18895v1",
      "title": "Multi-Source Hard and Soft Information Fusion Approach for Accurate Cryptocurrency Price Movement Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Saeed Mohammadi Dashtaki",
        "Mehdi Hosseini Chagahi",
        "Behzad Moshiri",
        "Md. Jalil Piran"
      ],
      "abstract": "One of the most important challenges in the financial and cryptocurrency\nfield is accurately predicting cryptocurrency price trends. Leveraging\nartificial intelligence (AI) is beneficial in addressing this challenge.\nCryptocurrency markets, marked by substantial growth and volatility, attract\ninvestors and scholars keen on deciphering and forecasting cryptocurrency price\nmovements. The vast and diverse array of data available for such predictions\nincreases the complexity of the task. In our study, we introduce a novel\napproach termed hard and soft information fusion (HSIF) to enhance the accuracy\nof cryptocurrency price movement forecasts. The hard information component of\nour approach encompasses historical price records alongside technical\nindicators. Complementing this, the soft data component extracts from X\n(formerly Twitter), encompassing news headlines and tweets about the\ncryptocurrency. To use this data, we use the Bidirectional Encoder\nRepresentations from Transformers (BERT)-based sentiment analysis method,\nfinancial BERT (FinBERT), which performs best. Finally, our model feeds on the\ninformation set including processed hard and soft data. We employ the\nbidirectional long short-term memory (BiLSTM) model because processing\ninformation in both forward and backward directions can capture long-term\ndependencies in sequential information. Our empirical findings emphasize the\nsuperiority of the HSIF approach over models dependent on single-source data by\ntesting on Bitcoin-related data. By fusing hard and soft information on Bitcoin\ndataset, our model has about 96.8\\% accuracy in predicting price movement.\nIncorporating information enables our model to grasp the influence of social\nsentiment on price fluctuations, thereby supplementing the technical\nanalysis-based predictions derived from hard information.",
      "tldr_zh": "本研究提出了一种硬软信息融合（HSIF）方法，用于提升加密货币价格波动预测的准确性。HSIF 结合硬信息（如历史价格记录和技术指标）和软信息（如从 X（Twitter）提取的新闻标题及推文，经 Financial BERT（FinBERT）进行情感分析），然后使用双向长短时记忆网络（BiLSTM）模型处理融合后的数据。实验结果显示，该方法在比特币数据集上实现了约96.8%的预测准确率，显著优于依赖单一数据来源的模型，并突显了社会情感对价格波动的影响，从而补充了基于技术分析的预测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18895v1",
      "published_date": "2024-09-27 16:32:57 UTC",
      "updated_date": "2024-09-27 16:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:32:33.980677"
    },
    {
      "arxiv_id": "2409.18878v2",
      "title": "Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zehan Li",
        "Yan Hu",
        "Scott Lane",
        "Salih Selek",
        "Lokesh Shahani",
        "Rodrigo Machado-Vieira",
        "Jair Soares",
        "Hua Xu",
        "Hongfang Liu",
        "Ming Huang"
      ],
      "abstract": "Accurate identification and categorization of suicidal events can yield\nbetter suicide precautions, reducing operational burden, and improving care\nquality in high-acuity psychiatric settings. Pre-trained language models offer\npromise for identifying suicidality from unstructured clinical narratives. We\nevaluated the performance of four BERT-based models using two fine-tuning\nstrategies (multiple single-label and single multi-label) for detecting\ncoexisting suicidal events from 500 annotated psychiatric evaluation notes. The\nnotes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure\nto suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed\nother models using multiple single-label classification strategy (acc=0.86,\nF1=0.78). MentalBERT (acc=0.83, F1=0.74) also exceeded BioClinicalBERT\n(acc=0.82, F1=0.72) which outperformed BERT (acc=0.80, F1=0.70). RoBERTa\nfine-tuned with single multi-label classification further improved the model\nperformance (acc=0.88, F1=0.81). The findings highlight that the model\noptimization, pretraining with domain-relevant data, and the single multi-label\nclassification strategy enhance the model performance of suicide phenotyping.\nKeywords: EHR-based Phenotyping; Natural Language Processing; Secondary Use of\nEHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health",
      "tldr_zh": "本研究使用多标签分类（Multi-Label Classification）和预训练语言模型（Pre-Trained Language Models）从安全网精神病房的500份临床笔记中识别自杀相关事件，包括自杀意念（SI）、自杀企图（SA）、暴露于自杀（ES）和非自杀性自伤（NSSI），以改善患者护理和减少负担。评估了四个BERT-based模型，结果显示RoBERTa在多个单标签策略下表现最佳（准确率0.86，F1分数0.78），而采用单个多标签策略进一步提升其性能（准确率0.88，F1分数0.81）。这些发现强调了模型优化、领域相关数据预训练和多标签策略在EHR-based Phenotyping和自杀分类（Suicide Classification）中的重要作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "submitted to AMIA Informatics Summit 2025 as a conference paper",
      "pdf_url": "http://arxiv.org/pdf/2409.18878v2",
      "published_date": "2024-09-27 16:13:38 UTC",
      "updated_date": "2024-10-03 20:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:32:48.113670"
    },
    {
      "arxiv_id": "2409.18877v2",
      "title": "UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Chuang Chen",
        "Xiao Sun",
        "Zhi Liu"
      ],
      "abstract": "Visual emotion analysis holds significant research value in both computer\nvision and psychology. However, existing methods for visual emotion analysis\nsuffer from limited generalizability due to the ambiguity of emotion perception\nand the diversity of data scenarios. To tackle this issue, we introduce\nUniEmoX, a cross-modal semantic-guided large-scale pretraining framework.\nInspired by psychological research emphasizing the inseparability of the\nemotional exploration process from the interaction between individuals and\ntheir environment, UniEmoX integrates scene-centric and person-centric\nlow-level image spatial structural information, aiming to derive more nuanced\nand discriminative emotional representations. By exploiting the similarity\nbetween paired and unpaired image-text samples, UniEmoX distills rich semantic\nknowledge from the CLIP model to enhance emotional embedding representations\nmore effectively. To the best of our knowledge, this is the first large-scale\npretraining framework that integrates psychological theories with contemporary\ncontrastive learning and masked image modeling techniques for emotion analysis\nacross diverse scenarios. Additionally, we develop a visual emotional dataset\ntitled Emo8. Emo8 samples cover a range of domains, including cartoon, natural,\nrealistic, science fiction and advertising cover styles, covering nearly all\ncommon emotional scenes. Comprehensive experiments conducted on six benchmark\ndatasets across two downstream tasks validate the effectiveness of UniEmoX. The\nsource code is available at https://github.com/chincharles/u-emo.",
      "tldr_zh": "本文提出 UniEmoX，一种跨模态语义引导的规模化预训练框架，旨在解决视觉情感分析中情感感知模糊性和数据场景多样性导致的泛化性问题。UniEmoX 受心理学理论启发，整合场景中心和个人中心的图像空间结构信息，并通过利用图像-文本样本相似性从 CLIP 模型中提炼语义知识，结合对比学习和掩码图像建模技术，以生成更细致的情感表示。该框架还开发了 Emo8 数据集，涵盖多种领域如卡通、自然和科幻场景，并在六个基准数据集上的下游任务实验中验证了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2409.18877v2",
      "published_date": "2024-09-27 16:12:51 UTC",
      "updated_date": "2024-09-30 13:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:33:00.224705"
    },
    {
      "arxiv_id": "2409.18874v1",
      "title": "CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Josef Koumar",
        "Karel Hynek",
        "Tomáš Čejka",
        "Pavel Šiška"
      ],
      "abstract": "Anomaly detection in network traffic is crucial for maintaining the security\nof computer networks and identifying malicious activities. One of the primary\napproaches to anomaly detection are methods based on forecasting. Nevertheless,\nextensive real-world network datasets for forecasting and anomaly detection\ntechniques are missing, potentially causing performance overestimation of\nanomaly detection algorithms. This manuscript addresses this gap by introducing\na dataset comprising time series data of network entities' behavior, collected\nfrom the CESNET3 network. The dataset was created from 40 weeks of network\ntraffic of 275 thousand active IP addresses. The ISP origin of the presented\ndata ensures a high level of variability among network entities, which forms a\nunique and authentic challenge for forecasting and anomaly detection models. It\nprovides valuable insights into the practical deployment of forecast-based\nanomaly detection approaches.",
      "tldr_zh": "该论文引入了CESNET-TimeSeries24数据集，用于网络流量异常检测和预测，旨在填补真实世界时间序列数据缺乏的空白。数据集基于CESNET3网络的40周流量数据，涵盖了275,000个活跃IP地址，并突显了网络实体间的高变异性，为预测和anomaly detection模型提供真实挑战。该数据集有助于评估算法性能，避免性能高估，并为基于forecasting的异常检测方法提供实际部署见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18874v1",
      "published_date": "2024-09-27 16:10:11 UTC",
      "updated_date": "2024-09-27 16:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:33:10.300754"
    },
    {
      "arxiv_id": "2409.18868v1",
      "title": "Individuation in Neural Models with and without Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Alexey Tikhonov",
        "Lisa Bylinina",
        "Ivan P. Yamshchikov"
      ],
      "abstract": "We show differences between a language-and-vision model CLIP and two\ntext-only models - FastText and SBERT - when it comes to the encoding of\nindividuation information. We study latent representations that CLIP provides\nfor substrates, granular aggregates, and various numbers of objects. We\ndemonstrate that CLIP embeddings capture quantitative differences in\nindividuation better than models trained on text-only data. Moreover, the\nindividuation hierarchy we deduce from the CLIP embeddings agrees with the\nhierarchies proposed in linguistics and cognitive science.",
      "tldr_zh": "本研究比较了具有视觉基础的神经模型 CLIP 与纯文本模型 FastText 和 SBERT 在编码个体化（individuation）信息方面的差异。研究者分析了 CLIP 的潜在表示，包括基质、颗粒聚合物以及不同物体数量的场景。结果显示，CLIP 嵌入更准确地捕捉个体化中的量化差异，且其推导出的个体化层次与语言学和认知科学中的理论一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.4; J.4; I.6.8; I.2.10"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18868v1",
      "published_date": "2024-09-27 16:04:06 UTC",
      "updated_date": "2024-09-27 16:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:33:32.393078"
    },
    {
      "arxiv_id": "2409.18865v2",
      "title": "Positional Encoder Graph Quantile Neural Networks for Geographic Data",
      "title_zh": "位置编码器图分位数神经网络用于地理数据",
      "authors": [
        "William E. R. de Amorim",
        "Scott A. Sisson",
        "T. Rodrigues",
        "David J. Nott",
        "Guilherme S. Rodrigues"
      ],
      "abstract": "Positional Encoder Graph Neural Networks (PE-GNNs) are among the most\neffective models for learning from continuous spatial data. However, their\npredictive distributions are often poorly calibrated, limiting their utility in\napplications that require reliable uncertainty quantification. We propose the\nPositional Encoder Graph Quantile Neural Network (PE-GQNN), a novel framework\nthat combines PE-GNNs with Quantile Neural Networks, partially monotonic neural\nblocks, and post-hoc recalibration techniques. The PE-GQNN enables flexible and\nrobust conditional density estimation with minimal assumptions about the target\ndistribution, and it extends naturally to tasks beyond spatial data. Empirical\nresults on benchmark datasets show that the PE-GQNN outperforms existing\nmethods in both predictive accuracy and uncertainty quantification, without\nincurring additional computational cost. We also provide theoretical insights\nand identify important special cases arising from our formulation, including\nthe PE-GNN.",
      "tldr_zh": "该论文提出了一种新型框架 Positional Encoder Graph Quantile Neural Network (PE-GQNN)，它将 Positional Encoder Graph Neural Networks (PE-GNNs) 与 Quantile Neural Networks 结合，使用部分单调神经块和事后重新校准技术，以解决 PE-GNNs 在处理地理数据时预测分布校准不佳的问题。PE-GQNN 实现了灵活的条件密度估计，对目标分布的假设最小化，并自然扩展到非空间数据任务。实验结果显示，该框架在基准数据集上优于现有方法，在预测准确性和不确定性量化方面表现出色，且不增加计算成本。该研究还提供了理论见解，包括 PE-GNN 等重要特殊情况。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "stat.ML",
      "comment": "12 main text pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18865v2",
      "published_date": "2024-09-27 16:02:12 UTC",
      "updated_date": "2025-05-15 19:11:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:33:36.111578"
    },
    {
      "arxiv_id": "2409.18857v2",
      "title": "Mitigating Selection Bias with Node Pruning and Auxiliary Options",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeong Kyu Choi",
        "Weijie Xu",
        "Chi Xue",
        "Stephanie Eckman",
        "Chandan K. Reddy"
      ],
      "abstract": "Large language models (LLMs) often exhibit systematic preferences for certain\nanswer choices when responding to multiple-choice questions-a behavior known as\nselection bias. This bias reduces the accuracy and reliability of LLM outputs,\nlimiting their usefulness in decision-critical applications. While prior work\nhas focused on adjusting model inputs or outputs to mitigate this issue, our\nwork takes a fundamentally different approach by identifying and removing the\ninternal sources of bias. We introduce two methods: Bias Node Pruning (BNP),\nwhich prunes parameters that contribute to selection bias, and Auxiliary Option\nInjection (AOI), which introduces an additional answer choice to reduce bias in\nboth white-box and black-box settings. To address the shortcomings of existing\nevaluation metrics, we propose Choice Kullback-Leibler Divergence (CKLD), a new\nmetric that captures distributional imbalances in model predictions.\nExperiments on three LLMs across multiple datasets demonstrate that our methods\nconsistently improve answer accuracy while reducing selection bias, providing a\nrobust solution for both open- and closed-source models.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在多选题中存在的选择偏见 (selection bias) 问题，提出两种新方法来缓解这一内部偏差：Bias Node Pruning (BNP) 通过修剪导致偏见的参数，以及 Auxiliary Option Injection (AOI) 通过引入额外答案选项，在白盒和黑盒设置中均有效。研究还引入了 Choice Kullback-Leibler Divergence (CKLD) 这一新指标，用于更准确地评估模型预测中的分布不平衡。实验结果显示，在三个 LLMs 和多个数据集上，这些方法显著提高了答案准确性，同时减少了选择偏见，适用于开源和闭源模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2409.18857v2",
      "published_date": "2024-09-27 15:53:54 UTC",
      "updated_date": "2025-05-17 04:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:33:46.625911"
    },
    {
      "arxiv_id": "2409.18828v2",
      "title": "MECG-E: Mamba-based ECG Enhancer for Baseline Wander Removal",
      "title_zh": "翻译失败",
      "authors": [
        "Kuo-Hsuan Hung",
        "Kuan-Chen Wang",
        "Kai-Chun Liu",
        "Wei-Lun Chen",
        "Xugang Lu",
        "Yu Tsao",
        "Chii-Wann Lin"
      ],
      "abstract": "Electrocardiogram (ECG) is an important non-invasive method for diagnosing\ncardiovascular disease. However, ECG signals are susceptible to noise\ncontamination, such as electrical interference or signal wandering, which\nreduces diagnostic accuracy. Various ECG denoising methods have been proposed,\nbut most existing methods yield suboptimal performance under very noisy\nconditions or require several steps during inference, leading to latency during\nonline processing. In this paper, we propose a novel ECG denoising model,\nnamely Mamba-based ECG Enhancer (MECG-E), which leverages the Mamba\narchitecture known for its fast inference and outstanding nonlinear mapping\ncapabilities. Experimental results indicate that MECG-E surpasses several\nwell-known existing models across multiple metrics under different noise\nconditions. Additionally, MECG-E requires less inference time than\nstate-of-the-art diffusion-based ECG denoisers, demonstrating the model's\nfunctionality and efficiency.",
      "tldr_zh": "这篇论文提出了一种新型心电图 (ECG) 去噪模型 MECG-E，基于 Mamba 架构，旨在高效去除 ECG 信号中的基线漂移 (Baseline Wander Removal)，以提升诊断心血管疾病的准确性。相比现有方法，MECG-E 利用 Mamba 的快速推理和出色非线性映射能力，能够在高噪声条件下实现更优性能，且减少了在线处理延迟。实验结果表明，该模型在多种噪声环境下超越了多项现有指标，并在推理时间上优于最先进的扩散-based ECG 去噪器，证明了其功能性和效率。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted at IEEE BigData 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18828v2",
      "published_date": "2024-09-27 15:22:44 UTC",
      "updated_date": "2024-11-24 07:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:34:08.699732"
    },
    {
      "arxiv_id": "2409.18814v1",
      "title": "Early diagnosis of Alzheimer's disease from MRI images with deep learning model",
      "title_zh": "基于 MRI 图像使用深度学习模型进行阿尔茨海默病的早期诊断",
      "authors": [
        "Sajjad Aghasi Javid",
        "Mahmood Mohassel Feghhi"
      ],
      "abstract": "It is acknowledged that the most common cause of dementia worldwide is\nAlzheimer's disease (AD). This condition progresses in severity from mild to\nsevere and interferes with people's everyday routines. Early diagnosis plays a\ncritical role in patient care and clinical trials. Convolutional neural\nnetworks (CNN) are used to create a framework for identifying specific disease\nfeatures from MRI scans Classification of dementia involves approaches such as\nmedical history review, neuropsychological tests, and magnetic resonance\nimaging (MRI). However, the image dataset obtained from Kaggle faces a\nsignificant issue of class imbalance, which requires equal distribution of\nsamples from each class to address. In this article, to address this imbalance,\nthe Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore,\na pre-trained convolutional neural network has been applied to the DEMNET\ndementia network to extract key features from AD images. The proposed model\nachieved an impressive accuracy of 98.67%.",
      "tldr_zh": "本研究针对阿尔茨海默病(Alzheimer's disease, AD)早期诊断问题，提出了一种基于MRI图像的深度学习框架，利用Convolutional neural networks (CNN)来识别疾病特征。针对Kaggle数据集中的类别不平衡问题，采用Synthetic Minority Oversampling Technique (SMOTE)进行样本均衡处理，并将预训练的CNN应用于DEMNET痴呆网络以提取关键特征。该模型在实验中实现了98.67%的准确率，为AD早期诊断提供了高效的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages, 3 figures, Presented at the 20-th CSI International\n  Symposium on Artificial Intelligence and Signal Processing (AISP) 21-22\n  February, 2024, Mazandaran University of Science and Technology, Babol, Iran",
      "pdf_url": "http://arxiv.org/pdf/2409.18814v1",
      "published_date": "2024-09-27 15:07:26 UTC",
      "updated_date": "2024-09-27 15:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:34:09.735618"
    },
    {
      "arxiv_id": "2409.18812v1",
      "title": "LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis",
      "title_zh": "LLMs4Synthesis：利用大型语言模型进行科学综合",
      "authors": [
        "Hamed Babaei Giglou",
        "Jennifer D'Souza",
        "Sören Auer"
      ],
      "abstract": "In response to the growing complexity and volume of scientific literature,\nthis paper introduces the LLMs4Synthesis framework, designed to enhance the\ncapabilities of Large Language Models (LLMs) in generating high-quality\nscientific syntheses. This framework addresses the need for rapid, coherent,\nand contextually rich integration of scientific insights, leveraging both\nopen-source and proprietary LLMs. It also examines the effectiveness of LLMs in\nevaluating the integrity and reliability of these syntheses, alleviating\ninadequacies in current quantitative metrics. Our study contributes to this\nfield by developing a novel methodology for processing scientific papers,\ndefining new synthesis types, and establishing nine detailed quality criteria\nfor evaluating syntheses. The integration of LLMs with reinforcement learning\nand AI feedback is proposed to optimize synthesis quality, ensuring alignment\nwith established criteria. The LLMs4Synthesis framework and its components are\nmade available, promising to enhance both the generation and evaluation\nprocesses in scientific research synthesis.",
      "tldr_zh": "本研究引入了 LLMs4Synthesis 框架，利用 Large Language Models (LLMs) 来提升科学文献综合的生成质量，针对日益复杂的文献量提供快速、连贯且语境丰富的洞见。框架开发了一种新方法处理科学论文、定义新综合类型，并建立了九个详细的质量标准，同时整合强化学习和 AI feedback 以优化综合的完整性和可靠性。实验结果显示，该框架有效缓解了现有量化指标的不足，并通过公开其组件，促进了科学研究综合的生成和评估过程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures, Accepted to JCDL 2024 Research Track",
      "pdf_url": "http://arxiv.org/pdf/2409.18812v1",
      "published_date": "2024-09-27 15:04:39 UTC",
      "updated_date": "2024-09-27 15:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:34:22.411744"
    },
    {
      "arxiv_id": "2409.18798v1",
      "title": "Esports Debut as a Medal Event at 2023 Asian Games: Exploring Public Perceptions with BERTopic and GPT-4 Topic Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Tyreal Yizhou Qian",
        "Bo Yu",
        "Weizhe Li",
        "Chenglong Xu"
      ],
      "abstract": "This study examined the public opinions of esports at the 2023 Asian Games\nand value co-creation during the event using an LLM-enhanced BERTopic modeling\nanalysis. We identified five major themes representing public perceptions, as\nwell as how major stakeholders co-created value within and beyond the esports\necosystem. Key findings highlighted the strategic use of social media marketing\nto influence public opinion and promote esports events and brands, emphasizing\nthe importance of event logistics and infrastructure. Additionally, the study\nrevealed the co-creation value contributed by stakeholders outside the\ntraditional esports ecosystem, particularly in promoting national\nrepresentation and performance. Our findings supported the ongoing efforts to\nlegitimize esports as a sport, noting that mainstream recognition remains a\nchallenge. The inclusion of esports as a medal event showcased broader\nacceptance and helped mitigate negative public perceptions. Moreover,\ncontributions from non-traditional stakeholders underscored the value of\ncross-subcultural collaborations in esports.",
      "tldr_zh": "这篇论文使用LLM增强的BERTopic模型和GPT-4主题微调，分析了2023年亚运会电子竞技作为奖牌项目的公众意见及其价值共同创造。研究识别了五个主要主题，包括社交媒体营销对公众影响、事件后勤和基础设施的重要性，以及非传统利益相关者（如国家代表）在促进电子竞技生态系统外价值的贡献。关键发现显示，电子竞技的纳入有助于提升其合法性、缓解负面感知，并强调跨子文化合作的潜力，尽管主流认可仍面临挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18798v1",
      "published_date": "2024-09-27 14:53:04 UTC",
      "updated_date": "2024-09-27 14:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:34:35.416506"
    },
    {
      "arxiv_id": "2409.18796v1",
      "title": "Hierarchical Federated ADMM",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Azimi-Abarghouyi",
        "Nicola Bastianello",
        "Karl H. Johansson",
        "Viktoria Fodor"
      ],
      "abstract": "In this paper, we depart from the widely-used gradient descent-based\nhierarchical federated learning (FL) algorithms to develop a novel hierarchical\nFL framework based on the alternating direction method of multipliers (ADMM).\nWithin this framework, we propose two novel FL algorithms, which both use ADMM\nin the top layer: one that employs ADMM in the lower layer and another that\nuses the conventional gradient descent-based approach. The proposed framework\nenhances privacy, and experiments demonstrate the superiority of the proposed\nalgorithms compared to the conventional algorithms in terms of learning\nconvergence and accuracy. Additionally, gradient descent on the lower layer\nperforms well even if the number of local steps is very limited, while ADMM on\nboth layers lead to better performance otherwise.",
      "tldr_zh": "本论文提出了一种基于交替方向乘子法 (ADMM) 的新型分层联邦学习 (FL) 框架，即 Hierarchical Federated ADMM，以取代传统的梯度下降方法。该框架包括两种算法：一种在顶层和下层均采用 ADMM，另一种在顶层使用 ADMM 而在下层使用梯度下降，从而增强了隐私保护。实验结果显示，这些算法在学习收敛性和准确性方面优于传统方法；此外，下层梯度下降在本地步骤有限时表现良好，而两层 ADMM 则在其他场景下提供更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "cs.SY",
        "eess.SY",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18796v1",
      "published_date": "2024-09-27 14:50:36 UTC",
      "updated_date": "2024-09-27 14:50:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:34:46.590276"
    },
    {
      "arxiv_id": "2409.18786v1",
      "title": "A Survey on the Honesty of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Siheng Li",
        "Cheng Yang",
        "Taiqiang Wu",
        "Chufan Shi",
        "Yuji Zhang",
        "Xinyu Zhu",
        "Zesen Cheng",
        "Deng Cai",
        "Mo Yu",
        "Lemao Liu",
        "Jie Zhou",
        "Yujiu Yang",
        "Ngai Wong",
        "Xixin Wu",
        "Wai Lam"
      ],
      "abstract": "Honesty is a fundamental principle for aligning large language models (LLMs)\nwith human values, requiring these models to recognize what they know and don't\nknow and be able to faithfully express their knowledge. Despite promising,\ncurrent LLMs still exhibit significant dishonest behaviors, such as confidently\npresenting wrong answers or failing to express what they know. In addition,\nresearch on the honesty of LLMs also faces challenges, including varying\ndefinitions of honesty, difficulties in distinguishing between known and\nunknown knowledge, and a lack of comprehensive understanding of related\nresearch. To address these issues, we provide a survey on the honesty of LLMs,\ncovering its clarification, evaluation approaches, and strategies for\nimprovement. Moreover, we offer insights for future research, aiming to inspire\nfurther exploration in this important area.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)的诚实性问题，认为诚实性是确保LLMs与人类价值观一致的关键，但当前模型常出现自信给出错误答案或未能表达已知知识等不诚实行为。论文澄清了诚实性的定义，分析了评估方法（如区分已知和未知知识的挑战）和改进策略，以提供全面的文献综述。最终，它为未来研究提供见解，旨在推动LLMs在诚实性方面的进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Project Page: https://github.com/SihengLi99/LLM-Honesty-Survey",
      "pdf_url": "http://arxiv.org/pdf/2409.18786v1",
      "published_date": "2024-09-27 14:34:54 UTC",
      "updated_date": "2024-09-27 14:34:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:34:57.536736"
    },
    {
      "arxiv_id": "2409.18778v1",
      "title": "HardCore Generation: Generating Hard UNSAT Problems for Data Augmentation",
      "title_zh": "HardCore 生成：生成困难的 UNSAT 问题用于数据增强",
      "authors": [
        "Joseph Cotnareanu",
        "Zhanguang Zhang",
        "Hui-Ling Zhen",
        "Yingxue Zhang",
        "Mark Coates"
      ],
      "abstract": "Efficiently determining the satisfiability of a boolean equation -- known as\nthe SAT problem for brevity -- is crucial in various industrial problems.\nRecently, the advent of deep learning methods has introduced significant\npotential for enhancing SAT solving. However, a major barrier to the\nadvancement of this field has been the scarcity of large, realistic datasets.\nThe majority of current public datasets are either randomly generated or\nextremely limited, containing only a few examples from unrelated problem\nfamilies. These datasets are inadequate for meaningful training of deep\nlearning methods. In light of this, researchers have started exploring\ngenerative techniques to create data that more accurately reflect SAT problems\nencountered in practical situations. These methods have so far suffered from\neither the inability to produce challenging SAT problems or time-scalability\nobstacles. In this paper we address both by identifying and manipulating the\nkey contributors to a problem's ``hardness'', known as cores. Although some\nprevious work has addressed cores, the time costs are unacceptably high due to\nthe expense of traditional heuristic core detection techniques. We introduce a\nfast core detection procedure that uses a graph neural network. Our empirical\nresults demonstrate that we can efficiently generate problems that remain hard\nto solve and retain key attributes of the original example problems. We show\nvia experiment that the generated synthetic SAT problems can be used in a data\naugmentation setting to provide improved prediction of solver runtimes.",
      "tldr_zh": "该论文针对布尔方程可满足性问题（SAT）的求解，解决了现有数据集稀缺和生成挑战性问题困难的问题，提出了一种名为 HardCore Generation 的框架。框架通过使用 Graph Neural Network 进行快速核心（cores）检测，并操纵这些核心来生成硬 UNSAT 问题，从而实现高效的数据增强。实验结果表明，生成的合成问题保留了原问题的关键属性，并显著提高了求解器运行时间预测的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18778v1",
      "published_date": "2024-09-27 14:24:16 UTC",
      "updated_date": "2024-09-27 14:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:35:10.726925"
    },
    {
      "arxiv_id": "2409.18769v5",
      "title": "State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features",
      "title_zh": "翻译失败",
      "authors": [
        "George R. Nahass",
        "Sasha Hubschman",
        "Jeffrey C. Peterson",
        "Ghasem Yazdanpanah",
        "Nicholas Tomaras",
        "Madison Cheung",
        "Alex Palacios",
        "Kevin Heinze",
        "Chad A. Purnell",
        "Pete Setabutr",
        "Ann Q. Tran",
        "Darvin Yi"
      ],
      "abstract": "Periorbital distances are critical markers for diagnosing and monitoring a\nrange of oculoplastic and craniofacial conditions. Manual measurement, however,\nis subjective and prone to intergrader variability. Automated methods have been\ndeveloped but remain limited by standardized imaging requirements, small\ndatasets, and a narrow focus on individual measurements. We developed a\nsegmentation pipeline trained on a domain-specific dataset of healthy eyes and\ncompared its performance against the Segment Anything Model (SAM) and the prior\nbenchmark, PeriorbitAI. Segmentation accuracy was evaluated across multiple\ndisease classes and imaging conditions. We further investigated the use of\npredicted periorbital distances as features for disease classification under\nin-distribution (ID) and out-of-distribution (OOD) settings, comparing shallow\nclassifiers, CNNs, and fusion models. Our segmentation model achieved\nstate-of-the-art accuracy across all datasets, with error rates within\nintergrader variability and superior performance relative to SAM and\nPeriorbitAI. In classification tasks, models trained on periorbital distances\nmatched CNN performance on ID data (77--78\\% accuracy) and substantially\noutperformed CNNs under OOD conditions (63--68\\% accuracy vs. 14\\%). Fusion\nmodels achieved the highest ID accuracy (80\\%) but were sensitive to degraded\nCNN features under OOD shifts. Segmentation-derived periorbital distances\nprovide robust, explainable features for disease classification and generalize\nbetter under domain shift than CNN image classifiers. These results establish a\nnew benchmark for periorbital distance prediction and highlight the potential\nof anatomy-based AI pipelines for real-world deployment in oculoplastic and\ncraniofacial care.",
      "tldr_zh": "该研究开发了一种先进的分割管道，使用特定数据集预测 periorbital distances，并将其作为特征进行眼部和颅面疾病分类，以解决手动测量主观性和现有方法局限性。相比 Segment Anything Model (SAM) 和 PeriorbitAI，该管道在多种疾病和成像条件下实现了 state-of-the-art 准确性，错误率处于评估者间变异范围内。实验显示，使用 periorbital distances 的模型在 in-distribution (ID) 数据上与 CNN 相当（77-78% 准确率），而在 out-of-distribution (OOD) 条件下显著优于 CNN（63-68% vs. 14%），融合模型则在 ID 上达到最高准确率（80%）。这些结果确立了 periorbital distance prediction 的新基准，并证明了基于解剖学的 AI 管道在实际眼部护理中的鲁棒性和泛化潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 12 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.18769v5",
      "published_date": "2024-09-27 14:14:16 UTC",
      "updated_date": "2025-05-14 16:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:35:24.644953"
    },
    {
      "arxiv_id": "2409.18768v3",
      "title": "Learning from Demonstration with Implicit Nonlinear Dynamics Models",
      "title_zh": "基于隐式非线性动力学模型的从演示学习",
      "authors": [
        "Peter David Fagan",
        "Subramanian Ramamoorthy"
      ],
      "abstract": "Learning from Demonstration (LfD) is a useful paradigm for training policies\nthat solve tasks involving complex motions, such as those encountered in\nrobotic manipulation. In practice, the successful application of LfD requires\novercoming error accumulation during policy execution, i.e. the problem of\ndrift due to errors compounding over time and the consequent\nout-of-distribution behaviours. Existing works seek to address this problem\nthrough scaling data collection, correcting policy errors with a\nhuman-in-the-loop, temporally ensembling policy predictions or through learning\na dynamical system model with convergence guarantees. In this work, we propose\nand validate an alternative approach to overcoming this issue. Inspired by\nreservoir computing, we develop a recurrent neural network layer that includes\na fixed nonlinear dynamical system with tunable dynamical properties for\nmodelling temporal dynamics. We validate the efficacy of our neural network\nlayer on the task of reproducing human handwriting motions using the LASA Human\nHandwriting Dataset. Through empirical experiments we demonstrate that\nincorporating our layer into existing neural network architectures addresses\nthe issue of compounding errors in LfD. Furthermore, we perform a comparative\nevaluation against existing approaches including a temporal ensemble of policy\npredictions and an Echo State Network (ESN) implementation. We find that our\napproach yields greater policy precision and robustness on the handwriting task\nwhile also generalising to multiple dynamics regimes and maintaining\ncompetitive latency scores.",
      "tldr_zh": "本文提出了一种基于隐式非线性动态模型的学习从演示 (LfD) 方法，以解决机器人操作任务中错误积累导致的漂移问题。受 reservoir computing 启发，该方法开发了一个包含固定非线性动态系统的循环神经网络层，用于建模时间动态，并允许动态属性的可调。实验在 LASA Human Handwriting Dataset 上验证了其效果，显示该层能有效减少错误积累，提供更高的策略精度和鲁棒性，同时与 Echo State Network (ESN) 等现有方法相比，具有更好的泛化性和竞争性延迟表现。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18768v3",
      "published_date": "2024-09-27 14:12:49 UTC",
      "updated_date": "2025-02-11 16:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:35:34.867178"
    },
    {
      "arxiv_id": "2409.18743v1",
      "title": "OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Tang",
        "Meiling Wang",
        "Yinan Deng",
        "Zibo Zheng",
        "Jiagui Zhong",
        "Yufeng Yue"
      ],
      "abstract": "In everyday life, frequently used objects like cups often have unfixed\npositions and multiple instances within the same category, and their carriers\nfrequently change as well. As a result, it becomes challenging for a robot to\nefficiently navigate to a specific instance. To tackle this challenge, the\nrobot must capture and update scene changes and plans continuously. However,\ncurrent object navigation approaches primarily focus on semantic-level and lack\nthe ability to dynamically update scene representation. This paper captures the\nrelationships between frequently used objects and their static carriers. It\nconstructs an open-vocabulary Carrier-Relationship Scene Graph (CRSG) and\nupdates the carrying status during robot navigation to reflect the dynamic\nchanges of the scene. Based on the CRSG, we further propose an instance\nnavigation strategy that models the navigation process as a Markov Decision\nProcess. At each step, decisions are informed by Large Language Model's\ncommonsense knowledge and visual-language feature similarity. We designed a\nseries of long-sequence navigation tasks for frequently used everyday items in\nthe Habitat simulator. The results demonstrate that by updating the CRSG, the\nrobot can efficiently navigate to moved targets. Additionally, we deployed our\nalgorithm on a real robot and validated its practical effectiveness.",
      "tldr_zh": "该论文针对机器人导航中日常物体（如杯子）位置不固定、多实例及载体动态变化的挑战，提出了一种基于动态 Carrier-Relationship Scene Graph (CRSG) 的开放词汇物体导向导航框架 OpenObject-NAV。该框架通过捕捉物体与静态载体之间的关系，并在导航过程中实时更新 CRSG，以动态反映场景变化，并将导航过程建模为 Markov Decision Process (MDP)。决策过程结合 Large Language Model (LLM) 的常识知识和视觉-语言特征相似度，提高了导航效率。在 Habitat 模拟器中进行的长序列任务实验显示，该方法能有效导航到移动目标，准确率显著提升，并在真实机器人上验证了其实用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://openobject-nav.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2409.18743v1",
      "published_date": "2024-09-27 13:33:52 UTC",
      "updated_date": "2024-09-27 13:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:35:46.488762"
    },
    {
      "arxiv_id": "2409.18735v1",
      "title": "Autoregressive Policy Optimization for Constrained Allocation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "David Winkel",
        "Niklas Strauß",
        "Maximilian Bernhard",
        "Zongyue Li",
        "Thomas Seidl",
        "Matthias Schubert"
      ],
      "abstract": "Allocation tasks represent a class of problems where a limited amount of\nresources must be allocated to a set of entities at each time step. Prominent\nexamples of this task include portfolio optimization or distributing\ncomputational workloads across servers. Allocation tasks are typically bound by\nlinear constraints describing practical requirements that have to be strictly\nfulfilled at all times. In portfolio optimization, for example, investors may\nbe obligated to allocate less than 30\\% of the funds into a certain industrial\nsector in any investment period. Such constraints restrict the action space of\nallowed allocations in intricate ways, which makes learning a policy that\navoids constraint violations difficult. In this paper, we propose a new method\nfor constrained allocation tasks based on an autoregressive process to\nsequentially sample allocations for each entity. In addition, we introduce a\nnovel de-biasing mechanism to counter the initial bias caused by sequential\nsampling. We demonstrate the superior performance of our approach compared to a\nvariety of Constrained Reinforcement Learning (CRL) methods on three distinct\nconstrained allocation tasks: portfolio optimization, computational workload\ndistribution, and a synthetic allocation benchmark. Our code is available at:\nhttps://github.com/niklasdbs/paspo",
      "tldr_zh": "这篇论文针对约束分配任务（如投资组合优化或计算工作负载分布）提出了一种基于自回归过程(Autoregressive process)的策略优化方法，通过顺序采样每个实体的分配来避免线性约束违反。论文引入了一个新型去偏机制(de-biasing mechanism)，以抵消顺序采样带来的初始偏置，从而提升策略的鲁棒性。在三个任务上进行的实验表明，该方法比传统Constrained Reinforcement Learning (CRL)方法表现出色，准确性和效率均有显著提升。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18735v1",
      "published_date": "2024-09-27 13:27:15 UTC",
      "updated_date": "2024-09-27 13:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:35:58.201267"
    },
    {
      "arxiv_id": "2409.18715v1",
      "title": "Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification",
      "title_zh": "多模态医学图像融合用于非小细胞肺癌分类",
      "authors": [
        "Salma Hassan",
        "Hamad Al Hammadi",
        "Ibrahim Mohammed",
        "Muhammad Haris Khan"
      ],
      "abstract": "The early detection and nuanced subtype classification of non-small cell lung\ncancer (NSCLC), a predominant cause of cancer mortality worldwide, is a\ncritical and complex issue. In this paper, we introduce an innovative\nintegration of multi-modal data, synthesizing fused medical imaging (CT and PET\nscans) with clinical health records and genomic data. This unique fusion\nmethodology leverages advanced machine learning models, notably MedClip and\nBEiT, for sophisticated image feature extraction, setting a new standard in\ncomputational oncology. Our research surpasses existing approaches, as\nevidenced by a substantial enhancement in NSCLC detection and classification\nprecision. The results showcase notable improvements across key performance\nmetrics, including accuracy, precision, recall, and F1-score. Specifically, our\nleading multi-modal classifier model records an impressive accuracy of 94.04%.\nWe believe that our approach has the potential to transform NSCLC diagnostics,\nfacilitating earlier detection and more effective treatment planning and,\nultimately, leading to superior patient outcomes in lung cancer care.",
      "tldr_zh": "本研究针对非小细胞肺癌 (NSCLC) 的早期检测和亚型分类问题，提出了一种创新的多模态医疗图像融合方法，将 CT 和 PET 扫描图像与临床健康记录及基因组数据整合。利用 MedClip 和 BEiT 等高级机器学习模型进行图像特征提取，该方法显著提升了 NSCLC 检测和分类的精确性。实验结果显示，该多模态分类器在关键指标上表现出色，包括准确率达到 94.04%、精确率、召回率和 F1-score 的整体改善。该方法有望革新 NSCLC 诊断流程，促进早期发现和更有效的治疗规划，从而提升患者预后。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18715v1",
      "published_date": "2024-09-27 12:59:29 UTC",
      "updated_date": "2024-09-27 12:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:36:10.168784"
    },
    {
      "arxiv_id": "2409.18708v4",
      "title": "Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity",
      "title_zh": "翻译失败",
      "authors": [
        "Sergey Berezin",
        "Reza Farahbakhsh",
        "Noel Crespi"
      ],
      "abstract": "We introduce a novel family of adversarial attacks that exploit the inability\nof language models to interpret ASCII art. To evaluate these attacks, we\npropose the ToxASCII benchmark and develop two custom ASCII art fonts: one\nleveraging special tokens and another using text-filled letter shapes. Our\nattacks achieve a perfect 1.0 Attack Success Rate across ten models, including\nOpenAI's o1-preview and LLaMA 3.1.\n  Warning: this paper contains examples of toxic language used for research\npurposes.",
      "tldr_zh": "本研究提出了一种新型对抗攻击方法，利用 ASCII art 来掩盖脏话，从而攻击大型语言模型(LLMs)和毒性检测系统。该方法开发了 ToxASCII 基准以及两种自定义 ASCII art 字体（一个基于特殊标记，另一个使用文本填充的字母形状），成功规避了模型的检测。在包括 OpenAI's o1-preview 和 LLaMA 3.1 在内的十个模型上，攻击实现了完美的 1.0 攻击成功率。注意：论文中包含用于研究目的的毒性语言示例。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18708v4",
      "published_date": "2024-09-27 12:54:13 UTC",
      "updated_date": "2024-10-09 12:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:36:23.463006"
    },
    {
      "arxiv_id": "2409.18705v1",
      "title": "Speech Boosting: Low-Latency Live Speech Enhancement for TWS Earbuds",
      "title_zh": "翻译失败",
      "authors": [
        "Hanbin Bae",
        "Pavel Andreev",
        "Azat Saginbaev",
        "Nicholas Babaev",
        "Won-Jun Lee",
        "Hosang Sung",
        "Hoon-Young Cho"
      ],
      "abstract": "This paper introduces a speech enhancement solution tailored for true\nwireless stereo (TWS) earbuds on-device usage. The solution was specifically\ndesigned to support conversations in noisy environments, with active noise\ncancellation (ANC) activated. The primary challenges for speech enhancement\nmodels in this context arise from computational complexity that limits\non-device usage and latency that must be less than 3 ms to preserve a live\nconversation. To address these issues, we evaluated several crucial design\nelements, including the network architecture and domain, design of loss\nfunctions, pruning method, and hardware-specific optimization. Consequently, we\ndemonstrated substantial improvements in speech enhancement quality compared\nwith that in baseline models, while simultaneously reducing the computational\ncomplexity and algorithmic latency.",
      "tldr_zh": "这篇论文提出了一种名为 Speech Boosting 的语音增强解决方案，针对 TWS Earbuds 的设备端应用，旨在在嘈杂环境中支持实时对话并启用主动噪声消除 (ANC)，同时确保延迟低于 3 ms。研究者评估了关键设计元素，包括网络架构、损失函数设计、修剪方法和硬件特定优化，以解决计算复杂性和延迟挑战。结果表明，该方案显著提升了语音增强质量，同时降低了计算复杂性和算法延迟。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted by Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18705v1",
      "published_date": "2024-09-27 12:47:36 UTC",
      "updated_date": "2024-09-27 12:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:36:33.985339"
    },
    {
      "arxiv_id": "2409.18704v1",
      "title": "Semantic Model Component Implementation for Model-driven Semantic Communications",
      "title_zh": "用于模型驱动语义通信的语义模型组件实现",
      "authors": [
        "Haotai Liang",
        "Mengran Shi",
        "Chen Dong",
        "Xiaodong Xu",
        "Long Liu",
        "Hao Chen"
      ],
      "abstract": "The key feature of model-driven semantic communication is the propagation of\nthe model. The semantic model component (SMC) is designed to drive the\nintelligent model to transmit in the physical channel, allowing the\nintelligence to flow through the networks. According to the characteristics of\nneural networks with common and individual model parameters, this paper designs\nthe cross-source-domain and cross-task semantic component model. Considering\nthat the basic model is deployed on the edge node, the large server node\nupdates the edge node by transmitting only the semantic component model to the\nedge node so that the edge node can handle different sources and different\ntasks. In addition, this paper also discusses how channel noise affects the\nperformance of the model and proposes methods of injection noise and\nregularization to improve the noise resistance of the model. Experiments show\nthat SMCs use smaller model parameters to achieve cross-source, cross-task\nfunctionality while maintaining performance and improving the model's tolerance\nto noise. Finally, a component transfer-based unmanned vehicle tracking\nprototype was implemented to verify the feasibility of model components in\npractical applications.",
      "tldr_zh": "该论文针对模型驱动语义通信（model-driven semantic communications）设计了语义模型组件（SMC），以实现神经网络模型的传播和智能流动，特别是通过跨源域和跨任务的语义组件模型，使边缘节点能处理不同来源和任务，仅需传输较少的模型参数。方法包括在大型服务器节点上更新并传输SMC到边缘节点，同时提出注入噪声和正则化技术来提升模型对通道噪声的耐受性。实验结果显示，SMC在使用更小参数量的基础上，实现了跨源跨任务功能，同时保持了性能并提高了噪声抗性。最后，通过基于组件传输的无人物流跟踪原型，验证了SMC在实际应用中的可行性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18704v1",
      "published_date": "2024-09-27 12:45:57 UTC",
      "updated_date": "2024-09-27 12:45:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:36:58.117714"
    },
    {
      "arxiv_id": "2409.18695v2",
      "title": "KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic Enhanced Large Model",
      "title_zh": "翻译失败",
      "authors": [
        "Weichen Dai",
        "Yezeng Chen",
        "Zijie Dai",
        "Yubo Liu",
        "Zhijie Huang",
        "Yixuan Pan",
        "Baiyang Song",
        "Chengli Zhong",
        "Xinhe Li",
        "Zeyu Wang",
        "Zhuoying Feng",
        "Yi Zhou"
      ],
      "abstract": "Artificial intelligence is gradually demonstrating its immense potential, and\nincreasing attention is being given to how AI can be harnessed to advance\nscientific research. In this vision paper, we present our perspectives on how\nAI can better assist scientific inquiry and explore corresponding technical\napproach. We have proposed and open-sourced two large models of our KALE-LM\nmodel series, KALE-LM-Chem(-1.5), which have achieved outstanding performance\nin tasks related to the field of chemistry. We hope that our work serves as a\nstrong starting point, helping to realize more intelligent AI and promoting the\nadvancement of human science and technology, as well as societal development.",
      "tldr_zh": "这篇论文探讨了如何通过知识和逻辑增强（Knowledge and Logic Enhanced）的大型模型（KALE-LM）来释放 AI 在科学研究中的潜力，强调了 AI 辅助科学探究的技术路径。作者开源了 KALE-LM 系列中的 KALE-LM-Chem(-1.5) 模型，该模型在化学相关任务中表现出色。总体而言，该工作旨在为更智能的 AI 提供起点，促进人类科学、技术和社会发展。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18695v2",
      "published_date": "2024-09-27 12:33:57 UTC",
      "updated_date": "2025-04-07 10:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:36:58.377520"
    },
    {
      "arxiv_id": "2409.18694v2",
      "title": "Learning from Pattern Completion: Self-supervised Controllable Generation",
      "title_zh": "从模式完成中学习：自监督可控生成",
      "authors": [
        "Zhiqiang Chen",
        "Guofan Fan",
        "Jinying Gao",
        "Lei Ma",
        "Bo Lei",
        "Tiejun Huang",
        "Shan Yu"
      ],
      "abstract": "The human brain exhibits a strong ability to spontaneously associate\ndifferent visual attributes of the same or similar visual scene, such as\nassociating sketches and graffiti with real-world visual objects, usually\nwithout supervising information. In contrast, in the field of artificial\nintelligence, controllable generation methods like ControlNet heavily rely on\nannotated training datasets such as depth maps, semantic segmentation maps, and\nposes, which limits the method's scalability. Inspired by the neural mechanisms\nthat may contribute to the brain's associative power, specifically the cortical\nmodularization and hippocampal pattern completion, here we propose a\nself-supervised controllable generation (SCG) framework. Firstly, we introduce\nan equivariant constraint to promote inter-module independence and intra-module\ncorrelation in a modular autoencoder network, thereby achieving functional\nspecialization. Subsequently, based on these specialized modules, we employ a\nself-supervised pattern completion approach for controllable generation\ntraining. Experimental results demonstrate that the proposed modular\nautoencoder effectively achieves functional specialization, including the\nmodular processing of color, brightness, and edge detection, and exhibits\nbrain-like features including orientation selectivity, color antagonism, and\ncenter-surround receptive fields. Through self-supervised training, associative\ngeneration capabilities spontaneously emerge in SCG, demonstrating excellent\ngeneralization ability to various tasks such as associative generation on\npainting, sketches, and ancient graffiti. Compared to the previous\nrepresentative method ControlNet, our proposed approach not only demonstrates\nsuperior robustness in more challenging high-noise scenarios but also possesses\nmore promising scalability potential due to its self-supervised manner.Codes\nare released on Github and Gitee.",
      "tldr_zh": "这篇论文受人类大脑的关联机制（如皮层模块化和海马体模式完成）启发，提出了一种自监督可控生成（SCG）框架，以实现无需标注数据的图像生成控制。具体方法包括引入equivariant constraint在模块化自编码器中，促进模块间独立性和模块内相关性，从而实现功能专业化，如颜色、亮度和边缘检测的处理。实验结果表明，SCG框架自发产生关联生成能力，在绘画、素描和古董涂鸦等任务上表现出色，并比ControlNet在高噪声场景具有更强的鲁棒性和更好的可扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18694v2",
      "published_date": "2024-09-27 12:28:47 UTC",
      "updated_date": "2024-11-07 08:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:37:11.096893"
    },
    {
      "arxiv_id": "2409.18692v1",
      "title": "MG-Net: Learn to Customize QAOA with Circuit Depth Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Qian",
        "Xinbiao Wang",
        "Yuxuan Du",
        "Yong Luo",
        "Dacheng Tao"
      ],
      "abstract": "Quantum Approximate Optimization Algorithm (QAOA) and its variants exhibit\nimmense potential in tackling combinatorial optimization challenges. However,\ntheir practical realization confronts a dilemma: the requisite circuit depth\nfor satisfactory performance is problem-specific and often exceeds the maximum\ncapability of current quantum devices. To address this dilemma, here we first\nanalyze the convergence behavior of QAOA, uncovering the origins of this\ndilemma and elucidating the intricate relationship between the employed mixer\nHamiltonian, the specific problem at hand, and the permissible maximum circuit\ndepth. Harnessing this understanding, we introduce the Mixer Generator Network\n(MG-Net), a unified deep learning framework adept at dynamically formulating\noptimal mixer Hamiltonians tailored to distinct tasks and circuit depths.\nSystematic simulations, encompassing Ising models and weighted Max-Cut\ninstances with up to 64 qubits, substantiate our theoretical findings,\nhighlighting MG-Net's superior performance in terms of both approximation ratio\nand efficiency.",
      "tldr_zh": "该论文分析了 Quantum Approximate Optimization Algorithm (QAOA) 在解决组合优化问题时的困境，即所需电路深度往往超出当前量子设备的限制，并揭示了 mixer Hamiltonian、具体问题和最大电路深度之间的复杂关系。为此，作者提出 Mixer Generator Network (MG-Net)，一个统一的深度学习框架，能够动态生成针对特定任务和电路深度的最优 mixer Hamiltonian。实验模拟包括 Ising models 和权重 Max-Cut 实例（最多 64 量子位），结果显示 MG-Net 在逼近比和效率上均优于传统方法，从而为实用量子优化算法提供了可扩展的解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "29 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18692v1",
      "published_date": "2024-09-27 12:28:18 UTC",
      "updated_date": "2024-09-27 12:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:37:22.469892"
    },
    {
      "arxiv_id": "2409.18680v3",
      "title": "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models",
      "title_zh": "超越单一音频：推进音频大型语言模型中的多音频处理",
      "authors": [
        "Yiming Chen",
        "Xianghu Yue",
        "Xiaoxue Gao",
        "Chen Zhang",
        "Luis Fernando D'Haro",
        "Robby T. Tan",
        "Haizhou Li"
      ],
      "abstract": "Various audio-LLMs (ALLMs) have been explored recently for tackling different\naudio tasks simultaneously using a single, unified model. While existing\nevaluations of ALLMs primarily focus on single-audio tasks, real-world\napplications often involve processing multiple audio streams simultaneously. To\nbridge this gap, we propose the first multi-audio evaluation (MAE) benchmark\nthat consists of 20 datasets from 11 multi-audio tasks encompassing both speech\nand sound scenarios. Comprehensive experiments on MAE demonstrate that the\nexisting ALLMs, while being powerful in comprehending primary audio elements in\nindividual audio inputs, struggling to handle multi-audio scenarios. To this\nend, we propose a novel multi-audio-LLM (MALLM) to capture audio context among\nmultiple similar audios using discriminative learning on our proposed synthetic\ndata. The results demonstrate that the proposed MALLM outperforms all baselines\nand achieves high data efficiency using synthetic data without requiring human\nannotations. The proposed MALLM opens the door for ALLMs towards multi-audio\nprocessing era and brings us closer to replicating human auditory capabilities\nin machines.",
      "tldr_zh": "这篇论文指出现有音频大型语言模型（ALLMs）在处理单个音频任务时表现出色，但多音频场景下表现不佳，并提出首个多音频评估基准（MAE），包括20个数据集和11个任务，涵盖语音和声音领域。针对这一问题，研究者开发了新型多音频LLM（MALLM），通过判别学习和合成数据捕捉多个相似音频间的上下文，实现高效处理而不需人工标注。实验结果显示，MALLM优于所有基线模型，并在数据效率上表现出色，推动ALLMs向多音频处理时代发展，并使机器更接近人类听觉能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "EMNLP24 Findings. Data available at\n  https://github.com/MatthewCYM/MALLM",
      "pdf_url": "http://arxiv.org/pdf/2409.18680v3",
      "published_date": "2024-09-27 12:06:53 UTC",
      "updated_date": "2024-11-06 10:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:37:34.716788"
    },
    {
      "arxiv_id": "2409.18676v2",
      "title": "Toward Universal and Interpretable World Models for Open-ended Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Lancelot Da Costa"
      ],
      "abstract": "We introduce a generic, compositional and interpretable class of generative\nworld models that supports open-ended learning agents. This is a sparse class\nof Bayesian networks capable of approximating a broad range of stochastic\nprocesses, which provide agents with the ability to learn world models in a\nmanner that may be both interpretable and computationally scalable. This\napproach integrating Bayesian structure learning and intrinsically motivated\n(model-based) planning enables agents to actively develop and refine their\nworld models, which may lead to developmental learning and more robust,\nadaptive behavior.",
      "tldr_zh": "该研究提出了一种通用、可组合且可解释的生成世界模型类，用于支持开放式学习代理。该模型基于稀疏的Bayesian networks，能够近似多种stochastic processes，从而以可解释和可扩展的方式帮助代理学习世界模型。通过整合Bayesian structure learning和intrinsically motivated planning，代理能够主动开发和完善其模型，促进发展性学习以及更稳健的适应行为。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages including appendix, 6 including appendix and references; 2\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18676v2",
      "published_date": "2024-09-27 12:03:15 UTC",
      "updated_date": "2024-10-15 16:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:37:46.027783"
    },
    {
      "arxiv_id": "2409.18673v1",
      "title": "Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras",
      "title_zh": "翻译失败",
      "authors": [
        "Yipeng Lu",
        "Yifan Zhao",
        "Haiping Wang",
        "Zhiwei Ruan",
        "Yuan Liu",
        "Zhen Dong",
        "Bisheng Yang"
      ],
      "abstract": "Dashboard cameras (dashcams) record millions of driving videos daily,\noffering a valuable potential data source for various applications, including\ndriving map production and updates. A necessary step for utilizing these\ndashcam data involves the estimation of camera poses. However, the low-quality\nimages captured by dashcams, characterized by motion blurs and dynamic objects,\npose challenges for existing image-matching methods in accurately estimating\ncamera poses. In this study, we propose a precise pose estimation method for\ndashcam images, leveraging the inherent camera motion prior. Typically, image\nsequences captured by dash cameras exhibit pronounced motion prior, such as\nforward movement or lateral turns, which serve as essential cues for\ncorrespondence estimation. Building upon this observation, we devise a pose\nregression module aimed at learning camera motion prior, subsequently\nintegrating these prior into both correspondences and pose estimation\nprocesses. The experiment shows that, in real dashcams dataset, our method is\n22% better than the baseline for pose estimation in AUC5\\textdegree, and it can\nestimate poses for 19% more images with less reprojection error in Structure\nfrom Motion (SfM).",
      "tldr_zh": "这篇论文针对仪表盘摄像头(dashcams)图像的姿态估计问题，提出了一种利用摄像头固有运动先验(motion prior)的方法，以克服图像质量低、运动模糊和动态物体带来的挑战。该方法设计了一个姿态回归模块来学习运动先验，并将其整合到对应点估计和姿态估计流程中。实验结果显示，在真实数据集上，该方法比基线模型在AUC5°指标上提高了22%，并为19%更多的图像成功估计姿态，同时减少了Structure from Motion (SfM)中的重投影错误。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18673v1",
      "published_date": "2024-09-27 11:59:00 UTC",
      "updated_date": "2024-09-27 11:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:37:59.421012"
    },
    {
      "arxiv_id": "2409.18661v1",
      "title": "Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice",
      "title_zh": "翻译失败",
      "authors": [
        "Eddie Antonio Santos",
        "Brett A. Becker"
      ],
      "abstract": "The sudden emergence of large language models (LLMs) such as ChatGPT has had\na disruptive impact throughout the computing education community. LLMs have\nbeen shown to excel at producing correct code to CS1 and CS2 problems, and can\neven act as friendly assistants to students learning how to code. Recent work\nshows that LLMs demonstrate unequivocally superior results in being able to\nexplain and resolve compiler error messages -- for decades, one of the most\nfrustrating parts of learning how to code. However, LLM-generated error message\nexplanations have only been assessed by expert programmers in artificial\nconditions. This work sought to understand how novice programmers resolve\nprogramming error messages (PEMs) in a more realistic scenario. We ran a\nwithin-subjects study with $n$ = 106 participants in which students were tasked\nto fix six buggy C programs. For each program, participants were randomly\nassigned to fix the problem using either a stock compiler error message, an\nexpert-handwritten error message, or an error message explanation generated by\nGPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4\ngenerated error messages outperformed conventional compiler error messages in\nonly 1 of the 6 tasks, measured by students' time-to-fix each problem.\nHandwritten explanations still outperform LLM and conventional error messages,\nboth on objective and subjective measures.",
      "tldr_zh": "该研究评估了大型语言模型 (LLMs) 如 GPT-4 在解释编程错误消息 (PEMs) 方面的实际效果，挑战了先前在人工条件下取得的优越表现。研究通过一个内部受试者实验 (within-subjects study)，让 106 名新手程序员修复六个有 bug 的 C 程序，并比较了标准编译器错误消息、专家手写消息和 GPT-4 生成消息的表现。结果显示，GPT-4 生成的消息仅在 6 个任务中优于传统消息的 1 个，而手写消息在时间修复效率和主观满意度上均表现最佳，表明 LLMs 并非解决编程教育中错误消息问题的“银弹”。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in the proceedings of the 2024 UK and Ireland Computing\n  Education Research conference (UKICER '24)",
      "pdf_url": "http://arxiv.org/pdf/2409.18661v1",
      "published_date": "2024-09-27 11:45:56 UTC",
      "updated_date": "2024-09-27 11:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:38:11.215499"
    },
    {
      "arxiv_id": "2409.18660v1",
      "title": "Effects of AI Feedback on Learning, the Skill Gap, and Intellectual Diversity",
      "title_zh": "AI 反馈对学习、技能差距和智力多样性的影响",
      "authors": [
        "Christoph Riedl",
        "Eric Bogert"
      ],
      "abstract": "Can human decision-makers learn from AI feedback? Using data on 52,000\ndecision-makers from a large online chess platform, we investigate how their AI\nuse affects three interrelated long-term outcomes: Learning, skill gap, and\ndiversity of decision strategies. First, we show that individuals are far more\nlikely to seek AI feedback in situations in which they experienced success\nrather than failure. This AI feedback seeking strategy turns out to be\ndetrimental to learning: Feedback on successes decreases future performance,\nwhile feedback on failures increases it. Second, higher-skilled decision-makers\nseek AI feedback more often and are far more likely to seek AI feedback after a\nfailure, and benefit more from AI feedback than lower-skilled individuals. As a\nresult, access to AI feedback increases, rather than decreases, the skill gap\nbetween high- and low-skilled individuals. Finally, we leverage 42 major\nplatform updates as natural experiments to show that access to AI feedback\ncauses a decrease in intellectual diversity of the population as individuals\ntend to specialize in the same areas. Together, those results indicate that\nlearning from AI feedback is not automatic and using AI correctly seems to be a\nskill itself. Furthermore, despite its individual-level benefits, access to AI\nfeedback can have significant population-level downsides including loss of\nintellectual diversity and an increasing skill gap.",
      "tldr_zh": "本研究利用52,000名在线国际象棋平台决策者的数据，探讨AI feedback对学习、skill gap和intellectual diversity的影响，发现决策者更倾向于在成功时寻求AI feedback，这反而降低了未来表现，而失败时的反馈则提升了学习效果。高技能决策者更频繁地使用AI feedback并从中获益更多，导致skill gap扩大。通过42个平台更新作为自然实验，研究显示AI feedback访问减少了intellectual diversity。总体结论是，从AI feedback中学习并非自动，使用AI本身是一种技能，其广泛应用可能加剧不平等和多样性损失。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.HC",
        "q-fin.EC",
        "68T01",
        "I.2; J.4"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18660v1",
      "published_date": "2024-09-27 11:44:03 UTC",
      "updated_date": "2024-09-27 11:44:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:38:23.868746"
    },
    {
      "arxiv_id": "2409.18653v2",
      "title": "When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation",
      "title_zh": "当 SAM2 遇上视频伪装物体分割：一个全面评估与适应",
      "authors": [
        "Yuli Zhou",
        "Guolei Sun",
        "Yawei Li",
        "Guo-Sen Xie",
        "Luca Benini",
        "Ender Konukoglu"
      ],
      "abstract": "This study investigates the application and performance of the Segment\nAnything Model 2 (SAM2) in the challenging task of video camouflaged object\nsegmentation (VCOS). VCOS involves detecting objects that blend seamlessly in\nthe surroundings for videos, due to similar colors and textures, poor light\nconditions, etc. Compared to the objects in normal scenes, camouflaged objects\nare much more difficult to detect. SAM2, a video foundation model, has shown\npotential in various tasks. But its effectiveness in dynamic camouflaged\nscenarios remains under-explored. This study presents a comprehensive study on\nSAM2's ability in VCOS. First, we assess SAM2's performance on camouflaged\nvideo datasets using different models and prompts (click, box, and mask).\nSecond, we explore the integration of SAM2 with existing multimodal large\nlanguage models (MLLMs) and VCOS methods. Third, we specifically adapt SAM2 by\nfine-tuning it on the video camouflaged dataset. Our comprehensive experiments\ndemonstrate that SAM2 has excellent zero-shot ability of detecting camouflaged\nobjects in videos. We also show that this ability could be further improved by\nspecifically adjusting SAM2's parameters for VCOS. The code is available at\nhttps://github.com/zhoustan/SAM2-VCOS",
      "tldr_zh": "本研究评估了 Segment Anything Model 2 (SAM2) 在视频伪装物体分割 (VCOS) 任务中的性能，VCOS 涉及检测与环境融为一体的动态物体，如颜色纹理相似或光线不足的场景。\n研究方法包括使用不同提示（click, box, mask）测试 SAM2 的表现、探索其与多模态大型语言模型 (MLLMs) 和现有 VCOS 方法的整合，以及通过在伪装视频数据集上微调来专门适应 SAM2。\n实验结果显示，SAM2 具有优秀的零样本检测能力，而经过参数调整后，其性能进一步提升。\n这项工作为 SAM2 在复杂视频场景中的应用提供了全面见解，并公开了代码（https://github.com/zhoustan/SAM2-VCOS）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report. Accepted by Visual Intelligence. Code is released\n  at https://github.com/zhoustan/SAM2-VCOS",
      "pdf_url": "http://arxiv.org/pdf/2409.18653v2",
      "published_date": "2024-09-27 11:35:50 UTC",
      "updated_date": "2025-05-10 02:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:38:35.611820"
    },
    {
      "arxiv_id": "2409.18642v1",
      "title": "Enhanced Convolution Neural Network with Optimized Pooling and Hyperparameter Tuning for Network Intrusion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush Kumar Sharma",
        "Sourav Patel",
        "Supriya Bharat Wakchaure",
        "Abirami S"
      ],
      "abstract": "Network Intrusion Detection Systems (NIDS) are essential for protecting\ncomputer networks from malicious activities, including Denial of Service (DoS),\nProbing, User-to-Root (U2R), and Remote-to-Local (R2L) attacks. Without\neffective NIDS, networks are vulnerable to significant security breaches and\ndata loss. Machine learning techniques provide a promising approach to enhance\nNIDS by automating threat detection and improving accuracy. In this research,\nwe propose an Enhanced Convolutional Neural Network (EnCNN) for NIDS and\nevaluate its performance using the KDDCUP'99 dataset. Our methodology includes\ncomprehensive data preprocessing, exploratory data analysis (EDA), and feature\nengineering. We compare EnCNN with various machine learning algorithms,\nincluding Logistic Regression, Decision Trees, Support Vector Machines (SVM),\nand ensemble methods like Random Forest, AdaBoost, and Voting Ensemble. The\nresults show that EnCNN significantly improves detection accuracy, with a\nnotable 10% increase over state-of-art approaches. This demonstrates the\neffectiveness of EnCNN in real-time network intrusion detection, offering a\nrobust solution for identifying and mitigating security threats, and enhancing\noverall network resilience.",
      "tldr_zh": "本研究提出了一种Enhanced Convolutional Neural Network (EnCNN)模型，用于网络入侵检测系统 (NIDS)，旨在提升对DoS、Probing、U2R和R2L等攻击的检测准确率。\nEnCNN通过优化池化层和超参数调整、结合数据预处理、探索性数据分析 (EDA) 和特征工程的方法，与Logistic Regression、Decision Trees、SVM、Random Forest、AdaBoost和Voting Ensemble等算法进行比较。\n实验结果显示，EnCNN在KDDCUP'99数据集上比现有方法提高了10%的检测准确率。\n该模型为实时网络入侵检测提供了稳健的解决方案，增强了网络的安全性和整体弹性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "7 Pages , 2 figures , 4 Tables , Conference paper",
      "pdf_url": "http://arxiv.org/pdf/2409.18642v1",
      "published_date": "2024-09-27 11:20:20 UTC",
      "updated_date": "2024-09-27 11:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:38:59.003720"
    },
    {
      "arxiv_id": "2409.18633v1",
      "title": "Reducing Diversity to Generate Hierarchical Archetypes",
      "title_zh": "翻译失败",
      "authors": [
        "Alfredo Ibias",
        "Hector Antona",
        "Guillem Ramirez-Miranda",
        "Enric Guinovart",
        "Eduard Alarcon"
      ],
      "abstract": "The Artificial Intelligence field seldom address the development of a\nfundamental building piece: a framework, methodology or algorithm to\nautomatically build hierarchies of abstractions. This is a key requirement in\norder to build intelligent behaviour, as recent neuroscience studies clearly\nexpose. In this paper we present a primitive-based framework to automatically\ngenerate hierarchies of constructive archetypes, as a theory of how to generate\nhierarchies of abstractions. We assume the existence of a primitive with very\nspecific characteristics, and we develop our framework over it. We prove the\neffectiveness of our framework through mathematical definitions and proofs.\nFinally, we give a few insights about potential uses of our framework and the\nexpected results.",
      "tldr_zh": "本论文指出，人工智能领域鲜少开发自动构建抽象层次的框架或算法，这对智能行为至关重要，如神经科学研究所示。作者提出一个基于原始（primitive）的框架，用于自动生成层次化的构造性 archetypes，通过假设一个具有特定特征的原始并运用数学定义和证明来验证其有效性。该框架的潜在应用包括提升智能系统构建，并提供对抽象层次生成理论的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18633v1",
      "published_date": "2024-09-27 11:06:59 UTC",
      "updated_date": "2024-09-27 11:06:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:38:57.599979"
    },
    {
      "arxiv_id": "2409.18631v1",
      "title": "Quantum Algorithms for Drone Mission Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Davies",
        "Pranav Kalidindi"
      ],
      "abstract": "Mission planning often involves optimising the use of ISR (Intelligence,\nSurveillance and Reconnaissance) assets in order to achieve a set of mission\nobjectives within allowed parameters subject to constraints. The missions of\ninterest here, involve routing multiple UAVs visiting multiple targets,\nutilising sensors to capture data relating to each target. Finding such\nsolutions is often an NP-Hard problem and cannot be solved efficiently on\nclassical computers. Furthermore, during the mission new constraints and\nobjectives may arise, requiring a new solution to be computed within a short\ntime period. To achieve this we investigate near term quantum algorithms that\nhave the potential to offer speed-ups against current classical methods. We\ndemonstrate how a large family of these problems can be formulated as a Mixed\nInteger Linear Program (MILP) and then converted to a Quadratic Unconstrained\nBinary Optimisation (QUBO). The formulation provided is versatile and can be\nadapted for many different constraints with clear qubit scaling provided. We\ndiscuss the results of solving the QUBO formulation using commercial quantum\nannealers and compare the solutions to current edge classical solvers. We also\nanalyse the results from solving the QUBO using Quantum Approximate\nOptimisation Algorithms (QAOA) and discuss their results. Finally, we also\nprovide efficient methods to encode to the problem into the Variational Quantum\nEigensolver (VQE) formalism, where we have tailored the ansatz to the problem\nmaking efficient use of the qubits available.",
      "tldr_zh": "这篇论文探讨了使用量子算法优化无人机（UAVs）任务规划问题，该问题是NP-Hard类型，无法在经典计算机上高效解决，尤其是在动态添加约束时。作者将问题表述为Mixed Integer Linear Program (MILP)，并转换为Quadratic Unconstrained Binary Optimisation (QUBO)，然后通过商业量子退火器、Quantum Approximate Optimisation Algorithms (QAOA) 和Variational Quantum Eigensolver (VQE)进行求解，并定制ansatz以高效利用qubits。实验结果显示，量子方法与经典求解器相比具有潜在速度优势，并提供了一个通用的、可适应多种约束的表述框架。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "math.OC",
        "68Q12"
      ],
      "primary_category": "quant-ph",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18631v1",
      "published_date": "2024-09-27 10:58:25 UTC",
      "updated_date": "2024-09-27 10:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:39:11.948219"
    },
    {
      "arxiv_id": "2409.18630v1",
      "title": "Entropy, concentration, and learning: a statistical mechanics primer",
      "title_zh": "翻译失败",
      "authors": [
        "Akshay Balsubramani"
      ],
      "abstract": "Artificial intelligence models trained through loss minimization have\ndemonstrated significant success, grounded in principles from fields like\ninformation theory and statistical physics. This work explores these\nestablished connections through the lens of statistical mechanics, starting\nfrom first-principles sample concentration behaviors that underpin AI and\nmachine learning. Our development of statistical mechanics for modeling\nhighlights the key role of exponential families, and quantities of statistics,\nphysics, and information theory.",
      "tldr_zh": "这篇论文从统计力学的角度探讨了人工智能模型通过损失最小化训练的成功原理，强调熵（entropy）、样本集中（concentration）和学习之间的内在联系。作者基于第一原理的样本集中行为，发展了统计力学在建模中的应用，突出指数族（exponential families）及其在统计学、物理学和信息理论中的关键作用。该工作为AI和机器学习提供了坚实的理论基础，揭示了这些领域的交叉联系。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18630v1",
      "published_date": "2024-09-27 10:58:18 UTC",
      "updated_date": "2024-09-27 10:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:39:22.950037"
    },
    {
      "arxiv_id": "2409.18628v1",
      "title": "Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow",
      "title_zh": "翻译失败",
      "authors": [
        "Marvin Tom Teichmann",
        "Manasi Datar",
        "Lisa Kratzke",
        "Fernando Vega",
        "Florin C. Ghesu"
      ],
      "abstract": "The precision of contouring target structures and organs-at-risk (OAR) in\nradiotherapy planning is crucial for ensuring treatment efficacy and patient\nsafety. Recent advancements in deep learning (DL) have significantly improved\nOAR contouring performance, yet the reliability of these models, especially in\nthe presence of out-of-distribution (OOD) scenarios, remains a concern in\nclinical settings. This application study explores the integration of epistemic\nuncertainty estimation within the OAR contouring workflow to enable OOD\ndetection in clinically relevant scenarios, using specifically compiled data.\nFurthermore, we introduce an advanced statistical method for OOD detection to\nenhance the methodological framework of uncertainty estimation. Our empirical\nevaluation demonstrates that epistemic uncertainty estimation is effective in\nidentifying instances where model predictions are unreliable and may require an\nexpert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD\ndetection, with a specificity of 0.95 and a sensitivity of 0.92 for implant\ncases, underscoring its efficacy. This study addresses significant gaps in the\ncurrent research landscape, such as the lack of ground truth for uncertainty\nestimation and limited empirical evaluations. Additionally, it provides a\nclinically relevant application of epistemic uncertainty estimation in an\nFDA-approved and widely used clinical solution for OAR segmentation from\nVarian, a Siemens Healthineers company, highlighting its practical benefits.",
      "tldr_zh": "本研究探讨了将认识论不确定性估计（epistemic uncertainty estimation）整合到放射治疗工作流中，以提升器官-at-risk (OAR) 勾勒的可靠性，尤其在分布外（OOD）场景下。研究引入了一种先进的统计方法，并使用编译的临床数据进行OOD检测，旨在识别深层学习（DL）模型预测的不确定性，从而触发专家审查。实证评估显示，该方法在OOD检测中达到AUC-ROC 0.95的性能，针对植入物病例的特异性为0.95和敏感性为0.92，显著填补了不确定性估计缺乏真实数据和实证评估的空白，并展示了其在Varian临床解决方案中的实际应用潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Keywords: Epistemic Uncertainty - Out-of-Distribution Detection - CT\n  Segmentation - OAR contouring - Radiotherapy",
      "pdf_url": "http://arxiv.org/pdf/2409.18628v1",
      "published_date": "2024-09-27 10:55:58 UTC",
      "updated_date": "2024-09-27 10:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:39:38.108908"
    },
    {
      "arxiv_id": "2409.18626v1",
      "title": "Refutation of Spectral Graph Theory Conjectures with Search Algorithms)",
      "title_zh": "翻译失败",
      "authors": [
        "Milo Roucairol",
        "Tristan Cazenave"
      ],
      "abstract": "We are interested in the automatic refutation of spectral graph theory\nconjectures. Most existing works address this problem either with the\nexhaustive generation of graphs with a limited size or with deep reinforcement\nlearning. Exhaustive generation is limited by the size of the generated graphs\nand deep reinforcement learning takes hours or days to refute a conjecture. We\npropose to use search algorithms to address these shortcomings to find\npotentially large counter-examples to spectral graph theory conjectures in\nseconds. We apply a wide range of search algorithms to a selection of\nconjectures from Graffiti. Out of 13 already refuted conjectures from Graffiti,\nour algorithms are able to refute 12 in seconds. We also refute conjecture 197\nfrom Graffiti which was open until now.",
      "tldr_zh": "本研究针对谱图论(Spectral Graph Theory)猜想的自动反驳问题，指出现有方法如穷举生成有限大小的图或深度强化学习(Deep Reinforcement Learning)存在效率低下或规模限制的缺点。论文提出使用搜索算法(Search Algorithms)来快速发现潜在的大型反例，从而在几秒钟内反驳猜想。实验结果显示，该方法成功反驳了Graffiti数据库中13个已知反驳猜想中的12个，并首次反驳了之前未解决的猜想197，为谱图论猜想的验证提供了高效工具。",
      "categories": [
        "cs.AI",
        "05-04, 05-08, 05B30, 05C40, 05C50, 68Q25, 68Q87, 68R05, 68R10,\n  68T05, 68W20, 68W40"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18626v1",
      "published_date": "2024-09-27 10:55:22 UTC",
      "updated_date": "2024-09-27 10:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:39:46.313823"
    },
    {
      "arxiv_id": "2409.18624v2",
      "title": "Unsupervised Cognition",
      "title_zh": "翻译失败",
      "authors": [
        "Alfredo Ibias",
        "Hector Antona",
        "Guillem Ramirez-Miranda",
        "Enric Guinovart",
        "Eduard Alarcon"
      ],
      "abstract": "Unsupervised learning methods have a soft inspiration in cognition models. To\nthis day, the most successful unsupervised learning methods revolve around\nclustering samples in a mathematical space. In this paper we propose a\nstate-of-the-art, primitive-based, unsupervised learning approach for\ndecision-making inspired by a novel cognition framework. This\nrepresentation-centric approach models the input space constructively as a\ndistributed hierarchical structure in an input-agnostic way. We compared our\napproach with both current state-of-the-art unsupervised learning\nclassification, and with current state-of-the-art cancer type classification.\nWe show how our proposal outperforms previous state-of-the-art. We also\nevaluate some cognition-like properties of our proposal where it not only\noutperforms the compared algorithms (even supervised learning ones), but it\nalso shows a different, more cognition-like, behaviour.",
      "tldr_zh": "本论文提出了一种先进的、primitive-based的无监督学习方法，用于决策支持，受新型认知框架启发。该方法采用representation-centric的策略，将输入空间构建为分布式层次结构，与输入无关，从而模拟认知过程。相比当前state-of-the-art的无监督学习分类和癌症类型分类方法，该方法表现出色，并在认知-like属性评估中超越了包括监督学习算法在内的竞争者，展示了更接近认知的行为。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18624v2",
      "published_date": "2024-09-27 10:50:49 UTC",
      "updated_date": "2024-11-07 14:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:39:57.946300"
    },
    {
      "arxiv_id": "2409.18618v3",
      "title": "Model-based Preference Optimization in Abstractive Summarization without Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Jaepill Choi",
        "Kyubyung Chae",
        "Jiwoo Song",
        "Yohan Jo",
        "Taesup Kim"
      ],
      "abstract": "In abstractive summarization, the challenge of producing concise and accurate\nsummaries arises from the vast amount of information contained in the source\ndocument. Consequently, although Large Language Models (LLMs) can generate\nfluent text, they often introduce inaccuracies by hallucinating content not\nfound in the original source. While supervised fine-tuning methods that\nmaximize likelihood contribute to this issue, they do not consistently enhance\nthe faithfulness of the summaries. Preference-based optimization methods, such\nas Direct Preference Optimization (DPO), can further refine the model to align\nwith human preferences. However, these methods still heavily depend on costly\nhuman feedback. In this work, we introduce a novel and straightforward approach\ncalled Model-based Preference Optimization (MPO) to fine-tune LLMs for improved\nsummarization abilities without any human feedback. By leveraging the model's\ninherent summarization capabilities, we create a preference dataset that is\nfully generated by the model using different decoding strategies. Our\nexperiments on standard summarization datasets and various metrics demonstrate\nthat our proposed MPO significantly enhances the quality of generated summaries\nwithout relying on human feedback.",
      "tldr_zh": "本文提出 Model-based Preference Optimization (MPO)，一种无需 Human Feedback 的方法，用于提升 Large Language Models (LLMs) 在抽象摘要中的性能，以解决摘要中出现的幻觉问题和准确性不足。MPO 通过利用模型自身的摘要能力，使用不同解码策略自动生成偏好数据集，从而对模型进行微调。实验在标准摘要数据集上显示，MPO 显著提高了生成摘要的质量和忠实度，在各种指标上表现优于基线方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18618v3",
      "published_date": "2024-09-27 10:35:45 UTC",
      "updated_date": "2024-10-02 11:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:40:10.524913"
    },
    {
      "arxiv_id": "2409.18597v1",
      "title": "TemporalPaD: a reinforcement-learning framework for temporal feature representation and dimension reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Xuechen Mu",
        "Zhenyu Huang",
        "Kewei Li",
        "Haotian Zhang",
        "Xiuli Wang",
        "Yusi Fan",
        "Kai Zhang",
        "Fengfeng Zhou"
      ],
      "abstract": "Recent advancements in feature representation and dimension reduction have\nhighlighted their crucial role in enhancing the efficacy of predictive\nmodeling. This work introduces TemporalPaD, a novel end-to-end deep learning\nframework designed for temporal pattern datasets. TemporalPaD integrates\nreinforcement learning (RL) with neural networks to achieve concurrent feature\nrepresentation and feature reduction. The framework consists of three\ncooperative modules: a Policy Module, a Representation Module, and a\nClassification Module, structured based on the Actor-Critic (AC) framework. The\nPolicy Module, responsible for dimensionality reduction through RL, functions\nas the actor, while the Representation Module for feature extraction and the\nClassification Module collectively serve as the critic. We comprehensively\nevaluate TemporalPaD using 29 UCI datasets, a well-known benchmark for\nvalidating feature reduction algorithms, through 10 independent tests and\n10-fold cross-validation. Additionally, given that TemporalPaD is specifically\ndesigned for time series data, we apply it to a real-world DNA classification\nproblem involving enhancer category and enhancer strength. The results\ndemonstrate that TemporalPaD is an efficient and effective framework for\nachieving feature reduction, applicable to both structured data and sequence\ndatasets. The source code of the proposed TemporalPaD is freely available as\nsupplementary material to this article and at\nhttp://www.healthinformaticslab.org/supp/.",
      "tldr_zh": "本文提出 TemporalPaD，一种新型端到端深度学习框架，结合 reinforcement learning (RL) 和 neural networks，用于时间序列数据的特征表示和 dimensionality reduction。框架基于 Actor-Critic (AC) 结构，包括 Policy Module（负责降维作为 actor）、Representation Module（特征提取）和 Classification Module（分类作为 critic），实现模块间协同优化。在 29 个 UCI 数据集和真实 DNA 分类任务上的实验显示，TemporalPaD 比传统方法更高效有效，可应用于结构化数据和序列数据集。源代码已公开以便进一步验证和使用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18597v1",
      "published_date": "2024-09-27 09:56:20 UTC",
      "updated_date": "2024-09-27 09:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:40:23.250840"
    },
    {
      "arxiv_id": "2409.18596v1",
      "title": "ASAG2024: A Combined Benchmark for Short Answer Grading",
      "title_zh": "ASAG2024：短答案评分的综合基准",
      "authors": [
        "Gérôme Meyer",
        "Philip Breuer",
        "Jonathan Fürst"
      ],
      "abstract": "Open-ended questions test a more thorough understanding than closed-ended\nquestions and are often a preferred assessment method. However, open-ended\nquestions are tedious to grade and subject to personal bias. Therefore, there\nhave been efforts to speed up the grading process through automation. Short\nAnswer Grading (SAG) systems aim to automatically score students' answers.\nDespite growth in SAG methods and capabilities, there exists no comprehensive\nshort-answer grading benchmark across different subjects, grading scales, and\ndistributions. Thus, it is hard to assess the capabilities of current automated\ngrading methods in terms of their generalizability. In this preliminary work,\nwe introduce the combined ASAG2024 benchmark to facilitate the comparison of\nautomated grading systems. Combining seven commonly used short-answer grading\ndatasets in a common structure and grading scale. For our benchmark, we\nevaluate a set of recent SAG methods, revealing that while LLM-based approaches\nreach new high scores, they still are far from reaching human performance. This\nopens up avenues for future research on human-machine SAG systems.",
      "tldr_zh": "该研究针对短答案评分（Short Answer Grading, SAG）面临的挑战，即手动评分耗时且易受偏见影响，引入了 ASAG2024 基准数据集，以评估自动化评分系统的泛化能力。ASAG2024 将七个常用 SAG 数据集整合到一个统一的结构和评分标准中，涵盖不同科目和分布。实验评估了最近的 SAG 方法，结果显示基于大语言模型（LLM-based approaches）的系统取得了新高分，但仍远低于人类表现。这为开发人类-机器混合 SAG 系统提供了新的研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at SIGCSE-Virtual 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18596v1",
      "published_date": "2024-09-27 09:56:02 UTC",
      "updated_date": "2024-09-27 09:56:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:40:35.636872"
    },
    {
      "arxiv_id": "2409.18594v1",
      "title": "\"Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree\": Zero-Shot Decision Tree Induction and Embedding with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Knauer",
        "Mario Koddenbrock",
        "Raphael Wallsberger",
        "Nicholas M. Brisson",
        "Georg N. Duda",
        "Deborah Falla",
        "David W. Evans",
        "Erik Rodner"
      ],
      "abstract": "Large language models (LLMs) provide powerful means to leverage prior\nknowledge for predictive modeling when data is limited. In this work, we\ndemonstrate how LLMs can use their compressed world knowledge to generate\nintrinsically interpretable machine learning models, i.e., decision trees,\nwithout any training data. We find that these zero-shot decision trees can\nsurpass data-driven trees on some small-sized tabular datasets and that\nembeddings derived from these trees perform on par with data-driven tree-based\nembeddings on average. Our knowledge-driven decision tree induction and\nembedding approaches therefore serve as strong new baselines for data-driven\nmachine learning methods in the low-data regime.",
      "tldr_zh": "本研究探索了如何利用大语言模型（LLMs）在无训练数据的情况下，通过零-shot 方法生成可解释的机器学习模型，即决策树（decision trees）。研究发现，这些零-shot 决策树在某些小规模表格数据集上表现优于传统数据驱动的决策树，而从这些树导出的嵌入表示（embeddings）平均与数据驱动的树基嵌入相当。总之，该方法为低数据情境下的机器学习提供了强大的知识驱动基线，提升了模型的可解释性和实用性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18594v1",
      "published_date": "2024-09-27 09:53:48 UTC",
      "updated_date": "2024-09-27 09:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:40:46.456766"
    },
    {
      "arxiv_id": "2409.18586v1",
      "title": "Analysis of Truncated Singular Value Decomposition for Koopman Operator-Based Lane Change Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chinnawut Nantabut"
      ],
      "abstract": "Understanding and modeling complex dynamic systems is crucial for enhancing\nvehicle performance and safety, especially in the context of autonomous\ndriving. Recently, popular methods such as Koopman operators and their\napproximators, known as Extended Dynamic Mode Decomposition (EDMD), have\nemerged for their effectiveness in transforming strongly nonlinear system\nbehavior into linear representations. This allows them to be integrated with\nconventional linear controllers. To achieve this, Singular Value Decomposition\n(SVD), specifically truncated SVD, is employed to approximate Koopman operators\nfrom extensive datasets efficiently. This study evaluates different basis\nfunctions used in EDMD and ranks for truncated SVD for representing lane change\nbehavior models, aiming to balance computational efficiency with information\nloss. The findings, however, suggest that the technique of truncated SVD does\nnot necessarily achieve substantial reductions in computational training time\nand results in significant information loss.",
      "tldr_zh": "本研究分析了 Truncated Singular Value Decomposition (Truncated SVD) 在基于 Koopman Operator 的变道行为模型中的应用，旨在通过 Extended Dynamic Mode Decomposition (EDMD) 将复杂非线性系统转化为线性表示，以提升车辆性能和自动驾驶安全性。研究评估了不同 basis functions 和 Truncated SVD ranks 的效果，力求在计算效率和信息损失之间实现平衡。结果显示，Truncated SVD 并未显著减少训练时间，反而导致了显著的信息损失，这为优化 Koopman Operator 方法提供了重要启示。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Submitted to the 21st International Conference on Informatics in\n  Control, Automation and Robotics (ICINCO 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.18586v1",
      "published_date": "2024-09-27 09:45:21 UTC",
      "updated_date": "2024-09-27 09:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:40:59.127958"
    },
    {
      "arxiv_id": "2409.18582v2",
      "title": "Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design",
      "title_zh": "翻译失败",
      "authors": [
        "Melis Ilayda Bal",
        "Pier Giuseppe Sessa",
        "Mojmir Mutny",
        "Andreas Krause"
      ],
      "abstract": "Bayesian optimization (BO) is a powerful framework to optimize black-box\nexpensive-to-evaluate functions via sequential interactions. In several\nimportant problems (e.g. drug discovery, circuit design, neural architecture\nsearch, etc.), though, such functions are defined over large\n$\\textit{combinatorial and unstructured}$ spaces. This makes existing BO\nalgorithms not feasible due to the intractable maximization of the acquisition\nfunction over these domains. To address this issue, we propose\n$\\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO.\n$\\textbf{GameOpt}$ establishes a cooperative game between the different\noptimization variables, and selects points that are game $\\textit{equilibria}$\nof an upper confidence bound acquisition function. These are stable\nconfigurations from which no variable has an incentive to deviate$-$ analog to\nlocal optima in continuous domains. Crucially, this allows us to efficiently\nbreak down the complexity of the combinatorial domain into individual decision\nsets, making $\\textbf{GameOpt}$ scalable to large combinatorial spaces. We\ndemonstrate the application of $\\textbf{GameOpt}$ to the challenging\n$\\textit{protein design}$ problem and validate its performance on four\nreal-world protein datasets. Each protein can take up to $20^{X}$ possible\nconfigurations, where $X$ is the length of a protein, making standard BO\nmethods infeasible. Instead, our approach iteratively selects informative\nprotein configurations and very quickly discovers highly active protein\nvariants compared to other baselines.",
      "tldr_zh": "这篇论文针对Bayesian Optimization (BO) 在大型组合和非结构化空间中的挑战（如药物发现和蛋白质设计），提出了一种新方法GameOpt。GameOpt 通过建立优化变量之间的合作博弈，选择Upper Confidence Bound获取函数的游戏均衡点，这些点类似于局部最优，能高效分解复杂域，使算法适用于高维组合空间。在蛋白质设计应用中，实验在四个真实数据集上验证了GameOpt的表现，它能快速迭代选择信息丰富的蛋白质配置，并比基线方法更快地发现高活性蛋白质变体。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "q-bio.BM",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the International Conference on Learning Representations\n  (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2409.18582v2",
      "published_date": "2024-09-27 09:37:49 UTC",
      "updated_date": "2025-02-24 13:35:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:41:11.886801"
    },
    {
      "arxiv_id": "2409.19038v1",
      "title": "Intention-aware policy graphs: answering what, how, and why in opaque agents",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Gimenez-Abalos",
        "Sergio Alvarez-Napagao",
        "Adrian Tormos",
        "Ulises Cortés",
        "Javier Vázquez-Salceda"
      ],
      "abstract": "Agents are a special kind of AI-based software in that they interact in\ncomplex environments and have increased potential for emergent behaviour.\nExplaining such emergent behaviour is key to deploying trustworthy AI, but the\nincreasing complexity and opaque nature of many agent implementations makes\nthis hard. In this work, we propose a Probabilistic Graphical Model along with\na pipeline for designing such model -- by which the behaviour of an agent can\nbe deliberated about -- and for computing a robust numerical value for the\nintentions the agent has at any moment. We contribute measurements that\nevaluate the interpretability and reliability of explanations provided, and\nenables explainability questions such as `what do you want to do now?' (e.g.\ndeliver soup) `how do you plan to do it?' (e.g. returning a plan that considers\nits skills and the world), and `why would you take this action at this state?'\n(e.g. explaining how that furthers or hinders its own goals). This model can be\nconstructed by taking partial observations of the agent's actions and world\nstates, and we provide an iterative workflow for increasing the proposed\nmeasurements through better design and/or pointing out irrational agent\nbehaviour.",
      "tldr_zh": "该论文提出了一种基于 Probabilistic Graphical Model 的框架，用于解释复杂和不透明 agents 的行为，旨在提升 AI 系统的可解释性和可靠性。该框架包括一个设计管道，能从 agents 的部分观察（如行动和世界状态）中计算出稳健的意图数值，并回答关键问题：如“what do you want to do now?”（例如，递送汤）、“how do you plan to do it?”（例如，考虑技能和环境的计划）、以及“why would you take this action?”（例如，如何推进或阻碍目标）。论文贡献了评估解释可解释性和可靠性的测量方法，并提供了一个迭代工作流，以优化设计或识别 agents 的非理性行为，从而促进可信赖 AI 的部署。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO",
        "68T42 (Primary), 68T37, 68T05, 68Q87, 68T30, 68T40, 68M15",
        "I.2; I.1; K.4; G.3"
      ],
      "primary_category": "cs.AI",
      "comment": "57 pages, 8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.19038v1",
      "published_date": "2024-09-27 09:31:45 UTC",
      "updated_date": "2024-09-27 09:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:41:22.459823"
    },
    {
      "arxiv_id": "2409.18578v1",
      "title": "An Enhanced Federated Prototype Learning Method under Domain Shift",
      "title_zh": "在域偏移下的增强联邦原型学习方法",
      "authors": [
        "Liang Kuang",
        "Kuangpu Guo",
        "Jian Liang",
        "Jianguo Zhang"
      ],
      "abstract": "Federated Learning (FL) allows collaborative machine learning training\nwithout sharing private data. Numerous studies have shown that one significant\nfactor affecting the performance of federated learning models is the\nheterogeneity of data across different clients, especially when the data is\nsampled from various domains. A recent paper introduces variance-aware\ndual-level prototype clustering and uses a novel $\\alpha$-sparsity prototype\nloss, which increases intra-class similarity and reduces inter-class\nsimilarity. To ensure that the features converge within specific clusters, we\nintroduce an improved algorithm, Federated Prototype Learning with Convergent\nClusters, abbreviated as FedPLCC. To increase inter-class distances, we weight\neach prototype with the size of the cluster it represents. To reduce\nintra-class distances, considering that prototypes with larger distances might\ncome from different domains, we select only a certain proportion of prototypes\nfor the loss function calculation. Evaluations on the Digit-5, Office-10, and\nDomainNet datasets show that our method performs better than existing\napproaches.",
      "tldr_zh": "本研究针对联邦学习(Federated Learning)中数据异质性和域偏移问题，提出了一种改进算法Federated Prototype Learning with Convergent Clusters (FedPLCC)。该方法基于variance-aware dual-level prototype clustering和α-sparsity prototype loss，通过为每个原型赋予聚类大小权重来增加类间(inter-class)距离，并选择一定比例的原型进行损失函数计算，以减少类内(intra-class)距离并处理不同域的影响。实验在Digit-5、Office-10和DomainNet数据集上显示，FedPLCC比现有方法表现出色，显著提升了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18578v1",
      "published_date": "2024-09-27 09:28:27 UTC",
      "updated_date": "2024-09-27 09:28:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:41:35.804197"
    },
    {
      "arxiv_id": "2409.18568v1",
      "title": "Experimental Evaluation of Machine Learning Models for Goal-oriented Customer Service Chatbot with Pipeline Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Nurul Ain Nabilah Mohd Isa",
        "Siti Nuraishah Agos Jawaddi",
        "Azlan Ismail"
      ],
      "abstract": "Integrating machine learning (ML) into customer service chatbots enhances\ntheir ability to understand and respond to user queries, ultimately improving\nservice performance. However, they may appear artificial to some users and\naffecting customer experience. Hence, meticulous evaluation of ML models for\neach pipeline component is crucial for optimizing performance, though\ndifferences in functionalities can lead to unfair comparisons. In this paper,\nwe present a tailored experimental evaluation approach for goal-oriented\ncustomer service chatbots with pipeline architecture, focusing on three key\ncomponents: Natural Language Understanding (NLU), dialogue management (DM), and\nNatural Language Generation (NLG). Our methodology emphasizes individual\nassessment to determine optimal ML models. Specifically, we focus on optimizing\nhyperparameters and evaluating candidate models for NLU (utilizing BERT and\nLSTM), DM (employing DQN and DDQN), and NLG (leveraging GPT-2 and DialoGPT).\nThe results show that for the NLU component, BERT excelled in intent detection\nwhereas LSTM was superior for slot filling. For the DM component, the DDQN\nmodel outperformed DQN by achieving fewer turns, higher rewards, as well as\ngreater success rates. For NLG, the large language model GPT-2 surpassed\nDialoGPT in BLEU, METEOR, and ROUGE metrics. These findings aim to provide a\nbenchmark for future research in developing and optimizing customer service\nchatbots, offering valuable insights into model performance and optimal\nhyperparameters.",
      "tldr_zh": "该研究评估了机器学习模型在基于管道架构的目标导向客服聊天机器人中的性能，重点关注三个关键组件：Natural Language Understanding (NLU)、dialogue management (DM) 和 Natural Language Generation (NLG)。研究方法包括优化模型超参数，并比较特定模型的表现，如在 NLU 中 BERT 优于意图检测而 LSTM 更适合槽填充，在 DM 中 DDQN 比 DQN 表现出更高的奖励和成功率，在 NLG 中 GPT-2 在 BLEU、METEOR 和 ROUGE 指标上超越 DialoGPT。这些发现为优化客服聊天机器人提供了宝贵基准，并为未来研究提供模型性能和超参数选择的见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18568v1",
      "published_date": "2024-09-27 09:11:52 UTC",
      "updated_date": "2024-09-27 09:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:41:49.753000"
    },
    {
      "arxiv_id": "2409.18553v1",
      "title": "Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators",
      "title_zh": "高效噪声抑制以提升混合信号加速器上深度神经网络推理准确性",
      "authors": [
        "Seyedarmin Azizi",
        "Mohammad Erfan Sadeghi",
        "Mehdi Kamal",
        "Massoud Pedram"
      ],
      "abstract": "In this paper, we propose a framework to enhance the robustness of the neural\nmodels by mitigating the effects of process-induced and aging-related\nvariations of analog computing components on the accuracy of the analog neural\nnetworks. We model these variations as the noise affecting the precision of the\nactivations and introduce a denoising block inserted between selected layers of\na pre-trained model. We demonstrate that training the denoising block\nsignificantly increases the model's robustness against various noise levels. To\nminimize the overhead associated with adding these blocks, we present an\nexploration algorithm to identify optimal insertion points for the denoising\nblocks. Additionally, we propose a specialized architecture to efficiently\nexecute the denoising blocks, which can be integrated into mixed-signal\naccelerators. We evaluate the effectiveness of our approach using Deep Neural\nNetwork (DNN) models trained on the ImageNet and CIFAR-10 datasets. The results\nshow that on average, by accepting 2.03% parameter count overhead, the accuracy\ndrop due to the variations reduces from 31.7% to 1.15%.",
      "tldr_zh": "本文提出一个框架，用于缓解模拟计算组件的工艺诱导和老化相关变异对 DNNs 推理准确性的影响，通过将这些变异建模为激活噪声并在预训练模型的选定层之间插入去噪块来提升鲁棒性。框架包括一个探索算法来优化去噪块的插入点，并设计了一个专门架构以高效集成到 mixed-signal accelerators 中，从而最小化开销。实验结果显示，在 ImageNet 和 CIFAR-10 数据集上，该方法仅增加 2.03% 参数计数，便将准确性下降从 31.7% 降低到 1.15%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18553v1",
      "published_date": "2024-09-27 08:45:55 UTC",
      "updated_date": "2024-09-27 08:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:42:01.848237"
    },
    {
      "arxiv_id": "2409.18548v1",
      "title": "Research on Predicting Public Opinion Event Heat Levels Based on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Ren",
        "Tianyi Zhang",
        "Weibin Li",
        "DuoMu Zhou",
        "Chenhao Qin",
        "FangCheng Dong"
      ],
      "abstract": "In recent years, with the rapid development of large language models, serval\nmodels such as GPT-4o have demonstrated extraordinary capabilities, surpassing\nhuman performance in various language tasks. As a result, many researchers have\nbegun exploring their potential applications in the field of public opinion\nanalysis. This study proposes a novel large-language-models-based method for\npublic opinion event heat level prediction. First, we preprocessed and\nclassified 62,836 Chinese hot event data collected between July 2022 and\nDecember 2023. Then, based on each event's online dissemination heat index, we\nused the MiniBatchKMeans algorithm to automatically cluster the events and\ncategorize them into four heat levels (ranging from low heat to very high\nheat). Next, we randomly selected 250 events from each heat level, totalling\n1,000 events, to build the evaluation dataset. During the evaluation process,\nwe employed various large language models to assess their accuracy in\npredicting event heat levels in two scenarios: without reference cases and with\nsimilar case references. The results showed that GPT-4o and DeepseekV2\nperformed the best in the latter case, achieving prediction accuracies of 41.4%\nand 41.5%, respectively. Although the overall prediction accuracy remains\nrelatively low, it is worth noting that for low-heat (Level 1) events, the\nprediction accuracies of these two models reached 73.6% and 70.4%,\nrespectively. Additionally, the prediction accuracy showed a downward trend\nfrom Level 1 to Level 4, which correlates with the uneven distribution of data\nacross the heat levels in the actual dataset. This suggests that with the more\nrobust dataset, public opinion event heat level prediction based on large\nlanguage models will have significant research potential for the future.",
      "tldr_zh": "本研究提出了一种基于Large Language Models（如GPT-4o）的方法，用于预测舆情事件热度水平，以应对公共舆论分析的需求。研究团队首先预处理并分类了62,836条中文热门事件数据，并使用MiniBatchKMeans算法根据在线传播热度指数将事件聚类为四个水平（从低热到极高热），随后构建了包含1,000个事件的评估数据集。实验结果显示，在有类似案例参考的场景下，GPT-4o和DeepseekV2的预测准确率最高，分别为41.4%和41.5%，且在低热度事件（Level 1）上准确率可达73.6%和70.4%；尽管整体准确率较低，但这与数据分布不均相关，并表明Large Language Models在未来舆情预测领域具有显著潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "conference",
      "pdf_url": "http://arxiv.org/pdf/2409.18548v1",
      "published_date": "2024-09-27 08:34:42 UTC",
      "updated_date": "2024-09-27 08:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:42:14.947234"
    },
    {
      "arxiv_id": "2409.18545v1",
      "title": "An Epistemic Human-Aware Task Planner which Anticipates Human Beliefs and Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Shekhar",
        "Anthony Favier",
        "Rachid Alami"
      ],
      "abstract": "We present a substantial extension of our Human-Aware Task Planning\nframework, tailored for scenarios with intermittent shared execution\nexperiences and significant belief divergence between humans and robots,\nparticularly due to the uncontrollable nature of humans. Our objective is to\nbuild a robot policy that accounts for uncontrollable human behaviors, thus\nenabling the anticipation of possible advancements achieved by the robot when\nthe execution is not shared, e.g. when humans are briefly absent from the\nshared environment to complete a subtask. But, this anticipation is considered\nfrom the perspective of humans who have access to an estimated model for the\nrobot. To this end, we propose a novel planning framework and build a solver\nbased on AND-OR search, which integrates knowledge reasoning, including\nsituation assessment by perspective taking. Our approach dynamically models and\nmanages the expansion and contraction of potential advances while precisely\nkeeping track of when (and when not) agents share the task execution\nexperience. The planner systematically assesses the situation and ignores\nworlds that it has reason to think are impossible for humans. Overall, our new\nsolver can estimate the distinct beliefs of the human and the robot along\npotential courses of action, enabling the synthesis of plans where the robot\nselects the right moment for communication, i.e. informing, or replying to an\ninquiry, or defers ontic actions until the execution experiences can be shared.\nPreliminary experiments in two domains, one novel and one adapted, demonstrate\nthe effectiveness of the framework.",
      "tldr_zh": "本研究扩展了人类感知任务规划（Human-Aware Task Planning）框架，旨在处理人类和机器人间断共享执行体验以及信念分歧问题，特别是针对不可控的人类行为。该框架通过一个基于 AND-OR 搜索的求解器，整合知识推理和视角转换（perspective taking），动态管理潜在进展并预测从人类视角看机器人可能的行动，从而选择合适的沟通时机，如告知或延迟执行。实验在两个领域展示了框架的有效性，提高了机器人在非共享场景下的规划准确性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2409.18545v1",
      "published_date": "2024-09-27 08:27:36 UTC",
      "updated_date": "2024-09-27 08:27:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:42:25.543902"
    },
    {
      "arxiv_id": "2409.18542v1",
      "title": "MIMII-Gen: Generative Modeling Approach for Simulated Evaluation of Anomalous Sound Detection System",
      "title_zh": "MIMII-Gen：用于异常声音检测系统模拟评估的生成式建模方法",
      "authors": [
        "Harsh Purohit",
        "Tomoya Nishida",
        "Kota Dohi",
        "Takashi Endo",
        "Yohei Kawaguchi"
      ],
      "abstract": "Insufficient recordings and the scarcity of anomalies present significant\nchallenges in developing and validating robust anomaly detection systems for\nmachine sounds. To address these limitations, we propose a novel approach for\ngenerating diverse anomalies in machine sound using a latent diffusion-based\nmodel that integrates an encoder-decoder framework. Our method utilizes the\nFlan-T5 model to encode captions derived from audio file metadata, enabling\nconditional generation through a carefully designed U-Net architecture. This\napproach aids our model in generating audio signals within the EnCodec latent\nspace, ensuring high contextual relevance and quality. We objectively evaluated\nthe quality of our generated sounds using the Fr\\'echet Audio Distance (FAD)\nscore and other metrics, demonstrating that our approach surpasses existing\nmodels in generating reliable machine audio that closely resembles actual\nabnormal conditions. The evaluation of the anomaly detection system using our\ngenerated data revealed a strong correlation, with the area under the curve\n(AUC) score differing by 4.8\\% from the original, validating the effectiveness\nof our generated data. These results demonstrate the potential of our approach\nto enhance the evaluation and robustness of anomaly detection systems across\nvaried and previously unseen conditions. Audio samples can be found at\n\\url{https://hpworkhub.github.io/MIMII-Gen.github.io/}.",
      "tldr_zh": "该论文提出 MIMII-Gen 方法，使用基于潜在扩散的模型（latent diffusion-based model）结合编码器-解码器框架，生成多样化的机器声音异常，以解决异常检测系统在录音不足和异常稀缺方面的挑战。方法利用 Flan-T5 模型编码音频文件元数据，并通过 U-Net 架构在 EnCodec 潜在空间中进行条件生成，确保生成的音频具有高上下文相关性和质量。实验评估显示，该方法在 Fréchet Audio Distance (FAD) 等指标上优于现有模型。最终，使用生成的异常数据评估异常检测系统时，AUC 得分仅比原数据低 4.8%，证明其能有效提升系统的鲁棒性和评估可靠性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18542v1",
      "published_date": "2024-09-27 08:21:31 UTC",
      "updated_date": "2024-09-27 08:21:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:42:38.278607"
    },
    {
      "arxiv_id": "2409.18541v2",
      "title": "Align$^2$LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation",
      "title_zh": "翻译失败",
      "authors": [
        "Hongzhe Huang",
        "Jiang Liu",
        "Zhewen Yu",
        "Li Cai",
        "Dian Jiao",
        "Wenqiao Zhang",
        "Siliang Tang",
        "Juncheng Li",
        "Hao Jiang",
        "Haoyuan Li",
        "Yueting Zhuang"
      ],
      "abstract": "Recent advances in Multi-modal Large Language Models (MLLMs), such as\nLLaVA-series models, are driven by massive machine-generated\ninstruction-following data tuning. Such automatic instruction collection\npipelines, however, inadvertently introduce significant variability in data\nquality. This paper introduces a novel instruction curation algorithm, derived\nfrom two unique perspectives, human and LLM preference alignment, to compress\nthis vast corpus of machine-generated multimodal instructions to a compact and\nhigh-quality form: (i) For human preference alignment, we have collected a\nmachine-generated multimodal instruction dataset and established a\ncomprehensive set of both subjective and objective criteria to guide the data\nquality assessment critically from human experts. By doing so, a reward model\nwas trained on the annotated dataset to internalize the nuanced human\nunderstanding of instruction alignment. (ii) For LLM preference alignment,\ngiven the instruction selected by the reward model, we propose leveraging the\ninner LLM used in MLLM to align the writing style of visual instructions with\nthat of the inner LLM itself, resulting in LLM-aligned instruction improvement.\nExtensive experiments demonstrate that we can maintain or even improve model\nperformance by compressing synthetic multimodal instructions by up to 90%.\nImpressively, by aggressively reducing the training instructions from 158k to\n14k (9$\\times$ smaller), our model consistently outperforms its full-size\ndataset counterpart across various MLLM benchmarks. Our project is available at\nhttps://github.com/DCDmllm/Align2LLaVA.",
      "tldr_zh": "这篇论文提出了 Align²LLaVA，一种级联的人类偏好和大型语言模型 (LLM) 偏好对齐算法，用于优化多模态指令整理，以解决机器生成数据质量不均的问题。具体方法包括：从人类偏好角度收集数据集并训练奖励模型，以主观和客观标准评估指令质量；从 LLM 偏好角度，利用 MLLM 中的内部 LLM 调整指令写作风格，实现高质量压缩。实验结果显示，该方法将合成多模态指令压缩高达 90%（从 158k 减少到 14k），模型在各种 MLLM 基准上保持或提升性能，证明了其在高效数据整理方面的显著贡献。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18541v2",
      "published_date": "2024-09-27 08:20:59 UTC",
      "updated_date": "2024-12-16 10:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:42:50.617137"
    },
    {
      "arxiv_id": "2409.18512v1",
      "title": "EmoPro: A Prompt Selection Strategy for Emotional Expression in LM-based Speech Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Wang",
        "Chunyu Qiang",
        "Tianrui Wang",
        "Cheng Gong",
        "Qiuyu Liu",
        "Yu Jiang",
        "Xiaobao Wang",
        "Chenyang Wang",
        "Chen Zhang"
      ],
      "abstract": "Recent advancements in speech synthesis models, trained on extensive\ndatasets, have demonstrated remarkable zero-shot capabilities. These models can\ncontrol content, timbre, and emotion in generated speech based on prompt\ninputs. Despite these advancements, the choice of prompts significantly impacts\nthe output quality, yet most existing selection schemes do not adequately\naddress the control of emotional intensity. To address this question, this\npaper proposes a two-stage prompt selection strategy EmoPro, which is\nspecifically designed for emotionally controllable speech synthesis. This\nstrategy focuses on selecting highly expressive and high-quality prompts by\nevaluating them from four perspectives: emotional expression strength, speech\nquality, text-emotion consistency, and model generation performance.\nExperimental results show that prompts selected using the proposed method\nresult in more emotionally expressive and engaging synthesized speech compared\nto those obtained through baseline. Audio samples and codes will be available\nat https://whyrrrrun.github.io/EmoPro/.",
      "tldr_zh": "本研究针对基于语言模型(LM-based)的语音合成中情感表达问题，提出了一种两阶段提示选择策略EmoPro，以优化提示对情感强度、语音质量和生成性能的影响。该策略从情感表达强度、语音质量、文本-情感一致性以及模型生成性能四个角度评估和选择高表达性提示，从而实现更精确的情感控制。实验结果表明，使用EmoPro选择的提示能生成比基线方法更富有情感和吸引力的合成语音，为情感可控语音合成提供有效改进。音频样本和代码可访问https://whyrrrrun.github.io/EmoPro/。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18512v1",
      "published_date": "2024-09-27 07:46:52 UTC",
      "updated_date": "2024-09-27 07:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:43:01.335925"
    },
    {
      "arxiv_id": "2409.18499v1",
      "title": "Fairness-aware Multiobjective Evolutionary Learning",
      "title_zh": "公平感知的多目标进化学习",
      "authors": [
        "Qingquan Zhang",
        "Jialin Liu",
        "Xin Yao"
      ],
      "abstract": "Multiobjective evolutionary learning (MOEL) has demonstrated its advantages\nof training fairer machine learning models considering a predefined set of\nconflicting objectives, including accuracy and different fairness measures.\nRecent works propose to construct a representative subset of fairness measures\nas optimisation objectives of MOEL throughout model training. However, the\ndetermination of a representative measure set relies on dataset, prior\nknowledge and requires substantial computational costs. What's more, those\nrepresentative measures may differ across different model training processes.\nInstead of using a static predefined set determined before model training, this\npaper proposes to dynamically and adaptively determine a representative measure\nset online during model training. The dynamically determined representative set\nis then used as optimising objectives of the MOEL framework and can vary with\ntime. Extensive experimental results on 12 well-known benchmark datasets\ndemonstrate that our proposed framework achieves outstanding performance\ncompared to state-of-the-art approaches for mitigating unfairness in terms of\naccuracy as well as 25 fairness measures although only a few of them were\ndynamically selected and used as optimisation objectives. The results indicate\nthe importance of setting optimisation objectives dynamically during training.",
      "tldr_zh": "本研究提出了一种公平性感知的多目标进化学习(MOEL)框架，通过动态自适应方式在线确定代表性公平性措施子集作为优化目标，以克服现有方法依赖静态预定义集的局限性。该框架允许优化目标随模型训练过程变化，从而更灵活地平衡准确性和公平性。在12个基准数据集上的实验表明，该方法在准确性以及25个公平性措施上显著优于最先进方法，尽管仅动态选择了少数措施作为优化目标。这些结果强调了在训练过程中动态设置优化目标的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.18499v1",
      "published_date": "2024-09-27 07:32:42 UTC",
      "updated_date": "2024-09-27 07:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:43:13.765911"
    },
    {
      "arxiv_id": "2409.18475v1",
      "title": "Data Analysis in the Era of Generative AI",
      "title_zh": "在生成式 AI 时代的数据分析",
      "authors": [
        "Jeevana Priya Inala",
        "Chenglong Wang",
        "Steven Drucker",
        "Gonzalo Ramos",
        "Victor Dibia",
        "Nathalie Riche",
        "Dave Brown",
        "Dan Marshall",
        "Jianfeng Gao"
      ],
      "abstract": "This paper explores the potential of AI-powered tools to reshape data\nanalysis, focusing on design considerations and challenges. We explore how the\nemergence of large language and multimodal models offers new opportunities to\nenhance various stages of data analysis workflow by translating high-level user\nintentions into executable code, charts, and insights. We then examine\nhuman-centered design principles that facilitate intuitive interactions, build\nuser trust, and streamline the AI-assisted analysis workflow across multiple\napps. Finally, we discuss the research challenges that impede the development\nof these AI-based systems such as enhancing model capabilities, evaluating and\nbenchmarking, and understanding end-user needs.",
      "tldr_zh": "这篇论文探讨了生成式 AI 如何重塑数据分析，聚焦于设计考虑和挑战，特别是通过大语言模型和多模态模型，将用户意图转化为可执行代码、图表和洞见，从而提升数据分析工作流各阶段的效率。论文强调了人性化设计原则的重要性，包括促进直观交互、建立用户信任，并整合多应用环境。最终，它讨论了关键研究挑战，如增强模型能力、进行评估和基准测试，以及深入理解最终用户需求，以推动 AI 辅助系统的开发。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18475v1",
      "published_date": "2024-09-27 06:31:03 UTC",
      "updated_date": "2024-09-27 06:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:43:24.533777"
    },
    {
      "arxiv_id": "2409.18461v2",
      "title": "Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Morafah",
        "Vyacheslav Kungurtsev",
        "Hojin Chang",
        "Chen Chen",
        "Bill Lin"
      ],
      "abstract": "Federated Learning has emerged as a promising paradigm for collaborative\nmachine learning, while preserving user data privacy. Despite its potential,\nstandard FL lacks support for diverse heterogeneous device prototypes, which\nvary significantly in model and dataset sizes -- from small IoT devices to\nlarge workstations. This limitation is only partially addressed by existing\nknowledge distillation techniques, which often fail to transfer knowledge\neffectively across a broad spectrum of device prototypes with varied\ncapabilities. This failure primarily stems from two issues: the dilution of\ninformative logits from more capable devices by those from less capable ones,\nand the use of a single integrated logits as the distillation target across all\ndevices, which neglects their individual learning capacities and and the unique\ncontributions of each. To address these challenges, we introduce TAKFL, a novel\nKD-based framework that treats the knowledge transfer from each device\nprototype's ensemble as a separate task, independently distilling each to\npreserve its unique contributions and avoid dilution. TAKFL also incorporates a\nKD-based self-regularization technique to mitigate the issues related to the\nnoisy and unsupervised ensemble distillation process. To integrate the\nseparately distilled knowledge, we introduce an adaptive task arithmetic\nknowledge integration process, allowing each student model to customize the\nknowledge integration for optimal performance. Additionally, we present\ntheoretical results demonstrating the effectiveness of task arithmetic in\ntransferring knowledge across heterogeneous devices with varying capacities.\nComprehensive evaluations of our method across both CV and NLP tasks\ndemonstrate that TAKFL achieves SOTA results in a variety of datasets and\nsettings, significantly outperforming existing KD-based methods Code is\nreleased at https://github.com/MMorafah/TAKFL",
      "tldr_zh": "该论文针对联邦学习（Federated Learning）中设备异构性问题（如IoT设备和工作站的差异），提出TAKFL框架，一种基于知识蒸馏（Knowledge Distillation）的创新方法，将每个设备原型的知识转移视为独立任务进行蒸馏，以避免信息性logits的稀释并保留独特贡献。TAKFL还整合了KD-based自正则化技术和自适应任务算术知识整合（Task Arithmetic Knowledge Integration），允许每个学生模型自定义知识整合，并通过理论分析证明了其在异构设备间知识转移的有效性。实验结果显示，TAKFL在计算机视觉（CV）和自然语言处理（NLP）任务上实现了State-of-the-Art性能，显著优于现有方法，并开源了代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18461v2",
      "published_date": "2024-09-27 05:49:48 UTC",
      "updated_date": "2024-11-11 22:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:43:39.359397"
    },
    {
      "arxiv_id": "2409.18455v1",
      "title": "Review of Digital Asset Development with Graph Neural Network Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Zara Lisbon"
      ],
      "abstract": "In the rapidly evolving landscape of digital assets, the imperative for\nrobust data privacy and compliance with regulatory frameworks has intensified.\nThis paper investigates the critical role of Graph Neural Networks (GNNs) in\nthe management of digital assets and introduces innovative unlearning\ntechniques specifically tailored to GNN architectures. We categorize unlearning\nstrategies into two primary classes: data-driven approximation, which\nmanipulates the graph structure to isolate and remove the influence of specific\nnodes, and model-driven approximation, which modifies the internal parameters\nand architecture of the GNN itself. By examining recent advancements in these\nunlearning methodologies, we highlight their applicability in various use\ncases, including fraud detection, risk assessment, token relationship\nprediction, and decentralized governance. We discuss the challenges inherent in\nbalancing model performance with the requirements for data unlearning,\nparticularly in the context of real-time financial applications. Furthermore,\nwe propose a hybrid approach that combines the strengths of both unlearning\nstrategies to enhance the efficiency and effectiveness of GNNs in digital asset\necosystems. Ultimately, this paper aims to provide a comprehensive framework\nfor understanding and implementing GNN unlearning techniques, paving the way\nfor secure and compliant deployment of machine learning in the digital asset\ndomain.",
      "tldr_zh": "这篇论文审视了Graph Neural Networks (GNNs)在数字资产开发中的作用，特别关注数据隐私和合规性需求，并引入了针对GNNs的创新unlearning技术。该技术分为两类：data-driven approximation（通过操作图结构隔离和移除特定节点的影响）和model-driven approximation（修改GNNs的内部参数和架构），以适应应用如欺诈检测、风险评估、token关系预测和去中心化治理的场景。论文讨论了在实时金融应用中平衡模型性能与unlearning要求的挑战，并提出了一种混合方法，结合两种策略来提升GNNs的效率和效果。最终，该框架为在数字资产领域安全合规部署机器学习提供了全面指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18455v1",
      "published_date": "2024-09-27 05:31:04 UTC",
      "updated_date": "2024-09-27 05:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:43:49.874941"
    },
    {
      "arxiv_id": "2409.18454v1",
      "title": "Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications",
      "title_zh": "利用长上下文大语言模型进行多文档理解和总结的企业应用",
      "authors": [
        "Aditi Godbole",
        "Jabin Geevarghese George",
        "Smita Shandilya"
      ],
      "abstract": "The rapid increase in unstructured data across various fields has made\nmulti-document comprehension and summarization a critical task. Traditional\napproaches often fail to capture relevant context, maintain logical\nconsistency, and extract essential information from lengthy documents. This\npaper explores the use of Long-context Large Language Models (LLMs) for\nmulti-document summarization, demonstrating their exceptional capacity to grasp\nextensive connections, provide cohesive summaries, and adapt to various\nindustry domains and integration with enterprise applications/systems. The\npaper discusses the workflow of multi-document summarization for effectively\ndeploying long-context LLMs, supported by case studies in legal applications,\nenterprise functions such as HR, finance, and sourcing, as well as in the\nmedical and news domains. These case studies show notable enhancements in both\nefficiency and accuracy. Technical obstacles, such as dataset diversity, model\nscalability, and ethical considerations like bias mitigation and factual\naccuracy, are carefully analyzed. Prospective research avenues are suggested to\naugment the functionalities and applications of long-context LLMs, establishing\nthem as pivotal tools for transforming information processing across diverse\nsectors and enterprise applications.",
      "tldr_zh": "本论文探讨了利用 Long-context Large Language Models (LLMs) 来提升多文档理解和总结能力，以应对企业应用中非结构化数据的快速增长。研究展示了这些模型在捕捉广泛上下文、保持逻辑一致性和提取关键信息方面的优势，并通过法律、企业职能（如 HR、财务和采购）、医疗及新闻领域的案例研究，证明了其在效率和准确性上的显著提升。论文同时分析了技术挑战，包括数据集多样性、模型可扩展性以及伦理问题如偏见缓解和事实准确性，并建议未来研究方向以进一步扩展 LLMs 在信息处理领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18454v1",
      "published_date": "2024-09-27 05:29:31 UTC",
      "updated_date": "2024-09-27 05:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:44:01.131654"
    },
    {
      "arxiv_id": "2409.18444v2",
      "title": "Cost-Aware Dynamic Cloud Workflow Scheduling using Self-Attention and Evolutionary Reinforcement Learning",
      "title_zh": "成本感知的动态",
      "authors": [
        "Ya Shen",
        "Gang Chen",
        "Hui Ma",
        "Mengjie Zhang"
      ],
      "abstract": "The Cost-aware Dynamic Multi-Workflow Scheduling (CDMWS) in the cloud is a\nkind of cloud workflow management problem, which aims to assign virtual machine\n(VM) instances to execute tasks in workflows so as to minimize the total costs,\nincluding both the penalties for violating Service Level Agreement (SLA) and\nthe VM rental fees. Powered by deep neural networks, Reinforcement Learning\n(RL) methods can construct effective scheduling policies for solving CDMWS\nproblems. Traditional policy networks in RL often use basic feedforward\narchitectures to separately determine the suitability of assigning any VM\ninstances, without considering all VMs simultaneously to learn their global\ninformation. This paper proposes a novel self-attention policy network for\ncloud workflow scheduling (SPN-CWS) that captures global information from all\nVMs. We also develop an Evolution Strategy-based RL (ERL) system to train\nSPN-CWS reliably and effectively. The trained SPN-CWS can effectively process\nall candidate VM instances simultaneously to identify the most suitable VM\ninstance to execute every workflow task. Comprehensive experiments show that\nour method can noticeably outperform several state-of-the-art algorithms on\nmultiple benchmark CDMWS problems.",
      "tldr_zh": "该研究针对成本感知动态多工作流调度(CDMWS)问题，提出了一种使用自注意力(Self-Attention)机制的策略网络(SPN-CWS)，旨在通过同时捕获所有虚拟机(VM)实例的全局信息来优化任务分配，从而最小化服务级别协议(SLA)违规罚款和VM租赁费用。作者还开发了基于进化策略的强化学习(ERL)系统来高效训练SPN-CWS，确保其可靠处理工作流任务。实验结果显示，该方法在多个基准CDMWS问题上显著优于现有算法，展示了其在云工作流管理中的实际优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by ICSOC (International Conference on\n  Service-Oriented Computing) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18444v2",
      "published_date": "2024-09-27 04:45:06 UTC",
      "updated_date": "2024-12-29 11:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:44:16.864737"
    },
    {
      "arxiv_id": "2409.18439v1",
      "title": "State-free Reinforcement Learning",
      "title_zh": "无状态强化学习",
      "authors": [
        "Mingyu Chen",
        "Aldo Pacchiano",
        "Xuezhou Zhang"
      ],
      "abstract": "In this work, we study the \\textit{state-free RL} problem, where the\nalgorithm does not have the states information before interacting with the\nenvironment. Specifically, denote the reachable state set by ${S}^\\Pi := \\{\ns|\\max_{\\pi\\in \\Pi}q^{P, \\pi}(s)>0 \\}$, we design an algorithm which requires\nno information on the state space $S$ while having a regret that is completely\nindependent of ${S}$ and only depend on ${S}^\\Pi$. We view this as a concrete\nfirst step towards \\textit{parameter-free RL}, with the goal of designing RL\nalgorithms that require no hyper-parameter tuning.",
      "tldr_zh": "本研究探讨了“state-free Reinforcement Learning”（无状态强化学习）问题，即算法在与环境交互前无需知道状态信息。具体地，论文设计了一种算法，仅依赖于可达状态集 \\( S^\\Pi \\) 而非整个状态空间 \\( S \\)，从而使算法的遗憾（regret）完全独立于 \\( S \\) 并仅与 \\( S^\\Pi \\) 相关。该方法被视为通往“parameter-free RL”（无参数强化学习）的关键一步，旨在开发不需要超参数调整的RL算法，以提升算法的通用性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18439v1",
      "published_date": "2024-09-27 04:28:19 UTC",
      "updated_date": "2024-09-27 04:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:44:27.822026"
    },
    {
      "arxiv_id": "2409.18438v1",
      "title": "Physics Augmented Tuple Transformer for Autism Severity Level Detection",
      "title_zh": "物理增强元组变换器用于自闭症严重程度检测",
      "authors": [
        "Chinthaka Ranasingha",
        "Harshala Gammulle",
        "Tharindu Fernando",
        "Sridha Sridharan",
        "Clinton Fookes"
      ],
      "abstract": "Early diagnosis of Autism Spectrum Disorder (ASD) is an effective and\nfavorable step towards enhancing the health and well-being of children with\nASD. Manual ASD diagnosis testing is labor-intensive, complex, and prone to\nhuman error due to several factors contaminating the results. This paper\nproposes a novel framework that exploits the laws of physics for ASD severity\nrecognition. The proposed physics-informed neural network architecture encodes\nthe behaviour of the subject extracted by observing a part of the\nskeleton-based motion trajectory in a higher dimensional latent space. Two\ndecoders, namely physics-based and non-physics-based decoder, use this latent\nembedding and predict the future motion patterns. The physics branch leverages\nthe laws of physics that apply to a skeleton sequence in the prediction process\nwhile the non-physics-based branch is optimised to minimise the difference\nbetween the predicted and actual motion of the subject. A classifier also\nleverages the same latent space embeddings to recognise the ASD severity. This\ndual generative objective explicitly forces the network to compare the actual\nbehaviour of the subject with the general normal behaviour of children that are\ngoverned by the laws of physics, aiding the ASD recognition task. The proposed\nmethod attains state-of-the-art performance on multiple ASD diagnosis\nbenchmarks. To illustrate the utility of the proposed framework beyond the task\nASD diagnosis, we conduct a third experiment using a publicly available\nbenchmark for the task of fall prediction and demonstrate the superiority of\nour model.",
      "tldr_zh": "本文提出一个名为Physics Augmented Tuple Transformer的框架，利用物理定律（laws of physics）来检测Autism Spectrum Disorder (ASD)的严重程度，以解决传统手动诊断的复杂性和误差问题。该框架采用physics-informed neural network架构，从骨骼运动轨迹中提取行为嵌入，并通过physics-based和non-physics-based解码器预测未来运动模式，同时使用分类器基于相同嵌入识别ASD严重程度。实验结果显示，该方法在多个ASD诊断基准上达到了state-of-the-art性能，并证明了其在fall prediction任务中的通用性和优越性。",
      "categories": [
        "cs.AI",
        "J.3; I.5.4; I.4.9"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.18438v1",
      "published_date": "2024-09-27 04:21:02 UTC",
      "updated_date": "2024-09-27 04:21:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:44:38.063924"
    },
    {
      "arxiv_id": "2409.18435v1",
      "title": "Multi-agent Reinforcement Learning for Dynamic Dispatching in Material Handling Systems",
      "title_zh": "多智能体强化学习用于物料搬运系统的动态调度",
      "authors": [
        "Xian Yeow Lee",
        "Haiyan Wang",
        "Daisuke Katsumata",
        "Takaharu Matsui",
        "Chetan Gupta"
      ],
      "abstract": "This paper proposes a multi-agent reinforcement learning (MARL) approach to\nlearn dynamic dispatching strategies, which is crucial for optimizing\nthroughput in material handling systems across diverse industries. To benchmark\nour method, we developed a material handling environment that reflects the\ncomplexities of an actual system, such as various activities at different\nlocations, physical constraints, and inherent uncertainties. To enhance\nexploration during learning, we propose a method to integrate domain knowledge\nin the form of existing dynamic dispatching heuristics. Our experimental\nresults show that our method can outperform heuristics by up to 7.4 percent in\nterms of median throughput. Additionally, we analyze the effect of different\narchitectures on MARL performance when training multiple agents with different\nfunctions. We also demonstrate that the MARL agents performance can be further\nimproved by using the first iteration of MARL agents as heuristics to train a\nsecond iteration of MARL agents. This work demonstrates the potential of\napplying MARL to learn effective dynamic dispatching strategies that may be\ndeployed in real-world systems to improve business outcomes.",
      "tldr_zh": "本文提出了一种基于 Multi-agent Reinforcement Learning (MARL) 的方法，用于学习动态调度策略，以优化材料处理系统的吞吐量。研究者开发了一个模拟真实系统复杂性的环境，包括不同位置的活动、物理约束和不确定性，并通过整合现有动态调度启发式方法来增强 MARL 的探索能力。实验结果显示，该方法在吞吐量中值上比传统启发式方法提高了高达 7.4%，并通过使用第一迭代 MARL 智能体训练第二迭代来进一步提升性能。该工作证明了 MARL 在真实系统中部署的有效性，有助于改善业务成果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18435v1",
      "published_date": "2024-09-27 03:57:54 UTC",
      "updated_date": "2024-09-27 03:57:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:44:50.480753"
    },
    {
      "arxiv_id": "2409.18433v1",
      "title": "Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization",
      "title_zh": "Easy2Hard-Bench：用于评估LLM性能和泛化能力的标准化难度标签",
      "authors": [
        "Mucong Ding",
        "Chenghao Deng",
        "Jocelyn Choo",
        "Zichu Wu",
        "Aakriti Agrawal",
        "Avi Schwarzschild",
        "Tianyi Zhou",
        "Tom Goldstein",
        "John Langford",
        "Anima Anandkumar",
        "Furong Huang"
      ],
      "abstract": "While generalization over tasks from easy to hard is crucial to profile\nlanguage models (LLMs), the datasets with fine-grained difficulty annotations\nfor each problem across a broad range of complexity are still blank. Aiming to\naddress this limitation, we present Easy2Hard-Bench, a consistently formatted\ncollection of 6 benchmark datasets spanning various domains, such as\nmathematics and programming problems, chess puzzles, and reasoning questions.\nEach problem within these datasets is annotated with numerical difficulty\nscores. To systematically estimate problem difficulties, we collect abundant\nperformance data on attempts to each problem by humans in the real world or\nLLMs on the prominent leaderboard. Leveraging the rich performance data, we\napply well-established difficulty ranking systems, such as Item Response Theory\n(IRT) and Glicko-2 models, to uniformly assign numerical difficulty scores to\nproblems. Moreover, datasets in Easy2Hard-Bench distinguish themselves from\nprevious collections by a higher proportion of challenging problems. Through\nextensive experiments with six state-of-the-art LLMs, we provide a\ncomprehensive analysis of their performance and generalization capabilities\nacross varying levels of difficulty, with the aim of inspiring future research\nin LLM generalization. The datasets are available at\nhttps://huggingface.co/datasets/furonghuang-lab/Easy2Hard-Bench.",
      "tldr_zh": "本论文提出了 Easy2Hard-Bench，这是一个包含6个基准数据集的集合，用于评估语言模型（LLMs）的性能和泛化能力，数据集涵盖数学、编程、国际象棋和推理等领域，并为每个问题分配标准化的数值难度分数。研究团队通过收集真实世界人类表现数据和LLMs排行榜数据，并应用 Item Response Theory (IRT) 和 Glicko-2 模型来系统地计算问题难度，确保数据集具有更高比例的挑战性问题。实验对六种最先进的LLMs进行全面测试，分析了它们在不同难度水平下的性能和泛化能力，为未来LLMs泛化研究提供宝贵资源。数据集可从https://huggingface.co/datasets/furonghuang-lab/Easy2Hard-Bench获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Datasets and Benchmarks Track",
      "pdf_url": "http://arxiv.org/pdf/2409.18433v1",
      "published_date": "2024-09-27 03:49:56 UTC",
      "updated_date": "2024-09-27 03:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:45:04.151752"
    },
    {
      "arxiv_id": "2409.18427v3",
      "title": "Neural Collaborative Filtering to Detect Anomalies in Human Semantic Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Yueyang Liu",
        "Lance Kennedy",
        "Hossein Amiri",
        "Andreas Züfle"
      ],
      "abstract": "Human trajectory anomaly detection has become increasingly important across a\nwide range of applications, including security surveillance and public health.\nHowever, existing trajectory anomaly detection methods are primarily focused on\nvehicle-level traffic, while human-level trajectory anomaly detection remains\nunder-explored. Since human trajectory data is often very sparse, machine\nlearning methods have become the preferred approach for identifying complex\npatterns. However, concerns regarding potential biases and the robustness of\nthese models have intensified the demand for more transparent and explainable\nalternatives. In response to these challenges, our research focuses on\ndeveloping a lightweight anomaly detection model specifically designed to\ndetect anomalies in human trajectories. We propose a Neural Collaborative\nFiltering approach to model and predict normal mobility. Our method is designed\nto model users' daily patterns of life without requiring prior knowledge,\nthereby enhancing performance in scenarios where data is sparse or incomplete,\nsuch as in cold start situations. Our algorithm consists of two main modules.\nThe first is the collaborative filtering module, which applies collaborative\nfiltering to model normal mobility of individual humans to places of interest.\nThe second is the neural module, responsible for interpreting the complex\nspatio-temporal relationships inherent in human trajectory data. To validate\nour approach, we conducted extensive experiments using simulated and real-world\ndatasets comparing to numerous state-of-the-art trajectory anomaly detection\napproaches.",
      "tldr_zh": "本研究针对人类语义轨迹异常检测问题，强调其在安全监控和公共健康领域的应用，但现有方法多聚焦于车辆轨迹，且受数据稀疏性影响。作者提出了一种轻量级的 Neural Collaborative Filtering 模型，通过协作过滤模块建模正常移动模式和神经模块处理复杂时空关系，而无需先验知识，提升了在稀疏数据和冷启动场景下的性能。实验结果显示，该方法在模拟和真实数据集上优于多种现有轨迹异常检测方法，提供更透明和鲁棒的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in the 1st ACM SIGSPATIAL International\n  Workshop on Geospatial Anomaly Detection (GeoAnomalies'24)",
      "pdf_url": "http://arxiv.org/pdf/2409.18427v3",
      "published_date": "2024-09-27 03:28:11 UTC",
      "updated_date": "2024-10-08 14:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:45:13.213962"
    },
    {
      "arxiv_id": "2409.18418v2",
      "title": "A3: Active Adversarial Alignment for Source-Free Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Chrisantus Eze",
        "Christopher Crick"
      ],
      "abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. Recent works have focused\non source-free UDA, where only target data is available. This is challenging as\nmodels rely on noisy pseudo-labels and struggle with distribution shifts. We\npropose Active Adversarial Alignment (A3), a novel framework combining\nself-supervised learning, adversarial training, and active learning for robust\nsource-free UDA. A3 actively samples informative and diverse data using an\nacquisition function for training. It adapts models via adversarial losses and\nconsistency regularization, aligning distributions without source data access.\nA3 advances source-free UDA through its synergistic integration of active and\nadversarial learning for effective domain alignment and noise reduction.",
      "tldr_zh": "本论文针对无监督域适应 (UDA) 中的 source-free 场景，提出了一种名为 Active Adversarial Alignment (A3) 的框架，以解决模型依赖嘈杂伪标签和分布偏移的挑战。A3 通过结合自监督学习、对抗训练和 active learning，使用获取函数主动采样信息丰富且多样的目标数据，并通过对抗损失和一致性正则化实现分布对齐，而无需访问源数据。该框架通过主动和对抗学习的协同整合，有效提升了域适应性能，并减少了噪声干扰，为 source-free UDA 提供了更鲁棒的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICMLA 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18418v2",
      "published_date": "2024-09-27 03:17:01 UTC",
      "updated_date": "2024-10-07 18:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:45:26.006282"
    },
    {
      "arxiv_id": "2409.18417v2",
      "title": "VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Guoxi Zhang",
        "Jiuding Duan"
      ],
      "abstract": "This paper addresses the cost-efficiency aspect of Reinforcement Learning\nfrom Human Feedback (RLHF). RLHF leverages datasets of human preferences over\noutputs of large language models (LLM)s to instill human expectations into\nLLMs. Although preference annotation comes with a monetized cost, the economic\nutility of a preference dataset has not been considered by far. What\nexacerbates this situation is that, given complex intransitive or cyclic\nrelationships in preference datasets, existing algorithms for fine-tuning LLMs\nare still far from capturing comprehensive preferences. This raises severe\ncost-efficiency concerns in production environments, where preference data\naccumulate over time. In this paper, we discuss the fine-tuning of LLMs as a\nmonetized economy and introduce an auction mechanism to improve the efficiency\nof preference data collection in dollar terms. We show that introducing an\nauction mechanism can play an essential role in enhancing the cost-efficiency\nof RLHF, while maintaining satisfactory model performance. Experimental results\ndemonstrate that our proposed auction-based protocol is cost-effective for\nfine-tuning LLMs concentrating on high-quality feedback.",
      "tldr_zh": "本论文针对 Reinforcement Learning from Human Feedback (RLHF) 中的成本效率问题，提出了一种名为 VickreyFeedback 的拍卖机制，以优化偏好数据收集过程。方法将 LLM 微调视为一个货币化经济系统，通过拍卖机制筛选高价值反馈，解决偏好数据集中的复杂关系（如非传递性和循环），从而提升数据建设的经济效用。实验结果表明，该协议在保持模型性能的同时，显著降低了成本，并专注于高质量反馈的收集。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18417v2",
      "published_date": "2024-09-27 03:15:07 UTC",
      "updated_date": "2024-12-12 06:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:45:39.431973"
    },
    {
      "arxiv_id": "2409.18412v3",
      "title": "SciDFM: A Large Language Model with Mixture-of-Experts for Science",
      "title_zh": "SciDFM：",
      "authors": [
        "Liangtai Sun",
        "Danyu Luo",
        "Da Ma",
        "Zihan Zhao",
        "Baocai Chen",
        "Zhennan Shen",
        "Su Zhu",
        "Lu Chen",
        "Xin Chen",
        "Kai Yu"
      ],
      "abstract": "Recently, there has been a significant upsurge of interest in leveraging\nlarge language models (LLMs) to assist scientific discovery. However, most LLMs\nonly focus on general science, while they lack domain-specific knowledge, such\nas chemical molecules and amino acid sequences. To bridge these gaps, we\nintroduce SciDFM, a mixture-of-experts LLM, which is trained from scratch and\nis able to conduct college-level scientific reasoning and understand molecules\nand amino acid sequences. We collect a large-scale training corpus containing\nnumerous scientific papers and books from different disciplines as well as data\nfrom domain-specific databases. We further fine-tune the pre-trained model on\nlots of instruction data to improve performances on downstream benchmarks. From\nexperiment results, we show that SciDFM achieves strong performance on general\nscientific benchmarks such as SciEval and SciQ, and it reaches a SOTA\nperformance on domain-specific benchmarks among models of similar size. We\nfurther analyze the expert layers and show that the results of expert selection\nvary with data from different disciplines. To benefit the broader research\ncommunity, we open-source SciDFM at\nhttps://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0.",
      "tldr_zh": "该研究提出 SciDFM，一种基于 Mixture-of-Experts 的 Large Language Model (LLM)，旨在解决现有 LLM 在科学领域缺乏特定知识（如化学分子和氨基酸序列）的问题。\nSciDFM 从零开始训练，使用大规模科学论文、书籍和领域数据库数据作为语料，并通过微调指令数据来提升下游任务性能。\n实验结果显示，该模型在一般科学基准如 SciEval 和 SciQ 上表现出色，并在同规模模型中于领域特定基准上达到 SOTA 水平；此外，分析表明专家层选择因学科不同而有所差异。\n为促进研究社区，SciDFM 已开源于 https://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 1 figure, 9 tables. Technical Report, accepted by NeurIPS\n  2024 Workshop FM4Science",
      "pdf_url": "http://arxiv.org/pdf/2409.18412v3",
      "published_date": "2024-09-27 03:00:29 UTC",
      "updated_date": "2024-11-12 09:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:45:50.670778"
    },
    {
      "arxiv_id": "2409.18411v1",
      "title": "BoT-Drive: Hierarchical Behavior and Trajectory Planning for Autonomous Driving using POMDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanjin Jin",
        "Chendong Zeng",
        "Shengfa Zhu",
        "Chunxiao Liu",
        "Panpan Cai"
      ],
      "abstract": "Uncertainties in dynamic road environments pose significant challenges for\nbehavior and trajectory planning in autonomous driving. This paper introduces\nBoT-Drive, a planning algorithm that addresses uncertainties at both behavior\nand trajectory levels within a Partially Observable Markov Decision Process\n(POMDP) framework. BoT-Drive employs driver models to characterize unknown\nbehavioral intentions and utilizes their model parameters to infer hidden\ndriving styles. By also treating driver models as decision-making actions for\nthe autonomous vehicle, BoT-Drive effectively tackles the exponential\ncomplexity inherent in POMDPs. To enhance safety and robustness, the planner\nfurther applies importance sampling to refine the driving trajectory\nconditioned on the planned high-level behavior. Evaluation on real-world data\nshows that BoT-Drive consistently outperforms both existing planning methods\nand learning-based methods in regular and complex urban driving scenes,\ndemonstrating significant improvements in driving safety and reliability.",
      "tldr_zh": "本论文提出 BoT-Drive，一种基于 Partially Observable Markov Decision Process (POMDPs) 的层次化规划算法，用于处理自动驾驶中动态道路环境的不确定性。该算法通过 driver models 表征未知行为意图，并利用这些模型的参数推断隐藏的驾驶风格，同时将 driver models 作为决策动作来应对 POMDPs 的指数复杂度。为提升安全性和鲁棒性，BoT-Drive 采用 importance sampling 优化驾驶轨迹。在真实世界数据评估中，该方法在常规和复杂城市场景中显著优于现有规划和基于学习的算法，提高了驾驶安全和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18411v1",
      "published_date": "2024-09-27 02:58:46 UTC",
      "updated_date": "2024-09-27 02:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:46:04.382987"
    },
    {
      "arxiv_id": "2409.18401v1",
      "title": "GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Lu",
        "Yingpeng Zhang",
        "Zengjun Zhao",
        "He Wang",
        "Kun Zhou",
        "Tianjia Shao"
      ],
      "abstract": "Large-scale text-guided image diffusion models have shown astonishing results\nin text-to-image (T2I) generation. However, applying these models to synthesize\ntextures for 3D geometries remains challenging due to the domain gap between 2D\nimages and textures on a 3D surface. Early works that used a\nprojecting-and-inpainting approach managed to preserve generation diversity but\noften resulted in noticeable artifacts and style inconsistencies. While recent\nmethods have attempted to address these inconsistencies, they often introduce\nother issues, such as blurring, over-saturation, or over-smoothing. To overcome\nthese challenges, we propose a novel text-to-texture synthesis framework that\nleverages pretrained diffusion models. We first introduce a local attention\nreweighing mechanism in the self-attention layers to guide the model in\nconcentrating on spatial-correlated patches across different views, thereby\nenhancing local details while preserving cross-view consistency. Additionally,\nwe propose a novel latent space merge pipeline, which further ensures\nconsistency across different viewpoints without sacrificing too much diversity.\nOur method significantly outperforms existing state-of-the-art techniques\nregarding texture consistency and visual quality, while delivering results much\nfaster than distillation-based methods. Importantly, our framework does not\nrequire additional training or fine-tuning, making it highly adaptable to a\nwide range of models available on public platforms.",
      "tldr_zh": "该论文提出了一种名为GenesisTex2的文本到纹理（text-to-texture）合成框架，旨在解决基于预训练扩散模型在3D几何纹理生成中的挑战，如风格不一致和视觉伪像问题。框架引入局部注意力重分配机制（local attention reweighing mechanism），在自注意力层（self-attention layers）中引导模型关注不同视图的空间相关补丁，从而提升局部细节并保持跨视图一致性；同时，采用新型潜在空间合并管道（latent space merge pipeline）来确保视角一致性而不牺牲生成多样性。该方法无需额外训练或微调，便于适应各种公共模型，并在纹理一致性和视觉质量上显著优于现有技术，比基于蒸馏的方法更快地生成高质量结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18401v1",
      "published_date": "2024-09-27 02:32:42 UTC",
      "updated_date": "2024-09-27 02:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:46:14.528193"
    },
    {
      "arxiv_id": "2409.18399v1",
      "title": "Multimodal Trajectory Prediction for Autonomous Driving on Unstructured Roads using Deep Convolutional Network",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Li",
        "Zhifa Chen",
        "Jian Wang",
        "Bin Zhou",
        "Guizhen Yu",
        "Xiaoxuan Chen"
      ],
      "abstract": "Recently, the application of autonomous driving in open-pit mining has\ngarnered increasing attention for achieving safe and efficient mineral\ntransportation. Compared to urban structured roads, unstructured roads in\nmining sites have uneven boundaries and lack clearly defined lane markings.\nThis leads to a lack of sufficient constraint information for predicting the\ntrajectories of other human-driven vehicles, resulting in higher uncertainty in\ntrajectory prediction problems. A method is proposed to predict multiple\npossible trajectories and their probabilities of the target vehicle. The\nsurrounding environment and historical trajectories of the target vehicle are\nencoded as a rasterized image, which is used as input to our deep convolutional\nnetwork to predict the target vehicle's multiple possible trajectories. The\nmethod underwent offline testing on a dataset specifically designed for\nautonomous driving scenarios in open-pit mining and was compared and evaluated\nagainst physics-based method. The open-source code and data are available at\nhttps://github.com/LLsxyc/mine_motion_prediction.git",
      "tldr_zh": "该研究针对露天矿山的非结构化道路（Unstructured Roads）上自主驾驶（Autonomous Driving）的轨迹预测问题，提出了一种多模态轨迹预测方法，以解决由于边界不均匀和缺乏车道标记导致的不确定性。方法将目标车辆的周围环境和历史轨迹编码为栅格化图像，作为深度卷积网络（Deep Convolutional Network）的输入，预测多条可能轨迹及其概率。在专为露天矿山场景设计的数据集上进行离线测试，该方法与基于物理的方法相比表现出色，并提供了开源代码和数据以支持进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.18399v1",
      "published_date": "2024-09-27 02:29:02 UTC",
      "updated_date": "2024-09-27 02:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:46:27.030502"
    },
    {
      "arxiv_id": "2409.18395v1",
      "title": "Code Vulnerability Repair with Large Language Model using Context-Aware Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Arshiya Khan",
        "Guannan Liu",
        "Xing Gao"
      ],
      "abstract": "Large Language Models (LLMs) have shown significant challenges in detecting\nand repairing vulnerable code, particularly when dealing with vulnerabilities\ninvolving multiple aspects, such as variables, code flows, and code structures.\nIn this study, we utilize GitHub Copilot as the LLM and focus on buffer\noverflow vulnerabilities. Our experiments reveal a notable gap in Copilot's\nabilities when dealing with buffer overflow vulnerabilities, with a 76%\nvulnerability detection rate but only a 15% vulnerability repair rate. To\naddress this issue, we propose context-aware prompt tuning techniques designed\nto enhance LLM performance in repairing buffer overflow. By injecting a\nsequence of domain knowledge about the vulnerability, including various\nsecurity and code contexts, we demonstrate that Copilot's successful repair\nrate increases to 63%, representing more than four times the improvement\ncompared to repairs without domain knowledge.",
      "tldr_zh": "本研究发现，大型语言模型(LLMs)如GitHub Copilot在检测和修复缓冲区溢出(buffer overflow)漏洞时存在显著挑战，检测率达76%但修复率仅为15%。为了解决这一问题，作者提出context-aware prompt tuning技术，通过注入相关领域知识（如安全和代码上下文）来优化提示内容，从而提升LLMs的修复性能。实验结果显示，该方法使Copilot的修复率提高到63%，实现了超过四倍的改进，为LLMs在代码漏洞修复中的应用提供了有效策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18395v1",
      "published_date": "2024-09-27 02:25:29 UTC",
      "updated_date": "2024-09-27 02:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:46:37.687289"
    },
    {
      "arxiv_id": "2409.18390v4",
      "title": "Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Htet Kyaw",
        "Se Hwan Jeon",
        "Miana Smith",
        "Neil Gershenfeld"
      ],
      "abstract": "We present a system that transforms speech into physical objects by combining\n3D generative Artificial Intelligence with robotic assembly. The system\nleverages natural language input to make design and manufacturing more\naccessible, enabling individuals without expertise in 3D modeling or robotic\nprogramming to create physical objects. We propose utilizing discrete robotic\nassembly of lattice-based voxel components to address the challenges of using\ngenerative AI outputs in physical production, such as design variability,\nfabrication speed, structural integrity, and material waste. The system\ninterprets speech to generate 3D objects, discretizes them into voxel\ncomponents, computes an optimized assembly sequence, and generates a robotic\ntoolpath. The results are demonstrated through the assembly of various objects,\nranging from chairs to shelves, which are prompted via speech and realized\nwithin 5 minutes using a 6-axis robotic arm.",
      "tldr_zh": "本文提出一个系统，名为Speech to Reality，通过Natural Language输入、3D Generative AI和Discrete Robotic Assembly相结合，将语音转化为物理物体，从而使非专家用户能够轻松进行设计和制造。系统采用基于格子的体素组件进行离散机器人组装，解决生成AI输出在实际生产中的挑战，如设计变异、制造速度、结构完整性和材料浪费，并通过计算优化组装序列和生成机器人toolpath实现高效流程。实验演示显示，该系统能在5分钟内使用6轴机器人臂组装各种物体，如椅子和架子，显著提升了生产的可访问性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been submitted to the IEEE for possible publication. An\n  updated version will replace this version",
      "pdf_url": "http://arxiv.org/pdf/2409.18390v4",
      "published_date": "2024-09-27 02:12:56 UTC",
      "updated_date": "2025-04-05 22:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:46:52.264534"
    },
    {
      "arxiv_id": "2409.18385v1",
      "title": "Robo-CSK-Organizer: Commonsense Knowledge to Organize Detected Objects for Multipurpose Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Hidalgo",
        "Jesse Parron",
        "Aparna S. Varde",
        "Weitian Wang"
      ],
      "abstract": "This paper presents a system called Robo-CSK-Organizer that infuses\ncommonsense knowledge from a classical knowledge based to enhance the context\nrecognition capabilities of robots so as to facilitate the organization of\ndetected objects by classifying them in a task-relevant manner. It is\nparticularly useful in multipurpose robotics. Unlike systems relying solely on\ndeep learning tools such as ChatGPT, the Robo-CSK-Organizer system stands out\nin multiple avenues as follows. It resolves ambiguities well, and maintains\nconsistency in object placement. Moreover, it adapts to diverse task-based\nclassifications. Furthermore, it contributes to explainable AI, hence helping\nto improve trust and human-robot collaboration. Controlled experiments\nperformed in our work, simulating domestic robotics settings, make\nRobo-CSK-Organizer demonstrate superior performance while placing objects in\ncontextually relevant locations. This work highlights the capacity of an\nAI-based system to conduct commonsense-guided decision-making in robotics\ncloser to the thresholds of human cognition. Hence, Robo-CSK-Organizer makes\npositive impacts on AI and robotics.",
      "tldr_zh": "本研究提出Robo-CSK-Organizer系统，通过整合经典常识知识（Commonsense Knowledge）来提升多功能机器人的上下文识别能力，从而实现对检测对象的任务相关分类和组织。该系统在解决对象放置歧义、保持一致性以及适应多样任务分类方面优于仅依赖深度学习工具（如ChatGPT）的模型，同时增强了可解释AI（Explainable AI），促进人类-机器人协作。在模拟家庭机器人环境的控制实验中，Robo-CSK-Organizer展示了卓越性能，接近人类认知水平的决策能力，并为AI和机器人领域带来积极影响。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.6; I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18385v1",
      "published_date": "2024-09-27 02:01:05 UTC",
      "updated_date": "2024-09-27 02:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:47:01.714041"
    },
    {
      "arxiv_id": "2409.18374v1",
      "title": "Adaptive Learning of the Latent Space of Wasserstein Generative Adversarial Networks",
      "title_zh": "Wasserstein 生成对抗网络潜空间的自适应学习",
      "authors": [
        "Yixuan Qiu",
        "Qingyi Gao",
        "Xiao Wang"
      ],
      "abstract": "Generative models based on latent variables, such as generative adversarial\nnetworks (GANs) and variational auto-encoders (VAEs), have gained lots of\ninterests due to their impressive performance in many fields. However, many\ndata such as natural images usually do not populate the ambient Euclidean space\nbut instead reside in a lower-dimensional manifold. Thus an inappropriate\nchoice of the latent dimension fails to uncover the structure of the data,\npossibly resulting in mismatch of latent representations and poor generative\nqualities. Towards addressing these problems, we propose a novel framework\ncalled the latent Wasserstein GAN (LWGAN) that fuses the Wasserstein\nauto-encoder and the Wasserstein GAN so that the intrinsic dimension of the\ndata manifold can be adaptively learned by a modified informative latent\ndistribution. We prove that there exist an encoder network and a generator\nnetwork in such a way that the intrinsic dimension of the learned encoding\ndistribution is equal to the dimension of the data manifold. We theoretically\nestablish that our estimated intrinsic dimension is a consistent estimate of\nthe true dimension of the data manifold. Meanwhile, we provide an upper bound\non the generalization error of LWGAN, implying that we force the synthetic data\ndistribution to be similar to the real data distribution from a population\nperspective. Comprehensive empirical experiments verify our framework and show\nthat LWGAN is able to identify the correct intrinsic dimension under several\nscenarios, and simultaneously generate high-quality synthetic data by sampling\nfrom the learned latent distribution.",
      "tldr_zh": "该研究针对生成模型如 GANs 和 VAEs 在处理低维数据流形（如自然图像）时的潜在维度不当问题，提出了一种新框架 Latent Wasserstein GAN (LWGAN)，它融合 Wasserstein Auto-Encoder 和 Wasserstein GAN，以自适应学习数据流形的内在维度。LWGAN 通过修改信息性潜在分布，确保编码分布的内在维度等于数据流形的真实维度，并证明了这一估计的相合性及泛化误差上界。实验结果显示，LWGAN 能够在多种场景下准确识别内在维度，同时生成高质量的合成数据。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18374v1",
      "published_date": "2024-09-27 01:25:22 UTC",
      "updated_date": "2024-09-27 01:25:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:47:15.176565"
    },
    {
      "arxiv_id": "2409.18364v3",
      "title": "Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images",
      "title_zh": "翻译失败",
      "authors": [
        "Donghwan Kim",
        "Tae-Kyun Kim"
      ],
      "abstract": "3D human shape reconstruction under severe occlusion due to human-object or\nhuman-human interaction is a challenging problem. Parametric models i.e.,\nSMPL(-X), which are based on the statistics across human shapes, can represent\nwhole human body shapes but are limited to minimally-clothed human shapes.\nImplicit-function-based methods extract features from the parametric models to\nemploy prior knowledge of human bodies and can capture geometric details such\nas clothing and hair. However, they often struggle to handle misaligned\nparametric models and inpaint occluded regions given a single RGB image. In\nthis work, we propose a novel pipeline, MHCDIFF, Multi-hypotheses Conditioned\nPoint Cloud Diffusion, composed of point cloud diffusion conditioned on\nprobabilistic distributions for pixel-aligned detailed 3D human reconstruction\nunder occlusion. Compared to previous implicit-function-based methods, the\npoint cloud diffusion model can capture the global consistent features to\ngenerate the occluded regions, and the denoising process corrects the\nmisaligned SMPL meshes. The core of MHCDIFF is extracting local features from\nmultiple hypothesized SMPL(-X) meshes and aggregating the set of features to\ncondition the diffusion model. In the experiments on CAPE and MultiHuman\ndatasets, the proposed method outperforms various SOTA methods based on SMPL,\nimplicit functions, point cloud diffusion, and their combined, under synthetic\nand real occlusions. Our code is publicly available at\nhttps://donghwankim0101.github.io/projects/mhcdiff/ .",
      "tldr_zh": "该研究提出 MHCDIFF，一种多假设条件点云扩散方法，用于从遮挡图像中重建详细的像素对齐 3D 人体形状，解决现有参数模型如 SMPL(-X) 和隐式函数方法的局限性，如处理不对齐网格和修复遮挡区域的挑战。核心机制涉及从多个假设的 SMPL(-X) 网格中提取局部特征，聚合这些特征来条件点云扩散模型，从而捕捉全局一致特征并生成遮挡区域。实验在 CAPE 和 MultiHuman 数据集上显示，该方法在合成和真实遮挡场景下优于多种 SOTA 方法，包括基于 SMPL、隐式函数和点云扩散的模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 7 figures, accepted NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.18364v3",
      "published_date": "2024-09-27 00:49:08 UTC",
      "updated_date": "2024-10-29 10:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:47:26.615873"
    },
    {
      "arxiv_id": "2409.18351v1",
      "title": "Tracking Software Security Topics",
      "title_zh": "追踪软件安全主题",
      "authors": [
        "Phong Minh Vu",
        "Tung Thanh Nguyen"
      ],
      "abstract": "Software security incidents occur everyday and thousands of software security\nreports are announced each month. Thus, it is difficult for software security\nresearchers, engineers, and other stakeholders to follow software security\ntopics of their interests in real-time. In this paper, we propose, SOSK, a\nnovel tool for this problem. SOSK allows a user to import a collection of\nsoftware security reports. It pre-processes and extracts the most important\nkeywords from the textual description of the reports. Based on the similarity\nof embedding vectors of keywords, SOSK can expand and/or refine a keyword set\nfrom a much smaller set of user-provided keywords. Thus, SOSK allows users to\ndefine any topic of their interests and retrieve security reports relevant to\nthat topic effectively. Our preliminary evaluation shows that SOSK can expand\nkeywords and retrieve reports relevant to user requests.",
      "tldr_zh": "该研究针对软件安全报告众多且难以实时跟踪的问题，提出了一种名为 SOSK 的工具。SOSK 允许用户导入报告，进行预处理并提取关键词，然后通过关键词的 embedding vectors 相似性来扩展或精炼用户提供的关键词集，从而定义和检索相关安全主题。初步评估显示，SOSK 能够有效扩展关键词并获取与用户请求相关的报告。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.18351v1",
      "published_date": "2024-09-27 00:05:01 UTC",
      "updated_date": "2024-09-27 00:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:47:37.801645"
    },
    {
      "arxiv_id": "2410.03521v2",
      "title": "Building a Chinese Medical Dialogue System: Integrating Large-scale Corpora and Novel Models",
      "title_zh": "构建中文医疗对话系统：整合大规模语料库和新型模型",
      "authors": [
        "Xinyuan Wang",
        "Haozhou Li",
        "Dingfang Zheng",
        "Qinke Peng"
      ],
      "abstract": "The global COVID-19 pandemic underscored major deficiencies in traditional\nhealthcare systems, hastening the advancement of online medical services,\nespecially in medical triage and consultation. However, existing studies face\ntwo main challenges. First, the scarcity of large-scale, publicly available,\ndomain-specific medical datasets due to privacy concerns, with current datasets\nbeing small and limited to a few diseases, limiting the effectiveness of triage\nmethods based on Pre-trained Language Models (PLMs). Second, existing methods\nlack medical knowledge and struggle to accurately understand professional terms\nand expressions in patient-doctor consultations. To overcome these obstacles,\nwe construct the Large-scale Chinese Medical Dialogue Corpora (LCMDC), thereby\naddressing the data shortage in this field. Moreover, we further propose a\nnovel triage system that combines BERT-based supervised learning with prompt\nlearning, as well as a GPT-based medical consultation model. To enhance domain\nknowledge acquisition, we pre-trained PLMs using our self-constructed\nbackground corpus. Experimental results on the LCMDC demonstrate the efficacy\nof our proposed systems.",
      "tldr_zh": "该研究针对在线医疗服务的挑战，构建了大规模中文医疗对话语料库（LCMDC），以解决现有数据集规模小和领域知识不足的问题。论文提出了一种新型分诊系统，结合BERT-based监督学习和提示学习，并开发了一个GPT-based医疗咨询模型，通过预训练PLMs来增强对专业医疗术语的理解。实验结果在LCMDC上证明了这些系统的有效性，为在线医疗问诊和分诊提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03521v2",
      "published_date": "2024-09-27 00:01:32 UTC",
      "updated_date": "2025-02-25 02:17:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:47:49.973123"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 110,
  "processed_papers_count": 110,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T04:48:11.297981"
}