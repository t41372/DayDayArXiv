[
  {
    "arxiv_id": "2408.05646v2",
    "title": "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression",
    "authors": [
      "Utkarsh Saxena",
      "Gobinda Saha",
      "Sakshi Choudhary",
      "Kaushik Roy"
    ],
    "abstract": "Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance. Code is available at\nhttps://github.com/UtkarshSaxena1/EigenAttn.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "12 page, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05646v2",
    "published_date": "2024-08-10 22:47:12 UTC",
    "updated_date": "2024-11-08 16:29:33 UTC"
  },
  {
    "arxiv_id": "2408.05640v2",
    "title": "Federated Smoothing Proximal Gradient for Quantile Regression with Non-Convex Penalties",
    "authors": [
      "Reza Mirzaeifard",
      "Diyako Ghaderyan",
      "Stefan Werner"
    ],
    "abstract": "Distributed sensors in the internet-of-things (IoT) generate vast amounts of\nsparse data. Analyzing this high-dimensional data and identifying relevant\npredictors pose substantial challenges, especially when data is preferred to\nremain on the device where it was collected for reasons such as data integrity,\ncommunication bandwidth, and privacy. This paper introduces a federated\nquantile regression algorithm to address these challenges. Quantile regression\nprovides a more comprehensive view of the relationship between variables than\nmean regression models. However, traditional approaches face difficulties when\ndealing with nonconvex sparse penalties and the inherent non-smoothness of the\nloss function. For this purpose, we propose a federated smoothing proximal\ngradient (FSPG) algorithm that integrates a smoothing mechanism with the\nproximal gradient framework, thereby enhancing both precision and computational\nspeed. This integration adeptly handles optimization over a network of devices,\neach holding local data samples, making it particularly effective in federated\nlearning scenarios. The FSPG algorithm ensures steady progress and reliable\nconvergence in each iteration by maintaining or reducing the value of the\nobjective function. By leveraging nonconvex penalties, such as the minimax\nconcave penalty (MCP) and smoothly clipped absolute deviation (SCAD), the\nproposed method can identify and preserve key predictors within sparse models.\nComprehensive simulations validate the robust theoretical foundations of the\nproposed algorithm and demonstrate improved estimation precision and reliable\nconvergence.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05640v2",
    "published_date": "2024-08-10 21:50:19 UTC",
    "updated_date": "2024-08-13 11:52:42 UTC"
  },
  {
    "arxiv_id": "2408.05639v1",
    "title": "Enhancing Computational Efficiency in Intensive Domains via Redundant Residue Number Systems",
    "authors": [
      "Soudabeh Mousavi",
      "Dara Rahmati",
      "Saeid Gorgin",
      "Jeong-A Lee"
    ],
    "abstract": "In computation-intensive domains such as digital signal processing,\nencryption, and neural networks, the performance of arithmetic units, including\nadders and multipliers, is pivotal. Conventional numerical systems often fall\nshort of meeting the efficiency requirements of these applications concerning\narea, time, and power consumption. Innovative approaches like residue number\nsystems (RNS) and redundant number systems have been introduced to surmount\nthis challenge, markedly elevating computational efficiency. This paper\nexamines from multiple perspectives how the fusion of redundant number systems\nwith RNS (termed R-RNS) can diminish latency and enhance circuit\nimplementation, yielding substantial benefits in practical scenarios. We\nconduct a comparative analysis of four systems - RNS, redundant number system,\nBinary Number System (BNS), and Signed-Digit Redundant Residue Number System\n(SD-RNS)-and appraise SD-RNS through an advanced Deep Neural Network (DNN)\nutilizing the CIFAR-10 dataset. Our findings are encouraging, demonstrating\nthat SD-RNS attains computational speedups of 1.27 times and 2.25 times over\nRNS and BNS, respectively, and reduces energy consumption by 60% compared to\nBNS during sequential addition and multiplication tasks.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "This paper has been accepted by the 21st International SoC Conference\n  (ISOCC), 2024, 2 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.05639v1",
    "published_date": "2024-08-10 21:45:35 UTC",
    "updated_date": "2024-08-10 21:45:35 UTC"
  },
  {
    "arxiv_id": "2408.15261v1",
    "title": "Civiverse: A Dataset for Analyzing User Engagement with Open-Source Text-to-Image Models",
    "authors": [
      "Maria-Teresa De Rosa Palmini",
      "Laura Wagner",
      "Eva Cetinic"
    ],
    "abstract": "Text-to-image (TTI) systems, particularly those utilizing open-source\nframeworks, have become increasingly prevalent in the production of Artificial\nIntelligence (AI)-generated visuals. While existing literature has explored\nvarious problematic aspects of TTI technologies, such as bias in generated\ncontent, intellectual property concerns, and the reinforcement of harmful\nstereotypes, open-source TTI frameworks have not yet been systematically\nexamined from a cultural perspective. This study addresses this gap by\nanalyzing the CivitAI platform, a leading open-source platform dedicated to TTI\nAI. We introduce the Civiverse prompt dataset, encompassing millions of images\nand related metadata. We focus on prompt analysis, specifically examining the\nsemantic characteristics of text prompts, as it is crucial for addressing\nsocietal issues related to generative technologies. This analysis provides\ninsights into user intentions, preferences, and behaviors, which in turn shape\nthe outputs of these models. Our findings reveal a predominant preference for\ngenerating explicit content, along with a focus on homogenization of semantic\ncontent. These insights underscore the need for further research into the\nperpetuation of misogyny, harmful stereotypes, and the uniformity of visual\nculture within these models.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.15261v1",
    "published_date": "2024-08-10 21:41:03 UTC",
    "updated_date": "2024-08-10 21:41:03 UTC"
  },
  {
    "arxiv_id": "2408.05631v1",
    "title": "PRTGaussian: Efficient Relighting Using 3D Gaussians with Precomputed Radiance Transfer",
    "authors": [
      "Libo Zhang",
      "Yuxuan Han",
      "Wenbin Lin",
      "Jingwang Ling",
      "Feng Xu"
    ],
    "abstract": "We present PRTGaussian, a realtime relightable novel-view synthesis method\nmade possible by combining 3D Gaussians and Precomputed Radiance Transfer\n(PRT). By fitting relightable Gaussians to multi-view OLAT data, our method\nenables real-time, free-viewpoint relighting. By estimating the radiance\ntransfer based on high-order spherical harmonics, we achieve a balance between\ncapturing detailed relighting effects and maintaining computational efficiency.\nWe utilize a two-stage process: in the first stage, we reconstruct a coarse\ngeometry of the object from multi-view images. In the second stage, we\ninitialize 3D Gaussians with the obtained point cloud, then simultaneously\nrefine the coarse geometry and learn the light transport for each Gaussian.\nExtensive experiments on synthetic datasets show that our approach can achieve\nfast and high-quality relighting for general objects. Code and data are\navailable at https://github.com/zhanglbthu/PRTGaussian.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05631v1",
    "published_date": "2024-08-10 20:57:38 UTC",
    "updated_date": "2024-08-10 20:57:38 UTC"
  },
  {
    "arxiv_id": "2408.05629v2",
    "title": "Quantum-secure multiparty deep learning",
    "authors": [
      "Kfir Sulimany",
      "Sri Krishna Vadlamani",
      "Ryan Hamerly",
      "Prahlad Iyengar",
      "Dirk Englund"
    ],
    "abstract": "Secure multiparty computation enables the joint evaluation of multivariate\nfunctions across distributed users while ensuring the privacy of their local\ninputs. This field has become increasingly urgent due to the exploding demand\nfor computationally intensive deep learning inference. These computations are\ntypically offloaded to cloud computing servers, leading to vulnerabilities that\ncan compromise the security of the clients' data. To solve this problem, we\nintroduce a linear algebra engine that leverages the quantum nature of light\nfor information-theoretically secure multiparty computation using only\nconventional telecommunication components. We apply this linear algebra engine\nto deep learning and derive rigorous upper bounds on the information leakage of\nboth the deep neural network weights and the client's data via the Holevo and\nthe Cram\\'er-Rao bounds, respectively. Applied to the MNIST classification\ntask, we obtain test accuracies exceeding $96\\%$ while leaking less than $0.1$\nbits per weight symbol and $0.01$ bits per data symbol. This weight leakage is\nan order of magnitude below the minimum bit precision required for accurate\ndeep learning using state-of-the-art quantization techniques. Our work lays the\nfoundation for practical quantum-secure computation and unlocks secure cloud\ndeep learning as a field.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "physics.optics"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05629v2",
    "published_date": "2024-08-10 20:48:40 UTC",
    "updated_date": "2024-09-13 10:49:21 UTC"
  },
  {
    "arxiv_id": "2408.05628v1",
    "title": "Forecasting Day-Ahead Electricity Prices in the Integrated Single Electricity Market: Addressing Volatility with Comparative Machine Learning Methods",
    "authors": [
      "Ben Harkin",
      "Xueqin Liu"
    ],
    "abstract": "This paper undertakes a comprehensive investigation of electricity price\nforecasting methods, focused on the Irish Integrated Single Electricity Market,\nparticularly on changes during recent periods of high volatility. The primary\nobjective of this research is to evaluate and compare the performance of\nvarious forecasting models, ranging from traditional machine learning models to\nmore complex neural networks, as well as the impact of different lengths of\ntraining periods. The performance metrics, mean absolute error, root mean\nsquare error, and relative mean absolute error, are utilized to assess and\ncompare the accuracy of each model. A comprehensive set of input features was\ninvestigated and selected from data recorded between October 2018 and September\n2022. The paper demonstrates that the daily EU Natural Gas price is a more\nuseful feature for electricity price forecasting in Ireland than the daily\nHenry Hub Natural Gas price. This study also shows that the correlation of\nfeatures to the day-ahead market price has changed in recent years. The price\nof natural gas on the day and the amount of wind energy on the grid that hour\nare significantly more important than any other features. More specifically\nspeaking, the input fuel for electricity has become a more important driver of\nthe price of it, than the total generation or demand. In addition, it can be\nseen that System Non-Synchronous Penetration (SNSP) is highly correlated with\nthe day-ahead market price, and that renewables are pushing down the price of\nelectricity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05628v1",
    "published_date": "2024-08-10 20:43:21 UTC",
    "updated_date": "2024-08-10 20:43:21 UTC"
  },
  {
    "arxiv_id": "2408.07208v1",
    "title": "Hierarchical Multi-Armed Bandits for the Concurrent Intelligent Tutoring of Concepts and Problems of Varying Difficulty Levels",
    "authors": [
      "Blake Castleman",
      "Uzay Macar",
      "Ansaf Salleb-Aouissi"
    ],
    "abstract": "Remote education has proliferated in the twenty-first century, yielding rise\nto intelligent tutoring systems. In particular, research has found multi-armed\nbandit (MAB) intelligent tutors to have notable abilities in traversing the\nexploration-exploitation trade-off landscape for student problem\nrecommendations. Prior literature, however, contains a significant lack of\nopen-sourced MAB intelligent tutors, which impedes potential applications of\nthese educational MAB recommendation systems. In this paper, we combine recent\nliterature on MAB intelligent tutoring techniques into an open-sourced and\nsimply deployable hierarchical MAB algorithm, capable of progressing students\nconcurrently through concepts and problems, determining ideal recommended\nproblem difficulties, and assessing latent memory decay. We evaluate our\nalgorithm using simulated groups of 500 students, utilizing Bayesian Knowledge\nTracing to estimate students' content mastery. Results suggest that our\nalgorithm, when turned difficulty-agnostic, significantly boosts student\nsuccess, and that the further addition of problem-difficulty adaptation notably\nimproves this metric.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CY",
    "comment": "Deployable RL: From Research to Practice @ Reinforcement Learning\n  Conference 2024, 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07208v1",
    "published_date": "2024-08-10 20:11:52 UTC",
    "updated_date": "2024-08-10 20:11:52 UTC"
  },
  {
    "arxiv_id": "2408.05618v1",
    "title": "UrFound: Towards Universal Retinal Foundation Models via Knowledge-Guided Masked Modeling",
    "authors": [
      "Kai Yu",
      "Yang Zhou",
      "Yang Bai",
      "Zhi Da Soh",
      "Xinxing Xu",
      "Rick Siow Mong Goh",
      "Ching-Yu Cheng",
      "Yong Liu"
    ],
    "abstract": "Retinal foundation models aim to learn generalizable representations from\ndiverse retinal images, facilitating label-efficient model adaptation across\nvarious ophthalmic tasks. Despite their success, current retinal foundation\nmodels are generally restricted to a single imaging modality, such as Color\nFundus Photography (CFP) or Optical Coherence Tomography (OCT), limiting their\nversatility. Moreover, these models may struggle to fully leverage expert\nannotations and overlook the valuable domain knowledge essential for\ndomain-specific representation learning. To overcome these limitations, we\nintroduce UrFound, a retinal foundation model designed to learn universal\nrepresentations from both multimodal retinal images and domain knowledge.\nUrFound is equipped with a modality-agnostic image encoder and accepts either\nCFP or OCT images as inputs. To integrate domain knowledge into representation\nlearning, we encode expert annotation in text supervision and propose a\nknowledge-guided masked modeling strategy for model pre-training. It involves\nreconstructing randomly masked patches of retinal images while predicting\nmasked text tokens conditioned on the corresponding retinal image. This\napproach aligns multimodal images and textual expert annotations within a\nunified latent space, facilitating generalizable and domain-specific\nrepresentation learning. Experimental results demonstrate that UrFound exhibits\nstrong generalization ability and data efficiency when adapting to various\ntasks in retinal image analysis. By training on ~180k retinal images, UrFound\nsignificantly outperforms the state-of-the-art retinal foundation model trained\non up to 1.6 million unlabelled images across 8 public retinal datasets. Our\ncode and data are available at https://github.com/yukkai/UrFound.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05618v1",
    "published_date": "2024-08-10 19:31:29 UTC",
    "updated_date": "2024-08-10 19:31:29 UTC"
  },
  {
    "arxiv_id": "2408.05617v3",
    "title": "Residual-INR: Communication Efficient On-Device Learning Using Implicit Neural Representation",
    "authors": [
      "Hanqiu Chen",
      "Xuebin Yao",
      "Pradeep Subedi",
      "Cong Hao"
    ],
    "abstract": "Edge computing is a distributed computing paradigm that collects and\nprocesses data at or near the source of data generation. The on-device learning\nat edge relies on device-to-device wireless communication to facilitate\nreal-time data sharing and collaborative decision-making among multiple\ndevices. This significantly improves the adaptability of the edge computing\nsystem to the changing environments. However, as the scale of the edge\ncomputing system is getting larger, communication among devices is becoming the\nbottleneck because of the limited bandwidth of wireless communication leads to\nlarge data transfer latency. To reduce the amount of device-to-device data\ntransmission and accelerate on-device learning, in this paper, we propose\nResidual-INR, a fog computing-based communication-efficient on-device learning\nframework by utilizing implicit neural representation (INR) to compress\nimages/videos into neural network weights. Residual-INR enhances data transfer\nefficiency by collecting JPEG images from edge devices, compressing them into\nINR format at the fog node, and redistributing them for on-device learning. By\nusing a smaller INR for full image encoding and a separate object INR for\nhigh-quality object region reconstruction through residual encoding, our\ntechnique can reduce the encoding redundancy while maintaining the object\nquality. Residual-INR is a promising solution for edge on-device learning\nbecause it reduces data transmission by up to 5.16 x across a network of 10\nedge devices. It also facilitates CPU-free accelerated on-device learning,\nachieving up to 2.9 x speedup without sacrificing accuracy. Our code is\navailable at: https://github.com/sharc-lab/Residual-INR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ICCAD 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05617v3",
    "published_date": "2024-08-10 19:31:21 UTC",
    "updated_date": "2024-12-16 21:35:54 UTC"
  },
  {
    "arxiv_id": "2408.05610v1",
    "title": "Representation Alignment from Human Feedback for Cross-Embodiment Reward Learning from Mixed-Quality Demonstrations",
    "authors": [
      "Connor Mattson",
      "Anurag Aribandi",
      "Daniel S. Brown"
    ],
    "abstract": "We study the problem of cross-embodiment inverse reinforcement learning,\nwhere we wish to learn a reward function from video demonstrations in one or\nmore embodiments and then transfer the learned reward to a different embodiment\n(e.g., different action space, dynamics, size, shape, etc.). Learning reward\nfunctions that transfer across embodiments is important in settings such as\nteaching a robot a policy via human video demonstrations or teaching a robot to\nimitate a policy from another robot with a different embodiment. However, prior\nwork has only focused on cases where near-optimal demonstrations are available,\nwhich is often difficult to ensure. By contrast, we study the setting of\ncross-embodiment reward learning from mixed-quality demonstrations. We\ndemonstrate that prior work struggles to learn generalizable reward\nrepresentations when learning from mixed-quality data. We then analyze several\ntechniques that leverage human feedback for representation learning and\nalignment to enable effective cross-embodiment learning. Our results give\ninsight into how different representation learning techniques lead to\nqualitatively different reward shaping behaviors and the importance of human\nfeedback when learning from mixed-quality, mixed-embodiment data.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "First Two Authors Share Equal Contribution. 19 Pages, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05610v1",
    "published_date": "2024-08-10 18:24:14 UTC",
    "updated_date": "2024-08-10 18:24:14 UTC"
  },
  {
    "arxiv_id": "2408.05609v1",
    "title": "Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale",
    "authors": [
      "Vindula Jayawardana",
      "Baptiste Freydt",
      "Ao Qu",
      "Cameron Hickert",
      "Edgar Sanchez",
      "Catherine Tang",
      "Mark Taylor",
      "Blaine Leonard",
      "Cathy Wu"
    ],
    "abstract": "The sheer scale and diversity of transportation make it a formidable sector\nto decarbonize. Here, we consider an emerging opportunity to reduce carbon\nemissions: the growing adoption of semi-autonomous vehicles, which can be\nprogrammed to mitigate stop-and-go traffic through intelligent speed commands\nand, thus, reduce emissions. But would such dynamic eco-driving move the needle\non climate change? A comprehensive impact analysis has been out of reach due to\nthe vast array of traffic scenarios and the complexity of vehicle emissions. We\naddress this challenge with large-scale scenario modeling efforts and by using\nmulti-task deep reinforcement learning with a carefully designed network\ndecomposition strategy. We perform an in-depth prospective impact assessment of\ndynamic eco-driving at 6,011 signalized intersections across three major US\nmetropolitan cities, simulating a million traffic scenarios. Overall, we find\nthat vehicle trajectories optimized for emissions can cut city-wide\nintersection carbon emissions by 11-22%, without harming throughput or safety,\nand with reasonable assumptions, equivalent to the national emissions of Israel\nand Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50%\nof the total reduction, and nearly 70% of the benefits come from 20% of\nintersections, suggesting near-term implementation pathways. However, the\ncomposition of this high-impact subset of intersections varies considerably\nacross different adoption levels, with minimal overlap, calling for careful\nstrategic planning for eco-driving deployments. Moreover, the impact of\neco-driving, when considered jointly with projections of vehicle\nelectrification and hybrid vehicle adoption remains significant. More broadly,\nthis work paves the way for large-scale analysis of traffic externalities, such\nas time, safety, and air quality, and the potential impact of solution\nstrategies.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "In review",
    "pdf_url": "http://arxiv.org/pdf/2408.05609v1",
    "published_date": "2024-08-10 18:23:59 UTC",
    "updated_date": "2024-08-10 18:23:59 UTC"
  },
  {
    "arxiv_id": "2408.05606v1",
    "title": "Exploring Applications of State Space Models and Advanced Training Techniques in Sequential Recommendations: A Comparative Study on Efficiency and Performance",
    "authors": [
      "Mark Obozov",
      "Makar Baderko",
      "Stepan Kulibaba",
      "Nikolay Kutuzov",
      "Alexander Gasnikov"
    ],
    "abstract": "Recommender systems aim to estimate the dynamically changing user preferences\nand sequential dependencies between historical user behaviour and metadata.\nAlthough transformer-based models have proven to be effective in sequential\nrecommendations, their state growth is proportional to the length of the\nsequence that is being processed, which makes them expensive in terms of memory\nand inference costs. Our research focused on three promising directions in\nsequential recommendations: enhancing speed through the use of State Space\nModels (SSM), as they can achieve SOTA results in the sequential\nrecommendations domain with lower latency, memory, and inference costs, as\nproposed by arXiv:2403.03900 improving the quality of recommendations with\nLarge Language Models (LLMs) via Monolithic Preference Optimization without\nReference Model (ORPO); and implementing adaptive batch- and step-size\nalgorithms to reduce costs and accelerate training processes.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.IR",
    "comment": "arXiv admin note: text overlap with arXiv:2403.07691 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2408.05606v1",
    "published_date": "2024-08-10 18:09:10 UTC",
    "updated_date": "2024-08-10 18:09:10 UTC"
  },
  {
    "arxiv_id": "2408.06385v1",
    "title": "ViC: Virtual Compiler Is All You Need For Assembly Code Search",
    "authors": [
      "Zeyu Gao",
      "Hao Wang",
      "Yuanda Wang",
      "Chao Zhang"
    ],
    "abstract": "Assembly code search is vital for reducing the burden on reverse engineers,\nallowing them to quickly identify specific functions using natural language\nwithin vast binary programs. Despite its significance, this critical task is\nimpeded by the complexities involved in building high-quality datasets. This\npaper explores training a Large Language Model (LLM) to emulate a general\ncompiler. By leveraging Ubuntu packages to compile a dataset of 20 billion\ntokens, we further continue pre-train CodeLlama as a Virtual Compiler (ViC),\ncapable of compiling any source code of any language to assembly code. This\napproach allows for virtual compilation across a wide range of programming\nlanguages without the need for a real compiler, preserving semantic equivalency\nand expanding the possibilities for assembly code dataset construction.\nFurthermore, we use ViC to construct a sufficiently large dataset for assembly\ncode search. Employing this extensive dataset, we achieve a substantial\nimprovement in assembly code search performance, with our model surpassing the\nleading baseline by 26%.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06385v1",
    "published_date": "2024-08-10 17:23:02 UTC",
    "updated_date": "2024-08-10 17:23:02 UTC"
  },
  {
    "arxiv_id": "2408.05599v1",
    "title": "Sequential Representation Learning via Static-Dynamic Conditional Disentanglement",
    "authors": [
      "Mathieu Cyrille Simon",
      "Pascal Frossard",
      "Christophe De Vleeschouwer"
    ],
    "abstract": "This paper explores self-supervised disentangled representation learning\nwithin sequential data, focusing on separating time-independent and\ntime-varying factors in videos. We propose a new model that breaks the usual\nindependence assumption between those factors by explicitly accounting for the\ncausal relationship between the static/dynamic variables and that improves the\nmodel expressivity through additional Normalizing Flows. A formal definition of\nthe factors is proposed. This formalism leads to the derivation of sufficient\nconditions for the ground truth factors to be identifiable, and to the\nintroduction of a novel theoretically grounded disentanglement constraint that\ncan be directly and efficiently incorporated into our new framework. The\nexperiments show that the proposed approach outperforms previous complex\nstate-of-the-art techniques in scenarios where the dynamics of a scene are\ninfluenced by its content.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05599v1",
    "published_date": "2024-08-10 17:04:39 UTC",
    "updated_date": "2024-08-10 17:04:39 UTC"
  },
  {
    "arxiv_id": "2408.05575v1",
    "title": "In-Context Exploiter for Extensive-Form Games",
    "authors": [
      "Shuxin Li",
      "Chang Yang",
      "Youzhi Zhang",
      "Pengdeng Li",
      "Xinrun Wang",
      "Xiao Huang",
      "Hau Chan",
      "Bo An"
    ],
    "abstract": "Nash equilibrium (NE) is a widely adopted solution concept in game theory due\nto its stability property. However, we observe that the NE strategy might not\nalways yield the best results, especially against opponents who do not adhere\nto NE strategies. Based on this observation, we pose a new game-solving\nquestion: Can we learn a model that can exploit any, even NE, opponent to\nmaximize their own utility? In this work, we make the first attempt to\ninvestigate this problem through in-context learning. Specifically, we\nintroduce a novel method, In-Context Exploiter (ICE), to train a single model\nthat can act as any player in the game and adaptively exploit opponents\nentirely by in-context learning. Our ICE algorithm involves generating diverse\nopponent strategies, collecting interactive history training data by a\nreinforcement learning algorithm, and training a transformer-based agent within\na well-designed curriculum learning framework. Finally, comprehensive\nexperimental results validate the effectiveness of our ICE algorithm,\nshowcasing its in-context learning ability to exploit any unknown opponent,\nthereby positively answering our initial game-solving question.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05575v1",
    "published_date": "2024-08-10 14:59:09 UTC",
    "updated_date": "2024-08-10 14:59:09 UTC"
  },
  {
    "arxiv_id": "2408.05568v1",
    "title": "Metacognitive Myopia in Large Language Models",
    "authors": [
      "Florian Scholten",
      "Tobias R. Rebholz",
      "Mandy HÃ¼tter"
    ],
    "abstract": "Large Language Models (LLMs) exhibit potentially harmful biases that\nreinforce culturally inherent stereotypes, cloud moral judgments, or amplify\npositive evaluations of majority groups. Previous explanations mainly\nattributed bias in LLMs to human annotators and the selection of training data.\nConsequently, they have typically been addressed with bottom-up approaches such\nas reinforcement learning or debiasing corpora. However, these methods only\ntreat the effects of LLM biases by indirectly influencing the model\narchitecture, but do not address the underlying causes in the computational\nprocess. Here, we propose metacognitive myopia as a cognitive-ecological\nframework that can account for a conglomerate of established and emerging LLM\nbiases and provide a lever to address problems in powerful but vulnerable\ntools. Our theoretical framework posits that a lack of the two components of\nmetacognition, monitoring and control, causes five symptoms of metacognitive\nmyopia in LLMs: integration of invalid tokens and embeddings, susceptibility to\nredundant information, neglect of base rates in conditional computation,\ndecision rules based on frequency, and inappropriate higher-order statistical\ninference for nested data structures. As a result, LLMs produce erroneous\noutput that reaches into the daily high-stakes decisions of humans. By\nintroducing metacognitive regulatory processes into LLMs, engineers and\nscientists can develop precise remedies for the underlying causes of these\nbiases. Our theory sheds new light on flawed human-machine interactions and\nraises ethical concerns regarding the increasing, imprudent implementation of\nLLMs in organizational structures.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05568v1",
    "published_date": "2024-08-10 14:43:57 UTC",
    "updated_date": "2024-08-10 14:43:57 UTC"
  },
  {
    "arxiv_id": "2408.05566v1",
    "title": "Document-Level Event Extraction with Definition-Driven ICL",
    "authors": [
      "Zhuoyuan Liu",
      "Yilin Luo"
    ],
    "abstract": "In the field of Natural Language Processing (NLP), Large Language Models\n(LLMs) have shown great potential in document-level event extraction tasks, but\nexisting methods face challenges in the design of prompts. To address this\nissue, we propose an optimization strategy called \"Definition-driven\nDocument-level Event Extraction (DDEE).\" By adjusting the length of the prompt\nand enhancing the clarity of heuristics, we have significantly improved the\nevent extraction performance of LLMs. We used data balancing techniques to\nsolve the long-tail effect problem, enhancing the model's generalization\nability for event types. At the same time, we refined the prompt to ensure it\nis both concise and comprehensive, adapting to the sensitivity of LLMs to the\nstyle of prompts. In addition, the introduction of structured heuristic methods\nand strict limiting conditions has improved the precision of event and argument\nrole extraction. These strategies not only solve the prompt engineering\nproblems of LLMs in document-level event extraction but also promote the\ndevelopment of event extraction technology, providing new research perspectives\nfor other tasks in the NLP field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05566v1",
    "published_date": "2024-08-10 14:24:09 UTC",
    "updated_date": "2024-08-10 14:24:09 UTC"
  },
  {
    "arxiv_id": "2408.10252v1",
    "title": "Balancing Innovation and Ethics in AI-Driven Software Development",
    "authors": [
      "Mohammad Baqar"
    ],
    "abstract": "This paper critically examines the ethical implications of integrating AI\ntools like GitHub Copilot and ChatGPT into the software development process. It\nexplores issues such as code ownership, bias, accountability, privacy, and the\npotential impact on the job market. While these AI tools offer significant\nbenefits in terms of productivity and efficiency, they also introduce complex\nethical challenges. The paper argues that addressing these challenges is\nessential to ensuring that AI's integration into software development is both\nresponsible and beneficial to society",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "20 Pages",
    "pdf_url": "http://arxiv.org/pdf/2408.10252v1",
    "published_date": "2024-08-10 14:11:22 UTC",
    "updated_date": "2024-08-10 14:11:22 UTC"
  },
  {
    "arxiv_id": "2408.05563v1",
    "title": "Impacts of Darwinian Evolution on Pre-trained Deep Neural Networks",
    "authors": [
      "Guodong Du",
      "Runhua Jiang",
      "Senqiao Yang",
      "Haoyang Li",
      "Wei Chen",
      "Keren Li",
      "Sim Kuan Goh",
      "Ho-Kin Tang"
    ],
    "abstract": "Darwinian evolution of the biological brain is documented through multiple\nlines of evidence, although the modes of evolutionary changes remain unclear.\nDrawing inspiration from the evolved neural systems (e.g., visual cortex), deep\nlearning models have demonstrated superior performance in visual tasks, among\nothers. While the success of training deep neural networks has been relying on\nback-propagation (BP) and its variants to learn representations from data, BP\ndoes not incorporate the evolutionary processes that govern biological neural\nsystems. This work proposes a neural network optimization framework based on\nevolutionary theory. Specifically, BP-trained deep neural networks for visual\nrecognition tasks obtained from the ending epochs are considered the primordial\nancestors (initial population). Subsequently, the population evolved with\ndifferential evolution. Extensive experiments are carried out to examine the\nrelationships between Darwinian evolution and neural network optimization,\nincluding the correspondence between datasets, environment, models, and living\nspecies. The empirical results show that the proposed framework has positive\nimpacts on the network, with reduced over-fitting and an order of magnitude\nlower time complexity compared to BP. Moreover, the experiments show that the\nproposed framework performs well on deep neural networks and big datasets.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2408.05563v1",
    "published_date": "2024-08-10 14:08:33 UTC",
    "updated_date": "2024-08-10 14:08:33 UTC"
  },
  {
    "arxiv_id": "2408.05556v1",
    "title": "Evolutionary Neural Architecture Search for 3D Point Cloud Analysis",
    "authors": [
      "Yisheng Yang",
      "Guodong Du",
      "Chean Khim Toa",
      "Ho-Kin Tang",
      "Sim Kuan Goh"
    ],
    "abstract": "Neural architecture search (NAS) automates neural network design by using\noptimization algorithms to navigate architecture spaces, reducing the burden of\nmanual architecture design. While NAS has achieved success, applying it to\nemerging domains, such as analyzing unstructured 3D point clouds, remains\nunderexplored due to the data lying in non-Euclidean spaces, unlike images.\nThis paper presents Success-History-based Self-adaptive Differential Evolution\nwith a Joint Point Interaction Dimension Search (SHSADE-PIDS), an evolutionary\nNAS framework that encodes discrete deep neural network architectures to\ncontinuous spaces and performs searches in the continuous spaces for efficient\npoint cloud neural architectures. Comprehensive experiments on challenging 3D\nsegmentation and classification benchmarks demonstrate SHSADE-PIDS's\ncapabilities. It discovered highly efficient architectures with higher\naccuracy, significantly advancing prior NAS techniques. For segmentation on\nSemanticKITTI, SHSADE-PIDS attained 64.51% mean IoU using only 0.55M parameters\nand 4.5GMACs, reducing overhead by over 22-26X versus other top methods. For\nModelNet40 classification, it achieved 93.4% accuracy with just 1.31M\nparameters, surpassing larger models. SHSADE-PIDS provided valuable insights\ninto bridging evolutionary algorithms with neural architecture optimization,\nparticularly for emerging frontiers like point cloud learning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2408.05556v1",
    "published_date": "2024-08-10 13:41:18 UTC",
    "updated_date": "2024-08-10 13:41:18 UTC"
  },
  {
    "arxiv_id": "2408.05545v2",
    "title": "Multi-layer Sequence Labeling-based Joint Biomedical Event Extraction",
    "authors": [
      "Gongchi Chen",
      "Pengchao Wu",
      "Jinghang Gu",
      "Longhua Qian",
      "Guodong Zhou"
    ],
    "abstract": "In recent years, biomedical event extraction has been dominated by\ncomplicated pipeline and joint methods, which need to be simplified. In\naddition, existing work has not effectively utilized trigger word information\nexplicitly. Hence, we propose MLSL, a method based on multi-layer sequence\nlabeling for joint biomedical event extraction. MLSL does not introduce prior\nknowledge and complex structures. Moreover, it explicitly incorporates the\ninformation of candidate trigger words into the sequence labeling to learn the\ninteraction relationships between trigger words and argument roles. Based on\nthis, MLSL can learn well with just a simple workflow. Extensive\nexperimentation demonstrates the superiority of MLSL in terms of extraction\nperformance compared to other state-of-the-art methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 3 figures, accepted by NLPCC2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05545v2",
    "published_date": "2024-08-10 13:03:19 UTC",
    "updated_date": "2024-08-14 05:43:22 UTC"
  },
  {
    "arxiv_id": "2408.05526v2",
    "title": "CryoBench: Diverse and challenging datasets for the heterogeneity problem in cryo-EM",
    "authors": [
      "Minkyu Jeon",
      "Rishwanth Raghu",
      "Miro Astore",
      "Geoffrey Woollard",
      "Ryan Feathers",
      "Alkin Kaz",
      "Sonya M. Hanson",
      "Pilar Cossio",
      "Ellen D. Zhong"
    ],
    "abstract": "Cryo-electron microscopy (cryo-EM) is a powerful technique for determining\nhigh-resolution 3D biomolecular structures from imaging data. Its unique\nability to capture structural variability has spurred the development of\nheterogeneous reconstruction algorithms that can infer distributions of 3D\nstructures from noisy, unlabeled imaging data. Despite the growing number of\nadvanced methods, progress in the field is hindered by the lack of standardized\nbenchmarks with ground truth information and reliable validation metrics. Here,\nwe introduce CryoBench, a suite of datasets, metrics, and benchmarks for\nheterogeneous reconstruction in cryo-EM. CryoBench includes five datasets\nrepresenting different sources of heterogeneity and degrees of difficulty.\nThese include conformational heterogeneity generated from designed motions of\nantibody complexes or sampled from a molecular dynamics simulation, as well as\ncompositional heterogeneity from mixtures of ribosome assembly states or 100\ncommon complexes present in cells. We then analyze state-of-the-art\nheterogeneous reconstruction tools, including neural and non-neural methods,\nassess their sensitivity to noise, and propose new metrics for quantitative\nevaluation. We hope that CryoBench will be a foundational resource for\naccelerating algorithmic development and evaluation in the cryo-EM and machine\nlearning communities. Project page: https://cryobench.cs.princeton.edu.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2408.05526v2",
    "published_date": "2024-08-10 11:48:14 UTC",
    "updated_date": "2025-01-16 00:54:04 UTC"
  },
  {
    "arxiv_id": "2408.05503v1",
    "title": "Disentangled Noisy Correspondence Learning",
    "authors": [
      "Zhuohang Dang",
      "Minnan Luo",
      "Jihong Wang",
      "Chengyou Jia",
      "Haochen Han",
      "Herun Wan",
      "Guang Dai",
      "Xiaojun Chang",
      "Jingdong Wang"
    ],
    "abstract": "Cross-modal retrieval is crucial in understanding latent correspondences\nacross modalities. However, existing methods implicitly assume well-matched\ntraining data, which is impractical as real-world data inevitably involves\nimperfect alignments, i.e., noisy correspondences. Although some works explore\nsimilarity-based strategies to address such noise, they suffer from sub-optimal\nsimilarity predictions influenced by modality-exclusive information (MEI),\ne.g., background noise in images and abstract definitions in texts. This issue\narises as MEI is not shared across modalities, thus aligning it in training can\nmarkedly mislead similarity predictions. Moreover, although intuitive, directly\napplying previous cross-modal disentanglement methods suffers from limited\nnoise tolerance and disentanglement efficacy. Inspired by the robustness of\ninformation bottlenecks against noise, we introduce DisNCL, a novel\ninformation-theoretic framework for feature Disentanglement in Noisy\nCorrespondence Learning, to adaptively balance the extraction of MII and MEI\nwith certifiable optimal cross-modal disentanglement efficacy. DisNCL then\nenhances similarity predictions in modality-invariant subspace, thereby greatly\nboosting similarity-based alleviation strategy for noisy correspondences.\nFurthermore, DisNCL introduces soft matching targets to model noisy\nmany-to-many relationships inherent in multi-modal input for noise-robust and\naccurate cross-modal alignment. Extensive experiments confirm DisNCL's efficacy\nby 2% average recall improvement. Mutual information estimation and\nvisualization results show that DisNCL learns meaningful MII/MEI subspaces,\nvalidating our theoretical analyses.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05503v1",
    "published_date": "2024-08-10 09:49:55 UTC",
    "updated_date": "2024-08-10 09:49:55 UTC"
  },
  {
    "arxiv_id": "2408.05500v2",
    "title": "PointNCBW: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark",
    "authors": [
      "Cheng Wei",
      "Yang Wang",
      "Kuofeng Gao",
      "Shuo Shao",
      "Yiming Li",
      "Zhibo Wang",
      "Zhan Qin"
    ],
    "abstract": "Recently, point clouds have been widely used in computer vision, whereas\ntheir collection is time-consuming and expensive. As such, point cloud datasets\nare the valuable intellectual property of their owners and deserve protection.\nTo detect and prevent unauthorized use of these datasets, especially for\ncommercial or open-sourced ones that cannot be sold again or used commercially\nwithout permission, we intend to identify whether a suspicious third-party\nmodel is trained on our protected dataset under the black-box setting. We\nachieve this goal by designing a scalable clean-label backdoor-based dataset\nwatermark for point clouds that ensures both effectiveness and stealthiness.\nUnlike existing clean-label watermark schemes, which are susceptible to the\nnumber of categories, our method could watermark samples from all classes\ninstead of only from the target one. Accordingly, it can still preserve high\neffectiveness even on large-scale datasets with many classes. Specifically, we\nperturb selected point clouds with non-target categories in both shape-wise and\npoint-wise manners before inserting trigger patterns without changing their\nlabels. The features of perturbed samples are similar to those of benign\nsamples from the target class. As such, models trained on the watermarked\ndataset will have a distinctive yet stealthy backdoor behavior, i.e.,\nmisclassifying samples from the target class whenever triggers appear, since\nthe trained DNNs will treat the inserted trigger pattern as a signal to deny\npredicting the target label. We also design a hypothesis-test-guided dataset\nownership verification based on the proposed watermark. Extensive experiments\non benchmark datasets are conducted, verifying the effectiveness of our method\nand its resistance to potential removal methods.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper was accepted by IEEE Transactions on Information Forensics\n  and Security (TIFS), 2024. 16 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.05500v2",
    "published_date": "2024-08-10 09:31:58 UTC",
    "updated_date": "2024-11-04 14:30:03 UTC"
  },
  {
    "arxiv_id": "2408.05499v1",
    "title": "LLMServingSim: A HW/SW Co-Simulation Infrastructure for LLM Inference Serving at Scale",
    "authors": [
      "Jaehong Cho",
      "Minsu Kim",
      "Hyunmin Choi",
      "Guseul Heo",
      "Jongse Park"
    ],
    "abstract": "Recently, there has been an extensive research effort in building efficient\nlarge language model (LLM) inference serving systems. These efforts not only\ninclude innovations in the algorithm and software domains but also constitute\ndevelopments of various hardware acceleration techniques. Nevertheless, there\nis a lack of simulation infrastructure capable of accurately modeling versatile\nhardware-software behaviors in LLM serving systems without extensively\nextending the simulation time. This paper aims to develop an effective\nsimulation tool, called LLMServingSim, to support future research in LLM\nserving systems. In designing LLMServingSim, we focus on two limitations of\nexisting simulators: (1) they lack consideration of the dynamic workload\nvariations of LLM inference serving due to its autoregressive nature, and (2)\nthey incur repetitive simulations without leveraging algorithmic redundancies\nin LLMs. To address these limitations, LLMServingSim simulates the LLM serving\nin the granularity of iterations, leveraging the computation redundancies\nacross decoder blocks and reusing the simulation results from previous\niterations. Additionally, LLMServingSim provides a flexible framework that\nallows users to plug in any accelerator compiler-and-simulation stacks for\nexploring various system designs with heterogeneous processors. Our experiments\ndemonstrate that LLMServingSim produces simulation results closely following\nthe performance behaviors of real GPU-based LLM serving system with less than\n14.7% error rate, while offering 91.5x faster simulation speed compared to\nexisting accelerator simulators.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "15 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05499v1",
    "published_date": "2024-08-10 09:26:15 UTC",
    "updated_date": "2024-08-10 09:26:15 UTC"
  },
  {
    "arxiv_id": "2408.05488v1",
    "title": "Structure and Reduction of MCTS for Explainable-AI",
    "authors": [
      "Ronit Bustin",
      "Claudia V. Goldman"
    ],
    "abstract": "Complex sequential decision-making planning problems, covering infinite\nstates' space have been shown to be solvable by AlphaZero type of algorithms.\nSuch an approach that trains a neural model while simulating projection of\nfutures with a Monte Carlo Tree Search algorithm were shown to be applicable to\nreal life planning problems. As such, engineers and users interacting with the\nresulting policy of behavior might benefit from obtaining automated\nexplanations about these planners' decisions offline or online. This paper\nfocuses on the information within the Monte Carlo Tree Search data structure.\nGiven its construction, this information contains much of the reasoning of the\nsequential decision-making algorithm and is essential for its explainability.\nWe show novel methods using information theoretic tools for the simplification\nand reduction of the Monte Carlo Tree Search and the extraction of information.\nSuch information can be directly used for the construction of human\nunderstandable explanations. We show that basic explainability quantities can\nbe calculated with limited additional computational cost, as an integrated part\nof the Monte Carlo Tree Search construction process. We focus on the\ntheoretical and algorithmic aspects and provide examples of how the methods\npresented here can be used in the construction of human understandable\nexplanations.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05488v1",
    "published_date": "2024-08-10 08:33:30 UTC",
    "updated_date": "2024-08-10 08:33:30 UTC"
  },
  {
    "arxiv_id": "2408.05478v2",
    "title": "Multi-Agent Planning Using Visual Language Models",
    "authors": [
      "Michele Brienza",
      "Francesco Argenziano",
      "Vincenzo Suriani",
      "Domenico D. Bloisi",
      "Daniele Nardi"
    ],
    "abstract": "Large Language Models (LLMs) and Visual Language Models (VLMs) are attracting\nincreasing interest due to their improving performance and applications across\nvarious domains and tasks. However, LLMs and VLMs can produce erroneous\nresults, especially when a deep understanding of the problem domain is\nrequired. For instance, when planning and perception are needed simultaneously,\nthese models often struggle because of difficulties in merging multi-modal\ninformation. To address this issue, fine-tuned models are typically employed\nand trained on specialized data structures representing the environment. This\napproach has limited effectiveness, as it can overly complicate the context for\nprocessing. In this paper, we propose a multi-agent architecture for embodied\ntask planning that operates without the need for specific data structures as\ninput. Instead, it uses a single image of the environment, handling free-form\ndomains by leveraging commonsense knowledge. We also introduce a novel, fully\nautomatic evaluation procedure, PG2S, designed to better assess the quality of\na plan. We validated our approach using the widely recognized ALFRED dataset,\ncomparing PG2S to the existing KAS metric to further evaluate the quality of\nthe generated plans.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05478v2",
    "published_date": "2024-08-10 08:10:17 UTC",
    "updated_date": "2024-12-29 12:15:40 UTC"
  },
  {
    "arxiv_id": "2408.05476v2",
    "title": "Artworks Reimagined: Exploring Human-AI Co-Creation through Body Prompting",
    "authors": [
      "Jonas Oppenlaender",
      "Hannah Johnston",
      "Johanna Silvennoinen",
      "Helena Barranha"
    ],
    "abstract": "Image generation using generative artificial intelligence has become a\npopular activity. However, text-to-image generation - where images are produced\nfrom typed prompts - can be less engaging in public settings since the act of\ntyping tends to limit interactive audience participation, thereby reducing its\nsuitability for designing dynamic public installations. In this article, we\nexplore body prompting as input modality for image generation in the context of\ninstallations at public event settings. Body prompting extends interaction with\ngenerative AI beyond textual inputs to reconnect the creative act of image\ngeneration with the physical act of creating artworks. We implement this\nconcept in an interactive art installation, Artworks Reimagined, designed to\ntransform existing artworks via body prompting. We deployed the installation at\nan event with hundreds of visitors in a public and private setting. Our\nsemi-structured interviews with a sample of visitors (N = 79) show that body\nprompting was well-received and provides an engaging and fun experience to the\ninstallation's visitors. We present insights into participants' experience of\nbody prompting and AI co-creation and identify three distinct strategies of\nembodied interaction focused on re-creating, reimagining, or casual\ninteraction. We provide valuable recommendations for practitioners seeking to\ndesign interactive generative AI experiences in museums, galleries, and public\nevent spaces.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "H.5.m"
    ],
    "primary_category": "cs.HC",
    "comment": "29 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05476v2",
    "published_date": "2024-08-10 08:05:59 UTC",
    "updated_date": "2025-02-16 09:20:54 UTC"
  },
  {
    "arxiv_id": "2408.05457v1",
    "title": "Investigating Instruction Tuning Large Language Models on Graphs",
    "authors": [
      "Kerui Zhu",
      "Bo-Wei Huang",
      "Bowen Jin",
      "Yizhu Jiao",
      "Ming Zhong",
      "Kevin Chang",
      "Shou-De Lin",
      "Jiawei Han"
    ],
    "abstract": "Inspired by the recent advancements of Large Language Models (LLMs) in NLP\ntasks, there's growing interest in applying LLMs to graph-related tasks. This\nstudy delves into the capabilities of instruction-following LLMs for engaging\nwith real-world graphs, aiming to offer empirical insights into how LLMs can\neffectively interact with graphs and generalize across graph tasks. We begin by\nconstructing a dataset designed for instruction tuning, which comprises a\ndiverse collection of 79 graph-related tasks from academic and e-commerce\ndomains, featuring 44,240 training instances and 18,960 test samples. Utilizing\nthis benchmark, our initial investigation focuses on identifying the optimal\ngraph representation that serves as a conduit for LLMs to understand complex\ngraph structures. Our findings indicate that JSON format for graph\nrepresentation consistently outperforms natural language and code formats\nacross various LLMs and graph types. Furthermore, we examine the key factors\nthat influence the generalization abilities of instruction-tuned LLMs by\nevaluating their performance on both in-domain and out-of-domain graph tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05457v1",
    "published_date": "2024-08-10 06:54:35 UTC",
    "updated_date": "2024-08-10 06:54:35 UTC"
  },
  {
    "arxiv_id": "2408.05451v1",
    "title": "Mathematical Models of Computation in Superposition",
    "authors": [
      "Kaarel HÃ¤nni",
      "Jake Mendel",
      "Dmitry Vaintrob",
      "Lawrence Chan"
    ],
    "abstract": "Superposition -- when a neural network represents more ``features'' than it\nhas dimensions -- seems to pose a serious challenge to mechanistically\ninterpreting current AI systems. Existing theory work studies\n\\emph{representational} superposition, where superposition is only used when\npassing information through bottlenecks. In this work, we present mathematical\nmodels of \\emph{computation} in superposition, where superposition is actively\nhelpful for efficiently accomplishing the task.\n  We first construct a task of efficiently emulating a circuit that takes the\nAND of the $\\binom{m}{2}$ pairs of each of $m$ features. We construct a 1-layer\nMLP that uses superposition to perform this task up to $\\varepsilon$-error,\nwhere the network only requires $\\tilde{O}(m^{\\frac{2}{3}})$ neurons, even when\nthe input features are \\emph{themselves in superposition}. We generalize this\nconstruction to arbitrary sparse boolean circuits of low depth, and then\nconstruct ``error correction'' layers that allow deep fully-connected networks\nof width $d$ to emulate circuits of width $\\tilde{O}(d^{1.5})$ and \\emph{any}\npolynomial depth. We conclude by providing some potential applications of our\nwork for interpreting neural networks that implement computation in\nsuperposition.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 5 figures. Published at the ICML 2024 Mechanistic\n  Interpretability (MI) Workshop",
    "pdf_url": "http://arxiv.org/pdf/2408.05451v1",
    "published_date": "2024-08-10 06:11:48 UTC",
    "updated_date": "2024-08-10 06:11:48 UTC"
  },
  {
    "arxiv_id": "2408.05212v2",
    "title": "Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions",
    "authors": [
      "Michele Miranda",
      "Elena Sofia Ruzzetti",
      "Andrea Santilli",
      "Fabio Massimo Zanzotto",
      "SÃ©bastien BratiÃ¨res",
      "Emanuele RodolÃ "
    ],
    "abstract": "Large Language Models (LLMs) represent a significant advancement in\nartificial intelligence, finding applications across various domains. However,\ntheir reliance on massive internet-sourced datasets for training brings notable\nprivacy issues, which are exacerbated in critical domains (e.g., healthcare).\nMoreover, certain application-specific scenarios may require fine-tuning these\nmodels on private data. This survey critically examines the privacy threats\nassociated with LLMs, emphasizing the potential for these models to memorize\nand inadvertently reveal sensitive information. We explore current threats by\nreviewing privacy attacks on LLMs and propose comprehensive solutions for\nintegrating privacy mechanisms throughout the entire learning pipeline. These\nsolutions range from anonymizing training datasets to implementing differential\nprivacy during training or inference and machine unlearning after training. Our\ncomprehensive review of existing literature highlights ongoing challenges,\navailable tools, and future directions for preserving privacy in LLMs. This\nwork aims to guide the development of more secure and trustworthy AI systems by\nproviding a thorough understanding of privacy preservation methods and their\neffectiveness in mitigating risks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Published in Transactions on Machine Learning Research (TMLR)\n  https://openreview.net/forum?id=Ss9MTTN7OL",
    "pdf_url": "http://arxiv.org/pdf/2408.05212v2",
    "published_date": "2024-08-10 05:41:19 UTC",
    "updated_date": "2025-02-10 15:42:08 UTC"
  },
  {
    "arxiv_id": "2408.15258v1",
    "title": "Transformer-based Neuro-Animator for Qualitative Simulation of Soft Body Movement",
    "authors": [
      "Somnuk Phon-Amnuaisuk"
    ],
    "abstract": "The human mind effortlessly simulates the movements of objects governed by\nthe laws of physics, such as a fluttering, or a waving flag under wind force,\nwithout understanding the underlying physics. This suggests that human\ncognition can predict the unfolding of physical events using an intuitive\nprediction process. This process might result from memory recall, yielding a\nqualitatively believable mental image, though it may not be exactly according\nto real-world physics. Drawing inspiration from the intriguing human ability to\nqualitatively visualize and describe dynamic events from past experiences\nwithout explicitly engaging in mathematical computations, this paper\ninvestigates the application of recent transformer architectures as a\nneuro-animator model. The visual transformer model is trained to predict flag\nmotions at the \\emph{t+1} time step, given information of previous motions from\n\\emph{t-n} $\\cdots$ \\emph{t} time steps. The results show that the visual\ntransformer-based architecture successfully learns temporal embedding of flag\nmotions and produces reasonable quality simulations of flag waving under\ndifferent wind forces.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.15258v1",
    "published_date": "2024-08-10 04:05:24 UTC",
    "updated_date": "2024-08-10 04:05:24 UTC"
  },
  {
    "arxiv_id": "2408.05421v2",
    "title": "EPAM-Net: An Efficient Pose-driven Attention-guided Multimodal Network for Video Action Recognition",
    "authors": [
      "Ahmed Abdelkawy",
      "Asem Ali",
      "Aly Farag"
    ],
    "abstract": "Existing multimodal-based human action recognition approaches are\ncomputationally intensive, limiting their deployment in real-time applications.\nIn this work, we present a novel and efficient pose-driven attention-guided\nmultimodal network (EPAM-Net) for action recognition in videos. Specifically,\nwe propose eXpand temporal Shift (X-ShiftNet) convolutional architectures for\nRGB and pose streams to capture spatio-temporal features from RGB videos and\ntheir skeleton sequences. The X-ShiftNet tackles the high computational cost of\nthe 3D CNNs by integrating the Temporal Shift Module (TSM) into an efficient 2D\nCNN, enabling efficient spatiotemporal learning. Then skeleton features are\nutilized to guide the visual network stream, focusing on keyframes and their\nsalient spatial regions using the proposed spatial-temporal attention block.\nFinally, the predictions of the two streams are fused for final classification.\nThe experimental results show that our method, with a significant reduction in\nfloating-point operations (FLOPs), outperforms and competes with the\nstate-of-the-art methods on NTU RGB-D 60, NTU RGB-D 120, PKU-MMD, and Toyota\nSmartHome datasets. The proposed EPAM-Net provides up to a 72.8x reduction in\nFLOPs and up to a 48.6x reduction in the number of network parameters. The code\nwill be available at\nhttps://github.com/ahmed-nady/Multimodal-Action-Recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05421v2",
    "published_date": "2024-08-10 03:15:24 UTC",
    "updated_date": "2025-03-20 15:21:00 UTC"
  },
  {
    "arxiv_id": "2408.05416v1",
    "title": "High-fidelity and Lip-synced Talking Face Synthesis via Landmark-based Diffusion Model",
    "authors": [
      "Weizhi Zhong",
      "Junfan Lin",
      "Peixin Chen",
      "Liang Lin",
      "Guanbin Li"
    ],
    "abstract": "Audio-driven talking face video generation has attracted increasing attention\ndue to its huge industrial potential. Some previous methods focus on learning a\ndirect mapping from audio to visual content. Despite progress, they often\nstruggle with the ambiguity of the mapping process, leading to flawed results.\nAn alternative strategy involves facial structural representations (e.g.,\nfacial landmarks) as intermediaries. This multi-stage approach better preserves\nthe appearance details but suffers from error accumulation due to the\nindependent optimization of different stages. Moreover, most previous methods\nrely on generative adversarial networks, prone to training instability and mode\ncollapse. To address these challenges, our study proposes a novel\nlandmark-based diffusion model for talking face generation, which leverages\nfacial landmarks as intermediate representations while enabling end-to-end\noptimization. Specifically, we first establish the less ambiguous mapping from\naudio to landmark motion of lip and jaw. Then, we introduce an innovative\nconditioning module called TalkFormer to align the synthesized motion with the\nmotion represented by landmarks via differentiable cross-attention, which\nenables end-to-end optimization for improved lip synchronization. Besides,\nTalkFormer employs implicit feature warping to align the reference image\nfeatures with the target motion for preserving more appearance details.\nExtensive experiments demonstrate that our approach can synthesize\nhigh-fidelity and lip-synced talking face videos, preserving more subject\nappearance details from the reference image.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "submitted to IEEE Transactions on Image Processing(TIP)",
    "pdf_url": "http://arxiv.org/pdf/2408.05416v1",
    "published_date": "2024-08-10 02:58:28 UTC",
    "updated_date": "2024-08-10 02:58:28 UTC"
  },
  {
    "arxiv_id": "2408.05412v1",
    "title": "Style-Preserving Lip Sync via Audio-Aware Style Reference",
    "authors": [
      "Weizhi Zhong",
      "Jichang Li",
      "Yinqi Cai",
      "Liang Lin",
      "Guanbin Li"
    ],
    "abstract": "Audio-driven lip sync has recently drawn significant attention due to its\nwidespread application in the multimedia domain. Individuals exhibit distinct\nlip shapes when speaking the same utterance, attributed to the unique speaking\nstyles of individuals, posing a notable challenge for audio-driven lip sync.\nEarlier methods for such task often bypassed the modeling of personalized\nspeaking styles, resulting in sub-optimal lip sync conforming to the general\nstyles. Recent lip sync techniques attempt to guide the lip sync for arbitrary\naudio by aggregating information from a style reference video, yet they can not\npreserve the speaking styles well due to their inaccuracy in style aggregation.\nThis work proposes an innovative audio-aware style reference scheme that\neffectively leverages the relationships between input audio and reference audio\nfrom style reference video to address the style-preserving audio-driven lip\nsync. Specifically, we first develop an advanced Transformer-based model adept\nat predicting lip motion corresponding to the input audio, augmented by the\nstyle information aggregated through cross-attention layers from style\nreference video. Afterwards, to better render the lip motion into realistic\ntalking face video, we devise a conditional latent diffusion model, integrating\nlip motion through modulated convolutional layers and fusing reference facial\nimages via spatial cross-attention layers. Extensive experiments validate the\nefficacy of the proposed approach in achieving precise lip sync, preserving\nspeaking styles, and generating high-fidelity, realistic talking face videos.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "submitted to IEEE Transactions on Image Processing(TIP)",
    "pdf_url": "http://arxiv.org/pdf/2408.05412v1",
    "published_date": "2024-08-10 02:46:11 UTC",
    "updated_date": "2024-08-10 02:46:11 UTC"
  }
]