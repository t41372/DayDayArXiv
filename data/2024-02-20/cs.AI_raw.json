[
  {
    "arxiv_id": "2403.18946v1",
    "title": "Random Aggregate Beamforming for Over-the-Air Federated Learning in Large-Scale Networks",
    "authors": [
      "Chunmei Xu",
      "Shengheng Liu",
      "Yongming Huang",
      "Bjorn Ottersten",
      "Dusit Niyato"
    ],
    "abstract": "At present, there is a trend to deploy ubiquitous artificial intelligence\n(AI) applications at the edge of the network. As a promising framework that\nenables secure edge intelligence, federated learning (FL) has received\nwidespread attention, and over-the-air computing (AirComp) has been integrated\nto further improve the communication efficiency. In this paper, we consider a\njoint device selection and aggregate beamforming design with the objectives of\nminimizing the aggregate error and maximizing the number of selected devices.\nThis yields a combinatorial problem, which is difficult to solve especially in\nlarge-scale networks. To tackle the problems in a cost-effective manner, we\npropose a random aggregate beamforming-based scheme, which generates the\naggregator beamforming vector via random sampling rather than optimization. The\nimplementation of the proposed scheme does not require the channel estimation.\nWe additionally use asymptotic analysis to study the obtained aggregate error\nand the number of the selected devices when the number of devices becomes\nlarge. Furthermore, a refined method that runs with multiple randomizations is\nalso proposed for performance improvement. Extensive simulation results are\npresented to demonstrate the effectiveness of the proposed random aggregate\nbeamforming-based scheme as well as the refined method.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "30 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.18946v1",
    "published_date": "2024-02-20 23:59:45 UTC",
    "updated_date": "2024-02-20 23:59:45 UTC"
  },
  {
    "arxiv_id": "2402.13432v1",
    "title": "DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain",
    "authors": [
      "Yanis Labrak",
      "Adrien Bazoge",
      "Oumaima El Khettari",
      "Mickael Rouvier",
      "Pacome Constant dit Beaufils",
      "Natalia Grabar",
      "Beatrice Daille",
      "Solen Quiniou",
      "Emmanuel Morin",
      "Pierre-Antoine Gourraud",
      "Richard Dufour"
    ],
    "abstract": "The biomedical domain has sparked a significant interest in the field of\nNatural Language Processing (NLP), which has seen substantial advancements with\npre-trained language models (PLMs). However, comparing these models has proven\nchallenging due to variations in evaluation protocols across different models.\nA fair solution is to aggregate diverse downstream tasks into a benchmark,\nallowing for the assessment of intrinsic PLMs qualities from various\nperspectives. Although still limited to few languages, this initiative has been\nundertaken in the biomedical field, notably English and Chinese. This\nlimitation hampers the evaluation of the latest French biomedical models, as\nthey are either assessed on a minimal number of tasks with non-standardized\nprotocols or evaluated using general downstream tasks. To bridge this research\ngap and account for the unique sensitivities of French, we present the\nfirst-ever publicly available French biomedical language understanding\nbenchmark called DrBenchmark. It encompasses 20 diversified tasks, including\nnamed-entity recognition, part-of-speech tagging, question-answering, semantic\ntextual similarity, and classification. We evaluate 8 state-of-the-art\npre-trained masked language models (MLMs) on general and biomedical-specific\ndata, as well as English specific MLMs to assess their cross-lingual\ncapabilities. Our experiments reveal that no single model excels across all\ntasks, while generalist models are sometimes still competitive.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-Coling 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13432v1",
    "published_date": "2024-02-20 23:54:02 UTC",
    "updated_date": "2024-02-20 23:54:02 UTC"
  },
  {
    "arxiv_id": "2402.13430v1",
    "title": "LinkSAGE: Optimizing Job Matching Using Graph Neural Networks",
    "authors": [
      "Ping Liu",
      "Haichao Wei",
      "Xiaochen Hou",
      "Jianqiang Shen",
      "Shihai He",
      "Kay Qianqi Shen",
      "Zhujun Chen",
      "Fedor Borisyuk",
      "Daniel Hewlett",
      "Liang Wu",
      "Srikant Veeraraghavan",
      "Alex Tsun",
      "Chengming Jiang",
      "Wenjing Zhang"
    ],
    "abstract": "We present LinkSAGE, an innovative framework that integrates Graph Neural\nNetworks (GNNs) into large-scale personalized job matching systems, designed to\naddress the complex dynamics of LinkedIns extensive professional network. Our\napproach capitalizes on a novel job marketplace graph, the largest and most\nintricate of its kind in industry, with billions of nodes and edges. This graph\nis not merely extensive but also richly detailed, encompassing member and job\nnodes along with key attributes, thus creating an expansive and interwoven\nnetwork. A key innovation in LinkSAGE is its training and serving methodology,\nwhich effectively combines inductive graph learning on a heterogeneous,\nevolving graph with an encoder-decoder GNN model. This methodology decouples\nthe training of the GNN model from that of existing Deep Neural Nets (DNN)\nmodels, eliminating the need for frequent GNN retraining while maintaining\nup-to-date graph signals in near realtime, allowing for the effective\nintegration of GNN insights through transfer learning. The subsequent nearline\ninference system serves the GNN encoder within a real-world setting,\nsignificantly reducing online latency and obviating the need for costly\nreal-time GNN infrastructure. Validated across multiple online A/B tests in\ndiverse product scenarios, LinkSAGE demonstrates marked improvements in member\nengagement, relevance matching, and member retention, confirming its\ngeneralizability and practical impact.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13430v1",
    "published_date": "2024-02-20 23:49:25 UTC",
    "updated_date": "2024-02-20 23:49:25 UTC"
  },
  {
    "arxiv_id": "2402.13427v1",
    "title": "Quantitative causality, causality-guided scientific discovery, and causal machine learning",
    "authors": [
      "X. San Liang",
      "Dake Chen",
      "Renhe Zhang"
    ],
    "abstract": "It has been said, arguably, that causality analysis should pave a promising\nway to interpretable deep learning and generalization. Incorporation of\ncausality into artificial intelligence (AI) algorithms, however, is challenged\nwith its vagueness, non-quantitiveness, computational inefficiency, etc. During\nthe past 18 years, these challenges have been essentially resolved, with the\nestablishment of a rigorous formalism of causality analysis initially motivated\nfrom atmospheric predictability. This not only opens a new field in the\natmosphere-ocean science, namely, information flow, but also has led to\nscientific discoveries in other disciplines, such as quantum mechanics,\nneuroscience, financial economics, etc., through various applications. This\nnote provides a brief review of the decade-long effort, including a list of\nmajor theoretical results, a sketch of the causal deep learning framework, and\nsome representative real-world applications in geoscience pertaining to this\njournal, such as those on the anthropogenic cause of global warming, the\ndecadal prediction of El Ni\\~no Modoki, the forecasting of an extreme drought\nin China, among others.",
    "categories": [
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 3 figures. To appear in Ocean-Land-Atmosphere Research.\n  arXiv admin note: substantial text overlap with arXiv:2112.14839",
    "pdf_url": "http://arxiv.org/pdf/2402.13427v1",
    "published_date": "2024-02-20 23:38:46 UTC",
    "updated_date": "2024-02-20 23:38:46 UTC"
  },
  {
    "arxiv_id": "2402.13425v2",
    "title": "Investigating the Histogram Loss in Regression",
    "authors": [
      "Ehsan Imani",
      "Kai Luedemann",
      "Sam Scholnick-Hughes",
      "Esraa Elelimy",
      "Martha White"
    ],
    "abstract": "It is becoming increasingly common in regression to train neural networks\nthat model the entire distribution even if only the mean is required for\nprediction. This additional modeling often comes with performance gain and the\nreasons behind the improvement are not fully known. This paper investigates a\nrecent approach to regression, the Histogram Loss, which involves learning the\nconditional distribution of the target variable by minimizing the cross-entropy\nbetween a target distribution and a flexible histogram prediction. We design\ntheoretical and empirical analyses to determine why and when this performance\ngain appears, and how different components of the loss contribute to it. Our\nresults suggest that the benefits of learning distributions in this setup come\nfrom improvements in optimization rather than modelling extra information. We\nthen demonstrate the viability of the Histogram Loss in common deep learning\napplications without a need for costly hyperparameter tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "52 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.13425v2",
    "published_date": "2024-02-20 23:29:41 UTC",
    "updated_date": "2024-10-19 21:53:25 UTC"
  },
  {
    "arxiv_id": "2402.13419v1",
    "title": "Reward Bound for Behavioral Guarantee of Model-based Planning Agents",
    "authors": [
      "Zhiyu An",
      "Xianzhong Ding",
      "Wan Du"
    ],
    "abstract": "Recent years have seen an emerging interest in the trustworthiness of machine\nlearning-based agents in the wild, especially in robotics, to provide safety\nassurance for the industry. Obtaining behavioral guarantees for these agents\nremains an important problem. In this work, we focus on guaranteeing a\nmodel-based planning agent reaches a goal state within a specific future time\nstep. We show that there exists a lower bound for the reward at the goal state,\nsuch that if the said reward is below that bound, it is impossible to obtain\nsuch a guarantee. By extension, we show how to enforce preferences over\nmultiple goals.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in ICLR 24 tiny paper track",
    "pdf_url": "http://arxiv.org/pdf/2402.13419v1",
    "published_date": "2024-02-20 23:17:07 UTC",
    "updated_date": "2024-02-20 23:17:07 UTC"
  },
  {
    "arxiv_id": "2402.14859v2",
    "title": "The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative",
    "authors": [
      "Zhen Tan",
      "Chengshuai Zhao",
      "Raha Moraffah",
      "Yifan Li",
      "Yu Kong",
      "Tianlong Chen",
      "Huan Liu"
    ],
    "abstract": "Due to their unprecedented ability to process and respond to various types of\ndata, Multimodal Large Language Models (MLLMs) are constantly defining the new\nboundary of Artificial General Intelligence (AGI). As these advanced generative\nmodels increasingly form collaborative networks for complex tasks, the\nintegrity and security of these systems are crucial. Our paper, ``The Wolf\nWithin'', explores a novel vulnerability in MLLM societies - the indirect\npropagation of malicious content. Unlike direct harmful output generation for\nMLLMs, our research demonstrates how a single MLLM agent can be subtly\ninfluenced to generate prompts that, in turn, induce other MLLM agents in the\nsociety to output malicious content. Our findings reveal that, an MLLM agent,\nwhen manipulated to produce specific prompts or instructions, can effectively\n``infect'' other agents within a society of MLLMs. This infection leads to the\ngeneration and circulation of harmful outputs, such as dangerous instructions\nor misinformation, across the society. We also show the transferability of\nthese indirectly generated prompts, highlighting their possibility in\npropagating malice through inter-agent communication. This research provides a\ncritical insight into a new dimension of threat posed by MLLMs, where a single\nagent can act as a catalyst for widespread malevolent influence. Our work\nunderscores the urgent need for developing robust mechanisms to detect and\nmitigate such covert manipulations within MLLM societies, ensuring their safe\nand ethical utilization in societal applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to workshop on ReGenAI@CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14859v2",
    "published_date": "2024-02-20 23:08:21 UTC",
    "updated_date": "2024-06-03 03:29:07 UTC"
  },
  {
    "arxiv_id": "2402.13412v1",
    "title": "Scaling physics-informed hard constraints with mixture-of-experts",
    "authors": [
      "Nithin Chalapathi",
      "Yiheng Du",
      "Aditi Krishnapriyan"
    ],
    "abstract": "Imposing known physical constraints, such as conservation laws, during neural\nnetwork training introduces an inductive bias that can improve accuracy,\nreliability, convergence, and data efficiency for modeling physical dynamics.\nWhile such constraints can be softly imposed via loss function penalties,\nrecent advancements in differentiable physics and optimization improve\nperformance by incorporating PDE-constrained optimization as individual layers\nin neural networks. This enables a stricter adherence to physical constraints.\nHowever, imposing hard constraints significantly increases computational and\nmemory costs, especially for complex dynamical systems. This is because it\nrequires solving an optimization problem over a large number of points in a\nmesh, representing spatial and temporal discretizations, which greatly\nincreases the complexity of the constraint. To address this challenge, we\ndevelop a scalable approach to enforce hard physical constraints using\nMixture-of-Experts (MoE), which can be used with any neural network\narchitecture. Our approach imposes the constraint over smaller decomposed\ndomains, each of which is solved by an \"expert\" through differentiable\noptimization. During training, each expert independently performs a localized\nbackpropagation step by leveraging the implicit function theorem; the\nindependence of each expert allows for parallelization across multiple GPUs.\nCompared to standard differentiable optimization, our scalable approach\nachieves greater accuracy in the neural PDE solver setting for predicting the\ndynamics of challenging non-linear systems. We also improve training stability\nand require significantly less computation time during both training and\ninference stages.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the International Conference on Learning Representations\n  (ICLR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13412v1",
    "published_date": "2024-02-20 22:45:00 UTC",
    "updated_date": "2024-02-20 22:45:00 UTC"
  },
  {
    "arxiv_id": "2403.05565v1",
    "title": "OpenHEXAI: An Open-Source Framework for Human-Centered Evaluation of Explainable Machine Learning",
    "authors": [
      "Jiaqi Ma",
      "Vivian Lai",
      "Yiming Zhang",
      "Chacha Chen",
      "Paul Hamilton",
      "Davor Ljubenkov",
      "Himabindu Lakkaraju",
      "Chenhao Tan"
    ],
    "abstract": "Recently, there has been a surge of explainable AI (XAI) methods driven by\nthe need for understanding machine learning model behaviors in high-stakes\nscenarios. However, properly evaluating the effectiveness of the XAI methods\ninevitably requires the involvement of human subjects, and conducting\nhuman-centered benchmarks is challenging in a number of ways: designing and\nimplementing user studies is complex; numerous design choices in the design\nspace of user study lead to problems of reproducibility; and running user\nstudies can be challenging and even daunting for machine learning researchers.\nTo address these challenges, this paper presents OpenHEXAI, an open-source\nframework for human-centered evaluation of XAI methods. OpenHEXAI features (1)\na collection of diverse benchmark datasets, pre-trained models, and post hoc\nexplanation methods; (2) an easy-to-use web application for user study; (3)\ncomprehensive evaluation metrics for the effectiveness of post hoc explanation\nmethods in the context of human-AI decision making tasks; (4) best practice\nrecommendations of experiment documentation; and (5) convenient tools for power\nanalysis and cost estimation. OpenHEAXI is the first large-scale\ninfrastructural effort to facilitate human-centered benchmarks of XAI methods.\nIt simplifies the design and implementation of user studies for XAI methods,\nthus allowing researchers and practitioners to focus on the scientific\nquestions. Additionally, it enhances reproducibility through standardized\ndesigns. Based on OpenHEXAI, we further conduct a systematic benchmark of four\nstate-of-the-art post hoc explanation methods and compare their impacts on\nhuman-AI decision making tasks in terms of accuracy, fairness, as well as\nusers' trust and understanding of the machine learning model.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05565v1",
    "published_date": "2024-02-20 22:17:59 UTC",
    "updated_date": "2024-02-20 22:17:59 UTC"
  },
  {
    "arxiv_id": "2402.13399v2",
    "title": "Learning and Sustaining Shared Normative Systems via Bayesian Rule Induction in Markov Games",
    "authors": [
      "Ninell Oldenburg",
      "Tan Zhi-Xuan"
    ],
    "abstract": "A universal feature of human societies is the adoption of systems of rules\nand norms in the service of cooperative ends. How can we build learning agents\nthat do the same, so that they may flexibly cooperate with the human\ninstitutions they are embedded in? We hypothesize that agents can achieve this\nby assuming there exists a shared set of norms that most others comply with\nwhile pursuing their individual desires, even if they do not know the exact\ncontent of those norms. By assuming shared norms, a newly introduced agent can\ninfer the norms of an existing population from observations of compliance and\nviolation. Furthermore, groups of agents can converge to a shared set of norms,\neven if they initially diverge in their beliefs about what the norms are. This\nin turn enables the stability of the normative system: since agents can\nbootstrap common knowledge of the norms, this leads the norms to be widely\nadhered to, enabling new entrants to rapidly learn those norms. We formalize\nthis framework in the context of Markov games and demonstrate its operation in\na multi-agent environment via approximately Bayesian rule induction of\nobligative and prohibitive norms. Using our approach, agents are able to\nrapidly learn and sustain a variety of cooperative institutions, including\nresource management norms and compensation for pro-social labor, promoting\ncollective welfare while still allowing agents to act in their own interests.",
    "categories": [
      "cs.AI",
      "I.2.0; I.6.5; G.3"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the 23rd International Conference on Autonomous Agents\n  and Multi-Agent Systems, 8 pages (excl. references), 6 figures/tables,\n  (Appendix: 7 pages, 6 figures/tables). Code available at:\n  https://github.com/ninell-oldenburg/social-contracts",
    "pdf_url": "http://arxiv.org/pdf/2402.13399v2",
    "published_date": "2024-02-20 21:58:40 UTC",
    "updated_date": "2024-02-22 15:46:21 UTC"
  },
  {
    "arxiv_id": "2402.13397v1",
    "title": "Xling: A Learned Filter Framework for Accelerating High-Dimensional Approximate Similarity Join",
    "authors": [
      "Yifan Wang",
      "Vyom Pathak",
      "Daisy Zhe Wang"
    ],
    "abstract": "Similarity join finds all pairs of close points within a given distance\nthreshold. Many similarity join methods have been proposed, but they are\nusually not efficient on high-dimensional space due to the curse of\ndimensionality and data-unawareness. We investigate the possibility of using\nmetric space Bloom filter (MSBF), a family of data structures checking if a\nquery point has neighbors in a multi-dimensional space, to speed up similarity\njoin. However, there are several challenges when applying MSBF to similarity\njoin, including excessive information loss, data-unawareness and hard\nconstraint on the distance metric. In this paper, we propose Xling, a generic\nframework to build a learning-based metric space filter with any existing\nregression model, aiming at accurately predicting whether a query point has\nenough number of neighbors. The framework provides a suite of optimization\nstrategies to further improve the prediction quality based on the learning\nmodel, which has demonstrated significantly higher prediction quality than\nexisting MSBF. We also propose XJoin, one of the first filter-based similarity\njoin methods, based on Xling. By predicting and skipping those queries without\nenough neighbors, XJoin can effectively reduce unnecessary neighbor searching\nand therefore it achieves a remarkable acceleration. Benefiting from the\ngeneralization capability of deep learning models, XJoin can be easily\ntransferred onto new dataset (in similar distribution) without re-training.\nFurthermore, Xling is not limited to being applied in XJoin, instead, it acts\nas a flexible plugin that can be inserted to any loop-based similarity join\nmethods for a speedup.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13397v1",
    "published_date": "2024-02-20 21:57:03 UTC",
    "updated_date": "2024-02-20 21:57:03 UTC"
  },
  {
    "arxiv_id": "2402.13380v3",
    "title": "Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers",
    "authors": [
      "Joshua F. Cooper",
      "Seung Jin Choi",
      "I. Esra Buyuktahtakin"
    ],
    "abstract": "In this study, we introduce an innovative deep learning framework that\nemploys a transformer model to address the challenges of mixed-integer\nprograms, specifically focusing on the Capacitated Lot Sizing Problem (CLSP).\nOur approach, to our knowledge, is the first to utilize transformers to predict\nthe binary variables of a mixed-integer programming (MIP) problem.\nSpecifically, our approach harnesses the encoder decoder transformer's ability\nto process sequential data, making it well-suited for predicting binary\nvariables indicating production setup decisions in each period of the CLSP.\nThis problem is inherently dynamic, and we need to handle sequential decision\nmaking under constraints. We present an efficient algorithm in which CLSP\nsolutions are learned through a transformer neural network. The proposed\npost-processed transformer algorithm surpasses the state-of-the-art solver,\nCPLEX and Long Short-Term Memory (LSTM) in solution time, optimal gap, and\npercent infeasibility over 240K benchmark CLSP instances tested. After the ML\nmodel is trained, conducting inference on the model, reduces the MIP into a\nlinear program (LP). This transforms the ML-based algorithm, combined with an\nLP solver, into a polynomial-time approximation algorithm to solve a well-known\nNP-Hard problem, with almost perfect solution quality.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.CO",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13380v3",
    "published_date": "2024-02-20 21:13:38 UTC",
    "updated_date": "2024-05-24 16:17:43 UTC"
  },
  {
    "arxiv_id": "2402.14858v1",
    "title": "ChatEL: Entity Linking with Chatbots",
    "authors": [
      "Yifan Ding",
      "Qingkai Zeng",
      "Tim Weninger"
    ],
    "abstract": "Entity Linking (EL) is an essential and challenging task in natural language\nprocessing that seeks to link some text representing an entity within a\ndocument or sentence with its corresponding entry in a dictionary or knowledge\nbase. Most existing approaches focus on creating elaborate contextual models\nthat look for clues the words surrounding the entity-text to help solve the\nlinking problem. Although these fine-tuned language models tend to work, they\ncan be unwieldy, difficult to train, and do not transfer well to other domains.\nFortunately, Large Language Models (LLMs) like GPT provide a highly-advanced\nsolution to the problems inherent in EL models, but simply naive prompts to\nLLMs do not work well. In the present work, we define ChatEL, which is a\nthree-step framework to prompt LLMs to return accurate results. Overall the\nChatEL framework improves the average F1 performance across 10 datasets by more\nthan 2%. Finally, a thorough error analysis shows many instances with the\nground truth labels were actually incorrect, and the labels predicted by ChatEL\nwere actually correct. This indicates that the quantitative results presented\nin this paper may be a conservative estimate of the actual performance. All\ndata and code are available as an open-source package on GitHub at\nhttps://github.com/yifding/In_Context_EL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14858v1",
    "published_date": "2024-02-20 20:52:57 UTC",
    "updated_date": "2024-02-20 20:52:57 UTC"
  },
  {
    "arxiv_id": "2402.13369v1",
    "title": "The Uncanny Valley: A Comprehensive Analysis of Diffusion Models",
    "authors": [
      "Karam Ghanem",
      "Danilo Bzdok"
    ],
    "abstract": "Through Diffusion Models (DMs), we have made significant advances in\ngenerating high-quality images. Our exploration of these models delves deeply\ninto their core operational principles by systematically investigating key\naspects across various DM architectures: i) noise schedules, ii) samplers, and\niii) guidance. Our comprehensive examination of these models sheds light on\ntheir hidden fundamental mechanisms, revealing the concealed foundational\nelements that are essential for their effectiveness. Our analyses emphasize the\nhidden key factors that determine model performance, offering insights that\ncontribute to the advancement of DMs. Past findings show that the configuration\nof noise schedules, samplers, and guidance is vital to the quality of generated\nimages; however, models reach a stable level of quality across different\nconfigurations at a remarkably similar point, revealing that the decisive\nfactors for optimal performance predominantly reside in the diffusion process\ndynamics and the structural design of the model's network, rather than the\nspecifics of configuration details. Our comparative analysis reveals that\nDenoising Diffusion Probabilistic Model (DDPM)-based diffusion dynamics\nconsistently outperform the Noise Conditioned Score Network (NCSN)-based ones,\nnot only when evaluated in their original forms but also when continuous\nthrough Stochastic Differential Equation (SDE)-based implementations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "I.2.10; I.4.8; I.4.5; I.4.m"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13369v1",
    "published_date": "2024-02-20 20:49:22 UTC",
    "updated_date": "2024-02-20 20:49:22 UTC"
  },
  {
    "arxiv_id": "2402.13352v3",
    "title": "KetGPT - Dataset Augmentation of Quantum Circuits using Transformers",
    "authors": [
      "Boran Apak",
      "Medina Bandic",
      "Aritra Sarkar",
      "Sebastian Feld"
    ],
    "abstract": "Quantum algorithms, represented as quantum circuits, can be used as\nbenchmarks for assessing the performance of quantum systems. Existing datasets,\nwidely utilized in the field, suffer from limitations in size and versatility,\nleading researchers to employ randomly generated circuits. Random circuits are,\nhowever, not representative benchmarks as they lack the inherent properties of\nreal quantum algorithms for which the quantum systems are manufactured. This\nshortage of `useful' quantum benchmarks poses a challenge to advancing the\ndevelopment and comparison of quantum compilers and hardware.\n  This research aims to enhance the existing quantum circuit datasets by\ngenerating what we refer to as `realistic-looking' circuits by employing the\nTransformer machine learning architecture. For this purpose, we introduce\nKetGPT, a tool that generates synthetic circuits in OpenQASM language, whose\nstructure is based on quantum circuits derived from existing quantum algorithms\nand follows the typical patterns of human-written algorithm-based code (e.g.,\norder of gates and qubits). Our three-fold verification process, involving\nmanual inspection and Qiskit framework execution, transformer-based\nclassification, and structural analysis, demonstrates the efficacy of KetGPT in\nproducing large amounts of additional circuits that closely align with\nalgorithm-based structures. Beyond benchmarking, we envision KetGPT\ncontributing substantially to AI-driven quantum compilers and systems.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13352v3",
    "published_date": "2024-02-20 20:02:21 UTC",
    "updated_date": "2024-02-23 08:55:48 UTC"
  },
  {
    "arxiv_id": "2402.13349v2",
    "title": "Aria Everyday Activities Dataset",
    "authors": [
      "Zhaoyang Lv",
      "Nicholas Charron",
      "Pierre Moulon",
      "Alexander Gamino",
      "Cheng Peng",
      "Chris Sweeney",
      "Edward Miller",
      "Huixuan Tang",
      "Jeff Meissner",
      "Jing Dong",
      "Kiran Somasundaram",
      "Luis Pesqueira",
      "Mark Schwesinger",
      "Omkar Parkhi",
      "Qiao Gu",
      "Renzo De Nardi",
      "Shangyi Cheng",
      "Steve Saarinen",
      "Vijay Baiyya",
      "Yuyang Zou",
      "Richard Newcombe",
      "Jakob Julian Engel",
      "Xiaqing Pan",
      "Carl Ren"
    ],
    "abstract": "We present Aria Everyday Activities (AEA) Dataset, an egocentric multimodal\nopen dataset recorded using Project Aria glasses. AEA contains 143 daily\nactivity sequences recorded by multiple wearers in five geographically diverse\nindoor locations. Each of the recording contains multimodal sensor data\nrecorded through the Project Aria glasses. In addition, AEA provides machine\nperception data including high frequency globally aligned 3D trajectories,\nscene point cloud, per-frame 3D eye gaze vector and time aligned speech\ntranscription. In this paper, we demonstrate a few exemplar research\napplications enabled by this dataset, including neural scene reconstruction and\nprompted segmentation. AEA is an open source dataset that can be downloaded\nfrom https://www.projectaria.com/datasets/aea/. We are also providing\nopen-source implementations and examples of how to use the dataset in Project\nAria Tools https://github.com/facebookresearch/projectaria_tools.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "Dataset website: https://www.projectaria.com/datasets/aea/",
    "pdf_url": "http://arxiv.org/pdf/2402.13349v2",
    "published_date": "2024-02-20 19:53:15 UTC",
    "updated_date": "2024-02-22 03:37:36 UTC"
  },
  {
    "arxiv_id": "2402.13326v2",
    "title": "Deep Hedging with Market Impact",
    "authors": [
      "Andrei Neagu",
      "Frédéric Godin",
      "Clarence Simard",
      "Leila Kosseim"
    ],
    "abstract": "Dynamic hedging is the practice of periodically transacting financial\ninstruments to offset the risk caused by an investment or a liability. Dynamic\nhedging optimization can be framed as a sequential decision problem; thus,\nReinforcement Learning (RL) models were recently proposed to tackle this task.\nHowever, existing RL works for hedging do not consider market impact caused by\nthe finite liquidity of traded instruments. Integrating such feature can be\ncrucial to achieve optimal performance when hedging options on stocks with\nlimited liquidity. In this paper, we propose a novel general market impact\ndynamic hedging model based on Deep Reinforcement Learning (DRL) that considers\nseveral realistic features such as convex market impacts, and impact\npersistence through time. The optimal policy obtained from the DRL model is\nanalysed using several option hedging simulations and compared to commonly used\nprocedures such as delta hedging. Results show our DRL model behaves better in\ncontexts of low liquidity by, among others: 1) learning the extent to which\nportfolio rebalancing actions should be dampened or delayed to avoid high\ncosts, 2) factoring in the impact of features not considered by conventional\napproaches, such as previous hedging errors through the portfolio value, and\nthe underlying asset's drift (i.e. the magnitude of its expected return).",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13326v2",
    "published_date": "2024-02-20 19:08:24 UTC",
    "updated_date": "2024-02-22 21:25:42 UTC"
  },
  {
    "arxiv_id": "2402.13254v4",
    "title": "CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples",
    "authors": [
      "Jianrui Zhang",
      "Mu Cai",
      "Tengyang Xie",
      "Yong Jae Lee"
    ],
    "abstract": "We propose CounterCurate, a framework to comprehensively improve the\nvisio-linguistic compositional reasoning capability for both contrastive and\ngenerative multimodal models. In particular, we identify two critical\nunder-explored problems: the neglect of the physically grounded reasoning\n(counting and position understanding) and the potential of using highly capable\ntext and image generation models for semantic counterfactual fine-tuning. Our\nwork pioneers an approach that addresses these gaps. We first spotlight the\nnear-chance performance of multimodal models like CLIP and LLaVA in physically\ngrounded compositional reasoning. We then apply simple data augmentation using\ngrounded image generation model GLIGEN to generate fine-tuning data, resulting\nin significant performance improvements: +33% and +37% for CLIP and LLaVA,\nrespectively, on our newly curated Flickr30k-Positions benchmark. Moreover, we\nexploit the capabilities of high-performing text generation and image\ngeneration models, specifically GPT-4V and DALLE-3, to curate challenging\nsemantic counterfactuals, thereby further enhancing compositional reasoning\ncapabilities on benchmarks such as SugarCrepe, where CounterCurate outperforms\nGPT-4V. To facilitate future research, we release our code, dataset, benchmark,\nand checkpoints at https://countercurate.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 6 figures, 12 tables, Project Page:\n  https://countercurate.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2402.13254v4",
    "published_date": "2024-02-20 18:59:55 UTC",
    "updated_date": "2024-06-12 17:59:55 UTC"
  },
  {
    "arxiv_id": "2402.13249v2",
    "title": "TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization",
    "authors": [
      "Liyan Tang",
      "Igor Shalyminov",
      "Amy Wing-mei Wong",
      "Jon Burnsky",
      "Jake W. Vincent",
      "Yu'an Yang",
      "Siffi Singh",
      "Song Feng",
      "Hwanjun Song",
      "Hang Su",
      "Lijia Sun",
      "Yi Zhang",
      "Saab Mansour",
      "Kathleen McKeown"
    ],
    "abstract": "Single document news summarization has seen substantial progress on\nfaithfulness in recent years, driven by research on the evaluation of factual\nconsistency, or hallucinations. We ask whether these advances carry over to\nother text summarization domains. We propose a new evaluation benchmark on\ntopic-focused dialogue summarization, generated by LLMs of varying sizes. We\nprovide binary sentence-level human annotations of the factual consistency of\nthese summaries along with detailed explanations of factually inconsistent\nsentences. Our analysis shows that existing LLMs hallucinate significant\namounts of factual errors in the dialogue domain, regardless of the model's\nsize. On the other hand, when LLMs, including GPT-4, serve as binary factual\nevaluators, they perform poorly and can be outperformed by prevailing\nstate-of-the-art specialized factuality evaluation metrics. Finally, we\nconducted an analysis of hallucination types with a curated error taxonomy. We\nfind that there are diverse errors and error distributions in model-generated\nsummaries and that non-LLM based metrics can capture all error types better\nthan LLM-based evaluators.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2024; Linguistic annotations available at\n  https://github.com/amazon-science/tofueval",
    "pdf_url": "http://arxiv.org/pdf/2402.13249v2",
    "published_date": "2024-02-20 18:58:49 UTC",
    "updated_date": "2024-03-31 15:30:34 UTC"
  },
  {
    "arxiv_id": "2404.07214v2",
    "title": "Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions",
    "authors": [
      "Akash Ghosh",
      "Arkadeep Acharya",
      "Sriparna Saha",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has significantly reshaped the\ntrajectory of the AI revolution. Nevertheless, these LLMs exhibit a notable\nlimitation, as they are primarily adept at processing textual information. To\naddress this constraint, researchers have endeavored to integrate visual\ncapabilities with LLMs, resulting in the emergence of Vision-Language Models\n(VLMs). These advanced models are instrumental in tackling more intricate tasks\nsuch as image captioning and visual question answering. In our comprehensive\nsurvey paper, we delve into the key advancements within the realm of VLMs. Our\nclassification organizes VLMs into three distinct categories: models dedicated\nto vision-language understanding, models that process multimodal inputs to\ngenerate unimodal (textual) outputs and models that both accept and produce\nmultimodal inputs and outputs.This classification is based on their respective\ncapabilities and functionalities in processing and generating various\nmodalities of data.We meticulously dissect each model, offering an extensive\nanalysis of its foundational architecture, training data sources, as well as\nits strengths and limitations wherever possible, providing readers with a\ncomprehensive understanding of its essential components. We also analyzed the\nperformance of VLMs in various benchmark datasets. By doing so, we aim to offer\na nuanced understanding of the diverse landscape of VLMs. Additionally, we\nunderscore potential avenues for future research in this dynamic domain,\nanticipating further breakthroughs and advancements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "The most extensive and up to date Survey on Visual Language Models\n  covering 76 Visual Language Models",
    "pdf_url": "http://arxiv.org/pdf/2404.07214v2",
    "published_date": "2024-02-20 18:57:34 UTC",
    "updated_date": "2024-04-12 21:20:37 UTC"
  },
  {
    "arxiv_id": "2402.13241v2",
    "title": "Federated Causal Discovery from Heterogeneous Data",
    "authors": [
      "Loka Li",
      "Ignavier Ng",
      "Gongxu Luo",
      "Biwei Huang",
      "Guangyi Chen",
      "Tongliang Liu",
      "Bin Gu",
      "Kun Zhang"
    ],
    "abstract": "Conventional causal discovery methods rely on centralized data, which is\ninconsistent with the decentralized nature of data in many real-world\nsituations. This discrepancy has motivated the development of federated causal\ndiscovery (FCD) approaches. However, existing FCD methods may be limited by\ntheir potentially restrictive assumptions of identifiable functional causal\nmodels or homogeneous data distributions, narrowing their applicability in\ndiverse scenarios. In this paper, we propose a novel FCD method attempting to\naccommodate arbitrary causal models and heterogeneous data. We first utilize a\nsurrogate variable corresponding to the client index to account for the data\nheterogeneity across different clients. We then develop a federated conditional\nindependence test (FCIT) for causal skeleton discovery and establish a\nfederated independent change principle (FICP) to determine causal directions.\nThese approaches involve constructing summary statistics as a proxy of the raw\ndata to protect data privacy. Owing to the nonparametric properties, FCIT and\nFICP make no assumption about particular functional forms, thereby facilitating\nthe handling of arbitrary causal models. We conduct extensive experiments on\nsynthetic and real datasets to show the efficacy of our method. The code is\navailable at https://github.com/lokali/FedCDH.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13241v2",
    "published_date": "2024-02-20 18:53:53 UTC",
    "updated_date": "2024-02-27 04:45:47 UTC"
  },
  {
    "arxiv_id": "2402.13228v2",
    "title": "Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive",
    "authors": [
      "Arka Pal",
      "Deep Karkhanis",
      "Samuel Dooley",
      "Manley Roberts",
      "Siddartha Naidu",
      "Colin White"
    ],
    "abstract": "Direct Preference Optimisation (DPO) is effective at significantly improving\nthe performance of large language models (LLMs) on downstream tasks such as\nreasoning, summarisation, and alignment. Using pairs of preferred and\ndispreferred data, DPO models the relative probability of picking one response\nover another. In this work, first we show theoretically that the standard DPO\nloss can lead to a reduction of the model's likelihood of the preferred\nexamples, as long as the relative probability between the preferred and\ndispreferred classes increases. We then show empirically that this phenomenon\noccurs when fine-tuning LLMs on common datasets, especially datasets in which\nthe edit distance between pairs of completions is low. Using these insights, we\ndesign DPO-Positive (DPOP), a new loss function and training procedure which\navoids this failure mode. Surprisingly, we find that DPOP outperforms DPO and\nother fine-tuning procedures across a wide variety of datasets and downstream\ntasks, including datasets with high edit distances between completions.\nFurthermore, we find that the DPOP-tuned model outperforms the DPO-tuned model\n(all else equal) on benchmarks independent of the fine-tuning data, such as\nMT-Bench. Finally, using DPOP, we create and open-source Smaug-34B and\nSmaug-72B, with the latter becoming the first open-source LLM to surpass an\naverage accuracy of 80% on the HuggingFace Open LLM Leaderboard.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13228v2",
    "published_date": "2024-02-20 18:42:34 UTC",
    "updated_date": "2024-07-03 13:46:33 UTC"
  },
  {
    "arxiv_id": "2402.13226v2",
    "title": "NeRF Solves Undersampled MRI Reconstruction",
    "authors": [
      "Tae Jun Jang",
      "Chang Min Hyun"
    ],
    "abstract": "This article presents a novel undersampled magnetic resonance imaging (MRI)\ntechnique that leverages the concept of Neural Radiance Field (NeRF). With\nradial undersampling, the corresponding imaging problem can be reformulated\ninto an image modeling task from sparse-view rendered data; therefore, a high\ndimensional MR image is obtainable from undersampled k-space data by taking\nadvantage of implicit neural representation. A multi-layer perceptron, which is\ndesigned to output an image intensity from a spatial coordinate, learns the MR\nphysics-driven rendering relation between given measurement data and desired\nimage. Effective undersampling strategies for high-quality neural\nrepresentation are investigated. The proposed method serves two benefits: (i)\nThe learning is based fully on single undersampled k-space data, not a bunch of\nmeasured data and target image sets. It can be used potentially for diagnostic\nMR imaging, such as fetal MRI, where data acquisition is relatively rare or\nlimited against diversity of clinical images while undersampled reconstruction\nis highly demanded. (ii) A reconstructed MR image is a scan-specific\nrepresentation highly adaptive to the given k-space measurement. Numerous\nexperiments validate the feasibility and capability of the proposed approach.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CE",
      "eess.SP"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13226v2",
    "published_date": "2024-02-20 18:37:42 UTC",
    "updated_date": "2024-03-02 15:46:20 UTC"
  },
  {
    "arxiv_id": "2402.13225v1",
    "title": "AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning",
    "authors": [
      "Qiao Jin",
      "Zhizheng Wang",
      "Yifan Yang",
      "Qingqing Zhu",
      "Donald Wright",
      "Thomas Huang",
      "W John Wilbur",
      "Zhe He",
      "Andrew Taylor",
      "Qingyu Chen",
      "Zhiyong Lu"
    ],
    "abstract": "Clinical calculators play a vital role in healthcare by offering accurate\nevidence-based predictions for various purposes such as prognosis.\nNevertheless, their widespread utilization is frequently hindered by usability\nchallenges, poor dissemination, and restricted functionality. Augmenting large\nlanguage models with extensive collections of clinical calculators presents an\nopportunity to overcome these obstacles and improve workflow efficiency, but\nthe scalability of the manual curation process poses a significant challenge.\nIn response, we introduce AgentMD, a novel language agent capable of curating\nand applying clinical calculators across various clinical contexts. Using the\npublished literature, AgentMD has automatically curated a collection of 2,164\ndiverse clinical calculators with executable functions and structured\ndocumentation, collectively named RiskCalcs. Manual evaluations show that\nRiskCalcs tools achieve an accuracy of over 80% on three quality metrics. At\ninference time, AgentMD can automatically select and apply the relevant\nRiskCalcs tools given any patient description. On the newly established RiskQA\nbenchmark, AgentMD significantly outperforms chain-of-thought prompting with\nGPT-4 (87.7% vs. 40.9% in accuracy). Additionally, we also applied AgentMD to\nreal-world clinical notes for analyzing both population-level and risk-level\npatient characteristics. In summary, our study illustrates the utility of\nlanguage agents augmented with clinical calculators for healthcare analytics\nand patient care.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2402.13225v1",
    "published_date": "2024-02-20 18:37:19 UTC",
    "updated_date": "2024-02-20 18:37:19 UTC"
  },
  {
    "arxiv_id": "2402.13224v4",
    "title": "Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming",
    "authors": [
      "Alban Puech",
      "Tristan Rigaut",
      "William Templier",
      "Maud Tournoud"
    ],
    "abstract": "This paper introduces an Electric Vehicle Charging Station (EVCS) model that\nincorporates real-world constraints, such as slot power limitations, contract\nthreshold overruns penalties, or early disconnections of electric vehicles\n(EVs). We propose a formulation of the problem of EVCS control under\nuncertainty, and implement two Multi-Stage Stochastic Programming approaches\nthat leverage user-provided information, namely, Model Predictive Control and\nTwo-Stage Stochastic Programming. The model addresses uncertainties in charging\nsession start and end times, as well as in energy demand. A user's behavior\nmodel based on a sojourn-time-dependent stochastic process enhances cost\nreduction while maintaining customer satisfaction. The benefits of the two\nproposed methods are showcased against two baselines over a 22-day simulation\nusing a real-world dataset. The two-stage approach demonstrates robustness\nagainst early disconnections by considering a wider range of uncertainty\nscenarios for optimization. The algorithm prioritizing user satisfaction over\nelectricity cost achieves a 20% and 36% improvement in two user satisfaction\nmetrics compared to an industry-standard baseline. Additionally, the algorithm\nstriking the best balance between cost and user satisfaction exhibits a mere 3%\nrelative cost increase compared to the theoretically optimal baseline - for\nwhich the nonanticipativity constraint is relaxed - while attaining 94% and 84%\nof the user satisfaction performance in the two used satisfaction metrics.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13224v4",
    "published_date": "2024-02-20 18:37:11 UTC",
    "updated_date": "2024-11-13 14:54:18 UTC"
  },
  {
    "arxiv_id": "2403.14639v1",
    "title": "On Defining Smart Cities using Transformer Neural Networks",
    "authors": [
      "Andrei Khurshudov"
    ],
    "abstract": "Cities worldwide are rapidly adopting smart technologies, transforming urban\nlife. Despite this trend, a universally accepted definition of 'smart city'\nremains elusive. Past efforts to define it have not yielded a consensus, as\nevidenced by the numerous definitions in use. In this paper, we endeavored to\ncreate a new 'compromise' definition that should resonate with most experts\npreviously involved in defining this concept and aimed to validate one of the\nexisting definitions. We reviewed 60 definitions of smart cities from industry,\nacademia, and various relevant organizations, employing transformer\narchitecture-based generative AI and semantic text analysis to reach this\ncompromise. We proposed a semantic similarity measure as an evaluation\ntechnique, which could generally be used to compare different smart city\ndefinitions, assessing their uniqueness or resemblance. Our methodology\nemployed generative AI to analyze various existing definitions of smart cities,\ngenerating a list of potential new composite definitions. Each of these new\ndefinitions was then tested against the pre-existing individual definitions we\nhave gathered, using cosine similarity as our metric. This process identified\nsmart city definitions with the highest average cosine similarity, semantically\npositioning them as the closest on average to all the 60 individual definitions\nselected.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, 2 fugures",
    "pdf_url": "http://arxiv.org/pdf/2403.14639v1",
    "published_date": "2024-02-20 18:34:24 UTC",
    "updated_date": "2024-02-20 18:34:24 UTC"
  },
  {
    "arxiv_id": "2402.13219v1",
    "title": "Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies",
    "authors": [
      "Ammar N. Abbas",
      "Chidera W. Amazu",
      "Joseph Mietkiewicz",
      "Houda Briwa",
      "Andres Alonzo Perez",
      "Gabriele Baldissone",
      "Micaela Demichela",
      "Georgios G. Chasparis",
      "John D. Kelleher",
      "Maria Chiara Leva"
    ],
    "abstract": "In complex industrial and chemical process control rooms, effective\ndecision-making is crucial for safety and efficiency. The experiments in this\npaper evaluate the impact and applications of an AI-based decision support\nsystem integrated into an improved human-machine interface, using dynamic\ninfluence diagrams, a hidden Markov model, and deep reinforcement learning. The\nenhanced support system aims to reduce operator workload, improve situational\nawareness, and provide different intervention strategies to the operator\nadapted to the current state of both the system and human performance. Such a\nsystem can be particularly useful in cases of information overload when many\nalarms and inputs are presented all within the same time window, or for junior\noperators during training. A comprehensive cross-data analysis was conducted,\ninvolving 47 participants and a diverse range of data sources such as\nsmartwatch metrics, eye-tracking data, process logs, and responses from\nquestionnaires. The results indicate interesting insights regarding the\neffectiveness of the approach in aiding decision-making, decreasing perceived\nworkload, and increasing situational awareness for the scenarios considered.\nAdditionally, the results provide valuable insights to compare differences\nbetween styles of information gathering when using the system by individual\nparticipants. These findings are particularly relevant when predicting the\noverall performance of the individual participant and their capacity to\nsuccessfully handle a plant upset and the alarms connected to it using process\nand human-machine interaction logs in real-time. These predictions enable the\ndevelopment of more effective intervention strategies.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13219v1",
    "published_date": "2024-02-20 18:31:27 UTC",
    "updated_date": "2024-02-20 18:31:27 UTC"
  },
  {
    "arxiv_id": "2402.13217v2",
    "title": "VideoPrism: A Foundational Visual Encoder for Video Understanding",
    "authors": [
      "Long Zhao",
      "Nitesh B. Gundavarapu",
      "Liangzhe Yuan",
      "Hao Zhou",
      "Shen Yan",
      "Jennifer J. Sun",
      "Luke Friedman",
      "Rui Qian",
      "Tobias Weyand",
      "Yue Zhao",
      "Rachel Hornung",
      "Florian Schroff",
      "Ming-Hsuan Yang",
      "David A. Ross",
      "Huisheng Wang",
      "Hartwig Adam",
      "Mikhail Sirotenko",
      "Ting Liu",
      "Boqing Gong"
    ],
    "abstract": "We introduce VideoPrism, a general-purpose video encoder that tackles diverse\nvideo understanding tasks with a single frozen model. We pretrain VideoPrism on\na heterogeneous corpus containing 36M high-quality video-caption pairs and 582M\nvideo clips with noisy parallel text (e.g., ASR transcripts). The pretraining\napproach improves upon masked autoencoding by global-local distillation of\nsemantic video embeddings and a token shuffling scheme, enabling VideoPrism to\nfocus primarily on the video modality while leveraging the invaluable text\nassociated with videos. We extensively test VideoPrism on four broad groups of\nvideo understanding tasks, from web video question answering to CV for science,\nachieving state-of-the-art performance on 31 out of 33 video understanding\nbenchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICML 2024. v2: added retrieval results on MSRVTT (1K-A),\n  more data analyses, and ablation studies",
    "pdf_url": "http://arxiv.org/pdf/2402.13217v2",
    "published_date": "2024-02-20 18:29:49 UTC",
    "updated_date": "2024-06-16 00:56:08 UTC"
  },
  {
    "arxiv_id": "2402.13213v3",
    "title": "Probabilities of Chat LLMs Are Miscalibrated but Still Predict Correctness on Multiple-Choice Q&A",
    "authors": [
      "Benjamin Plaut",
      "Nguyen X. Khanh",
      "Tu Trinh"
    ],
    "abstract": "We study 15 large language models (LLMs) fine-tuned for chat and find that\ntheir maximum softmax probabilities (MSPs) are consistently miscalibrated on\nmultiple-choice Q&A. However, those MSPs might still encode useful uncertainty\ninformation. Specifically, we hypothesized that wrong answers would be\nassociated with smaller MSPs compared to correct answers. Via rigorous\nstatistical testing, we show that this hypothesis holds for models which\nperform well on the underlying Q&A task. We also find a strong direction\ncorrelation between Q&A accuracy and MSP correctness prediction, while finding\nno correlation between Q&A accuracy and calibration error. This suggests that\nwithin the current fine-tuning paradigm, we can expect correctness prediction\nbut not calibration to improve as LLM capabilities progress. To demonstrate the\nutility of correctness prediction, we show that when models have the option to\nabstain, performance can be improved by selectively abstaining based on the MSP\nof the initial model response, using only a small amount of labeled data to\nchoose the MSP threshold.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13213v3",
    "published_date": "2024-02-20 18:24:47 UTC",
    "updated_date": "2025-03-19 16:57:23 UTC"
  },
  {
    "arxiv_id": "2402.13212v2",
    "title": "Soft Self-Consistency Improves Language Model Agents",
    "authors": [
      "Han Wang",
      "Archiki Prasad",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ],
    "abstract": "Generations from large language models (LLMs) can be improved by sampling and\nscoring multiple solutions to select a final answer. Current \"sample and\nselect\" methods such as self-consistency (SC) rely on majority voting to score\nanswers. However, when tasks have many distinct and valid answers, selection by\nvoting requires a large number of samples. This makes SC prohibitively\nexpensive for interactive tasks that involve generating multiple actions\n(answers) sequentially. After establishing that majority voting fails to\nprovide consistent gains on such tasks, we demonstrate how to increase success\nrates by softening the scoring criterion. We introduce Soft Self-Consistency\n(SOFT-SC), which replaces SC's discontinuous scoring with a continuous score\ncomputed from model likelihoods, allowing for selection even when actions are\nsparsely distributed. SOFT-SC improves both performance and efficiency on\nlong-horizon interactive tasks, requiring half as many samples as SC for\ncomparable or better performance. For a fixed number of samples, SOFT-SC leads\nto a 1.3% increase over SC in absolute success rate on writing bash programs, a\n6.6% increase on online shopping (WebShop), and a 4.7% increase for an\ninteractive household game (ALFWorld). Finally, we show that SOFT-SC can be\napplied to both open-source and black-box models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Camera-Ready, the first three authors contributed equally;\n  Code: https://github.com/HanNight/soft_self_consistency",
    "pdf_url": "http://arxiv.org/pdf/2402.13212v2",
    "published_date": "2024-02-20 18:22:38 UTC",
    "updated_date": "2024-06-05 19:50:19 UTC"
  },
  {
    "arxiv_id": "2402.13208v1",
    "title": "How do Hyenas deal with Human Speech? Speech Recognition and Translation with ConfHyena",
    "authors": [
      "Marco Gaido",
      "Sara Papi",
      "Matteo Negri",
      "Luisa Bentivogli"
    ],
    "abstract": "The attention mechanism, a cornerstone of state-of-the-art neural models,\nfaces computational hurdles in processing long sequences due to its quadratic\ncomplexity. Consequently, research efforts in the last few years focused on\nfinding more efficient alternatives. Among them, Hyena (Poli et al., 2023)\nstands out for achieving competitive results in both language modeling and\nimage classification, while offering sub-quadratic memory and computational\ncomplexity. Building on these promising results, we propose ConfHyena, a\nConformer whose encoder self-attentions are replaced with an adaptation of\nHyena for speech processing, where the long input sequences cause high\ncomputational costs. Through experiments in automatic speech recognition (for\nEnglish) and translation (from English into 8 target languages), we show that\nour best ConfHyena model significantly reduces the training time by 27%, at the\ncost of minimal quality degradation (~1%), which, in most cases, is not\nstatistically significant.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13208v1",
    "published_date": "2024-02-20 18:19:08 UTC",
    "updated_date": "2024-02-20 18:19:08 UTC"
  },
  {
    "arxiv_id": "2402.13201v1",
    "title": "Tiny Reinforcement Learning for Quadruped Locomotion using Decision Transformers",
    "authors": [
      "Orhan Eren Akgün",
      "Néstor Cuevas",
      "Matheus Farias",
      "Daniel Garces"
    ],
    "abstract": "Resource-constrained robotic platforms are particularly useful for tasks that\nrequire low-cost hardware alternatives due to the risk of losing the robot,\nlike in search-and-rescue applications, or the need for a large number of\ndevices, like in swarm robotics. For this reason, it is crucial to find\nmechanisms for adapting reinforcement learning techniques to the constraints\nimposed by lower computational power and smaller memory capacities of these\nultra low-cost robotic platforms. We try to address this need by proposing a\nmethod for making imitation learning deployable onto resource-constrained\nrobotic platforms. Here we cast the imitation learning problem as a conditional\nsequence modeling task and we train a decision transformer using expert\ndemonstrations augmented with a custom reward. Then, we compress the resulting\ngenerative model using software optimization schemes, including quantization\nand pruning. We test our method in simulation using Isaac Gym, a realistic\nphysics simulation environment designed for reinforcement learning. We\nempirically demonstrate that our method achieves natural looking gaits for\nBittle, a resource-constrained quadruped robot. We also run multiple\nsimulations to show the effects of pruning and quantization on the performance\nof the model. Our results show that quantization (down to 4 bits) and pruning\nreduce model size by around 30\\% while maintaining a competitive reward, making\nthe model deployable in a resource-constrained system.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13201v1",
    "published_date": "2024-02-20 18:10:39 UTC",
    "updated_date": "2024-02-20 18:10:39 UTC"
  },
  {
    "arxiv_id": "2403.00834v1",
    "title": "Virtual Reality for Understanding Artificial-Intelligence-driven Scientific Discovery with an Application in Quantum Optics",
    "authors": [
      "Philipp Schmidt",
      "Sören Arlt",
      "Carlos Ruiz-Gonzalez",
      "Xuemei Gu",
      "Carla Rodríguez",
      "Mario Krenn"
    ],
    "abstract": "Generative Artificial Intelligence (AI) models can propose solutions to\nscientific problems beyond human capability. To truly make conceptual\ncontributions, researchers need to be capable of understanding the AI-generated\nstructures and extracting the underlying concepts and ideas. When algorithms\nprovide little explanatory reasoning alongside the output, scientists have to\nreverse-engineer the fundamental insights behind proposals based solely on\nexamples. This task can be challenging as the output is often highly complex\nand thus not immediately accessible to humans. In this work we show how\ntransferring part of the analysis process into an immersive Virtual Reality\n(VR) environment can assist researchers in developing an understanding of\nAI-generated solutions. We demonstrate the usefulness of VR in finding\ninterpretable configurations of abstract graphs, representing Quantum Optics\nexperiments. Thereby, we can manually discover new generalizations of\nAI-discoveries as well as new understanding in experimental quantum optics.\nFurthermore, it allows us to customize the search space in an informed way - as\na human-in-the-loop - to achieve significantly faster subsequent discovery\niterations. As concrete examples, with this technology, we discover a new\nresource-efficient 3-dimensional entanglement swapping scheme, as well as a\n3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our\nresults show the potential of VR for increasing a human researcher's ability to\nderive knowledge from graph-based generative AI that, which is a common\nabstract data representation used in diverse fields of science.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.GR",
      "quant-ph"
    ],
    "primary_category": "cs.HC",
    "comment": "12 pages, 6 figures, comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2403.00834v1",
    "published_date": "2024-02-20 17:48:01 UTC",
    "updated_date": "2024-02-20 17:48:01 UTC"
  },
  {
    "arxiv_id": "2402.13178v2",
    "title": "Benchmarking Retrieval-Augmented Generation for Medicine",
    "authors": [
      "Guangzhi Xiong",
      "Qiao Jin",
      "Zhiyong Lu",
      "Aidong Zhang"
    ],
    "abstract": "While large language models (LLMs) have achieved state-of-the-art performance\non a wide range of medical question answering (QA) tasks, they still face\nchallenges with hallucinations and outdated knowledge. Retrieval-augmented\ngeneration (RAG) is a promising solution and has been widely adopted. However,\na RAG system can involve multiple flexible components, and there is a lack of\nbest practices regarding the optimal RAG setting for various medical purposes.\nTo systematically evaluate such systems, we propose the Medical Information\nRetrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind\nbenchmark including 7,663 questions from five medical QA datasets. Using\nMIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt\ntokens on 41 combinations of different corpora, retrievers, and backbone LLMs\nthrough the MedRAG toolkit introduced in this work. Overall, MedRAG improves\nthe accuracy of six different LLMs by up to 18% over chain-of-thought\nprompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level. Our\nresults show that the combination of various medical corpora and retrievers\nachieves the best performance. In addition, we discovered a log-linear scaling\nproperty and the \"lost-in-the-middle\" effects in medical RAG. We believe our\ncomprehensive evaluations can serve as practical guidelines for implementing\nRAG systems for medicine.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Homepage: https://teddy-xionggz.github.io/benchmark-medical-rag/",
    "pdf_url": "http://arxiv.org/pdf/2402.13178v2",
    "published_date": "2024-02-20 17:44:06 UTC",
    "updated_date": "2024-02-23 16:46:58 UTC"
  },
  {
    "arxiv_id": "2402.14857v2",
    "title": "Is the System Message Really Important to Jailbreaks in Large Language Models?",
    "authors": [
      "Xiaotian Zou",
      "Yongkang Chen",
      "Ke Li"
    ],
    "abstract": "The rapid evolution of Large Language Models (LLMs) has rendered them\nindispensable in modern society. While security measures are typically to align\nLLMs with human values prior to release, recent studies have unveiled a\nconcerning phenomenon named \"Jailbreak\". This term refers to the unexpected and\npotentially harmful responses generated by LLMs when prompted with malicious\nquestions. Most existing research focus on generating jailbreak prompts but\nsystem message configurations vary significantly in experiments. In this paper,\nwe aim to answer a question: Is the system message really important for\njailbreaks in LLMs? We conduct experiments in mainstream LLMs to generate\njailbreak prompts with varying system messages: short, long, and none. We\ndiscover that different system messages have distinct resistances to\njailbreaks. Therefore, we explore the transferability of jailbreaks across LLMs\nwith different system messages. Furthermore, we propose the System Messages\nEvolutionary Algorithm (SMEA) to generate system messages that are more\nresistant to jailbreak prompts, even with minor changes. Through SMEA, we get a\nrobust system messages population with little change in the length of system\nmessages. Our research not only bolsters LLMs security but also raises the bar\nfor jailbreaks, fostering advancements in this field of study.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14857v2",
    "published_date": "2024-02-20 17:39:40 UTC",
    "updated_date": "2024-06-18 19:22:19 UTC"
  },
  {
    "arxiv_id": "2402.13147v3",
    "title": "SPRINQL: Sub-optimal Demonstrations driven Offline Imitation Learning",
    "authors": [
      "Huy Hoang",
      "Tien Mai",
      "Pradeep Varakantham"
    ],
    "abstract": "We focus on offline imitation learning (IL), which aims to mimic an expert's\nbehavior using demonstrations without any interaction with the environment. One\nof the main challenges in offline IL is the limited support of expert\ndemonstrations, which typically cover only a small fraction of the state-action\nspace. While it may not be feasible to obtain numerous expert demonstrations,\nit is often possible to gather a larger set of sub-optimal demonstrations. For\nexample, in treatment optimization problems, there are varying levels of doctor\ntreatments available for different chronic conditions. These range from\ntreatment specialists and experienced general practitioners to less experienced\ngeneral practitioners. Similarly, when robots are trained to imitate humans in\nroutine tasks, they might learn from individuals with different levels of\nexpertise and efficiency.\n  In this paper, we propose an offline IL approach that leverages the larger\nset of sub-optimal demonstrations while effectively mimicking expert\ntrajectories. Existing offline IL methods based on behavior cloning or\ndistribution matching often face issues such as overfitting to the limited set\nof expert demonstrations or inadvertently imitating sub-optimal trajectories\nfrom the larger dataset. Our approach, which is based on inverse soft-Q\nlearning, learns from both expert and sub-optimal demonstrations. It assigns\nhigher importance (through learned weights) to aligning with expert\ndemonstrations and lower importance to aligning with sub-optimal ones. A key\ncontribution of our approach, called SPRINQL, is transforming the offline IL\nproblem into a convex optimization over the space of Q functions. Through\ncomprehensive experimental evaluations, we demonstrate that the SPRINQL\nalgorithm achieves state-of-the-art (SOTA) performance on offline IL\nbenchmarks. Code is available at https://github.com/hmhuy0/SPRINQL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13147v3",
    "published_date": "2024-02-20 17:02:48 UTC",
    "updated_date": "2024-10-10 19:27:40 UTC"
  },
  {
    "arxiv_id": "2402.13145v2",
    "title": "CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for Boosting Metaphor Generation",
    "authors": [
      "Yujie Shao",
      "Xinrong Yao",
      "Xingwei Qu",
      "Chenghua Lin",
      "Shi Wang",
      "Stephen W. Huang",
      "Ge Zhang",
      "Jie Fu"
    ],
    "abstract": "Metaphor is a prominent linguistic device in human language and literature,\nas they add color, imagery, and emphasis to enhance effective communication.\nThis paper introduces a large-scale high quality annotated Chinese Metaphor\nCorpus, which comprises around 28K sentences drawn from a diverse range of\nChinese literary sources, such as poems, prose, song lyrics, etc. To ensure the\naccuracy and consistency of our annotations, we introduce a comprehensive set\nof guidelines. These guidelines address the facets of metaphor annotation,\nincluding identifying tenors, vehicles, and grounds to handling the\ncomplexities of similes, personifications, juxtapositions, and hyperboles.\nBreaking tradition, our approach to metaphor generation emphasizes grounds and\ntheir distinct features rather than the conventional combination of tenors and\nvehicles. By integrating \"ground\" as a CoT (Chain of Thoughts) input, we are\nable to generate metaphors that resonate more with real-world intuition. We\ntest generative models such as Belle, Baichuan, and Chinese-alpaca-33B using\nour annotated corpus. These models are able to generate creative and fluent\nmetaphor sentences more frequently induced by selected samples from our\ndataset, demonstrating the value of our corpus for Chinese metaphor research.\nThe code is available in\nhttps://github.com/JasonShao55/Chinese_Metaphor_Explanation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13145v2",
    "published_date": "2024-02-20 17:00:41 UTC",
    "updated_date": "2024-02-21 03:18:04 UTC"
  },
  {
    "arxiv_id": "2404.07213v1",
    "title": "Evolving Genetic Programming Tree Models for Predicting the Mechanical Properties of Green Fibers for Better Biocomposite Materials",
    "authors": [
      "Faris M. AL-Oqla",
      "Hossam Faris",
      "Maria Habib",
      "Pedro A. Castillo-Valdivieso"
    ],
    "abstract": "Advanced modern technology and industrial sustainability theme have\ncontributed implementing composite materials for various industrial\napplications. Green composites are among the desired alternatives for the green\nproducts. However, to properly control the performance of the green composites,\npredicting their constituents properties are of paramount importance. This work\npresents an innovative evolving genetic programming tree models for predicting\nthe mechanical properties of natural fibers based upon several inherent\nchemical and physical properties. Cellulose, hemicellulose, lignin and moisture\ncontents as well as the Microfibrillar angle of various natural fibers were\nconsidered to establish the prediction models. A one-hold-out methodology was\napplied for training/testing phases. Robust models were developed to predict\nthe tensile strength, Young's modulus, and the elongation at break properties\nof the natural fibers. It was revealed that Microfibrillar angle was dominant\nand capable of determining the ultimate tensile strength of the natural fibers\nby 44.7% comparable to other considered properties, while the impact of\ncellulose content in the model was only 35.6%. This in order would facilitate\nutilizing artificial intelligence in predicting the overall mechanical\nproperties of natural fibers without experimental efforts and cost to enhance\ndeveloping better green composite materials for various industrial\napplications.",
    "categories": [
      "cs.NE",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07213v1",
    "published_date": "2024-02-20 16:55:57 UTC",
    "updated_date": "2024-02-20 16:55:57 UTC"
  },
  {
    "arxiv_id": "2402.13126v1",
    "title": "VGMShield: Mitigating Misuse of Video Generative Models",
    "authors": [
      "Yan Pang",
      "Yang Zhang",
      "Tianhao Wang"
    ],
    "abstract": "With the rapid advancement in video generation, people can conveniently\nutilize video generation models to create videos tailored to their specific\ndesires. Nevertheless, there are also growing concerns about their potential\nmisuse in creating and disseminating false information.\n  In this work, we introduce VGMShield: a set of three straightforward but\npioneering mitigations through the lifecycle of fake video generation. We start\nfrom \\textit{fake video detection} trying to understand whether there is\nuniqueness in generated videos and whether we can differentiate them from real\nvideos; then, we investigate the \\textit{tracing} problem, which maps a fake\nvideo back to a model that generates it. Towards these, we propose to leverage\npre-trained models that focus on {\\it spatial-temporal dynamics} as the\nbackbone to identify inconsistencies in videos. Through experiments on seven\nstate-of-the-art open-source models, we demonstrate that current models still\ncannot perfectly handle spatial-temporal relationships, and thus, we can\naccomplish detection and tracing with nearly perfect accuracy.\n  Furthermore, anticipating future generative model improvements, we propose a\n{\\it prevention} method that adds invisible perturbations to images to make the\ngenerated videos look unreal. Together with fake video detection and tracing,\nour multi-faceted set of solutions can effectively mitigate misuse of video\ngenerative models.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CR",
    "comment": "17 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13126v1",
    "published_date": "2024-02-20 16:39:23 UTC",
    "updated_date": "2024-02-20 16:39:23 UTC"
  },
  {
    "arxiv_id": "2402.13125v2",
    "title": "TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning",
    "authors": [
      "Xiang Li",
      "Yunshi Lan",
      "Chao Yang"
    ],
    "abstract": "Recently, numerous new benchmarks have been established to evaluate the\nperformance of large language models (LLMs) via either computing a holistic\nscore or employing another LLM as a judge. However, these approaches suffer\nfrom data leakage due to the open access of the benchmark and inflexible\nevaluation process. To address this issue, we introduce $\\textbf{TreeEval}$, a\nbenchmark-free evaluation method for LLMs that let a high-performance LLM host\nan irreproducible evaluation session and essentially avoids the data leakage.\nMoreover, this LLM performs as an examiner to raise up a series of questions\nunder a topic with a tree planing strategy, which considers the current\nevaluation status to decide the next question generation and ensures the\ncompleteness and efficiency of the evaluation process. We evaluate $6$ models\nof different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately\nachieved the highest correlation coefficient with AlpacaEval2.0 using only\naround $45$ questions. We also conduct more analysis to show the robustness and\nreliability of TreeEval. Our code can be accessed via the provided\nhttps://github.com/Ashura5/TreeEval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13125v2",
    "published_date": "2024-02-20 16:38:33 UTC",
    "updated_date": "2024-12-13 10:48:13 UTC"
  },
  {
    "arxiv_id": "2402.13114v1",
    "title": "BuffGraph: Enhancing Class-Imbalanced Node Classification via Buffer Nodes",
    "authors": [
      "Qian Wang",
      "Zemin Liu",
      "Zhen Zhang",
      "Bingsheng He"
    ],
    "abstract": "Class imbalance in graph-structured data, where minor classes are\nsignificantly underrepresented, poses a critical challenge for Graph Neural\nNetworks (GNNs). To address this challenge, existing studies generally generate\nnew minority nodes and edges connecting new nodes to the original graph to make\nclasses balanced. However, they do not solve the problem that majority classes\nstill propagate information to minority nodes by edges in the original graph\nwhich introduces bias towards majority classes. To address this, we introduce\nBuffGraph, which inserts buffer nodes into the graph, modulating the impact of\nmajority classes to improve minor class representation. Our extensive\nexperiments across diverse real-world datasets empirically demonstrate that\nBuffGraph outperforms existing baseline methods in class-imbalanced node\nclassification in both natural settings and imbalanced settings. Code is\navailable at https://anonymous.4open.science/r/BuffGraph-730A.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13114v1",
    "published_date": "2024-02-20 16:11:59 UTC",
    "updated_date": "2024-02-20 16:11:59 UTC"
  },
  {
    "arxiv_id": "2402.13109v2",
    "title": "CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models",
    "authors": [
      "Yizhi LI",
      "Ge Zhang",
      "Xingwei Qu",
      "Jiali Li",
      "Zhaoqun Li",
      "Zekun Wang",
      "Hao Li",
      "Ruibin Yuan",
      "Yinghao Ma",
      "Kai Zhang",
      "Wangchunshu Zhou",
      "Yiming Liang",
      "Lei Zhang",
      "Lei Ma",
      "Jiajun Zhang",
      "Zuowen Li",
      "Stephen W. Huang",
      "Chenghua Lin",
      "Jie Fu"
    ],
    "abstract": "The advancement of large language models (LLMs) has enhanced the ability to\ngeneralize across a wide range of unseen natural language processing (NLP)\ntasks through instruction-following. Yet, their effectiveness often diminishes\nin low-resource languages like Chinese, exacerbated by biased evaluations from\ndata leakage, casting doubt on their true generalizability to new linguistic\nterritories. In response, we introduce the Chinese Instruction-Following\nBenchmark (CIF-Bench), designed to evaluate the zero-shot generalizability of\nLLMs to the Chinese language. CIF-Bench comprises 150 tasks and 15,000\ninput-output pairs, developed by native speakers to test complex reasoning and\nChinese cultural nuances across 20 categories. To mitigate data contamination,\nwe release only half of the dataset publicly, with the remainder kept private,\nand introduce diversified instructions to minimize score variance, totaling\n45,000 data instances. Our evaluation of 28 selected LLMs reveals a noticeable\nperformance gap, with the best model scoring only 52.9%, highlighting the\nlimitations of LLMs in less familiar language and task contexts. This work not\nonly uncovers the current limitations of LLMs in handling Chinese language\ntasks but also sets a new standard for future LLM generalizability research,\npushing towards the development of more adaptable, culturally informed, and\nlinguistically diverse models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Camera-ready version for ACL 2024. Project page at\n  https://yizhilll.github.io/CIF-Bench/",
    "pdf_url": "http://arxiv.org/pdf/2402.13109v2",
    "published_date": "2024-02-20 16:02:12 UTC",
    "updated_date": "2024-06-04 14:26:30 UTC"
  },
  {
    "arxiv_id": "2402.13098v1",
    "title": "ELAD: Explanation-Guided Large Language Models Active Distillation",
    "authors": [
      "Yifei Zhang",
      "Bo Pan",
      "Chen Ling",
      "Yuntong Hu",
      "Liang Zhao"
    ],
    "abstract": "The deployment and application of Large Language Models (LLMs) is hindered by\ntheir memory inefficiency, computational demands, and the high costs of API\ninferences. Traditional distillation methods, which transfer the capabilities\nof LLMs to smaller models, often fail to determine whether the knowledge has\nbeen sufficiently transferred, potentially resulting in high costs or\nincomplete distillation. In this paper, we propose an Explanation-Guided LLMs\nActive Distillation (ELAD) framework that employs an active learning strategy\nto optimize the balance between annotation costs and model performance. To\nimprove efficient sample selection, we introduce an explanation-guided sample\nselection method that identifies samples challenging its reasoning by\nexploiting uncertainties in explanation steps. Additionally, we present a\ncustomized LLM-annotated explanation revision technique where the teacher model\ndetects and corrects flaws in the student model's reasoning. Our experiments\nacross various reasoning datasets demonstrate that our framework significantly\nenhances the efficiency of LLM knowledge distillation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13098v1",
    "published_date": "2024-02-20 15:47:59 UTC",
    "updated_date": "2024-02-20 15:47:59 UTC"
  },
  {
    "arxiv_id": "2402.13093v2",
    "title": "Event-level Knowledge Editing",
    "authors": [
      "Hao Peng",
      "Xiaozhi Wang",
      "Chunyang Li",
      "Kaisheng Zeng",
      "Jiangshan Duo",
      "Yixin Cao",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Knowledge editing aims at updating knowledge of large language models (LLMs)\nto prevent them from becoming outdated. Existing work edits LLMs at the level\nof factual knowledge triplets. However, natural knowledge updates in the real\nworld come from the occurrences of new events rather than direct changes in\nfactual triplets. In this paper, we propose a new task setting: event-level\nknowledge editing, which directly edits new events into LLMs and improves over\nconventional triplet-level editing on (1) Efficiency. A single event edit leads\nto updates in multiple entailed knowledge triplets. (2) Completeness. Beyond\nupdating factual knowledge, event-level editing also requires considering the\nevent influences and updating LLMs' knowledge about future trends. We construct\na high-quality event-level editing benchmark ELKEN, consisting of 1,515 event\nedits, 6,449 questions about factual knowledge, and 10,150 questions about\nfuture tendencies. We systematically evaluate the performance of various\nknowledge editing methods and LLMs on this benchmark. We find that ELKEN poses\nsignificant challenges to existing knowledge editing approaches. Our codes and\ndataset are publicly released to facilitate further research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13093v2",
    "published_date": "2024-02-20 15:36:41 UTC",
    "updated_date": "2024-04-21 06:13:45 UTC"
  },
  {
    "arxiv_id": "2402.13089v1",
    "title": "Towards an empirical understanding of MoE design choices",
    "authors": [
      "Dongyang Fan",
      "Bettina Messmer",
      "Martin Jaggi"
    ],
    "abstract": "In this study, we systematically evaluate the impact of common design choices\nin Mixture of Experts (MoEs) on validation performance, uncovering distinct\ninfluences at token and sequence levels. We also present empirical evidence\nshowing comparable performance between a learned router and a frozen, randomly\ninitialized router, suggesting that learned routing may not be essential. Our\nstudy further reveals that Sequence-level routing can result in topic-specific\nweak expert specialization, in contrast to syntax specialization observed with\nToken-level routing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13089v1",
    "published_date": "2024-02-20 15:31:44 UTC",
    "updated_date": "2024-02-20 15:31:44 UTC"
  },
  {
    "arxiv_id": "2402.13077v1",
    "title": "Mechanistic Neural Networks for Scientific Machine Learning",
    "authors": [
      "Adeel Pervez",
      "Francesco Locatello",
      "Efstratios Gavves"
    ],
    "abstract": "This paper presents Mechanistic Neural Networks, a neural network design for\nmachine learning applications in the sciences. It incorporates a new\nMechanistic Block in standard architectures to explicitly learn governing\ndifferential equations as representations, revealing the underlying dynamics of\ndata and enhancing interpretability and efficiency in data modeling. Central to\nour approach is a novel Relaxed Linear Programming Solver (NeuRLP) inspired by\na technique that reduces solving linear ODEs to solving linear programs. This\nintegrates well with neural networks and surpasses the limitations of\ntraditional ODE solvers enabling scalable GPU parallel processing. Overall,\nMechanistic Neural Networks demonstrate their versatility for scientific\nmachine learning applications, adeptly managing tasks from equation discovery\nto dynamic systems modeling. We prove their comprehensive capabilities in\nanalyzing and interpreting complex scientific data across various applications,\nshowing significant performance against specialized state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13077v1",
    "published_date": "2024-02-20 15:23:24 UTC",
    "updated_date": "2024-02-20 15:23:24 UTC"
  },
  {
    "arxiv_id": "2402.13304v1",
    "title": "Harmful algal bloom forecasting. A comparison between stream and batch learning",
    "authors": [
      "Andres Molares-Ulloa",
      "Elisabet Rocruz",
      "Daniel Rivero",
      "Xosé A. Padin",
      "Rita Nolasco",
      "Jesús Dubert",
      "Enrique Fernandez-Blanco"
    ],
    "abstract": "Diarrhetic Shellfish Poisoning (DSP) is a global health threat arising from\nshellfish contaminated with toxins produced by dinoflagellates. The condition,\nwith its widespread incidence, high morbidity rate, and persistent shellfish\ntoxicity, poses risks to public health and the shellfish industry. High biomass\nof toxin-producing algae such as DSP are known as Harmful Algal Blooms (HABs).\nMonitoring and forecasting systems are crucial for mitigating HABs impact.\nPredicting harmful algal blooms involves a time-series-based problem with a\nstrong historical seasonal component, however, recent anomalies due to changes\nin meteorological and oceanographic events have been observed. Stream Learning\nstands out as one of the most promising approaches for addressing\ntime-series-based problems with concept drifts. However, its efficacy in\npredicting HABs remains unproven and needs to be tested in comparison with\nBatch Learning. Historical data availability is a critical point in developing\npredictive systems. In oceanography, the available data collection can have\nsome constrains and limitations, which has led to exploring new tools to obtain\nmore exhaustive time series. In this study, a machine learning workflow for\npredicting the number of cells of a toxic dinoflagellate, Dinophysis acuminata,\nwas developed with several key advancements. Seven machine learning algorithms\nwere compared within two learning paradigms. Notably, the output data from\nCROCO, the ocean hydrodynamic model, was employed as the primary dataset,\npalliating the limitation of time-continuous historical data. This study\nhighlights the value of models interpretability, fair models comparison\nmethodology, and the incorporation of Stream Learning models. The model DoME,\nwith an average R2 of 0.77 in the 3-day-ahead prediction, emerged as the most\neffective and interpretable predictor, outperforming the other algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13304v1",
    "published_date": "2024-02-20 15:01:11 UTC",
    "updated_date": "2024-02-20 15:01:11 UTC"
  },
  {
    "arxiv_id": "2402.13058v2",
    "title": "Random Graph Set and Evidence Pattern Reasoning Model",
    "authors": [
      "Tianxiang Zhan",
      "Zhen Li",
      "Yong Deng"
    ],
    "abstract": "Evidence theory is widely used in decision-making and reasoning systems. In\nprevious research, Transferable Belief Model (TBM) is a commonly used\nevidential decision making model, but TBM is a non-preference model. In order\nto better fit the decision making goals, the Evidence Pattern Reasoning Model\n(EPRM) is proposed. By defining pattern operators and decision making\noperators, corresponding preferences can be set for different tasks. Random\nPermutation Set (RPS) expands order information for evidence theory. It is hard\nfor RPS to characterize the complex relationship between samples such as\ncycling, paralleling relationships. Therefore, Random Graph Set (RGS) were\nproposed to model complex relationships and represent more event types. In\norder to illustrate the significance of RGS and EPRM, an experiment of aircraft\nvelocity ranking was designed and 10,000 cases were simulated. The\nimplementation of EPRM called Conflict Resolution Decision optimized 18.17\\% of\nthe cases compared to Mean Velocity Decision, effectively improving the\naircraft velocity ranking. EPRM provides a unified solution for evidence-based\ndecision making.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13058v2",
    "published_date": "2024-02-20 14:52:52 UTC",
    "updated_date": "2024-03-09 08:43:20 UTC"
  },
  {
    "arxiv_id": "2402.13055v2",
    "title": "Identifying Semantic Induction Heads to Understand In-Context Learning",
    "authors": [
      "Jie Ren",
      "Qipeng Guo",
      "Hang Yan",
      "Dongrui Liu",
      "Quanshi Zhang",
      "Xipeng Qiu",
      "Dahua Lin"
    ],
    "abstract": "Although large language models (LLMs) have demonstrated remarkable\nperformance, the lack of transparency in their inference logic raises concerns\nabout their trustworthiness. To gain a better understanding of LLMs, we conduct\na detailed analysis of the operations of attention heads and aim to better\nunderstand the in-context learning of LLMs. Specifically, we investigate\nwhether attention heads encode two types of relationships between tokens\npresent in natural languages: the syntactic dependency parsed from sentences\nand the relation within knowledge graphs. We find that certain attention heads\nexhibit a pattern where, when attending to head tokens, they recall tail tokens\nand increase the output logits of those tail tokens. More crucially, the\nformulation of such semantic induction heads has a close correlation with the\nemergence of the in-context learning ability of language models. The study of\nsemantic attention heads advances our understanding of the intricate operations\nof attention heads in transformers, and further provides new insights into the\nin-context learning of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13055v2",
    "published_date": "2024-02-20 14:43:39 UTC",
    "updated_date": "2024-07-25 08:07:39 UTC"
  },
  {
    "arxiv_id": "2402.13040v1",
    "title": "Text-Guided Molecule Generation with Diffusion Language Model",
    "authors": [
      "Haisong Gong",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "abstract": "Text-guided molecule generation is a task where molecules are generated to\nmatch specific textual descriptions. Recently, most existing SMILES-based\nmolecule generation methods rely on an autoregressive architecture. In this\nwork, we propose the Text-Guided Molecule Generation with Diffusion Language\nModel (TGM-DLM), a novel approach that leverages diffusion models to address\nthe limitations of autoregressive methods. TGM-DLM updates token embeddings\nwithin the SMILES string collectively and iteratively, using a two-phase\ndiffusion generation process. The first phase optimizes embeddings from random\nnoise, guided by the text description, while the second phase corrects invalid\nSMILES strings to form valid molecular representations. We demonstrate that\nTGM-DLM outperforms MolT5-Base, an autoregressive model, without the need for\nadditional data resources. Our findings underscore the remarkable effectiveness\nof TGM-DLM in generating coherent and precise molecules with specific\nproperties, opening new avenues in drug discovery and related scientific\ndomains. Code will be released at: https://github.com/Deno-V/tgm-dlm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 38th Association for the Advancement of Artificial\n  Intelligence, AAAI",
    "pdf_url": "http://arxiv.org/pdf/2402.13040v1",
    "published_date": "2024-02-20 14:29:02 UTC",
    "updated_date": "2024-02-20 14:29:02 UTC"
  },
  {
    "arxiv_id": "2402.13037v2",
    "title": "Align Your Intents: Offline Imitation Learning via Optimal Transport",
    "authors": [
      "Maksim Bobrin",
      "Nazar Buzun",
      "Dmitrii Krylov",
      "Dmitry V. Dylov"
    ],
    "abstract": "Offline Reinforcement Learning (RL) addresses the problem of sequential\ndecision-making by learning optimal policy through pre-collected data, without\ninteracting with the environment. As yet, it has remained somewhat impractical,\nbecause one rarely knows the reward explicitly and it is hard to distill it\nretrospectively. Here, we show that an imitating agent can still learn the\ndesired behavior merely from observing the expert, despite the absence of\nexplicit rewards or action labels. In our method, AILOT (Aligned Imitation\nLearning via Optimal Transport), we involve special representation of states in\na form of intents that incorporate pairwise spatial distances within the data.\nGiven such representations, we define intrinsic reward function via optimal\ntransport distance between the expert's and the agent's trajectories. We report\nthat AILOT outperforms state-of-the art offline imitation learning algorithms\non D4RL benchmarks and improves the performance of other offline RL algorithms\nby dense reward relabelling in the sparse-reward tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13037v2",
    "published_date": "2024-02-20 14:24:00 UTC",
    "updated_date": "2024-10-04 07:24:42 UTC"
  },
  {
    "arxiv_id": "2402.13035v3",
    "title": "Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models",
    "authors": [
      "Che Zhang",
      "Zhenyang Xiao",
      "Chengcheng Han",
      "Yixin Lian",
      "Yuejian Fang"
    ],
    "abstract": "Self-correction has achieved impressive results in enhancing the style and\nsecurity of the generated output from large language models (LLMs). However,\nrecent studies suggest that self-correction might be limited or even\ncounterproductive in reasoning tasks due to LLMs' difficulties in identifying\nlogical mistakes.\n  In this paper, we aim to enhance the self-checking capabilities of LLMs by\nconstructing training data for checking tasks. Specifically, we apply the Chain\nof Thought (CoT) methodology to self-checking tasks, utilizing fine-grained\nstep-level analyses and explanations to assess the correctness of reasoning\npaths. We propose a specialized checking format called \"Step CoT Check\".\nFollowing this format, we construct a checking-correction dataset that includes\ndetailed step-by-step analysis and checking. Then we fine-tune LLMs to enhance\ntheir error detection and correction abilities.\n  Our experiments demonstrate that fine-tuning with the \"Step CoT Check\" format\nsignificantly improves the self-checking and self-correction abilities of LLMs\nacross multiple benchmarks. This approach outperforms other formats, especially\nin locating the incorrect position, with greater benefits observed in larger\nmodels.\n  For reproducibility, all the datasets and code are provided in\nhttps://github.com/bammt/Learn-to-check.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13035v3",
    "published_date": "2024-02-20 14:23:23 UTC",
    "updated_date": "2024-06-17 15:24:29 UTC"
  },
  {
    "arxiv_id": "2402.13028v1",
    "title": "Heterogeneous Graph Reasoning for Fact Checking over Texts and Tables",
    "authors": [
      "Haisong Gong",
      "Weizhi Xu",
      "Shu wu",
      "Qiang Liu",
      "Liang Wang"
    ],
    "abstract": "Fact checking aims to predict claim veracity by reasoning over multiple\nevidence pieces. It usually involves evidence retrieval and veracity reasoning.\nIn this paper, we focus on the latter, reasoning over unstructured text and\nstructured table information. Previous works have primarily relied on\nfine-tuning pretrained language models or training homogeneous-graph-based\nmodels. Despite their effectiveness, we argue that they fail to explore the\nrich semantic information underlying the evidence with different structures. To\naddress this, we propose a novel word-level Heterogeneous-graph-based model for\nFact Checking over unstructured and structured information, namely HeterFC. Our\napproach leverages a heterogeneous evidence graph, with words as nodes and\nthoughtfully designed edges representing different evidence properties. We\nperform information propagation via a relational graph neural network,\nfacilitating interactions between claims and evidence. An attention-based\nmethod is utilized to integrate information, combined with a language model for\ngenerating predictions. We introduce a multitask loss function to account for\npotential inaccuracies in evidence retrieval. Comprehensive experiments on the\nlarge fact checking dataset FEVEROUS demonstrate the effectiveness of HeterFC.\nCode will be released at: https://github.com/Deno-V/HeterFC.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by 38th Association for the Advancement of Artificial\n  Intelligence, AAAI",
    "pdf_url": "http://arxiv.org/pdf/2402.13028v1",
    "published_date": "2024-02-20 14:10:40 UTC",
    "updated_date": "2024-02-20 14:10:40 UTC"
  },
  {
    "arxiv_id": "2402.13025v1",
    "title": "CFEVER: A Chinese Fact Extraction and VERification Dataset",
    "authors": [
      "Ying-Jia Lin",
      "Chun-Yi Lin",
      "Chia-Jen Yeh",
      "Yi-Ting Li",
      "Yun-Yu Hu",
      "Chih-Hao Hsu",
      "Mei-Feng Lee",
      "Hung-Yu Kao"
    ],
    "abstract": "We present CFEVER, a Chinese dataset designed for Fact Extraction and\nVERification. CFEVER comprises 30,012 manually created claims based on content\nin Chinese Wikipedia. Each claim in CFEVER is labeled as \"Supports\", \"Refutes\",\nor \"Not Enough Info\" to depict its degree of factualness. Similar to the FEVER\ndataset, claims in the \"Supports\" and \"Refutes\" categories are also annotated\nwith corresponding evidence sentences sourced from single or multiple pages in\nChinese Wikipedia. Our labeled dataset holds a Fleiss' kappa value of 0.7934\nfor five-way inter-annotator agreement. In addition, through the experiments\nwith the state-of-the-art approaches developed on the FEVER dataset and a\nsimple baseline for CFEVER, we demonstrate that our dataset is a new rigorous\nbenchmark for factual extraction and verification, which can be further used\nfor developing automated systems to alleviate human fact-checking efforts.\nCFEVER is available at https://ikmlab.github.io/CFEVER.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI-24",
    "pdf_url": "http://arxiv.org/pdf/2402.13025v1",
    "published_date": "2024-02-20 14:08:24 UTC",
    "updated_date": "2024-02-20 14:08:24 UTC"
  },
  {
    "arxiv_id": "2402.13019v1",
    "title": "Improving Neural-based Classification with Logical Background Knowledge",
    "authors": [
      "Arthur Ledaguenel",
      "Céline Hudelot",
      "Mostepha Khouadjia"
    ],
    "abstract": "Neurosymbolic AI is a growing field of research aiming to combine neural\nnetworks learning capabilities with the reasoning abilities of symbolic\nsystems. This hybridization can take many shapes. In this paper, we propose a\nnew formalism for supervised multi-label classification with propositional\nbackground knowledge. We introduce a new neurosymbolic technique called\nsemantic conditioning at inference, which only constrains the system during\ninference while leaving the training unaffected. We discuss its theoritical and\npractical advantages over two other popular neurosymbolic techniques: semantic\nconditioning and semantic regularization. We develop a new multi-scale\nmethodology to evaluate how the benefits of a neurosymbolic technique evolve\nwith the scale of the network. We then evaluate experimentally and compare the\nbenefits of all three techniques across model scales on several datasets. Our\nresults demonstrate that semantic conditioning at inference can be used to\nbuild more accurate neural-based systems with fewer resources while\nguaranteeing the semantic consistency of outputs.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 3 figures, submitted to IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13019v1",
    "published_date": "2024-02-20 14:01:26 UTC",
    "updated_date": "2024-02-20 14:01:26 UTC"
  },
  {
    "arxiv_id": "2403.15405v3",
    "title": "Predicting Parkinson's disease trajectory using clinical and functional MRI features: a reproduction and replication study",
    "authors": [
      "Elodie Germani",
      "Nikhil Baghwat",
      "Mathieu Dugré",
      "Rémi Gau",
      "Albert Montillo",
      "Kevin Nguyen",
      "Andrzej Sokolowski",
      "Madeleine Sharp",
      "Jean-Baptiste Poline",
      "Tristan Glatard"
    ],
    "abstract": "Parkinson's disease (PD) is a common neurodegenerative disorder with a poorly\nunderstood physiopathology and no established biomarkers for the diagnosis of\nearly stages and for prediction of disease progression. Several neuroimaging\nbiomarkers have been studied recently, but these are susceptible to several\nsources of variability related for instance to cohort selection or image\nanalysis. In this context, an evaluation of the robustness of such biomarkers\nto variations in the data processing workflow is essential. This study is part\nof a larger project investigating the replicability of potential neuroimaging\nbiomarkers of PD. Here, we attempt to reproduce (re-implementing the\nexperiments with the same data, same method) and replicate (different data\nand/or method) the models described in [1] to predict individual's PD current\nstate and progression using demographic, clinical and neuroimaging features\n(fALFF and ReHo extracted from resting-state fMRI). We use the Parkinson's\nProgression Markers Initiative dataset (PPMI, ppmi-info.org), as in [1] and aim\nto reproduce the original cohort, imaging features and machine learning models\nas closely as possible using the information available in the paper and the\ncode. We also investigated methodological variations in cohort selection,\nfeature extraction pipelines and sets of input features. Different criteria\nwere used to evaluate the reproduction and compare the reproduced results with\nthe original ones. Notably, we obtained significantly better than chance\nperformance using the analysis pipeline closest to that in the original study\n(R2 \\&gt; 0), which is consistent with its findings. Moreover, using derived\ndata provided by the authors of the original study, we were able to make an\nexact reproduction and managed to obtain results that were close to the\noriginal ones. The challenges encountered while reproducing and replicating the\noriginal work are likely explained by the complexity of neuroimaging studies,\nin particular in clinical settings. We provide recommendations to further\nfacilitate the reproducibility of such studies in the future.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "q-bio.NC",
    "comment": "PLoS ONE, In press",
    "pdf_url": "http://arxiv.org/pdf/2403.15405v3",
    "published_date": "2024-02-20 13:42:50 UTC",
    "updated_date": "2025-02-12 10:33:58 UTC"
  },
  {
    "arxiv_id": "2402.13301v2",
    "title": "Structure-informed Positional Encoding for Music Generation",
    "authors": [
      "Manvi Agarwal",
      "Changhong Wang",
      "Gaël Richard"
    ],
    "abstract": "Music generated by deep learning methods often suffers from a lack of\ncoherence and long-term organization. Yet, multi-scale hierarchical structure\nis a distinctive feature of music signals. To leverage this information, we\npropose a structure-informed positional encoding framework for music generation\nwith Transformers. We design three variants in terms of absolute, relative and\nnon-stationary positional information. We comprehensively test them on two\nsymbolic music generation tasks: next-timestep prediction and accompaniment\ngeneration. As a comparison, we choose multiple baselines from the literature\nand demonstrate the merits of our methods using several musically-motivated\nevaluation metrics. In particular, our methods improve the melodic and\nstructural consistency of the generated pieces.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13301v2",
    "published_date": "2024-02-20 13:41:35 UTC",
    "updated_date": "2024-02-28 12:37:34 UTC"
  },
  {
    "arxiv_id": "2402.12993v1",
    "title": "An Autonomous Large Language Model Agent for Chemical Literature Data Mining",
    "authors": [
      "Kexin Chen",
      "Hanqun Cao",
      "Junyou Li",
      "Yuyang Du",
      "Menghao Guo",
      "Xin Zeng",
      "Lanqing Li",
      "Jiezhong Qiu",
      "Pheng Ann Heng",
      "Guangyong Chen"
    ],
    "abstract": "Chemical synthesis, which is crucial for advancing material synthesis and\ndrug discovery, impacts various sectors including environmental science and\nhealthcare. The rise of technology in chemistry has generated extensive\nchemical data, challenging researchers to discern patterns and refine synthesis\nprocesses. Artificial intelligence (AI) helps by analyzing data to optimize\nsynthesis and increase yields. However, AI faces challenges in processing\nliterature data due to the unstructured format and diverse writing style of\nchemical literature. To overcome these difficulties, we introduce an end-to-end\nAI agent framework capable of high-fidelity extraction from extensive chemical\nliterature. This AI agent employs large language models (LLMs) for prompt\ngeneration and iterative optimization. It functions as a chemistry assistant,\nautomating data collection and analysis, thereby saving manpower and enhancing\nperformance. Our framework's efficacy is evaluated using accuracy, recall, and\nF1 score of reaction condition data, and we compared our method with human\nexperts in terms of content correctness and time efficiency. The proposed\napproach marks a significant advancement in automating chemical literature\nextraction and demonstrates the potential for AI to revolutionize data\nmanagement and utilization in chemistry.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12993v1",
    "published_date": "2024-02-20 13:21:46 UTC",
    "updated_date": "2024-02-20 13:21:46 UTC"
  },
  {
    "arxiv_id": "2402.12991v2",
    "title": "TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification",
    "authors": [
      "Martin Gubri",
      "Dennis Ulmer",
      "Hwaran Lee",
      "Sangdoo Yun",
      "Seong Joon Oh"
    ],
    "abstract": "Large Language Model (LLM) services and models often come with legal rules on\nwho can use them and how they must use them. Assessing the compliance of the\nreleased LLMs is crucial, as these rules protect the interests of the LLM\ncontributor and prevent misuse. In this context, we describe the novel\nfingerprinting problem of Black-box Identity Verification (BBIV). The goal is\nto determine whether a third-party application uses a certain LLM through its\nchat function. We propose a method called Targeted Random Adversarial Prompt\n(TRAP) that identifies the specific LLM in use. We repurpose adversarial\nsuffixes, originally proposed for jailbreaking, to get a pre-defined answer\nfrom the target LLM, while other models give random answers. TRAP detects the\ntarget LLMs with over 95% true positive rate at under 0.2% false positive rate\neven after a single interaction. TRAP remains effective even if the LLM has\nminor changes that do not significantly alter the original function.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ACL 2024 (findings)",
    "pdf_url": "http://arxiv.org/pdf/2402.12991v2",
    "published_date": "2024-02-20 13:20:39 UTC",
    "updated_date": "2024-06-06 17:46:48 UTC"
  },
  {
    "arxiv_id": "2402.12984v1",
    "title": "Can GNN be Good Adapter for LLMs?",
    "authors": [
      "Xuanwen Huang",
      "Kaiqiao Han",
      "Yang Yang",
      "Dezheng Bao",
      "Quanjin Tao",
      "Ziwei Chai",
      "Qi Zhu"
    ],
    "abstract": "Recently, large language models (LLMs) have demonstrated superior\ncapabilities in understanding and zero-shot learning on textual data, promising\nsignificant advances for many text-related domains. In the graph domain,\nvarious real-world scenarios also involve textual data, where tasks and node\nfeatures can be described by text. These text-attributed graphs (TAGs) have\nbroad applications in social media, recommendation systems, etc. Thus, this\npaper explores how to utilize LLMs to model TAGs. Previous methods for TAG\nmodeling are based on million-scale LMs. When scaled up to billion-scale LLMs,\nthey face huge challenges in computational costs. Additionally, they also\nignore the zero-shot inference capabilities of LLMs. Therefore, we propose\nGraphAdapter, which uses a graph neural network (GNN) as an efficient adapter\nin collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN\nadapter introduces only a few trainable parameters and can be trained with low\ncomputation costs. The entire framework is trained using auto-regression on\nnode text (next token prediction). Once trained, GraphAdapter can be seamlessly\nfine-tuned with task-specific prompts for various downstream tasks. Through\nextensive experiments across multiple real-world TAGs, GraphAdapter based on\nLlama 2 gains an average improvement of approximately 5\\% in terms of node\nclassification. Furthermore, GraphAdapter can also adapt to other language\nmodels, including RoBERTa, GPT-2. The promising results demonstrate that GNNs\ncan serve as effective adapters for LLMs in TAG modeling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by WWW'24",
    "pdf_url": "http://arxiv.org/pdf/2402.12984v1",
    "published_date": "2024-02-20 13:13:13 UTC",
    "updated_date": "2024-02-20 13:13:13 UTC"
  },
  {
    "arxiv_id": "2402.14856v2",
    "title": "Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning",
    "authors": [
      "Philipp Mondorf",
      "Barbara Plank"
    ],
    "abstract": "Deductive reasoning plays a pivotal role in the formulation of sound and\ncohesive arguments. It allows individuals to draw conclusions that logically\nfollow, given the truth value of the information provided. Recent progress in\nthe domain of large language models (LLMs) has showcased their capability in\nexecuting deductive reasoning tasks. Nonetheless, a significant portion of\nresearch primarily assesses the accuracy of LLMs in solving such tasks, often\noverlooking a deeper analysis of their reasoning behavior. In this study, we\ndraw upon principles from cognitive psychology to examine inferential\nstrategies employed by LLMs, through a detailed evaluation of their responses\nto propositional logic problems. Our findings indicate that LLMs display\nreasoning patterns akin to those observed in humans, including strategies like\n$\\textit{supposition following}$ or $\\textit{chain construction}$. Moreover,\nour research demonstrates that the architecture and scale of the model\nsignificantly affect its preferred method of reasoning, with more advanced\nmodels tending to adopt strategies more frequently than less sophisticated\nones. Importantly, we assert that a model's accuracy, that is the correctness\nof its final conclusion, does not necessarily reflect the validity of its\nreasoning process. This distinction underscores the necessity for more nuanced\nevaluation procedures in the field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 main, 31 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14856v2",
    "published_date": "2024-02-20 12:58:14 UTC",
    "updated_date": "2024-06-03 13:53:01 UTC"
  },
  {
    "arxiv_id": "2402.12976v2",
    "title": "The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis",
    "authors": [
      "Miaoran Zhang",
      "Vagrant Gautam",
      "Mingyang Wang",
      "Jesujoba O. Alabi",
      "Xiaoyu Shen",
      "Dietrich Klakow",
      "Marius Mosbach"
    ],
    "abstract": "In-context learning is a popular inference strategy where large language\nmodels solve a task using only a few labeled demonstrations without needing any\nparameter updates. Although there have been extensive studies on English\nin-context learning, multilingual in-context learning remains under-explored,\nand we lack an in-depth understanding of the role of demonstrations in this\ncontext. To address this gap, we conduct a multidimensional analysis of\nmultilingual in-context learning, experimenting with 5 models from different\nmodel families, 9 datasets covering classification and generation tasks, and 56\ntypologically diverse languages. Our results reveal that the effectiveness of\ndemonstrations varies significantly across models, tasks, and languages. We\nalso find that strong instruction-following models including Llama 2-Chat,\nGPT-3.5, and GPT-4 are largely insensitive to the quality of demonstrations.\nInstead, a carefully crafted template often eliminates the benefits of\ndemonstrations for some tasks and languages altogether. These findings show\nthat the importance of demonstrations might be overestimated. Our work\nhighlights the need for granular evaluation across multiple axes towards a\nbetter understanding of in-context learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 findings",
    "pdf_url": "http://arxiv.org/pdf/2402.12976v2",
    "published_date": "2024-02-20 12:53:31 UTC",
    "updated_date": "2024-06-07 13:44:07 UTC"
  },
  {
    "arxiv_id": "2402.12969v1",
    "title": "GlórIA -- A Generative and Open Large Language Model for Portuguese",
    "authors": [
      "Ricardo Lopes",
      "João Magalhães",
      "David Semedo"
    ],
    "abstract": "Significant strides have been made in natural language tasks, largely\nattributed to the emergence of powerful large language models (LLMs). These\nmodels, pre-trained on extensive and diverse corpora, have become increasingly\ncapable of comprehending the intricacies of language. Despite the abundance of\nLLMs for many high-resource languages, the availability of such models remains\nlimited for European Portuguese. We introduce Gl\\'orIA, a robust European\nPortuguese decoder LLM. To pre-train Gl\\'orIA, we assembled a comprehensive\nPT-PT text corpus comprising 35 billion tokens from various sources. We present\nour pre-training methodology, followed by an assessment of the model's\neffectiveness on multiple downstream tasks. Additionally, to evaluate our\nmodels' language modeling capabilities, we introduce CALAME-PT (Context-Aware\nLAnguage Modeling Evaluation for Portuguese), the first Portuguese zero-shot\nlanguage-modeling benchmark. Evaluation shows that Gl\\'orIA significantly\noutperforms existing open PT decoder models in language modeling and that it\ncan generate sound, knowledge-rich, and coherent PT-PT text. The model also\nexhibits strong potential for various downstream tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication at PROPOR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12969v1",
    "published_date": "2024-02-20 12:36:40 UTC",
    "updated_date": "2024-02-20 12:36:40 UTC"
  },
  {
    "arxiv_id": "2402.12954v2",
    "title": "Conditional Logical Message Passing Transformer for Complex Query Answering",
    "authors": [
      "Chongzhi Zhang",
      "Zhiping Peng",
      "Junhao Zheng",
      "Qianli Ma"
    ],
    "abstract": "Complex Query Answering (CQA) over Knowledge Graphs (KGs) is a challenging\ntask. Given that KGs are usually incomplete, neural models are proposed to\nsolve CQA by performing multi-hop logical reasoning. However, most of them\ncannot perform well on both one-hop and multi-hop queries simultaneously.\nRecent work proposes a logical message passing mechanism based on the\npre-trained neural link predictors. While effective on both one-hop and\nmulti-hop queries, it ignores the difference between the constant and variable\nnodes in a query graph. In addition, during the node embedding update stage,\nthis mechanism cannot dynamically measure the importance of different messages,\nand whether it can capture the implicit logical dependencies related to a node\nand received messages remains unclear. In this paper, we propose Conditional\nLogical Message Passing Transformer (CLMPT), which considers the difference\nbetween constants and variables in the case of using pre-trained neural link\npredictors and performs message passing conditionally on the node type. We\nempirically verified that this approach can reduce computational costs without\naffecting performance. Furthermore, CLMPT uses the transformer to aggregate\nreceived messages and update the corresponding node embedding. Through the\nself-attention mechanism, CLMPT can assign adaptive weights to elements in an\ninput set consisting of received messages and the corresponding node and\nexplicitly model logical dependencies between various elements. Experimental\nresults show that CLMPT is a new state-of-the-art neural CQA model.\nhttps://github.com/qianlima-lab/CLMPT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "KDD 2024 Research Track",
    "pdf_url": "http://arxiv.org/pdf/2402.12954v2",
    "published_date": "2024-02-20 12:17:01 UTC",
    "updated_date": "2024-08-10 10:15:47 UTC"
  },
  {
    "arxiv_id": "2402.12950v2",
    "title": "QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems",
    "authors": [
      "Jinjing Shi",
      "Zimeng Xiao",
      "Heyuan Shi",
      "Yu Jiang",
      "Xuelong Li"
    ],
    "abstract": "Quantum Neural Network (QNN) combines the Deep Learning (DL) principle with\nthe fundamental theory of quantum mechanics to achieve machine learning tasks\nwith quantum acceleration. Recently, QNN systems have been found to manifest\nrobustness issues similar to classical DL systems. There is an urgent need for\nways to test their correctness and security. However, QNN systems differ\nsignificantly from traditional quantum software and classical DL systems,\nposing critical challenges for QNN testing. These challenges include the\ninapplicability of traditional quantum software testing methods to QNN systems\ndue to differences in programming paradigms and decision logic representations,\nthe dependence of quantum test sample generation on perturbation operators, and\nthe absence of effective information in quantum neurons. In this paper, we\npropose QuanTest, a quantum entanglement-guided adversarial testing framework\nto uncover potential erroneous behaviors in QNN systems. We design a quantum\nentanglement adequacy criterion to quantify the entanglement acquired by the\ninput quantum states from the QNN system, along with two similarity metrics to\nmeasure the proximity of generated quantum adversarial examples to the original\ninputs. Subsequently, QuanTest formulates the problem of generating test inputs\nthat maximize the quantum entanglement adequacy and capture incorrect behaviors\nof the QNN system as a joint optimization problem and solves it in a\ngradient-based manner to generate quantum adversarial examples. results\ndemonstrate that QuanTest possesses the capability to capture erroneous\nbehaviors in QNN systems. The entanglement-guided approach proves effective in\nadversarial testing, generating more adversarial examples.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper has been accepted by TOSEM 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12950v2",
    "published_date": "2024-02-20 12:11:28 UTC",
    "updated_date": "2024-08-26 08:02:40 UTC"
  },
  {
    "arxiv_id": "2402.12939v1",
    "title": "Discovering Behavioral Modes in Deep Reinforcement Learning Policies Using Trajectory Clustering in Latent Space",
    "authors": [
      "Sindre Benjamin Remman",
      "Anastasios M. Lekkas"
    ],
    "abstract": "Understanding the behavior of deep reinforcement learning (DRL) agents is\ncrucial for improving their performance and reliability. However, the\ncomplexity of their policies often makes them challenging to understand. In\nthis paper, we introduce a new approach for investigating the behavior modes of\nDRL policies, which involves utilizing dimensionality reduction and trajectory\nclustering in the latent space of neural networks. Specifically, we use\nPairwise Controlled Manifold Approximation Projection (PaCMAP) for\ndimensionality reduction and TRACLUS for trajectory clustering to analyze the\nlatent space of a DRL policy trained on the Mountain Car control task. Our\nmethodology helps identify diverse behavior patterns and suboptimal choices by\nthe policy, thus allowing for targeted improvements. We demonstrate how our\napproach, combined with domain knowledge, can enhance a policy's performance in\nspecific regions of the state space.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to the European Control Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12939v1",
    "published_date": "2024-02-20 11:50:50 UTC",
    "updated_date": "2024-02-20 11:50:50 UTC"
  },
  {
    "arxiv_id": "2402.17775v2",
    "title": "WhaleNet: a Novel Deep Learning Architecture for Marine Mammals Vocalizations on Watkins Marine Mammal Sound Database",
    "authors": [
      "Alessandro Licciardi",
      "Davide Carbone"
    ],
    "abstract": "Marine mammal communication is a complex field, hindered by the diversity of\nvocalizations and environmental factors. The Watkins Marine Mammal Sound\nDatabase (WMMD) constitutes a comprehensive labeled dataset employed in machine\nlearning applications. Nevertheless, the methodologies for data preparation,\npreprocessing, and classification documented in the literature exhibit\nconsiderable variability and are typically not applied to the dataset in its\nentirety. This study initially undertakes a concise review of the\nstate-of-the-art benchmarks pertaining to the dataset, with a particular focus\non clarifying data preparation and preprocessing techniques. Subsequently, we\nexplore the utilization of the Wavelet Scattering Transform (WST) and Mel\nspectrogram as preprocessing mechanisms for feature extraction. In this paper,\nwe introduce \\textbf{WhaleNet} (Wavelet Highly Adaptive Learning Ensemble\nNetwork), a sophisticated deep ensemble architecture for the classification of\nmarine mammal vocalizations, leveraging both WST and Mel spectrogram for\nenhanced feature discrimination. By integrating the insights derived from WST\nand Mel representations, we achieved an improvement in classification accuracy\nby $8-10\\%$ over existing architectures, corresponding to a classification\naccuracy of $97.61\\%$.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17775v2",
    "published_date": "2024-02-20 11:36:23 UTC",
    "updated_date": "2024-06-26 14:34:13 UTC"
  },
  {
    "arxiv_id": "2402.12928v5",
    "title": "A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence",
    "authors": [
      "Penghai Zhao",
      "Xin Zhang",
      "Jiayue Cao",
      "Ming-Ming Cheng",
      "Jian Yang",
      "Xiang Li"
    ],
    "abstract": "The rapid advancements in Pattern Analysis and Machine Intelligence (PAMI)\nhave led to an overwhelming expansion of scientific knowledge, spawning\nnumerous literature reviews aimed at collecting and synthesizing fragmented\ninformation. This paper presents a thorough analysis of these literature\nreviews within the PAMI field, and tries to address three core research\nquestions: (1) What are the prevalent structural and statistical\ncharacteristics of PAMI literature reviews? (2) What strategies can researchers\nemploy to efficiently navigate the growing corpus of reviews? (3) What are the\nadvantages and limitations of AI-generated reviews compared to human-authored\nones? To address the first research question, we begin with a narrative\noverview to highlight common preferences in composing PAMI reviews, followed by\na statistical analysis to quantitatively uncover patterns in these preferences.\nOur findings reveal several key insights. First, fewer than 20% of PAMI reviews\ncurrently comply with PRISMA standards, although this proportion is gradually\nincreasing. Second, there is a moderate positive correlation between the\nquality of references and the scholarly impact of reviews, emphasizing the\nimportance of reference selection. To further assist researchers in efficiently\nmanaging the rapidly growing number of literature reviews, we introduce four\nnovel, real-time, article-level bibliometric indicators that facilitate the\nscreening of numerous reviews. Finally, our comparative analysis reveals that\nAI-generated reviews currently fall short of human-authored ones in accurately\nevaluating the academic significance of newly published articles and\nintegrating rich visual elements, which limits their practical utility.\nOverall, this study provides a deeper understanding of PAMI literature reviews\nby uncovering key trends, evaluating current practices, and highlighting areas\nfor future improvement.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.DL",
    "comment": "V2, V3, and V4 with incremental quality improvements. V5 introduces\n  major updates, featuring 27 pages, 16 figures, and 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.12928v5",
    "published_date": "2024-02-20 11:28:50 UTC",
    "updated_date": "2024-12-14 14:04:28 UTC"
  },
  {
    "arxiv_id": "2402.12916v1",
    "title": "Data Pipeline Training: Integrating AutoML to Optimize the Data Flow of Machine Learning Models",
    "authors": [
      "Jiang Wu",
      "Hongbo Wang",
      "Chunhe Ni",
      "Chenwei Zhang",
      "Wenran Lu"
    ],
    "abstract": "Data Pipeline plays an indispensable role in tasks such as modeling machine\nlearning and developing data products. With the increasing diversification and\ncomplexity of Data sources, as well as the rapid growth of data volumes,\nbuilding an efficient Data Pipeline has become crucial for improving work\nefficiency and solving complex problems. This paper focuses on exploring how to\noptimize data flow through automated machine learning methods by integrating\nAutoML with Data Pipeline. We will discuss how to leverage AutoML technology to\nenhance the intelligence of Data Pipeline, thereby achieving better results in\nmachine learning tasks. By delving into the automation and optimization of Data\nflows, we uncover key strategies for constructing efficient data pipelines that\ncan adapt to the ever-changing data landscape. This not only accelerates the\nmodeling process but also provides innovative solutions to complex problems,\nenabling more significant outcomes in increasingly intricate data domains.\nKeywords- Data Pipeline Training;AutoML; Data environment; Machine learning",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12916v1",
    "published_date": "2024-02-20 11:06:42 UTC",
    "updated_date": "2024-02-20 11:06:42 UTC"
  },
  {
    "arxiv_id": "2402.12908v3",
    "title": "RealCompo: Balancing Realism and Compositionality Improves Text-to-Image Diffusion Models",
    "authors": [
      "Xinchen Zhang",
      "Ling Yang",
      "Yaqi Cai",
      "Zhaochen Yu",
      "Kai-Ni Wang",
      "Jiake Xie",
      "Ye Tian",
      "Minkai Xu",
      "Yong Tang",
      "Yujiu Yang",
      "Bin Cui"
    ],
    "abstract": "Diffusion models have achieved remarkable advancements in text-to-image\ngeneration. However, existing models still have many difficulties when faced\nwith multiple-object compositional generation. In this paper, we propose\nRealCompo, a new training-free and transferred-friendly text-to-image\ngeneration framework, which aims to leverage the respective advantages of\ntext-to-image models and spatial-aware image diffusion models (e.g., layout,\nkeypoints and segmentation maps) to enhance both realism and compositionality\nof the generated images. An intuitive and novel balancer is proposed to\ndynamically balance the strengths of the two models in denoising process,\nallowing plug-and-play use of any model without extra training. Extensive\nexperiments show that our RealCompo consistently outperforms state-of-the-art\ntext-to-image models and spatial-aware image diffusion models in\nmultiple-object compositional generation while keeping satisfactory realism and\ncompositionality of the generated images. Notably, our RealCompo can be\nseamlessly extended with a wide range of spatial-aware image diffusion models\nand stylized diffusion models. Our code is available at:\nhttps://github.com/YangLing0818/RealCompo",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024. Project: https://github.com/YangLing0818/RealCompo",
    "pdf_url": "http://arxiv.org/pdf/2402.12908v3",
    "published_date": "2024-02-20 10:56:52 UTC",
    "updated_date": "2024-10-14 07:27:37 UTC"
  },
  {
    "arxiv_id": "2402.12907v2",
    "title": "Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects",
    "authors": [
      "Zhaowei Zhang",
      "Fengshuo Bai",
      "Mingzhi Wang",
      "Haoyang Ye",
      "Chengdong Ma",
      "Yaodong Yang"
    ],
    "abstract": "The burgeoning integration of artificial intelligence (AI) into human society\nbrings forth significant implications for societal governance and safety. While\nconsiderable strides have been made in addressing AI alignment challenges,\nexisting methodologies primarily focus on technical facets, often neglecting\nthe intricate sociotechnical nature of AI systems, which can lead to a\nmisalignment between the development and deployment contexts. To this end, we\nposit a new problem worth exploring: Incentive Compatibility Sociotechnical\nAlignment Problem (ICSAP). We hope this can call for more researchers to\nexplore how to leverage the principles of Incentive Compatibility (IC) from\ngame theory to bridge the gap between technical and societal components to\nmaintain AI consensus with human societies in different contexts. We further\ndiscuss three classical game problems for achieving IC: mechanism design,\ncontract theory, and Bayesian persuasion, in addressing the perspectives,\npotentials, and challenges of solving ICSAP, and provide preliminary\nimplementation conceptions.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GT",
      "cs.HC",
      "I.2.m; K.4.m"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.12907v2",
    "published_date": "2024-02-20 10:52:57 UTC",
    "updated_date": "2024-03-01 11:18:44 UTC"
  },
  {
    "arxiv_id": "2404.07212v1",
    "title": "Hybrid Training of Denoising Networks to Improve the Texture Acutance of Digital Cameras",
    "authors": [
      "Raphaël Achddou",
      "Yann Gousseau",
      "Saïd Ladjal"
    ],
    "abstract": "In order to evaluate the capacity of a camera to render textures properly,\nthe standard practice, used by classical scoring protocols, is to compute the\nfrequential response to a dead leaves image target, from which is built a\ntexture acutance metric. In this work, we propose a mixed training procedure\nfor image restoration neural networks, relying on both natural and synthetic\nimages, that yields a strong improvement of this acutance metric without\nimpairing fidelity terms. The feasibility of the approach is demonstrated both\non the denoising of RGB images and the full development of RAW images, opening\nthe path to a systematic improvement of the texture acutance of real imaging\ndevices.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07212v1",
    "published_date": "2024-02-20 10:47:06 UTC",
    "updated_date": "2024-02-20 10:47:06 UTC"
  },
  {
    "arxiv_id": "2402.12887v1",
    "title": "The practice of qualitative parameterisation in the development of Bayesian networks",
    "authors": [
      "Steven Mascaro",
      "Owen Woodberry",
      "Yue Wu",
      "Ann E. Nicholson"
    ],
    "abstract": "The typical phases of Bayesian network (BN) structured development include\nspecification of purpose and scope, structure development, parameterisation and\nvalidation. Structure development is typically focused on qualitative issues\nand parameterisation quantitative issues, however there are qualitative and\nquantitative issues that arise in both phases. A common step that occurs after\nthe initial structure has been developed is to perform a rough parameterisation\nthat only captures and illustrates the intended qualitative behaviour of the\nmodel. This is done prior to a more rigorous parameterisation, ensuring that\nthe structure is fit for purpose, as well as supporting later development and\nvalidation. In our collective experience and in discussions with other\nmodellers, this step is an important part of the development process, but is\nunder-reported in the literature. Since the practice focuses on qualitative\nissues, despite being quantitative in nature, we call this step qualitative\nparameterisation and provide an outline of its role in the BN development\nprocess.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures, technical note",
    "pdf_url": "http://arxiv.org/pdf/2402.12887v1",
    "published_date": "2024-02-20 10:30:36 UTC",
    "updated_date": "2024-02-20 10:30:36 UTC"
  },
  {
    "arxiv_id": "2402.12865v1",
    "title": "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space",
    "authors": [
      "Shahar Katz",
      "Yonatan Belinkov",
      "Mor Geva",
      "Lior Wolf"
    ],
    "abstract": "Understanding how Transformer-based Language Models (LMs) learn and recall\ninformation is a key goal of the deep learning community. Recent\ninterpretability methods project weights and hidden states obtained from the\nforward pass to the models' vocabularies, helping to uncover how information\nflows within LMs. In this work, we extend this methodology to LMs' backward\npass and gradients. We first prove that a gradient matrix can be cast as a\nlow-rank linear combination of its forward and backward passes' inputs. We then\ndevelop methods to project these gradients into vocabulary items and explore\nthe mechanics of how new information is stored in the LMs' neurons.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12865v1",
    "published_date": "2024-02-20 09:57:08 UTC",
    "updated_date": "2024-02-20 09:57:08 UTC"
  },
  {
    "arxiv_id": "2402.12847v2",
    "title": "Instruction-tuned Language Models are Better Knowledge Learners",
    "authors": [
      "Zhengbao Jiang",
      "Zhiqing Sun",
      "Weijia Shi",
      "Pedro Rodriguez",
      "Chunting Zhou",
      "Graham Neubig",
      "Xi Victoria Lin",
      "Wen-tau Yih",
      "Srinivasan Iyer"
    ],
    "abstract": "In order for large language model (LLM)-based assistants to effectively adapt\nto evolving information needs, it must be possible to update their factual\nknowledge through continued training on new data. The standard recipe for doing\nso involves continued pre-training on new documents followed by\ninstruction-tuning on question-answer (QA) pairs. However, we find that LLMs\ntrained with this recipe struggle to answer questions, even though the\nperplexity of documents is minimized. We found that QA pairs are generally\nstraightforward, while documents are more complex, weaving many factual\nstatements together in an intricate manner. Therefore, we hypothesize that it\nis beneficial to expose LLMs to QA pairs before continued pre-training on\ndocuments so that the process of encoding knowledge from complex documents\ntakes into account how this knowledge is accessed through questions. Based on\nthis, we propose pre-instruction-tuning (PIT), a method that instruction-tunes\non questions prior to training on documents. This contrasts with standard\ninstruction-tuning, which learns how to extract knowledge after training on\ndocuments. Extensive experiments and ablation studies demonstrate that\npre-instruction-tuning significantly enhances the ability of LLMs to absorb\nknowledge from new documents, outperforming standard instruction-tuning by\n17.8%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024. The reproduced data for this paper is available at\n  https://github.com/Edward-Sun/PIT",
    "pdf_url": "http://arxiv.org/pdf/2402.12847v2",
    "published_date": "2024-02-20 09:20:32 UTC",
    "updated_date": "2024-05-26 03:19:48 UTC"
  },
  {
    "arxiv_id": "2402.12846v1",
    "title": "ConVQG: Contrastive Visual Question Generation with Multimodal Guidance",
    "authors": [
      "Li Mi",
      "Syrielle Montariol",
      "Javiera Castillo-Navarro",
      "Xianjie Dai",
      "Antoine Bosselut",
      "Devis Tuia"
    ],
    "abstract": "Asking questions about visual environments is a crucial way for intelligent\nagents to understand rich multi-faceted scenes, raising the importance of\nVisual Question Generation (VQG) systems. Apart from being grounded to the\nimage, existing VQG systems can use textual constraints, such as expected\nanswers or knowledge triplets, to generate focused questions. These constraints\nallow VQG systems to specify the question content or leverage external\ncommonsense knowledge that can not be obtained from the image content only.\nHowever, generating focused questions using textual constraints while enforcing\na high relevance to the image content remains a challenge, as VQG systems often\nignore one or both forms of grounding. In this work, we propose Contrastive\nVisual Question Generation (ConVQG), a method using a dual contrastive\nobjective to discriminate questions generated using both modalities from those\nbased on a single one. Experiments on both knowledge-aware and standard VQG\nbenchmarks demonstrate that ConVQG outperforms the state-of-the-art methods and\ngenerates image-grounded, text-guided, and knowledge-rich questions. Our human\nevaluation results also show preference for ConVQG questions compared to\nnon-contrastive baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2024. Project page at https://limirs.github.io/ConVQG",
    "pdf_url": "http://arxiv.org/pdf/2402.12846v1",
    "published_date": "2024-02-20 09:20:30 UTC",
    "updated_date": "2024-02-20 09:20:30 UTC"
  },
  {
    "arxiv_id": "2402.12845v1",
    "title": "MORE-3S:Multimodal-based Offline Reinforcement Learning with Shared Semantic Spaces",
    "authors": [
      "Tianyu Zheng",
      "Ge Zhang",
      "Xingwei Qu",
      "Ming Kuang",
      "Stephen W. Huang",
      "Zhaofeng He"
    ],
    "abstract": "Drawing upon the intuition that aligning different modalities to the same\nsemantic embedding space would allow models to understand states and actions\nmore easily, we propose a new perspective to the offline reinforcement learning\n(RL) challenge. More concretely, we transform it into a supervised learning\ntask by integrating multimodal and pre-trained language models. Our approach\nincorporates state information derived from images and action-related data\nobtained from text, thereby bolstering RL training performance and promoting\nlong-term strategic thinking. We emphasize the contextual understanding of\nlanguage and demonstrate how decision-making in RL can benefit from aligning\nstates' and actions' representation with languages' representation. Our method\nsignificantly outperforms current baselines as evidenced by evaluations\nconducted on Atari and OpenAI Gym environments. This contributes to advancing\noffline RL performance and efficiency while providing a novel perspective on\noffline RL.Our code and data are available at\nhttps://github.com/Zheng0428/MORE_.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12845v1",
    "published_date": "2024-02-20 09:15:50 UTC",
    "updated_date": "2024-02-20 09:15:50 UTC"
  },
  {
    "arxiv_id": "2402.12843v3",
    "title": "Solar Panel Segmentation :Self-Supervised Learning Solutions for Imperfect Datasets",
    "authors": [
      "Sankarshanaa Sagaram",
      "Krish Didwania",
      "Laven Srivastava",
      "Aditya Kasliwal",
      "Pallavi Kailas",
      "Ujjwal Verma"
    ],
    "abstract": "The increasing adoption of solar energy necessitates advanced methodologies\nfor monitoring and maintenance to ensure optimal performance of solar panel\ninstallations. A critical component in this context is the accurate\nsegmentation of solar panels from aerial or satellite imagery, which is\nessential for identifying operational issues and assessing efficiency. This\npaper addresses the significant challenges in panel segmentation, particularly\nthe scarcity of annotated data and the labour-intensive nature of manual\nannotation for supervised learning. We explore and apply Self-Supervised\nLearning (SSL) to solve these challenges. We demonstrate that SSL significantly\nenhances model generalization under various conditions and reduces dependency\non manually annotated data, paving the way for robust and adaptable solar panel\nsegmentation solutions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at ICLR Tiny Paper 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12843v3",
    "published_date": "2024-02-20 09:13:11 UTC",
    "updated_date": "2024-06-02 18:08:19 UTC"
  },
  {
    "arxiv_id": "2402.12842v3",
    "title": "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning",
    "authors": [
      "Gyeongman Kim",
      "Doohyuk Jang",
      "Eunho Yang"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have raised concerns\nabout inference costs, increasing the need for research into model compression.\nWhile knowledge distillation (KD) is a prominent method for this, research on\nKD for generative language models like LLMs is relatively sparse, and the\napproach of distilling student-friendly knowledge, which has shown promising\nperformance in KD for classification models, remains unexplored in generative\nlanguage models. To explore this approach, we propose PromptKD, a simple yet\neffective method that utilizes prompt tuning - for the first time in KD - to\nenable generative language models to transfer student-friendly knowledge.\nUnlike previous works in classification that require fine-tuning the entire\nteacher model for extracting student-friendly knowledge, PromptKD achieves\nsimilar effects by adding a small number of prompt tokens and tuning only the\nprompt with student guidance. Extensive experiments on instruction-following\ndatasets show that PromptKD achieves state-of-the-art performance while adding\nonly 0.0007% of the teacher's parameters as prompts. Further analysis suggests\nthat distilling student-friendly knowledge alleviates exposure bias effectively\nthroughout the entire training process, leading to performance enhancements.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings. Our project page: https://promptkd.github.io",
    "pdf_url": "http://arxiv.org/pdf/2402.12842v3",
    "published_date": "2024-02-20 09:10:08 UTC",
    "updated_date": "2024-09-27 06:25:33 UTC"
  },
  {
    "arxiv_id": "2402.12835v2",
    "title": "PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs",
    "authors": [
      "An Liu",
      "Zonghan Yang",
      "Zhenhe Zhang",
      "Qingyuan Hu",
      "Peng Li",
      "Ming Yan",
      "Ji Zhang",
      "Fei Huang",
      "Yang Liu"
    ],
    "abstract": "While Large language models (LLMs) have demonstrated considerable\ncapabilities across various natural language tasks, they often fall short of\nthe performance achieved by domain-specific state-of-the-art models. One\npotential approach to enhance domain-specific capabilities of LLMs involves\nfine-tuning them using corresponding datasets. However, this method can be both\nresource and time-intensive, and not applicable to closed-source commercial\nLLMs. In this paper, we propose Preference Adaptation for Enhancing\nDomain-specific Abilities of LLMs (PANDA), a method designed to augment the\ndomain-specific capabilities of LLMs by leveraging insights from the response\npreference of expert models without requiring fine-tuning. Our experimental\nresults reveal that PANDA significantly enhances the domain-specific ability of\nLLMs on text classification and interactive decision tasks. Moreover, LLM with\nPANDA even outperforms the expert model that being learned on 4 tasks of\nScienceWorld. This finding highlights the potential of exploring tuning-free\napproaches to achieve weak-to-strong generalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12835v2",
    "published_date": "2024-02-20 09:02:55 UTC",
    "updated_date": "2024-06-18 03:08:37 UTC"
  },
  {
    "arxiv_id": "2402.12819v2",
    "title": "Comparing Specialised Small and General Large Language Models on Text Classification: 100 Labelled Samples to Achieve Break-Even Performance",
    "authors": [
      "Branislav Pecher",
      "Ivan Srba",
      "Maria Bielikova"
    ],
    "abstract": "When solving NLP tasks with limited labelled data, researchers can either use\na general large language model without further update, or use a small number of\nlabelled examples to tune a specialised smaller model. In this work, we address\nthe research gap of how many labelled samples are required for the specialised\nsmall models to outperform general large models, while taking the performance\nvariance into consideration. By observing the behaviour of fine-tuning,\ninstruction-tuning, prompting and in-context learning on 7 language models, we\nidentify such performance break-even points across 8 representative text\nclassification tasks of varying characteristics. We show that the specialised\nmodels often need only few samples (on average $10 - 1000$) to be on par or\nbetter than the general ones. At the same time, the number of required labels\nstrongly depends on the dataset or task characteristics, with this number being\nsignificantly lower on multi-class datasets (up to $100$) than on binary\ndatasets (up to $5000$). When performance variance is taken into consideration,\nthe number of required labels increases on average by $100 - 200\\%$ and even up\nto $1500\\%$ in specific cases.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12819v2",
    "published_date": "2024-02-20 08:38:24 UTC",
    "updated_date": "2024-04-26 08:20:40 UTC"
  },
  {
    "arxiv_id": "2402.12817v2",
    "title": "On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices",
    "authors": [
      "Branislav Pecher",
      "Ivan Srba",
      "Maria Bielikova"
    ],
    "abstract": "While learning with limited labelled data can improve performance when the\nlabels are lacking, it is also sensitive to the effects of uncontrolled\nrandomness introduced by so-called randomness factors (e.g., varying order of\ndata). We propose a method to systematically investigate the effects of\nrandomness factors while taking the interactions between them into\nconsideration. To measure the true effects of an individual randomness factor,\nour method mitigates the effects of other factors and observes how the\nperformance varies across multiple runs. Applying our method to multiple\nrandomness factors across in-context learning and fine-tuning approaches on 7\nrepresentative text classification tasks and meta-learning on 3 tasks, we show\nthat: 1) disregarding interactions between randomness factors in existing works\ncaused inconsistent findings due to incorrect attribution of the effects of\nrandomness factors, such as disproving the consistent sensitivity of in-context\nlearning to sample order even with random sample selection; and 2) besides\nmutual interactions, the effects of randomness factors, especially sample\norder, are also dependent on more systematic choices unexplored in existing\nworks, such as number of classes, samples per class or choice of prompt format.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the EMNLP'24 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2402.12817v2",
    "published_date": "2024-02-20 08:38:19 UTC",
    "updated_date": "2024-10-03 14:56:24 UTC"
  },
  {
    "arxiv_id": "2402.12810v2",
    "title": "PIP-Net: Pedestrian Intention Prediction in the Wild",
    "authors": [
      "Mohsen Azarmi",
      "Mahdi Rezaei",
      "He Wang",
      "Sebastien Glaser"
    ],
    "abstract": "Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs)\nis one of the current research challenges in this field. In this article, we\nintroduce PIP-Net, a novel framework designed to predict pedestrian crossing\nintentions by AVs in real-world urban scenarios. We offer two variants of\nPIP-Net designed for different camera mounts and setups. Leveraging both\nkinematic data and spatial features from the driving scene, the proposed model\nemploys a recurrent and temporal attention-based solution, outperforming\nstate-of-the-art performance. To enhance the visual representation of road\nusers and their proximity to the ego vehicle, we introduce a categorical depth\nfeature map, combined with a local motion flow feature, providing rich insights\ninto the scene dynamics. Additionally, we explore the impact of expanding the\ncamera's field of view, from one to three cameras surrounding the ego vehicle,\nleading to enhancement in the model's contextual perception. Depending on the\ntraffic scenario and road environment, the model excels in predicting\npedestrian crossing intentions up to 4 seconds in advance which is a\nbreakthrough in current research studies in pedestrian intention prediction.\nFinally, for the first time, we present the Urban-PIP dataset, a customised\npedestrian intention prediction dataset, with multi-camera annotations in\nreal-world automated driving scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE",
      "eess.IV",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12810v2",
    "published_date": "2024-02-20 08:28:45 UTC",
    "updated_date": "2024-03-01 15:02:25 UTC"
  },
  {
    "arxiv_id": "2403.05562v1",
    "title": "SDXL Finetuned with LoRA for Coloring Therapy: Generating Graphic Templates Inspired by United Arab Emirates Culture",
    "authors": [
      "Abdulla Alfalasi",
      "Esrat Khan",
      "Mohamed Alhashmi",
      "Raed Aldweik",
      "Davor Svetinovic"
    ],
    "abstract": "A transformative approach to mental health therapy lies at the crossroads of\ncultural heritage and advanced technology. This paper introduces an innovative\nmethod that fuses machine learning techniques with traditional Emirati motifs,\nfocusing on the United Arab Emirates (UAE). We utilize the Stable Diffusion XL\n(SDXL) model, enhanced with Low-Rank Adaptation (LoRA), to create culturally\nsignificant coloring templates featuring Al-Sadu weaving patterns. This novel\napproach leverages coloring therapy for its recognized stress-relieving\nbenefits and embeds deep cultural resonance, making it a potent tool for\ntherapeutic intervention and cultural preservation. Specifically targeting\nGeneralized Anxiety Disorder (GAD), our method demonstrates significant\npotential in reducing associated symptoms. Additionally, the paper delves into\nthe broader implications of color and music therapy, emphasizing the importance\nof culturally tailored content. The technical aspects of the SDXL model and its\nLoRA fine-tuning showcase its capability to generate high-quality, culturally\nspecific images. This research stands at the forefront of integrating mental\nwellness practices with cultural heritage, providing a groundbreaking\nperspective on the synergy between technology, culture, and healthcare. In\nfuture work, we aim to employ biosignals to assess the level of engagement and\neffectiveness of color therapy. A key focus will be to examine the impact of\nthe Emirati heritage Al Sadu art on Emirati individuals and compare their\nresponses with those of other nationalities. This will provide deeper insights\ninto the cultural specificity of therapeutic interventions and further the\nunderstanding of the unique interplay between cultural identity and mental\nhealth therapy.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05562v1",
    "published_date": "2024-02-20 08:20:08 UTC",
    "updated_date": "2024-02-20 08:20:08 UTC"
  },
  {
    "arxiv_id": "2402.12794v1",
    "title": "Autonomous Reality Modelling for Cultural Heritage Sites employing cooperative quadrupedal robots and unmanned aerial vehicles",
    "authors": [
      "Nikolaos Giakoumidis",
      "Christos-Nikolaos Anagnostopoulos"
    ],
    "abstract": "Nowadays, the use of advanced sensors, such as terrestrial 3D laser scanners,\nmobile LiDARs and Unmanned Aerial Vehicles (UAV) photogrammetric imaging, has\nbecome the prevalent practice for 3D Reality Modeling and digitization of\nlarge-scale monuments of Cultural Heritage (CH). In practice, this process is\nheavily related to the expertise of the surveying team, handling the laborious\nplanning and time-consuming execution of the 3D mapping process that is\ntailored to the specific requirements and constraints of each site. To minimize\nhuman intervention, this paper introduces a novel methodology for autonomous 3D\nReality Modeling for CH monuments by employing au-tonomous biomimetic\nquadrupedal robotic agents and UAVs equipped with the appropriate sensors.\nThese autonomous robotic agents carry out the 3D RM process in a systematic and\nrepeatable ap-proach. The outcomes of this automated process may find\napplications in digital twin platforms, facilitating secure monitoring and\nmanagement of cultural heritage sites and spaces, in both indoor and outdoor\nenvironments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12794v1",
    "published_date": "2024-02-20 08:08:07 UTC",
    "updated_date": "2024-02-20 08:08:07 UTC"
  },
  {
    "arxiv_id": "2402.15526v1",
    "title": "Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models",
    "authors": [
      "Kaiwen Wei",
      "Jingyuan Zhang",
      "Hongzhi Zhang",
      "Fuzheng Zhang",
      "Di Zhang",
      "Li Jin",
      "Yue Yu"
    ],
    "abstract": "Large Language Models (LLMs) exhibit remarkable generative capabilities,\nenabling the generation of valuable information. Despite these advancements,\nprevious research found that LLMs sometimes struggle with adhering to specific\nconstraints (e.g., in specific place or at specific time), at times even\noverlooking them, which leads to responses that are either too generic or not\nfully satisfactory. Existing approaches attempted to address this issue by\ndecomposing or rewriting input instructions, yet they fall short in adequately\nemphasizing specific constraints and in unlocking the underlying knowledge\n(e.g., programming within the context of software development). In response,\nthis paper proposes a simple yet effective method named Chain-of-Specificity\n(CoS). Specifically, CoS iteratively emphasizes the specific constraints in the\ninput instructions, unlocks knowledge within LLMs, and refines responses.\nExperiments conducted on publicly available and self-build complex datasets\ndemonstrate that CoS outperforms existing methods in enhancing generated\ncontent especially for the specificity. Besides, as the number of specific\nconstraints increase, other baselines falter, while CoS still performs well.\nMoreover, we show that distilling responses generated by CoS effectively\nenhances the ability of smaller models to follow the constrained instructions.\nResources of this paper will be released for further research.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.15526v1",
    "published_date": "2024-02-20 08:03:05 UTC",
    "updated_date": "2024-02-20 08:03:05 UTC"
  },
  {
    "arxiv_id": "2402.12789v3",
    "title": "Fairness Without Harm: An Influence-Guided Active Sampling Approach",
    "authors": [
      "Jinlong Pang",
      "Jialu Wang",
      "Zhaowei Zhu",
      "Yuanshun Yao",
      "Chen Qian",
      "Yang Liu"
    ],
    "abstract": "The pursuit of fairness in machine learning (ML), ensuring that the models do\nnot exhibit biases toward protected demographic groups, typically results in a\ncompromise scenario. This compromise can be explained by a Pareto frontier\nwhere given certain resources (e.g., data), reducing the fairness violations\noften comes at the cost of lowering the model accuracy. In this work, we aim to\ntrain models that mitigate group fairness disparity without causing harm to\nmodel accuracy. Intuitively, acquiring more data is a natural and promising\napproach to achieve this goal by reaching a better Pareto frontier of the\nfairness-accuracy tradeoff. The current data acquisition methods, such as fair\nactive learning approaches, typically require annotating sensitive attributes.\nHowever, these sensitive attribute annotations should be protected due to\nprivacy and safety concerns. In this paper, we propose a tractable active data\nsampling algorithm that does not rely on training group annotations, instead\nonly requiring group annotations on a small validation set. Specifically, the\nalgorithm first scores each new example by its influence on fairness and\naccuracy evaluated on the validation dataset, and then selects a certain number\nof examples for training. We theoretically analyze how acquiring more data can\nimprove fairness without causing harm, and validate the possibility of our\nsampling approach in the context of risk disparity. We also provide the upper\nbound of generalization error and risk disparity as well as the corresponding\nconnections. Extensive experiments on real-world data demonstrate the\neffectiveness of our proposed algorithm. Our code is available at\nhttps://github.com/UCSC-REAL/FairnessWithoutHarm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12789v3",
    "published_date": "2024-02-20 07:57:38 UTC",
    "updated_date": "2024-11-08 10:17:29 UTC"
  },
  {
    "arxiv_id": "2402.12782v1",
    "title": "Advancing GenAI Assisted Programming--A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4",
    "authors": [
      "Angus Yang",
      "Zehan Li",
      "Jie Li"
    ],
    "abstract": "This study aims to explore the best practices for utilizing GenAI as a\nprogramming tool, through a comparative analysis between GPT-4 and GLM-4. By\nevaluating prompting strategies at different levels of complexity, we identify\nthat simplest and straightforward prompting strategy yields best code\ngeneration results. Additionally, adding a CoT-like preliminary confirmation\nstep would further increase the success rate. Our results reveal that while\nGPT-4 marginally outperforms GLM-4, the difference is minimal for average\nusers. In our simplified evaluation model, we see a remarkable 30 to 100-fold\nincrease in code generation efficiency over traditional coding norms. Our GenAI\nCoding Workshop highlights the effectiveness and accessibility of the prompting\nmethodology developed in this study. We observe that GenAI-assisted coding\nwould trigger a paradigm shift in programming landscape, which necessitates\ndevelopers to take on new roles revolving around supervising and guiding GenAI,\nand to focus more on setting high-level objectives and engaging more towards\ninnovation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.3"
    ],
    "primary_category": "cs.SE",
    "comment": "18 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.12782v1",
    "published_date": "2024-02-20 07:47:39 UTC",
    "updated_date": "2024-02-20 07:47:39 UTC"
  },
  {
    "arxiv_id": "2404.15282v1",
    "title": "Patent Value Characterization -- An Empirical Analysis of Elevator Industry Patents",
    "authors": [
      "Yuhang Guan",
      "Runzheng Wang",
      "Lei Fu",
      "Huanle Zhang"
    ],
    "abstract": "The global patent application count has steadily increased, achieving eight\nconsecutive years of growth.The global patent industry has shown a general\ntrend of expansion. This is attributed to the increasing innovation activities,\nparticularly in the fields of technology, healthcare, and biotechnology. Some\nemerging market countries, such as China and India, have experienced\nsignificant growth in the patent domain, becoming important participants in\nglobal patent activities.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15282v1",
    "published_date": "2024-02-20 07:18:16 UTC",
    "updated_date": "2024-02-20 07:18:16 UTC"
  },
  {
    "arxiv_id": "2402.12760v1",
    "title": "A User-Friendly Framework for Generating Model-Preferred Prompts in Text-to-Image Synthesis",
    "authors": [
      "Nailei Hei",
      "Qianyu Guo",
      "Zihao Wang",
      "Yan Wang",
      "Haofen Wang",
      "Wenqiang Zhang"
    ],
    "abstract": "Well-designed prompts have demonstrated the potential to guide text-to-image\nmodels in generating amazing images. Although existing prompt engineering\nmethods can provide high-level guidance, it is challenging for novice users to\nachieve the desired results by manually entering prompts due to a discrepancy\nbetween novice-user-input prompts and the model-preferred prompts. To bridge\nthe distribution gap between user input behavior and model training datasets,\nwe first construct a novel Coarse-Fine Granularity Prompts dataset (CFP) and\npropose a novel User-Friendly Fine-Grained Text Generation framework (UF-FGTG)\nfor automated prompt optimization. For CFP, we construct a novel dataset for\ntext-to-image tasks that combines coarse and fine-grained prompts to facilitate\nthe development of automated prompt generation methods. For UF-FGTG, we propose\na novel framework that automatically translates user-input prompts into\nmodel-preferred prompts. Specifically, we propose a prompt refiner that\ncontinually rewrites prompts to empower users to select results that align with\ntheir unique needs. Meanwhile, we integrate image-related loss functions from\nthe text-to-image model into the training process of text generation to\ngenerate model-preferred prompts. Additionally, we propose an adaptive feature\nextraction module to ensure diversity in the generated results. Experiments\ndemonstrate that our approach is capable of generating more visually appealing\nand diverse images than previous state-of-the-art methods, achieving an average\nimprovement of 5% across six quality and aesthetic metrics.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted by The 38th Annual AAAI Conference on Artificial\n  Intelligence (AAAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.12760v1",
    "published_date": "2024-02-20 06:58:49 UTC",
    "updated_date": "2024-02-20 06:58:49 UTC"
  },
  {
    "arxiv_id": "2402.12750v2",
    "title": "Model Composition for Multimodal Large Language Models",
    "authors": [
      "Chi Chen",
      "Yiyang Du",
      "Zheng Fang",
      "Ziyue Wang",
      "Fuwen Luo",
      "Peng Li",
      "Ming Yan",
      "Ji Zhang",
      "Fei Huang",
      "Maosong Sun",
      "Yang Liu"
    ],
    "abstract": "Recent developments in Multimodal Large Language Models (MLLMs) have shown\nrapid progress, moving towards the goal of creating versatile MLLMs that\nunderstand inputs from various modalities. However, existing methods typically\nrely on joint training with paired multimodal instruction data, which is\nresource-intensive and challenging to extend to new modalities. In this paper,\nwe propose a new paradigm through the model composition of existing MLLMs to\ncreate a new model that retains the modal understanding capabilities of each\noriginal model. Our basic implementation, NaiveMC, demonstrates the\neffectiveness of this paradigm by reusing modality encoders and merging LLM\nparameters. Furthermore, we introduce DAMC to address parameter interference\nand mismatch issues during the merging process, thereby enhancing the model\nperformance. To facilitate research in this area, we propose MCUB, a benchmark\nfor assessing ability of MLLMs to understand inputs from diverse modalities.\nExperiments on this benchmark and four other multimodal understanding tasks\nshow significant improvements over baselines, proving that model composition\ncan create a versatile model capable of processing inputs from multiple\nmodalities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ACL2024 Main Conference; Code is available at\n  https://github.com/THUNLP-MT/ModelCompose",
    "pdf_url": "http://arxiv.org/pdf/2402.12750v2",
    "published_date": "2024-02-20 06:38:10 UTC",
    "updated_date": "2024-07-26 10:15:38 UTC"
  },
  {
    "arxiv_id": "2402.12749v5",
    "title": "Me LLaMA: Foundation Large Language Models for Medical Applications",
    "authors": [
      "Qianqian Xie",
      "Qingyu Chen",
      "Aokun Chen",
      "Cheng Peng",
      "Yan Hu",
      "Fongci Lin",
      "Xueqing Peng",
      "Jimin Huang",
      "Jeffrey Zhang",
      "Vipina Keloth",
      "Xinyu Zhou",
      "Lingfei Qian",
      "Huan He",
      "Dennis Shung",
      "Lucila Ohno-Machado",
      "Yonghui Wu",
      "Hua Xu",
      "Jiang Bian"
    ],
    "abstract": "Recent advancements in large language models (LLMs) like ChatGPT and LLaMA\nshow promise in medical applications, yet challenges remain in medical language\ncomprehension. This study presents Me-LLaMA, a new medical LLM family based on\nopen-source LLaMA models, optimized for medical text analysis and diagnosis by\nleveraging large-scale, domain-specific datasets. The Me-LLaMA family,\nincluding foundation models Me-LLaMA 13/70B and their chat-enhanced versions,\nwas developed through continued pre-training and instruction tuning with 129B\ntokens and 214K samples from biomedical and clinical sources. Training the 70B\nmodels required over 100,000 A100 GPU hours. Me-LLaMA's performance was\nevaluated across six medical text analysis tasks using 12 benchmark datasets\nand complex clinical case diagnosis, with automatic and human evaluations.\nResults indicate Me-LLaMA outperforms LLaMA and other open-source medical LLMs\nin zero-shot and supervised settings. Task-specific tuning further boosts\nperformance, surpassing ChatGPT on 7 of 8 datasets and GPT-4 on 5 of 8. For\ncomplex clinical cases, Me-LLaMA achieves performance comparable to ChatGPT and\nGPT-4. This work underscores the importance of domain-specific data in\ndeveloping medical LLMs and addresses the high computational costs involved in\ntraining, highlighting a balance between pre-training and fine-tuning\nstrategies. Me-LLaMA models are now accessible under user agreements, providing\na valuable resource for advancing medical AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 4 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.12749v5",
    "published_date": "2024-02-20 06:37:31 UTC",
    "updated_date": "2024-11-02 03:17:34 UTC"
  },
  {
    "arxiv_id": "2402.14855v1",
    "title": "An LLM Maturity Model for Reliable and Transparent Text-to-Query",
    "authors": [
      "Lei Yu",
      "Abir Ray"
    ],
    "abstract": "Recognizing the imperative to address the reliability and transparency issues\nof Large Language Models (LLM), this work proposes an LLM maturity model\ntailored for text-to-query applications. This maturity model seeks to fill the\nexisting void in evaluating LLMs in such applications by incorporating\ndimensions beyond mere correctness or accuracy. Moreover, this work introduces\na real-world use case from the law enforcement domain and showcases QueryIQ, an\nLLM-powered, domain-specific text-to-query assistant to expedite user workflows\nand reveal hidden relationship in data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14855v1",
    "published_date": "2024-02-20 06:20:09 UTC",
    "updated_date": "2024-02-20 06:20:09 UTC"
  },
  {
    "arxiv_id": "2402.14854v1",
    "title": "A Dual-Prompting for Interpretable Mental Health Language Models",
    "authors": [
      "Hyolim Jeon",
      "Dongje Yoo",
      "Daeun Lee",
      "Sejung Son",
      "Seungbae Kim",
      "Jinyoung Han"
    ],
    "abstract": "Despite the increasing demand for AI-based mental health monitoring tools,\ntheir practical utility for clinicians is limited by the lack of\ninterpretability.The CLPsych 2024 Shared Task (Chim et al., 2024) aims to\nenhance the interpretability of Large Language Models (LLMs), particularly in\nmental health analysis, by providing evidence of suicidality through linguistic\ncontent. We propose a dual-prompting approach: (i) Knowledge-aware evidence\nextraction by leveraging the expert identity and a suicide dictionary with a\nmental health-specific LLM; and (ii) Evidence summarization by employing an\nLLM-based consistency evaluator. Comprehensive experiments demonstrate the\neffectiveness of combining domain-specific information, revealing performance\nimprovements and the approach's potential to aid clinicians in assessing mental\nstate progression.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14854v1",
    "published_date": "2024-02-20 06:18:02 UTC",
    "updated_date": "2024-02-20 06:18:02 UTC"
  },
  {
    "arxiv_id": "2402.12738v1",
    "title": "Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues",
    "authors": [
      "Michimasa Inaba",
      "Mariko Ukiyo",
      "Keiko Takamizo"
    ],
    "abstract": "Mental health care poses an increasingly serious challenge to modern\nsocieties. In this context, there has been a surge in research that utilizes\ninformation technologies to address mental health problems, including those\naiming to develop counseling dialogue systems. However, there is a need for\nmore evaluations of the performance of counseling dialogue systems that use\nlarge language models. For this study, we collected counseling dialogue data\nvia role-playing scenarios involving expert counselors, and the utterances were\nannotated with the intentions of the counselors. To determine the feasibility\nof a dialogue system in real-world counseling scenarios, third-party counselors\nevaluated the appropriateness of responses from human counselors and those\ngenerated by GPT-4 in identical contexts in role-play dialogue data. Analysis\nof the evaluation results showed that the responses generated by GPT-4 were\ncompetitive with those of human counselors.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as a conference paper at IWSDS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12738v1",
    "published_date": "2024-02-20 06:05:36 UTC",
    "updated_date": "2024-02-20 06:05:36 UTC"
  },
  {
    "arxiv_id": "2402.12736v1",
    "title": "CST: Calibration Side-Tuning for Parameter and Memory Efficient Transfer Learning",
    "authors": [
      "Feng Chen"
    ],
    "abstract": "Achieving a universally high accuracy in object detection is quite\nchallenging, and the mainstream focus in the industry currently lies on\ndetecting specific classes of objects. However, deploying one or multiple\nobject detection networks requires a certain amount of GPU memory for training\nand storage capacity for inference. This presents challenges in terms of how to\neffectively coordinate multiple object detection tasks under\nresource-constrained conditions. This paper introduces a lightweight\nfine-tuning strategy called Calibration side tuning, which integrates aspects\nof adapter tuning and side tuning to adapt the successful techniques employed\nin transformers for use with ResNet. The Calibration side tuning architecture\nthat incorporates maximal transition calibration, utilizing a small number of\nadditional parameters to enhance network performance while maintaining a smooth\ntraining process. Furthermore, this paper has conducted an analysis on multiple\nfine-tuning strategies and have implemented their application within ResNet,\nthereby expanding the research on fine-tuning strategies for object detection\nnetworks. Besides, this paper carried out extensive experiments using five\nbenchmark datasets. The experimental results demonstrated that this method\noutperforms other compared state-of-the-art techniques, and a better balance\nbetween the complexity and performance of the finetune schemes is achieved.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12736v1",
    "published_date": "2024-02-20 06:01:31 UTC",
    "updated_date": "2024-02-20 06:01:31 UTC"
  },
  {
    "arxiv_id": "2402.14853v1",
    "title": "NL2Formula: Generating Spreadsheet Formulas from Natural Language Queries",
    "authors": [
      "Wei Zhao",
      "Zhitao Hou",
      "Siyuan Wu",
      "Yan Gao",
      "Haoyu Dong",
      "Yao Wan",
      "Hongyu Zhang",
      "Yulei Sui",
      "Haidong Zhang"
    ],
    "abstract": "Writing formulas on spreadsheets, such as Microsoft Excel and Google Sheets,\nis a widespread practice among users performing data analysis. However,\ncrafting formulas on spreadsheets remains a tedious and error-prone task for\nmany end-users, particularly when dealing with complex operations. To alleviate\nthe burden associated with writing spreadsheet formulas, this paper introduces\na novel benchmark task called NL2Formula, with the aim to generate executable\nformulas that are grounded on a spreadsheet table, given a Natural Language\n(NL) query as input. To accomplish this, we construct a comprehensive dataset\nconsisting of 70,799 paired NL queries and corresponding spreadsheet formulas,\ncovering 21,670 tables and 37 types of formula functions. We realize the\nNL2Formula task by providing a sequence-to-sequence baseline implementation\ncalled fCoder. Experimental results validate the effectiveness of fCoder,\ndemonstrating its superior performance compared to the baseline models.\nFurthermore, we also compare fCoder with an initial GPT-3.5 model (i.e.,\ntext-davinci-003). Lastly, through in-depth error analysis, we identify\npotential challenges in the NL2Formula task and advocate for further\ninvestigation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14853v1",
    "published_date": "2024-02-20 05:58:05 UTC",
    "updated_date": "2024-02-20 05:58:05 UTC"
  },
  {
    "arxiv_id": "2402.12733v1",
    "title": "BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation",
    "authors": [
      "Weixin Li",
      "Yuhao Wu",
      "Yang Liu",
      "Weike Pan",
      "Zhong Ming"
    ],
    "abstract": "In real recommendation scenarios, users often have different types of\nbehaviors, such as clicking and buying. Existing research methods show that it\nis possible to capture the heterogeneous interests of users through different\ntypes of behaviors. However, most multi-behavior approaches have limitations in\nlearning the relationship between different behaviors. In this paper, we\npropose a novel multilayer perceptron (MLP)-based heterogeneous sequential\nrecommendation method, namely behavior-aware multilayer perceptron (BMLP).\nSpecifically, it has two main modules, including a heterogeneous interest\nperception (HIP) module, which models behaviors at multiple granularities\nthrough behavior types and transition relationships, and a purchase intent\nperception (PIP) module, which adaptively fuses subsequences of auxiliary\nbehaviors to capture users' purchase intent. Compared with mainstream sequence\nmodels, MLP is competitive in terms of accuracy and has unique advantages in\nsimplicity and efficiency. Extensive experiments show that BMLP achieves\nsignificant improvement over state-of-the-art algorithms on four public\ndatasets. In addition, its pure MLP architecture leads to a linear time\ncomplexity.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12733v1",
    "published_date": "2024-02-20 05:57:01 UTC",
    "updated_date": "2024-02-20 05:57:01 UTC"
  },
  {
    "arxiv_id": "2402.12730v2",
    "title": "UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation",
    "authors": [
      "Shubhashis Roy Dipta",
      "Sai Vallurupalli"
    ],
    "abstract": "The aim of SemEval-2024 Task 1, \"Semantic Textual Relatedness for African and\nAsian Languages\" is to develop models for identifying semantic textual\nrelatedness (STR) between two sentences using multiple languages (14 African\nand Asian languages) and settings (supervised, unsupervised, and\ncross-lingual). Large language models (LLMs) have shown impressive performance\non several natural language understanding tasks such as multilingual machine\ntranslation (MMT), semantic similarity (STS), and encoding sentence embeddings.\nUsing a combination of LLMs that perform well on these tasks, we developed two\nSTR models, $\\textit{TranSem}$ and $\\textit{FineSem}$, for the supervised and\ncross-lingual settings. We explore the effectiveness of several training\nmethods and the usefulness of machine translation. We find that direct\nfine-tuning on the task is comparable to using sentence embeddings and\ntranslating to English leads to better performance for some languages. In the\nsupervised setting, our model performance is better than the official baseline\nfor 3 languages with the remaining 4 performing on par. In the cross-lingual\nsetting, our model performance is better than the baseline for 3 languages\n(leading to $1^{st}$ place for Africaans and $2^{nd}$ place for Indonesian), is\non par for 2 languages and performs poorly on the remaining 7 languages. Our\ncode is publicly available at https://github.com/dipta007/SemEval24-Task8.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SemEval 2024 (Colocated with NAACL 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.12730v2",
    "published_date": "2024-02-20 05:46:29 UTC",
    "updated_date": "2024-04-12 00:53:29 UTC"
  },
  {
    "arxiv_id": "2402.13297v1",
    "title": "Integrating Deep Learning and Synthetic Biology: A Co-Design Approach for Enhancing Gene Expression via N-terminal Coding Sequences",
    "authors": [
      "Zhanglu Yan",
      "Weiran Chu",
      "Yuhua Sheng",
      "Kaiwen Tang",
      "Shida Wang",
      "Yanfeng Liu",
      "Weng-Fai Wong"
    ],
    "abstract": "N-terminal coding sequence (NCS) influences gene expression by impacting the\ntranslation initiation rate. The NCS optimization problem is to find an NCS\nthat maximizes gene expression. The problem is important in genetic\nengineering. However, current methods for NCS optimization such as rational\ndesign and statistics-guided approaches are labor-intensive yield only\nrelatively small improvements. This paper introduces a deep learning/synthetic\nbiology co-designed few-shot training workflow for NCS optimization. Our method\nutilizes k-nearest encoding followed by word2vec to encode the NCS, then\nperforms feature extraction using attention mechanisms, before constructing a\ntime-series network for predicting gene expression intensity, and finally a\ndirect search algorithm identifies the optimal NCS with limited training data.\nWe took green fluorescent protein (GFP) expressed by Bacillus subtilis as a\nreporting protein of NCSs, and employed the fluorescence enhancement factor as\nthe metric of NCS optimization. Within just six iterative experiments, our\nmodel generated an NCS (MLD62) that increased average GFP expression by\n5.41-fold, outperforming the state-of-the-art NCS designs. Extending our\nfindings beyond GFP, we showed that our engineered NCS (MLD62) can effectively\nboost the production of N-acetylneuraminic acid by enhancing the expression of\nthe crucial rate-limiting GNA1 gene, demonstrating its practical utility. We\nhave open-sourced our NCS expression database and experimental procedures for\npublic use.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13297v1",
    "published_date": "2024-02-20 05:41:46 UTC",
    "updated_date": "2024-02-20 05:41:46 UTC"
  },
  {
    "arxiv_id": "2402.12729v1",
    "title": "Scalable and reliable deep transfer learning for intelligent fault detection via multi-scale neural processes embedded with knowledge",
    "authors": [
      "Zhongzhi Li",
      "Jingqi Tu",
      "Jiacheng Zhu",
      "Jianliang Ai",
      "Yiqun Dong"
    ],
    "abstract": "Deep transfer learning (DTL) is a fundamental method in the field of\nIntelligent Fault Detection (IFD). It aims to mitigate the degradation of\nmethod performance that arises from the discrepancies in data distribution\nbetween training set (source domain) and testing set (target domain).\nConsidering the fact that fault data collection is challenging and certain\nfaults are scarce, DTL-based methods face the limitation of available\nobservable data, which reduces the detection performance of the methods in the\ntarget domain. Furthermore, DTL-based methods lack comprehensive uncertainty\nanalysis that is essential for building reliable IFD systems. To address the\naforementioned problems, this paper proposes a novel DTL-based method known as\nNeural Processes-based deep transfer learning with graph convolution network\n(GTNP). Feature-based transfer strategy of GTNP bridges the data distribution\ndiscrepancies of source domain and target domain in high-dimensional space.\nBoth the joint modeling based on global and local latent variables and sparse\nsampling strategy reduce the demand of observable data in the target domain.\nThe multi-scale uncertainty analysis is obtained by using the distribution\ncharacteristics of global and local latent variables. Global analysis of\nuncertainty enables GTNP to provide quantitative values that reflect the\ncomplexity of methods and the difficulty of tasks. Local analysis of\nuncertainty allows GTNP to model uncertainty (confidence of the fault detection\nresult) at each sample affected by noise and bias. The validation of the\nproposed method is conducted across 3 IFD tasks, consistently showing the\nsuperior detection performance of GTNP compared to the other DTL-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12729v1",
    "published_date": "2024-02-20 05:39:32 UTC",
    "updated_date": "2024-02-20 05:39:32 UTC"
  },
  {
    "arxiv_id": "2402.12728v2",
    "title": "Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering",
    "authors": [
      "Junnan Dong",
      "Qinggang Zhang",
      "Huachi Zhou",
      "Daochen Zha",
      "Pai Zheng",
      "Xiao Huang"
    ],
    "abstract": "Knowledge-based visual question answering (KVQA) has been extensively studied\nto answer visual questions with external knowledge, e.g., knowledge graphs\n(KGs). While several attempts have been proposed to leverage large language\nmodels (LLMs) as an implicit knowledge source, it remains challenging since\nLLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g.,\nimages, KGs and LLMs, cannot be readily aligned for complex scenarios. To\ntackle these, we present a novel modality-aware integration with LLMs for KVQA\n(MAIL). It carefully leverages multimodal knowledge for both image\nunderstanding and knowledge reasoning. Specifically, (i) we propose a two-stage\nprompting strategy with LLMs to densely embody the image into a scene graph\nwith detailed visual features; (ii) We construct a coupled concept graph by\nlinking the mentioned entities with external facts. (iii) A tailored\npseudo-siamese graph medium fusion is designed for sufficient multimodal\nfusion. We utilize the shared mentioned entities in two graphs as mediums to\nbridge a tight inter-modal exchange, while maximally preserving insightful\nintra-modal learning by constraining the fusion within mediums. Extensive\nexperiments on two benchmark datasets show the superiority of MAIL with 24x\nless resources.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages,3 figures and 1 page appendix; The processed graphs and codes\n  will be avalibale",
    "pdf_url": "http://arxiv.org/pdf/2402.12728v2",
    "published_date": "2024-02-20 05:32:24 UTC",
    "updated_date": "2024-03-03 04:51:28 UTC"
  },
  {
    "arxiv_id": "2402.12727v1",
    "title": "Diffusion Posterior Sampling is Computationally Intractable",
    "authors": [
      "Shivam Gupta",
      "Ajil Jalal",
      "Aditya Parulekar",
      "Eric Price",
      "Zhiyang Xun"
    ],
    "abstract": "Diffusion models are a remarkably effective way of learning and sampling from\na distribution $p(x)$. In posterior sampling, one is also given a measurement\nmodel $p(y \\mid x)$ and a measurement $y$, and would like to sample from $p(x\n\\mid y)$. Posterior sampling is useful for tasks such as inpainting,\nsuper-resolution, and MRI reconstruction, so a number of recent works have\ngiven algorithms to heuristically approximate it; but none are known to\nconverge to the correct distribution in polynomial time.\n  In this paper we show that posterior sampling is \\emph{computationally\nintractable}: under the most basic assumption in cryptography -- that one-way\nfunctions exist -- there are instances for which \\emph{every} algorithm takes\nsuperpolynomial time, even though \\emph{unconditional} sampling is provably\nfast. We also show that the exponential-time rejection sampling algorithm is\nessentially optimal under the stronger plausible assumption that there are\none-way functions that take exponential time to invert.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12727v1",
    "published_date": "2024-02-20 05:28:13 UTC",
    "updated_date": "2024-02-20 05:28:13 UTC"
  },
  {
    "arxiv_id": "2402.12721v4",
    "title": "PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images",
    "authors": [
      "Jinsung Jeon",
      "Hyundong Jin",
      "Jonghyun Choi",
      "Sanghyun Hong",
      "Dongeun Lee",
      "Kookjin Lee",
      "Noseong Park"
    ],
    "abstract": "A standard practice in developing image recognition models is to train a\nmodel on a specific image resolution and then deploy it. However, in real-world\ninference, models often encounter images different from the training sets in\nresolution and/or subject to natural variations such as weather changes, noise\ntypes and compression artifacts. While traditional solutions involve training\nmultiple models for different resolutions or input variations, these methods\nare computationally expensive and thus do not scale in practice. To this end,\nwe propose a novel neural network model, parallel-structured and all-component\nFourier neural operator (PAC-FNO), that addresses the problem. Unlike\nconventional feed-forward neural networks, PAC-FNO operates in the frequency\ndomain, allowing it to handle images of varying resolutions within a single\nmodel. We also propose a two-stage algorithm for training PAC-FNO with a\nminimal modification to the original, downstream model. Moreover, the proposed\nPAC-FNO is ready to work with existing image recognition models. Extensively\nevaluating methods with seven image recognition benchmarks, we show that the\nproposed PAC-FNO improves the performance of existing baseline models on images\nwith various resolutions by up to 77.1% and various types of natural variations\nin the images at inference.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12721v4",
    "published_date": "2024-02-20 05:06:20 UTC",
    "updated_date": "2024-03-14 04:41:03 UTC"
  },
  {
    "arxiv_id": "2402.12720v1",
    "title": "Revisiting the Information Capacity of Neural Network Watermarks: Upper Bound Estimation and Beyond",
    "authors": [
      "Fangqi Li",
      "Haodong Zhao",
      "Wei Du",
      "Shilin Wang"
    ],
    "abstract": "To trace the copyright of deep neural networks, an owner can embed its\nidentity information into its model as a watermark. The capacity of the\nwatermark quantify the maximal volume of information that can be verified from\nthe watermarked model. Current studies on capacity focus on the ownership\nverification accuracy under ordinary removal attacks and fail to capture the\nrelationship between robustness and fidelity. This paper studies the capacity\nof deep neural network watermarks from an information theoretical perspective.\nWe propose a new definition of deep neural network watermark capacity analogous\nto channel capacity, analyze its properties, and design an algorithm that\nyields a tight estimation of its upper bound under adversarial overwriting. We\nalso propose a universal non-invasive method to secure the transmission of the\nidentity message beyond capacity by multiple rounds of ownership verification.\nOur observations provide evidence for neural network owners and defenders that\nare curious about the tradeoff between the integrity of their ownership and the\nperformance degradation of their products.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12720v1",
    "published_date": "2024-02-20 05:05:28 UTC",
    "updated_date": "2024-02-20 05:05:28 UTC"
  },
  {
    "arxiv_id": "2403.00788v1",
    "title": "PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care",
    "authors": [
      "Satvik Tripathi",
      "Liam Mutter",
      "Meghana Muppuri",
      "Suhani Dheer",
      "Emiliano Garza-Frias",
      "Komal Awan",
      "Aakash Jha",
      "Michael Dezube",
      "Azadeh Tabari",
      "Christopher P. Bridge",
      "Dania Daye"
    ],
    "abstract": "This study introduces and evaluates the PRECISE framework, utilizing OpenAI's\nGPT-4 to enhance patient engagement by providing clearer and more accessible\nchest X-ray reports at a sixth-grade reading level. The framework was tested on\n500 reports, demonstrating significant improvements in readability,\nreliability, and understandability. Statistical analyses confirmed the\neffectiveness of the PRECISE approach, highlighting its potential to foster\npatient-centric care delivery in healthcare decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00788v1",
    "published_date": "2024-02-20 04:26:31 UTC",
    "updated_date": "2024-02-20 04:26:31 UTC"
  },
  {
    "arxiv_id": "2402.14852v1",
    "title": "HumanEval on Latest GPT Models -- 2024",
    "authors": [
      "Daniel Li",
      "Lincoln Murr"
    ],
    "abstract": "In 2023, we are using the latest models of GPT-4 to advance program\nsynthesis. The large language models have significantly improved the\nstate-of-the-art for this purpose. To make these advancements more accessible,\nwe have created a repository that connects these models to Huamn Eval. This\ndataset was initally developed to be used with a language model called CODEGEN\non natural and programming language data. The utility of these trained models\nis showcased by demonstrating their competitive performance in zero-shot Python\ncode generation on HumanEval tasks compared to previous state-of-the-art\nsolutions. Additionally, this gives way to developing more multi-step paradigm\nsynthesis. This benchmark features 160 diverse problem sets factorized into\nmultistep prompts that our analysis shows significantly improves program\nsynthesis over single-turn inputs. All code is open source at\nhttps://github.com/daniel442li/gpt-human-eval .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14852v1",
    "published_date": "2024-02-20 04:17:21 UTC",
    "updated_date": "2024-02-20 04:17:21 UTC"
  },
  {
    "arxiv_id": "2402.12702v2",
    "title": "From Cloud to Edge: Rethinking Generative AI for Low-Resource Design Challenges",
    "authors": [
      "Sai Krishna Revanth Vuruma",
      "Ashley Margetts",
      "Jianhai Su",
      "Faez Ahmed",
      "Biplav Srivastava"
    ],
    "abstract": "Generative Artificial Intelligence (AI) has shown tremendous prospects in all\naspects of technology, including design. However, due to its heavy demand on\nresources, it is usually trained on large computing infrastructure and often\nmade available as a cloud-based service. In this position paper, we consider\nthe potential, challenges, and promising approaches for generative AI for\ndesign on the edge, i.e., in resource-constrained settings where memory,\ncompute, energy (battery) and network connectivity may be limited. Adapting\ngenerative AI for such settings involves overcoming significant hurdles,\nprimarily in how to streamline complex models to function efficiently in\nlow-resource environments. This necessitates innovative approaches in model\ncompression, efficient algorithmic design, and perhaps even leveraging edge\ncomputing. The objective is to harness the power of generative AI in creating\nbespoke solutions for design problems, such as medical interventions, farm\nequipment maintenance, and educational material design, tailored to the unique\nconstraints and needs of remote areas. These efforts could democratize access\nto advanced technology and foster sustainable development, ensuring universal\naccessibility and environmental consideration of AI-driven design benefits.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for the Artificial Intelligence for Design Problems bridge\n  program at AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12702v2",
    "published_date": "2024-02-20 03:59:27 UTC",
    "updated_date": "2024-02-26 00:23:45 UTC"
  },
  {
    "arxiv_id": "2402.14851v2",
    "title": "$R^3$: \"This is My SQL, Are You With Me?\" A Consensus-Based Multi-Agent System for Text-to-SQL Tasks",
    "authors": [
      "Hanchen Xia",
      "Feng Jiang",
      "Naihao Deng",
      "Cunxiang Wang",
      "Guojiang Zhao",
      "Rada Mihalcea",
      "Yue Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong performance on various\ntasks. To unleash their power on the Text-to-SQL task, we propose $R^3$\n(Review-Rebuttal-Revision), a consensus-based multi-agent system for\nText-to-SQL tasks. $R^3$ outperforms the existing single LLM Text-to-SQL\nsystems as well as the multi-agent Text-to-SQL systems by $1.3\\%$ to $8.1\\%$ on\nSpider and Bird. Surprisingly, we find that for Llama-3-8B, $R^3$ outperforms\nchain-of-thought prompting by over 20\\%, even outperforming GPT-3.5 on the\ndevelopment set of Spider.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 2 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.14851v2",
    "published_date": "2024-02-20 03:57:55 UTC",
    "updated_date": "2024-07-11 03:14:54 UTC"
  },
  {
    "arxiv_id": "2402.12685v1",
    "title": "XRL-Bench: A Benchmark for Evaluating and Comparing Explainable Reinforcement Learning Techniques",
    "authors": [
      "Yu Xiong",
      "Zhipeng Hu",
      "Ye Huang",
      "Runze Wu",
      "Kai Guan",
      "Xingchen Fang",
      "Ji Jiang",
      "Tianze Zhou",
      "Yujing Hu",
      "Haoyu Liu",
      "Tangjie Lyu",
      "Changjie Fan"
    ],
    "abstract": "Reinforcement Learning (RL) has demonstrated substantial potential across\ndiverse fields, yet understanding its decision-making process, especially in\nreal-world scenarios where rationality and safety are paramount, is an ongoing\nchallenge. This paper delves in to Explainable RL (XRL), a subfield of\nExplainable AI (XAI) aimed at unravelling the complexities of RL models. Our\nfocus rests on state-explaining techniques, a crucial subset within XRL\nmethods, as they reveal the underlying factors influencing an agent's actions\nat any given time. Despite their significant role, the lack of a unified\nevaluation framework hinders assessment of their accuracy and effectiveness. To\naddress this, we introduce XRL-Bench, a unified standardized benchmark tailored\nfor the evaluation and comparison of XRL methods, encompassing three main\nmodules: standard RL environments, explainers based on state importance, and\nstandard evaluators. XRL-Bench supports both tabular and image data for state\nexplanation. We also propose TabularSHAP, an innovative and competitive XRL\nmethod. We demonstrate the practical utility of TabularSHAP in real-world\nonline gaming services and offer an open-source benchmark platform for the\nstraightforward implementation and evaluation of XRL methods. Our contributions\nfacilitate the continued progression of XRL technology.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.12685v1",
    "published_date": "2024-02-20 03:20:37 UTC",
    "updated_date": "2024-02-20 03:20:37 UTC"
  },
  {
    "arxiv_id": "2402.14029v3",
    "title": "Partially Frozen Random Networks Contain Compact Strong Lottery Tickets",
    "authors": [
      "Hikari Otsuka",
      "Daiki Chijiwa",
      "Ángel López García-Arias",
      "Yasuyuki Okoshi",
      "Kazushi Kawamura",
      "Thiem Van Chu",
      "Daichi Fujiki",
      "Susumu Takeuchi",
      "Masato Motomura"
    ],
    "abstract": "Randomly initialized dense networks contain subnetworks that achieve high\naccuracy without weight learning--strong lottery tickets (SLTs). Recently,\nGadhikar et al. (2023) demonstrated that SLTs could also be found within a\nrandomly pruned source network. This phenomenon can be exploited to further\ncompress the small memory size required by SLTs. However, their method is\nlimited to SLTs that are even sparser than the source, leading to worse\naccuracy due to unintentionally high sparsity. This paper proposes a method for\nreducing the SLT memory size without restricting the sparsity of the SLTs that\ncan be found. A random subset of the initial weights is frozen by either\npermanently pruning them or locking them as a fixed part of the SLT, resulting\nin a smaller model size. Experimental results show that Edge-Popup (Ramanujan\net al., 2020; Sreenivasan et al., 2022) finds SLTs with better\naccuracy-to-model size trade-off within frozen networks than within dense or\nrandomly pruned source networks. In particular, freezing $70\\%$ of a ResNet on\nImageNet provides $3.3 \\times$ compression compared to the SLT found within a\ndense counterpart, raises accuracy by up to $14.12$ points compared to the SLT\nfound within a randomly pruned counterpart, and offers a better accuracy-model\nsize trade-off than both.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at TMLR",
    "pdf_url": "http://arxiv.org/pdf/2402.14029v3",
    "published_date": "2024-02-20 03:14:45 UTC",
    "updated_date": "2025-02-08 05:48:57 UTC"
  },
  {
    "arxiv_id": "2402.12659v2",
    "title": "FinBen: A Holistic Financial Benchmark for Large Language Models",
    "authors": [
      "Qianqian Xie",
      "Weiguang Han",
      "Zhengyu Chen",
      "Ruoyu Xiang",
      "Xiao Zhang",
      "Yueru He",
      "Mengxi Xiao",
      "Dong Li",
      "Yongfu Dai",
      "Duanyu Feng",
      "Yijing Xu",
      "Haoqiang Kang",
      "Ziyan Kuang",
      "Chenhan Yuan",
      "Kailai Yang",
      "Zheheng Luo",
      "Tianlin Zhang",
      "Zhiwei Liu",
      "Guojun Xiong",
      "Zhiyang Deng",
      "Yuechen Jiang",
      "Zhiyuan Yao",
      "Haohang Li",
      "Yangyang Yu",
      "Gang Hu",
      "Jiajia Huang",
      "Xiao-Yang Liu",
      "Alejandro Lopez-Lira",
      "Benyou Wang",
      "Yanzhao Lai",
      "Hao Wang",
      "Min Peng",
      "Sophia Ananiadou",
      "Jimin Huang"
    ],
    "abstract": "LLMs have transformed NLP and shown promise in various fields, yet their\npotential in finance is underexplored due to a lack of comprehensive evaluation\nbenchmarks, the rapid development of LLMs, and the complexity of financial\ntasks. In this paper, we introduce FinBen, the first extensive open-source\nevaluation benchmark, including 36 datasets spanning 24 financial tasks,\ncovering seven critical aspects: information extraction (IE), textual analysis,\nquestion answering (QA), text generation, risk management, forecasting, and\ndecision-making. FinBen offers several key innovations: a broader range of\ntasks and datasets, the first evaluation of stock trading, novel agent and\nRetrieval-Augmented Generation (RAG) evaluation, and three novel open-source\nevaluation datasets for text summarization, question answering, and stock\ntrading. Our evaluation of 15 representative LLMs, including GPT-4, ChatGPT,\nand the latest Gemini, reveals several key findings: While LLMs excel in IE and\ntextual analysis, they struggle with advanced reasoning and complex tasks like\ntext generation and forecasting. GPT-4 excels in IE and stock trading, while\nGemini is better at text generation and forecasting. Instruction-tuned LLMs\nimprove textual analysis but offer limited benefits for complex tasks such as\nQA. FinBen has been used to host the first financial LLMs shared task at the\nFinNLP-AgentScen workshop during IJCAI-2024, attracting 12 teams. Their novel\nsolutions outperformed GPT-4, showcasing FinBen's potential to drive innovation\nin financial LLMs. All datasets, results, and codes are released for the\nresearch community: https://github.com/The-FinAI/PIXIU.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.12659v2",
    "published_date": "2024-02-20 02:16:16 UTC",
    "updated_date": "2024-06-19 03:38:56 UTC"
  },
  {
    "arxiv_id": "2402.12656v4",
    "title": "HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts",
    "authors": [
      "Hao Zhao",
      "Zihan Qiu",
      "Huijia Wu",
      "Zili Wang",
      "Zhaofeng He",
      "Jie Fu"
    ],
    "abstract": "The Mixture of Experts (MoE) for language models has been proven effective in\naugmenting the capacity of models by dynamically routing each input token to a\nspecific subset of experts for processing. Despite the success, most existing\nmethods face a challenge for balance between sparsity and the availability of\nexpert knowledge: enhancing performance through increased use of expert\nknowledge often results in diminishing sparsity during expert selection. To\nmitigate this contradiction, we propose HyperMoE, a novel MoE framework built\nupon Hypernetworks. This framework integrates the computational processes of\nMoE with the concept of knowledge transferring in multi-task learning. Specific\nmodules generated based on the information of unselected experts serve as\nsupplementary information, which allows the knowledge of experts not selected\nto be used while maintaining selection sparsity. Our comprehensive empirical\nevaluations across multiple datasets and backbones establish that HyperMoE\nsignificantly outperforms existing MoE methods under identical conditions\nconcerning the number of experts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12656v4",
    "published_date": "2024-02-20 02:09:55 UTC",
    "updated_date": "2024-07-25 06:28:01 UTC"
  },
  {
    "arxiv_id": "2402.14850v2",
    "title": "CHATATC: Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management",
    "authors": [
      "Sinan Abdulhak",
      "Wayne Hubbard",
      "Karthik Gopalakrishnan",
      "Max Z. Li"
    ],
    "abstract": "Generative artificial intelligence (AI) and large language models (LLMs) have\ngained rapid popularity through publicly available tools such as ChatGPT. The\nadoption of LLMs for personal and professional use is fueled by the natural\ninteractions between human users and computer applications such as ChatGPT,\nalong with powerful summarization and text generation capabilities. Given the\nwidespread use of such generative AI tools, in this work we investigate how\nthese tools can be deployed in a non-safety critical, strategic traffic flow\nmanagement setting. Specifically, we train an LLM, CHATATC, based on a large\nhistorical data set of Ground Delay Program (GDP) issuances, spanning 2000-2023\nand consisting of over 80,000 GDP implementations, revisions, and\ncancellations. We test the query and response capabilities of CHATATC,\ndocumenting successes (e.g., providing correct GDP rates, durations, and\nreason) and shortcomings (e.g,. superlative questions). We also detail the\ndesign of a graphical user interface for future users to interact and\ncollaborate with the CHATATC conversational agent.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures; minor revisions to address reviewer feedback for\n  final submission to the 11th International Conference on Research in Air\n  Transportation (ICRAT)",
    "pdf_url": "http://arxiv.org/pdf/2402.14850v2",
    "published_date": "2024-02-20 01:59:11 UTC",
    "updated_date": "2024-07-24 02:11:47 UTC"
  },
  {
    "arxiv_id": "2402.12646v1",
    "title": "Training Artificial Neural Networks by Coordinate Search Algorithm",
    "authors": [
      "Ehsan Rokhsatyazdi",
      "Shahryar Rahnamayan",
      "Sevil Zanjani Miyandoab",
      "Azam Asilian Bidgoli",
      "H. R. Tizhoosh"
    ],
    "abstract": "Training Artificial Neural Networks poses a challenging and critical problem\nin machine learning. Despite the effectiveness of gradient-based learning\nmethods, such as Stochastic Gradient Descent (SGD), in training neural\nnetworks, they do have several limitations. For instance, they require\ndifferentiable activation functions, and cannot optimize a model based on\nseveral independent non-differentiable loss functions simultaneously; for\nexample, the F1-score, which is used during testing, can be used during\ntraining when a gradient-free optimization algorithm is utilized. Furthermore,\nthe training in any DNN can be possible with a small size of the training\ndataset. To address these concerns, we propose an efficient version of the\ngradient-free Coordinate Search (CS) algorithm, an instance of General Pattern\nSearch methods, for training neural networks. The proposed algorithm can be\nused with non-differentiable activation functions and tailored to\nmulti-objective/multi-loss problems. Finding the optimal values for weights of\nANNs is a large-scale optimization problem. Therefore instead of finding the\noptimal value for each variable, which is the common technique in classical CS,\nwe accelerate optimization and convergence by bundling the weights. In fact,\nthis strategy is a form of dimension reduction for optimization problems. Based\non the experimental results, the proposed method, in some cases, outperforms\nthe gradient-based approach, particularly, in situations with insufficient\nlabeled training data. The performance plots demonstrate a high convergence\nrate, highlighting the capability of our suggested method to find a reasonable\nsolution with fewer function calls. As of now, the only practical and efficient\nway of training ANNs with hundreds of thousands of weights is gradient-based\nalgorithms such as SGD or Adam. In this paper we introduce an alternative\nmethod for training ANN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.12646v1",
    "published_date": "2024-02-20 01:47:25 UTC",
    "updated_date": "2024-02-20 01:47:25 UTC"
  },
  {
    "arxiv_id": "2402.12627v1",
    "title": "A Comprehensive Review of Machine Learning Advances on Data Change: A Cross-Field Perspective",
    "authors": [
      "Jeng-Lin Li",
      "Chih-Fan Hsu",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "abstract": "Recent artificial intelligence (AI) technologies show remarkable evolution in\nvarious academic fields and industries. However, in the real world, dynamic\ndata lead to principal challenges for deploying AI models. An unexpected data\nchange brings about severe performance degradation in AI models. We identify\ntwo major related research fields, domain shift and concept drift according to\nthe setting of the data change. Although these two popular research fields aim\nto solve distribution shift and non-stationary data stream problems, the\nunderlying properties remain similar which also encourages similar technical\napproaches. In this review, we regroup domain shift and concept drift into a\nsingle research problem, namely the data change problem, with a systematic\noverview of state-of-the-art methods in the two research fields. We propose a\nthree-phase problem categorization scheme to link the key ideas in the two\ntechnical fields. We thus provide a novel scope for researchers to explore\ncontemporary technical strategies, learn industrial applications, and identify\nfuture directions for addressing data change challenges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12627v1",
    "published_date": "2024-02-20 01:16:01 UTC",
    "updated_date": "2024-02-20 01:16:01 UTC"
  },
  {
    "arxiv_id": "2402.12624v1",
    "title": "Efficient Parameter Mining and Freezing for Continual Object Detection",
    "authors": [
      "Angelo G. Menezes",
      "Augusto J. Peterlevitz",
      "Mateus A. Chinelatto",
      "André C. P. L. F. de Carvalho"
    ],
    "abstract": "Continual Object Detection is essential for enabling intelligent agents to\ninteract proactively with humans in real-world settings. While\nparameter-isolation strategies have been extensively explored in the context of\ncontinual learning for classification, they have yet to be fully harnessed for\nincremental object detection scenarios. Drawing inspiration from prior research\nthat focused on mining individual neuron responses and integrating insights\nfrom recent developments in neural pruning, we proposed efficient ways to\nidentify which layers are the most important for a network to maintain the\nperformance of a detector across sequential updates. The presented findings\nhighlight the substantial advantages of layer-level parameter isolation in\nfacilitating incremental learning within object detection models, offering\npromising avenues for future research and application in real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "In Proceedings of the 19th International Joint Conference on Computer\n  Vision, Imaging and Computer Graphics Theory and Applications - Volume 2:\n  VISAPP, ISBN 978-989-758-679-8, ISSN 2184-4321, pages 466-474",
    "pdf_url": "http://arxiv.org/pdf/2402.12624v1",
    "published_date": "2024-02-20 01:07:32 UTC",
    "updated_date": "2024-02-20 01:07:32 UTC"
  },
  {
    "arxiv_id": "2402.12617v2",
    "title": "Generative AI Security: Challenges and Countermeasures",
    "authors": [
      "Banghua Zhu",
      "Norman Mu",
      "Jiantao Jiao",
      "David Wagner"
    ],
    "abstract": "Generative AI's expanding footprint across numerous industries has led to\nboth excitement and increased scrutiny. This paper delves into the unique\nsecurity challenges posed by Generative AI, and outlines potential research\ndirections for managing these risks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12617v2",
    "published_date": "2024-02-20 00:51:05 UTC",
    "updated_date": "2024-10-23 06:28:19 UTC"
  },
  {
    "arxiv_id": "2402.12608v1",
    "title": "Patient-Centric Knowledge Graphs: A Survey of Current Methods, Challenges, and Applications",
    "authors": [
      "Hassan S. Al Khatib",
      "Subash Neupane",
      "Harish Kumar Manchukonda",
      "Noorbakhsh Amiri Golilarz",
      "Sudip Mittal",
      "Amin Amirlatifi",
      "Shahram Rahimi"
    ],
    "abstract": "Patient-Centric Knowledge Graphs (PCKGs) represent an important shift in\nhealthcare that focuses on individualized patient care by mapping the patient's\nhealth information in a holistic and multi-dimensional way. PCKGs integrate\nvarious types of health data to provide healthcare professionals with a\ncomprehensive understanding of a patient's health, enabling more personalized\nand effective care. This literature review explores the methodologies,\nchallenges, and opportunities associated with PCKGs, focusing on their role in\nintegrating disparate healthcare data and enhancing patient care through a\nunified health perspective. In addition, this review also discusses the\ncomplexities of PCKG development, including ontology design, data integration\ntechniques, knowledge extraction, and structured representation of knowledge.\nIt highlights advanced techniques such as reasoning, semantic search, and\ninference mechanisms essential in constructing and evaluating PCKGs for\nactionable healthcare insights. We further explore the practical applications\nof PCKGs in personalized medicine, emphasizing their significance in improving\ndisease prediction and formulating effective treatment plans. Overall, this\nreview provides a foundational perspective on the current state-of-the-art and\nbest practices of PCKGs, guiding future research and applications in this\ndynamic field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12608v1",
    "published_date": "2024-02-20 00:07:55 UTC",
    "updated_date": "2024-02-20 00:07:55 UTC"
  }
]