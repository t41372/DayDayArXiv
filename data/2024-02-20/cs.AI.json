{
  "date": "2024-02-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-20 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，特别是大语言模型（LLM）的应用与优化、生成模型的安全性、多模态处理以及特定领域的基准数据集，令人印象深刻的包括 Google 团队的 VideoPrism 用于视频理解，以及 LLM 在医疗和知识编辑中的创新应用。\n\n### 重点论文讨论\n我们挑选了今天论文中具有高影响力、创新性和话题度的几篇进行简要分析，先从 LLM 相关的高影响力工作入手，再扩展到生成模型和医疗应用。其他论文如一些纯理论或小众主题（如特定算法优化），我们快速掠过，仅提及核心点。\n\n1. **VideoPrism: A Foundational Visual Encoder for Video Understanding** (VideoPrism: 视频理解的基础视觉编码器)  \n   这篇由 Google 研究团队主导的论文提出 VideoPrism，一种通用视频编码器，通过在 36M 高质量视频-描述对上预训练，显著提升了视频理解任务的性能。论文的主要贡献是处理多样化视频任务（如问答和分类），在 33 个基准上实现 SOTA，并在非线性系统预测中表现出色，强调了大规模预训练的潜力。\n\n2. **The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative** (The Wolf Within: 通过 MLLM 操作员向多模态大语言模型社会注入恶意)  \n   论文探讨多模态 LLM（MLLM）的安全漏洞，展示了如何通过一个受操控的 MLLM 代理间接传播恶意内容。关键发现是 MLLM 间的通信易受攻击，导致有害输出传播；这为 MLLM 的鲁棒性设计提供了新洞见，呼吁开发检测机制。\n\n3. **DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain** (DrBenchmark: 法语生物医学领域的语言理解评估基准)  \n   这篇论文引入 DrBenchmark，首个公开的法语生物医学基准数据集，包含 20 个任务如命名实体识别和问答。贡献在于评估 8 个 LLM 在法语特定领域的表现，发现通用模型在某些任务上仍具竞争力，但无一模型全面优越；这有助于法语 LLM 的改进。\n\n4. **LinkSAGE: Optimizing Job Matching Using Graph Neural Networks** (LinkSAGE: 使用图神经网络优化工作匹配)  \n   论文提出 LinkSAGE 框架，利用图神经网络（GNN）优化 LinkedIn 的工作匹配系统，通过异构图学习提升相关性和用户参与。关键发现是 GNN 的编码-解码方法在海量网络中实现实时信号整合，并在 A/B 测试中显著提高用户保留率。\n\n5. **AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning** (AgentMD: 使用大规模临床工具学习增强语言代理的风险预测)  \n   这篇医疗 AI 论文开发 AgentMD 框架，使用 LLM 整合 2000+ 临床计算器进行风险预测。贡献在于从文献中自动提取工具并应用于患者数据，显著提升预测准确性，并在风险评估基准上超越 GPT-4；这为 AI 在医疗决策中的应用提供了实用路径。\n\n6. **Me LLaMA: Foundation Large Language Models for Medical Applications** (Me LLaMA: 医疗应用的基礎大语言模型)  \n   论文构建 Me LLaMA 系列模型，通过在生物医学数据上微调 LLaMA，提升医疗任务性能。发现该模型在 6 个医疗基准上超越 GPT-4，尤其在文本分析和诊断中表现出色；这强调了领域特定数据的重要性。\n\n其他论文如纯强化学习或小众优化方法（如 \"Efficient Parameter Mining\" 或 \"CST\"），我们快速掠过：它们主要贡献于算法效率提升，但影响力较小，仅在特定子领域有应用价值。今天总计 119 篇论文，AI 生成和 LLM 安全主题占比高，建议关注这些前沿方向以捕捉实际应用潜力。明日见！",
  "papers": [
    {
      "arxiv_id": "2403.18946v1",
      "title": "Random Aggregate Beamforming for Over-the-Air Federated Learning in Large-Scale Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Chunmei Xu",
        "Shengheng Liu",
        "Yongming Huang",
        "Bjorn Ottersten",
        "Dusit Niyato"
      ],
      "abstract": "At present, there is a trend to deploy ubiquitous artificial intelligence\n(AI) applications at the edge of the network. As a promising framework that\nenables secure edge intelligence, federated learning (FL) has received\nwidespread attention, and over-the-air computing (AirComp) has been integrated\nto further improve the communication efficiency. In this paper, we consider a\njoint device selection and aggregate beamforming design with the objectives of\nminimizing the aggregate error and maximizing the number of selected devices.\nThis yields a combinatorial problem, which is difficult to solve especially in\nlarge-scale networks. To tackle the problems in a cost-effective manner, we\npropose a random aggregate beamforming-based scheme, which generates the\naggregator beamforming vector via random sampling rather than optimization. The\nimplementation of the proposed scheme does not require the channel estimation.\nWe additionally use asymptotic analysis to study the obtained aggregate error\nand the number of the selected devices when the number of devices becomes\nlarge. Furthermore, a refined method that runs with multiple randomizations is\nalso proposed for performance improvement. Extensive simulation results are\npresented to demonstrate the effectiveness of the proposed random aggregate\nbeamforming-based scheme as well as the refined method.",
      "tldr_zh": "本文提出了一种Random Aggregate Beamforming方案，用于Over-the-Air Federated Learning (FL)在大规模网络中的应用，旨在最小化聚合错误并最大化选定设备数量。该方案通过随机采样生成聚合波束向量，而非优化方法，从而避免了信道估计的需求，并结合渐近分析评估聚合错误和选定设备规模。作者还引入了一个通过多次随机化的精炼方法来进一步提升性能。模拟结果证明，该方案在通信效率和整体效果上显著优于传统基线。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "30 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.18946v1",
      "published_date": "2024-02-20 23:59:45 UTC",
      "updated_date": "2024-02-20 23:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:05:10.388960"
    },
    {
      "arxiv_id": "2402.13432v1",
      "title": "DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Yanis Labrak",
        "Adrien Bazoge",
        "Oumaima El Khettari",
        "Mickael Rouvier",
        "Pacome Constant dit Beaufils",
        "Natalia Grabar",
        "Beatrice Daille",
        "Solen Quiniou",
        "Emmanuel Morin",
        "Pierre-Antoine Gourraud",
        "Richard Dufour"
      ],
      "abstract": "The biomedical domain has sparked a significant interest in the field of\nNatural Language Processing (NLP), which has seen substantial advancements with\npre-trained language models (PLMs). However, comparing these models has proven\nchallenging due to variations in evaluation protocols across different models.\nA fair solution is to aggregate diverse downstream tasks into a benchmark,\nallowing for the assessment of intrinsic PLMs qualities from various\nperspectives. Although still limited to few languages, this initiative has been\nundertaken in the biomedical field, notably English and Chinese. This\nlimitation hampers the evaluation of the latest French biomedical models, as\nthey are either assessed on a minimal number of tasks with non-standardized\nprotocols or evaluated using general downstream tasks. To bridge this research\ngap and account for the unique sensitivities of French, we present the\nfirst-ever publicly available French biomedical language understanding\nbenchmark called DrBenchmark. It encompasses 20 diversified tasks, including\nnamed-entity recognition, part-of-speech tagging, question-answering, semantic\ntextual similarity, and classification. We evaluate 8 state-of-the-art\npre-trained masked language models (MLMs) on general and biomedical-specific\ndata, as well as English specific MLMs to assess their cross-lingual\ncapabilities. Our experiments reveal that no single model excels across all\ntasks, while generalist models are sometimes still competitive.",
      "tldr_zh": "本研究针对法语生物医学领域的自然语言处理（NLP），提出了第一个公开基准 DrBenchmark，以解决预训练语言模型（PLMs）评估协议不统一的问题。该基准涵盖20个多样化任务，包括命名实体识别（named-entity recognition）、词性标注（part-of-speech tagging）、问答（question-answering）、语义文本相似性（semantic textual similarity）和分类任务。作者评估了8个最先进的预训练掩码语言模型（MLMs），包括通用和生物医学特定模型，以及英语模型的跨语言能力；结果显示，没有单一模型在所有任务中表现出色，而通用模型有时仍具竞争力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-Coling 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13432v1",
      "published_date": "2024-02-20 23:54:02 UTC",
      "updated_date": "2024-02-20 23:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:05:22.373350"
    },
    {
      "arxiv_id": "2402.13430v1",
      "title": "LinkSAGE: Optimizing Job Matching Using Graph Neural Networks",
      "title_zh": "LinkSAGE: 使用图神经网络优化工作匹配",
      "authors": [
        "Ping Liu",
        "Haichao Wei",
        "Xiaochen Hou",
        "Jianqiang Shen",
        "Shihai He",
        "Kay Qianqi Shen",
        "Zhujun Chen",
        "Fedor Borisyuk",
        "Daniel Hewlett",
        "Liang Wu",
        "Srikant Veeraraghavan",
        "Alex Tsun",
        "Chengming Jiang",
        "Wenjing Zhang"
      ],
      "abstract": "We present LinkSAGE, an innovative framework that integrates Graph Neural\nNetworks (GNNs) into large-scale personalized job matching systems, designed to\naddress the complex dynamics of LinkedIns extensive professional network. Our\napproach capitalizes on a novel job marketplace graph, the largest and most\nintricate of its kind in industry, with billions of nodes and edges. This graph\nis not merely extensive but also richly detailed, encompassing member and job\nnodes along with key attributes, thus creating an expansive and interwoven\nnetwork. A key innovation in LinkSAGE is its training and serving methodology,\nwhich effectively combines inductive graph learning on a heterogeneous,\nevolving graph with an encoder-decoder GNN model. This methodology decouples\nthe training of the GNN model from that of existing Deep Neural Nets (DNN)\nmodels, eliminating the need for frequent GNN retraining while maintaining\nup-to-date graph signals in near realtime, allowing for the effective\nintegration of GNN insights through transfer learning. The subsequent nearline\ninference system serves the GNN encoder within a real-world setting,\nsignificantly reducing online latency and obviating the need for costly\nreal-time GNN infrastructure. Validated across multiple online A/B tests in\ndiverse product scenarios, LinkSAGE demonstrates marked improvements in member\nengagement, relevance matching, and member retention, confirming its\ngeneralizability and practical impact.",
      "tldr_zh": "本文提出 LinkSAGE 框架，利用 Graph Neural Networks (GNNs) 优化 LinkedIn 的规模化个性化职位匹配系统，通过构建一个包含数十亿节点的异构职位市场图来捕捉复杂的专业网络动态。创新点在于其训练和服务方法，将归纳图学习与编码器-解码器 GNN 模型相结合，并与现有 Deep Neural Nets (DNNs) 模型解耦，避免频繁重训的同时实现实时图信号更新和低延迟推理。在多个在线 A/B 测试中，LinkSAGE 显著提升了成员参与度、相关性匹配和成员保留率，展示了其在实际场景中的泛化性和实际影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13430v1",
      "published_date": "2024-02-20 23:49:25 UTC",
      "updated_date": "2024-02-20 23:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:05:35.090983"
    },
    {
      "arxiv_id": "2402.13427v1",
      "title": "Quantitative causality, causality-guided scientific discovery, and causal machine learning",
      "title_zh": "翻译失败",
      "authors": [
        "X. San Liang",
        "Dake Chen",
        "Renhe Zhang"
      ],
      "abstract": "It has been said, arguably, that causality analysis should pave a promising\nway to interpretable deep learning and generalization. Incorporation of\ncausality into artificial intelligence (AI) algorithms, however, is challenged\nwith its vagueness, non-quantitiveness, computational inefficiency, etc. During\nthe past 18 years, these challenges have been essentially resolved, with the\nestablishment of a rigorous formalism of causality analysis initially motivated\nfrom atmospheric predictability. This not only opens a new field in the\natmosphere-ocean science, namely, information flow, but also has led to\nscientific discoveries in other disciplines, such as quantum mechanics,\nneuroscience, financial economics, etc., through various applications. This\nnote provides a brief review of the decade-long effort, including a list of\nmajor theoretical results, a sketch of the causal deep learning framework, and\nsome representative real-world applications in geoscience pertaining to this\njournal, such as those on the anthropogenic cause of global warming, the\ndecadal prediction of El Ni\\~no Modoki, the forecasting of an extreme drought\nin China, among others.",
      "tldr_zh": "这篇论文探讨了量化因果分析（quantitative causality）及其在科学发现和因果机器学习（causal machine learning）中的应用，强调了因果分析如何提升可解释深度学习和模型泛化。作者回顾了过去18年的努力，建立了基于大气可预测性的严格形式主义，解决了因果分析的模糊性、非量化性和计算低效等问题，并由此开创了信息流新领域。论文概述了主要理论成果和因果深度学习框架（causal deep learning），并展示了实际应用，如揭示全球变暖的人为原因、预测厄尔尼诺模式（El Niño Modoki）和中国极端干旱等，在量子力学、神经科学和金融经济学等领域推动了科学发现。总的来说，这为因果引导的AI算法提供了坚实基础。",
      "categories": [
        "cs.AI",
        "physics.data-an"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 3 figures. To appear in Ocean-Land-Atmosphere Research.\n  arXiv admin note: substantial text overlap with arXiv:2112.14839",
      "pdf_url": "http://arxiv.org/pdf/2402.13427v1",
      "published_date": "2024-02-20 23:38:46 UTC",
      "updated_date": "2024-02-20 23:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:05:46.428667"
    },
    {
      "arxiv_id": "2402.13425v2",
      "title": "Investigating the Histogram Loss in Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Imani",
        "Kai Luedemann",
        "Sam Scholnick-Hughes",
        "Esraa Elelimy",
        "Martha White"
      ],
      "abstract": "It is becoming increasingly common in regression to train neural networks\nthat model the entire distribution even if only the mean is required for\nprediction. This additional modeling often comes with performance gain and the\nreasons behind the improvement are not fully known. This paper investigates a\nrecent approach to regression, the Histogram Loss, which involves learning the\nconditional distribution of the target variable by minimizing the cross-entropy\nbetween a target distribution and a flexible histogram prediction. We design\ntheoretical and empirical analyses to determine why and when this performance\ngain appears, and how different components of the loss contribute to it. Our\nresults suggest that the benefits of learning distributions in this setup come\nfrom improvements in optimization rather than modelling extra information. We\nthen demonstrate the viability of the Histogram Loss in common deep learning\napplications without a need for costly hyperparameter tuning.",
      "tldr_zh": "本论文调查了在回归任务中使用 Histogram Loss 的性能提升，该方法通过最小化目标分布与灵活直方图预测之间的交叉熵来学习目标变量的条件分布。研究通过理论和实证分析发现，这种提升主要源于优化过程的改进，而非额外的信息建模。结果表明，Histogram Loss 在常见深度学习应用中具有很强的可行性，无需复杂的超参数调整，从而为回归模型提供了更高效的训练策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "52 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.13425v2",
      "published_date": "2024-02-20 23:29:41 UTC",
      "updated_date": "2024-10-19 21:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:05:58.828254"
    },
    {
      "arxiv_id": "2402.13419v1",
      "title": "Reward Bound for Behavioral Guarantee of Model-based Planning Agents",
      "title_zh": "基于模型的规划代理的行为保证奖励边界",
      "authors": [
        "Zhiyu An",
        "Xianzhong Ding",
        "Wan Du"
      ],
      "abstract": "Recent years have seen an emerging interest in the trustworthiness of machine\nlearning-based agents in the wild, especially in robotics, to provide safety\nassurance for the industry. Obtaining behavioral guarantees for these agents\nremains an important problem. In this work, we focus on guaranteeing a\nmodel-based planning agent reaches a goal state within a specific future time\nstep. We show that there exists a lower bound for the reward at the goal state,\nsuch that if the said reward is below that bound, it is impossible to obtain\nsuch a guarantee. By extension, we show how to enforce preferences over\nmultiple goals.",
      "tldr_zh": "这篇论文探讨了基于模型的规划代理(Model-based Planning Agents)的行为保证问题，旨在为机器学习代理在机器人等领域的安全性提供保障。研究发现，存在一个目标状态的奖励下界(Reward Bound)，如果该奖励低于下界，则无法保证代理在指定时间步内到达目标状态。通过这一发现，论文扩展了方法，以强制执行多个目标的优先级偏好。该工作为提升代理的可信度和安全性奠定了理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in ICLR 24 tiny paper track",
      "pdf_url": "http://arxiv.org/pdf/2402.13419v1",
      "published_date": "2024-02-20 23:17:07 UTC",
      "updated_date": "2024-02-20 23:17:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:06:09.718089"
    },
    {
      "arxiv_id": "2402.14859v2",
      "title": "The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Tan",
        "Chengshuai Zhao",
        "Raha Moraffah",
        "Yifan Li",
        "Yu Kong",
        "Tianlong Chen",
        "Huan Liu"
      ],
      "abstract": "Due to their unprecedented ability to process and respond to various types of\ndata, Multimodal Large Language Models (MLLMs) are constantly defining the new\nboundary of Artificial General Intelligence (AGI). As these advanced generative\nmodels increasingly form collaborative networks for complex tasks, the\nintegrity and security of these systems are crucial. Our paper, ``The Wolf\nWithin'', explores a novel vulnerability in MLLM societies - the indirect\npropagation of malicious content. Unlike direct harmful output generation for\nMLLMs, our research demonstrates how a single MLLM agent can be subtly\ninfluenced to generate prompts that, in turn, induce other MLLM agents in the\nsociety to output malicious content. Our findings reveal that, an MLLM agent,\nwhen manipulated to produce specific prompts or instructions, can effectively\n``infect'' other agents within a society of MLLMs. This infection leads to the\ngeneration and circulation of harmful outputs, such as dangerous instructions\nor misinformation, across the society. We also show the transferability of\nthese indirectly generated prompts, highlighting their possibility in\npropagating malice through inter-agent communication. This research provides a\ncritical insight into a new dimension of threat posed by MLLMs, where a single\nagent can act as a catalyst for widespread malevolent influence. Our work\nunderscores the urgent need for developing robust mechanisms to detect and\nmitigate such covert manipulations within MLLM societies, ensuring their safe\nand ethical utilization in societal applications.",
      "tldr_zh": "本文研究了Multimodal Large Language Models (MLLMs) 在协作网络中的新型安全漏洞，即通过一个被操纵的MLLM代理间接传播恶意内容。研究发现，该代理可生成特定提示，诱导其他MLLM代理输出有害信息，如危险指令或误信息，从而在整个MLLM社会中“感染”其他成员。实验证明了这些间接提示的转移性，通过代理间通信实现恶意传播，并强调了开发鲁棒检测和缓解机制的紧迫性，以确保MLLMs在社会应用中的安全和伦理使用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to workshop on ReGenAI@CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14859v2",
      "published_date": "2024-02-20 23:08:21 UTC",
      "updated_date": "2024-06-03 03:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:06:22.104796"
    },
    {
      "arxiv_id": "2402.13412v1",
      "title": "Scaling physics-informed hard constraints with mixture-of-experts",
      "title_zh": "通过混合专家扩展物理信息硬约束",
      "authors": [
        "Nithin Chalapathi",
        "Yiheng Du",
        "Aditi Krishnapriyan"
      ],
      "abstract": "Imposing known physical constraints, such as conservation laws, during neural\nnetwork training introduces an inductive bias that can improve accuracy,\nreliability, convergence, and data efficiency for modeling physical dynamics.\nWhile such constraints can be softly imposed via loss function penalties,\nrecent advancements in differentiable physics and optimization improve\nperformance by incorporating PDE-constrained optimization as individual layers\nin neural networks. This enables a stricter adherence to physical constraints.\nHowever, imposing hard constraints significantly increases computational and\nmemory costs, especially for complex dynamical systems. This is because it\nrequires solving an optimization problem over a large number of points in a\nmesh, representing spatial and temporal discretizations, which greatly\nincreases the complexity of the constraint. To address this challenge, we\ndevelop a scalable approach to enforce hard physical constraints using\nMixture-of-Experts (MoE), which can be used with any neural network\narchitecture. Our approach imposes the constraint over smaller decomposed\ndomains, each of which is solved by an \"expert\" through differentiable\noptimization. During training, each expert independently performs a localized\nbackpropagation step by leveraging the implicit function theorem; the\nindependence of each expert allows for parallelization across multiple GPUs.\nCompared to standard differentiable optimization, our scalable approach\nachieves greater accuracy in the neural PDE solver setting for predicting the\ndynamics of challenging non-linear systems. We also improve training stability\nand require significantly less computation time during both training and\ninference stages.",
      "tldr_zh": "本研究提出了一种可扩展的方法，使用 Mixture-of-Experts (MoE) 来扩展物理信息硬约束的规模，旨在解决传统硬约束在神经网络训练中带来的高计算和内存成本问题。该方法将物理约束（如守恒定律）分解到较小的域上，由多个专家通过可微优化独立处理，并利用隐函数定理支持多 GPU 平行化。与标准可微优化相比，该方法在神经 PDE 求解器中显著提高了非线性系统动态预测的准确性，同时改善了训练稳定性和减少了计算时间。实验结果显示，该框架在复杂动态系统中表现出色，为高效建模物理过程提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the International Conference on Learning Representations\n  (ICLR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13412v1",
      "published_date": "2024-02-20 22:45:00 UTC",
      "updated_date": "2024-02-20 22:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:06:35.005730"
    },
    {
      "arxiv_id": "2403.05565v1",
      "title": "OpenHEXAI: An Open-Source Framework for Human-Centered Evaluation of Explainable Machine Learning",
      "title_zh": "OpenHEXAI：一个开源框架，用于以人为中心的可解释机器学习评估",
      "authors": [
        "Jiaqi Ma",
        "Vivian Lai",
        "Yiming Zhang",
        "Chacha Chen",
        "Paul Hamilton",
        "Davor Ljubenkov",
        "Himabindu Lakkaraju",
        "Chenhao Tan"
      ],
      "abstract": "Recently, there has been a surge of explainable AI (XAI) methods driven by\nthe need for understanding machine learning model behaviors in high-stakes\nscenarios. However, properly evaluating the effectiveness of the XAI methods\ninevitably requires the involvement of human subjects, and conducting\nhuman-centered benchmarks is challenging in a number of ways: designing and\nimplementing user studies is complex; numerous design choices in the design\nspace of user study lead to problems of reproducibility; and running user\nstudies can be challenging and even daunting for machine learning researchers.\nTo address these challenges, this paper presents OpenHEXAI, an open-source\nframework for human-centered evaluation of XAI methods. OpenHEXAI features (1)\na collection of diverse benchmark datasets, pre-trained models, and post hoc\nexplanation methods; (2) an easy-to-use web application for user study; (3)\ncomprehensive evaluation metrics for the effectiveness of post hoc explanation\nmethods in the context of human-AI decision making tasks; (4) best practice\nrecommendations of experiment documentation; and (5) convenient tools for power\nanalysis and cost estimation. OpenHEAXI is the first large-scale\ninfrastructural effort to facilitate human-centered benchmarks of XAI methods.\nIt simplifies the design and implementation of user studies for XAI methods,\nthus allowing researchers and practitioners to focus on the scientific\nquestions. Additionally, it enhances reproducibility through standardized\ndesigns. Based on OpenHEXAI, we further conduct a systematic benchmark of four\nstate-of-the-art post hoc explanation methods and compare their impacts on\nhuman-AI decision making tasks in terms of accuracy, fairness, as well as\nusers' trust and understanding of the machine learning model.",
      "tldr_zh": "该研究引入了 OpenHEXAI，这是一个开源框架，旨在简化可解释 AI (XAI) 方法的人类中心评估，解决用户研究设计复杂、重复性差和实施挑战等问题。OpenHEXAI 提供多样化的基准数据集、预训练模型、后验解释方法，以及易用性强的网络应用、评估指标、最佳实践推荐和工具，以提升实验的可重复性和效率。通过该框架，作者对四种最先进的后验解释方法进行了系统基准测试，发现这些方法在人类-AI 决策任务中影响了准确性、公平性以及用户的信任和理解。总的来说，OpenHEXAI 为 XAI 研究者提供了便利的基础设施，促进了更可靠的人类参与评估。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05565v1",
      "published_date": "2024-02-20 22:17:59 UTC",
      "updated_date": "2024-02-20 22:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:06:46.636605"
    },
    {
      "arxiv_id": "2402.13399v2",
      "title": "Learning and Sustaining Shared Normative Systems via Bayesian Rule Induction in Markov Games",
      "title_zh": "在马尔可夫博弈中通过贝叶斯规则归纳学习与维持共享规范系统",
      "authors": [
        "Ninell Oldenburg",
        "Tan Zhi-Xuan"
      ],
      "abstract": "A universal feature of human societies is the adoption of systems of rules\nand norms in the service of cooperative ends. How can we build learning agents\nthat do the same, so that they may flexibly cooperate with the human\ninstitutions they are embedded in? We hypothesize that agents can achieve this\nby assuming there exists a shared set of norms that most others comply with\nwhile pursuing their individual desires, even if they do not know the exact\ncontent of those norms. By assuming shared norms, a newly introduced agent can\ninfer the norms of an existing population from observations of compliance and\nviolation. Furthermore, groups of agents can converge to a shared set of norms,\neven if they initially diverge in their beliefs about what the norms are. This\nin turn enables the stability of the normative system: since agents can\nbootstrap common knowledge of the norms, this leads the norms to be widely\nadhered to, enabling new entrants to rapidly learn those norms. We formalize\nthis framework in the context of Markov games and demonstrate its operation in\na multi-agent environment via approximately Bayesian rule induction of\nobligative and prohibitive norms. Using our approach, agents are able to\nrapidly learn and sustain a variety of cooperative institutions, including\nresource management norms and compensation for pro-social labor, promoting\ncollective welfare while still allowing agents to act in their own interests.",
      "tldr_zh": "该研究探讨了如何构建学习代理，使其像人类社会一样采用共享规范系统来实现合作目标。代理假设存在一个大多数个体遵守的共享规范，并通过贝叶斯规则归纳(Bayesian Rule Induction)从观察到的合规和违规行为中推断这些规范，在Markov Games的框架下实现。实验结果显示，代理能够快速收敛到共享规范，促进合作机构如资源管理和补偿机制的稳定，从而提升集体福利，同时允许个体追求自身利益。",
      "categories": [
        "cs.AI",
        "I.2.0; I.6.5; G.3"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the 23rd International Conference on Autonomous Agents\n  and Multi-Agent Systems, 8 pages (excl. references), 6 figures/tables,\n  (Appendix: 7 pages, 6 figures/tables). Code available at:\n  https://github.com/ninell-oldenburg/social-contracts",
      "pdf_url": "http://arxiv.org/pdf/2402.13399v2",
      "published_date": "2024-02-20 21:58:40 UTC",
      "updated_date": "2024-02-22 15:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:06:57.623849"
    },
    {
      "arxiv_id": "2402.13397v1",
      "title": "Xling: A Learned Filter Framework for Accelerating High-Dimensional Approximate Similarity Join",
      "title_zh": "Xling：一个基于学习的过滤框架，用于加速高维近似相似性连接",
      "authors": [
        "Yifan Wang",
        "Vyom Pathak",
        "Daisy Zhe Wang"
      ],
      "abstract": "Similarity join finds all pairs of close points within a given distance\nthreshold. Many similarity join methods have been proposed, but they are\nusually not efficient on high-dimensional space due to the curse of\ndimensionality and data-unawareness. We investigate the possibility of using\nmetric space Bloom filter (MSBF), a family of data structures checking if a\nquery point has neighbors in a multi-dimensional space, to speed up similarity\njoin. However, there are several challenges when applying MSBF to similarity\njoin, including excessive information loss, data-unawareness and hard\nconstraint on the distance metric. In this paper, we propose Xling, a generic\nframework to build a learning-based metric space filter with any existing\nregression model, aiming at accurately predicting whether a query point has\nenough number of neighbors. The framework provides a suite of optimization\nstrategies to further improve the prediction quality based on the learning\nmodel, which has demonstrated significantly higher prediction quality than\nexisting MSBF. We also propose XJoin, one of the first filter-based similarity\njoin methods, based on Xling. By predicting and skipping those queries without\nenough neighbors, XJoin can effectively reduce unnecessary neighbor searching\nand therefore it achieves a remarkable acceleration. Benefiting from the\ngeneralization capability of deep learning models, XJoin can be easily\ntransferred onto new dataset (in similar distribution) without re-training.\nFurthermore, Xling is not limited to being applied in XJoin, instead, it acts\nas a flexible plugin that can be inserted to any loop-based similarity join\nmethods for a speedup.",
      "tldr_zh": "本论文提出 Xling，一种基于学习的过滤器框架，用于加速高维近似 Similarity Join，通过预测查询点是否有足够邻居来减少不必要的搜索。Xling 利用任何现有回归模型构建度量空间过滤器，并提供优化策略以提升预测质量，比传统 Metric Space Bloom Filter (MSBF) 显著提高准确性。基于 Xling，该研究开发了 XJoin 方法，这是一种创新的过滤器-based Similarity Join 算法，能有效跳过无邻居查询，实现显著加速，且凭借深度学习模型的泛化能力，可轻松转移到类似分布的新数据集。Xling 作为灵活插件，可插入任何基于循环的 Similarity Join 方法中，进一步扩展其应用潜力。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13397v1",
      "published_date": "2024-02-20 21:57:03 UTC",
      "updated_date": "2024-02-20 21:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:07:10.895009"
    },
    {
      "arxiv_id": "2402.13380v3",
      "title": "Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua F. Cooper",
        "Seung Jin Choi",
        "I. Esra Buyuktahtakin"
      ],
      "abstract": "In this study, we introduce an innovative deep learning framework that\nemploys a transformer model to address the challenges of mixed-integer\nprograms, specifically focusing on the Capacitated Lot Sizing Problem (CLSP).\nOur approach, to our knowledge, is the first to utilize transformers to predict\nthe binary variables of a mixed-integer programming (MIP) problem.\nSpecifically, our approach harnesses the encoder decoder transformer's ability\nto process sequential data, making it well-suited for predicting binary\nvariables indicating production setup decisions in each period of the CLSP.\nThis problem is inherently dynamic, and we need to handle sequential decision\nmaking under constraints. We present an efficient algorithm in which CLSP\nsolutions are learned through a transformer neural network. The proposed\npost-processed transformer algorithm surpasses the state-of-the-art solver,\nCPLEX and Long Short-Term Memory (LSTM) in solution time, optimal gap, and\npercent infeasibility over 240K benchmark CLSP instances tested. After the ML\nmodel is trained, conducting inference on the model, reduces the MIP into a\nlinear program (LP). This transforms the ML-based algorithm, combined with an\nLP solver, into a polynomial-time approximation algorithm to solve a well-known\nNP-Hard problem, with almost perfect solution quality.",
      "tldr_zh": "这篇论文提出了一种创新的深度学习框架，使用 Transformer 模型来解决混合整数规划 (MIP) 问题，特别是针对 Capacitated Lot Sizing Problem (CLSP)，这是首次将 Transformer 应用于预测 MIP 的二进制变量。框架利用 Transformer 的编码器-解码器结构处理序列数据，高效学习 CLSP 的生产设置决策，并通过后处理算法将 MIP 简化为线性规划 (LP)，从而实现多项式时间近似求解。实验结果显示，该算法在 240K 个基准实例上超越了 CPLEX 和 Long Short-Term Memory (LSTM)，在解决时间、优化间隙和不可行百分比方面表现出色，几乎达到完美解质量。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.CO",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13380v3",
      "published_date": "2024-02-20 21:13:38 UTC",
      "updated_date": "2024-05-24 16:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:07:23.143344"
    },
    {
      "arxiv_id": "2402.14858v1",
      "title": "ChatEL: Entity Linking with Chatbots",
      "title_zh": "ChatEL：使用聊天机器人的实体链接",
      "authors": [
        "Yifan Ding",
        "Qingkai Zeng",
        "Tim Weninger"
      ],
      "abstract": "Entity Linking (EL) is an essential and challenging task in natural language\nprocessing that seeks to link some text representing an entity within a\ndocument or sentence with its corresponding entry in a dictionary or knowledge\nbase. Most existing approaches focus on creating elaborate contextual models\nthat look for clues the words surrounding the entity-text to help solve the\nlinking problem. Although these fine-tuned language models tend to work, they\ncan be unwieldy, difficult to train, and do not transfer well to other domains.\nFortunately, Large Language Models (LLMs) like GPT provide a highly-advanced\nsolution to the problems inherent in EL models, but simply naive prompts to\nLLMs do not work well. In the present work, we define ChatEL, which is a\nthree-step framework to prompt LLMs to return accurate results. Overall the\nChatEL framework improves the average F1 performance across 10 datasets by more\nthan 2%. Finally, a thorough error analysis shows many instances with the\nground truth labels were actually incorrect, and the labels predicted by ChatEL\nwere actually correct. This indicates that the quantitative results presented\nin this paper may be a conservative estimate of the actual performance. All\ndata and code are available as an open-source package on GitHub at\nhttps://github.com/yifding/In_Context_EL.",
      "tldr_zh": "该研究针对Entity Linking (EL)任务的挑战，提出了一种名为ChatEL的框架，利用Large Language Models (LLMs)如GPT，通过三步提示策略来提升实体链接的准确性，以克服现有上下文模型的复杂性和跨域适应问题。ChatEL框架在10个数据集上实现了平均F1性能的超过2%的提升。错误分析进一步显示，许多ground truth labels可能有误，而ChatEL的预测更准确，表明其实际性能可能被低估；相关数据和代码已在GitHub上开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14858v1",
      "published_date": "2024-02-20 20:52:57 UTC",
      "updated_date": "2024-02-20 20:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:07:34.745847"
    },
    {
      "arxiv_id": "2402.13369v1",
      "title": "The Uncanny Valley: A Comprehensive Analysis of Diffusion Models",
      "title_zh": "恐怖谷：扩散模型的全面分析",
      "authors": [
        "Karam Ghanem",
        "Danilo Bzdok"
      ],
      "abstract": "Through Diffusion Models (DMs), we have made significant advances in\ngenerating high-quality images. Our exploration of these models delves deeply\ninto their core operational principles by systematically investigating key\naspects across various DM architectures: i) noise schedules, ii) samplers, and\niii) guidance. Our comprehensive examination of these models sheds light on\ntheir hidden fundamental mechanisms, revealing the concealed foundational\nelements that are essential for their effectiveness. Our analyses emphasize the\nhidden key factors that determine model performance, offering insights that\ncontribute to the advancement of DMs. Past findings show that the configuration\nof noise schedules, samplers, and guidance is vital to the quality of generated\nimages; however, models reach a stable level of quality across different\nconfigurations at a remarkably similar point, revealing that the decisive\nfactors for optimal performance predominantly reside in the diffusion process\ndynamics and the structural design of the model's network, rather than the\nspecifics of configuration details. Our comparative analysis reveals that\nDenoising Diffusion Probabilistic Model (DDPM)-based diffusion dynamics\nconsistently outperform the Noise Conditioned Score Network (NCSN)-based ones,\nnot only when evaluated in their original forms but also when continuous\nthrough Stochastic Differential Equation (SDE)-based implementations.",
      "tldr_zh": "这篇论文对Diffusion Models (DMs)进行了全面分析，系统探讨了噪声 schedules、samplers 和 guidance 等关键方面，以揭示这些模型的核心运作机制。研究强调，DMs 的性能主要取决于扩散过程动态和模型网络结构设计，而非具体配置细节。实验发现，DDPM-based 扩散动态在原生形式和基于Stochastic Differential Equation (SDE) 的实现中，均优于NCSN-based 动态。总体而言，该分析为提升DMs 生成图像质量提供了宝贵洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "I.2.10; I.4.8; I.4.5; I.4.m"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13369v1",
      "published_date": "2024-02-20 20:49:22 UTC",
      "updated_date": "2024-02-20 20:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:07:46.398482"
    },
    {
      "arxiv_id": "2402.13352v3",
      "title": "KetGPT - Dataset Augmentation of Quantum Circuits using Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Boran Apak",
        "Medina Bandic",
        "Aritra Sarkar",
        "Sebastian Feld"
      ],
      "abstract": "Quantum algorithms, represented as quantum circuits, can be used as\nbenchmarks for assessing the performance of quantum systems. Existing datasets,\nwidely utilized in the field, suffer from limitations in size and versatility,\nleading researchers to employ randomly generated circuits. Random circuits are,\nhowever, not representative benchmarks as they lack the inherent properties of\nreal quantum algorithms for which the quantum systems are manufactured. This\nshortage of `useful' quantum benchmarks poses a challenge to advancing the\ndevelopment and comparison of quantum compilers and hardware.\n  This research aims to enhance the existing quantum circuit datasets by\ngenerating what we refer to as `realistic-looking' circuits by employing the\nTransformer machine learning architecture. For this purpose, we introduce\nKetGPT, a tool that generates synthetic circuits in OpenQASM language, whose\nstructure is based on quantum circuits derived from existing quantum algorithms\nand follows the typical patterns of human-written algorithm-based code (e.g.,\norder of gates and qubits). Our three-fold verification process, involving\nmanual inspection and Qiskit framework execution, transformer-based\nclassification, and structural analysis, demonstrates the efficacy of KetGPT in\nproducing large amounts of additional circuits that closely align with\nalgorithm-based structures. Beyond benchmarking, we envision KetGPT\ncontributing substantially to AI-driven quantum compilers and systems.",
      "tldr_zh": "本研究针对现有量子电路数据集规模小且缺乏代表性的问题，提出使用 Transformer 架构生成“真实外观”的合成电路，以更好地评估量子系统性能。研究引入 KetGPT 工具，该工具基于现有量子算法的结构，使用 OpenQASM 语言创建电路，并模仿人类编写模式（如门和量子比特的顺序）。通过三重验证过程，包括手动检查、Qiskit 框架执行、Transformer-based 分类和结构分析，证明 KetGPT 能高效产生大量与算法结构相似的电路。最终，这不仅提升了量子基准测试的质量，还为 AI 驱动的量子编译器和硬件发展提供重要支持。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13352v3",
      "published_date": "2024-02-20 20:02:21 UTC",
      "updated_date": "2024-02-23 08:55:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:07:59.338983"
    },
    {
      "arxiv_id": "2402.13349v2",
      "title": "Aria Everyday Activities Dataset",
      "title_zh": "Aria 日常活动数据集",
      "authors": [
        "Zhaoyang Lv",
        "Nicholas Charron",
        "Pierre Moulon",
        "Alexander Gamino",
        "Cheng Peng",
        "Chris Sweeney",
        "Edward Miller",
        "Huixuan Tang",
        "Jeff Meissner",
        "Jing Dong",
        "Kiran Somasundaram",
        "Luis Pesqueira",
        "Mark Schwesinger",
        "Omkar Parkhi",
        "Qiao Gu",
        "Renzo De Nardi",
        "Shangyi Cheng",
        "Steve Saarinen",
        "Vijay Baiyya",
        "Yuyang Zou",
        "Richard Newcombe",
        "Jakob Julian Engel",
        "Xiaqing Pan",
        "Carl Ren"
      ],
      "abstract": "We present Aria Everyday Activities (AEA) Dataset, an egocentric multimodal\nopen dataset recorded using Project Aria glasses. AEA contains 143 daily\nactivity sequences recorded by multiple wearers in five geographically diverse\nindoor locations. Each of the recording contains multimodal sensor data\nrecorded through the Project Aria glasses. In addition, AEA provides machine\nperception data including high frequency globally aligned 3D trajectories,\nscene point cloud, per-frame 3D eye gaze vector and time aligned speech\ntranscription. In this paper, we demonstrate a few exemplar research\napplications enabled by this dataset, including neural scene reconstruction and\nprompted segmentation. AEA is an open source dataset that can be downloaded\nfrom https://www.projectaria.com/datasets/aea/. We are also providing\nopen-source implementations and examples of how to use the dataset in Project\nAria Tools https://github.com/facebookresearch/projectaria_tools.",
      "tldr_zh": "我们介绍了 Aria Everyday Activities (AEA) Dataset，这是一个使用 Project Aria glasses 记录的 egocentric 多模态开放数据集，包含 143 个日常活动序列，由多个佩戴者在五个地理上不同的室内位置采集。数据集提供多模态传感器数据，以及机器感知数据如高频全局对齐的 3D trajectories、scene point cloud、per-frame 3D eye gaze vector 和时间对齐的 speech transcription。论文展示了示例研究应用，包括 neural scene reconstruction 和 prompted segmentation；AEA 是开源资源，可从 https://www.projectaria.com/datasets/aea/ 下载，并附带开源工具示例。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Dataset website: https://www.projectaria.com/datasets/aea/",
      "pdf_url": "http://arxiv.org/pdf/2402.13349v2",
      "published_date": "2024-02-20 19:53:15 UTC",
      "updated_date": "2024-02-22 03:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:08:11.859106"
    },
    {
      "arxiv_id": "2402.13326v2",
      "title": "Deep Hedging with Market Impact",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Neagu",
        "Frédéric Godin",
        "Clarence Simard",
        "Leila Kosseim"
      ],
      "abstract": "Dynamic hedging is the practice of periodically transacting financial\ninstruments to offset the risk caused by an investment or a liability. Dynamic\nhedging optimization can be framed as a sequential decision problem; thus,\nReinforcement Learning (RL) models were recently proposed to tackle this task.\nHowever, existing RL works for hedging do not consider market impact caused by\nthe finite liquidity of traded instruments. Integrating such feature can be\ncrucial to achieve optimal performance when hedging options on stocks with\nlimited liquidity. In this paper, we propose a novel general market impact\ndynamic hedging model based on Deep Reinforcement Learning (DRL) that considers\nseveral realistic features such as convex market impacts, and impact\npersistence through time. The optimal policy obtained from the DRL model is\nanalysed using several option hedging simulations and compared to commonly used\nprocedures such as delta hedging. Results show our DRL model behaves better in\ncontexts of low liquidity by, among others: 1) learning the extent to which\nportfolio rebalancing actions should be dampened or delayed to avoid high\ncosts, 2) factoring in the impact of features not considered by conventional\napproaches, such as previous hedging errors through the portfolio value, and\nthe underlying asset's drift (i.e. the magnitude of its expected return).",
      "tldr_zh": "这篇论文提出了一种基于 Deep Reinforcement Learning (DRL) 的动态套期保值模型，旨在解决传统方法忽略的市场影响问题，如金融工具的有限流动性导致的凸型影响和持久性。模型将套期保值视为顺序决策问题，通过 DRL 优化策略，学习在低流动性环境中调整再平衡动作以降低成本，并考虑传统方法未涉及的因素，如之前的套期保值错误和资产漂移。实验结果显示，该模型在模拟中优于 delta hedging 等常见方法，提高了整体性能，尤其在低流动性场景下。",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13326v2",
      "published_date": "2024-02-20 19:08:24 UTC",
      "updated_date": "2024-02-22 21:25:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:08:23.246016"
    },
    {
      "arxiv_id": "2402.13254v4",
      "title": "CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Jianrui Zhang",
        "Mu Cai",
        "Tengyang Xie",
        "Yong Jae Lee"
      ],
      "abstract": "We propose CounterCurate, a framework to comprehensively improve the\nvisio-linguistic compositional reasoning capability for both contrastive and\ngenerative multimodal models. In particular, we identify two critical\nunder-explored problems: the neglect of the physically grounded reasoning\n(counting and position understanding) and the potential of using highly capable\ntext and image generation models for semantic counterfactual fine-tuning. Our\nwork pioneers an approach that addresses these gaps. We first spotlight the\nnear-chance performance of multimodal models like CLIP and LLaVA in physically\ngrounded compositional reasoning. We then apply simple data augmentation using\ngrounded image generation model GLIGEN to generate fine-tuning data, resulting\nin significant performance improvements: +33% and +37% for CLIP and LLaVA,\nrespectively, on our newly curated Flickr30k-Positions benchmark. Moreover, we\nexploit the capabilities of high-performing text generation and image\ngeneration models, specifically GPT-4V and DALLE-3, to curate challenging\nsemantic counterfactuals, thereby further enhancing compositional reasoning\ncapabilities on benchmarks such as SugarCrepe, where CounterCurate outperforms\nGPT-4V. To facilitate future research, we release our code, dataset, benchmark,\nand checkpoints at https://countercurate.github.io.",
      "tldr_zh": "我们提出了 CounterCurate 框架，用于提升对比和生成型多模态模型的 visio-linguistic compositional reasoning 能力，特别针对物理基础推理（如计数和位置理解）以及语义反事实微调的不足。框架首先使用 GLIGEN 进行数据增强生成图像，显著提升模型性能：在 Flickr30k-Positions 基准上，CLIP 和 LLaVA 分别提高了 33% 和 37%。此外，通过利用 GPT-4V 和 DALLE-3 生成挑战性的语义反事实示例，CounterCurate 在 SugarCrepe 基准上超越了 GPT-4V，并公开了代码、数据集和基准以促进未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 6 figures, 12 tables, Project Page:\n  https://countercurate.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2402.13254v4",
      "published_date": "2024-02-20 18:59:55 UTC",
      "updated_date": "2024-06-12 17:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:08:36.265862"
    },
    {
      "arxiv_id": "2402.13249v2",
      "title": "TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Liyan Tang",
        "Igor Shalyminov",
        "Amy Wing-mei Wong",
        "Jon Burnsky",
        "Jake W. Vincent",
        "Yu'an Yang",
        "Siffi Singh",
        "Song Feng",
        "Hwanjun Song",
        "Hang Su",
        "Lijia Sun",
        "Yi Zhang",
        "Saab Mansour",
        "Kathleen McKeown"
      ],
      "abstract": "Single document news summarization has seen substantial progress on\nfaithfulness in recent years, driven by research on the evaluation of factual\nconsistency, or hallucinations. We ask whether these advances carry over to\nother text summarization domains. We propose a new evaluation benchmark on\ntopic-focused dialogue summarization, generated by LLMs of varying sizes. We\nprovide binary sentence-level human annotations of the factual consistency of\nthese summaries along with detailed explanations of factually inconsistent\nsentences. Our analysis shows that existing LLMs hallucinate significant\namounts of factual errors in the dialogue domain, regardless of the model's\nsize. On the other hand, when LLMs, including GPT-4, serve as binary factual\nevaluators, they perform poorly and can be outperformed by prevailing\nstate-of-the-art specialized factuality evaluation metrics. Finally, we\nconducted an analysis of hallucination types with a curated error taxonomy. We\nfind that there are diverse errors and error distributions in model-generated\nsummaries and that non-LLM based metrics can capture all error types better\nthan LLM-based evaluators.",
      "tldr_zh": "本研究提出 TofuEval，一个新的评估基准，用于评估大型语言模型 (LLMs) 在主题聚焦对话摘要 (topic-focused dialogue summarization) 中的幻觉 (hallucinations)。研究人员使用不同大小的 LLMs 生成摘要，并提供二元句子级别的真实性一致性人类标注及详细解释，结果显示现有 LLMs 不论模型规模，都在对话领域产生大量事实错误。实验进一步表明，当 LLMs（如 GPT-4）用作事实评估器时，性能较差，且逊于先进的专业事实评估指标；同时，通过策划的错误分类法分析，发现模型生成的摘要错误类型多样，非 LLM 基于的指标能更有效地捕捉这些错误。整体而言，该工作强调了提升对话摘要真实性的必要性，并为幻觉评估提供新基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024; Linguistic annotations available at\n  https://github.com/amazon-science/tofueval",
      "pdf_url": "http://arxiv.org/pdf/2402.13249v2",
      "published_date": "2024-02-20 18:58:49 UTC",
      "updated_date": "2024-03-31 15:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:08:47.040234"
    },
    {
      "arxiv_id": "2404.07214v2",
      "title": "Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions",
      "title_zh": "视觉语言模型的前沿探索：当前方法论的综述与未来方向",
      "authors": [
        "Akash Ghosh",
        "Arkadeep Acharya",
        "Sriparna Saha",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has significantly reshaped the\ntrajectory of the AI revolution. Nevertheless, these LLMs exhibit a notable\nlimitation, as they are primarily adept at processing textual information. To\naddress this constraint, researchers have endeavored to integrate visual\ncapabilities with LLMs, resulting in the emergence of Vision-Language Models\n(VLMs). These advanced models are instrumental in tackling more intricate tasks\nsuch as image captioning and visual question answering. In our comprehensive\nsurvey paper, we delve into the key advancements within the realm of VLMs. Our\nclassification organizes VLMs into three distinct categories: models dedicated\nto vision-language understanding, models that process multimodal inputs to\ngenerate unimodal (textual) outputs and models that both accept and produce\nmultimodal inputs and outputs.This classification is based on their respective\ncapabilities and functionalities in processing and generating various\nmodalities of data.We meticulously dissect each model, offering an extensive\nanalysis of its foundational architecture, training data sources, as well as\nits strengths and limitations wherever possible, providing readers with a\ncomprehensive understanding of its essential components. We also analyzed the\nperformance of VLMs in various benchmark datasets. By doing so, we aim to offer\na nuanced understanding of the diverse landscape of VLMs. Additionally, we\nunderscore potential avenues for future research in this dynamic domain,\nanticipating further breakthroughs and advancements.",
      "tldr_zh": "这篇调查论文探讨了视觉语言模型(Vision-Language Models, VLMs)的最新进展，以解决大型语言模型(Large Language Models, LLMs)仅处理文本的局限性。论文将VLMs分类为三类：专注于视觉语言理解的模型、处理多模态输入生成文本输出的模型，以及支持多模态输入和输出的模型，并详细分析了它们的架构、训练数据、优势和局限性。作者评估了这些模型在各种基准数据集上的性能，并指出了未来研究方向，如进一步提升多模态处理能力，以推动AI领域的突破。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "The most extensive and up to date Survey on Visual Language Models\n  covering 76 Visual Language Models",
      "pdf_url": "http://arxiv.org/pdf/2404.07214v2",
      "published_date": "2024-02-20 18:57:34 UTC",
      "updated_date": "2024-04-12 21:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:08:57.953815"
    },
    {
      "arxiv_id": "2402.13241v2",
      "title": "Federated Causal Discovery from Heterogeneous Data",
      "title_zh": "异构数据的联邦因果发现",
      "authors": [
        "Loka Li",
        "Ignavier Ng",
        "Gongxu Luo",
        "Biwei Huang",
        "Guangyi Chen",
        "Tongliang Liu",
        "Bin Gu",
        "Kun Zhang"
      ],
      "abstract": "Conventional causal discovery methods rely on centralized data, which is\ninconsistent with the decentralized nature of data in many real-world\nsituations. This discrepancy has motivated the development of federated causal\ndiscovery (FCD) approaches. However, existing FCD methods may be limited by\ntheir potentially restrictive assumptions of identifiable functional causal\nmodels or homogeneous data distributions, narrowing their applicability in\ndiverse scenarios. In this paper, we propose a novel FCD method attempting to\naccommodate arbitrary causal models and heterogeneous data. We first utilize a\nsurrogate variable corresponding to the client index to account for the data\nheterogeneity across different clients. We then develop a federated conditional\nindependence test (FCIT) for causal skeleton discovery and establish a\nfederated independent change principle (FICP) to determine causal directions.\nThese approaches involve constructing summary statistics as a proxy of the raw\ndata to protect data privacy. Owing to the nonparametric properties, FCIT and\nFICP make no assumption about particular functional forms, thereby facilitating\nthe handling of arbitrary causal models. We conduct extensive experiments on\nsynthetic and real datasets to show the efficacy of our method. The code is\navailable at https://github.com/lokali/FedCDH.git.",
      "tldr_zh": "本研究针对传统因果发现方法依赖集中式数据的局限性，提出了一种新型 Federated Causal Discovery (FCD) 方法，以适应任意因果模型和异质数据分布。该方法使用代理变量（对应客户端索引）处理数据异质性，开发 Federated Conditional Independence Test (FCIT) 用于因果骨架发现，并建立 Federated Independent Change Principle (FICP) 来确定因果方向。FCIT 和 FICP 采用非参数方法，通过摘要统计作为原始数据的代理，确保数据隐私保护，并在合成和真实数据集的广泛实验中证明了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13241v2",
      "published_date": "2024-02-20 18:53:53 UTC",
      "updated_date": "2024-02-27 04:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:09:12.039802"
    },
    {
      "arxiv_id": "2402.13228v2",
      "title": "Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive",
      "title_zh": "翻译失败",
      "authors": [
        "Arka Pal",
        "Deep Karkhanis",
        "Samuel Dooley",
        "Manley Roberts",
        "Siddartha Naidu",
        "Colin White"
      ],
      "abstract": "Direct Preference Optimisation (DPO) is effective at significantly improving\nthe performance of large language models (LLMs) on downstream tasks such as\nreasoning, summarisation, and alignment. Using pairs of preferred and\ndispreferred data, DPO models the relative probability of picking one response\nover another. In this work, first we show theoretically that the standard DPO\nloss can lead to a reduction of the model's likelihood of the preferred\nexamples, as long as the relative probability between the preferred and\ndispreferred classes increases. We then show empirically that this phenomenon\noccurs when fine-tuning LLMs on common datasets, especially datasets in which\nthe edit distance between pairs of completions is low. Using these insights, we\ndesign DPO-Positive (DPOP), a new loss function and training procedure which\navoids this failure mode. Surprisingly, we find that DPOP outperforms DPO and\nother fine-tuning procedures across a wide variety of datasets and downstream\ntasks, including datasets with high edit distances between completions.\nFurthermore, we find that the DPOP-tuned model outperforms the DPO-tuned model\n(all else equal) on benchmarks independent of the fine-tuning data, such as\nMT-Bench. Finally, using DPOP, we create and open-source Smaug-34B and\nSmaug-72B, with the latter becoming the first open-source LLM to surpass an\naverage accuracy of 80% on the HuggingFace Open LLM Leaderboard.",
      "tldr_zh": "该论文揭示了 Direct Preference Optimisation (DPO) 在优化大语言模型 (LLMs) 时可能导致首选示例似然性降低的问题，尤其在编辑距离低的数据集上。作者提出 DPO-Positive (DPOP) 作为一种新损失函数和训练过程，能有效避免这一失败模式。实验结果显示，DPOP 在各种数据集和下游任务（如推理和对齐）上优于 DPO，甚至在编辑距离高的场景中表现突出，并在独立基准如 MT-Bench 上取得更好成绩。最后，基于 DPOP 开发的开源模型 Smaug-34B 和 Smaug-72B 首次在 HuggingFace Open LLM Leaderboard 上实现平均准确率超过 80%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13228v2",
      "published_date": "2024-02-20 18:42:34 UTC",
      "updated_date": "2024-07-03 13:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:09:24.139399"
    },
    {
      "arxiv_id": "2402.13226v2",
      "title": "NeRF Solves Undersampled MRI Reconstruction",
      "title_zh": "NeRF 解决欠采样 MRI 重建",
      "authors": [
        "Tae Jun Jang",
        "Chang Min Hyun"
      ],
      "abstract": "This article presents a novel undersampled magnetic resonance imaging (MRI)\ntechnique that leverages the concept of Neural Radiance Field (NeRF). With\nradial undersampling, the corresponding imaging problem can be reformulated\ninto an image modeling task from sparse-view rendered data; therefore, a high\ndimensional MR image is obtainable from undersampled k-space data by taking\nadvantage of implicit neural representation. A multi-layer perceptron, which is\ndesigned to output an image intensity from a spatial coordinate, learns the MR\nphysics-driven rendering relation between given measurement data and desired\nimage. Effective undersampling strategies for high-quality neural\nrepresentation are investigated. The proposed method serves two benefits: (i)\nThe learning is based fully on single undersampled k-space data, not a bunch of\nmeasured data and target image sets. It can be used potentially for diagnostic\nMR imaging, such as fetal MRI, where data acquisition is relatively rare or\nlimited against diversity of clinical images while undersampled reconstruction\nis highly demanded. (ii) A reconstructed MR image is a scan-specific\nrepresentation highly adaptive to the given k-space measurement. Numerous\nexperiments validate the feasibility and capability of the proposed approach.",
      "tldr_zh": "这篇论文提出了一种新颖的 undersampled MRI 重建技术，利用 Neural Radiance Field (NeRF) 将 radial undersampling 数据转化为 sparse-view 渲染建模任务，通过 implicit neural representation 从 undersampled k-space 数据重建高维 MR 图像。核心方法涉及设计一个 multi-layer perceptron (MLP) 来学习 MR 物理驱动的渲染关系，并探索有效的 undersampling 策略以提升神经表示质量。该方法的关键优势在于仅需单个 undersampled k-space 数据进行学习，适用于数据稀缺的诊断场景如 fetal MRI，并生成针对特定扫描的适应性图像；实验结果验证了其可行性和重建能力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CE",
        "eess.SP"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13226v2",
      "published_date": "2024-02-20 18:37:42 UTC",
      "updated_date": "2024-03-02 15:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:09:34.779766"
    },
    {
      "arxiv_id": "2402.13225v1",
      "title": "AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning",
      "title_zh": "AgentMD: 通过大规模临床工具学习赋能语言代理用于风险预测",
      "authors": [
        "Qiao Jin",
        "Zhizheng Wang",
        "Yifan Yang",
        "Qingqing Zhu",
        "Donald Wright",
        "Thomas Huang",
        "W John Wilbur",
        "Zhe He",
        "Andrew Taylor",
        "Qingyu Chen",
        "Zhiyong Lu"
      ],
      "abstract": "Clinical calculators play a vital role in healthcare by offering accurate\nevidence-based predictions for various purposes such as prognosis.\nNevertheless, their widespread utilization is frequently hindered by usability\nchallenges, poor dissemination, and restricted functionality. Augmenting large\nlanguage models with extensive collections of clinical calculators presents an\nopportunity to overcome these obstacles and improve workflow efficiency, but\nthe scalability of the manual curation process poses a significant challenge.\nIn response, we introduce AgentMD, a novel language agent capable of curating\nand applying clinical calculators across various clinical contexts. Using the\npublished literature, AgentMD has automatically curated a collection of 2,164\ndiverse clinical calculators with executable functions and structured\ndocumentation, collectively named RiskCalcs. Manual evaluations show that\nRiskCalcs tools achieve an accuracy of over 80% on three quality metrics. At\ninference time, AgentMD can automatically select and apply the relevant\nRiskCalcs tools given any patient description. On the newly established RiskQA\nbenchmark, AgentMD significantly outperforms chain-of-thought prompting with\nGPT-4 (87.7% vs. 40.9% in accuracy). Additionally, we also applied AgentMD to\nreal-world clinical notes for analyzing both population-level and risk-level\npatient characteristics. In summary, our study illustrates the utility of\nlanguage agents augmented with clinical calculators for healthcare analytics\nand patient care.",
      "tldr_zh": "本研究提出AgentMD，一种增强语言代理的框架，用于大规模临床工具学习，以改善风险预测。该框架从已发表文献中自动整理了2164个临床计算器（RiskCalcs），包括可执行函数和结构化文档，并通过手动评估显示其在三个质量指标上的准确率超过80%。AgentMD能在推理时根据患者描述自动选择和应用相关工具，在新建立的RiskQA基准上，其准确率（87.7%）显著优于GPT-4的链式思维提示（40.9%）。此外，AgentMD已应用于真实临床笔记中，分析患者特征，从而提升医疗分析和患者护理的效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2402.13225v1",
      "published_date": "2024-02-20 18:37:19 UTC",
      "updated_date": "2024-02-20 18:37:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:09:46.498961"
    },
    {
      "arxiv_id": "2402.13224v4",
      "title": "Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming",
      "title_zh": "通过用户行为建模和随机规划控制大型电动汽车充电站",
      "authors": [
        "Alban Puech",
        "Tristan Rigaut",
        "William Templier",
        "Maud Tournoud"
      ],
      "abstract": "This paper introduces an Electric Vehicle Charging Station (EVCS) model that\nincorporates real-world constraints, such as slot power limitations, contract\nthreshold overruns penalties, or early disconnections of electric vehicles\n(EVs). We propose a formulation of the problem of EVCS control under\nuncertainty, and implement two Multi-Stage Stochastic Programming approaches\nthat leverage user-provided information, namely, Model Predictive Control and\nTwo-Stage Stochastic Programming. The model addresses uncertainties in charging\nsession start and end times, as well as in energy demand. A user's behavior\nmodel based on a sojourn-time-dependent stochastic process enhances cost\nreduction while maintaining customer satisfaction. The benefits of the two\nproposed methods are showcased against two baselines over a 22-day simulation\nusing a real-world dataset. The two-stage approach demonstrates robustness\nagainst early disconnections by considering a wider range of uncertainty\nscenarios for optimization. The algorithm prioritizing user satisfaction over\nelectricity cost achieves a 20% and 36% improvement in two user satisfaction\nmetrics compared to an industry-standard baseline. Additionally, the algorithm\nstriking the best balance between cost and user satisfaction exhibits a mere 3%\nrelative cost increase compared to the theoretically optimal baseline - for\nwhich the nonanticipativity constraint is relaxed - while attaining 94% and 84%\nof the user satisfaction performance in the two used satisfaction metrics.",
      "tldr_zh": "本论文提出了一种电动车充电站(EVCS)控制模型，考虑真实约束如插槽功率限制、合同阈值超限罚款和电动车提前断开问题，并使用多阶段随机规划方法（包括模型预测控制和两阶段随机规划）来处理充电会话时间和能源需求的不确定性。该模型整合基于逗留时间依赖随机过程的用户行为建模，以降低成本同时维持客户满意度。在使用真实数据集的22天模拟中，两阶段随机规划方法显示出对提前断开事件的鲁棒性，并优先用户满意度的算法相比行业标准基线改善了20%和36%的用户满意度指标。总体上，该方法在成本和满意度之间取得最佳平衡，仅比理论最优基线成本增加3%，并在满意度指标上达到94%和84%。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13224v4",
      "published_date": "2024-02-20 18:37:11 UTC",
      "updated_date": "2024-11-13 14:54:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:09:59.375074"
    },
    {
      "arxiv_id": "2403.14639v1",
      "title": "On Defining Smart Cities using Transformer Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Khurshudov"
      ],
      "abstract": "Cities worldwide are rapidly adopting smart technologies, transforming urban\nlife. Despite this trend, a universally accepted definition of 'smart city'\nremains elusive. Past efforts to define it have not yielded a consensus, as\nevidenced by the numerous definitions in use. In this paper, we endeavored to\ncreate a new 'compromise' definition that should resonate with most experts\npreviously involved in defining this concept and aimed to validate one of the\nexisting definitions. We reviewed 60 definitions of smart cities from industry,\nacademia, and various relevant organizations, employing transformer\narchitecture-based generative AI and semantic text analysis to reach this\ncompromise. We proposed a semantic similarity measure as an evaluation\ntechnique, which could generally be used to compare different smart city\ndefinitions, assessing their uniqueness or resemblance. Our methodology\nemployed generative AI to analyze various existing definitions of smart cities,\ngenerating a list of potential new composite definitions. Each of these new\ndefinitions was then tested against the pre-existing individual definitions we\nhave gathered, using cosine similarity as our metric. This process identified\nsmart city definitions with the highest average cosine similarity, semantically\npositioning them as the closest on average to all the 60 individual definitions\nselected.",
      "tldr_zh": "本论文探讨了“智能城市”（Smart Cities）的定义问题，由于缺乏共识，过去定义众多但未统一。研究者审阅了60个来自行业、学术和组织的智能城市定义，并使用Transformer Neural Networks架构的生成AI和语义文本分析（Semantic Text Analysis）生成一个新的“妥协”定义，同时提出语义相似性度量作为评估工具。方法包括通过生成AI分析现有定义、创建复合定义，并采用余弦相似性（Cosine Similarity）计算这些定义与原始定义的平均相似度。结果显示，该方法成功识别出语义上最接近所有60个定义的版本，为未来定义标准化提供了实用框架。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, 2 fugures",
      "pdf_url": "http://arxiv.org/pdf/2403.14639v1",
      "published_date": "2024-02-20 18:34:24 UTC",
      "updated_date": "2024-02-20 18:34:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:10:10.469630"
    },
    {
      "arxiv_id": "2402.13219v1",
      "title": "Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Ammar N. Abbas",
        "Chidera W. Amazu",
        "Joseph Mietkiewicz",
        "Houda Briwa",
        "Andres Alonzo Perez",
        "Gabriele Baldissone",
        "Micaela Demichela",
        "Georgios G. Chasparis",
        "John D. Kelleher",
        "Maria Chiara Leva"
      ],
      "abstract": "In complex industrial and chemical process control rooms, effective\ndecision-making is crucial for safety and efficiency. The experiments in this\npaper evaluate the impact and applications of an AI-based decision support\nsystem integrated into an improved human-machine interface, using dynamic\ninfluence diagrams, a hidden Markov model, and deep reinforcement learning. The\nenhanced support system aims to reduce operator workload, improve situational\nawareness, and provide different intervention strategies to the operator\nadapted to the current state of both the system and human performance. Such a\nsystem can be particularly useful in cases of information overload when many\nalarms and inputs are presented all within the same time window, or for junior\noperators during training. A comprehensive cross-data analysis was conducted,\ninvolving 47 participants and a diverse range of data sources such as\nsmartwatch metrics, eye-tracking data, process logs, and responses from\nquestionnaires. The results indicate interesting insights regarding the\neffectiveness of the approach in aiding decision-making, decreasing perceived\nworkload, and increasing situational awareness for the scenarios considered.\nAdditionally, the results provide valuable insights to compare differences\nbetween styles of information gathering when using the system by individual\nparticipants. These findings are particularly relevant when predicting the\noverall performance of the individual participant and their capacity to\nsuccessfully handle a plant upset and the alarms connected to it using process\nand human-machine interaction logs in real-time. These predictions enable the\ndevelopment of more effective intervention strategies.",
      "tldr_zh": "本研究分析了控制室操作员状态及其AI增强决策支持系统的影响，提出了一种Human-in-the-Loop的专用强化学习框架，用于制定适应性干预策略。框架整合了dynamic influence diagrams、hidden Markov model和deep reinforcement learning，以减少操作员工作负载、提升situational awareness，并在信息过载或初级操作员训练场景中提供针对性支持。实验涉及47名参与者，利用smartwatch metrics、eye-tracking data、process logs和问卷等多源数据进行全面分析，结果显示该系统显著改善决策效率、降低感知工作负载，并为预测操作员性能和优化干预策略提供了宝贵见解。总的来说，此框架为工业控制室的自主决策系统奠定了更可靠的基础。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13219v1",
      "published_date": "2024-02-20 18:31:27 UTC",
      "updated_date": "2024-02-20 18:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:10:22.625985"
    },
    {
      "arxiv_id": "2402.13217v2",
      "title": "VideoPrism: A Foundational Visual Encoder for Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Long Zhao",
        "Nitesh B. Gundavarapu",
        "Liangzhe Yuan",
        "Hao Zhou",
        "Shen Yan",
        "Jennifer J. Sun",
        "Luke Friedman",
        "Rui Qian",
        "Tobias Weyand",
        "Yue Zhao",
        "Rachel Hornung",
        "Florian Schroff",
        "Ming-Hsuan Yang",
        "David A. Ross",
        "Huisheng Wang",
        "Hartwig Adam",
        "Mikhail Sirotenko",
        "Ting Liu",
        "Boqing Gong"
      ],
      "abstract": "We introduce VideoPrism, a general-purpose video encoder that tackles diverse\nvideo understanding tasks with a single frozen model. We pretrain VideoPrism on\na heterogeneous corpus containing 36M high-quality video-caption pairs and 582M\nvideo clips with noisy parallel text (e.g., ASR transcripts). The pretraining\napproach improves upon masked autoencoding by global-local distillation of\nsemantic video embeddings and a token shuffling scheme, enabling VideoPrism to\nfocus primarily on the video modality while leveraging the invaluable text\nassociated with videos. We extensively test VideoPrism on four broad groups of\nvideo understanding tasks, from web video question answering to CV for science,\nachieving state-of-the-art performance on 31 out of 33 video understanding\nbenchmarks.",
      "tldr_zh": "本研究引入了 VideoPrism，这是一个通用的视觉编码器，旨在使用单一冻结模型处理多种视频理解任务。VideoPrism 在包含 36M 高质量视频-标题对和 582M 带有噪声文本（如 ASR 转录）的视频剪辑的异构语料库上预训练，通过全局-本地语义视频嵌入蒸馏和令牌洗牌方案改进 masked autoencoding，从而专注于视频模式的同时利用相关文本。在四个视频理解任务组（如网络视频问答和 CV for science）的测试中，VideoPrism 在 33 个基准中取得了 31 个的最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICML 2024. v2: added retrieval results on MSRVTT (1K-A),\n  more data analyses, and ablation studies",
      "pdf_url": "http://arxiv.org/pdf/2402.13217v2",
      "published_date": "2024-02-20 18:29:49 UTC",
      "updated_date": "2024-06-16 00:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:10:35.657792"
    },
    {
      "arxiv_id": "2402.13213v3",
      "title": "Probabilities of Chat LLMs Are Miscalibrated but Still Predict Correctness on Multiple-Choice Q&A",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Plaut",
        "Nguyen X. Khanh",
        "Tu Trinh"
      ],
      "abstract": "We study 15 large language models (LLMs) fine-tuned for chat and find that\ntheir maximum softmax probabilities (MSPs) are consistently miscalibrated on\nmultiple-choice Q&A. However, those MSPs might still encode useful uncertainty\ninformation. Specifically, we hypothesized that wrong answers would be\nassociated with smaller MSPs compared to correct answers. Via rigorous\nstatistical testing, we show that this hypothesis holds for models which\nperform well on the underlying Q&A task. We also find a strong direction\ncorrelation between Q&A accuracy and MSP correctness prediction, while finding\nno correlation between Q&A accuracy and calibration error. This suggests that\nwithin the current fine-tuning paradigm, we can expect correctness prediction\nbut not calibration to improve as LLM capabilities progress. To demonstrate the\nutility of correctness prediction, we show that when models have the option to\nabstain, performance can be improved by selectively abstaining based on the MSP\nof the initial model response, using only a small amount of labeled data to\nchoose the MSP threshold.",
      "tldr_zh": "本研究评估了15个针对聊天优化的LLM，发现它们的最大softmax probabilities (MSPs) 在多选问答任务中一致存在校准错误（miscalibrated）。尽管如此，研究通过严格统计测试验证了这样一个假设：表现良好的模型在正确答案上具有较高的MSPs，而错误答案的MSPs较低。结果显示，Q&A准确率与MSPs的正确性预测呈强正相关，但与校准错误无关，这表明未来LLM能力提升可能改善正确性预测，而非校准。最终，研究证明，通过基于MSPs选择弃权阈值（仅需少量标注数据），模型在有弃权选项时能显著提升性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13213v3",
      "published_date": "2024-02-20 18:24:47 UTC",
      "updated_date": "2025-03-19 16:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:10:47.219082"
    },
    {
      "arxiv_id": "2402.13212v2",
      "title": "Soft Self-Consistency Improves Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Han Wang",
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "abstract": "Generations from large language models (LLMs) can be improved by sampling and\nscoring multiple solutions to select a final answer. Current \"sample and\nselect\" methods such as self-consistency (SC) rely on majority voting to score\nanswers. However, when tasks have many distinct and valid answers, selection by\nvoting requires a large number of samples. This makes SC prohibitively\nexpensive for interactive tasks that involve generating multiple actions\n(answers) sequentially. After establishing that majority voting fails to\nprovide consistent gains on such tasks, we demonstrate how to increase success\nrates by softening the scoring criterion. We introduce Soft Self-Consistency\n(SOFT-SC), which replaces SC's discontinuous scoring with a continuous score\ncomputed from model likelihoods, allowing for selection even when actions are\nsparsely distributed. SOFT-SC improves both performance and efficiency on\nlong-horizon interactive tasks, requiring half as many samples as SC for\ncomparable or better performance. For a fixed number of samples, SOFT-SC leads\nto a 1.3% increase over SC in absolute success rate on writing bash programs, a\n6.6% increase on online shopping (WebShop), and a 4.7% increase for an\ninteractive household game (ALFWorld). Finally, we show that SOFT-SC can be\napplied to both open-source and black-box models.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)生成任务，提出Soft Self-Consistency (SOFT-SC)方法，以解决传统Self-Consistency (SC)依赖多数投票的局限性，该方法在多答案交互任务中需要大量样本导致效率低下。SOFT-SC通过使用连续的模型似然分数进行评分，即使答案分布稀疏也能有效选择最优答案，从而提高性能并减少样本需求，仅需SC的一半样本即可实现相当或更好的结果。在实验中，SOFT-SC在编写bash程序上成功率提高1.3%、在WebShop在线购物任务上提高6.6%、在ALFWorld交互游戏上提高4.7%。该方法适用于开源和黑箱模型，提供了一种更高效的LLMs代理优化方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Camera-Ready, the first three authors contributed equally;\n  Code: https://github.com/HanNight/soft_self_consistency",
      "pdf_url": "http://arxiv.org/pdf/2402.13212v2",
      "published_date": "2024-02-20 18:22:38 UTC",
      "updated_date": "2024-06-05 19:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:10:59.946715"
    },
    {
      "arxiv_id": "2402.13208v1",
      "title": "How do Hyenas deal with Human Speech? Speech Recognition and Translation with ConfHyena",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Gaido",
        "Sara Papi",
        "Matteo Negri",
        "Luisa Bentivogli"
      ],
      "abstract": "The attention mechanism, a cornerstone of state-of-the-art neural models,\nfaces computational hurdles in processing long sequences due to its quadratic\ncomplexity. Consequently, research efforts in the last few years focused on\nfinding more efficient alternatives. Among them, Hyena (Poli et al., 2023)\nstands out for achieving competitive results in both language modeling and\nimage classification, while offering sub-quadratic memory and computational\ncomplexity. Building on these promising results, we propose ConfHyena, a\nConformer whose encoder self-attentions are replaced with an adaptation of\nHyena for speech processing, where the long input sequences cause high\ncomputational costs. Through experiments in automatic speech recognition (for\nEnglish) and translation (from English into 8 target languages), we show that\nour best ConfHyena model significantly reduces the training time by 27%, at the\ncost of minimal quality degradation (~1%), which, in most cases, is not\nstatistically significant.",
      "tldr_zh": "本研究探讨了注意力机制（attention mechanism）在处理长序列时的二次方复杂度问题，并引入Hyena作为更高效的替代方案。作者提出ConfHyena模型，将Hyena适应到Conformer的编码器中，用于语音处理，从而显著降低计算成本。在英语自动语音识别（automatic speech recognition）和英语到8种目标语言的翻译实验中，ConfHyena最佳模型将训练时间减少27%，而性能仅下降约1%，且在多数情况下差异不显著。总的来说，该方法为高效的语音任务处理提供了可行的新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13208v1",
      "published_date": "2024-02-20 18:19:08 UTC",
      "updated_date": "2024-02-20 18:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:11:12.573813"
    },
    {
      "arxiv_id": "2402.13201v1",
      "title": "Tiny Reinforcement Learning for Quadruped Locomotion using Decision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Orhan Eren Akgün",
        "Néstor Cuevas",
        "Matheus Farias",
        "Daniel Garces"
      ],
      "abstract": "Resource-constrained robotic platforms are particularly useful for tasks that\nrequire low-cost hardware alternatives due to the risk of losing the robot,\nlike in search-and-rescue applications, or the need for a large number of\ndevices, like in swarm robotics. For this reason, it is crucial to find\nmechanisms for adapting reinforcement learning techniques to the constraints\nimposed by lower computational power and smaller memory capacities of these\nultra low-cost robotic platforms. We try to address this need by proposing a\nmethod for making imitation learning deployable onto resource-constrained\nrobotic platforms. Here we cast the imitation learning problem as a conditional\nsequence modeling task and we train a decision transformer using expert\ndemonstrations augmented with a custom reward. Then, we compress the resulting\ngenerative model using software optimization schemes, including quantization\nand pruning. We test our method in simulation using Isaac Gym, a realistic\nphysics simulation environment designed for reinforcement learning. We\nempirically demonstrate that our method achieves natural looking gaits for\nBittle, a resource-constrained quadruped robot. We also run multiple\nsimulations to show the effects of pruning and quantization on the performance\nof the model. Our results show that quantization (down to 4 bits) and pruning\nreduce model size by around 30\\% while maintaining a competitive reward, making\nthe model deployable in a resource-constrained system.",
      "tldr_zh": "该研究针对资源受限机器人平台（如搜索救援或群机器人），提出一种使用 Decision Transformers 的微型强化学习方法，以实现四足机器人（如 Bittle）的运动控制。具体而言，该方法将模仿学习问题转化为条件序列建模任务，通过专家演示和自定义奖励训练模型，并采用 quantization 和 pruning 等软件优化方案压缩模型。实验在 Isaac Gym 模拟环境中进行，结果显示优化后模型大小减少约 30%，同时保持竞争性的奖励表现，为部署在低成本硬件上的机器人运动提供了可行方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13201v1",
      "published_date": "2024-02-20 18:10:39 UTC",
      "updated_date": "2024-02-20 18:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:11:24.180659"
    },
    {
      "arxiv_id": "2403.00834v1",
      "title": "Virtual Reality for Understanding Artificial-Intelligence-driven Scientific Discovery with an Application in Quantum Optics",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Schmidt",
        "Sören Arlt",
        "Carlos Ruiz-Gonzalez",
        "Xuemei Gu",
        "Carla Rodríguez",
        "Mario Krenn"
      ],
      "abstract": "Generative Artificial Intelligence (AI) models can propose solutions to\nscientific problems beyond human capability. To truly make conceptual\ncontributions, researchers need to be capable of understanding the AI-generated\nstructures and extracting the underlying concepts and ideas. When algorithms\nprovide little explanatory reasoning alongside the output, scientists have to\nreverse-engineer the fundamental insights behind proposals based solely on\nexamples. This task can be challenging as the output is often highly complex\nand thus not immediately accessible to humans. In this work we show how\ntransferring part of the analysis process into an immersive Virtual Reality\n(VR) environment can assist researchers in developing an understanding of\nAI-generated solutions. We demonstrate the usefulness of VR in finding\ninterpretable configurations of abstract graphs, representing Quantum Optics\nexperiments. Thereby, we can manually discover new generalizations of\nAI-discoveries as well as new understanding in experimental quantum optics.\nFurthermore, it allows us to customize the search space in an informed way - as\na human-in-the-loop - to achieve significantly faster subsequent discovery\niterations. As concrete examples, with this technology, we discover a new\nresource-efficient 3-dimensional entanglement swapping scheme, as well as a\n3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our\nresults show the potential of VR for increasing a human researcher's ability to\nderive knowledge from graph-based generative AI that, which is a common\nabstract data representation used in diverse fields of science.",
      "tldr_zh": "本研究探讨了如何利用虚拟现实(VR)技术辅助理解人工智能(AI)驱动的科学发现，针对AI生成复杂结构时人类逆向工程的挑战。研究者将分析过程转移到沉浸式VR环境中，应用于量子光学实验的抽象图形配置，从而帮助手动发现AI提案的新概括和实验洞见。结果显示，这种方法不仅发现了新的资源高效3维纠缠交换方案和3维4粒子Greenberger-Horne-Zeilinger-state(GHZ-state)分析器，还能通过人类在循环中自定义搜索空间，显著加速后续发现迭代。该框架突显了VR在提升人类从图-based生成AI中提取知识方面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.GR",
        "quant-ph"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 6 figures, comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2403.00834v1",
      "published_date": "2024-02-20 17:48:01 UTC",
      "updated_date": "2024-02-20 17:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:11:37.960840"
    },
    {
      "arxiv_id": "2402.13178v2",
      "title": "Benchmarking Retrieval-Augmented Generation for Medicine",
      "title_zh": "检索增强生成在医学领域的基准测试",
      "authors": [
        "Guangzhi Xiong",
        "Qiao Jin",
        "Zhiyong Lu",
        "Aidong Zhang"
      ],
      "abstract": "While large language models (LLMs) have achieved state-of-the-art performance\non a wide range of medical question answering (QA) tasks, they still face\nchallenges with hallucinations and outdated knowledge. Retrieval-augmented\ngeneration (RAG) is a promising solution and has been widely adopted. However,\na RAG system can involve multiple flexible components, and there is a lack of\nbest practices regarding the optimal RAG setting for various medical purposes.\nTo systematically evaluate such systems, we propose the Medical Information\nRetrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind\nbenchmark including 7,663 questions from five medical QA datasets. Using\nMIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt\ntokens on 41 combinations of different corpora, retrievers, and backbone LLMs\nthrough the MedRAG toolkit introduced in this work. Overall, MedRAG improves\nthe accuracy of six different LLMs by up to 18% over chain-of-thought\nprompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level. Our\nresults show that the combination of various medical corpora and retrievers\nachieves the best performance. In addition, we discovered a log-linear scaling\nproperty and the \"lost-in-the-middle\" effects in medical RAG. We believe our\ncomprehensive evaluations can serve as practical guidelines for implementing\nRAG systems for medicine.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在医疗问答 (QA) 任务中存在的幻觉和知识过时问题，评估了检索增强生成 (RAG) 系统的性能。研究者提出 MIRAGE 基准，包括 7,663 个问题来自五个医疗 QA 数据集，并使用 MedRAG 工具包进行了大规模实验，测试了 41 种不同语料库、检索器和 LLMs 的组合，总计超过 1.8 万亿提示标记。结果显示，MedRAG 使六个 LLMs 的准确率提高高达 18%，将 GPT-3.5 和 Mixtral 的性能提升到 GPT-4 水平；此外，发现了医疗 RAG 中的对数线性缩放属性和 \"lost-in-the-middle\" 效果。这些发现为实施医疗 RAG 系统提供了实用指南。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Homepage: https://teddy-xionggz.github.io/benchmark-medical-rag/",
      "pdf_url": "http://arxiv.org/pdf/2402.13178v2",
      "published_date": "2024-02-20 17:44:06 UTC",
      "updated_date": "2024-02-23 16:46:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:11:49.757865"
    },
    {
      "arxiv_id": "2402.14857v2",
      "title": "Is the System Message Really Important to Jailbreaks in Large Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaotian Zou",
        "Yongkang Chen",
        "Ke Li"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has rendered them\nindispensable in modern society. While security measures are typically to align\nLLMs with human values prior to release, recent studies have unveiled a\nconcerning phenomenon named \"Jailbreak\". This term refers to the unexpected and\npotentially harmful responses generated by LLMs when prompted with malicious\nquestions. Most existing research focus on generating jailbreak prompts but\nsystem message configurations vary significantly in experiments. In this paper,\nwe aim to answer a question: Is the system message really important for\njailbreaks in LLMs? We conduct experiments in mainstream LLMs to generate\njailbreak prompts with varying system messages: short, long, and none. We\ndiscover that different system messages have distinct resistances to\njailbreaks. Therefore, we explore the transferability of jailbreaks across LLMs\nwith different system messages. Furthermore, we propose the System Messages\nEvolutionary Algorithm (SMEA) to generate system messages that are more\nresistant to jailbreak prompts, even with minor changes. Through SMEA, we get a\nrobust system messages population with little change in the length of system\nmessages. Our research not only bolsters LLMs security but also raises the bar\nfor jailbreaks, fostering advancements in this field of study.",
      "tldr_zh": "这篇论文探讨了系统消息（system message）在大型语言模型（LLMs）中的“Jailbreak”现象是否重要。“Jailbreak”指LLMs在面对恶意提示时产生有害响应的安全问题，作者通过实验在主流LLMs上测试了不同系统消息（短的、长的或无）的抵抗力，发现这些消息对Jailbreak的抵抗能力存在显著差异，并验证了Jailbreak提示的可转移性。论文提出System Messages Evolutionary Algorithm (SMEA)，一种进化算法，用于生成更鲁棒的系统消息，即使微小修改也能提升安全性，同时保持消息长度基本不变。该研究增强了LLMs的安全性，提高了Jailbreak的门槛，并推动相关领域的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14857v2",
      "published_date": "2024-02-20 17:39:40 UTC",
      "updated_date": "2024-06-18 19:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:12:01.583486"
    },
    {
      "arxiv_id": "2402.13147v3",
      "title": "SPRINQL: Sub-optimal Demonstrations driven Offline Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Hoang",
        "Tien Mai",
        "Pradeep Varakantham"
      ],
      "abstract": "We focus on offline imitation learning (IL), which aims to mimic an expert's\nbehavior using demonstrations without any interaction with the environment. One\nof the main challenges in offline IL is the limited support of expert\ndemonstrations, which typically cover only a small fraction of the state-action\nspace. While it may not be feasible to obtain numerous expert demonstrations,\nit is often possible to gather a larger set of sub-optimal demonstrations. For\nexample, in treatment optimization problems, there are varying levels of doctor\ntreatments available for different chronic conditions. These range from\ntreatment specialists and experienced general practitioners to less experienced\ngeneral practitioners. Similarly, when robots are trained to imitate humans in\nroutine tasks, they might learn from individuals with different levels of\nexpertise and efficiency.\n  In this paper, we propose an offline IL approach that leverages the larger\nset of sub-optimal demonstrations while effectively mimicking expert\ntrajectories. Existing offline IL methods based on behavior cloning or\ndistribution matching often face issues such as overfitting to the limited set\nof expert demonstrations or inadvertently imitating sub-optimal trajectories\nfrom the larger dataset. Our approach, which is based on inverse soft-Q\nlearning, learns from both expert and sub-optimal demonstrations. It assigns\nhigher importance (through learned weights) to aligning with expert\ndemonstrations and lower importance to aligning with sub-optimal ones. A key\ncontribution of our approach, called SPRINQL, is transforming the offline IL\nproblem into a convex optimization over the space of Q functions. Through\ncomprehensive experimental evaluations, we demonstrate that the SPRINQL\nalgorithm achieves state-of-the-art (SOTA) performance on offline IL\nbenchmarks. Code is available at https://github.com/hmhuy0/SPRINQL.",
      "tldr_zh": "该论文针对离线模仿学习（offline imitation learning）中的关键挑战——专家演示支持有限——提出了一种利用次优演示（sub-optimal demonstrations）的新方法。SPRINQL 算法基于逆软Q学习（inverse soft-Q learning），通过为专家演示分配更高权重，同时降低次优演示的影响，避免过度拟合并有效模仿专家轨迹，从而将问题转化为 Q 函数空间的凸优化。实验结果显示，SPRINQL 在离线 IL 基准测试中实现了最先进（SOTA）性能，证明了其在实际应用如医疗和机器人训练中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13147v3",
      "published_date": "2024-02-20 17:02:48 UTC",
      "updated_date": "2024-10-10 19:27:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:12:12.312724"
    },
    {
      "arxiv_id": "2402.13145v2",
      "title": "CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for Boosting Metaphor Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Shao",
        "Xinrong Yao",
        "Xingwei Qu",
        "Chenghua Lin",
        "Shi Wang",
        "Stephen W. Huang",
        "Ge Zhang",
        "Jie Fu"
      ],
      "abstract": "Metaphor is a prominent linguistic device in human language and literature,\nas they add color, imagery, and emphasis to enhance effective communication.\nThis paper introduces a large-scale high quality annotated Chinese Metaphor\nCorpus, which comprises around 28K sentences drawn from a diverse range of\nChinese literary sources, such as poems, prose, song lyrics, etc. To ensure the\naccuracy and consistency of our annotations, we introduce a comprehensive set\nof guidelines. These guidelines address the facets of metaphor annotation,\nincluding identifying tenors, vehicles, and grounds to handling the\ncomplexities of similes, personifications, juxtapositions, and hyperboles.\nBreaking tradition, our approach to metaphor generation emphasizes grounds and\ntheir distinct features rather than the conventional combination of tenors and\nvehicles. By integrating \"ground\" as a CoT (Chain of Thoughts) input, we are\nable to generate metaphors that resonate more with real-world intuition. We\ntest generative models such as Belle, Baichuan, and Chinese-alpaca-33B using\nour annotated corpus. These models are able to generate creative and fluent\nmetaphor sentences more frequently induced by selected samples from our\ndataset, demonstrating the value of our corpus for Chinese metaphor research.\nThe code is available in\nhttps://github.com/JasonShao55/Chinese_Metaphor_Explanation.",
      "tldr_zh": "这篇论文引入了CMDAG，一种大规模高质量的中文隐喻数据集，包含约28K句来自诗歌、散文和歌词等文学来源的句子，并通过全面注解指南标识tenors、vehicles和grounds，同时处理simile、personification等复杂形式。不同于传统方法，该研究强调grounds及其特征作为Chain of Thoughts (CoT)输入，以生成更符合真实直觉的隐喻句子。实验使用Belle、Baichuan和Chinese-alpaca-33B模型验证了数据集的价值，这些模型在基于CMDAG的训练后，能产生更多创意和流畅的隐喻输出。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13145v2",
      "published_date": "2024-02-20 17:00:41 UTC",
      "updated_date": "2024-02-21 03:18:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:12:26.381593"
    },
    {
      "arxiv_id": "2404.07213v1",
      "title": "Evolving Genetic Programming Tree Models for Predicting the Mechanical Properties of Green Fibers for Better Biocomposite Materials",
      "title_zh": "演化遗传编程树模型用于预测绿色纤维的机械性能以获得更好的生物复合材料",
      "authors": [
        "Faris M. AL-Oqla",
        "Hossam Faris",
        "Maria Habib",
        "Pedro A. Castillo-Valdivieso"
      ],
      "abstract": "Advanced modern technology and industrial sustainability theme have\ncontributed implementing composite materials for various industrial\napplications. Green composites are among the desired alternatives for the green\nproducts. However, to properly control the performance of the green composites,\npredicting their constituents properties are of paramount importance. This work\npresents an innovative evolving genetic programming tree models for predicting\nthe mechanical properties of natural fibers based upon several inherent\nchemical and physical properties. Cellulose, hemicellulose, lignin and moisture\ncontents as well as the Microfibrillar angle of various natural fibers were\nconsidered to establish the prediction models. A one-hold-out methodology was\napplied for training/testing phases. Robust models were developed to predict\nthe tensile strength, Young's modulus, and the elongation at break properties\nof the natural fibers. It was revealed that Microfibrillar angle was dominant\nand capable of determining the ultimate tensile strength of the natural fibers\nby 44.7% comparable to other considered properties, while the impact of\ncellulose content in the model was only 35.6%. This in order would facilitate\nutilizing artificial intelligence in predicting the overall mechanical\nproperties of natural fibers without experimental efforts and cost to enhance\ndeveloping better green composite materials for various industrial\napplications.",
      "tldr_zh": "本研究提出了一种演化遗传编程树模型（evolving genetic programming tree models），用于基于天然纤维的化学和物理属性预测其机械性能，从而提升绿色复合材料（green composites）的开发。模型考虑了纤维素（Cellulose）、半纤维素（hemicellulose）、木质素（lignin）、湿度和微纤角（Microfibrillar angle）等因素，通过one-hold-out方法训练测试，成功预测了拉伸强度（tensile strength）、杨氏模量（Young's modulus）和断裂伸长率（elongation at break）。结果显示，微纤角对拉伸强度的影响最大，占44.7%，而纤维素含量的影响为35.6%，这有助于利用人工智能减少实验成本，实现更高效的工业应用。",
      "categories": [
        "cs.NE",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07213v1",
      "published_date": "2024-02-20 16:55:57 UTC",
      "updated_date": "2024-02-20 16:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:12:36.608197"
    },
    {
      "arxiv_id": "2402.13126v1",
      "title": "VGMShield: Mitigating Misuse of Video Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Pang",
        "Yang Zhang",
        "Tianhao Wang"
      ],
      "abstract": "With the rapid advancement in video generation, people can conveniently\nutilize video generation models to create videos tailored to their specific\ndesires. Nevertheless, there are also growing concerns about their potential\nmisuse in creating and disseminating false information.\n  In this work, we introduce VGMShield: a set of three straightforward but\npioneering mitigations through the lifecycle of fake video generation. We start\nfrom \\textit{fake video detection} trying to understand whether there is\nuniqueness in generated videos and whether we can differentiate them from real\nvideos; then, we investigate the \\textit{tracing} problem, which maps a fake\nvideo back to a model that generates it. Towards these, we propose to leverage\npre-trained models that focus on {\\it spatial-temporal dynamics} as the\nbackbone to identify inconsistencies in videos. Through experiments on seven\nstate-of-the-art open-source models, we demonstrate that current models still\ncannot perfectly handle spatial-temporal relationships, and thus, we can\naccomplish detection and tracing with nearly perfect accuracy.\n  Furthermore, anticipating future generative model improvements, we propose a\n{\\it prevention} method that adds invisible perturbations to images to make the\ngenerated videos look unreal. Together with fake video detection and tracing,\nour multi-faceted set of solutions can effectively mitigate misuse of video\ngenerative models.",
      "tldr_zh": "本研究提出 VGMShield，一套针对视频生成模型滥用的多方面缓解方案，包括假视频检测、追踪和预防，以防止虚假信息传播。研究利用关注 spatial-temporal dynamics 的预训练模型，识别生成视频中的不一致性，从而实现假视频检测和追踪，并在七个最先进开源模型上达到近乎完美的准确率。同时，预防方法通过向图像添加不可见的 perturbations，使生成视频看起来不真实。这些创新措施共同有效缓解了视频生成模型的潜在误用风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13126v1",
      "published_date": "2024-02-20 16:39:23 UTC",
      "updated_date": "2024-02-20 16:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:12:47.968607"
    },
    {
      "arxiv_id": "2402.13125v2",
      "title": "TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning",
      "title_zh": "TreeEval：通过树状规划进行的大型语言模型无基准评估",
      "authors": [
        "Xiang Li",
        "Yunshi Lan",
        "Chao Yang"
      ],
      "abstract": "Recently, numerous new benchmarks have been established to evaluate the\nperformance of large language models (LLMs) via either computing a holistic\nscore or employing another LLM as a judge. However, these approaches suffer\nfrom data leakage due to the open access of the benchmark and inflexible\nevaluation process. To address this issue, we introduce $\\textbf{TreeEval}$, a\nbenchmark-free evaluation method for LLMs that let a high-performance LLM host\nan irreproducible evaluation session and essentially avoids the data leakage.\nMoreover, this LLM performs as an examiner to raise up a series of questions\nunder a topic with a tree planing strategy, which considers the current\nevaluation status to decide the next question generation and ensures the\ncompleteness and efficiency of the evaluation process. We evaluate $6$ models\nof different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately\nachieved the highest correlation coefficient with AlpacaEval2.0 using only\naround $45$ questions. We also conduct more analysis to show the robustness and\nreliability of TreeEval. Our code can be accessed via the provided\nhttps://github.com/Ashura5/TreeEval.",
      "tldr_zh": "该论文提出 TreeEval，一种无基准评估方法，通过 tree planning strategy 让高性能 Large Language Models (LLMs) 主持不可复制的评估会话，避免了传统基准的数据泄露问题。TreeEval 采用树规划策略，由 LLM 作为考官根据当前评估状态动态生成问题，确保过程的完整性和效率。实验结果显示，在评估 6 个不同参数规模（7B、13B 和 33B）的模型时，仅需约 45 个问题就与 AlpacaEval 2.0 达到了最高相关系数，并通过进一步分析验证了其稳健性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13125v2",
      "published_date": "2024-02-20 16:38:33 UTC",
      "updated_date": "2024-12-13 10:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:13:00.821747"
    },
    {
      "arxiv_id": "2402.13114v1",
      "title": "BuffGraph: Enhancing Class-Imbalanced Node Classification via Buffer Nodes",
      "title_zh": "Buff",
      "authors": [
        "Qian Wang",
        "Zemin Liu",
        "Zhen Zhang",
        "Bingsheng He"
      ],
      "abstract": "Class imbalance in graph-structured data, where minor classes are\nsignificantly underrepresented, poses a critical challenge for Graph Neural\nNetworks (GNNs). To address this challenge, existing studies generally generate\nnew minority nodes and edges connecting new nodes to the original graph to make\nclasses balanced. However, they do not solve the problem that majority classes\nstill propagate information to minority nodes by edges in the original graph\nwhich introduces bias towards majority classes. To address this, we introduce\nBuffGraph, which inserts buffer nodes into the graph, modulating the impact of\nmajority classes to improve minor class representation. Our extensive\nexperiments across diverse real-world datasets empirically demonstrate that\nBuffGraph outperforms existing baseline methods in class-imbalanced node\nclassification in both natural settings and imbalanced settings. Code is\navailable at https://anonymous.4open.science/r/BuffGraph-730A.",
      "tldr_zh": "这篇论文针对图结构数据中的类别不平衡问题，指出现有方法虽生成新少数类节点和边，但未能解决多数类通过原始边传播信息导致的偏差。作者提出 BuffGraph 框架，通过插入 buffer nodes 来调节多数类的冲击，提升少数类的表示能力。实验结果显示，在多种真实数据集上，BuffGraph 在类别不平衡节点分类任务中优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13114v1",
      "published_date": "2024-02-20 16:11:59 UTC",
      "updated_date": "2024-02-20 16:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:13:13.544072"
    },
    {
      "arxiv_id": "2402.13109v2",
      "title": "CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models",
      "title_zh": "CIF-Bench：用于评估大型",
      "authors": [
        "Yizhi LI",
        "Ge Zhang",
        "Xingwei Qu",
        "Jiali Li",
        "Zhaoqun Li",
        "Zekun Wang",
        "Hao Li",
        "Ruibin Yuan",
        "Yinghao Ma",
        "Kai Zhang",
        "Wangchunshu Zhou",
        "Yiming Liang",
        "Lei Zhang",
        "Lei Ma",
        "Jiajun Zhang",
        "Zuowen Li",
        "Stephen W. Huang",
        "Chenghua Lin",
        "Jie Fu"
      ],
      "abstract": "The advancement of large language models (LLMs) has enhanced the ability to\ngeneralize across a wide range of unseen natural language processing (NLP)\ntasks through instruction-following. Yet, their effectiveness often diminishes\nin low-resource languages like Chinese, exacerbated by biased evaluations from\ndata leakage, casting doubt on their true generalizability to new linguistic\nterritories. In response, we introduce the Chinese Instruction-Following\nBenchmark (CIF-Bench), designed to evaluate the zero-shot generalizability of\nLLMs to the Chinese language. CIF-Bench comprises 150 tasks and 15,000\ninput-output pairs, developed by native speakers to test complex reasoning and\nChinese cultural nuances across 20 categories. To mitigate data contamination,\nwe release only half of the dataset publicly, with the remainder kept private,\nand introduce diversified instructions to minimize score variance, totaling\n45,000 data instances. Our evaluation of 28 selected LLMs reveals a noticeable\nperformance gap, with the best model scoring only 52.9%, highlighting the\nlimitations of LLMs in less familiar language and task contexts. This work not\nonly uncovers the current limitations of LLMs in handling Chinese language\ntasks but also sets a new standard for future LLM generalizability research,\npushing towards the development of more adaptable, culturally informed, and\nlinguistically diverse models.",
      "tldr_zh": "该研究引入了CIF-Bench，一种中文指令遵循基准，用于评估大型语言模型(LLMs)的零样本泛化能力，特别是针对中文等低资源语言的挑战。基准包括150个任务和15,000个输入-输出对，由母语者开发，涵盖20个类别并测试复杂推理和文化细微差别；为防止数据污染，只公开一半数据集，并创建45,000个多样化指令实例。评估28个LLMs后，发现最佳模型得分仅52.9%，揭示了LLMs在中文任务中的显著性能差距。该工作不仅暴露了现有模型的局限性，还为未来LLMs的开发设定新标准，推动更具适应性、文化敏感和语言多样化的模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera-ready version for ACL 2024. Project page at\n  https://yizhilll.github.io/CIF-Bench/",
      "pdf_url": "http://arxiv.org/pdf/2402.13109v2",
      "published_date": "2024-02-20 16:02:12 UTC",
      "updated_date": "2024-06-04 14:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:13:26.431875"
    },
    {
      "arxiv_id": "2402.13098v1",
      "title": "ELAD: Explanation-Guided Large Language Models Active Distillation",
      "title_zh": "ELAD：解释引导的大语言模型主动知识蒸馏",
      "authors": [
        "Yifei Zhang",
        "Bo Pan",
        "Chen Ling",
        "Yuntong Hu",
        "Liang Zhao"
      ],
      "abstract": "The deployment and application of Large Language Models (LLMs) is hindered by\ntheir memory inefficiency, computational demands, and the high costs of API\ninferences. Traditional distillation methods, which transfer the capabilities\nof LLMs to smaller models, often fail to determine whether the knowledge has\nbeen sufficiently transferred, potentially resulting in high costs or\nincomplete distillation. In this paper, we propose an Explanation-Guided LLMs\nActive Distillation (ELAD) framework that employs an active learning strategy\nto optimize the balance between annotation costs and model performance. To\nimprove efficient sample selection, we introduce an explanation-guided sample\nselection method that identifies samples challenging its reasoning by\nexploiting uncertainties in explanation steps. Additionally, we present a\ncustomized LLM-annotated explanation revision technique where the teacher model\ndetects and corrects flaws in the student model's reasoning. Our experiments\nacross various reasoning datasets demonstrate that our framework significantly\nenhances the efficiency of LLM knowledge distillation.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的内存效率低下、计算需求高和API推理成本高等问题，提出ELAD（Explanation-Guided LLMs Active Distillation）框架，利用主动学习策略优化知识蒸馏过程中的标注成本与模型性能。ELAD的核心包括解释引导的样本选择方法，通过检测解释步骤的不确定性来识别推理挑战样本，以及自定义的LLM-annotated解释修正技术，让教师模型检测并修正学生模型的推理缺陷。实验在多种推理数据集上证明，该框架显著提升了LLMs知识蒸馏的效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13098v1",
      "published_date": "2024-02-20 15:47:59 UTC",
      "updated_date": "2024-02-20 15:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:13:37.632823"
    },
    {
      "arxiv_id": "2402.13093v2",
      "title": "Event-level Knowledge Editing",
      "title_zh": "事件级知识编辑",
      "authors": [
        "Hao Peng",
        "Xiaozhi Wang",
        "Chunyang Li",
        "Kaisheng Zeng",
        "Jiangshan Duo",
        "Yixin Cao",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Knowledge editing aims at updating knowledge of large language models (LLMs)\nto prevent them from becoming outdated. Existing work edits LLMs at the level\nof factual knowledge triplets. However, natural knowledge updates in the real\nworld come from the occurrences of new events rather than direct changes in\nfactual triplets. In this paper, we propose a new task setting: event-level\nknowledge editing, which directly edits new events into LLMs and improves over\nconventional triplet-level editing on (1) Efficiency. A single event edit leads\nto updates in multiple entailed knowledge triplets. (2) Completeness. Beyond\nupdating factual knowledge, event-level editing also requires considering the\nevent influences and updating LLMs' knowledge about future trends. We construct\na high-quality event-level editing benchmark ELKEN, consisting of 1,515 event\nedits, 6,449 questions about factual knowledge, and 10,150 questions about\nfuture tendencies. We systematically evaluate the performance of various\nknowledge editing methods and LLMs on this benchmark. We find that ELKEN poses\nsignificant challenges to existing knowledge editing approaches. Our codes and\ndataset are publicly released to facilitate further research.",
      "tldr_zh": "该论文提出了一种新的任务设置：event-level knowledge editing，用于更新大型语言模型（LLMs）的知识，以适应现实世界中新事件的发生，而非传统的factual knowledge triplets层面编辑。该方法通过直接编辑新事件，提高了编辑效率（一个事件可更新多个相关三元组）和完整性（包括事件影响及未来趋势预测）。研究者构建了ELKEN基准数据集，包含1,515个事件编辑、6,449个事实知识问题和10,150个未来趋势问题，并评估了各种知识编辑方法，发现现有方法在该基准上面临显著挑战；代码和数据集已公开以推动后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13093v2",
      "published_date": "2024-02-20 15:36:41 UTC",
      "updated_date": "2024-04-21 06:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:13:49.979753"
    },
    {
      "arxiv_id": "2402.13089v1",
      "title": "Towards an empirical understanding of MoE design choices",
      "title_zh": "迈向 MoE 设计选择的实证理解",
      "authors": [
        "Dongyang Fan",
        "Bettina Messmer",
        "Martin Jaggi"
      ],
      "abstract": "In this study, we systematically evaluate the impact of common design choices\nin Mixture of Experts (MoEs) on validation performance, uncovering distinct\ninfluences at token and sequence levels. We also present empirical evidence\nshowing comparable performance between a learned router and a frozen, randomly\ninitialized router, suggesting that learned routing may not be essential. Our\nstudy further reveals that Sequence-level routing can result in topic-specific\nweak expert specialization, in contrast to syntax specialization observed with\nToken-level routing.",
      "tldr_zh": "这篇论文通过实证研究系统评估了Mixture of Experts (MoEs)中常见设计选择的对验证性能的影响，揭示了这些选择在token和sequence层面上的不同作用。研究发现，学习路由器和随机初始化的冻结路由器性能相当，这表明学习路由可能并非必需。进一步，论文指出Sequence-level routing会导致专家在特定主题上的弱专业化，而Token-level routing则倾向于语法专业化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13089v1",
      "published_date": "2024-02-20 15:31:44 UTC",
      "updated_date": "2024-02-20 15:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:14:01.024624"
    },
    {
      "arxiv_id": "2402.13077v1",
      "title": "Mechanistic Neural Networks for Scientific Machine Learning",
      "title_zh": "用于科学机器学习的机制神经网络",
      "authors": [
        "Adeel Pervez",
        "Francesco Locatello",
        "Efstratios Gavves"
      ],
      "abstract": "This paper presents Mechanistic Neural Networks, a neural network design for\nmachine learning applications in the sciences. It incorporates a new\nMechanistic Block in standard architectures to explicitly learn governing\ndifferential equations as representations, revealing the underlying dynamics of\ndata and enhancing interpretability and efficiency in data modeling. Central to\nour approach is a novel Relaxed Linear Programming Solver (NeuRLP) inspired by\na technique that reduces solving linear ODEs to solving linear programs. This\nintegrates well with neural networks and surpasses the limitations of\ntraditional ODE solvers enabling scalable GPU parallel processing. Overall,\nMechanistic Neural Networks demonstrate their versatility for scientific\nmachine learning applications, adeptly managing tasks from equation discovery\nto dynamic systems modeling. We prove their comprehensive capabilities in\nanalyzing and interpreting complex scientific data across various applications,\nshowing significant performance against specialized state-of-the-art methods.",
      "tldr_zh": "本文提出Mechanistic Neural Networks，一种专为科学机器学习设计的神经网络架构，通过在标准模型中融入Mechanistic Block，显式学习控制微分方程(ODE)作为数据表示，从而揭示底层动态并提升模型的可解释性和效率。核心创新是Novel Relaxed Linear Programming Solver (NeuRLP)，它将线性ODE求解简化为线性规划，支持可扩展的GPU并行处理，并克服了传统ODE求解器的局限性。该框架在方程发现和动态系统建模等应用中表现出色，性能显著优于专业化的最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13077v1",
      "published_date": "2024-02-20 15:23:24 UTC",
      "updated_date": "2024-02-20 15:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:14:13.958818"
    },
    {
      "arxiv_id": "2402.13304v1",
      "title": "Harmful algal bloom forecasting. A comparison between stream and batch learning",
      "title_zh": "有害藻华预测：流式学习与批量学习之间的比较",
      "authors": [
        "Andres Molares-Ulloa",
        "Elisabet Rocruz",
        "Daniel Rivero",
        "Xosé A. Padin",
        "Rita Nolasco",
        "Jesús Dubert",
        "Enrique Fernandez-Blanco"
      ],
      "abstract": "Diarrhetic Shellfish Poisoning (DSP) is a global health threat arising from\nshellfish contaminated with toxins produced by dinoflagellates. The condition,\nwith its widespread incidence, high morbidity rate, and persistent shellfish\ntoxicity, poses risks to public health and the shellfish industry. High biomass\nof toxin-producing algae such as DSP are known as Harmful Algal Blooms (HABs).\nMonitoring and forecasting systems are crucial for mitigating HABs impact.\nPredicting harmful algal blooms involves a time-series-based problem with a\nstrong historical seasonal component, however, recent anomalies due to changes\nin meteorological and oceanographic events have been observed. Stream Learning\nstands out as one of the most promising approaches for addressing\ntime-series-based problems with concept drifts. However, its efficacy in\npredicting HABs remains unproven and needs to be tested in comparison with\nBatch Learning. Historical data availability is a critical point in developing\npredictive systems. In oceanography, the available data collection can have\nsome constrains and limitations, which has led to exploring new tools to obtain\nmore exhaustive time series. In this study, a machine learning workflow for\npredicting the number of cells of a toxic dinoflagellate, Dinophysis acuminata,\nwas developed with several key advancements. Seven machine learning algorithms\nwere compared within two learning paradigms. Notably, the output data from\nCROCO, the ocean hydrodynamic model, was employed as the primary dataset,\npalliating the limitation of time-continuous historical data. This study\nhighlights the value of models interpretability, fair models comparison\nmethodology, and the incorporation of Stream Learning models. The model DoME,\nwith an average R2 of 0.77 in the 3-day-ahead prediction, emerged as the most\neffective and interpretable predictor, outperforming the other algorithms.",
      "tldr_zh": "本研究比较了 Stream Learning 和 Batch Learning 在有害藻华 (HABs) 预测中的效能，针对 Diarrhetic Shellfish Poisoning (DSP) 所带来的公共健康和 shellfish 产业风险。研究开发了一个机器学习工作流，使用七种算法和 CROCO 海洋水动力模型的输出作为主要数据集，来预测毒性甲藻 Dinophysis acuminata 的细胞数量，并强调了模型可解释性和公平比较方法。结果显示，DoME 模型在 3 天预测中表现最佳，平均 R2 为 0.77，证明了 Stream Learning 在处理时间序列概念漂移问题上的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13304v1",
      "published_date": "2024-02-20 15:01:11 UTC",
      "updated_date": "2024-02-20 15:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:14:26.551792"
    },
    {
      "arxiv_id": "2402.13058v2",
      "title": "Random Graph Set and Evidence Pattern Reasoning Model",
      "title_zh": "翻译失败",
      "authors": [
        "Tianxiang Zhan",
        "Zhen Li",
        "Yong Deng"
      ],
      "abstract": "Evidence theory is widely used in decision-making and reasoning systems. In\nprevious research, Transferable Belief Model (TBM) is a commonly used\nevidential decision making model, but TBM is a non-preference model. In order\nto better fit the decision making goals, the Evidence Pattern Reasoning Model\n(EPRM) is proposed. By defining pattern operators and decision making\noperators, corresponding preferences can be set for different tasks. Random\nPermutation Set (RPS) expands order information for evidence theory. It is hard\nfor RPS to characterize the complex relationship between samples such as\ncycling, paralleling relationships. Therefore, Random Graph Set (RGS) were\nproposed to model complex relationships and represent more event types. In\norder to illustrate the significance of RGS and EPRM, an experiment of aircraft\nvelocity ranking was designed and 10,000 cases were simulated. The\nimplementation of EPRM called Conflict Resolution Decision optimized 18.17\\% of\nthe cases compared to Mean Velocity Decision, effectively improving the\naircraft velocity ranking. EPRM provides a unified solution for evidence-based\ndecision making.",
      "tldr_zh": "本研究针对证据理论在决策系统中的应用，提出了Evidence Pattern Reasoning Model (EPRM)，通过定义pattern operators和decision making operators来设置任务偏好，从而改进Transferable Belief Model (TBM)的局限性。同时，引入Random Graph Set (RGS)来扩展Random Permutation Set (RPS)，以更好地建模样本间的复杂关系，如循环和并行。EPRM和RGS相结合，能处理更多事件类型，提供统一的证据决策框架。在飞机速度排序实验中，模拟1万案例后，EPRM的Conflict Resolution Decision比Mean Velocity Decision优化了18.17%的结果，显著提升了决策效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13058v2",
      "published_date": "2024-02-20 14:52:52 UTC",
      "updated_date": "2024-03-09 08:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:14:36.727869"
    },
    {
      "arxiv_id": "2402.13055v2",
      "title": "Identifying Semantic Induction Heads to Understand In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Ren",
        "Qipeng Guo",
        "Hang Yan",
        "Dongrui Liu",
        "Quanshi Zhang",
        "Xipeng Qiu",
        "Dahua Lin"
      ],
      "abstract": "Although large language models (LLMs) have demonstrated remarkable\nperformance, the lack of transparency in their inference logic raises concerns\nabout their trustworthiness. To gain a better understanding of LLMs, we conduct\na detailed analysis of the operations of attention heads and aim to better\nunderstand the in-context learning of LLMs. Specifically, we investigate\nwhether attention heads encode two types of relationships between tokens\npresent in natural languages: the syntactic dependency parsed from sentences\nand the relation within knowledge graphs. We find that certain attention heads\nexhibit a pattern where, when attending to head tokens, they recall tail tokens\nand increase the output logits of those tail tokens. More crucially, the\nformulation of such semantic induction heads has a close correlation with the\nemergence of the in-context learning ability of language models. The study of\nsemantic attention heads advances our understanding of the intricate operations\nof attention heads in transformers, and further provides new insights into the\nin-context learning of LLMs.",
      "tldr_zh": "这篇论文通过分析大型语言模型(LLMs)的注意力头(attention heads)，探讨了其上下文学习(in-context learning)机制，以提升模型的透明度和可信度。研究者检查了注意力头是否编码了标记之间的句法依赖(syntactic dependency)和知识图谱关系，并发现某些注意力头在关注头标记时会回想尾标记并提升其输出 logits，从而形成了语义归纳头(semantic induction heads)。这些发现揭示了语义归纳头与LLMs上下文学习能力之间的密切关联，为理解transformer中注意力头的复杂运作提供了新的见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13055v2",
      "published_date": "2024-02-20 14:43:39 UTC",
      "updated_date": "2024-07-25 08:07:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:14:49.722054"
    },
    {
      "arxiv_id": "2402.13040v1",
      "title": "Text-Guided Molecule Generation with Diffusion Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Haisong Gong",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang"
      ],
      "abstract": "Text-guided molecule generation is a task where molecules are generated to\nmatch specific textual descriptions. Recently, most existing SMILES-based\nmolecule generation methods rely on an autoregressive architecture. In this\nwork, we propose the Text-Guided Molecule Generation with Diffusion Language\nModel (TGM-DLM), a novel approach that leverages diffusion models to address\nthe limitations of autoregressive methods. TGM-DLM updates token embeddings\nwithin the SMILES string collectively and iteratively, using a two-phase\ndiffusion generation process. The first phase optimizes embeddings from random\nnoise, guided by the text description, while the second phase corrects invalid\nSMILES strings to form valid molecular representations. We demonstrate that\nTGM-DLM outperforms MolT5-Base, an autoregressive model, without the need for\nadditional data resources. Our findings underscore the remarkable effectiveness\nof TGM-DLM in generating coherent and precise molecules with specific\nproperties, opening new avenues in drug discovery and related scientific\ndomains. Code will be released at: https://github.com/Deno-V/tgm-dlm.",
      "tldr_zh": "本研究提出了一种名为 TGM-DLM 的文本引导分子生成方法，使用 diffusion models 来克服传统自回归架构（如基于 SMILES 的方法）的局限性。TGM-DLM 通过一个两阶段过程实现：第一阶段从随机噪声优化 token embeddings，并受文本描述引导；第二阶段修正无效 SMILES 字符串以生成有效的分子表示。该方法无需额外数据资源，便在性能上优于 MolT5-Base 模型，并在药物发现等领域展示了生成连贯且精确分子的显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by 38th Association for the Advancement of Artificial\n  Intelligence, AAAI",
      "pdf_url": "http://arxiv.org/pdf/2402.13040v1",
      "published_date": "2024-02-20 14:29:02 UTC",
      "updated_date": "2024-02-20 14:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:15:00.470991"
    },
    {
      "arxiv_id": "2402.13037v2",
      "title": "Align Your Intents: Offline Imitation Learning via Optimal Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Maksim Bobrin",
        "Nazar Buzun",
        "Dmitrii Krylov",
        "Dmitry V. Dylov"
      ],
      "abstract": "Offline Reinforcement Learning (RL) addresses the problem of sequential\ndecision-making by learning optimal policy through pre-collected data, without\ninteracting with the environment. As yet, it has remained somewhat impractical,\nbecause one rarely knows the reward explicitly and it is hard to distill it\nretrospectively. Here, we show that an imitating agent can still learn the\ndesired behavior merely from observing the expert, despite the absence of\nexplicit rewards or action labels. In our method, AILOT (Aligned Imitation\nLearning via Optimal Transport), we involve special representation of states in\na form of intents that incorporate pairwise spatial distances within the data.\nGiven such representations, we define intrinsic reward function via optimal\ntransport distance between the expert's and the agent's trajectories. We report\nthat AILOT outperforms state-of-the art offline imitation learning algorithms\non D4RL benchmarks and improves the performance of other offline RL algorithms\nby dense reward relabelling in the sparse-reward tasks.",
      "tldr_zh": "本论文提出 AILOT（Aligned Imitation Learning via Optimal Transport），一种离线模仿学习方法，用于在没有显式奖励或动作标签的情况下，从观察专家行为中学习最优策略。AILOT 通过意图（intents）表示状态，这些表示包含数据中的成对空间距离，并利用 Optimal Transport 距离定义内在奖励函数，从而对齐代理和专家的轨迹。实验结果显示，AILOT 在 D4RL 基准上超越最先进离线模仿学习算法，并在稀疏奖励任务中通过密集奖励重新标记，提升了其他 Offline Reinforcement Learning 算法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13037v2",
      "published_date": "2024-02-20 14:24:00 UTC",
      "updated_date": "2024-10-04 07:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:15:14.527218"
    },
    {
      "arxiv_id": "2402.13035v3",
      "title": "Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Che Zhang",
        "Zhenyang Xiao",
        "Chengcheng Han",
        "Yixin Lian",
        "Yuejian Fang"
      ],
      "abstract": "Self-correction has achieved impressive results in enhancing the style and\nsecurity of the generated output from large language models (LLMs). However,\nrecent studies suggest that self-correction might be limited or even\ncounterproductive in reasoning tasks due to LLMs' difficulties in identifying\nlogical mistakes.\n  In this paper, we aim to enhance the self-checking capabilities of LLMs by\nconstructing training data for checking tasks. Specifically, we apply the Chain\nof Thought (CoT) methodology to self-checking tasks, utilizing fine-grained\nstep-level analyses and explanations to assess the correctness of reasoning\npaths. We propose a specialized checking format called \"Step CoT Check\".\nFollowing this format, we construct a checking-correction dataset that includes\ndetailed step-by-step analysis and checking. Then we fine-tune LLMs to enhance\ntheir error detection and correction abilities.\n  Our experiments demonstrate that fine-tuning with the \"Step CoT Check\" format\nsignificantly improves the self-checking and self-correction abilities of LLMs\nacross multiple benchmarks. This approach outperforms other formats, especially\nin locating the incorrect position, with greater benefits observed in larger\nmodels.\n  For reproducibility, all the datasets and code are provided in\nhttps://github.com/bammt/Learn-to-check.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在推理任务中自校正能力的局限性（如难以识别逻辑错误），提出通过构建专用训练数据来提升其自检查能力。\n具体方法采用Chain of Thought (CoT)技术，开发了“Step CoT Check”格式，该格式通过细粒度的步骤级分析和解释来评估推理路径的正确性，并据此构建数据集对LLMs进行微调。\n实验结果表明，这种方法显著提高了LLMs在多个基准上的自检查和自修正性能，尤其在定位错误位置方面效果更佳，且较大模型受益更多。\n为便于复现，研究提供了开源数据集和代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13035v3",
      "published_date": "2024-02-20 14:23:23 UTC",
      "updated_date": "2024-06-17 15:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:15:27.267956"
    },
    {
      "arxiv_id": "2402.13028v1",
      "title": "Heterogeneous Graph Reasoning for Fact Checking over Texts and Tables",
      "title_zh": "翻译失败",
      "authors": [
        "Haisong Gong",
        "Weizhi Xu",
        "Shu wu",
        "Qiang Liu",
        "Liang Wang"
      ],
      "abstract": "Fact checking aims to predict claim veracity by reasoning over multiple\nevidence pieces. It usually involves evidence retrieval and veracity reasoning.\nIn this paper, we focus on the latter, reasoning over unstructured text and\nstructured table information. Previous works have primarily relied on\nfine-tuning pretrained language models or training homogeneous-graph-based\nmodels. Despite their effectiveness, we argue that they fail to explore the\nrich semantic information underlying the evidence with different structures. To\naddress this, we propose a novel word-level Heterogeneous-graph-based model for\nFact Checking over unstructured and structured information, namely HeterFC. Our\napproach leverages a heterogeneous evidence graph, with words as nodes and\nthoughtfully designed edges representing different evidence properties. We\nperform information propagation via a relational graph neural network,\nfacilitating interactions between claims and evidence. An attention-based\nmethod is utilized to integrate information, combined with a language model for\ngenerating predictions. We introduce a multitask loss function to account for\npotential inaccuracies in evidence retrieval. Comprehensive experiments on the\nlarge fact checking dataset FEVEROUS demonstrate the effectiveness of HeterFC.\nCode will be released at: https://github.com/Deno-V/HeterFC.",
      "tldr_zh": "这篇论文提出了一种新型事实核查方法HeterFC，用于在非结构化文本和结构化表格上进行推理，旨在解决现有模型未充分利用不同证据结构语义信息的问题。HeterFC构建了一个异构证据图（以单词为节点，边代表各种证据属性），并通过关系图神经网络（relational graph neural network）实现信息传播，促进声明与证据的互动。模型结合注意力-based method和语言模型生成预测，并引入多任务损失函数（multitask loss function）来处理证据检索的潜在不准确性。在FEVEROUS数据集上的全面实验证明，HeterFC显著提升了事实核查的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by 38th Association for the Advancement of Artificial\n  Intelligence, AAAI",
      "pdf_url": "http://arxiv.org/pdf/2402.13028v1",
      "published_date": "2024-02-20 14:10:40 UTC",
      "updated_date": "2024-02-20 14:10:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:15:39.067806"
    },
    {
      "arxiv_id": "2402.13025v1",
      "title": "CFEVER: A Chinese Fact Extraction and VERification Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Ying-Jia Lin",
        "Chun-Yi Lin",
        "Chia-Jen Yeh",
        "Yi-Ting Li",
        "Yun-Yu Hu",
        "Chih-Hao Hsu",
        "Mei-Feng Lee",
        "Hung-Yu Kao"
      ],
      "abstract": "We present CFEVER, a Chinese dataset designed for Fact Extraction and\nVERification. CFEVER comprises 30,012 manually created claims based on content\nin Chinese Wikipedia. Each claim in CFEVER is labeled as \"Supports\", \"Refutes\",\nor \"Not Enough Info\" to depict its degree of factualness. Similar to the FEVER\ndataset, claims in the \"Supports\" and \"Refutes\" categories are also annotated\nwith corresponding evidence sentences sourced from single or multiple pages in\nChinese Wikipedia. Our labeled dataset holds a Fleiss' kappa value of 0.7934\nfor five-way inter-annotator agreement. In addition, through the experiments\nwith the state-of-the-art approaches developed on the FEVER dataset and a\nsimple baseline for CFEVER, we demonstrate that our dataset is a new rigorous\nbenchmark for factual extraction and verification, which can be further used\nfor developing automated systems to alleviate human fact-checking efforts.\nCFEVER is available at https://ikmlab.github.io/CFEVER.",
      "tldr_zh": "本研究提出了 CFEVER，一个基于中文维基百科的 Fact Extraction and VERification 数据集，包含 30,012 个手动创建的声明，每个声明被标记为 \"Supports\"、\"Refutes\" 或 \"Not Enough Info\"，并标注了相应的证据句子。数据集的五分类 inter-annotator 一致性达到了 Fleiss' kappa 值 0.7934，展示了其高质量标注。实验结果表明，CFEVER 是一个严格的基准，能用于评估事实提取和验证模型，从而帮助开发自动化事实检查系统，以减轻人工负担。数据集可从 https://ikmlab.github.io/CFEVER 获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI-24",
      "pdf_url": "http://arxiv.org/pdf/2402.13025v1",
      "published_date": "2024-02-20 14:08:24 UTC",
      "updated_date": "2024-02-20 14:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:15:50.598938"
    },
    {
      "arxiv_id": "2402.13019v1",
      "title": "Improving Neural-based Classification with Logical Background Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Ledaguenel",
        "Céline Hudelot",
        "Mostepha Khouadjia"
      ],
      "abstract": "Neurosymbolic AI is a growing field of research aiming to combine neural\nnetworks learning capabilities with the reasoning abilities of symbolic\nsystems. This hybridization can take many shapes. In this paper, we propose a\nnew formalism for supervised multi-label classification with propositional\nbackground knowledge. We introduce a new neurosymbolic technique called\nsemantic conditioning at inference, which only constrains the system during\ninference while leaving the training unaffected. We discuss its theoritical and\npractical advantages over two other popular neurosymbolic techniques: semantic\nconditioning and semantic regularization. We develop a new multi-scale\nmethodology to evaluate how the benefits of a neurosymbolic technique evolve\nwith the scale of the network. We then evaluate experimentally and compare the\nbenefits of all three techniques across model scales on several datasets. Our\nresults demonstrate that semantic conditioning at inference can be used to\nbuild more accurate neural-based systems with fewer resources while\nguaranteeing the semantic consistency of outputs.",
      "tldr_zh": "本研究探讨了神经符号 AI（Neurosymbolic AI），提出了一种新的形式主义，用于在监督多标签分类中整合命题背景知识。作者引入了“semantic conditioning at inference”技术，该方法仅在推理阶段约束系统，而不影响训练过程，从而与“semantic conditioning”和“semantic regularization”等现有技术相比，具有理论和实际优势。研究开发了一种多尺度方法来评估这些技术的性能随模型规模的变化，并通过实验在多个数据集上比较了它们。结果表明，“semantic conditioning at inference”能提升神经系统的准确性，减少资源消耗，同时确保输出的语义一致性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures, submitted to IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13019v1",
      "published_date": "2024-02-20 14:01:26 UTC",
      "updated_date": "2024-02-20 14:01:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:16:01.330951"
    },
    {
      "arxiv_id": "2403.15405v3",
      "title": "Predicting Parkinson's disease trajectory using clinical and functional MRI features: a reproduction and replication study",
      "title_zh": "翻译失败",
      "authors": [
        "Elodie Germani",
        "Nikhil Baghwat",
        "Mathieu Dugré",
        "Rémi Gau",
        "Albert Montillo",
        "Kevin Nguyen",
        "Andrzej Sokolowski",
        "Madeleine Sharp",
        "Jean-Baptiste Poline",
        "Tristan Glatard"
      ],
      "abstract": "Parkinson's disease (PD) is a common neurodegenerative disorder with a poorly\nunderstood physiopathology and no established biomarkers for the diagnosis of\nearly stages and for prediction of disease progression. Several neuroimaging\nbiomarkers have been studied recently, but these are susceptible to several\nsources of variability related for instance to cohort selection or image\nanalysis. In this context, an evaluation of the robustness of such biomarkers\nto variations in the data processing workflow is essential. This study is part\nof a larger project investigating the replicability of potential neuroimaging\nbiomarkers of PD. Here, we attempt to reproduce (re-implementing the\nexperiments with the same data, same method) and replicate (different data\nand/or method) the models described in [1] to predict individual's PD current\nstate and progression using demographic, clinical and neuroimaging features\n(fALFF and ReHo extracted from resting-state fMRI). We use the Parkinson's\nProgression Markers Initiative dataset (PPMI, ppmi-info.org), as in [1] and aim\nto reproduce the original cohort, imaging features and machine learning models\nas closely as possible using the information available in the paper and the\ncode. We also investigated methodological variations in cohort selection,\nfeature extraction pipelines and sets of input features. Different criteria\nwere used to evaluate the reproduction and compare the reproduced results with\nthe original ones. Notably, we obtained significantly better than chance\nperformance using the analysis pipeline closest to that in the original study\n(R2 \\&gt; 0), which is consistent with its findings. Moreover, using derived\ndata provided by the authors of the original study, we were able to make an\nexact reproduction and managed to obtain results that were close to the\noriginal ones. The challenges encountered while reproducing and replicating the\noriginal work are likely explained by the complexity of neuroimaging studies,\nin particular in clinical settings. We provide recommendations to further\nfacilitate the reproducibility of such studies in the future.",
      "tldr_zh": "这篇研究旨在再现和复制先前模型，以预测帕金森病（PD）的当前状态和进展轨迹，使用人口统计学、临床特征以及从静息态 fMRI 提取的神经影像特征（如 fALFF 和 ReHo）。研究者使用了 Parkinson's Progression Markers Initiative 数据集 (PPMI)，并探索了方法变异，包括队列选择、特征提取管道和输入特征集，以评估模型的稳健性。结果显示，使用最接近原研究的分析管道，模型性能显著优于机会水平（R2 > 0），并通过原作者提供的派生数据实现了精确再现，结果与原研究高度一致。该研究突出了神经影像研究的复杂性及其临床挑战，并提供了建议以提升未来研究的再现性。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "PLoS ONE, In press",
      "pdf_url": "http://arxiv.org/pdf/2403.15405v3",
      "published_date": "2024-02-20 13:42:50 UTC",
      "updated_date": "2025-02-12 10:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:16:14.951787"
    },
    {
      "arxiv_id": "2402.13301v2",
      "title": "Structure-informed Positional Encoding for Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Manvi Agarwal",
        "Changhong Wang",
        "Gaël Richard"
      ],
      "abstract": "Music generated by deep learning methods often suffers from a lack of\ncoherence and long-term organization. Yet, multi-scale hierarchical structure\nis a distinctive feature of music signals. To leverage this information, we\npropose a structure-informed positional encoding framework for music generation\nwith Transformers. We design three variants in terms of absolute, relative and\nnon-stationary positional information. We comprehensively test them on two\nsymbolic music generation tasks: next-timestep prediction and accompaniment\ngeneration. As a comparison, we choose multiple baselines from the literature\nand demonstrate the merits of our methods using several musically-motivated\nevaluation metrics. In particular, our methods improve the melodic and\nstructural consistency of the generated pieces.",
      "tldr_zh": "本研究针对深度学习音乐生成中存在的连贯性和长期组织问题，提出了一种基于 Transformers 的结构信息位置编码框架，以利用音乐信号的多尺度层次结构。该框架设计了三种变体，包括 absolute positional information、relative positional information 和 non-stationary positional information，并在 next-timestep prediction 和 accompaniment generation 等符号音乐生成任务上进行测试。与文献中的基线模型相比，该方法显著提高了生成的音乐片段在 melodic 和 structural consistency 方面的表现。总的来说，此框架为提升音乐生成质量提供了有效途径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13301v2",
      "published_date": "2024-02-20 13:41:35 UTC",
      "updated_date": "2024-02-28 12:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:16:24.896698"
    },
    {
      "arxiv_id": "2402.12993v1",
      "title": "An Autonomous Large Language Model Agent for Chemical Literature Data Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Kexin Chen",
        "Hanqun Cao",
        "Junyou Li",
        "Yuyang Du",
        "Menghao Guo",
        "Xin Zeng",
        "Lanqing Li",
        "Jiezhong Qiu",
        "Pheng Ann Heng",
        "Guangyong Chen"
      ],
      "abstract": "Chemical synthesis, which is crucial for advancing material synthesis and\ndrug discovery, impacts various sectors including environmental science and\nhealthcare. The rise of technology in chemistry has generated extensive\nchemical data, challenging researchers to discern patterns and refine synthesis\nprocesses. Artificial intelligence (AI) helps by analyzing data to optimize\nsynthesis and increase yields. However, AI faces challenges in processing\nliterature data due to the unstructured format and diverse writing style of\nchemical literature. To overcome these difficulties, we introduce an end-to-end\nAI agent framework capable of high-fidelity extraction from extensive chemical\nliterature. This AI agent employs large language models (LLMs) for prompt\ngeneration and iterative optimization. It functions as a chemistry assistant,\nautomating data collection and analysis, thereby saving manpower and enhancing\nperformance. Our framework's efficacy is evaluated using accuracy, recall, and\nF1 score of reaction condition data, and we compared our method with human\nexperts in terms of content correctness and time efficiency. The proposed\napproach marks a significant advancement in automating chemical literature\nextraction and demonstrates the potential for AI to revolutionize data\nmanagement and utilization in chemistry.",
      "tldr_zh": "该研究提出了一种自主的 Large Language Model (LLM) 代理框架，用于化学文献数据挖掘，旨在解决文献数据非结构化和多样写作风格带来的挑战。框架通过 LLMs 进行提示生成和迭代优化，实现端到端的自动化数据提取和分析，提升化学合成过程的效率。该代理作为化学助手，能显著节省人力，并在反应条件数据的准确率、召回率和 F1 分数上优于人类专家，标志着 AI 在化学数据管理和利用领域的重大进展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12993v1",
      "published_date": "2024-02-20 13:21:46 UTC",
      "updated_date": "2024-02-20 13:21:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:16:37.679352"
    },
    {
      "arxiv_id": "2402.12991v2",
      "title": "TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Gubri",
        "Dennis Ulmer",
        "Hwaran Lee",
        "Sangdoo Yun",
        "Seong Joon Oh"
      ],
      "abstract": "Large Language Model (LLM) services and models often come with legal rules on\nwho can use them and how they must use them. Assessing the compliance of the\nreleased LLMs is crucial, as these rules protect the interests of the LLM\ncontributor and prevent misuse. In this context, we describe the novel\nfingerprinting problem of Black-box Identity Verification (BBIV). The goal is\nto determine whether a third-party application uses a certain LLM through its\nchat function. We propose a method called Targeted Random Adversarial Prompt\n(TRAP) that identifies the specific LLM in use. We repurpose adversarial\nsuffixes, originally proposed for jailbreaking, to get a pre-defined answer\nfrom the target LLM, while other models give random answers. TRAP detects the\ntarget LLMs with over 95% true positive rate at under 0.2% false positive rate\neven after a single interaction. TRAP remains effective even if the LLM has\nminor changes that do not significantly alter the original function.",
      "tldr_zh": "该论文针对大型语言模型（LLM）的合规性评估，提出了Black-box Identity Verification (BBIV)问题，即通过聊天功能检测第三方应用是否在使用特定LLM。为此，研究引入了Targeted Random Adversarial Prompt (TRAP)方法，该方法利用adversarial suffixes设计针对性提示，从目标LLM获取预定义答案，而其他模型则返回随机响应。实验结果显示，TRAP在单次交互中可实现超过95%的真正率和低于0.2%的假正率，即使LLM有轻微改动，检测效果依然稳定。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACL 2024 (findings)",
      "pdf_url": "http://arxiv.org/pdf/2402.12991v2",
      "published_date": "2024-02-20 13:20:39 UTC",
      "updated_date": "2024-06-06 17:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:16:48.959817"
    },
    {
      "arxiv_id": "2402.12984v1",
      "title": "Can GNN be Good Adapter for LLMs?",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanwen Huang",
        "Kaiqiao Han",
        "Yang Yang",
        "Dezheng Bao",
        "Quanjin Tao",
        "Ziwei Chai",
        "Qi Zhu"
      ],
      "abstract": "Recently, large language models (LLMs) have demonstrated superior\ncapabilities in understanding and zero-shot learning on textual data, promising\nsignificant advances for many text-related domains. In the graph domain,\nvarious real-world scenarios also involve textual data, where tasks and node\nfeatures can be described by text. These text-attributed graphs (TAGs) have\nbroad applications in social media, recommendation systems, etc. Thus, this\npaper explores how to utilize LLMs to model TAGs. Previous methods for TAG\nmodeling are based on million-scale LMs. When scaled up to billion-scale LLMs,\nthey face huge challenges in computational costs. Additionally, they also\nignore the zero-shot inference capabilities of LLMs. Therefore, we propose\nGraphAdapter, which uses a graph neural network (GNN) as an efficient adapter\nin collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN\nadapter introduces only a few trainable parameters and can be trained with low\ncomputation costs. The entire framework is trained using auto-regression on\nnode text (next token prediction). Once trained, GraphAdapter can be seamlessly\nfine-tuned with task-specific prompts for various downstream tasks. Through\nextensive experiments across multiple real-world TAGs, GraphAdapter based on\nLlama 2 gains an average improvement of approximately 5\\% in terms of node\nclassification. Furthermore, GraphAdapter can also adapt to other language\nmodels, including RoBERTa, GPT-2. The promising results demonstrate that GNNs\ncan serve as effective adapters for LLMs in TAG modeling.",
      "tldr_zh": "这篇论文探讨了图神经网络 (GNN) 是否能作为高效适配器，与大型语言模型 (LLMs) 协作来建模文本属性图 (TAGs)，以解决现有方法在计算成本和零样本推理能力上的局限。作者提出 GraphAdapter 框架，使用 GNN 作为适配器，仅引入少量可训练参数，通过节点文本的自回归训练实现高效学习。实验结果显示，该框架基于 Llama 2 在多个真实 TAGs 的节点分类任务上平均提升约 5%，并可扩展到其他模型如 RoBERTa 和 GPT-2，从而证明 GNNs 是 LLMs 在 TAG 建模中的有效适配器。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by WWW'24",
      "pdf_url": "http://arxiv.org/pdf/2402.12984v1",
      "published_date": "2024-02-20 13:13:13 UTC",
      "updated_date": "2024-02-20 13:13:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:17:02.569936"
    },
    {
      "arxiv_id": "2402.14856v2",
      "title": "Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Mondorf",
        "Barbara Plank"
      ],
      "abstract": "Deductive reasoning plays a pivotal role in the formulation of sound and\ncohesive arguments. It allows individuals to draw conclusions that logically\nfollow, given the truth value of the information provided. Recent progress in\nthe domain of large language models (LLMs) has showcased their capability in\nexecuting deductive reasoning tasks. Nonetheless, a significant portion of\nresearch primarily assesses the accuracy of LLMs in solving such tasks, often\noverlooking a deeper analysis of their reasoning behavior. In this study, we\ndraw upon principles from cognitive psychology to examine inferential\nstrategies employed by LLMs, through a detailed evaluation of their responses\nto propositional logic problems. Our findings indicate that LLMs display\nreasoning patterns akin to those observed in humans, including strategies like\n$\\textit{supposition following}$ or $\\textit{chain construction}$. Moreover,\nour research demonstrates that the architecture and scale of the model\nsignificantly affect its preferred method of reasoning, with more advanced\nmodels tending to adopt strategies more frequently than less sophisticated\nones. Importantly, we assert that a model's accuracy, that is the correctness\nof its final conclusion, does not necessarily reflect the validity of its\nreasoning process. This distinction underscores the necessity for more nuanced\nevaluation procedures in the field.",
      "tldr_zh": "这篇论文比较了人类和大型语言模型 (LLMs) 在演绎推理中的推理策略，强调现有研究多关注 LLMs 的准确性而忽略其推理行为。研究者借鉴认知心理学原则，通过分析 LLMs 对命题逻辑问题的响应，发现 LLMs 表现出类似于人类的模式，如 supposition following 和 chain construction 等策略。结果表明，模型的架构和规模显著影响其偏好的推理方法，更先进的模型更常采用这些策略。最终，该研究指出，LLMs 的准确性并不代表推理过程的有效性，呼吁采用更细致的评估程序。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 main, 31 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14856v2",
      "published_date": "2024-02-20 12:58:14 UTC",
      "updated_date": "2024-06-03 13:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:17:15.606689"
    },
    {
      "arxiv_id": "2402.12976v2",
      "title": "The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Miaoran Zhang",
        "Vagrant Gautam",
        "Mingyang Wang",
        "Jesujoba O. Alabi",
        "Xiaoyu Shen",
        "Dietrich Klakow",
        "Marius Mosbach"
      ],
      "abstract": "In-context learning is a popular inference strategy where large language\nmodels solve a task using only a few labeled demonstrations without needing any\nparameter updates. Although there have been extensive studies on English\nin-context learning, multilingual in-context learning remains under-explored,\nand we lack an in-depth understanding of the role of demonstrations in this\ncontext. To address this gap, we conduct a multidimensional analysis of\nmultilingual in-context learning, experimenting with 5 models from different\nmodel families, 9 datasets covering classification and generation tasks, and 56\ntypologically diverse languages. Our results reveal that the effectiveness of\ndemonstrations varies significantly across models, tasks, and languages. We\nalso find that strong instruction-following models including Llama 2-Chat,\nGPT-3.5, and GPT-4 are largely insensitive to the quality of demonstrations.\nInstead, a carefully crafted template often eliminates the benefits of\ndemonstrations for some tasks and languages altogether. These findings show\nthat the importance of demonstrations might be overestimated. Our work\nhighlights the need for granular evaluation across multiple axes towards a\nbetter understanding of in-context learning.",
      "tldr_zh": "这篇论文通过多维分析探讨了演示对多语言 in-context learning 的影响，实验涉及5个不同模型家族的模型、9个数据集（包括分类和生成任务）以及56种语言。结果显示，演示的有效性在模型、任务和语言之间存在显著差异，而强指令跟随模型如Llama 2-Chat、GPT-3.5和GPT-4对演示质量不敏感。研究发现，精心设计的模板往往能完全取代演示的好处，这表明in-context learning中演示的重要性可能被高估，并呼吁进行更细粒度的评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2402.12976v2",
      "published_date": "2024-02-20 12:53:31 UTC",
      "updated_date": "2024-06-07 13:44:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:17:27.878851"
    },
    {
      "arxiv_id": "2402.12969v1",
      "title": "GlórIA -- A Generative and Open Large Language Model for Portuguese",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Lopes",
        "João Magalhães",
        "David Semedo"
      ],
      "abstract": "Significant strides have been made in natural language tasks, largely\nattributed to the emergence of powerful large language models (LLMs). These\nmodels, pre-trained on extensive and diverse corpora, have become increasingly\ncapable of comprehending the intricacies of language. Despite the abundance of\nLLMs for many high-resource languages, the availability of such models remains\nlimited for European Portuguese. We introduce Gl\\'orIA, a robust European\nPortuguese decoder LLM. To pre-train Gl\\'orIA, we assembled a comprehensive\nPT-PT text corpus comprising 35 billion tokens from various sources. We present\nour pre-training methodology, followed by an assessment of the model's\neffectiveness on multiple downstream tasks. Additionally, to evaluate our\nmodels' language modeling capabilities, we introduce CALAME-PT (Context-Aware\nLAnguage Modeling Evaluation for Portuguese), the first Portuguese zero-shot\nlanguage-modeling benchmark. Evaluation shows that Gl\\'orIA significantly\noutperforms existing open PT decoder models in language modeling and that it\ncan generate sound, knowledge-rich, and coherent PT-PT text. The model also\nexhibits strong potential for various downstream tasks.",
      "tldr_zh": "该研究引入了 GlórIA，一种开源的生成式大型语言模型（LLM），专门针对欧洲葡萄牙语（PT-PT），以填补该语言在 LLM 领域的空白。研究团队构建了包含 350 亿 tokens 的综合 PT-PT 文本语料，并采用特定预训练方法来提升模型的语言理解和生成能力。同时，他们开发了 CALAME-PT，这是一个首创的葡萄牙语零样本语言建模基准，用于评估模型性能。实验结果显示，GlórIA 在语言建模和各种下游任务中显著优于现有开源 PT 解码器模型，能够生成高质量、知识丰富的葡萄牙语文本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at PROPOR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12969v1",
      "published_date": "2024-02-20 12:36:40 UTC",
      "updated_date": "2024-02-20 12:36:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:17:39.178811"
    },
    {
      "arxiv_id": "2402.12954v2",
      "title": "Conditional Logical Message Passing Transformer for Complex Query Answering",
      "title_zh": "条件逻辑消息传递 Transformer 用于复杂查询回答",
      "authors": [
        "Chongzhi Zhang",
        "Zhiping Peng",
        "Junhao Zheng",
        "Qianli Ma"
      ],
      "abstract": "Complex Query Answering (CQA) over Knowledge Graphs (KGs) is a challenging\ntask. Given that KGs are usually incomplete, neural models are proposed to\nsolve CQA by performing multi-hop logical reasoning. However, most of them\ncannot perform well on both one-hop and multi-hop queries simultaneously.\nRecent work proposes a logical message passing mechanism based on the\npre-trained neural link predictors. While effective on both one-hop and\nmulti-hop queries, it ignores the difference between the constant and variable\nnodes in a query graph. In addition, during the node embedding update stage,\nthis mechanism cannot dynamically measure the importance of different messages,\nand whether it can capture the implicit logical dependencies related to a node\nand received messages remains unclear. In this paper, we propose Conditional\nLogical Message Passing Transformer (CLMPT), which considers the difference\nbetween constants and variables in the case of using pre-trained neural link\npredictors and performs message passing conditionally on the node type. We\nempirically verified that this approach can reduce computational costs without\naffecting performance. Furthermore, CLMPT uses the transformer to aggregate\nreceived messages and update the corresponding node embedding. Through the\nself-attention mechanism, CLMPT can assign adaptive weights to elements in an\ninput set consisting of received messages and the corresponding node and\nexplicitly model logical dependencies between various elements. Experimental\nresults show that CLMPT is a new state-of-the-art neural CQA model.\nhttps://github.com/qianlima-lab/CLMPT.",
      "tldr_zh": "该论文针对知识图谱（Knowledge Graphs, KGs）上的复杂查询回答（Complex Query Answering, CQA）任务，提出了一种新的神经模型Conditional Logical Message Passing Transformer (CLMPT)，以解决现有模型在处理一跳和多跳查询时的局限性。CLMPT通过区分查询图中的常量和变量节点，进行条件性的消息传递，从而减少计算成本而不影响性能。利用Transformer的self-attention机制，该模型动态聚合接收到的消息、分配自适应权重，并显式建模节点间的逻辑依赖关系。实验结果表明，CLMPT在CQA基准上实现了新的state-of-the-art性能，并提供了开源实现（https://github.com/qianlima-lab/CLMPT）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2024 Research Track",
      "pdf_url": "http://arxiv.org/pdf/2402.12954v2",
      "published_date": "2024-02-20 12:17:01 UTC",
      "updated_date": "2024-08-10 10:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:17:52.227042"
    },
    {
      "arxiv_id": "2402.12950v2",
      "title": "QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jinjing Shi",
        "Zimeng Xiao",
        "Heyuan Shi",
        "Yu Jiang",
        "Xuelong Li"
      ],
      "abstract": "Quantum Neural Network (QNN) combines the Deep Learning (DL) principle with\nthe fundamental theory of quantum mechanics to achieve machine learning tasks\nwith quantum acceleration. Recently, QNN systems have been found to manifest\nrobustness issues similar to classical DL systems. There is an urgent need for\nways to test their correctness and security. However, QNN systems differ\nsignificantly from traditional quantum software and classical DL systems,\nposing critical challenges for QNN testing. These challenges include the\ninapplicability of traditional quantum software testing methods to QNN systems\ndue to differences in programming paradigms and decision logic representations,\nthe dependence of quantum test sample generation on perturbation operators, and\nthe absence of effective information in quantum neurons. In this paper, we\npropose QuanTest, a quantum entanglement-guided adversarial testing framework\nto uncover potential erroneous behaviors in QNN systems. We design a quantum\nentanglement adequacy criterion to quantify the entanglement acquired by the\ninput quantum states from the QNN system, along with two similarity metrics to\nmeasure the proximity of generated quantum adversarial examples to the original\ninputs. Subsequently, QuanTest formulates the problem of generating test inputs\nthat maximize the quantum entanglement adequacy and capture incorrect behaviors\nof the QNN system as a joint optimization problem and solves it in a\ngradient-based manner to generate quantum adversarial examples. results\ndemonstrate that QuanTest possesses the capability to capture erroneous\nbehaviors in QNN systems. The entanglement-guided approach proves effective in\nadversarial testing, generating more adversarial examples.",
      "tldr_zh": "本文提出 QuanTest，一种基于量子纠缠引导的对抗测试框架，用于检测 Quantum Neural Network (QNN) 系统的潜在错误行为，以解决其鲁棒性问题和测试挑战。QuanTest 设计了量子纠缠充分性标准（quantum entanglement adequacy criterion）和两个相似度指标，将测试输入生成问题转化为联合优化问题，并通过梯度方法产生量子对抗样本。实验结果显示，该框架能有效捕获 QNN 的错误行为，并在对抗测试中生成更多有效的对抗例子。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper has been accepted by TOSEM 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12950v2",
      "published_date": "2024-02-20 12:11:28 UTC",
      "updated_date": "2024-08-26 08:02:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:18:02.878675"
    },
    {
      "arxiv_id": "2402.12939v1",
      "title": "Discovering Behavioral Modes in Deep Reinforcement Learning Policies Using Trajectory Clustering in Latent Space",
      "title_zh": "使用轨迹聚类在",
      "authors": [
        "Sindre Benjamin Remman",
        "Anastasios M. Lekkas"
      ],
      "abstract": "Understanding the behavior of deep reinforcement learning (DRL) agents is\ncrucial for improving their performance and reliability. However, the\ncomplexity of their policies often makes them challenging to understand. In\nthis paper, we introduce a new approach for investigating the behavior modes of\nDRL policies, which involves utilizing dimensionality reduction and trajectory\nclustering in the latent space of neural networks. Specifically, we use\nPairwise Controlled Manifold Approximation Projection (PaCMAP) for\ndimensionality reduction and TRACLUS for trajectory clustering to analyze the\nlatent space of a DRL policy trained on the Mountain Car control task. Our\nmethodology helps identify diverse behavior patterns and suboptimal choices by\nthe policy, thus allowing for targeted improvements. We demonstrate how our\napproach, combined with domain knowledge, can enhance a policy's performance in\nspecific regions of the state space.",
      "tldr_zh": "这篇论文提出了一种新方法，用于分析深度强化学习(DRL)政策的behavior modes，通过在潜在空间中进行轨迹聚类来理解代理行为的多样性和复杂性。具体地，该方法利用Pairwise Controlled Manifold Approximation Projection (PaCMAP)进行降维，以及TRACLUS算法进行轨迹聚类，并在Mountain Car控制任务上进行了测试。实验结果显示，该方法能识别出不同行为模式和次优选择，结合领域知识帮助针对特定状态空间区域提升政策的性能和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to the European Control Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12939v1",
      "published_date": "2024-02-20 11:50:50 UTC",
      "updated_date": "2024-02-20 11:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:18:14.847465"
    },
    {
      "arxiv_id": "2402.17775v2",
      "title": "WhaleNet: a Novel Deep Learning Architecture for Marine Mammals Vocalizations on Watkins Marine Mammal Sound Database",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Licciardi",
        "Davide Carbone"
      ],
      "abstract": "Marine mammal communication is a complex field, hindered by the diversity of\nvocalizations and environmental factors. The Watkins Marine Mammal Sound\nDatabase (WMMD) constitutes a comprehensive labeled dataset employed in machine\nlearning applications. Nevertheless, the methodologies for data preparation,\npreprocessing, and classification documented in the literature exhibit\nconsiderable variability and are typically not applied to the dataset in its\nentirety. This study initially undertakes a concise review of the\nstate-of-the-art benchmarks pertaining to the dataset, with a particular focus\non clarifying data preparation and preprocessing techniques. Subsequently, we\nexplore the utilization of the Wavelet Scattering Transform (WST) and Mel\nspectrogram as preprocessing mechanisms for feature extraction. In this paper,\nwe introduce \\textbf{WhaleNet} (Wavelet Highly Adaptive Learning Ensemble\nNetwork), a sophisticated deep ensemble architecture for the classification of\nmarine mammal vocalizations, leveraging both WST and Mel spectrogram for\nenhanced feature discrimination. By integrating the insights derived from WST\nand Mel representations, we achieved an improvement in classification accuracy\nby $8-10\\%$ over existing architectures, corresponding to a classification\naccuracy of $97.61\\%$.",
      "tldr_zh": "该研究针对海洋哺乳动物 vocalizations 的复杂性和环境因素挑战，基于 Watkins Marine Mammal Sound Database (WMMD) 进行了数据准备和预处理技术回顾，并探索了 Wavelet Scattering Transform (WST) 和 Mel spectrogram 作为特征提取机制。论文引入了 WhaleNet，一种先进的深度集成架构（Wavelet Highly Adaptive Learning Ensemble Network），通过整合 WST 和 Mel spectrogram 表示来提升分类性能。在 WMMD 数据集上，WhaleNet 实现了 97.61% 的分类准确率，比现有架构提高了 8-10%。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17775v2",
      "published_date": "2024-02-20 11:36:23 UTC",
      "updated_date": "2024-06-26 14:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:18:26.774109"
    },
    {
      "arxiv_id": "2402.12928v5",
      "title": "A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Penghai Zhao",
        "Xin Zhang",
        "Jiayue Cao",
        "Ming-Ming Cheng",
        "Jian Yang",
        "Xiang Li"
      ],
      "abstract": "The rapid advancements in Pattern Analysis and Machine Intelligence (PAMI)\nhave led to an overwhelming expansion of scientific knowledge, spawning\nnumerous literature reviews aimed at collecting and synthesizing fragmented\ninformation. This paper presents a thorough analysis of these literature\nreviews within the PAMI field, and tries to address three core research\nquestions: (1) What are the prevalent structural and statistical\ncharacteristics of PAMI literature reviews? (2) What strategies can researchers\nemploy to efficiently navigate the growing corpus of reviews? (3) What are the\nadvantages and limitations of AI-generated reviews compared to human-authored\nones? To address the first research question, we begin with a narrative\noverview to highlight common preferences in composing PAMI reviews, followed by\na statistical analysis to quantitatively uncover patterns in these preferences.\nOur findings reveal several key insights. First, fewer than 20% of PAMI reviews\ncurrently comply with PRISMA standards, although this proportion is gradually\nincreasing. Second, there is a moderate positive correlation between the\nquality of references and the scholarly impact of reviews, emphasizing the\nimportance of reference selection. To further assist researchers in efficiently\nmanaging the rapidly growing number of literature reviews, we introduce four\nnovel, real-time, article-level bibliometric indicators that facilitate the\nscreening of numerous reviews. Finally, our comparative analysis reveals that\nAI-generated reviews currently fall short of human-authored ones in accurately\nevaluating the academic significance of newly published articles and\nintegrating rich visual elements, which limits their practical utility.\nOverall, this study provides a deeper understanding of PAMI literature reviews\nby uncovering key trends, evaluating current practices, and highlighting areas\nfor future improvement.",
      "tldr_zh": "这篇论文对模式分析和机器智能（PAMI）领域的文献综述进行了全面分析，探讨了三个核心研究问题：PAMI 文献综述的常见结构和统计特征、研究人员高效导航文献的方法，以及 AI-generated reviews 与人类撰写的优缺点。研究发现，少于 20% 的 PAMI 文献综述符合 PRISMA 标准，但这一比例正在上升，且参考质量与学术影响呈正相关；同时，论文引入了四个新的实时、文章级别的书目指标，以帮助筛选和管理日益增多的文献综述。总体而言，AI-generated reviews 在评估新文章学术意义和整合视觉元素方面仍逊于人类撰写，但这项研究揭示了关键趋势，并为未来改进提供了指导。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.DL",
      "comment": "V2, V3, and V4 with incremental quality improvements. V5 introduces\n  major updates, featuring 27 pages, 16 figures, and 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.12928v5",
      "published_date": "2024-02-20 11:28:50 UTC",
      "updated_date": "2024-12-14 14:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:18:38.973784"
    },
    {
      "arxiv_id": "2402.12916v1",
      "title": "Data Pipeline Training: Integrating AutoML to Optimize the Data Flow of Machine Learning Models",
      "title_zh": "数据管道训练：整合 AutoML 以优化机器学习模型的数据流",
      "authors": [
        "Jiang Wu",
        "Hongbo Wang",
        "Chunhe Ni",
        "Chenwei Zhang",
        "Wenran Lu"
      ],
      "abstract": "Data Pipeline plays an indispensable role in tasks such as modeling machine\nlearning and developing data products. With the increasing diversification and\ncomplexity of Data sources, as well as the rapid growth of data volumes,\nbuilding an efficient Data Pipeline has become crucial for improving work\nefficiency and solving complex problems. This paper focuses on exploring how to\noptimize data flow through automated machine learning methods by integrating\nAutoML with Data Pipeline. We will discuss how to leverage AutoML technology to\nenhance the intelligence of Data Pipeline, thereby achieving better results in\nmachine learning tasks. By delving into the automation and optimization of Data\nflows, we uncover key strategies for constructing efficient data pipelines that\ncan adapt to the ever-changing data landscape. This not only accelerates the\nmodeling process but also provides innovative solutions to complex problems,\nenabling more significant outcomes in increasingly intricate data domains.\nKeywords- Data Pipeline Training;AutoML; Data environment; Machine learning",
      "tldr_zh": "这篇论文探讨了如何通过整合 AutoML（Automated Machine Learning）来优化机器学习模型的数据流，针对数据来源多样化和数据量快速增长的挑战。论文重点介绍了利用 AutoML 技术增强 Data Pipeline 的智能性，实现数据流的自动化优化，从而提高建模效率并解决复杂问题。最终，该方法有助于构建适应性强的 Data Pipeline，在机器学习任务中取得更显著的成果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12916v1",
      "published_date": "2024-02-20 11:06:42 UTC",
      "updated_date": "2024-02-20 11:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:18:51.104534"
    },
    {
      "arxiv_id": "2402.12908v3",
      "title": "RealCompo: Balancing Realism and Compositionality Improves Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xinchen Zhang",
        "Ling Yang",
        "Yaqi Cai",
        "Zhaochen Yu",
        "Kai-Ni Wang",
        "Jiake Xie",
        "Ye Tian",
        "Minkai Xu",
        "Yong Tang",
        "Yujiu Yang",
        "Bin Cui"
      ],
      "abstract": "Diffusion models have achieved remarkable advancements in text-to-image\ngeneration. However, existing models still have many difficulties when faced\nwith multiple-object compositional generation. In this paper, we propose\nRealCompo, a new training-free and transferred-friendly text-to-image\ngeneration framework, which aims to leverage the respective advantages of\ntext-to-image models and spatial-aware image diffusion models (e.g., layout,\nkeypoints and segmentation maps) to enhance both realism and compositionality\nof the generated images. An intuitive and novel balancer is proposed to\ndynamically balance the strengths of the two models in denoising process,\nallowing plug-and-play use of any model without extra training. Extensive\nexperiments show that our RealCompo consistently outperforms state-of-the-art\ntext-to-image models and spatial-aware image diffusion models in\nmultiple-object compositional generation while keeping satisfactory realism and\ncompositionality of the generated images. Notably, our RealCompo can be\nseamlessly extended with a wide range of spatial-aware image diffusion models\nand stylized diffusion models. Our code is available at:\nhttps://github.com/YangLing0818/RealCompo",
      "tldr_zh": "这篇论文提出RealCompo框架，一种无需额外训练的文本-to-image扩散模型方法，旨在平衡图像的真实性（realism）和合成性（compositionality），通过结合文本-to-image模型和空间感知图像扩散模型（如布局、关键点和分割图）来提升多对象生成性能。框架引入一个动态平衡器，在去噪过程中实时调整两种模型的强度，实现即插即用。实验结果表明，RealCompo在多对象合成生成任务中优于现有状态-of-the-art模型，同时保持高真实性和合成性，并可无缝扩展到各种空间感知和风格化扩散模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024. Project: https://github.com/YangLing0818/RealCompo",
      "pdf_url": "http://arxiv.org/pdf/2402.12908v3",
      "published_date": "2024-02-20 10:56:52 UTC",
      "updated_date": "2024-10-14 07:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:19:03.098555"
    },
    {
      "arxiv_id": "2402.12907v2",
      "title": "Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects",
      "title_zh": "社会技术系统中 AI 对齐的激励兼容性：观点和前景",
      "authors": [
        "Zhaowei Zhang",
        "Fengshuo Bai",
        "Mingzhi Wang",
        "Haoyang Ye",
        "Chengdong Ma",
        "Yaodong Yang"
      ],
      "abstract": "The burgeoning integration of artificial intelligence (AI) into human society\nbrings forth significant implications for societal governance and safety. While\nconsiderable strides have been made in addressing AI alignment challenges,\nexisting methodologies primarily focus on technical facets, often neglecting\nthe intricate sociotechnical nature of AI systems, which can lead to a\nmisalignment between the development and deployment contexts. To this end, we\nposit a new problem worth exploring: Incentive Compatibility Sociotechnical\nAlignment Problem (ICSAP). We hope this can call for more researchers to\nexplore how to leverage the principles of Incentive Compatibility (IC) from\ngame theory to bridge the gap between technical and societal components to\nmaintain AI consensus with human societies in different contexts. We further\ndiscuss three classical game problems for achieving IC: mechanism design,\ncontract theory, and Bayesian persuasion, in addressing the perspectives,\npotentials, and challenges of solving ICSAP, and provide preliminary\nimplementation conceptions.",
      "tldr_zh": "该论文探讨了人工智能(AI)融入社会治理和安全中的挑战，指出现有AI Alignment方法主要关注技术层面，而忽略了Sociotechnical Systems的复杂社会技术性质，导致开发与部署环境的不一致。\n\n作者提出一个新问题：Incentive Compatibility Sociotechnical Alignment Problem (ICSAP)，旨在通过游戏理论的Incentive Compatibility (IC)原则桥接技术与社会组件，确保AI在不同语境下与人类社会保持共识。\n\n论文讨论了Mechanism Design、Contract Theory和Bayesian Persuasion等三个经典游戏理论问题，分析了其在解决ICSAP时的潜力、挑战，并提供了初步实施概念，以推动更多相关研究。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GT",
        "cs.HC",
        "I.2.m; K.4.m"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.12907v2",
      "published_date": "2024-02-20 10:52:57 UTC",
      "updated_date": "2024-03-01 11:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:19:17.346826"
    },
    {
      "arxiv_id": "2404.07212v1",
      "title": "Hybrid Training of Denoising Networks to Improve the Texture Acutance of Digital Cameras",
      "title_zh": "翻译失败",
      "authors": [
        "Raphaël Achddou",
        "Yann Gousseau",
        "Saïd Ladjal"
      ],
      "abstract": "In order to evaluate the capacity of a camera to render textures properly,\nthe standard practice, used by classical scoring protocols, is to compute the\nfrequential response to a dead leaves image target, from which is built a\ntexture acutance metric. In this work, we propose a mixed training procedure\nfor image restoration neural networks, relying on both natural and synthetic\nimages, that yields a strong improvement of this acutance metric without\nimpairing fidelity terms. The feasibility of the approach is demonstrated both\non the denoising of RGB images and the full development of RAW images, opening\nthe path to a systematic improvement of the texture acutance of real imaging\ndevices.",
      "tldr_zh": "该研究针对数码相机的纹理锐度（texture acutance）评估问题，提出了一种混合训练程序，用于训练图像恢复神经网络（image restoration neural networks）。该方法结合自然图像和合成图像作为训练数据，能够显著提升纹理锐度指标，同时不影响图像保真度（fidelity terms）。实验验证了该方法的有效性，在 RGB 图像去噪和 RAW 图像全开发任务中均取得了强有力的改善，为真实成像设备的系统性优化提供了新路径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07212v1",
      "published_date": "2024-02-20 10:47:06 UTC",
      "updated_date": "2024-02-20 10:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:19:28.255785"
    },
    {
      "arxiv_id": "2402.12887v1",
      "title": "The practice of qualitative parameterisation in the development of Bayesian networks",
      "title_zh": "贝叶斯网络开发中的定性参数化实践",
      "authors": [
        "Steven Mascaro",
        "Owen Woodberry",
        "Yue Wu",
        "Ann E. Nicholson"
      ],
      "abstract": "The typical phases of Bayesian network (BN) structured development include\nspecification of purpose and scope, structure development, parameterisation and\nvalidation. Structure development is typically focused on qualitative issues\nand parameterisation quantitative issues, however there are qualitative and\nquantitative issues that arise in both phases. A common step that occurs after\nthe initial structure has been developed is to perform a rough parameterisation\nthat only captures and illustrates the intended qualitative behaviour of the\nmodel. This is done prior to a more rigorous parameterisation, ensuring that\nthe structure is fit for purpose, as well as supporting later development and\nvalidation. In our collective experience and in discussions with other\nmodellers, this step is an important part of the development process, but is\nunder-reported in the literature. Since the practice focuses on qualitative\nissues, despite being quantitative in nature, we call this step qualitative\nparameterisation and provide an outline of its role in the BN development\nprocess.",
      "tldr_zh": "本论文探讨了Bayesian networks (BN)开发过程中的一个关键步骤，即qualitative parameterisation。该步骤发生在初步结构开发后，通过粗略参数化捕捉和展示模型的预期定性行为，确保结构适合目的并支持后续开发和验证。尽管这一实践基于作者的集体经验和与其他建模者的讨论，但它在文献中报道较少。论文强调qualitative parameterisation在BN开发中融合定性和定量问题的重要性，为改进BN模型提供了实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures, technical note",
      "pdf_url": "http://arxiv.org/pdf/2402.12887v1",
      "published_date": "2024-02-20 10:30:36 UTC",
      "updated_date": "2024-02-20 10:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:19:39.867045"
    },
    {
      "arxiv_id": "2402.12865v1",
      "title": "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space",
      "title_zh": "Backward Lens：将语言模型梯度投射到词汇空间",
      "authors": [
        "Shahar Katz",
        "Yonatan Belinkov",
        "Mor Geva",
        "Lior Wolf"
      ],
      "abstract": "Understanding how Transformer-based Language Models (LMs) learn and recall\ninformation is a key goal of the deep learning community. Recent\ninterpretability methods project weights and hidden states obtained from the\nforward pass to the models' vocabularies, helping to uncover how information\nflows within LMs. In this work, we extend this methodology to LMs' backward\npass and gradients. We first prove that a gradient matrix can be cast as a\nlow-rank linear combination of its forward and backward passes' inputs. We then\ndevelop methods to project these gradients into vocabulary items and explore\nthe mechanics of how new information is stored in the LMs' neurons.",
      "tldr_zh": "这篇论文扩展了 Transformer-based Language Models (LMs) 的解释方法，将前向传播的权重和隐藏状态投影扩展到后向传播的梯度上。研究者证明了梯度矩阵可以表示为前向和后向输入的低秩线性组合，并开发了相应的投影技术。最终，通过将梯度映射到词汇空间，他们探索了新信息如何存储在 LMs 的神经元中，从而加深了对模型学习机制的理解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12865v1",
      "published_date": "2024-02-20 09:57:08 UTC",
      "updated_date": "2024-02-20 09:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:19:53.240158"
    },
    {
      "arxiv_id": "2402.12847v2",
      "title": "Instruction-tuned Language Models are Better Knowledge Learners",
      "title_zh": "指令微调的语言模型是更好的知识学习者",
      "authors": [
        "Zhengbao Jiang",
        "Zhiqing Sun",
        "Weijia Shi",
        "Pedro Rodriguez",
        "Chunting Zhou",
        "Graham Neubig",
        "Xi Victoria Lin",
        "Wen-tau Yih",
        "Srinivasan Iyer"
      ],
      "abstract": "In order for large language model (LLM)-based assistants to effectively adapt\nto evolving information needs, it must be possible to update their factual\nknowledge through continued training on new data. The standard recipe for doing\nso involves continued pre-training on new documents followed by\ninstruction-tuning on question-answer (QA) pairs. However, we find that LLMs\ntrained with this recipe struggle to answer questions, even though the\nperplexity of documents is minimized. We found that QA pairs are generally\nstraightforward, while documents are more complex, weaving many factual\nstatements together in an intricate manner. Therefore, we hypothesize that it\nis beneficial to expose LLMs to QA pairs before continued pre-training on\ndocuments so that the process of encoding knowledge from complex documents\ntakes into account how this knowledge is accessed through questions. Based on\nthis, we propose pre-instruction-tuning (PIT), a method that instruction-tunes\non questions prior to training on documents. This contrasts with standard\ninstruction-tuning, which learns how to extract knowledge after training on\ndocuments. Extensive experiments and ablation studies demonstrate that\npre-instruction-tuning significantly enhances the ability of LLMs to absorb\nknowledge from new documents, outperforming standard instruction-tuning by\n17.8%.",
      "tldr_zh": "该研究发现，标准方法通过在新文档上继续预训练后进行指令微调，无法有效提升大型语言模型(LLM)回答问题的能力，因为QA pairs简单而文档复杂。作者提出pre-instruction-tuning (PIT)方法，即先在QA pairs上进行指令微调，然后再训练文档，从而帮助LLM更好地编码和提取知识。实验结果显示，PIT比标准指令微调提高了17.8%的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024. The reproduced data for this paper is available at\n  https://github.com/Edward-Sun/PIT",
      "pdf_url": "http://arxiv.org/pdf/2402.12847v2",
      "published_date": "2024-02-20 09:20:32 UTC",
      "updated_date": "2024-05-26 03:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:20:03.023100"
    },
    {
      "arxiv_id": "2402.12846v1",
      "title": "ConVQG: Contrastive Visual Question Generation with Multimodal Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Li Mi",
        "Syrielle Montariol",
        "Javiera Castillo-Navarro",
        "Xianjie Dai",
        "Antoine Bosselut",
        "Devis Tuia"
      ],
      "abstract": "Asking questions about visual environments is a crucial way for intelligent\nagents to understand rich multi-faceted scenes, raising the importance of\nVisual Question Generation (VQG) systems. Apart from being grounded to the\nimage, existing VQG systems can use textual constraints, such as expected\nanswers or knowledge triplets, to generate focused questions. These constraints\nallow VQG systems to specify the question content or leverage external\ncommonsense knowledge that can not be obtained from the image content only.\nHowever, generating focused questions using textual constraints while enforcing\na high relevance to the image content remains a challenge, as VQG systems often\nignore one or both forms of grounding. In this work, we propose Contrastive\nVisual Question Generation (ConVQG), a method using a dual contrastive\nobjective to discriminate questions generated using both modalities from those\nbased on a single one. Experiments on both knowledge-aware and standard VQG\nbenchmarks demonstrate that ConVQG outperforms the state-of-the-art methods and\ngenerates image-grounded, text-guided, and knowledge-rich questions. Our human\nevaluation results also show preference for ConVQG questions compared to\nnon-contrastive baselines.",
      "tldr_zh": "这篇论文提出了 ConVQG，一种基于对比学习的视觉问题生成（Visual Question Generation, VQG）方法，通过多模态指导生成与图像高度相关的、文本约束的问题。ConVQG 采用双对比目标（dual contrastive objective），将基于两种模态（图像和文本）生成的问题与单一模态生成的问题进行区分，从而解决现有系统在图像 grounding 和文本引导方面的不足。实验在知识感知和标准 VQG 基准上显示，ConVQG 优于最先进方法，能生成知识丰富的问句，且人类评估结果表明人们更偏好这些问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2024. Project page at https://limirs.github.io/ConVQG",
      "pdf_url": "http://arxiv.org/pdf/2402.12846v1",
      "published_date": "2024-02-20 09:20:30 UTC",
      "updated_date": "2024-02-20 09:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:20:16.205745"
    },
    {
      "arxiv_id": "2402.12845v1",
      "title": "MORE-3S:Multimodal-based Offline Reinforcement Learning with Shared Semantic Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Zheng",
        "Ge Zhang",
        "Xingwei Qu",
        "Ming Kuang",
        "Stephen W. Huang",
        "Zhaofeng He"
      ],
      "abstract": "Drawing upon the intuition that aligning different modalities to the same\nsemantic embedding space would allow models to understand states and actions\nmore easily, we propose a new perspective to the offline reinforcement learning\n(RL) challenge. More concretely, we transform it into a supervised learning\ntask by integrating multimodal and pre-trained language models. Our approach\nincorporates state information derived from images and action-related data\nobtained from text, thereby bolstering RL training performance and promoting\nlong-term strategic thinking. We emphasize the contextual understanding of\nlanguage and demonstrate how decision-making in RL can benefit from aligning\nstates' and actions' representation with languages' representation. Our method\nsignificantly outperforms current baselines as evidenced by evaluations\nconducted on Atari and OpenAI Gym environments. This contributes to advancing\noffline RL performance and efficiency while providing a novel perspective on\noffline RL.Our code and data are available at\nhttps://github.com/Zheng0428/MORE_.",
      "tldr_zh": "该论文提出MORE-3S方法，将多模态数据（如图像状态和文本动作）对齐到共享语义空间，从而将offline reinforcement learning (RL) 转化为监督学习任务。方法通过整合多模态模型和预训练语言模型，增强状态和动作的语义理解，促进长期战略思考和决策优化。在Atari和OpenAI Gym环境中，MORE-3S显著优于现有基线，提升了offline RL的性能和效率，为该领域提供了一个新视角。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12845v1",
      "published_date": "2024-02-20 09:15:50 UTC",
      "updated_date": "2024-02-20 09:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:20:27.156518"
    },
    {
      "arxiv_id": "2402.12843v3",
      "title": "Solar Panel Segmentation :Self-Supervised Learning Solutions for Imperfect Datasets",
      "title_zh": "太阳能面板分割：针对不完美数据集的自监督学习解决方案",
      "authors": [
        "Sankarshanaa Sagaram",
        "Krish Didwania",
        "Laven Srivastava",
        "Aditya Kasliwal",
        "Pallavi Kailas",
        "Ujjwal Verma"
      ],
      "abstract": "The increasing adoption of solar energy necessitates advanced methodologies\nfor monitoring and maintenance to ensure optimal performance of solar panel\ninstallations. A critical component in this context is the accurate\nsegmentation of solar panels from aerial or satellite imagery, which is\nessential for identifying operational issues and assessing efficiency. This\npaper addresses the significant challenges in panel segmentation, particularly\nthe scarcity of annotated data and the labour-intensive nature of manual\nannotation for supervised learning. We explore and apply Self-Supervised\nLearning (SSL) to solve these challenges. We demonstrate that SSL significantly\nenhances model generalization under various conditions and reduces dependency\non manually annotated data, paving the way for robust and adaptable solar panel\nsegmentation solutions.",
      "tldr_zh": "本论文针对太阳能面板分割(solar panel segmentation)面临的挑战，特别是标注数据稀缺和手动标注的劳动密集问题，提出基于Self-Supervised Learning (SSL)的解决方案。研究探索了SSL如何提升模型在各种条件下的泛化能力，同时减少对手动标注数据的依赖。通过实验验证，SSL方法显著改善了分割性能，为监控太阳能安装的效率和问题识别提供了稳健、可适应的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ICLR Tiny Paper 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12843v3",
      "published_date": "2024-02-20 09:13:11 UTC",
      "updated_date": "2024-06-02 18:08:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:20:40.042158"
    },
    {
      "arxiv_id": "2402.12842v3",
      "title": "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Gyeongman Kim",
        "Doohyuk Jang",
        "Eunho Yang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have raised concerns\nabout inference costs, increasing the need for research into model compression.\nWhile knowledge distillation (KD) is a prominent method for this, research on\nKD for generative language models like LLMs is relatively sparse, and the\napproach of distilling student-friendly knowledge, which has shown promising\nperformance in KD for classification models, remains unexplored in generative\nlanguage models. To explore this approach, we propose PromptKD, a simple yet\neffective method that utilizes prompt tuning - for the first time in KD - to\nenable generative language models to transfer student-friendly knowledge.\nUnlike previous works in classification that require fine-tuning the entire\nteacher model for extracting student-friendly knowledge, PromptKD achieves\nsimilar effects by adding a small number of prompt tokens and tuning only the\nprompt with student guidance. Extensive experiments on instruction-following\ndatasets show that PromptKD achieves state-of-the-art performance while adding\nonly 0.0007% of the teacher's parameters as prompts. Further analysis suggests\nthat distilling student-friendly knowledge alleviates exposure bias effectively\nthroughout the entire training process, leading to performance enhancements.",
      "tldr_zh": "该研究提出 PromptKD，一种创新的知识蒸馏（KD）方法，通过首次应用提示调整（prompt tuning），帮助生成式语言模型（如 LLMs）转移学生友好知识，从而实现高效模型压缩。不同于传统 KD 需要微调整个教师模型，PromptKD 只需添加少量提示标记并在学生指导下微调提示，显著降低了参数开销，仅增加了教师参数的 0.0007%。在指令跟随数据集上的广泛实验中，PromptKD 达到了最先进性能，并证明了蒸馏学生友好知识能有效缓解暴露偏差（exposure bias），从而提升整体模型表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings. Our project page: https://promptkd.github.io",
      "pdf_url": "http://arxiv.org/pdf/2402.12842v3",
      "published_date": "2024-02-20 09:10:08 UTC",
      "updated_date": "2024-09-27 06:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:20:53.543934"
    },
    {
      "arxiv_id": "2402.12835v2",
      "title": "PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs",
      "title_zh": "PANDA：偏好适应以增强大型语言模型的领域特定能力",
      "authors": [
        "An Liu",
        "Zonghan Yang",
        "Zhenhe Zhang",
        "Qingyuan Hu",
        "Peng Li",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang",
        "Yang Liu"
      ],
      "abstract": "While Large language models (LLMs) have demonstrated considerable\ncapabilities across various natural language tasks, they often fall short of\nthe performance achieved by domain-specific state-of-the-art models. One\npotential approach to enhance domain-specific capabilities of LLMs involves\nfine-tuning them using corresponding datasets. However, this method can be both\nresource and time-intensive, and not applicable to closed-source commercial\nLLMs. In this paper, we propose Preference Adaptation for Enhancing\nDomain-specific Abilities of LLMs (PANDA), a method designed to augment the\ndomain-specific capabilities of LLMs by leveraging insights from the response\npreference of expert models without requiring fine-tuning. Our experimental\nresults reveal that PANDA significantly enhances the domain-specific ability of\nLLMs on text classification and interactive decision tasks. Moreover, LLM with\nPANDA even outperforms the expert model that being learned on 4 tasks of\nScienceWorld. This finding highlights the potential of exploring tuning-free\napproaches to achieve weak-to-strong generalization.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在领域特定任务上表现不如专用模型的问题，提出了一种无需fine-tuning的优化方法——PANDA（Preference Adaptation）。PANDA通过利用专家模型的响应偏好（response preference）来增强LLMs的领域特定能力，从而在文本分类和交互决策任务中显著提升性能。实验结果显示，使用PANDA的LLMs甚至在ScienceWorld的4个任务上超过了专家模型，这突出了tuning-free方法在实现弱到强泛化（weak-to-strong generalization）方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12835v2",
      "published_date": "2024-02-20 09:02:55 UTC",
      "updated_date": "2024-06-18 03:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:21:03.578822"
    },
    {
      "arxiv_id": "2402.12819v2",
      "title": "Comparing Specialised Small and General Large Language Models on Text Classification: 100 Labelled Samples to Achieve Break-Even Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Branislav Pecher",
        "Ivan Srba",
        "Maria Bielikova"
      ],
      "abstract": "When solving NLP tasks with limited labelled data, researchers can either use\na general large language model without further update, or use a small number of\nlabelled examples to tune a specialised smaller model. In this work, we address\nthe research gap of how many labelled samples are required for the specialised\nsmall models to outperform general large models, while taking the performance\nvariance into consideration. By observing the behaviour of fine-tuning,\ninstruction-tuning, prompting and in-context learning on 7 language models, we\nidentify such performance break-even points across 8 representative text\nclassification tasks of varying characteristics. We show that the specialised\nmodels often need only few samples (on average $10 - 1000$) to be on par or\nbetter than the general ones. At the same time, the number of required labels\nstrongly depends on the dataset or task characteristics, with this number being\nsignificantly lower on multi-class datasets (up to $100$) than on binary\ndatasets (up to $5000$). When performance variance is taken into consideration,\nthe number of required labels increases on average by $100 - 200\\%$ and even up\nto $1500\\%$ in specific cases.",
      "tldr_zh": "本研究比较了在文本分类任务中使用有限标记样本时，专门的小型语言模型（specialised small models）与通用的大型语言模型（general large language models）的性能差异。研究者通过观察 fine-tuning、instruction-tuning、prompting 和 in-context learning 等技术在 7 个语言模型上的行为，确定了专门模型需要多少样本（平均 10-1000 个）才能达到或超过通用模型的性能，并在 8 个代表性任务中分析了任务特性的影响。结果显示，多类数据集所需的样本较少（最多 100 个），而二元数据集可能需要更多（最多 5000 个）；当考虑性能方差时，所需样本数平均增加 100-200%，某些情况下高达 1500%。这项工作填补了研究空白，为资源有限的 NLP 应用提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12819v2",
      "published_date": "2024-02-20 08:38:24 UTC",
      "updated_date": "2024-04-26 08:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:21:17.173549"
    },
    {
      "arxiv_id": "2402.12817v2",
      "title": "On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices",
      "title_zh": "翻译失败",
      "authors": [
        "Branislav Pecher",
        "Ivan Srba",
        "Maria Bielikova"
      ],
      "abstract": "While learning with limited labelled data can improve performance when the\nlabels are lacking, it is also sensitive to the effects of uncontrolled\nrandomness introduced by so-called randomness factors (e.g., varying order of\ndata). We propose a method to systematically investigate the effects of\nrandomness factors while taking the interactions between them into\nconsideration. To measure the true effects of an individual randomness factor,\nour method mitigates the effects of other factors and observes how the\nperformance varies across multiple runs. Applying our method to multiple\nrandomness factors across in-context learning and fine-tuning approaches on 7\nrepresentative text classification tasks and meta-learning on 3 tasks, we show\nthat: 1) disregarding interactions between randomness factors in existing works\ncaused inconsistent findings due to incorrect attribution of the effects of\nrandomness factors, such as disproving the consistent sensitivity of in-context\nlearning to sample order even with random sample selection; and 2) besides\nmutual interactions, the effects of randomness factors, especially sample\norder, are also dependent on more systematic choices unexplored in existing\nworks, such as number of classes, samples per class or choice of prompt format.",
      "tldr_zh": "该研究探讨了在标签数据有限的学习场景中，对随机性因素（如数据顺序）的敏感性，并强调了这些因素之间交互的影响。论文提出了一种系统方法，通过缓解其他随机性因素的干扰来精确测量单个因素对性能的影响，并在多个任务上进行实验，包括 in-context learning 和 fine-tuning 在7个文本分类任务上，以及 meta-learning 在3个任务上。结果显示，现有工作忽略交互导致了不一致结论，例如低估了 in-context learning 对样本顺序的敏感性；此外，随机性因素的效果还依赖于系统选择，如类数、样本数或提示格式，这为改进机器学习鲁棒性提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the EMNLP'24 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2402.12817v2",
      "published_date": "2024-02-20 08:38:19 UTC",
      "updated_date": "2024-10-03 14:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:21:27.773295"
    },
    {
      "arxiv_id": "2402.12810v2",
      "title": "PIP-Net: Pedestrian Intention Prediction in the Wild",
      "title_zh": "PIP-Net：行人意图预测在野外",
      "authors": [
        "Mohsen Azarmi",
        "Mahdi Rezaei",
        "He Wang",
        "Sebastien Glaser"
      ],
      "abstract": "Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs)\nis one of the current research challenges in this field. In this article, we\nintroduce PIP-Net, a novel framework designed to predict pedestrian crossing\nintentions by AVs in real-world urban scenarios. We offer two variants of\nPIP-Net designed for different camera mounts and setups. Leveraging both\nkinematic data and spatial features from the driving scene, the proposed model\nemploys a recurrent and temporal attention-based solution, outperforming\nstate-of-the-art performance. To enhance the visual representation of road\nusers and their proximity to the ego vehicle, we introduce a categorical depth\nfeature map, combined with a local motion flow feature, providing rich insights\ninto the scene dynamics. Additionally, we explore the impact of expanding the\ncamera's field of view, from one to three cameras surrounding the ego vehicle,\nleading to enhancement in the model's contextual perception. Depending on the\ntraffic scenario and road environment, the model excels in predicting\npedestrian crossing intentions up to 4 seconds in advance which is a\nbreakthrough in current research studies in pedestrian intention prediction.\nFinally, for the first time, we present the Urban-PIP dataset, a customised\npedestrian intention prediction dataset, with multi-camera annotations in\nreal-world automated driving scenarios.",
      "tldr_zh": "这篇论文提出了 PIP-Net，一种新型框架，用于自动驾驶车辆 (AVs) 在真实城市环境中预测行人过马路意图 (PIP)。该框架结合运动学数据、空间特征以及循环和时间注意力机制，引入分类深度特征图和局部运动流特征，以增强对行人动态和车辆周边场景的理解，并在扩展摄像头视野（从一个到三个）后显著提升上下文感知。实验结果显示，PIP-Net 比现有模型性能更优，能提前 4 秒预测行人意图，提供重要突破。最后，论文首次发布 Urban-PIP 数据集，包含多摄像头标注的真实自动驾驶场景数据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE",
        "eess.IV",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12810v2",
      "published_date": "2024-02-20 08:28:45 UTC",
      "updated_date": "2024-03-01 15:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:21:41.572090"
    },
    {
      "arxiv_id": "2403.05562v1",
      "title": "SDXL Finetuned with LoRA for Coloring Therapy: Generating Graphic Templates Inspired by United Arab Emirates Culture",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulla Alfalasi",
        "Esrat Khan",
        "Mohamed Alhashmi",
        "Raed Aldweik",
        "Davor Svetinovic"
      ],
      "abstract": "A transformative approach to mental health therapy lies at the crossroads of\ncultural heritage and advanced technology. This paper introduces an innovative\nmethod that fuses machine learning techniques with traditional Emirati motifs,\nfocusing on the United Arab Emirates (UAE). We utilize the Stable Diffusion XL\n(SDXL) model, enhanced with Low-Rank Adaptation (LoRA), to create culturally\nsignificant coloring templates featuring Al-Sadu weaving patterns. This novel\napproach leverages coloring therapy for its recognized stress-relieving\nbenefits and embeds deep cultural resonance, making it a potent tool for\ntherapeutic intervention and cultural preservation. Specifically targeting\nGeneralized Anxiety Disorder (GAD), our method demonstrates significant\npotential in reducing associated symptoms. Additionally, the paper delves into\nthe broader implications of color and music therapy, emphasizing the importance\nof culturally tailored content. The technical aspects of the SDXL model and its\nLoRA fine-tuning showcase its capability to generate high-quality, culturally\nspecific images. This research stands at the forefront of integrating mental\nwellness practices with cultural heritage, providing a groundbreaking\nperspective on the synergy between technology, culture, and healthcare. In\nfuture work, we aim to employ biosignals to assess the level of engagement and\neffectiveness of color therapy. A key focus will be to examine the impact of\nthe Emirati heritage Al Sadu art on Emirati individuals and compare their\nresponses with those of other nationalities. This will provide deeper insights\ninto the cultural specificity of therapeutic interventions and further the\nunderstanding of the unique interplay between cultural identity and mental\nhealth therapy.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用 Stable Diffusion XL (SDXL) 模型结合 Low-Rank Adaptation (LoRA) 微调，生成受阿联酋文化启发的着色模板，特别是基于 Al-Sadu 编织图案。旨在将着色疗法与传统 Emirati 图案融合，以缓解 Generalized Anxiety Disorder (GAD) 的症状，并增强文化共鸣和遗产保存。研究强调了文化定制内容在心理治疗中的重要性，展示了 SDXL 模型生成高质量图像的能力。未来工作将通过生物信号评估疗效，并比较不同国籍人群的响应，以深化文化与心理健康的互动。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05562v1",
      "published_date": "2024-02-20 08:20:08 UTC",
      "updated_date": "2024-02-20 08:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:21:53.633997"
    },
    {
      "arxiv_id": "2402.12794v1",
      "title": "Autonomous Reality Modelling for Cultural Heritage Sites employing cooperative quadrupedal robots and unmanned aerial vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Giakoumidis",
        "Christos-Nikolaos Anagnostopoulos"
      ],
      "abstract": "Nowadays, the use of advanced sensors, such as terrestrial 3D laser scanners,\nmobile LiDARs and Unmanned Aerial Vehicles (UAV) photogrammetric imaging, has\nbecome the prevalent practice for 3D Reality Modeling and digitization of\nlarge-scale monuments of Cultural Heritage (CH). In practice, this process is\nheavily related to the expertise of the surveying team, handling the laborious\nplanning and time-consuming execution of the 3D mapping process that is\ntailored to the specific requirements and constraints of each site. To minimize\nhuman intervention, this paper introduces a novel methodology for autonomous 3D\nReality Modeling for CH monuments by employing au-tonomous biomimetic\nquadrupedal robotic agents and UAVs equipped with the appropriate sensors.\nThese autonomous robotic agents carry out the 3D RM process in a systematic and\nrepeatable ap-proach. The outcomes of this automated process may find\napplications in digital twin platforms, facilitating secure monitoring and\nmanagement of cultural heritage sites and spaces, in both indoor and outdoor\nenvironments.",
      "tldr_zh": "本论文提出了一种自主3D Reality Modeling方法，使用合作四足机器人(quadrupedal robotic agents)和Unmanned Aerial Vehicles (UAVs)来数字化文化遗产(Cultural Heritage, CH)遗址，旨在减少人为干预并简化繁重的规划过程。该方法通过配备适当传感器的自主机器人系统，实现系统化和可重复的3D映射操作。实验结果表明，此创新框架可应用于数字孪生平台，促进CH遗址室内外环境的安全监控和管理。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12794v1",
      "published_date": "2024-02-20 08:08:07 UTC",
      "updated_date": "2024-02-20 08:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:22:05.138727"
    },
    {
      "arxiv_id": "2402.15526v1",
      "title": "Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Wei",
        "Jingyuan Zhang",
        "Hongzhi Zhang",
        "Fuzheng Zhang",
        "Di Zhang",
        "Li Jin",
        "Yue Yu"
      ],
      "abstract": "Large Language Models (LLMs) exhibit remarkable generative capabilities,\nenabling the generation of valuable information. Despite these advancements,\nprevious research found that LLMs sometimes struggle with adhering to specific\nconstraints (e.g., in specific place or at specific time), at times even\noverlooking them, which leads to responses that are either too generic or not\nfully satisfactory. Existing approaches attempted to address this issue by\ndecomposing or rewriting input instructions, yet they fall short in adequately\nemphasizing specific constraints and in unlocking the underlying knowledge\n(e.g., programming within the context of software development). In response,\nthis paper proposes a simple yet effective method named Chain-of-Specificity\n(CoS). Specifically, CoS iteratively emphasizes the specific constraints in the\ninput instructions, unlocks knowledge within LLMs, and refines responses.\nExperiments conducted on publicly available and self-build complex datasets\ndemonstrate that CoS outperforms existing methods in enhancing generated\ncontent especially for the specificity. Besides, as the number of specific\nconstraints increase, other baselines falter, while CoS still performs well.\nMoreover, we show that distilling responses generated by CoS effectively\nenhances the ability of smaller models to follow the constrained instructions.\nResources of this paper will be released for further research.",
      "tldr_zh": "本论文针对Large Language Models (LLMs) 在处理特定约束（如特定地点或时间）时易忽略问题，提出了一种简单有效的迭代精炼方法Chain-of-Specificity (CoS)。CoS 通过逐步强调输入指令中的特定约束、解锁LLMs的底层知识并精炼响应，从而生成更精确的内容。实验在公开和自建复杂数据集上表明，CoS 优于现有方法，尤其在提升生成的特定性方面，且当特定约束数量增加时，CoS 保持稳定性能；此外，通过蒸馏CoS生成的响应，可以显著提升较小模型的约束遵循能力。资源将公开以支持进一步研究。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15526v1",
      "published_date": "2024-02-20 08:03:05 UTC",
      "updated_date": "2024-02-20 08:03:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:22:17.198303"
    },
    {
      "arxiv_id": "2402.12789v3",
      "title": "Fairness Without Harm: An Influence-Guided Active Sampling Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlong Pang",
        "Jialu Wang",
        "Zhaowei Zhu",
        "Yuanshun Yao",
        "Chen Qian",
        "Yang Liu"
      ],
      "abstract": "The pursuit of fairness in machine learning (ML), ensuring that the models do\nnot exhibit biases toward protected demographic groups, typically results in a\ncompromise scenario. This compromise can be explained by a Pareto frontier\nwhere given certain resources (e.g., data), reducing the fairness violations\noften comes at the cost of lowering the model accuracy. In this work, we aim to\ntrain models that mitigate group fairness disparity without causing harm to\nmodel accuracy. Intuitively, acquiring more data is a natural and promising\napproach to achieve this goal by reaching a better Pareto frontier of the\nfairness-accuracy tradeoff. The current data acquisition methods, such as fair\nactive learning approaches, typically require annotating sensitive attributes.\nHowever, these sensitive attribute annotations should be protected due to\nprivacy and safety concerns. In this paper, we propose a tractable active data\nsampling algorithm that does not rely on training group annotations, instead\nonly requiring group annotations on a small validation set. Specifically, the\nalgorithm first scores each new example by its influence on fairness and\naccuracy evaluated on the validation dataset, and then selects a certain number\nof examples for training. We theoretically analyze how acquiring more data can\nimprove fairness without causing harm, and validate the possibility of our\nsampling approach in the context of risk disparity. We also provide the upper\nbound of generalization error and risk disparity as well as the corresponding\nconnections. Extensive experiments on real-world data demonstrate the\neffectiveness of our proposed algorithm. Our code is available at\nhttps://github.com/UCSC-REAL/FairnessWithoutHarm.",
      "tldr_zh": "这篇论文探讨了机器学习中公平性与准确性的权衡问题，提出了一种影响导向的主动采样方法（Influence-Guided Active Sampling Approach），旨在减少群组公平差异（如风险差异）而不损害模型性能。方法通过在小验证集上评估样本对公平性和准确性的影响来选择新数据进行训练，而非依赖训练集的敏感属性标注。理论分析证明了获取更多数据能改善Pareto frontier上的权衡，并提供了泛化误差和风险差异的上界；实验在真实数据集上验证了该算法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12789v3",
      "published_date": "2024-02-20 07:57:38 UTC",
      "updated_date": "2024-11-08 10:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:22:28.227888"
    },
    {
      "arxiv_id": "2402.12782v1",
      "title": "Advancing GenAI Assisted Programming--A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4",
      "title_zh": "翻译失败",
      "authors": [
        "Angus Yang",
        "Zehan Li",
        "Jie Li"
      ],
      "abstract": "This study aims to explore the best practices for utilizing GenAI as a\nprogramming tool, through a comparative analysis between GPT-4 and GLM-4. By\nevaluating prompting strategies at different levels of complexity, we identify\nthat simplest and straightforward prompting strategy yields best code\ngeneration results. Additionally, adding a CoT-like preliminary confirmation\nstep would further increase the success rate. Our results reveal that while\nGPT-4 marginally outperforms GLM-4, the difference is minimal for average\nusers. In our simplified evaluation model, we see a remarkable 30 to 100-fold\nincrease in code generation efficiency over traditional coding norms. Our GenAI\nCoding Workshop highlights the effectiveness and accessibility of the prompting\nmethodology developed in this study. We observe that GenAI-assisted coding\nwould trigger a paradigm shift in programming landscape, which necessitates\ndevelopers to take on new roles revolving around supervising and guiding GenAI,\nand to focus more on setting high-level objectives and engaging more towards\ninnovation.",
      "tldr_zh": "这篇论文通过比较 GPT-4 和 GLM-4，探讨了使用 GenAI 作为编程工具的最佳实践，重点评估不同复杂度的提示策略。研究发现，最简单直接的提示策略能产生最佳代码生成结果，而添加 CoT-like 初步确认步骤可进一步提升成功率。结果显示，GPT-4 略微优于 GLM-4，但差异对普通用户影响不大，且 GenAI 辅助编码的效率比传统方法高 30 到 100 倍。论文强调，这将引发编程领域的范式转变，开发者需转向监督 GenAI、设定高层目标并推动创新。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.3"
      ],
      "primary_category": "cs.SE",
      "comment": "18 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.12782v1",
      "published_date": "2024-02-20 07:47:39 UTC",
      "updated_date": "2024-02-20 07:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:22:40.984978"
    },
    {
      "arxiv_id": "2404.15282v1",
      "title": "Patent Value Characterization -- An Empirical Analysis of Elevator Industry Patents",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Guan",
        "Runzheng Wang",
        "Lei Fu",
        "Huanle Zhang"
      ],
      "abstract": "The global patent application count has steadily increased, achieving eight\nconsecutive years of growth.The global patent industry has shown a general\ntrend of expansion. This is attributed to the increasing innovation activities,\nparticularly in the fields of technology, healthcare, and biotechnology. Some\nemerging market countries, such as China and India, have experienced\nsignificant growth in the patent domain, becoming important participants in\nglobal patent activities.",
      "tldr_zh": "这篇论文通过实证分析（Empirical Analysis）考察了电梯行业专利的价值特征，聚焦于全球专利申请的增长趋势。研究强调了创新活动在技术、医疗和生物技术领域的增加，以及新兴市场如中国和印度在专利领域的显著贡献。论文揭示了这些因素如何影响电梯行业专利的价值评估，为理解专利行业动态提供了实证依据。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15282v1",
      "published_date": "2024-02-20 07:18:16 UTC",
      "updated_date": "2024-02-20 07:18:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:22:53.219929"
    },
    {
      "arxiv_id": "2402.12760v1",
      "title": "A User-Friendly Framework for Generating Model-Preferred Prompts in Text-to-Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Nailei Hei",
        "Qianyu Guo",
        "Zihao Wang",
        "Yan Wang",
        "Haofen Wang",
        "Wenqiang Zhang"
      ],
      "abstract": "Well-designed prompts have demonstrated the potential to guide text-to-image\nmodels in generating amazing images. Although existing prompt engineering\nmethods can provide high-level guidance, it is challenging for novice users to\nachieve the desired results by manually entering prompts due to a discrepancy\nbetween novice-user-input prompts and the model-preferred prompts. To bridge\nthe distribution gap between user input behavior and model training datasets,\nwe first construct a novel Coarse-Fine Granularity Prompts dataset (CFP) and\npropose a novel User-Friendly Fine-Grained Text Generation framework (UF-FGTG)\nfor automated prompt optimization. For CFP, we construct a novel dataset for\ntext-to-image tasks that combines coarse and fine-grained prompts to facilitate\nthe development of automated prompt generation methods. For UF-FGTG, we propose\na novel framework that automatically translates user-input prompts into\nmodel-preferred prompts. Specifically, we propose a prompt refiner that\ncontinually rewrites prompts to empower users to select results that align with\ntheir unique needs. Meanwhile, we integrate image-related loss functions from\nthe text-to-image model into the training process of text generation to\ngenerate model-preferred prompts. Additionally, we propose an adaptive feature\nextraction module to ensure diversity in the generated results. Experiments\ndemonstrate that our approach is capable of generating more visually appealing\nand diverse images than previous state-of-the-art methods, achieving an average\nimprovement of 5% across six quality and aesthetic metrics.",
      "tldr_zh": "该研究针对文本到图像合成中，用户输入提示与模型偏好提示之间的差距问题，提出了一种用户友好的框架 UF-FGTG，以帮助新手用户生成更理想的图像。首先，构建了新型数据集 CFP（Coarse-Fine Granularity Prompts），它结合粗粒度和细粒度提示，支持自动化提示生成。其次，框架包括一个提示 refiner 模块，用于持续重写用户输入提示，并整合文本到图像模型的图像相关损失函数以及自适应 feature extraction module，以确保生成提示的多样性和模型兼容性。实验结果显示，该方法在六个质量和美学指标上平均提高了5%，生成更具吸引力的图像。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted by The 38th Annual AAAI Conference on Artificial\n  Intelligence (AAAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.12760v1",
      "published_date": "2024-02-20 06:58:49 UTC",
      "updated_date": "2024-02-20 06:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:23:04.923042"
    },
    {
      "arxiv_id": "2402.12750v2",
      "title": "Model Composition for Multimodal Large Language Models",
      "title_zh": "多模态大语言模型的模型组合",
      "authors": [
        "Chi Chen",
        "Yiyang Du",
        "Zheng Fang",
        "Ziyue Wang",
        "Fuwen Luo",
        "Peng Li",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang",
        "Maosong Sun",
        "Yang Liu"
      ],
      "abstract": "Recent developments in Multimodal Large Language Models (MLLMs) have shown\nrapid progress, moving towards the goal of creating versatile MLLMs that\nunderstand inputs from various modalities. However, existing methods typically\nrely on joint training with paired multimodal instruction data, which is\nresource-intensive and challenging to extend to new modalities. In this paper,\nwe propose a new paradigm through the model composition of existing MLLMs to\ncreate a new model that retains the modal understanding capabilities of each\noriginal model. Our basic implementation, NaiveMC, demonstrates the\neffectiveness of this paradigm by reusing modality encoders and merging LLM\nparameters. Furthermore, we introduce DAMC to address parameter interference\nand mismatch issues during the merging process, thereby enhancing the model\nperformance. To facilitate research in this area, we propose MCUB, a benchmark\nfor assessing ability of MLLMs to understand inputs from diverse modalities.\nExperiments on this benchmark and four other multimodal understanding tasks\nshow significant improvements over baselines, proving that model composition\ncan create a versatile model capable of processing inputs from multiple\nmodalities.",
      "tldr_zh": "这篇论文提出了一种通过模型组合构建 Multimodal Large Language Models (MLLMs) 的新范式，以避免资源密集的联合训练，并保留各原始模型的模态理解能力。具体方法包括 NaiveMC（重用模态编码器并合并 LLM 参数）和 DAMC（处理参数干扰和不匹配问题以提升性能）。此外，论文引入了 MCUB 基准，用于评估 MLLMs 处理多种模态输入的能力，并在该基准以及其他四个多模态理解任务上，实验结果显示比基线模型有显著改进，证明了模型组合在创建通用多模态模型方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ACL2024 Main Conference; Code is available at\n  https://github.com/THUNLP-MT/ModelCompose",
      "pdf_url": "http://arxiv.org/pdf/2402.12750v2",
      "published_date": "2024-02-20 06:38:10 UTC",
      "updated_date": "2024-07-26 10:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:23:18.456718"
    },
    {
      "arxiv_id": "2402.12749v5",
      "title": "Me LLaMA: Foundation Large Language Models for Medical Applications",
      "title_zh": "Me LLaMA：用于医疗应用的基础大语言模型",
      "authors": [
        "Qianqian Xie",
        "Qingyu Chen",
        "Aokun Chen",
        "Cheng Peng",
        "Yan Hu",
        "Fongci Lin",
        "Xueqing Peng",
        "Jimin Huang",
        "Jeffrey Zhang",
        "Vipina Keloth",
        "Xinyu Zhou",
        "Lingfei Qian",
        "Huan He",
        "Dennis Shung",
        "Lucila Ohno-Machado",
        "Yonghui Wu",
        "Hua Xu",
        "Jiang Bian"
      ],
      "abstract": "Recent advancements in large language models (LLMs) like ChatGPT and LLaMA\nshow promise in medical applications, yet challenges remain in medical language\ncomprehension. This study presents Me-LLaMA, a new medical LLM family based on\nopen-source LLaMA models, optimized for medical text analysis and diagnosis by\nleveraging large-scale, domain-specific datasets. The Me-LLaMA family,\nincluding foundation models Me-LLaMA 13/70B and their chat-enhanced versions,\nwas developed through continued pre-training and instruction tuning with 129B\ntokens and 214K samples from biomedical and clinical sources. Training the 70B\nmodels required over 100,000 A100 GPU hours. Me-LLaMA's performance was\nevaluated across six medical text analysis tasks using 12 benchmark datasets\nand complex clinical case diagnosis, with automatic and human evaluations.\nResults indicate Me-LLaMA outperforms LLaMA and other open-source medical LLMs\nin zero-shot and supervised settings. Task-specific tuning further boosts\nperformance, surpassing ChatGPT on 7 of 8 datasets and GPT-4 on 5 of 8. For\ncomplex clinical cases, Me-LLaMA achieves performance comparable to ChatGPT and\nGPT-4. This work underscores the importance of domain-specific data in\ndeveloping medical LLMs and addresses the high computational costs involved in\ntraining, highlighting a balance between pre-training and fine-tuning\nstrategies. Me-LLaMA models are now accessible under user agreements, providing\na valuable resource for advancing medical AI.",
      "tldr_zh": "本文介绍了 Me-LLaMA，一系列基于开源 LLaMA 的基础大型语言模型 (LLMs)，针对医疗文本分析和诊断进行了优化，通过使用 129B tokens 和 214K 样本的生物医学及临床数据进行持续预训练和指令调整。Me-LLaMA 家族包括 13B 和 70B 模型及其聊天增强版本，训练过程耗费超过 100,000 A100 GPU 小时。实验结果显示，Me-LLaMA 在 12 个基准数据集和 6 个医疗任务上超越 LLaMA 及其他开源医疗 LLMs，在零样本和监督设置中击败 ChatGPT 于 7/8 数据集和 GPT-4 于 5/8 数据集，并在复杂临床病例诊断中达到与 ChatGPT、GPT-4 相当的性能。该研究强调了领域特定数据的重要性，并提供可访问的模型资源以推进医疗 AI 发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 4 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.12749v5",
      "published_date": "2024-02-20 06:37:31 UTC",
      "updated_date": "2024-11-02 03:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:23:31.873729"
    },
    {
      "arxiv_id": "2402.14855v1",
      "title": "An LLM Maturity Model for Reliable and Transparent Text-to-Query",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Yu",
        "Abir Ray"
      ],
      "abstract": "Recognizing the imperative to address the reliability and transparency issues\nof Large Language Models (LLM), this work proposes an LLM maturity model\ntailored for text-to-query applications. This maturity model seeks to fill the\nexisting void in evaluating LLMs in such applications by incorporating\ndimensions beyond mere correctness or accuracy. Moreover, this work introduces\na real-world use case from the law enforcement domain and showcases QueryIQ, an\nLLM-powered, domain-specific text-to-query assistant to expedite user workflows\nand reveal hidden relationship in data.",
      "tldr_zh": "这篇论文提出了一种针对文本到查询（text-to-query）应用的 LLM 成熟度模型（LLM maturity model），旨在解决大型语言模型（LLM）的可靠性和透明性问题，并填补现有评估标准的空白。该模型扩展了评估维度，不限于正确性或准确性，还包括其他关键因素。同时，论文通过执法领域的真实用例，展示了 QueryIQ 这款基于 LLM 的领域特定助手，能够加速用户工作流程并揭示数据中的隐藏关系。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14855v1",
      "published_date": "2024-02-20 06:20:09 UTC",
      "updated_date": "2024-02-20 06:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:23:42.114200"
    },
    {
      "arxiv_id": "2402.14854v1",
      "title": "A Dual-Prompting for Interpretable Mental Health Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyolim Jeon",
        "Dongje Yoo",
        "Daeun Lee",
        "Sejung Son",
        "Seungbae Kim",
        "Jinyoung Han"
      ],
      "abstract": "Despite the increasing demand for AI-based mental health monitoring tools,\ntheir practical utility for clinicians is limited by the lack of\ninterpretability.The CLPsych 2024 Shared Task (Chim et al., 2024) aims to\nenhance the interpretability of Large Language Models (LLMs), particularly in\nmental health analysis, by providing evidence of suicidality through linguistic\ncontent. We propose a dual-prompting approach: (i) Knowledge-aware evidence\nextraction by leveraging the expert identity and a suicide dictionary with a\nmental health-specific LLM; and (ii) Evidence summarization by employing an\nLLM-based consistency evaluator. Comprehensive experiments demonstrate the\neffectiveness of combining domain-specific information, revealing performance\nimprovements and the approach's potential to aid clinicians in assessing mental\nstate progression.",
      "tldr_zh": "该论文针对AI心理健康监测工具的可解释性不足问题，提出了双提示（dual-prompting）方法，以提升Large Language Models (LLMs)在心理健康分析中的透明度。具体而言，该方法包括（i）知识感知证据提取，利用专家身份和自杀字典与mental health-specific LLM提取相关证据；以及（ii）证据总结，通过LLM-based consistency evaluator进行一致性评估。实验结果显示，该方法结合领域特定信息显著提高了性能，并为临床医生提供有效工具，帮助评估心理状态进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14854v1",
      "published_date": "2024-02-20 06:18:02 UTC",
      "updated_date": "2024-02-20 06:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:23:52.982075"
    },
    {
      "arxiv_id": "2402.12738v1",
      "title": "Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Michimasa Inaba",
        "Mariko Ukiyo",
        "Keiko Takamizo"
      ],
      "abstract": "Mental health care poses an increasingly serious challenge to modern\nsocieties. In this context, there has been a surge in research that utilizes\ninformation technologies to address mental health problems, including those\naiming to develop counseling dialogue systems. However, there is a need for\nmore evaluations of the performance of counseling dialogue systems that use\nlarge language models. For this study, we collected counseling dialogue data\nvia role-playing scenarios involving expert counselors, and the utterances were\nannotated with the intentions of the counselors. To determine the feasibility\nof a dialogue system in real-world counseling scenarios, third-party counselors\nevaluated the appropriateness of responses from human counselors and those\ngenerated by GPT-4 in identical contexts in role-play dialogue data. Analysis\nof the evaluation results showed that the responses generated by GPT-4 were\ncompetitive with those of human counselors.",
      "tldr_zh": "这篇论文探讨了Large Language Models（如GPT-4）在提供心理咨询方面的可行性，通过分析其在角色扮演对话中的生成响应。研究方法包括收集专家咨询师参与的角色扮演对话数据，并标注咨询师意图，随后由第三方咨询师评估GPT-4生成的响应与人类响应的适当性。结果显示，GPT-4的响应在表现上与人类咨询师具有竞争力，这为利用大语言模型开发咨询对话系统提供了潜在价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a conference paper at IWSDS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12738v1",
      "published_date": "2024-02-20 06:05:36 UTC",
      "updated_date": "2024-02-20 06:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:24:04.538761"
    },
    {
      "arxiv_id": "2402.12736v1",
      "title": "CST: Calibration Side-Tuning for Parameter and Memory Efficient Transfer Learning",
      "title_zh": "CST：校准侧向调整用于参数和内存高效的迁移学习",
      "authors": [
        "Feng Chen"
      ],
      "abstract": "Achieving a universally high accuracy in object detection is quite\nchallenging, and the mainstream focus in the industry currently lies on\ndetecting specific classes of objects. However, deploying one or multiple\nobject detection networks requires a certain amount of GPU memory for training\nand storage capacity for inference. This presents challenges in terms of how to\neffectively coordinate multiple object detection tasks under\nresource-constrained conditions. This paper introduces a lightweight\nfine-tuning strategy called Calibration side tuning, which integrates aspects\nof adapter tuning and side tuning to adapt the successful techniques employed\nin transformers for use with ResNet. The Calibration side tuning architecture\nthat incorporates maximal transition calibration, utilizing a small number of\nadditional parameters to enhance network performance while maintaining a smooth\ntraining process. Furthermore, this paper has conducted an analysis on multiple\nfine-tuning strategies and have implemented their application within ResNet,\nthereby expanding the research on fine-tuning strategies for object detection\nnetworks. Besides, this paper carried out extensive experiments using five\nbenchmark datasets. The experimental results demonstrated that this method\noutperforms other compared state-of-the-art techniques, and a better balance\nbetween the complexity and performance of the finetune schemes is achieved.",
      "tldr_zh": "该论文提出了CST（Calibration Side-Tuning），一种参数和内存高效的迁移学习微调策略，旨在解决对象检测任务在资源受限条件下协调多个任务的挑战。该方法结合了adapter tuning和side tuning的技术，应用于ResNet架构，通过maximal transition calibration仅使用少量额外参数来提升网络性能并确保平滑训练过程。实验在五个基准数据集上进行，结果显示CST优于现有最先进技术，在微调策略的复杂性和性能之间实现了更好平衡，从而扩展了对象检测网络微调策略的研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12736v1",
      "published_date": "2024-02-20 06:01:31 UTC",
      "updated_date": "2024-02-20 06:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:24:16.754726"
    },
    {
      "arxiv_id": "2402.14853v1",
      "title": "NL2Formula: Generating Spreadsheet Formulas from Natural Language Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Zhao",
        "Zhitao Hou",
        "Siyuan Wu",
        "Yan Gao",
        "Haoyu Dong",
        "Yao Wan",
        "Hongyu Zhang",
        "Yulei Sui",
        "Haidong Zhang"
      ],
      "abstract": "Writing formulas on spreadsheets, such as Microsoft Excel and Google Sheets,\nis a widespread practice among users performing data analysis. However,\ncrafting formulas on spreadsheets remains a tedious and error-prone task for\nmany end-users, particularly when dealing with complex operations. To alleviate\nthe burden associated with writing spreadsheet formulas, this paper introduces\na novel benchmark task called NL2Formula, with the aim to generate executable\nformulas that are grounded on a spreadsheet table, given a Natural Language\n(NL) query as input. To accomplish this, we construct a comprehensive dataset\nconsisting of 70,799 paired NL queries and corresponding spreadsheet formulas,\ncovering 21,670 tables and 37 types of formula functions. We realize the\nNL2Formula task by providing a sequence-to-sequence baseline implementation\ncalled fCoder. Experimental results validate the effectiveness of fCoder,\ndemonstrating its superior performance compared to the baseline models.\nFurthermore, we also compare fCoder with an initial GPT-3.5 model (i.e.,\ntext-davinci-003). Lastly, through in-depth error analysis, we identify\npotential challenges in the NL2Formula task and advocate for further\ninvestigation.",
      "tldr_zh": "这篇论文引入了 NL2Formula 任务，旨在从 Natural Language (NL) 查询自动生成可执行的电子表格公式，以简化用户的数据分析过程。研究者构建了一个包含 70,799 对 NL 查询和对应公式的全面数据集，覆盖 21,670 个表格和 37 种公式函数，并开发了 sequence-to-sequence 基线模型 fCoder。实验结果表明，fCoder 优于其他基线模型和 GPT-3.5（text-davinci-003），通过错误分析还识别了任务中的潜在挑战，并呼吁进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14853v1",
      "published_date": "2024-02-20 05:58:05 UTC",
      "updated_date": "2024-02-20 05:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:24:29.646956"
    },
    {
      "arxiv_id": "2402.12733v1",
      "title": "BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Weixin Li",
        "Yuhao Wu",
        "Yang Liu",
        "Weike Pan",
        "Zhong Ming"
      ],
      "abstract": "In real recommendation scenarios, users often have different types of\nbehaviors, such as clicking and buying. Existing research methods show that it\nis possible to capture the heterogeneous interests of users through different\ntypes of behaviors. However, most multi-behavior approaches have limitations in\nlearning the relationship between different behaviors. In this paper, we\npropose a novel multilayer perceptron (MLP)-based heterogeneous sequential\nrecommendation method, namely behavior-aware multilayer perceptron (BMLP).\nSpecifically, it has two main modules, including a heterogeneous interest\nperception (HIP) module, which models behaviors at multiple granularities\nthrough behavior types and transition relationships, and a purchase intent\nperception (PIP) module, which adaptively fuses subsequences of auxiliary\nbehaviors to capture users' purchase intent. Compared with mainstream sequence\nmodels, MLP is competitive in terms of accuracy and has unique advantages in\nsimplicity and efficiency. Extensive experiments show that BMLP achieves\nsignificant improvement over state-of-the-art algorithms on four public\ndatasets. In addition, its pure MLP architecture leads to a linear time\ncomplexity.",
      "tldr_zh": "该论文提出了一种基于多层感知器(MLP)的异构序列推荐方法BMLP，用于捕捉用户不同行为（如点击和购买）间的关系。BMLP 包括两个核心模块：Heterogeneous Interest Perception (HIP) 模块，通过行为类型和转换关系建模多粒度行为；以及 Purchase Intent Perception (PIP) 模块，自适应融合辅助行为的子序列以捕获用户的购买意图。与主流序列模型相比，BMLP 在准确性和简单性上具有优势，并在四个公共数据集上显著优于现有算法，同时实现线性时间复杂度。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12733v1",
      "published_date": "2024-02-20 05:57:01 UTC",
      "updated_date": "2024-02-20 05:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:24:40.870007"
    },
    {
      "arxiv_id": "2402.12730v2",
      "title": "UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation",
      "title_zh": "翻译失败",
      "authors": [
        "Shubhashis Roy Dipta",
        "Sai Vallurupalli"
      ],
      "abstract": "The aim of SemEval-2024 Task 1, \"Semantic Textual Relatedness for African and\nAsian Languages\" is to develop models for identifying semantic textual\nrelatedness (STR) between two sentences using multiple languages (14 African\nand Asian languages) and settings (supervised, unsupervised, and\ncross-lingual). Large language models (LLMs) have shown impressive performance\non several natural language understanding tasks such as multilingual machine\ntranslation (MMT), semantic similarity (STS), and encoding sentence embeddings.\nUsing a combination of LLMs that perform well on these tasks, we developed two\nSTR models, $\\textit{TranSem}$ and $\\textit{FineSem}$, for the supervised and\ncross-lingual settings. We explore the effectiveness of several training\nmethods and the usefulness of machine translation. We find that direct\nfine-tuning on the task is comparable to using sentence embeddings and\ntranslating to English leads to better performance for some languages. In the\nsupervised setting, our model performance is better than the official baseline\nfor 3 languages with the remaining 4 performing on par. In the cross-lingual\nsetting, our model performance is better than the baseline for 3 languages\n(leading to $1^{st}$ place for Africaans and $2^{nd}$ place for Indonesian), is\non par for 2 languages and performs poorly on the remaining 7 languages. Our\ncode is publicly available at https://github.com/dipta007/SemEval24-Task8.",
      "tldr_zh": "这篇论文介绍了UMBCLU团队在SemEval-2024 Task 1A和1C中的工作，专注于开发语义文本相关性(STR)模型，用于14种非洲和亚洲语言的监督、跨语言设置。研究团队构建了TranSem和FineSem模型，利用大型语言模型(LLMs)结合直接微调、句子嵌入和机器翻译方法，评估了这些技术的有效性。结果显示，直接微调的性能与使用句子嵌入相当，而翻译到英语能提升某些语言的表现；在监督设置中，模型在3种语言上优于官方基线，在跨语言设置中则在Afrikaans上获第一名、在Indonesian上获第二名。代码已公开在GitHub，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SemEval 2024 (Colocated with NAACL 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.12730v2",
      "published_date": "2024-02-20 05:46:29 UTC",
      "updated_date": "2024-04-12 00:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:24:54.995825"
    },
    {
      "arxiv_id": "2402.13297v1",
      "title": "Integrating Deep Learning and Synthetic Biology: A Co-Design Approach for Enhancing Gene Expression via N-terminal Coding Sequences",
      "title_zh": "整合深度学习和合成生物学：一种通过 N 端编码序列增强",
      "authors": [
        "Zhanglu Yan",
        "Weiran Chu",
        "Yuhua Sheng",
        "Kaiwen Tang",
        "Shida Wang",
        "Yanfeng Liu",
        "Weng-Fai Wong"
      ],
      "abstract": "N-terminal coding sequence (NCS) influences gene expression by impacting the\ntranslation initiation rate. The NCS optimization problem is to find an NCS\nthat maximizes gene expression. The problem is important in genetic\nengineering. However, current methods for NCS optimization such as rational\ndesign and statistics-guided approaches are labor-intensive yield only\nrelatively small improvements. This paper introduces a deep learning/synthetic\nbiology co-designed few-shot training workflow for NCS optimization. Our method\nutilizes k-nearest encoding followed by word2vec to encode the NCS, then\nperforms feature extraction using attention mechanisms, before constructing a\ntime-series network for predicting gene expression intensity, and finally a\ndirect search algorithm identifies the optimal NCS with limited training data.\nWe took green fluorescent protein (GFP) expressed by Bacillus subtilis as a\nreporting protein of NCSs, and employed the fluorescence enhancement factor as\nthe metric of NCS optimization. Within just six iterative experiments, our\nmodel generated an NCS (MLD62) that increased average GFP expression by\n5.41-fold, outperforming the state-of-the-art NCS designs. Extending our\nfindings beyond GFP, we showed that our engineered NCS (MLD62) can effectively\nboost the production of N-acetylneuraminic acid by enhancing the expression of\nthe crucial rate-limiting GNA1 gene, demonstrating its practical utility. We\nhave open-sourced our NCS expression database and experimental procedures for\npublic use.",
      "tldr_zh": "本研究提出了一种深度学习与合成生物学的联合设计方法，用于优化N-terminal coding sequences (NCS)，以最大化基因表达并解决传统方法的局限性。方法包括使用k-nearest encoding和word2vec进行编码、注意力机制提取特征、时间序列网络预测基因表达强度，以及直接搜索算法在少样本数据下识别最优NCS。实验结果显示，该方法在绿色荧光蛋白(GFP)表达上实现了5.41倍的平均提升，优于现有设计，并成功扩展到提升N-乙酰神经氨酸生产的关键限速基因GNA1表达。研究开源了NCS表达数据库和实验程序，促进遗传工程领域的进一步应用。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13297v1",
      "published_date": "2024-02-20 05:41:46 UTC",
      "updated_date": "2024-02-20 05:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:25:07.434637"
    },
    {
      "arxiv_id": "2402.12729v1",
      "title": "Scalable and reliable deep transfer learning for intelligent fault detection via multi-scale neural processes embedded with knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongzhi Li",
        "Jingqi Tu",
        "Jiacheng Zhu",
        "Jianliang Ai",
        "Yiqun Dong"
      ],
      "abstract": "Deep transfer learning (DTL) is a fundamental method in the field of\nIntelligent Fault Detection (IFD). It aims to mitigate the degradation of\nmethod performance that arises from the discrepancies in data distribution\nbetween training set (source domain) and testing set (target domain).\nConsidering the fact that fault data collection is challenging and certain\nfaults are scarce, DTL-based methods face the limitation of available\nobservable data, which reduces the detection performance of the methods in the\ntarget domain. Furthermore, DTL-based methods lack comprehensive uncertainty\nanalysis that is essential for building reliable IFD systems. To address the\naforementioned problems, this paper proposes a novel DTL-based method known as\nNeural Processes-based deep transfer learning with graph convolution network\n(GTNP). Feature-based transfer strategy of GTNP bridges the data distribution\ndiscrepancies of source domain and target domain in high-dimensional space.\nBoth the joint modeling based on global and local latent variables and sparse\nsampling strategy reduce the demand of observable data in the target domain.\nThe multi-scale uncertainty analysis is obtained by using the distribution\ncharacteristics of global and local latent variables. Global analysis of\nuncertainty enables GTNP to provide quantitative values that reflect the\ncomplexity of methods and the difficulty of tasks. Local analysis of\nuncertainty allows GTNP to model uncertainty (confidence of the fault detection\nresult) at each sample affected by noise and bias. The validation of the\nproposed method is conducted across 3 IFD tasks, consistently showing the\nsuperior detection performance of GTNP compared to the other DTL-based methods.",
      "tldr_zh": "这篇论文提出了一种名为 GTNP 的新型深度迁移学习（Deep Transfer Learning）方法，用于智能故障检测（Intelligent Fault Detection），旨在解决数据分布差异、数据稀缺以及不确定性分析不足的问题。GTNP 通过特征转移策略结合图卷积网络（Graph Convolution Network），在高维空间桥接源域和目标域的数据分布，并利用基于全局和局部潜在变量的联合建模以及稀疏采样策略，减少了对目标域可观测数据的需求。同时，该方法引入多尺度不确定性分析，利用潜在变量的分布特性进行全局任务难度评估和局部样本置信度建模，提升了系统的可靠性和可解释性。实验验证显示，GTNP 在 3 个智能故障检测任务上比其他深度迁移学习方法表现出显著优越的检测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12729v1",
      "published_date": "2024-02-20 05:39:32 UTC",
      "updated_date": "2024-02-20 05:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:25:22.593770"
    },
    {
      "arxiv_id": "2402.12728v2",
      "title": "Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Junnan Dong",
        "Qinggang Zhang",
        "Huachi Zhou",
        "Daochen Zha",
        "Pai Zheng",
        "Xiao Huang"
      ],
      "abstract": "Knowledge-based visual question answering (KVQA) has been extensively studied\nto answer visual questions with external knowledge, e.g., knowledge graphs\n(KGs). While several attempts have been proposed to leverage large language\nmodels (LLMs) as an implicit knowledge source, it remains challenging since\nLLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g.,\nimages, KGs and LLMs, cannot be readily aligned for complex scenarios. To\ntackle these, we present a novel modality-aware integration with LLMs for KVQA\n(MAIL). It carefully leverages multimodal knowledge for both image\nunderstanding and knowledge reasoning. Specifically, (i) we propose a two-stage\nprompting strategy with LLMs to densely embody the image into a scene graph\nwith detailed visual features; (ii) We construct a coupled concept graph by\nlinking the mentioned entities with external facts. (iii) A tailored\npseudo-siamese graph medium fusion is designed for sufficient multimodal\nfusion. We utilize the shared mentioned entities in two graphs as mediums to\nbridge a tight inter-modal exchange, while maximally preserving insightful\nintra-modal learning by constraining the fusion within mediums. Extensive\nexperiments on two benchmark datasets show the superiority of MAIL with 24x\nless resources.",
      "tldr_zh": "该论文提出了一种模态感知整合框架MAIL（Modality-Aware Integration with LLMs），用于基于知识的视觉问答（KVQA），旨在整合图像、知识图谱（KGs）和大型语言模型（LLMs）来解决LLMs幻觉（hallucinations）和多源知识对齐挑战。方法包括两阶段提示策略将图像转化为详细的场景图（scene graph），构建耦合概念图（coupled concept graph）以链接实体和外部事实，以及定制的伪孪生图中介融合（pseudo-siamese graph medium fusion），通过共享实体作为桥梁实现多模态融合，同时保留内部模式学习。实验在两个基准数据集上证明了MAIL的优越性，仅使用24倍更少的资源，显著提升了KVQA的性能和效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages,3 figures and 1 page appendix; The processed graphs and codes\n  will be avalibale",
      "pdf_url": "http://arxiv.org/pdf/2402.12728v2",
      "published_date": "2024-02-20 05:32:24 UTC",
      "updated_date": "2024-03-03 04:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:25:32.232627"
    },
    {
      "arxiv_id": "2402.12727v1",
      "title": "Diffusion Posterior Sampling is Computationally Intractable",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Gupta",
        "Ajil Jalal",
        "Aditya Parulekar",
        "Eric Price",
        "Zhiyang Xun"
      ],
      "abstract": "Diffusion models are a remarkably effective way of learning and sampling from\na distribution $p(x)$. In posterior sampling, one is also given a measurement\nmodel $p(y \\mid x)$ and a measurement $y$, and would like to sample from $p(x\n\\mid y)$. Posterior sampling is useful for tasks such as inpainting,\nsuper-resolution, and MRI reconstruction, so a number of recent works have\ngiven algorithms to heuristically approximate it; but none are known to\nconverge to the correct distribution in polynomial time.\n  In this paper we show that posterior sampling is \\emph{computationally\nintractable}: under the most basic assumption in cryptography -- that one-way\nfunctions exist -- there are instances for which \\emph{every} algorithm takes\nsuperpolynomial time, even though \\emph{unconditional} sampling is provably\nfast. We also show that the exponential-time rejection sampling algorithm is\nessentially optimal under the stronger plausible assumption that there are\none-way functions that take exponential time to invert.",
      "tldr_zh": "这篇论文证明了扩散模型（Diffusion models）在后验采样（posterior sampling）任务中的计算不可行性，即在给定测量模型 p(y | x) 和测量 y 时，采样 p(x | y) 的过程。作者基于单向函数（one-way functions）存在的密码学假设，展示了某些实例下所有算法都需要超多项式时间，即使无条件采样是快速的。实验和理论分析表明，现有的启发式算法无法在多项式时间内收敛，而指数时间的拒绝采样算法在更强的假设下本质上是最佳的，这为理解此类任务的计算极限提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12727v1",
      "published_date": "2024-02-20 05:28:13 UTC",
      "updated_date": "2024-02-20 05:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:25:44.544042"
    },
    {
      "arxiv_id": "2402.12721v4",
      "title": "PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images",
      "title_zh": "翻译失败",
      "authors": [
        "Jinsung Jeon",
        "Hyundong Jin",
        "Jonghyun Choi",
        "Sanghyun Hong",
        "Dongeun Lee",
        "Kookjin Lee",
        "Noseong Park"
      ],
      "abstract": "A standard practice in developing image recognition models is to train a\nmodel on a specific image resolution and then deploy it. However, in real-world\ninference, models often encounter images different from the training sets in\nresolution and/or subject to natural variations such as weather changes, noise\ntypes and compression artifacts. While traditional solutions involve training\nmultiple models for different resolutions or input variations, these methods\nare computationally expensive and thus do not scale in practice. To this end,\nwe propose a novel neural network model, parallel-structured and all-component\nFourier neural operator (PAC-FNO), that addresses the problem. Unlike\nconventional feed-forward neural networks, PAC-FNO operates in the frequency\ndomain, allowing it to handle images of varying resolutions within a single\nmodel. We also propose a two-stage algorithm for training PAC-FNO with a\nminimal modification to the original, downstream model. Moreover, the proposed\nPAC-FNO is ready to work with existing image recognition models. Extensively\nevaluating methods with seven image recognition benchmarks, we show that the\nproposed PAC-FNO improves the performance of existing baseline models on images\nwith various resolutions by up to 77.1% and various types of natural variations\nin the images at inference.",
      "tldr_zh": "该研究提出了一种名为 PAC-FNO 的神经网络模型，用于处理图像识别中分辨率变化和自然变异（如天气、噪声或压缩伪影）的问题，旨在避免传统方法需训练多个模型的计算开销。PAC-FNO 采用并行结构和全组件 Fourier Neural Operators，在频率域操作，从而允许单个模型处理不同分辨率的图像，并通过两阶段训练算法与现有模型轻松集成。在七个图像识别基准测试中，PAC-FNO 使基线模型的性能提升高达 77.1%，特别是在低质量图像上的识别准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12721v4",
      "published_date": "2024-02-20 05:06:20 UTC",
      "updated_date": "2024-03-14 04:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:25:56.449923"
    },
    {
      "arxiv_id": "2402.12720v1",
      "title": "Revisiting the Information Capacity of Neural Network Watermarks: Upper Bound Estimation and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Fangqi Li",
        "Haodong Zhao",
        "Wei Du",
        "Shilin Wang"
      ],
      "abstract": "To trace the copyright of deep neural networks, an owner can embed its\nidentity information into its model as a watermark. The capacity of the\nwatermark quantify the maximal volume of information that can be verified from\nthe watermarked model. Current studies on capacity focus on the ownership\nverification accuracy under ordinary removal attacks and fail to capture the\nrelationship between robustness and fidelity. This paper studies the capacity\nof deep neural network watermarks from an information theoretical perspective.\nWe propose a new definition of deep neural network watermark capacity analogous\nto channel capacity, analyze its properties, and design an algorithm that\nyields a tight estimation of its upper bound under adversarial overwriting. We\nalso propose a universal non-invasive method to secure the transmission of the\nidentity message beyond capacity by multiple rounds of ownership verification.\nOur observations provide evidence for neural network owners and defenders that\nare curious about the tradeoff between the integrity of their ownership and the\nperformance degradation of their products.",
      "tldr_zh": "这篇论文重新审视了neural network watermarks的信息容量，从信息理论视角提出一个新的容量定义，类似于channel capacity，并分析其属性。作者设计了算法来估计水印容量的上界，尤其在对抗性覆盖攻击下，提供了一个紧凑的估计方法。同时，他们提出了一种通用非侵入性方法，通过多次ownership verification来传输超出容量的身份信息。研究结果为neural network所有者和防御者提供了证据，揭示了所有权完整性与模型性能退化之间的权衡关系。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12720v1",
      "published_date": "2024-02-20 05:05:28 UTC",
      "updated_date": "2024-02-20 05:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:26:08.538221"
    },
    {
      "arxiv_id": "2403.00788v1",
      "title": "PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care",
      "title_zh": "翻译失败",
      "authors": [
        "Satvik Tripathi",
        "Liam Mutter",
        "Meghana Muppuri",
        "Suhani Dheer",
        "Emiliano Garza-Frias",
        "Komal Awan",
        "Aakash Jha",
        "Michael Dezube",
        "Azadeh Tabari",
        "Christopher P. Bridge",
        "Dania Daye"
      ],
      "abstract": "This study introduces and evaluates the PRECISE framework, utilizing OpenAI's\nGPT-4 to enhance patient engagement by providing clearer and more accessible\nchest X-ray reports at a sixth-grade reading level. The framework was tested on\n500 reports, demonstrating significant improvements in readability,\nreliability, and understandability. Statistical analyses confirmed the\neffectiveness of the PRECISE approach, highlighting its potential to foster\npatient-centric care delivery in healthcare decision-making.",
      "tldr_zh": "本研究引入了 PRECISE framework，利用 OpenAI's GPT-4 生成更清晰的胸部 X-ray reports，使其达到六年级阅读水平，以提升患者参与度。框架在 500 份报告上进行测试，显著改善了报告的可读性、可靠性和可理解性。统计分析证实了 PRECISE 方法的有效性，有助于推动患者中心护理在医疗决策中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00788v1",
      "published_date": "2024-02-20 04:26:31 UTC",
      "updated_date": "2024-02-20 04:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:26:19.851996"
    },
    {
      "arxiv_id": "2402.14852v1",
      "title": "HumanEval on Latest GPT Models -- 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Li",
        "Lincoln Murr"
      ],
      "abstract": "In 2023, we are using the latest models of GPT-4 to advance program\nsynthesis. The large language models have significantly improved the\nstate-of-the-art for this purpose. To make these advancements more accessible,\nwe have created a repository that connects these models to Huamn Eval. This\ndataset was initally developed to be used with a language model called CODEGEN\non natural and programming language data. The utility of these trained models\nis showcased by demonstrating their competitive performance in zero-shot Python\ncode generation on HumanEval tasks compared to previous state-of-the-art\nsolutions. Additionally, this gives way to developing more multi-step paradigm\nsynthesis. This benchmark features 160 diverse problem sets factorized into\nmultistep prompts that our analysis shows significantly improves program\nsynthesis over single-turn inputs. All code is open source at\nhttps://github.com/daniel442li/gpt-human-eval .",
      "tldr_zh": "本研究评估了最新 GPT 模型（如 GPT-4）在程序合成（program synthesis）领域的表现，特别通过连接这些模型与 HumanEval 数据集来提升代码生成能力。研究创建了一个开源仓库，展示了这些模型在零样本（zero-shot）Python 代码生成任务上的竞争性能，与之前的最先进解决方案相比表现出色。HumanEval 数据集包含 160 个多样化问题集，通过多步提示（multistep prompts）显著改善了程序合成效果，所有代码可公开访问于 https://github.com/daniel442li/gpt-human-eval。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14852v1",
      "published_date": "2024-02-20 04:17:21 UTC",
      "updated_date": "2024-02-20 04:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:26:31.319818"
    },
    {
      "arxiv_id": "2402.12702v2",
      "title": "From Cloud to Edge: Rethinking Generative AI for Low-Resource Design Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Sai Krishna Revanth Vuruma",
        "Ashley Margetts",
        "Jianhai Su",
        "Faez Ahmed",
        "Biplav Srivastava"
      ],
      "abstract": "Generative Artificial Intelligence (AI) has shown tremendous prospects in all\naspects of technology, including design. However, due to its heavy demand on\nresources, it is usually trained on large computing infrastructure and often\nmade available as a cloud-based service. In this position paper, we consider\nthe potential, challenges, and promising approaches for generative AI for\ndesign on the edge, i.e., in resource-constrained settings where memory,\ncompute, energy (battery) and network connectivity may be limited. Adapting\ngenerative AI for such settings involves overcoming significant hurdles,\nprimarily in how to streamline complex models to function efficiently in\nlow-resource environments. This necessitates innovative approaches in model\ncompression, efficient algorithmic design, and perhaps even leveraging edge\ncomputing. The objective is to harness the power of generative AI in creating\nbespoke solutions for design problems, such as medical interventions, farm\nequipment maintenance, and educational material design, tailored to the unique\nconstraints and needs of remote areas. These efforts could democratize access\nto advanced technology and foster sustainable development, ensuring universal\naccessibility and environmental consideration of AI-driven design benefits.",
      "tldr_zh": "这篇论文探讨了生成式 AI 在设计领域的潜力，以及将其从云端迁移到边缘计算（edge computing）的必要性，以应对资源受限环境（如内存、计算、能源和网络连接的限制）。作者强调了适应这些挑战的关键方法，包括模型压缩（model compression）、高效算法设计和利用边缘计算技术，以简化复杂模型并提升效率。论文提出，通过这些创新方法，可以为偏远地区的设计问题（如医疗干预、农场设备维护和教育材料设计）提供定制化解决方案，从而实现技术民主化、促进可持续发展，并考虑环境因素。最终，这有助于确保生成式 AI 的益处更广泛可及。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for the Artificial Intelligence for Design Problems bridge\n  program at AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.12702v2",
      "published_date": "2024-02-20 03:59:27 UTC",
      "updated_date": "2024-02-26 00:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:26:43.286057"
    },
    {
      "arxiv_id": "2402.14851v2",
      "title": "$R^3$: \"This is My SQL, Are You With Me?\" A Consensus-Based Multi-Agent System for Text-to-SQL Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Hanchen Xia",
        "Feng Jiang",
        "Naihao Deng",
        "Cunxiang Wang",
        "Guojiang Zhao",
        "Rada Mihalcea",
        "Yue Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong performance on various\ntasks. To unleash their power on the Text-to-SQL task, we propose $R^3$\n(Review-Rebuttal-Revision), a consensus-based multi-agent system for\nText-to-SQL tasks. $R^3$ outperforms the existing single LLM Text-to-SQL\nsystems as well as the multi-agent Text-to-SQL systems by $1.3\\%$ to $8.1\\%$ on\nSpider and Bird. Surprisingly, we find that for Llama-3-8B, $R^3$ outperforms\nchain-of-thought prompting by over 20\\%, even outperforming GPT-3.5 on the\ndevelopment set of Spider.",
      "tldr_zh": "本研究提出 $R^3$ 系统，这是一个基于共识的 multi-agent 系统，用于处理 Text-to-SQL 任务，通过 Review-Rebuttal-Revision 过程来提升 Large Language Models (LLMs) 的性能。$R^3$ 显著优于现有单 LLM 和 multi-agent Text-to-SQL 系统，在 Spider 和 Bird 数据集上提升 1.3% 到 8.1%。令人惊讶的是，对于 Llama-3-8B 模型，$R^3$ 比 chain-of-thought prompting 高出超过 20%，甚至在 Spider 的开发集上超过了 GPT-3.5。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 2 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.14851v2",
      "published_date": "2024-02-20 03:57:55 UTC",
      "updated_date": "2024-07-11 03:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:26:56.028028"
    },
    {
      "arxiv_id": "2402.12685v1",
      "title": "XRL-Bench: A Benchmark for Evaluating and Comparing Explainable Reinforcement Learning Techniques",
      "title_zh": "XRL-Bench：用于评估和比较可解释强化学习技术的基准",
      "authors": [
        "Yu Xiong",
        "Zhipeng Hu",
        "Ye Huang",
        "Runze Wu",
        "Kai Guan",
        "Xingchen Fang",
        "Ji Jiang",
        "Tianze Zhou",
        "Yujing Hu",
        "Haoyu Liu",
        "Tangjie Lyu",
        "Changjie Fan"
      ],
      "abstract": "Reinforcement Learning (RL) has demonstrated substantial potential across\ndiverse fields, yet understanding its decision-making process, especially in\nreal-world scenarios where rationality and safety are paramount, is an ongoing\nchallenge. This paper delves in to Explainable RL (XRL), a subfield of\nExplainable AI (XAI) aimed at unravelling the complexities of RL models. Our\nfocus rests on state-explaining techniques, a crucial subset within XRL\nmethods, as they reveal the underlying factors influencing an agent's actions\nat any given time. Despite their significant role, the lack of a unified\nevaluation framework hinders assessment of their accuracy and effectiveness. To\naddress this, we introduce XRL-Bench, a unified standardized benchmark tailored\nfor the evaluation and comparison of XRL methods, encompassing three main\nmodules: standard RL environments, explainers based on state importance, and\nstandard evaluators. XRL-Bench supports both tabular and image data for state\nexplanation. We also propose TabularSHAP, an innovative and competitive XRL\nmethod. We demonstrate the practical utility of TabularSHAP in real-world\nonline gaming services and offer an open-source benchmark platform for the\nstraightforward implementation and evaluation of XRL methods. Our contributions\nfacilitate the continued progression of XRL technology.",
      "tldr_zh": "这篇论文介绍了XRL-Bench，一个用于评估和比较Explainable Reinforcement Learning (XRL)技术的标准化基准，以解决强化学习 (RL) 决策过程的复杂性和安全性挑战。XRL-Bench包括三个主要模块：标准RL环境、基于状态重要性的解释器，以及标准评估器，支持表格和图像数据进行状态解释。论文还提出了一种创新方法TabularSHAP，并展示了其在真实世界在线游戏服务中的实用性，最终提供开源平台以促进XRL技术的进一步发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.12685v1",
      "published_date": "2024-02-20 03:20:37 UTC",
      "updated_date": "2024-02-20 03:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:27:08.554378"
    },
    {
      "arxiv_id": "2402.14029v3",
      "title": "Partially Frozen Random Networks Contain Compact Strong Lottery Tickets",
      "title_zh": "翻译失败",
      "authors": [
        "Hikari Otsuka",
        "Daiki Chijiwa",
        "Ángel López García-Arias",
        "Yasuyuki Okoshi",
        "Kazushi Kawamura",
        "Thiem Van Chu",
        "Daichi Fujiki",
        "Susumu Takeuchi",
        "Masato Motomura"
      ],
      "abstract": "Randomly initialized dense networks contain subnetworks that achieve high\naccuracy without weight learning--strong lottery tickets (SLTs). Recently,\nGadhikar et al. (2023) demonstrated that SLTs could also be found within a\nrandomly pruned source network. This phenomenon can be exploited to further\ncompress the small memory size required by SLTs. However, their method is\nlimited to SLTs that are even sparser than the source, leading to worse\naccuracy due to unintentionally high sparsity. This paper proposes a method for\nreducing the SLT memory size without restricting the sparsity of the SLTs that\ncan be found. A random subset of the initial weights is frozen by either\npermanently pruning them or locking them as a fixed part of the SLT, resulting\nin a smaller model size. Experimental results show that Edge-Popup (Ramanujan\net al., 2020; Sreenivasan et al., 2022) finds SLTs with better\naccuracy-to-model size trade-off within frozen networks than within dense or\nrandomly pruned source networks. In particular, freezing $70\\%$ of a ResNet on\nImageNet provides $3.3 \\times$ compression compared to the SLT found within a\ndense counterpart, raises accuracy by up to $14.12$ points compared to the SLT\nfound within a randomly pruned counterpart, and offers a better accuracy-model\nsize trade-off than both.",
      "tldr_zh": "本文提出了一种方法，通过部分冻结随机网络的初始权重（例如永久修剪或锁定），来发现更紧凑的Strong Lottery Tickets (SLTs)，从而减小模型大小而不限制SLTs的稀疏度。相比以往方法，该技术避免了高稀疏度导致的准确率下降，并使用Edge-Popup算法在冻结网络中寻找SLTs。实验结果显示，在ImageNet数据集上冻结70%的ResNet权重，能实现3.3倍压缩，比密集网络中的SLTs提高准确率14.12点，并提供更好的准确率-模型大小权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at TMLR",
      "pdf_url": "http://arxiv.org/pdf/2402.14029v3",
      "published_date": "2024-02-20 03:14:45 UTC",
      "updated_date": "2025-02-08 05:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:27:21.857754"
    },
    {
      "arxiv_id": "2402.12659v2",
      "title": "FinBen: A Holistic Financial Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qianqian Xie",
        "Weiguang Han",
        "Zhengyu Chen",
        "Ruoyu Xiang",
        "Xiao Zhang",
        "Yueru He",
        "Mengxi Xiao",
        "Dong Li",
        "Yongfu Dai",
        "Duanyu Feng",
        "Yijing Xu",
        "Haoqiang Kang",
        "Ziyan Kuang",
        "Chenhan Yuan",
        "Kailai Yang",
        "Zheheng Luo",
        "Tianlin Zhang",
        "Zhiwei Liu",
        "Guojun Xiong",
        "Zhiyang Deng",
        "Yuechen Jiang",
        "Zhiyuan Yao",
        "Haohang Li",
        "Yangyang Yu",
        "Gang Hu",
        "Jiajia Huang",
        "Xiao-Yang Liu",
        "Alejandro Lopez-Lira",
        "Benyou Wang",
        "Yanzhao Lai",
        "Hao Wang",
        "Min Peng",
        "Sophia Ananiadou",
        "Jimin Huang"
      ],
      "abstract": "LLMs have transformed NLP and shown promise in various fields, yet their\npotential in finance is underexplored due to a lack of comprehensive evaluation\nbenchmarks, the rapid development of LLMs, and the complexity of financial\ntasks. In this paper, we introduce FinBen, the first extensive open-source\nevaluation benchmark, including 36 datasets spanning 24 financial tasks,\ncovering seven critical aspects: information extraction (IE), textual analysis,\nquestion answering (QA), text generation, risk management, forecasting, and\ndecision-making. FinBen offers several key innovations: a broader range of\ntasks and datasets, the first evaluation of stock trading, novel agent and\nRetrieval-Augmented Generation (RAG) evaluation, and three novel open-source\nevaluation datasets for text summarization, question answering, and stock\ntrading. Our evaluation of 15 representative LLMs, including GPT-4, ChatGPT,\nand the latest Gemini, reveals several key findings: While LLMs excel in IE and\ntextual analysis, they struggle with advanced reasoning and complex tasks like\ntext generation and forecasting. GPT-4 excels in IE and stock trading, while\nGemini is better at text generation and forecasting. Instruction-tuned LLMs\nimprove textual analysis but offer limited benefits for complex tasks such as\nQA. FinBen has been used to host the first financial LLMs shared task at the\nFinNLP-AgentScen workshop during IJCAI-2024, attracting 12 teams. Their novel\nsolutions outperformed GPT-4, showcasing FinBen's potential to drive innovation\nin financial LLMs. All datasets, results, and codes are released for the\nresearch community: https://github.com/The-FinAI/PIXIU.",
      "tldr_zh": "这篇论文引入了FinBen，一个全面的开源基准，用于评估大型语言模型(LLMs)在金融领域的性能，包括36个数据集和24个金融任务，覆盖信息提取(IE)、文本分析、问答(QA)、文本生成、风险管理、预测和决策等七个关键方面。FinBen的创新包括更广泛的任务范围、首次评估股票交易、引入代理和Retrieval-Augmented Generation (RAG)评估，以及三个新开源数据集。评估15个代表性LLMs（如GPT-4、ChatGPT和Gemini）后，发现LLMs在IE和文本分析上表现出色，但处理高级推理和复杂任务（如文本生成和预测）时存在挑战，GPT-4在IE和股票交易上领先，而Gemini在文本生成和预测上更强。FinBen已用于IJCAI-2024研讨会，吸引12个团队的创新解决方案超越了GPT-4，推动了金融LLMs的研究发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.12659v2",
      "published_date": "2024-02-20 02:16:16 UTC",
      "updated_date": "2024-06-19 03:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:27:34.669594"
    },
    {
      "arxiv_id": "2402.12656v4",
      "title": "HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Zhao",
        "Zihan Qiu",
        "Huijia Wu",
        "Zili Wang",
        "Zhaofeng He",
        "Jie Fu"
      ],
      "abstract": "The Mixture of Experts (MoE) for language models has been proven effective in\naugmenting the capacity of models by dynamically routing each input token to a\nspecific subset of experts for processing. Despite the success, most existing\nmethods face a challenge for balance between sparsity and the availability of\nexpert knowledge: enhancing performance through increased use of expert\nknowledge often results in diminishing sparsity during expert selection. To\nmitigate this contradiction, we propose HyperMoE, a novel MoE framework built\nupon Hypernetworks. This framework integrates the computational processes of\nMoE with the concept of knowledge transferring in multi-task learning. Specific\nmodules generated based on the information of unselected experts serve as\nsupplementary information, which allows the knowledge of experts not selected\nto be used while maintaining selection sparsity. Our comprehensive empirical\nevaluations across multiple datasets and backbones establish that HyperMoE\nsignificantly outperforms existing MoE methods under identical conditions\nconcerning the number of experts.",
      "tldr_zh": "该论文针对 Mixture of Experts (MoE) 模型在增强专家知识利用时面临的稀疏性下降问题，提出了一种新型框架 HyperMoE。HyperMoE 通过整合 Hypernetworks 和多任务学习的知识转移机制，基于未选专家的信息生成补充模块，从而在保持专家选择稀疏性的同时，利用未选专家的知识。实验结果显示，在多个数据集和骨干模型上，HyperMoE 在相同专家数量条件下显著优于现有 MoE 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12656v4",
      "published_date": "2024-02-20 02:09:55 UTC",
      "updated_date": "2024-07-25 06:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:27:45.858699"
    },
    {
      "arxiv_id": "2402.14850v2",
      "title": "CHATATC: Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management",
      "title_zh": "翻译失败",
      "authors": [
        "Sinan Abdulhak",
        "Wayne Hubbard",
        "Karthik Gopalakrishnan",
        "Max Z. Li"
      ],
      "abstract": "Generative artificial intelligence (AI) and large language models (LLMs) have\ngained rapid popularity through publicly available tools such as ChatGPT. The\nadoption of LLMs for personal and professional use is fueled by the natural\ninteractions between human users and computer applications such as ChatGPT,\nalong with powerful summarization and text generation capabilities. Given the\nwidespread use of such generative AI tools, in this work we investigate how\nthese tools can be deployed in a non-safety critical, strategic traffic flow\nmanagement setting. Specifically, we train an LLM, CHATATC, based on a large\nhistorical data set of Ground Delay Program (GDP) issuances, spanning 2000-2023\nand consisting of over 80,000 GDP implementations, revisions, and\ncancellations. We test the query and response capabilities of CHATATC,\ndocumenting successes (e.g., providing correct GDP rates, durations, and\nreason) and shortcomings (e.g,. superlative questions). We also detail the\ndesign of a graphical user interface for future users to interact and\ncollaborate with the CHATATC conversational agent.",
      "tldr_zh": "该研究开发了 CHATATC，一种基于 Large Language Models (LLMs) 的对话代理，用于支持非安全关键的战略航空交通流量管理，特别是处理 Ground Delay Program (GDP) 的查询和响应。研究团队使用 2000-2023 年的历史数据集（超过 80,000 条 GDP 实施、修订和取消记录）训练模型，测试结果显示 CHATATC 能准确提供 GDP 速率、持续时间和原因，但对极端查询（如 superlative questions）存在不足。最终，他们设计了图形用户界面，以便用户与该对话代理进行交互和协作，为航空流量管理提供潜在工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures; minor revisions to address reviewer feedback for\n  final submission to the 11th International Conference on Research in Air\n  Transportation (ICRAT)",
      "pdf_url": "http://arxiv.org/pdf/2402.14850v2",
      "published_date": "2024-02-20 01:59:11 UTC",
      "updated_date": "2024-07-24 02:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:27:57.574740"
    },
    {
      "arxiv_id": "2402.12646v1",
      "title": "Training Artificial Neural Networks by Coordinate Search Algorithm",
      "title_zh": "通过坐标搜索算法训练人工神经网络",
      "authors": [
        "Ehsan Rokhsatyazdi",
        "Shahryar Rahnamayan",
        "Sevil Zanjani Miyandoab",
        "Azam Asilian Bidgoli",
        "H. R. Tizhoosh"
      ],
      "abstract": "Training Artificial Neural Networks poses a challenging and critical problem\nin machine learning. Despite the effectiveness of gradient-based learning\nmethods, such as Stochastic Gradient Descent (SGD), in training neural\nnetworks, they do have several limitations. For instance, they require\ndifferentiable activation functions, and cannot optimize a model based on\nseveral independent non-differentiable loss functions simultaneously; for\nexample, the F1-score, which is used during testing, can be used during\ntraining when a gradient-free optimization algorithm is utilized. Furthermore,\nthe training in any DNN can be possible with a small size of the training\ndataset. To address these concerns, we propose an efficient version of the\ngradient-free Coordinate Search (CS) algorithm, an instance of General Pattern\nSearch methods, for training neural networks. The proposed algorithm can be\nused with non-differentiable activation functions and tailored to\nmulti-objective/multi-loss problems. Finding the optimal values for weights of\nANNs is a large-scale optimization problem. Therefore instead of finding the\noptimal value for each variable, which is the common technique in classical CS,\nwe accelerate optimization and convergence by bundling the weights. In fact,\nthis strategy is a form of dimension reduction for optimization problems. Based\non the experimental results, the proposed method, in some cases, outperforms\nthe gradient-based approach, particularly, in situations with insufficient\nlabeled training data. The performance plots demonstrate a high convergence\nrate, highlighting the capability of our suggested method to find a reasonable\nsolution with fewer function calls. As of now, the only practical and efficient\nway of training ANNs with hundreds of thousands of weights is gradient-based\nalgorithms such as SGD or Adam. In this paper we introduce an alternative\nmethod for training ANN.",
      "tldr_zh": "这篇论文针对训练人工神经网络 (ANNs) 的挑战，提出了一种基于 Coordinate Search (CS) 算法的梯度自由优化方法，以解决 Stochastic Gradient Descent (SGD) 等方法的局限性，如需可微激活函数和无法同时优化多个非可微损失函数 (如 F1-score)。该方法通过权重捆绑 (bundling the weights) 实现维度减少，加速优化过程，并适用于多目标问题。实验结果表明，在数据集较小的情况下，该算法在某些场景下优于梯度方法，具有更高的收敛率，并为 ANN 训练提供了一种高效替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.12646v1",
      "published_date": "2024-02-20 01:47:25 UTC",
      "updated_date": "2024-02-20 01:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:28:09.923161"
    },
    {
      "arxiv_id": "2402.12627v1",
      "title": "A Comprehensive Review of Machine Learning Advances on Data Change: A Cross-Field Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Jeng-Lin Li",
        "Chih-Fan Hsu",
        "Ming-Ching Chang",
        "Wei-Chao Chen"
      ],
      "abstract": "Recent artificial intelligence (AI) technologies show remarkable evolution in\nvarious academic fields and industries. However, in the real world, dynamic\ndata lead to principal challenges for deploying AI models. An unexpected data\nchange brings about severe performance degradation in AI models. We identify\ntwo major related research fields, domain shift and concept drift according to\nthe setting of the data change. Although these two popular research fields aim\nto solve distribution shift and non-stationary data stream problems, the\nunderlying properties remain similar which also encourages similar technical\napproaches. In this review, we regroup domain shift and concept drift into a\nsingle research problem, namely the data change problem, with a systematic\noverview of state-of-the-art methods in the two research fields. We propose a\nthree-phase problem categorization scheme to link the key ideas in the two\ntechnical fields. We thus provide a novel scope for researchers to explore\ncontemporary technical strategies, learn industrial applications, and identify\nfuture directions for addressing data change challenges.",
      "tldr_zh": "这篇综述论文审视了机器学习在面对数据变化（data change）时的进展，从跨领域视角出发，探讨了动态数据导致AI模型性能下降的问题，如domain shift和concept drift。作者将这些问题整合为一个统一的“data change problem”，并提出一个三阶段问题分类方案（three-phase problem categorization scheme），以系统概述两个领域的state-of-the-art方法。最终，该论文为研究者提供当代技术策略、工业应用案例，并指明未来应对数据变化挑战的方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12627v1",
      "published_date": "2024-02-20 01:16:01 UTC",
      "updated_date": "2024-02-20 01:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:28:20.396953"
    },
    {
      "arxiv_id": "2402.12624v1",
      "title": "Efficient Parameter Mining and Freezing for Continual Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Angelo G. Menezes",
        "Augusto J. Peterlevitz",
        "Mateus A. Chinelatto",
        "André C. P. L. F. de Carvalho"
      ],
      "abstract": "Continual Object Detection is essential for enabling intelligent agents to\ninteract proactively with humans in real-world settings. While\nparameter-isolation strategies have been extensively explored in the context of\ncontinual learning for classification, they have yet to be fully harnessed for\nincremental object detection scenarios. Drawing inspiration from prior research\nthat focused on mining individual neuron responses and integrating insights\nfrom recent developments in neural pruning, we proposed efficient ways to\nidentify which layers are the most important for a network to maintain the\nperformance of a detector across sequential updates. The presented findings\nhighlight the substantial advantages of layer-level parameter isolation in\nfacilitating incremental learning within object detection models, offering\npromising avenues for future research and application in real-world scenarios.",
      "tldr_zh": "该论文针对 Continual Object Detection 的挑战，提出了一种高效的参数挖掘和冻结策略，以支持智能代理在真实世界中的增量学习。方法借鉴神经元响应分析和 neural pruning 的见解，识别网络中最重要的层，从而维护检测器的性能。实验结果显示，层级 parameter isolation 显著提升了对象检测模型的更新效率，并为未来实际应用提供了有前景的路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "In Proceedings of the 19th International Joint Conference on Computer\n  Vision, Imaging and Computer Graphics Theory and Applications - Volume 2:\n  VISAPP, ISBN 978-989-758-679-8, ISSN 2184-4321, pages 466-474",
      "pdf_url": "http://arxiv.org/pdf/2402.12624v1",
      "published_date": "2024-02-20 01:07:32 UTC",
      "updated_date": "2024-02-20 01:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:28:31.996178"
    },
    {
      "arxiv_id": "2402.12617v2",
      "title": "Generative AI Security: Challenges and Countermeasures",
      "title_zh": "翻译失败",
      "authors": [
        "Banghua Zhu",
        "Norman Mu",
        "Jiantao Jiao",
        "David Wagner"
      ],
      "abstract": "Generative AI's expanding footprint across numerous industries has led to\nboth excitement and increased scrutiny. This paper delves into the unique\nsecurity challenges posed by Generative AI, and outlines potential research\ndirections for managing these risks.",
      "tldr_zh": "本论文探讨了 Generative AI 在各行业的广泛应用所带来的独特安全挑战，包括兴奋与审查的双重影响。作者深入分析了这些风险，并概述了潜在的研究方向，以管理 Generative AI 的安全问题。通过此研究，旨在为未来开发更可靠的 Generative AI 系统提供指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12617v2",
      "published_date": "2024-02-20 00:51:05 UTC",
      "updated_date": "2024-10-23 06:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:28:43.406140"
    },
    {
      "arxiv_id": "2402.12608v1",
      "title": "Patient-Centric Knowledge Graphs: A Survey of Current Methods, Challenges, and Applications",
      "title_zh": "以患者为中心的知识图谱：当前方法、挑战和应用的综述",
      "authors": [
        "Hassan S. Al Khatib",
        "Subash Neupane",
        "Harish Kumar Manchukonda",
        "Noorbakhsh Amiri Golilarz",
        "Sudip Mittal",
        "Amin Amirlatifi",
        "Shahram Rahimi"
      ],
      "abstract": "Patient-Centric Knowledge Graphs (PCKGs) represent an important shift in\nhealthcare that focuses on individualized patient care by mapping the patient's\nhealth information in a holistic and multi-dimensional way. PCKGs integrate\nvarious types of health data to provide healthcare professionals with a\ncomprehensive understanding of a patient's health, enabling more personalized\nand effective care. This literature review explores the methodologies,\nchallenges, and opportunities associated with PCKGs, focusing on their role in\nintegrating disparate healthcare data and enhancing patient care through a\nunified health perspective. In addition, this review also discusses the\ncomplexities of PCKG development, including ontology design, data integration\ntechniques, knowledge extraction, and structured representation of knowledge.\nIt highlights advanced techniques such as reasoning, semantic search, and\ninference mechanisms essential in constructing and evaluating PCKGs for\nactionable healthcare insights. We further explore the practical applications\nof PCKGs in personalized medicine, emphasizing their significance in improving\ndisease prediction and formulating effective treatment plans. Overall, this\nreview provides a foundational perspective on the current state-of-the-art and\nbest practices of PCKGs, guiding future research and applications in this\ndynamic field.",
      "tldr_zh": "本综述探讨了Patient-Centric Knowledge Graphs (PCKGs)，一种以患者为中心的知识图谱方法，通过整合多维健康数据，提供全面的患者健康洞察，从而提升个性化医疗护理。论文审查了PCKGs的构建方法，包括ontology design、data integration techniques、knowledge extraction和结构化知识表示，同时强调了高级技术如reasoning、semantic search和inference mechanisms在处理数据整合挑战中的作用。研究突出了PCKGs在个性化医学中的实际应用，如改善疾病预测和治疗计划，并为未来研究提供了当前最佳实践和指导方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12608v1",
      "published_date": "2024-02-20 00:07:55 UTC",
      "updated_date": "2024-02-20 00:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:28:56.890660"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 119,
  "processed_papers_count": 119,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T08:29:14.842739"
}