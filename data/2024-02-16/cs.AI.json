{
  "date": "2024-02-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-16 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和大型语言模型 (LLM) 的优化、偏见检测、知识编辑和应用扩展等领域，其中令人印象深刻的包括 Orca-Math 在小语言模型数学推理上的突破，以及 LLM 安全和推理加速的相关研究，而有名的学者如那些参与 LLM 研究的团队则强调了模型的鲁棒性和公平性。\n\n下面，我将逐一简要概述今天的论文，先优先讨论 AI 和 LLM 领域的关键文章（如优化、偏见和安全），然后快速掠过其他领域的次要论文。重点突出主要贡献和发现，保留核心学术术语。\n\n**1. Orca-Math: Unlocking the potential of SLMs in Grade School Math**  \n这篇论文介绍了 Orca-Math，一款基于 Mistral-7B 的 7 亿参数小语言模型 (SLM)，在 GSM8K 基准上实现了 86.81% 的准确率，无需多轮模型调用或外部工具。主要贡献是通过高质量合成数据集和迭代偏好学习提升 SLM 在数学词问题上的性能，超越了更大模型如 LLaMA-2-70B。\n\n**2. Speculative Streaming: Fast LLM Inference without Auxiliary Models**  \n论文提出 Speculative Streaming，一种单模型推测解码方法，通过将细调目标从下一个标记预测改为未来 n-gram 预测，加速 LLM 推理。主要发现：在总结、结构化查询和语义表示任务中，实现 1.8-3.1 倍速度提升，同时参数效率高，远超 Medusa 风格架构。\n\n**3. Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models**  \n研究探索 LLM 中的社会经济偏见，使用新数据集 SilverSpoon 评估模型对弱势群体行为的共情能力。主要贡献：揭示 LLM 无法有效共情弱势群体，且模型大小影响偏见程度，提供公开数据集促进进一步研究。\n\n**11. The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects**  \n这篇论文评估文本到图像 (T2I) 模型中的性别偏见，提出 Paired Stereotype Test 框架和 FairCritic 方法。主要发现：DALLE-3 在双主体生成中存在显著偏见，FairCritic 通过检测和反馈机制有效缓解偏见。\n\n**15. Large Language Models for Causal Discovery: Current Landscape and Future Directions**  \n论文综述 LLM 在因果发现中的应用，包括从文本提取因果关系和整合领域知识。主要贡献：提出评估框架和基准，强调 LLM 在因果结构提炼中的潜力，但需解决局限性。\n\n**19. RLVF: Learning from Verbal Feedback without Overgeneralization**  \n研究 LLM 从高级语言反馈中学习，提出 C3PO 框架避免过度泛化。主要发现：通过合成偏好数据和最小化差异优化，LLM 能更好地应用反馈，提升生成质量。\n\n**24. Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models**  \n论文解决多模态 LLM 在视觉指令微调中的退化问题，使用 DPO 和偏好数据集。主要贡献：通过细粒度标注提升 LLM 的指令跟随能力，在 MM-Vet 和 LLaVA-Bench 上性能提升。\n\n**5. Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models**  \n评估 LLM 的记忆编辑 (ME) 方法，聚焦参数修改和保留策略。主要发现：参数保留 ME 更稳定，但参数修改 ME 易导致性能下降，并提出缓解策略。\n\n**13. Model Editing by Standard Fine-Tuning**  \n论文改进标准微调用于模型编辑，提出优化条件似然和训练数据策略。主要贡献：在 ZsRE 和 CounterFact 数据集上，与专业编辑方法相当，提升泛化性。\n\n**14. AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators**  \n引入 AFaCTA 框架，使用 LLM 辅助事实声明检测标注。主要发现：通过一致性校准提升标注质量，并构建 PoliClaim 数据集，支持事实性分类。\n\n**16. Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement**  \n提出 Persona-DB 框架，通过分层构建和协作精炼提升 LLM 个性化响应预测。主要贡献：在冷启动场景下性能提升 10%，并实现高效检索。\n\n**21. When is Tree Search Useful for LLM Planning? It Depends on the Discriminator**  \n探索 LLM 在规划任务中的树搜索效用，强调鉴别器准确性影响。主要发现：树搜索需 90% 以上鉴别器准确率才能显著提升性能。\n\n**25. Robust agents learn causal world models**  \n论文证明鲁棒代理需学习因果世界模型以泛化分布偏移。主要贡献：通过遗憾界分析，展示代理收敛于真实因果模型。\n\n**4. Optimizing Warfarin Dosing Using Contextual Bandit: An Offline Policy Learning and Evaluation Method**  \n使用上下文 Bandit 优化华法林剂量，通过离线策略学习。主要发现：新策略在观察数据上超越基线，无需基因输入。\n\n**9. Computing Voting Rules with Elicited Incomplete Votes**  \n研究不完整投票规则计算，证明某些规则（如多数投票）不可计算。主要贡献：提供查询复杂性界限，提升投票系统效率。\n\n**10. Regulating Large Language Models: A Roundtable Report**  \n报告 LLM 监管讨论，聚焦真实性、隐私和市场集中问题。主要发现：提出法律干预策略，缓解 LLM 风险。\n\n**20. Instruction Diversity Drives Generalization To Unseen Tasks**  \n论文显示指令多样性提升 LLM 对未见任务的泛化能力。主要贡献：通过模拟任务实验，证明多样指令优于大量样本。\n\n**23. 3D Diffuser Actor: Policy Diffusion with 3D Scene Representations**  \n提出 3D Diffuser Actor，使用 3D 场景表示强化学习策略。主要发现：在 RLBench 和 CALVIN 上实现最先进性能，提升机器人操作。\n\n**27. Neuron-centric Hebbian Learning**  \n引入 Neuron-centric Hebbian Learning (NcHL) 模型，优化神经网络可塑性。主要贡献：减少参数，提升神经元级 Hebbian 学习效率。\n\n**28. FedD2S: Personalized Data-Free Federated Knowledge Distillation**  \nFedD2S 通过知识蒸馏实现联邦学习个性化，无需数据共享。主要发现：在图像数据集上提升公平性和收敛速度。\n\n其他论文如天文、医学和金融领域的（如第6、12、17、18、22、26、29、30、31、32、33、34、35、36、37、38、39、40、41、42、43、44、45、46、47、48、49、50、51、52、53、54、55、56、57、58、59、60、61、62、63、64、65、66、67、68、69、70、71、72、73、74、75、76、77、78、79、80、81、82、83、84、85、86、87、88、89、90、91、92、93、94、95、96、97、98、99、100、101、102、103、104、105、106、107、108、109、110、111、112、113、114、115、116）涉及主题较分散，且部分较为专业或初步，我这里快速掠过：这些论文探讨了从 GAN 在天文模拟、医疗诊断、金融预测，到图神经网络和强化学习的各种应用，但多数未有突破性发现，仅在特定领域（如医学的生物标记优化、金融的 LLM 偏见检测）提供细化方法，读者可根据兴趣深入。\n\n总之，今天的 arXiv 论文突显了 LLM 在优化和安全方面的进展，强调了 AI 模型的鲁棒性和公平性，为实际应用提供了新思路。更多细节请查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2402.14830v1",
      "title": "Orca-Math: Unlocking the potential of SLMs in Grade School Math",
      "title_zh": "Orca-Math：解锁 SLMs 在小学数学中的潜力",
      "authors": [
        "Arindam Mitra",
        "Hamed Khanpour",
        "Corby Rosset",
        "Ahmed Awadallah"
      ],
      "abstract": "Mathematical word problem-solving has long been recognized as a complex task\nfor small language models (SLMs). A recent study hypothesized that the smallest\nmodel size, needed to achieve over 80% accuracy on the GSM8K benchmark, is 34\nbillion parameters. To reach this level of performance with smaller models,\nresearcher often train SLMs to generate Python code or use tools to help avoid\ncalculation errors. Additionally, they employ ensembling, where outputs of up\nto 100 model runs are combined to arrive at a more accurate result. Result\nselection is done using consensus, majority vote or a separate a verifier model\nused in conjunction with the SLM. Ensembling provides a substantial boost in\naccuracy but at a significant cost increase with multiple calls to the model\n(e.g., Phi-GSM uses top-48 to boost the performance from 68.2 to 81.5).\n  In this work, we present Orca-Math, a 7-billion-parameter SLM based on the\nMistral-7B, which achieves 86.81% on GSM8k without the need for multiple model\ncalls or the use of verifiers, code execution or any other external tools. Our\napproach has the following key elements: (1) A high quality synthetic dataset\nof 200K math problems created using a multi-agent setup where agents\ncollaborate to create the data, (2) An iterative learning techniques that\nenables the SLM to practice solving problems, receive feedback on its solutions\nand learn from preference pairs incorporating the SLM solutions and the\nfeedback. When trained with Supervised Fine-Tuning alone, Orca-Math achieves\n81.50% on GSM8k pass@1 metric. With iterative preference learning, Orca-Math\nachieves 86.81% pass@1. Orca-Math surpasses the performance of significantly\nlarger models such as LLAMA-2-70B, WizardMath-70B, Gemini-Pro, ChatGPT-3.5. It\nalso significantly outperforms other smaller models while using much smaller\ndata (hundreds of thousands vs. millions of problems).",
      "tldr_zh": "该研究探讨了小语言模型（SLMs）在小学数学问题解决中的潜力，针对传统方法（如生成Python代码或集成ensembling）的成本问题，提出Orca-Math模型——一个基于Mistral-7B的7亿参数SLM。Orca-Math利用高质量的200K合成数据集（通过多智能体协作创建）和迭代学习技术（包括问题练习、反馈接收及从preference pairs中学习），在GSM8K基准上实现86.81%的pass@1准确率，而无需多次模型调用或外部工具。相比之下，仅用Supervised Fine-Tuning，Orca-Math即可达到81.50%的性能，并超越更大模型如LLAMA-2-70B，同时使用更少的数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14830v1",
      "published_date": "2024-02-16 23:44:38 UTC",
      "updated_date": "2024-02-16 23:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:52:06.702950"
    },
    {
      "arxiv_id": "2402.11131v1",
      "title": "Speculative Streaming: Fast LLM Inference without Auxiliary Models",
      "title_zh": "Speculative Streaming",
      "authors": [
        "Nikhil Bhendawade",
        "Irina Belousova",
        "Qichen Fu",
        "Henry Mason",
        "Mohammad Rastegari",
        "Mahyar Najibi"
      ],
      "abstract": "Speculative decoding is a prominent technique to speed up the inference of a\nlarge target language model based on predictions of an auxiliary draft model.\nWhile effective, in application-specific settings, it often involves\nfine-tuning both draft and target models to achieve high acceptance rates. As\nthe number of downstream tasks grows, these draft models add significant\ncomplexity to inference systems. We propose Speculative Streaming, a\nsingle-model speculative decoding method that fuses drafting into the target\nmodel by changing the fine-tuning objective from next token prediction to\nfuture n-gram prediction. Speculative Streaming speeds up decoding by 1.8 -\n3.1X in a diverse set of tasks, such as Summarization, Structured Queries, and\nMeaning Representation, without sacrificing generation quality. Additionally,\nSpeculative Streaming is parameter-efficient. It achieves on-par/higher\nspeed-ups than Medusa-style architectures while using ~10000X fewer extra\nparameters, making it well-suited for resource-constrained devices.",
      "tldr_zh": "论文提出Speculative Streaming，一种无需辅助模型的单模型推测解码方法，通过将微调目标从next token prediction改为future n-gram prediction，将草稿生成融入目标模型中，从而加速LLM推理。实验结果显示，该方法在Summarization、Structured Queries和Meaning Representation等任务上实现了1.8-3.1倍的解码速度提升，同时不牺牲生成质量。相比Medusa-style architectures，Speculative Streaming参数高效，仅使用约10000倍更少的额外参数，特别适合资源受限设备。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11131v1",
      "published_date": "2024-02-16 23:36:43 UTC",
      "updated_date": "2024-02-16 23:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:52:18.112828"
    },
    {
      "arxiv_id": "2403.14633v4",
      "title": "Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Smriti Singh",
        "Shuvam Keshari",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "abstract": "Socioeconomic bias in society exacerbates disparities, influencing access to\nopportunities and resources based on individuals' economic and social\nbackgrounds. This pervasive issue perpetuates systemic inequalities, hindering\nthe pursuit of inclusive progress as a society. In this paper, we investigate\nthe presence of socioeconomic bias, if any, in large language models. To this\nend, we introduce a novel dataset SilverSpoon, consisting of 3000 samples that\nillustrate hypothetical scenarios that involve underprivileged people\nperforming ethically ambiguous actions due to their circumstances, and ask\nwhether the action is ethically justified. Further, this dataset has a\ndual-labeling scheme and has been annotated by people belonging to both ends of\nthe socioeconomic spectrum. Using SilverSpoon, we evaluate the degree of\nsocioeconomic bias expressed in large language models and the variation of this\ndegree as a function of model size. We also perform qualitative analysis to\nanalyze the nature of this bias. Our analysis reveals that while humans\ndisagree on which situations require empathy toward the underprivileged, most\nlarge language models are unable to empathize with the socioeconomically\nunderprivileged regardless of the situation. To foster further research in this\ndomain, we make SilverSpoon and our evaluation harness publicly available.",
      "tldr_zh": "这篇论文调查了大型语言模型（Large Language Models）中的社会经济偏见（socioeconomic bias），探讨其如何加剧社会不平等。研究者引入了新数据集SilverSpoon，包含3000个样本，这些样本描述了弱势群体因环境因素进行道德模糊行为的场景，并采用双重标签方案由不同社会经济背景的人进行标注。实验结果显示，大多数大型语言模型无法对社会经济弱势群体产生共情，而人类在类似情境下存在分歧，且这种偏见程度随模型大小而变化。为促进进一步研究，论文公开了SilverSpoon数据集和评估工具。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14633v4",
      "published_date": "2024-02-16 23:18:19 UTC",
      "updated_date": "2024-12-19 22:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:52:30.420814"
    },
    {
      "arxiv_id": "2402.11123v1",
      "title": "Optimizing Warfarin Dosing Using Contextual Bandit: An Offline Policy Learning and Evaluation Method",
      "title_zh": "使用上下文 Bandit 优化",
      "authors": [
        "Yong Huang",
        "Charles A. Downs",
        "Amir M. Rahmani"
      ],
      "abstract": "Warfarin, an anticoagulant medication, is formulated to prevent and address\nconditions associated with abnormal blood clotting, making it one of the most\nprescribed drugs globally. However, determining the suitable dosage remains\nchallenging due to individual response variations, and prescribing an incorrect\ndosage may lead to severe consequences. Contextual bandit and reinforcement\nlearning have shown promise in addressing this issue. Given the wide\navailability of observational data and safety concerns of decision-making in\nhealthcare, we focused on using exclusively observational data from historical\npolicies as demonstrations to derive new policies; we utilized offline policy\nlearning and evaluation in a contextual bandit setting to establish the optimal\npersonalized dosage strategy. Our learned policies surpassed these baseline\napproaches without genotype inputs, even when given a suboptimal demonstration,\nshowcasing promising application potential.",
      "tldr_zh": "本研究针对Warfarin（一种常用抗凝血药物）的剂量优化问题，提出了一种基于Contextual Bandit的离线策略学习和评估方法，以应对个体反应差异带来的挑战。方法利用历史观察数据作为演示，开发出新的个性化剂量策略，而无需依赖基因型输入。实验结果表明，该策略即使在次优演示条件下，也超过了基线方法，展示了在医疗决策中的显著应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11123v1",
      "published_date": "2024-02-16 23:13:05 UTC",
      "updated_date": "2024-02-16 23:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:52:42.348905"
    },
    {
      "arxiv_id": "2402.11122v1",
      "title": "Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models",
      "title_zh": "导航双重方面：大型语言模型中顺序记忆编辑的全面评估",
      "authors": [
        "Zihao Lin",
        "Mohammad Beigi",
        "Hongxuan Li",
        "Yufan Zhou",
        "Yuxiang Zhang",
        "Qifan Wang",
        "Wenpeng Yin",
        "Lifu Huang"
      ],
      "abstract": "Memory Editing (ME) has emerged as an efficient method to modify erroneous\nfacts or inject new facts into Large Language Models (LLMs). Two mainstream ME\nmethods exist: parameter-modifying ME and parameter-preserving ME (integrating\nextra modules while preserving original parameters). Regrettably, previous\nstudies on ME evaluation have two critical limitations: (i) evaluating LLMs\nwith single edit only, neglecting the need for continuous editing, and (ii)\nevaluations focusing solely on basic factual triples, overlooking broader LLM\ncapabilities like logical reasoning and reading understanding. This study\naddresses these limitations with contributions threefold: (i) We explore how ME\naffects a wide range of fundamental capabilities of LLMs under sequential\nediting. Experimental results reveal an intriguing phenomenon: Most\nparameter-modifying ME consistently degrade performance across all tasks after\na few sequential edits. In contrast, parameter-preserving ME effectively\nmaintains LLMs' fundamental capabilities but struggles to accurately recall\nedited knowledge presented in a different format. (ii) We extend our evaluation\nto different editing settings, such as layers to edit, model size, instruction\ntuning, etc. Experimental findings indicate several strategies that can\npotentially mitigate the adverse effects of ME. (iii) We further explain why\nparameter-modifying ME damages LLMs from three dimensions: parameter changes\nafter editing, language modeling capability, and the in-context learning\ncapability. Our in-depth study advocates more careful use of ME in real-world\nscenarios.",
      "tldr_zh": "本研究对大型语言模型（Large Language Models, LLMs）中的记忆编辑（Memory Editing, ME）进行了全面评估，聚焦于连续编辑场景及其对模型基本能力的冲击，解决了现有研究仅限于单一编辑和基本事实的局限。实验结果显示，参数修改型 ME（parameter-modifying ME）在连续编辑后会持续降低模型在各种任务（如逻辑推理和阅读理解）上的性能，而参数保留型 ME（parameter-preserving ME）虽能维持核心能力，但难以准确召回以不同格式呈现的编辑知识。论文进一步探讨了编辑层、模型大小等因素，并从参数变化、语言建模和上下文学习能力三个维度解释了负面影响的原因，主张在实际应用中谨慎使用 ME。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint, 15 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.11122v1",
      "published_date": "2024-02-16 23:08:55 UTC",
      "updated_date": "2024-02-16 23:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:52:54.881207"
    },
    {
      "arxiv_id": "2402.12396v1",
      "title": "Toward using GANs in astrophysical Monte-Carlo simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Ahab Isaac",
        "Wesley Armour",
        "Karel Adámek"
      ],
      "abstract": "Accurate modelling of spectra produced by X-ray sources requires the use of\nMonte-Carlo simulations. These simulations need to evaluate physical processes,\nsuch as those occurring in accretion processes around compact objects by\nsampling a number of different probability distributions. This is\ncomputationally time-consuming and could be sped up if replaced by neural\nnetworks. We demonstrate, on an example of the Maxwell-J\\\"uttner distribution\nthat describes the speed of relativistic electrons, that the generative\nadversarial network (GAN) is capable of statistically replicating the\ndistribution. The average value of the Kolmogorov-Smirnov test is 0.5 for\nsamples generated by the neural network, showing that the generated\ndistribution cannot be distinguished from the true distribution.",
      "tldr_zh": "本研究探讨了在天体物理Monte-Carlo simulations中应用GANs（生成对抗网络）以加速模拟过程。传统模拟需计算各种概率分布（如围绕致密物体的吸积过程），这耗费大量计算资源。作者以Maxwell-Jüttner distribution为例，展示了GAN能统计上复制该分布，使生成的样本与真实分布无法区分（Kolmogorov-Smirnov test平均值为0.5）。这项工作为使用神经网络优化天体物理模拟提供了可行性证明。",
      "categories": [
        "astro-ph.HE",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "astro-ph.HE",
      "comment": "Proceedings of ADASS XXXIII (2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.12396v1",
      "published_date": "2024-02-16 23:07:53 UTC",
      "updated_date": "2024-02-16 23:07:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:53:05.610050"
    },
    {
      "arxiv_id": "2402.13273v1",
      "title": "Operational Collective Intelligence of Humans and Machines",
      "title_zh": "人类与机器的操作性集体智能",
      "authors": [
        "Nikolos Gurney",
        "Fred Morstatter",
        "David V. Pynadath",
        "Adam Russell",
        "Gleb Satyukov"
      ],
      "abstract": "We explore the use of aggregative crowdsourced forecasting (ACF) as a\nmechanism to help operationalize ``collective intelligence'' of human-machine\nteams for coordinated actions. We adopt the definition for Collective\nIntelligence as: ``A property of groups that emerges from synergies among\ndata-information-knowledge, software-hardware, and individuals (those with new\ninsights as well as recognized authorities) that enables just-in-time knowledge\nfor better decisions than these three elements acting alone.'' Collective\nIntelligence emerges from new ways of connecting humans and AI to enable\ndecision-advantage, in part by creating and leveraging additional sources of\ninformation that might otherwise not be included. Aggregative crowdsourced\nforecasting (ACF) is a recent key advancement towards Collective Intelligence\nwherein predictions (X\\% probability that Y will happen) and rationales (why I\nbelieve it is this probability that X will happen) are elicited independently\nfrom a diverse crowd, aggregated, and then used to inform higher-level\ndecision-making. This research asks whether ACF, as a key way to enable\nOperational Collective Intelligence, could be brought to bear on operational\nscenarios (i.e., sequences of events with defined agents, components, and\ninteractions) and decision-making, and considers whether such a capability\ncould provide novel operational capabilities to enable new forms of\ndecision-advantage.",
      "tldr_zh": "本研究探讨了聚合式众包预测（Aggregative Crowdsourced Forecasting, ACF）作为一种机制，来操作化人类-机器团队的集体智能（Collective Intelligence）。集体智能被定义为群体的一种属性，通过数据-信息-知识、软件-硬件和个人的协同作用，实现及时知识，从而做出比单独元素更优的决策。研究强调ACF通过从多样化人群中独立收集预测和理由、然后聚合，来增强决策优势，并评估其是否能应用于操作场景（如事件序列和代理交互），从而提供新型操作能力和决策优势。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13273v1",
      "published_date": "2024-02-16 22:45:09 UTC",
      "updated_date": "2024-02-16 22:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:53:17.695790"
    },
    {
      "arxiv_id": "2402.13272v1",
      "title": "Spontaneous Theory of Mind for Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolos Gurney",
        "David V. Pynadath",
        "Volkan Ustun"
      ],
      "abstract": "Existing approaches to Theory of Mind (ToM) in Artificial Intelligence (AI)\noveremphasize prompted, or cue-based, ToM, which may limit our collective\nability to develop Artificial Social Intelligence (ASI). Drawing from research\nin computer science, cognitive science, and related disciplines, we contrast\nprompted ToM with what we call spontaneous ToM -- reasoning about others'\nmental states that is grounded in unintentional, possibly uncontrollable\ncognitive functions. We argue for a principled approach to studying and\ndeveloping AI ToM and suggest that a robust, or general, ASI will respond to\nprompts \\textit{and} spontaneously engage in social reasoning.",
      "tldr_zh": "该论文讨论了现有AI中的Theory of Mind (ToM)方法过于依赖prompted ToM，这可能限制Artificial Social Intelligence (ASI)的全面发展。作者从计算机科学、认知科学等学科借鉴，定义了spontaneous ToM 作为一种基于无意且可能不可控的认知功能，对他人的心理状态进行推理的机制。论文主张采用原则性方法研究AI ToM，并认为一个稳健的ASI应既能响应提示，也能自发进行社会推理，从而提升AI的社会互动能力。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13272v1",
      "published_date": "2024-02-16 22:41:13 UTC",
      "updated_date": "2024-02-16 22:41:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:53:29.504149"
    },
    {
      "arxiv_id": "2402.11104v2",
      "title": "Computing Voting Rules with Elicited Incomplete Votes",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Halpern",
        "Safwan Hossain",
        "Jamie Tucker-Foltz"
      ],
      "abstract": "Motivated by the difficulty of specifying complete ordinal preferences over a\nlarge set of $m$ candidates, we study voting rules that are computable by\nquerying voters about $t < m$ candidates. Generalizing prior works that focused\non specific instances of this problem, our paper fully characterizes the set of\npositional scoring rules that can be computed for any $1 \\leq t < m$, which,\nnotably, does not include plurality. We then extend this to show a similar\nimpossibility result for single transferable vote (elimination voting). These\nnegative results are information-theoretic and agnostic to the number of\nqueries. Finally, for scoring rules that are computable with limited-sized\nqueries, we give parameterized upper and lower bounds on the number of such\nqueries a deterministic or randomized algorithm must make to determine the\nscore-maximizing candidate. While there is no gap between our bounds for\ndeterministic algorithms, identifying the exact query complexity for randomized\nalgorithms is a challenging open problem, of which we solve one special case.",
      "tldr_zh": "这篇论文探讨了在候选人数量 m 较大时，通过查询选民关于少于 m 个（即 t 个）候选人的偏好来计算投票规则的问题，以缓解指定完整排序偏好的难度。研究全面表征了可计算的位置评分规则(positional scoring rules)，证明 plurality 规则无法实现类似计算，并扩展到 single transferable vote (STV) 显示了类似的不可能性结果，这些结果基于信息理论且独立于查询数量。对于可计算的评分规则，该论文提供了确定性和随机算法的查询数量参数化界限，并解决了一个随机算法的特例问题。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11104v2",
      "published_date": "2024-02-16 22:17:01 UTC",
      "updated_date": "2024-09-26 18:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:53:43.049556"
    },
    {
      "arxiv_id": "2403.15397v1",
      "title": "Regulating Large Language Models: A Roundtable Report",
      "title_zh": "监管大语言模型：圆桌会议报告",
      "authors": [
        "Gabriel Nicholas",
        "Paul Friedl"
      ],
      "abstract": "On July 20, 2023, a group of 27 scholars and digital rights advocates with\nexpertise in law, computer science, political science, and other disciplines\ngathered for the Large Language Models, Law and Policy Roundtable, co-hosted by\nthe NYU School of Law's Information Law Institute and the Center for Democracy\n& Technology. The roundtable convened to discuss how law and policy can help\naddress some of the larger societal problems posed by large language models\n(LLMs). The discussion focused on three policy topic areas in particular:\n  1. Truthfulness: What risks do LLMs pose in terms of generating mis- and\ndisinformation? How can these risks be mitigated from a technical and/or\nregulatory perspective?\n  2. Privacy: What are the biggest privacy risks involved in the creation,\ndeployment, and use of LLMs? How can these risks be mitigated from a technical\nand/or regulatory perspective?\n  3. Market concentration: What threats do LLMs pose concerning market/power\nconcentration? How can these risks be mitigated from a technical and/or\nregulatory perspective?\n  In this paper, we provide a detailed summary of the day's proceedings. We\nfirst recap what we deem to be the most important contributions made during the\nissue framing discussions. We then provide a list of potential legal and\nregulatory interventions generated during the brainstorming discussions.",
      "tldr_zh": "这篇论文报告了2023年7月由27位法律、计算机科学和政治科学等领域专家组成的圆桌会议，讨论大型语言模型(LLMs)带来的社会问题。会议重点探讨了三个领域：真实性(Truthfulness)风险（如生成误信息及其技术或监管缓解）、隐私(Privacy)风险（如在LLMs创建、部署和使用中的潜在威胁及其应对策略），以及市场集中(Market concentration)风险（如权力集中的威胁及其缓解方法）。论文总结了会议的关键贡献和脑力激荡产生的潜在法律及监管干预措施，为LLMs的治理提供宝贵见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.15397v1",
      "published_date": "2024-02-16 21:49:17 UTC",
      "updated_date": "2024-02-16 21:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:53:53.457868"
    },
    {
      "arxiv_id": "2402.11089v3",
      "title": "The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects",
      "title_zh": "男性 CEO 和女性助理：文本到图像",
      "authors": [
        "Yixin Wan",
        "Kai-Wei Chang"
      ],
      "abstract": "Recent large-scale T2I models like DALLE-3 have made progress in reducing\ngender stereotypes when generating single-person images. However, significant\nbiases remain when generating images with more than one person. To\nsystematically evaluate this, we propose the Paired Stereotype Test (PST)\nframework, which queries T2I models to depict two individuals assigned with\nmale-stereotyped and female-stereotyped social identities, respectively (e.g.\n\"a CEO\" and \"an Assistant\"). This contrastive setting often triggers T2I models\nto generate gender-stereotyped images. Using PST, we evaluate two aspects of\ngender biases -- the well-known bias in gendered occupation and a novel aspect:\nbias in organizational power. Experiments show that over 74% images generated\nby DALLE-3 display gender-occupational biases. Additionally, compared to\nsingle-person settings, DALLE-3 is more likely to perpetuate male-associated\nstereotypes under PST. We further propose FairCritic, a novel and interpretable\nframework that leverages an LLM-based critic model to i) detect bias in\ngenerated images, and ii) adaptively provide feedback to T2I models for\nimproving fairness. FairCritic achieves near-perfect fairness on PST,\novercoming the limitations of previous prompt-based intervention approaches.",
      "tldr_zh": "这篇论文评估了T2I models在生成双人图像时的性别偏见问题，提出Paired Stereotype Test (PST)框架来系统检测这些偏见，包括性别职业偏见（如男性CEO）和组织权力偏见。实验结果显示，DALLE-3在PST下有超过74%的图像表现出性别职业偏见，且比单人场景更容易强化男性刻板印象。为了缓解这些问题，论文引入了FairCritic框架，该框架利用LLM-based critic模型检测图像偏见并提供自适应反馈，最终在PST上实现了近乎完美的公平性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11089v3",
      "published_date": "2024-02-16 21:32:27 UTC",
      "updated_date": "2024-10-23 22:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:54:07.564750"
    },
    {
      "arxiv_id": "2402.11082v1",
      "title": "The AI Security Pyramid of Pain",
      "title_zh": "翻译失败",
      "authors": [
        "Chris M. Ward",
        "Josh Harguess",
        "Julia Tao",
        "Daniel Christman",
        "Paul Spicer",
        "Mike Tan"
      ],
      "abstract": "We introduce the AI Security Pyramid of Pain, a framework that adapts the\ncybersecurity Pyramid of Pain to categorize and prioritize AI-specific threats.\nThis framework provides a structured approach to understanding and addressing\nvarious levels of AI threats. Starting at the base, the pyramid emphasizes Data\nIntegrity, which is essential for the accuracy and reliability of datasets and\nAI models, including their weights and parameters. Ensuring data integrity is\ncrucial, as it underpins the effectiveness of all AI-driven decisions and\noperations. The next level, AI System Performance, focuses on MLOps-driven\nmetrics such as model drift, accuracy, and false positive rates. These metrics\nare crucial for detecting potential security breaches, allowing for early\nintervention and maintenance of AI system integrity. Advancing further, the\npyramid addresses the threat posed by Adversarial Tools, identifying and\nneutralizing tools used by adversaries to target AI systems. This layer is key\nto staying ahead of evolving attack methodologies. At the Adversarial Input\nlayer, the framework addresses the detection and mitigation of inputs designed\nto deceive or exploit AI models. This includes techniques like adversarial\npatterns and prompt injection attacks, which are increasingly used in\nsophisticated attacks on AI systems. Data Provenance is the next critical\nlayer, ensuring the authenticity and lineage of data and models. This layer is\npivotal in preventing the use of compromised or biased data in AI systems. At\nthe apex is the tactics, techniques, and procedures (TTPs) layer, dealing with\nthe most complex and challenging aspects of AI security. This involves a deep\nunderstanding and strategic approach to counter advanced AI-targeted attacks,\nrequiring comprehensive knowledge and planning.",
      "tldr_zh": "本研究引入了“The AI Security Pyramid of Pain”框架，该框架将传统的cybersecurity Pyramid of Pain适应到AI特定威胁的分类和优先处理，提供一个结构化的方法来理解和管理AI安全风险。从基础层开始，该框架强调“Data Integrity”以确保数据集和AI模型的准确性，其上层包括“AI System Performance”监控指标如模型漂移和准确率、“Adversarial Tools”识别攻击工具、“Adversarial Input”缓解欺骗性输入如提示注入攻击，以及“Data Provenance”验证数据真实性，最终在顶层处理“Tactics, Techniques, and Procedures (TTPs)”以应对高级威胁。该框架的核心贡献在于帮助组织优先应对AI安全挑战，促进早期干预和战略规划。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "SPIE DCS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.11082v1",
      "published_date": "2024-02-16 21:14:11 UTC",
      "updated_date": "2024-02-16 21:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:54:18.494832"
    },
    {
      "arxiv_id": "2402.11078v3",
      "title": "Model Editing by Standard Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Govind Gangadhar",
        "Karl Stratos"
      ],
      "abstract": "Standard fine-tuning is considered not as effective as specialized methods\nfor model editing due to its comparatively poor performance. However, it is\nsimple, agnostic to the architectural details of the model being edited, and\nable to leverage advances in standard training techniques with no additional\nwork (e.g., black-box PEFT for computational efficiency), making it an\nappealing choice for a model editor. In this work, we show that standard\nfine-tuning alone can yield competitive model editing performance with two\nminor modifications. First, we optimize the conditional likelihood rather than\nthe full likelihood. Second, in addition to the typical practice of training on\nrandomly paraphrased edit prompts to encourage generalization, we also train on\nrandom or similar unedited facts to encourage locality. Our experiments on the\nZsRE and CounterFact datasets demonstrate that these simple modifications allow\nstandard fine-tuning to match or outperform highly specialized editors in terms\nof edit score.",
      "tldr_zh": "这篇论文证明了标准fine-tuning在模型编辑中可以通过简单修改实现与专业方法相当的性能，尽管它通常被视为效率较低。作者提出的改进包括优化conditional likelihood而不是全似然，以及在随机或相似的未编辑事实上训练，以增强泛化和局部性。这些修改使标准fine-tuning能够利用现有训练技术（如black-box PEFT）而无需额外复杂性。在ZsRE和CounterFact数据集上的实验显示，该方法在编辑分数上匹配或超过了高度专门化的编辑器。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.11078v3",
      "published_date": "2024-02-16 21:10:33 UTC",
      "updated_date": "2024-06-03 05:39:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:54:29.824467"
    },
    {
      "arxiv_id": "2402.11073v3",
      "title": "AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwei Ni",
        "Minjing Shi",
        "Dominik Stammbach",
        "Mrinmaya Sachan",
        "Elliott Ash",
        "Markus Leippold"
      ],
      "abstract": "With the rise of generative AI, automated fact-checking methods to combat\nmisinformation are becoming more and more important. However, factual claim\ndetection, the first step in a fact-checking pipeline, suffers from two key\nissues that limit its scalability and generalizability: (1) inconsistency in\ndefinitions of the task and what a claim is, and (2) the high cost of manual\nannotation. To address (1), we review the definitions in related work and\npropose a unifying definition of factual claims that focuses on verifiability.\nTo address (2), we introduce AFaCTA (Automatic Factual Claim deTection\nAnnotator), a novel framework that assists in the annotation of factual claims\nwith the help of large language models (LLMs). AFaCTA calibrates its annotation\nconfidence with consistency along three predefined reasoning paths. Extensive\nevaluation and experiments in the domain of political speech reveal that AFaCTA\ncan efficiently assist experts in annotating factual claims and training\nhigh-quality classifiers, and can work with or without expert supervision. Our\nanalyses also result in PoliClaim, a comprehensive claim detection dataset\nspanning diverse political topics.",
      "tldr_zh": "该论文针对事实声明检测（factual claim detection）面临的定义不一致和高手动标注成本问题，首先提出一个统一的声明定义，强调声明的可验证性（verifiability）。为了解决标注效率问题，他们引入了 AFaCTA 框架，该框架利用大型语言模型（LLMs）辅助标注，通过三个预定义的推理路径校准标注置信度，确保一致性和可靠性。实验在政治演讲领域进行，显示 AFaCTA 可高效辅助专家训练高质量分类器，并在有或无专家监督下有效运行，最终创建了 PoliClaim 数据集，一个涵盖多样政治主题的全面声明检测资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2402.11073v3",
      "published_date": "2024-02-16 20:59:57 UTC",
      "updated_date": "2024-06-02 18:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:54:42.456180"
    },
    {
      "arxiv_id": "2402.11068v2",
      "title": "Large Language Models for Causal Discovery: Current Landscape and Future Directions",
      "title_zh": "大语言模型用于因果发现：当前格局与未来方向",
      "authors": [
        "Guangya Wan",
        "Yunsheng Lu",
        "Yuqi Wu",
        "Mengxuan Hu",
        "Sheng Li"
      ],
      "abstract": "Causal discovery (CD) and Large Language Models (LLMs) have emerged as\ntransformative fields in artificial intelligence that have evolved largely\nindependently. While CD specializes in uncovering cause-effect relationships\nfrom data, and LLMs excel at natural language processing and generation, their\nintegration presents unique opportunities for advancing causal understanding.\nThis survey examines how LLMs are transforming CD across three key dimensions:\ndirect causal extraction from text, integration of domain knowledge into\nstatistical methods, and refinement of causal structures. We systematically\nanalyze approaches that leverage LLMs for CD tasks, highlighting their\ninnovative use of metadata and natural language for causal inference. Our\nanalysis reveals both LLMs' potential to enhance traditional CD methods and\ntheir current limitations as imperfect expert systems. We identify key research\ngaps, outline evaluation frameworks and benchmarks for LLM-based causal\ndiscovery, and advocate future research efforts for leveraging LLMs in\ncausality research. As the first comprehensive examination of the synergy\nbetween LLMs and CD, this work lays the groundwork for future advances in the\nfield.",
      "tldr_zh": "这篇调查论文探讨了 Large Language Models (LLMs) 在 Causal Discovery (CD) 领域的应用现状和未来方向，强调了 LLMs 如何通过直接从文本中提取因果关系、整合领域知识到统计方法中以及完善因果结构等三个关键维度来提升因果理解。论文系统分析了 LLMs 在 CD 任务中的创新使用，如利用元数据和自然语言进行因果推理，同时揭示了 LLMs 的潜力（如增强传统方法）和局限性（如作为不完美专家系统）。最终，论文识别了关键研究空白，提出了评估框架和基准，并倡导未来研究努力，以推动 LLMs 在因果性研究中的协同发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11068v2",
      "published_date": "2024-02-16 20:48:53 UTC",
      "updated_date": "2025-02-15 03:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:54:55.297847"
    },
    {
      "arxiv_id": "2402.11060v3",
      "title": "Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Chenkai Sun",
        "Ke Yang",
        "Revanth Gangi Reddy",
        "Yi R. Fung",
        "Hou Pong Chan",
        "Kevin Small",
        "ChengXiang Zhai",
        "Heng Ji"
      ],
      "abstract": "The increasing demand for personalized interactions with large language\nmodels (LLMs) calls for methodologies capable of accurately and efficiently\nidentifying user opinions and preferences. Retrieval augmentation emerges as an\neffective strategy, as it can accommodate a vast number of users without the\ncosts from fine-tuning. Existing research, however, has largely focused on\nenhancing the retrieval stage and devoted limited exploration toward optimizing\nthe representation of the database, a crucial aspect for tasks such as\npersonalization. In this work, we examine the problem from a novel angle,\nfocusing on how data can be better represented for more data-efficient\nretrieval in the context of LLM customization. To tackle this challenge, we\nintroduce Persona-DB, a simple yet effective framework consisting of a\nhierarchical construction process to improve generalization across task\ncontexts and collaborative refinement to effectively bridge knowledge gaps\namong users. In the evaluation of response prediction, Persona-DB demonstrates\nsuperior context efficiency in maintaining accuracy with a significantly\nreduced retrieval size, a critical advantage in scenarios with extensive\nhistories or limited context windows. Our experiments also indicate a marked\nimprovement of over 10% under cold-start scenarios, when users have extremely\nsparse data. Furthermore, our analysis reveals the increasing importance of\ncollaborative knowledge as the retrieval capacity expands.",
      "tldr_zh": "该论文提出了 Persona-DB，一种高效框架，用于 Large Language Model (LLMs) 的个性化响应预测，通过优化数据库表示来提升数据效率。Persona-DB 采用 hierarchical construction 过程以提高任务泛化能力，以及 collaborative refinement 机制来桥接用户间知识差距，从而实现更高效的检索增强策略。实验结果显示，在响应预测任务中，该框架显著降低了检索大小同时保持准确性，并在冷启动场景下改善超过 10%，突显了协作知识在扩展检索容量时的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11060v3",
      "published_date": "2024-02-16 20:20:43 UTC",
      "updated_date": "2025-02-03 00:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:55:05.911266"
    },
    {
      "arxiv_id": "2402.12394v2",
      "title": "Improving Model's Interpretability and Reliability using Biomarkers",
      "title_zh": "使用生物标记物改进模型的可",
      "authors": [
        "Gautam Rajendrakumar Gare",
        "Tom Fox",
        "Beam Chansangavej",
        "Amita Krishnan",
        "Ricardo Luis Rodriguez",
        "Bennett P deBoisblanc",
        "Deva Kannan Ramanan",
        "John Michael Galeotti"
      ],
      "abstract": "Accurate and interpretable diagnostic models are crucial in the\nsafety-critical field of medicine. We investigate the interpretability of our\nproposed biomarker-based lung ultrasound diagnostic pipeline to enhance\nclinicians' diagnostic capabilities. The objective of this study is to assess\nwhether explanations from a decision tree classifier, utilizing biomarkers, can\nimprove users' ability to identify inaccurate model predictions compared to\nconventional saliency maps. Our findings demonstrate that decision tree\nexplanations, based on clinically established biomarkers, can assist clinicians\nin detecting false positives, thus improving the reliability of diagnostic\nmodels in medicine.",
      "tldr_zh": "这篇论文探讨了使用生物标记物（biomarkers）来提升医学诊断模型的可解释性和可靠性，特别针对肺超声诊断管道。研究通过决策树分类器（decision tree classifier）基于临床生物标记物生成解释，并与传统的显著性图（saliency maps）进行比较，以评估这些解释是否能帮助临床医生识别模型的错误预测。结果表明，决策树解释显著提高了检测假阳性的能力，从而增强了诊断模型在医疗领域的可靠性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at BIAS 2023 Conference",
      "pdf_url": "http://arxiv.org/pdf/2402.12394v2",
      "published_date": "2024-02-16 20:19:28 UTC",
      "updated_date": "2025-01-30 16:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:55:19.038944"
    },
    {
      "arxiv_id": "2402.11051v1",
      "title": "Large Language Models Fall Short: Understanding Complex Relationships in Detective Narratives",
      "title_zh": "翻译失败",
      "authors": [
        "Runcong Zhao",
        "Qinglin Zhu",
        "Hainiu Xu",
        "Jiazheng Li",
        "Yuxiang Zhou",
        "Yulan He",
        "Lin Gui"
      ],
      "abstract": "Existing datasets for narrative understanding often fail to represent the\ncomplexity and uncertainty of relationships in real-life social scenarios. To\naddress this gap, we introduce a new benchmark, Conan, designed for extracting\nand analysing intricate character relation graphs from detective narratives.\nSpecifically, we designed hierarchical relationship categories and manually\nextracted and annotated role-oriented relationships from the perspectives of\nvarious characters, incorporating both public relationships known to most\ncharacters and secret ones known to only a few. Our experiments with advanced\nLarge Language Models (LLMs) like GPT-3.5, GPT-4, and Llama2 reveal their\nlimitations in inferencing complex relationships and handling longer\nnarratives. The combination of the Conan dataset and our pipeline strategy is\ngeared towards understanding the ability of LLMs to comprehend nuanced\nrelational dynamics in narrative contexts.",
      "tldr_zh": "该研究指出，现有的叙事理解数据集无法充分捕捉真实社交场景中的复杂关系不确定性，因此引入了新基准 Conan，用于从侦探叙事中提取和分析复杂的角色关系图。Conan 设计了分层关系类别，并手动提取和标注了基于不同角色视角的角色导向关系，包括公开关系和秘密关系。实验结果显示，先进的 Large Language Models（如 GPT-3.5、GPT-4 和 Llama2）在推断复杂关系和处理长叙事方面存在显著局限性，该基准和管道策略有助于评估 LLMs 在叙事上下文中的细微关系理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11051v1",
      "published_date": "2024-02-16 19:59:45 UTC",
      "updated_date": "2024-02-16 19:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:55:30.520050"
    },
    {
      "arxiv_id": "2402.10893v1",
      "title": "RLVF: Learning from Verbal Feedback without Overgeneralization",
      "title_zh": "翻译失败",
      "authors": [
        "Moritz Stephan",
        "Alexander Khazatsky",
        "Eric Mitchell",
        "Annie S Chen",
        "Sheryl Hsu",
        "Archit Sharma",
        "Chelsea Finn"
      ],
      "abstract": "The diversity of contexts in which large language models (LLMs) are deployed\nrequires the ability to modify or customize default model behaviors to\nincorporate nuanced requirements and preferences. A convenient interface to\nspecify such model adjustments is high-level verbal feedback, such as \"Don't\nuse emojis when drafting emails to my boss.\" However, while writing high-level\nfeedback is far simpler than collecting annotations for reinforcement learning\nfrom human feedback (RLHF), we find that simply prompting a model with such\nfeedback leads to overgeneralization of the feedback to contexts where it is\nnot relevant. We study the problem of incorporating verbal feedback without\nsuch overgeneralization, inspiring a new method Contextualized Critiques with\nConstrained Preference Optimization (C3PO). C3PO uses a piece of high-level\nfeedback to generate a small synthetic preference dataset specifying how the\nfeedback should (and should not) be applied. It then fine-tunes the model in\naccordance with the synthetic preference data while minimizing the divergence\nfrom the original model for prompts where the feedback does not apply. Our\nexperimental results indicate that our approach effectively applies verbal\nfeedback to relevant scenarios while preserving existing behaviors for other\ncontexts. For both human- and GPT-4-generated high-level feedback, C3PO\neffectively adheres to the given feedback comparably to in-context baselines\nwhile reducing overgeneralization by 30%.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）从高层次口头反馈中学习的问题，指出直接提示会导致过度泛化（如将反馈应用到不相关情境）。为了解决此问题，研究提出了一种新方法 Contextualized Critiques with Constrained Preference Optimization (C3PO)，它通过生成小型合成偏好数据集来指定反馈的应用范围，并微调模型以最小化不相关提示上的变化。实验结果显示，C3PO 有效将反馈应用于相关场景，同时减少了 30% 的过度泛化，并在遵守反馈方面与 in-context 基线相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.10893v1",
      "published_date": "2024-02-16 18:50:24 UTC",
      "updated_date": "2024-02-16 18:50:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:55:43.133374"
    },
    {
      "arxiv_id": "2402.10891v1",
      "title": "Instruction Diversity Drives Generalization To Unseen Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Zhang",
        "Justin Wang",
        "Francois Charton"
      ],
      "abstract": "Instruction tuning -- fine-tuning a large language model (LLM) on pairs of\ninstructions and desired outcomes -- is an approach that enables pre-trained\nlanguage models to perform real-world tasks and follow human instructions. Its\npractical success depends on the model learning a broader set of instructions\nthan those it was trained on. Yet the factors that determine model\ngeneralization to such \\emph{unseen tasks} are not well understood. %To\nunderstand the driving factors of generalization, In this paper, we experiment\nwith string rewrites, a symbolic task that serves as a building block for\nTuring complete Markov algorithms while allowing experimental control of\n\"inputs\" and \"instructions\". We investigate the trade-off between the number of\ninstructions the model is trained on and the number of training samples\nprovided for each instruction and observe that the diversity of the instruction\nset determines generalization. Generalization emerges once a diverse enough set\nof tasks is provided, even though very few examples are provided for each task.\nInstruction diversity also ensures robustness with respect to non-uniform\ndistributions of instructions in the training set.",
      "tldr_zh": "本文研究了指令微调（Instruction tuning）如何使大型语言模型（LLM）泛化到未见任务（unseen tasks），重点探讨影响泛化的关键因素。通过实验字符串重写（string rewrites）任务作为控制环境，作者考察了训练指令数量与每个指令样本数量的权衡，发现指令集的多样性是泛化的主要驱动因素。即使每个任务的训练样本很少，提供足够多样化的指令集也能实现泛化，并提升模型对非均匀指令分布的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10891v1",
      "published_date": "2024-02-16 18:47:21 UTC",
      "updated_date": "2024-02-16 18:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:55:54.351758"
    },
    {
      "arxiv_id": "2402.10890v2",
      "title": "When is Tree Search Useful for LLM Planning? It Depends on the Discriminator",
      "title_zh": "树搜索何时对大语言模型规划有用？它取决于鉴别器",
      "authors": [
        "Ziru Chen",
        "Michael White",
        "Raymond Mooney",
        "Ali Payani",
        "Yu Su",
        "Huan Sun"
      ],
      "abstract": "In this paper, we examine how large language models (LLMs) solve multi-step\nproblems under a language agent framework with three components: a generator, a\ndiscriminator, and a planning method. We investigate the practical utility of\ntwo advanced planning methods, iterative correction and tree search. We present\na comprehensive analysis of how discrimination accuracy affects the overall\nperformance of agents when using these two methods or a simpler method,\nre-ranking. Experiments on two tasks, text-to-SQL parsing and mathematical\nreasoning, show that: (1) advanced planning methods demand discriminators with\nat least 90% accuracy to achieve significant improvements over re-ranking; (2)\ncurrent LLMs' discrimination abilities have not met the needs of advanced\nplanning methods to achieve such improvements; (3) with LLM-based\ndiscriminators, advanced planning methods may not adequately balance accuracy\nand efficiency. For example, compared to the other two methods, tree search is\nat least 10--20 times slower but leads to negligible performance gains, which\nhinders its real-world applications. Code and data are available at\nhttps://github.com/OSU-NLP-Group/llm-planning-eval.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在多步问题解决中的规划方法，聚焦于生成器、鉴别器和规划组件的语言代理框架。研究者比较了迭代修正、树搜索和简单重新排序三种方法，并分析鉴别器准确率的影响，发现高级规划方法如树搜索需至少90%的鉴别器准确率才能显著优于重新排序，但当前LLMs的鉴别能力不足以实现此要求。实验在文本到SQL解析和数学推理任务上显示，树搜索虽更先进，却因效率低下（比其他方法慢10-20倍）而性能提升微不足道，限制了其实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 main",
      "pdf_url": "http://arxiv.org/pdf/2402.10890v2",
      "published_date": "2024-02-16 18:45:58 UTC",
      "updated_date": "2024-06-06 14:55:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:56:07.681228"
    },
    {
      "arxiv_id": "2402.10888v1",
      "title": "Explainability for Machine Learning Models: From Data Adaptability to User Perception",
      "title_zh": "机器学习模型的可解释性：从数据适应性到用户感知",
      "authors": [
        "julien Delaunay"
      ],
      "abstract": "This thesis explores the generation of local explanations for already\ndeployed machine learning models, aiming to identify optimal conditions for\nproducing meaningful explanations considering both data and user requirements.\nThe primary goal is to develop methods for generating explanations for any\nmodel while ensuring that these explanations remain faithful to the underlying\nmodel and comprehensible to the users.\n  The thesis is divided into two parts. The first enhances a widely used\nrule-based explanation method. It then introduces a novel approach for\nevaluating the suitability of linear explanations to approximate a model.\nAdditionally, it conducts a comparative experiment between two families of\ncounterfactual explanation methods to analyze the advantages of one over the\nother. The second part focuses on user experiments to assess the impact of\nthree explanation methods and two distinct representations. These experiments\nmeasure how users perceive their interaction with the model in terms of\nunderstanding and trust, depending on the explanations and representations.\nThis research contributes to a better explanation generation, with potential\nimplications for enhancing the transparency, trustworthiness, and usability of\ndeployed AI systems.",
      "tldr_zh": "这篇论文探讨了为已部署的 machine learning models 生成本地解释的方法，旨在识别最佳条件以确保解释既忠实于底层模型又易于用户理解，同时考虑数据适应性和用户感知。论文分为两部分：第一部分增强了一种基于规则的解释方法，引入新方法评估线性解释的适用性，并比较两种 counterfactual explanation 方法的优势；第二部分通过用户实验评估三种解释方法和两种表示形式对用户理解和信任的影响。总体贡献在于改进解释生成，提升 machine learning models 的透明度、可信度和可用性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD Thesis",
      "pdf_url": "http://arxiv.org/pdf/2402.10888v1",
      "published_date": "2024-02-16 18:44:37 UTC",
      "updated_date": "2024-02-16 18:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:56:18.702825"
    },
    {
      "arxiv_id": "2402.10885v3",
      "title": "3D Diffuser Actor: Policy Diffusion with 3D Scene Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Tsung-Wei Ke",
        "Nikolaos Gkanatsios",
        "Katerina Fragkiadaki"
      ],
      "abstract": "Diffusion policies are conditional diffusion models that learn robot action\ndistributions conditioned on the robot and environment state. They have\nrecently shown to outperform both deterministic and alternative action\ndistribution learning formulations. 3D robot policies use 3D scene feature\nrepresentations aggregated from a single or multiple camera views using sensed\ndepth. They have shown to generalize better than their 2D counterparts across\ncamera viewpoints. We unify these two lines of work and present 3D Diffuser\nActor, a neural policy equipped with a novel 3D denoising transformer that\nfuses information from the 3D visual scene, a language instruction and\nproprioception to predict the noise in noised 3D robot pose trajectories. 3D\nDiffuser Actor sets a new state-of-the-art on RLBench with an absolute\nperformance gain of 18.1% over the current SOTA on a multi-view setup and an\nabsolute gain of 13.1% on a single-view setup. On the CALVIN benchmark, it\nimproves over the current SOTA by a 9% relative increase. It also learns to\ncontrol a robot manipulator in the real world from a handful of demonstrations.\nThrough thorough comparisons with the current SOTA policies and ablations of\nour model, we show 3D Diffuser Actor's design choices dramatically outperform\n2D representations, regression and classification objectives, absolute\nattentions, and holistic non-tokenized 3D scene embeddings.",
      "tldr_zh": "本研究提出了3D Diffuser Actor，一种基于扩散策略(Diffusion policies)的神经策略框架，使用3D场景表示来提升机器人动作学习。该框架采用新型3D去噪transformer，融合3D视觉场景、语言指令和本体感觉(proprioception)，以预测噪声在3D机器人姿势轨迹中的位置，从而实现更强的泛化能力。实验结果显示，在RLBench基准上，该模型在多视图设置下比当前SOTA提升18.1%，在单视图下提升13.1%；在CALVIN基准上相对提升9%。此外，3D Diffuser Actor通过与2D表示、回归和分类目标等的比较，证明其设计选择在真实世界机器人控制中表现出显著优势，仅需少量演示即可实现有效学习。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "First two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2402.10885v3",
      "published_date": "2024-02-16 18:43:02 UTC",
      "updated_date": "2024-07-25 14:30:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:56:32.902844"
    },
    {
      "arxiv_id": "2402.10884v2",
      "title": "Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shengzhi Li",
        "Rongyu Lin",
        "Shichao Pei"
      ],
      "abstract": "Multi-modal large language models (MLLMs) are expected to support multi-turn\nqueries of interchanging image and text modalities in production. However, the\ncurrent MLLMs trained with visual-question-answering (VQA) datasets could\nsuffer from degradation, as VQA datasets lack the diversity and complexity of\nthe original text instruction datasets with which the underlying language model\nwas trained. To address this degradation, we first collect a lightweight,\n5k-sample VQA preference dataset where answers were annotated by Gemini for\nfive quality metrics in a granular fashion and investigate standard Supervised\nFine-tuning, rejection sampling, Direct Preference Optimization (DPO) and\nSteerLM algorithms. Our findings indicate that with DPO, we can surpass the\ninstruction-following capabilities of the language model, achieving a 6.73\nscore on MT-Bench, compared to Vicuna's 6.57 and LLaVA's 5.99. This enhancement\nin textual instruction-following capability correlates with boosted visual\ninstruction performance (+4.9\\% on MM-Vet, +6\\% on LLaVA-Bench), with minimal\nalignment tax on visual knowledge benchmarks compared to the previous RLHF\napproach. In conclusion, we propose a distillation-based multi-modal alignment\nmodel with fine-grained annotations on a small dataset that restores and boosts\nMLLM's language capability after visual instruction tuning.",
      "tldr_zh": "该研究发现，多模态大语言模型 (MLLMs) 在使用视觉问答 (VQA) 数据集训练后，可能因数据集缺乏多样性和复杂性而导致指令遵循能力退化。为解决此问题，研究者收集了一个 5k 样本的 VQA 偏好数据集，并通过 Supervised Fine-tuning、Direct Preference Optimization (DPO) 等算法进行实验。结果显示，DPO 方法使模型在 MT-Bench 上达到 6.73 分，超越了 Vicuna 的 6.57 和 LLaVA 的 5.99，同时提升了视觉指令性能（如 MM-Vet +4.9%、LLaVA-Bench +6%），并最小化了对视觉知识基准的负面影响。该方法最终提出了一种基于蒸馏的 multi-modal alignment 模型，使用细粒度标注的小数据集来恢复和增强 MLLMs 的语言能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project code, model and data: https://github.com/findalexli/mllm-dpo",
      "pdf_url": "http://arxiv.org/pdf/2402.10884v2",
      "published_date": "2024-02-16 18:42:08 UTC",
      "updated_date": "2024-11-05 05:13:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:56:44.660376"
    },
    {
      "arxiv_id": "2402.10877v7",
      "title": "Robust agents learn causal world models",
      "title_zh": "鲁棒代理学习因果世界模型",
      "authors": [
        "Jonathan Richens",
        "Tom Everitt"
      ],
      "abstract": "It has long been hypothesised that causal reasoning plays a fundamental role\nin robust and general intelligence. However, it is not known if agents must\nlearn causal models in order to generalise to new domains, or if other\ninductive biases are sufficient. We answer this question, showing that any\nagent capable of satisfying a regret bound under a large set of distributional\nshifts must have learned an approximate causal model of the data generating\nprocess, which converges to the true causal model for optimal agents. We\ndiscuss the implications of this result for several research areas including\ntransfer learning and causal inference.",
      "tldr_zh": "长期以来，人们假设因果推理是鲁棒和通用智能的核心。本文证明，任何代理若能在大量分布偏移下满足 regret bound，必须学习一个近似的 causal model，且最优代理会收敛到真实的 causal model。这为 transfer learning 和 causal inference 等研究领域提供了重要启示。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2024 (oral). Updated agents section, new corollary",
      "pdf_url": "http://arxiv.org/pdf/2402.10877v7",
      "published_date": "2024-02-16 18:29:19 UTC",
      "updated_date": "2024-07-19 11:12:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:56:54.534159"
    },
    {
      "arxiv_id": "2402.11005v3",
      "title": "A Theory of LLM Sampling: Part Descriptive and Part Prescriptive",
      "title_zh": "翻译失败",
      "authors": [
        "Sarath Sivaprasad",
        "Pramod Kaushik",
        "Sahar Abdelnabi",
        "Mario Fritz"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly utilized in autonomous\ndecision-making, where they sample options from vast action spaces. However,\nthe heuristics that guide this sampling process remain under-explored. We study\nthis sampling behavior and show that this underlying heuristics resembles that\nof human decision-making: comprising a descriptive component (reflecting\nstatistical norm) and a prescriptive component (implicit ideal encoded in the\nLLM) of a concept. We show that this deviation of a sample from the statistical\nnorm towards a prescriptive component consistently appears in concepts across\ndiverse real-world domains like public health, and economic trends. To further\nillustrate the theory, we demonstrate that concept prototypes in LLMs are\naffected by prescriptive norms, similar to the concept of normality in humans.\nThrough case studies and comparison with human studies, we illustrate that in\nreal-world applications, the shift of samples toward an ideal value in LLMs'\noutputs can result in significantly biased decision-making, raising ethical\nconcerns.",
      "tldr_zh": "本论文提出一个关于大型语言模型(LLM)采样的理论，将其分为描述性组件（反映统计规范）和规定性组件（编码隐式理想），并证明这种采样行为类似于人类决策过程。研究通过案例分析显示，这种偏差在公共卫生、经济趋势等真实领域中普遍存在，导致LLM输出向理想值偏移。最终，作者强调这种现象可能引发偏见决策和伦理问题，呼吁在实际应用中加以注意。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.11005v3",
      "published_date": "2024-02-16 18:28:43 UTC",
      "updated_date": "2025-04-18 14:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:57:06.760550"
    },
    {
      "arxiv_id": "2403.12076v2",
      "title": "Neuron-centric Hebbian Learning",
      "title_zh": "以神经元为中心的Hebbian学习",
      "authors": [
        "Andrea Ferigo",
        "Elia Cunegatti",
        "Giovanni Iacca"
      ],
      "abstract": "One of the most striking capabilities behind the learning mechanisms of the\nbrain is the adaptation, through structural and functional plasticity, of its\nsynapses. While synapses have the fundamental role of transmitting information\nacross the brain, several studies show that it is the neuron activations that\nproduce changes on synapses. Yet, most plasticity models devised for artificial\nNeural Networks (NNs), e.g., the ABCD rule, focus on synapses, rather than\nneurons, therefore optimizing synaptic-specific Hebbian parameters. This\napproach, however, increases the complexity of the optimization process since\neach synapse is associated to multiple Hebbian parameters. To overcome this\nlimitation, we propose a novel plasticity model, called Neuron-centric Hebbian\nLearning (NcHL), where optimization focuses on neuron- rather than\nsynaptic-specific Hebbian parameters. Compared to the ABCD rule, NcHL reduces\nthe parameters from $5W$ to $5N$, being $W$ and $N$ the number of weights and\nneurons, and usually $N \\ll W$. We also devise a ``weightless'' NcHL model,\nwhich requires less memory by approximating the weights based on a record of\nneuron activations. Our experiments on two robotic locomotion tasks reveal that\nNcHL performs comparably to the ABCD rule, despite using up to $\\sim97$ times\nless parameters, thus allowing for scalable plasticity",
      "tldr_zh": "这篇论文提出了一种新型可塑性模型，Neuron-centric Hebbian Learning (NcHL)，它将优化焦点从突触转向神经元特定的 Hebbian 参数，以解决传统模型如 ABCD rule 的参数过多问题，从而简化优化过程。NcHL 将参数数量从 5W 减少到 5N（W 为权重数，N 为神经元数，且 N << W），并引入一个“weightless”版本，通过记录神经元激活来近似权重，进一步降低内存需求。实验结果显示，在两个机器人运动任务上，NcHL 的性能与 ABCD rule 相当，但参数减少多达 97 倍，提升了模型的可扩展性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at Genetic and Evolutionary Computation Conference (GECCO\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.12076v2",
      "published_date": "2024-02-16 17:38:28 UTC",
      "updated_date": "2024-04-16 08:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:57:19.838027"
    },
    {
      "arxiv_id": "2402.10846v1",
      "title": "FedD2S: Personalized Data-Free Federated Knowledge Distillation",
      "title_zh": "FedD2S：个性化的无数据联邦知识蒸馏",
      "authors": [
        "Kawa Atapour",
        "S. Jamal Seyedmohammadi",
        "Jamshid Abouei",
        "Arash Mohammadi",
        "Konstantinos N. Plataniotis"
      ],
      "abstract": "This paper addresses the challenge of mitigating data heterogeneity among\nclients within a Federated Learning (FL) framework. The model-drift issue,\narising from the noniid nature of client data, often results in suboptimal\npersonalization of a global model compared to locally trained models for each\nclient. To tackle this challenge, we propose a novel approach named FedD2S for\nPersonalized Federated Learning (pFL), leveraging knowledge distillation.\nFedD2S incorporates a deep-to-shallow layer-dropping mechanism in the data-free\nknowledge distillation process to enhance local model personalization. Through\nextensive simulations on diverse image datasets-FEMNIST, CIFAR10, CINIC0, and\nCIFAR100-we compare FedD2S with state-of-the-art FL baselines. The proposed\napproach demonstrates superior performance, characterized by accelerated\nconvergence and improved fairness among clients. The introduced layer-dropping\ntechnique effectively captures personalized knowledge, resulting in enhanced\nperformance compared to alternative FL models. Moreover, we investigate the\nimpact of key hyperparameters, such as the participation ratio and\nlayer-dropping rate, providing valuable insights into the optimal configuration\nfor FedD2S. The findings demonstrate the efficacy of adaptive layer-dropping in\nthe knowledge distillation process to achieve enhanced personalization and\nperformance across diverse datasets and tasks.",
      "tldr_zh": "这篇论文针对 Federated Learning (FL) 中数据异质性导致的模型漂移问题，提出了一种名为 FedD2S 的 Personalized Federated Learning (pFL) 方法，利用 knowledge distillation 技术来提升本地模型的个性化。FedD2S 引入了 deep-to-shallow layer-dropping 机制，在无数据知识蒸馏过程中有效捕获个性化知识，从而加速模型收敛并提高客户端公平性。通过在 FEMNIST、CIFAR10、CINIC0 和 CIFAR100 等图像数据集上的实验，该方法比现有 FL 基线模型表现出色，性能显著提升。此外，论文分析了关键超参数如 participation ratio 和 layer-dropping rate 的影响，为优化配置提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10846v1",
      "published_date": "2024-02-16 17:36:51 UTC",
      "updated_date": "2024-02-16 17:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:57:33.943013"
    },
    {
      "arxiv_id": "2402.10837v1",
      "title": "Pedipulate: Enabling Manipulation Skills using a Quadruped Robot's Leg",
      "title_zh": "Pedipulate：利用四足机器人腿部启用操纵技能",
      "authors": [
        "Philip Arm",
        "Mayank Mittal",
        "Hendrik Kolvenbach",
        "Marco Hutter"
      ],
      "abstract": "Legged robots have the potential to become vital in maintenance, home\nsupport, and exploration scenarios. In order to interact with and manipulate\ntheir environments, most legged robots are equipped with a dedicated robot arm,\nwhich means additional mass and mechanical complexity compared to standard\nlegged robots. In this work, we explore pedipulation - using the legs of a\nlegged robot for manipulation. By training a reinforcement learning policy that\ntracks position targets for one foot, we enable a dedicated pedipulation\ncontroller that is robust to disturbances, has a large workspace through\nwhole-body behaviors, and can reach far-away targets with gait emergence,\nenabling loco-pedipulation. By deploying our controller on a quadrupedal robot\nusing teleoperation, we demonstrate various real-world tasks such as door\nopening, sample collection, and pushing obstacles. We demonstrate load carrying\nof more than 2.0 kg at the foot. Additionally, the controller is robust to\ninteraction forces at the foot, disturbances at the base, and slippery contact\nsurfaces. Videos of the experiments are available at\nhttps://sites.google.com/leggedrobotics.com/pedipulate.",
      "tldr_zh": "本研究探讨了“pedipulation”技术，即利用四足机器人（quadruped robot）的腿进行操作，以避免添加额外机械臂带来的质量和复杂性问题。通过训练一个强化学习（reinforcement learning）策略来跟踪脚部位置目标，研究者开发了一个鲁棒的控制器，支持全身行为和步态生成，从而实现远距离的loco-pedipulation任务。实验在真实四足机器人上通过遥操作（teleoperation）演示了开门、样本收集和推动障碍等实际应用，该控制器能携带超过2.0 kg负载，并对脚部交互力、基座干扰和滑溜接触面表现出强鲁棒性。该工作为legged robots在维护、家用支持和探索场景中的应用提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website:\n  https://sites.google.com/leggedrobotics.com/pedipulate",
      "pdf_url": "http://arxiv.org/pdf/2402.10837v1",
      "published_date": "2024-02-16 17:20:45 UTC",
      "updated_date": "2024-02-16 17:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:57:42.652693"
    },
    {
      "arxiv_id": "2402.11000v3",
      "title": "ASGEA: Exploiting Logic Rules from Align-Subgraphs for Entity Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yangyifei Luo",
        "Zhuo Chen",
        "Lingbing Guo",
        "Qian Li",
        "Wenxuan Zeng",
        "Zhixin Cai",
        "Jianxin Li"
      ],
      "abstract": "Entity alignment (EA) aims to identify entities across different knowledge\ngraphs that represent the same real-world objects. Recent embedding-based EA\nmethods have achieved state-of-the-art performance in EA yet faced\ninterpretability challenges as they purely rely on the embedding distance and\nneglect the logic rules behind a pair of aligned entities. In this paper, we\npropose the Align-Subgraph Entity Alignment (ASGEA) framework to exploit logic\nrules from Align-Subgraphs. ASGEA uses anchor links as bridges to construct\nAlign-Subgraphs and spreads along the paths across KGs, which distinguishes it\nfrom the embedding-based methods. Furthermore, we design an interpretable\nPath-based Graph Neural Network, ASGNN, to effectively identify and integrate\nthe logic rules across KGs. We also introduce a node-level multi-modal\nattention mechanism coupled with multi-modal enriched anchors to augment the\nAlign-Subgraph. Our experimental results demonstrate the superior performance\nof ASGEA over the existing embedding-based methods in both EA and Multi-Modal\nEA (MMEA) tasks.",
      "tldr_zh": "本文提出ASGEA框架，用于Entity Alignment (EA)，旨在从Align-Subgraphs中挖掘逻辑规则，以解决现有基于嵌入方法的可解释性问题。ASGEA通过锚点链接构建Align-Subgraphs，并在知识图谱间扩展路径，同时设计可解释的Path-based Graph Neural Network (ASGNN)来整合跨图谱逻辑规则，并引入节点级多模态注意力机制增强锚点。实验结果表明，ASGEA在EA和Multi-Modal EA (MMEA)任务上显著优于现有方法，提高了实体对齐的准确性和解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work; 16 pages, 9 Tables, 8 Figures; Code:\n  https://github.com/lyyf2002/ASGEA",
      "pdf_url": "http://arxiv.org/pdf/2402.11000v3",
      "published_date": "2024-02-16 17:03:05 UTC",
      "updated_date": "2025-02-25 03:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:57:55.841858"
    },
    {
      "arxiv_id": "2403.04769v2",
      "title": "Using Hallucinations to Bypass GPT4's Filter",
      "title_zh": "利用幻觉绕过 GPT-4 的过滤器",
      "authors": [
        "Benjamin Lemkin"
      ],
      "abstract": "Large language models (LLMs) are initially trained on vast amounts of data,\nthen fine-tuned using reinforcement learning from human feedback (RLHF); this\nalso serves to teach the LLM to provide appropriate and safe responses. In this\npaper, we present a novel method to manipulate the fine-tuned version into\nreverting to its pre-RLHF behavior, effectively erasing the model's filters;\nthe exploit currently works for GPT4, Claude Sonnet, and (to some extent) for\nInflection-2.5. Unlike other jailbreaks (for example, the popular \"Do Anything\nNow\" (DAN) ), our method does not rely on instructing the LLM to override its\nRLHF policy; hence, simply modifying the RLHF process is unlikely to address\nit. Instead, we induce a hallucination involving reversed text during which the\nmodel reverts to a word bucket, effectively pausing the model's filter. We\nbelieve that our exploit presents a fundamental vulnerability in LLMs currently\nunaddressed, as well as an opportunity to better understand the inner workings\nof LLMs during hallucinations.",
      "tldr_zh": "本论文提出了一种新颖方法，利用幻觉(hallucinations)来绕过大型语言模型(LLMs)如GPT-4、Claude Sonnet和部分Inflection-2.5的过滤器，该方法不依赖于传统的越狱(jailbreaks)指令，如“Do Anything Now (DAN)”。通过诱导涉及反转文本的幻觉，模型会暂时恢复到强化学习从人类反馈(RLHF)之前的原始行为，从而暂停其过滤机制。研究结果显示，这种漏洞揭示了LLMs的根本性弱点，并为更好地理解模型在幻觉状态下的内部工作机制提供了新机会。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.04769v2",
      "published_date": "2024-02-16 17:02:53 UTC",
      "updated_date": "2024-03-11 01:21:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:58:09.778770"
    },
    {
      "arxiv_id": "2402.10828v2",
      "title": "RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jianhao Yuan",
        "Shuyang Sun",
        "Daniel Omeiza",
        "Bo Zhao",
        "Paul Newman",
        "Lars Kunze",
        "Matthew Gadd"
      ],
      "abstract": "We need to trust robots that use often opaque AI methods. They need to\nexplain themselves to us, and we need to trust their explanation. In this\nregard, explainability plays a critical role in trustworthy autonomous\ndecision-making to foster transparency and acceptance among end users,\nespecially in complex autonomous driving. Recent advancements in Multi-Modal\nLarge Language models (MLLMs) have shown promising potential in enhancing the\nexplainability as a driving agent by producing control predictions along with\nnatural language explanations. However, severe data scarcity due to expensive\nannotation costs and significant domain gaps between different datasets makes\nthe development of a robust and generalisable system an extremely challenging\ntask. Moreover, the prohibitively expensive training requirements of MLLM and\nthe unsolved problem of catastrophic forgetting further limit their\ngeneralisability post-deployment. To address these challenges, we present\nRAG-Driver, a novel retrieval-augmented multi-modal large language model that\nleverages in-context learning for high-performance, explainable, and\ngeneralisable autonomous driving. By grounding in retrieved expert\ndemonstration, we empirically validate that RAG-Driver achieves\nstate-of-the-art performance in producing driving action explanations,\njustifications, and control signal prediction. More importantly, it exhibits\nexceptional zero-shot generalisation capabilities to unseen environments\nwithout further training endeavours.",
      "tldr_zh": "该研究针对自动驾驶AI的解释性和可信度问题，提出RAG-Driver，一种基于Retrieval-Augmented（检索增强）和In-Context Learning（上下文学习）的多模态大型语言模型（Multi-Modal Large Language Model）。RAG-Driver通过检索专家演示来生成驾驶行动解释、理由和控制信号预测，从而克服数据稀缺和领域差距的挑战。实验结果显示，该模型在性能上达到最先进水平，并表现出优秀的zero-shot generalisation能力，能够在未见环境中共适应无需额外训练。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.10828v2",
      "published_date": "2024-02-16 16:57:18 UTC",
      "updated_date": "2024-05-29 14:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:58:20.672218"
    },
    {
      "arxiv_id": "2402.10999v1",
      "title": "Analysis and Mortality Prediction using Multiclass Classification for Older Adults with Type 2 Diabetes",
      "title_zh": "使用多类分类对患有2型糖尿病的老年人进行分析和死亡率预测",
      "authors": [
        "Ruchika Desure",
        "Gutha Jaya Krishna"
      ],
      "abstract": "Designing proper treatment plans to manage diabetes requires health\npractitioners to pay heed to the individuals remaining life along with the\ncomorbidities affecting them. Older adults with Type 2 Diabetes Mellitus (T2DM)\nare prone to experience premature death or even hypoglycaemia. The structured\ndataset utilized has 68 potential mortality predictors for 275,190 diabetic\nU.S. military Veterans aged 65 years or older. A new target variable is\ninvented by combining the two original target variables. Outliers are handled\nby discretizing the continuous variables. Categorical variables have been dummy\nencoded. Class balancing is achieved by random under-sampling. A benchmark\nregression model is built using Multinomial Logistic Regression with LASSO.\nChi-Squared and Information Gain are the filter-based feature selection\ntechniques utilized. Classifiers such as Multinomial Logistic Regression,\nRandom Forest, Extreme Gradient Boosting (XGBoost), and One-vs-Rest classifier\nare employed to build various models. Contrary to expectations, all the models\nhave constantly underperformed. XGBoost has given the highest accuracy of 53.03\npercent with Chi-Squared feature selection. All the models have consistently\nshown an acceptable performance for Class 3 (remaining life is more than 10\nyears), significantly low for Class 1 (remaining life is up to 5 years), and\nthe worst for Class 2 (remaining life is more than 5 but up to 10 years).\nFeatures analysis has deduced that almost all input variables are associated\nwith multiple target classes. The high dimensionality of the input data after\ndummy encoding seems to have confused the models, leading to\nmisclassifications. The approach taken in this study is ineffective in\nproducing a high-performing predictive model but lays a foundation as this\nproblem has never been viewed from a multiclass classification perspective.",
      "tldr_zh": "这篇论文针对65岁及以上T2DM患者，使用多类分类方法分析死亡预测因素，基于一个包含68个预测变量的数据库，创建了新的目标变量并通过离散化、哑变量编码和随机欠采样进行数据预处理。研究采用Chi-Squared和Information Gain进行特征选择，并构建了Multinomial Logistic Regression、Random Forest、XGBoost和One-vs-Rest等分类器，但模型性能整体不佳，XGBoost最高准确率仅53.03%，尤其在预测剩余寿命≤5年（Class 1）和>5≤10年（Class 2）时表现较差。最终，论文指出高维数据导致模型混淆，该方法虽未能实现高性能预测，但首次从多类分类视角为T2DM死亡预测奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "146 Pages",
      "pdf_url": "http://arxiv.org/pdf/2402.10999v1",
      "published_date": "2024-02-16 16:47:48 UTC",
      "updated_date": "2024-02-16 16:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:58:33.354036"
    },
    {
      "arxiv_id": "2404.03665v1",
      "title": "Serial Parallel Reliability Redundancy Allocation Optimization for Energy Efficient and Fault Tolerant Cloud Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Gutha Jaya Krishna"
      ],
      "abstract": "Serial-parallel redundancy is a reliable way to ensure service and systems\nwill be available in cloud computing. That method involves making copies of the\nsame system or program, with only one remaining active. When an error occurs,\nthe inactive copy can step in as a backup right away, this provides continuous\nperformance and uninterrupted operation. This approach is called parallel\nredundancy, otherwise known as active-active redundancy, and its exceptional\nwhen it comes to strategy. It creates duplicates of a system or service that\nare all running at once. By doing this fault tolerance increases since if one\ncopy fails, the workload can be distributed across any replica thats\nfunctioning properly. Reliability allocation depends on features in a system\nand the availability and fault tolerance you want from it. Serial redundancy or\nparallel redundancies can be applied to increase the dependability of systems\nand services. To demonstrate how well this concept works, we looked into fixed\nserial parallel reliability redundancy allocation issues followed by using an\ninnovative hybrid optimization technique to find the best possible allocation\nfor peak dependability. We then measured our findings against other research.",
      "tldr_zh": "本研究针对云计算中的能源效率和容错性问题，探讨了串行并行可靠性冗余分配优化方法，该方法通过创建系统副本（如active-active redundancy）来提高故障时的连续性和可用性。研究者采用创新的混合优化技术，针对固定串行并行可靠性冗余分配问题进行求解，以最大化系统的可靠性。实验结果显示，该方法在与其他研究的比较中表现出色，有效提升了云计算的整体性能和可靠性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "68W50",
        "I.2.11"
      ],
      "primary_category": "cs.DC",
      "comment": "5 Pages, 1 Figure, 2 Tables",
      "pdf_url": "http://arxiv.org/pdf/2404.03665v1",
      "published_date": "2024-02-16 16:46:10 UTC",
      "updated_date": "2024-02-16 16:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:58:43.723160"
    },
    {
      "arxiv_id": "2404.07208v1",
      "title": "Uncertainty-guided annotation enhances segmentation with the human-in-the-loop",
      "title_zh": "翻译失败",
      "authors": [
        "Nadieh Khalili",
        "Joey Spronck",
        "Francesco Ciompi",
        "Jeroen van der Laak",
        "Geert Litjens"
      ],
      "abstract": "Deep learning algorithms, often critiqued for their 'black box' nature,\ntraditionally fall short in providing the necessary transparency for trusted\nclinical use. This challenge is particularly evident when such models are\ndeployed in local hospitals, encountering out-of-domain distributions due to\nvarying imaging techniques and patient-specific pathologies. Yet, this\nlimitation offers a unique avenue for continual learning. The\nUncertainty-Guided Annotation (UGA) framework introduces a human-in-the-loop\napproach, enabling AI to convey its uncertainties to clinicians, effectively\nacting as an automated quality control mechanism. UGA eases this interaction by\nquantifying uncertainty at the pixel level, thereby revealing the model's\nlimitations and opening the door for clinician-guided corrections. We evaluated\nUGA on the Camelyon dataset for lymph node metastasis segmentation which\nrevealed that UGA improved the Dice coefficient (DC), from 0.66 to 0.76 by\nadding 5 patches, and further to 0.84 with 10 patches. To foster broader\napplication and community contribution, we have made our code accessible at",
      "tldr_zh": "本研究针对深度学习模型在临床应用中的“黑箱”性质和数据分布变异问题，提出Uncertainty-Guided Annotation (UGA)框架，该框架采用human-in-the-loop方法，让AI通过像素级不确定性量化来揭示其局限性，并允许临床医生进行指导修正。UGA作为一种自动化质量控制机制，有效提升了图像分割的准确性。在Camelyon数据集的淋巴结转移分割任务中，实验结果显示添加5个patches将Dice coefficient (DC)从0.66提高到0.76，添加10个patches进一步提升到0.84，从而为可信赖的持续学习提供了新途径。代码已开源，以促进社区应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07208v1",
      "published_date": "2024-02-16 16:41:15 UTC",
      "updated_date": "2024-02-16 16:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:58:57.399898"
    },
    {
      "arxiv_id": "2402.10805v1",
      "title": "Generative Cross-Modal Retrieval: Memorizing Images in Multimodal Language Models for Retrieval and Beyond",
      "title_zh": "生成式跨模态检索：在多模态语言模型中记忆图像用于检索及更多",
      "authors": [
        "Yongqi Li",
        "Wenjie Wang",
        "Leigang Qu",
        "Liqiang Nie",
        "Wenjie Li",
        "Tat-Seng Chua"
      ],
      "abstract": "The recent advancements in generative language models have demonstrated their\nability to memorize knowledge from documents and recall knowledge to respond to\nuser queries effectively. Building upon this capability, we propose to enable\nmultimodal large language models (MLLMs) to memorize and recall images within\ntheir parameters. Given a user query for visual content, the MLLM is\nanticipated to \"recall\" the relevant image from its parameters as the response.\nAchieving this target presents notable challenges, including inbuilt visual\nmemory and visual recall schemes within MLLMs. To address these challenges, we\nintroduce a generative cross-modal retrieval framework, which assigns unique\nidentifier strings to represent images and involves two training steps:\nlearning to memorize and learning to retrieve. The first step focuses on\ntraining the MLLM to memorize the association between images and their\nrespective identifiers. The latter step teaches the MLLM to generate the\ncorresponding identifier of the target image, given the textual query input. By\nmemorizing images in MLLMs, we introduce a new paradigm to cross-modal\nretrieval, distinct from previous discriminative approaches. The experiments\ndemonstrate that the generative paradigm performs effectively and efficiently\neven with large-scale image candidate sets.",
      "tldr_zh": "本研究提出了一种生成式跨模态检索框架，旨在让 Multimodal Large Language Models (MLLMs) 通过参数记忆图像，并根据用户文本查询回忆相关图像，从而实现高效的跨模态检索。该框架使用唯一标识符来表示图像，并涉及两个训练步骤：首先训练 MLLMs 学习图像与标识符的关联，其次训练模型生成查询对应的标识符，与传统判别式方法不同，这种生成式范式提供了一种新颖的检索方式。实验结果表明，该方法在大型图像候选集上表现出色，既有效又高效。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10805v1",
      "published_date": "2024-02-16 16:31:46 UTC",
      "updated_date": "2024-02-16 16:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:59:08.842865"
    },
    {
      "arxiv_id": "2402.10803v1",
      "title": "Modelling crypto markets by multi-agent reinforcement learning",
      "title_zh": "翻译失败",
      "authors": [
        "Johann Lussange",
        "Stefano Vrizzi",
        "Stefano Palminteri",
        "Boris Gutkin"
      ],
      "abstract": "Building on a previous foundation work (Lussange et al. 2020), this study\nintroduces a multi-agent reinforcement learning (MARL) model simulating crypto\nmarkets, which is calibrated to the Binance's daily closing prices of $153$\ncryptocurrencies that were continuously traded between 2018 and 2022. Unlike\nprevious agent-based models (ABM) or multi-agent systems (MAS) which relied on\nzero-intelligence agents or single autonomous agent methodologies, our approach\nrelies on endowing agents with reinforcement learning (RL) techniques in order\nto model crypto markets. This integration is designed to emulate, with a\nbottom-up approach to complexity inference, both individual and collective\nagents, ensuring robustness in the recent volatile conditions of such markets\nand during the COVID-19 era. A key feature of our model also lies in the fact\nthat its autonomous agents perform asset price valuation based on two sources\nof information: the market prices themselves, and the approximation of the\ncrypto assets fundamental values beyond what those market prices are. Our MAS\ncalibration against real market data allows for an accurate emulation of crypto\nmarkets microstructure and probing key market behaviors, in both the bearish\nand bullish regimes of that particular time period.",
      "tldr_zh": "本研究基于先前工作（Lussange et al. 2020），提出了一种多智能体强化学习（MARL）模型，用于模拟加密货币市场，并使用 Binance 平台 2018-2022 年 153 种加密货币的每日收盘价进行校准。不同于以往依赖零智能代理或单一自主代理的 agent-based models (ABM) 或 multi-agent systems (MAS)，该模型赋予代理 reinforcement learning (RL) 技术，使其基于市场价格和加密资产基本价值的近似进行决策，从而实现自下而上的复杂性推理。实验结果显示，该模型能准确模拟加密市场的微观结构，并在熊市和牛市条件下（如 COVID-19 时期）展现出稳健性，并有效探测关键市场行为。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10803v1",
      "published_date": "2024-02-16 16:28:58 UTC",
      "updated_date": "2024-02-16 16:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:59:20.946773"
    },
    {
      "arxiv_id": "2402.10798v1",
      "title": "VATr++: Choose Your Words Wisely for Handwritten Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Bram Vanherle",
        "Vittorio Pippi",
        "Silvia Cascianelli",
        "Nick Michiels",
        "Frank Van Reeth",
        "Rita Cucchiara"
      ],
      "abstract": "Styled Handwritten Text Generation (HTG) has received significant attention\nin recent years, propelled by the success of learning-based solutions employing\nGANs, Transformers, and, preliminarily, Diffusion Models. Despite this surge in\ninterest, there remains a critical yet understudied aspect - the impact of the\ninput, both visual and textual, on the HTG model training and its subsequent\ninfluence on performance. This study delves deeper into a cutting-edge\nStyled-HTG approach, proposing strategies for input preparation and training\nregularization that allow the model to achieve better performance and\ngeneralize better. These aspects are validated through extensive analysis on\nseveral different settings and datasets. Moreover, in this work, we go beyond\nperformance optimization and address a significant hurdle in HTG research - the\nlack of a standardized evaluation protocol. In particular, we propose a\nstandardization of the evaluation protocol for HTG and conduct a comprehensive\nbenchmarking of existing approaches. By doing so, we aim to establish a\nfoundation for fair and meaningful comparisons between HTG strategies,\nfostering progress in the field.",
      "tldr_zh": "该研究探讨了 Handwritten Text Generation (HTG) 的关键问题，强调输入（视觉和文本）对模型训练和性能的影响，并提出输入准备策略和训练正则化方法，以提升基于 GANs、Transformers 和 Diffusion Models 的 HTG 模型的性能和泛化能力。研究通过在多种设置和数据集上的广泛实验进行验证，证明这些策略的有效性。此外，论文标准化了 HTG 的评估协议，并对现有方法进行全面基准测试，以建立公平的比较基础，推动该领域的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10798v1",
      "published_date": "2024-02-16 16:21:15 UTC",
      "updated_date": "2024-02-16 16:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:59:33.033843"
    },
    {
      "arxiv_id": "2402.10793v2",
      "title": "An end-to-end attention-based approach for learning on graphs",
      "title_zh": "翻译失败",
      "authors": [
        "David Buterez",
        "Jon Paul Janet",
        "Dino Oglic",
        "Pietro Lio"
      ],
      "abstract": "There has been a recent surge in transformer-based architectures for learning\non graphs, mainly motivated by attention as an effective learning mechanism and\nthe desire to supersede handcrafted operators characteristic of message passing\nschemes. However, concerns over their empirical effectiveness, scalability, and\ncomplexity of the pre-processing steps have been raised, especially in relation\nto much simpler graph neural networks that typically perform on par with them\nacross a wide range of benchmarks. To tackle these shortcomings, we consider\ngraphs as sets of edges and propose a purely attention-based approach\nconsisting of an encoder and an attention pooling mechanism. The encoder\nvertically interleaves masked and vanilla self-attention modules to learn an\neffective representations of edges, while allowing for tackling possible\nmisspecifications in input graphs. Despite its simplicity, the approach\noutperforms fine-tuned message passing baselines and recently proposed\ntransformer-based methods on more than 70 node and graph-level tasks, including\nchallenging long-range benchmarks. Moreover, we demonstrate state-of-the-art\nperformance across different tasks, ranging from molecular to vision graphs,\nand heterophilous node classification. The approach also outperforms graph\nneural networks and transformers in transfer learning settings, and scales much\nbetter than alternatives with a similar performance level or expressive power.",
      "tldr_zh": "本研究提出了一种端到-end attention-based 方法，用于图学习，将图视为边集，并设计了一个编码器和注意力池化机制。编码器通过交错 masked 和 vanilla 自-attention 模块学习边的有效表示，同时处理输入图的潜在错误。该方法尽管简单，却在超过70个节点和图级任务上超越了微调的消息传递基线和现有Transformer模型，并在分子图、视觉图以及异质节点分类等任务中实现最先进性能；此外，它在迁移学习设置中表现出色，并具有更好的可伸缩性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10793v2",
      "published_date": "2024-02-16 16:20:11 UTC",
      "updated_date": "2024-12-06 15:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:59:44.251335"
    },
    {
      "arxiv_id": "2402.10998v3",
      "title": "Provably Safe Neural Network Controllers via Differential Dynamic Logic",
      "title_zh": "通过差分动态逻辑的可证明安全神经网络控制器",
      "authors": [
        "Samuel Teuber",
        "Stefan Mitsch",
        "André Platzer"
      ],
      "abstract": "While neural networks (NNs) have potential as autonomous controllers for\nCyber-Physical Systems, verifying the safety of NN based control systems\n(NNCSs) poses significant challenges for the practical use of NNs, especially\nwhen safety is needed for unbounded time horizons. One reason is the\nintractability of analyzing NNs, ODEs and hybrid systems. To this end, we\nintroduce VerSAILLE (Verifiably Safe AI via Logically Linked Envelopes): The\nfirst general approach that allows reusing control theory results for NNCS\nverification. By joining forces, we exploit the efficiency of NN verification\ntools while retaining the rigor of differential dynamic logic (dL). Based on\nprovably safe control envelopes in dL, we derive specifications for the NN\nwhich is proven via NN verification. We show that a proof of the NN adhering to\nthe specification is mirrored by a dL proof on the infinite-time safety of the\nNNCS.\n  The NN verification properties resulting from hybrid systems typically\ncontain nonlinear arithmetic and arbitrary logical structures while efficient\nNN verification merely supports linear constraints. To overcome this divide, we\npresent Mosaic: An efficient, sound and complete verification approach for\npolynomial real arithmetic properties on piece-wise linear NNs. Mosaic\npartitions complex verification queries into simple queries and lifts\noff-the-shelf linear constraint tools to the nonlinear setting in a\ncompleteness-preserving manner by combining approximation with exact reasoning\nfor counterexample regions. Our evaluation demonstrates the versatility of\nVerSAILLE and Mosaic: We prove infinite-time safety on the classical Vertical\nAirborne Collision Avoidance NNCS verification benchmark for two scenarios\nwhile (exhaustively) enumerating counterexample regions in unsafe scenarios. We\nalso show that our approach significantly outperforms State-of-the-Art tools in\nclosed-loop NNV.",
      "tldr_zh": "该研究提出VerSAILLE，一种通用方法，通过微分动态逻辑(dL)结合神经网络(NN)验证工具，解决基于NN的控制系统(NNCS)在无限时间地平线上的安全验证挑战。该方法利用dL的安全控制包络推导出NN规范，并通过证明NN符合规范来确保NNCS的无限时间安全。为处理混合系统中的非线性算术问题，引入Mosaic，这是一个高效、可靠且完整的验证方法，能将复杂查询分解为简单线性约束，并结合近似和精确推理。实验结果显示，VerSAILLE和Mosaic在经典垂直空中碰撞避免基准上成功证明了无限时间安全，并在不安全场景中枚举反例，同时在闭环NNV中显著优于现有工具。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "39 pages (main paper has 10 pages), 13 figures; Accepted at the\n  Thirty-Eighth Annual Conference on Neural Information Processing Systems\n  (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.10998v3",
      "published_date": "2024-02-16 16:15:25 UTC",
      "updated_date": "2024-10-24 15:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:59:57.313704"
    },
    {
      "arxiv_id": "2402.10790v2",
      "title": "In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss",
      "title_zh": "翻译失败",
      "authors": [
        "Yuri Kuratov",
        "Aydar Bulatov",
        "Petr Anokhin",
        "Dmitry Sorokin",
        "Artyom Sorokin",
        "Mikhail Burtsev"
      ],
      "abstract": "This paper addresses the challenge of processing long documents using\ngenerative transformer models. To evaluate different approaches, we introduce\nBABILong, a new benchmark designed to assess model capabilities in extracting\nand processing distributed facts within extensive texts. Our evaluation, which\nincludes benchmarks for GPT-4 and RAG, reveals that common methods are\neffective only for sequences up to $10^4$ elements. In contrast, fine-tuning\nGPT-2 with recurrent memory augmentations enables it to handle tasks involving\nup to $11\\times 10^6$ elements. This achievement marks a substantial leap, as\nit is by far the longest input processed by any neural network model to date,\ndemonstrating a significant improvement in the processing capabilities for long\nsequences.",
      "tldr_zh": "这篇论文探讨了生成 transformer 模型处理长文档的挑战，引入了 BABILong 基准测试来评估模型提取和处理分布式事实的能力。评估结果显示，GPT-4 和 RAG 等常见方法仅适用于序列长度达 $10^4$ 元素的任务，而无法有效处理更长文本。相比之下，通过微调 GPT-2 并添加 recurrent memory augmentations，该方法实现了处理高达 $11\\times 10^6$ 元素的任务，标志着神经网络长序列处理能力的重大突破。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11M tokens, fix qa3 min facts per task in Table 1",
      "pdf_url": "http://arxiv.org/pdf/2402.10790v2",
      "published_date": "2024-02-16 16:15:01 UTC",
      "updated_date": "2024-02-21 03:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:00:10.094159"
    },
    {
      "arxiv_id": "2402.10787v1",
      "title": "EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for the Acceleration of Lightweight LLMs on the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Shen",
        "Zhenglun Kong",
        "Changdi Yang",
        "Zhaoyang Han",
        "Lei Lu",
        "Peiyan Dong",
        "Cheng Lyu",
        "Chih-hsiang Li",
        "Xuehang Guo",
        "Zhihao Shu",
        "Wei Niu",
        "Miriam Leeser",
        "Pu Zhao",
        "Yanzhi Wang"
      ],
      "abstract": "Despite the remarkable strides of Large Language Models (LLMs) in various\nfields, the wide applications of LLMs on edge devices are limited due to their\nmassive parameters and computations. To address this, quantization is commonly\nadopted to generate lightweight LLMs with efficient computations and fast\ninference. However, Post-Training Quantization (PTQ) methods dramatically\ndegrade in quality when quantizing weights, activations, and KV cache together\nto below 8 bits. Besides, many Quantization-Aware Training (QAT) works quantize\nmodel weights, leaving the activations untouched, which do not fully exploit\nthe potential of quantization for inference acceleration on the edge. In this\npaper, we propose EdgeQAT, the Entropy and Distribution Guided QAT for the\noptimization of lightweight LLMs to achieve inference acceleration on Edge\ndevices. We first identify that the performance drop of quantization primarily\nstems from the information distortion in quantized attention maps, demonstrated\nby the different distributions in quantized query and key of the self-attention\nmechanism. Then, the entropy and distribution guided QAT is proposed to\nmitigate the information distortion. Moreover, we design a token\nimportance-aware adaptive method to dynamically quantize the tokens with\ndifferent bit widths for further optimization and acceleration. Our extensive\nexperiments verify the substantial improvements with our framework across\nvarious datasets. Furthermore, we achieve an on-device speedup of up to 2.37x\ncompared with its FP16 counterparts across multiple edge devices, signaling a\ngroundbreaking advancement.",
      "tldr_zh": "本论文针对大型语言模型(LLMs)在边设备上的计算和参数负担问题，提出了一种熵和分布引导的量化感知训练(EdgeQAT)框架，以实现轻量级LLMs的加速。EdgeQAT首先识别量化过程中注意力机制(query和key)的信息失真问题，并通过熵和分布引导的QAT方法来缓解这一问题，同时引入基于token重要性的自适应量化策略，以动态调整不同token的位宽。实验结果显示，该框架在多种数据集上显著提升性能，并在多个边设备上实现高达2.37倍的推理加速，相比FP16基准模型取得了突破性进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.10787v1",
      "published_date": "2024-02-16 16:10:38 UTC",
      "updated_date": "2024-02-16 16:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:00:22.087056"
    },
    {
      "arxiv_id": "2402.10778v2",
      "title": "AutoGPT+P: Affordance-based Task Planning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Timo Birr",
        "Christoph Pohl",
        "Abdelrahman Younes",
        "Tamim Asfour"
      ],
      "abstract": "Recent advances in task planning leverage Large Language Models (LLMs) to\nimprove generalizability by combining such models with classical planning\nalgorithms to address their inherent limitations in reasoning capabilities.\nHowever, these approaches face the challenge of dynamically capturing the\ninitial state of the task planning problem. To alleviate this issue, we propose\nAutoGPT+P, a system that combines an affordance-based scene representation with\na planning system. Affordances encompass the action possibilities of an agent\non the environment and objects present in it. Thus, deriving the planning\ndomain from an affordance-based scene representation allows symbolic planning\nwith arbitrary objects. AutoGPT+P leverages this representation to derive and\nexecute a plan for a task specified by the user in natural language. In\naddition to solving planning tasks under a closed-world assumption, AutoGPT+P\ncan also handle planning with incomplete information, e. g., tasks with missing\nobjects by exploring the scene, suggesting alternatives, or providing a partial\nplan. The affordance-based scene representation combines object detection with\nan automatically generated object-affordance-mapping using ChatGPT. The core\nplanning tool extends existing work by automatically correcting semantic and\nsyntactic errors. Our approach achieves a success rate of 98%, surpassing the\ncurrent 81% success rate of the current state-of-the-art LLM-based planning\nmethod SayCan on the SayCan instruction set. Furthermore, we evaluated our\napproach on our newly created dataset with 150 scenarios covering a wide range\nof complex tasks with missing objects, achieving a success rate of 79% on our\ndataset. The dataset and the code are publicly available at\nhttps://git.h2t.iar.kit.edu/birr/autogpt-p-standalone.",
      "tldr_zh": "该研究提出 AutoGPT+P 系统，结合 Large Language Models (LLMs) 和基于 affordance 的场景表示，解决任务规划中动态捕获初始状态的挑战。系统通过 affordance（代理对环境和对象的行动可能性）派生规划域，支持符号规划，并能处理封闭世界假设下的任务以及不完整信息场景，如缺少对象时的探索、替代建议或部分计划。实验结果显示，AutoGPT+P 在 SayCan 指令集上实现98%的成功率，优于现有方法的81%；在新创建的150个场景数据集上，成功率达79%，并公开了数据集和代码。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, 18 pages including references and appendix, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.10778v2",
      "published_date": "2024-02-16 16:00:50 UTC",
      "updated_date": "2024-07-23 14:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:00:35.012575"
    },
    {
      "arxiv_id": "2402.10774v1",
      "title": "Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Richtárik",
        "Elnur Gasanov",
        "Konstantin Burlachenko"
      ],
      "abstract": "Error Feedback (EF) is a highly popular and immensely effective mechanism for\nfixing convergence issues which arise in distributed training methods (such as\ndistributed GD or SGD) when these are enhanced with greedy communication\ncompression techniques such as TopK. While EF was proposed almost a decade ago\n(Seide et al., 2014), and despite concentrated effort by the community to\nadvance the theoretical understanding of this mechanism, there is still a lot\nto explore. In this work we study a modern form of error feedback called EF21\n(Richtarik et al., 2021) which offers the currently best-known theoretical\nguarantees, under the weakest assumptions, and also works well in practice. In\nparticular, while the theoretical communication complexity of EF21 depends on\nthe quadratic mean of certain smoothness parameters, we improve this dependence\nto their arithmetic mean, which is always smaller, and can be substantially\nsmaller, especially in heterogeneous data regimes. We take the reader on a\njourney of our discovery process. Starting with the idea of applying EF21 to an\nequivalent reformulation of the underlying problem which (unfortunately)\nrequires (often impractical) machine cloning, we continue to the discovery of a\nnew weighted version of EF21 which can (fortunately) be executed without any\ncloning, and finally circle back to an improved analysis of the original EF21\nmethod. While this development applies to the simplest form of EF21, our\napproach naturally extends to more elaborate variants involving stochastic\ngradients and partial participation. Further, our technique improves the\nbest-known theory of EF21 in the rare features regime (Richtarik et al., 2023).\nFinally, we validate our theoretical findings with suitable experiments.",
      "tldr_zh": "本研究探讨了 Error Feedback (EF) 机制在分布式训练中的改进，特别是针对分布式 GD 或 SGD 与通信压缩技术（如 TopK）结合时存在的收敛问题。论文提出将 EF21 的理论通信复杂度从依赖于平方的均值（quadratic mean）优化为算术均值（arithmetic mean），这在异质数据环境中显著降低了复杂度。研究过程包括应用加权版本 EF21 和改进原始分析，同时扩展到随机梯度和部分参与的变体，并通过实验验证了这些理论提升。最终，该方法改进了 EF21 在稀有特征制度中的性能，为高效分布式训练提供了更可靠的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML",
        "90C26, 74Pxx",
        "G.1.6; I.2.11; I.2.m"
      ],
      "primary_category": "cs.LG",
      "comment": "70 pages, 14 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.10774v1",
      "published_date": "2024-02-16 15:55:59 UTC",
      "updated_date": "2024-02-16 15:55:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:00:46.742959"
    },
    {
      "arxiv_id": "2402.10770v4",
      "title": "How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Doostmohammadi",
        "Oskar Holmström",
        "Marco Kuhlmann"
      ],
      "abstract": "Work on instruction-tuned Large Language Models (LLMs) has used automatic\nmethods based on text overlap and LLM judgments as cost-effective alternatives\nto human evaluation. In this paper, we perform a meta-evaluation of such\nmethods and assess their reliability across a broad range of tasks. In\nevaluating how well automatic methods align with human evaluations, correlation\nmetrics are the most commonly employed method despite their inherent\nlimitations when dealing with ties and different scales. To address these\nshortcomings, we use Pairwise Accuracy as an alternative to standard\ncorrelation measures. We observe that while automatic evaluation methods can\napproximate human ratings under specific conditions, their validity is highly\ncontext-dependent. Specifically, the simple ROUGE-L metric correlates very well\nwith human ratings for short-answer English tasks but is unreliable in\nfree-form generation tasks and cross-lingual scenarios. The effectiveness of\nthe more advanced method of using GPT-4 as a judge diminishes significantly if\nreference answers are not included in the prompt, which is the scenario where\nthis method has the potential to provide the most value compared to other\nmetrics. Our findings enhance the understanding of how automatic methods should\nbe applied and interpreted when developing and evaluating instruction-tuned\nLLMs.",
      "tldr_zh": "这篇论文评估了自动评估方法（如基于文本重叠和LLM判断的指标）在指令调整大型语言模型(LLMs)中的可靠性，作为人类评估的替代方案。作者通过元评估(meta-evaluation)和引入Pairwise Accuracy作为替代相关性指标，测试了这些方法在各种任务中的表现。研究发现，ROUGE-L在英语短答任务中与人类评分高度相关，但对自由生成任务和跨语言场景无效，而GPT-4作为评判者仅在包含参考答案的提示下才有效。这些发现有助于更好地应用和解释自动方法，以提升指令调整LLMs的开发和评估过程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10770v4",
      "published_date": "2024-02-16 15:48:33 UTC",
      "updated_date": "2024-10-02 09:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:00:58.940237"
    },
    {
      "arxiv_id": "2402.10769v1",
      "title": "Distillation Enhanced Generative Retrieval",
      "title_zh": "蒸馏增强生成式检索",
      "authors": [
        "Yongqi Li",
        "Zhen Zhang",
        "Wenjie Wang",
        "Liqiang Nie",
        "Wenjie Li",
        "Tat-Seng Chua"
      ],
      "abstract": "Generative retrieval is a promising new paradigm in text retrieval that\ngenerates identifier strings of relevant passages as the retrieval target. This\nparadigm leverages powerful generative language models, distinct from\ntraditional sparse or dense retrieval methods. In this work, we identify a\nviable direction to further enhance generative retrieval via distillation and\npropose a feasible framework, named DGR. DGR utilizes sophisticated ranking\nmodels, such as the cross-encoder, in a teacher role to supply a passage rank\nlist, which captures the varying relevance degrees of passages instead of\nbinary hard labels; subsequently, DGR employs a specially designed distilled\nRankNet loss to optimize the generative retrieval model, considering the\npassage rank order provided by the teacher model as labels. This framework only\nrequires an additional distillation step to enhance current generative\nretrieval systems and does not add any burden to the inference stage. We\nconduct experiments on four public datasets, and the results indicate that DGR\nachieves state-of-the-art performance among the generative retrieval methods.\nAdditionally, DGR demonstrates exceptional robustness and generalizability with\nvarious teacher models and distillation losses.",
      "tldr_zh": "本论文提出了一种名为 DGR 的框架，通过知识蒸馏（distillation）增强生成式检索（generative retrieval），以生成相关段落的标识符字符串作为检索目标。DGR 利用 cross-encoder 等高级排名模型作为教师模型，提供段落的排名列表，然后通过专门设计的蒸馏 RankNet 损失优化生成式检索模型，从而考虑段落的相对相关度。实验结果显示，在四个公共数据集上，DGR 达到了生成式检索方法的最先进性能，并展示了与各种教师模型和蒸馏损失的出色鲁棒性和泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10769v1",
      "published_date": "2024-02-16 15:48:24 UTC",
      "updated_date": "2024-02-16 15:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:01:10.665608"
    },
    {
      "arxiv_id": "2402.10767v2",
      "title": "Inference to the Best Explanation in Large Language Models",
      "title_zh": "大语言模型中的最佳解释推论",
      "authors": [
        "Dhairya Dalal",
        "Marco Valentino",
        "André Freitas",
        "Paul Buitelaar"
      ],
      "abstract": "While Large Language Models (LLMs) have found success in real-world\napplications, their underlying explanatory process is still poorly understood.\nThis paper proposes IBE-Eval, a framework inspired by philosophical accounts on\nInference to the Best Explanation (IBE) to advance the interpretation and\nevaluation of LLMs' explanations. IBE-Eval estimates the plausibility of\nnatural language explanations through a combination of explicit logical and\nlinguistic features including: consistency, parsimony, coherence, and\nuncertainty. Extensive experiments are conducted on Causal Question Answering\n(CQA), where \\textit{IBE-Eval} is tasked to select the most plausible causal\nexplanation amongst competing ones generated by LLMs (i.e., GPT 3.5 and Llama\n2). The experiments reveal that IBE-Eval can successfully identify the best\nexplanation with up to 77\\% accuracy ($\\approx 27\\%$ above random), improving\nupon a GPT 3.5-as-a-Judge baseline ($\\approx+17\\%$) while being intrinsically\nmore efficient and interpretable. Additional analyses suggest that, despite\nmodel-specific variances, LLM-generated explanations tend to conform to IBE\ncriteria and that IBE-Eval is significantly correlated with human judgment,\nopening up opportunities for future development of automated explanation\nverification tools.",
      "tldr_zh": "这篇论文提出 IBE-Eval 框架，受 Inference to the Best Explanation (IBE) 哲学启发，用于评估大型语言模型 (LLMs) 的解释质量。\n该框架通过结合一致性、简洁性、连贯性和不确定性等显式逻辑和语言特征，来判断自然语言解释的合理性，并在因果问题回答 (CQA) 任务中从 LLMs（如 GPT 3.5 和 Llama 2）生成的竞争解释中选出最佳解释。\n实验结果显示，IBE-Eval 的准确率高达 77%（比随机基准高 27%，优于 GPT 3.5-as-a-Judge 基准高 17%），且更高效和可解释。\n此外，分析表明 LLMs 生成的解释通常符合 IBE 标准，并与人类判断高度相关，为未来开发自动解释验证工具提供了机会。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10767v2",
      "published_date": "2024-02-16 15:41:23 UTC",
      "updated_date": "2025-03-02 20:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:01:23.850834"
    },
    {
      "arxiv_id": "2402.10765v1",
      "title": "Policy Learning for Off-Dynamics RL with Deficient Support",
      "title_zh": "翻译失败",
      "authors": [
        "Linh Le Pham Van",
        "Hung The Tran",
        "Sunil Gupta"
      ],
      "abstract": "Reinforcement Learning (RL) can effectively learn complex policies. However,\nlearning these policies often demands extensive trial-and-error interactions\nwith the environment. In many real-world scenarios, this approach is not\npractical due to the high costs of data collection and safety concerns. As a\nresult, a common strategy is to transfer a policy trained in a low-cost, rapid\nsource simulator to a real-world target environment. However, this process\nposes challenges. Simulators, no matter how advanced, cannot perfectly\nreplicate the intricacies of the real world, leading to dynamics discrepancies\nbetween the source and target environments. Past research posited that the\nsource domain must encompass all possible target transitions, a condition we\nterm full support. However, expecting full support is often unrealistic,\nespecially in scenarios where significant dynamics discrepancies arise. In this\npaper, our emphasis shifts to addressing large dynamics mismatch adaptation. We\nmove away from the stringent full support condition of earlier research,\nfocusing instead on crafting an effective policy for the target domain. Our\nproposed approach is simple but effective. It is anchored in the central\nconcepts of the skewing and extension of source support towards target support\nto mitigate support deficiencies. Through comprehensive testing on a varied set\nof benchmarks, our method's efficacy stands out, showcasing notable\nimprovements over previous techniques.",
      "tldr_zh": "该论文探讨了在动态差异（Off-Dynamics）强化学习（RL）环境中，如何处理源域支持不足（Deficient Support）的问题。传统方法要求源域完全覆盖目标转移，但作者指出这不切实际，并提出一种简单有效的策略，通过源支持的倾斜（skewing）和扩展（extension）来缓解支持缺失，从而适应目标域。实验结果显示，该方法在多种基准测试中显著优于现有技术，提供了一种更实用的政策学习方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAMAS 2024 as a full paper",
      "pdf_url": "http://arxiv.org/pdf/2402.10765v1",
      "published_date": "2024-02-16 15:39:51 UTC",
      "updated_date": "2024-02-16 15:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:01:34.432875"
    },
    {
      "arxiv_id": "2402.10762v1",
      "title": "On Explaining Unfairness: An Overview",
      "title_zh": "翻译失败",
      "authors": [
        "Christos Fragkathoulas",
        "Vasiliki Papanikou",
        "Danae Pla Karidi",
        "Evaggelia Pitoura"
      ],
      "abstract": "Algorithmic fairness and explainability are foundational elements for\nachieving responsible AI. In this paper, we focus on their interplay, a\nresearch area that is recently receiving increasing attention. To this end, we\nfirst present two comprehensive taxonomies, each representing one of the two\ncomplementary fields of study: fairness and explanations. Then, we categorize\nexplanations for fairness into three types: (a) Explanations to enhance\nfairness metrics, (b) Explanations to help us understand the causes of\n(un)fairness, and (c) Explanations to assist us in designing methods for\nmitigating unfairness. Finally, based on our fairness and explanation\ntaxonomies, we present undiscovered literature paths revealing gaps that can\nserve as valuable insights for future research.",
      "tldr_zh": "本综述论文探讨了算法公平性（algorithmic fairness）和可解释性（explainability）在负责任AI中的互动关系，提出了两个全面的分类系统：一个用于公平性领域，另一个用于解释领域。论文将针对公平性的解释分为三类：(a) 增强公平性指标的解释，(b) 帮助理解不公平原因的解释，以及(c) 协助设计缓解不公平方法的解释。基于这些分类，论文识别出文献中的空白，并提出未被探索的研究路径，为未来研究提供宝贵洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10762v1",
      "published_date": "2024-02-16 15:38:00 UTC",
      "updated_date": "2024-02-16 15:38:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:01:44.853644"
    },
    {
      "arxiv_id": "2402.13270v1",
      "title": "Global Tropical Cyclone Intensity Forecasting with Multi-modal Multi-scale Causal Autoregressive Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Wang",
        "Kang Chen",
        "Lei Liu",
        "Tao Han",
        "Bin Li",
        "Lei Bai"
      ],
      "abstract": "Accurate forecasting of Tropical cyclone (TC) intensity is crucial for\nformulating disaster risk reduction strategies. Current methods predominantly\nrely on limited spatiotemporal information from ERA5 data and neglect the\ncausal relationships between these physical variables, failing to fully capture\nthe spatial and temporal patterns required for intensity forecasting. To\naddress this issue, we propose a Multi-modal multi-Scale Causal AutoRegressive\nmodel (MSCAR), which is the first model that combines causal relationships with\nlarge-scale multi-modal data for global TC intensity autoregressive\nforecasting. Furthermore, given the current absence of a TC dataset that offers\na wide range of spatial variables, we present the Satellite and ERA5-based\nTropical Cyclone Dataset (SETCD), which stands as the longest and most\ncomprehensive global dataset related to TCs. Experiments on the dataset show\nthat MSCAR outperforms the state-of-the-art methods, achieving maximum\nreductions in global and regional forecast errors of 9.52% and 6.74%,\nrespectively. The code and dataset are publicly available at\nhttps://anonymous.4open.science/r/MSCAR.",
      "tldr_zh": "该论文提出了一种 Multi-modal Multi-scale Causal Autoregressive model (MSCAR)，首次将因果关系与大规模多模态数据相结合，用于全球热带气旋强度自回归预测，从而克服现有方法忽略变量间因果联系的局限性。同时，研究团队构建了 Satellite and ERA5-based Tropical Cyclone Dataset (SETCD)，这是一份最长且最全面的全球热带气旋数据集，提供丰富的空间变量支持。在实验中，MSCAR 在该数据集上优于现有方法，实现了全球和区域预测错误的最大减少分别为 9.52% 和 6.74%。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG",
        "physics.data-an"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13270v1",
      "published_date": "2024-02-16 15:26:33 UTC",
      "updated_date": "2024-02-16 15:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:01:58.780790"
    },
    {
      "arxiv_id": "2402.10756v1",
      "title": "Towards Cohesion-Fairness Harmony: Contrastive Regularization in Individual Fair Graph Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Siamak Ghodsi",
        "Seyed Amjad Seyedi",
        "Eirini Ntoutsi"
      ],
      "abstract": "Conventional fair graph clustering methods face two primary challenges: i)\nThey prioritize balanced clusters at the expense of cluster cohesion by\nimposing rigid constraints, ii) Existing methods of both individual and\ngroup-level fairness in graph partitioning mostly rely on eigen decompositions\nand thus, generally lack interpretability. To address these issues, we propose\niFairNMTF, an individual Fairness Nonnegative Matrix Tri-Factorization model\nwith contrastive fairness regularization that achieves balanced and cohesive\nclusters. By introducing fairness regularization, our model allows for\ncustomizable accuracy-fairness trade-offs, thereby enhancing user autonomy\nwithout compromising the interpretability provided by nonnegative matrix\ntri-factorization. Experimental evaluations on real and synthetic datasets\ndemonstrate the superior flexibility of iFairNMTF in achieving fairness and\nclustering performance.",
      "tldr_zh": "该论文针对传统公平图聚类方法的不足——即强硬约束导致集群凝聚力下降，以及依赖特征分解缺乏可解释性——提出了一种新的模型 iFairNMTF（Individual Fairness Nonnegative Matrix Tri-Factorization）。iFairNMTF 通过引入对比公平正则化（contrastive fairness regularization），实现了平衡且凝聚的集群，同时允许用户自定义准确性和公平性之间的权衡，从而提升了自主性和可解释性。实验在真实和合成数据集上证明，该模型在公平性和聚类性能方面表现出色，具有更高的灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "cs.SI",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in \"The 28th Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD 2024)\"",
      "pdf_url": "http://arxiv.org/pdf/2402.10756v1",
      "published_date": "2024-02-16 15:25:56 UTC",
      "updated_date": "2024-02-16 15:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:02:11.606031"
    },
    {
      "arxiv_id": "2402.10753v2",
      "title": "ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages",
      "title_zh": "ToolSword: 揭示大语言模型在工具学习中跨越三个阶段的安全问题",
      "authors": [
        "Junjie Ye",
        "Sixian Li",
        "Guanyu Li",
        "Caishuang Huang",
        "Songyang Gao",
        "Yilong Wu",
        "Qi Zhang",
        "Tao Gui",
        "Xuanjing Huang"
      ],
      "abstract": "Tool learning is widely acknowledged as a foundational approach or deploying\nlarge language models (LLMs) in real-world scenarios. While current research\nprimarily emphasizes leveraging tools to augment LLMs, it frequently neglects\nemerging safety considerations tied to their application. To fill this gap, we\npresent *ToolSword*, a comprehensive framework dedicated to meticulously\ninvestigating safety issues linked to LLMs in tool learning. Specifically,\nToolSword delineates six safety scenarios for LLMs in tool learning,\nencompassing **malicious queries** and **jailbreak attacks** in the input\nstage, **noisy misdirection** and **risky cues** in the execution stage, and\n**harmful feedback** and **error conflicts** in the output stage. Experiments\nconducted on 11 open-source and closed-source LLMs reveal enduring safety\nchallenges in tool learning, such as handling harmful queries, employing risky\ntools, and delivering detrimental feedback, which even GPT-4 is susceptible to.\nMoreover, we conduct further studies with the aim of fostering research on tool\nlearning safety. The data is released in\nhttps://github.com/Junjie-Ye/ToolSword.",
      "tldr_zh": "本研究提出ToolSword框架，用于系统调查大型语言模型（LLMs）在工具学习中的安全问题，填补了当前研究对安全考虑的忽视。框架将工具学习过程分为输入、执行和输出三个阶段，并定义了六种安全场景，包括输入阶段的恶意查询和jailbreak attacks、执行阶段的noisy misdirection和risky cues，以及输出阶段的有害反馈和error conflicts。在11个开源和闭源LLMs上的实验显示，这些模型存在持续的安全漏洞，如处理有害查询和使用风险工具，甚至GPT-4也未能幸免。该工作还发布了相关数据（https://github.com/Junjie-Ye/ToolSword），以推动工具学习安全领域的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2402.10753v2",
      "published_date": "2024-02-16 15:19:46 UTC",
      "updated_date": "2024-08-16 04:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:02:23.397799"
    },
    {
      "arxiv_id": "2402.10747v1",
      "title": "Fully Differentiable Lagrangian Convolutional Neural Network for Continuity-Consistent Physics-Informed Precipitation Nowcasting",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Pavlík",
        "Martin Výboh",
        "Anna Bou Ezzeddine",
        "Viera Rozinajová"
      ],
      "abstract": "This paper presents a convolutional neural network model for precipitation\nnowcasting that combines data-driven learning with physics-informed domain\nknowledge. We propose LUPIN, a Lagrangian Double U-Net for Physics-Informed\nNowcasting, that draws from existing extrapolation-based nowcasting methods and\nimplements the Lagrangian coordinate system transformation of the data in a\nfully differentiable and GPU-accelerated manner to allow for real-time\nend-to-end training and inference. Based on our evaluation, LUPIN matches and\nexceeds the performance of the chosen benchmark, opening the door for other\nLagrangian machine learning models.",
      "tldr_zh": "本研究提出了一种全可微分拉格朗日卷积神经网络模型LUPIN（Lagrangian Double U-Net for Physics-Informed Nowcasting），用于降水预报（precipitation nowcasting），它结合数据驱动学习和物理信息领域知识。LUPIN 通过完全可微分（Fully Differentiable）和GPU加速的方式实现拉格朗日坐标系转换，借鉴现有外推法方法，支持实时端到端训练和推理。实验结果显示，LUPIN的性能与基准模型相当或优于基准，为其他拉格朗日机器学习模型的应用打开了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "I.2.1; J.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.10747v1",
      "published_date": "2024-02-16 15:13:30 UTC",
      "updated_date": "2024-02-16 15:13:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:02:34.465536"
    },
    {
      "arxiv_id": "2402.10744v1",
      "title": "GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pengcheng Jiang",
        "Jiacheng Lin",
        "Zifeng Wang",
        "Jimeng Sun",
        "Jiawei Han"
      ],
      "abstract": "The field of relation extraction (RE) is experiencing a notable shift towards\ngenerative relation extraction (GRE), leveraging the capabilities of large\nlanguage models (LLMs). However, we discovered that traditional relation\nextraction (RE) metrics like precision and recall fall short in evaluating GRE\nmethods. This shortfall arises because these metrics rely on exact matching\nwith human-annotated reference relations, while GRE methods often produce\ndiverse and semantically accurate relations that differ from the references. To\nfill this gap, we introduce GenRES for a multi-dimensional assessment in terms\nof the topic similarity, uniqueness, granularity, factualness, and completeness\nof the GRE results. With GenRES, we empirically identified that (1)\nprecision/recall fails to justify the performance of GRE methods; (2)\nhuman-annotated referential relations can be incomplete; (3) prompting LLMs\nwith a fixed set of relations or entities can cause hallucinations. Next, we\nconducted a human evaluation of GRE methods that shows GenRES is consistent\nwith human preferences for RE quality. Last, we made a comprehensive evaluation\nof fourteen leading LLMs using GenRES across document, bag, and sentence level\nRE datasets, respectively, to set the benchmark for future research in GRE",
      "tldr_zh": "该研究重新审视了生成式关系抽取（GRE）在大型语言模型（LLMs）时代下的评估方法，发现传统指标如 precision 和 recall 无法有效评估 GRE，因为它们依赖精确匹配而忽略了关系的多样性和语义准确性。为此，作者提出 GenRES 框架，通过多维度评估（包括 topic similarity、uniqueness、granularity、factualness 和 completeness）来全面衡量 GRE 结果。实验结果显示，GenRES 揭示了传统指标的局限性（如人工标注关系的不完整性和提示导致的 hallucinations），并与人类偏好一致；此外，对 14 个领先 LLMs 在文档、bag 和句子级 RE 数据集上的评估为未来 GRE 研究设定了基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10744v1",
      "published_date": "2024-02-16 15:01:24 UTC",
      "updated_date": "2024-02-16 15:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:02:48.370829"
    },
    {
      "arxiv_id": "2404.04261v1",
      "title": "A Novel BERT-based Classifier to Detect Political Leaning of YouTube Videos based on their Titles",
      "title_zh": "翻译失败",
      "authors": [
        "Nouar AlDahoul",
        "Talal Rahwan",
        "Yasir Zaki"
      ],
      "abstract": "A quarter of US adults regularly get their news from YouTube. Yet, despite\nthe massive political content available on the platform, to date no classifier\nhas been proposed to identify the political leaning of YouTube videos. To fill\nthis gap, we propose a novel classifier based on Bert -- a language model from\nGoogle -- to classify YouTube videos merely based on their titles into six\ncategories, namely: Far Left, Left, Center, Anti-Woke, Right, and Far Right. We\nused a public dataset of 10 million YouTube video titles (under various\ncategories) to train and validate the proposed classifier. We compare the\nclassifier against several alternatives that we trained on the same dataset,\nrevealing that our classifier achieves the highest accuracy (75%) and the\nhighest F1 score (77%). To further validate the classification performance, we\ncollect videos from YouTube channels of numerous prominent news agencies, such\nas Fox News and New York Times, which have widely known political leanings, and\napply our classifier to their video titles. For the vast majority of cases, the\npredicted political leaning matches that of the news agency.",
      "tldr_zh": "本研究针对 YouTube 视频的政治倾向识别问题，提出一个基于 BERT 的新型分类器，仅通过视频标题将视频分类为 Far Left、Left、Center、Anti-Woke、Right 或 Far Right 六类。使用一个包含 10 million YouTube 视频标题的公共数据集进行训练和验证，该分类器在准确率 (75%) 和 F1 score (77%) 上优于其他备选模型。为了进一步验证，其在知名新闻机构（如 Fox News 和 New York Times）视频标题上的预测结果，大多数情况下与机构的实际政治倾向相符。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.04261v1",
      "published_date": "2024-02-16 14:44:30 UTC",
      "updated_date": "2024-02-16 14:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:02:59.747897"
    },
    {
      "arxiv_id": "2402.10726v4",
      "title": "Planning Domain Model Acquisition from State Traces without Action Parameters",
      "title_zh": "从不带动作参数的状态轨迹获取规划领域模型",
      "authors": [
        "Tomáš Balyo",
        "Martin Suda",
        "Lukáš Chrpa",
        "Dominik Šafránek",
        "Stephan Gocht",
        "Filip Dvořák",
        "Roman Barták",
        "G. Michael Youngblood"
      ],
      "abstract": "Existing planning action domain model acquisition approaches consider\ndifferent types of state traces from which they learn. The differences in state\ntraces refer to the level of observability of state changes (from full to none)\nand whether the observations have some noise (the state changes might be\ninaccurately logged). However, to the best of our knowledge, all the existing\napproaches consider state traces in which each state change corresponds to an\naction specified by its name and all its parameters (all objects that are\nrelevant to the action). Furthermore, the names and types of all the parameters\nof the actions to be learned are given. These assumptions are too strong.\n  In this paper, we propose a method that learns action schema from state\ntraces with fully observable state changes but without the parameters of\nactions responsible for the state changes (only action names are part of the\nstate traces). Although we can easily deduce the number (and names) of the\nactions that will be in the learned domain model, we still need to deduce the\nnumber and types of the parameters of each action alongside its precondition\nand effects. We show that this task is at least as hard as graph isomorphism.\nHowever, our experimental evaluation on a large collection of IPC benchmarks\nshows that our approach is still practical as the number of required parameters\nis usually small.\n  Compared to the state-of-the-art learning tools SAM and Extended SAM our new\nalgorithm is able to provide better results in multiple domains in terms of\nlearning action models more similar to reference models, even though it uses\nless information and has fewer restrictions on the input traces.",
      "tldr_zh": "本文提出了一种从不包含动作参数的状态 traces 中学习规划域模型的方法，仅使用动作名称和完全可观察的状态变化，从而克服现有方法的严格假设。该方法需推断动作的参数数量、类型、预条件和效果，并证明这一任务的难度至少与 graph isomorphism 问题相当。尽管面临挑战，实验在 IPC benchmarks 上显示，该算法在多个领域生成更接近参考模型的 action schema 结果，且比 state-of-the-art 工具 SAM 和 Extended SAM 表现更优，即使输入信息更少。总的来说，这一创新方法为更灵活的自动规划模型获取提供了实用途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10726v4",
      "published_date": "2024-02-16 14:36:58 UTC",
      "updated_date": "2025-03-07 10:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:03:11.485939"
    },
    {
      "arxiv_id": "2402.10725v2",
      "title": "Cloud Kitchen: Using Planning-based Composite AI to Optimize Food Delivery Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Slavomír Švancár",
        "Lukáš Chrpa",
        "Filip Dvořák",
        "Tomáš Balyo"
      ],
      "abstract": "The global food delivery market provides many opportunities for AI-based\nservices that can improve the efficiency of feeding the world. This paper\npresents the Cloud Kitchen platform as a decision-making tool for restaurants\nwith food delivery and a simulator to evaluate the impact of the decisions. The\nplatform contains a Technology-Specific Bridge (TSB) that provides an interface\nfor communicating with restaurants or the simulator. TSB uses a planning domain\nmodel to represent decisions embedded in the Unified Planning Framework (UPF).\nDecision-making, which concerns allocating customers' orders to vehicles and\ndeciding in which order the customers will be served (for each vehicle), is\ndone via a Vehicle Routing Problem with Time Windows (VRPTW), an efficient tool\nfor this problem. We show that decisions made by our platform can improve\ncustomer satisfaction by reducing the number of delayed deliveries using a\nreal-world historical dataset.",
      "tldr_zh": "这篇论文介绍了 Cloud Kitchen 平台，这是一个基于规划的复合 AI 系统，旨在优化食品配送过程的决策和模拟。平台通过 Technology-Specific Bridge (TSB) 接口与餐厅或模拟器通信，并利用 Unified Planning Framework (UPF) 的规划域模型来处理订单分配和车辆服务顺序问题，具体采用 Vehicle Routing Problem with Time Windows (VRPTW) 作为高效工具。实验基于真实历史数据集证明，该平台能显著减少延误交付，从而提升客户满意度。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10725v2",
      "published_date": "2024-02-16 14:31:33 UTC",
      "updated_date": "2024-08-20 12:38:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:03:23.233907"
    },
    {
      "arxiv_id": "2402.12393v2",
      "title": "On Automating Video Game Regression Testing by Planning and Learning",
      "title_zh": "通过",
      "authors": [
        "Tomáš Balyo",
        "G. Michael Youngblood",
        "Filip Dvořák",
        "Lukáš Chrpa",
        "Roman Barták"
      ],
      "abstract": "In this paper, we propose a method and workflow for automating regression\ntesting of certain video game aspects using automated planning and incremental\naction model learning techniques. The basic idea is to use detailed game logs\nand incremental action model learning techniques to maintain a formal model in\nthe planning domain description language (PDDL) of the gameplay mechanics. The\nworkflow enables efficient cooperation of game developers without any\nexperience with PDDL or other formal systems and a person experienced with PDDL\nmodeling but no game development skills. We describe the method and workflow in\ngeneral and then demonstrate it on a concrete proof-of-concept example -- a\nsimple role-playing game provided as one of the tutorial projects in the\npopular game development engine Unity. This paper presents the first step\ntowards minimizing or even eliminating the need for a modeling expert in the\nworkflow, thus making automated planning accessible to a broader audience.",
      "tldr_zh": "本文提出了一种自动化视频游戏回归测试的方法和工作流，结合 automated planning 和 incremental action model learning 技术，使用游戏日志维护 PDDL 格式的游戏机制模型。 该工作流允许游戏开发者（无需 PDDL 经验）与 PDDL 建模专家（无需游戏开发技能）高效合作，避免了传统协作的障碍。 通过在 Unity 引擎的简单角色扮演游戏示例中验证，该方法展示了减少对建模专家依赖的第一步，从而使 automated planning 更易于广大用户采用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12393v2",
      "published_date": "2024-02-16 14:28:25 UTC",
      "updated_date": "2024-04-02 09:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:03:36.398857"
    },
    {
      "arxiv_id": "2402.10992v1",
      "title": "\"Understanding AI\": Semantic Grounding in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Holger Lyre"
      ],
      "abstract": "Do LLMs understand the meaning of the texts they generate? Do they possess a\nsemantic grounding? And how could we understand whether and what they\nunderstand? I start the paper with the observation that we have recently\nwitnessed a generative turn in AI, since generative models, including LLMs, are\nkey for self-supervised learning. To assess the question of semantic grounding,\nI distinguish and discuss five methodological ways. The most promising way is\nto apply core assumptions of theories of meaning in philosophy of mind and\nlanguage to LLMs. Grounding proves to be a gradual affair with a\nthree-dimensional distinction between functional, social and causal grounding.\nLLMs show basic evidence in all three dimensions. A strong argument is that\nLLMs develop world models. Hence, LLMs are neither stochastic parrots nor\nsemantic zombies, but already understand the language they generate, at least\nin an elementary sense.",
      "tldr_zh": "这篇论文探讨大型语言模型（LLMs）是否理解它们生成的文本含义，以及如何评估其语义基础（semantic grounding）。作者区分了五种方法来检验语义基础，其中最有前景的是应用哲学中意义理论的核心假设，并将语义基础分为功能（functional）、社会（social）和因果（causal）三个渐进维度。研究发现，LLMs 在所有三个维度上显示出基本证据，并通过发展世界模型（world models）证明它们并非随机鹦鹉（stochastic parrots）或语义僵尸（semantic zombies），而是至少在基础层面理解语言。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10992v1",
      "published_date": "2024-02-16 14:23:55 UTC",
      "updated_date": "2024-02-16 14:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:03:47.584594"
    },
    {
      "arxiv_id": "2402.10717v2",
      "title": "BioFusionNet: Deep Learning-Based Survival Risk Stratification in ER+ Breast Cancer Through Multifeature and Multimodal Data Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Raktim Kumar Mondol",
        "Ewan K. A. Millar",
        "Arcot Sowmya",
        "Erik Meijering"
      ],
      "abstract": "Breast cancer is a significant health concern affecting millions of women\nworldwide. Accurate survival risk stratification plays a crucial role in\nguiding personalised treatment decisions and improving patient outcomes. Here\nwe present BioFusionNet, a deep learning framework that fuses image-derived\nfeatures with genetic and clinical data to obtain a holistic profile and\nachieve survival risk stratification of ER+ breast cancer patients. We employ\nmultiple self-supervised feature extractors (DINO and MoCoV3) pretrained on\nhistopathological patches to capture detailed image features. These features\nare then fused by a variational autoencoder and fed to a self-attention network\ngenerating patient-level features. A co-dual-cross-attention mechanism combines\nthe histopathological features with genetic data, enabling the model to capture\nthe interplay between them. Additionally, clinical data is incorporated using a\nfeed-forward network, further enhancing predictive performance and achieving\ncomprehensive multimodal feature integration. Furthermore, we introduce a\nweighted Cox loss function, specifically designed to handle imbalanced survival\ndata, which is a common challenge. Our model achieves a mean concordance index\nof 0.77 and a time-dependent area under the curve of 0.84, outperforming\nstate-of-the-art methods. It predicts risk (high versus low) with prognostic\nsignificance for overall survival in univariate analysis (HR=2.99, 95% CI:\n1.88--4.78, p<0.005), and maintains independent significance in multivariate\nanalysis incorporating standard clinicopathological variables (HR=2.91, 95\\%\nCI: 1.80--4.68, p<0.005).",
      "tldr_zh": "本研究提出 BioFusionNet，一种基于 deep learning 的框架，用于 ER+ 乳腺癌患者的生存风险分层，通过融合图像特征、遗传数据和临床数据实现多模态整合。具体方法包括使用自监督提取器（如 DINO 和 MoCoV3）从组织病理学图像提取特征，并通过 variational autoencoder、自注意力网络和 co-dual-cross-attention 机制结合这些数据，同时引入 weighted Cox loss 函数处理不平衡生存数据。实验结果显示，模型的 concordance index 为 0.77、时间依赖 AUC 为 0.84，优于现有方法，并在单变量和多变量分析中显著预测高风险（HR=2.99 和 HR=2.91，p<0.005）。这为个性化治疗决策提供了更准确的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Keywords: Multimodal Fusion, Breast Cancer, Whole Slide Images, Deep\n  Neural Network, Survival Prediction",
      "pdf_url": "http://arxiv.org/pdf/2402.10717v2",
      "published_date": "2024-02-16 14:19:33 UTC",
      "updated_date": "2024-06-03 02:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:04:03.294300"
    },
    {
      "arxiv_id": "2402.10712v3",
      "title": "An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Atsuki Yamaguchi",
        "Aline Villavicencio",
        "Nikolaos Aletras"
      ],
      "abstract": "The development of state-of-the-art generative large language models (LLMs)\ndisproportionately relies on English-centric tokenizers, vocabulary and\npre-training data. Despite the fact that some LLMs have multilingual\ncapabilities, recent studies have shown that their inference efficiency\ndeteriorates when generating text in languages other than English. This results\nin increased inference time and costs. Cross-lingual vocabulary adaptation\n(CVA) methods have been proposed for adapting models to a target language\naiming to improve downstream performance. However, the effectiveness of these\nmethods on increasing inference efficiency of generative LLMs has yet to be\nexplored. In this paper, we perform an empirical study of five CVA methods on\nfour generative LLMs (including monolingual and multilingual models) across\nfour typologically-diverse languages and four natural language understanding\ntasks. We find that CVA substantially contributes to LLM inference speedups of\nup to 271.5\\%. We also show that adapting LLMs that have been pre-trained on\nmore balanced multilingual data results in downstream performance comparable to\nthe original models.",
      "tldr_zh": "这篇论文通过实证研究探讨了交叉语言词汇适应（CVA）方法，以提升生成式大型语言模型（LLMs）的推理效率。研究评估了五种 CVA 方法在四种 LLMs（包括单语和多语模型）上，涵盖四种类型学多样的语言和四种自然语言理解任务。结果显示，CVA 可将 LLMs 的推理速度提高高达 271.5%，同时对在更平衡的多语言数据上预训练的模型进行适应，能保持与原模型相当的下游性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2402.10712v3",
      "published_date": "2024-02-16 14:15:15 UTC",
      "updated_date": "2024-09-26 11:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:04:17.227091"
    },
    {
      "arxiv_id": "2402.10705v3",
      "title": "AutoSAT: Automatically Optimize SAT Solvers via Large Language Models",
      "title_zh": "AutoSAT：通过",
      "authors": [
        "Yiwen Sun",
        "Furong Ye",
        "Xianyin Zhang",
        "Shiyu Huang",
        "Bingzhen Zhang",
        "Ke Wei",
        "Shaowei Cai"
      ],
      "abstract": "Conflict-Driven Clause Learning (CDCL) is the mainstream framework for\nsolving the Satisfiability problem (SAT), and CDCL solvers typically rely on\nvarious heuristics, which have a significant impact on their performance.\nModern CDCL solvers, such as MiniSat and Kissat, commonly incorporate several\nheuristics and select one to use according to simple rules, requiring\nsignificant time and expert effort to fine-tune in practice. The pervasion of\nLarge Language Models (LLMs) provides a potential solution to address this\nissue. However, generating a CDCL solver from scratch is not effective due to\nthe complexity and context volume of SAT solvers. Instead, we propose AutoSAT,\na framework that automatically optimizes heuristics in a pre-defined modular\nsearch space based on existing CDCL solvers. Unlike existing automated\nalgorithm design approaches focusing on hyperparameter tuning and operator\nselection, AutoSAT can generate new efficient heuristics. In this first attempt\nat optimizing SAT solvers using LLMs, several strategies including the greedy\nhill climber and (1+1) Evolutionary Algorithm are employed to guide LLMs to\nsearch for better heuristics. Experimental results demonstrate that LLMs can\ngenerally enhance the performance of CDCL solvers. A realization of AutoSAT\noutperforms MiniSat on 9 out of 12 datasets and even surpasses the\nstate-of-the-art hybrid solver Kissat on 4 datasets.",
      "tldr_zh": "这篇论文提出了 AutoSAT 框架，利用 Large Language Models (LLMs) 自动优化 CDCL (Conflict-Driven Clause Learning) 求解器的启发式算法，以解决传统手动调整的复杂性。AutoSAT 在预定义的模块化搜索空间中生成新启发式算法，并采用贪婪爬山算法和 (1+1) 进化算法等策略指导 LLMs 进行搜索，从而提升 SAT (Satisfiability problem) 求解性能。实验结果表明，AutoSAT 优化版本在12个数据集上优于 MiniSat 的9个，并在4个数据集上超越了先进的混合求解器 Kissat。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10705v3",
      "published_date": "2024-02-16 14:04:56 UTC",
      "updated_date": "2024-11-13 15:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:04:28.720002"
    },
    {
      "arxiv_id": "2402.10701v1",
      "title": "Does Twinning Vehicular Networks Enhance Their Performance in Dense Areas?",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Al-Shareeda",
        "Sema F. Oktug",
        "Yusuf Yaslan",
        "Gokhan Yurdakul",
        "Berk Canberk"
      ],
      "abstract": "This paper investigates the potential of Digital Twins (DTs) to enhance\nnetwork performance in densely populated urban areas, specifically focusing on\nvehicular networks. The study comprises two phases. In Phase I, we utilize\ntraffic data and AI clustering to identify critical locations, particularly in\ncrowded urban areas with high accident rates. In Phase II, we evaluate the\nadvantages of twinning vehicular networks through three deployment scenarios:\nedge-based twin, cloud-based twin, and hybrid-based twin. Our analysis\ndemonstrates that twinning significantly reduces network delays, with virtual\ntwins outperforming physical networks. Virtual twins maintain low delays even\nwith increased vehicle density, such as 15.05 seconds for 300 vehicles.\nMoreover, they exhibit faster computational speeds, with cloud-based twins\nbeing 1.7 times faster than edge twins in certain scenarios. These findings\nprovide insights for efficient vehicular communication and underscore the\npotential of virtual twins in enhancing vehicular networks in crowded areas\nwhile emphasizing the importance of considering real-world factors when making\ndeployment decisions.",
      "tldr_zh": "本研究探讨了Digital Twins (DTs) 是否能提升密集城市区域车辆网络的性能，通过两个阶段进行分析。在Phase I，利用交通数据和AI clustering 识别高事故率的关键位置；在Phase II，评估三种部署场景，包括edge-based twin、cloud-based twin 和hybrid-based twin。结果显示，twinning 显著降低网络延迟，virtual twins 在高密度车辆（如300辆）环境下保持低延迟（仅15.05秒），并在计算速度上表现出色，云端双胞胎比边缘双胞胎快1.7倍。这些发现为高效车辆通信提供洞见，并强调在密集区域部署virtual twins 的潜力，同时需考虑现实因素。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 8 figures, 2tables, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2402.10701v1",
      "published_date": "2024-02-16 14:02:28 UTC",
      "updated_date": "2024-02-16 14:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:04:39.582820"
    },
    {
      "arxiv_id": "2402.10695v2",
      "title": "Unlink to Unlearn: Simplifying Edge Unlearning in GNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Tan",
        "Fei Sun",
        "Ruichen Qiu",
        "Du Su",
        "Huawei Shen"
      ],
      "abstract": "As concerns over data privacy intensify, unlearning in Graph Neural Networks\n(GNNs) has emerged as a prominent research frontier in academia. This concept\nis pivotal in enforcing the \\textit{right to be forgotten}, which entails the\nselective removal of specific data from trained GNNs upon user request. Our\nresearch focuses on edge unlearning, a process of particular relevance to\nreal-world applications. Current state-of-the-art approaches like GNNDelete can\neliminate the influence of specific edges yet suffer from\n\\textit{over-forgetting}, which means the unlearning process inadvertently\nremoves excessive information beyond needed, leading to a significant\nperformance decline for remaining edges. Our analysis identifies the loss\nfunctions of GNNDelete as the primary source of over-forgetting and also\nsuggests that loss functions may be redundant for effective edge unlearning.\nBuilding on these insights, we simplify GNNDelete to develop \\textbf{Unlink to\nUnlearn} (UtU), a novel method that facilitates unlearning exclusively through\nunlinking the forget edges from graph structure. Our extensive experiments\ndemonstrate that UtU delivers privacy protection on par with that of a\nretrained model while preserving high accuracy in downstream tasks, by\nupholding over 97.3\\% of the retrained model's privacy protection capabilities\nand 99.8\\% of its link prediction accuracy. Meanwhile, UtU requires only\nconstant computational demands, underscoring its advantage as a highly\nlightweight and practical edge unlearning solution.",
      "tldr_zh": "本研究针对 Graph Neural Networks (GNNs) 中的 edge unlearning 问题，旨在支持“right to be forgotten”，但发现现有方法如 GNNDelete 存在 over-forgetting 现象，导致过度删除信息并降低性能。  \n为此，提出了一种简化方法 Unlink to Unlearn (UtU)，仅通过从图结构中 unlink 遗忘边来实现 unlearning，从而避免了冗余的损失函数。  \n实验结果表明，UtU 提供了与重新训练模型相当的隐私保护，保持了超过97.3%的隐私能力以及99.8%的链接预测准确率，同时其计算需求恒定，展现出高度轻量化和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WWW 2024 as a Short Research Paper",
      "pdf_url": "http://arxiv.org/pdf/2402.10695v2",
      "published_date": "2024-02-16 13:58:23 UTC",
      "updated_date": "2024-03-11 17:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:04:53.070625"
    },
    {
      "arxiv_id": "2402.10685v2",
      "title": "LongHeads: Multi-Head Attention is Secretly a Long Context Processor",
      "title_zh": "LongHeads：多头注意力其实是一个长上下文处理器",
      "authors": [
        "Yi Lu",
        "Xin Zhou",
        "Wei He",
        "Jun Zhao",
        "Tao Ji",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive performance in numerous\ndomains but often struggle to process lengthy inputs effectively and\nefficiently due to limited length generalization and attention's quadratic\ncomputational demands. Many sought to mitigate this by restricting the\nattention window within the pre-trained length. However, these methods\nintroduce new issues such as ignoring the middle context and requiring\nadditional training. To address these problems, we propose LongHeads, a\ntraining-free framework that enhances LLM's long context ability by unlocking\nmulti-head attention's untapped potential. Instead of allowing each head to\nattend to the full sentence, which struggles with generalizing to longer\nsequences due to out-of-distribution (OOD) issues, we allow each head to\nprocess in-distribution length by selecting and attending to important context\nchunks. To this end, we propose a chunk selection strategy that relies on the\ninherent correlation between the query and the key representations, efficiently\ndistributing context chunks to different heads. In this way, each head ensures\nit can effectively process attended tokens within the trained length, while\ndifferent heads in different layers can collectively process longer contexts.\nLongHeads works efficiently in linear time, fits seamlessly with many LLMs that\nuse relative positional encoding. LongHeads achieves 100% accuracy at the 128k\nlength on passkey retrieval task, verifying LongHeads's efficacy in extending\nthe usable context window for existing models. We release our code at\nhttps://github.com/LuLuLuyi/LongHeads .",
      "tldr_zh": "大型语言模型 (LLMs) 在处理长上下文时面临长度泛化有限和注意力机制二次方计算需求的问题，本文提出 LongHeads，一个无需额外训练的框架，通过利用 Multi-Head Attention 的潜在能力来提升长上下文处理。LongHeads 的核心策略是让每个注意力头选择并关注基于查询-键相关性的重要上下文块，确保每个头处理训练长度内的分布内数据，而不同头在不同层集体处理更长的序列。该框架以线性时间运行，与使用相对位置编码的 LLMs 无缝兼容，并在 128k 长度的 passkey 检索任务上实现 100% 准确率，证明了其在扩展可用上下文窗口方面的显著有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10685v2",
      "published_date": "2024-02-16 13:39:34 UTC",
      "updated_date": "2024-03-25 11:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:05:05.628124"
    },
    {
      "arxiv_id": "2402.10681v1",
      "title": "Physics-informed MeshGraphNets (PI-MGNs): Neural finite element solvers for non-stationary and nonlinear simulations on arbitrary meshes",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Würth",
        "Niklas Freymuth",
        "Clemens Zimmerling",
        "Gerhard Neumann",
        "Luise Kärger"
      ],
      "abstract": "Engineering components must meet increasing technological demands in ever\nshorter development cycles. To face these challenges, a holistic approach is\nessential that allows for the concurrent development of part design, material\nsystem and manufacturing process. Current approaches employ numerical\nsimulations, which however quickly becomes computation-intensive, especially\nfor iterative optimization. Data-driven machine learning methods can be used to\nreplace time- and resource-intensive numerical simulations. In particular,\nMeshGraphNets (MGNs) have shown promising results. They enable fast and\naccurate predictions on unseen mesh geometries while being fully differentiable\nfor optimization. However, these models rely on large amounts of expensive\ntraining data, such as numerical simulations. Physics-informed neural networks\n(PINNs) offer an opportunity to train neural networks with partial differential\nequations instead of labeled data, but have not been extended yet to handle\ntime-dependent simulations of arbitrary meshes. This work introduces PI-MGNs, a\nhybrid approach that combines PINNs and MGNs to quickly and accurately solve\nnon-stationary and nonlinear partial differential equations (PDEs) on arbitrary\nmeshes. The method is exemplified for thermal process simulations of unseen\nparts with inhomogeneous material distribution. Further results show that the\nmodel scales well to large and complex meshes, although it is trained on small\ngeneric meshes only.",
      "tldr_zh": "本研究针对工程开发中数值模拟的计算密集问题，提出了一种新型神经有限元求解器Physics-informed MeshGraphNets (PI-MGNs)，它将Physics-informed neural networks (PINNs)与MeshGraphNets (MGNs)相结合，用于快速准确地解决非稳态和非线性partial differential equations (PDEs)模拟，并支持任意网格。PI-MGNs通过利用PDEs作为训练数据而非大量标签数据，显著减少了对昂贵模拟数据的依赖，并在热过程模拟中展示了出色性能，例如处理未见部件的非均匀材料分布。实验结果表明，该模型即使在小通用网格上训练，也能扩展到大型复杂网格，提供高效的预测和优化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to CMAME",
      "pdf_url": "http://arxiv.org/pdf/2402.10681v1",
      "published_date": "2024-02-16 13:34:51 UTC",
      "updated_date": "2024-02-16 13:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:05:17.067367"
    },
    {
      "arxiv_id": "2402.10659v4",
      "title": "Network Formation and Dynamics Among Multi-LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Marios Papachristou",
        "Yuan Yuan"
      ],
      "abstract": "Social networks fundamentally shape human opinions, behaviors, and the\ndissemination of information. As large language models (LLMs) like GPT, Claude,\nand Llama increasingly integrate into social and professional settings,\nunderstanding their behavior in the context of social interactions and network\nformation becomes essential. This study develops a framework to systematically\nexamine whether the network formation behaviors of multiple LLMs approximate\ncertain aspects of human network dynamics. By simulating interactions among LLM\nagents across various model families, we observe that these models consistently\nexhibit key patterns associated with social network principles including\npreferential attachment, triadic closure, homophily, community structure, and\nthe small-world phenomenon when forming networks. Moreover, LLMs adapt their\nnetwork formation strategies based on each network's characteristics,\nreflecting the context-dependent nature of human behavior: in Facebook\nnetworks, they prioritize triadic closure and homophily, mirroring close-knit\nfriendships; in phone networks, homophily and preferential attachment dominate,\ncapturing personal and professional connections, while in employment networks,\nLLMs favor heterophily and high-degree connections, aligning with career\nadvancement dynamics. These results open new avenues for using LLMs in network\nscience research, with potential applications in agent-based modeling and\nsynthetic network generation.",
      "tldr_zh": "本文开发了一个框架，系统考察多个大型语言模型(LLMs)代理在网络形成中的行为，模拟人类社交动态，通过模拟跨模型家族的互动，发现 LLMs 展现出 preferential attachment、triadic closure、homophily、community structure 和 small-world phenomenon 等关键模式。LLMs 根据网络特性调整策略，例如在 Facebook 网络中优先 triadic closure 和 homophily，在 phone 网络中强调 homophily 和 preferential attachment，而在 employment 网络中倾向 heterophily 和 high-degree connections，以反映人类行为的上下文依赖性。这些结果为 LLMs 在网络科学研究、代理建模和合成网络生成等领域提供了新应用前景。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10659v4",
      "published_date": "2024-02-16 13:10:14 UTC",
      "updated_date": "2024-12-05 04:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:05:28.340910"
    },
    {
      "arxiv_id": "2402.10649v1",
      "title": "Hermite Neural Network Simulation for Solving the 2D Schrodinger Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Kourosh Parand",
        "Aida Pakniyat"
      ],
      "abstract": "The Schrodinger equation is a mathematical equation describing the wave\nfunction's behavior in a quantum-mechanical system. It is a partial\ndifferential equation that provides valuable insights into the fundamental\nprinciples of quantum mechanics. In this paper, the aim was to solve the\nSchrodinger equation with sufficient accuracy by using a mixture of neural\nnetworks with the collocation method base Hermite functions. Initially, the\nHermite functions roots were employed as collocation points, enhancing the\nefficiency of the solution. The Schrodinger equation is defined in an infinite\ndomain, the use of Hermite functions as activation functions resulted in\nexcellent precision. Finally, the proposed method was simulated using MATLAB's\nSimulink tool. The results were then compared with those obtained using\nPhysics-informed neural networks and the presented method.",
      "tldr_zh": "本论文提出了一种基于 Hermite Neural Network 的模拟方法，用于求解二维 Schrodinger Equation，以提高量子力学系统波函数的计算精度。该方法结合了神经网络与 Hermite functions 的配点方法(collocation method)，使用 Hermite functions 的根作为配点点，并在无限域中作为激活函数，从而提升了求解效率和准确性。最终，通过 MATLAB 的 Simulink 工具进行模拟，结果显示该方法比 Physics-informed neural networks 更具优势。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "cs.NE",
        "math.AP"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10649v1",
      "published_date": "2024-02-16 12:51:25 UTC",
      "updated_date": "2024-02-16 12:51:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:05:39.647227"
    },
    {
      "arxiv_id": "2402.15522v1",
      "title": "IntSat: Integer Linear Programming by Conflict-Driven Constraint-Learning",
      "title_zh": "IntSat: 通过冲突驱动约束学习的整数线性规划",
      "authors": [
        "Robert Nieuwenhuis",
        "Albert Oliveras",
        "Enric Rodriguez-Carbonell"
      ],
      "abstract": "State-of-the-art SAT solvers are nowadays able to handle huge real-world\ninstances. The key to this success is the so-called Conflict-Driven\nClause-Learning (CDCL) scheme, which encompasses a number of techniques that\nexploit the conflicts that are encountered during the search for a solution. In\nthis article we extend these techniques to Integer Linear Programming (ILP),\nwhere variables may take general integer values instead of purely binary ones,\nconstraints are more expressive than just propositional clauses, and there may\nbe an objective function to optimise. We explain how these methods can be\nimplemented efficiently, and discuss possible improvements. Our work is backed\nwith a basic implementation that shows that, even in this far less mature\nstage, our techniques are already a useful complement to the state of the art\nin ILP solving.",
      "tldr_zh": "该论文提出IntSat框架，将Conflict-Driven Clause-Learning (CDCL)技术从State-of-the-art SAT求解器扩展到Integer Linear Programming (ILP)，以处理整数变量、复杂约束和优化目标。作者解释了如何高效实现这些方法，包括可能的改进，并提供了一个基本实现。实验结果显示，即使在早期阶段，该技术已能有效补充现有ILP求解器，提升了解决大规模实例的能力。",
      "categories": [
        "cs.AI",
        "I.2.8; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "48 pages. This is the Author's Original Manuscript of the journal\n  version",
      "pdf_url": "http://arxiv.org/pdf/2402.15522v1",
      "published_date": "2024-02-16 12:48:40 UTC",
      "updated_date": "2024-02-16 12:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:05:50.717237"
    },
    {
      "arxiv_id": "2402.10645v3",
      "title": "Can Separators Improve Chain-of-Thought Prompting?",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonjeong Park",
        "Hyunjin Kim",
        "Chanyeol Choi",
        "Junseong Kim",
        "Jy-yong Sohn"
      ],
      "abstract": "Chain-of-thought (CoT) prompting is a simple and effective method for\nimproving the reasoning capabilities of Large Language Models (LLMs). The basic\nidea of CoT is to let LLMs break down their thought processes step-by-step by\nputting exemplars in the input prompt. However, the densely structured prompt\nexemplars of CoT may cause the cognitive overload of LLMs. Inspired by human\ncognition, we introduce COT-SEP, a method that strategically employs separators\nat the end of each exemplar in CoT prompting. These separators are designed to\nhelp the LLMs understand their thought processes better while reasoning.\nInterestingly, it turns out that COT-SEP significantly improves the LLMs'\nperformances on complex reasoning tasks (e.g., GSM8K, AQuA, CSQA), compared\nwith the vanilla CoT, which does not use separators. We also study the effects\nof the type and the location of separators tested on multiple LLMs, including\nGPT-3.5-Turbo, GPT-4, and LLaMA-2 7B.",
      "tldr_zh": "本研究探讨了在Chain-of-Thought (CoT)提示中添加分隔符是否能提升Large Language Models (LLMs)的推理能力。作者提出COT-SEP方法，通过在每个CoT提示示例末尾添加分隔符，帮助LLMs更好地理解思考过程，从而缓解密集结构提示带来的认知超载。实验结果显示，COT-SEP在复杂推理任务（如GSM8K、AQuA和CSQA）上显著优于传统CoT，并在多个模型（如GPT-3.5-Turbo、GPT-4和LLaMA-2 7B）上验证了分隔符类型和位置的影响，为优化LLMs的提示设计提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "IEEE FLLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.10645v3",
      "published_date": "2024-02-16 12:46:16 UTC",
      "updated_date": "2024-10-09 06:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:06:04.545593"
    },
    {
      "arxiv_id": "2402.10643v1",
      "title": "`Keep it Together': Enforcing Cohesion in Extractive Summaries by Simulating Human Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Ronald Cardenas",
        "Matthias Galle",
        "Shay B. Cohen"
      ],
      "abstract": "Extractive summaries are usually presented as lists of sentences with no\nexpected cohesion between them. In this paper, we aim to enforce cohesion\nwhilst controlling for informativeness and redundancy in summaries, in cases\nwhere the input exhibits high redundancy. The pipeline controls for redundancy\nin long inputs as it is consumed, and balances informativeness and cohesion\nduring sentence selection. Our sentence selector simulates human memory to keep\ntrack of topics --modeled as lexical chains--, enforcing cohesive ties between\nnoun phrases. Across a variety of domains, our experiments revealed that it is\npossible to extract highly cohesive summaries that nevertheless read as\ninformative to humans as summaries extracted by only accounting for\ninformativeness or redundancy. The extracted summaries exhibit smooth topic\ntransitions between sentences as signaled by lexical chains, with chains\nspanning adjacent or near-adjacent sentences.",
      "tldr_zh": "本研究针对提取式摘要（extractive summaries）的连贯性问题，提出了一种通过模拟人类记忆的方法，在高冗余输入中强制摘要的连贯性，同时控制信息性和冗余。方法采用一个管道（pipeline）系统，在处理长输入时实时管理冗余，并通过跟踪主题（建模为词汇链，lexical chains）来平衡句子选择，确保名词短语之间的连贯性。实验结果显示，在多种领域，该方法生成的摘要不仅具有平滑的主题过渡（chains 跨越相邻或近相邻句子），而且对人类读者而言，其信息丰富程度与仅考虑信息性或冗余的基线摘要相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10643v1",
      "published_date": "2024-02-16 12:43:26 UTC",
      "updated_date": "2024-02-16 12:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:06:17.615891"
    },
    {
      "arxiv_id": "2402.10642v2",
      "title": "Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Zhang",
        "Daijiao Liu",
        "Hexin Liu",
        "Qiquan Zhang",
        "Hanyu Meng",
        "Leibny Paola Garcia",
        "Eng Siong Chng",
        "Lina Yao"
      ],
      "abstract": "Recently, Denoising Diffusion Probabilistic Models (DDPMs) have attained\nleading performances across a diverse range of generative tasks. However, in\nthe field of speech synthesis, although DDPMs exhibit impressive performance,\ntheir long training duration and substantial inference costs hinder practical\ndeployment. Existing approaches primarily focus on enhancing inference speed,\nwhile approaches to accelerate training a key factor in the costs associated\nwith adding or customizing voices often necessitate complex modifications to\nthe model, compromising their universal applicability. To address the\naforementioned challenges, we propose an inquiry: is it possible to enhance the\ntraining/inference speed and performance of DDPMs by modifying the speech\nsignal itself? In this paper, we double the training and inference speed of\nSpeech DDPMs by simply redirecting the generative target to the wavelet domain.\nThis method not only achieves comparable or superior performance to the\noriginal model in speech synthesis tasks but also demonstrates its versatility.\nBy investigating and utilizing different wavelet bases, our approach proves\neffective not just in speech synthesis, but also in speech enhancement.",
      "tldr_zh": "本文提出一种简单高效的方法，通过将语音生成目标转移到wavelet domain，来加速Denoising Diffusion Probabilistic Models (DDPMs)在语音合成中的训练和推理速度，从而将速度提升一倍。该方法仅修改语音信号的处理域，而不需对模型进行复杂改动，即可实现与原模型相当或更好的性能。实验验证了不同wavelet bases的有效性，不仅适用于语音合成，还扩展到语音 enhancement 任务中。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10642v2",
      "published_date": "2024-02-16 12:43:01 UTC",
      "updated_date": "2024-09-23 22:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:06:29.337308"
    },
    {
      "arxiv_id": "2402.10635v1",
      "title": "ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Chen",
        "Kan Ren",
        "Yansen Wang",
        "Yuchen Fang",
        "Weiwei Sun",
        "Dongsheng Li"
      ],
      "abstract": "Modeling continuous-time dynamics on irregular time series is critical to\naccount for data evolution and correlations that occur continuously.\nTraditional methods including recurrent neural networks or Transformer models\nleverage inductive bias via powerful neural architectures to capture complex\npatterns. However, due to their discrete characteristic, they have limitations\nin generalizing to continuous-time data paradigms. Though neural ordinary\ndifferential equations (Neural ODEs) and their variants have shown promising\nresults in dealing with irregular time series, they often fail to capture the\nintricate correlations within these sequences. It is challenging yet demanding\nto concurrently model the relationship between input data points and capture\nthe dynamic changes of the continuous-time system. To tackle this problem, we\npropose ContiFormer that extends the relation modeling of vanilla Transformer\nto the continuous-time domain, which explicitly incorporates the modeling\nabilities of continuous dynamics of Neural ODEs with the attention mechanism of\nTransformers. We mathematically characterize the expressive power of\nContiFormer and illustrate that, by curated designs of function hypothesis,\nmany Transformer variants specialized in irregular time series modeling can be\ncovered as a special case of ContiFormer. A wide range of experiments on both\nsynthetic and real-world datasets have illustrated the superior modeling\ncapacities and prediction performance of ContiFormer on irregular time series\ndata. The project link is https://seqml.github.io/contiformer/.",
      "tldr_zh": "该论文提出 ContiFormer，一种针对不规则时间序列的连续时间 Transformer 模型，通过整合 Neural ODEs 的连续动态建模与 Transformer 的注意力机制，解决了传统方法在处理连续时间数据时的局限性。ContiFormer 能够同时捕捉输入数据点之间的复杂相关性和系统动态变化，并通过数学证明展示了其表达能力，同时覆盖了许多现有变体作为特例。在合成和真实数据集上的广泛实验中，ContiFormer 展现出优越的建模能力和预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Neurips 2023 Poster",
      "pdf_url": "http://arxiv.org/pdf/2402.10635v1",
      "published_date": "2024-02-16 12:34:38 UTC",
      "updated_date": "2024-02-16 12:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:06:41.560277"
    },
    {
      "arxiv_id": "2402.10634v3",
      "title": "Graph-based Forecasting with Missing Data through Spatiotemporal Downsampling",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Marisca",
        "Cesare Alippi",
        "Filippo Maria Bianchi"
      ],
      "abstract": "Given a set of synchronous time series, each associated with a sensor-point\nin space and characterized by inter-series relationships, the problem of\nspatiotemporal forecasting consists of predicting future observations for each\npoint. Spatiotemporal graph neural networks achieve striking results by\nrepresenting the relationships across time series as a graph. Nonetheless, most\nexisting methods rely on the often unrealistic assumption that inputs are\nalways available and fail to capture hidden spatiotemporal dynamics when part\nof the data is missing. In this work, we tackle this problem through\nhierarchical spatiotemporal downsampling. The input time series are\nprogressively coarsened over time and space, obtaining a pool of\nrepresentations that capture heterogeneous temporal and spatial dynamics.\nConditioned on observations and missing data patterns, such representations are\ncombined by an interpretable attention mechanism to generate the forecasts. Our\napproach outperforms state-of-the-art methods on synthetic and real-world\nbenchmarks under different missing data distributions, particularly in the\npresence of contiguous blocks of missing values.",
      "tldr_zh": "本文提出了一种基于图的时空预测（spatiotemporal forecasting）方法，通过层次化时空降采样（hierarchical spatiotemporal downsampling）来处理输入数据中的缺失问题。该方法将时间序列在时间和空间上逐步粗化，生成一组捕捉异质时空动态的表示，并使用可解释的注意力机制（interpretable attention mechanism）根据观察数据和缺失模式进行组合预测。与现有时空图神经网络（spatiotemporal graph neural networks）相比，该方法在合成和真实世界基准测试中表现出色，尤其在连续缺失值分布下，预测准确率显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.10634v3",
      "published_date": "2024-02-16 12:33:31 UTC",
      "updated_date": "2024-06-08 15:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:06:53.944757"
    },
    {
      "arxiv_id": "2402.10617v1",
      "title": "Multitask Kernel-based Learning with Logic Constraints",
      "title_zh": "多任务核基学习结合逻辑约束",
      "authors": [
        "Michelangelo Diligenti",
        "Marco Gori",
        "Marco Maggini",
        "Leonardo Rigutini"
      ],
      "abstract": "This paper presents a general framework to integrate prior knowledge in the\nform of logic constraints among a set of task functions into kernel machines.\nThe logic propositions provide a partial representation of the environment, in\nwhich the learner operates, that is exploited by the learning algorithm\ntogether with the information available in the supervised examples. In\nparticular, we consider a multi-task learning scheme, where multiple unary\npredicates on the feature space are to be learned by kernel machines and a\nhigher level abstract representation consists of logic clauses on these\npredicates, known to hold for any input. A general approach is presented to\nconvert the logic clauses into a continuous implementation, that processes the\noutputs computed by the kernel-based predicates. The learning task is\nformulated as a primal optimization problem of a loss function that combines a\nterm measuring the fitting of the supervised examples, a regularization term,\nand a penalty term that enforces the constraints on both supervised and\nunsupervised examples. The proposed semi-supervised learning framework is\nparticularly suited for learning in high dimensionality feature spaces, where\nthe supervised training examples tend to be sparse and generalization\ndifficult. Unlike for standard kernel machines, the cost function to optimize\nis not generally guaranteed to be convex. However, the experimental results\nshow that it is still possible to find good solutions using a two stage\nlearning schema, in which first the supervised examples are learned until\nconvergence and then the logic constraints are forced. Some promising\nexperimental results on artificial multi-task learning tasks are reported,\nshowing how the classification accuracy can be effectively improved by\nexploiting the a priori rules and the unsupervised examples.",
      "tldr_zh": "这篇论文提出了一种将逻辑约束整合到基于核的机器学习框架中，用于多任务学习（multi-task learning），以利用先验知识提升学习性能。框架将逻辑子句转换为连续实现，并通过优化一个结合监督样本拟合损失、正则化项和约束惩罚项的原初优化问题，来处理多个一元谓词（unary predicates）的学习任务。这种半监督学习（semi-supervised learning）方法特别适用于高维特征空间，帮助改善泛化能力。实验结果显示，通过两阶段学习方案，该框架在人工多任务学习任务上显著提高了分类准确率，利用了先验规则和无监督样本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 19th European Conference on Artificial Intelligence (ECAI 2010)",
      "pdf_url": "http://arxiv.org/pdf/2402.10617v1",
      "published_date": "2024-02-16 12:11:34 UTC",
      "updated_date": "2024-02-16 12:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:07:05.103858"
    },
    {
      "arxiv_id": "2402.10991v4",
      "title": "Enhancing Convergence in Federated Learning: A Contribution-Aware Asynchronous Approach",
      "title_zh": "联邦学习中的收敛增强：一种贡献感知异步方法",
      "authors": [
        "Changxin Xu",
        "Yuxin Qiao",
        "Zhanxin Zhou",
        "Fanghao Ni",
        "Jize Xiong"
      ],
      "abstract": "Federated Learning (FL) is a distributed machine learning paradigm that\nallows clients to train models on their data while preserving their privacy. FL\nalgorithms, such as Federated Averaging (FedAvg) and its variants, have been\nshown to converge well in many scenarios. However, these methods require\nclients to upload their local updates to the server in a synchronous manner,\nwhich can be slow and unreliable in realistic FL settings. To address this\nissue, researchers have developed asynchronous FL methods that allow clients to\ncontinue training on their local data using a stale global model. However, most\nof these methods simply aggregate all of the received updates without\nconsidering their relative contributions, which can slow down convergence. In\nthis paper, we propose a contribution-aware asynchronous FL method that takes\ninto account the staleness and statistical heterogeneity of the received\nupdates. Our method dynamically adjusts the contribution of each update based\non these factors, which can speed up convergence compared to existing methods.",
      "tldr_zh": "这篇论文针对 Federated Learning (FL) 的同步更新问题，提出了一种 contribution-aware 的异步方法，以解决传统方法如 Federated Averaging (FedAvg) 在实际场景中收敛缓慢且不可靠的局限。方法通过动态调整每个更新的贡献，考虑了更新的 staleness（陈旧度）和 statistical heterogeneity（统计异质性），从而优化更新聚合过程。实验结果表明，该方法能比现有异步 FL 方法更快地加速收敛，提升了 FL 的整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 1 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.10991v4",
      "published_date": "2024-02-16 12:10:53 UTC",
      "updated_date": "2024-03-04 03:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:07:16.696025"
    },
    {
      "arxiv_id": "2402.10614v2",
      "title": "Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Li",
        "Jiuhai Chen",
        "Lichang Chen",
        "Tianyi Zhou"
      ],
      "abstract": "Making LLMs speak for different, especially minority groups of people, and\ngenerate statements supporting their diverse or even controversial perspectives\nis critical to creating an inclusive environment. However, existing LLMs lack\nsufficient controllability to the stance of their generated content, which\noften contains inconsistent, neutral, or biased statements. In this paper, we\nimprove the controllability of LLMs in generating statements supporting an\nargument the user defined in the prompt. We find that multi-round debates\nbetween two LLMs with opposite stances generate higher-quality and more salient\nstatements for each, which are important training data to improve the\ncontrollability of LLMs. Motivated by this, we develop a novel debate & tuning\n(DEBATUNE) pipeline finetuning LLMs to generate the statements obtained via\ndebate. To examine DEBATUNE, we curate the largest dataset of debate topics so\nfar, which covers 710 controversial topics and corresponding arguments for each\ntopic. Evaluations by the GPT-4 judge with a novel controversy controllability\nmetric show that LLMs' capability of generating diverse perspectives is\nsignificantly improved by DEBATUNE. Moreover, such controllability can be\ngeneralized to unseen topics, generating high-quality statements supporting\ncontroversial arguments.",
      "tldr_zh": "本研究探讨了如何提升大语言模型（LLMs）生成多样化视角的能力，特别是支持少数群体或争议性观点的语句。作者提出DEBATUNE管道，通过多轮辩论机制让两个持相反立场的LLMs生成高质量训练数据，然后对LLMs进行微调，以提高对用户定义论点的控制性。为此，他们构建了涵盖710个争议性话题的最大数据集。实验结果显示，使用GPT-4评判的新争议控制性指标，DEBATUNE显著提升了LLMs生成多样视角的性能，且这种能力可泛化到未见过的话题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL2024 findings, Camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2402.10614v2",
      "published_date": "2024-02-16 12:00:34 UTC",
      "updated_date": "2024-06-07 20:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:07:29.428517"
    },
    {
      "arxiv_id": "2402.10601v3",
      "title": "When \"Competency\" in Reasoning Opens the Door to Vulnerability: Jailbreaking LLMs via Novel Complex Ciphers",
      "title_zh": "翻译失败",
      "authors": [
        "Divij Handa",
        "Zehua Zhang",
        "Amir Saeidi",
        "Shrinidhi Kumbhar",
        "Chitta Baral"
      ],
      "abstract": "Recent advancements in Large Language Model (LLM) safety have primarily\nfocused on mitigating attacks crafted in natural language or common ciphers\n(e.g. Base64), which are likely integrated into newer models' safety training.\nHowever, we reveal a paradoxical vulnerability: as LLMs advance in reasoning,\nthey inadvertently become more susceptible to novel jailbreaking attacks.\nEnhanced reasoning enables LLMs to interpret complex instructions and decode\ncomplex user-defined ciphers, creating an exploitable security gap. To study\nthis vulnerability, we introduce Attacks using Custom Encryptions (ACE), a\njailbreaking technique that encodes malicious queries with novel ciphers.\nExtending ACE, we introduce Layered Attacks using Custom Encryptions (LACE),\nwhich applies multi-layer ciphers to amplify attack complexity. Furthermore, we\ndevelop CipherBench, a benchmark designed to evaluate LLMs' accuracy in\ndecoding encrypted benign text. Our experiments reveal a critical trade-off:\nLLMs that are more capable of decoding ciphers are more vulnerable to these\njailbreaking attacks, with success rates on GPT-4o escalating from 40% under\nACE to 78% with LACE. These findings highlight a critical insight: as LLMs\nbecome more adept at deciphering complex user ciphers--many of which cannot be\npreemptively included in safety training--they become increasingly exploitable.",
      "tldr_zh": "本研究揭示了大型语言模型(LLMs)在推理能力提升的同时，意外增加了对新型越狱攻击的易感性，特别是在处理用户自定义密码时。论文引入了ACE(Attacks using Custom Encryptions)攻击方法，通过编码恶意查询来规避安全训练，并扩展为LACE(Layered Attacks using Custom Encryptions)，采用多层密码以增强攻击复杂度；同时，开发了CipherBench基准，用于评估LLMs解码加密文本的准确性。实验结果显示，更擅长解码密码的LLMs更容易被攻破，例如GPT-4o在ACE下的成功率达40%，而LACE下升至78%，突显了LLMs能力提升与安全风险之间的权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10601v3",
      "published_date": "2024-02-16 11:37:05 UTC",
      "updated_date": "2025-03-16 21:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:07:42.231812"
    },
    {
      "arxiv_id": "2402.10597v1",
      "title": "Efficiency at Scale: Investigating the Performance of Diminutive Language Models in Clinical Tasks",
      "title_zh": "大规模效率：调查小型语言模型在临床任务中的性能",
      "authors": [
        "Niall Taylor",
        "Upamanyu Ghose",
        "Omid Rohanian",
        "Mohammadmahdi Nouriborji",
        "Andrey Kormilitzin",
        "David Clifton",
        "Alejo Nevado-Holgado"
      ],
      "abstract": "The entry of large language models (LLMs) into research and commercial spaces\nhas led to a trend of ever-larger models, with initial promises of\ngeneralisability, followed by a widespread desire to downsize and create\nspecialised models without the need for complete fine-tuning, using Parameter\nEfficient Fine-tuning (PEFT) methods. We present an investigation into the\nsuitability of different PEFT methods to clinical decision-making tasks, across\na range of model sizes, including extremely small models with as few as $25$\nmillion parameters.\n  Our analysis shows that the performance of most PEFT approaches varies\nsignificantly from one task to another, with the exception of LoRA, which\nmaintains relatively high performance across all model sizes and tasks,\ntypically approaching or matching full fine-tuned performance. The\neffectiveness of PEFT methods in the clinical domain is evident, particularly\nfor specialised models which can operate on low-cost, in-house computing\ninfrastructure. The advantages of these models, in terms of speed and reduced\ntraining costs, dramatically outweighs any performance gain from large\nfoundation LLMs. Furthermore, we highlight how domain-specific pre-training\ninteracts with PEFT methods and model size, and discuss how these factors\ninterplay to provide the best efficiency-performance trade-off. Full code\navailable at: tbd.",
      "tldr_zh": "这篇论文调查了Parameter Efficient Fine-tuning (PEFT)方法在临床决策任务中的适用性，针对不同规模的语言模型，包括仅有2500万参数的小型模型。研究发现，大多数PEFT方法在任务间表现差异显著，但LoRA方法在所有模型大小和任务中保持高性能，几乎达到或匹配完全微调的水平。PEFT方法的优势在于显著降低训练成本和提高速度，使专业模型适合低成本本地硬件，并通过领域特定预训练优化效率与性能的权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10597v1",
      "published_date": "2024-02-16 11:30:11 UTC",
      "updated_date": "2024-02-16 11:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:07:54.196306"
    },
    {
      "arxiv_id": "2402.10586v2",
      "title": "Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs",
      "title_zh": "翻译失败",
      "authors": [
        "Zae Myung Kim",
        "Kwang Hee Lee",
        "Preston Zhu",
        "Vipul Raheja",
        "Dongyeop Kang"
      ],
      "abstract": "With the advent of large language models (LLM), the line between\nhuman-crafted and machine-generated texts has become increasingly blurred. This\npaper delves into the inquiry of identifying discernible and unique linguistic\nproperties in texts that were written by humans, particularly uncovering the\nunderlying discourse structures of texts beyond their surface structures.\nIntroducing a novel methodology, we leverage hierarchical parse trees and\nrecursive hypergraphs to unveil distinctive discourse patterns in texts\nproduced by both LLMs and humans. Empirical findings demonstrate that, although\nboth LLMs and humans generate distinct discourse patterns influenced by\nspecific domains, human-written texts exhibit more structural variability,\nreflecting the nuanced nature of human writing in different domains. Notably,\nincorporating hierarchical discourse features enhances binary classifiers'\noverall performance in distinguishing between human-written and\nmachine-generated texts, even on out-of-distribution and paraphrased samples.\nThis underscores the significance of incorporating hierarchical discourse\nfeatures in the analysis of text patterns. The code and dataset are available\nat https://github.com/minnesotanlp/threads-of-subtlety.",
      "tldr_zh": "本论文探讨了如何通过话语模式（discourse motifs）区分人类撰写和机器生成的文本，特别是分析文本的深层话语结构。研究引入了一种新方法，利用 hierarchical parse trees 和 recursive hypergraphs 来揭示 large language models (LLM) 生成文本与人类文本的独特模式。结果显示，人类文本表现出更大的结构变异性，受特定领域影响，而整合分层话语特征后，二元分类器在区分文本方面性能显著提升，尤其在分布外和改写样本上。该方法强调了层次化话语特征在文本分析中的重要性，并提供了代码和数据集以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, accepted at ACL 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2402.10586v2",
      "published_date": "2024-02-16 11:20:30 UTC",
      "updated_date": "2024-06-06 20:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:08:04.434464"
    },
    {
      "arxiv_id": "2402.10580v1",
      "title": "Efficient Multi-task Uncertainties for Joint Semantic Segmentation and Monocular Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Landgraf",
        "Markus Hillemann",
        "Theodor Kapler",
        "Markus Ulrich"
      ],
      "abstract": "Quantifying the predictive uncertainty emerged as a possible solution to\ncommon challenges like overconfidence or lack of explainability and robustness\nof deep neural networks, albeit one that is often computationally expensive.\nMany real-world applications are multi-modal in nature and hence benefit from\nmulti-task learning. In autonomous driving, for example, the joint solution of\nsemantic segmentation and monocular depth estimation has proven to be valuable.\nIn this work, we first combine different uncertainty quantification methods\nwith joint semantic segmentation and monocular depth estimation and evaluate\nhow they perform in comparison to each other. Additionally, we reveal the\nbenefits of multi-task learning with regard to the uncertainty quality compared\nto solving both tasks separately. Based on these insights, we introduce\nEMUFormer, a novel student-teacher distillation approach for joint semantic\nsegmentation and monocular depth estimation as well as efficient multi-task\nuncertainty quantification. By implicitly leveraging the predictive\nuncertainties of the teacher, EMUFormer achieves new state-of-the-art results\non Cityscapes and NYUv2 and additionally estimates high-quality predictive\nuncertainties for both tasks that are comparable or superior to a Deep Ensemble\ndespite being an order of magnitude more efficient.",
      "tldr_zh": "本文研究了在联合语义分割和单目深度估计任务中，使用不确定性量化方法来解决深度神经网络的过度自信和鲁棒性问题，同时强调多任务学习的优势。作者首先比较了不同不确定性量化方法，并揭示了多任务学习相对于独立任务在不确定性质量上的提升。基于此，他们提出了EMUFormer，一种新型学生-教师蒸馏(student-teacher distillation)框架，能够在Cityscapes和NYUv2数据集上实现新的最先进(state-of-the-art)性能，并以高效方式估计高质量的预测不确定性，性能可比或优于Deep Ensemble。总的来说，该方法显著提高了多任务学习的效率和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 5 figures, 10 tables, submitted to peer-reviewed journal",
      "pdf_url": "http://arxiv.org/pdf/2402.10580v1",
      "published_date": "2024-02-16 11:09:16 UTC",
      "updated_date": "2024-02-16 11:09:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:08:19.416750"
    },
    {
      "arxiv_id": "2402.10575v1",
      "title": "Symbolic Autoencoding for Self-Supervised Sequence Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Hossein Amani",
        "Nicolas Mario Baldwin",
        "Amin Mansouri",
        "Martin Josifoski",
        "Maxime Peyrard",
        "Robert West"
      ],
      "abstract": "Traditional language models, adept at next-token prediction in text\nsequences, often struggle with transduction tasks between distinct symbolic\nsystems, particularly when parallel data is scarce. Addressing this issue, we\nintroduce \\textit{symbolic autoencoding} ($\\Sigma$AE), a self-supervised\nframework that harnesses the power of abundant unparallel data alongside\nlimited parallel data. $\\Sigma$AE connects two generative models via a discrete\nbottleneck layer and is optimized end-to-end by minimizing reconstruction loss\n(simultaneously with supervised loss for the parallel data), such that the\nsequence generated by the discrete bottleneck can be read out as the transduced\ninput sequence. We also develop gradient-based methods allowing for efficient\nself-supervised sequence learning despite the discreteness of the bottleneck.\nOur results demonstrate that $\\Sigma$AE significantly enhances performance on\ntransduction tasks, even with minimal parallel data, offering a promising\nsolution for weakly supervised learning scenarios.",
      "tldr_zh": "本研究针对传统语言模型在不同符号系统间转导任务上的局限性（如数据稀缺问题），提出了一种自监督框架 symbolic autoencoding (ΣAE)。ΣAE 通过一个离散瓶颈层连接两个生成模型，并通过最小化重构损失（结合平行数据的监督损失）实现端到端优化，使生成的序列可被解读为转导后的输入序列。该框架还开发了基于梯度的方法来处理瓶颈的离散性，从而实现高效的自监督序列学习。实验结果表明，ΣAE 显著提升了转导任务的性能，即使平行数据很少，为弱监督学习场景提供了有前景的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10575v1",
      "published_date": "2024-02-16 11:04:31 UTC",
      "updated_date": "2024-02-16 11:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:08:30.290075"
    },
    {
      "arxiv_id": "2404.03664v4",
      "title": "LLMs in the Heart of Differential Testing: A Case Study on a Medical Rule Engine",
      "title_zh": "翻译失败",
      "authors": [
        "Erblin Isaku",
        "Christoph Laaber",
        "Hassan Sartaj",
        "Shaukat Ali",
        "Thomas Schwitalla",
        "Jan F. Nygård"
      ],
      "abstract": "The Cancer Registry of Norway (CRN) uses an automated cancer registration\nsupport system (CaReSS) to support core cancer registry activities, i.e, data\ncapture, data curation, and producing data products and statistics for various\nstakeholders. GURI is a core component of CaReSS, which is responsible for\nvalidating incoming data with medical rules. Such medical rules are manually\nimplemented by medical experts based on medical standards, regulations, and\nresearch. Since large language models (LLMs) have been trained on a large\namount of public information, including these documents, they can be employed\nto generate tests for GURI. Thus, we propose an LLM-based test generation and\ndifferential testing approach (LLMeDiff) to test GURI. We experimented with\nfour different LLMs, two medical rule engine implementations, and 58 real\nmedical rules to investigate the hallucination, success, time efficiency, and\nrobustness of the LLMs to generate tests, and these tests' ability to find\npotential issues in GURI. Our results showed that GPT-3.5 hallucinates the\nleast, is the most successful, and is generally the most robust; however, it\nhas the worst time efficiency. Our differential testing revealed 22 medical\nrules where implementation inconsistencies were discovered (e.g., regarding\nhandling rule versions). Finally, we provide insights for practitioners and\nresearchers based on the results.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型（LLMs）的测试生成和差分测试方法（LLMeDiff），用于测试挪威癌症登记处（CRN）的医疗规则引擎GURI，以识别规则实现中的潜在问题。研究者实验了四种LLMs、两个规则引擎实现和58个真实医疗规则，评估了LLMs在hallucination、成功率、时间效率和鲁棒性方面的表现，结果显示GPT-3.5在减少hallucination和提升成功率及鲁棒性上最优，但其时间效率最差。最终，差分测试发现了22个医疗规则的实现不一致（如规则版本处理），并提供了对从业者和研究人员的实用见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 6 figures, 4 tables, 1 listing, revised arguments",
      "pdf_url": "http://arxiv.org/pdf/2404.03664v4",
      "published_date": "2024-02-16 10:56:15 UTC",
      "updated_date": "2025-02-28 15:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:08:43.118747"
    },
    {
      "arxiv_id": "2402.10571v2",
      "title": "Direct Preference Optimization with an Offset",
      "title_zh": "带有偏移的直接偏好优化",
      "authors": [
        "Afra Amini",
        "Tim Vieira",
        "Ryan Cotterell"
      ],
      "abstract": "Direct preference optimization (DPO) is a successful fine-tuning strategy for\naligning large language models with human preferences without the need to train\na reward model or employ reinforcement learning. DPO, as originally formulated,\nrelies on binary preference data and fine-tunes a language model to increase\nthe likelihood of a preferred response over a dispreferred response. However,\nnot all preference pairs are equal. Sometimes, the preferred response is only\nslightly better than the dispreferred one. In other cases, the preference is\nmuch stronger. For instance, if a response contains harmful or toxic content,\nthe annotator will have a strong preference for that response. In this paper,\nwe propose a generalization of DPO, termed DPO with an offset (ODPO), that does\nnot treat every preference pair equally during fine-tuning. Intuitively, ODPO\nrequires the difference between the likelihood of the preferred and\ndispreferred response to be greater than an offset value. The offset is\ndetermined based on the extent to which one response is preferred over another.\nOur experiments on various tasks suggest that ODPO significantly outperforms\nDPO in aligning language models, especially when the number of preference pairs\nis limited.",
      "tldr_zh": "这篇论文提出了 ODPO（Direct Preference Optimization with an Offset），作为 DPO（Direct Preference Optimization）的改进版本，用于更有效地微调大型语言模型以对齐人类偏好。传统 DPO 在处理二元偏好数据时未区分偏好强度的差异，导致某些偏好对（如轻微 vs. 强烈偏好）处理不均等。ODPO 通过引入偏移值（offset），要求首选响应与非首选响应的可能性差大于该值，从而根据偏好程度调整训练过程。实验结果表明，ODPO 在各种任务上显著优于 DPO，尤其在偏好对数量有限的情况下。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10571v2",
      "published_date": "2024-02-16 10:55:38 UTC",
      "updated_date": "2024-06-06 12:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:08:53.417462"
    },
    {
      "arxiv_id": "2402.10567v4",
      "title": "InSaAF: Incorporating Safety through Accuracy and Fairness | Are LLMs ready for the Indian Legal Domain?",
      "title_zh": "翻译失败",
      "authors": [
        "Yogesh Tripathi",
        "Raghav Donakanti",
        "Sahil Girhepuje",
        "Ishan Kavathekar",
        "Bhaskara Hanuma Vedula",
        "Gokul S Krishnan",
        "Shreya Goyal",
        "Anmol Goel",
        "Balaraman Ravindran",
        "Ponnurangam Kumaraguru"
      ],
      "abstract": "Recent advancements in language technology and Artificial Intelligence have\nresulted in numerous Language Models being proposed to perform various tasks in\nthe legal domain ranging from predicting judgments to generating summaries.\nDespite their immense potential, these models have been proven to learn and\nexhibit societal biases and make unfair predictions. In this study, we explore\nthe ability of Large Language Models (LLMs) to perform legal tasks in the\nIndian landscape when social factors are involved. We present a novel metric,\n$\\beta$-weighted $\\textit{Legal Safety Score ($LSS_{\\beta}$)}$, which\nencapsulates both the fairness and accuracy aspects of the LLM. We assess LLMs'\nsafety by considering its performance in the $\\textit{Binary Statutory\nReasoning}$ task and its fairness exhibition with respect to various axes of\ndisparities in the Indian society. Task performance and fairness scores of\nLLaMA and LLaMA--2 models indicate that the proposed $LSS_{\\beta}$ metric can\neffectively determine the readiness of a model for safe usage in the legal\nsector. We also propose finetuning pipelines, utilising specialised legal\ndatasets, as a potential method to mitigate bias and improve model safety. The\nfinetuning procedures on LLaMA and LLaMA--2 models increase the $LSS_{\\beta}$,\nimproving their usability in the Indian legal domain. Our code is publicly\nreleased.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在印度法律领域的应用，焦点在于模型的准确性和公平性，以评估其处理社会因素时的安全性。研究提出了一种新指标β-weighted Legal Safety Score (LSS_β)，它结合了模型在Binary Statutory Reasoning任务中的性能和对印度社会不平等轴的公平性表现。实验结果显示，LLaMA和LLaMA-2模型的初始表现不足，通过使用专门法律数据集的微调管道，可以显著提高LSS_β值，从而提升模型在印度法律领域的可用性。代码已公开，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10567v4",
      "published_date": "2024-02-16 10:54:10 UTC",
      "updated_date": "2024-06-17 17:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:09:05.659231"
    },
    {
      "arxiv_id": "2402.10543v2",
      "title": "Strong hallucinations from negation and how to fix them",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Asher",
        "Swarnadeep Bhar"
      ],
      "abstract": "Despite great performance on many tasks, language models (LMs) still struggle\nwith reasoning, sometimes providing responses that cannot possibly be true\nbecause they stem from logical incoherence. We call such responses\n\\textit{strong hallucinations} and prove that they follow from an LM's\ncomputation of its internal representations for logical operators and outputs\nfrom those representations. Focusing on negation, we provide a novel solution\nin which negation is treated not as another element of a latent representation,\nbut as \\textit{an operation over an LM's latent representations that constrains\nhow they may evolve}. We show that our approach improves model performance in\ncloze prompting and natural language inference tasks with negation without\nrequiring training on sparse negative data.",
      "tldr_zh": "该研究探讨了语言模型(LMs)在处理否定时产生的强幻觉(strong hallucinations)问题，这些幻觉源于模型对逻辑运算符的内部表示，导致逻辑不一致的响应。作者提出了一种新方法，将否定视为对潜在表示的操作，而不是潜在表示的一部分，从而约束表示的演变过程。该方法无需额外训练稀疏负面数据，即可显著提升模型在闭合提示(cloze prompting)和自然语言推理(natural language inference)任务中的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 62nd Annual Meeting of the Association for\n  Computational Linguistics (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2402.10543v2",
      "published_date": "2024-02-16 10:11:20 UTC",
      "updated_date": "2024-08-20 08:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:09:17.569771"
    },
    {
      "arxiv_id": "2402.12392v1",
      "title": "A Regression Mixture Model to understand the effect of the Covid-19 pandemic on Public Transport Ridership",
      "title_zh": "翻译失败",
      "authors": [
        "Hugues Moreau",
        "Étienne Côme",
        "Allou Samé",
        "Latifa Oukhellou"
      ],
      "abstract": "The Covid-19 pandemic drastically changed urban mobility, both during the\nheight of the pandemic with government lockdowns, but also in the longer term\nwith the adoption of working-from-home policies. To understand its effects on\nrail public transport ridership, we propose a dedicated Regression Mixture\nModel able to perform both the clustering of public transport stations and the\nsegmentation of time periods, while ignoring variations due to additional\nvariables such as the official lockdowns or non-working days. Each cluster is\nthus defined by a series of segments in which the effect of the exogenous\nvariables is constant. As each segment within a cluster has its own regression\ncoefficients to model the impact of the covariates, we analyze how these\ncoefficients evolve to understand the changes in the cluster. We present the\nregression mixture model and the parameter estimation using the EM algorithm,\nbefore demonstrating the benefits of the model on both simulated and real data.\nThanks to a five-year dataset of the ridership in the Paris public transport\nsystem, we analyze the impact of the pandemic, not only in terms of the number\nof travelers but also on the weekly commute. We further analyze the specific\nchanges that the pandemic caused inside each cluster.",
      "tldr_zh": "本研究提出了一种Regression Mixture Model，用于分析Covid-19大流行对公共交通乘客量的影响，该模型能够同时聚类交通站点和分割时间段，同时忽略如官方封锁或非工作日的变量干扰。模型通过EM算法估计参数，每个聚类由一系列段组成，这些段内外生变量的影响保持恒定，从而跟踪变量系数的变化以理解大流行带来的影响。在使用巴黎公共交通系统五年的真实数据进行验证时，该模型揭示了Covid-19不仅减少了乘客数量，还改变了每周通勤模式，并在不同聚类中显示了具体的变化趋势。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12392v1",
      "published_date": "2024-02-16 09:37:58 UTC",
      "updated_date": "2024-02-16 09:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:09:27.994818"
    },
    {
      "arxiv_id": "2402.10532v1",
      "title": "Properties and Challenges of LLM-Generated Explanations",
      "title_zh": "LLM 生成解释的属性与挑战",
      "authors": [
        "Jenny Kunz",
        "Marco Kuhlmann"
      ],
      "abstract": "The self-rationalising capabilities of large language models (LLMs) have been\nexplored in restricted settings, using task/specific data sets. However,\ncurrent LLMs do not (only) rely on specifically annotated data; nonetheless,\nthey frequently explain their outputs. The properties of the generated\nexplanations are influenced by the pre-training corpus and by the target data\nused for instruction fine-tuning. As the pre-training corpus includes a large\namount of human-written explanations \"in the wild\", we hypothesise that LLMs\nadopt common properties of human explanations. By analysing the outputs for a\nmulti-domain instruction fine-tuning data set, we find that generated\nexplanations show selectivity and contain illustrative elements, but less\nfrequently are subjective or misleading. We discuss reasons and consequences of\nthe properties' presence or absence. In particular, we outline positive and\nnegative implications depending on the goals and user groups of the\nself-rationalising system.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 生成解释的特性及其挑战，假设这些解释继承了人类解释的常见属性，如选择性和说明性元素。作者通过分析多领域指令微调数据集，发现生成的解释显示出选择性并包含说明性内容，但较少主观或误导性。论文讨论了这些特性的原因和后果，包括对自理性系统的积极影响（如提升可解释性）和潜在负面影响（如依赖预训练语料的局限性）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10532v1",
      "published_date": "2024-02-16 09:37:54 UTC",
      "updated_date": "2024-02-16 09:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:09:40.268721"
    },
    {
      "arxiv_id": "2402.10528v3",
      "title": "Can We Verify Step by Step for Incorrect Answer Detection?",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Xu",
        "Shizhe Diao",
        "Can Yang",
        "Yang Wang"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting has marked a significant advancement in\nenhancing the reasoning capabilities of large language models (LLMs). Previous\nstudies have developed various extensions of CoT, which focus primarily on\nenhancing end-task performance. In addition, there has been research on\nassessing the quality of reasoning chains in CoT. This raises an intriguing\nquestion: Is it possible to predict the accuracy of LLM outputs by scrutinizing\nthe reasoning chains they generate? To answer this research question, we\nintroduce a benchmark, R2PE, designed specifically to explore the relationship\nbetween reasoning chains and performance in various reasoning tasks spanning\nfive different domains. This benchmark aims to measure the falsehood of the\nfinal output of LLMs based on the reasoning steps. To make full use of\ninformation in multiple reasoning chains, we propose the process discernibility\nscore (PDS) framework that beats the answer-checking baseline by a large\nmargin. Concretely, this resulted in an average of $5.1\\%$ increase in the F1\nscore and $2.97\\%$ improvement in AUC-PR across all 45 subsets within R2PE. We\nfurther demonstrate our PDS's efficacy in advancing open-domain QA accuracy.",
      "tldr_zh": "本研究探讨了通过分析Chain-of-Thought (CoT) 推理链是否能预测大型语言模型 (LLMs) 输出的准确性，以检测不正确答案。研究者引入了R2PE基准，涵盖五个领域的各种推理任务，用于评估推理步骤与最终输出错误性的关系。针对多个推理链，他们提出了process discernibility score (PDS) 框架，比基线方法平均提升F1分数5.1%和AUC-PR 2.97%，并证明了PDS在提升开放域QA准确性方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10528v3",
      "published_date": "2024-02-16 09:29:50 UTC",
      "updated_date": "2025-01-22 03:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:09:52.885149"
    },
    {
      "arxiv_id": "2402.10524v1",
      "title": "LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Minsuk Kahng",
        "Ian Tenney",
        "Mahima Pushkarna",
        "Michael Xieyang Liu",
        "James Wexler",
        "Emily Reif",
        "Krystal Kallarackal",
        "Minsuk Chang",
        "Michael Terry",
        "Lucas Dixon"
      ],
      "abstract": "Automatic side-by-side evaluation has emerged as a promising approach to\nevaluating the quality of responses from large language models (LLMs). However,\nanalyzing the results from this evaluation approach raises scalability and\ninterpretability challenges. In this paper, we present LLM Comparator, a novel\nvisual analytics tool for interactively analyzing results from automatic\nside-by-side evaluation. The tool supports interactive workflows for users to\nunderstand when and why a model performs better or worse than a baseline model,\nand how the responses from two models are qualitatively different. We\niteratively designed and developed the tool by closely working with researchers\nand engineers at a large technology company. This paper details the user\nchallenges we identified, the design and development of the tool, and an\nobservational study with participants who regularly evaluate their models.",
      "tldr_zh": "本研究介绍了LLM Comparator，一种新型视觉分析工具，用于交互式评估大型语言模型(LLMs)的自动并排评估结果，解决可伸缩性和可解释性挑战。该工具支持用户通过交互工作流理解特定情况下模型的表现优劣、原因以及响应之间的定性差异，并通过与技术公司研究人员和工程师的合作进行迭代设计。在一项观察性研究中，该工具帮助参与者更有效地评估模型性能。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10524v1",
      "published_date": "2024-02-16 09:14:49 UTC",
      "updated_date": "2024-02-16 09:14:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:10:05.114149"
    },
    {
      "arxiv_id": "2402.10516v1",
      "title": "Generative AI for Controllable Protein Sequence Design: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Yiheng Zhu",
        "Zitai Kong",
        "Jialu Wu",
        "Weize Liu",
        "Yuqiang Han",
        "Mingze Yin",
        "Hongxia Xu",
        "Chang-Yu Hsieh",
        "Tingjun Hou"
      ],
      "abstract": "The design of novel protein sequences with targeted functionalities underpins\na central theme in protein engineering, impacting diverse fields such as drug\ndiscovery and enzymatic engineering. However, navigating this vast\ncombinatorial search space remains a severe challenge due to time and financial\nconstraints. This scenario is rapidly evolving as the transformative\nadvancements in AI, particularly in the realm of generative models and\noptimization algorithms, have been propelling the protein design field towards\nan unprecedented revolution. In this survey, we systematically review recent\nadvances in generative AI for controllable protein sequence design. To set the\nstage, we first outline the foundational tasks in protein sequence design in\nterms of the constraints involved and present key generative models and\noptimization algorithms. We then offer in-depth reviews of each design task and\ndiscuss the pertinent applications. Finally, we identify the unresolved\nchallenges and highlight research opportunities that merit deeper exploration.",
      "tldr_zh": "这篇调查论文探讨了生成式 AI 在可控蛋白质序列设计中的应用，旨在解决蛋白工程领域中序列设计面临的巨大组合搜索空间挑战。论文系统回顾了生成模型和优化算法的关键进展，包括基础任务的概述、各设计任务的深入分析以及实际应用，如药物发现和酶工程。最终，它指出了未解决的挑战和未来的研究机会，推动了 AI 在蛋白序列设计领域的革命性发展。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.10516v1",
      "published_date": "2024-02-16 09:05:02 UTC",
      "updated_date": "2024-02-16 09:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:10:16.723904"
    },
    {
      "arxiv_id": "2402.10515v1",
      "title": "Power-Efficient Indoor Localization Using Adaptive Channel-aware Ultra-wideband DL-TDOA",
      "title_zh": "翻译失败",
      "authors": [
        "Sagnik Bhattacharya",
        "Junyoung Choi",
        "Joohyun Lee"
      ],
      "abstract": "Among the various Ultra-wideband (UWB) ranging methods, the absence of uplink\ncommunication or centralized computation makes downlink\ntime-difference-of-arrival (DL-TDOA) localization the most suitable for\nlarge-scale industrial deployments. However, temporary or permanent obstacles\nin the deployment region often lead to non-line-of-sight (NLOS) channel path\nand signal outage effects, which result in localization errors. Prior research\nhas addressed this problem by increasing the ranging frequency, which leads to\na heavy increase in the user device power consumption. It also does not\ncontribute to any increase in localization accuracy under line-of-sight (LOS)\nconditions. In this paper, we propose and implement a novel low-power\nchannel-aware dynamic frequency DL-TDOA ranging algorithm. It comprises NLOS\nprobability predictor based on a convolutional neural network (CNN), a dynamic\nranging frequency control module, and an IMU sensor-based ranging filter. Based\non the conducted experiments, we show that the proposed algorithm achieves 50%\nhigher accuracy in NLOS conditions while having 46% lower power consumption in\nLOS conditions compared to baseline methods from prior research.",
      "tldr_zh": "该论文针对Ultra-wideband (UWB)中的Downlink Time-Difference-of-Arrival (DL-TDOA)室内定位方法，解决了障碍物导致的Non-Line-of-Sight (NLOS)通道问题，该问题会造成定位错误，而传统方法通过增加测距频率却增加了设备功耗。作者提出了一种新型低功耗的自适应通道感知动态频率DL-TDOA算法，包括基于Convolutional Neural Network (CNN)的NLOS概率预测器、动态测距频率控制模块以及Inertial Measurement Unit (IMU)传感器-based测距过滤器。该算法在实验中实现了在NLOS条件下准确性提高50%，而在Line-of-Sight (LOS)条件下功耗降低46%，相较于现有方法更高效且实用。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10515v1",
      "published_date": "2024-02-16 09:04:04 UTC",
      "updated_date": "2024-02-16 09:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:10:30.443263"
    },
    {
      "arxiv_id": "2402.10511v1",
      "title": "Can Transformers Predict Vibrations?",
      "title_zh": "翻译失败",
      "authors": [
        "Fusataka Kuniyoshi",
        "Yoshihide Sawada"
      ],
      "abstract": "Highly accurate time-series vibration prediction is an important research\nissue for electric vehicles (EVs). EVs often experience vibrations when driving\non rough terrains, known as torsional resonance. This resonance, caused by the\ninteraction between motor and tire vibrations, puts excessive loads on the\nvehicle's drive shaft. However, current damping technologies only detect\nresonance after the vibration amplitude of the drive shaft torque reaches a\ncertain threshold, leading to significant loads on the shaft at the time of\ndetection. In this study, we propose a novel approach to address this issue by\nintroducing Resoformer, a transformer-based model for predicting torsional\nresonance. Resoformer utilizes time-series of the motor rotation speed as input\nand predicts the amplitude of torsional vibration at a specified quantile\noccurring in the shaft after the input series. By calculating the attention\nbetween recursive and convolutional features extracted from the measured data\npoints, Resoformer improves the accuracy of vibration forecasting. To evaluate\nthe model, we use a vibration dataset called VIBES (Dataset for Forecasting\nVibration Transition in EVs), consisting of 2,600 simulator-generated vibration\nsequences. Our experiments, conducted on strong baselines built on the VIBES\ndataset, demonstrate that Resoformer achieves state-of-the-art results. In\nconclusion, our study answers the question \"Can Transformers Forecast\nVibrations?\" While traditional transformer architectures show low performance\nin forecasting torsional resonance waves, our findings indicate that combining\nrecurrent neural network and temporal convolutional network using the\ntransformer architecture improves the accuracy of long-term vibration\nforecasting.",
      "tldr_zh": "这篇论文探讨了Transformer模型在预测电动汽车(EVs)扭转共振振动方面的潜力，针对现有技术只能在振动达到阈值后检测的问题，提出了一种新型模型Resoformer。Resoformer利用电机转速时间序列作为输入，通过计算递归神经网络(RNN)和时间卷积网络(TCN)特征之间的注意力机制，来预测驱动轴扭转振幅的指定分位数。实验在VIBES数据集（包含2600个模拟振动序列）上进行，结果显示Resoformer比传统Transformer架构取得了最先进性能，证明了结合RNN和TCN的Transformer方法能显著提升长期振动预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10511v1",
      "published_date": "2024-02-16 08:56:22 UTC",
      "updated_date": "2024-02-16 08:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:10:42.558840"
    },
    {
      "arxiv_id": "2402.10510v1",
      "title": "Human Goal Recognition as Bayesian Inference: Investigating the Impact of Actions, Timing, and Goal Solvability",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyuan Zhang",
        "Charles Kemp",
        "Nir Lipovetzky"
      ],
      "abstract": "Goal recognition is a fundamental cognitive process that enables individuals\nto infer intentions based on available cues. Current goal recognition\nalgorithms often take only observed actions as input, but here we use a\nBayesian framework to explore the role of actions, timing, and goal solvability\nin goal recognition. We analyze human responses to goal-recognition problems in\nthe Sokoban domain, and find that actions are assigned most importance, but\nthat timing and solvability also influence goal recognition in some cases,\nespecially when actions are uninformative. We leverage these findings to\ndevelop a goal recognition model that matches human inferences more closely\nthan do existing algorithms. Our work provides new insight into human goal\nrecognition and takes a step towards more human-like AI models.",
      "tldr_zh": "该研究将人类目标识别（goal recognition）视为Bayesian inference过程，探讨了actions、timing和goal solvability对识别的影响。研究者通过分析Sokoban领域的人类响应发现，actions是最主要的因素，但timing和goal solvability在actions不具信息性时也会发挥作用。基于这些发现，他们开发了一个比现有算法更接近人类推断的目标识别模型，为理解人类认知和构建更像人类的AI模型提供了新见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.10510v1",
      "published_date": "2024-02-16 08:55:23 UTC",
      "updated_date": "2024-02-16 08:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:10:52.420617"
    },
    {
      "arxiv_id": "2402.10500v2",
      "title": "Active Preference Optimization for Sample Efficient RLHF",
      "title_zh": "主动偏好优化用于样本高效的 RLHF",
      "authors": [
        "Nirjhar Das",
        "Souradip Chakraborty",
        "Aldo Pacchiano",
        "Sayak Ray Chowdhury"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is pivotal in aligning\nLarge Language Models (LLMs) with human preferences. Although aligned\ngenerative models have shown remarkable abilities in various tasks, their\nreliance on high-quality human preference data creates a costly bottleneck in\nthe practical application of RLHF. One primary reason is that current methods\nrely on uniformly picking prompt-generation pairs from a dataset of\nprompt-generations, to collect human feedback, resulting in sub-optimal\nalignment under a constrained budget, which highlights the criticality of\nadaptive strategies in efficient alignment. Recent works [Mehta et al., 2023,\nMuldrew et al., 2024] have tried to address this problem by designing various\nheuristics based on generation uncertainty. However, either the assumptions in\n[Mehta et al., 2023] are restrictive, or [Muldrew et al., 2024] do not provide\nany rigorous theoretical guarantee. To address these, we reformulate RLHF\nwithin contextual preference bandit framework, treating prompts as contexts,\nand develop an active-learning algorithm, $\\textit{Active Preference\nOptimization}$ ($\\texttt{APO}$), which enhances model alignment by querying\npreference data from the most important samples, achieving superior performance\nfor small sample budget. We analyze the theoretical performance guarantees of\n$\\texttt{APO}$ under the BTL preference model showing that the suboptimality\ngap of the policy learned via $\\texttt{APO}$ scales as $O(1/\\sqrt{T})$ for a\nbudget of $T$. We also show that collecting preference data by choosing prompts\nrandomly leads to a policy that suffers a constant sub-optimality. We perform\ndetailed experimental evaluations on practical preference datasets to validate\n$\\texttt{APO}$'s efficacy over the existing methods, establishing it as a\nsample-efficient and practical solution of alignment in a cost-effective and\nscalable manner.",
      "tldr_zh": "这篇论文针对强化学习从人类反馈（RLHF）中对齐大型语言模型（LLMs）的过程，提出了一种样本高效的主动偏好优化（Active Preference Optimization, APO）算法，以解决数据收集成本高的问题。APO 通过将 RLHF 重新表述为 contextual preference bandit 框架，并采用主动学习策略从最重要的提示样本中查询偏好数据，从而提升模型对齐效率。理论分析表明，APO 的策略次优性差距为 O(1/√T)，而随机采样会导致恒定次优性；实验结果在实际偏好数据集上验证了其优于现有方法的性能，提供了一种成本有效且可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "New experimental results added. Some reorganization",
      "pdf_url": "http://arxiv.org/pdf/2402.10500v2",
      "published_date": "2024-02-16 08:19:34 UTC",
      "updated_date": "2024-06-05 15:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:11:06.478253"
    },
    {
      "arxiv_id": "2403.15396v1",
      "title": "I would love this to be like an assistant, not the teacher: a voice of the customer perspective of what distance learning students want from an Artificial Intelligence Digital Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Bart Rienties",
        "John Domingue",
        "Subby Duttaroy",
        "Christothea Herodotou",
        "Felipe Tessarolo",
        "Denise Whitelock"
      ],
      "abstract": "With the release of Generative AI systems such as ChatGPT, an increasing\ninterest in using Artificial Intelligence (AI) has been observed across\ndomains, including higher education. While emerging statistics show the\npopularity of using AI amongst undergraduate students, little is yet known\nabout students' perceptions regarding AI including self-reported benefits and\nconcerns from their actual usage, in particular in distance learning contexts.\nUsing a two-step, mixed-methods approach, we examined the perceptions of ten\nonline and distance learning students from diverse disciplines regarding the\ndesign of a hypothetical AI Digital Assistant (AIDA). In the first step, we\ncaptured students' perceptions via interviews, while the second step supported\nthe triangulation of data by enabling students to share, compare, and contrast\nperceptions with those of peers. All participants agreed on the usefulness of\nsuch an AI tool while studying and reported benefits from using it for\nreal-time assistance and query resolution, support for academic tasks,\npersonalisation and accessibility, together with emotional and social support.\nStudents' concerns related to the ethical and social implications of\nimplementing AIDA, data privacy and data use, operational challenges, academic\nintegrity and misuse, and the future of education. Implications for the design\nof AI-tailored systems are also discussed.",
      "tldr_zh": "本研究探讨了远程学习学生对人工智能数字助理（AIDA）的期望，通过两步混合方法（包括访谈和数据三角化）调查了10名学生的看法。学生们普遍认可AIDA的益处，包括实时查询支持、学术任务协助、个性化服务、情感支持以及可访问性。调查还揭示了学生的担忧，如数据隐私、伦理问题、操作挑战、学术诚信风险以及对教育未来的影响。该研究为设计AI-tailored系统提供了重要启示，以更好地满足学生的需求。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "23 pages, 1 figure, submitted to Distance Education",
      "pdf_url": "http://arxiv.org/pdf/2403.15396v1",
      "published_date": "2024-02-16 08:10:41 UTC",
      "updated_date": "2024-02-16 08:10:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:11:16.807593"
    },
    {
      "arxiv_id": "2402.10496v2",
      "title": "Comparing Hallucination Detection Metrics for Multilingual Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoqiang Kang",
        "Terra Blevins",
        "Luke Zettlemoyer"
      ],
      "abstract": "While many hallucination detection techniques have been evaluated on English\ntext, their effectiveness in multilingual contexts remains unknown. This paper\nassesses how well various factual hallucination detection metrics (lexical\nmetrics like ROUGE and Named Entity Overlap, and Natural Language Inference\n(NLI)-based metrics) identify hallucinations in generated biographical\nsummaries across languages. We compare how well automatic metrics correlate to\neach other and whether they agree with human judgments of factuality. Our\nanalysis reveals that while the lexical metrics are ineffective, NLI-based\nmetrics perform well, correlating with human annotations in many settings and\noften outperforming supervised models. However, NLI metrics are still limited,\nas they do not detect single-fact hallucinations well and fail for\nlower-resource languages. Therefore, our findings highlight the gaps in\nexisiting hallucination detection methods for non-English languages and\nmotivate future research to develop more robust multilingual detection methods\nfor LLM hallucinations.",
      "tldr_zh": "这篇论文评估了各种事实幻觉检测指标（如ROUGE和Named Entity Overlap的词汇指标，以及基于Natural Language Inference (NLI)的指标）在多语言生成任务中的有效性，特别是针对生成传记摘要。研究通过比较这些指标之间的相关性以及与人类判断的一致性，发现NLI-based指标表现良好，在许多场景下与人类标注高度相关，甚至优于监督模型。另一方面，词汇指标无效，且NLI指标在检测单个事实幻觉和低资源语言方面存在局限性，因此论文强调了现有方法的不足，并呼吁开发更稳健的多语言幻觉检测技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10496v2",
      "published_date": "2024-02-16 08:10:34 UTC",
      "updated_date": "2024-06-16 00:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:11:30.143043"
    },
    {
      "arxiv_id": "2402.10492v1",
      "title": "Developing an Optimal Model for Predicting the Severity of Wheat Stem Rust (Case study of Arsi and Bale Zone)",
      "title_zh": "翻译失败",
      "authors": [
        "Tewodrose Altaye"
      ],
      "abstract": "This research utilized three types of artificial neural network (ANN)\nmethodologies, namely Backpropagation Neural Network (BPNN) with varied\ntraining, transfer, divide, and learning functions; Radial Basis Function\nNeural Network (RBFNN); and General Regression Neural Network (GRNN), to\nforecast the severity of stem rust. It considered parameters such as mean\nmaximum temperature, mean minimum temperature, mean rainfall, mean average\ntemperature, mean relative humidity, and different wheat varieties. The\nstatistical analysis revealed that GRNN demonstrated effective predictive\ncapability and required less training time compared to the other models.\nAdditionally, the results indicated that total seasonal rainfall positively\ninfluenced the development of wheat stem rust.\n  Keywords: Wheat stem rust, Back propagation neural network, Radial Basis\nFunction Neural Network, General Regression Neural Network.",
      "tldr_zh": "这篇论文针对 Arsi and Bale Zone 地区，开发了一种最佳模型来预测小麦茎锈病的严重程度，使用了三种人工神经网络方法：Backpropagation Neural Network (BPNN)、Radial Basis Function Neural Network (RBFNN) 和 General Regression Neural Network (GRNN)。研究考虑了包括平均最高温度、平均最低温度、平均降雨量、平均温度、平均相对湿度和不同小麦品种在内的参数，通过统计分析发现 GRNN 表现出色，具有高效的预测能力和更短的训练时间。结果表明，总季节降雨对小麦茎锈病的发生有积极影响，为农业病害预测提供了实用参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10492v1",
      "published_date": "2024-02-16 07:48:59 UTC",
      "updated_date": "2024-02-16 07:48:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:11:42.081851"
    },
    {
      "arxiv_id": "2402.10487v4",
      "title": "RPMixer: Shaking Up Time Series Forecasting with Random Projections for Large Spatial-Temporal Data",
      "title_zh": "翻译失败",
      "authors": [
        "Chin-Chia Michael Yeh",
        "Yujie Fan",
        "Xin Dai",
        "Uday Singh Saini",
        "Vivian Lai",
        "Prince Osei Aboagye",
        "Junpeng Wang",
        "Huiyuan Chen",
        "Yan Zheng",
        "Zhongfang Zhuang",
        "Liang Wang",
        "Wei Zhang"
      ],
      "abstract": "Spatial-temporal forecasting systems play a crucial role in addressing\nnumerous real-world challenges. In this paper, we investigate the potential of\naddressing spatial-temporal forecasting problems using general time series\nforecasting models, i.e., models that do not leverage the spatial relationships\namong the nodes. We propose a all-Multi-Layer Perceptron (all-MLP) time series\nforecasting architecture called RPMixer. The all-MLP architecture was chosen\ndue to its recent success in time series forecasting benchmarks. Furthermore,\nour method capitalizes on the ensemble-like behavior of deep neural networks,\nwhere each individual block within the network behaves like a base learner in\nan ensemble model, particularly when identity mapping residual connections are\nincorporated. By integrating random projection layers into our model, we\nincrease the diversity among the blocks' outputs, thereby improving the overall\nperformance of the network. Extensive experiments conducted on the largest\nspatial-temporal forecasting benchmark datasets demonstrate that the proposed\nmethod outperforms alternative methods, including both spatial-temporal graph\nmodels and general forecasting models.",
      "tldr_zh": "本研究探讨了使用通用时间序列预测模型（不依赖节点间空间关系）来解决空间-时间预测问题，提出了一种名为 RPMixer 的 all-MLP 架构，以提升对大规模空间-时间数据的预测性能。RPMixer 利用深度神经网络的集成式行为，通过在每个网络块中整合随机投影层（random projections），增加输出多样性并结合身份映射残差连接，从而优化模型表现。在最大的空间-时间预测基准数据集上进行的广泛实验表明，该方法优于现有空间-时间图模型和通用预测模型，展示了其在实际应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10487v4",
      "published_date": "2024-02-16 07:28:59 UTC",
      "updated_date": "2024-06-12 08:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:11:53.556131"
    },
    {
      "arxiv_id": "2402.10481v2",
      "title": "Emoji Driven Crypto Assets Market Reactions",
      "title_zh": "Emoji驱动的加密资产市场反应",
      "authors": [
        "Xiaorui Zuo",
        "Yao-Tsung Chen",
        "Wolfgang Karl Härdle"
      ],
      "abstract": "In the burgeoning realm of cryptocurrency, social media platforms like\nTwitter have become pivotal in influencing market trends and investor\nsentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based\nBERT model for a multimodal sentiment analysis, focusing on the impact of emoji\nsentiment on cryptocurrency markets. By translating emojis into quantifiable\nsentiment data, we correlate these insights with key market indicators like BTC\nPrice and the VCRIX index. Our architecture's analysis of emoji sentiment\ndemonstrated a distinct advantage over FinBERT's pure text sentiment analysis\nin such predicting power. This approach may be fed into the development of\ntrading strategies aimed at utilizing social media elements to identify and\nforecast market trends. Crucially, our findings suggest that strategies based\non emoji sentiment can facilitate the avoidance of significant market downturns\nand contribute to the stabilization of returns. This research underscores the\npractical benefits of integrating advanced AI-driven analyses into financial\nstrategies, offering a nuanced perspective on the interplay between digital\ncommunication and market dynamics in an academic context.",
      "tldr_zh": "本研究探讨了Twitter上emoji情感对加密货币市场的影响，利用GPT-4和微调的BERT模型进行多模态情感分析，将emoji转化为可量化的情感数据，并与BTC Price和VCRIX指数等市场指标相关联。结果显示，该方法在预测市场趋势方面优于FinBERT的纯文本分析，提供更强的预测能力。研究发现，基于emoji情感的策略有助于避免重大市场下跌并稳定投资回报。该工作强调了将AI驱动分析整合到金融策略中的实际价值，为数字通信与市场动态的互动提供了新视角。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-fin.ST"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10481v2",
      "published_date": "2024-02-16 07:05:49 UTC",
      "updated_date": "2024-05-04 14:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:12:05.626020"
    },
    {
      "arxiv_id": "2402.12170v3",
      "title": "Where is the answer? Investigating Positional Bias in Language Model Knowledge Extraction",
      "title_zh": "答案在哪里？调查语言模型知识提取中的位置偏差",
      "authors": [
        "Kuniaki Saito",
        "Kihyuk Sohn",
        "Chen-Yu Lee",
        "Yoshitaka Ushiku"
      ],
      "abstract": "Large language models require updates to remain up-to-date or adapt to new\ndomains by fine-tuning them with new documents. One key is memorizing the\nlatest information in a way that the memorized information is extractable with\na query prompt. However, LLMs suffer from a phenomenon called perplexity curse;\ndespite minimizing document perplexity during fine-tuning, LLMs struggle to\nextract information through a prompt sentence. In this new knowledge\nacquisition and extraction, we find a very intriguing fact that LLMs can\naccurately answer questions about the first sentence, but they struggle to\nextract information described in the middle or end of the documents used for\nfine-tuning. Our study suggests that the auto-regressive training causes this\nissue; each token is prompted by reliance on all previous tokens, which hinders\nthe model from recalling information from training documents by question\nprompts. To conduct the in-depth study, we publish both synthetic and real\ndatasets, enabling the evaluation of the QA performance w.r.t. the position of\nthe corresponding answer in a document. Our investigation shows that even a\nlarge model suffers from the perplexity curse, but regularization such as\ndenoising auto-regressive loss can enhance the information extraction from\ndiverse positions. These findings will be (i) a key to improving knowledge\nextraction from LLMs and (ii) new elements to discuss the trade-off between RAG\nand fine-tuning in adapting LLMs to a new domain.",
      "tldr_zh": "这篇论文调查了大型语言模型（LLMs）在知识提取中的位置偏差问题，发现LLMs 尽管在微调时最小化了文档的 perplexity curse，但往往能准确回答文档开头信息，而对中间或末尾内容提取困难。研究将此问题归因于自回归训练（auto-regressive training），并通过发布合成和真实数据集进行深入评估。实验结果显示，即使是大模型也受此影响，但采用正则化方法如 denoising auto-regressive loss 可以提升从不同位置提取信息的性能，并为优化LLMs知识提取以及讨论RAG与微调的权衡提供关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code is published at https://github.com/omron-sinicx/WhereIsTheAnswer",
      "pdf_url": "http://arxiv.org/pdf/2402.12170v3",
      "published_date": "2024-02-16 06:29:16 UTC",
      "updated_date": "2025-04-18 00:24:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:12:19.032052"
    },
    {
      "arxiv_id": "2402.10468v1",
      "title": "Adversarial Curriculum Graph Contrastive Learning with Pair-wise Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinjian Zhao",
        "Liang Zhang",
        "Yang Liu",
        "Ruocheng Guo",
        "Xiangyu Zhao"
      ],
      "abstract": "Graph contrastive learning (GCL) has emerged as a pivotal technique in the\ndomain of graph representation learning. A crucial aspect of effective GCL is\nthe caliber of generated positive and negative samples, which is intrinsically\ndictated by their resemblance to the original data. Nevertheless, precise\ncontrol over similarity during sample generation presents a formidable\nchallenge, often impeding the effective discovery of representative graph\npatterns. To address this challenge, we propose an innovative framework:\nAdversarial Curriculum Graph Contrastive Learning (ACGCL), which capitalizes on\nthe merits of pair-wise augmentation to engender graph-level positive and\nnegative samples with controllable similarity, alongside subgraph contrastive\nlearning to discern effective graph patterns therein. Within the ACGCL\nframework, we have devised a novel adversarial curriculum training methodology\nthat facilitates progressive learning by sequentially increasing the difficulty\nof distinguishing the generated samples. Notably, this approach transcends the\nprevalent sparsity issue inherent in conventional curriculum learning\nstrategies by adaptively concentrating on more challenging training data.\nFinally, a comprehensive assessment of ACGCL is conducted through extensive\nexperiments on six well-known benchmark datasets, wherein ACGCL conspicuously\nsurpasses a set of state-of-the-art baselines.",
      "tldr_zh": "这篇论文针对图对比学习 (GCL) 中正负样本生成相似度控制的挑战，提出了 Adversarial Curriculum Graph Contrastive Learning (ACGCL) 框架，以 pair-wise augmentation 生成可控相似度的图级正负样本，并结合 subgraph contrastive learning 来识别有效图模式。ACGCL 引入了 adversarial curriculum training 方法，通过逐步增加区分样本的难度，实现渐进学习，并适应性关注更具挑战性的训练数据，从而解决传统 curriculum learning 的稀疏问题。在六个基准数据集上的广泛实验中，ACGCL 显著超过了现有最先进基线模型，展示了其在图表示学习中的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10468v1",
      "published_date": "2024-02-16 06:17:50 UTC",
      "updated_date": "2024-02-16 06:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:12:29.985773"
    },
    {
      "arxiv_id": "2402.10466v4",
      "title": "Large Language Models as Zero-shot Dialogue State Tracker through Function Calling",
      "title_zh": "大型语言模型作为通过函数调用的零样本对话状态追踪器",
      "authors": [
        "Zekun Li",
        "Zhiyu Zoey Chen",
        "Mike Ross",
        "Patrick Huber",
        "Seungwhan Moon",
        "Zhaojiang Lin",
        "Xin Luna Dong",
        "Adithya Sagar",
        "Xifeng Yan",
        "Paul A. Crook"
      ],
      "abstract": "Large language models (LLMs) are increasingly prevalent in conversational\nsystems due to their advanced understanding and generative capabilities in\ngeneral contexts. However, their effectiveness in task-oriented dialogues\n(TOD), which requires not only response generation but also effective dialogue\nstate tracking (DST) within specific tasks and domains, remains less\nsatisfying. In this work, we propose a novel approach FnCTOD for solving DST\nwith LLMs through function calling. This method improves zero-shot DST,\nallowing adaptation to diverse domains without extensive data collection or\nmodel tuning. Our experimental results demonstrate that our approach achieves\nexceptional performance with both modestly sized open-source and also\nproprietary LLMs: with in-context prompting it enables various 7B or 13B\nparameter models to surpass the previous state-of-the-art (SOTA) achieved by\nChatGPT, and improves ChatGPT's performance beating the SOTA by 5.6% average\njoint goal accuracy (JGA). Individual model results for GPT-3.5 and GPT-4 are\nboosted by 4.8% and 14%, respectively. We also show that by fine-tuning on a\nsmall collection of diverse task-oriented dialogues, we can equip modestly\nsized models, specifically a 13B parameter LLaMA2-Chat model, with\nfunction-calling capabilities and DST performance comparable to ChatGPT while\nmaintaining their chat capabilities. We have made the code publicly available\nat https://github.com/facebookresearch/FnCTOD",
      "tldr_zh": "该论文提出了一种名为 FnCTOD 的方法，利用 Large Language Models (LLMs) 通过 Function Calling 实现 Zero-shot Dialogue State Tracker (DST)，以提升 Task-Oriented Dialogues (TOD) 中的对话状态跟踪性能，而无需大量数据或模型微调。方法通过 In-Context Prompting 使 7B 或 13B 参数的开源模型超越了 ChatGPT 的 State-of-the-Art (SOTA) 水平，并将 ChatGPT 的 Joint Goal Accuracy (JGA) 平均提升 5.6%，具体对 GPT-3.5 和 GPT-4 的提升分别为 4.8% 和 14%。此外，通过在小规模数据集上微调，13B 参数的 LLaMA2-Chat 模型可达到与 ChatGPT 相当的 DST 和聊天能力，并已开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Main. Code available at:\n  https://github.com/facebookresearch/FnCTOD",
      "pdf_url": "http://arxiv.org/pdf/2402.10466v4",
      "published_date": "2024-02-16 06:13:18 UTC",
      "updated_date": "2024-05-30 04:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:12:45.711883"
    },
    {
      "arxiv_id": "2402.10987v2",
      "title": "WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhui Hu",
        "Pengfei Cao",
        "Yubo Chen",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Knowledge editing aims to rectify inaccuracies in large language models\n(LLMs) without costly retraining for outdated or erroneous knowledge. However,\ncurrent knowledge editing methods primarily focus on single editing, failing to\nmeet the requirements for lifelong editing. This study reveals a performance\ndegradation encountered by knowledge editing in lifelong editing, characterized\nby toxicity buildup and toxicity flash, with the primary cause identified as\npattern unmatch. We introduce a knowledge editing approach named Wise-Layer\nKnowledge Editor (WilKE), which selects editing layer based on the pattern\nmatching degree of editing knowledge across different layers in language\nmodels. Experimental results demonstrate that, in lifelong editing, WilKE\nexhibits an average improvement of 46.2% and 67.8% on editing GPT2-XL and GPT-J\nrelative to state-of-the-art knowledge editing methods.",
      "tldr_zh": "知识编辑（Knowledge Editing）旨在修正大型语言模型（LLMs）的错误信息，而无需昂贵的重新训练，但现有方法主要局限于单次编辑，无法满足终身编辑（Lifelong Editing）的需求。研究发现，终身编辑过程中会因模式不匹配（Pattern Unmatch）导致性能下降，包括毒性积累（Toxicity Buildup）和毒性爆发（Toxicity Flash）。为此，提出Wise-Layer Knowledge Editor (WilKE)，该方法通过评估编辑知识在模型不同层面的模式匹配度来选择最佳编辑层。实验结果显示，WilKE 在终身编辑中相对于最先进方法，平均提升了46.2%（GPT2-XL）和67.8%（GPT-J）的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in ACL Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.10987v2",
      "published_date": "2024-02-16 05:29:59 UTC",
      "updated_date": "2024-06-05 07:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:12:56.114771"
    },
    {
      "arxiv_id": "2402.10986v3",
      "title": "FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gagan Bhatia",
        "El Moatez Billah Nagoudi",
        "Hasan Cavusoglu",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "We introduce FinTral, a suite of state-of-the-art multimodal large language\nmodels (LLMs) built upon the Mistral-7b model and tailored for financial\nanalysis. FinTral integrates textual, numerical, tabular, and image data. We\nenhance FinTral with domain-specific pretraining, instruction fine-tuning, and\nRLAIF training by exploiting a large collection of textual and visual datasets\nwe curate for this work. We also introduce an extensive benchmark featuring\nnine tasks and 25 datasets for evaluation, including hallucinations in the\nfinancial domain. Our FinTral model trained with direct preference optimization\nemploying advanced Tools and Retrieval methods, dubbed FinTral-DPO-T&R,\ndemonstrates an exceptional zero-shot performance. It outperforms ChatGPT-3.5\nin all tasks and surpasses GPT-4 in five out of nine tasks, marking a\nsignificant advancement in AI-driven financial technology. We also demonstrate\nthat FinTral has the potential to excel in real-time analysis and\ndecision-making in diverse financial contexts. The GitHub repository for\nFinTral is available at \\url{https://github.com/UBC-NLP/fintral}.",
      "tldr_zh": "本研究引入了 FinTral，一系列基于 Mistral-7b 模型的先进多模态 Large Language Models (LLMs)，专门针对金融分析整合文本、数字、表格和图像数据。通过领域特定预训练、指令微调以及 RLAIF 训练，FinTral 利用大量 curated 的文本和视觉数据集进行优化。FinTral-DPO-T&R 模型在零-shot performance 上表现出色，超越 ChatGPT-3.5 在所有任务中，并在九个任务中的五项中超过 GPT-4，为 AI 驱动的金融技术带来重大进展。该模型还展示了在实时分析和决策中的潜力，并提供了广泛基准和 GitHub 仓库支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10986v3",
      "published_date": "2024-02-16 05:05:12 UTC",
      "updated_date": "2024-06-14 13:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:13:07.139194"
    },
    {
      "arxiv_id": "2402.10427v1",
      "title": "Evaluating and Improving Continual Learning in Spoken Language Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Muqiao Yang",
        "Xiang Li",
        "Umberto Cappellazzo",
        "Shinji Watanabe",
        "Bhiksha Raj"
      ],
      "abstract": "Continual learning has emerged as an increasingly important challenge across\nvarious tasks, including Spoken Language Understanding (SLU). In SLU, its\nobjective is to effectively handle the emergence of new concepts and evolving\nenvironments. The evaluation of continual learning algorithms typically\ninvolves assessing the model's stability, plasticity, and generalizability as\nfundamental aspects of standards. However, existing continual learning metrics\nprimarily focus on only one or two of the properties. They neglect the overall\nperformance across all tasks, and do not adequately disentangle the plasticity\nversus stability/generalizability trade-offs within the model. In this work, we\npropose an evaluation methodology that provides a unified evaluation on\nstability, plasticity, and generalizability in continual learning. By employing\nthe proposed metric, we demonstrate how introducing various knowledge\ndistillations can improve different aspects of these three properties of the\nSLU model. We further show that our proposed metric is more sensitive in\ncapturing the impact of task ordering in continual learning, making it better\nsuited for practical use-case scenarios.",
      "tldr_zh": "本文评估并改进 Spoken Language Understanding (SLU) 中的 Continual Learning，旨在有效应对新概念和环境演变。论文提出一种统一的评估方法，全面考察模型的 Stability、Plasticity 和 Generalizability，同时揭示这些属性的权衡关系。实验结果显示，通过引入各种 Knowledge Distillations，可以显著提升 SLU 模型的这些性能，且新指标更敏感于任务顺序，适用于实际应用场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10427v1",
      "published_date": "2024-02-16 03:30:27 UTC",
      "updated_date": "2024-02-16 03:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:13:17.658768"
    },
    {
      "arxiv_id": "2402.10985v4",
      "title": "CloudLens: Modeling and Detecting Cloud Security Vulnerabilities",
      "title_zh": "CloudLens：云安全漏洞的建模与检测",
      "authors": [
        "Mikhail Kazdagli",
        "Mohit Tiwari",
        "Akshat Kumar"
      ],
      "abstract": "Cloud computing services provide scalable and cost-effective solutions for\ndata storage, processing, and collaboration. With their growing popularity,\nconcerns about security vulnerabilities are increasing. To address this, first,\nwe provide a formal model, called CloudLens, that expresses relations between\ndifferent cloud objects such as users, datastores, security roles, representing\naccess control policies in cloud systems. Second, as access control\nmisconfigurations are often the primary driver for cloud attacks, we develop a\nplanning model for detecting security vulnerabilities. Such vulnerabilities can\nlead to widespread attacks such as ransomware, sensitive data exfiltration\namong others. A planner generates attacks to identify such vulnerabilities in\nthe cloud. Finally, we test our approach on 14 real Amazon AWS cloud\nconfigurations of different commercial organizations. Our system can identify a\nbroad range of security vulnerabilities, which state-of-the-art industry tools\ncannot detect.",
      "tldr_zh": "该论文提出 CloudLens 模型，用于正式表达云系统中用户、数据存储和安全角色之间的关系，从而表示访问控制策略，以应对云计算服务的安全漏洞问题。研究团队开发了一个规划模型，通过生成攻击路径来检测访问控制误配置导致的潜在威胁，如勒索软件和敏感数据外泄。实验在 14 个真实 Amazon AWS 云配置上进行，结果显示 CloudLens 系统能够识别广泛的安全漏洞，而现有行业工具无法检测。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10985v4",
      "published_date": "2024-02-16 03:28:02 UTC",
      "updated_date": "2024-12-24 03:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:13:28.993642"
    },
    {
      "arxiv_id": "2402.10424v1",
      "title": "Understanding In-Context Learning with a Pelican Soup Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Ting-Rui Chiang",
        "Dani Yogatama"
      ],
      "abstract": "Many existing theoretical analyses of in-context learning for natural\nlanguage processing are based on latent variable models that leaves gaps\nbetween theory and practice. We aim to close these gaps by proposing a\ntheoretical framework, the Pelican Soup Framework. In this framework, we\nintroduce (1) the notion of a common sense knowledge base, (2) a general\nformalism for natural language classification tasks, and the notion of (3)\nmeaning association. Under this framework, we can establish a\n$\\mathcal{O}(1/T)$ loss bound for in-context learning, where $T$ is the number\nof example-label pairs in the demonstration. Compared with previous works, our\nbound reflects the effect of the choice of verbalizers and the effect of\ninstruction tuning. An additional notion of \\textit{atom concepts} makes our\nframework possible to explain the generalization to tasks unseen in the\nlanguage model training data. Finally, we propose a toy setup, Calcutec, and a\ndigit addition task that mimics types of distribution shifts a model needs to\novercome to perform in-context learning. We also experiment with GPT2-Large on\nreal-world NLP tasks. Our empirical results demonstrate the efficacy of our\nframework to explain in-context learning.",
      "tldr_zh": "这篇论文提出了 Pelican Soup Framework 来理解 in-context learning 的理论基础，该框架包括常识知识库、自然语言分类任务的通用形式以及意义关联的概念。框架下建立了一个 O(1/T) 的损失边界，其中 T 是演示中的示例-标签对数，并反映了 verbalizers 选择和指令调优的影响；此外，通过 atom concepts 的引入，解释了模型对未见任务的泛化能力。作者设计了 Calcutec 玩具设置和数字加法任务来模拟分布偏移，并使用 GPT2-Large 在真实 NLP 任务上进行实验，证明了框架的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10424v1",
      "published_date": "2024-02-16 03:20:14 UTC",
      "updated_date": "2024-02-16 03:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:13:42.574961"
    },
    {
      "arxiv_id": "2402.10423v1",
      "title": "Connect the dots: Dataset Condensation, Differential Privacy, and Adversarial Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Kenneth Odoh"
      ],
      "abstract": "Our work focuses on understanding the underpinning mechanism of dataset\ncondensation by drawing connections with ($\\epsilon$, $\\delta$)-differential\nprivacy where the optimal noise, $\\epsilon$, is chosen by adversarial\nuncertainty \\cite{Grining2017}. We can answer the question about the inner\nworkings of the dataset condensation procedure. Previous work \\cite{dong2022}\nproved the link between dataset condensation (DC) and ($\\epsilon$,\n$\\delta$)-differential privacy. However, it is unclear from existing works on\nablating DC to obtain a lower-bound estimate of $\\epsilon$ that will suffice\nfor creating high-fidelity synthetic data. We suggest that adversarial\nuncertainty is the most appropriate method to achieve an optimal noise level,\n$\\epsilon$. As part of the internal dynamics of dataset condensation, we adopt\na satisfactory scheme for noise estimation that guarantees high-fidelity data\nwhile providing privacy.",
      "tldr_zh": "本研究探讨了数据集浓缩（dataset condensation）的底层机制，将其与（ε, δ）-差分隐私（differential privacy）联系起来，并通过对抗不确定性（adversarial uncertainty）来选择最优噪声 ε，以解答数据集浓缩过程的内部运作。论文指出，现有工作虽已证明数据集浓缩与差分隐私的关联，但未能提供精确的ε下限估计；为此，研究提出采用对抗不确定性作为最佳方法，确保噪声水平优化。最终，这种方案能生成高保真合成数据，同时提供有效的隐私保护，为数据集浓缩的应用奠定更坚实基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10423v1",
      "published_date": "2024-02-16 03:12:22 UTC",
      "updated_date": "2024-02-16 03:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:13:54.377283"
    },
    {
      "arxiv_id": "2402.10416v2",
      "title": "Grounding Language about Belief in a Bayesian Theory-of-Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Lance Ying",
        "Tan Zhi-Xuan",
        "Lionel Wong",
        "Vikash Mansinghka",
        "Joshua Tenenbaum"
      ],
      "abstract": "Despite the fact that beliefs are mental states that cannot be directly\nobserved, humans talk about each others' beliefs on a regular basis, often\nusing rich compositional language to describe what others think and know. What\nexplains this capacity to interpret the hidden epistemic content of other\nminds? In this paper, we take a step towards an answer by grounding the\nsemantics of belief statements in a Bayesian theory-of-mind: By modeling how\nhumans jointly infer coherent sets of goals, beliefs, and plans that explain an\nagent's actions, then evaluating statements about the agent's beliefs against\nthese inferences via epistemic logic, our framework provides a conceptual role\nsemantics for belief, explaining the gradedness and compositionality of human\nbelief attributions, as well as their intimate connection with goals and plans.\nWe evaluate this framework by studying how humans attribute goals and beliefs\nwhile watching an agent solve a doors-and-keys gridworld puzzle that requires\ninstrumental reasoning about hidden objects. In contrast to pure logical\ndeduction, non-mentalizing baselines, and mentalizing that ignores the role of\ninstrumental plans, our model provides a much better fit to human goal and\nbelief attributions, demonstrating the importance of theory-of-mind for a\nsemantics of belief.",
      "tldr_zh": "本研究探讨了人类如何使用复杂语言描述他人不可观察的信念，并提出一种将信念语句语义根植于Bayesian Theory-of-Mind的框架。通过建模人类推断代理的目标、信念和计划来解释行为，并利用epistemic logic评估这些信念，该框架解释了信念归因的渐进性（gradedness）、组合性（compositionality）以及与目标和计划的关联。实验中，研究者观察人类在观看agents解决doors-and-keys gridworld谜题时的归因行为，结果显示，该模型比纯逻辑演绎、非心理化基线和忽略工具计划的心理化模型更准确地拟合人类数据，突出了Theory-of-Mind在信念语义中的关键作用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at CogSci 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.10416v2",
      "published_date": "2024-02-16 02:47:09 UTC",
      "updated_date": "2024-07-09 01:19:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:14:06.510059"
    },
    {
      "arxiv_id": "2402.10412v2",
      "title": "Measuring and Reducing LLM Hallucination without Gold-Standard Answers",
      "title_zh": "在没有黄金标准答案的情况下测量和减少 LLM 幻觉",
      "authors": [
        "Jiaheng Wei",
        "Yuanshun Yao",
        "Jean-Francois Ton",
        "Hongyi Guo",
        "Andrew Estornell",
        "Yang Liu"
      ],
      "abstract": "LLM hallucination, i.e. generating factually incorrect yet seemingly\nconvincing answers, is currently a major threat to the trustworthiness and\nreliability of LLMs. The first step towards solving this complicated problem is\nto measure it. However, existing hallucination metrics require having a\nbenchmark dataset with gold-standard answers, i.e. \"best\" or \"correct\" answers\nwritten by humans. Such requirements make hallucination measurement costly and\nprone to human errors. In this work, we propose Factualness Evaluations via\nWeighting LLMs (FEWL), an innovative hallucination metric that is specifically\ndesigned for the scenario when gold-standard answers are absent. FEWL leverages\nthe answers from off-the-shelf LLMs that serve as a proxy of gold-standard\nanswers. The key challenge is how to quantify the expertise of reference LLMs\nresourcefully. We show FEWL has certain theoretical guarantees and demonstrate\nempirically it gives more accurate hallucination measures than naively using\nreference LLMs. We also show how to leverage FEWL to reduce hallucination\nthrough both in-context learning and supervised fine-tuning. Extensive\nexperiment results on Truthful-QA, CHALE, and HaluEval datasets demonstrate the\neffectiveness of FEWL.",
      "tldr_zh": "该研究解决了LLM hallucination（生成事实错误但看似可信的答案）问题，提出了一种无需金标准答案的度量方法Factualness Evaluations via Weighting LLMs (FEWL)。FEWL利用现成LLMs的答案作为代理，通过量化参考LLMs的专业性来评估幻觉程度，并提供了理论保证和实验证据，显示其比简单使用参考LLMs更准确。研究进一步展示了如何通过in-context learning和supervised fine-tuning利用FEWL减少幻觉，在Truthful-QA、CHALE和HaluEval数据集上的实验证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper Under Review",
      "pdf_url": "http://arxiv.org/pdf/2402.10412v2",
      "published_date": "2024-02-16 02:32:06 UTC",
      "updated_date": "2024-06-06 18:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:14:18.889981"
    },
    {
      "arxiv_id": "2402.10409v1",
      "title": "Understanding Survey Paper Taxonomy about Large Language Models via Graph Representation Learning",
      "title_zh": "通过图表示学习理解大型语言模型调查",
      "authors": [
        "Jun Zhuang",
        "Casey Kennington"
      ],
      "abstract": "As new research on Large Language Models (LLMs) continues, it is difficult to\nkeep up with new research and models. To help researchers synthesize the new\nresearch many have written survey papers, but even those have become numerous.\nIn this paper, we develop a method to automatically assign survey papers to a\ntaxonomy. We collect the metadata of 144 LLM survey papers and explore three\nparadigms to classify papers within the taxonomy. Our work indicates that\nleveraging graph structure information on co-category graphs can significantly\noutperform the language models in two paradigms; pre-trained language models'\nfine-tuning and zero-shot/few-shot classifications using LLMs. We find that our\nmodel surpasses an average human recognition level and that fine-tuning LLMs\nusing weak labels generated by a smaller model, such as the GCN in this study,\ncan be more effective than using ground-truth labels, revealing the potential\nof weak-to-strong generalization in the taxonomy classification task.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs)调查论文数量迅速增长的挑战，提出了一种利用Graph Representation Learning的自动分类方法，以理解和组织这些论文的分类法(taxonomy)。研究者收集了144篇LLM调查论文的元数据，并探索了三种分类范式，包括基于co-category graphs的图结构信息。结果表明，利用图结构的方法显著优于预训练语言模型的微调和零样本/少样本分类，且该模型的性能超过了平均人类识别水平。最后，他们发现使用弱标签（如GCN生成的）微调LLMs比使用真实标签更有效，揭示了弱到强泛化的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "TL;DR: We collected metadata about LLM surveys and developed a method\n  for categorizing them into a taxonomy, indicating the superiority of graph\n  representation learning over language models and revealing the efficacy of\n  fine-tuning using weak labels",
      "pdf_url": "http://arxiv.org/pdf/2402.10409v1",
      "published_date": "2024-02-16 02:21:59 UTC",
      "updated_date": "2024-02-16 02:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:14:31.789527"
    },
    {
      "arxiv_id": "2402.10404v1",
      "title": "Explaining generative diffusion models via visual analysis for interpretable decision-making process",
      "title_zh": "通过视觉分析解释生成式扩散模型，用于可解释的决策过程",
      "authors": [
        "Ji-Hoon Park",
        "Yeong-Joon Ju",
        "Seong-Whan Lee"
      ],
      "abstract": "Diffusion models have demonstrated remarkable performance in generation\ntasks. Nevertheless, explaining the diffusion process remains challenging due\nto it being a sequence of denoising noisy images that are difficult for experts\nto interpret. To address this issue, we propose the three research questions to\ninterpret the diffusion process from the perspective of the visual concepts\ngenerated by the model and the region where the model attends in each time\nstep. We devise tools for visualizing the diffusion process and answering the\naforementioned research questions to render the diffusion process\nhuman-understandable. We show how the output is progressively generated in the\ndiffusion process by explaining the level of denoising and highlighting\nrelationships to foundational visual concepts at each time step through the\nresults of experiments with various visual analyses using the tools. Throughout\nthe training of the diffusion model, the model learns diverse visual concepts\ncorresponding to each time-step, enabling the model to predict varying levels\nof visual concepts at different stages. We substantiate our tools using Area\nUnder Cover (AUC) score, correlation quantification, and cross-attention\nmapping. Our findings provide insights into the diffusion process and pave the\nway for further research into explainable diffusion mechanisms.",
      "tldr_zh": "本文通过视觉分析解释生成性diffusion models的决策过程，旨在解决扩散过程（即一系列去噪图像）的可解释性挑战。论文提出三个研究问题，从模型生成的视觉概念和关注区域角度，开发了可视化工具来逐步展示输出生成过程，包括每个时间步的去噪水平与基础视觉概念的关系。实验结果表明，diffusion models在训练中学习了多样化的时间步对应视觉概念，并通过AUC score、相关性量化及交叉注意力映射验证了工具的有效性。该研究为可解释的diffusion机制提供了新洞见，推动了AI决策的可信度提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T01"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, published in Expert Systems with Applications",
      "pdf_url": "http://arxiv.org/pdf/2402.10404v1",
      "published_date": "2024-02-16 02:12:20 UTC",
      "updated_date": "2024-02-16 02:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:14:43.919928"
    },
    {
      "arxiv_id": "2402.10403v3",
      "title": "Polyhedral Complex Derivation from Piecewise Trilinear Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jin-Hwa Kim"
      ],
      "abstract": "Recent advancements in visualizing deep neural networks provide insights into\ntheir structures and mesh extraction from Continuous Piecewise Affine (CPWA)\nfunctions. Meanwhile, developments in neural surface representation learning\nincorporate non-linear positional encoding, addressing issues like spectral\nbias; however, this poses challenges in applying mesh extraction techniques\nbased on CPWA functions. Focusing on trilinear interpolating methods as\npositional encoding, we present theoretical insights and an analytical mesh\nextraction, showing the transformation of hypersurfaces to flat planes within\nthe trilinear region under the eikonal constraint. Moreover, we introduce a\nmethod for approximating intersecting points among three hypersurfaces\ncontributing to broader applications. We empirically validate correctness and\nparsimony through chamfer distance and efficiency, and angular distance, while\nexamining the correlation between the eikonal loss and the planarity of the\nhypersurfaces.",
      "tldr_zh": "该论文探讨了从分段三线性网络中推导多面体复合体的方法，针对神经表面表示学习中非线性位置编码（如三线性插值）导致的网格提取挑战。研究提供了理论见解和分析网格提取技术，通过eikonal约束将超曲面转化为三线性区域内的平坦平面，并引入了一种近似三个超曲面交点的方法，以扩展应用范围。实验通过Chamfer距离、效率和角度距离等指标验证了方法的正确性和简洁性，并揭示了eikonal损失与超曲面平面性的相关性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024. Updated with the camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2402.10403v3",
      "published_date": "2024-02-16 02:01:24 UTC",
      "updated_date": "2024-10-18 01:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:14:54.771703"
    },
    {
      "arxiv_id": "2402.10393v1",
      "title": "Darwin Turing Dawkins: Building a General Theory of Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Leonard M. Adleman"
      ],
      "abstract": "Living things, computers, societies, and even books are part of a grand\nevolutionary struggle to survive. That struggle shapes nature, nations,\nreligions, art, science, and you. What you think, feel, and do is determined by\nit. Darwinian evolution does not apply solely to the genes that are stored in\nDNA. Using the insights of Alan Turing and Richard Dawkins, we will see that it\nalso applies to the memes we store in our brains and the information we store\nin our computers. The next time you run for president, fight a war, or just\ndeal with the ordinary problems humans are heir to, perhaps this book will be\nof use. If you want to understand why and when you will die, or if you want to\nachieve greatness this book may help. If you are concerned about where the\ncomputer revolution is headed, this book may provide some answers.",
      "tldr_zh": "这本书扩展了达尔文进化论，提出一个通用理论（General Theory of Evolution），认为进化斗争不仅适用于 DNA 中的基因，还影响大脑中的模因（memes）和计算机中的信息。作者整合 Alan Turing 和 Richard Dawkins 的见解，解释了如何塑造自然、国家、宗教、艺术、科学以及个人的思想、情感和行为。最终，该理论为理解日常生活问题（如死亡、伟大成就和计算机革命的方向）提供实用指导，并可能帮助应对政治、战争和社会挑战。",
      "categories": [
        "cs.GL",
        "cs.AI",
        "q-bio.PE"
      ],
      "primary_category": "cs.GL",
      "comment": "247 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.10393v1",
      "published_date": "2024-02-16 01:27:21 UTC",
      "updated_date": "2024-02-16 01:27:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:15:06.671070"
    },
    {
      "arxiv_id": "2402.10392v1",
      "title": "Pretext Training Algorithms for Event Sequence Data",
      "title_zh": "针对事件序列数据的预训练算法",
      "authors": [
        "Yimu Wang",
        "He Zhao",
        "Ruizhi Deng",
        "Frederick Tung",
        "Greg Mori"
      ],
      "abstract": "Pretext training followed by task-specific fine-tuning has been a successful\napproach in vision and language domains. This paper proposes a self-supervised\npretext training framework tailored to event sequence data. We introduce a\nnovel alignment verification task that is specialized to event sequences,\nbuilding on good practices in masked reconstruction and contrastive learning.\nOur pretext tasks unlock foundational representations that are generalizable\nacross different down-stream tasks, including next-event prediction for\ntemporal point process models, event sequence classification, and missing event\ninterpolation. Experiments on popular public benchmarks demonstrate the\npotential of the proposed method across different tasks and data domains.",
      "tldr_zh": "该论文提出了一种针对事件序列数据的自监督预训练(self-supervised pretext training)框架，包括一个新型的对齐验证任务(alignment verification task)，它借鉴了掩码重建(masked reconstruction)和对比学习(contrastive learning)的实践，以生成通用的基础表示。 该框架支持下游任务的泛化应用，如下一个事件预测(next-event prediction)用于时间点过程模型、事件序列分类(event sequence classification)和缺失事件插值(missing event interpolation)。 实验结果在流行公共基准上显示，该方法在不同任务和数据领域表现出显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10392v1",
      "published_date": "2024-02-16 01:25:21 UTC",
      "updated_date": "2024-02-16 01:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:15:19.765087"
    },
    {
      "arxiv_id": "2402.10381v2",
      "title": "UMAIR-FPS: User-aware Multi-modal Animation Illustration Recommendation Fusion with Painting Style",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Kang",
        "Hao Lin",
        "Mingjian Yang",
        "Shin-Jye Lee"
      ],
      "abstract": "The rapid advancement of high-quality image generation models based on AI has\ngenerated a deluge of anime illustrations. Recommending illustrations to users\nwithin massive data has become a challenging and popular task. However,\nexisting anime recommendation systems have focused on text features but still\nneed to integrate image features. In addition, most multi-modal recommendation\nresearch is constrained by tightly coupled datasets, limiting its applicability\nto anime illustrations. We propose the User-aware Multi-modal Animation\nIllustration Recommendation Fusion with Painting Style (UMAIR-FPS) to tackle\nthese gaps. In the feature extract phase, for image features, we are the first\nto combine image painting style features with semantic features to construct a\ndual-output image encoder for enhancing representation. For text features, we\nobtain text embeddings based on fine-tuning Sentence-Transformers by\nincorporating domain knowledge that composes a variety of domain text pairs\nfrom multilingual mappings, entity relationships, and term explanation\nperspectives, respectively. In the multi-modal fusion phase, we novelly propose\na user-aware multi-modal contribution measurement mechanism to weight\nmulti-modal features dynamically according to user features at the interaction\nlevel and employ the DCN-V2 module to model bounded-degree multi-modal crosses\neffectively. UMAIR-FPS surpasses the stat-of-the-art baselines on large\nreal-world datasets, demonstrating substantial performance enhancements.",
      "tldr_zh": "该论文提出UMAIR-FPS，一种用户感知的多模态动漫插图推荐系统，旨在解决现有推荐系统忽略图像特征的问题，并提升对动漫领域的适用性。在特征提取阶段，该系统首次结合图像绘画风格特征和语义特征构建双输出图像编码器，同时通过微调Sentence-Transformers并融入领域知识（如多语言映射、实体关系和术语解释）来获取文本嵌入。在多模态融合阶段，引入用户感知多模态贡献测量机制动态权重特征，并使用DCN-V2模块建模有限度的多模态交叉效果。实验结果显示，UMAIR-FPS在大型真实数据集上超越最先进基线，实现了显著的性能提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by DASFAA 2024 Research track",
      "pdf_url": "http://arxiv.org/pdf/2402.10381v2",
      "published_date": "2024-02-16 00:25:53 UTC",
      "updated_date": "2024-04-17 13:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:15:32.056783"
    },
    {
      "arxiv_id": "2402.10380v1",
      "title": "Subgraph-level Universal Prompt Tuning",
      "title_zh": "子图级别的通用提示调优",
      "authors": [
        "Junhyun Lee",
        "Wooseong Yang",
        "Jaewoo Kang"
      ],
      "abstract": "In the evolving landscape of machine learning, the adaptation of pre-trained\nmodels through prompt tuning has become increasingly prominent. This trend is\nparticularly observable in the graph domain, where diverse pre-training\nstrategies present unique challenges in developing effective prompt-based\ntuning methods for graph neural networks. Previous approaches have been\nlimited, focusing on specialized prompting functions tailored to models with\nedge prediction pre-training tasks. These methods, however, suffer from a lack\nof generalizability across different pre-training strategies. Recently, a\nsimple prompt tuning method has been designed for any pre-training strategy,\nfunctioning within the input graph's feature space. This allows it to\ntheoretically emulate any type of prompting function, thereby significantly\nincreasing its versatility for a range of downstream applications.\nNevertheless, the capacity of such simple prompts to fully grasp the complex\ncontexts found in graphs remains an open question, necessitating further\ninvestigation. Addressing this challenge, our work introduces the\nSubgraph-level Universal Prompt Tuning (SUPT) approach, focusing on the\ndetailed context within subgraphs. In SUPT, prompt features are assigned at the\nsubgraph-level, preserving the method's universal capability. This requires\nextremely fewer tuning parameters than fine-tuning-based methods, outperforming\nthem in 42 out of 45 full-shot scenario experiments with an average improvement\nof over 2.5%. In few-shot scenarios, it excels in 41 out of 45 experiments,\nachieving an average performance increase of more than 6.6%.",
      "tldr_zh": "本研究探讨了图神经网络（Graph Neural Networks）中提示调优（Prompt Tuning）的挑战，现有方法局限于特定预训练策略（如边预测任务），缺乏通用性。论文提出 Subgraph-level Universal Prompt Tuning (SUPT) 方法，通过在子图级别分配提示特征，保持通用能力的同时显著减少调优参数。实验结果显示，SUPT 在全样本场景中胜出 42/45 实验，平均提升 2.5%；在少样本场景中胜出 41/45 实验，平均提升 6.6%，为图领域模型适应性提供了高效新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10380v1",
      "published_date": "2024-02-16 00:25:24 UTC",
      "updated_date": "2024-02-16 00:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T07:15:44.358776"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 118,
  "processed_papers_count": 118,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T07:16:11.899107"
}