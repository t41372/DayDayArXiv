[
  {
    "arxiv_id": "2408.09053v2",
    "title": "Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models",
    "authors": [
      "Vladimir Araujo",
      "Marie-Francine Moens",
      "Tinne Tuytelaars"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) methods are increasingly used with\npre-trained language models (PLMs) for continual learning (CL). These methods\ntypically involve training a PEFT module for each new task and employing\nsimilarity-based selection to route modules during inference. However, they\nface two major limitations: 1) interference during module training with already\nlearned modules and 2) suboptimal routing when composing modules. In this\npaper, we present L2R, a method that isolates the training of new PEFT modules\nto ensure their task specialization. L2R then learns to compose the learned\nmodules by training a network of routers that leverages a small memory\ncontaining examples of previously seen tasks. We evaluate our method in two CL\nsetups using various benchmarks. Our results demonstrate that L2R provides an\neffective composition of PEFT modules, leading to improved generalization and\nperformance compared to other methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted paper EMNLP2024",
    "pdf_url": "http://arxiv.org/pdf/2408.09053v2",
    "published_date": "2024-08-16 23:57:29 UTC",
    "updated_date": "2024-10-30 01:38:27 UTC"
  },
  {
    "arxiv_id": "2408.09049v2",
    "title": "When Prompting Fails to Sway: Inertia in Moral and Value Judgments of Large Language Models",
    "authors": [
      "Bruce W. Lee",
      "Yeongheon Lee",
      "Hyunsoo Cho"
    ],
    "abstract": "Large Language Models (LLMs) exhibit non-deterministic behavior, and\nprompting has emerged as a primary method for steering their outputs toward\ndesired directions. One popular strategy involves assigning a specific\n\"persona\" to the model to induce more varied and context-sensitive responses,\nakin to the diversity found in human perspectives. However, contrary to the\nexpectation that persona-based prompting would yield a wide range of opinions,\nour experiments demonstrate that LLMs maintain consistent value orientations.\nIn particular, we observe a persistent inertia in their responses, where\ncertain moral and value dimensions, especially harm avoidance and fairness,\nremain distinctly skewed in one direction despite varied persona settings. To\ninvestigate this phenomenon systematically, use role-play at scale, which\ncombines randomized, diverse persona prompts with a macroscopic trend analysis\nof model outputs. Our findings highlight the strong internal biases and value\npreferences in LLMs, underscoring the need for careful scrutiny and potential\nadjustment of these models to ensure balanced and equitable applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.09049v2",
    "published_date": "2024-08-16 23:24:10 UTC",
    "updated_date": "2025-04-05 23:19:37 UTC"
  },
  {
    "arxiv_id": "2408.09048v2",
    "title": "mRNA2vec: mRNA Embedding with Language Model in the 5'UTR-CDS for mRNA Design",
    "authors": [
      "Honggen Zhang",
      "Xiangrui Gao",
      "June Zhang",
      "Lipeng Lai"
    ],
    "abstract": "Messenger RNA (mRNA)-based vaccines are accelerating the discovery of new\ndrugs and revolutionizing the pharmaceutical industry. However, selecting\nparticular mRNA sequences for vaccines and therapeutics from extensive mRNA\nlibraries is costly. Effective mRNA therapeutics require carefully designed\nsequences with optimized expression levels and stability. This paper proposes a\nnovel contextual language model (LM)-based embedding method: mRNA2vec. In\ncontrast to existing mRNA embedding approaches, our method is based on the\nself-supervised teacher-student learning framework of data2vec. We jointly use\nthe 5' untranslated region (UTR) and coding sequence (CDS) region as the input\nsequences. We adapt our LM-based approach specifically to mRNA by 1)\nconsidering the importance of location on the mRNA sequence with probabilistic\nmasking, 2) using Minimum Free Energy (MFE) prediction and Secondary Structure\n(SS) classification as additional pretext tasks. mRNA2vec demonstrates\nsignificant improvements in translation efficiency (TE) and expression level\n(EL) prediction tasks in UTR compared to SOTA methods such as UTR-LM. It also\ngives a competitive performance in mRNA stability and protein production level\ntasks in CDS such as CodonBERT.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.09048v2",
    "published_date": "2024-08-16 23:23:40 UTC",
    "updated_date": "2024-12-19 22:38:35 UTC"
  },
  {
    "arxiv_id": "2408.09046v1",
    "title": "Keep Calm and Relax -- HMI for Autonomous Vehicles",
    "authors": [
      "Tima M. Yekta",
      "Julius Sch√∂ning"
    ],
    "abstract": "The growing popularity of self-driving, so-called autonomous vehicles has\nincreased the need for human-machine interfaces~(HMI) and user interaction~(UI)\nto enhance passenger trust and comfort. While fallback drivers significantly\ninfluence the perceived trustfulness of self-driving vehicles, fallback drivers\nare an expensive solution that may not even improve vehicle safety in emergency\nsituations. Based on a comprehensive literature review, this work delves into\nthe potential of HMI and UI in enhancing trustfulness and emotion regulation in\ndriverless vehicles. By analyzing the impact of various HMI and UI on passenger\nemotions, innovative and cost-effective concepts for improving human-vehicle\ninteraction are conceptualized. To enable a trustful, highly comfortable, and\nsafe ride, this work concludes by discussing whether HMI and UI are suitable\nfor calming passengers down in emergencies, leading to smarter mobility for\nall.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "H.4; J.7"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2408.09046v1",
    "published_date": "2024-08-16 23:05:08 UTC",
    "updated_date": "2024-08-16 23:05:08 UTC"
  },
  {
    "arxiv_id": "2408.09043v1",
    "title": "Improving VTE Identification through Language Models from Radiology Reports: A Comparative Study of Mamba, Phi-3 Mini, and BERT",
    "authors": [
      "Jamie Deng",
      "Yusen Wu",
      "Yelena Yesha",
      "Phuong Nguyen"
    ],
    "abstract": "Venous thromboembolism (VTE) is a critical cardiovascular condition,\nencompassing deep vein thrombosis (DVT) and pulmonary embolism (PE). Accurate\nand timely identification of VTE is essential for effective medical care. This\nstudy builds upon our previous work, which addressed VTE detection using deep\nlearning methods for DVT and a hybrid approach combining deep learning and\nrule-based classification for PE. Our earlier approaches, while effective, had\ntwo major limitations: they were complex and required expert involvement for\nfeature engineering of the rule set. To overcome these challenges, we utilize\nthe Mamba architecture-based classifier. This model achieves remarkable\nresults, with a 97\\% accuracy and F1 score on the DVT dataset and a 98\\%\naccuracy and F1 score on the PE dataset. In contrast to the previous hybrid\nmethod on PE identification, the Mamba classifier eliminates the need for\nhand-engineered rules, significantly reducing model complexity while\nmaintaining comparable performance. Additionally, we evaluated a lightweight\nLarge Language Model (LLM), Phi-3 Mini, in detecting VTE. While this model\ndelivers competitive results, outperforming the baseline BERT models, it proves\nto be computationally intensive due to its larger parameter set. Our evaluation\nshows that the Mamba-based model demonstrates superior performance and\nefficiency in VTE identification, offering an effective solution to the\nlimitations of previous approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.09043v1",
    "published_date": "2024-08-16 22:51:56 UTC",
    "updated_date": "2024-08-16 22:51:56 UTC"
  },
  {
    "arxiv_id": "2409.03759v1",
    "title": "VERA: Validation and Evaluation of Retrieval-Augmented Systems",
    "authors": [
      "Tianyu Ding",
      "Adi Banerjee",
      "Laurent Mombaerts",
      "Yunhong Li",
      "Tarik Borogovac",
      "Juan Pablo De la Cruz Weinstein"
    ],
    "abstract": "The increasing use of Retrieval-Augmented Generation (RAG) systems in various\napplications necessitates stringent protocols to ensure RAG systems accuracy,\nsafety, and alignment with user intentions. In this paper, we introduce VERA\n(Validation and Evaluation of Retrieval-Augmented Systems), a framework\ndesigned to enhance the transparency and reliability of outputs from large\nlanguage models (LLMs) that utilize retrieved information. VERA improves the\nway we evaluate RAG systems in two important ways: (1) it introduces a\ncross-encoder based mechanism that encompasses a set of multidimensional\nmetrics into a single comprehensive ranking score, addressing the challenge of\nprioritizing individual metrics, and (2) it employs Bootstrap statistics on\nLLM-based metrics across the document repository to establish confidence\nbounds, ensuring the repositorys topical coverage and improving the overall\nreliability of retrieval systems. Through several use cases, we demonstrate how\nVERA can strengthen decision-making processes and trust in AI applications. Our\nfindings not only contribute to the theoretical understanding of LLM-based RAG\nevaluation metric but also promote the practical implementation of responsible\nAI systems, marking a significant advancement in the development of reliable\nand transparent generative AI technologies.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted in Workshop on Evaluation and Trustworthiness of Generative\n  AI Models, KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.03759v1",
    "published_date": "2024-08-16 21:59:59 UTC",
    "updated_date": "2024-08-16 21:59:59 UTC"
  },
  {
    "arxiv_id": "2408.09028v1",
    "title": "On the Completeness of Conflict-Based Search: Temporally-Relative Duplicate Pruning",
    "authors": [
      "Thayne T Walker",
      "Nathan R Sturtevant"
    ],
    "abstract": "Conflict-Based Search (CBS) algorithm for the multi-agent pathfinding (MAPF)\nproblem is that it is incomplete for problems which have no solution; if no\nmitigating procedure is run in parallel, CBS will run forever when given an\nunsolvable problem instance. In this work, we introduce Temporally-Relative\nDuplicate Pruning (TRDP), a technique for duplicate detection and removal in\nboth classic and continuous-time MAPF domains. TRDP is a simple procedure which\ncloses the long-standing theoretic loophole of incompleteness for CBS by\ndetecting and avoiding the expansion of duplicate states. TRDP is shown both\ntheoretically and empirically to ensure termination without a significant\nimpact on runtime in the majority of problem instances. In certain cases, TRDP\nis shown to increase performance significantly",
    "categories": [
      "cs.AI",
      "cs.RO",
      "F.2.2; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.09028v1",
    "published_date": "2024-08-16 21:49:39 UTC",
    "updated_date": "2024-08-16 21:49:39 UTC"
  },
  {
    "arxiv_id": "2408.09027v2",
    "title": "Efficient Autoregressive Audio Modeling via Next-Scale Prediction",
    "authors": [
      "Kai Qiu",
      "Xiang Li",
      "Hao Chen",
      "Jie Sun",
      "Jinglu Wang",
      "Zhe Lin",
      "Marios Savvides",
      "Bhiksha Raj"
    ],
    "abstract": "Audio generation has achieved remarkable progress with the advance of\nsophisticated generative models, such as diffusion models (DMs) and\nautoregressive (AR) models. However, due to the naturally significant sequence\nlength of audio, the efficiency of audio generation remains an essential issue\nto be addressed, especially for AR models that are incorporated in large\nlanguage models (LLMs). In this paper, we analyze the token length of audio\ntokenization and propose a novel \\textbf{S}cale-level \\textbf{A}udio\n\\textbf{T}okenizer (SAT), with improved residual quantization. Based on SAT, a\nscale-level \\textbf{A}coustic \\textbf{A}uto\\textbf{R}egressive (AAR) modeling\nframework is further proposed, which shifts the next-token AR prediction to\nnext-scale AR prediction, significantly reducing the training cost and\ninference time. To validate the effectiveness of the proposed approach, we\ncomprehensively analyze design choices and demonstrate the proposed AAR\nframework achieves a remarkable \\textbf{35}$\\times$ faster inference speed and\n+\\textbf{1.33} Fr\\'echet Audio Distance (FAD) against baselines on the AudioSet\nbenchmark. Code: \\url{https://github.com/qiuk2/AAR}.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "7 pages, 6 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.09027v2",
    "published_date": "2024-08-16 21:48:53 UTC",
    "updated_date": "2024-12-16 21:50:56 UTC"
  },
  {
    "arxiv_id": "2408.11861v1",
    "title": "Speaking the Same Language: Leveraging LLMs in Standardizing Clinical Data for AI",
    "authors": [
      "Arindam Sett",
      "Somaye Hashemifar",
      "Mrunal Yadav",
      "Yogesh Pandit",
      "Mohsen Hejrati"
    ],
    "abstract": "The implementation of Artificial Intelligence (AI) in the healthcare industry\nhas garnered considerable attention, attributable to its prospective\nenhancement of clinical outcomes, expansion of access to superior healthcare,\ncost reduction, and elevation of patient satisfaction. Nevertheless, the\nprimary hurdle that persists is related to the quality of accessible\nmulti-modal healthcare data in conjunction with the evolution of AI\nmethodologies. This study delves into the adoption of large language models to\naddress specific challenges, specifically, the standardization of healthcare\ndata. We advocate the use of these models to identify and map clinical data\nschemas to established data standard attributes, such as the Fast Healthcare\nInteroperability Resources. Our results illustrate that employing large\nlanguage models significantly diminishes the necessity for manual data curation\nand elevates the efficacy of the data standardization process. Consequently,\nthe proposed methodology has the propensity to expedite the integration of AI\nin healthcare, ameliorate the quality of patient care, whilst minimizing the\ntime and financial resources necessary for the preparation of data for AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.11861v1",
    "published_date": "2024-08-16 20:51:21 UTC",
    "updated_date": "2024-08-16 20:51:21 UTC"
  },
  {
    "arxiv_id": "2408.09000v2",
    "title": "Classifier-Free Guidance is a Predictor-Corrector",
    "authors": [
      "Arwen Bradley",
      "Preetum Nakkiran"
    ],
    "abstract": "We investigate the theoretical foundations of classifier-free guidance (CFG).\nCFG is the dominant method of conditional sampling for text-to-image diffusion\nmodels, yet unlike other aspects of diffusion, it remains on shaky theoretical\nfooting. In this paper, we disprove common misconceptions, by showing that CFG\ninteracts differently with DDPM (Ho et al., 2020) and DDIM (Song et al., 2021),\nand neither sampler with CFG generates the gamma-powered distribution\n$p(x|c)^\\gamma p(x)^{1-\\gamma}$. Then, we clarify the behavior of CFG by\nshowing that it is a kind of predictor-corrector method (Song et al., 2020)\nthat alternates between denoising and sharpening, which we call\npredictor-corrector guidance (PCG). We prove that in the SDE limit, CFG is\nactually equivalent to combining a DDIM predictor for the conditional\ndistribution together with a Langevin dynamics corrector for a gamma-powered\ndistribution (with a carefully chosen gamma). Our work thus provides a lens to\ntheoretically understand CFG by embedding it in a broader design space of\nprincipled sampling methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "AB and PN contributed equally. v2: Fixed typos",
    "pdf_url": "http://arxiv.org/pdf/2408.09000v2",
    "published_date": "2024-08-16 20:00:55 UTC",
    "updated_date": "2024-08-23 17:21:35 UTC"
  },
  {
    "arxiv_id": "2408.08995v1",
    "title": "On the Undecidability of Artificial Intelligence Alignment: Machines that Halt",
    "authors": [
      "Gabriel Adriano de Melo",
      "Marcos Ricardo Omena De Albuquerque Maximo",
      "Nei Yoshihiro Soma",
      "Paulo Andre Lima de Castro"
    ],
    "abstract": "The inner alignment problem, which asserts whether an arbitrary artificial\nintelligence (AI) model satisfices a non-trivial alignment function of its\noutputs given its inputs, is undecidable. This is rigorously proved by Rice's\ntheorem, which is also equivalent to a reduction to Turing's Halting Problem,\nwhose proof sketch is presented in this work. Nevertheless, there is an\nenumerable set of provenly aligned AIs that are constructed from a finite set\nof provenly aligned operations. Therefore, we argue that the alignment should\nbe a guaranteed property from the AI architecture rather than a characteristic\nimposed post-hoc on an arbitrary AI model. Furthermore, while the outer\nalignment problem is the definition of a judge function that captures human\nvalues and preferences, we propose that such a function must also impose a\nhalting constraint that guarantees that the AI model always reaches a terminal\nstate in finite execution steps. Our work presents examples and models that\nillustrate this constraint and the intricate challenges involved, advancing a\ncompelling case for adopting an intrinsically hard-aligned approach to AI\nsystems architectures that ensures halting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted for the Scientific Reports AI Alignment Collection",
    "pdf_url": "http://arxiv.org/pdf/2408.08995v1",
    "published_date": "2024-08-16 19:55:26 UTC",
    "updated_date": "2024-08-16 19:55:26 UTC"
  },
  {
    "arxiv_id": "2408.13270v1",
    "title": "Efficient Task Transfer for HLS DSE",
    "authors": [
      "Zijian Ding",
      "Atefeh Sohrabizadeh",
      "Weikai Li",
      "Zongyue Qin",
      "Yizhou Sun",
      "Jason Cong"
    ],
    "abstract": "There have been several recent works proposed to utilize model-based\noptimization methods to improve the productivity of using high-level synthesis\n(HLS) to design domain-specific architectures. They would replace the\ntime-consuming performance estimation or simulation of design with a proxy\nmodel, and automatically insert pragmas to guide hardware optimizations. In\nthis work, we address the challenges associated with high-level synthesis (HLS)\ndesign space exploration (DSE) through the evolving landscape of HLS tools. As\nthese tools develop, the quality of results (QoR) from synthesis can vary\nsignificantly, complicating the maintenance of optimal design strategies across\ndifferent toolchains. We introduce Active-CEM, a task transfer learning scheme\nthat leverages a model-based explorer designed to adapt efficiently to changes\nin toolchains. This approach optimizes sample efficiency by identifying\nhigh-quality design configurations under a new toolchain without requiring\nextensive re-evaluation. We further refine our methodology by incorporating\ntoolchain-invariant modeling. This allows us to predict QoR changes more\naccurately despite shifts in the black-box implementation of the toolchains.\nExperiment results on the HLSyn benchmark transitioning to new toolchain show\nan average performance improvement of 1.58$\\times$ compared to AutoDSE and a\n1.2$\\times$ improvement over HARP, while also increasing the sample efficiency\nby 5.26$\\times$, and reducing the runtime by 2.7$\\times$.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "13 pages, 7 figures, accept to ICCAD'24",
    "pdf_url": "http://arxiv.org/pdf/2408.13270v1",
    "published_date": "2024-08-16 19:54:41 UTC",
    "updated_date": "2024-08-16 19:54:41 UTC"
  },
  {
    "arxiv_id": "2408.08990v2",
    "title": "Adaptive Uncertainty Quantification for Generative AI",
    "authors": [
      "Jungeum Kim",
      "Sean O'Hagan",
      "Veronika Rockova"
    ],
    "abstract": "This work is concerned with conformal prediction in contemporary applications\n(including generative AI) where a black-box model has been trained on data that\nare not accessible to the user. Mirroring split-conformal inference, we design\na wrapper around a black-box algorithm which calibrates conformity scores. This\ncalibration is local and proceeds in two stages by first adaptively\npartitioning the predictor space into groups and then calibrating sectionally\ngroup by group. Adaptive partitioning (self-grouping) is achieved by fitting a\nrobust regression tree to the conformity scores on the calibration set. This\nnew tree variant is designed in such a way that adding a single new observation\ndoes not change the tree fit with overwhelmingly large probability. This\nadd-one-in robustness property allows us to conclude a finite sample\ngroup-conditional coverage guarantee, a refinement of the marginal guarantee.\nIn addition, unlike traditional split-conformal inference, adaptive splitting\nand within-group calibration yields adaptive bands which can stretch and shrink\nlocally. We demonstrate benefits of local tightening on several simulated as\nwell as real examples using non-parametric regression. Finally, we consider two\ncontemporary classification applications for obtaining uncertainty\nquantification around GPT-4o predictions. We conformalize skin disease\ndiagnoses based on self-reported symptoms as well as predicted states of U.S.\nlegislators based on summaries of their ideology. We demonstrate substantial\nlocal tightening of the uncertainty sets while attaining similar marginal\ncoverage.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08990v2",
    "published_date": "2024-08-16 19:37:33 UTC",
    "updated_date": "2025-04-24 21:53:32 UTC"
  },
  {
    "arxiv_id": "2408.08989v1",
    "title": "Ask, Attend, Attack: A Effective Decision-Based Black-Box Targeted Attack for Image-to-Text Models",
    "authors": [
      "Qingyuan Zeng",
      "Zhenzhong Wang",
      "Yiu-ming Cheung",
      "Min Jiang"
    ],
    "abstract": "While image-to-text models have demonstrated significant advancements in\nvarious vision-language tasks, they remain susceptible to adversarial attacks.\nExisting white-box attacks on image-to-text models require access to the\narchitecture, gradients, and parameters of the target model, resulting in low\npracticality. Although the recently proposed gray-box attacks have improved\npracticality, they suffer from semantic loss during the training process, which\nlimits their targeted attack performance. To advance adversarial attacks of\nimage-to-text models, this paper focuses on a challenging scenario:\ndecision-based black-box targeted attacks where the attackers only have access\nto the final output text and aim to perform targeted attacks. Specifically, we\nformulate the decision-based black-box targeted attack as a large-scale\noptimization problem. To efficiently solve the optimization problem, a\nthree-stage process \\textit{Ask, Attend, Attack}, called \\textit{AAA}, is\nproposed to coordinate with the solver. \\textit{Ask} guides attackers to create\ntarget texts that satisfy the specific semantics. \\textit{Attend} identifies\nthe crucial regions of the image for attacking, thus reducing the search space\nfor the subsequent \\textit{Attack}. \\textit{Attack} uses an evolutionary\nalgorithm to attack the crucial regions, where the attacks are semantically\nrelated to the target texts of \\textit{Ask}, thus achieving targeted attacks\nwithout semantic loss. Experimental results on transformer-based and\nCNN+RNN-based image-to-text models confirmed the effectiveness of our proposed\n\\textit{AAA}.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08989v1",
    "published_date": "2024-08-16 19:35:06 UTC",
    "updated_date": "2024-08-16 19:35:06 UTC"
  },
  {
    "arxiv_id": "2408.10270v1",
    "title": "SEAL: Systematic Error Analysis for Value ALignment",
    "authors": [
      "Manon Revel",
      "Matteo Cargnelutti",
      "Tyna Eloundou",
      "Greg Leppert"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) aims to align language\nmodels (LMs) with human values by training reward models (RMs) on binary\npreferences and using these RMs to fine-tune the base LMs. Despite its\nimportance, the internal mechanisms of RLHF remain poorly understood. This\npaper introduces new metrics to evaluate the effectiveness of modeling and\naligning human values, namely feature imprint, alignment resistance and\nalignment robustness. We categorize alignment datasets into target features\n(desired values) and spoiler features (undesired concepts). By regressing RM\nscores against these features, we quantify the extent to which RMs reward them\n- a metric we term feature imprint. We define alignment resistance as the\nproportion of the preference dataset where RMs fail to match human preferences,\nand we assess alignment robustness by analyzing RM responses to perturbed\ninputs. Our experiments, utilizing open-source components like the\nAnthropic/hh-rlhf preference dataset and OpenAssistant RMs, reveal significant\nimprints of target features and a notable sensitivity to spoiler features. We\nobserved a 26% incidence of alignment resistance in portions of the dataset\nwhere LM-labelers disagreed with human preferences. Furthermore, we find that\nmisalignment often arises from ambiguous entries within the alignment dataset.\nThese findings underscore the importance of scrutinizing both RMs and alignment\ndatasets for a deeper understanding of value alignment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 17 Figures, 8 Tables",
    "pdf_url": "http://arxiv.org/pdf/2408.10270v1",
    "published_date": "2024-08-16 18:48:30 UTC",
    "updated_date": "2024-08-16 18:48:30 UTC"
  },
  {
    "arxiv_id": "2408.08972v1",
    "title": "ASGM-KG: Unveiling Alluvial Gold Mining Through Knowledge Graphs",
    "authors": [
      "Debashis Gupta",
      "Aditi Golder",
      "Luis Fernendez",
      "Miles Silman",
      "Greg Lersen",
      "Fan Yang",
      "Bob Plemmons",
      "Sarra Alqahtani",
      "Paul Victor Pauca"
    ],
    "abstract": "Artisanal and Small-Scale Gold Mining (ASGM) is a low-cost yet highly\ndestructive mining practice, leading to environmental disasters across the\nworld's tropical watersheds. The topic of ASGM spans multiple domains of\nresearch and information, including natural and social systems, and knowledge\nis often atomized across a diversity of media and documents. We therefore\nintroduce a knowledge graph (ASGM-KG) that consolidates and provides crucial\ninformation about ASGM practices and their environmental effects. The current\nversion of ASGM-KG consists of 1,899 triples extracted using a large language\nmodel (LLM) from documents and reports published by both non-governmental and\ngovernmental organizations. These documents were carefully selected by a group\nof tropical ecologists with expertise in ASGM. This knowledge graph was\nvalidated using two methods. First, a small team of ASGM experts reviewed and\nlabeled triples as factual or non-factual. Second, we devised and applied an\nautomated factual reduction framework that relies on a search engine and an LLM\nfor labeling triples. Our framework performs as well as five baselines on a\npublicly available knowledge graph and achieves over 90 accuracy on our ASGM-KG\nvalidated by domain experts. ASGM-KG demonstrates an advancement in knowledge\naggregation and representation for complex, interdisciplinary environmental\ncrises such as ASGM.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08972v1",
    "published_date": "2024-08-16 18:48:15 UTC",
    "updated_date": "2024-08-16 18:48:15 UTC"
  },
  {
    "arxiv_id": "2408.08969v3",
    "title": "Differentiable Edge-based OPC",
    "authors": [
      "Guojin Chen",
      "Haoyu Yang",
      "Haoxing Ren",
      "Bei Yu",
      "David Z. Pan"
    ],
    "abstract": "Optical proximity correction (OPC) is crucial for pushing the boundaries of\nsemiconductor manufacturing and enabling the continued scaling of integrated\ncircuits. While pixel-based OPC, termed as inverse lithography technology\n(ILT), has gained research interest due to its flexibility and precision. Its\ncomplexity and intricate features can lead to challenges in mask writing,\nincreased defects, and higher costs, hence hindering widespread industrial\nadoption. In this paper, we propose DiffOPC, a differentiable OPC framework\nthat enjoys the virtue of both edge-based OPC and ILT. By employing a mask\nrule-aware gradient-based optimization approach, DiffOPC efficiently guides\nmask edge segment movement during mask optimization, minimizing wafer error by\npropagating true gradients from the cost function back to the mask edges. Our\napproach achieves lower edge placement error while reducing manufacturing cost\nby half compared to state-of-the-art OPC techniques, bridging the gap between\nthe high accuracy of pixel-based OPC and the practicality required for\nindustrial adoption, thus offering a promising solution for advanced\nsemiconductor manufacturing.",
    "categories": [
      "cs.AI",
      "physics.optics"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICCAD24",
    "pdf_url": "http://arxiv.org/pdf/2408.08969v3",
    "published_date": "2024-08-16 18:35:01 UTC",
    "updated_date": "2024-08-30 02:35:32 UTC"
  },
  {
    "arxiv_id": "2408.08968v4",
    "title": "Online SLA Decomposition: Enabling Real-Time Adaptation to Evolving Network Systems",
    "authors": [
      "Cyril Shih-Huan Hsu",
      "Danny De Vleeschauwer",
      "Chrysa Papagianni",
      "Paola Grosso"
    ],
    "abstract": "When a network slice spans multiple technology domains, it is crucial for\neach domain to uphold the End-to-End (E2E) Service Level Agreement (SLA)\nassociated with the slice. Consequently, the E2E SLA must be properly\ndecomposed into partial SLAs that are assigned to each domain involved. In a\nnetwork slice management system with a two-level architecture, comprising an\nE2E service orchestrator and local domain controllers, we consider that the\norchestrator has access only to historical data regarding the responses of\nlocal controllers to previous requests, and this information is used to\nconstruct a risk model for each domain. In this study, we extend our previous\nwork by investigating the dynamic nature of real-world systems and introducing\nan online learning-decomposition framework to tackle the dynamicity. We propose\na framework that continuously updates the risk models based on the most recent\nfeedback. This approach leverages key components such as online gradient\ndescent and FIFO memory buffers, which enhance the stability and robustness of\nthe overall process. Our empirical study on an analytic model-based simulator\ndemonstrates that the proposed framework outperforms the state-of-the-art\nstatic approach, delivering more accurate and resilient SLA decomposition under\nvarying conditions and data limitations. Furthermore, we provide a\ncomprehensive complexity analysis of the proposed solution.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "The paper has been accepted for publication at EuCNC & 6G Summit 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.08968v4",
    "published_date": "2024-08-16 18:34:11 UTC",
    "updated_date": "2025-04-11 16:19:31 UTC"
  },
  {
    "arxiv_id": "2408.08959v2",
    "title": "Trust-Oriented Adaptive Guardrails for Large Language Models",
    "authors": [
      "Jinwei Hu",
      "Yi Dong",
      "Xiaowei Huang"
    ],
    "abstract": "Guardrail, an emerging mechanism designed to ensure that large language\nmodels (LLMs) align with human values by moderating harmful or toxic responses,\nrequires a sociotechnical approach in their design. This paper addresses a\ncritical issue: existing guardrails lack a well-founded methodology to\naccommodate the diverse needs of different user groups, particularly concerning\naccess rights. Supported by trust modeling (primarily on `social' aspect) and\nenhanced with online in-context learning via retrieval-augmented generation (on\n`technical' aspect), we introduce an adaptive guardrail mechanism, to\ndynamically moderate access to sensitive content based on user trust metrics.\nUser trust metrics, defined as a novel combination of direct interaction trust\nand authority-verified trust, enable the system to precisely tailor the\nstrictness of content moderation by aligning with the user's credibility and\nthe specific context of their inquiries. Our empirical evaluation demonstrates\nthe effectiveness of the adaptive guardrail in meeting diverse user needs,\noutperforming existing guardrails while securing sensitive information and\nprecisely managing potentially hazardous content through a context-aware\nknowledge base. To the best of our knowledge, this work is the first to\nintroduce trust-oriented concept into a guardrail system, offering a scalable\nsolution that enriches the discourse on ethical deployment for next-generation\nLLM service.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2408.08959v2",
    "published_date": "2024-08-16 18:07:48 UTC",
    "updated_date": "2025-02-03 16:03:18 UTC"
  },
  {
    "arxiv_id": "2408.08872v2",
    "title": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models",
    "authors": [
      "Le Xue",
      "Manli Shu",
      "Anas Awadalla",
      "Jun Wang",
      "An Yan",
      "Senthil Purushwalkam",
      "Honglu Zhou",
      "Viraj Prabhu",
      "Yutong Dai",
      "Michael S Ryoo",
      "Shrikant Kendre",
      "Jieyu Zhang",
      "Can Qin",
      "Shu Zhang",
      "Chia-Chih Chen",
      "Ning Yu",
      "Juntao Tan",
      "Tulika Manoj Awalgaonkar",
      "Shelby Heinecke",
      "Huan Wang",
      "Yejin Choi",
      "Ludwig Schmidt",
      "Zeyuan Chen",
      "Silvio Savarese",
      "Juan Carlos Niebles",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "abstract": "This report introduces xGen-MM (also known as BLIP-3), a framework for\ndeveloping Large Multimodal Models (LMMs). The framework comprises meticulously\ncurated datasets, a training recipe, model architectures, and a resulting suite\nof LMMs. xGen-MM, short for xGen-MultiModal, expands the Salesforce xGen\ninitiative on foundation AI models. Our models undergo rigorous evaluation\nacross a range of tasks, including both single and multi-image benchmarks. Our\npre-trained base model exhibits strong in-context learning capabilities and the\ninstruction-tuned model demonstrates competitive performance among open-source\nLMMs with similar model sizes. In addition, we introduce a safety-tuned model\nwith DPO, aiming to mitigate harmful behaviors such as hallucinations and\nimprove safety. We open-source our models, curated large-scale datasets, and\nour fine-tuning codebase to facilitate further advancements in LMM research.\nAssociated resources will be available on our project page above.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08872v2",
    "published_date": "2024-08-16 17:57:01 UTC",
    "updated_date": "2024-08-28 05:03:34 UTC"
  },
  {
    "arxiv_id": "2408.08852v2",
    "title": "GeoTransformer: Enhancing Urban Forecasting with Dependency Retrieval and Geospatial Attention",
    "authors": [
      "Yuhao Jia",
      "Zile Wu",
      "Shengao Yi",
      "Yifei Sun"
    ],
    "abstract": "Recent advances in urban forecasting have leveraged high-dimensional spatial\ndata through two primary approaches: graph-based methods that rely on\npredefined spatial structures and region-based methods that use satellite\nimagery for local features. Although these methods have laid an important\nfoundation, they struggle to integrate holistic urban information and\ndynamically model spatial dependencies. To address this gap, we propose\nGeoTransformer, a framework combining high-dimensional regional embeddings with\ndynamic spatial modeling. GeoTransformer features two innovations: (1) a\ndependency retrieval module identifying spatial dependencies to select relevant\nregions, and (2) a geospatial attention mechanism leveraging global urban\ninformation. These components unify structural and global urban information for\nbetter predictions. Extensive experiments on GDP and ride-share demand\nforecasting show that GeoTransformer outperforms baselines, highlighting its\neffectiveness in advancing urban forecasting tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AAAI 25's workshop AI for urban planning",
    "pdf_url": "http://arxiv.org/pdf/2408.08852v2",
    "published_date": "2024-08-16 17:26:42 UTC",
    "updated_date": "2024-12-19 19:55:02 UTC"
  },
  {
    "arxiv_id": "2408.08823v1",
    "title": "Optimal Symmetries in Binary Classification",
    "authors": [
      "Vishal S. Ngairangbam",
      "Michael Spannowsky"
    ],
    "abstract": "We explore the role of group symmetries in binary classification tasks,\npresenting a novel framework that leverages the principles of Neyman-Pearson\noptimality. Contrary to the common intuition that larger symmetry groups lead\nto improved classification performance, our findings show that selecting the\nappropriate group symmetries is crucial for optimising generalisation and\nsample efficiency. We develop a theoretical foundation for designing group\nequivariant neural networks that align the choice of symmetries with the\nunderlying probability distributions of the data. Our approach provides a\nunified methodology for improving classification accuracy across a broad range\nof applications by carefully tailoring the symmetry group to the specific\ncharacteristics of the problem. Theoretical analysis and experimental results\ndemonstrate that optimal classification performance is not always associated\nwith the largest equivariant groups possible in the domain, even when the\nlikelihood ratio is invariant under one of its proper subgroups, but rather\nwith those subgroups themselves. This work offers insights and practical\nguidelines for constructing more effective group equivariant architectures in\ndiverse machine-learning contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 1 figure, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.08823v1",
    "published_date": "2024-08-16 16:15:18 UTC",
    "updated_date": "2024-08-16 16:15:18 UTC"
  },
  {
    "arxiv_id": "2409.00022v1",
    "title": "Detecting Misinformation in Multimedia Content through Cross-Modal Entity Consistency: A Dual Learning Approach",
    "authors": [
      "Zhe Fu",
      "Kanlun Wang",
      "Wangjiaxuan Xin",
      "Lina Zhou",
      "Shi Chen",
      "Yaorong Ge",
      "Daniel Janies",
      "Dongsong Zhang"
    ],
    "abstract": "The landscape of social media content has evolved significantly, extending\nfrom text to multimodal formats. This evolution presents a significant\nchallenge in combating misinformation. Previous research has primarily focused\non single modalities or text-image combinations, leaving a gap in detecting\nmultimodal misinformation. While the concept of entity consistency holds\npromise in detecting multimodal misinformation, simplifying the representation\nto a scalar value overlooks the inherent complexities of high-dimensional\nrepresentations across different modalities. To address these limitations, we\npropose a Multimedia Misinformation Detection (MultiMD) framework for detecting\nmisinformation from video content by leveraging cross-modal entity consistency.\nThe proposed dual learning approach allows for not only enhancing\nmisinformation detection performance but also improving representation learning\nof entity consistency across different modalities. Our results demonstrate that\nMultiMD outperforms state-of-the-art baseline models and underscore the\nimportance of each modality in misinformation detection. Our research provides\nnovel methodological and technical insights into multimodal misinformation\ndetection.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted to PACIS 2024. 15 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00022v1",
    "published_date": "2024-08-16 16:14:36 UTC",
    "updated_date": "2024-08-16 16:14:36 UTC"
  },
  {
    "arxiv_id": "2408.08821v3",
    "title": "EasyRec: Simple yet Effective Language Models for Recommendation",
    "authors": [
      "Xubin Ren",
      "Chao Huang"
    ],
    "abstract": "Deep neural networks have become a powerful technique for learning\nrepresentations from user-item interaction data in collaborative filtering (CF)\nfor recommender systems. However, many existing methods heavily rely on unique\nuser and item IDs, which limits their ability to perform well in practical\nzero-shot learning scenarios where sufficient training data may be unavailable.\nInspired by the success of language models (LMs) and their strong\ngeneralization capabilities, a crucial question arises: How can we harness the\npotential of language models to empower recommender systems and elevate its\ngeneralization capabilities to new heights? In this study, we propose EasyRec -\nan effective and easy-to-use approach that seamlessly integrates text-based\nsemantic understanding with collaborative signals. EasyRec employs a\ntext-behavior alignment framework, which combines contrastive learning with\ncollaborative language model tuning, to ensure a strong alignment between the\ntext-enhanced semantic space and the collaborative behavior information.\nExtensive empirical evaluations across diverse real-world datasets demonstrate\nthe superior performance of EasyRec compared to state-of-the-art alternative\nmodels, particularly in the challenging text-based zero-shot recommendation\nscenarios. Furthermore, the study highlights the potential of seamlessly\nintegrating EasyRec as a plug-and-play component into text-enhanced\ncollaborative filtering frameworks, thereby empowering existing recommender\nsystems to elevate their recommendation performance and adapt to the evolving\nuser preferences in dynamic environments. For better result reproducibility of\nour EasyRec framework, the model implementation details, source code, and\ndatasets are available at the link: https://github.com/HKUDS/EasyRec.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08821v3",
    "published_date": "2024-08-16 16:09:59 UTC",
    "updated_date": "2024-10-18 17:50:57 UTC"
  },
  {
    "arxiv_id": "2409.00021v1",
    "title": "TACOS: Task Agnostic Continual Learning in Spiking Neural Networks",
    "authors": [
      "Nicholas Soures",
      "Peter Helfer",
      "Anurag Daram",
      "Tej Pandit",
      "Dhireesha Kudithipudi"
    ],
    "abstract": "Catastrophic interference, the loss of previously learned information when\nlearning new information, remains a major challenge in machine learning. Since\nliving organisms do not seem to suffer from this problem, researchers have\ntaken inspiration from biology to improve memory retention in artificial\nintelligence systems. However, previous attempts to use bio-inspired mechanisms\nhave typically resulted in systems that rely on task boundary information\nduring training and/or explicit task identification during inference,\ninformation that is not available in real-world scenarios. Here, we show that\nneuro-inspired mechanisms such as synaptic consolidation and metaplasticity can\nmitigate catastrophic interference in a spiking neural network, using only\nsynapse-local information, with no need for task awareness, and with a fixed\nmemory size that does not need to be increased when training on new tasks. Our\nmodel, TACOS, combines neuromodulation with complex synaptic dynamics to enable\nnew learning while protecting previous information. We evaluate TACOS on\nsequential image recognition tasks and demonstrate its effectiveness in\nreducing catastrophic interference. Our results show that TACOS outperforms\nexisting regularization techniques in domain-incremental learning scenarios. We\nalso report the results of an ablation study to elucidate the contribution of\neach neuro-inspired mechanism separately.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00021v1",
    "published_date": "2024-08-16 15:42:16 UTC",
    "updated_date": "2024-08-16 15:42:16 UTC"
  },
  {
    "arxiv_id": "2408.08808v3",
    "title": "Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge",
    "authors": [
      "Ravi Raju",
      "Swayambhoo Jain",
      "Bo Li",
      "Jonathan Li",
      "Urmish Thakker"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized the landscape of machine\nlearning, yet current benchmarks often fall short in capturing the diverse\nbehavior of these models in real-world applications. A benchmark's usefulness\nis determined by its ability to clearly differentiate between models of varying\ncapabilities (separability) and closely align with human preferences. Existing\nframeworks like Alpaca-Eval 2.0 LC\n\\cite{dubois2024lengthcontrolledalpacaevalsimpleway} and Arena-Hard v0.1\n\\cite{li2024crowdsourced} are limited by their focus on general-purpose queries\nand lack of diversity across domains such as law, medicine, and multilingual\ncontexts. In this paper, we address these limitations by introducing a novel\ndata pipeline that curates diverse, domain-specific evaluation sets tailored\nfor LLM-as-a-Judge frameworks. Our approach leverages a combination of manual\ncuration, semi-supervised learning to generate clusters, and stratified\nsampling to ensure balanced representation across a wide range of domains and\nlanguages. The resulting evaluation set, which includes 1573 samples across 14\ncategories, demonstrates high separability (84\\%) across ten top-ranked models,\nand agreement (84\\%) with Chatbot Arena and (0.915) Spearman correlation. The\nagreement values are 9\\% better than Arena Hard and 20\\% better than AlpacaEval\n2.0 LC, while the Spearman coefficient is 0.7 more than the next best\nbenchmark, showcasing a significant improvement in the usefulness of the\nbenchmark. We further provide an open-source evaluation tool that enables\nfine-grained analysis of model performance across user-defined categories,\noffering valuable insights for practitioners. This work contributes to the\nongoing effort to enhance the transparency, diversity, and effectiveness of LLM\nevaluation methodologies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures, Under review",
    "pdf_url": "http://arxiv.org/pdf/2408.08808v3",
    "published_date": "2024-08-16 15:41:43 UTC",
    "updated_date": "2024-08-20 02:32:58 UTC"
  },
  {
    "arxiv_id": "2408.08805v1",
    "title": "CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems",
    "authors": [
      "Joanito Agili Lopo",
      "Marina Indah Prasasti",
      "Alma Permatasari"
    ],
    "abstract": "In this study, we introduce CIKMar, an efficient approach to educational\ndialogue systems powered by the Gemma Language model. By leveraging a\nDual-Encoder ranking system that incorporates both BERT and SBERT model, we\nhave designed CIKMar to deliver highly relevant and accurate responses, even\nwith the constraints of a smaller language model size. Our evaluation reveals\nthat CIKMar achieves a robust recall and F1-score of 0.70 using BERTScore\nmetrics. However, we have identified a significant challenge: the Dual-Encoder\ntends to prioritize theoretical responses over practical ones. These findings\nunderscore the potential of compact and efficient models like Gemma in\ndemocratizing access to advanced educational AI systems, ensuring effective and\ncontextually appropriate responses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is the result of the final project of the Natural Language\n  Processing course, Master of Artificial Intelligence, Universitas Gadjah Mada",
    "pdf_url": "http://arxiv.org/pdf/2408.08805v1",
    "published_date": "2024-08-16 15:29:54 UTC",
    "updated_date": "2024-08-16 15:29:54 UTC"
  },
  {
    "arxiv_id": "2408.10269v1",
    "title": "OpenCity: Open Spatio-Temporal Foundation Models for Traffic Prediction",
    "authors": [
      "Zhonghang Li",
      "Long Xia",
      "Lei Shi",
      "Yong Xu",
      "Dawei Yin",
      "Chao Huang"
    ],
    "abstract": "Accurate traffic forecasting is crucial for effective urban planning and\ntransportation management, enabling efficient resource allocation and enhanced\ntravel experiences. However, existing models often face limitations in\ngeneralization, struggling with zero-shot prediction on unseen regions and\ncities, as well as diminished long-term accuracy. This is primarily due to the\ninherent challenges in handling the spatial and temporal heterogeneity of\ntraffic data, coupled with the significant distribution shift across time and\nspace. In this work, we aim to unlock new possibilities for building versatile,\nresilient and adaptive spatio-temporal foundation models for traffic\nprediction. To achieve this goal, we introduce a novel foundation model, named\nOpenCity, that can effectively capture and normalize the underlying\nspatio-temporal patterns from diverse data characteristics, facilitating\nzero-shot generalization across diverse urban environments. OpenCity integrates\nthe Transformer architecture with graph neural networks to model the complex\nspatio-temporal dependencies in traffic data. By pre-training OpenCity on\nlarge-scale, heterogeneous traffic datasets, we enable the model to learn rich,\ngeneralizable representations that can be seamlessly applied to a wide range of\ntraffic forecasting scenarios. Experimental results demonstrate that OpenCity\nexhibits exceptional zero-shot predictive performance. Moreover, OpenCity\nshowcases promising scaling laws, suggesting the potential for developing a\ntruly one-for-all traffic prediction solution that can adapt to new urban\ncontexts with minimal overhead. We made our proposed OpenCity model open-source\nand it is available at the following link: https://github.com/HKUDS/OpenCity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.10269v1",
    "published_date": "2024-08-16 15:20:36 UTC",
    "updated_date": "2024-08-16 15:20:36 UTC"
  },
  {
    "arxiv_id": "2408.08790v1",
    "title": "A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks",
    "authors": [
      "Boa Jang",
      "Youngbin Ahn",
      "Eun Kyung Choe",
      "Chang Ki Yoon",
      "Hyuk Jin Choi",
      "Young-Gon Kim"
    ],
    "abstract": "Artificial intelligence applied to retinal images offers significant\npotential for recognizing signs and symptoms of retinal conditions and\nexpediting the diagnosis of eye diseases and systemic disorders. However,\ndeveloping generalized artificial intelligence models for medical data often\nrequires a large number of labeled images representing various disease signs,\nand most models are typically task-specific, focusing on major retinal\ndiseases. In this study, we developed a Fundus-Specific Pretrained Model\n(Image+Fundus), a supervised artificial intelligence model trained to detect\nabnormalities in fundus images. A total of 57,803 images were used to develop\nthis pretrained model, which achieved superior performance across various\ndownstream tasks, indicating that our proposed model outperforms other general\nmethods. Our Image+Fundus model offers a generalized approach to improve model\nperformance while reducing the number of labeled datasets required.\nAdditionally, it provides more disease-specific insights into fundus images,\nwith visualizations generated by our model. These disease-specific foundation\nmodels are invaluable in enhancing the performance and efficiency of deep\nlearning models in the field of fundus imaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08790v1",
    "published_date": "2024-08-16 15:03:06 UTC",
    "updated_date": "2024-08-16 15:03:06 UTC"
  },
  {
    "arxiv_id": "2408.08785v1",
    "title": "A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers",
    "authors": [
      "Daniel Omeiza",
      "Raunak Bhattacharyya",
      "Marina Jirotka",
      "Nick Hawes",
      "Lars Kunze"
    ],
    "abstract": "Transparency in automated systems could be afforded through the provision of\nintelligible explanations. While transparency is desirable, might it lead to\ncatastrophic outcomes (such as anxiety), that could outweigh its benefits? It's\nquite unclear how the specificity of explanations (level of transparency)\ninfluences recipients, especially in autonomous driving (AD). In this work, we\nexamined the effects of transparency mediated through varying levels of\nexplanation specificity in AD. We first extended a data-driven explainer model\nby adding a rule-based option for explanation generation in AD, and then\nconducted a within-subject lab study with 39 participants in an immersive\ndriving simulator to study the effect of the resulting explanations.\nSpecifically, our investigation focused on: (1) how different types of\nexplanations (specific vs. abstract) affect passengers' perceived safety,\nanxiety, and willingness to take control of the vehicle when the vehicle\nperception system makes erroneous predictions; and (2) the relationship between\npassengers' behavioural cues and their feelings during the autonomous drives.\nOur findings showed that passengers felt safer with specific explanations when\nthe vehicle's perception system had minimal errors, while abstract explanations\nthat hid perception errors led to lower feelings of safety. Anxiety levels\nincreased when specific explanations revealed perception system errors (high\ntransparency). We found no significant link between passengers' visual patterns\nand their anxiety levels. Our study suggests that passengers prefer clear and\nspecific explanations (high transparency) when they originate from autonomous\nvehicles (AVs) with optimal perceptual accuracy.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted to Transportation Research Part F: Traffic Psychology and\n  Behaviour. arXiv admin note: text overlap with arXiv:2307.00633",
    "pdf_url": "http://arxiv.org/pdf/2408.08785v1",
    "published_date": "2024-08-16 14:59:00 UTC",
    "updated_date": "2024-08-16 14:59:00 UTC"
  },
  {
    "arxiv_id": "2408.08781v1",
    "title": "Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions",
    "authors": [
      "Bhuvanashree Murugadoss",
      "Christian Poelitz",
      "Ian Drosos",
      "Vu Le",
      "Nick McKenna",
      "Carina Suzana Negreanu",
      "Chris Parnin",
      "Advait Sarkar"
    ],
    "abstract": "LLMs-as-a-judge is a recently popularized method which replaces human\njudgements in task evaluation (Zheng et al. 2024) with automatic evaluation\nusing LLMs. Due to widespread use of RLHF (Reinforcement Learning from Human\nFeedback), state-of-the-art LLMs like GPT4 and Llama3 are expected to have\nstrong alignment with human preferences when prompted for a quality judgement,\nsuch as the coherence of a text. While this seems beneficial, it is not clear\nwhether the assessments by an LLM-as-a-judge constitute only an evaluation\nbased on the instructions in the prompts, or reflect its preference for\nhigh-quality data similar to its fine-tune data. To investigate how much\ninfluence prompting the LLMs-as-a-judge has on the alignment of AI judgements\nto human judgements, we analyze prompts with increasing levels of instructions\nabout the target quality of an evaluation, for several LLMs-as-a-judge.\nFurther, we compare to a prompt-free method using model perplexity as a quality\nmeasure instead. We aggregate a taxonomy of quality criteria commonly used\nacross state-of-the-art evaluations with LLMs and provide this as a rigorous\nbenchmark of models as judges. Overall, we show that the LLMs-as-a-judge\nbenefit only little from highly detailed instructions in prompts and that\nperplexity can sometimes align better with human judgements than prompting,\nespecially on textual quality.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08781v1",
    "published_date": "2024-08-16 14:49:35 UTC",
    "updated_date": "2024-08-16 14:49:35 UTC"
  },
  {
    "arxiv_id": "2408.08770v3",
    "title": "Pessimistic Iterative Planning for Robust POMDPs",
    "authors": [
      "Maris F. L. Galesloot",
      "Marnix Suilen",
      "Thiago D. Sim√£o",
      "Steven Carr",
      "Matthijs T. J. Spaan",
      "Ufuk Topcu",
      "Nils Jansen"
    ],
    "abstract": "Robust POMDPs extend classical POMDPs to handle model uncertainty.\nSpecifically, robust POMDPs exhibit so-called uncertainty sets on the\ntransition and observation models, effectively defining ranges of\nprobabilities. Policies for robust POMDPs must be (1) memory-based to account\nfor partial observability and (2) robust against model uncertainty to account\nfor the worst-case instances from the uncertainty sets. To compute such robust\nmemory-based policies, we propose the pessimistic iterative planning (PIP)\nframework, which alternates between two main steps: (1) selecting a pessimistic\n(non-robust) POMDP via worst-case probability instances from the uncertainty\nsets; and (2) computing a finite-state controller (FSC) for this pessimistic\nPOMDP. We evaluate the performance of this FSC on the original robust POMDP and\nuse this evaluation in step (1) to select the next pessimistic POMDP. Within\nPIP, we propose the rFSCNet algorithm. In each iteration, rFSCNet finds an FSC\nthrough a recurrent neural network by using supervision policies optimized for\nthe pessimistic POMDP. The empirical evaluation in four benchmark environments\nshowcases improved robustness against several baseline methods and competitive\nperformance compared to a state-of-the-art robust POMDP solver.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08770v3",
    "published_date": "2024-08-16 14:25:20 UTC",
    "updated_date": "2024-11-12 13:50:05 UTC"
  },
  {
    "arxiv_id": "2408.10268v2",
    "title": "Generating Streamlining Constraints with Large Language Models",
    "authors": [
      "Florentina Voboril",
      "Vaidyanathan Peruvemba Ramaswamy",
      "Stefan Szeider"
    ],
    "abstract": "Streamlining constraints (or streamliners, for short) narrow the search\nspace, enhancing the speed and feasibility of solving complex constraint\nsatisfaction problems. Traditionally, streamliners were crafted manually or\ngenerated through systematically combined atomic constraints with high-effort\noffline testing. Our approach utilizes the creativity of Large Language Models\n(LLMs) to propose effective streamliners for problems specified in the MiniZinc\nconstraint programming language and integrates feedback to the LLM with quick\nempirical tests for validation. Evaluated across seven diverse constraint\nsatisfaction problems, our method achieves substantial runtime reductions. We\ncompare the results to obfuscated and disguised variants of the problem to see\nwhether the results depend on LLM memorization. We also analyze whether longer\noff-line runs improve the quality of streamliners and whether the LLM can\npropose good combinations of streamliners.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10268v2",
    "published_date": "2024-08-16 14:17:26 UTC",
    "updated_date": "2025-01-28 21:31:38 UTC"
  },
  {
    "arxiv_id": "2408.08739v1",
    "title": "ASVspoof 5: Crowdsourced Speech Data, Deepfakes, and Adversarial Attacks at Scale",
    "authors": [
      "Xin Wang",
      "Hector Delgado",
      "Hemlata Tak",
      "Jee-weon Jung",
      "Hye-jin Shim",
      "Massimiliano Todisco",
      "Ivan Kukanov",
      "Xuechen Liu",
      "Md Sahidullah",
      "Tomi Kinnunen",
      "Nicholas Evans",
      "Kong Aik Lee",
      "Junichi Yamagishi"
    ],
    "abstract": "ASVspoof 5 is the fifth edition in a series of challenges that promote the\nstudy of speech spoofing and deepfake attacks, and the design of detection\nsolutions. Compared to previous challenges, the ASVspoof 5 database is built\nfrom crowdsourced data collected from a vastly greater number of speakers in\ndiverse acoustic conditions. Attacks, also crowdsourced, are generated and\ntested using surrogate detection models, while adversarial attacks are\nincorporated for the first time. New metrics support the evaluation of\nspoofing-robust automatic speaker verification (SASV) as well as stand-alone\ndetection solutions, i.e., countermeasures without ASV. We describe the two\nchallenge tracks, the new database, the evaluation metrics, baselines, and the\nevaluation platform, and present a summary of the results. Attacks\nsignificantly compromise the baseline systems, while submissions bring\nsubstantial improvements.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "8 pages, ASVspoof 5 Workshop (Interspeech2024 Satellite)",
    "pdf_url": "http://arxiv.org/pdf/2408.08739v1",
    "published_date": "2024-08-16 13:37:20 UTC",
    "updated_date": "2024-08-16 13:37:20 UTC"
  },
  {
    "arxiv_id": "2408.08732v1",
    "title": "Symbolic Parameter Learning in Probabilistic Answer Set Programming",
    "authors": [
      "Damiano Azzolini",
      "Elisabetta Gentili",
      "Fabrizio Riguzzi"
    ],
    "abstract": "Parameter learning is a crucial task in the field of Statistical Relational\nArtificial Intelligence: given a probabilistic logic program and a set of\nobservations in the form of interpretations, the goal is to learn the\nprobabilities of the facts in the program such that the probabilities of the\ninterpretations are maximized. In this paper, we propose two algorithms to\nsolve such a task within the formalism of Probabilistic Answer Set Programming,\nboth based on the extraction of symbolic equations representing the\nprobabilities of the interpretations. The first solves the task using an\noff-the-shelf constrained optimization solver while the second is based on an\nimplementation of the Expectation Maximization algorithm. Empirical results\nshow that our proposals often outperform existing approaches based on projected\nanswer set enumeration in terms of quality of the solution and in terms of\nexecution time. The paper has been accepted at the ICLP2024 conference and is\nunder consideration in Theory and Practice of Logic Programming (TPLP).",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "The paper has been accepted at the ICLP2024 conference and is under\n  consideration in Theory and Practice of Logic Programming (TPLP)",
    "pdf_url": "http://arxiv.org/pdf/2408.08732v1",
    "published_date": "2024-08-16 13:32:47 UTC",
    "updated_date": "2024-08-16 13:32:47 UTC"
  },
  {
    "arxiv_id": "2408.08723v1",
    "title": "Correspondence-Guided SfM-Free 3D Gaussian Splatting for NVS",
    "authors": [
      "Wei Sun",
      "Xiaosong Zhang",
      "Fang Wan",
      "Yanzhao Zhou",
      "Yuan Li",
      "Qixiang Ye",
      "Jianbin Jiao"
    ],
    "abstract": "Novel View Synthesis (NVS) without Structure-from-Motion (SfM) pre-processed\ncamera poses--referred to as SfM-free methods--is crucial for promoting rapid\nresponse capabilities and enhancing robustness against variable operating\nconditions. Recent SfM-free methods have integrated pose optimization,\ndesigning end-to-end frameworks for joint camera pose estimation and NVS.\nHowever, most existing works rely on per-pixel image loss functions, such as L2\nloss. In SfM-free methods, inaccurate initial poses lead to misalignment issue,\nwhich, under the constraints of per-pixel image loss functions, results in\nexcessive gradients, causing unstable optimization and poor convergence for\nNVS. In this study, we propose a correspondence-guided SfM-free 3D Gaussian\nsplatting for NVS. We use correspondences between the target and the rendered\nresult to achieve better pixel alignment, facilitating the optimization of\nrelative poses between frames. We then apply the learned poses to optimize the\nentire scene. Each 2D screen-space pixel is associated with its corresponding\n3D Gaussians through approximated surface rendering to facilitate gradient back\npropagation. Experimental results underline the superior performance and time\nefficiency of the proposed approach compared to the state-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2312.07504 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2408.08723v1",
    "published_date": "2024-08-16 13:11:22 UTC",
    "updated_date": "2024-08-16 13:11:22 UTC"
  },
  {
    "arxiv_id": "2408.08713v4",
    "title": "CTR-KAN: KAN for Adaptive High-Order Feature Interaction Modeling",
    "authors": [
      "Yunxiao Shi",
      "Wujiang Xu",
      "Haimin Zhang",
      "Qiang Wu",
      "Yongfeng Zhang",
      "Min Xu"
    ],
    "abstract": "Modeling high-order feature interactions is critical for click-through rate\n(CTR) prediction, yet traditional approaches often face challenges in balancing\npredictive accuracy and computational efficiency. These methods typically rely\non pre-defined interaction orders, which limit flexibility and require\nextensive prior knowledge. Moreover, explicitly modeling high-order\ninteractions can lead to significant computational overhead. To tackle these\nchallenges, we propose CTR-KAN, an adaptive framework for efficient high-order\nfeature interaction modeling. CTR-KAN builds upon the Kolmogorov-Arnold Network\n(KAN) paradigm, addressing its limitations in CTR prediction tasks.\nSpecifically, we introduce key enhancements, including a lightweight\narchitecture that reduces the computational complexity of KAN and supports\nembedding-based feature representations. Additionally, CTR-KAN integrates\nguided symbolic regression to effectively capture multiplicative relationships,\na known challenge in standard KAN implementations. Extensive experiments\ndemonstrate that CTR-KAN achieves state-of-the-art predictive accuracy with\nsignificantly lower computational costs. Its sparse network structure also\nfacilitates feature pruning and enhances global interpretability, making\nCTR-KAN a powerful tool for efficient inference in real-world CTR prediction\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "draft paper",
    "pdf_url": "http://arxiv.org/pdf/2408.08713v4",
    "published_date": "2024-08-16 12:51:52 UTC",
    "updated_date": "2025-01-25 03:14:35 UTC"
  },
  {
    "arxiv_id": "2408.08707v2",
    "title": "Beam Prediction based on Large Language Models",
    "authors": [
      "Yucheng Sheng",
      "Kai Huang",
      "Le Liang",
      "Peng Liu",
      "Shi Jin",
      "Geoffrey Ye Li"
    ],
    "abstract": "In this letter, we use large language models (LLMs) to develop a\nhigh-performing and robust beam prediction method. We formulate the millimeter\nwave (mmWave) beam prediction problem as a time series forecasting task, where\nthe historical observations are aggregated through cross-variable attention and\nthen transformed into text-based representations using a trainable tokenizer.\nBy leveraging the prompt-as-prefix (PaP) technique for contextual enrichment,\nour method harnesses the power of LLMs to predict future optimal beams.\nSimulation results demonstrate that our LLM-based approach outperforms\ntraditional learning-based models in prediction accuracy as well as robustness,\nhighlighting the significant potential of LLMs in enhancing wireless\ncommunication systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08707v2",
    "published_date": "2024-08-16 12:40:01 UTC",
    "updated_date": "2025-02-12 13:29:11 UTC"
  },
  {
    "arxiv_id": "2408.08704v2",
    "title": "Beyond the Hype: A dispassionate look at vision-language models in medical scenario",
    "authors": [
      "Yang Nan",
      "Huichi Zhou",
      "Xiaodan Xing",
      "Guang Yang"
    ],
    "abstract": "Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated\nremarkable capabilities across diverse tasks, garnering significant attention\nin AI communities. However, their performance and reliability in specialized\ndomains such as medicine remain insufficiently assessed. In particular, most\nassessments over-concentrate on evaluating VLMs based on simple Visual Question\nAnswering (VQA) on multi-modality data, while ignoring the in-depth\ncharacteristics of LVLMs. In this study, we introduce RadVUQA, a novel\nRadiological Visual Understanding and Question Answering benchmark, to\ncomprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across\nfive dimensions: 1) Anatomical understanding, assessing the models' ability to\nvisually identify biological structures; 2) Multimodal comprehension, which\ninvolves the capability of interpreting linguistic and visual instructions to\nproduce desired outcomes; 3) Quantitative and spatial reasoning, evaluating the\nmodels' spatial awareness and proficiency in combining quantitative analysis\nwith visual and linguistic information; 4) Physiological knowledge, measuring\nthe models' capability to comprehend functions and mechanisms of organs and\nsystems; and 5) Robustness, which assesses the models' capabilities against\nunharmonized and synthetic data. The results indicate that both generalized\nLVLMs and medical-specific LVLMs have critical deficiencies with weak\nmultimodal comprehension and quantitative reasoning capabilities. Our findings\nreveal the large gap between existing LVLMs and clinicians, highlighting the\nurgent need for more robust and intelligent LVLMs. The code is available at\nhttps://github.com/Nandayang/RadVUQA",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.08704v2",
    "published_date": "2024-08-16 12:32:44 UTC",
    "updated_date": "2025-04-09 17:42:01 UTC"
  },
  {
    "arxiv_id": "2408.08698v1",
    "title": "NFDI4DSO: Towards a BFO Compliant Ontology for Data Science",
    "authors": [
      "Genet Asefa Gesese",
      "J√∂rg Waitelonis",
      "Zongxiong Chen",
      "Sonja Schimmler",
      "Harald Sack"
    ],
    "abstract": "The NFDI4DataScience (NFDI4DS) project aims to enhance the accessibility and\ninteroperability of research data within Data Science (DS) and Artificial\nIntelligence (AI) by connecting digital artifacts and ensuring they adhere to\nFAIR (Findable, Accessible, Interoperable, and Reusable) principles. To this\nend, this poster introduces the NFDI4DS Ontology, which describes resources in\nDS and AI and models the structure of the NFDI4DS consortium. Built upon the\nNFDICore ontology and mapped to the Basic Formal Ontology (BFO), this ontology\nserves as the foundation for the NFDI4DS knowledge graph currently under\ndevelopment.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08698v1",
    "published_date": "2024-08-16 12:26:22 UTC",
    "updated_date": "2024-08-16 12:26:22 UTC"
  },
  {
    "arxiv_id": "2408.08694v1",
    "title": "Quantifying the Effectiveness of Student Organization Activities using Natural Language Processing",
    "authors": [
      "Lyberius Ennio F. Taruc",
      "Arvin R. De La Cruz"
    ],
    "abstract": "Student extracurricular activities play an important role in enriching the\nstudents' educational experiences. With the increasing popularity of Machine\nLearning and Natural Language Processing, it becomes a logical step that\nincorporating ML-NLP in improving extracurricular activities is a potential\nfocus of study in Artificial Intelligence (AI). This research study aims to\ndevelop a machine learning workflow that will quantify the effectiveness of\nstudent-organized activities based on student emotional responses using\nsentiment analysis. The study uses the Bidirectional Encoder Representations\nfrom Transformers (BERT) Large Language Model (LLM) called via the\npysentimiento toolkit, as a Transformer pipeline in Hugging Face. A sample data\nset from Organization C, a Recognized Student Organization (RSO) of a higher\neducational institute in the Philippines, College X, was used to develop the\nworkflow. The workflow consisted of data preprocessing, key feature selection,\nLLM feature processing, and score aggregation, resulting in an Event Score for\neach data set. The results show that the BERT LLM can also be used effectively\nin analyzing sentiment beyond product reviews and post comments. For the\nstudent affairs offices of educational institutions, this study can provide a\npractical example of how NLP can be applied to real-world scenarios, showcasing\nthe potential impact of data-driven decision making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 4 figures, presented in International Conference on\n  Generative Al and its Applications (ICGAIA-24) last 22nd - 23rd, July, 2024\n  at Jakarta, Indonesia",
    "pdf_url": "http://arxiv.org/pdf/2408.08694v1",
    "published_date": "2024-08-16 12:16:59 UTC",
    "updated_date": "2024-08-16 12:16:59 UTC"
  },
  {
    "arxiv_id": "2408.08688v4",
    "title": "The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation",
    "authors": [
      "Samee Arif",
      "Sualeha Farid",
      "Abdul Hameed Azeemi",
      "Awais Athar",
      "Agha Ali Raza"
    ],
    "abstract": "This paper presents a novel methodology for generating synthetic Preference\nOptimization (PO) datasets using multi-agent workflows. We evaluate the\neffectiveness and potential of these workflows in automating and enhancing the\ndataset generation process. PO dataset generation requires two modules: (1)\nresponse evaluation, and (2) response generation. In the response evaluation\nmodule, the responses from Large Language Models (LLMs) are evaluated and\nranked - a task typically carried out by human annotators that we automate\nusing LLMs. We assess the response evaluation module in a 2 step process. In\nstep 1, we assess LLMs as evaluators using three distinct prompting strategies.\nIn step 2, we apply the winning prompting strategy to compare the performance\nof LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. Our evaluation shows that\nGPT-4o-as-a-Judge is more consistent across all datasets. For the response\ngeneration module, we use the identified LLM evaluator configuration and\ncompare different configurations of the LLM Feedback Loop. We use the win rate\nto determine the best multi-agent configuration for generation. Experimenting\nwith various configurations, we find that the LLM Feedback Loop, with Llama as\nthe generator and Gemma as the reviewer, achieves a notable 71.8% and 73.8% win\nrate over single-agent Llama and Gemma, respectively. After identifying the\nbest configurations for both modules, we generate our PO datasets using the\nabove pipeline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08688v4",
    "published_date": "2024-08-16 12:01:55 UTC",
    "updated_date": "2024-10-16 12:15:19 UTC"
  },
  {
    "arxiv_id": "2408.08686v2",
    "title": "SC-Rec: Enhancing Generative Retrieval with Self-Consistent Reranking for Sequential Recommendation",
    "authors": [
      "Tongyoung Kim",
      "Soojin Yoon",
      "Seongku Kang",
      "Jinyoung Yeo",
      "Dongha Lee"
    ],
    "abstract": "Language Models (LMs) are increasingly employed in recommendation systems due\nto their advanced language understanding and generation capabilities. Recent\nrecommender systems based on generative retrieval have leveraged the\ninferential abilities of LMs to directly generate the index tokens of the next\nitem, based on item sequences within the user's interaction history. Previous\nstudies have mostly focused on item indices based solely on textual semantic or\ncollaborative information. However, although the standalone effectiveness of\nthese aspects has been demonstrated, the integration of this information has\nremained unexplored. Our in-depth analysis finds that there is a significant\ndifference in the knowledge captured by the model from heterogeneous item\nindices and diverse input prompts, which can have a high potential for\ncomplementarity. In this paper, we propose SC-Rec, a unified recommender system\nthat learns diverse preference knowledge from two distinct item indices and\nmultiple prompt templates. Furthermore, SC-Rec adopts a novel reranking\nstrategy that aggregates a set of ranking results, inferred based on different\nindices and prompts, to achieve the self-consistency of the model. Our\nempirical evaluation on three real-world datasets demonstrates that SC-Rec\nconsiderably outperforms the state-of-the-art methods for sequential\nrecommendation, effectively incorporating complementary knowledge from varied\noutputs of the model.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08686v2",
    "published_date": "2024-08-16 11:59:01 UTC",
    "updated_date": "2024-08-19 04:31:51 UTC"
  },
  {
    "arxiv_id": "2408.08685v3",
    "title": "Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?",
    "authors": [
      "Zhongjian Zhang",
      "Xiao Wang",
      "Huichi Zhou",
      "Yue Yu",
      "Mengmei Zhang",
      "Cheng Yang",
      "Chuan Shi"
    ],
    "abstract": "Graph neural networks (GNNs) are vulnerable to adversarial attacks,\nespecially for topology perturbations, and many methods that improve the\nrobustness of GNNs have received considerable attention. Recently, we have\nwitnessed the significant success of large language models (LLMs), leading many\nto explore the great potential of LLMs on GNNs. However, they mainly focus on\nimproving the performance of GNNs by utilizing LLMs to enhance the node\nfeatures. Therefore, we ask: Will the robustness of GNNs also be enhanced with\nthe powerful understanding and inference capabilities of LLMs? By presenting\nthe empirical results, we find that despite that LLMs can improve the\nrobustness of GNNs, there is still an average decrease of 23.1% in accuracy,\nimplying that the GNNs remain extremely vulnerable against topology attacks.\nTherefore, another question is how to extend the capabilities of LLMs on graph\nadversarial robustness. In this paper, we propose an LLM-based robust graph\nstructure inference framework, LLM4RGNN, which distills the inference\ncapabilities of GPT-4 into a local LLM for identifying malicious edges and an\nLM-based edge predictor for finding missing important edges, so as to recover a\nrobust graph structure. Extensive experiments demonstrate that LLM4RGNN\nconsistently improves the robustness across various GNNs. Even in some cases\nwhere the perturbation ratio increases to 40%, the accuracy of GNNs is still\nbetter than that on the clean graph. The source code can be found in\nhttps://github.com/zhongjian-zhang/LLM4RGNN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.08685v3",
    "published_date": "2024-08-16 11:58:34 UTC",
    "updated_date": "2024-12-24 07:08:45 UTC"
  },
  {
    "arxiv_id": "2408.08682v1",
    "title": "LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression",
    "authors": [
      "Yuqi Ye",
      "Wei Gao"
    ],
    "abstract": "The key to effective point cloud compression is to obtain a robust context\nmodel consistent with complex 3D data structures. Recently, the advancement of\nlarge language models (LLMs) has highlighted their capabilities not only as\npowerful generators for in-context learning and generation but also as\neffective compressors. These dual attributes of LLMs make them particularly\nwell-suited to meet the demands of data compression. Therefore, this paper\nexplores the potential of using LLM for compression tasks, focusing on lossless\npoint cloud geometry compression (PCGC) experiments. However, applying LLM\ndirectly to PCGC tasks presents some significant challenges, i.e., LLM does not\nunderstand the structure of the point cloud well, and it is a difficult task to\nfill the gap between text and point cloud through text description, especially\nfor large complicated and small shapeless point clouds. To address these\nproblems, we introduce a novel architecture, namely the Large Language\nModel-based Point Cloud Geometry Compression (LLM-PCGC) method, using LLM to\ncompress point cloud geometry information without any text description or\naligning operation. By utilizing different adaptation techniques for\ncross-modality representation alignment and semantic consistency, including\nclustering, K-tree, token mapping invariance, and Low Rank Adaptation (LoRA),\nthe proposed method can translate LLM to a compressor/generator for point\ncloud. To the best of our knowledge, this is the first structure to employ LLM\nas a compressor for point cloud data. Experiments demonstrate that the LLM-PCGC\noutperforms the other existing methods significantly, by achieving -40.213% bit\nrate reduction compared to the reference software of MPEG Geometry-based Point\nCloud Compression (G-PCC) standard, and by achieving -2.267% bit rate reduction\ncompared to the state-of-the-art learning-based method.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08682v1",
    "published_date": "2024-08-16 11:55:44 UTC",
    "updated_date": "2024-08-16 11:55:44 UTC"
  },
  {
    "arxiv_id": "2408.08677v1",
    "title": "Neural Reward Machines",
    "authors": [
      "Elena Umili",
      "Francesco Argenziano",
      "Roberto Capobianco"
    ],
    "abstract": "Non-markovian Reinforcement Learning (RL) tasks are very hard to solve,\nbecause agents must consider the entire history of state-action pairs to act\nrationally in the environment. Most works use symbolic formalisms (as Linear\nTemporal Logic or automata) to specify the temporally-extended task. These\napproaches only work in finite and discrete state environments or continuous\nproblems for which a mapping between the raw state and a symbolic\ninterpretation is known as a symbol grounding (SG) function. Here, we define\nNeural Reward Machines (NRM), an automata-based neurosymbolic framework that\ncan be used for both reasoning and learning in non-symbolic non-markovian RL\ndomains, which is based on the probabilistic relaxation of Moore Machines. We\ncombine RL with semisupervised symbol grounding (SSSG) and we show that NRMs\ncan exploit high-level symbolic knowledge in non-symbolic environments without\nany knowledge of the SG function, outperforming Deep RL methods which cannot\nincorporate prior knowledge. Moreover, we advance the research in SSSG,\nproposing an algorithm for analysing the groundability of temporal\nspecifications, which is more efficient than baseline techniques of a factor\n$10^3$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08677v1",
    "published_date": "2024-08-16 11:44:27 UTC",
    "updated_date": "2024-08-16 11:44:27 UTC"
  },
  {
    "arxiv_id": "2408.08676v1",
    "title": "Fine-tuning LLMs for Autonomous Spacecraft Control: A Case Study Using Kerbal Space Program",
    "authors": [
      "Alejandro Carrasco",
      "Victor Rodriguez-Fernandez",
      "Richard Linares"
    ],
    "abstract": "Recent trends are emerging in the use of Large Language Models (LLMs) as\nautonomous agents that take actions based on the content of the user text\nprompt. This study explores the use of fine-tuned Large Language Models (LLMs)\nfor autonomous spacecraft control, using the Kerbal Space Program Differential\nGames suite (KSPDG) as a testing environment. Traditional Reinforcement\nLearning (RL) approaches face limitations in this domain due to insufficient\nsimulation capabilities and data. By leveraging LLMs, specifically fine-tuning\nmodels like GPT-3.5 and LLaMA, we demonstrate how these models can effectively\ncontrol spacecraft using language-based inputs and outputs. Our approach\nintegrates real-time mission telemetry into textual prompts processed by the\nLLM, which then generate control actions via an agent. The results open a\ndiscussion about the potential of LLMs for space operations beyond their\nnominal use for text-related tasks. Future work aims to expand this methodology\nto other space control tasks and evaluate the performance of different LLM\nfamilies. The code is available at this URL:\n\\texttt{https://github.com/ARCLab-MIT/kspdg}.",
    "categories": [
      "cs.AI",
      "astro-ph.IM"
    ],
    "primary_category": "cs.AI",
    "comment": "ESA SPAICE Conference 2024. arXiv admin note: text overlap with\n  arXiv:2404.00413",
    "pdf_url": "http://arxiv.org/pdf/2408.08676v1",
    "published_date": "2024-08-16 11:43:31 UTC",
    "updated_date": "2024-08-16 11:43:31 UTC"
  },
  {
    "arxiv_id": "2408.08673v2",
    "title": "MAT-SED: A Masked Audio Transformer with Masked-Reconstruction Based Pre-training for Sound Event Detection",
    "authors": [
      "Pengfei Cai",
      "Yan Song",
      "Kang Li",
      "Haoyu Song",
      "Ian McLoughlin"
    ],
    "abstract": "Sound event detection (SED) methods that leverage a large pre-trained\nTransformer encoder network have shown promising performance in recent DCASE\nchallenges. However, they still rely on an RNN-based context network to model\ntemporal dependencies, largely due to the scarcity of labeled data. In this\nwork, we propose a pure Transformer-based SED model with masked-reconstruction\nbased pre-training, termed MAT-SED. Specifically, a Transformer with relative\npositional encoding is first designed as the context network, pre-trained by\nthe masked-reconstruction task on all available target data in a\nself-supervised way. Both the encoder and the context network are jointly\nfine-tuned in a semi-supervised manner. Furthermore, a global-local feature\nfusion strategy is proposed to enhance the localization capability. Evaluation\nof MAT-SED on DCASE2023 task4 surpasses state-of-the-art performance, achieving\n0.587/0.896 PSDS1/PSDS2 respectively.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Received by interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08673v2",
    "published_date": "2024-08-16 11:33:16 UTC",
    "updated_date": "2024-08-19 07:11:39 UTC"
  },
  {
    "arxiv_id": "2408.08670v1",
    "title": "Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning",
    "authors": [
      "Alessio Devoto",
      "Federico Alvetreti",
      "Jary Pomponi",
      "Paolo Di Lorenzo",
      "Pasquale Minervini",
      "Simone Scardapane"
    ],
    "abstract": "Recently, foundation models based on Vision Transformers (ViTs) have become\nwidely available. However, their fine-tuning process is highly\nresource-intensive, and it hinders their adoption in several edge or low-energy\napplications. To this end, in this paper we introduce an efficient fine-tuning\nmethod for ViTs called $\\textbf{ALaST}$ ($\\textit{Adaptive Layer Selection\nFine-Tuning for Vision Transformers}$) to speed up the fine-tuning process\nwhile reducing computational cost, memory load, and training time. Our approach\nis based on the observation that not all layers are equally critical during\nfine-tuning, and their importance varies depending on the current mini-batch.\nTherefore, at each fine-tuning step, we adaptively estimate the importance of\nall layers and we assign what we call ``compute budgets'' accordingly. Layers\nthat were allocated lower budgets are either trained with a reduced number of\ninput tokens or kept frozen. Freezing a layer reduces the computational cost\nand memory usage by preventing updates to its weights, while discarding tokens\nremoves redundant data, speeding up processing and reducing memory\nrequirements. We show that this adaptive compute allocation enables a\nnearly-optimal schedule for distributing computational resources across layers,\nresulting in substantial reductions in training time (up to 1.5x), FLOPs (up to\n2x), and memory load (up to 2x) compared to traditional full fine-tuning\napproaches. Additionally, it can be successfully combined with other\nparameter-efficient fine-tuning methods, such as LoRA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08670v1",
    "published_date": "2024-08-16 11:27:52 UTC",
    "updated_date": "2024-08-16 11:27:52 UTC"
  },
  {
    "arxiv_id": "2408.08668v1",
    "title": "Robust Stochastic Shortest-Path Planning via Risk-Sensitive Incremental Sampling",
    "authors": [
      "Clinton Enwerem",
      "Erfaun Noorani",
      "John S. Baras",
      "Brian M. Sadler"
    ],
    "abstract": "With the pervasiveness of Stochastic Shortest-Path (SSP) problems in\nhigh-risk industries, such as last-mile autonomous delivery and supply chain\nmanagement, robust planning algorithms are crucial for ensuring successful task\ncompletion while mitigating hazardous outcomes. Mainstream chance-constrained\nincremental sampling techniques for solving SSP problems tend to be overly\nconservative and typically do not consider the likelihood of undesirable tail\nevents. We propose an alternative risk-aware approach inspired by the\nasymptotically-optimal Rapidly-Exploring Random Trees (RRT*) planning\nalgorithm, which selects nodes along path segments with minimal Conditional\nValue-at-Risk (CVaR). Our motivation rests on the step-wise coherence of the\nCVaR risk measure and the optimal substructure of the SSP problem. Thus,\noptimizing with respect to the CVaR at each sampling iteration necessarily\nleads to an optimal path in the limit of the sample size. We validate our\napproach via numerical path planning experiments in a two-dimensional grid\nworld with obstacles and stochastic path-segment lengths. Our simulation\nresults show that incorporating risk into the tree growth process yields paths\nwith lengths that are significantly less sensitive to variations in the noise\nparameter, or equivalently, paths that are more robust to environmental\nuncertainty. Algorithmic analyses reveal similar query time and memory space\ncomplexity to the baseline RRT* procedure, with only a marginal increase in\nprocessing time. This increase is offset by significantly lower noise\nsensitivity and reduced planner failure rates.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for presentation at the 2024 IEEE Conference on Decision and\n  Control (CDC)",
    "pdf_url": "http://arxiv.org/pdf/2408.08668v1",
    "published_date": "2024-08-16 11:21:52 UTC",
    "updated_date": "2024-08-16 11:21:52 UTC"
  },
  {
    "arxiv_id": "2408.08666v2",
    "title": "A Multivocal Literature Review on Privacy and Fairness in Federated Learning",
    "authors": [
      "Beatrice Balbierer",
      "Lukas Heinlein",
      "Domenique Zipperling",
      "Niklas K√ºhl"
    ],
    "abstract": "Federated Learning presents a way to revolutionize AI applications by\neliminating the necessity for data sharing. Yet, research has shown that\ninformation can still be extracted during training, making additional\nprivacy-preserving measures such as differential privacy imperative. To\nimplement real-world federated learning applications, fairness, ranging from a\nfair distribution of performance to non-discriminative behaviour, must be\nconsidered. Particularly in high-risk applications (e.g. healthcare), avoiding\nthe repetition of past discriminatory errors is paramount. As recent research\nhas demonstrated an inherent tension between privacy and fairness, we conduct a\nmultivocal literature review to examine the current methods to integrate\nprivacy and fairness in federated learning. Our analyses illustrate that the\nrelationship between privacy and fairness has been neglected, posing a critical\nrisk for real-world applications. We highlight the need to explore the\nrelationship between privacy, fairness, and performance, advocating for the\ncreation of integrated federated learning frameworks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the 19th International Conference on\n  Wirtschaftsinformatik (WI), 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08666v2",
    "published_date": "2024-08-16 11:15:52 UTC",
    "updated_date": "2024-10-27 11:08:39 UTC"
  },
  {
    "arxiv_id": "2408.08655v1",
    "title": "Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons",
    "authors": [
      "Binbin Ding",
      "Penghui Yang",
      "Zeqing Ge",
      "Shengjun Huang"
    ],
    "abstract": "Federated learning enables multiple clients to collaboratively train machine\nlearning models under the overall planning of the server while adhering to\nprivacy requirements. However, the server cannot directly oversee the local\ntraining process, creating an opportunity for malicious clients to introduce\nbackdoors. Existing research shows that backdoor attacks activate specific\nneurons in the compromised model, which remain dormant when processing clean\ndata. Leveraging this insight, we propose a method called Flipping Weight\nUpdates of Low-Activation Input Neurons (FLAIN) to defend against backdoor\nattacks in federated learning. Specifically, after completing global training,\nwe employ an auxiliary dataset to identify low-activation input neurons and\nflip the associated weight updates. We incrementally raise the threshold for\nlow-activation inputs and flip the weight updates iteratively, until the\nperformance degradation on the auxiliary data becomes unacceptable. Extensive\nexperiments validate that our method can effectively reduce the success rate of\nbackdoor attacks to a low level in various attack scenarios including those\nwith non-IID data distribution or high MCRs, causing only minimal performance\ndegradation on clean data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08655v1",
    "published_date": "2024-08-16 10:44:14 UTC",
    "updated_date": "2024-08-16 10:44:14 UTC"
  },
  {
    "arxiv_id": "2408.08652v1",
    "title": "TextCAVs: Debugging vision models using text",
    "authors": [
      "Angus Nicolson",
      "Yarin Gal",
      "J. Alison Noble"
    ],
    "abstract": "Concept-based interpretability methods are a popular form of explanation for\ndeep learning models which provide explanations in the form of high-level human\ninterpretable concepts. These methods typically find concept activation vectors\n(CAVs) using a probe dataset of concept examples. This requires labelled data\nfor these concepts -- an expensive task in the medical domain. We introduce\nTextCAVs: a novel method which creates CAVs using vision-language models such\nas CLIP, allowing for explanations to be created solely using text descriptions\nof the concept, as opposed to image exemplars. This reduced cost in testing\nconcepts allows for many concepts to be tested and for users to interact with\nthe model, testing new ideas as they are thought of, rather than a delay caused\nby image collection and annotation. In early experimental results, we\ndemonstrate that TextCAVs produces reasonable explanations for a chest x-ray\ndataset (MIMIC-CXR) and natural images (ImageNet), and that these explanations\ncan be used to debug deep learning-based models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "I.2.1; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 2 figures. Accepted at iMIMIC Workshop at MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08652v1",
    "published_date": "2024-08-16 10:36:08 UTC",
    "updated_date": "2024-08-16 10:36:08 UTC"
  },
  {
    "arxiv_id": "2408.08651v2",
    "title": "Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning",
    "authors": [
      "Kyle Moore",
      "Jesse Roberts",
      "Thao Pham",
      "Douglas Fisher"
    ],
    "abstract": "Language models are known to absorb biases from their training data, leading\nto predictions driven by statistical regularities rather than semantic\nrelevance. We investigate the impact of these biases on answer choice\npreferences in the Massive Multi-Task Language Understanding (MMLU) task. Our\nfindings reveal that differences in learned regularities across answer options\nare predictive of model preferences and mirror human test-taking strategies. To\naddress this issue, we introduce two novel methods: Counterfactual Prompting\nwith Chain of Thought (CoT) and Counterfactual Prompting with Agnostically\nPrimed CoT (APriCoT). We demonstrate that while Counterfactual Prompting with\nCoT alone is insufficient to mitigate bias, our novel Primed Counterfactual\nPrompting with CoT approach effectively reduces the influence of base-rate\nprobabilities while improving overall accuracy. Our results suggest that\nmitigating bias requires a \"System-2\" like process and that CoT reasoning is\nsusceptible to confirmation bias under some prompting methodologies. Our\ncontributions offer practical solutions for developing more robust and fair\nlanguage models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08651v2",
    "published_date": "2024-08-16 10:34:50 UTC",
    "updated_date": "2024-09-06 01:52:02 UTC"
  },
  {
    "arxiv_id": "2408.08648v1",
    "title": "Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based Argumentation",
    "authors": [
      "Jonathan Ben-Naim",
      "Victor David",
      "Anthony Hunter"
    ],
    "abstract": "Argument mining is natural language processing technology aimed at\nidentifying arguments in text. Furthermore, the approach is being developed to\nidentify the premises and claims of those arguments, and to identify the\nrelationships between arguments including support and attack relationships. In\nthis paper, we assume that an argument map contains the premises and claims of\narguments, and support and attack relationships between them, that have been\nidentified by argument mining. So from a piece of text, we assume an argument\nmap is obtained automatically by natural language processing. However, to\nunderstand and to automatically analyse that argument map, it would be\ndesirable to instantiate that argument map with logical arguments. Once we have\nthe logical representation of the arguments in an argument map, we can use\nautomated reasoning to analyze the argumentation (e.g. check consistency of\npremises, check validity of claims, and check the labelling on each arc\ncorresponds with thw logical arguments). We address this need by using\nclassical logic for representing the explicit information in the text, and\nusing default logic for representing the implicit information in the text. In\norder to investigate our proposal, we consider some specific options for\ninstantiation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Research note",
    "pdf_url": "http://arxiv.org/pdf/2408.08648v1",
    "published_date": "2024-08-16 10:30:30 UTC",
    "updated_date": "2024-08-16 10:30:30 UTC"
  },
  {
    "arxiv_id": "2408.08637v1",
    "title": "Magazine Supply Optimization: a Case-study",
    "authors": [
      "Duong Nguyen",
      "Ana Ulianovici",
      "Sami Achour",
      "Soline Aubry",
      "Nicolas Chesneau"
    ],
    "abstract": "Supply optimization is a complex and challenging task in the magazine retail\nindustry because of the fixed inventory assumption, irregular sales patterns,\nand varying product and point-of-sale characteristics. We introduce AthenIA, an\nindustrialized magazine supply optimization solution that plans the supply for\nover 20,000 points of sale in France. We modularize the supply planning process\ninto a four-step pipeline: demand sensing, optimization, business rules, and\noperating. The core of the solution is a novel group conformalized quantile\nregression method that integrates domain expert insights, coupled with a supply\noptimization technique that balances the costs of out-of-stock against the\ncosts of over-supply. AthenIA has proven to be a valuable tool for magazine\npublishers, particularly in the context of evolving economic and ecological\nchallenges.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08637v1",
    "published_date": "2024-08-16 10:06:59 UTC",
    "updated_date": "2024-08-16 10:06:59 UTC"
  },
  {
    "arxiv_id": "2408.08632v2",
    "title": "A Survey on Benchmarks of Multimodal Large Language Models",
    "authors": [
      "Jian Li",
      "Weiheng Lu",
      "Hao Fei",
      "Meng Luo",
      "Ming Dai",
      "Min Xia",
      "Yizhang Jin",
      "Zhenye Gan",
      "Ding Qi",
      "Chaoyou Fu",
      "Ying Tai",
      "Wankou Yang",
      "Yabiao Wang",
      "Chengjie Wang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are gaining increasing popularity in\nboth academia and industry due to their remarkable performance in various\napplications such as visual question answering, visual perception,\nunderstanding, and reasoning. Over the past few years, significant efforts have\nbeen made to examine MLLMs from multiple perspectives. This paper presents a\ncomprehensive review of 200 benchmarks and evaluations for MLLMs, focusing on\n(1)perception and understanding, (2)cognition and reasoning, (3)specific\ndomains, (4)key capabilities, and (5)other modalities. Finally, we discuss the\nlimitations of the current evaluation methods for MLLMs and explore promising\nfuture directions. Our key argument is that evaluation should be regarded as a\ncrucial discipline to support the development of MLLMs better. For more\ndetails, please visit our GitHub repository:\nhttps://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08632v2",
    "published_date": "2024-08-16 09:52:02 UTC",
    "updated_date": "2024-09-06 11:20:13 UTC"
  },
  {
    "arxiv_id": "2408.08934v1",
    "title": "A Factored MDP Approach To Moving Target Defense With Dynamic Threat Modeling and Cost Efficiency",
    "authors": [
      "Megha Bose",
      "Praveen Paruchuri",
      "Akshat Kumar"
    ],
    "abstract": "Moving Target Defense (MTD) has emerged as a proactive and dynamic framework\nto counteract evolving cyber threats. Traditional MTD approaches often rely on\nassumptions about the attackers knowledge and behavior. However, real-world\nscenarios are inherently more complex, with adaptive attackers and limited\nprior knowledge of their payoffs and intentions. This paper introduces a novel\napproach to MTD using a Markov Decision Process (MDP) model that does not rely\non predefined attacker payoffs. Our framework integrates the attackers\nreal-time responses into the defenders MDP using a dynamic Bayesian Network. By\nemploying a factored MDP model, we provide a comprehensive and realistic system\nrepresentation. We also incorporate incremental updates to an attack response\npredictor as new data emerges. This ensures an adaptive and robust defense\nmechanism. Additionally, we consider the costs of switching configurations in\nMTD, integrating them into the reward structure to balance execution and\ndefense costs. We first highlight the challenges of the problem through a\ntheoretical negative result on regret. However, empirical evaluations\ndemonstrate the frameworks effectiveness in scenarios marked by high\nuncertainty and dynamically changing attack landscapes.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08934v1",
    "published_date": "2024-08-16 09:38:59 UTC",
    "updated_date": "2024-08-16 09:38:59 UTC"
  },
  {
    "arxiv_id": "2408.08624v1",
    "title": "RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions",
    "authors": [
      "Gregory Kell",
      "Angus Roberts",
      "Serge Umansky",
      "Yuti Khare",
      "Najma Ahmed",
      "Nikhil Patel",
      "Chloe Simela",
      "Jack Coumbe",
      "Julian Rozario",
      "Ryan-Rhys Griffiths",
      "Iain J. Marshall"
    ],
    "abstract": "Clinical question answering systems have the potential to provide clinicians\nwith relevant and timely answers to their questions. Nonetheless, despite the\nadvances that have been made, adoption of these systems in clinical settings\nhas been slow. One issue is a lack of question-answering datasets which reflect\nthe real-world needs of health professionals. In this work, we present\nRealMedQA, a dataset of realistic clinical questions generated by humans and an\nLLM. We describe the process for generating and verifying the QA pairs and\nassess several QA models on BioASQ and RealMedQA to assess the relative\ndifficulty of matching answers to questions. We show that the LLM is more\ncost-efficient for generating \"ideal\" QA pairs. Additionally, we achieve a\nlower lexical similarity between questions and answers than BioASQ which\nprovides an additional challenge to the top two QA models, as per the results.\nWe release our code and our dataset publicly to encourage further research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AMIA Annual Symposium 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08624v1",
    "published_date": "2024-08-16 09:32:43 UTC",
    "updated_date": "2024-08-16 09:32:43 UTC"
  },
  {
    "arxiv_id": "2408.08623v2",
    "title": "SketchRef: a Multi-Task Evaluation Benchmark for Sketch Synthesis",
    "authors": [
      "Xingyue Lin",
      "Xingjian Hu",
      "Shuai Peng",
      "Jianhua Zhu",
      "Liangcai Gao"
    ],
    "abstract": "Sketching is a powerful artistic technique for capturing essential visual\ninformation about real-world objects and has increasingly attracted attention\nin image synthesis research. However, the field lacks a unified benchmark to\nevaluate the performance of various synthesis methods. To address this, we\npropose SketchRef, the first comprehensive multi-task evaluation benchmark for\nsketch synthesis. SketchRef fully leverages the shared characteristics between\nsketches and reference photos. It introduces two primary tasks: category\nprediction and structural consistency estimation, the latter being largely\noverlooked in previous studies. These tasks are further divided into five\nsub-tasks across four domains: animals, common things, human body, and faces.\nRecognizing the inherent trade-off between recognizability and simplicity in\nsketches, we are the first to quantify this balance by introducing a\nrecognizability calculation method constrained by simplicity, mRS, ensuring\nfair and meaningful evaluations. To validate our approach, we collected 7,920\nresponses from art enthusiasts, confirming the effectiveness of our proposed\nevaluation metrics. Additionally, we evaluate the performance of existing\nsketch synthesis methods on our benchmark, highlighting their strengths and\nweaknesses. We hope this study establishes a standardized benchmark and offers\nvaluable insights for advancing sketch synthesis algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08623v2",
    "published_date": "2024-08-16 09:32:26 UTC",
    "updated_date": "2025-04-09 03:18:01 UTC"
  },
  {
    "arxiv_id": "2408.08622v1",
    "title": "DeepDFA: Automata Learning through Neural Probabilistic Relaxations",
    "authors": [
      "Elena Umili",
      "Roberto Capobianco"
    ],
    "abstract": "In this work, we introduce DeepDFA, a novel approach to identifying\nDeterministic Finite Automata (DFAs) from traces, harnessing a differentiable\nyet discrete model. Inspired by both the probabilistic relaxation of DFAs and\nRecurrent Neural Networks (RNNs), our model offers interpretability\npost-training, alongside reduced complexity and enhanced training efficiency\ncompared to traditional RNNs. Moreover, by leveraging gradient-based\noptimization, our method surpasses combinatorial approaches in both scalability\nand noise resilience. Validation experiments conducted on target regular\nlanguages of varying size and complexity demonstrate that our approach is\naccurate, fast, and robust to noise in both the input symbols and the output\nlabels of training data, integrating the strengths of both logical grammar\ninduction and deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08622v1",
    "published_date": "2024-08-16 09:30:36 UTC",
    "updated_date": "2024-08-16 09:30:36 UTC"
  },
  {
    "arxiv_id": "2408.08619v1",
    "title": "PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code",
    "authors": [
      "Ziyou Jiang",
      "Lin Shi",
      "Guowei Yang",
      "Qing Wang"
    ],
    "abstract": "Security patches are essential for enhancing the stability and robustness of\nprojects in the software community. While vulnerabilities are officially\nexpected to be patched before being disclosed, patching vulnerabilities is\ncomplicated and remains a struggle for many organizations. To patch\nvulnerabilities, security practitioners typically track vulnerable issue\nreports (IRs), and analyze their relevant insecure code to generate potential\npatches. However, the relevant insecure code may not be explicitly specified\nand practitioners cannot track the insecure code in the repositories, thus\nlimiting their ability to generate patches. In such cases, providing examples\nof insecure code and the corresponding patches would benefit the security\ndevelopers to better locate and fix the insecure code. In this paper, we\npropose PatUntrack to automatically generating patch examples from IRs without\ntracked insecure code. It auto-prompts Large Language Models (LLMs) to make\nthem applicable to analyze the vulnerabilities. It first generates the\ncompleted description of the Vulnerability-Triggering Path (VTP) from\nvulnerable IRs. Then, it corrects hallucinations in the VTP description with\nexternal golden knowledge. Finally, it generates Top-K pairs of Insecure Code\nand Patch Example based on the corrected VTP description. To evaluate the\nperformance, we conducted experiments on 5,465 vulnerable IRs. The experimental\nresults show that PatUntrack can obtain the highest performance and improve the\ntraditional LLM baselines by +14.6% (Fix@10) on average in patch example\ngeneration. Furthermore, PatUntrack was applied to generate patch examples for\n76 newly disclosed vulnerable IRs. 27 out of 37 replies from the authors of\nthese IRs confirmed the usefulness of the patch examples generated by\nPatUntrack, indicating that they can benefit from these examples for patching\nthe vulnerabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by ASE'24",
    "pdf_url": "http://arxiv.org/pdf/2408.08619v1",
    "published_date": "2024-08-16 09:19:27 UTC",
    "updated_date": "2024-08-16 09:19:27 UTC"
  },
  {
    "arxiv_id": "2408.08610v1",
    "title": "Generative Dataset Distillation Based on Diffusion Model",
    "authors": [
      "Duo Su",
      "Junjie Hou",
      "Guang Li",
      "Ren Togo",
      "Rui Song",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "abstract": "This paper presents our method for the generative track of The First Dataset\nDistillation Challenge at ECCV 2024. Since the diffusion model has become the\nmainstay of generative models because of its high-quality generative effects,\nwe focus on distillation methods based on the diffusion model. Considering that\nthe track can only generate a fixed number of images in 10 minutes using a\ngenerative model for CIFAR-100 and Tiny-ImageNet datasets, we need to use a\ngenerative model that can generate images at high speed. In this study, we\nproposed a novel generative dataset distillation method based on Stable\nDiffusion. Specifically, we use the SDXL-Turbo model which can generate images\nat high speed and quality. Compared to other diffusion models that can only\ngenerate images per class (IPC) = 1, our method can achieve an IPC = 10 for\nTiny-ImageNet and an IPC = 20 for CIFAR-100, respectively. Additionally, to\ngenerate high-quality distilled datasets for CIFAR-100 and Tiny-ImageNet, we\nuse the class information as text prompts and post data augmentation for the\nSDXL-Turbo model. Experimental results show the effectiveness of the proposed\nmethod, and we achieved third place in the generative track of the ECCV 2024 DD\nChallenge. Codes are available at https://github.com/Guang000/BANKO.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "The Third Place Winner in Generative Track of the ECCV 2024 DD\n  Challenge",
    "pdf_url": "http://arxiv.org/pdf/2408.08610v1",
    "published_date": "2024-08-16 08:52:02 UTC",
    "updated_date": "2024-08-16 08:52:02 UTC"
  },
  {
    "arxiv_id": "2408.10266v1",
    "title": "Diffusion Model for Planning: A Systematic Literature Review",
    "authors": [
      "Toshihide Ubukata",
      "Jialong Li",
      "Kenji Tei"
    ],
    "abstract": "Diffusion models, which leverage stochastic processes to capture complex data\ndistributions effectively, have shown their performance as generative models,\nachieving notable success in image-related tasks through iterative denoising\nprocesses. Recently, diffusion models have been further applied and show their\nstrong abilities in planning tasks, leading to a significant growth in related\npublications since 2023. To help researchers better understand the field and\npromote the development of the field, we conduct a systematic literature review\nof recent advancements in the application of diffusion models for planning.\nSpecifically, this paper categorizes and discusses the current literature from\nthe following perspectives: (i) relevant datasets and benchmarks used for\nevaluating diffusion modelbased planning; (ii) fundamental studies that address\naspects such as sampling efficiency; (iii) skill-centric and condition-guided\nplanning for enhancing adaptability; (iv) safety and uncertainty managing\nmechanism for enhancing safety and robustness; and (v) domain-specific\napplication such as autonomous driving. Finally, given the above literature\nreview, we further discuss the challenges and future directions in this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.10266v1",
    "published_date": "2024-08-16 08:37:01 UTC",
    "updated_date": "2024-08-16 08:37:01 UTC"
  },
  {
    "arxiv_id": "2409.00015v1",
    "title": "Navigating the sociotechnical labyrinth: Dynamic certification for responsible embodied AI",
    "authors": [
      "Georgios Bakirtzis",
      "Andrea Aler Tubella",
      "Andreas Theodorou",
      "David Danks",
      "Ufuk Topcu"
    ],
    "abstract": "Sociotechnical requirements shape the governance of artificially intelligent\n(AI) systems. In an era where embodied AI technologies are rapidly reshaping\nvarious facets of contemporary society, their inherent dynamic adaptability\npresents a unique blend of opportunities and challenges. Traditional regulatory\nmechanisms, often designed for static -- or slower-paced -- technologies, find\nthemselves at a crossroads when faced with the fluid and evolving nature of AI\nsystems. Moreover, typical problems in AI, for example, the frequent opacity\nand unpredictability of the behaviour of the systems, add additional\nsociotechnical challenges.\n  To address these interconnected issues, we introduce the concept of dynamic\ncertification, an adaptive regulatory framework specifically crafted to keep\npace with the continuous evolution of AI systems. The complexity of these\nchallenges requires common progress in multiple domains: technical,\nsocio-governmental, and regulatory. Our proposed transdisciplinary approach is\ndesigned to ensure the safe, ethical, and practical deployment of AI systems,\naligning them bidirectionally with the real-world contexts in which they\noperate. By doing so, we aim to bridge the gap between rapid technological\nadvancement and effective regulatory oversight, ensuring that AI systems not\nonly achieve their intended goals but also adhere to ethical standards and\nsocietal values.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00015v1",
    "published_date": "2024-08-16 08:35:26 UTC",
    "updated_date": "2024-08-16 08:35:26 UTC"
  },
  {
    "arxiv_id": "2408.08600v1",
    "title": "MM-UNet: A Mixed MLP Architecture for Improved Ophthalmic Image Segmentation",
    "authors": [
      "Zunjie Xiao",
      "Xiaoqing Zhang",
      "Risa Higashita",
      "Jiang Liu"
    ],
    "abstract": "Ophthalmic image segmentation serves as a critical foundation for ocular\ndisease diagnosis. Although fully convolutional neural networks (CNNs) are\ncommonly employed for segmentation, they are constrained by inductive biases\nand face challenges in establishing long-range dependencies. Transformer-based\nmodels address these limitations but introduce substantial computational\noverhead. Recently, a simple yet efficient Multilayer Perceptron (MLP)\narchitecture was proposed for image classification, achieving competitive\nperformance relative to advanced transformers. However, its effectiveness for\nophthalmic image segmentation remains unexplored. In this paper, we introduce\nMM-UNet, an efficient Mixed MLP model tailored for ophthalmic image\nsegmentation. Within MM-UNet, we propose a multi-scale MLP (MMLP) module that\nfacilitates the interaction of features at various depths through a grouping\nstrategy, enabling simultaneous capture of global and local information. We\nconducted extensive experiments on both a private anterior segment optical\ncoherence tomography (AS-OCT) image dataset and a public fundus image dataset.\nThe results demonstrated the superiority of our MM-UNet model in comparison to\nstate-of-the-art deep segmentation networks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "OMIA2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08600v1",
    "published_date": "2024-08-16 08:34:50 UTC",
    "updated_date": "2024-08-16 08:34:50 UTC"
  },
  {
    "arxiv_id": "2408.12669v1",
    "title": "Bayesian Network Modeling of Causal Influence within Cognitive Domains and Clinical Dementia Severity Ratings for Western and Indian Cohorts",
    "authors": [
      "Wupadrasta Santosh Kumar",
      "Sayali Rajendra Bhutare",
      "Neelam Sinha",
      "Thomas Gregor Issac"
    ],
    "abstract": "This study investigates the causal relationships between Clinical Dementia\nRatings (CDR) and its six domain scores across two distinct aging datasets: the\nAlzheimer's Disease Neuroimaging Initiative (ADNI) and the Longitudinal Aging\nStudy of India (LASI). Using Directed Acyclic Graphs (DAGs) derived from\nBayesian network models, we analyze the dependencies among domain scores and\ntheir influence on the global CDR. Our approach leverages the PC algorithm to\nestimate the DAG structures for both datasets, revealing notable differences in\ncausal relationships and edge strengths between the Western and Indian\npopulations. The analysis highlights a stronger dependency of CDR scores on\nmemory functions in both datasets, but with significant variations in edge\nstrengths and node degrees. By contrasting these findings, we aim to elucidate\npopulation-specific differences and similarities in dementia progression,\nproviding insights that could inform targeted interventions and improve\nunderstanding of dementia across diverse demographic contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.12669v1",
    "published_date": "2024-08-16 07:53:57 UTC",
    "updated_date": "2024-08-16 07:53:57 UTC"
  },
  {
    "arxiv_id": "2408.08590v2",
    "title": "A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models",
    "authors": [
      "Geonhee Kim",
      "Marco Valentino",
      "Andr√© Freitas"
    ],
    "abstract": "Recent studies on logical reasoning in Language Models (LMs) have sparked a\ndebate on whether they can learn systematic reasoning principles during\npre-training or merely exploit superficial patterns in the training data. This\npaper presents a mechanistic interpretation of syllogistic reasoning in LMs to\nadvance the understanding of internal dynamics. Specifically, we present a\nmethodology for circuit discovery aimed at interpreting content-independent\nreasoning mechanisms. Through two distinct intervention methods, we uncover a\nsufficient and necessary circuit involving middle-term suppression that\nelucidates how LMs transfer information to derive valid conclusions from\npremises. Furthermore, we investigate how belief biases manifest in syllogistic\nreasoning, finding evidence of partial contamination from additional attention\nheads responsible for encoding commonsense and contextualized knowledge.\nFinally, we explore the generalization of the discovered mechanisms across\nvarious syllogistic schemes, model sizes and architectures, finding that the\nidentified circuit is sufficient and necessary for the schemes on which the\nmodels achieve high downstream accuracy (> 60%), and that the activation\npatterns apply to models of different families. Overall, our findings suggest\nthat LMs indeed learn transferable content-independent reasoning mechanisms,\nbut that, at the same time, such mechanisms do not involve generalizable and\nabstract logical primitives, being susceptible to contamination by the same\nworld knowledge acquired during pre-training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08590v2",
    "published_date": "2024-08-16 07:47:39 UTC",
    "updated_date": "2025-02-17 12:09:50 UTC"
  },
  {
    "arxiv_id": "2408.08584v1",
    "title": "S-RAF: A Simulation-Based Robustness Assessment Framework for Responsible Autonomous Driving",
    "authors": [
      "Daniel Omeiza",
      "Pratik Somaiya",
      "Jo-Ann Pattinson",
      "Carolyn Ten-Holter",
      "Jack Stilgoe",
      "Marina Jirotka",
      "Lars Kunze"
    ],
    "abstract": "As artificial intelligence (AI) technology advances, ensuring the robustness\nand safety of AI-driven systems has become paramount. However, varying\nperceptions of robustness among AI developers create misaligned evaluation\nmetrics, complicating the assessment and certification of safety-critical and\ncomplex AI systems such as autonomous driving (AD) agents. To address this\nchallenge, we introduce Simulation-Based Robustness Assessment Framework\n(S-RAF) for autonomous driving. S-RAF leverages the CARLA Driving simulator to\nrigorously assess AD agents across diverse conditions, including faulty\nsensors, environmental changes, and complex traffic situations. By quantifying\nrobustness and its relationship with other safety-critical factors, such as\ncarbon emissions, S-RAF aids developers and stakeholders in building safe and\nresponsible driving agents, and streamlining safety certification processes.\nFurthermore, S-RAF offers significant advantages, such as reduced testing\ncosts, and the ability to explore edge cases that may be unsafe to test in the\nreal world. The code for this framework is available here:\nhttps://github.com/cognitive-robots/rai-leaderboard",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08584v1",
    "published_date": "2024-08-16 07:37:05 UTC",
    "updated_date": "2024-08-16 07:37:05 UTC"
  },
  {
    "arxiv_id": "2408.08571v1",
    "title": "AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation",
    "authors": [
      "Lukas Kirchdorfer",
      "Robert Bl√ºmel",
      "Timotheus Kampik",
      "Han van der Aa",
      "Heiner Stuckenschmidt"
    ],
    "abstract": "Business process simulation (BPS) is a versatile technique for estimating\nprocess performance across various scenarios. Traditionally, BPS approaches\nemploy a control-flow-first perspective by enriching a process model with\nsimulation parameters. Although such approaches can mimic the behavior of\ncentrally orchestrated processes, such as those supported by workflow systems,\ncurrent control-flow-first approaches cannot faithfully capture the dynamics of\nreal-world processes that involve distinct resource behavior and decentralized\ndecision-making. Recognizing this issue, this paper introduces AgentSimulator,\na resource-first BPS approach that discovers a multi-agent system from an event\nlog, modeling distinct resource behaviors and interaction patterns to simulate\nthe underlying process. Our experiments show that AgentSimulator achieves\nstate-of-the-art simulation accuracy with significantly lower computation times\nthan existing approaches while providing high interpretability and adaptability\nto different types of process-execution scenarios.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08571v1",
    "published_date": "2024-08-16 07:19:11 UTC",
    "updated_date": "2024-08-16 07:19:11 UTC"
  },
  {
    "arxiv_id": "2408.08933v1",
    "title": "RoarGraph: A Projected Bipartite Graph for Efficient Cross-Modal Approximate Nearest Neighbor Search",
    "authors": [
      "Meng Chen",
      "Kai Zhang",
      "Zhenying He",
      "Yinan Jing",
      "X. Sean Wang"
    ],
    "abstract": "Approximate Nearest Neighbor Search (ANNS) is a fundamental and critical\ncomponent in many applications, including recommendation systems and large\nlanguage model-based applications. With the advancement of multimodal neural\nmodels, which transform data from different modalities into a shared\nhigh-dimensional space as feature vectors, cross-modal ANNS aims to use the\ndata vector from one modality (e.g., texts) as the query to retrieve the most\nsimilar items from another (e.g., images or videos). However, there is an\ninherent distribution gap between embeddings from different modalities, and\ncross-modal queries become Out-of-Distribution (OOD) to the base data.\nConsequently, state-of-the-art ANNS approaches suffer poor performance for OOD\nworkloads. In this paper, we quantitatively analyze the properties of the OOD\nworkloads to gain an understanding of their ANNS efficiency. Unlike\nsingle-modal workloads, we reveal OOD queries spatially deviate from base data,\nand the k-nearest neighbors of an OOD query are distant from each other in the\nembedding space. The property breaks the assumptions of existing ANNS\napproaches and mismatches their design for efficient search. With insights from\nthe OOD workloads, we propose pRojected bipartite Graph (RoarGraph), an\nefficient ANNS graph index built under the guidance of query distribution.\nExtensive experiments show that RoarGraph significantly outperforms\nstate-of-the-art approaches on modern cross-modal datasets, achieving up to\n3.56x faster search speed at a 90% recall rate for OOD queries.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.IR",
    "comment": "to be published in PVLDB",
    "pdf_url": "http://arxiv.org/pdf/2408.08933v1",
    "published_date": "2024-08-16 06:48:16 UTC",
    "updated_date": "2024-08-16 06:48:16 UTC"
  },
  {
    "arxiv_id": "2408.08550v2",
    "title": "String Diagram of Optimal Transports",
    "authors": [
      "Kazuki Watanabe",
      "Noboru Isobe"
    ],
    "abstract": "We present a novel hierarchical framework for optimal transport (OT) using\nstring diagrams, namely string diagrams of optimal transports. This framework\nreduces complex hierarchical OT problems to standard OT problems, allowing\nefficient synthesis of optimal hierarchical transportation plans. Our approach\nuses algebraic compositions of cost matrices to effectively model hierarchical\nstructures. We also study an adversarial situation with multiple choices in the\ncost matrices, where we present a polynomial-time algorithm for a relaxation of\nthe problem. Experimental results confirm the efficiency and performance\nadvantages of our proposed algorithm over the naive method.",
    "categories": [
      "cs.AI",
      "cs.NA",
      "math.NA",
      "math.OC",
      "90C05"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint, under review, 14 pages, 2 fugures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2408.08550v2",
    "published_date": "2024-08-16 06:33:56 UTC",
    "updated_date": "2025-01-25 04:50:05 UTC"
  },
  {
    "arxiv_id": "2408.14480v1",
    "title": "Handling abort commands for household kitchen robots",
    "authors": [
      "Darius Has",
      "Adrian Groza",
      "Mihai Pomarlan"
    ],
    "abstract": "We propose a solution for handling abort commands given to robots. The\nsolution is exemplified with a running scenario with household kitchen robots.\nThe robot uses planning to find sequences of actions that must be performed in\norder to gracefully cancel a previously received command. The Planning Domain\nDefinition Language (PDDL) is used to write a domain to model kitchen\nactivities and behaviours, and this domain is enriched with knowledge from\nonline ontologies and knowledge graphs, like DBPedia. We discuss the results\nobtained in different scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.14480v1",
    "published_date": "2024-08-16 06:20:37 UTC",
    "updated_date": "2024-08-16 06:20:37 UTC"
  },
  {
    "arxiv_id": "2408.08931v2",
    "title": "Personalized Federated Collaborative Filtering: A Variational AutoEncoder Approach",
    "authors": [
      "Zhiwei Li",
      "Guodong Long",
      "Tianyi Zhou",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "abstract": "Federated Collaborative Filtering (FedCF) is an emerging field focused on\ndeveloping a new recommendation framework with preserving privacy in a\nfederated setting. Existing FedCF methods typically combine distributed\nCollaborative Filtering (CF) algorithms with privacy-preserving mechanisms, and\nthen preserve personalized information into a user embedding vector. However,\nthe user embedding is usually insufficient to preserve the rich information of\nthe fine-grained personalization across heterogeneous clients. This paper\nproposes a novel personalized FedCF method by preserving users' personalized\ninformation into a latent variable and a neural model simultaneously.\nSpecifically, we decompose the modeling of user knowledge into two encoders,\neach designed to capture shared knowledge and personalized knowledge\nseparately. A personalized gating network is then applied to balance\npersonalization and generalization between the global and local encoders.\nMoreover, to effectively train the proposed framework, we model the CF problem\nas a specialized Variational AutoEncoder (VAE) task by integrating user\ninteraction vector reconstruction with missing value prediction. The decoder is\ntrained to reconstruct the implicit feedback from items the user has interacted\nwith, while also predicting items the user might be interested in but has not\nyet interacted with. Experimental results on benchmark datasets demonstrate\nthat the proposed method outperforms other baseline methods, showcasing\nsuperior performance. Our code is available at https://github.com/mtics/FedDAE.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 3 figures, 4 tables, conference",
    "pdf_url": "http://arxiv.org/pdf/2408.08931v2",
    "published_date": "2024-08-16 05:49:14 UTC",
    "updated_date": "2024-12-10 03:39:16 UTC"
  },
  {
    "arxiv_id": "2408.08531v2",
    "title": "Detecting Unsuccessful Students in Cybersecurity Exercises in Two Different Learning Environments",
    "authors": [
      "Valdemar ≈†v√°bensk√Ω",
      "Kristi√°n Tk√°ƒçik",
      "Aubrey Birdwell",
      "Richard Weiss",
      "Ryan S. Baker",
      "Pavel ƒåeleda",
      "Jan Vykopal",
      "Jens Mache",
      "Ankur Chattopadhyay"
    ],
    "abstract": "This full paper in the research track evaluates the usage of data logged from\ncybersecurity exercises in order to predict students who are potentially at\nrisk of performing poorly. Hands-on exercises are essential for learning since\nthey enable students to practice their skills. In cybersecurity, hands-on\nexercises are often complex and require knowledge of many topics. Therefore,\nstudents may miss solutions due to gaps in their knowledge and become\nfrustrated, which impedes their learning. Targeted aid by the instructor helps,\nbut since the instructor's time is limited, efficient ways to detect struggling\nstudents are needed. This paper develops automated tools to predict when a\nstudent is having difficulty. We formed a dataset with the actions of 313\nstudents from two countries and two learning environments: KYPO CRP and\nEDURange. These data are used in machine learning algorithms to predict the\nsuccess of students in exercises deployed in these environments. After\nextracting features from the data, we trained and cross-validated eight\nclassifiers for predicting the exercise outcome and evaluated their predictive\npower. The contribution of this paper is comparing two approaches to feature\nengineering, modeling, and classification performance on data from two learning\nenvironments. Using the features from either learning environment, we were able\nto detect and distinguish between successful and struggling students. A\ndecision tree classifier achieved the highest balanced accuracy and sensitivity\nwith data from both learning environments. The results show that activity data\nfrom cybersecurity exercises are suitable for predicting student success. In a\npotential application, such models can aid instructors in detecting struggling\nstudents and providing targeted help. We publish data and code for building\nthese models so that others can adopt or adapt them.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY",
      "K.3"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the FIE 2024 conference proceedings, see\n  https://doi.org/10.1109/FIE61694.2024.10893135",
    "pdf_url": "http://arxiv.org/pdf/2408.08531v2",
    "published_date": "2024-08-16 04:57:54 UTC",
    "updated_date": "2025-03-02 18:15:48 UTC"
  },
  {
    "arxiv_id": "2408.08527v1",
    "title": "Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading",
    "authors": [
      "Li Pan",
      "Yupei Zhang",
      "Qiushi Yang",
      "Tan Li",
      "Xiaohan Xing",
      "Maximus C. F. Yeung",
      "Zhen Chen"
    ],
    "abstract": "Recently, multimodal deep learning, which integrates histopathology slides\nand molecular biomarkers, has achieved a promising performance in glioma\ngrading. Despite great progress, due to the intra-modality complexity and\ninter-modality heterogeneity, existing studies suffer from inadequate\nhistopathology representation learning and inefficient molecular-pathology\nknowledge alignment. These two issues hinder existing methods to precisely\ninterpret diagnostic molecular-pathology features, thereby limiting their\ngrading performance. Moreover, the real-world applicability of existing\nmultimodal approaches is significantly restricted as molecular biomarkers are\nnot always available during clinical deployment. To address these problems, we\nintroduce a novel Focus on Focus (FoF) framework with paired pathology-genomic\ntraining and applicable pathology-only inference, enhancing molecular-pathology\nrepresentation effectively. Specifically, we propose a Focus-oriented\nRepresentation Learning (FRL) module to encourage the model to identify regions\npositively or negatively related to glioma grading and guide it to focus on the\ndiagnostic areas with a consistency constraint. To effectively link the\nmolecular biomarkers to morphological features, we propose a Multi-view\nCross-modal Alignment (MCA) module that projects histopathology representations\ninto molecular subspaces, aligning morphological features with corresponding\nmolecular biomarker status by supervised contrastive learning. Experiments on\nthe TCGA GBM-LGG dataset demonstrate that our FoF framework significantly\nimproves the glioma grading. Remarkably, our FoF achieves superior performance\nusing only histopathology slides compared to existing multimodal methods. The\nsource code is available at https://github.com/peterlipan/FoF.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08527v1",
    "published_date": "2024-08-16 04:54:10 UTC",
    "updated_date": "2024-08-16 04:54:10 UTC"
  },
  {
    "arxiv_id": "2409.00014v1",
    "title": "DivDiff: A Conditional Diffusion Model for Diverse Human Motion Prediction",
    "authors": [
      "Hua Yu",
      "Yaqing Hou",
      "Wenbin Pei",
      "Qiang Zhang"
    ],
    "abstract": "Diverse human motion prediction (HMP) aims to predict multiple plausible\nfuture motions given an observed human motion sequence. It is a challenging\ntask due to the diversity of potential human motions while ensuring an accurate\ndescription of future human motions. Current solutions are either low-diversity\nor limited in expressiveness. Recent denoising diffusion models (DDPM) hold\npotential generative capabilities in generative tasks. However, introducing\nDDPM directly into diverse HMP incurs some issues. Although DDPM can increase\nthe diversity of the potential patterns of human motions, the predicted human\nmotions become implausible over time because of the significant noise\ndisturbances in the forward process of DDPM. This phenomenon leads to the\npredicted human motions being hard to control, seriously impacting the quality\nof predicted motions and restricting their practical applicability in\nreal-world scenarios. To alleviate this, we propose a novel conditional\ndiffusion-based generative model, called DivDiff, to predict more diverse and\nrealistic human motions. Specifically, the DivDiff employs DDPM as our backbone\nand incorporates Discrete Cosine Transform (DCT) and transformer mechanisms to\nencode the observed human motion sequence as a condition to instruct the\nreverse process of DDPM. More importantly, we design a diversified\nreinforcement sampling function (DRSF) to enforce human skeletal constraints on\nthe predicted human motions. DRSF utilizes the acquired information from human\nskeletal as prior knowledge, thereby reducing significant disturbances\nintroduced during the forward process. Extensive results received in the\nexperiments on two widely-used datasets (Human3.6M and HumanEva-I) demonstrate\nthat our model obtains competitive performance on both diversity and accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00014v1",
    "published_date": "2024-08-16 04:51:32 UTC",
    "updated_date": "2024-08-16 04:51:32 UTC"
  },
  {
    "arxiv_id": "2408.08524v1",
    "title": "GS-ID: Illumination Decomposition on Gaussian Splatting via Diffusion Prior and Parametric Light Source Optimization",
    "authors": [
      "Kang Du",
      "Zhihao Liang",
      "Zeyu Wang"
    ],
    "abstract": "We present GS-ID, a novel framework for illumination decomposition on\nGaussian Splatting, achieving photorealistic novel view synthesis and intuitive\nlight editing. Illumination decomposition is an ill-posed problem facing three\nmain challenges: 1) priors for geometry and material are often lacking; 2)\ncomplex illumination conditions involve multiple unknown light sources; and 3)\ncalculating surface shading with numerous light sources is computationally\nexpensive. To address these challenges, we first introduce intrinsic diffusion\npriors to estimate the attributes for physically based rendering. Then we\ndivide the illumination into environmental and direct components for joint\noptimization. Last, we employ deferred rendering to reduce the computational\nload. Our framework uses a learnable environment map and Spherical Gaussians\n(SGs) to represent light sources parametrically, therefore enabling\ncontrollable and photorealistic relighting on Gaussian Splatting. Extensive\nexperiments and applications demonstrate that GS-ID produces state-of-the-art\nillumination decomposition results while achieving better geometry\nreconstruction and rendering performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08524v1",
    "published_date": "2024-08-16 04:38:31 UTC",
    "updated_date": "2024-08-16 04:38:31 UTC"
  },
  {
    "arxiv_id": "2408.08506v2",
    "title": "Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding",
    "authors": [
      "Lei Huang",
      "Jiaming Guo",
      "Guanhua He",
      "Xishan Zhang",
      "Rui Zhang",
      "Shaohui Peng",
      "Shaoli Liu",
      "Tianshi Chen"
    ],
    "abstract": "Generating long-term texts such as novels using artificial intelligence has\nalways been a challenge. A common approach is to use large language models\n(LLMs) to construct a hierarchical framework that first plans and then writes.\nDespite the fact that the generated novels reach a sufficient length, they\nexhibit poor logical coherence and appeal in their plots and deficiencies in\ncharacter and event depiction, ultimately compromising the overall narrative\nquality. In this paper, we propose a method named Extracting Excelsior and\nExpanding. Ex3 initially extracts structure information from raw novel data. By\ncombining this structure information with the novel data, an\ninstruction-following dataset is meticulously crafted. This dataset is then\nutilized to fine-tune the LLM, aiming for excelsior generation performance. In\nthe final stage, a tree-like expansion method is deployed to facilitate the\ngeneration of arbitrarily long novels. Evaluation against previous methods\nshowcases Ex3's ability to produce higher-quality long-form novels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08506v2",
    "published_date": "2024-08-16 03:06:57 UTC",
    "updated_date": "2024-09-01 08:30:58 UTC"
  },
  {
    "arxiv_id": "2408.08930v1",
    "title": "DePrompt: Desensitization and Evaluation of Personal Identifiable Information in Large Language Model Prompts",
    "authors": [
      "Xiongtao Sun",
      "Gan Liu",
      "Zhipeng He",
      "Hui Li",
      "Xiaoguang Li"
    ],
    "abstract": "Prompt serves as a crucial link in interacting with large language models\n(LLMs), widely impacting the accuracy and interpretability of model outputs.\nHowever, acquiring accurate and high-quality responses necessitates precise\nprompts, which inevitably pose significant risks of personal identifiable\ninformation (PII) leakage. Therefore, this paper proposes DePrompt, a\ndesensitization protection and effectiveness evaluation framework for prompt,\nenabling users to safely and transparently utilize LLMs. Specifically, by\nleveraging large model fine-tuning techniques as the underlying privacy\nprotection method, we integrate contextual attributes to define privacy types,\nachieving high-precision PII entity identification. Additionally, through the\nanalysis of key features in prompt desensitization scenarios, we devise\nadversarial generative desensitization methods that retain important semantic\ncontent while disrupting the link between identifiers and privacy attributes.\nFurthermore, we present utility evaluation metrics for prompt to better gauge\nand balance privacy and usability. Our framework is adaptable to prompts and\ncan be extended to text usability-dependent scenarios. Through comparison with\nbenchmarks and other model methods, experimental evaluations demonstrate that\nour desensitized prompt exhibit superior privacy protection utility and model\ninference results.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08930v1",
    "published_date": "2024-08-16 02:38:25 UTC",
    "updated_date": "2024-08-16 02:38:25 UTC"
  },
  {
    "arxiv_id": "2408.08488v2",
    "title": "PITN: Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation",
    "authors": [
      "Rui Wang",
      "Mengshi Qi",
      "Yingxia Shao",
      "Anfu Zhou",
      "Huadong Ma"
    ],
    "abstract": "Monitoring blood pressure with non-invasive sensors has gained popularity for\nproviding comfortable user experiences, one of which is a significant function\nof smart wearables. Although providing a comfortable user experience, such\nmethods are suffering from the demand for a significant amount of realistic\ndata to train an individual model for each subject, especially considering the\ninvasive or obtrusive BP ground-truth measurements. To tackle this challenge,\nwe introduce a novel physics-informed temporal network~(PITN) with adversarial\ncontrastive learning to enable precise BP estimation with very limited data.\nSpecifically, we first enhance the physics-informed neural network~(PINN) with\nthe temporal block for investigating BP dynamics' multi-periodicity for\npersonal cardiovascular cycle modeling and temporal variation. We then employ\nadversarial training to generate extra physiological time series data,\nimproving PITN's robustness in the face of sparse subject-specific training\ndata. Furthermore, we utilize contrastive learning to capture the\ndiscriminative variations of cardiovascular physiologic phenomena. This\napproach aggregates physiological signals with similar blood pressure values in\nlatent space while separating clusters of samples with dissimilar blood\npressure values. Experiments on three widely-adopted datasets with different\nmodailties (\\emph{i.e.,} bioimpedance, PPG, millimeter-wave) demonstrate the\nsuperiority and effectiveness of the proposed methods over previous\nstate-of-the-art approaches. The code is available\nat~\\url{https://github.com/Zest86/ACL-PITN}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08488v2",
    "published_date": "2024-08-16 02:17:21 UTC",
    "updated_date": "2024-12-03 11:06:03 UTC"
  },
  {
    "arxiv_id": "2408.08484v1",
    "title": "An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem",
    "authors": [
      "Huaiyuan Liu",
      "Xianzhang Liu",
      "Donghua Yang",
      "Hongzhi Wang",
      "Yingchi Long",
      "Mengtong Ji",
      "Dongjing Miao",
      "Zhiyu Liang"
    ],
    "abstract": "The Maximum Minimal Cut Problem (MMCP), a NP-hard combinatorial optimization\n(CO) problem, has not received much attention due to the demanding and\nchallenging bi-connectivity constraint. Moreover, as a CO problem, it is also a\ndaunting task for machine learning, especially without labeled instances. To\ndeal with these problems, this work proposes an unsupervised learning framework\ncombined with heuristics for MMCP that can provide valid and high-quality\nsolutions. As far as we know, this is the first work that explores machine\nlearning and heuristics to solve MMCP. The unsupervised solver is inspired by a\nrelaxation-plus-rounding approach, the relaxed solution is parameterized by\ngraph neural networks, and the cost and penalty of MMCP are explicitly written\nout, which can train the model end-to-end. A crucial observation is that each\nsolution corresponds to at least one spanning tree. Based on this finding, a\nheuristic solver that implements tree transformations by adding vertices is\nutilized to repair and improve the solution quality of the unsupervised solver.\nAlternatively, the graph is simplified while guaranteeing solution consistency,\nwhich reduces the running time. We conduct extensive experiments to evaluate\nour framework and give a specific application. The results demonstrate the\nsuperiority of our method against two techniques designed.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08484v1",
    "published_date": "2024-08-16 02:07:34 UTC",
    "updated_date": "2024-08-16 02:07:34 UTC"
  },
  {
    "arxiv_id": "2408.08471v2",
    "title": "Fairness Issues and Mitigations in (Differentially Private) Socio-Demographic Data Processes",
    "authors": [
      "Joonhyuk Ko",
      "Juba Ziani",
      "Saswat Das",
      "Matt Williams",
      "Ferdinando Fioretto"
    ],
    "abstract": "Statistical agencies rely on sampling techniques to collect socio-demographic\ndata crucial for policy-making and resource allocation. This paper shows that\nsurveys of important societal relevance introduce sampling errors that unevenly\nimpact group-level estimates, thereby compromising fairness in downstream\ndecisions. To address these issues, this paper introduces an optimization\napproach modeled on real-world survey design processes, ensuring sampling costs\nare optimized while maintaining error margins within prescribed tolerances.\nAdditionally, privacy-preserving methods used to determine sampling rates can\nfurther impact these fairness issues. This paper explores the impact of\ndifferential privacy on the statistics informing the sampling process,\nrevealing a surprising effect: not only is the expected negative effect from\nthe addition of noise for differential privacy negligible, but also this\nprivacy noise can in fact reduce unfairness as it positively biases smaller\ncounts. These findings are validated over an extensive analysis using datasets\ncommonly applied in census statistics.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08471v2",
    "published_date": "2024-08-16 01:13:36 UTC",
    "updated_date": "2025-01-19 20:59:49 UTC"
  },
  {
    "arxiv_id": "2408.08470v4",
    "title": "Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models",
    "authors": [
      "Jerry Huang",
      "Prasanna Parthasarathi",
      "Mehdi Rezagholizadeh",
      "Sarath Chandar"
    ],
    "abstract": "Despite their widespread adoption, large language models (LLMs) remain\nprohibitive to use under resource constraints, with their ever growing sizes\nonly increasing the barrier for use. One noted issue is the high latency\nassociated with auto-regressive generation, rendering large LLMs use dependent\non advanced computing infrastructure. Assisted decoding, where a smaller draft\nmodel guides a larger target model's generation, has helped alleviate this, but\nremains dependent on alignment between the two models. Thus if the draft model\nis insufficiently capable on some domain relative to the target model,\nperformance can degrade. Alternatively, one can leverage multiple draft models\nto better cover the expertise of the target, but when multiple black-box draft\nmodels are available, selecting an assistant without details about its\nconstruction can be difficult. To better understand this decision making\nproblem, we observe it as a contextual bandit, where a policy must choose a\ndraft model based on a context. We show that even without prior knowledge of\nthe draft models, creating an offline dataset from only outputs of independent\ndraft/target models and training a policy over the alignment of these outputs\ncan accelerate performance on multiple domains provided the candidates are\neffective. Further results show this to hold on various settings with multiple\nassisted decoding candidates, highlighting its flexibility and the advantageous\nrole that such decision making can play.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a long paper at the 2024 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP). Official version of paper within\n  conference proceedings is available at\n  http://aclanthology.org/2024.emnlp-main.332",
    "pdf_url": "http://arxiv.org/pdf/2408.08470v4",
    "published_date": "2024-08-16 01:12:21 UTC",
    "updated_date": "2024-12-15 22:27:58 UTC"
  },
  {
    "arxiv_id": "2408.16011v1",
    "title": "A Tutorial on Brownian Motion for Biostatisticians",
    "authors": [
      "Elvis Han Cui"
    ],
    "abstract": "This manuscript provides an in-depth exploration of Brownian Motion, a\nfundamental stochastic process in probability theory for Biostatisticians. It\nbegins with foundational definitions and properties, including the construction\nof Brownian motion and its Markovian characteristics. The document delves into\nadvanced topics such as the Karhunen-Loeve expansion, reflection principles,\nand Levy's modulus of continuity. Through rigorous proofs and theorems, the\nmanuscript examines the non-differentiability of Brownian paths, the behavior\nof zero sets, and the significance of local time. The notes also cover\nimportant results like Donsker's theorem and Blumenthal's 0-1 law, emphasizing\ntheir implications in the study of stochastic processes.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "math.PR",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.16011v1",
    "published_date": "2024-08-16 00:58:21 UTC",
    "updated_date": "2024-08-16 00:58:21 UTC"
  },
  {
    "arxiv_id": "2408.08463v1",
    "title": "A theory of understanding for artificial intelligence: composability, catalysts, and learning",
    "authors": [
      "Zijian Zhang",
      "Sara Aronowitz",
      "Al√°n Aspuru-Guzik"
    ],
    "abstract": "Understanding is a crucial yet elusive concept in artificial intelligence\n(AI). This work proposes a framework for analyzing understanding based on the\nnotion of composability. Given any subject (e.g., a person or an AI), we\nsuggest characterizing its understanding of an object in terms of its ability\nto process (compose) relevant inputs into satisfactory outputs from the\nperspective of a verifier. This highly universal framework can readily apply to\nnon-human subjects, such as AIs, non-human animals, and institutions. Further,\nwe propose methods for analyzing the inputs that enhance output quality in\ncompositions, which we call catalysts. We show how the structure of a subject\ncan be revealed by analyzing its components that act as catalysts and argue\nthat a subject's learning ability can be regarded as its ability to compose\ninputs into its inner catalysts. Finally we examine the importance of learning\nability for AIs to attain general intelligence. Our analysis indicates that\nmodels capable of generating outputs that can function as their own catalysts,\nsuch as language models, establish a foundation for potentially overcoming\nexisting limitations in AI understanding.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08463v1",
    "published_date": "2024-08-16 00:17:18 UTC",
    "updated_date": "2024-08-16 00:17:18 UTC"
  },
  {
    "arxiv_id": "2408.08928v1",
    "title": "Imprecise Belief Fusion Facing a DST benchmark problem",
    "authors": [
      "Francisco Arag√£o",
      "Jo√£o Alc√¢ntara"
    ],
    "abstract": "When we merge information in Dempster-Shafer Theory (DST), we are faced with\nanomalous behavior: agents with equal expertise and credibility can have their\nopinion disregarded after resorting to the belief combination rule of this\ntheory. This problem is interesting because belief fusion is an inherent part\nof dealing with situations where available information is imprecise, as often\noccurs in Artificial Intelligence. We managed to identify an isomorphism betwin\nthe DST formal apparatus into that of a Probabilistic Logic. Thus, we solved\nthe problematic inputs affair by replacing the DST combination rule with a new\nfusion process aiming at eliminating anomalies proposed by that rule. We apply\nthe new fusion method to the DST paradox Problem.",
    "categories": [
      "cs.AI",
      "00A05",
      "G.0"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.08928v1",
    "published_date": "2024-08-16 00:03:32 UTC",
    "updated_date": "2024-08-16 00:03:32 UTC"
  }
]