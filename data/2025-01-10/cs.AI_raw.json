[
  {
    "arxiv_id": "2501.06389v1",
    "title": "Kolmogorov-Arnold networks for metal surface defect classification",
    "authors": [
      "Maciej Krzywda",
      "Mariusz Wermiński",
      "Szymon Łukasik",
      "Amir H. Gandomi"
    ],
    "abstract": "This paper presents the application of Kolmogorov-Arnold Networks (KAN) in\nclassifying metal surface defects. Specifically, steel surfaces are analyzed to\ndetect defects such as cracks, inclusions, patches, pitted surfaces, and\nscratches. Drawing on the Kolmogorov-Arnold theorem, KAN provides a novel\napproach compared to conventional multilayer perceptrons (MLPs), facilitating\nmore efficient function approximation by utilizing spline functions. The\nresults show that KAN networks can achieve better accuracy than convolutional\nneural networks (CNNs) with fewer parameters, resulting in faster convergence\nand improved performance in image classification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06389v1",
    "published_date": "2025-01-10 23:58:30 UTC",
    "updated_date": "2025-01-10 23:58:30 UTC"
  },
  {
    "arxiv_id": "2501.06382v3",
    "title": "Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention",
    "authors": [
      "Mumin Jia",
      "Jairo Diaz-Rodriguez"
    ],
    "abstract": "Human cognition is punctuated by abrupt, spontaneous shifts between\ntopics-driven by emotional, contextual, or associative cues-a phenomenon known\nas spontaneous thought in neuroscience. In contrast, self-attention based\nmodels depend on structured patterns over their inputs to predict each next\ntoken, lacking spontaneity. Motivated by this distinction, we characterize\nspontaneous topic changes in self-attention architectures, revealing both their\nsimilarities and their divergences from spontaneous human thought. First, we\nestablish theoretical results under a simplified, single-layer self-attention\nmodel with suitable conditions by defining the topic as a set of Token Priority\nGraphs (TPGs). Specifically, we demonstrate that (1) the model maintains the\npriority order of tokens related to the input topic, (2) a spontaneous topic\nchange can occur only if lower-priority tokens outnumber all higher-priority\ntokens of the input topic, and (3) unlike human cognition, the longer context\nlength or the more ambiguous input topic reduces the likelihood of spontaneous\nchange. Second, we empirically validate that these dynamics persist in modern,\nstate-of-the-art LLMs, underscoring a fundamental disparity between human\ncognition and AI behaviour in the context of spontaneous topic changes. To the\nbest of our knowledge, no prior work has explored these questions with a focus\nas closely aligned to human thought.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06382v3",
    "published_date": "2025-01-10 23:18:23 UTC",
    "updated_date": "2025-05-02 02:25:37 UTC"
  },
  {
    "arxiv_id": "2501.06370v2",
    "title": "Towards a Probabilistic Framework for Analyzing and Improving LLM-Enabled Software",
    "authors": [
      "Juan Manuel Baldonado",
      "Flavia Bonomo-Braberman",
      "Víctor Adrián Braberman"
    ],
    "abstract": "Ensuring the reliability and verifiability of large language model\n(LLM)-enabled systems remains a significant challenge in software engineering.\nWe propose a probabilistic framework for systematically analyzing and improving\nthese systems by modeling and refining distributions over clusters of\nsemantically equivalent outputs. This framework facilitates the evaluation and\niterative improvement of Transference Models--key software components that\nutilize LLMs to transform inputs into outputs for downstream tasks. To\nillustrate its utility, we apply the framework to the autoformalization\nproblem, where natural language documentation is transformed into formal\nprogram specifications. Our case illustrates how distribution-aware analysis\nenables the identification of weaknesses and guides focused alignment\nimprovements, resulting in more reliable and interpretable outputs. This\nprincipled approach offers a foundation for addressing critical challenges in\nthe development of robust LLM-enabled systems.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5; D.2.4; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06370v2",
    "published_date": "2025-01-10 22:42:06 UTC",
    "updated_date": "2025-04-13 21:33:13 UTC"
  },
  {
    "arxiv_id": "2501.07601v5",
    "title": "Real-Time Decision-Making for Digital Twin in Additive Manufacturing with Model Predictive Control using Time-Series Deep Neural Networks",
    "authors": [
      "Yi-Ping Chen",
      "Vispi Karkaria",
      "Ying-Kuan Tsai",
      "Faith Rolark",
      "Daniel Quispe",
      "Robert X. Gao",
      "Jian Cao",
      "Wei Chen"
    ],
    "abstract": "Digital Twin -- a virtual replica of a physical system enabling real-time\nmonitoring, model updating, prediction, and decision-making -- combined with\nrecent advances in machine learning, offers new opportunities for proactive\ncontrol strategies in autonomous manufacturing. However, achieving real-time\ndecision-making with Digital Twins requires efficient optimization driven by\naccurate predictions of highly nonlinear manufacturing systems. This paper\npresents a simultaneous multi-step Model Predictive Control (MPC) framework for\nreal-time decision-making, using a multivariate deep neural network, named\nTime-Series Dense Encoder (TiDE), as the surrogate model. Unlike conventional\nMPC models which only provide one-step ahead prediction, TiDE is capable of\npredicting future states within the prediction horizon in one shot\n(multi-step), significantly accelerating the MPC. Using Directed Energy\nDeposition (DED) additive manufacturing as a case study, we demonstrate the\neffectiveness of the proposed MPC in achieving melt pool temperature tracking\nto ensure part quality, while reducing porosity defects by regulating laser\npower to maintain melt pool depth constraints. In this work, we first show that\nTiDE is capable of accurately predicting melt pool temperature and depth.\nSecond, we demonstrate that the proposed MPC achieves precise temperature\ntracking while satisfying melt pool depth constraints within a targeted\ndilution range (10\\%-30\\%), reducing potential porosity defects. Compared to\nPID controller, the MPC results in smoother and less fluctuating laser power\nprofiles with competitive or superior melt pool temperature control\nperformance. This demonstrates the MPC's proactive control capabilities,\nleveraging time-series prediction and real-time optimization, positioning it as\na powerful tool for future Digital Twin applications and real-time process\noptimization in manufacturing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07601v5",
    "published_date": "2025-01-10 22:31:53 UTC",
    "updated_date": "2025-04-11 04:22:39 UTC"
  },
  {
    "arxiv_id": "2501.06365v1",
    "title": "Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts",
    "authors": [
      "Elizabeth Schaefer",
      "Kirk Roberts"
    ],
    "abstract": "This paper presents a pipeline for mitigating gender bias in large language\nmodels (LLMs) used in medical literature by neutralizing gendered occupational\npronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to\nidentify and modify pronouns tied to professions. We developed a BERT-based\nmodel, ``Modern Occupational Bias Elimination with Refined Training,'' or\n``MOBERT,'' trained on these neutralized abstracts, and compared its\nperformance with ``1965Bert,'' trained on the original dataset. MOBERT achieved\na 70\\% inclusive replacement rate, while 1965Bert reached only 4\\%. A further\nanalysis of MOBERT revealed that pronoun replacement accuracy correlated with\nthe frequency of occupational terms in the training data. We propose expanding\nthe dataset and refining the pipeline to improve performance and ensure more\nequitable language modeling in medical applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06365v1",
    "published_date": "2025-01-10 22:07:56 UTC",
    "updated_date": "2025-01-10 22:07:56 UTC"
  },
  {
    "arxiv_id": "2501.06356v1",
    "title": "Ultrasound Image Synthesis Using Generative AI for Lung Ultrasound Detection",
    "authors": [
      "Yu-Cheng Chou",
      "Gary Y. Li",
      "Li Chen",
      "Mohsen Zahiri",
      "Naveen Balaraju",
      "Shubham Patil",
      "Bryson Hicks",
      "Nikolai Schnittke",
      "David O. Kessler",
      "Jeffrey Shupp",
      "Maria Parker",
      "Cristiana Baloescu",
      "Christopher Moore",
      "Cynthia Gregory",
      "Kenton Gregory",
      "Balasundar Raju",
      "Jochen Kruecker",
      "Alvin Chen"
    ],
    "abstract": "Developing reliable healthcare AI models requires training with\nrepresentative and diverse data. In imbalanced datasets, model performance\ntends to plateau on the more prevalent classes while remaining low on less\ncommon cases. To overcome this limitation, we propose DiffUltra, the first\ngenerative AI technique capable of synthesizing realistic Lung Ultrasound (LUS)\nimages with extensive lesion variability. Specifically, we condition the\ngenerative AI by the introduced Lesion-anatomy Bank, which captures the\nlesion's structural and positional properties from real patient data to guide\nthe image synthesis.We demonstrate that DiffUltra improves consolidation\ndetection by 5.6% in AP compared to the models trained solely on real patient\ndata. More importantly, DiffUltra increases data diversity and prevalence of\nrare cases, leading to a 25% AP improvement in detecting rare instances such as\nlarge lung consolidations, which make up only 10% of the dataset.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06356v1",
    "published_date": "2025-01-10 21:32:50 UTC",
    "updated_date": "2025-01-10 21:32:50 UTC"
  },
  {
    "arxiv_id": "2501.06339v1",
    "title": "On The Statistical Complexity of Offline Decision-Making",
    "authors": [
      "Thanh Nguyen-Tang",
      "Raman Arora"
    ],
    "abstract": "We study the statistical complexity of offline decision-making with function\napproximation, establishing (near) minimax-optimal rates for stochastic\ncontextual bandits and Markov decision processes. The performance limits are\ncaptured by the pseudo-dimension of the (value) function class and a new\ncharacterization of the behavior policy that \\emph{strictly} subsumes all the\nprevious notions of data coverage in the offline decision-making literature. In\naddition, we seek to understand the benefits of using offline data in online\ndecision-making and show nearly minimax-optimal rates in a wide range of\nregimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv version for the ICML'24 paper",
    "pdf_url": "http://arxiv.org/pdf/2501.06339v1",
    "published_date": "2025-01-10 20:45:23 UTC",
    "updated_date": "2025-01-10 20:45:23 UTC"
  },
  {
    "arxiv_id": "2501.06332v1",
    "title": "Aggregating Low Rank Adapters in Federated Fine-tuning",
    "authors": [
      "Evelyn Trautmann",
      "Ian Hales",
      "Martin F. Volk"
    ],
    "abstract": "Fine-tuning large language models requires high computational and memory\nresources, and is therefore associated with significant costs. When training on\nfederated datasets, an increased communication effort is also needed. For this\nreason, parameter-efficient methods (PEFT) are becoming increasingly important.\nIn this context, very good results have already been achieved by fine-tuning\nwith low-rank adaptation methods (LoRA). The application of LoRA methods in\nFederated Learning, and especially the aggregation of adaptation matrices, is a\ncurrent research field. In this article, we propose a novel aggregation method\nand compare it with different existing aggregation methods of low rank adapters\ntrained in a federated fine-tuning of large machine learning models and\nevaluate their performance with respect to selected GLUE benchmark datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "presented at conference\n  https://flta-conference.org/flta-2024-detailed-program/",
    "pdf_url": "http://arxiv.org/pdf/2501.06332v1",
    "published_date": "2025-01-10 20:24:33 UTC",
    "updated_date": "2025-01-10 20:24:33 UTC"
  },
  {
    "arxiv_id": "2501.06322v1",
    "title": "Multi-Agent Collaboration Mechanisms: A Survey of LLMs",
    "authors": [
      "Khanh-Tung Tran",
      "Dung Dao",
      "Minh-Duong Nguyen",
      "Quoc-Viet Pham",
      "Barry O'Sullivan",
      "Hoang D. Nguyen"
    ],
    "abstract": "With recent advances in Large Language Models (LLMs), Agentic AI has become\nphenomenal in real-world applications, moving toward multiple LLM-based agents\nto perceive, learn, reason, and act collaboratively. These LLM-based\nMulti-Agent Systems (MASs) enable groups of intelligent agents to coordinate\nand solve complex tasks collectively at scale, transitioning from isolated\nmodels to collaboration-centric approaches. This work provides an extensive\nsurvey of the collaborative aspect of MASs and introduces an extensible\nframework to guide future research. Our framework characterizes collaboration\nmechanisms based on key dimensions: actors (agents involved), types (e.g.,\ncooperation, competition, or coopetition), structures (e.g., peer-to-peer,\ncentralized, or distributed), strategies (e.g., role-based or model-based), and\ncoordination protocols. Through a review of existing methodologies, our\nfindings serve as a foundation for demystifying and advancing LLM-based MASs\ntoward more intelligent and collaborative solutions for complex, real-world use\ncases. In addition, various applications of MASs across diverse domains,\nincluding 5G/6G networks, Industry 5.0, question answering, and social and\ncultural settings, are also investigated, demonstrating their wider adoption\nand broader impacts. Finally, we identify key lessons learned, open challenges,\nand potential research directions of MASs towards artificial collective\nintelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06322v1",
    "published_date": "2025-01-10 19:56:50 UTC",
    "updated_date": "2025-01-10 19:56:50 UTC"
  },
  {
    "arxiv_id": "2501.06320v1",
    "title": "TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer",
    "authors": [
      "Vladimir Bataev",
      "Subhankar Ghosh",
      "Vitaly Lavrukhin",
      "Jason Li"
    ],
    "abstract": "This work introduces TTS-Transducer - a novel architecture for\ntext-to-speech, leveraging the strengths of audio codec models and neural\ntransducers. Transducers, renowned for their superior quality and robustness in\nspeech recognition, are employed to learn monotonic alignments and allow for\navoiding using explicit duration predictors. Neural audio codecs efficiently\ncompress audio into discrete codes, revealing the possibility of applying text\nmodeling approaches to speech generation. However, the complexity of predicting\nmultiple tokens per frame from several codebooks, as necessitated by audio\ncodec models with residual quantizers, poses a significant challenge. The\nproposed system first uses a transducer architecture to learn monotonic\nalignments between tokenized text and speech codec tokens for the first\ncodebook. Next, a non-autoregressive Transformer predicts the remaining codes\nusing the alignment extracted from transducer loss. The proposed system is\ntrained end-to-end. We show that TTS-Transducer is a competitive and robust\nalternative to contemporary TTS systems.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06320v1",
    "published_date": "2025-01-10 19:50:32 UTC",
    "updated_date": "2025-01-10 19:50:32 UTC"
  },
  {
    "arxiv_id": "2501.06317v1",
    "title": "Understanding How Paper Writers Use AI-Generated Captions in Figure Caption Writing",
    "authors": [
      "Ho Yin",
      "Ng",
      "Ting-Yao Hsu",
      "Jiyoo Min",
      "Sungchul Kim",
      "Ryan A. Rossi",
      "Tong Yu",
      "Hyunggu Jung",
      "Ting-Hao 'Kenneth' Huang"
    ],
    "abstract": "Figures and their captions play a key role in scientific publications.\nHowever, despite their importance, many captions in published papers are poorly\ncrafted, largely due to a lack of attention by paper authors. While prior AI\nresearch has explored caption generation, it has mainly focused on\nreader-centered use cases, where users evaluate generated captions rather than\nactively integrating them into their writing. This paper addresses this gap by\ninvestigating how paper authors incorporate AI-generated captions into their\nwriting process through a user study involving 18 participants. Each\nparticipant rewrote captions for two figures from their own recently published\nwork, using captions generated by state-of-the-art AI models as a resource. By\nanalyzing video recordings of the writing process through interaction analysis,\nwe observed that participants often began by copying and refining AI-generated\ncaptions. Paper writers favored longer, detail-rich captions that integrated\ntextual and visual elements but found current AI models less effective for\ncomplex figures. These findings highlight the nuanced and diverse nature of\nfigure caption composition, revealing design opportunities for AI systems to\nbetter support the challenges of academic writing.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "This paper will appear at AAAI 2025 Workshop (2nd AI4Research\n  Workshop: Towards a Knowledge-grounded Scientific Research Lifecycle)",
    "pdf_url": "http://arxiv.org/pdf/2501.06317v1",
    "published_date": "2025-01-10 19:39:06 UTC",
    "updated_date": "2025-01-10 19:39:06 UTC"
  },
  {
    "arxiv_id": "2501.06314v1",
    "title": "BioAgents: Democratizing Bioinformatics Analysis with Multi-Agent Systems",
    "authors": [
      "Nikita Mehandru",
      "Amanda K. Hall",
      "Olesya Melnichenko",
      "Yulia Dubinina",
      "Daniel Tsirulnikov",
      "David Bamman",
      "Ahmed Alaa",
      "Scott Saponas",
      "Venkat S. Malladi"
    ],
    "abstract": "Creating end-to-end bioinformatics workflows requires diverse domain\nexpertise, which poses challenges for both junior and senior researchers as it\ndemands a deep understanding of both genomics concepts and computational\ntechniques. While large language models (LLMs) provide some assistance, they\noften fall short in providing the nuanced guidance needed to execute complex\nbioinformatics tasks, and require expensive computing resources to achieve high\nperformance. We thus propose a multi-agent system built on small language\nmodels, fine-tuned on bioinformatics data, and enhanced with retrieval\naugmented generation (RAG). Our system, BioAgents, enables local operation and\npersonalization using proprietary data. We observe performance comparable to\nhuman experts on conceptual genomics tasks, and suggest next steps to enhance\ncode generation capabilities.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06314v1",
    "published_date": "2025-01-10 19:30:59 UTC",
    "updated_date": "2025-01-10 19:30:59 UTC"
  },
  {
    "arxiv_id": "2501.06293v1",
    "title": "LensNet: Enhancing Real-time Microlensing Event Discovery with Recurrent Neural Networks in the Korea Microlensing Telescope Network",
    "authors": [
      "Javier Viaña",
      "Kyu-Ha Hwang",
      "Zoë de Beurs",
      "Jennifer C. Yee",
      "Andrew Vanderburg",
      "Michael D. Albrow",
      "Sun-Ju Chung",
      "Andrew Gould",
      "Cheongho Han",
      "Youn Kil Jung",
      "Yoon-Hyun Ryu",
      "In-Gu Shin",
      "Yossi Shvartzvald",
      "Hongjing Yang",
      "Weicheng Zang",
      "Sang-Mok Cha",
      "Dong-Jin Kim",
      "Seung-Lee Kim",
      "Chung-Uk Lee",
      "Dong-Joo Lee",
      "Yongseok Lee",
      "Byeong-Gon Park",
      "Richard W. Pogge"
    ],
    "abstract": "Traditional microlensing event vetting methods require highly trained human\nexperts, and the process is both complex and time-consuming. This reliance on\nmanual inspection often leads to inefficiencies and constrains the ability to\nscale for widespread exoplanet detection, ultimately hindering discovery rates.\nTo address the limits of traditional microlensing event vetting, we have\ndeveloped LensNet, a machine learning pipeline specifically designed to\ndistinguish legitimate microlensing events from false positives caused by\ninstrumental artifacts, such as pixel bleed trails and diffraction spikes. Our\nsystem operates in conjunction with a preliminary algorithm that detects\nincreasing trends in flux. These flagged instances are then passed to LensNet\nfor further classification, allowing for timely alerts and follow-up\nobservations. Tailored for the multi-observatory setup of the Korea\nMicrolensing Telescope Network (KMTNet) and trained on a rich dataset of\nmanually classified events, LensNet is optimized for early detection and\nwarning of microlensing occurrences, enabling astronomers to organize follow-up\nobservations promptly. The internal model of the pipeline employs a\nmulti-branch Recurrent Neural Network (RNN) architecture that evaluates\ntime-series flux data with contextual information, including sky background,\nthe full width at half maximum of the target star, flux errors, PSF quality\nflags, and air mass for each observation. We demonstrate a classification\naccuracy above 87.5%, and anticipate further improvements as we expand our\ntraining set and continue to refine the algorithm.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP",
      "astro-ph.GA",
      "cs.AI",
      "85-08",
      "J.2"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "23 pages, 13 figures, Accepted for publication in the The\n  Astronomical Journal",
    "pdf_url": "http://arxiv.org/pdf/2501.06293v1",
    "published_date": "2025-01-10 19:00:01 UTC",
    "updated_date": "2025-01-10 19:00:01 UTC"
  },
  {
    "arxiv_id": "2501.06286v1",
    "title": "Bactrainus: Optimizing Large Language Models for Multi-hop Complex Question Answering Tasks",
    "authors": [
      "Iman Barati",
      "Arash Ghafouri",
      "Behrouz Minaei-Bidgoli"
    ],
    "abstract": "In recent years, the use of large language models (LLMs) has significantly\nincreased, and these models have demonstrated remarkable performance in a\nvariety of general language tasks. However, the evaluation of their performance\nin domain-specific tasks, particularly those requiring deep natural language\nunderstanding, has received less attention. In this research, we evaluate the\nability of large language models in performing domain-specific tasks, focusing\non the multi-hop question answering (MHQA) problem using the HotpotQA dataset.\nThis task, due to its requirement for reasoning and combining information from\nmultiple textual sources, serves as a challenging benchmark for assessing the\nlanguage comprehension capabilities of these models. To tackle this problem, we\nhave designed a two-stage selector-reader architecture, where each stage\nutilizes an independent LLM. In addition, methods such as Chain of Thought\n(CoT) and question decomposition have been employed to investigate their impact\non improving the model's performance. The results of the study show that the\nintegration of large language models with these techniques can lead to up to a\n4% improvement in F1 score for finding answers, providing evidence of the\nmodels' ability to handle domain-specific tasks and their understanding of\ncomplex language.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06286v1",
    "published_date": "2025-01-10 18:44:06 UTC",
    "updated_date": "2025-01-10 18:44:06 UTC"
  },
  {
    "arxiv_id": "2501.06164v4",
    "title": "Model Alignment Search",
    "authors": [
      "Satchel Grant"
    ],
    "abstract": "When can we say that two neural systems are the same? The answer to this\nquestion is goal-dependent, and it is often addressed through correlative\nmethods such as Representational Similarity Analysis (RSA) and Centered Kernel\nAlignment (CKA). We find ourselves chiefly interested in the relationship\nbetween representations and behavior, asking ourselves how we can isolate\nspecific functional aspects of representational similarity to relate our\nmeasures to behavior -- avoiding cause vs. correlation pitfalls in the process.\nIn this work, we introduce Model Alignment Search (MAS), a method for causally\nexploring distributed representational similarity as it relates to behavior.\nThe method learns invertible linear transformations that find an aligned\nsubspace between two distributed networks' representations where functional\ninformation can be isolated and manipulated. We first show that the method can\nbe used to transfer values of specific causal variables -- such as the number\nof items in a counting task -- between networks with different training seeds\nand different architectures. We then explore open questions in number cognition\nby comparing different types of numeric representations in models trained on\nstructurally different tasks, we explore differences between MAS and\npreexisting functional similarity methods, and lastly, we introduce a\ncounterfactual latent auxiliary loss that helps shape functionally relevant\nalignments even in cases where we do not have causal access to one of the two\nmodels for training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06164v4",
    "published_date": "2025-01-10 18:39:29 UTC",
    "updated_date": "2025-04-24 02:13:50 UTC"
  },
  {
    "arxiv_id": "2501.06146v2",
    "title": "xLSTM-SENet: xLSTM for Single-Channel Speech Enhancement",
    "authors": [
      "Nikolai Lund Kühne",
      "Jan Østergaard",
      "Jesper Jensen",
      "Zheng-Hua Tan"
    ],
    "abstract": "While attention-based architectures, such as Conformers, excel in speech\nenhancement, they face challenges such as scalability with respect to input\nsequence length. In contrast, the recently proposed Extended Long Short-Term\nMemory (xLSTM) architecture offers linear scalability. However, xLSTM-based\nmodels remain unexplored for speech enhancement. This paper introduces\nxLSTM-SENet, the first xLSTM-based single-channel speech enhancement system. A\ncomparative analysis reveals that xLSTM-and notably, even LSTM-can match or\noutperform state-of-the-art Mamba- and Conformer-based systems across various\nmodel sizes in speech enhancement on the VoiceBank+Demand dataset. Through\nablation studies, we identify key architectural design choices such as\nexponential gating and bidirectionality contributing to its effectiveness. Our\nbest xLSTM-based model, xLSTM-SENet2, outperforms state-of-the-art Mamba- and\nConformer-based systems of similar complexity on the Voicebank+DEMAND dataset.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at INTERSPEECH 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06146v2",
    "published_date": "2025-01-10 18:10:06 UTC",
    "updated_date": "2025-05-20 08:28:21 UTC"
  },
  {
    "arxiv_id": "2501.06143v3",
    "title": "Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories",
    "authors": [
      "Gerd Kortemeyer",
      "Marina Babayeva",
      "Giulia Polverini",
      "Ralf Widenhorn",
      "Bor Gregorcic"
    ],
    "abstract": "We investigate the multilingual and multimodal performance of a large\nlanguage model-based artificial intelligence (AI) system, GPT-4o, using a\ndiverse set of physics concept inventories spanning multiple languages and\nsubject categories. The inventories, sourced from the PhysPort website, cover\nclassical physics topics such as mechanics, electromagnetism, optics, and\nthermodynamics, as well as relativity, quantum mechanics, astronomy,\nmathematics, and laboratory skills. Unlike previous text-only studies, we\nuploaded the inventories as images to reflect what a student would see on\npaper, thereby assessing the system's multimodal functionality. Our results\nindicate variation in performance across subjects, with laboratory skills\nstanding out as the weakest. We also observe differences across languages, with\nEnglish and European languages showing the strongest performance. Notably, the\nrelative difficulty of an inventory item is largely independent of the language\nof the survey. When comparing AI results to existing literature on student\nperformance, we find that the AI system outperforms average post-instruction\nundergraduate students in all subject categories except laboratory skills.\nFurthermore, the AI performs worse on items requiring visual interpretation of\nimages than on those that are purely text-based. While our exploratory findings\nshow GPT-4o's potential usefulness in physics education, they highlight the\ncritical need for instructors to foster students' ability to critically\nevaluate AI outputs, adapt curricula thoughtfully in response to AI\nadvancements, and address equity concerns associated with AI integration.",
    "categories": [
      "physics.ed-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ed-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06143v3",
    "published_date": "2025-01-10 18:08:07 UTC",
    "updated_date": "2025-05-12 12:07:32 UTC"
  },
  {
    "arxiv_id": "2501.06141v2",
    "title": "Emergent Symbol-like Number Variables in Artificial Neural Networks",
    "authors": [
      "Satchel Grant",
      "Noah D. Goodman",
      "James L. McClelland"
    ],
    "abstract": "What types of numeric representations emerge in neural systems? What would a\nsatisfying answer to this question look like? In this work, we interpret Neural\nNetwork (NN) solutions to sequence based counting tasks through a variety of\nlenses. We seek to understand how well we can understand NNs through the lens\nof interpretable Symbolic Algorithms (SAs), where SAs are defined by precise,\nabstract, mutable variables used to perform computations. We use GRUs, LSTMs,\nand Transformers trained using Next Token Prediction (NTP) on numeric tasks\nwhere the solutions to the tasks depend on numeric information only latent in\nthe task structure. We show through multiple causal and theoretical methods\nthat we can interpret NN's raw activity through the lens of simplified SAs when\nwe frame the neural activity in terms of interpretable subspaces rather than\nindividual neurons. Depending on the analysis, however, these interpretations\ncan be graded, existing on a continuum, highlighting the philosophical question\nof what it means to \"interpret\" neural activity, and motivating us to introduce\nAlignment Functions to add flexibility to the existing Distributed Alignment\nSearch (DAS) method. Through our specific analyses we show the importance of\ncausal interventions for NN interpretability; we show that recurrent models\ndevelop graded, symbol-like number variables within their neural activity; we\nintroduce a generalization of DAS to frame NN activity in terms of linear\nfunctions of interpretable variables; and we show that Transformers must use\nanti-Markovian solutions -- solutions that avoid using cumulative, Markovian\nhidden states -- in the absence of sufficient attention layers. We use our\nresults to encourage interpreting NNs at the level of neural subspaces through\nthe lens of SAs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06141v2",
    "published_date": "2025-01-10 18:03:46 UTC",
    "updated_date": "2025-04-24 02:48:10 UTC"
  },
  {
    "arxiv_id": "2501.06137v1",
    "title": "Supervision policies can shape long-term risk management in general-purpose AI models",
    "authors": [
      "Manuel Cebrian",
      "Emilia Gomez",
      "David Fernandez Llorca"
    ],
    "abstract": "The rapid proliferation and deployment of General-Purpose AI (GPAI) models,\nincluding large language models (LLMs), present unprecedented challenges for AI\nsupervisory entities. We hypothesize that these entities will need to navigate\nan emergent ecosystem of risk and incident reporting, likely to exceed their\nsupervision capacity. To investigate this, we develop a simulation framework\nparameterized by features extracted from the diverse landscape of risk,\nincident, or hazard reporting ecosystems, including community-driven platforms,\ncrowdsourcing initiatives, and expert assessments. We evaluate four supervision\npolicies: non-prioritized (first-come, first-served), random selection,\npriority-based (addressing the highest-priority risks first), and\ndiversity-prioritized (balancing high-priority risks with comprehensive\ncoverage across risk types). Our results indicate that while priority-based and\ndiversity-prioritized policies are more effective at mitigating high-impact\nrisks, particularly those identified by experts, they may inadvertently neglect\nsystemic issues reported by the broader community. This oversight can create\nfeedback loops that amplify certain types of reporting while discouraging\nothers, leading to a skewed perception of the overall risk landscape. We\nvalidate our simulation results with several real-world datasets, including one\nwith over a million ChatGPT interactions, of which more than 150,000\nconversations were identified as risky. This validation underscores the complex\ntrade-offs inherent in AI risk supervision and highlights how the choice of\nrisk management policies can shape the future landscape of AI risks across\ndiverse GPAI models used in society.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06137v1",
    "published_date": "2025-01-10 17:52:34 UTC",
    "updated_date": "2025-01-10 17:52:34 UTC"
  },
  {
    "arxiv_id": "2501.06132v1",
    "title": "CoDriveVLM: VLM-Enhanced Urban Cooperative Dispatching and Motion Planning for Future Autonomous Mobility on Demand Systems",
    "authors": [
      "Haichao Liu",
      "Ruoyu Yao",
      "Wenru Liu",
      "Zhenmin Huang",
      "Shaojie Shen",
      "Jun Ma"
    ],
    "abstract": "The increasing demand for flexible and efficient urban transportation\nsolutions has spotlighted the limitations of traditional Demand Responsive\nTransport (DRT) systems, particularly in accommodating diverse passenger needs\nand dynamic urban environments. Autonomous Mobility-on-Demand (AMoD) systems\nhave emerged as a promising alternative, leveraging connected and autonomous\nvehicles (CAVs) to provide responsive and adaptable services. However, existing\nmethods primarily focus on either vehicle scheduling or path planning, which\noften simplify complex urban layouts and neglect the necessity for simultaneous\ncoordination and mutual avoidance among CAVs. This oversimplification poses\nsignificant challenges to the deployment of AMoD systems in real-world\nscenarios. To address these gaps, we propose CoDriveVLM, a novel framework that\nintegrates high-fidelity simultaneous dispatching and cooperative motion\nplanning for future AMoD systems. Our method harnesses Vision-Language Models\n(VLMs) to enhance multi-modality information processing, and this enables\ncomprehensive dispatching and collision risk evaluation. The VLM-enhanced CAV\ndispatching coordinator is introduced to effectively manage complex and\nunforeseen AMoD conditions, thus supporting efficient scheduling\ndecision-making. Furthermore, we propose a scalable decentralized cooperative\nmotion planning method via consensus alternating direction method of\nmultipliers (ADMM) focusing on collision risk evaluation and decentralized\ntrajectory optimization. Simulation results demonstrate the feasibility and\nrobustness of CoDriveVLM in various traffic conditions, showcasing its\npotential to significantly improve the fidelity and effectiveness of AMoD\nsystems in future urban transportation networks. The code is available at\nhttps://github.com/henryhcliu/CoDriveVLM.git.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06132v1",
    "published_date": "2025-01-10 17:44:57 UTC",
    "updated_date": "2025-01-10 17:44:57 UTC"
  },
  {
    "arxiv_id": "2501.06129v1",
    "title": "Contextual ASR Error Handling with LLMs Augmentation for Goal-Oriented Conversational AI",
    "authors": [
      "Yuya Asano",
      "Sabit Hassan",
      "Paras Sharma",
      "Anthony Sicilia",
      "Katherine Atwell",
      "Diane Litman",
      "Malihe Alikhani"
    ],
    "abstract": "General-purpose automatic speech recognition (ASR) systems do not always\nperform well in goal-oriented dialogue. Existing ASR correction methods rely on\nprior user data or named entities. We extend correction to tasks that have no\nprior user data and exhibit linguistic flexibility such as lexical and\nsyntactic variations. We propose a novel context augmentation with a large\nlanguage model and a ranking strategy that incorporates contextual information\nfrom the dialogue states of a goal-oriented conversational AI and its tasks.\nOur method ranks (1) n-best ASR hypotheses by their lexical and semantic\nsimilarity with context and (2) context by phonetic correspondence with ASR\nhypotheses. Evaluated in home improvement and cooking domains with real-world\nusers, our method improves recall and F1 of correction by 34% and 16%,\nrespectively, while maintaining precision and false positive rate. Users rated\n.8-1 point (out of 5) higher when our correction method worked properly, with\nno decrease due to false positives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to COLING 2025 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2501.06129v1",
    "published_date": "2025-01-10 17:35:06 UTC",
    "updated_date": "2025-01-10 17:35:06 UTC"
  },
  {
    "arxiv_id": "2501.06283v1",
    "title": "Dafny as Verification-Aware Intermediate Language for Code Generation",
    "authors": [
      "Yue Chen Li",
      "Stefan Zetzsche",
      "Siva Somayyajula"
    ],
    "abstract": "Using large language models (LLMs) to generate source code from natural\nlanguage prompts is a popular and promising idea with a wide range of\napplications. One of its limitations is that the generated code can be faulty\nat times, often in a subtle way, despite being presented to the user as\ncorrect. In this paper, we explore ways in which formal methods can assist with\nincreasing the quality of code generated by an LLM. Instead of emitting code in\na target language directly, we propose that the user guides the LLM to first\ngenerate an opaque intermediate representation, in the verification-aware\nlanguage Dafny, that can be automatically validated for correctness against\nagreed on specifications. The correct Dafny program is then compiled to the\ntarget language and returned to the user. All user-system interactions\nthroughout the procedure occur via natural language; Dafny code is never\nexposed. We describe our current prototype and report on its performance on the\nHumanEval Python code generation benchmarks.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LO",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06283v1",
    "published_date": "2025-01-10 17:23:14 UTC",
    "updated_date": "2025-01-10 17:23:14 UTC"
  },
  {
    "arxiv_id": "2501.06117v2",
    "title": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding",
    "authors": [
      "Fabian David Schmidt",
      "Ivan Vulić",
      "Goran Glavaš",
      "David Ifeoluwa Adelani"
    ],
    "abstract": "Spoken language understanding (SLU) is indispensable for half of all living\nlanguages that lack a formal writing system, since these languages cannot pair\nautomatic speech recognition (ASR) with language models to benefit from\nlanguage technology. Even if low-resource languages possess a writing system,\nASR for these languages remains unreliable due to limited bimodal speech and\ntext training data. Better SLU can strengthen the robustness of massively\nmultilingual ASR by levering language semantics to disambiguate utterances via\ncontext or exploiting semantic similarities across languages. However, the\nevaluation of multilingual SLU remains limited to shallow tasks such as intent\nclassification or language identification. To address this, we present\nFleurs-SLU, a multilingual SLU benchmark that encompasses (i) 692 hours of\nspeech for topical utterance classification in 102 languages and (ii)\nmultiple-choice question answering through listening comprehension spanning 944\nhours of speech across 92 languages. We extensively evaluate both end-to-end\nspeech classification models and cascaded systems that combine speech-to-text\ntranscription with subsequent classification by large language models on\nFleurs-SLU. Our results show that cascaded systems exhibit greater robustness\nin multilingual SLU tasks, though speech encoders can achieve competitive\nperformance in topical speech classification when appropriately pre-trained. We\nfurther find a strong correlation between robust multilingual ASR, effective\nspeech-to-text translation, and strong multilingual SLU, highlighting the\nmutual benefits between acoustic and semantic speech representations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06117v2",
    "published_date": "2025-01-10 17:15:38 UTC",
    "updated_date": "2025-02-19 06:23:54 UTC"
  },
  {
    "arxiv_id": "2501.06099v1",
    "title": "Explaining Deep Learning-based Anomaly Detection in Energy Consumption Data by Focusing on Contextually Relevant Data",
    "authors": [
      "Mohammad Noorchenarboo",
      "Katarina Grolinger"
    ],
    "abstract": "Detecting anomalies in energy consumption data is crucial for identifying\nenergy waste, equipment malfunction, and overall, for ensuring efficient energy\nmanagement. Machine learning, and specifically deep learning approaches, have\nbeen greatly successful in anomaly detection; however, they are black-box\napproaches that do not provide transparency or explanations. SHAP and its\nvariants have been proposed to explain these models, but they suffer from high\ncomputational complexity (SHAP) or instability and inconsistency (e.g., Kernel\nSHAP). To address these challenges, this paper proposes an explainability\napproach for anomalies in energy consumption data that focuses on\ncontext-relevant information. The proposed approach leverages existing\nexplainability techniques, focusing on SHAP variants, together with global\nfeature importance and weighted cosine similarity to select background dataset\nbased on the context of each anomaly point. By focusing on the context and most\nrelevant features, this approach mitigates the instability of explainability\nalgorithms. Experimental results across 10 different machine learning models,\nfive datasets, and five XAI techniques, demonstrate that our method reduces the\nvariability of explanations providing consistent explanations. Statistical\nanalyses confirm the robustness of our approach, showing an average reduction\nin variability of approximately 38% across multiple datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06099v1",
    "published_date": "2025-01-10 16:53:48 UTC",
    "updated_date": "2025-01-10 16:53:48 UTC"
  },
  {
    "arxiv_id": "2501.06089v2",
    "title": "Towards Developing Socially Compliant Automated Vehicles: Advances, Expert Insights, and A Conceptual Framework",
    "authors": [
      "Yongqi Dong",
      "Bart van Arem",
      "Haneen Farah"
    ],
    "abstract": "Automated Vehicles (AVs) hold promise for revolutionizing transportation by\nimproving road safety, traffic efficiency, and overall mobility. Despite the\nsteady advancement in high-level AVs in recent years, the transition to full\nautomation entails a period of mixed traffic, where AVs of varying automation\nlevels coexist with human-driven vehicles (HDVs). Making AVs socially compliant\nand understood by human drivers is expected to improve the safety and\nefficiency of mixed traffic. Thus, ensuring AVs' compatibility with HDVs and\nsocial acceptance is crucial for their successful and seamless integration into\nmixed traffic. However, research in this critical area of developing Socially\nCompliant AVs (SCAVs) remains sparse. This study carries out the first\ncomprehensive scoping review to assess the current state of the art in\ndeveloping SCAVs, identifying key concepts, methodological approaches, and\nresearch gaps. An informal expert interview was also conducted to discuss the\nliterature review results and identify critical research gaps and expectations\ntowards SCAVs. Based on the scoping review and expert interview input, a\nconceptual framework is proposed for the development of SCAVs. The conceptual\nframework is evaluated using an online survey targeting researchers,\ntechnicians, policymakers, and other relevant professionals worldwide. The\nsurvey results provide valuable validation and insights, affirming the\nsignificance of the proposed conceptual framework in tackling the challenges of\nintegrating AVs into mixed-traffic environments. Additionally, future research\nperspectives and suggestions are discussed, contributing to the research and\ndevelopment agenda of SCAVs.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "58 pages, 13 figures, accepted by the Journal of Communications in\n  Transportation Research",
    "pdf_url": "http://arxiv.org/pdf/2501.06089v2",
    "published_date": "2025-01-10 16:39:01 UTC",
    "updated_date": "2025-04-14 04:58:27 UTC"
  },
  {
    "arxiv_id": "2501.06086v1",
    "title": "All AI Models are Wrong, but Some are Optimal",
    "authors": [
      "Akhil S Anand",
      "Shambhuraj Sawant",
      "Dirk Reinhardt",
      "Sebastien Gros"
    ],
    "abstract": "AI models that predict the future behavior of a system (a.k.a. predictive AI\nmodels) are central to intelligent decision-making. However, decision-making\nusing predictive AI models often results in suboptimal performance. This is\nprimarily because AI models are typically constructed to best fit the data, and\nhence to predict the most likely future rather than to enable high-performance\ndecision-making. The hope that such prediction enables high-performance\ndecisions is neither guaranteed in theory nor established in practice. In fact,\nthere is increasing empirical evidence that predictive models must be tailored\nto decision-making objectives for performance. In this paper, we establish\nformal (necessary and sufficient) conditions that a predictive model (AI-based\nor not) must satisfy for a decision-making policy established using that model\nto be optimal. We then discuss their implications for building predictive AI\nmodels for sequential decision-making.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06086v1",
    "published_date": "2025-01-10 16:34:19 UTC",
    "updated_date": "2025-01-10 16:34:19 UTC"
  },
  {
    "arxiv_id": "2501.06080v1",
    "title": "Scale-up Unlearnable Examples Learning with High-Performance Computing",
    "authors": [
      "Yanfan Zhu",
      "Issac Lyngaas",
      "Murali Gopalakrishnan Meena",
      "Mary Ellen I. Koran",
      "Bradley Malin",
      "Daniel Moyer",
      "Shunxing Bao",
      "Anuj Kapadia",
      "Xiao Wang",
      "Bennett Landman",
      "Yuankai Huo"
    ],
    "abstract": "Recent advancements in AI models are structured to retain user interactions,\nwhich could inadvertently include sensitive healthcare data. In the healthcare\nfield, particularly when radiologists use AI-driven diagnostic tools hosted on\nonline platforms, there is a risk that medical imaging data may be repurposed\nfor future AI training without explicit consent, spotlighting critical privacy\nand intellectual property concerns around healthcare data usage. Addressing\nthese privacy challenges, a novel approach known as Unlearnable Examples (UEs)\nhas been introduced, aiming to make data unlearnable to deep learning models. A\nprominent method within this area, called Unlearnable Clustering (UC), has\nshown improved UE performance with larger batch sizes but was previously\nlimited by computational resources. To push the boundaries of UE performance\nwith theoretically unlimited resources, we scaled up UC learning across various\ndatasets using Distributed Data Parallel (DDP) training on the Summit\nsupercomputer. Our goal was to examine UE efficacy at high-performance\ncomputing (HPC) levels to prevent unauthorized learning and enhance data\nsecurity, particularly exploring the impact of batch size on UE's\nunlearnability. Utilizing the robust computational capabilities of the Summit,\nextensive experiments were conducted on diverse datasets such as Pets,\nMedMNist, Flowers, and Flowers102. Our findings reveal that both overly large\nand overly small batch sizes can lead to performance instability and affect\naccuracy. However, the relationship between batch size and unlearnability\nvaried across datasets, highlighting the necessity for tailored batch size\nstrategies to achieve optimal data protection. Our results underscore the\ncritical role of selecting appropriate batch sizes based on the specific\ncharacteristics of each dataset to prevent learning and ensure data security in\ndeep learning applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06080v1",
    "published_date": "2025-01-10 16:15:23 UTC",
    "updated_date": "2025-01-10 16:15:23 UTC"
  },
  {
    "arxiv_id": "2501.06078v1",
    "title": "Explaining k-Nearest Neighbors: Abductive and Counterfactual Explanations",
    "authors": [
      "Pablo Barceló",
      "Alexander Kozachinskiy",
      "Miguel Romero Orth",
      "Bernardo Subercaseaux",
      "José Verschae"
    ],
    "abstract": "Despite the wide use of $k$-Nearest Neighbors as classification models, their\nexplainability properties remain poorly understood from a theoretical\nperspective. While nearest neighbors classifiers offer interpretability from a\n\"data perspective\", in which the classification of an input vector $\\bar{x}$ is\nexplained by identifying the vectors $\\bar{v}_1, \\ldots, \\bar{v}_k$ in the\ntraining set that determine the classification of $\\bar{x}$, we argue that such\nexplanations can be impractical in high-dimensional applications, where each\nvector has hundreds or thousands of features and it is not clear what their\nrelative importance is. Hence, we focus on understanding nearest neighbor\nclassifications through a \"feature perspective\", in which the goal is to\nidentify how the values of the features in $\\bar{x}$ affect its classification.\nConcretely, we study abductive explanations such as \"minimum sufficient\nreasons\", which correspond to sets of features in $\\bar{x}$ that are enough to\nguarantee its classification, and \"counterfactual explanations\" based on the\nminimum distance feature changes one would have to perform in $\\bar{x}$ to\nchange its classification. We present a detailed landscape of positive and\nnegative complexity results for counterfactual and abductive explanations,\ndistinguishing between discrete and continuous feature spaces, and considering\nthe impact of the choice of distance function involved. Finally, we show that\ndespite some negative complexity results, Integer Quadratic Programming and SAT\nsolving allow for computing explanations in practice.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06078v1",
    "published_date": "2025-01-10 16:14:35 UTC",
    "updated_date": "2025-01-10 16:14:35 UTC"
  },
  {
    "arxiv_id": "2501.06066v3",
    "title": "Distilling Calibration via Conformalized Credal Inference",
    "authors": [
      "Jiayi Huang",
      "Sangwoo Park",
      "Nicola Paoletti",
      "Osvaldo Simeone"
    ],
    "abstract": "Deploying artificial intelligence (AI) models on edge devices involves a\ndelicate balance between meeting stringent complexity constraints, such as\nlimited memory and energy resources, and ensuring reliable performance in\nsensitive decision-making tasks. One way to enhance reliability is through\nuncertainty quantification via Bayesian inference. This approach, however,\ntypically necessitates maintaining and running multiple models in an ensemble,\nwhich may exceed the computational limits of edge devices. This paper\nintroduces a low-complexity methodology to address this challenge by distilling\ncalibration information from a more complex model. In an offline phase,\npredictive probabilities generated by a high-complexity cloud-based model are\nleveraged to determine a threshold based on the typical divergence between the\ncloud and edge models. At run time, this threshold is used to construct credal\nsets -- ranges of predictive probabilities that are guaranteed, with a\nuser-selected confidence level, to include the predictions of the cloud model.\nThe credal sets are obtained through thresholding of a divergence measure in\nthe simplex of predictive probabilities. Experiments on visual and language\ntasks demonstrate that the proposed approach, termed Conformalized Distillation\nfor Credal Inference (CD-CI), significantly improves calibration performance\ncompared to low-complexity Bayesian methods, such as Laplace approximation,\nmaking it a practical and efficient solution for edge AI deployments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2501.06066v3",
    "published_date": "2025-01-10 15:57:23 UTC",
    "updated_date": "2025-05-01 13:04:11 UTC"
  },
  {
    "arxiv_id": "2501.06282v1",
    "title": "MinMo: A Multimodal Large Language Model for Seamless Voice Interaction",
    "authors": [
      "Qian Chen",
      "Yafeng Chen",
      "Yanni Chen",
      "Mengzhe Chen",
      "Yingda Chen",
      "Chong Deng",
      "Zhihao Du",
      "Ruize Gao",
      "Changfeng Gao",
      "Zhifu Gao",
      "Yabin Li",
      "Xiang Lv",
      "Jiaqing Liu",
      "Haoneng Luo",
      "Bin Ma",
      "Chongjia Ni",
      "Xian Shi",
      "Jialong Tang",
      "Hui Wang",
      "Hao Wang",
      "Wen Wang",
      "Yuxuan Wang",
      "Yunlan Xu",
      "Fan Yu",
      "Zhijie Yan",
      "Yexin Yang",
      "Baosong Yang",
      "Xian Yang",
      "Guanrou Yang",
      "Tianyu Zhao",
      "Qinglin Zhang",
      "Shiliang Zhang",
      "Nan Zhao",
      "Pei Zhang",
      "Chong Zhang",
      "Jinren Zhou"
    ],
    "abstract": "Recent advancements in large language models (LLMs) and multimodal\nspeech-text models have laid the groundwork for seamless voice interactions,\nenabling real-time, natural, and human-like conversations. Previous models for\nvoice interactions are categorized as native and aligned. Native models\nintegrate speech and text processing in one framework but struggle with issues\nlike differing sequence lengths and insufficient pre-training. Aligned models\nmaintain text LLM capabilities but are often limited by small datasets and a\nnarrow focus on speech tasks. In this work, we introduce MinMo, a Multimodal\nLarge Language Model with approximately 8B parameters for seamless voice\ninteraction. We address the main limitations of prior aligned multimodal\nmodels. We train MinMo through multiple stages of speech-to-text alignment,\ntext-to-speech alignment, speech-to-speech alignment, and duplex interaction\nalignment, on 1.4 million hours of diverse speech data and a broad range of\nspeech tasks. After the multi-stage training, MinMo achieves state-of-the-art\nperformance across various benchmarks for voice comprehension and generation\nwhile maintaining the capabilities of text LLMs, and also facilitates\nfull-duplex conversation, that is, simultaneous two-way communication between\nthe user and the system. Moreover, we propose a novel and simple voice decoder\nthat outperforms prior models in voice generation. The enhanced\ninstruction-following capabilities of MinMo supports controlling speech\ngeneration based on user instructions, with various nuances including emotions,\ndialects, and speaking rates, and mimicking specific voices. For MinMo, the\nspeech-to-text latency is approximately 100ms, full-duplex latency is\napproximately 600ms in theory and 800ms in practice. The MinMo project web page\nis https://funaudiollm.github.io/minmo, and the code and models will be\nreleased soon.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. Authors are listed in alphabetical order by family\n  name",
    "pdf_url": "http://arxiv.org/pdf/2501.06282v1",
    "published_date": "2025-01-10 15:55:27 UTC",
    "updated_date": "2025-01-10 15:55:27 UTC"
  },
  {
    "arxiv_id": "2501.06051v1",
    "title": "Benchmarking Rotary Position Embeddings for Automatic Speech Recognition",
    "authors": [
      "Shucong Zhang",
      "Titouan Parcollet",
      "Rogier van Dalen",
      "Sourav Bhattacharya"
    ],
    "abstract": "Rotary Position Embedding (RoPE) encodes relative and absolute positional\ninformation in Transformer-based models through rotation matrices applied to\ninput vectors within sequences. While RoPE has demonstrated superior\nperformance compared to other positional embedding technologies in natural\nlanguage processing tasks, its effectiveness in speech processing applications\nremains understudied. In this work, we conduct a comprehensive evaluation of\nRoPE across diverse automatic speech recognition (ASR) tasks. Our experimental\nresults demonstrate that for ASR tasks, RoPE consistently achieves lower error\nrates compared to the currently widely used relative positional embedding. To\nfacilitate further research, we release the implementation and all experimental\nrecipes through the SpeechBrain toolkit.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06051v1",
    "published_date": "2025-01-10 15:30:46 UTC",
    "updated_date": "2025-01-10 15:30:46 UTC"
  },
  {
    "arxiv_id": "2501.06039v1",
    "title": "AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery",
    "authors": [
      "Johann Wenckstern",
      "Eeshaan Jain",
      "Kiril Vasilev",
      "Matteo Pariset",
      "Andreas Wicki",
      "Gabriele Gut",
      "Charlotte Bunne"
    ],
    "abstract": "Spatial proteomics technologies have transformed our understanding of complex\ntissue architectures by enabling simultaneous analysis of multiple molecular\nmarkers and their spatial organization. The high dimensionality of these data,\nvarying marker combinations across experiments and heterogeneous study designs\npose unique challenges for computational analysis. Here, we present Virtual\nTissues (VirTues), a foundation model framework for biological tissues that\noperates across the molecular, cellular and tissue scale. VirTues introduces\ninnovations in transformer architecture design, including a novel tokenization\nscheme that captures both spatial and marker dimensions, and attention\nmechanisms that scale to high-dimensional multiplex data while maintaining\ninterpretability. Trained on diverse cancer and non-cancer tissue datasets,\nVirTues demonstrates strong generalization capabilities without task-specific\nfine-tuning, enabling cross-study analysis and novel marker integration. As a\ngeneralist model, VirTues outperforms existing approaches across clinical\ndiagnostics, biological discovery and patient case retrieval tasks, while\nproviding insights into tissue function and disease mechanisms.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "23 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06039v1",
    "published_date": "2025-01-10 15:17:27 UTC",
    "updated_date": "2025-01-10 15:17:27 UTC"
  },
  {
    "arxiv_id": "2501.06025v1",
    "title": "How to Tune a Multilingual Encoder Model for Germanic Languages: A Study of PEFT, Full Fine-Tuning, and Language Adapters",
    "authors": [
      "Romina Oji",
      "Jenny Kunz"
    ],
    "abstract": "This paper investigates the optimal use of the multilingual encoder model\nmDeBERTa for tasks in three Germanic languages -- German, Swedish, and\nIcelandic -- representing varying levels of presence and likely data quality in\nmDeBERTas pre-training data. We compare full fine-tuning with the\nparameter-efficient fine-tuning (PEFT) methods LoRA and Pfeiffer bottleneck\nadapters, finding that PEFT is more effective for the higher-resource language,\nGerman. However, results for Swedish and Icelandic are less consistent. We also\nobserve differences between tasks: While PEFT tends to work better for question\nanswering, full fine-tuning is preferable for named entity recognition.\nInspired by previous research on modular approaches that combine task and\nlanguage adapters, we evaluate the impact of adding PEFT modules trained on\nunstructured text, finding that this approach is not beneficial.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NoDaLiDa Baltic-HLT 2025 Conference",
    "pdf_url": "http://arxiv.org/pdf/2501.06025v1",
    "published_date": "2025-01-10 15:01:51 UTC",
    "updated_date": "2025-01-10 15:01:51 UTC"
  },
  {
    "arxiv_id": "2501.06019v3",
    "title": "BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response",
    "authors": [
      "Hongruixuan Chen",
      "Jian Song",
      "Olivier Dietrich",
      "Clifford Broni-Bediako",
      "Weihao Xuan",
      "Junjue Wang",
      "Xinlei Shao",
      "Yimin Wei",
      "Junshi Xia",
      "Cuiling Lan",
      "Konrad Schindler",
      "Naoto Yokoya"
    ],
    "abstract": "Disaster events occur around the world and cause significant damage to human\nlife and property. Earth observation (EO) data enables rapid and comprehensive\nbuilding damage assessment (BDA), an essential capability in the aftermath of a\ndisaster to reduce human casualties and to inform disaster relief efforts.\nRecent research focuses on the development of AI models to achieve accurate\nmapping of unseen disaster events, mostly using optical EO data. However,\nsolutions based on optical data are limited to clear skies and daylight hours,\npreventing a prompt response to disasters. Integrating multimodal (MM) EO data,\nparticularly the combination of optical and SAR imagery, makes it possible to\nprovide all-weather, day-and-night disaster responses. Despite this potential,\nthe development of robust multimodal AI models has been constrained by the lack\nof suitable benchmark datasets. In this paper, we present a BDA dataset using\nveRy-hIGH-resoluTion optical and SAR imagery (BRIGHT) to support AI-based\nall-weather disaster response. To the best of our knowledge, BRIGHT is the\nfirst open-access, globally distributed, event-diverse MM dataset specifically\ncurated to support AI-based disaster response. It covers five types of natural\ndisasters and two types of man-made disasters across 14 regions worldwide, with\na particular focus on developing countries where external assistance is most\nneeded. The optical and SAR imagery in BRIGHT, with a spatial resolution\nbetween 0.3-1 meters, provides detailed representations of individual\nbuildings, making it ideal for precise BDA. In our experiments, we have tested\nseven advanced AI models trained with our BRIGHT to validate the\ntransferability and robustness. The dataset and code are available at\nhttps://github.com/ChenHongruixuan/BRIGHT. BRIGHT also serves as the official\ndataset for the 2025 IEEE GRSS Data Fusion Contest.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06019v3",
    "published_date": "2025-01-10 14:57:18 UTC",
    "updated_date": "2025-04-18 12:07:58 UTC"
  },
  {
    "arxiv_id": "2501.05989v1",
    "title": "Addressing speaker gender bias in large scale speech translation systems",
    "authors": [
      "Shubham Bansal",
      "Vikas Joshi",
      "Harveen Chadha",
      "Rupeshkumar Mehta",
      "Jinyu Li"
    ],
    "abstract": "This study addresses the issue of speaker gender bias in Speech Translation\n(ST) systems, which can lead to offensive and inaccurate translations. The\nmasculine bias often found in large-scale ST systems is typically perpetuated\nthrough training data derived from Machine Translation (MT) systems. Our\napproach involves two key steps. First, we employ Large Language Models (LLMs)\nto rectify translations based on the speaker's gender in a cost-effective\nmanner. Second, we fine-tune the ST model with the corrected data, enabling the\nmodel to generate gender-specific translations directly from audio cues,\nwithout the need for explicit gender input. Additionally, we propose a\nthree-mode fine-tuned model for scenarios where the speaker's gender is either\npredefined or should not be inferred from speech cues. We demonstrate a 70%\nimprovement in translations for female speakers compared to our baseline and\nother large-scale ST systems, such as Seamless M4T and Canary, on the MuST-SHE\ntest set.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05989v1",
    "published_date": "2025-01-10 14:20:46 UTC",
    "updated_date": "2025-01-10 14:20:46 UTC"
  },
  {
    "arxiv_id": "2501.05962v1",
    "title": "Effective faking of verbal deception detection with target-aligned adversarial attacks",
    "authors": [
      "Bennett Kleinberg",
      "Riccardo Loconte",
      "Bruno Verschuere"
    ],
    "abstract": "Background: Deception detection through analysing language is a promising\navenue using both human judgments and automated machine learning judgments. For\nboth forms of credibility assessment, automated adversarial attacks that\nrewrite deceptive statements to appear truthful pose a serious threat. Methods:\nWe used a dataset of 243 truthful and 262 fabricated autobiographical stories\nin a deception detection task for humans and machine learning models. A large\nlanguage model was tasked to rewrite deceptive statements so that they appear\ntruthful. In Study 1, humans who made a deception judgment or used the\ndetailedness heuristic and two machine learning models (a fine-tuned language\nmodel and a simple n-gram model) judged original or adversarial modifications\nof deceptive statements. In Study 2, we manipulated the target alignment of the\nmodifications, i.e. tailoring the attack to whether the statements would be\nassessed by humans or computer models. Results: When adversarial modifications\nwere aligned with their target, human (d=-0.07 and d=-0.04) and machine\njudgments (51% accuracy) dropped to the chance level. When the attack was not\naligned with the target, both human heuristics judgments (d=0.30 and d=0.36)\nand machine learning predictions (63-78%) were significantly better than\nchance. Conclusions: Easily accessible language models can effectively help\nanyone fake deception detection efforts both by humans and machine learning\nmodels. Robustness against adversarial modifications for humans and machines\ndepends on that target alignment. We close with suggestions on advancing\ndeception research with adversarial attack designs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2501.05962v1",
    "published_date": "2025-01-10 13:42:40 UTC",
    "updated_date": "2025-01-10 13:42:40 UTC"
  },
  {
    "arxiv_id": "2501.05932v1",
    "title": "DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information",
    "authors": [
      "Yongfan Lai",
      "Jiabo Chen",
      "Deyun Zhang",
      "Yue Wang",
      "Shijia Geng",
      "Hongyan Li",
      "Shenda Hong"
    ],
    "abstract": "Heart disease remains a significant threat to human health. As a non-invasive\ndiagnostic tool, the electrocardiogram (ECG) is one of the most widely used\nmethods for cardiac screening. However, the scarcity of high-quality ECG data,\ndriven by privacy concerns and limited medical resources, creates a pressing\nneed for effective ECG signal generation. Existing approaches for generating\nECG signals typically rely on small training datasets, lack comprehensive\nevaluation frameworks, and overlook potential applications beyond data\naugmentation. To address these challenges, we propose DiffuSETS, a novel\nframework capable of generating ECG signals with high semantic alignment and\nfidelity. DiffuSETS accepts various modalities of clinical text reports and\npatient-specific information as inputs, enabling the creation of clinically\nmeaningful ECG signals. Additionally, to address the lack of standardized\nevaluation in ECG generation, we introduce a comprehensive benchmarking\nmethodology to assess the effectiveness of generative models in this domain.\nOur model achieve excellent results in tests, proving its superiority in the\ntask of ECG generation. Furthermore, we showcase its potential to mitigate data\nscarcity while exploring novel applications in cardiology education and medical\nknowledge discovery, highlighting the broader impact of our work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05932v1",
    "published_date": "2025-01-10 12:55:34 UTC",
    "updated_date": "2025-01-10 12:55:34 UTC"
  },
  {
    "arxiv_id": "2501.05928v1",
    "title": "Towards Backdoor Stealthiness in Model Parameter Space",
    "authors": [
      "Xiaoyun Xu",
      "Zhuoran Liu",
      "Stefanos Koffas",
      "Stjepan Picek"
    ],
    "abstract": "Recent research on backdoor stealthiness focuses mainly on indistinguishable\ntriggers in input space and inseparable backdoor representations in feature\nspace, aiming to circumvent backdoor defenses that examine these respective\nspaces. However, existing backdoor attacks are typically designed to resist a\nspecific type of backdoor defense without considering the diverse range of\ndefense mechanisms. Based on this observation, we pose a natural question: Are\ncurrent backdoor attacks truly a real-world threat when facing diverse\npractical defenses?\n  To answer this question, we examine 12 common backdoor attacks that focus on\ninput-space or feature-space stealthiness and 17 diverse representative\ndefenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks\ndesigned to be stealthy in input and feature spaces can be mitigated by\nexamining backdoored models in parameter space. To investigate the underlying\ncauses behind this common vulnerability, we study the characteristics of\nbackdoor attacks in the parameter space. Notably, we find that input- and\nfeature-space attacks introduce prominent backdoor-related neurons in parameter\nspace, which are not thoroughly considered by current backdoor attacks. Taking\ncomprehensive stealthiness into account, we propose a novel supply-chain attack\ncalled Grond. Grond limits the parameter changes by a simple yet effective\nmodule, Adversarial Backdoor Injection (ABI), which adaptively increases the\nparameter-space stealthiness during the backdoor injection. Extensive\nexperiments demonstrate that Grond outperforms all 12 backdoor attacks against\nstate-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset\nof ImageNet. In addition, we show that ABI consistently improves the\neffectiveness of common backdoor attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05928v1",
    "published_date": "2025-01-10 12:49:12 UTC",
    "updated_date": "2025-01-10 12:49:12 UTC"
  },
  {
    "arxiv_id": "2501.05921v1",
    "title": "The New Anticipatory Governance Culture for Innovation: Regulatory Foresight, Regulatory Experimentation and Regulatory Learning",
    "authors": [
      "Deirdre Ahern"
    ],
    "abstract": "With the rapid pace of technological innovation, traditional methods of\npolicy formation and legislating are becoming conspicuously anachronistic. The\nneed for regulatory choices to be made to counter the deadening effect of\nregulatory lag is more important to developing markets and fostering growth\nthan achieving one off regulatory perfection. This article advances scholarship\non innovation policy and the regulation of technological innovation in the\nEuropean Union. It does so by considering what building an agile yet robust\nanticipatory governance regulatory culture involves. It systematically\nexcavates a variety of tools and elements that are being put into use in\ninventive ways and argues that these need to be more cohesively and\nsystemically integrated into the regulatory toolbox. Approaches covered include\nstrategic foresight, the critical embrace of iterative policy development and\nregulatory learning in the face of uncertainty and the embrace of bottom up\napproaches to cocreation of policy such as Policy Labs and the testing and\nregulatory learning through pilot regulation and experimentation. The growing\nuse of regulatory sandboxes as an EU policy tool to boost innovation and\nnavigate regulatory complexity as seen in the EU AI Act is also probed",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05921v1",
    "published_date": "2025-01-10 12:26:38 UTC",
    "updated_date": "2025-01-10 12:26:38 UTC"
  },
  {
    "arxiv_id": "2502.03469v1",
    "title": "A Capability Approach to AI Ethics",
    "authors": [
      "Emanuele Ratti",
      "Mark Graves"
    ],
    "abstract": "We propose a conceptualization and implementation of AI ethics via the\ncapability approach. We aim to show that conceptualizing AI ethics through the\ncapability approach has two main advantages for AI ethics as a discipline.\nFirst, it helps clarify the ethical dimension of AI tools. Second, it provides\nguidance to implementing ethical considerations within the design of AI tools.\nWe illustrate these advantages in the context of AI tools in medicine, by\nshowing how ethics-based auditing of AI tools in medicine can greatly benefit\nfrom our capability-based approach.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03469v1",
    "published_date": "2025-01-10 12:08:21 UTC",
    "updated_date": "2025-01-10 12:08:21 UTC"
  },
  {
    "arxiv_id": "2501.05891v2",
    "title": "Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs",
    "authors": [
      "Bianca Raimondi",
      "Saverio Giallorenzo",
      "Maurizio Gabbrielli"
    ],
    "abstract": "In education, the capability of generating human-like text of Large Language\nModels (LLMs) inspired work on how they can increase the efficiency of learning\nand teaching. We study the affordability of these models for educators and\nstudents by investigating how LLMs answer multiple-choice questions (MCQs) with\nrespect to hardware constraints and refinement techniques. We explore this\nspace by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of\nLLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming\nLanguages (PL) -- the MCQ dataset is a contribution of this work, which we make\npublicly available. Specifically, we dissect how different factors, such as\nusing readily-available material -- (parts of) the course's textbook -- for\nfine-tuning and quantisation (to decrease resource usage) can change the\naccuracy of the responses. The main takeaway is that smaller textbook-based\nfine-tuned models outperform generic larger ones (whose pre-training requires\nconspicuous resources), making the usage of LLMs for answering MCQs resource-\nand material-wise affordable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The 40th ACM/SIGAPP Symposium On Applied Computing",
    "pdf_url": "http://arxiv.org/pdf/2501.05891v2",
    "published_date": "2025-01-10 11:44:35 UTC",
    "updated_date": "2025-03-05 09:18:31 UTC"
  },
  {
    "arxiv_id": "2501.05885v1",
    "title": "EDNet: Edge-Optimized Small Target Detection in UAV Imagery -- Faster Context Attention, Better Feature Fusion, and Hardware Acceleration",
    "authors": [
      "Zhifan Song",
      "Yuan Zhang",
      "Abd Al Rahman M. Abu Ebayyeh"
    ],
    "abstract": "Detecting small targets in drone imagery is challenging due to low\nresolution, complex backgrounds, and dynamic scenes. We propose EDNet, a novel\nedge-target detection framework built on an enhanced YOLOv10 architecture,\noptimized for real-time applications without post-processing. EDNet\nincorporates an XSmall detection head and a Cross Concat strategy to improve\nfeature fusion and multi-scale context awareness for detecting tiny targets in\ndiverse environments. Our unique C2f-FCA block employs Faster Context Attention\nto enhance feature extraction while reducing computational complexity. The WIoU\nloss function is employed for improved bounding box regression. With seven\nmodel sizes ranging from Tiny to XL, EDNet accommodates various deployment\nenvironments, enabling local real-time inference and ensuring data privacy.\nNotably, EDNet achieves up to a 5.6% gain in mAP@50 with significantly fewer\nparameters. On an iPhone 12, EDNet variants operate at speeds ranging from 16\nto 55 FPS, providing a scalable and efficient solution for edge-based object\ndetection in challenging drone imagery. The source code and pre-trained models\nare available at: https://github.com/zsniko/EDNet.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in 21st IEEE International Conference on Ubiquitous\n  Intelligence and Computing (UIC 2024)\n  https://www.ieee-smart-world.org/2024/uic",
    "pdf_url": "http://arxiv.org/pdf/2501.05885v1",
    "published_date": "2025-01-10 11:37:50 UTC",
    "updated_date": "2025-01-10 11:37:50 UTC"
  },
  {
    "arxiv_id": "2501.05882v1",
    "title": "Solving nonograms using Neural Networks",
    "authors": [
      "José María Buades Rubio",
      "Antoni Jaume-i-Capó",
      "David López González",
      "Gabriel Moyà Alcover"
    ],
    "abstract": "Nonograms are logic puzzles in which cells in a grid must be colored or left\nblank according to the numbers that are located in its headers. In this study,\nwe analyze different techniques to solve this type of logical problem using an\nHeuristic Algorithm, Genetic Algorithm, and Heuristic Algorithm with Neural\nNetwork. Furthermore, we generate a public dataset to train the neural\nnetworks. We published this dataset and the code of the algorithms. Combination\nof the heuristic algorithm with a neural network obtained the best results.\nFrom state of the art review, no previous works used neural network to solve\nnonograms, nor combined a network with other algorithms to accelerate the\nresolution process.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05882v1",
    "published_date": "2025-01-10 11:34:22 UTC",
    "updated_date": "2025-01-10 11:34:22 UTC"
  },
  {
    "arxiv_id": "2501.05874v2",
    "title": "VideoRAG: Retrieval-Augmented Generation over Video Corpus",
    "authors": [
      "Soyeong Jeong",
      "Kangsan Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05874v2",
    "published_date": "2025-01-10 11:17:15 UTC",
    "updated_date": "2025-03-04 07:29:52 UTC"
  },
  {
    "arxiv_id": "2501.05845v1",
    "title": "Annealing Machine-assisted Learning of Graph Neural Network for Combinatorial Optimization",
    "authors": [
      "Pablo Loyola",
      "Kento Hasegawa",
      "Andres Hoyos-Idobro",
      "Kazuo Ono",
      "Toyotaro Suzumura",
      "Yu Hirate",
      "Masanao Yamaoka"
    ],
    "abstract": "While Annealing Machines (AM) have shown increasing capabilities in solving\ncomplex combinatorial problems, positioning themselves as a more immediate\nalternative to the expected advances of future fully quantum solutions, there\nare still scaling limitations. In parallel, Graph Neural Networks (GNN) have\nbeen recently adapted to solve combinatorial problems, showing competitive\nresults and potentially high scalability due to their distributed nature. We\npropose a merging approach that aims at retaining both the accuracy exhibited\nby AMs and the representational flexibility and scalability of GNNs. Our model\nconsiders a compression step, followed by a supervised interaction where\npartial solutions obtained from the AM are used to guide local GNNs from where\nnode feature representations are obtained and combined to initialize an\nadditional GNN-based solver that handles the original graph's target problem.\nIntuitively, the AM can solve the combinatorial problem indirectly by infusing\nits knowledge into the GNN. Experiments on canonical optimization problems show\nthat the idea is feasible, effectively allowing the AM to solve size problems\nbeyond its original limits.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Second Workshop on Machine Learning with New Compute Paradigms at\n  NeurIPS 2024 (MLNCP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2501.05845v1",
    "published_date": "2025-01-10 10:36:46 UTC",
    "updated_date": "2025-01-10 10:36:46 UTC"
  },
  {
    "arxiv_id": "2501.05826v2",
    "title": "AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India",
    "authors": [
      "Amit Kr Dey",
      "Pradeep Walia",
      "Girish Somvanshi",
      "Abrar Ali",
      "Sagarnil Das",
      "Pallabi Paul",
      "Minakhi Ghosh"
    ],
    "abstract": "Purpose: Diabetic retinopathy (DR) is a major cause of vision loss,\nparticularly in India, where access to retina specialists is limited in rural\nareas. This study aims to evaluate the Artificial Intelligence-based Diabetic\nRetinopathy Screening System (AIDRSS) for DR detection and prevalence\nassessment, addressing the growing need for scalable, automated screening\nsolutions in resource-limited settings.\n  Approach: A multicentric, cross-sectional study was conducted in Kolkata,\nIndia, involving 5,029 participants and 10,058 macula-centric retinal fundus\nimages. The AIDRSS employed a deep learning algorithm with 50 million trainable\nparameters, integrated with Contrast Limited Adaptive Histogram Equalization\n(CLAHE) preprocessing for enhanced image quality. DR was graded using the\nInternational Clinical Diabetic Retinopathy (ICDR) Scale, categorizing disease\ninto five stages (DR0 to DR4). Statistical metrics including sensitivity,\nspecificity, and prevalence rates were evaluated against expert retina\nspecialist assessments.\n  Results: The prevalence of DR in the general population was 13.7%, rising to\n38.2% among individuals with elevated random blood glucose levels. The AIDRSS\nachieved an overall sensitivity of 92%, specificity of 88%, and 100%\nsensitivity for detecting referable DR (DR3 and DR4). These results demonstrate\nthe system's robust performance in accurately identifying and grading DR in a\ndiverse population.\n  Conclusions: AIDRSS provides a reliable, scalable solution for early DR\ndetection in resource-constrained environments. Its integration of advanced AI\ntechniques ensures high diagnostic accuracy, with potential to significantly\nreduce the burden of diabetes-related vision loss in underserved regions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "22 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.05826v2",
    "published_date": "2025-01-10 10:03:56 UTC",
    "updated_date": "2025-01-13 08:56:05 UTC"
  },
  {
    "arxiv_id": "2501.05819v1",
    "title": "Diffusion Models for Smarter UAVs: Decision-Making and Modeling",
    "authors": [
      "Yousef Emami",
      "Hao Zhou",
      "Luis Almeida",
      "Kai Li"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly adopted in modern\ncommunication networks. However, challenges in decision-making and digital\nmodeling continue to impede their rapid advancement. Reinforcement Learning\n(RL) algorithms face limitations such as low sample efficiency and limited data\nversatility, further magnified in UAV communication scenarios. Moreover,\nDigital Twin (DT) modeling introduces substantial decision-making and data\nmanagement complexities. RL models, often integrated into DT frameworks,\nrequire extensive training data to achieve accurate predictions. In contrast to\ntraditional approaches that focus on class boundaries, Diffusion Models (DMs),\na new class of generative AI, learn the underlying probability distribution\nfrom the training data and can generate trustworthy new patterns based on this\nlearned distribution. This paper explores the integration of DMs with RL and DT\nto effectively address these challenges. By combining the data generation\ncapabilities of DMs with the decision-making framework of RL and the modeling\naccuracy of DT, the integration improves the adaptability and real-time\nperformance of UAV communication. Moreover, the study shows how DMs can\nalleviate data scarcity, improve policy networks, and optimize dynamic\nmodeling, providing a robust solution for complex UAV communication scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "53-01",
      "C.2; I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.05819v1",
    "published_date": "2025-01-10 09:59:16 UTC",
    "updated_date": "2025-01-10 09:59:16 UTC"
  },
  {
    "arxiv_id": "2501.05808v1",
    "title": "Real-Time Integrated Dispatching and Idle Fleet Steering with Deep Reinforcement Learning for A Meal Delivery Platform",
    "authors": [
      "Jingyi Cheng",
      "Shadi Sharif Azadeh"
    ],
    "abstract": "To achieve high service quality and profitability, meal delivery platforms\nlike Uber Eats and Grubhub must strategically operate their fleets to ensure\ntimely deliveries for current orders while mitigating the consequential impacts\nof suboptimal decisions that leads to courier understaffing in the future. This\nstudy set out to solve the real-time order dispatching and idle courier\nsteering problems for a meal delivery platform by proposing a reinforcement\nlearning (RL)-based strategic dual-control framework. To address the inherent\nsequential nature of these problems, we model both order dispatching and\ncourier steering as Markov Decision Processes. Trained via a deep reinforcement\nlearning (DRL) framework, we obtain strategic policies by leveraging the\nexplicitly predicted demands as part of the inputs. In our dual-control\nframework, the dispatching and steering policies are iteratively trained in an\nintegrated manner. These forward-looking policies can be executed in real-time\nand provide decisions while jointly considering the impacts on local and\nnetwork levels. To enhance dispatching fairness, we propose convolutional deep\nQ networks to construct fair courier embeddings. To simultaneously rebalance\nthe supply and demand within the service network, we propose to utilize\nmean-field approximated supply-demand knowledge to reallocate idle couriers at\nthe local level. Utilizing the policies generated by the RL-based strategic\ndual-control framework, we find the delivery efficiency and fairness of\nworkload distribution among couriers have been improved, and under-supplied\nconditions have been alleviated within the service network. Our study sheds\nlight on designing an RL-based framework to enable forward-looking real-time\noperations for meal delivery platforms and other on-demand services.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05808v1",
    "published_date": "2025-01-10 09:15:40 UTC",
    "updated_date": "2025-01-10 09:15:40 UTC"
  },
  {
    "arxiv_id": "2501.05803v3",
    "title": "Test-time Alignment of Diffusion Models without Reward Over-optimization",
    "authors": [
      "Sunwoo Kim",
      "Minkyu Kim",
      "Dongmin Park"
    ],
    "abstract": "Diffusion models excel in generative tasks, but aligning them with specific\nobjectives while maintaining their versatility remains challenging. Existing\nfine-tuning methods often suffer from reward over-optimization, while\napproximate guidance approaches fail to optimize target rewards effectively.\nAddressing these limitations, we propose a training-free, test-time method\nbased on Sequential Monte Carlo (SMC) to sample from the reward-aligned target\ndistribution. Our approach, tailored for diffusion sampling and incorporating\ntempering techniques, achieves comparable or superior target rewards to\nfine-tuning methods while preserving diversity and cross-reward generalization.\nWe demonstrate its effectiveness in single-reward optimization, multi-objective\nscenarios, and online black-box optimization. This work offers a robust\nsolution for aligning diffusion models with diverse downstream objectives\nwithout compromising their general capabilities. Code is available at\nhttps://github.com/krafton-ai/DAS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 (Spotlight). The Thirteenth International Conference on\n  Learning Representations. 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.05803v3",
    "published_date": "2025-01-10 09:10:30 UTC",
    "updated_date": "2025-04-17 12:23:46 UTC"
  },
  {
    "arxiv_id": "2501.05795v3",
    "title": "Robust Counterfactual Explanations under Model Multiplicity Using Multi-Objective Optimization",
    "authors": [
      "Keita Kinjo"
    ],
    "abstract": "In recent years, explainability in machine learning has gained importance. In\nthis context, counterfactual explanation (CE), which is an explanation method\nthat uses examples, has attracted attention. However, it has been pointed out\nthat CE is not robust when there are multiple machine-learning models with\nsimilar accuracy. These problems are important when using machine learning to\nmake safe decisions. In this paper, we propose robust CEs that introduce a new\nviewpoint -- Pareto improvement -- and a method that uses multi-objective\noptimization to generate it. To evaluate the proposed method, we conducted\nexperiments using both simulated and real data. The results demonstrate that\nthe proposed method is both robust and practical. This study highlights the\npotential of ensuring robustness in decision-making by applying the concept of\nsocial welfare. We believe that this research can serve as a valuable\nfoundation for various fields, including explainability in machine learning,\ndecision-making, and action planning based on machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.05795v3",
    "published_date": "2025-01-10 08:57:50 UTC",
    "updated_date": "2025-02-03 06:07:24 UTC"
  },
  {
    "arxiv_id": "2501.05790v1",
    "title": "Understanding Impact of Human Feedback via Influence Functions",
    "authors": [
      "Taywon Min",
      "Haeone Lee",
      "Hanho Ryu",
      "Yongchan Kwon",
      "Kimin Lee"
    ],
    "abstract": "In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn\nsuitable reward models from human feedback to align large language models\n(LLMs) with human intentions. However, human feedback can often be noisy,\ninconsistent, or biased, especially when evaluating complex responses. Such\nfeedback can lead to misaligned reward signals, potentially causing unintended\nside effects during the RLHF process. To address these challenges, we explore\nthe use of influence functions to measure the impact of human feedback on the\nperformance of reward models. We propose a compute-efficient approximation\nmethod that enables the application of influence functions to LLM-based reward\nmodels and large-scale preference datasets. In our experiments, we demonstrate\ntwo key applications of influence functions: (1) detecting common forms of\nlabeler bias in human feedback datasets and (2) guiding labelers to refine\ntheir strategies to align more closely with expert feedback. By quantifying the\nimpact of human feedback on reward models, we believe that influence functions\ncan enhance feedback interpretability and contribute to scalable oversight in\nRLHF, helping labelers provide more accurate and consistent feedback. Source\ncode is available at https://github.com/mintaywon/IF_RLHF",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Source code: https://github.com/mintaywon/IF_RLHF",
    "pdf_url": "http://arxiv.org/pdf/2501.05790v1",
    "published_date": "2025-01-10 08:50:38 UTC",
    "updated_date": "2025-01-10 08:50:38 UTC"
  },
  {
    "arxiv_id": "2501.05783v1",
    "title": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping",
    "authors": [
      "Yanjie Li",
      "Wenxuan Zhang",
      "Kaisheng Liang",
      "Bin Xiao"
    ],
    "abstract": "In recent research, adversarial attacks on person detectors using patches or\nstatic 3D model-based texture modifications have struggled with low success\nrates due to the flexible nature of human movement. Modeling the 3D\ndeformations caused by various actions has been a major challenge. Fortunately,\nadvancements in Neural Radiance Fields (NeRF) for dynamic human modeling offer\nnew possibilities. In this paper, we introduce UV-Attack, a groundbreaking\napproach that achieves high success rates even with extensive and unseen human\nactions. We address the challenge above by leveraging dynamic-NeRF-based UV\nmapping. UV-Attack can generate human images across diverse actions and\nviewpoints, and even create novel actions by sampling from the SMPL parameter\nspace. While dynamic NeRF models are capable of modeling human bodies,\nmodifying clothing textures is challenging because they are embedded in neural\nnetwork parameters. To tackle this, UV-Attack generates UV maps instead of RGB\nimages and modifies the texture stacks. This approach enables real-time texture\nedits and makes the attack more practical. We also propose a novel Expectation\nover Pose Transformation loss (EoPT) to improve the evasion success rate on\nunseen poses and views. Our experiments show that UV-Attack achieves a 92.75%\nattack success rate against the FastRCNN model across varied poses in dynamic\nvideo settings, significantly outperforming the state-of-the-art AdvCamou\nattack, which only had a 28.50% ASR. Moreover, we achieve 49.5% ASR on the\nlatest YOLOv8 detector in black-box settings. This work highlights the\npotential of dynamic NeRF-based UV mapping for creating more effective\nadversarial attacks on person detectors, addressing key challenges in modeling\nhuman movement and texture modification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 22 figures, submitted to ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2501.05783v1",
    "published_date": "2025-01-10 08:33:31 UTC",
    "updated_date": "2025-01-10 08:33:31 UTC"
  },
  {
    "arxiv_id": "2501.06274v2",
    "title": "Polarized Patterns of Language Toxicity and Sentiment of Debunking Posts on Social Media",
    "authors": [
      "Wentao Xu",
      "Wenlu Fan",
      "Shiqian Lu",
      "Tenghao Li",
      "Bin Wang"
    ],
    "abstract": "The rise of misinformation and fake news in online political discourse poses\nsignificant challenges to democratic processes and public engagement. While\ndebunking efforts aim to counteract misinformation and foster fact-based\ndialogue, these discussions often involve language toxicity and emotional\npolarization. We examined over 86 million debunking tweets and more than 4\nmillion Reddit debunking comments to investigate the relationship between\nlanguage toxicity, pessimism, and social polarization in debunking efforts.\nFocusing on discussions of the 2016 and 2020 U.S. presidential elections and\nthe QAnon conspiracy theory, our analysis reveals three key findings: (1)\nperipheral participants (1-degree users) play a disproportionate role in\nshaping toxic discourse, driven by lower community accountability and emotional\nexpression; (2) platform mechanisms significantly influence polarization, with\nTwitter amplifying partisan differences and Reddit fostering higher overall\ntoxicity due to its structured, community-driven interactions; and (3) a\nnegative correlation exists between language toxicity and pessimism, with\nincreased interaction reducing toxicity, especially on Reddit. We show that\nplatform architecture affects informational complexity of user interactions,\nwith Twitter promoting concentrated, uniform discourse and Reddit encouraging\ndiverse, complex communication. Our findings highlight the importance of user\nengagement patterns, platform dynamics, and emotional expressions in shaping\npolarization in debunking discourse. This study offers insights for\npolicymakers and platform designers to mitigate harmful effects and promote\nhealthier online discussions, with implications for understanding\nmisinformation, hate speech, and political polarization in digital\nenvironments.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06274v2",
    "published_date": "2025-01-10 08:00:58 UTC",
    "updated_date": "2025-01-31 16:41:17 UTC"
  },
  {
    "arxiv_id": "2501.05768v1",
    "title": "Halal or Not: Knowledge Graph Completion for Predicting Cultural Appropriateness of Daily Products",
    "authors": [
      "Van Thuy Hoang",
      "Tien-Bach-Thanh Do",
      "Jinho Seo",
      "Seung Charlie Kim",
      "Luong Vuong Nguyen",
      "Duong Nguyen Minh Huy",
      "Hyeon-Ju Jeon",
      "O-Joun Lee"
    ],
    "abstract": "The growing demand for halal cosmetic products has exposed significant\nchallenges, especially in Muslim-majority countries. Recently, various machine\nlearning-based strategies, e.g., image-based methods, have shown remarkable\nsuccess in predicting the halal status of cosmetics. However, these methods\nmainly focus on analyzing the discrete and specific ingredients within separate\ncosmetics, which ignore the high-order and complex relations between cosmetics\nand ingredients. To address this problem, we propose a halal cosmetic\nrecommendation framework, namely HaCKG, that leverages a knowledge graph of\ncosmetics and their ingredients to explicitly model and capture the\nrelationships between cosmetics and their components. By representing cosmetics\nand ingredients as entities within the knowledge graph, HaCKG effectively\nlearns the high-order and complex relations between entities, offering a robust\nmethod for predicting halal status. Specifically, we first construct a cosmetic\nknowledge graph representing the relations between various cosmetics,\ningredients, and their properties. We then propose a pre-trained relational\ngraph attention network model with residual connections to learn the structural\nrelation between entities in the knowledge graph. The pre-trained model is then\nfine-tuned on downstream cosmetic data to predict halal status. Extensive\nexperiments on the cosmetic dataset over halal prediction tasks demonstrate the\nsuperiority of our model over state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.05768v1",
    "published_date": "2025-01-10 07:56:30 UTC",
    "updated_date": "2025-01-10 07:56:30 UTC"
  },
  {
    "arxiv_id": "2501.05767v3",
    "title": "Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models",
    "authors": [
      "You Li",
      "Heyu Huang",
      "Chi Chen",
      "Kaiyu Huang",
      "Chao Huang",
      "Zonghao Guo",
      "Zhiyuan Liu",
      "Jinan Xu",
      "Yuhua Li",
      "Ruixuan Li",
      "Maosong Sun"
    ],
    "abstract": "The recent advancement of Multimodal Large Language Models (MLLMs) has\nsignificantly improved their fine-grained perception of single images and\ngeneral comprehension across multiple images. However, existing MLLMs still\nface challenges in achieving precise grounding in complex multi-image\nscenarios. To address this, we first explore a Chain-of-Thought (CoT) framework\nthat integrates single-image grounding with multi-image comprehension. While\npartially effective, it remains unstable and struggles to capture abstract\nvisual information due to its non-end-to-end nature. Therefore, we introduce\nMigician, the first multi-image grounding model capable of performing free-form\nand accurate grounding across multiple images. To support this, we present the\nMGrounding-630k dataset, which comprises data for several multi-image grounding\ntasks derived from existing datasets, along with newly generated free-form\ngrounding instruction-following data. Furthermore, we propose MIG-Bench, a\ncomprehensive benchmark specifically designed for evaluating multi-image\ngrounding capabilities. Experimental results demonstrate that our model\nachieves significantly superior multi-image grounding capabilities,\noutperforming the best existing MLLMs by 24.94% and even surpassing much larger\n70B models. Our code, model, dataset, and benchmark are fully open-sourced at\nhttps://migician-vg.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.05767v3",
    "published_date": "2025-01-10 07:56:23 UTC",
    "updated_date": "2025-02-18 02:40:14 UTC"
  },
  {
    "arxiv_id": "2501.05765v2",
    "title": "Deontic Temporal Logic for Formal Verification of AI Ethics",
    "authors": [
      "Priya T. V.",
      "Shrisha Rao"
    ],
    "abstract": "Ensuring ethical behavior in Artificial Intelligence (AI) systems amidst\ntheir increasing ubiquity and influence is a major concern the world over. The\nuse of formal methods in AI ethics is a possible crucial approach for\nspecifying and verifying the ethical behavior of AI systems. This paper\nproposes a formalization based on deontic logic to define and evaluate the\nethical behavior of AI systems, focusing on system-level specifications,\ncontributing to this important goal. It introduces axioms and theorems to\ncapture ethical requirements related to fairness and explainability. The\nformalization incorporates temporal operators to reason about the ethical\nbehavior of AI systems over time. The authors evaluate the effectiveness of\nthis formalization by assessing the ethics of the real-world COMPAS and loan\nprediction AI systems. Various ethical properties of the COMPAS and loan\nprediction systems are encoded using deontic logical formulas, allowing the use\nof an automated theorem prover to verify whether these systems satisfy the\ndefined properties. The formal verification reveals that both systems fail to\nfulfill certain key ethical properties related to fairness and\nnon-discrimination, demonstrating the effectiveness of the proposed\nformalization in identifying potential ethical issues in real-world AI\napplications.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "I.2.m; F.4.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05765v2",
    "published_date": "2025-01-10 07:48:40 UTC",
    "updated_date": "2025-05-14 16:47:37 UTC"
  },
  {
    "arxiv_id": "2501.05752v1",
    "title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models",
    "authors": [
      "Sungjae Lee",
      "Hyejin Park",
      "Jaechang Kim",
      "Jungseul Ok"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have shown remarkable\npotential in various complex tasks requiring multi-step reasoning methods like\ntree search to explore diverse reasoning paths. However, existing methods often\nsuffer from computational inefficiency and redundancy. First, they overlook the\ndiversity of task difficulties, leading to unnecessarily extensive searches\neven for easy tasks. Second, they neglect the semantics of reasoning paths,\nresulting in redundant exploration of semantically identical paths. To address\nthese limitations, we propose Semantic Exploration with Adaptive Gating (SEAG),\na computationally efficient method. SEAG employs an adaptive gating mechanism\nthat dynamically decides whether to conduct a tree search, based on the\nconfidence level of answers from a preceding simple reasoning method.\nFurthermore, its tree-based exploration consolidates semantically identical\nreasoning steps, reducing redundant explorations while maintaining or even\nimproving accuracy. Our extensive experiments demonstrate that SEAG\nsignificantly improves accuracy by 4.3% on average while requiring only 31% of\ncomputational costs compared to existing tree search-based methods on complex\nreasoning benchmarks including GSM8K and ARC with diverse language models such\nas Llama2, Llama3, and Mistral.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05752v1",
    "published_date": "2025-01-10 07:02:43 UTC",
    "updated_date": "2025-01-10 07:02:43 UTC"
  },
  {
    "arxiv_id": "2505.09616v1",
    "title": "SpecWav-Attack: Leveraging Spectrogram Resizing and Wav2Vec 2.0 for Attacking Anonymized Speech",
    "authors": [
      "Yuqi Li",
      "Yuanzhong Zheng",
      "Zhongtian Guo",
      "Yaoxuan Wang",
      "Jianjun Yin",
      "Haojun Fei"
    ],
    "abstract": "This paper presents SpecWav-Attack, an adversarial model for detecting\nspeakers in anonymized speech. It leverages Wav2Vec2 for feature extraction and\nincorporates spectrogram resizing and incremental training for improved\nperformance. Evaluated on librispeech-dev and librispeech-test, SpecWav-Attack\noutperforms conventional attacks, revealing vulnerabilities in anonymized\nspeech systems and emphasizing the need for stronger defenses, benchmarked\nagainst the ICASSP 2025 Attacker Challenge.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "I.2.0"
    ],
    "primary_category": "cs.SD",
    "comment": "2 pages,3 figures,1 chart",
    "pdf_url": "http://arxiv.org/pdf/2505.09616v1",
    "published_date": "2025-01-10 06:18:41 UTC",
    "updated_date": "2025-01-10 06:18:41 UTC"
  },
  {
    "arxiv_id": "2501.05730v1",
    "title": "Element-wise Attention Is All You Need",
    "authors": [
      "Guoxin Feng"
    ],
    "abstract": "The self-attention (SA) mechanism has demonstrated superior performance\nacross various domains, yet it suffers from substantial complexity during both\ntraining and inference. The next-generation architecture, aiming at retaining\nthe competitive performance of SA while achieving low-cost inference and\nefficient long-sequence training, primarily focuses on three approaches: linear\nattention, linear RNNs, and state space models. Although these approaches\nachieve reduced complexity than SA, they all have built-in performance\ndegradation factors, such as diminished “spikiness” and compression of\nhistorical information. In contrast to these approaches, we propose a novel\nelement-wise attention mechanism, which uses the element-wise squared Euclidean\ndistance, instead of the dot product operation, to compute similarity and\napproximates the quadratic complexity term $\\exp(q_{ic}k_{jc})$ with a Taylor\npolynomial. This design achieves remarkable efficiency: during training, the\nelement-wise attention has a complexity of $\\mathcal{O}(tLD)$, making\nlong-sequence training both computationally and memory efficient, where $L$ is\nthe sequence length, $D$ is the feature dimension, and $t$ is the highest order\nof the polynomial; during inference, it can be reformulated as recurrent neural\nnetworks, achieving a inference complexity of $\\mathcal{O}(tD)$. Furthermore,\nthe element-wise attention circumvents the performance degradation factors\npresent in these approaches and achieves performance comparable to SA in both\ncausal and non-causal forms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05730v1",
    "published_date": "2025-01-10 05:54:04 UTC",
    "updated_date": "2025-01-10 05:54:04 UTC"
  },
  {
    "arxiv_id": "2501.05729v2",
    "title": "ExPO: Explainable Phonetic Trait-Oriented Network for Speaker Verification",
    "authors": [
      "Yi Ma",
      "Shuai Wang",
      "Tianchi Liu",
      "Haizhou Li"
    ],
    "abstract": "In speaker verification, we use computational method to verify if an\nutterance matches the identity of an enrolled speaker. This task is similar to\nthe manual task of forensic voice comparison, where linguistic analysis is\ncombined with auditory measurements to compare and evaluate voice samples.\nDespite much success, we have yet to develop a speaker verification system that\noffers explainable results comparable to those from manual forensic voice\ncomparison. A novel approach, Explainable Phonetic Trait-Oriented (ExPO)\nnetwork, is proposed in this paper to introduce the speaker's phonetic trait\nwhich describes the speaker's characteristics at the phonetic level, resembling\nwhat forensic comparison does. ExPO not only generates utterance-level speaker\nembeddings but also allows for fine-grained analysis and visualization of\nphonetic traits, offering an explainable speaker verification process.\nFurthermore, we investigate phonetic traits from within-speaker and\nbetween-speaker variation perspectives to determine which trait is most\neffective for speaker verification, marking an important step towards\nexplainable speaker verification. Our code is available at\nhttps://github.com/mmmmayi/ExPO.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by IEEE Signal Processing Letters",
    "pdf_url": "http://arxiv.org/pdf/2501.05729v2",
    "published_date": "2025-01-10 05:53:37 UTC",
    "updated_date": "2025-01-14 07:28:10 UTC"
  },
  {
    "arxiv_id": "2501.05727v1",
    "title": "Enabling Scalable Oversight via Self-Evolving Critic",
    "authors": [
      "Zhengyang Tang",
      "Ziniu Li",
      "Zhenyang Xiao",
      "Tian Ding",
      "Ruoyu Sun",
      "Benyou Wang",
      "Dayiheng Liu",
      "Fei Huang",
      "Tianyu Liu",
      "Bowen Yu",
      "Junyang Lin"
    ],
    "abstract": "Despite their remarkable performance, the development of Large Language\nModels (LLMs) faces a critical challenge in scalable oversight: providing\neffective feedback for tasks where human evaluation is difficult or where LLMs\noutperform humans. While there is growing interest in using LLMs for critique,\ncurrent approaches still rely on human annotations or more powerful models,\nleaving the issue of enhancing critique capabilities without external\nsupervision unresolved. We introduce SCRIT (Self-evolving CRITic), a framework\nthat enables genuine self-evolution of critique abilities. Technically, SCRIT\nself-improves by training on synthetic data, generated by a contrastive-based\nself-critic that uses reference solutions for step-by-step critique, and a\nself-validation mechanism that ensures critique quality through correction\noutcomes. Implemented with Qwen2.5-72B-Instruct, one of the most powerful LLMs,\nSCRIT achieves up to a 10.3\\% improvement on critique-correction and error\nidentification benchmarks. Our analysis reveals that SCRIT's performance scales\npositively with data and model size, outperforms alternative approaches, and\nbenefits critically from its self-validation component.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05727v1",
    "published_date": "2025-01-10 05:51:52 UTC",
    "updated_date": "2025-01-10 05:51:52 UTC"
  },
  {
    "arxiv_id": "2501.05717v1",
    "title": "Zero-shot Shark Tracking and Biometrics from Aerial Imagery",
    "authors": [
      "Chinmay K Lalgudi",
      "Mark E Leone",
      "Jaden V Clark",
      "Sergio Madrigal-Mora",
      "Mario Espinoza"
    ],
    "abstract": "The recent widespread adoption of drones for studying marine animals provides\nopportunities for deriving biological information from aerial imagery. The\nlarge scale of imagery data acquired from drones is well suited for machine\nlearning (ML) analysis. Development of ML models for analyzing marine animal\naerial imagery has followed the classical paradigm of training, testing, and\ndeploying a new model for each dataset, requiring significant time, human\neffort, and ML expertise. We introduce Frame Level ALIgment and tRacking\n(FLAIR), which leverages the video understanding of Segment Anything Model 2\n(SAM2) and the vision-language capabilities of Contrastive Language-Image\nPre-training (CLIP). FLAIR takes a drone video as input and outputs\nsegmentation masks of the species of interest across the video. Notably, FLAIR\nleverages a zero-shot approach, eliminating the need for labeled data, training\na new model, or fine-tuning an existing model to generalize to other species.\nWith a dataset of 18,000 drone images of Pacific nurse sharks, we trained\nstate-of-the-art object detection models to compare against FLAIR. We show that\nFLAIR massively outperforms these object detectors and performs competitively\nagainst two human-in-the-loop methods for prompting SAM2, achieving a Dice\nscore of 0.81. FLAIR readily generalizes to other shark species without\nadditional human effort and can be combined with novel heuristics to\nautomatically extract relevant information including length and tailbeat\nfrequency. FLAIR has significant potential to accelerate aerial imagery\nanalysis workflows, requiring markedly less human effort and expertise than\ntraditional machine learning workflows, while achieving superior accuracy. By\nreducing the effort required for aerial imagery analysis, FLAIR allows\nscientists to spend more time interpreting results and deriving insights about\nmarine ecosystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05717v1",
    "published_date": "2025-01-10 05:29:09 UTC",
    "updated_date": "2025-01-10 05:29:09 UTC"
  },
  {
    "arxiv_id": "2501.05714v2",
    "title": "How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond",
    "authors": [
      "Chen Huang",
      "Yang Deng",
      "Wenqiang Lei",
      "Jiancheng Lv",
      "Tat-Seng Chua",
      "Jimmy Xiangji Huang"
    ],
    "abstract": "With the advancement of large language models (LLMs), intelligent models have\nevolved from mere tools to autonomous agents with their own goals and\nstrategies for cooperating with humans. This evolution has birthed a novel\nparadigm in NLP, i.e., human-model cooperation, that has yielded remarkable\nprogress in numerous NLP tasks in recent years. In this paper, we take the\nfirst step to present a thorough review of human-model cooperation, exploring\nits principles, formalizations, and open challenges. In particular, we\nintroduce a new taxonomy that provides a unified perspective to summarize\nexisting approaches. Also, we discuss potential frontier areas and their\ncorresponding challenges. We regard our work as an entry point, paving the way\nfor more breakthrough research in this regard.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "V2: Only minor edits were made to the main text, and we've added more\n  supplementary materials",
    "pdf_url": "http://arxiv.org/pdf/2501.05714v2",
    "published_date": "2025-01-10 05:15:14 UTC",
    "updated_date": "2025-04-20 02:18:50 UTC"
  },
  {
    "arxiv_id": "2501.05707v2",
    "title": "Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains",
    "authors": [
      "Vighnesh Subramaniam",
      "Yilun Du",
      "Joshua B. Tenenbaum",
      "Antonio Torralba",
      "Shuang Li",
      "Igor Mordatch"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable performance in recent\nyears but are fundamentally limited by the underlying training data. To improve\nmodels beyond the training data, recent works have explored how LLMs can be\nused to generate synthetic data for autonomous self-improvement. However,\nsuccessive steps of self-improvement can reach a point of diminishing returns.\nIn this work, we propose a complementary approach towards self-improvement\nwhere finetuning is applied to a multiagent society of language models. A group\nof language models, all starting from the same base model, are independently\nspecialized by updating each one using data generated through multiagent\ninteractions among the models. By training each model on independent sets of\ndata, we illustrate how this approach enables specialization across models and\ndiversification over the set of models. As a result, our overall system is able\nto preserve diverse reasoning chains and autonomously improve over many more\nrounds of fine-tuning than single-agent self-improvement methods. We\nquantitatively illustrate the efficacy of the approach across a wide suite of\nreasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025; 22 pages, 13 figures, 7 tables; Project page at\n  https://llm-multiagent-ft.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2501.05707v2",
    "published_date": "2025-01-10 04:35:46 UTC",
    "updated_date": "2025-03-03 18:58:16 UTC"
  },
  {
    "arxiv_id": "2501.10421v1",
    "title": "CodEv: An Automated Grading Framework Leveraging Large Language Models for Consistent and Constructive Feedback",
    "authors": [
      "En-Qi Tseng",
      "Pei-Cing Huang",
      "Chan Hsu",
      "Peng-Yi Wu",
      "Chan-Tung Ku",
      "Yihuang Kang"
    ],
    "abstract": "Grading programming assignments is crucial for guiding students to improve\ntheir programming skills and coding styles. This study presents an automated\ngrading framework, CodEv, which leverages Large Language Models (LLMs) to\nprovide consistent and constructive feedback. We incorporate Chain of Thought\n(CoT) prompting techniques to enhance the reasoning capabilities of LLMs and\nensure that the grading is aligned with human evaluation. Our framework also\nintegrates LLM ensembles to improve the accuracy and consistency of scores,\nalong with agreement tests to deliver reliable feedback and code review\ncomments. The results demonstrate that the framework can yield grading results\ncomparable to human evaluators, by using smaller LLMs. Evaluation and\nconsistency tests of the LLMs further validate our approach, confirming the\nreliability of the generated scores and feedback.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10421v1",
    "published_date": "2025-01-10 03:09:46 UTC",
    "updated_date": "2025-01-10 03:09:46 UTC"
  },
  {
    "arxiv_id": "2501.05680v1",
    "title": "EXION: Exploiting Inter- and Intra-Iteration Output Sparsity for Diffusion Models",
    "authors": [
      "Jaehoon Heo",
      "Adiwena Putra",
      "Jieon Yoon",
      "Sungwoong Yune",
      "Hangyeol Lee",
      "Ji-Hoon Kim",
      "Joo-Young Kim"
    ],
    "abstract": "Over the past few years, diffusion models have emerged as novel AI solutions,\ngenerating diverse multi-modal outputs from text prompts. Despite their\ncapabilities, they face challenges in computing, such as excessive latency and\nenergy consumption due to their iterative architecture. Although prior works\nspecialized in transformer acceleration can be applied, the iterative nature of\ndiffusion models remains unresolved. In this paper, we present EXION, the first\nSW-HW co-designed diffusion accelerator that solves the computation challenges\nby exploiting the unique inter- and intra-iteration output sparsity in\ndiffusion models. To this end, we propose two SW-level optimizations. First, we\nintroduce the FFN-Reuse algorithm that identifies and skips redundant\ncomputations in FFN layers across different iterations (inter-iteration\nsparsity). Second, we use a modified eager prediction method that employs\ntwo-step leading-one detection to accurately predict the attention score,\nskipping unnecessary computations within an iteration (intra-iteration\nsparsity). We also introduce a novel data compaction mechanism named ConMerge,\nwhich can enhance HW utilization by condensing and merging sparse matrices into\ncompact forms. Finally, it has a dedicated HW architecture that supports the\nabove sparsity-inducing algorithms, translating high output sparsity into\nimproved energy efficiency and performance. To verify the feasibility of the\nEXION, we first demonstrate that it has no impact on accuracy in various types\nof multi-modal diffusion models. We then instantiate EXION in both server- and\nedge-level settings and compare its performance against GPUs with similar\nspecifications. Our evaluation shows that EXION achieves dramatic improvements\nin performance and energy efficiency by 3.2-379.3x and 45.1-3067.6x compared to\na server GPU and by 42.6-1090.9x and 196.9-4668.2x compared to an edge GPU.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "To appear in 2025 IEEE International Symposium on High-Performance\n  Computer Architecture (HPCA 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.05680v1",
    "published_date": "2025-01-10 03:07:28 UTC",
    "updated_date": "2025-01-10 03:07:28 UTC"
  },
  {
    "arxiv_id": "2501.05675v4",
    "title": "Synergizing Large Language Models and Task-specific Models for Time Series Anomaly Detection",
    "authors": [
      "Feiyi Chen",
      "Leilei Zhang",
      "Guansong Pang",
      "Roger Zimmermann",
      "Shuiguang Deng"
    ],
    "abstract": "In anomaly detection, methods based on large language models (LLMs) can\nincorporate expert knowledge by reading professional document, while\ntask-specific small models excel at extracting normal data patterns and\ndetecting value fluctuations from training data of target applications.\nInspired by the human nervous system, where the brain stores expert knowledge\nand the peripheral nervous system and spinal cord handle specific tasks like\nwithdrawal and knee-jerk reflexes, we propose CoLLaTe, a framework designed to\nfacilitate collaboration between LLMs and task-specific models, leveraging the\nstrengths of both models for anomaly detection.\n  In particular, we first formulate the collaboration process and identify two\nkey challenges in the collaboration:\n  (1) the misalignment between the expression domains of the LLMs and\ntask-specific small models, and (2) error accumulation arising from the\npredictions of both models.\n  To address these challenges, we then introduce two key components in CoLLaTe:\na model alignment module and a collaborative loss function. Through theoretical\nanalysis and experimental validation, we demonstrate that these components\neffectively mitigate the identified challenges and achieve better performance\nthan both LLM-based and task-specific models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05675v4",
    "published_date": "2025-01-10 02:57:08 UTC",
    "updated_date": "2025-05-06 07:57:08 UTC"
  },
  {
    "arxiv_id": "2501.05673v1",
    "title": "Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration",
    "authors": [
      "Zuyuan Zhang",
      "Vaneet Aggarwal",
      "Tian Lan"
    ],
    "abstract": "Network services are increasingly managed by considering chained-up virtual\nnetwork functions and relevant traffic flows, known as the Service Function\nChains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,\nwe must consider two closely-coupled problems - an SFC placement problem that\nmaps SFCs to servers/links in the network and an SFC scheduling problem that\ndetermines when each SFC is executed. Solving the whole SFC problem targeting\nthese two optimizations jointly is extremely challenging. In this paper, we\npropose a novel network diffuser using conditional generative modeling for this\nSFC placing-scheduling optimization. Recent advances in generative AI and\ndiffusion models have made it possible to generate high-quality images/videos\nand decision trajectories from language description. We formulate the SFC\noptimization as a problem of generating a state sequence for planning and\nperform graph diffusion on the state trajectories to enable extraction of SFC\ndecisions, with SFC optimization constraints and objectives as conditions. To\naddress the lack of demonstration data due to NP-hardness and exponential\nproblem space of the SFC optimization, we also propose a novel and somewhat\nmaverick approach -- Rather than solving instances of this difficult\noptimization, we start with randomly-generated solutions as input, and then\ndetermine appropriate SFC optimization problems that render these solutions\nfeasible. This inverse demonstration enables us to obtain sufficient expert\ndemonstrations, i.e., problem-solution pairs, through further optimization. In\nour numerical evaluations, the proposed network diffuser outperforms learning\nand heuristic baselines, by $\\sim$20\\% improvement in SFC reward and $\\sim$50\\%\nreduction in SFC waiting time and blocking rate.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted to IEEE INFOCOM 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.05673v1",
    "published_date": "2025-01-10 02:51:58 UTC",
    "updated_date": "2025-01-10 02:51:58 UTC"
  },
  {
    "arxiv_id": "2501.05667v2",
    "title": "TransPlace: Transferable Circuit Global Placement via Graph Neural Network",
    "authors": [
      "Yunbo Hou",
      "Haoran Ye",
      "Shuwen Yang",
      "Yingxue Zhang",
      "Siyuan Xu",
      "Guojie Song"
    ],
    "abstract": "Global placement, a critical step in designing the physical layout of\ncomputer chips, is essential to optimize chip performance. Prior global\nplacement methods optimize each circuit design individually from scratch. Their\nneglect of transferable knowledge limits solution efficiency and chip\nperformance as circuit complexity drastically increases. This study presents\nTransPlace, a global placement framework that learns to place millions of\nmixed-size cells in continuous space. TransPlace introduces i) Netlist Graph to\nefficiently model netlist topology, ii) Cell-flow and relative position\nencoding to learn SE(2)-invariant representation, iii) a tailored graph neural\nnetwork architecture for informed parameterization of placement knowledge, and\niv) a two-stage strategy for coarse-to-fine placement. Compared to\nstate-of-the-art placement methods, TransPlace-trained on a few high-quality\nplacements-can place unseen circuits with 1.2x speedup while reducing\ncongestion by 30%, timing by 9%, and wirelength by 5%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.05667v2",
    "published_date": "2025-01-10 02:33:15 UTC",
    "updated_date": "2025-03-26 03:19:11 UTC"
  },
  {
    "arxiv_id": "2501.05663v1",
    "title": "Learning to Measure Quantum Neural Networks",
    "authors": [
      "Samuel Yen-Chi Chen",
      "Huan-Hsin Tseng",
      "Hsin-Yi Lin",
      "Shinjae Yoo"
    ],
    "abstract": "The rapid progress in quantum computing (QC) and machine learning (ML) has\nattracted growing attention, prompting extensive research into quantum machine\nlearning (QML) algorithms to solve diverse and complex problems. Designing\nhigh-performance QML models demands expert-level proficiency, which remains a\nsignificant obstacle to the broader adoption of QML. A few major hurdles\ninclude crafting effective data encoding techniques and parameterized quantum\ncircuits, both of which are crucial to the performance of QML models.\nAdditionally, the measurement phase is frequently overlooked-most current QML\nmodels rely on pre-defined measurement protocols that often fail to account for\nthe specific problem being addressed. We introduce a novel approach that makes\nthe observable of the quantum system-specifically, the Hermitian\nmatrix-learnable. Our method features an end-to-end differentiable learning\nframework, where the parameterized observable is trained alongside the ordinary\nquantum circuit parameters simultaneously. Using numerical simulations, we show\nthat the proposed method can identify observables for variational quantum\ncircuits that lead to improved outcomes, such as higher classification\naccuracy, thereby boosting the overall performance of QML models.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted by ICASSP 2025 Workshop: Quantum Machine Learning in Signal\n  Processing and Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2501.05663v1",
    "published_date": "2025-01-10 02:28:19 UTC",
    "updated_date": "2025-01-10 02:28:19 UTC"
  },
  {
    "arxiv_id": "2501.05662v2",
    "title": "Cascaded Self-Evaluation Augmented Training for Lightweight Multimodal LLMs",
    "authors": [
      "Zheqi Lv",
      "Wenkai Wang",
      "Jiawei Wang",
      "Shengyu Zhang",
      "Fei Wu"
    ],
    "abstract": "Efficient Multimodal Large Language Models (EMLLMs) can improve performance\nthrough Chain-of-Thought (CoT) reasoning, but they have poor self-evaluation\ncapabilities during the CoT reasoning process. This is due to their tendency to\nsimplify the reasoning process and the degradation of self-evaluation ability\nduring downstream task fine-tuning. To address this, we intuitively propose\n\\textit{Self-Evaluation Augmented Training (SEAT)}, which uses more powerful\nEMLLMs to evaluate CoT reasoning data. The evaluation data is then used to\ntrain EMLLMs. However, due to the difficulties EMLLMs face with processing long\ntoken input-output sequences, and the degradation of self-evaluation ability as\na basis for CoT reasoning, the SEAT method is not fully adapted. Therefore, we\nfurther propose \\textit{Cascaded Self-Evaluation Augmented Training\n(Cas-SEAT)}, which converts long prompts into cascaded short prompts, each\nfocusing on a specific task. Additionally, we mix CoT reasoning and\nself-evaluation data to preserve its CoT reasoning ability while enhancing the\nself-evaluation capability of EMLLMs. We also conduct \\textit{Double-level Data\nFiltering (DDF)}, which includes source data filtering and labeled data\nfiltering, using both manual selection and MLLMs for filtering. Cas-SEAT and\nDDF work together to improve the performance of EMLLMs. Experiments show that\nCas-SEAT achieves an average improvement of 22.16% across multiple datasets,\nand DDF significantly reduces the resource consumption of training",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05662v2",
    "published_date": "2025-01-10 02:28:04 UTC",
    "updated_date": "2025-03-16 02:28:32 UTC"
  },
  {
    "arxiv_id": "2501.06271v1",
    "title": "Large Language Models for Bioinformatics",
    "authors": [
      "Wei Ruan",
      "Yanjun Lyu",
      "Jing Zhang",
      "Jiazhang Cai",
      "Peng Shu",
      "Yang Ge",
      "Yao Lu",
      "Shang Gao",
      "Yue Wang",
      "Peilong Wang",
      "Lin Zhao",
      "Tao Wang",
      "Yufang Liu",
      "Luyang Fang",
      "Ziyu Liu",
      "Zhengliang Liu",
      "Yiwei Li",
      "Zihao Wu",
      "Junhao Chen",
      "Hanqi Jiang",
      "Yi Pan",
      "Zhenyuan Yang",
      "Jingyuan Chen",
      "Shizhe Liang",
      "Wei Zhang",
      "Terry Ma",
      "Yuan Dou",
      "Jianli Zhang",
      "Xinyu Gong",
      "Qi Gan",
      "Yusong Zou",
      "Zebang Chen",
      "Yuanxin Qian",
      "Shuo Yu",
      "Jin Lu",
      "Kenan Song",
      "Xianqiao Wang",
      "Andrea Sikora",
      "Gang Li",
      "Xiang Li",
      "Quanzheng Li",
      "Yingfeng Wang",
      "Lu Zhang",
      "Yohannes Abate",
      "Lifang He",
      "Wenxuan Zhong",
      "Rongjie Liu",
      "Chao Huang",
      "Wei Liu",
      "Ye Shen",
      "Ping Ma",
      "Hongtu Zhu",
      "Yajun Yan",
      "Dajiang Zhu",
      "Tianming Liu"
    ],
    "abstract": "With the rapid advancements in large language model (LLM) technology and the\nemergence of bioinformatics-specific language models (BioLMs), there is a\ngrowing need for a comprehensive analysis of the current landscape,\ncomputational characteristics, and diverse applications. This survey aims to\naddress this need by providing a thorough review of BioLMs, focusing on their\nevolution, classification, and distinguishing features, alongside a detailed\nexamination of training methodologies, datasets, and evaluation frameworks. We\nexplore the wide-ranging applications of BioLMs in critical areas such as\ndisease diagnosis, drug discovery, and vaccine development, highlighting their\nimpact and transformative potential in bioinformatics. We identify key\nchallenges and limitations inherent in BioLMs, including data privacy and\nsecurity concerns, interpretability issues, biases in training data and model\noutputs, and domain adaptation complexities. Finally, we highlight emerging\ntrends and future directions, offering valuable insights to guide researchers\nand clinicians toward advancing BioLMs for increasingly sophisticated\nbiological and clinical applications.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "q-bio.QM",
    "comment": "64 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2501.06271v1",
    "published_date": "2025-01-10 01:43:05 UTC",
    "updated_date": "2025-01-10 01:43:05 UTC"
  },
  {
    "arxiv_id": "2501.05647v2",
    "title": "Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation",
    "authors": [
      "Zheqi Lv",
      "Tianyu Zhan",
      "Wenjie Wang",
      "Xinyu Lin",
      "Shengyu Zhang",
      "Wenqiao Zhang",
      "Jiwei Li",
      "Kun Kuang",
      "Fei Wu"
    ],
    "abstract": "Large Language Models (LLMs) for Recommendation (LLM4Rec) is a promising\nresearch direction that has demonstrated exceptional performance in this field.\nHowever, its inability to capture real-time user preferences greatly limits the\npractical application of LLM4Rec because (i) LLMs are costly to train and infer\nfrequently, and (ii) LLMs struggle to access real-time data (its large number\nof parameters poses an obstacle to deployment on devices). Fortunately, small\nrecommendation models (SRMs) can effectively supplement these shortcomings of\nLLM4Rec diagrams by consuming minimal resources for frequent training and\ninference, and by conveniently accessing real-time data on devices.\n  In light of this, we designed the Device-Cloud LLM-SRM Collaborative\nRecommendation Framework (LSC4Rec) under a device-cloud collaboration setting.\nLSC4Rec aims to integrate the advantages of both LLMs and SRMs, as well as the\nbenefits of cloud and edge computing, achieving a complementary synergy. We\nenhance the practicability of LSC4Rec by designing three strategies:\ncollaborative training, collaborative inference, and intelligent request.\nDuring training, LLM generates candidate lists to enhance the ranking ability\nof SRM in collaborative scenarios and enables SRM to update adaptively to\ncapture real-time user interests. During inference, LLM and SRM are deployed on\nthe cloud and on the device, respectively. LLM generates candidate lists and\ninitial ranking results based on user behavior, and SRM get reranking results\nbased on the candidate list, with final results integrating both LLM's and\nSRM's scores. The device determines whether a new candidate list is needed by\ncomparing the consistency of the LLM's and SRM's sorted lists. Our\ncomprehensive and extensive experimental analysis validates the effectiveness\nof each strategy in LSC4Rec.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.IR",
    "comment": "Published on KDD'25: Proceedings of the ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.05647v2",
    "published_date": "2025-01-10 01:27:12 UTC",
    "updated_date": "2025-02-25 13:10:08 UTC"
  },
  {
    "arxiv_id": "2501.05646v1",
    "title": "Efficient Representations for High-Cardinality Categorical Variables in Machine Learning",
    "authors": [
      "Zixuan Liang"
    ],
    "abstract": "High\\-cardinality categorical variables pose significant challenges in\nmachine learning, particularly in terms of computational efficiency and model\ninterpretability. Traditional one\\-hot encoding often results in\nhigh\\-dimensional sparse feature spaces, increasing the risk of overfitting and\nreducing scalability. This paper introduces novel encoding techniques,\nincluding means encoding, low\\-rank encoding, and multinomial logistic\nregression encoding, to address these challenges. These methods leverage\nsufficient representations to generate compact and informative embeddings of\ncategorical data. We conduct rigorous theoretical analyses and empirical\nvalidations on diverse datasets, demonstrating significant improvements in\nmodel performance and computational efficiency compared to baseline methods.\nThe proposed techniques are particularly effective in domains requiring\nscalable solutions for large datasets, paving the way for more robust and\nefficient applications in machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "2025 International Conference on Advanced Machine Learning and Data\n  Science (AMLDS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.05646v1",
    "published_date": "2025-01-10 01:25:01 UTC",
    "updated_date": "2025-01-10 01:25:01 UTC"
  },
  {
    "arxiv_id": "2501.05643v1",
    "title": "Iconicity in Large Language Models",
    "authors": [
      "Anna Marklová",
      "Jiří Milička",
      "Leonid Ryvkin",
      "Ľudmila Lacková Bennet",
      "Libuše Kormaníková"
    ],
    "abstract": "Lexical iconicity, a direct relation between a word's meaning and its form,\nis an important aspect of every natural language, most commonly manifesting\nthrough sound-meaning associations. Since Large language models' (LLMs') access\nto both meaning and sound of text is only mediated (meaning through textual\ncontext, sound through written representation, further complicated by\ntokenization), we might expect that the encoding of iconicity in LLMs would be\neither insufficient or significantly different from human processing. This\nstudy addresses this hypothesis by having GPT-4 generate highly iconic\npseudowords in artificial languages. To verify that these words actually carry\niconicity, we had their meanings guessed by Czech and German participants\n(n=672) and subsequently by LLM-based participants (generated by GPT-4 and\nClaude 3.5 Sonnet). The results revealed that humans can guess the meanings of\npseudowords in the generated iconic language more accurately than words in\ndistant natural languages and that LLM-based participants are even more\nsuccessful than humans in this task. This core finding is accompanied by\nseveral additional analyses concerning the universality of the generated\nlanguage and the cues that both human and LLM-based participants utilize.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Supplementary information: https://osf.io/ywjrk/",
    "pdf_url": "http://arxiv.org/pdf/2501.05643v1",
    "published_date": "2025-01-10 01:00:05 UTC",
    "updated_date": "2025-01-10 01:00:05 UTC"
  },
  {
    "arxiv_id": "2501.05629v1",
    "title": "The Impact of Model Scaling on Seen and Unseen Language Performance",
    "authors": [
      "Rhitabrat Pokharel",
      "Sina Bagheri Nezhad",
      "Ameeta Agrawal",
      "Suresh Singh"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs), particularly those\ntrained on multilingual corpora, has intensified the need for a deeper\nunderstanding of their performance across a diverse range of languages and\nmodel sizes. Our research addresses this critical need by studying the\nperformance and scaling behavior of multilingual LLMs in text classification\nand machine translation tasks across 204 languages. We systematically examine\nboth seen and unseen languages across three model families of varying sizes in\nzero-shot and few-shot settings. Our findings show significant differences in\nscaling behavior between zero-shot and two-shot scenarios, with striking\ndisparities in performance between seen and unseen languages. Model scale has\nlittle effect on zero-shot performance, which remains mostly flat. However, in\ntwo-shot settings, larger models show clear linear improvements in multilingual\ntext classification. For translation tasks, however, only the instruction-tuned\nmodel showed clear benefits from scaling. Our analysis also suggests that\noverall resource levels, not just the proportions of pretraining languages, are\nbetter predictors of model performance, shedding light on what drives\nmultilingual LLM effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SEAS Workshop at AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2501.05629v1",
    "published_date": "2025-01-10 00:10:21 UTC",
    "updated_date": "2025-01-10 00:10:21 UTC"
  }
]