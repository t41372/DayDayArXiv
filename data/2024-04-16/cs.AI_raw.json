[
  {
    "arxiv_id": "2404.10960v1",
    "title": "Uncertainty-Based Abstention in LLMs Improves Safety and Reduces Hallucinations",
    "authors": [
      "Christian Tomani",
      "Kamalika Chaudhuri",
      "Ivan Evtimov",
      "Daniel Cremers",
      "Mark Ibrahim"
    ],
    "abstract": "A major barrier towards the practical deployment of large language models\n(LLMs) is their lack of reliability. Three situations where this is\nparticularly apparent are correctness, hallucinations when given unanswerable\nquestions, and safety. In all three cases, models should ideally abstain from\nresponding, much like humans, whose ability to understand uncertainty makes us\nrefrain from answering questions we don't know. Inspired by analogous\napproaches in classification, this study explores the feasibility and efficacy\nof abstaining while uncertain in the context of LLMs within the domain of\nquestion-answering. We investigate two kinds of uncertainties, statistical\nuncertainty metrics and a distinct verbalized measure, termed as In-Dialogue\nUncertainty (InDU). Using these uncertainty measures combined with models with\nand without Reinforcement Learning with Human Feedback (RLHF), we show that in\nall three situations, abstention based on the right kind of uncertainty measure\ncan boost the reliability of LLMs. By sacrificing only a few highly uncertain\nsamples we can improve correctness by 2% to 8%, avoid 50% hallucinations via\ncorrectly identifying unanswerable questions and increase safety by 70% up to\n99% with almost no additional computational overhead.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10960v1",
    "published_date": "2024-04-16 23:56:38 UTC",
    "updated_date": "2024-04-16 23:56:38 UTC"
  },
  {
    "arxiv_id": "2404.10952v1",
    "title": "Can Language Models Solve Olympiad Programming?",
    "authors": [
      "Quan Shi",
      "Michael Tang",
      "Karthik Narasimhan",
      "Shunyu Yao"
    ],
    "abstract": "Computing olympiads contain some of the most challenging problems for humans,\nrequiring complex algorithmic reasoning, puzzle solving, in addition to\ngenerating efficient code. However, it has been understudied as a domain to\nevaluate language models (LMs). In this paper, we introduce the USACO benchmark\nwith 307 problems from the USA Computing Olympiad, along with high-quality unit\ntests, reference code, and official analyses for each problem. These resources\nenable us to construct and test a range of LM inference methods for competitive\nprogramming for the first time. We find GPT-4 only achieves a 8.7% pass@1\naccuracy with zero-shot chain-of-thought prompting, and our best inference\nmethod improves it to 20.2% using a combination of self-reflection and\nretrieval over episodic knowledge. However, this is far from solving the\nbenchmark. To better understand the remaining challenges, we design a novel\nhuman-in-the-loop study and surprisingly find that a small number of targeted\nhints enable GPT-4 to solve 13 out of 15 problems previously unsolvable by any\nmodel and method. Our benchmark, baseline methods, quantitative results, and\nqualitative analysis serve as an initial step toward LMs with grounded,\ncreative, and algorithmic reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and data: https://princeton-nlp.github.io/USACOBench/",
    "pdf_url": "http://arxiv.org/pdf/2404.10952v1",
    "published_date": "2024-04-16 23:27:38 UTC",
    "updated_date": "2024-04-16 23:27:38 UTC"
  },
  {
    "arxiv_id": "2404.10946v1",
    "title": "Information encoding and decoding in in-vitro neural networks on micro electrode arrays through stimulation timing",
    "authors": [
      "Trym A. E. Lindell",
      "Ola H. Ramstad",
      "Ionna Sandvig",
      "Axel Sandvig",
      "Stefano Nichele"
    ],
    "abstract": "A primary challenge in utilizing in-vitro biological neural networks for\ncomputations is finding good encoding and decoding schemes for inputting and\ndecoding data to and from the networks. Furthermore, identifying the optimal\nparameter settings for a given combination of encoding and decoding schemes\nadds additional complexity to this challenge. In this study we explore\nstimulation timing as an encoding method, i.e. we encode information as the\ndelay between stimulation pulses and identify the bounds and acuity of\nstimulation timings which produce linearly separable spike responses. We also\nexamine the optimal readout parameters for a linear decoder in the form of\nepoch length, time bin size and epoch offset. Our results suggest that\nstimulation timings between 36 and 436ms may be optimal for encoding and that\ndifferent combinations of readout parameters may be optimal at different parts\nof the evoked spike response.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "50 pages, 23 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10946v1",
    "published_date": "2024-04-16 22:59:40 UTC",
    "updated_date": "2024-04-16 22:59:40 UTC"
  },
  {
    "arxiv_id": "2404.10942v2",
    "title": "What Hides behind Unfairness? Exploring Dynamics Fairness in Reinforcement Learning",
    "authors": [
      "Zhihong Deng",
      "Jing Jiang",
      "Guodong Long",
      "Chengqi Zhang"
    ],
    "abstract": "In sequential decision-making problems involving sensitive attributes like\nrace and gender, reinforcement learning (RL) agents must carefully consider\nlong-term fairness while maximizing returns. Recent works have proposed many\ndifferent types of fairness notions, but how unfairness arises in RL problems\nremains unclear. In this paper, we address this gap in the literature by\ninvestigating the sources of inequality through a causal lens. We first analyse\nthe causal relationships governing the data generation process and decompose\nthe effect of sensitive attributes on long-term well-being into distinct\ncomponents. We then introduce a novel notion called dynamics fairness, which\nexplicitly captures the inequality stemming from environmental dynamics,\ndistinguishing it from those induced by decision-making or inherited from the\npast. This notion requires evaluating the expected changes in the next state\nand the reward induced by changing the value of the sensitive attribute while\nholding everything else constant. To quantitatively evaluate this\ncounterfactual concept, we derive identification formulas that allow us to\nobtain reliable estimations from data. Extensive experiments demonstrate the\neffectiveness of the proposed techniques in explaining, detecting, and reducing\ninequality in reinforcement learning. We publicly release code at\nhttps://github.com/familyld/InsightFair.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 9 figures, accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10942v2",
    "published_date": "2024-04-16 22:47:59 UTC",
    "updated_date": "2024-04-28 08:49:45 UTC"
  },
  {
    "arxiv_id": "2404.10934v1",
    "title": "Shears: Unstructured Sparsity with Neural Low-rank Adapter Search",
    "authors": [
      "J. Pablo Mu√±oz",
      "Jinjie Yuan",
      "Nilesh Jain"
    ],
    "abstract": "Recently, several approaches successfully demonstrated that weight-sharing\nNeural Architecture Search (NAS) can effectively explore a search space of\nelastic low-rank adapters (LoRA), allowing the parameter-efficient fine-tuning\n(PEFT) and compression of large language models. In this paper, we introduce a\nnovel approach called Shears, demonstrating how the integration of\ncost-effective sparsity and a proposed Neural Low-rank adapter Search (NLS)\nalgorithm can further improve the efficiency of PEFT approaches. Results\ndemonstrate the benefits of Shears compared to other methods, reaching high\nsparsity levels while improving or with little drop in accuracy, utilizing a\nsingle GPU for a pair of hours.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "2024 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (Industry Track)",
    "pdf_url": "http://arxiv.org/pdf/2404.10934v1",
    "published_date": "2024-04-16 22:12:36 UTC",
    "updated_date": "2024-04-16 22:12:36 UTC"
  },
  {
    "arxiv_id": "2404.10933v1",
    "title": "LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs",
    "authors": [
      "Taeho Kim",
      "Yanming Wang",
      "Vatshank Chaturvedi",
      "Lokesh Gupta",
      "Seyeon Kim",
      "Yongin Kwon",
      "Sangtae Ha"
    ],
    "abstract": "Fine-tuning pre-trained large language models (LLMs) with limited hardware\npresents challenges due to GPU memory constraints. Various distributed\nfine-tuning methods have been proposed to alleviate memory constraints on GPU.\nHowever, determining the most effective method for achieving rapid fine-tuning\nwhile preventing GPU out-of-memory issues in a given environment remains\nunclear. To address this challenge, we introduce LLMem, a solution that\nestimates the GPU memory consumption when applying distributed fine-tuning\nmethods across multiple GPUs and identifies the optimal method. We conduct GPU\nmemory usage estimation prior to fine-tuning, leveraging the fundamental\nstructure of transformer-based decoder models and the memory usage distribution\nof each method. Experimental results show that LLMem accurately estimates peak\nGPU memory usage on a single GPU, with error rates of up to 1.6%. Additionally,\nit shows an average error rate of 3.0% when applying distributed fine-tuning\nmethods to LLMs with more than a billion parameters on multi-GPU setups.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 9 figures, accepted to IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10933v1",
    "published_date": "2024-04-16 22:11:35 UTC",
    "updated_date": "2024-04-16 22:11:35 UTC"
  },
  {
    "arxiv_id": "2404.10924v1",
    "title": "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
    "authors": [
      "Croix Gyurek",
      "Niloy Talukder",
      "Mohammad Al Hasan"
    ],
    "abstract": "For natural language understanding and generation, embedding concepts using\nan order-based representation is an essential task. Unlike traditional point\nvector based representation, an order-based representation imposes geometric\nconstraints on the representation vectors for explicitly capturing various\nsemantic relationships that may exist between a pair of concepts. In existing\nliterature, several approaches on order-based embedding have been proposed,\nmostly focusing on capturing hierarchical relationships; examples include\nvectors in Euclidean space, complex, Hyperbolic, order, and Box Embedding. Box\nembedding creates region-based rich representation of concepts, but along the\nprocess it sacrifices simplicity, requiring a custom-made optimization scheme\nfor learning the representation. Hyperbolic embedding improves embedding\nquality by exploiting the ever-expanding property of Hyperbolic space, but it\nalso suffers from the same fate as box embedding as gradient descent like\noptimization is not simple in the Hyperbolic space. In this work, we propose\nBinder, a novel approach for order-based representation. Binder uses binary\nvectors for embedding, so the embedding vectors are compact with an order of\nmagnitude smaller footprint than other methods. Binder uses a simple and\nefficient optimization scheme for learning representation vectors with a linear\ntime complexity. Our comprehensive experimental results show that Binder is\nvery accurate, yielding competitive results on the representation task. But\nBinder stands out from its competitors on the transitive closure link\nprediction task as it can learn concept embeddings just from the direct edges,\nwhereas all existing order-based approaches rely on the indirect edges.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10924v1",
    "published_date": "2024-04-16 21:52:55 UTC",
    "updated_date": "2024-04-16 21:52:55 UTC"
  },
  {
    "arxiv_id": "2404.10907v3",
    "title": "Causal Effect Estimation Using Random Hyperplane Tessellations",
    "authors": [
      "Abhishek Dalvi",
      "Neil Ashtekar",
      "Vasant Honavar"
    ],
    "abstract": "Matching is one of the simplest approaches for estimating causal effects from\nobservational data. Matching techniques compare the observed outcomes across\npairs of individuals with similar covariate values but different treatment\nstatuses in order to estimate causal effects. However, traditional matching\ntechniques are unreliable given high-dimensional covariates due to the infamous\ncurse of dimensionality. To overcome this challenge, we propose a simple, fast,\nyet highly effective approach to matching using Random Hyperplane Tessellations\n(RHPT). First, we prove that the RHPT representation is an approximate\nbalancing score -- thus maintaining the strong ignorability assumption -- and\nprovide empirical evidence for this claim. Second, we report results of\nextensive experiments showing that matching using RHPT outperforms traditional\nmatching techniques and is competitive with state-of-the-art deep learning\nmethods for causal effect estimation. In addition, RHPT avoids the need for\ncomputationally expensive training of deep neural networks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "At CLeaR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10907v3",
    "published_date": "2024-04-16 20:53:58 UTC",
    "updated_date": "2024-09-19 20:40:49 UTC"
  },
  {
    "arxiv_id": "2404.10906v1",
    "title": "Towards a Research Community in Interpretable Reinforcement Learning: the InterpPol Workshop",
    "authors": [
      "Hector Kohler",
      "Quentin Delfosse",
      "Paul Festor",
      "Philippe Preux"
    ],
    "abstract": "Embracing the pursuit of intrinsically explainable reinforcement learning\nraises crucial questions: what distinguishes explainability from\ninterpretability? Should explainable and interpretable agents be developed\noutside of domains where transparency is imperative? What advantages do\ninterpretable policies offer over neural networks? How can we rigorously define\nand measure interpretability in policies, without user studies? What\nreinforcement learning paradigms,are the most suited to develop interpretable\nagents? Can Markov Decision Processes integrate interpretable state\nrepresentations? In addition to motivate an Interpretable RL community centered\naround the aforementioned questions, we propose the first venue dedicated to\nInterpretable RL: the InterpPol Workshop.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10906v1",
    "published_date": "2024-04-16 20:53:17 UTC",
    "updated_date": "2024-04-16 20:53:17 UTC"
  },
  {
    "arxiv_id": "2404.10901v1",
    "title": "CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information",
    "authors": [
      "Ziyi Zhou",
      "Ming Cheng",
      "Yanjun Cui",
      "Xingjian Diao",
      "Zhaorui Ma"
    ],
    "abstract": "The increasing number of diabetic patients is a serious issue in society\ntoday, which has significant negative impacts on people's health and the\ncountry's financial expenditures. Because diabetes may develop into potential\nserious complications, early glucose prediction for diabetic patients is\nnecessary for timely medical treatment. Existing glucose prediction methods\ntypically utilize patients' private data (e.g. age, gender, ethnicity) and\nphysiological parameters (e.g. blood pressure, heart rate) as reference\nfeatures for glucose prediction, which inevitably leads to privacy protection\nconcerns. Moreover, these models generally focus on either long-term\n(monthly-based) or short-term (minute-based) predictions. Long-term prediction\nmethods are generally inaccurate because of the external uncertainties that can\ngreatly affect the glucose values, while short-term ones fail to provide timely\nmedical guidance. Based on the above issues, we propose CrossGP, a novel\nmachine-learning framework for cross-day glucose prediction solely based on the\npatient's external activities without involving any physiological parameters.\nMeanwhile, we implement three baseline models for comparison. Extensive\nexperiments on Anderson's dataset strongly demonstrate the superior performance\nof CrossGP and prove its potential for future real-life applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10901v1",
    "published_date": "2024-04-16 20:40:59 UTC",
    "updated_date": "2024-04-16 20:40:59 UTC"
  },
  {
    "arxiv_id": "2404.10896v1",
    "title": "From a Lossless (~1.5:1) Compression Algorithm for Llama2 7B Weights to Variable Precision, Variable Range, Compressed Numeric Data Types for CNNs and LLMs",
    "authors": [
      "Vincenzo Liguori"
    ],
    "abstract": "This paper starts with a simple lossless ~1.5:1 compression algorithm for the\nweights of the Large Language Model (LLM) Llama2 7B [1] that can be implemented\nin ~200 LUTs in AMD FPGAs, processing over 800 million bfloat16 numbers per\nsecond. This framework is then extended to variable precision, variable range,\ncompressed numerical data types that are a user defined super set of both\nfloats and posits [2]. The paper then discusses a simple hardware\nimplementation of such format based on ANS (Asymmetrical Numeral Systems) [3]\nthat acts as a bridge between this flexible data format and a computational\nengine while, at the same time, achieving bandwidth reduction. An example of a\ntoken factory using weight compression and sharing is also given.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10896v1",
    "published_date": "2024-04-16 20:37:54 UTC",
    "updated_date": "2024-04-16 20:37:54 UTC"
  },
  {
    "arxiv_id": "2404.10890v1",
    "title": "Exploring Augmentation and Cognitive Strategies for AI based Synthetic Personae",
    "authors": [
      "Rafael Arias Gonzalez",
      "Steve DiPaola"
    ],
    "abstract": "Large language models (LLMs) hold potential for innovative HCI research,\nincluding the creation of synthetic personae. However, their black-box nature\nand propensity for hallucinations pose challenges. To address these\nlimitations, this position paper advocates for using LLMs as data augmentation\nsystems rather than zero-shot generators. We further propose the development of\nrobust cognitive and memory frameworks to guide LLM responses. Initial\nexplorations suggest that data enrichment, episodic memory, and self-reflection\ntechniques can improve the reliability of synthetic personae and open up new\navenues for HCI research.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper was accepted for publication: Proceedings of ACM Conf on\n  Human Factors in Computing Systems (CHI 24), Rafael Arias Gonzalez, Steve\n  DiPaola. Exploring Augmentation and Cognitive Strategies for Synthetic\n  Personae. ACM SigCHI, in Challenges and Opportunities of LLM-Based Synthetic\n  Personae and Data in HCI Workshop, 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10890v1",
    "published_date": "2024-04-16 20:22:12 UTC",
    "updated_date": "2024-04-16 20:22:12 UTC"
  },
  {
    "arxiv_id": "2404.10889v1",
    "title": "Cognitive-Motor Integration in Assessing Bimanual Motor Skills",
    "authors": [
      "Erim Yanik",
      "Xavier Intes",
      "Suvranu De"
    ],
    "abstract": "Accurate assessment of bimanual motor skills is essential across various\nprofessions, yet, traditional methods often rely on subjective assessments or\nfocus solely on motor actions, overlooking the integral role of cognitive\nprocesses. This study introduces a novel approach by leveraging deep neural\nnetworks (DNNs) to analyze and integrate both cognitive decision-making and\nmotor execution. We tested this methodology by assessing laparoscopic surgery\nskills within the Fundamentals of Laparoscopic Surgery program, which is a\nprerequisite for general surgery certification. Utilizing video capture of\nmotor actions and non-invasive functional near-infrared spectroscopy (fNIRS)\nfor measuring neural activations, our approach precisely classifies subjects by\nexpertise level and predicts FLS behavioral performance scores, significantly\nsurpassing traditional single-modality assessments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.10889v1",
    "published_date": "2024-04-16 20:20:23 UTC",
    "updated_date": "2024-04-16 20:20:23 UTC"
  },
  {
    "arxiv_id": "2404.10883v1",
    "title": "Automated Discovery of Functional Actual Causes in Complex Environments",
    "authors": [
      "Caleb Chuck",
      "Sankaran Vaidyanathan",
      "Stephen Giguere",
      "Amy Zhang",
      "David Jensen",
      "Scott Niekum"
    ],
    "abstract": "Reinforcement learning (RL) algorithms often struggle to learn policies that\ngeneralize to novel situations due to issues such as causal confusion,\noverfitting to irrelevant factors, and failure to isolate control of state\nfactors. These issues stem from a common source: a failure to accurately\nidentify and exploit state-specific causal relationships in the environment.\nWhile some prior works in RL aim to identify these relationships explicitly,\nthey rely on informal domain-specific heuristics such as spatial and temporal\nproximity. Actual causality offers a principled and general framework for\ndetermining the causes of particular events. However, existing definitions of\nactual cause often attribute causality to a large number of events, even if\nmany of them rarely influence the outcome. Prior work on actual causality\nproposes normality as a solution to this problem, but its existing\nimplementations are challenging to scale to complex and continuous-valued RL\nenvironments. This paper introduces functional actual cause (FAC), a framework\nthat uses context-specific independencies in the environment to restrict the\nset of actual causes. We additionally introduce Joint Optimization for Actual\nCause Inference (JACI), an algorithm that learns from observational data to\ninfer functional actual causes. We demonstrate empirically that FAC agrees with\nknown results on a suite of examples from the actual causality literature, and\nJACI identifies actual causes with significantly higher accuracy than existing\nheuristic methods in a set of complex, continuous-valued environments.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10883v1",
    "published_date": "2024-04-16 20:04:29 UTC",
    "updated_date": "2024-04-16 20:04:29 UTC"
  },
  {
    "arxiv_id": "2404.10880v1",
    "title": "HumMUSS: Human Motion Understanding using State Space Models",
    "authors": [
      "Arnab Kumar Mondal",
      "Stefano Alletto",
      "Denis Tome"
    ],
    "abstract": "Understanding human motion from video is essential for a range of\napplications, including pose estimation, mesh recovery and action recognition.\nWhile state-of-the-art methods predominantly rely on transformer-based\narchitectures, these approaches have limitations in practical scenarios.\nTransformers are slower when sequentially predicting on a continuous stream of\nframes in real-time, and do not generalize to new frame rates. In light of\nthese constraints, we propose a novel attention-free spatiotemporal model for\nhuman motion understanding building upon recent advancements in state space\nmodels. Our model not only matches the performance of transformer-based models\nin various motion understanding tasks but also brings added benefits like\nadaptability to different video frame rates and enhanced training speed when\nworking with longer sequence of keypoints. Moreover, the proposed model\nsupports both offline and real-time applications. For real-time sequential\nprediction, our model is both memory efficient and several times faster than\ntransformer-based approaches while maintaining their high accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 24",
    "pdf_url": "http://arxiv.org/pdf/2404.10880v1",
    "published_date": "2024-04-16 19:59:21 UTC",
    "updated_date": "2024-04-16 19:59:21 UTC"
  },
  {
    "arxiv_id": "2404.10849v2",
    "title": "End-To-End Training and Testing Gamification Framework to Learn Human Highway Driving",
    "authors": [
      "Satya R. Jaladi",
      "Zhimin Chen",
      "Narahari R. Malayanur",
      "Raja M. Macherla",
      "Bing Li"
    ],
    "abstract": "The current autonomous stack is well modularized and consists of perception,\ndecision making and control in a handcrafted framework. With the advances in\nartificial intelligence (AI) and computing resources, researchers have been\npushing the development of end-to-end AI for autonomous driving, at least in\nproblems of small searching space such as in highway scenarios, and more and\nmore photorealistic simulation will be critical for efficient learning. In this\nresearch, we propose a novel game-based end-to-end learning and testing\nframework for autonomous vehicle highway driving, by learning from human\ndriving skills. Firstly, we utilize the popular game Grand Theft Auto V (GTA V)\nto collect highway driving data with our proposed programmable labels. Then, an\nend-to-end architecture predicts the steering and throttle values that control\nthe vehicle by the image of the game screen. The predicted control values are\nsent to the game via a virtual controller to keep the vehicle in lane and avoid\ncollisions with other vehicles on the road. The proposed solution is validated\nin GTA V games, and the results demonstrate the effectiveness of this\nend-to-end gamification framework for learning human driving skills.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by ITSC",
    "pdf_url": "http://arxiv.org/pdf/2404.10849v2",
    "published_date": "2024-04-16 18:51:58 UTC",
    "updated_date": "2024-04-18 05:14:08 UTC"
  },
  {
    "arxiv_id": "2404.10848v1",
    "title": "A LayoutLMv3-Based Model for Enhanced Relation Extraction in Visually-Rich Documents",
    "authors": [
      "Wiam Adnan",
      "Joel Tang",
      "Yassine Bel Khayat Zouggari",
      "Seif Edinne Laatiri",
      "Laurent Lam",
      "Fabien Caspani"
    ],
    "abstract": "Document Understanding is an evolving field in Natural Language Processing\n(NLP). In particular, visual and spatial features are essential in addition to\nthe raw text itself and hence, several multimodal models were developed in the\nfield of Visual Document Understanding (VDU). However, while research is mainly\nfocused on Key Information Extraction (KIE), Relation Extraction (RE) between\nidentified entities is still under-studied. For instance, RE is crucial to\nregroup entities or obtain a comprehensive hierarchy of data in a document. In\nthis paper, we present a model that, initialized from LayoutLMv3, can match or\noutperform the current state-of-the-art results in RE applied to Visually-Rich\nDocuments (VRD) on FUNSD and CORD datasets, without any specific pre-training\nand with fewer parameters. We also report an extensive ablation study performed\non FUNSD, highlighting the great impact of certain features and modelization\nchoices on the performances.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the International Conference on Document Analysis and\n  Recognition (ICDAR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.10848v1",
    "published_date": "2024-04-16 18:50:57 UTC",
    "updated_date": "2024-04-16 18:50:57 UTC"
  },
  {
    "arxiv_id": "2404.10843v1",
    "title": "Geometric Neural Operators (GNPs) for Data-Driven Deep Learning of Non-Euclidean Operators",
    "authors": [
      "Blaine Quackenbush",
      "Paul J. Atzberger"
    ],
    "abstract": "We introduce Geometric Neural Operators (GNPs) for accounting for geometric\ncontributions in data-driven deep learning of operators. We show how GNPs can\nbe used (i) to estimate geometric properties, such as the metric and\ncurvatures, (ii) to approximate Partial Differential Equations (PDEs) on\nmanifolds, (iii) learn solution maps for Laplace-Beltrami (LB) operators, and\n(iv) to solve Bayesian inverse problems for identifying manifold shapes. The\nmethods allow for handling geometries of general shape including point-cloud\nrepresentations. The developed GNPs provide approaches for incorporating the\nroles of geometry in data-driven learning of operators.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10843v1",
    "published_date": "2024-04-16 18:43:27 UTC",
    "updated_date": "2024-04-16 18:43:27 UTC"
  },
  {
    "arxiv_id": "2404.10786v1",
    "title": "Sustainability of Data Center Digital Twins with Reinforcement Learning",
    "authors": [
      "Soumyendu Sarkar",
      "Avisek Naug",
      "Antonio Guillen",
      "Ricardo Luna",
      "Vineet Gundecha",
      "Ashwin Ramesh Babu",
      "Sajad Mousavi"
    ],
    "abstract": "The rapid growth of machine learning (ML) has led to an increased demand for\ncomputational power, resulting in larger data centers (DCs) and higher energy\nconsumption. To address this issue and reduce carbon emissions, intelligent\ndesign and control of DC components such as IT servers, cabinets, HVAC cooling,\nflexible load shifting, and battery energy storage are essential. However, the\ncomplexity of designing and controlling them in tandem presents a significant\nchallenge. While some individual components like CFD-based design and\nReinforcement Learning (RL) based HVAC control have been researched, there's a\ngap in the holistic design and optimization covering all elements\nsimultaneously. To tackle this, we've developed DCRL-Green, a multi-agent RL\nenvironment that empowers the ML community to design data centers and research,\ndevelop, and refine RL controllers for carbon footprint reduction in DCs. It is\na flexible, modular, scalable, and configurable platform that can handle large\nHigh Performance Computing (HPC) clusters. Furthermore, in its default setup,\nDCRL-Green provides a benchmark for evaluating single as well as multi-agent RL\nalgorithms. It easily allows users to subclass the default implementations and\ndesign their own control approaches, encouraging community development for\nsustainable data centers. Open Source Link:\nhttps://github.com/HewlettPackard/dc-rl",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.DC",
    "comment": "2024 Proceedings of the AAAI Conference on Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2404.10786v1",
    "published_date": "2024-04-16 18:22:30 UTC",
    "updated_date": "2024-04-16 18:22:30 UTC"
  },
  {
    "arxiv_id": "2404.10830v2",
    "title": "Fewer Truncations Improve Language Modeling",
    "authors": [
      "Hantian Ding",
      "Zijian Wang",
      "Giovanni Paolini",
      "Varun Kumar",
      "Anoop Deoras",
      "Dan Roth",
      "Stefano Soatto"
    ],
    "abstract": "In large language model training, input documents are typically concatenated\ntogether and then split into sequences of equal length to avoid padding tokens.\nDespite its efficiency, the concatenation approach compromises data integrity\n-- it inevitably breaks many documents into incomplete pieces, leading to\nexcessive truncations that hinder the model from learning to compose logically\ncoherent and factually consistent content that is grounded on the complete\ncontext. To address the issue, we propose Best-fit Packing, a scalable and\nefficient method that packs documents into training sequences through\nlength-aware combinatorial optimization. Our method completely eliminates\nunnecessary truncations while retaining the same training efficiency as\nconcatenation. Empirical results from both text and code pre-training show that\nour method achieves superior performance (e.g., relatively +4.7% on reading\ncomprehension; +16.8% in context following; and +9.2% on program synthesis),\nand reduces closed-domain hallucination effectively by up to 58.3%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10830v2",
    "published_date": "2024-04-16 18:08:29 UTC",
    "updated_date": "2024-05-02 17:10:44 UTC"
  },
  {
    "arxiv_id": "2404.10824v2",
    "title": "Decoupled Weight Decay for Any $p$ Norm",
    "authors": [
      "Nadav Joseph Outmezguine",
      "Noam Levi"
    ],
    "abstract": "With the success of deep neural networks (NNs) in a variety of domains, the\ncomputational and storage requirements for training and deploying large NNs\nhave become a bottleneck for further improvements. Sparsification has\nconsequently emerged as a leading approach to tackle these issues. In this\nwork, we consider a simple yet effective approach to sparsification, based on\nthe Bridge, or $L_p$ regularization during training. We introduce a novel\nweight decay scheme, which generalizes the standard $L_2$ weight decay to any\n$p$ norm. We show that this scheme is compatible with adaptive optimizers, and\navoids the gradient divergence associated with $0<p<1$ norms. We empirically\ndemonstrate that it leads to highly sparse networks, while maintaining\ngeneralization performance comparable to standard $L_2$ regularization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "GitHub link: https://github.com/Nadav-out/PAdam",
    "pdf_url": "http://arxiv.org/pdf/2404.10824v2",
    "published_date": "2024-04-16 18:02:15 UTC",
    "updated_date": "2024-04-22 20:31:04 UTC"
  },
  {
    "arxiv_id": "2404.10775v3",
    "title": "COMBO: Compositional World Models for Embodied Multi-Agent Cooperation",
    "authors": [
      "Hongxin Zhang",
      "Zeyuan Wang",
      "Qiushi Lyu",
      "Zheyuan Zhang",
      "Sunli Chen",
      "Tianmin Shu",
      "Behzad Dariush",
      "Kwonjoon Lee",
      "Yilun Du",
      "Chuang Gan"
    ],
    "abstract": "In this paper, we investigate the problem of embodied multi-agent\ncooperation, where decentralized agents must cooperate given only egocentric\nviews of the world. To effectively plan in this setting, in contrast to\nlearning world dynamics in a single-agent scenario, we must simulate world\ndynamics conditioned on an arbitrary number of agents' actions given only\npartial egocentric visual observations of the world. To address this issue of\npartial observability, we first train generative models to estimate the overall\nworld state given partial egocentric observations. To enable accurate\nsimulation of multiple sets of actions on this world state, we then propose to\nlearn a compositional world model for multi-agent cooperation by factorizing\nthe naturally composable joint actions of multiple agents and compositionally\ngenerating the video conditioned on the world state. By leveraging this\ncompositional world model, in combination with Vision Language Models to infer\nthe actions of other agents, we can use a tree search procedure to integrate\nthese modules and facilitate online cooperative planning. We evaluate our\nmethods on three challenging benchmarks with 2-4 agents. The results show our\ncompositional world model is effective and the framework enables the embodied\nagents to cooperate efficiently with different agents across various tasks and\nan arbitrary number of agents, showing the promising future of our proposed\nmethods. More videos can be found at\nhttps://umass-embodied-agi.github.io/COMBO/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at ICLR 2025. 24 pages. The first three authors contributed\n  equally",
    "pdf_url": "http://arxiv.org/pdf/2404.10775v3",
    "published_date": "2024-04-16 17:59:11 UTC",
    "updated_date": "2025-04-16 00:50:58 UTC"
  },
  {
    "arxiv_id": "2404.10774v2",
    "title": "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents",
    "authors": [
      "Liyan Tang",
      "Philippe Laban",
      "Greg Durrett"
    ],
    "abstract": "Recognizing if LLM output can be grounded in evidence is central to many\ntasks in NLP: retrieval-augmented generation, summarization, document-grounded\ndialogue, and more. Current approaches to this kind of fact-checking are based\non verifying each piece of a model generation against potential evidence using\nan LLM. However, this process can be very computationally expensive, requiring\nmany calls to a model to check a single response. In this work, we show how to\nbuild small fact-checking models that have GPT-4-level performance but for 400x\nlower cost. We do this by constructing synthetic training data with GPT-4,\nwhich involves creating realistic yet challenging instances of factual errors\nvia a structured generation procedure. Training on this data teaches models to\ncheck each fact in the claim and recognize synthesis of information across\nsentences. For evaluation, we unify datasets from recent work on fact-checking\nand grounding LLM generations into a new benchmark, LLM-AggreFact. Our best\nsystem MiniCheck-FT5 (770M parameters) outperforms all systems of comparable\nsize and reaches GPT-4 accuracy. We release LLM-AggreFact, code for data\nsynthesis, and models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10774v2",
    "published_date": "2024-04-16 17:59:10 UTC",
    "updated_date": "2024-10-01 15:39:48 UTC"
  },
  {
    "arxiv_id": "2404.10763v1",
    "title": "LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?",
    "authors": [
      "Yuchi Wang",
      "Shuhuai Ren",
      "Rundong Gao",
      "Linli Yao",
      "Qingyan Guo",
      "Kaikai An",
      "Jianhong Bai",
      "Xu Sun"
    ],
    "abstract": "Diffusion models have exhibited remarkable capabilities in text-to-image\ngeneration. However, their performance in image-to-text generation,\nspecifically image captioning, has lagged behind Auto-Regressive (AR) models,\ncasting doubt on their applicability for such tasks. In this work, we revisit\ndiffusion models, highlighting their capacity for holistic context modeling and\nparallel decoding. With these benefits, diffusion models can alleviate the\ninherent limitations of AR methods, including their slow inference speed, error\npropagation, and unidirectional constraints. Furthermore, we identify the prior\nunderperformance of diffusion models stemming from the absence of an effective\nlatent space for image-text alignment, and the discrepancy between continuous\ndiffusion processes and discrete textual data. In response, we introduce a\nnovel architecture, LaDiC, which utilizes a split BERT to create a dedicated\nlatent space for captions and integrates a regularization module to manage\nvarying text lengths. Our framework also includes a diffuser for semantic\nimage-to-text conversion and a Back&Refine technique to enhance token\ninteractivity during inference. LaDiC achieves state-of-the-art performance for\ndiffusion-based methods on the MS COCO dataset with 38.2 BLEU@4 and 126.2\nCIDEr, demonstrating exceptional performance without pre-training or ancillary\nmodules. This indicates strong competitiveness with AR models, revealing the\npreviously untapped potential of diffusion models in image-to-text generation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10763v1",
    "published_date": "2024-04-16 17:47:16 UTC",
    "updated_date": "2024-04-16 17:47:16 UTC"
  },
  {
    "arxiv_id": "2404.10740v3",
    "title": "N-Agent Ad Hoc Teamwork",
    "authors": [
      "Caroline Wang",
      "Arrasy Rahman",
      "Ishan Durugkar",
      "Elad Liebman",
      "Peter Stone"
    ],
    "abstract": "Current approaches to learning cooperative multi-agent behaviors assume\nrelatively restrictive settings. In standard fully cooperative multi-agent\nreinforcement learning, the learning algorithm controls $\\textit{all}$ agents\nin the scenario, while in ad hoc teamwork, the learning algorithm usually\nassumes control over only a $\\textit{single}$ agent in the scenario. However,\nmany cooperative settings in the real world are much less restrictive. For\nexample, in an autonomous driving scenario, a company might train its cars with\nthe same learning algorithm, yet once on the road, these cars must cooperate\nwith cars from another company. Towards expanding the class of scenarios that\ncooperative learning methods may optimally address, we introduce $N$-agent ad\nhoc teamwork (NAHT), where a set of autonomous agents must interact and\ncooperate with dynamically varying numbers and types of teammates. This paper\nformalizes the problem, and proposes the Policy Optimization with Agent\nModelling (POAM) algorithm. POAM is a policy gradient, multi-agent\nreinforcement learning approach to the NAHT problem, that enables adaptation to\ndiverse teammate behaviors by learning representations of teammate behaviors.\nEmpirical evaluation on tasks from the multi-agent particle environment and\nStarCraft II shows that POAM improves cooperative task returns compared to\nbaseline approaches, and enables out-of-distribution generalization to unseen\nteammates.",
    "categories": [
      "cs.AI",
      "I.2.11; I.2.1; I.2.6; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10740v3",
    "published_date": "2024-04-16 17:13:08 UTC",
    "updated_date": "2024-10-04 16:08:52 UTC"
  },
  {
    "arxiv_id": "2404.10733v1",
    "title": "Bootstrapping Linear Models for Fast Online Adaptation in Human-Agent Collaboration",
    "authors": [
      "Benjamin A Newman",
      "Chris Paxton",
      "Kris Kitani",
      "Henny Admoni"
    ],
    "abstract": "Agents that assist people need to have well-initialized policies that can\nadapt quickly to align with their partners' reward functions. Initializing\npolicies to maximize performance with unknown partners can be achieved by\nbootstrapping nonlinear models using imitation learning over large, offline\ndatasets. Such policies can require prohibitive computation to fine-tune\nin-situ and therefore may miss critical run-time information about a partner's\nreward function as expressed through their immediate behavior. In contrast,\nonline logistic regression using low-capacity models performs rapid inference\nand fine-tuning updates and thus can make effective use of immediate in-task\nbehavior for reward function alignment. However, these low-capacity models\ncannot be bootstrapped as effectively by offline datasets and thus have poor\ninitializations. We propose BLR-HAC, Bootstrapped Logistic Regression for Human\nAgent Collaboration, which bootstraps large nonlinear models to learn the\nparameters of a low-capacity model which then uses online logistic regression\nfor updates during collaboration. We test BLR-HAC in a simulated surface\nrearrangement task and demonstrate that it achieves higher zero-shot accuracy\nthan shallow methods and takes far less computation to adapt online while still\nachieving similar performance to fine-tuned, large nonlinear models. For code,\nplease see our project page https://sites.google.com/view/blr-hac.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures, Accepted to AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10733v1",
    "published_date": "2024-04-16 17:05:43 UTC",
    "updated_date": "2024-04-16 17:05:43 UTC"
  },
  {
    "arxiv_id": "2404.10731v1",
    "title": "What is Meant by AGI? On the Definition of Artificial General Intelligence",
    "authors": [
      "Bowen Xu"
    ],
    "abstract": "This paper aims to establish a consensus on AGI's definition. General\nintelligence refers to the adaptation to open environments according to certain\nprinciples using limited resources. It emphasizes that adaptation or learning\nis an indispensable property of intelligence, and places the controversial part\nwithin the principles of intelligence, which can be described from different\nperspectives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10731v1",
    "published_date": "2024-04-16 17:03:50 UTC",
    "updated_date": "2024-04-16 17:03:50 UTC"
  },
  {
    "arxiv_id": "2404.10730v1",
    "title": "Insight Gained from Migrating a Machine Learning Model to Intelligence Processing Units",
    "authors": [
      "Hieu Le",
      "Zhenhua He",
      "Mai Le",
      "Dhruva K. Chakravorty",
      "Lisa M. Perez",
      "Akhil Chilumuru",
      "Yan Yao",
      "Jiefu Chen"
    ],
    "abstract": "The discoveries in this paper show that Intelligence Processing Units (IPUs)\noffer a viable accelerator alternative to GPUs for machine learning (ML)\napplications within the fields of materials science and battery research. We\ninvestigate the process of migrating a model from GPU to IPU and explore\nseveral optimization techniques, including pipelining and gradient\naccumulation, aimed at enhancing the performance of IPU-based models.\nFurthermore, we have effectively migrated a specialized model to the IPU\nplatform. This model is employed for predicting effective conductivity, a\nparameter crucial in ion transport processes, which govern the performance of\nmultiple charge and discharge cycles of batteries. The model utilizes a\nConvolutional Neural Network (CNN) architecture to perform prediction tasks for\neffective conductivity. The performance of this model on the IPU is found to be\ncomparable to its execution on GPUs. We also analyze the utilization and\nperformance of Graphcore's Bow IPU. Through benchmark tests, we observe\nsignificantly improved performance with the Bow IPU when compared to its\npredecessor, the Colossus IPU.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: This version has been removed by arXiv\n  administrators as the submitter did not have the right to agree to the\n  license at the time of submission",
    "pdf_url": "http://arxiv.org/pdf/2404.10730v1",
    "published_date": "2024-04-16 17:02:52 UTC",
    "updated_date": "2024-04-16 17:02:52 UTC"
  },
  {
    "arxiv_id": "2404.10717v1",
    "title": "Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation",
    "authors": [
      "Lijian Li"
    ],
    "abstract": "Recently, prototype learning has emerged in semi-supervised medical image\nsegmentation and achieved remarkable performance. However, the scarcity of\nlabeled data limits the expressiveness of prototypes in previous methods,\npotentially hindering the complete representation of prototypes for class\nembedding. To address this problem, we propose the Mixed Prototype Consistency\nLearning (MPCL) framework, which includes a Mean Teacher and an auxiliary\nnetwork. The Mean Teacher generates prototypes for labeled and unlabeled data,\nwhile the auxiliary network produces additional prototypes for mixed data\nprocessed by CutMix. Through prototype fusion, mixed prototypes provide extra\nsemantic information to both labeled and unlabeled prototypes. High-quality\nglobal prototypes for each class are formed by fusing two enhanced prototypes,\noptimizing the distribution of hidden embeddings used in consistency learning.\nExtensive experiments on the left atrium and type B aortic dissection datasets\ndemonstrate MPCL's superiority over previous state-of-the-art approaches,\nconfirming the effectiveness of our framework. The code will be released soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10717v1",
    "published_date": "2024-04-16 16:51:12 UTC",
    "updated_date": "2024-04-16 16:51:12 UTC"
  },
  {
    "arxiv_id": "2404.10704v1",
    "title": "Question Difficulty Ranking for Multiple-Choice Reading Comprehension",
    "authors": [
      "Vatsal Raina",
      "Mark Gales"
    ],
    "abstract": "Multiple-choice (MC) tests are an efficient method to assess English\nlearners. It is useful for test creators to rank candidate MC questions by\ndifficulty during exam curation. Typically, the difficulty is determined by\nhaving human test takers trial the questions in a pretesting stage. However,\nthis is expensive and not scalable. Therefore, we explore automated approaches\nto rank MC questions by difficulty. However, there is limited data for explicit\ntraining of a system for difficulty scores. Hence, we compare task transfer and\nzero-shot approaches: task transfer adapts level classification and reading\ncomprehension systems for difficulty ranking while zero-shot prompting of\ninstruction finetuned language models contrasts absolute assessment against\ncomparative. It is found that level classification transfers better than\nreading comprehension. Additionally, zero-shot comparative assessment is more\neffective at difficulty ranking than the absolute assessment and even the task\ntransfer approaches at question difficulty ranking with a Spearman's\ncorrelation of 40.4%. Combining the systems is observed to further boost the\ncorrelation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10704v1",
    "published_date": "2024-04-16 16:23:10 UTC",
    "updated_date": "2024-04-16 16:23:10 UTC"
  },
  {
    "arxiv_id": "2404.10683v1",
    "title": "Simplex Decomposition for Portfolio Allocation Constraints in Reinforcement Learning",
    "authors": [
      "David Winkel",
      "Niklas Strau√ü",
      "Matthias Schubert",
      "Thomas Seidl"
    ],
    "abstract": "Portfolio optimization tasks describe sequential decision problems in which\nthe investor's wealth is distributed across a set of assets. Allocation\nconstraints are used to enforce minimal or maximal investments into particular\nsubsets of assets to control for objectives such as limiting the portfolio's\nexposure to a certain sector due to environmental concerns. Although methods\nfor constrained Reinforcement Learning (CRL) can optimize policies while\nconsidering allocation constraints, it can be observed that these general\nmethods yield suboptimal results. In this paper, we propose a novel approach to\nhandle allocation constraints based on a decomposition of the constraint action\nspace into a set of unconstrained allocation problems. In particular, we\nexamine this approach for the case of two constraints. For example, an investor\nmay wish to invest at least a certain percentage of the portfolio into green\ntechnologies while limiting the investment in the fossil energy sector. We show\nthat the action space of the task is equivalent to the decomposed action space,\nand introduce a new reinforcement learning (RL) approach CAOSD, which is built\non top of the decomposition. The experimental evaluation on real-world\nNasdaq-100 data demonstrates that our approach consistently outperforms\nstate-of-the-art CRL benchmarks for portfolio optimization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10683v1",
    "published_date": "2024-04-16 16:00:59 UTC",
    "updated_date": "2024-04-16 16:00:59 UTC"
  },
  {
    "arxiv_id": "2404.10679v1",
    "title": "HSVI-based Online Minimax Strategies for Partially Observable Stochastic Games with Neural Perception Mechanisms",
    "authors": [
      "Rui Yan",
      "Gabriel Santos",
      "Gethin Norman",
      "David Parker",
      "Marta Kwiatkowska"
    ],
    "abstract": "We consider a variant of continuous-state partially-observable stochastic\ngames with neural perception mechanisms and an asymmetric information\nstructure. One agent has partial information, with the observation function\nimplemented as a neural network, while the other agent is assumed to have full\nknowledge of the state. We present, for the first time, an efficient online\nmethod to compute an $\\varepsilon$-minimax strategy profile, which requires\nonly one linear program to be solved for each agent at every stage, instead of\na complex estimation of opponent counterfactual values. For the\npartially-informed agent, we propose a continual resolving approach which uses\nlower bounds, pre-computed offline with heuristic search value iteration\n(HSVI), instead of opponent counterfactual values. This inherits the soundness\nof continual resolving at the cost of pre-computing the bound. For the\nfully-informed agent, we propose an inferred-belief strategy, where the agent\nmaintains an inferred belief about the belief of the partially-informed agent\nbased on (offline) upper bounds from HSVI, guaranteeing $\\varepsilon$-distance\nto the value of the game at the initial belief known to both agents.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "12 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10679v1",
    "published_date": "2024-04-16 15:58:20 UTC",
    "updated_date": "2024-04-16 15:58:20 UTC"
  },
  {
    "arxiv_id": "2404.10662v2",
    "title": "Continual Offline Reinforcement Learning via Diffusion-based Dual Generative Replay",
    "authors": [
      "Jinmei Liu",
      "Wenbin Li",
      "Xiangyu Yue",
      "Shilin Zhang",
      "Chunlin Chen",
      "Zhi Wang"
    ],
    "abstract": "We study continual offline reinforcement learning, a practical paradigm that\nfacilitates forward transfer and mitigates catastrophic forgetting to tackle\nsequential offline tasks. We propose a dual generative replay framework that\nretains previous knowledge by concurrent replay of generated pseudo-data.\nFirst, we decouple the continual learning policy into a diffusion-based\ngenerative behavior model and a multi-head action evaluation model, allowing\nthe policy to inherit distributional expressivity for encompassing a\nprogressive range of diverse behaviors. Second, we train a task-conditioned\ndiffusion model to mimic state distributions of past tasks. Generated states\nare paired with corresponding responses from the behavior generator to\nrepresent old tasks with high-fidelity replayed samples. Finally, by\ninterleaving pseudo samples with real ones of the new task, we continually\nupdate the state and behavior generators to model progressively diverse\nbehaviors, and regularize the multi-head critic via behavior cloning to\nmitigate forgetting. Experiments demonstrate that our method achieves better\nforward transfer with less forgetting, and closely approximates the results of\nusing previous ground-truth data due to its high-fidelity replay of the sample\nspace. Our code is available at\n\\href{https://github.com/NJU-RL/CuGRO}{https://github.com/NJU-RL/CuGRO}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10662v2",
    "published_date": "2024-04-16 15:39:11 UTC",
    "updated_date": "2024-04-18 04:49:02 UTC"
  },
  {
    "arxiv_id": "2404.10646v1",
    "title": "Efficient Parking Search using Shared Fleet Data",
    "authors": [
      "Niklas Strau√ü",
      "Lukas Rottkamp",
      "Sebatian Schmoll",
      "Matthias Schubert"
    ],
    "abstract": "Finding an available on-street parking spot is a relevant problem of\nday-to-day life. In recent years, cities such as Melbourne and San Francisco\ndeployed sensors that provide real-time information about the occupation of\nparking spots. Finding a free parking spot in such a smart environment can be\nmodeled and solved as a Markov decision process (MDP). The problem has to\nconsider uncertainty as available parking spots might not remain available\nuntil arrival due to other vehicles also claiming spots in the meantime.\nKnowing the parking intention of every vehicle in the environment would\neliminate this uncertainty. Unfortunately, it does currently not seem realistic\nto have such data from all vehicles. In contrast, acquiring data from a subset\nof vehicles or a vehicle fleet appears feasible and has the potential to reduce\nuncertainty.\n  In this paper, we examine the question of how useful sharing data within a\nvehicle fleet might be for the search times of particular drivers. We use fleet\ndata to better estimate the availability of parking spots at arrival. Since\noptimal solutions for large scenarios are infeasible, we base our method on\napproximate solutions, which have been shown to perform well in single-agent\nsettings. Our experiments are conducted on a simulation using real-world and\nsynthetic data from the city of Melbourne. The results indicate that fleet data\ncan significantly reduce search times for an available parking spot.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Long Version; published at 2021 22nd IEEE International Conference on\n  Mobile Data Management (MDM)",
    "pdf_url": "http://arxiv.org/pdf/2404.10646v1",
    "published_date": "2024-04-16 15:20:28 UTC",
    "updated_date": "2024-04-16 15:20:28 UTC"
  },
  {
    "arxiv_id": "2404.10645v1",
    "title": "Continuous Control Reinforcement Learning: Distributed Distributional DrQ Algorithms",
    "authors": [
      "Zehao Zhou"
    ],
    "abstract": "Distributed Distributional DrQ is a model-free and off-policy RL algorithm\nfor continuous control tasks based on the state and observation of the agent,\nwhich is an actor-critic method with the data-augmentation and the\ndistributional perspective of critic value function. Aim to learn to control\nthe agent and master some tasks in a high-dimensional continuous space. DrQ-v2\nuses DDPG as the backbone and achieves out-performance in various continuous\ncontrol tasks. Here Distributed Distributional DrQ uses Distributed\nDistributional DDPG as the backbone, and this modification aims to achieve\nbetter performance in some hard continuous control tasks through the better\nexpression ability of distributional value function and distributed actor\npolicies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10645v1",
    "published_date": "2024-04-16 15:18:40 UTC",
    "updated_date": "2024-04-16 15:18:40 UTC"
  },
  {
    "arxiv_id": "2404.10618v2",
    "title": "Private Attribute Inference from Images with Vision-Language Models",
    "authors": [
      "Batuhan T√∂mek√ße",
      "Mark Vero",
      "Robin Staab",
      "Martin Vechev"
    ],
    "abstract": "As large language models (LLMs) become ubiquitous in our daily tasks and\ndigital interactions, associated privacy risks are increasingly in focus. While\nLLM privacy research has primarily focused on the leakage of model training\ndata, it has recently been shown that LLMs can make accurate privacy-infringing\ninferences from previously unseen texts. With the rise of vision-language\nmodels (VLMs), capable of understanding both images and text, a key question is\nwhether this concern transfers to the previously unexplored domain of benign\nimages posted online. To answer this question, we compile an image dataset with\nhuman-annotated labels of the image owner's personal attributes. In order to\nunderstand the privacy risks posed by VLMs beyond traditional human attribute\nrecognition, our dataset consists of images where the inferable private\nattributes do not stem from direct depictions of humans. On this dataset, we\nevaluate 7 state-of-the-art VLMs, finding that they can infer various personal\nattributes at up to 77.6% accuracy. Concerningly, we observe that accuracy\nscales with the general capabilities of the models, implying that future models\ncan be misused as stronger inferential adversaries, establishing an imperative\nfor the development of adequate defenses.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10618v2",
    "published_date": "2024-04-16 14:42:49 UTC",
    "updated_date": "2024-11-04 11:11:49 UTC"
  },
  {
    "arxiv_id": "2404.10597v1",
    "title": "Hardware-aware training of models with synaptic delays for digital event-driven neuromorphic processors",
    "authors": [
      "Alberto Patino-Saucedo",
      "Roy Meijer",
      "Amirreza Yousefzadeh",
      "Manil-Dev Gomony",
      "Federico Corradi",
      "Paul Detteter",
      "Laura Garrido-Regife",
      "Bernabe Linares-Barranco",
      "Manolis Sifalakis"
    ],
    "abstract": "Configurable synaptic delays are a basic feature in many neuromorphic neural\nnetwork hardware accelerators. However, they have been rarely used in model\nimplementations, despite their promising impact on performance and efficiency\nin tasks that exhibit complex (temporal) dynamics, as it has been unclear how\nto optimize them. In this work, we propose a framework to train and deploy, in\ndigital neuromorphic hardware, highly performing spiking neural network models\n(SNNs) where apart from the synaptic weights, the per-synapse delays are also\nco-optimized. Leveraging spike-based back-propagation-through-time, the\ntraining accounts for both platform constraints, such as synaptic weight\nprecision and the total number of parameters per core, as a function of the\nnetwork size. In addition, a delay pruning technique is used to reduce memory\nfootprint with a low cost in performance. We evaluate trained models in two\nneuromorphic digital hardware platforms: Intel Loihi and Imec Seneca. Loihi\noffers synaptic delay support using the so-called Ring-Buffer hardware\nstructure. Seneca does not provide native hardware support for synaptic delays.\nA second contribution of this paper is therefore a novel area- and\nmemory-efficient hardware structure for acceleration of synaptic delays, which\nwe have integrated in Seneca. The evaluated benchmark involves several models\nfor solving the SHD (Spiking Heidelberg Digits) classification task, where\nminimal accuracy degradation during the transition from software to hardware is\ndemonstrated. To our knowledge, this is the first work showcasing how to train\nand deploy hardware-aware models parameterized with synaptic delays, on\nmulticore neuromorphic hardware accelerators.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10597v1",
    "published_date": "2024-04-16 14:22:58 UTC",
    "updated_date": "2024-04-16 14:22:58 UTC"
  },
  {
    "arxiv_id": "2404.10591v2",
    "title": "Learning Symbolic Task Representation from a Human-Led Demonstration: A Memory to Store, Retrieve, Consolidate, and Forget Experiences",
    "authors": [
      "Luca Buoncompagni",
      "Fulvio Mastrogiovanni"
    ],
    "abstract": "We present a symbolic learning framework inspired by cognitive-like memory\nfunctionalities (i.e., storing, retrieving, consolidating and forgetting) to\ngenerate task representations to support high-level task planning and knowledge\nbootstrapping. We address a scenario involving a non-expert human, who performs\na single task demonstration, and a robot, which online learns structured\nknowledge to re-execute the task based on experiences, i.e., observations. We\nconsider a one-shot learning process based on non-annotated data to store an\nintelligible representation of the task, which can be refined through\ninteraction, e.g., via verbal or visual communication. Our general-purpose\nframework relies on fuzzy Description Logic, which has been used to extend the\npreviously developed Scene Identification and Tagging algorithm. In this paper,\nwe exploit such an algorithm to implement cognitive-like memory functionalities\nemploying scores that rank memorised observations over time based on simple\nheuristics. Our main contribution is the formalisation of a framework that can\nbe used to systematically investigate different heuristics for bootstrapping\nhierarchical knowledge representations based on robot observations. Through an\nillustrative assembly task scenario, the paper presents the performance of our\nframework to discuss its benefits and limitations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LO",
      "68T40 (Primary) 68T20, 68T27, 68T30, 68T37, 05C72, 68Q32 (Secondary)",
      "I.2.4; I.2.6; E.1"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10591v2",
    "published_date": "2024-04-16 14:14:34 UTC",
    "updated_date": "2024-04-19 14:21:17 UTC"
  },
  {
    "arxiv_id": "2404.10579v1",
    "title": "The application of Augmented Reality (AR) in Remote Work and Education",
    "authors": [
      "Keqin Li",
      "Peng Xirui",
      "Jintong Song",
      "Bo Hong",
      "Jin Wang"
    ],
    "abstract": "With the rapid advancement of technology, Augmented Reality (AR) technology,\nknown for its ability to deeply integrate virtual information with the real\nworld, is gradually transforming traditional work modes and teaching methods.\nParticularly in the realms of remote work and online education, AR technology\ndemonstrates a broad spectrum of application prospects. This paper delves into\nthe application potential and actual effects of AR technology in remote work\nand education. Through a systematic literature review, this study outlines the\nkey features, advantages, and challenges of AR technology. Based on theoretical\nanalysis, it discusses the scientific basis and technical support that AR\ntechnology provides for enhancing remote work efficiency and promoting\ninnovation in educational teaching models. Additionally, by designing an\nempirical research plan and analyzing experimental data, this article reveals\nthe specific performance and influencing factors of AR technology in practical\napplications. Finally, based on the results of the experiments, this research\nsummarizes the application value of AR technology in remote work and education,\nlooks forward to its future development trends, and proposes forward-looking\nresearch directions and strategic suggestions, offering empirical foundation\nand theoretical guidance for further promoting the in-depth application of AR\ntechnology in related fields.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10579v1",
    "published_date": "2024-04-16 14:04:46 UTC",
    "updated_date": "2024-04-16 14:04:46 UTC"
  },
  {
    "arxiv_id": "2404.10575v1",
    "title": "EMC$^2$: Efficient MCMC Negative Sampling for Contrastive Learning with Global Convergence",
    "authors": [
      "Chung-Yiu Yau",
      "Hoi-To Wai",
      "Parameswaran Raman",
      "Soumajyoti Sarkar",
      "Mingyi Hong"
    ],
    "abstract": "A key challenge in contrastive learning is to generate negative samples from\na large sample set to contrast with positive samples, for learning better\nencoding of the data. These negative samples often follow a softmax\ndistribution which are dynamically updated during the training process.\nHowever, sampling from this distribution is non-trivial due to the high\ncomputational costs in computing the partition function. In this paper, we\npropose an Efficient Markov Chain Monte Carlo negative sampling method for\nContrastive learning (EMC$^2$). We follow the global contrastive learning loss\nas introduced in SogCLR, and propose EMC$^2$ which utilizes an adaptive\nMetropolis-Hastings subroutine to generate hardness-aware negative samples in\nan online fashion during the optimization. We prove that EMC$^2$ finds an\n$\\mathcal{O}(1/\\sqrt{T})$-stationary point of the global contrastive loss in\n$T$ iterations. Compared to prior works, EMC$^2$ is the first algorithm that\nexhibits global convergence (to stationarity) regardless of the choice of batch\nsize while exhibiting low computation and memory cost. Numerical experiments\nvalidate that EMC$^2$ is effective with small batch training and achieves\ncomparable or better performance than baseline algorithms. We report the\nresults for pre-training image encoders on STL-10 and Imagenet-100.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.10575v1",
    "published_date": "2024-04-16 13:53:58 UTC",
    "updated_date": "2024-04-16 13:53:58 UTC"
  },
  {
    "arxiv_id": "2404.10574v1",
    "title": "Uncertainty-guided Open-Set Source-Free Unsupervised Domain Adaptation with Target-private Class Segregation",
    "authors": [
      "Mattia Litrico",
      "Davide Talon",
      "Sebastiano Battiato",
      "Alessio Del Bue",
      "Mario Valerio Giuffrida",
      "Pietro Morerio"
    ],
    "abstract": "Standard Unsupervised Domain Adaptation (UDA) aims to transfer knowledge from\na labeled source domain to an unlabeled target but usually requires\nsimultaneous access to both source and target data. Moreover, UDA approaches\ncommonly assume that source and target domains share the same labels space.\nYet, these two assumptions are hardly satisfied in real-world scenarios. This\npaper considers the more challenging Source-Free Open-set Domain Adaptation\n(SF-OSDA) setting, where both assumptions are dropped. We propose a novel\napproach for SF-OSDA that exploits the granularity of target-private categories\nby segregating their samples into multiple unknown classes. Starting from an\ninitial clustering-based assignment, our method progressively improves the\nsegregation of target-private samples by refining their pseudo-labels with the\nguide of an uncertainty-based sample selection module. Additionally, we propose\na novel contrastive loss, named NL-InfoNCELoss, that, integrating negative\nlearning into self-supervised contrastive learning, enhances the model\nrobustness to noisy pseudo-labels. Extensive experiments on benchmark datasets\ndemonstrate the superiority of the proposed method over existing approaches,\nestablishing new state-of-the-art performance. Notably, additional analyses\nshow that our method is able to learn the underlying semantics of novel\nclasses, opening the possibility to perform novel class discovery.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10574v1",
    "published_date": "2024-04-16 13:52:00 UTC",
    "updated_date": "2024-04-16 13:52:00 UTC"
  },
  {
    "arxiv_id": "2404.10573v2",
    "title": "AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation",
    "authors": [
      "Lijun Liu",
      "Jiali Yang",
      "Jianfei Song",
      "Xinglin Yang",
      "Lele Niu",
      "Zeqi Cai",
      "Hui Shi",
      "Tingjun Hou",
      "Chang-yu Hsieh",
      "Weiran Shen",
      "Yafeng Deng"
    ],
    "abstract": "Recombinant adeno-associated virus (rAAV) vectors have revolutionized gene\ntherapy, but their broad tropism and suboptimal transduction efficiency limit\ntheir clinical applications. To overcome these limitations, researchers have\nfocused on designing and screening capsid libraries to identify improved\nvectors. However, the large sequence space and limited resources present\nchallenges in identifying viable capsid variants. In this study, we propose an\nend-to-end diffusion model to generate capsid sequences with enhanced\nviability. Using publicly available AAV2 data, we generated 38,000 diverse AAV2\nviral protein (VP) sequences, and evaluated 8,000 for viral selection. The\nresults attested the superiority of our model compared to traditional methods.\nAdditionally, in the absence of AAV9 capsid data, apart from one wild-type\nsequence, we used the same model to directly generate a number of viable\nsequences with up to 9 mutations. we transferred the remaining 30,000 samples\nto the AAV9 domain. Furthermore, we conducted mutagenesis on AAV9 VP\nhypervariable regions VI and V, contributing to the continuous improvement of\nthe AAV9 VP sequence. This research represents a significant advancement in the\ndesign and functional validation of rAAV vectors, offering innovative solutions\nto enhance specificity and transduction efficiency in gene therapy\napplications.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "q-bio.BM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10573v2",
    "published_date": "2024-04-16 13:51:43 UTC",
    "updated_date": "2024-04-17 12:08:46 UTC"
  },
  {
    "arxiv_id": "2404.10552v1",
    "title": "Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning",
    "authors": [
      "Xiao Wang",
      "Tianze Chen",
      "Xianjun Yang",
      "Qi Zhang",
      "Xun Zhao",
      "Dahua Lin"
    ],
    "abstract": "The open-sourcing of large language models (LLMs) accelerates application\ndevelopment, innovation, and scientific progress. This includes both base\nmodels, which are pre-trained on extensive datasets without alignment, and\naligned models, deliberately designed to align with ethical standards and human\nvalues. Contrary to the prevalent assumption that the inherent\ninstruction-following limitations of base LLMs serve as a safeguard against\nmisuse, our investigation exposes a critical oversight in this belief. By\ndeploying carefully designed demonstrations, our research demonstrates that\nbase LLMs could effectively interpret and execute malicious instructions. To\nsystematically assess these risks, we introduce a novel set of risk evaluation\nmetrics. Empirical results reveal that the outputs from base LLMs can exhibit\nrisk levels on par with those of models fine-tuned for malicious purposes. This\nvulnerability, requiring neither specialized knowledge nor training, can be\nmanipulated by almost anyone, highlighting the substantial risk and the\ncritical need for immediate attention to the base LLMs' security protocols.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10552v1",
    "published_date": "2024-04-16 13:22:54 UTC",
    "updated_date": "2024-04-16 13:22:54 UTC"
  },
  {
    "arxiv_id": "2404.10551v1",
    "title": "The Evolution of Learning: Assessing the Transformative Impact of Generative AI on Higher Education",
    "authors": [
      "Stefanie Krause",
      "Bhumi Hitesh Panchal",
      "Nikhil Ubhe"
    ],
    "abstract": "Generative Artificial Intelligence (GAI) models such as ChatGPT have\nexperienced a surge in popularity, attracting 100 million active users in 2\nmonths and generating an estimated 10 million daily queries. Despite this\nremarkable adoption, there remains a limited understanding to which extent this\ninnovative technology influences higher education. This research paper\ninvestigates the impact of GAI on university students and Higher Education\nInstitutions (HEIs). The study adopts a mixed-methods approach, combining a\ncomprehensive survey with scenario analysis to explore potential benefits,\ndrawbacks, and transformative changes the new technology brings. Using an\nonline survey with 130 participants we assessed students' perspectives and\nattitudes concerning present ChatGPT usage in academics. Results show that\nstudents use the current technology for tasks like assignment writing and exam\npreparation and believe it to be a effective help in achieving academic goals.\nThe scenario analysis afterwards projected potential future scenarios,\nproviding valuable insights into the possibilities and challenges associated\nwith incorporating GAI into higher education. The main motivation is to gain a\ntangible and precise understanding of the potential consequences for HEIs and\nto provide guidance responding to the evolving learning environment. The\nfindings indicate that irresponsible and excessive use of the technology could\nresult in significant challenges. Hence, HEIs must develop stringent policies,\nreevaluate learning objectives, upskill their lecturers, adjust the curriculum\nand reconsider examination approaches.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10551v1",
    "published_date": "2024-04-16 13:19:57 UTC",
    "updated_date": "2024-04-16 13:19:57 UTC"
  },
  {
    "arxiv_id": "2407.00004v1",
    "title": "Multi-objective generative AI for designing novel brain-targeting small molecules",
    "authors": [
      "Ayush Noori",
      "I√±aki Arango",
      "William E. Byrd",
      "Nada Amin"
    ],
    "abstract": "The strict selectivity of the blood-brain barrier (BBB) represents one of the\nmost formidable challenges to successful central nervous system (CNS) drug\ndelivery. Computational methods to generate BBB permeable drugs in silico may\nbe valuable tools in the CNS drug design pipeline. However, in real-world\napplications, BBB penetration alone is insufficient; rather, after transiting\nthe BBB, molecules must bind to a specific target or receptor in the brain and\nmust also be safe and non-toxic. To discover small molecules that concurrently\nsatisfy these constraints, we use multi-objective generative AI to synthesize\ndrug-like BBB-permeable small molecules. Specifically, we computationally\nsynthesize molecules with predicted binding affinity against dopamine receptor\nD2, the primary target for many clinically effective antipsychotic drugs. After\ntraining several graph neural network-based property predictors, we adapt\nSyntheMol (Swanson et al., 2024), a recently developed Monte Carlo Tree\nSearch-based algorithm for antibiotic design, to perform a multi-objective\nguided traversal over an easily synthesizable molecular space. We design a\nlibrary of 26,581 novel and diverse small molecules containing hits with high\npredicted BBB permeability and favorable predicted safety and toxicity\nprofiles, and that could readily be synthesized for experimental validation in\nthe wet lab. We also validate top scoring molecules with molecular docking\nsimulation against the D2 receptor and demonstrate predicted binding affinity\non par with risperidone, a clinically prescribed D2-targeting antipsychotic. In\nthe future, the SyntheMol-based computational approach described here may\nenable the discovery of novel neurotherapeutics for currently intractable\ndisorders of the CNS.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.BM",
    "comment": "20 pages, 4 figures, Generative and Experimental Perspectives for\n  Biomolecular Design Workshop at the 12th International Conference on Learning\n  Representations",
    "pdf_url": "http://arxiv.org/pdf/2407.00004v1",
    "published_date": "2024-04-16 12:57:06 UTC",
    "updated_date": "2024-04-16 12:57:06 UTC"
  },
  {
    "arxiv_id": "2404.10513v2",
    "title": "CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity",
    "authors": [
      "Moshe Berchansky",
      "Daniel Fleischer",
      "Moshe Wasserblat",
      "Peter Izsak"
    ],
    "abstract": "State-of-the-art performance in QA tasks is currently achieved by systems\nemploying Large Language Models (LLMs), however these models tend to\nhallucinate information in their responses. One approach focuses on enhancing\nthe generation process by incorporating attribution from the given input to the\noutput. However, the challenge of identifying appropriate attributions and\nverifying their accuracy against a source is a complex task that requires\nsignificant improvements in assessing such systems. We introduce an\nattribution-oriented Chain-of-Thought reasoning method to enhance the accuracy\nof attributions. This approach focuses the reasoning process on generating an\nattribution-centric output. Evaluations on two context-enhanced\nquestion-answering datasets using GPT-4 demonstrate improved accuracy and\ncorrectness of attributions. In addition, the combination of our method with\nfinetuning enhances the response and attribution accuracy of two smaller LLMs,\nshowing their potential to outperform GPT-4 in some cases.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of the Association for Computational Linguistics: EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10513v2",
    "published_date": "2024-04-16 12:37:10 UTC",
    "updated_date": "2024-11-26 21:43:01 UTC"
  },
  {
    "arxiv_id": "2404.10508v4",
    "title": "White Men Lead, Black Women Help? Benchmarking Language Agency Social Biases in LLMs",
    "authors": [
      "Yixin Wan",
      "Kai-Wei Chang"
    ],
    "abstract": "Social biases can manifest in language agency. While several studies\napproached agency-related bias in human-written language, very limited research\nhas investigated such biases in Large Language Model (LLM)-generated content.\nIn addition, previous works often rely on string-matching techniques to\nidentify agentic and communal words within texts, which fall short of\naccurately classifying language agency. We introduce the novel Language Agency\nBias Evaluation (LABE) benchmark, which comprehensively evaluates biases in\nLLMs by analyzing agency levels attributed to different demographic groups in\nmodel generations. LABE leverages 5,400 template-based prompts, an accurate\nagency classifier, and corresponding bias metrics to test for gender, racial,\nand intersectional language agency biases in LLMs on 3 text generation tasks:\nbiographies, professor reviews, and reference letters. We also contribute the\nLanguage Agency Classification (LAC) dataset, consisting of 3,724 agentic and\ncommunal sentences. Using LABE, we unveil language agency social biases in 3\nrecent LLMs: ChatGPT, Llama3, and Mistral. We observe that: (1) LLM generations\ntend to demonstrate greater gender bias than human-written texts; (2) Models\ndemonstrate remarkably higher levels of intersectional bias than the other bias\naspects. Those who are at the intersection of gender and racial minority\ngroups--such as Black females--are consistently described by texts with lower\nlevels of agency, aligning with real-world social inequalities; (3) Among the 3\nLLMs investigated, Llama3 demonstrates the greatest overall bias; (4) Not only\ndoes prompt-based mitigation fail to resolve language agency bias in LLMs, but\nit frequently leads to the exacerbation of biases in generated texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10508v4",
    "published_date": "2024-04-16 12:27:54 UTC",
    "updated_date": "2024-10-24 17:43:28 UTC"
  },
  {
    "arxiv_id": "2404.10505v1",
    "title": "Data Collection of Real-Life Knowledge Work in Context: The RLKWiC Dataset",
    "authors": [
      "Mahta Bakhshizadeh",
      "Christian Jilek",
      "Markus Schr√∂der",
      "Heiko Maus",
      "Andreas Dengel"
    ],
    "abstract": "Over the years, various approaches have been employed to enhance the\nproductivity of knowledge workers, from addressing psychological well-being to\nthe development of personal knowledge assistants. A significant challenge in\nthis research area has been the absence of a comprehensive, publicly accessible\ndataset that mirrors real-world knowledge work. Although a handful of datasets\nexist, many are restricted in access or lack vital information dimensions,\ncomplicating meaningful comparison and benchmarking in the domain. This paper\npresents RLKWiC, a novel dataset of Real-Life Knowledge Work in Context,\nderived from monitoring the computer interactions of eight participants over a\nspan of two months. As the first publicly available dataset offering a wealth\nof essential information dimensions (such as explicated contexts, textual\ncontents, and semantics), RLKWiC seeks to address the research gap in the\npersonal information management domain, providing valuable insights for\nmodeling user behavior.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted and presented at the 10th International Conference on\n  Information Management (ICIM2024), will be published in Springer CCIS series\n  Conference Proceedings (Electronic ISSN: 1865-0937; Print ISSN: 1865-0929)",
    "pdf_url": "http://arxiv.org/pdf/2404.10505v1",
    "published_date": "2024-04-16 12:23:59 UTC",
    "updated_date": "2024-04-16 12:23:59 UTC"
  },
  {
    "arxiv_id": "2404.10503v1",
    "title": "A Sentiment Analysis of Medical Text Based on Deep Learning",
    "authors": [
      "Yinan Chen"
    ],
    "abstract": "The field of natural language processing (NLP) has made significant progress\nwith the rapid development of deep learning technologies. One of the research\ndirections in text sentiment analysis is sentiment analysis of medical texts,\nwhich holds great potential for application in clinical diagnosis. However, the\nmedical field currently lacks sufficient text datasets, and the effectiveness\nof sentiment analysis is greatly impacted by different model design approaches,\nwhich presents challenges. Therefore, this paper focuses on the medical domain,\nusing bidirectional encoder representations from transformers (BERT) as the\nbasic pre-trained model and experimenting with modules such as convolutional\nneural network (CNN), fully connected network (FCN), and graph convolutional\nnetworks (GCN) at the output layer. Experiments and analyses were conducted on\nthe METS-CoV dataset to explore the training performance after integrating\ndifferent deep learning networks. The results indicate that CNN models\noutperform other networks when trained on smaller medical text datasets in\ncombination with pre-trained models like BERT. This study highlights the\nsignificance of model selection in achieving effective sentiment analysis in\nthe medical domain and provides a reference for future research to develop more\nefficient model architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10503v1",
    "published_date": "2024-04-16 12:20:49 UTC",
    "updated_date": "2024-04-16 12:20:49 UTC"
  },
  {
    "arxiv_id": "2404.10501v2",
    "title": "Self-Supervised Visual Preference Alignment",
    "authors": [
      "Ke Zhu",
      "Zheng Ge",
      "Liang Zhao",
      "Xiangyu Zhang"
    ],
    "abstract": "This paper makes the first attempt towards unsupervised preference alignment\nin Vision-Language Models (VLMs). We generate chosen and rejected responses\nwith regard to the original and augmented image pairs, and conduct preference\nalignment with direct preference optimization. It is based on a core idea:\nproperly designed augmentation to the image input will induce VLM to generate\nfalse but hard negative responses, which helps the model to learn from and\nproduce more robust and powerful answers. The whole pipeline no longer hinges\non supervision from GPT-4 or human involvement during alignment, and is highly\nefficient with few lines of code. With only 8k randomly sampled unsupervised\ndata, it achieves 90\\% relative score to GPT-4 on complex reasoning in\nLLaVA-Bench, and improves LLaVA-7B/13B by 6.7\\%/5.6\\% score on complex\nmulti-modal benchmark MM-Vet. Visualizations shows its improved ability to\nalign with user-intentions. A series of ablations are firmly conducted to\nreveal the latent mechanism of the approach, which also indicates its potential\ntowards further scaling. Code are available in\nhttps://github.com/Kevinz-code/SeVa.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "MM2024 oral",
    "pdf_url": "http://arxiv.org/pdf/2404.10501v2",
    "published_date": "2024-04-16 12:19:54 UTC",
    "updated_date": "2024-08-21 11:36:47 UTC"
  },
  {
    "arxiv_id": "2404.10500v1",
    "title": "When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical Paradigm",
    "authors": [
      "Chenggian Ma",
      "Xiangyu Zhao",
      "Chunhui Zhang",
      "Yanzhao Qin",
      "Wentao Zhang"
    ],
    "abstract": "With the development of Large Language Models (LLM), numerous prompts have\nbeen proposed, each with a rich set of features and their own merits. This\npaper summarizes the prompt words for large language models (LLMs),\ncategorizing them into stimulating and framework types, and proposes an\nAuto-Prompt Graphical Paradigm(APGP) that combines both stimulating and\nframework prompts to enhance the problem-solving capabilities of LLMs across\nmultiple domains, then exemplifies it with a framework that adheres to this\nparadigm. The framework involves automated prompt generation and consideration\nof emotion-stimulus factors, guiding LLMs in problem abstraction, diversified\nsolutions generation, comprehensive optimization, and self-verification after\nproviding answers, ensuring solution accuracy. Compared to traditional stimuli\nand framework prompts, this framework integrates the advantages of both by\nadopting automated approaches inspired by APE work, overcoming the limitations\nof manually designed prompts. Test results on the ruozhiba and BBH datasets\ndemonstrate that this framework can effectively improve the efficiency and\naccuracy of LLMs in problem-solving, paving the way for new applications of\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T20",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10500v1",
    "published_date": "2024-04-16 12:19:08 UTC",
    "updated_date": "2024-04-16 12:19:08 UTC"
  },
  {
    "arxiv_id": "2404.10499v1",
    "title": "Robust Noisy Label Learning via Two-Stream Sample Distillation",
    "authors": [
      "Sihan Bai",
      "Sanping Zhou",
      "Zheng Qin",
      "Le Wang",
      "Nanning Zheng"
    ],
    "abstract": "Noisy label learning aims to learn robust networks under the supervision of\nnoisy labels, which plays a critical role in deep learning. Existing work\neither conducts sample selection or label correction to deal with noisy labels\nduring the model training process. In this paper, we design a simple yet\neffective sample selection framework, termed Two-Stream Sample Distillation\n(TSSD), for noisy label learning, which can extract more high-quality samples\nwith clean labels to improve the robustness of network training. Firstly, a\nnovel Parallel Sample Division (PSD) module is designed to generate a certain\ntraining set with sufficient reliable positive and negative samples by jointly\nconsidering the sample structure in feature space and the human prior in loss\nspace. Secondly, a novel Meta Sample Purification (MSP) module is further\ndesigned to mine adequate semi-hard samples from the remaining uncertain\ntraining set by learning a strong meta classifier with extra golden data. As a\nresult, more and more high-quality samples will be distilled from the noisy\ntraining set to train networks robustly in every iteration. Extensive\nexperiments on four benchmark datasets, including CIFAR-10, CIFAR-100,\nTiny-ImageNet, and Clothing-1M, show that our method has achieved\nstate-of-the-art results over its competitors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10499v1",
    "published_date": "2024-04-16 12:18:08 UTC",
    "updated_date": "2024-04-16 12:18:08 UTC"
  },
  {
    "arxiv_id": "2404.10498v1",
    "title": "LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration for IoT-based Perception System",
    "authors": [
      "Shijing Hu",
      "Ruijun Deng",
      "Xin Du",
      "Zhihui Lu",
      "Qiang Duan",
      "Yi He",
      "Shih-Chia Huang",
      "Jie Wu"
    ],
    "abstract": "Recent large vision models (e.g., SAM) enjoy great potential to facilitate\nintelligent perception with high accuracy. Yet, the resource constraints in the\nIoT environment tend to limit such large vision models to be locally deployed,\nincurring considerable inference latency thereby making it difficult to support\nreal-time applications, such as autonomous driving and robotics. Edge-cloud\ncollaboration with large-small model co-inference offers a promising approach\nto achieving high inference accuracy and low latency. However, existing\nedge-cloud collaboration methods are tightly coupled with the model\narchitecture and cannot adapt to the dynamic data drifts in heterogeneous IoT\nenvironments. To address the issues, we propose LAECIPS, a new edge-cloud\ncollaboration framework. In LAECIPS, both the large vision model on the cloud\nand the lightweight model on the edge are plug-and-play. We design an\nedge-cloud collaboration strategy based on hard input mining, optimized for\nboth high accuracy and low latency. We propose to update the edge model and its\ncollaboration strategy with the cloud under the supervision of the large vision\nmodel, so as to adapt to the dynamic IoT data streams. Theoretical analysis of\nLAECIPS proves its feasibility. Experiments conducted in a robotic semantic\nsegmentation system using real-world datasets show that LAECIPS outperforms its\nstate-of-the-art competitors in accuracy, latency, and communication overhead\nwhile having better adaptability to dynamic environments.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10498v1",
    "published_date": "2024-04-16 12:12:06 UTC",
    "updated_date": "2024-04-16 12:12:06 UTC"
  },
  {
    "arxiv_id": "2404.10464v3",
    "title": "DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion",
    "authors": [
      "Yu Li",
      "Han Jiang",
      "Chuanyang Gong",
      "Zhihua Wei"
    ],
    "abstract": "Despite the remarkable achievements of language models (LMs) across a broad\nspectrum of tasks, their propensity for generating toxic outputs remains a\nprevalent concern. Current solutions involving finetuning or auxiliary models\nusually require extensive computational resources, hindering their practicality\nin large language models (LLMs). In this paper, we propose DeStein, a novel\nmethod that detoxifies LMs by applying representation engineering in activation\nspaces with lower resource and time costs. Specifically, we derive\ndetoxification vectors from self-induced, universal steering pairs through\narithmetic operations in activation spaces. During inference, detoxification is\nachieved by fusing the detoxification vectors with the original representations\nin a head-wise manner. Empirical results demonstrate that our method\nsignificantly outperforms previous state-of-the-art approaches on various\nmetrics, while also maintaining satisfactory generation quality and diversity.\nWe further validate the practicality and scalability of DeStein with a series\nof white-box LLMs. The method is open-sourced at\nhttps://github.com/LizLizLi/DeStein. Warning: Some example model outputs may\ncontain highly offensive or disturbing text.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10464v3",
    "published_date": "2024-04-16 11:07:48 UTC",
    "updated_date": "2024-08-10 14:17:59 UTC"
  },
  {
    "arxiv_id": "2404.10458v1",
    "title": "Advancing Long-Term Multi-Energy Load Forecasting with Patchformer: A Patch and Transformer-Based Approach",
    "authors": [
      "Qiuyi Hong",
      "Fanlin Meng",
      "Felipe Maldonado"
    ],
    "abstract": "In the context of increasing demands for long-term multi-energy load\nforecasting in real-world applications, this paper introduces Patchformer, a\nnovel model that integrates patch embedding with encoder-decoder\nTransformer-based architectures. To address the limitation in existing\nTransformer-based models, which struggle with intricate temporal patterns in\nlong-term forecasting, Patchformer employs patch embedding, which predicts\nmultivariate time-series data by separating it into multiple univariate data\nand segmenting each of them into multiple patches. This method effectively\nenhances the model's ability to capture local and global semantic dependencies.\nThe numerical analysis shows that the Patchformer obtains overall better\nprediction accuracy in both multivariate and univariate long-term forecasting\non the novel Multi-Energy dataset and other benchmark datasets. In addition,\nthe positive effect of the interdependence among energy-related products on the\nperformance of long-term time-series forecasting across Patchformer and other\ncompared models is discovered, and the superiority of the Patchformer against\nother models is also demonstrated, which presents a significant advancement in\nhandling the interdependence and complexities of long-term multi-energy\nforecasting. Lastly, Patchformer is illustrated as the only model that follows\nthe positive correlation between model performance and the length of the past\nsequence, which states its ability to capture long-range past local semantic\ninformation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10458v1",
    "published_date": "2024-04-16 10:56:33 UTC",
    "updated_date": "2024-04-16 10:56:33 UTC"
  },
  {
    "arxiv_id": "2404.10454v1",
    "title": "A Computer Vision-Based Quality Assessment Technique for the automatic control of consumables for analytical laboratories",
    "authors": [
      "Meriam Zribi",
      "Paolo Pagliuca",
      "Francesca Pitolli"
    ],
    "abstract": "The rapid growth of the Industry 4.0 paradigm is increasing the pressure to\ndevelop effective automated monitoring systems. Artificial Intelligence (AI) is\na convenient tool to improve the efficiency of industrial processes while\nreducing errors and waste. In fact, it allows the use of real-time data to\nincrease the effectiveness of monitoring systems, minimize errors, make the\nproduction process more sustainable, and save costs. In this paper, a novel\nautomatic monitoring system is proposed in the context of production process of\nplastic consumables used in analysis laboratories, with the aim to increase the\neffectiveness of the control process currently performed by a human operator.\nIn particular, we considered the problem of classifying the presence or absence\nof a transparent anticoagulant substance inside test tubes. Specifically, a\nhand-designed deep network model is used and compared with some\nstate-of-the-art models for its ability to categorize different images of vials\nthat can be either filled with the anticoagulant or empty. Collected results\nindicate that the proposed approach is competitive with state-of-the-art models\nin terms of accuracy. Furthermore, we increased the complexity of the task by\ntraining the models on the ability to discriminate not only the presence or\nabsence of the anticoagulant inside the vial, but also the size of the test\ntube. The analysis performed in the latter scenario confirms the\ncompetitiveness of our approach. Moreover, our model is remarkably superior in\nterms of its generalization ability and requires significantly fewer resources.\nThese results suggest the possibility of successfully implementing such a model\nin the production process of a plastic consumables company.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "31 pages, 13 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.10454v1",
    "published_date": "2024-04-16 10:50:16 UTC",
    "updated_date": "2024-04-16 10:50:16 UTC"
  },
  {
    "arxiv_id": "2404.10445v4",
    "title": "SparseDM: Toward Sparse Efficient Diffusion Models",
    "authors": [
      "Kafeng Wang",
      "Jianfei Chen",
      "He Li",
      "Zhenpeng Mi",
      "Jun Zhu"
    ],
    "abstract": "Diffusion models represent a powerful family of generative models widely used\nfor image and video generation. However, the time-consuming deployment, long\ninference time, and requirements on large memory hinder their applications on\nresource constrained devices. In this paper, we propose a method based on the\nimproved Straight-Through Estimator to improve the deployment efficiency of\ndiffusion models. Specifically, we add sparse masks to the Convolution and\nLinear layers in a pre-trained diffusion model, then transfer learn the sparse\nmodel during the fine-tuning stage and turn on the sparse masks during\ninference. Experimental results on a Transformer and UNet-based diffusion\nmodels demonstrate that our method reduces MACs by 50% while maintaining FID.\nSparse models are accelerated by approximately 1.2x on the GPU. Under other\nMACs conditions, the FID is also lower than 1 compared to other methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.10445v4",
    "published_date": "2024-04-16 10:31:06 UTC",
    "updated_date": "2025-04-17 16:05:20 UTC"
  },
  {
    "arxiv_id": "2404.10443v1",
    "title": "AGHINT: Attribute-Guided Representation Learning on Heterogeneous Information Networks with Transformer",
    "authors": [
      "Jinhui Yuan",
      "Shan Lu",
      "Peibo Duan",
      "Jieyue He"
    ],
    "abstract": "Recently, heterogeneous graph neural networks (HGNNs) have achieved\nimpressive success in representation learning by capturing long-range\ndependencies and heterogeneity at the node level. However, few existing studies\nhave delved into the utilization of node attributes in heterogeneous\ninformation networks (HINs). In this paper, we investigate the impact of\ninter-node attribute disparities on HGNNs performance within the benchmark\ntask, i.e., node classification, and empirically find that typical models\nexhibit significant performance decline when classifying nodes whose attributes\nmarkedly differ from their neighbors. To alleviate this issue, we propose a\nnovel Attribute-Guided heterogeneous Information Networks representation\nlearning model with Transformer (AGHINT), which allows a more effective\naggregation of neighbor node information under the guidance of attributes.\nSpecifically, AGHINT transcends the constraints of the original graph structure\nby directly integrating higher-order similar neighbor features into the\nlearning process and modifies the message-passing mechanism between nodes based\non their attribute disparities. Extensive experimental results on three\nreal-world heterogeneous graph benchmarks with target node attributes\ndemonstrate that AGHINT outperforms the state-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10443v1",
    "published_date": "2024-04-16 10:30:48 UTC",
    "updated_date": "2024-04-16 10:30:48 UTC"
  },
  {
    "arxiv_id": "2404.10433v1",
    "title": "Explainable concept mappings of MRI: Revealing the mechanisms underlying deep learning-based brain disease classification",
    "authors": [
      "Christian Tinauer",
      "Anna Damulina",
      "Maximilian Sackl",
      "Martin Soellradl",
      "Reduan Achtibat",
      "Maximilian Dreyer",
      "Frederik Pahde",
      "Sebastian Lapuschkin",
      "Reinhold Schmidt",
      "Stefan Ropele",
      "Wojciech Samek",
      "Christian Langkammer"
    ],
    "abstract": "Motivation. While recent studies show high accuracy in the classification of\nAlzheimer's disease using deep neural networks, the underlying learned concepts\nhave not been investigated.\n  Goals. To systematically identify changes in brain regions through concepts\nlearned by the deep neural network for model validation.\n  Approach. Using quantitative R2* maps we separated Alzheimer's patients\n(n=117) from normal controls (n=219) by using a convolutional neural network\nand systematically investigated the learned concepts using Concept Relevance\nPropagation and compared these results to a conventional region of\ninterest-based analysis.\n  Results. In line with established histological findings and the region of\ninterest-based analyses, highly relevant concepts were primarily found in and\nadjacent to the basal ganglia.\n  Impact. The identification of concepts learned by deep neural networks for\ndisease classification enables validation of the models and could potentially\nimprove reliability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10433v1",
    "published_date": "2024-04-16 09:56:08 UTC",
    "updated_date": "2024-04-16 09:56:08 UTC"
  },
  {
    "arxiv_id": "2404.10429v1",
    "title": "MEEL: Multi-Modal Event Evolution Learning",
    "authors": [
      "Zhengwei Tao",
      "Zhi Jin",
      "Junqiang Huang",
      "Xiancai Chen",
      "Xiaoying Bai",
      "Haiyan Zhao",
      "Yifan Zhang",
      "Chongyang Tao"
    ],
    "abstract": "Multi-modal Event Reasoning (MMER) endeavors to endow machines with the\nability to comprehend intricate event relations across diverse data modalities.\nMMER is fundamental and underlies a wide broad of applications. Despite\nextensive instruction fine-tuning, current multi-modal large language models\nstill fall short in such ability. The disparity stems from that existing models\nare insufficient to capture underlying principles governing event evolution in\nvarious scenarios. In this paper, we introduce Multi-Modal Event Evolution\nLearning (MEEL) to enable the model to grasp the event evolution mechanism,\nyielding advanced MMER ability. Specifically, we commence with the design of\nevent diversification to gather seed events from a rich spectrum of scenarios.\nSubsequently, we employ ChatGPT to generate evolving graphs for these seed\nevents. We propose an instruction encapsulation process that formulates the\nevolving graphs into instruction-tuning data, aligning the comprehension of\nevent reasoning to humans. Finally, we observe that models trained in this way\nare still struggling to fully comprehend event evolution. In such a case, we\npropose the guiding discrimination strategy, in which models are trained to\ndiscriminate the improper evolution direction. We collect and curate a\nbenchmark M-EV2 for MMER. Extensive experiments on M-EV2 validate the\neffectiveness of our approach, showcasing competitive performance in\nopen-source multi-modal LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10429v1",
    "published_date": "2024-04-16 09:46:37 UTC",
    "updated_date": "2024-04-16 09:46:37 UTC"
  },
  {
    "arxiv_id": "2404.10425v2",
    "title": "Optimizing BioTac Simulation for Realistic Tactile Perception",
    "authors": [
      "Wadhah Zai El Amri",
      "Nicol√°s Navarro-Guerrero"
    ],
    "abstract": "Tactile sensing presents a promising opportunity for enhancing the\ninteraction capabilities of today's robots. BioTac is a commonly used tactile\nsensor that enables robots to perceive and respond to physical tactile stimuli.\nHowever, the sensor's non-linearity poses challenges in simulating its\nbehavior. In this paper, we first investigate a BioTac simulation that uses\ntemperature, force, and contact point positions to predict the sensor outputs.\nWe show that training with BioTac temperature readings does not yield accurate\nsensor output predictions during deployment. Consequently, we tested three\nalternative models, i.e., an XGBoost regressor, a neural network, and a\ntransformer encoder. We train these models without temperature readings and\nprovide a detailed investigation of the window size of the input vectors. We\ndemonstrate that we achieve statistically significant improvements over the\nbaseline network. Furthermore, our results reveal that the XGBoost regressor\nand transformer outperform traditional feed-forward neural networks in this\ntask. We make all our code and results available online on\nhttps://github.com/wzaielamri/Optimizing_BioTac_Simulation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages (including appendix), Accepted at the International Joint\n  Conference on Neural Network (IJCNN) 2024, Yokohama, Japan. \\c{opyright} 2024\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for all other uses, in any current or future media... (We refer\n  to IEEE Copyrights)",
    "pdf_url": "http://arxiv.org/pdf/2404.10425v2",
    "published_date": "2024-04-16 09:43:58 UTC",
    "updated_date": "2024-10-21 13:28:20 UTC"
  },
  {
    "arxiv_id": "2404.10416v1",
    "title": "Disentangling Instructive Information from Ranked Multiple Candidates for Multi-Document Scientific Summarization",
    "authors": [
      "Pancheng Wang",
      "Shasha Li",
      "Dong Li",
      "Kehan Long",
      "Jintao Tang",
      "Ting Wang"
    ],
    "abstract": "Automatically condensing multiple topic-related scientific papers into a\nsuccinct and concise summary is referred to as Multi-Document Scientific\nSummarization (MDSS). Currently, while commonly used abstractive MDSS methods\ncan generate flexible and coherent summaries, the difficulty in handling global\ninformation and the lack of guidance during decoding still make it challenging\nto generate better summaries. To alleviate these two shortcomings, this paper\nintroduces summary candidates into MDSS, utilizing the global information of\nthe document set and additional guidance from the summary candidates to guide\nthe decoding process. Our insights are twofold: Firstly, summary candidates can\nprovide instructive information from both positive and negative perspectives,\nand secondly, selecting higher-quality candidates from multiple options\ncontributes to producing better summaries. Drawing on the insights, we propose\na summary candidates fusion framework -- Disentangling Instructive information\nfrom Ranked candidates (DIR) for MDSS. Specifically, DIR first uses a\nspecialized pairwise comparison method towards multiple candidates to pick out\nthose of higher quality. Then DIR disentangles the instructive information of\nsummary candidates into positive and negative latent variables with Conditional\nVariational Autoencoder. These variables are further incorporated into the\ndecoder to guide generation. We evaluate our approach with three different\ntypes of Transformer-based models and three different types of candidates, and\nconsistently observe noticeable performance improvements according to automatic\nand human evaluation. More analyses further demonstrate the effectiveness of\nour model in handling global information and enhancing decoding\ncontrollability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by SIGIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10416v1",
    "published_date": "2024-04-16 09:33:07 UTC",
    "updated_date": "2024-04-16 09:33:07 UTC"
  },
  {
    "arxiv_id": "2404.10405v1",
    "title": "Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition",
    "authors": [
      "Hao Feng",
      "Yuanzhe Jia",
      "Ruijia Xu",
      "Mukesh Prasad",
      "Ali Anaissi",
      "Ali Braytee"
    ],
    "abstract": "Image recognition techniques heavily rely on abundant labeled data,\nparticularly in medical contexts. Addressing the challenges associated with\nobtaining labeled data has led to the prominence of self-supervised learning\nand semi-supervised learning, especially in scenarios with limited annotated\ndata. In this paper, we proposed an innovative approach by integrating\nself-supervised learning into semi-supervised models to enhance medical image\nrecognition. Our methodology commences with pre-training on unlabeled data\nutilizing the BYOL method. Subsequently, we merge pseudo-labeled and labeled\ndatasets to construct a neural network classifier, refining it through\niterative fine-tuning. Experimental results on three different datasets\ndemonstrate that our approach optimally leverages unlabeled data, outperforming\nexisting methods in terms of accuracy for medical image recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICCS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10405v1",
    "published_date": "2024-04-16 09:12:16 UTC",
    "updated_date": "2024-04-16 09:12:16 UTC"
  },
  {
    "arxiv_id": "2404.10393v1",
    "title": "Offline Trajectory Generalization for Offline Reinforcement Learning",
    "authors": [
      "Ziqi Zhao",
      "Zhaochun Ren",
      "Liu Yang",
      "Fajie Yuan",
      "Pengjie Ren",
      "Zhumin Chen",
      "jun Ma",
      "Xin Xin"
    ],
    "abstract": "Offline reinforcement learning (RL) aims to learn policies from static\ndatasets of previously collected trajectories. Existing methods for offline RL\neither constrain the learned policy to the support of offline data or utilize\nmodel-based virtual environments to generate simulated rollouts. However, these\nmethods suffer from (i) poor generalization to unseen states; and (ii) trivial\nimprovement from low-qualified rollout simulation. In this paper, we propose\noffline trajectory generalization through world transformers for offline\nreinforcement learning (OTTO). Specifically, we use casual Transformers, a.k.a.\nWorld Transformers, to predict state dynamics and the immediate reward. Then we\npropose four strategies to use World Transformers to generate high-rewarded\ntrajectory simulation by perturbing the offline data. Finally, we jointly use\noffline data with simulated data to train an offline RL algorithm. OTTO serves\nas a plug-in module and can be integrated with existing offline RL methods to\nenhance them with better generalization capability of transformers and\nhigh-rewarded data augmentation. Conducting extensive experiments on D4RL\nbenchmark datasets, we verify that OTTO significantly outperforms\nstate-of-the-art offline RL methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10393v1",
    "published_date": "2024-04-16 08:48:46 UTC",
    "updated_date": "2024-04-16 08:48:46 UTC"
  },
  {
    "arxiv_id": "2404.10387v1",
    "title": "CNN-based explanation ensembling for dataset, representation and explanations evaluation",
    "authors": [
      "Weronika Hryniewska-Guzik",
      "Luca Longo",
      "Przemys≈Çaw Biecek"
    ],
    "abstract": "Explainable Artificial Intelligence has gained significant attention due to\nthe widespread use of complex deep learning models in high-stake domains such\nas medicine, finance, and autonomous cars. However, different explanations\noften present different aspects of the model's behavior. In this research\nmanuscript, we explore the potential of ensembling explanations generated by\ndeep classification models using convolutional model. Through experimentation\nand analysis, we aim to investigate the implications of combining explanations\nto uncover a more coherent and reliable patterns of the model's behavior,\nleading to the possibility of evaluating the representation learned by the\nmodel. With our method, we can uncover problems of under-representation of\nimages in a certain class. Moreover, we discuss other side benefits like\nfeatures' reduction by replacing the original image with its explanations\nresulting in the removal of some sensitive information. Through the use of\ncarefully selected evaluation metrics from the Quantus library, we demonstrated\nthe method's superior performance in terms of Localisation and Faithfulness,\ncompared to individual explanations.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted at 2nd World Conference on eXplainable Artificial\n  Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2404.10387v1",
    "published_date": "2024-04-16 08:39:29 UTC",
    "updated_date": "2024-04-16 08:39:29 UTC"
  },
  {
    "arxiv_id": "2404.10386v2",
    "title": "I/O in Machine Learning Applications on HPC Systems: A 360-degree Survey",
    "authors": [
      "Noah Lewis",
      "Jean Luca Bez",
      "Surendra Byna"
    ],
    "abstract": "Growing interest in Artificial Intelligence (AI) has resulted in a surge in\ndemand for faster methods of Machine Learning (ML) model training and\ninference. This demand for speed has prompted the use of high performance\ncomputing (HPC) systems that excel in managing distributed workloads. Because\ndata is the main fuel for AI applications, the performance of the storage and\nI/O subsystem of HPC systems is critical. In the past, HPC applications\naccessed large portions of data written by simulations or experiments or\ningested data for visualizations or analysis tasks. ML workloads perform small\nreads spread across a large number of random files. This shift of I/O access\npatterns poses several challenges to modern parallel storage systems. In this\npaper, we survey I/O in ML applications on HPC systems, and target literature\nwithin a 6-year time window from 2019 to 2024. We define the scope of the\nsurvey, provide an overview of the common phases of ML, review available\nprofilers and benchmarks, examine the I/O patterns encountered during offline\ndata preparation, training, and inference, and explore I/O optimizations\nutilized in modern ML frameworks and proposed in recent literature. Lastly, we\nseek to expose research gaps that could spawn further R&D.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "H.3.2; H.3.4; I.2.11"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10386v2",
    "published_date": "2024-04-16 08:37:36 UTC",
    "updated_date": "2025-03-07 15:11:30 UTC"
  },
  {
    "arxiv_id": "2404.10384v1",
    "title": "Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large Language Model for Domain Question Answering",
    "authors": [
      "Yuqi Wang",
      "Boran Jiang",
      "Yi Luo",
      "Dawei He",
      "Peng Cheng",
      "Liangcai Gao"
    ],
    "abstract": "Large language models (LLMs), such as GPT3.5, GPT4 and LLAMA2 perform\nsurprisingly well and outperform human experts on many tasks. However, in many\ndomain-specific evaluations, these LLMs often suffer from hallucination\nproblems due to insufficient training of relevant corpus. Furthermore,\nfine-tuning large models may face problems such as the LLMs are not open source\nor the construction of high-quality domain instruction is difficult. Therefore,\nstructured knowledge databases such as knowledge graph can better provide\ndomain background knowledge for LLMs and make full use of the reasoning and\nanalysis capabilities of LLMs. In some previous works, LLM was called multiple\ntimes to determine whether the current triplet was suitable for inclusion in\nthe subgraph when retrieving subgraphs through a question. Especially for the\nquestion that require a multi-hop reasoning path, frequent calls to LLM will\nconsume a lot of computing power. Moreover, when choosing the reasoning path,\nLLM will be called once for each step, and if one of the steps is selected\nincorrectly, it will lead to the accumulation of errors in the following steps.\nIn this paper, we integrated and optimized a pipeline for selecting reasoning\npaths from KG based on LLM, which can reduce the dependency on LLM. In\naddition, we propose a simple and effective subgraph retrieval method based on\nchain of thought (CoT) and page rank which can returns the paths most likely to\ncontain the answer. We conduct experiments on three datasets: GenMedGPT-5k\n[14], WebQuestions [2], and CMCQA [21]. Finally, RoK can demonstrate that using\nfewer LLM calls can achieve the same results as previous SOTAs models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10384v1",
    "published_date": "2024-04-16 08:28:16 UTC",
    "updated_date": "2024-04-16 08:28:16 UTC"
  },
  {
    "arxiv_id": "2404.10378v1",
    "title": "Second Edition FRCSyn Challenge at CVPR 2024: Face Recognition Challenge in the Era of Synthetic Data",
    "authors": [
      "Ivan DeAndres-Tame",
      "Ruben Tolosana",
      "Pietro Melzi",
      "Ruben Vera-Rodriguez",
      "Minchul Kim",
      "Christian Rathgeb",
      "Xiaoming Liu",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia",
      "Zhizhou Zhong",
      "Yuge Huang",
      "Yuxi Mi",
      "Shouhong Ding",
      "Shuigeng Zhou",
      "Shuai He",
      "Lingzhi Fu",
      "Heng Cong",
      "Rongyu Zhang",
      "Zhihong Xiao",
      "Evgeny Smirnov",
      "Anton Pimenov",
      "Aleksei Grigorev",
      "Denis Timoshenko",
      "Kaleb Mesfin Asfaw",
      "Cheng Yaw Low",
      "Hao Liu",
      "Chuyi Wang",
      "Qing Zuo",
      "Zhixiang He",
      "Hatef Otroshi Shahreza",
      "Anjith George",
      "Alexander Unnervik",
      "Parsa Rahimi",
      "S√©bastien Marcel",
      "Pedro C. Neto",
      "Marco Huber",
      "Jan Niklas Kolf",
      "Naser Damer",
      "Fadi Boutros",
      "Jaime S. Cardoso",
      "Ana F. Sequeira",
      "Andrea Atzori",
      "Gianni Fenu",
      "Mirko Marras",
      "Vitomir ≈†truc",
      "Jiang Yu",
      "Zhangjie Li",
      "Jichun Li",
      "Weisong Zhao",
      "Zhen Lei",
      "Xiangyu Zhu",
      "Xiao-Yu Zhang",
      "Bernardo Biesseck",
      "Pedro Vidal",
      "Luiz Coelho",
      "Roger Granada",
      "David Menotti"
    ],
    "abstract": "Synthetic data is gaining increasing relevance for training machine learning\nmodels. This is mainly motivated due to several factors such as the lack of\nreal data and intra-class variability, time and errors produced in manual\nlabeling, and in some cases privacy concerns, among others. This paper presents\nan overview of the 2nd edition of the Face Recognition Challenge in the Era of\nSynthetic Data (FRCSyn) organized at CVPR 2024. FRCSyn aims to investigate the\nuse of synthetic data in face recognition to address current technological\nlimitations, including data privacy concerns, demographic biases,\ngeneralization to novel scenarios, and performance constraints in challenging\nsituations such as aging, pose variations, and occlusions. Unlike the 1st\nedition, in which synthetic data from DCFace and GANDiffFace methods was only\nallowed to train face recognition systems, in this 2nd edition we propose new\nsub-tasks that allow participants to explore novel face generative methods. The\noutcomes of the 2nd FRCSyn Challenge, along with the proposed experimental\nprotocol and benchmarking contribute significantly to the application of\nsynthetic data to face recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2311.10476",
    "pdf_url": "http://arxiv.org/pdf/2404.10378v1",
    "published_date": "2024-04-16 08:15:10 UTC",
    "updated_date": "2024-04-16 08:15:10 UTC"
  },
  {
    "arxiv_id": "2404.10356v2",
    "title": "Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery",
    "authors": [
      "Payal Varshney",
      "Adriano Lucieri",
      "Christoph Balada",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "abstract": "Trustworthiness is a major prerequisite for the safe application of opaque\ndeep learning models in high-stakes domains like medicine. Understanding the\ndecision-making process not only contributes to fostering trust but might also\nreveal previously unknown decision criteria of complex models that could\nadvance the state of medical research. The discovery of decision-relevant\nconcepts from black box models is a particularly challenging task. This study\nproposes Concept Discovery through Latent Diffusion-based Counterfactual\nTrajectories (CDCT), a novel three-step framework for concept discovery\nleveraging the superior image synthesis capabilities of diffusion models. In\nthe first step, CDCT uses a Latent Diffusion Model (LDM) to generate a\ncounterfactual trajectory dataset. This dataset is used to derive a\ndisentangled representation of classification-relevant concepts using a\nVariational Autoencoder (VAE). Finally, a search algorithm is applied to\nidentify relevant concepts in the disentangled latent space. The application of\nCDCT to a classifier trained on the largest public skin lesion dataset revealed\nnot only the presence of several biases but also meaningful biomarkers.\nMoreover, the counterfactuals generated within CDCT show better FID scores than\nthose produced by a previously established state-of-the-art method, while being\n12 times more resource-efficient. Unsupervised concept discovery holds great\npotential for the application of trustworthy AI and the further development of\nhuman knowledge in various domains. CDCT represents a further step in this\ndirection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at International Conference on Pattern Recognition (ICPR)\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10356v2",
    "published_date": "2024-04-16 07:44:08 UTC",
    "updated_date": "2025-01-06 14:47:53 UTC"
  },
  {
    "arxiv_id": "2404.10337v3",
    "title": "Exploring the Role of Token in Transformer-based Time Series Forecasting",
    "authors": [
      "Jianqi Zhang",
      "Jingyao Wang",
      "Chuxiong Sun",
      "Xingchen Shen",
      "Fanjiang Xu",
      "Changwen Zheng",
      "Wenwen Qiang"
    ],
    "abstract": "Transformer-based methods are a mainstream approach for solving time series\nforecasting (TSF). These methods use temporal or variable tokens from\nobservable data to make predictions. However, most focus on optimizing the\nmodel structure, with few studies paying attention to the role of tokens for\npredictions. The role is crucial since a model that distinguishes useful tokens\nfrom useless ones will predict more effectively. In this paper, we explore this\nissue. Through theoretical analyses, we find that the gradients mainly depend\non tokens that contribute to the predicted series, called positive tokens.\nBased on this finding, we explore what helps models select these positive\ntokens. Through a series of experiments, we obtain three observations: i)\npositional encoding (PE) helps the model identify positive tokens; ii) as the\nnetwork depth increases, the PE information gradually weakens, affecting the\nmodel's ability to identify positive tokens in deeper layers; iii) both\nenhancing PE in the deeper layers and using semantic-based PE can improve the\nmodel's ability to identify positive tokens, thus boosting performance.\nInspired by these findings, we design temporal positional encoding (T-PE) for\ntemporal tokens and variable positional encoding (V-PE) for variable tokens. To\nutilize T-PE and V-PE, we propose T2B-PE, a Transformer-based dual-branch\nframework. Extensive experiments demonstrate that T2B-PE has superior\nrobustness and effectiveness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10337v3",
    "published_date": "2024-04-16 07:21:39 UTC",
    "updated_date": "2024-10-30 01:49:45 UTC"
  },
  {
    "arxiv_id": "2404.10332v1",
    "title": "Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning",
    "authors": [
      "Rui Hu",
      "Yahan Tu",
      "Jitao Sang"
    ],
    "abstract": "Despite achieving outstanding performance on various cross-modal tasks,\ncurrent large vision-language models (LVLMs) still suffer from hallucination\nissues, manifesting as inconsistencies between their generated responses and\nthe corresponding images. Prior research has implicated that the low quality of\ninstruction data, particularly the skewed balance between positive and negative\nsamples, is a significant contributor to model hallucinations. Recently,\nresearchers have proposed high-quality instruction datasets, such as\nLRV-Instruction, to mitigate model hallucination. Nonetheless, our\ninvestigation reveals that hallucinatory concepts from different LVLMs exhibit\nspecificity, i.e. the distribution of hallucinatory concepts varies\nsignificantly across models. Existing datasets did not consider the\nhallucination specificity of different models in the design processes, thereby\ndiminishing their efficacy in mitigating model hallucination. In this paper, we\npropose a targeted instruction data generation framework named DFTG that\ntailored to the hallucination specificity of different models. Concretely, DFTG\nconsists of two stages: hallucination diagnosis, which extracts the necessary\ninformation from the model's responses and images for hallucination diagnosis;\nand targeted data generation, which generates targeted instruction data based\non diagnostic results. The experimental results on hallucination benchmarks\ndemonstrate that the targeted instruction data generated by our method are more\neffective in mitigating hallucinations compared to previous datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10332v1",
    "published_date": "2024-04-16 07:14:32 UTC",
    "updated_date": "2024-04-16 07:14:32 UTC"
  },
  {
    "arxiv_id": "2404.10329v2",
    "title": "Towards Complex Ontology Alignment using Large Language Models",
    "authors": [
      "Reihaneh Amini",
      "Sanaz Saki Norouzi",
      "Pascal Hitzler",
      "Reza Amini"
    ],
    "abstract": "Ontology alignment, a critical process in the Semantic Web for detecting\nrelationships between different ontologies, has traditionally focused on\nidentifying so-called \"simple\" 1-to-1 relationships through class labels and\nproperties comparison. The more practically useful exploration of more complex\nalignments remains a hard problem to automate, and as such is largely\nunderexplored, i.e. in application practice it is usually done manually by\nontology and domain experts. Recently, the surge in Natural Language Processing\n(NLP) capabilities, driven by advancements in Large Language Models (LLMs),\npresents new opportunities for enhancing ontology engineering practices,\nincluding ontology alignment tasks. This paper investigates the application of\nLLM technologies to tackle the complex ontology alignment challenge. Leveraging\na prompt-based approach and integrating rich ontology content so-called modules\nour work constitutes a significant advance towards automating the complex\nalignment task.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10329v2",
    "published_date": "2024-04-16 07:13:22 UTC",
    "updated_date": "2024-07-22 20:07:33 UTC"
  },
  {
    "arxiv_id": "2404.10320v2",
    "title": "CARE to Compare: A real-world dataset for anomaly detection in wind turbine data",
    "authors": [
      "Christian G√ºck",
      "Cyriana M. A. Roelofs",
      "Stefan Faulstich"
    ],
    "abstract": "Anomaly detection plays a crucial role in the field of predictive maintenance\nfor wind turbines, yet the comparison of different algorithms poses a difficult\ntask because domain specific public datasets are scarce. Many comparisons of\ndifferent approaches either use benchmarks composed of data from many different\ndomains, inaccessible data or one of the few publicly available datasets which\nlack detailed information about the faults. Moreover, many publications\nhighlight a couple of case studies where fault detection was successful. With\nthis paper we publish a high quality dataset that contains data from 36 wind\nturbines across 3 different wind farms as well as the most detailed fault\ninformation of any public wind turbine dataset as far as we know. The new\ndataset contains 89 years worth of real-world operating data of wind turbines,\ndistributed across 44 labeled time frames for anomalies that led up to faults,\nas well as 51 time series representing normal behavior. Additionally, the\nquality of training data is ensured by turbine-status-based labels for each\ndata point. Furthermore, we propose a new scoring method, called CARE\n(Coverage, Accuracy, Reliability and Earliness), which takes advantage of the\ninformation depth that is present in the dataset to identify a good all-around\nanomaly detection model. This score considers the anomaly detection\nperformance, the ability to recognize normal behavior properly and the\ncapability to raise as few false alarms as possible while simultaneously\ndetecting anomalies early.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10320v2",
    "published_date": "2024-04-16 07:02:40 UTC",
    "updated_date": "2024-04-18 05:56:21 UTC"
  },
  {
    "arxiv_id": "2404.10317v2",
    "title": "LLMs4OM: Matching Ontologies with Large Language Models",
    "authors": [
      "Hamed Babaei Giglou",
      "Jennifer D'Souza",
      "Felix Engel",
      "S√∂ren Auer"
    ],
    "abstract": "Ontology Matching (OM), is a critical task in knowledge integration, where\naligning heterogeneous ontologies facilitates data interoperability and\nknowledge sharing. Traditional OM systems often rely on expert knowledge or\npredictive models, with limited exploration of the potential of Large Language\nModels (LLMs). We present the LLMs4OM framework, a novel approach to evaluate\nthe effectiveness of LLMs in OM tasks. This framework utilizes two modules for\nretrieval and matching, respectively, enhanced by zero-shot prompting across\nthree ontology representations: concept, concept-parent, and concept-children.\nThrough comprehensive evaluations using 20 OM datasets from various domains, we\ndemonstrate that LLMs, under the LLMs4OM framework, can match and even surpass\nthe performance of traditional OM systems, particularly in complex matching\nscenarios. Our results highlight the potential of LLMs to significantly\ncontribute to the field of OM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 1 figure, accepted to ESWC 2024 Special Track on LLMs for\n  Knowledge Engineering\n  (https://2024.eswc-conferences.org/call-for-papers-llms/)",
    "pdf_url": "http://arxiv.org/pdf/2404.10317v2",
    "published_date": "2024-04-16 06:55:45 UTC",
    "updated_date": "2024-04-23 10:37:51 UTC"
  },
  {
    "arxiv_id": "2404.10311v1",
    "title": "Learning and Optimization for Price-based Demand Response of Electric Vehicle Charging",
    "authors": [
      "Chengyang Gu",
      "Yuxin Pan",
      "Ruohong Liu",
      "Yize Chen"
    ],
    "abstract": "In the context of charging electric vehicles (EVs), the price-based demand\nresponse (PBDR) is becoming increasingly significant for charging load\nmanagement. Such response usually encourages cost-sensitive customers to adjust\ntheir energy demand in response to changes in price for financial incentives.\nThus, to model and optimize EV charging, it is important for charging station\noperator to model the PBDR patterns of EV customers by precisely predicting\ncharging demands given price signals. Then the operator refers to these demands\nto optimize charging station power allocation policy. The standard pipeline\ninvolves offline fitting of a PBDR function based on historical EV charging\nrecords, followed by applying estimated EV demands in downstream charging\nstation operation optimization. In this work, we propose a new decision-focused\nend-to-end framework for PBDR modeling that combines prediction errors and\ndownstream optimization cost errors in the model learning stage. We evaluate\nthe effectiveness of our method on a simulation of charging station operation\nwith synthetic PBDR patterns of EV customers, and experimental results\ndemonstrate that this framework can provide a more reliable prediction model\nfor the ultimate optimization process, leading to more effective optimization\nsolutions in terms of cost savings and charging station operation objectives\nwith only a few training samples.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted by American Control Conference (ACC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10311v1",
    "published_date": "2024-04-16 06:39:30 UTC",
    "updated_date": "2024-04-16 06:39:30 UTC"
  },
  {
    "arxiv_id": "2404.10308v1",
    "title": "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs",
    "authors": [
      "Woomin Song",
      "Seunghyuk Oh",
      "Sangwoo Mo",
      "Jaehyung Kim",
      "Sukmin Yun",
      "Jung-Woo Ha",
      "Jinwoo Shin"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance in various\nnatural language processing tasks. However, a primary constraint they face is\nthe context limit, i.e., the maximum number of tokens they can process.\nPrevious works have explored architectural changes and modifications in\npositional encoding to relax the constraint, but they often require expensive\ntraining or do not address the computational demands of self-attention. In this\npaper, we present Hierarchical cOntext MERging (HOMER), a new training-free\nscheme designed to overcome the limitations. HOMER uses a divide-and-conquer\nalgorithm, dividing long inputs into manageable chunks. Each chunk is then\nprocessed collectively, employing a hierarchical strategy that merges adjacent\nchunks at progressive transformer layers. A token reduction technique precedes\neach merging, ensuring memory usage efficiency. We also propose an optimized\ncomputational order reducing the memory requirement to logarithmically scale\nwith respect to input length, making it especially favorable for environments\nwith tight memory restrictions. Our experiments demonstrate the proposed\nmethod's superior performance and memory efficiency, enabling the broader use\nof LLMs in contexts requiring extended context. Code is available at\nhttps://github.com/alinlab/HOMER.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2024. The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2404.10308v1",
    "published_date": "2024-04-16 06:34:08 UTC",
    "updated_date": "2024-04-16 06:34:08 UTC"
  },
  {
    "arxiv_id": "2404.10307v1",
    "title": "Learnable Prompt for Few-Shot Semantic Segmentation in Remote Sensing Domain",
    "authors": [
      "Steve Andreas Immanuel",
      "Hagai Raja Sinulingga"
    ],
    "abstract": "Few-shot segmentation is a task to segment objects or regions of novel\nclasses within an image given only a few annotated examples. In the generalized\nsetting, the task extends to segment both the base and the novel classes. The\nmain challenge is how to train the model such that the addition of novel\nclasses does not hurt the base classes performance, also known as catastrophic\nforgetting. To mitigate this issue, we use SegGPT as our base model and train\nit on the base classes. Then, we use separate learnable prompts to handle\npredictions for each novel class. To handle various object sizes which\ntypically present in remote sensing domain, we perform patch-based prediction.\nTo address the discontinuities along patch boundaries, we propose a\npatch-and-stitch technique by re-framing the problem as an image inpainting\ntask. During inference, we also utilize image similarity search over image\nembeddings for prompt selection and novel class filtering to reduce false\npositive predictions. Based on our experiments, our proposed method boosts the\nweighted mIoU of a simple fine-tuned SegGPT from 15.96 to 35.08 on the\nvalidation set of few-shot OpenEarthMap dataset given in the challenge.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPRW 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10307v1",
    "published_date": "2024-04-16 06:33:08 UTC",
    "updated_date": "2024-04-16 06:33:08 UTC"
  },
  {
    "arxiv_id": "2404.10299v2",
    "title": "Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis",
    "authors": [
      "Shintaro Tamai",
      "Masayuki Numao",
      "Ken-ichi Fukui"
    ],
    "abstract": "Recently, growing health awareness, novel methods allow individuals to\nmonitor sleep at home. Utilizing sleep sounds offers advantages over\nconventional methods like smartwatches, being non-intrusive, and capable of\ndetecting various physiological activities. This study aims to construct a\nmachine learning-based sleep assessment model providing evidence-based\nassessments, such as poor sleep due to frequent movement during sleep onset.\nExtracting sleep sound events, deriving latent representations using VAE,\nclustering with GMM, and training LSTM for subjective sleep assessment achieved\na high accuracy of 94.8% in distinguishing sleep satisfaction. Moreover,\nTimeSHAP revealed differences in impactful sound event types and timings for\ndifferent individuals.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10299v2",
    "published_date": "2024-04-16 05:56:41 UTC",
    "updated_date": "2024-10-17 07:02:19 UTC"
  },
  {
    "arxiv_id": "2404.10297v1",
    "title": "Future Language Modeling from Temporal Document History",
    "authors": [
      "Changmao Li",
      "Jeffrey Flanigan"
    ],
    "abstract": "Predicting the future is of great interest across many aspects of human\nactivity. Businesses are interested in future trends, traders are interested in\nfuture stock prices, and companies are highly interested in future\ntechnological breakthroughs. While there are many automated systems for\npredicting future numerical data, such as weather, stock prices, and demand for\nproducts, there is relatively little work in automatically predicting textual\ndata. Humans are interested in textual data predictions because it is a natural\nformat for our consumption, and experts routinely make predictions in a textual\nformat (Christensen et al., 2004; Tetlock & Gardner, 2015; Frick, 2015).\nHowever, there has been relatively little formalization of this general problem\nin the machine learning or natural language processing communities. To address\nthis gap, we introduce the task of future language modeling: probabilistic\nmodeling of texts in the future based on a temporal history of texts. To our\nknowledge, our work is the first work to formalize the task of predicting the\nfuture in this way. We show that it is indeed possible to build future language\nmodels that improve upon strong non-temporal language model baselines, opening\nthe door to working on this important, and widely applicable problem.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10297v1",
    "published_date": "2024-04-16 05:45:52 UTC",
    "updated_date": "2024-04-16 05:45:52 UTC"
  },
  {
    "arxiv_id": "2404.10296v5",
    "title": "Interpolating neural network: A novel unification of machine learning and interpolation theory",
    "authors": [
      "Chanwook Park",
      "Sourav Saha",
      "Jiachen Guo",
      "Hantao Zhang",
      "Xiaoyu Xie",
      "Miguel A. Bessa",
      "Dong Qian",
      "Wei Chen",
      "Gregory J. Wagner",
      "Jian Cao",
      "Wing Kam Liu"
    ],
    "abstract": "Artificial intelligence (AI) has revolutionized software development,\nshifting from task-specific codes (Software 1.0) to neural network-based\napproaches (Software 2.0). However, applying this transition in engineering\nsoftware presents challenges, including low surrogate model accuracy, the curse\nof dimensionality in inverse design, and rising complexity in physical\nsimulations. We introduce an interpolating neural network (INN), grounded in\ninterpolation theory and tensor decomposition, to realize Engineering Software\n2.0 by advancing data training, partial differential equation solving, and\nparameter calibration. INN offers orders of magnitude fewer trainable/solvable\nparameters for comparable model accuracy than traditional multi-layer\nperceptron (MLP) or physics-informed neural networks (PINN). Demonstrated in\nmetal additive manufacturing, INN rapidly constructs an accurate surrogate\nmodel of Laser Powder Bed Fusion (L-PBF) heat transfer simulation, achieving\nsub-10-micrometer resolution for a 10 mm path in under 15 minutes on a single\nGPU. This makes a transformative step forward across all domains essential to\nengineering software.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10296v5",
    "published_date": "2024-04-16 05:40:30 UTC",
    "updated_date": "2024-11-25 15:00:32 UTC"
  },
  {
    "arxiv_id": "2404.10289v1",
    "title": "The Dearth of the Author in AI-Supported Writing",
    "authors": [
      "Max Kreminski"
    ],
    "abstract": "We diagnose and briefly discuss the dearth of the author: a condition that\narises when AI-based creativity support tools for writing allow users to\nproduce large amounts of text without making a commensurate number of creative\ndecisions, resulting in output that is sparse in expressive intent. We argue\nthat the dearth of the author helps to explain a number of recurring\ndifficulties and anxieties around AI-based writing support tools, but that it\nalso suggests an ambitious new goal for AI-based CSTs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Published as a workshop paper at the In2Writing workshop at CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10289v1",
    "published_date": "2024-04-16 05:23:03 UTC",
    "updated_date": "2024-04-16 05:23:03 UTC"
  },
  {
    "arxiv_id": "2404.10281v3",
    "title": "AI-Assisted Writing in Education: Ecosystem Risks and Mitigations",
    "authors": [
      "Antonette Shibani",
      "Simon Buckingham Shum"
    ],
    "abstract": "While the excitement around the capabilities of technological advancements is\ngiving rise to new AI-based writing assistants, the overarching ecosystem plays\na crucial role in how they are adopted in educational practice. In this paper,\nwe point to key ecological aspects for consideration. We draw insights from\nextensive research integrated with practice on a writing feedback tool over 9\nyears at a university, and we highlight potential risks when these are\noverlooked. It informs the design of educational writing support tools to be\nbetter aligned within broader contexts to balance innovation with practical\nimpact.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10281v3",
    "published_date": "2024-04-16 04:49:35 UTC",
    "updated_date": "2024-05-14 10:06:44 UTC"
  },
  {
    "arxiv_id": "2404.10275v1",
    "title": "OptiGrad: A Fair and more Efficient Price Elasticity Optimization via a Gradient Based Learning",
    "authors": [
      "Vincent Grari",
      "Marcin Detyniecki"
    ],
    "abstract": "This paper presents a novel approach to optimizing profit margins in non-life\ninsurance markets through a gradient descent-based method, targeting three key\nobjectives: 1) maximizing profit margins, 2) ensuring conversion rates, and 3)\nenforcing fairness criteria such as demographic parity (DP). Traditional\npricing optimization, which heavily lean on linear and semi definite\nprogramming, encounter challenges in balancing profitability and fairness.\nThese challenges become especially pronounced in situations that necessitate\ncontinuous rate adjustments and the incorporation of fairness criteria.\nSpecifically, indirect Ratebook optimization, a widely-used method for new\nbusiness price setting, relies on predictor models such as XGBoost or GLMs/GAMs\nto estimate on downstream individually optimized prices. However, this strategy\nis prone to sequential errors and struggles to effectively manage optimizations\nfor continuous rate scenarios. In practice, to save time actuaries frequently\nopt for optimization within discrete intervals (e.g., range of [-20\\%, +20\\%]\nwith fix increments) leading to approximate estimations. Moreover, to\ncircumvent infeasible solutions they often use relaxed constraints leading to\nsuboptimal pricing strategies. The reverse-engineered nature of traditional\nmodels complicates the enforcement of fairness and can lead to biased outcomes.\nOur method addresses these challenges by employing a direct optimization\nstrategy in the continuous space of rates and by embedding fairness through an\nadversarial predictor model. This innovation not only reduces sequential errors\nand simplifies the complexities found in traditional models but also directly\nintegrates fairness measures into the commercial premium calculation. We\ndemonstrate improved margin performance and stronger enforcement of fairness\nhighlighting the critical need to evolve existing pricing strategies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10275v1",
    "published_date": "2024-04-16 04:21:59 UTC",
    "updated_date": "2024-04-16 04:21:59 UTC"
  },
  {
    "arxiv_id": "2404.10274v2",
    "title": "Sparse Attention Regression Network Based Soil Fertility Prediction With Ummaso",
    "authors": [
      "R V Raghavendra Rao",
      "U Srinivasulu Reddy"
    ],
    "abstract": "The challenge of imbalanced soil nutrient datasets significantly hampers\naccurate predictions of soil fertility. To tackle this, a new method is\nsuggested in this research, combining Uniform Manifold Approximation and\nProjection (UMAP) with Least Absolute Shrinkage and Selection Operator (LASSO).\nThe main aim is to counter the impact of uneven data distribution and improve\nsoil fertility models' predictive precision. The model introduced uses Sparse\nAttention Regression, effectively incorporating pertinent features from the\nimbalanced dataset. UMAP is utilized initially to reduce data complexity,\nunveiling hidden structures and important patterns. Following this, LASSO is\napplied to refine features and enhance the model's interpretability. The\nexperimental outcomes highlight the effectiveness of the UMAP and LASSO hybrid\napproach. The proposed model achieves outstanding performance metrics, reaching\na predictive accuracy of 98%, demonstrating its capability in accurate soil\nfertility predictions. Additionally, it showcases a Precision of 91.25%,\nindicating its adeptness in identifying fertile soil instances accurately. The\nRecall metric stands at 90.90%, emphasizing the model's ability to capture true\npositive cases effectively.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "There is an error in the result section",
    "pdf_url": "http://arxiv.org/pdf/2404.10274v2",
    "published_date": "2024-04-16 04:17:17 UTC",
    "updated_date": "2024-09-10 07:21:27 UTC"
  },
  {
    "arxiv_id": "2404.10271v2",
    "title": "Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback",
    "authors": [
      "Vincent Conitzer",
      "Rachel Freedman",
      "Jobst Heitzig",
      "Wesley H. Holliday",
      "Bob M. Jacobs",
      "Nathan Lambert",
      "Milan Moss√©",
      "Eric Pacuit",
      "Stuart Russell",
      "Hailey Schoelkopf",
      "Emanuel Tewolde",
      "William S. Zwicker"
    ],
    "abstract": "Foundation models such as GPT-4 are fine-tuned to avoid unsafe or otherwise\nproblematic behavior, such as helping to commit crimes or producing racist\ntext. One approach to fine-tuning, called reinforcement learning from human\nfeedback, learns from humans' expressed preferences over multiple outputs.\nAnother approach is constitutional AI, in which the input from humans is a list\nof high-level principles. But how do we deal with potentially diverging input\nfrom humans? How can we aggregate the input into consistent data about\n\"collective\" preferences or otherwise use it to make collective choices about\nmodel behavior? In this paper, we argue that the field of social choice is well\npositioned to address these questions, and we discuss ways forward for this\nagenda, drawing on discussions in a recent workshop on Social Choice for AI\nEthics and Safety held in Berkeley, CA, USA in December 2023.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.GT",
      "68T01, 68T50, 91B14, 91B12",
      "I.2.0; I.2.7; K.4.2; I.2.m; J.4"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10271v2",
    "published_date": "2024-04-16 03:59:33 UTC",
    "updated_date": "2024-06-04 14:34:38 UTC"
  },
  {
    "arxiv_id": "2404.10267v4",
    "title": "OneActor: Consistent Character Generation via Cluster-Conditioned Guidance",
    "authors": [
      "Jiahao Wang",
      "Caixia Yan",
      "Haonan Lin",
      "Weizhan Zhang",
      "Mengmeng Wang",
      "Tieliang Gong",
      "Guang Dai",
      "Hao Sun"
    ],
    "abstract": "Text-to-image diffusion models benefit artists with high-quality image\ngeneration. Yet their stochastic nature hinders artists from creating\nconsistent images of the same subject. Existing methods try to tackle this\nchallenge and generate consistent content in various ways. However, they either\ndepend on external restricted data or require expensive tuning of the diffusion\nmodel. For this issue, we propose a novel one-shot tuning paradigm, termed\nOneActor. It efficiently performs consistent subject generation solely driven\nby prompts via a learned semantic guidance to bypass the laborious backbone\ntuning. We lead the way to formalize the objective of consistent subject\ngeneration from a clustering perspective, and thus design a cluster-conditioned\nmodel. To mitigate the overfitting challenge shared by one-shot tuning\npipelines, we augment the tuning with auxiliary samples and devise two\ninference strategies: semantic interpolation and cluster guidance. These\ntechniques are later verified to significantly improve the generation quality.\nComprehensive experiments show that our method outperforms a variety of\nbaselines with satisfactory subject consistency, superior prompt conformity as\nwell as high image quality. Our method is capable of multi-subject generation\nand compatible with popular diffusion extensions. Besides, we achieve a 4 times\nfaster tuning speed than tuning-based baselines and, if desired, avoid\nincreasing the inference time. Furthermore, our method can be naturally\nutilized to pre-train a consistent subject generation network from scratch,\nwhich will implement this research task into more practical applications.\n(Project page: https://johnneywang.github.io/OneActor-webpage/)",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10267v4",
    "published_date": "2024-04-16 03:45:45 UTC",
    "updated_date": "2024-10-28 03:05:40 UTC"
  },
  {
    "arxiv_id": "2404.10260v2",
    "title": "HelixFold-Multimer: Elevating Protein Complex Structure Prediction to New Heights",
    "authors": [
      "Xiaomin Fang",
      "Jie Gao",
      "Jing Hu",
      "Lihang Liu",
      "Yang Xue",
      "Xiaonan Zhang",
      "Kunrui Zhu"
    ],
    "abstract": "While monomer protein structure prediction tools boast impressive accuracy,\nthe prediction of protein complex structures remains a daunting challenge in\nthe field. This challenge is particularly pronounced in scenarios involving\ncomplexes with protein chains from different species, such as antigen-antibody\ninteractions, where accuracy often falls short. Limited by the accuracy of\ncomplex prediction, tasks based on precise protein-protein interaction analysis\nalso face obstacles. In this report, we highlight the ongoing advancements of\nour protein complex structure prediction model, HelixFold-Multimer,\nunderscoring its enhanced performance. HelixFold-Multimer provides precise\npredictions for diverse protein complex structures, especially in therapeutic\nprotein interactions. Notably, HelixFold-Multimer achieves remarkable success\nin antigen-antibody and peptide-protein structure prediction, greatly\nsurpassing AlphaFold 3. HelixFold-Multimer is now available for public use on\nthe PaddleHelix platform, offering both a general version and an\nantigen-antibody version. Researchers can conveniently access and utilize this\nservice for their development needs.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10260v2",
    "published_date": "2024-04-16 03:29:37 UTC",
    "updated_date": "2024-05-17 11:47:10 UTC"
  },
  {
    "arxiv_id": "2404.10259v4",
    "title": "Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "abstract": "The widespread use of social media has led to a surge in popularity for\nautomated methods of analyzing public opinion. Supervised methods are adept at\ntext categorization, yet the dynamic nature of social media discussions poses a\ncontinual challenge for these techniques due to the constant shifting of the\nfocus. On the other hand, traditional unsupervised methods for extracting\nthemes from public discourse, such as topic modeling, often reveal overarching\npatterns that might not capture specific nuances. Consequently, a significant\nportion of research into social media discourse still depends on\nlabor-intensive manual coding techniques and a human-in-the-loop approach,\nwhich are both time-consuming and costly. In this work, we study the problem of\ndiscovering arguments associated with a specific theme. We propose a generic\nLLMs-in-the-Loop strategy that leverages the advanced capabilities of Large\nLanguage Models (LLMs) to extract latent arguments from social media messaging.\nTo demonstrate our approach, we apply our framework to contentious topics. We\nuse two publicly available datasets: (1) the climate campaigns dataset of 14k\nFacebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of\n9k Facebook ads with 14 themes. Additionally, we design a downstream task as\nstance prediction by leveraging talking points in climate debates. Furthermore,\nwe analyze demographic targeting and the adaptation of messaging based on\nreal-world events.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the Findings of 2025 Annual Conference of the Nations of\n  the Americas Chapter of the ACL (NAACL 2025)",
    "pdf_url": "http://arxiv.org/pdf/2404.10259v4",
    "published_date": "2024-04-16 03:26:43 UTC",
    "updated_date": "2025-01-27 16:15:26 UTC"
  },
  {
    "arxiv_id": "2404.10242v1",
    "title": "Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology",
    "authors": [
      "Oren Kraus",
      "Kian Kenyon-Dean",
      "Saber Saberian",
      "Maryam Fallah",
      "Peter McLean",
      "Jess Leung",
      "Vasudev Sharma",
      "Ayla Khan",
      "Jia Balakrishnan",
      "Safiye Celik",
      "Dominique Beaini",
      "Maciej Sypetkowski",
      "Chi Vicky Cheng",
      "Kristen Morse",
      "Maureen Makes",
      "Ben Mabey",
      "Berton Earnshaw"
    ],
    "abstract": "Featurizing microscopy images for use in biological research remains a\nsignificant challenge, especially for large-scale experiments spanning millions\nof images. This work explores the scaling properties of weakly supervised\nclassifiers and self-supervised masked autoencoders (MAEs) when training with\nincreasingly larger model backbones and microscopy datasets. Our results show\nthat ViT-based MAEs outperform weakly supervised classifiers on a variety of\ntasks, achieving as much as a 11.5% relative improvement when recalling known\nbiological relationships curated from public databases. Additionally, we\ndevelop a new channel-agnostic MAE architecture (CA-MAE) that allows for\ninputting images of different numbers and orders of channels at inference time.\nWe demonstrate that CA-MAEs effectively generalize by inferring and evaluating\non a microscopy image dataset (JUMP-CP) generated under different experimental\nconditions with a different channel structure than our pretraining data\n(RPI-93M). Our findings motivate continued research into scaling\nself-supervised learning on microscopy data in order to create powerful\nfoundation models of cellular biology that have the potential to catalyze\nadvancements in drug discovery and beyond.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024 Highlight. arXiv admin note: text overlap with\n  arXiv:2309.16064",
    "pdf_url": "http://arxiv.org/pdf/2404.10242v1",
    "published_date": "2024-04-16 02:42:06 UTC",
    "updated_date": "2024-04-16 02:42:06 UTC"
  },
  {
    "arxiv_id": "2404.10241v1",
    "title": "Vision-and-Language Navigation via Causal Learning",
    "authors": [
      "Liuyi Wang",
      "Zongtao He",
      "Ronghao Dang",
      "Mengjiao Shen",
      "Chengju Liu",
      "Qijun Chen"
    ],
    "abstract": "In the pursuit of robust and generalizable environment perception and\nlanguage understanding, the ubiquitous challenge of dataset bias continues to\nplague vision-and-language navigation (VLN) agents, hindering their performance\nin unseen environments. This paper introduces the generalized cross-modal\ncausal transformer (GOAT), a pioneering solution rooted in the paradigm of\ncausal inference. By delving into both observable and unobservable confounders\nwithin vision, language, and history, we propose the back-door and front-door\nadjustment causal learning (BACL and FACL) modules to promote unbiased learning\nby comprehensively mitigating potential spurious correlations. Additionally, to\ncapture global confounder features, we propose a cross-modal feature pooling\n(CFP) module supervised by contrastive learning, which is also shown to be\neffective in improving cross-modal representations during pre-training.\nExtensive experiments across multiple VLN datasets (R2R, REVERIE, RxR, and\nSOON) underscore the superiority of our proposed method over previous\nstate-of-the-art approaches. Code is available at\nhttps://github.com/CrystalSixone/VLN-GOAT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10241v1",
    "published_date": "2024-04-16 02:40:35 UTC",
    "updated_date": "2024-04-16 02:40:35 UTC"
  },
  {
    "arxiv_id": "2404.10234v1",
    "title": "Compressible and Searchable: AI-native Multi-Modal Retrieval System with Learned Image Compression",
    "authors": [
      "Jixiang Luo"
    ],
    "abstract": "The burgeoning volume of digital content across diverse modalities\nnecessitates efficient storage and retrieval methods. Conventional approaches\nstruggle to cope with the escalating complexity and scale of multimedia data.\nIn this paper, we proposed framework addresses this challenge by fusing\nAI-native multi-modal search capabilities with neural image compression. First\nwe analyze the intricate relationship between compressibility and\nsearchability, recognizing the pivotal role each plays in the efficiency of\nstorage and retrieval systems. Through the usage of simple adapter is to bridge\nthe feature of Learned Image Compression(LIC) and Contrastive Language-Image\nPretraining(CLIP) while retaining semantic fidelity and retrieval of\nmulti-modal data. Experimental evaluations on Kodak datasets demonstrate the\nefficacy of our approach, showcasing significant enhancements in compression\nefficiency and search accuracy compared to existing methodologies. Our work\nmarks a significant advancement towards scalable and efficient multi-modal\nsearch systems in the era of big data.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10234v1",
    "published_date": "2024-04-16 02:29:00 UTC",
    "updated_date": "2024-04-16 02:29:00 UTC"
  },
  {
    "arxiv_id": "2404.10226v1",
    "title": "Find The Gap: Knowledge Base Reasoning For Visual Question Answering",
    "authors": [
      "Elham J. Barezi",
      "Parisa Kordjamshidi"
    ],
    "abstract": "We analyze knowledge-based visual question answering, for which given a\nquestion, the models need to ground it into the visual modality and retrieve\nthe relevant knowledge from a given large knowledge base (KB) to be able to\nanswer. Our analysis has two folds, one based on designing neural architectures\nand training them from scratch, and another based on large pre-trained language\nmodels (LLMs). Our research questions are: 1) Can we effectively augment models\nby explicit supervised retrieval of the relevant KB information to solve the\nKB-VQA problem? 2) How do task-specific and LLM-based models perform in the\nintegration of visual and external knowledge, and multi-hop reasoning over both\nsources of information? 3) Is the implicit knowledge of LLMs sufficient for\nKB-VQA and to what extent it can replace the explicit KB? Our results\ndemonstrate the positive impact of empowering task-specific and LLM models with\nsupervised external and visual knowledge retrieval models. Our findings show\nthat though LLMs are stronger in 1-hop reasoning, they suffer in 2-hop\nreasoning in comparison with our fine-tuned NN model even if the relevant\ninformation from both modalities is available to the model. Moreover, we\nobserved that LLM models outperform the NN model for KB-related questions which\nconfirms the effectiveness of implicit knowledge in LLMs however, they do not\nalleviate the need for external KB.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10226v1",
    "published_date": "2024-04-16 02:11:46 UTC",
    "updated_date": "2024-04-16 02:11:46 UTC"
  },
  {
    "arxiv_id": "2404.10225v1",
    "title": "Rethinking Software Engineering in the Foundation Model Era: From Task-Driven AI Copilots to Goal-Driven AI Pair Programmers",
    "authors": [
      "Ahmed E. Hassan",
      "Gustavo A. Oliva",
      "Dayi Lin",
      "Boyuan Chen",
      "Zhen Ming",
      "Jiang"
    ],
    "abstract": "The advent of Foundation Models (FMs) and AI-powered copilots has transformed\nthe landscape of software development, offering unprecedented code completion\ncapabilities and enhancing developer productivity. However, the current\ntask-driven nature of these copilots falls short in addressing the broader\ngoals and complexities inherent in software engineering (SE). In this paper, we\npropose a paradigm shift towards goal-driven AI-powered pair programmers that\ncollaborate with human developers in a more holistic and context-aware manner.\nWe envision AI pair programmers that are goal-driven, human partners, SE-aware,\nand self-learning. These AI partners engage in iterative, conversation-driven\ndevelopment processes, aligning closely with human goals and facilitating\ninformed decision-making. We discuss the desired attributes of such AI pair\nprogrammers and outline key challenges that must be addressed to realize this\nvision. Ultimately, our work represents a shift from AI-augmented SE to\nAI-transformed SE by replacing code completion with a collaborative partnership\nbetween humans and AI that enhances both productivity and software quality.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10225v1",
    "published_date": "2024-04-16 02:10:20 UTC",
    "updated_date": "2024-04-16 02:10:20 UTC"
  },
  {
    "arxiv_id": "2404.10220v2",
    "title": "Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V",
    "authors": [
      "Peiyuan Zhi",
      "Zhiyuan Zhang",
      "Yu Zhao",
      "Muzhi Han",
      "Zeyu Zhang",
      "Zhitian Li",
      "Ziyuan Jiao",
      "Baoxiong Jia",
      "Siyuan Huang"
    ],
    "abstract": "Autonomous robot navigation and manipulation in open environments require\nreasoning and replanning with closed-loop feedback. In this work, we present\nCOME-robot, the first closed-loop robotic system utilizing the GPT-4V\nvision-language foundation model for open-ended reasoning and adaptive planning\nin real-world scenarios.COME-robot incorporates two key innovative modules: (i)\na multi-level open-vocabulary perception and situated reasoning module that\nenables effective exploration of the 3D environment and target object\nidentification using commonsense knowledge and situated information, and (ii)\nan iterative closed-loop feedback and restoration mechanism that verifies task\nfeasibility, monitors execution success, and traces failure causes across\ndifferent modules for robust failure recovery. Through comprehensive\nexperiments involving 8 challenging real-world mobile and tabletop manipulation\ntasks, COME-robot demonstrates a significant improvement in task success rate\n(~35%) compared to state-of-the-art methods. We further conduct comprehensive\nanalyses to elucidate how COME-robot's design facilitates failure recovery,\nfree-form instruction following, and long-horizon task planning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, Accepted at 2025 IEEE ICRA, website:\n  https://come-robot.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2404.10220v2",
    "published_date": "2024-04-16 02:01:56 UTC",
    "updated_date": "2025-03-07 05:09:28 UTC"
  },
  {
    "arxiv_id": "2404.10218v1",
    "title": "Autonomous Implicit Indoor Scene Reconstruction with Frontier Exploration",
    "authors": [
      "Jing Zeng",
      "Yanxu Li",
      "Jiahao Sun",
      "Qi Ye",
      "Yunlong Ran",
      "Jiming Chen"
    ],
    "abstract": "Implicit neural representations have demonstrated significant promise for 3D\nscene reconstruction. Recent works have extended their applications to\nautonomous implicit reconstruction through the Next Best View (NBV) based\nmethod. However, the NBV method cannot guarantee complete scene coverage and\noften necessitates extensive viewpoint sampling, particularly in complex\nscenes. In the paper, we propose to 1) incorporate frontier-based exploration\ntasks for global coverage with implicit surface uncertainty-based\nreconstruction tasks to achieve high-quality reconstruction. and 2) introduce a\nmethod to achieve implicit surface uncertainty using color uncertainty, which\nreduces the time needed for view selection. Further with these two tasks, we\npropose an adaptive strategy for switching modes in view path planning, to\nreduce time and maintain superior reconstruction quality. Our method exhibits\nthe highest reconstruction quality among all planning methods and superior\nplanning efficiency in methods involving reconstruction tasks. We deploy our\nmethod on a UAV and the results show that our method can plan multi-task views\nand reconstruct a scene with high quality.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.10218v1",
    "published_date": "2024-04-16 01:59:03 UTC",
    "updated_date": "2024-04-16 01:59:03 UTC"
  },
  {
    "arxiv_id": "2404.10211v1",
    "title": "Anomaly Correction of Business Processes Using Transformer Autoencoder",
    "authors": [
      "Ziyou Gong",
      "Xianwen Fang",
      "Ping Wu"
    ],
    "abstract": "Event log records all events that occur during the execution of business\nprocesses, so detecting and correcting anomalies in event log can provide\nreliable guarantee for subsequent process analysis. The previous works mainly\ninclude next event prediction based methods and autoencoder-based methods.\nThese methods cannot accurately and efficiently detect anomalies and correct\nanomalies at the same time, and they all rely on the set threshold to detect\nanomalies. To solve these problems, we propose a business process anomaly\ncorrection method based on Transformer autoencoder. By using self-attention\nmechanism and autoencoder structure, it can efficiently process event sequences\nof arbitrary length, and can directly output corrected business process\ninstances, so that it can adapt to various scenarios. At the same time, the\nanomaly detection is transformed into a classification problem by means of\nselfsupervised learning, so that there is no need to set a specific threshold\nin anomaly detection. The experimental results on several real-life event logs\nshow that the proposed method is superior to the previous methods in terms of\nanomaly detection accuracy and anomaly correction results while ensuring high\nrunning efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10211v1",
    "published_date": "2024-04-16 01:45:18 UTC",
    "updated_date": "2024-04-16 01:45:18 UTC"
  },
  {
    "arxiv_id": "2404.10209v3",
    "title": "Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models",
    "authors": [
      "Siqiao Xue",
      "Danrui Qi",
      "Caigao Jiang",
      "Wenhui Shi",
      "Fangyin Cheng",
      "Keting Chen",
      "Hongjun Yang",
      "Zhiping Zhang",
      "Jianshan He",
      "Hongyang Zhang",
      "Ganglin Wei",
      "Wang Zhao",
      "Fan Zhou",
      "Hong Yi",
      "Shaodong Liu",
      "Hongjun Yang",
      "Faqiang Chen"
    ],
    "abstract": "The recent breakthroughs in large language models (LLMs) are positioned to\ntransition many areas of software. The technologies of interacting with data\nparticularly have an important entanglement with LLMs as efficient and\nintuitive data interactions are paramount. In this paper, we present DB-GPT, a\nrevolutionary and product-ready Python library that integrates LLMs into\ntraditional data interaction tasks to enhance user experience and\naccessibility. DB-GPT is designed to understand data interaction tasks\ndescribed by natural language and provide context-aware responses powered by\nLLMs, making it an indispensable tool for users ranging from novice to expert.\nIts system design supports deployment across local, distributed, and cloud\nenvironments. Beyond handling basic data interaction tasks like Text-to-SQL\nwith LLMs, it can handle complex tasks like generative data analysis through a\nMulti-Agents framework and the Agentic Workflow Expression Language (AWEL). The\nService-oriented Multi-model Management Framework (SMMF) ensures data privacy\nand security, enabling users to employ DB-GPT with private LLMs. Additionally,\nDB-GPT offers a series of product-ready features designed to enable users to\nintegrate DB-GPT within their product environments easily. The code of DB-GPT\nis available at Github(https://github.com/eosphoros-ai/DB-GPT) which already\nhas over 10.7k stars. Please install DB-GPT for your own usage with the\ninstructions(https://github.com/eosphoros-ai/DB-GPT#install) and watch a\n5-minute introduction video on Youtube(https://youtu.be/n_8RI1ENyl4) to further\ninvestigate DB-GPT.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10209v3",
    "published_date": "2024-04-16 01:38:34 UTC",
    "updated_date": "2024-04-24 23:50:13 UTC"
  },
  {
    "arxiv_id": "2404.10202v1",
    "title": "Towards a Novel Perspective on Adversarial Examples Driven by Frequency",
    "authors": [
      "Zhun Zhang",
      "Yi Zeng",
      "Qihe Liu",
      "Shijie Zhou"
    ],
    "abstract": "Enhancing our understanding of adversarial examples is crucial for the secure\napplication of machine learning models in real-world scenarios. A prevalent\nmethod for analyzing adversarial examples is through a frequency-based\napproach. However, existing research indicates that attacks designed to exploit\nlow-frequency or high-frequency information can enhance attack performance,\nleading to an unclear relationship between adversarial perturbations and\ndifferent frequency components. In this paper, we seek to demystify this\nrelationship by exploring the characteristics of adversarial perturbations\nwithin the frequency domain. We employ wavelet packet decomposition for\ndetailed frequency analysis of adversarial examples and conduct statistical\nexaminations across various frequency bands. Intriguingly, our findings\nindicate that significant adversarial perturbations are present within the\nhigh-frequency components of low-frequency bands. Drawing on this insight, we\npropose a black-box adversarial attack algorithm based on combining different\nfrequency bands. Experiments conducted on multiple datasets and models\ndemonstrate that combining low-frequency bands and high-frequency components of\nlow-frequency bands can significantly enhance attack efficiency. The average\nattack success rate reaches 99\\%, surpassing attacks that utilize a single\nfrequency segment. Additionally, we introduce the normalized disturbance\nvisibility index as a solution to the limitations of $L_2$ norm in assessing\ncontinuous and discrete perturbations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10202v1",
    "published_date": "2024-04-16 00:58:46 UTC",
    "updated_date": "2024-04-16 00:58:46 UTC"
  },
  {
    "arxiv_id": "2404.10200v1",
    "title": "TEL'M: Test and Evaluation of Language Models",
    "authors": [
      "George Cybenko",
      "Joshua Ackerman",
      "Paul Lintilhac"
    ],
    "abstract": "Language Models have demonstrated remarkable capabilities on some tasks while\nfailing dramatically on others. The situation has generated considerable\ninterest in understanding and comparing the capabilities of various Language\nModels (LMs) but those efforts have been largely ad hoc with results that are\noften little more than anecdotal. This is in stark contrast with testing and\nevaluation processes used in healthcare, radar signal processing, and other\ndefense areas. In this paper, we describe Test and Evaluation of Language\nModels (TEL'M) as a principled approach for assessing the value of current and\nfuture LMs focused on high-value commercial, government and national security\napplications. We believe that this methodology could be applied to other\nArtificial Intelligence (AI) technologies as part of the larger goal of\n\"industrializing\" AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10200v1",
    "published_date": "2024-04-16 00:54:17 UTC",
    "updated_date": "2024-04-16 00:54:17 UTC"
  },
  {
    "arxiv_id": "2404.10199v5",
    "title": "CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting",
    "authors": [
      "Huihan Li",
      "Liwei Jiang",
      "Jena D. Hwang",
      "Hyunwoo Kim",
      "Sebastin Santy",
      "Taylor Sorensen",
      "Bill Yuchen Lin",
      "Nouha Dziri",
      "Xiang Ren",
      "Yejin Choi"
    ],
    "abstract": "As the utilization of large language models (LLMs) has proliferated\nworld-wide, it is crucial for them to have adequate knowledge and fair\nrepresentation for diverse global cultures. In this work, we uncover culture\nperceptions of three SOTA models on 110 countries and regions on 8\nculture-related topics through culture-conditioned generations, and extract\nsymbols from these generations that are associated to each culture by the LLM.\nWe discover that culture-conditioned generation consist of linguistic \"markers\"\nthat distinguish marginalized cultures apart from default cultures. We also\ndiscover that LLMs have an uneven degree of diversity in the culture symbols,\nand that cultures from different geographic regions have different presence in\nLLMs' culture-agnostic generation. Our findings promote further research in\nstudying the knowledge and fairness of global culture perception in LLMs. Code\nand Data can be found here: https://github.com/huihanlhh/Culture-Gen/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10199v5",
    "published_date": "2024-04-16 00:50:43 UTC",
    "updated_date": "2024-08-20 06:53:45 UTC"
  },
  {
    "arxiv_id": "2404.10198v3",
    "title": "ClashEval: Quantifying the tug-of-war between an LLM's internal prior and external evidence",
    "authors": [
      "Kevin Wu",
      "Eric Wu",
      "James Zou"
    ],
    "abstract": "Retrieval augmented generation (RAG) is frequently used to mitigate\nhallucinations and provide up-to-date knowledge for large language models\n(LLMs). However, given that document retrieval is an imprecise task and\nsometimes results in erroneous or even harmful content being presented in\ncontext, this raises the question of how LLMs handle retrieved information: If\nthe provided content is incorrect, does the model know to ignore it, or does it\nrecapitulate the error? Conversely, when the model's initial response is\nincorrect, does it always know to use the retrieved information to correct\nitself, or does it insist on its wrong prior response? To answer this, we\ncurate a dataset of over 1200 questions across six domains (e.g., drug dosages,\nOlympic records, locations) along with content relevant to answering each\nquestion. We further apply precise perturbations to the answers in the content\nthat range from subtle to blatant errors. We benchmark six top-performing LLMs,\nincluding GPT-4o, on this dataset and find that LLMs are susceptible to\nadopting incorrect retrieved content, overriding their own correct prior\nknowledge over 60% of the time. However, the more unrealistic the retrieved\ncontent is (i.e. more deviated from truth), the less likely the model is to\nadopt it. Also, the less confident a model is in its initial response (via\nmeasuring token probabilities), the more likely it is to adopt the information\nin the retrieved content. We exploit this finding and demonstrate simple\nmethods for improving model accuracy where there is conflicting retrieved\ncontent. Our results highlight a difficult task and benchmark for LLMs --\nnamely, their ability to correctly discern when it is wrong in light of correct\nretrieved content and to reject cases when the provided content is incorrect.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Revised June 9 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10198v3",
    "published_date": "2024-04-16 00:43:03 UTC",
    "updated_date": "2025-02-07 05:11:18 UTC"
  },
  {
    "arxiv_id": "2404.10800v3",
    "title": "Integrating Graph Neural Networks with Scattering Transform for Anomaly Detection",
    "authors": [
      "Abdeljalil Zoubir",
      "Badr Missaoui"
    ],
    "abstract": "In this paper, we present two novel methods in Network Intrusion Detection\nSystems (NIDS) using Graph Neural Networks (GNNs). The first approach,\nScattering Transform with E-GraphSAGE (STEG), utilizes the scattering transform\nto conduct multi-resolution analysis of edge feature vectors. This provides a\ndetailed representation that is essential for identifying subtle anomalies in\nnetwork traffic. The second approach improves node representation by initiating\nwith Node2Vec, diverging from standard methods of using uniform values, thereby\ncapturing a more accurate and holistic network picture. Our methods have shown\nsignificant improvements in performance compared to existing state-of-the-art\nmethods in benchmark NIDS datasets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10800v3",
    "published_date": "2024-04-16 00:02:12 UTC",
    "updated_date": "2024-04-24 12:43:30 UTC"
  }
]