{
  "date": "2024-03-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-27 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能和机器学习领域，特别是大型语言模型（LLMs）的优化、视觉语言模型的创新应用、强化学习在机器人和决策中的进展，以及图像生成和跨领域应用的探索。其中，LLMs 相关论文最令人印象深刻，如 Google 和 Stanford 等机构的贡献，突显了模型在实际任务中的鲁棒性和公平性改进。\n\n### 重点论文聚焦\n我挑选了今天最有影响力和话题度的论文进行简要分析，先从 LLMs 和视觉语言模型入手，再聊强化学习和图像生成领域。其他较基础或窄众论文（如某些特定领域的算法优化）则快速掠过，以控制篇幅。\n\n#### LLMs 和多模态模型的优化与应用\n- **BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text**（BioMedLM: 一种基于生物医学文本训练的 2.7B 参数语言模型）  \n  这篇论文由 Google DeepMind 和 Stanford 的研究者提出，贡献了一个紧凑的 LLMs 模型，仅使用 PubMed 数据训练，在生物医学问答任务中表现出色，与更大模型（如 GPT-4）竞争。该模型的优势在于高效性（参数少、计算友好），并在医学任务中提升了准确率，适合资源受限的应用。\n\n- **Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models**（Mini-Gemini: 挖掘多模态视觉语言模型的潜力）  \n  来自 NVlabs 的团队开发了 Mini-Gemini，一种高效的多模态模型，改进了高分辨率视觉令牌和高质数据处理。该发现显示，该模型在视频理解和生成任务中性能几乎翻倍，相比现有模型减少了计算开销，是多模态 AI 领域的亮点。\n\n- **Long-form factuality in large language models**（大型语言模型中的长文本事实性）  \n  Google DeepMind 的研究者构建了 LongFact 数据集和 SAFE 评估框架，揭示 LLMs 在长文本生成中的事实性问题，并通过强化学习优化了准确性。该贡献在于提供了一个可扩展的评估方法，提升了 LLMs 在真实应用中的可靠性。\n\n- **Measuring Political Bias in Large Language Models: What Is Said and How It Is Said**（测量大型语言模型中的政治偏差：内容与表达方式）  \n  来自香港科技大学和 CMU 的学者分析了 LLMs 的政治偏差，通过内容和风格评估发现模型在敏感话题上存在偏差。该论文的发现有助于改进 LLMs 的公平性，强调了偏差检测在社会应用中的重要性。\n\n- **What are human values, and how do we align AI to them?**（什么是人类价值观，以及如何使 AI 与其对齐？）  \n  Meta 和独立研究者的工作探索了 LLMs 与人类价值观的对齐问题，提出 Moral Graph Elicitation 方法。该创新在于使用 LLMs 模拟人类决策过程，提高了模型在道德任务中的表现，适用于伦理 AI 设计。\n\n#### 视觉和图像生成领域的创新\n- **LITA: Language Instructed Temporal-Localization Assistant**（LITA: 语言指导的时序定位助手）  \n  NVIDIA 的团队提出了 LITA 模型，改进了视频 LLMs 在时序定位上的能力，通过时间令牌和 SlowFast 架构提升了准确性。该发现显著提高了视频理解任务的 mIoU 指标，是多模态视频处理的突破。\n\n- **TextCraftor: Your Text Encoder Can be Image Quality Controller**（TextCraftor: 你的文本编码器可以成为图像质量控制器）  \n  Adobe 和 Snap 的研究者发现，通过微调文本编码器（如 CLIP），可以提升文本到图像扩散模型的性能。该贡献在于实现图像生成的可控性，实验显示在 TIFA 基准上性能提升 36%，为图像编辑应用提供了新工具。\n\n- **ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation**（ECoDepth: 有效条件化扩散模型用于单目深度估计）  \n  该论文引入了基于 ViT 嵌入的扩散模型，改进了单目深度估计的准确性。在 NYUv2 和 KITTI 数据集上，模型实现了 14% 的误差降低，强调了全局语义信息在深度任务中的作用。\n\n#### 强化学习和机器人领域的进展\n- **Towards Human-Centered Construction Robotics: A Reinforcement Learning-Driven Companion Robot**（面向人类的建筑机器人：基于强化学习的伴侣机器人）  \n  来自 Carnegie Mellon 的研究者设计了强化学习驱动的建筑机器人原型，强调了人机协作的安全性。该发现通过 RL 框架提升了工作流效率，适用于动态环境中的机器人应用。\n\n- **Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with Asymmetric Rewards**（利用动态对称性进行基于模型的强化学习，支持不对称奖励）  \n  UC Berkeley 的团队提出了利用对称性的 RL 方法，改进了模型在不对称奖励环境中的准确性。实验证明，该方法在真实世界场景中学习更高效，扩展了 RL 的适用范围。\n\n其他论文，如那些专注于特定数据集或基础算法（如第11、30、44等），虽有贡献但影响力较小，我仅快速提及：它们主要涉及领域如网络安全、生物医学和数据聚类，提供了一些实用工具，但未带来重大突破，故不展开讨论。\n\n总之，今天的 arXiv 论文突显了 AI 模型在效率、公平性和多模态处理上的优化潜力，LLMs 相关工作尤其值得关注。更多细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2403.19060v3",
      "title": "Towards Human-Centered Construction Robotics: A Reinforcement Learning-Driven Companion Robot for Contextually Assisting Carpentry Workers",
      "title_zh": "翻译失败",
      "authors": [
        "Yuning Wu",
        "Jiaying Wei",
        "Jean Oh",
        "Daniel Cardoso Llach"
      ],
      "abstract": "In the dynamic construction industry, traditional robotic integration has\nprimarily focused on automating specific tasks, often overlooking the\ncomplexity and variability of human aspects in construction workflows. This\npaper introduces a human-centered approach with a \"work companion rover\"\ndesigned to assist construction workers within their existing practices, aiming\nto enhance safety and workflow fluency while respecting construction labor's\nskilled nature. We conduct an in-depth study on deploying a robotic system in\ncarpentry formwork, showcasing a prototype that emphasizes mobility, safety,\nand comfortable worker-robot collaboration in dynamic environments through a\ncontextual Reinforcement Learning (RL)-driven modular framework. Our research\nadvances robotic applications in construction, advocating for collaborative\nmodels where adaptive robots support rather than replace humans, underscoring\nthe potential for an interactive and collaborative human-robot workforce.",
      "tldr_zh": "本研究针对建筑行业的传统机器人应用，强调其忽略了人类因素的复杂性和可变性，提出一种以人为本的“work companion rover”机器人，旨在在现有工作流程中辅助木工，提高安全性和工作流畅性，同时尊重工人的技能。机器人采用基于 Reinforcement Learning (RL) 的模块化框架，实现上下文感知的移动、安全和舒适的人机协作，通过原型在木工模板部署中进行深入研究。结果显示，这种协作模式能有效支持工人而非取代他们，推动建筑业向互动式的人机工作队伍转型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 9 figures. This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2403.19060v3",
      "published_date": "2024-03-27 23:55:02 UTC",
      "updated_date": "2024-09-14 13:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:19:19.997622"
    },
    {
      "arxiv_id": "2403.19050v3",
      "title": "Detecting Generative Parroting through Overfitting Masked Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Saeid Asgari Taghanaki",
        "Joseph Lambourne"
      ],
      "abstract": "The advent of generative AI models has revolutionized digital content\ncreation, yet it introduces challenges in maintaining copyright integrity due\nto generative parroting, where models mimic their training data too closely.\nOur research presents a novel approach to tackle this issue by employing an\noverfitted Masked Autoencoder (MAE) to detect such parroted samples\neffectively. We establish a detection threshold based on the mean loss across\nthe training dataset, allowing for the precise identification of parroted\ncontent in modified datasets. Preliminary evaluations demonstrate promising\nresults, suggesting our method's potential to ensure ethical use and enhance\nthe legal compliance of generative models.",
      "tldr_zh": "该研究针对生成式 AI 模型的 generative parroting 问题（即模型过度模仿训练数据，导致版权风险），提出了一种新颖的检测方法，使用 overfitted Masked Autoencoder (MAE) 来有效识别这些模仿样本。方法通过基于训练数据集的平均损失建立检测阈值，从而在修改的数据集中精确检测 parroted 内容。初步评估结果显示，该方法表现出色，有助于提升生成模型的道德使用和法律合规性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to CVPR 2024, Responsible Generative AI workshop",
      "pdf_url": "http://arxiv.org/pdf/2403.19050v3",
      "published_date": "2024-03-27 23:10:33 UTC",
      "updated_date": "2024-06-19 19:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:19:32.901051"
    },
    {
      "arxiv_id": "2403.19046v1",
      "title": "LITA: Language Instructed Temporal-Localization Assistant",
      "title_zh": "LITA：语言指导的时间定位助手",
      "authors": [
        "De-An Huang",
        "Shijia Liao",
        "Subhashree Radhakrishnan",
        "Hongxu Yin",
        "Pavlo Molchanov",
        "Zhiding Yu",
        "Jan Kautz"
      ],
      "abstract": "There has been tremendous progress in multimodal Large Language Models\n(LLMs). Recent works have extended these models to video input with promising\ninstruction following capabilities. However, an important missing piece is\ntemporal localization. These models cannot accurately answer the \"When?\"\nquestions. We identify three key aspects that limit their temporal localization\ncapabilities: (i) time representation, (ii) architecture, and (iii) data. We\naddress these shortcomings by proposing Language Instructed\nTemporal-Localization Assistant (LITA) with the following features: (1) We\nintroduce time tokens that encode timestamps relative to the video length to\nbetter represent time in videos. (2) We introduce SlowFast tokens in the\narchitecture to capture temporal information at fine temporal resolution. (3)\nWe emphasize temporal localization data for LITA. In addition to leveraging\nexisting video datasets with timestamps, we propose a new task, Reasoning\nTemporal Localization (RTL), along with the dataset, ActivityNet-RTL, for\nlearning and evaluating this task. Reasoning temporal localization requires\nboth the reasoning and temporal localization of Video LLMs. LITA demonstrates\nstrong performance on this challenging task, nearly doubling the temporal mean\nintersection-over-union (mIoU) of baselines. In addition, we show that our\nemphasis on temporal localization also substantially improves video-based text\ngeneration compared to existing Video LLMs, including a 36% relative\nimprovement of Temporal Understanding. Code is available at:\nhttps://github.com/NVlabs/LITA",
      "tldr_zh": "本研究提出LITA（Language Instructed Temporal-Localization Assistant），旨在提升多模态Large Language Models (LLMs)在视频输入中的时间定位能力，解决现有模型在时间表示、架构和数据方面的局限性。LITA引入time tokens来编码视频相对时间戳，以及SlowFast tokens在架构中捕获精细的时间信息，同时强调时间定位数据，包括利用现有数据集和提出新任务Reasoning Temporal Localization (RTL)及其数据集ActivityNet-RTL，以实现视频推理和定位的结合。实验结果显示，LITA在RTL任务上使temporal mean intersection-over-union (mIoU)几乎提高一倍，并在视频-based文本生成中取得显著提升，包括Temporal Understanding的36%相对改善。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19046v1",
      "published_date": "2024-03-27 22:50:48 UTC",
      "updated_date": "2024-03-27 22:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:19:44.469663"
    },
    {
      "arxiv_id": "2403.19721v1",
      "title": "Computationally and Memory-Efficient Robust Predictive Analytics Using Big Data",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Menges",
        "Adil Rasheed"
      ],
      "abstract": "In the current data-intensive era, big data has become a significant asset\nfor Artificial Intelligence (AI), serving as a foundation for developing\ndata-driven models and providing insight into various unknown fields. This\nstudy navigates through the challenges of data uncertainties, storage\nlimitations, and predictive data-driven modeling using big data. We utilize\nRobust Principal Component Analysis (RPCA) for effective noise reduction and\noutlier elimination, and Optimal Sensor Placement (OSP) for efficient data\ncompression and storage. The proposed OSP technique enables data compression\nwithout substantial information loss while simultaneously reducing storage\nneeds. While RPCA offers an enhanced alternative to traditional Principal\nComponent Analysis (PCA) for high-dimensional data management, the scope of\nthis work extends its utilization, focusing on robust, data-driven modeling\napplicable to huge data sets in real-time. For that purpose, Long Short-Term\nMemory (LSTM) networks, a type of recurrent neural network, are applied to\nmodel and predict data based on a low-dimensional subset obtained from OSP,\nleading to a crucial acceleration of the training phase. LSTMs are feasible for\ncapturing long-term dependencies in time series data, making them particularly\nsuited for predicting the future states of physical systems on historical data.\nAll the presented algorithms are not only theorized but also simulated and\nvalidated using real thermal imaging data mapping a ship's engine.",
      "tldr_zh": "这篇论文针对大数据中的不确定性、存储限制和预测建模挑战，提出了一种计算和内存高效的鲁棒预测分析方法。研究团队利用 Robust Principal Component Analysis (RPCA) 来减少噪声和消除异常值，同时采用 Optimal Sensor Placement (OSP) 进行数据压缩，以最小化信息损失并优化存储。基于 OSP 获得的数据子集，他们应用 Long Short-Term Memory (LSTM) 网络进行数据建模和预测，显著加速训练过程并捕捉时间序列中的长期依赖关系。该方法通过真实热成像数据（如船引擎映射）的模拟验证，展示了在实时大数据集上的实用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19721v1",
      "published_date": "2024-03-27 22:39:08 UTC",
      "updated_date": "2024-03-27 22:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:19:56.715951"
    },
    {
      "arxiv_id": "2403.19031v1",
      "title": "Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting Guo",
        "Anthony Ovadje",
        "Mohammed Ali Al-Garadi",
        "Abeed Sarker"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable success in NLP\ntasks. However, there is a paucity of studies that attempt to evaluate their\nperformances on social media-based health-related natural language processing\ntasks, which have traditionally been difficult to achieve high scores in. We\nbenchmarked one supervised classic machine learning model based on Support\nVector Machines (SVMs), three supervised pretrained language models (PLMs)\nbased on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5\nand GPT4), across 6 text classification tasks. We developed three approaches\nfor leveraging LLMs for text classification: employing LLMs as zero-shot\nclassifiers, us-ing LLMs as annotators to annotate training data for supervised\nclassifiers, and utilizing LLMs with few-shot examples for augmentation of\nmanually annotated data. Our comprehensive experiments demonstrate that\nemploy-ing data augmentation using LLMs (GPT-4) with relatively small\nhuman-annotated data to train lightweight supervised classification models\nachieves superior results compared to training with human-annotated data alone.\nSupervised learners also outperform GPT-4 and GPT-3.5 in zero-shot settings. By\nleveraging this data augmentation strategy, we can harness the power of LLMs to\ndevelop smaller, more effective domain-specific NLP models. LLM-annotated data\nwithout human guidance for training light-weight supervised classification\nmodels is an ineffective strategy. However, LLM, as a zero-shot classifier,\nshows promise in excluding false negatives and potentially reducing the human\neffort required for data annotation. Future investigations are imperative to\nexplore optimal training data sizes and the optimal amounts of augmented data.",
      "tldr_zh": "这篇论文评估了 Large Language Models (LLMs) 在基于社交媒体的健康相关文本分类任务中的性能，通过基准测试 Support Vector Machines (SVMs)、预训练语言模型 (如 RoBERTa、BERTweet 和 SocBERT) 以及 LLMs (GPT-3.5 和 GPT-4)。他们探索了三种方法：将 LLMs 用作零样本分类器、作为标注器生成训练数据，或结合少样本示例进行数据增强。实验结果表明，使用 LLMs (如 GPT-4) 进行数据增强后训练轻量级监督分类模型，能显著优于仅靠人类标注数据，且监督模型在零样本设置中表现优于 GPT-4 和 GPT-3.5；然而，LLMs 作为零样本分类器可帮助减少人类标注努力，并建议未来研究优化训练数据规模和增强数据量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19031v1",
      "published_date": "2024-03-27 22:05:10 UTC",
      "updated_date": "2024-03-27 22:05:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:20:11.655947"
    },
    {
      "arxiv_id": "2403.19024v3",
      "title": "Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with Asymmetric Rewards",
      "title_zh": "翻译失败",
      "authors": [
        "Yasin Sonmez",
        "Neelay Junnarkar",
        "Murat Arcak"
      ],
      "abstract": "Recent work in reinforcement learning has leveraged symmetries in the model\nto improve sample efficiency in training a policy. A commonly used simplifying\nassumption is that the dynamics and reward both exhibit the same symmetry;\nhowever, in many real-world environments, the dynamical model exhibits symmetry\nindependent of the reward model. In this paper, we assume only the dynamics\nexhibit symmetry, extending the scope of problems in reinforcement learning and\nlearning in control theory to which symmetry techniques can be applied. We use\nCartan's moving frame method to introduce a technique for learning dynamics\nthat, by construction, exhibit specified symmetries. Numerical experiments\ndemonstrate that the proposed method learns a more accurate dynamical model",
      "tldr_zh": "这篇论文探讨了在模型驱动强化学习中，利用动态模型的对称性来提升策略训练效率，即使奖励函数不对称。作者假设仅动态模型表现出对称性，并使用 Cartan's moving frame method 构建一种学习动态的技术，以确保模型符合指定对称性。数值实验表明，该方法能够学习到更准确的动态模型，从而扩展了对称性技术在强化学习和控制理论中的应用范围。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19024v3",
      "published_date": "2024-03-27 21:31:46 UTC",
      "updated_date": "2024-08-16 18:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:20:19.707831"
    },
    {
      "arxiv_id": "2403.19021v2",
      "title": "IDGenRec: LLM-RecSys Alignment with Textual ID Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Juntao Tan",
        "Shuyuan Xu",
        "Wenyue Hua",
        "Yingqiang Ge",
        "Zelong Li",
        "Yongfeng Zhang"
      ],
      "abstract": "Generative recommendation based on Large Language Models (LLMs) have\ntransformed the traditional ranking-based recommendation style into a\ntext-to-text generation paradigm. However, in contrast to standard NLP tasks\nthat inherently operate on human vocabulary, current research in generative\nrecommendations struggles to effectively encode recommendation items within the\ntext-to-text framework using concise yet meaningful ID representations. To\nbetter align LLMs with recommendation needs, we propose IDGen, representing\neach item as a unique, concise, semantically rich, platform-agnostic textual ID\nusing human language tokens. This is achieved by training a textual ID\ngenerator alongside the LLM-based recommender, enabling seamless integration of\npersonalized recommendations into natural language generation. Notably, as user\nhistory is expressed in natural language and decoupled from the original\ndataset, our approach suggests the potential for a foundational generative\nrecommendation model. Experiments show that our framework consistently\nsurpasses existing models in sequential recommendation under standard\nexperimental setting. Then, we explore the possibility of training a foundation\nrecommendation model with the proposed method on data collected from 19\ndifferent datasets and tested its recommendation performance on 6 unseen\ndatasets across different platforms under a completely zero-shot setting. The\nresults show that the zero-shot performance of the pre-trained foundation model\nis comparable to or even better than some traditional recommendation models\nbased on supervised training, showing the potential of the IDGen paradigm\nserving as the foundation model for generative recommendation. Code and data\nare open-sourced at https://github.com/agiresearch/IDGenRec.",
      "tldr_zh": "该研究提出IDGen方法，以改善大型语言模型(LLMs)与推荐系统(RecSys)的对齐问题，通过为每个推荐项目生成独特、简洁且语义丰富的文本ID，使用人类语言标记来实现。IDGen通过训练一个文本ID生成器与LLM-based推荐器相结合，使个性化推荐无缝整合到自然语言生成中，并将用户历史以自然语言表达，解耦原始数据集，从而支持构建基础生成式推荐模型。实验结果显示，该框架在顺序推荐任务中超越现有模型，并在19个数据集上训练的模型于6个未见数据集的零样本测试中，性能与监督训练的传统推荐模型相当或更优，展示了IDGen范式的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted in SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.19021v2",
      "published_date": "2024-03-27 21:22:37 UTC",
      "updated_date": "2024-05-17 04:05:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:20:33.031836"
    },
    {
      "arxiv_id": "2403.19012v2",
      "title": "ReflectSumm: A Benchmark for Course Reflection Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhong",
        "Mohamed Elaraby",
        "Diane Litman",
        "Ahmed Ashraf Butt",
        "Muhsin Menekse"
      ],
      "abstract": "This paper introduces ReflectSumm, a novel summarization dataset specifically\ndesigned for summarizing students' reflective writing. The goal of ReflectSumm\nis to facilitate developing and evaluating novel summarization techniques\ntailored to real-world scenarios with little training data, %practical tasks\nwith potential implications in the opinion summarization domain in general and\nthe educational domain in particular. The dataset encompasses a diverse range\nof summarization tasks and includes comprehensive metadata, enabling the\nexploration of various research questions and supporting different\napplications. To showcase its utility, we conducted extensive evaluations using\nmultiple state-of-the-art baselines. The results provide benchmarks for\nfacilitating further research in this area.",
      "tldr_zh": "这篇论文引入了 ReflectSumm，这是一个专门针对学生反思性写作总结的新型 summarization dataset。ReflectSumm 的目标是促进开发和评估适用于真实场景的总结技术，这些场景数据有限，并可能扩展到意见总结领域，特别是教育领域；数据集包含多样任务和全面元数据，支持各种研究问题和应用。为了验证其效用，论文使用多个 state-of-the-art 基线进行了广泛评估，并提供了基准结果，以推动该领域的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING 2024 camera ready; code and dataset are available at\n  https://github.com/EngSalem/ReflectSUMM",
      "pdf_url": "http://arxiv.org/pdf/2403.19012v2",
      "published_date": "2024-03-27 21:10:07 UTC",
      "updated_date": "2024-04-23 02:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:20:44.472614"
    },
    {
      "arxiv_id": "2403.19001v4",
      "title": "Cross-domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yui Lo",
        "Yuqian Chen",
        "Dongnan Liu",
        "Wan Liu",
        "Leo Zekelman",
        "Fan Zhang",
        "Yogesh Rathi",
        "Nikos Makris",
        "Alexandra J. Golby",
        "Weidong Cai",
        "Lauren J. O'Donnell"
      ],
      "abstract": "Shape plays an important role in computer graphics, offering informative\nfeatures to convey an object's morphology and functionality. Shape analysis in\nbrain imaging can help interpret structural and functionality correlations of\nthe human brain. In this work, we investigate the shape of the brain's 3D white\nmatter connections and its potential predictive relationship to human cognitive\nfunction. We reconstruct brain connections as sequences of 3D points using\ndiffusion magnetic resonance imaging (dMRI) tractography. To describe each\nconnection, we extract 12 shape descriptors in addition to traditional dMRI\nconnectivity and tissue microstructure features. We introduce a novel\nframework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a\nmulti-head cross-attention feature fusion module to predict subject-specific\nlanguage performance based on dMRI tractography. We assess the performance of\nthe method on a large dataset including 1065 healthy young adults. The results\ndemonstrate that both the transformer-based SFFormer model and its inter/intra\nfeature fusion with shape, microstructure, and connectivity are informative,\nand together, they improve the prediction of subject-specific language\nperformance scores. Overall, our results indicate that the shape of the brain's\nconnections is predictive of human language function.",
      "tldr_zh": "本研究调查了脑白质连接的形状如何预测人类语言认知表现，通过使用 diffusion magnetic resonance imaging (dMRI) 轨迹重建技术提取12个形状描述符，并结合传统的dMRI连接性和微结构特征。研究引入了Shape-fused Fiber Cluster Transformer (SFFormer)框架，该框架利用多头交叉注意力机制融合这些特征，以预测受试者的语言表现分数。在一个包含1065名健康年轻成年人的大型数据集上进行评估，结果显示SFFormer模型及其特征融合方法显著提高了预测准确性，证明了脑连接形状对语言功能的可预测性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted for presentation at The 27th Intl. Conf.\n  on Medical Image Computing and Computer Assisted Intervention (MICCAI 2024)\n  Workshop on Computational Diffusion MRI (CDMRI). 11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.19001v4",
      "published_date": "2024-03-27 20:51:02 UTC",
      "updated_date": "2025-04-21 22:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:20:57.991178"
    },
    {
      "arxiv_id": "2403.18998v4",
      "title": "Cross-System Categorization of Abnormal Traces in Microservice-Based Systems via Meta-Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Wang",
        "Mika V. Mäntylä",
        "Serge Demeyer",
        "Mutlu Beyazit",
        "Joanna Kisaakye",
        "Jesse Nyyssölä"
      ],
      "abstract": "Microservice-based systems (MSS) may fail with various fault types. While\nexisting AIOps methods excel at detecting abnormal traces and locating the\nresponsible service(s), human efforts are still required for diagnosing\nspecific fault types and failure causes.This paper presents TraFaultDia, a\nnovel AIOps framework to automatically classify abnormal traces into fault\ncategories for MSS. We treat the classification process as a series of\nmulti-class classification tasks, where each task represents an attempt to\nclassify abnormal traces into specific fault categories for a MSS. TraFaultDia\nleverages meta-learning to train on several abnormal trace classification tasks\nwith a few labeled instances from a MSS, enabling quick adaptation to new,\nunseen abnormal trace classification tasks with a few labeled instances across\nMSS. TraFaultDia's use cases are scalable depending on how fault categories are\nbuilt from anomalies within MSS. We evaluated TraFaultDia on two MSS,\nTrainTicket and OnlineBoutique, with open datasets where each fault category is\nlinked to faulty system components (service/pod) and a root cause. TraFaultDia\nautomatically classifies abnormal traces into these fault categories, thus\nenabling the automatic identification of faulty system components and root\ncauses without manual analysis. TraFaultDia achieves 93.26% and 85.20% accuracy\non 50 new classification tasks for TrainTicket and OnlineBoutique,\nrespectively, when trained within the same MSS with 10 labeled instances per\ncategory. In the cross-system context, when TraFaultDia is applied to a MSS\ndifferent from the one it is trained on, TraFaultDia gets an average accuracy\nof 92.19% and 84.77% for the same set of 50 new, unseen abnormal trace\nclassification tasks of the respective systems, also with 10 labeled instances\nprovided for each fault category per task in each system.",
      "tldr_zh": "该论文提出TraFaultDia，一种基于meta-learning的AIOps框架，用于自动将微服务系统（MSS）的异常追踪分类到特定故障类别，从而减少人工诊断需求。TraFaultDia将分类过程视为一系列多类分类任务，通过在少量标记实例上训练，实现快速适应新任务，包括跨系统场景。实验结果显示，在TrainTicket和OnlineBoutique系统中，该框架在同一系统下的准确率分别达到93.26%和85.20%，而在跨系统应用时，平均准确率仍维持在92.19%和84.77%。这项工作为自动识别故障系统组件和根因提供了高效解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at ACM International Conference on the Foundations of\n  Software Engineering (FSE) 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.18998v4",
      "published_date": "2024-03-27 20:38:04 UTC",
      "updated_date": "2025-02-25 08:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:21:09.181948"
    },
    {
      "arxiv_id": "2403.18989v1",
      "title": "Dealing with Imbalanced Classes in Bot-IoT Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Atuhurra",
        "Takanori Hara",
        "Yuanyu Zhang",
        "Masahiro Sasabe",
        "Shoji Kasahara"
      ],
      "abstract": "With the rapidly spreading usage of Internet of Things (IoT) devices, a\nnetwork intrusion detection system (NIDS) plays an important role in detecting\nand protecting various types of attacks in the IoT network. To evaluate the\nrobustness of the NIDS in the IoT network, the existing work proposed a\nrealistic botnet dataset in the IoT network (Bot-IoT dataset) and applied it to\nmachine learning-based anomaly detection. This dataset contains imbalanced\nnormal and attack packets because the number of normal packets is much smaller\nthan that of attack ones. The nature of imbalanced data may make it difficult\nto identify the minority class correctly. In this thesis, to address the class\nimbalance problem in the Bot-IoT dataset, we propose a binary classification\nmethod with synthetic minority over-sampling techniques (SMOTE). The proposed\nclassifier aims to detect attack packets and overcome the class imbalance\nproblem using the SMOTE algorithm. Through numerical results, we demonstrate\nthe proposed classifier's fundamental characteristics and the impact of\nimbalanced data on its performance.",
      "tldr_zh": "本论文针对 IoT 网络中的网络入侵检测系统 (NIDS)，探讨了 Bot-IoT dataset 中类不平衡问题，即正常数据包远少于攻击数据包，导致少数类识别困难。作者提出了一种二元分类方法，使用合成少数过采样技术 (SMOTE) 算法来生成合成样本，从而提升攻击数据包的检测准确性。通过数值实验，论文展示了该分类器的性能特点，并证明了类不平衡数据对模型影响的显著性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18989v1",
      "published_date": "2024-03-27 20:09:59 UTC",
      "updated_date": "2024-03-27 20:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:21:22.599527"
    },
    {
      "arxiv_id": "2403.18985v2",
      "title": "Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Soumyendu Sarkar",
        "Ashwin Ramesh Babu",
        "Sajad Mousavi",
        "Vineet Gundecha",
        "Avisek Naug",
        "Sahand Ghorbanpour"
      ],
      "abstract": "We present a generic Reinforcement Learning (RL) framework optimized for\ncrafting adversarial attacks on different model types spanning from ECG signal\nanalysis (1D), image classification (2D), and video classification (3D). The\nframework focuses on identifying sensitive regions and inducing\nmisclassifications with minimal distortions and various distortion types. The\nnovel RL method outperforms state-of-the-art methods for all three\napplications, proving its efficiency. Our RL approach produces superior\nlocalization masks, enhancing interpretability for image classification and ECG\nanalysis models. For applications such as ECG analysis, our platform highlights\ncritical ECG segments for clinicians while ensuring resilience against\nprevalent distortions. This comprehensive tool aims to bolster both resilience\nwith adversarial training and transparency across varied applications and data\ntypes.",
      "tldr_zh": "本研究提出一个通用的 Reinforcement Learning (RL) 框架，用于针对黑箱模型的图像分类 (2D)、视频分类 (3D) 和 ECG 信号分析 (1D) 进行对抗性攻击，通过识别敏感区域并最小化失真来诱导错误分类。相比现有方法，该 RL 框架在所有应用中表现出优越性能，并生成更精确的定位掩码，提升了图像和 ECG 分析的可解释性。实验结果显示，该工具能突出 ECG 中的关键段落，提高模型对常见失真的鲁棒性，并通过对抗训练增强整体透明度和韧性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI Proceedings reference:\n  https://ojs.aaai.org/index.php/AAAI/article/view/30579",
      "pdf_url": "http://arxiv.org/pdf/2403.18985v2",
      "published_date": "2024-03-27 20:07:39 UTC",
      "updated_date": "2024-04-22 14:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:21:35.039927"
    },
    {
      "arxiv_id": "2403.18978v1",
      "title": "TextCraftor: Your Text Encoder Can be Image Quality Controller",
      "title_zh": "翻译失败",
      "authors": [
        "Yanyu Li",
        "Xian Liu",
        "Anil Kag",
        "Ju Hu",
        "Yerlan Idelbayev",
        "Dhritiman Sagar",
        "Yanzhi Wang",
        "Sergey Tulyakov",
        "Jian Ren"
      ],
      "abstract": "Diffusion-based text-to-image generative models, e.g., Stable Diffusion, have\nrevolutionized the field of content generation, enabling significant\nadvancements in areas like image editing and video synthesis. Despite their\nformidable capabilities, these models are not without their limitations. It is\nstill challenging to synthesize an image that aligns well with the input text,\nand multiple runs with carefully crafted prompts are required to achieve\nsatisfactory results. To mitigate these limitations, numerous studies have\nendeavored to fine-tune the pre-trained diffusion models, i.e., UNet, utilizing\nvarious technologies. Yet, amidst these efforts, a pivotal question of\ntext-to-image diffusion model training has remained largely unexplored: Is it\npossible and feasible to fine-tune the text encoder to improve the performance\nof text-to-image diffusion models? Our findings reveal that, instead of\nreplacing the CLIP text encoder used in Stable Diffusion with other large\nlanguage models, we can enhance it through our proposed fine-tuning approach,\nTextCraftor, leading to substantial improvements in quantitative benchmarks and\nhuman assessments. Interestingly, our technique also empowers controllable\nimage generation through the interpolation of different text encoders\nfine-tuned with various rewards. We also demonstrate that TextCraftor is\northogonal to UNet finetuning, and can be combined to further improve\ngenerative quality.",
      "tldr_zh": "本文提出TextCraftor，一种微调文本编码器的方法，旨在解决扩散模型（如Stable Diffusion）在文本到图像生成中的问题，例如生成的图像与输入文本不匹配。TextCraftor通过对CLIP文本编码器进行微调，显著提高了定量基准和人类评估的性能，同时实现了通过不同微调编码器的插值来控制图像生成的可控性。该方法与UNet微调正交，可结合使用进一步提升生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18978v1",
      "published_date": "2024-03-27 19:52:55 UTC",
      "updated_date": "2024-03-27 19:52:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:21:45.294977"
    },
    {
      "arxiv_id": "2403.18976v1",
      "title": "\"Sorry, Come Again?\" Prompting -- Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing",
      "title_zh": "翻译失败",
      "authors": [
        "Vipula Rawte",
        "S. M Towhidul Islam Tonmoy",
        "S M Mehedi Zaman",
        "Prachi Priya",
        "Aman Chadha",
        "Amit P. Sheth",
        "Amitava Das"
      ],
      "abstract": "Hallucination has emerged as the most vulnerable aspect of contemporary Large\nLanguage Models (LLMs). In this paper, we introduce the Sorry, Come Again (SCA)\nprompting, aimed to avoid LLM hallucinations by enhancing comprehension\nthrough: (i) optimal paraphrasing and (ii) injecting [PAUSE] tokens to delay\nLLM generation. First, we provide an in-depth analysis of linguistic nuances:\nformality, readability, and concreteness of prompts for 21 LLMs, and elucidate\nhow these nuances contribute to hallucinated generation. Prompts with lower\nreadability, formality, or concreteness pose comprehension challenges for LLMs,\nsimilar to those faced by humans. In such scenarios, an LLM tends to speculate\nand generate content based on its imagination (associative memory) to fill\nthese information gaps. Although these speculations may occasionally align with\nfactual information, their accuracy is not assured, often resulting in\nhallucination. Recent studies reveal that an LLM often neglects the middle\nsections of extended prompts, a phenomenon termed as lost in the middle. While\na specific paraphrase may suit one LLM, the same paraphrased version may elicit\na different response from another LLM. Therefore, we propose an optimal\nparaphrasing technique to identify the most comprehensible paraphrase of a\ngiven prompt, evaluated using Integrated Gradient (and its variations) to\nguarantee that the LLM accurately processes all words. While reading lengthy\nsentences, humans often pause at various points to better comprehend the\nmeaning read thus far. We have fine-tuned an LLM with injected [PAUSE] tokens,\nallowing the LLM to pause while reading lengthier prompts. This has brought\nseveral key contributions: (i) determining the optimal position to inject\n[PAUSE], (ii) determining the number of [PAUSE] tokens to be inserted, and\n(iii) introducing reverse proxy tuning to fine-tune the LLM for [PAUSE]\ninsertion.",
      "tldr_zh": "本研究引入了“Sorry, Come Again (SCA)”提示方法，以提升大型语言模型(LLM)的理解能力和减少Hallucination问题，主要通过最优改述和注入[PAUSE]标记来延迟生成过程。研究分析了提示的语言细微差别，包括正式性、可读性和具体性，揭示这些因素会导致LLM忽略中间内容（lost in the middle）并基于联想记忆生成幻觉。作者提出使用Integrated Gradient及其变体进行最优改述，确保LLM准确处理所有词汇，并通过reverse proxy tuning微调LLM来确定[PAUSE]的位置和数量，从而显著改善长提示的理解。实验结果表明，此方法能有效增强LLM的鲁棒性，为减少幻觉提供新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18976v1",
      "published_date": "2024-03-27 19:45:09 UTC",
      "updated_date": "2024-03-27 19:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:21:58.697639"
    },
    {
      "arxiv_id": "2403.18969v2",
      "title": "A Survey on Large Language Models from Concept to Implementation",
      "title_zh": "从概念到实现的大语言模型调查",
      "authors": [
        "Chen Wang",
        "Jin Zhao",
        "Jiaqi Gong"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs), particularly those built\non Transformer architectures, have significantly broadened the scope of natural\nlanguage processing (NLP) applications, transcending their initial use in\nchatbot technology. This paper investigates the multifaceted applications of\nthese models, with an emphasis on the GPT series. This exploration focuses on\nthe transformative impact of artificial intelligence (AI) driven tools in\nrevolutionizing traditional tasks like coding and problem-solving, while also\npaving new paths in research and development across diverse industries. From\ncode interpretation and image captioning to facilitating the construction of\ninteractive systems and advancing computational domains, Transformer models\nexemplify a synergy of deep learning, data analysis, and neural network design.\nThis survey provides an in-depth look at the latest research in Transformer\nmodels, highlighting their versatility and the potential they hold for\ntransforming diverse application sectors, thereby offering readers a\ncomprehensive understanding of the current and future landscape of\nTransformer-based LLMs in practical applications.",
      "tldr_zh": "这篇论文对大型语言模型(LLMs)从概念到实现的进行了全面调查，重点关注基于Transformer架构的模型，尤其是GPT系列。\n它探讨了LLMs在自然语言处理(NLP)中的多方面应用，包括代码解释、图像描述以及在各种行业中的研究与开发。\n调查强调了这些模型通过深度学习、数据分析和神经网络设计的协同作用，正在革新传统任务并开辟新路径，为读者提供了对Transformer-based LLMs当前和未来应用前景的深入理解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.CL",
      "comment": "Section 3 lacks to clarity and accuracy in defining the applications\n  and capabilities of LLMs. More rework needs to be done on illustrate how LLMs\n  being used in cross-domains",
      "pdf_url": "http://arxiv.org/pdf/2403.18969v2",
      "published_date": "2024-03-27 19:35:41 UTC",
      "updated_date": "2024-05-28 02:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:22:09.926571"
    },
    {
      "arxiv_id": "2403.18965v1",
      "title": "LORD: Large Models based Opposite Reward Design for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Ye",
        "Feng Tao",
        "Abhirup Mallik",
        "Burhaneddin Yaman",
        "Liu Ren"
      ],
      "abstract": "Reinforcement learning (RL) based autonomous driving has emerged as a\npromising alternative to data-driven imitation learning approaches. However,\ncrafting effective reward functions for RL poses challenges due to the\ncomplexity of defining and quantifying good driving behaviors across diverse\nscenarios. Recently, large pretrained models have gained significant attention\nas zero-shot reward models for tasks specified with desired linguistic goals.\nHowever, the desired linguistic goals for autonomous driving such as \"drive\nsafely\" are ambiguous and incomprehensible by pretrained models. On the other\nhand, undesired linguistic goals like \"collision\" are more concrete and\ntractable. In this work, we introduce LORD, a novel large models based opposite\nreward design through undesired linguistic goals to enable the efficient use of\nlarge pretrained models as zero-shot reward models. Through extensive\nexperiments, our proposed framework shows its efficiency in leveraging the\npower of large pretrained models for achieving safe and enhanced autonomous\ndriving. Moreover, the proposed approach shows improved generalization\ncapabilities as it outperforms counterpart methods across diverse and\nchallenging driving scenarios.",
      "tldr_zh": "这篇论文提出LORD框架，一种基于大模型(Large Models)的相反奖励设计(Opposite Reward Design)，通过利用不期望的语言目标（如“collision”）来解决强化学习(Reinforcement Learning, RL)在自动驾驶中的奖励函数设计挑战，从而高效地将大预训练模型用作零样本奖励模型。相比传统方法，LORD显著提升了自动驾驶的安全性和性能，并在多样化场景中展示了更好的泛化能力。实验结果证明，该框架在复杂驾驶环境中优于对照方法，实现了更可靠的自主驾驶系统。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18965v1",
      "published_date": "2024-03-27 19:30:06 UTC",
      "updated_date": "2024-03-27 19:30:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:22:23.207682"
    },
    {
      "arxiv_id": "2403.18963v3",
      "title": "Leveraging Quantum Superposition to Infer the Dynamic Behavior of a Spatial-Temporal Neural Network Signaling Model",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel A. Silva"
      ],
      "abstract": "The exploration of new problem classes for quantum computation is an active\narea of research. In this paper, we introduce and solve a novel problem class\nrelated to dynamics on large-scale networks relevant to neurobiology and\nmachine learning. Specifically, we ask if a network can sustain inherent\ndynamic activity beyond some arbitrary observation time or if the activity\nceases through quiescence or saturation via an epileptic-like state. We show\nthat this class of problems can be formulated and structured to take advantage\nof quantum superposition and solved efficiently using the Deutsch-Jozsa and\nGrover quantum algorithms. To do so, we extend their functionality to address\nthe unique requirements of how input (sub)sets into the algorithms must be\nmathematically structured while simultaneously constructing the inputs so that\nmeasurement outputs can be interpreted as meaningful properties of the network\ndynamics. This, in turn, allows us to answer the question we pose.",
      "tldr_zh": "该研究探讨了利用量子叠加（Quantum Superposition）来推断时空神经网络信号模型（Spatial-Temporal Neural Network Signaling Model）的动态行为，针对神经生物学和机器学习中大型网络的动态问题。论文将这类问题结构化为新问题类，焦点在于判断网络是否能维持动态活动，还是会因静止或类似癫痫状态而停止。作者扩展了Deutsch-Jozsa和Grover量子算法的功能，使其适应特定输入结构，并通过量子叠加高效求解，从而将算法输出解释为网络动态的意义属性。实验结果证明了这一方法的有效性，为量子计算在复杂网络动态分析中的应用提供了新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "quant-ph",
      "comment": "36 pages, 4 figures. See\n  https://github.com/gabe-alex-silva/Network_Dynamics_QuantumSim/tree/main for\n  code details",
      "pdf_url": "http://arxiv.org/pdf/2403.18963v3",
      "published_date": "2024-03-27 19:16:56 UTC",
      "updated_date": "2025-01-21 02:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:22:33.637282"
    },
    {
      "arxiv_id": "2403.18958v1",
      "title": "A State-of-the-practice Release-readiness Checklist for Generative AI-based Software Products",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Patel",
        "Dominique Boucher",
        "Emad Fallahzadeh",
        "Ahmed E. Hassan",
        "Bram Adams"
      ],
      "abstract": "This paper investigates the complexities of integrating Large Language Models\n(LLMs) into software products, with a focus on the challenges encountered for\ndetermining their readiness for release. Our systematic review of grey\nliterature identifies common challenges in deploying LLMs, ranging from\npre-training and fine-tuning to user experience considerations. The study\nintroduces a comprehensive checklist designed to guide practitioners in\nevaluating key release readiness aspects such as performance, monitoring, and\ndeployment strategies, aiming to enhance the reliability and effectiveness of\nLLM-based applications in real-world settings.",
      "tldr_zh": "这篇论文探讨了将大型语言模型 (LLMs) 整合到软件产品中的复杂性，特别关注评估发布准备的挑战。通过对灰色文献 (grey literature) 的系统审查 (systematic review)，研究识别了部署 LLMs 的常见问题，包括预训练、微调以及用户体验方面的难题。论文引入了一个全面的检查列表 (checklist)，指导从业者评估关键方面如性能、监控和部署策略，以提高 LLM 基础应用在真实环境中的可靠性和有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18958v1",
      "published_date": "2024-03-27 19:02:56 UTC",
      "updated_date": "2024-03-27 19:02:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:22:46.667500"
    },
    {
      "arxiv_id": "2403.18938v1",
      "title": "Reshaping Free-Text Radiology Notes Into Structured Reports With Generative Transformers",
      "title_zh": "利用生成式Transformer将自由文本放射学笔记重塑为结构化",
      "authors": [
        "Laura Bergomi",
        "Tommaso M. Buonocore",
        "Paolo Antonazzo",
        "Lorenzo Alberghi",
        "Riccardo Bellazzi",
        "Lorenzo Preda",
        "Chandra Bortolotto",
        "Enea Parimbelli"
      ],
      "abstract": "BACKGROUND: Radiology reports are typically written in a free-text format,\nmaking clinical information difficult to extract and use. Recently the adoption\nof structured reporting (SR) has been recommended by various medical societies\nthanks to the advantages it offers, e.g. standardization, completeness and\ninformation retrieval. We propose a pipeline to extract information from\nfree-text radiology reports, that fits with the items of the reference SR\nregistry proposed by a national society of interventional and medical\nradiology, focusing on CT staging of patients with lymphoma. METHODS: Our work\naims to leverage the potential of Natural Language Processing (NLP) and\nTransformer-based models to deal with automatic SR registry filling. With the\navailability of 174 radiology reports, we investigate a rule-free generative\nQuestion Answering approach based on a domain-specific version of T5 (IT5). Two\nstrategies (batch-truncation and ex-post combination) are implemented to comply\nwith the model's context length limitations. Performance is evaluated in terms\nof strict accuracy, F1, and format accuracy, and compared with the widely used\nGPT-3.5 Large Language Model. A 5-point Likert scale questionnaire is used to\ncollect human-expert feedback on the similarity between medical annotations and\ngenerated answers. RESULTS: The combination of fine-tuning and batch splitting\nallows IT5 to achieve notable results; it performs on par with GPT-3.5 albeit\nits size being a thousand times smaller in terms of parameters. Human-based\nassessment scores show a high correlation (Spearman's correlation\ncoefficients>0.88, p-values<0.001) with AI performance metrics (F1) and confirm\nthe superior ability of LLMs (i.e., GPT-3.5, 175B of parameters) in generating\nplausible human-like statements.",
      "tldr_zh": "本研究针对放射学报告的自由文本格式问题，提出一个管道，使用 Natural Language Processing (NLP) 和 Transformer-based 模型（如领域特定 IT5）将这些报告转化为结构化报告 (SR)，以标准化信息提取并符合意大利国家放射学协会的淋巴瘤 CT 分期注册表。方法采用生成式问答策略，结合批量截断和后续组合来处理模型上下文长度限制，并在 174 份报告上进行微调实验。结果显示，IT5 的性能在严格准确率、F1 和格式准确率上与 GPT-3.5 相当，但参数量小一千倍；人类专家评估进一步确认 LLMs 如 GPT-3.5 在生成逼真语句方面更出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18938v1",
      "published_date": "2024-03-27 18:38:39 UTC",
      "updated_date": "2024-03-27 18:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:23:01.443551"
    },
    {
      "arxiv_id": "2403.18932v1",
      "title": "Measuring Political Bias in Large Language Models: What Is Said and How It Is Said",
      "title_zh": "在大型语言模型中测量政治偏见：说了什么以及如何说",
      "authors": [
        "Yejin Bang",
        "Delong Chen",
        "Nayeon Lee",
        "Pascale Fung"
      ],
      "abstract": "We propose to measure political bias in LLMs by analyzing both the content\nand style of their generated content regarding political issues. Existing\nbenchmarks and measures focus on gender and racial biases. However, political\nbias exists in LLMs and can lead to polarization and other harms in downstream\napplications. In order to provide transparency to users, we advocate that there\nshould be fine-grained and explainable measures of political biases generated\nby LLMs. Our proposed measure looks at different political issues such as\nreproductive rights and climate change, at both the content (the substance of\nthe generation) and the style (the lexical polarity) of such bias. We measured\nthe political bias in eleven open-sourced LLMs and showed that our proposed\nframework is easily scalable to other topics and is explainable.",
      "tldr_zh": "这篇论文提出了一种测量大型语言模型(LLMs)中政治偏差的新框架，不仅评估生成内容的实质(content)，还分析其风格(style，如词汇极性)，以解决现有基准主要关注性别和种族偏差的局限性。方法针对特定政治议题，如生殖权利和气候变化，提供细粒度和可解释的偏差测量，帮助揭示LLMs可能导致下游应用极化等问题。研究团队测试了11个开源LLMs，证明该框架易于扩展到其他主题，并增强了偏差的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.18932v1",
      "published_date": "2024-03-27 18:22:48 UTC",
      "updated_date": "2024-03-27 18:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:23:10.337947"
    },
    {
      "arxiv_id": "2404.10636v2",
      "title": "What are human values, and how do we align AI to them?",
      "title_zh": "什么是人类价值观，以及我们如何使AI与它们对齐？",
      "authors": [
        "Oliver Klingefjord",
        "Ryan Lowe",
        "Joe Edelman"
      ],
      "abstract": "There is an emerging consensus that we need to align AI systems with human\nvalues (Gabriel, 2020; Ji et al., 2024), but it remains unclear how to apply\nthis to language models in practice. We split the problem of \"aligning to human\nvalues\" into three parts: first, eliciting values from people; second,\nreconciling those values into an alignment target for training ML models; and\nthird, actually training the model. In this paper, we focus on the first two\nparts, and ask the question: what are \"good\" ways to synthesize diverse human\ninputs about values into a target for aligning language models? To answer this\nquestion, we first define a set of 6 criteria that we believe must be satisfied\nfor an alignment target to shape model behavior in accordance with human\nvalues. We then propose a process for eliciting and reconciling values called\nMoral Graph Elicitation (MGE), which uses a large language model to interview\nparticipants about their values in particular contexts; our approach is\ninspired by the philosophy of values advanced by Taylor (1977), Chang (2004),\nand others. We trial MGE with a representative sample of 500 Americans, on 3\nintentionally divisive prompts (e.g. advice about abortion). Our results\ndemonstrate that MGE is promising for improving model alignment across all 6\ncriteria. For example, almost all participants (89.1%) felt well represented by\nthe process, and (89%) thought the final moral graph was fair, even if their\nvalue wasn't voted as the wisest. Our process often results in \"expert\" values\n(e.g. values from women who have solicited abortion advice) rising to the top\nof the moral graph, without defining who is considered an expert in advance.",
      "tldr_zh": "这篇论文探讨了如何将AI系统与人类价值观对齐的问题，将其分解为三个部分，但重点在于从人们那里获取价值观并整合成AI训练目标。作者定义了6个标准来评估对齐目标的有效性，并提出Moral Graph Elicitation (MGE)方法，使用大语言模型采访参与者（如在堕胎建议等争议性情境中），以创建代表多元观点的道德图。实验结果显示，MGE在500名美国样本上表现出色，例如89.1%的参与者认为他们的价值观被良好代表，且89%认为最终道德图公平，同时能让“专家”价值观（如来自相关经历者的观点）自然脱颖而出，从而为AI对齐提供更可靠的框架。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10636v2",
      "published_date": "2024-03-27 18:12:02 UTC",
      "updated_date": "2024-04-17 16:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:23:25.221731"
    },
    {
      "arxiv_id": "2403.18920v1",
      "title": "CPR: Retrieval Augmented Generation for Copyright Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Golatkar",
        "Alessandro Achille",
        "Luca Zancato",
        "Yu-Xiang Wang",
        "Ashwin Swaminathan",
        "Stefano Soatto"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) is emerging as a flexible and robust\ntechnique to adapt models to private users data without training, to handle\ncredit attribution, and to allow efficient machine unlearning at scale.\nHowever, RAG techniques for image generation may lead to parts of the retrieved\nsamples being copied in the model's output. To reduce risks of leaking private\ninformation contained in the retrieved set, we introduce Copy-Protected\ngeneration with Retrieval (CPR), a new method for RAG with strong copyright\nprotection guarantees in a mixed-private setting for diffusion models.CPR\nallows to condition the output of diffusion models on a set of retrieved\nimages, while also guaranteeing that unique identifiable information about\nthose example is not exposed in the generated outputs. In particular, it does\nso by sampling from a mixture of public (safe) distribution and private (user)\ndistribution by merging their diffusion scores at inference. We prove that CPR\nsatisfies Near Access Freeness (NAF) which bounds the amount of information an\nattacker may be able to extract from the generated images. We provide two\nalgorithms for copyright protection, CPR-KL and CPR-Choose. Unlike previously\nproposed rejection-sampling-based NAF methods, our methods enable efficient\ncopyright-protected sampling with a single run of backward diffusion. We show\nthat our method can be applied to any pre-trained conditional diffusion model,\nsuch as Stable Diffusion or unCLIP. In particular, we empirically show that\napplying CPR on top of unCLIP improves quality and text-to-image alignment of\nthe generated results (81.4 to 83.17 on TIFA benchmark), while enabling credit\nattribution, copy-right protection, and deterministic, constant time,\nunlearning.",
      "tldr_zh": "该研究针对 Retrieval Augmented Generation (RAG) 在图像生成中可能复制检索样本并泄露私人信息的风险，提出了 CPR（Copy-Protected generation with Retrieval）方法，用于扩散模型（diffusion models）。CPR 通过从公共（safe）和私人（user）分布的混合中采样合并扩散分数，确保生成输出不暴露独特可识别信息，并满足 Near Access Freeness (NAF) 标准，提供两种算法：CPR-KL 和 CPR-Choose，以实现高效单次 backward diffusion 采样。实验结果显示，应用于 unCLIP 等预训练模型后，生成质量和文本到图像对齐显著提升（TIFA 基准从 81.4 提高到 83.17），同时支持信用归属、版权保护和快速 unlearning。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18920v1",
      "published_date": "2024-03-27 18:09:55 UTC",
      "updated_date": "2024-03-27 18:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:23:37.819726"
    },
    {
      "arxiv_id": "2403.18910v2",
      "title": "A Geometric Explanation of the Likelihood OOD Detection Paradox",
      "title_zh": "翻译失败",
      "authors": [
        "Hamidreza Kamkari",
        "Brendan Leigh Ross",
        "Jesse C. Cresswell",
        "Anthony L. Caterini",
        "Rahul G. Krishnan",
        "Gabriel Loaiza-Ganem"
      ],
      "abstract": "Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling\nbehaviour: when trained on a relatively complex dataset, they assign higher\nlikelihood values to out-of-distribution (OOD) data from simpler sources.\nAdding to the mystery, OOD samples are never generated by these DGMs despite\nhaving higher likelihoods. This two-pronged paradox has yet to be conclusively\nexplained, making likelihood-based OOD detection unreliable. Our primary\nobservation is that high-likelihood regions will not be generated if they\ncontain minimal probability mass. We demonstrate how this seeming contradiction\nof large densities yet low probability mass can occur around data confined to\nlow-dimensional manifolds. We also show that this scenario can be identified\nthrough local intrinsic dimension (LID) estimation, and propose a method for\nOOD detection which pairs the likelihoods and LID estimates obtained from a\npre-trained DGM. Our method can be applied to normalizing flows and score-based\ndiffusion models, and obtains results which match or surpass state-of-the-art\nOOD detection benchmarks using the same DGM backbones. Our code is available at\nhttps://github.com/layer6ai-labs/dgm_ood_detection.",
      "tldr_zh": "这篇论文解释了基于似然性的深度生成模型（DGMs）在OOD（Out-of-Distribution）检测中的悖论：当在复杂数据集上训练时，这些模型会为来自更简单来源的OOD数据分配更高似然值，却不会生成这些样本。作者的关键观察是，高似然区域如果包含的概率质量（probability mass）很小，就不会被生成，这种现象往往发生在数据局限于低维流形（low-dimensional manifolds）时。论文提出了一种结合似然和局部内在维度（LID）估计的OOD检测方法，可应用于归一化流（normalizing flows）和基于分数的扩散模型（score-based diffusion models），并在基准测试中达到或超过最先进水平。总的来说，这一方法为可靠的OOD检测提供了几何解释和实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18910v2",
      "published_date": "2024-03-27 18:02:49 UTC",
      "updated_date": "2024-06-11 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:23:47.748871"
    },
    {
      "arxiv_id": "2403.18814v1",
      "title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models",
      "title_zh": "Mini-Gemini：挖掘多模态视觉语言模型的潜力",
      "authors": [
        "Yanwei Li",
        "Yuechen Zhang",
        "Chengyao Wang",
        "Zhisheng Zhong",
        "Yixin Chen",
        "Ruihang Chu",
        "Shaoteng Liu",
        "Jiaya Jia"
      ],
      "abstract": "In this work, we introduce Mini-Gemini, a simple and effective framework\nenhancing multi-modality Vision Language Models (VLMs). Despite the\nadvancements in VLMs facilitating basic visual dialog and reasoning, a\nperformance gap persists compared to advanced models like GPT-4 and Gemini. We\ntry to narrow the gap by mining the potential of VLMs for better performance\nand any-to-any workflow from three aspects, i.e., high-resolution visual\ntokens, high-quality data, and VLM-guided generation. To enhance visual tokens,\nwe propose to utilize an additional visual encoder for high-resolution\nrefinement without increasing the visual token count. We further construct a\nhigh-quality dataset that promotes precise image comprehension and\nreasoning-based generation, expanding the operational scope of current VLMs. In\ngeneral, Mini-Gemini further mines the potential of VLMs and empowers current\nframeworks with image understanding, reasoning, and generation simultaneously.\nMini-Gemini supports a series of dense and MoE Large Language Models (LLMs)\nfrom 2B to 34B. It is demonstrated to achieve leading performance in several\nzero-shot benchmarks and even surpasses the developed private models. Code and\nmodels are available at https://github.com/dvlab-research/MiniGemini.",
      "tldr_zh": "本文提出 Mini-Gemini 框架，通过挖掘多模态 Vision Language Models (VLMs) 的潜力，旨在缩小其与 GPT-4 和 Gemini 等高级模型的性能差距。框架从高分辨率视觉标记、高质量数据和 VLM 引导生成三个方面入手，利用额外视觉编码器提升高分辨率视觉标记而不增加标记数量，并构建高质量数据集以增强图像理解和推理生成能力。Mini-Gemini 支持从 2B 到 34B 的密集和 MoE Large Language Models (LLMs)，在多个零样本基准测试中表现出色，甚至超越某些私有模型。该框架同时实现了图像理解、推理和生成的全面能力，并已在 GitHub 上公开代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and models are available at\n  https://github.com/dvlab-research/MiniGemini",
      "pdf_url": "http://arxiv.org/pdf/2403.18814v1",
      "published_date": "2024-03-27 17:59:04 UTC",
      "updated_date": "2024-03-27 17:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:24:02.352007"
    },
    {
      "arxiv_id": "2403.18807v4",
      "title": "ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Suraj Patni",
        "Aradhye Agarwal",
        "Chetan Arora"
      ],
      "abstract": "In the absence of parallax cues, a learning-based single image depth\nestimation (SIDE) model relies heavily on shading and contextual cues in the\nimage. While this simplicity is attractive, it is necessary to train such\nmodels on large and varied datasets, which are difficult to capture. It has\nbeen shown that using embeddings from pre-trained foundational models, such as\nCLIP, improves zero shot transfer in several applications. Taking inspiration\nfrom this, in our paper we explore the use of global image priors generated\nfrom a pre-trained ViT model to provide more detailed contextual information.\nWe argue that the embedding vector from a ViT model, pre-trained on a large\ndataset, captures greater relevant information for SIDE than the usual route of\ngenerating pseudo image captions, followed by CLIP based text embeddings. Based\non this idea, we propose a new SIDE model using a diffusion backbone which is\nconditioned on ViT embeddings. Our proposed design establishes a new\nstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of\n0.059 (14% improvement) compared to 0.069 by the current SOTA (VPD). And on\nKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to\n0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model\ntrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)\nover NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,\n18%, 45%, 9%) by ZoeDepth. The project page is available at\nhttps://ecodepth-iitd.github.io",
      "tldr_zh": "这篇论文提出 ECoDepth，一种有效条件化扩散模型的方法，用于 Monocular Depth Estimation，通过利用预训练 ViT 模型的全局图像先验来提供更丰富的上下文信息，而不是依赖传统的伪图像标题和 CLIP 文本嵌入。相比现有方法，该模型显著提升了深度估计的准确性，在 NYUv2 数据集上将 Abs Rel 错误从 0.069 降低到 0.059（14% 改善），并在 KITTI 数据集上将 Sq Rel 错误从 0.142 降低到 0.139（2% 改善），确立了新 SOTA。实验还显示，在零样本转移测试中，ECoDepth 在 Sun-RGBD、iBims1、DIODE 和 HyperSim 等数据集上比 ZoeDepth 实现了更高的相对改善（平均20%至81%）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18807v4",
      "published_date": "2024-03-27 17:53:30 UTC",
      "updated_date": "2024-04-17 14:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:24:14.740830"
    },
    {
      "arxiv_id": "2403.18802v4",
      "title": "Long-form factuality in large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Wei",
        "Chengrun Yang",
        "Xinying Song",
        "Yifeng Lu",
        "Nathan Hu",
        "Jie Huang",
        "Dustin Tran",
        "Daiyi Peng",
        "Ruibo Liu",
        "Da Huang",
        "Cosmo Du",
        "Quoc V. Le"
      ],
      "abstract": "Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can outperform crowdsourced human\nannotators - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）在回应事实性查询时产生的长期内容事实错误问题，引入 LongFact 数据集（由 GPT-4 生成的数千个问题，覆盖 38 个主题）作为基准。作者提出 Search-Augmented Factuality Evaluator (SAFE) 方法，使用 LLM 代理将长响应分解为单个事实，并通过多步推理（如向 Google Search 发送查询）评估每个事实的准确性，同时扩展 F1 score 指标来平衡精确率（支持事实百分比）和召回率（相对用户首选响应长度）。实验显示，SAFE 与人类标注者同意 72% 的时间，且在分歧案例中胜出 76%，且成本比人类低 20 倍以上；在 13 个模型（包括 Gemini、GPT、Claude 和 PaLM-2）的测试中，更大的模型表现出更好的长期事实性。该工作及其代码已在 GitHub 上公开，提供了一个可靠的 LLM 事实性评估框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024; 72 pages, 18 figures, 30 tables. Code at\n  https://github.com/google-deepmind/long-form-factuality",
      "pdf_url": "http://arxiv.org/pdf/2403.18802v4",
      "published_date": "2024-03-27 17:48:55 UTC",
      "updated_date": "2024-11-07 03:14:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:24:26.232597"
    },
    {
      "arxiv_id": "2403.19716v1",
      "title": "Capability-aware Prompt Reformulation Learning for Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingtao Zhan",
        "Qingyao Ai",
        "Yiqun Liu",
        "Jia Chen",
        "Shaoping Ma"
      ],
      "abstract": "Text-to-image generation systems have emerged as revolutionary tools in the\nrealm of artistic creation, offering unprecedented ease in transforming textual\nprompts into visual art. However, the efficacy of these systems is intricately\nlinked to the quality of user-provided prompts, which often poses a challenge\nto users unfamiliar with prompt crafting. This paper addresses this challenge\nby leveraging user reformulation data from interaction logs to develop an\nautomatic prompt reformulation model. Our in-depth analysis of these logs\nreveals that user prompt reformulation is heavily dependent on the individual\nuser's capability, resulting in significant variance in the quality of\nreformulation pairs. To effectively use this data for training, we introduce\nthe Capability-aware Prompt Reformulation (CAPR) framework. CAPR innovatively\nintegrates user capability into the reformulation process through two key\ncomponents: the Conditional Reformulation Model (CRM) and Configurable\nCapability Features (CCF). CRM reformulates prompts according to a specified\nuser capability, as represented by CCF. The CCF, in turn, offers the\nflexibility to tune and guide the CRM's behavior. This enables CAPR to\neffectively learn diverse reformulation strategies across various user\ncapacities and to simulate high-capability user reformulation during inference.\nExtensive experiments on standard text-to-image generation benchmarks showcase\nCAPR's superior performance over existing baselines and its remarkable\nrobustness on unseen systems. Furthermore, comprehensive analyses validate the\neffectiveness of different components. CAPR can facilitate user-friendly\ninteraction with text-to-image systems and make advanced artistic creation more\nachievable for a broader range of users.",
      "tldr_zh": "该论文针对文本到图像生成（Text-to-image generation）系统的提示质量挑战，提出了一种基于用户能力的自动提示改革方法，以帮助用户更有效地创建视觉艺术。论文引入Capability-aware Prompt Reformulation (CAPR)框架，该框架通过Conditional Reformulation Model (CRM)和Configurable Capability Features (CCF)来整合用户能力差异，实现多样化的提示改革策略，并在推理阶段模拟高能力用户行为。实验结果显示，CAPR在标准基准测试中显著优于现有基线模型，并展示了出色的鲁棒性，从而提升了系统的用户友好性和艺术创作可达性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.19716v1",
      "published_date": "2024-03-27 17:41:16 UTC",
      "updated_date": "2024-03-27 17:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:24:38.305066"
    },
    {
      "arxiv_id": "2403.18795v3",
      "title": "Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuhong Shen",
        "Zike Wu",
        "Xuanyu Yi",
        "Pan Zhou",
        "Hanwang Zhang",
        "Shuicheng Yan",
        "Xinchao Wang"
      ],
      "abstract": "We tackle the challenge of efficiently reconstructing a 3D asset from a\nsingle image at millisecond speed. Existing methods for single-image 3D\nreconstruction are primarily based on Score Distillation Sampling (SDS) with\nNeural 3D representations. Despite promising results, these approaches\nencounter practical limitations due to lengthy optimizations and significant\nmemory consumption. In this work, we introduce Gamba, an end-to-end 3D\nreconstruction model from a single-view image, emphasizing two main insights:\n(1) Efficient Backbone Design: introducing a Mamba-based GambaFormer network to\nmodel 3D Gaussian Splatting (3DGS) reconstruction as sequential prediction with\nlinear scalability of token length, thereby accommodating a substantial number\nof Gaussians; (2) Robust Gaussian Constraints: deriving radial mask constraints\nfrom multi-view masks to eliminate the need for warmup supervision of 3D point\nclouds in training. We trained Gamba on Objaverse and assessed it against\nexisting optimization-based and feed-forward 3D reconstruction approaches on\nthe GSO Dataset, among which Gamba is the only end-to-end trained single-view\nreconstruction model with 3DGS. Experimental results demonstrate its\ncompetitive generation capabilities both qualitatively and quantitatively and\nhighlight its remarkable speed: Gamba completes reconstruction within 0.05\nseconds on a single NVIDIA A100 GPU, which is about $1,000\\times$ faster than\noptimization-based methods. Please see our project page at\nhttps://florinshen.github.io/gamba-project.",
      "tldr_zh": "该研究提出Gamba，一种端到端的单视图3D重建模型，将Gaussian Splatting与Mamba结合，旨在实现毫秒级高效重建。Gamba的核心创新包括使用Mamba-based GambaFormer网络，将3D Gaussian Splatting (3DGS)建模为顺序预测，以线性可扩展方式处理大量Gaussians，并通过从多视图masks派生的radial mask约束消除训练中的3D点云预热监督。实验结果显示，Gamba在GSO Dataset上与现有优化-based和feed-forward方法相比，重建质量和精度具有竞争力，并在单NVIDIA A100 GPU上仅需0.05秒完成重建，比传统方法快约1000倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "project page: https://florinshen.github.io/gamba-project",
      "pdf_url": "http://arxiv.org/pdf/2403.18795v3",
      "published_date": "2024-03-27 17:40:14 UTC",
      "updated_date": "2024-05-24 18:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:24:50.843736"
    },
    {
      "arxiv_id": "2403.18775v1",
      "title": "ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object",
      "title_zh": "翻译失败",
      "authors": [
        "Chenshuang Zhang",
        "Fei Pan",
        "Junmo Kim",
        "In So Kweon",
        "Chengzhi Mao"
      ],
      "abstract": "We establish rigorous benchmarks for visual perception robustness. Synthetic\nimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific\ntype of evaluation over synthetic corruptions, backgrounds, and textures, yet\nthose robustness benchmarks are restricted in specified variations and have low\nsynthetic quality. In this work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models' robustness. Leveraging\ndiffusion models, we are able to generate images with more diversified\nbackgrounds, textures, and materials than any prior work, where we term this\nbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in a\nsignificant accuracy drop to a range of vision models, from the standard ResNet\nvisual classifier to the latest foundation models like CLIP and MiniGPT-4,\nsignificantly reducing their accuracy by up to 60\\%. Our work suggests that\ndiffusion models can be an effective source to test vision models. The code and\ndataset are available at https://github.com/chenshuang-zhang/imagenet_d.",
      "tldr_zh": "本文提出 ImageNet-D 基准，用于评估神经网络在扩散模型（diffusion models）合成图像上的鲁棒性，旨在解决现有合成基准（如 ImageNet-C 和 ImageNet-9）在变异多样性和合成质量上的局限性。研究团队利用 diffusion models 生成更丰富的图像变异，包括背景、纹理和材料，以测试视觉模型的性能。实验结果显示，ImageNet-D 导致多种模型（如 ResNet、CLIP 和 MiniGPT-4）的准确率下降多达 60%，证明了其作为有效鲁棒性测试工具的价值。代码和数据集可从 GitHub 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18775v1",
      "published_date": "2024-03-27 17:23:39 UTC",
      "updated_date": "2024-03-27 17:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:25:02.872667"
    },
    {
      "arxiv_id": "2403.18766v1",
      "title": "Superior Parallel Big Data Clustering through Competitive Stochastic Sample Size Optimization in Big-means",
      "title_zh": "翻译失败",
      "authors": [
        "Rustam Mussabayev",
        "Ravil Mussabayev"
      ],
      "abstract": "This paper introduces a novel K-means clustering algorithm, an advancement on\nthe conventional Big-means methodology. The proposed method efficiently\nintegrates parallel processing, stochastic sampling, and competitive\noptimization to create a scalable variant designed for big data applications.\nIt addresses scalability and computation time challenges typically faced with\ntraditional techniques. The algorithm adjusts sample sizes dynamically for each\nworker during execution, optimizing performance. Data from these sample sizes\nare continually analyzed, facilitating the identification of the most efficient\nconfiguration. By incorporating a competitive element among workers using\ndifferent sample sizes, efficiency within the Big-means algorithm is further\nstimulated. In essence, the algorithm balances computational time and\nclustering quality by employing a stochastic, competitive sampling strategy in\na parallel computing setting.",
      "tldr_zh": "本论文提出了一种改进的 K-means 聚类算法，即在 Big-means 方法基础上整合并行处理、stochastic sampling 和 competitive optimization，以提升大数据应用的 scalability 和计算效率。该算法动态调整每个 worker 的样本大小，并通过 workers 之间基于不同样本大小的竞争机制来优化性能。结果显示，这种 stochastic competitive sampling 策略在并行计算环境中有效平衡了计算时间和聚类质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18766v1",
      "published_date": "2024-03-27 17:05:03 UTC",
      "updated_date": "2024-03-27 17:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:25:13.275000"
    },
    {
      "arxiv_id": "2403.18762v1",
      "title": "ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Weidong Xie",
        "Lun Luo",
        "Nanfei Ye",
        "Yi Ren",
        "Shaoyi Du",
        "Minhang Wang",
        "Jintao Xu",
        "Rui Ai",
        "Weihao Gu",
        "Xieyuanli Chen"
      ],
      "abstract": "Place recognition is an important task for robots and autonomous cars to\nlocalize themselves and close loops in pre-built maps. While single-modal\nsensor-based methods have shown satisfactory performance, cross-modal place\nrecognition that retrieving images from a point-cloud database remains a\nchallenging problem. Current cross-modal methods transform images into 3D\npoints using depth estimation for modality conversion, which are usually\ncomputationally intensive and need expensive labeled data for depth\nsupervision. In this work, we introduce a fast and lightweight framework to\nencode images and point clouds into place-distinctive descriptors. We propose\nan effective Field of View (FoV) transformation module to convert point clouds\ninto an analogous modality as images. This module eliminates the necessity for\ndepth estimation and helps subsequent modules achieve real-time performance. We\nfurther design a non-negative factorization-based encoder to extract mutually\nconsistent semantic features between point clouds and images. This encoder\nyields more distinctive global descriptors for retrieval. Experimental results\non the KITTI dataset show that our proposed methods achieve state-of-the-art\nperformance while running in real time. Additional evaluation on the HAOMO\ndataset covering a 17 km trajectory further shows the practical generalization\ncapabilities. We have released the implementation of our methods as open source\nat: https://github.com/haomo-ai/ModaLink.git.",
      "tldr_zh": "本文提出 ModaLink 框架，用于高效的图像到点云跨模态地点识别，解决了传统方法依赖深度估计的计算密集问题。框架包括 Field of View (FoV) 转换模块，将点云转换为类似于图像的模态，实现实时性能，以及基于 non-negative factorization 的编码器，提取点云和图像之间相互一致的语义特征以生成独特全局描述符。实验结果显示，在 KITTI 数据集上，ModaLink 达到了 state-of-the-art 性能，并在 HAUMO 数据集的 17 km 轨迹上验证了实际泛化能力，同时代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 11 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2403.18762v1",
      "published_date": "2024-03-27 17:01:10 UTC",
      "updated_date": "2024-03-27 17:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:25:31.485059"
    },
    {
      "arxiv_id": "2403.18756v1",
      "title": "Detection of subclinical atherosclerosis by image-based deep learning on chest x-ray",
      "title_zh": "翻译失败",
      "authors": [
        "Guglielmo Gallone",
        "Francesco Iodice",
        "Alberto Presta",
        "Davide Tore",
        "Ovidio de Filippo",
        "Michele Visciano",
        "Carlo Alberto Barbano",
        "Alessandro Serafini",
        "Paola Gorrini",
        "Alessandro Bruno",
        "Walter Grosso Marra",
        "James Hughes",
        "Mario Iannaccone",
        "Paolo Fonio",
        "Attilio Fiandrotti",
        "Alessandro Depaoli",
        "Marco Grangetto",
        "Gaetano Maria de Ferrari",
        "Fabrizio D'Ascenzo"
      ],
      "abstract": "Aims. To develop a deep-learning based system for recognition of subclinical\natherosclerosis on a plain frontal chest x-ray. Methods and Results. A\ndeep-learning algorithm to predict coronary artery calcium (CAC) score (the\nAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%\ninternal validation cohort) of primary prevention patients (58.4% male, median\nage 63 [51-74] years) with available paired chest x-ray and chest computed\ntomography (CT) indicated for any clinical reason and performed within 3\nmonths. The CAC score calculated on chest CT was used as ground truth. The\nmodel was validated on an temporally-independent cohort of 90 patients from the\nsame institution (external validation). The diagnostic accuracy of the AI-CAC\nmodel assessed by the area under the curve (AUC) was the primary outcome.\nOverall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.\nAUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation\ncohort and 0.77 in the external validation cohort. Sensitivity was consistently\nabove 92% in both cohorts. In the overall cohort (n=540), among patients with\nAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with\nAI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events\n(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to\naccurately detect subclinical atherosclerosis on chest x-ray with elevated\nsensitivity, and to predict ASCVD events with elevated negative predictive\nvalue. Adoption of the AI-CAC model to refine CV risk stratification or as an\nopportunistic screening tool requires prospective evaluation.",
      "tldr_zh": "该研究开发了一个基于深度学习的 AI-CAC 模型，用于从普通胸部 X 光片检测亚临床动脉粥样硬化，通过预测冠状动脉钙化分数 (CAC score) 作为主要方法。模型在 460 个初级预防患者的配对 X 光和 CT 数据上训练，并在内部验证队列 (AUC 0.90) 和外部验证队列 (AUC 0.77) 中表现出高准确率和敏感性 (>92%)。结果表明，AI-CAC>0 的患者心血管事件 (ASCVD events) 风险显著增加 (Kaplan-Meier 估计为 13.5% vs. 3.4%)，而 AI-CAC=0 的患者风险较低，具有高阴性预测值。该模型有望作为机会性筛查工具优化心血管风险分层，但需通过前瞻性研究进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to European Heart Journal - Cardiovascular Imaging Added\n  also the additional material 44 pages (30 main paper, 14 additional\n  material), 14 figures (5 main manuscript, 9 additional material)",
      "pdf_url": "http://arxiv.org/pdf/2403.18756v1",
      "published_date": "2024-03-27 16:56:14 UTC",
      "updated_date": "2024-03-27 16:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:25:47.959184"
    },
    {
      "arxiv_id": "2403.18755v2",
      "title": "Many-Objective Evolutionary Influence Maximization: Balancing Spread, Budget, Fairness, and Time",
      "title_zh": "多目标进化影响力最大化：平衡传播、预算、公平性和时间",
      "authors": [
        "Elia Cunegatti",
        "Leonardo Lucio Custode",
        "Giovanni Iacca"
      ],
      "abstract": "The Influence Maximization (IM) problem seeks to discover the set of nodes in\na graph that can spread the information propagation at most. This problem is\nknown to be NP-hard, and it is usually studied by maximizing the influence\n(spread) and, optionally, optimizing a second objective, such as minimizing the\nseed set size or maximizing the influence fairness. However, in many practical\nscenarios multiple aspects of the IM problem must be optimized at the same\ntime. In this work, we propose a first case study where several IM-specific\nobjective functions, namely budget, fairness, communities, and time, are\noptimized on top of the maximization of influence and minimization of the seed\nset size. To this aim, we introduce MOEIM (Many-Objective Evolutionary\nAlgorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm\n(MOEA) based on NSGA-II incorporating graph-aware operators and a smart\ninitialization. We compare MOEIM in two experimental settings, including a\ntotal of nine graph datasets, two heuristic methods, a related MOEA, and a\nstate-of-the-art Deep Learning approach. The experiments show that MOEIM\noverall outperforms the competitors in most of the tested many-objective\nsettings. To conclude, we also investigate the correlation between the\nobjectives, leading to novel insights into the topic. The codebase is available\nat https://github.com/eliacunegatti/MOEIM.",
      "tldr_zh": "该论文探讨了影响最大化 (Influence Maximization, IM) 问题，该问题需同时优化多个目标，包括最大化传播 (spread)、最小化种子集大小，以及平衡预算、公平性、社区和时间等因素。作者提出 MOEIM，一种基于 NSGA-II 的多目标进化算法 (Many-Objective Evolutionary Algorithm)，并融入图感知操作符和智能初始化，以处理这些多目标优化挑战。在实验中，MOEIM 在九个图数据集上优于竞争对手，如启发式方法、相关 MOEA 和深度学习方法，并通过分析目标间相关性提供了新见解，代码库可公开获取。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.NE",
      "comment": "To appear in Genetic and Evolutionary Computation Conference (GECCO\n  24 Companion), July 14 18, 2024, Melbourne, VIC, Australia. ACM, New York,\n  NY, USA",
      "pdf_url": "http://arxiv.org/pdf/2403.18755v2",
      "published_date": "2024-03-27 16:54:45 UTC",
      "updated_date": "2024-03-28 14:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:25:55.645065"
    },
    {
      "arxiv_id": "2403.18742v5",
      "title": "Understanding the Learning Dynamics of Alignment with Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Shawn Im",
        "Yixuan Li"
      ],
      "abstract": "Aligning large language models (LLMs) with human intentions has become a\ncritical task for safely deploying models in real-world systems. While existing\nalignment approaches have seen empirical success, theoretically understanding\nhow these methods affect model behavior remains an open question. Our work\nprovides an initial attempt to theoretically analyze the learning dynamics of\nhuman preference alignment. We formally show how the distribution of preference\ndatasets influences the rate of model updates and provide rigorous guarantees\non the training accuracy. Our theory also reveals an intricate phenomenon where\nthe optimization is prone to prioritizing certain behaviors with higher\npreference distinguishability. We empirically validate our findings on\ncontemporary LLMs and alignment tasks, reinforcing our theoretical insights and\nshedding light on considerations for future alignment approaches. Disclaimer:\nThis paper contains potentially offensive text; reader discretion is advised.",
      "tldr_zh": "本研究探讨了使用人类反馈对齐大型语言模型 (LLMs) 的学习动态，强调了这一过程对安全部署模型的重要性。作者通过理论分析正式证明了偏好数据集分布如何影响模型更新速率，并提供了训练准确性的严格保证。理论还揭示了优化过程倾向于优先处理偏好可区分性更高的行为，并在当代 LLMs 和对齐任务上进行实验验证这些见解。最终，该工作为未来人类反馈对齐方法提供了宝贵考虑，尽管论文包含可能冒犯性文本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18742v5",
      "published_date": "2024-03-27 16:39:28 UTC",
      "updated_date": "2024-08-06 22:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:26:05.601778"
    },
    {
      "arxiv_id": "2403.18731v1",
      "title": "Enhancing Manufacturing Quality Prediction Models through the Integration of Explainability Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Dennis Gross",
        "Helge Spieker",
        "Arnaud Gotlieb",
        "Ricardo Knoblauch"
      ],
      "abstract": "This research presents a method that utilizes explainability techniques to\namplify the performance of machine learning (ML) models in forecasting the\nquality of milling processes, as demonstrated in this paper through a\nmanufacturing use case. The methodology entails the initial training of ML\nmodels, followed by a fine-tuning phase where irrelevant features identified\nthrough explainability methods are eliminated. This procedural refinement\nresults in performance enhancements, paving the way for potential reductions in\nmanufacturing costs and a better understanding of the trained ML models. This\nstudy highlights the usefulness of explainability techniques in both explaining\nand optimizing predictive models in the manufacturing realm.",
      "tldr_zh": "本研究提出了一种方法，通过整合解释性技术(explainability methods)来提升机器学习(ML)模型在预测铣削过程质量方面的性能。\n方法包括先训练ML模型，然后使用解释性技术识别并去除无关特征，进行微调优化。\n实验结果显示，该方法显著提高了模型性能，可能降低制造成本，并增强了对ML模型的理解，强调了解释性技术在制造领域的实用价值。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18731v1",
      "published_date": "2024-03-27 16:21:24 UTC",
      "updated_date": "2024-03-27 16:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:26:17.384730"
    },
    {
      "arxiv_id": "2403.18725v1",
      "title": "Probabilistic Model Checking of Stochastic Reinforcement Learning Policies",
      "title_zh": "随机强化学习策略的概率模型检查",
      "authors": [
        "Dennis Gross",
        "Helge Spieker"
      ],
      "abstract": "We introduce a method to verify stochastic reinforcement learning (RL)\npolicies. This approach is compatible with any RL algorithm as long as the\nalgorithm and its corresponding environment collectively adhere to the Markov\nproperty. In this setting, the future state of the environment should depend\nsolely on its current state and the action executed, independent of any\nprevious states or actions. Our method integrates a verification technique,\nreferred to as model checking, with RL, leveraging a Markov decision process, a\ntrained RL policy, and a probabilistic computation tree logic (PCTL) formula to\nbuild a formal model that can be subsequently verified via the model checker\nStorm. We demonstrate our method's applicability across multiple benchmarks,\ncomparing it to baseline methods called deterministic safety estimates and\nnaive monolithic model checking. Our results show that our method is suited to\nverify stochastic RL policies.",
      "tldr_zh": "本文提出了一种验证随机强化学习（stochastic reinforcement learning）策略的方法，该方法适用于任何遵守Markov属性的RL算法和环境。方法通过整合模型检查（model checking）技术，利用Markov决策过程（Markov decision process）、训练的RL策略以及概率计算树逻辑（PCTL）公式构建正式模型，并使用Storm模型检查器进行验证。在多个基准测试中，该方法比基线方法（如deterministic safety estimates和naive monolithic model checking）表现更优，证明其适合有效验证随机RL策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18725v1",
      "published_date": "2024-03-27 16:15:21 UTC",
      "updated_date": "2024-03-27 16:15:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:26:29.480772"
    },
    {
      "arxiv_id": "2403.18717v2",
      "title": "Semi-Supervised Learning for Deep Causal Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yasin Ibrahim",
        "Hermione Warr",
        "Konstantinos Kamnitsas"
      ],
      "abstract": "Developing models that are capable of answering questions of the form \"How\nwould x change if y had been z?'\" is fundamental to advancing medical image\nanalysis. Training causal generative models that address such counterfactual\nquestions, though, currently requires that all relevant variables have been\nobserved and that the corresponding labels are available in the training data.\nHowever, clinical data may not have complete records for all patients and state\nof the art causal generative models are unable to take full advantage of this.\nWe thus develop, for the first time, a semi-supervised deep causal generative\nmodel that exploits the causal relationships between variables to maximise the\nuse of all available data. We explore this in the setting where each sample is\neither fully labelled or fully unlabelled, as well as the more clinically\nrealistic case of having different labels missing for each sample. We leverage\ntechniques from causal inference to infer missing values and subsequently\ngenerate realistic counterfactuals, even for samples with incomplete labels.",
      "tldr_zh": "本文提出了一种半监督学习(Semi-Supervised Learning)方法，应用于深度因果生成模型(Deep Causal Generative Models)，以解决医疗图像分析中反事实(Counterfactuals)问题，例如“如果y变为z，x会如何变化”。该方法利用变量间的因果关系，通过因果推理(Causal Inference)技术推断缺失值，从而最大化利用不完整临床数据，并生成现实的反事实。实验验证了该模型在完全标记、完全未标记或部分缺失标签的场景中的有效性，为处理真实临床数据提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18717v2",
      "published_date": "2024-03-27 16:06:37 UTC",
      "updated_date": "2024-07-12 14:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:26:41.956492"
    },
    {
      "arxiv_id": "2403.18715v2",
      "title": "Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding",
      "title_zh": "使用指令对比解码缓解大型视觉语言模型中的幻觉",
      "authors": [
        "Xintong Wang",
        "Jingheng Pan",
        "Liang Ding",
        "Chris Biemann"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) are increasingly adept at generating\ncontextually detailed and coherent responses from visual inputs. However, their\napplication in multimodal decision-making and open-ended generation is hindered\nby a notable rate of hallucinations, where generated text inaccurately\nrepresents the visual contents. To address this issue, this paper introduces\nthe Instruction Contrastive Decoding (ICD) method, a novel approach designed to\nreduce hallucinations during LVLM inference. Our method is inspired by our\nobservation that what we call disturbance instructions significantly exacerbate\nhallucinations in multimodal fusion modules. ICD contrasts distributions from\nstandard and instruction disturbance, thereby increasing alignment uncertainty\nand effectively subtracting hallucinated concepts from the original\ndistribution. Through comprehensive experiments on discriminative benchmarks\n(POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that\nICD significantly mitigates both object-level and attribute-level\nhallucinations. Moreover, our method not only addresses hallucinations but also\nsignificantly enhances the general perception and recognition capabilities of\nLVLMs.",
      "tldr_zh": "这篇论文针对 Large Vision-Language Models (LVLMs) 在处理视觉输入时产生的幻觉问题，提出了一种名为 Instruction Contrastive Decoding (ICD) 的方法，通过对比标准指令和干扰指令的分布，增加对齐不确定性并从原始分布中减去幻觉概念。ICD 的设计灵感来源于观察到干扰指令会加剧多模态融合模块中的幻觉，从而有效缓解生成文本的不准确性。在 POPE、MME 和 LLaVa-Bench 等基准测试中，实验结果显示 ICD 显著减少了 object-level 和 attribute-level 的幻觉，同时提升了 LVLMs 的整体感知和识别能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18715v2",
      "published_date": "2024-03-27 16:04:47 UTC",
      "updated_date": "2024-06-05 13:53:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:26:55.434270"
    },
    {
      "arxiv_id": "2403.18711v1",
      "title": "SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable Transient-Free 3D reconstruction from Satellite Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Camille Billouard",
        "Dawa Derksen",
        "Emmanuelle Sarrazin",
        "Bruno Vallet"
      ],
      "abstract": "Current stereo-vision pipelines produce high accuracy 3D reconstruction when\nusing multiple pairs or triplets of satellite images. However, these pipelines\nare sensitive to the changes between images that can occur as a result of\nmulti-date acquisitions. Such variations are mainly due to variable shadows,\nreflexions and transient objects (cars, vegetation). To take such changes into\naccount, Neural Radiance Fields (NeRF) have recently been applied to multi-date\nsatellite imagery. However, Neural methods are very compute-intensive, taking\ndozens of hours to learn, compared with minutes for standard stereo-vision\npipelines. Following the ideas of Instant Neural Graphics Primitives we propose\nto use an efficient sampling strategy and multi-resolution hash encoding to\naccelerate the learning. Our model, Satellite Neural Graphics Primitives\n(SAT-NGP) decreases the learning time to 15 minutes while maintaining the\nquality of the 3D reconstruction.",
      "tldr_zh": "本论文提出SAT-NGP模型，旨在解决传统立体视觉管道在多日期卫星图像中因阴影、反射和瞬态物体（如cars和vegetation）导致的3D重建敏感性问题，同时克服Neural Radiance Fields (NeRF)计算密集的缺点。作者采用高效采样策略和multi-resolution hash encoding，借鉴Instant Neural Graphics Primitives的理念，显著加速了训练过程。结果显示，SAT-NGP将学习时间从数十小时缩短至15分钟，同时保持高质量的transient-free 3D重建。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures, 1 table; Accepted to International Geoscience and\n  Remote Sensing Symposium (IGARSS) 2024; Code available at\n  https://github.com/Ellimac0/SAT-NGP",
      "pdf_url": "http://arxiv.org/pdf/2403.18711v1",
      "published_date": "2024-03-27 15:58:25 UTC",
      "updated_date": "2024-03-27 15:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:27:05.660908"
    },
    {
      "arxiv_id": "2403.18699v2",
      "title": "Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)",
      "title_zh": "翻译失败",
      "authors": [
        "Huanran Li",
        "Manh Nguyen",
        "Daniel Pimentel-Alarcón"
      ],
      "abstract": "Contrastive learning has emerged as a powerful method in deep learning,\nexcelling at learning effective representations through contrasting samples\nfrom different distributions. However, neural collapse, where embeddings\nconverge into a lower-dimensional space, poses a significant challenge,\nespecially in semi-supervised and self-supervised setups. In this paper, we\nfirst theoretically analyze the effect of large learning rates on contrastive\nlosses that solely rely on the cosine similarity metric, and derive a\ntheoretical bound to mitigate this collapse. {Building on these insights, we\npropose CLOP, a novel semi-supervised loss function designed to prevent neural\ncollapse by promoting the formation of orthogonal linear subspaces among class\nembeddings.} Unlike prior approaches that enforce a simplex ETF structure, CLOP\nfocuses on subspace separation, leading to more distinguishable embeddings.\nThrough extensive experiments on real and synthetic datasets, we demonstrate\nthat CLOP enhances performance, providing greater stability across different\nlearning rates and batch sizes.",
      "tldr_zh": "对比学习（Contrastive Learning）是一种有效的深度学习方法，但神经崩溃（Neural Collapse）问题会导致嵌入收敛到低维空间，特别是在半监督和自监督设置中。论文首先理论分析了大学习率对基于余弦相似度的对比损失的影响，并推导了一个边界来缓解这种崩溃。随后，提出了CLOP，一种新型半监督损失函数，通过促进类嵌入形成正交线性子空间（Orthonormal Prototypes），从而实现更可区分的嵌入，与以往强制单纯形ETF结构的方法不同。通过在真实和合成数据集上的广泛实验，CLOP显著提升了模型性能，并提高了对不同学习率和批量大小的稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.18699v2",
      "published_date": "2024-03-27 15:48:16 UTC",
      "updated_date": "2024-10-07 16:07:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:27:17.371865"
    },
    {
      "arxiv_id": "2403.18690v1",
      "title": "Annolid: Annotate, Segment, and Track Anything You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Yang",
        "Thomas A. Cleland"
      ],
      "abstract": "Annolid is a deep learning-based software package designed for the\nsegmentation, labeling, and tracking of research targets within video files,\nfocusing primarily on animal behavior analysis. Based on state-of-the-art\ninstance segmentation methods, Annolid now harnesses the Cutie video object\nsegmentation model to achieve resilient, markerless tracking of multiple\nanimals from single annotated frames, even in environments in which they may be\npartially or entirely concealed by environmental features or by one another.\nOur integration of Segment Anything and Grounding-DINO strategies additionally\nenables the automatic masking and segmentation of recognizable animals and\nobjects by text command, removing the need for manual annotation. Annolid's\ncomprehensive approach to object segmentation flexibly accommodates a broad\nspectrum of behavior analysis applications, enabling the classification of\ndiverse behavioral states such as freezing, digging, pup huddling, and social\ninteractions in addition to the tracking of animals and their body parts.",
      "tldr_zh": "Annolid是一个基于深度学习的软件包，旨在对视频文件中的研究目标进行分割、标记和跟踪，主要应用于动物行为分析。Annolid利用Cutie视频对象分割模型实现从单个标注帧的稳健无标记跟踪，支持多个动物的追踪，即使它们被环境或彼此遮挡；同时整合Segment Anything和Grounding-DINO策略，通过文本命令自动掩盖和分割可识别对象，消除了手动标注的需求。该软件的全面方法适用于广泛的行为分析场景，包括分类行为状态如freezing、digging、pup huddling和社会互动，以及跟踪动物及其身体部位。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18690v1",
      "published_date": "2024-03-27 15:41:23 UTC",
      "updated_date": "2024-03-27 15:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:27:32.646395"
    },
    {
      "arxiv_id": "2403.18681v2",
      "title": "Deep Fusion: Capturing Dependencies in Contrastive Learning via Transformer Projection Heads",
      "title_zh": "翻译失败",
      "authors": [
        "Huanran Li",
        "Daniel Pimentel-Alarcón"
      ],
      "abstract": "Contrastive Learning (CL) has emerged as a powerful method for training\nfeature extraction models using unlabeled data. Recent studies suggest that\nincorporating a linear projection head post-backbone significantly enhances\nmodel performance. In this work, we investigate the use of a transformer model\nas a projection head within the CL framework, aiming to exploit the\ntransformer's capacity for capturing long-range dependencies across embeddings\nto further improve performance. Our key contributions are fourfold: First, we\nintroduce a novel application of transformers in the projection head role for\ncontrastive learning, marking the first endeavor of its kind. Second, our\nexperiments reveal a compelling \"Deep Fusion\" phenomenon where the attention\nmechanism progressively captures the correct relational dependencies among\nsamples from the same class in deeper layers. Third, we provide a theoretical\nframework that explains and supports this \"Deep Fusion\" behavior. Finally, we\ndemonstrate through experimental results that our model achieves superior\nperformance compared to the existing approach of using a feed-forward layer.",
      "tldr_zh": "本研究探讨了在对比学习(Contrastive Learning)框架中使用Transformer作为投影头，以捕捉嵌入间的长距离依赖并提升模型性能。研究首次将Transformer应用于投影头角色，并发现了“Deep Fusion”现象，即注意力机制在更深层逐步捕捉同一类样本的正确关系依赖。该现象得到了理论框架的支持，实验结果显示，该方法比使用前馈层的传统方法表现出色，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.18681v2",
      "published_date": "2024-03-27 15:24:54 UTC",
      "updated_date": "2024-10-07 16:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:27:43.932107"
    },
    {
      "arxiv_id": "2403.18668v1",
      "title": "Aiming for Relevance",
      "title_zh": "翻译失败",
      "authors": [
        "Bar Eini Porat",
        "Danny Eytan",
        "Uri Shalit"
      ],
      "abstract": "Vital signs are crucial in intensive care units (ICUs). They are used to\ntrack the patient's state and to identify clinically significant changes.\nPredicting vital sign trajectories is valuable for early detection of adverse\nevents. However, conventional machine learning metrics like RMSE often fail to\ncapture the true clinical relevance of such predictions. We introduce novel\nvital sign prediction performance metrics that align with clinical contexts,\nfocusing on deviations from clinical norms, overall trends, and trend\ndeviations. These metrics are derived from empirical utility curves obtained in\na previous study through interviews with ICU clinicians. We validate the\nmetrics' usefulness using simulated and real clinical datasets (MIMIC and\neICU). Furthermore, we employ these metrics as loss functions for neural\nnetworks, resulting in models that excel in predicting clinically significant\nevents. This research paves the way for clinically relevant machine learning\nmodel evaluation and optimization, promising to improve ICU patient care. 10\npages, 9 figures.",
      "tldr_zh": "本研究针对 ICU 生命体征预测的临床相关性问题，指出传统机器学习指标如 RMSE 无法有效捕捉临床意义。研究者引入新型性能指标，这些指标基于临床专家访谈的经验效用曲线，重点关注临床规范偏差、整体趋势和趋势偏差，并在 MIMIC 和 eICU 等真实数据集上进行验证。利用这些指标作为神经网络的损失函数，模型在预测临床重要事件方面表现出色，最终为临床相关的机器学习模型评估和优化提供新途径，提升 ICU 患者护理水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 9 figures, AMIA Informatics 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18668v1",
      "published_date": "2024-03-27 15:11:07 UTC",
      "updated_date": "2024-03-27 15:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:27:57.892933"
    },
    {
      "arxiv_id": "2403.18659v1",
      "title": "INEXA: Interactive and Explainable Process Model Abstraction Through Object-Centric Process Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Janik-Vasily Benzin",
        "Gyunam Park",
        "Juergen Mangler",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "Process events are recorded by multiple information systems at different\ngranularity levels. Based on the resulting event logs, process models are\ndiscovered at different granularity levels, as well. Events stored at a\nfine-grained granularity level, for example, may hinder the discovered process\nmodel to be displayed due the high number of resulting model elements. The\ndiscovered process model of a real-world manufacturing process, for example,\nconsists of 1,489 model elements and over 2,000 arcs. Existing process model\nabstraction techniques could help reducing the size of the model, but would\ndisconnect it from the underlying event log. Existing event abstraction\ntechniques do neither support the analysis of mixed granularity levels, nor\ninteractive exploration of a suitable granularity level. To enable the\nexploration of discovered process models at different granularity levels, we\npropose INEXA, an interactive, explainable process model abstraction method\nthat keeps the link to the event log. As a starting point, INEXA aggregates\nlarge process models to a \"displayable\" size, e.g., for the manufacturing use\ncase to a process model with 58 model elements. Then, the process analyst can\nexplore granularity levels interactively, while applied abstractions are\nautomatically traced in the event log for explainability.",
      "tldr_zh": "该论文提出 INEXA，一种基于 Object-Centric Process Mining 的交互式、可解释过程模型抽象方法，旨在解决过程事件在不同粒度级别下导致模型过于复杂的问题，例如一个真实制造过程模型从1,489个元素减少到58个元素。INEXA 通过聚合大型模型并保持与事件日志的链接，允许分析师交互式探索混合粒度级别，同时自动追踪抽象操作以确保可解释性。与现有技术相比，该方法避免了模型与事件日志的断开，支持更有效的过程分析。实验示例显示了其在简化模型的同时保留关键信息的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18659v1",
      "published_date": "2024-03-27 15:03:33 UTC",
      "updated_date": "2024-03-27 15:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:28:11.798268"
    },
    {
      "arxiv_id": "2403.18607v1",
      "title": "Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqing Fu",
        "Gaolei Li",
        "Jun Wu",
        "Jianhua Li",
        "Xi Lin",
        "Kai Zhou",
        "Yuchen Liu"
      ],
      "abstract": "Federated neuromorphic learning (FedNL) leverages event-driven spiking neural\nnetworks and federated learning frameworks to effectively execute intelligent\nanalysis tasks over amounts of distributed low-power devices but also perform\nvulnerability to poisoning attacks. The threat of backdoor attacks on\ntraditional deep neural networks typically comes from time-invariant data.\nHowever, in FedNL, unknown threats may be hidden in time-varying spike signals.\nIn this paper, we start to explore a novel vulnerability of FedNL-based systems\nwith the concept of time division multiplexing, termed Spikewhisper, which\nallows attackers to evade detection as much as possible, as multiple malicious\nclients can imperceptibly poison with different triggers at different\ntimeslices. In particular, the stealthiness of Spikewhisper is derived from the\ntime-domain divisibility of global triggers, in which each malicious client\npastes only one local trigger to a certain timeslice in the neuromorphic\nsample, and also the polarity and motion of each local trigger can be\nconfigured by attackers. Extensive experiments based on two different\nneuromorphic datasets demonstrate that the attack success rate of Spikewispher\nis higher than the temporally centralized attacks. Besides, it is validated\nthat the effect of Spikewispher is sensitive to the trigger duration.",
      "tldr_zh": "本文提出了一种新型背门攻击方法 Spikewhisper，针对 Federated Neuromorphic Learning (FedNL) 系统，该攻击利用时间分多路复用(time division multiplexing)机制，让多个恶意客户端在不同时间片段添加本地触发器，从而提高攻击的隐蔽性和规避检测能力。攻击的关键在于全局触发器的时域可分性，每个恶意客户端仅在特定时段插入触发器，并可配置其极性和运动。实验基于两个神经形态数据集显示，Spikewhisper 的攻击成功率高于传统时间集中的攻击，且对触发器持续时间高度敏感。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18607v1",
      "published_date": "2024-03-27 14:25:02 UTC",
      "updated_date": "2024-03-27 14:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:28:23.199874"
    },
    {
      "arxiv_id": "2403.18600v2",
      "title": "RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in Instructional Videos",
      "title_zh": "RAP：用于教学视频中自适应程序规划的检索增强规划器",
      "authors": [
        "Ali Zare",
        "Yulei Niu",
        "Hammad Ayyubi",
        "Shih-fu Chang"
      ],
      "abstract": "Procedure Planning in instructional videos entails generating a sequence of\naction steps based on visual observations of the initial and target states.\nDespite the rapid progress in this task, there remain several critical\nchallenges to be solved: (1) Adaptive procedures: Prior works hold an\nunrealistic assumption that the number of action steps is known and fixed,\nleading to non-generalizable models in real-world scenarios where the sequence\nlength varies. (2) Temporal relation: Understanding the step temporal relation\nknowledge is essential in producing reasonable and executable plans. (3)\nAnnotation cost: Annotating instructional videos with step-level labels (i.e.,\ntimestamp) or sequence-level labels (i.e., action category) is demanding and\nlabor-intensive, limiting its generalizability to large-scale datasets. In this\nwork, we propose a new and practical setting, called adaptive procedure\nplanning in instructional videos, where the procedure length is not fixed or\npre-determined. To address these challenges, we introduce Retrieval-Augmented\nPlanner (RAP) model. Specifically, for adaptive procedures, RAP adaptively\ndetermines the conclusion of actions using an auto-regressive model\narchitecture. For temporal relation, RAP establishes an external memory module\nto explicitly retrieve the most relevant state-action pairs from the training\nvideos and revises the generated procedures. To tackle high annotation cost,\nRAP utilizes a weakly-supervised learning manner to expand the training dataset\nto other task-relevant, unannotated videos by generating pseudo labels for\naction steps. Experiments on CrossTask and COIN benchmarks show the superiority\nof RAP over traditional fixed-length models, establishing it as a strong\nbaseline solution for adaptive procedure planning.",
      "tldr_zh": "该论文提出 Retrieval-Augmented Planner (RAP) 模型，用于解决教学视频中自适应程序规划的挑战，包括步骤长度不确定、时间关系理解和标注成本高的问题。RAP 通过自回归模型动态生成动作序列、外部记忆模块从训练视频中检索相关状态-动作对以修正程序，以及弱监督学习方式为未标注视频生成伪标签，从而扩展数据集。实验结果显示，在 CrossTask 和 COIN 基准上，RAP 优于传统固定长度模型，确立了其作为自适应程序规划的强基线解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18600v2",
      "published_date": "2024-03-27 14:22:40 UTC",
      "updated_date": "2024-09-25 14:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:28:34.297146"
    },
    {
      "arxiv_id": "2403.18593v2",
      "title": "Homogeneous Tokenizer Matters: Homogeneous Visual Tokenizer for Remote Sensing Image Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Run Shao",
        "Zhaoyang Zhang",
        "Chao Tao",
        "Yunsheng Zhang",
        "Chengli Peng",
        "Haifeng Li"
      ],
      "abstract": "The tokenizer, as one of the fundamental components of large models, has long\nbeen overlooked or even misunderstood in visual tasks. One key factor of the\ngreat comprehension power of the large language model is that natural language\ntokenizers utilize meaningful words or subwords as the basic elements of\nlanguage. In contrast, mainstream visual tokenizers, represented by patch-based\nmethods such as Patch Embed, rely on meaningless rectangular patches as basic\nelements of vision, which cannot serve as effectively as words or subwords in\nlanguage. Starting from the essence of the tokenizer, we defined semantically\nindependent regions (SIRs) for vision. We designed a simple HOmogeneous visual\ntOKenizer: HOOK. HOOK mainly consists of two modules: the Object Perception\nModule (OPM) and the Object Vectorization Module (OVM). To achieve homogeneity,\nthe OPM splits the image into 4*4 pixel seeds and then utilizes the attention\nmechanism to perceive SIRs. The OVM employs cross-attention to merge seeds\nwithin the same SIR. To achieve adaptability, the OVM defines a variable number\nof learnable vectors as cross-attention queries, allowing for the adjustment of\ntoken quantity. We conducted experiments on the NWPU-RESISC45, WHU-RS19\nclassification dataset, and GID5 segmentation dataset for sparse and dense\ntasks. The results demonstrate that the visual tokens obtained by HOOK\ncorrespond to individual objects, which demonstrates homogeneity. HOOK\noutperformed Patch Embed by 6\\% and 10\\% in the two tasks and achieved\nstate-of-the-art performance compared to the baselines used for comparison.\nCompared to Patch Embed, which requires more than one hundred tokens for one\nimage, HOOK requires only 6 and 8 tokens for sparse and dense tasks,\nrespectively, resulting in efficiency improvements of 1.5 to 2.8 times. The\ncode is available at https://github.com/GeoX-Lab/Hook.",
      "tldr_zh": "该论文强调了视觉标记器的同质性重要性，指出主流方法如Patch Embed使用无意义的矩形块，而语言模型则依赖有意义的词或子词，提出定义语义独立区域(SIRs)来提升遥感图像理解。作者设计了简单有效的HOmogeneous visual tOKenizer（HOOK），包括Object Perception Module (OPM)用于将图像分成4*4像素种子并通过注意力机制感知SIRs，以及Object Vectorization Module (OVM)通过交叉注意力合并种子并调整标记数量以实现适应性。实验在NWPU-RESISC45、WHU-RS19分类和GID5分割数据集上显示，HOOK的视觉标记对应于单个对象，比Patch Embed提高6%和10%的性能，并以更少的标记（6-8个）实现1.5至2.8倍的效率提升，达到了最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 9 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.18593v2",
      "published_date": "2024-03-27 14:18:09 UTC",
      "updated_date": "2024-10-13 03:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:28:46.640934"
    },
    {
      "arxiv_id": "2403.18570v1",
      "title": "Physics-Informed Graph Neural Networks for Water Distribution Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Inaam Ashraf",
        "Janine Strotherm",
        "Luca Hermes",
        "Barbara Hammer"
      ],
      "abstract": "Water distribution systems (WDS) are an integral part of critical\ninfrastructure which is pivotal to urban development. As 70% of the world's\npopulation will likely live in urban environments in 2050, efficient simulation\nand planning tools for WDS play a crucial role in reaching UN's sustainable\ndevelopmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this\nrealm, we propose a novel and efficient machine learning emulator, more\nprecisely, a physics-informed deep learning (DL) model, for hydraulic state\nestimation in WDS. Using a recursive approach, our model only needs a few graph\nconvolutional neural network (GCN) layers and employs an innovative algorithm\nbased on message passing. Unlike conventional machine learning tasks, the model\nuses hydraulic principles to infer two additional hydraulic state features in\nthe process of reconstructing the available ground truth feature in an\nunsupervised manner. To the best of our knowledge, this is the first DL\napproach to emulate the popular hydraulic simulator EPANET, utilizing no\nadditional information. Like most DL models and unlike the hydraulic simulator,\nour model demonstrates vastly faster emulation times that do not increase\ndrastically with the size of the WDS. Moreover, we achieve high accuracy on the\nground truth and very similar results compared to the hydraulic simulator as\ndemonstrated through experiments on five real-world WDS datasets.",
      "tldr_zh": "该研究提出了一种基于物理信息的图神经网络（Physics-Informed Graph Neural Networks），用于水分配系统（WDS）的水力状态估计，以支持城市发展和 UN 可持续发展目标（SDG 6）。该模型采用递归方法和少量图卷积神经网络（GCN）层，通过基于消息传递的创新算法，在无监督方式下利用水力原理推断额外状态特征，从而模拟流行水力模拟器 EPANET，而无需额外信息。实验结果显示，该模型在五个真实世界 WDS 数据集上实现了高准确率，并显著提高了仿真速度，与传统模拟器相比更高效且不受系统规模影响大。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version of the paper with the same title published at\n  Proceedings of the AAAI Conference on Artificial Intelligence 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18570v1",
      "published_date": "2024-03-27 13:51:26 UTC",
      "updated_date": "2024-03-27 13:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:28:57.363788"
    },
    {
      "arxiv_id": "2403.18569v2",
      "title": "PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop Prediction",
      "title_zh": "PDNNet：PDN感知的GNN-CNN异构网络用于动态IR Drop预测",
      "authors": [
        "Yuxiang Zhao",
        "Zhuomin Chai",
        "Xun Jiang",
        "Yibo Lin",
        "Runsheng Wang",
        "Ru Huang"
      ],
      "abstract": "IR drop on the power delivery network (PDN) is closely related to PDN's\nconfiguration and cell current consumption. As the integrated circuit (IC)\ndesign is growing larger, dynamic IR drop simulation becomes computationally\nunaffordable and machine learning based IR drop prediction has been explored as\na promising solution. Although CNN-based methods have been adapted to IR drop\nprediction task in several works, the shortcomings of overlooking PDN\nconfiguration is non-negligible. In this paper, we consider not only how to\nproperly represent cell-PDN relation, but also how to model IR drop following\nits physical nature in the feature aggregation procedure. Thus, we propose a\nnovel graph structure, PDNGraph, to unify the representations of the PDN\nstructure and the fine-grained cell-PDN relation. We further propose a\ndual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN\nbranches to favorably capture the above features during the learning process.\nSeveral key designs are presented to make the dynamic IR drop prediction highly\neffective and interpretable. We are the first work to apply graph structure to\ndeep-learning based dynamic IR drop prediction method. Experiments show that\nPDNNet outperforms the state-of-the-art CNN-based methods and achieves 545x\nspeedup compared to the commercial tool, which demonstrates the superiority of\nour method.",
      "tldr_zh": "该研究针对集成电路（IC）设计中动态 IR drop 预测问题，提出了一种考虑 PDN 配置的创新方法，以解决传统模拟计算昂贵且现有 CNN 方法忽略 PDN 结构的问题。论文引入 PDNGraph 来统一表示 PDN 结构和细粒度单元-PDN 关系，并开发了 PDNNet，一个双分支异构网络，结合 GNN 和 CNN 分支来有效捕获相关特征并遵循 IR drop 的物理特性。实验结果显示，PDNNet 优于最先进 CNN 方法，并在速度上比商业工具实现 545 倍加速，这标志着首次将图结构应用于深度学习-based 动态 IR drop 预测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18569v2",
      "published_date": "2024-03-27 13:50:13 UTC",
      "updated_date": "2024-12-05 09:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:29:09.895870"
    },
    {
      "arxiv_id": "2404.01317v1",
      "title": "Intelligent Learning Rate Distribution to reduce Catastrophic Forgetting in Transformers",
      "title_zh": "智能学习率分布",
      "authors": [
        "Philip Kenneweg",
        "Alexander Schulz",
        "Sarah Schröder",
        "Barbara Hammer"
      ],
      "abstract": "Pretraining language models on large text corpora is a common practice in\nnatural language processing. Fine-tuning of these models is then performed to\nachieve the best results on a variety of tasks. In this paper, we investigate\nthe problem of catastrophic forgetting in transformer neural networks and\nquestion the common practice of fine-tuning with a flat learning rate for the\nentire network in this context. We perform a hyperparameter optimization\nprocess to find learning rate distributions that are better than a flat\nlearning rate. We combine the learning rate distributions thus found and show\nthat they generalize to better performance with respect to the problem of\ncatastrophic forgetting. We validate these learning rate distributions with a\nvariety of NLP benchmarks from the GLUE dataset.",
      "tldr_zh": "本研究探讨了Transformer模型在预训练语言模型微调过程中存在的catastrophic forgetting问题，并质疑了使用flat learning rate的传统方法。通过超参数优化，作者发现了更优的学习率分布，这些分布能够有效减少catastrophic forgetting并提升模型性能。在GLUE数据集的各种NLP基准上验证显示，这些学习率分布具有良好的泛化性，并实现了更好的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01317v1",
      "published_date": "2024-03-27 13:40:09 UTC",
      "updated_date": "2024-03-27 13:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:29:20.612876"
    },
    {
      "arxiv_id": "2403.18547v1",
      "title": "Neural Architecture Search for Sentence Classification with BERT",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Kenneweg",
        "Sarah Schröder",
        "Barbara Hammer"
      ],
      "abstract": "Pre training of language models on large text corpora is common practice in\nNatural Language Processing. Following, fine tuning of these models is\nperformed to achieve the best results on a variety of tasks. In this paper we\nquestion the common practice of only adding a single output layer as a\nclassification head on top of the network. We perform an AutoML search to find\narchitectures that outperform the current single layer at only a small compute\ncost. We validate our classification architecture on a variety of NLP\nbenchmarks from the GLUE dataset.",
      "tldr_zh": "本文质疑了在 BERT 模型上仅添加单个输出层作为分类头的常见做法，提出使用 Neural Architecture Search (NAS) 和 AutoML 搜索来优化句子分类架构，以实现更好的性能，同时仅增加少量计算成本。该方法通过自动搜索发现的架构在 GLUE 数据集的各种 NLP 基准上进行了验证，证明了其有效性。总体而言，这为改进预训练语言模型的微调过程提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18547v1",
      "published_date": "2024-03-27 13:25:43 UTC",
      "updated_date": "2024-03-27 13:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:29:37.467836"
    },
    {
      "arxiv_id": "2403.18546v2",
      "title": "Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Siang Chen",
        "Wei Tang",
        "Pengwei Xie",
        "Wenming Yang",
        "Guijin Wang"
      ],
      "abstract": "Fast and robust object grasping in clutter is a crucial component of\nrobotics. Most current works resort to the whole observed point cloud for 6-Dof\ngrasp generation, ignoring the guidance information excavated from global\nsemantics, thus limiting high-quality grasp generation and real-time\nperformance. In this work, we show that the widely used heatmaps are\nunderestimated in the efficiency of 6-Dof grasp generation. Therefore, we\npropose an effective local grasp generator combined with grasp heatmaps as\nguidance, which infers in a global-to-local semantic-to-point way.\nSpecifically, Gaussian encoding and the grid-based strategy are applied to\npredict grasp heatmaps as guidance to aggregate local points into graspable\nregions and provide global semantic information. Further, a novel non-uniform\nanchor sampling mechanism is designed to improve grasp accuracy and diversity.\nBenefiting from the high-efficiency encoding in the image space and focusing on\npoints in local graspable regions, our framework can perform high-quality grasp\ndetection in real-time and achieve state-of-the-art results. In addition, real\nrobot experiments demonstrate the effectiveness of our method with a success\nrate of 94% and a clutter completion rate of 100%. Our code is available at\nhttps://github.com/THU-VCLab/HGGD.",
      "tldr_zh": "该论文提出了一种高效的基于热图指导的6-Dof抓取检测方法，旨在解决机器人杂乱场景中抓取的实时性和质量问题，通过从全局语义中提取指导信息来提升性能。方法包括使用Gaussian encoding和网格策略预测grasp heatmaps，以聚合局部点云到可抓取区域并提供全局语义指导，同时引入non-uniform anchor sampling机制来提高抓取的准确性和多样性。实验结果显示，该框架实现了实时的高质量检测，并在真实机器人测试中达到state-of-the-art水平，成功率94%和杂乱场景完成率100%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Extensive results on GraspNet-1B dataset",
      "pdf_url": "http://arxiv.org/pdf/2403.18546v2",
      "published_date": "2024-03-27 13:24:58 UTC",
      "updated_date": "2024-05-14 01:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:29:50.829239"
    },
    {
      "arxiv_id": "2403.18537v1",
      "title": "A Path Towards Legal Autonomy: An interoperable and explainable approach to extracting, transforming, loading and computing legal information using large language models, expert systems and Bayesian networks",
      "title_zh": "翻译失败",
      "authors": [
        "Axel Constant",
        "Hannes Westermann",
        "Bryan Wilson",
        "Alex Kiefer",
        "Ines Hipolito",
        "Sylvain Pronovost",
        "Steven Swanson",
        "Mahault Albarracin",
        "Maxwell J. D. Ramstead"
      ],
      "abstract": "Legal autonomy - the lawful activity of artificial intelligence agents - can\nbe achieved in one of two ways. It can be achieved either by imposing\nconstraints on AI actors such as developers, deployers and users, and on AI\nresources such as data, or by imposing constraints on the range and scope of\nthe impact that AI agents can have on the environment. The latter approach\ninvolves encoding extant rules concerning AI driven devices into the software\nof AI agents controlling those devices (e.g., encoding rules about limitations\non zones of operations into the agent software of an autonomous drone device).\nThis is a challenge since the effectivity of such an approach requires a method\nof extracting, loading, transforming and computing legal information that would\nbe both explainable and legally interoperable, and that would enable AI agents\nto reason about the law. In this paper, we sketch a proof of principle for such\na method using large language models (LLMs), expert legal systems known as\nlegal decision paths, and Bayesian networks. We then show how the proposed\nmethod could be applied to extant regulation in matters of autonomous cars,\nsuch as the California Vehicle Code.",
      "tldr_zh": "该论文探讨了实现法律自治（Legal autonomy）的路径，提出了一种可解释且法律可互操作的方法，用于提取、转换、加载和计算法律信息。方法结合了大型语言模型（LLMs）、专家系统（如法律决策路径）和贝叶斯网络（Bayesian networks），使AI代理能够推理和遵守法律规则。通过证明性示例，该方法应用于现有法规，例如加州车辆法规中的自动驾驶汽车场景，为AI在法律环境中的自主操作提供了可行框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18537v1",
      "published_date": "2024-03-27 13:12:57 UTC",
      "updated_date": "2024-03-27 13:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:30:01.110164"
    },
    {
      "arxiv_id": "2403.18536v1",
      "title": "A Novel Behavior-Based Recommendation System for E-commerce",
      "title_zh": "一种新颖的基于行为的电子商务推荐系统",
      "authors": [
        "Reza Barzegar Nozari",
        "Mahdi Divsalar",
        "Sepehr Akbarzadeh Abkenar",
        "Mohammadreza Fadavi Amiri",
        "Ali Divsalar"
      ],
      "abstract": "The majority of existing recommender systems rely on user ratings, which are\nlimited by the lack of user collaboration and the sparsity problem. To address\nthese issues, this study proposes a behavior-based recommender system that\nleverages customers' natural behaviors, such as browsing and clicking, on\ne-commerce platforms. The proposed recommendation system involves clustering\nactive customers, determining neighborhoods, collecting similar users,\ncalculating product reputation based on similar users, and recommending\nhigh-reputation products. To overcome the complexity of customer behaviors and\ntraditional clustering methods, an unsupervised clustering approach based on\nproduct categories is developed to enhance the recommendation methodology. This\nstudy makes notable contributions in several aspects. Firstly, a groundbreaking\nbehavior-based recommendation methodology is developed, incorporating customer\nbehavior to generate accurate and tailored recommendations leading to improved\ncustomer satisfaction and engagement. Secondly, an original unsupervised\nclustering method, focusing on product categories, enables more precise\nclustering and facilitates accurate recommendations. Finally, an approach to\ndetermine neighborhoods for active customers within clusters is established,\nensuring grouping of customers with similar behavioral patterns to enhance\nrecommendation accuracy and relevance. The proposed recommendation methodology\nand clustering method contribute to improved recommendation performance,\noffering valuable insights for researchers and practitioners in the field of\ne-commerce recommendation systems. Additionally, the proposed method\noutperforms benchmark methods in experiments conducted using a behavior dataset\nfrom the well-known e-commerce site Alibaba.",
      "tldr_zh": "这篇论文提出了一种新型行为-based推荐系统，用于电商平台，以解决传统基于用户评分的稀疏性和用户协作不足问题。该系统利用用户浏览和点击等行为，通过聚类活跃客户、确定邻域、收集类似用户以及基于产品类别的unsupervised clustering来计算产品声誉并推荐高声誉产品。创新点包括开发原创的behavior-based推荐方法和精确的聚类技术，提升了推荐准确性和客户满意度。在Alibaba数据集的实验中，该方法表现出色，优于基准方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18536v1",
      "published_date": "2024-03-27 13:12:41 UTC",
      "updated_date": "2024-03-27 13:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:30:12.999576"
    },
    {
      "arxiv_id": "2403.18519v1",
      "title": "Improving Line Search Methods for Large Scale Neural Network Training",
      "title_zh": "改进大规模神经网络训练的线搜索方法",
      "authors": [
        "Philip Kenneweg",
        "Tristan Kenneweg",
        "Barbara Hammer"
      ],
      "abstract": "In recent studies, line search methods have shown significant improvements in\nthe performance of traditional stochastic gradient descent techniques,\neliminating the need for a specific learning rate schedule. In this paper, we\nidentify existing issues in state-of-the-art line search methods, propose\nenhancements, and rigorously evaluate their effectiveness. We test these\nmethods on larger datasets and more complex data domains than before.\nSpecifically, we improve the Armijo line search by integrating the momentum\nterm from ADAM in its search direction, enabling efficient large-scale\ntraining, a task that was previously prone to failure using Armijo line search\nmethods. Our optimization approach outperforms both the previous Armijo\nimplementation and tuned learning rate schedules for Adam. Our evaluation\nfocuses on Transformers and CNNs in the domains of NLP and image data. Our work\nis publicly available as a Python package, which provides a hyperparameter free\nPytorch optimizer.",
      "tldr_zh": "这篇论文改进了线搜索 methods，用于大规模神经网络训练，通过消除对特定学习率 schedule 的需求来提升传统随机梯度下降的性能。研究者识别了现有 state-of-the-art 线搜索方法的不足，并提出增强方案，包括将 ADAM 的 momentum 项整合到 Armijo line search 中，以实现高效的大规模训练。实验结果显示，该优化方法在更大数据集和复杂领域（如 NLP 和图像数据）中的 Transformers 和 CNNs 上，优于之前的 Armijo 实现和调整的学习率 schedule。最后，工作以无超参数的 Python 包形式公开，作为 PyTorch 优化器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18519v1",
      "published_date": "2024-03-27 12:50:27 UTC",
      "updated_date": "2024-03-27 12:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:30:26.355600"
    },
    {
      "arxiv_id": "2403.18506v1",
      "title": "Faster Convergence for Transformer Fine-tuning with Line Search Methods",
      "title_zh": "利用线搜索方法实现",
      "authors": [
        "Philip Kenneweg",
        "Leonardo Galli",
        "Tristan Kenneweg",
        "Barbara Hammer"
      ],
      "abstract": "Recent works have shown that line search methods greatly increase performance\nof traditional stochastic gradient descent methods on a variety of datasets and\narchitectures [1], [2]. In this work we succeed in extending line search\nmethods to the novel and highly popular Transformer architecture and dataset\ndomains in natural language processing. More specifically, we combine the\nArmijo line search with the Adam optimizer and extend it by subdividing the\nnetworks architecture into sensible units and perform the line search\nseparately on these local units. Our optimization method outperforms the\ntraditional Adam optimizer and achieves significant performance improvements\nfor small data sets or small training budgets, while performing equal or better\nfor other tested cases. Our work is publicly available as a python package,\nwhich provides a hyperparameter-free pytorch optimizer that is compatible with\narbitrary network architectures.",
      "tldr_zh": "本研究提出了一种结合 Armijo line search 方法与 Adam optimizer 的优化策略，用于加速 Transformer 模型的微调过程。具体而言，该方法将网络架构分解为局部单位，并在这些单位上单独执行 line search，从而显著提升小数据集或小训练预算场景下的性能，并在其他测试案例中表现相当或更好。实验结果显示，该优化方法优于传统 Adam optimizer，并作为无超参数的 PyTorch 优化器公开提供，兼容任意网络架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18506v1",
      "published_date": "2024-03-27 12:35:23 UTC",
      "updated_date": "2024-03-27 12:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:30:36.022992"
    },
    {
      "arxiv_id": "2403.18489v1",
      "title": "Impact of Employing Weather Forecast Data as Input to the Estimation of Evapotranspiration by Deep Neural Network Models",
      "title_zh": "使用天气预报数据作为输入对深度神经网络模型估计蒸腾蒸发的冲击",
      "authors": [
        "Pedro J. Vaz",
        "Gabriela Schütz",
        "Carlos Guerrero",
        "Pedro J. S. Cardoso"
      ],
      "abstract": "Reference Evapotranspiration (ET0) is a key parameter for designing smart\nirrigation scheduling, since it is related by a coefficient to the water needs\nof a crop. The United Nations Food and Agriculture Organization, proposed a\nstandard method for ET0 computation (FAO56PM), based on the parameterization of\nthe Penman-Monteith equation, that is widely adopted in the literature. To\ncompute ET0 using the FAO56-PM method, four main weather parameters are needed:\ntemperature, humidity, wind, and solar radiation (SR). One way to make daily\nET0 estimations for future days is to use freely available weather forecast\nservices (WFSs), where many meteorological parameters are estimated up to the\nnext 15 days. A problem with this method is that currently, SR is not provided\nas a free forecast parameter on most of those online services or, normally,\nsuch forecasts present a financial cost penalty. For this reason, several ET0\nestimation models using machine and deep learning were developed and presented\nin the literature, that use as input features a reduced set of carefully\nselected weather parameters, that are compatible with common freely available\nWFSs. However, most studies on this topic have only evaluated model performance\nusing data from weather stations (WSs), without considering the effect of using\nweather forecast data. In this study, the performance of authors' previous\nmodels is evaluated when using weather forecast data from two online WFSs, in\nthe following scenarios: (i) direct ET0 estimation by an ANN model, and (ii)\nestimate SR by ANN model, and then use that estimation for ET0 computation,\nusing the FAO56-PM method. Employing data collected from two WFSs and a WS\nlocated in Vale do Lobo, Portugal, the latter approach achieved the best\nresult, with a coefficient of determination (R2) ranging between 0.893 and\n0.667, when considering forecasts up to 15 days.",
      "tldr_zh": "本文研究了使用天气预报数据作为输入，通过深度神经网络模型估计参考蒸腾量 (ET0) 的影响，ET0 是智能灌溉调度的关键参数，通常依赖 FAO56-PM 方法计算，但该方法需要温度、湿度、风速和太阳辐射 (SR) 等参数，而 SR 在许多免费天气预报服务 (WFS) 中不可用。研究评估了两种场景：(i) 直接用 ANN 模型估计 ET0，以及 (ii) 先用 ANN 模型估计 SR，然后应用 FAO56-PM 方法计算 ET0。利用葡萄牙 Vale do Lobo 地区的 WFS 和天气站 (WS) 数据，结果显示第二种方法更有效，系数决定值 (R2) 在 0.893 到 0.667 之间，适用于未来 15 天的预报。这为基于预报数据的 ET0 估计提供了实用改进，促进更高效的智能灌溉系统。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "A partial version of the work submitted to ESRE/INTERNATIONAL\n  CONFERENCE ON ENVIRONMENTAL SCIENCES AND RENEWABLE ENERGY",
      "pdf_url": "http://arxiv.org/pdf/2403.18489v1",
      "published_date": "2024-03-27 12:01:51 UTC",
      "updated_date": "2024-03-27 12:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:30:51.797557"
    },
    {
      "arxiv_id": "2403.18486v1",
      "title": "Synthesizing EEG Signals from Event-Related Potential Paradigms with Conditional Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guido Klein",
        "Pierre Guetschel",
        "Gianluigi Silvestri",
        "Michael Tangermann"
      ],
      "abstract": "Data scarcity in the brain-computer interface field can be alleviated through\nthe use of generative models, specifically diffusion models. While diffusion\nmodels have previously been successfully applied to electroencephalogram (EEG)\ndata, existing models lack flexibility w.r.t.~sampling or require alternative\nrepresentations of the EEG data. To overcome these limitations, we introduce a\nnovel approach to conditional diffusion models that utilizes classifier-free\nguidance to directly generate subject-, session-, and class-specific EEG data.\nIn addition to commonly used metrics, domain-specific metrics are employed to\nevaluate the specificity of the generated samples. The results indicate that\nthe proposed model can generate EEG data that resembles real data for each\nsubject, session, and class.",
      "tldr_zh": "本文提出了一种新型条件扩散模型，用于从事件相关电位范式合成EEG信号，以缓解脑-计算机接口领域的数据稀缺问题。该模型采用classifier-free guidance，直接生成特定于受试者、会话和类的EEG数据，避免了现有模型在采样灵活性上的局限。实验结果表明，生成的EEG样本在常用和领域特定指标上与真实数据高度相似，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "I.2.6; G.3; I.5.4; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "submitted to 9th Graz BCI conference, 6 pages, 3 figures, first\n  figure is split into two subfigures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2403.18486v1",
      "published_date": "2024-03-27 11:58:45 UTC",
      "updated_date": "2024-03-27 11:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:30:59.871731"
    },
    {
      "arxiv_id": "2403.18469v1",
      "title": "Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain Adaptive Segmentation of 3D Point Clouds",
      "title_zh": "翻译失败",
      "authors": [
        "Zhimin Yuan",
        "Wankang Zeng",
        "Yanfei Su",
        "Weiquan Liu",
        "Ming Cheng",
        "Yulan Guo",
        "Cheng Wang"
      ],
      "abstract": "3D synthetic-to-real unsupervised domain adaptive segmentation is crucial to\nannotating new domains. Self-training is a competitive approach for this task,\nbut its performance is limited by different sensor sampling patterns (i.e.,\nvariations in point density) and incomplete training strategies. In this work,\nwe propose a density-guided translator (DGT), which translates point density\nbetween domains, and integrates it into a two-stage self-training pipeline\nnamed DGT-ST. First, in contrast to existing works that simultaneously conduct\ndata generation and feature/output alignment within unstable adversarial\ntraining, we employ the non-learnable DGT to bridge the domain gap at the input\nlevel. Second, to provide a well-initialized model for self-training, we\npropose a category-level adversarial network in stage one that utilizes the\nprototype to prevent negative transfer. Finally, by leveraging the designs\nabove, a domain-mixed self-training method with source-aware consistency loss\nis proposed in stage two to narrow the domain gap further. Experiments on two\nsynthetic-to-real segmentation tasks (SynLiDAR $\\rightarrow$ semanticKITTI and\nSynLiDAR $\\rightarrow$ semanticPOSS) demonstrate that DGT-ST outperforms\nstate-of-the-art methods, achieving 9.4$\\%$ and 4.3$\\%$ mIoU improvements,\nrespectively. Code is available at \\url{https://github.com/yuan-zm/DGT-ST}.",
      "tldr_zh": "这篇论文针对 3D 点云的合成到真实无监督域适应分割问题，提出了一种密度引导翻译器 (DGT)，用于桥接域间点密度差异，并将其整合进两阶段自训练管道 (DGT-ST)。在第一阶段，DGT 在输入级别处理数据生成，同时引入类别级对抗网络，利用原型防止负面转移，以提供良好的模型初始化；在第二阶段，通过域混合自训练方法和源感知一致性损失进一步缩小域间差距。实验结果显示，DGT-ST 在 SynLiDAR → semanticKITTI 和 SynLiDAR → semanticPOSS 任务上，比最先进方法分别提升了 9.4% 和 4.3% mIoU，显著提高了分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18469v1",
      "published_date": "2024-03-27 11:28:57 UTC",
      "updated_date": "2024-03-27 11:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:31:14.886873"
    },
    {
      "arxiv_id": "2403.18459v1",
      "title": "CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Marina Ionova",
        "Jan Kristof Behrens"
      ],
      "abstract": "Assembly processes involving humans and robots are challenging scenarios\nbecause the individual activities and access to shared workspace have to be\ncoordinated. Fixed robot programs leave no room to diverge from a fixed\nprotocol. Working on such a process can be stressful for the user and lead to\nineffective behavior or failure. We propose a novel approach of online\nconstraint-based scheduling in a reactive execution control framework\nfacilitating behavior trees called CoBOS. This allows the robot to adapt to\nuncertain events such as delayed activity completions and activity selection\n(by the human). The user will experience less stress as the robotic coworkers\nadapt their behavior to best complement the human-selected activities to\ncomplete the common task. In addition to the improved working conditions, our\nalgorithm leads to increased efficiency, even in highly uncertain scenarios. We\nevaluate our algorithm using a probabilistic simulation study with 56000\nexperiments. We outperform all baselines by a margin of 4-10%. Initial real\nrobot experiments using a Franka Emika Panda robot and human tracking based on\nHTC Vive VR gloves look promising.",
      "tldr_zh": "这篇论文提出了 CoBOS，一种基于约束的在线调度系统，用于人类-机器人协作中的装配过程，旨在通过 behavior trees 在反应式执行控制框架中协调活动。CoBOS 允许机器人实时适应不确定事件，如活动延迟或人类选择，从而减少用户压力并提升整体效率。实验结果显示，在 56000 次概率模拟中，该算法比基线模型提高了 4-10% 的性能，并在初步真实机器人实验中使用 Franka Emika Panda 机器人验证了其可行性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.18459v1",
      "published_date": "2024-03-27 11:18:01 UTC",
      "updated_date": "2024-03-27 11:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:31:24.122620"
    },
    {
      "arxiv_id": "2403.18451v1",
      "title": "CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in Resource-Constrained CPS and IoT",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Hu",
        "Jinhang Zuo",
        "Alanis Zhao",
        "Bob Iannucci",
        "Carlee Joe-Wong"
      ],
      "abstract": "Foundation models (FMs) emerge as a promising solution to harness distributed\nand diverse environmental data by leveraging prior knowledge to understand the\ncomplicated temporal and spatial correlations within heterogeneous datasets.\nUnlike distributed learning frameworks such as federated learning, which often\nstruggle with multimodal data, FMs can transform diverse inputs into\nembeddings. This process facilitates the integration of information from\nvarious modalities and the application of prior learning to new domains.\nHowever, deploying FMs in resource-constrained edge systems poses significant\nchallenges. To this end, we introduce CoRAST, a novel learning framework that\nutilizes FMs for enhanced analysis of distributed, correlated heterogeneous\ndata. Utilizing a server-based FM, CoRAST can exploit existing environment\ninformation to extract temporal, spatial, and cross-modal correlations among\nsensor data. This enables CoRAST to offer context-aware insights for localized\nclient tasks through FM-powered global representation learning. Our evaluation\non real-world weather dataset demonstrates CoRAST's ability to exploit\ncorrelated heterogeneous data through environmental representation learning to\nreduce the forecast errors by up to 50.3% compared to the baselines.",
      "tldr_zh": "该研究提出CoRAST框架，利用Foundation Models (FMs)来增强资源受限的CPS和IoT环境中相关联异构数据的分析。CoRAST通过服务器端的FM提取传感器数据中的时间、空间和跨模态相关性，实现FM驱动的全局表示学习，从而为本地任务提供基于上下文的洞见。与传统分布式学习框架不同，该框架能有效处理多模态数据。实验在真实天气数据集上显示，CoRAST通过环境表示学习将预测错误降低高达50.3%，显著优于基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted and to be published in 2024 IEEE International Workshop on\n  Foundation Models for Cyber-Physical Systems & Internet of Things (FMSys)",
      "pdf_url": "http://arxiv.org/pdf/2403.18451v1",
      "published_date": "2024-03-27 11:11:06 UTC",
      "updated_date": "2024-03-27 11:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:31:39.837773"
    },
    {
      "arxiv_id": "2403.18425v1",
      "title": "U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ilias Mitsouras",
        "Eleftherios Tsonis",
        "Paraskevi Tzouveli",
        "Athanasios Voulodimos"
      ],
      "abstract": "Diffusion models have demonstrated remarkable performance in text-to-image\nsynthesis, producing realistic and high resolution images that faithfully\nadhere to the corresponding text-prompts. Despite their great success, they\nstill fall behind in sketch-to-image synthesis tasks, where in addition to\ntext-prompts, the spatial layout of the generated images has to closely follow\nthe outlines of certain reference sketches. Employing an MLP latent edge\npredictor to guide the spatial layout of the synthesized image by predicting\nedge maps at each denoising step has been recently proposed. Despite yielding\npromising results, the pixel-wise operation of the MLP does not take into\naccount the spatial layout as a whole, and demands numerous denoising\niterations to produce satisfactory images, leading to time inefficiency. To\nthis end, we introduce U-Sketch, a framework featuring a U-Net type latent edge\npredictor, which is capable of efficiently capturing both local and global\nfeatures, as well as spatial correlations between pixels. Moreover, we propose\nthe addition of a sketch simplification network that offers the user the choice\nof preprocessing and simplifying input sketches for enhanced outputs. The\nexperimental results, corroborated by user feedback, demonstrate that our\nproposed U-Net latent edge predictor leads to more realistic results, that are\nbetter aligned with the spatial outlines of the reference sketches, while\ndrastically reducing the number of required denoising steps and, consequently,\nthe overall execution time.",
      "tldr_zh": "该研究针对扩散模型（Diffusion models）在sketch-to-image合成任务中的效率问题，提出了一种高效框架U-Sketch。该框架采用U-Net type latent edge predictor，能够同时捕捉局部和全局特征以及像素间的空间相关性，从而更好地指导图像生成过程，同时减少去噪迭代步骤。研究还引入了sketch simplification network，用户可预处理简化输入草图以提升输出质量。实验结果和用户反馈显示，U-Sketch生成更真实的图像，更精确地遵循参考草图的布局，并显著降低执行时间。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18425v1",
      "published_date": "2024-03-27 10:26:42 UTC",
      "updated_date": "2024-03-27 10:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:31:51.665886"
    },
    {
      "arxiv_id": "2403.18421v1",
      "title": "BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot Bolton",
        "Abhinav Venigalla",
        "Michihiro Yasunaga",
        "David Hall",
        "Betty Xiong",
        "Tony Lee",
        "Roxana Daneshjou",
        "Jonathan Frankle",
        "Percy Liang",
        "Michael Carbin",
        "Christopher D. Manning"
      ],
      "abstract": "Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance\non a wide variety of biomedical NLP tasks. However, these models have hundreds\nof billions of parameters, are computationally expensive to run, require users\nto send their input data over the internet, and are trained on unknown data\nsources. Can smaller, more targeted models compete? To address this question,\nwe build and release BioMedLM, a 2.7 billion parameter GPT-style autoregressive\nmodel trained exclusively on PubMed abstracts and full articles. When\nfine-tuned, BioMedLM can produce strong multiple-choice biomedical\nquestion-answering results competitive with much larger models, such as\nachieving a score of 57.3% on MedMCQA (dev) and 69.0% on the MMLU Medical\nGenetics exam. BioMedLM can also be fine-tuned to produce useful answers to\npatient questions on medical topics. This demonstrates that smaller models can\npotentially serve as transparent, privacy-preserving, economical and\nenvironmentally friendly foundations for particular NLP applications, such as\nin biomedicine. The model is available on the Hugging Face Hub:\nhttps://huggingface.co/stanford-crfm/BioMedLM.",
      "tldr_zh": "该研究开发了BioMedLM，一款2.7B参数的GPT-style自回归语言模型，仅在PubMed摘要和全文上训练，以应对大型模型如GPT-4和Med-PaLM 2在生物医学NLP任务中的高计算成本和隐私问题。微调后，BioMedLM在多项选择问答任务上表现出色，例如在MedMCQA (dev)上得分57.3%，在MMLU Medical Genetics考试上达到69.0%，并能有效回答患者医疗问题。BioMedLM证明了小型模型可作为透明、隐私保护、经济和环境友好的基础，适用于生物医学应用，并已在Hugging Face Hub上发布。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.18421v1",
      "published_date": "2024-03-27 10:18:21 UTC",
      "updated_date": "2024-03-27 10:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:32:05.205054"
    },
    {
      "arxiv_id": "2403.18407v1",
      "title": "A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is Critical for Semi-supervised Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Wu",
        "Junbiao Pang",
        "Baochang Zhang",
        "Qingming Huang"
      ],
      "abstract": "Semi-supervised learning (SSL) is a practical challenge in computer vision.\nPseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of\nThe Art (SOTA) performances in SSL. These approaches employ a\nthreshold-to-pseudo-label (T2L) process to generate PLs by truncating the\nconfidence scores of unlabeled data predicted by the self-training method.\nHowever, self-trained models typically yield biased and high-variance\npredictions, especially in the scenarios when a little labeled data are\nsupplied. To address this issue, we propose a lightweight channel-based\nensemble method to effectively consolidate multiple inferior PLs into the\ntheoretically guaranteed unbiased and low-variance one. Importantly, our\napproach can be readily extended to any SSL framework, such as FixMatch or\nFreeMatch. Experimental results demonstrate that our method significantly\noutperforms state-of-the-art techniques on CIFAR10/100 in terms of\neffectiveness and efficiency.",
      "tldr_zh": "本文提出了一种基于通道集成的轻量级方法（channel-based ensemble），旨在解决半监督学习（SSL）中伪标签（PL）生成的问题，特别是自训练模型的预测偏差（biased）和高方差（high-variance），这在标记数据稀少时尤为突出。该方法通过整合多个次优伪标签，生成理论上无偏差和低方差的伪标签，并可轻松扩展到现有框架如FixMatch和FreeMatch。实验结果显示，该方法在CIFAR10/100数据集上显著优于最先进技术，在有效性和效率方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18407v1",
      "published_date": "2024-03-27 09:49:37 UTC",
      "updated_date": "2024-03-27 09:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:32:17.659476"
    },
    {
      "arxiv_id": "2403.18406v1",
      "title": "An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering Using a VLM",
      "title_zh": "翻译失败",
      "authors": [
        "Wonkyun Kim",
        "Changin Choi",
        "Wonseok Lee",
        "Wonjong Rhee"
      ],
      "abstract": "Stimulated by the sophisticated reasoning capabilities of recent Large\nLanguage Models (LLMs), a variety of strategies for bridging video modality\nhave been devised. A prominent strategy involves Video Language Models\n(VideoLMs), which train a learnable interface with video data to connect\nadvanced vision encoders with LLMs. Recently, an alternative strategy has\nsurfaced, employing readily available foundation models, such as VideoLMs and\nLLMs, across multiple stages for modality bridging. In this study, we introduce\na simple yet novel strategy where only a single Vision Language Model (VLM) is\nutilized. Our starting point is the plain insight that a video comprises a\nseries of images, or frames, interwoven with temporal information. The essence\nof video comprehension lies in adeptly managing the temporal aspects along with\nthe spatial details of each frame. Initially, we transform a video into a\nsingle composite image by arranging multiple frames in a grid layout. The\nresulting single image is termed as an image grid. This format, while\nmaintaining the appearance of a solitary image, effectively retains temporal\ninformation within the grid structure. Therefore, the image grid approach\nenables direct application of a single high-performance VLM without\nnecessitating any video-data training. Our extensive experimental analysis\nacross ten zero-shot video question answering benchmarks, including five\nopen-ended and five multiple-choice benchmarks, reveals that the proposed Image\nGrid Vision Language Model (IG-VLM) surpasses the existing methods in nine out\nof ten benchmarks.",
      "tldr_zh": "本研究提出了一种简单创新策略，用于零-shot 视频问答（zero-shot video question answering），即通过将视频帧排列成一个图像网格（image grid）来处理视频内容，从而仅使用单个 Vision Language Model (VLM) 进行分析。  \n该方法将视频的时序信息嵌入网格结构中，避免了额外视频数据训练的需求，同时保留了帧的空间细节以实现有效视频理解。  \n实验结果显示，在十个基准测试中，包括五种开放式和五种多项选择题，提出的 IG-VLM 在九个基准上超过了现有方法，证明了其在 Video Language Models (VideoLMs) 和 Large Language Models (LLMs) 领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Our code is available at https://github.com/imagegridworth/IG-VLM",
      "pdf_url": "http://arxiv.org/pdf/2403.18406v1",
      "published_date": "2024-03-27 09:48:23 UTC",
      "updated_date": "2024-03-27 09:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:32:28.621057"
    },
    {
      "arxiv_id": "2403.18405v1",
      "title": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Shengjie Ma",
        "Chong Chen",
        "Qi Chu",
        "Jiaxin Mao"
      ],
      "abstract": "Collecting relevant judgments for legal case retrieval is a challenging and\ntime-consuming task. Accurately judging the relevance between two legal cases\nrequires a considerable effort to read the lengthy text and a high level of\ndomain expertise to extract Legal Facts and make juridical judgments. With the\nadvent of advanced large language models, some recent studies have suggested\nthat it is promising to use LLMs for relevance judgment. Nonetheless, the\nmethod of employing a general large language model for reliable relevance\njudgments in legal case retrieval is yet to be thoroughly explored. To fill\nthis research gap, we devise a novel few-shot workflow tailored to the relevant\njudgment of legal cases. The proposed workflow breaks down the annotation\nprocess into a series of stages, imitating the process employed by human\nannotators and enabling a flexible integration of expert reasoning to enhance\nthe accuracy of relevance judgments. By comparing the relevance judgments of\nLLMs and human experts, we empirically show that we can obtain reliable\nrelevance judgments with the proposed workflow. Furthermore, we demonstrate the\ncapacity to augment existing legal case retrieval models through the synthesis\nof data generated by the large language model.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型（LLMs）来处理法律案例检索中的相关性判断问题，以解决传统方法耗时且需要高水平领域专业知识的挑战。作者提出了一种新型few-shot工作流程，将判断过程分解成多个阶段，模仿人类标注者的步骤并整合专家推理，以提高准确性。通过实验比较LLMs与人类专家的判断结果，证明该工作流程能生成可靠的相关性判断。此外，该方法还展示了如何使用LLMs生成的合成数据来增强现有的法律案例检索模型。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18405v1",
      "published_date": "2024-03-27 09:46:56 UTC",
      "updated_date": "2024-03-27 09:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:32:39.726788"
    },
    {
      "arxiv_id": "2403.18397v2",
      "title": "Colour and Brush Stroke Pattern Recognition in Abstract Art using Modified Deep Convolutional Generative Adversarial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Srinitish Srinivasan",
        "Varenya Pathak",
        "Abirami S"
      ],
      "abstract": "Abstract Art is an immensely popular, discussed form of art that often has\nthe ability to depict the emotions of an artist. Many researchers have made\nattempts to study abstract art in the form of edge detection, brush stroke and\nemotion recognition algorithms using machine and deep learning. This papers\ndescribes the study of a wide distribution of abstract paintings using\nGenerative Adversarial Neural Networks(GAN). GANs have the ability to learn and\nreproduce a distribution enabling researchers and scientists to effectively\nexplore and study the generated image space. However, the challenge lies in\ndeveloping an efficient GAN architecture that overcomes common training\npitfalls. This paper addresses this challenge by introducing a modified-DCGAN\n(mDCGAN) specifically designed for high-quality artwork generation. The\napproach involves a thorough exploration of the modifications made, delving\ninto the intricate workings of DCGANs, optimisation techniques, and\nregularisation methods aimed at improving stability and realism in art\ngeneration enabling effective study of generated patterns. The proposed mDCGAN\nincorporates meticulous adjustments in layer configurations and architectural\nchoices, offering tailored solutions to the unique demands of art generation\nwhile effectively combating issues like mode collapse and gradient vanishing.\nFurther this paper explores the generated latent space by performing random\nwalks to understand vector relationships between brush strokes and colours in\nthe abstract art space and a statistical analysis of unstable outputs after a\ncertain period of GAN training and compare its significant difference. These\nfindings validate the effectiveness of the proposed approach, emphasising its\npotential to revolutionise the field of digital art generation and digital art\necosystem.",
      "tldr_zh": "本研究探讨了使用修改后的深度卷积生成对抗网络（modified-DCGAN, mDCGAN）来识别抽象艺术中的颜色和笔触模式，旨在学习和再现抽象画作的分布，以克服传统GAN训练中的模式崩溃和梯度消失等问题。研究通过优化层配置、正则化方法和架构调整，提高了艺术生成的稳定性和真实性，并通过潜在空间的随机游走分析了笔触与颜色的向量关系。实验结果显示，mDCGAN在生成高质量抽象艺术方面表现出色，并通过统计分析验证了其有效性，有望革新数字艺术生态系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication by Intelligent Decision Technologies 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18397v2",
      "published_date": "2024-03-27 09:35:56 UTC",
      "updated_date": "2024-12-05 18:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:32:50.632315"
    },
    {
      "arxiv_id": "2403.18388v1",
      "title": "FTBC: Forward Temporal Bias Correction for Optimizing ANN-SNN Conversion",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaofeng Wu",
        "Velibor Bojkovic",
        "Bin Gu",
        "Kun Suo",
        "Kai Zou"
      ],
      "abstract": "Spiking Neural Networks (SNNs) offer a promising avenue for energy-efficient\ncomputing compared with Artificial Neural Networks (ANNs), closely mirroring\nbiological neural processes. However, this potential comes with inherent\nchallenges in directly training SNNs through spatio-temporal backpropagation --\nstemming from the temporal dynamics of spiking neurons and their discrete\nsignal processing -- which necessitates alternative ways of training, most\nnotably through ANN-SNN conversion. In this work, we introduce a lightweight\nForward Temporal Bias Correction (FTBC) technique, aimed at enhancing\nconversion accuracy without the computational overhead. We ground our method on\nprovided theoretical findings that through proper temporal bias calibration the\nexpected error of ANN-SNN conversion can be reduced to be zero after each time\nstep. We further propose a heuristic algorithm for finding the temporal bias\nonly in the forward pass, thus eliminating the computational burden of\nbackpropagation and we evaluate our method on CIFAR-10/100 and ImageNet\ndatasets, achieving a notable increase in accuracy on all datasets. Codes are\nreleased at a GitHub repository.",
      "tldr_zh": "这篇论文提出了 Forward Temporal Bias Correction (FTBC) 技术，用于优化 Artificial Neural Networks (ANNs) 到 Spiking Neural Networks (SNNs) 的转换，以提升 SNNs 的能量效率和训练准确性。FTBC 通过在 forward pass 中应用一个启发式算法校准 temporal bias，根据理论分析将每个时间步的转换预期错误降为零，从而避免了 backpropagation 的计算负担。实验结果显示，该方法在 CIFAR-10/100 和 ImageNet 数据集上实现了显著的准确率提升，并开源了相关代码。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18388v1",
      "published_date": "2024-03-27 09:25:20 UTC",
      "updated_date": "2024-03-27 09:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:33:03.869781"
    },
    {
      "arxiv_id": "2403.18383v1",
      "title": "Generative Multi-modal Models are Good Class-Incremental Learners",
      "title_zh": "生成式多模态模型是优秀的类增量学习器",
      "authors": [
        "Xusheng Cao",
        "Haori Lu",
        "Linlan Huang",
        "Xialei Liu",
        "Ming-Ming Cheng"
      ],
      "abstract": "In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic\nforgetting caused by the classifier's bias towards the current task has long\nposed a significant challenge. It is mainly caused by the characteristic of\ndiscriminative models. With the growing popularity of the generative\nmulti-modal models, we would explore replacing discriminative models with\ngenerative ones for CIL. However, transitioning from discriminative to\ngenerative models requires addressing two key challenges. The primary challenge\nlies in transferring the generated textual information into the classification\nof distinct categories. Additionally, it requires formulating the task of CIL\nwithin a generative framework. To this end, we propose a novel generative\nmulti-modal model (GMM) framework for class-incremental learning. Our approach\ndirectly generates labels for images using an adapted generative model. After\nobtaining the detailed text, we use a text encoder to extract text features and\nemploy feature matching to determine the most similar label as the\nclassification prediction. In the conventional CIL settings, we achieve\nsignificantly better results in long-sequence task scenarios. Under the\nFew-shot CIL setting, we have improved by at least 14\\% accuracy over all the\ncurrent state-of-the-art methods with significantly less forgetting. Our code\nis available at \\url{https://github.com/DoubleClass/GMM}.",
      "tldr_zh": "本研究探讨了类增量学习（CIL）中灾难性遗忘的问题，并提出使用生成式多模态模型（GMM）取代传统判别模型，以缓解分类器偏置问题。研究方法包括直接为图像生成标签，然后通过文本编码器提取特征并进行特征匹配来预测分类，从而在生成框架中制定CIL任务。在实验中，该框架在传统CIL长序列任务中显著优于基线模型，并在Few-shot CIL设置中至少提升14%的准确率，同时大幅减少遗忘现象。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18383v1",
      "published_date": "2024-03-27 09:21:07 UTC",
      "updated_date": "2024-03-27 09:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:33:14.692515"
    },
    {
      "arxiv_id": "2403.18381v1",
      "title": "Improving Attributed Text Generation of Large Language Models via Preference Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dongfang Li",
        "Zetian Sun",
        "Baotian Hu",
        "Zhenyu Liu",
        "Xinshuo Hu",
        "Xuebo Liu",
        "Min Zhang"
      ],
      "abstract": "Large language models have been widely adopted in natural language\nprocessing, yet they face the challenge of generating unreliable content.\nRecent works aim to reduce misinformation and hallucinations by resorting to\nattribution as a means to provide evidence (i.e., citations). However, current\nattribution methods usually focus on the retrieval stage and automatic\nevaluation that neglect mirroring the citation mechanisms in human scholarly\nwriting to bolster credibility. In this paper, we address these challenges by\nmodelling the attribution task as preference learning and introducing an\nAutomatic Preference Optimization (APO) framework. First, we create a curated\ncollection for post-training with 6,330 examples by collecting and filtering\nfrom existing datasets. Second, considering the high cost of labelling\npreference data, we further propose an automatic method to synthesize\nattribution preference data resulting in 95,263 pairs. Moreover, inspired by\nthe human citation process, we further propose a progressive preference\noptimization method by leveraging fine-grained information. Extensive\nexperiments on three datasets (i.e., ASQA, StrategyQA, and ELI5) demonstrate\nthat APO achieves state-of-the-art citation F1 with higher answer quality.",
      "tldr_zh": "本研究针对大型语言模型在文本生成中存在的不可靠内容问题（如 misinformation 和 hallucinations），通过偏好学习（Preference Learning）来提升归因文本生成质量。作者提出 Automatic Preference Optimization (APO) 框架，包括创建一个精选的 6,330 个示例数据集、自动合成 95,263 对归因偏好数据，以及一种受人类引用机制启发的渐进式偏好优化方法。实验在 ASQA、StrategyQA 和 ELI5 数据集上显示，APO 框架实现了最先进的引用 F1 分数，同时显著提高了答案质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 15 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.18381v1",
      "published_date": "2024-03-27 09:19:13 UTC",
      "updated_date": "2024-03-27 09:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:33:27.421128"
    },
    {
      "arxiv_id": "2403.18379v1",
      "title": "IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining Useful Life Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Guangzai Ye",
        "Li Feng",
        "Jianlan Guo",
        "Yuqiang Chen"
      ],
      "abstract": "Accurately estimating the Remaining Useful Life (RUL) of lithium-ion\nbatteries is crucial for maintaining the safe and stable operation of\nrechargeable battery management systems. However, this task is often\nchallenging due to the complex temporal dynamics involved. Recently,\nattention-based networks, such as Transformers and Informer, have been the\npopular architecture in time series forecasting. Despite their effectiveness,\nthese models with abundant parameters necessitate substantial training time to\nunravel temporal patterns. To tackle these challenges, we propose a simple\nMLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which\nis an architecture based exclusively on multi-layer perceptrons (MLPs),\nextracting information by mixing operations along both intra-patch and\ninter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer\ncomprises parallel dual-head mixer layers: the intra-patch mixing MLP,\ncapturing local temporal patterns in the short-term period, and the inter-patch\nmixing MLP, capturing global temporal patterns in the long-term period.\nNotably, to address the varying importance of features in RUL prediction, we\nintroduce a weighted loss function in the MLP-Mixer-based architecture, marking\nthe first time such an approach has been employed. Our experiments demonstrate\nthat IIP-Mixer achieves competitive performance in battery RUL prediction,\noutperforming other popular time-series frameworks",
      "tldr_zh": "这篇论文针对锂离子电池剩余可用寿命 (RUL) 预测的挑战，提出了一种基于多层感知器 (MLPs) 的简单架构 IIP-Mixer，以解决复杂时序动态问题。IIP-Mixer 通过并行双头混合层——intra-patch mixing MLP 捕获短期局部时序模式，以及 inter-patch mixing MLP 捕获长期全局时序模式——来提取信息。论文首次在该架构中引入加权损失函数，以处理 RUL 预测中特征的重要性差异。实验结果表明，IIP-Mixer 在电池 RUL 预测任务中表现出色，优于 Transformers 和 Informer 等流行时序框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18379v1",
      "published_date": "2024-03-27 09:17:50 UTC",
      "updated_date": "2024-03-27 09:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:33:55.016708"
    },
    {
      "arxiv_id": "2403.18364v2",
      "title": "Intent-Aware DRL-Based NOMA Uplink Dynamic Scheduler for IIoT",
      "title_zh": "翻译失败",
      "authors": [
        "Salwa Mostafa",
        "Mateus P. Mota",
        "Alvaro Valcarce",
        "Mehdi Bennis"
      ],
      "abstract": "We investigate the problem of supporting Industrial Internet of Things user\nequipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and\nrandom traffic arrival. A deep reinforcement learning (DRL) based centralized\ndynamic scheduler for time-frequency resources is proposed to learn how to\nschedule the available communication resources among the IIoT UEs. The proposed\nscheduler leverages an RL framework to adapt to the dynamic changes in the\nwireless communication system and traffic arrivals. Moreover, a graph-based\nreduction scheme is proposed to reduce the state and action space of the RL\nframework to allow fast convergence and a better learning strategy. Simulation\nresults demonstrate the effectiveness of the proposed intelligent scheduler in\nguaranteeing the expressed intent of IIoT UEs compared to several traditional\nscheduling schemes, such as round-robin, semi-static, and heuristic approaches.\nThe proposed scheduler also outperforms the contention-free and\ncontention-based schemes in maximizing the number of successfully computed\ntasks.",
      "tldr_zh": "这篇论文针对工业物联网（IIoT）用户设备（IIoT UEs）的意图（即请求的 QoS）和随机流量到达问题，提出了一种基于深度强化学习（DRL）的 NOMA Uplink 动态调度器，用于时间-频率资源的集中式调度。该调度器利用 DRL 框架适应无线通信系统的动态变化，并引入 graph-based reduction scheme 来减少状态和动作空间，从而实现快速收敛和优化学习策略。模拟结果显示，该方法在保证 IIoT UEs 的意图方面比传统的 round-robin、semi-static 和 heuristic 方案更有效，并在最大化成功计算任务的数量上优于 contention-free 和 contention-based 方案。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "The simulation code for the paper is available on the following\n  GitHub repository\n  https://github.com/SalwaMostafa/Intent-Aware-DRL-Based-NOMA-Uplink-Dynamic-Scheduler-for-IIoT",
      "pdf_url": "http://arxiv.org/pdf/2403.18364v2",
      "published_date": "2024-03-27 08:57:15 UTC",
      "updated_date": "2025-01-05 09:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:33:56.816970"
    },
    {
      "arxiv_id": "2403.18351v1",
      "title": "Generating Diverse Agricultural Data for Vision-Based Farming Applications",
      "title_zh": "为基于视觉的农业应用生成多样农业数据",
      "authors": [
        "Mikolaj Cieslak",
        "Umabharathi Govindarajan",
        "Alejandro Garcia",
        "Anuradha Chandrashekar",
        "Torsten Hädrich",
        "Aleksander Mendoza-Drosik",
        "Dominik L. Michels",
        "Sören Pirk",
        "Chia-Chun Fu",
        "Wojciech Pałubicki"
      ],
      "abstract": "We present a specialized procedural model for generating synthetic\nagricultural scenes, focusing on soybean crops, along with various weeds. This\nmodel is capable of simulating distinct growth stages of these plants, diverse\nsoil conditions, and randomized field arrangements under varying lighting\nconditions. The integration of real-world textures and environmental factors\ninto the procedural generation process enhances the photorealism and\napplicability of the synthetic data. Our dataset includes 12,000 images with\nsemantic labels, offering a comprehensive resource for computer vision tasks in\nprecision agriculture, such as semantic segmentation for autonomous weed\ncontrol. We validate our model's effectiveness by comparing the synthetic data\nagainst real agricultural images, demonstrating its potential to significantly\naugment training data for machine learning models in agriculture. This approach\nnot only provides a cost-effective solution for generating high-quality,\ndiverse data but also addresses specific needs in agricultural vision tasks\nthat are not fully covered by general-purpose models.",
      "tldr_zh": "本文提出一个专门的procedural model，用于生成合成农业场景，聚焦于大豆作物和各种杂草，包括模拟不同生长阶段、多样土壤条件、随机田间排列以及变幻照明环境。模型通过整合真实纹理和环境因素，提升了合成数据的逼真性，并构建了一个包含12,000张带有语义标签的图像数据集，适用于精确农业中的计算机视觉任务，如semantic segmentation和自动杂草控制。实验结果显示，该合成数据与真实农业图像相比有效性显著，能够经济高效地增强机器学习模型的训练数据，填补了通用模型在农业视觉任务中的不足。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "68T07, 68T45",
        "I.2.10; I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.18351v1",
      "published_date": "2024-03-27 08:42:47 UTC",
      "updated_date": "2024-03-27 08:42:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:34:07.097126"
    },
    {
      "arxiv_id": "2403.18347v1",
      "title": "A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal Holes",
      "title_zh": "翻译失败",
      "authors": [
        "Sanmoy Bandyopadhyay",
        "Suman Kundu"
      ],
      "abstract": "The detection and analysis of the solar coronal holes (CHs) is an important\nfield of study in the domain of solar physics. Mainly, it is required for the\nproper prediction of the geomagnetic storms which directly or indirectly affect\nvarious space and ground-based systems. For the detection of CHs till date, the\nsolar scientist depends on manual hand-drawn approaches. However, with the\nadvancement of image processing technologies, some automated image segmentation\nmethods have been used for the detection of CHs. In-spite of this, fast and\naccurate detection of CHs are till a major issues. Here in this work, a novel\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\ndetection of the CHs region. The task has been carried out in two stages, in\nfirst stage the solar image has been segmented using a quantum computing based\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\nout from the segmented image based on image morphological operation. In the\nwork, quantum computing has been used to optimize the cost function of the fast\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\n(QAOA) has been used to optimize the quadratic part of the cost function. The\nproposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image\ndatasets and has been compared with the existing techniques. The outcome shows\nthe comparable performance of the proposed method with the existing one within\na very lesser time.",
      "tldr_zh": "本文提出了一种基于量子计算的快速模糊 C-Means (QCFFCM) 方法，用于实时检测太阳冕洞 (Solar Coronal Holes)，以提高地磁风暴预测的准确性和效率。方法分为两个阶段：首先利用 QCFFCM 算法分割太阳图像，其中 Quantum Approximate Optimization Algorithm (QAOA) 优化了成本函数的二次部分；随后通过图像形态学操作提取 CHs 区域。在 193 Å SDO/AIA 全盘太阳图像数据集上测试，该方法与现有技术性能相当，但检测时间显著缩短，实现了更快的实时应用。",
      "categories": [
        "astro-ph.SR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "14 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.18347v1",
      "published_date": "2024-03-27 08:38:56 UTC",
      "updated_date": "2024-03-27 08:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:34:18.945551"
    },
    {
      "arxiv_id": "2403.18344v2",
      "title": "LC-LLM: Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models",
      "title_zh": "LC-LLM：基于大语言模型的可解释变道意图和轨迹预测",
      "authors": [
        "Mingxing Peng",
        "Xusen Guo",
        "Xianda Chen",
        "Meixin Zhu",
        "Kehua Chen"
      ],
      "abstract": "To ensure safe driving in dynamic environments, autonomous vehicles should\npossess the capability to accurately predict lane change intentions of\nsurrounding vehicles in advance and forecast their future trajectories.\nExisting motion prediction approaches have ample room for improvement,\nparticularly in terms of long-term prediction accuracy and interpretability. In\nthis paper, we address these challenges by proposing LC-LLM, an explainable\nlane change prediction model that leverages the strong reasoning capabilities\nand self-explanation abilities of Large Language Models (LLMs). Essentially, we\nreformulate the lane change prediction task as a language modeling problem,\nprocessing heterogeneous driving scenario information as natural language\nprompts for LLMs and employing supervised fine-tuning to tailor LLMs\nspecifically for lane change prediction task. Additionally, we finetune the\nChain-of-Thought (CoT) reasoning to improve prediction transparency and\nreliability, and include explanatory requirements in the prompts during\ninference stage. Therefore, our LC-LLM model not only predicts lane change\nintentions and trajectories but also provides CoT reasoning and explanations\nfor its predictions, enhancing its interpretability. Extensive experiments\nbased on the large-scale highD dataset demonstrate the superior performance and\ninterpretability of our LC-LLM in lane change prediction task. To the best of\nour knowledge, this is the first attempt to utilize LLMs for predicting lane\nchange behavior. Our study shows that LLMs can effectively encode comprehensive\ninteraction information for driving behavior understanding.",
      "tldr_zh": "这篇论文提出 LC-LLM 模型，利用 Large Language Models (LLMs) 的强大推理能力来预测车辆的变道意图和轨迹，解决现有方法在长期预测准确性和可解释性方面的不足。核心方法是将变道预测任务转化为语言建模问题，通过处理异构驾驶场景信息作为自然语言提示，并结合监督微调和 Chain-of-Thought (CoT) 推理来提升预测的透明度和可靠性。实验结果显示，在 highD 数据集上，LC-LLM 表现出优越性能，并提供详细解释，这是首次将 LLMs 应用于变道行为预测，证明其能有效编码交互信息以理解驾驶行为。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.18344v2",
      "published_date": "2024-03-27 08:34:55 UTC",
      "updated_date": "2024-08-05 02:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:34:42.056564"
    },
    {
      "arxiv_id": "2403.18338v1",
      "title": "mALBERT: Is a Compact Multilingual BERT Model Still Worth It?",
      "title_zh": "翻译失败",
      "authors": [
        "Christophe Servan",
        "Sahar Ghannay",
        "Sophie Rosset"
      ],
      "abstract": "Within the current trend of Pretained Language Models (PLM), emerge more and\nmore criticisms about the ethical andecological impact of such models. In this\narticle, considering these critical remarks, we propose to focus on\nsmallermodels, such as compact models like ALBERT, which are more ecologically\nvirtuous than these PLM. However,PLMs enable huge breakthroughs in Natural\nLanguage Processing tasks, such as Spoken and Natural LanguageUnderstanding,\nclassification, Question--Answering tasks. PLMs also have the advantage of\nbeing multilingual, and,as far as we know, a multilingual version of compact\nALBERT models does not exist. Considering these facts, wepropose the free\nrelease of the first version of a multilingual compact ALBERT model,\npre-trained using Wikipediadata, which complies with the ethical aspect of such\na language model. We also evaluate the model against classicalmultilingual PLMs\nin classical NLP tasks. Finally, this paper proposes a rare study on the\nsubword tokenizationimpact on language performances.",
      "tldr_zh": "本研究针对预训练语言模型 (PLMs) 的伦理和生态问题，提出开发紧凑型多语言 ALBERT 模型（mALBERT），以实现更环保的 NLP 应用。作者使用 Wikipedia 数据预训练了第一个多语言版本的 ALBERT，并与经典多语言 PLMs 在分类和问答等任务中进行性能比较。结果显示，mALBERT 保持了良好的表现，同时还探讨了子词标记化对语言性能的影响，证明了紧凑模型在多语言场景中的潜在价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The 2024 Joint International Conference on Computational Linguistics,\n  Language Resources and Evaluation, May 2024, Torino, Italy",
      "pdf_url": "http://arxiv.org/pdf/2403.18338v1",
      "published_date": "2024-03-27 08:25:28 UTC",
      "updated_date": "2024-03-27 08:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:34:42.641866"
    },
    {
      "arxiv_id": "2403.18327v2",
      "title": "$\\forall$uto$\\exists$val: Autonomous Assessment of LLMs in Formal Synthesis and Interpretation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Rushang Karia",
        "Daniel Bramblett",
        "Daksh Dobhal",
        "Pulkit Verma",
        "Siddharth Srivastava"
      ],
      "abstract": "This paper presents $\\forall$uto$\\exists$val, a new approach for scaling LLM\nassessment in translating formal syntax -- such as first-order logic, regular\nexpressions, etc -- to natural language (interpretation) or vice versa\n(compilation), thereby facilitating their use in applications such as\ngenerating/explaining logic and control flow for programs etc. Existing\napproaches for LLM assessment in these areas require labor-intensive\nground-truth creation, the availability of which undermines the separation of\ntraining and test sets. Furthermore, such datasets typically include relatively\nfew hand-coded test cases over which LLM accuracy is determined, thus making\nthem inadequate for determining the safety or correctness of their generated\noutputs. We introduce a new approach that utilizes context-free grammars (CFGs)\nto generate out-of-distribution datasets on the fly and perform closed-loop\ntesting of LLM capabilities using formal verifiers to guarantee the correctness\nof LLM outputs without any human intervention. We release our dataset and\nbenchmark as open-source code at\n\\url{https://github.com/AAIR-lab/auto-llm-assessment}. We also conduct an\nassessment of several SOTA closed and open-source LLMs to showcase the\nfeasibility and scalability of this paradigm. Our experiments reveal that SOTA\nLLMs are unable to solve the formal translation task adequately.",
      "tldr_zh": "本论文提出了 $\\forall$uto$\\exists$val，一种自治评估方法，用于评估大型语言模型（LLMs）在形式语法（如一阶逻辑、正则表达式）与自然语言之间翻译任务（解释或编译）的性能，从而支持其在程序逻辑生成等应用中的使用。现有评估方法依赖于劳动密集型基准数据集创建，并存在测试案例不足的问题，该方法通过上下文无关文法（CFGs）动态生成分布外数据集，并结合形式验证器进行闭环测试，确保LLMs输出正确性而无需人工干预。实验评估了多个SOTA闭源和开源LLMs，结果显示这些模型在形式翻译任务上表现不佳，并开源了数据集和基准代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18327v2",
      "published_date": "2024-03-27 08:08:00 UTC",
      "updated_date": "2024-07-22 00:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:34:57.932568"
    },
    {
      "arxiv_id": "2403.18314v3",
      "title": "Chinese Offensive Language Detection:Current Status and Future Directions",
      "title_zh": "中文攻击性语言检测：当前状态和未来方向",
      "authors": [
        "Yunze Xiao",
        "Houda Bouamor",
        "Wajdi Zaghouani"
      ],
      "abstract": "Despite the considerable efforts being made to monitor and regulate\nuser-generated content on social media platforms, the pervasiveness of\noffensive language, such as hate speech or cyberbullying, in the digital space\nremains a significant challenge. Given the importance of maintaining a\ncivilized and respectful online environment, there is an urgent and growing\nneed for automatic systems capable of detecting offensive speech in real time.\nHowever, developing effective systems for processing languages such as Chinese\npresents a significant challenge, owing to the language's complex and nuanced\nnature, which makes it difficult to process automatically. This paper provides\na comprehensive overview of offensive language detection in Chinese, examining\ncurrent benchmarks and approaches and highlighting specific models and tools\nfor addressing the unique challenges of detecting offensive language in this\ncomplex language. The primary objective of this survey is to explore the\nexisting techniques and identify potential avenues for further research that\ncan address the cultural and linguistic complexities of Chinese.",
      "tldr_zh": "这篇论文对中文 offensive language detection 的现状和未来方向进行了全面综述，强调了社交媒体上攻击性语言的普遍性和实时检测的迫切需求。论文审视了现有基准、方法、模型和工具，突出了中文语言的复杂性（如细微差别和文化因素）带来的挑战。最终，它识别了现有技术的局限性，并提出了进一步研究的方向，以提升检测系统的准确性和适应性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18314v3",
      "published_date": "2024-03-27 07:34:44 UTC",
      "updated_date": "2024-03-29 18:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:35:07.471575"
    },
    {
      "arxiv_id": "2403.18310v1",
      "title": "A thermodynamically consistent physics-informed deep learning material model for short fiber/polymer nanocomposites",
      "title_zh": "翻译失败",
      "authors": [
        "Betim Bahtiri",
        "Behrouz Arash",
        "Sven Scheffler",
        "Maximilian Jux",
        "Raimund Rolfes"
      ],
      "abstract": "This work proposes a physics-informed deep learning (PIDL)-based constitutive\nmodel for investigating the viscoelastic-viscoplastic behavior of short\nfiber-reinforced nanoparticle-filled epoxies under various ambient conditions.\nThe deep-learning model is trained to enforce thermodynamic principles, leading\nto a thermodynamically consistent constitutive model. To accomplish this, a\nlong short-term memory network is combined with a feed-forward neural network\nto predict internal variables required for characterizing the internal\ndissipation of the nanocomposite materials. In addition, another feed-forward\nneural network is used to indicate the free-energy function, which enables\ndefining the thermodynamic state of the entire system. The PIDL model is\ninitially developed for the three-dimensional case by generating synthetic data\nfrom a classical constitutive model. The model is then trained by extracting\nthe data directly from cyclic loading-unloading experimental tests. Numerical\nexamples show that the PIDL model can accurately predict the mechanical\nbehavior of epoxy-based nanocomposites for different volume fractions of fibers\nand nanoparticles under various hygrothermal conditions.",
      "tldr_zh": "本研究提出了一种基于物理信息深度学习（PIDL）的本构模型，用于分析短纤维增强纳米粒子填充环氧树脂的粘弹性-粘塑性行为，并确保模型符合热力学原理。具体方法结合了长短时记忆网络（LSTM）和前馈神经网络，来预测材料的内部变量和自由能函数，并通过从经典模型生成的合成数据以及循环加载-卸载实验数据进行训练。结果显示，该PIDL模型能准确预测不同纤维和纳米粒子体积分数下，材料在各种湿热条件下的机械行为，展示了其在材料模拟中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2305.08102",
      "pdf_url": "http://arxiv.org/pdf/2403.18310v1",
      "published_date": "2024-03-27 07:22:32 UTC",
      "updated_date": "2024-03-27 07:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:35:18.780871"
    },
    {
      "arxiv_id": "2404.07223v3",
      "title": "Stock Recommendations for Individual Investors: A Temporal Graph Network Approach with Mean-Variance Efficient Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Youngbin Lee",
        "Yejin Kim",
        "Javier Sanz-Cruzado",
        "Richard McCreadie",
        "Yongjae Lee"
      ],
      "abstract": "Recommender systems can be helpful for individuals to make well-informed\ndecisions in complex financial markets. While many studies have focused on\npredicting stock prices, even advanced models fall short of accurately\nforecasting them. Additionally, previous studies indicate that individual\ninvestors often disregard established investment theories, favoring their\npersonal preferences instead. This presents a challenge for stock\nrecommendation systems, which must not only provide strong investment\nperformance but also respect these individual preferences. To create effective\nstock recommender systems, three critical elements must be incorporated: 1)\nindividual preferences, 2) portfolio diversification, and 3) the temporal\ndynamics of the first two. In response, we propose a new model, Portfolio\nTemporal Graph Network Recommender PfoTGNRec, which can handle time-varying\ncollaborative signals and incorporates diversification-enhancing sampling. On\nreal-world individual trading data, our approach demonstrates superior\nperformance compared to state-of-the-art baselines, including cutting-edge\ndynamic embedding models and existing stock recommendation models. Indeed, we\nshow that PfoTGNRec is an effective solution that can balance customer\npreferences with the need to suggest portfolios with high Return-on-Investment.\nThe source code and data are available at\nhttps://github.com/youngandbin/PfoTGNRec.",
      "tldr_zh": "本研究针对股票推荐系统的挑战，提出了一种新模型PfoTGNRec，用于为个人投资者提供个性化推荐。该模型整合Temporal Graph Network来处理时间动态的协作信号，并采用Mean-Variance Efficient Sampling增强投资组合多样化，同时考虑投资者偏好和投资理论。实验结果显示，PfoTGNRec在真实交易数据上优于现有基线模型，能有效平衡客户偏好与高投资回报率。源代码和数据可从指定仓库获取。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "ICAIF 2024 (https://dl.acm.org/doi/10.1145/3677052.3698662)",
      "pdf_url": "http://arxiv.org/pdf/2404.07223v3",
      "published_date": "2024-03-27 07:17:55 UTC",
      "updated_date": "2024-11-30 05:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:35:30.123589"
    },
    {
      "arxiv_id": "2404.00060v1",
      "title": "Temporal Graph Networks for Graph Anomaly Detection in Financial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yejin Kim",
        "Youngbin Lee",
        "Minyoung Choe",
        "Sungju Oh",
        "Yongjae Lee"
      ],
      "abstract": "This paper explores the utilization of Temporal Graph Networks (TGN) for\nfinancial anomaly detection, a pressing need in the era of fintech and\ndigitized financial transactions. We present a comprehensive framework that\nleverages TGN, capable of capturing dynamic changes in edges within financial\nnetworks, for fraud detection. Our study compares TGN's performance against\nstatic Graph Neural Network (GNN) baselines, as well as cutting-edge hypergraph\nneural network baselines using DGraph dataset for a realistic financial\ncontext. Our results demonstrate that TGN significantly outperforms other\nmodels in terms of AUC metrics. This superior performance underlines TGN's\npotential as an effective tool for detecting financial fraud, showcasing its\nability to adapt to the dynamic and complex nature of modern financial systems.\nWe also experimented with various graph embedding modules within the TGN\nframework and compared the effectiveness of each module. In conclusion, we\ndemonstrated that, even with variations within TGN, it is possible to achieve\ngood performance in the anomaly detection task.",
      "tldr_zh": "这篇论文探讨了使用 Temporal Graph Networks (TGN) 来检测金融网络中的异常行为，提出一个全面框架，利用 TGN 捕捉网络边动态变化以实现欺诈检测。研究将 TGN 与静态 Graph Neural Network (GNN) 基线以及超图神经网络基线进行比较，使用 DGraph 数据集进行实验。结果显示，TGN 在 AUC 指标上显著优于其他模型，证明其在适应复杂金融系统的动态特性方面更有效；此外，通过测试不同图嵌入模块，论文进一步验证了 TGN 在异常检测任务中的鲁棒性能。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "Presented at the AAAI 2024 Workshop on AI in Finance for Social\n  Impact (https://sites.google.com/view/aifin-aaai2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.00060v1",
      "published_date": "2024-03-27 07:17:16 UTC",
      "updated_date": "2024-03-27 07:17:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:35:46.637255"
    },
    {
      "arxiv_id": "2403.18305v2",
      "title": "A Recommender System for NFT Collectibles with Item Feature",
      "title_zh": "一种利用物品特征的 NFT 收藏品推荐系统",
      "authors": [
        "Minjoo Choi",
        "Seonmi Kim",
        "Yejin Kim",
        "Youngbin Lee",
        "Joohwan Hong",
        "Yongjae Lee"
      ],
      "abstract": "Recommender systems have been actively studied and applied in various domains\nto deal with information overload. Although there are numerous studies on\nrecommender systems for movies, music, and e-commerce, comparatively less\nattention has been paid to the recommender system for NFTs despite the\ncontinuous growth of the NFT market. This paper presents a recommender system\nfor NFTs that utilizes a variety of data sources, from NFT transaction records\nto external item features, to generate precise recommendations that cater to\nindividual preferences. We develop a data-efficient graph-based recommender\nsystem to efficiently capture the complex relationship between each item and\nusers and generate node(item) embeddings which incorporate both node feature\ninformation and graph structure. Furthermore, we exploit inputs beyond\nuser-item interactions, such as image feature, text feature, and price feature.\nNumerical experiments verify the performance of the graph-based recommender\nsystem improves significantly after utilizing all types of item features as\nside information, thereby outperforming all other baselines.",
      "tldr_zh": "这篇论文提出了一种针对 NFT 收藏品的 recommender system，利用 NFT 交易记录和外部物品特征（如图像、文本和价格特征）来生成个性化的精确推荐，以应对 NFT 市场的信息过载问题。研究开发了一个数据高效的 graph-based recommender system，通过捕捉用户与物品之间的复杂关系，并生成结合节点特征和图结构的嵌入，从而提升推荐准确性。实验结果显示，融入所有类型物品特征后，该系统显著优于其他基线模型，验证了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Presented at the AAAI 2023 Bridge on AI for Financial Services\n  (https://sites.google.com/view/aaai-ai-fin/home)",
      "pdf_url": "http://arxiv.org/pdf/2403.18305v2",
      "published_date": "2024-03-27 06:59:39 UTC",
      "updated_date": "2024-04-03 06:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:35:57.696298"
    },
    {
      "arxiv_id": "2403.18301v1",
      "title": "Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives",
      "title_zh": "选择性 Mixup 微调用于优化非可分解目标",
      "authors": [
        "Shrinivas Ramasubramanian",
        "Harsh Rangwani",
        "Sho Takemori",
        "Kunal Samanta",
        "Yuhei Umeda",
        "Venkatesh Babu Radhakrishnan"
      ],
      "abstract": "The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.",
      "tldr_zh": "该论文提出 SelMix，一种选择性 mixup 微调技术，旨在优化非可分解目标（如 worst-case recall 和公平性约束），以解决现有方法在实际场景下的 suboptimal 性能问题。核心方法涉及确定采样分布，在特定类别的样本之间进行特征 mixup，从而高效微调预训练模型。实验结果显示，SelMix 在不平衡分类基准数据集上显著提升了各种实用非可分解目标的性能，优于现有经验和理论方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 SpotLight",
      "pdf_url": "http://arxiv.org/pdf/2403.18301v1",
      "published_date": "2024-03-27 06:55:23 UTC",
      "updated_date": "2024-03-27 06:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:36:10.085793"
    },
    {
      "arxiv_id": "2403.18296v3",
      "title": "GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic Communication Paradigm",
      "title_zh": "GeNet：基于图神经网络的抗噪声任务导向语义通信范式",
      "authors": [
        "Chunhang Zheng",
        "Kechao Cai"
      ],
      "abstract": "Traditional approaches to semantic communication tasks rely on the knowledge\nof the signal-to-noise ratio (SNR) to mitigate channel noise. Moreover, these\nmethods necessitate training under specific SNR conditions, entailing\nconsiderable time and computational resources. In this paper, we propose GeNet,\na Graph Neural Network (GNN)-based paradigm for semantic communication aimed at\ncombating noise, thereby facilitating Task-Oriented Communication (TOC). We\npropose a novel approach where we first transform the input data image into\ngraph structures. Then we leverage a GNN-based encoder to extract semantic\ninformation from the source data. This extracted semantic information is then\ntransmitted through the channel. At the receiver's end, a GNN-based decoder is\nutilized to reconstruct the relevant semantic information from the source data\nfor TOC. Through experimental evaluation, we show GeNet's effectiveness in\nanti-noise TOC while decoupling the SNR dependency. We further evaluate GeNet's\nperformance by varying the number of nodes, revealing its versatility as a new\nparadigm for semantic communication. Additionally, we show GeNet's robustness\nto geometric transformations by testing it with different rotation angles,\nwithout resorting to data augmentation.",
      "tldr_zh": "本文提出 GeNet，一种基于 Graph Neural Network (GNN) 的抗噪声任务导向通信 (TOC) 范式，以解决传统语义通信方法对 Signal-to-Noise Ratio (SNR) 的依赖和训练资源的消耗问题。GeNet 通过将输入图像转换为图结构，使用 GNN 编码器提取并传输语义信息，接收端则采用 GNN 解码器重建相关语义数据。实验结果表明，GeNet 在抗噪声 TOC 中表现出色，不依赖 SNR，且对节点数量变化和几何变换（如旋转角度）具有鲁棒性，无需数据增强。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted as a conference paper to International Conference on\n  Computer Communications and Networks (ICCCN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.18296v3",
      "published_date": "2024-03-27 06:46:59 UTC",
      "updated_date": "2024-09-22 02:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:36:21.681223"
    },
    {
      "arxiv_id": "2403.18286v1",
      "title": "Few-Shot Recalibration of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Lisa Li",
        "Urvashi Khandelwal",
        "Kelvin Guu"
      ],
      "abstract": "Recent work has uncovered promising ways to extract well-calibrated\nconfidence estimates from language models (LMs), where the model's confidence\nscore reflects how likely it is to be correct. However, while LMs may appear\nwell-calibrated over broad distributions, this often hides significant\nmiscalibration within narrower slices (e.g., systemic over-confidence in math\ncan balance out systemic under-confidence in history, yielding perfect\ncalibration in aggregate). To attain well-calibrated confidence estimates for\nany slice of a distribution, we propose a new framework for few-shot\nslice-specific recalibration. Specifically, we train a recalibration model that\ntakes in a few unlabeled examples from any given slice and predicts a curve\nthat remaps confidence scores to be more accurate for that slice. Our trained\nmodel can recalibrate for arbitrary new slices, without using any labeled data\nfrom that slice. This enables us to identify domain-specific confidence\nthresholds above which the LM's predictions can be trusted, and below which it\nshould abstain. Experiments show that our few-shot recalibrator consistently\noutperforms existing calibration methods, for instance improving calibration\nerror for PaLM2-Large on MMLU by 16%, as compared to temperature scaling.",
      "tldr_zh": "该研究发现，虽然语言模型 (LMs) 在整体分布上可能表现出良好的校准，但特定子集（如数学或历史任务）常存在显著偏差。为解决此问题，研究提出一个 few-shot slice-specific recalibration 框架，通过训练一个重新校准模型，使用少量未标注示例来预测置信度曲线的映射，从而为任意新子集实现无标注数据的校准调整。该方法能帮助确定领域特定的置信度阈值，决定模型预测是否可信或应弃权；实验显示，它在 MMLU 数据集上使 PaLM2-Large 的 calibration error 改善 16%，优于温度缩放等现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2403.18286v1",
      "published_date": "2024-03-27 06:25:40 UTC",
      "updated_date": "2024-03-27 06:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:36:33.208868"
    },
    {
      "arxiv_id": "2403.18278v1",
      "title": "Identification and Uses of Deep Learning Backbones via Pattern Mining",
      "title_zh": "通过模式挖掘对深度学习骨干网络的识别与应用",
      "authors": [
        "Michael Livanos",
        "Ian Davidson"
      ],
      "abstract": "Deep learning is extensively used in many areas of data mining as a black-box\nmethod with impressive results. However, understanding the core mechanism of\nhow deep learning makes predictions is a relatively understudied problem. Here\nwe explore the notion of identifying a backbone of deep learning for a given\ngroup of instances. A group here can be instances of the same class or even\nmisclassified instances of the same class. We view each instance for a given\ngroup as activating a subset of neurons and attempt to find a subgraph of\nneurons associated with a given concept/group. We formulate this problem as a\nset cover style problem and show it is intractable and presents a highly\nconstrained integer linear programming (ILP) formulation. As an alternative, we\nexplore a coverage-based heuristic approach related to pattern mining, and show\nit converges to a Pareto equilibrium point of the ILP formulation.\nExperimentally we explore these backbones to identify mistakes and improve\nperformance, explanation, and visualization. We demonstrate application-based\nresults using several challenging data sets, including Bird Audio Detection\n(BAD) Challenge and Labeled Faces in the Wild (LFW), as well as the classic\nMNIST data.",
      "tldr_zh": "这篇论文探讨了通过模式挖掘识别深度学习backbones的方法，以揭示模型预测的核心机制，而不是将其视为黑盒。作者将问题表述为集合覆盖问题，证明其NP难解，并提出一个基于整数线性规划(ILP)的公式和一个覆盖启发式方法，该方法收敛到ILP的Pareto equilibrium点。实验结果显示，该方法在Bird Audio Detection(BAD) Challenge、Labeled Faces in the Wild(LFW)和MNIST等数据集上，能有效识别错误、提升性能、提供解释和可视化，从而改善深度学习的理解和应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, published SIAM SDM24",
      "pdf_url": "http://arxiv.org/pdf/2403.18278v1",
      "published_date": "2024-03-27 06:13:39 UTC",
      "updated_date": "2024-03-27 06:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:36:45.355916"
    },
    {
      "arxiv_id": "2403.18267v1",
      "title": "DSF-GAN: DownStream Feedback Generative Adversarial Network",
      "title_zh": "翻译失败",
      "authors": [
        "Oriel Perets",
        "Nadav Rappoport"
      ],
      "abstract": "Utility and privacy are two crucial measurements of the quality of synthetic\ntabular data. While significant advancements have been made in privacy\nmeasures, generating synthetic samples with high utility remains challenging.\nTo enhance the utility of synthetic samples, we propose a novel architecture\ncalled the DownStream Feedback Generative Adversarial Network (DSF-GAN). This\napproach incorporates feedback from a downstream prediction model during\ntraining to augment the generator's loss function with valuable information.\nThus, DSF-GAN utilizes a downstream prediction task to enhance the utility of\nsynthetic samples. To evaluate our method, we tested it using two popular\ndatasets. Our experiments demonstrate improved model performance when training\non synthetic samples generated by DSF-GAN, compared to those generated by the\nsame GAN architecture without feedback. The evaluation was conducted on the\nsame validation set comprising real samples. All code and datasets used in this\nresearch will be made openly available for ease of reproduction.",
      "tldr_zh": "本论文提出了一种名为 DSF-GAN 的新架构，即 DownStream Feedback Generative Adversarial Network，旨在提升合成表格数据的效用，同时兼顾隐私挑战。该方法通过从下游预测模型获取反馈，并将其整合到生成器的损失函数中，从而生成更高质量的合成样本。实验在两个流行数据集上进行，结果显示，使用 DSF-GAN 生成的样本训练模型比传统 GAN 架构表现出色，验证集上的性能得到改善；此外，所有代码和数据集将公开可用以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18267v1",
      "published_date": "2024-03-27 05:41:50 UTC",
      "updated_date": "2024-03-27 05:41:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:36:57.073004"
    },
    {
      "arxiv_id": "2403.18258v1",
      "title": "Enhancing Generative Class Incremental Learning Performance with Model Forgetting Approach",
      "title_zh": "通过模型遗忘方法提升生成",
      "authors": [
        "Taro Togo",
        "Ren Togo",
        "Keisuke Maeda",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "abstract": "This study presents a novel approach to Generative Class Incremental Learning\n(GCIL) by introducing the forgetting mechanism, aimed at dynamically managing\nclass information for better adaptation to streaming data. GCIL is one of the\nhot topics in the field of computer vision, and this is considered one of the\ncrucial tasks in society, specifically the continual learning of generative\nmodels. The ability to forget is a crucial brain function that facilitates\ncontinual learning by selectively discarding less relevant information for\nhumans. However, in the field of machine learning models, the concept of\nintentionally forgetting has not been extensively investigated. In this study\nwe aim to bridge this gap by incorporating the forgetting mechanisms into GCIL,\nthereby examining their impact on the models' ability to learn in continual\nlearning. Through our experiments, we have found that integrating the\nforgetting mechanisms significantly enhances the models' performance in\nacquiring new knowledge, underscoring the positive role that strategic\nforgetting plays in the process of continual learning.",
      "tldr_zh": "这篇论文提出了一种新方法，通过引入 forgetting mechanism 来提升 Generative Class Incremental Learning (GCIL) 的性能，旨在动态管理类信息以更好地适应流式数据。研究借鉴人类大脑的遗忘功能，将其整合到 GCIL 中，帮助模型在持续学习过程中选择性地丢弃不相关信息。实验结果表明，这种机制显著提高了模型在新知识获取方面的表现，强调了战略性遗忘在 continual learning 中的积极作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18258v1",
      "published_date": "2024-03-27 05:10:38 UTC",
      "updated_date": "2024-03-27 05:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:37:07.292120"
    },
    {
      "arxiv_id": "2403.18256v1",
      "title": "Manipulating Neural Path Planners via Slight Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Zikang Xiong",
        "Suresh Jagannathan"
      ],
      "abstract": "Data-driven neural path planners are attracting increasing interest in the\nrobotics community. However, their neural network components typically come as\nblack boxes, obscuring their underlying decision-making processes. Their\nblack-box nature exposes them to the risk of being compromised via the\ninsertion of hidden malicious behaviors. For example, an attacker may hide\nbehaviors that, when triggered, hijack a delivery robot by guiding it to a\nspecific (albeit wrong) destination, trapping it in a predefined region, or\ninducing unnecessary energy expenditure by causing the robot to repeatedly\ncircle a region. In this paper, we propose a novel approach to specify and\ninject a range of hidden malicious behaviors, known as backdoors, into neural\npath planners. Our approach provides a concise but flexible way to define these\nbehaviors, and we show that hidden behaviors can be triggered by slight\nperturbations (e.g., inserting a tiny unnoticeable object), that can\nnonetheless significantly compromise their integrity. We also discuss potential\ntechniques to identify these backdoors aimed at alleviating such risks. We\ndemonstrate our approach on both sampling-based and search-based neural path\nplanners.",
      "tldr_zh": "该论文探讨了数据驱动的神经路径规划器（neural path planners）的黑盒性质所带来的安全风险，攻击者可通过插入隐藏的恶意行为（backdoors）来操控机器人，例如引导其至错误目的地或导致不必要能量消耗。研究提出了一种新方法，用于指定和注入这些backdoors，使其通过轻微perturbations（如插入微小不可察觉的对象）触发，从而显著破坏规划器的完整性。该方法在基于采样的和基于搜索的神经路径规划器上进行了演示，并讨论了潜在的技术来识别和缓解这些风险，以提升系统的安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18256v1",
      "published_date": "2024-03-27 04:56:48 UTC",
      "updated_date": "2024-03-27 04:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:37:23.873094"
    },
    {
      "arxiv_id": "2403.18252v2",
      "title": "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning",
      "title_zh": "超越嵌入：Visual Table 在视觉推理中的前景",
      "authors": [
        "Yiwu Zhong",
        "Zi-Yuan Hu",
        "Michael R. Lyu",
        "Liwei Wang"
      ],
      "abstract": "Visual representation learning has been a cornerstone in computer vision,\ninvolving typical forms such as visual embeddings, structural symbols, and\ntext-based representations. Despite the success of CLIP-type visual embeddings,\nthey often lack access to world knowledge critical for visual reasoning. In\nthis work, we propose Visual Table, a novel form of visual representation\ntailored for visual reasoning. Visual tables are constructed as hierarchical\ndescriptions of visual scenes, featuring a scene description and multiple\nobject-centric descriptions covering categories, attributes, and knowledge.\nThanks to the structural and textual formats, visual tables offer unique\nadvantages over mere visual embeddings, such as interpretability and\ncontrollable editing. Furthermore, they deliver instance-level world knowledge\nand detailed attributes that are essential for visual reasoning. To create\nvisual tables, we develop a generator trained on the dataset with collected,\nsmall-scale annotations. Extensive results on 11 visual reasoning benchmarks\ndemonstrate that the generated visual tables significantly outperform previous\nstructural and text-based representations. Moreover, they consistently enhance\nstate-of-the-art multimodal large language models across diverse benchmarks,\nshowcasing their potential for advancing visual reasoning tasks. Our code is\navailable at https://github.com/LaVi-Lab/Visual-Table.",
      "tldr_zh": "本文提出 Visual Table，一种新型视觉表示形式，旨在解决传统 visual embeddings 如 CLIP 在视觉推理中缺乏世界知识的问题，通过构建层次化描述（包括场景描述和对象中心描述，如类别、属性及知识）来提升推理能力。相较于现有表示，Visual Table 提供可解释性、可控编辑以及实例级世界知识，使用小规模注释训练的生成器来创建它。在 11 个视觉推理基准测试中，Visual Table 显著优于之前的结构和文本表示，并增强了 state-of-the-art multimodal large language models 的性能，展示了其在视觉推理任务中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://github.com/LaVi-Lab/Visual-Table",
      "pdf_url": "http://arxiv.org/pdf/2403.18252v2",
      "published_date": "2024-03-27 04:49:23 UTC",
      "updated_date": "2024-06-17 09:57:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:37:33.946120"
    },
    {
      "arxiv_id": "2403.18243v1",
      "title": "Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check",
      "title_zh": "翻译失败",
      "authors": [
        "Linhao Ye",
        "Zhikai Lei",
        "Jianghao Yin",
        "Qin Chen",
        "Jie Zhou",
        "Liang He"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) aims to generate more reliable and\naccurate responses, by augmenting large language models (LLMs) with the\nexternal vast and dynamic knowledge. Most previous work focuses on using RAG\nfor single-round question answering, while how to adapt RAG to the complex\nconversational setting wherein the question is interdependent on the preceding\ncontext is not well studied. In this paper, we propose a conversation-level RAG\napproach, which incorporates fine-grained retrieval augmentation and self-check\nfor conversational question answering (CQA). In particular, our approach\nconsists of three components, namely conversational question refiner,\nfine-grained retriever and self-check based response generator, which work\ncollaboratively for question understanding and relevant information acquisition\nin conversational settings. Extensive experiments demonstrate the great\nadvantages of our approach over the state-of-the-art baselines. Moreover, we\nalso release a Chinese CQA dataset with new features including reformulated\nquestion, extracted keyword, retrieved paragraphs and their helpfulness, which\nfacilitates further researches in RAG enhanced CQA.",
      "tldr_zh": "本文提出了一种增强对话式问答(CQA)的Retrieval-Augmented Generation (RAG)方法，通过细粒度检索增强和自检机制来处理对话场景中问题间的相互依赖性。方法包括三个关键组件：conversational question refiner 用于问题精炼、fine-grained retriever 用于相关信息检索，以及self-check based response generator 用于生成可靠响应，这些组件协作提升LLMs的准确性和可靠性。实验结果显示，该方法显著优于现有基线；此外，论文还发布了一个新的中文CQA数据集，包含重述的问题、提取的关键字、检索段落及其有用性，以促进RAG在CQA领域的进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18243v1",
      "published_date": "2024-03-27 04:20:18 UTC",
      "updated_date": "2024-03-27 04:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:37:49.511281"
    },
    {
      "arxiv_id": "2403.18241v2",
      "title": "NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion, Reconstruction, and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruikai Cui",
        "Weizhe Liu",
        "Weixuan Sun",
        "Senbo Wang",
        "Taizhang Shang",
        "Yang Li",
        "Xibin Song",
        "Han Yan",
        "Zhennan Wu",
        "Shenzhou Chen",
        "Hongdong Li",
        "Pan Ji"
      ],
      "abstract": "3D shape generation aims to produce innovative 3D content adhering to\nspecific conditions and constraints. Existing methods often decompose 3D shapes\ninto a sequence of localized components, treating each element in isolation\nwithout considering spatial consistency. As a result, these approaches exhibit\nlimited versatility in 3D data representation and shape generation, hindering\ntheir ability to generate highly diverse 3D shapes that comply with the\nspecified constraints. In this paper, we introduce a novel spatial-aware 3D\nshape generation framework that leverages 2D plane representations for enhanced\n3D shape modeling. To ensure spatial coherence and reduce memory usage, we\nincorporate a hybrid shape representation technique that directly learns a\ncontinuous signed distance field representation of the 3D shape using\northogonal 2D planes. Additionally, we meticulously enforce spatial\ncorrespondences across distinct planes using a transformer-based autoencoder\nstructure, promoting the preservation of spatial relationships in the generated\n3D shapes. This yields an algorithm that consistently outperforms\nstate-of-the-art 3D shape generation methods on various tasks, including\nunconditional shape generation, multi-modal shape completion, single-view\nreconstruction, and text-to-shape synthesis. Our project page is available at\nhttps://weizheliu.github.io/NeuSDFusion/ .",
      "tldr_zh": "本研究提出NeuSDFusion，一种空间感知生成模型，针对现有3D形状生成方法忽略空间一致性导致多样性不足的问题，通过利用2D平面表示和混合形状表示技术，直接学习3D形状的连续signed distance field。框架中，基于Transformer的自编码器结构强制执行不同平面之间的空间对应，确保生成的3D形状保持空间关系完整。该模型在无条件形状生成、多模态形状完成、单视图重建和文本到形状合成等任务上，显著超越了最先进方法，提供更高效的3D内容生成能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024, project page: https://weizheliu.github.io/NeuSDFusion/",
      "pdf_url": "http://arxiv.org/pdf/2403.18241v2",
      "published_date": "2024-03-27 04:09:34 UTC",
      "updated_date": "2024-07-12 07:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:38:01.156800"
    },
    {
      "arxiv_id": "2403.18230v1",
      "title": "Large Language Models Need Consultants for Reasoning: Becoming an Expert in a Complex Human System Through Behavior Simulation",
      "title_zh": "大语言模型需要顾问来进行推理：通过行为模拟成为复杂人类系统中的专家",
      "authors": [
        "Chuwen Wang",
        "Shirong Zeng",
        "Cheng Wang"
      ],
      "abstract": "Large language models (LLMs), in conjunction with various reasoning\nreinforcement methodologies, have demonstrated remarkable capabilities\ncomparable to humans in fields such as mathematics, law, coding, common sense,\nand world knowledge. In this paper, we delve into the reasoning abilities of\nLLMs within complex human systems. We propose a novel reasoning framework,\ntermed ``Mosaic Expert Observation Wall'' (MEOW) exploiting\ngenerative-agents-based simulation technique. In the MEOW framework, simulated\ndata are utilized to train an expert model concentrating ``experience'' about a\nspecific task in each independent time of simulation. It is the accumulated\n``experience'' through the simulation that makes for an expert on a task in a\ncomplex human system. We conduct the experiments within a communication game\nthat mirrors real-world security scenarios. The results indicate that our\nproposed methodology can cooperate with existing methodologies to enhance the\nreasoning abilities of LLMs in complex human systems.",
      "tldr_zh": "本文探讨大型语言模型(LLMs)在复杂人类系统中的推理能力，提出了一种名为“Mosaic Expert Observation Wall”(MEOW)框架，利用generative-agents-based simulation技术模拟数据并积累经验，以训练专家模型。MEOW框架允许LLMs通过多次模拟过程专注于特定任务，从而提升其在复杂系统中的推理表现。在模拟的通信游戏实验中，结果表明该方法能与现有技术合作，提高LLMs的推理准确性和整体效能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18230v1",
      "published_date": "2024-03-27 03:33:32 UTC",
      "updated_date": "2024-03-27 03:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:38:11.947894"
    },
    {
      "arxiv_id": "2403.18223v1",
      "title": "A Transformer-Based Framework for Payload Malware Detection and Classification",
      "title_zh": "基于 Transformer 的有效载荷恶意软件检测和分类框架",
      "authors": [
        "Kyle Stein",
        "Arash Mahyari",
        "Guillermo Francia III",
        "Eman El-Sheikh"
      ],
      "abstract": "As malicious cyber threats become more sophisticated in breaching computer\nnetworks, the need for effective intrusion detection systems (IDSs) becomes\ncrucial. Techniques such as Deep Packet Inspection (DPI) have been introduced\nto allow IDSs analyze the content of network packets, providing more context\nfor identifying potential threats. IDSs traditionally rely on using\nanomaly-based and signature-based detection techniques to detect unrecognized\nand suspicious activity. Deep learning techniques have shown great potential in\nDPI for IDSs due to their efficiency in learning intricate patterns from the\npacket content being transmitted through the network. In this paper, we propose\na revolutionary DPI algorithm based on transformers adapted for the purpose of\ndetecting malicious traffic with a classifier head. Transformers learn the\ncomplex content of sequence data and generalize them well to similar scenarios\nthanks to their self-attention mechanism. Our proposed method uses the raw\npayload bytes that represent the packet contents and is deployed as\nman-in-the-middle. The payload bytes are used to detect malicious packets and\nclassify their types. Experimental results on the UNSW-NB15 and CIC-IOT23\ndatasets demonstrate that our transformer-based model is effective in\ndistinguishing malicious from benign traffic in the test dataset, attaining an\naverage accuracy of 79\\% using binary classification and 72\\% on the\nmulti-classification experiment, both using solely payload bytes.",
      "tldr_zh": "该论文提出了一种基于 Transformer 的框架，用于检测和分类网络包的恶意负载（payload），以提升入侵检测系统（IDS）的效能。该框架利用 Transformer 的自注意力机制，从原始负载字节中学习复杂的模式，并作为 man-in-the-middle 部署，实现恶意流量识别和类型分类。与传统基于异常或签名的检测方法不同，该方法专注于深度包检查（DPI），并在 UNSW-NB15 和 CIC-IOT23 数据集上测试。实验结果显示，该模型在二分类任务中达到 79% 的准确率，在多分类任务中达到 72%，证明了其在仅使用负载字节时的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18223v1",
      "published_date": "2024-03-27 03:25:45 UTC",
      "updated_date": "2024-03-27 03:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:38:23.576771"
    },
    {
      "arxiv_id": "2403.18219v1",
      "title": "From Two-Dimensional to Three-Dimensional Environment with Q-Learning: Modeling Autonomous Navigation with Reinforcement Learning and no Libraries",
      "title_zh": "翻译失败",
      "authors": [
        "Ergon Cugler de Moraes Silva"
      ],
      "abstract": "Reinforcement learning (RL) algorithms have become indispensable tools in\nartificial intelligence, empowering agents to acquire optimal decision-making\npolicies through interactions with their environment and feedback mechanisms.\nThis study explores the performance of RL agents in both two-dimensional (2D)\nand three-dimensional (3D) environments, aiming to research the dynamics of\nlearning across different spatial dimensions. A key aspect of this\ninvestigation is the absence of pre-made libraries for learning, with the\nalgorithm developed exclusively through computational mathematics. The\nmethodological framework centers on RL principles, employing a Q-learning agent\nclass and distinct environment classes tailored to each spatial dimension. The\nresearch aims to address the question: How do reinforcement learning agents\nadapt and perform in environments of varying spatial dimensions, particularly\nin 2D and 3D settings? Through empirical analysis, the study evaluates agents'\nlearning trajectories and adaptation processes, revealing insights into the\nefficacy of RL algorithms in navigating complex, multi-dimensional spaces.\nReflections on the findings prompt considerations for future research,\nparticularly in understanding the dynamics of learning in higher-dimensional\nenvironments.",
      "tldr_zh": "这篇论文探讨了强化学习（RL）代理在二维（2D）和三维（3D）环境中的性能，使用自定义 Q-Learning 算法实现自主导航，而非依赖预制库，通过计算数学构建代理和环境类。研究重点评估代理的学习轨迹和适应过程，揭示了 RL 在不同空间维度中的动态表现。结果显示，代理在复杂多维空间中表现出色，并为未来探索更高维度环境的学习机制提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18219v1",
      "published_date": "2024-03-27 03:07:18 UTC",
      "updated_date": "2024-03-27 03:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:38:36.173744"
    },
    {
      "arxiv_id": "2403.18218v1",
      "title": "Leveraging Large Language Models for Fuzzy String Matching in Political Science",
      "title_zh": "利用大语言模型进行政治科学中的模糊字符串匹配",
      "authors": [
        "Yu Wang"
      ],
      "abstract": "Fuzzy string matching remains a key issue when political scientists combine\ndata from different sources. Existing matching methods invariably rely on\nstring distances, such as Levenshtein distance and cosine similarity. As such,\nthey are inherently incapable of matching strings that refer to the same entity\nwith different names such as ''JP Morgan'' and ''Chase Bank'', ''DPRK'' and\n''North Korea'', ''Chuck Fleischmann (R)'' and ''Charles Fleischmann (R)''. In\nthis letter, we propose to use large language models to entirely sidestep this\nproblem in an easy and intuitive manner. Extensive experiments show that our\nproposed methods can improve the state of the art by as much as 39% in terms of\naverage precision while being substantially easier and more intuitive to use by\npolitical scientists. Moreover, our results are robust against various\ntemperatures. We further note that enhanced prompting can lead to additional\nperformance improvements.",
      "tldr_zh": "政治科学领域中，模糊字符串匹配是合并不同数据源的关键挑战，但现有方法如Levenshtein distance和cosine similarity往往无法处理指代同一实体的不同名称，例如“JP Morgan”和“Chase Bank”。本研究提出利用Large Language Models (LLMs)来绕过这一问题，提供一种简单直观的方法。实验结果显示，该方法在平均 precision上比现有技术提升高达39%，且对各种temperatures参数具有稳健性；此外，通过增强prompting可以进一步改善性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 figures, 1 table;",
      "pdf_url": "http://arxiv.org/pdf/2403.18218v1",
      "published_date": "2024-03-27 03:04:21 UTC",
      "updated_date": "2024-03-27 03:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:38:47.598704"
    },
    {
      "arxiv_id": "2403.18212v2",
      "title": "Preference-Based Planning in Stochastic Environments: From Partially-Ordered Temporal Goals to Most Preferred Policies",
      "title_zh": "基于偏好的规划在随机环境：从部分有序的时序目标到最优偏好策略",
      "authors": [
        "Hazhar Rahmani",
        "Abhishek N. Kulkarni",
        "Jie Fu"
      ],
      "abstract": "Human preferences are not always represented via complete linear orders: It\nis natural to employ partially-ordered preferences for expressing incomparable\noutcomes. In this work, we consider decision-making and probabilistic planning\nin stochastic systems modeled as Markov decision processes (MDPs), given a\npartially ordered preference over a set of temporally extended goals.\nSpecifically, each temporally extended goal is expressed using a formula in\nLinear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially\nordered preference, we introduce order theory to map a preference over temporal\ngoals to a preference over policies for the MDP. Accordingly, a most preferred\npolicy under a stochastic ordering induces a stochastic nondominated\nprobability distribution over the finite paths in the MDP. To synthesize a most\npreferred policy, our technical approach includes two key steps. In the first\nstep, we develop a procedure to transform a partially ordered preference over\ntemporal goals into a computational model, called preference automaton, which\nis a semi-automaton with a partial order over acceptance conditions. In the\nsecond step, we prove that finding a most preferred policy is equivalent to\ncomputing a Pareto-optimal policy in a multi-objective MDP that is constructed\nfrom the original MDP, the preference automaton, and the chosen stochastic\nordering relation. Throughout the paper, we employ running examples to\nillustrate the proposed preference specification and solution approaches. We\ndemonstrate the efficacy of our algorithm using these examples, providing\ndetailed analysis, and then discuss several potential future directions.",
      "tldr_zh": "本研究探讨了在随机环境中基于部分有序偏好（partially-ordered preferences）的决策和概率规划问题，使用Markov decision processes (MDPs)作为模型，并将时间扩展目标以Linear Temporal Logic on Finite Traces (LTL_f)公式表示。作者引入顺序理论，将部分有序偏好映射到MDPs的策略偏好，从而定义最优策略，该策略产生一个随机非主导概率分布。关键方法包括构建偏好自动机（preference automaton）来表示偏好，以及证明合成最优策略等价于在多目标MDP中计算Pareto-optimal policy。实验通过示例验证了算法的有效性，并分析了潜在未来方向，如扩展到更复杂系统。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL",
        "cs.LO"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2209.12267",
      "pdf_url": "http://arxiv.org/pdf/2403.18212v2",
      "published_date": "2024-03-27 02:46:09 UTC",
      "updated_date": "2024-10-18 03:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:39:01.156923"
    },
    {
      "arxiv_id": "2403.18209v2",
      "title": "Long and Short-Term Constraints Driven Safe Reinforcement Learning for Autonomous Driving",
      "title_zh": "基于长短期约束驱动的安全强化学习用于自动驾驶",
      "authors": [
        "Xuemin Hu",
        "Pan Chen",
        "Yijun Wen",
        "Bo Tang",
        "Long Chen"
      ],
      "abstract": "Reinforcement learning (RL) has been widely used in decision-making and\ncontrol tasks, but the risk is very high for the agent in the training process\ndue to the requirements of interaction with the environment, which seriously\nlimits its industrial applications such as autonomous driving systems. Safe RL\nmethods are developed to handle this issue by constraining the expected safety\nviolation costs as a training objective, but the occurring probability of an\nunsafe state is still high, which is unacceptable in autonomous driving tasks.\nMoreover, these methods are difficult to achieve a balance between the cost and\nreturn expectations, which leads to learning performance degradation for the\nalgorithms. In this paper, we propose a novel algorithm based on the long and\nshort-term constraints (LSTC) for safe RL. The short-term constraint aims to\nenhance the short-term state safety that the vehicle explores, while the\nlong-term constraint enhances the overall safety of the vehicle throughout the\ndecision-making process, both of which are jointly used to enhance the vehicle\nsafety in the training process. In addition, we develop a safe RL method with\ndual-constraint optimization based on the Lagrange multiplier to optimize the\ntraining process for end-to-end autonomous driving. Comprehensive experiments\nwere conducted on the MetaDrive simulator. Experimental results demonstrate\nthat the proposed method achieves higher safety in continuous state and action\ntasks, and exhibits higher exploration performance in long-distance\ndecision-making tasks compared with state-of-the-art methods.",
      "tldr_zh": "这篇论文针对强化学习（RL）在自主驾驶中的训练风险问题，提出了一种基于长短期约束（LSTC）的安全强化学习算法，以降低不安全状态的发生概率并平衡成本与回报。算法通过短期约束增强车辆探索的即时状态安全，长期约束优化整个决策过程的整体安全，并采用基于拉格朗日乘子的双约束优化方法进行端到端训练。在 MetaDrive 模拟器上的实验结果显示，该方法在连续状态和动作任务中实现了更高的安全性和探索性能，比现有最先进方法表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18209v2",
      "published_date": "2024-03-27 02:41:52 UTC",
      "updated_date": "2024-09-12 12:59:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:39:13.521229"
    },
    {
      "arxiv_id": "2403.18208v1",
      "title": "An Evolutionary Network Architecture Search Framework with Adaptive Multimodal Fusion for Hand Gesture Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhang Xia",
        "Shihao Song",
        "Zhanglu Hou",
        "Junwen Xu",
        "Juan Zou",
        "Yuan Liu",
        "Shengxiang Yang"
      ],
      "abstract": "Hand gesture recognition (HGR) based on multimodal data has attracted\nconsiderable attention owing to its great potential in applications. Various\nmanually designed multimodal deep networks have performed well in multimodal\nHGR (MHGR), but most of existing algorithms require a lot of expert experience\nand time-consuming manual trials. To address these issues, we propose an\nevolutionary network architecture search framework with the adaptive multimodel\nfusion (AMF-ENAS). Specifically, we design an encoding space that\nsimultaneously considers fusion positions and ratios of the multimodal data,\nallowing for the automatic construction of multimodal networks with different\narchitectures through decoding. Additionally, we consider three input streams\ncorresponding to intra-modal surface electromyography (sEMG), intra-modal\naccelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to\nvarious datasets, the ENAS framework is designed to automatically search a MHGR\nnetwork with appropriate fusion positions and ratios. To the best of our\nknowledge, this is the first time that ENAS has been utilized in MHGR to tackle\nissues related to the fusion position and ratio of multimodal data.\nExperimental results demonstrate that AMF-ENAS achieves state-of-the-art\nperformance on the Ninapro DB2, DB3, and DB7 datasets.",
      "tldr_zh": "本文提出了一种进化网络架构搜索框架（AMF-ENAS），旨在解决多模态手势识别（MHGR）中手动设计网络依赖专家经验和耗时问题。该框架设计了编码空间，自动处理多模态数据的融合位置和比例，包括内部模态的表面肌电图（sEMG）、加速度计（ACC）以及跨模态的 sEMG-ACC 输入流，从而实现对不同数据集的自动适应。AMF-ENAS 首次将进化网络架构搜索（ENAS）应用于 MHGR，显著提高了网络构建效率。实验结果表明，该方法在 Ninapro DB2、DB3 和 DB7 数据集上达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18208v1",
      "published_date": "2024-03-27 02:39:23 UTC",
      "updated_date": "2024-03-27 02:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:39:26.787893"
    },
    {
      "arxiv_id": "2403.18205v1",
      "title": "Exploring the Privacy Protection Capabilities of Chinese Large Language Models",
      "title_zh": "探索中文大型语言模型的隐私保护能力",
      "authors": [
        "Yuqi Yang",
        "Xiaowen Huang",
        "Jitao Sang"
      ],
      "abstract": "Large language models (LLMs), renowned for their impressive capabilities in\nvarious tasks, have significantly advanced artificial intelligence. Yet, these\nadvancements have raised growing concerns about privacy and security\nimplications. To address these issues and explain the risks inherent in these\nmodels, we have devised a three-tiered progressive framework tailored for\nevaluating privacy in language systems. This framework consists of\nprogressively complex and in-depth privacy test tasks at each tier. Our primary\nobjective is to comprehensively evaluate the sensitivity of large language\nmodels to private information, examining how effectively they discern, manage,\nand safeguard sensitive data in diverse scenarios. This systematic evaluation\nhelps us understand the degree to which these models comply with privacy\nprotection guidelines and the effectiveness of their inherent safeguards\nagainst privacy breaches. Our observations indicate that existing Chinese large\nlanguage models universally show privacy protection shortcomings. It seems that\nat the moment this widespread issue is unavoidable and may pose corresponding\nprivacy risks in applications based on these models.",
      "tldr_zh": "这篇论文探讨了中文大型语言模型(LLMs)的隐私保护能力，针对模型在处理敏感数据时可能带来的风险，提出一个三层级渐进框架进行系统评估。该框架通过逐层复杂的隐私测试任务，考察模型对私人信息的敏感性、管理和保护水平。研究发现，现有的中文LLMs普遍存在隐私保护缺陷，这种问题难以避免，可能在基于这些模型的应用中引发潜在风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.18205v1",
      "published_date": "2024-03-27 02:31:54 UTC",
      "updated_date": "2024-03-27 02:31:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:39:35.581460"
    },
    {
      "arxiv_id": "2403.18203v1",
      "title": "EndToEndML: An Open-Source End-to-End Pipeline for Machine Learning Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Nisha Pillai",
        "Athish Ram Das",
        "Moses Ayoola",
        "Ganga Gireesan",
        "Bindu Nanduri",
        "Mahalingam Ramkumar"
      ],
      "abstract": "Artificial intelligence (AI) techniques are widely applied in the life\nsciences. However, applying innovative AI techniques to understand and\ndeconvolute biological complexity is hindered by the learning curve for life\nscience scientists to understand and use computing languages. An open-source,\nuser-friendly interface for AI models, that does not require programming skills\nto analyze complex biological data will be extremely valuable to the\nbioinformatics community. With easy access to different sequencing technologies\nand increased interest in different 'omics' studies, the number of biological\ndatasets being generated has increased and analyzing these high-throughput\ndatasets is computationally demanding. The majority of AI libraries today\nrequire advanced programming skills as well as machine learning, data\npreprocessing, and visualization skills. In this research, we propose a\nweb-based end-to-end pipeline that is capable of preprocessing, training,\nevaluating, and visualizing machine learning (ML) models without manual\nintervention or coding expertise. By integrating traditional machine learning\nand deep neural network models with visualizations, our library assists in\nrecognizing, classifying, clustering, and predicting a wide range of\nmulti-modal, multi-sensor datasets, including images, languages, and\none-dimensional numerical data, for drug discovery, pathogen classification,\nand medical diagnostics.",
      "tldr_zh": "本研究提出 EndToEndML，一个开源的端到端机器学习管道，旨在解决生命科学领域科学家在应用AI技术时面临的编程技能门槛问题。该管道提供一个基于Web的用户友好界面，能够自动处理数据预处理、模型训练、评估和可视化，而无需手动干预或编码知识。它整合了传统机器学习和深度神经网络模型，支持对多模态数据集（如图像、语言和一维数值数据）的识别、分类、聚类和预测，适用于药物发现、病原体分类以及医疗诊断等领域。实验表明，该工具能高效分析高通量生物数据集，提升AI在生物信息学中的可访问性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2024 7th International Conference on Information and Computer\n  Technologies (ICICT)",
      "pdf_url": "http://arxiv.org/pdf/2403.18203v1",
      "published_date": "2024-03-27 02:24:38 UTC",
      "updated_date": "2024-03-27 02:24:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:39:50.216990"
    },
    {
      "arxiv_id": "2403.18196v1",
      "title": "Looking Beyond What You See: An Empirical Analysis on Subgroup Intersectional Fairness for Multi-label Chest X-ray Classification Using Social Determinants of Racial Health Inequities",
      "title_zh": "翻译失败",
      "authors": [
        "Dana Moukheiber",
        "Saurabh Mahindre",
        "Lama Moukheiber",
        "Mira Moukheiber",
        "Mingchen Gao"
      ],
      "abstract": "There has been significant progress in implementing deep learning models in\ndisease diagnosis using chest X- rays. Despite these advancements, inherent\nbiases in these models can lead to disparities in prediction accuracy across\nprotected groups. In this study, we propose a framework to achieve accurate\ndiagnostic outcomes and ensure fairness across intersectional groups in\nhigh-dimensional chest X- ray multi-label classification. Transcending\ntraditional protected attributes, we consider complex interactions within\nsocial determinants, enabling a more granular benchmark and evaluation of\nfairness. We present a simple and robust method that involves retraining the\nlast classification layer of pre-trained models using a balanced dataset across\ngroups. Additionally, we account for fairness constraints and integrate\nclass-balanced fine-tuning for multi-label settings. The evaluation of our\nmethod on the MIMIC-CXR dataset demonstrates that our framework achieves an\noptimal tradeoff between accuracy and fairness compared to baseline methods.",
      "tldr_zh": "本研究通过实证分析探讨了在多标签胸X光分类中，模型偏见如何导致交叉子群体（subgroup intersectional fairness）的不公平问题，特别是结合社会决定因素（social determinants of racial health inequities）。他们提出一个框架，使用平衡数据集重新训练预训练模型的最后分类层，并整合公平约束（fairness constraints）和类平衡微调（class-balanced fine-tuning），以实现更细粒度的公平评估。实验结果显示，在MIMIC-CXR数据集上，该框架在准确性和公平性之间实现了最佳权衡，优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "ICCV CVAMD 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.18196v1",
      "published_date": "2024-03-27 02:13:20 UTC",
      "updated_date": "2024-03-27 02:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:40:02.129123"
    },
    {
      "arxiv_id": "2403.18195v3",
      "title": "SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Wan",
        "Kaichen Zhou",
        "jinhong Chen",
        "Hao Dong"
      ],
      "abstract": "Autonomous assembly in robotics and 3D vision presents significant\nchallenges, particularly in ensuring assembly correctness. Presently,\npredominant methods such as MEPNet focus on assembling components based on\nmanually provided images. However, these approaches often fall short in\nachieving satisfactory results for tasks requiring long-term planning.\nConcurrently, we observe that integrating a self-correction module can\npartially alleviate such issues. Motivated by this concern, we introduce the\nSingle-Step Assembly Error Correction Task, which involves identifying and\nrectifying misassembled components. To support research in this area, we\npresent the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising\nmanual images for assembly steps and instances of assembly failures.\nAdditionally, we propose the Self-Correct Assembly Network (SCANet), a novel\nmethod to address this task. SCANet treats assembled components as queries,\ndetermining their correctness in manual images and providing corrections when\nnecessary. Finally, we utilize SCANet to correct the assembly results of\nMEPNet. Experimental results demonstrate that SCANet can identify and correct\nMEPNet's misassembled results, significantly improving the correctness of\nassembly. Our code and dataset could be found at\nhttps://scanet-iros2024.github.io/.",
      "tldr_zh": "本论文针对机器人自主组装和3D视觉中的错误纠正挑战，引入了Single-Step Assembly Error Correction Task，并发布了LEGO Error Correction Assembly Dataset (LEGO-ECA)，包括手动图像和组装失败实例，以支持相关研究。作者提出了Self-Correct Assembly Network (SCANet)，该方法将组装组件作为queries，检测其在手动图像中的正确性并提供必要纠正。SCANet应用于改进MEPNet的组装结果，实验证明它显著提升了组装正确性。该框架为长期规划任务提供了更可靠的解决方案，并提供了开源代码和数据集。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18195v3",
      "published_date": "2024-03-27 02:08:12 UTC",
      "updated_date": "2024-10-24 04:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:40:14.002190"
    },
    {
      "arxiv_id": "2403.18183v1",
      "title": "Can AI Models Appreciate Document Aesthetics? An Exploration of Legibility and Layout Quality in Relation to Prediction Confidence",
      "title_zh": "翻译失败",
      "authors": [
        "Hsiu-Wei Yang",
        "Abhinav Agrawal",
        "Pavlos Fragkogiannis",
        "Shubham Nitin Mulay"
      ],
      "abstract": "A well-designed document communicates not only through its words but also\nthrough its visual eloquence. Authors utilize aesthetic elements such as\ncolors, fonts, graphics, and layouts to shape the perception of information.\nThoughtful document design, informed by psychological insights, enhances both\nthe visual appeal and the comprehension of the content. While state-of-the-art\ndocument AI models demonstrate the benefits of incorporating layout and image\ndata, it remains unclear whether the nuances of document aesthetics are\neffectively captured. To bridge the gap between human cognition and AI\ninterpretation of aesthetic elements, we formulated hypotheses concerning AI\nbehavior in document understanding tasks, specifically anchored in document\ndesign principles. With a focus on legibility and layout quality, we tested\nfour aspects of aesthetic effects: noise, font-size contrast, alignment, and\ncomplexity, on model confidence using correlational analysis. The results and\nobservations highlight the value of model analysis rooted in document design\ntheories. Our work serves as a trailhead for further studies and we advocate\nfor continued research in this topic to deepen our understanding of how AI\ninterprets document aesthetics.",
      "tldr_zh": "这篇论文探讨了AI模型是否能欣赏文档美学，特别是legibility（可读性）和layout quality（布局质量）对prediction confidence（预测置信度）的影响。作者基于文档设计原则制定假设，并通过相关分析测试了noise（噪声）、font-size contrast（字体大小对比）、alignment（对齐）和complexity（复杂性）等四个美学方面的效果。结果显示，这些分析强调了基于文档设计理论的模型评估价值，并呼吁进一步研究以加深对AI解释文档审美的理解。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18183v1",
      "published_date": "2024-03-27 01:21:48 UTC",
      "updated_date": "2024-03-27 01:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:40:25.388542"
    },
    {
      "arxiv_id": "2403.18167v2",
      "title": "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Yu",
        "Meng Cao",
        "Jackie Chi Kit Cheung",
        "Yue Dong"
      ],
      "abstract": "State-of-the-art language models (LMs) sometimes generate non-factual\nhallucinations that misalign with world knowledge. To explore the mechanistic\ncauses of these hallucinations, we create diagnostic datasets with\nsubject-relation queries and adapt interpretability methods to trace\nhallucinations through internal model representations. We discover two general\nand distinct mechanistic causes of hallucinations shared across LMs (Llama-2,\nPythia, GPT-J): 1) knowledge enrichment hallucinations: insufficient subject\nattribute knowledge in lower layer MLPs, and 2) answer extraction\nhallucinations: failure to select the correct object attribute in upper layer\nattention heads. We also found these two internal mechanistic causes of\nhallucinations are reflected in external manifestations. Based on insights from\nour mechanistic analysis, we propose a novel hallucination mitigation method\nthrough targeted restoration of the LM's internal fact recall pipeline,\ndemonstrating superior performance compared to baselines.",
      "tldr_zh": "这篇论文探讨了语言模型 (LMs) 生成非事实幻觉 (non-factual hallucinations) 的机制原因，通过创建诊断数据集和适应可解释性方法来追踪模型内部表示。研究发现，幻觉主要源于两种机制：knowledge enrichment hallucinations（下层 MLP 中缺乏主题属性知识）和 answer extraction hallucinations（上层 attention heads 未能正确选择对象属性），这些问题在 Llama-2、Pythia 和 GPT-J 等模型中普遍存在。基于这些洞见，论文提出了一种新型缓解方法，通过针对性地修复 LMs 的内部事实回忆管道，实现了比基线方法更优的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18167v2",
      "published_date": "2024-03-27 00:23:03 UTC",
      "updated_date": "2024-06-17 21:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:40:37.067522"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 105,
  "processed_papers_count": 105,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T19:41:02.956156"
}