[
  {
    "arxiv_id": "2403.19060v3",
    "title": "Towards Human-Centered Construction Robotics: A Reinforcement Learning-Driven Companion Robot for Contextually Assisting Carpentry Workers",
    "authors": [
      "Yuning Wu",
      "Jiaying Wei",
      "Jean Oh",
      "Daniel Cardoso Llach"
    ],
    "abstract": "In the dynamic construction industry, traditional robotic integration has\nprimarily focused on automating specific tasks, often overlooking the\ncomplexity and variability of human aspects in construction workflows. This\npaper introduces a human-centered approach with a \"work companion rover\"\ndesigned to assist construction workers within their existing practices, aiming\nto enhance safety and workflow fluency while respecting construction labor's\nskilled nature. We conduct an in-depth study on deploying a robotic system in\ncarpentry formwork, showcasing a prototype that emphasizes mobility, safety,\nand comfortable worker-robot collaboration in dynamic environments through a\ncontextual Reinforcement Learning (RL)-driven modular framework. Our research\nadvances robotic applications in construction, advocating for collaborative\nmodels where adaptive robots support rather than replace humans, underscoring\nthe potential for an interactive and collaborative human-robot workforce.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 9 figures. This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2403.19060v3",
    "published_date": "2024-03-27 23:55:02 UTC",
    "updated_date": "2024-09-14 13:58:53 UTC"
  },
  {
    "arxiv_id": "2403.19050v3",
    "title": "Detecting Generative Parroting through Overfitting Masked Autoencoders",
    "authors": [
      "Saeid Asgari Taghanaki",
      "Joseph Lambourne"
    ],
    "abstract": "The advent of generative AI models has revolutionized digital content\ncreation, yet it introduces challenges in maintaining copyright integrity due\nto generative parroting, where models mimic their training data too closely.\nOur research presents a novel approach to tackle this issue by employing an\noverfitted Masked Autoencoder (MAE) to detect such parroted samples\neffectively. We establish a detection threshold based on the mean loss across\nthe training dataset, allowing for the precise identification of parroted\ncontent in modified datasets. Preliminary evaluations demonstrate promising\nresults, suggesting our method's potential to ensure ethical use and enhance\nthe legal compliance of generative models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to CVPR 2024, Responsible Generative AI workshop",
    "pdf_url": "http://arxiv.org/pdf/2403.19050v3",
    "published_date": "2024-03-27 23:10:33 UTC",
    "updated_date": "2024-06-19 19:53:26 UTC"
  },
  {
    "arxiv_id": "2403.19046v1",
    "title": "LITA: Language Instructed Temporal-Localization Assistant",
    "authors": [
      "De-An Huang",
      "Shijia Liao",
      "Subhashree Radhakrishnan",
      "Hongxu Yin",
      "Pavlo Molchanov",
      "Zhiding Yu",
      "Jan Kautz"
    ],
    "abstract": "There has been tremendous progress in multimodal Large Language Models\n(LLMs). Recent works have extended these models to video input with promising\ninstruction following capabilities. However, an important missing piece is\ntemporal localization. These models cannot accurately answer the \"When?\"\nquestions. We identify three key aspects that limit their temporal localization\ncapabilities: (i) time representation, (ii) architecture, and (iii) data. We\naddress these shortcomings by proposing Language Instructed\nTemporal-Localization Assistant (LITA) with the following features: (1) We\nintroduce time tokens that encode timestamps relative to the video length to\nbetter represent time in videos. (2) We introduce SlowFast tokens in the\narchitecture to capture temporal information at fine temporal resolution. (3)\nWe emphasize temporal localization data for LITA. In addition to leveraging\nexisting video datasets with timestamps, we propose a new task, Reasoning\nTemporal Localization (RTL), along with the dataset, ActivityNet-RTL, for\nlearning and evaluating this task. Reasoning temporal localization requires\nboth the reasoning and temporal localization of Video LLMs. LITA demonstrates\nstrong performance on this challenging task, nearly doubling the temporal mean\nintersection-over-union (mIoU) of baselines. In addition, we show that our\nemphasis on temporal localization also substantially improves video-based text\ngeneration compared to existing Video LLMs, including a 36% relative\nimprovement of Temporal Understanding. Code is available at:\nhttps://github.com/NVlabs/LITA",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.19046v1",
    "published_date": "2024-03-27 22:50:48 UTC",
    "updated_date": "2024-03-27 22:50:48 UTC"
  },
  {
    "arxiv_id": "2403.19721v1",
    "title": "Computationally and Memory-Efficient Robust Predictive Analytics Using Big Data",
    "authors": [
      "Daniel Menges",
      "Adil Rasheed"
    ],
    "abstract": "In the current data-intensive era, big data has become a significant asset\nfor Artificial Intelligence (AI), serving as a foundation for developing\ndata-driven models and providing insight into various unknown fields. This\nstudy navigates through the challenges of data uncertainties, storage\nlimitations, and predictive data-driven modeling using big data. We utilize\nRobust Principal Component Analysis (RPCA) for effective noise reduction and\noutlier elimination, and Optimal Sensor Placement (OSP) for efficient data\ncompression and storage. The proposed OSP technique enables data compression\nwithout substantial information loss while simultaneously reducing storage\nneeds. While RPCA offers an enhanced alternative to traditional Principal\nComponent Analysis (PCA) for high-dimensional data management, the scope of\nthis work extends its utilization, focusing on robust, data-driven modeling\napplicable to huge data sets in real-time. For that purpose, Long Short-Term\nMemory (LSTM) networks, a type of recurrent neural network, are applied to\nmodel and predict data based on a low-dimensional subset obtained from OSP,\nleading to a crucial acceleration of the training phase. LSTMs are feasible for\ncapturing long-term dependencies in time series data, making them particularly\nsuited for predicting the future states of physical systems on historical data.\nAll the presented algorithms are not only theorized but also simulated and\nvalidated using real thermal imaging data mapping a ship's engine.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.19721v1",
    "published_date": "2024-03-27 22:39:08 UTC",
    "updated_date": "2024-03-27 22:39:08 UTC"
  },
  {
    "arxiv_id": "2403.19031v1",
    "title": "Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data",
    "authors": [
      "Yuting Guo",
      "Anthony Ovadje",
      "Mohammed Ali Al-Garadi",
      "Abeed Sarker"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable success in NLP\ntasks. However, there is a paucity of studies that attempt to evaluate their\nperformances on social media-based health-related natural language processing\ntasks, which have traditionally been difficult to achieve high scores in. We\nbenchmarked one supervised classic machine learning model based on Support\nVector Machines (SVMs), three supervised pretrained language models (PLMs)\nbased on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5\nand GPT4), across 6 text classification tasks. We developed three approaches\nfor leveraging LLMs for text classification: employing LLMs as zero-shot\nclassifiers, us-ing LLMs as annotators to annotate training data for supervised\nclassifiers, and utilizing LLMs with few-shot examples for augmentation of\nmanually annotated data. Our comprehensive experiments demonstrate that\nemploy-ing data augmentation using LLMs (GPT-4) with relatively small\nhuman-annotated data to train lightweight supervised classification models\nachieves superior results compared to training with human-annotated data alone.\nSupervised learners also outperform GPT-4 and GPT-3.5 in zero-shot settings. By\nleveraging this data augmentation strategy, we can harness the power of LLMs to\ndevelop smaller, more effective domain-specific NLP models. LLM-annotated data\nwithout human guidance for training light-weight supervised classification\nmodels is an ineffective strategy. However, LLM, as a zero-shot classifier,\nshows promise in excluding false negatives and potentially reducing the human\neffort required for data annotation. Future investigations are imperative to\nexplore optimal training data sizes and the optimal amounts of augmented data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.19031v1",
    "published_date": "2024-03-27 22:05:10 UTC",
    "updated_date": "2024-03-27 22:05:10 UTC"
  },
  {
    "arxiv_id": "2403.19024v3",
    "title": "Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with Asymmetric Rewards",
    "authors": [
      "Yasin Sonmez",
      "Neelay Junnarkar",
      "Murat Arcak"
    ],
    "abstract": "Recent work in reinforcement learning has leveraged symmetries in the model\nto improve sample efficiency in training a policy. A commonly used simplifying\nassumption is that the dynamics and reward both exhibit the same symmetry;\nhowever, in many real-world environments, the dynamical model exhibits symmetry\nindependent of the reward model. In this paper, we assume only the dynamics\nexhibit symmetry, extending the scope of problems in reinforcement learning and\nlearning in control theory to which symmetry techniques can be applied. We use\nCartan's moving frame method to introduce a technique for learning dynamics\nthat, by construction, exhibit specified symmetries. Numerical experiments\ndemonstrate that the proposed method learns a more accurate dynamical model",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.19024v3",
    "published_date": "2024-03-27 21:31:46 UTC",
    "updated_date": "2024-08-16 18:00:05 UTC"
  },
  {
    "arxiv_id": "2403.19021v2",
    "title": "IDGenRec: LLM-RecSys Alignment with Textual ID Learning",
    "authors": [
      "Juntao Tan",
      "Shuyuan Xu",
      "Wenyue Hua",
      "Yingqiang Ge",
      "Zelong Li",
      "Yongfeng Zhang"
    ],
    "abstract": "Generative recommendation based on Large Language Models (LLMs) have\ntransformed the traditional ranking-based recommendation style into a\ntext-to-text generation paradigm. However, in contrast to standard NLP tasks\nthat inherently operate on human vocabulary, current research in generative\nrecommendations struggles to effectively encode recommendation items within the\ntext-to-text framework using concise yet meaningful ID representations. To\nbetter align LLMs with recommendation needs, we propose IDGen, representing\neach item as a unique, concise, semantically rich, platform-agnostic textual ID\nusing human language tokens. This is achieved by training a textual ID\ngenerator alongside the LLM-based recommender, enabling seamless integration of\npersonalized recommendations into natural language generation. Notably, as user\nhistory is expressed in natural language and decoupled from the original\ndataset, our approach suggests the potential for a foundational generative\nrecommendation model. Experiments show that our framework consistently\nsurpasses existing models in sequential recommendation under standard\nexperimental setting. Then, we explore the possibility of training a foundation\nrecommendation model with the proposed method on data collected from 19\ndifferent datasets and tested its recommendation performance on 6 unseen\ndatasets across different platforms under a completely zero-shot setting. The\nresults show that the zero-shot performance of the pre-trained foundation model\nis comparable to or even better than some traditional recommendation models\nbased on supervised training, showing the potential of the IDGen paradigm\nserving as the foundation model for generative recommendation. Code and data\nare open-sourced at https://github.com/agiresearch/IDGenRec.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted in SIGIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.19021v2",
    "published_date": "2024-03-27 21:22:37 UTC",
    "updated_date": "2024-05-17 04:05:18 UTC"
  },
  {
    "arxiv_id": "2403.19012v2",
    "title": "ReflectSumm: A Benchmark for Course Reflection Summarization",
    "authors": [
      "Yang Zhong",
      "Mohamed Elaraby",
      "Diane Litman",
      "Ahmed Ashraf Butt",
      "Muhsin Menekse"
    ],
    "abstract": "This paper introduces ReflectSumm, a novel summarization dataset specifically\ndesigned for summarizing students' reflective writing. The goal of ReflectSumm\nis to facilitate developing and evaluating novel summarization techniques\ntailored to real-world scenarios with little training data, %practical tasks\nwith potential implications in the opinion summarization domain in general and\nthe educational domain in particular. The dataset encompasses a diverse range\nof summarization tasks and includes comprehensive metadata, enabling the\nexploration of various research questions and supporting different\napplications. To showcase its utility, we conducted extensive evaluations using\nmultiple state-of-the-art baselines. The results provide benchmarks for\nfacilitating further research in this area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "LREC-COLING 2024 camera ready; code and dataset are available at\n  https://github.com/EngSalem/ReflectSUMM",
    "pdf_url": "http://arxiv.org/pdf/2403.19012v2",
    "published_date": "2024-03-27 21:10:07 UTC",
    "updated_date": "2024-04-23 02:28:10 UTC"
  },
  {
    "arxiv_id": "2403.19001v4",
    "title": "Cross-domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction",
    "authors": [
      "Yui Lo",
      "Yuqian Chen",
      "Dongnan Liu",
      "Wan Liu",
      "Leo Zekelman",
      "Fan Zhang",
      "Yogesh Rathi",
      "Nikos Makris",
      "Alexandra J. Golby",
      "Weidong Cai",
      "Lauren J. O'Donnell"
    ],
    "abstract": "Shape plays an important role in computer graphics, offering informative\nfeatures to convey an object's morphology and functionality. Shape analysis in\nbrain imaging can help interpret structural and functionality correlations of\nthe human brain. In this work, we investigate the shape of the brain's 3D white\nmatter connections and its potential predictive relationship to human cognitive\nfunction. We reconstruct brain connections as sequences of 3D points using\ndiffusion magnetic resonance imaging (dMRI) tractography. To describe each\nconnection, we extract 12 shape descriptors in addition to traditional dMRI\nconnectivity and tissue microstructure features. We introduce a novel\nframework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a\nmulti-head cross-attention feature fusion module to predict subject-specific\nlanguage performance based on dMRI tractography. We assess the performance of\nthe method on a large dataset including 1065 healthy young adults. The results\ndemonstrate that both the transformer-based SFFormer model and its inter/intra\nfeature fusion with shape, microstructure, and connectivity are informative,\nand together, they improve the prediction of subject-specific language\nperformance scores. Overall, our results indicate that the shape of the brain's\nconnections is predictive of human language function.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted for presentation at The 27th Intl. Conf.\n  on Medical Image Computing and Computer Assisted Intervention (MICCAI 2024)\n  Workshop on Computational Diffusion MRI (CDMRI). 11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.19001v4",
    "published_date": "2024-03-27 20:51:02 UTC",
    "updated_date": "2025-04-21 22:16:59 UTC"
  },
  {
    "arxiv_id": "2403.18998v4",
    "title": "Cross-System Categorization of Abnormal Traces in Microservice-Based Systems via Meta-Learning",
    "authors": [
      "Yuqing Wang",
      "Mika V. Mäntylä",
      "Serge Demeyer",
      "Mutlu Beyazit",
      "Joanna Kisaakye",
      "Jesse Nyyssölä"
    ],
    "abstract": "Microservice-based systems (MSS) may fail with various fault types. While\nexisting AIOps methods excel at detecting abnormal traces and locating the\nresponsible service(s), human efforts are still required for diagnosing\nspecific fault types and failure causes.This paper presents TraFaultDia, a\nnovel AIOps framework to automatically classify abnormal traces into fault\ncategories for MSS. We treat the classification process as a series of\nmulti-class classification tasks, where each task represents an attempt to\nclassify abnormal traces into specific fault categories for a MSS. TraFaultDia\nleverages meta-learning to train on several abnormal trace classification tasks\nwith a few labeled instances from a MSS, enabling quick adaptation to new,\nunseen abnormal trace classification tasks with a few labeled instances across\nMSS. TraFaultDia's use cases are scalable depending on how fault categories are\nbuilt from anomalies within MSS. We evaluated TraFaultDia on two MSS,\nTrainTicket and OnlineBoutique, with open datasets where each fault category is\nlinked to faulty system components (service/pod) and a root cause. TraFaultDia\nautomatically classifies abnormal traces into these fault categories, thus\nenabling the automatic identification of faulty system components and root\ncauses without manual analysis. TraFaultDia achieves 93.26% and 85.20% accuracy\non 50 new classification tasks for TrainTicket and OnlineBoutique,\nrespectively, when trained within the same MSS with 10 labeled instances per\ncategory. In the cross-system context, when TraFaultDia is applied to a MSS\ndifferent from the one it is trained on, TraFaultDia gets an average accuracy\nof 92.19% and 84.77% for the same set of 50 new, unseen abnormal trace\nclassification tasks of the respective systems, also with 10 labeled instances\nprovided for each fault category per task in each system.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at ACM International Conference on the Foundations of\n  Software Engineering (FSE) 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.18998v4",
    "published_date": "2024-03-27 20:38:04 UTC",
    "updated_date": "2025-02-25 08:50:14 UTC"
  },
  {
    "arxiv_id": "2403.18989v1",
    "title": "Dealing with Imbalanced Classes in Bot-IoT Dataset",
    "authors": [
      "Jesse Atuhurra",
      "Takanori Hara",
      "Yuanyu Zhang",
      "Masahiro Sasabe",
      "Shoji Kasahara"
    ],
    "abstract": "With the rapidly spreading usage of Internet of Things (IoT) devices, a\nnetwork intrusion detection system (NIDS) plays an important role in detecting\nand protecting various types of attacks in the IoT network. To evaluate the\nrobustness of the NIDS in the IoT network, the existing work proposed a\nrealistic botnet dataset in the IoT network (Bot-IoT dataset) and applied it to\nmachine learning-based anomaly detection. This dataset contains imbalanced\nnormal and attack packets because the number of normal packets is much smaller\nthan that of attack ones. The nature of imbalanced data may make it difficult\nto identify the minority class correctly. In this thesis, to address the class\nimbalance problem in the Bot-IoT dataset, we propose a binary classification\nmethod with synthetic minority over-sampling techniques (SMOTE). The proposed\nclassifier aims to detect attack packets and overcome the class imbalance\nproblem using the SMOTE algorithm. Through numerical results, we demonstrate\nthe proposed classifier's fundamental characteristics and the impact of\nimbalanced data on its performance.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18989v1",
    "published_date": "2024-03-27 20:09:59 UTC",
    "updated_date": "2024-03-27 20:09:59 UTC"
  },
  {
    "arxiv_id": "2403.18985v2",
    "title": "Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning",
    "authors": [
      "Soumyendu Sarkar",
      "Ashwin Ramesh Babu",
      "Sajad Mousavi",
      "Vineet Gundecha",
      "Avisek Naug",
      "Sahand Ghorbanpour"
    ],
    "abstract": "We present a generic Reinforcement Learning (RL) framework optimized for\ncrafting adversarial attacks on different model types spanning from ECG signal\nanalysis (1D), image classification (2D), and video classification (3D). The\nframework focuses on identifying sensitive regions and inducing\nmisclassifications with minimal distortions and various distortion types. The\nnovel RL method outperforms state-of-the-art methods for all three\napplications, proving its efficiency. Our RL approach produces superior\nlocalization masks, enhancing interpretability for image classification and ECG\nanalysis models. For applications such as ECG analysis, our platform highlights\ncritical ECG segments for clinicians while ensuring resilience against\nprevalent distortions. This comprehensive tool aims to bolster both resilience\nwith adversarial training and transparency across varied applications and data\ntypes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI Proceedings reference:\n  https://ojs.aaai.org/index.php/AAAI/article/view/30579",
    "pdf_url": "http://arxiv.org/pdf/2403.18985v2",
    "published_date": "2024-03-27 20:07:39 UTC",
    "updated_date": "2024-04-22 14:49:36 UTC"
  },
  {
    "arxiv_id": "2403.18978v1",
    "title": "TextCraftor: Your Text Encoder Can be Image Quality Controller",
    "authors": [
      "Yanyu Li",
      "Xian Liu",
      "Anil Kag",
      "Ju Hu",
      "Yerlan Idelbayev",
      "Dhritiman Sagar",
      "Yanzhi Wang",
      "Sergey Tulyakov",
      "Jian Ren"
    ],
    "abstract": "Diffusion-based text-to-image generative models, e.g., Stable Diffusion, have\nrevolutionized the field of content generation, enabling significant\nadvancements in areas like image editing and video synthesis. Despite their\nformidable capabilities, these models are not without their limitations. It is\nstill challenging to synthesize an image that aligns well with the input text,\nand multiple runs with carefully crafted prompts are required to achieve\nsatisfactory results. To mitigate these limitations, numerous studies have\nendeavored to fine-tune the pre-trained diffusion models, i.e., UNet, utilizing\nvarious technologies. Yet, amidst these efforts, a pivotal question of\ntext-to-image diffusion model training has remained largely unexplored: Is it\npossible and feasible to fine-tune the text encoder to improve the performance\nof text-to-image diffusion models? Our findings reveal that, instead of\nreplacing the CLIP text encoder used in Stable Diffusion with other large\nlanguage models, we can enhance it through our proposed fine-tuning approach,\nTextCraftor, leading to substantial improvements in quantitative benchmarks and\nhuman assessments. Interestingly, our technique also empowers controllable\nimage generation through the interpolation of different text encoders\nfine-tuned with various rewards. We also demonstrate that TextCraftor is\northogonal to UNet finetuning, and can be combined to further improve\ngenerative quality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18978v1",
    "published_date": "2024-03-27 19:52:55 UTC",
    "updated_date": "2024-03-27 19:52:55 UTC"
  },
  {
    "arxiv_id": "2403.18976v1",
    "title": "\"Sorry, Come Again?\" Prompting -- Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing",
    "authors": [
      "Vipula Rawte",
      "S. M Towhidul Islam Tonmoy",
      "S M Mehedi Zaman",
      "Prachi Priya",
      "Aman Chadha",
      "Amit P. Sheth",
      "Amitava Das"
    ],
    "abstract": "Hallucination has emerged as the most vulnerable aspect of contemporary Large\nLanguage Models (LLMs). In this paper, we introduce the Sorry, Come Again (SCA)\nprompting, aimed to avoid LLM hallucinations by enhancing comprehension\nthrough: (i) optimal paraphrasing and (ii) injecting [PAUSE] tokens to delay\nLLM generation. First, we provide an in-depth analysis of linguistic nuances:\nformality, readability, and concreteness of prompts for 21 LLMs, and elucidate\nhow these nuances contribute to hallucinated generation. Prompts with lower\nreadability, formality, or concreteness pose comprehension challenges for LLMs,\nsimilar to those faced by humans. In such scenarios, an LLM tends to speculate\nand generate content based on its imagination (associative memory) to fill\nthese information gaps. Although these speculations may occasionally align with\nfactual information, their accuracy is not assured, often resulting in\nhallucination. Recent studies reveal that an LLM often neglects the middle\nsections of extended prompts, a phenomenon termed as lost in the middle. While\na specific paraphrase may suit one LLM, the same paraphrased version may elicit\na different response from another LLM. Therefore, we propose an optimal\nparaphrasing technique to identify the most comprehensible paraphrase of a\ngiven prompt, evaluated using Integrated Gradient (and its variations) to\nguarantee that the LLM accurately processes all words. While reading lengthy\nsentences, humans often pause at various points to better comprehend the\nmeaning read thus far. We have fine-tuned an LLM with injected [PAUSE] tokens,\nallowing the LLM to pause while reading lengthier prompts. This has brought\nseveral key contributions: (i) determining the optimal position to inject\n[PAUSE], (ii) determining the number of [PAUSE] tokens to be inserted, and\n(iii) introducing reverse proxy tuning to fine-tune the LLM for [PAUSE]\ninsertion.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18976v1",
    "published_date": "2024-03-27 19:45:09 UTC",
    "updated_date": "2024-03-27 19:45:09 UTC"
  },
  {
    "arxiv_id": "2403.18969v2",
    "title": "A Survey on Large Language Models from Concept to Implementation",
    "authors": [
      "Chen Wang",
      "Jin Zhao",
      "Jiaqi Gong"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs), particularly those built\non Transformer architectures, have significantly broadened the scope of natural\nlanguage processing (NLP) applications, transcending their initial use in\nchatbot technology. This paper investigates the multifaceted applications of\nthese models, with an emphasis on the GPT series. This exploration focuses on\nthe transformative impact of artificial intelligence (AI) driven tools in\nrevolutionizing traditional tasks like coding and problem-solving, while also\npaving new paths in research and development across diverse industries. From\ncode interpretation and image captioning to facilitating the construction of\ninteractive systems and advancing computational domains, Transformer models\nexemplify a synergy of deep learning, data analysis, and neural network design.\nThis survey provides an in-depth look at the latest research in Transformer\nmodels, highlighting their versatility and the potential they hold for\ntransforming diverse application sectors, thereby offering readers a\ncomprehensive understanding of the current and future landscape of\nTransformer-based LLMs in practical applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "Section 3 lacks to clarity and accuracy in defining the applications\n  and capabilities of LLMs. More rework needs to be done on illustrate how LLMs\n  being used in cross-domains",
    "pdf_url": "http://arxiv.org/pdf/2403.18969v2",
    "published_date": "2024-03-27 19:35:41 UTC",
    "updated_date": "2024-05-28 02:34:26 UTC"
  },
  {
    "arxiv_id": "2403.18965v1",
    "title": "LORD: Large Models based Opposite Reward Design for Autonomous Driving",
    "authors": [
      "Xin Ye",
      "Feng Tao",
      "Abhirup Mallik",
      "Burhaneddin Yaman",
      "Liu Ren"
    ],
    "abstract": "Reinforcement learning (RL) based autonomous driving has emerged as a\npromising alternative to data-driven imitation learning approaches. However,\ncrafting effective reward functions for RL poses challenges due to the\ncomplexity of defining and quantifying good driving behaviors across diverse\nscenarios. Recently, large pretrained models have gained significant attention\nas zero-shot reward models for tasks specified with desired linguistic goals.\nHowever, the desired linguistic goals for autonomous driving such as \"drive\nsafely\" are ambiguous and incomprehensible by pretrained models. On the other\nhand, undesired linguistic goals like \"collision\" are more concrete and\ntractable. In this work, we introduce LORD, a novel large models based opposite\nreward design through undesired linguistic goals to enable the efficient use of\nlarge pretrained models as zero-shot reward models. Through extensive\nexperiments, our proposed framework shows its efficiency in leveraging the\npower of large pretrained models for achieving safe and enhanced autonomous\ndriving. Moreover, the proposed approach shows improved generalization\ncapabilities as it outperforms counterpart methods across diverse and\nchallenging driving scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18965v1",
    "published_date": "2024-03-27 19:30:06 UTC",
    "updated_date": "2024-03-27 19:30:06 UTC"
  },
  {
    "arxiv_id": "2403.18963v3",
    "title": "Leveraging Quantum Superposition to Infer the Dynamic Behavior of a Spatial-Temporal Neural Network Signaling Model",
    "authors": [
      "Gabriel A. Silva"
    ],
    "abstract": "The exploration of new problem classes for quantum computation is an active\narea of research. In this paper, we introduce and solve a novel problem class\nrelated to dynamics on large-scale networks relevant to neurobiology and\nmachine learning. Specifically, we ask if a network can sustain inherent\ndynamic activity beyond some arbitrary observation time or if the activity\nceases through quiescence or saturation via an epileptic-like state. We show\nthat this class of problems can be formulated and structured to take advantage\nof quantum superposition and solved efficiently using the Deutsch-Jozsa and\nGrover quantum algorithms. To do so, we extend their functionality to address\nthe unique requirements of how input (sub)sets into the algorithms must be\nmathematically structured while simultaneously constructing the inputs so that\nmeasurement outputs can be interpreted as meaningful properties of the network\ndynamics. This, in turn, allows us to answer the question we pose.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "quant-ph",
    "comment": "36 pages, 4 figures. See\n  https://github.com/gabe-alex-silva/Network_Dynamics_QuantumSim/tree/main for\n  code details",
    "pdf_url": "http://arxiv.org/pdf/2403.18963v3",
    "published_date": "2024-03-27 19:16:56 UTC",
    "updated_date": "2025-01-21 02:28:29 UTC"
  },
  {
    "arxiv_id": "2403.18958v1",
    "title": "A State-of-the-practice Release-readiness Checklist for Generative AI-based Software Products",
    "authors": [
      "Harsh Patel",
      "Dominique Boucher",
      "Emad Fallahzadeh",
      "Ahmed E. Hassan",
      "Bram Adams"
    ],
    "abstract": "This paper investigates the complexities of integrating Large Language Models\n(LLMs) into software products, with a focus on the challenges encountered for\ndetermining their readiness for release. Our systematic review of grey\nliterature identifies common challenges in deploying LLMs, ranging from\npre-training and fine-tuning to user experience considerations. The study\nintroduces a comprehensive checklist designed to guide practitioners in\nevaluating key release readiness aspects such as performance, monitoring, and\ndeployment strategies, aiming to enhance the reliability and effectiveness of\nLLM-based applications in real-world settings.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18958v1",
    "published_date": "2024-03-27 19:02:56 UTC",
    "updated_date": "2024-03-27 19:02:56 UTC"
  },
  {
    "arxiv_id": "2403.18938v1",
    "title": "Reshaping Free-Text Radiology Notes Into Structured Reports With Generative Transformers",
    "authors": [
      "Laura Bergomi",
      "Tommaso M. Buonocore",
      "Paolo Antonazzo",
      "Lorenzo Alberghi",
      "Riccardo Bellazzi",
      "Lorenzo Preda",
      "Chandra Bortolotto",
      "Enea Parimbelli"
    ],
    "abstract": "BACKGROUND: Radiology reports are typically written in a free-text format,\nmaking clinical information difficult to extract and use. Recently the adoption\nof structured reporting (SR) has been recommended by various medical societies\nthanks to the advantages it offers, e.g. standardization, completeness and\ninformation retrieval. We propose a pipeline to extract information from\nfree-text radiology reports, that fits with the items of the reference SR\nregistry proposed by a national society of interventional and medical\nradiology, focusing on CT staging of patients with lymphoma. METHODS: Our work\naims to leverage the potential of Natural Language Processing (NLP) and\nTransformer-based models to deal with automatic SR registry filling. With the\navailability of 174 radiology reports, we investigate a rule-free generative\nQuestion Answering approach based on a domain-specific version of T5 (IT5). Two\nstrategies (batch-truncation and ex-post combination) are implemented to comply\nwith the model's context length limitations. Performance is evaluated in terms\nof strict accuracy, F1, and format accuracy, and compared with the widely used\nGPT-3.5 Large Language Model. A 5-point Likert scale questionnaire is used to\ncollect human-expert feedback on the similarity between medical annotations and\ngenerated answers. RESULTS: The combination of fine-tuning and batch splitting\nallows IT5 to achieve notable results; it performs on par with GPT-3.5 albeit\nits size being a thousand times smaller in terms of parameters. Human-based\nassessment scores show a high correlation (Spearman's correlation\ncoefficients>0.88, p-values<0.001) with AI performance metrics (F1) and confirm\nthe superior ability of LLMs (i.e., GPT-3.5, 175B of parameters) in generating\nplausible human-like statements.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18938v1",
    "published_date": "2024-03-27 18:38:39 UTC",
    "updated_date": "2024-03-27 18:38:39 UTC"
  },
  {
    "arxiv_id": "2403.18932v1",
    "title": "Measuring Political Bias in Large Language Models: What Is Said and How It Is Said",
    "authors": [
      "Yejin Bang",
      "Delong Chen",
      "Nayeon Lee",
      "Pascale Fung"
    ],
    "abstract": "We propose to measure political bias in LLMs by analyzing both the content\nand style of their generated content regarding political issues. Existing\nbenchmarks and measures focus on gender and racial biases. However, political\nbias exists in LLMs and can lead to polarization and other harms in downstream\napplications. In order to provide transparency to users, we advocate that there\nshould be fine-grained and explainable measures of political biases generated\nby LLMs. Our proposed measure looks at different political issues such as\nreproductive rights and climate change, at both the content (the substance of\nthe generation) and the style (the lexical polarity) of such bias. We measured\nthe political bias in eleven open-sourced LLMs and showed that our proposed\nframework is easily scalable to other topics and is explainable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.18932v1",
    "published_date": "2024-03-27 18:22:48 UTC",
    "updated_date": "2024-03-27 18:22:48 UTC"
  },
  {
    "arxiv_id": "2404.10636v2",
    "title": "What are human values, and how do we align AI to them?",
    "authors": [
      "Oliver Klingefjord",
      "Ryan Lowe",
      "Joe Edelman"
    ],
    "abstract": "There is an emerging consensus that we need to align AI systems with human\nvalues (Gabriel, 2020; Ji et al., 2024), but it remains unclear how to apply\nthis to language models in practice. We split the problem of \"aligning to human\nvalues\" into three parts: first, eliciting values from people; second,\nreconciling those values into an alignment target for training ML models; and\nthird, actually training the model. In this paper, we focus on the first two\nparts, and ask the question: what are \"good\" ways to synthesize diverse human\ninputs about values into a target for aligning language models? To answer this\nquestion, we first define a set of 6 criteria that we believe must be satisfied\nfor an alignment target to shape model behavior in accordance with human\nvalues. We then propose a process for eliciting and reconciling values called\nMoral Graph Elicitation (MGE), which uses a large language model to interview\nparticipants about their values in particular contexts; our approach is\ninspired by the philosophy of values advanced by Taylor (1977), Chang (2004),\nand others. We trial MGE with a representative sample of 500 Americans, on 3\nintentionally divisive prompts (e.g. advice about abortion). Our results\ndemonstrate that MGE is promising for improving model alignment across all 6\ncriteria. For example, almost all participants (89.1%) felt well represented by\nthe process, and (89%) thought the final moral graph was fair, even if their\nvalue wasn't voted as the wisest. Our process often results in \"expert\" values\n(e.g. values from women who have solicited abortion advice) rising to the top\nof the moral graph, without defining who is considered an expert in advance.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10636v2",
    "published_date": "2024-03-27 18:12:02 UTC",
    "updated_date": "2024-04-17 16:27:37 UTC"
  },
  {
    "arxiv_id": "2403.18920v1",
    "title": "CPR: Retrieval Augmented Generation for Copyright Protection",
    "authors": [
      "Aditya Golatkar",
      "Alessandro Achille",
      "Luca Zancato",
      "Yu-Xiang Wang",
      "Ashwin Swaminathan",
      "Stefano Soatto"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) is emerging as a flexible and robust\ntechnique to adapt models to private users data without training, to handle\ncredit attribution, and to allow efficient machine unlearning at scale.\nHowever, RAG techniques for image generation may lead to parts of the retrieved\nsamples being copied in the model's output. To reduce risks of leaking private\ninformation contained in the retrieved set, we introduce Copy-Protected\ngeneration with Retrieval (CPR), a new method for RAG with strong copyright\nprotection guarantees in a mixed-private setting for diffusion models.CPR\nallows to condition the output of diffusion models on a set of retrieved\nimages, while also guaranteeing that unique identifiable information about\nthose example is not exposed in the generated outputs. In particular, it does\nso by sampling from a mixture of public (safe) distribution and private (user)\ndistribution by merging their diffusion scores at inference. We prove that CPR\nsatisfies Near Access Freeness (NAF) which bounds the amount of information an\nattacker may be able to extract from the generated images. We provide two\nalgorithms for copyright protection, CPR-KL and CPR-Choose. Unlike previously\nproposed rejection-sampling-based NAF methods, our methods enable efficient\ncopyright-protected sampling with a single run of backward diffusion. We show\nthat our method can be applied to any pre-trained conditional diffusion model,\nsuch as Stable Diffusion or unCLIP. In particular, we empirically show that\napplying CPR on top of unCLIP improves quality and text-to-image alignment of\nthe generated results (81.4 to 83.17 on TIFA benchmark), while enabling credit\nattribution, copy-right protection, and deterministic, constant time,\nunlearning.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18920v1",
    "published_date": "2024-03-27 18:09:55 UTC",
    "updated_date": "2024-03-27 18:09:55 UTC"
  },
  {
    "arxiv_id": "2403.18910v2",
    "title": "A Geometric Explanation of the Likelihood OOD Detection Paradox",
    "authors": [
      "Hamidreza Kamkari",
      "Brendan Leigh Ross",
      "Jesse C. Cresswell",
      "Anthony L. Caterini",
      "Rahul G. Krishnan",
      "Gabriel Loaiza-Ganem"
    ],
    "abstract": "Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling\nbehaviour: when trained on a relatively complex dataset, they assign higher\nlikelihood values to out-of-distribution (OOD) data from simpler sources.\nAdding to the mystery, OOD samples are never generated by these DGMs despite\nhaving higher likelihoods. This two-pronged paradox has yet to be conclusively\nexplained, making likelihood-based OOD detection unreliable. Our primary\nobservation is that high-likelihood regions will not be generated if they\ncontain minimal probability mass. We demonstrate how this seeming contradiction\nof large densities yet low probability mass can occur around data confined to\nlow-dimensional manifolds. We also show that this scenario can be identified\nthrough local intrinsic dimension (LID) estimation, and propose a method for\nOOD detection which pairs the likelihoods and LID estimates obtained from a\npre-trained DGM. Our method can be applied to normalizing flows and score-based\ndiffusion models, and obtains results which match or surpass state-of-the-art\nOOD detection benchmarks using the same DGM backbones. Our code is available at\nhttps://github.com/layer6ai-labs/dgm_ood_detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18910v2",
    "published_date": "2024-03-27 18:02:49 UTC",
    "updated_date": "2024-06-11 18:00:00 UTC"
  },
  {
    "arxiv_id": "2403.18814v1",
    "title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models",
    "authors": [
      "Yanwei Li",
      "Yuechen Zhang",
      "Chengyao Wang",
      "Zhisheng Zhong",
      "Yixin Chen",
      "Ruihang Chu",
      "Shaoteng Liu",
      "Jiaya Jia"
    ],
    "abstract": "In this work, we introduce Mini-Gemini, a simple and effective framework\nenhancing multi-modality Vision Language Models (VLMs). Despite the\nadvancements in VLMs facilitating basic visual dialog and reasoning, a\nperformance gap persists compared to advanced models like GPT-4 and Gemini. We\ntry to narrow the gap by mining the potential of VLMs for better performance\nand any-to-any workflow from three aspects, i.e., high-resolution visual\ntokens, high-quality data, and VLM-guided generation. To enhance visual tokens,\nwe propose to utilize an additional visual encoder for high-resolution\nrefinement without increasing the visual token count. We further construct a\nhigh-quality dataset that promotes precise image comprehension and\nreasoning-based generation, expanding the operational scope of current VLMs. In\ngeneral, Mini-Gemini further mines the potential of VLMs and empowers current\nframeworks with image understanding, reasoning, and generation simultaneously.\nMini-Gemini supports a series of dense and MoE Large Language Models (LLMs)\nfrom 2B to 34B. It is demonstrated to achieve leading performance in several\nzero-shot benchmarks and even surpasses the developed private models. Code and\nmodels are available at https://github.com/dvlab-research/MiniGemini.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Code and models are available at\n  https://github.com/dvlab-research/MiniGemini",
    "pdf_url": "http://arxiv.org/pdf/2403.18814v1",
    "published_date": "2024-03-27 17:59:04 UTC",
    "updated_date": "2024-03-27 17:59:04 UTC"
  },
  {
    "arxiv_id": "2403.18807v4",
    "title": "ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation",
    "authors": [
      "Suraj Patni",
      "Aradhye Agarwal",
      "Chetan Arora"
    ],
    "abstract": "In the absence of parallax cues, a learning-based single image depth\nestimation (SIDE) model relies heavily on shading and contextual cues in the\nimage. While this simplicity is attractive, it is necessary to train such\nmodels on large and varied datasets, which are difficult to capture. It has\nbeen shown that using embeddings from pre-trained foundational models, such as\nCLIP, improves zero shot transfer in several applications. Taking inspiration\nfrom this, in our paper we explore the use of global image priors generated\nfrom a pre-trained ViT model to provide more detailed contextual information.\nWe argue that the embedding vector from a ViT model, pre-trained on a large\ndataset, captures greater relevant information for SIDE than the usual route of\ngenerating pseudo image captions, followed by CLIP based text embeddings. Based\non this idea, we propose a new SIDE model using a diffusion backbone which is\nconditioned on ViT embeddings. Our proposed design establishes a new\nstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of\n0.059 (14% improvement) compared to 0.069 by the current SOTA (VPD). And on\nKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to\n0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model\ntrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)\nover NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,\n18%, 45%, 9%) by ZoeDepth. The project page is available at\nhttps://ecodepth-iitd.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18807v4",
    "published_date": "2024-03-27 17:53:30 UTC",
    "updated_date": "2024-04-17 14:59:51 UTC"
  },
  {
    "arxiv_id": "2403.18802v4",
    "title": "Long-form factuality in large language models",
    "authors": [
      "Jerry Wei",
      "Chengrun Yang",
      "Xinying Song",
      "Yifeng Lu",
      "Nathan Hu",
      "Jie Huang",
      "Dustin Tran",
      "Daiyi Peng",
      "Ruibo Liu",
      "Da Huang",
      "Cosmo Du",
      "Quoc V. Le"
    ],
    "abstract": "Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can outperform crowdsourced human\nannotators - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024; 72 pages, 18 figures, 30 tables. Code at\n  https://github.com/google-deepmind/long-form-factuality",
    "pdf_url": "http://arxiv.org/pdf/2403.18802v4",
    "published_date": "2024-03-27 17:48:55 UTC",
    "updated_date": "2024-11-07 03:14:38 UTC"
  },
  {
    "arxiv_id": "2403.19716v1",
    "title": "Capability-aware Prompt Reformulation Learning for Text-to-Image Generation",
    "authors": [
      "Jingtao Zhan",
      "Qingyao Ai",
      "Yiqun Liu",
      "Jia Chen",
      "Shaoping Ma"
    ],
    "abstract": "Text-to-image generation systems have emerged as revolutionary tools in the\nrealm of artistic creation, offering unprecedented ease in transforming textual\nprompts into visual art. However, the efficacy of these systems is intricately\nlinked to the quality of user-provided prompts, which often poses a challenge\nto users unfamiliar with prompt crafting. This paper addresses this challenge\nby leveraging user reformulation data from interaction logs to develop an\nautomatic prompt reformulation model. Our in-depth analysis of these logs\nreveals that user prompt reformulation is heavily dependent on the individual\nuser's capability, resulting in significant variance in the quality of\nreformulation pairs. To effectively use this data for training, we introduce\nthe Capability-aware Prompt Reformulation (CAPR) framework. CAPR innovatively\nintegrates user capability into the reformulation process through two key\ncomponents: the Conditional Reformulation Model (CRM) and Configurable\nCapability Features (CCF). CRM reformulates prompts according to a specified\nuser capability, as represented by CCF. The CCF, in turn, offers the\nflexibility to tune and guide the CRM's behavior. This enables CAPR to\neffectively learn diverse reformulation strategies across various user\ncapacities and to simulate high-capability user reformulation during inference.\nExtensive experiments on standard text-to-image generation benchmarks showcase\nCAPR's superior performance over existing baselines and its remarkable\nrobustness on unseen systems. Furthermore, comprehensive analyses validate the\neffectiveness of different components. CAPR can facilitate user-friendly\ninteraction with text-to-image systems and make advanced artistic creation more\nachievable for a broader range of users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SIGIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.19716v1",
    "published_date": "2024-03-27 17:41:16 UTC",
    "updated_date": "2024-03-27 17:41:16 UTC"
  },
  {
    "arxiv_id": "2403.18795v3",
    "title": "Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction",
    "authors": [
      "Qiuhong Shen",
      "Zike Wu",
      "Xuanyu Yi",
      "Pan Zhou",
      "Hanwang Zhang",
      "Shuicheng Yan",
      "Xinchao Wang"
    ],
    "abstract": "We tackle the challenge of efficiently reconstructing a 3D asset from a\nsingle image at millisecond speed. Existing methods for single-image 3D\nreconstruction are primarily based on Score Distillation Sampling (SDS) with\nNeural 3D representations. Despite promising results, these approaches\nencounter practical limitations due to lengthy optimizations and significant\nmemory consumption. In this work, we introduce Gamba, an end-to-end 3D\nreconstruction model from a single-view image, emphasizing two main insights:\n(1) Efficient Backbone Design: introducing a Mamba-based GambaFormer network to\nmodel 3D Gaussian Splatting (3DGS) reconstruction as sequential prediction with\nlinear scalability of token length, thereby accommodating a substantial number\nof Gaussians; (2) Robust Gaussian Constraints: deriving radial mask constraints\nfrom multi-view masks to eliminate the need for warmup supervision of 3D point\nclouds in training. We trained Gamba on Objaverse and assessed it against\nexisting optimization-based and feed-forward 3D reconstruction approaches on\nthe GSO Dataset, among which Gamba is the only end-to-end trained single-view\nreconstruction model with 3DGS. Experimental results demonstrate its\ncompetitive generation capabilities both qualitatively and quantitatively and\nhighlight its remarkable speed: Gamba completes reconstruction within 0.05\nseconds on a single NVIDIA A100 GPU, which is about $1,000\\times$ faster than\noptimization-based methods. Please see our project page at\nhttps://florinshen.github.io/gamba-project.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "project page: https://florinshen.github.io/gamba-project",
    "pdf_url": "http://arxiv.org/pdf/2403.18795v3",
    "published_date": "2024-03-27 17:40:14 UTC",
    "updated_date": "2024-05-24 18:43:28 UTC"
  },
  {
    "arxiv_id": "2403.18775v1",
    "title": "ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object",
    "authors": [
      "Chenshuang Zhang",
      "Fei Pan",
      "Junmo Kim",
      "In So Kweon",
      "Chengzhi Mao"
    ],
    "abstract": "We establish rigorous benchmarks for visual perception robustness. Synthetic\nimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific\ntype of evaluation over synthetic corruptions, backgrounds, and textures, yet\nthose robustness benchmarks are restricted in specified variations and have low\nsynthetic quality. In this work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models' robustness. Leveraging\ndiffusion models, we are able to generate images with more diversified\nbackgrounds, textures, and materials than any prior work, where we term this\nbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in a\nsignificant accuracy drop to a range of vision models, from the standard ResNet\nvisual classifier to the latest foundation models like CLIP and MiniGPT-4,\nsignificantly reducing their accuracy by up to 60\\%. Our work suggests that\ndiffusion models can be an effective source to test vision models. The code and\ndataset are available at https://github.com/chenshuang-zhang/imagenet_d.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18775v1",
    "published_date": "2024-03-27 17:23:39 UTC",
    "updated_date": "2024-03-27 17:23:39 UTC"
  },
  {
    "arxiv_id": "2403.18766v1",
    "title": "Superior Parallel Big Data Clustering through Competitive Stochastic Sample Size Optimization in Big-means",
    "authors": [
      "Rustam Mussabayev",
      "Ravil Mussabayev"
    ],
    "abstract": "This paper introduces a novel K-means clustering algorithm, an advancement on\nthe conventional Big-means methodology. The proposed method efficiently\nintegrates parallel processing, stochastic sampling, and competitive\noptimization to create a scalable variant designed for big data applications.\nIt addresses scalability and computation time challenges typically faced with\ntraditional techniques. The algorithm adjusts sample sizes dynamically for each\nworker during execution, optimizing performance. Data from these sample sizes\nare continually analyzed, facilitating the identification of the most efficient\nconfiguration. By incorporating a competitive element among workers using\ndifferent sample sizes, efficiency within the Big-means algorithm is further\nstimulated. In essence, the algorithm balances computational time and\nclustering quality by employing a stochastic, competitive sampling strategy in\na parallel computing setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18766v1",
    "published_date": "2024-03-27 17:05:03 UTC",
    "updated_date": "2024-03-27 17:05:03 UTC"
  },
  {
    "arxiv_id": "2403.18762v1",
    "title": "ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition",
    "authors": [
      "Weidong Xie",
      "Lun Luo",
      "Nanfei Ye",
      "Yi Ren",
      "Shaoyi Du",
      "Minhang Wang",
      "Jintao Xu",
      "Rui Ai",
      "Weihao Gu",
      "Xieyuanli Chen"
    ],
    "abstract": "Place recognition is an important task for robots and autonomous cars to\nlocalize themselves and close loops in pre-built maps. While single-modal\nsensor-based methods have shown satisfactory performance, cross-modal place\nrecognition that retrieving images from a point-cloud database remains a\nchallenging problem. Current cross-modal methods transform images into 3D\npoints using depth estimation for modality conversion, which are usually\ncomputationally intensive and need expensive labeled data for depth\nsupervision. In this work, we introduce a fast and lightweight framework to\nencode images and point clouds into place-distinctive descriptors. We propose\nan effective Field of View (FoV) transformation module to convert point clouds\ninto an analogous modality as images. This module eliminates the necessity for\ndepth estimation and helps subsequent modules achieve real-time performance. We\nfurther design a non-negative factorization-based encoder to extract mutually\nconsistent semantic features between point clouds and images. This encoder\nyields more distinctive global descriptors for retrieval. Experimental results\non the KITTI dataset show that our proposed methods achieve state-of-the-art\nperformance while running in real time. Additional evaluation on the HAOMO\ndataset covering a 17 km trajectory further shows the practical generalization\ncapabilities. We have released the implementation of our methods as open source\nat: https://github.com/haomo-ai/ModaLink.git.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 11 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2403.18762v1",
    "published_date": "2024-03-27 17:01:10 UTC",
    "updated_date": "2024-03-27 17:01:10 UTC"
  },
  {
    "arxiv_id": "2403.18756v1",
    "title": "Detection of subclinical atherosclerosis by image-based deep learning on chest x-ray",
    "authors": [
      "Guglielmo Gallone",
      "Francesco Iodice",
      "Alberto Presta",
      "Davide Tore",
      "Ovidio de Filippo",
      "Michele Visciano",
      "Carlo Alberto Barbano",
      "Alessandro Serafini",
      "Paola Gorrini",
      "Alessandro Bruno",
      "Walter Grosso Marra",
      "James Hughes",
      "Mario Iannaccone",
      "Paolo Fonio",
      "Attilio Fiandrotti",
      "Alessandro Depaoli",
      "Marco Grangetto",
      "Gaetano Maria de Ferrari",
      "Fabrizio D'Ascenzo"
    ],
    "abstract": "Aims. To develop a deep-learning based system for recognition of subclinical\natherosclerosis on a plain frontal chest x-ray. Methods and Results. A\ndeep-learning algorithm to predict coronary artery calcium (CAC) score (the\nAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%\ninternal validation cohort) of primary prevention patients (58.4% male, median\nage 63 [51-74] years) with available paired chest x-ray and chest computed\ntomography (CT) indicated for any clinical reason and performed within 3\nmonths. The CAC score calculated on chest CT was used as ground truth. The\nmodel was validated on an temporally-independent cohort of 90 patients from the\nsame institution (external validation). The diagnostic accuracy of the AI-CAC\nmodel assessed by the area under the curve (AUC) was the primary outcome.\nOverall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.\nAUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation\ncohort and 0.77 in the external validation cohort. Sensitivity was consistently\nabove 92% in both cohorts. In the overall cohort (n=540), among patients with\nAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with\nAI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events\n(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to\naccurately detect subclinical atherosclerosis on chest x-ray with elevated\nsensitivity, and to predict ASCVD events with elevated negative predictive\nvalue. Adoption of the AI-CAC model to refine CV risk stratification or as an\nopportunistic screening tool requires prospective evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to European Heart Journal - Cardiovascular Imaging Added\n  also the additional material 44 pages (30 main paper, 14 additional\n  material), 14 figures (5 main manuscript, 9 additional material)",
    "pdf_url": "http://arxiv.org/pdf/2403.18756v1",
    "published_date": "2024-03-27 16:56:14 UTC",
    "updated_date": "2024-03-27 16:56:14 UTC"
  },
  {
    "arxiv_id": "2403.18755v2",
    "title": "Many-Objective Evolutionary Influence Maximization: Balancing Spread, Budget, Fairness, and Time",
    "authors": [
      "Elia Cunegatti",
      "Leonardo Lucio Custode",
      "Giovanni Iacca"
    ],
    "abstract": "The Influence Maximization (IM) problem seeks to discover the set of nodes in\na graph that can spread the information propagation at most. This problem is\nknown to be NP-hard, and it is usually studied by maximizing the influence\n(spread) and, optionally, optimizing a second objective, such as minimizing the\nseed set size or maximizing the influence fairness. However, in many practical\nscenarios multiple aspects of the IM problem must be optimized at the same\ntime. In this work, we propose a first case study where several IM-specific\nobjective functions, namely budget, fairness, communities, and time, are\noptimized on top of the maximization of influence and minimization of the seed\nset size. To this aim, we introduce MOEIM (Many-Objective Evolutionary\nAlgorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm\n(MOEA) based on NSGA-II incorporating graph-aware operators and a smart\ninitialization. We compare MOEIM in two experimental settings, including a\ntotal of nine graph datasets, two heuristic methods, a related MOEA, and a\nstate-of-the-art Deep Learning approach. The experiments show that MOEIM\noverall outperforms the competitors in most of the tested many-objective\nsettings. To conclude, we also investigate the correlation between the\nobjectives, leading to novel insights into the topic. The codebase is available\nat https://github.com/eliacunegatti/MOEIM.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.NE",
    "comment": "To appear in Genetic and Evolutionary Computation Conference (GECCO\n  24 Companion), July 14 18, 2024, Melbourne, VIC, Australia. ACM, New York,\n  NY, USA",
    "pdf_url": "http://arxiv.org/pdf/2403.18755v2",
    "published_date": "2024-03-27 16:54:45 UTC",
    "updated_date": "2024-03-28 14:05:56 UTC"
  },
  {
    "arxiv_id": "2403.18742v5",
    "title": "Understanding the Learning Dynamics of Alignment with Human Feedback",
    "authors": [
      "Shawn Im",
      "Yixuan Li"
    ],
    "abstract": "Aligning large language models (LLMs) with human intentions has become a\ncritical task for safely deploying models in real-world systems. While existing\nalignment approaches have seen empirical success, theoretically understanding\nhow these methods affect model behavior remains an open question. Our work\nprovides an initial attempt to theoretically analyze the learning dynamics of\nhuman preference alignment. We formally show how the distribution of preference\ndatasets influences the rate of model updates and provide rigorous guarantees\non the training accuracy. Our theory also reveals an intricate phenomenon where\nthe optimization is prone to prioritizing certain behaviors with higher\npreference distinguishability. We empirically validate our findings on\ncontemporary LLMs and alignment tasks, reinforcing our theoretical insights and\nshedding light on considerations for future alignment approaches. Disclaimer:\nThis paper contains potentially offensive text; reader discretion is advised.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18742v5",
    "published_date": "2024-03-27 16:39:28 UTC",
    "updated_date": "2024-08-06 22:33:26 UTC"
  },
  {
    "arxiv_id": "2403.18731v1",
    "title": "Enhancing Manufacturing Quality Prediction Models through the Integration of Explainability Methods",
    "authors": [
      "Dennis Gross",
      "Helge Spieker",
      "Arnaud Gotlieb",
      "Ricardo Knoblauch"
    ],
    "abstract": "This research presents a method that utilizes explainability techniques to\namplify the performance of machine learning (ML) models in forecasting the\nquality of milling processes, as demonstrated in this paper through a\nmanufacturing use case. The methodology entails the initial training of ML\nmodels, followed by a fine-tuning phase where irrelevant features identified\nthrough explainability methods are eliminated. This procedural refinement\nresults in performance enhancements, paving the way for potential reductions in\nmanufacturing costs and a better understanding of the trained ML models. This\nstudy highlights the usefulness of explainability techniques in both explaining\nand optimizing predictive models in the manufacturing realm.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18731v1",
    "published_date": "2024-03-27 16:21:24 UTC",
    "updated_date": "2024-03-27 16:21:24 UTC"
  },
  {
    "arxiv_id": "2403.18725v1",
    "title": "Probabilistic Model Checking of Stochastic Reinforcement Learning Policies",
    "authors": [
      "Dennis Gross",
      "Helge Spieker"
    ],
    "abstract": "We introduce a method to verify stochastic reinforcement learning (RL)\npolicies. This approach is compatible with any RL algorithm as long as the\nalgorithm and its corresponding environment collectively adhere to the Markov\nproperty. In this setting, the future state of the environment should depend\nsolely on its current state and the action executed, independent of any\nprevious states or actions. Our method integrates a verification technique,\nreferred to as model checking, with RL, leveraging a Markov decision process, a\ntrained RL policy, and a probabilistic computation tree logic (PCTL) formula to\nbuild a formal model that can be subsequently verified via the model checker\nStorm. We demonstrate our method's applicability across multiple benchmarks,\ncomparing it to baseline methods called deterministic safety estimates and\nnaive monolithic model checking. Our results show that our method is suited to\nverify stochastic RL policies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18725v1",
    "published_date": "2024-03-27 16:15:21 UTC",
    "updated_date": "2024-03-27 16:15:21 UTC"
  },
  {
    "arxiv_id": "2403.18717v2",
    "title": "Semi-Supervised Learning for Deep Causal Generative Models",
    "authors": [
      "Yasin Ibrahim",
      "Hermione Warr",
      "Konstantinos Kamnitsas"
    ],
    "abstract": "Developing models that are capable of answering questions of the form \"How\nwould x change if y had been z?'\" is fundamental to advancing medical image\nanalysis. Training causal generative models that address such counterfactual\nquestions, though, currently requires that all relevant variables have been\nobserved and that the corresponding labels are available in the training data.\nHowever, clinical data may not have complete records for all patients and state\nof the art causal generative models are unable to take full advantage of this.\nWe thus develop, for the first time, a semi-supervised deep causal generative\nmodel that exploits the causal relationships between variables to maximise the\nuse of all available data. We explore this in the setting where each sample is\neither fully labelled or fully unlabelled, as well as the more clinically\nrealistic case of having different labels missing for each sample. We leverage\ntechniques from causal inference to infer missing values and subsequently\ngenerate realistic counterfactuals, even for samples with incomplete labels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18717v2",
    "published_date": "2024-03-27 16:06:37 UTC",
    "updated_date": "2024-07-12 14:13:41 UTC"
  },
  {
    "arxiv_id": "2403.18715v2",
    "title": "Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding",
    "authors": [
      "Xintong Wang",
      "Jingheng Pan",
      "Liang Ding",
      "Chris Biemann"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) are increasingly adept at generating\ncontextually detailed and coherent responses from visual inputs. However, their\napplication in multimodal decision-making and open-ended generation is hindered\nby a notable rate of hallucinations, where generated text inaccurately\nrepresents the visual contents. To address this issue, this paper introduces\nthe Instruction Contrastive Decoding (ICD) method, a novel approach designed to\nreduce hallucinations during LVLM inference. Our method is inspired by our\nobservation that what we call disturbance instructions significantly exacerbate\nhallucinations in multimodal fusion modules. ICD contrasts distributions from\nstandard and instruction disturbance, thereby increasing alignment uncertainty\nand effectively subtracting hallucinated concepts from the original\ndistribution. Through comprehensive experiments on discriminative benchmarks\n(POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that\nICD significantly mitigates both object-level and attribute-level\nhallucinations. Moreover, our method not only addresses hallucinations but also\nsignificantly enhances the general perception and recognition capabilities of\nLVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18715v2",
    "published_date": "2024-03-27 16:04:47 UTC",
    "updated_date": "2024-06-05 13:53:42 UTC"
  },
  {
    "arxiv_id": "2403.18711v1",
    "title": "SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable Transient-Free 3D reconstruction from Satellite Imagery",
    "authors": [
      "Camille Billouard",
      "Dawa Derksen",
      "Emmanuelle Sarrazin",
      "Bruno Vallet"
    ],
    "abstract": "Current stereo-vision pipelines produce high accuracy 3D reconstruction when\nusing multiple pairs or triplets of satellite images. However, these pipelines\nare sensitive to the changes between images that can occur as a result of\nmulti-date acquisitions. Such variations are mainly due to variable shadows,\nreflexions and transient objects (cars, vegetation). To take such changes into\naccount, Neural Radiance Fields (NeRF) have recently been applied to multi-date\nsatellite imagery. However, Neural methods are very compute-intensive, taking\ndozens of hours to learn, compared with minutes for standard stereo-vision\npipelines. Following the ideas of Instant Neural Graphics Primitives we propose\nto use an efficient sampling strategy and multi-resolution hash encoding to\naccelerate the learning. Our model, Satellite Neural Graphics Primitives\n(SAT-NGP) decreases the learning time to 15 minutes while maintaining the\nquality of the 3D reconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures, 1 table; Accepted to International Geoscience and\n  Remote Sensing Symposium (IGARSS) 2024; Code available at\n  https://github.com/Ellimac0/SAT-NGP",
    "pdf_url": "http://arxiv.org/pdf/2403.18711v1",
    "published_date": "2024-03-27 15:58:25 UTC",
    "updated_date": "2024-03-27 15:58:25 UTC"
  },
  {
    "arxiv_id": "2403.18699v2",
    "title": "Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)",
    "authors": [
      "Huanran Li",
      "Manh Nguyen",
      "Daniel Pimentel-Alarcón"
    ],
    "abstract": "Contrastive learning has emerged as a powerful method in deep learning,\nexcelling at learning effective representations through contrasting samples\nfrom different distributions. However, neural collapse, where embeddings\nconverge into a lower-dimensional space, poses a significant challenge,\nespecially in semi-supervised and self-supervised setups. In this paper, we\nfirst theoretically analyze the effect of large learning rates on contrastive\nlosses that solely rely on the cosine similarity metric, and derive a\ntheoretical bound to mitigate this collapse. {Building on these insights, we\npropose CLOP, a novel semi-supervised loss function designed to prevent neural\ncollapse by promoting the formation of orthogonal linear subspaces among class\nembeddings.} Unlike prior approaches that enforce a simplex ETF structure, CLOP\nfocuses on subspace separation, leading to more distinguishable embeddings.\nThrough extensive experiments on real and synthetic datasets, we demonstrate\nthat CLOP enhances performance, providing greater stability across different\nlearning rates and batch sizes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.18699v2",
    "published_date": "2024-03-27 15:48:16 UTC",
    "updated_date": "2024-10-07 16:07:23 UTC"
  },
  {
    "arxiv_id": "2403.18690v1",
    "title": "Annolid: Annotate, Segment, and Track Anything You Need",
    "authors": [
      "Chen Yang",
      "Thomas A. Cleland"
    ],
    "abstract": "Annolid is a deep learning-based software package designed for the\nsegmentation, labeling, and tracking of research targets within video files,\nfocusing primarily on animal behavior analysis. Based on state-of-the-art\ninstance segmentation methods, Annolid now harnesses the Cutie video object\nsegmentation model to achieve resilient, markerless tracking of multiple\nanimals from single annotated frames, even in environments in which they may be\npartially or entirely concealed by environmental features or by one another.\nOur integration of Segment Anything and Grounding-DINO strategies additionally\nenables the automatic masking and segmentation of recognizable animals and\nobjects by text command, removing the need for manual annotation. Annolid's\ncomprehensive approach to object segmentation flexibly accommodates a broad\nspectrum of behavior analysis applications, enabling the classification of\ndiverse behavioral states such as freezing, digging, pup huddling, and social\ninteractions in addition to the tracking of animals and their body parts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18690v1",
    "published_date": "2024-03-27 15:41:23 UTC",
    "updated_date": "2024-03-27 15:41:23 UTC"
  },
  {
    "arxiv_id": "2403.18681v2",
    "title": "Deep Fusion: Capturing Dependencies in Contrastive Learning via Transformer Projection Heads",
    "authors": [
      "Huanran Li",
      "Daniel Pimentel-Alarcón"
    ],
    "abstract": "Contrastive Learning (CL) has emerged as a powerful method for training\nfeature extraction models using unlabeled data. Recent studies suggest that\nincorporating a linear projection head post-backbone significantly enhances\nmodel performance. In this work, we investigate the use of a transformer model\nas a projection head within the CL framework, aiming to exploit the\ntransformer's capacity for capturing long-range dependencies across embeddings\nto further improve performance. Our key contributions are fourfold: First, we\nintroduce a novel application of transformers in the projection head role for\ncontrastive learning, marking the first endeavor of its kind. Second, our\nexperiments reveal a compelling \"Deep Fusion\" phenomenon where the attention\nmechanism progressively captures the correct relational dependencies among\nsamples from the same class in deeper layers. Third, we provide a theoretical\nframework that explains and supports this \"Deep Fusion\" behavior. Finally, we\ndemonstrate through experimental results that our model achieves superior\nperformance compared to the existing approach of using a feed-forward layer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.18681v2",
    "published_date": "2024-03-27 15:24:54 UTC",
    "updated_date": "2024-10-07 16:25:02 UTC"
  },
  {
    "arxiv_id": "2403.18668v1",
    "title": "Aiming for Relevance",
    "authors": [
      "Bar Eini Porat",
      "Danny Eytan",
      "Uri Shalit"
    ],
    "abstract": "Vital signs are crucial in intensive care units (ICUs). They are used to\ntrack the patient's state and to identify clinically significant changes.\nPredicting vital sign trajectories is valuable for early detection of adverse\nevents. However, conventional machine learning metrics like RMSE often fail to\ncapture the true clinical relevance of such predictions. We introduce novel\nvital sign prediction performance metrics that align with clinical contexts,\nfocusing on deviations from clinical norms, overall trends, and trend\ndeviations. These metrics are derived from empirical utility curves obtained in\na previous study through interviews with ICU clinicians. We validate the\nmetrics' usefulness using simulated and real clinical datasets (MIMIC and\neICU). Furthermore, we employ these metrics as loss functions for neural\nnetworks, resulting in models that excel in predicting clinically significant\nevents. This research paves the way for clinically relevant machine learning\nmodel evaluation and optimization, promising to improve ICU patient care. 10\npages, 9 figures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 9 figures, AMIA Informatics 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18668v1",
    "published_date": "2024-03-27 15:11:07 UTC",
    "updated_date": "2024-03-27 15:11:07 UTC"
  },
  {
    "arxiv_id": "2403.18659v1",
    "title": "INEXA: Interactive and Explainable Process Model Abstraction Through Object-Centric Process Mining",
    "authors": [
      "Janik-Vasily Benzin",
      "Gyunam Park",
      "Juergen Mangler",
      "Stefanie Rinderle-Ma"
    ],
    "abstract": "Process events are recorded by multiple information systems at different\ngranularity levels. Based on the resulting event logs, process models are\ndiscovered at different granularity levels, as well. Events stored at a\nfine-grained granularity level, for example, may hinder the discovered process\nmodel to be displayed due the high number of resulting model elements. The\ndiscovered process model of a real-world manufacturing process, for example,\nconsists of 1,489 model elements and over 2,000 arcs. Existing process model\nabstraction techniques could help reducing the size of the model, but would\ndisconnect it from the underlying event log. Existing event abstraction\ntechniques do neither support the analysis of mixed granularity levels, nor\ninteractive exploration of a suitable granularity level. To enable the\nexploration of discovered process models at different granularity levels, we\npropose INEXA, an interactive, explainable process model abstraction method\nthat keeps the link to the event log. As a starting point, INEXA aggregates\nlarge process models to a \"displayable\" size, e.g., for the manufacturing use\ncase to a process model with 58 model elements. Then, the process analyst can\nexplore granularity levels interactively, while applied abstractions are\nautomatically traced in the event log for explainability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18659v1",
    "published_date": "2024-03-27 15:03:33 UTC",
    "updated_date": "2024-03-27 15:03:33 UTC"
  },
  {
    "arxiv_id": "2403.18607v1",
    "title": "Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices",
    "authors": [
      "Hanqing Fu",
      "Gaolei Li",
      "Jun Wu",
      "Jianhua Li",
      "Xi Lin",
      "Kai Zhou",
      "Yuchen Liu"
    ],
    "abstract": "Federated neuromorphic learning (FedNL) leverages event-driven spiking neural\nnetworks and federated learning frameworks to effectively execute intelligent\nanalysis tasks over amounts of distributed low-power devices but also perform\nvulnerability to poisoning attacks. The threat of backdoor attacks on\ntraditional deep neural networks typically comes from time-invariant data.\nHowever, in FedNL, unknown threats may be hidden in time-varying spike signals.\nIn this paper, we start to explore a novel vulnerability of FedNL-based systems\nwith the concept of time division multiplexing, termed Spikewhisper, which\nallows attackers to evade detection as much as possible, as multiple malicious\nclients can imperceptibly poison with different triggers at different\ntimeslices. In particular, the stealthiness of Spikewhisper is derived from the\ntime-domain divisibility of global triggers, in which each malicious client\npastes only one local trigger to a certain timeslice in the neuromorphic\nsample, and also the polarity and motion of each local trigger can be\nconfigured by attackers. Extensive experiments based on two different\nneuromorphic datasets demonstrate that the attack success rate of Spikewispher\nis higher than the temporally centralized attacks. Besides, it is validated\nthat the effect of Spikewispher is sensitive to the trigger duration.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18607v1",
    "published_date": "2024-03-27 14:25:02 UTC",
    "updated_date": "2024-03-27 14:25:02 UTC"
  },
  {
    "arxiv_id": "2403.18600v2",
    "title": "RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in Instructional Videos",
    "authors": [
      "Ali Zare",
      "Yulei Niu",
      "Hammad Ayyubi",
      "Shih-fu Chang"
    ],
    "abstract": "Procedure Planning in instructional videos entails generating a sequence of\naction steps based on visual observations of the initial and target states.\nDespite the rapid progress in this task, there remain several critical\nchallenges to be solved: (1) Adaptive procedures: Prior works hold an\nunrealistic assumption that the number of action steps is known and fixed,\nleading to non-generalizable models in real-world scenarios where the sequence\nlength varies. (2) Temporal relation: Understanding the step temporal relation\nknowledge is essential in producing reasonable and executable plans. (3)\nAnnotation cost: Annotating instructional videos with step-level labels (i.e.,\ntimestamp) or sequence-level labels (i.e., action category) is demanding and\nlabor-intensive, limiting its generalizability to large-scale datasets. In this\nwork, we propose a new and practical setting, called adaptive procedure\nplanning in instructional videos, where the procedure length is not fixed or\npre-determined. To address these challenges, we introduce Retrieval-Augmented\nPlanner (RAP) model. Specifically, for adaptive procedures, RAP adaptively\ndetermines the conclusion of actions using an auto-regressive model\narchitecture. For temporal relation, RAP establishes an external memory module\nto explicitly retrieve the most relevant state-action pairs from the training\nvideos and revises the generated procedures. To tackle high annotation cost,\nRAP utilizes a weakly-supervised learning manner to expand the training dataset\nto other task-relevant, unannotated videos by generating pseudo labels for\naction steps. Experiments on CrossTask and COIN benchmarks show the superiority\nof RAP over traditional fixed-length models, establishing it as a strong\nbaseline solution for adaptive procedure planning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18600v2",
    "published_date": "2024-03-27 14:22:40 UTC",
    "updated_date": "2024-09-25 14:20:39 UTC"
  },
  {
    "arxiv_id": "2403.18593v2",
    "title": "Homogeneous Tokenizer Matters: Homogeneous Visual Tokenizer for Remote Sensing Image Understanding",
    "authors": [
      "Run Shao",
      "Zhaoyang Zhang",
      "Chao Tao",
      "Yunsheng Zhang",
      "Chengli Peng",
      "Haifeng Li"
    ],
    "abstract": "The tokenizer, as one of the fundamental components of large models, has long\nbeen overlooked or even misunderstood in visual tasks. One key factor of the\ngreat comprehension power of the large language model is that natural language\ntokenizers utilize meaningful words or subwords as the basic elements of\nlanguage. In contrast, mainstream visual tokenizers, represented by patch-based\nmethods such as Patch Embed, rely on meaningless rectangular patches as basic\nelements of vision, which cannot serve as effectively as words or subwords in\nlanguage. Starting from the essence of the tokenizer, we defined semantically\nindependent regions (SIRs) for vision. We designed a simple HOmogeneous visual\ntOKenizer: HOOK. HOOK mainly consists of two modules: the Object Perception\nModule (OPM) and the Object Vectorization Module (OVM). To achieve homogeneity,\nthe OPM splits the image into 4*4 pixel seeds and then utilizes the attention\nmechanism to perceive SIRs. The OVM employs cross-attention to merge seeds\nwithin the same SIR. To achieve adaptability, the OVM defines a variable number\nof learnable vectors as cross-attention queries, allowing for the adjustment of\ntoken quantity. We conducted experiments on the NWPU-RESISC45, WHU-RS19\nclassification dataset, and GID5 segmentation dataset for sparse and dense\ntasks. The results demonstrate that the visual tokens obtained by HOOK\ncorrespond to individual objects, which demonstrates homogeneity. HOOK\noutperformed Patch Embed by 6\\% and 10\\% in the two tasks and achieved\nstate-of-the-art performance compared to the baselines used for comparison.\nCompared to Patch Embed, which requires more than one hundred tokens for one\nimage, HOOK requires only 6 and 8 tokens for sparse and dense tasks,\nrespectively, resulting in efficiency improvements of 1.5 to 2.8 times. The\ncode is available at https://github.com/GeoX-Lab/Hook.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages, 9 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.18593v2",
    "published_date": "2024-03-27 14:18:09 UTC",
    "updated_date": "2024-10-13 03:01:11 UTC"
  },
  {
    "arxiv_id": "2403.18570v1",
    "title": "Physics-Informed Graph Neural Networks for Water Distribution Systems",
    "authors": [
      "Inaam Ashraf",
      "Janine Strotherm",
      "Luca Hermes",
      "Barbara Hammer"
    ],
    "abstract": "Water distribution systems (WDS) are an integral part of critical\ninfrastructure which is pivotal to urban development. As 70% of the world's\npopulation will likely live in urban environments in 2050, efficient simulation\nand planning tools for WDS play a crucial role in reaching UN's sustainable\ndevelopmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this\nrealm, we propose a novel and efficient machine learning emulator, more\nprecisely, a physics-informed deep learning (DL) model, for hydraulic state\nestimation in WDS. Using a recursive approach, our model only needs a few graph\nconvolutional neural network (GCN) layers and employs an innovative algorithm\nbased on message passing. Unlike conventional machine learning tasks, the model\nuses hydraulic principles to infer two additional hydraulic state features in\nthe process of reconstructing the available ground truth feature in an\nunsupervised manner. To the best of our knowledge, this is the first DL\napproach to emulate the popular hydraulic simulator EPANET, utilizing no\nadditional information. Like most DL models and unlike the hydraulic simulator,\nour model demonstrates vastly faster emulation times that do not increase\ndrastically with the size of the WDS. Moreover, we achieve high accuracy on the\nground truth and very similar results compared to the hydraulic simulator as\ndemonstrated through experiments on five real-world WDS datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of the paper with the same title published at\n  Proceedings of the AAAI Conference on Artificial Intelligence 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18570v1",
    "published_date": "2024-03-27 13:51:26 UTC",
    "updated_date": "2024-03-27 13:51:26 UTC"
  },
  {
    "arxiv_id": "2403.18569v2",
    "title": "PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop Prediction",
    "authors": [
      "Yuxiang Zhao",
      "Zhuomin Chai",
      "Xun Jiang",
      "Yibo Lin",
      "Runsheng Wang",
      "Ru Huang"
    ],
    "abstract": "IR drop on the power delivery network (PDN) is closely related to PDN's\nconfiguration and cell current consumption. As the integrated circuit (IC)\ndesign is growing larger, dynamic IR drop simulation becomes computationally\nunaffordable and machine learning based IR drop prediction has been explored as\na promising solution. Although CNN-based methods have been adapted to IR drop\nprediction task in several works, the shortcomings of overlooking PDN\nconfiguration is non-negligible. In this paper, we consider not only how to\nproperly represent cell-PDN relation, but also how to model IR drop following\nits physical nature in the feature aggregation procedure. Thus, we propose a\nnovel graph structure, PDNGraph, to unify the representations of the PDN\nstructure and the fine-grained cell-PDN relation. We further propose a\ndual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN\nbranches to favorably capture the above features during the learning process.\nSeveral key designs are presented to make the dynamic IR drop prediction highly\neffective and interpretable. We are the first work to apply graph structure to\ndeep-learning based dynamic IR drop prediction method. Experiments show that\nPDNNet outperforms the state-of-the-art CNN-based methods and achieves 545x\nspeedup compared to the commercial tool, which demonstrates the superiority of\nour method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18569v2",
    "published_date": "2024-03-27 13:50:13 UTC",
    "updated_date": "2024-12-05 09:02:11 UTC"
  },
  {
    "arxiv_id": "2404.01317v1",
    "title": "Intelligent Learning Rate Distribution to reduce Catastrophic Forgetting in Transformers",
    "authors": [
      "Philip Kenneweg",
      "Alexander Schulz",
      "Sarah Schröder",
      "Barbara Hammer"
    ],
    "abstract": "Pretraining language models on large text corpora is a common practice in\nnatural language processing. Fine-tuning of these models is then performed to\nachieve the best results on a variety of tasks. In this paper, we investigate\nthe problem of catastrophic forgetting in transformer neural networks and\nquestion the common practice of fine-tuning with a flat learning rate for the\nentire network in this context. We perform a hyperparameter optimization\nprocess to find learning rate distributions that are better than a flat\nlearning rate. We combine the learning rate distributions thus found and show\nthat they generalize to better performance with respect to the problem of\ncatastrophic forgetting. We validate these learning rate distributions with a\nvariety of NLP benchmarks from the GLUE dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.01317v1",
    "published_date": "2024-03-27 13:40:09 UTC",
    "updated_date": "2024-03-27 13:40:09 UTC"
  },
  {
    "arxiv_id": "2403.18547v1",
    "title": "Neural Architecture Search for Sentence Classification with BERT",
    "authors": [
      "Philip Kenneweg",
      "Sarah Schröder",
      "Barbara Hammer"
    ],
    "abstract": "Pre training of language models on large text corpora is common practice in\nNatural Language Processing. Following, fine tuning of these models is\nperformed to achieve the best results on a variety of tasks. In this paper we\nquestion the common practice of only adding a single output layer as a\nclassification head on top of the network. We perform an AutoML search to find\narchitectures that outperform the current single layer at only a small compute\ncost. We validate our classification architecture on a variety of NLP\nbenchmarks from the GLUE dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18547v1",
    "published_date": "2024-03-27 13:25:43 UTC",
    "updated_date": "2024-03-27 13:25:43 UTC"
  },
  {
    "arxiv_id": "2403.18546v2",
    "title": "Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes",
    "authors": [
      "Siang Chen",
      "Wei Tang",
      "Pengwei Xie",
      "Wenming Yang",
      "Guijin Wang"
    ],
    "abstract": "Fast and robust object grasping in clutter is a crucial component of\nrobotics. Most current works resort to the whole observed point cloud for 6-Dof\ngrasp generation, ignoring the guidance information excavated from global\nsemantics, thus limiting high-quality grasp generation and real-time\nperformance. In this work, we show that the widely used heatmaps are\nunderestimated in the efficiency of 6-Dof grasp generation. Therefore, we\npropose an effective local grasp generator combined with grasp heatmaps as\nguidance, which infers in a global-to-local semantic-to-point way.\nSpecifically, Gaussian encoding and the grid-based strategy are applied to\npredict grasp heatmaps as guidance to aggregate local points into graspable\nregions and provide global semantic information. Further, a novel non-uniform\nanchor sampling mechanism is designed to improve grasp accuracy and diversity.\nBenefiting from the high-efficiency encoding in the image space and focusing on\npoints in local graspable regions, our framework can perform high-quality grasp\ndetection in real-time and achieve state-of-the-art results. In addition, real\nrobot experiments demonstrate the effectiveness of our method with a success\nrate of 94% and a clutter completion rate of 100%. Our code is available at\nhttps://github.com/THU-VCLab/HGGD.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Extensive results on GraspNet-1B dataset",
    "pdf_url": "http://arxiv.org/pdf/2403.18546v2",
    "published_date": "2024-03-27 13:24:58 UTC",
    "updated_date": "2024-05-14 01:17:29 UTC"
  },
  {
    "arxiv_id": "2403.18537v1",
    "title": "A Path Towards Legal Autonomy: An interoperable and explainable approach to extracting, transforming, loading and computing legal information using large language models, expert systems and Bayesian networks",
    "authors": [
      "Axel Constant",
      "Hannes Westermann",
      "Bryan Wilson",
      "Alex Kiefer",
      "Ines Hipolito",
      "Sylvain Pronovost",
      "Steven Swanson",
      "Mahault Albarracin",
      "Maxwell J. D. Ramstead"
    ],
    "abstract": "Legal autonomy - the lawful activity of artificial intelligence agents - can\nbe achieved in one of two ways. It can be achieved either by imposing\nconstraints on AI actors such as developers, deployers and users, and on AI\nresources such as data, or by imposing constraints on the range and scope of\nthe impact that AI agents can have on the environment. The latter approach\ninvolves encoding extant rules concerning AI driven devices into the software\nof AI agents controlling those devices (e.g., encoding rules about limitations\non zones of operations into the agent software of an autonomous drone device).\nThis is a challenge since the effectivity of such an approach requires a method\nof extracting, loading, transforming and computing legal information that would\nbe both explainable and legally interoperable, and that would enable AI agents\nto reason about the law. In this paper, we sketch a proof of principle for such\na method using large language models (LLMs), expert legal systems known as\nlegal decision paths, and Bayesian networks. We then show how the proposed\nmethod could be applied to extant regulation in matters of autonomous cars,\nsuch as the California Vehicle Code.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18537v1",
    "published_date": "2024-03-27 13:12:57 UTC",
    "updated_date": "2024-03-27 13:12:57 UTC"
  },
  {
    "arxiv_id": "2403.18536v1",
    "title": "A Novel Behavior-Based Recommendation System for E-commerce",
    "authors": [
      "Reza Barzegar Nozari",
      "Mahdi Divsalar",
      "Sepehr Akbarzadeh Abkenar",
      "Mohammadreza Fadavi Amiri",
      "Ali Divsalar"
    ],
    "abstract": "The majority of existing recommender systems rely on user ratings, which are\nlimited by the lack of user collaboration and the sparsity problem. To address\nthese issues, this study proposes a behavior-based recommender system that\nleverages customers' natural behaviors, such as browsing and clicking, on\ne-commerce platforms. The proposed recommendation system involves clustering\nactive customers, determining neighborhoods, collecting similar users,\ncalculating product reputation based on similar users, and recommending\nhigh-reputation products. To overcome the complexity of customer behaviors and\ntraditional clustering methods, an unsupervised clustering approach based on\nproduct categories is developed to enhance the recommendation methodology. This\nstudy makes notable contributions in several aspects. Firstly, a groundbreaking\nbehavior-based recommendation methodology is developed, incorporating customer\nbehavior to generate accurate and tailored recommendations leading to improved\ncustomer satisfaction and engagement. Secondly, an original unsupervised\nclustering method, focusing on product categories, enables more precise\nclustering and facilitates accurate recommendations. Finally, an approach to\ndetermine neighborhoods for active customers within clusters is established,\nensuring grouping of customers with similar behavioral patterns to enhance\nrecommendation accuracy and relevance. The proposed recommendation methodology\nand clustering method contribute to improved recommendation performance,\noffering valuable insights for researchers and practitioners in the field of\ne-commerce recommendation systems. Additionally, the proposed method\noutperforms benchmark methods in experiments conducted using a behavior dataset\nfrom the well-known e-commerce site Alibaba.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18536v1",
    "published_date": "2024-03-27 13:12:41 UTC",
    "updated_date": "2024-03-27 13:12:41 UTC"
  },
  {
    "arxiv_id": "2403.18519v1",
    "title": "Improving Line Search Methods for Large Scale Neural Network Training",
    "authors": [
      "Philip Kenneweg",
      "Tristan Kenneweg",
      "Barbara Hammer"
    ],
    "abstract": "In recent studies, line search methods have shown significant improvements in\nthe performance of traditional stochastic gradient descent techniques,\neliminating the need for a specific learning rate schedule. In this paper, we\nidentify existing issues in state-of-the-art line search methods, propose\nenhancements, and rigorously evaluate their effectiveness. We test these\nmethods on larger datasets and more complex data domains than before.\nSpecifically, we improve the Armijo line search by integrating the momentum\nterm from ADAM in its search direction, enabling efficient large-scale\ntraining, a task that was previously prone to failure using Armijo line search\nmethods. Our optimization approach outperforms both the previous Armijo\nimplementation and tuned learning rate schedules for Adam. Our evaluation\nfocuses on Transformers and CNNs in the domains of NLP and image data. Our work\nis publicly available as a Python package, which provides a hyperparameter free\nPytorch optimizer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18519v1",
    "published_date": "2024-03-27 12:50:27 UTC",
    "updated_date": "2024-03-27 12:50:27 UTC"
  },
  {
    "arxiv_id": "2403.18506v1",
    "title": "Faster Convergence for Transformer Fine-tuning with Line Search Methods",
    "authors": [
      "Philip Kenneweg",
      "Leonardo Galli",
      "Tristan Kenneweg",
      "Barbara Hammer"
    ],
    "abstract": "Recent works have shown that line search methods greatly increase performance\nof traditional stochastic gradient descent methods on a variety of datasets and\narchitectures [1], [2]. In this work we succeed in extending line search\nmethods to the novel and highly popular Transformer architecture and dataset\ndomains in natural language processing. More specifically, we combine the\nArmijo line search with the Adam optimizer and extend it by subdividing the\nnetworks architecture into sensible units and perform the line search\nseparately on these local units. Our optimization method outperforms the\ntraditional Adam optimizer and achieves significant performance improvements\nfor small data sets or small training budgets, while performing equal or better\nfor other tested cases. Our work is publicly available as a python package,\nwhich provides a hyperparameter-free pytorch optimizer that is compatible with\narbitrary network architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18506v1",
    "published_date": "2024-03-27 12:35:23 UTC",
    "updated_date": "2024-03-27 12:35:23 UTC"
  },
  {
    "arxiv_id": "2403.18489v1",
    "title": "Impact of Employing Weather Forecast Data as Input to the Estimation of Evapotranspiration by Deep Neural Network Models",
    "authors": [
      "Pedro J. Vaz",
      "Gabriela Schütz",
      "Carlos Guerrero",
      "Pedro J. S. Cardoso"
    ],
    "abstract": "Reference Evapotranspiration (ET0) is a key parameter for designing smart\nirrigation scheduling, since it is related by a coefficient to the water needs\nof a crop. The United Nations Food and Agriculture Organization, proposed a\nstandard method for ET0 computation (FAO56PM), based on the parameterization of\nthe Penman-Monteith equation, that is widely adopted in the literature. To\ncompute ET0 using the FAO56-PM method, four main weather parameters are needed:\ntemperature, humidity, wind, and solar radiation (SR). One way to make daily\nET0 estimations for future days is to use freely available weather forecast\nservices (WFSs), where many meteorological parameters are estimated up to the\nnext 15 days. A problem with this method is that currently, SR is not provided\nas a free forecast parameter on most of those online services or, normally,\nsuch forecasts present a financial cost penalty. For this reason, several ET0\nestimation models using machine and deep learning were developed and presented\nin the literature, that use as input features a reduced set of carefully\nselected weather parameters, that are compatible with common freely available\nWFSs. However, most studies on this topic have only evaluated model performance\nusing data from weather stations (WSs), without considering the effect of using\nweather forecast data. In this study, the performance of authors' previous\nmodels is evaluated when using weather forecast data from two online WFSs, in\nthe following scenarios: (i) direct ET0 estimation by an ANN model, and (ii)\nestimate SR by ANN model, and then use that estimation for ET0 computation,\nusing the FAO56-PM method. Employing data collected from two WFSs and a WS\nlocated in Vale do Lobo, Portugal, the latter approach achieved the best\nresult, with a coefficient of determination (R2) ranging between 0.893 and\n0.667, when considering forecasts up to 15 days.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "A partial version of the work submitted to ESRE/INTERNATIONAL\n  CONFERENCE ON ENVIRONMENTAL SCIENCES AND RENEWABLE ENERGY",
    "pdf_url": "http://arxiv.org/pdf/2403.18489v1",
    "published_date": "2024-03-27 12:01:51 UTC",
    "updated_date": "2024-03-27 12:01:51 UTC"
  },
  {
    "arxiv_id": "2403.18486v1",
    "title": "Synthesizing EEG Signals from Event-Related Potential Paradigms with Conditional Diffusion Models",
    "authors": [
      "Guido Klein",
      "Pierre Guetschel",
      "Gianluigi Silvestri",
      "Michael Tangermann"
    ],
    "abstract": "Data scarcity in the brain-computer interface field can be alleviated through\nthe use of generative models, specifically diffusion models. While diffusion\nmodels have previously been successfully applied to electroencephalogram (EEG)\ndata, existing models lack flexibility w.r.t.~sampling or require alternative\nrepresentations of the EEG data. To overcome these limitations, we introduce a\nnovel approach to conditional diffusion models that utilizes classifier-free\nguidance to directly generate subject-, session-, and class-specific EEG data.\nIn addition to commonly used metrics, domain-specific metrics are employed to\nevaluate the specificity of the generated samples. The results indicate that\nthe proposed model can generate EEG data that resembles real data for each\nsubject, session, and class.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "I.2.6; G.3; I.5.4; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "submitted to 9th Graz BCI conference, 6 pages, 3 figures, first\n  figure is split into two subfigures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2403.18486v1",
    "published_date": "2024-03-27 11:58:45 UTC",
    "updated_date": "2024-03-27 11:58:45 UTC"
  },
  {
    "arxiv_id": "2403.18469v1",
    "title": "Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain Adaptive Segmentation of 3D Point Clouds",
    "authors": [
      "Zhimin Yuan",
      "Wankang Zeng",
      "Yanfei Su",
      "Weiquan Liu",
      "Ming Cheng",
      "Yulan Guo",
      "Cheng Wang"
    ],
    "abstract": "3D synthetic-to-real unsupervised domain adaptive segmentation is crucial to\nannotating new domains. Self-training is a competitive approach for this task,\nbut its performance is limited by different sensor sampling patterns (i.e.,\nvariations in point density) and incomplete training strategies. In this work,\nwe propose a density-guided translator (DGT), which translates point density\nbetween domains, and integrates it into a two-stage self-training pipeline\nnamed DGT-ST. First, in contrast to existing works that simultaneously conduct\ndata generation and feature/output alignment within unstable adversarial\ntraining, we employ the non-learnable DGT to bridge the domain gap at the input\nlevel. Second, to provide a well-initialized model for self-training, we\npropose a category-level adversarial network in stage one that utilizes the\nprototype to prevent negative transfer. Finally, by leveraging the designs\nabove, a domain-mixed self-training method with source-aware consistency loss\nis proposed in stage two to narrow the domain gap further. Experiments on two\nsynthetic-to-real segmentation tasks (SynLiDAR $\\rightarrow$ semanticKITTI and\nSynLiDAR $\\rightarrow$ semanticPOSS) demonstrate that DGT-ST outperforms\nstate-of-the-art methods, achieving 9.4$\\%$ and 4.3$\\%$ mIoU improvements,\nrespectively. Code is available at \\url{https://github.com/yuan-zm/DGT-ST}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18469v1",
    "published_date": "2024-03-27 11:28:57 UTC",
    "updated_date": "2024-03-27 11:28:57 UTC"
  },
  {
    "arxiv_id": "2403.18459v1",
    "title": "CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration",
    "authors": [
      "Marina Ionova",
      "Jan Kristof Behrens"
    ],
    "abstract": "Assembly processes involving humans and robots are challenging scenarios\nbecause the individual activities and access to shared workspace have to be\ncoordinated. Fixed robot programs leave no room to diverge from a fixed\nprotocol. Working on such a process can be stressful for the user and lead to\nineffective behavior or failure. We propose a novel approach of online\nconstraint-based scheduling in a reactive execution control framework\nfacilitating behavior trees called CoBOS. This allows the robot to adapt to\nuncertain events such as delayed activity completions and activity selection\n(by the human). The user will experience less stress as the robotic coworkers\nadapt their behavior to best complement the human-selected activities to\ncomplete the common task. In addition to the improved working conditions, our\nalgorithm leads to increased efficiency, even in highly uncertain scenarios. We\nevaluate our algorithm using a probabilistic simulation study with 56000\nexperiments. We outperform all baselines by a margin of 4-10%. Initial real\nrobot experiments using a Franka Emika Panda robot and human tracking based on\nHTC Vive VR gloves look promising.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.18459v1",
    "published_date": "2024-03-27 11:18:01 UTC",
    "updated_date": "2024-03-27 11:18:01 UTC"
  },
  {
    "arxiv_id": "2403.18451v1",
    "title": "CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in Resource-Constrained CPS and IoT",
    "authors": [
      "Yi Hu",
      "Jinhang Zuo",
      "Alanis Zhao",
      "Bob Iannucci",
      "Carlee Joe-Wong"
    ],
    "abstract": "Foundation models (FMs) emerge as a promising solution to harness distributed\nand diverse environmental data by leveraging prior knowledge to understand the\ncomplicated temporal and spatial correlations within heterogeneous datasets.\nUnlike distributed learning frameworks such as federated learning, which often\nstruggle with multimodal data, FMs can transform diverse inputs into\nembeddings. This process facilitates the integration of information from\nvarious modalities and the application of prior learning to new domains.\nHowever, deploying FMs in resource-constrained edge systems poses significant\nchallenges. To this end, we introduce CoRAST, a novel learning framework that\nutilizes FMs for enhanced analysis of distributed, correlated heterogeneous\ndata. Utilizing a server-based FM, CoRAST can exploit existing environment\ninformation to extract temporal, spatial, and cross-modal correlations among\nsensor data. This enables CoRAST to offer context-aware insights for localized\nclient tasks through FM-powered global representation learning. Our evaluation\non real-world weather dataset demonstrates CoRAST's ability to exploit\ncorrelated heterogeneous data through environmental representation learning to\nreduce the forecast errors by up to 50.3% compared to the baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted and to be published in 2024 IEEE International Workshop on\n  Foundation Models for Cyber-Physical Systems & Internet of Things (FMSys)",
    "pdf_url": "http://arxiv.org/pdf/2403.18451v1",
    "published_date": "2024-03-27 11:11:06 UTC",
    "updated_date": "2024-03-27 11:11:06 UTC"
  },
  {
    "arxiv_id": "2403.18425v1",
    "title": "U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models",
    "authors": [
      "Ilias Mitsouras",
      "Eleftherios Tsonis",
      "Paraskevi Tzouveli",
      "Athanasios Voulodimos"
    ],
    "abstract": "Diffusion models have demonstrated remarkable performance in text-to-image\nsynthesis, producing realistic and high resolution images that faithfully\nadhere to the corresponding text-prompts. Despite their great success, they\nstill fall behind in sketch-to-image synthesis tasks, where in addition to\ntext-prompts, the spatial layout of the generated images has to closely follow\nthe outlines of certain reference sketches. Employing an MLP latent edge\npredictor to guide the spatial layout of the synthesized image by predicting\nedge maps at each denoising step has been recently proposed. Despite yielding\npromising results, the pixel-wise operation of the MLP does not take into\naccount the spatial layout as a whole, and demands numerous denoising\niterations to produce satisfactory images, leading to time inefficiency. To\nthis end, we introduce U-Sketch, a framework featuring a U-Net type latent edge\npredictor, which is capable of efficiently capturing both local and global\nfeatures, as well as spatial correlations between pixels. Moreover, we propose\nthe addition of a sketch simplification network that offers the user the choice\nof preprocessing and simplifying input sketches for enhanced outputs. The\nexperimental results, corroborated by user feedback, demonstrate that our\nproposed U-Net latent edge predictor leads to more realistic results, that are\nbetter aligned with the spatial outlines of the reference sketches, while\ndrastically reducing the number of required denoising steps and, consequently,\nthe overall execution time.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18425v1",
    "published_date": "2024-03-27 10:26:42 UTC",
    "updated_date": "2024-03-27 10:26:42 UTC"
  },
  {
    "arxiv_id": "2403.18421v1",
    "title": "BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text",
    "authors": [
      "Elliot Bolton",
      "Abhinav Venigalla",
      "Michihiro Yasunaga",
      "David Hall",
      "Betty Xiong",
      "Tony Lee",
      "Roxana Daneshjou",
      "Jonathan Frankle",
      "Percy Liang",
      "Michael Carbin",
      "Christopher D. Manning"
    ],
    "abstract": "Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance\non a wide variety of biomedical NLP tasks. However, these models have hundreds\nof billions of parameters, are computationally expensive to run, require users\nto send their input data over the internet, and are trained on unknown data\nsources. Can smaller, more targeted models compete? To address this question,\nwe build and release BioMedLM, a 2.7 billion parameter GPT-style autoregressive\nmodel trained exclusively on PubMed abstracts and full articles. When\nfine-tuned, BioMedLM can produce strong multiple-choice biomedical\nquestion-answering results competitive with much larger models, such as\nachieving a score of 57.3% on MedMCQA (dev) and 69.0% on the MMLU Medical\nGenetics exam. BioMedLM can also be fine-tuned to produce useful answers to\npatient questions on medical topics. This demonstrates that smaller models can\npotentially serve as transparent, privacy-preserving, economical and\nenvironmentally friendly foundations for particular NLP applications, such as\nin biomedicine. The model is available on the Hugging Face Hub:\nhttps://huggingface.co/stanford-crfm/BioMedLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.18421v1",
    "published_date": "2024-03-27 10:18:21 UTC",
    "updated_date": "2024-03-27 10:18:21 UTC"
  },
  {
    "arxiv_id": "2403.18407v1",
    "title": "A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is Critical for Semi-supervised Classification",
    "authors": [
      "Jiaqi Wu",
      "Junbiao Pang",
      "Baochang Zhang",
      "Qingming Huang"
    ],
    "abstract": "Semi-supervised learning (SSL) is a practical challenge in computer vision.\nPseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of\nThe Art (SOTA) performances in SSL. These approaches employ a\nthreshold-to-pseudo-label (T2L) process to generate PLs by truncating the\nconfidence scores of unlabeled data predicted by the self-training method.\nHowever, self-trained models typically yield biased and high-variance\npredictions, especially in the scenarios when a little labeled data are\nsupplied. To address this issue, we propose a lightweight channel-based\nensemble method to effectively consolidate multiple inferior PLs into the\ntheoretically guaranteed unbiased and low-variance one. Importantly, our\napproach can be readily extended to any SSL framework, such as FixMatch or\nFreeMatch. Experimental results demonstrate that our method significantly\noutperforms state-of-the-art techniques on CIFAR10/100 in terms of\neffectiveness and efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18407v1",
    "published_date": "2024-03-27 09:49:37 UTC",
    "updated_date": "2024-03-27 09:49:37 UTC"
  },
  {
    "arxiv_id": "2403.18406v1",
    "title": "An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering Using a VLM",
    "authors": [
      "Wonkyun Kim",
      "Changin Choi",
      "Wonseok Lee",
      "Wonjong Rhee"
    ],
    "abstract": "Stimulated by the sophisticated reasoning capabilities of recent Large\nLanguage Models (LLMs), a variety of strategies for bridging video modality\nhave been devised. A prominent strategy involves Video Language Models\n(VideoLMs), which train a learnable interface with video data to connect\nadvanced vision encoders with LLMs. Recently, an alternative strategy has\nsurfaced, employing readily available foundation models, such as VideoLMs and\nLLMs, across multiple stages for modality bridging. In this study, we introduce\na simple yet novel strategy where only a single Vision Language Model (VLM) is\nutilized. Our starting point is the plain insight that a video comprises a\nseries of images, or frames, interwoven with temporal information. The essence\nof video comprehension lies in adeptly managing the temporal aspects along with\nthe spatial details of each frame. Initially, we transform a video into a\nsingle composite image by arranging multiple frames in a grid layout. The\nresulting single image is termed as an image grid. This format, while\nmaintaining the appearance of a solitary image, effectively retains temporal\ninformation within the grid structure. Therefore, the image grid approach\nenables direct application of a single high-performance VLM without\nnecessitating any video-data training. Our extensive experimental analysis\nacross ten zero-shot video question answering benchmarks, including five\nopen-ended and five multiple-choice benchmarks, reveals that the proposed Image\nGrid Vision Language Model (IG-VLM) surpasses the existing methods in nine out\nof ten benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Our code is available at https://github.com/imagegridworth/IG-VLM",
    "pdf_url": "http://arxiv.org/pdf/2403.18406v1",
    "published_date": "2024-03-27 09:48:23 UTC",
    "updated_date": "2024-03-27 09:48:23 UTC"
  },
  {
    "arxiv_id": "2403.18405v1",
    "title": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval",
    "authors": [
      "Shengjie Ma",
      "Chong Chen",
      "Qi Chu",
      "Jiaxin Mao"
    ],
    "abstract": "Collecting relevant judgments for legal case retrieval is a challenging and\ntime-consuming task. Accurately judging the relevance between two legal cases\nrequires a considerable effort to read the lengthy text and a high level of\ndomain expertise to extract Legal Facts and make juridical judgments. With the\nadvent of advanced large language models, some recent studies have suggested\nthat it is promising to use LLMs for relevance judgment. Nonetheless, the\nmethod of employing a general large language model for reliable relevance\njudgments in legal case retrieval is yet to be thoroughly explored. To fill\nthis research gap, we devise a novel few-shot workflow tailored to the relevant\njudgment of legal cases. The proposed workflow breaks down the annotation\nprocess into a series of stages, imitating the process employed by human\nannotators and enabling a flexible integration of expert reasoning to enhance\nthe accuracy of relevance judgments. By comparing the relevance judgments of\nLLMs and human experts, we empirically show that we can obtain reliable\nrelevance judgments with the proposed workflow. Furthermore, we demonstrate the\ncapacity to augment existing legal case retrieval models through the synthesis\nof data generated by the large language model.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18405v1",
    "published_date": "2024-03-27 09:46:56 UTC",
    "updated_date": "2024-03-27 09:46:56 UTC"
  },
  {
    "arxiv_id": "2403.18397v2",
    "title": "Colour and Brush Stroke Pattern Recognition in Abstract Art using Modified Deep Convolutional Generative Adversarial Networks",
    "authors": [
      "Srinitish Srinivasan",
      "Varenya Pathak",
      "Abirami S"
    ],
    "abstract": "Abstract Art is an immensely popular, discussed form of art that often has\nthe ability to depict the emotions of an artist. Many researchers have made\nattempts to study abstract art in the form of edge detection, brush stroke and\nemotion recognition algorithms using machine and deep learning. This papers\ndescribes the study of a wide distribution of abstract paintings using\nGenerative Adversarial Neural Networks(GAN). GANs have the ability to learn and\nreproduce a distribution enabling researchers and scientists to effectively\nexplore and study the generated image space. However, the challenge lies in\ndeveloping an efficient GAN architecture that overcomes common training\npitfalls. This paper addresses this challenge by introducing a modified-DCGAN\n(mDCGAN) specifically designed for high-quality artwork generation. The\napproach involves a thorough exploration of the modifications made, delving\ninto the intricate workings of DCGANs, optimisation techniques, and\nregularisation methods aimed at improving stability and realism in art\ngeneration enabling effective study of generated patterns. The proposed mDCGAN\nincorporates meticulous adjustments in layer configurations and architectural\nchoices, offering tailored solutions to the unique demands of art generation\nwhile effectively combating issues like mode collapse and gradient vanishing.\nFurther this paper explores the generated latent space by performing random\nwalks to understand vector relationships between brush strokes and colours in\nthe abstract art space and a statistical analysis of unstable outputs after a\ncertain period of GAN training and compare its significant difference. These\nfindings validate the effectiveness of the proposed approach, emphasising its\npotential to revolutionise the field of digital art generation and digital art\necosystem.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication by Intelligent Decision Technologies 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18397v2",
    "published_date": "2024-03-27 09:35:56 UTC",
    "updated_date": "2024-12-05 18:11:22 UTC"
  },
  {
    "arxiv_id": "2403.18388v1",
    "title": "FTBC: Forward Temporal Bias Correction for Optimizing ANN-SNN Conversion",
    "authors": [
      "Xiaofeng Wu",
      "Velibor Bojkovic",
      "Bin Gu",
      "Kun Suo",
      "Kai Zou"
    ],
    "abstract": "Spiking Neural Networks (SNNs) offer a promising avenue for energy-efficient\ncomputing compared with Artificial Neural Networks (ANNs), closely mirroring\nbiological neural processes. However, this potential comes with inherent\nchallenges in directly training SNNs through spatio-temporal backpropagation --\nstemming from the temporal dynamics of spiking neurons and their discrete\nsignal processing -- which necessitates alternative ways of training, most\nnotably through ANN-SNN conversion. In this work, we introduce a lightweight\nForward Temporal Bias Correction (FTBC) technique, aimed at enhancing\nconversion accuracy without the computational overhead. We ground our method on\nprovided theoretical findings that through proper temporal bias calibration the\nexpected error of ANN-SNN conversion can be reduced to be zero after each time\nstep. We further propose a heuristic algorithm for finding the temporal bias\nonly in the forward pass, thus eliminating the computational burden of\nbackpropagation and we evaluate our method on CIFAR-10/100 and ImageNet\ndatasets, achieving a notable increase in accuracy on all datasets. Codes are\nreleased at a GitHub repository.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18388v1",
    "published_date": "2024-03-27 09:25:20 UTC",
    "updated_date": "2024-03-27 09:25:20 UTC"
  },
  {
    "arxiv_id": "2403.18383v1",
    "title": "Generative Multi-modal Models are Good Class-Incremental Learners",
    "authors": [
      "Xusheng Cao",
      "Haori Lu",
      "Linlan Huang",
      "Xialei Liu",
      "Ming-Ming Cheng"
    ],
    "abstract": "In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic\nforgetting caused by the classifier's bias towards the current task has long\nposed a significant challenge. It is mainly caused by the characteristic of\ndiscriminative models. With the growing popularity of the generative\nmulti-modal models, we would explore replacing discriminative models with\ngenerative ones for CIL. However, transitioning from discriminative to\ngenerative models requires addressing two key challenges. The primary challenge\nlies in transferring the generated textual information into the classification\nof distinct categories. Additionally, it requires formulating the task of CIL\nwithin a generative framework. To this end, we propose a novel generative\nmulti-modal model (GMM) framework for class-incremental learning. Our approach\ndirectly generates labels for images using an adapted generative model. After\nobtaining the detailed text, we use a text encoder to extract text features and\nemploy feature matching to determine the most similar label as the\nclassification prediction. In the conventional CIL settings, we achieve\nsignificantly better results in long-sequence task scenarios. Under the\nFew-shot CIL setting, we have improved by at least 14\\% accuracy over all the\ncurrent state-of-the-art methods with significantly less forgetting. Our code\nis available at \\url{https://github.com/DoubleClass/GMM}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18383v1",
    "published_date": "2024-03-27 09:21:07 UTC",
    "updated_date": "2024-03-27 09:21:07 UTC"
  },
  {
    "arxiv_id": "2403.18381v1",
    "title": "Improving Attributed Text Generation of Large Language Models via Preference Learning",
    "authors": [
      "Dongfang Li",
      "Zetian Sun",
      "Baotian Hu",
      "Zhenyu Liu",
      "Xinshuo Hu",
      "Xuebo Liu",
      "Min Zhang"
    ],
    "abstract": "Large language models have been widely adopted in natural language\nprocessing, yet they face the challenge of generating unreliable content.\nRecent works aim to reduce misinformation and hallucinations by resorting to\nattribution as a means to provide evidence (i.e., citations). However, current\nattribution methods usually focus on the retrieval stage and automatic\nevaluation that neglect mirroring the citation mechanisms in human scholarly\nwriting to bolster credibility. In this paper, we address these challenges by\nmodelling the attribution task as preference learning and introducing an\nAutomatic Preference Optimization (APO) framework. First, we create a curated\ncollection for post-training with 6,330 examples by collecting and filtering\nfrom existing datasets. Second, considering the high cost of labelling\npreference data, we further propose an automatic method to synthesize\nattribution preference data resulting in 95,263 pairs. Moreover, inspired by\nthe human citation process, we further propose a progressive preference\noptimization method by leveraging fine-grained information. Extensive\nexperiments on three datasets (i.e., ASQA, StrategyQA, and ELI5) demonstrate\nthat APO achieves state-of-the-art citation F1 with higher answer quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 15 tables, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.18381v1",
    "published_date": "2024-03-27 09:19:13 UTC",
    "updated_date": "2024-03-27 09:19:13 UTC"
  },
  {
    "arxiv_id": "2403.18379v1",
    "title": "IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining Useful Life Prediction",
    "authors": [
      "Guangzai Ye",
      "Li Feng",
      "Jianlan Guo",
      "Yuqiang Chen"
    ],
    "abstract": "Accurately estimating the Remaining Useful Life (RUL) of lithium-ion\nbatteries is crucial for maintaining the safe and stable operation of\nrechargeable battery management systems. However, this task is often\nchallenging due to the complex temporal dynamics involved. Recently,\nattention-based networks, such as Transformers and Informer, have been the\npopular architecture in time series forecasting. Despite their effectiveness,\nthese models with abundant parameters necessitate substantial training time to\nunravel temporal patterns. To tackle these challenges, we propose a simple\nMLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which\nis an architecture based exclusively on multi-layer perceptrons (MLPs),\nextracting information by mixing operations along both intra-patch and\ninter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer\ncomprises parallel dual-head mixer layers: the intra-patch mixing MLP,\ncapturing local temporal patterns in the short-term period, and the inter-patch\nmixing MLP, capturing global temporal patterns in the long-term period.\nNotably, to address the varying importance of features in RUL prediction, we\nintroduce a weighted loss function in the MLP-Mixer-based architecture, marking\nthe first time such an approach has been employed. Our experiments demonstrate\nthat IIP-Mixer achieves competitive performance in battery RUL prediction,\noutperforming other popular time-series frameworks",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18379v1",
    "published_date": "2024-03-27 09:17:50 UTC",
    "updated_date": "2024-03-27 09:17:50 UTC"
  },
  {
    "arxiv_id": "2403.18364v2",
    "title": "Intent-Aware DRL-Based NOMA Uplink Dynamic Scheduler for IIoT",
    "authors": [
      "Salwa Mostafa",
      "Mateus P. Mota",
      "Alvaro Valcarce",
      "Mehdi Bennis"
    ],
    "abstract": "We investigate the problem of supporting Industrial Internet of Things user\nequipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and\nrandom traffic arrival. A deep reinforcement learning (DRL) based centralized\ndynamic scheduler for time-frequency resources is proposed to learn how to\nschedule the available communication resources among the IIoT UEs. The proposed\nscheduler leverages an RL framework to adapt to the dynamic changes in the\nwireless communication system and traffic arrivals. Moreover, a graph-based\nreduction scheme is proposed to reduce the state and action space of the RL\nframework to allow fast convergence and a better learning strategy. Simulation\nresults demonstrate the effectiveness of the proposed intelligent scheduler in\nguaranteeing the expressed intent of IIoT UEs compared to several traditional\nscheduling schemes, such as round-robin, semi-static, and heuristic approaches.\nThe proposed scheduler also outperforms the contention-free and\ncontention-based schemes in maximizing the number of successfully computed\ntasks.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "The simulation code for the paper is available on the following\n  GitHub repository\n  https://github.com/SalwaMostafa/Intent-Aware-DRL-Based-NOMA-Uplink-Dynamic-Scheduler-for-IIoT",
    "pdf_url": "http://arxiv.org/pdf/2403.18364v2",
    "published_date": "2024-03-27 08:57:15 UTC",
    "updated_date": "2025-01-05 09:51:55 UTC"
  },
  {
    "arxiv_id": "2403.18351v1",
    "title": "Generating Diverse Agricultural Data for Vision-Based Farming Applications",
    "authors": [
      "Mikolaj Cieslak",
      "Umabharathi Govindarajan",
      "Alejandro Garcia",
      "Anuradha Chandrashekar",
      "Torsten Hädrich",
      "Aleksander Mendoza-Drosik",
      "Dominik L. Michels",
      "Sören Pirk",
      "Chia-Chun Fu",
      "Wojciech Pałubicki"
    ],
    "abstract": "We present a specialized procedural model for generating synthetic\nagricultural scenes, focusing on soybean crops, along with various weeds. This\nmodel is capable of simulating distinct growth stages of these plants, diverse\nsoil conditions, and randomized field arrangements under varying lighting\nconditions. The integration of real-world textures and environmental factors\ninto the procedural generation process enhances the photorealism and\napplicability of the synthetic data. Our dataset includes 12,000 images with\nsemantic labels, offering a comprehensive resource for computer vision tasks in\nprecision agriculture, such as semantic segmentation for autonomous weed\ncontrol. We validate our model's effectiveness by comparing the synthetic data\nagainst real agricultural images, demonstrating its potential to significantly\naugment training data for machine learning models in agriculture. This approach\nnot only provides a cost-effective solution for generating high-quality,\ndiverse data but also addresses specific needs in agricultural vision tasks\nthat are not fully covered by general-purpose models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "68T07, 68T45",
      "I.2.10; I.4.6"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.18351v1",
    "published_date": "2024-03-27 08:42:47 UTC",
    "updated_date": "2024-03-27 08:42:47 UTC"
  },
  {
    "arxiv_id": "2403.18347v1",
    "title": "A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal Holes",
    "authors": [
      "Sanmoy Bandyopadhyay",
      "Suman Kundu"
    ],
    "abstract": "The detection and analysis of the solar coronal holes (CHs) is an important\nfield of study in the domain of solar physics. Mainly, it is required for the\nproper prediction of the geomagnetic storms which directly or indirectly affect\nvarious space and ground-based systems. For the detection of CHs till date, the\nsolar scientist depends on manual hand-drawn approaches. However, with the\nadvancement of image processing technologies, some automated image segmentation\nmethods have been used for the detection of CHs. In-spite of this, fast and\naccurate detection of CHs are till a major issues. Here in this work, a novel\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\ndetection of the CHs region. The task has been carried out in two stages, in\nfirst stage the solar image has been segmented using a quantum computing based\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\nout from the segmented image based on image morphological operation. In the\nwork, quantum computing has been used to optimize the cost function of the fast\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\n(QAOA) has been used to optimize the quadratic part of the cost function. The\nproposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image\ndatasets and has been compared with the existing techniques. The outcome shows\nthe comparable performance of the proposed method with the existing one within\na very lesser time.",
    "categories": [
      "astro-ph.SR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "14 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.18347v1",
    "published_date": "2024-03-27 08:38:56 UTC",
    "updated_date": "2024-03-27 08:38:56 UTC"
  },
  {
    "arxiv_id": "2403.18344v2",
    "title": "LC-LLM: Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models",
    "authors": [
      "Mingxing Peng",
      "Xusen Guo",
      "Xianda Chen",
      "Meixin Zhu",
      "Kehua Chen"
    ],
    "abstract": "To ensure safe driving in dynamic environments, autonomous vehicles should\npossess the capability to accurately predict lane change intentions of\nsurrounding vehicles in advance and forecast their future trajectories.\nExisting motion prediction approaches have ample room for improvement,\nparticularly in terms of long-term prediction accuracy and interpretability. In\nthis paper, we address these challenges by proposing LC-LLM, an explainable\nlane change prediction model that leverages the strong reasoning capabilities\nand self-explanation abilities of Large Language Models (LLMs). Essentially, we\nreformulate the lane change prediction task as a language modeling problem,\nprocessing heterogeneous driving scenario information as natural language\nprompts for LLMs and employing supervised fine-tuning to tailor LLMs\nspecifically for lane change prediction task. Additionally, we finetune the\nChain-of-Thought (CoT) reasoning to improve prediction transparency and\nreliability, and include explanatory requirements in the prompts during\ninference stage. Therefore, our LC-LLM model not only predicts lane change\nintentions and trajectories but also provides CoT reasoning and explanations\nfor its predictions, enhancing its interpretability. Extensive experiments\nbased on the large-scale highD dataset demonstrate the superior performance and\ninterpretability of our LC-LLM in lane change prediction task. To the best of\nour knowledge, this is the first attempt to utilize LLMs for predicting lane\nchange behavior. Our study shows that LLMs can effectively encode comprehensive\ninteraction information for driving behavior understanding.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.18344v2",
    "published_date": "2024-03-27 08:34:55 UTC",
    "updated_date": "2024-08-05 02:47:09 UTC"
  },
  {
    "arxiv_id": "2403.18338v1",
    "title": "mALBERT: Is a Compact Multilingual BERT Model Still Worth It?",
    "authors": [
      "Christophe Servan",
      "Sahar Ghannay",
      "Sophie Rosset"
    ],
    "abstract": "Within the current trend of Pretained Language Models (PLM), emerge more and\nmore criticisms about the ethical andecological impact of such models. In this\narticle, considering these critical remarks, we propose to focus on\nsmallermodels, such as compact models like ALBERT, which are more ecologically\nvirtuous than these PLM. However,PLMs enable huge breakthroughs in Natural\nLanguage Processing tasks, such as Spoken and Natural LanguageUnderstanding,\nclassification, Question--Answering tasks. PLMs also have the advantage of\nbeing multilingual, and,as far as we know, a multilingual version of compact\nALBERT models does not exist. Considering these facts, wepropose the free\nrelease of the first version of a multilingual compact ALBERT model,\npre-trained using Wikipediadata, which complies with the ethical aspect of such\na language model. We also evaluate the model against classicalmultilingual PLMs\nin classical NLP tasks. Finally, this paper proposes a rare study on the\nsubword tokenizationimpact on language performances.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The 2024 Joint International Conference on Computational Linguistics,\n  Language Resources and Evaluation, May 2024, Torino, Italy",
    "pdf_url": "http://arxiv.org/pdf/2403.18338v1",
    "published_date": "2024-03-27 08:25:28 UTC",
    "updated_date": "2024-03-27 08:25:28 UTC"
  },
  {
    "arxiv_id": "2403.18327v2",
    "title": "$\\forall$uto$\\exists$val: Autonomous Assessment of LLMs in Formal Synthesis and Interpretation Tasks",
    "authors": [
      "Rushang Karia",
      "Daniel Bramblett",
      "Daksh Dobhal",
      "Pulkit Verma",
      "Siddharth Srivastava"
    ],
    "abstract": "This paper presents $\\forall$uto$\\exists$val, a new approach for scaling LLM\nassessment in translating formal syntax -- such as first-order logic, regular\nexpressions, etc -- to natural language (interpretation) or vice versa\n(compilation), thereby facilitating their use in applications such as\ngenerating/explaining logic and control flow for programs etc. Existing\napproaches for LLM assessment in these areas require labor-intensive\nground-truth creation, the availability of which undermines the separation of\ntraining and test sets. Furthermore, such datasets typically include relatively\nfew hand-coded test cases over which LLM accuracy is determined, thus making\nthem inadequate for determining the safety or correctness of their generated\noutputs. We introduce a new approach that utilizes context-free grammars (CFGs)\nto generate out-of-distribution datasets on the fly and perform closed-loop\ntesting of LLM capabilities using formal verifiers to guarantee the correctness\nof LLM outputs without any human intervention. We release our dataset and\nbenchmark as open-source code at\n\\url{https://github.com/AAIR-lab/auto-llm-assessment}. We also conduct an\nassessment of several SOTA closed and open-source LLMs to showcase the\nfeasibility and scalability of this paradigm. Our experiments reveal that SOTA\nLLMs are unable to solve the formal translation task adequately.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18327v2",
    "published_date": "2024-03-27 08:08:00 UTC",
    "updated_date": "2024-07-22 00:41:38 UTC"
  },
  {
    "arxiv_id": "2403.18314v3",
    "title": "Chinese Offensive Language Detection:Current Status and Future Directions",
    "authors": [
      "Yunze Xiao",
      "Houda Bouamor",
      "Wajdi Zaghouani"
    ],
    "abstract": "Despite the considerable efforts being made to monitor and regulate\nuser-generated content on social media platforms, the pervasiveness of\noffensive language, such as hate speech or cyberbullying, in the digital space\nremains a significant challenge. Given the importance of maintaining a\ncivilized and respectful online environment, there is an urgent and growing\nneed for automatic systems capable of detecting offensive speech in real time.\nHowever, developing effective systems for processing languages such as Chinese\npresents a significant challenge, owing to the language's complex and nuanced\nnature, which makes it difficult to process automatically. This paper provides\na comprehensive overview of offensive language detection in Chinese, examining\ncurrent benchmarks and approaches and highlighting specific models and tools\nfor addressing the unique challenges of detecting offensive language in this\ncomplex language. The primary objective of this survey is to explore the\nexisting techniques and identify potential avenues for further research that\ncan address the cultural and linguistic complexities of Chinese.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18314v3",
    "published_date": "2024-03-27 07:34:44 UTC",
    "updated_date": "2024-03-29 18:48:35 UTC"
  },
  {
    "arxiv_id": "2403.18310v1",
    "title": "A thermodynamically consistent physics-informed deep learning material model for short fiber/polymer nanocomposites",
    "authors": [
      "Betim Bahtiri",
      "Behrouz Arash",
      "Sven Scheffler",
      "Maximilian Jux",
      "Raimund Rolfes"
    ],
    "abstract": "This work proposes a physics-informed deep learning (PIDL)-based constitutive\nmodel for investigating the viscoelastic-viscoplastic behavior of short\nfiber-reinforced nanoparticle-filled epoxies under various ambient conditions.\nThe deep-learning model is trained to enforce thermodynamic principles, leading\nto a thermodynamically consistent constitutive model. To accomplish this, a\nlong short-term memory network is combined with a feed-forward neural network\nto predict internal variables required for characterizing the internal\ndissipation of the nanocomposite materials. In addition, another feed-forward\nneural network is used to indicate the free-energy function, which enables\ndefining the thermodynamic state of the entire system. The PIDL model is\ninitially developed for the three-dimensional case by generating synthetic data\nfrom a classical constitutive model. The model is then trained by extracting\nthe data directly from cyclic loading-unloading experimental tests. Numerical\nexamples show that the PIDL model can accurately predict the mechanical\nbehavior of epoxy-based nanocomposites for different volume fractions of fibers\nand nanoparticles under various hygrothermal conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2305.08102",
    "pdf_url": "http://arxiv.org/pdf/2403.18310v1",
    "published_date": "2024-03-27 07:22:32 UTC",
    "updated_date": "2024-03-27 07:22:32 UTC"
  },
  {
    "arxiv_id": "2404.07223v3",
    "title": "Stock Recommendations for Individual Investors: A Temporal Graph Network Approach with Mean-Variance Efficient Sampling",
    "authors": [
      "Youngbin Lee",
      "Yejin Kim",
      "Javier Sanz-Cruzado",
      "Richard McCreadie",
      "Yongjae Lee"
    ],
    "abstract": "Recommender systems can be helpful for individuals to make well-informed\ndecisions in complex financial markets. While many studies have focused on\npredicting stock prices, even advanced models fall short of accurately\nforecasting them. Additionally, previous studies indicate that individual\ninvestors often disregard established investment theories, favoring their\npersonal preferences instead. This presents a challenge for stock\nrecommendation systems, which must not only provide strong investment\nperformance but also respect these individual preferences. To create effective\nstock recommender systems, three critical elements must be incorporated: 1)\nindividual preferences, 2) portfolio diversification, and 3) the temporal\ndynamics of the first two. In response, we propose a new model, Portfolio\nTemporal Graph Network Recommender PfoTGNRec, which can handle time-varying\ncollaborative signals and incorporates diversification-enhancing sampling. On\nreal-world individual trading data, our approach demonstrates superior\nperformance compared to state-of-the-art baselines, including cutting-edge\ndynamic embedding models and existing stock recommendation models. Indeed, we\nshow that PfoTGNRec is an effective solution that can balance customer\npreferences with the need to suggest portfolios with high Return-on-Investment.\nThe source code and data are available at\nhttps://github.com/youngandbin/PfoTGNRec.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "ICAIF 2024 (https://dl.acm.org/doi/10.1145/3677052.3698662)",
    "pdf_url": "http://arxiv.org/pdf/2404.07223v3",
    "published_date": "2024-03-27 07:17:55 UTC",
    "updated_date": "2024-11-30 05:54:34 UTC"
  },
  {
    "arxiv_id": "2404.00060v1",
    "title": "Temporal Graph Networks for Graph Anomaly Detection in Financial Networks",
    "authors": [
      "Yejin Kim",
      "Youngbin Lee",
      "Minyoung Choe",
      "Sungju Oh",
      "Yongjae Lee"
    ],
    "abstract": "This paper explores the utilization of Temporal Graph Networks (TGN) for\nfinancial anomaly detection, a pressing need in the era of fintech and\ndigitized financial transactions. We present a comprehensive framework that\nleverages TGN, capable of capturing dynamic changes in edges within financial\nnetworks, for fraud detection. Our study compares TGN's performance against\nstatic Graph Neural Network (GNN) baselines, as well as cutting-edge hypergraph\nneural network baselines using DGraph dataset for a realistic financial\ncontext. Our results demonstrate that TGN significantly outperforms other\nmodels in terms of AUC metrics. This superior performance underlines TGN's\npotential as an effective tool for detecting financial fraud, showcasing its\nability to adapt to the dynamic and complex nature of modern financial systems.\nWe also experimented with various graph embedding modules within the TGN\nframework and compared the effectiveness of each module. In conclusion, we\ndemonstrated that, even with variations within TGN, it is possible to achieve\ngood performance in the anomaly detection task.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "Presented at the AAAI 2024 Workshop on AI in Finance for Social\n  Impact (https://sites.google.com/view/aifin-aaai2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.00060v1",
    "published_date": "2024-03-27 07:17:16 UTC",
    "updated_date": "2024-03-27 07:17:16 UTC"
  },
  {
    "arxiv_id": "2403.18305v2",
    "title": "A Recommender System for NFT Collectibles with Item Feature",
    "authors": [
      "Minjoo Choi",
      "Seonmi Kim",
      "Yejin Kim",
      "Youngbin Lee",
      "Joohwan Hong",
      "Yongjae Lee"
    ],
    "abstract": "Recommender systems have been actively studied and applied in various domains\nto deal with information overload. Although there are numerous studies on\nrecommender systems for movies, music, and e-commerce, comparatively less\nattention has been paid to the recommender system for NFTs despite the\ncontinuous growth of the NFT market. This paper presents a recommender system\nfor NFTs that utilizes a variety of data sources, from NFT transaction records\nto external item features, to generate precise recommendations that cater to\nindividual preferences. We develop a data-efficient graph-based recommender\nsystem to efficiently capture the complex relationship between each item and\nusers and generate node(item) embeddings which incorporate both node feature\ninformation and graph structure. Furthermore, we exploit inputs beyond\nuser-item interactions, such as image feature, text feature, and price feature.\nNumerical experiments verify the performance of the graph-based recommender\nsystem improves significantly after utilizing all types of item features as\nside information, thereby outperforming all other baselines.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Presented at the AAAI 2023 Bridge on AI for Financial Services\n  (https://sites.google.com/view/aaai-ai-fin/home)",
    "pdf_url": "http://arxiv.org/pdf/2403.18305v2",
    "published_date": "2024-03-27 06:59:39 UTC",
    "updated_date": "2024-04-03 06:52:50 UTC"
  },
  {
    "arxiv_id": "2403.18301v1",
    "title": "Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives",
    "authors": [
      "Shrinivas Ramasubramanian",
      "Harsh Rangwani",
      "Sho Takemori",
      "Kunal Samanta",
      "Yuhei Umeda",
      "Venkatesh Babu Radhakrishnan"
    ],
    "abstract": "The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024 SpotLight",
    "pdf_url": "http://arxiv.org/pdf/2403.18301v1",
    "published_date": "2024-03-27 06:55:23 UTC",
    "updated_date": "2024-03-27 06:55:23 UTC"
  },
  {
    "arxiv_id": "2403.18296v3",
    "title": "GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic Communication Paradigm",
    "authors": [
      "Chunhang Zheng",
      "Kechao Cai"
    ],
    "abstract": "Traditional approaches to semantic communication tasks rely on the knowledge\nof the signal-to-noise ratio (SNR) to mitigate channel noise. Moreover, these\nmethods necessitate training under specific SNR conditions, entailing\nconsiderable time and computational resources. In this paper, we propose GeNet,\na Graph Neural Network (GNN)-based paradigm for semantic communication aimed at\ncombating noise, thereby facilitating Task-Oriented Communication (TOC). We\npropose a novel approach where we first transform the input data image into\ngraph structures. Then we leverage a GNN-based encoder to extract semantic\ninformation from the source data. This extracted semantic information is then\ntransmitted through the channel. At the receiver's end, a GNN-based decoder is\nutilized to reconstruct the relevant semantic information from the source data\nfor TOC. Through experimental evaluation, we show GeNet's effectiveness in\nanti-noise TOC while decoupling the SNR dependency. We further evaluate GeNet's\nperformance by varying the number of nodes, revealing its versatility as a new\nparadigm for semantic communication. Additionally, we show GeNet's robustness\nto geometric transformations by testing it with different rotation angles,\nwithout resorting to data augmentation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted as a conference paper to International Conference on\n  Computer Communications and Networks (ICCCN 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.18296v3",
    "published_date": "2024-03-27 06:46:59 UTC",
    "updated_date": "2024-09-22 02:44:31 UTC"
  },
  {
    "arxiv_id": "2403.18286v1",
    "title": "Few-Shot Recalibration of Language Models",
    "authors": [
      "Xiang Lisa Li",
      "Urvashi Khandelwal",
      "Kelvin Guu"
    ],
    "abstract": "Recent work has uncovered promising ways to extract well-calibrated\nconfidence estimates from language models (LMs), where the model's confidence\nscore reflects how likely it is to be correct. However, while LMs may appear\nwell-calibrated over broad distributions, this often hides significant\nmiscalibration within narrower slices (e.g., systemic over-confidence in math\ncan balance out systemic under-confidence in history, yielding perfect\ncalibration in aggregate). To attain well-calibrated confidence estimates for\nany slice of a distribution, we propose a new framework for few-shot\nslice-specific recalibration. Specifically, we train a recalibration model that\ntakes in a few unlabeled examples from any given slice and predicts a curve\nthat remaps confidence scores to be more accurate for that slice. Our trained\nmodel can recalibrate for arbitrary new slices, without using any labeled data\nfrom that slice. This enables us to identify domain-specific confidence\nthresholds above which the LM's predictions can be trusted, and below which it\nshould abstain. Experiments show that our few-shot recalibrator consistently\noutperforms existing calibration methods, for instance improving calibration\nerror for PaLM2-Large on MMLU by 16%, as compared to temperature scaling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2403.18286v1",
    "published_date": "2024-03-27 06:25:40 UTC",
    "updated_date": "2024-03-27 06:25:40 UTC"
  },
  {
    "arxiv_id": "2403.18278v1",
    "title": "Identification and Uses of Deep Learning Backbones via Pattern Mining",
    "authors": [
      "Michael Livanos",
      "Ian Davidson"
    ],
    "abstract": "Deep learning is extensively used in many areas of data mining as a black-box\nmethod with impressive results. However, understanding the core mechanism of\nhow deep learning makes predictions is a relatively understudied problem. Here\nwe explore the notion of identifying a backbone of deep learning for a given\ngroup of instances. A group here can be instances of the same class or even\nmisclassified instances of the same class. We view each instance for a given\ngroup as activating a subset of neurons and attempt to find a subgraph of\nneurons associated with a given concept/group. We formulate this problem as a\nset cover style problem and show it is intractable and presents a highly\nconstrained integer linear programming (ILP) formulation. As an alternative, we\nexplore a coverage-based heuristic approach related to pattern mining, and show\nit converges to a Pareto equilibrium point of the ILP formulation.\nExperimentally we explore these backbones to identify mistakes and improve\nperformance, explanation, and visualization. We demonstrate application-based\nresults using several challenging data sets, including Bird Audio Detection\n(BAD) Challenge and Labeled Faces in the Wild (LFW), as well as the classic\nMNIST data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, published SIAM SDM24",
    "pdf_url": "http://arxiv.org/pdf/2403.18278v1",
    "published_date": "2024-03-27 06:13:39 UTC",
    "updated_date": "2024-03-27 06:13:39 UTC"
  },
  {
    "arxiv_id": "2403.18267v1",
    "title": "DSF-GAN: DownStream Feedback Generative Adversarial Network",
    "authors": [
      "Oriel Perets",
      "Nadav Rappoport"
    ],
    "abstract": "Utility and privacy are two crucial measurements of the quality of synthetic\ntabular data. While significant advancements have been made in privacy\nmeasures, generating synthetic samples with high utility remains challenging.\nTo enhance the utility of synthetic samples, we propose a novel architecture\ncalled the DownStream Feedback Generative Adversarial Network (DSF-GAN). This\napproach incorporates feedback from a downstream prediction model during\ntraining to augment the generator's loss function with valuable information.\nThus, DSF-GAN utilizes a downstream prediction task to enhance the utility of\nsynthetic samples. To evaluate our method, we tested it using two popular\ndatasets. Our experiments demonstrate improved model performance when training\non synthetic samples generated by DSF-GAN, compared to those generated by the\nsame GAN architecture without feedback. The evaluation was conducted on the\nsame validation set comprising real samples. All code and datasets used in this\nresearch will be made openly available for ease of reproduction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18267v1",
    "published_date": "2024-03-27 05:41:50 UTC",
    "updated_date": "2024-03-27 05:41:50 UTC"
  },
  {
    "arxiv_id": "2403.18258v1",
    "title": "Enhancing Generative Class Incremental Learning Performance with Model Forgetting Approach",
    "authors": [
      "Taro Togo",
      "Ren Togo",
      "Keisuke Maeda",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "abstract": "This study presents a novel approach to Generative Class Incremental Learning\n(GCIL) by introducing the forgetting mechanism, aimed at dynamically managing\nclass information for better adaptation to streaming data. GCIL is one of the\nhot topics in the field of computer vision, and this is considered one of the\ncrucial tasks in society, specifically the continual learning of generative\nmodels. The ability to forget is a crucial brain function that facilitates\ncontinual learning by selectively discarding less relevant information for\nhumans. However, in the field of machine learning models, the concept of\nintentionally forgetting has not been extensively investigated. In this study\nwe aim to bridge this gap by incorporating the forgetting mechanisms into GCIL,\nthereby examining their impact on the models' ability to learn in continual\nlearning. Through our experiments, we have found that integrating the\nforgetting mechanisms significantly enhances the models' performance in\nacquiring new knowledge, underscoring the positive role that strategic\nforgetting plays in the process of continual learning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18258v1",
    "published_date": "2024-03-27 05:10:38 UTC",
    "updated_date": "2024-03-27 05:10:38 UTC"
  },
  {
    "arxiv_id": "2403.18256v1",
    "title": "Manipulating Neural Path Planners via Slight Perturbations",
    "authors": [
      "Zikang Xiong",
      "Suresh Jagannathan"
    ],
    "abstract": "Data-driven neural path planners are attracting increasing interest in the\nrobotics community. However, their neural network components typically come as\nblack boxes, obscuring their underlying decision-making processes. Their\nblack-box nature exposes them to the risk of being compromised via the\ninsertion of hidden malicious behaviors. For example, an attacker may hide\nbehaviors that, when triggered, hijack a delivery robot by guiding it to a\nspecific (albeit wrong) destination, trapping it in a predefined region, or\ninducing unnecessary energy expenditure by causing the robot to repeatedly\ncircle a region. In this paper, we propose a novel approach to specify and\ninject a range of hidden malicious behaviors, known as backdoors, into neural\npath planners. Our approach provides a concise but flexible way to define these\nbehaviors, and we show that hidden behaviors can be triggered by slight\nperturbations (e.g., inserting a tiny unnoticeable object), that can\nnonetheless significantly compromise their integrity. We also discuss potential\ntechniques to identify these backdoors aimed at alleviating such risks. We\ndemonstrate our approach on both sampling-based and search-based neural path\nplanners.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18256v1",
    "published_date": "2024-03-27 04:56:48 UTC",
    "updated_date": "2024-03-27 04:56:48 UTC"
  },
  {
    "arxiv_id": "2403.18252v2",
    "title": "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning",
    "authors": [
      "Yiwu Zhong",
      "Zi-Yuan Hu",
      "Michael R. Lyu",
      "Liwei Wang"
    ],
    "abstract": "Visual representation learning has been a cornerstone in computer vision,\ninvolving typical forms such as visual embeddings, structural symbols, and\ntext-based representations. Despite the success of CLIP-type visual embeddings,\nthey often lack access to world knowledge critical for visual reasoning. In\nthis work, we propose Visual Table, a novel form of visual representation\ntailored for visual reasoning. Visual tables are constructed as hierarchical\ndescriptions of visual scenes, featuring a scene description and multiple\nobject-centric descriptions covering categories, attributes, and knowledge.\nThanks to the structural and textual formats, visual tables offer unique\nadvantages over mere visual embeddings, such as interpretability and\ncontrollable editing. Furthermore, they deliver instance-level world knowledge\nand detailed attributes that are essential for visual reasoning. To create\nvisual tables, we develop a generator trained on the dataset with collected,\nsmall-scale annotations. Extensive results on 11 visual reasoning benchmarks\ndemonstrate that the generated visual tables significantly outperform previous\nstructural and text-based representations. Moreover, they consistently enhance\nstate-of-the-art multimodal large language models across diverse benchmarks,\nshowcasing their potential for advancing visual reasoning tasks. Our code is\navailable at https://github.com/LaVi-Lab/Visual-Table.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://github.com/LaVi-Lab/Visual-Table",
    "pdf_url": "http://arxiv.org/pdf/2403.18252v2",
    "published_date": "2024-03-27 04:49:23 UTC",
    "updated_date": "2024-06-17 09:57:09 UTC"
  },
  {
    "arxiv_id": "2403.18243v1",
    "title": "Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check",
    "authors": [
      "Linhao Ye",
      "Zhikai Lei",
      "Jianghao Yin",
      "Qin Chen",
      "Jie Zhou",
      "Liang He"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) aims to generate more reliable and\naccurate responses, by augmenting large language models (LLMs) with the\nexternal vast and dynamic knowledge. Most previous work focuses on using RAG\nfor single-round question answering, while how to adapt RAG to the complex\nconversational setting wherein the question is interdependent on the preceding\ncontext is not well studied. In this paper, we propose a conversation-level RAG\napproach, which incorporates fine-grained retrieval augmentation and self-check\nfor conversational question answering (CQA). In particular, our approach\nconsists of three components, namely conversational question refiner,\nfine-grained retriever and self-check based response generator, which work\ncollaboratively for question understanding and relevant information acquisition\nin conversational settings. Extensive experiments demonstrate the great\nadvantages of our approach over the state-of-the-art baselines. Moreover, we\nalso release a Chinese CQA dataset with new features including reformulated\nquestion, extracted keyword, retrieved paragraphs and their helpfulness, which\nfacilitates further researches in RAG enhanced CQA.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18243v1",
    "published_date": "2024-03-27 04:20:18 UTC",
    "updated_date": "2024-03-27 04:20:18 UTC"
  },
  {
    "arxiv_id": "2403.18241v2",
    "title": "NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion, Reconstruction, and Generation",
    "authors": [
      "Ruikai Cui",
      "Weizhe Liu",
      "Weixuan Sun",
      "Senbo Wang",
      "Taizhang Shang",
      "Yang Li",
      "Xibin Song",
      "Han Yan",
      "Zhennan Wu",
      "Shenzhou Chen",
      "Hongdong Li",
      "Pan Ji"
    ],
    "abstract": "3D shape generation aims to produce innovative 3D content adhering to\nspecific conditions and constraints. Existing methods often decompose 3D shapes\ninto a sequence of localized components, treating each element in isolation\nwithout considering spatial consistency. As a result, these approaches exhibit\nlimited versatility in 3D data representation and shape generation, hindering\ntheir ability to generate highly diverse 3D shapes that comply with the\nspecified constraints. In this paper, we introduce a novel spatial-aware 3D\nshape generation framework that leverages 2D plane representations for enhanced\n3D shape modeling. To ensure spatial coherence and reduce memory usage, we\nincorporate a hybrid shape representation technique that directly learns a\ncontinuous signed distance field representation of the 3D shape using\northogonal 2D planes. Additionally, we meticulously enforce spatial\ncorrespondences across distinct planes using a transformer-based autoencoder\nstructure, promoting the preservation of spatial relationships in the generated\n3D shapes. This yields an algorithm that consistently outperforms\nstate-of-the-art 3D shape generation methods on various tasks, including\nunconditional shape generation, multi-modal shape completion, single-view\nreconstruction, and text-to-shape synthesis. Our project page is available at\nhttps://weizheliu.github.io/NeuSDFusion/ .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024, project page: https://weizheliu.github.io/NeuSDFusion/",
    "pdf_url": "http://arxiv.org/pdf/2403.18241v2",
    "published_date": "2024-03-27 04:09:34 UTC",
    "updated_date": "2024-07-12 07:30:00 UTC"
  },
  {
    "arxiv_id": "2403.18230v1",
    "title": "Large Language Models Need Consultants for Reasoning: Becoming an Expert in a Complex Human System Through Behavior Simulation",
    "authors": [
      "Chuwen Wang",
      "Shirong Zeng",
      "Cheng Wang"
    ],
    "abstract": "Large language models (LLMs), in conjunction with various reasoning\nreinforcement methodologies, have demonstrated remarkable capabilities\ncomparable to humans in fields such as mathematics, law, coding, common sense,\nand world knowledge. In this paper, we delve into the reasoning abilities of\nLLMs within complex human systems. We propose a novel reasoning framework,\ntermed ``Mosaic Expert Observation Wall'' (MEOW) exploiting\ngenerative-agents-based simulation technique. In the MEOW framework, simulated\ndata are utilized to train an expert model concentrating ``experience'' about a\nspecific task in each independent time of simulation. It is the accumulated\n``experience'' through the simulation that makes for an expert on a task in a\ncomplex human system. We conduct the experiments within a communication game\nthat mirrors real-world security scenarios. The results indicate that our\nproposed methodology can cooperate with existing methodologies to enhance the\nreasoning abilities of LLMs in complex human systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18230v1",
    "published_date": "2024-03-27 03:33:32 UTC",
    "updated_date": "2024-03-27 03:33:32 UTC"
  },
  {
    "arxiv_id": "2403.18223v1",
    "title": "A Transformer-Based Framework for Payload Malware Detection and Classification",
    "authors": [
      "Kyle Stein",
      "Arash Mahyari",
      "Guillermo Francia III",
      "Eman El-Sheikh"
    ],
    "abstract": "As malicious cyber threats become more sophisticated in breaching computer\nnetworks, the need for effective intrusion detection systems (IDSs) becomes\ncrucial. Techniques such as Deep Packet Inspection (DPI) have been introduced\nto allow IDSs analyze the content of network packets, providing more context\nfor identifying potential threats. IDSs traditionally rely on using\nanomaly-based and signature-based detection techniques to detect unrecognized\nand suspicious activity. Deep learning techniques have shown great potential in\nDPI for IDSs due to their efficiency in learning intricate patterns from the\npacket content being transmitted through the network. In this paper, we propose\na revolutionary DPI algorithm based on transformers adapted for the purpose of\ndetecting malicious traffic with a classifier head. Transformers learn the\ncomplex content of sequence data and generalize them well to similar scenarios\nthanks to their self-attention mechanism. Our proposed method uses the raw\npayload bytes that represent the packet contents and is deployed as\nman-in-the-middle. The payload bytes are used to detect malicious packets and\nclassify their types. Experimental results on the UNSW-NB15 and CIC-IOT23\ndatasets demonstrate that our transformer-based model is effective in\ndistinguishing malicious from benign traffic in the test dataset, attaining an\naverage accuracy of 79\\% using binary classification and 72\\% on the\nmulti-classification experiment, both using solely payload bytes.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18223v1",
    "published_date": "2024-03-27 03:25:45 UTC",
    "updated_date": "2024-03-27 03:25:45 UTC"
  },
  {
    "arxiv_id": "2403.18219v1",
    "title": "From Two-Dimensional to Three-Dimensional Environment with Q-Learning: Modeling Autonomous Navigation with Reinforcement Learning and no Libraries",
    "authors": [
      "Ergon Cugler de Moraes Silva"
    ],
    "abstract": "Reinforcement learning (RL) algorithms have become indispensable tools in\nartificial intelligence, empowering agents to acquire optimal decision-making\npolicies through interactions with their environment and feedback mechanisms.\nThis study explores the performance of RL agents in both two-dimensional (2D)\nand three-dimensional (3D) environments, aiming to research the dynamics of\nlearning across different spatial dimensions. A key aspect of this\ninvestigation is the absence of pre-made libraries for learning, with the\nalgorithm developed exclusively through computational mathematics. The\nmethodological framework centers on RL principles, employing a Q-learning agent\nclass and distinct environment classes tailored to each spatial dimension. The\nresearch aims to address the question: How do reinforcement learning agents\nadapt and perform in environments of varying spatial dimensions, particularly\nin 2D and 3D settings? Through empirical analysis, the study evaluates agents'\nlearning trajectories and adaptation processes, revealing insights into the\nefficacy of RL algorithms in navigating complex, multi-dimensional spaces.\nReflections on the findings prompt considerations for future research,\nparticularly in understanding the dynamics of learning in higher-dimensional\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18219v1",
    "published_date": "2024-03-27 03:07:18 UTC",
    "updated_date": "2024-03-27 03:07:18 UTC"
  },
  {
    "arxiv_id": "2403.18218v1",
    "title": "Leveraging Large Language Models for Fuzzy String Matching in Political Science",
    "authors": [
      "Yu Wang"
    ],
    "abstract": "Fuzzy string matching remains a key issue when political scientists combine\ndata from different sources. Existing matching methods invariably rely on\nstring distances, such as Levenshtein distance and cosine similarity. As such,\nthey are inherently incapable of matching strings that refer to the same entity\nwith different names such as ''JP Morgan'' and ''Chase Bank'', ''DPRK'' and\n''North Korea'', ''Chuck Fleischmann (R)'' and ''Charles Fleischmann (R)''. In\nthis letter, we propose to use large language models to entirely sidestep this\nproblem in an easy and intuitive manner. Extensive experiments show that our\nproposed methods can improve the state of the art by as much as 39% in terms of\naverage precision while being substantially easier and more intuitive to use by\npolitical scientists. Moreover, our results are robust against various\ntemperatures. We further note that enhanced prompting can lead to additional\nperformance improvements.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 2 figures, 1 table;",
    "pdf_url": "http://arxiv.org/pdf/2403.18218v1",
    "published_date": "2024-03-27 03:04:21 UTC",
    "updated_date": "2024-03-27 03:04:21 UTC"
  },
  {
    "arxiv_id": "2403.18212v2",
    "title": "Preference-Based Planning in Stochastic Environments: From Partially-Ordered Temporal Goals to Most Preferred Policies",
    "authors": [
      "Hazhar Rahmani",
      "Abhishek N. Kulkarni",
      "Jie Fu"
    ],
    "abstract": "Human preferences are not always represented via complete linear orders: It\nis natural to employ partially-ordered preferences for expressing incomparable\noutcomes. In this work, we consider decision-making and probabilistic planning\nin stochastic systems modeled as Markov decision processes (MDPs), given a\npartially ordered preference over a set of temporally extended goals.\nSpecifically, each temporally extended goal is expressed using a formula in\nLinear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially\nordered preference, we introduce order theory to map a preference over temporal\ngoals to a preference over policies for the MDP. Accordingly, a most preferred\npolicy under a stochastic ordering induces a stochastic nondominated\nprobability distribution over the finite paths in the MDP. To synthesize a most\npreferred policy, our technical approach includes two key steps. In the first\nstep, we develop a procedure to transform a partially ordered preference over\ntemporal goals into a computational model, called preference automaton, which\nis a semi-automaton with a partial order over acceptance conditions. In the\nsecond step, we prove that finding a most preferred policy is equivalent to\ncomputing a Pareto-optimal policy in a multi-objective MDP that is constructed\nfrom the original MDP, the preference automaton, and the chosen stochastic\nordering relation. Throughout the paper, we employ running examples to\nillustrate the proposed preference specification and solution approaches. We\ndemonstrate the efficacy of our algorithm using these examples, providing\ndetailed analysis, and then discuss several potential future directions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.FL",
      "cs.LO"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2209.12267",
    "pdf_url": "http://arxiv.org/pdf/2403.18212v2",
    "published_date": "2024-03-27 02:46:09 UTC",
    "updated_date": "2024-10-18 03:50:57 UTC"
  },
  {
    "arxiv_id": "2403.18209v2",
    "title": "Long and Short-Term Constraints Driven Safe Reinforcement Learning for Autonomous Driving",
    "authors": [
      "Xuemin Hu",
      "Pan Chen",
      "Yijun Wen",
      "Bo Tang",
      "Long Chen"
    ],
    "abstract": "Reinforcement learning (RL) has been widely used in decision-making and\ncontrol tasks, but the risk is very high for the agent in the training process\ndue to the requirements of interaction with the environment, which seriously\nlimits its industrial applications such as autonomous driving systems. Safe RL\nmethods are developed to handle this issue by constraining the expected safety\nviolation costs as a training objective, but the occurring probability of an\nunsafe state is still high, which is unacceptable in autonomous driving tasks.\nMoreover, these methods are difficult to achieve a balance between the cost and\nreturn expectations, which leads to learning performance degradation for the\nalgorithms. In this paper, we propose a novel algorithm based on the long and\nshort-term constraints (LSTC) for safe RL. The short-term constraint aims to\nenhance the short-term state safety that the vehicle explores, while the\nlong-term constraint enhances the overall safety of the vehicle throughout the\ndecision-making process, both of which are jointly used to enhance the vehicle\nsafety in the training process. In addition, we develop a safe RL method with\ndual-constraint optimization based on the Lagrange multiplier to optimize the\ntraining process for end-to-end autonomous driving. Comprehensive experiments\nwere conducted on the MetaDrive simulator. Experimental results demonstrate\nthat the proposed method achieves higher safety in continuous state and action\ntasks, and exhibits higher exploration performance in long-distance\ndecision-making tasks compared with state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18209v2",
    "published_date": "2024-03-27 02:41:52 UTC",
    "updated_date": "2024-09-12 12:59:19 UTC"
  },
  {
    "arxiv_id": "2403.18208v1",
    "title": "An Evolutionary Network Architecture Search Framework with Adaptive Multimodal Fusion for Hand Gesture Recognition",
    "authors": [
      "Yizhang Xia",
      "Shihao Song",
      "Zhanglu Hou",
      "Junwen Xu",
      "Juan Zou",
      "Yuan Liu",
      "Shengxiang Yang"
    ],
    "abstract": "Hand gesture recognition (HGR) based on multimodal data has attracted\nconsiderable attention owing to its great potential in applications. Various\nmanually designed multimodal deep networks have performed well in multimodal\nHGR (MHGR), but most of existing algorithms require a lot of expert experience\nand time-consuming manual trials. To address these issues, we propose an\nevolutionary network architecture search framework with the adaptive multimodel\nfusion (AMF-ENAS). Specifically, we design an encoding space that\nsimultaneously considers fusion positions and ratios of the multimodal data,\nallowing for the automatic construction of multimodal networks with different\narchitectures through decoding. Additionally, we consider three input streams\ncorresponding to intra-modal surface electromyography (sEMG), intra-modal\naccelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to\nvarious datasets, the ENAS framework is designed to automatically search a MHGR\nnetwork with appropriate fusion positions and ratios. To the best of our\nknowledge, this is the first time that ENAS has been utilized in MHGR to tackle\nissues related to the fusion position and ratio of multimodal data.\nExperimental results demonstrate that AMF-ENAS achieves state-of-the-art\nperformance on the Ninapro DB2, DB3, and DB7 datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18208v1",
    "published_date": "2024-03-27 02:39:23 UTC",
    "updated_date": "2024-03-27 02:39:23 UTC"
  },
  {
    "arxiv_id": "2403.18205v1",
    "title": "Exploring the Privacy Protection Capabilities of Chinese Large Language Models",
    "authors": [
      "Yuqi Yang",
      "Xiaowen Huang",
      "Jitao Sang"
    ],
    "abstract": "Large language models (LLMs), renowned for their impressive capabilities in\nvarious tasks, have significantly advanced artificial intelligence. Yet, these\nadvancements have raised growing concerns about privacy and security\nimplications. To address these issues and explain the risks inherent in these\nmodels, we have devised a three-tiered progressive framework tailored for\nevaluating privacy in language systems. This framework consists of\nprogressively complex and in-depth privacy test tasks at each tier. Our primary\nobjective is to comprehensively evaluate the sensitivity of large language\nmodels to private information, examining how effectively they discern, manage,\nand safeguard sensitive data in diverse scenarios. This systematic evaluation\nhelps us understand the degree to which these models comply with privacy\nprotection guidelines and the effectiveness of their inherent safeguards\nagainst privacy breaches. Our observations indicate that existing Chinese large\nlanguage models universally show privacy protection shortcomings. It seems that\nat the moment this widespread issue is unavoidable and may pose corresponding\nprivacy risks in applications based on these models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.18205v1",
    "published_date": "2024-03-27 02:31:54 UTC",
    "updated_date": "2024-03-27 02:31:54 UTC"
  },
  {
    "arxiv_id": "2403.18203v1",
    "title": "EndToEndML: An Open-Source End-to-End Pipeline for Machine Learning Applications",
    "authors": [
      "Nisha Pillai",
      "Athish Ram Das",
      "Moses Ayoola",
      "Ganga Gireesan",
      "Bindu Nanduri",
      "Mahalingam Ramkumar"
    ],
    "abstract": "Artificial intelligence (AI) techniques are widely applied in the life\nsciences. However, applying innovative AI techniques to understand and\ndeconvolute biological complexity is hindered by the learning curve for life\nscience scientists to understand and use computing languages. An open-source,\nuser-friendly interface for AI models, that does not require programming skills\nto analyze complex biological data will be extremely valuable to the\nbioinformatics community. With easy access to different sequencing technologies\nand increased interest in different 'omics' studies, the number of biological\ndatasets being generated has increased and analyzing these high-throughput\ndatasets is computationally demanding. The majority of AI libraries today\nrequire advanced programming skills as well as machine learning, data\npreprocessing, and visualization skills. In this research, we propose a\nweb-based end-to-end pipeline that is capable of preprocessing, training,\nevaluating, and visualizing machine learning (ML) models without manual\nintervention or coding expertise. By integrating traditional machine learning\nand deep neural network models with visualizations, our library assists in\nrecognizing, classifying, clustering, and predicting a wide range of\nmulti-modal, multi-sensor datasets, including images, languages, and\none-dimensional numerical data, for drug discovery, pathogen classification,\nand medical diagnostics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "2024 7th International Conference on Information and Computer\n  Technologies (ICICT)",
    "pdf_url": "http://arxiv.org/pdf/2403.18203v1",
    "published_date": "2024-03-27 02:24:38 UTC",
    "updated_date": "2024-03-27 02:24:38 UTC"
  },
  {
    "arxiv_id": "2403.18196v1",
    "title": "Looking Beyond What You See: An Empirical Analysis on Subgroup Intersectional Fairness for Multi-label Chest X-ray Classification Using Social Determinants of Racial Health Inequities",
    "authors": [
      "Dana Moukheiber",
      "Saurabh Mahindre",
      "Lama Moukheiber",
      "Mira Moukheiber",
      "Mingchen Gao"
    ],
    "abstract": "There has been significant progress in implementing deep learning models in\ndisease diagnosis using chest X- rays. Despite these advancements, inherent\nbiases in these models can lead to disparities in prediction accuracy across\nprotected groups. In this study, we propose a framework to achieve accurate\ndiagnostic outcomes and ensure fairness across intersectional groups in\nhigh-dimensional chest X- ray multi-label classification. Transcending\ntraditional protected attributes, we consider complex interactions within\nsocial determinants, enabling a more granular benchmark and evaluation of\nfairness. We present a simple and robust method that involves retraining the\nlast classification layer of pre-trained models using a balanced dataset across\ngroups. Additionally, we account for fairness constraints and integrate\nclass-balanced fine-tuning for multi-label settings. The evaluation of our\nmethod on the MIMIC-CXR dataset demonstrates that our framework achieves an\noptimal tradeoff between accuracy and fairness compared to baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "ICCV CVAMD 2023",
    "pdf_url": "http://arxiv.org/pdf/2403.18196v1",
    "published_date": "2024-03-27 02:13:20 UTC",
    "updated_date": "2024-03-27 02:13:20 UTC"
  },
  {
    "arxiv_id": "2403.18195v3",
    "title": "SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly Network",
    "authors": [
      "Yuxuan Wan",
      "Kaichen Zhou",
      "jinhong Chen",
      "Hao Dong"
    ],
    "abstract": "Autonomous assembly in robotics and 3D vision presents significant\nchallenges, particularly in ensuring assembly correctness. Presently,\npredominant methods such as MEPNet focus on assembling components based on\nmanually provided images. However, these approaches often fall short in\nachieving satisfactory results for tasks requiring long-term planning.\nConcurrently, we observe that integrating a self-correction module can\npartially alleviate such issues. Motivated by this concern, we introduce the\nSingle-Step Assembly Error Correction Task, which involves identifying and\nrectifying misassembled components. To support research in this area, we\npresent the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising\nmanual images for assembly steps and instances of assembly failures.\nAdditionally, we propose the Self-Correct Assembly Network (SCANet), a novel\nmethod to address this task. SCANet treats assembled components as queries,\ndetermining their correctness in manual images and providing corrections when\nnecessary. Finally, we utilize SCANet to correct the assembly results of\nMEPNet. Experimental results demonstrate that SCANet can identify and correct\nMEPNet's misassembled results, significantly improving the correctness of\nassembly. Our code and dataset could be found at\nhttps://scanet-iros2024.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18195v3",
    "published_date": "2024-03-27 02:08:12 UTC",
    "updated_date": "2024-10-24 04:59:25 UTC"
  },
  {
    "arxiv_id": "2403.18183v1",
    "title": "Can AI Models Appreciate Document Aesthetics? An Exploration of Legibility and Layout Quality in Relation to Prediction Confidence",
    "authors": [
      "Hsiu-Wei Yang",
      "Abhinav Agrawal",
      "Pavlos Fragkogiannis",
      "Shubham Nitin Mulay"
    ],
    "abstract": "A well-designed document communicates not only through its words but also\nthrough its visual eloquence. Authors utilize aesthetic elements such as\ncolors, fonts, graphics, and layouts to shape the perception of information.\nThoughtful document design, informed by psychological insights, enhances both\nthe visual appeal and the comprehension of the content. While state-of-the-art\ndocument AI models demonstrate the benefits of incorporating layout and image\ndata, it remains unclear whether the nuances of document aesthetics are\neffectively captured. To bridge the gap between human cognition and AI\ninterpretation of aesthetic elements, we formulated hypotheses concerning AI\nbehavior in document understanding tasks, specifically anchored in document\ndesign principles. With a focus on legibility and layout quality, we tested\nfour aspects of aesthetic effects: noise, font-size contrast, alignment, and\ncomplexity, on model confidence using correlational analysis. The results and\nobservations highlight the value of model analysis rooted in document design\ntheories. Our work serves as a trailhead for further studies and we advocate\nfor continued research in this topic to deepen our understanding of how AI\ninterprets document aesthetics.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18183v1",
    "published_date": "2024-03-27 01:21:48 UTC",
    "updated_date": "2024-03-27 01:21:48 UTC"
  },
  {
    "arxiv_id": "2403.18167v2",
    "title": "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations",
    "authors": [
      "Lei Yu",
      "Meng Cao",
      "Jackie Chi Kit Cheung",
      "Yue Dong"
    ],
    "abstract": "State-of-the-art language models (LMs) sometimes generate non-factual\nhallucinations that misalign with world knowledge. To explore the mechanistic\ncauses of these hallucinations, we create diagnostic datasets with\nsubject-relation queries and adapt interpretability methods to trace\nhallucinations through internal model representations. We discover two general\nand distinct mechanistic causes of hallucinations shared across LMs (Llama-2,\nPythia, GPT-J): 1) knowledge enrichment hallucinations: insufficient subject\nattribute knowledge in lower layer MLPs, and 2) answer extraction\nhallucinations: failure to select the correct object attribute in upper layer\nattention heads. We also found these two internal mechanistic causes of\nhallucinations are reflected in external manifestations. Based on insights from\nour mechanistic analysis, we propose a novel hallucination mitigation method\nthrough targeted restoration of the LM's internal fact recall pipeline,\ndemonstrating superior performance compared to baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18167v2",
    "published_date": "2024-03-27 00:23:03 UTC",
    "updated_date": "2024-06-17 21:35:41 UTC"
  }
]