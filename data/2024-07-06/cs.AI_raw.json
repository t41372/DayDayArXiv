[
  {
    "arxiv_id": "2407.05213v1",
    "title": "BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records",
    "authors": [
      "Weimin Lyu",
      "Zexin Bi",
      "Fusheng Wang",
      "Chao Chen"
    ],
    "abstract": "The advent of clinical language models integrated into electronic health\nrecords (EHR) for clinical decision support has marked a significant\nadvancement, leveraging the depth of clinical notes for improved\ndecision-making. Despite their success, the potential vulnerabilities of these\nmodels remain largely unexplored. This paper delves into the realm of backdoor\nattacks on clinical language models, introducing an innovative attention-based\nbackdoor attack method, BadCLM (Bad Clinical Language Models). This technique\nclandestinely embeds a backdoor within the models, causing them to produce\nincorrect predictions when a pre-defined trigger is present in inputs, while\nfunctioning accurately otherwise. We demonstrate the efficacy of BadCLM through\nan in-hospital mortality prediction task with MIMIC III dataset, showcasing its\npotential to compromise model integrity. Our findings illuminate a significant\nsecurity risk in clinical decision support systems and pave the way for future\nendeavors in fortifying clinical language models against such vulnerabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AMIA 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.05213v1",
    "published_date": "2024-07-06 23:56:43 UTC",
    "updated_date": "2024-07-06 23:56:43 UTC"
  },
  {
    "arxiv_id": "2407.05202v1",
    "title": "Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing",
    "authors": [
      "Rabimba Karanjai",
      "Aftab Hussain",
      "Md Rafiqul Islam Rabin",
      "Lei Xu",
      "Weidong Shi",
      "Mohammad Amin Alipour"
    ],
    "abstract": "Unit testing is crucial in software engineering for ensuring quality.\nHowever, it's not widely used in parallel and high-performance computing\nsoftware, particularly scientific applications, due to their smaller, diverse\nuser base and complex logic. These factors make unit testing challenging and\nexpensive, as it requires specialized knowledge and existing automated tools\nare often ineffective.\n  To address this, we propose an automated method for generating unit tests for\nsuch software, considering their unique features like complex logic and\nparallel processing. Recently, large language models (LLMs) have shown promise\nin coding and testing. We explored the capabilities of Davinci\n(text-davinci-002) and ChatGPT (gpt-3.5-turbo) in creating unit tests for C++\nparallel programs. Our results show that LLMs can generate mostly correct and\ncomprehensive unit tests, although they have some limitations, such as\nrepetitive assertions and blank test cases.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05202v1",
    "published_date": "2024-07-06 22:45:55 UTC",
    "updated_date": "2024-07-06 22:45:55 UTC"
  },
  {
    "arxiv_id": "2407.05197v1",
    "title": "A Generalized Transformer-based Radio Link Failure Prediction Framework in 5G RANs",
    "authors": [
      "Kazi Hasan",
      "Thomas Trappenberg",
      "Israat Haque"
    ],
    "abstract": "Radio link failure (RLF) prediction system in Radio Access Networks (RANs) is\ncritical for ensuring seamless communication and meeting the stringent\nrequirements of high data rates, low latency, and improved reliability in 5G\nnetworks. However, weather conditions such as precipitation, humidity,\ntemperature, and wind impact these communication links. Usually, historical\nradio link Key Performance Indicators (KPIs) and their surrounding weather\nstation observations are utilized for building learning-based RLF prediction\nmodels. However, such models must be capable of learning the spatial weather\ncontext in a dynamic RAN and effectively encoding time series KPIs with the\nweather observation data. Existing works fail to incorporate both of these\nessential design aspects of the prediction models. This paper fills the gap by\nproposing GenTrap, a novel RLF prediction framework that introduces a graph\nneural network (GNN)-based learnable weather effect aggregation module and\nemploys state-of-the-art time series transformer as the temporal feature\nextractor for radio link failure prediction. The proposed aggregation method of\nGenTrap can be integrated into any existing prediction model to achieve better\nperformance and generalizability. We evaluate GenTrap on two real-world\ndatasets (rural and urban) with 2.6 million KPI data points and show that\nGenTrap offers a significantly higher F1-score (0.93 for rural and 0.79 for\nurban) compared to its counterparts while possessing generalization capability.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05197v1",
    "published_date": "2024-07-06 21:57:23 UTC",
    "updated_date": "2024-07-06 21:57:23 UTC"
  },
  {
    "arxiv_id": "2407.05193v2",
    "title": "CBM: Curriculum by Masking",
    "authors": [
      "Andrei Jarca",
      "Florinel-Alin Croitoru",
      "Radu Tudor Ionescu"
    ],
    "abstract": "We propose Curriculum by Masking (CBM), a novel state-of-the-art curriculum\nlearning strategy that effectively creates an easy-to-hard training schedule\nvia patch (token) masking, offering significant accuracy improvements over the\nconventional training regime and previous curriculum learning (CL) methods. CBM\nleverages gradient magnitudes to prioritize the masking of salient image\nregions via a novel masking algorithm and a novel masking block. Our approach\nenables controlling sample difficulty via the patch masking ratio, generating\nan effective easy-to-hard curriculum by gradually introducing harder samples as\ntraining progresses. CBM operates with two easily configurable parameters, i.e.\nthe number of patches and the curriculum schedule, making it a versatile\ncurriculum learning approach for object recognition and detection. We conduct\nexperiments with various neural architectures, ranging from convolutional\nnetworks to vision transformers, on five benchmark data sets (CIFAR-10,\nCIFAR-100, ImageNet, Food-101 and PASCAL VOC), to compare CBM with conventional\nas well as curriculum-based training regimes. Our results reveal the\nsuperiority of our strategy compared with the state-of-the-art curriculum\nlearning regimes. We also observe improvements in transfer learning contexts,\nwhere CBM surpasses previous work by considerable margins in terms of accuracy.\nWe release our code for free non-commercial use at\nhttps://github.com/CroitoruAlin/CBM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.05193v2",
    "published_date": "2024-07-06 21:35:18 UTC",
    "updated_date": "2024-07-09 09:40:38 UTC"
  },
  {
    "arxiv_id": "2407.05183v2",
    "title": "FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding",
    "authors": [
      "Huitong Pan",
      "Qi Zhang",
      "Cornelia Caragea",
      "Eduard Dragut",
      "Longin Jan Latecki"
    ],
    "abstract": "Flowcharts are graphical tools for representing complex concepts in concise\nvisual representations. This paper introduces the FlowLearn dataset, a resource\ntailored to enhance the understanding of flowcharts. FlowLearn contains complex\nscientific flowcharts and simulated flowcharts. The scientific subset contains\n3,858 flowcharts sourced from scientific literature and the simulated subset\ncontains 10,000 flowcharts created using a customizable script. The dataset is\nenriched with annotations for visual components, OCR, Mermaid code\nrepresentation, and VQA question-answer pairs. Despite the proven capabilities\nof Large Vision-Language Models (LVLMs) in various visual understanding tasks,\ntheir effectiveness in decoding flowcharts - a crucial element of scientific\ncommunication - has yet to be thoroughly investigated. The FlowLearn test set\nis crafted to assess the performance of LVLMs in flowchart comprehension. Our\nstudy thoroughly evaluates state-of-the-art LVLMs, identifying existing\nlimitations and establishing a foundation for future enhancements in this\nrelatively underexplored domain. For instance, in tasks involving simulated\nflowcharts, GPT-4V achieved the highest accuracy (58%) in counting the number\nof nodes, while Claude recorded the highest accuracy (83%) in OCR tasks.\nNotably, no single model excels in all tasks within the FlowLearn framework,\nhighlighting significant opportunities for further development.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.05183v2",
    "published_date": "2024-07-06 20:58:51 UTC",
    "updated_date": "2024-07-09 21:16:00 UTC"
  },
  {
    "arxiv_id": "2407.05174v1",
    "title": "Synthetic Data Aided Federated Learning Using Foundation Models",
    "authors": [
      "Fatima Abacha",
      "Sin G. Teo",
      "Lucas C. Cordeiro",
      "Mustafa A. Mustafa"
    ],
    "abstract": "In heterogeneous scenarios where the data distribution amongst the Federated\nLearning (FL) participants is Non-Independent and Identically distributed\n(Non-IID), FL suffers from the well known problem of data heterogeneity. This\nleads the performance of FL to be significantly degraded, as the global model\ntends to struggle to converge. To solve this problem, we propose Differentially\nPrivate Synthetic Data Aided Federated Learning Using Foundation Models\n(DPSDA-FL), a novel data augmentation strategy that aids in homogenizing the\nlocal data present on the clients' side. DPSDA-FL improves the training of the\nlocal models by leveraging differentially private synthetic data generated from\nfoundation models. We demonstrate the effectiveness of our approach by\nevaluating it on the benchmark image dataset: CIFAR-10. Our experimental\nresults have shown that DPSDA-FL can improve class recall and classification\naccuracy of the global model by up to 26% and 9%, respectively, in FL with\nNon-IID issues.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05174v1",
    "published_date": "2024-07-06 20:31:43 UTC",
    "updated_date": "2024-07-06 20:31:43 UTC"
  },
  {
    "arxiv_id": "2407.05154v1",
    "title": "Identifying Intensity of the Structure and Content in Tweets and the Discriminative Power of Attributes in Context with Referential Translation Machines",
    "authors": [
      "Ergun Biçici"
    ],
    "abstract": "We use referential translation machines (RTMs) to identify the similarity\nbetween an attribute and two words in English by casting the task as machine\ntranslation performance prediction (MTPP) between the words and the attribute\nword and the distance between their similarities for Task 10 with stacked RTM\nmodels. RTMs are also used to predict the intensity of the structure and\ncontent in tweets in English, Arabic, and Spanish in Task 1 where MTPP is\nbetween the tweets and the set of words for the emotion selected from WordNet\naffect emotion lists. Stacked RTM models obtain encouraging results in both.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 3 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.05154v1",
    "published_date": "2024-07-06 18:58:10 UTC",
    "updated_date": "2024-07-06 18:58:10 UTC"
  },
  {
    "arxiv_id": "2407.05153v1",
    "title": "Lucy: Think and Reason to Solve Text-to-SQL",
    "authors": [
      "Nina Narodytska",
      "Shay Vargaftik"
    ],
    "abstract": "Large Language Models (LLMs) have made significant progress in assisting\nusers to query databases in natural language. While LLM-based techniques\nprovide state-of-the-art results on many standard benchmarks, their performance\nsignificantly drops when applied to large enterprise databases. The reason is\nthat these databases have a large number of tables with complex relationships\nthat are challenging for LLMs to reason about. We analyze challenges that LLMs\nface in these settings and propose a new solution that combines the power of\nLLMs in understanding questions with automated reasoning techniques to handle\ncomplex database constraints. Based on these ideas, we have developed a new\nframework that outperforms state-of-the-art techniques in zero-shot text-to-SQL\non complex benchmarks",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05153v1",
    "published_date": "2024-07-06 18:56:42 UTC",
    "updated_date": "2024-07-06 18:56:42 UTC"
  },
  {
    "arxiv_id": "2407.05138v2",
    "title": "Are LLMs Correctly Integrated into Software Systems?",
    "authors": [
      "Yuchen Shao",
      "Yuheng Huang",
      "Jiawei Shen",
      "Lei Ma",
      "Ting Su",
      "Chengcheng Wan"
    ],
    "abstract": "Large language models (LLMs) provide effective solutions in various\napplication scenarios, with the support of retrieval-augmented generation\n(RAG). However, developers face challenges in integrating LLM and RAG into\nsoftware systems, due to lacking interface specifications, various requirements\nfrom software context, and complicated system management. In this paper, we\nhave conducted a comprehensive study of 100 open-source applications that\nincorporate LLMs with RAG support, and identified 18 defect patterns. Our study\nreveals that 77% of these applications contain more than three types of\nintegration defects that degrade software functionality, efficiency, and\nsecurity. Guided by our study, we propose systematic guidelines for resolving\nthese defects in software life cycle. We also construct an open-source defect\nlibrary Hydrangea.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "accepted by ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.05138v2",
    "published_date": "2024-07-06 17:25:11 UTC",
    "updated_date": "2025-02-08 08:57:00 UTC"
  },
  {
    "arxiv_id": "2407.05134v1",
    "title": "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?",
    "authors": [
      "Kuei-Chun Kao",
      "Ruochen Wang",
      "Cho-Jui Hsieh"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in\nsolving math problems, a hallmark of human intelligence. Despite high success\nrates on current benchmarks; however, these often feature simple problems with\nonly one or two unknowns, which do not sufficiently challenge their reasoning\ncapacities. This paper introduces a novel benchmark, BeyondX, designed to\naddress these limitations by incorporating problems with multiple unknowns.\nRecognizing the challenges in proposing multi-unknown problems from scratch, we\ndeveloped BeyondX using an innovative automated pipeline that progressively\nincreases complexity by expanding the number of unknowns in simpler problems.\nEmpirical study on BeyondX reveals that the performance of existing LLMs, even\nthose fine-tuned specifically on math tasks, significantly decreases as the\nnumber of unknowns increases - with a performance drop of up to 70\\% observed\nin GPT-4. To tackle these challenges, we propose the Formulate-and-Solve\nstrategy, a generalized prompting approach that effectively handles problems\nwith an arbitrary number of unknowns. Our findings reveal that this strategy\nnot only enhances LLM performance on the BeyondX benchmark but also provides\ndeeper insights into the computational limits of LLMs when faced with more\ncomplex mathematical challenges.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05134v1",
    "published_date": "2024-07-06 17:01:04 UTC",
    "updated_date": "2024-07-06 17:01:04 UTC"
  },
  {
    "arxiv_id": "2407.05131v2",
    "title": "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models",
    "authors": [
      "Peng Xia",
      "Kangyu Zhu",
      "Haoran Li",
      "Hongtu Zhu",
      "Yun Li",
      "Gang Li",
      "Linjun Zhang",
      "Huaxiu Yao"
    ],
    "abstract": "The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has\nenhanced medical diagnosis. However, current Med-LVLMs frequently encounter\nfactual issues, often generating responses that do not align with established\nmedical facts. Retrieval-Augmented Generation (RAG), which utilizes external\nknowledge, can improve the factual accuracy of these models but introduces two\nmajor challenges. First, limited retrieved contexts might not cover all\nnecessary information, while excessive retrieval can introduce irrelevant and\ninaccurate references, interfering with the model's generation. Second, in\ncases where the model originally responds correctly, applying RAG can lead to\nan over-reliance on retrieved contexts, resulting in incorrect answers. To\naddress these issues, we propose RULE, which consists of two components. First,\nwe introduce a provably effective strategy for controlling factuality risk\nthrough the calibrated selection of the number of retrieved contexts. Second,\nbased on samples where over-reliance on retrieved contexts led to errors, we\ncurate a preference dataset to fine-tune the model, balancing its dependence on\ninherent knowledge and retrieved contexts for generation. We demonstrate the\neffectiveness of RULE on medical VQA and report generation tasks across three\ndatasets, achieving an average improvement of 47.4% in factual accuracy. We\npublicly release our benchmark and code in\nhttps://github.com/richard-peng-xia/RULE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2024 main",
    "pdf_url": "http://arxiv.org/pdf/2407.05131v2",
    "published_date": "2024-07-06 16:45:07 UTC",
    "updated_date": "2024-10-17 01:55:28 UTC"
  },
  {
    "arxiv_id": "2407.05116v1",
    "title": "Automatic Prediction of the Performance of Every Parser",
    "authors": [
      "Ergun Biçici"
    ],
    "abstract": "We present a new parser performance prediction (PPP) model using machine\ntranslation performance prediction system (MTPPS), statistically independent of\nany language or parser, relying only on extrinsic and novel features based on\ntextual, link structural, and bracketing tree structural information. This new\nsystem, MTPPS-PPP, can predict the performance of any parser in any language\nand can be useful for estimating the grammatical difficulty when understanding\na given text, for setting expectations from parsing output, for parser\nselection for a specific domain, and for parser combination systems. We obtain\nSoA results in PPP of bracketing $F_1$ with better results over textual\nfeatures and similar performance with previous results that use parser and\nlinguistic label specific information. Our results show the contribution of\ndifferent types of features as well as rankings of individual features in\ndifferent experimental settings (cased vs. uncased), in different learning\ntasks (in-domain vs. out-of-domain), with different training sets, with\ndifferent learning algorithms, and with different dimensionality reduction\ntechniques. We achieve $0.0678$ MAE and $0.85$ RAE in setting +Link, which\ncorresponds to about $7.4\\%$ error when predicting the bracketing $F_1$ score\nfor the Charniak and Johnson parser on the WSJ23 test set. MTPPS-PPP system can\npredict without parsing using only the text, without a supervised parser using\nonly an unsupervised parser, without any parser or language dependent\ninformation, without using a reference parser output, and can be used to\npredict the performance of any parser in any language.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.05116v1",
    "published_date": "2024-07-06 15:49:24 UTC",
    "updated_date": "2024-07-06 15:49:24 UTC"
  },
  {
    "arxiv_id": "2407.05112v1",
    "title": "Releasing Malevolence from Benevolence: The Menace of Benign Data on Machine Unlearning",
    "authors": [
      "Binhao Ma",
      "Tianhang Zheng",
      "Hongsheng Hu",
      "Di Wang",
      "Shuo Wang",
      "Zhongjie Ba",
      "Zhan Qin",
      "Kui Ren"
    ],
    "abstract": "Machine learning models trained on vast amounts of real or synthetic data\noften achieve outstanding predictive performance across various domains.\nHowever, this utility comes with increasing concerns about privacy, as the\ntraining data may include sensitive information. To address these concerns,\nmachine unlearning has been proposed to erase specific data samples from\nmodels. While some unlearning techniques efficiently remove data at low costs,\nrecent research highlights vulnerabilities where malicious users could request\nunlearning on manipulated data to compromise the model. Despite these attacks'\neffectiveness, perturbed data differs from original training data, failing hash\nverification. Existing attacks on machine unlearning also suffer from practical\nlimitations and require substantial additional knowledge and resources. To fill\nthe gaps in current unlearning attacks, we introduce the Unlearning Usability\nAttack. This model-agnostic, unlearning-agnostic, and budget-friendly attack\ndistills data distribution information into a small set of benign data. These\ndata are identified as benign by automatic poisoning detection tools due to\ntheir positive impact on model training. While benign for machine learning,\nunlearning these data significantly degrades model information. Our evaluation\ndemonstrates that unlearning this benign data, comprising no more than 1% of\nthe total training data, can reduce model accuracy by up to 50%. Furthermore,\nour findings show that well-prepared benign data poses challenges for recent\nunlearning techniques, as erasing these synthetic instances demands higher\nresources than regular data. These insights underscore the need for future\nresearch to reconsider \"data poisoning\" in the context of machine unlearning.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05112v1",
    "published_date": "2024-07-06 15:42:28 UTC",
    "updated_date": "2024-07-06 15:42:28 UTC"
  },
  {
    "arxiv_id": "2407.11042v1",
    "title": "An Automated Approach to Collecting and Labeling Time Series Data for Event Detection Using Elastic Node Hardware",
    "authors": [
      "Tianheng Ling",
      "Islam Mansour",
      "Chao Qian",
      "Gregor Schiele"
    ],
    "abstract": "Recent advancements in IoT technologies have underscored the importance of\nusing sensor data to understand environmental contexts effectively. This paper\nintroduces a novel embedded system designed to autonomously label sensor data\ndirectly on IoT devices, thereby enhancing the efficiency of data collection\nmethods. We present an integrated hardware and software solution equipped with\nspecialized labeling sensors that streamline the capture and labeling of\ndiverse types of sensor data. By implementing local processing with lightweight\nlabeling methods, our system minimizes the need for extensive data transmission\nand reduces dependence on external resources. Experimental validation with\ncollected data and a Convolutional Neural Network model achieved a high\nclassification accuracy of up to 91.67%, as confirmed through 4-fold\ncross-validation. These results demonstrate the system's robust capability to\ncollect audio and vibration data with correct labels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is accepted by the 4th Workshop on Collaborative\n  Technologies and Data Science in Smart City Applications (CODASSCA 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.11042v1",
    "published_date": "2024-07-06 15:19:16 UTC",
    "updated_date": "2024-07-06 15:19:16 UTC"
  },
  {
    "arxiv_id": "2407.05102v1",
    "title": "Towards Auto-Building of Embedded FPGA-based Soft Sensors for Wastewater Flow Estimation",
    "authors": [
      "Tianheng Ling",
      "Chao Qian",
      "Gregor Schiele"
    ],
    "abstract": "Executing flow estimation using Deep Learning (DL)-based soft sensors on\nresource-limited IoT devices has demonstrated promise in terms of reliability\nand energy efficiency. However, its application in the field of wastewater flow\nestimation remains underexplored due to: (1) a lack of available datasets, (2)\ninconvenient toolchains for on-device AI model development and deployment, and\n(3) hardware platforms designed for general DL purposes rather than being\noptimized for energy-efficient soft sensor applications. This study addresses\nthese gaps by proposing an automated, end-to-end solution for wastewater flow\nestimation using a prototype IoT device.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "This paper is accepted by 2024 IEEE Annual Congress on Artificial\n  Intelligence of Things (IEEE AIoT)",
    "pdf_url": "http://arxiv.org/pdf/2407.05102v1",
    "published_date": "2024-07-06 15:10:27 UTC",
    "updated_date": "2024-07-06 15:10:27 UTC"
  },
  {
    "arxiv_id": "2407.12051v1",
    "title": "Dy-mer: An Explainable DNA Sequence Representation Scheme using Sparse Recovery",
    "authors": [
      "Zhiyuan Peng",
      "Yuanbo Tang",
      "Yang Li"
    ],
    "abstract": "DNA sequences encode vital genetic and biological information, yet these\nunfixed-length sequences cannot serve as the input of common data mining\nalgorithms. Hence, various representation schemes have been developed to\ntransform DNA sequences into fixed-length numerical representations. However,\nthese schemes face difficulties in learning high-quality representations due to\nthe complexity and sparsity of DNA data. Additionally, DNA sequences are\ninherently noisy because of mutations. While several schemes have been proposed\nfor their effectiveness, they often lack semantic structure, making it\ndifficult for biologists to validate and leverage the results. To address these\nchallenges, we propose \\textbf{Dy-mer}, an explainable and robust DNA\nrepresentation scheme based on sparse recovery. Leveraging the underlying\nsemantic structure of DNA, we modify the traditional sparse recovery to capture\nrecurring patterns indicative of biological functions by representing frequent\nK-mers as basis vectors and reconstructing each DNA sequence through simple\nconcatenation. Experimental results demonstrate that \\textbf{Dy-mer} achieves\nstate-of-the-art performance in DNA promoter classification, yielding a\nremarkable \\textbf{13\\%} increase in accuracy. Moreover, its inherent\nexplainability facilitates DNA clustering and motif detection, enhancing its\nutility in biological research.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12051v1",
    "published_date": "2024-07-06 15:08:31 UTC",
    "updated_date": "2024-07-06 15:08:31 UTC"
  },
  {
    "arxiv_id": "2407.11041v4",
    "title": "Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT",
    "authors": [
      "Tianheng Ling",
      "Chao Qian",
      "Gregor Schiele"
    ],
    "abstract": "This paper presents the design of a hardware accelerator for Transformers,\noptimized for on-device time-series forecasting in AIoT systems. It integrates\ninteger-only quantization and Quantization-Aware Training with optimized\nhardware designs to realize 6-bit and 4-bit quantized Transformer models, which\nachieved precision comparable to 8-bit quantized models from related research.\nUtilizing a complete implementation on an embedded FPGA (Xilinx Spartan-7\nXC7S15), we examine the feasibility of deploying Transformer models on embedded\nIoT devices. This includes a thorough analysis of achievable precision,\nresource utilization, timing, power, and energy consumption for on-device\ninference. Our results indicate that while sufficient performance can be\nattained, the optimization process is not trivial. For instance, reducing the\nquantization bitwidth does not consistently result in decreased latency or\nenergy consumption, underscoring the necessity of systematically exploring\nvarious optimization combinations. Compared to an 8-bit quantized Transformer\nmodel in related studies, our 4-bit quantized Transformer model increases test\nloss by only 0.63%, operates up to 132.33x faster, and consumes 48.19x less\nenergy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 2024 IEEE Annual Congress on Artificial Intelligence of\n  Things (IEEE AIoT) and got best paper award. 7 pages, 3 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.11041v4",
    "published_date": "2024-07-06 15:03:40 UTC",
    "updated_date": "2024-10-04 10:15:10 UTC"
  },
  {
    "arxiv_id": "2407.05098v2",
    "title": "FedTSA: A Cluster-based Two-Stage Aggregation Method for Model-heterogeneous Federated Learning",
    "authors": [
      "Boyu Fan",
      "Chenrui Wu",
      "Xiang Su",
      "Pan Hui"
    ],
    "abstract": "Despite extensive research into data heterogeneity in federated learning\n(FL), system heterogeneity remains a significant yet often overlooked\nchallenge. Traditional FL approaches typically assume homogeneous hardware\nresources across FL clients, implying that clients can train a global model\nwithin a comparable time frame. However, in practical FL systems, clients often\nhave heterogeneous resources, which impacts their training capacity. This\ndiscrepancy underscores the importance of exploring model-heterogeneous FL, a\nparadigm allowing clients to train different models based on their resource\ncapabilities. To address this challenge, we introduce FedTSA, a cluster-based\ntwo-stage aggregation method tailored for system heterogeneity in FL. FedTSA\nbegins by clustering clients based on their capabilities, then performs a\ntwo-stage aggregation: conventional weight averaging for homogeneous models in\nStage 1, and deep mutual learning with a diffusion model for aggregating\nheterogeneous models in Stage 2. Extensive experiments demonstrate that FedTSA\nnot only outperforms the baselines but also explores various factors\ninfluencing model performance, validating FedTSA as a promising approach for\nmodel-heterogeneous FL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.05098v2",
    "published_date": "2024-07-06 14:59:55 UTC",
    "updated_date": "2024-07-15 08:19:30 UTC"
  },
  {
    "arxiv_id": "2407.06227v2",
    "title": "Communication and Control Co-Design in 6G: Sequential Decision-Making with LLMs",
    "authors": [
      "Xianfu Chen",
      "Celimuge Wu",
      "Yi Shen",
      "Yusheng Ji",
      "Tsutomu Yoshinaga",
      "Qiang Ni",
      "Charilaos C. Zarakovitis",
      "Honggang Zhang"
    ],
    "abstract": "This article investigates a control system within the context of\nsix-generation wireless networks. The control performance optimization\nconfronts the technical challenges that arise from the intricate interactions\nbetween communication and control sub-systems, asking for a co-design.\nAccounting for the system dynamics, we formulate the sequential co-design\ndecision-makings of communication and control over the discrete time horizon as\na Markov decision process, for which a practical offline learning framework is\nproposed. Our proposed framework integrates large language models into the\nelements of reinforcement learning. We present a case study on the age of\nsemantics-aware communication and control co-design to showcase the potentials\nfrom our proposed learning framework. Furthermore, we discuss the open issues\nremaining to make our proposed offline learning framework feasible for\nreal-world implementations, and highlight the research directions for future\nexplorations.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06227v2",
    "published_date": "2024-07-06 14:49:46 UTC",
    "updated_date": "2024-09-09 11:38:24 UTC"
  },
  {
    "arxiv_id": "2407.05087v1",
    "title": "Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal",
    "authors": [
      "Xiao Siyao",
      "Huang Libing",
      "Zhang Shunsheng"
    ],
    "abstract": "Multiplicative noise widely exists in radar images, medical images and other\nimportant fields' images. Compared to normal noises, multiplicative noise has a\ngenerally stronger effect on the visual expression of images. Aiming at the\ndenoising problem of multiplicative noise, we linearize the nonlocal means\nalgorithm with deep learning and propose a linear attention mechanism based\ndeep nonlocal means filtering (LDNLM). Starting from the traditional nonlocal\nmeans filtering, we employ deep channel convolution neural networks to extract\nthe information of the neighborhood matrix and obtain representation vectors of\nevery pixel. Then we replace the similarity calculation and weighted averaging\nprocesses with the inner operations of the attention mechanism. To reduce the\ncomputational overhead, through the formula of similarity calculation and\nweighted averaging, we derive a nonlocal filter with linear complexity.\nExperiments on both simulated and real multiplicative noise demonstrate that\nthe LDNLM is more competitive compared with the state-of-the-art methods.\nAdditionally, we prove that the LDNLM possesses interpretability close to\ntraditional NLM.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05087v1",
    "published_date": "2024-07-06 14:22:07 UTC",
    "updated_date": "2024-07-06 14:22:07 UTC"
  },
  {
    "arxiv_id": "2407.05082v1",
    "title": "DMTG: One-Shot Differentiable Multi-Task Grouping",
    "authors": [
      "Yuan Gao",
      "Shuguo Jiang",
      "Moran Li",
      "Jin-Gang Yu",
      "Gui-Song Xia"
    ],
    "abstract": "We aim to address Multi-Task Learning (MTL) with a large number of tasks by\nMulti-Task Grouping (MTG). Given N tasks, we propose to simultaneously identify\nthe best task groups from 2^N candidates and train the model weights\nsimultaneously in one-shot, with the high-order task-affinity fully exploited.\nThis is distinct from the pioneering methods which sequentially identify the\ngroups and train the model weights, where the group identification often relies\non heuristics. As a result, our method not only improves the training\nefficiency, but also mitigates the objective bias introduced by the sequential\nprocedures that potentially lead to a suboptimal solution. Specifically, we\nformulate MTG as a fully differentiable pruning problem on an adaptive network\narchitecture determined by an underlying Categorical distribution. To\ncategorize N tasks into K groups (represented by K encoder branches), we\ninitially set up KN task heads, where each branch connects to all N task heads\nto exploit the high-order task-affinity. Then, we gradually prune the KN heads\ndown to N by learning a relaxed differentiable Categorical distribution,\nensuring that each task is exclusively and uniquely categorized into only one\nbranch. Extensive experiments on CelebA and Taskonomy datasets with detailed\nablations show the promising performance and efficiency of our method. The\ncodes are available at https://github.com/ethanygao/DMTG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.05082v1",
    "published_date": "2024-07-06 13:54:00 UTC",
    "updated_date": "2024-07-06 13:54:00 UTC"
  },
  {
    "arxiv_id": "2407.05079v1",
    "title": "Form Forge: Latent Space Exploration of Architectural Forms via Explicit Latent Variable Manipulation",
    "authors": [
      "Kevin Dunnell",
      "Andy Lippman"
    ],
    "abstract": "This paper presents 'Form Forge,' a prototype of a creative system for\ninteractively exploring the latent space of architectural forms, inspired by\nFranois Blanciak's SITELESS: 1001 Building Forms via direct manipulation of\nlatent variables. Utilizing a fine-tuned StyleGAN2-ADA model, the system allows\nusers to navigate an array of possible building forms derived from Blanciak's\nsketches. Distinct from common latent space exploration tools that often rely\non projected navigation landmarks, Form Forge provides direct access to\nmanipulate each latent variable, aiming to offer a more granular exploration of\nthe model's capabilities. Form Forge's design is intended to simplify the\ninteraction with a complex, high-dimensional space and to serve as a\npreliminary investigation into how such tools might support creative processes\nin architectural design.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05079v1",
    "published_date": "2024-07-06 13:46:23 UTC",
    "updated_date": "2024-07-06 13:46:23 UTC"
  },
  {
    "arxiv_id": "2407.05058v1",
    "title": "Advancing Algorithmic Approaches to Probabilistic Argumentation under the Constellation Approach",
    "authors": [
      "Andrei Popescu",
      "Johannes P. Wallner"
    ],
    "abstract": "Reasoning with defeasible and conflicting knowledge in an argumentative form\nis a key research field in computational argumentation. Reasoning under various\nforms of uncertainty is both a key feature and a challenging barrier for\nautomated argumentative reasoning. It was shown that argumentative reasoning\nusing probabilities faces in general high computational complexity, in\nparticular for the so-called constellation approach. In this paper, we develop\nan algorithmic approach to overcome this obstacle. We refine existing\ncomplexity results and show that two main reasoning tasks, that of computing\nthe probability of a given set being an extension and an argument being\nacceptable, diverge in their complexity: the former is #P-complete and the\nlatter is #-dot-NP-complete when considering their underlying counting\nproblems. We present an algorithm for the complex task of computing the\nprobability of a set of arguments being a complete extension by using dynamic\nprogramming operating on tree-decompositions. An experimental evaluation shows\npromise of our approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05058v1",
    "published_date": "2024-07-06 12:08:38 UTC",
    "updated_date": "2024-07-06 12:08:38 UTC"
  },
  {
    "arxiv_id": "2407.05047v3",
    "title": "MFE-ETP: A Comprehensive Evaluation Benchmark for Multi-modal Foundation Models on Embodied Task Planning",
    "authors": [
      "Min Zhang",
      "Xian Fu",
      "Jianye Hao",
      "Peilong Han",
      "Hao Zhang",
      "Lei Shi",
      "Hongyao Tang",
      "Yan Zheng"
    ],
    "abstract": "In recent years, Multi-modal Foundation Models (MFMs) and Embodied Artificial\nIntelligence (EAI) have been advancing side by side at an unprecedented pace.\nThe integration of the two has garnered significant attention from the AI\nresearch community. In this work, we attempt to provide an in-depth and\ncomprehensive evaluation of the performance of MFM s on embodied task planning,\naiming to shed light on their capabilities and limitations in this domain. To\nthis end, based on the characteristics of embodied task planning, we first\ndevelop a systematic evaluation framework, which encapsulates four crucial\ncapabilities of MFMs: object understanding, spatio-temporal perception, task\nunderstanding, and embodied reasoning. Following this, we propose a new\nbenchmark, named MFE-ETP, characterized its complex and variable task\nscenarios, typical yet diverse task types, task instances of varying\ndifficulties, and rich test case types ranging from multiple embodied question\nanswering to embodied task reasoning. Finally, we offer a simple and\neasy-to-use automatic evaluation platform that enables the automated testing of\nmultiple MFMs on the proposed benchmark. Using the benchmark and evaluation\nplatform, we evaluated several state-of-the-art MFMs and found that they\nsignificantly lag behind human-level performance. The MFE-ETP is a\nhigh-quality, large-scale, and challenging benchmark relevant to real-world\ntasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05047v3",
    "published_date": "2024-07-06 11:07:18 UTC",
    "updated_date": "2024-10-07 14:05:05 UTC"
  },
  {
    "arxiv_id": "2407.05015v1",
    "title": "How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions",
    "authors": [
      "Bojana Bašaragin",
      "Adela Ljajić",
      "Darija Medvecki",
      "Lorenzo Cassano",
      "Miloš Košprdić",
      "Nikola Milošević"
    ],
    "abstract": "Large language models (LLMs) have recently become the leading source of\nanswers for users' questions online. Despite their ability to offer eloquent\nanswers, their accuracy and reliability can pose a significant challenge. This\nis especially true for sensitive domains such as biomedicine, where there is a\nhigher need for factually correct answers. This paper introduces a biomedical\nretrieval-augmented generation (RAG) system designed to enhance the reliability\nof generated responses. The system is based on a fine-tuned LLM for the\nreferenced question-answering, where retrieved relevant abstracts from PubMed\nare passed to LLM's context as input through a prompt. Its output is an answer\nbased on PubMed abstracts, where each statement is referenced accordingly,\nallowing the users to verify the answer. Our retrieval system achieves an\nabsolute improvement of 23% compared to the PubMed search engine. Based on the\nmanual evaluation on a small sample, our fine-tuned LLM component achieves\ncomparable results to GPT-4 Turbo in referencing relevant abstracts. We make\nthe dataset used to fine-tune the models and the fine-tuned models based on\nMistral-7B-instruct-v0.1 and v0.2 publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at BioNLP Workshop 2024, colocated with ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.05015v1",
    "published_date": "2024-07-06 09:10:05 UTC",
    "updated_date": "2024-07-06 09:10:05 UTC"
  },
  {
    "arxiv_id": "2407.04997v1",
    "title": "Achieving Tool Calling Functionality in LLMs Using Only Prompt Engineering Without Fine-Tuning",
    "authors": [
      "Shengtao He"
    ],
    "abstract": "Currently, the vast majority of locally deployed open-source large language\nmodels (LLMs) and some commercial model interfaces do not support stable tool\ncalling functionality. The existing solution involves fine-tuning LLMs, which\nresults in significant time and computational resource consumption. This paper\nproposes a method that enables LLMs to achieve stable tool calling capabilities\nusing only prompt engineering and some ingenious code design. We conducted\nexperiments on multiple LLMs that lack tool calling capabilities across various\ntool calling tasks, achieving a success rate of 100%.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC",
      "I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages, 2 figures,review comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2407.04997v1",
    "published_date": "2024-07-06 08:29:12 UTC",
    "updated_date": "2024-07-06 08:29:12 UTC"
  },
  {
    "arxiv_id": "2407.11040v1",
    "title": "High-Quality and Full Bandwidth Seismic Signal Synthesis using Operational GANs",
    "authors": [
      "Ozer Can Devecioglu",
      "Serkan Kiranyaz",
      "Zafer Yilmaz",
      "Onur Avci",
      "Moncef Gabbouj",
      "Ertugrul Taciroglu"
    ],
    "abstract": "Vibration sensors are essential in acquiring seismic activity for an accurate\nearthquake assessment. The state-of-the-art sensors can provide the best signal\nquality and the highest bandwidth; however, their high cost usually hinders a\nwide range of applicability and coverage, which is otherwise possible with\ntheir basic and cheap counterparts. But, their poor quality and low bandwidth\ncan significantly degrade the signal fidelity and result in an imprecise\nanalysis. To address these drawbacks, in this study, we propose a novel,\nhigh-quality, and full bandwidth seismic signal synthesis by transforming the\nsignal acquired from an inferior sensor. We employ 1D Operational Generative\nAdversarial Networks (Op-GANs) with novel loss functions to achieve this.\nTherefore, the study's key contributions include releasing a new dataset,\naddressing operational constraints in seismic monitoring, and pioneering a\ndeep-learning transformation technique to create the first virtual seismic\nsensor. The proposed method is extensively evaluated over the Simulated Ground\nMotion (SimGM) benchmark dataset, and the results demonstrated that the\nproposed approach significantly improves the quality and bandwidth of seismic\nsignals acquired from a variety of sensors, including a cheap seismic sensor,\nthe CSN-Phidgets, and the integrated accelerometers of an Android, and iOS\nphone, to the same level as the state-of-the-art sensor (e.g.,\nKinemetrics-Episensor). The SimGM dataset, our results, and the optimized\nPyTorch implementation of the proposed approach are publicly shared.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11040v1",
    "published_date": "2024-07-06 08:07:23 UTC",
    "updated_date": "2024-07-06 08:07:23 UTC"
  },
  {
    "arxiv_id": "2407.04992v2",
    "title": "Scalable Variational Causal Discovery Unconstrained by Acyclicity",
    "authors": [
      "Nu Hoang",
      "Bao Duong",
      "Thin Nguyen"
    ],
    "abstract": "Bayesian causal discovery offers the power to quantify epistemic\nuncertainties among a broad range of structurally diverse causal theories\npotentially explaining the data, represented in forms of directed acyclic\ngraphs (DAGs). However, existing methods struggle with efficient DAG sampling\ndue to the complex acyclicity constraint. In this study, we propose a scalable\nBayesian approach to effectively learn the posterior distribution over causal\ngraphs given observational data thanks to the ability to generate DAGs without\nexplicitly enforcing acyclicity. Specifically, we introduce a novel\ndifferentiable DAG sampling method that can generate a valid acyclic causal\ngraph by mapping an unconstrained distribution of implicit topological orders\nto a distribution over DAGs. Given this efficient DAG sampling scheme, we are\nable to model the posterior distribution over causal graphs using a simple\nvariational distribution over a continuous domain, which can be learned via the\nvariational inference framework. Extensive empirical experiments on both\nsimulated and real datasets demonstrate the superior performance of the\nproposed model compared to several state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04992v2",
    "published_date": "2024-07-06 07:56:23 UTC",
    "updated_date": "2024-08-29 00:40:05 UTC"
  },
  {
    "arxiv_id": "2407.04990v1",
    "title": "Conditional Semi-Supervised Data Augmentation for Spam Message Detection with Low Resource Data",
    "authors": [
      "Ulin Nuha",
      "Chih-Hsueh Lin"
    ],
    "abstract": "Several machine learning schemes have attempted to perform the detection of\nspam messages. However, those schemes mostly require a huge amount of labeled\ndata. The existing techniques addressing the lack of data availability have\nissues with effectiveness and robustness. Therefore, this paper proposes a\nconditional semi-supervised data augmentation (CSSDA) for a spam detection\nmodel lacking the availability of data. The main architecture of CSSDA\ncomprises feature extraction and enhanced generative network. Here, we exploit\nunlabeled data for data augmentation to extend training data. The enhanced\ngenerative in our proposed scheme produces latent variables as fake samples\nfrom unlabeled data through a conditional scheme. Latent variables can come\nfrom labeled and unlabeled data as the input for the final classifier in our\nspam detection model. The experimental results indicate that our proposed CSSDA\nachieves excellent results compared to several related methods both exploiting\nunlabeled data and not. In the experiment stage with various amounts of\nunlabeled data, CSSDA is the only robust model that obtains a balanced accuracy\nof about 85% when the availability of labeled data is large. We also conduct\nseveral ablation studies to investigate our proposed scheme in detail. The\nresult also shows that several ablation studies strengthen our proposed\ninnovations. These experiments indicate that unlabeled data has a significant\ncontribution to data augmentation using the conditional semi-supervised scheme\nfor spam detection.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04990v1",
    "published_date": "2024-07-06 07:51:24 UTC",
    "updated_date": "2024-07-06 07:51:24 UTC"
  },
  {
    "arxiv_id": "2407.04986v1",
    "title": "Calorie Burn Estimation in Community Parks Through DLICP: A Mathematical Modelling Approach",
    "authors": [
      "Abhishek Sebastian",
      "Annis Fathima A",
      "Pragna R",
      "Madhan Kumar S",
      "Jesher Joshua M"
    ],
    "abstract": "Community parks play a crucial role in promoting physical activity and\noverall well-being. This study introduces DLICP (Deep Learning Integrated\nCommunity Parks), an innovative approach that combines deep learning techniques\nspecifically, face recognition technology with a novel walking activity\nmeasurement algorithm to enhance user experience in community parks. The DLICP\nutilizes a camera with face recognition software to accurately identify and\ntrack park users. Simultaneously, a walking activity measurement algorithm\ncalculates parameters such as the average pace and calories burned, tailored to\nindividual attributes. Extensive evaluations confirm the precision of DLICP,\nwith a Mean Absolute Error (MAE) of 5.64 calories and a Mean Percentage Error\n(MPE) of 1.96%, benchmarked against widely available fitness measurement\ndevices, such as the Apple Watch Series 6. This study contributes significantly\nto the development of intelligent smart park systems, enabling real-time\nupdates on burned calories and personalized fitness tracking.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted and to be presented at Intellisys 2024 , Also Part of the\n  Indian Patent: 202441050325",
    "pdf_url": "http://arxiv.org/pdf/2407.04986v1",
    "published_date": "2024-07-06 07:45:05 UTC",
    "updated_date": "2024-07-06 07:45:05 UTC"
  },
  {
    "arxiv_id": "2407.04980v2",
    "title": "Enabling Causal Discovery in Post-Nonlinear Models with Normalizing Flows",
    "authors": [
      "Nu Hoang",
      "Bao Duong",
      "Thin Nguyen"
    ],
    "abstract": "Post-nonlinear (PNL) causal models stand out as a versatile and adaptable\nframework for modeling intricate causal relationships. However, accurately\ncapturing the invertibility constraint required in PNL models remains\nchallenging in existing studies. To address this problem, we introduce CAF-PoNo\n(Causal discovery via Normalizing Flows for Post-Nonlinear models), harnessing\nthe power of the normalizing flows architecture to enforce the crucial\ninvertibility constraint in PNL models. Through normalizing flows, our method\nprecisely reconstructs the hidden noise, which plays a vital role in\ncause-effect identification through statistical independence testing.\nFurthermore, the proposed approach exhibits remarkable extensibility, as it can\nbe seamlessly expanded to facilitate multivariate causal discovery via causal\norder identification, empowering us to efficiently unravel complex causal\nrelationships. Extensive experimental evaluations on both simulated and real\ndatasets consistently demonstrate that the proposed method outperforms several\nstate-of-the-art approaches in both bivariate and multivariate causal discovery\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "Acepted at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04980v2",
    "published_date": "2024-07-06 07:19:21 UTC",
    "updated_date": "2024-08-29 00:34:59 UTC"
  },
  {
    "arxiv_id": "2407.04973v1",
    "title": "LogicVista: Multimodal LLM Logical Reasoning Benchmark in Visual Contexts",
    "authors": [
      "Yijia Xiao",
      "Edward Sun",
      "Tianyu Liu",
      "Wei Wang"
    ],
    "abstract": "We propose LogicVista, an evaluation benchmark that assesses the integrated\nlogical reasoning capabilities of multimodal large language models (MLLMs) in\nVisual contexts. Recent advancements in MLLMs have demonstrated various\nfascinating abilities, from crafting poetry based on an image to performing\nmathematical reasoning. However, there is still a lack of systematic evaluation\nof MLLMs' proficiency in logical reasoning tasks, which are essential for\nactivities like navigation and puzzle-solving. Thus we evaluate general logical\ncognition abilities across 5 logical reasoning tasks encompassing 9 different\ncapabilities, using a sample of 448 multiple-choice questions. Each question is\nannotated with the correct answer and the human-written reasoning behind the\nselection, enabling both open-ended and multiple-choice evaluation. A total of\n8 MLLMs are comprehensively evaluated using LogicVista. Code and Data Available\nat https://github.com/Yijia-Xiao/LogicVista.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "LogicVista benchmarks the logical reasoning of multimodal large\n  language models in visual tasks",
    "pdf_url": "http://arxiv.org/pdf/2407.04973v1",
    "published_date": "2024-07-06 06:48:16 UTC",
    "updated_date": "2024-07-06 06:48:16 UTC"
  },
  {
    "arxiv_id": "2407.04964v1",
    "title": "ZOBNN: Zero-Overhead Dependable Design of Binary Neural Networks with Deliberately Quantized Parameters",
    "authors": [
      "Behnam Ghavami",
      "Mohammad Shahidzadeh",
      "Lesley Shannon",
      "Steve Wilton"
    ],
    "abstract": "Low-precision weights and activations in deep neural networks (DNNs)\noutperform their full-precision counterparts in terms of hardware efficiency.\nWhen implemented with low-precision operations, specifically in the extreme\ncase where network parameters are binarized (i.e. BNNs), the two most\nfrequently mentioned benefits of quantization are reduced memory consumption\nand a faster inference process. In this paper, we introduce a third advantage\nof very low-precision neural networks: improved fault-tolerance attribute. We\ninvestigate the impact of memory faults on state-of-the-art binary neural\nnetworks (BNNs) through comprehensive analysis. Despite the inclusion of\nfloating-point parameters in BNN architectures to improve accuracy, our\nfindings reveal that BNNs are highly sensitive to deviations in these\nparameters caused by memory faults. In light of this crucial finding, we\npropose a technique to improve BNN dependability by restricting the range of\nfloat parameters through a novel deliberately uniform quantization. The\nintroduced quantization technique results in a reduction in the proportion of\nfloating-point parameters utilized in the BNN, without incurring any additional\ncomputational overheads during the inference stage. The extensive experimental\nfault simulation on the proposed BNN architecture (i.e. ZOBNN) reveal a\nremarkable 5X enhancement in robustness compared to conventional floating-point\nDNN. Notably, this improvement is achieved without incurring any computational\noverhead. Crucially, this enhancement comes without computational overhead.\n\\ToolName~excels in critical edge applications characterized by limited\ncomputational resources, prioritizing both dependability and real-time\nperformance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04964v1",
    "published_date": "2024-07-06 05:31:11 UTC",
    "updated_date": "2024-07-06 05:31:11 UTC"
  },
  {
    "arxiv_id": "2407.12848v2",
    "title": "Applicability of Large Language Models and Generative Models for Legal Case Judgement Summarization",
    "authors": [
      "Aniket Deroy",
      "Kripabandhu Ghosh",
      "Saptarshi Ghosh"
    ],
    "abstract": "Automatic summarization of legal case judgements, which are known to be long\nand complex, has traditionally been tried via extractive summarization models.\nIn recent years, generative models including abstractive summarization models\nand Large language models (LLMs) have gained huge popularity. In this paper, we\nexplore the applicability of such models for legal case judgement\nsummarization. We applied various domain specific abstractive summarization\nmodels and general domain LLMs as well as extractive summarization models over\ntwo sets of legal case judgements from the United Kingdom (UK) Supreme Court\nand the Indian (IN) Supreme Court and evaluated the quality of the generated\nsummaries. We also perform experiments on a third dataset of legal documents of\na different type, Government reports from the United States (US). Results show\nthat abstractive summarization models and LLMs generally perform better than\nthe extractive methods as per traditional metrics for evaluating summary\nquality. However, detailed investigation shows the presence of inconsistencies\nand hallucinations in the outputs of the generative models, and we explore ways\nto reduce the hallucinations and inconsistencies in the summaries. Overall, the\ninvestigation suggests that further improvements are needed to enhance the\nreliability of abstractive models and LLMs for legal case judgement\nsummarization. At present, a human-in-the-loop technique is more suitable for\nperforming manual checks to identify inconsistencies in the generated\nsummaries.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Artificial Intelligence and Law, Springer, 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12848v2",
    "published_date": "2024-07-06 04:49:40 UTC",
    "updated_date": "2024-07-20 05:50:41 UTC"
  },
  {
    "arxiv_id": "2407.04925v1",
    "title": "RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations",
    "authors": [
      "Jiarui Rao",
      "Jionghao Lin"
    ],
    "abstract": "Massive Open Online Courses (MOOCs) have significantly enhanced educational\naccessibility by offering a wide variety of courses and breaking down\ntraditional barriers related to geography, finance, and time. However, students\noften face difficulties navigating the vast selection of courses, especially\nwhen exploring new fields of study. Driven by this challenge, researchers have\nbeen exploring course recommender systems to offer tailored guidance that\naligns with individual learning preferences and career aspirations. These\nsystems face particular challenges in effectively addressing the ``cold start''\nproblem for new users. Recent advancements in recommender systems suggest\nintegrating large language models (LLMs) into the recommendation process to\nenhance personalized recommendations and address the ``cold start'' problem.\nMotivated by these advancements, our study introduces RAMO (Retrieval-Augmented\nGeneration for MOOCs), a system specifically designed to overcome the ``cold\nstart'' challenges of traditional course recommender systems. The RAMO system\nleverages the capabilities of LLMs, along with Retrieval-Augmented Generation\n(RAG)-facilitated contextual understanding, to provide course recommendations\nthrough a conversational interface, aiming to enhance the e-learning\nexperience.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "7 pages, this paper underwent a rigorous review process and was\n  officially accepted on May 31, 2024, for presentation at the Educational Data\n  Mining 2024 Workshop: Leveraging Large Language Models for Next Generation\n  Educational Technologies",
    "pdf_url": "http://arxiv.org/pdf/2407.04925v1",
    "published_date": "2024-07-06 02:22:25 UTC",
    "updated_date": "2024-07-06 02:22:25 UTC"
  },
  {
    "arxiv_id": "2407.11039v3",
    "title": "Balancing Immediate Revenue and Future Off-Policy Evaluation in Coupon Allocation",
    "authors": [
      "Naoki Nishimura",
      "Ken Kobayashi",
      "Kazuhide Nakata"
    ],
    "abstract": "Coupon allocation drives customer purchases and boosts revenue. However, it\npresents a fundamental trade-off between exploiting the current optimal policy\nto maximize immediate revenue and exploring alternative policies to collect\ndata for future policy improvement via off-policy evaluation (OPE). To balance\nthis trade-off, we propose a novel approach that combines a model-based revenue\nmaximization policy and a randomized exploration policy for data collection.\nOur framework enables flexible adjustment of the mixture ratio between these\ntwo policies to optimize the balance between short-term revenue and future\npolicy improvement. We formulate the problem of determining the optimal mixture\nratio as multi-objective optimization, enabling quantitative evaluation of this\ntrade-off. We empirically verified the effectiveness of the proposed mixed\npolicy using synthetic data. Our main contributions are: (1) Demonstrating a\nmixed policy combining deterministic and probabilistic policies, flexibly\nadjusting the data collection vs. revenue trade-off. (2) Formulating the\noptimal mixture ratio problem as multi-objective optimization, enabling\nquantitative evaluation of this trade-off.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11039v3",
    "published_date": "2024-07-06 02:04:17 UTC",
    "updated_date": "2024-09-08 23:10:59 UTC"
  },
  {
    "arxiv_id": "2407.04921v1",
    "title": "Aortic root landmark localization with optimal transport loss for heatmap regression",
    "authors": [
      "Tsuyoshi Ishizone",
      "Masaki Miyasaka",
      "Sae Ochi",
      "Norio Tada",
      "Kazuyuki Nakamura"
    ],
    "abstract": "Anatomical landmark localization is gaining attention to ease the burden on\nphysicians. Focusing on aortic root landmark localization, the three hinge\npoints of the aortic valve can reduce the burden by automatically determining\nthe valve size required for transcatheter aortic valve implantation surgery.\nExisting methods for landmark prediction of the aortic root mainly use\ntime-consuming two-step estimation methods. We propose a highly accurate\none-step landmark localization method from even coarse images. The proposed\nmethod uses an optimal transport loss to break the trade-off between prediction\nprecision and learning stability in conventional heatmap regression methods. We\napply the proposed method to the 3D CT image dataset collected at Sendai Kousei\nHospital and show that it significantly improves the estimation error over\nexisting methods and other loss functions. Our code is available on GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04921v1",
    "published_date": "2024-07-06 02:01:48 UTC",
    "updated_date": "2024-07-06 02:01:48 UTC"
  },
  {
    "arxiv_id": "2407.11038v2",
    "title": "Fuzzy Recurrent Stochastic Configuration Networks for Industrial Data Analytics",
    "authors": [
      "Dianhui Wang",
      "Gang Dang"
    ],
    "abstract": "This paper presents a novel neuro-fuzzy model, termed fuzzy recurrent\nstochastic configuration networks (F-RSCNs), for industrial data analytics.\nUnlike the original recurrent stochastic configuration network (RSCN), the\nproposed F-RSCN is constructed by multiple sub-reservoirs, and each\nsub-reservoir is associated with a Takagi-Sugeno-Kang (TSK) fuzzy rule. Through\nthis hybrid framework, first, the interpretability of the model is enhanced by\nincorporating fuzzy reasoning to embed the prior knowledge into the network.\nThen, the parameters of the neuro-fuzzy model are determined by the recurrent\nstochastic configuration (RSC) algorithm. This scheme not only ensures the\nuniversal approximation property and fast learning speed of the built model but\nalso overcomes uncertain problems, such as unknown dynamic orders, arbitrary\nstructure determination, and the sensitivity of learning parameters in\nmodelling nonlinear dynamics. Finally, an online update of the output weights\nis performed using the projection algorithm, and the convergence analysis of\nthe learning parameters is given. By integrating TSK fuzzy inference systems\ninto RSCNs, F-RSCNs have strong fuzzy inference capability and can achieve\nsound performance for both learning and generalization. Comprehensive\nexperiments show that the proposed F-RSCNs outperform other classical\nneuro-fuzzy and non-fuzzy models, demonstrating great potential for modelling\ncomplex industrial systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11038v2",
    "published_date": "2024-07-06 01:40:31 UTC",
    "updated_date": "2024-08-13 00:55:09 UTC"
  },
  {
    "arxiv_id": "2407.04910v1",
    "title": "NADI 2024: The Fifth Nuanced Arabic Dialect Identification Shared Task",
    "authors": [
      "Muhammad Abdul-Mageed",
      "Amr Keleg",
      "AbdelRahim Elmadany",
      "Chiyu Zhang",
      "Injy Hamed",
      "Walid Magdy",
      "Houda Bouamor",
      "Nizar Habash"
    ],
    "abstract": "We describe the findings of the fifth Nuanced Arabic Dialect Identification\nShared Task (NADI 2024). NADI's objective is to help advance SoTA Arabic NLP by\nproviding guidance, datasets, modeling opportunities, and standardized\nevaluation conditions that allow researchers to collaboratively compete on\npre-specified tasks. NADI 2024 targeted both dialect identification cast as a\nmulti-label task (Subtask~1), identification of the Arabic level of dialectness\n(Subtask~2), and dialect-to-MSA machine translation (Subtask~3). A total of 51\nunique teams registered for the shared task, of whom 12 teams have participated\n(with 76 valid submissions during the test phase). Among these, three teams\nparticipated in Subtask~1, three in Subtask~2, and eight in Subtask~3. The\nwinning teams achieved 50.57 F\\textsubscript{1} on Subtask~1, 0.1403 RMSE for\nSubtask~2, and 20.44 BLEU in Subtask~3, respectively. Results show that Arabic\ndialect processing tasks such as dialect identification and machine translation\nremain challenging. We describe the methods employed by the participating teams\nand briefly offer an outlook for NADI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by The Second Arabic Natural Language Processing Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.04910v1",
    "published_date": "2024-07-06 01:18:58 UTC",
    "updated_date": "2024-07-06 01:18:58 UTC"
  },
  {
    "arxiv_id": "2407.04903v3",
    "title": "MMSci: A Dataset for Graduate-Level Multi-Discipline Multimodal Scientific Understanding",
    "authors": [
      "Zekun Li",
      "Xianjun Yang",
      "Kyuri Choi",
      "Wanrong Zhu",
      "Ryan Hsieh",
      "HyeonJung Kim",
      "Jin Hyuk Lim",
      "Sungyoung Ji",
      "Byungju Lee",
      "Xifeng Yan",
      "Linda Ruth Petzold",
      "Stephen D. Wilson",
      "Woosang Lim",
      "William Yang Wang"
    ],
    "abstract": "Scientific figure interpretation is a crucial capability for AI-driven\nscientific assistants built on advanced Large Vision Language Models. However,\ncurrent datasets and benchmarks primarily focus on simple charts or other\nrelatively straightforward figures from limited science domains. To address\nthis gap, we present a comprehensive dataset compiled from peer-reviewed Nature\nCommunications articles covering 72 scientific fields, encompassing complex\nvisualizations such as schematic diagrams, microscopic images, and experimental\ndata which require graduate-level expertise to interpret. We evaluated 19\nproprietary and open-source models on two benchmark tasks, figure captioning\nand multiple-choice, and conducted human expert annotation. Our analysis\nrevealed significant task challenges and performance gaps among models. Beyond\nserving as a benchmark, this dataset serves as a valuable resource for\nlarge-scale training. Fine-tuning Qwen2-VL-7B with our task-specific data\nachieved better performance than GPT-4o and even human experts in\nmultiple-choice evaluations. Furthermore, continuous pre-training on our\ninterleaved article and figure data substantially enhanced the model's\ndownstream task performance in materials science. We have released our dataset\nto support further research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and data are available at https://github.com/Leezekun/MMSci",
    "pdf_url": "http://arxiv.org/pdf/2407.04903v3",
    "published_date": "2024-07-06 00:40:53 UTC",
    "updated_date": "2025-02-20 05:57:34 UTC"
  },
  {
    "arxiv_id": "2407.04899v1",
    "title": "Algorithmic Language Models with Neurally Compiled Libraries",
    "authors": [
      "Lucas Saldyt",
      "Subbarao Kambhampati"
    ],
    "abstract": "Important tasks such as reasoning and planning are fundamentally algorithmic,\nmeaning that solving them robustly requires acquiring true reasoning or\nplanning algorithms, rather than shortcuts. Large Language Models lack true\nalgorithmic ability primarily because of the limitations of neural network\noptimization algorithms, their optimization data and optimization objective,\nbut also due to architectural inexpressivity. To solve this, our paper proposes\naugmenting LLMs with a library of fundamental operations and sophisticated\ndifferentiable programs, so that common algorithms do not need to be learned\nfrom scratch. We add memory, registers, basic operations, and adaptive\nrecurrence to a transformer architecture built on LLaMA3. Then, we define a\nmethod for directly compiling algorithms into a differentiable starting\nlibrary, which is used natively and propagates gradients for optimization. In\nthis preliminary study, we explore the feasability of augmenting LLaMA3 with a\ndifferentiable computer, for instance by fine-tuning small transformers on\nsimple algorithmic tasks with variable computational depth.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04899v1",
    "published_date": "2024-07-06 00:27:05 UTC",
    "updated_date": "2024-07-06 00:27:05 UTC"
  }
]