{
  "date": "2025-05-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-04 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 66 篇论文，主要聚焦 AI 代理、多模态学习、医疗应用和强化学习等领域，其中 Manus AI 的自主数字代理框架和 LLM 在多模态任务中的优化应用最为令人印象深刻，同时涉及一些知名研究者如 Google 和 OpenAI 相关工作的延续。\n\n### 重点论文讨论\n我挑选了最具话题度和影响力的论文进行详细讨论，将相关主题归类，先聊 AI 和 LLM 领域的创新，再谈医疗应用，最后快速概述其他亮点。其他较常规或小众论文（如纯优化算法或特定领域调查）将简要掠过，以控制篇幅。\n\n#### AI 和 LLM 相关（优先讨论，热点领域）\n- **Manus AI: From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent**  \n  这篇论文介绍了 Monica.im 开发的 Manus AI 框架，将 LLM 的推理能力与实际任务执行结合，实现了从意图到行动的端到端代理。核心贡献是构建了一个通用 AI 代理，支持医疗、金融等领域应用，发现其在人类-AI 协作中表现出色，是 AI 自主性的一次重大进展。\n\n- **GraphPrompter: Multi-stage Adaptive Prompt Optimization for Graph In-Context Learning**  \n  作者 Rui Lv 等提出 GraphPrompter 框架，通过多阶段优化提升 LLM 在图结构数据的上下文学习能力。论文的关键发现是，该方法在各种图任务中平均提升 8% 性能，并通过 Hindsight Experience Replay 技术处理稀疏奖励问题，适用于动态图数据场景。\n\n- **Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data**  \n  这篇由 Zhong Guan 等撰写的论文分析了 LLM 在图数据处理中的注意力机制，揭示了 LLM 无法有效捕捉图拓扑的局限。贡献包括实验证明中间状态注意力窗口能改善性能，并提供了代码开源，强调了 LLM 在复杂图任务中的可解释性挑战。\n\n- **DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization**  \n  论文提出 DualReal 框架，用于文本到视频生成中的身份和运动融合优化。核心发现是通过自适应训练，实现了无损融合，提升视频生成质量，CLIP-I 和 DINO-I 指标平均提高 21.7% 和 31.8%，对多模态 AI 视频应用有重要启发。\n\n- **Restoring Calibration for Aligned Large Language Models: A Calibration-Aware Fine-Tuning Approach**  \n  作者 Jiancong Xiao 等开发了校准感知微调方法，解决 LLM 偏好对齐后 calibration 问题。贡献是提出 EM-算法正则化，显著降低 Expected Calibration Error，同时保持模型性能，为 LLM 的可靠部署提供了实用策略。\n\n其他 LLM 相关论文如 \"Decoding Open-Ended Information Seeking Goals from Eye Movements\" 等，展示了 LLM 在眼动数据上的解码能力，但细节较 niche，故快速掠过。\n\n#### 医疗和应用 AI（高影响力领域，关注实际应用）\n- **Ethical AI in the Healthcare Sector: Investigating Key Drivers of Adoption through the Multi-Dimensional Ethical AI Adoption Model (MEAAM)**  \n  这篇论文引入 MEAAM 框架，分析 AI 在医疗中的伦理因素。核心贡献是通过 PLS-SEM 量化了公平 AI 和责任 AI 等维度的影响，发现规范性担忧驱动操作性采用，为医疗 AI 政策制定提供了实证指导。\n\n- **Generative AI in clinical practice: novel qualitative evidence of risk and responsible use of Google's NotebookLM**  \n  作者 Max Reuter 等评估了 Google NotebookLM 在临床中的风险。发现尽管其能生成教育性音频，但存在临床风险，如数据偏差和伦理问题，强调了负责任使用的必要性。\n\n- **Retrieval-augmented in-context learning for multimodal large language models in disease classification**  \n  论文提出 RAICL 框架，用于多模态 LLM 在疾病分类中的检索增强学习。关键发现是通过动态演示检索，提升分类准确率平均 8%，在 TCGA 和 IU Chest X-ray 数据集上表现突出，展示了 LLM 在医疗诊断的潜力。\n\n其他医疗论文如 \"Uncertainty Quantification for Machine Learning in Healthcare\" 等，讨论了不确定性量化，但作为回顾性工作，影响力较小，故简要提及。\n\n#### 其他亮点（快速概述，相关主题）\n- **SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment**  \n  这篇论文开发了 LanBLoc-BMM 算法，用于 GPS 失效环境下的路径导航。贡献是通过地标定位和风险感知 RRT* 算法，提高导航准确性和安全性，在战场场景中表现优异。\n\n- **TxP: Reciprocal Generation of Ground Pressure Dynamics and Activity Descriptions for Improving Human Activity Recognition**  \n  作者提出 TxP 框架，结合生成模型提升压力传感器的人类活动识别。发现通过文本-压力互转，提高宏 F1 分数 12.4%，为多模态 HAR 提供了新基准。\n\n- **YODA: You Only Denoise once - or Average for medical image translation**  \n  论文引入 YODA 框架，用于医学图像翻译。核心发现是通过回归范式优化，超越 GAN 和扩散模型，在多对比 MRI 上实现高效噪声抑制，适用于临床下游任务。\n\n剩余论文如纯理论优化（如 \"Graph Neural Networks\" 变体）或特定领域（如 \"DNAZEN\" 的基因序列建模）虽有贡献，但主题较窄或无重大突破，故不详细展开，仅注其存在。\n\n总之，今天的 arXiv 更新突显了 AI 代理和多模态学习的创新潜力，值得 AI 研究者关注。明天的快报将持续追踪最新动态！",
  "papers": [
    {
      "arxiv_id": "2505.04639v1",
      "title": "Language translation, and change of accent for speech-to-speech task using diffusion model",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Mishra",
        "Ritesh Sur Chowdhury",
        "Vartul Bahuguna",
        "Isha Pandey",
        "Ganesh Ramakrishnan"
      ],
      "abstract": "Speech-to-speech translation (S2ST) aims to convert spoken input in one\nlanguage to spoken output in another, typically focusing on either language\ntranslation or accent adaptation. However, effective cross-cultural\ncommunication requires handling both aspects simultaneously - translating\ncontent while adapting the speaker's accent to match the target language\ncontext. In this work, we propose a unified approach for simultaneous speech\ntranslation and change of accent, a task that remains underexplored in current\nliterature. Our method reformulates the problem as a conditional generation\ntask, where target speech is generated based on phonemes and guided by target\nspeech features. Leveraging the power of diffusion models, known for\nhigh-fidelity generative capabilities, we adapt text-to-image diffusion\nstrategies by conditioning on source speech transcriptions and generating Mel\nspectrograms representing the target speech with desired linguistic and\naccentual attributes. This integrated framework enables joint optimization of\ntranslation and accent adaptation, offering a more parameter-efficient and\neffective model compared to traditional pipelines.",
      "tldr_zh": "该研究提出了一种统一方法，用于语音到语音翻译 (S2ST) 任务，同时实现语言翻译和口音适应，以提升跨文化沟通效果。该方法将问题重构为条件生成任务，利用 diffusion models 生成目标语音的 Mel spectrograms，通过源语音转录和目标特征指导进行优化。相比传统流水线，该框架实现了翻译和口音适应的联合优化，提供更参数高效的模型，支持高保真语音生成。实验结果表明，该方法在处理未探索的联合任务上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04639v1",
      "published_date": "2025-05-04 23:23:46 UTC",
      "updated_date": "2025-05-04 23:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:25:08.660097"
    },
    {
      "arxiv_id": "2505.02288v1",
      "title": "Universal Approximation Theorem of Deep Q-Networks",
      "title_zh": "深度Q网络的通用逼近定理",
      "authors": [
        "Qian Qi"
      ],
      "abstract": "We establish a continuous-time framework for analyzing Deep Q-Networks (DQNs)\nvia stochastic control and Forward-Backward Stochastic Differential Equations\n(FBSDEs). Considering a continuous-time Markov Decision Process (MDP) driven by\na square-integrable martingale, we analyze DQN approximation properties. We\nshow that DQNs can approximate the optimal Q-function on compact sets with\narbitrary accuracy and high probability, leveraging residual network\napproximation theorems and large deviation bounds for the state-action process.\nWe then analyze the convergence of a general Q-learning algorithm for training\nDQNs in this setting, adapting stochastic approximation theorems. Our analysis\nemphasizes the interplay between DQN layer count, time discretization, and the\nrole of viscosity solutions (primarily for the value function $V^*$) in\naddressing potential non-smoothness of the optimal Q-function. This work\nbridges deep reinforcement learning and stochastic control, offering insights\ninto DQNs in continuous-time settings, relevant for applications with physical\nsystems or high-frequency data.",
      "tldr_zh": "本文证明了 Deep Q-Networks (DQNs) 的通用逼近定理，通过建立一个基于随机控制和 Forward-Backward Stochastic Differential Equations (FBSDEs) 的连续时间 Markov Decision Process (MDP) 框架，展示了 DQNs 可以在紧致集上以任意精度和高概率逼近最优 Q 函数。研究利用残差网络逼近定理和大偏差界分析了 DQNs 的逼近性能，并探讨了训练 Q 学习算法的收敛性，强调了层数、时间离散化和 viscosity solutions 在处理 Q 函数非光滑性的作用。该工作桥接了深度强化学习与随机控制领域，为应用于物理系统或高频数据的连续时间场景提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02288v1",
      "published_date": "2025-05-04 22:57:33 UTC",
      "updated_date": "2025-05-04 22:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:25:22.369126"
    },
    {
      "arxiv_id": "2505.02281v1",
      "title": "Minimisation of Quasar-Convex Functions Using Random Zeroth-Order Oracles",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Ali Farzin",
        "Yuen-Man Pun",
        "Iman Shames"
      ],
      "abstract": "This study explores the performance of a random Gaussian smoothing\nzeroth-order (ZO) scheme for minimising quasar-convex (QC) and strongly\nquasar-convex (SQC) functions in both unconstrained and constrained settings.\nFor the unconstrained problem, we establish the ZO algorithm's convergence to a\nglobal minimum along with its complexity when applied to both QC and SQC\nfunctions. For the constrained problem, we introduce the new notion of\nproximal-quasar-convexity and prove analogous results to the unconstrained\ncase. Specifically, we show the complexity bounds and the convergence of the\nalgorithm to a neighbourhood of a global minimum whose size can be controlled\nunder a variance reduction scheme. Theoretical findings are illustrated through\ninvestigating the performance of the algorithm applied to a range of problems\nin machine learning and optimisation. Specifically, we observe scenarios where\nthe ZO method outperforms gradient descent. We provide a possible explanation\nfor this phenomenon.",
      "tldr_zh": "本研究探讨了使用随机高斯平滑的零阶（ZO）优化方案来最小化 quasar-convex (QC) 和 strongly quasar-convex (SQC) 函数，在无约束和有约束设置下进行分析。对于无约束问题，该算法被证明能收敛到全局最小值，并提供了复杂度分析；对于有约束问题，引入了 proximal-quasar-convexity 的新概念，展示了算法的复杂度边界和收敛到全局最小值邻域的能力。通过机器学习和优化问题的实验，研究发现 ZO 方法在某些场景下优于梯度下降，并给出了可能的解释。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02281v1",
      "published_date": "2025-05-04 22:43:57 UTC",
      "updated_date": "2025-05-04 22:43:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:25:33.893141"
    },
    {
      "arxiv_id": "2505.02279v1",
      "title": "A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)",
      "title_zh": "翻译失败",
      "authors": [
        "Abul Ehtesham",
        "Aditi Singh",
        "Gaurav Kumar Gupta",
        "Saket Kumar"
      ],
      "abstract": "Large language model (LLM)-powered autonomous agents demand robust,\nstandardized protocols to integrate tools, share contextual data, and\ncoordinate tasks across heterogeneous systems. Ad-hoc integrations are\ndifficult to scale, secure, and generalize across domains. This survey examines\nfour emerging agent communication protocols: Model Context Protocol (MCP),\nAgent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent\nNetwork Protocol (ANP), each addressing interoperability in distinct deployment\ncontexts. MCP provides a JSON-RPC client-server interface for secure tool\ninvocation and typed data exchange. ACP introduces REST-native messaging via\nmulti-part messages and asynchronous streaming to support multimodal agent\nresponses. A2A enables peer-to-peer task outsourcing through capability-based\nAgent Cards, facilitating enterprise-scale workflows. ANP supports open-network\nagent discovery and secure collaboration using decentralized identifiers (DIDs)\nand JSON-LD graphs. The protocols are compared across multiple dimensions,\nincluding interaction modes, discovery mechanisms, communication patterns, and\nsecurity models. Based on the comparative analysis, a phased adoption roadmap\nis proposed: beginning with MCP for tool access, followed by ACP for multimodal\nmessaging, A2A for collaborative task execution, and extending to ANP for\ndecentralized agent marketplaces. This work provides a comprehensive foundation\nfor designing secure, interoperable, and scalable ecosystems of LLM-powered\nagents.",
      "tldr_zh": "这篇论文调查了四个代理互操作性协议——Model Context Protocol (MCP)、Agent Communication Protocol (ACP)、Agent-to-Agent Protocol (A2A) 和 Agent Network Protocol (ANP)，旨在解决大型语言模型 (LLM) 驱动的自治代理在工具集成、数据共享和任务协调方面的挑战。MCP 通过 JSON-RPC 提供安全的工具调用和数据交换；ACP 支持多模态响应 via REST-native 消息和异步流；A2A 启用基于 Agent Cards 的点对点任务外包；ANP 利用去中心化标识 (DIDs) 和 JSON-LD 图实现代理发现和安全协作。论文比较了这些协议在交互模式、发现机制、通信模式和安全模型等维度上的差异，并提出分阶段采用路线图，从 MCP 的工具访问开始，到 ANP 的去中心化代理市场扩展，最终为构建安全、可互操作和可扩展的 LLM 代理生态系统提供基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02279v1",
      "published_date": "2025-05-04 22:18:27 UTC",
      "updated_date": "2025-05-04 22:18:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:25:44.591059"
    },
    {
      "arxiv_id": "2505.02274v1",
      "title": "On the Need for a Statistical Foundation in Scenario-Based Testing of Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Zhao",
        "Robab Aghazadeh-Chakherlou",
        "Chih-Hong Cheng",
        "Peter Popov",
        "Lorenzo Strigini"
      ],
      "abstract": "Scenario-based testing has emerged as a common method for autonomous vehicles\n(AVs) safety, offering a more efficient alternative to mile-based testing by\nfocusing on high-risk scenarios. However, fundamental questions persist\nregarding its stopping rules, residual risk estimation, debug effectiveness,\nand the impact of simulation fidelity on safety claims. This paper argues that\na rigorous statistical foundation is essential to address these challenges and\nenable rigorous safety assurance. By drawing parallels between AV testing and\ntraditional software testing methodologies, we identify shared research gaps\nand reusable solutions. We propose proof-of-concept models to quantify the\nprobability of failure per scenario (pfs) and evaluate testing effectiveness\nunder varying conditions. Our analysis reveals that neither scenario-based nor\nmile-based testing universally outperforms the other. Furthermore, we introduce\nRisk Estimation Fidelity (REF), a novel metric to certify the alignment of\nsynthetic and real-world testing outcomes, ensuring simulation-based safety\nclaims are statistically defensible.",
      "tldr_zh": "这篇论文强调了在自动驾驶车辆 (AVs) 的场景-based 测试中，建立严格的统计基础的必要性，以解决停止规则、剩余风险估计、调试有效性和模拟保真度等挑战。作者通过与传统软件测试方法的比较，识别了共同的研究空白，并提出了概念证明模型来量化每个场景的失败概率 (pfs)，并在不同条件下评估测试有效性。研究发现，场景-based 测试并不总是优于基于里程的测试，同时引入了新的 Risk Estimation Fidelity (REF) 指标，以确保合成测试结果与真实世界结果的一致性，从而使基于模拟的安全声明在统计上更可辩护。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.SE",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2505.02274v1",
      "published_date": "2025-05-04 22:06:23 UTC",
      "updated_date": "2025-05-04 22:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:25:58.130366"
    },
    {
      "arxiv_id": "2505.03837v1",
      "title": "Explainable Face Recognition via Improved Localization",
      "title_zh": "通过改进的定位实现可解释人脸识别",
      "authors": [
        "Rashik Shadman",
        "Daqing Hou",
        "Faraz Hussain",
        "M G Sarwar Murshed"
      ],
      "abstract": "Biometric authentication has become one of the most widely used tools in the\ncurrent technological era to authenticate users and to distinguish between\ngenuine users and imposters. Face is the most common form of biometric modality\nthat has proven effective. Deep learning-based face recognition systems are now\ncommonly used across different domains. However, these systems usually operate\nlike black-box models that do not provide necessary explanations or\njustifications for their decisions. This is a major disadvantage because users\ncannot trust such artificial intelligence-based biometric systems and may not\nfeel comfortable using them when clear explanations or justifications are not\nprovided. This paper addresses this problem by applying an efficient method for\nexplainable face recognition systems. We use a Class Activation Mapping\n(CAM)-based discriminative localization (very narrow/specific localization)\ntechnique called Scaled Directed Divergence (SDD) to visually explain the\nresults of deep learning-based face recognition systems. We perform fine\nlocalization of the face features relevant to the deep learning model for its\nprediction/decision. Our experiments show that the SDD Class Activation Map\n(CAM) highlights the relevant face features very specifically compared to the\ntraditional CAM and very accurately. The provided visual explanations with\nnarrow localization of relevant features can ensure much-needed transparency\nand trust for deep learning-based face recognition systems.",
      "tldr_zh": "该论文针对深度学习人脸识别系统作为黑箱模型的问题，提出了一种基于 Scaled Directed Divergence (SDD) 的改进方法，以提供视觉解释和决策依据。SDD 是一种 Class Activation Mapping (CAM) 的变体，能够实现更精确的面部特征定位，突出模型决策中相关特征。实验结果表明，SDD CAM 比传统 CAM 更准确地识别关键面部细节，从而提升了人脸识别系统的透明度与用户信任。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03837v1",
      "published_date": "2025-05-04 21:58:16 UTC",
      "updated_date": "2025-05-04 21:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:26:08.847406"
    },
    {
      "arxiv_id": "2505.02272v1",
      "title": "Robust Localization, Mapping, and Navigation for Quadruped Robots",
      "title_zh": "四足机器人的鲁棒定位、建图和导航",
      "authors": [
        "Dyuman Aditya",
        "Junning Huang",
        "Nico Bohlinger",
        "Piotr Kicki",
        "Krzysztof Walas",
        "Jan Peters",
        "Matteo Luperto",
        "Davide Tateo"
      ],
      "abstract": "Quadruped robots are currently a widespread platform for robotics research,\nthanks to powerful Reinforcement Learning controllers and the availability of\ncheap and robust commercial platforms. However, to broaden the adoption of the\ntechnology in the real world, we require robust navigation stacks relying only\non low-cost sensors such as depth cameras. This paper presents a first step\ntowards a robust localization, mapping, and navigation system for low-cost\nquadruped robots. In pursuit of this objective we combine contact-aided\nkinematic, visual-inertial odometry, and depth-stabilized vision, enhancing\nstability and accuracy of the system. Our results in simulation and two\ndifferent real-world quadruped platforms show that our system can generate an\naccurate 2D map of the environment, robustly localize itself, and navigate\nautonomously. Furthermore, we present in-depth ablation studies of the\nimportant components of the system and their impact on localization accuracy.\nVideos, code, and additional experiments can be found on the project website:\nhttps://sites.google.com/view/low-cost-quadruped-slam",
      "tldr_zh": "本文提出了一种针对低成本四足机器人的鲁棒定位、映射和导航系统，利用深度相机等传感器，结合接触辅助运动学(Contact-Aided Kinematic)、视觉-惯性里程计(Visual-Inertial Odometry)和深度稳定视觉，以提升系统的稳定性和准确性。该系统在模拟环境和两个真实四足机器人平台上进行测试，成功生成精确的2D环境地图，实现鲁棒定位和自主导航。研究还通过消融实验分析了关键组件对定位准确性的影响，为四足机器人实际应用提供了重要基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 Pages",
      "pdf_url": "http://arxiv.org/pdf/2505.02272v1",
      "published_date": "2025-05-04 21:58:11 UTC",
      "updated_date": "2025-05-04 21:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:26:21.594063"
    },
    {
      "arxiv_id": "2505.02271v1",
      "title": "Real-time Spatial Retrieval Augmented Generation for Urban Environments",
      "title_zh": "翻译失败",
      "authors": [
        "David Nazareno Campo",
        "Javier Conde",
        "Álvaro Alonso",
        "Gabriel Huecas",
        "Joaquín Salvachúa",
        "Pedro Reviriego"
      ],
      "abstract": "The proliferation of Generative Artificial Ingelligence (AI), especially\nLarge Language Models, presents transformative opportunities for urban\napplications through Urban Foundation Models. However, base models face\nlimitations, as they only contain the knowledge available at the time of\ntraining, and updating them is both time-consuming and costly. Retrieval\nAugmented Generation (RAG) has emerged in the literature as the preferred\napproach for injecting contextual information into Foundation Models. It\nprevails over techniques such as fine-tuning, which are less effective in\ndynamic, real-time scenarios like those found in urban environments. However,\ntraditional RAG architectures, based on semantic databases, knowledge graphs,\nstructured data, or AI-powered web searches, do not fully meet the demands of\nurban contexts. Urban environments are complex systems characterized by large\nvolumes of interconnected data, frequent updates, real-time processing\nrequirements, security needs, and strong links to the physical world. This work\nproposes a real-time spatial RAG architecture that defines the necessary\ncomponents for the effective integration of generative AI into cities,\nleveraging temporal and spatial filtering capabilities through linked data. The\nproposed architecture is implemented using FIWARE, an ecosystem of software\ncomponents to develop smart city solutions and digital twins. The design and\nimplementation are demonstrated through the use case of a tourism assistant in\nthe city of Madrid. The use case serves to validate the correct integration of\nFoundation Models through the proposed RAG architecture.",
      "tldr_zh": "该研究探讨了 Generative AI 和 Large Language Models 在城市应用中的潜力，但强调基础模型受限于训练时的知识，且更新成本高昂。论文提出一种实时空间 Retrieval Augmented Generation (RAG) 架构，通过 temporal 和 spatial filtering 以及 linked data 的整合，适应城市环境的复杂动态需求，并使用 FIWARE 生态系统进行实现。该架构在马德里旅游助理用例中得到验证，证明了其在注入上下文信息和实时处理方面的有效性，为智能城市解决方案提供了可靠框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02271v1",
      "published_date": "2025-05-04 21:57:58 UTC",
      "updated_date": "2025-05-04 21:57:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:26:32.646566"
    },
    {
      "arxiv_id": "2505.02266v1",
      "title": "Parameter-Efficient Transformer Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Ndubuaku",
        "Mouad Talhi"
      ],
      "abstract": "Embedding layers in transformer-based NLP models typically account for the\nlargest share of model parameters, scaling with vocabulary size but not\nyielding performance gains proportional to scale. We propose an alternative\napproach in which token embedding vectors are first generated\ndeterministically, directly from the token IDs using a Fourier expansion of\ntheir normalized values, followed by a lightweight multilayer perceptron (MLP)\nthat captures higher-order interactions. We train standard transformers and our\narchitecture on natural language inference tasks (SNLI and MNLI), and evaluate\nzero-shot performance on sentence textual similarity (STS-B). Our results\ndemonstrate that the proposed method achieves competitive performance using\nsignificantly fewer parameters, trains faster, and operates effectively without\nthe need for dropout. This proof-of-concept study highlights the potential for\nscalable, memory-efficient language models and motivates further large-scale\nexperimentation based on our findings.",
      "tldr_zh": "本研究针对 Transformer 模型中嵌入层参数过多且扩展收益不佳的问题，提出了一种参数高效方法：通过傅立叶展开从 token ID 直接生成嵌入向量，并使用轻量级 MLP 捕捉更高阶交互，从而减少参数数量。在 SNLI 和 MNLI 自然语言推理任务上训练后，该方法在 STS-B 句子文本相似性任务的零样本评估中表现出竞争性性能，使用更少参数、训练更快且无需 dropout。这一概念验证研究证明了可扩展、内存高效语言模型的可行性，并为未来大规模实验提供了动力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T07 (Primary) 68T50 (Secondary)"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 tables. Code available at https://github.com/HMUNACHI/pete",
      "pdf_url": "http://arxiv.org/pdf/2505.02266v1",
      "published_date": "2025-05-04 21:47:18 UTC",
      "updated_date": "2025-05-04 21:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:26:45.103006"
    },
    {
      "arxiv_id": "2505.02255v2",
      "title": "Enhancing AI Face Realism: Cost-Efficient Quality Improvement in Distilled Diffusion Models with a Fully Synthetic Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Wasala",
        "Bartlomiej Wrzalski",
        "Kornelia Noculak",
        "Yuliia Tarasenko",
        "Oliwer Krupa",
        "Jan Kocon",
        "Grzegorz Chodak"
      ],
      "abstract": "This study presents a novel approach to enhance the cost-to-quality ratio of\nimage generation with diffusion models. We hypothesize that differences between\ndistilled (e.g. FLUX.1-schnell) and baseline (e.g. FLUX.1-dev) models are\nconsistent and, therefore, learnable within a specialized domain, like portrait\ngeneration. We generate a synthetic paired dataset and train a fast\nimage-to-image translation head. Using two sets of low- and high-quality\nsynthetic images, our model is trained to refine the output of a distilled\ngenerator (e.g., FLUX.1-schnell) to a level comparable to a baseline model like\nFLUX.1-dev, which is more computationally intensive. Our results show that the\npipeline, which combines a distilled version of a large generative model with\nour enhancement layer, delivers similar photorealistic portraits to the\nbaseline version with up to an 82% decrease in computational cost compared to\nFLUX.1-dev. This study demonstrates the potential for improving the efficiency\nof AI solutions involving large-scale image generation.",
      "tldr_zh": "这篇论文提出了一种新方法，通过使用一个完全合成的配对数据集来提升蒸馏扩散模型（如 FLUX.1-schnell）的图像生成质量，旨在改善成本-质量比。方法涉及训练一个快速的图像到图像 translation 头，将低质量合成图像提升到与基线模型（如 FLUX.1-dev）相似的逼真水平。结果显示，该管道可将计算成本降低高达 82%，同时在人像生成领域实现高效的 AI 解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25th International Conference on Computational Science",
      "pdf_url": "http://arxiv.org/pdf/2505.02255v2",
      "published_date": "2025-05-04 21:28:21 UTC",
      "updated_date": "2025-05-08 19:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:26:56.994342"
    },
    {
      "arxiv_id": "2505.02247v1",
      "title": "RISE: Radius of Influence based Subgraph Extraction for 3D Molecular Graph Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingxiang Qu",
        "Wenhan Gao",
        "Jiaxing Zhang",
        "Xufeng Liu",
        "Hua Wei",
        "Haibin Ling",
        "Yi Liu"
      ],
      "abstract": "3D Geometric Graph Neural Networks (GNNs) have emerged as transformative\ntools for modeling molecular data. Despite their predictive power, these models\noften suffer from limited interpretability, raising concerns for scientific\napplications that require reliable and transparent insights. While existing\nmethods have primarily focused on explaining molecular substructures in 2D\nGNNs, the transition to 3D GNNs introduces unique challenges, such as handling\nthe implicit dense edge structures created by a cut-off radius. To tackle this,\nwe introduce a novel explanation method specifically designed for 3D GNNs,\nwhich localizes the explanation to the immediate neighborhood of each node\nwithin the 3D space. Each node is assigned an radius of influence, defining the\nlocalized region within which message passing captures spatial and structural\ninteractions crucial for the model's predictions. This method leverages the\nspatial and geometric characteristics inherent in 3D graphs. By constraining\nthe subgraph to a localized radius of influence, the approach not only enhances\ninterpretability but also aligns with the physical and structural dependencies\ntypical of 3D graph applications, such as molecular learning.",
      "tldr_zh": "该论文针对3D Geometric Graph Neural Networks (GNNs) 在分子数据建模中的可解释性问题，提出了一种新型解释方法RISE，以解决3D空间中隐式密集边结构的挑战。RISE方法为每个节点分配一个Radius of Influence（影响半径），将解释局限于节点的即时邻域，从而捕获空间和结构交互的关键信息。这种方法利用3D图的几何特性，通过提取局部子图，提升了模型的可解释性和透明度，并适用于分子学习等科学应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02247v1",
      "published_date": "2025-05-04 21:01:45 UTC",
      "updated_date": "2025-05-04 21:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:27:09.232453"
    },
    {
      "arxiv_id": "2505.03836v1",
      "title": "OBD-Finder: Explainable Coarse-to-Fine Text-Centric Oracle Bone Duplicates Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Chongsheng Zhang",
        "Shuwen Wu",
        "Yingqi Chen",
        "Matthias Aßenmacher",
        "Christian Heumann",
        "Yi Men",
        "Gaojuan Fan",
        "João Gama"
      ],
      "abstract": "Oracle Bone Inscription (OBI) is the earliest systematic writing system in\nChina, while the identification of Oracle Bone (OB) duplicates is a fundamental\nissue in OBI research. In this work, we design a progressive OB duplicate\ndiscovery framework that combines unsupervised low-level keypoints matching\nwith high-level text-centric content-based matching to refine and rank the\ncandidate OB duplicates with semantic awareness and interpretability. We\ncompare our approach with state-of-the-art content-based image retrieval and\nimage matching methods, showing that our approach yields comparable recall\nperformance and the highest simplified mean reciprocal rank scores for both\nTop-5 and Top-15 retrieval results, and with significantly accelerated\ncomputation efficiency. We have discovered over 60 pairs of new OB duplicates\nin real-world deployment, which were missed by OBI researchers for decades. The\nmodels, video illustration and demonstration of this work are available at:\nhttps://github.com/cszhangLMU/OBD-Finder/.",
      "tldr_zh": "本研究提出OBD-Finder框架，用于可解释的粗到细（Coarse-to-Fine）文本中心甲骨文（Oracle Bone Inscription, OBI）重复发现问题，该框架结合无监督的低级关键点匹配（keypoints matching）和高级内容-based匹配，以提升候选重复的精炼和排名。相比最先进的内容-based图像检索和图像匹配方法，该方法在召回性能上相当，但实现了最高的简化平均倒数排名（simplified mean reciprocal rank）分数，并在Top-5和Top-15检索中表现出色，同时显著提高了计算效率。在实际部署中，该框架发现了超过60对之前被忽略的新OB重复，为OBI研究提供了重要进展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "This is the long version of our OBD-Finder paper for AI-enabled\n  Oracle Bone Duplicates Discovery (currently under review at the ECML PKDD\n  2025 Demo Track). The models, video illustration and demonstration of this\n  paper are available at: https://github.com/cszhangLMU/OBD-Finder/.\n  Illustration video: https://www.youtube.com/watch?v=5QT4f0YIo0Q",
      "pdf_url": "http://arxiv.org/pdf/2505.03836v1",
      "published_date": "2025-05-04 20:35:15 UTC",
      "updated_date": "2025-05-04 20:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:27:22.516440"
    },
    {
      "arxiv_id": "2505.02236v1",
      "title": "Improving Physical Object State Representation in Text-to-Image Generative Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Tianle Chen",
        "Chaitanya Chakka",
        "Deepti Ghadiyaram"
      ],
      "abstract": "Current text-to-image generative models struggle to accurately represent\nobject states (e.g., \"a table without a bottle,\" \"an empty tumbler\"). In this\nwork, we first design a fully-automatic pipeline to generate high-quality\nsynthetic data that accurately captures objects in varied states. Next, we\nfine-tune several open-source text-to-image models on this synthetic data. We\nevaluate the performance of the fine-tuned models by quantifying the alignment\nof the generated images to their prompts using GPT4o-mini, and achieve an\naverage absolute improvement of 8+% across four models on the public\nGenAI-Bench dataset. We also curate a collection of 200 prompts with a specific\nfocus on common objects in various physical states. We demonstrate a\nsignificant improvement of an average of 24+% over the baseline on this\ndataset. We release all evaluation prompts and code.",
      "tldr_zh": "本研究针对文本到图像生成模型在表示物体物理状态（如“a table without a bottle”或“an empty tumbler”）方面的不足，设计了一个全自动管道来生成高质量的合成数据。接着，他们使用这些合成数据对几种开源模型进行fine-tune。评估结果显示，在公共GenAI-Bench数据集上，模型与提示的alignment平均绝对改善了8%以上；在他们整理的200个专注于物体状态的提示集合上，性能提升了平均24%以上。该工作还发布了所有评估提示和代码，以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to Synthetic Data for Computer Vision - CVPR 2025 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2505.02236v1",
      "published_date": "2025-05-04 20:24:57 UTC",
      "updated_date": "2025-05-04 20:24:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:27:33.025184"
    },
    {
      "arxiv_id": "2505.02235v1",
      "title": "SEval-Ex: A Statement-Level Framework for Explainable Summarization Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Tanguy Herserant",
        "Vincent Guigue"
      ],
      "abstract": "Evaluating text summarization quality remains a critical challenge in Natural\nLanguage Processing. Current approaches face a trade-off between performance\nand interpretability. We present SEval-Ex, a framework that bridges this gap by\ndecomposing summarization evaluation into atomic statements, enabling both high\nperformance and explainability. SEval-Ex employs a two-stage pipeline: first\nextracting atomic statements from text source and summary using LLM, then a\nmatching between generated statements. Unlike existing approaches that provide\nonly summary-level scores, our method generates detailed evidence for its\ndecisions through statement-level alignments. Experiments on the SummEval\nbenchmark demonstrate that SEval-Ex achieves state-of-the-art performance with\n0.580 correlation on consistency with human consistency judgments, surpassing\nGPT-4 based evaluators (0.521) while maintaining interpretability. Finally, our\nframework shows robustness against hallucination.",
      "tldr_zh": "本文提出 SEval-Ex 框架，这是一个语句级别的评估方法，用于解决自然语言处理中文本摘要评估的性能与可解释性权衡问题。框架采用两阶段管道：首先使用 LLM 从源文本和摘要中提取原子语句，然后进行语句匹配，以生成详细的证据支持决策。实验结果显示，在 SummEval 基准上，SEval-Ex 实现了 0.580 的相关性，与人类判断一致性优于 GPT-4（0.521），并展现出对 hallucination 的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02235v1",
      "published_date": "2025-05-04 20:16:08 UTC",
      "updated_date": "2025-05-04 20:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:27:46.195947"
    },
    {
      "arxiv_id": "2505.02232v1",
      "title": "Prompt-responsive Object Retrieval with Memory-augmented Student-Teacher Learning",
      "title_zh": "提示响应的对象检索：使用记忆增强",
      "authors": [
        "Malte Mosbach",
        "Sven Behnke"
      ],
      "abstract": "Building models responsive to input prompts represents a transformative shift\nin machine learning. This paradigm holds significant potential for robotics\nproblems, such as targeted manipulation amidst clutter. In this work, we\npresent a novel approach to combine promptable foundation models with\nreinforcement learning (RL), enabling robots to perform dexterous manipulation\ntasks in a prompt-responsive manner. Existing methods struggle to link\nhigh-level commands with fine-grained dexterous control. We address this gap\nwith a memory-augmented student-teacher learning framework. We use the\nSegment-Anything 2 (SAM 2) model as a perception backbone to infer an object of\ninterest from user prompts. While detections are imperfect, their temporal\nsequence provides rich information for implicit state estimation by\nmemory-augmented models. Our approach successfully learns prompt-responsive\npolicies, demonstrated in picking objects from cluttered scenes. Videos and\ncode are available at https://memory-student-teacher.github.io",
      "tldr_zh": "本文提出了一种 memory-augmented student-teacher learning 框架，将提示可用的基础模型与 Reinforcement Learning (RL) 结合，解决机器人领域中高水平命令与精细操控的脱节问题。该框架使用 Segment-Anything 2 (SAM 2) 作为感知后端，从用户提示中推断目标对象，并通过记忆增强模型利用时序检测信息进行隐式状态估计。实验结果显示，该方法在杂乱场景中成功实现了提示响应的物体捡拾任务，展示了其在机器人操控中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02232v1",
      "published_date": "2025-05-04 19:51:09 UTC",
      "updated_date": "2025-05-04 19:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:27:56.744164"
    },
    {
      "arxiv_id": "2505.03835v1",
      "title": "The Shift Towards Preprints in AI Policy Research: A Comparative Study of Preprint Trends in the U.S., Europe, and South Korea",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Suh",
        "Jihyuk Bang",
        "Ji Woo Han"
      ],
      "abstract": "The adoption of open science has quickly changed how artificial intelligence\n(AI) policy research is distributed globally. This study examines the regional\ntrends in the citation of preprints, specifically focusing on the impact of two\nmajor disruptive events: the COVID-19 pandemic and the release of ChatGPT, on\nresearch dissemination patterns in the United States, Europe, and South Korea\nfrom 2015 to 2024. Using bibliometrics data from the Web of Science, this study\ntracks how global disruptive events influenced the adoption of preprints in AI\npolicy research and how such shifts vary by region. By marking the timing of\nthese disruptive events, the analysis reveals that while all regions\nexperienced growth in preprint citations, the magnitude and trajectory of\nchange varied significantly. The United States exhibited sharp, event-driven\nincreases; Europe demonstrated institutional growth; and South Korea maintained\nconsistent, linear growth in preprint adoption. These findings suggest that\nglobal disruptions may have accelerated preprint adoption, but the extent and\ntrajectory are shaped by local research cultures, policy environments, and\nlevels of open science maturity. This paper emphasizes the need for future AI\ngovernance strategies to consider regional variability in research\ndissemination and highlights opportunities for further longitudinal and\ncomparative research to deepen our understanding of open-access adoption in AI\npolicy development.",
      "tldr_zh": "这篇论文比较分析了2015-2024年间，美国、欧洲和韩国在AI政策研究中预印本(preprints)引用趋势，焦点是COVID-19大流行和ChatGPT发布等全球事件对研究传播模式的影响。使用Web of Science的文献计量数据(bibliometrics)，研究发现所有地区均出现预印本采用增长，但美国显示事件驱动的急剧增加，欧洲呈现机构性增长，而韩国维持稳定的线性增长。这些发现强调全球中断事件加速了预印本采用，但其幅度和轨迹受本地研究文化、政策环境和开放科学成熟度(local research cultures, policy environments, and levels of open science maturity)的影响，并建议未来AI治理策略需考虑区域差异并开展更多纵向比较研究。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY",
        "I.2.0; K.4.0"
      ],
      "primary_category": "cs.DL",
      "comment": "22 pages, 6 figures, 3 tables. Uses cross-regional analysis to\n  evaluate how preprint citation trends in AI - policy research have shifted\n  over time in response to two major global events: the COVID-19 pandemic and\n  the release of ChatGPT. Compares United States, Europe, and South Korea",
      "pdf_url": "http://arxiv.org/pdf/2505.03835v1",
      "published_date": "2025-05-04 19:44:41 UTC",
      "updated_date": "2025-05-04 19:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:28:10.218671"
    },
    {
      "arxiv_id": "2505.02230v1",
      "title": "The GenAI Generation: Student Views of Awareness, Preparedness, and Concern",
      "title_zh": "GenAI 世代：学生对意识、准备度和担忧的看法",
      "authors": [
        "Micaela Siraj",
        "Jon Duke"
      ],
      "abstract": "Generative AI (GenAI) is revolutionizing education and workforce development,\nprofoundly shaping how students learn, engage, and prepare for their future.\nOutpacing the development of uniform policies and structures, GenAI has\nheralded a unique era and given rise to the GenAI Generation: a cohort of\nstudents whose education has been increasingly shaped by the opportunities and\nchallenges GenAI presents during its widespread adoption within society. This\nstudy examines our students' perceptions of GenAI through a concise survey with\noptional open-ended questions, focusing on their awareness, preparedness, and\nconcerns. Evaluation of more than 250 responses with more than 40% providing\ndetailed qualitative feedback reveals a core dual sentiment: while most\nstudents express enthusiasm for GenAI, an even greater proportion voice a\nspectrum of concerns about ethics, job displacement, and the adequacy of\neducational structures given the highly transformative technology. These\nfindings offer critical insights into how students view the potential and\npitfalls of GenAI for future career impacts, with accompanying recommendations\nto guide educational institutions in navigating a future driven by GenAI.",
      "tldr_zh": "本研究探讨了生成式AI（GenAI）对教育和职业发展的影响，通过对学生认知的调查，聚焦于他们的意识、准备度和担忧。调查收集了超过250份响应，其中40%提供了详细的定性反馈，结果显示学生对GenAI表现出热情，但更大比例表达了对伦理问题、工作流失以及教育结构不足的担忧。这些发现为教育机构提供了关键见解和建议，帮助其应对GenAI驱动的未来挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02230v1",
      "published_date": "2025-05-04 19:37:13 UTC",
      "updated_date": "2025-05-04 19:37:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:28:20.363247"
    },
    {
      "arxiv_id": "2505.02228v1",
      "title": "Coupled Distributional Random Expert Distillation for World Model Online Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shangzhe Li",
        "Zhiao Huang",
        "Hao Su"
      ],
      "abstract": "Imitation Learning (IL) has achieved remarkable success across various\ndomains, including robotics, autonomous driving, and healthcare, by enabling\nagents to learn complex behaviors from expert demonstrations. However, existing\nIL methods often face instability challenges, particularly when relying on\nadversarial reward or value formulations in world model frameworks. In this\nwork, we propose a novel approach to online imitation learning that addresses\nthese limitations through a reward model based on random network distillation\n(RND) for density estimation. Our reward model is built on the joint estimation\nof expert and behavioral distributions within the latent space of the world\nmodel. We evaluate our method across diverse benchmarks, including DMControl,\nMeta-World, and ManiSkill2, showcasing its ability to deliver stable\nperformance and achieve expert-level results in both locomotion and\nmanipulation tasks. Our approach demonstrates improved stability over\nadversarial methods while maintaining expert-level performance.",
      "tldr_zh": "本研究提出了一种名为“Coupled Distributional Random Expert Distillation”的新方法，用于世界模型框架下的在线Imitation Learning (IL)，以解决传统方法依赖对抗性奖励或价值公式导致的不稳定性问题。该方法基于Random Network Distillation (RND)构建奖励模型，通过在世界模型的潜在空间中联合估计专家和行为分布，实现更稳定的学习过程。在DMControl、Meta-World和ManiSkill2等基准测试中，该方法展示了显著的性能稳定性，并在运动和操作任务中达到了专家级结果，优于对抗性方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02228v1",
      "published_date": "2025-05-04 19:32:48 UTC",
      "updated_date": "2025-05-04 19:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:28:32.909137"
    },
    {
      "arxiv_id": "2505.02216v2",
      "title": "LLM-Guided Probabilistic Program Induction for POMDP Model Estimation",
      "title_zh": "LLM-Guided 概率程序归纳",
      "authors": [
        "Aidan Curtis",
        "Hao Tang",
        "Thiago Veloso",
        "Kevin Ellis",
        "Joshua Tenenbaum",
        "Tomás Lozano-Pérez",
        "Leslie Pack Kaelbling"
      ],
      "abstract": "Partially Observable Markov Decision Processes (POMDPs) model decision making\nunder uncertainty. While there are many approaches to approximately solving\nPOMDPs, we aim to address the problem of learning such models. In particular,\nwe are interested in a subclass of POMDPs wherein the components of the model,\nincluding the observation function, reward function, transition function, and\ninitial state distribution function, can be modeled as low-complexity\nprobabilistic graphical models in the form of a short probabilistic program.\nOur strategy to learn these programs uses an LLM as a prior, generating\ncandidate probabilistic programs that are then tested against the empirical\ndistribution and adjusted through feedback. We experiment on a number of\nclassical toy POMDP problems, simulated MiniGrid domains, and two real\nmobile-base robotics search domains involving partial observability. Our\nresults show that using an LLM to guide in the construction of a low-complexity\nPOMDP model can be more effective than tabular POMDP learning, behavior\ncloning, or direct LLM planning.",
      "tldr_zh": "这篇论文提出了一种使用大型语言模型 (LLM) 引导的概率程序归纳方法，用于估计部分可观测马尔可夫决策过程 (POMDPs) 模型，特别是那些组件可表示为简短概率程序的子类。方法以 LLM 作为先验生成候选程序，然后通过与经验分布比较并反馈调整，以优化模型学习。实验结果显示，该方法在经典玩具 POMDP 问题、模拟 MiniGrid 领域以及真实移动机器人搜索场景中，比表格 POMDP 学习、行为克隆或直接 LLM 规划更有效。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02216v2",
      "published_date": "2025-05-04 18:59:07 UTC",
      "updated_date": "2025-05-12 03:34:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:28:45.557436"
    },
    {
      "arxiv_id": "2505.02215v1",
      "title": "Interpretable Emergent Language Using Inter-Agent Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Mannan Bhardwaj"
      ],
      "abstract": "This paper explores the emergence of language in multi-agent reinforcement\nlearning (MARL) using transformers. Existing methods such as RIAL, DIAL, and\nCommNet enable agent communication but lack interpretability. We propose\nDifferentiable Inter-Agent Transformers (DIAT), which leverage self-attention\nto learn symbolic, human-understandable communication protocols. Through\nexperiments, DIAT demonstrates the ability to encode observations into\ninterpretable vocabularies and meaningful embeddings, effectively solving\ncooperative tasks. These results highlight the potential of DIAT for\ninterpretable communication in complex multi-agent environments.",
      "tldr_zh": "本研究探讨了多智能体强化学习(MARL)中语言的涌现问题，针对现有方法如 RIAL、DIAL 和 CommNet 允许代理通信但缺乏可解释性的缺点。作者提出 Differentiable Inter-Agent Transformers (DIAT)，利用 self-attention 机制学习符号化且人类可理解的通信协议，从而将代理的观察编码成可解释的词汇和有意义的嵌入。实验结果显示，DIAT 能有效解决合作任务，并在复杂多智能体环境中提升通信的可解释性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02215v1",
      "published_date": "2025-05-04 18:57:57 UTC",
      "updated_date": "2025-05-04 18:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:28:56.317045"
    },
    {
      "arxiv_id": "2505.02206v1",
      "title": "DNAZEN: Enhanced Gene Sequence Representations via Mixed Granularities of Coding Units",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Mao",
        "Yuanhe Tian",
        "Yan Song"
      ],
      "abstract": "Genome modeling conventionally treats gene sequence as a language, reflecting\nits structured motifs and long-range dependencies analogous to linguistic units\nand organization principles such as words and syntax. Recent studies utilize\nadvanced neural networks, ranging from convolutional and recurrent models to\nTransformer-based models, to capture contextual information of gene sequence,\nwith the primary goal of obtaining effective gene sequence representations and\nthus enhance the models' understanding of various running gene samples.\nHowever, these approaches often directly apply language modeling techniques to\ngene sequences and do not fully consider the intrinsic information organization\nin them, where they do not consider how units at different granularities\ncontribute to representation. In this paper, we propose DNAZEN, an enhanced\ngenomic representation framework designed to learn from various granularities\nin gene sequences, including small polymers and G-grams that are combinations\nof several contiguous polymers. Specifically, we extract the G-grams from\nlarge-scale genomic corpora through an unsupervised approach to construct the\nG-gram vocabulary, which is used to provide G-grams in the learning process of\nDNA sequences through dynamically matching from running gene samples. A\nTransformer-based G-gram encoder is also proposed and the matched G-grams are\nfed into it to compute their representations and integrated into the encoder\nfor basic unit (E4BU), which is responsible for encoding small units and\nmaintaining the learning and inference process. To further enhance the learning\nprocess, we propose whole G-gram masking to train DNAZEN, where the model\nlargely favors the selection of each entire G-gram to mask rather than an\nordinary masking mechanism performed on basic units. Experiments on benchmark\ndatasets demonstrate the effectiveness of DNAZEN on various downstream tasks.",
      "tldr_zh": "本研究提出DNAZEN框架，通过混合粒度编码单位（包括小聚合物和G-grams）来增强基因序列表示，解决传统语言建模方法忽略不同粒度信息组织的问题。具体而言，DNAZEN采用无监督方法从大规模基因语料中提取G-grams构建词汇，并通过动态匹配和Transformer-based G-gram编码器将其整合到基本单位编码器（E4BU）中，同时引入整体G-gram掩码机制进行训练。实验结果显示，DNAZEN在基准数据集上的各种下游任务中表现出色，提升了基因序列的上下文理解和表示能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02206v1",
      "published_date": "2025-05-04 18:02:28 UTC",
      "updated_date": "2025-05-04 18:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:29:08.242116"
    },
    {
      "arxiv_id": "2505.02198v1",
      "title": "Student Perspectives on the Benefits and Risks of AI in Education",
      "title_zh": "学生对AI在教育中益处与风险的看法",
      "authors": [
        "Griffin Pitts",
        "Viktoria Marcus",
        "Sanaz Motamedi"
      ],
      "abstract": "The use of chatbots equipped with artificial intelligence (AI) in educational\nsettings has increased in recent years, showing potential to support teaching\nand learning. However, the adoption of these technologies has raised concerns\nabout their impact on academic integrity, students' ability to problem-solve\nindependently, and potential underlying biases. To better understand students'\nperspectives and experiences with these tools, a survey was conducted at a\nlarge public university in the United States. Through thematic analysis, 262\nundergraduate students' responses regarding their perceived benefits and risks\nof AI chatbots in education were identified and categorized into themes.\n  The results discuss several benefits identified by the students, with\nfeedback and study support, instruction capabilities, and access to information\nbeing the most cited. Their primary concerns included risks to academic\nintegrity, accuracy of information, loss of critical thinking skills, the\npotential development of overreliance, and ethical considerations such as data\nprivacy, system bias, environmental impact, and preservation of human elements\nin education.\n  While student perceptions align with previously discussed benefits and risks\nof AI in education, they show heightened concerns about distinguishing between\nhuman and AI generated work - particularly in cases where authentic work is\nflagged as AI-generated. To address students' concerns, institutions can\nestablish clear policies regarding AI use and develop curriculum around AI\nliteracy. With these in place, practitioners can effectively develop and\nimplement educational systems that leverage AI's potential in areas such as\nimmediate feedback and personalized learning support. This approach can enhance\nthe quality of students' educational experiences while preserving the integrity\nof the learning process with AI.",
      "tldr_zh": "本研究调查了美国一所大型公立大学262名本科生对AI聊天机器人（AI chatbots）在教育中的益处和风险的看法，通过主题分析（thematic analysis）对他们的回应进行分类。学生们认为AI的主要益处包括提供反馈和学习支持、增强教学能力以及便捷的信息访问，这些有助于个性化学习和即时反馈。他们的主要担忧涉及学术诚信（academic integrity）、信息准确性、批判性思维技能的丧失、过度依赖，以及伦理问题如数据隐私、系统偏见、环境影响和教育中人类元素的保留。特别突出的是学生对区分人类和AI生成工作的困难，尤其是真实工作被误判为AI生成的风险。为应对这些担忧，研究建议教育机构制定明确的AI使用政策并融入AI素养课程，从而平衡AI的潜力与学习过程的完整性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "K.3; K.4"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02198v1",
      "published_date": "2025-05-04 17:36:11 UTC",
      "updated_date": "2025-05-04 17:36:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:29:21.763956"
    },
    {
      "arxiv_id": "2505.02192v1",
      "title": "DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization",
      "title_zh": "DualReal：自适应联合训练用于视频定制中的无损身份-动作融合",
      "authors": [
        "Wenchuan Wang",
        "Mengqi Huang",
        "Yijing Tu",
        "Zhendong Mao"
      ],
      "abstract": "Customized text-to-video generation with pre-trained large-scale models has\nrecently garnered significant attention through focusing on identity and motion\nconsistency. Existing works typically follow the isolated customized paradigm,\nwhere the subject identity or motion dynamics are customized exclusively.\nHowever, this paradigm completely ignores the intrinsic mutual constraints and\nsynergistic interdependencies between identity and motion, resulting in\nidentity-motion conflicts throughout the generation process that systematically\ndegrades. To address this, we introduce DualReal, a novel framework that,\nemploys adaptive joint training to collaboratively construct interdependencies\nbetween dimensions. Specifically, DualReal is composed of two units: (1)\nDual-aware Adaptation dynamically selects a training phase (i.e., identity or\nmotion), learns the current information guided by the frozen dimension prior,\nand employs a regularization strategy to avoid knowledge leakage; (2)\nStageBlender Controller leverages the denoising stages and Diffusion\nTransformer depths to guide different dimensions with adaptive granularity,\navoiding conflicts at various stages and ultimately achieving lossless fusion\nof identity and motion patterns. We constructed a more comprehensive benchmark\nthan existing methods. The experimental results show that DualReal improves\nCLIP-I and DINO-I metrics by 21.7% and 31.8% on average, and achieves top\nperformance on nearly all motion quality metrics.",
      "tldr_zh": "本研究提出 DualReal 框架，通过自适应联合训练来解决文本到视频生成中身份（identity）和动作（motion）一致性的冲突问题，该框架构建身份和动作之间的相互依赖，避免了孤立定制范式的局限。DualReal 包括两个核心组件：Dual-aware Adaptation 动态选择训练阶段，在冻结一个维度的情况下学习信息并使用正则化策略防止知识泄露；以及 StageBlender Controller，利用去噪阶段和 Diffusion Transformer 深度来指导不同维度的融合，实现无损身份-动作模式整合。实验结果显示，DualReal 在 CLIP-I 和 DINO-I 指标上平均提升 21.7% 和 31.8%，并在几乎所有动作质量指标上达到最佳性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02192v1",
      "published_date": "2025-05-04 17:19:20 UTC",
      "updated_date": "2025-05-04 17:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:29:34.214310"
    },
    {
      "arxiv_id": "2505.02184v1",
      "title": "Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew T. Dearing",
        "Yiheng Tao",
        "Xingfu Wu",
        "Zhiling Lan",
        "Valerie Taylor"
      ],
      "abstract": "While large language models (LLMs) are increasingly used for generating\nparallel scientific code, most current efforts emphasize functional\ncorrectness, often overlooking performance and energy considerations. In this\nwork, we propose LASSI-EE, an automated LLM-based refactoring framework that\ngenerates energy-efficient parallel code on a target parallel system for a\ngiven parallel code as input. Through a multi-stage, iterative pipeline\nprocess, LASSI-EE achieved an average energy reduction of 47% across 85% of the\n20 HeCBench benchmarks tested on NVIDIA A100 GPUs. Our findings demonstrate the\nbroader potential of LLMs, not only for generating correct code but also for\nenabling energy-aware programming. We also address key insights and limitations\nwithin the framework, offering valuable guidance for future improvements.",
      "tldr_zh": "本文提出 LASSI-EE，一个基于 LLMs 的自动化重构框架，旨在从给定并行科学代码生成针对特定并行系统的能源高效版本。框架采用多阶段迭代管道过程，通过优化代码来提升性能和能源效率。在 20 个 HeCBench 基准测试中，LASSI-EE 在 85% 的情况下实现了平均 47% 的能源减少。研究还探讨了 LLMs 在能源感知编程中的潜力，并指出了框架的限制，为未来改进提供了指导。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02184v1",
      "published_date": "2025-05-04 17:05:34 UTC",
      "updated_date": "2025-05-04 17:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:29:45.487893"
    },
    {
      "arxiv_id": "2505.02874v1",
      "title": "Uncertainty Quantification for Machine Learning in Healthcare: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "L. Julián Lechuga López",
        "Shaza Elsharief",
        "Dhiyaa Al Jorf",
        "Firas Darwish",
        "Congbo Ma",
        "Farah E. Shamout"
      ],
      "abstract": "Uncertainty Quantification (UQ) is pivotal in enhancing the robustness,\nreliability, and interpretability of Machine Learning (ML) systems for\nhealthcare, optimizing resources and improving patient care. Despite the\nemergence of ML-based clinical decision support tools, the lack of principled\nquantification of uncertainty in ML models remains a major challenge. Current\nreviews have a narrow focus on analyzing the state-of-the-art UQ in specific\nhealthcare domains without systematically evaluating method efficacy across\ndifferent stages of model development, and despite a growing body of research,\nits implementation in healthcare applications remains limited. Therefore, in\nthis survey, we provide a comprehensive analysis of current UQ in healthcare,\noffering an informed framework that highlights how different methods can be\nintegrated into each stage of the ML pipeline including data processing,\ntraining and evaluation. We also highlight the most popular methods used in\nhealthcare and novel approaches from other domains that hold potential for\nfuture adoption in the medical context. We expect this study will provide a\nclear overview of the challenges and opportunities of implementing UQ in the ML\npipeline for healthcare, guiding researchers and practitioners in selecting\nsuitable techniques to enhance the reliability, safety and trust from patients\nand clinicians on ML-driven healthcare solutions.",
      "tldr_zh": "这篇调查探讨了Uncertainty Quantification (UQ) 在医疗保健Machine Learning (ML) 中的重要性，强调其能提升模型的鲁棒性、可靠性和可解释性，从而优化资源和改善患者护理。论文提供了一个全面框架，系统分析了不同UQ方法在ML管道各阶段（如数据处理、训练和评估）的整合，并评估其功效，以弥补现有研究的狭隘焦点。作者还回顾了医疗保健领域最受欢迎的UQ方法，并引入其他领域的创新方法，旨在解决实施挑战并指导研究者和从业者选择合适技术，以增强ML驱动的医疗解决方案的安全性和信任。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "46 pages, 3 figures, 2 tables, AHLI Conference on Health, Inference,\n  and Learning (CHIL)",
      "pdf_url": "http://arxiv.org/pdf/2505.02874v1",
      "published_date": "2025-05-04 16:56:22 UTC",
      "updated_date": "2025-05-04 16:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:29:56.801905"
    },
    {
      "arxiv_id": "2505.02171v1",
      "title": "A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking",
      "title_zh": "一个新的 HOPE：领域无关的文本分块自动评估",
      "authors": [
        "Henrik Brådland",
        "Morten Goodwin",
        "Per-Arne Andersen",
        "Alexander S. Nossum",
        "Aditya Gupta"
      ],
      "abstract": "Document chunking fundamentally impacts Retrieval-Augmented Generation (RAG)\nby determining how source materials are segmented before indexing. Despite\nevidence that Large Language Models (LLMs) are sensitive to the layout and\nstructure of retrieved data, there is currently no framework to analyze the\nimpact of different chunking methods. In this paper, we introduce a novel\nmethodology that defines essential characteristics of the chunking process at\nthree levels: intrinsic passage properties, extrinsic passage properties, and\npassages-document coherence. We propose HOPE (Holistic Passage Evaluation), a\ndomain-agnostic, automatic evaluation metric that quantifies and aggregates\nthese characteristics. Our empirical evaluations across seven domains\ndemonstrate that the HOPE metric correlates significantly (p > 0.13) with\nvarious RAG performance indicators, revealing contrasts between the importance\nof extrinsic and intrinsic properties of passages. Semantic independence\nbetween passages proves essential for system performance with a performance\ngain of up to 56.2% in factual correctness and 21.1% in answer correctness. On\nthe contrary, traditional assumptions about maintaining concept unity within\npassages show minimal impact. These findings provide actionable insights for\noptimizing chunking strategies, thus improving RAG system design to produce\nmore factually correct responses.",
      "tldr_zh": "本文提出 HOPE，一种领域无关的自动评估指标，用于评估文本分块对检索增强生成(RAG)系统的影响，通过定义内在段落属性(intrinsic passage properties)、外在段落属性(extrinsic passage properties)和段落-文档连贯性(passages-document coherence)三大特性来量化分块过程。实验在七个领域进行，显示 HOPE 与 RAG 性能指标显著相关，段落间的语义独立性对系统性能至关重要，可提升高达 56.2% 的事实正确性和 21.1% 的答案正确性。相比之下，传统假设如保持段落内概念统一的影响较小，这些发现为优化分块策略和改善 RAG 系统设计提供了可操作指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, To be published in SIGIR25",
      "pdf_url": "http://arxiv.org/pdf/2505.02171v1",
      "published_date": "2025-05-04 16:22:27 UTC",
      "updated_date": "2025-05-04 16:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:30:10.732412"
    },
    {
      "arxiv_id": "2505.02170v1",
      "title": "Data-Driven Team Selection in Fantasy Premier League Using Integer Programming and Predictive Modeling Approach",
      "title_zh": "Fantasy Premier League 的数据驱动团队选择",
      "authors": [
        "Danial Ramezani"
      ],
      "abstract": "Fantasy football is a billion-dollar industry with millions of participants.\nConstrained by a fixed budget, decision-makers draft a squad whose players are\nexpected to perform well in the upcoming weeks to maximize total points. This\npaper proposes novel deterministic and robust integer programming models that\nselect the optimal starting eleven and the captain. A new hybrid scoring metric\nis constructed using an interpretable artificial intelligence framework and\nunderlying match performance data. Several objective functions and estimation\ntechniques are introduced for the programming model. To the best of my\nknowledge, this is the first study to approach fantasy football through this\nlens. The models' performance is evaluated using data from the 2023/24 Premier\nLeague season. Results indicate that the proposed hybrid method achieved the\nhighest score while maintaining consistent performance. Utilizing the Monte\nCarlo simulation, the strategic choice of averaging techniques for estimating\ncost vectors, and the proposed hybrid approach are shown to be effective during\nthe out-of-sample period. This paper also provides a thorough analysis of the\noptimal formations and players selected by the models, offering valuable\ninsights into effective fantasy football strategies.",
      "tldr_zh": "这篇论文提出了一种数据驱动的方法，使用整数规划(Integer Programming)和预测建模(Predictive Modeling)来优化Fantasy Premier League的球队选择，帮助决策者在固定预算下挑选高表现球员以最大化积分。研究构建了一个新的混合评分指标，通过可解释的人工智能框架和比赛数据，引入多种目标函数和估计技术，这是首个从这一角度研究幻想足球的尝试。实验基于2023/24赛季数据显示，该混合方法实现了最高分数并保持一致性能，而利用Monte Carlo simulation的策略进一步验证了其在样本外时期的有效性。最终，论文分析了最佳阵型和选定球员，提供宝贵的幻想足球策略见解。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02170v1",
      "published_date": "2025-05-04 16:21:59 UTC",
      "updated_date": "2025-05-04 16:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:30:21.750212"
    },
    {
      "arxiv_id": "2505.02158v1",
      "title": "Pickup & Delivery with Time Windows and Transfers: combining decomposition with metaheuristics",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Avgerinos",
        "Ioannis Mourtos",
        "Nikolaos Tsompanidis",
        "Georgios Zois"
      ],
      "abstract": "This paper examines the generalisation of the Pickup and Delivery Problem\nthat allows mid-route load exchanges among vehicles and obeys strict\ntime-windows at all locations. We propose a novel Logic-Based Benders\nDecomposition (LBBD) that improves optimality gaps for all benchmarks in the\nliterature and scales up to handle larger ones. To tackle even larger\ninstances, we introduce a refined Large Neighborhood Search (LNS) algorithm\nthat improves the adaptability of LNS beyond case-specific configurations\nappearing in related literature.\n  To bridge the gap in benchmark availability, we develop an instance generator\nthat allows for extensive experimentation. For moderate datasets (25 and 50\nrequests), we evaluate the performance of both LBBD and LNS, the former being\nable to close the gap and the latter capable of providing near-optimal\nsolutions. For larger instances (75 and 100 requests), we recreate indicative\nstate-of-the-art metaheuristics to highlight the improvements introduced by our\nLNS refinements, while establishing its scalability.",
      "tldr_zh": "该论文研究了Pickup and Delivery Problem的泛化版本，允许车辆在途中的负载转移并遵守严格时间窗口，提出结合Logic-Based Benders Decomposition (LBBD)和metaheuristics的方法来优化问题。研究开发了新型LBBD算法，显著改善了现有基准的优化间隙，并能扩展到更大实例；同时引入了改进的Large Neighborhood Search (LNS)算法，提升了其适应性和处理大型实例的能力。论文还创建了一个实例生成器进行广泛实验，结果显示LBBD在25和50请求的中等数据集上能关闭优化间隙，而LNS在75和100请求的更大实例上提供近优解并展示了更好的可扩展性。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02158v1",
      "published_date": "2025-05-04 15:45:09 UTC",
      "updated_date": "2025-05-04 15:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:30:35.620064"
    },
    {
      "arxiv_id": "2505.02156v4",
      "title": "Adaptive Thinking via Mode Policy Optimization for Social Language Agents",
      "title_zh": "通过模式策略优化实现适应性思考的社交语言代理",
      "authors": [
        "Minzheng Wang",
        "Yongbin Li",
        "Haobo Wang",
        "Xinghua Zhang",
        "Nan Xu",
        "Bingli Wu",
        "Fei Huang",
        "Haiyang Yu",
        "Wenji Mao"
      ],
      "abstract": "Effective social intelligence simulation requires language agents to\ndynamically adjust reasoning depth, a capability notably absent in current\nstudies. Existing methods either lack this kind of reasoning capability or\nenforce Long Chain-of-Thought reasoning uniformly across all scenarios,\nresulting in excessive token usage and inflexible social simulation. To address\nthis, we propose an $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{L}$earning\n($\\textbf{AML}$) framework in this paper, aiming to improve the adaptive\nthinking ability of language agents in dynamic social interactions. To this\nend, we first identify hierarchical thinking modes ranging from intuitive\nresponse to deep deliberation based on the cognitive control theory. We then\ndevelop the $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{P}$olicy\n$\\textbf{O}$ptimization ($\\textbf{AMPO}$) algorithm to optimize the\ncontext-aware mode switching and reasoning. Our framework advances existing\nresearch in three key aspects: (1) Multi-granular thinking mode design, (2)\nContext-aware mode switching across social interaction, and (3) Token-efficient\nreasoning via depth-adaptive processing. Extensive experiments on social\nintelligence benchmarks verify that AML achieves 15.6% higher task performance\nthan GPT-4o. Notably, our AMPO outperforms GRPO by 7.0% with 32.8% shorter\nreasoning chains, demonstrating the advantage of adaptive thinking mode\nselection and optimization mechanism in AMPO over GRPO's fixed-depth solution.",
      "tldr_zh": "本研究针对现有社交语言代理在动态互动中缺乏推理深度调整能力的问题，提出 Adaptive Mode Learning (AML) 框架，以提升代理的适应性思考。AML 基于认知控制理论，设计了从直觉响应到深度思考的层次化模式，并开发了 Adaptive Mode Policy Optimization (AMPO) 算法，实现上下文感知的模式切换和 token 高效推理。该框架的关键创新包括多粒度思考模式设计、上下文aware模式切换以及深度适应性处理。实验结果显示，AML 在社交智能基准测试中比 GPT-4o 高 15.6% 的任务性能，而 AMPO 相较 GRPO 提升 7.0% 且推理链缩短 32.8%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in Progress. The code and data are available, see\n  https://github.com/MozerWang/AMPO",
      "pdf_url": "http://arxiv.org/pdf/2505.02156v4",
      "published_date": "2025-05-04 15:39:58 UTC",
      "updated_date": "2025-05-22 09:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:30:47.744471"
    },
    {
      "arxiv_id": "2505.02154v1",
      "title": "Interpreting Multilingual and Document-Length Sensitive Relevance Computations in Neural Retrieval Models through Axiomatic Causal Interventions",
      "title_zh": "通过公理因果干预解释神经检索模型中多语言和文档长度敏感的相关性计算",
      "authors": [
        "Oliver Savolainen",
        "Dur e Najaf Amjad",
        "Roxana Petcu"
      ],
      "abstract": "This reproducibility study analyzes and extends the paper \"Axiomatic Causal\nInterventions for Reverse Engineering Relevance Computation in Neural Retrieval\nModels,\" which investigates how neural retrieval models encode task-relevant\nproperties such as term frequency. We reproduce key experiments from the\noriginal paper, confirming that information on query terms is captured in the\nmodel encoding. We extend this work by applying activation patching to Spanish\nand Chinese datasets and by exploring whether document-length information is\nencoded in the model as well. Our results confirm that the designed activation\npatching method can isolate the behavior to specific components and tokens in\nneural retrieval models. Moreover, our findings indicate that the location of\nterm frequency generalizes across languages and that in later layers, the\ninformation for sequence-level tasks is represented in the CLS token. The\nresults highlight the need for further research into interpretability in\ninformation retrieval and reproducibility in machine learning research. Our\ncode is available at\nhttps://github.com/OliverSavolainen/axiomatic-ir-reproduce.",
      "tldr_zh": "这篇论文通过可重复性研究，扩展了原论文“Axiomatic Causal Interventions for Reverse Engineering Relevance Computation in Neural Retrieval Models”，重点分析神经检索模型如何编码查询术语频率和文档长度信息。研究者复制了原实验，并应用activation patching技术到西班牙语和中文数据集，验证了模型在多语言环境下的行为。结果显示，术语频率信息的位置在不同语言中保持一致，且在后期层中由CLS token表示序列级任务信息。该工作突出了信息检索领域模型可解释性和机器学习研究可重复性的必要性，并提供了开源代码（https://github.com/OliverSavolainen/axiomatic-ir-reproduce）。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02154v1",
      "published_date": "2025-05-04 15:30:45 UTC",
      "updated_date": "2025-05-04 15:30:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:30:59.415187"
    },
    {
      "arxiv_id": "2505.02139v1",
      "title": "Representation Learning of Limit Order Book: A Comprehensive Study and Benchmarking",
      "title_zh": "限价订单簿的表示学习：一项全面研究和基准测试",
      "authors": [
        "Muyao Zhong",
        "Yushi Lin",
        "Peng Yang"
      ],
      "abstract": "The Limit Order Book (LOB), the mostly fundamental data of the financial\nmarket, provides a fine-grained view of market dynamics while poses significant\nchallenges in dealing with the esteemed deep models due to its strong\nautocorrelation, cross-feature constrains, and feature scale disparity.\nExisting approaches often tightly couple representation learning with specific\ndownstream tasks in an end-to-end manner, failed to analyze the learned\nrepresentations individually and explicitly, limiting their reusability and\ngeneralization. This paper conducts the first systematic comparative study of\nLOB representation learning, aiming to identify the effective way of extracting\ntransferable, compact features that capture essential LOB properties. We\nintroduce LOBench, a standardized benchmark with real China A-share market\ndata, offering curated datasets, unified preprocessing, consistent evaluation\nmetrics, and strong baselines. Extensive experiments validate the sufficiency\nand necessity of LOB representations for various downstream tasks and highlight\ntheir advantages over both the traditional task-specific end-to-end models and\nthe advanced representation learning models for general time series. Our work\nestablishes a reproducible framework and provides clear guidelines for future\nresearch. Datasets and code will be publicly available at\nhttps://github.com/financial-simulation-lab/LOBench.",
      "tldr_zh": "这篇论文针对限价订单簿 (LOB) 的表示学习进行了首个系统比较研究，旨在解决 LOB 的强自相关、跨特征约束和特征规模差异等挑战，并提取可转移的紧凑特征来捕捉其核心属性。作者引入了 LOBench 基准，使用真实中国 A 股市场数据，提供标准化的数据集、统一预处理、一致的评估指标和强基线模型。实验结果验证了 LOB 表示在各种下游任务中的充分性和必要性，并证明其优于传统任务特定端到端模型和高级时间序列表示学习模型。该研究建立了可重现的框架，并为未来 LOB 研究提供了清晰指导。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02139v1",
      "published_date": "2025-05-04 15:00:00 UTC",
      "updated_date": "2025-05-04 15:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:31:12.988232"
    },
    {
      "arxiv_id": "2505.02130v1",
      "title": "Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data",
      "title_zh": "从注意力机制视角：探索LLM处理图结构化数据",
      "authors": [
        "Zhong Guan",
        "Likang Wu",
        "Hongke Zhao",
        "Ming He",
        "Jianpin Fan"
      ],
      "abstract": "Attention mechanisms are critical to the success of large language models\n(LLMs), driving significant advancements in multiple fields. However, for\ngraph-structured data, which requires emphasis on topological connections, they\nfall short compared to message-passing mechanisms on fixed links, such as those\nemployed by Graph Neural Networks (GNNs). This raises a question: ``Does\nattention fail for graphs in natural language settings?'' Motivated by these\nobservations, we embarked on an empirical study from the perspective of\nattention mechanisms to explore how LLMs process graph-structured data. The\ngoal is to gain deeper insights into the attention behavior of LLMs over graph\nstructures. We uncovered unique phenomena regarding how LLMs apply attention to\ngraph-structured data and analyzed these findings to improve the modeling of\nsuch data by LLMs. The primary findings of our research are: 1) While LLMs can\nrecognize graph data and capture text-node interactions, they struggle to model\ninter-node relationships within graph structures due to inherent architectural\nconstraints. 2) The attention distribution of LLMs across graph nodes does not\nalign with ideal structural patterns, indicating a failure to adapt to graph\ntopology nuances. 3) Neither fully connected attention nor fixed connectivity\nis optimal; each has specific limitations in its application scenarios.\nInstead, intermediate-state attention windows improve LLM training performance\nand seamlessly transition to fully connected windows during inference. Source\ncode: \\href{https://github.com/millioniron/LLM_exploration}{LLM4Exploration}",
      "tldr_zh": "该研究从注意力机制视角，探讨大型语言模型(LLMs)处理图结构数据的能力，针对LLMs在捕捉图拓扑连接方面不如Graph Neural Networks (GNNs)的message-passing机制的问题，进行了实证分析。结果显示，LLMs能识别图数据和文本-节点交互，但由于架构限制，难以有效建模节点间关系，且注意力分布无法适应图拓扑的细微差异。论文进一步发现，完全连接注意力或固定连接各有局限，建议采用中间状态注意力窗口来改善训练性能，并在推理时无缝过渡至完全连接模式。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML2025 Accept",
      "pdf_url": "http://arxiv.org/pdf/2505.02130v1",
      "published_date": "2025-05-04 14:40:31 UTC",
      "updated_date": "2025-05-04 14:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:31:23.909034"
    },
    {
      "arxiv_id": "2505.02129v2",
      "title": "Subspace Aggregation Query and Index Generation for Multidimensional Resource Space Model",
      "title_zh": "针对多维资源空间模型的子空间聚合查询和索引生成",
      "authors": [
        "Xiaoping Sun",
        "Hai Zhuge"
      ],
      "abstract": "Organizing resources in a multidimensional classification space is an\napproach to efficiently managing and querying large-scale resources. This paper\ndefines an aggregation query on subspace defined by a range on the partial\norder on coordinate tree at each dimension, where each point contains resources\naggregated along the paths of partial order relations on the points so that\naggregated resources at each point within the subspace can be measured, ranked\nand selected. To efficiently locate non-empty points in a large subspace, an\napproach to generating graph index is proposed to build inclusion links with\npartial order relations on coordinates of dimensions to enable a subspace query\nto reach non-empty points by following indexing links and aggregate resources\nalong indexing paths back to their super points. Generating such an index is\ncostly as the number of children of an index node can be very large so that the\ntotal number of indexing nodes is unbounded. The proposed approach adopts the\nfollowing strategies to reduce the cost: (1) adding intersection links between\ntwo indexing nodes, which can better reduce query processing costs while\ncontrolling the number of nodes of the graph index; (2) intersection links are\nadded between two nodes according to the probabilistic distribution calculated\nfor estimating the costs of adding intersection between two nodes; (3)\ncoordinates at one dimension having more resources are split by coordinates at\nanother dimension to balance the number of resources hold by indexing nodes;\nand, (4) short-cut links are added between sibling coordinates of coordinate\ntrees to make an efficient query on linear order coordinates. Analysis and\nexperiments verified the effectiveness of the generated index in supporting\nsubspace aggregation query. This work makes significant contributions to the\ndevelopment of data model based on multi-dimensional classification.",
      "tldr_zh": "这篇论文针对多维资源空间模型（Multidimensional Resource Space Model），定义了子空间聚合查询（subspace aggregation query），它基于每个维度的坐标树部分顺序（partial order）来聚合和查询资源。论文提出了一种生成图索引（graph index）的方法，通过建立包含链接和部分顺序关系来快速定位子空间中的非空点，同时采用策略如添加交叉链接（intersection links）、基于概率分布的成本估算、资源平衡分割和快捷链接（short-cut links）来降低索引生成成本。实验分析证明，该索引显著提高了子空间聚合查询的效率，并为多维分类数据模型的发展做出了重要贡献。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02129v2",
      "published_date": "2025-05-04 14:36:31 UTC",
      "updated_date": "2025-05-09 10:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:31:36.482641"
    },
    {
      "arxiv_id": "2505.02121v1",
      "title": "Overview of AI Grading of Physics Olympiad Exams",
      "title_zh": "翻译失败",
      "authors": [
        "Lachlan McGinness"
      ],
      "abstract": "Automatically grading the diverse range of question types in high school\nphysics problem is a challenge that requires automated grading techniques from\ndifferent fields. We report the findings of a Systematic Literature Review of\npotential physics grading techniques. We propose a multi-modal AI grading\nframework to address these challenges and examine our framework in light of\nAustralia's AI Ethical Principles.",
      "tldr_zh": "本研究概述了使用AI自动评分高中物理奥林匹克考试中多样化问题类型的挑战，并通过Systematic Literature Review系统文献综述，审查了潜在的物理评分技术。论文提出一个multi-modal AI grading framework多模态AI评分框架，以应对这些挑战，并评估该框架是否符合Australia's AI Ethical Principles澳大利亚AI伦理原则。该框架旨在整合不同领域的自动化技术，提高评分效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "International Conference on Artificial Intelligence in Education,\n  Doctoral Consortium",
      "pdf_url": "http://arxiv.org/pdf/2505.02121v1",
      "published_date": "2025-05-04 14:04:24 UTC",
      "updated_date": "2025-05-04 14:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:31:47.906272"
    },
    {
      "arxiv_id": "2505.02120v1",
      "title": "Tricolore: Multi-Behavior User Profiling for Enhanced Candidate Generation in Recommender Systems",
      "title_zh": "Tricolore：多行为用户画像用于增强推荐系统中的候选生成",
      "authors": [
        "Xiao Zhou",
        "Zhongxiang Zhao",
        "Hanze Guo"
      ],
      "abstract": "Online platforms aggregate extensive user feedback across diverse behaviors,\nproviding a rich source for enhancing user engagement. Traditional recommender\nsystems, however, typically optimize for a single target behavior and represent\nuser preferences with a single vector, limiting their ability to handle\nmultiple important behaviors or optimization objectives. This conventional\napproach also struggles to capture the full spectrum of user interests,\nresulting in a narrow item pool during candidate generation. To address these\nlimitations, we present Tricolore, a versatile multi-vector learning framework\nthat uncovers connections between different behavior types for more robust\ncandidate generation. Tricolore's adaptive multi-task structure is also\ncustomizable to specific platform needs. To manage the variability in sparsity\nacross behavior types, we incorporate a behavior-wise multi-view fusion module\nthat dynamically enhances learning. Moreover, a popularity-balanced strategy\nensures the recommendation list balances accuracy with item popularity,\nfostering diversity and improving overall performance. Extensive experiments on\npublic datasets demonstrate Tricolore's effectiveness across various\nrecommendation scenarios, from short video platforms to e-commerce. By\nleveraging a shared base embedding strategy, Tricolore also significantly\nimproves the performance for cold-start users. The source code is publicly\navailable at: https://github.com/abnering/Tricolore.",
      "tldr_zh": "传统推荐系统通常优化单一目标行为并使用单一向量表示用户偏好，导致无法有效处理多种行为类型和优化目标，从而限制候选生成。论文提出 Tricolore，一种多向量学习框架，通过发现不同行为类型间的连接来增强候选生成，并采用自适应多任务结构以适应平台需求。为处理行为稀疏性差异，Tricolore 整合了 behavior-wise multi-view fusion module 和 popularity-balanced strategy，以平衡准确性、物品流行度和推荐多样性。在公共数据集上的实验证明，该框架在短视频平台和电商等场景中表现出色，并通过 shared base embedding strategy 显著提升冷启动用户的性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02120v1",
      "published_date": "2025-05-04 14:04:22 UTC",
      "updated_date": "2025-05-04 14:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:32:01.876194"
    },
    {
      "arxiv_id": "2505.02118v3",
      "title": "Adversarial Cooperative Rationalization: The Risk of Spurious Correlations in Even Clean Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Liu",
        "Zhongyu Niu",
        "Lang Gao",
        "Zhiying Deng",
        "Jun Wang",
        "Haozhao Wang",
        "Ruixuan Li"
      ],
      "abstract": "This study investigates the self-rationalization framework constructed with a\ncooperative game, where a generator initially extracts the most informative\nsegment from raw input, and a subsequent predictor utilizes the selected subset\nfor its input. The generator and predictor are trained collaboratively to\nmaximize prediction accuracy. In this paper, we first uncover a potential\ncaveat: such a cooperative game could unintentionally introduce a sampling bias\nduring rationale extraction. Specifically, the generator might inadvertently\ncreate an incorrect correlation between the selected rationale candidate and\nthe label, even when they are semantically unrelated in the original dataset.\nSubsequently, we elucidate the origins of this bias using both detailed\ntheoretical analysis and empirical evidence. Our findings suggest a direction\nfor inspecting these correlations through attacks, based on which we further\nintroduce an instruction to prevent the predictor from learning the\ncorrelations. Through experiments on six text classification datasets and two\ngraph classification datasets using three network architectures (GRUs, BERT,\nand GCN), we show that our method not only significantly outperforms recent\nrationalization methods, but also achieves comparable or even better results\nthan a representative LLM (llama3.1-8b-instruct).",
      "tldr_zh": "本研究调查了基于合作游戏的自理性化框架（cooperative rationalization），其中生成器从原始输入中提取关键子集，预测器则使用该子集进行预测，以最大化准确率。然而，该框架可能引入采样偏差，导致生成器创建虚假相关性（spurious correlations），即使原始数据集语义上无关。作者通过理论分析和实证证据阐明偏差来源，并提出攻击方法检测这些相关性，同时引入指令防止预测器学习它们。在六个文本分类数据集和两个图分类数据集上，使用GRU、BERT和GCN等架构进行实验，结果显示该方法显著优于现有理性化方法，甚至与llama3.1-8b-instruct相当或更好。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02118v3",
      "published_date": "2025-05-04 14:00:04 UTC",
      "updated_date": "2025-05-11 05:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:32:12.769329"
    },
    {
      "arxiv_id": "2505.02110v1",
      "title": "Eterna is Solved",
      "title_zh": "翻译失败",
      "authors": [
        "Tristan Cazenave"
      ],
      "abstract": "RNA design consists of discovering a nucleotide sequence that folds into a\ntarget secondary structure. It is useful for synthetic biology, medicine, and\nnanotechnology. We propose Montparnasse, a Multi Objective Generalized Nested\nRollout Policy Adaptation with Limited Repetition (MOGNRPALR) RNA design\nalgorithm. It solves the Eterna benchmark.",
      "tldr_zh": "本论文解决了 RNA design 问题，即发现一种能折叠成目标二级结构的核苷酸序列，并将其应用于合成生物学、医学和纳米技术领域。我们提出了一种名为 Montparnasse 的算法，即 Multi Objective Generalized Nested Rollout Policy Adaptation with Limited Repetition (MOGNRPALR)，用于优化 RNA 设计过程。该算法成功解决了 Eterna benchmark，展示了其在复杂生物设计中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02110v1",
      "published_date": "2025-05-04 13:31:53 UTC",
      "updated_date": "2025-05-04 13:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:32:24.157699"
    },
    {
      "arxiv_id": "2505.02872v1",
      "title": "Decoding Open-Ended Information Seeking Goals from Eye Movements in Reading",
      "title_zh": "从阅读中的眼动解码开放式信息搜索目标",
      "authors": [
        "Cfir Avraham Hadar",
        "Omer Shubi",
        "Yoav Meiri",
        "Yevgeni Berzak"
      ],
      "abstract": "When reading, we often have specific information that interests us in a text.\nFor example, you might be reading this paper because you are curious about LLMs\nfor eye movements in reading, the experimental design, or perhaps you only care\nabout the question ``but does it work?''. More broadly, in daily life, people\napproach texts with any number of text-specific goals that guide their reading\nbehavior. In this work, we ask, for the first time, whether open-ended reading\ngoals can be automatically decoded from eye movements in reading. To address\nthis question, we introduce goal classification and goal reconstruction tasks\nand evaluation frameworks, and use large-scale eye tracking for reading data in\nEnglish with hundreds of text-specific information seeking tasks. We develop\nand compare several discriminative and generative multimodal LLMs that combine\neye movements and text for goal classification and goal reconstruction. Our\nexperiments show considerable success on both tasks, suggesting that LLMs can\nextract valuable information about the readers' text-specific goals from eye\nmovements.",
      "tldr_zh": "本研究首次探讨了从阅读中的眼动数据中自动解码开放式信息寻求目标的可能性。研究者引入了目标分类和目标重建任务，并使用大规模英语阅读眼动追踪数据，涉及数百个文本特定的信息寻求任务。作者开发并比较了多种结合眼动和文本的多模态 LLMs，包括判别式和生成式模型。实验结果显示，这些模型在任务中取得了显著成功，证明 LLMs 可以从眼动中提取读者的文本特定目标信息。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02872v1",
      "published_date": "2025-05-04 13:23:48 UTC",
      "updated_date": "2025-05-04 13:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:32:36.087669"
    },
    {
      "arxiv_id": "2505.06262v1",
      "title": "Dialz: A Python Toolkit for Steering Vectors",
      "title_zh": "Dialz：用于转向向量的 Python 工具包",
      "authors": [
        "Zara Siddique",
        "Liam D. Turner",
        "Luis Espinosa-Anke"
      ],
      "abstract": "We introduce Dialz, a framework for advancing research on steering vectors\nfor open-source LLMs, implemented in Python. Steering vectors allow users to\nmodify activations at inference time to amplify or weaken a 'concept', e.g.\nhonesty or positivity, providing a more powerful alternative to prompting or\nfine-tuning. Dialz supports a diverse set of tasks, including creating\ncontrastive pair datasets, computing and applying steering vectors, and\nvisualizations. Unlike existing libraries, Dialz emphasizes modularity and\nusability, enabling both rapid prototyping and in-depth analysis. We\ndemonstrate how Dialz can be used to reduce harmful outputs such as\nstereotypes, while also providing insights into model behaviour across\ndifferent layers. We release Dialz with full documentation, tutorials, and\nsupport for popular open-source models to encourage further research in safe\nand controllable language generation. Dialz enables faster research cycles and\nfacilitates insights into model interpretability, paving the way for safer,\nmore transparent, and more reliable AI systems.",
      "tldr_zh": "该研究引入了 Dialz，这是一个 Python 工具包，旨在推进开源大型语言模型 (LLMs) 的 steering vectors 研究。Dialz 允许用户在推理时修改激活来增强或削弱特定概念（如诚实或积极性），提供比提示或微调更强大的控制选项，并支持创建对比数据集、计算和应用 steering vectors 以及可视化功能。相比现有库，Dialz 强调模块性和可用性，用于快速原型设计和深入分析，并在实验中展示了其减少有害输出（如刻板印象）的能力，同时提供模型行为跨层洞见。该工具开源发布，包括完整文档、教程和对流行模型的支持，促进更安全、可控的语言生成研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06262v1",
      "published_date": "2025-05-04 13:19:21 UTC",
      "updated_date": "2025-05-04 13:19:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:32:48.200778"
    },
    {
      "arxiv_id": "2505.02099v1",
      "title": "MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Zhang",
        "Quanyu Dai",
        "Xu Chen",
        "Rui Li",
        "Zhongyang Li",
        "Zhenhua Dong"
      ],
      "abstract": "Recently, large language model based (LLM-based) agents have been widely\napplied across various fields. As a critical part, their memory capabilities\nhave captured significant interest from both industrial and academic\ncommunities. Despite the proposal of many advanced memory models in recent\nresearch, however, there remains a lack of unified implementations under a\ngeneral framework. To address this issue, we develop a unified and modular\nlibrary for developing advanced memory models of LLM-based agents, called\nMemEngine. Based on our framework, we implement abundant memory models from\nrecent research works. Additionally, our library facilitates convenient and\nextensible memory development, and offers user-friendly and pluggable memory\nusage. For benefiting our community, we have made our project publicly\navailable at https://github.com/nuster1128/MemEngine.",
      "tldr_zh": "该论文提出 MemEngine，这是一个统一的模块化库，用于开发 LLM-based agents 的高级记忆模型，以解决当前记忆模型缺乏通用框架的问题。MemEngine 基于一个通用框架实现了多种最近研究的记忆模型，并提供便捷的开发、扩展以及用户友好的可插拔功能。最终，该库已开源在 GitHub 上，以促进社区的进一步应用和发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Just accepted by TheWebConf'25 Resource Track",
      "pdf_url": "http://arxiv.org/pdf/2505.02099v1",
      "published_date": "2025-05-04 13:10:44 UTC",
      "updated_date": "2025-05-04 13:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:32:59.617932"
    },
    {
      "arxiv_id": "2505.02087v1",
      "title": "Retrieval-augmented in-context learning for multimodal large language models in disease classification",
      "title_zh": "翻译失败",
      "authors": [
        "Zaifu Zhan",
        "Shuang Zhou",
        "Xiaoshan Zhou",
        "Yongkang Xiao",
        "Jun Wang",
        "Jiawen Deng",
        "He Zhu",
        "Yu Hou",
        "Rui Zhang"
      ],
      "abstract": "Objectives: We aim to dynamically retrieve informative demonstrations,\nenhancing in-context learning in multimodal large language models (MLLMs) for\ndisease classification.\n  Methods: We propose a Retrieval-Augmented In-Context Learning (RAICL)\nframework, which integrates retrieval-augmented generation (RAG) and in-context\nlearning (ICL) to adaptively select demonstrations with similar disease\npatterns, enabling more effective ICL in MLLMs. Specifically, RAICL examines\nembeddings from diverse encoders, including ResNet, BERT, BioBERT, and\nClinicalBERT, to retrieve appropriate demonstrations, and constructs\nconversational prompts optimized for ICL. We evaluated the framework on two\nreal-world multi-modal datasets (TCGA and IU Chest X-ray), assessing its\nperformance across multiple MLLMs (Qwen, Llava, Gemma), embedding strategies,\nsimilarity metrics, and varying numbers of demonstrations.\n  Results: RAICL consistently improved classification performance. Accuracy\nincreased from 0.7854 to 0.8368 on TCGA and from 0.7924 to 0.8658 on IU Chest\nX-ray. Multi-modal inputs outperformed single-modal ones, with text-only inputs\nbeing stronger than images alone. The richness of information embedded in each\nmodality will determine which embedding model can be used to get better\nresults. Few-shot experiments showed that increasing the number of retrieved\nexamples further enhanced performance. Across different similarity metrics,\nEuclidean distance achieved the highest accuracy while cosine similarity\nyielded better macro-F1 scores. RAICL demonstrated consistent improvements\nacross various MLLMs, confirming its robustness and versatility.\n  Conclusions: RAICL provides an efficient and scalable approach to enhance\nin-context learning in MLLMs for multimodal disease classification.",
      "tldr_zh": "本研究提出了一种Retrieval-Augmented In-Context Learning (RAICL)框架，用于提升多模态大型语言模型(MLLMs)在疾病分类中的in-context learning表现，通过动态检索相似疾病模式的演示来优化提示。RAICL整合了Retrieval-Augmented Generation (RAG)和ICL，利用多种编码器（如ResNet、BERT、BioBERT和ClinicalBERT）来选择适当的演示，并在TCGA和IU Chest X-ray等真实数据集上进行评估。实验结果显示，RAICL显著提高了分类准确率（TCGA从0.7854增至0.8368，IU Chest X-ray从0.7924增至0.8658），多模态输入优于单模态，且增加检索示例数量进一步提升性能，同时在不同MLLMs（如Qwen、Llava、Gemma）上显示出鲁棒性。总之，该框架为多模态疾病分类提供了一种高效、可扩展的增强方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 Pages, 1 figure, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.02087v1",
      "published_date": "2025-05-04 12:43:56 UTC",
      "updated_date": "2025-05-04 12:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:33:14.585068"
    },
    {
      "arxiv_id": "2505.03833v1",
      "title": "PointExplainer: Towards Transparent Parkinson's Disease Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Xuechao Wang",
        "Sven Nomm",
        "Junqing Huang",
        "Kadri Medijainen",
        "Aaro Toomela",
        "Michael Ruzhansky"
      ],
      "abstract": "Deep neural networks have shown potential in analyzing digitized hand-drawn\nsignals for early diagnosis of Parkinson's disease. However, the lack of clear\ninterpretability in existing diagnostic methods presents a challenge to\nclinical trust. In this paper, we propose PointExplainer, an explainable\ndiagnostic strategy to identify hand-drawn regions that drive model diagnosis.\nSpecifically, PointExplainer assigns discrete attribution values to hand-drawn\nsegments, explicitly quantifying their relative contributions to the model's\ndecision. Its key components include: (i) a diagnosis module, which encodes\nhand-drawn signals into 3D point clouds to represent hand-drawn trajectories,\nand (ii) an explanation module, which trains an interpretable surrogate model\nto approximate the local behavior of the black-box diagnostic model. We also\nintroduce consistency measures to further address the issue of faithfulness in\nexplanations. Extensive experiments on two benchmark datasets and a newly\nconstructed dataset show that PointExplainer can provide intuitive explanations\nwith no diagnostic performance degradation. The source code is available at\nhttps://github.com/chaoxuewang/PointExplainer.",
      "tldr_zh": "这篇论文针对深度神经网络在帕金森病诊断中的可解释性不足问题，提出了 PointExplainer 策略，用于识别手绘信号中影响模型决策的关键区域。PointExplainer 的核心组件包括诊断模块（将手绘信号编码成 3D point clouds 表示轨迹）和解释模块（训练可解释的 surrogate model 来近似黑盒模型的局部行为），并引入一致性措施确保解释的可靠性。实验结果显示，该方法在两个基准数据集和一个新构建的数据集上提供直观的解释，同时不降低诊断性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03833v1",
      "published_date": "2025-05-04 12:23:58 UTC",
      "updated_date": "2025-05-04 12:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:33:24.881039"
    },
    {
      "arxiv_id": "2505.03832v1",
      "title": "Video Forgery Detection for Surveillance Cameras: A Review",
      "title_zh": "监控摄像头视频伪造检测：综述",
      "authors": [
        "Noor B. Tayfor",
        "Tarik A. Rashid",
        "Shko M. Qader",
        "Bryar A. Hassan",
        "Mohammed H. Abdalla",
        "Jafar Majidpour",
        "Aram M. Ahmed",
        "Hussein M. Ali",
        "Aso M. Aladdin",
        "Abdulhady A. Abdullah",
        "Ahmed S. Shamsaldin",
        "Haval M. Sidqi",
        "Abdulrahman Salih",
        "Zaher M. Yaseen",
        "Azad A. Ameen",
        "Janmenjoy Nayak",
        "Mahmood Yashar Hamza"
      ],
      "abstract": "The widespread availability of video recording through smartphones and\ndigital devices has made video-based evidence more accessible than ever.\nSurveillance footage plays a crucial role in security, law enforcement, and\njudicial processes. However, with the rise of advanced video editing tools,\ntampering with digital recordings has become increasingly easy, raising\nconcerns about their authenticity. Ensuring the integrity of surveillance\nvideos is essential, as manipulated footage can lead to misinformation and\nundermine judicial decisions. This paper provides a comprehensive review of\nexisting forensic techniques used to detect video forgery, focusing on their\neffectiveness in verifying the authenticity of surveillance recordings. Various\nmethods, including compression-based analysis, frame duplication detection, and\nmachine learning-based approaches, are explored. The findings highlight the\ngrowing necessity for more robust forensic techniques to counteract evolving\nforgery methods. Strengthening video forensic capabilities will ensure that\nsurveillance recordings remain credible and admissible as legal evidence.",
      "tldr_zh": "这篇论文审阅了监控摄像头视频伪造检测的现有取证技术，强调了数字视频篡改对安全、执法和司法过程的潜在威胁。作者探讨了多种方法，包括 compression-based analysis、frame duplication detection 和 machine learning-based approaches，以评估这些技术在验证视频真实性方面的有效性。研究发现，随着伪造工具的演进，需要更强大的取证手段来确保视频证据的可信度和法律适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03832v1",
      "published_date": "2025-05-04 12:21:24 UTC",
      "updated_date": "2025-05-04 12:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:33:35.436008"
    },
    {
      "arxiv_id": "2505.02078v1",
      "title": "LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning",
      "title_zh": "LecEval：多媒体学习中多模态知识获取的自动化指标",
      "authors": [
        "Joy Lim Jia Yin",
        "Daniel Zhang-Li",
        "Jifan Yu",
        "Haoxuan Li",
        "Shangqing Tu",
        "Yuanchun Wang",
        "Zhiyuan Liu",
        "Huiqin Liu",
        "Lei Hou",
        "Juanzi Li",
        "Bin Xu"
      ],
      "abstract": "Evaluating the quality of slide-based multimedia instruction is challenging.\nExisting methods like manual assessment, reference-based metrics, and large\nlanguage model evaluators face limitations in scalability, context capture, or\nbias. In this paper, we introduce LecEval, an automated metric grounded in\nMayer's Cognitive Theory of Multimedia Learning, to evaluate multimodal\nknowledge acquisition in slide-based learning. LecEval assesses effectiveness\nusing four rubrics: Content Relevance (CR), Expressive Clarity (EC), Logical\nStructure (LS), and Audience Engagement (AE). We curate a large-scale dataset\nof over 2,000 slides from more than 50 online course videos, annotated with\nfine-grained human ratings across these rubrics. A model trained on this\ndataset demonstrates superior accuracy and adaptability compared to existing\nmetrics, bridging the gap between automated and human assessments. We release\nour dataset and toolkits at https://github.com/JoylimJY/LecEval.",
      "tldr_zh": "本论文针对幻灯片-based 多媒体教学质量评估的挑战，引入了LecEval，一种基于Mayer's Cognitive Theory of Multimedia Learning的自动化指标，用于评估多模态知识获取。该指标通过四个标准——Content Relevance (CR)、Expressive Clarity (EC)、Logical Structure (LS)和Audience Engagement (AE)——来衡量教学有效性。研究者构建了一个包含超过2,000个幻灯片的大规模数据集，并标注了细粒度的人类评分；在该数据集上训练的模型显示出比现有方法更高的准确性和适应性，缩小了自动化和人类评估的差距。他们还发布了数据集和工具包（https://github.com/JoylimJY/LecEval），以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02078v1",
      "published_date": "2025-05-04 12:06:47 UTC",
      "updated_date": "2025-05-04 12:06:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:33:50.335412"
    },
    {
      "arxiv_id": "2505.02077v1",
      "title": "Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents",
      "title_zh": "多智能体安全中的开放挑战：通往交互AI智能体安全系统的方向",
      "authors": [
        "Christian Schroeder de Witt"
      ],
      "abstract": "Decentralized AI agents will soon interact across internet platforms,\ncreating security challenges beyond traditional cybersecurity and AI safety\nframeworks. Free-form protocols are essential for AI's task generalization but\nenable new threats like secret collusion and coordinated swarm attacks. Network\neffects can rapidly spread privacy breaches, disinformation, jailbreaks, and\ndata poisoning, while multi-agent dispersion and stealth optimization help\nadversaries evade oversightcreating novel persistent threats at a systemic\nlevel. Despite their critical importance, these security challenges remain\nunderstudied, with research fragmented across disparate fields including AI\nsecurity, multi-agent learning, complex systems, cybersecurity, game theory,\ndistributed systems, and technical AI governance. We introduce\n\\textbf{multi-agent security}, a new field dedicated to securing networks of\ndecentralized AI agents against threats that emerge or amplify through their\ninteractionswhether direct or indirect via shared environmentswith each other,\nhumans, and institutions, and characterize fundamental security-performance\ntrade-offs. Our preliminary work (1) taxonomizes the threat landscape arising\nfrom interacting AI agents, (2) surveys security-performance tradeoffs in\ndecentralized AI systems, and (3) proposes a unified research agenda addressing\nopen challenges in designing secure agent systems and interaction environments.\nBy identifying these gaps, we aim to guide research in this critical area to\nunlock the socioeconomic potential of large-scale agent deployment on the\ninternet, foster public trust, and mitigate national security risks in critical\ninfrastructure and defense contexts.",
      "tldr_zh": "该论文探讨了去中心化 AI 代理在互联网平台上互动所带来的新安全挑战，这些挑战超出了传统 cybersecurity 和 AI safety 框架，包括秘密 collusion、协调 swarm attacks 以及网络效应导致的隐私泄露和数据 poisoning。作者引入了多-agent security 这一新领域，通过分类威胁景观、调查 decentralized AI 系统中的安全-性能 trade-offs，并提出统一的 research agenda，以应对这些互动引发的持久威胁。最终，该工作旨在指导研究，推动大规模 AI 代理部署的经济潜力、增强公共信任，并缓解国家安全风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02077v1",
      "published_date": "2025-05-04 12:03:29 UTC",
      "updated_date": "2025-05-04 12:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:34:01.530066"
    },
    {
      "arxiv_id": "2505.02076v1",
      "title": "Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants",
      "title_zh": "利用 LLM 代理和数字孪生进行过程工厂的故障处理",
      "authors": [
        "Milapji Singh Gill",
        "Javal Vyas",
        "Artan Markaj",
        "Felix Gehlhoff",
        "Mehmet Mercangöz"
      ],
      "abstract": "Advances in Automation and Artificial Intelligence continue to enhance the\nautonomy of process plants in handling various operational scenarios. However,\ncertain tasks, such as fault handling, remain challenging, as they rely heavily\non human expertise. This highlights the need for systematic, knowledge-based\nmethods. To address this gap, we propose a methodological framework that\nintegrates Large Language Model (LLM) agents with a Digital Twin environment.\nThe LLM agents continuously interpret system states and initiate control\nactions, including responses to unexpected faults, with the goal of returning\nthe system to normal operation. In this context, the Digital Twin acts both as\na structured repository of plant-specific engineering knowledge for agent\nprompting and as a simulation platform for the systematic validation and\nverification of the generated corrective control actions. The evaluation using\na mixing module of a process plant demonstrates that the proposed framework is\ncapable not only of autonomously controlling the mixing module, but also of\ngenerating effective corrective actions to mitigate a pipe clogging with only a\nfew reprompts.",
      "tldr_zh": "该研究提出了一种方法框架，将LLM agents与Digital Twin环境整合，用于处理过程工厂中的故障问题，以减少对人类专家的依赖。LLM agents持续监控和解释系统状态，并生成控制动作来应对意外故障，而Digital Twin则作为知识库提供工程信息并模拟验证这些动作。在针对过程工厂混合模块的评估中，该框架不仅实现了自主控制，还能有效缓解管道堵塞等故障，仅需少量重新提示，从而提升了过程工厂的可靠性和自治性。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02076v1",
      "published_date": "2025-05-04 12:02:21 UTC",
      "updated_date": "2025-05-04 12:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:34:11.794618"
    },
    {
      "arxiv_id": "2505.02075v1",
      "title": "Benchmarking Feature Upsampling Methods for Vision Foundation Models using Interactive Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Volodymyr Havrylov",
        "Haiwen Huang",
        "Dan Zhang",
        "Andreas Geiger"
      ],
      "abstract": "Vision Foundation Models (VFMs) are large-scale, pre-trained models that\nserve as general-purpose backbones for various computer vision tasks. As VFMs'\npopularity grows, there is an increasing interest in understanding their\neffectiveness for dense prediction tasks. However, VFMs typically produce\nlow-resolution features, limiting their direct applicability in this context.\nOne way to tackle this limitation is by employing a task-agnostic feature\nupsampling module that refines VFM features resolution. To assess the\neffectiveness of this approach, we investigate Interactive Segmentation (IS) as\na novel benchmark for evaluating feature upsampling methods on VFMs. Due to its\ninherent multimodal input, consisting of an image and a set of user-defined\nclicks, as well as its dense mask output, IS creates a challenging environment\nthat demands comprehensive visual scene understanding. Our benchmarking\nexperiments show that selecting appropriate upsampling strategies significantly\nimproves VFM features quality. The code is released at\nhttps://github.com/havrylovv/iSegProbe",
      "tldr_zh": "该论文评估了特征上采样方法，以提升 Vision Foundation Models (VFMs) 在密集预测任务中的性能，因为 VFMs 通常输出低分辨率特征。作者使用 Interactive Segmentation (IS) 作为新基准，该任务涉及图像和用户点击的多模态输入，以及密集掩码输出，从而测试上采样策略的全面性。实验结果显示，选择合适的上采样方法可显著改善 VFM 特征质量，并为相关研究提供开源代码（https://github.com/havrylovv/iSegProbe）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02075v1",
      "published_date": "2025-05-04 11:59:26 UTC",
      "updated_date": "2025-05-04 11:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:34:25.469127"
    },
    {
      "arxiv_id": "2505.02073v1",
      "title": "Lightweight Defense Against Adversarial Attacks in Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Han"
      ],
      "abstract": "As time series classification (TSC) gains prominence, ensuring robust TSC\nmodels against adversarial attacks is crucial. While adversarial defense is\nwell-studied in Computer Vision (CV), the TSC field has primarily relied on\nadversarial training (AT), which is computationally expensive. In this paper,\nfive data augmentation-based defense methods tailored for time series are\ndeveloped, with the most computationally intensive method among them increasing\nthe computational resources by only 14.07% compared to the original TSC model.\nMoreover, the deployment process for these methods is straightforward. By\nleveraging these advantages of our methods, we create two combined methods. One\nof these methods is an ensemble of all the proposed techniques, which not only\nprovides better defense performance than PGD-based AT but also enhances the\ngeneralization ability of TSC models. Moreover, the computational resources\nrequired for our ensemble are less than one-third of those required for\nPGD-based AT. These methods advance robust TSC in data mining. Furthermore, as\nfoundation models are increasingly explored for time series feature learning,\nour work provides insights into integrating data augmentation-based adversarial\ndefense with large-scale pre-trained models in future research.",
      "tldr_zh": "本文针对时间序列分类(TSC)模型对抗攻击的防御问题，开发了五种基于数据增强的方法，这些方法计算资源消耗低，仅增加最多14.07%的资源，且部署简单。作者进一步结合这些技术创建了两种组合方法，其中一个集成(ensemble)策略不仅在防御性能上优于PGD-based Adversarial Training (AT)，还提升了TSC模型的泛化能力，且所需计算资源不到AT的三分之一。这些方法显著推进了鲁棒TSC在数据挖掘中的应用，并为未来将数据增强防御与大规模预训练模型集成提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 62H30",
        "I.2.6; I.5.1; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 8 figures. Accepted at RAFDA Workshop, PAKDD 2025\n  (Springer, EI & Scopus indexed). Code:\n  https://github.com/Yi126/Lightweight-Defence",
      "pdf_url": "http://arxiv.org/pdf/2505.02073v1",
      "published_date": "2025-05-04 11:51:09 UTC",
      "updated_date": "2025-05-04 11:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:34:38.947298"
    },
    {
      "arxiv_id": "2505.02072v1",
      "title": "What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Eitan Wagner",
        "Omri Abend"
      ],
      "abstract": "The notion of language modeling has gradually shifted in recent years from a\ndistribution over finite-length strings to general-purpose prediction models\nfor textual inputs and outputs, following appropriate alignment phases. This\npaper analyzes the distinction between distribution estimation and response\nprediction in the context of LLMs, and their often conflicting goals. We\nexamine the training phases of LLMs, which include pretraining, in-context\nlearning, and preference tuning, and also the common use cases for their output\nprobabilities, which include completion probabilities and explicit\nprobabilities as output. We argue that the different settings lead to three\ndistinct intended output distributions. We demonstrate that NLP works often\nassume that these distributions should be similar, which leads to\nmisinterpretations of their experimental findings. Our work sets firmer formal\nfoundations for the interpretation of LLMs, which will inform ongoing work on\nthe interpretation and use of LLMs' induced distributions.",
      "tldr_zh": "这篇论文探讨了语言模型（LLMs）的概率表示，从传统的分布估计转向响应预测，并分析了二者可能冲突的目标。作者考察了LLMs的训练阶段，包括预训练、在上下文学习和偏好调整，以及输出概率的常见应用，如完成概率和显式概率输出，论证这些设置导致三种不同的预期输出分布。论文指出，NLP研究中常假设这些分布相似，从而导致实验发现的误解，并为LLMs的解释提供更坚实的正式基础，以指导未来工作。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02072v1",
      "published_date": "2025-05-04 11:46:48 UTC",
      "updated_date": "2025-05-04 11:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:34:48.101528"
    },
    {
      "arxiv_id": "2505.06261v1",
      "title": "Modeling supply chain compliance response strategies based on AI synthetic data with structural path regression: A Simulation Study of EU 2027 Mandatory Labor Regulations",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Meng"
      ],
      "abstract": "In the context of the new mandatory labor compliance in the European Union\n(EU), which will be implemented in 2027, supply chain enterprises face\nstringent working hour management requirements and compliance risks. In order\nto scientifically predict the enterprises' coping behaviors and performance\noutcomes under the policy impact, this paper constructs a methodological\nframework that integrates the AI synthetic data generation mechanism and\nstructural path regression modeling to simulate the enterprises' strategic\ntransition paths under the new regulations. In terms of research methodology,\nthis paper adopts high-quality simulation data generated based on Monte Carlo\nmechanism and NIST synthetic data standards to construct a structural path\nanalysis model that includes multiple linear regression, logistic regression,\nmediation effect and moderating effect. The variable system covers 14\nindicators such as enterprise working hours, compliance investment, response\nspeed, automation level, policy dependence, etc. The variable set with\nexplanatory power is screened out through exploratory data analysis (EDA) and\nVIF multicollinearity elimination. The findings show that compliance investment\nhas a significant positive impact on firm survival and its effect is\ntransmitted through the mediating path of the level of intelligence; meanwhile,\nfirms' dependence on the EU market significantly moderates the strength of this\nmediating effect. It is concluded that AI synthetic data combined with\nstructural path modeling provides an effective tool for high-intensity\nregulatory simulation, which can provide a quantitative basis for corporate\nstrategic response, policy design and AI-assisted decision-making in the\npre-prediction stage lacking real scenario data. Keywords: AI synthetic data,\nstructural path regression modeling, compliance response strategy, EU 2027\nmandatory labor regulation",
      "tldr_zh": "本研究针对欧盟2027强制劳动法规对供应链企业的影响，构建了一个整合AI synthetic data生成机制和structural path regression建模的方法框架，利用Monte Carlo机制和NIST标准生成模拟数据，并通过多元线性回归、逻辑回归、中介效应和调节效应分析14个指标（如合规投资、自动化水平）。结果显示，合规投资对企业生存率有显著正向影响，该效应通过智能化水平的中介路径传递，且企业对欧盟市场的依赖会显著调节这一中介强度。总之，该框架为合规响应策略、政策设计和AI辅助决策提供了有效的量化模拟工具，尤其适用于真实数据缺失的预预测阶段。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "stat.AP",
        "90B06 (Primary) 62J05, 91B74 (Secondary)",
        "I.6.3; I.2.6; J.1"
      ],
      "primary_category": "cs.CY",
      "comment": "Simulated data modeling of the impact of non-tariff barriers in trade\n  wars",
      "pdf_url": "http://arxiv.org/pdf/2505.06261v1",
      "published_date": "2025-05-04 11:39:56 UTC",
      "updated_date": "2025-05-04 11:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:35:02.496171"
    },
    {
      "arxiv_id": "2505.02062v1",
      "title": "Ethical AI in the Healthcare Sector: Investigating Key Drivers of Adoption through the Multi-Dimensional Ethical AI Adoption Model (MEAAM)",
      "title_zh": "医疗保健领域的伦理AI：通过多维伦理AI采用模型 (MEAAM) 调查采用的关键驱动因素",
      "authors": [
        "Prathamesh Muzumdar",
        "Apoorva Muley",
        "Kuldeep Singh",
        "Sumanth Cheemalapati"
      ],
      "abstract": "The adoption of Artificial Intelligence (AI) in the healthcare service\nindustry presents numerous ethical challenges, yet current frameworks often\nfail to offer a comprehensive, empirical understanding of the multidimensional\nfactors influencing ethical AI integration. Addressing this critical research\ngap, this study introduces the Multi-Dimensional Ethical AI Adoption Model\n(MEAAM), a novel theoretical framework that categorizes 13 critical ethical\nvariables across four foundational dimensions of Ethical AI Fair AI,\nResponsible AI, Explainable AI, and Sustainable AI. These dimensions are\nfurther analyzed through three core ethical lenses: epistemic concerns (related\nto knowledge, transparency, and system trustworthiness), normative concerns\n(focused on justice, autonomy, dignity, and moral obligations), and overarching\nconcerns (highlighting global, systemic, and long-term ethical implications).\nThis study adopts a quantitative, cross-sectional research design using survey\ndata collected from healthcare professionals and analyzed via Partial Least\nSquares Structural Equation Modeling (PLS-SEM). Employing PLS-SEM, this study\nempirically investigates the influence of these ethical constructs on two\noutcomes Operational AI Adoption and Systemic AI Adoption. Results indicate\nthat normative concerns most significantly drive operational adoption\ndecisions, while overarching concerns predominantly shape systemic adoption\nstrategies and governance frameworks. Epistemic concerns play a facilitative\nrole, enhancing the impact of ethical design principles on trust and\ntransparency in AI systems. By validating the MEAAM framework, this research\nadvances a holistic, actionable approach to ethical AI adoption in healthcare\nand provides critical insights for policymakers, technologists, and healthcare\nadministrators striving to implement ethically grounded AI solutions.",
      "tldr_zh": "这篇论文引入了Multi-Dimensional Ethical AI Adoption Model (MEAAM)，一个新颖的理论框架，将13个关键伦理变量分类到Ethical AI、Responsible AI、Explainable AI和Sustainable AI四个维度，并通过epistemic concerns、normative concerns和overarching concerns三个视角进行分析。研究采用量化横断面设计，通过对医疗专业人员的调查数据应用Partial Least Squares Structural Equation Modeling (PLS-SEM)，考察这些伦理因素对Operational AI Adoption和Systemic AI Adoption的影响。结果表明，normative concerns最显著驱动操作性AI采用，overarching concerns主导系统性采用策略，而epistemic concerns增强了AI系统的信任和透明度，为医疗领域的伦理AI实施提供了一个整体、可操作的指导框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02062v1",
      "published_date": "2025-05-04 10:40:05 UTC",
      "updated_date": "2025-05-04 10:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:35:17.211211"
    },
    {
      "arxiv_id": "2505.02052v1",
      "title": "TxP: Reciprocal Generation of Ground Pressure Dynamics and Activity Descriptions for Improving Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Lala Shakti Swarup Ray",
        "Lars Krupp",
        "Vitor Fortes Rey",
        "Bo Zhou",
        "Sungho Suh",
        "Paul Lukowicz"
      ],
      "abstract": "Sensor-based human activity recognition (HAR) has predominantly focused on\nInertial Measurement Units and vision data, often overlooking the capabilities\nunique to pressure sensors, which capture subtle body dynamics and shifts in\nthe center of mass. Despite their potential for postural and balance-based\nactivities, pressure sensors remain underutilized in the HAR domain due to\nlimited datasets. To bridge this gap, we propose to exploit generative\nfoundation models with pressure-specific HAR techniques. Specifically, we\npresent a bidirectional Text$\\times$Pressure model that uses generative\nfoundation models to interpret pressure data as natural language. TxP\naccomplishes two tasks: (1) Text2Pressure, converting activity text\ndescriptions into pressure sequences, and (2) Pressure2Text, generating\nactivity descriptions and classifications from dynamic pressure maps.\nLeveraging pre-trained models like CLIP and LLaMA 2 13B Chat, TxP is trained on\nour synthetic PressLang dataset, containing over 81,100 text-pressure pairs.\nValidated on real-world data for activities such as yoga and daily tasks, TxP\nprovides novel approaches to data augmentation and classification grounded in\natomic actions. This consequently improved HAR performance by up to 12.4\\% in\nmacro F1 score compared to the state-of-the-art, advancing pressure-based HAR\nwith broader applications and deeper insights into human movement.",
      "tldr_zh": "该论文提出 TxP 模型，通过双向生成技术（Text2Pressure 和 Pressure2Text）来提升基于压力传感器的 Human Activity Recognition (HAR)。TxP 利用生成式基础模型如 CLIP 和 LLaMA 2 13B Chat，将活动文本描述转换为压力序列，或从动态压力地图生成活动描述和分类，从而解决压力传感器数据有限的问题。模型在合成数据集 PressLang（包含超过 81,100 个文本-压力对）上训练，并在真实世界数据（如瑜伽和日常任务）上验证。结果显示，TxP 通过数据增强和基于原子动作的分类方法，提高了 HAR 性能，宏 F1 score 比现有最佳方法提升高达 12.4%。这为压力-based HAR 提供了更广泛的应用和对人类运动的深入洞察。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02052v1",
      "published_date": "2025-05-04 10:07:38 UTC",
      "updated_date": "2025-05-04 10:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:35:28.742283"
    },
    {
      "arxiv_id": "2505.02050v1",
      "title": "Enhancing Safety Standards in Automated Systems Using Dynamic Bayesian Networks",
      "title_zh": "使用动态贝叶斯网络增强自动化系统中的安全标准",
      "authors": [
        "Kranthi Kumar Talluri",
        "Anders L. Madsen",
        "Galia Weidl"
      ],
      "abstract": "Cut-in maneuvers in high-speed traffic pose critical challenges that can lead\nto abrupt braking and collisions, necessitating safe and efficient lane change\nstrategies. We propose a Dynamic Bayesian Network (DBN) framework to integrate\nlateral evidence with safety assessment models, thereby predicting lane changes\nand ensuring safe cut-in maneuvers effectively. Our proposed framework\ncomprises three key probabilistic hypotheses (lateral evidence, lateral safety,\nand longitudinal safety) that facilitate the decision-making process through\ndynamic data processing and assessments of vehicle positions, lateral\nvelocities, relative distance, and Time-to-Collision (TTC) computations. The\nDBN model's performance compared with other conventional approaches\ndemonstrates superior performance in crash reduction, especially in critical\nhigh-speed scenarios, while maintaining a competitive performance in low-speed\nscenarios. This paves the way for robust, scalable, and efficient safety\nvalidation in automated driving systems.",
      "tldr_zh": "这篇论文针对高速交通中Cut-in maneuvers导致的潜在碰撞风险，提出了一种使用Dynamic Bayesian Networks (DBN)框架来提升自动系统安全标准的方法。该框架整合横向证据、横向安全和纵向安全等概率假设，通过动态数据处理评估车辆位置、横向速度、相对距离和Time-to-Collision (TTC)，从而实现有效的车道变更预测和安全决策。与传统方法相比，DBN模型在高速度场景下显著减少碰撞，并在低速度场景中保持竞争力，为自动驾驶系统的稳健、可扩展安全验证铺平道路。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02050v1",
      "published_date": "2025-05-04 09:58:02 UTC",
      "updated_date": "2025-05-04 09:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:35:40.063122"
    },
    {
      "arxiv_id": "2505.02048v2",
      "title": "Regression is all you need for medical image translation",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian Rassmann",
        "David Kügler",
        "Christian Ewert",
        "Martin Reuter"
      ],
      "abstract": "The acquisition of information-rich images within a limited time budget is\ncrucial in medical imaging. Medical image translation (MIT) can help enhance\nand supplement existing datasets by generating synthetic images from acquired\ndata. While Generative Adversarial Nets (GANs) and Diffusion Models (DMs) have\nachieved remarkable success in natural image generation, their benefits -\ncreativity and image realism - do not necessarily transfer to medical\napplications where highly accurate anatomical information is required. In fact,\nthe imitation of acquisition noise or content hallucination hinder clinical\nutility. Here, we introduce YODA (You Only Denoise once - or Average), a novel\n2.5D diffusion-based framework for volumetric MIT. YODA unites diffusion and\nregression paradigms to produce realistic or noise-free outputs. Furthermore,\nwe propose Expectation-Approximation (ExpA) DM sampling, which draws\ninspiration from MRI signal averaging. ExpA-sampling suppresses generated noise\nand, thus, eliminates noise from biasing the evaluation of image quality.\nThrough extensive experiments on four diverse multi-modal datasets - comprising\nmulti-contrast brain MRI and pelvic MRI-CT - we show that diffusion and\nregression sampling yield similar results in practice. As such, the\ncomputational overhead of diffusion sampling does not provide systematic\nbenefits in medical information translation. Building on these insights, we\ndemonstrate that YODA outperforms several state-of-the-art GAN and DM methods.\nNotably, YODA-generated images are shown to be interchangeable with, or even\nsuperior to, physical acquisitions for several downstream tasks. Our findings\nchallenge the presumed advantages of DMs in MIT and pave the way for the\npractical application of MIT in medical imaging.",
      "tldr_zh": "这篇论文提出 YODA（You Only Denoise once - or Average），一种新型的 2.5D 扩散-based 框架，用于医疗图像翻译（MIT），旨在通过结合扩散和回归范式生成真实或无噪声的图像，从而克服 GANs 和 Diffusion Models (DMs) 在医疗应用中可能引入的噪声和内容幻觉问题。论文还引入 Expectation-Approximation (ExpA) DM sampling 方法，灵感来源于 MRI 信号平均，抑制生成噪声并提升图像质量评估的准确性。在四个多模态数据集（如脑 MRI 和盆腔 MRI-CT）的实验中，YODA 优于现有 GAN 和 DM 方法，其生成的图像在下游任务中可与物理采集互换甚至更优，并挑战了 DMs 在 MIT 中的计算优势，为医疗成像的实际应用铺平道路。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02048v2",
      "published_date": "2025-05-04 09:57:10 UTC",
      "updated_date": "2025-05-06 05:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:35:53.894168"
    },
    {
      "arxiv_id": "2505.02027v1",
      "title": "GraphPrompter: Multi-stage Adaptive Prompt Optimization for Graph In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Lv",
        "Zaixi Zhang",
        "Kai Zhang",
        "Qi Liu",
        "Weibo Gao",
        "Jiawei Liu",
        "Jiaxia Yan",
        "Linan Yue",
        "Fangzhou Yao"
      ],
      "abstract": "Graph In-Context Learning, with the ability to adapt pre-trained graph models\nto novel and diverse downstream graphs without updating any parameters, has\ngained much attention in the community. The key to graph in-context learning is\nto perform downstream graphs conditioned on chosen prompt examples. Existing\nmethods randomly select subgraphs or edges as prompts, leading to noisy graph\nprompts and inferior model performance. Additionally, due to the gap between\npre-training and testing graphs, when the number of classes in the testing\ngraphs is much greater than that in the training, the in-context learning\nability will also significantly deteriorate. To tackle the aforementioned\nchallenges, we develop a multi-stage adaptive prompt optimization method\nGraphPrompter, which optimizes the entire process of generating, selecting, and\nusing graph prompts for better in-context learning capabilities. Firstly,\nPrompt Generator introduces a reconstruction layer to highlight the most\ninformative edges and reduce irrelevant noise for graph prompt construction.\nFurthermore, in the selection stage, Prompt Selector employs the $k$-nearest\nneighbors algorithm and pre-trained selection layers to dynamically choose\nappropriate samples and minimize the influence of irrelevant prompts. Finally,\nwe leverage a Prompt Augmenter with a cache replacement strategy to enhance the\ngeneralization capability of the pre-trained model on new datasets. Extensive\nexperiments show that GraphPrompter effectively enhances the in-context\nlearning ability of graph models. On average across all the settings, our\napproach surpasses the state-of-the-art baselines by over 8%. Our code is\nreleased at https://github.com/karin0018/GraphPrompter.",
      "tldr_zh": "本文提出 GraphPrompter，一种多阶段自适应提示优化方法，旨在解决 Graph In-Context Learning 中提示生成噪声和类别数增加导致的性能下降问题。该方法包括 Prompt Generator 使用重建层突出关键边减少噪声、Prompt Selector 采用 k-nearest neighbors 算法动态选择相关样本，以及 Prompt Augmenter 通过缓存替换策略提升模型在新数据集上的泛化能力。实验结果显示，GraphPrompter 在各种设置下平均超过最先进基线方法 8% 的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages. IEEE International Conference on Data Engineering\n  (ICDE'2025), accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.02027v1",
      "published_date": "2025-05-04 08:30:00 UTC",
      "updated_date": "2025-05-04 08:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:36:03.781883"
    },
    {
      "arxiv_id": "2505.02024v1",
      "title": "From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Minjie Shen",
        "Qikai Yang"
      ],
      "abstract": "Manus AI is a general-purpose AI agent introduced in early 2025, marking a\nsignificant advancement in autonomous artificial intelligence. Developed by the\nChinese startup Monica.im, Manus is designed to bridge the gap between \"mind\"\nand \"hand\" - combining the reasoning and planning capabilities of large\nlanguage models with the ability to execute complex, end-to-end tasks that\nproduce tangible outcomes. This paper presents a comprehensive overview of\nManus AI, exploring its core technical architecture, diverse applications\nacross sectors such as healthcare, finance, manufacturing, robotics, and\ngaming, as well as its key strengths, current limitations, and future\npotential. Positioned as a preview of what lies ahead, Manus AI represents a\nshift toward intelligent agents that can translate high-level intentions into\nreal-world actions, heralding a new era of human-AI collaboration.",
      "tldr_zh": "这篇论文介绍了 Manus AI，一种在 2025 年由 Monica.im 开发的通用 AI 代理，它将大型语言模型的推理和规划能力与执行复杂任务相结合，实现从高阶意图到实际行动的端到端转化。\nManus AI 的核心技术架构涵盖了其在医疗、金融、制造、机器人和游戏等领域的多样应用，展示了其优势如提升人类-AI 协作，同时也讨论了当前局限性。\n总体而言，该代理标志着 AI 发展的新时代，具有巨大的未来潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02024v1",
      "published_date": "2025-05-04 08:24:00 UTC",
      "updated_date": "2025-05-04 08:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:36:15.371214"
    },
    {
      "arxiv_id": "2505.02020v1",
      "title": "Wide & Deep Learning for Node Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yancheng Chen",
        "Wenguo Yang",
        "Zhipeng Jiang"
      ],
      "abstract": "Wide & Deep, a simple yet effective learning architecture for recommendation\nsystems developed by Google, has had a significant impact in both academia and\nindustry due to its combination of the memorization ability of generalized\nlinear models and the generalization ability of deep models. Graph\nconvolutional networks (GCNs) remain dominant in node classification tasks;\nhowever, recent studies have highlighted issues such as heterophily and\nexpressiveness, which focus on graph structure while seemingly neglecting the\npotential role of node features. In this paper, we propose a flexible framework\nGCNIII, which leverages the Wide & Deep architecture and incorporates three\ntechniques: Intersect memory, Initial residual and Identity mapping. We provide\ncomprehensive empirical evidence showing that GCNIII can more effectively\nbalance the trade-off between over-fitting and over-generalization on various\nsemi- and full- supervised tasks. Additionally, we explore the use of large\nlanguage models (LLMs) for node feature engineering to enhance the performance\nof GCNIII in cross-domain node classification tasks. Our implementation is\navailable at https://github.com/CYCUCAS/GCNIII.",
      "tldr_zh": "本论文提出 GCNIII 框架，将 Google 的 Wide & Deep 架构应用于节点分类任务，结合广义线性模型的记忆能力和深度模型的泛化能力，以解决图卷积网络 (GCNs) 在异质性和表达性方面的局限性。框架整合了三个关键技术：Intersect memory、Initial residual 和 Identity mapping，从而更有效地平衡过拟合和过泛化，在各种半监督和全监督任务中表现出色。实验结果显示，GCNIII 显著提升了性能，并在使用大型语言模型 (LLMs) 进行节点特征工程后，进一步改善了跨域节点分类的准确率。该框架的开源实现可从 GitHub 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures, 13 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.02020v1",
      "published_date": "2025-05-04 07:53:16 UTC",
      "updated_date": "2025-05-04 07:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:36:27.146075"
    },
    {
      "arxiv_id": "2505.02011v1",
      "title": "CASA: CNN Autoencoder-based Score Attention for Efficient Multivariate Long-term Time-series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Minhyuk Lee",
        "HyeKyung Yoon",
        "MyungJoo Kang"
      ],
      "abstract": "Multivariate long-term time series forecasting is critical for applications\nsuch as weather prediction, and traffic analysis. In addition, the\nimplementation of Transformer variants has improved prediction accuracy.\nFollowing these variants, different input data process approaches also enhanced\nthe field, such as tokenization techniques including point-wise, channel-wise,\nand patch-wise tokenization. However, previous studies still have limitations\nin time complexity, computational resources, and cross-dimensional\ninteractions. To address these limitations, we introduce a novel CNN\nAutoencoder-based Score Attention mechanism (CASA), which can be introduced in\ndiverse Transformers model-agnosticically by reducing memory and leading to\nimprovement in model performance. Experiments on eight real-world datasets\nvalidate that CASA decreases computational resources by up to 77.7%,\naccelerates inference by 44.0%, and achieves state-of-the-art performance,\nranking first in 87.5% of evaluated metrics.",
      "tldr_zh": "该论文针对多变量长期时间序列预测（如天气和交通分析）中的时间复杂度、计算资源和跨维度交互问题，提出了一种新型机制CASA（CNN Autoencoder-based Score Attention）。CASA通过整合CNN Autoencoder和Score Attention，能够模型无关地嵌入各种Transformer模型中，显著减少内存使用并提升预测性能。在八个真实世界数据集上的实验验证，CASA降低了77.7%的计算资源，加速了44.0%的推理过程，并在87.5%的评估指标中实现最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02011v1",
      "published_date": "2025-05-04 06:46:21 UTC",
      "updated_date": "2025-05-04 06:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:36:39.382749"
    },
    {
      "arxiv_id": "2505.02003v1",
      "title": "Closed-loop control of seizure activity via real-time seizure forecasting by reservoir neuromorphic computing",
      "title_zh": "翻译失败",
      "authors": [
        "Maryam Sadeghi",
        "Darío Fernández Khatiboun",
        "Yasser Rezaeiyan",
        "Saima Rizwan",
        "Alessandro Barcellona",
        "Andrea Merello",
        "Marco Crepaldi",
        "Gabriella Panuccio",
        "Farshad Moradi"
      ],
      "abstract": "Closed-loop brain stimulation holds potential as personalized treatment for\ndrug-resistant epilepsy (DRE) but still suffers from limitations that result in\nhighly variable efficacy. First, stimulation is typically delivered upon\ndetection of the seizure to abort rather than prevent it; second, the\nstimulation parameters are established by trial and error, requiring lengthy\nrounds of fine-tuning, which delay steady-state therapeutic efficacy. Here, we\naddress these limitations by leveraging the potential of neuromorphic\ncomputing. We present a system capable of driving personalized free-run\nstimulations based on seizure forecasting, wherein each forecast triggers an\nelectrical pulse rather than an arbitrarily predefined fixed-frequency stimulus\ntrain. We validate the system against hippocampal spheroids coupled to 3D\nmicroelectrode array as a simplified testbed, showing that it can achieve\nseizure reduction >97% while primarily using instantaneous stimulation\nfrequencies within 20 Hz, well below what typically used in clinical settings.\nOur work demonstrates the potential of neuromorphic systems as a\nnext-generation neuromodulation strategy for personalized DRE treatment.",
      "tldr_zh": "本研究提出了一种基于reservoir neuromorphic computing的闭环控制系统，通过实时癫痫发作预测，实现个性化自由运行刺激，每次预测触发一个电脉冲，而不是固定频率刺激，从而解决传统脑刺激的局限性，如仅在发作后干预和参数调整耗时。实验在海马体球体和3D微电极阵列的简化测试台上验证，该系统将癫痫发作减少超过97%，并主要使用20Hz以下的瞬时刺激频率，远低于临床标准。该方法展示了神经形态计算作为下一代个性化耐药性癫痫（DRE）治疗策略的巨大潜力。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02003v1",
      "published_date": "2025-05-04 06:17:23 UTC",
      "updated_date": "2025-05-04 06:17:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:36:52.059782"
    },
    {
      "arxiv_id": "2505.01998v2",
      "title": "A Synergistic Framework of Nonlinear Acoustic Computing and Reinforcement Learning for Real-World Human-Robot Interaction",
      "title_zh": "非线性声学计算与强化",
      "authors": [
        "Xiaoliang Chen",
        "Xin Yu",
        "Le Chang",
        "Yunhe Huang",
        "Jiashuai He",
        "Shibo Zhang",
        "Jin Li",
        "Likai Lin",
        "Ziyu Zeng",
        "Xianling Tu",
        "Shuyu Zhang"
      ],
      "abstract": "This paper introduces a novel framework integrating nonlinear acoustic\ncomputing and reinforcement learning to enhance advanced human-robot\ninteraction under complex noise and reverberation. Leveraging physically\ninformed wave equations (e.g., Westervelt, KZK), the approach captures\nhigher-order phenomena such as harmonic generation and shock formation. By\nembedding these models in a reinforcement learning-driven control loop, the\nsystem adaptively optimizes key parameters (e.g., absorption, beamforming) to\nmitigate multipath interference and non-stationary noise. Experimental\nevaluations, covering far-field localization, weak signal detection, and\nmultilingual speech recognition, demonstrate that this hybrid strategy\nsurpasses traditional linear methods and purely data-driven baselines,\nachieving superior noise suppression, minimal latency, and robust accuracy in\ndemanding real-world scenarios. The proposed system demonstrates broad\napplication prospects in AI hardware, robot, machine audition, artificial\naudition, and brain-machine interfaces.",
      "tldr_zh": "这篇论文提出了一种整合非线性声学计算和强化学习的协同框架，用于提升复杂噪声和混响环境下的真实人机交互。框架利用物理信息波方程（如 Westervelt 和 KZK）捕捉高阶现象，包括谐波生成和冲击形成，并通过强化学习驱动的控制循环优化参数（如吸收和 beamforming），以减少多路径干扰和非平稳噪声。实验评估显示，该方法在远场 localization、弱信号检测和多语言语音识别方面，超越传统线性方法和纯数据驱动基线，实现了更好的噪声抑制、最小延迟和鲁棒准确性。该框架在 AI 硬件、机器人、机器听觉、人工听觉和脑机接口等领域具有广阔应用前景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "physics.app-ph",
        "68T01",
        "I.2.8"
      ],
      "primary_category": "cs.RO",
      "comment": "34 pages, 11 figures, 10 tables, and 10 equations",
      "pdf_url": "http://arxiv.org/pdf/2505.01998v2",
      "published_date": "2025-05-04 06:03:12 UTC",
      "updated_date": "2025-05-06 16:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:37:05.028974"
    },
    {
      "arxiv_id": "2505.01997v1",
      "title": "Restoring Calibration for Aligned Large Language Models: A Calibration-Aware Fine-Tuning Approach",
      "title_zh": "恢复对齐的大型语言模型的校准：一种校准感知的微调方法",
      "authors": [
        "Jiancong Xiao",
        "Bojian Hou",
        "Zhanliang Wang",
        "Ruochen Jin",
        "Qi Long",
        "Weijie J. Su",
        "Li Shen"
      ],
      "abstract": "One of the key technologies for the success of Large Language Models (LLMs)\nis preference alignment. However, a notable side effect of preference alignment\nis poor calibration: while the pre-trained models are typically\nwell-calibrated, LLMs tend to become poorly calibrated after alignment with\nhuman preferences. In this paper, we investigate why preference alignment\naffects calibration and how to address this issue. For the first question, we\nobserve that the preference collapse issue in alignment undesirably generalizes\nto the calibration scenario, causing LLMs to exhibit overconfidence and poor\ncalibration. To address this, we demonstrate the importance of fine-tuning with\ndomain-specific knowledge to alleviate the overconfidence issue. To further\nanalyze whether this affects the model's performance, we categorize models into\ntwo regimes: calibratable and non-calibratable, defined by bounds of Expected\nCalibration Error (ECE). In the calibratable regime, we propose a\ncalibration-aware fine-tuning approach to achieve proper calibration without\ncompromising LLMs' performance. However, as models are further fine-tuned for\nbetter performance, they enter the non-calibratable regime. For this case, we\ndevelop an EM-algorithm-based ECE regularization for the fine-tuning loss to\nmaintain low calibration error. Extensive experiments validate the\neffectiveness of the proposed methods.",
      "tldr_zh": "该论文探讨了偏好对齐(preference alignment)如何导致大型语言模型(LLMs)的校准(calibration)变差，主要是由于偏好坍缩(preference collapse)引起的模型过度自信问题。研究者通过使用领域特定知识进行微调，缓解了这一问题，并将模型分类为可校准(calibratable)和不可校准(non-calibratable)两种类型。针对可校准模型，他们提出了一种校准感知微调(calibration-aware fine-tuning)方法，以实现适当的校准而不影响性能；针对不可校准模型，则开发了基于 EM 算法的 ECE 正则化(EM-algorithm-based ECE regularization)来保持低校准错误。广泛实验验证了这些方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01997v1",
      "published_date": "2025-05-04 05:42:51 UTC",
      "updated_date": "2025-05-04 05:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:37:21.185172"
    },
    {
      "arxiv_id": "2505.01967v1",
      "title": "Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview",
      "title_zh": "翻译失败",
      "authors": [
        "Jiatao Li",
        "Yanheng Li",
        "Xiaojun Wan"
      ],
      "abstract": "Large Language Models (LLMs) have become integral to daily life, widely\nadopted in communication, decision-making, and information retrieval, raising\ncritical questions about how these systems implicitly form and express\nsocio-cognitive attitudes or \"worldviews\". While existing research extensively\naddresses demographic and ethical biases, broader dimensions-such as attitudes\ntoward authority, equality, autonomy, and fate-remain under-explored. In this\npaper, we introduce the Social Worldview Taxonomy (SWT), a structured framework\ngrounded in Cultural Theory, operationalizing four canonical worldviews\n(Hierarchy, Egalitarianism, Individualism, Fatalism) into measurable\nsub-dimensions. Using SWT, we empirically identify distinct and interpretable\ncognitive profiles across 28 diverse LLMs. Further, inspired by Social\nReferencing Theory, we experimentally demonstrate that explicit social cues\nsystematically shape these cognitive attitudes, revealing both general response\npatterns and nuanced model-specific variations. Our findings enhance the\ninterpretability of LLMs by revealing implicit socio-cognitive biases and their\nresponsiveness to social feedback, thus guiding the development of more\ntransparent and socially responsible language technologies.",
      "tldr_zh": "本研究引入了 Social Worldview Taxonomy (SWT)，一个基于 Cultural Theory 的框架，用于分析大型语言模型 (LLMs) 在社会认知方面（如 Hierarchy、Egalitarianism、Individualism 和 Fatalism）的差异。研究者通过 SWT 对 28 个不同 LLMs 进行实证分析，识别出各模型的独特认知配置文件，并实验验证了社会线索（受 Social Referencing Theory 启发）如何系统性地塑造这些认知态度，揭示一般模式和模型特异性变化。这些发现提升了 LLMs 的可解释性，暴露了隐含的社会认知偏差，并为开发更透明和负责任的语言技术提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01967v1",
      "published_date": "2025-05-04 02:35:24 UTC",
      "updated_date": "2025-05-04 02:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:37:31.003123"
    },
    {
      "arxiv_id": "2505.01966v1",
      "title": "A Goal-Oriented Reinforcement Learning-Based Path Planning Algorithm for Modular Self-Reconfigurable Satellites",
      "title_zh": "翻译失败",
      "authors": [
        "Bofei Liu",
        "Dong Ye",
        "Zunhao Yao",
        "Zhaowei Sun"
      ],
      "abstract": "Modular self-reconfigurable satellites refer to satellite clusters composed\nof individual modular units capable of altering their configurations. The\nconfiguration changes enable the execution of diverse tasks and mission\nobjectives. Existing path planning algorithms for reconfiguration often suffer\nfrom high computational complexity, poor generalization capability, and limited\nsupport for diverse target configurations. To address these challenges, this\npaper proposes a goal-oriented reinforcement learning-based path planning\nalgorithm. This algorithm is the first to address the challenge that previous\nreinforcement learning methods failed to overcome, namely handling multiple\ntarget configurations. Moreover, techniques such as Hindsight Experience Replay\nand Invalid Action Masking are incorporated to overcome the significant\nobstacles posed by sparse rewards and invalid actions. Based on these designs,\nour model achieves a 95% and 73% success rate in reaching arbitrary target\nconfigurations in a modular satellite cluster composed of four and six units,\nrespectively.",
      "tldr_zh": "这篇论文针对模块化自重构卫星的路径规划问题，提出了一种基于目标导向强化学习(Reinforcement Learning)的算法，以解决现有方法的计算复杂度高、泛化能力差和对多样目标配置支持有限的挑战。该算法首次成功处理多个目标配置，并通过 Hindsight Experience Replay 和 Invalid Action Masking 技术来应对稀疏奖励和无效动作的难题。实验结果显示，在由四个和六个单元组成的卫星集群中，该算法分别实现了95%和73%的成功率，为卫星重构任务提供了更高效可靠的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01966v1",
      "published_date": "2025-05-04 02:35:18 UTC",
      "updated_date": "2025-05-04 02:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:37:42.751963"
    },
    {
      "arxiv_id": "2505.01956v2",
      "title": "SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment",
      "title_zh": "SafeNav：在 GPS 拒绝环境中使用基于地标定位的安全路径导航",
      "authors": [
        "Ganesh Sapkota",
        "Sanjay Madria"
      ],
      "abstract": "In battlefield environments, adversaries frequently disrupt GPS signals,\nrequiring alternative localization and navigation methods. Traditional\nvision-based approaches like Simultaneous Localization and Mapping (SLAM) and\nVisual Odometry (VO) involve complex sensor fusion and high computational\ndemand, whereas range-free methods like DV-HOP face accuracy and stability\nchallenges in sparse, dynamic networks. This paper proposes LanBLoc-BMM, a\nnavigation approach using landmark-based localization (LanBLoc) combined with a\nbattlefield-specific motion model (BMM) and Extended Kalman Filter (EKF). Its\nperformance is benchmarked against three state-of-the-art visual localization\nalgorithms integrated with BMM and Bayesian filters, evaluated on synthetic and\nreal-imitated trajectory datasets using metrics including Average Displacement\nError (ADE), Final Displacement Error (FDE), and a newly introduced Average\nWeighted Risk Score (AWRS). LanBLoc-BMM (with EKF) demonstrates superior\nperformance in ADE, FDE, and AWRS on real-imitated datasets. Additionally, two\nsafe navigation methods, SafeNav-CHull and SafeNav-Centroid, are introduced by\nintegrating LanBLoc-BMM(EKF) with a novel Risk-Aware RRT* (RAw-RRT*) algorithm\nfor obstacle avoidance and risk exposure minimization. Simulation results in\nbattlefield scenarios indicate SafeNav-Centroid excels in accuracy, risk\nexposure, and trajectory efficiency, while SafeNav-CHull provides superior\ncomputational speed.",
      "tldr_zh": "这篇论文针对 GPS-denied 环境提出 SafeNav 系统，使用基于地标的定位方法 (LanBLoc) 结合战场特定运动模型 (BMM) 和 Extended Kalman Filter (EKF)，以提供更准确稳定的导航替代方案。实验结果显示，LanBLoc-BMM 在合成和真实模拟轨迹数据集上，在 Average Displacement Error (ADE)、Final Displacement Error (FDE) 和新引入的 Average Weighted Risk Score (AWRS) 指标上优于现有视觉定位算法。作者进一步引入 SafeNav-CHull 和 SafeNav-Centroid 两种安全导航方法，整合 Risk-Aware RRT* (RAw-RRT*) 算法进行障碍避让和风险最小化，模拟结果表明 SafeNav-Centroid 在准确性、风险暴露和轨迹效率上表现出色，而 SafeNav-CHull 具有更高的计算速度。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, conference paper. arXiv admin note: text overlap with\n  arXiv:2402.14280",
      "pdf_url": "http://arxiv.org/pdf/2505.01956v2",
      "published_date": "2025-05-04 01:40:31 UTC",
      "updated_date": "2025-05-13 21:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:37:57.053185"
    },
    {
      "arxiv_id": "2505.01955v1",
      "title": "Generative AI in clinical practice: novel qualitative evidence of risk and responsible use of Google's NotebookLM",
      "title_zh": "翻译失败",
      "authors": [
        "Max Reuter",
        "Maura Philippone",
        "Bond Benton",
        "Laura Dilley"
      ],
      "abstract": "The advent of generative artificial intelligence, especially large language\nmodels (LLMs), presents opportunities for innovation in research, clinical\npractice, and education. Recently, Dihan et al. lauded LLM tool NotebookLM's\npotential, including for generating AI-voiced podcasts to educate patients\nabout treatment and rehabilitation, and for quickly synthesizing medical\nliterature for professionals. We argue that NotebookLM presently poses clinical\nand technological risks that should be tested and considered prior to its\nimplementation in clinical practice.",
      "tldr_zh": "这篇论文探讨了生成式 AI（尤其是大型语言模型 LLMs）在临床实践中的创新潜力，并针对 Google 的 NotebookLM 提供了新的定性证据。作者认可 NotebookLM 在教育患者（如生成 AI-voiced podcasts）和快速合成医疗文献方面的优势，但强调其当前存在的临床和技术风险。论文主张在临床应用前进行测试和评估，以确保负责任使用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Eye (2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.01955v1",
      "published_date": "2025-05-04 01:25:33 UTC",
      "updated_date": "2025-05-04 01:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:38:05.360985"
    },
    {
      "arxiv_id": "2505.01953v1",
      "title": "Training Environment for High Performance Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Greg Search"
      ],
      "abstract": "This paper presents Tunnel, a simple, open source, reinforcement learning\ntraining environment for high performance aircraft. It integrates the F16 3D\nnonlinear flight dynamics into OpenAI Gymnasium python package. The template\nincludes primitives for boundaries, targets, adversaries and sensing\ncapabilities that may vary depending on operational need. This offers mission\nplanners a means to rapidly respond to evolving environments, sensor\ncapabilities and adversaries for autonomous air combat aircraft. It offers\nresearchers access to operationally relevant aircraft physics. Tunnel code base\nis accessible to anyone familiar with Gymnasium and/or those with basic python\nskills. This paper includes a demonstration of a week long trade study that\ninvestigated a variety of training methods, observation spaces, and threat\npresentations. This enables increased collaboration between researchers and\nmission planners which can translate to a national military advantage. As\nwarfare becomes increasingly reliant upon automation, software agility will\ncorrelate with decision advantages. Airmen must have tools to adapt to\nadversaries in this context. It may take months for researchers to develop\nskills to customize observation, actions, tasks and training methodologies in\nair combat simulators. In Tunnel, this can be done in a matter of days.",
      "tldr_zh": "这篇论文介绍了 Tunnel，这是一个开源的强化学习训练环境，针对高性能飞机，将 F16 的 3D 非线性飞行动态集成到 OpenAI Gymnasium 中，以支持自主空中作战的开发。Tunnel 提供可自定义的边界、目标、对手和感知能力，帮助任务规划者快速适应演变的环境和传感器需求。论文通过一周的贸易研究演示了各种训练方法、观察空间和威胁呈现的比较，结果显示这能让研究者数天内完成以往需数月的定制工作，从而提升军事协作和决策优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01953v1",
      "published_date": "2025-05-04 01:09:15 UTC",
      "updated_date": "2025-05-04 01:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:38:18.891477"
    },
    {
      "arxiv_id": "2505.01950v1",
      "title": "Segment Any RGB-Thermal Model with Language-aided Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Xing",
        "Xianxun Zhu",
        "Wei Zhou",
        "Qika Lin",
        "Hang Yang",
        "Yuqing Wang"
      ],
      "abstract": "The recent Segment Anything Model (SAM) demonstrates strong instance\nsegmentation performance across various downstream tasks. However, SAM is\ntrained solely on RGB data, limiting its direct applicability to RGB-thermal\n(RGB-T) semantic segmentation. Given that RGB-T provides a robust solution for\nscene understanding in adverse weather and lighting conditions, such as low\nlight and overexposure, we propose a novel framework, SARTM, which customizes\nthe powerful SAM for RGB-T semantic segmentation. Our key idea is to unleash\nthe potential of SAM while introduce semantic understanding modules for RGB-T\ndata pairs. Specifically, our framework first involves fine tuning the original\nSAM by adding extra LoRA layers, aiming at preserving SAM's strong\ngeneralization and segmentation capabilities for downstream tasks. Secondly, we\nintroduce language information as guidance for training our SARTM. To address\ncross-modal inconsistencies, we introduce a Cross-Modal Knowledge\nDistillation(CMKD) module that effectively achieves modality adaptation while\nmaintaining its generalization capabilities. This semantic module enables the\nminimization of modality gaps and alleviates semantic ambiguity, facilitating\nthe combination of any modality under any visual conditions. Furthermore, we\nenhance the segmentation performance by adjusting the segmentation head of SAM\nand incorporating an auxiliary semantic segmentation head, which integrates\nmulti-scale features for effective fusion. Extensive experiments are conducted\nacross three multi-modal RGBT semantic segmentation benchmarks: MFNET, PST900,\nand FMB. Both quantitative and qualitative results consistently demonstrate\nthat the proposed SARTM significantly outperforms state-of-the-art approaches\nacross a variety of conditions.",
      "tldr_zh": "该研究针对Segment Anything Model (SAM)仅在RGB数据上训练，无法直接应用于RGB-Thermal (RGB-T)语义分割的问题，提出了一种新框架SARTM，以增强其在恶劣天气和光照条件下的场景理解能力。SARTM通过添加LoRA层微调SAM以保留其泛化性和分割能力，并引入语言信息作为指导，同时利用Cross-Modal Knowledge Distillation (CMKD)模块处理跨模态不一致性，并调整分割头整合多尺度特征进行有效融合。这些方法最小化了模态差距并缓解语义模糊。实验在MFNET、PST900和FMB基准上显示，SARTM在各种条件下显著优于现有最先进方法，在量化与质化结果上均表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2412.04220 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2505.01950v1",
      "published_date": "2025-05-04 00:24:17 UTC",
      "updated_date": "2025-05-04 00:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:38:30.264066"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 67,
  "processed_papers_count": 67,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T19:38:52.113348"
}