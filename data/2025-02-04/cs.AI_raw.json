[
  {
    "arxiv_id": "2502.02780v1",
    "title": "Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation",
    "authors": [
      "Songlin Xu",
      "Hao-Ning Wen",
      "Hongyi Pan",
      "Dallas Dominguez",
      "Dongyin Hu",
      "Xinyu Zhang"
    ],
    "abstract": "Student simulation supports educators to improve teaching by interacting with\nvirtual students. However, most existing approaches ignore the modulation\neffects of course materials because of two challenges: the lack of datasets\nwith granularly annotated course materials, and the limitation of existing\nsimulation models in processing extremely long textual data. To solve the\nchallenges, we first run a 6-week education workshop from N = 60 students to\ncollect fine-grained data using a custom built online education system, which\nlogs students' learning behaviors as they interact with lecture materials over\ntime. Second, we propose a transferable iterative reflection (TIR) module that\naugments both prompting-based and finetuning-based large language models (LLMs)\nfor simulating learning behaviors. Our comprehensive experiments show that TIR\nenables the LLMs to perform more accurate student simulation than classical\ndeep learning models, even with limited demonstration data. Our TIR approach\nbetter captures the granular dynamism of learning performance and inter-student\ncorrelations in classrooms, paving the way towards a ''digital twin'' for\nonline education.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.02780v1",
    "published_date": "2025-02-04 23:42:52 UTC",
    "updated_date": "2025-02-04 23:42:52 UTC"
  },
  {
    "arxiv_id": "2502.02779v1",
    "title": "3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography",
    "authors": [
      "Weicheng Zhu",
      "Haoxu Huang",
      "Huanze Tang",
      "Rushabh Musthyala",
      "Boyang Yu",
      "Long Chen",
      "Emilio Vega",
      "Thomas O'Donnell",
      "Seena Dehkharghani",
      "Jennifer A. Frontera",
      "Arjun V. Masurkar",
      "Kara Melmed",
      "Narges Razavian"
    ],
    "abstract": "Head computed tomography (CT) imaging is a widely-used imaging modality with\nmultitudes of medical indications, particularly in assessing pathology of the\nbrain, skull, and cerebrovascular system. It is commonly the first-line imaging\nin neurologic emergencies given its rapidity of image acquisition, safety,\ncost, and ubiquity. Deep learning models may facilitate detection of a wide\nrange of diseases. However, the scarcity of high-quality labels and\nannotations, particularly among less common conditions, significantly hinders\nthe development of powerful models. To address this challenge, we introduce\nFM-CT: a Foundation Model for Head CT for generalizable disease detection,\ntrained using self-supervised learning. Our approach pre-trains a deep learning\nmodel on a large, diverse dataset of 361,663 non-contrast 3D head CT scans\nwithout the need for manual annotations, enabling the model to learn robust,\ngeneralizable features. To investigate the potential of self-supervised\nlearning in head CT, we employed both discrimination with self-distillation and\nmasked image modeling, and we construct our model in 3D rather than at the\nslice level (2D) to exploit the structure of head CT scans more comprehensively\nand efficiently. The model's downstream classification performance is evaluated\nusing internal and three external datasets, encompassing both in-distribution\n(ID) and out-of-distribution (OOD) data. Our results demonstrate that the\nself-supervised foundation model significantly improves performance on\ndownstream diagnostic tasks compared to models trained from scratch and\nprevious 3D CT foundation models on scarce annotated datasets. This work\nhighlights the effectiveness of self-supervised learning in medical imaging and\nsets a new benchmark for head CT image analysis in 3D, enabling broader use of\nartificial intelligence for head CT-based diagnosis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.02779v1",
    "published_date": "2025-02-04 23:42:18 UTC",
    "updated_date": "2025-02-04 23:42:18 UTC"
  },
  {
    "arxiv_id": "2502.02772v2",
    "title": "Cross-modality Force and Language Embeddings for Natural Human-Robot Communication",
    "authors": [
      "Ravi Tejwani",
      "Karl Velazquez",
      "John Payne",
      "Paolo Bonato",
      "Harry Asada"
    ],
    "abstract": "A method for cross-modality embedding of force profile and words is presented\nfor synergistic coordination of verbal and haptic communication. When two\npeople carry a large, heavy object together, they coordinate through verbal\ncommunication about the intended movements and physical forces applied to the\nobject. This natural integration of verbal and physical cues enables effective\ncoordination. Similarly, human-robot interaction could achieve this level of\ncoordination by integrating verbal and haptic communication modalities. This\npaper presents a framework for embedding words and force profiles in a unified\nmanner, so that the two communication modalities can be integrated and\ncoordinated in a way that is effective and synergistic. Here, it will be shown\nthat, although language and physical force profiles are deemed completely\ndifferent, the two can be embedded in a unified latent space and proximity\nbetween the two can be quantified. In this latent space, a force profile and\nwords can a) supplement each other, b) integrate the individual effects, and c)\nsubstitute in an exchangeable manner. First, the need for cross-modality\nembedding is addressed, and the basic architecture and key building block\ntechnologies are presented. Methods for data collection and implementation\nchallenges will be addressed, followed by experimental results and discussions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review in RSS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02772v2",
    "published_date": "2025-02-04 23:32:45 UTC",
    "updated_date": "2025-04-25 21:31:38 UTC"
  },
  {
    "arxiv_id": "2502.02768v1",
    "title": "Planning with affordances: Integrating learned affordance models and symbolic planning",
    "authors": [
      "Rajesh Mangannavar"
    ],
    "abstract": "Intelligent agents working in real-world environments must be able to learn\nabout the environment and its capabilities which enable them to take actions to\nchange to the state of the world to complete a complex multi-step task in a\nphotorealistic environment. Learning about the environment is especially\nimportant to perform various multiple-step tasks without having to redefine an\nagent's action set for different tasks or environment settings. In our work, we\naugment an existing task and motion planning framework with learned affordance\nmodels of objects in the world to enable planning and executing multi-step\ntasks using learned models. Each task can be seen as changing the current state\nof the world to a given goal state. The affordance models provide us with what\nactions are possible and how to perform those actions in any given state. A\nsymbolic planning algorithm uses this information and the starting and goal\nstate to create a feasible plan to reach the desired goal state to complete a\ngiven task. We demonstrate our approach in a virtual 3D photorealistic\nenvironment, AI2-Thor, and evaluate it on real-world tasks. Our results show\nthat our agent quickly learns how to interact with the environment and is well\nprepared to perform tasks such as \"Moving an object out of the way to reach the\ndesired location.\"",
    "categories": [
      "cs.AI",
      "cs.RO",
      "I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02768v1",
    "published_date": "2025-02-04 23:15:38 UTC",
    "updated_date": "2025-02-04 23:15:38 UTC"
  },
  {
    "arxiv_id": "2502.04359v1",
    "title": "Exploring Spatial Language Grounding Through Referring Expressions",
    "authors": [
      "Akshar Tumu",
      "Parisa Kordjamshidi"
    ],
    "abstract": "Spatial Reasoning is an important component of human cognition and is an area\nin which the latest Vision-language models (VLMs) show signs of difficulty. The\ncurrent analysis works use image captioning tasks and visual question\nanswering. In this work, we propose using the Referring Expression\nComprehension task instead as a platform for the evaluation of spatial\nreasoning by VLMs. This platform provides the opportunity for a deeper analysis\nof spatial comprehension and grounding abilities when there is 1) ambiguity in\nobject detection, 2) complex spatial expressions with a longer sentence\nstructure and multiple spatial relations, and 3) expressions with negation\n('not'). In our analysis, we use task-specific architectures as well as large\nVLMs and highlight their strengths and weaknesses in dealing with these\nspecific situations. While all these models face challenges with the task at\nhand, the relative behaviors depend on the underlying models and the specific\ncategories of spatial semantics (topological, directional, proximal, etc.). Our\nresults highlight these challenges and behaviors and provide insight into\nresearch gaps and future directions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04359v1",
    "published_date": "2025-02-04 22:58:15 UTC",
    "updated_date": "2025-02-04 22:58:15 UTC"
  },
  {
    "arxiv_id": "2502.02756v1",
    "title": "Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images",
    "authors": [
      "Obed Korshie Dzikunu",
      "Shadab Ahamed",
      "Amirhossein Toosi",
      "Xiaoxiao Li",
      "Arman Rahmim"
    ],
    "abstract": "This study proposes a new loss function for deep neural networks, L1-weighted\nDice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of\nvoxels based on their classification difficulty, towards automated detection\nand segmentation of metastatic prostate cancer lesions in PET/CT scans. We\nobtained 380 PSMA [18-F] DCFPyL PET/CT scans of patients diagnosed with\nbiochemical recurrence metastatic prostate cancer. We trained two 3D\nconvolutional neural networks, Attention U-Net and SegResNet, and concatenated\nthe PET and CT volumes channel-wise as input. The performance of our custom\nloss function was evaluated against the Dice and Dice Focal Loss functions. For\nclinical significance, we considered a detected region of interest (ROI) as a\ntrue positive if at least the voxel with the maximum standardized uptake value\nfalls within the ROI. We assessed the models' performance based on the number\nof lesions in an image, tumour volume, activity, and extent of spread. The\nL1DFL outperformed the comparative loss functions by at least 13% on the test\nset. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were\nlower than that of L1DFL by at least 6% and 34%, respectively. The Dice Focal\nLoss yielded more false positives, whereas the Dice Loss was more sensitive to\nsmaller volumes and struggled to segment larger lesions accurately. They also\nexhibited network-specific variations and yielded declines in segmentation\naccuracy with increased tumour spread. Our results demonstrate the potential of\nL1DFL to yield robust segmentation of metastatic prostate cancer lesions in\nPSMA PET/CT images. The results further highlight potential complexities\narising from the variations in lesion characteristics that may influence\nautomated prostate cancer tumour detection and segmentation. The code is\npublicly available at: https://github.com/ObedDzik/pca_segment.git.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "29 pages, 7 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.02756v1",
    "published_date": "2025-02-04 22:45:16 UTC",
    "updated_date": "2025-02-04 22:45:16 UTC"
  },
  {
    "arxiv_id": "2502.02747v1",
    "title": "PatchPilot: A Stable and Cost-Efficient Agentic Patching Framework",
    "authors": [
      "Hongwei Li",
      "Yuheng Tang",
      "Shiqi Wang",
      "Wenbo Guo"
    ],
    "abstract": "Recent research builds various patching agents that combine large language\nmodels (LLMs) with non-ML tools and achieve promising results on the\nstate-of-the-art (SOTA) software patching benchmark, SWE-Bench. Based on how to\ndetermine the patching workflows, existing patching agents can be categorized\nas agent-based planning methods, which rely on LLMs for planning, and\nhuman-based planning methods, which follow a pre-defined workflow. At a high\nlevel, agent-based planning methods achieve high patching performance but with\na high cost and limited stability. Human-based planning methods, on the other\nhand, are more stable and efficient but have key workflow limitations that\ncompromise their patching performance. In this paper, we propose PatchPilot, an\nagentic patcher that strikes a balance between patching efficacy, stability,\nand cost-efficiency. PatchPilot proposes a novel human-based planning workflow\nwith five components: reproduction, localization, generation, validation, and\nrefinement (where refinement is unique to PatchPilot). We introduce novel and\ncustomized designs to each component to optimize their effectiveness and\nefficiency. Through extensive experiments on the SWE-Bench benchmarks,\nPatchPilot shows a superior performance than existing open-source methods while\nmaintaining low cost (less than 1$ per instance) and ensuring higher stability.\nWe also conduct a detailed ablation study to validate the key designs in each\ncomponent.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02747v1",
    "published_date": "2025-02-04 22:30:02 UTC",
    "updated_date": "2025-02-04 22:30:02 UTC"
  },
  {
    "arxiv_id": "2502.06814v1",
    "title": "Diffusion Instruction Tuning",
    "authors": [
      "Chen Jin",
      "Ryutaro Tanno",
      "Amrutha Saseendran",
      "Tom Diethe",
      "Philip Teare"
    ],
    "abstract": "We introduce Lavender, a simple supervised fine-tuning (SFT) method that\nboosts the performance of advanced vision-language models (VLMs) by leveraging\nstate-of-the-art image generation models such as Stable Diffusion.\nSpecifically, Lavender aligns the text-vision attention in the VLM transformer\nwith the equivalent used by Stable Diffusion during SFT, instead of adapting\nseparate encoders. This alignment enriches the model's visual understanding and\nsignificantly boosts performance across in- and out-of-distribution tasks.\nLavender requires just 0.13 million training examples, 2.5% of typical\nlarge-scale SFT datasets, and fine-tunes on standard hardware (8 GPUs) in a\nsingle day. It consistently improves state-of-the-art open-source multimodal\nLLMs (e.g., Llama-3.2-11B, MiniCPM-Llama3-v2.5), achieving up to 30% gains and\na 68% boost on challenging out-of-distribution medical QA tasks. By efficiently\ntransferring the visual expertise of image generators with minimal supervision,\nLavender offers a scalable solution for more accurate vision-language systems.\nAll code, training data, and models will be shared at\nhttps://astrazeneca.github.io/vlm/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "Project page at https://astrazeneca.github.io/vlm/",
    "pdf_url": "http://arxiv.org/pdf/2502.06814v1",
    "published_date": "2025-02-04 22:20:20 UTC",
    "updated_date": "2025-02-04 22:20:20 UTC"
  },
  {
    "arxiv_id": "2502.06813v1",
    "title": "Policy Guided Tree Search for Enhanced LLM Reasoning",
    "authors": [
      "Yang Li"
    ],
    "abstract": "Despite their remarkable capabilities, large language models often struggle\nwith tasks requiring complex reasoning and planning. While existing approaches\nlike Chain-of-Thought prompting and tree search techniques show promise, they\nare limited by their reliance on predefined heuristics and computationally\nexpensive exploration strategies. We propose Policy-Guided Tree Search (PGTS),\na framework that combines reinforcement learning with structured tree\nexploration to efficiently navigate reasoning paths. Our key innovation is a\nlearned policy that dynamically decides between expanding, branching,\nbacktracking, or terminating exploration, eliminating the need for manual\nheuristics or exhaustive search. Experiments across mathematical reasoning,\nlogical deduction, and planning benchmarks demonstrate that PGTS achieves\nsuperior reasoning performance while significantly reducing computational costs\ncompared to existing methods. These results establish PGTS as a scalable and\neffective solution for tackling complex reasoning tasks with LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06813v1",
    "published_date": "2025-02-04 22:08:20 UTC",
    "updated_date": "2025-02-04 22:08:20 UTC"
  },
  {
    "arxiv_id": "2502.02740v1",
    "title": "Vision-Language Model Dialog Games for Self-Improvement",
    "authors": [
      "Ksenia Konyushkova",
      "Christos Kaplanis",
      "Serkan Cabi",
      "Misha Denil"
    ],
    "abstract": "The increasing demand for high-quality, diverse training data poses a\nsignificant bottleneck in advancing vision-language models (VLMs). This paper\npresents VLM Dialog Games, a novel and scalable self-improvement framework for\nVLMs. Our approach leverages self-play between two agents engaged in a\ngoal-oriented play centered around image identification. By filtering for\nsuccessful game interactions, we automatically curate a high-quality dataset of\ninterleaved images and text. We demonstrate that fine-tuning on this synthetic\ndata leads to performance gains on downstream tasks and generalises across\ndatasets. Moreover, as the improvements in the model lead to better game play,\nthis procedure can be applied iteratively. This work paves the way for\nself-improving VLMs, with potential applications in various real-world\nscenarios especially when the high-quality multimodal data is scarce.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02740v1",
    "published_date": "2025-02-04 21:58:07 UTC",
    "updated_date": "2025-02-04 21:58:07 UTC"
  },
  {
    "arxiv_id": "2502.02732v2",
    "title": "Peri-LN: Revisiting Layer Normalization in the Transformer Architecture",
    "authors": [
      "Jeonghoon Kim",
      "Byeongchan Lee",
      "Cheonbok Park",
      "Yeontaek Oh",
      "Beomjun Kim",
      "Taehwan Yoo",
      "Seongjin Shin",
      "Dongyoon Han",
      "Jinwoo Shin",
      "Kang Min Yoo"
    ],
    "abstract": "Designing Transformer architectures with the optimal layer normalization (LN)\nstrategy that ensures large-scale training stability and expedite convergence\nhas remained elusive, even in this era of large language models (LLMs). To this\nend, we present a comprehensive analytical foundation for understanding how\ndifferent LN strategies influence training dynamics in large-scale Transformer\ntraining. Until recently, Pre-LN and Post-LN have long dominated standard\npractices despite their limitations in large-scale training. However, several\nopen-source large-scale models have recently begun silently adopting a third\nstrategy without much explanation. This strategy places layer normalization\n(LN) peripherally around sublayers, a design we term Peri-LN. While Peri-LN has\ndemonstrated promising empirical performance, its precise mechanisms and\nbenefits remain almost unexplored. Our in-depth analysis shows that Peri-LN\nstrikes an ideal balance in variance growth -- unlike Pre-LN and Post-LN, which\nare prone to vanishing gradients and ``massive activations.'' To validate our\ntheoretical insight, we conduct large-scale experiments on Transformers up to\n3.2B parameters, showing that Peri-LN consistently achieves more balanced\nvariance growth, steadier gradient flow, and convergence stability. Our results\nsuggest that Peri-LN warrants broader consideration for large-scale Transformer\narchitectures, providing renewed insights into the optimal placement and\napplication of LN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.02732v2",
    "published_date": "2025-02-04 21:29:47 UTC",
    "updated_date": "2025-02-06 20:12:02 UTC"
  },
  {
    "arxiv_id": "2502.02727v3",
    "title": "Gradient Correction in Federated Learning with Adaptive Optimization",
    "authors": [
      "Evan Chen",
      "Shiqiang Wang",
      "Jianing Zhang",
      "Dong-Jun Han",
      "Chaoyue Liu",
      "Christopher Brinton"
    ],
    "abstract": "In federated learning (FL), model training performance is strongly impacted\nby data heterogeneity across clients. Client-drift compensation methods have\nrecently emerged as a solution to this issue, introducing correction terms into\nlocal model updates. To date, these methods have only been considered under\nstochastic gradient descent (SGD)-based model training, while modern FL\nframeworks also employ adaptive optimizers (e.g., Adam) for improved\nconvergence. However, due to the complex interplay between first and second\nmoments found in most adaptive optimization methods, naively injecting\ncorrection terms can lead to performance degradation in heterogeneous settings.\nIn this work, we propose {\\tt FAdamGC}, the first algorithm to integrate drift\ncompensation into adaptive federated optimization. The key idea of {\\tt\nFAdamGC} is injecting a pre-estimation correction term that aligns with the\nmoment structure of adaptive methods. We provide a rigorous convergence\nanalysis of our algorithm under non-convex settings, showing that {\\tt FAdamGC}\nresults in better rate and milder assumptions than naively porting SGD-based\ncorrection algorithms into adaptive optimizers. Our experimental results\ndemonstrate that {\\tt FAdamGC} consistently outperform existing methods in\ntotal communication and computation cost across varying levels of data\nheterogeneity, showing the efficacy of correcting gradient information in\nfederated adaptive optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02727v3",
    "published_date": "2025-02-04 21:21:30 UTC",
    "updated_date": "2025-05-18 02:48:18 UTC"
  },
  {
    "arxiv_id": "2502.02717v1",
    "title": "Astromer 2",
    "authors": [
      "Cristobal Donoso-Oliva",
      "Ignacio Becker",
      "Pavlos Protopapas",
      "Guillermo Cabrera-Vives",
      "Martina Cádiz-Leyton",
      "Daniel Moreno-Cartagena"
    ],
    "abstract": "Foundational models have emerged as a powerful paradigm in deep learning\nfield, leveraging their capacity to learn robust representations from\nlarge-scale datasets and effectively to diverse downstream applications such as\nclassification. In this paper, we present Astromer 2 a foundational model\nspecifically designed for extracting light curve embeddings. We introduce\nAstromer 2 as an enhanced iteration of our self-supervised model for light\ncurve analysis. This paper highlights the advantages of its pre-trained\nembeddings, compares its performance with that of its predecessor, Astromer 1,\nand provides a detailed empirical analysis of its capabilities, offering deeper\ninsights into the model's representations. Astromer 2 is pretrained on 1.5\nmillion single-band light curves from the MACHO survey using a self-supervised\nlearning task that predicts randomly masked observations within sequences.\nFine-tuning on a smaller labeled dataset allows us to assess its performance in\nclassification tasks. The quality of the embeddings is measured by the F1 score\nof an MLP classifier trained on Astromer-generated embeddings. Our results\ndemonstrate that Astromer 2 significantly outperforms Astromer 1 across all\nevaluated scenarios, including limited datasets of 20, 100, and 500 samples per\nclass. The use of weighted per-sample embeddings, which integrate intermediate\nrepresentations from Astromer's attention blocks, is particularly impactful.\nNotably, Astromer 2 achieves a 15% improvement in F1 score on the ATLAS dataset\ncompared to prior models, showcasing robust generalization to new datasets.\nThis enhanced performance, especially with minimal labeled data, underscores\nthe potential of Astromer 2 for more efficient and scalable light curve\nanalysis.",
    "categories": [
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "10 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02717v1",
    "published_date": "2025-02-04 20:56:14 UTC",
    "updated_date": "2025-02-04 20:56:14 UTC"
  },
  {
    "arxiv_id": "2502.02715v1",
    "title": "An Analysis of LLM Fine-Tuning and Few-Shot Learning for Flaky Test Detection and Classification",
    "authors": [
      "Riddhi More",
      "Jeremy S. Bradbury"
    ],
    "abstract": "Flaky tests exhibit non-deterministic behavior during execution and they may\npass or fail without any changes to the program under test. Detecting and\nclassifying these flaky tests is crucial for maintaining the robustness of\nautomated test suites and ensuring the overall reliability and confidence in\nthe testing. However, flaky test detection and classification is challenging\ndue to the variability in test behavior, which can depend on environmental\nconditions and subtle code interactions. Large Language Models (LLMs) offer\npromising approaches to address this challenge, with fine-tuning and few-shot\nlearning (FSL) emerging as viable techniques. With enough data fine-tuning a\npre-trained LLM can achieve high accuracy, making it suitable for organizations\nwith more resources. Alternatively, we introduce FlakyXbert, an FSL approach\nthat employs a Siamese network architecture to train efficiently with limited\ndata. To understand the performance and cost differences between these two\nmethods, we compare fine-tuning on larger datasets with FSL in scenarios\nrestricted by smaller datasets. Our evaluation involves two existing flaky test\ndatasets, FlakyCat and IDoFT. Our results suggest that while fine-tuning can\nachieve high accuracy, FSL provides a cost-effective approach with competitive\naccuracy, which is especially beneficial for organizations or projects with\nlimited historical data available for training. These findings underscore the\nviability of both fine-tuning and FSL in flaky test detection and\nclassification with each suited to different organizational needs and resource\navailability.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.02715v1",
    "published_date": "2025-02-04 20:54:51 UTC",
    "updated_date": "2025-02-04 20:54:51 UTC"
  },
  {
    "arxiv_id": "2502.04358v1",
    "title": "Position: Scaling LLM Agents Requires Asymptotic Analysis with LLM Primitives",
    "authors": [
      "Elliot Meyerson",
      "Xin Qiu"
    ],
    "abstract": "Decomposing hard problems into subproblems often makes them easier and more\nefficient to solve. With large language models (LLMs) crossing critical\nreliability thresholds for a growing slate of capabilities, there is an\nincreasing effort to decompose systems into sets of LLM-based agents, each of\nwhom can be delegated sub-tasks. However, this decomposition (even when\nautomated) is often intuitive, e.g., based on how a human might assign roles to\nmembers of a human team. How close are these role decompositions to optimal?\nThis position paper argues that asymptotic analysis with LLM primitives is\nneeded to reason about the efficiency of such decomposed systems, and that\ninsights from such analysis will unlock opportunities for scaling them. By\ntreating the LLM forward pass as the atomic unit of computational cost, one can\nseparate out the (often opaque) inner workings of a particular LLM from the\ninherent efficiency of how a set of LLMs are orchestrated to solve hard\nproblems. In other words, if we want to scale the deployment of LLMs to the\nlimit, instead of anthropomorphizing LLMs, asymptotic analysis with LLM\nprimitives should be used to reason about and develop more powerful\ndecompositions of large problems into LLM agents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CC",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages including references",
    "pdf_url": "http://arxiv.org/pdf/2502.04358v1",
    "published_date": "2025-02-04 20:47:43 UTC",
    "updated_date": "2025-02-04 20:47:43 UTC"
  },
  {
    "arxiv_id": "2502.06811v2",
    "title": "Aligning Human and Machine Attention for Enhanced Supervised Learning",
    "authors": [
      "Avihay Chriqui",
      "Inbal Yahav",
      "Dov Teeni",
      "Ahmed Abbasi"
    ],
    "abstract": "Attention, or prioritization of certain information items over others, is a\ncritical element of any learning process, for both humans and machines. Given\nthat humans continue to outperform machines in certain learning tasks, it seems\nplausible that machine performance could be enriched by aligning machine\nattention with human attention mechanisms -- yet research on this topic is\nsparse and has achieved only limited success. This paper proposes a new\napproach to address this gap, called Human-Machine Attention Learning (HuMAL).\nThis approach involves reliance on data annotated by humans to reflect their\nself-perceived attention during specific tasks. We evaluate several alternative\nstrategies for integrating such human attention data into machine learning (ML)\nalgorithms, using a sentiment analysis task (review data from Yelp) and a\npersonality-type classification task (data from myPersonality). The\nbest-performing HuMAL strategy significantly enhances the task performance of\nfine-tuned transformer models (BERT, as well as GPT-2 and XLNET), and the\nbenefit is particularly pronounced under challenging conditions of imbalanced\nor sparse labeled data. This research contributes to a deeper understanding of\nstrategies for integrating human attention into ML models and highlights the\npotential of leveraging human cognition to augment ML in real-world\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06811v2",
    "published_date": "2025-02-04 20:44:38 UTC",
    "updated_date": "2025-02-19 20:57:37 UTC"
  },
  {
    "arxiv_id": "2502.02703v1",
    "title": "Developing multilingual speech synthesis system for Ojibwe, Mi'kmaq, and Maliseet",
    "authors": [
      "Shenran Wang",
      "Changbing Yang",
      "Mike Parkhill",
      "Chad Quinn",
      "Christopher Hammerly",
      "Jian Zhu"
    ],
    "abstract": "We present lightweight flow matching multilingual text-to-speech (TTS)\nsystems for Ojibwe, Mi'kmaq, and Maliseet, three Indigenous languages in North\nAmerica. Our results show that training a multilingual TTS model on three\ntypologically similar languages can improve the performance over monolingual\nmodels, especially when data are scarce. Attention-free architectures are\nhighly competitive with self-attention architecture with higher memory\nefficiency. Our research not only advances technical development for the\nrevitalization of low-resource languages but also highlights the cultural gap\nin human evaluation protocols, calling for a more community-centered approach\nto human evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02703v1",
    "published_date": "2025-02-04 20:36:55 UTC",
    "updated_date": "2025-02-04 20:36:55 UTC"
  },
  {
    "arxiv_id": "2502.02701v1",
    "title": "Practically Effective Adjustment Variable Selection in Causal Inference",
    "authors": [
      "Atsushi Noda",
      "Takashi Isozaki"
    ],
    "abstract": "In the estimation of causal effects, one common method for removing the\ninfluence of confounders is to adjust the variables that satisfy the back-door\ncriterion. However, it is not always possible to uniquely determine sets of\nsuch variables. Moreover, real-world data is almost always limited, which means\nit may be insufficient for statistical estimation. Therefore, we propose\ncriteria for selecting variables from a list of candidate adjustment variables\nalong with an algorithm to prevent accuracy degradation in causal effect\nestimation. We initially focus on directed acyclic graphs (DAGs) and then\noutlines specific steps for applying this method to completed partially\ndirected acyclic graphs (CPDAGs). We also present and prove a theorem on causal\neffect computation possibility in CPDAGs. Finally, we demonstrate the practical\nutility of our method using both existing and artificial data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02701v1",
    "published_date": "2025-02-04 20:35:19 UTC",
    "updated_date": "2025-02-04 20:35:19 UTC"
  },
  {
    "arxiv_id": "2502.02690v1",
    "title": "Controllable Video Generation with Provable Disentanglement",
    "authors": [
      "Yifan Shen",
      "Peiyuan Zhu",
      "Zijian Li",
      "Shaoan Xie",
      "Zeyu Tang",
      "Namrata Deka",
      "Zongfang Liu",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "abstract": "Controllable video generation remains a significant challenge, despite recent\nadvances in generating high-quality and consistent videos. Most existing\nmethods for controlling video generation treat the video as a whole, neglecting\nintricate fine-grained spatiotemporal relationships, which limits both control\nprecision and efficiency. In this paper, we propose Controllable Video\nGenerative Adversarial Networks (CoVoGAN) to disentangle the video concepts,\nthus facilitating efficient and independent control over individual concepts.\nSpecifically, following the minimal change principle, we first disentangle\nstatic and dynamic latent variables. We then leverage the sufficient change\nproperty to achieve component-wise identifiability of dynamic latent variables,\nenabling independent control over motion and identity. To establish the\ntheoretical foundation, we provide a rigorous analysis demonstrating the\nidentifiability of our approach. Building on these theoretical insights, we\ndesign a Temporal Transition Module to disentangle latent dynamics. To enforce\nthe minimal change principle and sufficient change property, we minimize the\ndimensionality of latent dynamic variables and impose temporal conditional\nindependence. To validate our approach, we integrate this module as a plug-in\nfor GANs. Extensive qualitative and quantitative experiments on various video\ngeneration benchmarks demonstrate that our method significantly improves\ngeneration quality and controllability across diverse real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02690v1",
    "published_date": "2025-02-04 20:10:20 UTC",
    "updated_date": "2025-02-04 20:10:20 UTC"
  },
  {
    "arxiv_id": "2502.02688v1",
    "title": "Efficient Implementation of the Global Cardinality Constraint with Costs",
    "authors": [
      "Margaux Schmied",
      "Jean-Charles Regin"
    ],
    "abstract": "The success of Constraint Programming relies partly on the global constraints\nand implementation of the associated filtering algorithms. Recently, new ideas\nemerged to improve these implementations in practice, especially regarding the\nall different constraint. In this paper, we consider the cardinality constraint\nwith costs. The cardinality constraint is a generalization of the all different\nconstraint that specifies the number of times each value must be taken by a\ngiven set of variables in a solution. The version with costs introduces an\nassignment cost and bounds the total sum of assignment costs. The arc\nconsistency filtering algorithm of this constraint is difficult to use in\npractice, as it systematically searches for many shortest paths. We propose a\nnew approach that works with upper bounds on shortest paths based on landmarks.\nThis approach can be seen as a preprocessing. It is fast and avoids, in\npractice, a large number of explicit computations of shortest paths.",
    "categories": [
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at the 30th International Conference on Principles and\n  Practice of Constraint Programming (CP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2502.02688v1",
    "published_date": "2025-02-04 20:03:53 UTC",
    "updated_date": "2025-02-04 20:03:53 UTC"
  },
  {
    "arxiv_id": "2502.03487v1",
    "title": "Artificial Intelligence and Legal Analysis: Implications for Legal Education and the Profession",
    "authors": [
      "Lee Peoples"
    ],
    "abstract": "This article reports the results of a study examining the ability of legal\nand non-legal Large Language Models to perform legal analysis using the\nIssue-Rule-Application-Conclusion framework. LLMs were tested on legal\nreasoning tasks involving rule analysis and analogical reasoning. The results\nshow that LLMs can conduct basic IRAC analysis, but are limited by brief\nresponses lacking detail, an inability to commit to answers, false confidence,\nand hallucinations. The study compares legal and nonlegal LLMs, identifies\nshortcomings, and explores traits that may hinder their ability to think like a\nlawyer. It also discusses the implications for legal education and practice,\nhighlighting the need for critical thinking skills in future lawyers and the\npotential pitfalls of overreliance on artificial intelligence AI resulting in a\nloss of logic, reasoning, and critical thinking skills.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03487v1",
    "published_date": "2025-02-04 19:50:48 UTC",
    "updated_date": "2025-02-04 19:50:48 UTC"
  },
  {
    "arxiv_id": "2502.02683v1",
    "title": "Streaming Speaker Change Detection and Gender Classification for Transducer-Based Multi-Talker Speech Translation",
    "authors": [
      "Peidong Wang",
      "Naoyuki Kanda",
      "Jian Xue",
      "Jinyu Li",
      "Xiaofei Wang",
      "Aswin Shanmugam Subramanian",
      "Junkun Chen",
      "Sunit Sivasankaran",
      "Xiong Xiao",
      "Yong Zhao"
    ],
    "abstract": "Streaming multi-talker speech translation is a task that involves not only\ngenerating accurate and fluent translations with low latency but also\nrecognizing when a speaker change occurs and what the speaker's gender is.\nSpeaker change information can be used to create audio prompts for a zero-shot\ntext-to-speech system, and gender can help to select speaker profiles in a\nconventional text-to-speech model. We propose to tackle streaming speaker\nchange detection and gender classification by incorporating speaker embeddings\ninto a transducer-based streaming end-to-end speech translation model. Our\nexperiments demonstrate that the proposed methods can achieve high accuracy for\nboth speaker change detection and gender classification.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02683v1",
    "published_date": "2025-02-04 19:50:15 UTC",
    "updated_date": "2025-02-04 19:50:15 UTC"
  },
  {
    "arxiv_id": "2502.04357v1",
    "title": "Reusing Embeddings: Reproducible Reward Model Research in Large Language Model Alignment without GPUs",
    "authors": [
      "Hao Sun",
      "Yunyi Shen",
      "Jean-Francois Ton",
      "Mihaela van der Schaar"
    ],
    "abstract": "Large Language Models (LLMs) have made substantial strides in structured\ntasks through Reinforcement Learning (RL), demonstrating proficiency in\nmathematical reasoning and code generation. However, applying RL in broader\ndomains like chatbots and content generation -- through the process known as\nReinforcement Learning from Human Feedback (RLHF) -- presents unique\nchallenges. Reward models in RLHF are critical, acting as proxies that evaluate\nthe alignment of LLM outputs with human intent. Despite advancements, the\ndevelopment of reward models is hindered by challenges such as computational\nheavy training, costly evaluation, and therefore poor reproducibility. We\nadvocate for using embedding-based input in reward model research as an\naccelerated solution to those challenges. By leveraging embeddings for reward\nmodeling, we can enhance reproducibility, reduce computational demands on\nhardware, improve training stability, and significantly reduce training and\nevaluation costs, hence facilitating fair and efficient comparisons in this\nactive research area. We then show a case study of reproducing existing reward\nmodel ensemble research using embedding-based reward models. We discussed\nfuture avenues for research, aiming to contribute to safer and more effective\nLLM deployments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04357v1",
    "published_date": "2025-02-04 19:37:35 UTC",
    "updated_date": "2025-02-04 19:37:35 UTC"
  },
  {
    "arxiv_id": "2502.02673v1",
    "title": "MedRAX: Medical Reasoning Agent for Chest X-ray",
    "authors": [
      "Adibvafa Fallahpour",
      "Jun Ma",
      "Alif Munim",
      "Hongwei Lyu",
      "Bo Wang"
    ],
    "abstract": "Chest X-rays (CXRs) play an integral role in driving critical decisions in\ndisease management and patient care. While recent innovations have led to\nspecialized models for various CXR interpretation tasks, these solutions often\noperate in isolation, limiting their practical utility in clinical practice. We\npresent MedRAX, the first versatile AI agent that seamlessly integrates\nstate-of-the-art CXR analysis tools and multimodal large language models into a\nunified framework. MedRAX dynamically leverages these models to address complex\nmedical queries without requiring additional training. To rigorously evaluate\nits capabilities, we introduce ChestAgentBench, a comprehensive benchmark\ncontaining 2,500 complex medical queries across 7 diverse categories. Our\nexperiments demonstrate that MedRAX achieves state-of-the-art performance\ncompared to both open-source and proprietary models, representing a significant\nstep toward the practical deployment of automated CXR interpretation systems.\nData and code have been publicly available at\nhttps://github.com/bowang-lab/MedRAX",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.02673v1",
    "published_date": "2025-02-04 19:31:00 UTC",
    "updated_date": "2025-02-04 19:31:00 UTC"
  },
  {
    "arxiv_id": "2502.02671v1",
    "title": "On Teacher Hacking in Language Model Distillation",
    "authors": [
      "Daniil Tiapkin",
      "Daniele Calandriello",
      "Johan Ferret",
      "Sarah Perrin",
      "Nino Vieillard",
      "Alexandre Ramé",
      "Mathieu Blondel"
    ],
    "abstract": "Post-training of language models (LMs) increasingly relies on the following\ntwo stages: (i) knowledge distillation, where the LM is trained to imitate a\nlarger teacher LM, and (ii) reinforcement learning from human feedback (RLHF),\nwhere the LM is aligned by optimizing a reward model. In the second RLHF stage,\na well-known challenge is reward hacking, where the LM over-optimizes the\nreward model. Such phenomenon is in line with Goodhart's law and can lead to\ndegraded performance on the true objective. In this paper, we investigate\nwhether a similar phenomenon, that we call teacher hacking, can occur during\nknowledge distillation. This could arise because the teacher LM is itself an\nimperfect approximation of the true distribution. To study this, we propose a\ncontrolled experimental setup involving: (i) an oracle LM representing the\nground-truth distribution, (ii) a teacher LM distilled from the oracle, and\n(iii) a student LM distilled from the teacher. Our experiments reveal the\nfollowing insights. When using a fixed offline dataset for distillation,\nteacher hacking occurs; moreover, we can detect it by observing when the\noptimization process deviates from polynomial convergence laws. In contrast,\nemploying online data generation techniques effectively mitigates teacher\nhacking. More precisely, we identify data diversity as the key factor in\npreventing hacking. Overall, our findings provide a deeper understanding of the\nbenefits and limitations of distillation for building robust and efficient LMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02671v1",
    "published_date": "2025-02-04 19:26:28 UTC",
    "updated_date": "2025-02-04 19:26:28 UTC"
  },
  {
    "arxiv_id": "2502.04356v1",
    "title": "Open Foundation Models in Healthcare: Challenges, Paradoxes, and Opportunities with GenAI Driven Personalized Prescription",
    "authors": [
      "Mahdi Alkaeed",
      "Sofiat Abioye",
      "Adnan Qayyum",
      "Yosra Magdi Mekki",
      "Ilhem Berrou",
      "Mohamad Abdallah",
      "Ala Al-Fuqaha",
      "Muhammad Bilal",
      "Junaid Qadir"
    ],
    "abstract": "In response to the success of proprietary Large Language Models (LLMs) such\nas OpenAI's GPT-4, there is a growing interest in developing open,\nnon-proprietary LLMs and AI foundation models (AIFMs) for transparent use in\nacademic, scientific, and non-commercial applications. Despite their inability\nto match the refined functionalities of their proprietary counterparts, open\nmodels hold immense potential to revolutionize healthcare applications. In this\npaper, we examine the prospects of open-source LLMs and AIFMs for developing\nhealthcare applications and make two key contributions. Firstly, we present a\ncomprehensive survey of the current state-of-the-art open-source healthcare\nLLMs and AIFMs and introduce a taxonomy of these open AIFMs, categorizing their\nutility across various healthcare tasks. Secondly, to evaluate the\ngeneral-purpose applications of open LLMs in healthcare, we present a case\nstudy on personalized prescriptions. This task is particularly significant due\nto its critical role in delivering tailored, patient-specific medications that\ncan greatly improve treatment outcomes. In addition, we compare the performance\nof open-source models with proprietary models in settings with and without\nRetrieval-Augmented Generation (RAG). Our findings suggest that, although less\nrefined, open LLMs can achieve performance comparable to proprietary models\nwhen paired with grounding techniques such as RAG. Furthermore, to highlight\nthe clinical significance of LLMs-empowered personalized prescriptions, we\nperform subjective assessment through an expert clinician. We also elaborate on\nethical considerations and potential risks associated with the misuse of\npowerful LLMs and AIFMs, highlighting the need for a cautious and responsible\nimplementation in healthcare.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04356v1",
    "published_date": "2025-02-04 19:16:56 UTC",
    "updated_date": "2025-02-04 19:16:56 UTC"
  },
  {
    "arxiv_id": "2502.02659v1",
    "title": "A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)",
    "authors": [
      "Yan Li",
      "Tianyi Zhang",
      "Zechuan Li",
      "Soyeon Caren Han"
    ],
    "abstract": "Transformer-based Large Language Models (LLMs) struggle to process inputs\nexceeding their training context window, with performance degrading due to\npositional out-of-distribution (O.O.D.) that disrupt attention computations.\nExisting solutions, fine-tuning and training-free methods, are limited by\ncomputational inefficiency, attention logit outliers or loss of local\npositional information. To address this, we propose Greedy Attention Logit\nInterpolation (GALI), a training-free length extrapolation method that\nmaximizes the utilization of pretrained positional intervals while avoiding\nattention logit outliers through attention logit interpolation. The result\ndemonstrates that GALI consistently outperforms state-of-the-art training-free\nmethods. Our findings reveal that LLMs interpret positional intervals unevenly\nwithin their training context window, suggesting that extrapolating within a\nsmaller positional interval range yields superior results-even for\nshort-context tasks. GALI represents a significant step toward resolving the\npositional O.O.D. challenge, enabling more reliable long-text understanding in\nLLMs. Our implementation of GALI, along with the experiments from our paper, is\nopen-sourced at https://github.com/AcademyCityL/GALI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, under review in the conference",
    "pdf_url": "http://arxiv.org/pdf/2502.02659v1",
    "published_date": "2025-02-04 19:01:24 UTC",
    "updated_date": "2025-02-04 19:01:24 UTC"
  },
  {
    "arxiv_id": "2502.02649v2",
    "title": "Fully Autonomous AI Agents Should Not be Developed",
    "authors": [
      "Margaret Mitchell",
      "Avijit Ghosh",
      "Alexandra Sasha Luccioni",
      "Giada Pistilli"
    ],
    "abstract": "This paper argues that fully autonomous AI agents should not be developed. In\nsupport of this position, we build from prior scientific literature and current\nproduct marketing to delineate different AI agent levels and detail the ethical\nvalues at play in each, documenting trade-offs in potential benefits and risks.\nOur analysis reveals that risks to people increase with the autonomy of a\nsystem: The more control a user cedes to an AI agent, the more risks to people\narise. Particularly concerning are safety risks, which affect human life and\nimpact further values.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02649v2",
    "published_date": "2025-02-04 19:00:06 UTC",
    "updated_date": "2025-02-06 17:04:58 UTC"
  },
  {
    "arxiv_id": "2502.02631v1",
    "title": "ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization",
    "authors": [
      "Zechun Liu",
      "Changsheng Zhao",
      "Hanxian Huang",
      "Sijia Chen",
      "Jing Zhang",
      "Jiawei Zhao",
      "Scott Roy",
      "Lisa Jin",
      "Yunyang Xiong",
      "Yangyang Shi",
      "Lin Xiao",
      "Yuandong Tian",
      "Bilge Soran",
      "Raghuraman Krishnamoorthi",
      "Tijmen Blankevoort",
      "Vikas Chandra"
    ],
    "abstract": "The optimal bit-width for achieving the best trade-off between quantized\nmodel size and accuracy has been a subject of ongoing debate. While some\nadvocate for 4-bit quantization, others propose that 1.58-bit offers superior\nresults. However, the lack of a cohesive framework for different bits has left\nsuch conclusions relatively tenuous. We present ParetoQ, the first unified\nframework that facilitates rigorous comparisons across 1-bit, 1.58-bit, 2-bit,\n3-bit, and 4-bit quantization settings. Our findings reveal a notable learning\ntransition between 2 and 3 bits: For 3-bits and above, the fine-tuned models\nstay close to their original pre-trained distributions, whereas for learning\n2-bit networks or below, the representations change drastically. By optimizing\ntraining schemes and refining quantization functions, ParetoQ surpasses all\nprevious methods tailored to specific bit widths. Remarkably, our ParetoQ\nternary 600M-parameter model even outperforms the previous SoTA ternary\n3B-parameter model in accuracy, using only one-fifth of the parameters.\nExtensive experimentation shows that ternary, 2-bit, and 3-bit quantization\nmaintains comparable performance in the size-accuracy trade-off and generally\nexceeds 4-bit and binary quantization. Considering hardware constraints, 2-bit\nquantization offers promising potential for memory reduction and speedup.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02631v1",
    "published_date": "2025-02-04 18:59:26 UTC",
    "updated_date": "2025-02-04 18:59:26 UTC"
  },
  {
    "arxiv_id": "2502.02584v1",
    "title": "QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search",
    "authors": [
      "Zongyu Lin",
      "Yao Tang",
      "Xingcheng Yao",
      "Da Yin",
      "Ziniu Hu",
      "Yizhou Sun",
      "Kai-Wei Chang"
    ],
    "abstract": "Language agents have become a promising solution to complex interactive\ntasks. One of the key ingredients to the success of language agents is the\nreward model on the trajectory of the agentic workflow, which provides valuable\nguidance during training or inference. However, due to the lack of annotations\nof intermediate interactions, most existing works use an outcome reward model\nto optimize policies across entire trajectories. This may lead to sub-optimal\npolicies and hinder the overall performance. To address this, we propose QLASS\n(Q-guided Language Agent Stepwise Search), to automatically generate\nannotations by estimating Q-values in a stepwise manner for open language\nagents. By introducing a reasoning tree and performing process reward modeling,\nQLASS provides effective intermediate guidance for each step. With the stepwise\nguidance, we propose a Q-guided generation strategy to enable language agents\nto better adapt to long-term value, resulting in significant performance\nimprovement during model inference on complex interactive agent tasks. Notably,\neven with almost half the annotated data, QLASS retains strong performance,\ndemonstrating its efficiency in handling limited supervision. We also\nempirically demonstrate that QLASS can lead to more effective decision making\nthrough qualitative analysis. We will release our code and data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02584v1",
    "published_date": "2025-02-04 18:58:31 UTC",
    "updated_date": "2025-02-04 18:58:31 UTC"
  },
  {
    "arxiv_id": "2502.04355v1",
    "title": "LLM-ProS: Analyzing Large Language Models' Performance in Competitive Problem Solving",
    "authors": [
      "Md Sifat Hossain",
      "Anika Tabassum",
      "Md. Fahim Arefin",
      "Tarannum Shaila Zaman"
    ],
    "abstract": "The rapid advancement of large language models has opened new avenues for\nautomating complex problem-solving tasks such as algorithmic coding and\ncompetitive programming. This paper introduces a novel evaluation technique,\nLLM-ProS, to assess the performance of state-of-the-art LLMs on International\nCollegiate Programming Contest (ICPC) problems. Using a curated dataset of 166\nWorld Finals problems from 2011 to 2024, we benchmark the models' reasoning,\naccuracy, and efficiency. We evaluate the five models-GPT-4o, Mistral Large,\nLlama-3.1-405B, and the o1 family, consisting of o1-mini and o1-preview, across\ncritical metrics like correctness, resource utilization, and response\ncalibration. Our results reveal significant differences in the models'\nabilities to generalize, adapt, and solve novel problems. We also investigated\nthe impact of training methodologies, dataset contamination, and\nchain-of-thought reasoning on model performance. The findings provide new\ninsights into optimizing LLMs for algorithmic tasks, highlighting both\nstrengths and limitations of current models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in LLM4Code 2025 workshop proceedings",
    "pdf_url": "http://arxiv.org/pdf/2502.04355v1",
    "published_date": "2025-02-04 18:55:14 UTC",
    "updated_date": "2025-02-04 18:55:14 UTC"
  },
  {
    "arxiv_id": "2502.05215v1",
    "title": "Watermarking across Modalities for Content Tracing and Generative AI",
    "authors": [
      "Pierre Fernandez"
    ],
    "abstract": "Watermarking embeds information into digital content like images, audio, or\ntext, imperceptible to humans but robustly detectable by specific algorithms.\nThis technology has important applications in many challenges of the industry\nsuch as content moderation, tracing AI-generated content, and monitoring the\nusage of AI models. The contributions of this thesis include the development of\nnew watermarking techniques for images, audio, and text. We first introduce\nmethods for active moderation of images on social platforms. We then develop\nspecific techniques for AI-generated content. We specifically demonstrate\nmethods to adapt latent generative models to embed watermarks in all generated\ncontent, identify watermarked sections in speech, and improve watermarking in\nlarge language models with tests that ensure low false positive rates.\nFurthermore, we explore the use of digital watermarking to detect model misuse,\nincluding the detection of watermarks in language models fine-tuned on\nwatermarked text, and introduce training-free watermarks for the weights of\nlarge transformers. Through these contributions, the thesis provides effective\nsolutions for the challenges posed by the increasing use of generative AI\nmodels and the need for model monitoring and content moderation. It finally\nexamines the challenges and limitations of watermarking techniques and discuss\npotential future directions for research in this area.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "PhD thesis - webpage available at\n  https://pierrefdz.github.io/publications/phd-thesis",
    "pdf_url": "http://arxiv.org/pdf/2502.05215v1",
    "published_date": "2025-02-04 18:49:50 UTC",
    "updated_date": "2025-02-04 18:49:50 UTC"
  },
  {
    "arxiv_id": "2502.02573v1",
    "title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement",
    "authors": [
      "Soheil Abbasloo"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nnumerous fields, presenting an opportunity to revolutionize optimization\nproblem-solving, a crucial, ubiquitous, and complex domain. This paper explores\nthe proficiency of LLMs in handling Sequential Optimization Problems (SOPs). We\nintroduce WorldGen, a dynamic framework for generating unseen SOPs with\ncontrollable complexities, to evaluate LLM performance. Our initial\nobservations reveal that while LLMs perform well on simple SOPs, their\nperformance significantly degrades with increased complexity. Motivated by\nthis, we revisit philosophical hypotheses on reasoning to enhance LLM\nperformance. Inspired by the influential framework of Hegelian Dialectics, we\npropose ACE, demonstrating how the performance of LLMs in SOP contexts can be\nsignificantly improved without any retraining or further fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02573v1",
    "published_date": "2025-02-04 18:47:31 UTC",
    "updated_date": "2025-02-04 18:47:31 UTC"
  },
  {
    "arxiv_id": "2502.04354v1",
    "title": "Reviving The Classics: Active Reward Modeling in Large Language Model Alignment",
    "authors": [
      "Yunyi Shen",
      "Hao Sun",
      "Jean-François Ton"
    ],
    "abstract": "Building neural reward models from human preferences is a pivotal component\nin reinforcement learning from human feedback (RLHF) and large language model\nalignment research. Given the scarcity and high cost of human annotation, how\nto select the most informative pairs to annotate is an essential yet\nchallenging open problem. In this work, we highlight the insight that an ideal\ncomparison dataset for reward modeling should balance exploration of the\nrepresentation space and make informative comparisons between pairs with\nmoderate reward differences. Technically, challenges arise in quantifying the\ntwo objectives and efficiently prioritizing the comparisons to be annotated. To\naddress this, we propose the Fisher information-based selection strategies,\nadapt theories from the classical experimental design literature, and apply\nthem to the final linear layer of the deep neural network-based reward modeling\ntasks. Empirically, our method demonstrates remarkable performance, high\ncomputational efficiency, and stability compared to other selection methods\nfrom deep learning and classical statistical literature across multiple\nopen-source LLMs and datasets. Further ablation studies reveal that\nincorporating cross-prompt comparisons in active reward modeling significantly\nenhances labeling efficiency, shedding light on the potential for improved\nannotation strategies in RLHF.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04354v1",
    "published_date": "2025-02-04 18:47:11 UTC",
    "updated_date": "2025-02-04 18:47:11 UTC"
  },
  {
    "arxiv_id": "2502.02567v1",
    "title": "Fairness in Survival Analysis: A Novel Conditional Mutual Information Augmentation Approach",
    "authors": [
      "Tianyang Xie",
      "Yong Ge"
    ],
    "abstract": "Survival analysis, a vital tool for predicting the time to event, has been\nused in many domains such as healthcare, criminal justice, and finance. Like\nclassification tasks, survival analysis can exhibit bias against disadvantaged\ngroups, often due to biases inherent in data or algorithms. Several studies in\nboth the IS and CS communities have attempted to address fairness in survival\nanalysis. However, existing methods often overlook the importance of prediction\nfairness at pre-defined evaluation time points, which is crucial in real-world\napplications where decision making often hinges on specific time frames. To\naddress this critical research gap, we introduce a new fairness concept:\nequalized odds (EO) in survival analysis, which emphasizes prediction fairness\nat pre-defined time points. To achieve the EO fairness in survival analysis, we\npropose a Conditional Mutual Information Augmentation (CMIA) approach, which\nfeatures a novel fairness regularization term based on conditional mutual\ninformation and an innovative censored data augmentation technique. Our CMIA\napproach can effectively balance prediction accuracy and fairness, and it is\napplicable to various survival models. We evaluate the CMIA approach against\nseveral state-of-the-art methods within three different application domains,\nand the results demonstrate that CMIA consistently reduces prediction disparity\nwhile maintaining good accuracy and significantly outperforms the other\ncompeting methods across multiple datasets and survival models (e.g., linear\nCOX, deep AFT).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02567v1",
    "published_date": "2025-02-04 18:40:38 UTC",
    "updated_date": "2025-02-04 18:40:38 UTC"
  },
  {
    "arxiv_id": "2502.02630v1",
    "title": "scBIT: Integrating Single-cell Transcriptomic Data into fMRI-based Prediction for Alzheimer's Disease Diagnosis",
    "authors": [
      "Yu-An Huang",
      "Yao Hu",
      "Yue-Chao Li",
      "Xiyue Cao",
      "Xinyuan Li",
      "Kay Chen Tan",
      "Zhu-Hong You",
      "Zhi-An Huang"
    ],
    "abstract": "Functional MRI (fMRI) and single-cell transcriptomics are pivotal in\nAlzheimer's disease (AD) research, each providing unique insights into neural\nfunction and molecular mechanisms. However, integrating these complementary\nmodalities remains largely unexplored. Here, we introduce scBIT, a novel method\nfor enhancing AD prediction by combining fMRI with single-nucleus RNA (snRNA).\nscBIT leverages snRNA as an auxiliary modality, significantly improving\nfMRI-based prediction models and providing comprehensive interpretability. It\nemploys a sampling strategy to segment snRNA data into cell-type-specific gene\nnetworks and utilizes a self-explainable graph neural network to extract\ncritical subgraphs. Additionally, we use demographic and genetic similarities\nto pair snRNA and fMRI data across individuals, enabling robust cross-modal\nlearning. Extensive experiments validate scBIT's effectiveness in revealing\nintricate brain region-gene associations and enhancing diagnostic prediction\naccuracy. By advancing brain imaging transcriptomics to the single-cell level,\nscBIT sheds new light on biomarker discovery in AD research. Experimental\nresults show that incorporating snRNA data into the scBIT model significantly\nboosts accuracy, improving binary classification by 3.39% and five-class\nclassification by 26.59%. The codes were implemented in Python and have been\nreleased on GitHub (https://github.com/77YQ77/scBIT) and Zenodo\n(https://zenodo.org/records/11599030) with detailed instructions.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "31 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02630v1",
    "published_date": "2025-02-04 18:37:46 UTC",
    "updated_date": "2025-02-04 18:37:46 UTC"
  },
  {
    "arxiv_id": "2502.02562v1",
    "title": "Learning the RoPEs: Better 2D and 3D Position Encodings with STRING",
    "authors": [
      "Connor Schenck",
      "Isaac Reid",
      "Mithun George Jacob",
      "Alex Bewley",
      "Joshua Ainslie",
      "David Rendleman",
      "Deepali Jain",
      "Mohit Sharma",
      "Avinava Dubey",
      "Ayzaan Wahid",
      "Sumeet Singh",
      "René Wagner",
      "Tianli Ding",
      "Chuyuan Fu",
      "Arunkumar Byravan",
      "Jake Varley",
      "Alexey Gritsenko",
      "Matthias Minderer",
      "Dmitry Kalashnikov",
      "Jonathan Tompson",
      "Vikas Sindhwani",
      "Krzysztof Choromanski"
    ],
    "abstract": "We introduce STRING: Separable Translationally Invariant Position Encodings.\nSTRING extends Rotary Position Encodings, a recently proposed and widely used\nalgorithm in large language models, via a unifying theoretical framework.\nImportantly, STRING still provides exact translation invariance, including\ntoken coordinates of arbitrary dimensionality, whilst maintaining a low\ncomputational footprint. These properties are especially important in robotics,\nwhere efficient 3D token representation is key. We integrate STRING into Vision\nTransformers with RGB(-D) inputs (color plus optional depth), showing\nsubstantial gains, e.g. in open-vocabulary object detection and for robotics\ncontrollers. We complement our experiments with a rigorous mathematical\nanalysis, proving the universality of our methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Videos of STRING-based robotics controllers can be found here:\n  https://sites.google.com/view/string-robotics",
    "pdf_url": "http://arxiv.org/pdf/2502.02562v1",
    "published_date": "2025-02-04 18:37:17 UTC",
    "updated_date": "2025-02-04 18:37:17 UTC"
  },
  {
    "arxiv_id": "2502.02561v1",
    "title": "Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents",
    "authors": [
      "Shayan Kiyani",
      "George Pappas",
      "Aaron Roth",
      "Hamed Hassani"
    ],
    "abstract": "A fundamental question in data-driven decision making is how to quantify the\nuncertainty of predictions in ways that can usefully inform downstream action.\nThis interface between prediction uncertainty and decision-making is especially\nimportant in risk-sensitive domains, such as medicine. In this paper, we\ndevelop decision-theoretic foundations that connect uncertainty quantification\nusing prediction sets with risk-averse decision-making. Specifically, we answer\nthree fundamental questions: (1) What is the correct notion of uncertainty\nquantification for risk-averse decision makers? We prove that prediction sets\nare optimal for decision makers who wish to optimize their value at risk. (2)\nWhat is the optimal policy that a risk averse decision maker should use to map\nprediction sets to actions? We show that a simple max-min decision policy is\noptimal for risk-averse decision makers. Finally, (3) How can we derive\nprediction sets that are optimal for such decision makers? We provide an exact\ncharacterization in the population regime and a distribution free finite-sample\nconstruction. Answering these questions naturally leads to an algorithm,\nRisk-Averse Calibration (RAC), which follows a provably optimal design for\nderiving action policies from predictions. RAC is designed to be both\npractical-capable of leveraging the quality of predictions in a black-box\nmanner to enhance downstream utility-and safe-adhering to a user-defined risk\nthreshold and optimizing the corresponding risk quantile of the user's\ndownstream utility. Finally, we experimentally demonstrate the significant\nadvantages of RAC in applications such as medical diagnosis and recommendation\nsystems. Specifically, we show that RAC achieves a substantially improved\ntrade-off between safety and utility, offering higher utility compared to\nexisting methods while maintaining the safety guarantee.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02561v1",
    "published_date": "2025-02-04 18:37:10 UTC",
    "updated_date": "2025-02-04 18:37:10 UTC"
  },
  {
    "arxiv_id": "2502.02629v1",
    "title": "Graph Structure Learning for Tumor Microenvironment with Cell Type Annotation from non-spatial scRNA-seq data",
    "authors": [
      "Yu-An Huang",
      "Yue-Chao Li",
      "Hai-Ru You",
      "Jie Pan",
      "Xiyue Cao",
      "Xinyuan Li",
      "Zhi-An Huang",
      "Zhu-Hong You"
    ],
    "abstract": "The exploration of cellular heterogeneity within the tumor microenvironment\n(TME) via single-cell RNA sequencing (scRNA-seq) is essential for understanding\ncancer progression and response to therapy. Current scRNA-seq approaches,\nhowever, lack spatial context and rely on incomplete datasets of\nligand-receptor interactions (LRIs), limiting accurate cell type annotation and\ncell-cell communication (CCC) inference. This study addresses these challenges\nusing a novel graph neural network (GNN) model that enhances cell type\nprediction and cell interaction analysis. Our study utilized a dataset\nconsisting of 49,020 cells from 19 patients across three cancer types:\nLeukemia, Breast Invasive Carcinoma, and Colorectal Cancer. The proposed scGSL\nmodel demonstrated robust performance, achieving an average accuracy of 84.83%,\nprecision of 86.23%, recall of 81.51%, and an F1 score of 80.92% across all\ndatasets. These metrics represent a significant enhancement over existing\nmethods, which typically exhibit lower performance metrics. Additionally, by\nreviewing existing literature on gene interactions within the TME, the scGSL\nmodel proves to robustly identify biologically meaningful gene interactions in\nan unsupervised manner, validated by significant expression differences in key\ngene pairs across various cancers. The source code and data used in this paper\ncan be found in https://github.com/LiYuechao1998/scGSL.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "29 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02629v1",
    "published_date": "2025-02-04 18:28:25 UTC",
    "updated_date": "2025-02-04 18:28:25 UTC"
  },
  {
    "arxiv_id": "2502.02549v1",
    "title": "Anytime Incremental $ρ$POMDP Planning in Continuous Spaces",
    "authors": [
      "Ron Benchetrit",
      "Idan Lev-Yehudi",
      "Andrey Zhitnikov",
      "Vadim Indelman"
    ],
    "abstract": "Partially Observable Markov Decision Processes (POMDPs) provide a robust\nframework for decision-making under uncertainty in applications such as\nautonomous driving and robotic exploration. Their extension, $\\rho$POMDPs,\nintroduces belief-dependent rewards, enabling explicit reasoning about\nuncertainty. Existing online $\\rho$POMDP solvers for continuous spaces rely on\nfixed belief representations, limiting adaptability and refinement - critical\nfor tasks such as information-gathering. We present $\\rho$POMCPOW, an anytime\nsolver that dynamically refines belief representations, with formal guarantees\nof improvement over time. To mitigate the high computational cost of updating\nbelief-dependent rewards, we propose a novel incremental computation approach.\nWe demonstrate its effectiveness for common entropy estimators, reducing\ncomputational cost by orders of magnitude. Experimental results show that\n$\\rho$POMCPOW outperforms state-of-the-art solvers in both efficiency and\nsolution quality.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02549v1",
    "published_date": "2025-02-04 18:19:40 UTC",
    "updated_date": "2025-02-04 18:19:40 UTC"
  },
  {
    "arxiv_id": "2502.02544v1",
    "title": "Addressing Label Shift in Distributed Learning via Entropy Regularization",
    "authors": [
      "Zhiyuan Wu",
      "Changkyu Choi",
      "Xiangcheng Cao",
      "Volkan Cevher",
      "Ali Ramezani-Kebrya"
    ],
    "abstract": "We address the challenge of minimizing true risk in multi-node distributed\nlearning. These systems are frequently exposed to both inter-node and\nintra-node label shifts, which present a critical obstacle to effectively\noptimizing model performance while ensuring that data remains confined to each\nnode. To tackle this, we propose the Versatile Robust Label Shift (VRLS)\nmethod, which enhances the maximum likelihood estimation of the test-to-train\nlabel density ratio. VRLS incorporates Shannon entropy-based regularization and\nadjusts the density ratio during training to better handle label shifts at the\ntest time. In multi-node learning environments, VRLS further extends its\ncapabilities by learning and adapting density ratios across nodes, effectively\nmitigating label shifts and improving overall model performance. Experiments\nconducted on MNIST, Fashion MNIST, and CIFAR-10 demonstrate the effectiveness\nof VRLS, outperforming baselines by up to 20% in imbalanced settings. These\nresults highlight the significant improvements VRLS offers in addressing label\nshifts. Our theoretical analysis further supports this by establishing\nhigh-probability bounds on estimation errors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the International Conference on Learning Representations\n  (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.02544v1",
    "published_date": "2025-02-04 18:14:27 UTC",
    "updated_date": "2025-02-04 18:14:27 UTC"
  },
  {
    "arxiv_id": "2502.04353v1",
    "title": "CognArtive: Large Language Models for Automating Art Analysis and Decoding Aesthetic Elements",
    "authors": [
      "Afshin Khadangi",
      "Amir Sartipi",
      "Igor Tchappi",
      "Gilbert Fridgen"
    ],
    "abstract": "Art, as a universal language, can be interpreted in diverse ways, with\nartworks embodying profound meanings and nuances. The advent of Large Language\nModels (LLMs) and the availability of Multimodal Large Language Models (MLLMs)\nraise the question of how these transformative models can be used to assess and\ninterpret the artistic elements of artworks. While research has been conducted\nin this domain, to the best of our knowledge, a deep and detailed understanding\nof the technical and expressive features of artworks using LLMs has not been\nexplored. In this study, we investigate the automation of a formal art analysis\nframework to analyze a high-throughput number of artworks rapidly and examine\nhow their patterns evolve over time. We explore how LLMs can decode artistic\nexpressions, visual elements, composition, and techniques, revealing emerging\npatterns that develop across periods. Finally, we discuss the strengths and\nlimitations of LLMs in this context, emphasizing their ability to process vast\nquantities of art-related data and generate insightful interpretations. Due to\nthe exhaustive and granular nature of the results, we have developed\ninteractive data visualizations, available online\nhttps://cognartive.github.io/, to enhance understanding and accessibility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04353v1",
    "published_date": "2025-02-04 18:08:23 UTC",
    "updated_date": "2025-02-04 18:08:23 UTC"
  },
  {
    "arxiv_id": "2502.02538v1",
    "title": "Flow Q-Learning",
    "authors": [
      "Seohong Park",
      "Qiyang Li",
      "Sergey Levine"
    ],
    "abstract": "We present flow Q-learning (FQL), a simple and performant offline\nreinforcement learning (RL) method that leverages an expressive flow-matching\npolicy to model arbitrarily complex action distributions in data. Training a\nflow policy with RL is a tricky problem, due to the iterative nature of the\naction generation process. We address this challenge by training an expressive\none-step policy with RL, rather than directly guiding an iterative flow policy\nto maximize values. This way, we can completely avoid unstable recursive\nbackpropagation, eliminate costly iterative action generation at test time, yet\nstill mostly maintain expressivity. We experimentally show that FQL leads to\nstrong performance across 73 challenging state- and pixel-based OGBench and\nD4RL tasks in offline RL and offline-to-online RL. Project page:\nhttps://seohong.me/projects/fql/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02538v1",
    "published_date": "2025-02-04 18:04:05 UTC",
    "updated_date": "2025-02-04 18:04:05 UTC"
  },
  {
    "arxiv_id": "2502.02533v1",
    "title": "Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies",
    "authors": [
      "Han Zhou",
      "Xingchen Wan",
      "Ruoxi Sun",
      "Hamid Palangi",
      "Shariq Iqbal",
      "Ivan Vulić",
      "Anna Korhonen",
      "Sercan Ö. Arık"
    ],
    "abstract": "Large language models, employed as multiple agents that interact and\ncollaborate with each other, have excelled at solving complex tasks. The agents\nare programmed with prompts that declare their functionality, along with the\ntopologies that orchestrate interactions across agents. Designing prompts and\ntopologies for multi-agent systems (MAS) is inherently complex. To automate the\nentire design process, we first conduct an in-depth analysis of the design\nspace aiming to understand the factors behind building effective MAS. We reveal\nthat prompts together with topologies play critical roles in enabling more\neffective MAS design. Based on the insights, we propose Multi-Agent System\nSearch (MASS), a MAS optimization framework that efficiently exploits the\ncomplex MAS design space by interleaving its optimization stages, from local to\nglobal, from prompts to topologies, over three stages: 1) block-level (local)\nprompt optimization; 2) workflow topology optimization; 3) workflow-level\n(global) prompt optimization, where each stage is conditioned on the\niteratively optimized prompts/topologies from former stages. We show that\nMASS-optimized multi-agent systems outperform a spectrum of existing\nalternatives by a substantial margin. Based on the MASS-found systems, we\nfinally propose design principles behind building effective multi-agent\nsystems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures, 1 table (30 pages, 9 figures, 5 tables including\n  references and appendices)",
    "pdf_url": "http://arxiv.org/pdf/2502.02533v1",
    "published_date": "2025-02-04 17:56:44 UTC",
    "updated_date": "2025-02-04 17:56:44 UTC"
  },
  {
    "arxiv_id": "2502.02528v1",
    "title": "Why human-AI relationships need socioaffective alignment",
    "authors": [
      "Hannah Rose Kirk",
      "Iason Gabriel",
      "Chris Summerfield",
      "Bertie Vidgen",
      "Scott A. Hale"
    ],
    "abstract": "Humans strive to design safe AI systems that align with our goals and remain\nunder our control. However, as AI capabilities advance, we face a new\nchallenge: the emergence of deeper, more persistent relationships between\nhumans and AI systems. We explore how increasingly capable AI agents may\ngenerate the perception of deeper relationships with users, especially as AI\nbecomes more personalised and agentic. This shift, from transactional\ninteraction to ongoing sustained social engagement with AI, necessitates a new\nfocus on socioaffective alignment-how an AI system behaves within the social\nand psychological ecosystem co-created with its user, where preferences and\nperceptions evolve through mutual influence. Addressing these dynamics involves\nresolving key intrapersonal dilemmas, including balancing immediate versus\nlong-term well-being, protecting autonomy, and managing AI companionship\nalongside the desire to preserve human social bonds. By framing these\nchallenges through a notion of basic psychological needs, we seek AI systems\nthat support, rather than exploit, our fundamental nature as social and\nemotional beings.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02528v1",
    "published_date": "2025-02-04 17:50:08 UTC",
    "updated_date": "2025-02-04 17:50:08 UTC"
  },
  {
    "arxiv_id": "2502.02516v1",
    "title": "Adaptive Exploration for Multi-Reward Multi-Policy Evaluation",
    "authors": [
      "Alessio Russo",
      "Aldo Pacchiano"
    ],
    "abstract": "We study the policy evaluation problem in an online multi-reward multi-policy\ndiscounted setting, where multiple reward functions must be evaluated\nsimultaneously for different policies. We adopt an $(\\epsilon,\\delta)$-PAC\nperspective to achieve $\\epsilon$-accurate estimates with high confidence\nacross finite or convex sets of rewards, a setting that has not been\ninvestigated in the literature. Building on prior work on Multi-Reward Best\nPolicy Identification, we adapt the MR-NaS exploration scheme to jointly\nminimize sample complexity for evaluating different policies across different\nreward sets. Our approach leverages an instance-specific lower bound revealing\nhow the sample complexity scales with a measure of value deviation, guiding the\ndesign of an efficient exploration policy. Although computing this bound\nentails a hard non-convex optimization, we propose an efficient convex\napproximation that holds for both finite and convex reward sets. Experiments in\ntabular domains demonstrate the effectiveness of this adaptive exploration\nscheme.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02516v1",
    "published_date": "2025-02-04 17:35:51 UTC",
    "updated_date": "2025-02-04 17:35:51 UTC"
  },
  {
    "arxiv_id": "2502.02508v1",
    "title": "Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search",
    "authors": [
      "Maohao Shen",
      "Guangtao Zeng",
      "Zhenting Qi",
      "Zhang-Wei Hong",
      "Zhenfang Chen",
      "Wei Lu",
      "Gregory Wornell",
      "Subhro Das",
      "David Cox",
      "Chuang Gan"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities across diverse domains. Recent studies have shown that increasing\ntest-time computation enhances LLMs' reasoning capabilities. This typically\ninvolves extensive sampling at inference time guided by an external LLM\nverifier, resulting in a two-player system. Despite external guidance, the\neffectiveness of this system demonstrates the potential of a single LLM to\ntackle complex tasks. Thus, we pose a new research problem: Can we internalize\nthe searching capabilities to fundamentally enhance the reasoning abilities of\na single LLM? This work explores an orthogonal direction focusing on\npost-training LLMs for autoregressive searching (i.e., an extended reasoning\nprocess with self-reflection and self-exploration of new strategies). To\nachieve this, we propose the Chain-of-Action-Thought (COAT) reasoning and a\ntwo-stage training paradigm: 1) a small-scale format tuning stage to\ninternalize the COAT reasoning format and 2) a large-scale self-improvement\nstage leveraging reinforcement learning. Our approach results in Satori, a 7B\nLLM trained on open-source models and data. Extensive empirical evaluations\ndemonstrate that Satori achieves state-of-the-art performance on mathematical\nreasoning benchmarks while exhibits strong generalization to out-of-domain\ntasks. Code, data, and models will be fully open-sourced.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02508v1",
    "published_date": "2025-02-04 17:26:58 UTC",
    "updated_date": "2025-02-04 17:26:58 UTC"
  },
  {
    "arxiv_id": "2502.02504v1",
    "title": "Unified Spatial-Temporal Edge-Enhanced Graph Networks for Pedestrian Trajectory Prediction",
    "authors": [
      "Ruochen Li",
      "Tanqiu Qiao",
      "Stamos Katsigiannis",
      "Zhanxing Zhu",
      "Hubert P. H. Shum"
    ],
    "abstract": "Pedestrian trajectory prediction aims to forecast future movements based on\nhistorical paths. Spatial-temporal (ST) methods often separately model spatial\ninteractions among pedestrians and temporal dependencies of individuals. They\noverlook the direct impacts of interactions among different pedestrians across\nvarious time steps (i.e., high-order cross-time interactions). This limits\ntheir ability to capture ST inter-dependencies and hinders prediction\nperformance. To address these limitations, we propose UniEdge with three major\ndesigns. Firstly, we introduce a unified ST graph data structure that\nsimplifies high-order cross-time interactions into first-order relationships,\nenabling the learning of ST inter-dependencies in a single step. This avoids\nthe information loss caused by multi-step aggregation. Secondly, traditional\nGNNs focus on aggregating pedestrian node features, neglecting the propagation\nof implicit interaction patterns encoded in edge features. We propose the\nEdge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN), a novel dual-graph\nnetwork that jointly models explicit N2N social interactions among pedestrians\nand implicit E2E influence propagation across these interaction patterns.\nFinally, to overcome the limited receptive fields and challenges in capturing\nlong-range dependencies of auto-regressive architectures, we introduce a\ntransformer encoder-based predictor that enables global modeling of temporal\ncorrelation. UniEdge outperforms state-of-the-arts on multiple datasets,\nincluding ETH, UCY, and SDD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02504v1",
    "published_date": "2025-02-04 17:18:54 UTC",
    "updated_date": "2025-02-04 17:18:54 UTC"
  },
  {
    "arxiv_id": "2502.04352v1",
    "title": "Investigating the Robustness of Deductive Reasoning with Large Language Models",
    "authors": [
      "Fabian Hoppe",
      "Filip Ilievski",
      "Jan-Christoph Kalo"
    ],
    "abstract": "Large Language Models (LLMs) have been shown to achieve impressive results\nfor many reasoning-based Natural Language Processing (NLP) tasks, suggesting a\ndegree of deductive reasoning capability. However, it remains unclear to which\nextent LLMs, in both informal and autoformalisation methods, are robust on\nlogical deduction tasks. Moreover, while many LLM-based deduction methods have\nbeen proposed, there is a lack of a systematic study that analyses the impact\nof their design components. Addressing these two challenges, we propose the\nfirst study of the robustness of LLM-based deductive reasoning methods. We\ndevise a framework with two families of perturbations: adversarial noise and\ncounterfactual statements, which jointly generate seven perturbed datasets. We\norganize the landscape of LLM reasoners according to their reasoning format,\nformalisation syntax, and feedback for error recovery. The results show that\nadversarial noise affects autoformalisation, while counterfactual statements\ninfluence all approaches. Detailed feedback does not improve overall accuracy\ndespite reducing syntax errors, pointing to the challenge of LLM-based methods\nto self-correct effectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04352v1",
    "published_date": "2025-02-04 17:16:51 UTC",
    "updated_date": "2025-02-04 17:16:51 UTC"
  },
  {
    "arxiv_id": "2502.05214v2",
    "title": "CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models",
    "authors": [
      "Amy Rafferty",
      "Rishi Ramaesh",
      "Ajitha Rajan"
    ],
    "abstract": "Deep learning models for medical image classification tasks are becoming\nwidely implemented in AI-assisted diagnostic tools, aiming to enhance\ndiagnostic accuracy, reduce clinician workloads, and improve patient outcomes.\nHowever, their vulnerability to adversarial attacks poses significant risks to\npatient safety. Current attack methodologies use general techniques such as\nmodel querying or pixel value perturbations to generate adversarial examples\ndesigned to fool a model. These approaches may not adequately address the\nunique characteristics of clinical errors stemming from missed or incorrectly\nidentified clinical features. We propose the Concept-based Report Perturbation\nAttack (CoRPA), a clinically-focused black-box adversarial attack framework\ntailored to the medical imaging domain. CoRPA leverages clinical concepts to\ngenerate adversarial radiological reports and images that closely mirror\nrealistic clinical misdiagnosis scenarios. We demonstrate the utility of CoRPA\nusing the MIMIC-CXR-JPG dataset of chest X-rays and radiological reports. Our\nevaluation reveals that deep learning models exhibiting strong resilience to\nconventional adversarial attacks are significantly less robust when subjected\nto CoRPA's clinically-focused perturbations. This underscores the importance of\naddressing domain-specific vulnerabilities in medical AI systems. By\nintroducing a specialized adversarial attack framework, this study provides a\nfoundation for developing robust, real-world-ready AI models in healthcare,\nensuring their safe and reliable deployment in high-stakes clinical\nenvironments.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05214v2",
    "published_date": "2025-02-04 17:14:31 UTC",
    "updated_date": "2025-03-28 15:34:58 UTC"
  },
  {
    "arxiv_id": "2502.02495v3",
    "title": "The Causal-Effect Score in Data Management",
    "authors": [
      "Felipe Azua",
      "Leopoldo Bertossi"
    ],
    "abstract": "The Causal Effect (CE) is a numerical measure of causal influence of\nvariables on observed results. Despite being widely used in many areas, only\npreliminary attempts have been made to use CE as an attribution score in data\nmanagement, to measure the causal strength of tuples for query answering in\ndatabases. In this work, we introduce, generalize and investigate the so-called\nCausal-Effect Score in the context of classical and probabilistic databases.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "To appear in Proceedings of the 4th Conference on Causal Learning and\n  Reasoning, 2025. This is the camera-ready version, and included a couple of\n  new references",
    "pdf_url": "http://arxiv.org/pdf/2502.02495v3",
    "published_date": "2025-02-04 17:12:23 UTC",
    "updated_date": "2025-02-28 00:40:10 UTC"
  },
  {
    "arxiv_id": "2502.02489v1",
    "title": "A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation",
    "authors": [
      "Edward Ellis",
      "Andrew Bulpitt",
      "Nasim Parsa",
      "Michael F Byrne",
      "Sharib Ali"
    ],
    "abstract": "Ultrasound (US) imaging is clinically invaluable due to its noninvasive and\nsafe nature. However, interpreting US images is challenging, requires\nsignificant expertise, and time, and is often prone to errors. Deep learning\noffers assistive solutions such as segmentation. Supervised methods rely on\nlarge, high-quality, and consistently labeled datasets, which are challenging\nto curate. Moreover, these methods tend to underperform on out-of-distribution\ndata, limiting their clinical utility. Self-supervised learning (SSL) has\nemerged as a promising alternative, leveraging unlabeled data to enhance model\nperformance and generalisability. We introduce a contrastive SSL approach\ntailored for B-mode US images, incorporating a novel Relation Contrastive Loss\n(RCL). RCL encourages learning of distinct features by differentiating positive\nand negative sample pairs through a learnable metric. Additionally, we propose\nspatial and frequency-based augmentation strategies for the representation\nlearning on US images. Our approach significantly outperforms traditional\nsupervised segmentation methods across three public breast US datasets,\nparticularly in data-limited scenarios. Notable improvements on the Dice\nsimilarity metric include a 4% increase on 20% and 50% of the BUSI dataset,\nnearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4%\nand 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively.\nFurthermore, we demonstrate superior generalisability on the\nout-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6%\ncompared to the supervised baseline using 20% and 50% of the BUSI and BrEaST\ntraining data, respectively. Our research highlights that domain-inspired SSL\ncan improve US segmentation, especially under data-limited conditions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "12",
    "pdf_url": "http://arxiv.org/pdf/2502.02489v1",
    "published_date": "2025-02-04 17:06:41 UTC",
    "updated_date": "2025-02-04 17:06:41 UTC"
  },
  {
    "arxiv_id": "2502.04351v1",
    "title": "NER4all or Context is All You Need: Using LLMs for low-effort, high-performance NER on historical texts. A humanities informed approach",
    "authors": [
      "Torsten Hiltmann",
      "Martin Dröge",
      "Nicole Dresselhaus",
      "Till Grallert",
      "Melanie Althage",
      "Paul Bayer",
      "Sophie Eckenstaler",
      "Koray Mendi",
      "Jascha Marijn Schmitz",
      "Philipp Schneider",
      "Wiebke Sczeponik",
      "Anica Skibba"
    ],
    "abstract": "Named entity recognition (NER) is a core task for historical research in\nautomatically establishing all references to people, places, events and the\nlike. Yet, do to the high linguistic and genre diversity of sources, only\nlimited canonisation of spellings, the level of required historical domain\nknowledge, and the scarcity of annotated training data, established approaches\nto natural language processing (NLP) have been both extremely expensive and\nyielded only unsatisfactory results in terms of recall and precision. Our paper\nintroduces a new approach. We demonstrate how readily-available,\nstate-of-the-art LLMs significantly outperform two leading NLP frameworks,\nspaCy and flair, for NER in historical documents by seven to twentytwo percent\nhigher F1-Scores. Our ablation study shows how providing historical context to\nthe task and a bit of persona modelling that turns focus away from a purely\nlinguistic approach are core to a successful prompting strategy. We also\ndemonstrate that, contrary to our expectations, providing increasing numbers of\nexamples in few-shot approaches does not improve recall or precision below a\nthreshold of 16-shot. In consequence, our approach democratises access to NER\nfor all historians by removing the barrier of scripting languages and\ncomputational skills required for established NLP tools and instead leveraging\nnatural language prompts and consumer-grade tools and frontends.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04351v1",
    "published_date": "2025-02-04 16:54:23 UTC",
    "updated_date": "2025-02-04 16:54:23 UTC"
  },
  {
    "arxiv_id": "2502.02471v1",
    "title": "Mind the Gap: Evaluating Patch Embeddings from General-Purpose and Histopathology Foundation Models for Cell Segmentation and Classification",
    "authors": [
      "Valentina Vadori",
      "Antonella Peruffo",
      "Jean-Marie Graïc",
      "Livio Finos",
      "Enrico Grisan"
    ],
    "abstract": "Recent advancements in foundation models have transformed computer vision,\ndriving significant performance improvements across diverse domains, including\ndigital histopathology. However, the advantages of domain-specific\nhistopathology foundation models over general-purpose models for specialized\ntasks such as cell analysis remain underexplored. This study investigates the\nrepresentation learning gap between these two categories by analyzing\nmulti-level patch embeddings applied to cell instance segmentation and\nclassification. We implement an encoder-decoder architecture with a consistent\ndecoder and various encoders. These include convolutional, vision transformer\n(ViT), and hybrid encoders pre-trained on ImageNet-22K or LVD-142M,\nrepresenting general-purpose foundation models. These are compared against ViT\nencoders from the recently released UNI, Virchow2, and Prov-GigaPath foundation\nmodels, trained on patches extracted from hundreds of thousands of\nhistopathology whole-slide images. The decoder integrates patch embeddings from\ndifferent encoder depths via skip connections to generate semantic and distance\nmaps. These maps are then post-processed to create instance segmentation masks\nwhere each label corresponds to an individual cell and to perform cell-type\nclassification. All encoders remain frozen during training to assess their\npre-trained feature extraction capabilities. Using the PanNuke and CoNIC\nhistopathology datasets, and the newly introduced Nissl-stained CytoDArk0\ndataset for brain cytoarchitecture studies, we evaluate instance-level\ndetection, segmentation accuracy, and cell-type classification. This study\nprovides insights into the comparative strengths and limitations of\ngeneral-purpose vs. histopathology foundation models, offering guidance for\nmodel selection in cell-focused histopathology and brain cytoarchitecture\nanalysis workflows.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02471v1",
    "published_date": "2025-02-04 16:47:00 UTC",
    "updated_date": "2025-02-04 16:47:00 UTC"
  },
  {
    "arxiv_id": "2502.02470v2",
    "title": "Modular Training of Neural Networks aids Interpretability",
    "authors": [
      "Satvik Golechha",
      "Maheep Chaudhary",
      "Joan Velja",
      "Alessandro Abate",
      "Nandi Schoots"
    ],
    "abstract": "An approach to improve neural network interpretability is via clusterability,\ni.e., splitting a model into disjoint clusters that can be studied\nindependently. We define a measure for clusterability and show that pre-trained\nmodels form highly enmeshed clusters via spectral graph clustering. We thus\ntrain models to be more modular using a \"clusterability loss\" function that\nencourages the formation of non-interacting clusters. Using automated\ninterpretability techniques, we show that our method can help train models that\nare more modular and learn different, disjoint, and smaller circuits. We\ninvestigate CNNs trained on MNIST and CIFAR, small transformers trained on\nmodular addition, and language models. Our approach provides a promising\ndirection for training neural networks that learn simpler functions and are\neasier to interpret.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, under review. arXiv admin note: text overlap with\n  arXiv:2409.15747 (author note: this is an extension of that workshop paper\n  but has different authors)",
    "pdf_url": "http://arxiv.org/pdf/2502.02470v2",
    "published_date": "2025-02-04 16:44:38 UTC",
    "updated_date": "2025-02-07 01:40:17 UTC"
  },
  {
    "arxiv_id": "2502.02456v4",
    "title": "Model Human Learners: Computational Models to Guide Instructional Design",
    "authors": [
      "Christopher J. MacLellan"
    ],
    "abstract": "Instructional designers face an overwhelming array of design choices, making\nit challenging to identify the most effective interventions. To address this\nissue, I propose the concept of a Model Human Learner, a unified computational\nmodel of learning that can aid designers in evaluating candidate interventions.\nThis paper presents the first successful demonstration of this concept, showing\nthat a computational model can accurately predict the outcomes of two human A/B\nexperiments -- one testing a problem sequencing intervention and the other\ntesting an item design intervention. It also demonstrates that such a model can\ngenerate learning curves without requiring human data and provide theoretical\ninsights into why an instructional intervention is effective. These findings\nlay the groundwork for future Model Human Learners that integrate cognitive and\nlearning theories to support instructional design across diverse tasks and\ninterventions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.HC",
    "comment": "Published at CogSci 2025; 6 pages, 6 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.02456v4",
    "published_date": "2025-02-04 16:24:42 UTC",
    "updated_date": "2025-05-10 16:50:38 UTC"
  },
  {
    "arxiv_id": "2502.02628v1",
    "title": "e-SimFT: Alignment of Generative Models with Simulation Feedback for Pareto-Front Design Exploration",
    "authors": [
      "Hyunmin Cheong",
      "Mohammadmehdi Ataei",
      "Amir Hosein Khasahmadi",
      "Pradeep Kumar Jayaraman"
    ],
    "abstract": "Deep generative models have recently shown success in solving complex\nengineering design problems where models predict solutions that address the\ndesign requirements specified as input. However, there remains a challenge in\naligning such models for effective design exploration. For many design\nproblems, finding a solution that meets all the requirements is infeasible. In\nsuch a case, engineers prefer to obtain a set of Pareto optimal solutions with\nrespect to those requirements, but uniform sampling of generative models may\nnot yield a useful Pareto front. To address this gap, we introduce a new\nframework for Pareto-front design exploration with simulation fine-tuned\ngenerative models. First, the framework adopts preference alignment methods\ndeveloped for Large Language Models (LLMs) and showcases the first application\nin fine-tuning a generative model for engineering design. The important\ndistinction here is that we use a simulator instead of humans to provide\naccurate and scalable feedback. Next, we propose epsilon-sampling, inspired by\nthe epsilon-constraint method used for Pareto-front generation with classical\noptimization algorithms, to construct a high-quality Pareto front with the\nfine-tuned models. Our framework, named e-SimFT, is shown to produce\nbetter-quality Pareto fronts than existing multi-objective alignment methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02628v1",
    "published_date": "2025-02-04 16:17:22 UTC",
    "updated_date": "2025-02-04 16:17:22 UTC"
  },
  {
    "arxiv_id": "2502.02446v1",
    "title": "Towards graph neural networks for provably solving convex optimization problems",
    "authors": [
      "Chendi Qian",
      "Christopher Morris"
    ],
    "abstract": "Recently, message-passing graph neural networks (MPNNs) have shown potential\nfor solving combinatorial and continuous optimization problems due to their\nability to capture variable-constraint interactions. While existing approaches\nleverage MPNNs to approximate solutions or warm-start traditional solvers, they\noften lack guarantees for feasibility, particularly in convex optimization\nsettings. Here, we propose an iterative MPNN framework to solve convex\noptimization problems with provable feasibility guarantees. First, we\ndemonstrate that MPNNs can provably simulate standard interior-point methods\nfor solving quadratic problems with linear constraints, covering relevant\nproblems such as SVMs. Secondly, to ensure feasibility, we introduce a variant\nthat starts from a feasible point and iteratively restricts the search within\nthe feasible region. Experimental results show that our approach outperforms\nexisting neural baselines in solution quality and feasibility, generalizes well\nto unseen problem sizes, and, in some cases, achieves faster solution times\nthan state-of-the-art solvers such as Gurobi.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02446v1",
    "published_date": "2025-02-04 16:11:41 UTC",
    "updated_date": "2025-02-04 16:11:41 UTC"
  },
  {
    "arxiv_id": "2502.02444v4",
    "title": "Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models",
    "authors": [
      "Haoran Ye",
      "Tianze Zhang",
      "Yuhang Xie",
      "Liyuan Zhang",
      "Yuanyi Ren",
      "Xin Zhang",
      "Guojie Song"
    ],
    "abstract": "Values are core drivers of individual and collective perception, cognition,\nand behavior. Value systems, such as Schwartz's Theory of Basic Human Values,\ndelineate the hierarchy and interplay among these values, enabling\ncross-disciplinary investigations into decision-making and societal dynamics.\nRecently, the rise of Large Language Models (LLMs) has raised concerns\nregarding their elusive intrinsic values. Despite growing efforts in\nevaluating, understanding, and aligning LLM values, a psychologically grounded\nLLM value system remains underexplored. This study addresses the gap by\nintroducing the Generative Psycho-Lexical Approach (GPLA), a scalable,\nadaptable, and theoretically informed method for constructing value systems.\nLeveraging GPLA, we propose a psychologically grounded five-factor value system\ntailored for LLMs. For systematic validation, we present three benchmarking\ntasks that integrate psychological principles with cutting-edge AI priorities.\nOur results reveal that the proposed value system meets standard psychological\ncriteria, better captures LLM values, improves LLM safety prediction, and\nenhances LLM alignment, when compared to the canonical Schwartz's values.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2502.02444v4",
    "published_date": "2025-02-04 16:10:55 UTC",
    "updated_date": "2025-05-18 10:05:57 UTC"
  },
  {
    "arxiv_id": "2502.02441v1",
    "title": "LLMER: Crafting Interactive Extended Reality Worlds with JSON Data Generated by Large Language Models",
    "authors": [
      "Jiangong Chen",
      "Xiaoyi Wu",
      "Tian Lan",
      "Bin Li"
    ],
    "abstract": "The integration of Large Language Models (LLMs) like GPT-4 with Extended\nReality (XR) technologies offers the potential to build truly immersive XR\nenvironments that interact with human users through natural language, e.g.,\ngenerating and animating 3D scenes from audio inputs. However, the complexity\nof XR environments makes it difficult to accurately extract relevant contextual\ndata and scene/object parameters from an overwhelming volume of XR artifacts.\nIt leads to not only increased costs with pay-per-use models, but also elevated\nlevels of generation errors. Moreover, existing approaches focusing on coding\nscript generation are often prone to generation errors, resulting in flawed or\ninvalid scripts, application crashes, and ultimately a degraded user\nexperience. To overcome these challenges, we introduce LLMER, a novel framework\nthat creates interactive XR worlds using JSON data generated by LLMs. Unlike\nprior approaches focusing on coding script generation, LLMER translates natural\nlanguage inputs into JSON data, significantly reducing the likelihood of\napplication crashes and processing latency. It employs a multi-stage strategy\nto supply only the essential contextual information adapted to the user's\nrequest and features multiple modules designed for various XR tasks. Our\npreliminary user study reveals the effectiveness of the proposed system, with\nover 80% reduction in consumed tokens and around 60% reduction in task\ncompletion time compared to state-of-the-art approaches. The analysis of users'\nfeedback also illuminates a series of directions for further optimization.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02441v1",
    "published_date": "2025-02-04 16:08:48 UTC",
    "updated_date": "2025-02-04 16:08:48 UTC"
  },
  {
    "arxiv_id": "2502.02438v1",
    "title": "Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment",
    "authors": [
      "Yaling Shen",
      "Zhixiong Zhuang",
      "Kun Yuan",
      "Maria-Irina Nicolae",
      "Nassir Navab",
      "Nicolas Padoy",
      "Mario Fritz"
    ],
    "abstract": "Medical multimodal large language models (MLLMs) are becoming an instrumental\npart of healthcare systems, assisting medical personnel with decision making\nand results analysis. Models for radiology report generation are able to\ninterpret medical imagery, thus reducing the workload of radiologists. As\nmedical data is scarce and protected by privacy regulations, medical MLLMs\nrepresent valuable intellectual property. However, these assets are potentially\nvulnerable to model stealing, where attackers aim to replicate their\nfunctionality via black-box access. So far, model stealing for the medical\ndomain has focused on classification; however, existing attacks are not\neffective against MLLMs. In this paper, we introduce Adversarial Domain\nAlignment (ADA-STEAL), the first stealing attack against medical MLLMs.\nADA-STEAL relies on natural images, which are public and widely available, as\nopposed to their medical counterparts. We show that data augmentation with\nadversarial noise is sufficient to overcome the data distribution gap between\nnatural images and the domain-specific distribution of the victim MLLM.\nExperiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that\nAdversarial Domain Alignment enables attackers to steal the medical MLLM\nwithout any access to medical data.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02438v1",
    "published_date": "2025-02-04 16:04:48 UTC",
    "updated_date": "2025-02-04 16:04:48 UTC"
  },
  {
    "arxiv_id": "2502.02431v1",
    "title": "Connections between Schedule-Free Optimizers, AdEMAMix, and Accelerated SGD Variants",
    "authors": [
      "Depen Morwani",
      "Nikhil Vyas",
      "Hanlin Zhang",
      "Sham Kakade"
    ],
    "abstract": "Recent advancements in deep learning optimization have introduced new\nalgorithms, such as Schedule-Free optimizers, AdEMAMix, MARS and Lion which\nmodify traditional momentum mechanisms. In a separate line of work, theoretical\nacceleration of stochastic gradient descent (SGD) in noise-dominated regime has\nbeen achieved by decoupling the momentum coefficient from the current\ngradient's weight. In this paper, we establish explicit connections between\nthese two lines of work. We substantiate our theoretical findings with\npreliminary experiments on a 150m language modeling task. We find that\nAdEMAMix, which most closely resembles accelerated versions of stochastic\ngradient descent, exhibits superior performance. Building on these insights, we\nintroduce a modification to AdEMAMix, termed Simplified-AdEMAMix, which\nmaintains the same performance as AdEMAMix across both large and small\nbatch-size settings while eliminating the need for two different momentum\nterms. The code for Simplified-AdEMAMix is available on the repository:\nhttps://github.com/DepenM/Simplified-AdEMAMix/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02431v1",
    "published_date": "2025-02-04 15:55:35 UTC",
    "updated_date": "2025-02-04 15:55:35 UTC"
  },
  {
    "arxiv_id": "2502.04350v1",
    "title": "CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance",
    "authors": [
      "Yongchao Chen",
      "Yilun Hao",
      "Yueying Liu",
      "Yang Zhang",
      "Chuchu Fan"
    ],
    "abstract": "Existing methods fail to effectively steer Large Language Models (LLMs)\nbetween textual reasoning and code generation, leaving symbolic computing\ncapabilities underutilized. We introduce CodeSteer, an effective method for\nguiding LLM code/text generation. We construct a comprehensive benchmark\nSymBench comprising 37 symbolic tasks with adjustable complexity and also\nsynthesize datasets of 12k multi-round guidance/generation trajectories and\n5.5k guidance comparison pairs. We fine-tune the Llama-3-8B model with a newly\ndesigned multi-round supervised fine-tuning (SFT) and direct preference\noptimization (DPO). The resulting model, CodeSteerLLM, augmented with the\nproposed symbolic and self-answer checkers, effectively guides the code/text\ngeneration of larger models. Augmenting GPT-4o with CodeSteer raises its\naverage performance score from 53.3 to 86.4, even outperforming the existing\nbest LLM OpenAI o1 (82.7), o1-preview (74.8), and DeepSeek R1 (76.8) across all\n37 tasks (28 seen, 9 unseen). Trained for GPT-4o, CodeSteer demonstrates\nsuperior generalizability, providing an average 41.8 performance boost on\nClaude, Mistral, and GPT-3.5. CodeSteer-guided LLMs fully harness symbolic\ncomputing to maintain strong performance on highly complex tasks. Models,\nDatasets, and Codes are available at\nhttps://github.com/yongchao98/CodeSteer-v1.0.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SC",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04350v1",
    "published_date": "2025-02-04 15:53:59 UTC",
    "updated_date": "2025-02-04 15:53:59 UTC"
  },
  {
    "arxiv_id": "2503.15528v1",
    "title": "Complying with the EU AI Act: Innovations in Explainable and User-Centric Hand Gesture Recognition",
    "authors": [
      "Sarah Seifi",
      "Tobias Sukianto",
      "Cecilia Carbonelli",
      "Lorenzo Servadei",
      "Robert Wille"
    ],
    "abstract": "The EU AI Act underscores the importance of transparency, user-centricity,\nand robustness in AI systems, particularly for high-risk systems. In response,\nwe present advancements in XentricAI, an explainable hand gesture recognition\n(HGR) system designed to meet these regulatory requirements. XentricAI adresses\nfundamental challenges in HGR, such as the opacity of black-box models using\nexplainable AI methods and the handling of distributional shifts in real-world\ndata through transfer learning techniques. We extend an existing radar-based\nHGR dataset by adding 28,000 new gestures, with contributions from multiple\nusers across varied locations, including 24,000 out-of-distribution gestures.\nLeveraging this real-world dataset, we enhance XentricAI's capabilities by\nintegrating a variational autoencoder module for improved gesture anomaly\ndetection, incorporating user-specific thresholding. This integration enables\nthe identification of 11.50% more anomalous gestures. Our extensive evaluations\ndemonstrate a 97.5% sucess rate in characterizing these anomalies,\nsignificantly improving system explainability. Furthermore, the implementation\nof transfer learning techniques has shown a substantial increase in user\nadaptability, with an average improvement of at least 15.17%. This work\ncontributes to the development of trustworthy AI systems by providing both\ntechnical advancements and regulatory compliance, offering a commercially\nviable solution that aligns with the EU AI Act requirements.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15528v1",
    "published_date": "2025-02-04 15:50:03 UTC",
    "updated_date": "2025-02-04 15:50:03 UTC"
  },
  {
    "arxiv_id": "2502.04349v1",
    "title": "Dynamic benchmarking framework for LLM-based conversational data capture",
    "authors": [
      "Pietro Alessandro Aluffi",
      "Patrick Zietkiewicz",
      "Marya Bazzi",
      "Matt Arderne",
      "Vladimirs Murevics"
    ],
    "abstract": "The rapid evolution of large language models (LLMs) has transformed\nconversational agents, enabling complex human-machine interactions. However,\nevaluation frameworks often focus on single tasks, failing to capture the\ndynamic nature of multi-turn dialogues. This paper introduces a dynamic\nbenchmarking framework to assess LLM-based conversational agents through\ninteractions with synthetic users. The framework integrates generative agent\nsimulation to evaluate performance on key dimensions: information extraction,\ncontext awareness, and adaptive engagement. By simulating various aspects of\nuser behavior, our work provides a scalable, automated, and flexible\nbenchmarking approach. Experimental evaluation - within a loan application use\ncase - demonstrates the framework's effectiveness under one-shot and few-shot\nextraction conditions. Results show that adaptive strategies improve data\nextraction accuracy, especially when handling ambiguous responses. Future work\nwill extend its applicability to broader domains and incorporate additional\nmetrics (e.g., conversational coherence, user engagement). This study\ncontributes a structured, scalable approach to evaluating LLM-based\nconversational agents, facilitating real-world deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04349v1",
    "published_date": "2025-02-04 15:47:47 UTC",
    "updated_date": "2025-02-04 15:47:47 UTC"
  },
  {
    "arxiv_id": "2502.02421v1",
    "title": "Activation-Informed Merging of Large Language Models",
    "authors": [
      "Amin Heyrani Nobari",
      "Kaveh Alimohammadi",
      "Ali ArjomandBigdeli",
      "Akash Srivastava",
      "Faez Ahmed",
      "Navid Azizan"
    ],
    "abstract": "Model merging, a method that combines the parameters and embeddings of\nmultiple fine-tuned large language models (LLMs), offers a promising approach\nto enhance model performance across various tasks while maintaining\ncomputational efficiency. This paper introduces Activation-Informed Merging\n(AIM), a technique that integrates the information from the activation space of\nLLMs into the merging process to improve performance and robustness. AIM is\ndesigned as a flexible, complementary solution that is applicable to any\nexisting merging method. It aims to preserve critical weights from the base\nmodel, drawing on principles from continual learning~(CL) and model\ncompression. Utilizing a task-agnostic calibration set, AIM selectively\nprioritizes essential weights during merging. We empirically demonstrate that\nAIM significantly enhances the performance of merged models across multiple\nbenchmarks. Our findings suggest that considering the activation-space\ninformation can provide substantial advancements in the model merging\nstrategies for LLMs with up to 40\\% increase in benchmark performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02421v1",
    "published_date": "2025-02-04 15:42:03 UTC",
    "updated_date": "2025-02-04 15:42:03 UTC"
  },
  {
    "arxiv_id": "2502.02406v2",
    "title": "LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models",
    "authors": [
      "Tzu-Tao Chang",
      "Shivaram Venkataraman"
    ],
    "abstract": "Cross-attention is commonly adopted in multimodal large language models\n(MLLMs) for integrating visual information into the language backbone. However,\nin applications with large visual inputs, such as video understanding,\nprocessing a large number of visual tokens in cross-attention layers leads to\nhigh memory demands and often necessitates distributed computation across\nmultiple GPUs. Existing distributed attention mechanisms face significant\ncommunication overheads, making cross-attention layers a critical bottleneck\nfor efficient training and inference of MLLMs. To address this, we propose\nLV-XAttn, a distributed, exact cross-attention mechanism with minimal\ncommunication overhead. We observe that in applications involving large visual\ninputs the size of the query block is typically much smaller than that of the\nkey-value blocks. Thus, in LV-XAttn we keep the large key-value blocks locally\non each GPU and exchange smaller query blocks across GPUs. We also introduce an\nefficient activation recomputation technique enabling support for longer visual\ncontext. We theoretically analyze the communication benefits of LV-XAttn and\nshow that it can achieve speedups for a wide range of models. Our evaluations\nwith mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to\n5.58$\\times$ end-to-end speedup compared to existing approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02406v2",
    "published_date": "2025-02-04 15:24:16 UTC",
    "updated_date": "2025-02-06 19:50:41 UTC"
  },
  {
    "arxiv_id": "2502.04348v2",
    "title": "Prompt-based Depth Pruning of Large Language Models",
    "authors": [
      "Juyun Wee",
      "Minjae Park",
      "Jaeho Lee"
    ],
    "abstract": "Depth pruning aims to reduce the inference cost of a large language model\nwithout any hardware-specific complications, by simply removing several less\nimportant transformer blocks. However, our empirical findings suggest that the\nimportance of a transformer block may be highly task-dependent -- a block that\nis crucial for a task can be removed without degrading the accuracy on another\ntask. Based on this observation, we develop a dynamic depth pruning algorithm,\ncoined PuDDing (Prompt-routed Dynamic Depth Pruning), which determines which\nblocks to omit from the model based on the input prompt. PuDDing operates by\ntraining a lightweight router to predict the best omission set among a set of\noptions, where this option set has also been constructed in a data-driven\nmanner. Empirical results on commonsense reasoning benchmarks demonstrate that\nPuDDing effectively accelerates the inference language models, and achieves\nbetter on-task performance than static depth pruning baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04348v2",
    "published_date": "2025-02-04 15:16:17 UTC",
    "updated_date": "2025-02-14 11:46:43 UTC"
  },
  {
    "arxiv_id": "2502.04347v1",
    "title": "SCALM: Detecting Bad Practices in Smart Contracts Through LLMs",
    "authors": [
      "Zongwei Li",
      "Xiaoqi Li",
      "Wenkai Li",
      "Xin Wang"
    ],
    "abstract": "As the Ethereum platform continues to mature and gain widespread usage, it is\ncrucial to maintain high standards of smart contract writing practices. While\nbad practices in smart contracts may not directly lead to security issues, they\ndo elevate the risk of encountering problems. Therefore, to understand and\navoid these bad practices, this paper introduces the first systematic study of\nbad practices in smart contracts, delving into over 35 specific issues.\nSpecifically, we propose a large language models (LLMs)-based framework, SCALM.\nIt combines Step-Back Prompting and Retrieval-Augmented Generation (RAG) to\nidentify and address various bad practices effectively. Our extensive\nexperiments using multiple LLMs and datasets have shown that SCALM outperforms\nexisting tools in detecting bad practices in smart contracts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.04347v1",
    "published_date": "2025-02-04 15:15:13 UTC",
    "updated_date": "2025-02-04 15:15:13 UTC"
  },
  {
    "arxiv_id": "2502.02391v1",
    "title": "FewTopNER: Integrating Few-Shot Learning with Topic Modeling and Named Entity Recognition in a Multilingual Framework",
    "authors": [
      "Ibrahim Bouabdallaoui",
      "Fatima Guerouate",
      "Samya Bouhaddour",
      "Chaimae Saadi",
      "Mohammed Sbihi"
    ],
    "abstract": "We introduce FewTopNER, a novel framework that integrates few-shot named\nentity recognition (NER) with topic-aware contextual modeling to address the\nchallenges of cross-lingual and low-resource scenarios. FewTopNER leverages a\nshared multilingual encoder based on XLM-RoBERTa, augmented with\nlanguage-specific calibration mechanisms, to generate robust contextual\nembeddings. The architecture comprises a prototype-based entity recognition\nbranch, employing BiLSTM and Conditional Random Fields for sequence labeling,\nand a topic modeling branch that extracts document-level semantic features\nthrough hybrid probabilistic and neural methods. A cross-task bridge\nfacilitates dynamic bidirectional attention and feature fusion between entity\nand topic representations, thereby enhancing entity disambiguation by\nincorporating global semantic context. Empirical evaluations on multilingual\nbenchmarks across English, French, Spanish, German, and Italian demonstrate\nthat FewTopNER significantly outperforms existing state-of-the-art few-shot NER\nmodels. In particular, the framework achieves improvements of 2.5-4.0\npercentage points in F1 score and exhibits enhanced topic coherence, as\nmeasured by normalized pointwise mutual information. Ablation studies further\nconfirm the critical contributions of the shared encoder and cross-task\nintegration mechanisms to the overall performance. These results underscore the\nefficacy of incorporating topic-aware context into few-shot NER and highlight\nthe potential of FewTopNER for robust cross-lingual applications in\nlow-resource settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code source : https://github.com/ibrahimself/FewTopNER/",
    "pdf_url": "http://arxiv.org/pdf/2502.02391v1",
    "published_date": "2025-02-04 15:13:40 UTC",
    "updated_date": "2025-02-04 15:13:40 UTC"
  },
  {
    "arxiv_id": "2502.02390v1",
    "title": "CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning",
    "authors": [
      "Jianfeng Pan",
      "Senyou Deng",
      "Shaomang Huang"
    ],
    "abstract": "Research on LLM technologies is rapidly emerging, with most of them employing\na 'fast thinking' approach to inference. Most LLMs generate the final result\nbased solely on a single query and LLM's reasoning capabilities. However, with\nthe advent of OpenAI-o1, 'slow thinking' techniques have garnered increasing\nattention because its process is closer to the human thought process. Inspired\nby the human ability to constantly associate and replenish knowledge during\nthinking, we developed the novel Chain-of-Associated-Thoughts (CoAT) framework,\nwhich introduces an innovative synergy between the Monte Carlo Tree Search\n(MCTS) algorithm and a dynamic mechanism for integrating new key information,\ntermed 'associative memory'. By combining the structured exploration\ncapabilities of MCTS with the adaptive learning capacity of associative memory,\nCoAT significantly expands the LLM search space, enabling our framework to\nexplore diverse reasoning pathways and dynamically update its knowledge base in\nreal-time. This allows the framework to not only revisit and refine earlier\ninferences but also adaptively incorporate evolving information, ensuring that\nthe final output is both accurate and comprehensive. To validate the\neffectiveness of our framework, we conducted extensive experiments across a\nrange of generative and reasoning tasks. These experiments demonstrated that\nour framework outperforms conventional inference processes on accuracy,\ncoherence, and diversity. The framework's ability to iteratively expand its\nsearch space while retaining contextually relevant information results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02390v1",
    "published_date": "2025-02-04 15:10:33 UTC",
    "updated_date": "2025-02-04 15:10:33 UTC"
  },
  {
    "arxiv_id": "2502.02380v1",
    "title": "The Cost Perspective of Liquid Democracy: Feasibility and Control",
    "authors": [
      "Shiri Alouf-Heffetz",
      "Łukasz Janeczko",
      "Grzegorz Lisowski",
      "Georgios Papasotiropoulos"
    ],
    "abstract": "We examine an approval-based model of Liquid Democracy with a budget\nconstraint on voting and delegating costs, aiming to centrally select casting\nvoters ensuring complete representation of the electorate. From a computational\ncomplexity perspective, we focus on minimizing overall costs, maintaining short\ndelegation paths, and preventing excessive concentration of voting power.\nFurthermore, we explore computational aspects of strategic control,\nspecifically, whether external agents can change election components to\ninfluence the voting power of certain voters.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02380v1",
    "published_date": "2025-02-04 14:59:56 UTC",
    "updated_date": "2025-02-04 14:59:56 UTC"
  },
  {
    "arxiv_id": "2502.02377v1",
    "title": "A Minimax Approach to Ad Hoc Teamwork",
    "authors": [
      "Victor Villin",
      "Thomas Kleine Buening",
      "Christos Dimitrakakis"
    ],
    "abstract": "We propose a minimax-Bayes approach to Ad Hoc Teamwork (AHT) that optimizes\npolicies against an adversarial prior over partners, explicitly accounting for\nuncertainty about partners at time of deployment. Unlike existing methods that\nassume a specific distribution over partners, our approach improves worst-case\nperformance guarantees. Extensive experiments, including evaluations on\ncoordinated cooking tasks from the Melting Pot suite, show our method's\nsuperior robustness compared to self-play, fictitious play, and best response\nlearning. Our work highlights the importance of selecting an appropriate\ntraining distribution over teammates to achieve robustness in AHT.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02377v1",
    "published_date": "2025-02-04 14:57:54 UTC",
    "updated_date": "2025-02-04 14:57:54 UTC"
  },
  {
    "arxiv_id": "2502.02372v1",
    "title": "MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by Continual Learning",
    "authors": [
      "Shengbo Gu",
      "Yu-Kun Qiu",
      "Yu-Ming Tang",
      "Ancong Wu",
      "Wei-Shi Zheng"
    ],
    "abstract": "The generation of a virtual digital avatar is a crucial research topic in the\nfield of computer vision. Many existing works utilize Neural Radiance Fields\n(NeRF) to address this issue and have achieved impressive results. However,\nprevious works assume the images of the training person are available and fixed\nwhile the appearances and poses of a subject could constantly change and\nincrease in real-world scenarios. How to update the human avatar but also\nmaintain the ability to render the old appearance of the person is a practical\nchallenge. One trivial solution is to combine the existing virtual avatar\nmodels based on NeRF with continual learning methods. However, there are some\ncritical issues in this approach: learning new appearances and poses can cause\nthe model to forget past information, which in turn leads to a degradation in\nthe rendering quality of past appearances, especially color bleeding issues,\nand incorrect human body poses. In this work, we propose a maintainable avatar\n(MaintaAvatar) based on neural radiance fields by continual learning, which\nresolves the issues by utilizing a Global-Local Joint Storage Module and a Pose\nDistillation Module. Overall, our model requires only limited data collection\nto quickly fine-tune the model while avoiding catastrophic forgetting, thus\nachieving a maintainable virtual avatar. The experimental results validate the\neffectiveness of our MaintaAvatar model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2025. 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.02372v1",
    "published_date": "2025-02-04 14:52:34 UTC",
    "updated_date": "2025-02-04 14:52:34 UTC"
  },
  {
    "arxiv_id": "2502.02371v1",
    "title": "Accurate Pocket Identification for Binding-Site-Agnostic Docking",
    "authors": [
      "Yaroslav Balytskyi",
      "Inna Hubenko",
      "Alina Balytska",
      "Christopher V. Kelly"
    ],
    "abstract": "Accurate identification of druggable pockets is essential for structure-based\ndrug design. However, most pocket-identification algorithms prioritize their\ngeometric properties over downstream docking performance. To address this\nlimitation, we developed RAPID-Net, a pocket-finding algorithm for seamless\nintegration with docking workflows. When guiding AutoDock Vina, RAPID-Net\noutperforms DiffBindFR on the PoseBusters benchmark and enables blind docking\non large proteins that AlphaFold 3 cannot process as a whole. Furthermore,\nRAPID-Net surpasses PUResNet and Kalasanty in docking accuracy and\npocket-ligand intersection rates across diverse datasets, including\nPoseBusters, Astex Diverse Set, BU48, and Coach420. When accuracy is evaluated\nas ``at least one correct pose in the ensemble'', RAPID-Net outperforms\nAlphaFold 3 on the PoseBusters benchmark, suggesting that our approach can be\nfurther improved with a suitable pose reweighting tool offering a\ncost-effective and competitive alternative to AlphaFold 3 for docking. Finally,\nusing several therapeutically relevant examples, we demonstrate the ability of\nRAPID-Net to identify remote functional sites, highlighting its potential to\nfacilitate the development of innovative therapeutics.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "physics.bio-ph",
      "physics.med-ph"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02371v1",
    "published_date": "2025-02-04 14:52:10 UTC",
    "updated_date": "2025-02-04 14:52:10 UTC"
  },
  {
    "arxiv_id": "2502.02368v1",
    "title": "Evaluating the Effectiveness of LLMs in Fixing Maintainability Issues in Real-World Projects",
    "authors": [
      "Henrique Nunes",
      "Eduardo Figueiredo",
      "Larissa Rocha",
      "Sarah Nadi",
      "Fischer Ferreira",
      "Geanderson Esteves"
    ],
    "abstract": "Large Language Models (LLMs) have gained attention for addressing coding\nproblems, but their effectiveness in fixing code maintainability remains\nunclear. This study evaluates LLMs capability to resolve 127 maintainability\nissues from 10 GitHub repositories. We use zero-shot prompting for Copilot Chat\nand Llama 3.1, and few-shot prompting with Llama only. The LLM-generated\nsolutions are assessed for compilation errors, test failures, and new\nmaintainability problems. Llama with few-shot prompting successfully fixed\n44.9% of the methods, while Copilot Chat and Llama zero-shot fixed 32.29% and\n30%, respectively. However, most solutions introduced errors or new\nmaintainability issues. We also conducted a human study with 45 participants to\nevaluate the readability of 51 LLM-generated solutions. The human study showed\nthat 68.63% of participants observed improved readability. Overall, while LLMs\nshow potential for fixing maintainability issues, their introduction of errors\nhighlights their current limitations.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02368v1",
    "published_date": "2025-02-04 14:50:23 UTC",
    "updated_date": "2025-02-04 14:50:23 UTC"
  },
  {
    "arxiv_id": "2502.02367v1",
    "title": "Field Matching: an Electrostatic Paradigm to Generate and Transfer Data",
    "authors": [
      "Alexander Kolesov",
      "Manukhov Stepan",
      "Vladimir V. Palyulin",
      "Alexander Korotin"
    ],
    "abstract": "We propose Electrostatic Field Matching (EFM), a novel method that is\nsuitable for both generative modeling and distribution transfer tasks. Our\napproach is inspired by the physics of an electrical capacitor. We place source\nand target distributions on the capacitor plates and assign them positive and\nnegative charges, respectively. We then learn the electrostatic field of the\ncapacitor using a neural network approximator. To map the distributions to each\nother, we start at one plate of the capacitor and move the samples along the\nlearned electrostatic field lines until they reach the other plate. We\ntheoretically justify that this approach provably yields the distribution\ntransfer. In practice, we demonstrate the performance of our EFM in toy and\nimage data experiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02367v1",
    "published_date": "2025-02-04 14:50:16 UTC",
    "updated_date": "2025-02-04 14:50:16 UTC"
  },
  {
    "arxiv_id": "2503.04739v1",
    "title": "Responsible Artificial Intelligence Systems: A Roadmap to Society's Trust through Trustworthy AI, Auditability, Accountability, and Governance",
    "authors": [
      "Andrés Herrera-Poyatos",
      "Javier Del Ser",
      "Marcos López de Prado",
      "Fei-Yue Wang",
      "Enrique Herrera-Viedma",
      "Francisco Herrera"
    ],
    "abstract": "Artificial intelligence (AI) has matured as a technology, necessitating the\ndevelopment of responsibility frameworks that are fair, inclusive, trustworthy,\nsafe and secure, transparent, and accountable. By establishing such frameworks,\nwe can harness the full potential of AI while mitigating its risks,\nparticularly in high-risk scenarios. This requires the design of responsible AI\nsystems based on trustworthy AI technologies and ethical principles, with the\naim of ensuring auditability and accountability throughout their design,\ndevelopment, and deployment, adhering to domain-specific regulations and\nstandards.\n  This paper explores the concept of a responsible AI system from a holistic\nperspective, which encompasses four key dimensions: 1) regulatory context; 2)\ntrustworthy AI technology along with standardization and assessments; 3)\nauditability and accountability; and 4) AI governance. The aim of this paper is\ndouble. First, we analyze and understand these four dimensions and their\ninterconnections in the form of an analysis and overview. Second, the final\ngoal of the paper is to propose a roadmap in the design of responsible AI\nsystems, ensuring that they can gain society's trust. To achieve this\ntrustworthiness, this paper also fosters interdisciplinary discussions on the\nethical, legal, social, economic, and cultural aspects of AI from a global\ngovernance perspective. Last but not least, we also reflect on the current\nstate and those aspects that need to be developed in the near future, as ten\nlessons learned.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "I.2.0"
    ],
    "primary_category": "cs.CY",
    "comment": "22 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04739v1",
    "published_date": "2025-02-04 14:47:30 UTC",
    "updated_date": "2025-02-04 14:47:30 UTC"
  },
  {
    "arxiv_id": "2502.02341v1",
    "title": "Test Time Training for 4D Medical Image Interpolation",
    "authors": [
      "Qikang Zhang",
      "Yingjie Lei",
      "Zihao Zheng",
      "Ziyang Chen",
      "Zhonghao Xie"
    ],
    "abstract": "4D medical image interpolation is essential for improving temporal resolution\nand diagnostic precision in clinical applications. Previous works ignore the\nproblem of distribution shifts, resulting in poor generalization under\ndifferent distribution. A natural solution would be to adapt the model to a new\ntest distribution, but this cannot be done if the test input comes without a\nground truth label. In this paper, we propose a novel test time training\nframework which uses self-supervision to adapt the model to a new distribution\nwithout requiring any labels. Indeed, before performing frame interpolation on\neach test video, the model is trained on the same instance using a\nself-supervised task, such as rotation prediction or image reconstruction. We\nconduct experiments on two publicly available 4D medical image interpolation\ndatasets, Cardiac and 4D-Lung. The experimental results show that the proposed\nmethod achieves significant performance across various evaluation metrics on\nboth datasets. It achieves higher peak signal-to-noise ratio values, 33.73dB on\nCardiac and 34.02dB on 4D-Lung. Our method not only advances 4D medical image\ninterpolation but also provides a template for domain adaptation in other\nfields such as image segmentation and image registration.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02341v1",
    "published_date": "2025-02-04 14:19:16 UTC",
    "updated_date": "2025-02-04 14:19:16 UTC"
  },
  {
    "arxiv_id": "2502.02623v1",
    "title": "Sample Complexity of Bias Detection with Subsampled Point-to-Subspace Distances",
    "authors": [
      "German Martinez Matilla",
      "Jakub Marecek"
    ],
    "abstract": "Sample complexity of bias estimation is a lower bound on the runtime of any\nbias detection method. Many regulatory frameworks require the bias to be tested\nfor all subgroups, whose number grows exponentially with the number of\nprotected attributes. Unless one wishes to run a bias detection with a\ndoubly-exponential run-time, one should like to have polynomial complexity of\nbias detection for a single subgroup. At the same time, the reference data may\nbe based on surveys, and thus come with non-trivial uncertainty.\n  Here, we reformulate bias detection as a point-to-subspace problem on the\nspace of measures and show that, for supremum norm, it can be subsampled\nefficiently. In particular, our probabilistically approximately correct (PAC)\nresults are corroborated by tests on well-known instances.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02623v1",
    "published_date": "2025-02-04 14:03:49 UTC",
    "updated_date": "2025-02-04 14:03:49 UTC"
  },
  {
    "arxiv_id": "2502.02302v1",
    "title": "EdgeGFL: Rethinking Edge Information in Graph Feature Preference Learning",
    "authors": [
      "Shengda Zhuo",
      "Jiwang Fang",
      "Hongguang Lin",
      "Yin Tang",
      "Min Chen",
      "Changdong Wang",
      "Shuqiang Huang"
    ],
    "abstract": "Graph Neural Networks (GNNs) have significant advantages in handling\nnon-Euclidean data and have been widely applied across various areas, thus\nreceiving increasing attention in recent years. The framework of GNN models\nmainly includes the information propagation phase and the aggregation phase,\ntreating nodes and edges as information entities and propagation channels,\nrespectively. However, most existing GNN models face the challenge of\ndisconnection between node and edge feature information, as these models\ntypically treat the learning of edge and node features as independent tasks. To\naddress this limitation, we aim to develop an edge-empowered graph feature\npreference learning framework that can capture edge embeddings to assist node\nembeddings. By leveraging the learned multidimensional edge feature matrix, we\nconstruct multi-channel filters to more effectively capture accurate node\nfeatures, thereby obtaining the non-local structural characteristics and\nfine-grained high-order node features. Specifically, the inclusion of\nmultidimensional edge information enhances the functionality and flexibility of\nthe GNN model, enabling it to handle complex and diverse graph data more\neffectively. Additionally, integrating relational representation learning into\nthe message passing framework allows graph nodes to receive more useful\ninformation, thereby facilitating node representation learning. Finally,\nexperiments on four real-world heterogeneous graphs demonstrate the\neffectiveness of theproposed model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02302v1",
    "published_date": "2025-02-04 13:16:54 UTC",
    "updated_date": "2025-02-04 13:16:54 UTC"
  },
  {
    "arxiv_id": "2502.13972v1",
    "title": "IncepFormerNet: A multi-scale multi-head attention network for SSVEP classification",
    "authors": [
      "Yan Huang",
      "Yongru Chen",
      "Lei Cao",
      "Yongnian Cao",
      "Xuechun Yang",
      "Yilin Dong",
      "Tianyu Liu"
    ],
    "abstract": "In recent years, deep learning (DL) models have shown outstanding performance\nin EEG classification tasks, particularly in Steady-State Visually Evoked\nPotential(SSVEP)-based Brain-Computer-Interfaces(BCI)systems. DL methods have\nbeen successfully applied to SSVEP-BCI. This study proposes a new model called\nIncepFormerNet, which is a hybrid of the Inception and Transformer\narchitectures. IncepFormerNet adeptly extracts multi-scale temporal information\nfrom time series data using parallel convolution kernels of varying sizes,\naccurately capturing the subtle variations and critical features within SSVEP\nsignals.Furthermore, the model integrates the multi-head attention mechanism\nfrom the Transformer architecture, which not only provides insights into global\ndependencies but also significantly enhances the understanding and\nrepresentation of complex patterns.Additionally, it takes advantage of filter\nbank techniques to extract features based on the spectral characteristics of\nSSVEP data. To validate the effectiveness of the proposed model, we conducted\nexperiments on two public datasets, . The experimental results show that\nIncepFormerNet achieves an accuracy of 87.41 on Dataset 1 and 71.97 on Dataset\n2 using a 1.0-second time window. To further verify the superiority of the\nproposed model, we compared it with other deep learning models, and the results\nindicate that our method achieves significantly higher accuracy than the\nothers.The source codes in this work are available at:\nhttps://github.com/CECNL/SSVEP-DAN.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13972v1",
    "published_date": "2025-02-04 13:04:03 UTC",
    "updated_date": "2025-02-04 13:04:03 UTC"
  },
  {
    "arxiv_id": "2502.02290v1",
    "title": "FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection",
    "authors": [
      "Daniele Lunghi",
      "Yannick Molinghen",
      "Alkis Simitsis",
      "Tom Lenaerts",
      "Gianluca Bontempi"
    ],
    "abstract": "Adversarial attacks pose a significant threat to data-driven systems, and\nresearchers have spent considerable resources studying them. Despite its\neconomic relevance, this trend largely overlooked the issue of credit card\nfraud detection. To address this gap, we propose a new threat model that\ndemonstrates the limitations of existing attacks and highlights the necessity\nto investigate new approaches. We then design a new adversarial attack for\ncredit card fraud detection, employing reinforcement learning to bypass\nclassifiers. This attack, called FRAUD-RLA, is designed to maximize the\nattacker's reward by optimizing the exploration-exploitation tradeoff and\nworking with significantly less required knowledge than competitors. Our\nexperiments, conducted on three different heterogeneous datasets and against\ntwo fraud detection systems, indicate that FRAUD-RLA is effective, even\nconsidering the severe limitations imposed by our threat model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02290v1",
    "published_date": "2025-02-04 12:59:35 UTC",
    "updated_date": "2025-02-04 12:59:35 UTC"
  },
  {
    "arxiv_id": "2502.02283v5",
    "title": "GP-GS: Gaussian Processes for Enhanced Gaussian Splatting",
    "authors": [
      "Zhihao Guo",
      "Jingxuan Su",
      "Shenglin Wang",
      "Jinlong Fan",
      "Jing Zhang",
      "Wei Zhou",
      "Hadi Amirpour",
      "Yunlong Zhao",
      "Liangxiu Han",
      "Peng Wang"
    ],
    "abstract": "3D Gaussian Splatting has emerged as an efficient photorealistic novel view\nsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)\npoint clouds often limits scene reconstruction quality. To address the\nlimitation, this paper proposes a novel 3D reconstruction framework, Gaussian\nProcesses enhanced Gaussian Splatting (GP-GS), in which a multi-output Gaussian\nProcess model is developed to enable adaptive and uncertainty-guided\ndensification of sparse SfM point clouds. Specifically, we propose a dynamic\nsampling and filtering pipeline that adaptively expands the SfM point clouds by\nleveraging GP-based predictions to infer new candidate points from the input 2D\npixels and depth maps. The pipeline utilizes uncertainty estimates to guide the\npruning of high-variance predictions, ensuring geometric consistency and\nenabling the generation of dense point clouds. These densified point clouds\nprovide high-quality initial 3D Gaussians, enhancing reconstruction\nperformance. Extensive experiments conducted on synthetic and real-world\ndatasets across various scales validate the effectiveness and practicality of\nthe proposed framework.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02283v5",
    "published_date": "2025-02-04 12:50:16 UTC",
    "updated_date": "2025-05-13 15:14:37 UTC"
  },
  {
    "arxiv_id": "2502.02277v1",
    "title": "Error Distribution Smoothing:Advancing Low-Dimensional Imbalanced Regression",
    "authors": [
      "Donghe Chen",
      "Jiaxuan Yue",
      "Tengjie Zheng",
      "Lanxuan Wang",
      "Lin Cheng"
    ],
    "abstract": "In real-world regression tasks, datasets frequently exhibit imbalanced\ndistributions, characterized by a scarcity of data in high-complexity regions\nand an abundance in low-complexity areas. This imbalance presents significant\nchallenges for existing classification methods with clear class boundaries,\nwhile highlighting a scarcity of approaches specifically designed for\nimbalanced regression problems. To better address these issues, we introduce a\nnovel concept of Imbalanced Regression, which takes into account both the\ncomplexity of the problem and the density of data points, extending beyond\ntraditional definitions that focus only on data density. Furthermore, we\npropose Error Distribution Smoothing (EDS) as a solution to tackle imbalanced\nregression, effectively selecting a representative subset from the dataset to\nreduce redundancy while maintaining balance and representativeness. Through\nseveral experiments, EDS has shown its effectiveness, and the related code and\ndataset can be accessed at\nhttps://anonymous.4open.science/r/Error-Distribution-Smoothing-762F.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02277v1",
    "published_date": "2025-02-04 12:40:07 UTC",
    "updated_date": "2025-02-04 12:40:07 UTC"
  },
  {
    "arxiv_id": "2502.02265v1",
    "title": "Adviser-Actor-Critic: Eliminating Steady-State Error in Reinforcement Learning Control",
    "authors": [
      "Donghe Chen",
      "Yubin Peng",
      "Tengjie Zheng",
      "Han Wang",
      "Chaoran Qu",
      "Lin Cheng"
    ],
    "abstract": "High-precision control tasks present substantial challenges for reinforcement\nlearning (RL) algorithms, frequently resulting in suboptimal performance\nattributed to network approximation inaccuracies and inadequate sample\nquality.These issues are exacerbated when the task requires the agent to\nachieve a precise goal state, as is common in robotics and other real-world\napplications.We introduce Adviser-Actor-Critic (AAC), designed to address the\nprecision control dilemma by combining the precision of feedback control theory\nwith the adaptive learning capability of RL and featuring an Adviser that\nmentors the actor to refine control actions, thereby enhancing the precision of\ngoal attainment.Finally, through benchmark tests, AAC outperformed standard RL\nalgorithms in precision-critical, goal-conditioned tasks, demonstrating AAC's\nhigh precision, reliability, and robustness.Code are available at:\nhttps://anonymous.4open.science/r/Adviser-Actor-Critic-8AC5.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02265v1",
    "published_date": "2025-02-04 12:26:47 UTC",
    "updated_date": "2025-02-04 12:26:47 UTC"
  },
  {
    "arxiv_id": "2502.02249v1",
    "title": "Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation",
    "authors": [
      "Atharva Mangeshkumar Agrawal",
      "Rutika Pandurang Shinde",
      "Vasanth Kumar Bhukya",
      "Ashmita Chakraborty",
      "Sagar Bharat Shah",
      "Tanmay Shukla",
      "Sree Pradeep Kumar Relangi",
      "Nilesh Mutyam"
    ],
    "abstract": "Large language models (LLMs) have shown impressive capabilities in natural\nlanguage processing tasks, including dialogue generation. This research aims to\nconduct a novel comparative analysis of two prominent techniques, fine-tuning\nwith LoRA (Low-Rank Adaptation) and the Retrieval-Augmented Generation (RAG)\nframework, in the context of doctor-patient chat conversations with multiple\ndatasets of mixed medical domains. The analysis involves three state-of-the-art\nmodels: Llama-2, GPT, and the LSTM model. Employing real-world doctor-patient\ndialogues, we comprehensively evaluate the performance of models, assessing key\nmetrics such as language quality (perplexity, BLEU score), factual accuracy\n(fact-checking against medical knowledge bases), adherence to medical\nguidelines, and overall human judgments (coherence, empathy, safety). The\nfindings provide insights into the strengths and limitations of each approach,\nshedding light on their suitability for healthcare applications. Furthermore,\nthe research investigates the robustness of the models in handling diverse\npatient queries, ranging from general health inquiries to specific medical\nconditions. The impact of domain-specific knowledge integration is also\nexplored, highlighting the potential for enhancing LLM performance through\ntargeted data augmentation and retrieval strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.02249v1",
    "published_date": "2025-02-04 11:50:40 UTC",
    "updated_date": "2025-02-04 11:50:40 UTC"
  },
  {
    "arxiv_id": "2502.02247v1",
    "title": "Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning",
    "authors": [
      "Bangzhen Liu",
      "Chenxi Zheng",
      "Xuemiao Xu",
      "Cheng Xu",
      "Huaidong Zhang",
      "Shengfeng He"
    ],
    "abstract": "The vulnerability of 3D point cloud analysis to unpredictable rotations poses\nan open yet challenging problem: orientation-aware 3D domain generalization.\nCross-domain robustness and adaptability of 3D representations are crucial but\nnot easily achieved through rotation augmentation. Motivated by the inherent\nadvantages of intricate orientations in enhancing generalizability, we propose\nan innovative rotation-adaptive domain generalization framework for 3D point\ncloud analysis. Our approach aims to alleviate orientational shifts by\nleveraging intricate samples in an iterative learning process. Specifically, we\nidentify the most challenging rotation for each point cloud and construct an\nintricate orientation set by optimizing intricate orientations. Subsequently,\nwe employ an orientation-aware contrastive learning framework that incorporates\nan orientation consistency loss and a margin separation loss, enabling\neffective learning of categorically discriminative and generalizable features\nwith rotation consistency. Extensive experiments and ablations conducted on 3D\ncross-domain benchmarks firmly establish the state-of-the-art performance of\nour proposed approach in the context of orientation-aware 3D domain\ngeneralization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "13pages, supplementary included, early accepted by TPAMI",
    "pdf_url": "http://arxiv.org/pdf/2502.02247v1",
    "published_date": "2025-02-04 11:46:32 UTC",
    "updated_date": "2025-02-04 11:46:32 UTC"
  },
  {
    "arxiv_id": "2502.05213v1",
    "title": "DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models",
    "authors": [
      "Qihao Lin",
      "Chen Tang",
      "Lan zhang",
      "Junyang zhang",
      "Xiangyang Li"
    ],
    "abstract": "Well-trained large language models (LLMs) present significant risks,\nincluding potential malicious use and copyright infringement. Current studies\naim to trace the distribution of LLM-generated texts by implicitly embedding\nwatermarks. Among these, the single-bit watermarking method can only determine\nwhether a given text was generated by an LLM. In contrast, the multi-bit\nwatermarking method embeds richer information into the generated text, which\ncan identify which LLM generated and distributed a given text to which user.\nHowever, existing efforts embed the multi-bit watermark directly into the\ngenerated text without accounting for its watermarking capacity. This approach\ncan result in embedding failures when the text's watermarking capacity is\ninsufficient. In this paper, we derive the watermark embedding distribution\nbased on the logits of LLMs and propose a formal inequality to segment the text\noptimally for watermark embedding. Building on this foundation, we propose\nDERMARK, a dynamic, efficient, and robust multi-bit watermarking method.\nDERMARK divides the text into segments of varying lengths for each bit\nembedding, adaptively matching the text's capacity. It achieves this with\nnegligible overhead and robust performance against text editing by minimizing\nwatermark extraction loss. Comprehensive experiments demonstrate that, compared\nto the SOTA method, our method reduces the number of tokens required for\nembedding each bit by 20\\%, reduces watermark embedding time by 50\\%, and is\nrobust to text editing and watermark erasure attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.05213v1",
    "published_date": "2025-02-04 11:23:49 UTC",
    "updated_date": "2025-02-04 11:23:49 UTC"
  },
  {
    "arxiv_id": "2502.02618v1",
    "title": "Deep Learning-Based Facial Expression Recognition for the Elderly: A Systematic Review",
    "authors": [
      "F. Xavier Gaya-Morey",
      "Jose M. Buades-Rubio",
      "Philippe Palanque",
      "Raquel Lacuesta",
      "Cristina Manresa-Yee"
    ],
    "abstract": "The rapid aging of the global population has highlighted the need for\ntechnologies to support elderly, particularly in healthcare and emotional\nwell-being. Facial expression recognition (FER) systems offer a non-invasive\nmeans of monitoring emotional states, with applications in assisted living,\nmental health support, and personalized care. This study presents a systematic\nreview of deep learning-based FER systems, focusing on their applications for\nthe elderly population. Following a rigorous methodology, we analyzed 31\nstudies published over the last decade, addressing challenges such as the\nscarcity of elderly-specific datasets, class imbalances, and the impact of\nage-related facial expression differences. Our findings show that convolutional\nneural networks remain dominant in FER, and especially lightweight versions for\nresource-constrained environments. However, existing datasets often lack\ndiversity in age representation, and real-world deployment remains limited.\nAdditionally, privacy concerns and the need for explainable artificial\nintelligence emerged as key barriers to adoption. This review underscores the\nimportance of developing age-inclusive datasets, integrating multimodal\nsolutions, and adopting XAI techniques to enhance system usability,\nreliability, and trustworthiness. We conclude by offering recommendations for\nfuture research to bridge the gap between academic progress and real-world\nimplementation in elderly care.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02618v1",
    "published_date": "2025-02-04 11:05:24 UTC",
    "updated_date": "2025-02-04 11:05:24 UTC"
  },
  {
    "arxiv_id": "2502.02225v1",
    "title": "Exploring the latent space of diffusion models directly through singular value decomposition",
    "authors": [
      "Li Wang",
      "Boyan Gao",
      "Yanran Li",
      "Zhao Wang",
      "Xiaosong Yang",
      "David A. Clifton",
      "Jun Xiao"
    ],
    "abstract": "Despite the groundbreaking success of diffusion models in generating\nhigh-fidelity images, their latent space remains relatively under-explored,\neven though it holds significant promise for enabling versatile and\ninterpretable image editing capabilities. The complicated denoising trajectory\nand high dimensionality of the latent space make it extremely challenging to\ninterpret. Existing methods mainly explore the feature space of U-Net in\nDiffusion Models (DMs) instead of the latent space itself. In contrast, we\ndirectly investigate the latent space via Singular Value Decomposition (SVD)\nand discover three useful properties that can be used to control generation\nresults without the requirements of data collection and maintain identity\nfidelity generated images. Based on these properties, we propose a novel image\nediting framework that is capable of learning arbitrary attributes from one\npair of latent codes destined by text prompts in Stable Diffusion Models. To\nvalidate our approach, extensive experiments are conducted to demonstrate its\neffectiveness and flexibility in image editing. We will release our codes soon\nto foster further research and applications in this area.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02225v1",
    "published_date": "2025-02-04 11:04:36 UTC",
    "updated_date": "2025-02-04 11:04:36 UTC"
  },
  {
    "arxiv_id": "2502.10421v1",
    "title": "DRiVE: Dynamic Recognition in VEhicles using snnTorch",
    "authors": [
      "Heerak Vora",
      "Param Pathak",
      "Parul Bakaraniya"
    ],
    "abstract": "Spiking Neural Networks (SNNs) mimic biological brain activity, processing\ndata efficiently through an event-driven design, wherein the neurons activate\nonly when inputs exceed specific thresholds. Their ability to track voltage\nchanges over time via membrane potential dynamics helps retain temporal\ninformation. This study combines SNNs with PyTorch's adaptable framework,\nsnnTorch, to test their potential for image-based tasks. We introduce DRiVE, a\nvehicle detection model that uses spiking neuron dynamics to classify images,\nachieving 94.8% accuracy and a near-perfect 0.99 AUC score. These results\nhighlight DRiVE's ability to distinguish vehicle classes effectively,\nchallenging the notion that SNNs are limited to temporal data. As interest\ngrows in energy-efficient neural models, DRiVE's success emphasizes the need to\nrefine SNN optimization for visual tasks. This work encourages broader\nexploration of SNNs in scenarios where conventional networks struggle,\nparticularly for real-world applications requiring both precision and\nefficiency.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "6 pages, 7 figures, 3 tables, Accepted at the 2025 IEEE International\n  Conference on Advancements in Smart, Secure And Intelligent Computing (ASSIC\n  2025), May 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10421v1",
    "published_date": "2025-02-04 11:01:13 UTC",
    "updated_date": "2025-02-04 11:01:13 UTC"
  },
  {
    "arxiv_id": "2502.02221v1",
    "title": "Bias Detection via Maximum Subgroup Discrepancy",
    "authors": [
      "Jiří Němeček",
      "Mark Kozdoba",
      "Illia Kryvoviaz",
      "Tomáš Pevný",
      "Jakub Mareček"
    ],
    "abstract": "Bias evaluation is fundamental to trustworthy AI, both in terms of checking\ndata quality and in terms of checking the outputs of AI systems. In testing\ndata quality, for example, one may study a distance of a given dataset, viewed\nas a distribution, to a given ground-truth reference dataset. However,\nclassical metrics, such as the Total Variation and the Wasserstein distances,\nare known to have high sample complexities and, therefore, may fail to provide\nmeaningful distinction in many practical scenarios.\n  In this paper, we propose a new notion of distance, the Maximum Subgroup\nDiscrepancy (MSD). In this metric, two distributions are close if, roughly,\ndiscrepancies are low for all feature subgroups. While the number of subgroups\nmay be exponential, we show that the sample complexity is linear in the number\nof features, thus making it feasible for practical applications. Moreover, we\nprovide a practical algorithm for the evaluation of the distance, based on\nMixed-integer optimization (MIO). We also note that the proposed distance is\neasily interpretable, thus providing clearer paths to fixing the biases once\nthey have been identified. It also provides guarantees for all subgroups.\nFinally, we empirically evaluate, compare with other metrics, and demonstrate\nthe above properties of MSD on real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02221v1",
    "published_date": "2025-02-04 11:01:03 UTC",
    "updated_date": "2025-02-04 11:01:03 UTC"
  },
  {
    "arxiv_id": "2502.02201v1",
    "title": "Can You Move These Over There? An LLM-based VR Mover for Supporting Object Manipulation",
    "authors": [
      "Xiangzhi Eric Wang",
      "Zackary P. T. Sin",
      "Ye Jia",
      "Daniel Archer",
      "Wynonna H. Y. Fong",
      "Qing Li",
      "Chen Li"
    ],
    "abstract": "In our daily lives, we can naturally convey instructions for the spatial\nmanipulation of objects using words and gestures. Transposing this form of\ninteraction into virtual reality (VR) object manipulation can be beneficial. We\npropose VR Mover, an LLM-empowered solution that can understand and interpret\nthe user's vocal instruction to support object manipulation. By simply pointing\nand speaking, the LLM can manipulate objects without structured input. Our user\nstudy demonstrates that VR Mover enhances user usability, overall experience\nand performance on multi-object manipulation, while also reducing workload and\narm fatigue. Users prefer the proposed natural interface for broad movements\nand may complementarily switch to gizmos or virtual hands for finer\nadjustments. These findings are believed to contribute to design implications\nfor future LLM-based object manipulation interfaces, highlighting the potential\nfor more intuitive and efficient user interactions in VR environments.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "64 pages (30 in main text), 22 figures (19 in main text)",
    "pdf_url": "http://arxiv.org/pdf/2502.02201v1",
    "published_date": "2025-02-04 10:27:40 UTC",
    "updated_date": "2025-02-04 10:27:40 UTC"
  },
  {
    "arxiv_id": "2502.02197v1",
    "title": "An Efficient Local Search Approach for Polarized Community Discovery in Signed Networks",
    "authors": [
      "Linus Aronsson",
      "Morteza Haghir Chehreghani"
    ],
    "abstract": "Signed networks, where edges are labeled as positive or negative to indicate\nfriendly or antagonistic interactions, offer a natural framework for studying\npolarization, trust, and conflict in social systems. Detecting meaningful group\nstructures in these networks is crucial for understanding online discourse,\npolitical division, and trust dynamics. A key challenge is to identify groups\nthat are cohesive internally yet antagonistic externally, while allowing for\nneutral or unaligned vertices. In this paper, we address this problem by\nidentifying $k$ polarized communities that are large, dense, and balanced in\nsize. We develop an approach based on Frank-Wolfe optimization, leading to a\nlocal search procedure with provable convergence guarantees. Our method is both\nscalable and efficient, outperforming state-of-the-art baselines in solution\nquality while remaining competitive in terms of computational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02197v1",
    "published_date": "2025-02-04 10:22:01 UTC",
    "updated_date": "2025-02-04 10:22:01 UTC"
  },
  {
    "arxiv_id": "2502.02196v1",
    "title": "Exploiting Ensemble Learning for Cross-View Isolated Sign Language Recognition",
    "authors": [
      "Fei Wang",
      "Kun Li",
      "Yiqi Nie",
      "Zhangling Duan",
      "Peng Zou",
      "Zhiliang Wu",
      "Yuwei Wang",
      "Yanyan Wei"
    ],
    "abstract": "In this paper, we present our solution to the Cross-View Isolated Sign\nLanguage Recognition (CV-ISLR) challenge held at WWW 2025. CV-ISLR addresses a\ncritical issue in traditional Isolated Sign Language Recognition (ISLR), where\nexisting datasets predominantly capture sign language videos from a frontal\nperspective, while real-world camera angles often vary. To accurately recognize\nsign language from different viewpoints, models must be capable of\nunderstanding gestures from multiple angles, making cross-view recognition\nchallenging. To address this, we explore the advantages of ensemble learning,\nwhich enhances model robustness and generalization across diverse views. Our\napproach, built on a multi-dimensional Video Swin Transformer model, leverages\nthis ensemble strategy to achieve competitive performance. Finally, our\nsolution ranked 3rd in both the RGB-based ISLR and RGB-D-based ISLR tracks,\ndemonstrating the effectiveness in handling the challenges of cross-view\nrecognition. The code is available at:\nhttps://github.com/Jiafei127/CV_ISLR_WWW2025.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "3rd Place in Cross-View Isolated Sign Language Recognition Challenge\n  at WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02196v1",
    "published_date": "2025-02-04 10:21:28 UTC",
    "updated_date": "2025-02-04 10:21:28 UTC"
  },
  {
    "arxiv_id": "2502.06810v1",
    "title": "Emergence of Self-Awareness in Artificial Systems: A Minimalist Three-Layer Approach to Artificial Consciousness",
    "authors": [
      "Kurando Iida"
    ],
    "abstract": "This paper proposes a minimalist three-layer model for artificial\nconsciousness, focusing on the emergence of self-awareness. The model comprises\na Cognitive Integration Layer, a Pattern Prediction Layer, and an Instinctive\nResponse Layer, interacting with Access-Oriented and Pattern-Integrated Memory\nsystems. Unlike brain-replication approaches, we aim to achieve minimal\nself-awareness through essential elements only. Self-awareness emerges from\nlayer interactions and dynamic self-modeling, without initial explicit\nself-programming. We detail each component's structure, function, and\nimplementation strategies, addressing technical feasibility. This research\noffers new perspectives on consciousness emergence in artificial systems, with\npotential implications for human consciousness understanding and adaptable AI\ndevelopment. We conclude by discussing ethical considerations and future\nresearch directions.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "68T05",
      "I.2.6; I.2.0"
    ],
    "primary_category": "q-bio.NC",
    "comment": "46 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.06810v1",
    "published_date": "2025-02-04 10:06:25 UTC",
    "updated_date": "2025-02-04 10:06:25 UTC"
  },
  {
    "arxiv_id": "2502.02187v2",
    "title": "ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion",
    "authors": [
      "Nissim Maruani",
      "Wang Yifan",
      "Matthew Fisher",
      "Pierre Alliez",
      "Mathieu Desbrun"
    ],
    "abstract": "This paper proposes ShapeShifter, a new 3D generative model that learns to\nsynthesize shape variations based on a single reference model. While generative\nmethods for 3D objects have recently attracted much attention, current\ntechniques often lack geometric details and/or require long training times and\nlarge resources. Our approach remedies these issues by combining sparse voxel\ngrids and point, normal, and color sampling within a multiscale neural\narchitecture that can be trained efficiently and in parallel. We show that our\nresulting variations better capture the fine details of their original input\nand can handle more general types of surfaces than previous SDF-based methods.\nMoreover, we offer interactive generation of 3D shape variants, allowing more\nhuman control in the design loop if needed.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02187v2",
    "published_date": "2025-02-04 10:02:40 UTC",
    "updated_date": "2025-03-17 12:06:19 UTC"
  },
  {
    "arxiv_id": "2502.02180v2",
    "title": "The Elicitation Game: Evaluating Capability Elicitation Techniques",
    "authors": [
      "Felix Hofstätter",
      "Teun van der Weij",
      "Jayden Teoh",
      "Henning Bartsch",
      "Francis Rhys Ward"
    ],
    "abstract": "Capability evaluations are required to understand and regulate AI systems\nthat may be deployed or further developed. Therefore, it is important that\nevaluations provide an accurate estimation of an AI system's capabilities.\nHowever, in numerous cases, previously latent capabilities have been elicited\nfrom models, sometimes long after initial release. Accordingly, substantial\nefforts have been made to develop methods for eliciting latent capabilities\nfrom models. In this paper, we evaluate the effectiveness of capability\nelicitation techniques by intentionally training model organisms -- language\nmodels with hidden capabilities that are revealed by a password. We introduce a\nnovel method for training model organisms, based on circuit breaking, which is\nmore robust to elicitation techniques than standard password-locked models. We\nfocus on elicitation techniques based on prompting and activation steering, and\ncompare these to fine-tuning methods. Prompting techniques can elicit the\nactual capability of both password-locked and circuit-broken model organisms in\nan MCQA setting, while steering fails to do so. For a code-generation task,\nonly fine-tuning can elicit the hidden capabilities of our novel model\norganism. Additionally, our results suggest that combining techniques improves\nelicitation. Still, if possible, fine-tuning should be the method of choice to\nimprove the trustworthiness of capability evaluations.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02180v2",
    "published_date": "2025-02-04 09:54:24 UTC",
    "updated_date": "2025-02-24 18:51:21 UTC"
  },
  {
    "arxiv_id": "2502.02173v1",
    "title": "Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge",
    "authors": [
      "Daniel Tamayo",
      "Aitor Gonzalez-Agirre",
      "Javier Hernando",
      "Marta Villegas"
    ],
    "abstract": "Recent research has explored methods for updating and modifying factual\nknowledge in large language models, often focusing on specific multi-layer\nperceptron blocks. This study expands on this work by examining the\neffectiveness of existing knowledge editing methods across languages and\ndelving into the role of attention mechanisms in this process. Drawing from the\ninsights gained, we propose Mass-Editing Memory with Attention in Transformers\n(MEMAT), a method that achieves significant improvements in all metrics while\nrequiring minimal parameter modifications. MEMAT delivers a remarkable 10%\nincrease in magnitude metrics, benefits languages not included in the training\ndata and also demonstrates a high degree of portability. Our code and data are\nat https://github.com/dtamayo-nlp/MEMAT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02173v1",
    "published_date": "2025-02-04 09:47:55 UTC",
    "updated_date": "2025-02-04 09:47:55 UTC"
  },
  {
    "arxiv_id": "2502.02170v1",
    "title": "Graph Neural Networks for O-RAN Mobility Management: A Link Prediction Approach",
    "authors": [
      "Ana Gonzalez Bermudez",
      "Miquel Farreras",
      "Milan Groshev",
      "José Antonio Trujillo",
      "Isabel de la Bandera",
      "Raquel Barco"
    ],
    "abstract": "Mobility performance has been a key focus in cellular networks up to 5G. To\nenhance handover (HO) performance, 3GPP introduced Conditional Handover (CHO)\nand Layer 1/Layer 2 Triggered Mobility (LTM) mechanisms in 5G. While these\nreactive HO strategies address the trade-off between HO failures (HOF) and\nping-pong effects, they often result in inefficient radio resource utilization\ndue to additional HO preparations. To overcome these challenges, this article\nproposes a proactive HO framework for mobility management in O-RAN, leveraging\nuser-cell link predictions to identify the optimal target cell for HO. We\nexplore various categories of Graph Neural Networks (GNNs) for link prediction\nand analyze the complexity of applying them to the mobility management domain.\nTwo GNN models are compared using a real-world dataset, with experimental\nresults demonstrating their ability to capture the dynamic and graph-structured\nnature of cellular networks. Finally, we present key insights from our study\nand outline future steps to enable the integration of GNN-based link prediction\nfor mobility management in 6G networks.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "7 pages, 2 figures, 2 tables. Submitted to IEEE Vehicular Technology\n  Magazine, Special Issue on \"AI for 6G O-RAN Intelligent, Cost-Efficient and\n  Secure Automation\"",
    "pdf_url": "http://arxiv.org/pdf/2502.02170v1",
    "published_date": "2025-02-04 09:44:41 UTC",
    "updated_date": "2025-02-04 09:44:41 UTC"
  },
  {
    "arxiv_id": "2502.02153v1",
    "title": "Vulnerability Mitigation for Safety-Aligned Language Models via Debiasing",
    "authors": [
      "Thien Q. Tran",
      "Akifumi Wachi",
      "Rei Sato",
      "Takumi Tanabe",
      "Youhei Akimoto"
    ],
    "abstract": "Safety alignment is an essential research topic for real-world AI\napplications. Despite the multifaceted nature of safety and trustworthiness in\nAI, current safety alignment methods often focus on a comprehensive notion of\nsafety. By carefully assessing models from the existing safety-alignment\nmethods, we found that, while they generally improved overall safety\nperformance, they failed to ensure safety in specific categories. Our study\nfirst identified the difficulty of eliminating such vulnerabilities without\nsacrificing the model's helpfulness. We observed that, while smaller KL penalty\nparameters, increased training iterations, and dataset cleansing can enhance\nsafety, they do not necessarily improve the trade-off between safety and\nhelpfulness. We discovered that safety alignment could even induce undesired\neffects and result in a model that prefers generating negative tokens leading\nto rejective responses, regardless of the input context. To address this, we\nintroduced a learning-free method, Token-level Safety-Debiased Inference\n(TSDI), to estimate and correct this bias during the generation process using\nrandomly constructed prompts. Our experiments demonstrated that our method\ncould enhance the model's helpfulness while maintaining safety, thus improving\nthe trade-off Pareto-front.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "37 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.02153v1",
    "published_date": "2025-02-04 09:31:54 UTC",
    "updated_date": "2025-02-04 09:31:54 UTC"
  },
  {
    "arxiv_id": "2502.02145v3",
    "title": "From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios",
    "authors": [
      "Yuan Gao",
      "Mattia Piccinini",
      "Korbinian Moller",
      "Amr Alanwar",
      "Johannes Betz"
    ],
    "abstract": "Ensuring the safety of autonomous vehicles requires virtual scenario-based\ntesting, which depends on the robust evaluation and generation of\nsafety-critical scenarios. So far, researchers have used scenario-based testing\nframeworks that rely heavily on handcrafted scenarios as safety metrics. To\nreduce the effort of human interpretation and overcome the limited scalability\nof these approaches, we combine Large Language Models (LLMs) with structured\nscenario parsing and prompt engineering to automatically evaluate and generate\nsafety-critical driving scenarios. We introduce Cartesian and Ego-centric\nprompt strategies for scenario evaluation, and an adversarial generation module\nthat modifies trajectories of risk-inducing vehicles (ego-attackers) to create\ncritical scenarios. We validate our approach using a 2D simulation framework\nand multiple pre-trained LLMs. The results show that the evaluation module\neffectively detects collision scenarios and infers scenario safety. Meanwhile,\nthe new generation module identifies high-risk agents and synthesizes\nrealistic, safety-critical scenarios. We conclude that an LLM equipped with\ndomain-informed prompting techniques can effectively evaluate and generate\nsafety-critical driving scenarios, reducing dependence on handcrafted metrics.\nWe release our open-source code and scenarios at:\nhttps://github.com/TUM-AVS/From-Words-to-Collisions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "New version of the paper",
    "pdf_url": "http://arxiv.org/pdf/2502.02145v3",
    "published_date": "2025-02-04 09:19:13 UTC",
    "updated_date": "2025-05-21 07:47:01 UTC"
  },
  {
    "arxiv_id": "2502.02135v1",
    "title": "Standard Neural Computation Alone Is Insufficient for Logical Intelligence",
    "authors": [
      "Youngsung Kim"
    ],
    "abstract": "Neural networks, as currently designed, fall short of achieving true logical\nintelligence. Modern AI models rely on standard neural\ncomputation-inner-product-based transformations and nonlinear activations-to\napproximate patterns from data. While effective for inductive learning, this\narchitecture lacks the structural guarantees necessary for deductive inference\nand logical consistency. As a result, deep networks struggle with rule-based\nreasoning, structured generalization, and interpretability without extensive\npost-hoc modifications. This position paper argues that standard neural layers\nmust be fundamentally rethought to integrate logical reasoning. We advocate for\nLogical Neural Units (LNUs)-modular components that embed differentiable\napproximations of logical operations (e.g., AND, OR, NOT) directly within\nneural architectures. We critique existing neurosymbolic approaches, highlight\nthe limitations of standard neural computation for logical inference, and\npresent LNUs as a necessary paradigm shift in AI. Finally, we outline a roadmap\nfor implementation, discussing theoretical foundations, architectural\nintegration, and key challenges for future research.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02135v1",
    "published_date": "2025-02-04 09:07:45 UTC",
    "updated_date": "2025-02-04 09:07:45 UTC"
  },
  {
    "arxiv_id": "2502.02133v1",
    "title": "Synthesis of Model Predictive Control and Reinforcement Learning: Survey and Classification",
    "authors": [
      "Rudolf Reiter",
      "Jasper Hoffmann",
      "Dirk Reinhardt",
      "Florian Messerer",
      "Katrin Baumgärtner",
      "Shamburaj Sawant",
      "Joschka Boedecker",
      "Moritz Diehl",
      "Sebastien Gros"
    ],
    "abstract": "The fields of MPC and RL consider two successful control techniques for\nMarkov decision processes. Both approaches are derived from similar fundamental\nprinciples, and both are widely used in practical applications, including\nrobotics, process control, energy systems, and autonomous driving. Despite\ntheir similarities, MPC and RL follow distinct paradigms that emerged from\ndiverse communities and different requirements. Various technical\ndiscrepancies, particularly the role of an environment model as part of the\nalgorithm, lead to methodologies with nearly complementary advantages. Due to\ntheir orthogonal benefits, research interest in combination methods has\nrecently increased significantly, leading to a large and growing set of complex\nideas leveraging MPC and RL. This work illuminates the differences,\nsimilarities, and fundamentals that allow for different combination algorithms\nand categorizes existing work accordingly. Particularly, we focus on the\nversatile actor-critic RL approach as a basis for our categorization and\nexamine how the online optimization approach of MPC can be used to improve the\noverall closed-loop performance of a policy.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02133v1",
    "published_date": "2025-02-04 09:06:07 UTC",
    "updated_date": "2025-02-04 09:06:07 UTC"
  },
  {
    "arxiv_id": "2502.02132v1",
    "title": "How Memory in Optimization Algorithms Implicitly Modifies the Loss",
    "authors": [
      "Matias D. Cattaneo",
      "Boris Shigida"
    ],
    "abstract": "In modern optimization methods used in deep learning, each update depends on\nthe history of previous iterations, often referred to as memory, and this\ndependence decays fast as the iterates go further into the past. For example,\ngradient descent with momentum has exponentially decaying memory through\nexponentially averaged past gradients. We introduce a general technique for\nidentifying a memoryless algorithm that approximates an optimization algorithm\nwith memory. It is obtained by replacing all past iterates in the update by the\ncurrent one, and then adding a correction term arising from memory (also a\nfunction of the current iterate). This correction term can be interpreted as a\nperturbation of the loss, and the nature of this perturbation can inform how\nmemory implicitly (anti-)regularizes the optimization dynamics. As an\napplication of our theory, we find that Lion does not have the kind of implicit\nanti-regularization induced by memory that AdamW does, providing a theory-based\nexplanation for Lion's better generalization performance recently documented.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02132v1",
    "published_date": "2025-02-04 09:04:50 UTC",
    "updated_date": "2025-02-04 09:04:50 UTC"
  },
  {
    "arxiv_id": "2502.02617v1",
    "title": "PolarQuant: Quantizing KV Caches with Polar Transformation",
    "authors": [
      "Insu Han",
      "Praneeth Kacham",
      "Amin Karbasi",
      "Vahab Mirrokni",
      "Amir Zandieh"
    ],
    "abstract": "Large language models (LLMs) require significant memory to store Key-Value\n(KV) embeddings in their KV cache, especially when handling long-range\ncontexts. Quantization of these KV embeddings is a common technique to reduce\nmemory consumption. This work introduces PolarQuant, a novel quantization\nmethod employing random preconditioning and polar transformation. Our method\ntransforms the KV embeddings into polar coordinates using an efficient\nrecursive algorithm and then quantizes resulting angles. Our key insight is\nthat, after random preconditioning, the angles in the polar representation\nexhibit a tightly bounded and highly concentrated distribution with an\nanalytically computable form. This nice distribution eliminates the need for\nexplicit normalization, a step required by traditional quantization methods\nwhich introduces significant memory overhead because quantization parameters\n(e.g., zero point and scale) must be stored in full precision per each data\nblock. PolarQuant bypasses this normalization step, enabling substantial memory\nsavings. The long-context evaluation demonstrates that PolarQuant compresses\nthe KV cache by over x4.2 while achieving the best quality scores compared to\nthe state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02617v1",
    "published_date": "2025-02-04 08:52:13 UTC",
    "updated_date": "2025-02-04 08:52:13 UTC"
  },
  {
    "arxiv_id": "2502.02109v1",
    "title": "Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care",
    "authors": [
      "Yuxiao Cheng",
      "Xinxin Song",
      "Ziqian Wang",
      "Qin Zhong",
      "Kunlun He",
      "Jinli Suo"
    ],
    "abstract": "Recent advances in deep learning (DL) have prompted the development of\nhigh-performing early warning score (EWS) systems, predicting clinical\ndeteriorations such as acute kidney injury, acute myocardial infarction, or\ncirculatory failure. DL models have proven to be powerful tools for various\ntasks but come with the cost of lacking interpretability and limited\ngeneralizability, hindering their clinical applications. To develop a practical\nEWS system applicable to various outcomes, we propose causally-informed\nexplainable early prediction model, which leverages causal discovery to\nidentify the underlying causal relationships of prediction and thus owns two\nunique advantages: demonstrating the explicit interpretation of the prediction\nwhile exhibiting decent performance when applied to unfamiliar environments.\nBenefiting from these features, our approach achieves superior accuracy for 6\ndifferent critical deteriorations and achieves better generalizability across\ndifferent patient groups, compared to various baseline algorithms. Besides, we\nprovide explicit causal pathways to serve as references for assistant clinical\ndiagnosis and potential interventions. The proposed approach enhances the\npractical application of deep learning in various medical scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02109v1",
    "published_date": "2025-02-04 08:43:39 UTC",
    "updated_date": "2025-02-04 08:43:39 UTC"
  },
  {
    "arxiv_id": "2502.02103v1",
    "title": "Neural Networks Learn Distance Metrics",
    "authors": [
      "Alan Oursland"
    ],
    "abstract": "Neural networks may naturally favor distance-based representations, where\nsmaller activations indicate closer proximity to learned prototypes. This\ncontrasts with intensity-based approaches, which rely on activation magnitudes.\nTo test this hypothesis, we conducted experiments with six MNIST architectural\nvariants constrained to learn either distance or intensity representations. Our\nresults reveal that the underlying representation affects model performance. We\ndevelop a novel geometric framework that explains these findings and introduce\nOffsetL2, a new architecture based on Mahalanobis distance equations, to\nfurther validate this framework. This work highlights the importance of\nconsidering distance-based learning in neural network design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "68T07 (Primary) 62H12 (Secondary)",
      "I.5.1; G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 1 figures. Code and additional resources available at\n  https://github.com/alanoursland/neural_networks_learn_distance_metrics",
    "pdf_url": "http://arxiv.org/pdf/2502.02103v1",
    "published_date": "2025-02-04 08:35:57 UTC",
    "updated_date": "2025-02-04 08:35:57 UTC"
  },
  {
    "arxiv_id": "2502.02088v3",
    "title": "IPO: Iterative Preference Optimization for Text-to-Video Generation",
    "authors": [
      "Xiaomeng Yang",
      "Zhiyu Tan",
      "Hao Li"
    ],
    "abstract": "Video foundation models have achieved significant advancement with the help\nof network upgrade as well as model scale-up. However, they are still hard to\nmeet requirements of applications due to unsatisfied generation quality. To\nsolve this problem, we propose to align video foundation models with human\npreferences from the perspective of post-training in this paper. Consequently,\nwe introduce an Iterative Preference Optimization strategy to enhance generated\nvideo quality by incorporating human feedback. Specifically, IPO exploits a\ncritic model to justify video generations for pairwise ranking as in Direct\nPreference Optimization or point-wise scoring as in Kahneman-Tversky\nOptimization. Given this, IPO optimizes video foundation models with guidance\nof signals from preference feedback, which helps improve generated video\nquality in subject consistency, motion smoothness and aesthetic quality, etc.\nIn addition, IPO incorporates the critic model with the multi-modality large\nlanguage model, which enables it to automatically assign preference labels\nwithout need of retraining or relabeling. In this way, IPO can efficiently\nperform multi-round preference optimization in an iterative manner, without the\nneed of tediously manual labeling. Comprehensive experiments demonstrate that\nthe proposed IPO can effectively improve the video generation quality of a\npretrained model and help a model with only 2B parameters surpass the one with\n5B parameters. Besides, IPO achieves new state-of-the-art performance on VBench\nbenchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02088v3",
    "published_date": "2025-02-04 08:14:34 UTC",
    "updated_date": "2025-03-09 12:30:00 UTC"
  },
  {
    "arxiv_id": "2502.10420v1",
    "title": "Position: Stop Acting Like Language Model Agents Are Normal Agents",
    "authors": [
      "Elija Perrier",
      "Michael Timothy Bennett"
    ],
    "abstract": "Language Model Agents (LMAs) are increasingly treated as capable of\nautonomously navigating interactions with humans and tools. Their design and\ndeployment tends to presume they are normal agents capable of sustaining\ncoherent goals, adapting across contexts and acting with a measure of\nintentionality. These assumptions are critical to prospective use cases in\nindustrial, social and governmental settings. But LMAs are not normal agents.\nThey inherit the structural problems of the large language models (LLMs) around\nwhich they are built: hallucinations, jailbreaking, misalignment and\nunpredictability. In this Position paper we argue LMAs should not be treated as\nnormal agents, because doing so leads to problems that undermine their utility\nand trustworthiness. We enumerate pathologies of agency intrinsic to LMAs.\nDespite scaffolding such as external memory and tools, they remain\nontologically stateless, stochastic, semantically sensitive, and linguistically\nintermediated. These pathologies destabilise the ontological properties of LMAs\nincluding identifiability, continuity, persistence and and consistency,\nproblematising their claim to agency. In response, we argue LMA ontological\nproperties should be measured before, during and after deployment so that the\nnegative effects of pathologies can be mitigated.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.10420v1",
    "published_date": "2025-02-04 08:14:18 UTC",
    "updated_date": "2025-02-04 08:14:18 UTC"
  },
  {
    "arxiv_id": "2502.02079v1",
    "title": "Online Clustering of Dueling Bandits",
    "authors": [
      "Zhiyong Wang",
      "Jiahang Sun",
      "Mingze Kong",
      "Jize Xie",
      "Qinghua Hu",
      "John C. S. Lui",
      "Zhongxiang Dai"
    ],
    "abstract": "The contextual multi-armed bandit (MAB) is a widely used framework for\nproblems requiring sequential decision-making under uncertainty, such as\nrecommendation systems. In applications involving a large number of users, the\nperformance of contextual MAB can be significantly improved by facilitating\ncollaboration among multiple users. This has been achieved by the clustering of\nbandits (CB) methods, which adaptively group the users into different clusters\nand achieve collaboration by allowing the users in the same cluster to share\ndata. However, classical CB algorithms typically rely on numerical reward\nfeedback, which may not be practical in certain real-world applications. For\ninstance, in recommendation systems, it is more realistic and reliable to\nsolicit preference feedback between pairs of recommended items rather than\nabsolute rewards. To address this limitation, we introduce the first\n\"clustering of dueling bandit algorithms\" to enable collaborative\ndecision-making based on preference feedback. We propose two novel algorithms:\n(1) Clustering of Linear Dueling Bandits (COLDB) which models the user reward\nfunctions as linear functions of the context vectors, and (2) Clustering of\nNeural Dueling Bandits (CONDB) which uses a neural network to model complex,\nnon-linear user reward functions. Both algorithms are supported by rigorous\ntheoretical analyses, demonstrating that user collaboration leads to improved\nregret bounds. Extensive empirical evaluations on synthetic and real-world\ndatasets further validate the effectiveness of our methods, establishing their\npotential in real-world applications involving multiple users with\npreference-based feedback.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.02079v1",
    "published_date": "2025-02-04 07:55:41 UTC",
    "updated_date": "2025-02-04 07:55:41 UTC"
  },
  {
    "arxiv_id": "2502.02072v1",
    "title": "ASCenD-BDS: Adaptable, Stochastic and Context-aware framework for Detection of Bias, Discrimination and Stereotyping",
    "authors": [
      "Rajiv Bahl",
      "Venkatesan N",
      "Parimal Aglawe",
      "Aastha Sarasapalli",
      "Bhavya Kancharla",
      "Chaitanya kolukuluri",
      "Harish Mohite",
      "Japneet Hora",
      "Kiran Kakollu",
      "Rahul Diman",
      "Shubham Kapale",
      "Sri Bhagya Kathula",
      "Vamsikrishna Motru",
      "Yogeshwar Reddy"
    ],
    "abstract": "The rapid evolution of Large Language Models (LLMs) has transformed natural\nlanguage processing but raises critical concerns about biases inherent in their\ndeployment and use across diverse linguistic and sociocultural contexts. This\npaper presents a framework named ASCenD BDS (Adaptable, Stochastic and\nContext-aware framework for Detection of Bias, Discrimination and\nStereotyping). The framework presents approach to detecting bias,\ndiscrimination, stereotyping across various categories such as gender, caste,\nage, disability, socioeconomic status, linguistic variations, etc., using an\napproach which is Adaptive, Stochastic and Context-Aware. The existing\nframeworks rely heavily on usage of datasets to generate scenarios for\ndetection of Bias, Discrimination and Stereotyping. Examples include datasets\nsuch as Civil Comments, Wino Gender, WinoBias, BOLD, CrowS Pairs and BBQ.\nHowever, such an approach provides point solutions. As a result, these datasets\nprovide a finite number of scenarios for assessment. The current framework\novercomes this limitation by having features which enable Adaptability,\nStochasticity, Context Awareness. Context awareness can be customized for any\nnation or culture or sub-culture (for example an organization's unique\nculture). In this paper, context awareness in the Indian context has been\nestablished. Content has been leveraged from Indian Census 2011 to have a\ncommonality of categorization. A framework has been developed using Category,\nSub-Category, STEM, X-Factor, Synonym to enable the features for Adaptability,\nStochasticity and Context awareness. The framework has been described in detail\nin Section 3. Overall 800 plus STEMs, 10 Categories, 31 unique SubCategories\nwere developed by a team of consultants at Saint Fox Consultancy Private Ltd.\nThe concept has been tested out in SFCLabs as part of product development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 6 Figures and this manuscript will be submitted to Q1,Q2\n  Journals",
    "pdf_url": "http://arxiv.org/pdf/2502.02072v1",
    "published_date": "2025-02-04 07:44:20 UTC",
    "updated_date": "2025-02-04 07:44:20 UTC"
  },
  {
    "arxiv_id": "2502.02067v2",
    "title": "AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement",
    "authors": [
      "Shivam Singh",
      "Karthik Swaminathan",
      "Nabanita Dash",
      "Ramandeep Singh",
      "Snehasis Banerjee",
      "Mohan Sridharan",
      "Madhava Krishna"
    ],
    "abstract": "An embodied agent assisting humans is often asked to complete new tasks, and\nthere may not be sufficient time or labeled examples to train the agent to\nperform these new tasks. Large Language Models (LLMs) trained on considerable\nknowledge across many domains can be used to predict a sequence of abstract\nactions for completing such tasks, although the agent may not be able to\nexecute this sequence due to task-, agent-, or domain-specific constraints. Our\nframework addresses these challenges by leveraging the generic predictions\nprovided by LLM and the prior domain knowledge encoded in a Knowledge Graph\n(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits\nand uses human input as needed to refine its existing knowledge. Based on\nexperimental evaluation in the context of cooking and cleaning tasks in\nsimulation domains, we demonstrate that the interplay between LLM, KG, and\nhuman input leads to substantial performance gains compared with just using the\nLLM. Project website{\\S}: https://sssshivvvv.github.io/adaptbot/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02067v2",
    "published_date": "2025-02-04 07:32:39 UTC",
    "updated_date": "2025-03-06 18:09:38 UTC"
  },
  {
    "arxiv_id": "2502.02063v1",
    "title": "CASIM: Composite Aware Semantic Injection for Text to Motion Generation",
    "authors": [
      "Che-Jui Chang",
      "Qingze Tony Liu",
      "Honglu Zhou",
      "Vladimir Pavlovic",
      "Mubbasir Kapadia"
    ],
    "abstract": "Recent advances in generative modeling and tokenization have driven\nsignificant progress in text-to-motion generation, leading to enhanced quality\nand realism in generated motions. However, effectively leveraging textual\ninformation for conditional motion generation remains an open challenge. We\nobserve that current approaches, primarily relying on fixed-length text\nembeddings (e.g., CLIP) for global semantic injection, struggle to capture the\ncomposite nature of human motion, resulting in suboptimal motion quality and\ncontrollability. To address this limitation, we propose the Composite Aware\nSemantic Injection Mechanism (CASIM), comprising a composite-aware semantic\nencoder and a text-motion aligner that learns the dynamic correspondence\nbetween text and motion tokens. Notably, CASIM is model and\nrepresentation-agnostic, readily integrating with both autoregressive and\ndiffusion-based methods. Experiments on HumanML3D and KIT benchmarks\ndemonstrate that CASIM consistently improves motion quality, text-motion\nalignment, and retrieval scores across state-of-the-art methods. Qualitative\nanalyses further highlight the superiority of our composite-aware approach over\nfixed-length semantic injection, enabling precise motion control from text\nprompts and stronger generalization to unseen text inputs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02063v1",
    "published_date": "2025-02-04 07:22:07 UTC",
    "updated_date": "2025-02-04 07:22:07 UTC"
  },
  {
    "arxiv_id": "2502.02060v1",
    "title": "CH-MARL: Constrained Hierarchical Multiagent Reinforcement Learning for Sustainable Maritime Logistics",
    "authors": [
      "Saad Alqithami"
    ],
    "abstract": "Addressing global challenges such as greenhouse gas emissions and resource\ninequity demands advanced AI-driven coordination among autonomous agents. We\npropose CH-MARL (Constrained Hierarchical Multiagent Reinforcement Learning), a\nnovel framework that integrates hierarchical decision-making with dynamic\nconstraint enforcement and fairness-aware reward shaping. CH-MARL employs a\nreal-time constraint-enforcement layer to ensure adherence to global emission\ncaps, while incorporating fairness metrics that promote equitable resource\ndistribution among agents. Experiments conducted in a simulated maritime\nlogistics environment demonstrate considerable reductions in emissions, along\nwith improvements in fairness and operational efficiency. Beyond this\ndomain-specific success, CH-MARL provides a scalable, generalizable solution to\nmulti-agent coordination challenges in constrained, dynamic settings, thus\nadvancing the state of the art in reinforcement learning.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02060v1",
    "published_date": "2025-02-04 07:13:21 UTC",
    "updated_date": "2025-02-04 07:13:21 UTC"
  },
  {
    "arxiv_id": "2502.18471v1",
    "title": "FinBloom: Knowledge Grounding Large Language Model with Real-time Financial Data",
    "authors": [
      "Ankur Sinha",
      "Chaitanya Agarwal",
      "Pekka Malo"
    ],
    "abstract": "Large language models (LLMs) excel at generating human-like responses but\noften struggle with interactive tasks that require access to real-time\ninformation. This limitation poses challenges in finance, where models must\naccess up-to-date information, such as recent news or price movements, to\nsupport decision-making. To address this, we introduce Financial Agent, a\nknowledge-grounding approach for LLMs to handle financial queries using\nreal-time text and tabular data. Our contributions are threefold: First, we\ndevelop a Financial Context Dataset of over 50,000 financial queries paired\nwith the required context. Second, we train FinBloom 7B, a custom 7 billion\nparameter LLM, on 14 million financial news articles from Reuters and Deutsche\nPresse-Agentur, alongside 12 million Securities and Exchange Commission (SEC)\nfilings. Third, we fine-tune FinBloom 7B using the Financial Context Dataset to\nserve as a Financial Agent. This agent generates relevant financial context,\nenabling efficient real-time data retrieval to answer user queries. By reducing\nlatency and eliminating the need for users to manually provide accurate data,\nour approach significantly enhances the capability of LLMs to handle dynamic\nfinancial tasks. Our proposed approach makes real-time financial decisions,\nalgorithmic trading and other related tasks streamlined, and is valuable in\ncontexts with high-velocity data flows.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "q-fin.ST"
    ],
    "primary_category": "cs.IR",
    "comment": "27 pages, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.18471v1",
    "published_date": "2025-02-04 06:51:34 UTC",
    "updated_date": "2025-02-04 06:51:34 UTC"
  },
  {
    "arxiv_id": "2502.02054v1",
    "title": "RAPID: Robust and Agile Planner Using Inverse Reinforcement Learning for Vision-Based Drone Navigation",
    "authors": [
      "Minwoo Kim",
      "Geunsik Bae",
      "Jinwoo Lee",
      "Woojae Shin",
      "Changseung Kim",
      "Myong-Yol Choi",
      "Heejung Shin",
      "Hyondong Oh"
    ],
    "abstract": "This paper introduces a learning-based visual planner for agile drone flight\nin cluttered environments. The proposed planner generates collision-free\nwaypoints in milliseconds, enabling drones to perform agile maneuvers in\ncomplex environments without building separate perception, mapping, and\nplanning modules. Learning-based methods, such as behavior cloning (BC) and\nreinforcement learning (RL), demonstrate promising performance in visual\nnavigation but still face inherent limitations. BC is susceptible to\ncompounding errors due to limited expert imitation, while RL struggles with\nreward function design and sample inefficiency. To address these limitations,\nthis paper proposes an inverse reinforcement learning (IRL)-based framework for\nhigh-speed visual navigation. By leveraging IRL, it is possible to reduce the\nnumber of interactions with simulation environments and improve capability to\ndeal with high-dimensional spaces while preserving the robustness of RL\npolicies. A motion primitive-based path planning algorithm collects an expert\ndataset with privileged map data from diverse environments, ensuring\ncomprehensive scenario coverage. By leveraging both the acquired expert and\nlearner dataset gathered from the agent's interactions with the simulation\nenvironments, a robust reward function and policy are learned across diverse\nstates. While the proposed method is trained in a simulation environment only,\nit can be directly applied to real-world scenarios without additional training\nor tuning. The performance of the proposed method is validated in both\nsimulation and real-world environments, including forests and various\nstructures. The trained policy achieves an average speed of 7 m/s and a maximum\nspeed of 8.8 m/s in real flight experiments. To the best of our knowledge, this\nis the first work to successfully apply an IRL framework for high-speed visual\nnavigation of drones.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "18 pages, 11 figures, 58 references, and appendix is included",
    "pdf_url": "http://arxiv.org/pdf/2502.02054v1",
    "published_date": "2025-02-04 06:42:08 UTC",
    "updated_date": "2025-02-04 06:42:08 UTC"
  },
  {
    "arxiv_id": "2502.02040v1",
    "title": "M2R2: Mixture of Multi-Rate Residuals for Efficient Transformer Inference",
    "authors": [
      "Nikhil Bhendawade",
      "Mahyar Najibi",
      "Devang Naik",
      "Irina Belousova"
    ],
    "abstract": "Residual transformations enhance the representational depth and expressive\npower of large language models (LLMs). However, applying static residual\ntransformations across all tokens in auto-regressive generation leads to a\nsuboptimal trade-off between inference efficiency and generation fidelity.\nExisting methods, including Early Exiting, Skip Decoding, and Mixture-of-Depth\naddress this by modulating the residual transformation based on token-level\ncomplexity. Nevertheless, these approaches predominantly consider the distance\ntraversed by tokens through the model layers, neglecting the underlying\nvelocity of residual evolution. We introduce Mixture of Multi-rate Residuals\n(M2R2), a framework that dynamically modulates residual velocity to improve\nearly alignment, enhancing inference efficiency. Evaluations on reasoning\noriented tasks such as Koala, Self-Instruct, WizardLM, and MT-Bench show M2R2\nsurpasses state-of-the-art distance-based strategies, balancing generation\nquality and speedup. In self-speculative decoding setup, M2R2 achieves up to\n2.8x speedups on MT-Bench, outperforming methods like 2-model speculative\ndecoding, Medusa, LookAhead Decoding, and DEED. In Mixture-of-Experts (MoE)\narchitectures, integrating early residual alignment with ahead-of-time expert\nloading into high-bandwidth memory (HBM) accelerates decoding, reduces\nexpert-switching bottlenecks, and achieves a 2.9x speedup, making it highly\neffective in resource-constrained environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02040v1",
    "published_date": "2025-02-04 06:13:52 UTC",
    "updated_date": "2025-02-04 06:13:52 UTC"
  },
  {
    "arxiv_id": "2502.02036v1",
    "title": "From Human Hands to Robotic Limbs: A Study in Motor Skill Embodiment for Telemanipulation",
    "authors": [
      "Haoyi Shi",
      "Mingxi Su",
      "Ted Morris",
      "Vassilios Morellas",
      "Nikolaos Papanikolopoulos"
    ],
    "abstract": "This paper presents a teleoperation system for controlling a redundant degree\nof freedom robot manipulator using human arm gestures. We propose a GRU-based\nVariational Autoencoder to learn a latent representation of the manipulator's\nconfiguration space, capturing its complex joint kinematics. A fully connected\nneural network maps human arm configurations into this latent space, allowing\nthe system to mimic and generate corresponding manipulator trajectories in real\ntime through the VAE decoder. The proposed method shows promising results in\nteleoperating the manipulator, enabling the generation of novel manipulator\nconfigurations from human features that were not present during training.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02036v1",
    "published_date": "2025-02-04 05:52:57 UTC",
    "updated_date": "2025-02-04 05:52:57 UTC"
  },
  {
    "arxiv_id": "2502.02032v1",
    "title": "Heteroscedastic Double Bayesian Elastic Net",
    "authors": [
      "Masanari Kimura"
    ],
    "abstract": "In many practical applications, regression models are employed to uncover\nrelationships between predictors and a response variable, yet the common\nassumption of constant error variance is frequently violated. This issue is\nfurther compounded in high-dimensional settings where the number of predictors\nexceeds the sample size, necessitating regularization for effective estimation\nand variable selection. To address this problem, we propose the Heteroscedastic\nDouble Bayesian Elastic Net (HDBEN), a novel framework that jointly models the\nmean and log-variance using hierarchical Bayesian priors incorporating both\n$\\ell_1$ and $\\ell_2$ penalties. Our approach simultaneously induces sparsity\nand grouping in the regression coefficients and variance parameters, capturing\ncomplex variance structures in the data. Theoretical results demonstrate that\nproposed HDBEN achieves posterior concentration, variable selection\nconsistency, and asymptotic normality under mild conditions which justifying\nits behavior. Simulation studies further illustrate that HDBEN outperforms\nexisting methods, particularly in scenarios characterized by heteroscedasticity\nand high dimensionality.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02032v1",
    "published_date": "2025-02-04 05:44:19 UTC",
    "updated_date": "2025-02-04 05:44:19 UTC"
  },
  {
    "arxiv_id": "2502.02028v2",
    "title": "Fine-tuning Language Models for Recipe Generation: A Comparative Analysis and Benchmark Study",
    "authors": [
      "Anneketh Vij",
      "Changhao Liu",
      "Rahul Anil Nair",
      "Theodore Eugene Ho",
      "Edward Shi",
      "Ayan Bhowmick"
    ],
    "abstract": "This research presents an exploration and study of the recipe generation task\nby fine-tuning various very small language models, with a focus on developing\nrobust evaluation metrics and comparing across different language models the\nopen-ended task of recipe generation. This study presents extensive experiments\nwith multiple model architectures, ranging from T5-small (Raffel et al., 2023)\nand SmolLM-135M(Allal et al., 2024) to Phi-2 (Research, 2023), implementing\nboth traditional NLP metrics and custom domain-specific evaluation metrics. Our\nnovel evaluation framework incorporates recipe-specific metrics for assessing\ncontent quality and introduces approaches to allergen substitution. The results\nindicate that, while larger models generally perform better on standard\nmetrics, the relationship between model size and recipe quality is more nuanced\nwhen considering domain-specific metrics. SmolLM-360M and SmolLM-1.7B\ndemonstrate comparable performance despite their size difference before and\nafter fine-tuning, while fine-tuning Phi-2 shows notable limitations in recipe\ngeneration despite its larger parameter count. The comprehensive evaluation\nframework and allergen substitution systems provide valuable insights for\nfuture work in recipe generation and broader NLG tasks that require domain\nexpertise and safety considerations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 10 figures,14 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.02028v2",
    "published_date": "2025-02-04 05:25:01 UTC",
    "updated_date": "2025-02-16 23:50:00 UTC"
  },
  {
    "arxiv_id": "2502.02027v4",
    "title": "From Fog to Failure: The Unintended Consequences of Dehazing on Object Detection in Clear Images",
    "authors": [
      "Ashutosh Kumar",
      "Aman Chadha"
    ],
    "abstract": "This study explores the challenges of integrating human visual cue-based\ndehazing into object detection, given the selective nature of human perception.\nWhile human vision adapts dynamically to environmental conditions,\ncomputational dehazing does not always enhance detection uniformly. We propose\na multi-stage framework where a lightweight detector identifies regions of\ninterest (RoIs), which are then improved via spatial attention-based dehazing\nbefore final detection by a heavier model. Though effective in foggy\nconditions, this approach unexpectedly degrades the performance on clear\nimages. We analyze this phenomenon, investigate possible causes, and offer\ninsights for designing hybrid pipelines that balance enhancement and detection.\nOur findings highlight the need for selective preprocessing and challenge\nassumptions about universal benefits from cascading transformations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02027v4",
    "published_date": "2025-02-04 05:24:44 UTC",
    "updated_date": "2025-03-16 14:10:05 UTC"
  },
  {
    "arxiv_id": "2502.02017v1",
    "title": "Multi-Domain Graph Foundation Models: Robust Knowledge Transfer via Topology Alignment",
    "authors": [
      "Shuo Wang",
      "Bokui Wang",
      "Zhixiang Shen",
      "Boyan Deng",
      "Zhao Kang"
    ],
    "abstract": "Recent advances in CV and NLP have inspired researchers to develop\ngeneral-purpose graph foundation models through pre-training across diverse\ndomains. However, a fundamental challenge arises from the substantial\ndifferences in graph topologies across domains. Additionally, real-world graphs\nare often sparse and prone to noisy connections and adversarial attacks. To\naddress these issues, we propose the Multi-Domain Graph Foundation Model\n(MDGFM), a unified framework that aligns and leverages cross-domain topological\ninformation to facilitate robust knowledge transfer. MDGFM bridges different\ndomains by adaptively balancing features and topology while refining original\ngraphs to eliminate noise and align topological structures. To further enhance\nknowledge transfer, we introduce an efficient prompt-tuning approach. By\naligning topologies, MDGFM not only improves multi-domain pre-training but also\nenables robust knowledge transfer to unseen domains. Theoretical analyses\nprovide guarantees of MDGFM's effectiveness and domain generalization\ncapabilities. Extensive experiments on both homophilic and heterophilic graph\ndatasets validate the robustness and efficacy of our method.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02017v1",
    "published_date": "2025-02-04 05:09:23 UTC",
    "updated_date": "2025-02-04 05:09:23 UTC"
  },
  {
    "arxiv_id": "2502.02016v1",
    "title": "A Periodic Bayesian Flow for Material Generation",
    "authors": [
      "Hanlin Wu",
      "Yuxuan Song",
      "Jingjing Gong",
      "Ziyao Cao",
      "Yawen Ouyang",
      "Jianbing Zhang",
      "Hao Zhou",
      "Wei-Ying Ma",
      "Jingjing Liu"
    ],
    "abstract": "Generative modeling of crystal data distribution is an important yet\nchallenging task due to the unique periodic physical symmetry of crystals.\nDiffusion-based methods have shown early promise in modeling crystal\ndistribution. More recently, Bayesian Flow Networks were introduced to\naggregate noisy latent variables, resulting in a variance-reduced parameter\nspace that has been shown to be advantageous for modeling Euclidean data\ndistributions with structural constraints (Song et al., 2023). Inspired by\nthis, we seek to unlock its potential for modeling variables located in\nnon-Euclidean manifolds e.g. those within crystal structures, by overcoming\nchallenging theoretical issues. We introduce CrysBFN, a novel crystal\ngeneration method by proposing a periodic Bayesian flow, which essentially\ndiffers from the original Gaussian-based BFN by exhibiting non-monotonic\nentropy dynamics. To successfully realize the concept of periodic Bayesian\nflow, CrysBFN integrates a new entropy conditioning mechanism and empirically\ndemonstrates its significance compared to time-conditioning. Extensive\nexperiments over both crystal ab initio generation and crystal structure\nprediction tasks demonstrate the superiority of CrysBFN, which consistently\nachieves new state-of-the-art on all benchmarks. Surprisingly, we found that\nCrysBFN enjoys a significant improvement in sampling efficiency, e.g., ~100x\nspeedup 10 v.s. 2000 steps network forwards) compared with previous\ndiffusion-based methods on MP-20 dataset. Code is available at\nhttps://github.com/wu-han-lin/CrysBFN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR25",
    "pdf_url": "http://arxiv.org/pdf/2502.02016v1",
    "published_date": "2025-02-04 05:07:13 UTC",
    "updated_date": "2025-02-04 05:07:13 UTC"
  },
  {
    "arxiv_id": "2502.02014v2",
    "title": "Analytical Lyapunov Function Discovery: An RL-based Generative Approach",
    "authors": [
      "Haohan Zou",
      "Jie Feng",
      "Hao Zhao",
      "Yuanyuan Shi"
    ],
    "abstract": "Despite advances in learning-based methods, finding valid Lyapunov functions\nfor nonlinear dynamical systems remains challenging. Current neural network\napproaches face two main issues: challenges in scalable verification and\nlimited interpretability. To address these, we propose an end-to-end framework\nusing transformers to construct analytical Lyapunov functions (local), which\nsimplifies formal verification, enhances interpretability, and provides\nvaluable insights for control engineers. Our framework consists of a\ntransformer-based trainer that generates candidate Lyapunov functions and a\nfalsifier that verifies candidate expressions and refines the model via\nrisk-seeking policy gradient. Unlike Alfarano et al. (2024), which utilizes\npre-training and seeks global Lyapunov functions for low-dimensional systems,\nour model is trained from scratch via reinforcement learning (RL) and succeeds\nin finding local Lyapunov functions for high-dimensional and non-polynomial\nsystems. Given the analytical nature of the candidates, we employ efficient\noptimization methods for falsification during training and formal verification\ntools for the final verification. We demonstrate the efficiency of our approach\non a range of nonlinear dynamical systems with up to ten dimensions and show\nthat it can discover Lyapunov functions not previously identified in the\ncontrol literature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages (8+18), preprint for discussion. Haohan and Jie contribute\n  equally",
    "pdf_url": "http://arxiv.org/pdf/2502.02014v2",
    "published_date": "2025-02-04 05:04:15 UTC",
    "updated_date": "2025-02-11 00:19:47 UTC"
  },
  {
    "arxiv_id": "2502.02013v1",
    "title": "Layer by Layer: Uncovering Hidden Representations in Language Models",
    "authors": [
      "Oscar Skean",
      "Md Rifat Arefin",
      "Dan Zhao",
      "Niket Patel",
      "Jalal Naghiyev",
      "Yann LeCun",
      "Ravid Shwartz-Ziv"
    ],
    "abstract": "From extracting features to generating text, the outputs of large language\nmodels (LLMs) typically rely on their final layers, following the conventional\nwisdom that earlier layers capture only low-level cues. However, our analysis\nshows that intermediate layers can encode even richer representations, often\nimproving performance on a wide range of downstream tasks. To explain and\nquantify these hidden-layer properties, we propose a unified framework of\nrepresentation quality metrics based on information theory, geometry, and\ninvariance to input perturbations. Our framework highlights how each model\nlayer balances information compression and signal preservation, revealing why\nmid-depth embeddings can exceed the last layer's performance. Through extensive\nexperiments on 32 text-embedding tasks and comparisons across model\narchitectures (transformers, state-space models) and domains (language,\nvision), we demonstrate that intermediate layers consistently provide stronger\nfeatures. These findings challenge the standard focus on final-layer embeddings\nand open new directions for model analysis and optimization, including\nstrategic use of mid-layer representations for more robust and accurate AI\nsystems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02013v1",
    "published_date": "2025-02-04 05:03:42 UTC",
    "updated_date": "2025-02-04 05:03:42 UTC"
  },
  {
    "arxiv_id": "2502.02009v1",
    "title": "LLMSecConfig: An LLM-Based Approach for Fixing Software Container Misconfigurations",
    "authors": [
      "Ziyang Ye",
      "Triet Huynh Minh Le",
      "M. Ali Babar"
    ],
    "abstract": "Security misconfigurations in Container Orchestrators (COs) can pose serious\nthreats to software systems. While Static Analysis Tools (SATs) can effectively\ndetect these security vulnerabilities, the industry currently lacks automated\nsolutions capable of fixing these misconfigurations. The emergence of Large\nLanguage Models (LLMs), with their proven capabilities in code understanding\nand generation, presents an opportunity to address this limitation. This study\nintroduces LLMSecConfig, an innovative framework that bridges this gap by\ncombining SATs with LLMs. Our approach leverages advanced prompting techniques\nand Retrieval-Augmented Generation (RAG) to automatically repair security\nmisconfigurations while preserving operational functionality. Evaluation of\n1,000 real-world Kubernetes configurations achieved a 94\\% success rate while\nmaintaining a low rate of introducing new misconfigurations.\n  Our work makes a promising step towards automated container security\nmanagement, reducing the manual effort required for configuration maintenance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02009v1",
    "published_date": "2025-02-04 04:56:34 UTC",
    "updated_date": "2025-02-04 04:56:34 UTC"
  },
  {
    "arxiv_id": "2503.04738v1",
    "title": "Copyright in AI-generated works: Lessons from recent developments in patent law",
    "authors": [
      "Rita Matulionyte",
      "Jyh-An Lee"
    ],
    "abstract": "In Thaler v The Comptroller-General of Patents, Designs and Trade Marks\n(DABUS), Smith J. held that an AI owner can possibly claim patent ownership\nover an AI-generated invention based on their ownership and control of the AI\nsystem. This AI-owner approach reveals a new option to allocate property rights\nover AI-generated output. While this judgment was primarily about inventorship\nand ownership of AI-generated invention in patent law, it has important\nimplications for copyright law. After analysing the weaknesses of applying\nexisting judicial approaches to copyright ownership of AI-generated works, this\npaper examines whether the AI-owner approach is a better option for determining\ncopyright ownership of AI-generated works. The paper argues that while\ncontracts can be used to work around the AI-owner approach in scenarios where\nusers want to commercially exploit the outputs, this approach still provides\nmore certainty and less transaction costs for relevant parties than other\napproaches proposed so far.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04738v1",
    "published_date": "2025-02-04 04:16:44 UTC",
    "updated_date": "2025-02-04 04:16:44 UTC"
  },
  {
    "arxiv_id": "2502.01995v1",
    "title": "Theoretical and Practical Analysis of Fréchet Regression via Comparison Geometry",
    "authors": [
      "Masanari Kimura",
      "Howard Bondell"
    ],
    "abstract": "Fr\\'echet regression extends classical regression methods to non-Euclidean\nmetric spaces, enabling the analysis of data relationships on complex\nstructures such as manifolds and graphs. This work establishes a rigorous\ntheoretical analysis for Fr\\'echet regression through the lens of comparison\ngeometry which leads to important considerations for its use in practice. The\nanalysis provides key results on the existence, uniqueness, and stability of\nthe Fr\\'echet mean, along with statistical guarantees for nonparametric\nregression, including exponential concentration bounds and convergence rates.\nAdditionally, insights into angle stability reveal the interplay between\ncurvature of the manifold and the behavior of the regression estimator in these\nnon-Euclidean contexts. Empirical experiments validate the theoretical\nfindings, demonstrating the effectiveness of proposed hyperbolic mappings,\nparticularly for data with heteroscedasticity, and highlighting the practical\nusefulness of these results.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01995v1",
    "published_date": "2025-02-04 04:16:00 UTC",
    "updated_date": "2025-02-04 04:16:00 UTC"
  },
  {
    "arxiv_id": "2502.01991v2",
    "title": "Can LLMs Assist Annotators in Identifying Morality Frames? -- Case Study on Vaccination Debate on Social Media",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "abstract": "Nowadays, social media is pivotal in shaping public discourse, especially on\npolarizing issues like vaccination, where diverse moral perspectives influence\nindividual opinions. In NLP, data scarcity and complexity of psycholinguistic\ntasks, such as identifying morality frames, make relying solely on human\nannotators costly, time-consuming, and prone to inconsistency due to cognitive\nload. To address these issues, we leverage large language models (LLMs), which\nare adept at adapting new tasks through few-shot learning, utilizing a handful\nof in-context examples coupled with explanations that connect examples to task\nprinciples. Our research explores LLMs' potential to assist human annotators in\nidentifying morality frames within vaccination debates on social media. We\nemploy a two-step process: generating concepts and explanations with LLMs,\nfollowed by human evaluation using a \"think-aloud\" tool. Our study shows that\nintegrating LLMs into the annotation process enhances accuracy, reduces task\ndifficulty, lowers cognitive load, suggesting a promising avenue for human-AI\ncollaboration in complex psycholinguistic tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 17th ACM Web Science Conference 2025 (WebSci'25)",
    "pdf_url": "http://arxiv.org/pdf/2502.01991v2",
    "published_date": "2025-02-04 04:10:23 UTC",
    "updated_date": "2025-02-05 03:16:10 UTC"
  },
  {
    "arxiv_id": "2502.01980v1",
    "title": "Generative Data Mining with Longtail-Guided Diffusion",
    "authors": [
      "David S. Hayden",
      "Mao Ye",
      "Timur Garipov",
      "Gregory P. Meyer",
      "Carl Vondrick",
      "Zhao Chen",
      "Yuning Chai",
      "Eric Wolff",
      "Siddhartha S. Srinivasa"
    ],
    "abstract": "It is difficult to anticipate the myriad challenges that a predictive model\nwill encounter once deployed. Common practice entails a reactive, cyclical\napproach: model deployment, data mining, and retraining. We instead develop a\nproactive longtail discovery process by imagining additional data during\ntraining. In particular, we develop general model-based longtail signals,\nincluding a differentiable, single forward pass formulation of epistemic\nuncertainty that does not impact model parameters or predictive performance but\ncan flag rare or hard inputs. We leverage these signals as guidance to generate\nadditional training data from a latent diffusion model in a process we call\nLongtail Guidance (LTG). Crucially, we can perform LTG without retraining the\ndiffusion model or the predictive model, and we do not need to expose the\npredictive model to intermediate diffusion states. Data generated by LTG\nexhibit semantically meaningful variation, yield significant generalization\nimprovements on image classification benchmarks, and can be analyzed to\nproactively discover, explain, and address conceptual gaps in a predictive\nmodel.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01980v1",
    "published_date": "2025-02-04 03:51:00 UTC",
    "updated_date": "2025-02-04 03:51:00 UTC"
  },
  {
    "arxiv_id": "2502.04346v1",
    "title": "Multi-Lingual Cyber Threat Detection in Tweets/X Using ML, DL, and LLM: A Comparative Analysis",
    "authors": [
      "Saydul Akbar Murad",
      "Ashim Dahal",
      "Nick Rahimi"
    ],
    "abstract": "Cyber threat detection has become an important area of focus in today's\ndigital age due to the growing spread of fake information and harmful content\non social media platforms such as Twitter (now 'X'). These cyber threats, often\ndisguised within tweets, pose significant risks to individuals, communities,\nand even nations, emphasizing the need for effective detection systems. While\nprevious research has explored tweet-based threats, much of the work is limited\nto specific languages, domains, or locations, or relies on single-model\napproaches, reducing their applicability to diverse real-world scenarios. To\naddress these gaps, our study focuses on multi-lingual tweet cyber threat\ndetection using a variety of advanced models. The research was conducted in\nthree stages: (1) We collected and labeled tweet datasets in four languages\nEnglish, Chinese, Russian, and Arabic employing both manual and polarity-based\nlabeling methods to ensure high-quality annotations. (2) Each dataset was\nanalyzed individually using machine learning (ML) and deep learning (DL) models\nto assess their performance on distinct languages. (3) Finally, we combined all\nfour datasets into a single multi-lingual dataset and applied DL and large\nlanguage model (LLM) architectures to evaluate their efficacy in identifying\ncyber threats across various languages. Our results show that among machine\nlearning models, Random Forest (RF) attained the highest performance; however,\nthe Bi-LSTM architecture consistently surpassed other DL and LLM architectures\nacross all datasets. These findings underline the effectiveness of Bi-LSTM in\nmultilingual cyber threat detection. The code for this paper can be found at\nthis link: https://github.com/Mmurrad/Tweet-Data-Classification.git.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04346v1",
    "published_date": "2025-02-04 03:46:24 UTC",
    "updated_date": "2025-02-04 03:46:24 UTC"
  },
  {
    "arxiv_id": "2502.01976v5",
    "title": "CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing",
    "authors": [
      "Wenhao Zheng",
      "Yixiao Chen",
      "Weitong Zhang",
      "Souvik Kundu",
      "Yun Li",
      "Zhengzhong Liu",
      "Eric P. Xing",
      "Hongyi Wang",
      "Huaxiu Yao"
    ],
    "abstract": "Large language models have achieved remarkable success in various tasks but\nsuffer from high computational costs during inference, limiting their\ndeployment in resource-constrained applications. To address this issue, we\npropose a novel Collaborative Inference with Token-lEvel Routing (CITER)\nframework that enables efficient collaboration between small and large language\nmodels (SLMs \\& LLMs) through a token-level routing strategy. Specifically,\nCITER routes non-critical tokens to an SLM for efficiency and routes critical\ntokens to an LLM for generalization quality. We formulate router training as a\npolicy optimization, where the router receives rewards based on both the\nquality of predictions and the inference costs of generation. This allows the\nrouter to learn to predict token-level routing scores and make routing\ndecisions based on both the current token and the future impact of its\ndecisions. To further accelerate the reward evaluation process, we introduce a\nshortcut which significantly reduces the costs of the reward estimation and\nimproving the practicality of our approach. Extensive experiments on five\nbenchmark datasets demonstrate that CITER reduces the inference costs while\npreserving high-quality generation, offering a promising solution for real-time\nand resource-constrained applications. Our data and code are available at\nhttps://github.com/aiming-lab/CITER.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01976v5",
    "published_date": "2025-02-04 03:36:44 UTC",
    "updated_date": "2025-05-01 20:11:36 UTC"
  },
  {
    "arxiv_id": "2502.06809v2",
    "title": "Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution",
    "authors": [
      "Muhammad Umair Haider",
      "Hammad Rizwan",
      "Hassan Sajjad",
      "Peizhong Ju",
      "A. B. Siddique"
    ],
    "abstract": "Interpreting the internal mechanisms of large language models (LLMs) is\ncrucial for improving their trustworthiness and utility. Prior work has\nprimarily focused on mapping individual neurons to discrete semantic concepts.\nHowever, such mappings struggle to handle the inherent polysemanticity in LLMs,\nwhere individual neurons encode multiple, distinct concepts. Through a\ncomprehensive analysis of both encoder and decoder-based LLMs across diverse\ndatasets, we observe that even highly salient neurons, identified via various\nattribution techniques for specific semantic concepts, consistently exhibit\npolysemantic behavior. Importantly, activation magnitudes for fine-grained\nconcepts follow distinct, often Gaussian-like distributions with minimal\noverlap. This observation motivates a shift from neuron attribution to\nrange-based interpretation. We hypothesize that interpreting and manipulating\nneuron activation ranges would enable more precise interpretability and\ntargeted interventions in LLMs. To validate our hypothesis, we introduce\nNeuronLens, a novel range-based interpretation and manipulation framework that\nprovides a finer view of neuron activation distributions to localize concept\nattribution within a neuron. Extensive empirical evaluations demonstrate that\nNeuronLens significantly reduces unintended interference, while maintaining\nprecise manipulation of targeted concepts, outperforming neuron attribution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06809v2",
    "published_date": "2025-02-04 03:33:55 UTC",
    "updated_date": "2025-05-21 03:16:45 UTC"
  },
  {
    "arxiv_id": "2502.01972v1",
    "title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography",
    "authors": [
      "Haolin Wang",
      "Yafei Ou",
      "Prasoon Ambalathankandy",
      "Gen Ota",
      "Pengyu Dai",
      "Masayuki Ikebe",
      "Kenji Suzuki",
      "Tamotsu Kamishima"
    ],
    "abstract": "Rheumatoid arthritis (RA) is a chronic autoimmune disease characterized by\njoint inflammation and progressive structural damage. Joint space width (JSW)\nis a critical indicator in conventional radiography for evaluating disease\nprogression, which has become a prominent research topic in computer-aided\ndiagnostic (CAD) systems. However, deep learning-based radiological CAD systems\nfor JSW analysis face significant challenges in data quality, including data\nimbalance, limited variety, and annotation difficulties. This work introduced a\nchallenging image synthesis scenario and proposed Layer Separation Networks\n(LSN) to accurately separate the soft tissue layer, the upper bone layer, and\nthe lower bone layer in conventional radiographs of finger joints. Using these\nlayers, the adjustable JSW images can be synthesized to address data quality\nchallenges and achieve ground truth (GT) generation. Experimental results\ndemonstrated that LSN-based synthetic images closely resemble real radiographs,\nand significantly enhanced the performance in downstream tasks. The code and\ndataset will be available.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.3.3; J.3; I.4.0"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01972v1",
    "published_date": "2025-02-04 03:33:52 UTC",
    "updated_date": "2025-02-04 03:33:52 UTC"
  },
  {
    "arxiv_id": "2502.01969v1",
    "title": "Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration",
    "authors": [
      "Younan Zhu",
      "Linwei Tao",
      "Minjing Dong",
      "Chang Xu"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning\ncapabilities but remain highly susceptible to object hallucination, where\nmodels generate responses that are not factually aligned with the visual\ncontent. Recent works attribute this issue to an inherent bias of LVLMs where\nvision token attention map has a fixed correlation with spatial position, and\npropose to mitigate this issue by reordering visual tokens. However, we find\nthat different LVLMs exhibit different correlations between attention and\nspatial position, which makes the existing solution difficult to generalize to\nother LVLMs. To address this issue, we first introduce a training-free\nsolution, Uniform Attention Calibration (UAC), that estimates the bias from\nsingle meaningless input image and applies a calibration matrix to rectify\nattention imbalances. To further alleviate the bias, we relax the assumption of\nsingle meaningless input in UAC and introduce a fine-tuning solution, Dynamic\nAttention Calibration (DAC), that enforces the consistent outputs wherever the\nobject locates in the image via a plug-and-plays module. Comprehensive\nexperiments across multiple benchmarks demonstrate that UAC and DAC\nsignificantly reduce object hallucination while improving general multimodal\nalignment. Our methods achieve state-of-the-art performance across diverse LVLM\narchitectures on various metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01969v1",
    "published_date": "2025-02-04 03:27:38 UTC",
    "updated_date": "2025-02-04 03:27:38 UTC"
  },
  {
    "arxiv_id": "2502.01968v1",
    "title": "Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning",
    "authors": [
      "Jinlong Pang",
      "Na Di",
      "Zhaowei Zhu",
      "Jiaheng Wei",
      "Hao Cheng",
      "Chen Qian",
      "Yang Liu"
    ],
    "abstract": "Recent studies show that in supervised fine-tuning (SFT) of large language\nmodels (LLMs), data quality matters more than quantity. While most data\ncleaning methods concentrate on filtering entire samples, the quality of\nindividual tokens within a sample can vary significantly. After pre-training,\neven in high-quality samples, patterns or phrases that are not task-related can\nbe redundant or uninformative. Continuing to fine-tune on these patterns may\noffer limited benefit and even degrade downstream task performance. In this\npaper, we investigate token quality from a noisy-label perspective and propose\na generic token cleaning pipeline for SFT tasks. Our method filters out\nuninformative tokens while preserving those carrying key task-specific\ninformation. Specifically, we first evaluate token quality by examining the\ninfluence of model updates on each token, then apply a threshold-based\nseparation. The token influence can be measured in a single pass with a fixed\nreference model or iteratively with self-evolving reference models. The\nbenefits and limitations of both methods are analyzed theoretically by error\nupper bounds. Extensive experiments show that our framework consistently\nimproves performance across multiple downstream tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01968v1",
    "published_date": "2025-02-04 03:26:58 UTC",
    "updated_date": "2025-02-04 03:26:58 UTC"
  },
  {
    "arxiv_id": "2503.15527v1",
    "title": "Exploring the Panorama of Anxiety Levels: A Multi-Scenario Study Based on Human-Centric Anxiety Level Detection and Personalized Guidance",
    "authors": [
      "Longdi Xian",
      "Junhao Xu"
    ],
    "abstract": "More and more people are experiencing pressure from work, life, and\neducation. These pressures often lead to an anxious state of mind, or even the\nearly symptoms of suicidal ideation. With the advancement of artificial\nintelligence (AI) technology, large language models have become one of the most\nprominent technologies. They are often used for detecting psychological\ndisorders. However, current studies primarily provide categorization results\nwithout offering interpretable explanations for these results. To address this\ngap, this study adopts a person-centered perspective and focuses on\nGPT-generated multi-scenario simulated conversations. These simulated\nconversations were selected as data samples for the study. Various\ntransformer-based encoder models were utilized to develop a classification\nmodel capable of identifying different levels of anxiety. Additionally, a\nknowledge base focusing on anxiety was constructed using LangChain and GPT-4.\nWhen analyzing classification results, this knowledge base was able to provide\nexplanations and reasons most relevant to the interlocutor's anxiety situation.\nThe study demonstrates that the proposed model achieves over 94% accuracy in\ncategorical prediction, and the advice provided is highly personalized and\nrelevant.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15527v1",
    "published_date": "2025-02-04 03:14:21 UTC",
    "updated_date": "2025-02-04 03:14:21 UTC"
  },
  {
    "arxiv_id": "2502.01956v1",
    "title": "DHP: Discrete Hierarchical Planning for Hierarchical Reinforcement Learning Agents",
    "authors": [
      "Shashank Sharma",
      "Janina Hoffmann",
      "Vinay Namboodiri"
    ],
    "abstract": "In this paper, we address the challenge of long-horizon visual planning tasks\nusing Hierarchical Reinforcement Learning (HRL). Our key contribution is a\nDiscrete Hierarchical Planning (DHP) method, an alternative to traditional\ndistance-based approaches. We provide theoretical foundations for the method\nand demonstrate its effectiveness through extensive empirical evaluations.\n  Our agent recursively predicts subgoals in the context of a long-term goal\nand receives discrete rewards for constructing plans as compositions of\nabstract actions. The method introduces a novel advantage estimation strategy\nfor tree trajectories, which inherently encourages shorter plans and enables\ngeneralization beyond the maximum tree depth. The learned policy function\nallows the agent to plan efficiently, requiring only $\\log N$ computational\nsteps, making re-planning highly efficient. The agent, based on a soft-actor\ncritic (SAC) framework, is trained using on-policy imagination data.\nAdditionally, we propose a novel exploration strategy that enables the agent to\ngenerate relevant training examples for the planning modules. We evaluate our\nmethod on long-horizon visual planning tasks in a 25-room environment, where it\nsignificantly outperforms previous benchmarks at success rate and average\nepisode length. Furthermore, an ablation study highlights the individual\ncontributions of key modules to the overall performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01956v1",
    "published_date": "2025-02-04 03:05:55 UTC",
    "updated_date": "2025-02-04 03:05:55 UTC"
  },
  {
    "arxiv_id": "2502.06808v3",
    "title": "On the Benefits of Attribute-Driven Graph Domain Adaptation",
    "authors": [
      "Ruiyi Fang",
      "Bingheng Li",
      "Zhao Kang",
      "Qiuhao Zeng",
      "Nima Hosseini Dashtbayaz",
      "Ruizhi Pu",
      "Boyu Wang",
      "Charles Ling"
    ],
    "abstract": "Graph Domain Adaptation (GDA) addresses a pressing challenge in cross-network\nlearning, particularly pertinent due to the absence of labeled data in\nreal-world graph datasets. Recent studies attempted to learn domain invariant\nrepresentations by eliminating structural shifts between graphs. In this work,\nwe show that existing methodologies have overlooked the significance of the\ngraph node attribute, a pivotal factor for graph domain alignment.\nSpecifically, we first reveal the impact of node attributes for GDA by\ntheoretically proving that in addition to the graph structural divergence\nbetween the domains, the node attribute discrepancy also plays a critical role\nin GDA. Moreover, we also empirically show that the attribute shift is more\nsubstantial than the topology shift, which further underscores the importance\nof node attribute alignment in GDA. Inspired by this finding, a novel\ncross-channel module is developed to fuse and align both views between the\nsource and target graphs for GDA. Experimental results on a variety of\nbenchmarks verify the effectiveness of our method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.06808v3",
    "published_date": "2025-02-04 03:04:04 UTC",
    "updated_date": "2025-02-24 19:57:07 UTC"
  },
  {
    "arxiv_id": "2502.10419v1",
    "title": "A Hybrid Swarm Intelligence Approach for Optimizing Multimodal Large Language Models Deployment in Edge-Cloud-based Federated Learning Environments",
    "authors": [
      "Gaith Rjouba",
      "Hanae Elmekki",
      "Saidul Islam",
      "Jamal Bentahar",
      "Rachida Dssouli"
    ],
    "abstract": "The combination of Federated Learning (FL), Multimodal Large Language Models\n(MLLMs), and edge-cloud computing enables distributed and real-time data\nprocessing while preserving privacy across edge devices and cloud\ninfrastructure. However, the deployment of MLLMs in FL environments with\nresource-constrained edge devices presents significant challenges, including\nresource management, communication overhead, and non-IID data. To address these\nchallenges, we propose a novel hybrid framework wherein MLLMs are deployed on\nedge devices equipped with sufficient resources and battery life, while the\nmajority of training occurs in the cloud. To identify suitable edge devices for\ndeployment, we employ Particle Swarm Optimization (PSO), and Ant Colony\nOptimization (ACO) is utilized to optimize the transmission of model updates\nbetween edge and cloud nodes. This proposed swarm intelligence-based framework\naims to enhance the efficiency of MLLM training by conducting extensive\ntraining in the cloud and fine-tuning at the edge, thereby reducing energy\nconsumption and communication costs. Our experimental results show that the\nproposed method significantly improves system performance, achieving an\naccuracy of 92%, reducing communication cost by 30%, and enhancing client\nparticipation compared to traditional FL methods. These results make the\nproposed approach highly suitable for large-scale edge-cloud computing systems.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10419v1",
    "published_date": "2025-02-04 03:03:24 UTC",
    "updated_date": "2025-02-04 03:03:24 UTC"
  },
  {
    "arxiv_id": "2502.01949v2",
    "title": "LAYOUTDREAMER: Physics-guided Layout for Text-to-3D Compositional Scene Generation",
    "authors": [
      "Yang Zhou",
      "Zongjin He",
      "Qixuan Li",
      "Chao Wang"
    ],
    "abstract": "Recently, the field of text-guided 3D scene generation has garnered\nsignificant attention. High-quality generation that aligns with physical\nrealism and high controllability is crucial for practical 3D scene\napplications. However, existing methods face fundamental limitations: (i)\ndifficulty capturing complex relationships between multiple objects described\nin the text, (ii) inability to generate physically plausible scene layouts, and\n(iii) lack of controllability and extensibility in compositional scenes. In\nthis paper, we introduce LayoutDreamer, a framework that leverages 3D Gaussian\nSplatting (3DGS) to facilitate high-quality, physically consistent\ncompositional scene generation guided by text. Specifically, given a text\nprompt, we convert it into a directed scene graph and adaptively adjust the\ndensity and layout of the initial compositional 3D Gaussians. Subsequently,\ndynamic camera adjustments are made based on the training focal point to ensure\nentity-level generation quality. Finally, by extracting directed dependencies\nfrom the scene graph, we tailor physical and layout energy to ensure both\nrealism and flexibility. Comprehensive experiments demonstrate that\nLayoutDreamer outperforms other compositional scene generation quality and\nsemantic alignment methods. Specifically, it achieves state-of-the-art (SOTA)\nperformance in the multiple objects generation metric of T3Bench.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01949v2",
    "published_date": "2025-02-04 02:51:37 UTC",
    "updated_date": "2025-03-22 12:12:36 UTC"
  },
  {
    "arxiv_id": "2502.01942v1",
    "title": "Boundary-Driven Table-Filling with Cross-Granularity Contrastive Learning for Aspect Sentiment Triplet Extraction",
    "authors": [
      "Qingling Li",
      "Wushao Wen",
      "Jinghui Qin"
    ],
    "abstract": "The Aspect Sentiment Triplet Extraction (ASTE) task aims to extract aspect\nterms, opinion terms, and their corresponding sentiment polarity from a given\nsentence. It remains one of the most prominent subtasks in fine-grained\nsentiment analysis. Most existing approaches frame triplet extraction as a 2D\ntable-filling process in an end-to-end manner, focusing primarily on word-level\ninteractions while often overlooking sentence-level representations. This\nlimitation hampers the model's ability to capture global contextual\ninformation, particularly when dealing with multi-word aspect and opinion terms\nin complex sentences. To address these issues, we propose boundary-driven\ntable-filling with cross-granularity contrastive learning (BTF-CCL) to enhance\nthe semantic consistency between sentence-level representations and word-level\nrepresentations. By constructing positive and negative sample pairs, the model\nis forced to learn the associations at both the sentence level and the word\nlevel. Additionally, a multi-scale, multi-granularity convolutional method is\nproposed to capture rich semantic information better. Our approach can capture\nsentence-level contextual information more effectively while maintaining\nsensitivity to local details. Experimental results show that the proposed\nmethod achieves state-of-the-art performance on public benchmarks according to\nthe F1 score.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.01942v1",
    "published_date": "2025-02-04 02:23:45 UTC",
    "updated_date": "2025-02-04 02:23:45 UTC"
  },
  {
    "arxiv_id": "2502.01941v2",
    "title": "Can LLMs Maintain Fundamental Abilities under KV Cache Compression?",
    "authors": [
      "Xiang Liu",
      "Zhenheng Tang",
      "Hong Chen",
      "Peijie Dong",
      "Zeyu Li",
      "Xiuze Zhou",
      "Bo Li",
      "Xuming Hu",
      "Xiaowen Chu"
    ],
    "abstract": "This paper investigates an underexplored challenge in large language models\n(LLMs): the impact of KV cache compression methods on LLMs' fundamental\ncapabilities. Although existing methods achieve impressive compression ratios\non long-context benchmarks, their effects on core model capabilities remain\nunderstudied. We present a comprehensive benchmark KVFundaBench to\nsystematically evaluate the effects of KV cache compression across diverse\nfundamental LLM capabilities, spanning world knowledge, commonsense reasoning,\narithmetic reasoning, code generation, safety, and long-context understanding\nand generation.Our analysis reveals serval key findings: (1)\n\\textit{Task-Dependent Degradation}; (2) \\textit{Model-Type Robustness} (3)\n\\textit{Prompt Length Vulnerability}; (4) \\textit{Chunk-Level Superiority}; (5)\n\\textit{Prompt-Gain Sensitivity}; (6) \\textit{Long-Context Generation\nSensitivity}. Based on our analysis of attention patterns and cross-task\ncompression performance, we propose ShotKV, a novel compression approach that\ndistinctly handles prefill and decoding phases while maintaining shot-level\nsemantic coherence. Empirical results show that ShotKV achieves $9\\%$-$18\\%$\nperformance improvements on long-context generation tasks under aggressive\ncompression ratios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01941v2",
    "published_date": "2025-02-04 02:23:06 UTC",
    "updated_date": "2025-05-21 10:37:50 UTC"
  },
  {
    "arxiv_id": "2502.01932v3",
    "title": "VolleyBots: A Testbed for Multi-Drone Volleyball Game Combining Motion Control and Strategic Play",
    "authors": [
      "Zelai Xu",
      "Ruize Zhang",
      "Chao Yu",
      "Huining Yuan",
      "Xiangmin Yi",
      "Shilong Ji",
      "Chuqi Wang",
      "Wenhao Tang",
      "Feng Gao",
      "Wenbo Ding",
      "Xinlei Chen",
      "Yu Wang"
    ],
    "abstract": "Robot sports, characterized by well-defined objectives, explicit rules, and\ndynamic interactions, present ideal scenarios for demonstrating embodied\nintelligence. In this paper, we present VolleyBots, a novel robot sports\ntestbed where multiple drones cooperate and compete in the sport of volleyball\nunder physical dynamics. VolleyBots integrates three features within a unified\nplatform: competitive and cooperative gameplay, turn-based interaction\nstructure, and agile 3D maneuvering. Competitive and cooperative gameplay\nchallenges each drone to coordinate with its teammates while anticipating and\ncountering opposing teams' tactics. Turn-based interaction demands precise\ntiming, accurate state prediction, and management of long-horizon temporal\ndependencies. Agile 3D maneuvering requires rapid accelerations, sharp turns,\nand precise 3D positioning despite the quadrotor's underactuated dynamics.\nThese intertwined features yield a complex problem combining motion control and\nstrategic play, with no available expert demonstrations. We provide a\ncomprehensive suite of tasks ranging from single-drone drills to multi-drone\ncooperative and competitive tasks, accompanied by baseline evaluations of\nrepresentative multi-agent reinforcement learning (MARL) and game-theoretic\nalgorithms. Simulation results show that on-policy reinforcement learning (RL)\nmethods outperform off-policy methods in single-agent tasks, but both\napproaches struggle in complex tasks that combine motion control and strategic\nplay. We additionally design a hierarchical policy which achieves a 69.5%\npercent win rate against the strongest baseline in the 3 vs 3 task,\nunderscoring its potential as an effective solution for tackling the complex\ninterplay between low-level control and high-level strategy. The project page\nis at https://sites.google.com/view/thu-volleybots.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01932v3",
    "published_date": "2025-02-04 02:07:23 UTC",
    "updated_date": "2025-05-17 11:20:39 UTC"
  },
  {
    "arxiv_id": "2502.01930v1",
    "title": "Distributionally Robust Direct Preference Optimization",
    "authors": [
      "Zaiyan Xu",
      "Sushil Vemuri",
      "Kishan Panaganti",
      "Dileep Kalathil",
      "Rahul Jain",
      "Deepak Ramachandran"
    ],
    "abstract": "A major challenge in aligning large language models (LLMs) with human\npreferences is the issue of distribution shift. LLM alignment algorithms rely\non static preference datasets, assuming that they accurately represent\nreal-world user preferences. However, user preferences vary significantly\nacross geographical regions, demographics, linguistic patterns, and evolving\ncultural trends. This preference distribution shift leads to catastrophic\nalignment failures in many real-world applications. We address this problem\nusing the principled framework of distributionally robust optimization, and\ndevelop two novel distributionally robust direct preference optimization (DPO)\nalgorithms, namely, Wasserstein DPO (WDPO) and Kullback-Leibler DPO (KLDPO). We\ncharacterize the sample complexity of learning the optimal policy parameters\nfor WDPO and KLDPO. Moreover, we propose scalable gradient descent-style\nlearning algorithms by developing suitable approximations for the challenging\nminimax loss functions of WDPO and KLDPO. Our empirical experiments demonstrate\nthe superior performance of WDPO and KLDPO in substantially improving the\nalignment when there is a preference distribution shift.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01930v1",
    "published_date": "2025-02-04 02:03:19 UTC",
    "updated_date": "2025-02-04 02:03:19 UTC"
  },
  {
    "arxiv_id": "2502.04345v1",
    "title": "JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment",
    "authors": [
      "Yehan Yan",
      "Tianhao Ma",
      "Ruotai Li",
      "Xinhan Zheng",
      "Guodong Shan",
      "Chisheng Li"
    ],
    "abstract": "Traditional Chinese medicine (TCM) plays a vital role in health protection\nand disease treatment, but its practical application requires extensive medical\nknowledge and clinical experience. Existing TCM Large Language Models (LLMs)\nexhibit critical limitations of uncomprehensive medical consultation and\ndiagnoses, and inaccurate syndrome differentiation-based treatment. To address\nthese issues, this study establishes JingFang (JF): a novel TCM Large Language\nModel that demonstrates the expert-level capability of medical diagnosis and\nsyndrome differentiation-based treatment. We innovate a Multi-agent Dynamic\nCollaborative Chain-of-Thought Mechanism (MDCCTM) for medical consultation,\nenabling JF with effective and accurate diagnostic ability. In addition, a\nSyndrome Agent and a Dual-Stage Retrieval Scheme (DSRS) are developed to\nsignificantly enhance the capacity of JF for disease treatment based on\nsyndrome differentiation. JingFang not only facilitates the application of LLMs\nbut also promotes the effective practice of TCM in human health protection and\ndisease treatment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04345v1",
    "published_date": "2025-02-04 01:45:42 UTC",
    "updated_date": "2025-02-04 01:45:42 UTC"
  },
  {
    "arxiv_id": "2502.01922v1",
    "title": "LAST SToP For Modeling Asynchronous Time Series",
    "authors": [
      "Shubham Gupta",
      "Thibaut Durand",
      "Graham Taylor",
      "Lilian W. Białokozowicz"
    ],
    "abstract": "We present a novel prompt design for Large Language Models (LLMs) tailored to\nAsynchronous Time Series. Unlike regular time series, which assume values at\nevenly spaced time points, asynchronous time series consist of timestamped\nevents occurring at irregular intervals, each described in natural language.\nOur approach effectively utilizes the rich natural language of event\ndescriptions, allowing LLMs to benefit from their broad world knowledge for\nreasoning across different domains and tasks. This allows us to extend the\nscope of asynchronous time series analysis beyond forecasting to include tasks\nlike anomaly detection and data imputation. We further introduce Stochastic\nSoft Prompting, a novel prompt-tuning mechanism that significantly improves\nmodel performance, outperforming existing fine-tuning methods such as QLoRA.\nThrough extensive experiments on real world datasets, we demonstrate that our\napproach achieves state-of-the-art performance across different tasks and\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01922v1",
    "published_date": "2025-02-04 01:42:45 UTC",
    "updated_date": "2025-02-04 01:42:45 UTC"
  },
  {
    "arxiv_id": "2502.01918v1",
    "title": "Wake-Informed 3D Path Planning for Autonomous Underwater Vehicles Using A* and Neural Network Approximations",
    "authors": [
      "Zachary Cooper-Baldock",
      "Stephen Turnock",
      "Karl Sammut"
    ],
    "abstract": "Autonomous Underwater Vehicles (AUVs) encounter significant energy, control\nand navigation challenges in complex underwater environments, particularly\nduring close-proximity operations, such as launch and recovery (LAR), where\nfluid interactions and wake effects present additional navigational and energy\nchallenges. Traditional path planning methods fail to incorporate these\ndetailed wake structures, resulting in increased energy consumption, reduced\ncontrol stability, and heightened safety risks. This paper presents a novel\nwake-informed, 3D path planning approach that fully integrates localized wake\neffects and global currents into the planning algorithm. Two variants of the A*\nalgorithm - a current-informed planner and a wake-informed planner - are\ncreated to assess its validity and two neural network models are then trained\nto approximate these planners for real-time applications. Both the A* planners\nand NN models are evaluated using important metrics such as energy expenditure,\npath length, and encounters with high-velocity and turbulent regions. The\nresults demonstrate a wake-informed A* planner consistently achieves the lowest\nenergy expenditure and minimizes encounters with high-velocity regions,\nreducing energy consumption by up to 11.3%. The neural network models are\nobserved to offer computational speedup of 6 orders of magnitude, but exhibit\n4.51 - 19.79% higher energy expenditures and 9.81 - 24.38% less optimal paths.\nThese findings underscore the importance of incorporating detailed wake\nstructures into traditional path planning algorithms and the benefits of neural\nnetwork approximations to enhance energy efficiency and operational safety for\nAUVs in complex 3D domains.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "68T40, 68T07, 90C35",
      "I.2.8; I.2.9; I.5.1"
    ],
    "primary_category": "cs.RO",
    "comment": "11 pages, 6 figures, preprint of journal paper",
    "pdf_url": "http://arxiv.org/pdf/2502.01918v1",
    "published_date": "2025-02-04 01:23:23 UTC",
    "updated_date": "2025-02-04 01:23:23 UTC"
  },
  {
    "arxiv_id": "2502.01912v2",
    "title": "PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings",
    "authors": [
      "Andrew Van Horn",
      "Lauryn Smith",
      "Mahamad Mahmoud",
      "Michael McMaster",
      "Clara Pinchbeck",
      "Ina Martin",
      "Andrew Lininger",
      "Anthony Ingrisano",
      "Adam Lowe",
      "Carlos Bayod",
      "Elizabeth Bolman",
      "Kenneth Singer",
      "Michael Hinczewski"
    ],
    "abstract": "The history of art has seen significant shifts in the manner in which\nartworks are created, making understanding of creative processes a central\nquestion in technical art history. In the Renaissance and Early Modern period,\npaintings were largely produced by master painters directing workshops of\napprentices who often contributed to projects. The masters varied significantly\nin artistic and managerial styles, meaning different combinations of artists\nand implements might be seen both between masters and within workshops or even\nindividual canvases. Information on how different workshops were managed and\nthe processes by which artworks were created remains elusive. Machine learning\nmethods have potential to unearth new information about artists' creative\nprocesses by extending the analysis of brushwork to a microscopic scale.\nAnalysis of workshop paintings, however, presents a challenge in that\ndocumentation of the artists and materials involved is sparse, meaning external\nexamples are not available to train networks to recognize their contributions.\nHere we present a novel machine learning approach we call pairwise assignment\ntraining for classifying heterogeneity (PATCH) that is capable of identifying\nindividual artistic practice regimes with no external training data, or \"ground\ntruth.\" The method achieves unsupervised results by supervised means, and\noutperforms both simple statistical procedures and unsupervised machine\nlearning methods. We apply this method to two historical paintings by the\nSpanish Renaissance master, El Greco: The Baptism of Christ and Christ on the\nCross with Landscape, and our findings regarding the former potentially\nchallenge previous work that has assigned the painting to workshop members.\nFurther, the results of our analyses create a measure of heterogeneity of\nartistic practice that can be used to characterize artworks across time and\nspace.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "main text: 16 pages, 6 figures; SI: 7 pages, 3 figures; v2: minor\n  typo corrections, higher resolution figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01912v2",
    "published_date": "2025-02-04 01:05:12 UTC",
    "updated_date": "2025-03-03 05:25:43 UTC"
  }
]