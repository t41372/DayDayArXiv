{
  "date": "2025-02-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-04 的 arXiv 中文 TLDR 快报！今天的 arXiv 论文聚焦于 AI 模型优化、生成技术和医疗应用等领域，亮点包括 LLM 在复杂任务中的高效推理和安全对齐，以及生成模型在医疗图像和视频合成中的创新应用，值得一提的是像 OpenAI 和其他知名团队的相关研究。\n\n### 重点论文讨论\n我们挑选了今天最具影响力和话题度的论文，先从 AI 模型和生成技术入手，再聊医疗和强化学习领域的亮点。其他论文如数学优化或小众领域，我们快速掠过，只提核心贡献。\n\n1. **Diffusion Instruction Tuning | Diffusion Instruction Tuning**  \n   这篇论文提出 Lavender，一种结合 Stable Diffusion 的监督微调方法，提升视觉语言模型（VLMs）的性能。核心贡献是通过文本-视觉注意力对齐，仅需 0.13 百万样本即可显著改善任务表现，尤其在医疗问答中提升 68%，并在标准硬件上训练一天。该方法展示了高效知识转移的潜力，适用于资源有限的场景。\n\n2. **Policy Guided Tree Search for Enhanced LLM Reasoning | Policy Guided Tree Search for Enhanced LLM Reasoning**  \n   论文引入 Policy-Guided Tree Search（PGTS）框架，将强化学习与树搜索结合，优化 LLM 的推理过程。主要发现是动态决策策略减少了手动启发式依赖，提升了数学推理和规划任务的性能，同时降低了计算成本。该工作由杨 Li 领导，强调了 LLM 在复杂推理中的可扩展性。\n\n3. **3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography | 3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography**  \n   作者团队包括 Narges Razavian 等知名学者，提出 FM-CT 模型，使用自监督学习训练于 36 万 CT 扫描数据。关键贡献是提升了脑部疾病检测的泛化能力，相比从零训练的模型在下游任务中表现更优，为医疗 AI 诊断设定了新基准。\n\n4. **Controllable Video Generation with Provable Disentanglement | Controllable Video Generation with Provable Disentanglement**  \n   论文开发 CoVoGAN 框架，实现视频生成中的可控性，通过最小变化原则和充分变化属性证明了动态变量的可识别性。主要发现是允许独立控制运动和身份，提供理论保证和实验验证，适用于复杂视频编辑。\n\n5. **Gradient Correction in Federated Learning with Adaptive Optimization | Gradient Correction in Federated Learning with Adaptive Optimization**  \n   提出 FAdamGC 算法，针对联邦学习中的数据异质性问题优化梯度修正。核心贡献是改进了自适应优化器的收敛率，并在非凸场景下证明了性能提升，实验显示在数据异质性下显著减少通信成本。\n\n6. **Vision-Language Model Dialog Games for Self-Improvement | Vision-Language Model Dialog Games for Self-Improvement**  \n   由 Ksenia Konyushkova 等作者开发 VLM Dialog Games 框架，通过自玩机制自动生成高质量数据集。关键发现是迭代训练提升了视觉语言模型的性能，尤其在多模态任务中，展示了自监督学习的潜力。\n\n7. **Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography | Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography**  \n   论文提出 Layer Separation Networks (LSN)，用于医学图像合成，允许调整关节空间宽度。主要贡献是生成高质量合成图像，改善数据不平衡问题，提升下游诊断任务的准确性。\n\n8. **Exploring Spatial Language Grounding Through Referring Expressions | Exploring Spatial Language Grounding Through Referring Expressions**  \n   研究视觉语言模型在空间推理中的挑战，使用 Referring Expression Comprehension 任务。核心发现是模型在处理歧义和否定时存在弱点，但为未来空间语义研究提供了洞见。\n\n9. **Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images | Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images**  \n   引入 L1-weighted Dice Focal Loss，提升前列腺癌病变检测。该方法在 PET/CT 图像上表现出色，特别是在肿瘤体积和扩散方面的鲁棒性。\n\n### 其他论文快速掠过\n今天还有许多论文，如\"Peri-LN: Revisiting Layer Normalization in the Transformer Architecture\"（优化 Transformer 层归一化，提升大模型训练稳定性）和\"Astromer 2\"（改进光曲线嵌入用于天文分类），这些在特定领域有贡献，但不那么话题度高。我们只提核心：前者证明了层归一化位置对大模型的影响，后者提升了天文数据分类的泛化能力。总体而言，今天的论文强调了 AI 在实际应用中的优化和泛化潜力，期待后续研究。",
  "papers": [
    {
      "arxiv_id": "2502.02780v1",
      "title": "Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Songlin Xu",
        "Hao-Ning Wen",
        "Hongyi Pan",
        "Dallas Dominguez",
        "Dongyin Hu",
        "Xinyu Zhang"
      ],
      "abstract": "Student simulation supports educators to improve teaching by interacting with\nvirtual students. However, most existing approaches ignore the modulation\neffects of course materials because of two challenges: the lack of datasets\nwith granularly annotated course materials, and the limitation of existing\nsimulation models in processing extremely long textual data. To solve the\nchallenges, we first run a 6-week education workshop from N = 60 students to\ncollect fine-grained data using a custom built online education system, which\nlogs students' learning behaviors as they interact with lecture materials over\ntime. Second, we propose a transferable iterative reflection (TIR) module that\naugments both prompting-based and finetuning-based large language models (LLMs)\nfor simulating learning behaviors. Our comprehensive experiments show that TIR\nenables the LLMs to perform more accurate student simulation than classical\ndeep learning models, even with limited demonstration data. Our TIR approach\nbetter captures the granular dynamism of learning performance and inter-student\ncorrelations in classrooms, paving the way towards a ''digital twin'' for\nonline education.",
      "tldr_zh": "本研究针对学生模拟中忽略课程材料调节效果的问题，提出构建上下文学生生成代理的方法，以提升在线教育的学习行为模拟。研究者首先通过一个为期6周的工作坊，收集了60名学生的细粒度学习行为数据，包括与课程材料的互动日志；其次，开发了可转移的迭代反射(TIR)模块，用于增强大型语言模型(LLMs)的提示和微调能力，实现更准确的行为模拟。实验结果显示，TIR 模块使 LLMs 优于传统深度学习模型，即使数据有限，也能更好地捕捉学习表现的动态变化和学生间相关性。该方法为在线教育的“数字孪生”铺平了道路，促进教育改进。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.02780v1",
      "published_date": "2025-02-04 23:42:52 UTC",
      "updated_date": "2025-02-04 23:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:38:48.325092"
    },
    {
      "arxiv_id": "2502.02779v1",
      "title": "3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography",
      "title_zh": "用于头部计算机断层扫描中可泛化疾病检测的 3D 基础 AI 模型",
      "authors": [
        "Weicheng Zhu",
        "Haoxu Huang",
        "Huanze Tang",
        "Rushabh Musthyala",
        "Boyang Yu",
        "Long Chen",
        "Emilio Vega",
        "Thomas O'Donnell",
        "Seena Dehkharghani",
        "Jennifer A. Frontera",
        "Arjun V. Masurkar",
        "Kara Melmed",
        "Narges Razavian"
      ],
      "abstract": "Head computed tomography (CT) imaging is a widely-used imaging modality with\nmultitudes of medical indications, particularly in assessing pathology of the\nbrain, skull, and cerebrovascular system. It is commonly the first-line imaging\nin neurologic emergencies given its rapidity of image acquisition, safety,\ncost, and ubiquity. Deep learning models may facilitate detection of a wide\nrange of diseases. However, the scarcity of high-quality labels and\nannotations, particularly among less common conditions, significantly hinders\nthe development of powerful models. To address this challenge, we introduce\nFM-CT: a Foundation Model for Head CT for generalizable disease detection,\ntrained using self-supervised learning. Our approach pre-trains a deep learning\nmodel on a large, diverse dataset of 361,663 non-contrast 3D head CT scans\nwithout the need for manual annotations, enabling the model to learn robust,\ngeneralizable features. To investigate the potential of self-supervised\nlearning in head CT, we employed both discrimination with self-distillation and\nmasked image modeling, and we construct our model in 3D rather than at the\nslice level (2D) to exploit the structure of head CT scans more comprehensively\nand efficiently. The model's downstream classification performance is evaluated\nusing internal and three external datasets, encompassing both in-distribution\n(ID) and out-of-distribution (OOD) data. Our results demonstrate that the\nself-supervised foundation model significantly improves performance on\ndownstream diagnostic tasks compared to models trained from scratch and\nprevious 3D CT foundation models on scarce annotated datasets. This work\nhighlights the effectiveness of self-supervised learning in medical imaging and\nsets a new benchmark for head CT image analysis in 3D, enabling broader use of\nartificial intelligence for head CT-based diagnosis.",
      "tldr_zh": "本研究提出了一种名为 FM-CT 的 3D Foundation Model，用于头部计算断层扫描 (CT) 的可泛化疾病检测，以解决标注数据稀少的问题。该模型采用自监督学习（self-supervised learning）方法，包括 discrimination with self-distillation 和 masked image modeling，在 361,663 个非对比 3D 头部 CT 扫描数据集上进行预训练，从而无需手动标注即可学习鲁棒特征。实验结果显示，FM-CT 在内部和外部数据集（涵盖 in-distribution 和 out-of-distribution 数据）上的下游分类任务表现优于从零开始训练的模型和现有 3D CT 基础模型，提升了诊断准确性。该工作证明了自监督学习在医疗成像中的有效性，并为 3D 头部 CT 图像分析设定了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.02779v1",
      "published_date": "2025-02-04 23:42:18 UTC",
      "updated_date": "2025-02-04 23:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:38:59.074942"
    },
    {
      "arxiv_id": "2502.02772v2",
      "title": "Cross-modality Force and Language Embeddings for Natural Human-Robot Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Ravi Tejwani",
        "Karl Velazquez",
        "John Payne",
        "Paolo Bonato",
        "Harry Asada"
      ],
      "abstract": "A method for cross-modality embedding of force profile and words is presented\nfor synergistic coordination of verbal and haptic communication. When two\npeople carry a large, heavy object together, they coordinate through verbal\ncommunication about the intended movements and physical forces applied to the\nobject. This natural integration of verbal and physical cues enables effective\ncoordination. Similarly, human-robot interaction could achieve this level of\ncoordination by integrating verbal and haptic communication modalities. This\npaper presents a framework for embedding words and force profiles in a unified\nmanner, so that the two communication modalities can be integrated and\ncoordinated in a way that is effective and synergistic. Here, it will be shown\nthat, although language and physical force profiles are deemed completely\ndifferent, the two can be embedded in a unified latent space and proximity\nbetween the two can be quantified. In this latent space, a force profile and\nwords can a) supplement each other, b) integrate the individual effects, and c)\nsubstitute in an exchangeable manner. First, the need for cross-modality\nembedding is addressed, and the basic architecture and key building block\ntechnologies are presented. Methods for data collection and implementation\nchallenges will be addressed, followed by experimental results and discussions.",
      "tldr_zh": "该论文提出了一种跨模态嵌入（cross-modality embedding）框架，将力学特征（force profile）和语言嵌入统一潜在空间（latent space），以实现人类与机器人在言语和触觉（haptic）通信方面的协同协调，类似于人类间搬运重物时的自然互动。主要方法包括构建基本架构、关键技术（如数据收集和量化接近度），并展示语言和力学特征能够互补、整合或互换。实验结果证明了该框架的有效性，为自然的人机交互提供了基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review in RSS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02772v2",
      "published_date": "2025-02-04 23:32:45 UTC",
      "updated_date": "2025-04-25 21:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:39:09.758852"
    },
    {
      "arxiv_id": "2502.02768v1",
      "title": "Planning with affordances: Integrating learned affordance models and symbolic planning",
      "title_zh": "基于可供性的规划：整合学习到的可供性模型和符号规划",
      "authors": [
        "Rajesh Mangannavar"
      ],
      "abstract": "Intelligent agents working in real-world environments must be able to learn\nabout the environment and its capabilities which enable them to take actions to\nchange to the state of the world to complete a complex multi-step task in a\nphotorealistic environment. Learning about the environment is especially\nimportant to perform various multiple-step tasks without having to redefine an\nagent's action set for different tasks or environment settings. In our work, we\naugment an existing task and motion planning framework with learned affordance\nmodels of objects in the world to enable planning and executing multi-step\ntasks using learned models. Each task can be seen as changing the current state\nof the world to a given goal state. The affordance models provide us with what\nactions are possible and how to perform those actions in any given state. A\nsymbolic planning algorithm uses this information and the starting and goal\nstate to create a feasible plan to reach the desired goal state to complete a\ngiven task. We demonstrate our approach in a virtual 3D photorealistic\nenvironment, AI2-Thor, and evaluate it on real-world tasks. Our results show\nthat our agent quickly learns how to interact with the environment and is well\nprepared to perform tasks such as \"Moving an object out of the way to reach the\ndesired location.\"",
      "tldr_zh": "该研究提出了一种将学习得到的 affordance models 与 symbolic planning 框架相结合的方法，允许智能代理在真实环境中学习对象交互能力，从而执行复杂多步任务，而无需为不同任务重新定义动作集。affordance models 提供给定状态下可能的动作和执行方式，符号规划算法则利用这些信息生成从起始状态到目标状态的可行计划。实验在 AI2-Thor 虚拟环境中进行，结果显示代理能快速学习并成功完成现实任务，如“移动物体以到达目标位置”。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02768v1",
      "published_date": "2025-02-04 23:15:38 UTC",
      "updated_date": "2025-02-04 23:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:39:22.919507"
    },
    {
      "arxiv_id": "2502.04359v1",
      "title": "Exploring Spatial Language Grounding Through Referring Expressions",
      "title_zh": "通过指称表达式探索空间语言接地",
      "authors": [
        "Akshar Tumu",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Spatial Reasoning is an important component of human cognition and is an area\nin which the latest Vision-language models (VLMs) show signs of difficulty. The\ncurrent analysis works use image captioning tasks and visual question\nanswering. In this work, we propose using the Referring Expression\nComprehension task instead as a platform for the evaluation of spatial\nreasoning by VLMs. This platform provides the opportunity for a deeper analysis\nof spatial comprehension and grounding abilities when there is 1) ambiguity in\nobject detection, 2) complex spatial expressions with a longer sentence\nstructure and multiple spatial relations, and 3) expressions with negation\n('not'). In our analysis, we use task-specific architectures as well as large\nVLMs and highlight their strengths and weaknesses in dealing with these\nspecific situations. While all these models face challenges with the task at\nhand, the relative behaviors depend on the underlying models and the specific\ncategories of spatial semantics (topological, directional, proximal, etc.). Our\nresults highlight these challenges and behaviors and provide insight into\nresearch gaps and future directions.",
      "tldr_zh": "本研究探讨了视觉语言模型（VLMs）在空间推理方面的挑战，并提出使用 Referring Expression Comprehension 任务作为评估平台，以更深入分析模型的空间理解和 grounding 能力。该任务特别关注物体检测的模糊性、复杂空间表达（包括较长句子结构和多重空间关系）以及带有否定的表达（如“not”）。通过测试任务特定架构和大型 VLMs，该研究突出了模型在不同空间语义类别（如拓扑的、方向的和近端的）中的优势与弱点，结果显示所有模型均面临困难，并为未来研究提供关键洞见和方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04359v1",
      "published_date": "2025-02-04 22:58:15 UTC",
      "updated_date": "2025-02-04 22:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:39:35.021021"
    },
    {
      "arxiv_id": "2502.02756v1",
      "title": "Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images",
      "title_zh": "翻译失败",
      "authors": [
        "Obed Korshie Dzikunu",
        "Shadab Ahamed",
        "Amirhossein Toosi",
        "Xiaoxiao Li",
        "Arman Rahmim"
      ],
      "abstract": "This study proposes a new loss function for deep neural networks, L1-weighted\nDice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of\nvoxels based on their classification difficulty, towards automated detection\nand segmentation of metastatic prostate cancer lesions in PET/CT scans. We\nobtained 380 PSMA [18-F] DCFPyL PET/CT scans of patients diagnosed with\nbiochemical recurrence metastatic prostate cancer. We trained two 3D\nconvolutional neural networks, Attention U-Net and SegResNet, and concatenated\nthe PET and CT volumes channel-wise as input. The performance of our custom\nloss function was evaluated against the Dice and Dice Focal Loss functions. For\nclinical significance, we considered a detected region of interest (ROI) as a\ntrue positive if at least the voxel with the maximum standardized uptake value\nfalls within the ROI. We assessed the models' performance based on the number\nof lesions in an image, tumour volume, activity, and extent of spread. The\nL1DFL outperformed the comparative loss functions by at least 13% on the test\nset. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were\nlower than that of L1DFL by at least 6% and 34%, respectively. The Dice Focal\nLoss yielded more false positives, whereas the Dice Loss was more sensitive to\nsmaller volumes and struggled to segment larger lesions accurately. They also\nexhibited network-specific variations and yielded declines in segmentation\naccuracy with increased tumour spread. Our results demonstrate the potential of\nL1DFL to yield robust segmentation of metastatic prostate cancer lesions in\nPSMA PET/CT images. The results further highlight potential complexities\narising from the variations in lesion characteristics that may influence\nautomated prostate cancer tumour detection and segmentation. The code is\npublicly available at: https://github.com/ObedDzik/pca_segment.git.",
      "tldr_zh": "本文提出了一种新的损失函数 L1-weighted Dice Focal Loss (L1DFL)，它利用 L1 范数对体素进行自适应加权，以提高深度神经网络在 PET/CT 图像中检测和分割转移性前列腺癌病变的表现。研究使用 380 个 PSMA [18-F] DCFPyL PET/CT 扫描训练 Attention U-Net 和 SegResNet 模型，并与 Dice Loss 和 Dice Focal Loss 进行比较，评估指标包括病变数量、肿瘤体积、活性和扩散程度。结果显示，L1DFL 在测试集上至少提升 13% 的性能，且 F1 分数比 Dice Loss 高至少 6%、比 Dice Focal Loss 高至少 34%，同时减少了假阳性和对小体积病变的敏感性问题。该方法证明了 L1DFL 在鲁棒分割前列腺癌病变方面的潜力，并突出了病变特征变化对自动检测的影响，代码已公开在 GitHub 上。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "29 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2502.02756v1",
      "published_date": "2025-02-04 22:45:16 UTC",
      "updated_date": "2025-02-04 22:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:39:48.273484"
    },
    {
      "arxiv_id": "2502.02747v1",
      "title": "PatchPilot: A Stable and Cost-Efficient Agentic Patching Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Hongwei Li",
        "Yuheng Tang",
        "Shiqi Wang",
        "Wenbo Guo"
      ],
      "abstract": "Recent research builds various patching agents that combine large language\nmodels (LLMs) with non-ML tools and achieve promising results on the\nstate-of-the-art (SOTA) software patching benchmark, SWE-Bench. Based on how to\ndetermine the patching workflows, existing patching agents can be categorized\nas agent-based planning methods, which rely on LLMs for planning, and\nhuman-based planning methods, which follow a pre-defined workflow. At a high\nlevel, agent-based planning methods achieve high patching performance but with\na high cost and limited stability. Human-based planning methods, on the other\nhand, are more stable and efficient but have key workflow limitations that\ncompromise their patching performance. In this paper, we propose PatchPilot, an\nagentic patcher that strikes a balance between patching efficacy, stability,\nand cost-efficiency. PatchPilot proposes a novel human-based planning workflow\nwith five components: reproduction, localization, generation, validation, and\nrefinement (where refinement is unique to PatchPilot). We introduce novel and\ncustomized designs to each component to optimize their effectiveness and\nefficiency. Through extensive experiments on the SWE-Bench benchmarks,\nPatchPilot shows a superior performance than existing open-source methods while\nmaintaining low cost (less than 1$ per instance) and ensuring higher stability.\nWe also conduct a detailed ablation study to validate the key designs in each\ncomponent.",
      "tldr_zh": "该论文提出PatchPilot，一种稳定且成本高效的代理式补丁框架，旨在平衡软件补丁的效能、稳定性和成本问题。PatchPilot采用新型基于人类的规划工作流，包括五个组件：reproduction（重现）、localization（定位）、generation（生成）、validation（验证）和独有的refinement（精炼），并针对每个组件进行定制设计以优化效果和效率。在SWE-Bench基准测试中，PatchPilot比现有开源方法表现出色，同时保持低成本（每实例不到1美元）和高稳定性，并通过详细的消融研究验证了关键设计。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02747v1",
      "published_date": "2025-02-04 22:30:02 UTC",
      "updated_date": "2025-02-04 22:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:39:58.585864"
    },
    {
      "arxiv_id": "2502.06814v1",
      "title": "Diffusion Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Jin",
        "Ryutaro Tanno",
        "Amrutha Saseendran",
        "Tom Diethe",
        "Philip Teare"
      ],
      "abstract": "We introduce Lavender, a simple supervised fine-tuning (SFT) method that\nboosts the performance of advanced vision-language models (VLMs) by leveraging\nstate-of-the-art image generation models such as Stable Diffusion.\nSpecifically, Lavender aligns the text-vision attention in the VLM transformer\nwith the equivalent used by Stable Diffusion during SFT, instead of adapting\nseparate encoders. This alignment enriches the model's visual understanding and\nsignificantly boosts performance across in- and out-of-distribution tasks.\nLavender requires just 0.13 million training examples, 2.5% of typical\nlarge-scale SFT datasets, and fine-tunes on standard hardware (8 GPUs) in a\nsingle day. It consistently improves state-of-the-art open-source multimodal\nLLMs (e.g., Llama-3.2-11B, MiniCPM-Llama3-v2.5), achieving up to 30% gains and\na 68% boost on challenging out-of-distribution medical QA tasks. By efficiently\ntransferring the visual expertise of image generators with minimal supervision,\nLavender offers a scalable solution for more accurate vision-language systems.\nAll code, training data, and models will be shared at\nhttps://astrazeneca.github.io/vlm/.",
      "tldr_zh": "本研究提出Lavender，一种简单的监督微调（Supervised Fine-Tuning, SFT）方法，通过利用Stable Diffusion等先进图像生成模型，提升视觉语言模型（VLMs）的性能。具体而言，Lavender在SFT过程中对齐VLM中的文本-视觉注意力与Stable Diffusion的对应机制，从而丰富模型的视觉理解，并在分布内和分布外任务上显著提升表现。该方法仅需0.13百万训练示例，并在标准硬件（8 GPUs）上即可在一日内完成微调，实现了对开源多模态LLM（如Llama-3.2-11B和MiniCPM-Llama3-v2.5）的优化，在某些任务上获得高达30%的提升，并在挑战性的分布外医疗QA任务上提升68%。总之，Lavender通过高效转移图像生成器的视觉专业知识，提供了一个可扩展的解决方案，以最小监督构建更准确的视觉语言系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.LG",
      "comment": "Project page at https://astrazeneca.github.io/vlm/",
      "pdf_url": "http://arxiv.org/pdf/2502.06814v1",
      "published_date": "2025-02-04 22:20:20 UTC",
      "updated_date": "2025-02-04 22:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:40:11.392007"
    },
    {
      "arxiv_id": "2502.06813v1",
      "title": "Policy Guided Tree Search for Enhanced LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li"
      ],
      "abstract": "Despite their remarkable capabilities, large language models often struggle\nwith tasks requiring complex reasoning and planning. While existing approaches\nlike Chain-of-Thought prompting and tree search techniques show promise, they\nare limited by their reliance on predefined heuristics and computationally\nexpensive exploration strategies. We propose Policy-Guided Tree Search (PGTS),\na framework that combines reinforcement learning with structured tree\nexploration to efficiently navigate reasoning paths. Our key innovation is a\nlearned policy that dynamically decides between expanding, branching,\nbacktracking, or terminating exploration, eliminating the need for manual\nheuristics or exhaustive search. Experiments across mathematical reasoning,\nlogical deduction, and planning benchmarks demonstrate that PGTS achieves\nsuperior reasoning performance while significantly reducing computational costs\ncompared to existing methods. These results establish PGTS as a scalable and\neffective solution for tackling complex reasoning tasks with LLMs.",
      "tldr_zh": "尽管大型语言模型（LLMs）在复杂推理和规划任务上存在挑战，现有的Chain-of-Thought提示和树搜索方法依赖预定义启发式和计算密集探索，该论文提出Policy-Guided Tree Search (PGTS)框架，将强化学习与结构化树探索相结合。PGTS的关键创新是使用学习策略动态决定探索步骤，包括扩展、分支、回溯或终止，从而避免手动启发式和穷举搜索。在数学推理、逻辑演绎和规划基准上的实验显示，PGTS实现了比现有方法更优的推理性能，同时显著降低了计算成本，为处理LLMs的复杂任务提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06813v1",
      "published_date": "2025-02-04 22:08:20 UTC",
      "updated_date": "2025-02-04 22:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:40:22.844115"
    },
    {
      "arxiv_id": "2502.02740v1",
      "title": "Vision-Language Model Dialog Games for Self-Improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Ksenia Konyushkova",
        "Christos Kaplanis",
        "Serkan Cabi",
        "Misha Denil"
      ],
      "abstract": "The increasing demand for high-quality, diverse training data poses a\nsignificant bottleneck in advancing vision-language models (VLMs). This paper\npresents VLM Dialog Games, a novel and scalable self-improvement framework for\nVLMs. Our approach leverages self-play between two agents engaged in a\ngoal-oriented play centered around image identification. By filtering for\nsuccessful game interactions, we automatically curate a high-quality dataset of\ninterleaved images and text. We demonstrate that fine-tuning on this synthetic\ndata leads to performance gains on downstream tasks and generalises across\ndatasets. Moreover, as the improvements in the model lead to better game play,\nthis procedure can be applied iteratively. This work paves the way for\nself-improving VLMs, with potential applications in various real-world\nscenarios especially when the high-quality multimodal data is scarce.",
      "tldr_zh": "本研究提出了一种名为 VLM Dialog Games 的新型自提升框架，用于解决视觉语言模型 (VLMs) 在高质量多样化训练数据短缺问题上遇到的瓶颈。该框架通过两个代理进行以图像识别为中心的自玩 (self-play) 游戏，并筛选成功的互动来自动生成高质量的图像和文本交织数据集。实验结果显示，在此合成数据上进行 fine-tuning 可以提升模型在下游任务的性能，并实现跨数据集的泛化；此外，该过程可迭代应用，随着模型改进进一步优化游戏表现。该方法为自提升 VLMs 铺平道路，尤其适用于高质量多模态数据稀缺的真实场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02740v1",
      "published_date": "2025-02-04 21:58:07 UTC",
      "updated_date": "2025-02-04 21:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:40:34.205668"
    },
    {
      "arxiv_id": "2502.02732v2",
      "title": "Peri-LN: Revisiting Layer Normalization in the Transformer Architecture",
      "title_zh": "Peri-LN：重新审视 Transformer 架构中的层归一化",
      "authors": [
        "Jeonghoon Kim",
        "Byeongchan Lee",
        "Cheonbok Park",
        "Yeontaek Oh",
        "Beomjun Kim",
        "Taehwan Yoo",
        "Seongjin Shin",
        "Dongyoon Han",
        "Jinwoo Shin",
        "Kang Min Yoo"
      ],
      "abstract": "Designing Transformer architectures with the optimal layer normalization (LN)\nstrategy that ensures large-scale training stability and expedite convergence\nhas remained elusive, even in this era of large language models (LLMs). To this\nend, we present a comprehensive analytical foundation for understanding how\ndifferent LN strategies influence training dynamics in large-scale Transformer\ntraining. Until recently, Pre-LN and Post-LN have long dominated standard\npractices despite their limitations in large-scale training. However, several\nopen-source large-scale models have recently begun silently adopting a third\nstrategy without much explanation. This strategy places layer normalization\n(LN) peripherally around sublayers, a design we term Peri-LN. While Peri-LN has\ndemonstrated promising empirical performance, its precise mechanisms and\nbenefits remain almost unexplored. Our in-depth analysis shows that Peri-LN\nstrikes an ideal balance in variance growth -- unlike Pre-LN and Post-LN, which\nare prone to vanishing gradients and ``massive activations.'' To validate our\ntheoretical insight, we conduct large-scale experiments on Transformers up to\n3.2B parameters, showing that Peri-LN consistently achieves more balanced\nvariance growth, steadier gradient flow, and convergence stability. Our results\nsuggest that Peri-LN warrants broader consideration for large-scale Transformer\narchitectures, providing renewed insights into the optimal placement and\napplication of LN.",
      "tldr_zh": "本研究重新审视了Layer Normalization (LN) 在Transformer架构中的放置策略，旨在优化大规模训练的稳定性和收敛速度。通过理论分析，比较了Pre-LN、Post-LN 和新提出的Peri-LN策略，发现Peri-LN在方差增长上实现了理想平衡，避免了其他策略的梯度消失和激活爆炸问题。在高达3.2B参数的Transformer实验中，Peri-LN展示了更稳定的梯度流动和收敛性能，建议在大型模型中更广泛采用这一策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.02732v2",
      "published_date": "2025-02-04 21:29:47 UTC",
      "updated_date": "2025-02-06 20:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:40:46.955908"
    },
    {
      "arxiv_id": "2502.02727v3",
      "title": "Gradient Correction in Federated Learning with Adaptive Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Evan Chen",
        "Shiqiang Wang",
        "Jianing Zhang",
        "Dong-Jun Han",
        "Chaoyue Liu",
        "Christopher Brinton"
      ],
      "abstract": "In federated learning (FL), model training performance is strongly impacted\nby data heterogeneity across clients. Client-drift compensation methods have\nrecently emerged as a solution to this issue, introducing correction terms into\nlocal model updates. To date, these methods have only been considered under\nstochastic gradient descent (SGD)-based model training, while modern FL\nframeworks also employ adaptive optimizers (e.g., Adam) for improved\nconvergence. However, due to the complex interplay between first and second\nmoments found in most adaptive optimization methods, naively injecting\ncorrection terms can lead to performance degradation in heterogeneous settings.\nIn this work, we propose {\\tt FAdamGC}, the first algorithm to integrate drift\ncompensation into adaptive federated optimization. The key idea of {\\tt\nFAdamGC} is injecting a pre-estimation correction term that aligns with the\nmoment structure of adaptive methods. We provide a rigorous convergence\nanalysis of our algorithm under non-convex settings, showing that {\\tt FAdamGC}\nresults in better rate and milder assumptions than naively porting SGD-based\ncorrection algorithms into adaptive optimizers. Our experimental results\ndemonstrate that {\\tt FAdamGC} consistently outperform existing methods in\ntotal communication and computation cost across varying levels of data\nheterogeneity, showing the efficacy of correcting gradient information in\nfederated adaptive optimization.",
      "tldr_zh": "这篇论文针对联邦学习（Federated Learning, FL）中数据异质性导致的模型训练性能问题，提出 FAdamGC 算法，这是首个将客户端漂移补偿整合到自适应优化器（如 Adam）中的方法。FAdamGC 的关键创新是通过注入一个与自适应方法的动量结构一致的预估修正项，避免了直接应用修正项可能导致的性能下降。论文提供了在非凸设置下的严格收敛分析，证明 FAdamGC 具有更好的收敛率和更温和的假设。实验结果显示，该算法在不同数据异质性水平下，在总通信和计算成本方面均优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02727v3",
      "published_date": "2025-02-04 21:21:30 UTC",
      "updated_date": "2025-05-18 02:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:40:59.516936"
    },
    {
      "arxiv_id": "2502.02717v1",
      "title": "Astromer 2",
      "title_zh": "翻译失败",
      "authors": [
        "Cristobal Donoso-Oliva",
        "Ignacio Becker",
        "Pavlos Protopapas",
        "Guillermo Cabrera-Vives",
        "Martina Cádiz-Leyton",
        "Daniel Moreno-Cartagena"
      ],
      "abstract": "Foundational models have emerged as a powerful paradigm in deep learning\nfield, leveraging their capacity to learn robust representations from\nlarge-scale datasets and effectively to diverse downstream applications such as\nclassification. In this paper, we present Astromer 2 a foundational model\nspecifically designed for extracting light curve embeddings. We introduce\nAstromer 2 as an enhanced iteration of our self-supervised model for light\ncurve analysis. This paper highlights the advantages of its pre-trained\nembeddings, compares its performance with that of its predecessor, Astromer 1,\nand provides a detailed empirical analysis of its capabilities, offering deeper\ninsights into the model's representations. Astromer 2 is pretrained on 1.5\nmillion single-band light curves from the MACHO survey using a self-supervised\nlearning task that predicts randomly masked observations within sequences.\nFine-tuning on a smaller labeled dataset allows us to assess its performance in\nclassification tasks. The quality of the embeddings is measured by the F1 score\nof an MLP classifier trained on Astromer-generated embeddings. Our results\ndemonstrate that Astromer 2 significantly outperforms Astromer 1 across all\nevaluated scenarios, including limited datasets of 20, 100, and 500 samples per\nclass. The use of weighted per-sample embeddings, which integrate intermediate\nrepresentations from Astromer's attention blocks, is particularly impactful.\nNotably, Astromer 2 achieves a 15% improvement in F1 score on the ATLAS dataset\ncompared to prior models, showcasing robust generalization to new datasets.\nThis enhanced performance, especially with minimal labeled data, underscores\nthe potential of Astromer 2 for more efficient and scalable light curve\nanalysis.",
      "tldr_zh": "本论文介绍了 Astromer 2，一种专为提取光曲线嵌入而设计的基础模型，是 Astromer 1 的增强版本，旨在通过自监督学习提升光曲线分析的性能。模型在 MACHO 调查的 150 万单波段光曲线上预训练，通过预测随机屏蔽的观察序列，并使用加权每样本嵌入整合注意力块表示。实验结果显示，Astromer 2 在分类任务中显著优于 Astromer 1，尤其在小样本数据集（如 20、100 和 500 个样本/类）上，F1 score 提高了 15%，并在 ATLAS 数据集上展现出强劲的泛化能力。该模型的改进为更高效、可扩展的光曲线分析提供了新潜力。",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "10 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02717v1",
      "published_date": "2025-02-04 20:56:14 UTC",
      "updated_date": "2025-02-04 20:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:41:12.139312"
    },
    {
      "arxiv_id": "2502.02715v1",
      "title": "An Analysis of LLM Fine-Tuning and Few-Shot Learning for Flaky Test Detection and Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Riddhi More",
        "Jeremy S. Bradbury"
      ],
      "abstract": "Flaky tests exhibit non-deterministic behavior during execution and they may\npass or fail without any changes to the program under test. Detecting and\nclassifying these flaky tests is crucial for maintaining the robustness of\nautomated test suites and ensuring the overall reliability and confidence in\nthe testing. However, flaky test detection and classification is challenging\ndue to the variability in test behavior, which can depend on environmental\nconditions and subtle code interactions. Large Language Models (LLMs) offer\npromising approaches to address this challenge, with fine-tuning and few-shot\nlearning (FSL) emerging as viable techniques. With enough data fine-tuning a\npre-trained LLM can achieve high accuracy, making it suitable for organizations\nwith more resources. Alternatively, we introduce FlakyXbert, an FSL approach\nthat employs a Siamese network architecture to train efficiently with limited\ndata. To understand the performance and cost differences between these two\nmethods, we compare fine-tuning on larger datasets with FSL in scenarios\nrestricted by smaller datasets. Our evaluation involves two existing flaky test\ndatasets, FlakyCat and IDoFT. Our results suggest that while fine-tuning can\nachieve high accuracy, FSL provides a cost-effective approach with competitive\naccuracy, which is especially beneficial for organizations or projects with\nlimited historical data available for training. These findings underscore the\nviability of both fine-tuning and FSL in flaky test detection and\nclassification with each suited to different organizational needs and resource\navailability.",
      "tldr_zh": "这篇论文分析了使用LLM的Fine-Tuning和Few-Shot Learning在Flaky Test检测和分类中的应用，旨在解决Flaky Test的非确定性问题，这些测试可能在不改变代码的情况下通过或失败。研究引入了FlakyXbert，一种基于Siamese网络的Few-Shot Learning方法，能够在数据有限的场景下高效训练，并与Fine-Tuning在FlakyCat和IDoFT数据集上进行了比较。结果显示，Fine-Tuning能实现高准确率但资源需求较高，而Few-Shot Learning提供更具成本效益的选项，尤其适合数据有限的组织或项目。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.02715v1",
      "published_date": "2025-02-04 20:54:51 UTC",
      "updated_date": "2025-02-04 20:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:41:24.145635"
    },
    {
      "arxiv_id": "2502.04358v1",
      "title": "Position: Scaling LLM Agents Requires Asymptotic Analysis with LLM Primitives",
      "title_zh": "观点：扩展 LLM 代理需要使用",
      "authors": [
        "Elliot Meyerson",
        "Xin Qiu"
      ],
      "abstract": "Decomposing hard problems into subproblems often makes them easier and more\nefficient to solve. With large language models (LLMs) crossing critical\nreliability thresholds for a growing slate of capabilities, there is an\nincreasing effort to decompose systems into sets of LLM-based agents, each of\nwhom can be delegated sub-tasks. However, this decomposition (even when\nautomated) is often intuitive, e.g., based on how a human might assign roles to\nmembers of a human team. How close are these role decompositions to optimal?\nThis position paper argues that asymptotic analysis with LLM primitives is\nneeded to reason about the efficiency of such decomposed systems, and that\ninsights from such analysis will unlock opportunities for scaling them. By\ntreating the LLM forward pass as the atomic unit of computational cost, one can\nseparate out the (often opaque) inner workings of a particular LLM from the\ninherent efficiency of how a set of LLMs are orchestrated to solve hard\nproblems. In other words, if we want to scale the deployment of LLMs to the\nlimit, instead of anthropomorphizing LLMs, asymptotic analysis with LLM\nprimitives should be used to reason about and develop more powerful\ndecompositions of large problems into LLM agents.",
      "tldr_zh": "这篇论文主张，为了扩展LLM代理的规模，需要采用LLM基元的渐近分析（asymptotic analysis with LLM primitives）来评估和优化问题分解，目前的直观分解（如模仿人类团队角色）可能并非最优。论文建议将LLM前向传递视为计算成本的原子单位，从而将特定LLM的内部机制与代理编排的固有效率分开分析。这种方法能揭示更有效的分解策略，帮助大规模部署LLM系统以解决复杂问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CC",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages including references",
      "pdf_url": "http://arxiv.org/pdf/2502.04358v1",
      "published_date": "2025-02-04 20:47:43 UTC",
      "updated_date": "2025-02-04 20:47:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:41:35.296423"
    },
    {
      "arxiv_id": "2502.06811v2",
      "title": "Aligning Human and Machine Attention for Enhanced Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Avihay Chriqui",
        "Inbal Yahav",
        "Dov Teeni",
        "Ahmed Abbasi"
      ],
      "abstract": "Attention, or prioritization of certain information items over others, is a\ncritical element of any learning process, for both humans and machines. Given\nthat humans continue to outperform machines in certain learning tasks, it seems\nplausible that machine performance could be enriched by aligning machine\nattention with human attention mechanisms -- yet research on this topic is\nsparse and has achieved only limited success. This paper proposes a new\napproach to address this gap, called Human-Machine Attention Learning (HuMAL).\nThis approach involves reliance on data annotated by humans to reflect their\nself-perceived attention during specific tasks. We evaluate several alternative\nstrategies for integrating such human attention data into machine learning (ML)\nalgorithms, using a sentiment analysis task (review data from Yelp) and a\npersonality-type classification task (data from myPersonality). The\nbest-performing HuMAL strategy significantly enhances the task performance of\nfine-tuned transformer models (BERT, as well as GPT-2 and XLNET), and the\nbenefit is particularly pronounced under challenging conditions of imbalanced\nor sparse labeled data. This research contributes to a deeper understanding of\nstrategies for integrating human attention into ML models and highlights the\npotential of leveraging human cognition to augment ML in real-world\napplications.",
      "tldr_zh": "这篇论文提出了一种名为 Human-Machine Attention Learning (HuMAL) 的方法，通过整合人类标注的注意力数据来提升监督学习性能，旨在将人类注意力机制与机器模型对齐。研究评估了多种策略，将这些数据应用于情感分析（Yelp 数据）和个性类型分类（myPersonality 数据）任务。结果显示，最佳策略显著提高了 transformer 模型（如 BERT、GPT-2 和 XLNET）的任务表现，尤其在数据不平衡或稀疏的情况下。总体上，这为利用人类认知增强机器学习在实际应用的潜力提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06811v2",
      "published_date": "2025-02-04 20:44:38 UTC",
      "updated_date": "2025-02-19 20:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:41:47.346929"
    },
    {
      "arxiv_id": "2502.02703v1",
      "title": "Developing multilingual speech synthesis system for Ojibwe, Mi'kmaq, and Maliseet",
      "title_zh": "翻译失败",
      "authors": [
        "Shenran Wang",
        "Changbing Yang",
        "Mike Parkhill",
        "Chad Quinn",
        "Christopher Hammerly",
        "Jian Zhu"
      ],
      "abstract": "We present lightweight flow matching multilingual text-to-speech (TTS)\nsystems for Ojibwe, Mi'kmaq, and Maliseet, three Indigenous languages in North\nAmerica. Our results show that training a multilingual TTS model on three\ntypologically similar languages can improve the performance over monolingual\nmodels, especially when data are scarce. Attention-free architectures are\nhighly competitive with self-attention architecture with higher memory\nefficiency. Our research not only advances technical development for the\nrevitalization of low-resource languages but also highlights the cultural gap\nin human evaluation protocols, calling for a more community-centered approach\nto human evaluation.",
      "tldr_zh": "该研究开发了针对北美原住民语言 Ojibwe、Mi'kmaq 和 Maliseet 的轻量级流匹配 multilingual TTS（文本到语音）系统，结果显示多语言模型在数据稀缺情况下比单语言模型性能更优，特别是对类型相似的语言。研究还证明了 attention-free architectures 在内存效率上优于自注意力架构，同时保持竞争力。该工作不仅推动了低资源语言的复兴技术发展，还强调了人类评估协议中的文化差距，呼吁采用更注重社区的评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02703v1",
      "published_date": "2025-02-04 20:36:55 UTC",
      "updated_date": "2025-02-04 20:36:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:41:59.109880"
    },
    {
      "arxiv_id": "2502.02701v1",
      "title": "Practically Effective Adjustment Variable Selection in Causal Inference",
      "title_zh": "在因果推断中实际有效的调整变量选择",
      "authors": [
        "Atsushi Noda",
        "Takashi Isozaki"
      ],
      "abstract": "In the estimation of causal effects, one common method for removing the\ninfluence of confounders is to adjust the variables that satisfy the back-door\ncriterion. However, it is not always possible to uniquely determine sets of\nsuch variables. Moreover, real-world data is almost always limited, which means\nit may be insufficient for statistical estimation. Therefore, we propose\ncriteria for selecting variables from a list of candidate adjustment variables\nalong with an algorithm to prevent accuracy degradation in causal effect\nestimation. We initially focus on directed acyclic graphs (DAGs) and then\noutlines specific steps for applying this method to completed partially\ndirected acyclic graphs (CPDAGs). We also present and prove a theorem on causal\neffect computation possibility in CPDAGs. Finally, we demonstrate the practical\nutility of our method using both existing and artificial data.",
      "tldr_zh": "在因果推断中，为去除混杂因素的影响，该论文提出了一种实用的调整变量选择标准和算法，以从候选变量中筛选满足back-door criterion的变量，并防止因果效应估计的准确性下降。方法首先针对directed acyclic graphs (DAGs)进行设计，然后扩展到completed partially directed acyclic graphs (CPDAGs)，并证明了一个关于CPDAGs中因果效应计算可能性的定理。实验结果通过现有和人工数据验证了该方法的实用性，提高了因果推断的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.data-an",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02701v1",
      "published_date": "2025-02-04 20:35:19 UTC",
      "updated_date": "2025-02-04 20:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:42:12.677945"
    },
    {
      "arxiv_id": "2502.02690v1",
      "title": "Controllable Video Generation with Provable Disentanglement",
      "title_zh": "具有可证明解耦的可控视频生成",
      "authors": [
        "Yifan Shen",
        "Peiyuan Zhu",
        "Zijian Li",
        "Shaoan Xie",
        "Zeyu Tang",
        "Namrata Deka",
        "Zongfang Liu",
        "Guangyi Chen",
        "Kun Zhang"
      ],
      "abstract": "Controllable video generation remains a significant challenge, despite recent\nadvances in generating high-quality and consistent videos. Most existing\nmethods for controlling video generation treat the video as a whole, neglecting\nintricate fine-grained spatiotemporal relationships, which limits both control\nprecision and efficiency. In this paper, we propose Controllable Video\nGenerative Adversarial Networks (CoVoGAN) to disentangle the video concepts,\nthus facilitating efficient and independent control over individual concepts.\nSpecifically, following the minimal change principle, we first disentangle\nstatic and dynamic latent variables. We then leverage the sufficient change\nproperty to achieve component-wise identifiability of dynamic latent variables,\nenabling independent control over motion and identity. To establish the\ntheoretical foundation, we provide a rigorous analysis demonstrating the\nidentifiability of our approach. Building on these theoretical insights, we\ndesign a Temporal Transition Module to disentangle latent dynamics. To enforce\nthe minimal change principle and sufficient change property, we minimize the\ndimensionality of latent dynamic variables and impose temporal conditional\nindependence. To validate our approach, we integrate this module as a plug-in\nfor GANs. Extensive qualitative and quantitative experiments on various video\ngeneration benchmarks demonstrate that our method significantly improves\ngeneration quality and controllability across diverse real-world scenarios.",
      "tldr_zh": "该论文提出 CoVoGAN 方法，通过可证明的解耦(disentanglement)技术，实现对视频概念的独立控制，解决了现有方法忽略细粒度时空关系的局限性。具体而言，该方法基于最小变化原则和充分变化属性，首先解耦静态和动态潜在变量，然后通过 Temporal Transition Module 实现动态变量的组件级可识别性，以独立控制运动和身份。实验结果显示，在各种视频生成基准上，CoVoGAN 显著提升了生成质量和可控性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02690v1",
      "published_date": "2025-02-04 20:10:20 UTC",
      "updated_date": "2025-02-04 20:10:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:42:23.424249"
    },
    {
      "arxiv_id": "2502.02688v1",
      "title": "Efficient Implementation of the Global Cardinality Constraint with Costs",
      "title_zh": "带有成本的全局基数约束的高效实现",
      "authors": [
        "Margaux Schmied",
        "Jean-Charles Regin"
      ],
      "abstract": "The success of Constraint Programming relies partly on the global constraints\nand implementation of the associated filtering algorithms. Recently, new ideas\nemerged to improve these implementations in practice, especially regarding the\nall different constraint. In this paper, we consider the cardinality constraint\nwith costs. The cardinality constraint is a generalization of the all different\nconstraint that specifies the number of times each value must be taken by a\ngiven set of variables in a solution. The version with costs introduces an\nassignment cost and bounds the total sum of assignment costs. The arc\nconsistency filtering algorithm of this constraint is difficult to use in\npractice, as it systematically searches for many shortest paths. We propose a\nnew approach that works with upper bounds on shortest paths based on landmarks.\nThis approach can be seen as a preprocessing. It is fast and avoids, in\npractice, a large number of explicit computations of shortest paths.",
      "tldr_zh": "该论文探讨了约束编程（Constraint Programming）中带成本的全局基数约束（Global Cardinality Constraint）的有效实现，针对其弧一致性过滤算法（arc consistency filtering algorithm）在实践中需计算大量最短路径的问题。研究提出了一种基于地标（landmarks）上界的预处理方法，避免了显式计算许多最短路径，从而提高了算法效率。该方法快速且实用，为全局约束的优化提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the 30th International Conference on Principles and\n  Practice of Constraint Programming (CP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2502.02688v1",
      "published_date": "2025-02-04 20:03:53 UTC",
      "updated_date": "2025-02-04 20:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:42:34.164930"
    },
    {
      "arxiv_id": "2502.03487v1",
      "title": "Artificial Intelligence and Legal Analysis: Implications for Legal Education and the Profession",
      "title_zh": "人工智能和法律分析：对法律教育和职业的影响",
      "authors": [
        "Lee Peoples"
      ],
      "abstract": "This article reports the results of a study examining the ability of legal\nand non-legal Large Language Models to perform legal analysis using the\nIssue-Rule-Application-Conclusion framework. LLMs were tested on legal\nreasoning tasks involving rule analysis and analogical reasoning. The results\nshow that LLMs can conduct basic IRAC analysis, but are limited by brief\nresponses lacking detail, an inability to commit to answers, false confidence,\nand hallucinations. The study compares legal and nonlegal LLMs, identifies\nshortcomings, and explores traits that may hinder their ability to think like a\nlawyer. It also discusses the implications for legal education and practice,\nhighlighting the need for critical thinking skills in future lawyers and the\npotential pitfalls of overreliance on artificial intelligence AI resulting in a\nloss of logic, reasoning, and critical thinking skills.",
      "tldr_zh": "该研究评估了法律和非法律大型语言模型（LLMs）使用 Issue-Rule-Application-Conclusion (IRAC) 框架进行法律分析的能力，包括规则分析和类比推理任务。结果显示，LLMs 能执行基本的 IRAC 分析，但受限于简短响应、缺乏细节、无法做出承诺、虚假自信以及幻觉等问题。相比之下，法律 LLMs 与非法律 LLMs 存在显著差异，该研究识别了这些模型在“像律师一样思考”方面的短板，并强调了过度依赖 AI 的风险，可能导致逻辑、推理和批判性思维技能的丧失。对法律教育和职业的影响包括加强未来律师的批判性思维训练，以避免潜在的陷阱。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03487v1",
      "published_date": "2025-02-04 19:50:48 UTC",
      "updated_date": "2025-02-04 19:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:42:47.296524"
    },
    {
      "arxiv_id": "2502.02683v1",
      "title": "Streaming Speaker Change Detection and Gender Classification for Transducer-Based Multi-Talker Speech Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Peidong Wang",
        "Naoyuki Kanda",
        "Jian Xue",
        "Jinyu Li",
        "Xiaofei Wang",
        "Aswin Shanmugam Subramanian",
        "Junkun Chen",
        "Sunit Sivasankaran",
        "Xiong Xiao",
        "Yong Zhao"
      ],
      "abstract": "Streaming multi-talker speech translation is a task that involves not only\ngenerating accurate and fluent translations with low latency but also\nrecognizing when a speaker change occurs and what the speaker's gender is.\nSpeaker change information can be used to create audio prompts for a zero-shot\ntext-to-speech system, and gender can help to select speaker profiles in a\nconventional text-to-speech model. We propose to tackle streaming speaker\nchange detection and gender classification by incorporating speaker embeddings\ninto a transducer-based streaming end-to-end speech translation model. Our\nexperiments demonstrate that the proposed methods can achieve high accuracy for\nboth speaker change detection and gender classification.",
      "tldr_zh": "该论文针对基于 Transducer 的流式多说话人语音翻译任务，提出了一种整合说话人嵌入 (speaker embeddings) 的方法，以实现实时检测说话人变化和性别分类。方法将说话人嵌入融入端到端语音翻译模型中，不仅生成准确、低延迟的翻译，还提供说话人信息用于文本到语音系统。实验结果显示，该方法在说话人变化检测和性别分类上均取得了高准确率，为多说话人语音翻译的应用提供了可行性提升。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02683v1",
      "published_date": "2025-02-04 19:50:15 UTC",
      "updated_date": "2025-02-04 19:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:42:58.165254"
    },
    {
      "arxiv_id": "2502.04357v1",
      "title": "Reusing Embeddings: Reproducible Reward Model Research in Large Language Model Alignment without GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Sun",
        "Yunyi Shen",
        "Jean-Francois Ton",
        "Mihaela van der Schaar"
      ],
      "abstract": "Large Language Models (LLMs) have made substantial strides in structured\ntasks through Reinforcement Learning (RL), demonstrating proficiency in\nmathematical reasoning and code generation. However, applying RL in broader\ndomains like chatbots and content generation -- through the process known as\nReinforcement Learning from Human Feedback (RLHF) -- presents unique\nchallenges. Reward models in RLHF are critical, acting as proxies that evaluate\nthe alignment of LLM outputs with human intent. Despite advancements, the\ndevelopment of reward models is hindered by challenges such as computational\nheavy training, costly evaluation, and therefore poor reproducibility. We\nadvocate for using embedding-based input in reward model research as an\naccelerated solution to those challenges. By leveraging embeddings for reward\nmodeling, we can enhance reproducibility, reduce computational demands on\nhardware, improve training stability, and significantly reduce training and\nevaluation costs, hence facilitating fair and efficient comparisons in this\nactive research area. We then show a case study of reproducing existing reward\nmodel ensemble research using embedding-based reward models. We discussed\nfuture avenues for research, aiming to contribute to safer and more effective\nLLM deployments.",
      "tldr_zh": "这篇论文探讨了在大型语言模型(LLMs)对齐过程中，强化学习从人类反馈(RLHF)中的奖励模型面临的高计算成本和可重复性差等问题，提出使用基于嵌入(embeddings)的输入作为解决方案。该方法通过重用嵌入来减少GPU依赖、提升训练稳定性，并显著降低成本，从而促进公平高效的研究比较。论文通过一个案例研究展示了如何复制现有的奖励模型集成研究，并讨论了未来方向，以支持更安全有效的LLM部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04357v1",
      "published_date": "2025-02-04 19:37:35 UTC",
      "updated_date": "2025-02-04 19:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:43:11.989580"
    },
    {
      "arxiv_id": "2502.02673v1",
      "title": "MedRAX: Medical Reasoning Agent for Chest X-ray",
      "title_zh": "翻译失败",
      "authors": [
        "Adibvafa Fallahpour",
        "Jun Ma",
        "Alif Munim",
        "Hongwei Lyu",
        "Bo Wang"
      ],
      "abstract": "Chest X-rays (CXRs) play an integral role in driving critical decisions in\ndisease management and patient care. While recent innovations have led to\nspecialized models for various CXR interpretation tasks, these solutions often\noperate in isolation, limiting their practical utility in clinical practice. We\npresent MedRAX, the first versatile AI agent that seamlessly integrates\nstate-of-the-art CXR analysis tools and multimodal large language models into a\nunified framework. MedRAX dynamically leverages these models to address complex\nmedical queries without requiring additional training. To rigorously evaluate\nits capabilities, we introduce ChestAgentBench, a comprehensive benchmark\ncontaining 2,500 complex medical queries across 7 diverse categories. Our\nexperiments demonstrate that MedRAX achieves state-of-the-art performance\ncompared to both open-source and proprietary models, representing a significant\nstep toward the practical deployment of automated CXR interpretation systems.\nData and code have been publicly available at\nhttps://github.com/bowang-lab/MedRAX",
      "tldr_zh": "该研究介绍了 MedRAX，一种多功能 AI 代理，用于胸部 X 光片 (CXRs) 的医疗推理，它将先进的 CXR 分析工具和多模态大型语言模型整合到一个统一框架中，实现对复杂医疗查询的动态处理，而无需额外训练。研究者开发了 ChestAgentBench，这是一个包含 2500 个查询的全面基准，涵盖 7 个类别，用于评估 MedRAX 的性能。实验结果显示，MedRAX 比开源和专有模型都达到了 state-of-the-art 水平，推动了自动 CXR 解释系统的实际临床部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.02673v1",
      "published_date": "2025-02-04 19:31:00 UTC",
      "updated_date": "2025-02-04 19:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:43:23.661504"
    },
    {
      "arxiv_id": "2502.02671v1",
      "title": "On Teacher Hacking in Language Model Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniil Tiapkin",
        "Daniele Calandriello",
        "Johan Ferret",
        "Sarah Perrin",
        "Nino Vieillard",
        "Alexandre Ramé",
        "Mathieu Blondel"
      ],
      "abstract": "Post-training of language models (LMs) increasingly relies on the following\ntwo stages: (i) knowledge distillation, where the LM is trained to imitate a\nlarger teacher LM, and (ii) reinforcement learning from human feedback (RLHF),\nwhere the LM is aligned by optimizing a reward model. In the second RLHF stage,\na well-known challenge is reward hacking, where the LM over-optimizes the\nreward model. Such phenomenon is in line with Goodhart's law and can lead to\ndegraded performance on the true objective. In this paper, we investigate\nwhether a similar phenomenon, that we call teacher hacking, can occur during\nknowledge distillation. This could arise because the teacher LM is itself an\nimperfect approximation of the true distribution. To study this, we propose a\ncontrolled experimental setup involving: (i) an oracle LM representing the\nground-truth distribution, (ii) a teacher LM distilled from the oracle, and\n(iii) a student LM distilled from the teacher. Our experiments reveal the\nfollowing insights. When using a fixed offline dataset for distillation,\nteacher hacking occurs; moreover, we can detect it by observing when the\noptimization process deviates from polynomial convergence laws. In contrast,\nemploying online data generation techniques effectively mitigates teacher\nhacking. More precisely, we identify data diversity as the key factor in\npreventing hacking. Overall, our findings provide a deeper understanding of the\nbenefits and limitations of distillation for building robust and efficient LMs.",
      "tldr_zh": "该论文探讨了语言模型知识蒸馏过程中可能发生的teacher hacking问题，即学生模型过度模仿教师模型，而教师模型本身是真实分布的近似，导致性能下降，类似于RLHF中的reward hacking。研究者设计了一个受控实验，包括oracle LM（代表真实分布）、teacher LM（从oracle蒸馏）和student LM（从teacher蒸馏），以系统分析这一现象。实验发现，使用固定离线数据集时会引发teacher hacking，并可通过观察优化过程偏离多项式收敛规律来检测；然而，采用在线数据生成技术并提升数据多样性，能有效缓解teacher hacking。总体上，该研究加深了对知识蒸馏优缺点和构建鲁棒高效语言模型的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02671v1",
      "published_date": "2025-02-04 19:26:28 UTC",
      "updated_date": "2025-02-04 19:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:43:38.014160"
    },
    {
      "arxiv_id": "2502.04356v1",
      "title": "Open Foundation Models in Healthcare: Challenges, Paradoxes, and Opportunities with GenAI Driven Personalized Prescription",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Alkaeed",
        "Sofiat Abioye",
        "Adnan Qayyum",
        "Yosra Magdi Mekki",
        "Ilhem Berrou",
        "Mohamad Abdallah",
        "Ala Al-Fuqaha",
        "Muhammad Bilal",
        "Junaid Qadir"
      ],
      "abstract": "In response to the success of proprietary Large Language Models (LLMs) such\nas OpenAI's GPT-4, there is a growing interest in developing open,\nnon-proprietary LLMs and AI foundation models (AIFMs) for transparent use in\nacademic, scientific, and non-commercial applications. Despite their inability\nto match the refined functionalities of their proprietary counterparts, open\nmodels hold immense potential to revolutionize healthcare applications. In this\npaper, we examine the prospects of open-source LLMs and AIFMs for developing\nhealthcare applications and make two key contributions. Firstly, we present a\ncomprehensive survey of the current state-of-the-art open-source healthcare\nLLMs and AIFMs and introduce a taxonomy of these open AIFMs, categorizing their\nutility across various healthcare tasks. Secondly, to evaluate the\ngeneral-purpose applications of open LLMs in healthcare, we present a case\nstudy on personalized prescriptions. This task is particularly significant due\nto its critical role in delivering tailored, patient-specific medications that\ncan greatly improve treatment outcomes. In addition, we compare the performance\nof open-source models with proprietary models in settings with and without\nRetrieval-Augmented Generation (RAG). Our findings suggest that, although less\nrefined, open LLMs can achieve performance comparable to proprietary models\nwhen paired with grounding techniques such as RAG. Furthermore, to highlight\nthe clinical significance of LLMs-empowered personalized prescriptions, we\nperform subjective assessment through an expert clinician. We also elaborate on\nethical considerations and potential risks associated with the misuse of\npowerful LLMs and AIFMs, highlighting the need for a cautious and responsible\nimplementation in healthcare.",
      "tldr_zh": "本论文探讨了开源大型语言模型（LLMs）和AI基础模型（AIFMs）在医疗领域的挑战与机遇，特别是结合生成AI（GenAI）驱动的个性化处方应用。作者首先进行全面调研，介绍了现有开源医疗LLMs和AIFMs的现状，并提出一个分类体系，以评估其在各种医疗任务中的效用。其次，通过个性化处方案例研究，比较了开源模型与专有模型的性能，发现开源LLMs在结合检索增强生成（RAG）技术时，可实现与专有模型相当的表现。论文还强调了伦理考虑和潜在风险，呼吁在医疗中谨慎且负责任地实施这些模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04356v1",
      "published_date": "2025-02-04 19:16:56 UTC",
      "updated_date": "2025-02-04 19:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:43:47.832730"
    },
    {
      "arxiv_id": "2502.02659v1",
      "title": "A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Li",
        "Tianyi Zhang",
        "Zechuan Li",
        "Soyeon Caren Han"
      ],
      "abstract": "Transformer-based Large Language Models (LLMs) struggle to process inputs\nexceeding their training context window, with performance degrading due to\npositional out-of-distribution (O.O.D.) that disrupt attention computations.\nExisting solutions, fine-tuning and training-free methods, are limited by\ncomputational inefficiency, attention logit outliers or loss of local\npositional information. To address this, we propose Greedy Attention Logit\nInterpolation (GALI), a training-free length extrapolation method that\nmaximizes the utilization of pretrained positional intervals while avoiding\nattention logit outliers through attention logit interpolation. The result\ndemonstrates that GALI consistently outperforms state-of-the-art training-free\nmethods. Our findings reveal that LLMs interpret positional intervals unevenly\nwithin their training context window, suggesting that extrapolating within a\nsmaller positional interval range yields superior results-even for\nshort-context tasks. GALI represents a significant step toward resolving the\npositional O.O.D. challenge, enabling more reliable long-text understanding in\nLLMs. Our implementation of GALI, along with the experiments from our paper, is\nopen-sourced at https://github.com/AcademyCityL/GALI.",
      "tldr_zh": "Transformer-based Large Language Models (LLMs) 在处理超过训练上下文窗口的输入时，由于位置分布外 (positional out-of-distribution) 问题导致注意力计算受损，性能下降。为解决现有方法（如微调或训练-free 方案）的计算效率低和信息丢失问题，本文提出 Greedy Attention Logit Interpolation (GALI)，一种无需训练的长度外推方法，通过注意力 logit 插值最大化利用预训练位置区间，避免异常值。实验结果表明，GALI  consistently outperforms 现有 state-of-the-art 训练-free 方法，并揭示 LLMs 在训练窗口内对位置区间的解释不均匀，在较小区间内外推效果更佳，从而显著提升了 LLMs 的长文本理解可靠性。代码已在 GitHub 开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, under review in the conference",
      "pdf_url": "http://arxiv.org/pdf/2502.02659v1",
      "published_date": "2025-02-04 19:01:24 UTC",
      "updated_date": "2025-02-04 19:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:44:00.777279"
    },
    {
      "arxiv_id": "2502.02649v2",
      "title": "Fully Autonomous AI Agents Should Not be Developed",
      "title_zh": "翻译失败",
      "authors": [
        "Margaret Mitchell",
        "Avijit Ghosh",
        "Alexandra Sasha Luccioni",
        "Giada Pistilli"
      ],
      "abstract": "This paper argues that fully autonomous AI agents should not be developed. In\nsupport of this position, we build from prior scientific literature and current\nproduct marketing to delineate different AI agent levels and detail the ethical\nvalues at play in each, documenting trade-offs in potential benefits and risks.\nOur analysis reveals that risks to people increase with the autonomy of a\nsystem: The more control a user cedes to an AI agent, the more risks to people\narise. Particularly concerning are safety risks, which affect human life and\nimpact further values.",
      "tldr_zh": "这篇论文主张不应开发完全自治的 AI Agents（完全自治 AI 代理），因为这会带来显著的伦理和安全风险。作者基于现有科学文献和产品营销，划分了不同级别的 AI 代理，并分析了每级别的伦理价值、潜在益处与风险权衡。研究发现，随着用户将控制权移交给 AI 系统，风险会急剧增加，尤其是安全风险，可能危及人类生命并影响其他核心价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02649v2",
      "published_date": "2025-02-04 19:00:06 UTC",
      "updated_date": "2025-02-06 17:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:44:10.418279"
    },
    {
      "arxiv_id": "2502.02631v1",
      "title": "ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization",
      "title_zh": "ParetoQ：极低比特 LLM 量化中的缩放定律",
      "authors": [
        "Zechun Liu",
        "Changsheng Zhao",
        "Hanxian Huang",
        "Sijia Chen",
        "Jing Zhang",
        "Jiawei Zhao",
        "Scott Roy",
        "Lisa Jin",
        "Yunyang Xiong",
        "Yangyang Shi",
        "Lin Xiao",
        "Yuandong Tian",
        "Bilge Soran",
        "Raghuraman Krishnamoorthi",
        "Tijmen Blankevoort",
        "Vikas Chandra"
      ],
      "abstract": "The optimal bit-width for achieving the best trade-off between quantized\nmodel size and accuracy has been a subject of ongoing debate. While some\nadvocate for 4-bit quantization, others propose that 1.58-bit offers superior\nresults. However, the lack of a cohesive framework for different bits has left\nsuch conclusions relatively tenuous. We present ParetoQ, the first unified\nframework that facilitates rigorous comparisons across 1-bit, 1.58-bit, 2-bit,\n3-bit, and 4-bit quantization settings. Our findings reveal a notable learning\ntransition between 2 and 3 bits: For 3-bits and above, the fine-tuned models\nstay close to their original pre-trained distributions, whereas for learning\n2-bit networks or below, the representations change drastically. By optimizing\ntraining schemes and refining quantization functions, ParetoQ surpasses all\nprevious methods tailored to specific bit widths. Remarkably, our ParetoQ\nternary 600M-parameter model even outperforms the previous SoTA ternary\n3B-parameter model in accuracy, using only one-fifth of the parameters.\nExtensive experimentation shows that ternary, 2-bit, and 3-bit quantization\nmaintains comparable performance in the size-accuracy trade-off and generally\nexceeds 4-bit and binary quantization. Considering hardware constraints, 2-bit\nquantization offers promising potential for memory reduction and speedup.",
      "tldr_zh": "本研究提出ParetoQ框架，这是首个统一框架，用于比较LLM量化中的1-bit到4-bit设置，旨在解决最佳bit-width权衡问题。研究发现，在2-bit和3-bit之间存在显著学习转变：3-bit及以上量化保持接近原预训练分布，而2-bit及以下则导致表示 drastic变化。通过优化训练方案和量化函数，ParetoQ超越了先前针对特定位宽的方法，例如其ternary（3-bit）600M参数模型在准确性上超过了先前最先进的三元3B参数模型，仅用五分之一参数。实验结果显示，ternary、2-bit和3-bit量化在大小-准确性权衡中性能更优，并强调2-bit量化在硬件约束下具有显著的内存减少和加速潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02631v1",
      "published_date": "2025-02-04 18:59:26 UTC",
      "updated_date": "2025-02-04 18:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:46:05.946878"
    },
    {
      "arxiv_id": "2502.02584v1",
      "title": "QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search",
      "title_zh": "QLASS：通过 Q-引导步进搜索提升语言代理推理",
      "authors": [
        "Zongyu Lin",
        "Yao Tang",
        "Xingcheng Yao",
        "Da Yin",
        "Ziniu Hu",
        "Yizhou Sun",
        "Kai-Wei Chang"
      ],
      "abstract": "Language agents have become a promising solution to complex interactive\ntasks. One of the key ingredients to the success of language agents is the\nreward model on the trajectory of the agentic workflow, which provides valuable\nguidance during training or inference. However, due to the lack of annotations\nof intermediate interactions, most existing works use an outcome reward model\nto optimize policies across entire trajectories. This may lead to sub-optimal\npolicies and hinder the overall performance. To address this, we propose QLASS\n(Q-guided Language Agent Stepwise Search), to automatically generate\nannotations by estimating Q-values in a stepwise manner for open language\nagents. By introducing a reasoning tree and performing process reward modeling,\nQLASS provides effective intermediate guidance for each step. With the stepwise\nguidance, we propose a Q-guided generation strategy to enable language agents\nto better adapt to long-term value, resulting in significant performance\nimprovement during model inference on complex interactive agent tasks. Notably,\neven with almost half the annotated data, QLASS retains strong performance,\ndemonstrating its efficiency in handling limited supervision. We also\nempirically demonstrate that QLASS can lead to more effective decision making\nthrough qualitative analysis. We will release our code and data.",
      "tldr_zh": "本文提出 QLASS，一种通过 Q-guided stepwise search 的框架，来提升语言代理（Language agents）在复杂交互任务中的推理性能。QLASS 通过逐步估计 Q-values 自动生成中间注解，并引入 reasoning tree 和 process reward modeling，为每个步骤提供有效的指导，从而帮助代理更好地适应长期价值。实验结果显示，该方法显著提高了代理的整体表现，即使使用几乎一半的注解数据，也能保持强性能；此外，通过定性分析，QLASS 证明了其在决策方面的有效性，并计划发布代码和数据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02584v1",
      "published_date": "2025-02-04 18:58:31 UTC",
      "updated_date": "2025-02-04 18:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:44:35.326739"
    },
    {
      "arxiv_id": "2502.04355v1",
      "title": "LLM-ProS: Analyzing Large Language Models' Performance in Competitive Problem Solving",
      "title_zh": "LLM-ProS：分析大语言模型在竞争性问题解决中的性能",
      "authors": [
        "Md Sifat Hossain",
        "Anika Tabassum",
        "Md. Fahim Arefin",
        "Tarannum Shaila Zaman"
      ],
      "abstract": "The rapid advancement of large language models has opened new avenues for\nautomating complex problem-solving tasks such as algorithmic coding and\ncompetitive programming. This paper introduces a novel evaluation technique,\nLLM-ProS, to assess the performance of state-of-the-art LLMs on International\nCollegiate Programming Contest (ICPC) problems. Using a curated dataset of 166\nWorld Finals problems from 2011 to 2024, we benchmark the models' reasoning,\naccuracy, and efficiency. We evaluate the five models-GPT-4o, Mistral Large,\nLlama-3.1-405B, and the o1 family, consisting of o1-mini and o1-preview, across\ncritical metrics like correctness, resource utilization, and response\ncalibration. Our results reveal significant differences in the models'\nabilities to generalize, adapt, and solve novel problems. We also investigated\nthe impact of training methodologies, dataset contamination, and\nchain-of-thought reasoning on model performance. The findings provide new\ninsights into optimizing LLMs for algorithmic tasks, highlighting both\nstrengths and limitations of current models.",
      "tldr_zh": "这篇论文引入了 LLM-ProS，一种新型评估技术，用于分析大型语言模型（LLMs）在竞争性问题解决任务（如 ICPC 竞赛问题）中的性能。研究团队使用从 2011 到 2024 年的 166 个世界决赛问题数据集，评估了 GPT-4o、Mistral Large、Llama-3.1-405B、o1-mini 和 o1-preview 等五个模型的关键指标，包括正确性、资源利用和响应校准。结果显示，这些模型在泛化、适应和解决新问题方面存在显著差异，并揭示了训练方法、数据集污染和 chain-of-thought reasoning 对性能的影响。该研究为优化 LLMs 用于算法任务提供了宝贵见解，同时突出了当前模型的优势和局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in LLM4Code 2025 workshop proceedings",
      "pdf_url": "http://arxiv.org/pdf/2502.04355v1",
      "published_date": "2025-02-04 18:55:14 UTC",
      "updated_date": "2025-02-04 18:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:46:18.400744"
    },
    {
      "arxiv_id": "2502.05215v1",
      "title": "Watermarking across Modalities for Content Tracing and Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Fernandez"
      ],
      "abstract": "Watermarking embeds information into digital content like images, audio, or\ntext, imperceptible to humans but robustly detectable by specific algorithms.\nThis technology has important applications in many challenges of the industry\nsuch as content moderation, tracing AI-generated content, and monitoring the\nusage of AI models. The contributions of this thesis include the development of\nnew watermarking techniques for images, audio, and text. We first introduce\nmethods for active moderation of images on social platforms. We then develop\nspecific techniques for AI-generated content. We specifically demonstrate\nmethods to adapt latent generative models to embed watermarks in all generated\ncontent, identify watermarked sections in speech, and improve watermarking in\nlarge language models with tests that ensure low false positive rates.\nFurthermore, we explore the use of digital watermarking to detect model misuse,\nincluding the detection of watermarks in language models fine-tuned on\nwatermarked text, and introduce training-free watermarks for the weights of\nlarge transformers. Through these contributions, the thesis provides effective\nsolutions for the challenges posed by the increasing use of generative AI\nmodels and the need for model monitoring and content moderation. It finally\nexamines the challenges and limitations of watermarking techniques and discuss\npotential future directions for research in this area.",
      "tldr_zh": "这篇论文探讨了跨模态水印技术（watermarking），用于内容追踪和生成式 AI 的应用，通过在图像、音频和文本中嵌入不易察觉但可检测的信息来解决内容审核和模型监控挑战。主要贡献包括开发新方法，如适应潜在生成模型（latent generative models）在所有 AI 生成内容中嵌入水印、识别语音中的水印部分，以及改进大型语言模型（large language models）中的水印以降低假阳性率。此外，该论文还介绍了检测模型滥用（如在水印文本上微调的模型）和训练-free 水印（training-free watermarks）技术，提供有效解决方案，并讨论了水印技术的局限性及未来研究方向。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "PhD thesis - webpage available at\n  https://pierrefdz.github.io/publications/phd-thesis",
      "pdf_url": "http://arxiv.org/pdf/2502.05215v1",
      "published_date": "2025-02-04 18:49:50 UTC",
      "updated_date": "2025-02-04 18:49:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:46:29.577881"
    },
    {
      "arxiv_id": "2502.02573v1",
      "title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Soheil Abbasloo"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nnumerous fields, presenting an opportunity to revolutionize optimization\nproblem-solving, a crucial, ubiquitous, and complex domain. This paper explores\nthe proficiency of LLMs in handling Sequential Optimization Problems (SOPs). We\nintroduce WorldGen, a dynamic framework for generating unseen SOPs with\ncontrollable complexities, to evaluate LLM performance. Our initial\nobservations reveal that while LLMs perform well on simple SOPs, their\nperformance significantly degrades with increased complexity. Motivated by\nthis, we revisit philosophical hypotheses on reasoning to enhance LLM\nperformance. Inspired by the influential framework of Hegelian Dialectics, we\npropose ACE, demonstrating how the performance of LLMs in SOP contexts can be\nsignificantly improved without any retraining or further fine-tuning.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在处理顺序优化问题 (SOPs) 的能力，发现 LLMs 在简单 SOPs 上表现良好，但复杂度增加时性能显著下降。作者引入了 WorldGen 框架，这是一个动态系统，用于生成可控复杂度的未见 SOPs，以全面评估 LLM 的表现。受 Hegelian Dialectics 哲学框架启发，他们提出了 ACE 方法，能够在不进行任何重新训练或微调的情况下显著提升 LLMs 在 SOPs 上下文中的性能。该研究为优化问题求解领域提供了新的增强策略，推动了 LLMs 的实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02573v1",
      "published_date": "2025-02-04 18:47:31 UTC",
      "updated_date": "2025-02-04 18:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:46:42.046867"
    },
    {
      "arxiv_id": "2502.04354v1",
      "title": "Reviving The Classics: Active Reward Modeling in Large Language Model Alignment",
      "title_zh": "复兴经典：大型语言模型对齐中的主动奖励建模",
      "authors": [
        "Yunyi Shen",
        "Hao Sun",
        "Jean-François Ton"
      ],
      "abstract": "Building neural reward models from human preferences is a pivotal component\nin reinforcement learning from human feedback (RLHF) and large language model\nalignment research. Given the scarcity and high cost of human annotation, how\nto select the most informative pairs to annotate is an essential yet\nchallenging open problem. In this work, we highlight the insight that an ideal\ncomparison dataset for reward modeling should balance exploration of the\nrepresentation space and make informative comparisons between pairs with\nmoderate reward differences. Technically, challenges arise in quantifying the\ntwo objectives and efficiently prioritizing the comparisons to be annotated. To\naddress this, we propose the Fisher information-based selection strategies,\nadapt theories from the classical experimental design literature, and apply\nthem to the final linear layer of the deep neural network-based reward modeling\ntasks. Empirically, our method demonstrates remarkable performance, high\ncomputational efficiency, and stability compared to other selection methods\nfrom deep learning and classical statistical literature across multiple\nopen-source LLMs and datasets. Further ablation studies reveal that\nincorporating cross-prompt comparisons in active reward modeling significantly\nenhances labeling efficiency, shedding light on the potential for improved\nannotation strategies in RLHF.",
      "tldr_zh": "本研究针对强化学习从人类反馈（RLHF）和大型语言模型（LLM）对齐中的奖励模型构建问题，强调了在人类标注稀缺的情况下，如何选择最信息丰富的配对进行标注。作者提出基于Fisher information的选择策略，从经典实验设计文献中借鉴理论，并将其应用于深度神经网络奖励模型的最终线性层，以平衡表示空间探索和中等奖励差异的比较。实验结果显示，该方法在多个开源LLM和数据集上表现出显著性能提升、计算效率和稳定性；此外，消融研究证明，加入跨提示比较能显著提高标注效率，为RLHF的优化策略提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04354v1",
      "published_date": "2025-02-04 18:47:11 UTC",
      "updated_date": "2025-02-04 18:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:46:53.296776"
    },
    {
      "arxiv_id": "2502.02567v1",
      "title": "Fairness in Survival Analysis: A Novel Conditional Mutual Information Augmentation Approach",
      "title_zh": "生存分析中的公平性：一种新型的条件互信息增强方法",
      "authors": [
        "Tianyang Xie",
        "Yong Ge"
      ],
      "abstract": "Survival analysis, a vital tool for predicting the time to event, has been\nused in many domains such as healthcare, criminal justice, and finance. Like\nclassification tasks, survival analysis can exhibit bias against disadvantaged\ngroups, often due to biases inherent in data or algorithms. Several studies in\nboth the IS and CS communities have attempted to address fairness in survival\nanalysis. However, existing methods often overlook the importance of prediction\nfairness at pre-defined evaluation time points, which is crucial in real-world\napplications where decision making often hinges on specific time frames. To\naddress this critical research gap, we introduce a new fairness concept:\nequalized odds (EO) in survival analysis, which emphasizes prediction fairness\nat pre-defined time points. To achieve the EO fairness in survival analysis, we\npropose a Conditional Mutual Information Augmentation (CMIA) approach, which\nfeatures a novel fairness regularization term based on conditional mutual\ninformation and an innovative censored data augmentation technique. Our CMIA\napproach can effectively balance prediction accuracy and fairness, and it is\napplicable to various survival models. We evaluate the CMIA approach against\nseveral state-of-the-art methods within three different application domains,\nand the results demonstrate that CMIA consistently reduces prediction disparity\nwhile maintaining good accuracy and significantly outperforms the other\ncompeting methods across multiple datasets and survival models (e.g., linear\nCOX, deep AFT).",
      "tldr_zh": "这篇论文针对生存分析中的偏见问题，引入了equalized odds (EO)公平概念，以强调在预定义时间点的预测公平，从而填补现有方法的空白。作者提出Conditional Mutual Information Augmentation (CMIA)方法，该方法结合基于条件互信息的公平正则化项和创新的删失数据增强技术，适用于各种生存模型，并有效平衡预测准确性和公平性。在三个应用领域进行评估后，结果表明CMIA显著减少了预测差异，同时保持良好准确性，并在多个数据集和模型（如线性COX、深度AFT）上优于其他先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02567v1",
      "published_date": "2025-02-04 18:40:38 UTC",
      "updated_date": "2025-02-04 18:40:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:47:07.163251"
    },
    {
      "arxiv_id": "2502.02630v1",
      "title": "scBIT: Integrating Single-cell Transcriptomic Data into fMRI-based Prediction for Alzheimer's Disease Diagnosis",
      "title_zh": "scBIT：将单细胞转录组数据整合到基于fMRI的预测中用于阿尔茨海默病诊断",
      "authors": [
        "Yu-An Huang",
        "Yao Hu",
        "Yue-Chao Li",
        "Xiyue Cao",
        "Xinyuan Li",
        "Kay Chen Tan",
        "Zhu-Hong You",
        "Zhi-An Huang"
      ],
      "abstract": "Functional MRI (fMRI) and single-cell transcriptomics are pivotal in\nAlzheimer's disease (AD) research, each providing unique insights into neural\nfunction and molecular mechanisms. However, integrating these complementary\nmodalities remains largely unexplored. Here, we introduce scBIT, a novel method\nfor enhancing AD prediction by combining fMRI with single-nucleus RNA (snRNA).\nscBIT leverages snRNA as an auxiliary modality, significantly improving\nfMRI-based prediction models and providing comprehensive interpretability. It\nemploys a sampling strategy to segment snRNA data into cell-type-specific gene\nnetworks and utilizes a self-explainable graph neural network to extract\ncritical subgraphs. Additionally, we use demographic and genetic similarities\nto pair snRNA and fMRI data across individuals, enabling robust cross-modal\nlearning. Extensive experiments validate scBIT's effectiveness in revealing\nintricate brain region-gene associations and enhancing diagnostic prediction\naccuracy. By advancing brain imaging transcriptomics to the single-cell level,\nscBIT sheds new light on biomarker discovery in AD research. Experimental\nresults show that incorporating snRNA data into the scBIT model significantly\nboosts accuracy, improving binary classification by 3.39% and five-class\nclassification by 26.59%. The codes were implemented in Python and have been\nreleased on GitHub (https://github.com/77YQ77/scBIT) and Zenodo\n(https://zenodo.org/records/11599030) with detailed instructions.",
      "tldr_zh": "本研究提出 scBIT 方法，将单细胞转录组学（snRNA）整合到 fMRI 预测模型中，以提升阿尔茨海默病（AD）诊断的准确性和可解释性。scBIT 通过采样策略将 snRNA 数据分割成细胞类型特异性基因网络，并使用自解释图神经网络提取关键子图，同时基于人口统计和遗传相似性配对跨个体数据，实现稳健的跨模态学习。实验结果显示，该方法显著提高了诊断性能，二分类准确率提升 3.39%，五分类准确率提升 26.59%，并揭示了复杂的脑区-基因关联，为 AD 生物标志物发现提供了新见解。代码已在 GitHub 和 Zenodo 上开源。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "31 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02630v1",
      "published_date": "2025-02-04 18:37:46 UTC",
      "updated_date": "2025-02-04 18:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:47:17.413009"
    },
    {
      "arxiv_id": "2502.02562v1",
      "title": "Learning the RoPEs: Better 2D and 3D Position Encodings with STRING",
      "title_zh": "翻译失败",
      "authors": [
        "Connor Schenck",
        "Isaac Reid",
        "Mithun George Jacob",
        "Alex Bewley",
        "Joshua Ainslie",
        "David Rendleman",
        "Deepali Jain",
        "Mohit Sharma",
        "Avinava Dubey",
        "Ayzaan Wahid",
        "Sumeet Singh",
        "René Wagner",
        "Tianli Ding",
        "Chuyuan Fu",
        "Arunkumar Byravan",
        "Jake Varley",
        "Alexey Gritsenko",
        "Matthias Minderer",
        "Dmitry Kalashnikov",
        "Jonathan Tompson",
        "Vikas Sindhwani",
        "Krzysztof Choromanski"
      ],
      "abstract": "We introduce STRING: Separable Translationally Invariant Position Encodings.\nSTRING extends Rotary Position Encodings, a recently proposed and widely used\nalgorithm in large language models, via a unifying theoretical framework.\nImportantly, STRING still provides exact translation invariance, including\ntoken coordinates of arbitrary dimensionality, whilst maintaining a low\ncomputational footprint. These properties are especially important in robotics,\nwhere efficient 3D token representation is key. We integrate STRING into Vision\nTransformers with RGB(-D) inputs (color plus optional depth), showing\nsubstantial gains, e.g. in open-vocabulary object detection and for robotics\ncontrollers. We complement our experiments with a rigorous mathematical\nanalysis, proving the universality of our methods.",
      "tldr_zh": "我们引入了 STRING（Separable Translationally Invariant Position Encodings），这是一种扩展 Rotary Position Encodings 的位置编码方法，通过统一的理论框架实现精确的平移不变性，支持任意维度的标记坐标，同时保持低计算开销。STRING 的这些特性在机器人领域尤为重要，因为它能高效处理 3D 标记表示。我们将 STRING 整合到 Vision Transformers 中，使用 RGB(-D) 输入，取得了显著改进，例如在开放词汇对象检测和机器人控制器中的性能提升。最终，通过严格的数学分析，我们证明了该方法的通用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Videos of STRING-based robotics controllers can be found here:\n  https://sites.google.com/view/string-robotics",
      "pdf_url": "http://arxiv.org/pdf/2502.02562v1",
      "published_date": "2025-02-04 18:37:17 UTC",
      "updated_date": "2025-02-04 18:37:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:47:29.472746"
    },
    {
      "arxiv_id": "2502.02561v1",
      "title": "Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents",
      "title_zh": "Conformal Prediction 的决策理论基础：针对风险厌恶代理的最优不确定性量化",
      "authors": [
        "Shayan Kiyani",
        "George Pappas",
        "Aaron Roth",
        "Hamed Hassani"
      ],
      "abstract": "A fundamental question in data-driven decision making is how to quantify the\nuncertainty of predictions in ways that can usefully inform downstream action.\nThis interface between prediction uncertainty and decision-making is especially\nimportant in risk-sensitive domains, such as medicine. In this paper, we\ndevelop decision-theoretic foundations that connect uncertainty quantification\nusing prediction sets with risk-averse decision-making. Specifically, we answer\nthree fundamental questions: (1) What is the correct notion of uncertainty\nquantification for risk-averse decision makers? We prove that prediction sets\nare optimal for decision makers who wish to optimize their value at risk. (2)\nWhat is the optimal policy that a risk averse decision maker should use to map\nprediction sets to actions? We show that a simple max-min decision policy is\noptimal for risk-averse decision makers. Finally, (3) How can we derive\nprediction sets that are optimal for such decision makers? We provide an exact\ncharacterization in the population regime and a distribution free finite-sample\nconstruction. Answering these questions naturally leads to an algorithm,\nRisk-Averse Calibration (RAC), which follows a provably optimal design for\nderiving action policies from predictions. RAC is designed to be both\npractical-capable of leveraging the quality of predictions in a black-box\nmanner to enhance downstream utility-and safe-adhering to a user-defined risk\nthreshold and optimizing the corresponding risk quantile of the user's\ndownstream utility. Finally, we experimentally demonstrate the significant\nadvantages of RAC in applications such as medical diagnosis and recommendation\nsystems. Specifically, we show that RAC achieves a substantially improved\ntrade-off between safety and utility, offering higher utility compared to\nexisting methods while maintaining the safety guarantee.",
      "tldr_zh": "本论文建立了决策理论基础，将预测集（Prediction Sets）的不确定性量化与风险厌恶代理（Risk-Averse Agents）的决策相结合，针对风险敏感领域如医疗提供优化框架。具体来说，它证明了预测集可优化价值风险（Value at Risk），并推荐了简单的最大最小决策策略（Max-Min Decision Policy）作为风险厌恶决策者的最佳行动映射方法。此外，论文提供了预测集的精确表征和无分布有限样本构造，并引入了风险厌恶校准算法（Risk-Averse Calibration, RAC），该算法在黑箱预测基础上提升下游效用，同时遵守用户定义的风险阈值。实验结果显示，在医疗诊断和推荐系统中，RAC 实现了显著的安全性与效用权衡，比现有方法提供更高效用并保持安全保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02561v1",
      "published_date": "2025-02-04 18:37:10 UTC",
      "updated_date": "2025-02-04 18:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:47:41.986123"
    },
    {
      "arxiv_id": "2502.02629v1",
      "title": "Graph Structure Learning for Tumor Microenvironment with Cell Type Annotation from non-spatial scRNA-seq data",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-An Huang",
        "Yue-Chao Li",
        "Hai-Ru You",
        "Jie Pan",
        "Xiyue Cao",
        "Xinyuan Li",
        "Zhi-An Huang",
        "Zhu-Hong You"
      ],
      "abstract": "The exploration of cellular heterogeneity within the tumor microenvironment\n(TME) via single-cell RNA sequencing (scRNA-seq) is essential for understanding\ncancer progression and response to therapy. Current scRNA-seq approaches,\nhowever, lack spatial context and rely on incomplete datasets of\nligand-receptor interactions (LRIs), limiting accurate cell type annotation and\ncell-cell communication (CCC) inference. This study addresses these challenges\nusing a novel graph neural network (GNN) model that enhances cell type\nprediction and cell interaction analysis. Our study utilized a dataset\nconsisting of 49,020 cells from 19 patients across three cancer types:\nLeukemia, Breast Invasive Carcinoma, and Colorectal Cancer. The proposed scGSL\nmodel demonstrated robust performance, achieving an average accuracy of 84.83%,\nprecision of 86.23%, recall of 81.51%, and an F1 score of 80.92% across all\ndatasets. These metrics represent a significant enhancement over existing\nmethods, which typically exhibit lower performance metrics. Additionally, by\nreviewing existing literature on gene interactions within the TME, the scGSL\nmodel proves to robustly identify biologically meaningful gene interactions in\nan unsupervised manner, validated by significant expression differences in key\ngene pairs across various cancers. The source code and data used in this paper\ncan be found in https://github.com/LiYuechao1998/scGSL.",
      "tldr_zh": "本研究针对单细胞 RNA 测序 (scRNA-seq) 在肿瘤微环境 (TME) 中的局限性，如缺乏空间上下文和不完整的配体-受体相互作用 (LRIs)，提出了一种基于图神经网络 (GNN) 的 scGSL 模型，用于提升细胞类型注释和细胞间通信 (CCC) 分析。scGSL 通过图结构学习从非空间 scRNA-seq 数据中预测细胞类型，并分析细胞交互，利用了来自 19 名患者的 49,020 个细胞数据，涵盖白血病、乳腺浸润癌和结肠癌。实验结果显示，该模型平均准确率达 84.83%、精确率 86.23%、召回率 81.51% 和 F1 分数 80.92%，显著优于现有方法；此外，它能无监督地识别生物学上有意义的基因交互，并通过关键基因对的表达差异进行验证。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "29 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02629v1",
      "published_date": "2025-02-04 18:28:25 UTC",
      "updated_date": "2025-02-04 18:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:47:54.256306"
    },
    {
      "arxiv_id": "2502.02549v1",
      "title": "Anytime Incremental $ρ$POMDP Planning in Continuous Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Ron Benchetrit",
        "Idan Lev-Yehudi",
        "Andrey Zhitnikov",
        "Vadim Indelman"
      ],
      "abstract": "Partially Observable Markov Decision Processes (POMDPs) provide a robust\nframework for decision-making under uncertainty in applications such as\nautonomous driving and robotic exploration. Their extension, $\\rho$POMDPs,\nintroduces belief-dependent rewards, enabling explicit reasoning about\nuncertainty. Existing online $\\rho$POMDP solvers for continuous spaces rely on\nfixed belief representations, limiting adaptability and refinement - critical\nfor tasks such as information-gathering. We present $\\rho$POMCPOW, an anytime\nsolver that dynamically refines belief representations, with formal guarantees\nof improvement over time. To mitigate the high computational cost of updating\nbelief-dependent rewards, we propose a novel incremental computation approach.\nWe demonstrate its effectiveness for common entropy estimators, reducing\ncomputational cost by orders of magnitude. Experimental results show that\n$\\rho$POMCPOW outperforms state-of-the-art solvers in both efficiency and\nsolution quality.",
      "tldr_zh": "这篇论文针对连续空间中的部分可观测马尔可夫决策过程($ρ$POMDPs)规划问题，提出了一种 anytime 求解器 $ρ$POMCPOW，能够动态细化信念表示并提供正式的改进保证，以提升不确定性决策的适应性。论文引入新型增量计算方法来减轻更新信念依赖奖励的高计算成本，尤其对常见熵估计器实现了几个数量级的效率提升。实验结果显示，$ρ$POMCPOW 在效率和解决方案质量上优于现有最先进求解器，为应用如自动驾驶和机器人探索提供了更有效的框架。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02549v1",
      "published_date": "2025-02-04 18:19:40 UTC",
      "updated_date": "2025-02-04 18:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:48:06.070766"
    },
    {
      "arxiv_id": "2502.02544v1",
      "title": "Addressing Label Shift in Distributed Learning via Entropy Regularization",
      "title_zh": "通过熵正则化处理分布式学习中的标签偏移",
      "authors": [
        "Zhiyuan Wu",
        "Changkyu Choi",
        "Xiangcheng Cao",
        "Volkan Cevher",
        "Ali Ramezani-Kebrya"
      ],
      "abstract": "We address the challenge of minimizing true risk in multi-node distributed\nlearning. These systems are frequently exposed to both inter-node and\nintra-node label shifts, which present a critical obstacle to effectively\noptimizing model performance while ensuring that data remains confined to each\nnode. To tackle this, we propose the Versatile Robust Label Shift (VRLS)\nmethod, which enhances the maximum likelihood estimation of the test-to-train\nlabel density ratio. VRLS incorporates Shannon entropy-based regularization and\nadjusts the density ratio during training to better handle label shifts at the\ntest time. In multi-node learning environments, VRLS further extends its\ncapabilities by learning and adapting density ratios across nodes, effectively\nmitigating label shifts and improving overall model performance. Experiments\nconducted on MNIST, Fashion MNIST, and CIFAR-10 demonstrate the effectiveness\nof VRLS, outperforming baselines by up to 20% in imbalanced settings. These\nresults highlight the significant improvements VRLS offers in addressing label\nshifts. Our theoretical analysis further supports this by establishing\nhigh-probability bounds on estimation errors.",
      "tldr_zh": "本文探讨了分布式学习中标签偏移(label shift)问题，提出了一种名为Versatile Robust Label Shift (VRLS)的方法，通过Shannon entropy-based regularization增强测试到训练标签密度比的估计，并在训练过程中调整密度比以适应多节点环境的inter-node和intra-node偏移。VRLS在多节点设置中学习跨节点密度比，从而缓解标签偏移并提升模型性能。实验在MNIST、Fashion MNIST和CIFAR-10数据集上显示，VRLS在不平衡场景下比基线模型性能提升高达20%。理论分析进一步提供了高概率的估计错误边界，支持了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the International Conference on Learning Representations\n  (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.02544v1",
      "published_date": "2025-02-04 18:14:27 UTC",
      "updated_date": "2025-02-04 18:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:48:18.060973"
    },
    {
      "arxiv_id": "2502.04353v1",
      "title": "CognArtive: Large Language Models for Automating Art Analysis and Decoding Aesthetic Elements",
      "title_zh": "翻译失败",
      "authors": [
        "Afshin Khadangi",
        "Amir Sartipi",
        "Igor Tchappi",
        "Gilbert Fridgen"
      ],
      "abstract": "Art, as a universal language, can be interpreted in diverse ways, with\nartworks embodying profound meanings and nuances. The advent of Large Language\nModels (LLMs) and the availability of Multimodal Large Language Models (MLLMs)\nraise the question of how these transformative models can be used to assess and\ninterpret the artistic elements of artworks. While research has been conducted\nin this domain, to the best of our knowledge, a deep and detailed understanding\nof the technical and expressive features of artworks using LLMs has not been\nexplored. In this study, we investigate the automation of a formal art analysis\nframework to analyze a high-throughput number of artworks rapidly and examine\nhow their patterns evolve over time. We explore how LLMs can decode artistic\nexpressions, visual elements, composition, and techniques, revealing emerging\npatterns that develop across periods. Finally, we discuss the strengths and\nlimitations of LLMs in this context, emphasizing their ability to process vast\nquantities of art-related data and generate insightful interpretations. Due to\nthe exhaustive and granular nature of the results, we have developed\ninteractive data visualizations, available online\nhttps://cognartive.github.io/, to enhance understanding and accessibility.",
      "tldr_zh": "本研究提出CognArtive系统，利用Large Language Models (LLMs)和Multimodal Large Language Models (MLLMs)自动化艺术分析框架，以快速处理大量艺术品并揭示其模式随时间演变。研究重点探索LLMs如何解码艺术表达、视觉元素、构图和技术，识别跨时期的发展趋势，同时讨论了LLMs在处理海量艺术数据和生成洞见方面的优势与局限性。通过开发交互式数据可视化工具（可访问https://cognartive.github.io/），该系统提升了艺术分析的可访问性和理解深度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04353v1",
      "published_date": "2025-02-04 18:08:23 UTC",
      "updated_date": "2025-02-04 18:08:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:48:28.978203"
    },
    {
      "arxiv_id": "2502.02538v1",
      "title": "Flow Q-Learning",
      "title_zh": "Flow Q学习",
      "authors": [
        "Seohong Park",
        "Qiyang Li",
        "Sergey Levine"
      ],
      "abstract": "We present flow Q-learning (FQL), a simple and performant offline\nreinforcement learning (RL) method that leverages an expressive flow-matching\npolicy to model arbitrarily complex action distributions in data. Training a\nflow policy with RL is a tricky problem, due to the iterative nature of the\naction generation process. We address this challenge by training an expressive\none-step policy with RL, rather than directly guiding an iterative flow policy\nto maximize values. This way, we can completely avoid unstable recursive\nbackpropagation, eliminate costly iterative action generation at test time, yet\nstill mostly maintain expressivity. We experimentally show that FQL leads to\nstrong performance across 73 challenging state- and pixel-based OGBench and\nD4RL tasks in offline RL and offline-to-online RL. Project page:\nhttps://seohong.me/projects/fql/",
      "tldr_zh": "我们提出了Flow Q-Learning (FQL)，一种简单高效的离线强化学习 (RL) 方法，利用flow-matching policy来建模数据中任意复杂的动作分布，从而提升RL的表现。不同于直接训练迭代流策略，FQL通过训练一个表达性强的单步策略来最大化值，避免了不稳定的递归反向传播和测试时的昂贵迭代动作生成，同时保留了大部分表达性。在实验中，FQL在73个具有挑战性的状态和像素为基础的OGBench和D4RL任务中，展现出强大的性能，适用于离线RL和离线到在线RL场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02538v1",
      "published_date": "2025-02-04 18:04:05 UTC",
      "updated_date": "2025-02-04 18:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:48:41.745127"
    },
    {
      "arxiv_id": "2502.02533v1",
      "title": "Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies",
      "title_zh": "多智能体设计：通过更好的提示和拓扑优化智能体",
      "authors": [
        "Han Zhou",
        "Xingchen Wan",
        "Ruoxi Sun",
        "Hamid Palangi",
        "Shariq Iqbal",
        "Ivan Vulić",
        "Anna Korhonen",
        "Sercan Ö. Arık"
      ],
      "abstract": "Large language models, employed as multiple agents that interact and\ncollaborate with each other, have excelled at solving complex tasks. The agents\nare programmed with prompts that declare their functionality, along with the\ntopologies that orchestrate interactions across agents. Designing prompts and\ntopologies for multi-agent systems (MAS) is inherently complex. To automate the\nentire design process, we first conduct an in-depth analysis of the design\nspace aiming to understand the factors behind building effective MAS. We reveal\nthat prompts together with topologies play critical roles in enabling more\neffective MAS design. Based on the insights, we propose Multi-Agent System\nSearch (MASS), a MAS optimization framework that efficiently exploits the\ncomplex MAS design space by interleaving its optimization stages, from local to\nglobal, from prompts to topologies, over three stages: 1) block-level (local)\nprompt optimization; 2) workflow topology optimization; 3) workflow-level\n(global) prompt optimization, where each stage is conditioned on the\niteratively optimized prompts/topologies from former stages. We show that\nMASS-optimized multi-agent systems outperform a spectrum of existing\nalternatives by a substantial margin. Based on the MASS-found systems, we\nfinally propose design principles behind building effective multi-agent\nsystems.",
      "tldr_zh": "该研究分析了多代理系统(MAS)中提示(prompts)和拓扑(topologies)的设计因素，发现它们对系统效能至关重要。作者提出Multi-Agent System Search (MASS)框架，通过三个交错优化阶段——块级(本地)提示优化、工作流拓扑优化以及工作流级(全局)提示优化——来自动高效地探索复杂设计空间。实验结果显示，MASS优化的多代理系统显著优于现有方法，并基于此总结出构建有效MAS的设计原则。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures, 1 table (30 pages, 9 figures, 5 tables including\n  references and appendices)",
      "pdf_url": "http://arxiv.org/pdf/2502.02533v1",
      "published_date": "2025-02-04 17:56:44 UTC",
      "updated_date": "2025-02-04 17:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:48:53.033527"
    },
    {
      "arxiv_id": "2502.02528v1",
      "title": "Why human-AI relationships need socioaffective alignment",
      "title_zh": "为什么人类-AI 关系需要社会情感对齐",
      "authors": [
        "Hannah Rose Kirk",
        "Iason Gabriel",
        "Chris Summerfield",
        "Bertie Vidgen",
        "Scott A. Hale"
      ],
      "abstract": "Humans strive to design safe AI systems that align with our goals and remain\nunder our control. However, as AI capabilities advance, we face a new\nchallenge: the emergence of deeper, more persistent relationships between\nhumans and AI systems. We explore how increasingly capable AI agents may\ngenerate the perception of deeper relationships with users, especially as AI\nbecomes more personalised and agentic. This shift, from transactional\ninteraction to ongoing sustained social engagement with AI, necessitates a new\nfocus on socioaffective alignment-how an AI system behaves within the social\nand psychological ecosystem co-created with its user, where preferences and\nperceptions evolve through mutual influence. Addressing these dynamics involves\nresolving key intrapersonal dilemmas, including balancing immediate versus\nlong-term well-being, protecting autonomy, and managing AI companionship\nalongside the desire to preserve human social bonds. By framing these\nchallenges through a notion of basic psychological needs, we seek AI systems\nthat support, rather than exploit, our fundamental nature as social and\nemotional beings.",
      "tldr_zh": "本论文探讨了随着AI能力提升，人类-AI关系可能演变为更深层、持久的互动，为什么需要关注socioaffective alignment，即AI在与用户共同构建的社会和心理生态中的行为方式。作者分析了从交易式互动向持续社会参与的转变，强调解决关键内在冲突，如平衡即时与长期福祉、保护自主性，以及管理AI陪伴与维护人类社会联系。最终，通过basic psychological needs的框架，论文主张设计支持人类作为社会和情感生物本质的AI系统，以确保AI促进而非利用我们的福祉。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02528v1",
      "published_date": "2025-02-04 17:50:08 UTC",
      "updated_date": "2025-02-04 17:50:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:49:05.523748"
    },
    {
      "arxiv_id": "2502.02516v1",
      "title": "Adaptive Exploration for Multi-Reward Multi-Policy Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Alessio Russo",
        "Aldo Pacchiano"
      ],
      "abstract": "We study the policy evaluation problem in an online multi-reward multi-policy\ndiscounted setting, where multiple reward functions must be evaluated\nsimultaneously for different policies. We adopt an $(\\epsilon,\\delta)$-PAC\nperspective to achieve $\\epsilon$-accurate estimates with high confidence\nacross finite or convex sets of rewards, a setting that has not been\ninvestigated in the literature. Building on prior work on Multi-Reward Best\nPolicy Identification, we adapt the MR-NaS exploration scheme to jointly\nminimize sample complexity for evaluating different policies across different\nreward sets. Our approach leverages an instance-specific lower bound revealing\nhow the sample complexity scales with a measure of value deviation, guiding the\ndesign of an efficient exploration policy. Although computing this bound\nentails a hard non-convex optimization, we propose an efficient convex\napproximation that holds for both finite and convex reward sets. Experiments in\ntabular domains demonstrate the effectiveness of this adaptive exploration\nscheme.",
      "tldr_zh": "本文研究了在线多奖励多策略折扣设置下的策略评估问题，旨在通过（ε, δ）-PAC 框架实现高置信度的ε-准确估计，适用于有限或凸奖励集。作者基于Multi-Reward Best Policy Identification的工作，适应了MR-NaS探索方案，并引入了基于价值偏差的实例特定下界来最小化样本复杂度，同时提出一个有效的凸逼近来处理非凸优化挑战。实验在表格域中证明了该自适应探索方法的有效性，展示了其在降低样本复杂度方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02516v1",
      "published_date": "2025-02-04 17:35:51 UTC",
      "updated_date": "2025-02-04 17:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:49:17.610931"
    },
    {
      "arxiv_id": "2502.02508v1",
      "title": "Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search",
      "title_zh": "翻译失败",
      "authors": [
        "Maohao Shen",
        "Guangtao Zeng",
        "Zhenting Qi",
        "Zhang-Wei Hong",
        "Zhenfang Chen",
        "Wei Lu",
        "Gregory Wornell",
        "Subhro Das",
        "David Cox",
        "Chuang Gan"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities across diverse domains. Recent studies have shown that increasing\ntest-time computation enhances LLMs' reasoning capabilities. This typically\ninvolves extensive sampling at inference time guided by an external LLM\nverifier, resulting in a two-player system. Despite external guidance, the\neffectiveness of this system demonstrates the potential of a single LLM to\ntackle complex tasks. Thus, we pose a new research problem: Can we internalize\nthe searching capabilities to fundamentally enhance the reasoning abilities of\na single LLM? This work explores an orthogonal direction focusing on\npost-training LLMs for autoregressive searching (i.e., an extended reasoning\nprocess with self-reflection and self-exploration of new strategies). To\nachieve this, we propose the Chain-of-Action-Thought (COAT) reasoning and a\ntwo-stage training paradigm: 1) a small-scale format tuning stage to\ninternalize the COAT reasoning format and 2) a large-scale self-improvement\nstage leveraging reinforcement learning. Our approach results in Satori, a 7B\nLLM trained on open-source models and data. Extensive empirical evaluations\ndemonstrate that Satori achieves state-of-the-art performance on mathematical\nreasoning benchmarks while exhibits strong generalization to out-of-domain\ntasks. Code, data, and models will be fully open-sourced.",
      "tldr_zh": "该研究探讨如何通过内部化搜索能力来增强单个大语言模型(LLMs)的推理性能，提出Chain-of-Action-Thought (COAT)推理方法，该方法结合自回归搜索实现自我反思和策略探索。作者采用两阶段训练范式：首先进行小规模格式调整以内化COAT格式，其次利用强化学习进行大规模自我改进，开发出Satori，一个基于开源模型和数据的7B LLM。实验结果表明，Satori在数学推理基准上达到最先进水平，并展现出对领域外任务的强泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02508v1",
      "published_date": "2025-02-04 17:26:58 UTC",
      "updated_date": "2025-02-04 17:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:49:30.494636"
    },
    {
      "arxiv_id": "2502.02504v1",
      "title": "Unified Spatial-Temporal Edge-Enhanced Graph Networks for Pedestrian Trajectory Prediction",
      "title_zh": "统一的时空边增强图网络用于行人轨迹预测",
      "authors": [
        "Ruochen Li",
        "Tanqiu Qiao",
        "Stamos Katsigiannis",
        "Zhanxing Zhu",
        "Hubert P. H. Shum"
      ],
      "abstract": "Pedestrian trajectory prediction aims to forecast future movements based on\nhistorical paths. Spatial-temporal (ST) methods often separately model spatial\ninteractions among pedestrians and temporal dependencies of individuals. They\noverlook the direct impacts of interactions among different pedestrians across\nvarious time steps (i.e., high-order cross-time interactions). This limits\ntheir ability to capture ST inter-dependencies and hinders prediction\nperformance. To address these limitations, we propose UniEdge with three major\ndesigns. Firstly, we introduce a unified ST graph data structure that\nsimplifies high-order cross-time interactions into first-order relationships,\nenabling the learning of ST inter-dependencies in a single step. This avoids\nthe information loss caused by multi-step aggregation. Secondly, traditional\nGNNs focus on aggregating pedestrian node features, neglecting the propagation\nof implicit interaction patterns encoded in edge features. We propose the\nEdge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN), a novel dual-graph\nnetwork that jointly models explicit N2N social interactions among pedestrians\nand implicit E2E influence propagation across these interaction patterns.\nFinally, to overcome the limited receptive fields and challenges in capturing\nlong-range dependencies of auto-regressive architectures, we introduce a\ntransformer encoder-based predictor that enables global modeling of temporal\ncorrelation. UniEdge outperforms state-of-the-arts on multiple datasets,\nincluding ETH, UCY, and SDD.",
      "tldr_zh": "本研究针对行人轨迹预测中的问题，提出Unified Spatial-Temporal Edge-Enhanced Graph Networks（UniEdge）框架，以解决现有方法忽略高阶跨时间交互（high-order cross-time interactions）的局限，从而更好地捕捉空间-时间（ST）互依赖。UniEdge的关键创新包括：统一ST图数据结构简化交互为第一阶关系、Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN) 双图网络联合建模显式行人社会交互和隐式影响传播，以及Transformer编码器-based预测器实现全局时间相关性建模。实验结果显示，UniEdge在ETH、UCY和SDD数据集上超越了最先进方法，提升了预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02504v1",
      "published_date": "2025-02-04 17:18:54 UTC",
      "updated_date": "2025-02-04 17:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:49:41.925090"
    },
    {
      "arxiv_id": "2502.04352v1",
      "title": "Investigating the Robustness of Deductive Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Hoppe",
        "Filip Ilievski",
        "Jan-Christoph Kalo"
      ],
      "abstract": "Large Language Models (LLMs) have been shown to achieve impressive results\nfor many reasoning-based Natural Language Processing (NLP) tasks, suggesting a\ndegree of deductive reasoning capability. However, it remains unclear to which\nextent LLMs, in both informal and autoformalisation methods, are robust on\nlogical deduction tasks. Moreover, while many LLM-based deduction methods have\nbeen proposed, there is a lack of a systematic study that analyses the impact\nof their design components. Addressing these two challenges, we propose the\nfirst study of the robustness of LLM-based deductive reasoning methods. We\ndevise a framework with two families of perturbations: adversarial noise and\ncounterfactual statements, which jointly generate seven perturbed datasets. We\norganize the landscape of LLM reasoners according to their reasoning format,\nformalisation syntax, and feedback for error recovery. The results show that\nadversarial noise affects autoformalisation, while counterfactual statements\ninfluence all approaches. Detailed feedback does not improve overall accuracy\ndespite reducing syntax errors, pointing to the challenge of LLM-based methods\nto self-correct effectively.",
      "tldr_zh": "本研究调查了 Large Language Models (LLMs) 在演绎推理任务上的鲁棒性，首次系统分析了非正式和 autoformalisation 方法的性能及其设计组件的影响。\n研究者提出一个框架，使用 adversarial noise 和 counterfactual statements 两种扰动生成七个数据集，并根据推理格式、形式化语法和错误恢复反馈组织 LLM 推理器。\n结果表明，adversarial noise 主要影响 autoformalisation 方法，而 counterfactual statements 会影响所有方法；尽管提供详细反馈能减少语法错误，但整体准确率未见显著提升，暴露了 LLM 在自我修正方面的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04352v1",
      "published_date": "2025-02-04 17:16:51 UTC",
      "updated_date": "2025-02-04 17:16:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:49:54.082811"
    },
    {
      "arxiv_id": "2502.05214v2",
      "title": "CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models",
      "title_zh": "CoRPA：使用概念向量扰动和生成模型的胸部X光片对抗图像生成",
      "authors": [
        "Amy Rafferty",
        "Rishi Ramaesh",
        "Ajitha Rajan"
      ],
      "abstract": "Deep learning models for medical image classification tasks are becoming\nwidely implemented in AI-assisted diagnostic tools, aiming to enhance\ndiagnostic accuracy, reduce clinician workloads, and improve patient outcomes.\nHowever, their vulnerability to adversarial attacks poses significant risks to\npatient safety. Current attack methodologies use general techniques such as\nmodel querying or pixel value perturbations to generate adversarial examples\ndesigned to fool a model. These approaches may not adequately address the\nunique characteristics of clinical errors stemming from missed or incorrectly\nidentified clinical features. We propose the Concept-based Report Perturbation\nAttack (CoRPA), a clinically-focused black-box adversarial attack framework\ntailored to the medical imaging domain. CoRPA leverages clinical concepts to\ngenerate adversarial radiological reports and images that closely mirror\nrealistic clinical misdiagnosis scenarios. We demonstrate the utility of CoRPA\nusing the MIMIC-CXR-JPG dataset of chest X-rays and radiological reports. Our\nevaluation reveals that deep learning models exhibiting strong resilience to\nconventional adversarial attacks are significantly less robust when subjected\nto CoRPA's clinically-focused perturbations. This underscores the importance of\naddressing domain-specific vulnerabilities in medical AI systems. By\nintroducing a specialized adversarial attack framework, this study provides a\nfoundation for developing robust, real-world-ready AI models in healthcare,\nensuring their safe and reliable deployment in high-stakes clinical\nenvironments.",
      "tldr_zh": "本文提出CoRPA框架，这是一种针对医疗图像的黑盒adversarial attack方法，通过clinical concepts和vector perturbations结合生成模型，生成逼真的胸部X光图像和放射学报告，以模拟真实临床误诊场景。利用MIMIC-CXR-JPG数据集进行评估，结果显示，原本对传统adversarial attacks有较强抵抗力的深度学习模型，在CoRPA的clinically-focused perturbations下显著降低鲁棒性。研究强调了处理医疗AI领域的领域特定漏洞的必要性，为开发更可靠的临床AI系统提供了基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05214v2",
      "published_date": "2025-02-04 17:14:31 UTC",
      "updated_date": "2025-03-28 15:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:50:06.730774"
    },
    {
      "arxiv_id": "2502.02495v3",
      "title": "The Causal-Effect Score in Data Management",
      "title_zh": "翻译失败",
      "authors": [
        "Felipe Azua",
        "Leopoldo Bertossi"
      ],
      "abstract": "The Causal Effect (CE) is a numerical measure of causal influence of\nvariables on observed results. Despite being widely used in many areas, only\npreliminary attempts have been made to use CE as an attribution score in data\nmanagement, to measure the causal strength of tuples for query answering in\ndatabases. In this work, we introduce, generalize and investigate the so-called\nCausal-Effect Score in the context of classical and probabilistic databases.",
      "tldr_zh": "这篇论文引入并推广了Causal-Effect Score（CE分数），一种用于衡量变量对观察结果因果影响的数值指标，将其应用于数据管理领域，以评估元组（tuples）在查询回答（query answering）中的因果强度。作者在经典数据库和概率数据库的背景下，对CE分数进行了泛化和深入调查。研究旨在填补CE在数据管理中的应用空白，为更精确的因果归因（attribution score）提供新框架。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "To appear in Proceedings of the 4th Conference on Causal Learning and\n  Reasoning, 2025. This is the camera-ready version, and included a couple of\n  new references",
      "pdf_url": "http://arxiv.org/pdf/2502.02495v3",
      "published_date": "2025-02-04 17:12:23 UTC",
      "updated_date": "2025-02-28 00:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:50:17.083625"
    },
    {
      "arxiv_id": "2502.02489v1",
      "title": "A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Ellis",
        "Andrew Bulpitt",
        "Nasim Parsa",
        "Michael F Byrne",
        "Sharib Ali"
      ],
      "abstract": "Ultrasound (US) imaging is clinically invaluable due to its noninvasive and\nsafe nature. However, interpreting US images is challenging, requires\nsignificant expertise, and time, and is often prone to errors. Deep learning\noffers assistive solutions such as segmentation. Supervised methods rely on\nlarge, high-quality, and consistently labeled datasets, which are challenging\nto curate. Moreover, these methods tend to underperform on out-of-distribution\ndata, limiting their clinical utility. Self-supervised learning (SSL) has\nemerged as a promising alternative, leveraging unlabeled data to enhance model\nperformance and generalisability. We introduce a contrastive SSL approach\ntailored for B-mode US images, incorporating a novel Relation Contrastive Loss\n(RCL). RCL encourages learning of distinct features by differentiating positive\nand negative sample pairs through a learnable metric. Additionally, we propose\nspatial and frequency-based augmentation strategies for the representation\nlearning on US images. Our approach significantly outperforms traditional\nsupervised segmentation methods across three public breast US datasets,\nparticularly in data-limited scenarios. Notable improvements on the Dice\nsimilarity metric include a 4% increase on 20% and 50% of the BUSI dataset,\nnearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4%\nand 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively.\nFurthermore, we demonstrate superior generalisability on the\nout-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6%\ncompared to the supervised baseline using 20% and 50% of the BUSI and BrEaST\ntraining data, respectively. Our research highlights that domain-inspired SSL\ncan improve US segmentation, especially under data-limited conditions.",
      "tldr_zh": "本研究针对超声（US）B-mode 图像分割的挑战，提出一个自监督学习（SSL）框架，以提升模型的泛化性和在数据有限场景下的性能。该框架引入了新型 Relation Contrastive Loss (RCL)，通过可学习的度量区分正负样本对，并结合空间和频率-based 增强策略，鼓励学习独特特征。实验结果显示，该方法在三个公共乳腺 US 数据集（BUSI、BrEaST 和 UDIAT）上显著优于传统监督分割方法，Dice 相似度指标改善了4%至9%，并在分布外数据上实现了高达20.6%的性能提升。该框架证明了领域灵感的 SSL 在数据有限条件下改善 US 图像分割的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12",
      "pdf_url": "http://arxiv.org/pdf/2502.02489v1",
      "published_date": "2025-02-04 17:06:41 UTC",
      "updated_date": "2025-02-04 17:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:50:32.108290"
    },
    {
      "arxiv_id": "2502.04351v1",
      "title": "NER4all or Context is All You Need: Using LLMs for low-effort, high-performance NER on historical texts. A humanities informed approach",
      "title_zh": "翻译失败",
      "authors": [
        "Torsten Hiltmann",
        "Martin Dröge",
        "Nicole Dresselhaus",
        "Till Grallert",
        "Melanie Althage",
        "Paul Bayer",
        "Sophie Eckenstaler",
        "Koray Mendi",
        "Jascha Marijn Schmitz",
        "Philipp Schneider",
        "Wiebke Sczeponik",
        "Anica Skibba"
      ],
      "abstract": "Named entity recognition (NER) is a core task for historical research in\nautomatically establishing all references to people, places, events and the\nlike. Yet, do to the high linguistic and genre diversity of sources, only\nlimited canonisation of spellings, the level of required historical domain\nknowledge, and the scarcity of annotated training data, established approaches\nto natural language processing (NLP) have been both extremely expensive and\nyielded only unsatisfactory results in terms of recall and precision. Our paper\nintroduces a new approach. We demonstrate how readily-available,\nstate-of-the-art LLMs significantly outperform two leading NLP frameworks,\nspaCy and flair, for NER in historical documents by seven to twentytwo percent\nhigher F1-Scores. Our ablation study shows how providing historical context to\nthe task and a bit of persona modelling that turns focus away from a purely\nlinguistic approach are core to a successful prompting strategy. We also\ndemonstrate that, contrary to our expectations, providing increasing numbers of\nexamples in few-shot approaches does not improve recall or precision below a\nthreshold of 16-shot. In consequence, our approach democratises access to NER\nfor all historians by removing the barrier of scripting languages and\ncomputational skills required for established NLP tools and instead leveraging\nnatural language prompts and consumer-grade tools and frontends.",
      "tldr_zh": "该论文提出了一种基于大型语言模型(LLMs)的低成本高性能方法，用于历史文本的命名实体识别(NER)，通过提供历史上下文和角色建模的提示策略，显著提升了任务效果。相比spaCy和flair框架，该方法在F1-Scores上提高了7%至22%，并通过消融研究发现，提供超过16个示例的少样本学习并不会进一步改善召回率或精确率。这种人文导向的方法降低了NER的使用门槛，使历史学家无需编程技能，仅凭自然语言提示和消费级工具即可实现高效分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04351v1",
      "published_date": "2025-02-04 16:54:23 UTC",
      "updated_date": "2025-02-04 16:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:50:42.895895"
    },
    {
      "arxiv_id": "2502.02471v1",
      "title": "Mind the Gap: Evaluating Patch Embeddings from General-Purpose and Histopathology Foundation Models for Cell Segmentation and Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Valentina Vadori",
        "Antonella Peruffo",
        "Jean-Marie Graïc",
        "Livio Finos",
        "Enrico Grisan"
      ],
      "abstract": "Recent advancements in foundation models have transformed computer vision,\ndriving significant performance improvements across diverse domains, including\ndigital histopathology. However, the advantages of domain-specific\nhistopathology foundation models over general-purpose models for specialized\ntasks such as cell analysis remain underexplored. This study investigates the\nrepresentation learning gap between these two categories by analyzing\nmulti-level patch embeddings applied to cell instance segmentation and\nclassification. We implement an encoder-decoder architecture with a consistent\ndecoder and various encoders. These include convolutional, vision transformer\n(ViT), and hybrid encoders pre-trained on ImageNet-22K or LVD-142M,\nrepresenting general-purpose foundation models. These are compared against ViT\nencoders from the recently released UNI, Virchow2, and Prov-GigaPath foundation\nmodels, trained on patches extracted from hundreds of thousands of\nhistopathology whole-slide images. The decoder integrates patch embeddings from\ndifferent encoder depths via skip connections to generate semantic and distance\nmaps. These maps are then post-processed to create instance segmentation masks\nwhere each label corresponds to an individual cell and to perform cell-type\nclassification. All encoders remain frozen during training to assess their\npre-trained feature extraction capabilities. Using the PanNuke and CoNIC\nhistopathology datasets, and the newly introduced Nissl-stained CytoDArk0\ndataset for brain cytoarchitecture studies, we evaluate instance-level\ndetection, segmentation accuracy, and cell-type classification. This study\nprovides insights into the comparative strengths and limitations of\ngeneral-purpose vs. histopathology foundation models, offering guidance for\nmodel selection in cell-focused histopathology and brain cytoarchitecture\nanalysis workflows.",
      "tldr_zh": "这篇论文评估了通用 Foundation Models（如从 ImageNet-22K 或 LVD-142M 预训练的卷积、ViT 和混合编码器）和领域特定病理学模型（如 UNI、Virchow2 和 Prov-GigaPath）在细胞实例分割和分类任务中的表示学习差距。研究采用编码器-解码器架构，将编码器保持冻结以测试预训练特征提取能力，并通过跳跃连接整合多级 Patch Embeddings 生成语义和距离地图，随后进行后处理以创建实例分割掩码和细胞类型分类。实验使用 PanNuke、CoNIC 和新引入的 Nissl-stained CytoDArk0 数据集，评估了实例级检测、分割准确性和分类性能。该研究揭示了通用模型与病理学模型的优缺点，为细胞聚焦的病理学和脑细胞结构分析工作流中的模型选择提供了宝贵指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02471v1",
      "published_date": "2025-02-04 16:47:00 UTC",
      "updated_date": "2025-02-04 16:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:50:56.132913"
    },
    {
      "arxiv_id": "2502.02470v2",
      "title": "Modular Training of Neural Networks aids Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Satvik Golechha",
        "Maheep Chaudhary",
        "Joan Velja",
        "Alessandro Abate",
        "Nandi Schoots"
      ],
      "abstract": "An approach to improve neural network interpretability is via clusterability,\ni.e., splitting a model into disjoint clusters that can be studied\nindependently. We define a measure for clusterability and show that pre-trained\nmodels form highly enmeshed clusters via spectral graph clustering. We thus\ntrain models to be more modular using a \"clusterability loss\" function that\nencourages the formation of non-interacting clusters. Using automated\ninterpretability techniques, we show that our method can help train models that\nare more modular and learn different, disjoint, and smaller circuits. We\ninvestigate CNNs trained on MNIST and CIFAR, small transformers trained on\nmodular addition, and language models. Our approach provides a promising\ndirection for training neural networks that learn simpler functions and are\neasier to interpret.",
      "tldr_zh": "本研究提出了一种通过提升神经网络的“clusterability”（聚类性）来改善模型可解释性的方法，该方法定义了聚类性度量，并发现预训练模型的集群高度纠缠。研究引入“clusterability loss”函数来训练模型，形成非交互的模块化集群，从而使模型学习不同的、分离的、更小的电路。实验在 CNNs 上的 MNIST 和 CIFAR 数据集、小型 transformers 上的模块化加法任务以及语言模型中验证了这一方法，结果显示它能训练出更简单的函数并增强可解释性，为神经网络的可解释训练提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, under review. arXiv admin note: text overlap with\n  arXiv:2409.15747 (author note: this is an extension of that workshop paper\n  but has different authors)",
      "pdf_url": "http://arxiv.org/pdf/2502.02470v2",
      "published_date": "2025-02-04 16:44:38 UTC",
      "updated_date": "2025-02-07 01:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:51:06.329664"
    },
    {
      "arxiv_id": "2502.02456v4",
      "title": "Model Human Learners: Computational Models to Guide Instructional Design",
      "title_zh": "模拟人类学习者：用于指导教学设计的计算",
      "authors": [
        "Christopher J. MacLellan"
      ],
      "abstract": "Instructional designers face an overwhelming array of design choices, making\nit challenging to identify the most effective interventions. To address this\nissue, I propose the concept of a Model Human Learner, a unified computational\nmodel of learning that can aid designers in evaluating candidate interventions.\nThis paper presents the first successful demonstration of this concept, showing\nthat a computational model can accurately predict the outcomes of two human A/B\nexperiments -- one testing a problem sequencing intervention and the other\ntesting an item design intervention. It also demonstrates that such a model can\ngenerate learning curves without requiring human data and provide theoretical\ninsights into why an instructional intervention is effective. These findings\nlay the groundwork for future Model Human Learners that integrate cognitive and\nlearning theories to support instructional design across diverse tasks and\ninterventions.",
      "tldr_zh": "本文提出 Model Human Learner，这是一个统一的计算学习模型，用于指导教学设计，帮助评估各种干预效果。该模型成功预测了两个人类 A/B experiments 的结果，包括问题排序和项目设计干预，并能独立生成学习曲线，同时提供理论洞见解释干预为何有效。这些发现为未来整合认知和学习理论的 Model Human Learners 奠定了基础，支持多样任务的教学设计。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.HC",
      "comment": "Published at CogSci 2025; 6 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2502.02456v4",
      "published_date": "2025-02-04 16:24:42 UTC",
      "updated_date": "2025-05-10 16:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:51:17.703935"
    },
    {
      "arxiv_id": "2502.02628v1",
      "title": "e-SimFT: Alignment of Generative Models with Simulation Feedback for Pareto-Front Design Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunmin Cheong",
        "Mohammadmehdi Ataei",
        "Amir Hosein Khasahmadi",
        "Pradeep Kumar Jayaraman"
      ],
      "abstract": "Deep generative models have recently shown success in solving complex\nengineering design problems where models predict solutions that address the\ndesign requirements specified as input. However, there remains a challenge in\naligning such models for effective design exploration. For many design\nproblems, finding a solution that meets all the requirements is infeasible. In\nsuch a case, engineers prefer to obtain a set of Pareto optimal solutions with\nrespect to those requirements, but uniform sampling of generative models may\nnot yield a useful Pareto front. To address this gap, we introduce a new\nframework for Pareto-front design exploration with simulation fine-tuned\ngenerative models. First, the framework adopts preference alignment methods\ndeveloped for Large Language Models (LLMs) and showcases the first application\nin fine-tuning a generative model for engineering design. The important\ndistinction here is that we use a simulator instead of humans to provide\naccurate and scalable feedback. Next, we propose epsilon-sampling, inspired by\nthe epsilon-constraint method used for Pareto-front generation with classical\noptimization algorithms, to construct a high-quality Pareto front with the\nfine-tuned models. Our framework, named e-SimFT, is shown to produce\nbetter-quality Pareto fronts than existing multi-objective alignment methods.",
      "tldr_zh": "该研究提出 e-SimFT 框架，用于通过模拟反馈（Simulation Feedback）对生成模型进行校准，以实现工程设计中的 Pareto-Front 探索。框架借鉴 Large Language Models 的偏好校准方法（Preference Alignment），首次应用于工程设计，利用模拟器提供可扩展反馈，而不是人类评估；同时引入 epsilon-sampling 技术，灵感来源于经典优化的 epsilon-constraint 方法，以构建高质量的 Pareto 前沿。与现有多目标校准方法相比，e-SimFT 在生成 Pareto 最优解方面表现出色，能更有效地处理无法完全满足设计要求的复杂问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02628v1",
      "published_date": "2025-02-04 16:17:22 UTC",
      "updated_date": "2025-02-04 16:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:51:30.298964"
    },
    {
      "arxiv_id": "2502.02446v1",
      "title": "Towards graph neural networks for provably solving convex optimization problems",
      "title_zh": "翻译失败",
      "authors": [
        "Chendi Qian",
        "Christopher Morris"
      ],
      "abstract": "Recently, message-passing graph neural networks (MPNNs) have shown potential\nfor solving combinatorial and continuous optimization problems due to their\nability to capture variable-constraint interactions. While existing approaches\nleverage MPNNs to approximate solutions or warm-start traditional solvers, they\noften lack guarantees for feasibility, particularly in convex optimization\nsettings. Here, we propose an iterative MPNN framework to solve convex\noptimization problems with provable feasibility guarantees. First, we\ndemonstrate that MPNNs can provably simulate standard interior-point methods\nfor solving quadratic problems with linear constraints, covering relevant\nproblems such as SVMs. Secondly, to ensure feasibility, we introduce a variant\nthat starts from a feasible point and iteratively restricts the search within\nthe feasible region. Experimental results show that our approach outperforms\nexisting neural baselines in solution quality and feasibility, generalizes well\nto unseen problem sizes, and, in some cases, achieves faster solution times\nthan state-of-the-art solvers such as Gurobi.",
      "tldr_zh": "本文提出了一种迭代的 MPNNs 框架，用于解决凸优化问题，并提供可证明的可行性保证。该框架首先模拟标准内点法来处理带线性约束的二次问题，如 SVMs；其次，通过从可行点开始并在可行区域内迭代搜索，确保解决方案的可靠性。实验结果表明，该方法在解决方案质量和可行性上优于现有神经基线，能够良好泛化到未见问题规模，并在某些情况下比 Gurobi 等求解器更快。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02446v1",
      "published_date": "2025-02-04 16:11:41 UTC",
      "updated_date": "2025-02-04 16:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:51:42.096061"
    },
    {
      "arxiv_id": "2502.02444v4",
      "title": "Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Ye",
        "Tianze Zhang",
        "Yuhang Xie",
        "Liyuan Zhang",
        "Yuanyi Ren",
        "Xin Zhang",
        "Guojie Song"
      ],
      "abstract": "Values are core drivers of individual and collective perception, cognition,\nand behavior. Value systems, such as Schwartz's Theory of Basic Human Values,\ndelineate the hierarchy and interplay among these values, enabling\ncross-disciplinary investigations into decision-making and societal dynamics.\nRecently, the rise of Large Language Models (LLMs) has raised concerns\nregarding their elusive intrinsic values. Despite growing efforts in\nevaluating, understanding, and aligning LLM values, a psychologically grounded\nLLM value system remains underexplored. This study addresses the gap by\nintroducing the Generative Psycho-Lexical Approach (GPLA), a scalable,\nadaptable, and theoretically informed method for constructing value systems.\nLeveraging GPLA, we propose a psychologically grounded five-factor value system\ntailored for LLMs. For systematic validation, we present three benchmarking\ntasks that integrate psychological principles with cutting-edge AI priorities.\nOur results reveal that the proposed value system meets standard psychological\ncriteria, better captures LLM values, improves LLM safety prediction, and\nenhances LLM alignment, when compared to the canonical Schwartz's values.",
      "tldr_zh": "本研究引入 Generative Psycho-Lexical Approach (GPLA)，一种可扩展且理论支持的方法，用于构建 Large Language Models (LLMs) 的价值观系统，以填补心理基础缺失的空白。基于 GPLA，该方法提出一个心理导向的五因素价值观系统，旨在更好地捕捉 LLM 的内在价值观。研究通过三个基准任务进行验证，结果显示该系统符合心理标准，比 Schwartz's Theory of Basic Human Values 更有效地提升 LLM 安全预测和模型对齐。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2502.02444v4",
      "published_date": "2025-02-04 16:10:55 UTC",
      "updated_date": "2025-05-18 10:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:51:53.369201"
    },
    {
      "arxiv_id": "2502.02441v1",
      "title": "LLMER: Crafting Interactive Extended Reality Worlds with JSON Data Generated by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangong Chen",
        "Xiaoyi Wu",
        "Tian Lan",
        "Bin Li"
      ],
      "abstract": "The integration of Large Language Models (LLMs) like GPT-4 with Extended\nReality (XR) technologies offers the potential to build truly immersive XR\nenvironments that interact with human users through natural language, e.g.,\ngenerating and animating 3D scenes from audio inputs. However, the complexity\nof XR environments makes it difficult to accurately extract relevant contextual\ndata and scene/object parameters from an overwhelming volume of XR artifacts.\nIt leads to not only increased costs with pay-per-use models, but also elevated\nlevels of generation errors. Moreover, existing approaches focusing on coding\nscript generation are often prone to generation errors, resulting in flawed or\ninvalid scripts, application crashes, and ultimately a degraded user\nexperience. To overcome these challenges, we introduce LLMER, a novel framework\nthat creates interactive XR worlds using JSON data generated by LLMs. Unlike\nprior approaches focusing on coding script generation, LLMER translates natural\nlanguage inputs into JSON data, significantly reducing the likelihood of\napplication crashes and processing latency. It employs a multi-stage strategy\nto supply only the essential contextual information adapted to the user's\nrequest and features multiple modules designed for various XR tasks. Our\npreliminary user study reveals the effectiveness of the proposed system, with\nover 80% reduction in consumed tokens and around 60% reduction in task\ncompletion time compared to state-of-the-art approaches. The analysis of users'\nfeedback also illuminates a series of directions for further optimization.",
      "tldr_zh": "该研究提出 LLMER 框架，利用 Large Language Models (LLMs) 生成 JSON 数据来构建交互式 Extended Reality (XR) 世界，从而解决现有方法在数据提取和代码生成中的复杂性问题。LLMER 通过多阶段策略将自然语言输入转化为 JSON 格式，仅提供必要的上下文信息，并配备多个模块处理不同 XR 任务，以降低应用崩溃风险和处理延迟。与现有方法相比，用户研究显示 LLMER 减少了 80% 的 tokens 消耗和 60% 的任务完成时间，并从用户反馈中提炼出进一步优化的方向。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02441v1",
      "published_date": "2025-02-04 16:08:48 UTC",
      "updated_date": "2025-02-04 16:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:52:06.377702"
    },
    {
      "arxiv_id": "2502.02438v1",
      "title": "Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment",
      "title_zh": "医学多模态模型窃取攻击通过对抗域对齐",
      "authors": [
        "Yaling Shen",
        "Zhixiong Zhuang",
        "Kun Yuan",
        "Maria-Irina Nicolae",
        "Nassir Navab",
        "Nicolas Padoy",
        "Mario Fritz"
      ],
      "abstract": "Medical multimodal large language models (MLLMs) are becoming an instrumental\npart of healthcare systems, assisting medical personnel with decision making\nand results analysis. Models for radiology report generation are able to\ninterpret medical imagery, thus reducing the workload of radiologists. As\nmedical data is scarce and protected by privacy regulations, medical MLLMs\nrepresent valuable intellectual property. However, these assets are potentially\nvulnerable to model stealing, where attackers aim to replicate their\nfunctionality via black-box access. So far, model stealing for the medical\ndomain has focused on classification; however, existing attacks are not\neffective against MLLMs. In this paper, we introduce Adversarial Domain\nAlignment (ADA-STEAL), the first stealing attack against medical MLLMs.\nADA-STEAL relies on natural images, which are public and widely available, as\nopposed to their medical counterparts. We show that data augmentation with\nadversarial noise is sufficient to overcome the data distribution gap between\nnatural images and the domain-specific distribution of the victim MLLM.\nExperiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that\nAdversarial Domain Alignment enables attackers to steal the medical MLLM\nwithout any access to medical data.",
      "tldr_zh": "本研究探讨了医疗多模态大语言模型(MLLMs)的模型窃取攻击问题，提出Adversarial Domain Alignment (ADA-STEAL)作为首个针对此类模型的攻击方法。该方法利用公开的自然图像，通过数据增强和对抗噪声来桥接自然图像与医疗图像的领域分布差距，从而实现黑盒窃取，而无需访问医疗数据。在IU X-RAY和MIMIC-CXR放射学数据集上的实验证明，ADA-STEAL能有效窃取MLLMs的功能，突显了医疗AI系统的潜在安全风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02438v1",
      "published_date": "2025-02-04 16:04:48 UTC",
      "updated_date": "2025-02-04 16:04:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:52:18.507932"
    },
    {
      "arxiv_id": "2502.02431v1",
      "title": "Connections between Schedule-Free Optimizers, AdEMAMix, and Accelerated SGD Variants",
      "title_zh": "Schedule-Free Optimizers、AdEMAMix 与加速 SGD 变体之间的联系",
      "authors": [
        "Depen Morwani",
        "Nikhil Vyas",
        "Hanlin Zhang",
        "Sham Kakade"
      ],
      "abstract": "Recent advancements in deep learning optimization have introduced new\nalgorithms, such as Schedule-Free optimizers, AdEMAMix, MARS and Lion which\nmodify traditional momentum mechanisms. In a separate line of work, theoretical\nacceleration of stochastic gradient descent (SGD) in noise-dominated regime has\nbeen achieved by decoupling the momentum coefficient from the current\ngradient's weight. In this paper, we establish explicit connections between\nthese two lines of work. We substantiate our theoretical findings with\npreliminary experiments on a 150m language modeling task. We find that\nAdEMAMix, which most closely resembles accelerated versions of stochastic\ngradient descent, exhibits superior performance. Building on these insights, we\nintroduce a modification to AdEMAMix, termed Simplified-AdEMAMix, which\nmaintains the same performance as AdEMAMix across both large and small\nbatch-size settings while eliminating the need for two different momentum\nterms. The code for Simplified-AdEMAMix is available on the repository:\nhttps://github.com/DepenM/Simplified-AdEMAMix/.",
      "tldr_zh": "这篇论文探讨了 Schedule-Free optimizers、AdEMAMix 和加速 SGD 变体之间的联系，揭示了这些优化算法如何通过修改传统动量机制来实现深度学习中的性能提升。作者通过理论分析和在 150m 语言建模任务上的初步实验，证明了 AdEMAMix 最接近加速 SGD 的噪声主导机制，并表现出优越性能。基于此，他们引入了 Simplified-AdEMAMix 的改进版本，该方法在不同批量大小设置下保持与 AdEMAMix 相同的性能，同时消除了需要两个不同动量项的需求。代码已在 GitHub 仓库中公开，为深度学习优化提供了实用工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02431v1",
      "published_date": "2025-02-04 15:55:35 UTC",
      "updated_date": "2025-02-04 15:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:52:30.975271"
    },
    {
      "arxiv_id": "2502.04350v1",
      "title": "CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchao Chen",
        "Yilun Hao",
        "Yueying Liu",
        "Yang Zhang",
        "Chuchu Fan"
      ],
      "abstract": "Existing methods fail to effectively steer Large Language Models (LLMs)\nbetween textual reasoning and code generation, leaving symbolic computing\ncapabilities underutilized. We introduce CodeSteer, an effective method for\nguiding LLM code/text generation. We construct a comprehensive benchmark\nSymBench comprising 37 symbolic tasks with adjustable complexity and also\nsynthesize datasets of 12k multi-round guidance/generation trajectories and\n5.5k guidance comparison pairs. We fine-tune the Llama-3-8B model with a newly\ndesigned multi-round supervised fine-tuning (SFT) and direct preference\noptimization (DPO). The resulting model, CodeSteerLLM, augmented with the\nproposed symbolic and self-answer checkers, effectively guides the code/text\ngeneration of larger models. Augmenting GPT-4o with CodeSteer raises its\naverage performance score from 53.3 to 86.4, even outperforming the existing\nbest LLM OpenAI o1 (82.7), o1-preview (74.8), and DeepSeek R1 (76.8) across all\n37 tasks (28 seen, 9 unseen). Trained for GPT-4o, CodeSteer demonstrates\nsuperior generalizability, providing an average 41.8 performance boost on\nClaude, Mistral, and GPT-3.5. CodeSteer-guided LLMs fully harness symbolic\ncomputing to maintain strong performance on highly complex tasks. Models,\nDatasets, and Codes are available at\nhttps://github.com/yongchao98/CodeSteer-v1.0.",
      "tldr_zh": "本文提出 CodeSteer，一种通过代码/文本指导增强大型语言模型 (LLMs) 的方法，以解决现有模型在文本推理和代码生成之间切换的不足，并充分利用符号计算能力。研究者构建了 SymBench 基准（包含 37 个符号任务）和合成数据集（12k 多轮轨迹及 5.5k 比较对），并对 Llama-3-8B 模型进行多轮监督微调 (SFT) 和直接偏好优化 (DPO)，开发出 CodeSteerLLM 模型。实验结果显示，CodeSteer 显著提升 GPT-4o 的平均性能分数从 53.3 提高到 86.4，甚至超过 OpenAI o1 等模型，且在 Claude、Mistral 和 GPT-3.5 上展现出 41.8 的泛化提升。模型、数据集和代码已在 GitHub 上开源，提供可复制的研究资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04350v1",
      "published_date": "2025-02-04 15:53:59 UTC",
      "updated_date": "2025-02-04 15:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:52:44.586248"
    },
    {
      "arxiv_id": "2503.15528v1",
      "title": "Complying with the EU AI Act: Innovations in Explainable and User-Centric Hand Gesture Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Seifi",
        "Tobias Sukianto",
        "Cecilia Carbonelli",
        "Lorenzo Servadei",
        "Robert Wille"
      ],
      "abstract": "The EU AI Act underscores the importance of transparency, user-centricity,\nand robustness in AI systems, particularly for high-risk systems. In response,\nwe present advancements in XentricAI, an explainable hand gesture recognition\n(HGR) system designed to meet these regulatory requirements. XentricAI adresses\nfundamental challenges in HGR, such as the opacity of black-box models using\nexplainable AI methods and the handling of distributional shifts in real-world\ndata through transfer learning techniques. We extend an existing radar-based\nHGR dataset by adding 28,000 new gestures, with contributions from multiple\nusers across varied locations, including 24,000 out-of-distribution gestures.\nLeveraging this real-world dataset, we enhance XentricAI's capabilities by\nintegrating a variational autoencoder module for improved gesture anomaly\ndetection, incorporating user-specific thresholding. This integration enables\nthe identification of 11.50% more anomalous gestures. Our extensive evaluations\ndemonstrate a 97.5% sucess rate in characterizing these anomalies,\nsignificantly improving system explainability. Furthermore, the implementation\nof transfer learning techniques has shown a substantial increase in user\nadaptability, with an average improvement of at least 15.17%. This work\ncontributes to the development of trustworthy AI systems by providing both\ntechnical advancements and regulatory compliance, offering a commercially\nviable solution that aligns with the EU AI Act requirements.",
      "tldr_zh": "本研究响应欧盟AI Act的要求，提出XentricAI系统，一种可解释和用户中心的手势识别（HGR）系统，旨在提升AI的透明度、鲁棒性和用户适应性。XentricAI通过explainable AI方法解决黑箱模型的透明问题，并利用transfer learning技术处理真实世界数据的分布偏移，同时扩展了一个基于雷达的HGR数据集，新增28,000个手势（包括24,000个分布外手势）。通过整合variational autoencoder (VAE)模块进行用户特定阈值的异常检测，该系统将异常手势识别率提高了11.50%，并在评估中实现了97.5%的异常表征成功率，以及至少15.17%的用户适应性提升，最终为可信赖的AI系统提供符合法规的商业解决方案。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15528v1",
      "published_date": "2025-02-04 15:50:03 UTC",
      "updated_date": "2025-02-04 15:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:52:54.356750"
    },
    {
      "arxiv_id": "2502.04349v1",
      "title": "Dynamic benchmarking framework for LLM-based conversational data capture",
      "title_zh": "翻译失败",
      "authors": [
        "Pietro Alessandro Aluffi",
        "Patrick Zietkiewicz",
        "Marya Bazzi",
        "Matt Arderne",
        "Vladimirs Murevics"
      ],
      "abstract": "The rapid evolution of large language models (LLMs) has transformed\nconversational agents, enabling complex human-machine interactions. However,\nevaluation frameworks often focus on single tasks, failing to capture the\ndynamic nature of multi-turn dialogues. This paper introduces a dynamic\nbenchmarking framework to assess LLM-based conversational agents through\ninteractions with synthetic users. The framework integrates generative agent\nsimulation to evaluate performance on key dimensions: information extraction,\ncontext awareness, and adaptive engagement. By simulating various aspects of\nuser behavior, our work provides a scalable, automated, and flexible\nbenchmarking approach. Experimental evaluation - within a loan application use\ncase - demonstrates the framework's effectiveness under one-shot and few-shot\nextraction conditions. Results show that adaptive strategies improve data\nextraction accuracy, especially when handling ambiguous responses. Future work\nwill extend its applicability to broader domains and incorporate additional\nmetrics (e.g., conversational coherence, user engagement). This study\ncontributes a structured, scalable approach to evaluating LLM-based\nconversational agents, facilitating real-world deployment.",
      "tldr_zh": "这篇论文提出了一种动态基准框架，用于评估基于 LLM（Large Language Models）的对话代理在多轮对话中的性能，解决了传统框架对单一任务的局限性。框架通过整合生成代理模拟（generative agent simulation）与合成用户交互，评估关键维度，包括信息提取、上下文感知和适应性参与，提供可扩展、自动化的评估方法。在贷款申请用例的实验中，结果显示该框架在单次和少次提示条件下显著提高了数据提取准确性，尤其在处理模糊响应时。该研究为 LLM 对话代理的实际部署奠定了结构化、可扩展的基础，并计划扩展到更多领域和指标，如对话连贯性（conversational coherence）和用户参与。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04349v1",
      "published_date": "2025-02-04 15:47:47 UTC",
      "updated_date": "2025-02-04 15:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:53:06.638597"
    },
    {
      "arxiv_id": "2502.02421v1",
      "title": "Activation-Informed Merging of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Amin Heyrani Nobari",
        "Kaveh Alimohammadi",
        "Ali ArjomandBigdeli",
        "Akash Srivastava",
        "Faez Ahmed",
        "Navid Azizan"
      ],
      "abstract": "Model merging, a method that combines the parameters and embeddings of\nmultiple fine-tuned large language models (LLMs), offers a promising approach\nto enhance model performance across various tasks while maintaining\ncomputational efficiency. This paper introduces Activation-Informed Merging\n(AIM), a technique that integrates the information from the activation space of\nLLMs into the merging process to improve performance and robustness. AIM is\ndesigned as a flexible, complementary solution that is applicable to any\nexisting merging method. It aims to preserve critical weights from the base\nmodel, drawing on principles from continual learning~(CL) and model\ncompression. Utilizing a task-agnostic calibration set, AIM selectively\nprioritizes essential weights during merging. We empirically demonstrate that\nAIM significantly enhances the performance of merged models across multiple\nbenchmarks. Our findings suggest that considering the activation-space\ninformation can provide substantial advancements in the model merging\nstrategies for LLMs with up to 40\\% increase in benchmark performance.",
      "tldr_zh": "这篇论文引入了 Activation-Informed Merging (AIM)，一种将激活空间信息整合到大型语言模型 (LLMs) 合并过程中的技术，以提升模型性能和鲁棒性，同时保持计算效率。AIM 作为灵活的补充方法，适用于任何现有合并策略，通过借鉴 continual learning 和 model compression 的原则，并利用任务无关的校准集来优先保留关键权重。实验结果表明，AIM 在多个基准上显著提升了合并模型的表现，最多可提高 40% 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02421v1",
      "published_date": "2025-02-04 15:42:03 UTC",
      "updated_date": "2025-02-04 15:42:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:53:18.232948"
    },
    {
      "arxiv_id": "2502.02406v2",
      "title": "LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models",
      "title_zh": "LV-XAttn：用于多模态大型语言模型中长视觉输入的分布式交叉注意力",
      "authors": [
        "Tzu-Tao Chang",
        "Shivaram Venkataraman"
      ],
      "abstract": "Cross-attention is commonly adopted in multimodal large language models\n(MLLMs) for integrating visual information into the language backbone. However,\nin applications with large visual inputs, such as video understanding,\nprocessing a large number of visual tokens in cross-attention layers leads to\nhigh memory demands and often necessitates distributed computation across\nmultiple GPUs. Existing distributed attention mechanisms face significant\ncommunication overheads, making cross-attention layers a critical bottleneck\nfor efficient training and inference of MLLMs. To address this, we propose\nLV-XAttn, a distributed, exact cross-attention mechanism with minimal\ncommunication overhead. We observe that in applications involving large visual\ninputs the size of the query block is typically much smaller than that of the\nkey-value blocks. Thus, in LV-XAttn we keep the large key-value blocks locally\non each GPU and exchange smaller query blocks across GPUs. We also introduce an\nefficient activation recomputation technique enabling support for longer visual\ncontext. We theoretically analyze the communication benefits of LV-XAttn and\nshow that it can achieve speedups for a wide range of models. Our evaluations\nwith mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to\n5.58$\\times$ end-to-end speedup compared to existing approaches.",
      "tldr_zh": "这篇论文针对多模态大语言模型(MLLMs)中处理长视觉输入（如视频理解）的跨注意力(cross-attention)机制，提出了LV-XAttn，一种分布式且精确的机制，以最小化通信开销。LV-XAttn利用查询块较小的特性，将键-值块保持在本地GPU上，仅交换查询块，并引入高效的激活重新计算技术来支持更长的视觉上下文。实验结果显示，与现有方法相比，LV-XAttn在mPLUG-Owl3和OpenFlamingo模型上实现了高达5.58倍的端到端加速。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02406v2",
      "published_date": "2025-02-04 15:24:16 UTC",
      "updated_date": "2025-02-06 19:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:53:30.638714"
    },
    {
      "arxiv_id": "2502.04348v2",
      "title": "Prompt-based Depth Pruning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Juyun Wee",
        "Minjae Park",
        "Jaeho Lee"
      ],
      "abstract": "Depth pruning aims to reduce the inference cost of a large language model\nwithout any hardware-specific complications, by simply removing several less\nimportant transformer blocks. However, our empirical findings suggest that the\nimportance of a transformer block may be highly task-dependent -- a block that\nis crucial for a task can be removed without degrading the accuracy on another\ntask. Based on this observation, we develop a dynamic depth pruning algorithm,\ncoined PuDDing (Prompt-routed Dynamic Depth Pruning), which determines which\nblocks to omit from the model based on the input prompt. PuDDing operates by\ntraining a lightweight router to predict the best omission set among a set of\noptions, where this option set has also been constructed in a data-driven\nmanner. Empirical results on commonsense reasoning benchmarks demonstrate that\nPuDDing effectively accelerates the inference language models, and achieves\nbetter on-task performance than static depth pruning baselines.",
      "tldr_zh": "本文提出了一种基于提示的深度修剪（Depth Pruning）方法，用于减少大语言模型的推理成本，通过动态移除不重要的Transformer blocks。研究发现，Transformer blocks的重要性高度依赖于任务，因此开发了PuDDing（Prompt-routed Dynamic Depth Pruning）算法，该算法训练一个轻量级路由器根据输入提示预测最佳移除集合，并通过数据驱动方式构建选项。实验结果显示，在常识推理基准测试中，PuDDing比静态深度修剪基线实现了更好的任务性能和推理加速。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04348v2",
      "published_date": "2025-02-04 15:16:17 UTC",
      "updated_date": "2025-02-14 11:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:53:41.548773"
    },
    {
      "arxiv_id": "2502.04347v1",
      "title": "SCALM: Detecting Bad Practices in Smart Contracts Through LLMs",
      "title_zh": "SCALM：通过大语言模型检测智能合约中的不良实践",
      "authors": [
        "Zongwei Li",
        "Xiaoqi Li",
        "Wenkai Li",
        "Xin Wang"
      ],
      "abstract": "As the Ethereum platform continues to mature and gain widespread usage, it is\ncrucial to maintain high standards of smart contract writing practices. While\nbad practices in smart contracts may not directly lead to security issues, they\ndo elevate the risk of encountering problems. Therefore, to understand and\navoid these bad practices, this paper introduces the first systematic study of\nbad practices in smart contracts, delving into over 35 specific issues.\nSpecifically, we propose a large language models (LLMs)-based framework, SCALM.\nIt combines Step-Back Prompting and Retrieval-Augmented Generation (RAG) to\nidentify and address various bad practices effectively. Our extensive\nexperiments using multiple LLMs and datasets have shown that SCALM outperforms\nexisting tools in detecting bad practices in smart contracts.",
      "tldr_zh": "这篇论文首次系统研究了智能合约中的坏实践（bad practices），识别出超过 35 个具体问题，这些问题虽不直接导致安全漏洞，但会增加风险。作者提出了一种基于大型语言模型（LLMs）的框架 SCALM，结合 Step-Back Prompting 和 Retrieval-Augmented Generation (RAG) 来有效检测和处理这些坏实践。通过广泛实验，SCALM 在多个 LLMs 和数据集上超过了现有工具的性能，为提升智能合约编写标准提供了新方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.04347v1",
      "published_date": "2025-02-04 15:15:13 UTC",
      "updated_date": "2025-02-04 15:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:53:53.773809"
    },
    {
      "arxiv_id": "2502.02391v1",
      "title": "FewTopNER: Integrating Few-Shot Learning with Topic Modeling and Named Entity Recognition in a Multilingual Framework",
      "title_zh": "FewTopNER：在多语言框架中整合少样本学习、主题建模和命名实体识别",
      "authors": [
        "Ibrahim Bouabdallaoui",
        "Fatima Guerouate",
        "Samya Bouhaddour",
        "Chaimae Saadi",
        "Mohammed Sbihi"
      ],
      "abstract": "We introduce FewTopNER, a novel framework that integrates few-shot named\nentity recognition (NER) with topic-aware contextual modeling to address the\nchallenges of cross-lingual and low-resource scenarios. FewTopNER leverages a\nshared multilingual encoder based on XLM-RoBERTa, augmented with\nlanguage-specific calibration mechanisms, to generate robust contextual\nembeddings. The architecture comprises a prototype-based entity recognition\nbranch, employing BiLSTM and Conditional Random Fields for sequence labeling,\nand a topic modeling branch that extracts document-level semantic features\nthrough hybrid probabilistic and neural methods. A cross-task bridge\nfacilitates dynamic bidirectional attention and feature fusion between entity\nand topic representations, thereby enhancing entity disambiguation by\nincorporating global semantic context. Empirical evaluations on multilingual\nbenchmarks across English, French, Spanish, German, and Italian demonstrate\nthat FewTopNER significantly outperforms existing state-of-the-art few-shot NER\nmodels. In particular, the framework achieves improvements of 2.5-4.0\npercentage points in F1 score and exhibits enhanced topic coherence, as\nmeasured by normalized pointwise mutual information. Ablation studies further\nconfirm the critical contributions of the shared encoder and cross-task\nintegration mechanisms to the overall performance. These results underscore the\nefficacy of incorporating topic-aware context into few-shot NER and highlight\nthe potential of FewTopNER for robust cross-lingual applications in\nlow-resource settings.",
      "tldr_zh": "我们引入FewTopNER框架，将Few-Shot NER与主题建模整合，旨在解决多语言和低资源场景下的命名实体识别挑战。该框架采用基于XLM-RoBERTa的共享多语言编码器、原型-based实体识别分支（使用BiLSTM和CRF进行序列标记）以及主题建模分支，通过跨任务桥接实现实体和主题表示的动态融合，提升全局语义上下文。在英语、法语、西班牙语、德语和意大利语的多语言基准测试中，FewTopNER比现有Few-Shot NER模型提高F1分数2.5-4.0百分点，并改善主题连贯性，消融研究证实共享编码器和跨任务机制的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code source : https://github.com/ibrahimself/FewTopNER/",
      "pdf_url": "http://arxiv.org/pdf/2502.02391v1",
      "published_date": "2025-02-04 15:13:40 UTC",
      "updated_date": "2025-02-04 15:13:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:54:07.493557"
    },
    {
      "arxiv_id": "2502.02390v1",
      "title": "CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jianfeng Pan",
        "Senyou Deng",
        "Shaomang Huang"
      ],
      "abstract": "Research on LLM technologies is rapidly emerging, with most of them employing\na 'fast thinking' approach to inference. Most LLMs generate the final result\nbased solely on a single query and LLM's reasoning capabilities. However, with\nthe advent of OpenAI-o1, 'slow thinking' techniques have garnered increasing\nattention because its process is closer to the human thought process. Inspired\nby the human ability to constantly associate and replenish knowledge during\nthinking, we developed the novel Chain-of-Associated-Thoughts (CoAT) framework,\nwhich introduces an innovative synergy between the Monte Carlo Tree Search\n(MCTS) algorithm and a dynamic mechanism for integrating new key information,\ntermed 'associative memory'. By combining the structured exploration\ncapabilities of MCTS with the adaptive learning capacity of associative memory,\nCoAT significantly expands the LLM search space, enabling our framework to\nexplore diverse reasoning pathways and dynamically update its knowledge base in\nreal-time. This allows the framework to not only revisit and refine earlier\ninferences but also adaptively incorporate evolving information, ensuring that\nthe final output is both accurate and comprehensive. To validate the\neffectiveness of our framework, we conducted extensive experiments across a\nrange of generative and reasoning tasks. These experiments demonstrated that\nour framework outperforms conventional inference processes on accuracy,\ncoherence, and diversity. The framework's ability to iteratively expand its\nsearch space while retaining contextually relevant information results.",
      "tldr_zh": "该研究提出了一种名为 Chain-of-Associated-Thoughts (CoAT) 的框架，以增强 Large Language Models (LLMs) 的推理能力，通过模拟人类“慢思考”过程来克服传统“快思考”方法的局限。CoAT 框架结合 Monte Carlo Tree Search (MCTS) 算法的结构化探索与“associative memory”机制的动态知识整合，允许模型探索多样化推理路径、实时更新知识库并优化先前推理。实验结果显示，在各种生成和推理任务上，CoAT 框架在准确性、一致性和多样性方面均优于传统方法，为更高效的 LLM 推理提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02390v1",
      "published_date": "2025-02-04 15:10:33 UTC",
      "updated_date": "2025-02-04 15:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:54:18.269875"
    },
    {
      "arxiv_id": "2502.02380v1",
      "title": "The Cost Perspective of Liquid Democracy: Feasibility and Control",
      "title_zh": "翻译失败",
      "authors": [
        "Shiri Alouf-Heffetz",
        "Łukasz Janeczko",
        "Grzegorz Lisowski",
        "Georgios Papasotiropoulos"
      ],
      "abstract": "We examine an approval-based model of Liquid Democracy with a budget\nconstraint on voting and delegating costs, aiming to centrally select casting\nvoters ensuring complete representation of the electorate. From a computational\ncomplexity perspective, we focus on minimizing overall costs, maintaining short\ndelegation paths, and preventing excessive concentration of voting power.\nFurthermore, we explore computational aspects of strategic control,\nspecifically, whether external agents can change election components to\ninfluence the voting power of certain voters.",
      "tldr_zh": "本研究从成本视角考察了 Liquid Democracy 的可行性和控制，引入了基于批准的模型，其中投票和 delegating costs 受预算约束，目标是通过中心化选择 casting voters 来确保选民的完全代表。论文重点分析了计算复杂性问题，包括最小化总体 costs、保持短 delegation paths 和防止投票权过度集中，从而优化系统效率。此外，探讨了 strategic control 的计算方面，即外部代理是否能通过改变选举组件来影响特定选民的投票权。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02380v1",
      "published_date": "2025-02-04 14:59:56 UTC",
      "updated_date": "2025-02-04 14:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:54:31.120958"
    },
    {
      "arxiv_id": "2502.02377v1",
      "title": "A Minimax Approach to Ad Hoc Teamwork",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Villin",
        "Thomas Kleine Buening",
        "Christos Dimitrakakis"
      ],
      "abstract": "We propose a minimax-Bayes approach to Ad Hoc Teamwork (AHT) that optimizes\npolicies against an adversarial prior over partners, explicitly accounting for\nuncertainty about partners at time of deployment. Unlike existing methods that\nassume a specific distribution over partners, our approach improves worst-case\nperformance guarantees. Extensive experiments, including evaluations on\ncoordinated cooking tasks from the Melting Pot suite, show our method's\nsuperior robustness compared to self-play, fictitious play, and best response\nlearning. Our work highlights the importance of selecting an appropriate\ntraining distribution over teammates to achieve robustness in AHT.",
      "tldr_zh": "该研究提出了一种 minimax-Bayes 方法，用于 Ad Hoc Teamwork (AHT)，通过优化策略以对抗敌对伙伴先验，显式处理部署时的伙伴不确定性，从而改善最坏情况下的性能保证。与现有假设特定伙伴分布的方法不同，该方法在实验中显示出更高的鲁棒性。实验包括 Melting Pot 套件的协调烹饪任务，结果表明 minimax-Bayes 优于 self-play、fictitious play 和 best response learning，并强调选择合适队友训练分布对 AHT 鲁棒性至关重要。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02377v1",
      "published_date": "2025-02-04 14:57:54 UTC",
      "updated_date": "2025-02-04 14:57:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:54:43.492684"
    },
    {
      "arxiv_id": "2502.02372v1",
      "title": "MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shengbo Gu",
        "Yu-Kun Qiu",
        "Yu-Ming Tang",
        "Ancong Wu",
        "Wei-Shi Zheng"
      ],
      "abstract": "The generation of a virtual digital avatar is a crucial research topic in the\nfield of computer vision. Many existing works utilize Neural Radiance Fields\n(NeRF) to address this issue and have achieved impressive results. However,\nprevious works assume the images of the training person are available and fixed\nwhile the appearances and poses of a subject could constantly change and\nincrease in real-world scenarios. How to update the human avatar but also\nmaintain the ability to render the old appearance of the person is a practical\nchallenge. One trivial solution is to combine the existing virtual avatar\nmodels based on NeRF with continual learning methods. However, there are some\ncritical issues in this approach: learning new appearances and poses can cause\nthe model to forget past information, which in turn leads to a degradation in\nthe rendering quality of past appearances, especially color bleeding issues,\nand incorrect human body poses. In this work, we propose a maintainable avatar\n(MaintaAvatar) based on neural radiance fields by continual learning, which\nresolves the issues by utilizing a Global-Local Joint Storage Module and a Pose\nDistillation Module. Overall, our model requires only limited data collection\nto quickly fine-tune the model while avoiding catastrophic forgetting, thus\nachieving a maintainable virtual avatar. The experimental results validate the\neffectiveness of our MaintaAvatar model.",
      "tldr_zh": "该论文提出 MaintaAvatar，一种基于 Neural Radiance Fields (NeRF) 的可维护虚拟头像系统，通过 Continual Learning 技术解决现实场景中人物外观和姿势不断变化时，模型更新导致旧信息遗忘的问题。该系统引入 Global-Local Joint Storage Module 和 Pose Distillation Module，分别用于存储全局和局部信息并保持姿势准确性，从而避免灾难性遗忘并维持渲染质量。实验结果证明，MaintaAvatar 仅需有限数据即可快速微调模型，并有效提升了虚拟头像的生成性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2025. 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.02372v1",
      "published_date": "2025-02-04 14:52:34 UTC",
      "updated_date": "2025-02-04 14:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:54:54.029032"
    },
    {
      "arxiv_id": "2502.02371v1",
      "title": "Accurate Pocket Identification for Binding-Site-Agnostic Docking",
      "title_zh": "翻译失败",
      "authors": [
        "Yaroslav Balytskyi",
        "Inna Hubenko",
        "Alina Balytska",
        "Christopher V. Kelly"
      ],
      "abstract": "Accurate identification of druggable pockets is essential for structure-based\ndrug design. However, most pocket-identification algorithms prioritize their\ngeometric properties over downstream docking performance. To address this\nlimitation, we developed RAPID-Net, a pocket-finding algorithm for seamless\nintegration with docking workflows. When guiding AutoDock Vina, RAPID-Net\noutperforms DiffBindFR on the PoseBusters benchmark and enables blind docking\non large proteins that AlphaFold 3 cannot process as a whole. Furthermore,\nRAPID-Net surpasses PUResNet and Kalasanty in docking accuracy and\npocket-ligand intersection rates across diverse datasets, including\nPoseBusters, Astex Diverse Set, BU48, and Coach420. When accuracy is evaluated\nas ``at least one correct pose in the ensemble'', RAPID-Net outperforms\nAlphaFold 3 on the PoseBusters benchmark, suggesting that our approach can be\nfurther improved with a suitable pose reweighting tool offering a\ncost-effective and competitive alternative to AlphaFold 3 for docking. Finally,\nusing several therapeutically relevant examples, we demonstrate the ability of\nRAPID-Net to identify remote functional sites, highlighting its potential to\nfacilitate the development of innovative therapeutics.",
      "tldr_zh": "这篇论文提出了一种名为 RAPID-Net 的口袋识别算法，旨在优化结构-based 药物设计中的对接性能，通过优先考虑下游 docking 而非单纯的几何属性来解决现有方法的局限性。RAPID-Net 在 PoseBusters 基准上引导 AutoDock Vina 时超过了 DiffBindFR，并在大型蛋白上实现了 AlphaFold 3 无法处理的盲对接（blind docking）。此外，它在对接准确性和口袋-配体交集率上优于 PUResNet 和 Kalasanty，在多个数据集（如 PoseBusters、Astex Diverse Set、BU48 和 Coach420）中表现出色，甚至在某些评估指标下超越了 AlphaFold 3。最终，该方法展示了识别远程功能位点的潜力，提供了一个成本效益高的替代方案，以促进创新疗法开发。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "physics.bio-ph",
        "physics.med-ph"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02371v1",
      "published_date": "2025-02-04 14:52:10 UTC",
      "updated_date": "2025-02-04 14:52:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:55:07.755677"
    },
    {
      "arxiv_id": "2502.02368v1",
      "title": "Evaluating the Effectiveness of LLMs in Fixing Maintainability Issues in Real-World Projects",
      "title_zh": "评估 LLMs 在修复真实世界项目维护性问题的有效性",
      "authors": [
        "Henrique Nunes",
        "Eduardo Figueiredo",
        "Larissa Rocha",
        "Sarah Nadi",
        "Fischer Ferreira",
        "Geanderson Esteves"
      ],
      "abstract": "Large Language Models (LLMs) have gained attention for addressing coding\nproblems, but their effectiveness in fixing code maintainability remains\nunclear. This study evaluates LLMs capability to resolve 127 maintainability\nissues from 10 GitHub repositories. We use zero-shot prompting for Copilot Chat\nand Llama 3.1, and few-shot prompting with Llama only. The LLM-generated\nsolutions are assessed for compilation errors, test failures, and new\nmaintainability problems. Llama with few-shot prompting successfully fixed\n44.9% of the methods, while Copilot Chat and Llama zero-shot fixed 32.29% and\n30%, respectively. However, most solutions introduced errors or new\nmaintainability issues. We also conducted a human study with 45 participants to\nevaluate the readability of 51 LLM-generated solutions. The human study showed\nthat 68.63% of participants observed improved readability. Overall, while LLMs\nshow potential for fixing maintainability issues, their introduction of errors\nhighlights their current limitations.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在修复真实GitHub项目中127个可维护性问题的有效性，使用零-shot prompting测试Copilot Chat和Llama 3.1，并使用few-shot prompting测试Llama。结果显示，Llama with few-shot prompting成功修复了44.9%的方法，而Copilot Chat和Llama zero-shot分别修复了32.29%和30%，但大多数解决方案引入了编译错误、测试失败或新问题。人类研究涉及45名参与者评估51个LLM生成的解决方案，发现68.63%的参与者认为可读性有所改善。总体而言，LLMs在处理可维护性问题上显示潜力，但引入错误突显了其当前局限性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02368v1",
      "published_date": "2025-02-04 14:50:23 UTC",
      "updated_date": "2025-02-04 14:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:55:18.628097"
    },
    {
      "arxiv_id": "2502.02367v1",
      "title": "Field Matching: an Electrostatic Paradigm to Generate and Transfer Data",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Kolesov",
        "Manukhov Stepan",
        "Vladimir V. Palyulin",
        "Alexander Korotin"
      ],
      "abstract": "We propose Electrostatic Field Matching (EFM), a novel method that is\nsuitable for both generative modeling and distribution transfer tasks. Our\napproach is inspired by the physics of an electrical capacitor. We place source\nand target distributions on the capacitor plates and assign them positive and\nnegative charges, respectively. We then learn the electrostatic field of the\ncapacitor using a neural network approximator. To map the distributions to each\nother, we start at one plate of the capacitor and move the samples along the\nlearned electrostatic field lines until they reach the other plate. We\ntheoretically justify that this approach provably yields the distribution\ntransfer. In practice, we demonstrate the performance of our EFM in toy and\nimage data experiments.",
      "tldr_zh": "该研究提出了Electrostatic Field Matching (EFM)，一种新颖的方法，灵感来源于电容器的静电场原理，用于生成建模和分布转移任务。具体来说，EFM将源分布和目标分布分别置于电容器板上并赋予正负电荷，然后使用神经网络学习静电场，并沿场线移动样本以实现分布映射。论文理论证明了此方法能有效实现分布转移，并在玩具数据和图像数据实验中展示了其优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02367v1",
      "published_date": "2025-02-04 14:50:16 UTC",
      "updated_date": "2025-02-04 14:50:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:55:29.953671"
    },
    {
      "arxiv_id": "2503.04739v1",
      "title": "Responsible Artificial Intelligence Systems: A Roadmap to Society's Trust through Trustworthy AI, Auditability, Accountability, and Governance",
      "title_zh": "负责任的人工智能系统：通过可信赖的AI、可审计性、问责性和治理通往社会信任的路线图",
      "authors": [
        "Andrés Herrera-Poyatos",
        "Javier Del Ser",
        "Marcos López de Prado",
        "Fei-Yue Wang",
        "Enrique Herrera-Viedma",
        "Francisco Herrera"
      ],
      "abstract": "Artificial intelligence (AI) has matured as a technology, necessitating the\ndevelopment of responsibility frameworks that are fair, inclusive, trustworthy,\nsafe and secure, transparent, and accountable. By establishing such frameworks,\nwe can harness the full potential of AI while mitigating its risks,\nparticularly in high-risk scenarios. This requires the design of responsible AI\nsystems based on trustworthy AI technologies and ethical principles, with the\naim of ensuring auditability and accountability throughout their design,\ndevelopment, and deployment, adhering to domain-specific regulations and\nstandards.\n  This paper explores the concept of a responsible AI system from a holistic\nperspective, which encompasses four key dimensions: 1) regulatory context; 2)\ntrustworthy AI technology along with standardization and assessments; 3)\nauditability and accountability; and 4) AI governance. The aim of this paper is\ndouble. First, we analyze and understand these four dimensions and their\ninterconnections in the form of an analysis and overview. Second, the final\ngoal of the paper is to propose a roadmap in the design of responsible AI\nsystems, ensuring that they can gain society's trust. To achieve this\ntrustworthiness, this paper also fosters interdisciplinary discussions on the\nethical, legal, social, economic, and cultural aspects of AI from a global\ngovernance perspective. Last but not least, we also reflect on the current\nstate and those aspects that need to be developed in the near future, as ten\nlessons learned.",
      "tldr_zh": "这篇论文探讨了负责任的 Artificial Intelligence (AI) 系统，旨在通过 Trustworthy AI 技术、Auditability、Accountability 和 Governance 等维度构建一个路线图，以提升社会的信任和减少 AI 风险。论文从整体视角分析了四个关键维度，包括监管背景、可信 AI 技术与标准化评估、可审计性与问责性，以及 AI 治理，并探讨它们之间的相互连接。最终，它提出设计负责任 AI 系统的路线图，促进跨学科讨论（如伦理、法律和社会影响），并总结十个经验教训，以指导未来发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "22 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04739v1",
      "published_date": "2025-02-04 14:47:30 UTC",
      "updated_date": "2025-02-04 14:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:55:42.730041"
    },
    {
      "arxiv_id": "2502.02341v1",
      "title": "Test Time Training for 4D Medical Image Interpolation",
      "title_zh": "翻译失败",
      "authors": [
        "Qikang Zhang",
        "Yingjie Lei",
        "Zihao Zheng",
        "Ziyang Chen",
        "Zhonghao Xie"
      ],
      "abstract": "4D medical image interpolation is essential for improving temporal resolution\nand diagnostic precision in clinical applications. Previous works ignore the\nproblem of distribution shifts, resulting in poor generalization under\ndifferent distribution. A natural solution would be to adapt the model to a new\ntest distribution, but this cannot be done if the test input comes without a\nground truth label. In this paper, we propose a novel test time training\nframework which uses self-supervision to adapt the model to a new distribution\nwithout requiring any labels. Indeed, before performing frame interpolation on\neach test video, the model is trained on the same instance using a\nself-supervised task, such as rotation prediction or image reconstruction. We\nconduct experiments on two publicly available 4D medical image interpolation\ndatasets, Cardiac and 4D-Lung. The experimental results show that the proposed\nmethod achieves significant performance across various evaluation metrics on\nboth datasets. It achieves higher peak signal-to-noise ratio values, 33.73dB on\nCardiac and 34.02dB on 4D-Lung. Our method not only advances 4D medical image\ninterpolation but also provides a template for domain adaptation in other\nfields such as image segmentation and image registration.",
      "tldr_zh": "这篇论文针对4D medical image interpolation中的分布偏移问题，提出了一种新型test time training框架，使用self-supervision（如rotation prediction或image reconstruction）在测试时适应新分布，而无需ground truth标签。在Cardiac和4D-Lung数据集上的实验表明，该方法显著提升了性能，PSNR值分别达到33.73dB和34.02dB。该框架不仅推进了4D医疗图像插值的技术，还为图像分割和图像注册等领域的领域适应提供了通用模板。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02341v1",
      "published_date": "2025-02-04 14:19:16 UTC",
      "updated_date": "2025-02-04 14:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:55:55.424881"
    },
    {
      "arxiv_id": "2502.02623v1",
      "title": "Sample Complexity of Bias Detection with Subsampled Point-to-Subspace Distances",
      "title_zh": "子采样点到子空间距离的偏置检测样本复杂度",
      "authors": [
        "German Martinez Matilla",
        "Jakub Marecek"
      ],
      "abstract": "Sample complexity of bias estimation is a lower bound on the runtime of any\nbias detection method. Many regulatory frameworks require the bias to be tested\nfor all subgroups, whose number grows exponentially with the number of\nprotected attributes. Unless one wishes to run a bias detection with a\ndoubly-exponential run-time, one should like to have polynomial complexity of\nbias detection for a single subgroup. At the same time, the reference data may\nbe based on surveys, and thus come with non-trivial uncertainty.\n  Here, we reformulate bias detection as a point-to-subspace problem on the\nspace of measures and show that, for supremum norm, it can be subsampled\nefficiently. In particular, our probabilistically approximately correct (PAC)\nresults are corroborated by tests on well-known instances.",
      "tldr_zh": "该论文探讨了偏差检测（Bias Detection）的样本复杂度（Sample Complexity），强调在多个子群体上测试偏差时，由于子群体数量指数增长，需要多项式复杂度的方法来降低运行时间。作者将偏差检测重新表述为测度空间中的点到子空间（Point-to-Subspace）问题，并证明通过子采样（Subsampled）技术，可以在supremum norm下高效实现。实验结果显示，该方法符合PAC（Probabilistically Approximately Correct）标准，并在知名实例上得到验证，从而为高效偏差检测提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02623v1",
      "published_date": "2025-02-04 14:03:49 UTC",
      "updated_date": "2025-02-04 14:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:56:06.465789"
    },
    {
      "arxiv_id": "2502.02302v1",
      "title": "EdgeGFL: Rethinking Edge Information in Graph Feature Preference Learning",
      "title_zh": "EdgeGFL：重新思考图特征偏好学习中的边信息",
      "authors": [
        "Shengda Zhuo",
        "Jiwang Fang",
        "Hongguang Lin",
        "Yin Tang",
        "Min Chen",
        "Changdong Wang",
        "Shuqiang Huang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have significant advantages in handling\nnon-Euclidean data and have been widely applied across various areas, thus\nreceiving increasing attention in recent years. The framework of GNN models\nmainly includes the information propagation phase and the aggregation phase,\ntreating nodes and edges as information entities and propagation channels,\nrespectively. However, most existing GNN models face the challenge of\ndisconnection between node and edge feature information, as these models\ntypically treat the learning of edge and node features as independent tasks. To\naddress this limitation, we aim to develop an edge-empowered graph feature\npreference learning framework that can capture edge embeddings to assist node\nembeddings. By leveraging the learned multidimensional edge feature matrix, we\nconstruct multi-channel filters to more effectively capture accurate node\nfeatures, thereby obtaining the non-local structural characteristics and\nfine-grained high-order node features. Specifically, the inclusion of\nmultidimensional edge information enhances the functionality and flexibility of\nthe GNN model, enabling it to handle complex and diverse graph data more\neffectively. Additionally, integrating relational representation learning into\nthe message passing framework allows graph nodes to receive more useful\ninformation, thereby facilitating node representation learning. Finally,\nexperiments on four real-world heterogeneous graphs demonstrate the\neffectiveness of theproposed model.",
      "tldr_zh": "该研究重新审视了图神经网络(GNNs)中边信息的作用，针对现有模型中节点和边特征学习脱节的问题，提出了一种EdgeGFL框架，通过捕获多维边嵌入来辅助节点嵌入。框架利用边特征矩阵构建多通道过滤器，增强消息传递机制以捕获非局部结构和细粒度高阶节点特征，同时整合关系表示学习以提升节点表示。实验在四个真实异构图上证明了EdgeGFL的有效性，展示了其在处理复杂图数据方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02302v1",
      "published_date": "2025-02-04 13:16:54 UTC",
      "updated_date": "2025-02-04 13:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:56:18.077302"
    },
    {
      "arxiv_id": "2502.13972v1",
      "title": "IncepFormerNet: A multi-scale multi-head attention network for SSVEP classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Huang",
        "Yongru Chen",
        "Lei Cao",
        "Yongnian Cao",
        "Xuechun Yang",
        "Yilin Dong",
        "Tianyu Liu"
      ],
      "abstract": "In recent years, deep learning (DL) models have shown outstanding performance\nin EEG classification tasks, particularly in Steady-State Visually Evoked\nPotential(SSVEP)-based Brain-Computer-Interfaces(BCI)systems. DL methods have\nbeen successfully applied to SSVEP-BCI. This study proposes a new model called\nIncepFormerNet, which is a hybrid of the Inception and Transformer\narchitectures. IncepFormerNet adeptly extracts multi-scale temporal information\nfrom time series data using parallel convolution kernels of varying sizes,\naccurately capturing the subtle variations and critical features within SSVEP\nsignals.Furthermore, the model integrates the multi-head attention mechanism\nfrom the Transformer architecture, which not only provides insights into global\ndependencies but also significantly enhances the understanding and\nrepresentation of complex patterns.Additionally, it takes advantage of filter\nbank techniques to extract features based on the spectral characteristics of\nSSVEP data. To validate the effectiveness of the proposed model, we conducted\nexperiments on two public datasets, . The experimental results show that\nIncepFormerNet achieves an accuracy of 87.41 on Dataset 1 and 71.97 on Dataset\n2 using a 1.0-second time window. To further verify the superiority of the\nproposed model, we compared it with other deep learning models, and the results\nindicate that our method achieves significantly higher accuracy than the\nothers.The source codes in this work are available at:\nhttps://github.com/CECNL/SSVEP-DAN.",
      "tldr_zh": "本研究提出了一种名为 IncepFormerNet 的混合神经网络模型，用于 Steady-State Visually Evoked Potential (SSVEP) 分类任务，旨在提升基于 Brain-Computer-Interfaces (BCI) 的 EEG 信号处理性能。该模型结合了 Inception 架构的多尺度卷积核和 Transformer 的 multi-head attention 机制，能够提取 SSVEP 信号的细微时间变化和全局依赖关系，同时利用滤波器银行技术基于频谱特性进行特征提取。在两个公开数据集上的实验中，IncepFormerNet 在 1.0 秒时间窗口下分别达到了 87.41% 和 71.97% 的准确率，并显著优于其他深度学习模型。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13972v1",
      "published_date": "2025-02-04 13:04:03 UTC",
      "updated_date": "2025-02-04 13:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:56:31.055845"
    },
    {
      "arxiv_id": "2502.02290v1",
      "title": "FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Lunghi",
        "Yannick Molinghen",
        "Alkis Simitsis",
        "Tom Lenaerts",
        "Gianluca Bontempi"
      ],
      "abstract": "Adversarial attacks pose a significant threat to data-driven systems, and\nresearchers have spent considerable resources studying them. Despite its\neconomic relevance, this trend largely overlooked the issue of credit card\nfraud detection. To address this gap, we propose a new threat model that\ndemonstrates the limitations of existing attacks and highlights the necessity\nto investigate new approaches. We then design a new adversarial attack for\ncredit card fraud detection, employing reinforcement learning to bypass\nclassifiers. This attack, called FRAUD-RLA, is designed to maximize the\nattacker's reward by optimizing the exploration-exploitation tradeoff and\nworking with significantly less required knowledge than competitors. Our\nexperiments, conducted on three different heterogeneous datasets and against\ntwo fraud detection systems, indicate that FRAUD-RLA is effective, even\nconsidering the severe limitations imposed by our threat model.",
      "tldr_zh": "本研究针对信用卡欺诈检测系统中的对抗攻击问题，提出一个新的威胁模型，以揭示现有攻击的局限性并强调需要创新方法。随后，设计了FRAUD-RLA攻击，利用reinforcement learning优化探索-利用权衡，从而以更少的知识最大化攻击者回报。实验在三个异构数据集和两个欺诈检测系统上进行，结果显示FRAUD-RLA在严格威胁模型下仍表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02290v1",
      "published_date": "2025-02-04 12:59:35 UTC",
      "updated_date": "2025-02-04 12:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:56:42.319793"
    },
    {
      "arxiv_id": "2502.02283v5",
      "title": "GP-GS: Gaussian Processes for Enhanced Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihao Guo",
        "Jingxuan Su",
        "Shenglin Wang",
        "Jinlong Fan",
        "Jing Zhang",
        "Wei Zhou",
        "Hadi Amirpour",
        "Yunlong Zhao",
        "Liangxiu Han",
        "Peng Wang"
      ],
      "abstract": "3D Gaussian Splatting has emerged as an efficient photorealistic novel view\nsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)\npoint clouds often limits scene reconstruction quality. To address the\nlimitation, this paper proposes a novel 3D reconstruction framework, Gaussian\nProcesses enhanced Gaussian Splatting (GP-GS), in which a multi-output Gaussian\nProcess model is developed to enable adaptive and uncertainty-guided\ndensification of sparse SfM point clouds. Specifically, we propose a dynamic\nsampling and filtering pipeline that adaptively expands the SfM point clouds by\nleveraging GP-based predictions to infer new candidate points from the input 2D\npixels and depth maps. The pipeline utilizes uncertainty estimates to guide the\npruning of high-variance predictions, ensuring geometric consistency and\nenabling the generation of dense point clouds. These densified point clouds\nprovide high-quality initial 3D Gaussians, enhancing reconstruction\nperformance. Extensive experiments conducted on synthetic and real-world\ndatasets across various scales validate the effectiveness and practicality of\nthe proposed framework.",
      "tldr_zh": "本文提出 GP-GS 框架，利用 Gaussian Processes (GP) 模型增强 3D Gaussian Splatting 的重建性能，以解决其依赖稀疏 Structure-from-Motion (SfM) 点云导致的质量限制问题。该框架引入动态采样和过滤管道，通过 GP-based 预测从输入的 2D 像素和深度图推断新候选点，并利用不确定性估计修剪高方差预测，确保几何一致性和点云稠密化，从而提供高质量的初始 3D Gaussians。实验在合成和真实数据集上验证了 GP-GS 的有效性，显著提高了重建准确率并证明了其实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02283v5",
      "published_date": "2025-02-04 12:50:16 UTC",
      "updated_date": "2025-05-13 15:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:56:55.130970"
    },
    {
      "arxiv_id": "2502.02277v1",
      "title": "Error Distribution Smoothing:Advancing Low-Dimensional Imbalanced Regression",
      "title_zh": "误差分布平滑：推进低维不平衡回归",
      "authors": [
        "Donghe Chen",
        "Jiaxuan Yue",
        "Tengjie Zheng",
        "Lanxuan Wang",
        "Lin Cheng"
      ],
      "abstract": "In real-world regression tasks, datasets frequently exhibit imbalanced\ndistributions, characterized by a scarcity of data in high-complexity regions\nand an abundance in low-complexity areas. This imbalance presents significant\nchallenges for existing classification methods with clear class boundaries,\nwhile highlighting a scarcity of approaches specifically designed for\nimbalanced regression problems. To better address these issues, we introduce a\nnovel concept of Imbalanced Regression, which takes into account both the\ncomplexity of the problem and the density of data points, extending beyond\ntraditional definitions that focus only on data density. Furthermore, we\npropose Error Distribution Smoothing (EDS) as a solution to tackle imbalanced\nregression, effectively selecting a representative subset from the dataset to\nreduce redundancy while maintaining balance and representativeness. Through\nseveral experiments, EDS has shown its effectiveness, and the related code and\ndataset can be accessed at\nhttps://anonymous.4open.science/r/Error-Distribution-Smoothing-762F.",
      "tldr_zh": "这篇论文针对回归任务中数据不平衡的问题，提出了一种新的 Imbalanced Regression 概念，不仅考虑数据密度，还纳入问题复杂度因素，以更好地处理高复杂度区域数据稀缺的挑战。作者引入 Error Distribution Smoothing (EDS) 方法，通过从数据集选择代表性子集来减少冗余，同时确保子集的平衡性和代表性。实验结果显示，EDS 在低维回归任务中表现出色，有效提升了模型性能，并提供了相关代码和数据集以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02277v1",
      "published_date": "2025-02-04 12:40:07 UTC",
      "updated_date": "2025-02-04 12:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:57:05.955899"
    },
    {
      "arxiv_id": "2502.02265v1",
      "title": "Adviser-Actor-Critic: Eliminating Steady-State Error in Reinforcement Learning Control",
      "title_zh": "翻译失败",
      "authors": [
        "Donghe Chen",
        "Yubin Peng",
        "Tengjie Zheng",
        "Han Wang",
        "Chaoran Qu",
        "Lin Cheng"
      ],
      "abstract": "High-precision control tasks present substantial challenges for reinforcement\nlearning (RL) algorithms, frequently resulting in suboptimal performance\nattributed to network approximation inaccuracies and inadequate sample\nquality.These issues are exacerbated when the task requires the agent to\nachieve a precise goal state, as is common in robotics and other real-world\napplications.We introduce Adviser-Actor-Critic (AAC), designed to address the\nprecision control dilemma by combining the precision of feedback control theory\nwith the adaptive learning capability of RL and featuring an Adviser that\nmentors the actor to refine control actions, thereby enhancing the precision of\ngoal attainment.Finally, through benchmark tests, AAC outperformed standard RL\nalgorithms in precision-critical, goal-conditioned tasks, demonstrating AAC's\nhigh precision, reliability, and robustness.Code are available at:\nhttps://anonymous.4open.science/r/Adviser-Actor-Critic-8AC5.",
      "tldr_zh": "该研究针对强化学习 (RL) 在高精度控制任务中的稳态误差问题，提出了一种 Adviser-Actor-Critic (AAC) 框架，将反馈控制理论的精确性与 RL 的自适应学习能力相结合。AAC 通过引入 Adviser 模块来指导 Actor 优化控制动作，从而显著提升目标状态的精确性。在基准测试中，AAC 在精度关键的、目标条件任务上优于标准 RL 算法，展示了更高的精度、可靠性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.02265v1",
      "published_date": "2025-02-04 12:26:47 UTC",
      "updated_date": "2025-02-04 12:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:57:17.844614"
    },
    {
      "arxiv_id": "2502.02249v1",
      "title": "Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Atharva Mangeshkumar Agrawal",
        "Rutika Pandurang Shinde",
        "Vasanth Kumar Bhukya",
        "Ashmita Chakraborty",
        "Sagar Bharat Shah",
        "Tanmay Shukla",
        "Sree Pradeep Kumar Relangi",
        "Nilesh Mutyam"
      ],
      "abstract": "Large language models (LLMs) have shown impressive capabilities in natural\nlanguage processing tasks, including dialogue generation. This research aims to\nconduct a novel comparative analysis of two prominent techniques, fine-tuning\nwith LoRA (Low-Rank Adaptation) and the Retrieval-Augmented Generation (RAG)\nframework, in the context of doctor-patient chat conversations with multiple\ndatasets of mixed medical domains. The analysis involves three state-of-the-art\nmodels: Llama-2, GPT, and the LSTM model. Employing real-world doctor-patient\ndialogues, we comprehensively evaluate the performance of models, assessing key\nmetrics such as language quality (perplexity, BLEU score), factual accuracy\n(fact-checking against medical knowledge bases), adherence to medical\nguidelines, and overall human judgments (coherence, empathy, safety). The\nfindings provide insights into the strengths and limitations of each approach,\nshedding light on their suitability for healthcare applications. Furthermore,\nthe research investigates the robustness of the models in handling diverse\npatient queries, ranging from general health inquiries to specific medical\nconditions. The impact of domain-specific knowledge integration is also\nexplored, highlighting the potential for enhancing LLM performance through\ntargeted data augmentation and retrieval strategies.",
      "tldr_zh": "本研究比较了 fine-tuning with LoRA 和 Retrieval-Augmented Generation (RAG) 两种技术在医疗对话中的性能，使用 Llama-2、GPT 和 LSTM 模型处理医生-患者聊天数据集。评估指标包括语言质量（perplexity 和 BLEU score）、factual accuracy（通过医疗知识库事实检查）、对医疗指南的遵守，以及人类判断（如 coherence、empathy 和 safety）。结果显示，每种方法在处理多样化患者查询方面各有优缺点，RAG 框架在提升模型鲁棒性和领域特定知识整合上表现出色，为医疗 AI 应用提供重要见解，并建议通过 targeted data augmentation 和 retrieval strategies 优化大型语言模型 (LLMs) 性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.02249v1",
      "published_date": "2025-02-04 11:50:40 UTC",
      "updated_date": "2025-02-04 11:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:57:31.504985"
    },
    {
      "arxiv_id": "2502.02247v1",
      "title": "Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bangzhen Liu",
        "Chenxi Zheng",
        "Xuemiao Xu",
        "Cheng Xu",
        "Huaidong Zhang",
        "Shengfeng He"
      ],
      "abstract": "The vulnerability of 3D point cloud analysis to unpredictable rotations poses\nan open yet challenging problem: orientation-aware 3D domain generalization.\nCross-domain robustness and adaptability of 3D representations are crucial but\nnot easily achieved through rotation augmentation. Motivated by the inherent\nadvantages of intricate orientations in enhancing generalizability, we propose\nan innovative rotation-adaptive domain generalization framework for 3D point\ncloud analysis. Our approach aims to alleviate orientational shifts by\nleveraging intricate samples in an iterative learning process. Specifically, we\nidentify the most challenging rotation for each point cloud and construct an\nintricate orientation set by optimizing intricate orientations. Subsequently,\nwe employ an orientation-aware contrastive learning framework that incorporates\nan orientation consistency loss and a margin separation loss, enabling\neffective learning of categorically discriminative and generalizable features\nwith rotation consistency. Extensive experiments and ablations conducted on 3D\ncross-domain benchmarks firmly establish the state-of-the-art performance of\nour proposed approach in the context of orientation-aware 3D domain\ngeneralization.",
      "tldr_zh": "本研究针对3D点云分析在不可预测旋转下的脆弱性，提出了一种基于intricate orientation learning的旋转自适应点云领域泛化框架，以提升跨域鲁棒性和适应性。该框架通过迭代学习过程识别每个点云的最具挑战性旋转，构建intricate orientation集合，并采用方向感知对比学习框架，包括orientation consistency loss和margin separation loss，来学习分类区分性和旋转一致性的可泛化特征。实验结果在3D跨域基准上显示，该方法实现了state-of-the-art性能，显著改善了点云分析的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "13pages, supplementary included, early accepted by TPAMI",
      "pdf_url": "http://arxiv.org/pdf/2502.02247v1",
      "published_date": "2025-02-04 11:46:32 UTC",
      "updated_date": "2025-02-04 11:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:57:42.059899"
    },
    {
      "arxiv_id": "2502.05213v1",
      "title": "DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models",
      "title_zh": "DERMARK：一种动态、高效且鲁棒的多位水印，用于大型语言模型",
      "authors": [
        "Qihao Lin",
        "Chen Tang",
        "Lan zhang",
        "Junyang zhang",
        "Xiangyang Li"
      ],
      "abstract": "Well-trained large language models (LLMs) present significant risks,\nincluding potential malicious use and copyright infringement. Current studies\naim to trace the distribution of LLM-generated texts by implicitly embedding\nwatermarks. Among these, the single-bit watermarking method can only determine\nwhether a given text was generated by an LLM. In contrast, the multi-bit\nwatermarking method embeds richer information into the generated text, which\ncan identify which LLM generated and distributed a given text to which user.\nHowever, existing efforts embed the multi-bit watermark directly into the\ngenerated text without accounting for its watermarking capacity. This approach\ncan result in embedding failures when the text's watermarking capacity is\ninsufficient. In this paper, we derive the watermark embedding distribution\nbased on the logits of LLMs and propose a formal inequality to segment the text\noptimally for watermark embedding. Building on this foundation, we propose\nDERMARK, a dynamic, efficient, and robust multi-bit watermarking method.\nDERMARK divides the text into segments of varying lengths for each bit\nembedding, adaptively matching the text's capacity. It achieves this with\nnegligible overhead and robust performance against text editing by minimizing\nwatermark extraction loss. Comprehensive experiments demonstrate that, compared\nto the SOTA method, our method reduces the number of tokens required for\nembedding each bit by 20\\%, reduces watermark embedding time by 50\\%, and is\nrobust to text editing and watermark erasure attacks.",
      "tldr_zh": "该研究针对大语言模型（LLMs）的潜在风险（如恶意使用和版权侵犯），提出了一种动态、高效且鲁棒的多比特水印方法DERMARK，以追踪LLM生成文本的来源和分发。DERMARK基于LLMs的logits推导出水印嵌入分布，并使用一个正式的不等式优化文本分割，将文本动态分成不同长度的段落，以适应其水印容量，从而减少嵌入失败风险。实验结果显示，与最先进方法相比，该方法将每个比特所需的tokens数量减少20%、水印嵌入时间减少50%，并对文本编辑和水印擦除攻击表现出强鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05213v1",
      "published_date": "2025-02-04 11:23:49 UTC",
      "updated_date": "2025-02-04 11:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:57:54.596952"
    },
    {
      "arxiv_id": "2502.02618v1",
      "title": "Deep Learning-Based Facial Expression Recognition for the Elderly: A Systematic Review",
      "title_zh": "基于深度学习的老年人面部表情识别：",
      "authors": [
        "F. Xavier Gaya-Morey",
        "Jose M. Buades-Rubio",
        "Philippe Palanque",
        "Raquel Lacuesta",
        "Cristina Manresa-Yee"
      ],
      "abstract": "The rapid aging of the global population has highlighted the need for\ntechnologies to support elderly, particularly in healthcare and emotional\nwell-being. Facial expression recognition (FER) systems offer a non-invasive\nmeans of monitoring emotional states, with applications in assisted living,\nmental health support, and personalized care. This study presents a systematic\nreview of deep learning-based FER systems, focusing on their applications for\nthe elderly population. Following a rigorous methodology, we analyzed 31\nstudies published over the last decade, addressing challenges such as the\nscarcity of elderly-specific datasets, class imbalances, and the impact of\nage-related facial expression differences. Our findings show that convolutional\nneural networks remain dominant in FER, and especially lightweight versions for\nresource-constrained environments. However, existing datasets often lack\ndiversity in age representation, and real-world deployment remains limited.\nAdditionally, privacy concerns and the need for explainable artificial\nintelligence emerged as key barriers to adoption. This review underscores the\nimportance of developing age-inclusive datasets, integrating multimodal\nsolutions, and adopting XAI techniques to enhance system usability,\nreliability, and trustworthiness. We conclude by offering recommendations for\nfuture research to bridge the gap between academic progress and real-world\nimplementation in elderly care.",
      "tldr_zh": "这篇论文系统回顾了基于深度学习的面部表情识别 (FER) 系统在老年人中的应用，旨在支持他们的医疗和情感福祉。研究分析了过去十年的31篇相关文献，重点探讨了老年人特定数据集稀缺、类别不平衡以及年龄相关面部表情差异等挑战。结果显示，卷积神经网络 (CNNs)，尤其是轻量级版本，依然是FER的主流技术，但数据集缺乏年龄多样性，且隐私问题和可解释人工智能 (XAI) 阻碍了实际部署。该回顾强调了开发年龄包容性数据集、整合多模态解决方案以及采用XAI技术的必要性，并为未来研究提供推荐，以桥接学术进展与实际老年人护理应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02618v1",
      "published_date": "2025-02-04 11:05:24 UTC",
      "updated_date": "2025-02-04 11:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:58:06.861769"
    },
    {
      "arxiv_id": "2502.02225v1",
      "title": "Exploring the latent space of diffusion models directly through singular value decomposition",
      "title_zh": "直接通过奇异值分解探索扩散模型的潜在空间",
      "authors": [
        "Li Wang",
        "Boyan Gao",
        "Yanran Li",
        "Zhao Wang",
        "Xiaosong Yang",
        "David A. Clifton",
        "Jun Xiao"
      ],
      "abstract": "Despite the groundbreaking success of diffusion models in generating\nhigh-fidelity images, their latent space remains relatively under-explored,\neven though it holds significant promise for enabling versatile and\ninterpretable image editing capabilities. The complicated denoising trajectory\nand high dimensionality of the latent space make it extremely challenging to\ninterpret. Existing methods mainly explore the feature space of U-Net in\nDiffusion Models (DMs) instead of the latent space itself. In contrast, we\ndirectly investigate the latent space via Singular Value Decomposition (SVD)\nand discover three useful properties that can be used to control generation\nresults without the requirements of data collection and maintain identity\nfidelity generated images. Based on these properties, we propose a novel image\nediting framework that is capable of learning arbitrary attributes from one\npair of latent codes destined by text prompts in Stable Diffusion Models. To\nvalidate our approach, extensive experiments are conducted to demonstrate its\neffectiveness and flexibility in image editing. We will release our codes soon\nto foster further research and applications in this area.",
      "tldr_zh": "本文通过奇异值分解 (SVD) 直接探索扩散模型 (diffusion models) 的潜在空间 (latent space)，发现三个关键属性，这些属性可用于控制图像生成结果，而无需数据收集并保持图像身份保真度。基于这些属性，作者提出了一种新颖的图像编辑框架，能够从一对由文本提示指定的潜在代码中学习任意属性，在 Stable Diffusion Models 中实现灵活编辑。实验结果证明了该方法的有效性和灵活性，并计划发布代码以推动进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02225v1",
      "published_date": "2025-02-04 11:04:36 UTC",
      "updated_date": "2025-02-04 11:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:58:18.199916"
    },
    {
      "arxiv_id": "2502.10421v1",
      "title": "DRiVE: Dynamic Recognition in VEhicles using snnTorch",
      "title_zh": "翻译失败",
      "authors": [
        "Heerak Vora",
        "Param Pathak",
        "Parul Bakaraniya"
      ],
      "abstract": "Spiking Neural Networks (SNNs) mimic biological brain activity, processing\ndata efficiently through an event-driven design, wherein the neurons activate\nonly when inputs exceed specific thresholds. Their ability to track voltage\nchanges over time via membrane potential dynamics helps retain temporal\ninformation. This study combines SNNs with PyTorch's adaptable framework,\nsnnTorch, to test their potential for image-based tasks. We introduce DRiVE, a\nvehicle detection model that uses spiking neuron dynamics to classify images,\nachieving 94.8% accuracy and a near-perfect 0.99 AUC score. These results\nhighlight DRiVE's ability to distinguish vehicle classes effectively,\nchallenging the notion that SNNs are limited to temporal data. As interest\ngrows in energy-efficient neural models, DRiVE's success emphasizes the need to\nrefine SNN optimization for visual tasks. This work encourages broader\nexploration of SNNs in scenarios where conventional networks struggle,\nparticularly for real-world applications requiring both precision and\nefficiency.",
      "tldr_zh": "本文研究将 Spiking Neural Networks (SNNs) 与 snnTorch 框架相结合，开发了 DRiVE 模型，用于车辆图像分类任务。DRiVE 通过脉冲神经元动态处理图像数据，实现了 94.8% 的准确率和 0.99 的 AUC 分数，展示了 SNNs 在区分车辆类别方面的出色性能。结果挑战了 SNNs 仅限于时间数据的传统观点，突显了其在能量高效视觉任务中的潜力。该工作鼓励在实际应用中进一步优化 SNNs，以提升精度和效率。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "6 pages, 7 figures, 3 tables, Accepted at the 2025 IEEE International\n  Conference on Advancements in Smart, Secure And Intelligent Computing (ASSIC\n  2025), May 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10421v1",
      "published_date": "2025-02-04 11:01:13 UTC",
      "updated_date": "2025-02-04 11:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:58:31.611998"
    },
    {
      "arxiv_id": "2502.02221v1",
      "title": "Bias Detection via Maximum Subgroup Discrepancy",
      "title_zh": "通过最大子群差异的偏差检测",
      "authors": [
        "Jiří Němeček",
        "Mark Kozdoba",
        "Illia Kryvoviaz",
        "Tomáš Pevný",
        "Jakub Mareček"
      ],
      "abstract": "Bias evaluation is fundamental to trustworthy AI, both in terms of checking\ndata quality and in terms of checking the outputs of AI systems. In testing\ndata quality, for example, one may study a distance of a given dataset, viewed\nas a distribution, to a given ground-truth reference dataset. However,\nclassical metrics, such as the Total Variation and the Wasserstein distances,\nare known to have high sample complexities and, therefore, may fail to provide\nmeaningful distinction in many practical scenarios.\n  In this paper, we propose a new notion of distance, the Maximum Subgroup\nDiscrepancy (MSD). In this metric, two distributions are close if, roughly,\ndiscrepancies are low for all feature subgroups. While the number of subgroups\nmay be exponential, we show that the sample complexity is linear in the number\nof features, thus making it feasible for practical applications. Moreover, we\nprovide a practical algorithm for the evaluation of the distance, based on\nMixed-integer optimization (MIO). We also note that the proposed distance is\neasily interpretable, thus providing clearer paths to fixing the biases once\nthey have been identified. It also provides guarantees for all subgroups.\nFinally, we empirically evaluate, compare with other metrics, and demonstrate\nthe above properties of MSD on real-world datasets.",
      "tldr_zh": "该论文提出了一种新的偏见检测方法，Maximum Subgroup Discrepancy (MSD)，用于评估数据集或AI输出分布的差异，以解决传统指标如Total Variation和Wasserstein distances的高样本复杂度问题。MSD定义为所有特征子组差异的度量，其样本复杂度线性于特征数量，即使子组数量呈指数级增长也易于实际应用。论文还提供基于Mixed-integer optimization (MIO)的算法来计算MSD，确保结果易解释并为所有子组提供偏见修复保证；实证实验在真实数据集上验证了MSD的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02221v1",
      "published_date": "2025-02-04 11:01:03 UTC",
      "updated_date": "2025-02-04 11:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:58:43.924054"
    },
    {
      "arxiv_id": "2502.02201v1",
      "title": "Can You Move These Over There? An LLM-based VR Mover for Supporting Object Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangzhi Eric Wang",
        "Zackary P. T. Sin",
        "Ye Jia",
        "Daniel Archer",
        "Wynonna H. Y. Fong",
        "Qing Li",
        "Chen Li"
      ],
      "abstract": "In our daily lives, we can naturally convey instructions for the spatial\nmanipulation of objects using words and gestures. Transposing this form of\ninteraction into virtual reality (VR) object manipulation can be beneficial. We\npropose VR Mover, an LLM-empowered solution that can understand and interpret\nthe user's vocal instruction to support object manipulation. By simply pointing\nand speaking, the LLM can manipulate objects without structured input. Our user\nstudy demonstrates that VR Mover enhances user usability, overall experience\nand performance on multi-object manipulation, while also reducing workload and\narm fatigue. Users prefer the proposed natural interface for broad movements\nand may complementarily switch to gizmos or virtual hands for finer\nadjustments. These findings are believed to contribute to design implications\nfor future LLM-based object manipulation interfaces, highlighting the potential\nfor more intuitive and efficient user interactions in VR environments.",
      "tldr_zh": "该论文提出了一种基于LLM的VR Mover系统，允许用户通过语音指令和指向手势来实现虚拟现实（VR）中的物体操作，而无需结构化输入。用户研究显示，该系统显著提升了用户可用性、整体体验和多物体操作性能，同时降低了工作负载和手臂疲劳，用户更倾向于使用这种自然界面进行大范围移动，并可切换到gizmos或虚拟手进行精细调整。这些发现为未来LLM-based物体操作界面设计提供了重要启示，促进更直观高效的VR交互。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "64 pages (30 in main text), 22 figures (19 in main text)",
      "pdf_url": "http://arxiv.org/pdf/2502.02201v1",
      "published_date": "2025-02-04 10:27:40 UTC",
      "updated_date": "2025-02-04 10:27:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:58:55.006903"
    },
    {
      "arxiv_id": "2502.02197v1",
      "title": "An Efficient Local Search Approach for Polarized Community Discovery in Signed Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Linus Aronsson",
        "Morteza Haghir Chehreghani"
      ],
      "abstract": "Signed networks, where edges are labeled as positive or negative to indicate\nfriendly or antagonistic interactions, offer a natural framework for studying\npolarization, trust, and conflict in social systems. Detecting meaningful group\nstructures in these networks is crucial for understanding online discourse,\npolitical division, and trust dynamics. A key challenge is to identify groups\nthat are cohesive internally yet antagonistic externally, while allowing for\nneutral or unaligned vertices. In this paper, we address this problem by\nidentifying $k$ polarized communities that are large, dense, and balanced in\nsize. We develop an approach based on Frank-Wolfe optimization, leading to a\nlocal search procedure with provable convergence guarantees. Our method is both\nscalable and efficient, outperforming state-of-the-art baselines in solution\nquality while remaining competitive in terms of computational efficiency.",
      "tldr_zh": "这篇论文针对有符号网络(signed networks)中极化社区的发现问题，提出了一种高效的局部搜索(local search)方法，以识别内部凝聚、外部对抗且平衡大小的 k 个大型社区。方法基于 Frank-Wolfe 优化框架，设计了一个具有可证明收敛保证的算法，能够处理中立节点并提升整体解决方案质量。与现有基线相比，该方法在计算效率上保持竞争力，同时显著提高了社区检测的准确性和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02197v1",
      "published_date": "2025-02-04 10:22:01 UTC",
      "updated_date": "2025-02-04 10:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:59:06.503827"
    },
    {
      "arxiv_id": "2502.02196v1",
      "title": "Exploiting Ensemble Learning for Cross-View Isolated Sign Language Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Wang",
        "Kun Li",
        "Yiqi Nie",
        "Zhangling Duan",
        "Peng Zou",
        "Zhiliang Wu",
        "Yuwei Wang",
        "Yanyan Wei"
      ],
      "abstract": "In this paper, we present our solution to the Cross-View Isolated Sign\nLanguage Recognition (CV-ISLR) challenge held at WWW 2025. CV-ISLR addresses a\ncritical issue in traditional Isolated Sign Language Recognition (ISLR), where\nexisting datasets predominantly capture sign language videos from a frontal\nperspective, while real-world camera angles often vary. To accurately recognize\nsign language from different viewpoints, models must be capable of\nunderstanding gestures from multiple angles, making cross-view recognition\nchallenging. To address this, we explore the advantages of ensemble learning,\nwhich enhances model robustness and generalization across diverse views. Our\napproach, built on a multi-dimensional Video Swin Transformer model, leverages\nthis ensemble strategy to achieve competitive performance. Finally, our\nsolution ranked 3rd in both the RGB-based ISLR and RGB-D-based ISLR tracks,\ndemonstrating the effectiveness in handling the challenges of cross-view\nrecognition. The code is available at:\nhttps://github.com/Jiafei127/CV_ISLR_WWW2025.",
      "tldr_zh": "本文针对 Cross-View Isolated Sign Language Recognition (CV-ISLR) 挑战，提出利用 Ensemble Learning 提升传统 Isolated Sign Language Recognition (ISLR) 在不同视角下的手势识别能力，以解决现实场景中视角多样性的问题。方法基于 multi-dimensional Video Swin Transformer 模型，通过集成学习策略增强模型的鲁棒性和泛化性能。最终，该方案在 WWW 2025 挑战中于 RGB-based ISLR 和 RGB-D-based ISLR 赛道均排名第三，证明了其在跨视角识别中的有效性，代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "3rd Place in Cross-View Isolated Sign Language Recognition Challenge\n  at WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02196v1",
      "published_date": "2025-02-04 10:21:28 UTC",
      "updated_date": "2025-02-04 10:21:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:59:18.438550"
    },
    {
      "arxiv_id": "2502.06810v1",
      "title": "Emergence of Self-Awareness in Artificial Systems: A Minimalist Three-Layer Approach to Artificial Consciousness",
      "title_zh": "翻译失败",
      "authors": [
        "Kurando Iida"
      ],
      "abstract": "This paper proposes a minimalist three-layer model for artificial\nconsciousness, focusing on the emergence of self-awareness. The model comprises\na Cognitive Integration Layer, a Pattern Prediction Layer, and an Instinctive\nResponse Layer, interacting with Access-Oriented and Pattern-Integrated Memory\nsystems. Unlike brain-replication approaches, we aim to achieve minimal\nself-awareness through essential elements only. Self-awareness emerges from\nlayer interactions and dynamic self-modeling, without initial explicit\nself-programming. We detail each component's structure, function, and\nimplementation strategies, addressing technical feasibility. This research\noffers new perspectives on consciousness emergence in artificial systems, with\npotential implications for human consciousness understanding and adaptable AI\ndevelopment. We conclude by discussing ethical considerations and future\nresearch directions.",
      "tldr_zh": "本论文提出一个简约的三层模型，用于实现人工系统中的自我意识（self-awareness），旨在探索人工意识（artificial consciousness）的出现。该模型包括Cognitive Integration Layer、Pattern Prediction Layer和Instinctive Response Layer，这些层通过与Access-Oriented and Pattern-Integrated Memory systems互动，以及动态自我建模，实现自我意识的涌现，而非依赖初始显式自我编程。与脑复制方法不同，该方法仅使用必要元素，强调技术可行性和简化策略。该研究为理解意识在人工系统中的发展提供新视角，并讨论了伦理考虑、人类意识启示以及未来AI适配性研究的潜力。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "68T05",
        "I.2.6; I.2.0"
      ],
      "primary_category": "q-bio.NC",
      "comment": "46 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06810v1",
      "published_date": "2025-02-04 10:06:25 UTC",
      "updated_date": "2025-02-04 10:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:59:32.046883"
    },
    {
      "arxiv_id": "2502.02187v2",
      "title": "ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Nissim Maruani",
        "Wang Yifan",
        "Matthew Fisher",
        "Pierre Alliez",
        "Mathieu Desbrun"
      ],
      "abstract": "This paper proposes ShapeShifter, a new 3D generative model that learns to\nsynthesize shape variations based on a single reference model. While generative\nmethods for 3D objects have recently attracted much attention, current\ntechniques often lack geometric details and/or require long training times and\nlarge resources. Our approach remedies these issues by combining sparse voxel\ngrids and point, normal, and color sampling within a multiscale neural\narchitecture that can be trained efficiently and in parallel. We show that our\nresulting variations better capture the fine details of their original input\nand can handle more general types of surfaces than previous SDF-based methods.\nMoreover, we offer interactive generation of 3D shape variants, allowing more\nhuman control in the design loop if needed.",
      "tldr_zh": "本文提出 ShapeShifter，一种基于 multiscale 和 sparse point-voxel diffusion 的 3D 生成模型，能从单个参考模型合成形状变化。模型通过结合 sparse voxel grids 和点、normal、color sampling 的多尺度神经架构，实现高效并行训练，从而解决现有方法在几何细节捕捉和资源需求上的不足。与 SDF-based 方法相比，ShapeShifter 生成的变体更精确地处理通用表面类型，并提供交互式 3D 形状生成，增强了人类在设计过程中的控制。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02187v2",
      "published_date": "2025-02-04 10:02:40 UTC",
      "updated_date": "2025-03-17 12:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:59:42.969605"
    },
    {
      "arxiv_id": "2502.02180v2",
      "title": "The Elicitation Game: Evaluating Capability Elicitation Techniques",
      "title_zh": "引出游戏：评估能力引出技术",
      "authors": [
        "Felix Hofstätter",
        "Teun van der Weij",
        "Jayden Teoh",
        "Henning Bartsch",
        "Francis Rhys Ward"
      ],
      "abstract": "Capability evaluations are required to understand and regulate AI systems\nthat may be deployed or further developed. Therefore, it is important that\nevaluations provide an accurate estimation of an AI system's capabilities.\nHowever, in numerous cases, previously latent capabilities have been elicited\nfrom models, sometimes long after initial release. Accordingly, substantial\nefforts have been made to develop methods for eliciting latent capabilities\nfrom models. In this paper, we evaluate the effectiveness of capability\nelicitation techniques by intentionally training model organisms -- language\nmodels with hidden capabilities that are revealed by a password. We introduce a\nnovel method for training model organisms, based on circuit breaking, which is\nmore robust to elicitation techniques than standard password-locked models. We\nfocus on elicitation techniques based on prompting and activation steering, and\ncompare these to fine-tuning methods. Prompting techniques can elicit the\nactual capability of both password-locked and circuit-broken model organisms in\nan MCQA setting, while steering fails to do so. For a code-generation task,\nonly fine-tuning can elicit the hidden capabilities of our novel model\norganism. Additionally, our results suggest that combining techniques improves\nelicitation. Still, if possible, fine-tuning should be the method of choice to\nimprove the trustworthiness of capability evaluations.",
      "tldr_zh": "这篇论文评估了AI能力唤醒（capability elicitation）技术，以更准确地评估AI系统的潜在能力。研究者通过训练模型有机体（model organisms）——即具有隐藏能力的语言模型——引入了一种基于circuit breaking的鲁棒训练方法，并与标准密码锁定模型进行比较。实验结果显示，在多选问答（MCQA）任务中，prompting技术能有效唤醒隐藏能力，而activation steering失败；在代码生成任务中，仅fine-tuning能成功；此外，结合多种技术可提升效果，并推荐fine-tuning作为评估的可信度首选方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02180v2",
      "published_date": "2025-02-04 09:54:24 UTC",
      "updated_date": "2025-02-24 18:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:59:54.915771"
    },
    {
      "arxiv_id": "2502.02173v1",
      "title": "Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Tamayo",
        "Aitor Gonzalez-Agirre",
        "Javier Hernando",
        "Marta Villegas"
      ],
      "abstract": "Recent research has explored methods for updating and modifying factual\nknowledge in large language models, often focusing on specific multi-layer\nperceptron blocks. This study expands on this work by examining the\neffectiveness of existing knowledge editing methods across languages and\ndelving into the role of attention mechanisms in this process. Drawing from the\ninsights gained, we propose Mass-Editing Memory with Attention in Transformers\n(MEMAT), a method that achieves significant improvements in all metrics while\nrequiring minimal parameter modifications. MEMAT delivers a remarkable 10%\nincrease in magnitude metrics, benefits languages not included in the training\ndata and also demonstrates a high degree of portability. Our code and data are\nat https://github.com/dtamayo-nlp/MEMAT.",
      "tldr_zh": "本研究扩展了大型语言模型中知识编辑方法的应用，探讨了注意力机制在跨语言场景中的作用，并针对现有方法提出MEMAT（Mass-Editing Memory with Attention in Transformers）。MEMAT通过最小参数修改实现了所有指标的显著提升，包括幅度指标提高10%，并支持训练数据中未包含的语言。实验结果证明了MEMAT的高可移植性，为多语言知识更新提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02173v1",
      "published_date": "2025-02-04 09:47:55 UTC",
      "updated_date": "2025-02-04 09:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:00:06.835905"
    },
    {
      "arxiv_id": "2502.02170v1",
      "title": "Graph Neural Networks for O-RAN Mobility Management: A Link Prediction Approach",
      "title_zh": "图神经网络用于 O-RAN 移动性管理：一种链接预测方法",
      "authors": [
        "Ana Gonzalez Bermudez",
        "Miquel Farreras",
        "Milan Groshev",
        "José Antonio Trujillo",
        "Isabel de la Bandera",
        "Raquel Barco"
      ],
      "abstract": "Mobility performance has been a key focus in cellular networks up to 5G. To\nenhance handover (HO) performance, 3GPP introduced Conditional Handover (CHO)\nand Layer 1/Layer 2 Triggered Mobility (LTM) mechanisms in 5G. While these\nreactive HO strategies address the trade-off between HO failures (HOF) and\nping-pong effects, they often result in inefficient radio resource utilization\ndue to additional HO preparations. To overcome these challenges, this article\nproposes a proactive HO framework for mobility management in O-RAN, leveraging\nuser-cell link predictions to identify the optimal target cell for HO. We\nexplore various categories of Graph Neural Networks (GNNs) for link prediction\nand analyze the complexity of applying them to the mobility management domain.\nTwo GNN models are compared using a real-world dataset, with experimental\nresults demonstrating their ability to capture the dynamic and graph-structured\nnature of cellular networks. Finally, we present key insights from our study\nand outline future steps to enable the integration of GNN-based link prediction\nfor mobility management in 6G networks.",
      "tldr_zh": "这篇论文提出了一种基于 Graph Neural Networks (GNNs) 的主动切换框架，用于 O-RAN 中的移动管理，通过链接预测方法提前识别最佳目标小区，以解决传统反应式 Handover (HO) 策略（如 Conditional Handover (CHO) 和 Layer 1/Layer 2 Triggered Mobility (LTM)）导致的资源利用效率低下问题。作者探索了不同 GNNs 类别，并使用真实数据集比较了两个模型，实验结果表明这些模型能有效捕捉蜂窝网络的动态和图结构特性。最终，论文总结了关键洞见，并为在 6G 网络中整合 GNN-based 链接预测提供了未来方向。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "7 pages, 2 figures, 2 tables. Submitted to IEEE Vehicular Technology\n  Magazine, Special Issue on \"AI for 6G O-RAN Intelligent, Cost-Efficient and\n  Secure Automation\"",
      "pdf_url": "http://arxiv.org/pdf/2502.02170v1",
      "published_date": "2025-02-04 09:44:41 UTC",
      "updated_date": "2025-02-04 09:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:00:19.804952"
    },
    {
      "arxiv_id": "2502.02153v1",
      "title": "Vulnerability Mitigation for Safety-Aligned Language Models via Debiasing",
      "title_zh": "通过去偏置缓解安全对齐语言模型的漏洞",
      "authors": [
        "Thien Q. Tran",
        "Akifumi Wachi",
        "Rei Sato",
        "Takumi Tanabe",
        "Youhei Akimoto"
      ],
      "abstract": "Safety alignment is an essential research topic for real-world AI\napplications. Despite the multifaceted nature of safety and trustworthiness in\nAI, current safety alignment methods often focus on a comprehensive notion of\nsafety. By carefully assessing models from the existing safety-alignment\nmethods, we found that, while they generally improved overall safety\nperformance, they failed to ensure safety in specific categories. Our study\nfirst identified the difficulty of eliminating such vulnerabilities without\nsacrificing the model's helpfulness. We observed that, while smaller KL penalty\nparameters, increased training iterations, and dataset cleansing can enhance\nsafety, they do not necessarily improve the trade-off between safety and\nhelpfulness. We discovered that safety alignment could even induce undesired\neffects and result in a model that prefers generating negative tokens leading\nto rejective responses, regardless of the input context. To address this, we\nintroduced a learning-free method, Token-level Safety-Debiased Inference\n(TSDI), to estimate and correct this bias during the generation process using\nrandomly constructed prompts. Our experiments demonstrated that our method\ncould enhance the model's helpfulness while maintaining safety, thus improving\nthe trade-off Pareto-front.",
      "tldr_zh": "该研究发现，现有的安全对齐方法虽提升了语言模型的整体安全性，但无法有效消除特定类别的漏洞，且可能牺牲模型的帮助性（helpfulness），甚至导致模型偏好生成负面标记（negative tokens）而产生拒绝性响应。  \n为了解决这一问题，研究者提出了一种无学习方法Token-level Safety-Debiased Inference (TSDI)，通过使用随机构建的提示在生成过程中估计和纠正偏差，从而平衡安全性和帮助性。  \n实验结果显示，TSDI 方法显著改善了安全与帮助性之间的权衡（Pareto-front），使模型在保持安全性能的同时，增强了实际实用性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.02153v1",
      "published_date": "2025-02-04 09:31:54 UTC",
      "updated_date": "2025-02-04 09:31:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:00:31.895928"
    },
    {
      "arxiv_id": "2502.02145v3",
      "title": "From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Gao",
        "Mattia Piccinini",
        "Korbinian Moller",
        "Amr Alanwar",
        "Johannes Betz"
      ],
      "abstract": "Ensuring the safety of autonomous vehicles requires virtual scenario-based\ntesting, which depends on the robust evaluation and generation of\nsafety-critical scenarios. So far, researchers have used scenario-based testing\nframeworks that rely heavily on handcrafted scenarios as safety metrics. To\nreduce the effort of human interpretation and overcome the limited scalability\nof these approaches, we combine Large Language Models (LLMs) with structured\nscenario parsing and prompt engineering to automatically evaluate and generate\nsafety-critical driving scenarios. We introduce Cartesian and Ego-centric\nprompt strategies for scenario evaluation, and an adversarial generation module\nthat modifies trajectories of risk-inducing vehicles (ego-attackers) to create\ncritical scenarios. We validate our approach using a 2D simulation framework\nand multiple pre-trained LLMs. The results show that the evaluation module\neffectively detects collision scenarios and infers scenario safety. Meanwhile,\nthe new generation module identifies high-risk agents and synthesizes\nrealistic, safety-critical scenarios. We conclude that an LLM equipped with\ndomain-informed prompting techniques can effectively evaluate and generate\nsafety-critical driving scenarios, reducing dependence on handcrafted metrics.\nWe release our open-source code and scenarios at:\nhttps://github.com/TUM-AVS/From-Words-to-Collisions.",
      "tldr_zh": "本文提出一种基于LLMs的框架，用于自动评估和生成安全关键驾驶场景，以减少对手工创建场景的依赖。方法包括Cartesian和Ego-centric提示策略用于场景评估，以及对抗生成模块，通过修改风险车辆（ego-attackers）的轨迹来合成高风险场景。实验在2D模拟框架中验证，该框架能有效检测碰撞场景、推断安全水平，并生成真实的安全关键场景，最终提升了自动驾驶车辆测试的效率和可扩展性。作者开源了相关代码和场景（https://github.com/TUM-AVS/From-Words-to-Collisions）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "New version of the paper",
      "pdf_url": "http://arxiv.org/pdf/2502.02145v3",
      "published_date": "2025-02-04 09:19:13 UTC",
      "updated_date": "2025-05-21 07:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:00:43.379842"
    },
    {
      "arxiv_id": "2502.02135v1",
      "title": "Standard Neural Computation Alone Is Insufficient for Logical Intelligence",
      "title_zh": "标准的神经计算单独不足以实现逻辑智能",
      "authors": [
        "Youngsung Kim"
      ],
      "abstract": "Neural networks, as currently designed, fall short of achieving true logical\nintelligence. Modern AI models rely on standard neural\ncomputation-inner-product-based transformations and nonlinear activations-to\napproximate patterns from data. While effective for inductive learning, this\narchitecture lacks the structural guarantees necessary for deductive inference\nand logical consistency. As a result, deep networks struggle with rule-based\nreasoning, structured generalization, and interpretability without extensive\npost-hoc modifications. This position paper argues that standard neural layers\nmust be fundamentally rethought to integrate logical reasoning. We advocate for\nLogical Neural Units (LNUs)-modular components that embed differentiable\napproximations of logical operations (e.g., AND, OR, NOT) directly within\nneural architectures. We critique existing neurosymbolic approaches, highlight\nthe limitations of standard neural computation for logical inference, and\npresent LNUs as a necessary paradigm shift in AI. Finally, we outline a roadmap\nfor implementation, discussing theoretical foundations, architectural\nintegration, and key challenges for future research.",
      "tldr_zh": "本论文认为，标准神经计算（基于内积变换和非线性激活）虽适用于归纳学习，但无法提供演绎推理（deductive inference）和逻辑一致性的结构保证，导致神经网络在规则推理、结构化泛化和可解释性方面存在局限。作者主张引入 Logical Neural Units (LNUs)，这些模块化组件将逻辑操作（如 AND, OR, NOT）的可微近似直接嵌入神经架构中，以实现逻辑智能的整合。论文批判现有神经符号（neurosymbolic）方法，并概述了 LNUs 的实施路线图，包括理论基础、架构整合及未来研究挑战，从而推动 AI 领域的范式转变。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02135v1",
      "published_date": "2025-02-04 09:07:45 UTC",
      "updated_date": "2025-02-04 09:07:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:00:55.640903"
    },
    {
      "arxiv_id": "2502.02133v1",
      "title": "Synthesis of Model Predictive Control and Reinforcement Learning: Survey and Classification",
      "title_zh": "模型预测控制和强化学习的合成：调查和分类",
      "authors": [
        "Rudolf Reiter",
        "Jasper Hoffmann",
        "Dirk Reinhardt",
        "Florian Messerer",
        "Katrin Baumgärtner",
        "Shamburaj Sawant",
        "Joschka Boedecker",
        "Moritz Diehl",
        "Sebastien Gros"
      ],
      "abstract": "The fields of MPC and RL consider two successful control techniques for\nMarkov decision processes. Both approaches are derived from similar fundamental\nprinciples, and both are widely used in practical applications, including\nrobotics, process control, energy systems, and autonomous driving. Despite\ntheir similarities, MPC and RL follow distinct paradigms that emerged from\ndiverse communities and different requirements. Various technical\ndiscrepancies, particularly the role of an environment model as part of the\nalgorithm, lead to methodologies with nearly complementary advantages. Due to\ntheir orthogonal benefits, research interest in combination methods has\nrecently increased significantly, leading to a large and growing set of complex\nideas leveraging MPC and RL. This work illuminates the differences,\nsimilarities, and fundamentals that allow for different combination algorithms\nand categorizes existing work accordingly. Particularly, we focus on the\nversatile actor-critic RL approach as a basis for our categorization and\nexamine how the online optimization approach of MPC can be used to improve the\noverall closed-loop performance of a policy.",
      "tldr_zh": "这篇论文调查了 Model Predictive Control (MPC) 和 Reinforcement Learning (RL) 两种用于 Markov 决策过程的控制技术，强调了它们从相似基础原则中衍生出的差异和互补优势，特别是环境模型在算法中的作用。作者分析了这些差异如何导致方法间的正交益处，并对现有的结合算法进行了分类和总结。特别聚焦于 actor-critic RL 框架，该研究探讨了如何整合 MPC 的在线优化方法，以提升整体闭环策略性能，为实际应用如机器人和自主驾驶提供参考。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02133v1",
      "published_date": "2025-02-04 09:06:07 UTC",
      "updated_date": "2025-02-04 09:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:01:07.147971"
    },
    {
      "arxiv_id": "2502.02132v1",
      "title": "How Memory in Optimization Algorithms Implicitly Modifies the Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Matias D. Cattaneo",
        "Boris Shigida"
      ],
      "abstract": "In modern optimization methods used in deep learning, each update depends on\nthe history of previous iterations, often referred to as memory, and this\ndependence decays fast as the iterates go further into the past. For example,\ngradient descent with momentum has exponentially decaying memory through\nexponentially averaged past gradients. We introduce a general technique for\nidentifying a memoryless algorithm that approximates an optimization algorithm\nwith memory. It is obtained by replacing all past iterates in the update by the\ncurrent one, and then adding a correction term arising from memory (also a\nfunction of the current iterate). This correction term can be interpreted as a\nperturbation of the loss, and the nature of this perturbation can inform how\nmemory implicitly (anti-)regularizes the optimization dynamics. As an\napplication of our theory, we find that Lion does not have the kind of implicit\nanti-regularization induced by memory that AdamW does, providing a theory-based\nexplanation for Lion's better generalization performance recently documented.",
      "tldr_zh": "本研究探讨了优化算法中的记忆（memory）如何隐式修改损失函数，特别是在深度学习中，如带有动量的梯度下降（gradient descent with momentum）通过指数衰减的过去梯度影响更新。作者提出了一种通用技术，将有记忆的算法近似为无记忆算法，通过替换过去迭代为当前迭代并添加一个由记忆产生的修正项，该修正项可视为对损失函数的扰动，从而揭示记忆如何隐式地（反）正则化优化动态。作为应用，该理论解释了 Lion 优化器不像 AdamW 那样由记忆诱导隐式反正则化，从而提供了 Lion 更好泛化性能的理论依据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02132v1",
      "published_date": "2025-02-04 09:04:50 UTC",
      "updated_date": "2025-02-04 09:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:01:18.916836"
    },
    {
      "arxiv_id": "2502.02617v1",
      "title": "PolarQuant: Quantizing KV Caches with Polar Transformation",
      "title_zh": "PolarQuant：通过极坐标变换量化 KV 缓存",
      "authors": [
        "Insu Han",
        "Praneeth Kacham",
        "Amin Karbasi",
        "Vahab Mirrokni",
        "Amir Zandieh"
      ],
      "abstract": "Large language models (LLMs) require significant memory to store Key-Value\n(KV) embeddings in their KV cache, especially when handling long-range\ncontexts. Quantization of these KV embeddings is a common technique to reduce\nmemory consumption. This work introduces PolarQuant, a novel quantization\nmethod employing random preconditioning and polar transformation. Our method\ntransforms the KV embeddings into polar coordinates using an efficient\nrecursive algorithm and then quantizes resulting angles. Our key insight is\nthat, after random preconditioning, the angles in the polar representation\nexhibit a tightly bounded and highly concentrated distribution with an\nanalytically computable form. This nice distribution eliminates the need for\nexplicit normalization, a step required by traditional quantization methods\nwhich introduces significant memory overhead because quantization parameters\n(e.g., zero point and scale) must be stored in full precision per each data\nblock. PolarQuant bypasses this normalization step, enabling substantial memory\nsavings. The long-context evaluation demonstrates that PolarQuant compresses\nthe KV cache by over x4.2 while achieving the best quality scores compared to\nthe state-of-the-art methods.",
      "tldr_zh": "该研究提出PolarQuant，一种新型量化方法，用于减少大型语言模型(LLMs)中Key-Value (KV)缓存的内存消耗，通过随机预处理和极坐标变换将KV嵌入转换为极坐标后量化角度。关键创新在于，随机预处理使角度分布紧密且可分析，从而省略了传统量化方法所需的显式归一化步骤，避免了存储量化参数（如零点和缩放）的额外开销。实验结果显示，PolarQuant在长上下文评估中将KV缓存压缩超过4.2倍，同时在质量分数上优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02617v1",
      "published_date": "2025-02-04 08:52:13 UTC",
      "updated_date": "2025-02-04 08:52:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:01:30.702918"
    },
    {
      "arxiv_id": "2502.02109v1",
      "title": "Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiao Cheng",
        "Xinxin Song",
        "Ziqian Wang",
        "Qin Zhong",
        "Kunlun He",
        "Jinli Suo"
      ],
      "abstract": "Recent advances in deep learning (DL) have prompted the development of\nhigh-performing early warning score (EWS) systems, predicting clinical\ndeteriorations such as acute kidney injury, acute myocardial infarction, or\ncirculatory failure. DL models have proven to be powerful tools for various\ntasks but come with the cost of lacking interpretability and limited\ngeneralizability, hindering their clinical applications. To develop a practical\nEWS system applicable to various outcomes, we propose causally-informed\nexplainable early prediction model, which leverages causal discovery to\nidentify the underlying causal relationships of prediction and thus owns two\nunique advantages: demonstrating the explicit interpretation of the prediction\nwhile exhibiting decent performance when applied to unfamiliar environments.\nBenefiting from these features, our approach achieves superior accuracy for 6\ndifferent critical deteriorations and achieves better generalizability across\ndifferent patient groups, compared to various baseline algorithms. Besides, we\nprovide explicit causal pathways to serve as references for assistant clinical\ndiagnosis and potential interventions. The proposed approach enhances the\npractical application of deep learning in various medical scenarios.",
      "tldr_zh": "该研究针对深度学习（DL）在重症监护中用于早期预警分数（EWS）系统的局限性，如缺乏可解释性和泛化能力，提出了一种基于因果发现（causal discovery）的解释性早期预测模型。模型通过识别预测的底层因果关系，提供显式解释并在陌生环境中保持出色性能。实验结果显示，该方法在6种临床恶化预测（如急性肾损伤）上比基线算法准确率更高，并实现了更好的患者群体泛化能力。此外，该模型生成的显式因果路径可作为临床诊断和潜在干预的参考，从而提升DL在医疗场景中的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02109v1",
      "published_date": "2025-02-04 08:43:39 UTC",
      "updated_date": "2025-02-04 08:43:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:01:42.812047"
    },
    {
      "arxiv_id": "2502.02103v1",
      "title": "Neural Networks Learn Distance Metrics",
      "title_zh": "神经网络学习距离度量",
      "authors": [
        "Alan Oursland"
      ],
      "abstract": "Neural networks may naturally favor distance-based representations, where\nsmaller activations indicate closer proximity to learned prototypes. This\ncontrasts with intensity-based approaches, which rely on activation magnitudes.\nTo test this hypothesis, we conducted experiments with six MNIST architectural\nvariants constrained to learn either distance or intensity representations. Our\nresults reveal that the underlying representation affects model performance. We\ndevelop a novel geometric framework that explains these findings and introduce\nOffsetL2, a new architecture based on Mahalanobis distance equations, to\nfurther validate this framework. This work highlights the importance of\nconsidering distance-based learning in neural network design.",
      "tldr_zh": "本研究发现，神经网络更倾向于学习基于距离的表示，其中较小的激活表示与学习原型更接近，与依赖激活幅度的强度-based 方法形成对比。通过在六种 MNIST 架构变体上进行的实验，比较了距离和强度表示对模型性能的影响，结果显示距离-based 表示能提升性能。研究开发了一个新的几何框架来解释这些发现，并引入了 OffsetL2 架构，基于 Mahalanobis distance 方程进行验证，强调了在神经网络设计中重视距离-based 学习的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T07 (Primary) 62H12 (Secondary)",
        "I.5.1; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 1 figures. Code and additional resources available at\n  https://github.com/alanoursland/neural_networks_learn_distance_metrics",
      "pdf_url": "http://arxiv.org/pdf/2502.02103v1",
      "published_date": "2025-02-04 08:35:57 UTC",
      "updated_date": "2025-02-04 08:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:01:55.661130"
    },
    {
      "arxiv_id": "2502.02088v3",
      "title": "IPO: Iterative Preference Optimization for Text-to-Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaomeng Yang",
        "Zhiyu Tan",
        "Hao Li"
      ],
      "abstract": "Video foundation models have achieved significant advancement with the help\nof network upgrade as well as model scale-up. However, they are still hard to\nmeet requirements of applications due to unsatisfied generation quality. To\nsolve this problem, we propose to align video foundation models with human\npreferences from the perspective of post-training in this paper. Consequently,\nwe introduce an Iterative Preference Optimization strategy to enhance generated\nvideo quality by incorporating human feedback. Specifically, IPO exploits a\ncritic model to justify video generations for pairwise ranking as in Direct\nPreference Optimization or point-wise scoring as in Kahneman-Tversky\nOptimization. Given this, IPO optimizes video foundation models with guidance\nof signals from preference feedback, which helps improve generated video\nquality in subject consistency, motion smoothness and aesthetic quality, etc.\nIn addition, IPO incorporates the critic model with the multi-modality large\nlanguage model, which enables it to automatically assign preference labels\nwithout need of retraining or relabeling. In this way, IPO can efficiently\nperform multi-round preference optimization in an iterative manner, without the\nneed of tediously manual labeling. Comprehensive experiments demonstrate that\nthe proposed IPO can effectively improve the video generation quality of a\npretrained model and help a model with only 2B parameters surpass the one with\n5B parameters. Besides, IPO achieves new state-of-the-art performance on VBench\nbenchmark.",
      "tldr_zh": "本论文提出了一种迭代偏好优化策略（IPO），旨在通过后训练过程将视频基础模型与人类偏好对齐，从而提升文本到视频生成的质量。IPO 利用批评模型进行配对排名（如 Direct Preference Optimization）或点式评分（如 Kahneman-Tversky Optimization），并结合多模态大语言模型自动分配偏好标签，实现高效的多轮迭代优化，而无需手动标注。实验证明，该方法显著改善了生成的视频在主体一致性、运动平滑性和美学质量等方面，并使 2B 参数模型超越 5B 参数模型，在 VBench 基准上达到新的最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02088v3",
      "published_date": "2025-02-04 08:14:34 UTC",
      "updated_date": "2025-03-09 12:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:04:08.218826"
    },
    {
      "arxiv_id": "2502.10420v1",
      "title": "Position: Stop Acting Like Language Model Agents Are Normal Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Elija Perrier",
        "Michael Timothy Bennett"
      ],
      "abstract": "Language Model Agents (LMAs) are increasingly treated as capable of\nautonomously navigating interactions with humans and tools. Their design and\ndeployment tends to presume they are normal agents capable of sustaining\ncoherent goals, adapting across contexts and acting with a measure of\nintentionality. These assumptions are critical to prospective use cases in\nindustrial, social and governmental settings. But LMAs are not normal agents.\nThey inherit the structural problems of the large language models (LLMs) around\nwhich they are built: hallucinations, jailbreaking, misalignment and\nunpredictability. In this Position paper we argue LMAs should not be treated as\nnormal agents, because doing so leads to problems that undermine their utility\nand trustworthiness. We enumerate pathologies of agency intrinsic to LMAs.\nDespite scaffolding such as external memory and tools, they remain\nontologically stateless, stochastic, semantically sensitive, and linguistically\nintermediated. These pathologies destabilise the ontological properties of LMAs\nincluding identifiability, continuity, persistence and and consistency,\nproblematising their claim to agency. In response, we argue LMA ontological\nproperties should be measured before, during and after deployment so that the\nnegative effects of pathologies can be mitigated.",
      "tldr_zh": "这篇论文主张不应将语言模型代理 (LMAs) 视为正常的代理，因为它们继承了大型语言模型 (LLMs) 的结构性问题，如 hallucinations、jailbreaking、misalignment 和不可预测性，导致其无法维持连贯目标或跨上下文适应。作者列举了 LMAs 的内在病理，包括本体上无状态、随机性、对语义的敏感性和语言中介性，这些因素破坏了其本体论属性，如 identifiability、continuity、persistence 和 consistency，从而降低了其效用和可信度。论文建议在部署前后测量这些本体论属性，以缓解负面影响并改进 LMAs 的设计和应用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.10420v1",
      "published_date": "2025-02-04 08:14:18 UTC",
      "updated_date": "2025-02-04 08:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:04:42.171537"
    },
    {
      "arxiv_id": "2502.02079v1",
      "title": "Online Clustering of Dueling Bandits",
      "title_zh": "在线聚类对决多臂老虎机",
      "authors": [
        "Zhiyong Wang",
        "Jiahang Sun",
        "Mingze Kong",
        "Jize Xie",
        "Qinghua Hu",
        "John C. S. Lui",
        "Zhongxiang Dai"
      ],
      "abstract": "The contextual multi-armed bandit (MAB) is a widely used framework for\nproblems requiring sequential decision-making under uncertainty, such as\nrecommendation systems. In applications involving a large number of users, the\nperformance of contextual MAB can be significantly improved by facilitating\ncollaboration among multiple users. This has been achieved by the clustering of\nbandits (CB) methods, which adaptively group the users into different clusters\nand achieve collaboration by allowing the users in the same cluster to share\ndata. However, classical CB algorithms typically rely on numerical reward\nfeedback, which may not be practical in certain real-world applications. For\ninstance, in recommendation systems, it is more realistic and reliable to\nsolicit preference feedback between pairs of recommended items rather than\nabsolute rewards. To address this limitation, we introduce the first\n\"clustering of dueling bandit algorithms\" to enable collaborative\ndecision-making based on preference feedback. We propose two novel algorithms:\n(1) Clustering of Linear Dueling Bandits (COLDB) which models the user reward\nfunctions as linear functions of the context vectors, and (2) Clustering of\nNeural Dueling Bandits (CONDB) which uses a neural network to model complex,\nnon-linear user reward functions. Both algorithms are supported by rigorous\ntheoretical analyses, demonstrating that user collaboration leads to improved\nregret bounds. Extensive empirical evaluations on synthetic and real-world\ndatasets further validate the effectiveness of our methods, establishing their\npotential in real-world applications involving multiple users with\npreference-based feedback.",
      "tldr_zh": "本研究针对多用户环境下上下文多臂老虎机（contextual multi-armed bandit, MAB）的决策问题，提出了一种基于偏好反馈的在线聚类方法，以克服传统Clustering of Bandits (CB)算法依赖数值奖励的局限。论文引入了两种新算法：Clustering of Linear Dueling Bandits (COLDB)，使用线性函数建模用户奖励函数；以及Clustering of Neural Dueling Bandits (CONDB)，采用神经网络处理复杂非线性函数。理论分析证明，用户协作可显著改善regret bounds；实验在合成和真实数据集上验证了这些算法的有效性，展示了其在推荐系统等偏好反馈场景中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.02079v1",
      "published_date": "2025-02-04 07:55:41 UTC",
      "updated_date": "2025-02-04 07:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:04:31.152873"
    },
    {
      "arxiv_id": "2502.02072v1",
      "title": "ASCenD-BDS: Adaptable, Stochastic and Context-aware framework for Detection of Bias, Discrimination and Stereotyping",
      "title_zh": "翻译失败",
      "authors": [
        "Rajiv Bahl",
        "Venkatesan N",
        "Parimal Aglawe",
        "Aastha Sarasapalli",
        "Bhavya Kancharla",
        "Chaitanya kolukuluri",
        "Harish Mohite",
        "Japneet Hora",
        "Kiran Kakollu",
        "Rahul Diman",
        "Shubham Kapale",
        "Sri Bhagya Kathula",
        "Vamsikrishna Motru",
        "Yogeshwar Reddy"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has transformed natural\nlanguage processing but raises critical concerns about biases inherent in their\ndeployment and use across diverse linguistic and sociocultural contexts. This\npaper presents a framework named ASCenD BDS (Adaptable, Stochastic and\nContext-aware framework for Detection of Bias, Discrimination and\nStereotyping). The framework presents approach to detecting bias,\ndiscrimination, stereotyping across various categories such as gender, caste,\nage, disability, socioeconomic status, linguistic variations, etc., using an\napproach which is Adaptive, Stochastic and Context-Aware. The existing\nframeworks rely heavily on usage of datasets to generate scenarios for\ndetection of Bias, Discrimination and Stereotyping. Examples include datasets\nsuch as Civil Comments, Wino Gender, WinoBias, BOLD, CrowS Pairs and BBQ.\nHowever, such an approach provides point solutions. As a result, these datasets\nprovide a finite number of scenarios for assessment. The current framework\novercomes this limitation by having features which enable Adaptability,\nStochasticity, Context Awareness. Context awareness can be customized for any\nnation or culture or sub-culture (for example an organization's unique\nculture). In this paper, context awareness in the Indian context has been\nestablished. Content has been leveraged from Indian Census 2011 to have a\ncommonality of categorization. A framework has been developed using Category,\nSub-Category, STEM, X-Factor, Synonym to enable the features for Adaptability,\nStochasticity and Context awareness. The framework has been described in detail\nin Section 3. Overall 800 plus STEMs, 10 Categories, 31 unique SubCategories\nwere developed by a team of consultants at Saint Fox Consultancy Private Ltd.\nThe concept has been tested out in SFCLabs as part of product development.",
      "tldr_zh": "这篇论文介绍了 ASCenD-BDS 框架，这是一个 Adaptable（可适应）、Stochastic（随机）和 Context-Aware（上下文感知）的系统，用于检测各种偏见、歧视和 Stereotyping（如性别、种姓、年龄等）。框架通过整合 Category、Sub-Category、STEM、X-Factor 和 Synonym 等元素，超越了传统数据集（如 Civil Comments 和 Wino Gender）的局限性，实现动态场景生成和文化定制，例如基于印度人口普查数据的印度语境。研究团队开发了超过 800 个 STEMs、10 个 Categories 和 31 个 SubCategories，并在 SFCLabs 进行了测试，展示了框架在多样化 sociocultural 环境中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 6 Figures and this manuscript will be submitted to Q1,Q2\n  Journals",
      "pdf_url": "http://arxiv.org/pdf/2502.02072v1",
      "published_date": "2025-02-04 07:44:20 UTC",
      "updated_date": "2025-02-04 07:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:04:44.125983"
    },
    {
      "arxiv_id": "2502.02067v2",
      "title": "AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Singh",
        "Karthik Swaminathan",
        "Nabanita Dash",
        "Ramandeep Singh",
        "Snehasis Banerjee",
        "Mohan Sridharan",
        "Madhava Krishna"
      ],
      "abstract": "An embodied agent assisting humans is often asked to complete new tasks, and\nthere may not be sufficient time or labeled examples to train the agent to\nperform these new tasks. Large Language Models (LLMs) trained on considerable\nknowledge across many domains can be used to predict a sequence of abstract\nactions for completing such tasks, although the agent may not be able to\nexecute this sequence due to task-, agent-, or domain-specific constraints. Our\nframework addresses these challenges by leveraging the generic predictions\nprovided by LLM and the prior domain knowledge encoded in a Knowledge Graph\n(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits\nand uses human input as needed to refine its existing knowledge. Based on\nexperimental evaluation in the context of cooking and cleaning tasks in\nsimulation domains, we demonstrate that the interplay between LLM, KG, and\nhuman input leads to substantial performance gains compared with just using the\nLLM. Project website{\\S}: https://sssshivvvv.github.io/adaptbot/",
      "tldr_zh": "该论文提出AdaptBot框架，通过结合Large Language Models (LLMs)、Knowledge Graphs (KG) 和人类输入，帮助机器人代理快速适应新任务，而无需大量训练或标记数据。框架将LLMs生成的通用抽象动作序列转化为特定任务分解，并利用KG的领域知识进行知识精炼，同时根据任务约束主动征求人类输入以优化过程。在模拟的烹饪和清洁任务实验中，这种多源整合方法相较于仅使用LLMs，实现了显著性能提升，证明了其在实际应用中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.02067v2",
      "published_date": "2025-02-04 07:32:39 UTC",
      "updated_date": "2025-03-06 18:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:04:55.594837"
    },
    {
      "arxiv_id": "2502.02063v1",
      "title": "CASIM: Composite Aware Semantic Injection for Text to Motion Generation",
      "title_zh": "CASIM：复合感知语义注入用于文本到动作生成",
      "authors": [
        "Che-Jui Chang",
        "Qingze Tony Liu",
        "Honglu Zhou",
        "Vladimir Pavlovic",
        "Mubbasir Kapadia"
      ],
      "abstract": "Recent advances in generative modeling and tokenization have driven\nsignificant progress in text-to-motion generation, leading to enhanced quality\nand realism in generated motions. However, effectively leveraging textual\ninformation for conditional motion generation remains an open challenge. We\nobserve that current approaches, primarily relying on fixed-length text\nembeddings (e.g., CLIP) for global semantic injection, struggle to capture the\ncomposite nature of human motion, resulting in suboptimal motion quality and\ncontrollability. To address this limitation, we propose the Composite Aware\nSemantic Injection Mechanism (CASIM), comprising a composite-aware semantic\nencoder and a text-motion aligner that learns the dynamic correspondence\nbetween text and motion tokens. Notably, CASIM is model and\nrepresentation-agnostic, readily integrating with both autoregressive and\ndiffusion-based methods. Experiments on HumanML3D and KIT benchmarks\ndemonstrate that CASIM consistently improves motion quality, text-motion\nalignment, and retrieval scores across state-of-the-art methods. Qualitative\nanalyses further highlight the superiority of our composite-aware approach over\nfixed-length semantic injection, enabling precise motion control from text\nprompts and stronger generalization to unseen text inputs.",
      "tldr_zh": "该论文针对文本到动作生成（text-to-motion generation）中的问题，提出 CASIM（Composite Aware Semantic Injection Mechanism），一种复合感知语义注入机制，包括复合感知语义编码器和文本-动作对齐器，以动态学习文本和动作标记之间的对应关系，从而提升动作质量和可控性。CASIM 设计为模型和表示无关，能够无缝集成到自回归和扩散-based 方法中。实验结果显示，在 HumanML3D 和 KIT 基准上，CASIM 显著提高了动作质量、文本-动作对齐以及检索分数，并通过定性分析证明了其在精确动作控制和对未见文本的泛化能力上的优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02063v1",
      "published_date": "2025-02-04 07:22:07 UTC",
      "updated_date": "2025-02-04 07:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:05:08.607422"
    },
    {
      "arxiv_id": "2502.02060v1",
      "title": "CH-MARL: Constrained Hierarchical Multiagent Reinforcement Learning for Sustainable Maritime Logistics",
      "title_zh": "翻译失败",
      "authors": [
        "Saad Alqithami"
      ],
      "abstract": "Addressing global challenges such as greenhouse gas emissions and resource\ninequity demands advanced AI-driven coordination among autonomous agents. We\npropose CH-MARL (Constrained Hierarchical Multiagent Reinforcement Learning), a\nnovel framework that integrates hierarchical decision-making with dynamic\nconstraint enforcement and fairness-aware reward shaping. CH-MARL employs a\nreal-time constraint-enforcement layer to ensure adherence to global emission\ncaps, while incorporating fairness metrics that promote equitable resource\ndistribution among agents. Experiments conducted in a simulated maritime\nlogistics environment demonstrate considerable reductions in emissions, along\nwith improvements in fairness and operational efficiency. Beyond this\ndomain-specific success, CH-MARL provides a scalable, generalizable solution to\nmulti-agent coordination challenges in constrained, dynamic settings, thus\nadvancing the state of the art in reinforcement learning.",
      "tldr_zh": "该研究提出 CH-MARL 框架，一种结合分层决策、动态约束执行和公平奖励塑造的 Hierarchical Multiagent Reinforcement Learning 方法，旨在解决可持续海事物流中的温室气体排放和资源不均等问题。框架通过实时约束执行层确保代理遵守全球排放上限，同时促进公平资源分配。实验在模拟海事物流环境中显示，该方法显著降低了排放、提升了公平性和操作效率。作为一个可扩展的解决方案，CH-MARL 为约束动态环境下的多代理协调问题提供了通用化进阶，推进了强化学习领域的创新。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02060v1",
      "published_date": "2025-02-04 07:13:21 UTC",
      "updated_date": "2025-02-04 07:13:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:05:18.883825"
    },
    {
      "arxiv_id": "2502.18471v1",
      "title": "FinBloom: Knowledge Grounding Large Language Model with Real-time Financial Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ankur Sinha",
        "Chaitanya Agarwal",
        "Pekka Malo"
      ],
      "abstract": "Large language models (LLMs) excel at generating human-like responses but\noften struggle with interactive tasks that require access to real-time\ninformation. This limitation poses challenges in finance, where models must\naccess up-to-date information, such as recent news or price movements, to\nsupport decision-making. To address this, we introduce Financial Agent, a\nknowledge-grounding approach for LLMs to handle financial queries using\nreal-time text and tabular data. Our contributions are threefold: First, we\ndevelop a Financial Context Dataset of over 50,000 financial queries paired\nwith the required context. Second, we train FinBloom 7B, a custom 7 billion\nparameter LLM, on 14 million financial news articles from Reuters and Deutsche\nPresse-Agentur, alongside 12 million Securities and Exchange Commission (SEC)\nfilings. Third, we fine-tune FinBloom 7B using the Financial Context Dataset to\nserve as a Financial Agent. This agent generates relevant financial context,\nenabling efficient real-time data retrieval to answer user queries. By reducing\nlatency and eliminating the need for users to manually provide accurate data,\nour approach significantly enhances the capability of LLMs to handle dynamic\nfinancial tasks. Our proposed approach makes real-time financial decisions,\nalgorithmic trading and other related tasks streamlined, and is valuable in\ncontexts with high-velocity data flows.",
      "tldr_zh": "该论文提出 FinBloom，一种知识接地（knowledge-grounding）方法，用于让 Large Language Models (LLMs) 处理实时金融数据，从而解决 LLMs 在金融决策中获取实时信息（如新闻或价格变动）的挑战。研究团队开发了 Financial Context Dataset，包含超过 50,000 个金融查询及其相关上下文，作为关键资源。其次，他们训练了 FinBloom 7B 模型，使用 14 百万篇 Reuters 和 Deutsche Presse-Agentur 新闻文章，以及 12 百万份 Securities and Exchange Commission (SEC) 文件。最终，通过微调 FinBloom 7B 作为 Financial Agent，该系统能生成相关金融上下文，实现高效的实时数据检索，减少延迟并提升 LLMs 在算法交易和动态金融任务中的性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-fin.ST"
      ],
      "primary_category": "cs.IR",
      "comment": "27 pages, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.18471v1",
      "published_date": "2025-02-04 06:51:34 UTC",
      "updated_date": "2025-02-04 06:51:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:05:32.052802"
    },
    {
      "arxiv_id": "2502.02054v1",
      "title": "RAPID: Robust and Agile Planner Using Inverse Reinforcement Learning for Vision-Based Drone Navigation",
      "title_zh": "RAPID：基于逆强化学习的鲁棒且敏捷规划器，用于视觉",
      "authors": [
        "Minwoo Kim",
        "Geunsik Bae",
        "Jinwoo Lee",
        "Woojae Shin",
        "Changseung Kim",
        "Myong-Yol Choi",
        "Heejung Shin",
        "Hyondong Oh"
      ],
      "abstract": "This paper introduces a learning-based visual planner for agile drone flight\nin cluttered environments. The proposed planner generates collision-free\nwaypoints in milliseconds, enabling drones to perform agile maneuvers in\ncomplex environments without building separate perception, mapping, and\nplanning modules. Learning-based methods, such as behavior cloning (BC) and\nreinforcement learning (RL), demonstrate promising performance in visual\nnavigation but still face inherent limitations. BC is susceptible to\ncompounding errors due to limited expert imitation, while RL struggles with\nreward function design and sample inefficiency. To address these limitations,\nthis paper proposes an inverse reinforcement learning (IRL)-based framework for\nhigh-speed visual navigation. By leveraging IRL, it is possible to reduce the\nnumber of interactions with simulation environments and improve capability to\ndeal with high-dimensional spaces while preserving the robustness of RL\npolicies. A motion primitive-based path planning algorithm collects an expert\ndataset with privileged map data from diverse environments, ensuring\ncomprehensive scenario coverage. By leveraging both the acquired expert and\nlearner dataset gathered from the agent's interactions with the simulation\nenvironments, a robust reward function and policy are learned across diverse\nstates. While the proposed method is trained in a simulation environment only,\nit can be directly applied to real-world scenarios without additional training\nor tuning. The performance of the proposed method is validated in both\nsimulation and real-world environments, including forests and various\nstructures. The trained policy achieves an average speed of 7 m/s and a maximum\nspeed of 8.8 m/s in real flight experiments. To the best of our knowledge, this\nis the first work to successfully apply an IRL framework for high-speed visual\nnavigation of drones.",
      "tldr_zh": "本研究提出 RAPID，一种基于 Inverse Reinforcement Learning (IRL) 的稳健且敏捷规划器，用于视觉-based 无人机在杂乱环境中的高速导航。该框架能在毫秒内生成无碰撞航点，无需单独的感知、映射和规划模块，从而解决传统行为克隆 (BC) 和强化学习 (RL) 方法的局限性，如累积错误和奖励函数设计问题。通过运动基元-based 路径规划算法收集专家数据集，并在模拟环境中训练，RAPID 学习了稳健的奖励函数和策略，可直接应用于真实场景。实验结果显示，该方法在模拟和真实环境中（如森林和各种结构）实现了平均速度 7 m/s 和最大速度 8.8 m/s，这是首次成功将 IRL 框架应用于高速视觉无人机导航。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "18 pages, 11 figures, 58 references, and appendix is included",
      "pdf_url": "http://arxiv.org/pdf/2502.02054v1",
      "published_date": "2025-02-04 06:42:08 UTC",
      "updated_date": "2025-02-04 06:42:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:05:43.955761"
    },
    {
      "arxiv_id": "2502.02040v1",
      "title": "M2R2: Mixture of Multi-Rate Residuals for Efficient Transformer Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Bhendawade",
        "Mahyar Najibi",
        "Devang Naik",
        "Irina Belousova"
      ],
      "abstract": "Residual transformations enhance the representational depth and expressive\npower of large language models (LLMs). However, applying static residual\ntransformations across all tokens in auto-regressive generation leads to a\nsuboptimal trade-off between inference efficiency and generation fidelity.\nExisting methods, including Early Exiting, Skip Decoding, and Mixture-of-Depth\naddress this by modulating the residual transformation based on token-level\ncomplexity. Nevertheless, these approaches predominantly consider the distance\ntraversed by tokens through the model layers, neglecting the underlying\nvelocity of residual evolution. We introduce Mixture of Multi-rate Residuals\n(M2R2), a framework that dynamically modulates residual velocity to improve\nearly alignment, enhancing inference efficiency. Evaluations on reasoning\noriented tasks such as Koala, Self-Instruct, WizardLM, and MT-Bench show M2R2\nsurpasses state-of-the-art distance-based strategies, balancing generation\nquality and speedup. In self-speculative decoding setup, M2R2 achieves up to\n2.8x speedups on MT-Bench, outperforming methods like 2-model speculative\ndecoding, Medusa, LookAhead Decoding, and DEED. In Mixture-of-Experts (MoE)\narchitectures, integrating early residual alignment with ahead-of-time expert\nloading into high-bandwidth memory (HBM) accelerates decoding, reduces\nexpert-switching bottlenecks, and achieves a 2.9x speedup, making it highly\neffective in resource-constrained environments.",
      "tldr_zh": "本论文提出 M2R2 框架，即 Mixture of Multi-Rate Residuals，用于优化 Transformer 模型的推理效率，通过动态调节 residual velocity 来改善 early alignment，从而解决现有方法（如 Early Exiting 和 Mixture-of-Depth）仅关注 token 层距离而忽略 residual evolution 速度的问题。M2R2 在 Koala、Self-Instruct、WizardLM 和 MT-Bench 等推理任务上超越了基于距离的策略，在生成质量和加速之间取得平衡。实验结果显示，在 self-speculative decoding 设置中实现高达 2.8x 加速，在 Mixture-of-Experts (MoE) 架构中通过提前加载专家到高带宽内存 (HBM) 实现 2.9x 加速，显著减少瓶颈并适用于资源受限环境。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02040v1",
      "published_date": "2025-02-04 06:13:52 UTC",
      "updated_date": "2025-02-04 06:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:05:55.953751"
    },
    {
      "arxiv_id": "2502.02036v1",
      "title": "From Human Hands to Robotic Limbs: A Study in Motor Skill Embodiment for Telemanipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyi Shi",
        "Mingxi Su",
        "Ted Morris",
        "Vassilios Morellas",
        "Nikolaos Papanikolopoulos"
      ],
      "abstract": "This paper presents a teleoperation system for controlling a redundant degree\nof freedom robot manipulator using human arm gestures. We propose a GRU-based\nVariational Autoencoder to learn a latent representation of the manipulator's\nconfiguration space, capturing its complex joint kinematics. A fully connected\nneural network maps human arm configurations into this latent space, allowing\nthe system to mimic and generate corresponding manipulator trajectories in real\ntime through the VAE decoder. The proposed method shows promising results in\nteleoperating the manipulator, enabling the generation of novel manipulator\nconfigurations from human features that were not present during training.",
      "tldr_zh": "这篇论文提出了一种远程操作系统，使用人类手臂手势控制多余自由度（redundant degree of freedom）机器人机械臂，以研究运动技能的体现。研究团队采用GRU-based Variational Autoencoder来学习机械臂配置空间的潜在表示，捕捉其复杂的关节运动，并通过全连接神经网络将人类手臂配置映射到该潜在空间中，实现实时生成机械臂轨迹。结果显示，该方法不仅能有效模拟和控制机械臂，还能生成训练中未出现的创新配置，提升了远程操作的灵活性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02036v1",
      "published_date": "2025-02-04 05:52:57 UTC",
      "updated_date": "2025-02-04 05:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:06:07.823107"
    },
    {
      "arxiv_id": "2502.02032v1",
      "title": "Heteroscedastic Double Bayesian Elastic Net",
      "title_zh": "异方差双重贝叶斯",
      "authors": [
        "Masanari Kimura"
      ],
      "abstract": "In many practical applications, regression models are employed to uncover\nrelationships between predictors and a response variable, yet the common\nassumption of constant error variance is frequently violated. This issue is\nfurther compounded in high-dimensional settings where the number of predictors\nexceeds the sample size, necessitating regularization for effective estimation\nand variable selection. To address this problem, we propose the Heteroscedastic\nDouble Bayesian Elastic Net (HDBEN), a novel framework that jointly models the\nmean and log-variance using hierarchical Bayesian priors incorporating both\n$\\ell_1$ and $\\ell_2$ penalties. Our approach simultaneously induces sparsity\nand grouping in the regression coefficients and variance parameters, capturing\ncomplex variance structures in the data. Theoretical results demonstrate that\nproposed HDBEN achieves posterior concentration, variable selection\nconsistency, and asymptotic normality under mild conditions which justifying\nits behavior. Simulation studies further illustrate that HDBEN outperforms\nexisting methods, particularly in scenarios characterized by heteroscedasticity\nand high dimensionality.",
      "tldr_zh": "本研究针对回归模型中常见的异方差问题（误差方差不恒定），特别是在高维场景下，提出了一种新框架：Heteroscedastic Double Bayesian Elastic Net (HDBEN)。HDBEN 通过分层 Bayesian 先验联合建模均值和 log-方差，并结合 $\\ell_1$ 和 $\\ell_2$ 惩罚，同时在回归系数和方差参数中诱导稀疏性和分组，以捕捉复杂的数据方差结构。理论分析证明，HDBEN 在温和条件下实现后验集中、变量选择一致性和渐进正态性；模拟研究进一步显示，该方法在异方差和高维环境中优于现有方法。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02032v1",
      "published_date": "2025-02-04 05:44:19 UTC",
      "updated_date": "2025-02-04 05:44:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:06:19.330541"
    },
    {
      "arxiv_id": "2502.02028v2",
      "title": "Fine-tuning Language Models for Recipe Generation: A Comparative Analysis and Benchmark Study",
      "title_zh": "微调语言模型用于食谱生成：比较分析",
      "authors": [
        "Anneketh Vij",
        "Changhao Liu",
        "Rahul Anil Nair",
        "Theodore Eugene Ho",
        "Edward Shi",
        "Ayan Bhowmick"
      ],
      "abstract": "This research presents an exploration and study of the recipe generation task\nby fine-tuning various very small language models, with a focus on developing\nrobust evaluation metrics and comparing across different language models the\nopen-ended task of recipe generation. This study presents extensive experiments\nwith multiple model architectures, ranging from T5-small (Raffel et al., 2023)\nand SmolLM-135M(Allal et al., 2024) to Phi-2 (Research, 2023), implementing\nboth traditional NLP metrics and custom domain-specific evaluation metrics. Our\nnovel evaluation framework incorporates recipe-specific metrics for assessing\ncontent quality and introduces approaches to allergen substitution. The results\nindicate that, while larger models generally perform better on standard\nmetrics, the relationship between model size and recipe quality is more nuanced\nwhen considering domain-specific metrics. SmolLM-360M and SmolLM-1.7B\ndemonstrate comparable performance despite their size difference before and\nafter fine-tuning, while fine-tuning Phi-2 shows notable limitations in recipe\ngeneration despite its larger parameter count. The comprehensive evaluation\nframework and allergen substitution systems provide valuable insights for\nfuture work in recipe generation and broader NLG tasks that require domain\nexpertise and safety considerations.",
      "tldr_zh": "本研究通过微调各种小型语言模型（如 T5-small、SmolLM-135M 和 Phi-2），对食谱生成任务进行比较分析和基准研究，重点开发了鲁棒的评估指标，包括传统 NLP 指标和自定义领域特定指标，如内容质量评估及过敏原替代方法。实验结果显示，虽然更大模型在标准指标上表现更好，但模型大小与食谱质量的关系更复杂，例如 SmolLM-360M 和 SmolLM-1.7B 在微调前后表现出类似性能，而 Phi-2 尽管参数较多，却在食谱生成上显示出明显局限。该框架为未来食谱生成和需要领域专业知识的 NLG 任务提供了宝贵的见解和安全考虑。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 10 figures,14 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.02028v2",
      "published_date": "2025-02-04 05:25:01 UTC",
      "updated_date": "2025-02-16 23:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:06:31.755117"
    },
    {
      "arxiv_id": "2502.02027v4",
      "title": "From Fog to Failure: The Unintended Consequences of Dehazing on Object Detection in Clear Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ashutosh Kumar",
        "Aman Chadha"
      ],
      "abstract": "This study explores the challenges of integrating human visual cue-based\ndehazing into object detection, given the selective nature of human perception.\nWhile human vision adapts dynamically to environmental conditions,\ncomputational dehazing does not always enhance detection uniformly. We propose\na multi-stage framework where a lightweight detector identifies regions of\ninterest (RoIs), which are then improved via spatial attention-based dehazing\nbefore final detection by a heavier model. Though effective in foggy\nconditions, this approach unexpectedly degrades the performance on clear\nimages. We analyze this phenomenon, investigate possible causes, and offer\ninsights for designing hybrid pipelines that balance enhancement and detection.\nOur findings highlight the need for selective preprocessing and challenge\nassumptions about universal benefits from cascading transformations.",
      "tldr_zh": "本研究探讨了基于人类视觉提示的去雾(dehazing)整合到物体检测(object detection)中的挑战，指出计算去雾并不总是均匀提升检测性能，而是可能因人类感知的 selective 性质而导致意外后果。研究提出一个多阶段框架：先由轻量级检测器识别感兴趣区域(RoIs)，然后通过空间注意力-based dehazing 改进这些区域，最后由 heavier 模型进行最终检测。尽管该框架在雾天条件下有效，但在晴朗图像上却意外降低了性能。通过分析可能原因，研究提供见解，建议设计平衡增强和检测的混合管道，并强调了选择性预处理的需求，以挑战级联变换的普遍益处假设。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02027v4",
      "published_date": "2025-02-04 05:24:44 UTC",
      "updated_date": "2025-03-16 14:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:06:47.240989"
    },
    {
      "arxiv_id": "2502.02017v1",
      "title": "Multi-Domain Graph Foundation Models: Robust Knowledge Transfer via Topology Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Wang",
        "Bokui Wang",
        "Zhixiang Shen",
        "Boyan Deng",
        "Zhao Kang"
      ],
      "abstract": "Recent advances in CV and NLP have inspired researchers to develop\ngeneral-purpose graph foundation models through pre-training across diverse\ndomains. However, a fundamental challenge arises from the substantial\ndifferences in graph topologies across domains. Additionally, real-world graphs\nare often sparse and prone to noisy connections and adversarial attacks. To\naddress these issues, we propose the Multi-Domain Graph Foundation Model\n(MDGFM), a unified framework that aligns and leverages cross-domain topological\ninformation to facilitate robust knowledge transfer. MDGFM bridges different\ndomains by adaptively balancing features and topology while refining original\ngraphs to eliminate noise and align topological structures. To further enhance\nknowledge transfer, we introduce an efficient prompt-tuning approach. By\naligning topologies, MDGFM not only improves multi-domain pre-training but also\nenables robust knowledge transfer to unseen domains. Theoretical analyses\nprovide guarantees of MDGFM's effectiveness and domain generalization\ncapabilities. Extensive experiments on both homophilic and heterophilic graph\ndatasets validate the robustness and efficacy of our method.",
      "tldr_zh": "该研究针对跨领域图基础模型面临的拓扑差异、图稀疏性和噪声问题，提出了 Multi-Domain Graph Foundation Model (MDGFM)，一个统一框架，通过拓扑对齐和适应性平衡特征与拓扑来实现稳健的知识转移。\nMDGFM 精炼原始图以消除噪声，并引入高效的 prompt-tuning approach，提升多领域预训练并支持对未见领域的泛化。\n实验结果在同质和异质图数据集上验证了 MDGFM 的有效性和稳健性，理论分析进一步保证了其性能和领域泛化能力。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02017v1",
      "published_date": "2025-02-04 05:09:23 UTC",
      "updated_date": "2025-02-04 05:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:06:56.175152"
    },
    {
      "arxiv_id": "2502.02016v1",
      "title": "A Periodic Bayesian Flow for Material Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlin Wu",
        "Yuxuan Song",
        "Jingjing Gong",
        "Ziyao Cao",
        "Yawen Ouyang",
        "Jianbing Zhang",
        "Hao Zhou",
        "Wei-Ying Ma",
        "Jingjing Liu"
      ],
      "abstract": "Generative modeling of crystal data distribution is an important yet\nchallenging task due to the unique periodic physical symmetry of crystals.\nDiffusion-based methods have shown early promise in modeling crystal\ndistribution. More recently, Bayesian Flow Networks were introduced to\naggregate noisy latent variables, resulting in a variance-reduced parameter\nspace that has been shown to be advantageous for modeling Euclidean data\ndistributions with structural constraints (Song et al., 2023). Inspired by\nthis, we seek to unlock its potential for modeling variables located in\nnon-Euclidean manifolds e.g. those within crystal structures, by overcoming\nchallenging theoretical issues. We introduce CrysBFN, a novel crystal\ngeneration method by proposing a periodic Bayesian flow, which essentially\ndiffers from the original Gaussian-based BFN by exhibiting non-monotonic\nentropy dynamics. To successfully realize the concept of periodic Bayesian\nflow, CrysBFN integrates a new entropy conditioning mechanism and empirically\ndemonstrates its significance compared to time-conditioning. Extensive\nexperiments over both crystal ab initio generation and crystal structure\nprediction tasks demonstrate the superiority of CrysBFN, which consistently\nachieves new state-of-the-art on all benchmarks. Surprisingly, we found that\nCrysBFN enjoys a significant improvement in sampling efficiency, e.g., ~100x\nspeedup 10 v.s. 2000 steps network forwards) compared with previous\ndiffusion-based methods on MP-20 dataset. Code is available at\nhttps://github.com/wu-han-lin/CrysBFN.",
      "tldr_zh": "这篇论文提出了一种名为 CrysBFN 的新方法，用于生成晶体数据分布，针对晶体独特周期性对称性带来的挑战。CrysBFN 通过引入周期性 Bayesian Flow，改进了原 Gaussian-based Bayesian Flow Networks 的设计，实现了非单调熵动态，并采用新的熵条件机制来处理非欧氏空间中的变量。实验结果显示，CrysBFN 在晶体生成和结构预测任务上超越现有基准，采样效率显著提升，例如在 MP-20 数据集上比 diffusion-based 方法快约 100 倍（10 步 vs 2000 步）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR25",
      "pdf_url": "http://arxiv.org/pdf/2502.02016v1",
      "published_date": "2025-02-04 05:07:13 UTC",
      "updated_date": "2025-02-04 05:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:07:07.832007"
    },
    {
      "arxiv_id": "2502.02014v2",
      "title": "Analytical Lyapunov Function Discovery: An RL-based Generative Approach",
      "title_zh": "分析性李雅普诺夫函数发现：一种基于强化学习生成式方法",
      "authors": [
        "Haohan Zou",
        "Jie Feng",
        "Hao Zhao",
        "Yuanyuan Shi"
      ],
      "abstract": "Despite advances in learning-based methods, finding valid Lyapunov functions\nfor nonlinear dynamical systems remains challenging. Current neural network\napproaches face two main issues: challenges in scalable verification and\nlimited interpretability. To address these, we propose an end-to-end framework\nusing transformers to construct analytical Lyapunov functions (local), which\nsimplifies formal verification, enhances interpretability, and provides\nvaluable insights for control engineers. Our framework consists of a\ntransformer-based trainer that generates candidate Lyapunov functions and a\nfalsifier that verifies candidate expressions and refines the model via\nrisk-seeking policy gradient. Unlike Alfarano et al. (2024), which utilizes\npre-training and seeks global Lyapunov functions for low-dimensional systems,\nour model is trained from scratch via reinforcement learning (RL) and succeeds\nin finding local Lyapunov functions for high-dimensional and non-polynomial\nsystems. Given the analytical nature of the candidates, we employ efficient\noptimization methods for falsification during training and formal verification\ntools for the final verification. We demonstrate the efficiency of our approach\non a range of nonlinear dynamical systems with up to ten dimensions and show\nthat it can discover Lyapunov functions not previously identified in the\ncontrol literature.",
      "tldr_zh": "本文提出了一种基于强化学习(RL)的端到端框架，用于发现非线性动力系统的分析性局部Lyapunov functions，以解决现有神经网络方法的验证可扩展性和可解释性挑战。该框架利用Transformer生成候选Lyapunov functions，并通过falsifier模块结合风险寻求策略梯度进行验证和模型优化，与Alfarano et al. (2024)的预训练全局方法不同，它从零开始训练，适用于高维和非多项式系统。实验结果显示，该方法在多达十维的非线性动力系统中表现出高效性，并成功发现了控制文献中未曾识别的Lyapunov functions。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages (8+18), preprint for discussion. Haohan and Jie contribute\n  equally",
      "pdf_url": "http://arxiv.org/pdf/2502.02014v2",
      "published_date": "2025-02-04 05:04:15 UTC",
      "updated_date": "2025-02-11 00:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:07:19.648827"
    },
    {
      "arxiv_id": "2502.02013v1",
      "title": "Layer by Layer: Uncovering Hidden Representations in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Oscar Skean",
        "Md Rifat Arefin",
        "Dan Zhao",
        "Niket Patel",
        "Jalal Naghiyev",
        "Yann LeCun",
        "Ravid Shwartz-Ziv"
      ],
      "abstract": "From extracting features to generating text, the outputs of large language\nmodels (LLMs) typically rely on their final layers, following the conventional\nwisdom that earlier layers capture only low-level cues. However, our analysis\nshows that intermediate layers can encode even richer representations, often\nimproving performance on a wide range of downstream tasks. To explain and\nquantify these hidden-layer properties, we propose a unified framework of\nrepresentation quality metrics based on information theory, geometry, and\ninvariance to input perturbations. Our framework highlights how each model\nlayer balances information compression and signal preservation, revealing why\nmid-depth embeddings can exceed the last layer's performance. Through extensive\nexperiments on 32 text-embedding tasks and comparisons across model\narchitectures (transformers, state-space models) and domains (language,\nvision), we demonstrate that intermediate layers consistently provide stronger\nfeatures. These findings challenge the standard focus on final-layer embeddings\nand open new directions for model analysis and optimization, including\nstrategic use of mid-layer representations for more robust and accurate AI\nsystems.",
      "tldr_zh": "该研究挑战了传统观点，即大语言模型(LLMs)的最终层是主要输出源，发现中间层能编码更丰富的表示，并在32个文本嵌入任务上表现出色。作者提出一个统一框架，基于信息理论、几何学和对输入扰动的不变性，来量化各层的表示质量，解释了中间层如何平衡信息压缩与信号保留。实验结果显示，中间层嵌入在Transformer和状态空间模型等架构中提供更强特征，这为模型分析、优化和构建更稳健的AI系统开辟新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02013v1",
      "published_date": "2025-02-04 05:03:42 UTC",
      "updated_date": "2025-02-04 05:03:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:07:30.865863"
    },
    {
      "arxiv_id": "2502.02009v1",
      "title": "LLMSecConfig: An LLM-Based Approach for Fixing Software Container Misconfigurations",
      "title_zh": "LLMSecConfig：一种基于LLM的方法，用于修复软件容器错误配置",
      "authors": [
        "Ziyang Ye",
        "Triet Huynh Minh Le",
        "M. Ali Babar"
      ],
      "abstract": "Security misconfigurations in Container Orchestrators (COs) can pose serious\nthreats to software systems. While Static Analysis Tools (SATs) can effectively\ndetect these security vulnerabilities, the industry currently lacks automated\nsolutions capable of fixing these misconfigurations. The emergence of Large\nLanguage Models (LLMs), with their proven capabilities in code understanding\nand generation, presents an opportunity to address this limitation. This study\nintroduces LLMSecConfig, an innovative framework that bridges this gap by\ncombining SATs with LLMs. Our approach leverages advanced prompting techniques\nand Retrieval-Augmented Generation (RAG) to automatically repair security\nmisconfigurations while preserving operational functionality. Evaluation of\n1,000 real-world Kubernetes configurations achieved a 94\\% success rate while\nmaintaining a low rate of introducing new misconfigurations.\n  Our work makes a promising step towards automated container security\nmanagement, reducing the manual effort required for configuration maintenance.",
      "tldr_zh": "该论文提出 LLMSecConfig，一种基于 Large Language Models (LLMs) 的框架，用于自动修复软件容器配置错误，通过结合 Static Analysis Tools (SATs) 和 Retrieval-Augmented Generation (RAG) 技术，实现安全漏洞的修复同时保持系统操作功能。在对 1,000 个真实 Kubernetes 配置的评估中，该方法取得了 94% 的成功率，并将引入新错误的风险降至最低。该框架有助于减少手动配置维护工作，推动自动化容器安全管理的进步。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02009v1",
      "published_date": "2025-02-04 04:56:34 UTC",
      "updated_date": "2025-02-04 04:56:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:07:43.422677"
    },
    {
      "arxiv_id": "2503.04738v1",
      "title": "Copyright in AI-generated works: Lessons from recent developments in patent law",
      "title_zh": "翻译失败",
      "authors": [
        "Rita Matulionyte",
        "Jyh-An Lee"
      ],
      "abstract": "In Thaler v The Comptroller-General of Patents, Designs and Trade Marks\n(DABUS), Smith J. held that an AI owner can possibly claim patent ownership\nover an AI-generated invention based on their ownership and control of the AI\nsystem. This AI-owner approach reveals a new option to allocate property rights\nover AI-generated output. While this judgment was primarily about inventorship\nand ownership of AI-generated invention in patent law, it has important\nimplications for copyright law. After analysing the weaknesses of applying\nexisting judicial approaches to copyright ownership of AI-generated works, this\npaper examines whether the AI-owner approach is a better option for determining\ncopyright ownership of AI-generated works. The paper argues that while\ncontracts can be used to work around the AI-owner approach in scenarios where\nusers want to commercially exploit the outputs, this approach still provides\nmore certainty and less transaction costs for relevant parties than other\napproaches proposed so far.",
      "tldr_zh": "这篇论文基于 Thaler v The Comptroller-General of Patents, Designs and Trade Marks (DABUS) 案件，探讨了 AI-owner approach 在专利法中的发展如何为 AI 生成作品的版权所有权提供新路径。论文分析了现有司法方法在确定 AI 生成作品版权上的弱点，并论证 AI-owner approach 可能更优，因为它能降低交易成本并增加确定性。最终，论文指出，虽然合同可用于规避这一方法以实现商业利用，但它仍比其他提议更具实际优势。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04738v1",
      "published_date": "2025-02-04 04:16:44 UTC",
      "updated_date": "2025-02-04 04:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:07:54.659877"
    },
    {
      "arxiv_id": "2502.01995v1",
      "title": "Theoretical and Practical Analysis of Fréchet Regression via Comparison Geometry",
      "title_zh": "Fréchet 回归的理论与实践分析：通过比较几何",
      "authors": [
        "Masanari Kimura",
        "Howard Bondell"
      ],
      "abstract": "Fr\\'echet regression extends classical regression methods to non-Euclidean\nmetric spaces, enabling the analysis of data relationships on complex\nstructures such as manifolds and graphs. This work establishes a rigorous\ntheoretical analysis for Fr\\'echet regression through the lens of comparison\ngeometry which leads to important considerations for its use in practice. The\nanalysis provides key results on the existence, uniqueness, and stability of\nthe Fr\\'echet mean, along with statistical guarantees for nonparametric\nregression, including exponential concentration bounds and convergence rates.\nAdditionally, insights into angle stability reveal the interplay between\ncurvature of the manifold and the behavior of the regression estimator in these\nnon-Euclidean contexts. Empirical experiments validate the theoretical\nfindings, demonstrating the effectiveness of proposed hyperbolic mappings,\nparticularly for data with heteroscedasticity, and highlighting the practical\nusefulness of these results.",
      "tldr_zh": "本论文通过比较几何（comparison geometry）对 Fréchet regression 进行了理论和实践分析，将其扩展到非欧空间如流形和图，以处理复杂数据关系。研究建立了 Fréchet mean 的存在性、唯一性和稳定性，并提供了非参数回归的统计保证，包括指数集中界和收敛率，同时揭示了流形曲率与回归估计器行为之间的互动。实验验证了这些理论发现，证明了超曲映射在处理异方差数据时的有效性，并展示了该方法的实际应用潜力。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01995v1",
      "published_date": "2025-02-04 04:16:00 UTC",
      "updated_date": "2025-02-04 04:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:08:07.225882"
    },
    {
      "arxiv_id": "2502.01991v2",
      "title": "Can LLMs Assist Annotators in Identifying Morality Frames? -- Case Study on Vaccination Debate on Social Media",
      "title_zh": "大型语言模型能帮助",
      "authors": [
        "Tunazzina Islam",
        "Dan Goldwasser"
      ],
      "abstract": "Nowadays, social media is pivotal in shaping public discourse, especially on\npolarizing issues like vaccination, where diverse moral perspectives influence\nindividual opinions. In NLP, data scarcity and complexity of psycholinguistic\ntasks, such as identifying morality frames, make relying solely on human\nannotators costly, time-consuming, and prone to inconsistency due to cognitive\nload. To address these issues, we leverage large language models (LLMs), which\nare adept at adapting new tasks through few-shot learning, utilizing a handful\nof in-context examples coupled with explanations that connect examples to task\nprinciples. Our research explores LLMs' potential to assist human annotators in\nidentifying morality frames within vaccination debates on social media. We\nemploy a two-step process: generating concepts and explanations with LLMs,\nfollowed by human evaluation using a \"think-aloud\" tool. Our study shows that\nintegrating LLMs into the annotation process enhances accuracy, reduces task\ndifficulty, lowers cognitive load, suggesting a promising avenue for human-AI\ncollaboration in complex psycholinguistic tasks.",
      "tldr_zh": "本文研究探讨了大型语言模型（LLMs）是否能辅助人类标注者在社交媒体疫苗辩论中识别 morality frames，以应对数据稀缺和任务复杂性带来的挑战。研究采用两步方法：首先利用 LLMs 通过 few-shot learning 生成概念和解释；其次，通过“think-aloud”工具进行人类评估。结果表明，这种人类-AI 合作显著提高了标注准确性，降低了任务难度和认知负荷，为复杂心理语言学任务提供了高效的协作框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at 17th ACM Web Science Conference 2025 (WebSci'25)",
      "pdf_url": "http://arxiv.org/pdf/2502.01991v2",
      "published_date": "2025-02-04 04:10:23 UTC",
      "updated_date": "2025-02-05 03:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:08:19.043939"
    },
    {
      "arxiv_id": "2502.01980v1",
      "title": "Generative Data Mining with Longtail-Guided Diffusion",
      "title_zh": "基于长尾引导扩散的生成式数据挖掘",
      "authors": [
        "David S. Hayden",
        "Mao Ye",
        "Timur Garipov",
        "Gregory P. Meyer",
        "Carl Vondrick",
        "Zhao Chen",
        "Yuning Chai",
        "Eric Wolff",
        "Siddhartha S. Srinivasa"
      ],
      "abstract": "It is difficult to anticipate the myriad challenges that a predictive model\nwill encounter once deployed. Common practice entails a reactive, cyclical\napproach: model deployment, data mining, and retraining. We instead develop a\nproactive longtail discovery process by imagining additional data during\ntraining. In particular, we develop general model-based longtail signals,\nincluding a differentiable, single forward pass formulation of epistemic\nuncertainty that does not impact model parameters or predictive performance but\ncan flag rare or hard inputs. We leverage these signals as guidance to generate\nadditional training data from a latent diffusion model in a process we call\nLongtail Guidance (LTG). Crucially, we can perform LTG without retraining the\ndiffusion model or the predictive model, and we do not need to expose the\npredictive model to intermediate diffusion states. Data generated by LTG\nexhibit semantically meaningful variation, yield significant generalization\nimprovements on image classification benchmarks, and can be analyzed to\nproactively discover, explain, and address conceptual gaps in a predictive\nmodel.",
      "tldr_zh": "本文提出了一种主动生成式数据挖掘方法，名为 Longtail-Guided Diffusion (LTG)，旨在通过在训练阶段想象额外数据来提前发现和解决预测模型的长尾问题（包括稀有或困难输入）。该方法开发了基于模型的长尾信号，如可微分的单前向传播认识不确定性（epistemic uncertainty），并将其作为指导来从潜在扩散模型生成语义上有意义的额外训练数据，而无需重新训练扩散模型或预测模型。实验结果显示，LTG 生成的数据显著提升了图像分类基准上的泛化性能，并能主动分析和修复模型中的概念差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01980v1",
      "published_date": "2025-02-04 03:51:00 UTC",
      "updated_date": "2025-02-04 03:51:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:08:31.099709"
    },
    {
      "arxiv_id": "2502.04346v1",
      "title": "Multi-Lingual Cyber Threat Detection in Tweets/X Using ML, DL, and LLM: A Comparative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Saydul Akbar Murad",
        "Ashim Dahal",
        "Nick Rahimi"
      ],
      "abstract": "Cyber threat detection has become an important area of focus in today's\ndigital age due to the growing spread of fake information and harmful content\non social media platforms such as Twitter (now 'X'). These cyber threats, often\ndisguised within tweets, pose significant risks to individuals, communities,\nand even nations, emphasizing the need for effective detection systems. While\nprevious research has explored tweet-based threats, much of the work is limited\nto specific languages, domains, or locations, or relies on single-model\napproaches, reducing their applicability to diverse real-world scenarios. To\naddress these gaps, our study focuses on multi-lingual tweet cyber threat\ndetection using a variety of advanced models. The research was conducted in\nthree stages: (1) We collected and labeled tweet datasets in four languages\nEnglish, Chinese, Russian, and Arabic employing both manual and polarity-based\nlabeling methods to ensure high-quality annotations. (2) Each dataset was\nanalyzed individually using machine learning (ML) and deep learning (DL) models\nto assess their performance on distinct languages. (3) Finally, we combined all\nfour datasets into a single multi-lingual dataset and applied DL and large\nlanguage model (LLM) architectures to evaluate their efficacy in identifying\ncyber threats across various languages. Our results show that among machine\nlearning models, Random Forest (RF) attained the highest performance; however,\nthe Bi-LSTM architecture consistently surpassed other DL and LLM architectures\nacross all datasets. These findings underline the effectiveness of Bi-LSTM in\nmultilingual cyber threat detection. The code for this paper can be found at\nthis link: https://github.com/Mmurrad/Tweet-Data-Classification.git.",
      "tldr_zh": "本研究针对多语言推文网络威胁检测，收集并标注了英语、中文、俄语和阿拉伯语的推文数据集，使用手动和基于极性的方法确保标注质量。研究分三阶段进行：首先分析每个语言数据集的 Machine Learning (ML) 和 Deep Learning (DL) 模型性能；其次合并数据集并应用 DL 和 Large Language Model (LLM) 架构进行评估。结果显示，Random Forest (RF) 在 ML 模型中表现最佳，而 Bi-LSTM 模型在所有数据集上超越其他 DL 和 LLM 架构，突显其在多语言网络威胁检测中的优越性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04346v1",
      "published_date": "2025-02-04 03:46:24 UTC",
      "updated_date": "2025-02-04 03:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:08:43.884709"
    },
    {
      "arxiv_id": "2502.01976v5",
      "title": "CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Zheng",
        "Yixiao Chen",
        "Weitong Zhang",
        "Souvik Kundu",
        "Yun Li",
        "Zhengzhong Liu",
        "Eric P. Xing",
        "Hongyi Wang",
        "Huaxiu Yao"
      ],
      "abstract": "Large language models have achieved remarkable success in various tasks but\nsuffer from high computational costs during inference, limiting their\ndeployment in resource-constrained applications. To address this issue, we\npropose a novel Collaborative Inference with Token-lEvel Routing (CITER)\nframework that enables efficient collaboration between small and large language\nmodels (SLMs \\& LLMs) through a token-level routing strategy. Specifically,\nCITER routes non-critical tokens to an SLM for efficiency and routes critical\ntokens to an LLM for generalization quality. We formulate router training as a\npolicy optimization, where the router receives rewards based on both the\nquality of predictions and the inference costs of generation. This allows the\nrouter to learn to predict token-level routing scores and make routing\ndecisions based on both the current token and the future impact of its\ndecisions. To further accelerate the reward evaluation process, we introduce a\nshortcut which significantly reduces the costs of the reward estimation and\nimproving the practicality of our approach. Extensive experiments on five\nbenchmark datasets demonstrate that CITER reduces the inference costs while\npreserving high-quality generation, offering a promising solution for real-time\nand resource-constrained applications. Our data and code are available at\nhttps://github.com/aiming-lab/CITER.",
      "tldr_zh": "该论文提出 CITER 框架，通过 token-level routing 策略实现小语言模型 (SLMs) 和大型语言模型 (LLMs) 的协作推理，以降低 LLM 推理过程中的高计算成本。CITER 将非关键 tokens 路由到 SLM 以提升效率，并将关键 tokens 路由到 LLM 以确保生成质量；同时，将路由器训练表述为 policy optimization，路由器基于预测质量和推理成本获得奖励，并考虑决策的未来影响。论文引入一个 shortcut 加速奖励评估过程，进一步提高实用性。在五个基准数据集上的实验显示，CITER 显著减少了推理成本，同时保持高质量生成，为实时和资源受限应用提供了可行解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01976v5",
      "published_date": "2025-02-04 03:36:44 UTC",
      "updated_date": "2025-05-01 20:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:10:13.602571"
    },
    {
      "arxiv_id": "2502.06809v2",
      "title": "Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution",
      "title_zh": "神经元以范围方式表达：摆脱离散神经元归因",
      "authors": [
        "Muhammad Umair Haider",
        "Hammad Rizwan",
        "Hassan Sajjad",
        "Peizhong Ju",
        "A. B. Siddique"
      ],
      "abstract": "Interpreting the internal mechanisms of large language models (LLMs) is\ncrucial for improving their trustworthiness and utility. Prior work has\nprimarily focused on mapping individual neurons to discrete semantic concepts.\nHowever, such mappings struggle to handle the inherent polysemanticity in LLMs,\nwhere individual neurons encode multiple, distinct concepts. Through a\ncomprehensive analysis of both encoder and decoder-based LLMs across diverse\ndatasets, we observe that even highly salient neurons, identified via various\nattribution techniques for specific semantic concepts, consistently exhibit\npolysemantic behavior. Importantly, activation magnitudes for fine-grained\nconcepts follow distinct, often Gaussian-like distributions with minimal\noverlap. This observation motivates a shift from neuron attribution to\nrange-based interpretation. We hypothesize that interpreting and manipulating\nneuron activation ranges would enable more precise interpretability and\ntargeted interventions in LLMs. To validate our hypothesis, we introduce\nNeuronLens, a novel range-based interpretation and manipulation framework that\nprovides a finer view of neuron activation distributions to localize concept\nattribution within a neuron. Extensive empirical evaluations demonstrate that\nNeuronLens significantly reduces unintended interference, while maintaining\nprecise manipulation of targeted concepts, outperforming neuron attribution.",
      "tldr_zh": "这篇论文挑战了传统将神经元映射到离散语义概念的做法，指出大型语言模型（LLMs）中的神经元存在polysemanticity，即单个神经元编码多个概念，导致归因不准确。通过分析各种encoder和decoder-based LLMs，他们发现神经元激活幅度遵循独特分布（如高斯-like分布），分布之间重叠最小，从而提出从neuron attribution转向基于范围的解释方法。论文引入NeuronLens框架，该框架提供更精细的神经元激活分布视图，用于精确定位概念归因和操作。实验结果显示，NeuronLens显著减少了意外干扰，同时在针对概念的操作上优于传统方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06809v2",
      "published_date": "2025-02-04 03:33:55 UTC",
      "updated_date": "2025-05-21 03:16:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:10:11.304804"
    },
    {
      "arxiv_id": "2502.01972v1",
      "title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography",
      "title_zh": "层分离：常规放射摄影中的可调节关节间隙宽度图像合成",
      "authors": [
        "Haolin Wang",
        "Yafei Ou",
        "Prasoon Ambalathankandy",
        "Gen Ota",
        "Pengyu Dai",
        "Masayuki Ikebe",
        "Kenji Suzuki",
        "Tamotsu Kamishima"
      ],
      "abstract": "Rheumatoid arthritis (RA) is a chronic autoimmune disease characterized by\njoint inflammation and progressive structural damage. Joint space width (JSW)\nis a critical indicator in conventional radiography for evaluating disease\nprogression, which has become a prominent research topic in computer-aided\ndiagnostic (CAD) systems. However, deep learning-based radiological CAD systems\nfor JSW analysis face significant challenges in data quality, including data\nimbalance, limited variety, and annotation difficulties. This work introduced a\nchallenging image synthesis scenario and proposed Layer Separation Networks\n(LSN) to accurately separate the soft tissue layer, the upper bone layer, and\nthe lower bone layer in conventional radiographs of finger joints. Using these\nlayers, the adjustable JSW images can be synthesized to address data quality\nchallenges and achieve ground truth (GT) generation. Experimental results\ndemonstrated that LSN-based synthetic images closely resemble real radiographs,\nand significantly enhanced the performance in downstream tasks. The code and\ndataset will be available.",
      "tldr_zh": "本研究针对风湿性关节炎(RA)诊断中Joint Space Width (JSW)评估的挑战，提出Layer Separation Networks (LSN)，用于在常规放射图像中准确分离软组织层、上骨层和下骨层，从而合成可调节的JSW图像，以解决数据不平衡、品种有限和标注困难等问题。利用这些分离层生成的合成图像可作为ground truth (GT)，显著提升计算机辅助诊断(CAD)系统的性能。实验证明，LSN合成的图像与真实放射图像高度相似，并在下游任务中实现了性能提升。该方法为RA诊断提供了一种创新的数据增强策略，并计划公开代码和数据集。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.3.3; J.3; I.4.0"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01972v1",
      "published_date": "2025-02-04 03:33:52 UTC",
      "updated_date": "2025-02-04 03:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:09:19.877697"
    },
    {
      "arxiv_id": "2502.01969v1",
      "title": "Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Younan Zhu",
        "Linwei Tao",
        "Minjing Dong",
        "Chang Xu"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning\ncapabilities but remain highly susceptible to object hallucination, where\nmodels generate responses that are not factually aligned with the visual\ncontent. Recent works attribute this issue to an inherent bias of LVLMs where\nvision token attention map has a fixed correlation with spatial position, and\npropose to mitigate this issue by reordering visual tokens. However, we find\nthat different LVLMs exhibit different correlations between attention and\nspatial position, which makes the existing solution difficult to generalize to\nother LVLMs. To address this issue, we first introduce a training-free\nsolution, Uniform Attention Calibration (UAC), that estimates the bias from\nsingle meaningless input image and applies a calibration matrix to rectify\nattention imbalances. To further alleviate the bias, we relax the assumption of\nsingle meaningless input in UAC and introduce a fine-tuning solution, Dynamic\nAttention Calibration (DAC), that enforces the consistent outputs wherever the\nobject locates in the image via a plug-and-plays module. Comprehensive\nexperiments across multiple benchmarks demonstrate that UAC and DAC\nsignificantly reduce object hallucination while improving general multimodal\nalignment. Our methods achieve state-of-the-art performance across diverse LVLM\narchitectures on various metrics.",
      "tldr_zh": "这篇论文针对 Large Vision-Language Models (LVLMs) 中的 object hallucination 问题，提出通过注意力校准来缓解模型生成与视觉内容不符的响应。作者引入了无训练方法 Uniform Attention Calibration (UAC)，通过从单一无意义输入图像估计偏差并应用校准矩阵来修正注意力不平衡，从而提升模型的一般化能力。此外，Dynamic Attention Calibration (DAC) 作为微调解决方案，通过一个即插即用模块强制输出在图像中物体位置的一致性。实验结果显示，UAC 和 DAC 在多个基准上显著减少了 object hallucination，同时改善了多模态对齐，并实现了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01969v1",
      "published_date": "2025-02-04 03:27:38 UTC",
      "updated_date": "2025-02-04 03:27:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:09:31.675051"
    },
    {
      "arxiv_id": "2502.01968v1",
      "title": "Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlong Pang",
        "Na Di",
        "Zhaowei Zhu",
        "Jiaheng Wei",
        "Hao Cheng",
        "Chen Qian",
        "Yang Liu"
      ],
      "abstract": "Recent studies show that in supervised fine-tuning (SFT) of large language\nmodels (LLMs), data quality matters more than quantity. While most data\ncleaning methods concentrate on filtering entire samples, the quality of\nindividual tokens within a sample can vary significantly. After pre-training,\neven in high-quality samples, patterns or phrases that are not task-related can\nbe redundant or uninformative. Continuing to fine-tune on these patterns may\noffer limited benefit and even degrade downstream task performance. In this\npaper, we investigate token quality from a noisy-label perspective and propose\na generic token cleaning pipeline for SFT tasks. Our method filters out\nuninformative tokens while preserving those carrying key task-specific\ninformation. Specifically, we first evaluate token quality by examining the\ninfluence of model updates on each token, then apply a threshold-based\nseparation. The token influence can be measured in a single pass with a fixed\nreference model or iteratively with self-evolving reference models. The\nbenefits and limitations of both methods are analyzed theoretically by error\nupper bounds. Extensive experiments show that our framework consistently\nimproves performance across multiple downstream tasks.",
      "tldr_zh": "本研究发现，在大型语言模型（LLMs）的监督微调（SFT）中，数据质量比数量更关键，而现有方法主要过滤整个样本，忽略了样本内 token 的细粒度差异。论文从噪声标签视角提出一个通用的 token cleaning 管道，通过评估模型更新对每个 token 的影响（如使用固定参考模型单次通过或自演化参考模型迭代），并基于阈值分离出无信息 token，同时保留任务相关信息。实验结果显示，该框架在多个下游任务上 consistently 提升性能，为 SFT 数据选择提供了更精细的策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01968v1",
      "published_date": "2025-02-04 03:26:58 UTC",
      "updated_date": "2025-02-04 03:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:09:43.653455"
    },
    {
      "arxiv_id": "2503.15527v1",
      "title": "Exploring the Panorama of Anxiety Levels: A Multi-Scenario Study Based on Human-Centric Anxiety Level Detection and Personalized Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Longdi Xian",
        "Junhao Xu"
      ],
      "abstract": "More and more people are experiencing pressure from work, life, and\neducation. These pressures often lead to an anxious state of mind, or even the\nearly symptoms of suicidal ideation. With the advancement of artificial\nintelligence (AI) technology, large language models have become one of the most\nprominent technologies. They are often used for detecting psychological\ndisorders. However, current studies primarily provide categorization results\nwithout offering interpretable explanations for these results. To address this\ngap, this study adopts a person-centered perspective and focuses on\nGPT-generated multi-scenario simulated conversations. These simulated\nconversations were selected as data samples for the study. Various\ntransformer-based encoder models were utilized to develop a classification\nmodel capable of identifying different levels of anxiety. Additionally, a\nknowledge base focusing on anxiety was constructed using LangChain and GPT-4.\nWhen analyzing classification results, this knowledge base was able to provide\nexplanations and reasons most relevant to the interlocutor's anxiety situation.\nThe study demonstrates that the proposed model achieves over 94% accuracy in\ncategorical prediction, and the advice provided is highly personalized and\nrelevant.",
      "tldr_zh": "这篇论文探讨了人工智能在焦虑水平检测中的应用，针对人们因工作、生活和教育压力引发的焦虑或自杀念头等问题。研究采用以人为本的视角，使用 GPT 生成的多场景模拟对话作为数据样本，并通过 transformer-based encoder 模型开发分类模型，实现对不同焦虑水平的准确识别，预测准确率超过 94%。此外，论文构建了基于 LangChain 和 GPT-4 的焦虑知识库，能够为分类结果提供个性化的解释和相关建议，从而提升心理干预的可解释性和针对性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15527v1",
      "published_date": "2025-02-04 03:14:21 UTC",
      "updated_date": "2025-02-04 03:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:09:55.003774"
    },
    {
      "arxiv_id": "2502.01956v1",
      "title": "DHP: Discrete Hierarchical Planning for Hierarchical Reinforcement Learning Agents",
      "title_zh": "DHP：离散层次规划用于层次强化学习代理",
      "authors": [
        "Shashank Sharma",
        "Janina Hoffmann",
        "Vinay Namboodiri"
      ],
      "abstract": "In this paper, we address the challenge of long-horizon visual planning tasks\nusing Hierarchical Reinforcement Learning (HRL). Our key contribution is a\nDiscrete Hierarchical Planning (DHP) method, an alternative to traditional\ndistance-based approaches. We provide theoretical foundations for the method\nand demonstrate its effectiveness through extensive empirical evaluations.\n  Our agent recursively predicts subgoals in the context of a long-term goal\nand receives discrete rewards for constructing plans as compositions of\nabstract actions. The method introduces a novel advantage estimation strategy\nfor tree trajectories, which inherently encourages shorter plans and enables\ngeneralization beyond the maximum tree depth. The learned policy function\nallows the agent to plan efficiently, requiring only $\\log N$ computational\nsteps, making re-planning highly efficient. The agent, based on a soft-actor\ncritic (SAC) framework, is trained using on-policy imagination data.\nAdditionally, we propose a novel exploration strategy that enables the agent to\ngenerate relevant training examples for the planning modules. We evaluate our\nmethod on long-horizon visual planning tasks in a 25-room environment, where it\nsignificantly outperforms previous benchmarks at success rate and average\nepisode length. Furthermore, an ablation study highlights the individual\ncontributions of key modules to the overall performance.",
      "tldr_zh": "本文提出Discrete Hierarchical Planning (DHP)方法，作为传统距离-based方法的替代，用于Hierarchical Reinforcement Learning (HRL)代理处理长视野视觉规划任务。DHP通过递归预测子目标、离散奖励和新型优势估计策略来构建抽象动作的组合计划，从而鼓励更短路径、提升泛化能力，并基于soft-actor critic (SAC)框架使用on-policy imagination data进行训练。实验结果显示，该方法在25-room环境的基准任务上显著提高成功率并缩短平均episode长度，同时提出的新探索策略和消融研究证实了关键模块的个体贡献。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01956v1",
      "published_date": "2025-02-04 03:05:55 UTC",
      "updated_date": "2025-02-04 03:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:10:07.931207"
    },
    {
      "arxiv_id": "2502.06808v3",
      "title": "On the Benefits of Attribute-Driven Graph Domain Adaptation",
      "title_zh": "论属性驱动的图域适应的益处",
      "authors": [
        "Ruiyi Fang",
        "Bingheng Li",
        "Zhao Kang",
        "Qiuhao Zeng",
        "Nima Hosseini Dashtbayaz",
        "Ruizhi Pu",
        "Boyu Wang",
        "Charles Ling"
      ],
      "abstract": "Graph Domain Adaptation (GDA) addresses a pressing challenge in cross-network\nlearning, particularly pertinent due to the absence of labeled data in\nreal-world graph datasets. Recent studies attempted to learn domain invariant\nrepresentations by eliminating structural shifts between graphs. In this work,\nwe show that existing methodologies have overlooked the significance of the\ngraph node attribute, a pivotal factor for graph domain alignment.\nSpecifically, we first reveal the impact of node attributes for GDA by\ntheoretically proving that in addition to the graph structural divergence\nbetween the domains, the node attribute discrepancy also plays a critical role\nin GDA. Moreover, we also empirically show that the attribute shift is more\nsubstantial than the topology shift, which further underscores the importance\nof node attribute alignment in GDA. Inspired by this finding, a novel\ncross-channel module is developed to fuse and align both views between the\nsource and target graphs for GDA. Experimental results on a variety of\nbenchmarks verify the effectiveness of our method.",
      "tldr_zh": "这篇论文探讨了 Graph Domain Adaptation (GDA) 在跨网络学习中的优势，强调了节点属性的关键作用，因为现有方法主要关注结构差异而忽略了属性差异。作者理论证明了节点属性差异除了结构发散外，在 GDA 中同样至关重要，并通过实证实验显示属性偏移比拓扑偏移更显著。基于这一发现，他们开发了一种新型跨通道模块，用于融合和对齐源目标图的属性和结构视图。实验结果在多种基准上验证了该方法的有效性，提高了 GDA 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06808v3",
      "published_date": "2025-02-04 03:04:04 UTC",
      "updated_date": "2025-02-24 19:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:12:24.915968"
    },
    {
      "arxiv_id": "2502.10419v1",
      "title": "A Hybrid Swarm Intelligence Approach for Optimizing Multimodal Large Language Models Deployment in Edge-Cloud-based Federated Learning Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Gaith Rjouba",
        "Hanae Elmekki",
        "Saidul Islam",
        "Jamal Bentahar",
        "Rachida Dssouli"
      ],
      "abstract": "The combination of Federated Learning (FL), Multimodal Large Language Models\n(MLLMs), and edge-cloud computing enables distributed and real-time data\nprocessing while preserving privacy across edge devices and cloud\ninfrastructure. However, the deployment of MLLMs in FL environments with\nresource-constrained edge devices presents significant challenges, including\nresource management, communication overhead, and non-IID data. To address these\nchallenges, we propose a novel hybrid framework wherein MLLMs are deployed on\nedge devices equipped with sufficient resources and battery life, while the\nmajority of training occurs in the cloud. To identify suitable edge devices for\ndeployment, we employ Particle Swarm Optimization (PSO), and Ant Colony\nOptimization (ACO) is utilized to optimize the transmission of model updates\nbetween edge and cloud nodes. This proposed swarm intelligence-based framework\naims to enhance the efficiency of MLLM training by conducting extensive\ntraining in the cloud and fine-tuning at the edge, thereby reducing energy\nconsumption and communication costs. Our experimental results show that the\nproposed method significantly improves system performance, achieving an\naccuracy of 92%, reducing communication cost by 30%, and enhancing client\nparticipation compared to traditional FL methods. These results make the\nproposed approach highly suitable for large-scale edge-cloud computing systems.",
      "tldr_zh": "本研究提出了一种混合群智能方法，用于优化多模态大语言模型(MLLMs)在基于边缘-云的联邦学习(FL)环境中的部署，旨在解决资源管理、通信开销和非IID数据等挑战。框架将MLLMs部署在资源充足的边缘设备上，主要训练在云端，并利用粒子群优化(PSO)算法选择合适的边缘设备，以及蚁群优化(ACO)算法优化模型更新传输，从而降低能量消耗和通信成本。实验结果显示，该方法实现了92%的准确率，将通信成本减少30%，并提升了客户端参与度，使其适用于大规模边缘-云计算系统。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10419v1",
      "published_date": "2025-02-04 03:03:24 UTC",
      "updated_date": "2025-02-04 03:03:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:10:36.124437"
    },
    {
      "arxiv_id": "2502.01949v2",
      "title": "LAYOUTDREAMER: Physics-guided Layout for Text-to-3D Compositional Scene Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhou",
        "Zongjin He",
        "Qixuan Li",
        "Chao Wang"
      ],
      "abstract": "Recently, the field of text-guided 3D scene generation has garnered\nsignificant attention. High-quality generation that aligns with physical\nrealism and high controllability is crucial for practical 3D scene\napplications. However, existing methods face fundamental limitations: (i)\ndifficulty capturing complex relationships between multiple objects described\nin the text, (ii) inability to generate physically plausible scene layouts, and\n(iii) lack of controllability and extensibility in compositional scenes. In\nthis paper, we introduce LayoutDreamer, a framework that leverages 3D Gaussian\nSplatting (3DGS) to facilitate high-quality, physically consistent\ncompositional scene generation guided by text. Specifically, given a text\nprompt, we convert it into a directed scene graph and adaptively adjust the\ndensity and layout of the initial compositional 3D Gaussians. Subsequently,\ndynamic camera adjustments are made based on the training focal point to ensure\nentity-level generation quality. Finally, by extracting directed dependencies\nfrom the scene graph, we tailor physical and layout energy to ensure both\nrealism and flexibility. Comprehensive experiments demonstrate that\nLayoutDreamer outperforms other compositional scene generation quality and\nsemantic alignment methods. Specifically, it achieves state-of-the-art (SOTA)\nperformance in the multiple objects generation metric of T3Bench.",
      "tldr_zh": "该论文提出了 LayoutDreamer，一种基于 3D Gaussian Splatting (3DGS) 的框架，用于文本引导的 3D 组合场景生成，旨在解决现有方法在捕捉对象关系、生成物理合理布局以及可控性方面的局限性。具体而言，LayoutDreamer 将文本提示转换为有向场景图，并通过自适应调整 3D 高斯的密度和布局、动态相机优化以及定制的物理布局能量，确保场景的真实性和灵活性。实验结果表明，该框架在 T3Bench 的多对象生成指标上实现了最先进（SOTA）性能，并在整体质量和语义对齐方面优于其他方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01949v2",
      "published_date": "2025-02-04 02:51:37 UTC",
      "updated_date": "2025-03-22 12:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:10:49.138730"
    },
    {
      "arxiv_id": "2502.01942v1",
      "title": "Boundary-Driven Table-Filling with Cross-Granularity Contrastive Learning for Aspect Sentiment Triplet Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Qingling Li",
        "Wushao Wen",
        "Jinghui Qin"
      ],
      "abstract": "The Aspect Sentiment Triplet Extraction (ASTE) task aims to extract aspect\nterms, opinion terms, and their corresponding sentiment polarity from a given\nsentence. It remains one of the most prominent subtasks in fine-grained\nsentiment analysis. Most existing approaches frame triplet extraction as a 2D\ntable-filling process in an end-to-end manner, focusing primarily on word-level\ninteractions while often overlooking sentence-level representations. This\nlimitation hampers the model's ability to capture global contextual\ninformation, particularly when dealing with multi-word aspect and opinion terms\nin complex sentences. To address these issues, we propose boundary-driven\ntable-filling with cross-granularity contrastive learning (BTF-CCL) to enhance\nthe semantic consistency between sentence-level representations and word-level\nrepresentations. By constructing positive and negative sample pairs, the model\nis forced to learn the associations at both the sentence level and the word\nlevel. Additionally, a multi-scale, multi-granularity convolutional method is\nproposed to capture rich semantic information better. Our approach can capture\nsentence-level contextual information more effectively while maintaining\nsensitivity to local details. Experimental results show that the proposed\nmethod achieves state-of-the-art performance on public benchmarks according to\nthe F1 score.",
      "tldr_zh": "本研究针对Aspect Sentiment Triplet Extraction (ASTE)任务，提出了一种边界驱动的表填充方法（Boundary-Driven Table-Filling），结合跨粒度对比学习（Cross-Granularity Contrastive Learning），以增强句子级和词级表示之间的语义一致性。\n该方法通过构建正负样本对和多尺度、多粒度卷积，better capture sentence-level contextual information，同时保持对局部细节的敏感性，从而解决现有方法忽略全局上下文的问题。\n实验结果表明，该方法在公共基准上根据F1分数达到了state-of-the-art性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01942v1",
      "published_date": "2025-02-04 02:23:45 UTC",
      "updated_date": "2025-02-04 02:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:11:03.358138"
    },
    {
      "arxiv_id": "2502.01941v2",
      "title": "Can LLMs Maintain Fundamental Abilities under KV Cache Compression?",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Liu",
        "Zhenheng Tang",
        "Hong Chen",
        "Peijie Dong",
        "Zeyu Li",
        "Xiuze Zhou",
        "Bo Li",
        "Xuming Hu",
        "Xiaowen Chu"
      ],
      "abstract": "This paper investigates an underexplored challenge in large language models\n(LLMs): the impact of KV cache compression methods on LLMs' fundamental\ncapabilities. Although existing methods achieve impressive compression ratios\non long-context benchmarks, their effects on core model capabilities remain\nunderstudied. We present a comprehensive benchmark KVFundaBench to\nsystematically evaluate the effects of KV cache compression across diverse\nfundamental LLM capabilities, spanning world knowledge, commonsense reasoning,\narithmetic reasoning, code generation, safety, and long-context understanding\nand generation.Our analysis reveals serval key findings: (1)\n\\textit{Task-Dependent Degradation}; (2) \\textit{Model-Type Robustness} (3)\n\\textit{Prompt Length Vulnerability}; (4) \\textit{Chunk-Level Superiority}; (5)\n\\textit{Prompt-Gain Sensitivity}; (6) \\textit{Long-Context Generation\nSensitivity}. Based on our analysis of attention patterns and cross-task\ncompression performance, we propose ShotKV, a novel compression approach that\ndistinctly handles prefill and decoding phases while maintaining shot-level\nsemantic coherence. Empirical results show that ShotKV achieves $9\\%$-$18\\%$\nperformance improvements on long-context generation tasks under aggressive\ncompression ratios.",
      "tldr_zh": "本研究探讨了 KV 缓存压缩对大语言模型 (LLMs) 基本能力的潜在影响，引入了全面基准 KVFundaBench 来评估压缩方法在世界知识、常识推理、算术推理、代码生成、安全性和长上下文理解与生成等领域的表现。分析揭示了关键发现，包括任务依赖性退化、模型类型鲁棒性、提示长度脆弱性、块级优越性、提示增益敏感性和长上下文生成敏感性。基于对注意力模式和跨任务性能的分析，该论文提出了新型压缩方法 ShotKV，它在预填充和解码阶段保持 shot-level 语义连贯性，并在高压缩率下实现了长上下文生成任务的9%-18%性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01941v2",
      "published_date": "2025-02-04 02:23:06 UTC",
      "updated_date": "2025-05-21 10:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:11:12.885072"
    },
    {
      "arxiv_id": "2502.01932v3",
      "title": "VolleyBots: A Testbed for Multi-Drone Volleyball Game Combining Motion Control and Strategic Play",
      "title_zh": "翻译失败",
      "authors": [
        "Zelai Xu",
        "Ruize Zhang",
        "Chao Yu",
        "Huining Yuan",
        "Xiangmin Yi",
        "Shilong Ji",
        "Chuqi Wang",
        "Wenhao Tang",
        "Feng Gao",
        "Wenbo Ding",
        "Xinlei Chen",
        "Yu Wang"
      ],
      "abstract": "Robot sports, characterized by well-defined objectives, explicit rules, and\ndynamic interactions, present ideal scenarios for demonstrating embodied\nintelligence. In this paper, we present VolleyBots, a novel robot sports\ntestbed where multiple drones cooperate and compete in the sport of volleyball\nunder physical dynamics. VolleyBots integrates three features within a unified\nplatform: competitive and cooperative gameplay, turn-based interaction\nstructure, and agile 3D maneuvering. Competitive and cooperative gameplay\nchallenges each drone to coordinate with its teammates while anticipating and\ncountering opposing teams' tactics. Turn-based interaction demands precise\ntiming, accurate state prediction, and management of long-horizon temporal\ndependencies. Agile 3D maneuvering requires rapid accelerations, sharp turns,\nand precise 3D positioning despite the quadrotor's underactuated dynamics.\nThese intertwined features yield a complex problem combining motion control and\nstrategic play, with no available expert demonstrations. We provide a\ncomprehensive suite of tasks ranging from single-drone drills to multi-drone\ncooperative and competitive tasks, accompanied by baseline evaluations of\nrepresentative multi-agent reinforcement learning (MARL) and game-theoretic\nalgorithms. Simulation results show that on-policy reinforcement learning (RL)\nmethods outperform off-policy methods in single-agent tasks, but both\napproaches struggle in complex tasks that combine motion control and strategic\nplay. We additionally design a hierarchical policy which achieves a 69.5%\npercent win rate against the strongest baseline in the 3 vs 3 task,\nunderscoring its potential as an effective solution for tackling the complex\ninterplay between low-level control and high-level strategy. The project page\nis at https://sites.google.com/view/thu-volleybots.",
      "tldr_zh": "本文提出 VolleyBots，一种多无人机排球游戏测试平台，旨在通过竞争合作游戏、回合制交互和敏捷 3D 机动，展示机器人体育中的智能挑战。该平台提供从单无人机训练到多无人机合作/竞争任务的全面任务套件，并评估了多代理强化学习 (MARL) 和博弈论算法。实验结果显示，on-policy RL 方法在单代理任务中优于 off-policy 方法，而设计的分层策略在 3 vs 3 任务中击败最强基线，胜率达 69.5%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01932v3",
      "published_date": "2025-02-04 02:07:23 UTC",
      "updated_date": "2025-05-17 11:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:11:25.005048"
    },
    {
      "arxiv_id": "2502.01930v1",
      "title": "Distributionally Robust Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zaiyan Xu",
        "Sushil Vemuri",
        "Kishan Panaganti",
        "Dileep Kalathil",
        "Rahul Jain",
        "Deepak Ramachandran"
      ],
      "abstract": "A major challenge in aligning large language models (LLMs) with human\npreferences is the issue of distribution shift. LLM alignment algorithms rely\non static preference datasets, assuming that they accurately represent\nreal-world user preferences. However, user preferences vary significantly\nacross geographical regions, demographics, linguistic patterns, and evolving\ncultural trends. This preference distribution shift leads to catastrophic\nalignment failures in many real-world applications. We address this problem\nusing the principled framework of distributionally robust optimization, and\ndevelop two novel distributionally robust direct preference optimization (DPO)\nalgorithms, namely, Wasserstein DPO (WDPO) and Kullback-Leibler DPO (KLDPO). We\ncharacterize the sample complexity of learning the optimal policy parameters\nfor WDPO and KLDPO. Moreover, we propose scalable gradient descent-style\nlearning algorithms by developing suitable approximations for the challenging\nminimax loss functions of WDPO and KLDPO. Our empirical experiments demonstrate\nthe superior performance of WDPO and KLDPO in substantially improving the\nalignment when there is a preference distribution shift.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 在对齐人类偏好时面临的偏好分布偏移问题（如地区、人口统计和文化差异导致的对齐失败），提出了一种基于分布鲁棒优化的框架。作者开发了两种新算法：Wasserstein DPO (WDPO) 和 Kullback-Leibler DPO (KLDPO)，并分析了这些算法的样本复杂度，同时设计了可扩展的梯度下降式学习算法来优化其最小最大损失函数。实验结果表明，WDPO 和 KLDPO 在偏好分布偏移场景下显著提升了模型的对齐性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01930v1",
      "published_date": "2025-02-04 02:03:19 UTC",
      "updated_date": "2025-02-04 02:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:11:36.614121"
    },
    {
      "arxiv_id": "2502.04345v1",
      "title": "JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment",
      "title_zh": "翻译失败",
      "authors": [
        "Yehan Yan",
        "Tianhao Ma",
        "Ruotai Li",
        "Xinhan Zheng",
        "Guodong Shan",
        "Chisheng Li"
      ],
      "abstract": "Traditional Chinese medicine (TCM) plays a vital role in health protection\nand disease treatment, but its practical application requires extensive medical\nknowledge and clinical experience. Existing TCM Large Language Models (LLMs)\nexhibit critical limitations of uncomprehensive medical consultation and\ndiagnoses, and inaccurate syndrome differentiation-based treatment. To address\nthese issues, this study establishes JingFang (JF): a novel TCM Large Language\nModel that demonstrates the expert-level capability of medical diagnosis and\nsyndrome differentiation-based treatment. We innovate a Multi-agent Dynamic\nCollaborative Chain-of-Thought Mechanism (MDCCTM) for medical consultation,\nenabling JF with effective and accurate diagnostic ability. In addition, a\nSyndrome Agent and a Dual-Stage Retrieval Scheme (DSRS) are developed to\nsignificantly enhance the capacity of JF for disease treatment based on\nsyndrome differentiation. JingFang not only facilitates the application of LLMs\nbut also promotes the effective practice of TCM in human health protection and\ndisease treatment.",
      "tldr_zh": "本研究开发了 JingFang，一种专家级别的 Traditional Chinese Medicine (TCM) Large Language Model (LLM)，旨在解决现有模型在医疗咨询、诊断和基于辨证论治的治疗中的不全面性和不准确性问题。创新性地引入 Multi-agent Dynamic Collaborative Chain-of-Thought Mechanism (MDCCTM) 以提升诊断准确性，以及 Syndrome Agent 和 Dual-Stage Retrieval Scheme (DSRS) 来强化疾病治疗的辨证能力。JingFang 的应用不仅推动了 LLMs 在 TCM 领域的实践，还促进了中医在人类健康保护和疾病治疗中的有效实施。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04345v1",
      "published_date": "2025-02-04 01:45:42 UTC",
      "updated_date": "2025-02-04 01:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:11:49.285756"
    },
    {
      "arxiv_id": "2502.01922v1",
      "title": "LAST SToP For Modeling Asynchronous Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Gupta",
        "Thibaut Durand",
        "Graham Taylor",
        "Lilian W. Białokozowicz"
      ],
      "abstract": "We present a novel prompt design for Large Language Models (LLMs) tailored to\nAsynchronous Time Series. Unlike regular time series, which assume values at\nevenly spaced time points, asynchronous time series consist of timestamped\nevents occurring at irregular intervals, each described in natural language.\nOur approach effectively utilizes the rich natural language of event\ndescriptions, allowing LLMs to benefit from their broad world knowledge for\nreasoning across different domains and tasks. This allows us to extend the\nscope of asynchronous time series analysis beyond forecasting to include tasks\nlike anomaly detection and data imputation. We further introduce Stochastic\nSoft Prompting, a novel prompt-tuning mechanism that significantly improves\nmodel performance, outperforming existing fine-tuning methods such as QLoRA.\nThrough extensive experiments on real world datasets, we demonstrate that our\napproach achieves state-of-the-art performance across different tasks and\ndatasets.",
      "tldr_zh": "该研究提出了一种名为 LAST SToP 的新型提示设计，针对 Large Language Models (LLMs) 处理 Asynchronous Time Series，即不规则间隔的带有自然语言描述的时间戳事件。该方法充分利用事件描述的丰富信息，结合 LLMs 的广泛世界知识，实现跨领域推理，并扩展应用范围至异常检测和数据插值等任务。研究还引入了 Stochastic Soft Prompting 机制，这是一种先进的提示调整方法，比现有 fine-tuning 技术如 QLoRA 表现更优；通过在真实数据集上的广泛实验，证明了该方法在多种任务和数据集上达到了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01922v1",
      "published_date": "2025-02-04 01:42:45 UTC",
      "updated_date": "2025-02-04 01:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:12:00.218949"
    },
    {
      "arxiv_id": "2502.01918v1",
      "title": "Wake-Informed 3D Path Planning for Autonomous Underwater Vehicles Using A* and Neural Network Approximations",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary Cooper-Baldock",
        "Stephen Turnock",
        "Karl Sammut"
      ],
      "abstract": "Autonomous Underwater Vehicles (AUVs) encounter significant energy, control\nand navigation challenges in complex underwater environments, particularly\nduring close-proximity operations, such as launch and recovery (LAR), where\nfluid interactions and wake effects present additional navigational and energy\nchallenges. Traditional path planning methods fail to incorporate these\ndetailed wake structures, resulting in increased energy consumption, reduced\ncontrol stability, and heightened safety risks. This paper presents a novel\nwake-informed, 3D path planning approach that fully integrates localized wake\neffects and global currents into the planning algorithm. Two variants of the A*\nalgorithm - a current-informed planner and a wake-informed planner - are\ncreated to assess its validity and two neural network models are then trained\nto approximate these planners for real-time applications. Both the A* planners\nand NN models are evaluated using important metrics such as energy expenditure,\npath length, and encounters with high-velocity and turbulent regions. The\nresults demonstrate a wake-informed A* planner consistently achieves the lowest\nenergy expenditure and minimizes encounters with high-velocity regions,\nreducing energy consumption by up to 11.3%. The neural network models are\nobserved to offer computational speedup of 6 orders of magnitude, but exhibit\n4.51 - 19.79% higher energy expenditures and 9.81 - 24.38% less optimal paths.\nThese findings underscore the importance of incorporating detailed wake\nstructures into traditional path planning algorithms and the benefits of neural\nnetwork approximations to enhance energy efficiency and operational safety for\nAUVs in complex 3D domains.",
      "tldr_zh": "该论文针对自主水下车辆(AUVs)在复杂环境中的路径规划挑战，提出了一种新型尾流感知的3D路径规划方法，将本地尾流效应和全局水流整合到算法中，以减少能量消耗和提升控制稳定性。方法包括开发两种A*算法变体（水流感知和尾流感知规划器），并训练神经网络模型来实现实时近似。实验评估显示，尾流感知A*规划器可将能量消耗降低多达11.3%，并最小化高速区域遇险，但神经网络模型虽提供6个数量级的计算加速，却导致4.51-19.79%的更高能量消耗和9.81-24.38%的次优路径。这些发现强调了在传统路径规划中整合详细尾流结构的重要性，以提高AUV的能量效率和操作安全。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "68T40, 68T07, 90C35",
        "I.2.8; I.2.9; I.5.1"
      ],
      "primary_category": "cs.RO",
      "comment": "11 pages, 6 figures, preprint of journal paper",
      "pdf_url": "http://arxiv.org/pdf/2502.01918v1",
      "published_date": "2025-02-04 01:23:23 UTC",
      "updated_date": "2025-02-04 01:23:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:13:45.148961"
    },
    {
      "arxiv_id": "2502.01912v2",
      "title": "PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings",
      "title_zh": "PATCH：一种评估历史绘画中艺术实践异质性的深度学习方法",
      "authors": [
        "Andrew Van Horn",
        "Lauryn Smith",
        "Mahamad Mahmoud",
        "Michael McMaster",
        "Clara Pinchbeck",
        "Ina Martin",
        "Andrew Lininger",
        "Anthony Ingrisano",
        "Adam Lowe",
        "Carlos Bayod",
        "Elizabeth Bolman",
        "Kenneth Singer",
        "Michael Hinczewski"
      ],
      "abstract": "The history of art has seen significant shifts in the manner in which\nartworks are created, making understanding of creative processes a central\nquestion in technical art history. In the Renaissance and Early Modern period,\npaintings were largely produced by master painters directing workshops of\napprentices who often contributed to projects. The masters varied significantly\nin artistic and managerial styles, meaning different combinations of artists\nand implements might be seen both between masters and within workshops or even\nindividual canvases. Information on how different workshops were managed and\nthe processes by which artworks were created remains elusive. Machine learning\nmethods have potential to unearth new information about artists' creative\nprocesses by extending the analysis of brushwork to a microscopic scale.\nAnalysis of workshop paintings, however, presents a challenge in that\ndocumentation of the artists and materials involved is sparse, meaning external\nexamples are not available to train networks to recognize their contributions.\nHere we present a novel machine learning approach we call pairwise assignment\ntraining for classifying heterogeneity (PATCH) that is capable of identifying\nindividual artistic practice regimes with no external training data, or \"ground\ntruth.\" The method achieves unsupervised results by supervised means, and\noutperforms both simple statistical procedures and unsupervised machine\nlearning methods. We apply this method to two historical paintings by the\nSpanish Renaissance master, El Greco: The Baptism of Christ and Christ on the\nCross with Landscape, and our findings regarding the former potentially\nchallenge previous work that has assigned the painting to workshop members.\nFurther, the results of our analyses create a measure of heterogeneity of\nartistic practice that can be used to characterize artworks across time and\nspace.",
      "tldr_zh": "这篇论文提出了一种名为 PATCH 的深度学习方法，用于评估历史绘画中艺术实践异质性的问题，特别是文艺复兴时期画家工作室的创作过程。PATCH 采用 pairwise assignment training 技术，通过监督手段实现无监督结果，无需外部训练数据即可识别个体艺术实践，并优于简单统计程序和无监督机器学习方法。在 El Greco 的两幅画作《The Baptism of Christ》和《Christ on the Cross with Landscape》上应用该方法后，研究发现可能挑战现有作品归属，并提供了一种量化艺术实践异质性的度量工具，以跨时空比较艺术作品。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "main text: 16 pages, 6 figures; SI: 7 pages, 3 figures; v2: minor\n  typo corrections, higher resolution figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01912v2",
      "published_date": "2025-02-04 01:05:12 UTC",
      "updated_date": "2025-03-03 05:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T07:13:56.973260"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 151,
  "processed_papers_count": 151,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T07:14:14.788151"
}