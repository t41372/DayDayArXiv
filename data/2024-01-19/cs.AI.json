{
  "date": "2024-01-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-19 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 65 篇论文，主要聚焦 AI 和机器学习领域，包括大型语言模型（LLMs）的多任务应用、深度学习模型优化、多模态理解和强化学习等关键话题。其中，令人印象深刻的是 Jitendra Malik 参与的视频生成论文，以及多模态基准数据集 Mementos 的提出，这些工作展示了 LLMs 在动态场景中的潜力；同时，有名学者如 Jitendra Malik 和 Roger Levy 的文章在视频理解和语言判断方面表现出色。\n\n以下是今日值得关注的论文，我将优先讨论那些具有创新性、潜在影响力和知名作者的文章，并将相关主题归类讨论。对于一些较基础或小众论文，我将简要掠过，以控制篇幅。每篇论文标题以中文 + 英文形式列出，焦点放在核心贡献和发现上。\n\n### AI 模型优化与安全\n- **Harnessing Neuron Stability to Improve DNN Verification（利用神经元稳定性提升 DNN 验证）**：这篇论文提出 VeriStable，一种基于 DPLL 的 DNN 验证扩展方法，通过检测稳定神经元减少组合复杂性，并在 MNIST 和 CIFAR 数据集上超越了状态-of-the-art 工具，如 α-β-CROWN 和 MN-BaB，提升了深度神经网络的安全验证效率。\n- **Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning（剪枝以保护：无需微调提升对齐 LLMs 的越狱抵抗力）**：作者 Adib Hasan 等开发了一种 WANDA 剪枝技术，使 LLMs 在保持基准性能的同时，提高了对越狱攻击的抵抗力，实验显示剪枝后模型在有害任务上更安全。\n- **Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model（基于可行性引导扩散模型的安全离线强化学习）**：论文引入 FISOR 框架，通过扩散模型优化离线强化学习的平衡策略，确保零违规约束，并在 DSRL 基准上表现出色，解决了安全性和效率的权衡问题。\n\n### 语言模型与多任务应用\n- **Language models align with human judgments on key grammatical constructions（语言模型在关键语法结构上与人类判断一致）**：Roger Levy 等研究发现，LLMs 如 GPT-4 在语法判断上高度匹配人类行为，实验通过重新评估数据证明了模型的细粒度变异能力，这对 NLP 任务的鲁棒性有重要启示。\n- **Episodic Reinforcement Learning with Expanded State-reward Space（扩展状态-奖励空间的 episodic 强化学习）**：该工作扩展了状态和奖励空间，改进了强化学习中的值估计，实验在 Box2d 和 Mujoco 任务上显著提升了性能，避免了 Q 值过估计问题。\n- **FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis（适用于金融分析的模型无关 LLMs 文本到 SQL 框架）**：论文提出 FinSQL 框架，通过提示构建和输出校准提升了金融任务的文本到 SQL 转换效率，在 Hundsun 数据集上实现了高达 36.64% 的性能改进，支持跨数据库迁移。\n- **Interactions with Prompt Problems: A New Way to Teach Programming with Large Language Models（使用 LLMs 的提示问题互动：LLMs 在编程教学中的新方法）**：作者 James Prather 等设计了 Prompt Problems 工具，让学生通过提示生成代码，实验显示这提升了编程学习效率，并已在 CHI 2024 接受。\n\n### 多模态理解与视觉任务\n- **Synthesizing Moving People with 3D Control（使用 3D 控制合成移动人物）**：Jitendra Malik 参与的这篇论文开发了一个扩散模型框架，通过填充模型和 3D 姿势控制生成逼真的动画序列，实验证明了其在复杂姿势下的鲁棒性，并公开了数据集。\n- **Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences（Mementos：多模态 LLMs 在图像序列推理的全面基准）**：作者 Huaxiu Yao 等提出 Mementos 数据集和基准，评估 LLMs 在序列图像上的推理能力，实验显示现有模型易出现幻觉，强调了行为一致性的挑战。\n- **PhotoBot: Reference-Guided Interactive Photography via Natural Language（PhotoBot：通过自然语言的参考引导交互式摄影）**：论文介绍 PhotoBot 框架，使用 VLM 和 LLM 结合视觉变换器实现机器人摄影，用户研究显示其生成的照片在美学上优于人类操作。\n\n其他论文如 WiFi 感知（RSCNet）、多语言仇恨检测（Analysis and Detection of Multilingual Hate Speech）和视频变换器概念发现（Understanding Video Transformers）等，虽然有技术创新，但影响力较小，我仅简要提及：RSCNet 通过 LSTM 优化 CSI 压缩，提升了 WiFi 感知准确率至 97.4%；多语言仇恨检测模型在 Bengali 和 English 数据集上达到 89-91% 准确率；视频变换器工作揭示了通用时空推理机制。\n\n总之，今天的 arXiv 论文突出了 AI 领域的动态进展，尤其在 LLMs 的扩展应用和模型鲁棒性上。感兴趣的读者可关注这些关键工作，以探索实际应用潜力。快报到此结束，欢迎下次阅读！",
  "papers": [
    {
      "arxiv_id": "2401.14412v1",
      "title": "Harnessing Neuron Stability to Improve DNN Verification",
      "title_zh": "利用神经元稳定性改善 DNN 验证",
      "authors": [
        "Hai Duong",
        "Dong Xu",
        "ThanhVu Nguyen",
        "Matthew B. Dwyer"
      ],
      "abstract": "Deep Neural Networks (DNN) have emerged as an effective approach to tackling\nreal-world problems. However, like human-written software, DNNs are susceptible\nto bugs and attacks. This has generated significant interests in developing\neffective and scalable DNN verification techniques and tools. In this paper, we\npresent VeriStable, a novel extension of recently proposed DPLL-based\nconstraint DNN verification approach. VeriStable leverages the insight that\nwhile neuron behavior may be non-linear across the entire DNN input space, at\nintermediate states computed during verification many neurons may be\nconstrained to have linear behavior - these neurons are stable. Efficiently\ndetecting stable neurons reduces combinatorial complexity without compromising\nthe precision of abstractions. Moreover, the structure of clauses arising in\nDNN verification problems shares important characteristics with industrial SAT\nbenchmarks. We adapt and incorporate multi-threading and restart optimizations\ntargeting those characteristics to further optimize DPLL-based DNN\nverification. We evaluate the effectiveness of VeriStable across a range of\nchallenging benchmarks including fully-connected feedforward networks (FNNs),\nconvolutional neural networks (CNNs) and residual networks (ResNets) applied to\nthe standard MNIST and CIFAR datasets. Preliminary results show that VeriStable\nis competitive and outperforms state-of-the-art DNN verification tools,\nincluding $\\alpha$-$\\beta$-CROWN and MN-BaB, the first and second performers of\nthe VNN-COMP, respectively.",
      "tldr_zh": "本论文提出 VeriStable，一种扩展 DPLL-based DNN 验证的方法，通过利用 neuron stability 检测中间状态下线性行为的神经元，从而减少组合复杂性并保持抽象精度。该框架还整合多线程和重启优化，以适应 DNN 验证问题的特性，如工业 SAT 基准。实验结果显示，VeriStable 在 MNIST 和 CIFAR 数据集上的 FNNs、CNNs 和 ResNets 等网络中，性能优于现有顶尖工具 α-β-CROWN 和 MN-BaB，提升了验证效率和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "VeriStable and experimental data are available at:\n  https://github.com/veristable/veristable",
      "pdf_url": "http://arxiv.org/pdf/2401.14412v1",
      "published_date": "2024-01-19 23:48:04 UTC",
      "updated_date": "2024-01-19 23:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:47:56.401683"
    },
    {
      "arxiv_id": "2401.11061v4",
      "title": "PhotoBot: Reference-Guided Interactive Photography via Natural Language",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Limoyo",
        "Jimmy Li",
        "Dmitriy Rivkin",
        "Jonathan Kelly",
        "Gregory Dudek"
      ],
      "abstract": "We introduce PhotoBot, a framework for fully automated photo acquisition\nbased on an interplay between high-level human language guidance and a robot\nphotographer. We propose to communicate photography suggestions to the user via\nreference images that are selected from a curated gallery. We leverage a visual\nlanguage model (VLM) and an object detector to characterize the reference\nimages via textual descriptions and then use a large language model (LLM) to\nretrieve relevant reference images based on a user's language query through\ntext-based reasoning. To correspond the reference image and the observed scene,\nwe exploit pre-trained features from a vision transformer capable of capturing\nsemantic similarity across marked appearance variations. Using these features,\nwe compute suggested pose adjustments for an RGB-D camera by solving a\nperspective-n-point (PnP) problem. We demonstrate our approach using a\nmanipulator equipped with a wrist camera. Our user studies show that photos\ntaken by PhotoBot are often more aesthetically pleasing than those taken by\nusers themselves, as measured by human feedback. We also show that PhotoBot can\ngeneralize to other reference sources such as paintings.",
      "tldr_zh": "该论文提出 PhotoBot，一个基于自然语言指导的交互式摄影框架，允许用户通过高层次语言查询来实现自动化照片获取。PhotoBot 利用视觉语言模型 (VLM) 和物体检测器对参考图像进行文本描述，然后借助大型语言模型 (LLM) 通过文本推理从精选图库中检索相关图像，并使用 Vision Transformer 的预训练特征计算语义相似性，以解决透视-n-点 (PnP) 问题调整 RGB-D 相机姿态。实验在配备腕部相机的机械臂上进行，用户研究显示 PhotoBot 拍摄的照片在美学上更受欢迎，且能推广到其他参考来源如绘画，从而提升摄影交互的效率和质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "In Proceedings of the IEEE/RSJ International Conference on\n  Intelligent Robotics and Systems (IROS'24), Abu Dhabi, UAE, Oct. 14-18, 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11061v4",
      "published_date": "2024-01-19 23:34:48 UTC",
      "updated_date": "2024-12-26 03:38:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:48:09.780009"
    },
    {
      "arxiv_id": "2401.11044v2",
      "title": "Preservation of Feature Stability in Machine Learning Under Data Uncertainty for Decision Support in Critical Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Karol Capała",
        "Paulina Tworek",
        "Jose Sousa"
      ],
      "abstract": "In a world where Machine Learning (ML) is increasingly deployed to support\ndecision-making in critical domains, providing decision-makers with\nexplainable, stable, and relevant inputs becomes fundamental. Understanding how\nmachine learning works under missing data and how this affects feature\nvariability is paramount. This is even more relevant as machine learning\napproaches focus on standardising decision-making approaches that rely on an\nidealised set of features. However, decision-making in human activities often\nrelies on incomplete data, even in critical domains. This paper addresses this\ngap by conducting a set of experiments using traditional machine learning\nmethods that look for optimal decisions in comparison to a recently deployed\nmachine learning method focused on a classification that is more descriptive\nand mimics human decision making, allowing for the natural integration of\nexplainability. We found that the ML descriptive approach maintains higher\nclassification accuracy while ensuring the stability of feature selection as\ndata incompleteness increases. This suggests that descriptive classification\nmethods can be helpful in uncertain decision-making scenarios.",
      "tldr_zh": "本研究探讨了机器学习（ML）在关键领域决策支持中的特征稳定性问题，特别是在数据不确定性（如缺失数据）下的表现。研究通过实验比较了传统ML方法与一种新的描述性分类方法，后者更模仿人类决策并增强了可解释性。结果显示，随着数据不完整性的增加，描述性分类方法维持了更高的分类准确率，同时确保了特征选择的稳定性。这表明，描述性ML方法在不确定决策场景中更具优势，为关键领域的可靠决策支持提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 6 figures, supplementary materials",
      "pdf_url": "http://arxiv.org/pdf/2401.11044v2",
      "published_date": "2024-01-19 22:11:54 UTC",
      "updated_date": "2024-08-06 11:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:48:18.582970"
    },
    {
      "arxiv_id": "2402.04885v1",
      "title": "A Unified Gaussian Process for Branching and Nested Hyperparameter Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jiazhao Zhang",
        "Ying Hung",
        "Chung-Ching Lin",
        "Zicheng Liu"
      ],
      "abstract": "Choosing appropriate hyperparameters plays a crucial role in the success of\nneural networks as hyper-parameters directly control the behavior and\nperformance of the training algorithms. To obtain efficient tuning, Bayesian\noptimization methods based on Gaussian process (GP) models are widely used.\nDespite numerous applications of Bayesian optimization in deep learning, the\nexisting methodologies are developed based on a convenient but restrictive\nassumption that the tuning parameters are independent of each other. However,\ntuning parameters with conditional dependence are common in practice. In this\npaper, we focus on two types of them: branching and nested parameters. Nested\nparameters refer to those tuning parameters that exist only within a particular\nsetting of another tuning parameter, and a parameter within which other\nparameters are nested is called a branching parameter. To capture the\nconditional dependence between branching and nested parameters, a unified\nBayesian optimization framework is proposed. The sufficient conditions are\nrigorously derived to guarantee the validity of the kernel function, and the\nasymptotic convergence of the proposed optimization framework is proven under\nthe continuum-armed-bandit setting. Based on the new GP model, which accounts\nfor the dependent structure among input variables through a new kernel\nfunction, higher prediction accuracy and better optimization efficiency are\nobserved in a series of synthetic simulations and real data applications of\nneural networks. Sensitivity analysis is also performed to provide insights\ninto how changes in hyperparameter values affect prediction accuracy.",
      "tldr_zh": "该论文针对超参数优化中的分支（branching）和嵌套（nested）参数依赖问题，提出一个统一的Gaussian Process (GP)框架，以克服现有Bayesian Optimization方法对参数独立性的限制。框架通过设计新的核函数（kernel function）捕捉参数间的条件依赖，并严格证明了其有效性和渐近收敛性（asymptotic convergence）。实验结果显示，该方法在合成模拟和神经网络实际应用中实现了更高的预测准确性和优化效率，并通过敏感性分析（sensitivity analysis）揭示了超参数变化对性能的影响。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04885v1",
      "published_date": "2024-01-19 21:11:32 UTC",
      "updated_date": "2024-01-19 21:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:48:30.996048"
    },
    {
      "arxiv_id": "2401.11021v1",
      "title": "Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning",
      "title_zh": "基于Transformer的深度学习的多语言仇恨言论分析和检测",
      "authors": [
        "Arijit Das",
        "Somashree Nandy",
        "Rupam Saha",
        "Srijan Das",
        "Diganta Saha"
      ],
      "abstract": "Hate speech is harmful content that directly attacks or promotes hatred\nagainst members of groups or individuals based on actual or perceived aspects\nof identity, such as racism, religion, or sexual orientation. This can affect\nsocial life on social media platforms as hateful content shared through social\nmedia can harm both individuals and communities. As the prevalence of hate\nspeech increases online, the demand for automated detection as an NLP task is\nincreasing. In this work, the proposed method is using transformer-based model\nto detect hate speech in social media, like twitter, Facebook, WhatsApp,\nInstagram, etc. The proposed model is independent of languages and has been\ntested on Italian, English, German, Bengali. The Gold standard datasets were\ncollected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel,\nand Rezaul Karim. The success rate of the proposed model for hate speech\ndetection is higher than the existing baseline and state-of-the-art models with\naccuracy in Bengali dataset is 89%, in English: 91%, in German dataset 91% and\nin Italian dataset it is 77%. The proposed algorithm shows substantial\nimprovement to the benchmark method.",
      "tldr_zh": "这篇论文分析了仇恨言论（Hate speech）的危害，包括针对群体或个人的攻击，可能基于种族、宗教或性取向等身份特征，并讨论了其在社交媒体上的社会影响。研究提出了一种基于 Transformer 的深度学习模型，用于检测多语言仇恨言论，该模型独立于语言，并在意大利语、英语、德语和孟加拉语数据集上进行了测试。实验结果显示，该模型的准确率分别为意大利语 77%、英语 91%、德语 91% 和孟加拉语 89%，整体性能优于现有基线和最先进模型，从而为多语言仇恨言论检测提供了显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.11021v1",
      "published_date": "2024-01-19 20:40:23 UTC",
      "updated_date": "2024-01-19 20:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:48:43.494242"
    },
    {
      "arxiv_id": "2402.04888v2",
      "title": "RSCNet: Dynamic CSI Compression for Cloud-based WiFi Sensing",
      "title_zh": "RSCNet：动态 CSI 压缩用于基于云的 WiFi 感知",
      "authors": [
        "Borna Barahimi",
        "Hakam Singh",
        "Hina Tabassum",
        "Omer Waqar",
        "Mohammad Omer"
      ],
      "abstract": "WiFi-enabled Internet-of-Things (IoT) devices are evolving from mere\ncommunication devices to sensing instruments, leveraging Channel State\nInformation (CSI) extraction capabilities. Nevertheless, resource-constrained\nIoT devices and the intricacies of deep neural networks necessitate\ntransmitting CSI to cloud servers for sensing. Although feasible, this leads to\nconsiderable communication overhead. In this context, this paper develops a\nnovel Real-time Sensing and Compression Network (RSCNet) which enables sensing\nwith compressed CSI; thereby reducing the communication overheads. RSCNet\nfacilitates optimization across CSI windows composed of a few CSI frames. Once\ntransmitted to cloud servers, it employs Long Short-Term Memory (LSTM) units to\nharness data from prior windows, thus bolstering both the sensing accuracy and\nCSI reconstruction. RSCNet adeptly balances the trade-off between CSI\ncompression and sensing precision, thus streamlining real-time cloud-based WiFi\nsensing with reduced communication costs. Numerical findings demonstrate the\ngains of RSCNet over the existing benchmarks like SenseFi, showcasing a sensing\naccuracy of 97.4% with minimal CSI reconstruction error. Numerical results also\nshow a computational analysis of the proposed RSCNet as a function of the\nnumber of CSI frames.",
      "tldr_zh": "该研究针对资源受限的 WiFi IoT 设备在云-based 传感中传输 Channel State Information (CSI) 导致的通信开销问题，提出了一种新型 Real-time Sensing and Compression Network (RSCNet)。RSCNet 通过对 CSI 窗口进行优化并结合 Long Short-Term Memory (LSTM) 单位，利用先前窗口的数据来提升传感准确性和 CSI 重建精度，从而平衡压缩效率与性能 trade-off。实验结果显示，RSCNet 相较于基准如 SenseFi，实现了 97.4% 的传感准确率和最小重建错误，并提供了与 CSI 帧数量相关的计算分析。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "The paper has been accepted by IEEE International Conference on\n  Communications (ICC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04888v2",
      "published_date": "2024-01-19 20:30:23 UTC",
      "updated_date": "2024-05-20 15:48:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:48:56.036840"
    },
    {
      "arxiv_id": "2401.11002v2",
      "title": "Fast Registration of Photorealistic Avatars for VR Facial Animation",
      "title_zh": "翻译失败",
      "authors": [
        "Chaitanya Patel",
        "Shaojie Bai",
        "Te-Li Wang",
        "Jason Saragih",
        "Shih-En Wei"
      ],
      "abstract": "Virtual Reality (VR) bares promise of social interactions that can feel more\nimmersive than other media. Key to this is the ability to accurately animate a\npersonalized photorealistic avatar, and hence the acquisition of the labels for\nheadset-mounted camera (HMC) images need to be efficient and accurate, while\nwearing a VR headset. This is challenging due to oblique camera views and\ndifferences in image modality. In this work, we first show that the domain gap\nbetween the avatar and HMC images is one of the primary sources of difficulty,\nwhere a transformer-based architecture achieves high accuracy on\ndomain-consistent data, but degrades when the domain-gap is re-introduced.\nBuilding on this finding, we propose a system split into two parts: an\niterative refinement module that takes in-domain inputs, and a generic\navatar-guided image-to-image domain transfer module conditioned on current\nestimates. These two modules reinforce each other: domain transfer becomes\neasier when close-to-groundtruth examples are shown, and better domain-gap\nremoval in turn improves the registration. Our system obviates the need for\ncostly offline optimization, and produces online registration of higher quality\nthan direct regression method. We validate the accuracy and efficiency of our\napproach through extensive experiments on a commodity headset, demonstrating\nsignificant improvements over these baselines. To stimulate further research in\nthis direction, we make our large-scale dataset and code publicly available.",
      "tldr_zh": "这篇论文针对 Virtual Reality (VR) 中个性化逼真头像的快速注册问题，解决了头戴式相机 (HMC) 图像的倾斜视角和领域差距带来的挑战。作者提出一个双模块系统，包括一个迭代精炼模块（处理领域内输入）和一个基于当前估计的通用头像引导图像到图像领域转移模块，这两个模块相互强化，提高了注册准确性和效率。实验结果显示，该系统比直接回归方法在商品化头戴设备上实现了更高的在线注册质量，并通过大规模数据集验证了其优势；同时，作者公开了数据集和代码以推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024. Project page:\n  https://chaitanya100100.github.io/FastRegistration/",
      "pdf_url": "http://arxiv.org/pdf/2401.11002v2",
      "published_date": "2024-01-19 19:42:38 UTC",
      "updated_date": "2024-07-18 22:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:49:08.271754"
    },
    {
      "arxiv_id": "2402.01676v2",
      "title": "Language models align with human judgments on key grammatical constructions",
      "title_zh": "语言模型在关键语法结构上与人类判断一致",
      "authors": [
        "Jennifer Hu",
        "Kyle Mahowald",
        "Gary Lupyan",
        "Anna Ivanova",
        "Roger Levy"
      ],
      "abstract": "Do large language models (LLMs) make human-like linguistic generalizations?\nDentella et al. (2023) (\"DGL\") prompt several LLMs (\"Is the following sentence\ngrammatically correct in English?\") to elicit grammaticality judgments of 80\nEnglish sentences, concluding that LLMs demonstrate a \"yes-response bias\" and a\n\"failure to distinguish grammatical from ungrammatical sentences\". We\nre-evaluate LLM performance using well-established practices and find that\nDGL's data in fact provide evidence for just how well LLMs capture human\nbehaviors. Models not only achieve high accuracy overall, but also capture\nfine-grained variation in human linguistic judgments.",
      "tldr_zh": "这篇论文重新评估了大型语言模型 (LLMs) 在关键语法结构上的表现，挑战了 Dentella et al. (2023) 的研究结论，即 LLMs 存在“yes-response bias”和无法区分语法正确与错误的缺陷。作者使用 DGL 的数据并采用更可靠的评估实践，发现 LLMs 不仅在整体语法判断中实现了高准确率，还捕捉了人类语言判断的细粒度变化。最终，这为 LLMs 模拟人类语言泛化提供了强有力的证据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in PNAS at https://www.pnas.org/doi/10.1073/pnas.2400917121\n  as response to Dentella et al. (2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.01676v2",
      "published_date": "2024-01-19 19:36:54 UTC",
      "updated_date": "2024-08-30 14:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:49:19.060722"
    },
    {
      "arxiv_id": "2401.10889v2",
      "title": "Synthesizing Moving People with 3D Control",
      "title_zh": "翻译失败",
      "authors": [
        "Boyi Li",
        "Junming Chen",
        "Jathushan Rajasegaran",
        "Yossi Gandelsman",
        "Alexei A. Efros",
        "Jitendra Malik"
      ],
      "abstract": "In this paper, we present a diffusion model-based framework for animating\npeople from a single image for a given target 3D motion sequence. Our approach\nhas two core components: a) learning priors about invisible parts of the human\nbody and clothing, and b) rendering novel body poses with proper clothing and\ntexture. For the first part, we learn an in-filling diffusion model to\nhallucinate unseen parts of a person given a single image. We train this model\non texture map space, which makes it more sample-efficient since it is\ninvariant to pose and viewpoint. Second, we develop a diffusion-based rendering\npipeline, which is controlled by 3D human poses. This produces realistic\nrenderings of novel poses of the person, including clothing, hair, and\nplausible in-filling of unseen regions. This disentangled approach allows our\nmethod to generate a sequence of images that are faithful to the target motion\nin the 3D pose and, to the input image in terms of visual similarity. In\naddition to that, the 3D control allows various synthetic camera trajectories\nto render a person. Our experiments show that our method is resilient in\ngenerating prolonged motions and varied challenging and complex poses compared\nto prior methods. Please check our website for more details:\nhttps://boyiliee.github.io/3DHM.github.io/.",
      "tldr_zh": "本研究提出了一种基于扩散模型（diffusion model）的框架，用于从单张图像生成给定目标 3D 动作序列的人体动画。该框架的核心组件包括：a) 一个补全扩散模型（in-filling diffusion model），在纹理映射空间（texture map space）训练，以高效学习和幻想人体不可见部分；b) 一个受 3D 人体姿势控制的渲染管道，能够生成真实的新姿势渲染，包括衣服、头发和未见区域的合理填充。这种解耦方法确保生成的图像序列忠实于目标 3D 姿势和输入图像的视觉相似性，同时支持各种合成相机轨迹。实验结果表明，该方法在处理长时间动作和复杂姿势时，比现有方法更具韧性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10889v2",
      "published_date": "2024-01-19 18:59:11 UTC",
      "updated_date": "2024-12-20 18:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:49:32.119452"
    },
    {
      "arxiv_id": "2401.10886v1",
      "title": "SCENES: Subpixel Correspondence Estimation With Epipolar Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik A. Kloepfer",
        "João F. Henriques",
        "Dylan Campbell"
      ],
      "abstract": "Extracting point correspondences from two or more views of a scene is a\nfundamental computer vision problem with particular importance for relative\ncamera pose estimation and structure-from-motion. Existing local feature\nmatching approaches, trained with correspondence supervision on large-scale\ndatasets, obtain highly-accurate matches on the test sets. However, they do not\ngeneralise well to new datasets with different characteristics to those they\nwere trained on, unlike classic feature extractors. Instead, they require\nfinetuning, which assumes that ground-truth correspondences or ground-truth\ncamera poses and 3D structure are available. We relax this assumption by\nremoving the requirement of 3D structure, e.g., depth maps or point clouds, and\nonly require camera pose information, which can be obtained from odometry. We\ndo so by replacing correspondence losses with epipolar losses, which encourage\nputative matches to lie on the associated epipolar line. While weaker than\ncorrespondence supervision, we observe that this cue is sufficient for\nfinetuning existing models on new data. We then further relax the assumption of\nknown camera poses by using pose estimates in a novel bootstrapping approach.\nWe evaluate on highly challenging datasets, including an indoor drone dataset\nand an outdoor smartphone camera dataset, and obtain state-of-the-art results\nwithout strong supervision.",
      "tldr_zh": "这篇论文提出了 SCENES，一种基于极线监督（Epipolar Supervision）的子像素对应关系估计方法，旨在解决现有特征匹配算法在不同数据集上泛化性差的问题。传统方法依赖地面实测对应关系或3D结构，而 SCENES 仅需相机位姿信息（如从里程计获取），通过极线损失（Epipolar Losses）鼓励匹配点位于相关极线上，并引入一个新颖的引导方法（Bootstrapping Approach）来处理未知位姿。实验在室内无人机和室外智能手机数据集上取得了最先进的结果，而无需强监督，从而提升了相对相机位姿估计和结构从运动（Structure-from-Motion）的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10886v1",
      "published_date": "2024-01-19 18:57:46 UTC",
      "updated_date": "2024-01-19 18:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:49:44.559850"
    },
    {
      "arxiv_id": "2401.10882v1",
      "title": "Reinforcement learning for question answering in programming domain using public community scoring as a human feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Alexey Gorbatovski",
        "Sergey Kovalchuk"
      ],
      "abstract": "In this study, we investigate the enhancement of the GPT Neo 125M performance\nin Community Question Answering (CQA) with a focus on programming, through the\nintegration of Reinforcement Learning from Human Feedback (RLHF) and the\nutilization of scores from Stack Overflow. Two distinct reward model training\nstrategies are employed for fine-tuning with Proximal Policy Optimization\n(PPO). Notably, the improvements in performance achieved through this method\nare comparable to those of GPT Neo 2.7B parameter variant. Additionally, an\nauxiliary scoring mechanism is introduced, which demonstrates the limitations\nof conventional linguistic metrics in evaluating responses in the programming\ndomain. Through accurate analysis, this paper looks at the divergence between\ntraditional linguistic metrics and our human-preferences-based reward model,\nunderscoring the imperative for domain-specific evaluation methods. By\nelucidating the complexities involved in applying RLHF to programming CQA and\naccentuating the significance of context-aware evaluation, this study\ncontributes to the ongoing efforts in refining Large Language Models through\nfocused human feedback.",
      "tldr_zh": "本研究探讨了使用强化学习从人类反馈（RLHF）来提升 GPT Neo 125M 在编程社区问答（CQA）中的性能，具体通过 Stack Overflow 的公共社区评分作为反馈机制。研究采用两种奖励模型训练策略与 Proximal Policy Optimization (PPO) 相结合进行微调，结果显示这种方法使模型的性能提升与 GPT Neo 2.7B 参数变体相当。论文还引入了一个辅助评分机制，揭示了传统语言指标在编程领域的局限性，并强调了基于人类偏好的奖励模型与上下文感知评估的重要性，从而为针对性人类反馈改进大型语言模型提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10882v1",
      "published_date": "2024-01-19 18:49:36 UTC",
      "updated_date": "2024-01-19 18:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:49:57.028655"
    },
    {
      "arxiv_id": "2401.10862v3",
      "title": "Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Adib Hasan",
        "Ileana Rugina",
        "Alex Wang"
      ],
      "abstract": "This paper investigates the impact of model compression on the way Large\nLanguage Models (LLMs) process prompts, particularly concerning jailbreak\nresistance. We show that moderate WANDA pruning can enhance resistance to\njailbreaking attacks without fine-tuning, while maintaining performance on\nstandard benchmarks. To systematically evaluate this safety enhancement, we\nintroduce a dataset of 225 harmful tasks across five categories. Our analysis\nof LLaMA-2 Chat, Vicuna 1.3, and Mistral Instruct v0.2 reveals that pruning\nbenefits correlate with initial model safety levels. We interpret these results\nby examining changes in attention patterns and perplexity shifts, demonstrating\nthat pruned models exhibit sharper attention and increased sensitivity to\nartificial jailbreak constructs. We extend our evaluation to the AdvBench\nharmful behavior tasks and the GCG attack method. We find that LLaMA-2 is much\nsafer on AdvBench prompts than on our dataset when evaluated with manual\njailbreak attempts, and that pruning is effective against both automated\nattacks and manual jailbreaking on Advbench.",
      "tldr_zh": "本研究探讨了通过模型压缩技术（特别是 moderate WANDA pruning）来提升对齐大型语言模型（LLMs）的抗越狱攻击（jailbreak resistance）能力，而无需进行 fine-tuning，同时保持标准基准上的性能表现。研究者引入了一个包含225个有害任务的数据集，并分析了LLaMA-2 Chat、Vicuna 1.3和Mistral Instruct v0.2等模型，结果显示pruning的效果与模型的初始安全水平相关，pruned模型表现出更锐利的注意力模式和对人工越狱构造的更高敏感性。在扩展评估中，该方法对AdvBench任务和GCG攻击均有效，证明了其在增强LLMs安全性的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 7th BlackboxNLP Workshop: Analyzing and\n  Interpreting Neural Networks for NLP",
      "pdf_url": "http://arxiv.org/pdf/2401.10862v3",
      "published_date": "2024-01-19 18:05:34 UTC",
      "updated_date": "2024-10-31 04:16:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:50:09.840093"
    },
    {
      "arxiv_id": "2401.10850v1",
      "title": "Advancements in eHealth Data Analytics through Natural Language Processing and Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Elena-Simona Apostol",
        "Ciprian-Octavian Truică"
      ],
      "abstract": "The healthcare environment is commonly referred to as \"information-rich\" but\nalso \"knowledge poor\". Healthcare systems collect huge amounts of data from\nvarious sources: lab reports, medical letters, logs of medical tools or\nprograms, medical prescriptions, etc. These massive sets of data can provide\ngreat knowledge and information that can improve the medical services, and\noverall the healthcare domain, such as disease prediction by analyzing the\npatient's symptoms or disease prevention, by facilitating the discovery of\nbehavioral factors for diseases. Unfortunately, only a relatively small volume\nof the textual eHealth data is processed and interpreted, an important factor\nbeing the difficulty in efficiently performing Big Data operations. In the\nmedical field, detecting domain-specific multi-word terms is a crucial task as\nthey can define an entire concept with a few words. A term can be defined as a\nlinguistic structure or a concept, and it is composed of one or more words with\na specific meaning to a domain. All the terms of a domain create its\nterminology. This chapter offers a critical study of the current, most\nperformant solutions for analyzing unstructured (image and textual) eHealth\ndata. This study also provides a comparison of the current Natural Language\nProcessing and Deep Learning techniques in the eHealth context. Finally, we\nexamine and discuss some of the current issues, and we define a set of research\ndirections in this area.",
      "tldr_zh": "该论文探讨了电子健康（eHealth）领域数据丰富的现状，却因大数据处理困难而知识不足的问题，强调通过分析实验室报告、医疗信函等非结构化数据，可以提升疾病预测和预防等医疗服务。研究对当前Natural Language Processing (NLP) 和Deep Learning 技术进行了批判性比较，评估它们在检测领域特定多词术语（如医疗概念）方面的表现，以改善eHealth数据分析。最终，论文指出了现有挑战并提出了未来研究方向，为推进医疗数据利用提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10850v1",
      "published_date": "2024-01-19 17:51:11 UTC",
      "updated_date": "2024-01-19 17:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:50:20.988748"
    },
    {
      "arxiv_id": "2401.10848v1",
      "title": "Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Prakhar Kaushik",
        "Aayush Mishra",
        "Adam Kortylewski",
        "Alan Yuille"
      ],
      "abstract": "We consider the problem of source-free unsupervised category-level pose\nestimation from only RGB images to a target domain without any access to source\ndomain data or 3D annotations during adaptation. Collecting and annotating\nreal-world 3D data and corresponding images is laborious, expensive, yet\nunavoidable process, since even 3D pose domain adaptation methods require 3D\ndata in the target domain. We introduce 3DUDA, a method capable of adapting to\na nuisance-ridden target domain without 3D or depth data. Our key insight stems\nfrom the observation that specific object subparts remain stable across\nout-of-domain (OOD) scenarios, enabling strategic utilization of these\ninvariant subcomponents for effective model updates. We represent object\ncategories as simple cuboid meshes, and harness a generative model of neural\nfeature activations modeled at each mesh vertex learnt using differential\nrendering. We focus on individual locally robust mesh vertex features and\niteratively update them based on their proximity to corresponding features in\nthe target domain even when the global pose is not correct. Our model is then\ntrained in an EM fashion, alternating between updating the vertex features and\nthe feature extractor. We show that our method simulates fine-tuning on a\nglobal pseudo-labeled dataset under mild assumptions, which converges to the\ntarget domain asymptotically. Through extensive empirical validation, including\na complex extreme UDA setup which combines real nuisances, synthetic noise, and\nocclusion, we demonstrate the potency of our simple approach in addressing the\ndomain shift challenge and significantly improving pose estimation accuracy.",
      "tldr_zh": "这篇论文解决了无源且仅图像(Image-Only)的无监督域适应(Unsupervised Domain Adaptation)问题，用于类别级对象姿态估计(Object Pose Estimation)，无需访问源域数据或3D标注。论文提出3DUDA方法，利用对象子部分的跨域稳定性，通过简单立方体网格表示对象类别，并基于差分渲染学习神经特征激活，然后采用EM算法交替更新局部网格顶点特征和特征提取器。实验结果表明，该方法在包含真实干扰、合成噪声和遮挡的极端UDA设置中显著提高了姿态估计准确性，并在温和假设下渐进收敛到目标域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "36 pages, 9 figures, 50 tables; ICLR 2024 (Poster)",
      "pdf_url": "http://arxiv.org/pdf/2401.10848v1",
      "published_date": "2024-01-19 17:48:05 UTC",
      "updated_date": "2024-01-19 17:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:50:34.297820"
    },
    {
      "arxiv_id": "2401.10841v2",
      "title": "Using LLMs to discover emerging coded antisemitic hate-speech in extremist social media",
      "title_zh": "翻译失败",
      "authors": [
        "Dhanush Kikkisetti",
        "Raza Ul Mustafa",
        "Wendy Melillo",
        "Roberto Corizzo",
        "Zois Boukouvalas",
        "Jeff Gill",
        "Nathalie Japkowicz"
      ],
      "abstract": "Online hate speech proliferation has created a difficult problem for social\nmedia platforms. A particular challenge relates to the use of coded language by\ngroups interested in both creating a sense of belonging for its users and\nevading detection. Coded language evolves quickly and its use varies over time.\nThis paper proposes a methodology for detecting emerging coded hate-laden\nterminology. The methodology is tested in the context of online antisemitic\ndiscourse. The approach considers posts scraped from social media platforms,\noften used by extremist users. The posts are scraped using seed expressions\nrelated to previously known discourse of hatred towards Jews. The method begins\nby identifying the expressions most representative of each post and calculating\ntheir frequency in the whole corpus. It filters out grammatically incoherent\nexpressions as well as previously encountered ones so as to focus on emergent\nwell-formed terminology. This is followed by an assessment of semantic\nsimilarity to known antisemitic terminology using a fine-tuned large language\nmodel, and subsequent filtering out of the expressions that are too distant\nfrom known expressions of hatred. Emergent antisemitic expressions containing\nterms clearly relating to Jewish topics are then removed to return only coded\nexpressions of hatred.",
      "tldr_zh": "这篇论文提出了一种利用大型语言模型(LLMs)检测极端主义社交媒体上新兴编码反犹仇恨言论的方法，以应对仇恨语言的快速演变和逃避检测问题。方法包括从社交媒体抓取帖子、使用种子表达式识别代表性表达、计算频率，并通过语义相似性评估过滤出语法连贯且与已知仇恨术语相关的全新编码表达。最终，该方法成功聚焦于编码的仇恨语言，提高了在线仇恨监测的针对性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures, 2 algorithms, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.10841v2",
      "published_date": "2024-01-19 17:40:50 UTC",
      "updated_date": "2024-01-23 20:05:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:50:46.168972"
    },
    {
      "arxiv_id": "2401.10831v3",
      "title": "Understanding Video Transformers via Universal Concept Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Kowal",
        "Achal Dave",
        "Rares Ambrus",
        "Adrien Gaidon",
        "Konstantinos G. Derpanis",
        "Pavel Tokmakov"
      ],
      "abstract": "This paper studies the problem of concept-based interpretability of\ntransformer representations for videos. Concretely, we seek to explain the\ndecision-making process of video transformers based on high-level,\nspatiotemporal concepts that are automatically discovered. Prior research on\nconcept-based interpretability has concentrated solely on image-level tasks.\nComparatively, video models deal with the added temporal dimension, increasing\ncomplexity and posing challenges in identifying dynamic concepts over time. In\nthis work, we systematically address these challenges by introducing the first\nVideo Transformer Concept Discovery (VTCD) algorithm. To this end, we propose\nan efficient approach for unsupervised identification of units of video\ntransformer representations - concepts, and ranking their importance to the\noutput of a model. The resulting concepts are highly interpretable, revealing\nspatio-temporal reasoning mechanisms and object-centric representations in\nunstructured video models. Performing this analysis jointly over a diverse set\nof supervised and self-supervised representations, we discover that some of\nthese mechanism are universal in video transformers. Finally, we show that VTCD\ncan be used for fine-grained action recognition and video object segmentation.",
      "tldr_zh": "本研究探讨了视频Transformer表示的概念-based可解释性，通过自动发现的高级时空spatiotemporal concepts来解释模型的决策过程。作者引入了首个Video Transformer Concept Discovery (VTCD)算法，该算法采用高效的无监督方法识别视频Transformer中的概念，并评估其对模型输出的重要性。实验结果显示，这些概念高度可解释，揭示了视频模型中的时空推理机制和对象中心object-centric representations，且某些机制在多种监督和自监督视频Transformers中是通用的。最后，VTCD可应用于细粒度动作识别fine-grained action recognition和视频对象分割video object segmentation。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 (Highlight)",
      "pdf_url": "http://arxiv.org/pdf/2401.10831v3",
      "published_date": "2024-01-19 17:27:21 UTC",
      "updated_date": "2024-04-10 15:19:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:50:57.440652"
    },
    {
      "arxiv_id": "2401.10819v1",
      "title": "Optimisation in Neurosymbolic Learning Systems",
      "title_zh": "神经符号学习系统的优化",
      "authors": [
        "Emile van Krieken"
      ],
      "abstract": "Neurosymbolic AI aims to integrate deep learning with symbolic AI. This\nintegration has many promises, such as decreasing the amount of data required\nto train a neural network, improving the explainability and interpretability of\nanswers given by models and verifying the correctness of trained systems. We\nstudy neurosymbolic learning, where we have both data and background knowledge\nexpressed using symbolic languages. How do we connect the symbolic and neural\ncomponents to communicate this knowledge? One option is fuzzy reasoning, which\nstudies degrees of truth. For example, being tall is not a binary concept.\nInstead, probabilistic reasoning studies the probability that something is true\nor will happen. Our first research question studies how different forms of\nfuzzy reasoning combine with learning. We find surprising results like a\nconnection to the Raven paradox stating we confirm \"ravens are black\" when we\nobserve a green apple. In this study, we did not use the background knowledge\nwhen we deployed our models after training. In our second research question, we\nstudied how to use background knowledge in deployed models. We developed a new\nneural network layer based on fuzzy reasoning. Probabilistic reasoning is a\nnatural fit for neural networks, which we usually train to be probabilistic.\nHowever, they are expensive to compute and do not scale well to large tasks. In\nour third research question, we study how to connect probabilistic reasoning\nwith neural networks by sampling to estimate averages, while in the final\nresearch question, we study scaling probabilistic neurosymbolic learning to\nmuch larger problems than before. Our insight is to train a neural network with\nsynthetic data to predict the result of probabilistic reasoning.",
      "tldr_zh": "这篇论文探讨了神经符号学习系统中的优化问题，旨在整合深度学习与符号 AI，以减少训练数据需求、提升模型解释性和验证正确性。研究首先考察了模糊推理(fuzzy reasoning)与学习的结合，发现了如乌鸦悖论(Raven paradox)般的意外结果，并开发了一种基于模糊推理的新神经网络层来在部署模型中使用背景知识。其次，论文通过采样估计平均值将概率推理(probabilistic reasoning)与神经网络连接，并利用合成数据训练神经网络，成功扩展了概率神经符号学习至更大规模任务。总的来说，这些贡献为高效、可解释的神经符号系统提供了新方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD dissertation",
      "pdf_url": "http://arxiv.org/pdf/2401.10819v1",
      "published_date": "2024-01-19 17:09:32 UTC",
      "updated_date": "2024-01-19 17:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:51:11.396190"
    },
    {
      "arxiv_id": "2401.10816v2",
      "title": "Co-Pilot for Health: Personalized Algorithmic AI Nudging to Improve Health Outcomes",
      "title_zh": "翻译失败",
      "authors": [
        "Jodi Chiam",
        "Aloysius Lim",
        "Cheryl Nott",
        "Nicholas Mark",
        "Ankur Teredesai",
        "Sunil Shinde"
      ],
      "abstract": "The ability to shape health behaviors of large populations automatically,\nacross wearable types and disease conditions at scale has tremendous potential\nto improve global health outcomes. We designed and implemented an AI driven\nplatform for digital algorithmic nudging, enabled by a Graph-Neural Network\n(GNN) based Recommendation System, and granular health behavior data from\nwearable fitness devices. Here we describe the efficacy results of this\nplatform with its capabilities of personalized and contextual nudging to\n$n=84,764$ individuals over a 12-week period in Singapore. We statistically\nvalidated that participants in the target group who received such AI optimized\ndaily nudges increased daily physical activity like step count by 6.17% ($p =\n3.09\\times10^{-4}$) and weekly minutes of Moderate to Vigorous Physical\nActivity (MVPA) by 7.61% ($p = 1.16\\times10^{-2}$), compared to matched\nparticipants in control group who did not receive any nudges. Further, such\nnudges were very well received, with a 13.1% of nudges sent being opened (open\nrate), and 11.7% of the opened nudges rated useful compared to 1.9% rated as\nnot useful thereby demonstrating significant improvement in population level\nengagement metrics.",
      "tldr_zh": "该研究开发了一个名为“Co-Pilot for Health”的AI平台，使用Graph-Neural Network (GNN)推荐系统和可穿戴设备数据，提供个性化和上下文化的算法推动（AI nudging），以改善全球健康行为。平台针对84,764名新加坡参与者进行了12周的实验，结果显示接收AI优化每日推动的目标组，日常步数增加了6.17%（p = 3.09×10^{-4}），每周Moderate to Vigorous Physical Activity (MVPA)增加了7.61%（p = 1.16×10^{-2}），相比未接收推动的对照组有显著提升。推动的参与度也很高，打开率为13.1%，其中11.7%的推动被评为有用，仅1.9%被评为无用，从而证明了该方法在提升人群健康参与度方面的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "20 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10816v2",
      "published_date": "2024-01-19 17:03:37 UTC",
      "updated_date": "2024-02-09 00:55:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:51:22.733568"
    },
    {
      "arxiv_id": "2401.10805v3",
      "title": "Learning to Visually Connect Actions and their Effects",
      "title_zh": "翻译失败",
      "authors": [
        "Paritosh Parmar",
        "Eric Peh",
        "Basura Fernando"
      ],
      "abstract": "We introduce the novel concept of visually Connecting Actions and Their\nEffects (CATE) in video understanding. CATE can have applications in areas like\ntask planning and learning from demonstration. We identify and explore two\ndifferent aspects of the concept of CATE: Action Selection (AS) and\nEffect-Affinity Assessment (EAA), where video understanding models connect\nactions and effects at semantic and fine-grained levels, respectively. We\ndesign various baseline models for AS and EAA. Despite the intuitive nature of\nthe task, we observe that models struggle, and humans outperform them by a\nlarge margin. Our experiments show that in solving AS and EAA, models learn\nintuitive properties like object tracking and pose encoding without explicit\nsupervision. We demonstrate that CATE can be an effective self-supervised task\nfor learning video representations from unlabeled videos. The study aims to\nshowcase the fundamental nature and versatility of CATE, with the hope of\ninspiring advanced formulations and models.",
      "tldr_zh": "本研究引入了视觉连接动作及其效果 (CATE) 的新概念，旨在提升视频理解在任务规划和从演示中学习等领域的应用。论文探讨了 CATE 的两个方面：Action Selection (AS) 在语义层面连接动作和效果，以及 Effect-Affinity Assessment (EAA) 在细粒度层面进行评估，并设计了各种基线模型。实验结果显示，尽管模型能够在无监督条件下学习对象跟踪和姿势编码等直观属性，但其性能远低于人类。总体而言，该研究证明 CATE 是一种有效的自监督任务，可用于从无标签视频中学习表示，并有望激发更先进的模型开发。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10805v3",
      "published_date": "2024-01-19 16:48:49 UTC",
      "updated_date": "2024-07-26 16:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:51:34.724728"
    },
    {
      "arxiv_id": "2401.10969v2",
      "title": "MacroSwarm: A Field-based Compositional Framework for Swarm Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Gianluca Aguzzi",
        "Roberto Casadei",
        "Mirko Viroli"
      ],
      "abstract": "Swarm behaviour engineering is an area of research that seeks to investigate\nmethods and techniques for coordinating computation and action within groups of\nsimple agents to achieve complex global goals like pattern formation,\ncollective movement, clustering, and distributed sensing. Despite recent\nprogress in the analysis and engineering of swarms (of drones, robots,\nvehicles), there is still a need for general design and implementation methods\nand tools that can be used to define complex swarm behaviour in a principled\nway. To contribute to this quest, this article proposes a new field-based\ncoordination approach, called MacroSwarm, to design and program swarm behaviour\nin terms of reusable and fully composable functional blocks embedding\ncollective computation and coordination. Based on the macroprogramming paradigm\nof aggregate computing, MacroSwarm builds on the idea of expressing each swarm\nbehaviour block as a pure function, mapping sensing fields into actuation goal\nfields, e.g., including movement vectors. In order to demonstrate the\nexpressiveness, compositionality, and practicality of MacroSwarm as a framework\nfor swarm programming, we perform a variety of simulations covering common\npatterns of flocking, pattern formation, and collective decision-making. The\nimplications of the inherent self-stabilisation properties of field-based\ncomputations in MacroSwarm are discussed, which formally guarantee some\nresilience properties and guided the design of the library.",
      "tldr_zh": "该研究针对群智能（swarm behaviour）工程提出了一种基于场域（field-based）的可组合框架——MacroSwarm，用于以原则化的方式设计和编程复杂群行为。该框架借鉴 macroprogramming 范式，将每个行为块设计为纯函数，从感知场域映射到动作目标场域（如运动向量），从而实现可重用和完全可组合的功能模块。通过各种模拟实验，MacroSwarm 展示了在 flocking、pattern formation 和 collective decision-making 等常见模式中的表达性、组合性和实用性。此外，该框架利用 field-based computations 的自稳定特性，确保系统具备韧性（如恢复能力和可靠性）。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10969v2",
      "published_date": "2024-01-19 16:32:02 UTC",
      "updated_date": "2024-11-11 09:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:51:45.574774"
    },
    {
      "arxiv_id": "2401.10781v1",
      "title": "Metric Dynamic Equilibrium Logic",
      "title_zh": "度量动态平衡逻辑",
      "authors": [
        "Arvid Becker",
        "Pedro Cabalar",
        "Martín Diéguez",
        "Luis Fariñas",
        "Torsten Schaub",
        "Anna Schuhmann"
      ],
      "abstract": "In temporal extensions of Answer Set Programming (ASP) based on linear-time,\nthe behavior of dynamic systems is captured by sequences of states. While this\nrepresentation reflects their relative order, it abstracts away the specific\ntimes associated with each state. In many applications, however, timing\nconstraints are important like, for instance, when planning and scheduling go\nhand in hand. We address this by developing a metric extension of linear-time\nDynamic Equilibrium Logic, in which dynamic operators are constrained by\nintervals over integers. The resulting Metric Dynamic Equilibrium Logic\nprovides the foundation of an ASP-based approach for specifying qualitative and\nquantitative dynamic constraints. As such, it constitutes the most general\namong a whole spectrum of temporal extensions of Equilibrium Logic. In detail,\nwe show that it encompasses Temporal, Dynamic, Metric, and regular Equilibrium\nLogic, as well as its classic counterparts once the law of the excluded middle\nis added.",
      "tldr_zh": "本文提出 Metric Dynamic Equilibrium Logic，一种扩展 Answer Set Programming (ASP) 的线性时间框架，用于处理动态系统状态序列中时间约束的问题，通过在动态操作中加入整数区间来整合定性和定量动态约束。该方法允许指定时间相关的规划和调度需求，并证明它是 Equilibrium Logic 各种时间扩展中最通用的形式，涵盖了 Temporal, Dynamic, Metric 和常规 Equilibrium Logic，以及添加排中律后的经典版本。总的来说，这一贡献为 ASP 在时间敏感应用中的应用提供了更坚实的基础。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2304.14778",
      "pdf_url": "http://arxiv.org/pdf/2401.10781v1",
      "published_date": "2024-01-19 16:01:38 UTC",
      "updated_date": "2024-01-19 16:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:51:58.702717"
    },
    {
      "arxiv_id": "2401.10759v1",
      "title": "Interactions with Prompt Problems: A New Way to Teach Programming with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "James Prather",
        "Paul Denny",
        "Juho Leinonen",
        "David H. Smith IV",
        "Brent N. Reeves",
        "Stephen MacNeil",
        "Brett A. Becker",
        "Andrew Luxton-Reilly",
        "Thezyrie Amarouche",
        "Bailey Kimmel"
      ],
      "abstract": "Large Language Models (LLMs) have upended decades of pedagogy in computing\neducation. Students previously learned to code through \\textit{writing} many\nsmall problems with less emphasis on code reading and comprehension. Recent\nresearch has shown that free code generation tools powered by LLMs can solve\nintroductory programming problems presented in natural language with ease. In\nthis paper, we propose a new way to teach programming with Prompt Problems.\nStudents receive a problem visually, indicating how input should be transformed\nto output, and must translate that to a prompt for an LLM to decipher. The\nproblem is considered correct when the code that is generated by the student\nprompt can pass all test cases. In this paper we present the design of this\ntool, discuss student interactions with it as they learn, and provide insights\ninto this new class of programming problems as well as the design tools that\nintegrate LLMs.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 如何革新编程教育，提出了一种新方法“Prompt Problems”，让学生通过创建提示来学习编程，而不是直接编写代码。学生需将视觉化的输入输出问题转化为 LLM 可理解的提示，并通过生成的代码是否通过所有测试用例来验证正确性。该方法强调代码阅读和理解，论文分析了学生与工具的互动、工具设计，以及这种新类编程问题的潜在见解和益处。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "accepted for CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10759v1",
      "published_date": "2024-01-19 15:32:46 UTC",
      "updated_date": "2024-01-19 15:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:52:11.061833"
    },
    {
      "arxiv_id": "2401.10753v1",
      "title": "BoolGebra: Attributed Graph-learning for Boolean Algebraic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yingjie Li",
        "Anthony Agnesina",
        "Yanqing Zhang",
        "Haoxing Ren",
        "Cunxi Yu"
      ],
      "abstract": "Boolean algebraic manipulation is at the core of logic synthesis in\nElectronic Design Automation (EDA) design flow. Existing methods struggle to\nfully exploit optimization opportunities, and often suffer from an explosive\nsearch space and limited scalability efficiency. This work presents BoolGebra,\na novel attributed graph-learning approach for Boolean algebraic manipulation\nthat aims to improve fundamental logic synthesis. BoolGebra incorporates Graph\nNeural Networks (GNNs) and takes initial feature embeddings from both\nstructural and functional information as inputs. A fully connected neural\nnetwork is employed as the predictor for direct optimization result\npredictions, significantly reducing the search space and efficiently locating\nthe optimization space. The experiments involve training the BoolGebra model\nw.r.t design-specific and cross-design inferences using the trained model,\nwhere BoolGebra demonstrates generalizability for cross-design inference and\nits potential to scale from small, simple training datasets to large, complex\ninference datasets. Finally, BoolGebra is integrated with existing synthesis\ntool ABC to perform end-to-end logic minimization evaluation w.r.t SOTA\nbaselines.",
      "tldr_zh": "这篇论文提出 BoolGebra，一种基于属性图学习的框架，用于优化电子设计自动化 (EDA) 中的布尔代数操作，旨在解决现有方法在搜索空间爆炸和可扩展性方面的局限性。BoolGebra 利用 Graph Neural Networks (GNNs) 结合结构和功能信息作为输入，并通过全连接神经网络直接预测优化结果，从而显著减少搜索空间并提升效率。实验结果表明，该模型在设计特定和跨设计推理中显示出良好的泛化性和可扩展性，并在与现有合成工具 ABC 集成的端到端逻辑最小化评估中优于最先进基线 (SOTA)。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "DATE 2024 extended version. arXiv admin note: text overlap with\n  arXiv:2310.07846",
      "pdf_url": "http://arxiv.org/pdf/2401.10753v1",
      "published_date": "2024-01-19 15:22:28 UTC",
      "updated_date": "2024-01-19 15:22:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:52:23.486836"
    },
    {
      "arxiv_id": "2401.10751v1",
      "title": "EFO: the Emotion Frame Ontology",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano De Giorgis",
        "Aldo Gangemi"
      ],
      "abstract": "Emotions are a subject of intense debate in various disciplines. Despite the\nproliferation of theories and definitions, there is still no consensus on what\nemotions are, and how to model the different concepts involved when we talk\nabout - or categorize - them. In this paper, we propose an OWL frame-based\nontology of emotions: the Emotion Frames Ontology (EFO). EFO treats emotions as\nsemantic frames, with a set of semantic roles that capture the different\naspects of emotional experience. EFO follows pattern-based ontology design, and\nis aligned to the DOLCE foundational ontology. EFO is used to model multiple\nemotion theories, which can be cross-linked as modules in an Emotion Ontology\nNetwork. In this paper, we exemplify it by modeling Ekman's Basic Emotions (BE)\nTheory as an EFO-BE module, and demonstrate how to perform automated inferences\non the representation of emotion situations. EFO-BE has been evaluated by\nlexicalizing the BE emotion frames from within the Framester knowledge graph,\nand implementing a graph-based emotion detector from text. In addition, an EFO\nintegration of multimodal datasets, including emotional speech and emotional\nface expressions, has been performed to enable further inquiry into crossmodal\nemotion semantics.",
      "tldr_zh": "本论文提出了一种OWL框架为基础的情感本体——Emotion Frames Ontology (EFO)，将情感视为语义框架，并通过一组语义角色来捕捉情感体验的不同方面。EFO采用模式设计方法，并与DOLCE基础本体对齐，支持建模多种情感理论，如Ekman's Basic Emotions (BE)理论，并作为模块在情感本体网络中交叉链接。论文通过在Framester知识图谱中词汇化BE情感框架并实现基于图的文本情感检测器来评估EFO-BE模块，并整合多模态数据集（如情感语音和面部表情），以促进跨模态情感语义的进一步探究。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10751v1",
      "published_date": "2024-01-19 15:20:57 UTC",
      "updated_date": "2024-01-19 15:20:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:52:34.046665"
    },
    {
      "arxiv_id": "2401.12167v1",
      "title": "Dynamic Semantic Compression for CNN Inference in Multi-access Edge Computing: A Graph Reinforcement Learning-based Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Nan Li",
        "Alexandros Iosifidis",
        "Qi Zhang"
      ],
      "abstract": "This paper studies the computational offloading of CNN inference in dynamic\nmulti-access edge computing (MEC) networks. To address the uncertainties in\ncommunication time and computation resource availability, we propose a novel\nsemantic compression method, autoencoder-based CNN architecture (AECNN), for\neffective semantic extraction and compression in partial offloading. In the\nsemantic encoder, we introduce a feature compression module based on the\nchannel attention mechanism in CNNs, to compress intermediate data by selecting\nthe most informative features. In the semantic decoder, we design a lightweight\ndecoder to reconstruct the intermediate data through learning from the received\ncompressed data to improve accuracy. To effectively trade-off communication,\ncomputation, and inference accuracy, we design a reward function and formulate\nthe offloading problem of CNN inference as a maximization problem with the goal\nof maximizing the average inference accuracy and throughput over the long term.\nTo address this maximization problem, we propose a graph reinforcement\nlearning-based AECNN (GRL-AECNN) method, which outperforms existing works\nDROO-AECNN, GRL-BottleNet++ and GRL-DeepJSCC under different dynamic scenarios.\nThis highlights the advantages of GRL-AECNN in offloading decision-making in\ndynamic MEC.",
      "tldr_zh": "这篇论文针对动态多接入边缘计算 (MEC) 网络中 CNN 推理的计算卸载问题，提出了一种新型语义压缩方法，即基于自编码器的 CNN 架构 (AECNN)，通过在语义编码器中使用通道注意机制的特征压缩模块和在语义解码器中设计轻量级解码器，实现有效的语义提取和中间数据重建，以权衡通信、计算资源和推理准确性。论文将卸载问题表述为最大化平均推理准确性和吞吐量的长期优化问题，并引入基于图强化学习的 GRL-AECNN 方法。实验结果显示，GRL-AECNN 在不同动态场景下优于现有方法如 DROO-AECNN 和 GRL-BottleNet++，突出了其在动态 MEC 卸载决策中的优势。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "arXiv admin note: text overlap with arXiv:2211.13745",
      "pdf_url": "http://arxiv.org/pdf/2401.12167v1",
      "published_date": "2024-01-19 15:19:47 UTC",
      "updated_date": "2024-01-19 15:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:52:49.544626"
    },
    {
      "arxiv_id": "2401.10746v4",
      "title": "A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding",
      "title_zh": "欧几里得对齐与深度学习在 EEG 解码中的系统评估",
      "authors": [
        "Bruna Junqueira",
        "Bruno Aristimunha",
        "Sylvain Chevallier",
        "Raphael Y. de Camargo"
      ],
      "abstract": "Electroencephalography (EEG) signals are frequently used for various\nBrain-Computer Interface (BCI) tasks. While Deep Learning (DL) techniques have\nshown promising results, they are hindered by the substantial data\nrequirements. By leveraging data from multiple subjects, transfer learning\nenables more effective training of DL models. A technique that is gaining\npopularity is Euclidean Alignment (EA) due to its ease of use, low\ncomputational complexity, and compatibility with Deep Learning models. However,\nfew studies evaluate its impact on the training performance of shared and\nindividual DL models. In this work, we systematically evaluate the effect of EA\ncombined with DL for decoding BCI signals. We used EA to train shared models\nwith data from multiple subjects and evaluated its transferability to new\nsubjects. Our experimental results show that it improves decoding in the target\nsubject by 4.33% and decreases convergence time by more than 70%. We also\ntrained individual models for each subject to use as a majority-voting ensemble\nclassifier. In this scenario, using EA improved the 3-model ensemble accuracy\nby 3.7%. However, when compared to the shared model with EA, the ensemble\naccuracy was 3.62% lower.",
      "tldr_zh": "本研究系统评估了Euclidean Alignment (EA)与Deep Learning (DL)结合用于Electroencephalography (EEG)信号解码的效果，旨在通过多主体数据转移学习解决DL模型数据需求大的问题。实验结果显示，使用EA训练共享模型时，目标主体的解码准确率提高了4.33%，并将收敛时间减少超过70%。此外，在个体模型的多数投票集成分类器中，EA提升了3-模型集成准确率3.7%，但与EA增强的共享模型相比，集成准确率仍低3.62%。这项工作为Brain-Computer Interface (BCI)任务中的高效模型训练提供了重要见解。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "I.5.1; I.6.3; I.2.6"
      ],
      "primary_category": "eess.SP",
      "comment": "14 pages and 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10746v4",
      "published_date": "2024-01-19 15:13:30 UTC",
      "updated_date": "2024-05-23 00:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:53:00.756785"
    },
    {
      "arxiv_id": "2401.10744v1",
      "title": "FinLLMs: A Framework for Financial Reasoning Dataset Generation with Large Language Models",
      "title_zh": "FinLLMs：一个用于金融推理数据集生成的框架，利用大型语言模型",
      "authors": [
        "Ziqiang Yuan",
        "Kaiyuan Wang",
        "Shoutai Zhu",
        "Ye Yuan",
        "Jingya Zhou",
        "Yanlin Zhu",
        "Wenqi Wei"
      ],
      "abstract": "Large Language models (LLMs) usually rely on extensive training datasets. In\nthe financial domain, creating numerical reasoning datasets that include a mix\nof tables and long text often involves substantial manual annotation expenses.\nTo address the limited data resources and reduce the annotation cost, we\nintroduce FinLLMs, a method for generating financial question-answering data\nbased on common financial formulas using Large Language Models. First, we\ncompile a list of common financial formulas and construct a graph based on the\nvariables these formulas employ. We then augment the formula set by combining\nthose that share identical variables as new elements. Specifically, we explore\nformulas obtained by manual annotation and merge those formulas with shared\nvariables by traversing the constructed graph. Finally, utilizing GPT-3.5, we\ngenerate financial question-answering data that encompasses both tabular\ninformation and long textual content, building on the collected formula set.\nOur experiments demonstrate that synthetic data generated by FinLLMs\neffectively enhances the performance of several large-scale numerical reasoning\nmodels in the financial domain, outperforming two established benchmark\nfinancial question-answering datasets.",
      "tldr_zh": "这篇论文介绍了 FinLLMs 框架，一种利用 Large Language Models (LLMs) 生成金融推理数据集的方法，旨在解决金融领域数据资源有限和手动标注成本高的问题。框架首先编译常见金融公式、构建基于变量的图结构，并通过遍历图合并共享变量的公式，以增强公式集；随后，使用 GPT-3.5 生成包含表格和长文本的金融问答数据。实验结果显示，FinLLMs 生成的合成数据显著提升了多个大规模数值推理模型在金融领域的性能，并超过了两个现有基准数据集。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under submission of IEEE Transactions",
      "pdf_url": "http://arxiv.org/pdf/2401.10744v1",
      "published_date": "2024-01-19 15:09:39 UTC",
      "updated_date": "2024-01-19 15:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:53:10.626734"
    },
    {
      "arxiv_id": "2401.10733v2",
      "title": "Dynamic Q&A of Clinical Documents with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Elgedawy",
        "Ioana Danciu",
        "Maria Mahbub",
        "Sudarshan Srinivasan"
      ],
      "abstract": "Electronic health records (EHRs) house crucial patient data in clinical\nnotes. As these notes grow in volume and complexity, manual extraction becomes\nchallenging. This work introduces a natural language interface using large\nlanguage models (LLMs) for dynamic question-answering on clinical notes. Our\nchatbot, powered by Langchain and transformer-based LLMs, allows users to query\nin natural language, receiving relevant answers from clinical notes.\nExperiments, utilizing various embedding models and advanced LLMs, show Wizard\nVicuna's superior accuracy, albeit with high compute demands. Model\noptimization, including weight quantization, improves latency by approximately\n48 times. Promising results indicate potential, yet challenges such as model\nhallucinations and limited diverse medical case evaluations remain. Addressing\nthese gaps is crucial for unlocking the value in clinical notes and advancing\nAI-driven clinical decision-making.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型（LLMs）的自然语言接口，用于电子健康记录（EHRs）临床笔记的动态问答（Q&A），以解决手动提取数据的问题。系统利用 Langchain 和 transformer-based LLMs 构建了一个聊天机器人，允许用户以自然语言查询并获取相关答案。实验结果显示，Wizard Vicuna 模型在准确性上优于其他模型，但计算需求较高，通过权重量化优化将延迟降低了约 48 倍。尽管有前景，但仍存在模型幻觉和对多样化医疗案例评估不足的挑战，需要进一步解决以推动 AI 驱动的临床决策。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10733v2",
      "published_date": "2024-01-19 14:50:22 UTC",
      "updated_date": "2024-07-02 15:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:53:23.533015"
    },
    {
      "arxiv_id": "2401.10725v1",
      "title": "Proceedings 14th International Conference on Automated Deduction in Geometry",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Quaresma",
        "Zoltán Kovács"
      ],
      "abstract": "ADG is a forum to exchange ideas and views, to present research results and\nprogress, and to demonstrate software tools at the intersection between\ngeometry and automated deduction. The conference is held every two years. The\nprevious editions of ADG were held in Hagenberg in 2021 (online, postponed from\n2020 due to COVID-19), Nanning in 2018, Strasbourg in 2016, Coimbra in 2014,\nEdinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006,\nGainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and\nToulouse in 1996.\n  The 14th edition, ADG 2023, was held in Belgrade, Serbia, in September 20-22,\n2023. This edition of ADG had an additional special focus topic, Deduction in\nEducation.\n  Invited Speakers: Julien Narboux, University of Strasbourg, France\n\"Formalisation, arithmetization and automatisation of geometry\"; Filip Mari\\'c,\nUniversity of Belgrade, Serbia, \"Automatization, formalization and\nvisualization of hyperbolic geometry\"; Zlatan Magajna, University of Ljubljana,\nSlovenia, \"Workshop OK Geometry\"",
      "tldr_zh": "ADG（Automated Deduction in Geometry）是每两年举办一次的国际会议，旨在促进几何学与自动推理交叉领域的学术交流、研究成果分享和软件工具展示。第 14 届 ADG 于 2023 年 9 月 20-22 日在塞尔维亚贝尔格莱德举行，特别聚焦于 Deduction in Education 主题。会议邀请了多位专家演讲，包括 Julien Narboux 讨论几何的 Formalisation, arithmetization and automatisation，以及 Filip Marić 探讨超几何的 Automatization, formalization and visualization 等内容。整体活动回顾了 ADG 的历史发展，并强调了教育领域的推理应用潜力。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.CG",
        "cs.MS"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10725v1",
      "published_date": "2024-01-19 14:42:08 UTC",
      "updated_date": "2024-01-19 14:42:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:53:35.109458"
    },
    {
      "arxiv_id": "2401.10712v5",
      "title": "Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Haibo Wang",
        "Weifeng Ge"
      ],
      "abstract": "With the breakthrough of multi-modal large language models, answering complex\nvisual questions that demand advanced reasoning abilities and world knowledge\nhas become a much more important testbed for developing AI models than ever.\nHowever, equipping AI models with robust cross-modality reasoning ability\nremains challenging since the cognition scheme of humans has not been\nunderstood systematically. In this paper, we believe that if we can collect\nvisual clues in the given image as much as possible, we will recognize the\nimage more accurately, understand the question better, recall relevant\nknowledge more easily, and finally reason out the answer. We discover these\nrich visual clues by mining question-answer pairs in images and sending them\ninto multi-modal large language models as prompts. We call the proposed method\nQ&A Prompts. Specifically, we first use the image-answer pairs and the\ncorresponding questions in the training set as inputs and outputs to train a\nvisual question generation model. Then, we use an image tagging model to\nidentify various instances and send packaged image-tag pairs into the visual\nquestion generation model to generate relevant questions with the extracted\nimage tags as answers. Finally, we encode these generated question-answer pairs\nas prompts with a visual-aware prompting module and send them into pre-trained\nmulti-modal large language models to reason out the final answers. Experimental\nresults show that, compared with state-of-the-art methods, our Q&A Prompts\nachieves substantial improvements on the challenging visual question answering\ndatasets requiring reasoning over diverse world knowledge, such as OK-VQA and\nA-OKVQA.",
      "tldr_zh": "本文提出Q&A Prompts方法，通过挖掘图像中的问题-答案对来发现丰富的视觉线索，从而提升视觉问答(VQA)任务中对多样世界知识的推理能力。具体而言，该方法先利用训练集的图像-答案对训练一个视觉问题生成模型，然后通过图像标记模型生成相关Q&A对，并将这些对编码为提示输入多模态大语言模型进行最终推理。实验结果显示，与现有方法相比，Q&A Prompts在需要世界知识的VQA数据集如OK-VQA和A-OKVQA上取得了显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV'24",
      "pdf_url": "http://arxiv.org/pdf/2401.10712v5",
      "published_date": "2024-01-19 14:22:29 UTC",
      "updated_date": "2024-10-12 08:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:53:47.523828"
    },
    {
      "arxiv_id": "2401.10711v4",
      "title": "Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Haibo Wang",
        "Chenghang Lai",
        "Yixuan Sun",
        "Weifeng Ge"
      ],
      "abstract": "Video Question Answering (VideoQA) aims to answer natural language questions\nbased on the information observed in videos. Despite the recent success of\nLarge Multimodal Models (LMMs) in image-language understanding and reasoning,\nthey deal with VideoQA insufficiently, by simply taking uniformly sampled\nframes as visual inputs, which ignores question-relevant visual clues.\nMoreover, there are no human annotations for question-critical timestamps in\nexisting VideoQA datasets. In light of this, we propose a novel weakly\nsupervised framework to enforce the LMMs to reason out the answers with\nquestion-critical moments as visual inputs. Specifically, we first fuse the\nquestion and answer pairs as event descriptions to find multiple keyframes as\ntarget moments and pseudo-labels, with the visual-language alignment capability\nof the CLIP models. With these pseudo-labeled keyframes as additionally weak\nsupervision, we devise a lightweight Gaussian-based Contrastive Grounding (GCG)\nmodule. GCG learns multiple Gaussian functions to characterize the temporal\nstructure of the video, and sample question-critical frames as positive moments\nto be the visual inputs of LMMs. Extensive experiments on several benchmarks\nverify the effectiveness of our framework, and we achieve substantial\nimprovements compared to previous state-of-the-art methods.",
      "tldr_zh": "该论文针对视频问答（VideoQA）任务，提出了一种弱监督框架，利用大型多模态模型（LMMs）来识别问题相关的关键时刻，从而提升回答准确性。该框架首先使用 CLIP 模型将问题和答案融合为事件描述，生成多个关键帧作为伪标签；接着引入轻量级的 Gaussian-based Contrastive Grounding (GCG) 模块，通过学习多个高斯函数表征视频时序结构，并采样关键帧作为 LMMs 的视觉输入。实验结果显示，该方法在多个基准测试中显著优于现有最先进方法，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by ACM Multimedia 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10711v4",
      "published_date": "2024-01-19 14:21:46 UTC",
      "updated_date": "2024-07-23 10:17:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:54:00.604823"
    },
    {
      "arxiv_id": "2401.10700v1",
      "title": "Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model",
      "title_zh": "安全的离线强化学习与可行性引导的扩散模型",
      "authors": [
        "Yinan Zheng",
        "Jianxiong Li",
        "Dongjie Yu",
        "Yujie Yang",
        "Shengbo Eben Li",
        "Xianyuan Zhan",
        "Jingjing Liu"
      ],
      "abstract": "Safe offline RL is a promising way to bypass risky online interactions\ntowards safe policy learning. Most existing methods only enforce soft\nconstraints, i.e., constraining safety violations in expectation below\nthresholds predetermined. This can lead to potentially unsafe outcomes, thus\nunacceptable in safety-critical scenarios. An alternative is to enforce the\nhard constraint of zero violation. However, this can be challenging in offline\nsetting, as it needs to strike the right balance among three highly intricate\nand correlated aspects: safety constraint satisfaction, reward maximization,\nand behavior regularization imposed by offline datasets. Interestingly, we\ndiscover that via reachability analysis of safe-control theory, the hard safety\nconstraint can be equivalently translated to identifying the largest feasible\nregion given the offline dataset. This seamlessly converts the original trilogy\nproblem to a feasibility-dependent objective, i.e., maximizing reward value\nwithin the feasible region while minimizing safety risks in the infeasible\nregion. Inspired by these, we propose FISOR (FeasIbility-guided Safe Offline\nRL), which allows safety constraint adherence, reward maximization, and offline\npolicy learning to be realized via three decoupled processes, while offering\nstrong safety performance and stability. In FISOR, the optimal policy for the\ntranslated optimization problem can be derived in a special form of weighted\nbehavior cloning. Thus, we propose a novel energy-guided diffusion model that\ndoes not require training a complicated time-dependent classifier to extract\nthe policy, greatly simplifying the training. We compare FISOR against\nbaselines on DSRL benchmark for safe offline RL. Evaluation results show that\nFISOR is the only method that can guarantee safety satisfaction in all tasks,\nwhile achieving top returns in most tasks.",
      "tldr_zh": "该论文针对安全离线强化学习（Safe Offline RL）提出了一种新方法 FISOR（FeasIbility-guided Safe Offline RL），通过安全控制理论的可达性分析，将硬安全约束转化为识别离线数据集中的最大可行区域，从而平衡安全约束满足、奖励最大化和行为正则化。FISOR 将优化问题解耦为三个过程，包括使用一种特殊的加权行为克隆（weighted behavior cloning）形式导出策略，并引入能量引导扩散模型（energy-guided diffusion model）来简化训练过程，而无需复杂的时序分类器。实验结果显示，在 DSRL 基准测试中，FISOR 是唯一能保证所有任务零安全违规的方法，并在大多数任务中实现最高回报。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024, 30pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10700v1",
      "published_date": "2024-01-19 14:05:09 UTC",
      "updated_date": "2024-01-19 14:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:54:12.524247"
    },
    {
      "arxiv_id": "2401.10690v4",
      "title": "Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models",
      "title_zh": "超越 RMSE 和 MAE：引入 EAUC 以揭示二元回归模型中的隐藏偏差和不公平",
      "authors": [
        "Jorge Paz-Ruza",
        "Amparo Alonso-Betanzos",
        "Bertha Guijarro-Berdiñas",
        "Brais Cancela",
        "Carlos Eiras-Franco"
      ],
      "abstract": "Dyadic regression models, which output real-valued predictions for pairs of\nentities, are fundamental in many domains (e.g. obtaining user-product ratings\nin Recommender Systems) and promising and under exploration in others (e.g.\ntuning patient-drug dosages in precision pharmacology). In this work, we prove\nthat non-uniform observed value distributions of individual entities lead to\nsevere biases in state-of-the-art models, skewing predictions towards the\naverage of observed past values for the entity and providing worse-than-random\npredictive power in eccentric yet crucial cases; we name this phenomenon\neccentricity bias. We show that global error metrics like Root Mean Squared\nError (RMSE) are insufficient to capture this bias, and we introduce\nEccentricity-Area Under the Curve (EAUC) as a novel metric that can quantify it\nin all studied domains and models. We prove the intuitive interpretation of\nEAUC by experimenting with naive post-training bias corrections, and theorize\nother options to use EAUC to guide the construction of fair models. This work\ncontributes a bias-aware evaluation of dyadic regression to prevent unfairness\nin critical real-world applications of such systems.",
      "tldr_zh": "本研究揭示了 dyadic regression 模型中的隐藏偏置问题，即 eccentricity bias，这种偏置源于实体观察值分布的不均匀，导致预测偏向过去值的平均，并在某些关键场景下表现不如随机。传统全局错误指标如 RMSE 和 MAE 无法有效捕捉这一偏置，因此作者引入了新的评估指标 Eccentricity-Area Under the Curve (EAUC)，用于量化偏置在不同领域和模型中的影响。实验通过简单的后训练偏置修正验证了 EAUC 的直观解释，并探讨了如何利用该指标指导构建更公平的模型。该工作为 dyadic regression 模型在关键应用（如推荐系统和精准药理学）中提供偏置感知评估，防止潜在的不公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10690v4",
      "published_date": "2024-01-19 13:41:08 UTC",
      "updated_date": "2025-03-07 08:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:54:24.833547"
    },
    {
      "arxiv_id": "2401.10685v2",
      "title": "Towards End-to-End GPS Localization with Neural Pseudorange Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Weng",
        "KV Ling",
        "Haochen Liu",
        "Kun Cao"
      ],
      "abstract": "The pseudorange error is one of the root causes of localization inaccuracy in\nGPS. Previous data-driven methods regress and eliminate pseudorange errors\nusing handcrafted intermediate labels. Unlike them, we propose an end-to-end\nGPS localization framework, E2E-PrNet, to train a neural network for\npseudorange correction (PrNet) directly using the final task loss calculated\nwith the ground truth of GPS receiver states. The gradients of the loss with\nrespect to learnable parameters are backpropagated through a Differentiable\nNonlinear Least Squares (DNLS) optimizer to PrNet. The feasibility of fusing\nthe data-driven neural network and the model-based DNLS module is verified with\nGPS data collected by Android phones, showing that E2E-PrNet outperforms the\nbaseline weighted least squares method and the state-of-the-art end-to-end\ndata-driven approach. Finally, we discuss the explainability of E2E-PrNet.",
      "tldr_zh": "该研究针对GPS定位中pseudorange错误的根因，提出了一种端到端框架E2E-PrNet，使用神经网络直接修正pseudorange错误，而非依赖手工中间标签。E2E-PrNet通过最终任务损失（基于GPS接收器状态的真实值）训练网络，并利用Differentiable Nonlinear Least Squares (DNLS)优化器反向传播梯度，实现数据驱动神经网络与模型-based模块的融合。实验结果显示，在Android手机收集的GPS数据上，E2E-PrNet优于基线weighted least squares方法和现有端到端数据驱动方法，并讨论了该框架的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10685v2",
      "published_date": "2024-01-19 13:32:55 UTC",
      "updated_date": "2024-08-21 06:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:54:36.532942"
    },
    {
      "arxiv_id": "2401.10965v1",
      "title": "Decentralizing Coordination in Open Vehicle Fleets for Scalable and Dynamic Task Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Marin Lujak",
        "Stefano Giordani",
        "Andrea Omicini",
        "Sascha Ossowski"
      ],
      "abstract": "One of the major challenges in the coordination of large, open,\ncollaborative, and commercial vehicle fleets is dynamic task allocation.\nSelf-concerned individually rational vehicle drivers have both local and global\nobjectives, which require coordination using some fair and efficient task\nallocation method. In this paper, we review the literature on scalable and\ndynamic task allocation focusing on deterministic and dynamic two-dimensional\nlinear assignment problems. We focus on multiagent system representation of\nopen vehicle fleets where dynamically appearing vehicles are represented by\nsoftware agents that should be allocated to a set of dynamically appearing\ntasks. We give a comparison and critical analysis of recent research results\nfocusing on centralized, distributed, and decentralized solution approaches.\nMoreover, we propose mathematical models for dynamic versions of the following\nassignment problems well known in combinatorial optimization: the assignment\nproblem, bottleneck assignment problem, fair matching problem, dynamic minimum\ndeviation assignment problem, $\\sum_{k}$-assignment problem, the semiassignment\nproblem, the assignment problem with side constraints, and the assignment\nproblem while recognizing agent qualification; all while considering the main\naspect of open vehicle fleets: random arrival of tasks and vehicles (agents)\nthat may become available after assisting previous tasks or by participating in\nthe fleet at times based on individual interest.",
      "tldr_zh": "该论文探讨了在开放车辆车队中实现可扩展和动态任务分配的去中心化协调问题，针对车辆司机本地和全局目标提出公平有效的分配方法。作者回顾了相关文献，聚焦于确定性和动态二维线性分配问题，并使用多智能体系统(multiagent system)表示动态出现的车辆和任务，比较了集中式、分布式和去中心化解决方案。论文贡献包括提出数学模型扩展多种经典分配问题，如assignment problem、bottleneck assignment problem和fair matching problem，同时考虑任务和车辆的随机到达，以提升车队协调的灵活性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10965v1",
      "published_date": "2024-01-19 12:47:27 UTC",
      "updated_date": "2024-01-19 12:47:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:54:48.451122"
    },
    {
      "arxiv_id": "2401.10660v2",
      "title": "Accelerating Multilingual Language Model for Excessively Tokenized Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Jimin Hong",
        "Gibbeum Lee",
        "Jaewoong Cho"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have remarkably enhanced\nperformances on a variety of tasks in multiple languages. However, tokenizers\nin LLMs trained primarily on English-centric corpora often overly fragment a\ntext into character or Unicode-level tokens in non-Roman alphabetic languages,\nleading to inefficient text generation. We introduce a simple yet effective\nframework to accelerate text generation in such languages. Our approach\ninvolves employing a new language model head with a vocabulary set tailored to\na specific target language for a pre-trained LLM. This is followed by\nfine-tuning the new head while incorporating a verification step to ensure the\nmodel's performance is preserved. We show that this targeted fine-tuning, while\nfreezing other model parameters, effectively reduces token fragmentation for\nthe target language. Our extensive experiments demonstrate that the proposed\nframework increases the generation speed by a factor of 1.7 while maintaining\nthe performance of pre-trained multilingual models on target monolingual tasks.",
      "tldr_zh": "最近的大型语言模型 (LLMs) 在多语言任务上表现突出，但其基于英语的 tokenizer 往往过度将非罗马字母语言的文本分解成字符或 Unicode 级 token，从而降低生成效率。作者提出一个简单框架，使用针对特定目标语言的词汇表和新的语言模型 head，对预训练 LLM 进行微调 (fine-tuning)，同时冻结其他参数并添加验证步骤以保持性能。实验结果显示，该方法有效减少 token 碎片化，将文本生成速度提高了 1.7 倍，同时在目标单语任务上维持了模型的原有表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2401.10660v2",
      "published_date": "2024-01-19 12:26:57 UTC",
      "updated_date": "2024-08-06 08:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:55:00.999629"
    },
    {
      "arxiv_id": "2401.10643v1",
      "title": "A Comprehensive Survey on Deep-Learning-based Vehicle Re-Identification: Models, Data Sets and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Amiri",
        "Aydin Kaya",
        "Ali Seydi Keceli"
      ],
      "abstract": "Vehicle re-identification (ReID) endeavors to associate vehicle images\ncollected from a distributed network of cameras spanning diverse traffic\nenvironments. This task assumes paramount importance within the spectrum of\nvehicle-centric technologies, playing a pivotal role in deploying Intelligent\nTransportation Systems (ITS) and advancing smart city initiatives. Rapid\nadvancements in deep learning have significantly propelled the evolution of\nvehicle ReID technologies in recent years. Consequently, undertaking a\ncomprehensive survey of methodologies centered on deep learning for vehicle\nre-identification has become imperative and inescapable. This paper extensively\nexplores deep learning techniques applied to vehicle ReID. It outlines the\ncategorization of these methods, encompassing supervised and unsupervised\napproaches, delves into existing research within these categories, introduces\ndatasets and evaluation criteria, and delineates forthcoming challenges and\npotential research directions. This comprehensive assessment examines the\nlandscape of deep learning in vehicle ReID and establishes a foundation and\nstarting point for future works. It aims to serve as a complete reference by\nhighlighting challenges and emerging trends, fostering advancements and\napplications in vehicle ReID utilizing deep learning models.",
      "tldr_zh": "这篇论文对基于深度学习的车辆再识别 (Vehicle Re-Identification, ReID) 进行了全面调查，强调其在智能交通系统 (ITS) 和智能城市中的关键作用。论文分类了监督和无监督方法，回顾了现有研究、数据集和评估标准，并探讨了面临的挑战，如数据多样性和模型泛化问题。最终，它为未来车辆 ReID 研究提供了基础，突出新兴趋势并促进深度学习模型的应用和发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10643v1",
      "published_date": "2024-01-19 11:45:10 UTC",
      "updated_date": "2024-01-19 11:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:55:12.190590"
    },
    {
      "arxiv_id": "2401.10642v1",
      "title": "Fast Butterfly-Core Community Search For Large Labeled Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "JiaYi Du",
        "Yinghao Wu",
        "Wei Ai",
        "Tao Meng",
        "CanHao Xie",
        "KeQin Li"
      ],
      "abstract": "Community Search (CS) aims to identify densely interconnected subgraphs\ncorresponding to query vertices within a graph. However, existing heterogeneous\ngraph-based community search methods need help identifying cross-group\ncommunities and suffer from efficiency issues, making them unsuitable for large\ngraphs. This paper presents a fast community search model based on the\nButterfly-Core Community (BCC) structure for heterogeneous graphs. The Random\nWalk with Restart (RWR) algorithm and butterfly degree comprehensively evaluate\nthe importance of vertices within communities, allowing leader vertices to be\nrapidly updated to maintain cross-group cohesion. Moreover, we devised a more\nefficient method for updating vertex distances, which minimizes vertex visits\nand enhances operational efficiency. Extensive experiments on several\nreal-world temporal graphs demonstrate the effectiveness and efficiency of this\nsolution.",
      "tldr_zh": "这篇论文针对大型标记图的社区搜索问题，提出了基于Butterfly-Core Community (BCC)结构的快速模型，以解决现有方法在异构图中识别跨组社区的效率不足问题。该模型利用Random Walk with Restart (RWR)算法和butterfly degree评估顶点重要性，并快速更新leader vertices，同时优化顶点距离更新方法以减少计算开销。实验结果显示，该方法在多个真实世界的时间图上表现出色，在有效性和效率方面均优于基线方案。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "8 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10642v1",
      "published_date": "2024-01-19 11:44:09 UTC",
      "updated_date": "2024-01-19 11:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:55:24.578840"
    },
    {
      "arxiv_id": "2401.10641v1",
      "title": "An Effective Index for Truss-based Community Search on Large Directed Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Ai",
        "CanHao Xie",
        "Tao Meng",
        "Yinghao Wu",
        "KeQin Li"
      ],
      "abstract": "Community search is a derivative of community detection that enables online\nand personalized discovery of communities and has found extensive applications\nin massive real-world networks. Recently, there needs to be more focus on the\ncommunity search issue within directed graphs, even though substantial research\nhas been carried out on undirected graphs. The recently proposed D-truss model\nhas achieved good results in the quality of retrieved communities. However,\nexisting D-truss-based work cannot perform efficient community searches on\nlarge graphs because it consumes too many computing resources to retrieve the\nmaximal D-truss. To overcome this issue, we introduce an innovative merge\nrelation known as D-truss-connected to capture the inherent density and\ncohesiveness of edges within D-truss. This relation allows us to partition all\nthe edges in the original graph into a series of D-truss-connected classes.\nThen, we construct a concise and compact index, ConDTruss, based on\nD-truss-connected. Using ConDTruss, the efficiency of maximum D-truss retrieval\nwill be greatly improved, making it a theoretically optimal approach.\nExperimental evaluations conducted on large directed graph certificate the\neffectiveness of our proposed method.",
      "tldr_zh": "本文提出了一种高效索引方法 ConDTruss，用于在大型有向图上进行基于 D-truss 的社区搜索，以解决现有方法计算资源消耗过大的问题。方法引入 D-truss-connected 关系来捕捉图边密度和连贯性，将图边分区为多个类，并基于此构建紧凑索引，从而显著提高最大 D-truss 检索效率。实验结果在大型有向图上验证了该方法的有效性，并证明其是理论上最优的社区搜索方案。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "8 pages, 8figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10641v1",
      "published_date": "2024-01-19 11:37:30 UTC",
      "updated_date": "2024-01-19 11:37:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:55:36.479010"
    },
    {
      "arxiv_id": "2401.10640v1",
      "title": "A comprehensive study on fidelity metrics for XAI",
      "title_zh": "针对 XAI 的保真度指标的全面研究",
      "authors": [
        "Miquel Miró-Nicolau",
        "Antoni Jaume-i-Capó",
        "Gabriel Moyà-Alcover"
      ],
      "abstract": "The use of eXplainable Artificial Intelligence (XAI) systems has introduced a\nset of challenges that need resolution. Herein, we focus on how to correctly\nselect an XAI method, an open questions within the field. The inherent\ndifficulty of this task is due to the lack of a ground truth. Several authors\nhave proposed metrics to approximate the fidelity of different XAI methods.\nThese metrics lack verification and have concerning disagreements. In this\nstudy, we proposed a novel methodology to verify fidelity metrics, using a\nwell-known transparent model, namely a decision tree. This model allowed us to\nobtain explanations with perfect fidelity. Our proposal constitutes the first\nobjective benchmark for these metrics, facilitating a comparison of existing\nproposals, and surpassing existing methods. We applied our benchmark to assess\nthe existing fidelity metrics in two different experiments, each using public\ndatasets comprising 52,000 images. The images from these datasets had a size a\n128 by 128 pixels and were synthetic data that simplified the training process.\nAll metric values, indicated a lack of fidelity, with the best one showing a 30\n\\% deviation from the expected values for perfect explanation. Our\nexperimentation led us to conclude that the current fidelity metrics are not\nreliable enough to be used in real scenarios. From this finding, we deemed it\nnecessary to development new metrics, to avoid the detected problems, and we\nrecommend the usage of our proposal as a benchmark within the scientific\ncommunity to address these limitations.",
      "tldr_zh": "本研究针对eXplainable Artificial Intelligence (XAI)中fidelity metrics的可靠性问题进行全面分析，指出现有metrics由于缺乏ground truth验证而存在分歧和不足。研究者提出一种新方法，使用决策树(decision tree)作为透明模型生成完美fidelity的解释，从而创建首个客观基准，用于评估和比较现有metrics。实验在两个公共数据集上进行，每数据集包含52,000张128x128像素的合成图像，结果显示所有metrics均显示fidelity不足，最佳者与预期值偏差达30%。最终结论是当前fidelity metrics不可靠，需要开发新metrics，并推荐使用该基准作为科学社区的标准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10640v1",
      "published_date": "2024-01-19 11:35:52 UTC",
      "updated_date": "2024-01-19 11:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:55:48.805289"
    },
    {
      "arxiv_id": "2401.10603v1",
      "title": "ZnTrack -- Data as Code",
      "title_zh": "ZnTrack：数据即代码",
      "authors": [
        "Fabian Zills",
        "Moritz Schäfer",
        "Samuel Tovey",
        "Johannes Kästner",
        "Christian Holm"
      ],
      "abstract": "The past decade has seen tremendous breakthroughs in computation and there is\nno indication that this will slow any time soon. Machine learning, large-scale\ncomputing resources, and increased industry focus have resulted in rising\ninvestments in computer-driven solutions for data management, simulations, and\nmodel generation. However, with this growth in computation has come an even\nlarger expansion of data and with it, complexity in data storage, sharing, and\ntracking. In this work, we introduce ZnTrack, a Python-driven data versioning\ntool. ZnTrack builds upon established version control systems to provide a\nuser-friendly and easy-to-use interface for tracking parameters in experiments,\ndesigning workflows, and storing and sharing data. From this ability to reduce\nlarge datasets to a simple Python script emerges the concept of Data as Code, a\ncore component of the work presented here and an undoubtedly important concept\nas the age of computation continues to evolve. ZnTrack offers an open-source,\nFAIR data compatible Python package to enable users to harness these concepts\nof the future.",
      "tldr_zh": "这篇论文介绍了 ZnTrack，一种基于 Python 的数据版本控制工具，旨在解决计算领域的快速发展和数据复杂性带来的存储、共享和跟踪挑战。ZnTrack 构建于现有版本控制系统之上，提供简便接口，用于跟踪实验参数、设计工作流以及高效管理数据集。核心贡献在于提出 “Data as Code” 概念，将大型数据集简化为 Python 脚本，同时 ZnTrack 作为开源工具，支持 FAIR data 兼容性，推动未来计算时代的创新。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "22 pages, 10 figures, 2MB PDF",
      "pdf_url": "http://arxiv.org/pdf/2401.10603v1",
      "published_date": "2024-01-19 10:21:27 UTC",
      "updated_date": "2024-01-19 10:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:56:02.428691"
    },
    {
      "arxiv_id": "2401.10589v1",
      "title": "Rethinking the Soft Conflict Pseudo Boolean Constraint on MaxSAT Local Search Solvers",
      "title_zh": "重新思考 MaxSAT 局部搜索求解器中的软冲突伪布尔约束",
      "authors": [
        "Jiongzhi Zheng",
        "Zhuo Chen",
        "Chu-Min Li",
        "Kun He"
      ],
      "abstract": "MaxSAT is an optimization version of the famous NP-complete Satisfiability\nproblem (SAT). Algorithms for MaxSAT mainly include complete solvers and local\nsearch incomplete solvers. In many complete solvers, once a better solution is\nfound, a Soft conflict Pseudo Boolean (SPB) constraint will be generated to\nenforce the algorithm to find better solutions. In many local search\nalgorithms, clause weighting is a key technique for effectively guiding the\nsearch directions. In this paper, we propose to transfer the SPB constraint\ninto the clause weighting system of the local search method, leading the\nalgorithm to better solutions. We further propose an adaptive clause weighting\nstrategy that breaks the tradition of using constant values to adjust clause\nweights. Based on the above methods, we propose a new local search algorithm\ncalled SPB-MaxSAT that provides new perspectives for clause weighting on MaxSAT\nlocal search solvers. Extensive experiments demonstrate the excellent\nperformance of the proposed methods.",
      "tldr_zh": "本论文重新审视了 Soft Conflict Pseudo Boolean (SPB) 约束在 MaxSAT 局部搜索求解器中的作用，提出将 SPB 约束整合到从句加权系统中，以更有效地引导搜索方向。论文进一步引入了一种自适应从句加权策略，取代传统常量值调整方法，提升算法的优化能力。最终，基于这些创新，开发了新的局部搜索算法 SPB-MaxSAT，并通过广泛实验证明了其在 MaxSAT 问题求解中的优异性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10589v1",
      "published_date": "2024-01-19 09:59:02 UTC",
      "updated_date": "2024-01-19 09:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:56:14.244954"
    },
    {
      "arxiv_id": "2401.10586v1",
      "title": "PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Ping Guo",
        "Zhiyuan Yang",
        "Xi Lin",
        "Qingchuan Zhao",
        "Qingfu Zhang"
      ],
      "abstract": "Black-box query-based attacks constitute significant threats to Machine\nLearning as a Service (MLaaS) systems since they can generate adversarial\nexamples without accessing the target model's architecture and parameters.\nTraditional defense mechanisms, such as adversarial training, gradient masking,\nand input transformations, either impose substantial computational costs or\ncompromise the test accuracy of non-adversarial inputs. To address these\nchallenges, we propose an efficient defense mechanism, PuriDefense, that\nemploys random patch-wise purifications with an ensemble of lightweight\npurification models at a low level of inference cost. These models leverage the\nlocal implicit function and rebuild the natural image manifold. Our theoretical\nanalysis suggests that this approach slows down the convergence of query-based\nattacks by incorporating randomness into purifications. Extensive experiments\non CIFAR-10 and ImageNet validate the effectiveness of our proposed\npurifier-based defense mechanism, demonstrating significant improvements in\nrobustness against query-based attacks.",
      "tldr_zh": "该研究针对黑-box query-based attacks 对机器学习即服务（MLaaS）系统的威胁，提出了一种高效防御机制 PuriDefense，利用随机补丁式净化和一组轻量级净化模型来重建自然图像流形，从而降低防御的计算成本并维持非对抗输入的准确率。PuriDefense 通过引入随机性来减缓攻击的收敛速度，其理论分析证明了这一机制的有效性。在 CIFAR-10 和 ImageNet 数据集上的广泛实验显示，该方法显著提高了模型对查询攻击的鲁棒性，证明了其在实际应用中的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10586v1",
      "published_date": "2024-01-19 09:54:23 UTC",
      "updated_date": "2024-01-19 09:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:56:26.265884"
    },
    {
      "arxiv_id": "2401.10568v2",
      "title": "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Qi",
        "Shuo Chen",
        "Yexin Li",
        "Xiangyu Kong",
        "Junqi Wang",
        "Bangcheng Yang",
        "Pring Wong",
        "Yifan Zhong",
        "Xiaoyuan Zhang",
        "Zhaowei Zhang",
        "Nian Liu",
        "Wei Wang",
        "Yaodong Yang",
        "Song-Chun Zhu"
      ],
      "abstract": "The generalization of decision-making agents encompasses two fundamental\nelements: learning from past experiences and reasoning in novel contexts.\nHowever, the predominant emphasis in most interactive environments is on\nlearning, often at the expense of complexity in reasoning. In this paper, we\nintroduce CivRealm, an environment inspired by the Civilization game.\nCivilization's profound alignment with human history and society necessitates\nsophisticated learning, while its ever-changing situations demand strong\nreasoning to generalize. Particularly, CivRealm sets up an\nimperfect-information general-sum game with a changing number of players; it\npresents a plethora of complex features, challenging the agent to deal with\nopen-ended stochastic environments that require diplomacy and negotiation\nskills. Within CivRealm, we provide interfaces for two typical agent types:\ntensor-based agents that focus on learning, and language-based agents that\nemphasize reasoning. To catalyze further research, we present initial results\nfor both paradigms. The canonical RL-based agents exhibit reasonable\nperformance in mini-games, whereas both RL- and LLM-based agents struggle to\nmake substantial progress in the full game. Overall, CivRealm stands as a\nunique learning and reasoning challenge for decision-making agents. The code is\navailable at https://github.com/bigai-ai/civrealm.",
      "tldr_zh": "该论文引入了 CivRealm，这是一个受 Civilization 游戏启发的交互环境，旨在测试决策代理的学习和推理能力，强调两者在泛化中的平衡。CivRealm 模拟人类历史和社会，设置了一个不完美信息、general-sum 游戏，涉及玩家数量变化、随机性和外交谈判等复杂特征。研究提供了 tensor-based agents（注重学习）和 language-based agents（注重推理）的接口，并展示了初步实验结果：RL-based agents 在小游戏中表现合理，但所有代理在完整游戏中均难以取得实质进展，从而为决策代理的泛化研究提供了一个独特挑战。代码开源于 https://github.com/bigai-ai/civrealm。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10568v2",
      "published_date": "2024-01-19 09:14:11 UTC",
      "updated_date": "2024-03-12 08:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:56:38.304157"
    },
    {
      "arxiv_id": "2401.10559v1",
      "title": "OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy",
      "title_zh": "翻译失败",
      "authors": [
        "Haowen Wang",
        "Tao Sun",
        "Kaixiang Ji",
        "Jian Wang",
        "Cong Fan",
        "Jinjie Gu"
      ],
      "abstract": "We advance the field of Parameter-Efficient Fine-Tuning (PEFT) with our novel\nmulti-adapter method, OrchMoE, which capitalizes on modular skill architecture\nfor enhanced forward transfer in neural networks. Unlike prior models that\ndepend on explicit task identification inputs, OrchMoE automatically discerns\ntask categories, streamlining the learning process. This is achieved through an\nintegrated mechanism comprising an Automatic Task Classification module and a\nTask-Skill Allocation module, which collectively deduce task-specific\nclassifications and tailor skill allocation matrices. Our extensive evaluations\non the 'Super Natural Instructions' dataset, featuring 1,600 diverse\ninstructional tasks, indicate that OrchMoE substantially outperforms comparable\nmulti-adapter baselines in terms of both performance and sample utilization\nefficiency, all while operating within the same parameter constraints. These\nfindings suggest that OrchMoE offers a significant leap forward in multi-task\nlearning efficiency.",
      "tldr_zh": "该研究提出了一种高效的多适配器学习方法 OrchMoE，用于 Parameter-Efficient Fine-Tuning (PEFT)，通过模块化技能架构提升神经网络的前向转移能力。OrchMoE 不再依赖显式任务标识，而是通过 Automatic Task Classification 模块和 Task-Skill Allocation 模块自动识别任务类别并优化技能分配。实验在 'Super Natural Instructions' 数据集（包含1,600个多样化指令任务）上显示，OrchMoE 在性能和样本利用效率上显著优于其他多适配器基线，同时保持相同的参数约束，从而为多任务学习效率带来重大进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10559v1",
      "published_date": "2024-01-19 08:50:54 UTC",
      "updated_date": "2024-01-19 08:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:56:49.689463"
    },
    {
      "arxiv_id": "2401.10544v1",
      "title": "AAT: Adapting Audio Transformer for Various Acoustics Recognition Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Liang",
        "Hai Lin",
        "Shaojian Qiu",
        "Yihang Zhang"
      ],
      "abstract": "Recently, Transformers have been introduced into the field of acoustics\nrecognition. They are pre-trained on large-scale datasets using methods such as\nsupervised learning and semi-supervised learning, demonstrating robust\ngenerality--It fine-tunes easily to downstream tasks and shows more robust\nperformance. However, the predominant fine-tuning method currently used is\nstill full fine-tuning, which involves updating all parameters during training.\nThis not only incurs significant memory usage and time costs but also\ncompromises the model's generality. Other fine-tuning methods either struggle\nto address this issue or fail to achieve matching performance. Therefore, we\nconducted a comprehensive analysis of existing fine-tuning methods and proposed\nan efficient fine-tuning approach based on Adapter tuning, namely AAT. The core\nidea is to freeze the audio Transformer model and insert extra learnable\nAdapters, efficiently acquiring downstream task knowledge without compromising\nthe model's original generality. Extensive experiments have shown that our\nmethod achieves performance comparable to or even superior to full fine-tuning\nwhile optimizing only 7.118% of the parameters. It also demonstrates\nsuperiority over other fine-tuning methods.",
      "tldr_zh": "本研究针对 Transformers 在声学识别任务中的微调问题，指出现有全参数微调方法会导致高内存消耗和泛化性下降。论文提出 AAT（Adapting Audio Transformer）方法，该方法基于 Adapter tuning，通过冻结音频 Transformer 模型并插入可学习 Adapter，仅优化 7.118% 的参数，即可高效获取下游任务知识。实验结果显示，AAT 的性能与全参数微调相当甚至优于其他方法，在各种声学识别任务上表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Preprint version for ICASSP 2024, Korea",
      "pdf_url": "http://arxiv.org/pdf/2401.10544v1",
      "published_date": "2024-01-19 08:07:59 UTC",
      "updated_date": "2024-01-19 08:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:57:02.081436"
    },
    {
      "arxiv_id": "2402.06634v1",
      "title": "SocraSynth: Multi-LLM Reasoning with Conditional Statistics",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "Large language models (LLMs), while promising, face criticisms for biases,\nhallucinations, and a lack of reasoning capability. This paper introduces\nSocraSynth, a multi-LLM agent reasoning platform developed to mitigate these\nissues. SocraSynth utilizes conditional statistics and systematic context\nenhancement through continuous arguments, alongside adjustable debate\ncontentiousness levels. The platform typically involves a human moderator and\ntwo LLM agents representing opposing viewpoints on a given subject. SocraSynth\noperates in two main phases: knowledge generation and reasoning evaluation. In\nthe knowledge generation phase, the moderator defines the debate topic and\ncontentiousness level, prompting the agents to formulate supporting arguments\nfor their respective stances. The reasoning evaluation phase then employs\nSocratic reasoning and formal logic principles to appraise the quality of the\narguments presented. The dialogue concludes with the moderator adjusting the\ncontentiousness from confrontational to collaborative, gathering final,\nconciliatory remarks to aid in human reasoning and decision-making. Through\ncase studies in three distinct application domains, this paper showcases\nSocraSynth's effectiveness in fostering rigorous research, dynamic reasoning,\ncomprehensive assessment, and enhanced collaboration. This underscores the\nvalue of multi-agent interactions in leveraging LLMs for advanced knowledge\nextraction and decision-making support.",
      "tldr_zh": "本文引入 SocraSynth，一种多-LLM 代理推理平台，利用条件统计和系统上下文增强来缓解 LLMs 的偏见、幻觉和推理能力不足问题。该平台通过可调节的辩论对抗性水平，涉及人类主持人及两个代表对立观点的 LLM 代理，分为知识生成阶段（定义主题并生成论点）和推理评估阶段（采用 Socratic reasoning 和 formal logic 原则评估论点质量）。最终，SocraSynth 通过三个应用领域的案例研究，展示了其在促进严格研究、动态推理、全面评估和增强合作方面的显著有效性，从而提升了 LLMs 在知识提取和决策支持中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "1 figure, 6 tables, 6 appendices",
      "pdf_url": "http://arxiv.org/pdf/2402.06634v1",
      "published_date": "2024-01-19 07:16:21 UTC",
      "updated_date": "2024-01-19 07:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:57:14.148729"
    },
    {
      "arxiv_id": "2401.10529v2",
      "title": "Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyao Wang",
        "Yuhang Zhou",
        "Xiaoyu Liu",
        "Hongjin Lu",
        "Yuancheng Xu",
        "Feihong He",
        "Jaehong Yoon",
        "Taixi Lu",
        "Gedas Bertasius",
        "Mohit Bansal",
        "Huaxiu Yao",
        "Furong Huang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated proficiency in\nhandling a variety of visual-language tasks. However, current MLLM benchmarks\nare predominantly designed to evaluate reasoning based on static information\nabout a single image, and the ability of modern MLLMs to extrapolate from image\nsequences, which is essential for understanding our ever-changing world, has\nbeen less investigated. To address this challenge, this paper introduces\nMementos, a new benchmark designed to assess MLLMs' sequential image reasoning\nabilities. Mementos features 4,761 diverse image sequences with varying\nlengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning\nperformance. Through a careful evaluation of nine recent MLLMs on Mementos,\nincluding GPT-4V and Gemini, we find that they struggle to accurately describe\ndynamic information about given image sequences, often leading to\nhallucinations/misrepresentations of objects and their corresponding behaviors.\nOur quantitative analysis and case studies identify three key factors impacting\nMLLMs' sequential image reasoning: the correlation between object and\nbehavioral hallucinations, the influence of cooccurring behaviors, and the\ncompounding impact of behavioral hallucinations. Our dataset is available at\nhttps://github.com/umd-huang-lab/Mementos.",
      "tldr_zh": "本研究引入了 Mementos，这是一个全面基准，用于评估多模态大语言模型 (MLLMs) 在图像序列上的推理能力，填补了现有基准主要关注单一静态图像的空白。Mementos 包含 4,761 个多样化图像序列，并采用 GPT-4 辅助方法对九个最新 MLLMs（如 GPT-4V 和 Gemini）进行评估，结果显示这些模型在描述动态信息时经常出现 hallucinations/误表示。研究还识别了三个关键影响因素：对象和行为 hallucinations 的相关性、共同发生行为的干扰，以及行为 hallucinations 的累积效应，为提升 MLLMs 的顺序图像推理提供重要见解。数据集可从 https://github.com/umd-huang-lab/Mementos 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10529v2",
      "published_date": "2024-01-19 07:10:13 UTC",
      "updated_date": "2024-01-25 04:11:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:57:27.810998"
    },
    {
      "arxiv_id": "2401.10521v2",
      "title": "Cross-lingual Editing in Multilingual Language Models",
      "title_zh": "多语言语言模型中的跨语言编辑",
      "authors": [
        "Himanshu Beniwal",
        "Kowsik Nandagopan D",
        "Mayank Singh"
      ],
      "abstract": "The training of large language models (LLMs) necessitates substantial data\nand computational resources, and updating outdated LLMs entails significant\nefforts and resources. While numerous model editing techniques (METs) have\nemerged to efficiently update model outputs without retraining, their\neffectiveness in multilingual LLMs, where knowledge is stored in diverse\nlanguages, remains an underexplored research area. This research paper\nintroduces the cross-lingual model editing (\\textbf{XME}) paradigm, wherein a\nfact is edited in one language, and the subsequent update propagation is\nobserved across other languages. To investigate the XME paradigm, we conducted\nexperiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts:\n\\textit{Latin} (English, French, and Spanish) and \\textit{Indic} (Hindi,\nGujarati, and Bengali). The results reveal notable performance limitations of\nstate-of-the-art METs under the XME setting, mainly when the languages involved\nbelong to two distinct script families. These findings highlight the need for\nfurther research and development of XME techniques to address these challenges.\nFor more comprehensive information, the dataset used in this research and the\nassociated code are publicly available at the following\nURL\\url{https://github.com/lingo-iitgn/XME}.",
      "tldr_zh": "这篇论文引入了跨语言模型编辑 (XME) 范式，用于高效更新多语言大型语言模型 (LLMs) 中的事实，而无需重新训练整个模型。研究者通过实验评估了现有模型编辑技术 (METs) 在不同语言脚本（如拉丁语系的英语、法语、西班牙语和印度语系的印地语、古吉拉特语、孟加拉语）之间的传播效果，使用 BLOOM、mBERT 和 XLM-RoBERTa 模型。结果显示，METs 在 XME 设置下表现有限，尤其是跨不同脚本家族的语言时，准确性显著下降。论文强调需要进一步开发 XME 技术，并公开了相关数据集和代码以支持后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10521v2",
      "published_date": "2024-01-19 06:54:39 UTC",
      "updated_date": "2024-02-03 05:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:57:40.110094"
    },
    {
      "arxiv_id": "2401.10516v1",
      "title": "Episodic Reinforcement Learning with Expanded State-reward Space",
      "title_zh": "扩展状态-奖励空间的 Episodic 强化学习",
      "authors": [
        "Dayang Liang",
        "Yaru Zhang",
        "Yunlong Liu"
      ],
      "abstract": "Empowered by deep neural networks, deep reinforcement learning (DRL) has\ndemonstrated tremendous empirical successes in various domains, including\ngames, health care, and autonomous driving. Despite these advancements, DRL is\nstill identified as data-inefficient as effective policies demand vast numbers\nof environmental samples. Recently, episodic control (EC)-based model-free DRL\nmethods enable sample efficiency by recalling past experiences from episodic\nmemory. However, existing EC-based methods suffer from the limitation of\npotential misalignment between the state and reward spaces for neglecting the\nutilization of (past) retrieval states with extensive information, which\nprobably causes inaccurate value estimation and degraded policy performance. To\ntackle this issue, we introduce an efficient EC-based DRL framework with\nexpanded state-reward space, where the expanded states used as the input and\nthe expanded rewards used in the training both contain historical and current\ninformation. To be specific, we reuse the historical states retrieved by EC as\npart of the input states and integrate the retrieved MC-returns into the\nimmediate reward in each interactive transition. As a result, our method is\nable to simultaneously achieve the full utilization of retrieval information\nand the better evaluation of state values by a Temporal Difference (TD) loss.\nEmpirical results on challenging Box2d and Mujoco tasks demonstrate the\nsuperiority of our method over a recent sibling method and common baselines.\nFurther, we also verify our method's effectiveness in alleviating Q-value\noverestimation by additional experiments of Q-value comparison.",
      "tldr_zh": "该论文针对深度强化学习(DRL)的样本效率问题，提出了一种基于Episodic Control (EC)的框架，通过扩展状态-奖励空间来解决现有方法忽略历史信息导致的价值估计不准确问题。具体而言，该框架将历史状态作为输入的一部分，并将检索到的Monte Carlo (MC) returns整合到即时奖励中，使用Temporal Difference (TD)损失实现更精确的状态值评估。实验结果显示，该方法在Box2d和Mujoco任务上优于现有基线，提升了政策性能，并有效缓解了Q-value过估计问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAMAS'24",
      "pdf_url": "http://arxiv.org/pdf/2401.10516v1",
      "published_date": "2024-01-19 06:14:36 UTC",
      "updated_date": "2024-01-19 06:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:57:50.225919"
    },
    {
      "arxiv_id": "2401.10510v3",
      "title": "When Large Language Models Meet Evolutionary Algorithms: Potential Enhancements and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Wang",
        "Jiaxuan Zhao",
        "Licheng Jiao",
        "Lingling Li",
        "Fang Liu",
        "Shuyuan Yang"
      ],
      "abstract": "Pre-trained large language models (LLMs) exhibit powerful capabilities for\ngenerating natural text. Evolutionary algorithms (EAs) can discover diverse\nsolutions to complex real-world problems. Motivated by the common collective\nand directionality of text generation and evolution, this paper first\nillustrates the conceptual parallels between LLMs and EAs at a micro level,\nwhich includes multiple one-to-one key characteristics: token representation\nand individual representation, position encoding and fitness shaping, position\nembedding and selection, Transformers block and reproduction, and model\ntraining and parameter adaptation. These parallels highlight potential\nopportunities for technical advancements in both LLMs and EAs. Subsequently, we\nanalyze existing interdisciplinary research from a macro perspective to uncover\ncritical challenges, with a particular focus on evolutionary fine-tuning and\nLLM-enhanced EAs. These analyses not only provide insights into the\nevolutionary mechanisms behind LLMs but also offer potential directions for\nenhancing the capabilities of artificial agents.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）和进化算法（EAs）之间的概念相似性，强调了二者在微观层面的一对一对应特性，如 token representation 与 individual representation、position encoding 与 fitness shaping等。这些平行关系为LLMs和EAs的技术进步提供了潜在机会，包括改进模型训练和参数适应。论文从宏观角度分析了现有的跨学科研究，聚焦于evolutionary fine-tuning和LLM-enhanced EAs，揭示了关键挑战。总体上，该研究为理解LLMs的进化机制并提升人工智能代理能力提供了宝贵洞见。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "The article has been accepted for publication in Research",
      "pdf_url": "http://arxiv.org/pdf/2401.10510v3",
      "published_date": "2024-01-19 05:58:30 UTC",
      "updated_date": "2025-03-07 05:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:58:02.438486"
    },
    {
      "arxiv_id": "2401.10956v1",
      "title": "AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment",
      "title_zh": "翻译失败",
      "authors": [
        "Sida Peng",
        "Wojciech Swiatek",
        "Allen Gao",
        "Paul Cullivan",
        "Haoge Chang"
      ],
      "abstract": "In recent years, generative AI has undergone major advancements,\ndemonstrating significant promise in augmenting human productivity. Notably,\nlarge language models (LLM), with ChatGPT-4 as an example, have drawn\nconsiderable attention. Numerous articles have examined the impact of LLM-based\ntools on human productivity in lab settings and designed tasks or in\nobservational studies. Despite recent advances, field experiments applying\nLLM-based tools in realistic settings are limited. This paper presents the\nfindings of a field randomized controlled trial assessing the effectiveness of\nLLM-based tools in providing unmonitored support services for information\nretrieval.",
      "tldr_zh": "近年来，生成式 AI 尤其是大型语言模型 (LLM) 如 ChatGPT-4，已显示出显著提升人类生产力的潜力，但实地实验仍较为有限。  \n本文通过一个实地随机对照试验 (randomized controlled trial)，评估了 LLM 工具在提供不受监控的信息检索支持服务方面的有效性。  \n研究结果填补了实验室和观察性研究的空白，为 AI 在真实场景中革命性应用提供了实证证据。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10956v1",
      "published_date": "2024-01-19 05:54:35 UTC",
      "updated_date": "2024-01-19 05:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:58:15.655771"
    },
    {
      "arxiv_id": "2401.10506v1",
      "title": "FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Zhang",
        "Yuren Mao",
        "Yijiang Fan",
        "Yu Mi",
        "Yunjun Gao",
        "Lu Chen",
        "Dongfang Lou",
        "Jinshu Lin"
      ],
      "abstract": "Text-to-SQL, which provides zero-code interface for operating relational\ndatabases, has gained much attention in financial analysis; because, financial\nprofessionals may not well-skilled in SQL programming. However, until now,\nthere is no practical Text-to-SQL benchmark dataset for financial analysis, and\nexisting Text-to-SQL methods have not considered the unique characteristics of\ndatabases in financial applications, such as commonly existing wide tables. To\naddress these issues, we collect a practical Text-to-SQL benchmark dataset and\npropose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL\nframework for financial analysis. The benchmark dataset, BULL, is collected\nfrom the practical financial analysis business of Hundsun Technologies Inc.,\nincluding databases for fund, stock, and macro economy. Besides, the proposed\nLLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for\nfinancial Text-to-SQL from the perspectives of prompt construction,\nparameter-efficient fine-tuning and output calibration. Extensive experimental\nresults on BULL demonstrate that FinSQL achieves the state-of-the-art\nText-to-SQL performance at a small cost; furthermore, FinSQL can bring up to\n36.64% performance improvement in scenarios requiring few-shot cross-database\nmodel transfer.",
      "tldr_zh": "该研究针对金融分析中的Text-to-SQL问题，提出一个模型无关的基于Large Language Models (LLMs)的框架FinSQL，以解决现有方法忽略金融数据库特性的不足，如宽表结构。研究者首先构建了新的基准数据集BULL，从Hundsun Technologies Inc.的实际业务中收集基金、股票和宏观经济相关数据。FinSQL框架通过提示构建、参数高效微调和输出校准等系统方法，提升了Text-to-SQL的准确性。实验结果显示，FinSQL在BULL数据集上实现了最先进的性能，并在少样本跨数据库转移场景中带来高达36.64%的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10506v1",
      "published_date": "2024-01-19 05:48:07 UTC",
      "updated_date": "2024-01-19 05:48:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:58:27.885753"
    },
    {
      "arxiv_id": "2401.10495v1",
      "title": "Causal Layering via Conditional Entropy",
      "title_zh": "通过条件熵的因果分层",
      "authors": [
        "Itai Feigenbaum",
        "Devansh Arpit",
        "Huan Wang",
        "Shelby Heinecke",
        "Juan Carlos Niebles",
        "Weiran Yao",
        "Caiming Xiong",
        "Silvio Savarese"
      ],
      "abstract": "Causal discovery aims to recover information about an unobserved causal graph\nfrom the observable data it generates. Layerings are orderings of the variables\nwhich place causes before effects. In this paper, we provide ways to recover\nlayerings of a graph by accessing the data via a conditional entropy oracle,\nwhen distributions are discrete. Our algorithms work by repeatedly removing\nsources or sinks from the graph. Under appropriate assumptions and\nconditioning, we can separate the sources or sinks from the remainder of the\nnodes by comparing their conditional entropy to the unconditional entropy of\ntheir noise. Our algorithms are provably correct and run in worst-case\nquadratic time. The main assumptions are faithfulness and injective noise, and\neither known noise entropies or weakly monotonically increasing noise entropies\nalong directed paths. In addition, we require one of either a very mild\nextension of faithfulness, or strictly monotonically increasing noise\nentropies, or expanding noise injectivity to include an additional single\nargument in the structural functions.",
      "tldr_zh": "这篇论文探讨了因果发现（Causal Discovery），旨在通过条件熵（Conditional Entropy）预言机从离散分布的数据中恢复因果图（Causal Graph）的层级顺序（Layerings），将原因变量置于结果变量之前。算法通过反复移除源节点（Sources）或汇节点（Sinks），并通过比较这些节点的条件熵与噪声的无条件熵来实现分离，主要假设包括忠实性（Faithfulness）、注入噪声（Injective Noise）以及噪声熵的已知或弱单调增加特性。论文证明了算法的正确性，并在最坏情况下运行时间为二次方，同时额外要求忠实性的轻微扩展或严格单调增加的噪声熵，以确保鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10495v1",
      "published_date": "2024-01-19 05:18:28 UTC",
      "updated_date": "2024-01-19 05:18:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:58:39.879942"
    },
    {
      "arxiv_id": "2401.10484v1",
      "title": "Enhancing Scalability in Recommender Systems through Lottery Ticket Hypothesis and Knowledge Distillation-based Neural Network Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Rajaram R",
        "Manoj Bharadhwaj",
        "Vasan VS",
        "Nargis Pervin"
      ],
      "abstract": "This study introduces an innovative approach aimed at the efficient pruning\nof neural networks, with a particular focus on their deployment on edge\ndevices. Our method involves the integration of the Lottery Ticket Hypothesis\n(LTH) with the Knowledge Distillation (KD) framework, resulting in the\nformulation of three distinct pruning models. These models have been developed\nto address scalability issue in recommender systems, whereby the complexities\nof deep learning models have hindered their practical deployment. With\njudicious application of the pruning techniques, we effectively curtail the\npower consumption and model dimensions without compromising on accuracy.\nEmpirical evaluation has been performed using two real world datasets from\ndiverse domains against two baselines. Gratifyingly, our approaches yielded a\nGPU computation-power reduction of up to 66.67%. Notably, our study contributes\nto the field of recommendation system by pioneering the application of LTH and\nKD.",
      "tldr_zh": "本研究提出了一种创新方法，通过整合Lottery Ticket Hypothesis (LTH)和Knowledge Distillation (KD)框架，开发出三种神经网络剪枝模型，以提升推荐系统的可扩展性。该方法针对深度学习模型的复杂性问题，实现了功耗和模型尺寸的显著减少，同时保持了准确性不变。在两个真实世界数据集上的实证评估中，与基线模型相比，该方法将GPU计算功耗降低了高达66.67%。这项工作首次将LTH和KD应用于推荐系统，为其在边缘设备上的部署提供了高效解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted in WITS 2023 as a workshop paper",
      "pdf_url": "http://arxiv.org/pdf/2401.10484v1",
      "published_date": "2024-01-19 04:17:50 UTC",
      "updated_date": "2024-01-19 04:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:58:51.359616"
    },
    {
      "arxiv_id": "2401.10480v1",
      "title": "Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Li",
        "Peiwen Yuan",
        "Shaoxiong Feng",
        "Boyuan Pan",
        "Xinglin Wang",
        "Bin Sun",
        "Heda Wang",
        "Kan Li"
      ],
      "abstract": "Self-consistency (SC) has been a widely used decoding strategy for\nchain-of-thought reasoning. Despite bringing significant performance\nimprovements across a variety of multi-step reasoning tasks, it is a high-cost\nmethod that requires multiple sampling with the preset size. In this paper, we\npropose a simple and scalable sampling process, \\textbf{E}arly-Stopping\n\\textbf{S}elf-\\textbf{C}onsistency (ESC), to greatly reduce the cost of SC\nwithout sacrificing performance. On this basis, one control scheme for ESC is\nfurther derivated to dynamically choose the performance-cost balance for\ndifferent tasks and models. To demonstrate ESC's effectiveness, we conducted\nextensive experiments on three popular categories of reasoning tasks:\narithmetic, commonsense and symbolic reasoning over language models with\nvarying scales. The empirical results show that ESC reduces the average number\nof sampling of chain-of-thought reasoning by a significant margin on six\nbenchmarks, including MATH (-33.8%), GSM8K (-80.1%), StrategyQA (-76.8%),\nCommonsenseQA (-78.5%), Coin Flip (-84.2%) and Last Letters (-67.4%), while\nattaining comparable performances.",
      "tldr_zh": "本文提出 Early-Stopping Self-Consistency (ESC)，一种简单可扩展的方法，用于减少 Self-consistency (SC) 在链式思维推理中的高采样成本，同时保持性能不变。ESC 通过早停机制动态控制采样过程，并衍生出控制方案以适应不同任务和模型的需求。在算术、常识和符号推理任务的实验中，ESC 在多个基准上大幅降低了采样次数（如 MATH 减少33.8%、GSM8K 减少80.1%），而性能与原方法相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10480v1",
      "published_date": "2024-01-19 04:03:59 UTC",
      "updated_date": "2024-01-19 04:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:59:02.342992"
    },
    {
      "arxiv_id": "2401.10474v2",
      "title": "LDReg: Local Dimensionality Regularized Self-Supervised Learning",
      "title_zh": "LDReg：局部维度正则化自监督学习",
      "authors": [
        "Hanxun Huang",
        "Ricardo J. G. B. Campello",
        "Sarah Monazam Erfani",
        "Xingjun Ma",
        "Michael E. Houle",
        "James Bailey"
      ],
      "abstract": "Representations learned via self-supervised learning (SSL) can be susceptible\nto dimensional collapse, where the learned representation subspace is of\nextremely low dimensionality and thus fails to represent the full data\ndistribution and modalities. Dimensional collapse also known as the\n\"underfilling\" phenomenon is one of the major causes of degraded performance on\ndownstream tasks. Previous work has investigated the dimensional collapse\nproblem of SSL at a global level. In this paper, we demonstrate that\nrepresentations can span over high dimensional space globally, but collapse\nlocally. To address this, we propose a method called $\\textit{local\ndimensionality regularization (LDReg)}$. Our formulation is based on the\nderivation of the Fisher-Rao metric to compare and optimize local distance\ndistributions at an asymptotically small radius for each data point. By\nincreasing the local intrinsic dimensionality, we demonstrate through a range\nof experiments that LDReg improves the representation quality of SSL. The\nresults also show that LDReg can regularize dimensionality at both local and\nglobal levels.",
      "tldr_zh": "自监督学习 (SSL) 中，维度坍缩问题可能导致表示子空间在局部上坍缩，尽管全局维度较高，从而影响下游任务性能。论文提出了一种名为 LDReg 的局部维度正则化方法，该方法基于 Fisher-Rao 度量推导，优化每个数据点的局部距离分布，以增加局部内在维度。实验结果显示，LDReg 显著提高了 SSL 的表示质量，并在局部和全局层面有效正则化了维度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.10474v2",
      "published_date": "2024-01-19 03:50:19 UTC",
      "updated_date": "2024-03-14 04:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:59:14.995817"
    },
    {
      "arxiv_id": "2401.10471v5",
      "title": "DeepEdit: Knowledge Editing as Decoding with Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Wang",
        "Muhao Chen",
        "Nanyun Peng",
        "Kai-Wei Chang"
      ],
      "abstract": "How to edit the knowledge in multi-step reasoning has become the major\nchallenge in the knowledge editing (KE) of large language models (LLMs). The\ndifficulty arises because the hallucinations of LLMs during multi-step\nreasoning often lead to incorrect use of new knowledge and incorrect answers.\nTo address this issue, we design decoding constraints to \"regulate\" LLMs'\nreasoning, enhancing logical coherence when incorporating new knowledge. We\npropose a new KE framework: DEEPEDIT (Depth-first Search-based Constrained\nDecoding for Knowledge Editing), which enhances LLMs's ability to generate\ncoherent reasoning chains with new knowledge through depth-first search. Our\nsearch selects the most important knowledge that satisfies our constraints as\nthe reasoning step to efficiently increase the reasoning depth. In addition to\nDEEPEDIT, we propose two new KE benchmarks: MQUAKE-2002 and MQUAKE-HARD, which\nprovide more precise and challenging assessments of KE approaches.\nQualitatively, DEEPEDIT enables LLMs to produce succinct and coherent reasoning\nchains involving new knowledge. Quantitatively, it yields significant\nimprovements on multiple KE benchmarks.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在知识编辑（KE）中的多步推理挑战，提出DeepEdit框架，通过设计解码约束来调节模型的推理过程，提高逻辑连贯性和新知识的正确整合。DeepEdit采用深度优先搜索（Depth-first Search）来选择满足约束的最重要知识作为推理步骤，从而高效提升推理深度。论文还引入了两个新基准MQUAKE-2002和MQUAKE-HARD，用于更精确的KE评估，并在实验中实现了显著性能改进，包括生成简洁连贯的推理链和在多个基准上的定量提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10471v5",
      "published_date": "2024-01-19 03:48:27 UTC",
      "updated_date": "2024-11-09 03:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:59:27.541012"
    },
    {
      "arxiv_id": "2401.10467v2",
      "title": "Learning Backdoors for Mixed Integer Linear Programs with Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junyang Cai",
        "Taoan Huang",
        "Bistra Dilkina"
      ],
      "abstract": "Many real-world problems can be efficiently modeled as Mixed Integer Linear\nPrograms (MILPs) and solved with the Branch-and-Bound method. Prior work has\nshown the existence of MILP backdoors, small sets of variables such that\nprioritizing branching on them when possible leads to faster running times.\nHowever, finding high-quality backdoors that improve running times remains an\nopen question. Previous work learns to estimate the relative solver speed of\nrandomly sampled backdoors through ranking and then decide whether to use the\nhighest-ranked backdoor candidate. In this paper, we utilize the Monte-Carlo\ntree search method to collect backdoors for training, rather than relying on\nrandom sampling, and adapt a contrastive learning framework to train a Graph\nAttention Network model to predict backdoors. Our method, evaluated on several\ncommon MILP problem domains, demonstrates performance improvements over both\nGurobi and previous models.",
      "tldr_zh": "这篇论文针对 Mixed Integer Linear Programs (MILPs) 的求解问题，提出了一种新方法来学习 backdoors，即变量的小集合，以优先分支并加速 Branch-and-Bound 过程。作者使用 Monte-Carlo tree search 方法收集 backdoors 数据，并通过 contrastive learning 框架训练一个 Graph Attention Network (GAT) 模型来预测高质量 backdoors。实验在多个常见的 MILP 问题领域上评估，结果显示该方法比 Gurobi 和现有模型表现出显著性能提升。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10467v2",
      "published_date": "2024-01-19 03:39:43 UTC",
      "updated_date": "2024-08-01 01:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:59:39.736889"
    },
    {
      "arxiv_id": "2401.10463v3",
      "title": "Critical Data Size of Language Models from a Grokking Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Xuekai Zhu",
        "Yao Fu",
        "Bowen Zhou",
        "Zhouhan Lin"
      ],
      "abstract": "We explore the critical data size in language models, a threshold that marks\na fundamental shift from quick memorization to slow generalization. We\nformalize the phase transition under the grokking configuration into the Data\nEfficiency Hypothesis and identify data insufficiency, sufficiency, and surplus\nregimes in language models training dynamics. We develop a grokking\nconfiguration to reproduce grokking on simplistic language models stably by\nrescaling initialization and weight decay. We show that generalization occurs\nonly when language models reach a critical size. We analyze grokking across\nsample-wise and model-wise, verifying the proposed data efficiency hypothesis.\nOur experiments reveal smoother phase transitions occurring at the critical\ndataset size for language datasets. As the model size increases, this critical\npoint also becomes larger, indicating that larger models require more data. Our\nresults deepen the understanding of language model training, offering a novel\nperspective on the role of data in the learning mechanism of language models.",
      "tldr_zh": "本文从 grokking 的视角探讨语言模型的关键数据规模（critical data size），提出 Data Efficiency Hypothesis，并将模型训练动态分为数据不足、充足和过剩三种状态。研究者开发了一种 grokking 配置，通过调整初始化和权重衰减，在简单语言模型上稳定重现 grokking 现象，并验证了泛化仅在模型达到特定规模时发生。实验结果显示，随着模型规模增加，关键数据规模也变大，且相变过程在语言数据集上更平滑，这为理解语言模型的学习机制提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10463v3",
      "published_date": "2024-01-19 03:24:36 UTC",
      "updated_date": "2024-05-23 03:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:59:51.861274"
    },
    {
      "arxiv_id": "2401.10447v1",
      "title": "Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Yu",
        "Chao-Han Huck Yang",
        "Tuan Dinh",
        "Sungho Ryu",
        "Jari Kolehmainen",
        "Roger Ren",
        "Denis Filimonov",
        "Prashanth G. Shivakumar",
        "Ankur Gandhe",
        "Ariya Rastow",
        "Jia Xu",
        "Ivan Bulyko",
        "Andreas Stolcke"
      ],
      "abstract": "The use of low-rank adaptation (LoRA) with frozen pretrained language models\n(PLMs) has become increasing popular as a mainstream, resource-efficient\nmodeling approach for memory-constrained hardware. In this study, we first\nexplore how to enhance model performance by introducing various LoRA training\nstrategies, achieving relative word error rate reductions of 3.50\\% on the\npublic Librispeech dataset and of 3.67\\% on an internal dataset in the\nmessaging domain. To further characterize the stability of LoRA-based\nsecond-pass speech recognition models, we examine robustness against input\nperturbations. These perturbations are rooted in homophone replacements and a\nnovel metric called N-best Perturbation-based Rescoring Robustness (NPRR), both\ndesigned to measure the relative degradation in the performance of rescoring\nmodels. Our experimental results indicate that while advanced variants of LoRA,\nsuch as dynamic rank-allocated LoRA, lead to performance degradation in\n$1$-best perturbation, they alleviate the degradation in $N$-best perturbation.\nThis finding is in comparison to fully-tuned models and vanilla LoRA tuning\nbaselines, suggesting that a comprehensive selection is needed when using\nLoRA-based adaptation for compute-cost savings and robust language modeling.",
      "tldr_zh": "本文研究了低秩适配 (LoRA) 在语音识别中的训练策略和模型鲁棒性，通过结合冻结预训练语言模型 (PLMs) 的方法，实现了在 Librispeech 数据集上 3.50% 和内部数据集上 3.67% 的相对词错误率减少。研究引入了输入扰动测试，如同音词替换和新型指标 N-best Perturbation-based Rescoring Robustness (NPRR)，评估了 LoRA 模型的稳定性。结果显示，高级 LoRA 变体（如动态秩分配 LoRA）在 N-best 扰动下减轻了性能下降，但需与完全微调模型和 vanilla LoRA 相比，选择合适的策略以平衡计算成本节约和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10447v1",
      "published_date": "2024-01-19 01:30:16 UTC",
      "updated_date": "2024-01-19 01:30:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:00:06.693087"
    },
    {
      "arxiv_id": "2401.10446v1",
      "title": "Large Language Models are Efficient Learners of Noise-Robust Speech Recognition",
      "title_zh": "大语言模型是噪声鲁棒语音识别的高效学习者",
      "authors": [
        "Yuchen Hu",
        "Chen Chen",
        "Chao-Han Huck Yang",
        "Ruizhe Li",
        "Chao Zhang",
        "Pin-Yu Chen",
        "EnSiong Chng"
      ],
      "abstract": "Recent advances in large language models (LLMs) have promoted generative\nerror correction (GER) for automatic speech recognition (ASR), which leverages\nthe rich linguistic knowledge and powerful reasoning ability of LLMs to improve\nrecognition results. The latest work proposes a GER benchmark with HyPoradise\ndataset to learn the mapping from ASR N-best hypotheses to ground-truth\ntranscription by efficient LLM finetuning, which shows great effectiveness but\nlacks specificity on noise-robust ASR. In this work, we extend the benchmark to\nnoisy conditions and investigate if we can teach LLMs to perform denoising for\nGER just like what robust ASR do}, where one solution is introducing noise\ninformation as a conditioner into LLM. However, directly incorporating noise\nembeddings from audio encoder could harm the LLM tuning due to cross-modality\ngap. To this end, we propose to extract a language-space noise embedding from\nthe N-best list to represent the noise conditions of source speech, which can\npromote the denoising process in GER. Furthermore, in order to enhance its\nrepresentation ability of audio noise, we design a knowledge distillation (KD)\napproach via mutual information estimation to distill the real noise\ninformation in audio embeddings to our language embedding. Experiments on\nvarious latest LLMs demonstrate our approach achieves a new breakthrough with\nup to 53.9% correction improvement in terms of word error rate while with\nlimited training data. Analysis shows that our language-space noise embedding\ncan well represent the noise conditions of source speech, under which\noff-the-shelf LLMs show strong ability of language-space denoising.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在噪声鲁棒语音识别 (ASR) 中的高效学习能力，通过生成错误修正 (GER) 方法扩展到嘈杂环境。研究提出从 ASR N-best 假设列表中提取语言空间噪声嵌入，并使用知识蒸馏 (KD) 通过互信息估计，将音频噪声信息蒸馏到该嵌入中，以提升去噪效果。实验在多种最新 LLMs 上显示，这种方法仅用有限训练数据就实现了高达 53.9% 的单词错误率修正改善，并证明 LLMs 能有效在语言空间进行去噪。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2024, Spotlight top 5%, 24 pages. This work will be\n  open sourced at: https://github.com/YUCHEN005/RobustGER under MIT license",
      "pdf_url": "http://arxiv.org/pdf/2401.10446v1",
      "published_date": "2024-01-19 01:29:27 UTC",
      "updated_date": "2024-01-19 01:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:00:16.862897"
    },
    {
      "arxiv_id": "2401.10444v1",
      "title": "Can A Cognitive Architecture Fundamentally Enhance LLMs? Or Vice Versa?",
      "title_zh": "认知架构能否根本增强 LLMs？抑或反之亦然？",
      "authors": [
        "Ron Sun"
      ],
      "abstract": "The paper discusses what is needed to address the limitations of current\nLLM-centered AI systems. The paper argues that incorporating insights from\nhuman cognition and psychology, as embodied by a computational cognitive\narchitecture, can help develop systems that are more capable, more reliable,\nand more human-like. It emphasizes the importance of the dual-process\narchitecture and the hybrid neuro-symbolic approach in addressing the\nlimitations of current LLMs. In the opposite direction, the paper also\nhighlights the need for an overhaul of computational cognitive architectures to\nbetter reflect advances in AI and computing technology. Overall, the paper\nadvocates for a multidisciplinary, mutually beneficial approach towards\ndeveloping better models both for AI and for understanding the human mind.",
      "tldr_zh": "这篇论文探讨了计算认知架构（cognitive architecture）是否能从根本上提升大型语言模型（LLMs）的能力，反之亦然。它认为，通过整合人类认知和心理学的见解，例如采用双重过程架构（dual-process architecture）和混合神经符号方法（hybrid neuro-symbolic approach），可以帮助开发出更强大、更可靠且更人性化的AI系统。同时，论文强调需要更新计算认知架构，以适应AI和计算技术的最新进展。总体上，它倡导一种多学科的互惠方法，来推动AI模型的改进和对人类思维的更深入理解。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10444v1",
      "published_date": "2024-01-19 01:14:45 UTC",
      "updated_date": "2024-01-19 01:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:00:28.728151"
    },
    {
      "arxiv_id": "2401.10431v1",
      "title": "Learning a Prior for Monte Carlo Search by Replaying Solutions to Combinatorial Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Tristan Cazenave"
      ],
      "abstract": "Monte Carlo Search gives excellent results in multiple difficult\ncombinatorial problems. Using a prior to perform non uniform playouts during\nthe search improves a lot the results compared to uniform playouts. Handmade\nheuristics tailored to the combinatorial problem are often used as priors. We\npropose a method to automatically compute a prior. It uses statistics on solved\nproblems. It is a simple and general method that incurs no computational cost\nat playout time and that brings large performance gains. The method is applied\nto three difficult combinatorial problems: Latin Square Completion, Kakuro, and\nInverse RNA Folding.",
      "tldr_zh": "该研究探讨了在Monte Carlo Search中，通过重放已解决组合问题的解决方案来学习一个先验(prior)，以改进非均匀模拟(playouts)的性能。传统方法依赖手工设计的启发式规则，而本方法自动利用问题统计数据，生成简单且通用的先验，在模拟时不增加计算成本。实验在Latin Square Completion、Kakuro和Inverse RNA Folding等困难组合问题上验证了该方法，能显著提升搜索性能，提供了一个高效的优化策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10431v1",
      "published_date": "2024-01-19 00:22:31 UTC",
      "updated_date": "2024-01-19 00:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:00:40.373090"
    },
    {
      "arxiv_id": "2401.10428v1",
      "title": "Understanding Learning through the Lens of Dynamical Invariants",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Ushveridze"
      ],
      "abstract": "This paper proposes a novel perspective on learning, positing it as the\npursuit of dynamical invariants -- data combinations that remain constant or\nexhibit minimal change over time as a system evolves. This concept is\nunderpinned by both informational and physical principles, rooted in the\ninherent properties of these invariants. Firstly, their stability makes them\nideal for memorization and integration into associative networks, forming the\nbasis of our knowledge structures. Secondly, the predictability of these stable\ninvariants makes them valuable sources of usable energy, quantifiable as kTln2\nper bit of accurately predicted information. This energy can be harnessed to\nexplore new transformations, rendering learning systems energetically\nautonomous and increasingly effective. Such systems are driven to continuously\nseek new data invariants as energy sources. The paper further explores several\nmeta-architectures of autonomous, self-propelled learning agents that utilize\npredictable information patterns as a source of usable energy.",
      "tldr_zh": "本论文从动态不变量（dynamical invariants）的视角重新审视学习过程，将其定义为追求那些在系统演化中保持恒定或变化最小的数据组合。基于信息和物理原则，这些不变量因其稳定性而适合用于记忆和构建关联网络，形成知识结构，同时其可预测性可转化为可用能量，每比特准确预测的信息相当于 kTln2。论文进一步指出，这种能量驱动学习系统实现能量自治和探索新变换，推动系统持续寻求新不变量；最后，探讨了利用预测信息作为能量来源的自驱动学习代理的元架构（meta-architectures）。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.10428v1",
      "published_date": "2024-01-19 00:13:44 UTC",
      "updated_date": "2024-01-19 00:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:00:52.825847"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 65,
  "processed_papers_count": 65,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T23:01:15.581421"
}