[
  {
    "arxiv_id": "2402.07051v1",
    "title": "$L^*LM$: Learning Automata from Examples using Natural Language Oracles",
    "authors": [
      "Marcell Vazquez-Chanlatte",
      "Karim Elmaaroufi",
      "Stefan J. Witwicki",
      "Sanjit A. Seshia"
    ],
    "abstract": "Expert demonstrations have proven an easy way to indirectly specify complex\ntasks. Recent algorithms even support extracting unambiguous formal\nspecifications, e.g. deterministic finite automata (DFA), from demonstrations.\nUnfortunately, these techniques are generally not sample efficient. In this\nwork, we introduce $L^*LM$, an algorithm for learning DFAs from both\ndemonstrations and natural language. Due to the expressivity of natural\nlanguage, we observe a significant improvement in the data efficiency of\nlearning DFAs from expert demonstrations. Technically, $L^*LM$ leverages large\nlanguage models to answer membership queries about the underlying task. This is\nthen combined with recent techniques for transforming learning from\ndemonstrations into a sequence of labeled example learning problems. In our\nexperiments, we observe the two modalities complement each other, yielding a\npowerful few-shot learner.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.FL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07051v1",
    "published_date": "2024-02-10 21:46:34 UTC",
    "updated_date": "2024-02-10 21:46:34 UTC"
  },
  {
    "arxiv_id": "2402.07049v1",
    "title": "A Factor Graph Model of Trust for a Collaborative Multi-Agent System",
    "authors": [
      "Behzad Akbari",
      "Mingfeng Yuan",
      "Hao Wang",
      "Haibin Zhu",
      "Jinjun Shan"
    ],
    "abstract": "In the field of Multi-Agent Systems (MAS), known for their openness,\ndynamism, and cooperative nature, the ability to trust the resources and\nservices of other agents is crucial. Trust, in this setting, is the reliance\nand confidence an agent has in the information, behaviors, intentions,\ntruthfulness, and capabilities of others within the system. Our paper\nintroduces a new graphical approach that utilizes factor graphs to represent\nthe interdependent behaviors and trustworthiness among agents. This includes\nmodeling the behavior of robots as a trajectory of actions using a Gaussian\nprocess factor graph, which accounts for smoothness, obstacle avoidance, and\ntrust-related factors. Our method for evaluating trust is decentralized and\nconsiders key interdependent sub-factors such as proximity safety, consistency,\nand cooperation. The overall system comprises a network of factor graphs that\ninteract through trust-related factors and employs a Bayesian inference method\nto dynamically assess trust-based decisions with informed consent. The\neffectiveness of this method is validated via simulations and empirical tests\nwith autonomous robots navigating unsignalized intersections.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07049v1",
    "published_date": "2024-02-10 21:44:28 UTC",
    "updated_date": "2024-02-10 21:44:28 UTC"
  },
  {
    "arxiv_id": "2402.07043v2",
    "title": "A Tale of Tails: Model Collapse as a Change of Scaling Laws",
    "authors": [
      "Elvis Dohmatob",
      "Yunzhen Feng",
      "Pu Yang",
      "Francois Charton",
      "Julia Kempe"
    ],
    "abstract": "As AI model size grows, neural scaling laws have become a crucial tool to\npredict the improvements of large models when increasing capacity and the size\nof original (human or natural) training data. Yet, the widespread use of\npopular models means that the ecosystem of online data and text will co-evolve\nto progressively contain increased amounts of synthesized data. In this paper\nwe ask: How will the scaling laws change in the inevitable regime where\nsynthetic data makes its way into the training corpus? Will future models,\nstill improve, or be doomed to degenerate up to total (model) collapse? We\ndevelop a theoretical framework of model collapse through the lens of scaling\nlaws. We discover a wide range of decay phenomena, analyzing loss of scaling,\nshifted scaling with number of generations, the ''un-learning\" of skills, and\ngrokking when mixing human and synthesized data. Our theory is validated by\nlarge-scale experiments with a transformer on an arithmetic task and text\ngeneration using the large language model Llama2.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07043v2",
    "published_date": "2024-02-10 21:06:34 UTC",
    "updated_date": "2024-05-31 12:27:52 UTC"
  },
  {
    "arxiv_id": "2402.07039v3",
    "title": "Coordinated Flaw Disclosure for AI: Beyond Security Vulnerabilities",
    "authors": [
      "Sven Cattell",
      "Avijit Ghosh",
      "Lucie-Aim√©e Kaffee"
    ],
    "abstract": "Harm reporting in Artificial Intelligence (AI) currently lacks a structured\nprocess for disclosing and addressing algorithmic flaws, relying largely on an\nad-hoc approach. This contrasts sharply with the well-established Coordinated\nVulnerability Disclosure (CVD) ecosystem in software security. While global\nefforts to establish frameworks for AI transparency and collaboration are\nunderway, the unique challenges presented by machine learning (ML) models\ndemand a specialized approach. To address this gap, we propose implementing a\nCoordinated Flaw Disclosure (CFD) framework tailored to the complexities of ML\nand AI issues. This paper reviews the evolution of ML disclosure practices,\nfrom ad hoc reporting to emerging participatory auditing methods, and compares\nthem with cybersecurity norms. Our framework introduces innovations such as\nextended model cards, dynamic scope expansion, an independent adjudication\npanel, and an automated verification process. We also outline a forthcoming\nreal-world pilot of CFD. We argue that CFD could significantly enhance public\ntrust in AI systems. By balancing organizational and community interests, CFD\naims to improve AI accountability in a rapidly evolving technological\nlandscape.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the 7th AAAI Conference on AI, Ethics, and Society (AIES)\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2402.07039v3",
    "published_date": "2024-02-10 20:39:04 UTC",
    "updated_date": "2024-07-26 13:45:36 UTC"
  },
  {
    "arxiv_id": "2402.07035v1",
    "title": "Distilling Symbolic Priors for Concept Learning into Neural Networks",
    "authors": [
      "Ioana Marinescu",
      "R. Thomas McCoy",
      "Thomas L. Griffiths"
    ],
    "abstract": "Humans can learn new concepts from a small number of examples by drawing on\ntheir inductive biases. These inductive biases have previously been captured by\nusing Bayesian models defined over symbolic hypothesis spaces. Is it possible\nto create a neural network that displays the same inductive biases? We show\nthat inductive biases that enable rapid concept learning can be instantiated in\nartificial neural networks by distilling a prior distribution from a symbolic\nBayesian model via meta-learning, an approach for extracting the common\nstructure from a set of tasks. By generating the set of tasks used in\nmeta-learning from the prior distribution of a Bayesian model, we are able to\ntransfer that prior into a neural network. We use this approach to create a\nneural network with an inductive bias towards concepts expressed as short\nlogical formulas. Analyzing results from previous behavioral experiments in\nwhich people learned logical concepts from a few examples, we find that our\nmeta-trained models are highly aligned with human performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.07035v1",
    "published_date": "2024-02-10 20:06:26 UTC",
    "updated_date": "2024-02-10 20:06:26 UTC"
  },
  {
    "arxiv_id": "2402.07033v3",
    "title": "Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models",
    "authors": [
      "Keisuke Kamahori",
      "Tian Tang",
      "Yile Gu",
      "Kan Zhu",
      "Baris Kasikci"
    ],
    "abstract": "Large Language Models (LLMs) with the Mixture-of-Experts (MoE) architectures\nhave shown promising performance on various tasks. However, due to the huge\nmodel sizes, running them in resource-constrained environments where the GPU\nmemory is not abundant is challenging. Some existing systems propose to use CPU\nresources to solve that, but they either suffer from the significant overhead\nof frequently moving data between CPU and GPU, or fail to consider distinct\ncharacteristics of CPUs and GPUs. This paper proposes Fiddler, a\nresource-efficient inference system for MoE models with limited GPU resources.\nFiddler strategically utilizes CPU and GPU resources by determining the optimal\nexecution strategy. Our evaluation shows that, unlike state-of-the-art systems\nthat optimize for specific scenarios such as single batch inference or long\nprefill, Fiddler performs better in all scenarios. Compared against different\nbaselines, Fiddler achieves 1.26 times speed up in single batch inference, 1.30\ntimes in long prefill processing, and 11.57 times in beam search inference. The\ncode of Fiddler is publicly available at https://github.com/efeslab/fiddler.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.OS"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2402.07033v3",
    "published_date": "2024-02-10 19:54:08 UTC",
    "updated_date": "2025-05-01 09:58:34 UTC"
  },
  {
    "arxiv_id": "2402.07031v2",
    "title": "Instance-Level Safety-Aware Fidelity of Synthetic Data and Its Calibration",
    "authors": [
      "Chih-Hong Cheng",
      "Paul St√∂ckel",
      "Xingyu Zhao"
    ],
    "abstract": "Modeling and calibrating the fidelity of synthetic data is paramount in\nshaping the future of safe and reliable self-driving technology by offering a\ncost-effective and scalable alternative to real-world data collection. We focus\non its role in safety-critical applications, introducing four types of\ninstance-level fidelity that go beyond mere visual input characteristics. The\naim is to ensure that applying testing on synthetic data can reveal real-world\nsafety issues, and the absence of safety-critical issues when testing under\nsynthetic data can provide a strong safety guarantee in real-world behavior. We\nsuggest an optimization method to refine the synthetic data generator, reducing\nfidelity gaps identified by deep learning components. Experiments show this\ntuning enhances the correlation between safety-critical errors in synthetic and\nreal data.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07031v2",
    "published_date": "2024-02-10 19:45:40 UTC",
    "updated_date": "2024-05-02 07:27:33 UTC"
  },
  {
    "arxiv_id": "2402.07023v1",
    "title": "Gemini Goes to Med School: Exploring the Capabilities of Multimodal Large Language Models on Medical Challenge Problems & Hallucinations",
    "authors": [
      "Ankit Pal",
      "Malaikannan Sankarasubbu"
    ],
    "abstract": "Large language models have the potential to be valuable in the healthcare\nindustry, but it's crucial to verify their safety and effectiveness through\nrigorous evaluation. For this purpose, we comprehensively evaluated both\nopen-source LLMs and Google's new multimodal LLM called Gemini across Medical\nreasoning, hallucination detection, and Medical Visual Question Answering\ntasks. While Gemini showed competence, it lagged behind state-of-the-art models\nlike MedPaLM 2 and GPT-4 in diagnostic accuracy. Additionally, Gemini achieved\nan accuracy of 61.45\\% on the medical VQA dataset, significantly lower than\nGPT-4V's score of 88\\%. Our analysis revealed that Gemini is highly susceptible\nto hallucinations, overconfidence, and knowledge gaps, which indicate risks if\ndeployed uncritically. We also performed a detailed analysis by medical subject\nand test type, providing actionable feedback for developers and clinicians. To\nmitigate risks, we applied prompting strategies that improved performance.\nAdditionally, we facilitated future research and development by releasing a\nPython module for medical LLM evaluation and establishing a dedicated\nleaderboard on Hugging Face for medical domain LLMs. Python module can be found\nat https://github.com/promptslab/RosettaEval",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint version, Under Review",
    "pdf_url": "http://arxiv.org/pdf/2402.07023v1",
    "published_date": "2024-02-10 19:08:28 UTC",
    "updated_date": "2024-02-10 19:08:28 UTC"
  },
  {
    "arxiv_id": "2402.07956v1",
    "title": "Educational data mining and learning analytics: An updated survey",
    "authors": [
      "C. Romero",
      "S. Ventura"
    ],
    "abstract": "This survey is an updated and improved version of the previous one published\nin 2013 in this journal with the title data mining in education. It reviews in\na comprehensible and very general way how Educational Data Mining and Learning\nAnalytics have been applied over educational data. In the last decade, this\nresearch area has evolved enormously and a wide range of related terms are now\nused in the bibliography such as Academic Analytics, Institutional Analytics,\nTeaching Analytics, Data-Driven Education, Data-Driven Decision-Making in\nEducation, Big Data in Education, and Educational Data Science. This paper\nprovides the current state of the art by reviewing the main publications, the\nkey milestones, the knowledge discovery cycle, the main educational\nenvironments, the specific tools, the free available datasets, the most used\nmethods, the main objectives, and the future trends in this research area.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07956v1",
    "published_date": "2024-02-10 18:48:45 UTC",
    "updated_date": "2024-02-10 18:48:45 UTC"
  },
  {
    "arxiv_id": "2402.07016v1",
    "title": "REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large Language Models",
    "authors": [
      "Yinghao Zhu",
      "Changyu Ren",
      "Shiyun Xie",
      "Shukai Liu",
      "Hangyuan Ji",
      "Zixiang Wang",
      "Tao Sun",
      "Long He",
      "Zhoujun Li",
      "Xi Zhu",
      "Chengwei Pan"
    ],
    "abstract": "The integration of multimodal Electronic Health Records (EHR) data has\nsignificantly improved clinical predictive capabilities. Leveraging clinical\nnotes and multivariate time-series EHR, existing models often lack the medical\ncontext relevent to clinical tasks, prompting the incorporation of external\nknowledge, particularly from the knowledge graph (KG). Previous approaches with\nKG knowledge have primarily focused on structured knowledge extraction,\nneglecting unstructured data modalities and semantic high dimensional medical\nknowledge. In response, we propose REALM, a Retrieval-Augmented Generation\n(RAG) driven framework to enhance multimodal EHR representations that address\nthese limitations. Firstly, we apply Large Language Model (LLM) to encode long\ncontext clinical notes and GRU model to encode time-series EHR data. Secondly,\nwe prompt LLM to extract task-relevant medical entities and match entities in\nprofessionally labeled external knowledge graph (PrimeKG) with corresponding\nmedical knowledge. By matching and aligning with clinical standards, our\nframework eliminates hallucinations and ensures consistency. Lastly, we propose\nan adaptive multimodal fusion network to integrate extracted knowledge with\nmultimodal EHR data. Our extensive experiments on MIMIC-III mortality and\nreadmission tasks showcase the superior performance of our REALM framework over\nbaselines, emphasizing the effectiveness of each module. REALM framework\ncontributes to refining the use of multimodal EHR data in healthcare and\nbridging the gap with nuanced medical context essential for informed clinical\npredictions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07016v1",
    "published_date": "2024-02-10 18:27:28 UTC",
    "updated_date": "2024-02-10 18:27:28 UTC"
  },
  {
    "arxiv_id": "2402.07011v2",
    "title": "FedImpro: Measuring and Improving Client Update in Federated Learning",
    "authors": [
      "Zhenheng Tang",
      "Yonggang Zhang",
      "Shaohuai Shi",
      "Xinmei Tian",
      "Tongliang Liu",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "abstract": "Federated Learning (FL) models often experience client drift caused by\nheterogeneous data, where the distribution of data differs across clients. To\naddress this issue, advanced research primarily focuses on manipulating the\nexisting gradients to achieve more consistent client models. In this paper, we\npresent an alternative perspective on client drift and aim to mitigate it by\ngenerating improved local models. First, we analyze the generalization\ncontribution of local training and conclude that this generalization\ncontribution is bounded by the conditional Wasserstein distance between the\ndata distribution of different clients. Then, we propose FedImpro, to construct\nsimilar conditional distributions for local training. Specifically, FedImpro\ndecouples the model into high-level and low-level components, and trains the\nhigh-level portion on reconstructed feature distributions. This approach\nenhances the generalization contribution and reduces the dissimilarity of\ngradients in FL. Experimental results show that FedImpro can help FL defend\nagainst data heterogeneity and enhance the generalization performance of the\nmodel.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07011v2",
    "published_date": "2024-02-10 18:14:57 UTC",
    "updated_date": "2024-03-14 15:45:56 UTC"
  },
  {
    "arxiv_id": "2402.14827v1",
    "title": "Optimizing Uterine Synchronization Analysis in Pregnancy and Labor through Window Selection and Node Optimization",
    "authors": [
      "Kamil Bader El Dine",
      "Noujoud Nader",
      "Mohamad Khalil",
      "Catherine Marque"
    ],
    "abstract": "Preterm labor (PL) has globally become the leading cause of death in children\nunder the age of 5 years. To address this problem, this paper will provide a\nnew approach by analyzing the EHG signals, which are recorded on the abdomen of\nthe mother during labor and pregnancy. The EHG signal reflects the electrical\nactivity that induces the mechanical contraction of the myometrium. Because\nEHGs are known to be non-stationary signals, and because we anticipate\nconnectivity to alter during contraction, we applied the windowing approach on\nreal signals to help us identify the best windows and the best nodes with the\nmost significant data to be used for classification. The suggested pipeline\nincludes i) divide the 16 EHG signals that are recorded from the abdomen of\npregnant women in N windows; ii) apply the connectivity matrices on each\nwindow; iii) apply the Graph theory-based measures on the connectivity matrices\non each window; iv) apply the consensus Matrix on each window in order to\nretrieve the best windows and the best nodes. Following that, several neural\nnetwork and machine learning methods are applied to the best windows and best\nnodes to categorize pregnancy and labor contractions, based on the different\ninput parameters (connectivity method alone, connectivity method plus graph\nparameters, best nodes, all nodes, best windows, all windows). Results showed\nthat the best nodes are nodes 8, 9, 10, 11, and 12; while the best windows are\n2, 4, and 5. The classification results obtained by using only these best nodes\nare better than when using the whole nodes. The results are always better when\nusing the full burst, whatever the chosen nodes. Thus, the windowing approach\nproved to be an innovative technique that can improve the differentiation\nbetween labor and pregnancy EHG signals.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "q-bio.QM",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14827v1",
    "published_date": "2024-02-10 17:59:12 UTC",
    "updated_date": "2024-02-10 17:59:12 UTC"
  },
  {
    "arxiv_id": "2402.07002v2",
    "title": "Clients Collaborate: Flexible Differentially Private Federated Learning with Guaranteed Improvement of Utility-Privacy Trade-off",
    "authors": [
      "Yuecheng Li",
      "Lele Fu",
      "Tong Wang",
      "Jian Lou",
      "Bin Chen",
      "Lei Yang",
      "Jian Shen",
      "Zibin Zheng",
      "Chuan Chen"
    ],
    "abstract": "To defend against privacy leakage of user data, differential privacy is\nwidely used in federated learning, but it is not free. The addition of noise\nrandomly disrupts the semantic integrity of the model and this disturbance\naccumulates with increased communication rounds. In this paper, we introduce a\nnovel federated learning framework with rigorous privacy guarantees, named\nFedCEO, designed to strike a trade-off between model utility and user privacy\nby letting clients ''Collaborate with Each Other''. Specifically, we perform\nefficient tensor low-rank proximal optimization on stacked local model\nparameters at the server, demonstrating its capability to flexibly truncate\nhigh-frequency components in spectral space. This capability implies that our\nFedCEO can effectively recover the disrupted semantic information by smoothing\nthe global semantic space for different privacy settings and continuous\ntraining processes. Moreover, we improve the SOTA utility-privacy trade-off\nbound by order of $\\sqrt{d}$, where $d$ is the input dimension. We illustrate\nour theoretical results with experiments on representative datasets and observe\nsignificant performance improvements and strict privacy guarantees under\ndifferent privacy settings. The code is available at\nhttps://github.com/6lyc/FedCEO_Collaborate-with-Each-Other.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.07002v2",
    "published_date": "2024-02-10 17:39:34 UTC",
    "updated_date": "2025-05-05 17:50:42 UTC"
  },
  {
    "arxiv_id": "2402.06992v1",
    "title": "A Rational Analysis of the Speech-to-Song Illusion",
    "authors": [
      "Raja Marjieh",
      "Pol van Rijn",
      "Ilia Sucholutsky",
      "Harin Lee",
      "Thomas L. Griffiths",
      "Nori Jacoby"
    ],
    "abstract": "The speech-to-song illusion is a robust psychological phenomenon whereby a\nspoken sentence sounds increasingly more musical as it is repeated. Despite\ndecades of research, a complete formal account of this transformation is still\nlacking, and some of its nuanced characteristics, namely, that certain phrases\nappear to transform while others do not, is not well understood. Here we\nprovide a formal account of this phenomenon, by recasting it as a statistical\ninference whereby a rational agent attempts to decide whether a sequence of\nutterances is more likely to have been produced in a song or speech. Using this\napproach and analyzing song and speech corpora, we further introduce a novel\nprose-to-lyrics illusion that is purely text-based. In this illusion, simply\nduplicating written sentences makes them appear more like song lyrics. We\nprovide robust evidence for this new illusion in both human participants and\nlarge language models.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL",
      "stat.AP"
    ],
    "primary_category": "q-bio.NC",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.06992v1",
    "published_date": "2024-02-10 16:54:28 UTC",
    "updated_date": "2024-02-10 16:54:28 UTC"
  },
  {
    "arxiv_id": "2402.06985v1",
    "title": "OSSAR: Towards Open-Set Surgical Activity Recognition in Robot-assisted Surgery",
    "authors": [
      "Long Bai",
      "Guankun Wang",
      "Jie Wang",
      "Xiaoxiao Yang",
      "Huxin Gao",
      "Xin Liang",
      "An Wang",
      "Mobarakol Islam",
      "Hongliang Ren"
    ],
    "abstract": "In the realm of automated robotic surgery and computer-assisted\ninterventions, understanding robotic surgical activities stands paramount.\nExisting algorithms dedicated to surgical activity recognition predominantly\ncater to pre-defined closed-set paradigms, ignoring the challenges of\nreal-world open-set scenarios. Such algorithms often falter in the presence of\ntest samples originating from classes unseen during training phases. To tackle\nthis problem, we introduce an innovative Open-Set Surgical Activity Recognition\n(OSSAR) framework. Our solution leverages the hyperspherical reciprocal point\nstrategy to enhance the distinction between known and unknown classes in the\nfeature space. Additionally, we address the issue of over-confidence in the\nclosed set by refining model calibration, avoiding misclassification of unknown\nclasses as known ones. To support our assertions, we establish an open-set\nsurgical activity benchmark utilizing the public JIGSAWS dataset. Besides, we\nalso collect a novel dataset on endoscopic submucosal dissection for surgical\nactivity tasks. Extensive comparisons and ablation experiments on these\ndatasets demonstrate the significant outperformance of our method over existing\nstate-of-the-art approaches. Our proposed solution can effectively address the\nchallenges of real-world surgical scenarios. Our code is publicly accessible at\nhttps://github.com/longbai1006/OSSAR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear in IEEE ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06985v1",
    "published_date": "2024-02-10 16:23:12 UTC",
    "updated_date": "2024-02-10 16:23:12 UTC"
  },
  {
    "arxiv_id": "2402.06982v1",
    "title": "Treatment-wise Glioblastoma Survival Inference with Multi-parametric Preoperative MRI",
    "authors": [
      "Xiaofeng Liu",
      "Nadya Shusharina",
      "Helen A Shih",
      "C. -C. Jay Kuo",
      "Georges El Fakhri",
      "Jonghye Woo"
    ],
    "abstract": "In this work, we aim to predict the survival time (ST) of glioblastoma (GBM)\npatients undergoing different treatments based on preoperative magnetic\nresonance (MR) scans. The personalized and precise treatment planning can be\nachieved by comparing the ST of different treatments. It is well established\nthat both the current status of the patient (as represented by the MR scans)\nand the choice of treatment are the cause of ST. While previous related\nMR-based glioblastoma ST studies have focused only on the direct mapping of MR\nscans to ST, they have not included the underlying causal relationship between\ntreatments and ST. To address this limitation, we propose a\ntreatment-conditioned regression model for glioblastoma ST that incorporates\ntreatment information in addition to MR scans. Our approach allows us to\neffectively utilize the data from all of the treatments in a unified manner,\nrather than having to train separate models for each of the treatments.\nFurthermore, treatment can be effectively injected into each convolutional\nlayer through the adaptive instance normalization we employ. We evaluate our\nframework on the BraTS20 ST prediction task. Three treatment options are\nconsidered: Gross Total Resection (GTR), Subtotal Resection (STR), and no\nresection. The evaluation results demonstrate the effectiveness of injecting\nthe treatment for estimating GBM survival.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "SPIE Medical Imaging 2024: Computer-Aided Diagnosis",
    "pdf_url": "http://arxiv.org/pdf/2402.06982v1",
    "published_date": "2024-02-10 16:13:09 UTC",
    "updated_date": "2024-02-10 16:13:09 UTC"
  },
  {
    "arxiv_id": "2402.06973v1",
    "title": "Event-Keyed Summarization",
    "authors": [
      "William Gantt",
      "Alexander Martin",
      "Pavlo Kuchmiichuk",
      "Aaron Steven White"
    ],
    "abstract": "We introduce event-keyed summarization (EKS), a novel task that marries\ntraditional summarization and document-level event extraction, with the goal of\ngenerating a contextualized summary for a specific event, given a document and\nan extracted event structure. We introduce a dataset for this task, MUCSUM,\nconsisting of summaries of all events in the classic MUC-4 dataset, along with\na set of baselines that comprises both pretrained LM standards in the\nsummarization literature, as well as larger frontier models. We show that\nablations that reduce EKS to traditional summarization or structure-to-text\nyield inferior summaries of target events and that MUCSUM is a robust benchmark\nfor this task. Lastly, we conduct a human evaluation of both reference and\nmodel summaries, and provide some detailed analysis of the results.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ARR short paper (under review)",
    "pdf_url": "http://arxiv.org/pdf/2402.06973v1",
    "published_date": "2024-02-10 15:32:53 UTC",
    "updated_date": "2024-02-10 15:32:53 UTC"
  },
  {
    "arxiv_id": "2402.06967v2",
    "title": "Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning Framework for Dialogue",
    "authors": [
      "Jian Wang",
      "Chak Tou Leong",
      "Jiashuo Wang",
      "Dongding Lin",
      "Wenjie Li",
      "Xiao-Yong Wei"
    ],
    "abstract": "Tuning language models for dialogue generation has been a prevalent paradigm\nfor building capable dialogue agents. Yet, traditional tuning narrowly views\ndialogue generation as resembling other language generation tasks, ignoring the\nrole disparities between two speakers and the multi-round interactive process\nthat dialogues ought to be. Such a manner often leads to unsatisfactory chat\nconsistency for the built agent. In this work, we emphasize the interactive,\ncommunicative nature of dialogue and argue that it is more feasible to model\nthe speaker roles of agent and user separately, enabling the agent to adhere to\nits role consistently. With this in mind, we propose an efficient Multi-round\nInteractive Dialogue Tuning (Midi-Tuning) framework. It models the agent and\nuser individually with two adapters built upon large language models. The\nadapters make use of respective utterances round by round in alternating order\nand they are tuned via a round-level memory caching mechanism. Extensive\nexperiments demonstrate that, our framework performs superior to traditional\nfine-tuning and harbors the tremendous potential for improving dialogue\nconsistency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06967v2",
    "published_date": "2024-02-10 14:52:52 UTC",
    "updated_date": "2024-05-30 04:57:36 UTC"
  },
  {
    "arxiv_id": "2402.06963v3",
    "title": "Tree Ensembles for Contextual Bandits",
    "authors": [
      "Hannes Nilsson",
      "Rikard Johansson",
      "Niklas √Ökerblom",
      "Morteza Haghir Chehreghani"
    ],
    "abstract": "We propose a new framework for contextual multi-armed bandits based on tree\nensembles. Our framework adapts two widely used bandit methods, Upper\nConfidence Bound and Thompson Sampling, for both standard and combinatorial\nsettings. As part of this framework, we propose a novel method of estimating\nthe uncertainty in tree ensemble predictions. We further demonstrate the\neffectiveness of our framework via several experimental studies, employing\nXGBoost and random forests, two popular tree ensemble methods. Compared to\nstate-of-the-art methods based on decision trees and neural networks, our\nmethods exhibit superior performance in terms of both regret minimization and\ncomputational runtime, when applied to benchmark datasets and the real-world\napplication of navigation over road networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2402.06963v3",
    "published_date": "2024-02-10 14:36:31 UTC",
    "updated_date": "2024-11-01 11:46:22 UTC"
  },
  {
    "arxiv_id": "2402.06957v1",
    "title": "Architectural Neural Backdoors from First Principles",
    "authors": [
      "Harry Langford",
      "Ilia Shumailov",
      "Yiren Zhao",
      "Robert Mullins",
      "Nicolas Papernot"
    ],
    "abstract": "While previous research backdoored neural networks by changing their\nparameters, recent work uncovered a more insidious threat: backdoors embedded\nwithin the definition of the network's architecture. This involves injecting\ncommon architectural components, such as activation functions and pooling\nlayers, to subtly introduce a backdoor behavior that persists even after (full\nre-)training. However, the full scope and implications of architectural\nbackdoors have remained largely unexplored. Bober-Irizar et al. [2023]\nintroduced the first architectural backdoor; they showed how to create a\nbackdoor for a checkerboard pattern, but never explained how to target an\narbitrary trigger pattern of choice. In this work we construct an arbitrary\ntrigger detector which can be used to backdoor an architecture with no human\nsupervision. This leads us to revisit the concept of architecture backdoors and\ntaxonomise them, describing 12 distinct types. To gauge the difficulty of\ndetecting such backdoors, we conducted a user study, revealing that ML\ndevelopers can only identify suspicious components in common model definitions\nas backdoors in 37% of cases, while they surprisingly preferred backdoored\nmodels in 33% of cases. To contextualize these results, we find that language\nmodels outperform humans at the detection of backdoors. Finally, we discuss\ndefenses against architectural backdoors, emphasizing the need for robust and\ncomprehensive strategies to safeguard the integrity of ML systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06957v1",
    "published_date": "2024-02-10 13:57:51 UTC",
    "updated_date": "2024-02-10 13:57:51 UTC"
  },
  {
    "arxiv_id": "2402.06955v3",
    "title": "Feature Mapping in Physics-Informed Neural Networks (PINNs)",
    "authors": [
      "Chengxi Zeng",
      "Tilo Burghardt",
      "Alberto M Gambaruto"
    ],
    "abstract": "In this paper, the training dynamics of PINNs with a feature mapping layer\nvia the limiting Conjugate Kernel and Neural Tangent Kernel is investigated,\nshedding light on the convergence of PINNs; Although the commonly used\nFourier-based feature mapping has achieved great success, we show its\ninadequacy in some physics scenarios. Via these two scopes, we propose\nconditionally positive definite Radial Basis Function as a better alternative.\nLastly, we explore the feature mapping numerically in wide neural networks. Our\nempirical results reveal the efficacy of our method in diverse forward and\ninverse problem sets. Composing feature functions is found to be a practical\nway to address the expressivity and generalisability trade-off, viz., tuning\nthe bandwidth of the kernels and the surjectivity of the feature mapping\nfunction. This simple technique can be implemented for coordinate inputs and\nbenefits the broader PINNs research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06955v3",
    "published_date": "2024-02-10 13:51:09 UTC",
    "updated_date": "2024-10-21 15:26:26 UTC"
  },
  {
    "arxiv_id": "2402.06952v3",
    "title": "Estimating the Effect of Crosstalk Error on Circuit Fidelity Using Noisy Intermediate-Scale Quantum Devices",
    "authors": [
      "Sovanmonynuth Heng",
      "Myeongseong Go",
      "Youngsun Han"
    ],
    "abstract": "Current advancements in technology have focused the attention of the quantum\ncomputing community toward exploring the potential of near-term devices whose\ncomputing power surpasses that of classical computers in practical\napplications. An unresolved central question revolves around whether the\ninherent noise in these devices can be overcome or whether any potential\nquantum advantage would be limited. There is no doubt that crosstalk is one of\nthe main sources of noise in noisy intermediate-scale quantum (NISQ) systems,\nand it poses a fundamental challenge to hardware designs. Crosstalk between\nparallel instructions can corrupt quantum states and cause incorrect program\nexecution. In this study, we present a necessary analysis of the crosstalk\nerror effect on NISQ devices. Our approach is extremely straightforward and\npractical to estimate the crosstalk error of various multi-qubit devices. In\nparticular, we combine the randomized benchmarking (RB) and simultaneous\nrandomized benchmarking (SRB) protocol to estimate the crosstalk error from the\ncorrelation controlled-NOT (CNOT) gate. We demonstrate this protocol\nexperimentally on 5-, 7-, \\& 16-qubit devices. Our results demonstrate the\ncrosstalk error model of three different IBM quantum devices over the\nexperimental week and compare the error variation against the machine, number\nof qubits, quantum volume, processor, and topology. We then confirm the\nimprovement in the circuit fidelity on different benchmarks by up to 3.06x via\ninserting an instruction barrier, as compared with an IBM quantum noisy device\nwhich offers near-optimal crosstalk mitigation in practice. Finally, we discuss\nthe current system limitation, its tradeoff on fidelity and depth, noise beyond\nthe NISQ system, and mitigation opportunities to ensure that the quantum\noperation can perform its quantum magic undisturbed.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "After careful consideration, we have decided to withdraw the\n  manuscript due to the need for significant revisions and a change in research\n  direction",
    "pdf_url": "http://arxiv.org/pdf/2402.06952v3",
    "published_date": "2024-02-10 13:42:14 UTC",
    "updated_date": "2024-11-05 09:23:47 UTC"
  },
  {
    "arxiv_id": "2402.06945v1",
    "title": "Evaluation Metrics for Automated Typographic Poster Generation",
    "authors": [
      "S√©rgio M. Rebelo",
      "J. J. Merelo",
      "Jo√£o Bicker",
      "Penousal Machado"
    ],
    "abstract": "Computational Design approaches facilitate the generation of typographic\ndesign, but evaluating these designs remains a challenging task. In this paper,\nwe propose a set of heuristic metrics for typographic design evaluation,\nfocusing on their legibility, which assesses the text visibility, aesthetics,\nwhich evaluates the visual quality of the design, and semantic features, which\nestimate how effectively the design conveys the content semantics. We\nexperiment with a constrained evolutionary approach for generating typographic\nposters, incorporating the proposed evaluation metrics with varied setups, and\ntreating the legibility metrics as constraints. We also integrate emotion\nrecognition to identify text semantics automatically and analyse the\nperformance of the approach and the visual characteristics outputs.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.HC",
      "68W50",
      "I.2.1; I.7; J.7; J.5"
    ],
    "primary_category": "cs.MM",
    "comment": "Paper accepted be presented in the 13th International Conference\n  Artificial Intelligence in Music, Sound, Art and Design -- EvoMUSART 2024,\n  Held as Part of EvoStar 2024, Aberystwyth, Wales, United Kingdom, April\n  3\\textendash{}5, 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06945v1",
    "published_date": "2024-02-10 13:18:10 UTC",
    "updated_date": "2024-02-10 13:18:10 UTC"
  },
  {
    "arxiv_id": "2402.06938v2",
    "title": "Efficient Resource Scheduling for Distributed Infrastructures Using Negotiation Capabilities",
    "authors": [
      "Junjie Chu",
      "Prashant Singh",
      "Salman Toor"
    ],
    "abstract": "In the past few decades, the rapid development of information and internet\ntechnologies has spawned massive amounts of data and information. The\ninformation explosion drives many enterprises or individuals to seek to rent\ncloud computing infrastructure to put their applications in the cloud. However,\nthe agreements reached between cloud computing providers and clients are often\nnot efficient. Many factors affect the efficiency, such as the idleness of the\nproviders' cloud computing infrastructure, and the additional cost to the\nclients. One possible solution is to introduce a comprehensive, bargaining game\n(a type of negotiation), and schedule resources according to the negotiation\nresults. We propose an agent-based auto-negotiation system for resource\nscheduling based on fuzzy logic. The proposed method can complete a one-to-one\nauto-negotiation process and generate optimal offers for the provider and\nclient. We compare the impact of different member functions, fuzzy rule sets,\nand negotiation scenario cases on the offers to optimize the system. It can be\nconcluded that our proposed method can utilize resources more efficiently and\nis interpretable, highly flexible, and customizable. We successfully train\nmachine learning models to replace the fuzzy negotiation system to improve\nprocessing speed. The article also highlights possible future improvements to\nthe proposed system and machine learning models. All the codes and data are\navailable in the open-source repository.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted in IEEE CLOUD 2023. 13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.06938v2",
    "published_date": "2024-02-10 12:26:20 UTC",
    "updated_date": "2024-02-13 15:58:40 UTC"
  },
  {
    "arxiv_id": "2402.06931v1",
    "title": "ORIENT: A Priority-Aware Energy-Efficient Approach for Latency-Sensitive Applications in 6G",
    "authors": [
      "Masoud Shokrnezhad",
      "Tarik Taleb"
    ],
    "abstract": "Anticipation for 6G's arrival comes with growing concerns about increased\nenergy consumption in computing and networking. The expected surge in connected\ndevices and resource-demanding applications presents unprecedented challenges\nfor energy resources. While sustainable resource allocation strategies have\nbeen discussed in the past, these efforts have primarily focused on\nsingle-domain orchestration or ignored the unique requirements posed by 6G. To\naddress this gap, we investigate the joint problem of service instance\nplacement and assignment, path selection, and request prioritization, dubbed\nPIRA. The objective function is to maximize the system's overall profit as a\nfunction of the number of concurrently supported requests while simultaneously\nminimizing energy consumption over an extended period of time. In addition,\nend-to-end latency requirements and resource capacity constraints are\nconsidered for computing and networking resources, where queuing theory is\nutilized to estimate the Age of Information (AoI) for requests. After\nformulating the problem in a non-linear fashion, we prove its NP-hardness and\npropose a method, denoted ORIENT. This method is based on the Double Dueling\nDeep Q-Learning (D3QL) mechanism and leverages Graph Neural Networks (GNNs) for\nstate encoding. Extensive numerical simulations demonstrate that ORIENT yields\nnear-optimal solutions for varying system sizes and request counts.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "Conference, 6 pages, 2 figures, 28 equations, 1 table, 1 algorithm,\n  and 16 references",
    "pdf_url": "http://arxiv.org/pdf/2402.06931v1",
    "published_date": "2024-02-10 12:05:52 UTC",
    "updated_date": "2024-02-10 12:05:52 UTC"
  },
  {
    "arxiv_id": "2402.06929v1",
    "title": "Making a prototype of Seoul historical sites chatbot using Langchain",
    "authors": [
      "Jae Young Suh",
      "Minsoo Kwak",
      "Soo Yong Kim",
      "Hyoungseo Cho"
    ],
    "abstract": "In this paper, we are going to share a draft of the development of a\nconversational agent created to disseminate information about historical sites\nlocated in the Seoul. The primary objective of the agent is to increase\nawareness among visitors who are not familiar with Seoul, about the presence\nand precise locations of valuable cultural heritage sites. It aims to promote a\nbasic understanding of Korea's rich and diverse cultural history. The agent is\nthoughtfully designed for accessibility in English and utilizes data generously\nprovided by the Seoul Metropolitan Government. Despite the limited data volume,\nit consistently delivers reliable and accurate responses, seamlessly aligning\nwith the available information. We have meticulously detailed the methodologies\nemployed in creating this agent and provided a comprehensive overview of its\nunderlying structure within the paper. Additionally, we delve into potential\nimprovements to enhance this initial version of the system, with a primary\nemphasis on expanding the available data through our prompting. In conclusion,\nwe provide an in-depth discussion of our expectations regarding the future\nimpact of this agent in promoting and facilitating the sharing of historical\nsites.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 4 figures, draft",
    "pdf_url": "http://arxiv.org/pdf/2402.06929v1",
    "published_date": "2024-02-10 11:38:09 UTC",
    "updated_date": "2024-02-10 11:38:09 UTC"
  },
  {
    "arxiv_id": "2403.08813v1",
    "title": "Federated Deep Q-Learning and 5G load balancing",
    "authors": [
      "Hsin Lin",
      "Yi-Kang Su",
      "Hong-Qi Chen",
      "La-Fei Ko"
    ],
    "abstract": "Despite advances in cellular network technology, base station (BS) load\nbalancing remains a persistent problem. Although centralized resource\nallocation methods can address the load balancing problem, it still remains an\nNP-hard problem. In this research, we study how federated deep Q learning can\nbe used to inform each user equipment (UE) of the each BS's load conditions.\nFederated deep Q learning's load balancing enables intelligent UEs to\nindependently select the best BS while also limiting the amount of private\ninformation exposed to the network.\n  In this study, we propose and analyze a federated deep Q learning load\nbalancing system, which is implemented using the Open-RAN xAPP framework and\nthe near-Real Time Radio Interface Controller (near-RT RIC). Our simulation\nresults indicate that compared to the maximum Signal-To-Noise-Ratio (MAX-SINR)\nmethod currently used by UEs, our proposed deep Q learning model can\nconsistently provide better High average UE quality of service",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.NI",
    "comment": "5 pages, in Chinese language. 8 figures. Presented at 2022 Taiwan\n  telecommunications annual symposium",
    "pdf_url": "http://arxiv.org/pdf/2403.08813v1",
    "published_date": "2024-02-10 10:34:20 UTC",
    "updated_date": "2024-02-10 10:34:20 UTC"
  },
  {
    "arxiv_id": "2402.06918v2",
    "title": "Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to Searching for the Most Promising Intermediate Thought",
    "authors": [
      "Zhen-Yu Zhang",
      "Siwei Han",
      "Huaxiu Yao",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "abstract": "To improve the ability of the large language model (LLMs) to tackle complex\nreasoning problems, chain-of-thoughts (CoT) methods were proposed to guide LLMs\nto reason step-by-step, enabling problem solving from simple to complex.\nState-of-the-art methods for generating such a chain involve interactive\ncollaboration, where the learner generates candidate intermediate thoughts,\nevaluated by the LLM, guiding the generation of subsequent thoughts. However, a\nwidespread yet understudied problem is that the evaluation from the LLM is\ntypically noisy and unreliable, potentially misleading the generation process\nin selecting promising intermediate thoughts. In this paper, motivated by\nVapnik's principle, we use pairwise-comparison evaluation instead of point-wise\nscoring to search for promising intermediate thoughts with the noisy feedback\nfrom the LLM. In each round, we randomly pair intermediate thoughts and\ndirectly prompt the LLM to select the more promising one from each pair,\nallowing us to identify the most promising thoughts through an iterative\nprocess. To further alleviate the noise in the comparison, we incorporate\ntechniques from ensemble learning and dueling bandits, proposing two variants\nof the algorithm. Experiments on three real-world tasks demonstrate the\neffectiveness of our proposed algorithm and verify the rationale of the\npairwise comparison mechanism.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06918v2",
    "published_date": "2024-02-10 09:51:03 UTC",
    "updated_date": "2024-06-26 05:47:52 UTC"
  },
  {
    "arxiv_id": "2403.07194v1",
    "title": "Improving prediction of students' performance in intelligent tutoring systems using attribute selection and ensembles of different multimodal data sources",
    "authors": [
      "W. Chango",
      "R. Cerezo",
      "M. Sanchez-Santillan",
      "R. Azevedo",
      "C. Romero"
    ],
    "abstract": "The aim of this study was to predict university students' learning\nperformance using different sources of data from an Intelligent Tutoring\nSystem. We collected and preprocessed data from 40 students from different\nmultimodal sources: learning strategies from system logs, emotions from face\nrecording videos, interaction zones from eye tracking, and test performance\nfrom final knowledge evaluation. Our objective was to test whether the\nprediction could be improved by using attribute selection and classification\nensembles. We carried out three experiments by applying six classification\nalgorithms to numerical and discretized preprocessed multimodal data. The\nresults show that the best predictions were produced using ensembles and\nselecting the best attributes approach with numerical data.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07194v1",
    "published_date": "2024-02-10 09:31:39 UTC",
    "updated_date": "2024-02-10 09:31:39 UTC"
  },
  {
    "arxiv_id": "2402.06912v2",
    "title": "Solving Deep Reinforcement Learning Tasks with Evolution Strategies and Linear Policy Networks",
    "authors": [
      "Annie Wong",
      "Jacob de Nobel",
      "Thomas B√§ck",
      "Aske Plaat",
      "Anna V. Kononova"
    ],
    "abstract": "Although deep reinforcement learning methods can learn effective policies for\nchallenging problems such as Atari games and robotics tasks, algorithms are\ncomplex, and training times are often long. This study investigates how\nEvolution Strategies perform compared to gradient-based deep reinforcement\nlearning methods. We use Evolution Strategies to optimize the weights of a\nneural network via neuroevolution, performing direct policy search. We\nbenchmark both deep policy networks and networks consisting of a single linear\nlayer from observations to actions for three gradient-based methods, such as\nProximal Policy Optimization. These methods are evaluated against three\nclassical Evolution Strategies and Augmented Random Search, which all use\nlinear policy networks. Our results reveal that Evolution Strategies can find\neffective linear policies for many reinforcement learning benchmark tasks,\nunlike deep reinforcement learning methods that can only find successful\npolicies using much larger networks, suggesting that current benchmarks are\neasier to solve than previously assumed. Interestingly, Evolution Strategies\nalso achieve results comparable to gradient-based deep reinforcement learning\nalgorithms for higher-complexity tasks. Furthermore, we find that by directly\naccessing the memory state of the game, Evolution Strategies can find\nsuccessful policies in Atari that outperform the policies found by Deep\nQ-Learning. Evolution Strategies also outperform Augmented Random Search in\nmost benchmarks, demonstrating superior sample efficiency and robustness in\ntraining linear policy networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06912v2",
    "published_date": "2024-02-10 09:15:21 UTC",
    "updated_date": "2024-07-24 17:15:44 UTC"
  },
  {
    "arxiv_id": "2402.06908v1",
    "title": "Topological Neural Networks: Mitigating the Bottlenecks of Graph Neural Networks via Higher-Order Interactions",
    "authors": [
      "Lorenzo Giusti"
    ],
    "abstract": "The irreducible complexity of natural phenomena has led Graph Neural Networks\nto be employed as a standard model to perform representation learning tasks on\ngraph-structured data. While their capacity to capture local and global\npatterns is remarkable, the implications associated with long-range and\nhigher-order dependencies pose considerable challenges to such models. This\nwork starts with a theoretical framework to reveal the impact of network's\nwidth, depth, and graph topology on the over-squashing phenomena in\nmessage-passing neural networks. Then, the work drifts towards, higher-order\ninteractions and multi-relational inductive biases via Topological Neural\nNetworks. Such models propagate messages through higher-dimensional structures,\nproviding shortcuts or additional routes for information flow. With this\nconstruction, the underlying computational graph is no longer coupled with the\ninput graph structure, thus mitigating the aforementioned bottlenecks while\naccounting also for higher-order interactions. Inspired by Graph Attention\nNetworks, two topological attention networks are proposed: Simplicial and Cell\nAttention Networks. The rationale behind these architecture is to leverage the\nextended notion of neighbourhoods provided by the arrangement of groups of\nnodes within a simplicial or cell complex to design anisotropic aggregations\nable to measure the importance of the information coming from different regions\nof the domain. By doing so, they capture dependencies that conventional Graph\nNeural Networks might miss. Finally, a multi-way communication scheme is\nintroduced with Enhanced Cellular Isomorphism Networks, which augment\ntopological message passing schemes to enable a direct interactions among\ngroups of nodes arranged in ring-like structures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD thesis, 135 pages, 51 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.06908v1",
    "published_date": "2024-02-10 08:26:06 UTC",
    "updated_date": "2024-02-10 08:26:06 UTC"
  },
  {
    "arxiv_id": "2402.06900v5",
    "title": "Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric",
    "authors": [
      "Hyukhun Koh",
      "Dohyung Kim",
      "Minwoo Lee",
      "Kyomin Jung"
    ],
    "abstract": "In the pursuit of developing Large Language Models (LLMs) that adhere to\nsocietal standards, it is imperative to detect the toxicity in the generated\ntext. The majority of existing toxicity metrics rely on encoder models trained\non specific toxicity datasets, which are susceptible to out-of-distribution\n(OOD) problems and depend on the dataset's definition of toxicity. In this\npaper, we introduce a robust metric grounded on LLMs to flexibly measure\ntoxicity according to the given definition. We first analyze the toxicity\nfactors, followed by an examination of the intrinsic toxic attributes of LLMs\nto ascertain their suitability as evaluators. Finally, we evaluate the\nperformance of our metric with detailed analysis. Our empirical results\ndemonstrate outstanding performance in measuring toxicity within verified\nfactors, improving on conventional metrics by 12 points in the F1 score. Our\nfindings also indicate that upstream toxicity significantly influences\ndownstream metrics, suggesting that LLMs are unsuitable for toxicity\nevaluations within unverified factors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 page long",
    "pdf_url": "http://arxiv.org/pdf/2402.06900v5",
    "published_date": "2024-02-10 07:55:27 UTC",
    "updated_date": "2024-11-14 14:28:58 UTC"
  },
  {
    "arxiv_id": "2402.06894v2",
    "title": "GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators",
    "authors": [
      "Yuchen Hu",
      "Chen Chen",
      "Chao-Han Huck Yang",
      "Ruizhe Li",
      "Dong Zhang",
      "Zhehuai Chen",
      "Eng Siong Chng"
    ],
    "abstract": "Recent advances in large language models (LLMs) have stepped forward the\ndevelopment of multilingual speech and machine translation by its reduced\nrepresentation errors and incorporated external knowledge. However, both\ntranslation tasks typically utilize beam search decoding and top-1 hypothesis\nselection for inference. These techniques struggle to fully exploit the rich\ninformation in the diverse N-best hypotheses, making them less optimal for\ntranslation tasks that require a single, high-quality output sequence. In this\npaper, we propose a new generative paradigm for translation tasks, namely\n\"GenTranslate\", which builds upon LLMs to generate better results from the\ndiverse translation versions in N-best list. Leveraging the rich linguistic\nknowledge and strong reasoning abilities of LLMs, our new paradigm can\nintegrate the rich information in N-best candidates to generate a\nhigher-quality translation result. Furthermore, to support LLM finetuning, we\nbuild and release a HypoTranslate dataset that contains over 592K\nhypotheses-translation pairs in 11 languages. Experiments on various speech and\nmachine translation benchmarks (e.g., FLEURS, CoVoST-2, WMT) demonstrate that\nour GenTranslate significantly outperforms the state-of-the-art model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, Accepted by ACL 2024. This work is open sourced at:\n  https://github.com/YUCHEN005/GenTranslate",
    "pdf_url": "http://arxiv.org/pdf/2402.06894v2",
    "published_date": "2024-02-10 07:20:49 UTC",
    "updated_date": "2024-05-16 13:17:05 UTC"
  },
  {
    "arxiv_id": "2402.06871v6",
    "title": "Non-autoregressive Generative Models for Reranking Recommendation",
    "authors": [
      "Yuxin Ren",
      "Qiya Yang",
      "Yichun Wu",
      "Wei Xu",
      "Yalong Wang",
      "Zhiqiang Zhang"
    ],
    "abstract": "Contemporary recommendation systems are designed to meet users' needs by\ndelivering tailored lists of items that align with their specific demands or\ninterests. In a multi-stage recommendation system, reranking plays a crucial\nrole by modeling the intra-list correlations among items. The key challenge of\nreranking lies in the exploration of optimal sequences within the combinatorial\nspace of permutations. Recent research proposes a generator-evaluator learning\nparadigm, where the generator generates multiple feasible sequences and the\nevaluator picks out the best sequence based on the estimated listwise score.\nThe generator is of vital importance, and generative models are well-suited for\nthe generator function. Current generative models employ an autoregressive\nstrategy for sequence generation. However, deploying autoregressive models in\nreal-time industrial systems is challenging. To address these issues, we\npropose a Non-AutoRegressive generative model for reranking Recommendation\n(NAR4Rec) designed to enhance efficiency and effectiveness. To tackle\nchallenges such as sparse training samples and dynamic candidates, we introduce\na matching model. Considering the diverse nature of user feedback, we employ a\nsequence-level unlikelihood training objective to differentiate feasible\nsequences from unfeasible ones. Additionally, to overcome the lack of\ndependency modeling in non-autoregressive models regarding target items, we\nintroduce contrastive decoding to capture correlations among these items.\nExtensive offline experiments validate the superior performance of NAR4Rec over\nstate-of-the-art reranking methods. Online A/B tests reveal that NAR4Rec\nsignificantly enhances the user experience. Furthermore, NAR4Rec has been fully\ndeployed in a popular video app Kuaishou with over 300 million daily active\nusers.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06871v6",
    "published_date": "2024-02-10 03:21:13 UTC",
    "updated_date": "2025-03-25 02:54:01 UTC"
  },
  {
    "arxiv_id": "2402.06864v2",
    "title": "Discriminative Adversarial Unlearning",
    "authors": [
      "Rohan Sharma",
      "Shijie Zhou",
      "Kaiyi Ji",
      "Changyou Chen"
    ],
    "abstract": "We introduce a novel machine unlearning framework founded upon the\nestablished principles of the min-max optimization paradigm. We capitalize on\nthe capabilities of strong Membership Inference Attacks (MIA) to facilitate the\nunlearning of specific samples from a trained model. We consider the scenario\nof two networks, the attacker $\\mathbf{A}$ and the trained defender\n$\\mathbf{D}$ pitted against each other in an adversarial objective, wherein the\nattacker aims at teasing out the information of the data to be unlearned in\norder to infer membership, and the defender unlearns to defend the network\nagainst the attack, whilst preserving its general performance. The algorithm\ncan be trained end-to-end using backpropagation, following the well known\niterative min-max approach in updating the attacker and the defender. We\nadditionally incorporate a self-supervised objective effectively addressing the\nfeature space discrepancies between the forget set and the validation set,\nenhancing unlearning performance. Our proposed algorithm closely approximates\nthe ideal benchmark of retraining from scratch for both random sample\nforgetting and class-wise forgetting schemes on standard machine-unlearning\ndatasets. Specifically, on the class unlearning scheme, the method demonstrates\nnear-optimal performance and comprehensively overcomes known methods over the\nrandom sample forgetting scheme across all metrics and multiple network pruning\nstrategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages including references, 2 tables, 2 figures and 1 algorithm",
    "pdf_url": "http://arxiv.org/pdf/2402.06864v2",
    "published_date": "2024-02-10 03:04:57 UTC",
    "updated_date": "2024-02-13 06:14:21 UTC"
  },
  {
    "arxiv_id": "2402.06861v2",
    "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction",
    "authors": [
      "Yansong Ning",
      "Hao Liu"
    ],
    "abstract": "Urban knowledge graph has recently worked as an emerging building block to\ndistill critical knowledge from multi-sourced urban data for diverse urban\napplication scenarios. Despite its promising benefits, urban knowledge graph\nconstruction (UrbanKGC) still heavily relies on manual effort, hindering its\npotential advancement. This paper presents UrbanKGent, a unified large language\nmodel agent framework, for urban knowledge graph construction. Specifically, we\nfirst construct the knowledgeable instruction set for UrbanKGC tasks (such as\nrelational triplet extraction and knowledge graph completion) via\nheterogeneity-aware and geospatial-infused instruction generation. Moreover, we\npropose a tool-augmented iterative trajectory refinement module to enhance and\nrefine the trajectories distilled from GPT-4. Through hybrid instruction\nfine-tuning with augmented trajectories on Llama 2 and Llama 3 family, we\nobtain UrbanKGC agent family, consisting of UrbanKGent-7/8/13B version. We\nperform a comprehensive evaluation on two real-world datasets using both human\nand GPT-4 self-evaluation. The experimental results demonstrate that UrbanKGent\nfamily can not only significantly outperform 31 baselines in UrbanKGC tasks,\nbut also surpass the state-of-the-art LLM, GPT-4, by more than 10% with\napproximately 20 times lower cost. Compared with the existing benchmark, the\nUrbanKGent family could help construct an UrbanKG with hundreds of times richer\nrelationships using only one-fifth of the data. Our data and code are available\nat https://github.com/usail-hkust/UrbanKGent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06861v2",
    "published_date": "2024-02-10 01:50:19 UTC",
    "updated_date": "2024-10-06 03:40:58 UTC"
  },
  {
    "arxiv_id": "2402.06859v2",
    "title": "LiRank: Industrial Large Scale Ranking Models at LinkedIn",
    "authors": [
      "Fedor Borisyuk",
      "Mingzhou Zhou",
      "Qingquan Song",
      "Siyu Zhu",
      "Birjodh Tiwana",
      "Ganesh Parameswaran",
      "Siddharth Dangi",
      "Lars Hertel",
      "Qiang Xiao",
      "Xiaochen Hou",
      "Yunbo Ouyang",
      "Aman Gupta",
      "Sheallika Singh",
      "Dan Liu",
      "Hailing Cheng",
      "Lei Le",
      "Jonathan Hung",
      "Sathiya Keerthi",
      "Ruoyan Wang",
      "Fengyu Zhang",
      "Mohit Kothari",
      "Chen Zhu",
      "Daqi Sun",
      "Yun Dai",
      "Xun Luan",
      "Sirou Zhu",
      "Zhiwei Wang",
      "Neil Daftary",
      "Qianqi Shen",
      "Chengming Jiang",
      "Haichao Wei",
      "Maneesh Varshney",
      "Amol Ghoting",
      "Souvik Ghosh"
    ],
    "abstract": "We present LiRank, a large-scale ranking framework at LinkedIn that brings to\nproduction state-of-the-art modeling architectures and optimization methods. We\nunveil several modeling improvements, including Residual DCN, which adds\nattention and residual connections to the famous DCNv2 architecture. We share\ninsights into combining and tuning SOTA architectures to create a unified\nmodel, including Dense Gating, Transformers and Residual DCN. We also propose\nnovel techniques for calibration and describe how we productionalized deep\nlearning based explore/exploit methods. To enable effective, production-grade\nserving of large ranking models, we detail how to train and compress models\nusing quantization and vocabulary compression. We provide details about the\ndeployment setup for large-scale use cases of Feed ranking, Jobs\nRecommendations, and Ads click-through rate (CTR) prediction. We summarize our\nlearnings from various A/B tests by elucidating the most effective technical\napproaches. These ideas have contributed to relative metrics improvements\nacross the board at LinkedIn: +0.5% member sessions in the Feed, +1.76%\nqualified job applications for Jobs search and recommendations, and +4.3% for\nAds CTR. We hope this work can provide practical insights and solutions for\npractitioners interested in leveraging large-scale deep ranking systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "H.3.3"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06859v2",
    "published_date": "2024-02-10 01:47:10 UTC",
    "updated_date": "2024-08-07 16:54:23 UTC"
  },
  {
    "arxiv_id": "2402.06852v2",
    "title": "ChemLLM: A Chemical Large Language Model",
    "authors": [
      "Di Zhang",
      "Wei Liu",
      "Qian Tan",
      "Jingdan Chen",
      "Hang Yan",
      "Yuliang Yan",
      "Jiatong Li",
      "Weiran Huang",
      "Xiangyu Yue",
      "Wanli Ouyang",
      "Dongzhan Zhou",
      "Shufei Zhang",
      "Mao Su",
      "Han-Sen Zhong",
      "Yuqiang Li"
    ],
    "abstract": "Large language models (LLMs) have made impressive progress in chemistry\napplications. However, the community lacks an LLM specifically designed for\nchemistry. The main challenges are two-fold: firstly, most chemical data and\nscientific knowledge are stored in structured databases, which limits the\nmodel's ability to sustain coherent dialogue when used directly. Secondly,\nthere is an absence of objective and fair benchmark that encompass most\nchemistry tasks. Here, we introduce ChemLLM, a comprehensive framework that\nfeatures the first LLM dedicated to chemistry. It also includes ChemData, a\ndataset specifically designed for instruction tuning, and ChemBench, a robust\nbenchmark covering nine essential chemistry tasks. ChemLLM is adept at\nperforming various tasks across chemical disciplines with fluid dialogue\ninteraction. Notably, ChemLLM achieves results comparable to GPT-4 on the core\nchemical tasks and demonstrates competitive performance with LLMs of similar\nsize in general scenarios. ChemLLM paves a new path for exploration in chemical\nstudies, and our method of incorporating structured chemical knowledge into\ndialogue systems sets a new standard for developing LLMs in various scientific\nfields. Codes, Datasets, and Model weights are publicly accessible at\nhttps://hf.co/AI4Chem",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.06852v2",
    "published_date": "2024-02-10 01:11:59 UTC",
    "updated_date": "2024-04-25 14:34:28 UTC"
  },
  {
    "arxiv_id": "2402.07949v1",
    "title": "Optimizing the Design of an Artificial Pancreas to Improve Diabetes Management",
    "authors": [
      "Ashok Khanna",
      "Olivier Francon",
      "Risto Miikkulainen"
    ],
    "abstract": "Diabetes, a chronic condition that impairs how the body turns food into\nenergy, i.e. blood glucose, affects 38 million people in the US alone. The\nstandard treatment is to supplement carbohydrate intake with an artificial\npancreas, i.e. a continuous insulin pump (basal shots), as well as occasional\ninsulin injections (bolus shots). The goal of the treatment is to keep blood\nglucose at the center of an acceptable range, as measured through a continuous\nglucose meter. A secondary goal is to minimize injections, which are unpleasant\nand difficult for some patients to implement. In this study, neuroevolution was\nused to discover an optimal strategy for the treatment. Based on a dataset of\n30 days of treatment and measurements of a single patient, a random forest was\nfirst trained to predict future glucose levels. A neural network was then\nevolved to prescribe carbohydrates, basal pumping levels, and bolus injections.\nEvolution discovered a Pareto front that reduced deviation from the target and\nnumber of injections compared to the original data, thus improving patients'\nquality of life. To make the system easier to adopt, a language interface was\ndeveloped with a large language model. Thus, these technologies not only\nimprove patient care but also adoption in a broader population.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07949v1",
    "published_date": "2024-02-10 00:49:46 UTC",
    "updated_date": "2024-02-10 00:49:46 UTC"
  }
]