{
  "date": "2024-10-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-05 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 63 篇论文，主要聚焦 AI 模型优化、强化学习、图像生成和知识图谱等领域，其中 LLM 的推理微调方法（如 Mechanistic Behavior Editing）和量子计算语义网络的进展最令人印象深刻，相关作者如 Alexandre M. Bayen 的控制理论工作也值得关注。\n\n### 重点论文聚焦：AI 和 LLM 创新\n今天的多篇论文强调了大型语言模型（LLM）的优化和应用，这些工作可能引发话题讨论，因为它们直接提升了模型的推理和泛化能力。\n\n- **Mechanistic Behavior Editing of Language Models（机制行为编辑的语言模型）**  \n  作者：Joykirat Singh 等。这篇论文提出 TaRot 方法，通过可学习的旋转矩阵和贝叶斯优化编辑 LLM 的神经电路，实现任务适应。贡献：显著提升分类和生成任务的性能，平均改善零样本和少样本表现 23.81% 和 11.15%，为 LLM 泛化提供新框架。\n\n- **Reward Learning From Preference With Ties（考虑平局的偏好奖励学习）**  \n  作者：Jinsong Liu 等。论文扩展 Bradley-Terry 模型为 BTT（带平局的版本），处理人类偏好中的平局情况。发现：忽略平局会导致偏好强度偏差，BTT 在合成数据集上优于传统方法，提升 LLM 微调效果。\n\n- **Self-Supervised Anomaly Detection in the Wild: Favor Joint Embeddings Methods（野外自监督异常检测：偏好联合嵌入方法）**  \n  作者：Daniel Otero 等。评估自监督学习（如 SimCLR 和 Barlow Twins）在异常检测中的表现。关键发现：联合嵌入方法在不平衡数据下优于重建方法（如 MAE），为视觉基础设施检查提供高效框架。\n\n- **Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills（预判人类误解的对比解释可提升决策技能）**  \n  作者：Zana Buçinca 等。引入人类中心对比解释框架，帮助 AI 解释与用户推理差异。贡献：实验显示，这种解释显著提升用户独立决策准确性，而不牺牲 AI 性能，强调 AI 设计中融入人类推理。\n\n- **Enhancing Future Link Prediction in Quantum Computing Semantic Networks through LLM-Initiated Node Features（通过 LLM 启动的节点特征提升量子计算语义网络的未来链接预测）**  \n  作者：Gilchan Park 等。使用 LLM 初始化节点特征，提高图神经网络的链接预测。发现：该方法在量子计算语义网络上优于传统嵌入技术，促进知识图谱应用。\n\n### 图像和视频生成进展\n图像生成领域的论文展示了一些高效方法，值得快速浏览。\n\n- **Accelerating Diffusion Models with One-to-Many Knowledge Distillation（通过一对多知识蒸馏加速扩散模型）**  \n  作者：Linfeng Zhang 等。提出 O2MKD 方法，将教师模型知识蒸馏到多个学生模型。贡献：在 CIFAR10 和 Stable Diffusion 数据集上，实现生成质量提升，同时显著加速采样过程。\n\n- **IV-Mixed Sampler: Leveraging Image Diffusion Models for Enhanced Video Synthesis（IV-Mixed Sampler：利用图像扩散模型增强视频合成）**  \n  作者：Shitong Shao 等。设计训练-free 算法，结合图像和视频扩散模型提升视频生成。发现：在 UCF-101 等基准上，状态优于现有方法，如 Animatediff 与此结合可降低 FVD 分数。\n\n### 其他领域亮点\n其他论文覆盖量子计算、医学和优化等领域，这里快速掠过不那么热门的。\n\n- **Pareto Control Barrier Function for Inner Safe Set Maximization Under Input Constraints（Pareto 控制屏障函数：最大化输入约束下的内部安全集）**  \n  作者：Xiaoyang Cao 等（包括知名学者 Alexandre M. Bayen）。提出 PCBF 算法，平衡安全性和安全集体积。贡献：在高维系统中优于传统方法，如倒立摆和四旋翼模拟中获得更大安全集。\n\n- **Applying Quantum Autoencoders for Time Series Anomaly Detection（应用于时间序列异常检测的量子自动编码器）**  \n  作者：Robin Frehner 等。使用量子自动编码器检测异常，结合重建误差和潜在表示分析。发现：在多个数据集上，量子方法比经典深度学习模型更高效，使用更少参数。\n\n- **From Incomplete Coarse-Grained to Complete Fine-Grained: A Two-Stage Framework for Spatiotemporal Data Reconstruction（从不完整粗粒度到完整细粒度：时空数据重建的两阶段框架）**  \n  作者：Ziyu Sun 等。提出 DiffRecon 框架，使用扩散模型重建时空数据。贡献：有效处理稀疏数据，提升泛化能力。\n\n其他论文，如那些涉及区块链（如 BlockFound）、医学图像（如 An Electrocardiogram Foundation Model）或多文档摘要（如 GlobeSumm），虽有技术创新但影响力较小，仅提要：BlockFound 使用 LLM 检测区块链异常，ECGFounder 在心电图分析中实现高准确率，GlobeSumm 统一多语言摘要任务。这些工作为各自领域提供工具，但未见突破性发现，故从简。\n\n总之，今天的 arXiv 更新突显 AI 领域的动态优化和应用潜力，LLM 相关论文尤其值得跟踪。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2410.17257v2",
      "title": "Code-Driven Law NO, Normware SI!",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Sileno"
      ],
      "abstract": "With the digitalization of society, the interest, the debates and the\nresearch efforts concerning \"code\", \"law\", \"artificial intelligence\", and their\nvarious relationships, have been widely increasing. Yet, most arguments\nprimarily focus on contemporary computational methods and artifacts\n(inferential models constructed via machine-learning methods, rule-based\nsystems, smart contracts), rather than attempting to identify more fundamental\nmechanisms. Aiming to go beyond this conceptual limitation, this paper\nintroduces and elaborates on \"normware\" as an explicit additional stance --\ncomplementary to software and hardware -- for the interpretation and the design\nof artificial devices. By means of a few examples, I will argue that a\nnormware-centred perspective provides a more adequate abstraction to study and\ndesign interactions between computational systems and human institutions, and\nmay help with the design and development of technical interventions within\nwider socio-technical views.",
      "tldr_zh": "该论文批评了现有研究过度关注当代计算方法（如机器学习模型和智能合约）来探讨 code（代码）、law（法律）和 artificial intelligence（人工智能）之间的关系，而忽略了更根本的机制。作者引入 normware 作为一种补充软件和硬件的立场，用于解释和设计人工智能设备，从而提供一个更合适的抽象框架。通过具体例子，论文论证了 normware 视角有助于更好地研究计算系统与人类机构的互动，并支持在更广泛的 socio-technical views（社会技术观点）下进行技术干预的设计。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "First version of the paper presented at CRCL 2022",
      "pdf_url": "http://arxiv.org/pdf/2410.17257v2",
      "published_date": "2024-10-05 22:37:45 UTC",
      "updated_date": "2025-01-20 19:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:28:02.016722"
    },
    {
      "arxiv_id": "2410.04289v1",
      "title": "Self-Supervised Anomaly Detection in the Wild: Favor Joint Embeddings Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Otero",
        "Rafael Mateus",
        "Randall Balestriero"
      ],
      "abstract": "Accurate anomaly detection is critical in vision-based infrastructure\ninspection, where it helps prevent costly failures and enhances safety.\nSelf-Supervised Learning (SSL) offers a promising approach by learning robust\nrepresentations from unlabeled data. However, its application in anomaly\ndetection remains underexplored. This paper addresses this gap by providing a\ncomprehensive evaluation of SSL methods for real-world anomaly detection,\nfocusing on sewer infrastructure. Using the Sewer-ML dataset, we evaluate\nlightweight models such as ViT-Tiny and ResNet-18 across SSL frameworks,\nincluding BYOL, Barlow Twins, SimCLR, DINO, and MAE, under varying class\nimbalance levels. Through 250 experiments, we rigorously assess the performance\nof these SSL methods to ensure a robust and comprehensive evaluation. Our\nfindings highlight the superiority of joint-embedding methods like SimCLR and\nBarlow Twins over reconstruction-based approaches such as MAE, which struggle\nto maintain performance under class imbalance. Furthermore, we find that the\nSSL model choice is more critical than the backbone architecture. Additionally,\nwe emphasize the need for better label-free assessments of SSL representations,\nas current methods like RankMe fail to adequately evaluate representation\nquality, making cross-validation without labels infeasible. Despite the\nremaining performance gap between SSL and supervised models, these findings\nhighlight the potential of SSL to enhance anomaly detection, paving the way for\nfurther research in this underexplored area of SSL applications.",
      "tldr_zh": "这篇论文评估了Self-Supervised Learning (SSL) 在真实世界异常检测中的应用，特别是针对视觉基础架构检查如下水道基础设施，使用Sewer-ML数据集进行实验。研究者通过250次实验测试了轻量级模型如ViT-Tiny和ResNet-18，在BYOL、Barlow Twins、SimCLR、DINO和MAE等SSL框架下的性能。结果显示，joint-embedding methods如SimCLR和Barlow Twins在类别不平衡情况下优于reconstruction-based approaches如MAE，且SSL模型选择比骨干架构更重要。论文强调，需要改进标签无关评估方法如RankMe，以充分挖掘SSL在异常检测领域的潜力，尽管其性能仍落后于监督模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04289v1",
      "published_date": "2024-10-05 21:27:47 UTC",
      "updated_date": "2024-10-05 21:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:28:15.310084"
    },
    {
      "arxiv_id": "2410.05328v1",
      "title": "Reward Learning From Preference With Ties",
      "title_zh": "翻译失败",
      "authors": [
        "Jinsong Liu",
        "Dongdong Ge",
        "Ruihao Zhu"
      ],
      "abstract": "Reward learning plays a pivotal role in Reinforcement Learning from Human\nFeedback (RLHF), ensuring the alignment of language models. The Bradley-Terry\n(BT) model stands as the prevalent choice for capturing human preferences from\ndatasets containing pairs of chosen and rejected responses. In preference\nmodeling, the focus is not on absolute values but rather on the reward\ndifference between chosen and rejected responses, referred to as preference\nstrength. Thus, precise evaluation of preference strength holds paramount\nimportance in preference modeling. However, an easily overlooked factor\nsignificantly affecting preference strength measurement is that human attitudes\ntowards two responses may not solely indicate a preference for one over the\nother and ties are also a common occurrence. To address this, we propose the\nadoption of the generalized Bradley-Terry model -- the Bradley-Terry model with\nties (BTT) -- to accommodate tied preferences, thus leveraging additional\ninformation. We prove that even with the access to the true distributions of\nprompt and response, disregarding ties can lead to a notable bias in preference\nstrength measurement. Comprehensive experiments further validate the advantages\nof incorporating ties in preference modeling. Notably, fine-tuning with BTT\nsignificantly outperforms fine-tuning with BT on synthetic preference datasets\nwith ties, labeled by state-of-the-art open-source LLMs.",
      "tldr_zh": "这项研究探讨了在强化学习从人类反馈（RLHF）中，奖励学习的关键作用，强调了 Bradley-Terry (BT) 模型在处理成对偏好数据时的局限性，因为它忽略了常见的平局（ties），导致偏好强度测量出现偏差。论文提出采用广义的 Bradley-Terry with ties (BTT) 模型来纳入平局信息，从而更准确地评估偏好强度，并证明即使知道真实分布，忽略 ties 也会引入显著偏差。通过全面实验验证，BTT 在使用先进开源大型语言模型（LLMs）标注的合成偏好数据集上，显著优于 BT 模型，提高了奖励学习的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05328v1",
      "published_date": "2024-10-05 21:02:57 UTC",
      "updated_date": "2024-10-05 21:02:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:28:26.953198"
    },
    {
      "arxiv_id": "2410.04277v1",
      "title": "Mechanistic Behavior Editing of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Joykirat Singh",
        "Subhabrata Dutta",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Large Language Models trained on web-scale text acquire language generation\nabilities that can solve a wide range of tasks, particularly when task\nknowledge is refined into the generative prior using in-context examples.\nHowever, spurious features learned from noisy data hinder their\ngeneralizability. Supervised finetuning can introduce task specificity, but\nintroduce data inefficiency. Prior studies indicate that (i) noisy neural\ncircuitries coexist with generalizable ones within LLMs, and (ii) finetuning\ntypically enhances (or suppresses) existing abilities without introducing newer\nones. Building upon these, we propose TaRot, a novel method for task\nadaptation. TaRot intervenes in the neural circuitries using learnable rotation\nmatrices that are optimized using Bayesian Optimization, on labelled samples in\nthe order of standard few-shot prompting examples. Experiments on multiple\nclassification and generation tasks using LLMs of varying sizes reveal the\nefficacy of TaRot, improving upon both zero- as well as few-shot performance,\nwith average improvements (across models and tasks) of 23.81% and 11.15%,\nrespectively. The source code is available at\nhttps://github.com/joykirat18/TaRot",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）中噪声特征对泛化能力的影响，提出了一种新型任务适应方法TaRot，以优化神经回路。TaRot通过使用可学习的旋转矩阵和贝叶斯优化干预现有回路，仅需少量标记样本即可增强模型性能，而非引入新能力。实验在多种分类和生成任务上验证了其有效性，与零样本和少样本基准相比，平均改善率分别为23.81%和11.15%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04277v1",
      "published_date": "2024-10-05 19:58:08 UTC",
      "updated_date": "2024-10-05 19:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:28:38.711835"
    },
    {
      "arxiv_id": "2410.04266v1",
      "title": "Constructing Cloze Questions Generatively",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Sun",
        "Jie Wang"
      ],
      "abstract": "We present a generative method called CQG for constructing cloze questions\nfrom a given article using neural networks and WordNet, with an emphasis on\ngenerating multigram distractors. Built on sense disambiguation, text-to-text\ntransformation, WordNet's synset taxonomies and lexical labels, CQG selects an\nanswer key for a given sentence, segments it into a sequence of instances,\ngenerates instance-level distractor candidates (IDCs) using a transformer and\nsibling synsets.It then removes inappropriate IDCs, ranks the remaining IDCs\nbased on contextual embedding similarities, as well as synset and lexical\nrelatedness, forms distractor candidates by combinatorially replacing instances\nwith the corresponding top-ranked IDCs, and checks if they are legitimate\nphrases. Finally, it selects top-ranked distractor candidates based on\ncontextual semantic similarities to the answer key. Experiments show that this\nmethod significantly outperforms SOTA results. Human judges also confirm the\nhigh qualities of the generated distractors.",
      "tldr_zh": "本论文提出了一种名为 CQG 的生成方法，使用神经网络和 WordNet 从给定文章中构建完形填空（cloze）问题，重点生成多词干扰项（multigram distractors）。该方法基于词义消歧（sense disambiguation）、文本到文本转换（text-to-text transformation）和 WordNet 的同义集分类（synset taxonomies）及词汇标签，涉及选择答案关键句、分割实例序列、生成并排名干扰候选（IDCs），并最终筛选高质量候选。实验结果显示，CQG 显著优于现有最先进（SOTA）方法，且人为评判确认了生成干扰项的优质表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures,5 tables, 2023 International Joint Conference on\n  Neural Networks (IJCNN)",
      "pdf_url": "http://arxiv.org/pdf/2410.04266v1",
      "published_date": "2024-10-05 18:55:38 UTC",
      "updated_date": "2024-10-05 18:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:28:51.730283"
    },
    {
      "arxiv_id": "2410.04260v2",
      "title": "Pareto Control Barrier Function for Inner Safe Set Maximization Under Input Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyang Cao",
        "Zhe Fu",
        "Alexandre M. Bayen"
      ],
      "abstract": "This article introduces the Pareto Control Barrier Function (PCBF) algorithm\nto maximize the inner safe set of dynamical systems under input constraints.\nTraditional Control Barrier Functions (CBFs) ensure safety by maintaining\nsystem trajectories within a safe set but often fail to account for realistic\ninput constraints. To address this problem, we leverage the Pareto multi-task\nlearning framework to balance competing objectives of safety and safe set\nvolume. The PCBF algorithm is applicable to high-dimensional systems and is\ncomputationally efficient. We validate its effectiveness through comparison\nwith Hamilton-Jacobi reachability for an inverted pendulum and through\nsimulations on a 12-dimensional quadrotor system. Results show that the PCBF\nconsistently outperforms existing methods, yielding larger safe sets and\nensuring safety under input constraints.",
      "tldr_zh": "本研究引入了Pareto Control Barrier Function (PCBF) 算法，以在输入约束下最大化动态系统的内安全集。相比传统 Control Barrier Functions (CBFs)，PCBF 通过 Pareto 多任务学习框架平衡安全性和安全集体积，确保算法适用于高维系统并保持计算效率高效。实验结果显示，PCBF 在倒立摆和12维四旋翼系统上与 Hamilton-Jacobi reachability 方法比较后，实现了更大的安全集并在输入约束下可靠地确保系统安全。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "math.OC",
      "comment": "Accepted for presentation at American Control Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.04260v2",
      "published_date": "2024-10-05 18:45:19 UTC",
      "updated_date": "2025-03-20 17:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:29:01.392671"
    },
    {
      "arxiv_id": "2410.04256v1",
      "title": "Implicit to Explicit Entropy Regularization: Benchmarking ViT Fine-tuning under Noisy Labels",
      "title_zh": "从隐式到显式熵正则化：噪声标签下 ViT 微调的基准",
      "authors": [
        "Maria Marrium",
        "Arif Mahmood",
        "Mohammed Bennamoun"
      ],
      "abstract": "Automatic annotation of large-scale datasets can introduce noisy training\ndata labels, which adversely affect the learning process of deep neural\nnetworks (DNNs). Consequently, Noisy Labels Learning (NLL) has become a\ncritical research field for Convolutional Neural Networks (CNNs), though it\nremains less explored for Vision Transformers (ViTs). In this study, we\nevaluate the vulnerability of ViT fine-tuning to noisy labels and compare its\nrobustness with CNNs. We also investigate whether NLL methods developed for\nCNNs are equally effective for ViTs. Using linear probing and MLP-K\nfine-tuning, we benchmark two ViT backbones (ViT-B/16 and ViT-L/16) using three\ncommonly used classification losses: Cross Entropy (CE), Focal Loss (FL), and\nMean Absolute Error (MAE), alongside six robust NLL methods: GCE, SCE, NLNL,\nAPL, NCE+AGCE, and ANL-CE. The evaluation is conducted across six datasets\nincluding MNIST, CIFAR-10/100, WebVision, Clothing1M, and Food-101N.\nFurthermore, we explore whether implicit prediction entropy minimization\ncontributes to ViT robustness against noisy labels, noting a general trend of\nprediction entropy reduction across most NLL methods. Building on this\nobservation, we examine whether explicit entropy minimization could enhance ViT\nresilience to noisy labels. Our findings indicate that incorporating entropy\nregularization enhances the performance of established loss functions such as\nCE and FL, as well as the robustness of the six studied NLL methods across both\nViT backbones.",
      "tldr_zh": "该研究评估了 Vision Transformers (ViTs) 在噪声标签下的微调鲁棒性，并与 Convolutional Neural Networks (CNNs) 进行了比较，揭示 ViTs 更易受噪声标签影响。研究者基准测试了 ViT-B/16 和 ViT-L/16 两种骨干网络，使用线性探测和 MLP-K 微调，结合 Cross Entropy (CE)、Focal Loss (FL)、Mean Absolute Error (MAE) 等分类损失，以及 GCE、SCE、NLNL、APL、NCE+AGCE 和 ANL-CE 等六种 Noisy Labels Learning (NLL) 方法，在 MNIST、CIFAR-10/100、WebVision、Clothing1M 和 Food-101N 等六个数据集上进行实验。结果表明，隐式预测熵最小化有助于提升 ViTs 的鲁棒性，而引入显式熵正则化进一步改善了 CE、FL 等损失函数以及 NLL 方法的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04256v1",
      "published_date": "2024-10-05 18:24:38 UTC",
      "updated_date": "2024-10-05 18:24:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:29:16.576176"
    },
    {
      "arxiv_id": "2410.04254v1",
      "title": "Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia",
      "title_zh": "多语言链接语料库中的实体插入：Wikipedia 的案例",
      "authors": [
        "Tomás Feith",
        "Akhil Arora",
        "Martin Gerlach",
        "Debjit Paul",
        "Robert West"
      ],
      "abstract": "Links are a fundamental part of information networks, turning isolated pieces\nof knowledge into a network of information that is much richer than the sum of\nits parts. However, adding a new link to the network is not trivial: it\nrequires not only the identification of a suitable pair of source and target\nentities but also the understanding of the content of the source to locate a\nsuitable position for the link in the text. The latter problem has not been\naddressed effectively, particularly in the absence of text spans in the source\nthat could serve as anchors to insert a link to the target entity. To bridge\nthis gap, we introduce and operationalize the task of entity insertion in\ninformation networks. Focusing on the case of Wikipedia, we empirically show\nthat this problem is, both, relevant and challenging for editors. We compile a\nbenchmark dataset in 105 languages and develop a framework for entity insertion\ncalled LocEI (Localized Entity Insertion) and its multilingual variant XLocEI.\nWe show that XLocEI outperforms all baseline models (including state-of-the-art\nprompt-based ranking with LLMs such as GPT-4) and that it can be applied in a\nzero-shot manner on languages not seen during training with minimal performance\ndrop. These findings are important for applying entity insertion models in\npractice, e.g., to support editors in adding links across the more than 300\nlanguage versions of Wikipedia.",
      "tldr_zh": "本文探讨了在多语言链接语料库中进行 entity insertion 的任务，特别是以 Wikipedia 为例，旨在解决在源文本中缺乏锚点时添加实体链接的挑战。研究者编译了一个涵盖 105 种语言的基准数据集，并开发了 LocEI（Localized Entity Insertion）和其多语言版本 XLocEI 框架，这些框架通过有效的定位和插入机制提升了链接添加的准确性。实验结果显示，XLocEI 优于基线模型（如使用 GPT-4 的提示-based ranking），并能在 zero-shot 模式下应用于未训练语言，性能下降最小，从而为支持 Wikipedia 编辑在 300 多种语言版本中添加链接提供了实用工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024; 24 pages; 62 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04254v1",
      "published_date": "2024-10-05 18:22:15 UTC",
      "updated_date": "2024-10-05 18:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:29:26.686860"
    },
    {
      "arxiv_id": "2410.04253v2",
      "title": "Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills",
      "title_zh": "翻译失败",
      "authors": [
        "Zana Buçinca",
        "Siddharth Swaroop",
        "Amanda E. Paluch",
        "Finale Doshi-Velez",
        "Krzysztof Z. Gajos"
      ],
      "abstract": "People's decision-making abilities often fail to improve or may even erode\nwhen they rely on AI for decision-support, even when the AI provides\ninformative explanations. We argue this is partly because people intuitively\nseek contrastive explanations, which clarify the difference between the AI's\ndecision and their own reasoning, while most AI systems offer \"unilateral\"\nexplanations that justify the AI's decision but do not account for users'\nthinking. To align human-AI knowledge on decision tasks, we introduce a\nframework for generating human-centered contrastive explanations that explain\nthe difference between AI's choice and a predicted, likely human choice about\nthe same task. Results from a large-scale experiment (N = 628) demonstrate that\ncontrastive explanations significantly enhance users' independent\ndecision-making skills compared to unilateral explanations, without sacrificing\ndecision accuracy. Amid rising deskilling concerns, our research demonstrates\nthat incorporating human reasoning into AI design can foster human skill\ndevelopment.",
      "tldr_zh": "这项研究探讨了为什么人们在使用 AI 决策支持时，决策能力往往无法提升或下降，部分原因是人们更倾向于寻求 contrastive explanations（对比性解释），而非 AI 系统常见的 unilateral explanations（单向解释），后者仅证明 AI 的决策。论文引入了一个框架，用于生成 human-centered contrastive explanations，该框架解释 AI 选择与预测人类选择的差异，从而更好地对齐人类和 AI 的知识。实验结果（N=628）显示，与单向解释相比，对比性解释显著提高了用户的独立决策技能，同时不影响决策准确性。该方法证明，在 AI 设计中融入人类推理可以促进人类技能发展，缓解 deskilling 担忧。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04253v2",
      "published_date": "2024-10-05 18:21:04 UTC",
      "updated_date": "2025-03-19 00:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:29:39.704590"
    },
    {
      "arxiv_id": "2410.04251v1",
      "title": "Enhancing Future Link Prediction in Quantum Computing Semantic Networks through LLM-Initiated Node Features",
      "title_zh": "翻译失败",
      "authors": [
        "Gilchan Park",
        "Paul Baity",
        "Byung-Jun Yoon",
        "Adolfy Hoisie"
      ],
      "abstract": "Quantum computing is rapidly evolving in both physics and computer science,\noffering the potential to solve complex problems and accelerate computational\nprocesses. The development of quantum chips necessitates understanding the\ncorrelations among diverse experimental conditions. Semantic networks built on\nscientific literature, representing meaningful relationships between concepts,\nhave been used across various domains to identify knowledge gaps and novel\nconcept combinations. Neural network-based approaches have shown promise in\nlink prediction within these networks. This study proposes initializing node\nfeatures using LLMs to enhance node representations for link prediction tasks\nin graph neural networks. LLMs can provide rich descriptions, reducing the need\nfor manual feature creation and lowering costs. Our method, evaluated using\nvarious link prediction models on a quantum computing semantic network,\ndemonstrated efficacy compared to traditional node embedding techniques.",
      "tldr_zh": "本研究旨在通过LLM（Large Language Models）初始化节点特征来提升量子计算语义网络中的未来链接预测（Link Prediction）性能。论文提出了一种方法，利用LLM生成丰富的节点描述，减少手动特征工程的成本，并将其整合到图神经网络（Graph Neural Networks）中以增强节点表示。该方法在量子计算语义网络上进行评估，与传统节点嵌入技术相比，显示出更高的有效性，为识别实验条件相关性和知识空白提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04251v1",
      "published_date": "2024-10-05 18:16:07 UTC",
      "updated_date": "2024-10-05 18:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:29:49.512392"
    },
    {
      "arxiv_id": "2410.21279v1",
      "title": "Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US",
      "title_zh": "翻译失败",
      "authors": [
        "Jon Chun",
        "Christian Schroeder de Witt",
        "Katherine Elkins"
      ],
      "abstract": "As a powerful and rapidly advancing dual-use technology, AI offers both\nimmense benefits and worrisome risks. In response, governing bodies around the\nworld are developing a range of regulatory AI laws and policies. This paper\ncompares three distinct approaches taken by the EU, China and the US. Within\nthe US, we explore AI regulation at both the federal and state level, with a\nfocus on California's pending Senate Bill 1047. Each regulatory system reflects\ndistinct cultural, political and economic perspectives. Each also highlights\ndiffering regional perspectives on regulatory risk-benefit tradeoffs, with\ndivergent judgments on the balance between safety versus innovation and\ncooperation versus competition. Finally, differences between regulatory\nframeworks reflect contrastive stances in regards to trust in centralized\nauthority versus trust in a more decentralized free market of self-interested\nstakeholders. Taken together, these varied approaches to AI innovation and\nregulation influence each other, the broader international community, and the\nfuture of AI regulation.",
      "tldr_zh": "这篇论文比较了欧盟、中国和美国的 AI 监管方法，探讨了这些框架如何反映各自的文化、政治和经济视角。论文重点分析了安全与创新、合作与竞争以及中央权威与自由市场的权衡，尤其关注美国的联邦和州级政策，如加州的 Senate Bill 1047。总体而言，这些差异性方法相互影响国际社区，并塑造了 AI 监管的未来方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "91B32, 68T01 91B32, 68T99, 91F10, 91F50",
        "K.5.1; K.4.1; K.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "36 pages, 11 figures and tables",
      "pdf_url": "http://arxiv.org/pdf/2410.21279v1",
      "published_date": "2024-10-05 18:08:48 UTC",
      "updated_date": "2024-10-05 18:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:30:05.180021"
    },
    {
      "arxiv_id": "2410.04245v1",
      "title": "Towards Propositional KLM-Style Defeasible Standpoint Logics",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Leisegang",
        "Thomas Meyer",
        "Sebastian Rudolph"
      ],
      "abstract": "The KLM approach to defeasible reasoning introduces a weakened form of\nimplication into classical logic. This allows one to incorporate exceptions to\ngeneral rules into a logical system, and for old conclusions to be withdrawn\nupon learning new contradictory information. Standpoint logics are a group of\nlogics, introduced to the field of Knowledge Representation in the last 5\nyears, which allow for multiple viewpoints to be integrated into the same\nontology, even when certain viewpoints may hold contradicting beliefs. In this\npaper, we aim to integrate standpoints into KLM propositional logic in a\nrestricted setting. We introduce the logical system of Defeasible Restricted\nStandpoint Logic (DRSL) and define its syntax and semantics. Specifically, we\nintegrate ranked interpretations and standpoint structures, which provide the\nsemantics for propositional KLM and propositional standpoint logic\nrespectively, in order to introduce ranked standpoint structures for DRSL.\nMoreover, we extend the non-monotonic entailment relation of rational closure\nfrom the propositional KLM case to the DRSL case. The main contribution of this\npaper is to characterize rational closure for DRSL both algorithmically and\nsemantically, showing that rational closure can be characterized through a\nsingle representative ranked standpoint structure. Finally, we conclude that\nthe semantic and algorithmic characterizations of rational closure are\nequivalent, and that entailment-checking for DRSL under rational closure is in\nthe same complexity class as entailment-checking for propositional KLM.",
      "tldr_zh": "这篇论文旨在将standpoint logics整合到KLM-style defeasible reasoning中，引入Defeasible Restricted Standpoint Logic (DRSL)，以处理多个矛盾观点在命题逻辑中的整合。作者定义了DRSL的语法和语义，通过结合ranked interpretations和standpoint structures，创建了ranked standpoint structures作为语义基础，并扩展了rational closure的非单调蕴涵关系。论文的主要贡献是算法和语义上表征DRSL的rational closure，使用单一的representative ranked standpoint structure，并证明其等价性，同时显示DRSL的蕴涵检查复杂度与命题KLM相同。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04245v1",
      "published_date": "2024-10-05 18:07:03 UTC",
      "updated_date": "2024-10-05 18:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:30:14.949302"
    },
    {
      "arxiv_id": "2410.04236v1",
      "title": "Overview of Factify5WQA: Fact Verification through 5W Question-Answering",
      "title_zh": "Factify5WQA 的概述：通过 5W 问答的事实验证",
      "authors": [
        "Suryavardan Suresh",
        "Anku Rani",
        "Parth Patwa",
        "Aishwarya Reganti",
        "Vinija Jain",
        "Aman Chadha",
        "Amitava Das",
        "Amit Sheth",
        "Asif Ekbal"
      ],
      "abstract": "Researchers have found that fake news spreads much times faster than real\nnews. This is a major problem, especially in today's world where social media\nis the key source of news for many among the younger population. Fact\nverification, thus, becomes an important task and many media sites contribute\nto the cause. Manual fact verification is a tedious task, given the volume of\nfake news online. The Factify5WQA shared task aims to increase research towards\nautomated fake news detection by providing a dataset with an aspect-based\nquestion answering based fact verification method. Each claim and its\nsupporting document is associated with 5W questions that help compare the two\ninformation sources. The objective performance measure in the task is done by\ncomparing answers using BLEU score to measure the accuracy of the answers,\nfollowed by an accuracy measure of the classification. The task had submissions\nusing custom training setup and pre-trained language-models among others. The\nbest performing team posted an accuracy of 69.56%, which is a near 35%\nimprovement over the baseline.",
      "tldr_zh": "本文概述了 Factify5WQA，这是一个基于 5W Question-Answering 的共享任务，旨在通过问题回答方法（如 Who, What, When, Where, Why）自动验证事实，从而应对假新闻快速传播的问题。每个声明和支持文档关联 5W 问题，用于比较信息源，并通过 BLEU score 评估答案准确性，随后计算分类准确率。实验结果显示，最佳团队的准确率达到 69.56%，比基线模型提高了约 35%，为自动假新闻检测研究提供了重要推动。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at defactify3@aaai2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04236v1",
      "published_date": "2024-10-05 17:28:18 UTC",
      "updated_date": "2024-10-05 17:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:30:26.836264"
    },
    {
      "arxiv_id": "2410.04234v2",
      "title": "Functional Homotopy: Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Zi Wang",
        "Divyam Anshumaan",
        "Ashish Hooda",
        "Yudong Chen",
        "Somesh Jha"
      ],
      "abstract": "Optimization methods are widely employed in deep learning to identify and\nmitigate undesired model responses. While gradient-based techniques have proven\neffective for image models, their application to language models is hindered by\nthe discrete nature of the input space. This study introduces a novel\noptimization approach, termed the \\emph{functional homotopy} method, which\nleverages the functional duality between model training and input generation.\nBy constructing a series of easy-to-hard optimization problems, we iteratively\nsolve these problems using principles derived from established homotopy\nmethods. We apply this approach to jailbreak attack synthesis for large\nlanguage models (LLMs), achieving a $20\\%-30\\%$ improvement in success rate\nover existing methods in circumventing established safe open-source models such\nas Llama-2 and Llama-3.",
      "tldr_zh": "该研究针对大型语言模型(LLM)中输入空间的离散性问题，提出了一种名为functional homotopy的新优化方法，利用模型训练和输入生成的函数对偶性，通过构建一系列从简单到复杂的优化问题，并应用homotopy methods的原理进行迭代求解。该方法有效平滑离散优化过程，应用于LLM的jailbreak attacks中，成功率较现有方法提高20%-30%，成功绕过安全模型如Llama-2和Llama-3。实验结果表明，该方法为优化语言模型的安全性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.04234v2",
      "published_date": "2024-10-05 17:22:39 UTC",
      "updated_date": "2025-02-16 02:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:30:48.424968"
    },
    {
      "arxiv_id": "2410.13883v1",
      "title": "Transformers Utilization in Chart Understanding: A Review of Recent Advances & Future Trends",
      "title_zh": "Transformer 在图表理解中的应用：最近进展与未来趋势综述",
      "authors": [
        "Mirna Al-Shetairy",
        "Hanan Hindy",
        "Dina Khattab",
        "Mostafa M. Aref"
      ],
      "abstract": "In recent years, interest in vision-language tasks has grown, especially\nthose involving chart interactions. These tasks are inherently multimodal,\nrequiring models to process chart images, accompanying text, underlying data\ntables, and often user queries. Traditionally, Chart Understanding (CU) relied\non heuristics and rule-based systems. However, recent advancements that have\nintegrated transformer architectures significantly improved performance. This\npaper reviews prominent research in CU, focusing on State-of-The-Art (SoTA)\nframeworks that employ transformers within End-to-End (E2E) solutions. Relevant\nbenchmarking datasets and evaluation techniques are analyzed. Additionally,\nthis article identifies key challenges and outlines promising future directions\nfor advancing CU solutions. Following the PRISMA guidelines, a comprehensive\nliterature search is conducted across Google Scholar, focusing on publications\nfrom Jan'20 to Jun'24. After rigorous screening and quality assessment, 32\nstudies are selected for in-depth analysis. The CU tasks are categorized into a\nthree-layered paradigm based on the cognitive task required. Recent\nadvancements in the frameworks addressing various CU tasks are also reviewed.\nFrameworks are categorized into single-task or multi-task based on the number\nof tasks solvable by the E2E solution. Within multi-task frameworks,\npre-trained and prompt-engineering-based techniques are explored. This review\noverviews leading architectures, datasets, and pre-training tasks. Despite\nsignificant progress, challenges remain in OCR dependency, handling\nlow-resolution images, and enhancing visual reasoning. Future directions\ninclude addressing these challenges, developing robust benchmarks, and\noptimizing model efficiency. Additionally, integrating explainable AI\ntechniques and exploring the balance between real and synthetic data are\ncrucial for advancing CU research.",
      "tldr_zh": "这篇综述论文回顾了 Transformers 在 Chart Understanding (CU) 中的应用，聚焦于最近进展和未来趋势，涵盖了处理图表图像、文本、数据表及用户查询的多模态任务。作者遵循 PRISMA 指南，从 2020 年 1 月到 2024 年 6 月筛选了 32 篇研究，将 CU 任务分类为三层认知范式，并分析了单任务和多任务 End-to-End (E2E) 框架，包括预训练和提示工程技术。研究发现，Transformer 架构显著提升了 CU 性能，但仍存在 OCR 依赖、低分辨率图像处理以及视觉推理的挑战。未来方向包括优化模型效率、开发鲁棒基准、整合 Explainable AI，并探索真实与合成数据的平衡，以推进 CU 研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13883v1",
      "published_date": "2024-10-05 16:26:44 UTC",
      "updated_date": "2024-10-05 16:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:30:51.691954"
    },
    {
      "arxiv_id": "2410.04217v2",
      "title": "Improving Portfolio Optimization Results with Bandit Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Gustavo de Freitas Fonseca",
        "Lucas Coelho e Silva",
        "Paulo André Lima de Castro"
      ],
      "abstract": "In Reinforcement Learning (RL), multi-armed Bandit (MAB) problems have found\napplications across diverse domains such as recommender systems, healthcare,\nand finance. Traditional MAB algorithms typically assume stationary reward\ndistributions, which limits their effectiveness in real-world scenarios\ncharacterized by non-stationary dynamics. This paper addresses this limitation\nby introducing and evaluating novel Bandit algorithms designed for\nnon-stationary environments. First, we present the Adaptive Discounted Thompson\nSampling (ADTS) algorithm, which enhances adaptability through relaxed\ndiscounting and sliding window mechanisms to better respond to changes in\nreward distributions. We then extend this approach to the Portfolio\nOptimization problem by introducing the Combinatorial Adaptive Discounted\nThompson Sampling (CADTS) algorithm, which addresses computational challenges\nwithin Combinatorial Bandits and improves dynamic asset allocation.\nAdditionally, we propose a novel architecture called Bandit Networks, which\nintegrates the outputs of ADTS and CADTS, thereby mitigating computational\nlimitations in stock selection. Through extensive experiments using real\nfinancial market data, we demonstrate the potential of these algorithms and\narchitectures in adapting to dynamic environments and optimizing\ndecision-making processes. For instance, the proposed bandit network instances\npresent superior performance when compared to classic portfolio optimization\napproaches, such as capital asset pricing model, equal weights, risk parity,\nand Markovitz, with the best network presenting an out-of-sample Sharpe Ratio\n20% higher than the best performing classical model.",
      "tldr_zh": "本研究针对多臂赌博机 (MAB) 在非平稳环境下的局限性，提出 Adaptive Discounted Thompson Sampling (ADTS) 算法，通过折扣和滑动窗口机制提升算法对动态奖励分布的适应性。随后，扩展至组合式赌博机领域，引入 Combinatorial Adaptive Discounted Thompson Sampling (CADTS) 算法，以优化投资组合问题，并开发 Bandit Networks 架构整合 ADTS 和 CADTS 输出，缓解计算挑战。实验使用真实金融数据表明，该架构在动态环境中显著优于传统方法，如资本资产定价模型 (Capital Asset Pricing Model) 和 Markowitz 模型，其中最佳 Bandit Network 的出样本夏普比率 (Sharpe Ratio) 比最佳经典模型高 20%。这为强化学习在金融决策中的应用提供了新的改进路径。",
      "categories": [
        "cs.AI",
        "q-fin.PM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04217v2",
      "published_date": "2024-10-05 16:17:31 UTC",
      "updated_date": "2024-10-08 07:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:31:02.360048"
    },
    {
      "arxiv_id": "2410.04211v1",
      "title": "Correlation-Aware Select and Merge Attention for Efficient Fine-Tuning and Context Length Extension",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Wang",
        "Zekun Li",
        "Tongxin Bai",
        "Guoqi Li"
      ],
      "abstract": "Modeling long sequences is crucial for various large-scale models; however,\nextending existing architectures to handle longer sequences presents\nsignificant technical and resource challenges. In this paper, we propose an\nefficient and flexible attention architecture that enables the extension of\ncontext lengths in large language models with reduced computational resources\nand fine-tuning time compared to other excellent methods. Specifically, we\nintroduce correlation-aware selection and merging mechanisms to facilitate\nefficient sparse attention. In addition, we also propose a novel data\naugmentation technique involving positional encodings to enhance generalization\nto unseen positions. The results are as follows: First, using a single A100, we\nachieve fine-tuning on Llama2-7B with a sequence length of 32K, which is more\nefficient than other methods that rely on subsets for regression. Second, we\npresent a comprehensive method for extending context lengths across the\npre-training, fine-tuning, and inference phases. During pre-training, our\nattention mechanism partially breaks translation invariance during token\nselection, so we apply positional encodings only to the selected tokens. This\napproach achieves relatively high performance and significant extrapolation\ncapabilities. For fine-tuning, we introduce Cyclic, Randomly Truncated, and\nDynamically Growing NTK Positional Embedding (CRD NTK). This design allows\nfine-tuning with a sequence length of only 16K, enabling models such as\nLlama2-7B and Mistral-7B to perform inference with context lengths of up to 1M\nor even arbitrary lengths. Our method achieves 100\\% accuracy on the passkey\ntask with a context length of 4M and maintains stable perplexity at a 1M\ncontext length. This represents at least a 64-fold reduction in resource\nrequirements compared to traditional full-attention mechanisms, while still\nachieving competitive performance.",
      "tldr_zh": "本研究提出了一种Correlation-Aware Select and Merge Attention机制，用于高效扩展大型语言模型的上下文长度，显著减少计算资源和微调时间。该机制结合correlation-aware selection and merging实现稀疏注意力，并引入一种新型数据增强技术，包括positional encodings，以提升模型对未见位置的泛化能力。在实验中，该方法在单A100 GPU上对Llama2-7B进行微调，支持32K序列长度，并在预训练和微调阶段采用CRD NTK Positional Embedding，实现推理上下文长度达1M或更高，达到passkey任务100%准确率和稳定困惑度，同时资源需求比传统全注意力机制降低至少64倍。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04211v1",
      "published_date": "2024-10-05 15:59:32 UTC",
      "updated_date": "2024-10-05 15:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:31:14.930959"
    },
    {
      "arxiv_id": "2410.04203v2",
      "title": "RainbowPO: A Unified Framework for Combining Improvements in Preference Optimization",
      "title_zh": "RainbowPO：一种用于结合偏好优化的改进的统一框架",
      "authors": [
        "Hanyang Zhao",
        "Genta Indra Winata",
        "Anirban Das",
        "Shi-Xiong Zhang",
        "David D. Yao",
        "Wenpin Tang",
        "Sambit Sahu"
      ],
      "abstract": "Recently, numerous preference optimization algorithms have been introduced as\nextensions to the Direct Preference Optimization (DPO) family. While these\nmethods have successfully aligned models with human preferences, there is a\nlack of understanding regarding the contributions of their additional\ncomponents. Moreover, fair and consistent comparisons are scarce, making it\ndifficult to discern which components genuinely enhance downstream performance.\nIn this work, we propose RainbowPO, a unified framework that demystifies the\neffectiveness of existing DPO methods by categorizing their key components into\nseven broad directions. We integrate these components into a single cohesive\nobjective, enhancing the performance of each individual element. Through\nextensive experiments, we demonstrate that RainbowPO outperforms existing DPO\nvariants. Additionally, we provide insights to guide researchers in developing\nnew DPO methods and assist practitioners in their implementations.",
      "tldr_zh": "本文提出 RainbowPO，一个统一的框架，用于整合和提升 Direct Preference Optimization (DPO) 方法的改进组件。通过将现有 DPO 算法的关键元素分类为七个大方向，并将其整合到一个连贯的目标中，该框架有助于更好地理解这些组件的贡献。实验结果显示，RainbowPO 在性能上优于现有 DPO 变体。作者还提供了指导见解，帮助研究者开发新 DPO 方法并辅助实际实施。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04203v2",
      "published_date": "2024-10-05 15:44:46 UTC",
      "updated_date": "2025-03-01 00:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:31:29.406200"
    },
    {
      "arxiv_id": "2410.04199v3",
      "title": "LongGenBench: Long-context Generation Benchmark",
      "title_zh": "LongGenBench：长上下文生成基准测试",
      "authors": [
        "Xiang Liu",
        "Peijie Dong",
        "Xuming Hu",
        "Xiaowen Chu"
      ],
      "abstract": "Current long-context benchmarks primarily focus on retrieval-based tests,\nrequiring Large Language Models (LLMs) to locate specific information within\nextensive input contexts, such as the needle-in-a-haystack (NIAH) benchmark.\nLong-context generation refers to the ability of a language model to generate\ncoherent and contextually accurate text that spans across lengthy passages or\ndocuments. While recent studies show strong performance on NIAH and other\nretrieval-based long-context benchmarks, there is a significant lack of\nbenchmarks for evaluating long-context generation capabilities. To bridge this\ngap and offer a comprehensive assessment, we introduce a synthetic benchmark,\nLongGenBench, which allows for flexible configurations of customized generation\ncontext lengths. LongGenBench advances beyond traditional benchmarks by\nredesigning the format of questions and necessitating that LLMs respond with a\nsingle, cohesive long-context answer. Upon extensive evaluation using\nLongGenBench, we observe that: (1) both API accessed and open source models\nexhibit performance degradation in long-context generation scenarios, ranging\nfrom 1.2% to 47.1%; (2) different series of LLMs exhibit varying trends of\nperformance degradation, with the Gemini-1.5-Flash model showing the least\ndegradation among API accessed models, and the Qwen2 series exhibiting the\nleast degradation in LongGenBench among open source models.",
      "tldr_zh": "该论文指出，现有的长上下文基准主要聚焦于检索任务（如needle-in-a-haystack (NIAH)），而忽略了对Large Language Models (LLMs)生成连贯长文本的能力评估。为填补这一空白，研究者引入了LongGenBench，一个可自定义生成上下文长度的合成基准，通过重设计问题格式，要求LLMs输出单一连贯的答案。实验结果显示，API和开源模型在长上下文生成场景下性能下降幅度从1.2%至47.1%不等，其中Gemini-1.5-Flash在API模型中表现最稳定，Qwen2系列在开源模型中下降最小。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 https://github.com/Dominic789654/LongGenBench",
      "pdf_url": "http://arxiv.org/pdf/2410.04199v3",
      "published_date": "2024-10-05 15:33:25 UTC",
      "updated_date": "2024-10-24 14:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:31:38.357547"
    },
    {
      "arxiv_id": "2410.04191v1",
      "title": "Accelerating Diffusion Models with One-to-Many Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Linfeng Zhang",
        "Kaisheng Ma"
      ],
      "abstract": "Significant advancements in image generation have been made with diffusion\nmodels. Nevertheless, when contrasted with previous generative models,\ndiffusion models face substantial computational overhead, leading to failure in\nreal-time generation. Recent approaches have aimed to accelerate diffusion\nmodels by reducing the number of sampling steps through improved sampling\ntechniques or step distillation. However, the methods to diminish the\ncomputational cost for each timestep remain a relatively unexplored area.\nObserving the fact that diffusion models exhibit varying input distributions\nand feature distributions at different timesteps, we introduce one-to-many\nknowledge distillation (O2MKD), which distills a single teacher diffusion model\ninto multiple student diffusion models, where each student diffusion model is\ntrained to learn the teacher's knowledge for a subset of continuous timesteps.\nExperiments on CIFAR10, LSUN Church, CelebA-HQ with DDPM and COCO30K with\nStable Diffusion show that O2MKD can be applied to previous knowledge\ndistillation and fast sampling methods to achieve significant acceleration.\nCodes will be released in Github.",
      "tldr_zh": "本研究针对扩散模型(diffusion models)在图像生成中的高计算开销问题，提出了一种one-to-many knowledge distillation (O2MKD)方法，该方法将一个教师扩散模型蒸馏到多个学生扩散模型，每个学生模型专门学习教师模型在连续子集时间步的知识，从而减少每个时间步的计算成本。实验在CIFAR10、LSUN Church、CelebA-HQ和COCO30K数据集上进行，结果显示O2MKD能与现有的知识蒸馏和快速采样技术结合，实现显著的加速效果。总体而言，此方法为实时图像生成提供了高效解决方案，并计划在GitHub上发布代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04191v1",
      "published_date": "2024-10-05 15:10:04 UTC",
      "updated_date": "2024-10-05 15:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:32:01.128864"
    },
    {
      "arxiv_id": "2410.04184v1",
      "title": "Non-monotonic Extensions to Formal Concept Analysis via Object Preferences",
      "title_zh": "通过对象偏好对形式概念分析的非单调扩展",
      "authors": [
        "Lucas Carr",
        "Nicholas Leisegang",
        "Thomas Meyer",
        "Sebastian Rudolph"
      ],
      "abstract": "Formal Concept Analysis (FCA) is an approach to creating a conceptual\nhierarchy in which a \\textit{concept lattice} is generated from a\n\\textit{formal context}. That is, a triple consisting of a set of objects, $G$,\na set of attributes, $M$, and an incidence relation $I$ on $G \\times M$. A\n\\textit{concept} is then modelled as a pair consisting of a set of objects (the\n\\textit{extent}), and a set of shared attributes (the \\textit{intent}).\nImplications in FCA describe how one set of attributes follows from another.\nThe semantics of these implications closely resemble that of logical\nconsequence in classical logic. In that sense, it describes a monotonic\nconditional. The contributions of this paper are two-fold. First, we introduce\na non-monotonic conditional between sets of attributes, which assumes a\npreference over the set of objects. We show that this conditional gives rise to\na consequence relation that is consistent with the postulates for\nnon-monotonicty proposed by Kraus, Lehmann, and Magidor (commonly referred to\nas the KLM postulates). We argue that our contribution establishes a strong\ncharacterisation of non-monotonicity in FCA. Typical concepts represent\nconcepts where the intent aligns with expectations from the extent, allowing\nfor an exception-tolerant view of concepts. To this end, we show that the set\nof all typical concepts is a meet semi-lattice of the original concept lattice.\nThis notion of typical concepts is a further introduction of KLM-style\ntypicality into FCA, and is foundational towards developing an algebraic\nstructure representing a concept lattice of prototypical concepts.",
      "tldr_zh": "本论文扩展了 Formal Concept Analysis (FCA)，通过引入对象偏好来处理其原本单调的属性含义关系，构建一种非单调条件。研究者证明，这种条件符合 Kraus, Lehmann, and Magidor (KLM) 的非单调假设，从而为 FCA 提供了更强的非单调性表征。论文进一步定义了典型概念（typical concepts），这些概念对异常具有容忍性，并证明它们在原概念格中形成一个 meet semi-lattice，为开发基于原型的概念格代数结构奠定基础。总的来说，此工作增强了 FCA 在处理不确定性和偏好方面的能力。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04184v1",
      "published_date": "2024-10-05 15:01:00 UTC",
      "updated_date": "2024-10-05 15:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:32:14.035695"
    },
    {
      "arxiv_id": "2410.16285v1",
      "title": "Assessing the Performance of Human-Capable LLMs -- Are LLMs Coming for Your Job?",
      "title_zh": "评估具备人类能力的LLMs性能——LLMs会抢走你的工作吗？",
      "authors": [
        "John Mavi",
        "Nathan Summers",
        "Sergio Coronado"
      ],
      "abstract": "The current paper presents the development and validation of SelfScore, a\nnovel benchmark designed to assess the performance of automated Large Language\nModel (LLM) agents on help desk and professional consultation tasks. Given the\nincreasing integration of AI in industries, particularly within customer\nservice, SelfScore fills a crucial gap by enabling the comparison of automated\nagents and human workers. The benchmark evaluates agents on problem complexity\nand response helpfulness, ensuring transparency and simplicity in its scoring\nsystem. The study also develops automated LLM agents to assess SelfScore and\nexplores the benefits of Retrieval-Augmented Generation (RAG) for\ndomain-specific tasks, demonstrating that automated LLM agents incorporating\nRAG outperform those without. All automated LLM agents were observed to perform\nbetter than the human control group. Given these results, the study raises\nconcerns about the potential displacement of human workers, especially in areas\nwhere AI technologies excel. Ultimately, SelfScore provides a foundational tool\nfor understanding the impact of AI in help desk environments while advocating\nfor ethical considerations in the ongoing transition towards automation.",
      "tldr_zh": "本论文开发了SelfScore基准，用于评估LLM代理在帮助台和专业咨询任务中的表现，并与人类工作者进行比较。\nSelfScore通过评估问题复杂性和响应帮助性，提供一个透明简单的评分系统，同时探索了RAG（Retrieval-Augmented Generation）技术的益处，发现使用RAG的自动化LLM代理表现更优越。\n实验结果显示，所有自动化LLM代理均优于人类对照组，这引发了对AI可能取代人类工作的担忧。\n最终，SelfScore作为基础工具，帮助理解AI在帮助台环境中的影响，并强调了自动化转型中的伦理考虑。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16285v1",
      "published_date": "2024-10-05 14:37:35 UTC",
      "updated_date": "2024-10-05 14:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:32:34.058771"
    },
    {
      "arxiv_id": "2410.04171v2",
      "title": "IV-Mixed Sampler: Leveraging Image Diffusion Models for Enhanced Video Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Shitong Shao",
        "Zikai Zhou",
        "Lichen Bai",
        "Haoyi Xiong",
        "Zeke Xie"
      ],
      "abstract": "The multi-step sampling mechanism, a key feature of visual diffusion models,\nhas significant potential to replicate the success of OpenAI's Strawberry in\nenhancing performance by increasing the inference computational cost.\nSufficient prior studies have demonstrated that correctly scaling up\ncomputation in the sampling process can successfully lead to improved\ngeneration quality, enhanced image editing, and compositional generalization.\nWhile there have been rapid advancements in developing inference-heavy\nalgorithms for improved image generation, relatively little work has explored\ninference scaling laws in video diffusion models (VDMs). Furthermore, existing\nresearch shows only minimal performance gains that are perceptible to the naked\neye. To address this, we design a novel training-free algorithm IV-Mixed\nSampler that leverages the strengths of image diffusion models (IDMs) to assist\nVDMs surpass their current capabilities. The core of IV-Mixed Sampler is to use\nIDMs to significantly enhance the quality of each video frame and VDMs ensure\nthe temporal coherence of the video during the sampling process. Our\nexperiments have demonstrated that IV-Mixed Sampler achieves state-of-the-art\nperformance on 4 benchmarks including UCF-101-FVD, MSR-VTT-FVD,\nChronomagic-Bench-150, and Chronomagic-Bench-1649. For example, the open-source\nAnimatediff with IV-Mixed Sampler reduces the UMT-FVD score from 275.2 to\n228.6, closing to 223.1 from the closed-source Pika-2.0.",
      "tldr_zh": "本论文提出了 IV-Mixed Sampler，一种无训练算法，利用 Image Diffusion Models (IDMs) 来提升 Video Diffusion Models (VDMs) 的视频合成性能，旨在通过增加推理计算成本解决 VDMs 在生成质量和时序连贯性上的局限。\n该算法的核心机制是使用 IDMs 增强每个视频帧的质量，同时由 VDMs 确保视频的整体时序一致性，从而实现训练-free 的性能提升。\n实验结果显示，IV-Mixed Sampler 在 UCF-101-FVD、MSR-VTT-FVD 和 Chronomagic-Bench 等 4 个基准上达到了最先进水平，例如将 Animatediff 的 UMT-FVD 分数从 275.2 降低到 228.6，接近闭源模型 Pika-2.0 的 223.1。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04171v2",
      "published_date": "2024-10-05 14:33:28 UTC",
      "updated_date": "2024-10-08 03:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:32:39.619927"
    },
    {
      "arxiv_id": "2410.04154v2",
      "title": "Applying Quantum Autoencoders for Time Series Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Robin Frehner",
        "Kurt Stockinger"
      ],
      "abstract": "Anomaly detection is an important problem with applications in various\ndomains such as fraud detection, pattern recognition or medical diagnosis.\nSeveral algorithms have been introduced using classical computing approaches.\nHowever, using quantum computing for solving anomaly detection problems in time\nseries data is a widely unexplored research field.\n  This paper explores the application of quantum autoencoders to time series\nanomaly detection. We investigate two primary techniques for classifying\nanomalies: (1) Analyzing the reconstruction error generated by the quantum\nautoencoder and (2) latent representation analysis. Our simulated experimental\nresults, conducted across various ansaetze, demonstrate that quantum\nautoencoders consistently outperform classical deep learning-based autoencoders\nacross multiple datasets. Specifically, quantum autoencoders achieve superior\nanomaly detection performance while utilizing 60-230 times fewer parameters and\nrequiring five times fewer training iterations. In addition, we implement our\nquantum encoder on real quantum hardware. Our experimental results demonstrate\nthat quantum autoencoders achieve anomaly detection performance on par with\ntheir simulated counterparts.",
      "tldr_zh": "本研究探讨了量子自编码器（quantum autoencoders）在时间序列异常检测中的应用，以解决这一领域的未充分探索问题。论文调查了两种主要技术：分析重建错误（reconstruction error）和潜在表示分析（latent representation analysis），并通过模拟实验在多个数据集上进行测试。结果显示，量子自编码器比经典深度学习自编码器表现出色，实现更高的异常检测性能，同时使用60-230倍更少的参数和五倍更少的训练迭代。此外，在真实量子硬件上的实现证明了其性能与模拟结果相当，为量子计算在异常检测领域的潜力提供了实证支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04154v2",
      "published_date": "2024-10-05 13:29:25 UTC",
      "updated_date": "2024-10-09 13:56:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:32:48.073083"
    },
    {
      "arxiv_id": "2410.04153v1",
      "title": "Neuro-Symbolic Entity Alignment via Variational Inference",
      "title_zh": "基于变分推理的神经符号实体对齐",
      "authors": [
        "Shengyuan Chen",
        "Qinggang Zhang",
        "Junnan Dong",
        "Wen Hua",
        "Jiannong Cao",
        "Xiao Huang"
      ],
      "abstract": "Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying\nequivalent entity pairs. Existing methods can be categorized into symbolic and\nneural models. Symbolic models, while precise, struggle with substructure\nheterogeneity and sparsity, whereas neural models, although effective,\ngenerally lack interpretability and cannot handle uncertainty. We propose\nNeuSymEA, a probabilistic neuro-symbolic framework that combines the strengths\nof both methods. NeuSymEA models the joint probability of all possible pairs'\ntruth scores in a Markov random field, regulated by a set of rules, and\noptimizes it with the variational EM algorithm. In the E-step, a neural model\nparameterizes the truth score distributions and infers missing alignments. In\nthe M-step, the rule weights are updated based on the observed and inferred\nalignments. To facilitate interpretability, we further design a\npath-ranking-based explainer upon this framework that generates supporting\nrules for the inferred alignments. Experiments on benchmarks demonstrate that\nNeuSymEA not only significantly outperforms baselines in terms of effectiveness\nand robustness, but also provides interpretable results.",
      "tldr_zh": "本文提出NeuSymEA，一种概率神经符号框架，用于实体对齐（Entity Alignment），旨在结合符号模型的精确性和神经模型的有效性，同时解决子结构异质性、稀疏性和不确定性问题。该框架在Markov Random Field中建模所有可能配对的真值分数联合概率，并通过变分EM算法的E-step（神经模型推断缺失对齐）和M-step（更新规则权重）进行优化，同时引入基于路径排名的解释器以提升结果的可解释性。实验结果表明，NeuSymEA在基准测试中显著优于基线方法，在有效性和鲁棒性方面表现出色，并提供可解释的输出。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04153v1",
      "published_date": "2024-10-05 13:29:22 UTC",
      "updated_date": "2024-10-05 13:29:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:33:00.674800"
    },
    {
      "arxiv_id": "2410.04152v1",
      "title": "DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Falah Rad",
        "Kamrad Khoshhal Roudposhti",
        "Mohammad Hassan Khoobkar",
        "Mohsen Shirali",
        "Zahra Ahmadi",
        "Carlos Fernandez-Llatas"
      ],
      "abstract": "The growth in the elderly population and the shift in the age pyramid have\nincreased the demand for healthcare and well-being services. To address this\nconcern, alongside the rising cost of medical care, the concept of ageing at\nhome has emerged, driven by recent advances in medical and technological\nsolutions. Experts in computer science, communication technology, and\nhealthcare have collaborated to develop affordable health solutions by\nemploying sensors in living environments, wearable devices, and smartphones, in\nassociation with advanced data mining and intelligent systems with learning\ncapabilities, to monitor, analyze, and predict the health status of elderly\nindividuals. However, implementing intelligent healthcare systems and\ndeveloping analytical techniques requires testing and evaluating algorithms on\nreal-world data. Despite the need, there is a shortage of publicly available\ndatasets that meet these requirements. To address this gap, we present the\nDAMMI dataset in this work, designed to support researchers in the field. The\ndataset includes daily activity data of an elderly individual collected via\nhome-installed sensors, smartphone data, and a wristband over 146 days. It also\ncontains daily psychological reports provided by a team of psychologists.\nFurthermore, the data collection spans significant events such as the COVID-19\npandemic, New Year's holidays, and the religious month of Ramadan, offering\nadditional opportunities for analysis. In this paper, we outline detailed\ninformation about the data collection system, the types of data recorded, and\npre-processed event logs. This dataset is intended to assist professionals in\nIoT and data mining in evaluating and implementing their research ideas.",
      "tldr_zh": "该研究介绍了DAMMI数据集，这是一个多模态IoT数据集，旨在支持智能医疗系统的开发，以应对老龄化人口的医疗需求。数据集收集了146天内一位老年人的日常活动数据，包括家庭传感器、智能手机和腕带记录的信息，以及心理学家提供的日常心理报告，并覆盖了特殊事件如COVID-19大流行、新年假期和斋月。DAMMI数据集通过提供真实世界数据，帮助IoT和数据挖掘研究者测试和评估算法，推动健康状态监测和预测技术的进步。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.04152v1",
      "published_date": "2024-10-05 13:26:54 UTC",
      "updated_date": "2024-10-05 13:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:33:11.574292"
    },
    {
      "arxiv_id": "2410.05323v1",
      "title": "From Incomplete Coarse-Grained to Complete Fine-Grained: A Two-Stage Framework for Spatiotemporal Data Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Sun",
        "Haoyang Su",
        "En Wang",
        "Funing Yang",
        "Yongjian Yang",
        "Wenbin Liu"
      ],
      "abstract": "With the rapid development of various sensing devices, spatiotemporal data is\nbecoming increasingly important nowadays. However, due to sensing costs and\nprivacy concerns, the collected data is often incomplete and coarse-grained,\nlimiting its application to specific tasks. To address this, we propose a new\ntask called spatiotemporal data reconstruction, which aims to infer complete\nand fine-grained data from sparse and coarse-grained observations. To achieve\nthis, we introduce a two-stage data inference framework, DiffRecon, grounded in\nthe Denoising Diffusion Probabilistic Model (DDPM). In the first stage, we\npresent Diffusion-C, a diffusion model augmented by ST-PointFormer, a powerful\nencoder designed to leverage the spatial correlations between sparse data\npoints. Following this, the second stage introduces Diffusion-F, which\nincorporates the proposed T-PatternNet to capture the temporal pattern within\nsequential data. Together, these two stages form an end-to-end framework\ncapable of inferring complete, fine-grained data from incomplete and\ncoarse-grained observations. We conducted experiments on multiple real-world\ndatasets to demonstrate the superiority of our method.",
      "tldr_zh": "该研究针对时空数据的不完整性和粗粒度问题，提出了一种新的任务——时空数据重建，并引入了基于Denoising Diffusion Probabilistic Model (DDPM)的两阶段框架DiffRecon，用于从稀疏粗粒度观测推断出完整细粒度数据。在第一阶段，Diffusion-C利用ST-PointFormer编码器捕捉稀疏数据点之间的空间相关性；在第二阶段，Diffusion-F则通过T-PatternNet捕获序列数据中的时间模式，形成一个端到端的推理框架。实验在多个真实数据集上验证了该方法的优越性，展示了其在处理不完整时空数据方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.05323v1",
      "published_date": "2024-10-05 13:16:53 UTC",
      "updated_date": "2024-10-05 13:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:33:23.665991"
    },
    {
      "arxiv_id": "2410.04148v1",
      "title": "Reasoning with Natural Language Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Valentino",
        "André Freitas"
      ],
      "abstract": "Explanation constitutes an archetypal feature of human rationality,\nunderpinning learning and generalisation, and representing one of the media\nsupporting scientific discovery and communication. Due to the importance of\nexplanations in human reasoning, an increasing amount of research in Natural\nLanguage Inference (NLI) has started reconsidering the role that explanations\nplay in learning and inference, attempting to build explanation-based NLI\nmodels that can effectively encode and use natural language explanations on\ndownstream tasks. Research in explanation-based NLI, however, presents specific\nchallenges and opportunities, as explanatory reasoning reflects aspects of both\nmaterial and formal inference, making it a particularly rich setting to model\nand deliver complex reasoning. In this tutorial, we provide a comprehensive\nintroduction to the field of explanation-based NLI, grounding this discussion\non the epistemological-linguistic foundations of explanations, systematically\ndescribing the main architectural trends and evaluation methodologies that can\nbe used to build systems capable of explanatory reasoning.",
      "tldr_zh": "这篇论文探讨了自然语言解释(Natural Language Explanations)在人类理性中的核心作用，特别是其在学习、泛化和科学发现中的重要性。作者重新审视了解释在自然语言推理(NLI)中的应用，旨在开发基于解释的NLI模型，这些模型能有效编码和利用解释来进行下游任务。教程系统地介绍了解释的认识论-语言学基础、主要架构趋势以及评估方法，以构建支持复杂推理的系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Tutorial to be presented at EMNLP 2024. Website:\n  https://sites.google.com/view/reasoning-with-explanations",
      "pdf_url": "http://arxiv.org/pdf/2410.04148v1",
      "published_date": "2024-10-05 13:15:24 UTC",
      "updated_date": "2024-10-05 13:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:33:37.121658"
    },
    {
      "arxiv_id": "2410.04139v2",
      "title": "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Eunseong Choi",
        "Sunkyung Lee",
        "Minjin Choi",
        "June Park",
        "Jongwuk Lee"
      ],
      "abstract": "Large language models (LLMs) have achieved significant performance gains\nusing advanced prompting techniques over various tasks. However, the increasing\nlength of prompts leads to high computational costs and often obscures crucial\ninformation. Prompt compression has been proposed to alleviate these issues,\nbut it faces challenges in (i) capturing the global context and (ii) training\nthe compressor effectively. To tackle these challenges, we introduce a novel\nprompt compression method, namely Reading To Compressing (R2C), utilizing the\nFusion-in-Decoder (FiD) architecture to identify the important information in\nthe prompt. Specifically, the cross-attention scores of the FiD are used to\ndiscern essential chunks and sentences from the prompt. R2C effectively\ncaptures the global context without compromising semantic consistency while\ndetouring the necessity of pseudo-labels for training the compressor. Empirical\nresults show that R2C retains key contexts, enhancing the LLM performance by 6%\nin out-of-domain evaluations while reducing the prompt length by 80%.",
      "tldr_zh": "大型语言模型 (LLMs) 在使用高级提示技术时面临提示长度增加导致的高计算成本和关键信息模糊的问题，为此，本文提出了一种新方法 Reading To Compressing (R2C)。R2C 利用 Fusion-in-Decoder (FiD) 架构，通过跨注意力分数来识别提示中的重要块和句子，从而有效捕获全局上下文、保持语义一致性，且无需伪标签来训练压缩器。实验结果表明，R2C 在域外评估中提升了 LLM 性能 6%，同时将提示长度减少 80%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of the Association for Computational Linguistics: EMNLP\n  2024; 21 pages; 10 figures and 7 tables. Code available at\n  https://github.com/eunseongc/R2C",
      "pdf_url": "http://arxiv.org/pdf/2410.04139v2",
      "published_date": "2024-10-05 12:27:47 UTC",
      "updated_date": "2024-12-31 07:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:33:59.386784"
    },
    {
      "arxiv_id": "2410.04135v1",
      "title": "IceCloudNet: 3D reconstruction of cloud ice from Meteosat SEVIRI",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Jeggle",
        "Mikolaj Czerkawski",
        "Federico Serva",
        "Bertrand Le Saux",
        "David Neubauer",
        "Ulrike Lohmann"
      ],
      "abstract": "IceCloudNet is a novel method based on machine learning able to predict\nhigh-quality vertically resolved cloud ice water contents (IWC) and ice crystal\nnumber concentrations (N$_\\textrm{ice}$). The predictions come at the\nspatio-temporal coverage and resolution of geostationary satellite observations\n(SEVIRI) and the vertical resolution of active satellite retrievals (DARDAR).\nIceCloudNet consists of a ConvNeXt-based U-Net and a 3D PatchGAN discriminator\nmodel and is trained by predicting DARDAR profiles from co-located SEVIRI\nimages. Despite the sparse availability of DARDAR data due to its narrow\noverpass, IceCloudNet is able to predict cloud occurrence, spatial structure,\nand microphysical properties with high precision. The model has been applied to\nten years of SEVIRI data, producing a dataset of vertically resolved IWC and\nN$_\\textrm{ice}$ of clouds containing ice with a 3 kmx3 kmx240 mx15 minute\nresolution in a spatial domain of 30{\\deg}W to 30{\\deg}E and 30{\\deg}S to\n30{\\deg}N. The produced dataset increases the availability of vertical cloud\nprofiles, for the period when DARDAR is available, by more than six orders of\nmagnitude and moreover, IceCloudNet is able to produce vertical cloud profiles\nbeyond the lifetime of the recently ended satellite missions underlying DARDAR.",
      "tldr_zh": "IceCloudNet 是一种基于机器学习的方法，用于从 Meteosat SEVIRI 卫星数据重建云冰的 3D 结构，预测高质量的垂直分辨率云冰水含量 (IWC) 和冰晶数浓度 (N$_\\textrm{ice}$)。该框架结合 ConvNeXt-based U-Net 和 3D PatchGAN 判别器模型，通过训练 SEVIRI 图像预测 DARDAR 配置文件，实现高精度云发生、空间结构和微物理属性的预测。实验应用到十年 SEVIRI 数据，生成了一个高分辨率数据集（3 km x 3 km x 240 m x 15 分钟），将垂直云配置文件可用性提高了六个数量级以上，并能在 DARDAR 卫星使命结束后继续扩展应用。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.CV",
        "J.2"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "his paper was submitted to Artificial Intelligence for the Earth\n  Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.04135v1",
      "published_date": "2024-10-05 12:15:38 UTC",
      "updated_date": "2024-10-05 12:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:34:03.638811"
    },
    {
      "arxiv_id": "2410.04133v3",
      "title": "An Electrocardiogram Foundation Model Built on over 10 Million Recordings with External Evaluation across Multiple Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Li",
        "Aaron Aguirre",
        "Junior Moura",
        "Che Liu",
        "Lanhai Zhong",
        "Chenxi Sun",
        "Gari Clifford",
        "Brandon Westover",
        "Shenda Hong"
      ],
      "abstract": "Artificial intelligence (AI) has demonstrated significant potential in ECG\nanalysis and cardiovascular disease assessment. Recently, foundation models\nhave played a remarkable role in advancing medical AI. The development of an\nECG foundation model holds the promise of elevating AI-ECG research to new\nheights. However, building such a model faces several challenges, including\ninsufficient database sample sizes and inadequate generalization across\nmultiple domains. Additionally, there is a notable performance gap between\nsingle-lead and multi-lead ECG analyses. We introduced an ECG Foundation Model\n(ECGFounder), a general-purpose model that leverages real-world ECG annotations\nfrom cardiology experts to broaden the diagnostic capabilities of ECG analysis.\nECGFounder was trained on over 10 million ECGs with 150 label categories from\nthe Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease\ndiagnosis through ECG analysis. The model is designed to be both an effective\nout-of-the-box solution, and a to be fine-tunable for downstream tasks,\nmaximizing usability. Importantly, we extended its application to lower rank\nECGs, and arbitrary single-lead ECGs in particular. ECGFounder is applicable to\nsupporting various downstream tasks in mobile monitoring scenarios.\nExperimental results demonstrate that ECGFounder achieves expert-level\nperformance on internal validation sets, with AUROC exceeding 0.95 for eighty\ndiagnoses. It also shows strong classification performance and generalization\nacross various diagnoses on external validation sets. When fine-tuned,\nECGFounder outperforms baseline models in demographic analysis, clinical event\ndetection, and cross-modality cardiac rhythm diagnosis. The trained model and\ndata will be publicly released upon publication through the bdsp.io. Our code\nis available at https://github.com/PKUDigitalHealth/ECGFounder",
      "tldr_zh": "这篇论文引入了 ECGFounder，一种基于超过 1000 万 ECG 记录的通用基础模型，旨在提升心电图分析和心血管疾病诊断能力。模型利用真实世界的心电图专家注释进行训练，支持单导联和多导联分析，并设计为即用型解决方案或通过 fine-tuning 适应下游任务，如人口统计分析和临床事件检测。实验结果显示，ECGFounder 在内部验证集上 AUROC 超过 0.95，并在外部验证集上表现出色，泛化能力强，且在微调后超越基线模型。该模型及其数据将通过公开渠道发布，促进医疗 AI 研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/PKUDigitalHealth/ECGFounder",
      "pdf_url": "http://arxiv.org/pdf/2410.04133v3",
      "published_date": "2024-10-05 12:12:02 UTC",
      "updated_date": "2025-04-03 08:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:34:14.544815"
    },
    {
      "arxiv_id": "2410.04118v2",
      "title": "Riemann Sum Optimization for Accurate Integrated Gradients Computation",
      "title_zh": "Riemann 和优化用于准确的集成梯度计算",
      "authors": [
        "Swadesh Swain",
        "Shree Singhi"
      ],
      "abstract": "Integrated Gradients (IG) is a widely used algorithm for attributing the\noutputs of a deep neural network to its input features. Due to the absence of\nclosed-form integrals for deep learning models, inaccurate Riemann Sum\napproximations are used to calculate IG. This often introduces undesirable\nerrors in the form of high levels of noise, leading to false insights in the\nmodel's decision-making process. We introduce a framework, RiemannOpt, that\nminimizes these errors by optimizing the sample point selection for the Riemann\nSum. Our algorithm is highly versatile and applicable to IG as well as its\nderivatives like Blur IG and Guided IG. RiemannOpt achieves up to 20%\nimprovement in Insertion Scores. Additionally, it enables its users to curtail\ncomputational costs by up to four folds, thereby making it highly functional\nfor constrained environments.",
      "tldr_zh": "这篇论文针对 Integrated Gradients (IG) 在深度神经网络输出归因中的计算问题，指出传统的 Riemann Sum 近似方法会导致高噪声和错误洞见。作者提出 RiemannOpt 框架，通过优化采样点选择来最小化这些错误，使其适用于 IG 及其衍生版本如 Blur IG 和 Guided IG。实验结果显示，该框架可将 Insertion Scores 提高多达 20%，并将计算成本减少多达四倍，从而适用于资源受限的环境。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Interpretable AI: Past, Present and Future Workshop at\n  NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04118v2",
      "published_date": "2024-10-05 10:57:13 UTC",
      "updated_date": "2025-01-05 15:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:34:26.395032"
    },
    {
      "arxiv_id": "2410.04114v1",
      "title": "Transport-Embedded Neural Architecture: Redefining the Landscape of physics aware neural models in fluid mechanics",
      "title_zh": "翻译失败",
      "authors": [
        "Amirmahdi Jafari"
      ],
      "abstract": "This work introduces a new neural model which follows the transport equation\nby design. A physical problem, the Taylor-Green vortex, defined on a\nbi-periodic domain, is used as a benchmark to evaluate the performance of both\nthe standard physics-informed neural network and our model (transport-embedded\nneural network). Results exhibit that while the standard physics-informed\nneural network fails to predict the solution accurately and merely returns the\ninitial condition for the entire time span, our model successfully captures the\ntemporal changes in the physics, particularly for high Reynolds numbers of the\nflow. Additionally, the ability of our model to prevent false minima can pave\nthe way for addressing multiphysics problems, which are more prone to false\nminima, and help them accurately predict complex physics.",
      "tldr_zh": "这篇论文提出了一种新的神经架构——transport-embedded neural architecture，它从设计上遵循传输方程（transport equation），旨在提升物理感知神经模型在流体力学中的性能。研究以 Taylor-Green vortex 为基准测试，将该模型与标准 physics-informed neural network (PINN) 进行比较，结果显示 PINN 仅返回初始条件，而新模型能准确捕捉流体物理的时变变化，尤其在高 Reynolds numbers 下。实验证明，该架构能有效防止假最小值（false minima），为处理多物理问题和复杂物理预测提供更可靠的框架。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04114v1",
      "published_date": "2024-10-05 10:32:51 UTC",
      "updated_date": "2024-10-05 10:32:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:34:38.604741"
    },
    {
      "arxiv_id": "2410.04108v2",
      "title": "Towards Scalable General Utility Reinforcement Learning: Occupancy Approximation, Sample Complexity and Global Optimality",
      "title_zh": "朝着可扩展的一般效用强化学习：占用近似、样本复杂度和全局最优性",
      "authors": [
        "Anas Barakat",
        "Souradip Chakraborty",
        "Peihong Yu",
        "Pratap Tokekar",
        "Amrit Singh Bedi"
      ],
      "abstract": "Reinforcement learning with general utilities has recently gained attention\nthanks to its ability to unify several problems, including imitation learning,\npure exploration, and safe reinforcement learning. However, prior work for\nsolving this general problem in a unified way has only focused on the tabular\nsetting. This is restrictive when considering larger state-action spaces\nbecause of the need to estimate occupancy measures during policy optimization.\nIn this work, we address this issue and propose to approximate occupancy\nmeasures within a function approximation class using maximum likelihood\nestimation (MLE). We propose a simple policy gradient algorithm where an actor\nupdates the policy parameters to maximize the general utility objective whereas\na critic approximates the occupancy measure using MLE. We provide a statistical\ncomplexity analysis showing that our occupancy measure estimation error only\nscales with the dimension of our function approximation class rather than the\nsize of the state action space. Under suitable assumptions, we establish first\norder stationarity and global optimality performance bounds for the proposed\nalgorithm for nonconcave and concave general utilities respectively. We\ncomplement our methodological and theoretical findings with promising empirical\nresults showing the scalability potential of our approach compared to existing\ntabular count-based approaches.",
      "tldr_zh": "本文针对一般效用强化学习（general utility reinforcement learning）的可扩展性问题，提出了一种新方法，通过最大似然估计（MLE）在函数逼近类中近似占用度量（occupancy measures），以克服现有表格设置（tabular setting）的限制。算法采用一个策略梯度算法（policy gradient algorithm），其中演员更新策略参数来最大化效用目标，而评论者使用 MLE 估计占用度量。研究结果显示，该方法的估计误差仅与函数逼近类的维度相关，并为非凹和凹效用建立了性能界限；实验证明其比传统计数方法更具可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "revised version",
      "pdf_url": "http://arxiv.org/pdf/2410.04108v2",
      "published_date": "2024-10-05 10:24:07 UTC",
      "updated_date": "2025-02-26 21:19:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:34:51.642919"
    },
    {
      "arxiv_id": "2410.04098v1",
      "title": "The OCON model: an old but green solution for distributable supervised classification for acoustic monitoring in smart cities",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano Giacomelli",
        "Marco Giordano",
        "Claudia Rinaldi"
      ],
      "abstract": "This paper explores a structured application of the One-Class approach and\nthe One-Class-One-Network model for supervised classification tasks, focusing\non vowel phonemes classification and speakers recognition for the Automatic\nSpeech Recognition (ASR) domain. For our case-study, the ASR model runs on a\nproprietary sensing and lightning system, exploited to monitor acoustic and air\npollution on urban streets. We formalize combinations of pseudo-Neural\nArchitecture Search and Hyper-Parameters Tuning experiments, using an informed\ngrid-search methodology, to achieve classification accuracy comparable to\nnowadays most complex architectures, delving into the speaker recognition and\nenergy efficiency aspects. Despite its simplicity, our model proposal has a\nvery good chance to generalize the language and speaker genders context for\nwidespread applicability in computational constrained contexts, proved by\nrelevant statistical and performance metrics. Our experiments code is openly\naccessible on our GitHub.",
      "tldr_zh": "本论文提出 OCON 模型（One-Class-One-Network），作为一种简单且节能的解决方案，用于分布式监督分类任务，专注于 Automatic Speech Recognition (ASR) 领域的元音音素分类和说话者识别，应用于智能城市的声学和空气污染监控系统。研究通过伪-Neural Architecture Search 和 Hyper-Parameters Tuning 的组合实验，采用 informed grid-search 方法，实现了与复杂架构相当的分类准确率，同时强调了能源效率和说话者识别性能。尽管模型相对简单，它在计算受限环境中显示出良好的泛化性，并通过统计和性能指标验证了其广泛适用性，相关实验代码已在 GitHub 上公开。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "68T05, 68T07, 68T10, 68T30, 68T50",
        "C.2.4; C.2.5; C.2.6; C.3; B.8.2; C.4; D.2.8; D.2.13; H.3.1; I.2.4;\n  I.2.6; I.2.7; I.2.8; I.2.11; I.5.1; I.5.4; I.5.5; J.5; J.7; K.4.0"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at \"IEEE 5th International Symposium on the Internet of\n  Sounds, 30 Sep / 2 Oct 2024, Erlangen, Germany\"",
      "pdf_url": "http://arxiv.org/pdf/2410.04098v1",
      "published_date": "2024-10-05 09:47:54 UTC",
      "updated_date": "2024-10-05 09:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:35:02.837020"
    },
    {
      "arxiv_id": "2410.04096v1",
      "title": "Sinc Kolmogorov-Arnold Network and Its Applications on Physics-informed Neural Networks",
      "title_zh": "Sinc Kolmogorov-Arnold 网络及其",
      "authors": [
        "Tianchi Yu",
        "Jingwei Qiu",
        "Jiang Yang",
        "Ivan Oseledets"
      ],
      "abstract": "In this paper, we propose to use Sinc interpolation in the context of\nKolmogorov-Arnold Networks, neural networks with learnable activation\nfunctions, which recently gained attention as alternatives to multilayer\nperceptron. Many different function representations have already been tried,\nbut we show that Sinc interpolation proposes a viable alternative, since it is\nknown in numerical analysis to represent well both smooth functions and\nfunctions with singularities. This is important not only for function\napproximation but also for the solutions of partial differential equations with\nphysics-informed neural networks. Through a series of experiments, we show that\nSincKANs provide better results in almost all of the examples we have\nconsidered.",
      "tldr_zh": "本文提出使用 Sinc 插值应用于 Kolmogorov-Arnold Networks（一种具有可学习激活函数的神经网络），作为多层感知器的替代方案，以更好地表示平滑函数和具有奇点的函数。Sinc 插值在数值分析中表现出色，不仅提升函数逼近能力，还适用于 Physics-informed Neural Networks 求解偏微分方程。通过一系列实验，SincKANs 在几乎所有测试案例中均提供了比传统方法更优的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "cs.NE",
        "math.NA",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04096v1",
      "published_date": "2024-10-05 09:33:39 UTC",
      "updated_date": "2024-10-05 09:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:35:18.464397"
    },
    {
      "arxiv_id": "2410.05320v1",
      "title": "The OCON model: an old but gold solution for distributable supervised classification",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano Giacomelli",
        "Marco Giordano",
        "Claudia Rinaldi"
      ],
      "abstract": "This paper introduces to a structured application of the One-Class approach\nand the One-Class-One-Network model for supervised classification tasks,\nspecifically addressing a vowel phonemes classification case study within the\nAutomatic Speech Recognition research field. Through pseudo-Neural Architecture\nSearch and Hyper-Parameters Tuning experiments conducted with an informed\ngrid-search methodology, we achieve classification accuracy comparable to\nnowadays complex architectures (90.0 - 93.7%). Despite its simplicity, our\nmodel prioritizes generalization of language context and distributed\napplicability, supported by relevant statistical and performance metrics. The\nexperiments code is openly available at our GitHub.",
      "tldr_zh": "这篇论文介绍了 One-Class 方法和 One-Class-One-Network (OCON) 模型在监督分类任务中的结构化应用，特别针对 Automatic Speech Recognition 领域中的元音音素分类案例。研究者通过 pseudo-Neural Architecture Search 和 Hyper-Parameters Tuning 的实验，利用知情网格搜索方法，实现了与现代复杂架构相当的分类准确率（90.0% - 93.7%）。尽管模型简单，该方法强调了语言上下文的泛化能力和分布式适用性，并提供了相关的统计指标和开源实验代码。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG",
        "cs.SD",
        "68T07, 68T09, 68T10, 68T50, 91F20",
        "I.2.7; I.2.11; I.5.1; I.5.2; I.5.5; J.5; E.4; D.2.7; D.2.13"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at \"2024 29th IEEE Symposium on Computers and Communications\n  (ISCC): workshop on Next-Generation Multimedia Services at the Edge:\n  Leveraging 5G and Beyond (NGMSE2024)\". arXiv admin note: text overlap with\n  arXiv:2410.04098",
      "pdf_url": "http://arxiv.org/pdf/2410.05320v1",
      "published_date": "2024-10-05 09:15:01 UTC",
      "updated_date": "2024-10-05 09:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:35:27.894197"
    },
    {
      "arxiv_id": "2410.04087v1",
      "title": "GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Yangfan Ye",
        "Xiachong Feng",
        "Xiaocheng Feng",
        "Weitao Ma",
        "Libo Qin",
        "Dongliang Xu",
        "Qing Yang",
        "Hongtao Liu",
        "Bing Qin"
      ],
      "abstract": "News summarization in today's global scene can be daunting with its flood of\nmultilingual content and varied viewpoints from different sources. However,\ncurrent studies often neglect such real-world scenarios as they tend to focus\nsolely on either single-language or single-document tasks. To bridge this gap,\nwe aim to unify Multi-lingual, Cross-lingual and Multi-document Summarization\ninto a novel task, i.e., MCMS, which encapsulates the real-world requirements\nall-in-one. Nevertheless, the lack of a benchmark inhibits researchers from\nadequately studying this invaluable problem. To tackle this, we have\nmeticulously constructed the GLOBESUMM dataset by first collecting a wealth of\nmultilingual news reports and restructuring them into event-centric format.\nAdditionally, we introduce the method of protocol-guided prompting for\nhigh-quality and cost-effective reference annotation. In MCMS, we also\nhighlight the challenge of conflicts between news reports, in addition to the\nissues of redundancies and omissions, further enhancing the complexity of\nGLOBESUMM. Through extensive experimental analysis, we validate the quality of\nour dataset and elucidate the inherent challenges of the task. We firmly\nbelieve that GLOBESUMM, given its challenging nature, will greatly contribute\nto the multilingual communities and the evaluation of LLMs.",
      "tldr_zh": "该论文提出一个新的任务MCMS（Multi-lingual, Cross-lingual and Multi-document Summarization），旨在统一多语言、跨语言和多文档新闻摘要，以应对真实世界新闻洪流中的多样化挑战。研究者构建了GLOBESUMM数据集，通过收集多语言新闻报道并重组为事件中心格式，同时引入protocol-guided prompting方法，实现高质量且低成本的参考标注。实验结果验证了数据集的可靠性，并强调了MCMS任务中新闻冲突、冗余和遗漏问题的复杂性，这将为多语言社区和LLMs评估带来重大贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 main conference, long paper",
      "pdf_url": "http://arxiv.org/pdf/2410.04087v1",
      "published_date": "2024-10-05 08:56:44 UTC",
      "updated_date": "2024-10-05 08:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:35:39.142791"
    },
    {
      "arxiv_id": "2410.04084v1",
      "title": "Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance",
      "title_zh": "翻译失败",
      "authors": [
        "Pankhi Kashyap",
        "Pavni Tandon",
        "Sunny Gupta",
        "Abhishek Tiwari",
        "Ritwik Kulkarni",
        "Kshitij Sharad Jadhav"
      ],
      "abstract": "Long-tailed problems in healthcare emerge from data imbalance due to\nvariability in the prevalence and representation of different medical\nconditions, warranting the requirement of precise and dependable classification\nmethods. Traditional loss functions such as cross-entropy and binary\ncross-entropy are often inadequate due to their inability to address the\nimbalances between the classes with high representation and the classes with\nlow representation found in medical image datasets. We introduce a novel\npolynomial loss function based on Pade approximation, designed specifically to\novercome the challenges associated with long-tailed classification. This\napproach incorporates asymmetric sampling techniques to better classify\nunder-represented classes. We conducted extensive evaluations on three publicly\navailable medical datasets and a proprietary medical dataset. Our\nimplementation of the proposed loss function is open-sourced in the public\nrepository:https://github.com/ipankhi/ALPA.",
      "tldr_zh": "该论文针对医疗图像数据集中的 long-tailed class imbalance 问题，提出了一种基于 Pade approximation 的新多项式损失函数，以解决传统损失函数（如 cross-entropy 和 binary cross-entropy）无法有效处理类别不平衡的挑战。该方法结合 asymmetric sampling 技术，优先改善 underrepresented classes 的分类性能。通过在三个公开医疗数据集和一个私有数据集上的广泛评估，实验结果证明了该方法的有效性。该实现已开源在 GitHub 仓库（https://github.com/ipankhi/ALPA），为医疗图像分类提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10; I.4.0; I.4.1; I.4.2; I.4.6; I.4.7; I.4.8; I.4.9; I.4.10;\n  I.2.10; I.5.1; I.5.2; I.5.4; J.2; I.2.6; I.2.11; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 1 figures. Accepted in The 35th British Machine Vision\n  Conference (BMVC24)",
      "pdf_url": "http://arxiv.org/pdf/2410.04084v1",
      "published_date": "2024-10-05 08:49:33 UTC",
      "updated_date": "2024-10-05 08:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:35:50.464907"
    },
    {
      "arxiv_id": "2410.04081v3",
      "title": "Epsilon-VAE: Denoising as Visual Decoding",
      "title_zh": "ε-VAE：将去噪视为视觉解码",
      "authors": [
        "Long Zhao",
        "Sanghyun Woo",
        "Ziyu Wan",
        "Yandong Li",
        "Han Zhang",
        "Boqing Gong",
        "Hartwig Adam",
        "Xuhui Jia",
        "Ting Liu"
      ],
      "abstract": "In generative modeling, tokenization simplifies complex data into compact,\nstructured representations, creating a more efficient, learnable space. For\nhigh-dimensional visual data, it reduces redundancy and emphasizes key features\nfor high-quality generation. Current visual tokenization methods rely on a\ntraditional autoencoder framework, where the encoder compresses data into\nlatent representations, and the decoder reconstructs the original input. In\nthis work, we offer a new perspective by proposing denoising as decoding,\nshifting from single-step reconstruction to iterative refinement. Specifically,\nwe replace the decoder with a diffusion process that iteratively refines noise\nto recover the original image, guided by the latents provided by the encoder.\nWe evaluate our approach by assessing both reconstruction (rFID) and generation\nquality (FID), comparing it to state-of-the-art autoencoding approaches. By\nadopting iterative reconstruction through diffusion, our autoencoder, namely\n$\\epsilon$-VAE, achieves high reconstruction quality, which in turn enhances\ndownstream generation quality by 22% and provides 2.3$\\times$ inference\nspeedup. We hope this work offers new insights into integrating iterative\ngeneration and autoencoding for improved compression and generation.",
      "tldr_zh": "本文提出 Epsilon-VAE，一种新型 autoencoder 框架，将 denoising 视为视觉解码过程，从传统的单步重建转向迭代精炼。具体方法是用 diffusion process 替换解码器，由编码器提供的 latents 引导，从噪声中逐步恢复原始图像。与现有 autoencoding 方法相比，Epsilon-VAE 显著提高了重建质量（rFID），并将下游生成质量（FID）提升 22%，同时实现 2.3 倍的推理加速。该工作为整合迭代生成和 autoencoding 提供了新见解，以优化视觉数据的压缩和生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. v2: added comparisons to SD-VAE and more visual results",
      "pdf_url": "http://arxiv.org/pdf/2410.04081v3",
      "published_date": "2024-10-05 08:27:53 UTC",
      "updated_date": "2025-02-24 22:54:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:36:02.831045"
    },
    {
      "arxiv_id": "2410.04074v1",
      "title": "On Eliciting Syntax from Language Models via Hashing",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Wang",
        "Masao Utiyama"
      ],
      "abstract": "Unsupervised parsing, also known as grammar induction, aims to infer\nsyntactic structure from raw text. Recently, binary representation has\nexhibited remarkable information-preserving capabilities at both lexicon and\nsyntax levels. In this paper, we explore the possibility of leveraging this\ncapability to deduce parsing trees from raw text, relying solely on the\nimplicitly induced grammars within models. To achieve this, we upgrade the\nbit-level CKY from zero-order to first-order to encode the lexicon and syntax\nin a unified binary representation space, switch training from supervised to\nunsupervised under the contrastive hashing framework, and introduce a novel\nloss function to impose stronger yet balanced alignment signals. Our model\nshows competitive performance on various datasets, therefore, we claim that our\nmethod is effective and efficient enough to acquire high-quality parsing trees\nfrom pre-trained language models at a low cost.",
      "tldr_zh": "这篇论文探讨了通过散列技术从语言模型中提取语法结构的方法，针对无监督解析（unsupervised parsing），即从原始文本中推断语法树。作者升级了 bit-level CKY 从零阶到一阶，将词汇和语法统一编码在二进制表示空间中，并采用对比散列框架（contrastive hashing framework）进行无监督训练，同时引入一个新损失函数以增强平衡的 alignment 信号。实验结果表明，该模型在各种数据集上表现出竞争性性能，能够以低成本从预训练语言模型获取高质量的解析树。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP-2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04074v1",
      "published_date": "2024-10-05 08:06:19 UTC",
      "updated_date": "2024-10-05 08:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:36:14.304587"
    },
    {
      "arxiv_id": "2410.04072v2",
      "title": "MROSS: Multi-Round Region-based Optimization for Scene Sketching",
      "title_zh": "MROSS：多轮次基于区域的优化用于场景素描",
      "authors": [
        "Yiqi Liang",
        "Ying Liu",
        "Dandan Long",
        "Ruihui Li"
      ],
      "abstract": "Scene sketching is to convert a scene into a simplified, abstract\nrepresentation that captures the essential elements and composition of the\noriginal scene. It requires a semantic understanding of the scene and\nconsideration of different regions within the scene. Since scenes often contain\ndiverse visual information across various regions, such as foreground objects,\nbackground elements, and spatial divisions, dealing with these different\nregions poses unique difficulties. In this paper, we define a sketch as some\nsets of B\\'ezier curves because of their smooth and versatile characteristics.\nWe optimize different regions of input scene in multiple rounds. In each\noptimization round, the strokes sampled from the next region can seamlessly be\nintegrated into the sketch generated in the previous optimization round. We\npropose an additional stroke initialization method to ensure the integrity of\nthe scene and the convergence of optimization. A novel CLIP-based Semantic Loss\nand a VGG-based Feature Loss are utilized to guide our multi-round\noptimization. Extensive experimental results on the quality and quantity of the\ngenerated sketches confirm the effectiveness of our method.",
      "tldr_zh": "本论文提出 MROSS 方法，用于将场景转换为简化的抽象表示，即场景素描，通过捕捉本质元素和组成。该方法采用多轮基于区域的优化策略，将场景分成不同区域（如前景对象和背景元素）逐轮处理，使用 Bézier curves 作为平滑的素描表示，并引入笔画初始化方法确保优化完整性和收敛。优化过程结合 CLIP-based Semantic Loss 和 VGG-based Feature Loss 指导生成，大量实验结果显示 MROSS 在生成的素描质量和数量上均表现出色，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04072v2",
      "published_date": "2024-10-05 08:04:26 UTC",
      "updated_date": "2025-04-15 11:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:36:26.670812"
    },
    {
      "arxiv_id": "2410.04070v7",
      "title": "PAD: Personalized Alignment of LLMs at Decoding-Time",
      "title_zh": "翻译失败",
      "authors": [
        "Ruizhe Chen",
        "Xiaotian Zhang",
        "Meng Luo",
        "Wenhao Chai",
        "Zuozhu Liu"
      ],
      "abstract": "Aligning with personalized preferences, which vary significantly across\ncultural, educational, and political differences, poses a significant challenge\ndue to the computational costs and data demands of traditional alignment\nmethods. In response, this paper presents Personalized Alignment at\nDecoding-time (PAD), a novel framework designed to align LLM outputs with\ndiverse personalized preferences during the inference phase, eliminating the\nneed for additional training. By introducing a unique personalized reward\nmodeling strategy, this framework decouples the text generation process from\npersonalized preferences, facilitating the generation of generalizable\ntoken-level personalized rewards. The PAD algorithm leverages these rewards to\nguide the decoding process, dynamically tailoring the base model's predictions\nto personalized preferences. Extensive experimental results demonstrate that\nPAD not only outperforms existing training-based alignment methods in terms of\naligning with diverse preferences but also shows significant generalizability\nto preferences unseen during training and scalability across different base\nmodels. This work advances the capability of LLMs to meet user needs in\nreal-time applications, presenting a substantial step forward in personalized\nLLM alignment.",
      "tldr_zh": "这篇论文提出了 PAD 框架（Personalized Alignment of LLMs at Decoding-Time），旨在在推理阶段对齐大型语言模型（LLMs）的输出，以适应用户多样化的个性化偏好（如文化、教育和政治差异），而无需额外训练，从而克服传统方法的计算成本和数据需求问题。PAD 通过引入独特的个性化奖励模型（personalized reward modeling）将文本生成过程与偏好分离，生成可泛化的 token-level 个性化奖励，并利用这些奖励指导解码过程，实现动态调整。实验结果表明，PAD 不仅在对齐多样偏好方面优于现有基于训练的 alignment 方法，还展现出强大的泛化性（适用于训练中未见的偏好）和可扩展性（跨不同基础模型），为 LLMs 在实时应用中满足用户需求提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.04070v7",
      "published_date": "2024-10-05 08:00:55 UTC",
      "updated_date": "2025-03-13 13:37:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:36:38.680296"
    },
    {
      "arxiv_id": "2410.04068v1",
      "title": "ECon: On the Detection and Resolution of Evidence Conflicts",
      "title_zh": "ECon: 证据冲突的检测与",
      "authors": [
        "Cheng Jiayang",
        "Chunkit Chan",
        "Qianqian Zhuang",
        "Lin Qiu",
        "Tianhang Zhang",
        "Tengxiao Liu",
        "Yangqiu Song",
        "Yue Zhang",
        "Pengfei Liu",
        "Zheng Zhang"
      ],
      "abstract": "The rise of large language models (LLMs) has significantly influenced the\nquality of information in decision-making systems, leading to the prevalence of\nAI-generated content and challenges in detecting misinformation and managing\nconflicting information, or \"inter-evidence conflicts.\" This study introduces a\nmethod for generating diverse, validated evidence conflicts to simulate\nreal-world misinformation scenarios. We evaluate conflict detection methods,\nincluding Natural Language Inference (NLI) models, factual consistency (FC)\nmodels, and LLMs, on these conflicts (RQ1) and analyze LLMs' conflict\nresolution behaviors (RQ2). Our key findings include: (1) NLI and LLM models\nexhibit high precision in detecting answer conflicts, though weaker models\nsuffer from low recall; (2) FC models struggle with lexically similar answer\nconflicts, while NLI and LLM models handle these better; and (3) stronger\nmodels like GPT-4 show robust performance, especially with nuanced conflicts.\nFor conflict resolution, LLMs often favor one piece of conflicting evidence\nwithout justification and rely on internal knowledge if they have prior\nbeliefs.",
      "tldr_zh": "这篇论文介绍了 ECon 方法，用于检测和解决证据冲突，特别是针对大型语言模型（LLMs）引发的虚假信息问题。研究者开发了一种生成多样化、验证过的证据冲突模拟场景的技术，并评估了 Natural Language Inference (NLI) 模型、事实一致性 (FC) 模型和 LLMs 在冲突检测中的性能（RQ1），结果显示 NLI 和 LLM 模型在答案冲突检测上具有高精确度，但较弱模型的召回率较低，而 FC 模型在词汇相似冲突上表现不佳。进一步分析 LLMs 的冲突解决行为（RQ2）发现，更强模型如 GPT-4 处理细微冲突更稳健，但 LLMs 往往偏好某一证据而不提供理由，或依赖内部知识。总体而言，该工作为管理信息冲突提供了关键见解和改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2410.04068v1",
      "published_date": "2024-10-05 07:41:17 UTC",
      "updated_date": "2024-10-05 07:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:37:43.907899"
    },
    {
      "arxiv_id": "2410.04064v2",
      "title": "Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Fatemeh Pesaran Zadeh",
        "Juyeon Kim",
        "Jin-Hwa Kim",
        "Gunhee Kim"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong capabilities across\nvarious language tasks, notably through instruction-tuning methods. However,\nLLMs face challenges in visualizing complex, real-world data through charts and\nplots. Firstly, existing datasets rarely cover a full range of chart types,\nsuch as 3D, volumetric, and gridded charts. Secondly, supervised fine-tuning\nmethods do not fully leverage the intricate relationships within rich datasets,\nincluding text, code, and figures. To address these challenges, we propose a\nhierarchical pipeline and a new dataset for chart generation. Our dataset,\nText2Chart31, includes 31 unique plot types referring to the Matplotlib\nlibrary, with 11.1K tuples of descriptions, code, data tables, and plots.\nMoreover, we introduce a reinforcement learning-based instruction tuning\ntechnique for chart generation tasks without requiring human feedback. Our\nexperiments show that this approach significantly enhances the model\nperformance, enabling smaller models to outperform larger open-source models\nand be comparable to state-of-the-art proprietary models in data visualization\ntasks. We make the code and dataset available at\nhttps://github.com/fatemehpesaran310/Text2Chart31.",
      "tldr_zh": "本研究针对大语言模型(LLMs)在图表生成中的挑战（如图表类型覆盖不足和未充分利用数据集关系），提出一个分层管道(hierarchical pipeline)和新数据集Text2Chart31。Text2Chart31基于Matplotlib库，包含31种独特图表类型和11.1K个元组，包括描述、代码、数据表和图表。作者引入基于强化学习的指令微调技术(reinforcement learning-based instruction tuning)，无需人工反馈，即可显著提升模型性能，使小型模型超越大型开源模型，并在数据可视化任务中媲美最先进专有模型。代码和数据集已在https://github.com/fatemehpesaran310/Text2Chart31开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024 Main Oral. Code and dataset are released at\n  https://github.com/fatemehpesaran310/Text2Chart31",
      "pdf_url": "http://arxiv.org/pdf/2410.04064v2",
      "published_date": "2024-10-05 07:25:56 UTC",
      "updated_date": "2025-02-17 13:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:37:02.421696"
    },
    {
      "arxiv_id": "2410.04061v3",
      "title": "Enhancing Graph Self-Supervised Learning with Graph Interplay",
      "title_zh": "翻译失败",
      "authors": [
        "Xinjian Zhao",
        "Wei Pang",
        "Xiangru Jian",
        "Yaoyao Xu",
        "Chaolong Ying",
        "Tianshu Yu"
      ],
      "abstract": "Graph self-supervised learning (GSSL) has emerged as a compelling framework\nfor extracting informative representations from graph-structured data without\nextensive reliance on labeled inputs. In this study, we introduce Graph\nInterplay (GIP), an innovative and versatile approach that significantly\nenhances the performance equipped with various existing GSSL methods. To this\nend, GIP advocates direct graph-level communications by introducing random\ninter-graph edges within standard batches. Against GIP's simplicity, we further\ntheoretically show that \\textsc{GIP} essentially performs a principled manifold\nseparation via combining inter-graph message passing and GSSL, bringing about\nmore structured embedding manifolds and thus benefits a series of downstream\ntasks. Our empirical study demonstrates that GIP surpasses the performance of\nprevailing GSSL methods across multiple benchmarks by significant margins,\nhighlighting its potential as a breakthrough approach. Besides, GIP can be\nreadily integrated into a series of GSSL methods and consistently offers\nadditional performance gain. This advancement not only amplifies the capability\nof GSSL but also potentially sets the stage for a novel graph learning paradigm\nin a broader sense.",
      "tldr_zh": "本文提出Graph Interplay (GIP)，一种创新方法，用于提升Graph Self-Supervised Learning (GSSL)的性能，通过在标准批次中引入随机inter-graph edges实现直接的graph-level通信。GIP理论上通过结合inter-graph message passing和GSSL，进行principled manifold separation，从而生成更结构化的embedding manifolds，支持下游任务。实验结果显示，GIP在多个基准上显著超越现有GSSL方法，并可轻松整合到各种GSSL框架中，提供额外性能提升。该方法不仅增强了GSSL的能力，还可能开创更广泛的图学习范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Due to potential implicit data leakage in our experimental setup,\n  where the pretraining dataset was ordered by default labels, we withdraw this\n  manuscript for further self-examination and rigorous validation",
      "pdf_url": "http://arxiv.org/pdf/2410.04061v3",
      "published_date": "2024-10-05 07:05:21 UTC",
      "updated_date": "2025-01-16 01:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:37:14.845044"
    },
    {
      "arxiv_id": "2410.04060v3",
      "title": "LoRTA: Low Rank Tensor Adaptation of Large Language Models",
      "title_zh": "LoRTA：大型语言模型的低秩张量适应",
      "authors": [
        "Ignacio Hounie",
        "Charilaos Kanatsoulis",
        "Arnuv Tandon",
        "Alejandro Ribeiro"
      ],
      "abstract": "Low Rank Adaptation (LoRA) is a popular Parameter Efficient Fine Tuning\n(PEFT) method that effectively adapts large pre-trained models for downstream\ntasks. LoRA parameterizes model updates using low-rank matrices at each layer,\nsignificantly reducing the number of trainable parameters and, consequently,\nresource requirements during fine-tuning. However, the lower bound on the\nnumber of trainable parameters remains high due to the use of the low-rank\nmatrix model. Recent works have addressed this limitation by proposing low rank\ntensor parameterizations for model updates. However, they only exploit\nredundancy across layers, or tensorize individual matrices using ad-hoc schemes\nthat introduce additional hyperparameters. In this work, we propose a\nhigher-order Candecomp/Parafac (CP) decomposition, enabling a more compact and\nflexible representation compared to existing matrix and tensor based PEFT\nmethods. Our experiments on Natural Language Understanding, Instruction Tuning,\nPreference Optimization and Protein Folding benchmarks demonstrate that our\nmethod can achieve a reduction in the number of parameters while maintaining\ncomparable performance.",
      "tldr_zh": "该论文提出LoRTA，一种基于低秩张量适配的方法，用于优化大型语言模型的Parameter Efficient Fine Tuning (PEFT)。LoRTA采用higher-order Candecomp/Parafac (CP)分解来参数化模型更新，提供比传统LoRA和现有张量方法更紧凑、灵活的表示，从而进一步减少可训练参数。实验结果显示，在Natural Language Understanding、Instruction Tuning、Preference Optimization和Protein Folding等基准上，LoRTA实现了参数数量的显著降低，同时保持了与基线模型相当的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04060v3",
      "published_date": "2024-10-05 06:59:50 UTC",
      "updated_date": "2025-02-02 17:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:37:26.487808"
    },
    {
      "arxiv_id": "2410.04054v2",
      "title": "Large Language Models can Achieve Social Balance",
      "title_zh": "大型语言模型能够实现社会平衡",
      "authors": [
        "Pedro Cisneros-Velarde"
      ],
      "abstract": "Social balance is a well-established concept in sociology which dictates how\nindividual interactions can lead a population to become one faction of positive\ninteractions or be divided in two or more antagonistic factions. In this paper,\nwe consider a group of large language models (LLMs) and study how, after\ncontinuous interactions, they can achieve social balance. Across three\ndifferent LLM models, we find that achieving social balance depends on (i) the\ntype of interaction; (ii) whether agents consider homophily or influence from\ntheir peers; and (iii) the population size. We characterize how each model\nachieves social balance with different frequency, diversity of positive or\nnegative interactions, and interaction stability across conditions (i) to\n(iii). We show that models achieve different notions of social balance and\njustify their social dynamics differently. Remarkably, the largest model is not\nnecessarily more likely to achieve social balance with more frequency,\nstability, and diversity than the smaller ones.",
      "tldr_zh": "本文研究大型语言模型（LLMs）是否能通过持续互动实现社会平衡，即群体形成正向派系或对立派系的概念。研究者实验了三种LLM模型，考察了互动类型、代理是否考虑homophily（同质性）或同伴影响，以及群体规模等因素对平衡的影响。结果显示，不同模型以不同频率、多样性和稳定性达到社会平衡，且最大模型并不总是更频繁或稳定地实现这一状态，为理解LLMs的社会动态提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA",
        "cs.SI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04054v2",
      "published_date": "2024-10-05 06:23:28 UTC",
      "updated_date": "2025-03-15 01:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:37:37.759772"
    },
    {
      "arxiv_id": "2410.04047v3",
      "title": "Multi-Step Time Series Inference Agent for Reasoning and Automated Task Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Ye",
        "Yizhou Zhang",
        "Wei Yang",
        "Defu Cao",
        "Lumingyuan Tang",
        "Jie Cai",
        "Yan Liu"
      ],
      "abstract": "Time series analysis is crucial in real-world applications, yet traditional\nmethods focus on isolated tasks only, and recent studies on time series\nreasoning remain limited to simple, single-step inference constrained to\nnatural language answer. In this work, we propose a practical novel task:\nmulti-step time series inference that demands both compositional reasoning and\ncomputation precision of time series analysis. To address such challenge, we\npropose a simple but effective program-aided inference agent that leverages\nLLMs' reasoning ability to decompose complex tasks into structured execution\npipelines. By integrating in-context learning, self-correction, and\nprogram-aided execution, our proposed approach ensures accurate and\ninterpretable results. To benchmark performance, we introduce a new dataset and\na unified evaluation framework with task-specific success criteria. Experiments\nshow that our approach outperforms standalone general purpose LLMs in both\nbasic time series concept understanding as well as multi-step time series\ninference task, highlighting the importance of hybrid approaches that combine\nreasoning with computational precision.",
      "tldr_zh": "该论文提出了一种多步时间序列推理任务，旨在解决传统方法仅限于孤立任务和单步推理的局限性，通过结合组合推理和计算精度来处理实际应用中的复杂时间序列分析。研究引入了一个程序辅助推理代理，利用 LLMs 的推理能力，将任务分解为结构化的执行管道，并整合 in-context learning、自校正和 program-aided execution，以确保结果的准确性和可解释性。为此，作者开发了一个新数据集和统一的评估框架，采用任务特定的成功标准。实验结果显示，该方法在基本时间序列概念理解和多步推理任务上优于独立的通用 LLMs，突出了结合推理与计算精度的混合方法的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04047v3",
      "published_date": "2024-10-05 06:04:19 UTC",
      "updated_date": "2025-02-12 00:23:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:37:57.196764"
    },
    {
      "arxiv_id": "2410.05318v1",
      "title": "Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenwen Liang",
        "Ye Liu",
        "Tong Niu",
        "Xiangliang Zhang",
        "Yingbo Zhou",
        "Semih Yavuz"
      ],
      "abstract": "Despite significant advancements in the general capability of large language\nmodels (LLMs), they continue to struggle with consistent and accurate\nreasoning, especially in complex tasks such as mathematical and code reasoning.\nOne key limitation is that LLMs are trained primarily on correct solutions,\nreducing their ability to detect and learn from errors, which hampers their\nability to reliably verify and rank outputs. To address this, we scale up the\ninference-time computation by generating multiple reasoning paths and employing\nverifiers to assess and rank the generated outputs by correctness. To\nfacilitate this, we introduce a comprehensive dataset consisting of correct and\nincorrect solutions for math and code tasks, generated by multiple LLMs. This\ndiverse set of solutions enables verifiers to more effectively distinguish and\nrank correct answers from erroneous outputs. The training methods for building\nverifiers were selected based on an extensive comparison of existing\napproaches. Moreover, to leverage the unique strengths of different reasoning\nstrategies, we propose a novel collaborative method integrating\nChain-of-Thought (CoT) and Program-of-Thought (PoT) solutions for verification.\nCoT provides a clear, step-by-step reasoning process that enhances\ninterpretability, while PoT, being executable, offers a precise and\nerror-sensitive validation mechanism. By taking both of their strengths, our\napproach significantly improves the accuracy and reliability of reasoning\nverification. Our verifiers, Math-Rev and Code-Rev, demonstrate substantial\nperformance gains to existing LLMs, achieving state-of-the-art results on\nbenchmarks such as GSM8k and MATH and even outperforming GPT-4o with\nQwen-72B-Instruct as the reasoner.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在复杂推理任务（如数学和代码）中的不准确问题，提出通过扩展推理计算来生成多条推理路径，并使用协作验证器评估和排名输出，以提升错误检测能力。研究者引入了一个包含正确和错误解决方案的数据集，由多个LLMs生成，并结合Chain-of-Thought (CoT) 的步步推理与Program-of-Thought (PoT) 的可执行验证机制，形成新型协作方法。实验结果显示，该方法显著提升了验证器的性能，Math-Rev 和 Code-Rev 在 GSM8k 和 MATH 等基准上超越了现有模型，甚至以 Qwen-72B-Instruct 作为推理器超过了 GPT-4o。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05318v1",
      "published_date": "2024-10-05 05:21:48 UTC",
      "updated_date": "2024-10-05 05:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:38:09.160023"
    },
    {
      "arxiv_id": "2410.04039v3",
      "title": "BlockFound: Customized blockchain foundation model for anomaly detection",
      "title_zh": "BlockFound：用于异常检测的自定义区块链基础模型",
      "authors": [
        "Jiahao Yu",
        "Xian Wu",
        "Hao Liu",
        "Wenbo Guo",
        "Xinyu Xing"
      ],
      "abstract": "We propose BlockFound, a customized foundation model for anomaly blockchain\ntransaction detection. Unlike existing methods that rely on rule-based systems\nor directly apply off-the-shelf large language models, BlockFound introduces a\nseries of customized designs to model the unique data structure of blockchain\ntransactions. First, a blockchain transaction is multi-modal, containing\nblockchain-specific tokens, texts, and numbers. We design a modularized\ntokenizer to handle these multi-modal inputs, balancing the information across\ndifferent modalities. Second, we design a customized mask language learning\nmechanism for pretraining with RoPE embedding and FlashAttention for handling\nlonger sequences. After training the foundation model, we further design a\nnovel detection method for anomaly detection. Extensive evaluations on Ethereum\nand Solana transactions demonstrate BlockFound's exceptional capability in\nanomaly detection while maintaining a low false positive rate. Remarkably,\nBlockFound is the only method that successfully detects anomalous transactions\non Solana with high accuracy, whereas all other approaches achieved very low or\nzero detection recall scores. This work not only provides new foundation models\nfor blockchain but also sets a new benchmark for applying LLMs in blockchain\ndata.",
      "tldr_zh": "我们提出了BlockFound，一种定制化的区块链基础模型，用于检测异常交易。该模型通过模块化tokenizer处理区块链交易的多模态数据（如特定tokens、文本和数字），并采用定制的掩码语言学习机制（包括RoPE embedding和FlashAttention）来处理长序列数据，同时设计了新颖的异常检测方法。在Ethereum和Solana交易的广泛评估中，BlockFound实现了高准确率和低假阳性率，尤其是在Solana上成为唯一成功检测异常交易的方法，为区块链数据应用LLMs设定新基准。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04039v3",
      "published_date": "2024-10-05 05:11:34 UTC",
      "updated_date": "2024-10-18 04:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:38:19.787852"
    },
    {
      "arxiv_id": "2410.04038v2",
      "title": "Gamified crowd-sourcing of high-quality data for visual fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Yadav",
        "Rohan Tomar",
        "Garvit Jain",
        "Chirag Ahooja",
        "Shubham Chaudhary",
        "Charles Elkan"
      ],
      "abstract": "This paper introduces Gamified Adversarial Prompting (GAP), a framework that\ncrowd-sources high-quality data for visual instruction tuning of large\nmultimodal models. GAP transforms the data collection process into an engaging\ngame, incentivizing players to provide fine-grained, challenging questions and\nanswers that target gaps in the model's knowledge. Our contributions include\n(1) an approach to capture question-answer pairs from humans that directly\naddress weaknesses in a model's knowledge, (2) a method for evaluating and\nrewarding players that successfully incentivizes them to provide high-quality\nsubmissions, and (3) a scalable, gamified platform that succeeds in collecting\nthis data from over 50,000 participants in just a few weeks. Our implementation\nof GAP has significantly improved the accuracy of a small multimodal model,\nnamely MiniCPM-Llama3-V-2.5-8B, increasing its GPT score from 0.147 to 0.477 on\nour dataset, approaching the benchmark set by the much larger GPT-4V. Moreover,\nwe demonstrate that the data generated using MiniCPM-Llama3-V-2.5-8B also\nenhances its performance across other benchmarks, and exhibits cross-model\nbenefits. Specifically, the same data improves the performance of QWEN2-VL-2B\nand QWEN2-VL-7B on the same multiple benchmarks.",
      "tldr_zh": "这篇论文提出了 Gamified Adversarial Prompting (GAP) 框架，通过游戏化众包方式收集高质量数据，用于大型多模态模型的视觉指令微调，旨在针对模型知识缺口生成细粒度和挑战性的问题-答案对。\nGAP 的主要贡献包括：一种捕获人类问题-答案对的方法来直接解决模型弱点、评估和奖励玩家的机制，以及一个可扩展平台，在几周内从超过50,000参与者中成功收集数据。\n实验结果显示，该框架显著提升了 MiniCPM-Llama3-V-2.5-8B 模型的准确性，其 GPT 分数从0.147提高到0.477，接近 GPT-4V 的基准，并展示了数据在其他基准和模型（如 QWEN2-VL-2B 和 QWEN2-VL-7B）上的跨模型益处。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04038v2",
      "published_date": "2024-10-05 05:10:29 UTC",
      "updated_date": "2024-10-08 02:37:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:38:33.442871"
    },
    {
      "arxiv_id": "2410.04029v1",
      "title": "SyllableLM: Learning Coarse Semantic Units for Speech Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Baade",
        "Puyuan Peng",
        "David Harwath"
      ],
      "abstract": "Language models require tokenized inputs. However, tokenization strategies\nfor continuous data like audio and vision are often based on simple heuristics\nsuch as fixed sized convolutions or discrete clustering, which do not\nnecessarily align with the semantic structure of the data. For speech in\nparticular, the high resolution of waveforms (16,000 samples/second or more)\npresents a significant challenge as speech-based language models have had to\nuse several times more tokens per word than text-based language models. In this\nwork, we introduce a controllable self-supervised technique to merge speech\nrepresentations into coarser syllable-like units while still preserving\nsemantic information. We do this by 1) extracting noisy boundaries through\nanalyzing correlations in pretrained encoder losses and 2) iteratively\nimproving model representations with a novel distillation technique. Our method\nproduces controllable-rate semantic units at as low as 5Hz and 60bps and\nachieves SotA in syllabic segmentation and clustering. Using these coarse\ntokens, we successfully train SyllableLM, a Speech Language Model (SpeechLM)\nthat matches or outperforms current SotA SpeechLMs on a range of spoken\nlanguage modeling tasks. SyllableLM also achieves significant improvements in\nefficiency with a 30x reduction in training compute and a 4x wall-clock\ninference speedup.",
      "tldr_zh": "这篇论文提出了 SyllableLM，一种针对语音语言模型（Speech Language Models）的创新方法，通过可控自监督技术将语音表示合并成粗粒度的音节-like 单位，从而保留语义信息并解决传统分词策略的局限性。方法包括提取预训练编码器损失的相关性以获取噪声边界，并使用新型蒸馏技术迭代优化模型表示，实现低至 5Hz 和 60bps 的语义单位。实验结果显示，SyllableLM 在音节分割和聚类任务上达到 SOTA，并在各种口语语言建模任务中匹配或超越现有模型，同时训练计算减少 30 倍，推理速度加速 4 倍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04029v1",
      "published_date": "2024-10-05 04:29:55 UTC",
      "updated_date": "2024-10-05 04:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:38:45.289584"
    },
    {
      "arxiv_id": "2410.04025v1",
      "title": "IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Pu",
        "K. J. Kevin Feng",
        "Tovi Grossman",
        "Tom Hope",
        "Bhavana Dalvi Mishra",
        "Matt Latzke",
        "Jonathan Bragg",
        "Joseph Chee Chang",
        "Pao Siangliulue"
      ],
      "abstract": "Research ideation involves broad exploring and deep refining ideas. Both\nrequire deep engagement with literature. Existing tools focus primarily on idea\nbroad generation, yet offer little support for iterative specification,\nrefinement, and evaluation needed to further develop initial ideas. To bridge\nthis gap, we introduce IdeaSynth, a research idea development system that uses\nLLMs to provide literature-grounded feedback for articulating research\nproblems, solutions, evaluations, and contributions. IdeaSynth represents these\nidea facets as nodes on a canvas, and allow researchers to iteratively refine\nthem by creating and exploring variations and composing them. Our lab study\n(N=20) showed that participants, while using IdeaSynth, explored more\nalternative ideas and expanded initial ideas with more details compared to a\nstrong LLM-based baseline. Our deployment study (N=7) demonstrated that\nparticipants effectively used IdeaSynth for real-world research projects at\nvarious ideation stages from developing initial ideas to revising framings of\nmature manuscripts, highlighting the possibilities to adopt IdeaSynth in\nresearcher's workflows.",
      "tldr_zh": "本研究针对研究构思的探索和精炼过程，引入IdeaSynth系统，该系统利用LLMs提供基于文献的反馈，帮助研究者迭代表述研究问题、解决方案、评估和贡献。IdeaSynth将这些idea facets表示为画布上的节点，允许用户通过创建变体和组合来逐步精炼想法。实验室研究（N=20）显示，使用IdeaSynth的参与者探索了更多备选想法并添加更多细节，比LLM基准表现更优；部署研究（N=7）进一步证明，该系统在真实研究工作流中从初始想法开发到修改成熟手稿框架都有效。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04025v1",
      "published_date": "2024-10-05 04:06:07 UTC",
      "updated_date": "2024-10-05 04:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:38:56.680783"
    },
    {
      "arxiv_id": "2410.04022v2",
      "title": "Efficient Large-Scale Urban Parking Prediction: Graph Coarsening Based on Real-Time Parking Service Capability",
      "title_zh": "高效的大规模城市停车预测：基于实时停车服务能力的图粗化",
      "authors": [
        "Yixuan Wang",
        "Zhenwu Chen",
        "Kangshuai Zhang",
        "Yunduan Cui",
        "Yang Yang",
        "Lei Peng"
      ],
      "abstract": "With the sharp increase in the number of vehicles, the issue of parking\ndifficulties has emerged as an urgent challenge that many cities need to\naddress promptly. In the task of predicting large-scale urban parking data,\nexisting research often lacks effective deep learning models and strategies. To\ntackle this challenge, this paper proposes an innovative framework for\npredicting large-scale urban parking graphs leveraging real-time service\ncapabilities, aimed at improving the accuracy and efficiency of parking\npredictions. Specifically, we introduce a graph attention mechanism that\nassesses the real-time service capabilities of parking lots to construct a\ndynamic parking graph that accurately reflects real preferences in parking\nbehavior. To effectively handle large-scale parking data, this study combines\ngraph coarsening techniques with temporal convolutional autoencoders to achieve\nunified dimension reduction of the complex urban parking graph structure and\nfeatures. Subsequently, we use a spatio-temporal graph convolutional model to\nmake predictions based on the coarsened graph, and a pre-trained\nautoencoder-decoder module restores the predicted results to their original\ndata dimensions, completing the task. Our methodology has been rigorously\ntested on a real dataset from parking lots in Shenzhen. The experimental\nresults indicate that compared to traditional parking prediction models, our\nframework achieves improvements of 46.8\\% and 30.5\\% in accuracy and\nefficiency, respectively. Remarkably, with the expansion of the graph's scale,\nour framework's advantages become even more apparent, showcasing its\nsubstantial potential for solving complex urban parking dilemmas in practical\nscenarios.",
      "tldr_zh": "该论文针对城市停车难题，提出了一种高效的大规模城市停车预测框架，利用实时服务能力构建动态停车图。框架引入 graph attention mechanism 评估停车场服务能力，并结合 graph coarsening 和 temporal convolutional autoencoders 进行图结构和特征的统一降维，随后使用 spatio-temporal graph convolutional model 进行预测，并通过预训练的自动编码器-解码器模块恢复原始数据。实验在深圳真实数据集上显示，与传统模型相比，准确率和效率分别提高了46.8%和30.5%，在大规模停车图中表现出色，为解决实际城市停车问题提供了潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04022v2",
      "published_date": "2024-10-05 03:54:25 UTC",
      "updated_date": "2025-01-20 03:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:39:08.910826"
    },
    {
      "arxiv_id": "2410.05317v4",
      "title": "Accelerating Diffusion Transformers with Token-wise Feature Caching",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Zou",
        "Xuyang Liu",
        "Ting Liu",
        "Siteng Huang",
        "Linfeng Zhang"
      ],
      "abstract": "Diffusion transformers have shown significant effectiveness in both image and\nvideo synthesis at the expense of huge computation costs. To address this\nproblem, feature caching methods have been introduced to accelerate diffusion\ntransformers by caching the features in previous timesteps and reusing them in\nthe following timesteps. However, previous caching methods ignore that\ndifferent tokens exhibit different sensitivities to feature caching, and\nfeature caching on some tokens may lead to 10$\\times$ more destruction to the\noverall generation quality compared with other tokens. In this paper, we\nintroduce token-wise feature caching, allowing us to adaptively select the most\nsuitable tokens for caching, and further enable us to apply different caching\nratios to neural layers in different types and depths. Extensive experiments on\nPixArt-$\\alpha$, OpenSora, and DiT demonstrate our effectiveness in both image\nand video generation with no requirements for training. For instance,\n2.36$\\times$ and 1.93$\\times$ acceleration are achieved on OpenSora and\nPixArt-$\\alpha$ with almost no drop in generation quality.",
      "tldr_zh": "本文提出了一种基于标记的特征缓存（token-wise feature caching）方法，用于加速扩散变换器（Diffusion Transformers），以解决其在图像和视频合成中计算成本高的难题。该方法通过自适应选择敏感性较低的标记进行缓存，并为不同类型和深度的神经层应用不同的缓存比率，从而避免了传统特征缓存对生成质量的破坏。实验在 PixArt-α、OpenSora 和 DiT 等模型上验证了其有效性，无需额外训练即可实现高达 2.36× 的加速，同时几乎不影响生成质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ToCa is honored to be accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05317v4",
      "published_date": "2024-10-05 03:47:06 UTC",
      "updated_date": "2025-02-19 10:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:39:21.111964"
    },
    {
      "arxiv_id": "2410.05315v2",
      "title": "PalmBench: A Comprehensive Benchmark of Compressed Large Language Models on Mobile Platforms",
      "title_zh": "PalmBench: 移动平台上压缩大型语言模型的全面基准测试",
      "authors": [
        "Yilong Li",
        "Jingyu Liu",
        "Hao Zhang",
        "M Badri Narayanan",
        "Utkarsh Sharma",
        "Shuai Zhang",
        "Pan Hu",
        "Yijing Zeng",
        "Jayaram Raghuram",
        "Suman Banerjee"
      ],
      "abstract": "Deploying large language models (LLMs) locally on mobile devices is\nadvantageous in scenarios where transmitting data to remote cloud servers is\neither undesirable due to privacy concerns or impractical due to network\nconnection. Recent advancements (MLC, 2023a; Gerganov, 2023) have facilitated\nthe local deployment of LLMs. However, local deployment also presents\nchallenges, particularly in balancing quality (generative performance),\nlatency, and throughput within the hardware constraints of mobile devices. In\nthis paper, we introduce our lightweight, all-in-one automated benchmarking\nframework that allows users to evaluate LLMs on mobile devices. We provide a\ncomprehensive benchmark of various popular LLMs with different quantization\nconfigurations (both weights and activations) across multiple mobile platforms\nwith varying hardware capabilities. Unlike traditional benchmarks that assess\nfull-scale models on high-end GPU clusters, we focus on evaluating resource\nefficiency (memory and power consumption) and harmful output for compressed\nmodels on mobile devices. Our key observations include i) differences in energy\nefficiency and throughput across mobile platforms; ii) the impact of\nquantization on memory usage, GPU execution time, and power consumption; and\niii) accuracy and performance degradation of quantized models compared to their\nnon-quantized counterparts; and iv) the frequency of hallucinations and toxic\ncontent generated by compressed LLMs on mobile devices.",
      "tldr_zh": "本文引入了 PalmBench，一个轻量级全自动基准测试框架，用于评估压缩的大语言模型（LLMs）在移动设备上的性能，特别关注隐私和网络限制下的本地部署挑战。框架通过测试各种 LLMs 的不同量化配置（包括权重和激活），在多个硬件能力不同的移动平台上，评估资源效率（如内存和功耗）、延迟和有害输出。研究发现，量化技术会导致模型准确性和性能退化，移动平台间能源效率和吞吐量存在差异，同时压缩模型增加了幻觉和有毒内容的生成频率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05315v2",
      "published_date": "2024-10-05 03:37:07 UTC",
      "updated_date": "2025-01-09 00:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:39:34.021901"
    },
    {
      "arxiv_id": "2410.04012v2",
      "title": "JAM: A Comprehensive Model for Age Estimation, Verification, and Comparability",
      "title_zh": "翻译失败",
      "authors": [
        "François David",
        "Alexey A. Novikov",
        "Ruslan Parkhomenko",
        "Artem Voronin",
        "Alix Melchy"
      ],
      "abstract": "This paper introduces a comprehensive model for age estimation, verification,\nand comparability, offering a comprehensive solution for a wide range of\napplications. It employs advanced learning techniques to understand age\ndistribution and uses confidence scores to create probabilistic age ranges,\nenhancing its ability to handle ambiguous cases. The model has been tested on\nboth proprietary and public datasets and compared against one of the\ntop-performing models in the field. Additionally, it has recently been\nevaluated by NIST as part of the FATE challenge, achieving top places in many\ncategories.",
      "tldr_zh": "本论文介绍了JAM模型，这是一个全面的框架，用于年龄估计(age estimation)、验证(verification)和可比性(comparability)，适用于多种应用场景。该模型采用高级学习技术理解年龄分布，并通过置信分数(confidence scores)生成概率年龄范围(probabilistic age ranges)，从而有效处理模糊案例。在专有和公共数据集上测试后，JAM模型与顶尖模型相比表现出色，并在NIST的FATE挑战中获得多项类别领先成绩。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04012v2",
      "published_date": "2024-10-05 03:02:47 UTC",
      "updated_date": "2025-01-27 19:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:39:44.211036"
    },
    {
      "arxiv_id": "2410.04010v1",
      "title": "Hyperbolic Fine-tuning for Large Language Models",
      "title_zh": "针对大语言模型的双曲微调",
      "authors": [
        "Menglin Yang",
        "Aosong Feng",
        "Bo Xiong",
        "Jihong Liu",
        "Irwin King",
        "Rex Ying"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable performance on\nvarious tasks. However, it remains an open question whether the default\nEuclidean space is the most suitable choice for embedding tokens in LLMs. In\nthis study, we first investigate the non-Euclidean characteristics of LLMs. Our\nfindings reveal that token frequency follows a power-law distribution, with\nhigh-frequency tokens clustering near the origin and low-frequency tokens\npositioned farther away. Additionally, token embeddings exhibit a high degree\nof hyperbolicity, indicating a latent tree-like structure in the embedding\nspace. Building on the observation, we propose to efficiently fine-tune LLMs in\nhyperbolic space to better exploit the underlying complex structures. However,\nwe found that this fine-tuning in hyperbolic space cannot be achieved with\nnaive application of exponential and logarithmic maps, when the embedding and\nweight matrices both reside in Euclidean space. To address this technique\nissue, we introduce a new method called hyperbolic low-rank efficient\nfine-tuning, HypLoRA, that performs low-rank adaptation directly on the\nhyperbolic manifold, avoiding the cancellation effect caused by the exponential\nand logarithmic maps, thus preserving the hyperbolic modeling capabilities.\nThrough extensive experiments, we demonstrate that HypLoRA significantly\nenhances the performance of LLMs on reasoning tasks, particularly for complex\nreasoning problems. In particular, HypLoRA improves the performance in the\ncomplex AQuA dataset by up to 13.0%, showcasing its effectiveness in handling\ncomplex reasoning challenges",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）的非欧氏特性，发现 token 频率遵循幂律分布，且嵌入空间具有高超曲度，暗示潜在的树状结构，从而质疑默认欧氏空间的适用性。为更好地利用这些复杂结构，论文提出了一种高效微调方法 HypLoRA（Hyperbolic Low-Rank Efficient Fine-tuning），它在超曲流形上直接进行低秩适配，避免了指数和对数映射的取消效应。实验结果显示，HypLoRA 显著提升了 LLMs 在推理任务上的性能，尤其在复杂数据集如 AQuA 上，准确率最高提高了 13.0%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "The preliminary work was accepted for the ICML 2024 LLM Cognition\n  Workshop, and this version includes new investigations, analyses,\n  experiments, and results",
      "pdf_url": "http://arxiv.org/pdf/2410.04010v1",
      "published_date": "2024-10-05 02:58:25 UTC",
      "updated_date": "2024-10-05 02:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:39:56.441984"
    },
    {
      "arxiv_id": "2410.04002v1",
      "title": "Take It Easy: Label-Adaptive Self-Rationalization for Fact Verification and Explanation Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Yang",
        "Anderson Rocha"
      ],
      "abstract": "Computational methods to aid journalists in the task often require adapting a\nmodel to specific domains and generating explanations. However, most automated\nfact-checking methods rely on three-class datasets, which do not accurately\nreflect real-world misinformation. Moreover, fact-checking explanations are\noften generated based on text summarization of evidence, failing to address the\nrelationship between the claim and the evidence. To address these issues, we\nextend the self-rationalization method--typically used in natural language\ninference (NLI) tasks--to fact verification. We propose a label-adaptive\nlearning approach: first, we fine-tune a model to learn veracity prediction\nwith annotated labels (step-1 model). Then, we fine-tune the step-1 model again\nto learn self-rationalization, using the same data and additional annotated\nexplanations. Our results show that our label-adaptive approach improves\nveracity prediction by more than ten percentage points (Macro F1) on both the\nPubHealth and AVeriTec datasets, outperforming the GPT-4 model. Furthermore, to\naddress the high cost of explanation annotation, we generated 64 synthetic\nexplanations from three large language models: GPT-4-turbo, GPT-3.5-turbo, and\nLlama-3-8B and few-shot fine-tune our step-1 model. The few-shot synthetic\nexplanation fine-tuned model performed comparably to the fully fine-tuned\nself-rationalization model, demonstrating the potential of low-budget learning\nwith synthetic data. Our label-adaptive self-rationalization approach presents\na promising direction for future research on real-world explainable\nfact-checking with different labeling schemes.",
      "tldr_zh": "该论文提出了一种标签自适应自理性化（Label-Adaptive Self-Rationalization）方法，用于事实验证（Fact Verification）和解释生成，旨在解决现有模型依赖三分类数据集和忽略声明与证据关系的局限性。方法包括两步微调过程：首先微调模型学习真实性预测（step-1 model），然后使用相同数据和额外注释的解释再次微调以实现自理性化。实验结果显示，该方法在PubHealth和AVeriTeC数据集上使Macro F1分数提高超过10个百分点，优于GPT-4模型。针对解释注释的高成本问题，作者使用大型语言模型（如GPT-4-turbo、GPT-3.5-turbo和Llama-3-8B）生成64个合成解释进行少样本微调，结果与完全微调模型相当，为低预算的真实世界可解释事实检查提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted in the 16th IEEE INTERNATIONAL WORKSHOP ON INFORMATION\n  FORENSICS AND SECURITY (WIFS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04002v1",
      "published_date": "2024-10-05 02:19:49 UTC",
      "updated_date": "2024-10-05 02:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:40:09.193067"
    },
    {
      "arxiv_id": "2410.04001v1",
      "title": "FastLRNR and Sparse Physics Informed Backpropagation",
      "title_zh": "翻译失败",
      "authors": [
        "Woojin Cho",
        "Kookjin Lee",
        "Noseong Park",
        "Donsub Rim",
        "Gerrit Welper"
      ],
      "abstract": "We introduce Sparse Physics Informed Backpropagation (SPInProp), a new class\nof methods for accelerating backpropagation for a specialized neural network\narchitecture called Low Rank Neural Representation (LRNR). The approach\nexploits the low rank structure within LRNR and constructs a reduced neural\nnetwork approximation that is much smaller in size. We call the smaller network\nFastLRNR. We show that backpropagation of FastLRNR can be substituted for that\nof LRNR, enabling a significant reduction in complexity. We apply SPInProp to a\nphysics informed neural networks framework and demonstrate how the solution of\nparametrized partial differential equations is accelerated.",
      "tldr_zh": "本文引入了 Sparse Physics Informed Backpropagation (SPInProp)，一种新方法，用于加速 Low Rank Neural Representation (LRNR) 神经网络架构的反向传播。SPInProp 通过利用 LRNR 的低秩结构，构建了一个更小、更高效的网络近似 FastLRNR，从而显著降低计算复杂度。实验结果显示，该方法在物理信息神经网络框架中成功加速了参数化偏微分方程的求解，提供了一种高效的神经网络优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "68T07, 65D25, 65M22"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04001v1",
      "published_date": "2024-10-05 02:19:28 UTC",
      "updated_date": "2024-10-05 02:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:40:20.241243"
    },
    {
      "arxiv_id": "2410.09081v1",
      "title": "Semantic Environment Atlas for Object-Goal Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Nuri Kim",
        "Jeongho Park",
        "Mineui Hong",
        "Songhwai Oh"
      ],
      "abstract": "In this paper, we introduce the Semantic Environment Atlas (SEA), a novel\nmapping approach designed to enhance visual navigation capabilities of embodied\nagents. The SEA utilizes semantic graph maps that intricately delineate the\nrelationships between places and objects, thereby enriching the navigational\ncontext. These maps are constructed from image observations and capture visual\nlandmarks as sparsely encoded nodes within the environment. The SEA integrates\nmultiple semantic maps from various environments, retaining a memory of\nplace-object relationships, which proves invaluable for tasks such as visual\nlocalization and navigation. We developed navigation frameworks that\neffectively leverage the SEA, and we evaluated these frameworks through visual\nlocalization and object-goal navigation tasks. Our SEA-based localization\nframework significantly outperforms existing methods, accurately identifying\nlocations from single query images. Experimental results in Habitat scenarios\nshow that our method not only achieves a success rate of 39.0%, an improvement\nof 12.4% over the current state-of-the-art, but also maintains robustness under\nnoisy odometry and actuation conditions, all while keeping computational costs\nlow.",
      "tldr_zh": "本论文引入了 Semantic Environment Atlas (SEA)，一种新型映射方法，用于提升 embodied agents 的视觉导航能力，通过 semantic graph maps 详细描绘地点和物体之间的关系。SEA 基于图像观察构建稀疏编码的视觉地标节点，并整合多个环境的语义地图，以保留地点-物体关系的记忆，支持视觉定位和 object-goal navigation 任务。在 Habitat 场景的实验中，SEA-based 框架的成功率达到 39.0%，比现有最先进方法提高 12.4%，并在嘈杂的测距和执行条件下保持鲁棒性，同时保持低计算成本。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.09081v1",
      "published_date": "2024-10-05 00:37:15 UTC",
      "updated_date": "2024-10-05 00:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:40:33.264643"
    },
    {
      "arxiv_id": "2410.16283v2",
      "title": "Understanding the Effect of Algorithm Transparency of Model Explanations in Text-to-SQL Semantic Parsing",
      "title_zh": "翻译失败",
      "authors": [
        "Daking Rai",
        "Rydia R. Weiland",
        "Kayla Margaret Gabriella Herrera",
        "Tyler H. Shaw",
        "Ziyu Yao"
      ],
      "abstract": "Explaining the decisions of AI has become vital for fostering appropriate\nuser trust in these systems. This paper investigates explanations for a\nstructured prediction task called ``text-to-SQL Semantic Parsing'', which\ntranslates a natural language question into a structured query language (SQL)\nprogram. In this task setting, we designed three levels of model explanation,\neach exposing a different amount of the model's decision-making details (called\n``algorithm transparency''), and investigated how different model explanations\ncould potentially yield different impacts on the user experience. Our study\nwith $\\sim$100 participants shows that (1) the low-/high-transparency\nexplanations often lead to less/more user reliance on the model decisions,\nwhereas the medium-transparency explanations strike a good balance. We also\nshow that (2) only the medium-transparency participant group was able to engage\nfurther in the interaction and exhibit increasing performance over time, and\nthat (3) they showed the least changes in trust before and after the study.",
      "tldr_zh": "这篇论文探讨了在text-to-SQL Semantic Parsing任务中，模型解释的algorithm transparency如何影响用户信任和体验。研究者设计了三种不同透明度水平的模型解释（低、中、高），并通过约100名参与者的实验评估其对用户依赖、互动和性能的影响。结果表明，低透明度解释减少了用户对模型决策的依赖，而高透明度则增加了依赖；中等透明度解释达到了最佳平衡，不仅促进用户进一步互动并提升性能，还使信任水平在研究前后变化最小。总的来说，该研究为优化AI解释设计提供了重要见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "I.3.6"
      ],
      "primary_category": "cs.IR",
      "comment": "15 pages, 18 figure, Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.16283v2",
      "published_date": "2024-10-05 00:13:33 UTC",
      "updated_date": "2024-11-24 14:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:40:44.613073"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 63,
  "processed_papers_count": 63,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T07:40:57.762132"
}