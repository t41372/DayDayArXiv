{
  "date": "2024-01-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-08 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 56 篇论文，主要聚焦 AI 和机器学习领域，包括大型语言模型（LLMs）的优化与应用、图像处理、强化学习和多模态模型等热门话题。其中，令人印象深刻的是 LLMs 在代码生成和多模态任务中的进展，如 LLM4PLC 和 MoE-Mamba 展示了高效的代码生成和模型优化，而 Sergey Levine 等知名学者参与的论文（如 Functional Graphical Models）则在数据驱动优化方面提供了理论突破。以下，我将挑选并讨论最具代表性和话题度的论文，先从 LLMs 和 AI 核心应用入手，再快速概述其他相关内容。\n\n### 1. LLM4PLC: Harnessing Large Language Models for Verifiable Programming of PLCs in Industrial Control Systems  \n（中文标题：利用大型语言模型实现可验证的 PLC 编程）  \n这篇论文提出 LLM4PLC 框架，利用用户反馈和外部工具（如语法检查器和编译器）指导 LLMs 生成可验证的工业控制系统代码。主要贡献是提升了代码生成成功率（从 47% 到 72%），并通过 Prompt Engineering 和模型微调验证了其在实际工业应用中的有效性。该工作对 AI 在工业自动化中的应用有重要启示，尤其在确保代码可靠性和可解释性方面。\n\n### 2. Functional Graphical Models: Structure Enables Offline Data-Driven Optimization  \n（中文标题：功能图形模型：结构支持离线数据驱动优化）  \n由 Sergey Levine 等知名学者主导，这篇论文引入功能图形模型（FGMs），理论上证明了其在数据驱动优化（如蛋白质设计）中的优势。主要发现是，FGMs 通过分解高维问题实现更高效的遗憾边界，并开发了算法来推断模型结构。该研究扩展了强化学习在复杂优化任务中的潜力，值得关注。\n\n### 3. Attack-Resilient Image Watermarking Using Stable Diffusion  \n（中文标题：使用 Stable Diffusion 的抗攻击图像水印）  \n论文提出 ZoDiac 方法，利用预训练的 Stable Diffusion 模型在潜在空间注入水印，实现对图像来源的鲁棒追踪。主要贡献是水印检测率超过 98%，并证明扩散模型的去噪过程增强了抗攻击能力。该工作在 AI 生成内容版权保护方面有实际意义，相关代码已开源。\n\n### 4. MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts  \n（中文标题：MoE-Mamba：高效的选择性状态空间模型）  \n这篇论文结合 Mixture of Experts（MoE）和状态空间模型（SSMs），优化了 Mamba 模型的性能。主要发现是，MoE-Mamba 在训练步骤减少 2.35 倍的情况下，保持了与基线相当的性能，并超越了传统 Transformer-MoE。该方法在高效 AI 模型设计中具有话题度，适合资源受限场景。\n\n### 5. TeleChat Technical Report  \n（中文标题：TeleChat 技术报告）  \n论文介绍了 TeleChat 系列 LLMs（参数规模 3B 到 12B），包括预训练和微调模型。主要贡献是通过海量文本训练和微调，实现多语言任务的高性能，并在基准测试中与同规模开源模型相当。该工作由多个作者团队发布，突显 LLMs 在实际应用的潜力，代码和部分数据已公开。\n\n### 6. FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs  \n（中文标题：在 FPGA 上实现高效大型语言模型推理）  \n论文提出 FlightLLM 框架，利用 FPGA 资源优化 LLMs 推理，显著降低了计算和内存开销。主要发现是，与 GPU 相比，FlightLLM 在 LLaMA2-7B 上实现了 6 倍能效提升。该研究在硬件加速 AI 推理方面有突破，适用于边缘计算场景。\n\n### 7. Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems with Multi-Leg Demand Routes  \n（中文标题：多卡车多段需求路径的深度强化学习）  \n这篇论文扩展了深度强化学习应用于复杂车辆路径问题，处理多卡车和多段路由需求。主要贡献是新模型在真实供应链环境中超越了基线解决方案。该工作对工业物流优化有实际价值，展示了 RL 在大规模应用的潜力。\n\n### 8. FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild  \n（中文标题：FunnyNet-W：野外视频中多模态幽默时刻学习）  \n论文开发了 FunnyNet-W 模型，使用视觉、音频和文本多模态数据预测视频中的幽默时刻。主要发现是，该模型在多个数据集上刷新了状态，并证明了多模态线索的有效性。该研究在视频理解和情感分析中具有趣味性和创新性。\n\n### 9. Effects of Multimodal Explanations for Autonomous Driving on Driving Performance, Cognitive Load, Expertise, Confidence, and Trust  \n（中文标题：多模态解释对自动驾驶的影响）  \n这篇论文探索多模态解释（如音频和视觉）对自动驾驶的影响，主要发现是，“为什么”类型解释能改善驾驶性能和信任度。该工作对人机交互设计有启示，尤其在 AI 辅助决策的公平性和可用性方面。\n\n### 10. AI and Generative AI for Research Discovery and Summarization  \n（中文标题：AI 和生成式 AI 在研究发现和总结中的应用）  \n论文讨论了 LLMs（如 ChatGPT）在研究文献发现和总结中的作用，主要贡献是概述了 AI 工具的潜力，并提出未来方向。该研究由 Mark Glickman 等学者发布，对学术界使用 AI 工具有指导意义。\n\n其他论文，如那些涉及交通规划（Exploring Attack Resilience in Distributed Platoon Controllers）、医疗应用（Catalyzing Equity in STEM Teams）或基础模型（如Tiny Time Mixers），虽有一定价值，但相对次要，我仅快速提及：这些工作在特定领域（如时间序列预测或公平性评估）提供了新方法，但未有重大突破，可作为补充阅读。\n\n总之，今天的 arXiv 更新突显了 AI 模型的优化和实际应用潜力，LLMs 相关论文尤其值得追踪。读者可根据自身兴趣优先查看上述重点内容！如果有特定主题，欢迎反馈。",
  "papers": [
    {
      "arxiv_id": "2401.05443v1",
      "title": "LLM4PLC: Harnessing Large Language Models for Verifiable Programming of PLCs in Industrial Control Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamad Fakih",
        "Rahul Dharmaji",
        "Yasamin Moghaddas",
        "Gustavo Quiros Araya",
        "Oluwatosin Ogundare",
        "Mohammad Abdullah Al Faruque"
      ],
      "abstract": "Although Large Language Models (LLMs) have established pre-dominance in\nautomated code generation, they are not devoid of shortcomings. The pertinent\nissues primarily relate to the absence of execution guarantees for generated\ncode, a lack of explainability, and suboptimal support for essential but niche\nprogramming languages. State-of-the-art LLMs such as GPT-4 and LLaMa2 fail to\nproduce valid programs for Industrial Control Systems (ICS) operated by\nProgrammable Logic Controllers (PLCs). We propose LLM4PLC, a user-guided\niterative pipeline leveraging user feedback and external verification tools\nincluding grammar checkers, compilers and SMV verifiers to guide the LLM's\ngeneration. We further enhance the generation potential of LLM by employing\nPrompt Engineering and model fine-tuning through the creation and usage of\nLoRAs. We validate this system using a FischerTechnik Manufacturing TestBed\n(MFTB), illustrating how LLMs can evolve from generating structurally flawed\ncode to producing verifiably correct programs for industrial applications. We\nrun a complete test suite on GPT-3.5, GPT-4, Code Llama-7B, a fine-tuned Code\nLlama-7B model, Code Llama-34B, and a fine-tuned Code Llama-34B model. The\nproposed pipeline improved the generation success rate from 47% to 72%, and the\nSurvey-of-Experts code quality from 2.25/10 to 7.75/10. To promote open\nresearch, we share the complete experimental setup, the LLM Fine-Tuning\nWeights, and the video demonstrations of the different programs on our\ndedicated webpage.",
      "tldr_zh": "这篇论文提出了 LLM4PLC，一种利用 Large Language Models (LLMs) 生成可验证 PLC (Programmable Logic Controllers) 程序的框架，针对工业控制系统 (ICS) 的代码生成问题，如缺少执行保证和对特定语言的支持不足。框架采用用户引导的迭代管道，结合外部验证工具（如语法检查器、编译器和 SMV verifiers）、Prompt Engineering 以及模型微调 (LoRAs) 来指导和优化代码生成过程。实验在 FischerTechnik Manufacturing TestBed 上验证了该系统，将生成成功率从 47% 提高到 72%，代码质量由专家评估从 2.25/10 提升至 7.75/10，并分享了实验设置和微调权重以促进开放研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PL",
        "D.2.4; I.2.7; I.2.2"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages; 8 figures; Appearing in the 46th International Conference\n  on Software Engineering: Software Engineering in Practice; for demo website,\n  see https://sites.google.com/uci.edu/llm4plc/home",
      "pdf_url": "http://arxiv.org/pdf/2401.05443v1",
      "published_date": "2024-01-08 23:52:42 UTC",
      "updated_date": "2024-01-08 23:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:24:46.032743"
    },
    {
      "arxiv_id": "2401.05442v3",
      "title": "Functional Graphical Models: Structure Enables Offline Data-Driven Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Grudzien Kuba",
        "Masatoshi Uehara",
        "Pieter Abbeel",
        "Sergey Levine"
      ],
      "abstract": "While machine learning models are typically trained to solve prediction\nproblems, we might often want to use them for optimization problems. For\nexample, given a dataset of proteins and their corresponding fluorescence\nlevels, we might want to optimize for a new protein with the highest possible\nfluorescence. This kind of data-driven optimization (DDO) presents a range of\nchallenges beyond those in standard prediction problems, since we need models\nthat successfully predict the performance of new designs that are better than\nthe best designs seen in the training set. It is not clear theoretically when\nexisting approaches can even perform better than the naive approach that simply\nselects the best design in the dataset. In this paper, we study how structure\ncan enable sample-efficient data-driven optimization. To formalize the notion\nof structure, we introduce functional graphical models (FGMs) and show\ntheoretically how they can provide for principled data-driven optimization by\ndecomposing the original high-dimensional optimization problem into smaller\nsub-problems. This allows us to derive much more practical regret bounds for\nDDO, and the result implies that DDO with FGMs can achieve nearly optimal\ndesigns in situations where naive approaches fail due to insufficient coverage\nof the offline data. We further present a data-driven optimization algorithm\nthat inferes the FGM structure itself, either over the original input variables\nor a latent variable representation of the inputs.",
      "tldr_zh": "这篇论文探讨了数据驱动优化（DDO）的问题，即利用机器学习模型从离线数据中优化新设计（如蛋白质的荧光水平），这比标准预测更具挑战，因为需预测优于训练集的最佳方案。作者引入了Functional Graphical Models (FGMs)，通过结构化分解高维优化问题为更小的子问题，提供更实用的遗憾界（regret bounds），从而实现样例高效的DDO。理论分析表明，FGMs能在离线数据覆盖不足时实现近优设计，而论文还提出了一种算法来推断FGMs的结构，适用于原始变量或潜在变量表示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.05442v3",
      "published_date": "2024-01-08 22:33:14 UTC",
      "updated_date": "2024-10-17 00:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:24:45.880126"
    },
    {
      "arxiv_id": "2401.04247v2",
      "title": "Attack-Resilient Image Watermarking Using Stable Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Lijun Zhang",
        "Xiao Liu",
        "Antoni Viros Martin",
        "Cindy Xiong Bearfield",
        "Yuriy Brun",
        "Hui Guan"
      ],
      "abstract": "Watermarking images is critical for tracking image provenance and proving\nownership. With the advent of generative models, such as stable diffusion, that\ncan create fake but realistic images, watermarking has become particularly\nimportant to make human-created images reliably identifiable. Unfortunately,\nthe very same stable diffusion technology can remove watermarks injected using\nexisting methods. To address this problem, we present ZoDiac, which uses a\npre-trained stable diffusion model to inject a watermark into the trainable\nlatent space, resulting in watermarks that can be reliably detected in the\nlatent vector even when attacked. We evaluate ZoDiac on three benchmarks,\nMS-COCO, DiffusionDB, and WikiArt, and find that ZoDiac is robust against\nstate-of-the-art watermark attacks, with a watermark detection rate above 98%\nand a false positive rate below 6.4%, outperforming state-of-the-art\nwatermarking methods. We hypothesize that the reciprocating denoising process\nin diffusion models may inherently enhance the robustness of the watermark when\nfaced with strong attacks and validate the hypothesis. Our research\ndemonstrates that stable diffusion is a promising approach to robust\nwatermarking, able to withstand even stable-diffusion--based attack methods.\nZoDiac is open-sourced and available at https://github.com/zhanglijun95/ZoDiac.",
      "tldr_zh": "该研究提出了一种名为ZoDiac的图像水印方法，利用预训练的Stable Diffusion模型在可训练的latent space中注入水印，以提升水印对攻击的鲁棒性。ZoDiac针对现有水印易被Stable Diffusion移除的问题，通过往复去噪过程增强水印的可靠性，并在MS-COCO、DiffusionDB和WikiArt数据集上进行评估。实验结果显示，ZoDiac的检测率超过98%，假阳性率低于6.4%，显著优于现有方法。研究还验证了扩散模型的去噪机制可能内在提升水印抗攻击能力，并开源了ZoDiac代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 11 figures; NeurIPS24",
      "pdf_url": "http://arxiv.org/pdf/2401.04247v2",
      "published_date": "2024-01-08 21:42:56 UTC",
      "updated_date": "2024-10-28 15:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:24:56.615972"
    },
    {
      "arxiv_id": "2401.08669v3",
      "title": "Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems with Multi-Leg Demand Routes",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Levin",
        "Randall Correll",
        "Takanori Ide",
        "Takafumi Suzuki",
        "Takaho Saito",
        "Alan Arai"
      ],
      "abstract": "Deep reinforcement learning (RL) has been shown to be effective in producing\napproximate solutions to some vehicle routing problems (VRPs), especially when\nusing policies generated by encoder-decoder attention mechanisms. While these\ntechniques have been quite successful for relatively simple problem instances,\nthere are still under-researched and highly complex VRP variants for which no\neffective RL method has been demonstrated. In this work we focus on one such\nVRP variant, which contains multiple trucks and multi-leg routing requirements.\nIn these problems, demand is required to move along sequences of nodes, instead\nof just from a start node to an end node. With the goal of making deep RL a\nviable strategy for real-world industrial-scale supply chain logistics, we\ndevelop new extensions to existing encoder-decoder attention models which allow\nthem to handle multiple trucks and multi-leg routing requirements. Our models\nhave the advantage that they can be trained for a small number of trucks and\nnodes, and then embedded into a large supply chain to yield solutions for\nlarger numbers of trucks and nodes. We test our approach on a real supply chain\nenvironment arising in the operations of Japanese automotive parts manufacturer\nAisin Corporation, and find that our algorithm outperforms Aisin's previous\nbest solution.",
      "tldr_zh": "本文使用深度强化学习（Deep Reinforcement Learning）扩展了编码器-解码器注意力机制（Encoder-Decoder Attention Mechanisms），以解决多卡车车辆路径问题（Multi-Truck Vehicle Routing Problems）中的多段需求路由（Multi-Leg Demand Routes），其中需求需沿节点序列移动。研究开发了新模型扩展，使其能够在小规模场景下训练，并无缝嵌入大型供应链环境中。实验结果显示，该算法在日本汽车零部件制造商Aisin Corporation的真实供应链中，优于其原有解决方案，证明了深度强化学习在工业规模物流中的可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is more appropriate as a revised version of\n  arXiv:2211.17078, so it has been resubmitted as such",
      "pdf_url": "http://arxiv.org/pdf/2401.08669v3",
      "published_date": "2024-01-08 21:13:07 UTC",
      "updated_date": "2024-12-18 16:08:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:25:09.310778"
    },
    {
      "arxiv_id": "2402.00037v1",
      "title": "Catalyzing Equity in STEM Teams: Harnessing Generative AI for Inclusion and Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Nia Nixon",
        "Yiwen Lin",
        "Lauren Snow"
      ],
      "abstract": "Collaboration is key to STEM, where multidisciplinary team research can solve\ncomplex problems. However, inequality in STEM fields hinders their full\npotential, due to persistent psychological barriers in underrepresented\nstudents' experience. This paper documents teamwork in STEM and explores the\ntransformative potential of computational modeling and generative AI in\npromoting STEM-team diversity and inclusion. Leveraging generative AI, this\npaper outlines two primary areas for advancing diversity, equity, and\ninclusion. First, formalizing collaboration assessment with inclusive analytics\ncan capture fine-grained learner behavior. Second, adaptive, personalized AI\nsystems can support diversity and inclusion in STEM teams. Four policy\nrecommendations highlight AI's capacity: formalized collaborative skill\nassessment, inclusive analytics, funding for socio-cognitive research, human-AI\nteaming for inclusion training. Researchers, educators, policymakers can build\nan equitable STEM ecosystem. This roadmap advances AI-enhanced collaboration,\noffering a vision for the future of STEM where diverse voices are actively\nencouraged and heard within collaborative scientific endeavors.",
      "tldr_zh": "这篇论文探讨了STEM领域团队合作的不平等问题，特别是对 underrepresented students 的心理障碍，并提出利用 Generative AI 来推动多样性和包容性。论文强调两个主要领域：通过 inclusive analytics 形式化合作评估，以捕捉细粒度的学习者行为；以及开发自适应、个性化的AI系统来支持STEM团队的多样性。论文还提供了四个政策推荐，包括形式化协作技能评估、inclusive analytics、资助社会认知研究，以及人类-AI团队合作用于包容性训练。最终，这为研究者、教育者和政策制定者构建一个公平的STEM生态系统提供了路线图，促进AI增强的合作和多样声音的表达。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "21 pages, 0 figure, to be published in Policy Insights from\n  Behavioral and Brain Sciences",
      "pdf_url": "http://arxiv.org/pdf/2402.00037v1",
      "published_date": "2024-01-08 21:10:18 UTC",
      "updated_date": "2024-01-08 21:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:25:21.551850"
    },
    {
      "arxiv_id": "2401.04736v1",
      "title": "Exploring Attack Resilience in Distributed Platoon Controllers with Model Predictive Control",
      "title_zh": "使用模型",
      "authors": [
        "Tashfique Hasnine Choudhury"
      ],
      "abstract": "The extensive use of distributed vehicle platoon controllers has resulted in\nseveral benefits for transportation systems, such as increased traffic flow,\nfuel efficiency, and decreased pollution. The rising reliance on interconnected\nsystems and communication networks, on the other hand, exposes these\ncontrollers to potential cyber-attacks, which may compromise their safety and\nfunctionality. This thesis aims to improve the security of distributed vehicle\nplatoon controllers by investigating attack scenarios and assessing their\ninfluence on system performance. Various attack techniques, including\nman-in-the-middle (MITM) and false data injection (FDI), are simulated using\nModel Predictive Control (MPC) controller to identify vulnerabilities and\nweaknesses of the platoon controller. Countermeasures are offered and tested,\nthat includes attack analysis and reinforced communication protocols using\nMachine Learning techniques for detection. The findings emphasize the\nsignificance of integrating security issues into their design and\nimplementation, which helps to construct safe and resilient distributed platoon\ncontrollers.",
      "tldr_zh": "本论文探讨了分布式车辆编队控制器的攻击弹性，旨在通过模拟各种网络攻击（如 Man-in-the-Middle (MITM) 和 False Data Injection (FDI)）来评估其对系统安全和性能的影响。\n研究采用 Model Predictive Control (MPC) 作为核心方法，模拟攻击场景并识别控制器漏洞，同时提出 countermeasures，包括使用 Machine Learning 技术进行攻击检测和强化通信协议。\n结果表明，整合安全措施到设计和实施过程中至关重要，有助于构建更具弹性和可靠的分布式编队控制器。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "68T99",
        "C.3; I.2"
      ],
      "primary_category": "eess.SY",
      "comment": "Thesis",
      "pdf_url": "http://arxiv.org/pdf/2401.04736v1",
      "published_date": "2024-01-08 20:27:16 UTC",
      "updated_date": "2024-01-08 20:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:25:32.798975"
    },
    {
      "arxiv_id": "2401.04210v1",
      "title": "FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi-Song Liu",
        "Robin Courant",
        "Vicky Kalogeiton"
      ],
      "abstract": "Automatically understanding funny moments (i.e., the moments that make people\nlaugh) when watching comedy is challenging, as they relate to various features,\nsuch as body language, dialogues and culture. In this paper, we propose\nFunnyNet-W, a model that relies on cross- and self-attention for visual, audio\nand text data to predict funny moments in videos. Unlike most methods that rely\non ground truth data in the form of subtitles, in this work we exploit\nmodalities that come naturally with videos: (a) video frames as they contain\nvisual information indispensable for scene understanding, (b) audio as it\ncontains higher-level cues associated with funny moments, such as intonation,\npitch and pauses and (c) text automatically extracted with a speech-to-text\nmodel as it can provide rich information when processed by a Large Language\nModel. To acquire labels for training, we propose an unsupervised approach that\nspots and labels funny audio moments. We provide experiments on five datasets:\nthe sitcoms TBBT, MHD, MUStARD, Friends, and the TED talk UR-Funny. Extensive\nexperiments and analysis show that FunnyNet-W successfully exploits visual,\nauditory and textual cues to identify funny moments, while our findings reveal\nFunnyNet-W's ability to predict funny moments in the wild. FunnyNet-W sets the\nnew state of the art for funny moment detection with multimodal cues on all\ndatasets with and without using ground truth information.",
      "tldr_zh": "这篇论文提出了 FunnyNet-W 模型，通过 cross-attention 和 self-attention 处理视觉、音频和文本数据，来自动预测视频中的搞笑时刻。不同于依赖 ground truth 字幕的传统方法，FunnyNet-W 利用视频帧（提供视觉信息）、音频（捕捉 intonation、pitch 和 pauses 等线索）以及自动提取的 speech-to-text 文本进行多模态学习，并采用无监督方法识别和标记搞笑音频时刻。实验在 TBBT、MHD、MUStARD、Friends 和 UR-Funny 等五个数据集上显示，FunnyNet-W 成功利用 multimodal cues 设置了新的 state of the art 性能，即使不使用 ground truth 信息。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.04210v1",
      "published_date": "2024-01-08 19:39:36 UTC",
      "updated_date": "2024-01-08 19:39:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:25:46.245042"
    },
    {
      "arxiv_id": "2401.04206v4",
      "title": "Effects of Multimodal Explanations for Autonomous Driving on Driving Performance, Cognitive Load, Expertise, Confidence, and Trust",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Kaufman",
        "Jean Costa",
        "Everlyne Kimani"
      ],
      "abstract": "Advances in autonomous driving provide an opportunity for AI-assisted driving\ninstruction that directly addresses the critical need for human driving\nimprovement. How should an AI instructor convey information to promote\nlearning? In a pre-post experiment (n = 41), we tested the impact of an AI\nCoach's explanatory communications modeled after performance driving expert\ninstructions. Participants were divided into four (4) groups to assess two (2)\ndimensions of the AI coach's explanations: information type ('what' and\n'why'-type explanations) and presentation modality (auditory and visual). We\ncompare how different explanatory techniques impact driving performance,\ncognitive load, confidence, expertise, and trust via observational learning.\nThrough interview, we delineate participant learning processes. Results show AI\ncoaching can effectively teach performance driving skills to novices. We find\nthe type and modality of information influences performance outcomes.\nDifferences in how successfully participants learned are attributed to how\ninformation directs attention, mitigates uncertainty, and influences overload\nexperienced by participants. Results suggest efficient, modality-appropriate\nexplanations should be opted for when designing effective HMI communications\nthat can instruct without overwhelming. Further, results support the need to\nalign communications with human learning and cognitive processes. We provide\neight design implications for future autonomous vehicle HMI and AI coach\ndesign.",
      "tldr_zh": "这篇论文探讨了多模态解释（包括 'what' 和 'why' 类型，以及听觉和视觉模式）对自主驾驶的影响，通过一个涉及 41 名参与者的预后实验，评估了这些解释对驾驶表现、认知负荷、专业知识、信心和信任的影响。结果显示，AI Coach 的解释能有效教导新手驾驶技能，不同的信息类型和呈现模式会显著改变学习效果，因为它们能引导注意力、减少不确定性并减轻认知负荷。研究强调，应设计高效且适合人类学习过程的 HMI 通信，并提供了八点设计启示，以优化未来自主车辆和 AI 教练系统。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, published in Scientific Reports",
      "pdf_url": "http://arxiv.org/pdf/2401.04206v4",
      "published_date": "2024-01-08 19:33:57 UTC",
      "updated_date": "2024-06-13 17:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:25:58.038891"
    },
    {
      "arxiv_id": "2401.04198v1",
      "title": "Curiosity & Entropy Driven Unsupervised RL in Multiple Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Shaurya Dewan",
        "Anisha Jain",
        "Zoe LaLena",
        "Lifan Yu"
      ],
      "abstract": "The authors of 'Unsupervised Reinforcement Learning in Multiple environments'\npropose a method, alpha-MEPOL, to tackle unsupervised RL across multiple\nenvironments. They pre-train a task-agnostic exploration policy using\ninteractions from an entire environment class and then fine-tune this policy\nfor various tasks using supervision. We expanded upon this work, with the goal\nof improving performance. We primarily propose and experiment with five new\nmodifications to the original work: sampling trajectories using an\nentropy-based probability distribution, dynamic alpha, higher KL Divergence\nthreshold, curiosity-driven exploration, and alpha-percentile sampling on\ncuriosity. Dynamic alpha and higher KL-Divergence threshold both provided a\nsignificant improvement over the baseline from the earlier work. PDF-sampling\nfailed to provide any improvement due to it being approximately equivalent to\nthe baseline method when the sample space is small. In high-dimensional\nenvironments, the addition of curiosity-driven exploration enhances learning by\nencouraging the agent to seek diverse experiences and explore the unknown more.\nHowever, its benefits are limited in low-dimensional and simpler environments\nwhere exploration possibilities are constrained and there is little that is\ntruly unknown to the agent. Overall, some of our experiments did boost\nperformance over the baseline and there are a few directions that seem\npromising for further research.",
      "tldr_zh": "本文扩展了alpha-MEPOL方法，用于多环境下的无监督强化学习（unsupervised RL），通过引入五个新改进：基于熵的概率分布采样轨迹、动态alpha、更高的KL Divergence阈值、好奇心驱动探索，以及alpha-percentile采样。实验结果表明，动态alpha和更高的KL Divergence阈值显著提升了基线性能，而好奇心驱动探索在高维环境中促进了代理的多样性探索，但在低维环境中效果有限。总体上，这些修改提高了探索效率，并为未来研究提供了有前景的方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04198v1",
      "published_date": "2024-01-08 19:25:40 UTC",
      "updated_date": "2024-01-08 19:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:26:10.100059"
    },
    {
      "arxiv_id": "2401.04192v1",
      "title": "Interactive Multi-Objective Evolutionary Optimization of Software Architectures",
      "title_zh": "交互式多目标进化优化软件架构",
      "authors": [
        "Aurora Ramírez",
        "José Raúl Romero",
        "Sebastián Ventura"
      ],
      "abstract": "While working on a software specification, designers usually need to evaluate\ndifferent architectural alternatives to be sure that quality criteria are met.\nEven when these quality aspects could be expressed in terms of multiple\nsoftware metrics, other qualitative factors cannot be numerically measured, but\nthey are extracted from the engineer's know-how and prior experiences. In fact,\ndetecting not only strong but also weak points in the different solutions seems\nto fit better with the way humans make their decisions. Putting the human in\nthe loop brings new challenges to the search-based software engineering field,\nespecially for those human-centered activities within the early analysis phase.\nThis paper explores how the interactive evolutionary computation can serve as a\nbasis for integrating the human's judgment into the search process. An\ninteractive approach is proposed to discover software architectures, in which\nboth quantitative and qualitative criteria are applied to guide a\nmulti-objective evolutionary algorithm. The obtained feedback is incorporated\ninto the fitness function using architectural preferences allowing the\nalgorithm to discern between promising and poor solutions. Experimentation with\nreal users has revealed that the proposed interaction mechanism can effectively\nguide the search towards those regions of the search space that are of real\ninterest to the expert.",
      "tldr_zh": "这篇论文提出了一种交互式多目标进化优化方法，用于软件架构设计，旨在整合定量指标（如软件度量）和定性因素（如工程师经验），以帮助设计师评估架构备选方案。方法通过将人类判断纳入多-objective evolutionary algorithm的搜索过程，利用反馈机制调整适应度函数，从而区分出有前景的解决方案。实验结果显示，这种交互式机制能有效引导算法向专家感兴趣的搜索空间区域收敛，提高了架构优化的实用性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.NE",
        "68",
        "D.2.11; F.2.2"
      ],
      "primary_category": "cs.SE",
      "comment": "41 pages, 5 figures, journal \"Information Sciences\"",
      "pdf_url": "http://arxiv.org/pdf/2401.04192v1",
      "published_date": "2024-01-08 19:15:40 UTC",
      "updated_date": "2024-01-08 19:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:26:21.476711"
    },
    {
      "arxiv_id": "2401.04105v2",
      "title": "Dr$^2$Net: Dynamic Reversible Dual-Residual Networks for Memory-Efficient Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Zhao",
        "Shuming Liu",
        "Karttikeya Mangalam",
        "Guocheng Qian",
        "Fatimah Zohra",
        "Abdulmohsen Alghannam",
        "Jitendra Malik",
        "Bernard Ghanem"
      ],
      "abstract": "Large pretrained models are increasingly crucial in modern computer vision\ntasks. These models are typically used in downstream tasks by end-to-end\nfinetuning, which is highly memory-intensive for tasks with high-resolution\ndata, e.g., video understanding, small object detection, and point cloud\nanalysis. In this paper, we propose Dynamic Reversible Dual-Residual Networks,\nor Dr$^2$Net, a novel family of network architectures that acts as a surrogate\nnetwork to finetune a pretrained model with substantially reduced memory\nconsumption. Dr$^2$Net contains two types of residual connections, one\nmaintaining the residual structure in the pretrained models, and the other\nmaking the network reversible. Due to its reversibility, intermediate\nactivations, which can be reconstructed from output, are cleared from memory\nduring training. We use two coefficients on either type of residual connections\nrespectively, and introduce a dynamic training strategy that seamlessly\ntransitions the pretrained model to a reversible network with much higher\nnumerical precision. We evaluate Dr$^2$Net on various pretrained models and\nvarious tasks, and show that it can reach comparable performance to\nconventional finetuning but with significantly less memory usage.",
      "tldr_zh": "本文提出Dr²Net，一种动态可逆双残差网络架构，旨在解决大型预训练模型在高分辨率任务（如视频理解和小物体检测）中的端到端微调内存消耗问题。Dr²Net通过两种残差连接（一种保持预训练模型的结构，另一种实现网络可逆性）结合动态训练策略，使中间激活可从输出重建，从而在训练过程中清除内存。实验结果显示，Dr²Net在各种预训练模型和任务上可达到与传统微调相当的性能，但内存使用显著减少。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04105v2",
      "published_date": "2024-01-08 18:59:31 UTC",
      "updated_date": "2024-03-30 08:06:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:26:36.760449"
    },
    {
      "arxiv_id": "2401.06795v2",
      "title": "AI and Generative AI for Research Discovery and Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Glickman",
        "Yi Zhang"
      ],
      "abstract": "AI and generative AI tools, including chatbots like ChatGPT that rely on\nlarge language models (LLMs), have burst onto the scene this year, creating\nincredible opportunities to increase work productivity and improve our lives.\nStatisticians and data scientists have begun experiencing the benefits from the\navailability of these tools in numerous ways, such as the generation of\nprogramming code from text prompts to analyze data or fit statistical models.\nOne area that these tools can make a substantial impact is in research\ndiscovery and summarization. Standalone tools and plugins to chatbots are being\ndeveloped that allow researchers to more quickly find relevant literature than\npre-2023 search tools. Furthermore, generative AI tools have improved to the\npoint where they can summarize and extract the key points from research\narticles in succinct language. Finally, chatbots based on highly parameterized\nLLMs can be used to simulate abductive reasoning, which provides researchers\nthe ability to make connections among related technical topics, which can also\nbe used for research discovery. We review the developments in AI and generative\nAI for research discovery and summarization, and propose directions where these\ntypes of tools are likely to head in the future that may be of interest to\nstatistician and data scientists.",
      "tldr_zh": "本论文探讨了AI和生成式AI（如ChatGPT和LLMs）在研究发现和总结中的应用，这些工具能显著提升工作效率，例如通过文本提示生成编程代码来分析数据或拟合统计模型。作者强调，AI工具可加速相关文献的检索、提取文章关键点并以简洁语言总结内容，同时利用高度参数化的LLMs模拟演绎推理，帮助研究人员连接相关技术主题。论文回顾了这些工具的发展，并提出未来方向，如更先进的插件和chatbots，可能对统计学家和数据科学家特别有益。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.06795v2",
      "published_date": "2024-01-08 18:42:55 UTC",
      "updated_date": "2024-03-26 16:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:26:45.717890"
    },
    {
      "arxiv_id": "2401.04081v2",
      "title": "MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Maciej Pióro",
        "Kamil Ciebiera",
        "Krystian Król",
        "Jan Ludziejewski",
        "Michał Krutul",
        "Jakub Krajewski",
        "Szymon Antoniak",
        "Piotr Miłoś",
        "Marek Cygan",
        "Sebastian Jaszczur"
      ],
      "abstract": "State Space Models (SSMs) have become serious contenders in the field of\nsequential modeling, challenging the dominance of Transformers. At the same\ntime, Mixture of Experts (MoE) has significantly improved Transformer-based\nLarge Language Models, including recent state-of-the-art open models. We\npropose that to unlock the potential of SSMs for scaling, they should be\ncombined with MoE. We showcase this on Mamba, a recent SSM-based model that\nachieves remarkable performance. Our model, MoE-Mamba, outperforms both Mamba\nand baseline Transformer-MoE. In particular, MoE-Mamba reaches the same\nperformance as Mamba in $2.35\\times$ fewer training steps while preserving the\ninference performance gains of Mamba against Transformer.",
      "tldr_zh": "本论文提出 MoE-Mamba，一种将 Mixture of Experts (MoE) 与 State Space Models (SSMs) 相结合的模型，旨在提升序列建模的效率和可扩展性。MoE-Mamba 基于现有的 SSM 模型 Mamba，允许选择性专家参与以优化性能。实验结果显示，MoE-Mamba 在 2.35 倍更少的训练步骤中达到与 Mamba 相同的性能，同时保留了 Mamba 在推理速度上的优势，并整体超过了 Mamba 和 Transformer-MoE 的基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04081v2",
      "published_date": "2024-01-08 18:35:07 UTC",
      "updated_date": "2024-02-26 17:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:26:59.067955"
    },
    {
      "arxiv_id": "2401.04057v1",
      "title": "Unveiling Bias in Fairness Evaluations of Large Language Models: A Critical Literature Review of Music and Movie Recommendation Systems",
      "title_zh": "揭示大型语言模型公平",
      "authors": [
        "Chandan Kumar Sah",
        "Lian Xiaoli",
        "Muhammad Mirajul Islam"
      ],
      "abstract": "The rise of generative artificial intelligence, particularly Large Language\nModels (LLMs), has intensified the imperative to scrutinize fairness alongside\naccuracy. Recent studies have begun to investigate fairness evaluations for\nLLMs within domains such as recommendations. Given that personalization is an\nintrinsic aspect of recommendation systems, its incorporation into fairness\nassessments is paramount. Yet, the degree to which current fairness evaluation\nframeworks account for personalization remains unclear. Our comprehensive\nliterature review aims to fill this gap by examining how existing frameworks\nhandle fairness evaluations of LLMs, with a focus on the integration of\npersonalization factors. Despite an exhaustive collection and analysis of\nrelevant works, we discovered that most evaluations overlook personalization, a\ncritical facet of recommendation systems, thereby inadvertently perpetuating\nunfair practices. Our findings shed light on this oversight and underscore the\nurgent need for more nuanced fairness evaluations that acknowledge\npersonalization. Such improvements are vital for fostering equitable\ndevelopment within the AI community.",
      "tldr_zh": "本研究通过对现有文献的批判性审视，揭示了大型语言模型(LLMs)在音乐和电影推荐系统中的公平性评估中存在的偏见问题，特别是忽略了个性化因素的重要性。作者分析发现，大多数评估框架未充分考虑推荐系统的个性化特性，从而无意中 perpetuated 不公平实践。最终，该论文强调需要更细致的公平性评估框架，以推动 AI 社区的公平发展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.04057v1",
      "published_date": "2024-01-08 17:57:29 UTC",
      "updated_date": "2024-01-08 17:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:27:10.389064"
    },
    {
      "arxiv_id": "2401.04023v1",
      "title": "Efficient Multiscale Multimodal Bottleneck Transformer for Audio-Video Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Zhu"
      ],
      "abstract": "In recent years, researchers combine both audio and video signals to deal\nwith challenges where actions are not well represented or captured by visual\ncues. However, how to effectively leverage the two modalities is still under\ndevelopment. In this work, we develop a multiscale multimodal Transformer (MMT)\nthat leverages hierarchical representation learning. Particularly, MMT is\ncomposed of a novel multiscale audio Transformer (MAT) and a multiscale video\nTransformer [43]. To learn a discriminative cross-modality fusion, we further\ndesign multimodal supervised contrastive objectives called audio-video\ncontrastive loss (AVC) and intra-modal contrastive loss (IMC) that robustly\nalign the two modalities. MMT surpasses previous state-of-the-art approaches by\n7.3% and 2.1% on Kinetics-Sounds and VGGSound in terms of the top-1 accuracy\nwithout external training data. Moreover, the proposed MAT significantly\noutperforms AST [28] by 22.2%, 4.4% and 4.7% on three public benchmark\ndatasets, and is about 3% more efficient based on the number of FLOPs and 9.8%\nmore efficient based on GPU memory usage.",
      "tldr_zh": "本文提出了一种高效的多尺度多模态 Bottleneck Transformer (MMT) 用于音频-视频分类，通过整合音频和视频模态来处理视觉线索不足的动作识别挑战。MMT 包括多尺度音频 Transformer (MAT) 和多尺度视频 Transformer，并采用音频-视频对比损失 (AVC) 和 intra-modal 对比损失 (IMC) 来实现鲁棒的跨模态融合和判别性学习。实验结果显示，MMT 在 Kinetics-Sounds 和 VGGSound 数据集上分别比现有最佳方法提高了 7.3% 和 2.1% 的 top-1 准确率，且 MAT 相较于 AST 模型在三个基准数据集上提升了 22.2%、4.4% 和 4.7%，同时在 FLOPs 和 GPU 内存使用上更高效。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by WACV 2024; well-formatted PDF is in\n  https://drive.google.com/file/d/10Zo_ydJZFAm7YsxHDgTjhyc4dEJbW_dk/view?usp=sharing",
      "pdf_url": "http://arxiv.org/pdf/2401.04023v1",
      "published_date": "2024-01-08 17:02:25 UTC",
      "updated_date": "2024-01-08 17:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:27:25.748662"
    },
    {
      "arxiv_id": "2401.04154v1",
      "title": "Efficient Selective Audio Masked Multimodal Bottleneck Transformer for Audio-Video Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Zhu"
      ],
      "abstract": "Audio and video are two most common modalities in the mainstream media\nplatforms, e.g., YouTube. To learn from multimodal videos effectively, in this\nwork, we propose a novel audio-video recognition approach termed audio video\nTransformer, AVT, leveraging the effective spatio-temporal representation by\nthe video Transformer to improve action recognition accuracy. For multimodal\nfusion, simply concatenating multimodal tokens in a cross-modal Transformer\nrequires large computational and memory resources, instead we reduce the\ncross-modality complexity through an audio-video bottleneck Transformer. To\nimprove the learning efficiency of multimodal Transformer, we integrate\nself-supervised objectives, i.e., audio-video contrastive learning, audio-video\nmatching, and masked audio and video learning, into AVT training, which maps\ndiverse audio and video representations into a common multimodal representation\nspace. We further propose a masked audio segment loss to learn semantic audio\nactivities in AVT. Extensive experiments and ablation studies on three public\ndatasets and two in-house datasets consistently demonstrate the effectiveness\nof the proposed AVT. Specifically, AVT outperforms its previous\nstate-of-the-art counterparts on Kinetics-Sounds by 8%. AVT also surpasses one\nof the previous state-of-the-art video Transformers [25] by 10% on VGGSound by\nleveraging the audio signal. Compared to one of the previous state-of-the-art\nmultimodal methods, MBT [32], AVT is 1.3% more efficient in terms of FLOPs and\nimproves the accuracy by 3.8% on Epic-Kitchens-100.",
      "tldr_zh": "本研究提出了一种高效的多模态音频-视频分类框架，名为 Efficient Selective Audio Masked Multimodal Bottleneck Transformer (AVT)，旨在通过视频 Transformer's 时空表示提升动作识别准确性，同时采用瓶颈 Transformer 减少跨模态融合的计算和内存开销。AVT 整合了自监督目标，包括音频-视频对比学习、匹配学习以及 masked 音频和视频学习，以将音频和视频表示映射到共同的多模态空间，并引入 masked audio segment loss 来学习语义音频活动。在多个公开数据集（如 Kinetics-Sounds、VGGSound 和 Epic-Kitchens-100）上的实验显示，AVT 比先前最先进方法提高了 8% 到 10% 的准确率，且在 FLOPs 效率上比 MBT 提升 1.3%。这项工作为多模态视频处理提供了更高效且有效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by WACV 2024; well-formatted PDF is in\n  https://drive.google.com/file/d/1qvW52lamsvNGMCqPS7q8g8L4NaR_LlbR/view?usp=sharing.\n  arXiv admin note: text overlap with arXiv:2401.04023",
      "pdf_url": "http://arxiv.org/pdf/2401.04154v1",
      "published_date": "2024-01-08 16:58:59 UTC",
      "updated_date": "2024-01-08 16:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:27:35.960001"
    },
    {
      "arxiv_id": "2401.04152v2",
      "title": "Cross-Speaker Encoding Network for Multi-Talker Speech Recognition",
      "title_zh": "跨说话者编码网络用于多说话者语音识别",
      "authors": [
        "Jiawen Kang",
        "Lingwei Meng",
        "Mingyu Cui",
        "Haohan Guo",
        "Xixin Wu",
        "Xunying Liu",
        "Helen Meng"
      ],
      "abstract": "End-to-end multi-talker speech recognition has garnered great interest as an\neffective approach to directly transcribe overlapped speech from multiple\nspeakers. Current methods typically adopt either 1) single-input\nmultiple-output (SIMO) models with a branched encoder, or 2) single-input\nsingle-output (SISO) models based on attention-based encoder-decoder\narchitecture with serialized output training (SOT). In this work, we propose a\nCross-Speaker Encoding (CSE) network to address the limitations of SIMO models\nby aggregating cross-speaker representations. Furthermore, the CSE model is\nintegrated with SOT to leverage both the advantages of SIMO and SISO while\nmitigating their drawbacks. To the best of our knowledge, this work represents\nan early effort to integrate SIMO and SISO for multi-talker speech recognition.\nExperiments on the two-speaker LibrispeechMix dataset show that the CES model\nreduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model\nreduces WER by 10% overall and by 16% on high-overlap speech compared to the\nSOT model. Code is available at https://github.com/kjw11/CSEnet-ASR.",
      "tldr_zh": "该论文提出Cross-Speaker Encoding (CSE) 网络，用于端到端多说话人语音识别，通过聚合跨说话人表示来克服现有Single-Input Multiple-Output (SIMO) 模型的局限性，并将其与序列化输出训练 (SOT) 整合，结合SIMO和Single-Input Single-Output (SISO) 模型的优势。CSE模型在LibrispeechMix数据集上的实验中，比SIMO基线减少8%的词错误率 (WER)。此外，CSE-SOT模型整体比SOT模型减少10%的WER，并在高重叠语音场景中减少16%，展示了其在处理重叠语音方面的显著改进。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICASSP2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04152v2",
      "published_date": "2024-01-08 16:37:45 UTC",
      "updated_date": "2024-07-22 12:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:27:47.290987"
    },
    {
      "arxiv_id": "2401.04003v3",
      "title": "Simultaneous Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications",
      "title_zh": "翻译失败",
      "authors": [
        "Xusheng Luo",
        "Changliu Liu"
      ],
      "abstract": "Research in robotic planning with temporal logic specifications, such as\nsyntactically co-safe Linear Temporal Logic (sc-LTL), has relied on single\nformulas. However, as task complexity increases, sc-LTL formulas become\nlengthy, making them difficult to interpret and generate, and straining the\ncomputational capacities of planners. To address this, we introduce a\nhierarchical structure to sc-LTL specifications with both syntax and semantics,\nproving it to be more expressive than flat counterparts. We conducted a user\nstudy that compared the flat sc-LTL with our hierarchical version and found\nthat users could more easily comprehend complex tasks using the hierarchical\nstructure. We develop a search-based approach to synthesize plans for\nmulti-robot systems, achieving simultaneous task allocation and planning. This\nmethod approximates the search space by loosely interconnected sub-spaces, each\ncorresponding to an sc-LTL specification. The search primarily focuses on a\nsingle sub-space, transitioning to another under conditions determined by the\ndecomposition of automatons. We develop multiple heuristics to significantly\nexpedite the search. Our theoretical analysis, conducted under mild\nassumptions, addresses completeness and optimality. Compared to existing\nmethods used in various simulators for service tasks, our approach improves\nplanning times while maintaining comparable solution quality.",
      "tldr_zh": "本研究针对多机器人系统下的 sc-LTL 规范问题，引入了具有语法和语义层次结构的改进版本，以提升任务表达性和可解读性，并通过用户研究证实了其对复杂任务理解的显著优势。我们开发了一种基于搜索的方法，实现 sc-LTL 规范下的任务分配和规划同时进行，通过将搜索空间分解为松散连接的子空间、应用启发式算法和自动机分解来加速过程。在理论分析下，该方法在温和假设中确保了完整性和最优性，并在实验中比现有方法显著缩短了规划时间，同时保持了相似的解决方案质量。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.04003v3",
      "published_date": "2024-01-08 16:35:13 UTC",
      "updated_date": "2024-08-14 18:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:27:59.509925"
    },
    {
      "arxiv_id": "2401.03999v1",
      "title": "Polynomial Precision Dependence Solutions to Alignment Research Center Matrix Completion Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Rico Angell"
      ],
      "abstract": "We present solutions to the matrix completion problems proposed by the\nAlignment Research Center that have a polynomial dependence on the precision\n$\\varepsilon$. The motivation for these problems is to enable efficient\ncomputation of heuristic estimators to formally evaluate and reason about\ndifferent quantities of deep neural networks in the interest of AI alignment.\nOur solutions involve reframing the matrix completion problems as a\nsemidefinite program (SDP) and using recent advances in spectral bundle methods\nfor fast, efficient, and scalable SDP solving.",
      "tldr_zh": "该论文针对 Alignment Research Center 提出的矩阵补全问题，提供了具有多项式精度依赖（Polynomial Precision Dependence）的解决方案，以实现高效计算启发式估计器，用于正式评估和推理深度神经网络的各种量，从而服务于 AI alignment。研究方法包括将矩阵补全问题重构为半正定规划（Semidefinite Program, SDP），并利用最近的谱束方法（Spectral Bundle Methods）进行快速、有效和可扩展的求解。这些创新有助于提升 AI 对齐研究的计算效率和可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03999v1",
      "published_date": "2024-01-08 16:25:45 UTC",
      "updated_date": "2024-01-08 16:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:28:10.394933"
    },
    {
      "arxiv_id": "2401.03993v1",
      "title": "Behavioural Cloning in VizDoom",
      "title_zh": "VizDoom 中的行为克隆",
      "authors": [
        "Ryan Spick",
        "Timothy Bradley",
        "Ayush Raina",
        "Pierluigi Vito Amadori",
        "Guy Moss"
      ],
      "abstract": "This paper describes methods for training autonomous agents to play the game\n\"Doom 2\" through Imitation Learning (IL) using only pixel data as input. We\nalso explore how Reinforcement Learning (RL) compares to IL for humanness by\ncomparing camera movement and trajectory data. Through behavioural cloning, we\nexamine the ability of individual models to learn varying behavioural traits.\nWe attempt to mimic the behaviour of real players with different play styles,\nand find we can train agents that behave aggressively, passively, or simply\nmore human-like than traditional AIs. We propose these methods of introducing\nmore depth and human-like behaviour to agents in video games. The trained IL\nagents perform on par with the average players in our dataset, whilst\noutperforming the worst players. While performance was not as strong as common\nRL approaches, it provides much stronger human-like behavioural traits to the\nagent.",
      "tldr_zh": "本文使用 Imitation Learning (IL) 通过 Behavioural Cloning 方法训练自主代理在 VizDoom 中玩 Doom 2，仅依赖像素数据作为输入，旨在模仿不同玩家的行为特质，如攻击性、被动性或更人性化。研究比较了 IL 与 Reinforcement Learning (RL)，发现 IL 代理在相机运动和轨迹数据上表现出更强的“人性化”行为，尽管整体性能不如 RL 方法。实验结果表明，训练的 IL 代理性能与数据集中的平均玩家相当，并优于最差玩家。总体上，这为视频游戏中的代理引入更深度和人类-like 行为提供了新颖方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.03993v1",
      "published_date": "2024-01-08 16:15:43 UTC",
      "updated_date": "2024-01-08 16:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:28:23.842312"
    },
    {
      "arxiv_id": "2401.03991v1",
      "title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Fangjun Li",
        "David C. Hogg",
        "Anthony G. Cohn"
      ],
      "abstract": "Artificial intelligence (AI) has made remarkable progress across various\ndomains, with large language models like ChatGPT gaining substantial attention\nfor their human-like text-generation capabilities. Despite these achievements,\nspatial reasoning remains a significant challenge for these models. Benchmarks\nlike StepGame evaluate AI spatial reasoning, where ChatGPT has shown\nunsatisfactory performance. However, the presence of template errors in the\nbenchmark has an impact on the evaluation results. Thus there is potential for\nChatGPT to perform better if these template errors are addressed, leading to\nmore accurate assessments of its spatial reasoning capabilities. In this study,\nwe refine the StepGame benchmark, providing a more accurate dataset for model\nevaluation. We analyze GPT's spatial reasoning performance on the rectified\nbenchmark, identifying proficiency in mapping natural language text to spatial\nrelations but limitations in multi-hop reasoning. We provide a flawless\nsolution to the benchmark by combining template-to-relation mapping with\nlogic-based reasoning. This combination demonstrates proficiency in performing\nqualitative reasoning on StepGame without encountering any errors. We then\naddress the limitations of GPT models in spatial reasoning. We deploy\nChain-of-thought and Tree-of-thoughts prompting strategies, offering insights\ninto GPT's ``cognitive process\", and achieving remarkable improvements in\naccuracy. Our investigation not only sheds light on model deficiencies but also\nproposes enhancements, contributing to the advancement of AI with more robust\nspatial reasoning capabilities.",
      "tldr_zh": "这篇论文评估并提升了大型语言模型（Large Language Models）在空间推理方面的能力，使用修正后的 StepGame Benchmark 作为基准。研究发现，GPT 模型擅长将自然语言文本映射到空间关系，但存在多跳推理的局限性，并通过结合模板到关系映射和基于逻辑的推理，提供了一个无误的基准解决方案。作者采用 Chain-of-thought 和 Tree-of-thoughts 提示策略，显著提高了模型的准确性。最终，这为AI模型的缺陷分析和空间推理能力提升提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Camera-Ready version for AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03991v1",
      "published_date": "2024-01-08 16:13:08 UTC",
      "updated_date": "2024-01-08 16:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:28:38.603385"
    },
    {
      "arxiv_id": "2401.03988v2",
      "title": "A Primer on Temporal Graph Learning",
      "title_zh": "时序图学习入门",
      "authors": [
        "Aniq Ur Rahman",
        "Justin P. Coon"
      ],
      "abstract": "This document aims to familiarize readers with temporal graph learning (TGL)\nthrough a concept-first approach. We have systematically presented vital\nconcepts essential for understanding the workings of a TGL framework. In\naddition to qualitative explanations, we have incorporated mathematical\nformulations where applicable, enhancing the clarity of the text. Since TGL\ninvolves temporal and spatial learning, we introduce relevant learning\narchitectures ranging from recurrent and convolutional neural networks to\ntransformers and graph neural networks. We also discuss classical time series\nforecasting methods to inspire interpretable learning solutions for TGL.",
      "tldr_zh": "这篇论文作为时间图学习 (Temporal Graph Learning, TGL) 的入门指南，通过概念优先的方法系统介绍其核心概念，包括定性解释和数学公式。论文涵盖了涉及时间和空间学习的架构，如循环神经网络 (Recurrent Neural Networks)、卷积神经网络 (Convolutional Neural Networks)、Transformers 和图神经网络 (Graph Neural Networks)。此外，它讨论了经典时间序列预测方法，以启发 TGL 的可解释性学习解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM",
        "cs.SI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 47 equations",
      "pdf_url": "http://arxiv.org/pdf/2401.03988v2",
      "published_date": "2024-01-08 16:08:21 UTC",
      "updated_date": "2024-01-09 15:47:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:28:48.202275"
    },
    {
      "arxiv_id": "2401.03955v8",
      "title": "Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Vijay Ekambaram",
        "Arindam Jati",
        "Pankaj Dayama",
        "Sumanta Mukherjee",
        "Nam H. Nguyen",
        "Wesley M. Gifford",
        "Chandra Reddy",
        "Jayant Kalagnanam"
      ],
      "abstract": "Large pre-trained models excel in zero/few-shot learning for language and\nvision tasks but face challenges in multivariate time series (TS) forecasting\ndue to diverse data characteristics. Consequently, recent research efforts have\nfocused on developing pre-trained TS forecasting models. These models, whether\nbuilt from scratch or adapted from large language models (LLMs), excel in\nzero/few-shot forecasting tasks. However, they are limited by slow performance,\nhigh computational demands, and neglect of cross-channel and exogenous\ncorrelations. To address this, we introduce Tiny Time Mixers (TTM), a compact\nmodel (starting from 1M parameters) with effective transfer learning\ncapabilities, trained exclusively on public TS datasets. TTM, based on the\nlight-weight TSMixer architecture, incorporates innovations like adaptive\npatching, diverse resolution sampling, and resolution prefix tuning to handle\npre-training on varied dataset resolutions with minimal model capacity.\nAdditionally, it employs multi-level modeling to capture channel correlations\nand infuse exogenous signals during fine-tuning. TTM outperforms existing\npopular benchmarks in zero/few-shot forecasting by (4-40%), while reducing\ncomputational requirements significantly. Moreover, TTMs are lightweight and\ncan be executed even on CPU-only machines, enhancing usability and fostering\nwider adoption in resource-constrained environments. The model weights for\nreproducibility and research use are available at\nhttps://huggingface.co/ibm/ttm-research-r2/, while enterprise-use weights under\nthe Apache license can be accessed as follows: the initial TTM-Q variant at\nhttps://huggingface.co/ibm-granite/granite-timeseries-ttm-r1, and the latest\nvariants (TTM-B, TTM-E, TTM-A) weights are available at\nhttps://huggingface.co/ibm-granite/granite-timeseries-ttm-r2.",
      "tldr_zh": "这篇论文介绍了 Tiny Time Mixers (TTMs)，一个紧凑的预训练模型（从1M参数起），旨在提升多变量时间序列（TS）的零/少样本预测性能，同时解决现有模型的慢速和高计算需求问题。TTM 基于轻量级 TSMixer 架构，创新性地整合了 adaptive patching、多样分辨率采样和 resolution prefix tuning 等技术，以处理不同数据集分辨率，并通过多级建模捕获通道相关性和外生信号。实验结果显示，TTM 在零/少样本预测任务中比现有基准高出4-40%，显著降低计算资源需求，并能在仅CPU的机器上运行，促进更广泛的应用。模型权重已在Hugging Face上公开，以支持可重复性和研究使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.03955v8",
      "published_date": "2024-01-08 15:21:21 UTC",
      "updated_date": "2024-11-07 15:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:29:02.922690"
    },
    {
      "arxiv_id": "2401.03925v1",
      "title": "Rastro-DM: data mining with a trail",
      "title_zh": "翻译失败",
      "authors": [
        "Marcus Vinicius Borela de Castro",
        "Remis Balaniuk"
      ],
      "abstract": "This paper proposes a methodology for documenting data mining (DM) projects,\nRastro-DM (Trail Data Mining), with a focus not on the model that is generated,\nbut on the processes behind its construction, in order to leave a trail (Rastro\nin Portuguese) of planned actions, training completed, results obtained, and\nlessons learned. The proposed practices are complementary to structuring\nmethodologies of DM, such as CRISP-DM, which establish a methodological and\nparadigmatic framework for the DM process. The application of best practices\nand their benefits is illustrated in a project called 'Cladop' that was created\nfor the classification of PDF documents associated with the investigative\nprocess of damages to the Brazilian Federal Public Treasury. Building the\nRastro-DM kit in the context of a project is a small step that can lead to an\ninstitutional leap to be achieved by sharing and using the trail across the\nenterprise.",
      "tldr_zh": "本论文提出了一种名为 Rastro-DM 的数据挖掘 (DM) 项目文档化方法，强调记录过程背后的计划行动、完成训练、获得结果以及吸取教训，而不是仅关注最终模型。Rastro-DM 与 CRISP-DM 等结构化方法互补，可为数据挖掘项目提供更全面的跟踪框架。在 'Cladop' 项目中，该方法应用于分类与巴西联邦公共财政损害相关的 PDF 文档，展示了其最佳实践如何促进项目共享和机构级进步。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "It was published in the Brazilian Federal Court of Accounts Journal\n  n. 145 on 2021\n  (https://revista.tcu.gov.br/ojs/index.php/RTCU/article/view/1733)",
      "pdf_url": "http://arxiv.org/pdf/2401.03925v1",
      "published_date": "2024-01-08 14:39:21 UTC",
      "updated_date": "2024-01-08 14:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:29:12.280892"
    },
    {
      "arxiv_id": "2401.03910v1",
      "title": "A Philosophical Introduction to Language Models -- Part I: Continuity With Classic Debates",
      "title_zh": "语言模型的哲学导论——第一部分：与经典辩论的连续性",
      "authors": [
        "Raphaël Millière",
        "Cameron Buckner"
      ],
      "abstract": "Large language models like GPT-4 have achieved remarkable proficiency in a\nbroad spectrum of language-based tasks, some of which are traditionally\nassociated with hallmarks of human intelligence. This has prompted ongoing\ndisagreements about the extent to which we can meaningfully ascribe any kind of\nlinguistic or cognitive competence to language models. Such questions have deep\nphilosophical roots, echoing longstanding debates about the status of\nartificial neural networks as cognitive models. This article -- the first part\nof two companion papers -- serves both as a primer on language models for\nphilosophers, and as an opinionated survey of their significance in relation to\nclassic debates in the philosophy cognitive science, artificial intelligence,\nand linguistics. We cover topics such as compositionality, language\nacquisition, semantic competence, grounding, world models, and the transmission\nof cultural knowledge. We argue that the success of language models challenges\nseveral long-held assumptions about artificial neural networks. However, we\nalso highlight the need for further empirical investigation to better\nunderstand their internal mechanisms. This sets the stage for the companion\npaper (Part II), which turns to novel empirical methods for probing the inner\nworkings of language models, and new philosophical questions prompted by their\nlatest developments.",
      "tldr_zh": "这篇论文作为哲学家对大型语言模型（Large Language Models，如 GPT-4）的入门指南，同时探讨这些模型在语言任务上的出色表现如何与认知科学、人工智能和语言学的经典辩论相连。作者调查了关键主题，包括组合性（compositionality）、语言习得（language acquisition）、语义能力（semantic competence）、接地（grounding）、世界模型（world models）和文化知识传播（transmission of cultural knowledge），并认为语言模型的成功挑战了关于人工神经网络（artificial neural networks）的传统假设。论文强调需要进一步的实证调查来理解这些模型的内部机制，为后续部分（Part II）奠定基础，该部分将聚焦于新型探测方法和新哲学问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03910v1",
      "published_date": "2024-01-08 14:12:31 UTC",
      "updated_date": "2024-01-08 14:12:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:29:24.827260"
    },
    {
      "arxiv_id": "2401.03890v6",
      "title": "A Survey on 3D Gaussian Splatting",
      "title_zh": "3D Gaussian Splatting 的综述",
      "authors": [
        "Guikun Chen",
        "Wenguan Wang"
      ],
      "abstract": "3D Gaussian splatting (GS) has emerged as a transformative technique in\nexplicit radiance field and computer graphics. This innovative approach,\ncharacterized by the use of millions of learnable 3D Gaussians, represents a\nsignificant departure from mainstream neural radiance field approaches, which\npredominantly use implicit, coordinate-based models to map spatial coordinates\nto pixel values. 3D GS, with its explicit scene representation and\ndifferentiable rendering algorithm, not only promises real-time rendering\ncapability but also introduces unprecedented levels of editability. This\npositions 3D GS as a potential game-changer for the next generation of 3D\nreconstruction and representation. In the present paper, we provide the first\nsystematic overview of the recent developments and critical contributions in\nthe domain of 3D GS. We begin with a detailed exploration of the underlying\nprinciples and the driving forces behind the emergence of 3D GS, laying the\ngroundwork for understanding its significance. A focal point of our discussion\nis the practical applicability of 3D GS. By enabling unprecedented rendering\nspeed, 3D GS opens up a plethora of applications, ranging from virtual reality\nto interactive media and beyond. This is complemented by a comparative analysis\nof leading 3D GS models, evaluated across various benchmark tasks to highlight\ntheir performance and practical utility. The survey concludes by identifying\ncurrent challenges and suggesting potential avenues for future research.\nThrough this survey, we aim to provide a valuable resource for both newcomers\nand seasoned researchers, fostering further exploration and advancement in\nexplicit radiance field.",
      "tldr_zh": "3D Gaussian Splatting (3D GS) 是一种新兴的显式辐射场技术，使用数百万可学习的 3D 高斯函数，实现实时渲染和高度可编辑性，与传统的神经辐射场 (neural radiance field) 方法相比，具有显著优势。\n本调查首次系统概述了 3D GS 的底层原理、关键贡献和发展驱动力，并探讨其在虚拟现实、交互媒体等领域的实际应用。\n通过比较领先模型在基准任务中的性能，该文识别了当前挑战，并提出未来研究方向，为初学者和资深研究者提供宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Ongoing project. Paper list:\n  https://github.com/guikunchen/Awesome3DGS ; Benchmark:\n  https://github.com/guikunchen/3DGS-Benchmarks",
      "pdf_url": "http://arxiv.org/pdf/2401.03890v6",
      "published_date": "2024-01-08 13:42:59 UTC",
      "updated_date": "2025-03-07 13:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:29:37.204820"
    },
    {
      "arxiv_id": "2401.03880v1",
      "title": "Metaheuristics for (Variable-Size) Mixed Optimization Problems: A Unified Taxonomy and Survey",
      "title_zh": "翻译失败",
      "authors": [
        "El-Ghazali Talbi"
      ],
      "abstract": "Many real world optimization problems are formulated as mixed-variable\noptimization problems (MVOPs) which involve both continuous and discrete\nvariables. MVOPs including dimensional variables are characterized by a\nvariable-size search space. Depending on the values of dimensional variables,\nthe number and type of the variables of the problem can vary dynamically. MVOPs\nand variable-size MVOPs (VMVOPs) are difficult to solve and raise a number of\nscientific challenges in the design of metaheuristics. Standard metaheuristics\nhave been first designed to address continuous or discrete optimization\nproblems, and are not able to tackle (V)MVOPs in an efficient way. The\ndevelopment of metaheuristics for solving such problems has attracted the\nattention of many researchers and is increasingly popular. However, to our\nknowledge there is no well established taxonomy and comprehensive survey for\nhandling this important family of optimization problems.\n  This paper presents a unified taxonomy for metaheuristic solutions for\nsolving (V)MVOPs in an attempt to provide a common terminology and\nclassification mechanisms. It provides a general mathematical formulation and\nconcepts of (V)MVOPs, and identifies the various solving methodologies than can\nbe applied in metaheuristics. The advantages, the weaknesses and the\nlimitations of the presented methodologies are discussed. The proposed taxonomy\nalso allows to identify some open research issues which needs further in-depth\ninvestigations.",
      "tldr_zh": "该论文针对混合变量优化问题(MVOPs)和变量大小MVOPs(VMVOPs)提出一个统一的分类法(taxonomy)和全面调查，这些问题涉及连续和离散变量，且搜索空间动态变化，导致标准metaheuristics难以高效解决。论文提供了MVOPs的通用数学公式、核心概念以及各种解决方法，详细讨论了这些方法的优势、弱点和限制。最终，该taxonomy有助于识别和突出未来metaheuristics研究的开放问题，如更深入的算法设计挑战。",
      "categories": [
        "cs.AI",
        "cs.DM",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03880v1",
      "published_date": "2024-01-08 13:24:55 UTC",
      "updated_date": "2024-01-08 13:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:29:48.972679"
    },
    {
      "arxiv_id": "2401.03868v2",
      "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
      "title_zh": "翻译失败",
      "authors": [
        "Shulin Zeng",
        "Jun Liu",
        "Guohao Dai",
        "Xinhao Yang",
        "Tianyu Fu",
        "Hongyi Wang",
        "Wenheng Ma",
        "Hanbo Sun",
        "Shiyao Li",
        "Zixiao Huang",
        "Yadong Dai",
        "Jintao Li",
        "Zehao Wang",
        "Ruoyu Zhang",
        "Kairui Wen",
        "Xuefei Ning",
        "Yu Wang"
      ],
      "abstract": "Transformer-based Large Language Models (LLMs) have made a significant impact\non various domains. However, LLMs' efficiency suffers from both heavy\ncomputation and memory overheads. Compression techniques like sparsification\nand quantization are commonly used to mitigate the gap between LLM's\ncomputation/memory overheads and hardware capacity. However, existing GPU and\ntransformer-based accelerators cannot efficiently process compressed LLMs, due\nto the following unresolved challenges: low computational efficiency,\nunderutilized memory bandwidth, and large compilation overheads.\n  This paper proposes FlightLLM, enabling efficient LLMs inference with a\ncomplete mapping flow on FPGAs. In FlightLLM, we highlight an innovative\nsolution that the computation and memory overhead of LLMs can be solved by\nutilizing FPGA-specific resources (e.g., DSP48 and heterogeneous memory\nhierarchy). We propose a configurable sparse DSP chain to support different\nsparsity patterns with high computation efficiency. Second, we propose an\nalways-on-chip decode scheme to boost memory bandwidth with mixed-precision\nsupport. Finally, to make FlightLLM available for real-world LLMs, we propose a\nlength adaptive compilation method to reduce the compilation overhead.\nImplemented on the Xilinx Alveo U280 FPGA, FlightLLM achieves 6.0$\\times$\nhigher energy efficiency and 1.8$\\times$ better cost efficiency against\ncommercial GPUs (e.g., NVIDIA V100S) on modern LLMs (e.g., LLaMA2-7B) using\nvLLM and SmoothQuant under the batch size of one. FlightLLM beats NVIDIA A100\nGPU with 1.2$\\times$ higher throughput using the latest Versal VHK158 FPGA.",
      "tldr_zh": "本研究提出FlightLLM，一种在FPGAs上实现高效Large Language Model (LLM)推理的完整映射流程，针对LLMs的计算和内存开销问题，通过利用FPGA特定资源（如DSP48和异构内存层次）来解决现有加速器效率低下的挑战。FlightLLM包括可配置的sparse DSP chain以支持不同sparsity patterns提高计算效率、always-on-chip decode scheme以提升内存带宽并支持mixed-precision，以及length adaptive compilation method以减少编译开销。在实验中，FlightLLM在Xilinx Alveo U280 FPGA上比NVIDIA V100S GPU实现6.0×更高的能量效率和1.8×更好的成本效率，并在Versal VHK158 FPGA上比NVIDIA A100 GPU提高1.2×吞吐量。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted to FPGA'24",
      "pdf_url": "http://arxiv.org/pdf/2401.03868v2",
      "published_date": "2024-01-08 13:00:53 UTC",
      "updated_date": "2024-01-09 06:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:30:01.445760"
    },
    {
      "arxiv_id": "2401.03857v1",
      "title": "Inverse Reinforcement Learning with Sub-optimal Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Poiani",
        "Gabriele Curti",
        "Alberto Maria Metelli",
        "Marcello Restelli"
      ],
      "abstract": "Inverse Reinforcement Learning (IRL) techniques deal with the problem of\ndeducing a reward function that explains the behavior of an expert agent who is\nassumed to act optimally in an underlying unknown task. In several problems of\ninterest, however, it is possible to observe the behavior of multiple experts\nwith different degree of optimality (e.g., racing drivers whose skills ranges\nfrom amateurs to professionals). For this reason, in this work, we extend the\nIRL formulation to problems where, in addition to demonstrations from the\noptimal agent, we can observe the behavior of multiple sub-optimal experts.\nGiven this problem, we first study the theoretical properties of the class of\nreward functions that are compatible with a given set of experts, i.e., the\nfeasible reward set. Our results show that the presence of multiple sub-optimal\nexperts can significantly shrink the set of compatible rewards. Furthermore, we\nstudy the statistical complexity of estimating the feasible reward set with a\ngenerative model. To this end, we analyze a uniform sampling algorithm that\nresults in being minimax optimal whenever the sub-optimal experts' performance\nlevel is sufficiently close to the one of the optimal agent.",
      "tldr_zh": "本文扩展逆强化学习（IRL）框架，允许处理多个次优专家的行为，而非仅依赖最优专家，从而推断出解释这些行为的奖励函数。研究者首先分析了与给定专家集兼容的奖励函数集合（feasible reward set）的理论性质，发现多位次优专家的存在能显著缩小该集合的范围。接着，他们评估了使用生成模型估计该集合的统计复杂性，并证明了一个均匀采样算法在次优专家性能接近最优时达到最小最大最优（minimax optimal）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03857v1",
      "published_date": "2024-01-08 12:39:25 UTC",
      "updated_date": "2024-01-08 12:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:30:12.518169"
    },
    {
      "arxiv_id": "2401.03855v4",
      "title": "PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ankit Yadav",
        "Himanshu Beniwal",
        "Mayank Singh"
      ],
      "abstract": "Driven by the surge in code generation using large language models (LLMs),\nnumerous benchmarks have emerged to evaluate these LLMs capabilities. We\nconducted a large-scale human evaluation of HumanEval and MBPP, two popular\nbenchmarks for Python code generation, analyzing their diversity and\ndifficulty. Our findings unveil a critical bias towards a limited set of\nprogramming concepts, neglecting most of the other concepts entirely.\nFurthermore, we uncover a worrying prevalence of easy tasks, potentially\ninflating model performance estimations. To address these limitations, we\npropose a novel benchmark, PythonSaga, featuring 185 hand-crafted prompts on a\nbalanced representation of 38 programming concepts across diverse difficulty\nlevels. The robustness of our benchmark is demonstrated by the poor performance\nof existing Code-LLMs.",
      "tldr_zh": "这项研究评估了现有代码生成 LLMs 基准如 HumanEval 和 MBPP，发现它们存在偏差：偏向有限的编程概念并忽略其他内容，同时任务过于简单，导致模型性能估计被夸大。作者提出新基准 PythonSaga，由 185 个手工制作的提示组成，平衡覆盖 38 个编程概念并包含多种难度水平，以提升评估的全面性和准确性。通过实验，现有 Code-LLMs 在 PythonSaga 上表现不佳，证明了这一基准的鲁棒性和实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03855v4",
      "published_date": "2024-01-08 12:36:43 UTC",
      "updated_date": "2024-07-04 05:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:30:24.974920"
    },
    {
      "arxiv_id": "2401.03854v2",
      "title": "TIER: Text-Image Encoder-based Regression for AIGC Image Quality Assessment",
      "title_zh": "TIER：基于文本",
      "authors": [
        "Jiquan Yuan",
        "Xinyan Cao",
        "Jinming Che",
        "Qinyuan Wang",
        "Sen Liang",
        "Wei Ren",
        "Jinlong Lin",
        "Xixin Cao"
      ],
      "abstract": "Recently, AIGC image quality assessment (AIGCIQA), which aims to assess the\nquality of AI-generated images (AIGIs) from a human perception perspective, has\nemerged as a new topic in computer vision. Unlike common image quality\nassessment tasks where images are derived from original ones distorted by\nnoise, blur, and compression, \\textit{etc.}, in AIGCIQA tasks, images are\ntypically generated by generative models using text prompts. Considerable\nefforts have been made in the past years to advance AIGCIQA. However, most\nexisting AIGCIQA methods regress predicted scores directly from individual\ngenerated images, overlooking the information contained in the text prompts of\nthese images. This oversight partially limits the performance of these AIGCIQA\nmethods. To address this issue, we propose a text-image encoder-based\nregression (TIER) framework. Specifically, we process the generated images and\ntheir corresponding text prompts as inputs, utilizing a text encoder and an\nimage encoder to extract features from these text prompts and generated images,\nrespectively. To demonstrate the effectiveness of our proposed TIER method, we\nconduct extensive experiments on several mainstream AIGCIQA databases,\nincluding AGIQA-1K, AGIQA-3K, and AIGCIQA2023. The experimental results\nindicate that our proposed TIER method generally demonstrates superior\nperformance compared to baseline in most cases.",
      "tldr_zh": "该论文针对 AIGC 图像质量评估 (AIGCIQA) 的新挑战，提出 TIER 框架，以评估 AI 生成图像 (AIGIs) 的质量时融入文本提示信息。不同于传统方法直接从图像回归分数，TIER 使用 text encoder 和 image encoder 分别提取文本提示和生成图像的特征，实现更全面的回归预测。实验结果显示，在 AGIQA-1K、AGIQA-3K 和 AIGCIQA2023 等数据库上，TIER 方法在大多数情况下比基线模型表现出色，提升了评估性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2312.05897",
      "pdf_url": "http://arxiv.org/pdf/2401.03854v2",
      "published_date": "2024-01-08 12:35:15 UTC",
      "updated_date": "2024-01-11 08:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:30:38.464720"
    },
    {
      "arxiv_id": "2401.04148v1",
      "title": "Online Test-Time Adaptation of Spatial-Temporal Traffic Flow Forecasting",
      "title_zh": "在线测试时适应的时空交通流量预测",
      "authors": [
        "Pengxin Guo",
        "Pengrong Jin",
        "Ziyue Li",
        "Lei Bai",
        "Yu Zhang"
      ],
      "abstract": "Accurate spatial-temporal traffic flow forecasting is crucial in aiding\ntraffic managers in implementing control measures and assisting drivers in\nselecting optimal travel routes. Traditional deep-learning based methods for\ntraffic flow forecasting typically rely on historical data to train their\nmodels, which are then used to make predictions on future data. However, the\nperformance of the trained model usually degrades due to the temporal drift\nbetween the historical and future data. To make the model trained on historical\ndata better adapt to future data in a fully online manner, this paper conducts\nthe first study of the online test-time adaptation techniques for\nspatial-temporal traffic flow forecasting problems. To this end, we propose an\nAdaptive Double Correction by Series Decomposition (ADCSD) method, which first\ndecomposes the output of the trained model into seasonal and trend-cyclical\nparts and then corrects them by two separate modules during the testing phase\nusing the latest observed data entry by entry. In the proposed ADCSD method,\ninstead of fine-tuning the whole trained model during the testing phase, a lite\nnetwork is attached after the trained model, and only the lite network is\nfine-tuned in the testing process each time a data entry is observed. Moreover,\nto satisfy that different time series variables may have different levels of\ntemporal drift, two adaptive vectors are adopted to provide different weights\nfor different time series variables. Extensive experiments on four real-world\ntraffic flow forecasting datasets demonstrate the effectiveness of the proposed\nADCSD method. The code is available at https://github.com/Pengxin-Guo/ADCSD.",
      "tldr_zh": "这篇论文针对时空交通流量预测（Spatial-Temporal Traffic Flow Forecasting）中的时间漂移问题，首次提出在线测试时适应（Online Test-Time Adaptation）技术，以帮助模型更好地适应未来数据。作者开发了Adaptive Double Correction by Series Decomposition (ADCSD) 方法，该方法先将模型输出分解为季节性和趋势周期部分，然后通过附加的轻量网络逐个条目修正这些部分，并使用自适应向量为不同时间序列变量提供个性化权重。实验在四个真实世界交通流量数据集上验证了ADCSD的有效性，证明其显著提升了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04148v1",
      "published_date": "2024-01-08 12:04:39 UTC",
      "updated_date": "2024-01-08 12:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:30:50.548744"
    },
    {
      "arxiv_id": "2401.03830v1",
      "title": "A foundation for exact binarized morphological neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Theodore Aouad",
        "Hugues Talbot"
      ],
      "abstract": "Training and running deep neural networks (NNs) often demands a lot of\ncomputation and energy-intensive specialized hardware (e.g. GPU, TPU...). One\nway to reduce the computation and power cost is to use binary weight NNs, but\nthese are hard to train because the sign function has a non-smooth gradient. We\npresent a model based on Mathematical Morphology (MM), which can binarize\nConvNets without losing performance under certain conditions, but these\nconditions may not be easy to satisfy in real-world scenarios. To solve this,\nwe propose two new approximation methods and develop a robust theoretical\nframework for ConvNets binarization using MM. We propose as well regularization\nlosses to improve the optimization. We empirically show that our model can\nlearn a complex morphological network, and explore its performance on a\nclassification task.",
      "tldr_zh": "本研究针对深度神经网络（NNs）的计算和能源消耗问题，提出了一种基于Mathematical Morphology (MM)的模型，用于精确二值化ConvNets，从而在特定条件下不损失性能。论文引入两种新近似方法，并建立了一个稳健的理论框架，同时设计正则化损失来优化训练过程，以缓解二值化权重带来的梯度不平滑问题。实验结果显示，该模型能够学习复杂的形态网络，并在分类任务上表现出色，证明了其在实际场景中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at conference ICCV 2023 Workshop LBQNN. Same work, different\n  format, accepted at conference NeurIPS 2023 Workshop WANT. 8 pages, 17 pages\n  appendix",
      "pdf_url": "http://arxiv.org/pdf/2401.03830v1",
      "published_date": "2024-01-08 11:37:44 UTC",
      "updated_date": "2024-01-08 11:37:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:31:00.745664"
    },
    {
      "arxiv_id": "2403.12055v1",
      "title": "Deep learning based detection of collateral circulation in coronary angiographies",
      "title_zh": "基于深度学习的冠状动脉造影中侧枝循环检测",
      "authors": [
        "Cosmin-Andrei Hatfaludi",
        "Daniel Bunescu",
        "Costin Florian Ciusdel",
        "Alex Serban",
        "Karl Bose",
        "Marc Oppel",
        "Stephanie Schroder",
        "Christopher Seehase",
        "Harald F. Langer",
        "Jeanette Erdmann",
        "Henry Nording",
        "Lucian Mihai Itu"
      ],
      "abstract": "Coronary artery disease (CAD) is the dominant cause of death and\nhospitalization across the globe. Atherosclerosis, an inflammatory condition\nthat gradually narrows arteries and has potentially fatal effects, is the most\nfrequent cause of CAD. Nonetheless, the circulation regularly adapts in the\npresence of atherosclerosis, through the formation of collateral arteries,\nresulting in significant long-term health benefits. Therefore, timely detection\nof coronary collateral circulation (CCC) is crucial for CAD personalized\nmedicine. We propose a novel deep learning based method to detect CCC in\nangiographic images. Our method relies on a convolutional backbone to extract\nspatial features from each frame of an angiography sequence. The features are\nthen concatenated, and subsequently processed by another convolutional layer\nthat processes embeddings temporally. Due to scarcity of data, we also\nexperiment with pretraining the backbone on coronary artery segmentation, which\nimproves the results consistently. Moreover, we experiment with few-shot\nlearning to further improve performance, given our low data regime. We present\nour results together with subgroup analyses based on Rentrop grading,\ncollateral flow, and collateral grading, which provide valuable insights into\nmodel performance. Overall, the proposed method shows promising results in\ndetecting CCC, and can be further extended to perform landmark based CCC\ndetection and CCC quantification.",
      "tldr_zh": "这篇论文提出了一种基于 deep learning 的方法，用于检测冠状动脉造影图像中的冠状动脉侧支循环（CCC），以支持冠状动脉病（CAD）的个性化医学。方法采用卷积神经网络（CNN）骨干提取图像序列的空間特征，然后通过另一个卷积层处理时间嵌入；同时，通过在冠状动脉分割任务上预训练和 few-shot learning 来应对数据稀缺问题，提高模型性能。实验结果显示，该方法在检测 CCC 方面表现出色，并通过基于 Rentrop grading、侧支血流和侧支分级的子组分析提供了宝贵洞见，具有潜力扩展到基于地标的检测和量化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12055v1",
      "published_date": "2024-01-08 11:25:42 UTC",
      "updated_date": "2024-01-08 11:25:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:31:15.064312"
    },
    {
      "arxiv_id": "2401.03804v2",
      "title": "TeleChat Technical Report",
      "title_zh": "TeleChat 技术报告",
      "authors": [
        "Zhongjiang He",
        "Zihan Wang",
        "Xinzhang Liu",
        "Shixuan Liu",
        "Yitong Yao",
        "Yuyao Huang",
        "Xuelong Li",
        "Yongxiang Li",
        "Zhonghao Che",
        "Zhaoxi Zhang",
        "Yan Wang",
        "Xin Wang",
        "Luwen Pu",
        "Huinan Xu",
        "Ruiyu Fang",
        "Yu Zhao",
        "Jie Zhang",
        "Xiaomeng Huang",
        "Zhilong Lu",
        "Jiaxin Peng",
        "Wenjun Zheng",
        "Shiquan Wang",
        "Bingkai Yang",
        "Xuewei he",
        "Zhuoru Jiang",
        "Qiyi Xie",
        "Yanhan Zhang",
        "Zhongqiu Li",
        "Lingling Shi",
        "Weiwei Fu",
        "Yin Zhang",
        "Zilu Huang",
        "Sishi Xiong",
        "Yuxiang Zhang",
        "Chao Wang",
        "Shuangyong Song"
      ],
      "abstract": "In this technical report, we present TeleChat, a collection of large language\nmodels (LLMs) with parameters of 3 billion, 7 billion and 12 billion. It\nincludes pretrained language models as well as fine-tuned chat models that is\naligned with human preferences. TeleChat is initially pretrained on an\nextensive corpus containing a diverse collection of texts from both English and\nChinese languages, including trillions of tokens. Subsequently, the model\nundergoes fine-tuning to align with human preferences, following a detailed\nmethodology that we describe. We evaluate the performance of TeleChat on\nvarious tasks, including language understanding, mathematics, reasoning, code\ngeneration, and knowledge-based question answering. Our findings indicate that\nTeleChat achieves comparable performance to other open-source models of similar\nsize across a wide range of public benchmarks. To support future research and\napplications utilizing LLMs, we release the fine-tuned model checkpoints of\nTeleChat's 7B and 12B variant, along with code and a portion of our pretraining\ndata, to the public community.",
      "tldr_zh": "本报告介绍了 TeleChat，一系列参数规模为 3B、7B 和 12B 的 LLMs，包括预训练模型和微调后的聊天模型，这些模型先在包含英语和中文的数万亿 tokens 语料上进行预训练，随后通过详细方法微调以对齐人类偏好。TeleChat 在语言理解、数学、推理、代码生成和知识问答等任务上进行了评估，结果显示其性能与同规模开源模型在多个公共基准上相当。作者开源了 7B 和 12B 变体的微调模型检查点、代码以及部分预训练数据，以支持未来的 LLM 研究和应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.03804v2",
      "published_date": "2024-01-08 10:43:19 UTC",
      "updated_date": "2024-04-02 01:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:31:26.852711"
    },
    {
      "arxiv_id": "2401.06686v1",
      "title": "Exploring Conversational Agents as an Effective Tool for Measuring Cognitive Biases in Decision-Making",
      "title_zh": "探索对话代理作为测量决策中认知偏差的有效工具",
      "authors": [
        "Stephen Pilli"
      ],
      "abstract": "Heuristics and cognitive biases are an integral part of human\ndecision-making. Automatically detecting a particular cognitive bias could\nenable intelligent tools to provide better decision-support. Detecting the\npresence of a cognitive bias currently requires a hand-crafted experiment and\nhuman interpretation. Our research aims to explore conversational agents as an\neffective tool to measure various cognitive biases in different domains. Our\nproposed conversational agent incorporates a bias measurement mechanism that is\ninformed by the existing experimental designs and various experimental tasks\nidentified in the literature. Our initial experiments to measure framing and\nloss-aversion biases indicate that the conversational agents can be effectively\nused to measure the biases.",
      "tldr_zh": "该研究探讨了对话代理(conversational agents)作为测量人类决策中认知偏差(cognitive biases)的有效工具，目前这类偏差检测依赖手工实验和人工解释。研究提出了一种整合现有实验设计和任务的对话代理机制，用于评估不同领域的认知偏差。初步实验针对框架偏差(framing bias)和损失厌恶偏差(loss-aversion bias)表明，该方法能有效测量这些偏差，为智能决策支持工具的开发提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06686v1",
      "published_date": "2024-01-08 10:23:52 UTC",
      "updated_date": "2024-01-08 10:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:31:36.632768"
    },
    {
      "arxiv_id": "2401.03786v2",
      "title": "Long-term Safe Reinforcement Learning with Binary Feedback",
      "title_zh": "基于二元反馈的长期安全强化学习",
      "authors": [
        "Akifumi Wachi",
        "Wataru Hashimoto",
        "Kazumune Hashimoto"
      ],
      "abstract": "Safety is an indispensable requirement for applying reinforcement learning\n(RL) to real problems. Although there has been a surge of safe RL algorithms\nproposed in recent years, most existing work typically 1) relies on receiving\nnumeric safety feedback; 2) does not guarantee safety during the learning\nprocess; 3) limits the problem to a priori known, deterministic transition\ndynamics; and/or 4) assume the existence of a known safe policy for any states.\nAddressing the issues mentioned above, we thus propose Long-term Binaryfeedback\nSafe RL (LoBiSaRL), a safe RL algorithm for constrained Markov decision\nprocesses (CMDPs) with binary safety feedback and an unknown, stochastic state\ntransition function. LoBiSaRL optimizes a policy to maximize rewards while\nguaranteeing a long-term safety that an agent executes only safe state-action\npairs throughout each episode with high probability. Specifically, LoBiSaRL\nmodels the binary safety function via a generalized linear model (GLM) and\nconservatively takes only a safe action at every time step while inferring its\neffect on future safety under proper assumptions. Our theoretical results show\nthat LoBiSaRL guarantees the long-term safety constraint, with high\nprobability. Finally, our empirical results demonstrate that our algorithm is\nsafer than existing methods without significantly compromising performance in\nterms of reward.",
      "tldr_zh": "这篇论文针对强化学习 (RL) 中的安全挑战，提出了 Long-term Binaryfeedback Safe RL (LoBiSaRL) 算法，用于约束的 Markov 决策过程 (CMDPs)，它仅依赖二进制安全反馈并处理未知的随机状态转移函数。LoBiSaRL 通过广义线性模型 (GLM) 建模安全函数，并在每个时间步保守地选择安全动作，以确保代理在每个 episode 中只执行安全的状态-动作对，从而实现长期安全约束。理论分析证明了该算法以高概率满足安全要求，实验结果显示它比现有方法更安全，同时在奖励性能方面没有显著损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI-24",
      "pdf_url": "http://arxiv.org/pdf/2401.03786v2",
      "published_date": "2024-01-08 10:07:31 UTC",
      "updated_date": "2024-01-11 11:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:31:50.942172"
    },
    {
      "arxiv_id": "2401.03768v4",
      "title": "Corn Yield Prediction Model with Deep Neural Networks for Smallholder Farmer Decision Support System",
      "title_zh": "基于深度神经网络的玉米产量预测模型，用于小农",
      "authors": [
        "Chollette C. Olisah",
        "Lyndon Smith",
        "Melvyn Smith",
        "Morolake O. Lawrence",
        "Osita Ojukwu"
      ],
      "abstract": "Crop yield prediction has been modeled on the assumption that there is no\ninteraction between weather and soil variables. However, this paper argues that\nan interaction exists, and it can be finely modelled using the Kendall\nCorrelation coefficient. Given the nonlinearity of the interaction between\nweather and soil variables, a deep neural network regressor (DNNR) is carefully\ndesigned with consideration to the depth, number of neurons of the hidden\nlayers, and the hyperparameters with their optimizations. Additionally, a new\nmetric, the average of absolute root squared error (ARSE) is proposed to\ncombine the strengths of root mean square error (RMSE) and mean absolute error\n(MAE). With the ARSE metric, the proposed DNNR(s), optimised random forest\nregressor (RFR) and the extreme gradient boosting regressor (XGBR) achieved\nimpressively small yield errors, 0.0172 t/ha, and 0.0243 t/ha, 0.0001 t/ha, and\n0.001 t/ha, respectively. However, the DNNR(s), with changes to the explanatory\nvariables to ensure generalizability to unforeseen data, DNNR(s) performed\nbest. Further analysis reveals that a strong interaction does exist between\nweather and soil variables. Precisely, yield is observed to increase when\nprecipitation is reduced and silt increased, and vice-versa. However, the\ndegree of decrease or increase is not quantified in this paper. Contrary to\nexisting yield models targeted towards agricultural policies and global food\nsecurity, the goal of the proposed corn yield model is to empower the\nsmallholder farmer to farm smartly and intelligently, thus the prediction model\nis integrated into a mobile application that includes education, and a\nfarmer-to-market access module.",
      "tldr_zh": "本论文提出了一种玉米产量预测模型，通过 Kendall 相关系数细化建模天气和土壤变量之间的交互关系，以克服传统模型的局限。模型采用深度神经网络回归器 (DNNR)，优化了网络深度、隐藏层神经元数量及超参数，同时引入新指标绝对根均方误差的平均值 (ARSE) 来结合 RMSE 和 MAE 的优势。实验结果显示，DNNR 在预测中表现最佳，误差低至 0.0172 t/ha，并证实减少降水和增加淤泥可提高产量；最终，该模型整合到移动应用中，支持小农的决策、教育和市场访问。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "30 Pages, 11 Figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2401.03768v4",
      "published_date": "2024-01-08 09:47:19 UTC",
      "updated_date": "2024-12-01 08:43:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:32:03.010044"
    },
    {
      "arxiv_id": "2401.03756v3",
      "title": "Adaptive Experimental Design for Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Masahiro Kato",
        "Kyohei Okumura",
        "Takuya Ishihara",
        "Toru Kitagawa"
      ],
      "abstract": "Evidence-based targeting has been a topic of growing interest among the\npractitioners of policy and business. Formulating decision-maker's policy\nlearning as a fixed-budget best arm identification (BAI) problem with\ncontextual information, we study an optimal adaptive experimental design for\npolicy learning with multiple treatment arms. In the sampling stage, the\nplanner assigns treatment arms adaptively over sequentially arriving\nexperimental units upon observing their contextual information (covariates).\nAfter the experiment, the planner recommends an individualized assignment rule\nto the population. Setting the worst-case expected regret as the performance\ncriterion of adaptive sampling and recommended policies, we derive its\nasymptotic lower bounds, and propose a strategy, Adaptive Sampling-Policy\nLearning strategy (PLAS), whose leading factor of the regret upper bound aligns\nwith the lower bound as the size of experimental units increases.",
      "tldr_zh": "这篇论文研究了自适应实验设计在政策学习中的应用，将决策者的政策学习表述为固定预算的best arm identification (BAI)问题，并考虑上下文信息。作者提出了一种Adaptive Sampling-Policy Learning strategy (PLAS)，在采样阶段通过观察实验单元的协变量自适应分配多个治疗臂，以最小化最坏情况期望regret。实验结果显示，PLAS的regret上界与渐近下界对齐，随着实验单元规模增加，其性能得到优化，为证据-based targeting在政策和商业领域提供了高效的个性化分配规则。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.EM",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2302.02988",
      "pdf_url": "http://arxiv.org/pdf/2401.03756v3",
      "published_date": "2024-01-08 09:29:07 UTC",
      "updated_date": "2024-02-08 17:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:32:14.112559"
    },
    {
      "arxiv_id": "2401.06793v1",
      "title": "Greedy Algorithm for Inference of Decision Trees from Decision Rule Systems",
      "title_zh": "从决策规则系统推断决策树的贪心算法",
      "authors": [
        "Kerven Durdymyradov",
        "Mikhail Moshkov"
      ],
      "abstract": "Decision trees and decision rule systems play important roles as classifiers,\nknowledge representation tools, and algorithms. They are easily interpretable\nmodels for data analysis, making them widely used and studied in computer\nscience. Understanding the relationships between these two models is an\nimportant task in this field. There are well-known methods for converting\ndecision trees into systems of decision rules. In this paper, we consider the\ninverse transformation problem, which is not so simple. Instead of constructing\nan entire decision tree, our study focuses on a greedy polynomial time\nalgorithm that simulates the operation of a decision tree on a given tuple of\nattribute values.",
      "tldr_zh": "本文研究了从决策规则 systems 推断 decision trees 的反向转换问题，旨在探索这两种模型之间的关系。作者提出了一种贪婪 algorithm 的多项式时间算法，该算法不需构建完整的决策树，而是模拟决策树在给定属性值元组上的操作。该方法为决策树和决策规则 systems 在数据分析中的应用提供了更高效、可解释的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2305.01721,\n  arXiv:2302.07063",
      "pdf_url": "http://arxiv.org/pdf/2401.06793v1",
      "published_date": "2024-01-08 09:28:55 UTC",
      "updated_date": "2024-01-08 09:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:32:25.285611"
    },
    {
      "arxiv_id": "2401.03737v2",
      "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Fatouros",
        "Konstantinos Metaxas",
        "John Soldatos",
        "Dimosthenis Kyriazis"
      ],
      "abstract": "This paper introduces MarketSenseAI, an innovative framework leveraging\nGPT-4's advanced reasoning for selecting stocks in financial markets. By\nintegrating Chain of Thought and In-Context Learning, MarketSenseAI analyzes\ndiverse data sources, including market trends, news, fundamentals, and\nmacroeconomic factors, to emulate expert investment decision-making. The\ndevelopment, implementation, and validation of the framework are elaborately\ndiscussed, underscoring its capability to generate actionable and interpretable\ninvestment signals. A notable feature of this work is employing GPT-4 both as a\npredictive mechanism and signal evaluator, revealing the significant impact of\nthe AI-generated explanations on signal accuracy, reliability and acceptance.\nThrough empirical testing on the competitive S&P 100 stocks over a 15-month\nperiod, MarketSenseAI demonstrated exceptional performance, delivering excess\nalpha of 10% to 30% and achieving a cumulative return of up to 72% over the\nperiod, while maintaining a risk profile comparable to the broader market. Our\nfindings highlight the transformative potential of Large Language Models in\nfinancial decision-making, marking a significant leap in integrating generative\nAI into financial analytics and investment strategies.",
      "tldr_zh": "这篇论文介绍了 MarketSenseAI 框架，利用 GPT-4 的高级推理结合 Chain of Thought 和 In-Context Learning，分析市场趋势、新闻、基本面和宏观经济因素，以模拟专家级股票选择决策。框架的关键创新在于使用 GPT-4 作为预测机制和信号评估器，生成可解释的投资信号，提升信号的准确性和可靠性。在 S&P 100 股票的 15 个月实证测试中，MarketSenseAI 实现了 10% 到 30% 的超额 alpha 和高达 72% 的累计回报，同时保持与市场相当的风险水平。研究突显了大型语言模型在金融决策中的变革潜力，推动 AI 在投资策略中的应用。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG",
        "68T07, 68T50, 91G10, 91G15",
        "I.2.1; I.2.7; J.4"
      ],
      "primary_category": "q-fin.CP",
      "comment": "17 pages, 12 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.03737v2",
      "published_date": "2024-01-08 08:58:46 UTC",
      "updated_date": "2024-04-04 13:18:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:32:39.355203"
    },
    {
      "arxiv_id": "2401.03729v3",
      "title": "The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Abel Salinas",
        "Fred Morstatter"
      ],
      "abstract": "Large Language Models (LLMs) are regularly being used to label data across\nmany domains and for myriad tasks. By simply asking the LLM for an answer, or\n``prompting,'' practitioners are able to use LLMs to quickly get a response for\nan arbitrary task. This prompting is done through a series of decisions by the\npractitioner, from simple wording of the prompt, to requesting the output in a\ncertain data format, to jailbreaking in the case of prompts that address more\nsensitive topics. In this work, we ask: do variations in the way a prompt is\nconstructed change the ultimate decision of the LLM? We answer this using a\nseries of prompt variations across a variety of text classification tasks. We\nfind that even the smallest of perturbations, such as adding a space at the end\nof a prompt, can cause the LLM to change its answer. Further, we find that\nrequesting responses in XML and commonly used jailbreaks can have cataclysmic\neffects on the data labeled by LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在提示 (prompts) 构建上的微小变化如何影响其性能，特别是通过测试提示变体在各种文本分类任务中的效果。研究发现，即使像在提示末尾添加一个空格这样的细微扰动，也能导致 LLMs 的输出答案发生改变。进一步，请求以 XML 格式响应或使用常见越狱 (jailbreaks) 方法，会显著降低模型的标注准确性。该研究强调了提示设计的敏感性，为 LLMs 在数据标注领域的可靠应用提供了重要警示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03729v3",
      "published_date": "2024-01-08 08:28:08 UTC",
      "updated_date": "2024-04-01 20:56:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:32:51.121191"
    },
    {
      "arxiv_id": "2401.05437v2",
      "title": "Representation Learning for Wearable-Based Applications in the Case of Missing Data",
      "title_zh": "翻译失败",
      "authors": [
        "Janosch Jungo",
        "Yutong Xiang",
        "Shkurta Gashi",
        "Christian Holz"
      ],
      "abstract": "Wearable devices continuously collect sensor data and use it to infer an\nindividual's behavior, such as sleep, physical activity, and emotions. Despite\nthe significant interest and advancements in this field, modeling multimodal\nsensor data in real-world environments is still challenging due to low data\nquality and limited data annotations. In this work, we investigate\nrepresentation learning for imputing missing wearable data and compare it with\nstate-of-the-art statistical approaches. We investigate the performance of the\ntransformer model on 10 physiological and behavioral signals with different\nmasking ratios. Our results show that transformers outperform baselines for\nmissing data imputation of signals that change more frequently, but not for\nmonotonic signals. We further investigate the impact of imputation strategies\nand masking rations on downstream classification tasks. Our study provides\ninsights for the design and development of masking-based self-supervised\nlearning tasks and advocates the adoption of hybrid-based imputation strategies\nto address the challenge of missing data in wearable devices.",
      "tldr_zh": "这篇论文探讨了在缺失数据情况下，使用表示学习（representation learning）对可穿戴设备数据进行插值（imputation），并将其与传统统计方法进行比较。研究利用Transformer模型测试了10种生理和行为信号在不同masking ratios下的表现，结果显示Transformer在频繁变化信号上优于基线方法，但在单调信号上表现不如。论文进一步分析了插值策略和masking ratios对下游分类任务的影响，并为masking-based自监督学习（self-supervised learning）任务的设计提供见解，主张采用混合插值策略来解决可穿戴设备中的缺失数据挑战。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024 (https://hcrl-workshop.github.io/2024/)",
      "pdf_url": "http://arxiv.org/pdf/2401.05437v2",
      "published_date": "2024-01-08 08:21:37 UTC",
      "updated_date": "2024-01-12 11:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:33:02.663105"
    },
    {
      "arxiv_id": "2401.03717v3",
      "title": "Universal Time-Series Representation Learning: A Survey",
      "title_zh": "通用时间序列表示学习：一个综述",
      "authors": [
        "Patara Trirat",
        "Yooju Shin",
        "Junhyeok Kang",
        "Youngeun Nam",
        "Jihye Na",
        "Minyoung Bae",
        "Joeun Kim",
        "Byunghyun Kim",
        "Jae-Gil Lee"
      ],
      "abstract": "Time-series data exists in every corner of real-world systems and services,\nranging from satellites in the sky to wearable devices on human bodies.\nLearning representations by extracting and inferring valuable information from\nthese time series is crucial for understanding the complex dynamics of\nparticular phenomena and enabling informed decisions. With the learned\nrepresentations, we can perform numerous downstream analyses more effectively.\nAmong several approaches, deep learning has demonstrated remarkable performance\nin extracting hidden patterns and features from time-series data without manual\nfeature engineering. This survey first presents a novel taxonomy based on three\nfundamental elements in designing state-of-the-art universal representation\nlearning methods for time series. According to the proposed taxonomy, we\ncomprehensively review existing studies and discuss their intuitions and\ninsights into how these methods enhance the quality of learned representations.\nFinally, as a guideline for future studies, we summarize commonly used\nexperimental setups and datasets and discuss several promising research\ndirections. An up-to-date corresponding resource is available at\nhttps://github.com/itouchz/awesome-deep-time-series-representations.",
      "tldr_zh": "这篇调查论文探讨了时间序列（time-series）表示学习的通用方法，强调其在从卫星到可穿戴设备等真实世界应用中的重要性。作者提出一个基于三个基本元素的创新分类法（taxonomy），并全面回顾了现有深度学习（deep learning）方法，这些方法无需手动特征工程就能提取隐藏模式，从而提升表示质量的学习效果。最后，论文总结了常用实验设置、数据集，并指出了未来研究方向，同时提供资源链接（https://github.com/itouchz/awesome-deep-time-series-representations）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.03717v3",
      "published_date": "2024-01-08 08:00:04 UTC",
      "updated_date": "2024-08-27 19:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:33:14.194735"
    },
    {
      "arxiv_id": "2401.03695v2",
      "title": "A Large-Scale Empirical Study on Improving the Fairness of Image Classification Models",
      "title_zh": "大规模实证研究：改善图像分类模型公平性的方法",
      "authors": [
        "Junjie Yang",
        "Jiajun Jiang",
        "Zeyu Sun",
        "Junjie Chen"
      ],
      "abstract": "Fairness has been a critical issue that affects the adoption of deep learning\nmodels in real practice. To improve model fairness, many existing methods have\nbeen proposed and evaluated to be effective in their own contexts. However,\nthere is still no systematic evaluation among them for a comprehensive\ncomparison under the same context, which makes it hard to understand the\nperformance distinction among them, hindering the research progress and\npractical adoption of them. To fill this gap, this paper endeavours to conduct\nthe first large-scale empirical study to comprehensively compare the\nperformance of existing state-of-the-art fairness improving techniques.\nSpecifically, we target the widely-used application scenario of image\nclassification, and utilized three different datasets and five commonly-used\nperformance metrics to assess in total 13 methods from diverse categories. Our\nfindings reveal substantial variations in the performance of each method across\ndifferent datasets and sensitive attributes, indicating over-fitting on\nspecific datasets by many existing methods. Furthermore, different fairness\nevaluation metrics, due to their distinct focuses, yield significantly\ndifferent assessment results. Overall, we observe that pre-processing methods\nand in-processing methods outperform post-processing methods, with\npre-processing methods exhibiting the best performance. Our empirical study\noffers comprehensive recommendations for enhancing fairness in deep learning\nmodels. We approach the problem from multiple dimensions, aiming to provide a\nuniform evaluation platform and inspire researchers to explore more effective\nfairness solutions via a set of implications.",
      "tldr_zh": "本文进行了一个大规模实证研究，系统比较了13种现有的公平性改进技术在图像分类模型中的性能，使用三个数据集和五种性能指标进行评估。研究发现，这些方法在不同数据集和敏感属性上表现出显著差异，许多方法存在过拟合问题，且不同fairness evaluation metrics会导致评估结果大相径庭。总体观察显示，pre-processing methods和in-processing methods优于post-processing methods，前者表现出最佳性能。该研究提供了全面的推荐和启示，旨在建立统一评估平台并推动更有效的fairness解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 33rd ACM SIGSOFT International Symposium on Software\n  Testing and Analysis (ISSTA 2024). Please include ISSTA in any citations",
      "pdf_url": "http://arxiv.org/pdf/2401.03695v2",
      "published_date": "2024-01-08 06:53:33 UTC",
      "updated_date": "2024-03-24 02:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:33:26.219752"
    },
    {
      "arxiv_id": "2401.03694v1",
      "title": "GloTSFormer: Global Video Text Spotting Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Han Wang",
        "Yanjie Wang",
        "Yang Li",
        "Can Huang"
      ],
      "abstract": "Video Text Spotting (VTS) is a fundamental visual task that aims to predict\nthe trajectories and content of texts in a video. Previous works usually\nconduct local associations and apply IoU-based distance and complex\npost-processing procedures to boost performance, ignoring the abundant temporal\ninformation and the morphological characteristics in VTS. In this paper, we\npropose a novel Global Video Text Spotting Transformer GloTSFormer to model the\ntracking problem as global associations and utilize the Gaussian Wasserstein\ndistance to guide the morphological correlation between frames. Our main\ncontributions can be summarized as three folds. 1). We propose a\nTransformer-based global tracking method GloTSFormer for VTS and associate\nmultiple frames simultaneously. 2). We introduce a Wasserstein distance-based\nmethod to conduct positional associations between frames. 3). We conduct\nextensive experiments on public datasets. On the ICDAR2015 video dataset,\nGloTSFormer achieves 56.0 MOTA with 4.6 absolute improvement compared with the\nprevious SOTA method and outperforms the previous Transformer-based method by a\nsignificant 8.3 MOTA.",
      "tldr_zh": "该论文提出 GloTSFormer，一种基于 Transformer's 全局视频文本检测（Video Text Spotting, VTS）框架，通过同时关联多个帧并使用 Gaussian Wasserstein distance 来指导帧之间的形态和位置相关性，从而克服了传统方法的局部关联和忽略时间信息的局限。关键贡献包括：引入全局跟踪机制、基于 Wasserstein distance 的位置关联方法，以及在公开数据集上的广泛实验验证。在 ICDAR2015 视频数据集上，GloTSFormer 实现了 56.0 的 MOTA，比之前的最先进方法提高了 4.6，并比之前的 Transformer-based 方法高出 8.3。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03694v1",
      "published_date": "2024-01-08 06:52:16 UTC",
      "updated_date": "2024-01-08 06:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:33:38.326181"
    },
    {
      "arxiv_id": "2401.03676v1",
      "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
      "title_zh": "评估 AI 检测器在识别 AI 生成代码方面的性能：对教育的启示",
      "authors": [
        "Wei Hung Pan",
        "Ming Jie Chok",
        "Jonathan Leong Shan Wong",
        "Yung Xin Shin",
        "Yeong Shian Poon",
        "Zhou Yang",
        "Chun Yong Chong",
        "David Lo",
        "Mei Kuan Lim"
      ],
      "abstract": "Educators are increasingly concerned about the usage of Large Language Models\n(LLMs) such as ChatGPT in programming education, particularly regarding the\npotential exploitation of imperfections in Artificial Intelligence Generated\nContent (AIGC) Detectors for academic misconduct. In this paper, we present an\nempirical study where the LLM is examined for its attempts to bypass detection\nby AIGC Detectors. This is achieved by generating code in response to a given\nquestion using different variants. We collected a dataset comprising 5,069\nsamples, with each sample consisting of a textual description of a coding\nproblem and its corresponding human-written Python solution codes. These\nsamples were obtained from various sources, including 80 from Quescol, 3,264\nfrom Kaggle, and 1,725 from LeetCode. From the dataset, we created 13 sets of\ncode problem variant prompts, which were used to instruct ChatGPT to generate\nthe outputs. Subsequently, we assessed the performance of five AIGC detectors.\nOur results demonstrate that existing AIGC Detectors perform poorly in\ndistinguishing between human-written code and AI-generated code.",
      "tldr_zh": "本研究评估了 AI 检测器在识别 AI 生成代码（AIGC）方面的性能，并探讨其对教育领域的学术不端影响，特别是 Large Language Models (LLMs) 如 ChatGPT 的潜在滥用。研究者收集了 5,069 个编程问题样本，包括人类编写的 Python 代码，并使用 13 组变体提示指令 ChatGPT 生成代码。随后，他们测试了五个 AIGC 检测器的表现。结果显示，这些检测器在区分人类编写代码和 AI 生成代码时表现不佳，准确率较低。这突显了教育中需要改进 AIGC 检测技术，以防范学术不端行为。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages, paper accepted at 46th International Conference on Software\n  Engineering, Software Engineering Education and Training Track (ICSE-SEET\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.03676v1",
      "published_date": "2024-01-08 05:53:52 UTC",
      "updated_date": "2024-01-08 05:53:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:33:51.234924"
    },
    {
      "arxiv_id": "2401.06792v2",
      "title": "LightHouse: A Survey of AGI Hallucination",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Wang"
      ],
      "abstract": "With the development of artificial intelligence, large-scale models have\nbecome increasingly intelligent. However, numerous studies indicate that\nhallucinations within these large models are a bottleneck hindering the\ndevelopment of AI research. In the pursuit of achieving strong artificial\nintelligence, a significant volume of research effort is being invested in the\nAGI (Artificial General Intelligence) hallucination research. Previous\nexplorations have been conducted in researching hallucinations within LLMs\n(Large Language Models). As for multimodal AGI, research on hallucinations is\nstill in an early stage. To further the progress of research in the domain of\nhallucinatory phenomena, we present a bird's eye view of hallucinations in AGI,\nsummarizing the current work on AGI hallucinations and proposing some\ndirections for future research.",
      "tldr_zh": "这篇论文“LightHouse: A Survey of AGI Hallucination”对人工智能通用智能（AGI）中的幻觉（hallucinations）问题进行了全面调查，强调这些问题已成为阻碍AI发展的主要瓶颈。论文回顾了现有研究，特别是Large Language Models (LLMs)中幻觉的探索进展，并指出多模态AGI领域的研究仍处于早期阶段。最终，它总结了AGI幻觉的当前工作，并提出未来研究方向，以推动该领域的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06792v2",
      "published_date": "2024-01-08 03:52:40 UTC",
      "updated_date": "2024-01-17 04:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:34:01.202249"
    },
    {
      "arxiv_id": "2401.06791v1",
      "title": "A Span-based Model for Extracting Overlapping PICO Entities from RCT Publications",
      "title_zh": "一种基于跨度的模型用于从 RCT",
      "authors": [
        "Gongbo Zhang",
        "Yiliang Zhou",
        "Yan Hu",
        "Hua Xu",
        "Chunhua Weng",
        "Yifan Peng"
      ],
      "abstract": "Objectives Extraction of PICO (Populations, Interventions, Comparison, and\nOutcomes) entities is fundamental to evidence retrieval. We present a novel\nmethod PICOX to extract overlapping PICO entities.\n  Materials and Methods PICOX first identifies entities by assessing whether a\nword marks the beginning or conclusion of an entity. Then it uses a multi-label\nclassifier to assign one or more PICO labels to a span candidate. PICOX was\nevaluated using one of the best-performing baselines, EBM-NLP, and three more\ndatasets, i.e., PICO-Corpus, and RCT publications on Alzheimer's Disease or\nCOVID-19, using entity-level precision, recall, and F1 scores.\n  Results PICOX achieved superior precision, recall, and F1 scores across the\nboard, with the micro F1 score improving from 45.05 to 50.87 (p << 0.01). On\nthe PICO-Corpus, PICOX obtained higher recall and F1 scores than the baseline\nand improved the micro recall score from 56.66 to 67.33. On the COVID-19\ndataset, PICOX also outperformed the baseline and improved the micro F1 score\nfrom 77.10 to 80.32. On the AD dataset, PICOX demonstrated comparable F1 scores\nwith higher precision when compared to the baseline.\n  Conclusion PICOX excels in identifying overlapping entities and consistently\nsurpasses a leading baseline across multiple datasets. Ablation studies reveal\nthat its data augmentation strategy effectively minimizes false positives and\nimproves precision.",
      "tldr_zh": "本文提出了一种基于跨度的模型 PICOX，用于从 RCT 出版物中提取重叠的 PICO 实体（包括 Populations, Interventions, Comparison 和 Outcomes），以提升证据检索效率。PICOX 先通过判断词语是否标记实体边界来识别实体，然后使用多标签分类器为实体跨度分配一个或多个 PICO 标签。实验结果显示，PICOX 在多个数据集上超越基线模型 EBM-NLP，提升微 F1 分数从 45.05 到 50.87（p << 0.01），并在 PICO-Corpus 和 COVID-19 数据集上显著提高了召回率和精确率。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06791v1",
      "published_date": "2024-01-08 03:35:02 UTC",
      "updated_date": "2024-01-08 03:35:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:34:15.789579"
    },
    {
      "arxiv_id": "2402.00034v1",
      "title": "Why does Prediction Accuracy Decrease over Time? Uncertain Positive Learning for Cloud Failure Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Li",
        "Minghua Ma",
        "Yudong Liu",
        "Pu Zhao",
        "Lingling Zheng",
        "Ze Li",
        "Yingnong Dang",
        "Murali Chintalapati",
        "Saravan Rajmohan",
        "Qingwei Lin",
        "Dongmei Zhang"
      ],
      "abstract": "With the rapid growth of cloud computing, a variety of software services have\nbeen deployed in the cloud. To ensure the reliability of cloud services, prior\nstudies focus on failure instance (disk, node, and switch, etc.) prediction.\nOnce the output of prediction is positive, mitigation actions are taken to\nrapidly resolve the underlying failure. According to our real-world practice in\nMicrosoft Azure, we find that the prediction accuracy may decrease by about 9%\nafter retraining the models. Considering that the mitigation actions may result\nin uncertain positive instances since they cannot be verified after mitigation,\nwhich may introduce more noise while updating the prediction model. To the best\nof our knowledge, we are the first to identify this Uncertain Positive Learning\n(UPLearning) issue in the real-world cloud failure prediction scenario. To\ntackle this problem, we design an Uncertain Positive Learning Risk Estimator\n(Uptake) approach. Using two real-world datasets of disk failure prediction and\nconducting node prediction experiments in Microsoft Azure, which is a top-tier\ncloud provider that serves millions of users, we demonstrate Uptake can\nsignificantly improve the failure prediction accuracy by 5% on average.",
      "tldr_zh": "这篇论文探讨了云故障预测中预测准确率随时间下降的原因，主要是由于缓解行动导致的不确定正例(Uncertain Positive Learning, UPLearning)问题，这些正例无法验证从而引入噪声。作者首次识别了这一真实场景中的UPLearning问题，并提出了一种Uncertain Positive Learning Risk Estimator (Uptake)方法来评估和减轻风险。通过Microsoft Azure的磁盘故障和节点预测数据集实验，Uptake显著提高了预测准确率，平均提升约5%。这为提升云服务可靠性提供了新颖的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "K.6.3; I.2.0"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00034v1",
      "published_date": "2024-01-08 03:13:09 UTC",
      "updated_date": "2024-01-08 03:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:34:26.272264"
    },
    {
      "arxiv_id": "2401.03639v1",
      "title": "Deep Learning for Visual Neuroprosthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Beech",
        "Shanshan Jia",
        "Zhaofei Yu",
        "Jian K. Liu"
      ],
      "abstract": "The visual pathway involves complex networks of cells and regions which\ncontribute to the encoding and processing of visual information. While some\naspects of visual perception are understood, there are still many unanswered\nquestions regarding the exact mechanisms of visual encoding and the\norganization of visual information along the pathway. This chapter discusses\nthe importance of visual perception and the challenges associated with\nunderstanding how visual information is encoded and represented in the brain.\nFurthermore, this chapter introduces the concept of neuroprostheses: devices\ndesigned to enhance or replace bodily functions, and highlights the importance\nof constructing computational models of the visual pathway in the\nimplementation of such devices. A number of such models, employing the use of\ndeep learning models, are outlined, and their value to understanding visual\ncoding and natural vision is discussed.",
      "tldr_zh": "这篇论文探讨了视觉通路的复杂编码机制和视觉感知的挑战，强调了理解大脑中视觉信息处理的重要性。论文引入了神经假体(neuroprostheses)的概念，即用于增强或替换身体功能的设备，并强调构建视觉通路计算模型的必要性。作者概述了基于深度学习(deep learning)模型的多种方法，这些模型有助于揭示视觉编码过程，并为实现自然视觉和神经假体应用提供宝贵见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03639v1",
      "published_date": "2024-01-08 02:53:22 UTC",
      "updated_date": "2024-01-08 02:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:34:38.882765"
    },
    {
      "arxiv_id": "2401.04145v1",
      "title": "Learn Once Plan Arbitrarily (LOPA): Attention-Enhanced Deep Reinforcement Learning Method for Global Path Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Guoming Huang",
        "Mingxin Hou",
        "Xiaofang Yuan",
        "Shuqiao Huang",
        "Yaonan Wang"
      ],
      "abstract": "Deep reinforcement learning (DRL) methods have recently shown promise in path\nplanning tasks. However, when dealing with global planning tasks, these methods\nface serious challenges such as poor convergence and generalization. To this\nend, we propose an attention-enhanced DRL method called LOPA (Learn Once Plan\nArbitrarily) in this paper. Firstly, we analyze the reasons of these problems\nfrom the perspective of DRL's observation, revealing that the traditional\ndesign causes DRL to be interfered by irrelevant map information. Secondly, we\ndevelop the LOPA which utilizes a novel attention-enhanced mechanism to attain\nan improved attention capability towards the key information of the\nobservation. Such a mechanism is realized by two steps: (1) an attention model\nis built to transform the DRL's observation into two dynamic views: local and\nglobal, significantly guiding the LOPA to focus on the key information on the\ngiven maps; (2) a dual-channel network is constructed to process these two\nviews and integrate them to attain an improved reasoning capability. The LOPA\nis validated via multi-objective global path planning experiments. The result\nsuggests the LOPA has improved convergence and generalization performance as\nwell as great path planning efficiency.",
      "tldr_zh": "本研究针对深度强化学习(DRL)方法在全局路径规划任务中存在的收敛性和泛化性差的问题，提出了一种注意力增强的DRL方法LOPA (Learn Once Plan Arbitrarily)。LOPA通过构建一个注意力模型，将DRL的观察转化为局部和全局动态视图，帮助模型聚焦关键地图信息，并利用双通道网络处理这些视图以提升推理能力。实验结果显示，LOPA在多目标全局路径规划任务上显著改善了收敛和泛化性能，同时提高了路径规划效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04145v1",
      "published_date": "2024-01-08 02:27:14 UTC",
      "updated_date": "2024-01-08 02:27:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:34:50.194224"
    },
    {
      "arxiv_id": "2401.03631v1",
      "title": "Bridging the Skills Gap: Evaluating an AI-Assisted Provider Platform to Support Care Providers with Empathetic Delivery of Protocolized Therapy",
      "title_zh": "翻译失败",
      "authors": [
        "William R. Kearns",
        "Jessica Bertram",
        "Myra Divina",
        "Lauren Kemp",
        "Yinzhou Wang",
        "Alex Marin",
        "Trevor Cohen",
        "Weichao Yuwen"
      ],
      "abstract": "Despite the high prevalence and burden of mental health conditions, there is\na global shortage of mental health providers. Artificial Intelligence (AI)\nmethods have been proposed as a way to address this shortage, by supporting\nproviders with less extensive training as they deliver care. To this end, we\ndeveloped the AI-Assisted Provider Platform (A2P2), a text-based virtual\ntherapy interface that includes a response suggestion feature, which supports\nproviders in delivering protocolized therapies empathetically. We studied\nproviders with and without expertise in mental health treatment delivering a\ntherapy session using the platform with (intervention) and without (control)\nAI-assistance features. Upon evaluation, the AI-assisted system significantly\ndecreased response times by 29.34% (p=0.002), tripled empathic response\naccuracy (p=0.0001), and increased goal recommendation accuracy by 66.67%\n(p=0.001) across both user groups compared to the control. Both groups rated\nthe system as having excellent usability.",
      "tldr_zh": "该研究针对全球心理健康提供者短缺的问题，开发了 AI-Assisted Provider Platform (A2P2)，一个文本-based 虚拟治疗界面，提供响应建议以帮助提供者（无论是否有专业经验）以 empathetic 方式交付标准化治疗。实验比较了有无 AI 辅助的组别，结果显示 AI 辅助显著减少了响应时间 29.34%（p=0.002），将 empathic 响应准确性提高三倍（p=0.0001），并将目标推荐准确性提高 66.67%（p=0.001）。整体而言，该平台被评为具有优秀可用性，为 AI 在心理健康支持中的应用提供了有效解决方案。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted: AMIA Annual Symposium 2023. To appear as: Kearns W, Bertram\n  J, Divina M, Kemp L, Wang Y, Marin A, Cohen T, Yuwen W. Bridging the Skills\n  Gap: Evaluating an AI-Assisted Provider Platform to Support Care Providers\n  with Empathetic Delivery of Protocolized Therapy. AMIA Annual Symposium\n  Proceedings 2023. American Medical Informatics Association",
      "pdf_url": "http://arxiv.org/pdf/2401.03631v1",
      "published_date": "2024-01-08 02:23:17 UTC",
      "updated_date": "2024-01-08 02:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:35:04.856492"
    },
    {
      "arxiv_id": "2401.03630v2",
      "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhe Chen",
        "Sven Koenig",
        "Bistra Dilkina"
      ],
      "abstract": "With the explosive influence caused by the success of large language models\n(LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work\nshowing that foundation models can be used to solve a large variety of tasks.\nHowever, there is very limited work that shares insights on multi-agent\nplanning. Multi-agent planning is different from other domains by combining the\ndifficulty of multi-agent coordination and planning, and making it hard to\nleverage external tools to facilitate the reasoning needed. In this paper, we\nfocus on the problem of multi-agent path finding (MAPF), which is also known as\nmulti-robot route planning, and study the performance of solving MAPF with\nLLMs. We first show the motivating success on an empty room map without\nobstacles, then the failure to plan on the harder room map and maze map of the\nstandard MAPF benchmark. We present our position on why directly solving MAPF\nwith LLMs has not been successful yet, and we use various experiments to\nsupport our hypothesis. Based on our results, we discussed how researchers with\ndifferent backgrounds could help with this problem from different perspectives.",
      "tldr_zh": "该论文探讨了Large Language Model (LLM) 在解决Multi-agent Path Finding (MAPF) 问题上尚未成功的原因，强调了多智能体规划的复杂性，包括协调挑战和难以使用外部工具辅助推理。作者通过实验展示了LLM在简单空房间地图上的成功表现，但在大标准基准中的复杂房间和迷宫地图上失败。论文基于这些结果提出假设，支持LLM直接处理MAPF的局限性，并讨论了不同背景的研究者如何从多角度（如改进工具或算法）帮助解决这一问题。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03630v2",
      "published_date": "2024-01-08 02:22:04 UTC",
      "updated_date": "2024-02-09 17:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:35:15.754695"
    },
    {
      "arxiv_id": "2402.00033v1",
      "title": "LF-ViT: Reducing Spatial Redundancy in Vision Transformer for Efficient Image Recognition",
      "title_zh": "LF-ViT：减少视觉Transformer中空间冗余以实现高效图像识别",
      "authors": [
        "Youbing Hu",
        "Yun Cheng",
        "Anqi Lu",
        "Zhiqiang Cao",
        "Dawei Wei",
        "Jie Liu",
        "Zhijun Li"
      ],
      "abstract": "The Vision Transformer (ViT) excels in accuracy when handling high-resolution\nimages, yet it confronts the challenge of significant spatial redundancy,\nleading to increased computational and memory requirements. To address this, we\npresent the Localization and Focus Vision Transformer (LF-ViT). This model\noperates by strategically curtailing computational demands without impinging on\nperformance. In the Localization phase, a reduced-resolution image is\nprocessed; if a definitive prediction remains elusive, our pioneering\nNeighborhood Global Class Attention (NGCA) mechanism is triggered, effectively\nidentifying and spotlighting class-discriminative regions based on initial\nfindings. Subsequently, in the Focus phase, this designated region is used from\nthe original image to enhance recognition. Uniquely, LF-ViT employs consistent\nparameters across both phases, ensuring seamless end-to-end optimization. Our\nempirical tests affirm LF-ViT's prowess: it remarkably decreases Deit-S's FLOPs\nby 63\\% and concurrently amplifies throughput twofold. Code of this project is\nat https://github.com/edgeai1/LF-ViT.git.",
      "tldr_zh": "该论文提出 LF-ViT 模型，旨在减少 Vision Transformer (ViT) 在图像识别中的空间冗余，从而降低计算和内存需求，同时保持性能。LF-ViT 通过 Localization 阶段处理低分辨率图像，若预测不确定则触发 Neighborhood Global Class Attention (NGCA) 机制来识别关键区域，随后在 Focus 阶段使用原始图像的指定区域进行增强识别。模型采用一致的参数实现端到端优化，实验结果显示其将 Deit-S 的 FLOPs 减少 63%，并将吞吐量提高一倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00033v1",
      "published_date": "2024-01-08 01:32:49 UTC",
      "updated_date": "2024-01-08 01:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:35:27.542745"
    },
    {
      "arxiv_id": "2401.04144v1",
      "title": "Robust Calibration For Improved Weather Prediction Under Distributional Shift",
      "title_zh": "稳健校准用于改进分布偏移下的天气预测",
      "authors": [
        "Sankalp Gilda",
        "Neel Bhandari",
        "Wendy Mak",
        "Andrea Panizza"
      ],
      "abstract": "In this paper, we present results on improving out-of-domain weather\nprediction and uncertainty estimation as part of the \\texttt{Shifts Challenge\non Robustness and Uncertainty under Real-World Distributional Shift} challenge.\nWe find that by leveraging a mixture of experts in conjunction with an advanced\ndata augmentation technique borrowed from the computer vision domain, in\nconjunction with robust \\textit{post-hoc} calibration of predictive\nuncertainties, we can potentially achieve more accurate and better-calibrated\nresults with deep neural networks than with boosted tree models for tabular\ndata. We quantify our predictions using several metrics and propose several\nfuture lines of inquiry and experimentation to boost performance.",
      "tldr_zh": "这篇论文探讨了在Distributional Shift下提升天气预测准确性和不确定性估计的方法，针对真实世界分布偏移问题。研究者结合了mixture of experts模型、从计算机视觉领域借用的高级data augmentation技术，以及robust post-hoc calibration，对深度神经网络进行优化，结果显示其性能优于boosted tree models。论文通过多种指标量化了预测效果，并提出了未来实验方向以进一步提升表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the Bayesian Deep Learning workshop at NeurIPS 2021",
      "pdf_url": "http://arxiv.org/pdf/2401.04144v1",
      "published_date": "2024-01-08 01:29:56 UTC",
      "updated_date": "2024-01-08 01:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:35:39.108885"
    },
    {
      "arxiv_id": "2401.03621v2",
      "title": "Machine Learning Applications in Traumatic Brain Injury: A Spotlight on Mild TBI",
      "title_zh": "机器学习在创伤性脑损伤中的应用：聚焦于轻度 TBI",
      "authors": [
        "Hanem Ellethy",
        "Shekhar S. Chandra",
        "Viktor Vegh"
      ],
      "abstract": "Traumatic Brain Injury (TBI) poses a significant global public health\nchallenge, contributing to high morbidity and mortality rates and placing a\nsubstantial economic burden on healthcare systems worldwide. The diagnosis of\nTBI relies on clinical information along with Computed Tomography (CT) scans.\nAddressing the multifaceted challenges posed by TBI has seen the development of\ninnovative, data-driven approaches, for this complex condition. Particularly\nnoteworthy is the prevalence of mild TBI (mTBI), which constitutes the majority\nof TBI cases where conventional methods often fall short. As such, we review\nthe state-of-the-art Machine Learning (ML) techniques applied to clinical\ninformation and CT scans in TBI, with a particular focus on mTBI. We categorize\nML applications based on their data sources, and there is a spectrum of ML\ntechniques used to date. Most of these techniques have primarily focused on\ndiagnosis, with relatively few attempts at predicting the prognosis. This\nreview may serve as a source of inspiration for future research studies aimed\nat improving the diagnosis of TBI using data-driven approaches and standard\ndiagnostic data.",
      "tldr_zh": "本论文回顾了机器学习 (ML) 在外伤性脑损伤 (TBI) 领域的应用，特别是针对占大多数病例的轻度 TBI (mTBI)，强调了其在诊断和预后预测中的潜力。TBI 作为全球公共健康挑战，依赖临床信息和 Computed Tomography (CT) 扫描进行诊断，但传统方法常有局限，因此数据驱动方法变得至关重要。作者基于数据来源对现有 ML 技术进行了分类，主要集中在诊断应用上，而预后预测的研究相对较少。该回顾旨在为未来研究提供灵感，推动使用 ML 和标准诊断数据改进 TBI 的诊断准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "The manuscript has 34 pages, 3 figures, and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.03621v2",
      "published_date": "2024-01-08 01:29:00 UTC",
      "updated_date": "2024-01-11 13:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:35:51.096808"
    },
    {
      "arxiv_id": "2401.06790v2",
      "title": "Using Zero-shot Prompting in the Automatic Creation and Expansion of Topic Taxonomies for Tagging Retail Banking Transactions",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel de S. Moraes",
        "Pedro T. C. Santos",
        "Polyana B. da Costa",
        "Matheus A. S. Pinto",
        "Ivan de J. P. Pinto",
        "Álvaro M. G. da Veiga",
        "Sergio Colcher",
        "Antonio J. G. Busson",
        "Rafael H. Rocha",
        "Rennan Gaio",
        "Rafael Miceli",
        "Gabriela Tourinho",
        "Marcos Rabaioli",
        "Leandro Santos",
        "Fellipe Marques",
        "David Favaro"
      ],
      "abstract": "This work presents an unsupervised method for automatically constructing and\nexpanding topic taxonomies using instruction-based fine-tuned LLMs (Large\nLanguage Models). We apply topic modeling and keyword extraction techniques to\ncreate initial topic taxonomies and LLMs to post-process the resulting terms\nand create a hierarchy. To expand an existing taxonomy with new terms, we use\nzero-shot prompting to find out where to add new nodes, which, to our\nknowledge, is the first work to present such an approach to taxonomy tasks. We\nuse the resulting taxonomies to assign tags that characterize merchants from a\nretail bank dataset. To evaluate our work, we asked 12 volunteers to answer a\ntwo-part form in which we first assessed the quality of the taxonomies created\nand then the tags assigned to merchants based on that taxonomy. The evaluation\nrevealed a coherence rate exceeding 90% for the chosen taxonomies. The\ntaxonomies' expansion with LLMs also showed exciting results for parent node\nprediction, with an f1-score above 70% in our taxonomies.",
      "tldr_zh": "这篇论文提出了一种无监督方法，使用指令微调的LLMs（Large Language Models）来自动构建和扩展主题分类法（topic taxonomies），以标记零售银行交易中的商户。方法结合主题建模和关键词提取创建初始分类法，然后通过LLMs后处理形成层次结构，并首次应用zero-shot prompting来扩展分类法中的新节点。实验结果显示，生成的分类法连贯性超过90%，扩展部分的父节点预测F1分数超过70%，证明了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06790v2",
      "published_date": "2024-01-08 00:27:16 UTC",
      "updated_date": "2024-02-11 15:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:36:03.099104"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 58,
  "processed_papers_count": 58,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T20:36:25.086073"
}