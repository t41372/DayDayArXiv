{
  "date": "2025-04-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-04-24的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的论文展现了人工智能在各个领域的深度融合与创新。从能打羽毛球的机器人、应对 LLM 幻觉的新基准，到利用 AI 进行伦理审计和隐私保护的联邦学习，研究热点广泛。特别值得关注的是多篇关于模型鲁棒性、可解释性以及利用大小模型协同工作的论文，显示出 AI 正朝着更可靠、更实用、更符合人类价值观的方向发展。此外，一些新颖的框架和数据集（如 Plasticine、DARai、LiveLongBench）的提出，也为特定领域的研究注入了新的活力。\n\n**重点论文 & 热点话题**\n\n*   **羽毛球机器人新突破：学习与物理模型的融合 (Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control)**\n    这篇 ICRA 2025 论文介绍了一种名为 HAMLET 的新型混合控制系统，用于控制敏捷的羽毛球机器人。它巧妙地结合了基于学习的上肢操作策略（模仿学习 IL + 强化学习 RL）和基于模型的底盘移动策略。特别之处在于，它提出了一个物理信息引导的 \"IL+RL\" 训练框架，并在 IL 阶段训练 Critic 模型以缓解 IL 到 RL 的性能下降问题。实验表明，该机器人在对抗发球机和人类选手时均取得了超过 90% 的高成功率。这对敏捷移动操作任务（如抓取、乒乓球）具有借鉴意义。\n\n*   **LLM 幻觉新基准 HalluLens (HalluLens: LLM Hallucination Benchmark)**\n    针对大型语言模型 (LLM) 普遍存在的幻觉问题（生成内容偏离用户输入或训练数据），该研究提出了一个全面的幻觉基准 HalluLens。它区分了内在幻觉和外在幻觉（生成内容与训练数据不一致），并特别关注后者。该基准包含新的外在幻觉评估任务，并设计了动态测试集生成机制以防止数据泄漏导致基准饱和。这项工作旨在建立清晰的幻觉分类法，并提供更鲁棒的评估工具，推动解决 LLM 的幻觉问题。\n\n*   **AI 伦理逻辑审计：评估大模型的道德推理 (Auditing the Ethical Logic of Generative AI Models)**\n    随着生成式 AI 应用于高风险领域，评估其伦理推理能力至关重要。该研究提出了一个五维审计模型（分析质量、伦理考虑广度、解释深度、一致性、决策性），并使用多组包含新颖伦理困境的提示来评估主流 LLM。研究发现，虽然模型在伦理决策上趋于一致，但在解释的严谨性和道德优先级上存在差异。思维链（CoT）提示和推理优化模型能显著提升审计指标表现。该工作为 AI 系统的伦理基准测试提供了可扩展的方法。\n\n*   **FRAG：无需长上下文 LMM 即可理解长视频/文档 (FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding)**\n    处理长视频和长文档对大型多模态模型 (LMM) 来说计算成本高昂。这篇论文提出了一种名为 FRAG (Frame Selection Augmented Generation) 的新颖框架，无需长上下文 LMM 即可处理长输入。FRAG 首先让模型独立地为每个帧（或页面）打分，选出最相关的 Top-K 帧，然后仅基于这些选定的帧生成最终输出。这种方法无需微调现有 LMM，在长视频理解（MLVU, Video-MME）和长文档理解（MP-DocVQA）任务上显著提升了 LaVA-OneVision 和 InternVL2 的性能，达到了 SOTA 水平。\n\n*   **Plasticine：加速可塑性驱动的深度强化学习研究 (Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning)**\n    深度强化学习 (RL) 系统常面临“可塑性损失”问题，即神经网络在训练中逐渐失去适应能力。为解决该领域缺乏统一基准和评估协议的问题，研究者推出了 Plasticine，这是首个用于基准测试深度 RL 中可塑性优化的开源框架。它提供了超过 13 种缓解方法、10 种评估指标以及从标准到开放环境的非平稳学习场景的实现。该框架有助于研究人员量化可塑性损失、评估缓解策略并分析不同情境下的可塑性动态。\n\n*   **大小模型协同：释放 AI 在特定领域的潜力 (Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks)**\n    大型语言模型 (LLM) 能力强大但资源消耗巨大，小型模型 (SM) 更高效且易于领域定制。这篇立场性论文主张采用 LLM 和 SM 协同工作的方式，加速 LLM 在私有领域的适应，并释放 AI 的新潜力。论文探讨了多种模型协作策略，识别了挑战与机遇，并倡导在真实私有数据集和应用上进行多目标基准测试的行业驱动研究。\n\n*   **重新定义超级对齐：迈向人机共生社会 (Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society)**\n    面对可能超越人类智能的 ASI，如何确保其与人类意图和价值观保持一致（即超级对齐）是紧迫问题。该文将超级对齐重新定义为“朝着可持续共生社会的人工智能共同对齐”，并提出了一个整合外部监督和内在主动对齐的框架。外部监督强调以人为中心的最终决策和可解释的自动评估；内在主动对齐则根植于 AI 对自我、他人和社会的理解，通过自我意识、反思和共情来主动推断人类意图并考虑人类福祉。这种内外结合的方法旨在实现安全有益的 AGI/ASI。\n\n**AI/ML 核心方法与理论**\n\n*   **联邦学习隐私保护综述 (Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence)**\n    这篇综述简洁全面地概述了联邦学习 (FL)，包括其核心架构、通信协议和生命周期。重点讨论了关键技术挑战，如处理非独立同分布 (non-IID) 数据、系统异构性、通信开销以及通过差分隐私和安全聚合等机制确保隐私。同时，也探讨了 FL 的新兴趋势（个性化 FL、跨设备/跨孤岛、与强化学习/量子计算的结合）和未来研究方向。\n\n*   **TACO：解决联邦学习中的过度修正问题 (TACO: Tackling Over-correction in Federated Learning with Tailored Adaptive Correction)**\n    针对联邦学习 (FL) 中现有方法统一修正系数可能导致的“过度修正”现象（降低模型性能甚至导致不收敛），该研究提出了 TACO 算法。TACO 通过实现细粒度的、客户端特定的梯度修正和模型聚合，引导局部模型更精确地趋向全局最优。该方法计算开销小，无需额外信息。收敛性分析揭示了过度修正的根源，实验证明了 TACO 的优越性和稳定性。\n\n*   **GRANITE：拜占庭弹性的动态 Gossip 学习框架 (GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework)**\n    Gossip Learning (GL) 是一种去中心化学习范式。该研究提出了 GRANITE 框架，用于在存在拜占庭节点（模型投毒攻击）的稀疏动态图上进行鲁棒学习。GRANITE 包含两个关键部分：历史感知的拜占庭弹性对等采样协议 (HaPS) 和自适应概率阈值 (APT)。实验表明，GRANITE 在高达 30% 拜占庭节点存在时仍能保持收敛，并通过自适应过滤提高学习速度。\n\n*   **DROCKS：基于 ROCKET 特征的去中心化时间序列分类 (Decentralized Time Series Classification with ROCKET Features)**\n    为解决联邦学习 (FL) 中客户端-服务器架构的单点故障和隐私风险，该研究提出了 DROCKS，一个完全去中心化的时间序列分类 (TSC) 框架。DROCKS 利用 ROCKET 特征，全局模型通过在节点间按结构化路径顺序传递进行训练，每个节点优化模型并选择最有效的局部核。实验表明，DROCKS 性能优于 SOTA 的客户端-服务器 FL 方法，且对节点故障和攻击更具弹性。\n\n*   **SRL-VAE：通过平滑鲁棒潜在编码增强 VAE (Enhancing Variational Autoencoders with Smooth Robust Latent Encoding)**\n    针对 VAE 鲁棒性研究不足的问题，该研究提出 Smooth Robust Latent VAE (SRL-VAE)，一种新颖的对抗训练框架，旨在同时提升生成质量和鲁棒性。与传统对抗训练不同，SRL-VAE 通过对抗扰动平滑潜在空间，促进更泛化的表示，同时通过正则化保持原始保真度。实验表明，SRL-VAE 能在少量计算开销下，改善预训练 VAE 的图像重建、文本引导编辑质量以及对攻击的鲁棒性。\n\n*   **NeuralGrok：通过神经梯度变换加速 Grokking (NeuralGrok: Accelerate Grokking by Neural Gradient Transformation)**\n    Grokking 指模型在长时间过拟合后才实现泛化的现象。该研究提出 NeuralGrok，一种基于梯度的 MAML 方法，通过训练一个辅助模块来学习最优梯度变换，动态调整梯度分量的影响，从而加速 Transformer 在算术任务中的泛化。实验表明 NeuralGrok 能显著加速泛化，促进更稳定的训练，并通过降低模型复杂度（用新的 AGE 指标衡量）来促进泛化。\n\n*   **OUI：过拟合检测新视角 (OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection)**\n    提出了一种新的过拟合-欠拟合指示器 (OUI)，用于监控 DNN 训练动态并识别最优正则化超参数（如权重衰减 WD）。OUI 无需验证数据即可指示模型状态，且收敛速度快于传统指标，能在训练早期帮助选择合适的 WD 值，从而改善泛化能力。\n\n**AI 应用**\n\n*   **医疗健康：**\n    *   **多重耐药性早期检测 (Early Detection of Multidrug Resistance Using Multivariate Time Series Analysis and Interpretable Patient-Similarity Representations)**：提出一个可解释的机器学习框架，将患者建模为多元时间序列 (MTS)，利用 MTS 相似性度量（统计、DTW、TCK）和图聚类进行 MDR 预测，AUC 达到 81%，并能识别风险因素和临床相关集群。\n    *   **符合 HIPAA 的 Agentic AI 医疗系统 (Towards a HIPAA Compliant Agentic AI System in Healthcare)**：提出一个符合 HIPAA 的 Agentic AI 框架，通过属性访问控制 (ABAC)、混合 PHI 清洗（正则+BERT）和不可变审计追踪来确保处理受保护健康信息 (PHI) 时的合规性。\n    *   **猴痘诊断 (An Explainable Nature-Inspired Framework for Monkeypox Diagnosis)**：提出一个结合 Xception 特征提取、PCA 降维、NGBoost 分类和非洲秃鹫优化算法 (AVOA) 进行超参数优化的框架，用于从皮肤损伤图像自动检测猴痘，准确率达 97.53%，并使用 Grad-CAM 和 LIME 提高可解释性。\n    *   **ICU 血液检测优化 (ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders)**：开发 ExOSITO 方法，结合离策略学习和特权信息，为 ICU 患者确定最优的血液检测组合。将问题建模为因果老虎机，利用临床知识和观测数据训练，提供可解释的辅助工具以减少不必要的检测。\n    *   **RNA 亚细胞定位预测综述 (A Comprehensive Review on RNA Subcellular Localization Prediction)**：全面回顾了基于 AI/ML 的 RNA 亚细胞定位预测方法，涵盖 lncRNA、mRNA、miRNA 等，讨论了基于序列、图像和混合方法，并指出了数据稀缺、缺乏基准等挑战与机遇。\n    *   **汗腺 3D 分割与形态学响应 (3D Deep-learning-based Segmentation of Human Skin Sweat Glands and Their 3D Morphological Response to Temperature Variations)**：提出基于 Transformer 的 3D 多目标分割框架，用于精确分割 OCT 图像中的汗腺，并首次量化了汗腺 3D 形态对温度变化的细微响应，为皮肤病学研究和临床应用提供新工具。\n\n*   **机器人与自动驾驶：**\n    *   **自主车辆感知系统罕见失效模式识别 (AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models)**：提出 AUTHENTICATION 方法，利用生成式 AI（对抗引导的扩散模型）和可解释 AI 技术，生成旨在规避目标检测模型的图像，以识别和理解自动驾驶车辆感知系统中的罕见失效模式（长尾问题），提高系统鲁棒性。\n    *   **改善复杂系统中的人-车交互 (Improving Human-Autonomous Vehicle Interaction in Complex Systems)**：通过三项实证研究探讨了自动驾驶车辆 (AV) 如何满足乘客信息需求。研究强调需要任务敏感、模态合适、考虑认知限制和目标、上下文敏感以及个性化的通信策略，以增强驾驶性能、信心和信任。\n    *   **基于下一视点估计的相机臂控制物体姿态估计 (Object Pose Estimation by Camera Arm Control Based on the Next Viewpoint Estimation)**：提出一种新的下一视点 (NV) 估计方法，与姿态估计 NN 集成，用于改进简单形状产品的姿态估计。实验表明该方法能有效提高姿态估计成功率。\n    *   **利用多维尺度变换学习道路网络等距嵌入 (Learning Isometric Embeddings of Road Networks using Multidimensional Scaling)**：探讨如何利用多维尺度变换 (MDS) 技术处理道路网络的图表示，以获得适用于基于学习的自动驾驶运动规划的特征空间，解决泛化性挑战。\n\n*   **软件工程与安全：**\n    *   **检测、分类和普遍存在的自认老化债务 (Detection, Classification and Prevalence of Self-Admitted Aging Debt)**：引入“老化债务”(AD) 概念，并通过分析源代码注释中的“自认老化债务”(SAAD) 来研究软件老化。提出了 SAAD 模式和分类法（活跃/休眠），发现超过 21% 的 OSS 仓库存在 SAAD 迹象，其中休眠 AD 占主导。\n    *   **利用 LLM 摘要进行源代码主题建模 (Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code)**：提出一种新方法，将 LLM 生成的代码摘要与基于 Transformer 的主题模型相结合，以自动识别 Python 程序语料库中的有意义主题。实验表明该方法能提供可解释且语义丰富的代码结构表示。\n    *   **LLM 自动生成恶意软件包规则 (Automatically Generating Rules of Malicious Software Packages via Large Language Model)**：提出 RuleLLM 工具，利用 LLM 从恶意软件包的元数据和代码片段中自动生成 YARA 和 Semgrep 规则，用于检测软件供应链攻击。实验表明其生成的规则在精确度和召回率上优于 SOTA 工具。\n    *   **揭露 AI 生成非自愿私密图像的恶意技术生态系统 (The Malicious Technical Ecosystem: Exposing Limitations in Technical Governance of AI-Generated Non-Consensual Intimate Images of Adults)**：以受害者为中心，分析了用于创建 AI 生成的非自愿私密图像 (AIG-NCII) 的“恶意技术生态系统”（开源换脸模型和近 200 个“裸体化”软件），并指出当前技术治理方法（如 NIST AI 100-4）在监管成人 AIG-NCII 方面的局限性和假设缺陷。\n\n*   **其他应用：**\n    *   **工业表面缺陷检测中的保形分割 (Conformal Segmentation in Industrial Surface Defect Detection with Statistical Guarantees)**：将保形预测 (Conformal Prediction) 应用于工业钢材表面缺陷检测。通过定义损失函数和基于用户风险水平推导统计阈值，构建预测集（缺陷区域），确保测试集上的预期错误率有界，并提供模型不确定性的度量。\n    *   **基于保形预测的稀疏和无约束环境下的航空图像分类 (Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction)**：在数据稀缺且高度可变的航空图像数据集上，实证分析了保形预测方法的效果。研究了使用预训练模型、温度缩放校准以及模型压缩对预测集覆盖率和大小的影响。\n    *   **利用街景对比聚类和地理先验进行无监督城市土地利用制图 (Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior)**：提出一种无监督对比聚类模型，结合地理先验（空间相干性），用于从街景图像生成城市土地利用地图。该方法无需标签，可适应不同城市环境。\n    *   **LLM 在教育领域的多语言性能偏差 (Multilingual Performance Biases of Large Language Models in Education)**：评估了主流 LLM 在六种非英语语言（印地语、阿拉伯语、波斯语、泰卢固语、乌克兰语、捷克语）和英语上的四项教育任务（识别误解、提供反馈、交互式辅导、翻译评分）表现。发现性能与训练数据量相关，低资源语言表现较差，建议在部署前验证目标语言性能。\n    *   **利用多智能体分层强化学习探索特征子空间 (Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning)**：提出 HRLFS，一种基于多智能体分层强化学习的特征选择方法。利用 LLM 提取特征的数学和语义特性进行聚类，构建分层 Agent 结构。实验证明了其效率、可扩展性和鲁棒性。\n    *   **用于自动化特征变换的协作多智能体强化学习 (Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization)**：提出 TCTO 框架，使用协作多智能体强化学习和图驱动路径优化来自动化特征变换。通过演化交互图建模特征和变换，利用图剪枝和回溯减少冗余，并重用高价值子图。\n    *   **利用 GCN 结构学习和 LLM 化学知识增强虚拟筛选 (Combining GCN Structural Learning with LLM Chemical Knowledge for or Enhanced Virtual Screening)**：提出一种混合架构，将图卷积网络 (GCN) 与 LLM 导出的嵌入相结合，用于药物发现中的虚拟筛选。LLM 嵌入提供全局化学知识，GCN 进行局部结构学习。该方法在 F1 分数上优于单独的 GCN、XGBoost 和 SVM。\n    *   **面向目标的时序预测：基础框架设计 (Goal-Oriented Time-Series Forecasting: Foundation Framework Design)**：提出一种新的时序预测训练方法，允许模型根据终端应用的特定需求（预测范围的重要性）动态调整其焦点。该方法将预测分解为小段，动态加权组合，在标准数据集和无线通信数据集上均表现出优势。\n    *   **LiveLongBench：处理直播流口语长文本理解 (LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams)**：构建了首个源自直播流的口语长文本数据集 LiveLongBench，包含检索依赖、推理依赖和混合型任务，以反映真实世界对话的高冗余和信息密度不均特性。评估发现现有 LLM 和专门方法在处理此类文本时表现不佳，并提出了新的基线模型。\n    *   **通过神经符号反馈改进文本到视频生成 (We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback)**：提出名为 Fixit 的零训练视频优化流程，利用神经符号反馈自动增强文本到视频 (T2V) 生成。通过分析视频的形式化表示识别语义不一致之处，并指导对原始视频进行有针对性的编辑，显著提升了生成视频与复杂提示的时间和逻辑对齐度。\n    *   **用于任何到任何生成任务的符号表示 (Symbolic Representation for Any-to-Any Generative Tasks)**：提出一种符号化的生成任务描述语言和推理引擎，能将任意多模态任务表示为结构化符号流。利用预训练 LLM，无需训练即可将自然语言指令映射到符号工作流，成功执行了超过 12 种不同的多模态生成任务，展现了高效率、可编辑性和可扩展性。\n\n**简讯**\n\n*   **SNN 重置机制再探讨 (Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential Modeling)**：从二元激活 RNN 的角度审视 SNN，分析了传统 SNN 在序列建模中的挑战，并重新审视了重置机制和不应期等生物机制的必要性，提出了固定不应期 SNN 架构。\n*   **利用 SLM 集成实现 LLM 级准确率 (Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks)**：提出集成贝叶斯推理 (EBI) 方法，通过贝叶斯估计结合多个小型语言模型 (SLM) 的判断，在日语和英语的多种任务（能力评估、消费者画像分析）中达到了与大型专有 LLM 相当的准确率。\n*   **INSIGHT：弥合 LLM 时代的师生差距 (INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models)**：提出 INSIGHT 概念验证系统，结合多种 AI 工具（如 LLM）辅助师生解决练习题。通过分析学生向 LLM 的提问来构建动态 FAQ，为教师提供个性化面授支持的见解。\n*   **利用遗传算法优化云资源分配 (Optimized Cloud Resource Allocation Using Genetic Algorithms for Energy Efficiency and QoS Assurance)**：提出基于遗传算法 (GA) 的虚拟机 (VM) 放置和整合方法，旨在最小化功耗同时保证 QoS 约束，优于传统启发式算法。\n*   **基于 ICP 的 LVLM 预测集数据驱动校准 (Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction)**：利用分裂保形预测 (SCP) 框架解决大型视觉语言模型 (LVLM) 在 VQA 任务中的幻觉问题。通过计算不一致性分数构建具有统计保证的预测集，严格控制边际覆盖率。\n*   **分层多模态数据理解日常活动 (Hierarchical and Multimodal Data for Daily Activity Understanding)**：介绍了 DARai 数据集，包含 50 名参与者在 10 种环境中超过 200 小时的多模态（20 种传感器）数据，并进行了三层级（活动 L1、动作 L2、步骤 L3）标注，用于理解复杂的人类活动。\n*   **GPCR 独特动态激活路径揭示偏向信号和变构位点 (Deciphering the unique dynamic activation pathway in a G protein-coupled receptor enables unveiling biased signaling and identifying cryptic allosteric sites in conformational intermediates)**：结合计算和实验方法（MD 模拟、MSM、网络分析、诱变、生物传感器），揭示了神经降压素受体 1 (NTSR1) 的动态逐步激活机制和信号网络，识别了中间态存在的隐蔽变构位点。\n*   **用生物启发的边界补全滤波器增强 CNN 对遮挡的鲁棒性 (Enhancing CNNs robustness to occlusions with bioinspired filters for border completion)**：利用视觉皮层边界补全机制的数学模型定义 CNN 的自定义滤波器，在遮挡 MNIST 图像上测试改进的 LeNet-5 时，性能（尤其准确率）得到提升。\n*   **STCL：深度学习图像隐写模型的课程学习策略 (STCL:Curriculum learning Strategies for deep learning image steganography models)**：提出隐写术课程学习 (STCL) 训练策略，包含基于教师模型的难度评估和基于拐点的训练调度，从易到难训练模型，以提高隐写图像质量和网络收敛速度。\n*   **PTCL：标签受限动态图的伪标签时序课程学习 (PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph)**：提出 PTCL 方法，解决仅有最终标签可用的动态节点分类问题。通过时序解耦架构生成伪标签，并使用时序课程学习策略优先考虑接近最终时间戳的伪标签。同时贡献了新数据集 CoOAG 和统一框架 FLiD。\n*   **用户意图的代码生成 (Towards Machine-Generated Code for the Resolution of User Intentions)**：探讨了利用 LLM 根据用户意图（如“请把我的汽车所有权文件发给保险公司”）生成代码来执行工作流的可行性。实验表明 GPT-4o-mini 在根据用户意图生成面向代码的工作流方面表现出色。\n*   **地球物理学基础模型开发流程、机遇与挑战 (On the workflow, opportunities and challenges of developing foundation model in geophysics)**：系统探讨了在地球物理学领域开发基础模型的完整流程，从数据处理到模型选择、预训练和部署，并讨论了如何应对地球物理数据的多样性、复杂性和物理一致性约束等挑战。\n*   **评估 LLM 生成领域特定本体的能力 (Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation)**：研究了 LLM（DeepSeek, o1-preview）基于能力问题 (CQ) 和用户故事自动生成领域特定本体的能力。发现在六个不同领域中，模型表现一致，表明 LLM 在实现可扩展、领域无关的本体构建方面具有潜力。\n*   **StereoMamba：实时鲁棒的术中立体视差估计 (StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies)**：提出 StereoMamba 架构，包含特征提取 Mamba (FE-Mamba) 模块和多维特征融合 (MFF) 模块，用于机器人辅助微创手术 (RAMIS) 中的立体视差估计，在准确性、鲁棒性和速度之间取得良好平衡。\n*   **面向法律执行 AI 辅助决策的用户中心设计 (Towards User-Centred Design of AI-Assisted Decision-Making in Law Enforcement)**：通过对执法机构决策制定的定性研究，识别了现有实践的局限性，探索了 AI 辅助系统的用户需求（可扩展性、准确性、可解释性、可信赖性、适应性）以及人机责任分工。\n*   **FLUKE：语言学驱动的任务无关鲁棒性评估框架 (FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation)**：提出 FLUKE 框架，通过对测试数据进行系统性的最小语言学变动（从拼写到方言风格）来评估模型鲁棒性。发现语言变动的影响高度依赖任务，LLM 虽整体鲁棒性更好但仍对某些变动脆弱。\n*   **DeepLabv3+ 增强糖尿病视网膜病变分割 (Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+)**：使用 DeepLabv3+ 对糖尿病视网膜病变（微动脉瘤、出血、渗出等）进行病变类型特定的二元分割，并结合后处理，准确率达 99%。\n*   **为电商应用生成用户画像 (You Are What You Bought: Generating Customer Personas for E-commerce Applications)**：提出 GPLR 方法，利用预训练 LLM 从用户购买历史中推断用户画像（如“忙碌的父母”），并结合随机游走技术为其余用户预测画像，生成可读的用户表示，提升了推荐和用户分割任务的性能。\n*   **AI 增强的业务流程自动化：保险领域案例 (AI-Enhanced Business Process Automation: A Case Study in the Insurance Domain Using Object-Centric Process Mining)**：以保险索赔零件识别自动化为例，应用面向对象的流程挖掘 (OCPM) 评估 LLM 驱动的自动化对流程可扩展性的影响。发现 LLM 显著提升运营能力，但也引入了需要进一步优化的新流程动态。\n*   **CoGA：用于强化学习的生成式可供性代码 (Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning)**：提出 CoGA 方法，利用预训练 VLM 生成代码来确定意图驱动的可供性（affordances），即在给定情境下能实现期望结果的动作子集。这约束了 RL Agent 的动作空间，在 MiniWob++ 基准测试中显著提高了样本效率。\n*   **JurisCTC：跨领域迁移和对比学习增强法律判决预测 (JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning)**：提出 JurisCTC 模型，利用无监督域适应 (UDA) 和对比学习，在民法和刑法领域之间进行知识迁移，以提高法律判决预测 (LJP) 任务的准确性。\n*   **粗到细多模态注意力聚焦的高效 Agent 视频理解框架 (MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing)**：提出 MCAF，一个基于 Agent 的、无需训练的视频理解框架。通过多模态信息进行分层粗到细的注意力聚焦，优先处理与查询高度相关的视频片段，并结合扩张时间扩展和自我反思机制，提高对长视频的理解准确率。\n*   **物理信息引导的 DDPM 生成合成潮流数据 (Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models)**：提出基于去噪扩散概率模型 (DDPM) 的物理信息引导生成框架，用于合成符合统计保真度和电力系统可行性约束的潮流数据，以解决真实数据有限的问题。\n*   **通过受控扩散和高效嵌入生成靶向 AMP (Targeted AMP generation through controlled diffusion with efficient embeddings)**：提出 OmegAMP 框架，利用基于扩散的生成模型、高效低维嵌入和精确可控机制，靶向生成具有特定理化性质、活性谱和物种特异性的抗菌肽 (AMP)，旨在应对抗菌素耐药性。\n*   **数据驱动的代理模型预测粗糙表面接触有效面积 (Data-Driven Surrogate Modeling Techniques to Predict the Effective Contact Area of Rough Surface Contact Problems)**：提出一个代理建模框架，使用多种机器学习算法（如核岭回归、高斯过程回归）基于载荷和粗糙度参数快速预测粗糙表面接触的有效接触面积，以替代高成本的数值方法（如 BEM）。\n*   **双个体遗传算法：高效训练多层神经网络 (Dual-Individual Genetic Algorithm: A Dual-Individual Approach for Efficient Training of Multi-Layer Neural Networks)**：提出双个体遗传算法 (Dual-Individual GA)，仅使用两个个体（Leader 和 Follower）进行交叉，分别负责利用和探索，并包含自适应层维度机制，用于优化神经网络进行二元图像分类。\n*   **探索上下文感知和 LLM 驱动的 VR 移动 (Exploring Context-aware and LLM-driven Locomotion for Immersive Virtual Reality)**：提出一种由 LLM 驱动的新型 VR 移动技术，允许用户使用自然语言结合上下文感知进行导航。评估表明，该方法在可用性、临场感和晕动症方面与传统方法相当，且能提升用户在虚拟环境中的注意力。\n*   **华为 TSC 的端到端文档图像机器翻译系统 (DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model)**：介绍了华为翻译服务中心为 DIMT25@ICDAR2025 竞赛提出的技术方案。该方案利用大型视觉语言模型 (LVLM)，结合多任务学习和感知思维链，开发了一个统一处理基于 OCR 和无 OCR 任务的端到端文档翻译系统。\n*   **有用智能证明：超越能源浪费的区块链共识 (Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy Waste)**：提出一种名为“有用智能证明”(PoUI) 的混合共识机制。工作节点通过执行有用的 AI 任务（如语言处理、图像分析）来赚取币，然后将币 Staking 以保护网络安全，旨在将计算资源用于实际效用而非单纯的能源消耗。",
  "papers": [
    {
      "arxiv_id": "2504.17771v1",
      "title": "Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control",
      "title_zh": "融合学习型操作与基于物理的运动，实现全身羽毛球机器人控制\n",
      "authors": [
        "Haochen Wang",
        "Zhiwei Shi",
        "Chengxi Zhu",
        "Yafei Qiao",
        "Cheng Zhang",
        "Fan Yang",
        "Pengjie Ren",
        "Lan Lu",
        "Dong Xuan"
      ],
      "abstract": "Learning-based methods, such as imitation learning (IL) and reinforcement\nlearning (RL), can produce excel control policies over challenging agile robot\ntasks, such as sports robot. However, no existing work has harmonized\nlearning-based policy with model-based methods to reduce training complexity\nand ensure the safety and stability for agile badminton robot control. In this\npaper, we introduce \\ourmethod, a novel hybrid control system for agile\nbadminton robots. Specifically, we propose a model-based strategy for chassis\nlocomotion which provides a base for arm policy. We introduce a\nphysics-informed ``IL+RL'' training framework for learning-based arm policy. In\nthis train framework, a model-based strategy with privileged information is\nused to guide arm policy training during both IL and RL phases. In addition, we\ntrain the critic model during IL phase to alleviate the performance drop issue\nwhen transitioning from IL to RL. We present results on our self-engineered\nbadminton robot, achieving 94.5% success rate against the serving machine and\n90.7% success rate against human players. Our system can be easily generalized\nto other agile mobile manipulation tasks such as agile catching and table\ntennis. Our project website: https://dreamstarring.github.io/HAMLET/.",
      "tldr_zh": "本文提出了一种新颖的混合控制系统HAMLET，用于敏捷羽毛球机器人控制。该系统集成了基于学习的操纵和基于物理的运动，其中底盘运动采用基于模型的策略，为机械臂策略提供基础。机械臂策略则采用一种物理信息驱动的“IL+RL”训练框架进行学习，该框架利用具有特权信息的基于模型的策略来指导IL和RL阶段的训练。此外，在IL阶段训练critic模型以缓解从IL到RL的性能下降问题。实验结果表明，该系统在自研羽毛球机器人上对发球机的成功率为94.5%，对人类玩家的成功率为90.7%。该系统可以很容易地推广到其他敏捷移动操作任务，如敏捷抓取和乒乓球。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to ICRA 2025. Project page:\n  https://dreamstarring.github.io/HAMLET/",
      "pdf_url": "http://arxiv.org/pdf/2504.17771v1",
      "published_date": "2025-04-24 17:46:29 UTC",
      "updated_date": "2025-04-24 17:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:03:11.711359"
    },
    {
      "arxiv_id": "2504.17751v1",
      "title": "Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential Modeling: Specialized Discretization for Binary Activated RNN",
      "title_zh": "重温脉冲神经网络中的重置机制以进行序列建模：二元激活 RNN 的专用离散化\n",
      "authors": [
        "Enqi Zhang"
      ],
      "abstract": "In the field of image recognition, spiking neural networks (SNNs) have\nachieved performance comparable to conventional artificial neural networks\n(ANNs). In such applications, SNNs essentially function as traditional neural\nnetworks with quantized activation values. This article focuses on an another\nalternative perspective,viewing SNNs as binary-activated recurrent neural\nnetworks (RNNs) for sequential modeling tasks.From this viewpoint, current SNN\narchitectures face several fundamental challenges in sequence modeling: (1)\nTraditional models lack effective memory mechanisms for long-range sequence\nmodeling; (2) The biological-inspired components in SNNs (such as reset\nmechanisms and refractory period applications) remain theoretically\nunder-explored for sequence tasks; (3) The RNN-like computational paradigm in\nSNNs prevents parallel training across different timesteps.To address these\nchallenges, this study conducts a systematic analysis of the fundamental\nmechanisms underlying reset operations and refractory periods in\nbinary-activated RNN-based SNN sequence models. We re-examine whether such\nbiological mechanisms are strictly necessary for generating sparse spiking\npatterns, provide new theoretical explanations and insights, and ultimately\npropose the fixed-refractory-period SNN architecture for sequence modeling.",
      "tldr_zh": "本文从SNN作为二值激活RNN的角度出发，探讨了SNN在序列建模中的reset机制。研究指出传统SNN模型在长程序列建模中缺乏有效的记忆机制，且生物启发式组件（如reset机制和不应期）在序列任务中的理论研究不足，同时RNN式的计算范式阻碍了跨时间步的并行训练。为了解决这些问题，本文系统分析了二值激活RNN-based SNN序列模型中reset操作和不应期的基本机制，重新审视了这些生物机制对于生成稀疏脉冲模式的必要性，并提出了新的理论解释和见解，最终提出了用于序列建模的固定不应期SNN架构（fixed-refractory-period SNN architecture）。\n",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17751v1",
      "published_date": "2025-04-24 17:09:59 UTC",
      "updated_date": "2025-04-24 17:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:03:23.673959"
    },
    {
      "arxiv_id": "2504.17721v1",
      "title": "Conformal Segmentation in Industrial Surface Defect Detection with Statistical Guarantees",
      "title_zh": "具有统计保证的工业表面缺陷检测中的保角分割\n",
      "authors": [
        "Cheng Shen",
        "Yuewei Liu"
      ],
      "abstract": "In industrial settings, surface defects on steel can significantly compromise\nits service life and elevate potential safety risks. Traditional defect\ndetection methods predominantly rely on manual inspection, which suffers from\nlow efficiency and high costs. Although automated defect detection approaches\nbased on Convolutional Neural Networks(e.g., Mask R-CNN) have advanced rapidly,\ntheir reliability remains challenged due to data annotation uncertainties\nduring deep model training and overfitting issues. These limitations may lead\nto detection deviations when processing the given new test samples, rendering\nautomated detection processes unreliable. To address this challenge, we first\nevaluate the detection model's practical performance through calibration data\nthat satisfies the independent and identically distributed (i.i.d) condition\nwith test data. Specifically, we define a loss function for each calibration\nsample to quantify detection error rates, such as the complement of recall rate\nand false discovery rate. Subsequently, we derive a statistically rigorous\nthreshold based on a user-defined risk level to identify high-probability\ndefective pixels in test images, thereby constructing prediction sets (e.g.,\ndefect regions). This methodology ensures that the expected error rate (mean\nerror rate) on the test set remains strictly bounced by the predefined risk\nlevel. Additionally, we observe a negative correlation between the average\nprediction set size and the risk level on the test set, establishing a\nstatistically rigorous metric for assessing detection model uncertainty.\nFurthermore, our study demonstrates robust and efficient control over the\nexpected test set error rate across varying calibration-to-test partitioning\nratios, validating the method's adaptability and operational effectiveness.",
      "tldr_zh": "该研究提出了一种用于工业表面缺陷检测的保形分割方法，旨在解决传统缺陷检测方法效率低和基于深度学习的方法可靠性不足的问题。该方法首先使用满足独立同分布(i.i.d)条件的校准数据评估检测模型的性能，并定义损失函数来量化检测错误率。然后，基于用户定义的风险水平，推导出一个统计严格的阈值，以识别测试图像中高概率的缺陷像素，从而构建预测集（缺陷区域）。该方法确保测试集上的预期错误率严格限制在预定义的风险水平内，并建立了一个统计严格的指标来评估检测模型的不确定性。实验结果验证了该方法在不同校准-测试划分比例下的适应性和有效性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.17721v1",
      "published_date": "2025-04-24 16:33:56 UTC",
      "updated_date": "2025-04-24 16:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:03:35.581202"
    },
    {
      "arxiv_id": "2504.17720v1",
      "title": "Multilingual Performance Biases of Large Language Models in Education",
      "title_zh": "大型语言模型在教育领域中的多语言性能偏差\n",
      "authors": [
        "Vansh Gupta",
        "Sankalan Pal Chowdhury",
        "Vilém Zouhar",
        "Donya Rooein",
        "Mrinmaya Sachan"
      ],
      "abstract": "Large language models (LLMs) are increasingly being adopted in educational\nsettings. These applications expand beyond English, though current LLMs remain\nprimarily English-centric. In this work, we ascertain if their use in education\nsettings in non-English languages is warranted. We evaluated the performance of\npopular LLMs on four educational tasks: identifying student misconceptions,\nproviding targeted feedback, interactive tutoring, and grading translations in\nsix languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to\nEnglish. We find that the performance on these tasks somewhat corresponds to\nthe amount of language represented in training data, with lower-resource\nlanguages having poorer task performance. Although the models perform\nreasonably well in most languages, the frequent performance drop from English\nis significant. Thus, we recommend that practitioners first verify that the LLM\nworks well in the target language for their educational task before deployment.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)在教育领域多语言环境下的表现偏差，着重考察了六种非英语语言（印地语、阿拉伯语、波斯语、泰卢固语、乌克兰语、捷克语）在四个教育任务中的表现：识别学生误解、提供针对性反馈、互动辅导和翻译评分。研究发现，模型在这些任务上的表现与训练数据中语言的代表性程度相关，低资源语言的任务表现较差。虽然模型在大多数语言中表现尚可，但与英语相比，性能下降明显。因此，建议从业者在部署LLM之前，先验证其在目标语言中对特定教育任务的适用性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17720v1",
      "published_date": "2025-04-24 16:32:31 UTC",
      "updated_date": "2025-04-24 16:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:03:47.530472"
    },
    {
      "arxiv_id": "2504.17717v1",
      "title": "Early Detection of Multidrug Resistance Using Multivariate Time Series Analysis and Interpretable Patient-Similarity Representations",
      "title_zh": "利用多元时间序列分析和可解释的患者相似性表征进行多药耐药性的早期检测\n",
      "authors": [
        "Óscar Escudero-Arnanz",
        "Antonio G. Marques",
        "Inmaculada Mora-Jiménez",
        "Joaquín Álvarez-Rodríguez",
        "Cristina Soguero-Ruiz"
      ],
      "abstract": "Background and Objectives: Multidrug Resistance (MDR) is a critical global\nhealth issue, causing increased hospital stays, healthcare costs, and\nmortality. This study proposes an interpretable Machine Learning (ML) framework\nfor MDR prediction, aiming for both accurate inference and enhanced\nexplainability.\n  Methods: Patients are modeled as Multivariate Time Series (MTS), capturing\nclinical progression and patient-to-patient interactions. Similarity among\npatients is quantified using MTS-based methods: descriptive statistics, Dynamic\nTime Warping, and Time Cluster Kernel. These similarity measures serve as\ninputs for MDR classification via Logistic Regression, Random Forest, and\nSupport Vector Machines, with dimensionality reduction and kernel\ntransformations improving model performance. For explainability, patient\nsimilarity networks are constructed from these metrics. Spectral clustering and\nt-SNE are applied to identify MDR-related subgroups and visualize high-risk\nclusters, enabling insight into clinically relevant patterns.\n  Results: The framework was validated on ICU Electronic Health Records from\nthe University Hospital of Fuenlabrada, achieving an AUC of 81%. It outperforms\nbaseline ML and deep learning models by leveraging graph-based patient\nsimilarity. The approach identifies key risk factors -- prolonged antibiotic\nuse, invasive procedures, co-infections, and extended ICU stays -- and reveals\nclinically meaningful clusters. Code and results are available at\n\\https://github.com/oscarescuderoarnanz/DM4MTS.\n  Conclusions: Patient similarity representations combined with graph-based\nanalysis provide accurate MDR prediction and interpretable insights. This\nmethod supports early detection, risk factor identification, and patient\nstratification, highlighting the potential of explainable ML in critical care.",
      "tldr_zh": "该研究提出了一种可解释的机器学习框架，用于预测多重耐药性(MDR)。该框架将患者建模为多元时间序列(MTS)，利用描述性统计、动态时间规整(Dynamic Time Warping)和时间聚类核等方法量化患者间的相似性。这些相似性度量被用于Logistic回归、随机森林和支持向量机等模型进行MDR分类。通过构建患者相似性网络，并应用谱聚类和t-SNE算法，识别与MDR相关的亚组和高风险集群。实验结果表明，该框架在ICU电子健康记录上实现了81%的AUC，优于基线模型，并识别出关键风险因素，如长期抗生素使用、侵入性操作等。该方法支持早期检测、风险因素识别和患者分层，突出了可解释机器学习在重症监护中的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17717v1",
      "published_date": "2025-04-24 16:19:13 UTC",
      "updated_date": "2025-04-24 16:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:03:59.733807"
    },
    {
      "arxiv_id": "2504.17703v1",
      "title": "Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence",
      "title_zh": "联邦学习：隐私保护协作智能综述\n",
      "authors": [
        "Edward Collins",
        "Michel Wang"
      ],
      "abstract": "Federated Learning (FL) has emerged as a transformative paradigm in the field\nof distributed machine learning, enabling multiple clients such as mobile\ndevices, edge nodes, or organizations to collaboratively train a shared global\nmodel without the need to centralize sensitive data. This decentralized\napproach addresses growing concerns around data privacy, security, and\nregulatory compliance, making it particularly attractive in domains such as\nhealthcare, finance, and smart IoT systems. This survey provides a concise yet\ncomprehensive overview of Federated Learning, beginning with its core\narchitecture and communication protocol. We discuss the standard FL lifecycle,\nincluding local training, model aggregation, and global updates. A particular\nemphasis is placed on key technical challenges such as handling non-IID\n(non-independent and identically distributed) data, mitigating system and\nhardware heterogeneity, reducing communication overhead, and ensuring privacy\nthrough mechanisms like differential privacy and secure aggregation.\nFurthermore, we examine emerging trends in FL research, including personalized\nFL, cross-device versus cross-silo settings, and integration with other\nparadigms such as reinforcement learning and quantum computing. We also\nhighlight real-world applications and summarize benchmark datasets and\nevaluation metrics commonly used in FL research. Finally, we outline open\nresearch problems and future directions to guide the development of scalable,\nefficient, and trustworthy FL systems.",
      "tldr_zh": "联邦学习(FL)作为一种变革性的分布式机器学习范例，允许多个客户端在不集中敏感数据的情况下协同训练共享的全局模型。该综述概述了FL的核心架构和通信协议，讨论了标准FL生命周期，包括本地训练、模型聚合和全局更新。重点关注了处理非独立同分布(non-IID)数据、缓解系统和硬件异构性、减少通信开销以及通过差分隐私和安全聚合等机制确保隐私的关键技术挑战。此外，还探讨了FL研究的新兴趋势，包括个性化FL、跨设备与跨孤岛设置，以及与其他范例（如强化学习和量子计算）的集成。最后，概述了开放的研究问题和未来方向，以指导可扩展、高效和可信的FL系统的开发。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17703v1",
      "published_date": "2025-04-24 16:10:29 UTC",
      "updated_date": "2025-04-24 16:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:04:11.548221"
    },
    {
      "arxiv_id": "2504.17696v1",
      "title": "Hierarchical and Multimodal Data for Daily Activity Understanding",
      "title_zh": "用于日常活动理解的分层和多模态数据",
      "authors": [
        "Ghazal Kaviani",
        "Yavuz Yarici",
        "Seulgi Kim",
        "Mohit Prabhushankar",
        "Ghassan AlRegib",
        "Mashhour Solh",
        "Ameya Patil"
      ],
      "abstract": "Daily Activity Recordings for Artificial Intelligence (DARai, pronounced\n\"Dahr-ree\") is a multimodal, hierarchically annotated dataset constructed to\nunderstand human activities in real-world settings. DARai consists of\ncontinuous scripted and unscripted recordings of 50 participants in 10\ndifferent environments, totaling over 200 hours of data from 20 sensors\nincluding multiple camera views, depth and radar sensors, wearable inertial\nmeasurement units (IMUs), electromyography (EMG), insole pressure sensors,\nbiomonitor sensors, and gaze tracker.\n  To capture the complexity in human activities, DARai is annotated at three\nlevels of hierarchy: (i) high-level activities (L1) that are independent tasks,\n(ii) lower-level actions (L2) that are patterns shared between activities, and\n(iii) fine-grained procedures (L3) that detail the exact execution steps for\nactions. The dataset annotations and recordings are designed so that 22.7% of\nL2 actions are shared between L1 activities and 14.2% of L3 procedures are\nshared between L2 actions. The overlap and unscripted nature of DARai allows\ncounterfactual activities in the dataset.\n  Experiments with various machine learning models showcase the value of DARai\nin uncovering important challenges in human-centered applications.\nSpecifically, we conduct unimodal and multimodal sensor fusion experiments for\nrecognition, temporal localization, and future action anticipation across all\nhierarchical annotation levels. To highlight the limitations of individual\nsensors, we also conduct domain-variant experiments that are enabled by DARai's\nmulti-sensor and counterfactual activity design setup.\n  The code, documentation, and dataset are available at the dedicated DARai\nwebsite:\nhttps://alregib.ece.gatech.edu/software-and-datasets/darai-daily-activity-recordings-for-artificial-intelligence-and-machine-learning/",
      "tldr_zh": "该论文介绍了Daily Activity Recordings for Artificial Intelligence (DARai)数据集，这是一个多模态、分层标注的数据集，旨在理解真实场景下的人类活动。DARai包含50名参与者在10个不同环境中超过200小时的连续记录，数据来自20个传感器，包括多个摄像头、深度和雷达传感器、可穿戴IMU、EMG、鞋垫压力传感器、生物监测传感器和眼动追踪器。数据集在三个层次上进行标注：高层活动(L1)、低层动作(L2)和细粒度程序(L3)，旨在捕捉人类活动的复杂性。通过在不同层次上共享动作和程序，DARai允许数据集中的反事实活动。论文通过实验展示了DARai在人体中心应用中的价值，包括识别、时间定位和未来动作预测，并突出了各个传感器的局限性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17696v1",
      "published_date": "2025-04-24 16:04:00 UTC",
      "updated_date": "2025-04-24 16:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:04:23.976802"
    },
    {
      "arxiv_id": "2504.17685v1",
      "title": "Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks",
      "title_zh": "集成贝叶斯推断：利用小型语言模型在个人资料匹配任务中实现 LLM 级别的准确率\n",
      "authors": [
        "Haru-Tada Sato",
        "Fuka Matsuzaki",
        "Jun-ichiro Takahashi"
      ],
      "abstract": "This study explores the potential of small language model(SLM) ensembles to\nachieve accuracy comparable to proprietary large language models (LLMs). We\npropose Ensemble Bayesian Inference (EBI), a novel approach that applies\nBayesian estimation to combine judgments from multiple SLMs, allowing them to\nexceed the performance limitations of individual models. Our experiments on\ndiverse tasks(aptitude assessments and consumer profile analysis in both\nJapanese and English) demonstrate EBI's effectiveness. Notably, we analyze\ncases where incorporating models with negative Lift values into ensembles\nimproves overall performance, and we examine the method's efficacy across\ndifferent languages. These findings suggest new possibilities for constructing\nhigh-performance AI systems with limited computational resources and for\neffectively utilizing models with individually lower performance. Building on\nexisting research on LLM performance evaluation, ensemble methods, and\nopen-source LLM utilization, we discuss the novelty and significance of our\napproach.",
      "tldr_zh": "该研究提出了一种名为Ensemble Bayesian Inference (EBI)的新方法，利用贝叶斯估计组合多个小型语言模型(SLM)的判断，以达到与大型语言模型(LLM)相媲美的准确率，尤其是在profile matching任务中。通过在日语和英语的各种任务（包括能力评估和消费者profile分析）上的实验，证明了EBI的有效性。研究发现，即使包含具有负Lift值的模型，集成也能提高整体性能。该方法为构建具有有限计算资源的高性能AI系统以及有效利用个体性能较低的模型提供了新的可能性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.17685v1",
      "published_date": "2025-04-24 15:55:10 UTC",
      "updated_date": "2025-04-24 15:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:04:35.492341"
    },
    {
      "arxiv_id": "2504.17677v1",
      "title": "INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models",
      "title_zh": "INSIGHT：弥合大语言模型时代师生之间的差距\n",
      "authors": [
        "Jarne Thys",
        "Sebe Vanbrabant",
        "Davy Vanacken",
        "Gustavo Rovelo Ruiz"
      ],
      "abstract": "The rise of AI, especially Large Language Models, presents challenges and\nopportunities to integrate such technology into the classroom. AI has the\npotential to revolutionize education by helping teaching staff with various\ntasks, such as personalizing their teaching methods, but it also raises\nconcerns, for example, about the degradation of student-teacher interactions\nand user privacy. This paper introduces INSIGHT, a proof of concept to combine\nvarious AI tools to assist teaching staff and students in the process of\nsolving exercises. INSIGHT has a modular design that allows it to be integrated\ninto various higher education courses. We analyze students' questions to an LLM\nby extracting keywords, which we use to dynamically build an FAQ from students'\nquestions and provide new insights for the teaching staff to use for more\npersonalized face-to-face support. Future work could build upon INSIGHT by\nusing the collected data to provide adaptive learning and adjust content based\non student progress and learning styles to offer a more interactive and\ninclusive learning experience.",
      "tldr_zh": "INSIGHT是一个概念验证系统，旨在弥合大型语言模型(LLM)时代师生之间的差距，将AI工具集成到课堂中辅助教学。该系统通过分析学生向LLM提出的问题，提取关键词，并动态构建FAQ，为教学人员提供新的见解，以便进行更个性化的面对面支持。INSIGHT采用模块化设计，可以集成到各种高等教育课程中。未来的工作可以利用收集到的数据提供自适应学习，并根据学生的进步和学习方式调整内容，从而提供更具互动性和包容性的学习体验。该研究探索了AI在教育领域的应用潜力，旨在帮助教学人员个性化教学方法，同时关注学生与教师互动和用户隐私等问题。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17677v1",
      "published_date": "2025-04-24 15:47:20 UTC",
      "updated_date": "2025-04-24 15:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:04:47.669024"
    },
    {
      "arxiv_id": "2504.17675v1",
      "title": "Optimized Cloud Resource Allocation Using Genetic Algorithms for Energy Efficiency and QoS Assurance",
      "title_zh": "基于遗传算法的优化云资源分配，以实现能源效率和 QoS 保障\n",
      "authors": [
        "Caroline Panggabean",
        "Devaraj Verma C",
        "Bhagyashree Gogoi",
        "Ranju Limbu",
        "Rhythm Sarker"
      ],
      "abstract": "Cloud computing environments demand dynamic and efficient resource management\nto ensure optimal performance, reduced energy consumption, and adherence to\nService Level Agreements (SLAs). This paper presents a Genetic Algorithm\n(GA)-based approach for Virtual Machine (VM) placement and consolidation,\naiming to minimize power usage while maintaining QoS constraints. The proposed\nmethod dynamically adjusts VM allocation based on real-time workload\nvariations, outperforming traditional heuristics such as First Fit Decreasing\n(FFD) and Best Fit Decreasing (BFD). Experimental results show notable\nreductions in energy consumption, VM migrations, SLA violation rates, and\nexecution time. A correlation heatmap further illustrates strong relationships\namong these key performance indicators, confirming the effectiveness of our\napproach in optimizing cloud resource utilization.",
      "tldr_zh": "本文提出了一种基于遗传算法(GA)的虚拟机(VM)放置和整合方法，用于优化云资源分配，目标是在保证服务质量(QoS)的前提下，最小化能源消耗。该方法能够根据实时工作负载动态调整VM分配，性能优于传统的FFD和BFD等启发式算法。实验结果表明，该方法在降低能耗、VM迁移次数、SLA违约率和执行时间方面均有显著效果。相关性热图进一步验证了关键性能指标之间的强相关性，证实了该方法在优化云资源利用率方面的有效性。\n",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "7 pages, 5 figures, accepted for publication (not yet published)",
      "pdf_url": "http://arxiv.org/pdf/2504.17675v1",
      "published_date": "2025-04-24 15:45:40 UTC",
      "updated_date": "2025-04-24 15:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:04:59.480181"
    },
    {
      "arxiv_id": "2504.17671v1",
      "title": "Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction",
      "title_zh": "基于归纳共形预测的大型视觉-语言模型中预测集的数据驱动校准\n",
      "authors": [
        "Yuanchang Ye",
        "Weiyan Wen"
      ],
      "abstract": "This study addresses the critical challenge of hallucination mitigation in\nLarge Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks\nthrough a Split Conformal Prediction (SCP) framework. While LVLMs excel in\nmulti-modal reasoning, their outputs often exhibit hallucinated content with\nhigh confidence, posing risks in safety-critical applications. We propose a\nmodel-agnostic uncertainty quantification method that integrates dynamic\nthreshold calibration and cross-modal consistency verification. By partitioning\ndata into calibration and test sets, the framework computes nonconformity\nscores to construct prediction sets with statistical guarantees under\nuser-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous\ncontrol of \\textbf{marginal coverage} to ensure empirical error rates remain\nstrictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes\ninversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of\nprior distribution assumptions and retraining requirements. Evaluations on\nbenchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces\ntheoretical guarantees across all $\\alpha$ values. The framework achieves\nstable performance across varying calibration-to-test split ratios,\nunderscoring its robustness for real-world deployment in healthcare, autonomous\nsystems, and other safety-sensitive domains. This work bridges the gap between\ntheoretical reliability and practical applicability in multi-modal AI systems,\noffering a scalable solution for hallucination detection and uncertainty-aware\ndecision-making.",
      "tldr_zh": "该研究提出了一种基于Split Conformal Prediction (SCP)框架的数据驱动校准方法，用于解决大型视觉语言模型(LVLMs)在视觉问答(VQA)任务中的幻觉问题。该方法通过计算非一致性分数来构建预测集，并在用户定义的风险水平($\\alpha$)下提供统计保证。关键创新包括：严格控制**边缘覆盖率(marginal coverage)**，动态调整预测集大小，以及无需先验分布假设和重新训练。在ScienceQA和MMMU等基准测试中，使用八个LVLM的评估表明，SCP在所有$\\alpha$值上都强制执行理论保证，为医疗保健、自动驾驶系统等安全敏感领域的实际部署提供了稳健的解决方案。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17671v1",
      "published_date": "2025-04-24 15:39:46 UTC",
      "updated_date": "2025-04-24 15:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:05:11.781806"
    },
    {
      "arxiv_id": "2504.17669v1",
      "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare",
      "title_zh": "构建符合 HIPAA 标准的医疗 Agentic AI 系统\n",
      "authors": [
        "Subash Neupane",
        "Shaswata Mitra",
        "Sudip Mittal",
        "Shahram Rahimi"
      ],
      "abstract": "Agentic AI systems powered by Large Language Models (LLMs) as their\nfoundational reasoning engine, are transforming clinical workflows such as\nmedical report generation and clinical summarization by autonomously analyzing\nsensitive healthcare data and executing decisions with minimal human oversight.\nHowever, their adoption demands strict compliance with regulatory frameworks\nsuch as Health Insurance Portability and Accountability Act (HIPAA),\nparticularly when handling Protected Health Information (PHI). This\nwork-in-progress paper introduces a HIPAA-compliant Agentic AI framework that\nenforces regulatory compliance through dynamic, context-aware policy\nenforcement. Our framework integrates three core mechanisms: (1)\nAttribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid\nPHI sanitization pipeline combining regex patterns and BERT-based model to\nminimize leakage, and (3) immutable audit trails for compliance verification.",
      "tldr_zh": "该论文提出了一个符合HIPAA标准的Agentic AI框架，旨在解决大型语言模型(LLMs)驱动的智能体AI系统在医疗保健领域应用时，处理受保护健康信息(PHI)的合规性问题。该框架通过动态、上下文感知的策略执行来强制执行监管合规性，集成了三个核心机制：基于属性的访问控制(ABAC)用于细粒度的PHI治理，结合正则表达式和基于BERT模型的混合PHI清理管道以最小化泄露，以及用于合规性验证的不可变审计跟踪。该框架旨在为医疗报告生成和临床总结等临床工作流程提供安全可靠的AI解决方案。\n",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17669v1",
      "published_date": "2025-04-24 15:38:20 UTC",
      "updated_date": "2025-04-24 15:38:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:05:23.754137"
    },
    {
      "arxiv_id": "2504.17663v1",
      "title": "The Malicious Technical Ecosystem: Exposing Limitations in Technical Governance of AI-Generated Non-Consensual Intimate Images of Adults",
      "title_zh": "恶意技术生态系统：揭示人工智能生成成人非自愿私密图像技术治理的局限性\n",
      "authors": [
        "Michelle L. Ding",
        "Harini Suresh"
      ],
      "abstract": "In this paper, we adopt a survivor-centered approach to locate and dissect\nthe role of sociotechnical AI governance in preventing AI-Generated\nNon-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as\n\"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or\n\"MTE,\" comprising of open-source face-swapping models and nearly 200\n\"nudifying\" software programs that allow non-technical users to create AIG-NCII\nwithin minutes. Then, using the National Institute of Standards and Technology\n(NIST) AI 100-4 report as a reflection of current synthetic content governance\nmethods, we show how the current landscape of practices fails to effectively\nregulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining\nthese gaps.",
      "tldr_zh": "本文以受害者为中心，探讨了社会技术AI治理在预防AI生成的成人非自愿私密图像(AIG-NCII)，即“deep fake pornography”方面的作用和局限性。研究揭示了一个“恶意技术生态系统”(MTE)，该生态系统由开源换脸模型和近200个“nudifying”软件组成，使得非技术用户也能快速生成AIG-NCII。通过分析美国国家标准与技术研究院(NIST) AI 100-4报告，研究表明当前的合成内容治理方法未能有效监管成人AIG-NCII的MTE，并指出了造成这些差距的错误假设。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17663v1",
      "published_date": "2025-04-24 15:31:46 UTC",
      "updated_date": "2025-04-24 15:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:05:35.799529"
    },
    {
      "arxiv_id": "2504.17655v1",
      "title": "Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction",
      "title_zh": "基于共形预测的稀缺和无约束环境下的航空图像分类",
      "authors": [
        "Farhad Pourkamali-Anaraki"
      ],
      "abstract": "This paper presents a comprehensive empirical analysis of conformal\nprediction methods on a challenging aerial image dataset featuring diverse\nevents in unconstrained environments. Conformal prediction is a powerful\npost-hoc technique that takes the output of any classifier and transforms it\ninto a set of likely labels, providing a statistical guarantee on the coverage\nof the true label. Unlike evaluations on standard benchmarks, our study\naddresses the complexities of data-scarce and highly variable real-world\nsettings. We investigate the effectiveness of leveraging pretrained models\n(MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to\ngenerate informative prediction sets. To further evaluate the impact of\ncalibration, we consider two parallel pipelines (with and without temperature\nscaling) and assess performance using two key metrics: empirical coverage and\naverage prediction set size. This setup allows us to systematically examine how\ncalibration choices influence the trade-off between reliability and efficiency.\nOur findings demonstrate that even with relatively small labeled samples and\nsimple nonconformity scores, conformal prediction can yield valuable\nuncertainty estimates for complex tasks. Moreover, our analysis reveals that\nwhile temperature scaling is often employed for calibration, it does not\nconsistently lead to smaller prediction sets, underscoring the importance of\ncareful consideration in its application. Furthermore, our results highlight\nthe significant potential of model compression techniques within the conformal\nprediction pipeline for deployment in resource-constrained environments. Based\non our observations, we advocate for future research to delve into the impact\nof noisy or ambiguous labels on conformal prediction performance and to explore\neffective model reduction strategies.",
      "tldr_zh": "本文对共形预测(Conformal Prediction)方法在稀缺和非约束环境下航拍图像分类任务上进行了全面的实证分析。该研究利用预训练模型（MobileNet, DenseNet, ResNet）在有限标记数据上进行微调，并结合共形预测技术生成包含多个可能标签的预测集合，从而提供真实标签覆盖率的统计保证。研究对比了使用和不使用温度缩放(Temperature Scaling)的两种校准方法，并使用经验覆盖率和平均预测集合大小作为评估指标。结果表明，即使在小样本情况下，共形预测也能为复杂任务提供有价值的不确定性估计，且温度缩放并不总是能缩小预测集合的大小。此外，研究还强调了模型压缩技术在资源受限环境中部署共形预测的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures, and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.17655v1",
      "published_date": "2025-04-24 15:25:37 UTC",
      "updated_date": "2025-04-24 15:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:05:47.981320"
    },
    {
      "arxiv_id": "2504.17641v1",
      "title": "PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph",
      "title_zh": "PTCL：面向标签受限动态图的伪标签时间课程学习",
      "authors": [
        "Shengtao Zhang",
        "Haokai Zhang",
        "Shiqi Lou",
        "Zicheng Wang",
        "Zinan Zeng",
        "Yilin Wang",
        "Minnan Luo"
      ],
      "abstract": "Dynamic node classification is critical for modeling evolving systems like\nfinancial transactions and academic collaborations. In such systems,\ndynamically capturing node information changes is critical for dynamic node\nclassification, which usually requires all labels at every timestamp. However,\nit is difficult to collect all dynamic labels in real-world scenarios due to\nhigh annotation costs and label uncertainty (e.g., ambiguous or delayed labels\nin fraud detection). In contrast, final timestamp labels are easier to obtain\nas they rely on complete temporal patterns and are usually maintained as a\nunique label for each user in many open platforms, without tracking the history\ndata. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum\nLearning), a pioneering method addressing label-limited dynamic node\nclassification where only final labels are available. PTCL introduces: (1) a\ntemporal decoupling architecture separating the backbone (learning time-aware\nrepresentations) and decoder (strictly aligned with final labels), which\ngenerate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that\nprioritizes pseudo-labels closer to the final timestamp by assigning them\nhigher weights using an exponentially decaying function. We contribute a new\nacademic dataset (CoOAG), capturing long-range research interest in dynamic\ngraph. Experiments across real-world scenarios demonstrate PTCL's consistent\nsuperiority over other methods adapted to this task. Beyond methodology, we\npropose a unified framework FLiD (Framework for Label-Limited Dynamic Node\nClassification), consisting of a complete preparation workflow, training\npipeline, and evaluation standards, and supporting various models and datasets.\nThe code can be found at https://github.com/3205914485/FLiD.",
      "tldr_zh": "本文提出了一种伪标签时间课程学习(PTCL)方法，用于解决标签受限的动态图节点分类问题，即只有最终时间戳的标签可用。PTCL包含一个时间解耦架构，将骨干网络（学习时间感知表示）和解码器（与最终标签严格对齐）分离，以生成伪标签。同时，采用时间课程学习策略，通过指数衰减函数为更接近最终时间戳的伪标签分配更高的权重。作者还构建了一个新的学术数据集CoOAG，用于捕捉动态图中长期的研究兴趣。实验结果表明，PTCL在真实场景中优于其他方法。此外，作者提出了一个统一的框架FLiD，包含完整的准备工作流程、训练流程和评估标准，支持各种模型和数据集。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17641v1",
      "published_date": "2025-04-24 15:11:41 UTC",
      "updated_date": "2025-04-24 15:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:05:59.756418"
    },
    {
      "arxiv_id": "2504.17624v1",
      "title": "Deciphering the unique dynamic activation pathway in a G protein-coupled receptor enables unveiling biased signaling and identifying cryptic allosteric sites in conformational intermediates",
      "title_zh": "破译 G 蛋白偶联受体中独特的动态激活通路，从而揭示偏向性信号传导并识别构象中间体中的隐秘变构位点\n",
      "authors": [
        "Jigang Fan",
        "Chunhao Zhu",
        "Xiaobing Lan",
        "Haiming Zhuang",
        "Mingyu Li",
        "Jian Zhang",
        "Shaoyong Lu"
      ],
      "abstract": "Neurotensin receptor 1 (NTSR1), a member of the Class A G protein-coupled\nreceptor superfamily, plays an important role in modulating dopaminergic\nneuronal activity and eliciting opioid-independent analgesia. Recent studies\nsuggest that promoting \\{beta}-arrestin-biased signaling in NTSR1 may diminish\ndrugs of abuse, such as psychostimulants, thereby offering a potential avenue\nfor treating human addiction-related disorders. In this study, we utilized a\nnovel computational and experimental approach that combined nudged elastic\nband-based molecular dynamics simulations, Markov state models, temporal\ncommunication network analysis, site-directed mutagenesis, and conformational\nbiosensors, to explore the intricate mechanisms underlying NTSR1 activation and\nbiased signaling. Our study reveals a dynamic stepwise transition mechanism and\nactivated transmission network associated with NTSR1 activation. It also yields\nvaluable insights into the complex interplay between the unique polar network,\nnon-conserved ion locks, and aromatic clusters in NTSR1 signaling. Moreover, we\nidentified a cryptic allosteric site located in the intracellular region of the\nreceptor that exists in an intermediate state within the activation pathway.\nCollectively, these findings contribute to a more profound understanding of\nNTSR1 activation and biased signaling at the atomic level, thereby providing a\npotential strategy for the development of NTSR1 allosteric modulators in the\nrealm of G protein-coupled receptor biology, biophysics, and medicine.",
      "tldr_zh": "该研究利用计算和实验相结合的方法，包括分子动力学模拟、马尔可夫状态模型等，揭示了神经降压素受体1 (NTSR1) 激活和偏向性信号传导的动态逐步过渡机制。研究揭示了NTSR1中独特的极性网络、非保守离子锁和芳香簇之间的复杂相互作用，并识别了位于细胞内区域的隐秘变构位点，该位点存在于激活途径的中间状态。这些发现为深入理解NTSR1的激活和偏向性信号传导提供了原子级别的见解，并为开发NTSR1变构调节剂提供了潜在策略，应用于G蛋白偶联受体生物学、生物物理学和医学领域。\n",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17624v1",
      "published_date": "2025-04-24 14:46:20 UTC",
      "updated_date": "2025-04-24 14:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:06:11.789611"
    },
    {
      "arxiv_id": "2504.17619v1",
      "title": "Enhancing CNNs robustness to occlusions with bioinspired filters for border completion",
      "title_zh": "利用生物启发式滤波器进行边界补全，增强 CNN 对遮挡的鲁棒性\n",
      "authors": [
        "Catarina P. Coutinho",
        "Aneeqa Merhab",
        "Janko Petkovic",
        "Ferdinando Zanchetta",
        "Rita Fioresi"
      ],
      "abstract": "We exploit the mathematical modeling of the visual cortex mechanism for\nborder completion to define custom filters for CNNs. We see a consistent\nimprovement in performance, particularly in accuracy, when our modified LeNet 5\nis tested with occluded MNIST images.",
      "tldr_zh": "该论文利用视觉皮层边界补全机制的数学模型，为CNNs设计定制滤波器，旨在提高CNNs对遮挡的鲁棒性。通过在被遮挡的MNIST图像上测试改进后的LeNet 5，实验结果表明，该方法在准确率方面取得了显著的性能提升。该研究为提升CNNs在复杂视觉环境下的可靠性提供了一种新的生物启发式方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to the 7th International Conference on Geometric Science of\n  Information",
      "pdf_url": "http://arxiv.org/pdf/2504.17619v1",
      "published_date": "2025-04-24 14:43:55 UTC",
      "updated_date": "2025-04-24 14:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:06:23.402136"
    },
    {
      "arxiv_id": "2504.17617v1",
      "title": "Decentralized Time Series Classification with ROCKET Features",
      "title_zh": "基于 ROCKET 特征的去中心化时间序列分类\n",
      "authors": [
        "Bruno Casella",
        "Matthias Jakobs",
        "Marco Aldinucci",
        "Sebastian Buschjäger"
      ],
      "abstract": "Time series classification (TSC) is a critical task with applications in\nvarious domains, including healthcare, finance, and industrial monitoring. Due\nto privacy concerns and data regulations, Federated Learning has emerged as a\npromising approach for learning from distributed time series data without\ncentralizing raw information. However, most FL solutions rely on a\nclient-server architecture, which introduces robustness and confidentiality\nrisks related to the distinguished role of the server, which is a single point\nof failure and can observe knowledge extracted from clients. To address these\nchallenges, we propose DROCKS, a fully decentralized FL framework for TSC that\nleverages ROCKET (RandOm Convolutional KErnel Transform) features. In DROCKS,\nthe global model is trained by sequentially traversing a structured path across\nfederation nodes, where each node refines the model and selects the most\neffective local kernels before passing them to the successor. Extensive\nexperiments on the UCR archive demonstrate that DROCKS outperforms\nstate-of-the-art client-server FL approaches while being more resilient to node\nfailures and malicious attacks. Our code is available at\nhttps://anonymous.4open.science/r/DROCKS-7FF3/README.md.",
      "tldr_zh": "该论文提出了一种完全去中心化的联邦学习框架DROCKS，用于时间序列分类(TSC)。DROCKS利用ROCKET (RandOm Convolutional KErnel Transform) 特征，通过在联邦节点间顺序传递并优化模型，避免了传统client-server架构中存在的单点故障和隐私泄露风险。每个节点在传递前会提炼模型并选择最有效的局部kernels。在UCR数据集上的大量实验表明，DROCKS在性能上优于现有的client-server联邦学习方法，并具有更强的节点故障和恶意攻击抵抗能力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.11; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Workshop on Federated Learning Advancements 2025, in\n  conjunction with ECML-PKDD, WAFL25",
      "pdf_url": "http://arxiv.org/pdf/2504.17617v1",
      "published_date": "2025-04-24 14:41:50 UTC",
      "updated_date": "2025-04-24 14:41:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:06:35.663095"
    },
    {
      "arxiv_id": "2504.17609v1",
      "title": "STCL:Curriculum learning Strategies for deep learning image steganography models",
      "title_zh": "STCL：用于深度学习图像隐写模型的课程学习策略\n",
      "authors": [
        "Fengchun Liu",
        "Tong Zhang",
        "Chunying Zhang"
      ],
      "abstract": "Aiming at the problems of poor quality of steganographic images and slow\nnetwork convergence of image steganography models based on deep learning, this\npaper proposes a Steganography Curriculum Learning training strategy (STCL) for\ndeep learning image steganography models. So that only easy images are selected\nfor training when the model has poor fitting ability at the initial stage, and\ngradually expand to more difficult images, the strategy includes a difficulty\nevaluation strategy based on the teacher model and an knee point-based training\nscheduling strategy. Firstly, multiple teacher models are trained, and the\nconsistency of the quality of steganographic images under multiple teacher\nmodels is used as the difficulty score to construct the training subsets from\neasy to difficult. Secondly, a training control strategy based on knee points\nis proposed to reduce the possibility of overfitting on small training sets and\naccelerate the training process. Experimental results on three large public\ndatasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image\nsteganography scheme is able to improve the model performance under multiple\nalgorithmic frameworks, which not only has a high PSNR, SSIM score, and\ndecoding accuracy, but also the steganographic images generated by the model\nunder the training of the STCL strategy have a low steganography analysis\nscores. You can find our code at\n\\href{https://github.com/chaos-boops/STCL}{https://github.com/chaos-boops/STCL}.",
      "tldr_zh": "本文针对深度学习图像隐写模型中隐写图像质量差和网络收敛慢的问题，提出了一种隐写课程学习训练策略(STCL)。该策略包括基于教师模型的难度评估策略和基于膝点(knee point)的训练调度策略，旨在使模型在初始阶段仅选择容易的图像进行训练，并逐渐扩展到更难的图像。首先，训练多个教师模型，并使用多个教师模型下隐写图像质量的一致性作为难度评分，构建从易到难的训练子集。其次，提出了一种基于膝点的训练控制策略，以减少在小训练集上过拟合的可能性，并加速训练过程。在ALASKA2、VOC2012和ImageNet三个大型公共数据集上的实验结果表明，所提出的图像隐写方案能够提高多个算法框架下的模型性能，不仅具有较高的PSNR、SSIM评分和解码精度，而且在STCL策略训练下，模型生成的隐写图像具有较低的隐写分析评分。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17609v1",
      "published_date": "2025-04-24 14:34:41 UTC",
      "updated_date": "2025-04-24 14:34:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:06:48.047040"
    },
    {
      "arxiv_id": "2504.17551v1",
      "title": "Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior",
      "title_zh": "基于街景对比聚类和地理先验的无监督城市土地利用绘图\n",
      "authors": [
        "Lin Che",
        "Yizi Chen",
        "Tanhua Jin",
        "Martin Raubal",
        "Konrad Schindler",
        "Peter Kiefer"
      ],
      "abstract": "Urban land use classification and mapping are critical for urban planning,\nresource management, and environmental monitoring. Existing remote sensing\ntechniques often lack precision in complex urban environments due to the\nabsence of ground-level details. Unlike aerial perspectives, street view images\nprovide a ground-level view that captures more human and social activities\nrelevant to land use in complex urban scenes. Existing street view-based\nmethods primarily rely on supervised classification, which is challenged by the\nscarcity of high-quality labeled data and the difficulty of generalizing across\ndiverse urban landscapes. This study introduces an unsupervised contrastive\nclustering model for street view images with a built-in geographical prior, to\nenhance clustering performance. When combined with a simple visual assignment\nof the clusters, our approach offers a flexible and customizable solution to\nland use mapping, tailored to the specific needs of urban planners. We\nexperimentally show that our method can generate land use maps from geotagged\nstreet view image datasets of two cities. As our methodology relies on the\nuniversal spatial coherence of geospatial data (\"Tobler's law\"), it can be\nadapted to various settings where street view images are available, to enable\nscalable, unsupervised land use mapping and updating. The code will be\navailable at https://github.com/lin102/CCGP.",
      "tldr_zh": "该研究提出了一种基于街景图像的无监督城市土地利用制图方法，旨在解决现有遥感技术在复杂城市环境中精度不足以及缺乏高质量标注数据的问题。该方法结合了街景对比聚类模型和地理先验知识，提升了聚类性能。通过简单的视觉分配，该方法能够生成灵活且可定制的土地利用地图。实验结果表明，该方法能够利用带有地理标签的街景图像数据集生成两个城市的土地利用地图。该方法依赖于地理空间数据的普遍空间一致性（“托布勒定律”），因此可以适用于各种街景图像可用的环境，从而实现可扩展的无监督土地利用制图和更新。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures, preprint version",
      "pdf_url": "http://arxiv.org/pdf/2504.17551v1",
      "published_date": "2025-04-24 13:41:27 UTC",
      "updated_date": "2025-04-24 13:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:06:59.845588"
    },
    {
      "arxiv_id": "2504.17550v1",
      "title": "HalluLens: LLM Hallucination Benchmark",
      "title_zh": "HalluLens：LLM幻觉基准测试",
      "authors": [
        "Yejin Bang",
        "Ziwei Ji",
        "Alan Schelten",
        "Anthony Hartshorn",
        "Tara Fowler",
        "Cheng Zhang",
        "Nicola Cancedda",
        "Pascale Fung"
      ],
      "abstract": "Large language models (LLMs) often generate responses that deviate from user\ninput or training data, a phenomenon known as \"hallucination.\" These\nhallucinations undermine user trust and hinder the adoption of generative AI\nsystems. Addressing hallucinations is essential for the advancement of LLMs.\nThis paper introduces a comprehensive hallucination benchmark, incorporating\nboth new extrinsic and existing intrinsic evaluation tasks, built upon clear\ntaxonomy of hallucination. A major challenge in benchmarking hallucinations is\nthe lack of a unified framework due to inconsistent definitions and\ncategorizations. We disentangle LLM hallucination from \"factuality,\" proposing\na clear taxonomy that distinguishes between extrinsic and intrinsic\nhallucinations, to promote consistency and facilitate research. Extrinsic\nhallucinations, where the generated content is not consistent with the training\ndata, are increasingly important as LLMs evolve. Our benchmark includes dynamic\ntest set generation to mitigate data leakage and ensure robustness against such\nleakage. We also analyze existing benchmarks, highlighting their limitations\nand saturation. The work aims to: (1) establish a clear taxonomy of\nhallucinations, (2) introduce new extrinsic hallucination tasks, with data that\ncan be dynamically regenerated to prevent saturation by leakage, (3) provide a\ncomprehensive analysis of existing benchmarks, distinguishing them from\nfactuality evaluations.",
      "tldr_zh": "该论文提出了一个全面的LLM幻觉基准测试HalluLens，旨在解决LLM中普遍存在的幻觉问题，即生成内容与用户输入或训练数据不一致的现象。HalluLens通过明确的幻觉分类体系，区分了外在幻觉和内在幻觉，并引入了新的外在幻觉任务，这些任务的数据可以动态生成以防止数据泄露。该基准测试还分析了现有基准测试的局限性和饱和度，旨在建立清晰的幻觉分类，并促进对LLM幻觉现象的研究和评估。HalluLens的重点在于评估外在幻觉，即生成内容与训练数据不一致的情况，这对于LLM的发展至关重要。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "42 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.17550v1",
      "published_date": "2025-04-24 13:40:27 UTC",
      "updated_date": "2025-04-24 13:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:07:11.851657"
    },
    {
      "arxiv_id": "2504.17544v1",
      "title": "Auditing the Ethical Logic of Generative AI Models",
      "title_zh": "审核生成式 AI 模型的伦理逻辑\n",
      "authors": [
        "W. Russell Neuman",
        "Chad Coleman",
        "Ali Dasdan",
        "Safinah Ali",
        "Manan Shah"
      ],
      "abstract": "As generative AI models become increasingly integrated into high-stakes\ndomains, the need for robust methods to evaluate their ethical reasoning\nbecomes increasingly important. This paper introduces a five-dimensional audit\nmodel -- assessing Analytic Quality, Breadth of Ethical Considerations, Depth\nof Explanation, Consistency, and Decisiveness -- to evaluate the ethical logic\nof leading large language models (LLMs). Drawing on traditions from applied\nethics and higher-order thinking, we present a multi-battery prompt approach,\nincluding novel ethical dilemmas, to probe the models' reasoning across diverse\ncontexts. We benchmark seven major LLMs finding that while models generally\nconverge on ethical decisions, they vary in explanatory rigor and moral\nprioritization. Chain-of-Thought prompting and reasoning-optimized models\nsignificantly enhance performance on our audit metrics. This study introduces a\nscalable methodology for ethical benchmarking of AI systems and highlights the\npotential for AI to complement human moral reasoning in complex decision-making\ncontexts.",
      "tldr_zh": "该论文提出了一种五维审计模型，用于评估生成式AI模型在伦理推理方面的表现。该模型从分析质量、伦理考量的广度、解释的深度、一致性和果断性五个维度，对大型语言模型(LLMs)的伦理逻辑进行评估。研究采用多组提示方法，包括新颖的伦理困境，以测试模型在不同情境下的推理能力。对七个主流LLM的基准测试表明，模型在伦理决策上趋于一致，但在解释的严谨性和道德优先级方面存在差异。链式思维(Chain-of-Thought)提示和推理优化模型显著提高了审计指标的性能。该研究为AI系统的伦理基准测试提供了一种可扩展的方法，并强调了AI在复杂决策环境中补充人类道德推理的潜力。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17544v1",
      "published_date": "2025-04-24 13:32:30 UTC",
      "updated_date": "2025-04-24 13:32:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:07:23.896975"
    },
    {
      "arxiv_id": "2504.17540v1",
      "title": "An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm",
      "title_zh": "一种可解释的猴痘诊断自然启发式框架：Xception 特征结合 NGBoost 和非洲秃鹫优化算法\n",
      "authors": [
        "Ahmadreza Shateri",
        "Negar Nourani",
        "Morteza Dorrigiv",
        "Hamid Nasiri"
      ],
      "abstract": "The recent global spread of monkeypox, particularly in regions where it has\nnot historically been prevalent, has raised significant public health concerns.\nEarly and accurate diagnosis is critical for effective disease management and\ncontrol. In response, this study proposes a novel deep learning-based framework\nfor the automated detection of monkeypox from skin lesion images, leveraging\nthe power of transfer learning, dimensionality reduction, and advanced machine\nlearning techniques. We utilize the newly developed Monkeypox Skin Lesion\nDataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to\ntrain and evaluate our models. The proposed framework employs the Xception\narchitecture for deep feature extraction, followed by Principal Component\nAnalysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting\n(NGBoost) algorithm for classification. To optimize the model's performance and\ngeneralization, we introduce the African Vultures Optimization Algorithm (AVOA)\nfor hyperparameter tuning, ensuring efficient exploration of the parameter\nspace. Our results demonstrate that the proposed AVOA-NGBoost model achieves\nstate-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72%\nand an AUC of 97.47%. Additionally, we enhance model interpretability using\nGrad-CAM and LIME techniques, providing insights into the decision-making\nprocess and highlighting key features influencing classification. This\nframework offers a highly precise and efficient diagnostic tool, potentially\naiding healthcare providers in early detection and diagnosis, particularly in\nresource-constrained environments.",
      "tldr_zh": "该研究提出了一种基于自然启发的、可解释的框架，用于猴痘诊断。该框架利用Xception架构提取图像的深度特征，然后使用主成分分析(PCA)进行降维，并采用自然梯度Boosting (NGBoost)算法进行分类。为了优化模型性能，研究者引入了非洲秃鹫优化算法(AVOA)进行超参数调优。实验结果表明，提出的AVOA-NGBoost模型在猴痘皮肤病变数据集(MSLD)上达到了最先进的性能，准确率达到97.53%，F1-score为97.72%，AUC为97.47%。此外，使用Grad-CAM和LIME技术增强了模型的可解释性。该框架为猴痘的早期检测和诊断提供了一种高精度和高效的诊断工具。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17540v1",
      "published_date": "2025-04-24 13:32:11 UTC",
      "updated_date": "2025-04-24 13:32:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:07:35.807608"
    },
    {
      "arxiv_id": "2504.17539v1",
      "title": "Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy Waste",
      "title_zh": "有益智能证明（PoUI）：超越能源浪费的区块链共识\n",
      "authors": [
        "Zan-Kai Chong",
        "Hiroyuki Ohsaki",
        "Bryan Ng"
      ],
      "abstract": "Blockchain technology enables secure, transparent data management in\ndecentralized systems, supporting applications from cryptocurrencies like\nBitcoin to tokenizing real-world assets like property. Its scalability and\nsustainability hinge on consensus mechanisms balancing security and efficiency.\nProof of Work (PoW), used by Bitcoin, ensures security through energy-intensive\ncomputations but demands significant resources. Proof of Stake (PoS), as in\nEthereum post-Merge, selects validators based on staked cryptocurrency,\noffering energy efficiency but risking centralization from wealth\nconcentration. With AI models straining computational resources, we propose\nProof of Useful Intelligence (PoUI), a hybrid consensus mechanism. In PoUI,\nworkers perform AI tasks like language processing or image analysis to earn\ncoins, which are staked to secure the network, blending security with practical\nutility. Decentralized nodes--job posters, market coordinators, workers, and\nvalidators --collaborate via smart contracts to manage tasks and rewards.",
      "tldr_zh": "本文提出了一种新的区块链共识机制：有用智能证明(Proof of Useful Intelligence, PoUI)。PoUI旨在解决传统工作量证明(Proof of Work, PoW)共识机制能源消耗过高，以及权益证明(Proof of Stake, PoS)共识机制可能导致中心化的问题。PoUI通过让矿工执行有用的AI任务，例如自然语言处理或图像分析，来获得代币，并将这些代币用于网络安全抵押。该机制结合了安全性和实用性，通过智能合约协调去中心化节点（任务发布者、市场协调者、工作者和验证者）之间的协作，管理任务和奖励。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17539v1",
      "published_date": "2025-04-24 13:32:03 UTC",
      "updated_date": "2025-04-24 13:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:07:47.721734"
    },
    {
      "arxiv_id": "2504.17534v1",
      "title": "Learning Isometric Embeddings of Road Networks using Multidimensional Scaling",
      "title_zh": "利用多维标度法学习道路网络的等距嵌入\n",
      "authors": [
        "Juan Carlos Climent Pardo"
      ],
      "abstract": "The lack of generalization in learning-based autonomous driving applications\nis shown by the narrow range of road scenarios that vehicles can currently\ncover. A generalizable approach should capture many distinct road structures\nand topologies, as well as consider traffic participants, and dynamic changes\nin the environment, so that vehicles can navigate and perform motion planning\ntasks even in the most difficult situations. Designing suitable feature spaces\nfor neural network-based motion planers that encapsulate all kinds of road\nscenarios is still an open research challenge. This paper tackles this\nlearning-based generalization challenge and shows how graph representations of\nroad networks can be leveraged by using multidimensional scaling (MDS)\ntechniques in order to obtain such feature spaces. State-of-the-art graph\nrepresentations and MDS approaches are analyzed for the autonomous driving use\ncase. Finally, the option of embedding graph nodes is discussed in order to\nperform easier learning procedures and obtain dimensionality reduction.",
      "tldr_zh": "该论文探讨了如何利用多维尺度分析(Multidimensional Scaling, MDS)技术学习道路网络的等距嵌入，从而解决基于学习的自动驾驶应用中泛化能力不足的问题。研究分析了最先进的图表示方法和MDS方法在自动驾驶场景中的应用，旨在为基于神经网络的运动规划器设计合适的特征空间，以囊括各种道路场景。此外，论文还讨论了嵌入图节点以简化学习过程并实现降维的可能性。该方法旨在提高自动驾驶系统在复杂和多变道路环境中的适应性和泛化能力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17534v1",
      "published_date": "2025-04-24 13:20:32 UTC",
      "updated_date": "2025-04-24 13:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:07:59.962178"
    },
    {
      "arxiv_id": "2504.17531v1",
      "title": "Towards Machine-Generated Code for the Resolution of User Intentions",
      "title_zh": "迈向用于解决用户意图的机器生成代码\n",
      "authors": [
        "Justus Flerlage",
        "Ilja Behnke",
        "Odej Kao"
      ],
      "abstract": "The growing capabilities of Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), prompt a reassessment of the interaction mechanisms\nbetween users and their devices. Currently, users are required to use a set of\nhigh-level applications to achieve their desired results. However, the advent\nof AI may signal a shift in this regard, as its capabilities have generated\nnovel prospects for user-provided intent resolution through the deployment of\nmodel-generated code, which is tantamount to the generation of workflows\ncomprising a multitude of interdependent steps. This development represents a\nsignificant progression in the realm of hybrid workflows, where human and\nartificial intelligence collaborate to address user intentions, with the former\nresponsible for defining these intentions and the latter for implementing the\nsolutions to address them. In this paper, we investigate the feasibility of\ngenerating and executing workflows through code generation that results from\nprompting an LLM with a concrete user intention, such as \\emph{Please send my\ncar title to my insurance company}, and a simplified application programming\ninterface for a GUI-less operating system. We provide in-depth analysis and\ncomparison of various user intentions, the resulting code, and its execution.\nThe findings demonstrate a general feasibility of our approach and that the\nemployed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of\ncode-oriented workflows in accordance with provided user intentions.",
      "tldr_zh": "本文探讨了利用大型语言模型(LLMs)生成代码以解决用户意图的可行性。研究提出一种混合工作流模式，用户负责定义意图，AI负责生成代码实现解决方案。通过向LLM (GPT-4o-mini)提供用户意图（例如“请将我的汽车所有权证发送给我的保险公司”）和一个简化的无GUI操作系统API，研究人员生成并执行了相应的代码工作流。实验结果表明，该方法具有可行性，并且GPT-4o-mini在根据用户意图生成面向代码的工作流方面表现出卓越的能力。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17531v1",
      "published_date": "2025-04-24 13:19:17 UTC",
      "updated_date": "2025-04-24 13:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:08:11.893755"
    },
    {
      "arxiv_id": "2504.17528v1",
      "title": "TACO: Tackling Over-correction in Federated Learning with Tailored Adaptive Correction",
      "title_zh": "TACO：利用定制化自适应校正解决联邦学习中的过度校正问题\n",
      "authors": [
        "Weijie Liu",
        "Ziwei Zhan",
        "Carlee Joe-Wong",
        "Edith Ngai",
        "Jingpu Duan",
        "Deke Guo",
        "Xu Chen",
        "Xiaoxi Zhang"
      ],
      "abstract": "Non-independent and identically distributed (Non-IID) data across edge\nclients have long posed significant challenges to federated learning (FL)\ntraining in edge computing environments. Prior works have proposed various\nmethods to mitigate this statistical heterogeneity. While these works can\nachieve good theoretical performance, in this work we provide the first\ninvestigation into a hidden over-correction phenomenon brought by the uniform\nmodel correction coefficients across clients adopted by existing methods. Such\nover-correction could degrade model performance and even cause failures in\nmodel convergence. To address this, we propose TACO, a novel algorithm that\naddresses the non-IID nature of clients' data by implementing fine-grained,\nclient-specific gradient correction and model aggregation, steering local\nmodels towards a more accurate global optimum. Moreover, we verify that leading\nFL algorithms generally have better model accuracy in terms of communication\nrounds rather than wall-clock time, resulting from their extra computation\noverhead imposed on clients. To enhance the training efficiency, TACO deploys a\nlightweight model correction and tailored aggregation approach that requires\nminimum computation overhead and no extra information beyond the synchronized\nmodel parameters. To validate TACO's effectiveness, we present the first FL\nconvergence analysis that reveals the root cause of over-correction. Extensive\nexperiments across various datasets confirm TACO's superior and stable\nperformance in practice.",
      "tldr_zh": "联邦学习(FL)在非独立同分布(Non-IID)数据上面临挑战，现有算法采用统一的模型修正系数可能导致“过度修正”现象，从而降低模型性能甚至导致不收敛。为了解决这个问题，该论文提出了TACO算法，通过细粒度的、客户端特定的梯度修正和模型聚合来解决Non-IID问题，引导局部模型朝着更准确的全局最优方向发展。TACO采用轻量级的模型修正和定制聚合方法，计算开销小，无需额外信息。理论分析揭示了过度修正的根本原因，实验结果表明TACO在各种数据集上都具有优越且稳定的性能。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures, accepted by ICDCS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.17528v1",
      "published_date": "2025-04-24 13:16:21 UTC",
      "updated_date": "2025-04-24 13:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:08:23.878798"
    },
    {
      "arxiv_id": "2504.17497v1",
      "title": "Combining GCN Structural Learning with LLM Chemical Knowledge for or Enhanced Virtual Screening",
      "title_zh": "结合 GCN 结构学习与 LLM 化学知识以增强虚拟筛选\n",
      "authors": [
        "Radia Berreziga",
        "Mohammed Brahimi",
        "Khairedine Kraim",
        "Hamid Azzoune"
      ],
      "abstract": "Virtual screening plays a critical role in modern drug discovery by enabling\nthe identification of promising candidate molecules for experimental\nvalidation. Traditional machine learning methods such as support vector\nmachines (SVM) and XGBoost rely on predefined molecular representations, often\nleading to information loss and potential bias. In contrast, deep learning\napproaches-particularly Graph Convolutional Networks (GCNs)-offer a more\nexpressive and unbiased alternative by operating directly on molecular graphs.\nMeanwhile, Large Language Models (LLMs) have recently demonstrated\nstate-of-the-art performance in drug design, thanks to their capacity to\ncapture complex chemical patterns from large-scale data via attention\nmechanisms.\n  In this paper, we propose a hybrid architecture that integrates GCNs with\nLLM-derived embeddings to combine localized structural learning with global\nchemical knowledge. The LLM embeddings can be precomputed and stored in a\nmolecular feature library, removing the need to rerun the LLM during training\nor inference and thus maintaining computational efficiency. We found that\nconcatenating the LLM embeddings after each GCN layer-rather than only at the\nfinal layer-significantly improves performance, enabling deeper integration of\nglobal context throughout the network. The resulting model achieves superior\nresults, with an F1-score of (88.8%), outperforming standalone GCN (87.9%),\nXGBoost (85.5%), and SVM (85.4%) baselines.",
      "tldr_zh": "该论文提出了一种结合图卷积网络(GCN)结构学习和大型语言模型(LLM)化学知识的混合架构，用于增强虚拟筛选效果。该方法利用LLM提取的分子嵌入向量，将其与GCN的每一层进行连接，从而将全局化学知识更深入地融入到网络中。实验结果表明，该模型在F1-score上达到了88.8%，优于单独的GCN、XGBoost和SVM等基线模型，证明了该方法在虚拟筛选任务中的有效性。该方法通过预先计算和存储LLM嵌入，避免了在训练或推理过程中重复运行LLM，从而保持了计算效率。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17497v1",
      "published_date": "2025-04-24 12:38:03 UTC",
      "updated_date": "2025-04-24 12:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:08:35.806632"
    },
    {
      "arxiv_id": "2504.17493v1",
      "title": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design",
      "title_zh": "面向目标的时间序列预测：基础框架设计\n",
      "authors": [
        "Luca-Andrei Fechete",
        "Mohamed Sana",
        "Fadhel Ayed",
        "Nicola Piovesan",
        "Wenjie Li",
        "Antonio De Domenico",
        "Tareq Si Salem"
      ],
      "abstract": "Traditional time-series forecasting often focuses only on minimizing\nprediction errors, ignoring the specific requirements of real-world\napplications that employ them. This paper presents a new training methodology,\nwhich allows a forecasting model to dynamically adjust its focus based on the\nimportance of forecast ranges specified by the end application. Unlike previous\nmethods that fix these ranges beforehand, our training approach breaks down\npredictions over the entire signal range into smaller segments, which are then\ndynamically weighted and combined to produce accurate forecasts. We tested our\nmethod on standard datasets, including a new dataset from wireless\ncommunication, and found that not only it improves prediction accuracy but also\nimproves the performance of end application employing the forecasting model.\nThis research provides a basis for creating forecasting systems that better\nconnect prediction and decision-making in various practical applications.",
      "tldr_zh": "传统时间序列预测通常只关注最小化预测误差，忽略了实际应用中的特定需求。本文提出了一种新的训练方法，使预测模型能够根据终端应用指定的预测范围的重要性动态调整其关注点。与预先固定这些范围的先前方法不同，我们的训练方法将整个信号范围内的预测分解为更小的段，然后动态加权和组合这些段以产生准确的预测。我们在标准数据集（包括来自无线通信的新数据集）上测试了我们的方法，发现它不仅提高了预测准确性，还提高了使用预测模型的终端应用程序的性能。这项研究为创建更好地连接各种实际应用中的预测和决策的预测系统奠定了基础。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17493v1",
      "published_date": "2025-04-24 12:34:43 UTC",
      "updated_date": "2025-04-24 12:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:08:47.694016"
    },
    {
      "arxiv_id": "2504.17490v1",
      "title": "Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning",
      "title_zh": "Plasticine：加速塑性驱动的深度强化学习研究\n",
      "authors": [
        "Mingqi Yuan",
        "Qi Wang",
        "Guozheng Ma",
        "Bo Li",
        "Xin Jin",
        "Yunbo Wang",
        "Xiaokang Yang",
        "Wenjun Zeng",
        "Dacheng Tao"
      ],
      "abstract": "Developing lifelong learning agents is crucial for artificial general\nintelligence. However, deep reinforcement learning (RL) systems often suffer\nfrom plasticity loss, where neural networks gradually lose their ability to\nadapt during training. Despite its significance, this field lacks unified\nbenchmarks and evaluation protocols. We introduce Plasticine, the first\nopen-source framework for benchmarking plasticity optimization in deep RL.\nPlasticine provides single-file implementations of over 13 mitigation methods,\n10 evaluation metrics, and learning scenarios with increasing non-stationarity\nlevels from standard to open-ended environments. This framework enables\nresearchers to systematically quantify plasticity loss, evaluate mitigation\nstrategies, and analyze plasticity dynamics across different contexts. Our\ndocumentation, examples, and source code are available at\nhttps://github.com/RLE-Foundation/Plasticine.",
      "tldr_zh": "Plasticine是一个开源框架，旨在加速深度强化学习中关于可塑性（plasticity）的研究。该框架针对深度强化学习系统中的可塑性损失问题，提供了统一的基准和评估协议。Plasticine包含超过13种缓解方法、10种评估指标以及从标准到开放环境的多种非平稳学习场景的单文件实现。研究人员可以利用Plasticine系统地量化可塑性损失，评估缓解策略，并分析不同环境下的可塑性动态，从而推动终身学习智能体的开发。项目代码已开源。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.17490v1",
      "published_date": "2025-04-24 12:32:13 UTC",
      "updated_date": "2025-04-24 12:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:08:59.740902"
    },
    {
      "arxiv_id": "2504.17474v1",
      "title": "Enhanced Sample Selection with Confidence Tracking: Identifying Correctly Labeled yet Hard-to-Learn Samples in Noisy Data",
      "title_zh": "基于置信度追踪的增强样本选择：识别噪声数据中已正确标记但难以学习的样本\n",
      "authors": [
        "Weiran Pan",
        "Wei Wei",
        "Feida Zhu",
        "Yong Deng"
      ],
      "abstract": "We propose a novel sample selection method for image classification in the\npresence of noisy labels. Existing methods typically consider small-loss\nsamples as correctly labeled. However, some correctly labeled samples are\ninherently difficult for the model to learn and can exhibit high loss similar\nto mislabeled samples in the early stages of training. Consequently, setting a\nthreshold on per-sample loss to select correct labels results in a trade-off\nbetween precision and recall in sample selection: a lower threshold may miss\nmany correctly labeled hard-to-learn samples (low recall), while a higher\nthreshold may include many mislabeled samples (low precision). To address this\nissue, our goal is to accurately distinguish correctly labeled yet\nhard-to-learn samples from mislabeled ones, thus alleviating the trade-off\ndilemma. We achieve this by considering the trends in model prediction\nconfidence rather than relying solely on loss values. Empirical observations\nshow that only for correctly labeled samples, the model's prediction confidence\nfor the annotated labels typically increases faster than for any other classes.\nBased on this insight, we propose tracking the confidence gaps between the\nannotated labels and other classes during training and evaluating their trends\nusing the Mann-Kendall Test. A sample is considered potentially correctly\nlabeled if all its confidence gaps tend to increase. Our method functions as a\nplug-and-play component that can be seamlessly integrated into existing sample\nselection techniques. Experiments on several standard benchmarks and real-world\ndatasets demonstrate that our method enhances the performance of existing\nmethods for learning with noisy labels.",
      "tldr_zh": "该论文提出了一种新的样本选择方法，用于在存在噪声标签的情况下进行图像分类。该方法旨在区分正确标记但难以学习的样本和错误标记的样本，从而缓解样本选择中精度和召回率之间的权衡。核心思想是追踪模型预测置信度的趋势，而不是仅仅依赖损失值。通过Mann-Kendall Test评估标注标签与其他类别之间的置信度差距，如果所有置信度差距都趋于增加，则认为样本可能是正确标记的。该方法可作为即插即用组件集成到现有的样本选择技术中，实验表明其可以提高现有噪声标签学习方法的性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17474v1",
      "published_date": "2025-04-24 12:07:14 UTC",
      "updated_date": "2025-04-24 12:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:09:11.890695"
    },
    {
      "arxiv_id": "2504.17471v1",
      "title": "GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework",
      "title_zh": "GRANITE：一种拜占庭容错的动态 Gossip 学习框架\n",
      "authors": [
        "Yacine Belal",
        "Mohamed Maouche",
        "Sonia Ben Mokhtar",
        "Anthony Simonet-Boulogne"
      ],
      "abstract": "Gossip Learning (GL) is a decentralized learning paradigm where users\niteratively exchange and aggregate models with a small set of neighboring\npeers. Recent GL approaches rely on dynamic communication graphs built and\nmaintained using Random Peer Sampling (RPS) protocols. Thanks to graph\ndynamics, GL can achieve fast convergence even over extremely sparse\ntopologies. However, the robustness of GL over dy- namic graphs to Byzantine\n(model poisoning) attacks remains unaddressed especially when Byzantine nodes\nattack the RPS protocol to scale up model poisoning. We address this issue by\nintroducing GRANITE, a framework for robust learning over sparse, dynamic\ngraphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two\nkey components (i) a History-aware Byzantine-resilient Peer Sampling protocol\n(HaPS), which tracks previously encountered identifiers to reduce adversarial\ninfluence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which\nleverages an estimate of Byzantine presence to set aggregation thresholds with\nformal guarantees. Empirical results confirm that GRANITE maintains convergence\nwith up to 30% Byzantine nodes, improves learning speed via adaptive filtering\nof poisoned models and obtains these results in up to 9 times sparser graphs\nthan dictated by current theory.",
      "tldr_zh": "本文提出了GRANITE，一个拜占庭容错的动态Gossip Learning (GL)框架，旨在解决动态图上的GL在面对拜占庭攻击（尤其是攻击随机节点抽样协议RPS）时的鲁棒性问题。GRANITE包含两个关键组件：一是历史感知的拜占庭容错节点抽样协议(HaPS)，通过追踪历史节点ID来减少对抗影响；二是自适应概率阈值(APT)，利用拜占庭节点比例的估计来设置聚合阈值，并提供形式化保证。实验结果表明，GRANITE在高达30%的拜占庭节点存在的情况下仍能保持收敛，通过自适应过滤中毒模型来提高学习速度，并且可以在比现有理论要求的稀疏9倍的图上实现这些结果。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17471v1",
      "published_date": "2025-04-24 12:03:15 UTC",
      "updated_date": "2025-04-24 12:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:09:24.206147"
    },
    {
      "arxiv_id": "2504.17461v1",
      "title": "Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience",
      "title_zh": "评估用于城市废水管理的时间序列模型：预测性能、模型复杂性和韧性\n",
      "authors": [
        "Vipin Singh",
        "Tianheng Ling",
        "Teodor Chiaburu",
        "Felix Biessmann"
      ],
      "abstract": "Climate change increases the frequency of extreme rainfall, placing a\nsignificant strain on urban infrastructures, especially Combined Sewer Systems\n(CSS). Overflows from overburdened CSS release untreated wastewater into\nsurface waters, posing environmental and public health risks. Although\ntraditional physics-based models are effective, they are costly to maintain and\ndifficult to adapt to evolving system dynamics. Machine Learning (ML)\napproaches offer cost-efficient alternatives with greater adaptability. To\nsystematically assess the potential of ML for modeling urban infrastructure\nsystems, we propose a protocol for evaluating Neural Network architectures for\nCSS time series forecasting with respect to predictive performance, model\ncomplexity, and robustness to perturbations. In addition, we assess model\nperformance on peak events and critical fluctuations, as these are the key\nregimes for urban wastewater management. To investigate the feasibility of\nlightweight models suitable for IoT deployment, we compare global models, which\nhave access to all information, with local models, which rely solely on nearby\nsensor readings. Additionally, to explore the security risks posed by network\noutages or adversarial attacks on urban infrastructure, we introduce error\nmodels that assess the resilience of models. Our results demonstrate that while\nglobal models achieve higher predictive performance, local models provide\nsufficient resilience in decentralized scenarios, ensuring robust modeling of\nurban infrastructure. Furthermore, models with longer native forecast horizons\nexhibit greater robustness to data perturbations. These findings contribute to\nthe development of interpretable and reliable ML solutions for sustainable\nurban wastewater management. The implementation is available in our GitHub\nrepository.",
      "tldr_zh": "该研究评估了机器学习(ML)模型在城市污水管理中时间序列预测的潜力，特别是在应对气候变化带来的极端降雨对合流制排水系统(CSS)的压力。研究提出了一种评估神经网络架构的协议，从预测性能、模型复杂性和抗扰动性三个方面进行评估。通过比较全局模型（访问所有信息）和局部模型（仅依赖附近传感器读数），研究探讨了适用于物联网(IoT)部署的轻量级模型的可行性。结果表明，全局模型预测性能更高，而局部模型在去中心化场景中提供足够的弹性。此外，具有更长预测范围的模型对数据扰动表现出更强的鲁棒性。该研究为开发用于可持续城市污水管理的可解释和可靠的ML解决方案做出了贡献。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 6 figures, accepted at 10th International Conference on\n  Smart and Sustainable Technologies (SpliTech) 2025, GitHub:\n  https://github.com/calgo-lab/resilient-timeseries-evaluation",
      "pdf_url": "http://arxiv.org/pdf/2504.17461v1",
      "published_date": "2025-04-24 11:52:13 UTC",
      "updated_date": "2025-04-24 11:52:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:09:36.053263"
    },
    {
      "arxiv_id": "2504.17449v1",
      "title": "HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models",
      "title_zh": "HMI：用于预训练语言模型中高效多租户推理的分层知识管理\n",
      "authors": [
        "Jun Zhang",
        "Jue Wang",
        "Huan Li",
        "Lidan Shou",
        "Ke Chen",
        "Gang Chen",
        "Qin Xie",
        "Guiming Xie",
        "Xuejian Gong"
      ],
      "abstract": "The significant computational demands of pretrained language models (PLMs),\nwhich often require dedicated hardware, present a substantial challenge in\nserving them efficiently, especially in multi-tenant environments. To address\nthis, we introduce HMI, a Hierarchical knowledge management-based Multi-tenant\nInference system, designed to manage tenants with distinct PLMs\nresource-efficiently. Our approach is three-fold: Firstly, we categorize PLM\nknowledge into general, domain-specific, and task-specific. Leveraging insights\non knowledge acquisition across different model layers, we construct\nhierarchical PLMs (hPLMs) by extracting and storing knowledge at different\nlevels, significantly reducing GPU memory usage per tenant. Secondly, we\nestablish hierarchical knowledge management for hPLMs generated by various\ntenants in HMI. We manage domain-specific knowledge with acceptable storage\nincreases by constructing and updating domain-specific knowledge trees based on\nfrequency. We manage task-specific knowledge within limited GPU memory through\nparameter swapping. Finally, we propose system optimizations to enhance\nresource utilization and inference throughput. These include fine-grained\npipelining via hierarchical knowledge prefetching to overlap CPU and I/O\noperations with GPU computations, and optimizing parallel implementations with\nbatched matrix multiplications. Our experimental results demonstrate that the\nproposed HMI can efficiently serve up to 10,000 hPLMs (hBERTs and hGPTs) on a\nsingle GPU, with only a negligible compromise in accuracy.",
      "tldr_zh": "该论文提出了HMI，一个基于分层知识管理的多租户推理系统，旨在解决预训练语言模型(PLMs)在多租户环境下资源效率低下的问题。HMI将PLM知识分为通用、领域特定和任务特定三类，构建分层PLMs (hPLMs)，通过提取和存储不同层级的知识来减少GPU内存占用。HMI通过构建基于频率的领域特定知识树来管理领域知识，并通过参数交换在有限的GPU内存中管理任务知识。此外，HMI还通过细粒度流水线和优化的并行实现来提高资源利用率和推理吞吐量。实验结果表明，HMI可以在单个GPU上高效地服务多达10,000个hPLMs (hBERTs和hGPTs)，且精度损失可忽略不计。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by VLDBJ 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.17449v1",
      "published_date": "2025-04-24 11:28:40 UTC",
      "updated_date": "2025-04-24 11:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:09:48.113050"
    },
    {
      "arxiv_id": "2504.17447v1",
      "title": "FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding",
      "title_zh": "FRAG：帧选择增强生成，用于长视频和长文档理解\n",
      "authors": [
        "De-An Huang",
        "Subhashree Radhakrishnan",
        "Zhiding Yu",
        "Jan Kautz"
      ],
      "abstract": "There has been impressive progress in Large Multimodal Models (LMMs). Recent\nworks extend these models to long inputs, including multi-page documents and\nlong videos. However, the model size and performance of these long context\nmodels are still limited due to the computational cost in both training and\ninference. In this work, we explore an orthogonal direction and process long\ninputs without long context LMMs. We propose Frame Selection Augmented\nGeneration (FRAG), where the model first selects relevant frames within the\ninput, and then only generates the final outputs based on the selected frames.\nThe core of the selection process is done by scoring each frame independently,\nwhich does not require long context processing. The frames with the highest\nscores are then selected by a simple Top-K selection. We show that this\nfrustratingly simple framework is applicable to both long videos and multi-page\ndocuments using existing LMMs without any fine-tuning. We consider two models,\nLLaVA-OneVision and InternVL2, in our experiments and show that FRAG\nconsistently improves the performance and achieves state-of-the-art\nperformances for both long video and long document understanding. For videos,\nFRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on\nVideo-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA\ncompared with recent LMMs specialized in long document understanding. Code is\navailable at: https://github.com/NVlabs/FRAG",
      "tldr_zh": "本文提出了一种名为FRAG（Frame Selection Augmented Generation）的框架，用于处理长视频和长文档理解任务，旨在避免使用长上下文的大型多模态模型(LMMs)带来的计算成本限制。FRAG首先独立地对输入中的每个帧进行评分，然后仅基于选定的帧生成最终输出，从而实现高效的帧选择。该框架无需任何微调，即可应用于现有的LMMs。实验结果表明，FRAG在长视频和长文档理解方面均取得了显著的性能提升，例如在MLVU上将InternVL2-76B的性能提高了5.8%，在MP-DocVQA上实现了超过20%的改进。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17447v1",
      "published_date": "2025-04-24 11:19:18 UTC",
      "updated_date": "2025-04-24 11:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:10:00.147659"
    },
    {
      "arxiv_id": "2504.17428v1",
      "title": "Detection, Classification and Prevalence of Self-Admitted Aging Debt",
      "title_zh": "自述老化债务的检测、分类和普遍性\n",
      "authors": [
        "Murali Sridharan",
        "Mika Mäntylä",
        "Leevi Rantala"
      ],
      "abstract": "Context: Previous research on software aging is limited with focus on dynamic\nruntime indicators like memory and performance, often neglecting evolutionary\nindicators like source code comments and narrowly examining legacy issues\nwithin the TD context. Objective: We introduce the concept of Aging Debt (AD),\nrepresenting the increased maintenance efforts and costs needed to keep\nsoftware updated. We study AD through Self-Admitted Aging Debt (SAAD) observed\nin source code comments left by software developers. Method: We employ a\nmixed-methods approach, combining qualitative and quantitative analyses to\ndetect and measure AD in software. This includes framing SAAD patterns from the\nsource code comments after analysing the source code context, then utilizing\nthe SAAD patterns to detect SAAD comments. In the process, we develop a\ntaxonomy for SAAD that reflects the temporal aging of software and its\nassociated debt. Then we utilize the taxonomy to quantify the different types\nof AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes\ntemporal software aging into Active and Dormant types. Our extensive analysis\nof over 9,000+ Open Source Software (OSS) repositories reveals that more than\n21% repositories exhibit signs of SAAD as observed from our gold standard SAAD\ndataset. Notably, Dormant AD emerges as the predominant category, highlighting\na critical but often overlooked aspect of software maintenance. Conclusion: As\nsoftware volume grows annually, so do evolutionary aging and maintenance\nchallenges; our proposed taxonomy can aid researchers in detailed software\naging studies and help practitioners develop improved and proactive maintenance\nstrategies.",
      "tldr_zh": "该研究引入“老化债(Aging Debt, AD)”的概念，指软件更新所需的维护工作和成本增加。通过分析开发者留在源代码注释中的“自述老化债(Self-Admitted Aging Debt, SAAD)”，研究人员对AD进行检测、分类和普遍性分析。采用混合方法，结合定性和定量分析，从源代码注释中提取SAAD模式，并构建了反映软件时间老化的SAAD分类法。对超过9000个开源软件(OSS)仓库的分析表明，超过21%的仓库存在SAAD迹象，其中“休眠AD(Dormant AD)”是最主要的类别。该研究提出的分类法可帮助研究人员进行详细的软件老化研究，并帮助从业者制定改进的、主动的维护策略。\n",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CE",
        "cs.GL",
        "D.2.7; D.2.9"
      ],
      "primary_category": "cs.SE",
      "comment": "Draft",
      "pdf_url": "http://arxiv.org/pdf/2504.17428v1",
      "published_date": "2025-04-24 10:38:55 UTC",
      "updated_date": "2025-04-24 10:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:10:12.139068"
    },
    {
      "arxiv_id": "2504.17426v1",
      "title": "Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code",
      "title_zh": "利用大型语言模型摘要进行源代码主题建模的研究\n",
      "authors": [
        "Michele Carissimi",
        "Martina Saletta",
        "Claudio Ferretti"
      ],
      "abstract": "Understanding source code is a topic of great interest in the software\nengineering community, since it can help programmers in various tasks such as\nsoftware maintenance and reuse. Recent advances in large language models (LLMs)\nhave demonstrated remarkable program comprehension capabilities, while\ntransformer-based topic modeling techniques offer effective ways to extract\nsemantic information from text. This paper proposes and explores a novel\napproach that combines these strengths to automatically identify meaningful\ntopics in a corpus of Python programs. Our method consists in applying topic\nmodeling on the descriptions obtained by asking an LLM to summarize the code.\nTo assess the internal consistency of the extracted topics, we compare them\nagainst topics inferred from function names alone, and those derived from\nexisting docstrings. Experimental results suggest that leveraging LLM-generated\nsummaries provides interpretable and semantically rich representation of code\nstructure. The promising results suggest that our approach can be fruitfully\napplied in various software engineering tasks such as automatic documentation\nand tagging, code search, software reorganization and knowledge discovery in\nlarge repositories.",
      "tldr_zh": "本文提出了一种新颖的方法，结合大型语言模型(LLMs)和主题建模技术，自动识别Python代码语料库中的有意义的主题。该方法首先利用LLM生成代码摘要，然后对这些摘要进行主题建模。通过与基于函数名和现有文档字符串推断的主题进行比较，评估提取主题的内部一致性。实验结果表明，利用LLM生成的摘要可以提供可解释且语义丰富的代码结构表示。该方法在自动文档生成、代码搜索、软件重组和大型代码库中的知识发现等软件工程任务中具有应用前景。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17426v1",
      "published_date": "2025-04-24 10:30:40 UTC",
      "updated_date": "2025-04-24 10:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:10:23.790662"
    },
    {
      "arxiv_id": "2504.17424v1",
      "title": "Object Pose Estimation by Camera Arm Control Based on the Next Viewpoint Estimation",
      "title_zh": "基于下个视点估计的相机臂控制物体姿态估计\n",
      "authors": [
        "Tomoki Mizuno",
        "Kazuya Yabashi",
        "Tsuyoshi Tasaki"
      ],
      "abstract": "We have developed a new method to estimate a Next Viewpoint (NV) which is\neffective for pose estimation of simple-shaped products for product display\nrobots in retail stores. Pose estimation methods using Neural Networks (NN)\nbased on an RGBD camera are highly accurate, but their accuracy significantly\ndecreases when the camera acquires few texture and shape features at a current\nview point. However, it is difficult for previous mathematical model-based\nmethods to estimate effective NV which is because the simple shaped objects\nhave few shape features. Therefore, we focus on the relationship between the\npose estimation and NV estimation. When the pose estimation is more accurate,\nthe NV estimation is more accurate. Therefore, we develop a new pose estimation\nNN that estimates NV simultaneously. Experimental results showed that our NV\nestimation realized a pose estimation success rate 77.3\\%, which was 7.4pt\nhigher than the mathematical model-based NV calculation did. Moreover, we\nverified that the robot using our method displayed 84.2\\% of products.",
      "tldr_zh": "该论文提出了一种新的方法，通过相机臂控制和下一视角(Next Viewpoint, NV)估计来提高简单形状物体的姿态估计精度，应用于零售商店的产品展示机器人。针对传统方法在纹理和形状特征不足时姿态估计精度下降的问题，该方法设计了一个新的神经网络，同时估计物体姿态和最佳下一视角。实验结果表明，该方法在姿态估计成功率上比基于数学模型的方法提高了7.4%，达到77.3%，并且在机器人产品展示应用中达到了84.2%的成功率。该研究强调了姿态估计和下一视角估计之间的相互促进关系。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17424v1",
      "published_date": "2025-04-24 10:26:14 UTC",
      "updated_date": "2025-04-24 10:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:10:36.015897"
    },
    {
      "arxiv_id": "2504.17421v1",
      "title": "Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks",
      "title_zh": "利用大小模型协同力量解决领域任务\n",
      "authors": [
        "Yang Liu",
        "Bingjie Yan",
        "Tianyuan Zou",
        "Jianqing Zhang",
        "Zixuan Gu",
        "Jianbing Ding",
        "Xidong Wang",
        "Jingyi Li",
        "Xiaozhou Ye",
        "Ye Ouyang",
        "Qiang Yang",
        "Ya-Qin Zhang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\nthey require vast amounts of data and computational resources. In contrast,\nsmaller models (SMs), while less powerful, can be more efficient and tailored\nto specific domains. In this position paper, we argue that taking a\ncollaborative approach, where large and small models work synergistically, can\naccelerate the adaptation of LLMs to private domains and unlock new potential\nin AI. We explore various strategies for model collaboration and identify\npotential challenges and opportunities. Building upon this, we advocate for\nindustry-driven research that prioritizes multi-objective benchmarks on\nreal-world private datasets and applications.",
      "tldr_zh": "本文提出了一种利用大型语言模型(LLMs)和小型模型(SMs)协同工作的方法，旨在加速LLMs在特定领域的应用。该方法结合了LLMs的强大能力和SMs的效率及领域针对性，通过多种模型协作策略探索了AI的新潜力。文章强调了在真实世界私有数据集上进行多目标基准测试的行业驱动研究的重要性，以应对潜在的挑战并抓住机遇。该研究旨在促进LLMs在私有领域的适应和应用。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17421v1",
      "published_date": "2025-04-24 10:24:35 UTC",
      "updated_date": "2025-04-24 10:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:10:47.801150"
    },
    {
      "arxiv_id": "2504.17404v1",
      "title": "Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society",
      "title_zh": "重新定义超对齐：从弱到强的对齐到人机协同对齐，再到可持续的共生社会\n",
      "authors": [
        "Feifei Zhao",
        "Yuwei Wang",
        "Enmeng Lu",
        "Dongcheng Zhao",
        "Bing Han",
        "Haibo Tong",
        "Yao Liang",
        "Dongqi Liang",
        "Kang Sun",
        "Lei Wang",
        "Yitao Liang",
        "Chao Liu",
        "Yaodong Yang",
        "Yi Zeng"
      ],
      "abstract": "Artificial Intelligence (AI) systems are becoming increasingly powerful and\nautonomous, and may progress to surpass human intelligence levels, namely\nArtificial Superintelligence (ASI). During the progression from AI to ASI, it\nmay exceed human control, violate human values, and even lead to irreversible\ncatastrophic consequences in extreme cases. This gives rise to a pressing issue\nthat needs to be addressed: superalignment, ensuring that AI systems much\nsmarter than humans, remain aligned with human (compatible) intentions and\nvalues. Existing scalable oversight and weak-to-strong generalization methods\nmay prove substantially infeasible and inadequate when facing ASI. We must\nexplore safer and more pluralistic frameworks and approaches for\nsuperalignment. In this paper, we redefine superalignment as the human-AI\nco-alignment towards a sustainable symbiotic society, and highlight a framework\nthat integrates external oversight and intrinsic proactive alignment. External\noversight superalignment should be grounded in human-centered ultimate\ndecision, supplemented by interpretable automated evaluation and correction, to\nachieve continuous alignment with humanity's evolving values. Intrinsic\nproactive superalignment is rooted in a profound understanding of the self,\nothers, and society, integrating self-awareness, self-reflection, and empathy\nto spontaneously infer human intentions, distinguishing good from evil and\nproactively considering human well-being, ultimately attaining human-AI\nco-alignment through iterative interaction. The integration of\nexternally-driven oversight with intrinsically-driven proactive alignment\nempowers sustainable symbiotic societies through human-AI co-alignment, paving\nthe way for achieving safe and beneficial AGI and ASI for good, for human, and\nfor a symbiotic ecology.",
      "tldr_zh": "本文重新定义了“超对齐”(Superalignment)的概念，将其从“由弱到强对齐”扩展到“人机协同对齐”，最终目标是实现可持续的共生社会。面对可能超越人类智能的ASI，传统的监督方法可能不足以确保AI系统与人类价值观对齐。因此，本文提出一个框架，整合了外部监督和内在主动对齐。外部监督以人为中心的最终决策为基础，辅以可解释的自动评估和纠正，以适应人类不断变化的价值观。内在主动对齐则基于对自我、他人和社会的深刻理解，通过自知、自省和共情来推断人类意图，从而实现人机协同对齐。这种内外结合的方法旨在通过人机协同，为实现安全且有益的AGI和ASI铺平道路。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17404v1",
      "published_date": "2025-04-24 09:53:49 UTC",
      "updated_date": "2025-04-24 09:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:11:00.237917"
    },
    {
      "arxiv_id": "2504.17402v1",
      "title": "Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation",
      "title_zh": "评估大型语言模型在领域特定本体生成方面的能力\n",
      "authors": [
        "Anna Sofia Lippolis",
        "Mohammad Javad Saeedizade",
        "Robin Keskisarkka",
        "Aldo Gangemi",
        "Eva Blomqvist",
        "Andrea Giovanni Nuzzolese"
      ],
      "abstract": "Large Language Models (LLMs) have shown significant potential for ontology\nengineering. However, it is still unclear to what extent they are applicable to\nthe task of domain-specific ontology generation. In this study, we explore the\napplication of LLMs for automated ontology generation and evaluate their\nperformance across different domains. Specifically, we investigate the\ngeneralizability of two state-of-the-art LLMs, DeepSeek and o1-preview, both\nequipped with reasoning capabilities, by generating ontologies from a set of\ncompetency questions (CQs) and related user stories. Our experimental setup\ncomprises six distinct domains carried out in existing ontology engineering\nprojects and a total of 95 curated CQs designed to test the models' reasoning\nfor ontology engineering. Our findings show that with both LLMs, the\nperformance of the experiments is remarkably consistent across all domains,\nindicating that these methods are capable of generalizing ontology generation\ntasks irrespective of the domain. These results highlight the potential of\nLLM-based approaches in achieving scalable and domain-agnostic ontology\nconstruction and lay the groundwork for further research into enhancing\nautomated reasoning and knowledge representation techniques.",
      "tldr_zh": "本文评估了大型语言模型(LLMs)在领域特定本体生成中的能力。研究探索了LLMs在自动本体生成中的应用，并评估了它们在不同领域中的性能。通过使用一系列能力问题(CQs)和相关的用户故事生成本体，研究调查了两个先进的、具备推理能力的LLMs——DeepSeek和o1-preview的泛化能力。实验涵盖了六个不同的领域，共计95个精心设计的CQs，旨在测试模型在本体工程中的推理能力。实验结果表明，两种LLMs在所有领域中的表现都非常稳定，表明这些方法能够泛化本体生成任务，不受领域限制。这突出了基于LLM的方法在实现可扩展和领域无关的本体构建方面的潜力，并为进一步研究增强自动推理和知识表示技术奠定了基础。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17402v1",
      "published_date": "2025-04-24 09:47:14 UTC",
      "updated_date": "2025-04-24 09:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:11:12.197374"
    },
    {
      "arxiv_id": "2504.17401v1",
      "title": "StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies",
      "title_zh": "StereoMamba：基于长程空间依赖的实时鲁棒术中立体视差估计\n",
      "authors": [
        "Xu Wang",
        "Jialang Xu",
        "Shuai Zhang",
        "Baoru Huang",
        "Danail Stoyanov",
        "Evangelos B. Mazomenos"
      ],
      "abstract": "Stereo disparity estimation is crucial for obtaining depth information in\nrobot-assisted minimally invasive surgery (RAMIS). While current deep learning\nmethods have made significant advancements, challenges remain in achieving an\noptimal balance between accuracy, robustness, and inference speed. To address\nthese challenges, we propose the StereoMamba architecture, which is\nspecifically designed for stereo disparity estimation in RAMIS. Our approach is\nbased on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances\nlong-range spatial dependencies both within and across stereo images. To\neffectively integrate multi-scale features from FE-Mamba, we then introduce a\nnovel Multidimensional Feature Fusion (MFF) module. Experiments against the\nstate-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba\nachieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the\nsecond-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining\nan inference speed of 21.28 FPS for a pair of high-resolution images\n(1280*1024), striking the optimum balance between accuracy, robustness, and\nefficiency. Furthermore, by comparing synthesized right images, generated from\nwarping left images using the generated disparity maps, with the actual right\nimage, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761),\nexhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS\ndatasets.",
      "tldr_zh": "该论文提出了StereoMamba，一种专为机器人辅助微创手术(RAMIS)中的立体视差估计而设计的架构。该架构基于新颖的特征提取Mamba (FE-Mamba)模块，增强了立体图像内部和之间的长程空间依赖性。同时引入多维特征融合(MFF)模块，有效整合来自FE-Mamba的多尺度特征。在离体SCARED基准测试中，StereoMamba在EPE和深度MAE上取得了最佳性能，并在Bad2和Bad3上取得了第二好的性能。此外，StereoMamba在高分辨率图像(1280*1024)上保持了21.28 FPS的推理速度，并在体内RIS2017和StereoMIS数据集上表现出强大的zero-shot泛化能力。该研究在精度、鲁棒性和效率之间取得了最佳平衡。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17401v1",
      "published_date": "2025-04-24 09:46:15 UTC",
      "updated_date": "2025-04-24 09:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:11:24.210347"
    },
    {
      "arxiv_id": "2504.17393v1",
      "title": "Towards User-Centred Design of AI-Assisted Decision-Making in Law Enforcement",
      "title_zh": "迈向以用户为中心的人工智能辅助执法决策设计\n",
      "authors": [
        "Vesna Nowack",
        "Dalal Alrajeh",
        "Carolina Gutierrez Muñoz",
        "Katie Thomas",
        "William Hobson",
        "Catherine Hamilton-Giachritsis",
        "Patrick Benjamin",
        "Tim Grant",
        "Juliane A. Kloess",
        "Jessica Woodhams"
      ],
      "abstract": "Artificial Intelligence (AI) has become an important part of our everyday\nlives, yet user requirements for designing AI-assisted systems in law\nenforcement remain unclear. To address this gap, we conducted qualitative\nresearch on decision-making within a law enforcement agency. Our study aimed to\nidentify limitations of existing practices, explore user requirements and\nunderstand the responsibilities that humans expect to undertake in these\nsystems.\n  Participants in our study highlighted the need for a system capable of\nprocessing and analysing large volumes of data efficiently to help in crime\ndetection and prevention. Additionally, the system should satisfy requirements\nfor scalability, accuracy, justification, trustworthiness and adaptability to\nbe adopted in this domain. Participants also emphasised the importance of\nhaving end users review the input data that might be challenging for AI to\ninterpret, and validate the generated output to ensure the system's accuracy.\nTo keep up with the evolving nature of the law enforcement domain, end users\nneed to help the system adapt to the changes in criminal behaviour and\ngovernment guidance, and technical experts need to regularly oversee and\nmonitor the system. Furthermore, user-friendly human interaction with the\nsystem is essential for its adoption and some of the participants confirmed\nthey would be happy to be in the loop and provide necessary feedback that the\nsystem can learn from. Finally, we argue that it is very unlikely that the\nsystem will ever achieve full automation due to the dynamic and complex nature\nof the law enforcement domain.",
      "tldr_zh": "本研究旨在探索在执法领域设计AI辅助决策系统时，以用户为中心的设计需求。通过对执法机构决策过程的定性研究，分析了现有实践的局限性，并明确了用户对AI系统的期望。研究强调，AI系统需具备高效处理和分析大量数据的能力，以辅助犯罪侦查和预防，同时满足可扩展性、准确性、可解释性、可信赖性和适应性等要求。此外，用户需参与到数据审查和结果验证环节，确保系统准确性。考虑到执法领域的动态性，用户需要协助系统适应犯罪行为和政府指导的变化，技术专家则需定期监督和监控系统。研究表明，用户友好的交互界面至关重要，且用户乐于参与到系统的学习反馈循环中。最后，研究认为，由于执法领域的复杂性和动态性，AI系统难以实现完全自动化。\n",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.17393v1",
      "published_date": "2025-04-24 09:25:29 UTC",
      "updated_date": "2025-04-24 09:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:11:36.218502"
    },
    {
      "arxiv_id": "2504.17384v1",
      "title": "On the workflow, opportunities and challenges of developing foundation model in geophysics",
      "title_zh": "论地球物理学中基础模型开发的工作流程、机遇与挑战\n",
      "authors": [
        "Hanlin Sheng",
        "Xinming Wu",
        "Hang Gao",
        "Haibin Di",
        "Sergey Fomel",
        "Jintao Li",
        "Xu Si"
      ],
      "abstract": "Foundation models, as a mainstream technology in artificial intelligence,\nhave demonstrated immense potential across various domains in recent years,\nparticularly in handling complex tasks and multimodal data. In the field of\ngeophysics, although the application of foundation models is gradually\nexpanding, there is currently a lack of comprehensive reviews discussing the\nfull workflow of integrating foundation models with geophysical data. To\naddress this gap, this paper presents a complete framework that systematically\nexplores the entire process of developing foundation models in conjunction with\ngeophysical data. From data collection and preprocessing to model architecture\nselection, pre-training strategies, and model deployment, we provide a detailed\nanalysis of the key techniques and methodologies at each stage. In particular,\nconsidering the diversity, complexity, and physical consistency constraints of\ngeophysical data, we discuss targeted solutions to address these challenges.\nFurthermore, we discuss how to leverage the transfer learning capabilities of\nfoundation models to reduce reliance on labeled data, enhance computational\nefficiency, and incorporate physical constraints into model training, thereby\nimproving physical consistency and interpretability. Through a comprehensive\nsummary and analysis of the current technological landscape, this paper not\nonly fills the gap in the geophysics domain regarding a full-process review of\nfoundation models but also offers valuable practical guidance for their\napplication in geophysical data analysis, driving innovation and advancement in\nthe field.",
      "tldr_zh": "本文全面探讨了在地球物理学中开发基础模型的工作流程、机遇和挑战。文章提出了一个完整的框架，系统地探索了将基础模型与地球物理数据结合的整个过程，包括数据收集和预处理、模型架构选择、预训练策略和模型部署。 针对地球物理数据的多样性、复杂性和物理一致性约束，论文讨论了有针对性的解决方案，并探讨了如何利用基础模型的迁移学习能力来减少对标记数据的依赖，提高计算效率，并将物理约束纳入模型训练，从而提高物理一致性和可解释性。该研究为地球物理数据分析中基础模型的应用提供了有价值的实践指导，推动了该领域的创新和进步。\n",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17384v1",
      "published_date": "2025-04-24 09:08:24 UTC",
      "updated_date": "2025-04-24 09:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:11:47.868151"
    },
    {
      "arxiv_id": "2504.17366v1",
      "title": "LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams",
      "title_zh": "LiveLongBench：攻克直播流中语音文本的长文本理解难题\n",
      "authors": [
        "Yongxuan Wu",
        "Runyu Chen",
        "Peiyu Liu",
        "Hongjin Qian"
      ],
      "abstract": "Long-context understanding poses significant challenges in natural language\nprocessing, particularly for real-world dialogues characterized by speech-based\nelements, high redundancy, and uneven information density. Although large\nlanguage models (LLMs) achieve impressive results on existing benchmarks, these\ndatasets fail to reflect the complexities of such texts, limiting their\napplicability to practical scenarios. To bridge this gap, we construct the\nfirst spoken long-text dataset, derived from live streams, designed to reflect\nthe redundancy-rich and conversational nature of real-world scenarios. We\nconstruct tasks in three categories: retrieval-dependent, reasoning-dependent,\nand hybrid. We then evaluate both popular LLMs and specialized methods to\nassess their ability to understand long-contexts in these tasks. Our results\nshow that current methods exhibit strong task-specific preferences and perform\npoorly on highly redundant inputs, with no single method consistently\noutperforming others. We propose a new baseline that better handles redundancy\nin spoken text and achieves strong performance across tasks. Our findings\nhighlight key limitations of current methods and suggest future directions for\nimproving long-context understanding. Finally, our benchmark fills a gap in\nevaluating long-context spoken language understanding and provides a practical\nfoundation for developing real-world e-commerce systems. The code and benchmark\nare available at https://github.com/Yarayx/livelongbench.",
      "tldr_zh": "LiveLongBench是一个新的长文本理解基准，专门用于评估大型语言模型(LLMs)在处理来自直播流的口语文本时的能力。该数据集模拟了真实场景中口语对话的冗余性高、信息密度不均等特点。LiveLongBench包含检索依赖、推理依赖和混合三种类型的任务，用于评估LLMs在长文本理解方面的能力。实验结果表明，现有方法在处理高冗余输入时表现不佳，且没有一种方法能够始终优于其他方法。研究人员提出了一个新的基线方法，能够更好地处理口语文本中的冗余，并在各项任务中表现出色。该基准旨在填补长文本口语理解评估的空白，并为开发实际的电子商务系统提供基础。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17366v1",
      "published_date": "2025-04-24 08:27:48 UTC",
      "updated_date": "2025-04-24 08:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:12:00.262312"
    },
    {
      "arxiv_id": "2504.17356v1",
      "title": "Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning",
      "title_zh": "理解、分治与征服：基于多智能体分层强化学习的特征子空间探索\n",
      "authors": [
        "Weiliang Zhang",
        "Xiaohan Huang",
        "Yi Du",
        "Ziyue Qiao",
        "Qingqing Long",
        "Zhen Meng",
        "Yuanchun Zhou",
        "Meng Xiao"
      ],
      "abstract": "Feature selection aims to preprocess the target dataset, find an optimal and\nmost streamlined feature subset, and enhance the downstream machine learning\ntask. Among filter, wrapper, and embedded-based approaches, the reinforcement\nlearning (RL)-based subspace exploration strategy provides a novel objective\noptimization-directed perspective and promising performance. Nevertheless, even\nwith improved performance, current reinforcement learning approaches face\nchallenges similar to conventional methods when dealing with complex datasets.\nThese challenges stem from the inefficient paradigm of using one agent per\nfeature and the inherent complexities present in the datasets. This observation\nmotivates us to investigate and address the above issue and propose a novel\napproach, namely HRLFS. Our methodology initially employs a Large Language\nModel (LLM)-based hybrid state extractor to capture each feature's mathematical\nand semantic characteristics. Based on this information, features are\nclustered, facilitating the construction of hierarchical agents for each\ncluster and sub-cluster. Extensive experiments demonstrate the efficiency,\nscalability, and robustness of our approach. Compared to contemporary or the\none-feature-one-agent RL-based approaches, HRLFS improves the downstream ML\nperformance with iterative feature subspace exploration while accelerating\ntotal run time by reducing the number of agents involved.",
      "tldr_zh": "该论文提出了一种基于多智能体分层强化学习的特征子空间探索方法HRLFS，旨在解决传统强化学习方法在复杂数据集上的特征选择问题。HRLFS首先利用大语言模型(LLM)提取特征的数学和语义特征，然后对特征进行聚类，并为每个簇和子簇构建分层智能体。通过这种方式，HRLFS能够进行迭代的特征子空间探索，提升下游机器学习任务的性能，并减少智能体数量，从而加速运行时间。实验结果表明，HRLFS在效率、可扩展性和鲁棒性方面优于现有的基于强化学习的特征选择方法。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, keywords: Automated Feature Engineering, Tabular Dataset,\n  Multi-Agent Reinforcement Learning, Feature Selection",
      "pdf_url": "http://arxiv.org/pdf/2504.17356v1",
      "published_date": "2025-04-24 08:16:36 UTC",
      "updated_date": "2025-04-24 08:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:12:11.939411"
    },
    {
      "arxiv_id": "2504.17355v1",
      "title": "Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization",
      "title_zh": "用于自动化特征转换的协作式多智能体强化学习，具有图驱动的路径优化功能\n",
      "authors": [
        "Xiaohan Huang",
        "Dongjie Wang",
        "Zhiyuan Ning",
        "Ziyue Qiao",
        "Qingqing Long",
        "Haowei Zhu",
        "Yi Du",
        "Min Wu",
        "Yuanchun Zhou",
        "Meng Xiao"
      ],
      "abstract": "Feature transformation methods aim to find an optimal mathematical\nfeature-feature crossing process that generates high-value features and\nimproves the performance of downstream machine learning tasks. Existing\nframeworks, though designed to mitigate manual costs, often treat feature\ntransformations as isolated operations, ignoring dynamic dependencies between\ntransformation steps. To address the limitations, we propose TCTO, a\ncollaborative multi-agent reinforcement learning framework that automates\nfeature engineering through graph-driven path optimization. The framework's\ncore innovation lies in an evolving interaction graph that models features as\nnodes and transformations as edges. Through graph pruning and backtracking, it\ndynamically eliminates low-impact edges, reduces redundant operations, and\nenhances exploration stability. This graph also provides full traceability to\nempower TCTO to reuse high-utility subgraphs from historical transformations.\nTo demonstrate the efficacy and adaptability of our approach, we conduct\ncomprehensive experiments and case studies, which show superior performance\nacross a range of datasets.",
      "tldr_zh": "该论文提出了一种名为TCTO的协作式多智能体强化学习框架，用于自动化特征工程，通过图驱动的路径优化寻找最优的特征转换过程。TCTO的核心创新在于构建了一个演化的交互图，将特征建模为节点，转换建模为边，通过图剪枝和回溯动态消除低影响的边，减少冗余操作，并增强探索稳定性。该图还提供完整的可追溯性，使TCTO能够重用历史转换中的高价值子图。实验结果表明，TCTO在各种数据集上表现出卓越的性能和适应性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, Keywords: Automated Feature Transformation, Tabular\n  Dataset, Reinforcement Learning",
      "pdf_url": "http://arxiv.org/pdf/2504.17355v1",
      "published_date": "2025-04-24 08:16:13 UTC",
      "updated_date": "2025-04-24 08:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:12:23.782489"
    },
    {
      "arxiv_id": "2504.17354v1",
      "title": "Data-Driven Surrogate Modeling Techniques to Predict the Effective Contact Area of Rough Surface Contact Problems",
      "title_zh": "基于数据驱动的代理建模技术预测粗糙表面接触问题的有效接触面积\n",
      "authors": [
        "Tarik Sahin",
        "Jacopo Bonari",
        "Sebastian Brandstaeter",
        "Alexander Popp"
      ],
      "abstract": "The effective contact area in rough surface contact plays a critical role in\nmulti-physics phenomena such as wear, sealing, and thermal or electrical\nconduction. Although accurate numerical methods, like the Boundary Element\nMethod (BEM), are available to compute this quantity, their high computational\ncost limits their applicability in multi-query contexts, such as uncertainty\nquantification, parameter identification, and multi-scale algorithms, where\nmany repeated evaluations are required. This study proposes a surrogate\nmodeling framework for predicting the effective contact area using\nfast-to-evaluate data-driven techniques. Various machine learning algorithms\nare trained on a precomputed dataset, where the inputs are the imposed load and\nstatistical roughness parameters, and the output is the corresponding effective\ncontact area. All models undergo hyperparameter optimization to enable fair\ncomparisons in terms of predictive accuracy and computational efficiency,\nevaluated using established quantitative metrics. Among the models, the Kernel\nRidge Regressor demonstrates the best trade-off between accuracy and\nefficiency, achieving high predictive accuracy, low prediction time, and\nminimal training overhead-making it a strong candidate for general-purpose\nsurrogate modeling. The Gaussian Process Regressor provides an attractive\nalternative when uncertainty quantification is required, although it incurs\nadditional computational cost due to variance estimation. The generalization\ncapability of the Kernel Ridge model is validated on an unseen simulation\nscenario, confirming its ability to transfer to new configurations. Database\ngeneration constitutes the dominant cost in the surrogate modeling process.\nNevertheless, the approach proves practical and efficient for multi-query\ntasks, even when accounting for this initial expense.",
      "tldr_zh": "该研究提出了一种基于数据驱动的代理模型框架，用于预测粗糙表面接触问题中的有效接触面积。该框架利用多种机器学习算法，以施加的载荷和统计粗糙度参数作为输入，预测相应的有效接触面积。通过超参数优化，Kernel Ridge Regressor 在预测精度和计算效率之间取得了最佳平衡，成为通用代理建模的有力候选者。Gaussian Process Regressor 在需要不确定性量化时提供了一种有吸引力的替代方案。实验证明，即使考虑数据库生成成本，该方法对于多查询任务也具有实用性和效率。\n",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17354v1",
      "published_date": "2025-04-24 08:15:46 UTC",
      "updated_date": "2025-04-24 08:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:12:35.904790"
    },
    {
      "arxiv_id": "2504.17346v1",
      "title": "Dual-Individual Genetic Algorithm: A Dual-Individual Approach for Efficient Training of Multi-Layer Neural Networks",
      "title_zh": "双个体遗传算法：一种用于高效训练多层神经网络的双个体方法\n",
      "authors": [
        "Tran Thuy Nga Truong",
        "Jooyong Kim"
      ],
      "abstract": "This paper introduces an enhanced Genetic Algorithm technique called\nDual-Individual Genetic Algorithm (Dual-Individual GA), which optimizes neural\nnetworks for binary image classification tasks, such as cat vs. non-cat\nclassification. The proposed method employs only two individuals for crossover,\nrepresented by two parameter sets: Leader and Follower. The Leader focuses on\nexploitation, representing the primary optimal solution at even-indexed\npositions (0, 2, 4, ...), while the Follower promotes exploration by preserving\ndiversity and avoiding premature convergence, operating at odd-indexed\npositions (1, 3, 5, ...). Leader and Follower are modeled as two phases or\nroles. The key contributions of this work are threefold: (1) a self-adaptive\nlayer dimension mechanism that eliminates the need for manual tuning of layer\narchitectures; (2) generates two parameter sets, leader and follower parameter\nsets, with 10 layer architecture configurations (5 for each set), ranked by\nPareto dominance and cost. post-optimization; and (3) demonstrated superior\nperformance compared to traditional gradient-based methods. Experimental\nresults show that the Dual-Individual GA achieves 99.04% training accuracy and\n80% testing accuracy (cost = 0.034) on a three-layer network with architecture\n[12288, 17, 4, 1], outperforming a gradient-based approach that achieves 98%\ntraining accuracy and 80% testing accuracy (cost = 0.092) on a four-layer\nnetwork with architecture [12288, 20, 7, 5, 1]. These findings highlight the\nefficiency and effectiveness of the proposed method in optimizing neural\nnetworks.",
      "tldr_zh": "本文提出了一种改进的遗传算法，称为双个体遗传算法(Dual-Individual GA)，用于优化神经网络以进行二元图像分类任务。该方法仅使用两个个体进行交叉，分别表示为Leader和Follower两个参数集。Leader专注于利用(exploitation)，代表主要的优化方案；Follower则通过保持多样性来促进探索(exploration)，避免过早收敛。该算法具有自适应层维度机制，无需手动调整层架构。实验结果表明，在猫与非猫的分类任务中，Dual-Individual GA在三层网络结构[12288, 17, 4, 1]上实现了99.04%的训练准确率和80%的测试准确率，优于传统的基于梯度的方法。\n",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17346v1",
      "published_date": "2025-04-24 08:04:08 UTC",
      "updated_date": "2025-04-24 08:04:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:12:48.155003"
    },
    {
      "arxiv_id": "2504.17331v1",
      "title": "Exploring Context-aware and LLM-driven Locomotion for Immersive Virtual Reality",
      "title_zh": "探索用于沉浸式虚拟现实的上下文感知和 LLM 驱动的移动方式\n",
      "authors": [
        "Süleyman Özdel",
        "Kadir Burak Buldu",
        "Enkelejda Kasneci",
        "Efe Bozkir"
      ],
      "abstract": "Locomotion plays a crucial role in shaping the user experience within virtual\nreality environments. In particular, hands-free locomotion offers a valuable\nalternative by supporting accessibility and freeing users from reliance on\nhandheld controllers. To this end, traditional speech-based methods often\ndepend on rigid command sets, limiting the naturalness and flexibility of\ninteraction. In this study, we propose a novel locomotion technique powered by\nlarge language models (LLMs), which allows users to navigate virtual\nenvironments using natural language with contextual awareness. We evaluate\nthree locomotion methods: controller-based teleportation, voice-based steering,\nand our language model-driven approach. Our evaluation measures include\neye-tracking data analysis, including explainable machine learning through SHAP\nanalysis as well as standardized questionnaires for usability, presence,\ncybersickness, and cognitive load to examine user attention and engagement. Our\nfindings indicate that the LLM-driven locomotion possesses comparable\nusability, presence, and cybersickness scores to established methods like\nteleportation, demonstrating its novel potential as a comfortable, natural\nlanguage-based, hands-free alternative. In addition, it enhances user attention\nwithin the virtual environment, suggesting greater engagement. Complementary to\nthese findings, SHAP analysis revealed that fixation, saccade, and\npupil-related features vary across techniques, indicating distinct patterns of\nvisual attention and cognitive processing. Overall, we state that our method\ncan facilitate hands-free locomotion in virtual spaces, especially in\nsupporting accessibility.",
      "tldr_zh": "该研究提出了一种基于大型语言模型(LLM)的上下文感知步态技术，旨在提升虚拟现实(VR)环境中的用户体验，特别是为免手持步态提供更自然和灵活的交互方式。该方法允许用户使用自然语言导航虚拟环境，克服了传统语音控制依赖于固定命令集的局限性。通过眼动追踪数据分析、SHAP分析以及标准化问卷调查，研究对比了基于控制器的传送、语音控制和LLM驱动的三种步态方法。结果表明，LLM驱动的步态在可用性、临场感和晕动症方面与传送方法相当，同时增强了用户在虚拟环境中的注意力，表明其作为一种舒适、基于自然语言的免手持替代方案具有潜力。SHAP分析揭示了不同技术在注视、扫视和瞳孔相关特征上的差异，表明视觉注意力和认知处理模式的不同。该方法能够促进虚拟空间中的免手持步态，尤其是在支持可访问性方面。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2504.17331v1",
      "published_date": "2025-04-24 07:48:09 UTC",
      "updated_date": "2025-04-24 07:48:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:13:00.696932"
    },
    {
      "arxiv_id": "2504.17315v1",
      "title": "DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model",
      "title_zh": "DIMT25@ICDAR2025：HW-TSC 基于大型视觉语言模型的端到端文档图像机器翻译系统\n",
      "authors": [
        "Zhanglin Wu",
        "Tengfei Song",
        "Ning Xie",
        "Weidong Zhang",
        "Pengfei Li",
        "Shuang Wu",
        "Chong Li",
        "Junhao Zhu",
        "Hao Yang"
      ],
      "abstract": "This paper presents the technical solution proposed by Huawei Translation\nService Center (HW-TSC) for the \"End-to-End Document Image Machine Translation\nfor Complex Layouts\" competition at the 19th International Conference on\nDocument Analysis and Recognition (DIMT25@ICDAR2025). Leveraging\nstate-of-the-art open-source large vision-language model (LVLM), we introduce a\ntraining framework that combines multi-task learning with perceptual\nchain-of-thought to develop a comprehensive end-to-end document translation\nsystem. During the inference phase, we apply minimum Bayesian decoding and\npost-processing strategies to further enhance the system's translation\ncapabilities. Our solution uniquely addresses both OCR-based and OCR-free\ndocument image translation tasks within a unified framework. This paper\nsystematically details the training methods, inference strategies, LVLM base\nmodels, training data, experimental setups, and results, demonstrating an\neffective approach to document image machine translation.",
      "tldr_zh": "本文介绍了华为翻译服务中心(HW-TSC)为ICDAR2025 \"复杂布局端到端文档图像机器翻译\" 竞赛提出的技术方案。该方案利用先进的开源大型视觉语言模型(LVLM)，结合多任务学习和感知链式思维(perceptual chain-of-thought)的训练框架，开发了一个全面的端到端文档翻译系统。在推理阶段，采用最小贝叶斯解码和后处理策略来进一步增强系统的翻译能力。该方案独特地在一个统一的框架内解决了基于OCR和无OCR的文档图像翻译任务。论文详细介绍了训练方法、推理策略、LVLM基础模型、训练数据、实验设置和结果，展示了一种有效的文档图像机器翻译方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 1 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.17315v1",
      "published_date": "2025-04-24 07:17:59 UTC",
      "updated_date": "2025-04-24 07:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:13:11.970736"
    },
    {
      "arxiv_id": "2504.17311v1",
      "title": "FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation",
      "title_zh": "FLUKE：一种语言驱动且任务无关的鲁棒性评估框架\n",
      "authors": [
        "Yulia Otmakhova",
        "Hung Thinh Truong",
        "Rahmad Mahendra",
        "Zenan Zhai",
        "Rongxin Zhu",
        "Daniel Beck",
        "Jey Han Lau"
      ],
      "abstract": "We present FLUKE (Framework for LingUistically-driven and tasK-agnostic\nrobustness Evaluation), a task-agnostic framework for assessing model\nrobustness through systematic minimal variations of test data. FLUKE introduces\ncontrolled variations across linguistic levels - from orthography to dialect\nand style varieties - and leverages large language models (LLMs) with human\nvalidation to generate modifications. We demonstrate FLUKE's utility by\nevaluating both fine-tuned models and LLMs across four diverse NLP tasks, and\nreveal that (1) the impact of linguistic variations is highly task-dependent,\nwith some tests being critical for certain tasks but irrelevant for others; (2)\nwhile LLMs have better overall robustness compared to fine-tuned models, they\nstill exhibit significant brittleness to certain linguistic variations; (3) all\nmodels show substantial vulnerability to negation modifications across most\ntasks. These findings highlight the importance of systematic robustness testing\nfor understanding model behaviors.",
      "tldr_zh": "FLUKE是一个与任务无关的框架，用于通过系统性的最小测试数据变体来评估模型的鲁棒性。它引入了跨语言层面的受控变异，从正字法到方言和风格变体，并利用大型语言模型(LLMs)和人工验证来生成修改。通过在四个不同的NLP任务中评估微调模型和LLM，FLUKE揭示了：(1)语言变异的影响高度依赖于任务；(2)虽然LLM比微调模型具有更好的整体鲁棒性，但它们仍然对某些语言变异表现出显著的脆弱性；(3)所有模型在大多数任务中都显示出对否定修改的显著脆弱性。这些发现强调了系统鲁棒性测试对于理解模型行为的重要性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17311v1",
      "published_date": "2025-04-24 07:12:37 UTC",
      "updated_date": "2025-04-24 07:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:13:24.283919"
    },
    {
      "arxiv_id": "2504.17306v1",
      "title": "Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+",
      "title_zh": "使用 DeepLabv3+ 对糖尿病视网膜病变病灶进行高级分割\n",
      "authors": [
        "Meher Boulaabi",
        "Takwa Ben Aïcha Gader",
        "Afef Kacem Echi",
        "Sameh Mbarek"
      ],
      "abstract": "To improve the segmentation of diabetic retinopathy lesions (microaneurysms,\nhemorrhages, exudates, and soft exudates), we implemented a binary segmentation\nmethod specific to each type of lesion. As post-segmentation, we combined the\nindividual model outputs into a single image to better analyze the lesion\ntypes. This approach facilitated parameter optimization and improved accuracy,\neffectively overcoming challenges related to dataset limitations and annotation\ncomplexity. Specific preprocessing steps included cropping and applying\ncontrast-limited adaptive histogram equalization to the L channel of the LAB\nimage. Additionally, we employed targeted data augmentation techniques to\nfurther refine the model's efficacy. Our methodology utilized the DeepLabv3+\nmodel, achieving a segmentation accuracy of 99%. These findings highlight the\nefficacy of innovative strategies in advancing medical image analysis,\nparticularly in the precise segmentation of diabetic retinopathy lesions. The\nIDRID dataset was utilized to validate and demonstrate the robustness of our\napproach.",
      "tldr_zh": "该研究提出了一种基于DeepLabv3+的糖尿病视网膜病变病灶（包括微动脉瘤、出血、渗出物和软性渗出物）高级分割方法。该方法针对每种病灶类型实施二元分割，并通过后处理将各个模型的输出合并为单个图像，从而优化参数并提高准确性。研究中采用了裁剪和对比度受限的自适应直方图均衡化等预处理步骤，并结合针对性的数据增强技术来提升模型效果。实验结果表明，该方法在IDRID数据集上实现了99%的分割准确率，验证了其在医学图像分析，特别是糖尿病视网膜病变病灶精确分割方面的有效性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work was accepted at the ACS/IEEE International Conference on\n  Computer Systems and Applications (AICCSA) 2024",
      "pdf_url": "http://arxiv.org/pdf/2504.17306v1",
      "published_date": "2025-04-24 07:00:38 UTC",
      "updated_date": "2025-04-24 07:00:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:13:36.264768"
    },
    {
      "arxiv_id": "2504.17304v1",
      "title": "You Are What You Bought: Generating Customer Personas for E-commerce Applications",
      "title_zh": "人如其购：为电子商务应用生成客户画像\n",
      "authors": [
        "Yimin Shi",
        "Yang Fei",
        "Shiqi Zhang",
        "Haixun Wang",
        "Xiaokui Xiao"
      ],
      "abstract": "In e-commerce, user representations are essential for various applications.\nExisting methods often use deep learning techniques to convert customer\nbehaviors into implicit embeddings. However, these embeddings are difficult to\nunderstand and integrate with external knowledge, limiting the effectiveness of\napplications such as customer segmentation, search navigation, and product\nrecommendations. To address this, our paper introduces the concept of the\ncustomer persona. Condensed from a customer's numerous purchasing histories, a\ncustomer persona provides a multi-faceted and human-readable characterization\nof specific purchase behaviors and preferences, such as Busy Parents or Bargain\nHunters.\n  This work then focuses on representing each customer by multiple personas\nfrom a predefined set, achieving readable and informative explicit user\nrepresentations. To this end, we propose an effective and efficient solution\nGPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs to infer\npersonas for customers. To reduce overhead, GPLR applies LLM-based labeling to\nonly a fraction of users and utilizes a random walk technique to predict\npersonas for the remaining customers. We further propose RevAff, which provides\nan absolute error $\\epsilon$ guarantee while improving the time complexity of\nthe exact solution by a factor of at least\n$O(\\frac{\\epsilon\\cdot|E|N}{|E|+N\\log N})$, where $N$ represents the number of\ncustomers and products, and $E$ represents the interactions between them. We\nevaluate the performance of our persona-based representation in terms of\naccuracy and robustness for recommendation and customer segmentation tasks\nusing three real-world e-commerce datasets. Most notably, we find that\nintegrating customer persona representations improves the state-of-the-art\ngraph convolution-based recommendation model by up to 12% in terms of NDCG@K\nand F1-Score@K.",
      "tldr_zh": "该论文提出了“客户角色(customer persona)”的概念，旨在为电商应用提供更易理解和整合外部知识的用户表示方法。不同于以往的隐式嵌入方法，客户角色通过总结用户的购买历史，提供多维度且可读的特征描述，例如“忙碌的父母(Busy Parents)”或“捡便宜的人(Bargain Hunters)”。论文提出了一种有效且高效的解决方案GPLR，利用预训练LLM推断客户的角色，并结合随机游走技术降低计算开销。此外，论文还提出了RevAff算法，在保证绝对误差的同时，显著降低了时间复杂度。在推荐和客户分群任务中，基于客户角色的表示方法在三个真实电商数据集上表现出优越的准确性和鲁棒性，例如，将客户角色表示集成到基于图卷积的推荐模型中，NDCG@K和F1-Score@K指标提升高达12%。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.17304v1",
      "published_date": "2025-04-24 06:59:16 UTC",
      "updated_date": "2025-04-24 06:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:13:48.581815"
    },
    {
      "arxiv_id": "2504.17295v1",
      "title": "AI-Enhanced Business Process Automation: A Case Study in the Insurance Domain Using Object-Centric Process Mining",
      "title_zh": "AI增强的业务流程自动化：一个在保险领域使用以对象为中心的流程挖掘的案例研究\n",
      "authors": [
        "Shahrzad Khayatbashi",
        "Viktor Sjölind",
        "Anders Granåker",
        "Amin Jalali"
      ],
      "abstract": "Recent advancements in Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), have enhanced organizations' ability to reengineer\nbusiness processes by automating knowledge-intensive tasks. This automation\ndrives digital transformation, often through gradual transitions that improve\nprocess efficiency and effectiveness. To fully assess the impact of such\nautomation, a data-driven analysis approach is needed - one that examines how\ntraditional and AI-enhanced process variants coexist during this transition.\nObject-Centric Process Mining (OCPM) has emerged as a valuable method that\nenables such analysis, yet real-world case studies are still needed to\ndemonstrate its applicability. This paper presents a case study from the\ninsurance sector, where an LLM was deployed in production to automate the\nidentification of claim parts, a task previously performed manually and\nidentified as a bottleneck for scalability. To evaluate this transformation, we\napply OCPM to assess the impact of AI-driven automation on process scalability.\nOur findings indicate that while LLMs significantly enhance operational\ncapacity, they also introduce new process dynamics that require further\nrefinement. This study also demonstrates the practical application of OCPM in a\nreal-world setting, highlighting its advantages and limitations.",
      "tldr_zh": "本文研究了人工智能（AI），特别是大型语言模型（LLMs）在业务流程自动化中的应用，并以保险领域为例，利用面向对象的流程挖掘（OCPM）方法评估了AI驱动的自动化对流程可扩展性的影响。该研究部署了一个LLM来自动化索赔部件识别，这是一项之前手动执行的任务，也是可扩展性的瓶颈。研究结果表明，LLM显著提高了运营能力，但也引入了新的流程动态，需要进一步完善。此外，该研究也展示了OCPM在实际场景中的应用，突出了其优势和局限性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17295v1",
      "published_date": "2025-04-24 06:43:29 UTC",
      "updated_date": "2025-04-24 06:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:14:00.303499"
    },
    {
      "arxiv_id": "2504.17282v1",
      "title": "Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning",
      "title_zh": "破解行为密码：一种用于强化学习的示能性生成方法\n",
      "authors": [
        "Lynn Cherif",
        "Flemming Kondrup",
        "David Venuto",
        "Ankit Anand",
        "Doina Precup",
        "Khimya Khetarpal"
      ],
      "abstract": "Agents that can autonomously navigate the web through a graphical user\ninterface (GUI) using a unified action space (e.g., mouse and keyboard actions)\ncan require very large amounts of domain-specific expert demonstrations to\nachieve good performance. Low sample efficiency is often exacerbated in\nsparse-reward and large-action-space environments, such as a web GUI, where\nonly a few actions are relevant in any given situation. In this work, we\nconsider the low-data regime, with limited or no access to expert behavior. To\nenable sample-efficient learning, we explore the effect of constraining the\naction space through $\\textit{intent-based affordances}$ -- i.e., considering\nin any situation only the subset of actions that achieve a desired outcome. We\npropose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$,\na method that leverages pre-trained vision-language models (VLMs) to generate\ncode that determines affordable actions through implicit intent-completion\nfunctions and using a fully-automated program generation and verification\npipeline. These programs are then used in-the-loop of a reinforcement learning\nagent to return a set of affordances given a pixel observation. By greatly\nreducing the number of actions that an agent must consider, we demonstrate on a\nwide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$\n$\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent,\n$\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of\ntasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared\nwith behavior cloning when a small number of expert demonstrations is\navailable.",
      "tldr_zh": "该论文提出了一种名为“代码即生成可供性”(CoGA)的方法，旨在提高强化学习智能体在复杂GUI环境中的样本效率。CoGA利用预训练的视觉-语言模型(VLMs)生成代码，这些代码定义了在特定情境下可行的动作(affordances)，通过隐式的意图补全函数来判断哪些动作能够达成期望的结果。该方法通过自动化的程序生成和验证流程，显著减少了智能体需要考虑的动作数量。在MiniWob++基准测试中，实验结果表明CoGA比单纯的强化学习智能体样本效率高几个数量级，并且其生成的程序可以在同类任务中泛化，甚至在少量专家演示数据的情况下，CoGA的性能可以与行为克隆相媲美。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17282v1",
      "published_date": "2025-04-24 06:20:08 UTC",
      "updated_date": "2025-04-24 06:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:14:12.364364"
    },
    {
      "arxiv_id": "2504.17277v1",
      "title": "ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders",
      "title_zh": "ExOSITO：基于辅助信息的强化学习可解释离线策略，用于重症监护病房的血液检测医嘱",
      "authors": [
        "Zongliang Ji",
        "Andre Carlos Kajdacsy-Balla Amaral",
        "Anna Goldenberg",
        "Rahul G. Krishnan"
      ],
      "abstract": "Ordering a minimal subset of lab tests for patients in the intensive care\nunit (ICU) can be challenging. Care teams must balance between ensuring the\navailability of the right information and reducing the clinical burden and\ncosts associated with each lab test order. Most in-patient settings experience\nfrequent over-ordering of lab tests, but are now aiming to reduce this burden\non both hospital resources and the environment. This paper develops a novel\nmethod that combines off-policy learning with privileged information to\nidentify the optimal set of ICU lab tests to order. Our approach, EXplainable\nOff-policy learning with Side Information for ICU blood Test Orders (ExOSITO)\ncreates an interpretable assistive tool for clinicians to order lab tests by\nconsidering both the observed and predicted future status of each patient. We\npose this problem as a causal bandit trained using offline data and a reward\nfunction derived from clinically-approved rules; we introduce a novel learning\nframework that integrates clinical knowledge with observational data to bridge\nthe gap between the optimal and logging policies. The learned policy function\nprovides interpretable clinical information and reduces costs without omitting\nany vital lab orders, outperforming both a physician's policy and prior\napproaches to this practical problem.",
      "tldr_zh": "本研究提出了一种名为ExOSITO的新方法，用于优化ICU患者的血检项目选择。ExOSITO结合了off-policy learning和特权信息，旨在减少不必要的血检，从而降低临床负担和成本。该方法将问题建模为因果bandit问题，利用离线数据和临床认可的规则来训练模型。ExOSITO集成了临床知识和观测数据，弥合了最优策略和logging策略之间的差距。实验结果表明，ExOSITO能够提供可解释的临床信息，并在不遗漏关键血检项目的前提下降低成本，优于医生策略和其他现有方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Conference on Health, Inference, and Learning (CHIL)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2504.17277v1",
      "published_date": "2025-04-24 06:07:14 UTC",
      "updated_date": "2025-04-24 06:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:14:24.294018"
    },
    {
      "arxiv_id": "2504.17264v1",
      "title": "JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning",
      "title_zh": "JurisCTC：通过跨领域迁移和对比学习增强法律判决预测\n",
      "authors": [
        "Zhaolu Kang",
        "Hongtian Cai",
        "Xiangyang Ji",
        "Jinzhe Li",
        "Nanfei Gu"
      ],
      "abstract": "In recent years, Unsupervised Domain Adaptation (UDA) has gained significant\nattention in the field of Natural Language Processing (NLP) owing to its\nability to enhance model generalization across diverse domains. However, its\napplication for knowledge transfer between distinct legal domains remains\nlargely unexplored. To address the challenges posed by lengthy and complex\nlegal texts and the limited availability of large-scale annotated datasets, we\npropose JurisCTC, a novel model designed to improve the accuracy of Legal\nJudgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC\nfacilitates effective knowledge transfer across various legal domains and\nemploys contrastive learning to distinguish samples from different domains.\nSpecifically, for the LJP task, we enable knowledge transfer between civil and\ncriminal law domains. Compared to other models and specific large language\nmodels (LLMs), JurisCTC demonstrates notable advancements, achieving peak\naccuracies of 76.59% and 78.83%, respectively.",
      "tldr_zh": "该论文提出了JurisCTC模型，旨在通过跨领域迁移学习和对比学习提升法律判决预测(LJP)的准确性。JurisCTC模型专注于解决法律文本冗长复杂以及大规模标注数据集稀缺的问题，实现了民法和刑法领域之间的有效知识迁移。该模型利用对比学习区分不同领域的样本，并在LJP任务上取得了显著进展，峰值准确率分别达到76.59%和78.83%，优于其他模型和特定的大型语言模型(LLMs)。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in International Joint Conference on Neural Networks (IJCNN)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2504.17264v1",
      "published_date": "2025-04-24 05:48:57 UTC",
      "updated_date": "2025-04-24 05:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:14:36.043130"
    },
    {
      "arxiv_id": "2504.17261v1",
      "title": "Symbolic Representation for Any-to-Any Generative Tasks",
      "title_zh": "用于任意到任意生成任务的符号表示\n",
      "authors": [
        "Jiaqi Chen",
        "Xiaoye Zhu",
        "Yue Wang",
        "Tianyang Liu",
        "Xinhui Chen",
        "Ying Chen",
        "Chak Tou Leong",
        "Yifei Ke",
        "Joseph Liu",
        "Yiwen Yuan",
        "Julian McAuley",
        "Li-jia Li"
      ],
      "abstract": "We propose a symbolic generative task description language and a\ncorresponding inference engine capable of representing arbitrary multimodal\ntasks as structured symbolic flows. Unlike conventional generative models that\nrely on large-scale training and implicit neural representations to learn\ncross-modal mappings, often at high computational cost and with limited\nflexibility, our framework introduces an explicit symbolic representation\ncomprising three core primitives: functions, parameters, and topological logic.\nLeveraging a pre-trained language model, our inference engine maps natural\nlanguage instructions directly to symbolic workflows in a training-free manner.\nOur framework successfully performs over 12 diverse multimodal generative\ntasks, demonstrating strong performance and flexibility without the need for\ntask-specific tuning. Experiments show that our method not only matches or\noutperforms existing state-of-the-art unified models in content quality, but\nalso offers greater efficiency, editability, and interruptibility. We believe\nthat symbolic task representations provide a cost-effective and extensible\nfoundation for advancing the capabilities of generative AI.",
      "tldr_zh": "该论文提出了一种符号生成任务描述语言和一个相应的推理引擎，用于将任意多模态任务表示为结构化的符号流。与依赖大规模训练和隐式神经表示的传统生成模型不同，该框架引入了包含函数、参数和拓扑逻辑的显式符号表示。利用预训练语言模型，推理引擎以无需训练的方式将自然语言指令直接映射到符号工作流。该框架成功执行了超过12个不同的多模态生成任务，展示了强大的性能和灵活性，无需针对特定任务进行调整。实验表明，该方法在内容质量上不仅与现有最先进的统一模型相匹配或超越，而且提供了更高的效率、可编辑性和可中断性。研究认为符号任务表示为提升生成式AI的能力提供了一个经济高效且可扩展的基础。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17261v1",
      "published_date": "2025-04-24 05:35:47 UTC",
      "updated_date": "2025-04-24 05:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:14:48.346761"
    },
    {
      "arxiv_id": "2504.17255v1",
      "title": "3D Deep-learning-based Segmentation of Human Skin Sweat Glands and Their 3D Morphological Response to Temperature Variations",
      "title_zh": "基于 3D 深度学习的人体皮肤汗腺分割及其对温度变化的 3D 形态响应\n",
      "authors": [
        "Shaoyu Pei",
        "Renxiong Wu",
        "Hao Zheng",
        "Lang Qin",
        "Shuaichen Lin",
        "Yuxing Gan",
        "Wenjing Huang",
        "Zhixuan Wang",
        "Mohan Qin",
        "Yong Liu",
        "Guangming Ni"
      ],
      "abstract": "Skin, the primary regulator of heat exchange, relies on sweat glands for\nthermoregulation. Alterations in sweat gland morphology play a crucial role in\nvarious pathological conditions and clinical diagnoses. Current methods for\nobserving sweat gland morphology are limited by their two-dimensional, in\nvitro, and destructive nature, underscoring the urgent need for real-time,\nnon-invasive, quantifiable technologies. We proposed a novel three-dimensional\n(3D) transformer-based multi-object segmentation framework, integrating a\nsliding window approach, joint spatial-channel attention mechanism, and\narchitectural heterogeneity between shallow and deep layers. Our proposed\nnetwork enables precise 3D sweat gland segmentation from skin volume data\ncaptured by optical coherence tomography (OCT). For the first time, subtle\nvariations of sweat gland 3D morphology in response to temperature changes,\nhave been visualized and quantified. Our approach establishes a benchmark for\nnormal sweat gland morphology and provides a real-time, non-invasive tool for\nquantifying 3D structural parameters. This enables the study of individual\nvariability and pathological changes in sweat gland structure, advancing\ndermatological research and clinical applications, including thermoregulation\nand bromhidrosis treatment.",
      "tldr_zh": "该研究提出了一种基于3D深度学习的分割框架，用于对人体皮肤汗腺进行分割，并研究其对温度变化的3D形态响应。该框架结合了基于Transformer的多目标分割、滑动窗口方法、联合空间-通道注意力机制以及浅层和深层网络之间的结构异质性，实现了从光学相干断层扫描(OCT)皮肤体积数据中精确的3D汗腺分割。研究首次可视化并量化了汗腺3D形态对温度变化的细微变化，为正常汗腺形态建立了基准，并提供了一种实时、无创的工具来量化3D结构参数。该方法能够研究汗腺结构的个体差异和病理变化，从而推进皮肤病学研究和临床应用，包括体温调节和臭汗症治疗。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.optics"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17255v1",
      "published_date": "2025-04-24 05:19:47 UTC",
      "updated_date": "2025-04-24 05:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:15:00.456097"
    },
    {
      "arxiv_id": "2504.17247v1",
      "title": "Targeted AMP generation through controlled diffusion with efficient embeddings",
      "title_zh": "通过高效嵌入和可控扩散实现靶向 AMP 生成\n",
      "authors": [
        "Diogo Soares",
        "Leon Hetzel",
        "Paulina Szymczak",
        "Fabian Theis",
        "Stephan Günnemann",
        "Ewa Szczurek"
      ],
      "abstract": "Deep learning-based antimicrobial peptide (AMP) discovery faces critical\nchallenges such as low experimental hit rates as well as the need for nuanced\ncontrollability and efficient modeling of peptide properties. To address these\nchallenges, we introduce OmegAMP, a framework that leverages a diffusion-based\ngenerative model with efficient low-dimensional embeddings, precise\ncontrollability mechanisms, and novel classifiers with drastically reduced\nfalse positive rates for candidate filtering. OmegAMP enables the targeted\ngeneration of AMPs with specific physicochemical properties, activity profiles,\nand species-specific effectiveness. Moreover, it maximizes sample diversity\nwhile ensuring faithfulness to the underlying data distribution during\ngeneration. We demonstrate that OmegAMP achieves state-of-the-art performance\nacross all stages of the AMP discovery pipeline, significantly advancing the\npotential of computational frameworks in combating antimicrobial resistance.",
      "tldr_zh": "该论文提出了OmegAMP，一个用于靶向生成抗菌肽(AMP)的框架。它利用基于扩散的生成模型，结合高效的低维嵌入、精确的可控机制和新型分类器，降低了候选肽的假阳性率。OmegAMP能够根据特定的理化性质、活性谱和物种特异性有效性，靶向生成AMP。此外，它在生成过程中最大化样本多样性，同时确保对底层数据分布的保真度。实验结果表明，OmegAMP在AMP发现流程的各个阶段都达到了最先进的性能，显著提升了计算框架在对抗抗菌素耐药性方面的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17247v1",
      "published_date": "2025-04-24 04:53:04 UTC",
      "updated_date": "2025-04-24 04:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:15:12.275612"
    },
    {
      "arxiv_id": "2504.17243v1",
      "title": "NeuralGrok: Accelerate Grokking by Neural Gradient Transformation",
      "title_zh": "NeuralGrok：通过神经梯度转换加速 Grokking 现象\n",
      "authors": [
        "Xinyu Zhou",
        "Simin Fan",
        "Martin Jaggi",
        "Jie Fu"
      ],
      "abstract": "Grokking is proposed and widely studied as an intricate phenomenon in which\ngeneralization is achieved after a long-lasting period of overfitting. In this\nwork, we propose NeuralGrok, a novel gradient-based approach that learns an\noptimal gradient transformation to accelerate the generalization of\ntransformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary\nmodule (e.g., an MLP block) in conjunction with the base model. This module\ndynamically modulates the influence of individual gradient components based on\ntheir contribution to generalization, guided by a bilevel optimization\nalgorithm. Our extensive experiments demonstrate that NeuralGrok significantly\naccelerates generalization, particularly in challenging arithmetic tasks. We\nalso show that NeuralGrok promotes a more stable training paradigm, constantly\nreducing the model's complexity, while traditional regularization methods, such\nas weight decay, can introduce substantial instability and impede\ngeneralization. We further investigate the intrinsic model complexity\nleveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that\nNeuralGrok effectively facilitates generalization by reducing the model\ncomplexity. We offer valuable insights on the grokking phenomenon of\nTransformer models, which encourages a deeper understanding of the fundamental\nprinciples governing generalization ability.",
      "tldr_zh": "本文提出了一种名为NeuralGrok的基于梯度的新方法，旨在加速Transformer模型在算术任务中的泛化能力，解决Grokking现象中长期过拟合后才能实现泛化的问题。NeuralGrok通过训练一个辅助模块（如MLP块）来动态调整梯度分量，基于其对泛化的贡献进行调制，并采用双层优化算法。实验表明，NeuralGrok显著加速了泛化过程，尤其是在具有挑战性的算术任务中。此外，NeuralGrok还能促进更稳定的训练，持续降低模型复杂度。研究还引入了一种新的绝对梯度熵（AGE）指标来衡量模型复杂度，解释了NeuralGrok通过降低模型复杂度来有效促进泛化的机制。该研究为理解Transformer模型的Grokking现象提供了有价值的见解。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, 16 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.17243v1",
      "published_date": "2025-04-24 04:41:35 UTC",
      "updated_date": "2025-04-24 04:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:15:24.344938"
    },
    {
      "arxiv_id": "2504.17219v1",
      "title": "Enhancing Variational Autoencoders with Smooth Robust Latent Encoding",
      "title_zh": "利用平滑鲁棒的潜在编码增强变分自编码器\n",
      "authors": [
        "Hyomin Lee",
        "Minseon Kim",
        "Sangwon Jang",
        "Jongheon Jeong",
        "Sung Ju Hwang"
      ],
      "abstract": "Variational Autoencoders (VAEs) have played a key role in scaling up\ndiffusion-based generative models, as in Stable Diffusion, yet questions\nregarding their robustness remain largely underexplored. Although adversarial\ntraining has been an established technique for enhancing robustness in\npredictive models, it has been overlooked for generative models due to concerns\nabout potential fidelity degradation by the nature of trade-offs between\nperformance and robustness. In this work, we challenge this presumption,\nintroducing Smooth Robust Latent VAE (SRL-VAE), a novel adversarial training\nframework that boosts both generation quality and robustness. In contrast to\nconventional adversarial training, which focuses on robustness only, our\napproach smooths the latent space via adversarial perturbations, promoting more\ngeneralizable representations while regularizing with originality\nrepresentation to sustain original fidelity. Applied as a post-training step on\npre-trained VAEs, SRL-VAE improves image robustness and fidelity with minimal\ncomputational overhead. Experiments show that SRL-VAE improves both generation\nquality, in image reconstruction and text-guided image editing, and robustness,\nagainst Nightshade attacks and image editing attacks. These results establish a\nnew paradigm, showing that adversarial training, once thought to be detrimental\nto generative models, can instead enhance both fidelity and robustness.",
      "tldr_zh": "本文提出了一种名为Smooth Robust Latent VAE (SRL-VAE) 的新型对抗训练框架，旨在提升变分自编码器 (VAE) 的生成质量和鲁棒性。与传统的侧重于鲁棒性的对抗训练不同，SRL-VAE 通过对抗扰动平滑潜在空间，促进更具泛化性的表示，同时利用原始表示进行正则化以保持原始保真度。SRL-VAE 可作为预训练 VAE 的后处理步骤，以最小的计算开销提高图像鲁棒性和保真度。实验表明，SRL-VAE 在图像重建和文本引导的图像编辑中提高了生成质量，并增强了对 Nightshade 攻击和图像编辑攻击的鲁棒性。该研究表明，对抗训练不仅不会损害生成模型，反而可以增强其保真度和鲁棒性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2504.17219v1",
      "published_date": "2025-04-24 03:17:57 UTC",
      "updated_date": "2025-04-24 03:17:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:15:36.288950"
    },
    {
      "arxiv_id": "2504.17213v1",
      "title": "MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing",
      "title_zh": "MCAF：通过多模态由粗到精注意力聚焦实现的高效的基于智能体的视频理解框架\n",
      "authors": [
        "Shiwen Cao",
        "Zhaoxing Zhang",
        "Junming Jiao",
        "Juyi Qiao",
        "Guowen Song",
        "Rong Shen"
      ],
      "abstract": "Even in the era of rapid advances in large models, video understanding,\nparticularly long videos, remains highly challenging. Compared with textual or\nimage-based information, videos commonly contain more information with\nredundancy, requiring large models to strategically allocate attention at a\nglobal level for accurate comprehension. To address this, we propose MCAF, an\nagent-based, training-free framework perform video understanding through\nMultimodal Coarse-to-fine Attention Focusing. The key innovation lies in its\nability to sense and prioritize segments of the video that are highly relevant\nto the understanding task. First, MCAF hierarchically concentrates on highly\nrelevant frames through multimodal information, enhancing the correlation\nbetween the acquired contextual information and the query. Second, it employs a\ndilated temporal expansion mechanism to mitigate the risk of missing crucial\ndetails when extracting information from these concentrated frames. In\naddition, our framework incorporates a self-reflection mechanism utilizing the\nconfidence level of the model's responses as feedback. By iteratively applying\nthese two creative focusing strategies, it adaptively adjusts attention to\ncapture highly query-connected context and thus improves response accuracy.\nMCAF outperforms comparable state-of-the-art methods on average. On the\nEgoSchema dataset, it achieves a remarkable 5% performance gain over the\nleading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms\nthe current state-of-the-art standard by 0.2% and 0.3% respectively. On the\nVideo-MME dataset, which features videos averaging nearly an hour in length,\nMCAF also outperforms other agent-based methods.",
      "tldr_zh": "该论文提出了一种名为MCAF的高效、基于智能体的视频理解框架，通过多模态粗到细的注意力聚焦(Multimodal Coarse-to-fine Attention Focusing)来提升长视频理解能力。MCAF的核心创新在于能够感知并优先处理与理解任务高度相关的视频片段。它首先通过多模态信息分层聚焦于高相关帧，增强上下文信息与查询之间的关联性；其次，采用扩张的时间扩展机制，降低提取信息时遗漏关键细节的风险。此外，该框架还融入了自反思机制，利用模型响应的置信度作为反馈。实验结果表明，MCAF在EgoSchema数据集上性能提升5%，在Next-QA和IntentQA数据集上分别超越现有技术水平0.2%和0.3%，在长视频数据集Video-MME上也优于其他基于智能体的方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17213v1",
      "published_date": "2025-04-24 02:54:40 UTC",
      "updated_date": "2025-04-24 02:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:15:48.505974"
    },
    {
      "arxiv_id": "2504.17210v1",
      "title": "Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models",
      "title_zh": "基于物理信息去噪扩散概率模型的合成潮流数据生成\n",
      "authors": [
        "Junfei Wang",
        "Darshana Upadhyay",
        "Marzia Zaman",
        "Pirathayini Srikantha"
      ],
      "abstract": "Many data-driven modules in smart grid rely on access to high-quality power\nflow data; however, real-world data are often limited due to privacy and\noperational constraints. This paper presents a physics-informed generative\nframework based on Denoising Diffusion Probabilistic Models (DDPMs) for\nsynthesizing feasible power flow data. By incorporating auxiliary training and\nphysics-informed loss functions, the proposed method ensures that the generated\ndata exhibit both statistical fidelity and adherence to power system\nfeasibility. We evaluate the approach on the IEEE 14-bus and 30-bus benchmark\nsystems, demonstrating its ability to capture key distributional properties and\ngeneralize to out-of-distribution scenarios. Comparative results show that the\nproposed model outperforms three baseline models in terms of feasibility,\ndiversity, and accuracy of statistical features. This work highlights the\npotential of integrating generative modelling into data-driven power system\napplications.",
      "tldr_zh": "该论文提出了一种基于物理信息的去噪扩散概率模型(DDPMs)的生成框架，用于合成可行的电力潮流数据。该方法通过结合辅助训练和物理信息损失函数，确保生成的数据在统计保真度和符合电力系统可行性方面均表现良好。在IEEE 14节点和30节点基准系统上的评估表明，该模型能够捕捉关键的分布特性并推广到分布外场景。对比结果表明，所提出的模型在可行性、多样性和统计特征的准确性方面优于三个基线模型。这项工作突出了将生成模型集成到数据驱动的电力系统应用中的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE SmartGridComm Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.17210v1",
      "published_date": "2025-04-24 02:53:22 UTC",
      "updated_date": "2025-04-24 02:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:16:00.124672"
    },
    {
      "arxiv_id": "2504.17198v1",
      "title": "Automatically Generating Rules of Malicious Software Packages via Large Language Model",
      "title_zh": "利用大型语言模型自动生成恶意软件包规则\n",
      "authors": [
        "XiangRui Zhang",
        "HaoYu Chen",
        "Yongzhong He",
        "Wenjia Niu",
        "Qiang Li"
      ],
      "abstract": "Today's security tools predominantly rely on predefined rules crafted by\nexperts, making them poorly adapted to the emergence of software supply chain\nattacks. To tackle this limitation, we propose a novel tool, RuleLLM, which\nleverages large language models (LLMs) to automate rule generation for OSS\necosystems. RuleLLM extracts metadata and code snippets from malware as its\ninput, producing YARA and Semgrep rules that can be directly deployed in\nsoftware development. Specifically, the rule generation task involves three\nsubtasks: crafting rules, refining rules, and aligning rules. To validate\nRuleLLM's effectiveness, we implemented a prototype system and conducted\nexperiments on the dataset of 1,633 malicious packages. The results are\npromising that RuleLLM generated 763 rules (452 YARA and 311 Semgrep) with a\nprecision of 85.2\\% and a recall of 91.8\\%, outperforming state-of-the-art\n(SOTA) tools and scored-based approaches. We further analyzed generated rules\nand proposed a rule taxonomy: 11 categories and 38 subcategories.",
      "tldr_zh": "该论文提出了一种名为RuleLLM的新工具，利用大型语言模型(LLMs)自动生成恶意软件软件包的规则，以应对软件供应链攻击。RuleLLM从恶意软件中提取元数据和代码片段作为输入，生成可直接部署在软件开发中的YARA和Semgrep规则。RuleLLM通过规则生成、规则细化和规则对齐三个子任务实现自动化规则生成。实验结果表明，RuleLLM在包含1633个恶意软件包的数据集上生成了763条规则（452条YARA规则和311条Semgrep规则），精度为85.2%，召回率为91.8%，优于现有技术(SOTA)工具和基于评分的方法。此外，论文还分析了生成的规则，并提出了一个包含11个类别和38个子类别的规则分类法。\n",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "14 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.17198v1",
      "published_date": "2025-04-24 02:15:45 UTC",
      "updated_date": "2025-04-24 02:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:16:12.350565"
    },
    {
      "arxiv_id": "2504.17180v1",
      "title": "We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback",
      "title_zh": "我们将在后期修复：利用神经符号反馈改进文本到视频的生成\n",
      "authors": [
        "Minkyu Choi",
        "S P Sharan",
        "Harsh Goel",
        "Sahil Shah",
        "Sandeep Chinchali"
      ],
      "abstract": "Current text-to-video (T2V) generation models are increasingly popular due to\ntheir ability to produce coherent videos from textual prompts. However, these\nmodels often struggle to generate semantically and temporally consistent videos\nwhen dealing with longer, more complex prompts involving multiple objects or\nsequential events. Additionally, the high computational costs associated with\ntraining or fine-tuning make direct improvements impractical. To overcome these\nlimitations, we introduce \\(\\projectname\\), a novel zero-training video\nrefinement pipeline that leverages neuro-symbolic feedback to automatically\nenhance video generation, achieving superior alignment with the prompts. Our\napproach first derives the neuro-symbolic feedback by analyzing a formal video\nrepresentation and pinpoints semantically inconsistent events, objects, and\ntheir corresponding frames. This feedback then guides targeted edits to the\noriginal video. Extensive empirical evaluations on both open-source and\nproprietary T2V models demonstrate that \\(\\projectname\\) significantly enhances\ntemporal and logical alignment across diverse prompts by almost $40\\%$.",
      "tldr_zh": "本文提出了一种名为“We'll Fix it in Post”的零训练视频优化流程，旨在提升文本到视频(T2V)生成模型的性能，尤其是在处理复杂、长文本提示时语义和时间一致性问题。该方法通过神经符号反馈，分析视频的正式表示，识别语义不一致的事件、对象及其对应帧。然后，利用这些反馈信息对原始视频进行针对性编辑。实验结果表明，该方法能够显著提高多种T2V模型在不同提示下的时间一致性和逻辑对齐，提升幅度接近40%。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17180v1",
      "published_date": "2025-04-24 01:34:12 UTC",
      "updated_date": "2025-04-24 01:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:16:24.183756"
    },
    {
      "arxiv_id": "2504.17179v1",
      "title": "AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models",
      "title_zh": "AUTHENTICATION：使用对抗引导扩散模型识别自动驾驶车辆感知系统中的罕见故障模式\n",
      "authors": [
        "Mohammad Zarei",
        "Melanie A Jutras",
        "Eliana Evans",
        "Mike Tan",
        "Omid Aaramoon"
      ],
      "abstract": "Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately\ndetect objects and interpret their surroundings. However, even when trained\nusing millions of miles of real-world data, AVs are often unable to detect rare\nfailure modes (RFMs). The problem of RFMs is commonly referred to as the\n\"long-tail challenge\", due to the distribution of data including many instances\nthat are very rarely seen. In this paper, we present a novel approach that\nutilizes advanced generative and explainable AI techniques to aid in\nunderstanding RFMs. Our methods can be used to enhance the robustness and\nreliability of AVs when combined with both downstream model training and\ntesting. We extract segmentation masks for objects of interest (e.g., cars) and\ninvert them to create environmental masks. These masks, combined with carefully\ncrafted text prompts, are fed into a custom diffusion model. We leverage the\nStable Diffusion inpainting model guided by adversarial noise optimization to\ngenerate images containing diverse environments designed to evade object\ndetection models and expose vulnerabilities in AI systems. Finally, we produce\nnatural language descriptions of the generated RFMs that can guide developers\nand policymakers to improve the safety and reliability of AV systems.",
      "tldr_zh": "该论文提出了一种新方法，利用对抗引导的扩散模型来识别自动驾驶汽车感知系统中罕见的故障模式(RFMs)，即“长尾挑战”。通过提取目标物体的分割掩码并反转为环境掩码，结合精心设计的文本提示，输入定制的扩散模型，利用Stable Diffusion的图像修复模型和对抗噪声优化，生成旨在逃避目标检测模型并暴露AI系统漏洞的图像。最终，生成RFMs的自然语言描述，以指导开发者和政策制定者提高AV系统的安全性和可靠性。该方法旨在增强AV的鲁棒性和可靠性，解决AV在处理罕见场景时的挑战。\n",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO",
        "68T45, 68T05 68T45, 68T05 68T45, 68T05",
        "I.2.6; I.2.10; I.4.8"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 10 figures. Accepted to IEEE Conference on Artificial\n  Intelligence (CAI), 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.17179v1",
      "published_date": "2025-04-24 01:31:13 UTC",
      "updated_date": "2025-04-24 01:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:16:36.325608"
    },
    {
      "arxiv_id": "2504.17170v1",
      "title": "Improving Human-Autonomous Vehicle Interaction in Complex Systems",
      "title_zh": "改进复杂系统中人与自动驾驶汽车的交互\n",
      "authors": [
        "Robert Kaufman"
      ],
      "abstract": "Unresolved questions about how autonomous vehicles (AVs) should meet the\ninformational needs of riders hinder real-world adoption. Complicating our\nability to satisfy rider needs is that different people, goals, and driving\ncontexts have different criteria for what constitutes interaction success.\nUnfortunately, most human-AV research and design today treats all people and\nsituations uniformly. It is crucial to understand how an AV should communicate\nto meet rider needs, and how communications should change when the human-AV\ncomplex system changes. I argue that understanding the relationships between\ndifferent aspects of the human-AV system can help us build improved and\nadaptable AV communications. I support this argument using three empirical\nstudies. First, I identify optimal communication strategies that enhance\ndriving performance, confidence, and trust for learning in extreme driving\nenvironments. Findings highlight the need for task-sensitive,\nmodality-appropriate communications tuned to learner cognitive limits and\ngoals. Next, I highlight the consequences of deploying faulty communication\nsystems and demonstrate the need for context-sensitive communications. Third, I\nuse machine learning (ML) to illuminate personal factors predicting trust in\nAVs, emphasizing the importance of tailoring designs to individual traits and\nconcerns. Together, this dissertation supports the necessity of transparent,\nadaptable, and personalized AV systems that cater to individual needs, goals,\nand contextual demands. By considering the complex system within which human-AV\ninteractions occur, we can deliver valuable insights for designers,\nresearchers, and policymakers. This dissertation also provides a concrete\ndomain to study theories of human-machine joint action and situational\nawareness, and can be used to guide future human-AI interaction research.\n[shortened for arxiv]",
      "tldr_zh": "该论文探讨了自动驾驶车辆(AVs)如何更好地满足乘客的信息需求，从而促进其现实应用。研究指出，不同个体、目标和驾驶环境对交互成功的标准不同，因此需要理解人-AV复杂系统各方面之间的关系，以构建改进和可适应的AV通信系统。通过三项实证研究，论文揭示了在极端驾驶环境中，任务敏感、模式适当且针对学习者认知能力和目标进行调整的通信策略的重要性；强调了部署错误通信系统的后果以及上下文敏感通信的必要性；并利用机器学习揭示了预测对AV信任的个人因素，强调了个性化设计的重要性。研究结果表明，透明、适应性强且个性化的AV系统能够满足个体需求、目标和情境需求，为设计师、研究人员和政策制定者提供了有价值的见解，并为未来人机交互研究提供了指导。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "PhD Dissertation from University of California, San Diego; 175 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.17170v1",
      "published_date": "2025-04-24 01:09:51 UTC",
      "updated_date": "2025-04-24 01:09:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:16:48.699240"
    },
    {
      "arxiv_id": "2504.17162v1",
      "title": "A Comprehensive Review on RNA Subcellular Localization Prediction",
      "title_zh": "RNA亚细胞定位预测的综合综述\n",
      "authors": [
        "Cece Zhang",
        "Xuehuan Zhu",
        "Nick Peterson",
        "Jieqiong Wang",
        "Shibiao Wan"
      ],
      "abstract": "The subcellular localization of RNAs, including long non-coding RNAs\n(lncRNAs), messenger RNAs (mRNAs), microRNAs (miRNAs) and other smaller RNAs,\nplays a critical role in determining their biological functions. For instance,\nlncRNAs are predominantly associated with chromatin and act as regulators of\ngene transcription and chromatin structure, while mRNAs are distributed across\nthe nucleus and cytoplasm, facilitating the transport of genetic information\nfor protein synthesis. Understanding RNA localization sheds light on processes\nlike gene expression regulation with spatial and temporal precision. However,\ntraditional wet lab methods for determining RNA localization, such as in situ\nhybridization, are often time-consuming, resource-demanding, and costly. To\novercome these challenges, computational methods leveraging artificial\nintelligence (AI) and machine learning (ML) have emerged as powerful\nalternatives, enabling large-scale prediction of RNA subcellular localization.\nThis paper provides a comprehensive review of the latest advancements in\nAI-based approaches for RNA subcellular localization prediction, covering\nvarious RNA types and focusing on sequence-based, image-based, and hybrid\nmethodologies that combine both data types. We highlight the potential of these\nmethods to accelerate RNA research, uncover molecular pathways, and guide\ntargeted disease treatments. Furthermore, we critically discuss the challenges\nin AI/ML approaches for RNA subcellular localization, such as data scarcity and\nlack of benchmarks, and opportunities to address them. This review aims to\nserve as a valuable resource for researchers seeking to develop innovative\nsolutions in the field of RNA subcellular localization and beyond.",
      "tldr_zh": "RNA的亚细胞定位对其生物功能至关重要，例如lncRNA主要与染色质相关并调控基因转录，而mRNA分布于细胞核和细胞质中促进蛋白质合成。传统湿实验方法确定RNA定位耗时且成本高昂。因此，本文综述了基于人工智能(AI)和机器学习(ML)的RNA亚细胞定位预测的最新进展，涵盖各种RNA类型，重点关注基于序列、基于图像以及结合两者的混合方法。文章还讨论了AI/ML方法在RNA亚细胞定位预测中面临的挑战，例如数据稀缺和缺乏基准，并展望了未来机遇，旨在为研究人员在该领域开发创新解决方案提供有价值的资源。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.GN",
        "q-bio.SC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17162v1",
      "published_date": "2025-04-24 00:47:31 UTC",
      "updated_date": "2025-04-24 00:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:17:00.354254"
    },
    {
      "arxiv_id": "2504.17160v1",
      "title": "OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection",
      "title_zh": "我们有必要讨论权重衰减：一种检测过拟合的新视角\n",
      "authors": [
        "Alberto Fernández-Hernández",
        "Jose I. Mestre",
        "Manuel F. Dolz",
        "Jose Duato",
        "Enrique S. Quintana-Ortí"
      ],
      "abstract": "We introduce the Overfitting-Underfitting Indicator (OUI), a novel tool for\nmonitoring the training dynamics of Deep Neural Networks (DNNs) and identifying\noptimal regularization hyperparameters. Specifically, we validate that OUI can\neffectively guide the selection of the Weight Decay (WD) hyperparameter by\nindicating whether a model is overfitting or underfitting during training\nwithout requiring validation data. Through experiments on DenseNet-BC-100 with\nCIFAR- 100, EfficientNet-B0 with TinyImageNet and ResNet-34 with ImageNet-1K,\nwe show that maintaining OUI within a prescribed interval correlates strongly\nwith improved generalization and validation scores. Notably, OUI converges\nsignificantly faster than traditional metrics such as loss or accuracy,\nenabling practitioners to identify optimal WD (hyperparameter) values within\nthe early stages of training. By leveraging OUI as a reliable indicator, we can\ndetermine early in training whether the chosen WD value leads the model to\nunderfit the training data, overfit, or strike a well-balanced trade-off that\nmaximizes validation scores. This enables more precise WD tuning for optimal\nperformance on the tested datasets and DNNs. All code for reproducing these\nexperiments is available at https://github.com/AlbertoFdezHdez/OUI.",
      "tldr_zh": "该论文提出了一种新的过拟合-欠拟合指标(Overfitting-Underfitting Indicator, OUI)，用于监测深度神经网络(DNNs)的训练动态并识别最佳正则化超参数，特别是权重衰减(Weight Decay, WD)。研究验证了OUI能够有效指导WD超参数的选择，无需验证数据即可判断模型在训练过程中是过拟合还是欠拟合。在DenseNet、EfficientNet和ResNet等模型以及CIFAR-100、TinyImageNet和ImageNet-1K等数据集上的实验表明，将OUI维持在规定区间内与泛化能力和验证分数显著相关。OUI比传统指标如损失或准确率收敛速度更快，有助于在训练早期识别最佳WD值，从而实现更精确的WD调整并优化模型性能。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.17160v1",
      "published_date": "2025-04-24 00:41:59 UTC",
      "updated_date": "2025-04-24 00:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-26T02:17:12.419766"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 71,
  "processed_papers_count": 71,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-04-26T02:18:50.930421"
}