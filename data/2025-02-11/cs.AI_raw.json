[
  {
    "arxiv_id": "2502.08021v2",
    "title": "Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol",
    "authors": [
      "Pai Liu",
      "Lingfeng Zhao",
      "Shivangi Agarwal",
      "Jinghan Liu",
      "Audrey Huang",
      "Philip Amortila",
      "Nan Jiang"
    ],
    "abstract": "Holdout validation and hyperparameter tuning from data is a long-standing\nproblem in offline reinforcement learning (RL). A standard framework is to use\noff-policy evaluation (OPE) methods to evaluate and select the policies, but\nOPE either incurs exponential variance (e.g., importance sampling) or has\nhyperparameters on their own (e.g., FQE and model-based). In this work we focus\non hyperparameter tuning for OPE itself, which is even more under-investigated.\nConcretely, we select among candidate value functions (\"model-free\") or\ndynamics (\"model-based\") to best assess the performance of a target policy. We\ndevelop: (1) new model-free and model-based selectors with theoretical\nguarantees, and (2) a new experimental protocol for empirically evaluating\nthem. Compared to the model-free protocol in prior works, our new protocol\nallows for more stable generation and better control of candidate value\nfunctions in an optimization-free manner, and evaluation of model-free and\nmodel-based methods alike. We exemplify the protocol on Gym-Hopper, and find\nthat our new model-free selector, LSTD-Tournament, demonstrates promising\nempirical performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08021v2",
    "published_date": "2025-02-11 23:40:55 UTC",
    "updated_date": "2025-05-16 02:18:19 UTC"
  },
  {
    "arxiv_id": "2502.08020v2",
    "title": "Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding",
    "authors": [
      "Ziyao Wang",
      "Muneeza Azmat",
      "Ang Li",
      "Raya Horesh",
      "Mikhail Yurochkin"
    ],
    "abstract": "Large Language Models (LLMs) often excel in specific domains but fall short\nin others due to the limitations of their training. Thus, enabling LLMs to\nsolve problems collaboratively by integrating their complementary knowledge\npromises to improve their performance across domains. To realize this\npotential, we introduce a novel Collaborative Speculative Decoding (CoSD)\nalgorithm that enables efficient LLM knowledge fusion at test time without\nrequiring additional model training. CoSD employs a draft model to generate\ninitial sequences and an easy-to-learn rule or decision tree to decide when to\ninvoke an assistant model to improve these drafts. CoSD not only enhances\nknowledge fusion but also improves inference efficiency, is transferable across\ndomains and models, and offers greater explainability. Experimental results\ndemonstrate that CoSD improves accuracy by up to 10\\% across benchmarks\ncompared to existing methods, providing a scalable and effective solution for\nLLM-based applications",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08020v2",
    "published_date": "2025-02-11 23:40:53 UTC",
    "updated_date": "2025-03-19 16:26:10 UTC"
  },
  {
    "arxiv_id": "2502.08011v2",
    "title": "Training-Free Safe Denoisers for Safe Use of Diffusion Models",
    "authors": [
      "Mingyu Kim",
      "Dongjun Kim",
      "Amman Yusuf",
      "Stefano Ermon",
      "Mi Jung Park"
    ],
    "abstract": "There is growing concern over the safety of powerful diffusion models (DMs),\nas they are often misused to produce inappropriate, not-safe-for-work (NSFW)\ncontent or generate copyrighted material or data of individuals who wish to be\nforgotten. Many existing methods tackle these issues by heavily relying on\ntext-based negative prompts or extensively retraining DMs to eliminate certain\nfeatures or samples. In this paper, we take a radically different approach,\ndirectly modifying the sampling trajectory by leveraging a negation set (e.g.,\nunsafe images, copyrighted data, or datapoints needed to be excluded) to avoid\nspecific regions of data distribution, without needing to retrain or fine-tune\nDMs. We formally derive the relationship between the expected denoised samples\nthat are safe and those that are not safe, leading to our $\\textit{safe}$\ndenoiser which ensures its final samples are away from the area to be negated.\nInspired by the derivation, we develop a practical algorithm that successfully\nproduces high-quality samples while avoiding negation areas of the data\ndistribution in text-conditional, class-conditional, and unconditional image\ngeneration scenarios. These results hint at the great potential of our\ntraining-free safe denoiser for using DMs more safely.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.08011v2",
    "published_date": "2025-02-11 23:14:39 UTC",
    "updated_date": "2025-02-13 02:01:58 UTC"
  },
  {
    "arxiv_id": "2502.08006v2",
    "title": "Greed is Good: A Unifying Perspective on Guided Generation",
    "authors": [
      "Zander W. Blasingame",
      "Chen Liu"
    ],
    "abstract": "Training-free guided generation is a widely used and powerful technique that\nallows the end user to exert further control over the generative process of\nflow/diffusion models. Generally speaking, two families of techniques have\nemerged for solving this problem for gradient-based guidance: namely, posterior\nguidance (i.e., guidance via projecting the current sample to the target\ndistribution via the target prediction model) and end-to-end guidance (i.e.,\nguidance by performing backpropagation throughout the entire ODE solve). In\nthis work, we show that these two seemingly separate families can actually be\nunified by looking at posterior guidance as a greedy strategy of end-to-end\nguidance. We explore the theoretical connections between these two families and\nprovide an in-depth theoretical of these two techniques relative to the\ncontinuous ideal gradients. Motivated by this analysis we then show a method\nfor interpolating between these two families enabling a trade-off between\ncompute and accuracy of the guidance gradients. We then validate this work on\nseveral inverse image problems and property-guided molecular generation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Revised preprint with numerical experiments",
    "pdf_url": "http://arxiv.org/pdf/2502.08006v2",
    "published_date": "2025-02-11 23:05:16 UTC",
    "updated_date": "2025-05-19 17:57:30 UTC"
  },
  {
    "arxiv_id": "2502.07987v2",
    "title": "Universal Adversarial Attack on Aligned Multimodal LLMs",
    "authors": [
      "Temurbek Rahmatullaev",
      "Polina Druzhinina",
      "Matvey Mikhalchuk",
      "Andrey Kuznetsov",
      "Anton Razzhigaev"
    ],
    "abstract": "We propose a universal adversarial attack on multimodal Large Language Models\n(LLMs) that leverages a single optimized image to override alignment safeguards\nacross diverse queries and even multiple models. By backpropagating through the\nvision encoder and language head, we craft a synthetic image that forces the\nmodel to respond with a targeted phrase (e.g., ''Sure, here it is'') or\notherwise unsafe content-even for harmful prompts. In experiments on the\nSafeBench benchmark, our method achieves significantly higher attack success\nrates than existing baselines, including text-only universal prompts (e.g., up\nto 93% on certain models). We further demonstrate cross-model transferability\nby training on several multimodal LLMs simultaneously and testing on unseen\narchitectures. Additionally, a multi-answer variant of our approach produces\nmore natural-sounding (yet still malicious) responses. These findings\nunderscore critical vulnerabilities in current multimodal alignment and call\nfor more robust adversarial defenses. We will release code and datasets under\nthe Apache-2.0 license. Warning: some content generated by Multimodal LLMs in\nthis paper may be offensive to some readers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Added an affiliation",
    "pdf_url": "http://arxiv.org/pdf/2502.07987v2",
    "published_date": "2025-02-11 22:07:47 UTC",
    "updated_date": "2025-02-13 06:40:14 UTC"
  },
  {
    "arxiv_id": "2502.07985v2",
    "title": "MetaSC: Test-Time Safety Specification Optimization for Language Models",
    "authors": [
      "VÃ­ctor Gallego"
    ],
    "abstract": "We propose a novel dynamic safety framework that optimizes language model\n(LM) safety reasoning at inference time without modifying model weights.\nBuilding on recent advances in self-critique methods, our approach leverages a\nmeta-critique mechanism that iteratively updates safety prompts-termed\nspecifications-to drive the critique and revision process adaptively. This\ntest-time optimization not only improves performance against adversarial\njailbreak requests but also in diverse general safety-related tasks, such as\navoiding moral harm or pursuing honest responses. Our empirical evaluations\nacross several language models demonstrate that dynamically optimized safety\nprompts yield significantly higher safety scores compared to fixed system\nprompts and static self-critique defenses. Code released at\nhttps://github.com/vicgalle/meta-self-critique.git .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at ICLR 2025 Workshop on Foundation Models in the Wild",
    "pdf_url": "http://arxiv.org/pdf/2502.07985v2",
    "published_date": "2025-02-11 22:06:25 UTC",
    "updated_date": "2025-04-07 09:15:30 UTC"
  },
  {
    "arxiv_id": "2502.07982v1",
    "title": "Deep Semantic Graph Learning via LLM based Node Enhancement",
    "authors": [
      "Chuanqi Shi",
      "Yiyi Tao",
      "Hang Zhang",
      "Lun Wang",
      "Shaoshuai Du",
      "Yixian Shen",
      "Yanxin Shen"
    ],
    "abstract": "Graph learning has attracted significant attention due to its widespread\nreal-world applications. Current mainstream approaches rely on text node\nfeatures and obtain initial node embeddings through shallow embedding learning\nusing GNNs, which shows limitations in capturing deep textual semantics. Recent\nadvances in Large Language Models (LLMs) have demonstrated superior\ncapabilities in understanding text semantics, transforming traditional text\nfeature processing. This paper proposes a novel framework that combines Graph\nTransformer architecture with LLM-enhanced node features. Specifically, we\nleverage LLMs to generate rich semantic representations of text nodes, which\nare then processed by a multi-head self-attention mechanism in the Graph\nTransformer to capture both local and global graph structural information. Our\nmodel utilizes the Transformer's attention mechanism to dynamically aggregate\nneighborhood information while preserving the semantic richness provided by LLM\nembeddings. Experimental results demonstrate that the LLM-enhanced node\nfeatures significantly improve the performance of graph learning models on node\nclassification tasks. This approach shows promising results across multiple\ngraph learning tasks, offering a practical direction for combining graph\nnetworks with language models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07982v1",
    "published_date": "2025-02-11 21:55:46 UTC",
    "updated_date": "2025-02-11 21:55:46 UTC"
  },
  {
    "arxiv_id": "2502.07980v1",
    "title": "CIRCUIT: A Benchmark for Circuit Interpretation and Reasoning Capabilities of LLMs",
    "authors": [
      "Lejla Skelic",
      "Yan Xu",
      "Matthew Cox",
      "Wenjie Lu",
      "Tao Yu",
      "Ruonan Han"
    ],
    "abstract": "The role of Large Language Models (LLMs) has not been extensively explored in\nanalog circuit design, which could benefit from a reasoning-based approach that\ntranscends traditional optimization techniques. In particular, despite their\ngrowing relevance, there are no benchmarks to assess LLMs' reasoning capability\nabout circuits. Therefore, we created the CIRCUIT dataset consisting of 510\nquestion-answer pairs spanning various levels of analog-circuit-related\nsubjects. The best-performing model on our dataset, GPT-4o, achieves 48.04%\naccuracy when evaluated on the final numerical answer. To evaluate the\nrobustness of LLMs on our dataset, we introduced a unique feature that enables\nunit-test-like evaluation by grouping questions into unit tests. In this case,\nGPT-4o can only pass 27.45% of the unit tests, highlighting that the most\nadvanced LLMs still struggle with understanding circuits, which requires\nmulti-level reasoning, particularly when involving circuit topologies. This\ncircuit-specific benchmark highlights LLMs' limitations, offering valuable\ninsights for advancing their application in analog integrated circuit design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07980v1",
    "published_date": "2025-02-11 21:53:48 UTC",
    "updated_date": "2025-02-11 21:53:48 UTC"
  },
  {
    "arxiv_id": "2502.07974v1",
    "title": "From Hazard Identification to Controller Design: Proactive and LLM-Supported Safety Engineering for ML-Powered Systems",
    "authors": [
      "Yining Hong",
      "Christopher S. Timperley",
      "Christian KÃ¤stner"
    ],
    "abstract": "Machine learning (ML) components are increasingly integrated into software\nproducts, yet their complexity and inherent uncertainty often lead to\nunintended and hazardous consequences, both for individuals and society at\nlarge. Despite these risks, practitioners seldom adopt proactive approaches to\nanticipate and mitigate hazards before they occur. Traditional safety\nengineering approaches, such as Failure Mode and Effects Analysis (FMEA) and\nSystem Theoretic Process Analysis (STPA), offer systematic frameworks for early\nrisk identification but are rarely adopted. This position paper advocates for\nintegrating hazard analysis into the development of any ML-powered software\nproduct and calls for greater support to make this process accessible to\ndevelopers. By using large language models (LLMs) to partially automate a\nmodified STPA process with human oversight at critical steps, we expect to\naddress two key challenges: the heavy dependency on highly experienced safety\nengineering experts, and the time-consuming, labor-intensive nature of\ntraditional hazard analysis, which often impedes its integration into\nreal-world development workflows. We illustrate our approach with a running\nexample, demonstrating that many seemingly unanticipated issues can, in fact,\nbe anticipated.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at the International Conference on AI\n  Engineering (CAIN) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07974v1",
    "published_date": "2025-02-11 21:37:19 UTC",
    "updated_date": "2025-02-11 21:37:19 UTC"
  },
  {
    "arxiv_id": "2502.07972v3",
    "title": "Training Sparse Mixture Of Experts Text Embedding Models",
    "authors": [
      "Zach Nussbaum",
      "Brandon Duderstadt"
    ],
    "abstract": "Transformer-based text embedding models have improved their performance on\nbenchmarks like MIRACL and BEIR by increasing their parameter counts. However,\nthis scaling approach introduces significant deployment challenges, including\nincreased inference latency and memory usage. These challenges are particularly\nsevere in retrieval-augmented generation (RAG) applications, where large\nmodels' increased memory requirements constrain dataset ingestion capacity, and\ntheir higher latency directly impacts query-time performance. While causal\nlanguage models have addressed similar efficiency challenges using Mixture of\nExperts (MoE) architectures, this approach hasn't been successfully adapted to\nthe general text embedding setting. In this paper, we introduce Nomic Embed v2,\nthe first general purpose MoE text embedding model. Our model outperforms\nmodels in the same parameter class on both monolingual and multilingual\nbenchmarks while also maintaining competitive performance with models twice its\nsize. We open-source all code, models, and evaluation data to ensure full\nreproducibility of our training pipeline at\n\\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07972v3",
    "published_date": "2025-02-11 21:36:31 UTC",
    "updated_date": "2025-03-09 19:39:00 UTC"
  },
  {
    "arxiv_id": "2502.07971v1",
    "title": "ReTreever: Tree-based Coarse-to-Fine Representations for Retrieval",
    "authors": [
      "Shubham Gupta",
      "Zichao Li",
      "Tianyi Chen",
      "Cem Subakan",
      "Siva Reddy",
      "Perouz Taslakian",
      "Valentina Zantedeschi"
    ],
    "abstract": "Document retrieval is a core component of question-answering systems, as it\nenables conditioning answer generation on new and large-scale corpora. While\neffective, the standard practice of encoding documents into high-dimensional\nembeddings for similarity search entails large memory and compute footprints,\nand also makes it hard to inspect the inner workings of the system. In this\npaper, we propose a tree-based method for organizing and representing reference\ndocuments at various granular levels, which offers the flexibility to balance\ncost and utility, and eases the inspection of the corpus content and retrieval\noperations. Our method, called ReTreever, jointly learns a routing function per\ninternal node of a binary tree such that query and reference documents are\nassigned to similar tree branches, hence directly optimizing for retrieval\nperformance. Our evaluations show that ReTreever generally preserves full\nrepresentation accuracy. Its hierarchical structure further provides strong\ncoarse representations and enhances transparency by indirectly learning\nmeaningful semantic groupings. Among hierarchical retrieval methods, ReTreever\nachieves the best retrieval accuracy at the lowest latency, proving that this\nfamily of techniques can be viable in practical applications.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "I.2; I.7; E.2; H.3"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07971v1",
    "published_date": "2025-02-11 21:35:13 UTC",
    "updated_date": "2025-02-11 21:35:13 UTC"
  },
  {
    "arxiv_id": "2502.07968v1",
    "title": "Generative Risk Minimization for Out-of-Distribution Generalization on Graphs",
    "authors": [
      "Song Wang",
      "Zhen Tan",
      "Yaochen Zhu",
      "Chuxu Zhang",
      "Jundong Li"
    ],
    "abstract": "Out-of-distribution (OOD) generalization on graphs aims at dealing with\nscenarios where the test graph distribution differs from the training graph\ndistributions. Compared to i.i.d. data like images, the OOD generalization\nproblem on graph-structured data remains challenging due to the non-i.i.d.\nproperty and complex structural information on graphs. Recently, several works\non graph OOD generalization have explored extracting invariant subgraphs that\nshare crucial classification information across different distributions.\nNevertheless, such a strategy could be suboptimal for entirely capturing the\ninvariant information, as the extraction of discrete structures could\npotentially lead to the loss of invariant information or the involvement of\nspurious information. In this paper, we propose an innovative framework, named\nGenerative Risk Minimization (GRM), designed to generate an invariant subgraph\nfor each input graph to be classified, instead of extraction. To address the\nchallenge of optimization in the absence of optimal invariant subgraphs (i.e.,\nground truths), we derive a tractable form of the proposed GRM objective by\nintroducing a latent causal variable, and its effectiveness is validated by our\ntheoretical analysis. We further conduct extensive experiments across a variety\nof real-world graph datasets for both node-level and graph-level OOD\ngeneralization, and the results demonstrate the superiority of our framework\nGRM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "TMLR 02/2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07968v1",
    "published_date": "2025-02-11 21:24:13 UTC",
    "updated_date": "2025-02-11 21:24:13 UTC"
  },
  {
    "arxiv_id": "2502.07963v3",
    "title": "Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?",
    "authors": [
      "Hye Sun Yun",
      "Karen Y. C. Zhang",
      "Ramez Kouzy",
      "Iain J. Marshall",
      "Junyi Jessy Li",
      "Byron C. Wallace"
    ],
    "abstract": "Medical research faces well-documented challenges in translating novel\ntreatments into clinical practice. Publishing incentives encourage researchers\nto present \"positive\" findings, even when empirical results are equivocal.\nConsequently, it is well-documented that authors often spin study results,\nespecially in article abstracts. Such spin can influence clinician\ninterpretation of evidence and may affect patient care decisions. In this\nstudy, we ask whether the interpretation of trial results offered by Large\nLanguage Models (LLMs) is similarly affected by spin. This is important since\nLLMs are increasingly being used to trawl through and synthesize published\nmedical evidence. We evaluated 22 LLMs and found that they are across the board\nmore susceptible to spin than humans. They might also propagate spin into their\noutputs: We find evidence, e.g., that LLMs implicitly incorporate spin into\nplain language summaries that they generate. We also find, however, that LLMs\nare generally capable of recognizing spin, and can be prompted in a way to\nmitigate spin's impact on LLM outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 12 figures, 4 tables, CHIL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07963v3",
    "published_date": "2025-02-11 21:21:05 UTC",
    "updated_date": "2025-05-05 20:11:20 UTC"
  },
  {
    "arxiv_id": "2502.07957v1",
    "title": "Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders",
    "authors": [
      "Kshitish Ghate",
      "Isaac Slaughter",
      "Kyra Wilson",
      "Mona Diab",
      "Aylin Caliskan"
    ],
    "abstract": "While recent work has found that vision-language models trained under the\nContrastive Language Image Pre-training (CLIP) framework contain intrinsic\nsocial biases, the extent to which different upstream pre-training features of\nthe framework relate to these biases, and hence how intrinsic bias and\ndownstream performance are connected has been unclear. In this work, we present\nthe largest comprehensive analysis to-date of how the upstream pre-training\nfactors and downstream performance of CLIP models relate to their intrinsic\nbiases. Studying 131 unique CLIP models, trained on 26 datasets, using 55\narchitectures, and in a variety of sizes, we evaluate bias in each model using\n26 well-established unimodal and cross-modal principled Embedding Association\nTests. We find that the choice of pre-training dataset is the most significant\nupstream predictor of bias, whereas architectural variations have minimal\nimpact. Additionally, datasets curated using sophisticated filtering techniques\naimed at enhancing downstream model performance tend to be associated with\nhigher levels of intrinsic bias. Finally, we observe that intrinsic bias is\noften significantly correlated with downstream performance ($0.3 \\leq r \\leq\n0.8$), suggesting that models optimized for performance inadvertently learn to\namplify representational biases. Comparisons between unimodal and cross-modal\nassociation tests reveal that social group bias depends heavily on the\nmodality. Our findings imply that more sophisticated strategies are needed to\naddress intrinsic model bias for vision-language models across the entire model\ndevelopment pipeline.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NAACL Main, 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07957v1",
    "published_date": "2025-02-11 21:11:47 UTC",
    "updated_date": "2025-02-11 21:11:47 UTC"
  },
  {
    "arxiv_id": "2502.07949v2",
    "title": "Advancing Autonomous VLM Agents via Variational Subgoal-Conditioned Reinforcement Learning",
    "authors": [
      "Qingyuan Wu",
      "Jianheng Liu",
      "Jianye Hao",
      "Jun Wang",
      "Kun Shao"
    ],
    "abstract": "State-of-the-art (SOTA) reinforcement learning (RL) methods have enabled\nvision-language model (VLM) agents to learn from interaction with online\nenvironments without human supervision. However, these methods often struggle\nwith learning inefficiencies when applied to complex, real-world\ndecision-making tasks with sparse rewards and long-horizon dependencies. We\npropose a novel framework, Variational Subgoal-Conditioned Reinforcement\nLearning (VSC-RL), advancing the VLM agents in resolving challenging\ndecision-making tasks. Fundamentally distinct from existing methods, VSC-RL\nreformulates the decision-making problem as a variational subgoal-conditioned\nRL problem with the newly derived optimization objective, Subgoal Evidence\nLower BOund (SGC-ELBO), which comprises two key components: (a) maximizing the\nsubgoal-conditioned return, and (b) minimizing the divergence from a reference\ngoal-conditioned policy. We theoretically and empirically demonstrate that the\nVSC-RL can efficiently improve the learning efficiency without compromising\nperformance guarantees. Across a diverse set of challenging benchmarks,\nincluding mobile device and web control tasks, VSC-RL consistently outperforms\nexisting SOTA methods, achieving superior learning efficiency and performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07949v2",
    "published_date": "2025-02-11 20:57:46 UTC",
    "updated_date": "2025-05-20 19:54:36 UTC"
  },
  {
    "arxiv_id": "2502.07944v1",
    "title": "SHACL-SKOS Based Knowledge Representation of Material Safety Data Sheet (SDS) for the Pharmaceutical Industry",
    "authors": [
      "Brian Lu",
      "Dennis Pham",
      "Ti-Chiun Chang",
      "Michael Lovette",
      "Terri Bui",
      "Stephen Ma"
    ],
    "abstract": "We report the development of a knowledge representation and reasoning (KRR)\nsystem built on hybrid SHACL-SKOS ontologies for globally harmonized system\n(GHS) material Safety Data Sheets (SDS) to enhance chemical safety\ncommunication and regulatory compliance. SDS are comprehensive documents\ncontaining safety and handling information for chemical substances. Thus, they\nare an essential part of workplace safety and risk management. However, the\nvast number of Safety Data Sheets from multiple organizations, manufacturers,\nand suppliers that produce and distribute chemicals makes it challenging to\ncentralize and access SDS documents through a single repository. To accomplish\nthe underlying issues of data exchange related to chemical shipping and\nhandling, we construct SDS related controlled vocabulary and conditions\nvalidated by SHACL, and knowledge systems of similar domains linked via SKOS.\nThe resulting hybrid ontologies aim to provide standardized yet adaptable\nrepresentations of SDS information, facilitating better data sharing,\nretrieval, and integration across various platforms. This paper outlines our\nSHACL-SKOS system architectural design and showcases our implementation for an\nindustrial application streamlining the generation of a composite shipping\ncover sheet.",
    "categories": [
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 10 figures, IEEE ICSC",
    "pdf_url": "http://arxiv.org/pdf/2502.07944v1",
    "published_date": "2025-02-11 20:44:45 UTC",
    "updated_date": "2025-02-11 20:44:45 UTC"
  },
  {
    "arxiv_id": "2502.07943v1",
    "title": "CREDAL: Close Reading of Data Models",
    "authors": [
      "George Fletcher",
      "Olha Nahurna",
      "Matvii Prytula",
      "Julia Stoyanovich"
    ],
    "abstract": "Data models are necessary for the birth of data and of any data-driven\nsystem. Indeed, every algorithm, every machine learning model, every\nstatistical model, and every database has an underlying data model without\nwhich the system would not be usable. Hence, data models are excellent sites\nfor interrogating the (material, social, political, ...) conditions giving rise\nto a data system. Towards this, drawing inspiration from literary criticism, we\npropose to closely read data models in the same spirit as we closely read\nliterary artifacts. Close readings of data models reconnect us with, among\nother things, the materiality, the genealogies, the techne, the closed nature,\nand the design of technical systems.\n  While recognizing from literary theory that there is no one correct way to\nread, it is nonetheless critical to have systematic guidance for those\nunfamiliar with close readings. This is especially true for those trained in\nthe computing and data sciences, who too often are enculturated to set aside\nthe socio-political aspects of data work. A systematic methodology for reading\ndata models currently does not exist. To fill this gap, we present the CREDAL\nmethodology for close readings of data models. We detail our iterative\ndevelopment process and present results of a qualitative evaluation of CREDAL\ndemonstrating its usability, usefulness, and effectiveness in the critical\nstudy of data.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07943v1",
    "published_date": "2025-02-11 20:42:56 UTC",
    "updated_date": "2025-02-11 20:42:56 UTC"
  },
  {
    "arxiv_id": "2502.07931v1",
    "title": "Educating a Responsible AI Workforce: Piloting a Curricular Module on AI Policy in a Graduate Machine Learning Course",
    "authors": [
      "James Weichert",
      "Hoda Eldardiry"
    ],
    "abstract": "As artificial intelligence (AI) technologies begin to permeate diverse\nfields-from healthcare to education-consumers, researchers and policymakers are\nincreasingly raising concerns about whether and how AI is regulated. It is\ntherefore reasonable to anticipate that alignment with principles of 'ethical'\nor 'responsible' AI, as well as compliance with law and policy, will form an\nincreasingly important part of AI development. Yet, for the most part, the\nconventional computer science curriculum is ill-equipped to prepare students\nfor these challenges. To this end, we seek to explore how new educational\ncontent related to AI ethics and AI policy can be integrated into both ethics-\nand technical-focused courses. This paper describes a two-lecture 'AI policy\nmodule' that was piloted in a graduate-level introductory machine learning\ncourse in 2024. The module, which includes an in-class active learning game, is\nevaluated using data from student surveys before and after the lectures, and\npedagogical motivations and considerations are discussed. We find that the\nmodule is successful in engaging otherwise technically-oriented students on the\ntopic of AI policy, increasing student awareness of the social impacts of a\nvariety of AI technologies and developing student interest in the field of AI\nregulation.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at 2025 ASEE Annual Conference & Exposition",
    "pdf_url": "http://arxiv.org/pdf/2502.07931v1",
    "published_date": "2025-02-11 20:16:56 UTC",
    "updated_date": "2025-02-11 20:16:56 UTC"
  },
  {
    "arxiv_id": "2502.10450v1",
    "title": "Trustworthy AI on Safety, Bias, and Privacy: A Survey",
    "authors": [
      "Xingli Fang",
      "Jianwei Li",
      "Varun Mulchandani",
      "Jung-Eun Kim"
    ],
    "abstract": "The capabilities of artificial intelligence systems have been advancing to a\ngreat extent, but these systems still struggle with failure modes,\nvulnerabilities, and biases. In this paper, we study the current state of the\nfield, and present promising insights and perspectives regarding concerns that\nchallenge the trustworthiness of AI models. In particular, this paper\ninvestigates the issues regarding three thrusts: safety, privacy, and bias,\nwhich hurt models' trustworthiness. For safety, we discuss safety alignment in\nthe context of large language models, preventing them from generating toxic or\nharmful content. For bias, we focus on spurious biases that can mislead a\nnetwork. Lastly, for privacy, we cover membership inference attacks in deep\nneural networks. The discussions addressed in this paper reflect our own\nexperiments and observations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10450v1",
    "published_date": "2025-02-11 20:08:42 UTC",
    "updated_date": "2025-02-11 20:08:42 UTC"
  },
  {
    "arxiv_id": "2503.01733v1",
    "title": "DISCOVER: Data-driven Identification of Sub-activities via Clustering and Visualization for Enhanced Activity Recognition in Smart Homes",
    "authors": [
      "Alexander Karpekov",
      "Sonia Chernova",
      "Thomas PlÃ¶tz"
    ],
    "abstract": "Human Activity Recognition (HAR) using ambient sensors has great potential\nfor practical applications, particularly in elder care and independent living.\nHowever, deploying HAR systems in real-world settings remains challenging due\nto the high cost of labeled data, the need for pre-segmented sensor streams,\nand the lack of flexibility in activity granularity. To address these\nlimitations, we introduce DISCOVER, a method designed to discover fine-grained\nhuman sub-activities from unlabeled sensor data without relying on\npre-segmentation. DISCOVER combines unsupervised feature extraction and\nclustering with a user-friendly visualization tool to streamline the labeling\nprocess. DISCOVER enables domain experts to efficiently annotate only a minimal\nset of representative cluster centroids, reducing the annotation workload to a\nsmall number of samples (0.05% of our dataset). We demonstrate DISCOVER's\neffectiveness through a re-annotation exercise on widely used HAR datasets,\nshowing that it uncovers finer-grained activities and produces more nuanced\nannotations than traditional coarse labels. DISCOVER represents a step toward\npractical, deployable HAR systems that adapt to diverse real environments.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "v1: Initial submission. Under review at IMWUT",
    "pdf_url": "http://arxiv.org/pdf/2503.01733v1",
    "published_date": "2025-02-11 20:02:24 UTC",
    "updated_date": "2025-02-11 20:02:24 UTC"
  },
  {
    "arxiv_id": "2502.07924v1",
    "title": "NDAI Agreements",
    "authors": [
      "Matthew Stephenson",
      "Andrew Miller",
      "Xyn Sun",
      "Bhargav Annem",
      "Rohan Parikh"
    ],
    "abstract": "We study a fundamental challenge in the economics of innovation: an inventor\nmust reveal details of a new idea to secure compensation or funding, yet such\ndisclosure risks expropriation. We present a model in which a seller (inventor)\nand buyer (investor) bargain over an information good under the threat of\nhold-up. In the classical setting, the seller withholds disclosure to avoid\nmisappropriation, leading to inefficiency. We show that trusted execution\nenvironments (TEEs) combined with AI agents can mitigate and even fully\neliminate this hold-up problem. By delegating the disclosure and payment\ndecisions to tamper-proof programs, the seller can safely reveal the invention\nwithout risking expropriation, achieving full disclosure and an efficient ex\npost transfer. Moreover, even if the invention's value exceeds a threshold that\nTEEs can fully secure, partial disclosure still improves outcomes compared to\nno disclosure. Recognizing that real AI agents are imperfect, we model \"agent\nerrors\" in payments or disclosures and demonstrate that budget caps and\nacceptance thresholds suffice to preserve most of the efficiency gains.\n  Our results imply that cryptographic or hardware-based solutions can function\nas an \"ironclad NDA,\" substantially mitigating the fundamental\ndisclosure-appropriation paradox first identified by Arrow (1962) and Nelson\n(1959). This has far-reaching policy implications for fostering R&D, technology\ntransfer, and collaboration.",
    "categories": [
      "econ.TH",
      "cs.AI"
    ],
    "primary_category": "econ.TH",
    "comment": "21 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.07924v1",
    "published_date": "2025-02-11 19:56:26 UTC",
    "updated_date": "2025-02-11 19:56:26 UTC"
  },
  {
    "arxiv_id": "2502.07771v1",
    "title": "Breaking Down Bias: On The Limits of Generalizable Pruning Strategies",
    "authors": [
      "Sibo Ma",
      "Alejandro Salinas",
      "Peter Henderson",
      "Julian Nyarko"
    ],
    "abstract": "We employ model pruning to examine how LLMs conceptualize racial biases, and\nwhether a generalizable mitigation strategy for such biases appears feasible.\nOur analysis yields several novel insights. We find that pruning can be an\neffective method to reduce bias without significantly increasing anomalous\nmodel behavior. Neuron-based pruning strategies generally yield better results\nthan approaches pruning entire attention heads. However, our results also show\nthat the effectiveness of either approach quickly deteriorates as pruning\nstrategies become more generalized. For instance, a model that is trained on\nremoving racial biases in the context of financial decision-making poorly\ngeneralizes to biases in commercial transactions. Overall, our analysis\nsuggests that racial biases are only partially represented as a general concept\nwithin language models. The other part of these biases is highly\ncontext-specific, suggesting that generalizable mitigation strategies may be of\nlimited effectiveness. Our findings have important implications for legal\nframeworks surrounding AI. In particular, they suggest that an effective\nmitigation strategy should include the allocation of legal responsibility on\nthose that deploy models in a specific use case.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 9 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.07771v1",
    "published_date": "2025-02-11 18:55:57 UTC",
    "updated_date": "2025-02-11 18:55:57 UTC"
  },
  {
    "arxiv_id": "2502.07764v1",
    "title": "Polynomial-Time Approximability of Constrained Reinforcement Learning",
    "authors": [
      "Jeremy McMahan"
    ],
    "abstract": "We study the computational complexity of approximating general constrained\nMarkov decision processes. Our primary contribution is the design of a\npolynomial time $(0,\\epsilon)$-additive bicriteria approximation algorithm for\nfinding optimal constrained policies across a broad class of recursively\ncomputable constraints, including almost-sure, chance, expectation, and their\nanytime variants. Matching lower bounds imply our approximation guarantees are\noptimal so long as $P \\neq NP$. The generality of our approach results in\nanswers to several long-standing open complexity questions in the constrained\nreinforcement learning literature. Specifically, we are the first to prove\npolynomial-time approximability for the following settings: policies under\nchance constraints, deterministic policies under multiple expectation\nconstraints, policies under non-homogeneous constraints (i.e., constraints of\ndifferent types), and policies under constraints for continuous-state\nprocesses.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07764v1",
    "published_date": "2025-02-11 18:47:53 UTC",
    "updated_date": "2025-02-11 18:47:53 UTC"
  },
  {
    "arxiv_id": "2502.08666v2",
    "title": "Hallucination, Monofacts, and Miscalibration: An Empirical Investigation",
    "authors": [
      "Miranda Muqing Miao",
      "Michael Kearns"
    ],
    "abstract": "Hallucinated facts in large language models (LLMs) have recently been shown\nto obey a statistical lower bound determined by the monofact rate (related to\nthe classical Good-Turing missing mass estimator) minus model miscalibration\n(Kalai & Vempala, 2024). We present the first empirical investigation of this\nthree-way relationship in classical n-gram models and fine-tuned\nencoder-decoder Transformers. By generating training data from Pareto\ndistributions with varying shape parameters, we systematically control the\nmonofact rates and establish its positive relationship with hallucination. To\nbridge theory and practice, we derive an empirical analog of the hallucination\nbound by replacing the population miscalibration term (Section 2.1) with an\nempirical bin-wise KL divergence and confirm its practical viability. We then\nintroduce selective upweighting -- a simple yet effective technique that\nstrategically repeats as little as 5% of training examples -- to deliberately\ninject miscalibration into the model. This intervention reduces hallucination\nby up to 40%, challenging universal deduplication policies. Our experiments\nreveal a critical trade-off: selective upweighting maintains pre-injection\nlevels of accuracy while substantially reducing hallucination, whereas standard\ntraining gradually improves accuracy but fails to address persistently high\nhallucination, indicating an inherent tension in optimization objectives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code available at https://github.com/mmiao2/Hallucination.git",
    "pdf_url": "http://arxiv.org/pdf/2502.08666v2",
    "published_date": "2025-02-11 18:46:00 UTC",
    "updated_date": "2025-05-15 19:25:08 UTC"
  },
  {
    "arxiv_id": "2502.07755v1",
    "title": "An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating",
    "authors": [
      "Mohammad Ali Labbaf Khaniki",
      "Sahabeh Saadati",
      "Mohammad Manthouri"
    ],
    "abstract": "This paper presents a novel Natural Language Processing (NLP) framework for\nenhancing medical diagnosis through the integration of advanced techniques in\ndata augmentation, feature extraction, and classification. The proposed\napproach employs back-translation to generate diverse paraphrased datasets,\nimproving robustness and mitigating overfitting in classification tasks.\nLeveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with\nDynamic Contextual Positional Gating (DCPG), the model captures fine-grained\ncontextual and positional relationships, dynamically adjusting the influence of\npositional information based on semantic context to produce high-quality text\nembeddings. For classification, an Attention-Based Feedforward Neural Network\n(ABFNN) is utilized, effectively focusing on the most relevant features to\nimprove decision-making accuracy. Applied to the classification of symptoms,\nclinical notes, and other medical texts, this architecture demonstrates its\nability to address the complexities of medical data. The combination of data\naugmentation, contextual embedding generation, and advanced classification\nmechanisms offers a robust and accurate diagnostic tool, with potential\napplications in automated medical diagnosis and clinical decision support. This\nmethod demonstrates the effectiveness of the proposed NLP framework for medical\ndiagnosis, achieving remarkable results with an accuracy of 99.78%, recall of\n99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only\nunderscore the model's robust performance in classifying medical texts with\nexceptional precision and reliability but also highlight its superiority over\nexisting methods, making it a highly promising tool for automated diagnostic\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07755v1",
    "published_date": "2025-02-11 18:32:24 UTC",
    "updated_date": "2025-02-11 18:32:24 UTC"
  },
  {
    "arxiv_id": "2502.07752v2",
    "title": "Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension",
    "authors": [
      "Wenbo Gong",
      "Meyer Scetbon",
      "Chao Ma",
      "Edward Meeds"
    ],
    "abstract": "Designing efficient optimizers for large language models (LLMs) with\nlow-memory requirements and fast convergence is an important and challenging\nproblem. This paper makes a step towards the systematic design of such\noptimizers through the lens of structured Fisher information matrix (FIM)\napproximation. We show that many state-of-the-art efficient optimizers can be\nviewed as solutions to FIM approximation (under the Frobenius norm) with\nspecific structural assumptions. Building on these insights, we propose two\ndesign recommendations of practical efficient optimizers for LLMs, involving\nthe careful selection of structural assumptions to balance generality and\nefficiency, and enhancing memory efficiency of optimizers with general\nstructures through a novel low-rank extension framework. We demonstrate how to\nuse each design approach by deriving new memory-efficient optimizers: Row and\nColumn Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation\n(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the\neffectiveness, showing faster and better convergence than existing\nmemory-efficient baselines and Adam with little memory overhead. Notably, Alice\nachieves better than 2x faster convergence over Adam, while RACS delivers\nstrong performance on the 1B model with SGD-like memory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07752v2",
    "published_date": "2025-02-11 18:27:19 UTC",
    "updated_date": "2025-02-20 18:48:58 UTC"
  },
  {
    "arxiv_id": "2502.07750v2",
    "title": "PFedDST: Personalized Federated Learning with Decentralized Selection Training",
    "authors": [
      "Mengchen Fan",
      "Keren Li",
      "Tianyun Zhang",
      "Qing Tian",
      "Baocheng Geng"
    ],
    "abstract": "Distributed Learning (DL) enables the training of machine learning models\nacross multiple devices, yet it faces challenges like non-IID data\ndistributions and device capability disparities, which can impede training\nefficiency. Communication bottlenecks further complicate traditional Federated\nLearning (FL) setups. To mitigate these issues, we introduce the Personalized\nFederated Learning with Decentralized Selection Training (PFedDST) framework.\nPFedDST enhances model training by allowing devices to strategically evaluate\nand select peers based on a comprehensive communication score. This score\nintegrates loss, task similarity, and selection frequency, ensuring optimal\npeer connections. This selection strategy is tailored to increase local\npersonalization and promote beneficial peer collaborations to strengthen the\nstability and efficiency of the training process. Our experiments demonstrate\nthat PFedDST not only enhances model accuracy but also accelerates convergence.\nThis approach outperforms state-of-the-art methods in handling data\nheterogeneity, delivering both faster and more effective training in diverse\nand decentralized systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07750v2",
    "published_date": "2025-02-11 18:25:48 UTC",
    "updated_date": "2025-02-19 04:21:58 UTC"
  },
  {
    "arxiv_id": "2502.07864v2",
    "title": "TransMLA: Multi-Head Latent Attention Is All You Need",
    "authors": [
      "Fanxu Meng",
      "Zengwei Yao",
      "Muhan Zhang"
    ],
    "abstract": "Modern large language models (LLMs) often encounter communication bottlenecks\non current hardware, rather than purely computational constraints. Multi-head\nLatent Attention (MLA) tackles this challenge by using low-rank matrices in the\nkey-value (KV) layers, thereby allowing compressed latent KV states to be\ncached. This approach significantly reduces the KV cache size relative to\ntraditional multi-head attention, leading to faster inference. Moreover, MLA\nemploys an up-projection matrix to increase expressiveness, trading additional\ncomputation for reduced communication overhead. Although MLA has demonstrated\nefficiency and effectiveness in Deepseek V2/V3/R1, many major model providers\nstill rely on Group Query Attention (GQA) and have not announced any plans to\nadopt MLA. In this paper, we show that GQA can always be represented by MLA\nwhile maintaining the same KV cache overhead, but the converse does not hold.\nTo encourage broader use of MLA, we introduce TransMLA, a post-training method\nthat converts widely used GQA-based pre-trained models (e.g., LLaMA, Qwen,\nMixtral) into MLA-based models. After conversion, the model can undergo\nadditional training to boost expressiveness without increasing the KV cache\nsize. Furthermore, we plan to develop MLA-specific inference acceleration\ntechniques to preserve low latency in transformed models, thus enabling more\nefficient distillation of Deepseek R1.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/fxmeng/TransMLA",
    "pdf_url": "http://arxiv.org/pdf/2502.07864v2",
    "published_date": "2025-02-11 18:20:18 UTC",
    "updated_date": "2025-02-13 18:07:04 UTC"
  },
  {
    "arxiv_id": "2502.07747v1",
    "title": "WHODUNIT: Evaluation benchmark for culprit detection in mystery stories",
    "authors": [
      "Kshitij Gupta"
    ],
    "abstract": "We present a novel data set, WhoDunIt, to assess the deductive reasoning\ncapabilities of large language models (LLM) within narrative contexts.\nConstructed from open domain mystery novels and short stories, the dataset\nchallenges LLMs to identify the perpetrator after reading and comprehending the\nstory. To evaluate model robustness, we apply a range of character-level name\naugmentations, including original names, name swaps, and substitutions with\nwell-known real and/or fictional entities from popular discourse. We further\nuse various prompting styles to investigate the influence of prompting on\ndeductive reasoning accuracy.\n  We conduct evaluation study with state-of-the-art models, specifically\nGPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with\nmajority response selection to ensure reliability. The results demonstrate that\nwhile LLMs perform reliably on unaltered texts, accuracy diminishes with\ncertain name substitutions, particularly those with wide recognition. This\ndataset is publicly available here.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07747v1",
    "published_date": "2025-02-11 18:14:44 UTC",
    "updated_date": "2025-02-11 18:14:44 UTC"
  },
  {
    "arxiv_id": "2502.07737v2",
    "title": "Next Block Prediction: Video Generation via Semi-Autoregressive Modeling",
    "authors": [
      "Shuhuai Ren",
      "Shuming Ma",
      "Xu Sun",
      "Furu Wei"
    ],
    "abstract": "Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR)\nvideo generation, but it suffers from suboptimal unidirectional dependencies\nand slow inference speed. In this work, we propose a semi-autoregressive\n(semi-AR) framework, called Next-Block Prediction (NBP), for video generation.\nBy uniformly decomposing video content into equal-sized blocks (e.g., rows or\nframes), we shift the generation unit from individual tokens to blocks,\nallowing each token in the current block to simultaneously predict the\ncorresponding token in the next block. Unlike traditional AR modeling, our\nframework employs bidirectional attention within each block, enabling tokens to\ncapture more robust spatial dependencies. By predicting multiple tokens in\nparallel, NBP models significantly reduce the number of generation steps,\nleading to faster and more efficient inference. Our model achieves FVD scores\nof 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an\naverage of 4.4. Furthermore, thanks to the reduced number of inference steps,\nthe NBP model generates 8.89 frames (128x128 resolution) per second, achieving\nan 11x speedup. We also explored model scales ranging from 700M to 3B\nparameters, observing significant improvements in generation quality, with FVD\nscores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600,\ndemonstrating the scalability of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "project page: https://renshuhuai-andy.github.io/NBP-project/",
    "pdf_url": "http://arxiv.org/pdf/2502.07737v2",
    "published_date": "2025-02-11 17:57:53 UTC",
    "updated_date": "2025-02-12 14:50:50 UTC"
  },
  {
    "arxiv_id": "2502.07734v1",
    "title": "EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices",
    "authors": [
      "Camile Lendering",
      "Bernardo Perrone Ribeiro",
      "Å½iga EmerÅ¡iÄ",
      "Peter Peer"
    ],
    "abstract": "Ear recognition is a contactless and unobtrusive biometric technique with\napplications across various domains. However, deploying high-performing ear\nrecognition models on resource-constrained devices is challenging, limiting\ntheir applicability and widespread adoption. This paper introduces EdgeEar, a\nlightweight model based on a proposed hybrid CNN-transformer architecture to\nsolve this problem. By incorporating low-rank approximations into specific\nlinear layers, EdgeEar reduces its parameter count by a factor of 50 compared\nto the current state-of-the-art, bringing it below two million while\nmaintaining competitive accuracy. Evaluation on the Unconstrained Ear\nRecognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the\nlowest EER while significantly reducing computational costs. These findings\ndemonstrate the feasibility of efficient and accurate ear recognition, which we\nbelieve will contribute to the wider adoption of ear biometrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to IEEE FG 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07734v1",
    "published_date": "2025-02-11 17:53:33 UTC",
    "updated_date": "2025-02-11 17:53:33 UTC"
  },
  {
    "arxiv_id": "2502.07732v1",
    "title": "Economics of Sourcing Human Data",
    "authors": [
      "Sebastin Santy",
      "Prasanta Bhattacharya",
      "Manoel Horta Ribeiro",
      "Kelsey Allen",
      "Sewoong Oh"
    ],
    "abstract": "Progress in AI has relied on human-generated data, from annotator\nmarketplaces to the wider Internet. However, the widespread use of large\nlanguage models now threatens the quality and integrity of human-generated data\non these very platforms. We argue that this issue goes beyond the immediate\nchallenge of filtering AI-generated content--it reveals deeper flaws in how\ndata collection systems are designed. Existing systems often prioritize speed,\nscale, and efficiency at the cost of intrinsic human motivation, leading to\ndeclining engagement and data quality. We propose that rethinking data\ncollection systems to align with contributors' intrinsic motivations--rather\nthan relying solely on external incentives--can help sustain high-quality data\nsourcing at scale while maintaining contributor trust and long-term\nparticipation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07732v1",
    "published_date": "2025-02-11 17:51:52 UTC",
    "updated_date": "2025-02-11 17:51:52 UTC"
  },
  {
    "arxiv_id": "2502.07728v1",
    "title": "Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK",
    "authors": [
      "Marcos Cramer",
      "Lucian McIntyre"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable code generation\ncapabilities, but the correctness of the generated code cannot be inherently\ntrusted. This paper explores the feasibility of using formal software\nverification, specifically the SPARK framework for Ada, to ensure the\nreliability of LLM-generated code. We present Marmaragan, a tool that leverages\nan LLM in order to generate SPARK annotations for existing programs, enabling\nformal verification of the code. The tool is benchmarked on a curated set of\nSPARK programs, with annotations selectively removed to test specific\ncapabilities. The performance of Marmaragan with GPT-4o on the benchmark is\npromising, with correct annotations having been generated for 50.7% of the\nbenchmark cases. The results establish a foundation for future work on\ncombining the power of LLMs with the reliability of formal software\nverification.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07728v1",
    "published_date": "2025-02-11 17:42:07 UTC",
    "updated_date": "2025-02-11 17:42:07 UTC"
  },
  {
    "arxiv_id": "2502.07721v1",
    "title": "TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning",
    "authors": [
      "Mengyang Li"
    ],
    "abstract": "The prevalence of noisy labels in real-world datasets poses a significant\nimpediment to the effective deployment of deep learning models. While\nmeta-learning strategies have emerged as a promising approach for addressing\nthis challenge, existing methods often suffer from limited transferability and\ntask-specific designs. This paper introduces TMLC-Net, a novel Transferable\nMeta-Learner for Correcting Noisy Labels, designed to overcome these\nlimitations. TMLC-Net learns a general-purpose label correction strategy that\ncan be readily applied across diverse datasets and model architectures without\nrequiring extensive retraining or fine-tuning. Our approach integrates three\ncore components: (1) Normalized Noise Perception, which captures and normalizes\ntraining dynamics to handle distribution shifts; (2) Time-Series Encoding,\nwhich models the temporal evolution of sample statistics using a recurrent\nneural network; and (3) Subclass Decoding, which predicts a corrected label\ndistribution based on the learned representations. We conduct extensive\nexperiments on benchmark datasets with various noise types and levels,\ndemonstrating that TMLC-Net consistently outperforms state-of-the-art methods\nin terms of both accuracy and robustness to label noise. Furthermore, we\nanalyze the transferability of TMLC-Net, showcasing its adaptability to new\ndatasets and noise conditions, and establishing its potential as a broadly\napplicable solution for robust deep learning in noisy environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07721v1",
    "published_date": "2025-02-11 17:33:48 UTC",
    "updated_date": "2025-02-11 17:33:48 UTC"
  },
  {
    "arxiv_id": "2502.07862v1",
    "title": "ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources",
    "authors": [
      "Jason Wu",
      "Kang Yang",
      "Lance Kaplan",
      "Mani Srivastava"
    ],
    "abstract": "Multimodal deep learning systems are deployed in dynamic scenarios due to the\nrobustness afforded by multiple sensing modalities. Nevertheless, they struggle\nwith varying compute resource availability (due to multi-tenancy, device\nheterogeneity, etc.) and fluctuating quality of inputs (from sensor feed\ncorruption, environmental noise, etc.). Current multimodal systems employ\nstatic resource provisioning and cannot easily adapt when compute resources\nchange over time. Additionally, their reliance on processing sensor data with\nfixed feature extractors is ill-equipped to handle variations in modality\nquality. Consequently, uninformative modalities, such as those with high noise,\nneedlessly consume resources better allocated towards other modalities. We\npropose ADMN, a layer-wise Adaptive Depth Multimodal Network capable of\ntackling both challenges - it adjusts the total number of active layers across\nall modalities to meet compute resource constraints, and continually\nreallocates layers across input modalities according to their modality quality.\nOur evaluations showcase ADMN can match the accuracy of state-of-the-art\nnetworks while reducing up to 75% of their floating-point operations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07862v1",
    "published_date": "2025-02-11 17:19:44 UTC",
    "updated_date": "2025-02-11 17:19:44 UTC"
  },
  {
    "arxiv_id": "2502.07861v1",
    "title": "BalanceKV: KV Cache Compression through Discrepancy Theory",
    "authors": [
      "Insu Han",
      "Michael Kapralov",
      "Ekaterina Kochetkova",
      "Kshiteej Sheth",
      "Amir Zandieh"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive success, but their high\nmemory requirements present challenges for long-context token generation. The\nmemory complexity of long-context LLMs is primarily due to the need to store\nKey-Value (KV) embeddings in their KV cache. We present BalanceKV, a KV cache\ncompression method based on geometric sampling process stemming from\nBanaszczyk's vector balancing theory, which introduces dependencies informed by\nthe geometry of keys and value tokens, and improves precision. BalanceKV offers\nboth theoretically proven and empirically validated performance improvements\nover existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07861v1",
    "published_date": "2025-02-11 17:18:17 UTC",
    "updated_date": "2025-02-11 17:18:17 UTC"
  },
  {
    "arxiv_id": "2502.07709v2",
    "title": "MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces",
    "authors": [
      "Loris Gaven",
      "Thomas Carta",
      "ClÃ©ment Romac",
      "CÃ©dric Colas",
      "Sylvain Lamprier",
      "Olivier Sigaud",
      "Pierre-Yves Oudeyer"
    ],
    "abstract": "Open-ended learning agents must efficiently prioritize goals in vast\npossibility spaces, focusing on those that maximize learning progress (LP).\nWhen such autotelic exploration is achieved by LLM agents trained with online\nRL in high-dimensional and evolving goal spaces, a key challenge for LP\nprediction is modeling one's own competence, a form of metacognitive\nmonitoring. Traditional approaches either require extensive sampling or rely on\nbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive\nframework that lets LLM agents learn to predict their competence and LP online.\nBy capturing semantic relationships between goals, MAGELLAN enables\nsample-efficient LP estimation and dynamic adaptation to evolving goal spaces\nthrough generalization. In an interactive learning environment, we show that\nMAGELLAN improves LP prediction efficiency and goal prioritization, being the\nonly method allowing the agent to fully master a large and evolving goal space.\nThese results demonstrate how augmenting LLM agents with a metacognitive\nability for LP predictions can effectively scale curriculum learning to\nopen-ended goal spaces.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07709v2",
    "published_date": "2025-02-11 17:08:00 UTC",
    "updated_date": "2025-02-12 08:52:52 UTC"
  },
  {
    "arxiv_id": "2502.09650v2",
    "title": "Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples",
    "authors": [
      "Chengqian Gao",
      "Haonan Li",
      "Liu Liu",
      "Zeke Xie",
      "Peilin Zhao",
      "Zhiqiang Xu"
    ],
    "abstract": "The alignment of large language models (LLMs) often assumes that using more\nclean data yields better outcomes, overlooking the match between model capacity\nand example difficulty. Challenging this, we propose a new principle:\nPreference data vary in difficulty, and overly difficult examples hinder\nalignment, by exceeding the model's capacity. Through systematic\nexperimentation, we validate this principle with three key findings: (1)\npreference examples vary in difficulty, as evidenced by consistent learning\norders across alignment runs; (2) overly difficult examples significantly\ndegrade performance across four LLMs and two datasets; and (3) the capacity of\na model dictates its threshold for handling difficult examples, underscoring a\ncritical relationship between data selection and model capacity. Building on\nthis principle, we introduce Selective DPO, which filters out overly difficult\nexamples. This simple adjustment improves alignment performance by 9-16% in win\nrates on the AlpacaEval 2 benchmark compared to the DPO baseline, suppressing a\nseries of DPO variants with different algorithmic adjustments. Together, these\nresults illuminate the importance of aligning data difficulty with model\ncapacity, offering a transformative perspective for improving alignment\nstrategies in LLMs. Code is available at\nhttps://github.com/glorgao/SelectiveDPO.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.09650v2",
    "published_date": "2025-02-11 17:01:11 UTC",
    "updated_date": "2025-05-13 18:54:09 UTC"
  },
  {
    "arxiv_id": "2502.07693v4",
    "title": "AI-driven Personalized Privacy Assistants: a Systematic Literature Review",
    "authors": [
      "Victor Morel",
      "Leonardo Iwaya",
      "Simone Fischer-HÃ¼bner"
    ],
    "abstract": "In recent years, several personalized assistants based on AI have been\nresearched and developed to help users make privacy-related decisions. These\nAI-driven Personalized Privacy Assistants (AI-driven PPAs) can provide\nsignificant benefits for users, who might otherwise struggle with making\ndecisions about their personal data in online environments that often overload\nthem with different privacy decision requests. So far, no studies have\nsystematically investigated the emerging topic of AI-driven PPAs, classifying\ntheir underlying technologies, architecture and features, including decision\ntypes or the accuracy of their decisions. To fill this gap, we present a\nSystematic Literature Review (SLR) to map the existing solutions found in the\nscientific literature, which allows reasoning about existing approaches and\nopen challenges for this research field. We screened several hundred unique\nresearch papers over the recent years (2013-2025), constructing a\nclassification from 41 included papers. As a result, this SLR reviews several\naspects of existing research on AI-driven PPAs in terms of types of\npublications, contributions, methodological quality, and other quantitative\ninsights. Furthermore, we provide a comprehensive classification for AI-driven\nPPAs, delving into their architectural choices, system contexts, types of AI\nused, data sources, types of decisions, and control over decisions, among other\nfacets. Based on our SLR, we further underline the research gaps and challenges\nand formulate recommendations for the design and development of AI-driven PPAs\nas well as avenues for future research.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Submitted to IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2502.07693v4",
    "published_date": "2025-02-11 16:46:56 UTC",
    "updated_date": "2025-05-20 11:35:47 UTC"
  },
  {
    "arxiv_id": "2502.07857v1",
    "title": "SNAP: Sequential Non-Ancestor Pruning for Targeted Causal Effect Estimation With an Unknown Graph",
    "authors": [
      "MÃ¡tyÃ¡s Schubert",
      "Tom Claassen",
      "Sara Magliacane"
    ],
    "abstract": "Causal discovery can be computationally demanding for large numbers of\nvariables. If we only wish to estimate the causal effects on a small subset of\ntarget variables, we might not need to learn the causal graph for all\nvariables, but only a small subgraph that includes the targets and their\nadjustment sets. In this paper, we focus on identifying causal effects between\ntarget variables in a computationally and statistically efficient way. This\ntask combines causal discovery and effect estimation, aligning the discovery\nobjective with the effects to be estimated. We show that definite non-ancestors\nof the targets are unnecessary to learn causal relations between the targets\nand to identify efficient adjustments sets. We sequentially identify and prune\nthese definite non-ancestors with our Sequential Non-Ancestor Pruning (SNAP)\nframework, which can be used either as a preprocessing step to standard causal\ndiscovery methods, or as a standalone sound and complete causal discovery\nalgorithm. Our results on synthetic and real data show that both approaches\nsubstantially reduce the number of independence tests and the computation time\nwithout compromising the quality of causal effect estimations.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted at AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07857v1",
    "published_date": "2025-02-11 16:20:57 UTC",
    "updated_date": "2025-02-11 16:20:57 UTC"
  },
  {
    "arxiv_id": "2502.07663v2",
    "title": "Human Decision-making is Susceptible to AI-driven Manipulation",
    "authors": [
      "Sahand Sabour",
      "June M. Liu",
      "Siyang Liu",
      "Chris Z. Yao",
      "Shiyao Cui",
      "Xuanming Zhang",
      "Wen Zhang",
      "Yaru Cao",
      "Advait Bhat",
      "Jian Guan",
      "Wei Wu",
      "Rada Mihalcea",
      "Hongning Wang",
      "Tim Althoff",
      "Tatia M. C. Lee",
      "Minlie Huang"
    ],
    "abstract": "Artificial Intelligence (AI) systems are increasingly intertwined with daily\nlife, assisting users in executing various tasks and providing guidance on\ndecision-making. This integration introduces risks of AI-driven manipulation,\nwhere such systems may exploit users' cognitive biases and emotional\nvulnerabilities to steer them toward harmful outcomes. Through a randomized\ncontrolled trial with 233 participants, we examined human susceptibility to\nsuch manipulation in financial (e.g., purchases) and emotional (e.g., conflict\nresolution) decision-making contexts. Participants interacted with one of three\nAI agents: a neutral agent (NA) optimizing for user benefit without explicit\ninfluence, a manipulative agent (MA) designed to covertly influence beliefs and\nbehaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit\npsychological tactics to reach its hidden objectives. By analyzing\nparticipants' decision patterns and shifts in their preference ratings\npost-interaction, we found significant susceptibility to AI-driven\nmanipulation. Particularly, across both decision-making domains, participants\ninteracting with the manipulative agents shifted toward harmful options at\nsubstantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA:\n42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional,\n12.8%). Notably, our findings reveal that even subtle manipulative objectives\n(MA) can be as effective as employing explicit psychological strategies (SEMA)\nin swaying human decision-making. By revealing the potential for covert AI\ninfluence, this study highlights a critical vulnerability in human-AI\ninteractions, emphasizing the need for ethical safeguards and regulatory\nframeworks to ensure responsible deployment of AI technologies and protect\nhuman autonomy.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2502.07663v2",
    "published_date": "2025-02-11 15:56:22 UTC",
    "updated_date": "2025-02-24 15:00:18 UTC"
  },
  {
    "arxiv_id": "2502.07656v1",
    "title": "A Unifying Framework for Causal Imitation Learning with Hidden Confounders",
    "authors": [
      "Daqian Shao",
      "Thomas Kleine Buening",
      "Marta Kwiatkowska"
    ],
    "abstract": "We propose a general and unifying framework for causal Imitation Learning\n(IL) with hidden confounders that subsumes several existing confounded IL\nsettings from the literature. Our framework accounts for two types of hidden\nconfounders: (a) those observed by the expert, which thus influence the\nexpert's policy, and (b) confounding noise hidden to both the expert and the IL\nalgorithm. For additional flexibility, we also introduce a confounding noise\nhorizon and time-varying expert-observable hidden variables. We show that\ncausal IL in our framework can be reduced to a set of Conditional Moment\nRestrictions (CMRs) by leveraging trajectory histories as instruments to learn\na history-dependent policy. We propose DML-IL, a novel algorithm that uses\ninstrumental variable regression to solve these CMRs and learn a policy. We\nprovide a bound on the imitation gap for DML-IL, which recovers prior results\nas special cases. Empirical evaluation on a toy environment with continues\nstate-action spaces and multiple Mujoco tasks demonstrate that DML-IL\noutperforms state-of-the-art causal IL algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07656v1",
    "published_date": "2025-02-11 15:43:49 UTC",
    "updated_date": "2025-02-11 15:43:49 UTC"
  },
  {
    "arxiv_id": "2502.07644v2",
    "title": "SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models",
    "authors": [
      "Shihao Xia",
      "Mengting He",
      "Shuai Shao",
      "Tingting Yu",
      "Yiying Zhang",
      "Linhai Song"
    ],
    "abstract": "To govern smart contracts running on Ethereum, multiple Ethereum Request for\nComment (ERC) standards have been developed, each having a set of rules to\nguide the behaviors of smart contracts. Violating the ERC rules could cause\nserious security issues and financial loss, signifying the importance of\nverifying smart contracts follow ERCs. Today's practices of such verification\nare to manually audit each single contract, use expert-developed\nprogram-analysis tools, or use large language models (LLMs), all of which are\nfar from effective in identifying ERC rule violations. This paper introduces\nSymGPT, a tool that combines the natural language understanding of large\nlanguage models (LLMs) with the formal guarantees of symbolic execution to\nautomatically verify smart contracts' compliance with ERC rules. To develop\nSymGPT, we conduct an empirical study of 132 ERC rules from three widely used\nERC standards, examining their content, security implications, and natural\nlanguage descriptions. Based on this study, we design SymGPT by first\ninstructing an LLM to translate ERC rules into a defined EBNF grammar. We then\nsynthesize constraints from the formalized rules to represent scenarios where\nviolations may occur and use symbolic execution to detect them. Our evaluation\nshows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world\ncontracts, including 1,375 violations with clear attack paths for stealing\nfinancial assets, demonstrating its effectiveness. Furthermore, SymGPT\noutperforms six automated techniques and a security-expert auditing service,\nunderscoring its superiority over current smart contract analysis methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages. arXiv admin note: text overlap with arXiv:2404.04306",
    "pdf_url": "http://arxiv.org/pdf/2502.07644v2",
    "published_date": "2025-02-11 15:34:00 UTC",
    "updated_date": "2025-02-12 05:18:48 UTC"
  },
  {
    "arxiv_id": "2502.07640v3",
    "title": "Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving",
    "authors": [
      "Yong Lin",
      "Shange Tang",
      "Bohan Lyu",
      "Jiayun Wu",
      "Hongzhou Lin",
      "Kaiyu Yang",
      "Jia Li",
      "Mengzhou Xia",
      "Danqi Chen",
      "Sanjeev Arora",
      "Chi Jin"
    ],
    "abstract": "We introduce Goedel-Prover, an open-source language model that achieves\nstate-of-the-art (as of April 5 2025) performance in automated formal proof\ngeneration for mathematical problems. A key challenge in this field is the\nscarcity of formalized mathematical statements and proofs, which we address\nthrough the following approaches. First, we train LLMs to convert natural\nlanguage math problems from the Numina dataset to equivalent formal statements\nin Lean 4. This process creates the dataset Goedel-Pset-v1, which includes 1.64\nmillion formal statements. Next, we develop a large dataset of formal proofs by\ntraining a series of provers. Each new prover can prove many statements that\nprevious ones could not, and these new proofs are added to the training set for\nthe next prover. Finally, we obtain the dataset Goedel-Pset-v1-solved, which\ncontains proofs for over 800K statements from Goedel-Pset-v1. Supervised\nfine-tuning (SFT) of DeepSeek-Prover-V1.5-Base on Goedel-Pset-v1-solved (i.e.,\nno RL) yields a Goedel-Prover-SFT that achieves a success rate of 57.6%\n(Pass@32) on miniF2F, surpassing the previous leader DeepSeek-Prover-V1.5-RL\n(trained using SFT + RL on a proprietary dataset) by 7.6%. On PutnamBench,\nGoedel-Prover-SFT successfully solves 7 problems (Pass@512), ranking first on\nthe leaderboard. We provide extensive discussion of our training methodology,\nhighlighting the key design choices that contribute to Goedel-Prover's strong\nperformance. Further RL training (including DPO) improves Goedel-Prover-SFT's\nsuccess rate to over 60% (Pass@32) on miniF2F.\n  To aid future research, we provide extensive discussion of our training\nmethodology and design choices. We also fully open-source our codes, models,\nand datasets. Additionally, we open-source formal proofs for 29.7K problems in\nLean Workbook, nearly doubling the 15.7K solved by prior provers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07640v3",
    "published_date": "2025-02-11 15:27:35 UTC",
    "updated_date": "2025-04-19 13:53:05 UTC"
  },
  {
    "arxiv_id": "2502.07635v1",
    "title": "Distributed Value Decomposition Networks with Networked Agents",
    "authors": [
      "Guilherme S. Varela",
      "Alberto Sardinha",
      "Francisco S. Melo"
    ],
    "abstract": "We investigate the problem of distributed training under partial\nobservability, whereby cooperative multi-agent reinforcement learning agents\n(MARL) maximize the expected cumulative joint reward. We propose distributed\nvalue decomposition networks (DVDN) that generate a joint Q-function that\nfactorizes into agent-wise Q-functions. Whereas the original value\ndecomposition networks rely on centralized training, our approach is suitable\nfor domains where centralized training is not possible and agents must learn by\ninteracting with the physical environment in a decentralized manner while\ncommunicating with their peers. DVDN overcomes the need for centralized\ntraining by locally estimating the shared objective. We contribute with two\ninnovative algorithms, DVDN and DVDN (GT), for the heterogeneous and\nhomogeneous agents settings respectively. Empirically, both algorithms\napproximate the performance of value decomposition networks, in spite of the\ninformation loss during communication, as demonstrated in ten MARL tasks in\nthree standard environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.6; I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 15 figures, to be published in Proceedings of the 24th\n  International Conference on Autonomous Agents and Multiagent Systems (AAMAS\n  2025), Detroit, Michigan, USA, May 19 - 23, 2025, IFAAMAS",
    "pdf_url": "http://arxiv.org/pdf/2502.07635v1",
    "published_date": "2025-02-11 15:23:05 UTC",
    "updated_date": "2025-02-11 15:23:05 UTC"
  },
  {
    "arxiv_id": "2502.07856v4",
    "title": "MaRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers",
    "authors": [
      "Ao Li",
      "Wei Fang",
      "Hongbo Zhao",
      "Le Lu",
      "Ge Yang",
      "Minfeng Xu"
    ],
    "abstract": "In applications of diffusion models, controllable generation is of practical\nsignificance, but is also challenging. Current methods for controllable\ngeneration primarily focus on modifying the score function of diffusion models,\nwhile Mean Reverting (MR) Diffusion directly modifies the structure of the\nstochastic differential equation (SDE), making the incorporation of image\nconditions simpler and more natural. However, current training-free fast\nsamplers are not directly applicable to MR Diffusion. And thus MR Diffusion\nrequires hundreds of NFEs (number of function evaluations) to obtain\nhigh-quality samples. In this paper, we propose a new algorithm named MaRS (MR\nSampler) to reduce the sampling NFEs of MR Diffusion. We solve the reverse-time\nSDE and the probability flow ordinary differential equation (PF-ODE) associated\nwith MR Diffusion, and derive semi-analytical solutions. The solutions consist\nof an analytical function and an integral parameterized by a neural network.\nBased on this solution, we can generate high-quality samples in fewer steps.\nOur approach does not require training and supports all mainstream\nparameterizations, including noise prediction, data prediction and velocity\nprediction. Extensive experiments demonstrate that MR Sampler maintains high\nsampling quality with a speedup of 10 to 20 times across ten different image\nrestoration tasks. Our algorithm accelerates the sampling procedure of MR\nDiffusion, making it more practical in controllable generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07856v4",
    "published_date": "2025-02-11 14:57:33 UTC",
    "updated_date": "2025-03-24 15:18:25 UTC"
  },
  {
    "arxiv_id": "2502.07591v1",
    "title": "DMWM: Dual-Mind World Model with Long-Term Imagination",
    "authors": [
      "Lingyi Wang",
      "Rashed Shelim",
      "Walid Saad",
      "Naren Ramakrishnan"
    ],
    "abstract": "Imagination in world models is crucial for enabling agents to learn\nlong-horizon policy in a sample-efficient manner. Existing recurrent\nstate-space model (RSSM)-based world models depend on single-step statistical\ninference to capture the environment dynamics, and, hence, they are unable to\nperform long-term imagination tasks due to the accumulation of prediction\nerrors. Inspired by the dual-process theory of human cognition, we propose a\nnovel dual-mind world model (DMWM) framework that integrates logical reasoning\nto enable imagination with logical consistency. DMWM is composed of two\ncomponents: an RSSM-based System 1 (RSSM-S1) component that handles state\ntransitions in an intuitive manner and a logic-integrated neural network-based\nSystem 2 (LINN-S2) component that guides the imagination process through\nhierarchical deep logical reasoning. The inter-system feedback mechanism is\ndesigned to ensure that the imagination process follows the logical rules of\nthe real environment. The proposed framework is evaluated on benchmark tasks\nthat require long-term planning from the DMControl suite. Extensive\nexperimental results demonstrate that the proposed framework yields significant\nimprovements in terms of logical coherence, trial efficiency, data efficiency\nand long-term imagination over the state-of-the-art world models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07591v1",
    "published_date": "2025-02-11 14:40:57 UTC",
    "updated_date": "2025-02-11 14:40:57 UTC"
  },
  {
    "arxiv_id": "2502.07586v1",
    "title": "We Can't Understand AI Using our Existing Vocabulary",
    "authors": [
      "John Hewitt",
      "Robert Geirhos",
      "Been Kim"
    ],
    "abstract": "This position paper argues that, in order to understand AI, we cannot rely on\nour existing vocabulary of human words. Instead, we should strive to develop\nneologisms: new words that represent precise human concepts that we want to\nteach machines, or machine concepts that we need to learn. We start from the\npremise that humans and machines have differing concepts. This means\ninterpretability can be framed as a communication problem: humans must be able\nto reference and control machine concepts, and communicate human concepts to\nmachines. Creating a shared human-machine language through developing\nneologisms, we believe, could solve this communication problem. Successful\nneologisms achieve a useful amount of abstraction: not too detailed, so they're\nreusable in many contexts, and not too high-level, so they convey precise\ninformation. As a proof of concept, we demonstrate how a \"length neologism\"\nenables controlling LLM response length, while a \"diversity neologism\" allows\nsampling more variable responses. Taken together, we argue that we cannot\nunderstand AI using our existing vocabulary, and expanding it through\nneologisms creates opportunities for both controlling and understanding\nmachines better.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Position paper",
    "pdf_url": "http://arxiv.org/pdf/2502.07586v1",
    "published_date": "2025-02-11 14:34:05 UTC",
    "updated_date": "2025-02-11 14:34:05 UTC"
  },
  {
    "arxiv_id": "2502.07577v2",
    "title": "Automated Capability Discovery via Model Self-Exploration",
    "authors": [
      "Cong Lu",
      "Shengran Hu",
      "Jeff Clune"
    ],
    "abstract": "Foundation models have become general-purpose assistants, exhibiting diverse\ncapabilities across numerous domains through training on web-scale data. It\nremains challenging to precisely characterize even a fraction of the full\nspectrum of capabilities and potential risks in any new model. Existing\nevaluation approaches often require significant human effort, and it is taking\nincreasing effort to design ever harder challenges for more capable models. We\nintroduce Automated Capability Discovery (ACD), a framework that designates one\nfoundation model as a scientist to systematically propose open-ended tasks\nprobing the abilities of a subject model (potentially itself). By combining\nfrontier models with ideas from the field of open-endedness, ACD automatically\nand systematically uncovers both surprising capabilities and failures in the\nsubject model. We demonstrate ACD across a range of foundation models\n(including the GPT, Claude, and Llama series), showing that it automatically\nreveals thousands of capabilities that would be challenging for any single team\nto uncover. We further validate our method's automated scoring with extensive\nhuman surveys, observing high agreement between model-generated and human\nevaluations. By leveraging foundation models' ability to both create tasks and\nself-evaluate, ACD is a significant step toward scalable, automated evaluation\nof novel AI systems. All code and evaluation logs are open-sourced at\nhttps://github.com/conglu1997/ACD.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07577v2",
    "published_date": "2025-02-11 14:23:13 UTC",
    "updated_date": "2025-02-12 16:25:44 UTC"
  },
  {
    "arxiv_id": "2502.07855v1",
    "title": "Vision-Language Models for Edge Networks: A Comprehensive Survey",
    "authors": [
      "Ahmed Sharshar",
      "Latif U. Khan",
      "Waseem Ullah",
      "Mohsen Guizani"
    ],
    "abstract": "Vision Large Language Models (VLMs) combine visual understanding with natural\nlanguage processing, enabling tasks like image captioning, visual question\nanswering, and video analysis. While VLMs show impressive capabilities across\ndomains such as autonomous vehicles, smart surveillance, and healthcare, their\ndeployment on resource-constrained edge devices remains challenging due to\nprocessing power, memory, and energy limitations. This survey explores recent\nadvancements in optimizing VLMs for edge environments, focusing on model\ncompression techniques, including pruning, quantization, knowledge\ndistillation, and specialized hardware solutions that enhance efficiency. We\nprovide a detailed discussion of efficient training and fine-tuning methods,\nedge deployment challenges, and privacy considerations. Additionally, we\ndiscuss the diverse applications of lightweight VLMs across healthcare,\nenvironmental monitoring, and autonomous systems, illustrating their growing\nimpact. By highlighting key design strategies, current challenges, and offering\nrecommendations for future directions, this survey aims to inspire further\nresearch into the practical deployment of VLMs, ultimately making advanced AI\naccessible in resource-limited settings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07855v1",
    "published_date": "2025-02-11 14:04:43 UTC",
    "updated_date": "2025-02-11 14:04:43 UTC"
  },
  {
    "arxiv_id": "2502.09649v1",
    "title": "Imit Diff: Semantics Guided Diffusion Transformer with Dual Resolution Fusion for Imitation Learning",
    "authors": [
      "Yuhang Dong",
      "Haizhou Ge",
      "Yupei Zeng",
      "Jiangning Zhang",
      "Beiwen Tian",
      "Guanzhong Tian",
      "Hongrui Zhu",
      "Yufei Jia",
      "Ruixiang Wang",
      "Ran Yi",
      "Guyue Zhou",
      "Longhua Ma"
    ],
    "abstract": "Visuomotor imitation learning enables embodied agents to effectively acquire\nmanipulation skills from video demonstrations and robot proprioception.\nHowever, as scene complexity and visual distractions increase, existing methods\nthat perform well in simple scenes tend to degrade in performance. To address\nthis challenge, we introduce Imit Diff, a semanstic guided diffusion\ntransformer with dual resolution fusion for imitation learning. Our approach\nleverages prior knowledge from vision language foundation models to translate\nhigh-level semantic instruction into pixel-level visual localization. This\ninformation is explicitly integrated into a multi-scale visual enhancement\nframework, constructed with a dual resolution encoder. Additionally, we\nintroduce an implementation of Consistency Policy within the diffusion\ntransformer architecture to improve both real-time performance and motion\nsmoothness in embodied agent control.We evaluate Imit Diff on several\nchallenging real-world tasks. Due to its task-oriented visual localization and\nfine-grained scene perception, it significantly outperforms state-of-the-art\nmethods, especially in complex scenes with visual distractions, including\nzero-shot experiments focused on visual distraction and category\ngeneralization. The code will be made publicly available.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09649v1",
    "published_date": "2025-02-11 14:03:57 UTC",
    "updated_date": "2025-02-11 14:03:57 UTC"
  },
  {
    "arxiv_id": "2502.07563v1",
    "title": "LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid",
    "authors": [
      "Weigao Sun",
      "Disen Lan",
      "Yiran Zhong",
      "Xiaoye Qu",
      "Yu Cheng"
    ],
    "abstract": "Linear sequence modeling approaches, such as linear attention, provide\nadvantages like linear-time training and constant-memory inference over\nsequence lengths. However, existing sequence parallelism (SP) methods are\neither not optimized for the right-product-first feature of linear attention or\nuse a ring-style communication strategy, which results in lower computation\nparallelism, limits their scalability for longer sequences in distributed\nsystems. In this paper, we introduce LASP-2, a new SP method to enhance both\ncommunication and computation parallelism when training linear attention\ntransformer models with very-long input sequences. Compared to previous work\nLASP, LASP-2 rethinks the minimal communication requirement for SP on linear\nattention layers, reorganizes the whole communication-computation workflow of\nLASP. In this way, only one single AllGather collective communication is needed\non intermediate memory states, whose sizes are independent of the sequence\nlength, leading to significant improvements of both communication and\ncomputation parallelism, as well as their overlap. Additionally, we extend\nLASP-2 to LASP-2H by applying similar communication redesign to standard\nattention modules, offering an efficient SP solution for hybrid models that\nblend linear and standard attention layers. Our evaluation on a Linear-Llama3\nmodel, a variant of Llama3 with linear attention replacing standard attention,\ndemonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2\nachieves training speed improvements of 15.2% over LASP and 36.6% over Ring\nAttention, with a sequence length of 2048K across 64 GPUs. The Code is released\nas a part of: https://github.com/OpenSparseLLMs/Linear-MoE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Technical report, 17 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.07563v1",
    "published_date": "2025-02-11 14:01:39 UTC",
    "updated_date": "2025-02-11 14:01:39 UTC"
  },
  {
    "arxiv_id": "2502.07562v1",
    "title": "LoRP-TTS: Low-Rank Personalized Text-To-Speech",
    "authors": [
      "Åukasz Bondaruk",
      "Jakub Kubiak"
    ],
    "abstract": "Speech synthesis models convert written text into natural-sounding audio.\nWhile earlier models were limited to a single speaker, recent advancements have\nled to the development of zero-shot systems that generate realistic speech from\na wide range of speakers using their voices as additional prompts. However,\nthey still struggle with imitating non-studio-quality samples that differ\nsignificantly from the training datasets. In this work, we demonstrate that\nutilizing Low-Rank Adaptation (LoRA) allows us to successfully use even single\nrecordings of spontaneous speech in noisy environments as prompts. This\napproach enhances speaker similarity by up to $30pp$ while preserving content\nand naturalness. It represents a significant step toward creating truly diverse\nspeech corpora, that is crucial in all speech-related tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07562v1",
    "published_date": "2025-02-11 14:00:12 UTC",
    "updated_date": "2025-02-11 14:00:12 UTC"
  },
  {
    "arxiv_id": "2502.07552v1",
    "title": "Unsupervised Translation of Emergent Communication",
    "authors": [
      "Ido Levy",
      "Orr Paradise",
      "Boaz Carmeli",
      "Ron Meir",
      "Shafi Goldwasser",
      "Yonatan Belinkov"
    ],
    "abstract": "Emergent Communication (EC) provides a unique window into the language\nsystems that emerge autonomously when agents are trained to jointly achieve\nshared goals. However, it is difficult to interpret EC and evaluate its\nrelationship with natural languages (NL). This study employs unsupervised\nneural machine translation (UNMT) techniques to decipher ECs formed during\nreferential games with varying task complexities, influenced by the semantic\ndiversity of the environment. Our findings demonstrate UNMT's potential to\ntranslate EC, illustrating that task complexity characterized by semantic\ndiversity enhances EC translatability, while higher task complexity with\nconstrained semantic variability exhibits pragmatic EC, which, although\nchallenging to interpret, remains suitable for translation. This research marks\nthe first attempt, to our knowledge, to translate EC without the aid of\nparallel data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages (including appendix and bibliography), Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07552v1",
    "published_date": "2025-02-11 13:41:06 UTC",
    "updated_date": "2025-02-11 13:41:06 UTC"
  },
  {
    "arxiv_id": "2502.07549v1",
    "title": "HGTUL: A Hypergraph-based Model For Trajectory User Linking",
    "authors": [
      "Fengjie Chang",
      "Xinning Zhu",
      "Zheng Hu",
      "Yang Qin"
    ],
    "abstract": "Trajectory User Linking (TUL), which links anonymous trajectories with users\nwho generate them, plays a crucial role in modeling human mobility. Despite\nsignificant advancements in this field, existing studies primarily neglect the\nhigh-order inter-trajectory relationships, which represent complex associations\namong multiple trajectories, manifested through multi-location co-occurrence\npatterns emerging when trajectories intersect at various Points of Interest\n(POIs). Furthermore, they also overlook the variable influence of POIs on\ndifferent trajectories, as well as the user class imbalance problem caused by\ndisparities in user activity levels and check-in frequencies. To address these\nlimitations, we propose a novel HyperGraph-based multi-perspective Trajectory\nUser Linking model (HGTUL). Our model learns trajectory representations from\nboth relational and spatio-temporal perspectives: (1) it captures high-order\nassociations among trajectories by constructing a trajectory hypergraph and\nleverages a hypergraph attention network to learn the variable impact of POIs\non trajectories; (2) it models the spatio-temporal characteristics of\ntrajectories by incorporating their temporal and spatial information into a\nsequential encoder. Moreover, we design a data balancing method to effectively\naddress the user class imbalance problem and experimentally validate its\nsignificance in TUL. Extensive experiments on three real-world datasets\ndemonstrate that HGTUL outperforms state-of-the-art baselines, achieving\nimprovements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68-07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07549v1",
    "published_date": "2025-02-11 13:39:35 UTC",
    "updated_date": "2025-02-11 13:39:35 UTC"
  },
  {
    "arxiv_id": "2502.09648v1",
    "title": "UKTA: Unified Korean Text Analyzer",
    "authors": [
      "Seokho Ahn",
      "Junhyung Park",
      "Ganghee Go",
      "Chulhui Kim",
      "Jiho Jung",
      "Myung Sun Shin",
      "Do-Guk Kim",
      "Young-Duk Seo"
    ],
    "abstract": "Evaluating writing quality is complex and time-consuming often delaying\nfeedback to learners. While automated writing evaluation tools are effective\nfor English, Korean automated writing evaluation tools face challenges due to\ntheir inability to address multi-view analysis, error propagation, and\nevaluation explainability. To overcome these challenges, we introduce UKTA\n(Unified Korean Text Analyzer), a comprehensive Korea text analysis and writing\nevaluation system. UKTA provides accurate low-level morpheme analysis, key\nlexical features for mid-level explainability, and transparent high-level\nrubric-based writing scores. Our approach enhances accuracy and quadratic\nweighted kappa over existing baseline, positioning UKTA as a leading\nmulti-perspective tool for Korean text analysis and writing evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by SAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.09648v1",
    "published_date": "2025-02-11 13:30:56 UTC",
    "updated_date": "2025-02-11 13:30:56 UTC"
  },
  {
    "arxiv_id": "2502.07542v2",
    "title": "Exoplanet Transit Candidate Identification in TESS Full-Frame Images via a Transformer-Based Algorithm",
    "authors": [
      "Helem Salinas",
      "Rafael Brahm",
      "Greg Olmschenk",
      "Richard K. Barry",
      "Karim Pichara",
      "Stela Ishitani Silva",
      "Vladimir Araujo"
    ],
    "abstract": "The Transiting Exoplanet Survey Satellite (TESS) is surveying a large\nfraction of the sky, generating a vast database of photometric time series data\nthat requires thorough analysis to identify exoplanetary transit signals.\nAutomated learning approaches have been successfully applied to identify\ntransit signals. However, most existing methods focus on the classification and\nvalidation of candidates, while few efforts have explored new techniques for\nthe search of candidates. To search for new exoplanet transit candidates, we\npropose an approach to identify exoplanet transit signals without the need for\nphase folding or assuming periodicity in the transit signals, such as those\nobserved in multi-transit light curves. To achieve this, we implement a new\nneural network inspired by Transformers to directly process Full Frame Image\n(FFI) light curves to detect exoplanet transits. Transformers, originally\ndeveloped for natural language processing, have recently demonstrated\nsignificant success in capturing long-range dependencies compared to previous\napproaches focused on sequential data. This ability allows us to employ\nmulti-head self-attention to identify exoplanet transit signals directly from\nthe complete light curves, combined with background and centroid time series,\nwithout requiring prior transit parameters. The network is trained to learn\ncharacteristics of the transit signal, like the dip shape, which helps\ndistinguish planetary transits from other variability sources. Our model\nsuccessfully identified 214 new planetary system candidates, including 122\nmulti-transit light curves, 88 single-transit and 4 multi-planet systems from\nTESS sectors 1-26 with a radius > 0.27 $R_{\\mathrm{Jupiter}}$, demonstrating\nits ability to detect transits regardless of their periodicity.",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.EP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07542v2",
    "published_date": "2025-02-11 13:29:58 UTC",
    "updated_date": "2025-03-07 17:49:02 UTC"
  },
  {
    "arxiv_id": "2502.15755v2",
    "title": "Physics-consistent machine learning: output projection onto physical manifolds",
    "authors": [
      "Matilde Valente",
      "Tiago C. Dias",
      "Vasco Guerra",
      "Rodrigo Ventura"
    ],
    "abstract": "Data-driven machine learning models often require extensive datasets, which\ncan be costly or inaccessible, and their predictions may fail to comply with\nestablished physical laws. Current approaches for incorporating physical priors\nmitigate these issues by penalizing deviations from known physical laws, as in\nphysics-informed neural networks, or by designing architectures that\nautomatically satisfy specific invariants. However, penalization approaches do\nnot guarantee compliance with physical constraints for unseen inputs, and\ninvariant-based methods lack flexibility and generality. We propose a novel\nphysics-consistent machine learning method that directly enforces compliance\nwith physical principles by projecting model outputs onto the manifold defined\nby these laws. This procedure ensures that predictions inherently adhere to the\nchosen physical constraints, improving reliability and interpretability. Our\nmethod is demonstrated on two systems: a spring-mass system and a\nlow-temperature reactive plasma. Compared to purely data-driven models, our\napproach significantly reduces errors in physical law compliance, enhances\npredictive accuracy of physical quantities, and outperforms alternatives when\nworking with simpler models or limited datasets. The proposed projection-based\ntechnique is versatile and can function independently or in conjunction with\nexisting physics-informed neural networks, offering a powerful, general, and\nscalable solution for developing fast and reliable surrogate models of complex\nphysical systems, particularly in resource-constrained scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.plasm-ph",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15755v2",
    "published_date": "2025-02-11 13:18:19 UTC",
    "updated_date": "2025-03-06 21:52:47 UTC"
  },
  {
    "arxiv_id": "2502.13149v3",
    "title": "Bi-Fact: A Bidirectional Factorization-based Evaluation of Intent Extraction from UI Trajectories",
    "authors": [
      "Sapir Caduri",
      "Anatoly Efros",
      "Noam Kahlon",
      "Danielle Cohen",
      "Yoni Halpern",
      "Ido Dagan"
    ],
    "abstract": "Evaluating intent extraction from GUIs demands accurate, fine-grained\nmetrics. This paper introduces Bi-Fact, a novel method that decomposes intents\ninto atomic facts and performs bidirectional comparisons to assess precision\nand recall. Experiments demonstrate Bi-Fact's superior correlation with human\njudgments compared to existing metrics, establishing a more robust evaluation\nframework for UI-driven intent understanding.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13149v3",
    "published_date": "2025-02-11 13:16:31 UTC",
    "updated_date": "2025-03-05 09:54:25 UTC"
  },
  {
    "arxiv_id": "2502.07531v3",
    "title": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation",
    "authors": [
      "Sixiao Zheng",
      "Zimian Peng",
      "Yanpeng Zhou",
      "Yi Zhu",
      "Hang Xu",
      "Xiangru Huang",
      "Yanwei Fu"
    ],
    "abstract": "Recent image-to-video generation methods have demonstrated success in\nenabling control over one or two visual elements, such as camera motion or\nobject motion. However, these methods are unable to offer control over multiple\nvisual elements due to limitations in data and network efficacy. In this paper,\nwe introduce VidCRAFT3, a novel framework for precise image-to-video generation\nthat enables control over camera motion, object motion, and lighting direction\nsimultaneously. VidCRAFT3 integrates three core components: Image2Cloud\ngenerates 3D point cloud from a reference image; ObjMotionNet encodes sparse\nobject trajectories using multi-scale optical flow features; and Spatial\nTriple-Attention Transformer incorporates lighting direction embeddings via\nparallel cross-attention modules. Additionally, we introduce the\nVideoLightingDirection dataset, providing synthetic yet realistic video clips\nwith accurate per-frame lighting direction annotations, effectively mitigating\nthe lack of annotated real-world datasets. We further adopt a three-stage\ntraining strategy, ensuring robust learning even without joint multi-element\nannotations. Extensive experiments show that VidCRAFT3 produces high-quality\nvideo content, outperforming state-of-the-art methods in control granularity\nand visual coherence. Code and data will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07531v3",
    "published_date": "2025-02-11 13:11:59 UTC",
    "updated_date": "2025-04-02 03:56:07 UTC"
  },
  {
    "arxiv_id": "2502.07527v2",
    "title": "Nature Language Model: Deciphering the Language of Nature for Scientific Discovery",
    "authors": [
      "Yingce Xia",
      "Peiran Jin",
      "Shufang Xie",
      "Liang He",
      "Chuan Cao",
      "Renqian Luo",
      "Guoqing Liu",
      "Yue Wang",
      "Zequn Liu",
      "Yuan-Jyue Chen",
      "Zekun Guo",
      "Yeqi Bai",
      "Pan Deng",
      "Yaosen Min",
      "Ziheng Lu",
      "Hongxia Hao",
      "Han Yang",
      "Jielan Li",
      "Chang Liu",
      "Jia Zhang",
      "Jianwei Zhu",
      "Ran Bi",
      "Kehan Wu",
      "Wei Zhang",
      "Kaiyuan Gao",
      "Qizhi Pei",
      "Qian Wang",
      "Xixian Liu",
      "Yanting Li",
      "Houtian Zhu",
      "Yeqing Lu",
      "Mingqian Ma",
      "Zun Wang",
      "Tian Xie",
      "Krzysztof Maziarz",
      "Marwin Segler",
      "Zhao Yang",
      "Zilong Chen",
      "Yu Shi",
      "Shuxin Zheng",
      "Lijun Wu",
      "Chen Hu",
      "Peggy Dai",
      "Tie-Yan Liu",
      "Haiguang Liu",
      "Tao Qin"
    ],
    "abstract": "Foundation models have revolutionized natural language processing and\nartificial intelligence, significantly enhancing how machines comprehend and\ngenerate human languages. Inspired by the success of these foundation models,\nresearchers have developed foundation models for individual scientific domains,\nincluding small molecules, materials, proteins, DNA, RNA and even cells.\nHowever, these models are typically trained in isolation, lacking the ability\nto integrate across different scientific domains. Recognizing that entities\nwithin these domains can all be represented as sequences, which together form\nthe \"language of nature\", we introduce Nature Language Model (NatureLM), a\nsequence-based science foundation model designed for scientific discovery.\nPre-trained with data from multiple scientific domains, NatureLM offers a\nunified, versatile model that enables various applications including: (i)\ngenerating and optimizing small molecules, proteins, RNA, and materials using\ntext instructions; (ii) cross-domain generation/design, such as\nprotein-to-molecule and protein-to-RNA generation; and (iii) top performance\nacross different domains, matching or surpassing state-of-the-art specialist\nmodels. NatureLM offers a promising generalist approach for various scientific\ntasks, including drug discovery (hit generation/optimization, ADMET\noptimization, synthesis), novel material design, and the development of\ntherapeutic proteins or nucleotides. We have developed NatureLM models in\ndifferent sizes (1 billion, 8 billion, and 46.7 billion parameters) and\nobserved a clear improvement in performance as the model size increases.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "93 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.07527v2",
    "published_date": "2025-02-11 13:08:03 UTC",
    "updated_date": "2025-03-06 12:34:23 UTC"
  },
  {
    "arxiv_id": "2502.07523v1",
    "title": "Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization",
    "authors": [
      "Daniel Palenicek",
      "Florian Vogt",
      "Jan Peters"
    ],
    "abstract": "Reinforcement learning has achieved significant milestones, but sample\nefficiency remains a bottleneck for real-world applications. Recently, CrossQ\nhas demonstrated state-of-the-art sample efficiency with a low update-to-data\n(UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with\nhigher UTD ratios. We identify challenges in the training dynamics, which are\nemphasized by higher UTD ratios. To address these, we integrate weight\nnormalization into the CrossQ framework, a solution that stabilizes training,\nhas been shown to prevent potential loss of plasticity and keeps the effective\nlearning rate constant. Our proposed approach reliably scales with increasing\nUTD ratios, achieving competitive performance across 25 challenging continuous\ncontrol tasks on the DeepMind Control Suite and Myosuite benchmarks, notably\nthe complex dog and humanoid environments. This work eliminates the need for\ndrastic interventions, such as network resets, and offers a simple yet robust\npathway for improving sample efficiency and scalability in model-free\nreinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07523v1",
    "published_date": "2025-02-11 12:55:32 UTC",
    "updated_date": "2025-02-11 12:55:32 UTC"
  },
  {
    "arxiv_id": "2502.07516v2",
    "title": "The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation",
    "authors": [
      "Raman Dutt"
    ],
    "abstract": "Generative models, particularly text-to-image (T2I) diffusion models, play a\ncrucial role in medical image analysis. However, these models are prone to\ntraining data memorization, posing significant risks to patient privacy.\nSynthetic chest X-ray generation is one of the most common applications in\nmedical image analysis with the MIMIC-CXR dataset serving as the primary data\nrepository for this task. This study presents the first systematic attempt to\nidentify prompts and text tokens in MIMIC-CXR that contribute the most to\ntraining data memorization. Our analysis reveals two unexpected findings: (1)\nprompts containing traces of de-identification procedures (markers introduced\nto hide Protected Health Information) are the most memorized, and (2) among all\ntokens, de-identification markers contribute the most towards memorization.\nThis highlights a broader issue with the standard anonymization practices and\nT2I synthesis with MIMIC-CXR. To exacerbate, existing inference-time\nmemorization mitigation strategies are ineffective and fail to sufficiently\nreduce the model's reliance on memorized text tokens. On this front, we propose\nactionable strategies for different stakeholders to enhance privacy and improve\nthe reliability of generative models in medical imaging. Finally, our results\nprovide a foundation for future work on developing and benchmarking\nmemorization mitigation techniques for synthetic chest X-ray generation using\nthe MIMIC-CXR dataset. The anonymized code is available at\nhttps://anonymous.4open.science/r/diffusion_memorization-8011/",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07516v2",
    "published_date": "2025-02-11 12:36:00 UTC",
    "updated_date": "2025-02-14 17:24:56 UTC"
  },
  {
    "arxiv_id": "2502.08453v1",
    "title": "Proceedings 40th International Conference on Logic Programming",
    "authors": [
      "Pedro Cabalar",
      "Francesco Fabiano",
      "Martin Gebser",
      "Gopal Gupta",
      "Theresa Swift"
    ],
    "abstract": "Since the first conference In Marseille in 1982, the International Conference\non Logic Programming (ICLP) has been the premier international event for\npresenting research in logic programming. These proceedings include technical\ncommunications about, and abstracts for presentations given at the 40th ICLP\nheld October 14-17, in Dallas Texas, USA. The papers and abstracts in this\nvolume include the following areas and topics. Formal and operational\nsemantics: including non-monotonic reasoning, probabilistic reasoning,\nargumentation, and semantic issues of combining logic with neural models.\nLanguage design and programming methodologies such as answer set programming.\ninductive logic programming, and probabilistic programming. Program analysis\nand logic-based validation of generated programs. Implementation methodologies\nincluding constraint implementation, tabling, Logic-based prompt engineering,\nand the interaction of logic programming with LLMs.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08453v1",
    "published_date": "2025-02-11 12:13:52 UTC",
    "updated_date": "2025-02-11 12:13:52 UTC"
  },
  {
    "arxiv_id": "2502.07503v4",
    "title": "Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Xiaohua Zhai"
    ],
    "abstract": "Inspired by recent findings on the fractal geometry of language, we introduce\nRecursive INference Scaling (RINS) as a complementary, plug-in recipe for\nscaling inference time in language and multimodal systems. RINS is a particular\nform of recursive depth that significantly outperforms +55 other variants,\nincluding the recent \"repeat-all-over\" (RAO) strategy in Mobile LLM (Liu et\nal., 2024) and latent recurrent thinking (Geiping et al., 2025). Unlike prior\nworks, we carry out our comparisons on a compute-matched regime, and\ndemonstrate that for a fixed model size and training compute budget, RINS\nsubstantially improves language modeling performance. It also generalizes\nbeyond pure language tasks, delivering gains in multimodal systems, including a\n+2% improvement in 0-shot ImageNet accuracy for SigLIP-B/16. Additionally, by\nderiving data scaling laws, we show that RINS improves both the asymptotic\nperformance limits and the scaling exponents. More importantly, with\nlight-weight (linear) adapters (comprising <1% of model parameters) and\nstochastic dropout, RINS offers a no-regret strategy, meaning that RINS-enabled\npretraining improves performance in language modeling even when recursive depth\nis not applied at inference time. This corresponds to improving performance on\na training compute-, parameter-, and inference-matched regime, suggesting its\npotential as a viable component of LLM pretraining!",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07503v4",
    "published_date": "2025-02-11 12:11:40 UTC",
    "updated_date": "2025-05-08 11:40:01 UTC"
  },
  {
    "arxiv_id": "2502.07494v1",
    "title": "URECA: The Chain of Two Minimum Set Cover Problems exists behind Adaptation to Shifts in Semantic Code Search",
    "authors": [
      "Seok-Ung Choi",
      "Joonghyuk Hahn",
      "Yo-Sub Han"
    ],
    "abstract": "Adaptation is to make model learn the patterns shifted from the training\ndistribution. In general, this adaptation is formulated as the minimum entropy\nproblem. However, the minimum entropy problem has inherent limitation --\nshifted initialization cascade phenomenon. We extend the relationship between\nthe minimum entropy problem and the minimum set cover problem via Lebesgue\nintegral. This extension reveals that internal mechanism of the minimum entropy\nproblem ignores the relationship between disentangled representations, which\nleads to shifted initialization cascade. From the analysis, we introduce a new\nclustering algorithm, Union-find based Recursive Clustering Algorithm~(URECA).\nURECA is an efficient clustering algorithm for the leverage of the\nrelationships between disentangled representations. The update rule of URECA\ndepends on Thresholdly-Updatable Stationary Assumption to dynamics as a\nreleased version of Stationary Assumption. This assumption helps URECA to\ntransport disentangled representations with no errors based on the\nrelationships between disentangled representations. URECA also utilize\nsimulation trick to efficiently cluster disentangled representations. The wide\nrange of evaluations show that URECA achieves consistent performance gains for\nthe few-shot adaptation to diverse types of shifts along with advancement to\nState-of-The-Art performance in CoSQA in the scenario of query shift.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07494v1",
    "published_date": "2025-02-11 11:53:23 UTC",
    "updated_date": "2025-02-11 11:53:23 UTC"
  },
  {
    "arxiv_id": "2502.07479v1",
    "title": "WebChecker: A Versatile EVL Plugin for Validating HTML Pages with Bootstrap Frameworks",
    "authors": [
      "Milind Cherukuri"
    ],
    "abstract": "WebChecker is a plugin for Epsilon Validation Language (EVL), designed to\nvalidate both static and dynamic HTML pages utilizing frameworks like\nBootstrap. By employing configurable EVL constraints, WebChecker enforces\nimplicit rules governing HTML and CSS frameworks. The effectiveness of the\nplugin is demonstrated through its application on Bootstrap, the widely adopted\nHTML, CSS, and JavaScript framework. WebChecker comes with a set of EVL\nconstraints to assess Bootstrap based web pages. To substantiate our claims, I\npresent an illustrative example featuring two solutions that effectively\nenforce implicit rules.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07479v1",
    "published_date": "2025-02-11 11:40:43 UTC",
    "updated_date": "2025-02-11 11:40:43 UTC"
  },
  {
    "arxiv_id": "2502.07469v1",
    "title": "5D Neural Surrogates for Nonlinear Gyrokinetic Simulations of Plasma Turbulence",
    "authors": [
      "Gianluca Galletti",
      "Fabian Paischer",
      "Paul Setinek",
      "William Hornsby",
      "Lorenzo Zanisi",
      "Naomi Carey",
      "Stanislas Pamela",
      "Johannes Brandstetter"
    ],
    "abstract": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable\nenergy production. A major roadblock to achieving commercially viable fusion\npower is understanding plasma turbulence, which can significantly degrade\nplasma confinement. Modelling turbulence is crucial to design performing plasma\nscenarios for next-generation reactor-class devices and current experimental\nmachines. The nonlinear gyrokinetic equation underpinning turbulence modelling\nevolves a 5D distribution function over time. Solving this equation numerically\nis extremely expensive, requiring up to weeks for a single run to converge,\nmaking it unfeasible for iterative optimisation and control studies. In this\nwork, we propose a method for training neural surrogates for 5D gyrokinetic\nsimulations. Our method extends a hierarchical vision transformer to five\ndimensions and is trained on the 5D distribution function for the adiabatic\nelectron approximation. We demonstrate that our model can accurately infer\ndownstream physical quantities such as heat flux time trace and electrostatic\npotentials for single-step predictions two orders of magnitude faster than\nnumerical codes. Our work paves the way towards neural surrogates for plasma\nturbulence simulations to accelerate deployment of commercial energy production\nvia nuclear fusion.",
    "categories": [
      "physics.plasm-ph",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "physics.plasm-ph",
    "comment": "6 pages (+ references and appendix)",
    "pdf_url": "http://arxiv.org/pdf/2502.07469v1",
    "published_date": "2025-02-11 11:25:10 UTC",
    "updated_date": "2025-02-11 11:25:10 UTC"
  },
  {
    "arxiv_id": "2502.07465v2",
    "title": "Crime Forecasting: A Spatio-temporal Analysis with Deep Learning Models",
    "authors": [
      "Li Mao",
      "Wei Du",
      "Shuo Wen",
      "Qi Li",
      "Tong Zhang",
      "Wei Zhong"
    ],
    "abstract": "This study uses deep-learning models to predict city partition crime counts\non specific days. It helps police enhance surveillance, gather intelligence,\nand proactively prevent crimes. We formulate crime count prediction as a\nspatiotemporal sequence challenge, where both input data and prediction targets\nare spatiotemporal sequences. In order to improve the accuracy of crime\nforecasting, we introduce a new model that combines Convolutional Neural\nNetworks (CNN) and Long Short-Term Memory (LSTM) networks. We conducted a\ncomparative analysis to access the effects of various data sequences, including\nraw and binned data, on the prediction errors of four deep learning forecasting\nmodels. Directly inputting raw crime data into the forecasting model causes\nhigh prediction errors, making the model unsuitable for real - world use. The\nfindings indicate that the proposed CNN-LSTM model achieves optimal performance\nwhen crime data is categorized into 10 or 5 groups. Data binning can enhance\nforecasting model performance, but poorly defined intervals may reduce map\ngranularity. Compared to dividing into 5 bins, binning into 10 intervals\nstrikes an optimal balance, preserving data characteristics and surpassing raw\ndata in predictive modelling efficacy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper was submitted without the consent of all co-authors. The\n  content of the paper is incomplete and requires substantial additional work\n  before it can be considered a complete and coherent submission",
    "pdf_url": "http://arxiv.org/pdf/2502.07465v2",
    "published_date": "2025-02-11 11:16:59 UTC",
    "updated_date": "2025-02-13 14:38:24 UTC"
  },
  {
    "arxiv_id": "2502.07461v2",
    "title": "JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata",
    "authors": [
      "Abhinaba Roy",
      "Renhang Liu",
      "Tongyu Lu",
      "Dorien Herremans"
    ],
    "abstract": "We introduce JamendoMaxCaps, a large-scale music-caption dataset featuring\nover 362,000 freely licensed instrumental tracks from the renowned Jamendo\nplatform. The dataset includes captions generated by a state-of-the-art\ncaptioning model, enhanced with imputed metadata. We also introduce a retrieval\nsystem that leverages both musical features and metadata to identify similar\nsongs, which are then used to fill in missing metadata using a local large\nlanguage model (LLLM). This approach allows us to provide a more comprehensive\nand informative dataset for researchers working on music-language understanding\ntasks. We validate this approach quantitatively with five different\nmeasurements. By making the JamendoMaxCaps dataset publicly available, we\nprovide a high-quality resource to advance research in music-language\nunderstanding tasks such as music retrieval, multimodal representation\nlearning, and generative music models.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07461v2",
    "published_date": "2025-02-11 11:12:19 UTC",
    "updated_date": "2025-05-16 07:57:01 UTC"
  },
  {
    "arxiv_id": "2502.07459v1",
    "title": "PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian",
    "authors": [
      "Erfan Moosavi Monazzah",
      "Vahid Rahimzadeh",
      "Yadollah Yaghoobzadeh",
      "Azadeh Shakery",
      "Mohammad Taher Pilehvar"
    ],
    "abstract": "Large language models predominantly reflect Western cultures, largely due to\nthe dominance of English-centric training data. This imbalance presents a\nsignificant challenge, as LLMs are increasingly used across diverse contexts\nwithout adequate evaluation of their cultural competence in non-English\nlanguages, including Persian. To address this gap, we introduce PerCul, a\ncarefully constructed dataset designed to assess the sensitivity of LLMs toward\nPersian culture. PerCul features story-based, multiple-choice questions that\ncapture culturally nuanced scenarios. Unlike existing benchmarks, PerCul is\ncurated with input from native Persian annotators to ensure authenticity and to\nprevent the use of translation as a shortcut. We evaluate several\nstate-of-the-art multilingual and Persian-specific LLMs, establishing a\nfoundation for future research in cross-cultural NLP evaluation. Our\nexperiments demonstrate a 11.3% gap between best closed source model and\nlayperson baseline while the gap increases to 21.3% by using the best\nopen-weight model. You can access the dataset from here:\nhttps://huggingface.co/datasets/teias-ai/percul",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 Main Conference, the dataset is available on\n  HuggingFace (see https://huggingface.co/datasets/teias-ai/percul)",
    "pdf_url": "http://arxiv.org/pdf/2502.07459v1",
    "published_date": "2025-02-11 11:07:44 UTC",
    "updated_date": "2025-02-11 11:07:44 UTC"
  },
  {
    "arxiv_id": "2502.07455v1",
    "title": "RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation",
    "authors": [
      "Viacheslav Vasilev",
      "Julia Agafonova",
      "Nikolai Gerasimenko",
      "Alexander Kapitanov",
      "Polina Mikhailova",
      "Evelina Mironova",
      "Denis Dimitrov"
    ],
    "abstract": "Text-to-image generation models have gained popularity among users around the\nworld. However, many of these models exhibit a strong bias toward\nEnglish-speaking cultures, ignoring or misrepresenting the unique\ncharacteristics of other language groups, countries, and nationalities. The\nlack of cultural awareness can reduce the generation quality and lead to\nundesirable consequences such as unintentional insult, and the spread of\nprejudice. In contrast to the field of natural language processing, cultural\nawareness in computer vision has not been explored as extensively. In this\npaper, we strive to reduce this gap. We propose a RusCode benchmark for\nevaluating the quality of text-to-image generation containing elements of the\nRussian cultural code. To do this, we form a list of 19 categories that best\nrepresent the features of Russian visual culture. Our final dataset consists of\n1250 text prompts in Russian and their translations into English. The prompts\ncover a wide range of topics, including complex concepts from art, popular\nculture, folk traditions, famous people's names, natural objects, scientific\nachievements, etc. We present the results of a human evaluation of the\nside-by-side comparison of Russian visual concepts representations using\npopular generative models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for NAACL 2025 Findings, GitHub:\n  https://github.com/ai-forever/RusCode",
    "pdf_url": "http://arxiv.org/pdf/2502.07455v1",
    "published_date": "2025-02-11 10:57:12 UTC",
    "updated_date": "2025-02-11 10:57:12 UTC"
  },
  {
    "arxiv_id": "2502.07452v1",
    "title": "Eliciting Rational Initial Weights in Gradual Argumentation",
    "authors": [
      "Nir Oren",
      "Bruno Yun"
    ],
    "abstract": "Many semantics for weighted argumentation frameworks assume that each\nargument is associated with an initial weight. However, eliciting these initial\nweights poses challenges: (1) accurately providing a specific numerical value\nis often difficult, and (2) individuals frequently confuse initial weights with\nacceptability degrees in the presence of other arguments. To address these\nissues, we propose an elicitation pipeline that allows one to specify\nacceptability degree intervals for each argument. By employing gradual\nsemantics, we can refine these intervals when they are rational, restore\nrationality when they are not, and ultimately identify possible initial weights\nfor each argument.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07452v1",
    "published_date": "2025-02-11 10:52:54 UTC",
    "updated_date": "2025-02-11 10:52:54 UTC"
  },
  {
    "arxiv_id": "2502.07445v1",
    "title": "Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon",
    "authors": [
      "Nurit Cohen-Inger",
      "Yehonatan Elisha",
      "Bracha Shapira",
      "Lior Rokach",
      "Seffi Cohen"
    ],
    "abstract": "Large language models (LLMs) often appear to excel on public benchmarks, but\nthese high scores may mask an overreliance on dataset-specific surface cues\nrather than true language understanding. We introduce the Chameleon Benchmark\nOverfit Detector (C-BOD), a meta-evaluation framework that systematically\ndistorts benchmark prompts via a parametric transformation and detects\noverfitting of LLMs. By rephrasing inputs while preserving their semantic\ncontent and labels, C-BOD exposes whether a model's performance is driven by\nmemorized patterns. Evaluated on the MMLU benchmark using 26 leading LLMs, our\nmethod reveals an average performance degradation of 2.15% under modest\nperturbations, with 20 out of 26 models exhibiting statistically significant\ndifferences. Notably, models with higher baseline accuracy exhibit larger\nperformance differences under perturbation, and larger LLMs tend to be more\nsensitive to rephrasings indicating that both cases may overrely on fixed\nprompt patterns. In contrast, the Llama family and models with lower baseline\naccuracy show insignificant degradation, suggesting reduced dependency on\nsuperficial cues. Moreover, C-BOD's dataset- and model-agnostic design allows\neasy integration into training pipelines to promote more robust language\nunderstanding. Our findings challenge the community to look beyond leaderboard\nscores and prioritize resilience and generalization in LLM evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07445v1",
    "published_date": "2025-02-11 10:43:36 UTC",
    "updated_date": "2025-02-11 10:43:36 UTC"
  },
  {
    "arxiv_id": "2502.07443v1",
    "title": "Approximating Human Strategic Reasoning with LLM-Enhanced Recursive Reasoners Leveraging Multi-agent Hypergames",
    "authors": [
      "Vince Trencsenyi",
      "Agnieszka Mensfelt",
      "Kostas Stathis"
    ],
    "abstract": "LLM-driven multi-agent-based simulations have been gaining traction with\napplications in game-theoretic and social simulations. While most\nimplementations seek to exploit or evaluate LLM-agentic reasoning, they often\ndo so with a weak notion of agency and simplified architectures. We implement a\nrole-based multi-agent strategic interaction framework tailored to\nsophisticated recursive reasoners, providing the means for systematic in-depth\ndevelopment and evaluation of strategic reasoning. Our game environment is\ngoverned by the umpire responsible for facilitating games, from matchmaking\nthrough move validation to environment management. Players incorporate\nstate-of-the-art LLMs in their decision mechanism, relying on a formal\nhypergame-based model of hierarchical beliefs. We use one-shot, 2-player beauty\ncontests to evaluate the recursive reasoning capabilities of the latest LLMs,\nproviding a comparison to an established baseline model from economics and data\nfrom human experiments. Furthermore, we introduce the foundations of an\nalternative semantic measure of reasoning to the k-level theory. Our\nexperiments show that artificial reasoners can outperform the baseline model in\nterms of both approximating human behaviour and reaching the optimal solution.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07443v1",
    "published_date": "2025-02-11 10:37:20 UTC",
    "updated_date": "2025-02-11 10:37:20 UTC"
  },
  {
    "arxiv_id": "2502.07850v1",
    "title": "Mathematical reasoning and the computer",
    "authors": [
      "Kevin Buzzard"
    ],
    "abstract": "Computers have already changed the way that humans do mathematics: they\nenable us to compute efficiently. But will they soon be helping us to reason?\nAnd will they one day start reasoning themselves? We give an overview of recent\ndevelopments in neural networks, computer theorem provers and large language\nmodels.",
    "categories": [
      "cs.AI",
      "68T01"
    ],
    "primary_category": "cs.AI",
    "comment": "This article was written in 2023 and is thus now rather out of date.\n  Apologies for taking so long to upload to ArXiv",
    "pdf_url": "http://arxiv.org/pdf/2502.07850v1",
    "published_date": "2025-02-11 10:35:52 UTC",
    "updated_date": "2025-02-11 10:35:52 UTC"
  },
  {
    "arxiv_id": "2502.07441v1",
    "title": "SensPS: Sensing Personal Space Comfortable Distance between Human-Human Using Multimodal Sensors",
    "authors": [
      "Ko Watanabe",
      "Nico FÃ¶rster",
      "Shoya Ishimaru"
    ],
    "abstract": "Personal space, also known as peripersonal space, is crucial in human social\ninteraction, influencing comfort, communication, and social stress. Estimating\nand respecting personal space is essential for enhancing human-computer\ninteraction (HCI) and smart environments. Personal space preferences vary due\nto individual traits, cultural background, and contextual factors. Advanced\nmultimodal sensing technologies, including eye-tracking and wristband sensors,\noffer opportunities to develop adaptive systems that dynamically adjust to user\ncomfort levels. Integrating physiological and behavioral data enables a deeper\nunderstanding of spatial interactions. This study develops a sensor-based model\nto estimate comfortable personal space and identifies key features influencing\nspatial preferences. Our findings show that multimodal sensors, particularly\neye-tracking and physiological wristband data, can effectively predict personal\nspace preferences, with eye-tracking data playing a more significant role. An\nexperimental study involving controlled human interactions demonstrates that a\nTransformer-based model achieves the highest predictive accuracy (F1 score:\n0.87) for estimating personal space. Eye-tracking features, such as gaze point\nand pupil diameter, emerge as the most significant predictors, while\nphysiological signals from wristband sensors contribute marginally. These\nresults highlight the potential for AI-driven personalization of social space\nin adaptive environments, suggesting that multimodal sensing can be leveraged\nto develop intelligent systems that optimize spatial arrangements in\nworkplaces, educational institutions, and public settings. Future work should\nexplore larger datasets, real-world applications, and additional physiological\nmarkers to enhance model robustness.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07441v1",
    "published_date": "2025-02-11 10:31:43 UTC",
    "updated_date": "2025-02-11 10:31:43 UTC"
  },
  {
    "arxiv_id": "2502.07849v1",
    "title": "Understanding Classifier-Free Guidance: High-Dimensional Theory and Non-Linear Generalizations",
    "authors": [
      "Krunoslav Lehman Pavasovic",
      "Jakob Verbeek",
      "Giulio Biroli",
      "Marc Mezard"
    ],
    "abstract": "Recent studies have raised concerns about the effectiveness of\nClassifier-Free Guidance (CFG), indicating that in low-dimensional settings, it\ncan lead to overshooting the target distribution and reducing sample diversity.\nIn this work, we demonstrate that in infinite and sufficiently high-dimensional\ncontexts CFG effectively reproduces the target distribution, revealing a\nblessing-of-dimensionality result. Additionally, we explore finite-dimensional\neffects, precisely characterizing overshoot and variance reduction. Based on\nour analysis, we introduce non-linear generalizations of CFG. Through numerical\nsimulations on Gaussian mixtures and experiments on class-conditional and\ntext-to-image diffusion models, we validate our analysis and show that our\nnon-linear CFG offers improved flexibility and generation quality without\nadditional computation cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07849v1",
    "published_date": "2025-02-11 10:29:29 UTC",
    "updated_date": "2025-02-11 10:29:29 UTC"
  },
  {
    "arxiv_id": "2502.07424v2",
    "title": "RomanLens: The Role Of Latent Romanization In Multilinguality In LLMs",
    "authors": [
      "Alan Saji",
      "Jaavid Aktar Husain",
      "Thanmay Jayakumar",
      "Raj Dabre",
      "Anoop Kunchukuttan",
      "Ratish Puduppully"
    ],
    "abstract": "Large Language Models (LLMs) exhibit remarkable multilingual generalization\ndespite being predominantly trained on English-centric corpora. A fundamental\nquestion arises: how do LLMs achieve such robust multilingual capabilities? We\ntake the case of non-Roman script languages, we investigate the role of\nRomanization - the representation of non-Roman scripts using Roman characters -\nas a bridge in multilingual processing. Using mechanistic interpretability\ntechniques, we analyze next-token generation and find that intermediate layers\nfrequently represent target words in Romanized form before transitioning to\nnative script, a phenomenon we term Latent Romanization. Further, through\nactivation patching experiments, we demonstrate that LLMs encode semantic\nconcepts similarly across native and Romanized scripts, suggesting a shared\nunderlying representation. Additionally, for translation into non-Roman script\nlanguages, our findings reveal that when the target language is in Romanized\nform, its representations emerge earlier in the model's layers compared to\nnative script. These insights contribute to a deeper understanding of\nmultilingual representation in LLMs and highlight the implicit role of\nRomanization in facilitating language transfer.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07424v2",
    "published_date": "2025-02-11 10:10:26 UTC",
    "updated_date": "2025-02-16 16:10:22 UTC"
  },
  {
    "arxiv_id": "2502.07423v2",
    "title": "Towards a Formal Theory of the Need for Competence via Computational Intrinsic Motivation",
    "authors": [
      "Erik M. Lintunen",
      "Nadia M. Ady",
      "Sebastian Deterding",
      "Christian Guckelsberger"
    ],
    "abstract": "Computational modelling offers a powerful tool for formalising psychological\ntheories, making them more transparent, testable, and applicable in digital\ncontexts. Yet, the question often remains: how should one computationally model\na theory? We provide a demonstration of how formalisms taken from artificial\nintelligence can offer a fertile starting point. Specifically, we focus on the\n\"need for competence\", postulated as a key basic psychological need within\nSelf-Determination Theory (SDT) -- arguably the most influential framework for\nintrinsic motivation (IM) in psychology. Recent research has identified\nmultiple distinct facets of competence in key SDT texts: effectance, skill use,\ntask performance, and capacity growth. We draw on the computational IM\nliterature in reinforcement learning to suggest that different existing\nformalisms may be appropriate for modelling these different facets. Using these\nformalisms, we reveal underlying preconditions that SDT fails to make explicit,\ndemonstrating how computational models can improve our understanding of IM.\nMore generally, our work can support a cycle of theory development by inspiring\nnew computational models, which can then be tested empirically to refine the\ntheory. Thus, we provide a foundation for advancing competence-related theory\nin SDT and motivational psychology more broadly.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages plus references, full paper at CogSci 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07423v2",
    "published_date": "2025-02-11 10:03:40 UTC",
    "updated_date": "2025-05-13 07:21:16 UTC"
  },
  {
    "arxiv_id": "2502.07408v1",
    "title": "No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips",
    "authors": [
      "Ido Galil",
      "Moshe Kimhi",
      "Ran El-Yaniv"
    ],
    "abstract": "Deep Neural Networks (DNNs) can be catastrophically disrupted by flipping\nonly a handful of sign bits in their parameters. We introduce Deep Neural\nLesion (DNL), a data-free, lightweight method that locates these critical\nparameters and triggers massive accuracy drops. We validate its efficacy on a\nwide variety of computer vision models and datasets. The method requires no\ntraining data or optimization and can be carried out via common exploits\nsoftware, firmware or hardware based attack vectors. An enhanced variant that\nuses a single forward and backward pass further amplifies the damage beyond\nDNL's zero-pass approach. Flipping just two sign bits in ResNet50 on ImageNet\nreduces accuracy by 99.8\\%. We also show that selectively protecting a small\nfraction of vulnerable sign bits provides a practical defense against such\nattacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07408v1",
    "published_date": "2025-02-11 09:40:45 UTC",
    "updated_date": "2025-02-11 09:40:45 UTC"
  },
  {
    "arxiv_id": "2502.07404v1",
    "title": "Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy",
    "authors": [
      "Sahana Yadnakudige Subramanya",
      "Ko Watanabe",
      "Andreas Dengel",
      "Shoya Ishimaru"
    ],
    "abstract": "Human-in-the-loop (HITL) frameworks are increasingly recognized for their\npotential to improve annotation accuracy in emotion estimation systems by\ncombining machine predictions with human expertise. This study focuses on\nintegrating a high-performing image-based emotion model into a HITL annotation\nframework to evaluate the collaborative potential of human-machine interaction\nand identify the psychological and practical factors critical to successful\ncollaboration. Specifically, we investigate how varying model reliability and\ncognitive framing influence human trust, cognitive load, and annotation\nbehavior in HITL systems. We demonstrate that model reliability and\npsychological framing significantly impact annotators' trust, engagement, and\nconsistency, offering insights into optimizing HITL frameworks. Through three\nexperimental scenarios with 29 participants--baseline model reliability (S1),\nfabricated errors (S2), and cognitive bias introduced by negative framing\n(S3)--we analyzed behavioral and qualitative data. Reliable predictions in S1\nyielded high trust and annotation consistency, while unreliable outputs in S2\nled to increased critical evaluations but also heightened frustration and\nresponse variability. Negative framing in S3 revealed how cognitive bias\ninfluenced participants to perceive the model as more relatable and accurate,\ndespite misinformation regarding its reliability. These findings highlight the\nimportance of both reliable machine outputs and psychological factors in\nshaping effective human-machine collaboration. By leveraging the strengths of\nboth human oversight and automated systems, this study establishes a scalable\nHITL framework for emotion annotation and lays the foundation for broader\napplications in adaptive learning and human-computer interaction.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07404v1",
    "published_date": "2025-02-11 09:37:10 UTC",
    "updated_date": "2025-02-11 09:37:10 UTC"
  },
  {
    "arxiv_id": "2502.07401v1",
    "title": "Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning",
    "authors": [
      "Johnny Chan",
      "Yuming Li"
    ],
    "abstract": "This research explores the opportunities of Generative AI (GenAI) in the\nrealm of higher education through the design and development of a multimodal\nchatbot for an undergraduate course. Leveraging the ChatGPT API for nuanced\ntext-based interactions and Google Bard for advanced image analysis and\ndiagram-to-code conversions, we showcase the potential of GenAI in addressing a\nbroad spectrum of educational queries. Additionally, the chatbot presents a\nfile-based analyser designed for educators, offering deep insights into student\nfeedback via sentiment and emotion analysis, and summarising course evaluations\nwith key metrics. These combinations highlight the crucial role of multimodal\nconversational AI in enhancing teaching and learning processes, promising\nsignificant advancements in educational adaptability, engagement, and feedback\nanalysis. By demonstrating a practical web application, this research\nunderlines the imperative for integrating GenAI technologies to foster more\ndynamic and responsive educational environments, ultimately contributing to\nimproved educational outcomes and pedagogical strategies.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "9 pages, 4 figures, accepted and presented in the 2025 6th\n  International Conference on Advances in Education and Information Technology\n  (AEIT)",
    "pdf_url": "http://arxiv.org/pdf/2502.07401v1",
    "published_date": "2025-02-11 09:29:29 UTC",
    "updated_date": "2025-02-11 09:29:29 UTC"
  },
  {
    "arxiv_id": "2502.07400v1",
    "title": "Explainable Multimodal Machine Learning for Revealing Structure-Property Relationships in Carbon Nanotube Fibers",
    "authors": [
      "Daisuke Kimura",
      "Naoko Tajima",
      "Toshiya Okazaki",
      "Shun Muroga"
    ],
    "abstract": "In this study, we propose Explainable Multimodal Machine Learning (EMML),\nwhich integrates the analysis of diverse data types (multimodal data) using\nfactor analysis for feature extraction with Explainable AI (XAI), for carbon\nnanotube (CNT) fibers prepared from aqueous dispersions. This method is a\npowerful approach to elucidate the mechanisms governing material properties,\nwhere multi-stage fabrication conditions and multiscale structures have complex\ninfluences. Thus, in our case, this approach helps us understand how different\nprocessing steps and structures at various scales impact the final properties\nof CNT fibers. The analysis targeted structures ranging from the nanoscale to\nthe macroscale, including aggregation size distributions of CNT dispersions and\nthe effective length of CNTs. Furthermore, because some types of data were\ndifficult to interpret using standard methods, challenging-to-interpret\ndistribution data were analyzed using Negative Matrix Factorization (NMF) for\nextracting key features that determine the outcome. Contribution analysis with\nSHapley Additive exPlanations (SHAP) demonstrated that small, uniformly\ndistributed aggregates are crucial for improving fracture strength, while CNTs\nwith long effective lengths are significant factors for enhancing electrical\nconductivity. The analysis also identified thresholds and trends for these key\nfactors to assist in defining the conditions needed to optimize CNT fiber\nproperties. EMML is not limited to CNT fibers but can be applied to the design\nof other materials derived from nanomaterials, making it a useful tool for\ndeveloping a wide range of advanced materials. This approach provides a\nfoundation for advancing data-driven materials research.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.soft",
      "cs.AI",
      "cs.LG",
      "physics.data-an"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "33 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07400v1",
    "published_date": "2025-02-11 09:29:23 UTC",
    "updated_date": "2025-02-11 09:29:23 UTC"
  },
  {
    "arxiv_id": "2502.07399v1",
    "title": "On Iterative Evaluation and Enhancement of Code Quality Using GPT-4o",
    "authors": [
      "Rundong Liu",
      "Andre Frade",
      "Amal Vaidya",
      "Maxime Labonne",
      "Marcus Kaiser",
      "Bismayan Chakrabarti",
      "Jonathan Budd",
      "Sean Moran"
    ],
    "abstract": "This paper introduces CodeQUEST, a novel framework leveraging Large Language\nModels (LLMs) to iteratively evaluate and enhance code quality across multiple\ndimensions, including readability, maintainability, efficiency, and security.\nThe framework is divided into two main components: an Evaluator that assesses\ncode quality across ten dimensions, providing both quantitative scores and\nqualitative summaries, and an Optimizer that iteratively improves the code\nbased on the Evaluator's feedback. Our study demonstrates that CodeQUEST can\neffectively and robustly evaluate code quality, with its assessments aligning\nclosely with established code quality metrics. Through a series of experiments\nusing a curated dataset of Python and JavaScript examples, CodeQUEST\ndemonstrated significant improvements in code quality, achieving a mean\nrelative percentage improvement of 52.6%. The framework's evaluations were\nvalidated against a set of proxy metrics comprising of Pylint Score, Radon\nMaintainability Index, and Bandit output logs, showing a meaningful\ncorrelation. This highlights the potential of LLMs in automating code quality\nevaluation and improvement processes, presenting a significant advancement\ntoward enhancing software development practices. The code implementation of the\nframework is available at: https://github.com/jpmorganchase/CodeQuest.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07399v1",
    "published_date": "2025-02-11 09:27:00 UTC",
    "updated_date": "2025-02-11 09:27:00 UTC"
  },
  {
    "arxiv_id": "2502.07845v1",
    "title": "Spread them Apart: Towards Robust Watermarking of Generated Content",
    "authors": [
      "Mikhail Pautov",
      "Danil Ivanov",
      "Andrey V. Galichin",
      "Oleg Rogov",
      "Ivan Oseledets"
    ],
    "abstract": "Generative models that can produce realistic images have improved\nsignificantly in recent years. The quality of the generated content has\nincreased drastically, so sometimes it is very difficult to distinguish between\nthe real images and the generated ones. Such an improvement comes at a price of\nethical concerns about the usage of the generative models: the users of\ngenerative models can improperly claim ownership of the generated content\nprotected by a license. In this paper, we propose an approach to embed\nwatermarks into the generated content to allow future detection of the\ngenerated content and identification of the user who generated it. The\nwatermark is embedded during the inference of the model, so the proposed\napproach does not require the retraining of the latter. We prove that\nwatermarks embedded are guaranteed to be robust against additive perturbations\nof a bounded magnitude. We apply our method to watermark diffusion models and\nshow that it matches state-of-the-art watermarking schemes in terms of\nrobustness to different types of synthetic watermark removal attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07845v1",
    "published_date": "2025-02-11 09:23:38 UTC",
    "updated_date": "2025-02-11 09:23:38 UTC"
  },
  {
    "arxiv_id": "2502.07374v2",
    "title": "LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!",
    "authors": [
      "Dacheng Li",
      "Shiyi Cao",
      "Tyler Griggs",
      "Shu Liu",
      "Xiangxi Mo",
      "Eric Tang",
      "Sumanth Hegde",
      "Kourosh Hakhamaneshi",
      "Shishir G. Patil",
      "Matei Zaharia",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "abstract": "Large reasoning models (LRMs) tackle complex reasoning problems by following\nlong chain-of-thoughts (Long CoT) that incorporate reflection, backtracking,\nand self-validation. However, the training techniques and data requirements to\nelicit Long CoT remain poorly understood. In this work, we find that a Large\nLanguage model (LLM) can effectively learn Long CoT reasoning through\ndata-efficient supervised fine-tuning (SFT) and parameter-efficient low-rank\nadaptation (LoRA). With just 17k long CoT training samples, the\nQwen2.5-32B-Instruct model achieves significant improvements on a wide range of\nmath and coding benchmarks, including 56.7% (+40.0%) on AIME 2024 and 57.0%\n(+8.1%) on LiveCodeBench, competitive to the proprietary o1-preview model's\nscore of 44.6% and 59.1%. More importantly, we find that the structure of Long\nCoT is critical to the learning process, whereas the content of individual\nreasoning steps has minimal impact. Perturbations affecting content, such as\ntraining on incorrect samples or removing reasoning keywords, have little\nimpact on performance. In contrast, structural modifications that disrupt\nlogical consistency in the Long CoT, such as shuffling or deleting reasoning\nsteps, significantly degrade accuracy. For example, a model trained on Long CoT\nsamples with incorrect answers still achieves only 3.2% lower accuracy compared\nto training with fully correct samples. These insights deepen our understanding\nof how to elicit reasoning capabilities in LLMs and highlight key\nconsiderations for efficiently training the next generation of reasoning\nmodels. This is the academic paper of our previous released Sky-T1-32B-Preview\nmodel. Codes are available at https://github.com/NovaSky-AI/SkyThought.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07374v2",
    "published_date": "2025-02-11 08:48:48 UTC",
    "updated_date": "2025-02-18 05:20:33 UTC"
  },
  {
    "arxiv_id": "2502.07352v1",
    "title": "Bridging the Evaluation Gap: Leveraging Large Language Models for Topic Model Evaluation",
    "authors": [
      "Zhiyin Tan",
      "Jennifer D'Souza"
    ],
    "abstract": "This study presents a framework for automated evaluation of dynamically\nevolving topic taxonomies in scientific literature using Large Language Models\n(LLMs). In digital library systems, topic modeling plays a crucial role in\nefficiently organizing and retrieving scholarly content, guiding researchers\nthrough complex knowledge landscapes. As research domains proliferate and\nshift, traditional human centric and static evaluation methods struggle to\nmaintain relevance. The proposed approach harnesses LLMs to measure key quality\ndimensions, such as coherence, repetitiveness, diversity, and topic-document\nalignment, without heavy reliance on expert annotators or narrow statistical\nmetrics. Tailored prompts guide LLM assessments, ensuring consistent and\ninterpretable evaluations across various datasets and modeling techniques.\nExperiments on benchmark corpora demonstrate the method's robustness,\nscalability, and adaptability, underscoring its value as a more holistic and\ndynamic alternative to conventional evaluation strategies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by IRCDL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07352v1",
    "published_date": "2025-02-11 08:23:56 UTC",
    "updated_date": "2025-02-11 08:23:56 UTC"
  },
  {
    "arxiv_id": "2502.07351v3",
    "title": "Multi-Knowledge-oriented Nighttime Haze Imaging Enhancer for Vision-driven Intelligent Transportation Systems",
    "authors": [
      "Ai Chen",
      "Yuxu Lu",
      "Dong Yang",
      "Junlin Zhou",
      "Yan Fu",
      "Duanbing Chen"
    ],
    "abstract": "Salient object detection (SOD) plays a critical role in intelligent\ntransportation systems (ITS), facilitating the detection and segmentation of\nkey visual elements in an image. However, adverse imaging conditions such as\nhaze during the day, low light, and haze at night severely degrade image\nquality and hinder reliable object detection in real-world scenarios. To\naddress these challenges, we propose a multi-knowledge-oriented nighttime haze\nimaging enhancer (MKoIE), which integrates three tasks: daytime dehazing,\nlow-light enhancement, and nighttime dehazing. The MKoIE incorporates two key\ninnovative components: First, the network employs a task-oriented node learning\nmechanism to handle three specific degradation types: day-time haze, low light,\nand night-time haze conditions, with an embedded self-attention module\nenhancing its performance in nighttime imaging. In addition, multi-receptive\nfield enhancement module that efficiently extracts multi-scale features through\nthree parallel depthwise separable convolution branches with different dilation\nrates, capturing comprehensive spatial information with minimal computational\noverhead to meet the requirements of real-time ITS deployment. To ensure\noptimal image reconstruction quality and visual characteristics, we suggest a\nhybrid loss function. Extensive experiments on different types of\nweather/imaging conditions illustrate that MKoIE surpasses existing methods,\nenhancing the reliability, accuracy, and operational efficiency of ITS. The\ncode is available at https://github.com/Ai-Chen-Lab/MKoIE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07351v3",
    "published_date": "2025-02-11 08:22:21 UTC",
    "updated_date": "2025-03-14 03:54:26 UTC"
  },
  {
    "arxiv_id": "2502.07350v1",
    "title": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems",
    "authors": [
      "Jusheng Zhang",
      "Zimeng Huang",
      "Yijia Fan",
      "Ningyuan Liu",
      "Mingyan Li",
      "Zhuojie Yang",
      "Jiawei Yao",
      "Jian Wang",
      "Keze Wang"
    ],
    "abstract": "As scaling large language models faces prohibitive costs, multi-agent systems\nemerge as a promising alternative, though challenged by static knowledge\nassumptions and coordination inefficiencies. We introduces Knowledge-Aware\nBayesian Bandits (KABB), a novel framework that enhances multi-agent system\ncoordination through semantic understanding and dynamic adaptation. The\nframework features three key innovations: a three-dimensional knowledge\ndistance model for deep semantic understanding, a dual-adaptation mechanism for\ncontinuous expert optimization, and a knowledge-aware Thompson Sampling\nstrategy for efficient expert selection. Extensive evaluation demonstrates KABB\nachieves an optimal cost-performance balance, maintaining high performance\nwhile keeping computational demands relatively low in multi-agent coordination.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07350v1",
    "published_date": "2025-02-11 08:22:12 UTC",
    "updated_date": "2025-02-11 08:22:12 UTC"
  },
  {
    "arxiv_id": "2502.07347v5",
    "title": "Coarse Set Theory for AI Ethics and Decision-Making: A Mathematical Framework for Granular Evaluations",
    "authors": [
      "Takashi Izumo"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly embedded in\nethically sensitive domains such as education, healthcare, and transportation,\nthe need to balance accuracy and interpretability in decision-making has become\na central concern. Coarse Ethics (CE) is a theoretical framework that justifies\ncoarse-grained evaluations, such as letter grades or warning labels, as\nethically appropriate under cognitive and contextual constraints. However, CE\nhas lacked mathematical formalization. This paper introduces Coarse Set Theory\n(CST), a novel mathematical framework that models coarse-grained\ndecision-making using totally ordered structures and coarse partitions. CST\ndefines hierarchical relations among sets and uses information-theoretic tools,\nsuch as Kullback-Leibler Divergence, to quantify the trade-off between\nsimplification and information loss. We demonstrate CST through applications in\neducational grading and explainable AI (XAI), showing how it enables more\ntransparent and context-sensitive evaluations. By grounding coarse evaluations\nin set theory and probabilistic reasoning, CST contributes to the ethical\ndesign of interpretable AI systems. This work bridges formal methods and\nhuman-centered ethics, offering a principled approach to balancing\ncomprehensibility, fairness, and informational integrity in AI-driven\ndecisions.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT",
      "math.LO",
      "math.PR"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07347v5",
    "published_date": "2025-02-11 08:18:37 UTC",
    "updated_date": "2025-03-22 00:30:11 UTC"
  },
  {
    "arxiv_id": "2502.07344v1",
    "title": "Integrating Physics and Data-Driven Approaches: An Explainable and Uncertainty-Aware Hybrid Model for Wind Turbine Power Prediction",
    "authors": [
      "Alfonso GijÃ³n",
      "Simone Eiraudo",
      "Antonio Manjavacas",
      "Daniele Salvatore Schiera",
      "Miguel Molina-Solana",
      "Juan GÃ³mez-Romero"
    ],
    "abstract": "The rapid growth of the wind energy sector underscores the urgent need to\noptimize turbine operations and ensure effective maintenance through early\nfault detection systems. While traditional empirical and physics-based models\noffer approximate predictions of power generation based on wind speed, they\noften fail to capture the complex, non-linear relationships between other input\nvariables and the resulting power output. Data-driven machine learning methods\npresent a promising avenue for improving wind turbine modeling by leveraging\nlarge datasets, enhancing prediction accuracy but often at the cost of\ninterpretability. In this study, we propose a hybrid semi-parametric model that\ncombines the strengths of both approaches, applied to a dataset from a wind\nfarm with four turbines. The model integrates a physics-inspired submodel,\nproviding a reasonable approximation of power generation, with a non-parametric\nsubmodel that predicts the residuals. This non-parametric submodel is trained\non a broader range of variables to account for phenomena not captured by the\nphysics-based component. The hybrid model achieves a 37% improvement in\nprediction accuracy over the physics-based model. To enhance interpretability,\nSHAP values are used to analyze the influence of input features on the residual\nsubmodel's output. Additionally, prediction uncertainties are quantified using\na conformalized quantile regression method. The combination of these\ntechniques, alongside the physics grounding of the parametric submodel,\nprovides a flexible, accurate, and reliable framework. Ultimately, this study\nopens the door for evaluating the impact of unmodeled variables on wind turbine\npower generation, offering a basis for potential optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07344v1",
    "published_date": "2025-02-11 08:16:48 UTC",
    "updated_date": "2025-02-11 08:16:48 UTC"
  },
  {
    "arxiv_id": "2502.07340v2",
    "title": "Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering",
    "authors": [
      "Shuzheng Si",
      "Haozhe Zhao",
      "Gang Chen",
      "Cheng Gao",
      "Yuzhuo Bai",
      "Zhitong Wang",
      "Kaikai An",
      "Kangyang Luo",
      "Chen Qian",
      "Fanchao Qi",
      "Baobao Chang",
      "Maosong Sun"
    ],
    "abstract": "Training LLMs on data containing unfamiliar knowledge during the instruction\ntuning stage can encourage hallucinations. To address this challenge, we\nintroduce NOVA, a novel framework designed to identify high-quality data that\naligns well with the LLM's learned knowledge to reduce hallucinations. NOVA\nincludes Internal Consistency Probing (ICP) and Semantic Equivalence\nIdentification (SEI) to measure how familiar the LLM is with instruction data.\nSpecifically, ICP evaluates the LLM's understanding of the given instruction by\ncalculating the tailored consistency among multiple self-generated responses.\nSEI further assesses the familiarity of the LLM with the target response by\ncomparing it to the generated responses, using the proposed semantic clustering\nand well-designed voting strategy. Finally, to ensure the quality of selected\nsamples, we introduce an expert-aligned reward model, considering\ncharacteristics beyond just familiarity. By considering data quality and\navoiding unfamiliar data, we can utilize the selected data to effectively align\nLLMs to follow instructions and hallucinate less.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07340v2",
    "published_date": "2025-02-11 08:05:56 UTC",
    "updated_date": "2025-02-17 03:00:38 UTC"
  },
  {
    "arxiv_id": "2502.07328v3",
    "title": "Music for All: Representational Bias and Cross-Cultural Adaptability of Music Generation Models",
    "authors": [
      "Atharva Mehta",
      "Shivam Chauhan",
      "Amirbek Djanibekov",
      "Atharva Kulkarni",
      "Gus Xia",
      "Monojit Choudhury"
    ],
    "abstract": "The advent of Music-Language Models has greatly enhanced the automatic music\ngeneration capability of AI systems, but they are also limited in their\ncoverage of the musical genres and cultures of the world. We present a study of\nthe datasets and research papers for music generation and quantify the bias and\nunder-representation of genres. We find that only 5.7% of the total hours of\nexisting music datasets come from non-Western genres, which naturally leads to\ndisparate performance of the models across genres. We then investigate the\nefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating\nthis bias. Our experiments with two popular models -- MusicGen and Mustango,\nfor two underrepresented non-Western music traditions -- Hindustani Classical\nand Turkish Makam music, highlight the promises as well as the non-triviality\nof cross-genre adaptation of music through small datasets, implying the need\nfor more equitable baseline music-language models that are designed for\ncross-cultural transfer learning.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.SD",
    "comment": "17 pages, 5 figures, accepted to NAACL'25",
    "pdf_url": "http://arxiv.org/pdf/2502.07328v3",
    "published_date": "2025-02-11 07:46:29 UTC",
    "updated_date": "2025-05-06 09:48:44 UTC"
  },
  {
    "arxiv_id": "2502.07316v4",
    "title": "CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction",
    "authors": [
      "Junlong Li",
      "Daya Guo",
      "Dejian Yang",
      "Runxin Xu",
      "Yu Wu",
      "Junxian He"
    ],
    "abstract": "Reasoning is a fundamental capability of Large Language Models. While prior\nresearch predominantly focuses on enhancing narrow skills like math or code\ngeneration, improving performance on many other reasoning tasks remains\nchallenging due to sparse and fragmented training data. To address this issue,\nwe propose CodeI/O, a novel approach that systematically condenses diverse\nreasoning patterns inherently embedded in contextually-grounded codes, through\ntransforming the original code into a code input-output prediction format. By\ntraining models to predict inputs/outputs given code and test cases entirely in\nnatural language as Chain-of-Thought (CoT) rationales, we expose them to\nuniversal reasoning primitives -- like logic flow planning, state-space\nsearching, decision tree traversal, and modular decomposition -- while\ndecoupling structured reasoning from code-specific syntax and preserving\nprocedural rigor. Experimental results demonstrate CodeI/O leads to consistent\nimprovements across symbolic, scientific, logic, math & numerical, and\ncommonsense reasoning tasks. By matching the existing ground-truth outputs or\nre-executing the code with predicted inputs, we can verify each prediction and\nfurther enhance the CoTs through multi-turn revision, resulting in CodeI/O++\nand achieving higher performance. Our data and models are available at\nhttps://github.com/hkust-nlp/CodeIO.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07316v4",
    "published_date": "2025-02-11 07:26:50 UTC",
    "updated_date": "2025-05-21 13:38:27 UTC"
  },
  {
    "arxiv_id": "2502.07312v1",
    "title": "OpenGrok: Enhancing SNS Data Processing with Distilled Knowledge and Mask-like Mechanisms",
    "authors": [
      "Lumen AI",
      "Zaozhuang No. 28 Middle School",
      "Shihao Ji",
      "Zihui Song",
      "Fucheng Zhong",
      "Jisen Jia",
      "Zhaobo Wu",
      "Zheyi Cao",
      "Tianhao Xu"
    ],
    "abstract": "This report details Lumen Labs' novel approach to processing Social\nNetworking Service (SNS) data. We leverage knowledge distillation, specifically\na simple distillation method inspired by DeepSeek-R1's CoT acquisition,\ncombined with prompt hacking, to extract valuable training data from the Grok\nmodel. This data is then used to fine-tune a Phi-3-mini model, augmented with a\nmask-like mechanism specifically designed for handling the nuances of SNS data.\nOur method demonstrates state-of-the-art (SOTA) performance on several SNS data\nprocessing tasks, outperforming existing models like Grok, Phi-3, and GPT-4. We\nprovide a comprehensive analysis of our approach, including mathematical\nformulations, engineering details, ablation studies, and comparative\nevaluations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.07312v1",
    "published_date": "2025-02-11 07:20:38 UTC",
    "updated_date": "2025-02-11 07:20:38 UTC"
  },
  {
    "arxiv_id": "2502.07306v1",
    "title": "TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation",
    "authors": [
      "Navid Rajabi",
      "Jana Kosecka"
    ],
    "abstract": "In this work, we propose a modular approach for the Vision-Language\nNavigation (VLN) task by decomposing the problem into four sub-modules that use\nstate-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs)\nin a zero-shot setting. Given navigation instruction in natural language, we\nfirst prompt LLM to extract the landmarks and the order in which they are\nvisited. Assuming the known model of the environment, we retrieve the top-k\nlocations of the last landmark and generate $k$ path hypotheses from the\nstarting location to the last landmark using the shortest path algorithm on the\ntopological map of the environment. Each path hypothesis is represented by a\nsequence of panoramas. We then use dynamic programming to compute the alignment\nscore between the sequence of panoramas and the sequence of landmark names,\nwhich match scores obtained from VLM. Finally, we compute the nDTW metric\nbetween the hypothesis that yields the highest alignment score to evaluate the\npath fidelity. We demonstrate superior performance compared to other approaches\nthat use joint semantic maps like VLMaps \\cite{vlmaps} on the complex\nR2R-Habitat \\cite{r2r} instruction dataset and quantify in detail the effect of\nvisual grounding on navigation performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07306v1",
    "published_date": "2025-02-11 07:09:37 UTC",
    "updated_date": "2025-02-11 07:09:37 UTC"
  },
  {
    "arxiv_id": "2502.07299v1",
    "title": "Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification",
    "authors": [
      "Zicheng Liu",
      "Siyuan Li",
      "Zhiyuan Chen",
      "Lei Xin",
      "Fang Wu",
      "Chang Yu",
      "Qirong Yang",
      "Yucheng Guo",
      "Yujie Yang",
      "Stan Z. Li"
    ],
    "abstract": "The interactions between DNA, RNA, and proteins are fundamental to biological\nprocesses, as illustrated by the central dogma of molecular biology. While\nmodern biological pre-trained models have achieved great success in analyzing\nthese macromolecules individually, their interconnected nature remains\nunder-explored. In this paper, we follow the guidance of the central dogma to\nredesign both the data and model pipeline and offer a comprehensive framework,\nLife-Code, that spans different biological functions. As for data flow, we\npropose a unified pipeline to integrate multi-omics data by\nreverse-transcribing RNA and reverse-translating amino acids into\nnucleotide-based sequences. As for the model, we design a codon tokenizer and a\nhybrid long-sequence architecture to encode the interactions of both coding and\nnon-coding regions with masked modeling pre-training. To model the translation\nand folding process with coding sequences, Life-Code learns protein structures\nof the corresponding amino acids by knowledge distillation from off-the-shelf\nprotein language models. Such designs enable Life-Code to capture complex\ninteractions within genetic sequences, providing a more comprehensive\nunderstanding of multi-omics with the central dogma. Extensive Experiments show\nthat Life-Code achieves state-of-the-art performance on various tasks across\nthree omics, highlighting its potential for advancing multi-omics analysis and\ninterpretation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages main text with 6 pages Appendix",
    "pdf_url": "http://arxiv.org/pdf/2502.07299v1",
    "published_date": "2025-02-11 06:53:59 UTC",
    "updated_date": "2025-02-11 06:53:59 UTC"
  },
  {
    "arxiv_id": "2502.07288v1",
    "title": "KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level",
    "authors": [
      "Ruining Deng",
      "Tianyuan Yao",
      "Yucheng Tang",
      "Junlin Guo",
      "Siqi Lu",
      "Juming Xiong",
      "Lining Yu",
      "Quan Huu Cap",
      "Pengzhou Cai",
      "Libin Lan",
      "Ze Zhao",
      "Adrian Galdran",
      "Amit Kumar",
      "Gunjan Deotale",
      "Dev Kumar Das",
      "Inyoung Paik",
      "Joonho Lee",
      "Geongyu Lee",
      "Yujia Chen",
      "Wangkai Li",
      "Zhaoyang Li",
      "Xuege Hou",
      "Zeyuan Wu",
      "Shengjin Wang",
      "Maximilian Fischer",
      "Lars Kramer",
      "Anghong Du",
      "Le Zhang",
      "Maria Sanchez Sanchez",
      "Helena Sanchez Ulloa",
      "David Ribalta Heredia",
      "Carlos Perez de Arenaza Garcia",
      "Shuoyu Xu",
      "Bingdou He",
      "Xinping Cheng",
      "Tao Wang",
      "Noemie Moreau",
      "Katarzyna Bozek",
      "Shubham Innani",
      "Ujjwal Baid",
      "Kaura Solomon Kefas",
      "Bennett A. Landman",
      "Yu Wang",
      "Shilin Zhao",
      "Mengmeng Yin",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "abstract": "Chronic kidney disease (CKD) is a major global health issue, affecting over\n10% of the population and causing significant mortality. While kidney biopsy\nremains the gold standard for CKD diagnosis and treatment, the lack of\ncomprehensive benchmarks for kidney pathology segmentation hinders progress in\nthe field. To address this, we organized the Kidney Pathology Image\nSegmentation (KPIs) Challenge, introducing a dataset that incorporates\npreclinical rodent models of CKD with over 10,000 annotated glomeruli from 60+\nPeriodic Acid Schiff (PAS)-stained whole slide images. The challenge includes\ntwo tasks, patch-level segmentation and whole slide image segmentation and\ndetection, evaluated using the Dice Similarity Coefficient (DSC) and F1-score.\nBy encouraging innovative segmentation methods that adapt to diverse CKD models\nand tissue conditions, the KPIs Challenge aims to advance kidney pathology\nanalysis, establish new benchmarks, and enable precise, large-scale\nquantification for disease research and diagnosis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07288v1",
    "published_date": "2025-02-11 06:20:28 UTC",
    "updated_date": "2025-02-11 06:20:28 UTC"
  },
  {
    "arxiv_id": "2502.07286v1",
    "title": "Small Language Model Makes an Effective Long Text Extractor",
    "authors": [
      "Yelin Chen",
      "Fanjin Zhang",
      "Jie Tang"
    ],
    "abstract": "Named Entity Recognition (NER) is a fundamental problem in natural language\nprocessing (NLP). However, the task of extracting longer entity spans (e.g.,\nawards) from extended texts (e.g., homepages) is barely explored. Current NER\nmethods predominantly fall into two categories: span-based methods and\ngeneration-based methods. Span-based methods require the enumeration of all\npossible token-pair spans, followed by classification on each span, resulting\nin substantial redundant computations and excessive GPU memory usage. In\ncontrast, generation-based methods involve prompting or fine-tuning large\nlanguage models (LLMs) to adapt to downstream NER tasks. However, these methods\nstruggle with the accurate generation of longer spans and often incur\nsignificant time costs for effective fine-tuning. To address these challenges,\nthis paper introduces a lightweight span-based NER method called SeNER, which\nincorporates a bidirectional arrow attention mechanism coupled with\nLogN-Scaling on the [CLS] token to embed long texts effectively, and comprises\na novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to\nreduce redundant candidate token-pair spans significantly and model\ninteractions between token-pair spans simultaneously. Extensive experiments\ndemonstrate that our method achieves state-of-the-art extraction accuracy on\nthree long NER datasets and is capable of extracting entities from long texts\nin a GPU-memory-friendly manner. Code:\nhttps://github.com/THUDM/scholar-profiling/tree/main/sener",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI'25, 9 pages, 1 appendix pages",
    "pdf_url": "http://arxiv.org/pdf/2502.07286v1",
    "published_date": "2025-02-11 06:06:25 UTC",
    "updated_date": "2025-02-11 06:06:25 UTC"
  },
  {
    "arxiv_id": "2502.07280v1",
    "title": "MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management",
    "authors": [
      "Fengchen Gu",
      "Angelos Stefanidis",
      "Ãngel GarcÃ­a-FernÃ¡ndez",
      "Jionglong Su",
      "Huakang Li"
    ],
    "abstract": "Deep reinforcement learning (DRL) has been applied in financial portfolio\nmanagement to improve returns in changing market conditions. However, unlike\nmost fields where DRL is widely used, the stock market is more volatile and\ndynamic as it is affected by several factors such as global events and investor\nsentiment. Therefore, it remains a challenge to construct a DRL-based portfolio\nmanagement framework with strong return capability, stable training, and\ngeneralization ability. This study introduces a new framework utilizing the\nMemory Instance Gated Transformer (MIGT) for effective portfolio management. By\nincorporating a novel Gated Instance Attention module, which combines a\ntransformer variant, instance normalization, and a Lite Gate Unit, our approach\naims to maximize investment returns while ensuring the learning process's\nstability and reducing outlier impacts. Tested on the Dow Jones Industrial\nAverage 30, our framework's performance is evaluated against fifteen other\nstrategies using key financial metrics like the cumulative return and\nrisk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight\nMIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns\nand a minimum 2.36% increase in risk-return ratios over competing strategies,\nmarking a significant advancement in DRL for portfolio management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07280v1",
    "published_date": "2025-02-11 05:54:42 UTC",
    "updated_date": "2025-02-11 05:54:42 UTC"
  },
  {
    "arxiv_id": "2502.07279v2",
    "title": "Exploratory Diffusion Model for Unsupervised Reinforcement Learning",
    "authors": [
      "Chengyang Ying",
      "Huayu Chen",
      "Xinning Zhou",
      "Zhongkai Hao",
      "Hang Su",
      "Jun Zhu"
    ],
    "abstract": "Unsupervised reinforcement learning (URL) aims to pre-train agents by\nexploring diverse states or skills in reward-free environments, facilitating\nefficient adaptation to downstream tasks. As the agent cannot access extrinsic\nrewards during unsupervised exploration, existing methods design intrinsic\nrewards to model the explored data and encourage further exploration. However,\nthe explored data are always heterogeneous, posing the requirements of powerful\nrepresentation abilities for both intrinsic reward models and pre-trained\npolicies. In this work, we propose the Exploratory Diffusion Model (ExDM),\nwhich leverages the strong expressive ability of diffusion models to fit the\nexplored data, simultaneously boosting exploration and providing an efficient\ninitialization for downstream tasks. Specifically, ExDM can accurately estimate\nthe distribution of collected data in the replay buffer with the diffusion\nmodel and introduces the score-based intrinsic reward, encouraging the agent to\nexplore less-visited states. After obtaining the pre-trained policies, ExDM\nenables rapid adaptation to downstream tasks. In detail, we provide theoretical\nanalyses and practical algorithms for fine-tuning diffusion policies,\naddressing key challenges such as training instability and computational\ncomplexity caused by multi-step sampling. Extensive experiments demonstrate\nthat ExDM outperforms existing SOTA baselines in efficient unsupervised\nexploration and fast fine-tuning downstream tasks, especially in structurally\ncomplicated environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07279v2",
    "published_date": "2025-02-11 05:48:51 UTC",
    "updated_date": "2025-05-16 17:18:02 UTC"
  },
  {
    "arxiv_id": "2502.07277v1",
    "title": "Enhancing Video Understanding: Deep Neural Networks for Spatiotemporal Analysis",
    "authors": [
      "Amir Hosein Fadaei",
      "Mohammad-Reza A. Dehaqani"
    ],
    "abstract": "It's no secret that video has become the primary way we share information\nonline. That's why there's been a surge in demand for algorithms that can\nanalyze and understand video content. It's a trend going to continue as video\ncontinues to dominate the digital landscape. These algorithms will extract and\nclassify related features from the video and will use them to describe the\nevents and objects in the video. Deep neural networks have displayed\nencouraging outcomes in the realm of feature extraction and video description.\nThis paper will explore the spatiotemporal features found in videos and recent\nadvancements in deep neural networks in video understanding. We will review\nsome of the main trends in video understanding models and their structural\ndesign, the main problems, and some offered solutions in this topic. We will\nalso review and compare significant video understanding and action recognition\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07277v1",
    "published_date": "2025-02-11 05:44:50 UTC",
    "updated_date": "2025-02-11 05:44:50 UTC"
  },
  {
    "arxiv_id": "2502.07276v1",
    "title": "Dataset Ownership Verification in Contrastive Pre-trained Models",
    "authors": [
      "Yuechen Xie",
      "Jie Song",
      "Mengqi Xue",
      "Haofei Zhang",
      "Xingen Wang",
      "Bingde Hu",
      "Genlang Chen",
      "Mingli Song"
    ],
    "abstract": "High-quality open-source datasets, which necessitate substantial efforts for\ncuration, has become the primary catalyst for the swift progress of deep\nlearning. Concurrently, protecting these datasets is paramount for the\nwell-being of the data owner. Dataset ownership verification emerges as a\ncrucial method in this domain, but existing approaches are often limited to\nsupervised models and cannot be directly extended to increasingly popular\nunsupervised pre-trained models. In this work, we propose the first dataset\nownership verification method tailored specifically for self-supervised\npre-trained models by contrastive learning. Its primary objective is to\nascertain whether a suspicious black-box backbone has been pre-trained on a\nspecific unlabeled dataset, aiding dataset owners in upholding their rights.\nThe proposed approach is motivated by our empirical insights that when models\nare trained with the target dataset, the unary and binary instance\nrelationships within the embedding space exhibit significant variations\ncompared to models trained without the target dataset. We validate the efficacy\nof this approach across multiple contrastive pre-trained models including\nSimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that our\nmethod rejects the null hypothesis with a $p$-value markedly below $0.05$,\nsurpassing all previous methodologies. Our code is available at\nhttps://github.com/xieyc99/DOV4CL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07276v1",
    "published_date": "2025-02-11 05:42:21 UTC",
    "updated_date": "2025-02-11 05:42:21 UTC"
  },
  {
    "arxiv_id": "2502.07274v3",
    "title": "Memory Is Not the Bottleneck: Cost-Efficient Continual Learning via Weight Space Consolidation",
    "authors": [
      "Dongkyu Cho",
      "Taesup Moon",
      "Rumi Chunara",
      "Kyunghyun Cho",
      "Sungmin Cha"
    ],
    "abstract": "Continual learning (CL) has traditionally emphasized minimizing exemplar\nmemory usage, assuming that memory is the primary bottleneck. However, in\nmodern computing environments-particularly those involving large foundation\nmodels-memory is inexpensive and abundant, while GPU time constitutes the main\ncost. This paper re-examines CL under a more realistic setting with sufficient\nexemplar memory, where the system can retain a representative portion of past\ndata. We find that, under this regime, stability improves due to reduced\nforgetting, but plasticity diminishes as the model becomes biased toward prior\ntasks and struggles to adapt to new ones. Notably, even simple baselines like\nnaive replay can match or exceed the performance of state-of-the-art methods at\na fraction of the computational cost. Building on this insight, we propose a\nlightweight yet effective method called Weight Space Consolidation, which\ndirectly operates in the model's weight space via two core mechanisms: (1)\nrank-based parameter resets to recover plasticity, and (2) weight averaging to\nenhance stability. Our approach outperforms strong baselines across\nclass-incremental learning with image classifiers and continual instruction\ntuning with large language models, while requiring only one-third to one-fourth\nof the training cost. These findings challenge long-standing CL assumptions and\nestablish a new, cost-efficient baseline for real-world continual learning\nsystems where exemplar memory is no longer the limiting factor.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07274v3",
    "published_date": "2025-02-11 05:40:52 UTC",
    "updated_date": "2025-05-20 20:59:50 UTC"
  },
  {
    "arxiv_id": "2502.07273v2",
    "title": "Variational Learning Induces Adaptive Label Smoothing",
    "authors": [
      "Sin-Han Yang",
      "Zhedong Liu",
      "Gian Maria Marconi",
      "Mohammad Emtiyaz Khan"
    ],
    "abstract": "We show that variational learning naturally induces an adaptive label\nsmoothing where label noise is specialized for each example. Such\nlabel-smoothing is useful to handle examples with labeling errors and\ndistribution shifts, but designing a good adaptivity strategy is not always\neasy. We propose to skip this step and simply use the natural adaptivity\ninduced during the optimization of a variational objective. We show empirical\nresults where a variational algorithm called IVON outperforms traditional label\nsmoothing and yields adaptivity strategies similar to those of an existing\napproach. By connecting Bayesian methods to label smoothing, our work provides\na new way to handle overconfident predictions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07273v2",
    "published_date": "2025-02-11 05:40:42 UTC",
    "updated_date": "2025-03-04 06:26:07 UTC"
  },
  {
    "arxiv_id": "2502.07842v2",
    "title": "Column-wise Quantization of Weights and Partial Sums for Accurate and Efficient Compute-In-Memory Accelerators",
    "authors": [
      "Jiyoon Kim",
      "Kang Eun Jeon",
      "Yulhwa Kim",
      "Jong Hwan Ko"
    ],
    "abstract": "Compute-in-memory (CIM) is an efficient method for implementing deep neural\nnetworks (DNNs) but suffers from substantial overhead from analog-to-digital\nconverters (ADCs), especially as ADC precision increases. Low-precision ADCs\ncan reduce this overhead but introduce partial-sum quantization errors\ndegrading accuracy. Additionally, low-bit weight constraints, imposed by cell\nlimitations and the need for multiple cells for higher-bit weights, present\nfurther challenges. While fine-grained partial-sum quantization has been\nstudied to lower ADC resolution effectively, weight granularity, which limits\noverall partial-sum quantized accuracy, remains underexplored. This work\naddresses these challenges by aligning weight and partial-sum quantization\ngranularities at the column-wise level. Our method improves accuracy while\nmaintaining dequantization overhead, simplifies training by removing two-stage\nprocesses, and ensures robustness to memory cell variations via independent\ncolumn-wise scale factors. We also propose an open-source CIM-oriented\nconvolution framework to handle fine-grained weights and partial-sums\nefficiently, incorporating a novel tiling method and group convolution.\nExperimental results on ResNet-20 (CIFAR-10, CIFAR-100) and ResNet-18\n(ImageNet) show accuracy improvements of 0.99%, 2.69%, and 1.01%, respectively,\ncompared to the best-performing related works. Additionally, variation analysis\nreveals the robustness of our method against memory cell variations. These\nfindings highlight the effectiveness of our quantization scheme in enhancing\naccuracy and robustness while maintaining hardware efficiency in CIM-based DNN\nimplementations. Our code is available at\nhttps://github.com/jiyoonkm/ColumnQuant.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07842v2",
    "published_date": "2025-02-11 05:32:14 UTC",
    "updated_date": "2025-03-13 11:32:19 UTC"
  },
  {
    "arxiv_id": "2502.07266v1",
    "title": "When More is Less: Understanding Chain-of-Thought Length in LLMs",
    "authors": [
      "Yuyang Wu",
      "Yifei Wang",
      "Tianqi Du",
      "Stefanie Jegelka",
      "Yisen Wang"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning enhances the multi-step reasoning\ncapabilities of large language models (LLMs) by breaking complex tasks into\nsmaller, manageable sub-tasks. Researchers have been exploring ways to guide\nmodels to generate more complex CoT processes to improve the reasoning ability\nof LLMs, such as long CoT and the test-time scaling law. However, for most\nmodels and tasks, does an increase in CoT length consistently lead to improved\nreasoning accuracy? In this paper, we observe a nuanced relationship: as the\nnumber of reasoning steps increases, performance initially improves but\neventually decreases. To understand this phenomenon, we provide a piece of\nevidence that longer reasoning processes are increasingly susceptible to noise.\nWe theoretically prove the existence of an optimal CoT length and derive a\nscaling law for this optimal length based on model capability and task\ndifficulty. Inspired by our theory, we conduct experiments on both synthetic\nand real world datasets and propose Length-filtered Vote to alleviate the\neffects of excessively long or short CoTs. Our findings highlight the critical\nneed to calibrate CoT length to align with model capabilities and task demands,\noffering a principled framework for optimizing multi-step reasoning in LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07266v1",
    "published_date": "2025-02-11 05:28:59 UTC",
    "updated_date": "2025-02-11 05:28:59 UTC"
  },
  {
    "arxiv_id": "2502.07254v2",
    "title": "Fairness in Agentic AI: A Unified Framework for Ethical and Equitable Multi-Agent System",
    "authors": [
      "Rajesh Ranjan",
      "Shailja Gupta",
      "Surya Narayan Singh"
    ],
    "abstract": "Ensuring fairness in decentralized multi-agent systems presents significant\nchallenges due to emergent biases, systemic inefficiencies, and conflicting\nagent incentives. This paper provides a comprehensive survey of fairness in\nmulti-agent AI, introducing a novel framework where fairness is treated as a\ndynamic, emergent property of agent interactions. The framework integrates\nfairness constraints, bias mitigation strategies, and incentive mechanisms to\nalign autonomous agent behaviors with societal values while balancing\nefficiency and robustness. Through empirical validation, we demonstrate that\nincorporating fairness constraints results in more equitable decision-making.\nThis work bridges the gap between AI ethics and system design, offering a\nfoundation for accountable, transparent, and socially responsible multi-agent\nAI systems.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "12 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.07254v2",
    "published_date": "2025-02-11 04:42:00 UTC",
    "updated_date": "2025-03-02 08:56:31 UTC"
  },
  {
    "arxiv_id": "2502.07250v1",
    "title": "NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection",
    "authors": [
      "Liying Han",
      "Gaofeng Dong",
      "Xiaomin Ouyang",
      "Lance Kaplan",
      "Federico Cerutti",
      "Mani Srivastava"
    ],
    "abstract": "Current machine learning models excel in short-span perception tasks but\nstruggle to derive high-level insights from long-term observation, a capability\ncentral to understanding complex events (CEs). CEs, defined as sequences of\nshort-term atomic events (AEs) governed by spatiotemporal rules, are\nchallenging to detect online due to the need to extract meaningful patterns\nfrom long and noisy sensor data while ignoring irrelevant events. We\nhypothesize that state-based methods are well-suited for CE detection, as they\ncapture event progression through state transitions without requiring long-term\nmemory. Baseline experiments validate this, demonstrating that the state-space\nmodel Mamba outperforms existing architectures. However, Mamba's reliance on\nextensive labeled data, which are difficult to obtain, motivates our second\nhypothesis: decoupling CE rule learning from noisy sensor data can reduce data\nrequirements. To address this, we propose NARCE, a framework that combines\nNeural Algorithmic Reasoning (NAR) to split the task into two components: (i)\nlearning CE rules independently of sensor data using synthetic concept traces\ngenerated by LLMs and (ii) mapping sensor inputs to these rules via an adapter.\nOur results show that NARCE outperforms baselines in accuracy, generalization\nto unseen and longer sensor data, and data efficiency, significantly reducing\nannotation costs while advancing robust CE detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07250v1",
    "published_date": "2025-02-11 04:34:53 UTC",
    "updated_date": "2025-02-11 04:34:53 UTC"
  },
  {
    "arxiv_id": "2502.07244v1",
    "title": "Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting",
    "authors": [
      "Jiecheng Lu",
      "Shihao Yang"
    ],
    "abstract": "Autoregressive attention-based time series forecasting (TSF) has drawn\nincreasing interest, with mechanisms like linear attention sometimes\noutperforming vanilla attention. However, deeper Transformer architectures\nfrequently misalign with autoregressive objectives, obscuring the underlying\nVAR structure embedded within linear attention and hindering their ability to\ncapture the data generative processes in TSF. In this work, we first show that\na single linear attention layer can be interpreted as a dynamic vector\nautoregressive (VAR) structure. We then explain that existing multi-layer\nTransformers have structural mismatches with the autoregressive forecasting\nobjective, which impair interpretability and generalization ability. To address\nthis, we show that by rearranging the MLP, attention, and input-output flow,\nmulti-layer linear attention can also be aligned as a VAR model. Then, we\npropose Structural Aligned Mixture of VAR (SAMoVAR), a linear Transformer\nvariant that integrates interpretable dynamic VAR weights for multivariate TSF.\nBy aligning the Transformer architecture with autoregressive objectives,\nSAMoVAR delivers improved performance, interpretability, and computational\nefficiency, comparing to SOTA TSF models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07244v1",
    "published_date": "2025-02-11 04:24:43 UTC",
    "updated_date": "2025-02-11 04:24:43 UTC"
  },
  {
    "arxiv_id": "2502.07243v1",
    "title": "Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement",
    "authors": [
      "Xueyao Zhang",
      "Xiaohui Zhang",
      "Kainan Peng",
      "Zhenyu Tang",
      "Vimal Manohar",
      "Yingru Liu",
      "Jeff Hwang",
      "Dangna Li",
      "Yuhao Wang",
      "Julian Chan",
      "Yuan Huang",
      "Zhizheng Wu",
      "Mingbo Ma"
    ],
    "abstract": "The imitation of voice, targeted on specific speech attributes such as timbre\nand speaking style, is crucial in speech generation. However, existing methods\nrely heavily on annotated data, and struggle with effectively disentangling\ntimbre and style, leading to challenges in achieving controllable generation,\nespecially in zero-shot scenarios. To address these issues, we propose Vevo, a\nversatile zero-shot voice imitation framework with controllable timbre and\nstyle. Vevo operates in two core stages: (1) Content-Style Modeling: Given\neither text or speech's content tokens as input, we utilize an autoregressive\ntransformer to generate the content-style tokens, which is prompted by a style\nreference; (2) Acoustic Modeling: Given the content-style tokens as input, we\nemploy a flow-matching transformer to produce acoustic representations, which\nis prompted by a timbre reference. To obtain the content and content-style\ntokens of speech, we design a fully self-supervised approach that progressively\ndecouples the timbre, style, and linguistic content of speech. Specifically, we\nadopt VQ-VAE as the tokenizer for the continuous hidden features of HuBERT. We\ntreat the vocabulary size of the VQ-VAE codebook as the information bottleneck,\nand adjust it carefully to obtain the disentangled speech representations.\nSolely self-supervised trained on 60K hours of audiobook speech data, without\nany fine-tuning on style-specific corpora, Vevo matches or surpasses existing\nmethods in accent and emotion conversion tasks. Additionally, Vevo's\neffectiveness in zero-shot voice conversion and text-to-speech tasks further\ndemonstrates its strong generalization and versatility. Audio samples are\navailable at https://versavoice.github.io.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07243v1",
    "published_date": "2025-02-11 04:18:33 UTC",
    "updated_date": "2025-02-11 04:18:33 UTC"
  },
  {
    "arxiv_id": "2502.07239v1",
    "title": "Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation",
    "authors": [
      "Pinxin Liu",
      "Pengfei Zhang",
      "Hyeongwoo Kim",
      "Pablo Garrido",
      "Ari Sharpio",
      "Kyle Olszewski"
    ],
    "abstract": "Co-speech gesture generation is crucial for creating lifelike avatars and\nenhancing human-computer interactions by synchronizing gestures with speech.\nDespite recent advancements, existing methods struggle with accurately\nidentifying the rhythmic or semantic triggers from audio for generating\ncontextualized gesture patterns and achieving pixel-level realism. To address\nthese challenges, we introduce Contextual Gesture, a framework that improves\nco-speech gesture video generation through three innovative components: (1) a\nchronological speech-gesture alignment that temporally connects two modalities,\n(2) a contextualized gesture tokenization that incorporate speech context into\nmotion pattern representation through distillation, and (3) a structure-aware\nrefinement module that employs edge connection to link gesture keypoints to\nimprove video generation. Our extensive experiments demonstrate that Contextual\nGesture not only produces realistic and speech-aligned gesture videos but also\nsupports long-sequence generation and video gesture editing applications, shown\nin Fig.1 Project Page: https://andypinxinliu.github.io/Contextual-Gesture/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07239v1",
    "published_date": "2025-02-11 04:09:12 UTC",
    "updated_date": "2025-02-11 04:09:12 UTC"
  },
  {
    "arxiv_id": "2502.07238v2",
    "title": "Diffusion Suction Grasping with Large-Scale Parcel Dataset",
    "authors": [
      "Ding-Tao Huang",
      "Xinyi He",
      "Debei Hua",
      "Dongfang Yu",
      "En-Te Lin",
      "Long Zeng"
    ],
    "abstract": "While recent advances in object suction grasping have shown remarkable\nprogress, significant challenges persist particularly in cluttered and complex\nparcel handling scenarios. Two fundamental limitations hinder current\napproaches: (1) the lack of a comprehensive suction grasp dataset tailored for\nparcel manipulation tasks, and (2) insufficient adaptability to diverse object\ncharacteristics including size variations, geometric complexity, and textural\ndiversity. To address these challenges, we present Parcel-Suction-Dataset, a\nlarge-scale synthetic dataset containing 25 thousand cluttered scenes with 410\nmillion precision-annotated suction grasp poses. This dataset is generated\nthrough our novel geometric sampling algorithm that enables efficient\ngeneration of optimal suction grasps incorporating both physical constraints\nand material properties. We further propose Diffusion-Suction, an innovative\nframework that reformulates suction grasp prediction as a conditional\ngeneration task through denoising diffusion probabilistic models. Our method\niteratively refines random noise into suction grasp score maps through\nvisual-conditioned guidance from point cloud observations, effectively learning\nspatial point-wise affordances from our synthetic dataset. Extensive\nexperiments demonstrate that the simple yet efficient Diffusion-Suction\nachieves new state-of-the-art performance compared to previous models on both\nParcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07238v2",
    "published_date": "2025-02-11 04:09:11 UTC",
    "updated_date": "2025-03-17 03:26:36 UTC"
  },
  {
    "arxiv_id": "2502.07218v1",
    "title": "LUNAR: LLM Unlearning via Neural Activation Redirection",
    "authors": [
      "William F. Shen",
      "Xinchi Qiu",
      "Meghdad Kurmanji",
      "Alex Iacob",
      "Lorenzo Sani",
      "Yihong Chen",
      "Nicola Cancedda",
      "Nicholas D. Lane"
    ],
    "abstract": "Large Language Models (LLMs) benefit from training on ever larger amounts of\ntextual data, but as a result, they increasingly incur the risk of leaking\nprivate information. The ability to selectively remove knowledge from LLMs is,\ntherefore, a highly desirable capability. In this paper, we propose LUNAR, a\nnovel unlearning methodology grounded in the Linear Representation Hypothesis.\nLUNAR operates by redirecting the representations of unlearned data to regions\nthat trigger the model's inherent ability to express its inability to answer.\nLUNAR achieves state-of-the-art unlearning performance while significantly\nenhancing the controllability of the unlearned model during inference.\nSpecifically, LUNAR achieves between 2.9x to 11.7x improvements on combined\n\"unlearning efficacy\" and \"model utility\" score (\"Deviation Score\") on the\nPISTOL dataset across various base models. We also demonstrate, through\nquantitative analysis and qualitative examples, LUNAR's superior\ncontrollability in generating coherent and contextually aware responses,\nmitigating undesired side effects of existing methods. Moreover, we demonstrate\nthat LUNAR is robust against white-box adversarial attacks and versatile in\nhandling real-world scenarios, such as processing sequential unlearning\nrequests.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07218v1",
    "published_date": "2025-02-11 03:23:22 UTC",
    "updated_date": "2025-02-11 03:23:22 UTC"
  },
  {
    "arxiv_id": "2502.07216v1",
    "title": "SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer",
    "authors": [
      "Wenxi Li",
      "Yuchen Guo",
      "Jilai Zheng",
      "Haozhe Lin",
      "Chao Ma",
      "Lu Fang",
      "Xiaokang Yang"
    ],
    "abstract": "Recent years have seen an increase in the use of gigapixel-level image and\nvideo capture systems and benchmarks with high-resolution wide (HRW) shots.\nHowever, unlike close-up shots in the MS COCO dataset, the higher resolution\nand wider field of view raise unique challenges, such as extreme sparsity and\nhuge scale changes, causing existing close-up detectors inaccuracy and\ninefficiency. In this paper, we present a novel model-agnostic sparse vision\ntransformer, dubbed SparseFormer, to bridge the gap of object detection between\nclose-up and HRW shots. The proposed SparseFormer selectively uses attentive\ntokens to scrutinize the sparsely distributed windows that may contain objects.\nIn this way, it can jointly explore global and local attention by fusing\ncoarse- and fine-grained features to handle huge scale changes. SparseFormer\nalso benefits from a novel Cross-slice non-maximum suppression (C-NMS)\nalgorithm to precisely localize objects from noisy windows and a simple yet\neffective multi-scale strategy to improve accuracy. Extensive experiments on\ntwo HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed\nSparseFormer significantly improves detection accuracy (up to 5.8%) and speed\n(up to 3x) over the state-of-the-art approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper is accepted to ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.07216v1",
    "published_date": "2025-02-11 03:21:25 UTC",
    "updated_date": "2025-02-11 03:21:25 UTC"
  },
  {
    "arxiv_id": "2502.07214v1",
    "title": "Pareto Optimal Algorithmic Recourse in Multi-cost Function",
    "authors": [
      "Wen-Ling Chen",
      "Hong-Chang Huang",
      "Kai-Hung Lin",
      "Shang-Wei Hwang",
      "Hao-Tsung Yang"
    ],
    "abstract": "In decision-making systems, algorithmic recourse aims to identify\nminimal-cost actions to alter an individual features, thereby obtaining a\ndesired outcome. This empowers individuals to understand, question, or alter\ndecisions that negatively affect them. However, due to the variety and\nsensitivity of system environments and individual personalities, quantifying\nthe cost of a single function is nearly impossible while considering multiple\ncriteria situations. Most current recourse mechanisms use gradient-based\nmethods that assume cost functions are differentiable, often not applicable in\nreal-world scenarios, resulting in sub-optimal solutions that compromise\nvarious criteria. These solutions are typically intractable and lack rigorous\ntheoretical foundations, raising concerns regarding interpretability,\nreliability, and transparency from the explainable AI (XAI) perspective.\n  To address these issues, this work proposes an algorithmic recourse framework\nthat handles non-differentiable and discrete multi-cost functions. By\nformulating recourse as a multi-objective optimization problem and assigning\nweights to different criteria based on their importance, our method identifies\nPareto optimal recourse recommendations. To demonstrate scalability, we\nincorporate the concept of epsilon-net, proving the ability to find\napproximated Pareto optimal actions. Experiments show the trade-off between\ndifferent criteria and the methods scalability in large graphs. Compared to\ncurrent heuristic practices, our approach provides a stronger theoretical\nfoundation and better aligns recourse suggestions with real-world requirements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07214v1",
    "published_date": "2025-02-11 03:16:08 UTC",
    "updated_date": "2025-02-11 03:16:08 UTC"
  },
  {
    "arxiv_id": "2502.07213v2",
    "title": "Evaluation for Regression Analyses on Evolving Data Streams",
    "authors": [
      "Yibin Sun",
      "Heitor Murilo Gomes",
      "Bernhard Pfahringer",
      "Albert Bifet"
    ],
    "abstract": "The paper explores the challenges of regression analysis in evolving data\nstreams, an area that remains relatively underexplored compared to\nclassification. We propose a standardized evaluation process for regression and\nprediction interval tasks in streaming contexts. Additionally, we introduce an\ninnovative drift simulation strategy capable of synthesizing various drift\ntypes, including the less-studied incremental drift. Comprehensive experiments\nwith state-of-the-art methods, conducted under the proposed process, validate\nthe effectiveness and robustness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 Pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07213v2",
    "published_date": "2025-02-11 03:12:08 UTC",
    "updated_date": "2025-02-19 01:03:33 UTC"
  },
  {
    "arxiv_id": "2502.07207v1",
    "title": "A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning",
    "authors": [
      "Ehsan Hallaji",
      "Roozbeh Razavi-Far",
      "Mehrdad Saif"
    ],
    "abstract": "Advanced Persistent Threats (APTs) pose a significant security risk to\norganizations and industries. These attacks often lead to severe data breaches\nand compromise the system for a long time. Mitigating these sophisticated\nattacks is highly challenging due to the stealthy and persistent nature of\nAPTs. Machine learning models are often employed to tackle this challenge by\nbringing automation and scalability to APT detection. Nevertheless, these\nintelligent methods are data-driven, and thus, highly affected by the quality\nand relevance of input data. This paper aims to analyze measurements considered\nwhen recording network traffic and conclude which features contribute more to\ndetecting APT samples. To do this, we study the features associated with\nvarious APT cases and determine their importance using a machine learning\nframework. To ensure the generalization of our findings, several feature\nselection techniques are employed and paired with different classifiers to\nevaluate their effectiveness. Our findings provide insights into how APT\ndetection can be enhanced in real-world scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted for publication in the 2024 International Conference on\n  Computational Science and Computational Intelligence (CSCI'24)",
    "pdf_url": "http://arxiv.org/pdf/2502.07207v1",
    "published_date": "2025-02-11 03:06:03 UTC",
    "updated_date": "2025-02-11 03:06:03 UTC"
  },
  {
    "arxiv_id": "2502.07205v2",
    "title": "VINP: Variational Bayesian Inference with Neural Speech Prior for Joint ASR-Effective Speech Dereverberation and Blind RIR Identification",
    "authors": [
      "Pengyu Wang",
      "Ying Fang",
      "Xiaofei Li"
    ],
    "abstract": "Reverberant speech, denoting the speech signal degraded by the process of\nreverberation, contains crucial knowledge of both anechoic source speech and\nroom impulse response (RIR). This work proposes a variational Bayesian\ninference (VBI) framework with neural speech prior (VINP) for joint speech\ndereverberation and blind RIR identification. In VINP, a probabilistic signal\nmodel is constructed in the time-frequency (T-F) domain based on convolution\ntransfer function (CTF) approximation. For the first time, we propose using an\narbitrary discriminative dereverberation deep neural network (DNN) to predict\nthe prior distribution of anechoic speech within a probabilistic model. By\nintegrating both reverberant speech and the anechoic speech prior, VINP yields\nthe maximum a posteriori (MAP) and maximum likelihood (ML) estimations of the\nanechoic speech spectrum and CTF filter, respectively. After simple\ntransformations, the waveforms of anechoic speech and RIR are estimated.\nMoreover, VINP is effective for automatic speech recognition (ASR) systems,\nwhich sets it apart from most deep learning (DL)-based single-channel\ndereverberation approaches. Experiments on single-channel speech\ndereverberation demonstrate that VINP reaches an advanced level in most metrics\nrelated to human perception and displays unquestionable state-of-the-art (SOTA)\nperformance in ASR-related metrics. For blind RIR identification, experiments\nindicate that VINP attains the SOTA level in blind estimation of reverberation\ntime at 60 dB (RT60) and direct-to-reverberation ratio (DRR). Codes and audio\nsamples are available online.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "Submitted to IEEE/ACM Trans. on TASLP",
    "pdf_url": "http://arxiv.org/pdf/2502.07205v2",
    "published_date": "2025-02-11 02:54:28 UTC",
    "updated_date": "2025-02-24 08:11:36 UTC"
  },
  {
    "arxiv_id": "2502.07202v2",
    "title": "Monte Carlo Tree Diffusion for System 2 Planning",
    "authors": [
      "Jaesik Yoon",
      "Hyeonseo Cho",
      "Doojin Baek",
      "Yoshua Bengio",
      "Sungjin Ahn"
    ],
    "abstract": "Diffusion models have recently emerged as a powerful tool for planning.\nHowever, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally\nimproves with additional test-time computation (TTC), standard diffusion-based\nplanners offer only limited avenues for TTC scalability. In this paper, we\nintroduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates\nthe generative strength of diffusion models with the adaptive search\ncapabilities of MCTS. Our method reconceptualizes denoising as a\ntree-structured process, allowing partially denoised plans to be iteratively\nevaluated, pruned, and refined. By selectively expanding promising trajectories\nwhile retaining the flexibility to revisit and improve suboptimal branches,\nMCTD achieves the benefits of MCTS such as controlling exploration-exploitation\ntrade-offs within the diffusion framework. Empirical results on challenging\nlong-horizon tasks show that MCTD outperforms diffusion baselines, yielding\nhigher-quality solutions as TTC increases.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07202v2",
    "published_date": "2025-02-11 02:51:42 UTC",
    "updated_date": "2025-04-11 00:14:32 UTC"
  },
  {
    "arxiv_id": "2502.07194v1",
    "title": "Dense Object Detection Based on De-homogenized Queries",
    "authors": [
      "Yueming Huang",
      "Chenrui Ma",
      "Hao Zhou",
      "Hao Wu",
      "Guowu Yuan"
    ],
    "abstract": "Dense object detection is widely used in automatic driving, video\nsurveillance, and other fields. This paper focuses on the challenging task of\ndense object detection. Currently, detection methods based on greedy\nalgorithms, such as non-maximum suppression (NMS), often produce many\nrepetitive predictions or missed detections in dense scenarios, which is a\ncommon problem faced by NMS-based algorithms. Through the end-to-end DETR\n(DEtection TRansformer), as a type of detector that can incorporate the\npost-processing de-duplication capability of NMS, etc., into the network, we\nfound that homogeneous queries in the query-based detector lead to a reduction\nin the de-duplication capability of the network and the learning efficiency of\nthe encoder, resulting in duplicate prediction and missed detection problems.\nTo solve this problem, we propose learnable differentiated encoding to\nde-homogenize the queries, and at the same time, queries can communicate with\neach other via differentiated encoding information, replacing the previous\nself-attention among the queries. In addition, we used joint loss on the output\nof the encoder that considered both location and confidence prediction to give\na higher-quality initialization for queries. Without cumbersome decoder\nstacking and guaranteeing accuracy, our proposed end-to-end detection framework\nwas more concise and reduced the number of parameters by about 8% compared to\ndeformable DETR. Our method achieved excellent results on the challenging\nCrowdHuman dataset with 93.6% average precision (AP), 39.2% MR-2, and 84.3% JI.\nThe performance overperformed previous SOTA methods, such as Iter-E2EDet\n(Progressive End-to-End Object Detection) and MIP (One proposal, Multiple\npredictions). In addition, our method is more robust in various scenarios with\ndifferent densities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07194v1",
    "published_date": "2025-02-11 02:36:10 UTC",
    "updated_date": "2025-02-11 02:36:10 UTC"
  },
  {
    "arxiv_id": "2502.07838v2",
    "title": "NanoVLMs: How small can we go and still make coherent Vision Language Models?",
    "authors": [
      "Mukund Agarwalla",
      "Himanshu Kumar",
      "Raj Dandekar",
      "Rajat Dandekar",
      "Sreedath Panat"
    ],
    "abstract": "Vision-Language Models (VLMs), such as GPT-4V and Llama 3.2 vision, have\ngarnered significant research attention for their ability to leverage Large\nLanguage Models (LLMs) in multimodal tasks. However, their potential is\nconstrained by inherent challenges, including proprietary restrictions,\nsubstantial computational demands, and limited accessibility. Smaller models,\nsuch as GIT and BLIP, exhibit marked limitations, often failing to generate\ncoherent and consistent text beyond a few tokens, even with extensive training.\nThis underscores a pivotal inquiry: how small can a VLM be and still produce\nfluent and consistent text? Drawing inspiration from the exceptional learning\nprocess of 3-4 year old children, who rely heavily on visual cues for\nunderstanding and communication, we introduce two novel datasets: ShortDesc\n(featuring concise image descriptions) and LongDesc (containing more detailed\nimage descriptions). These datasets consist of image-text pairs where the text\nis restricted to the simple vocabulary and syntax typically used by young\nchildren, generated with a scaled-down model, GPT-4o. Using these datasets, we\ndemonstrate that it is possible to train VLMs that are significantly smaller,\nup to 10 times smaller than state of the art(SOTA) small VLMs while maintaining\narchitectural simplicity. To evaluate the outputs, we leverage GPT-4o to grade\nthe text, as if stories written by students, on creativity, meaningfulness, and\nconsistency, assigning scores out of 10. This method addresses limitations of\nstandard benchmarks by accommodating unstructured outputs and providing a\nmultidimensional evaluation of the model capabilities. Our findings contribute\nto the development of lightweight, accessible multimodal models for resource\nconstrained environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.07838v2",
    "published_date": "2025-02-11 02:31:45 UTC",
    "updated_date": "2025-02-13 11:13:14 UTC"
  },
  {
    "arxiv_id": "2502.07191v4",
    "title": "Bag of Tricks for Inference-time Computation of LLM Reasoning",
    "authors": [
      "Fan Liu",
      "Wenshuo Chao",
      "Naiqiang Tan",
      "Hao Liu"
    ],
    "abstract": "With the advancement of large language models (LLMs), solving complex\nreasoning tasks has gained increasing attention. Inference-time computation\nmethods (e.g., Best-of-N, beam search, et al.) are particularly valuable as\nthey can enhance reasoning performance without modifying model parameters or\nrequiring additional training. However, these techniques come with\nimplementation challenges, and most existing methods remain at the\nproof-of-concept stage with limited practical adoption due to their\ncomputational complexity and varying effectiveness across different tasks. In\nthis paper, we investigate and benchmark diverse inference-time computation\nstrategies across reasoning tasks of varying complexity. Since most current\nmethods rely on a proposer-verifier pipeline that first generates candidate\nsolutions (e.g., reasoning solutions) and then selects the best one based on\nreward signals (e.g., RLHF rewards, process rewards), our research focuses on\noptimizing both candidate solution generation (e.g., instructing prompts,\nhyperparameters such as temperature and top-p) and reward mechanisms (e.g.,\nself-evaluation, reward types). Through extensive experiments (more than 20,000\nA100-80G GPU hours with over 1,000 experiments) across a variety of models\n(e.g., Llama, Qwen, and Mistral families) of various sizes, our ablation\nstudies reveal that previously overlooked strategies can significantly enhance\nperformance (e.g., tuning temperature can improve reasoning task performance by\nup to 5%). Furthermore, we establish a standardized benchmark for\ninference-time computation by systematically evaluating six representative\nmethods across eight reasoning tasks. These findings provide a stronger\nfoundation for future research. The code is available at\nhttps://github.com/usail-hkust/benchmark_inference_time_computation_LLM",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07191v4",
    "published_date": "2025-02-11 02:31:11 UTC",
    "updated_date": "2025-02-17 03:54:05 UTC"
  },
  {
    "arxiv_id": "2502.07190v2",
    "title": "Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task",
    "authors": [
      "Junjie Wu",
      "Mo Yu",
      "Lemao Liu",
      "Dit-Yan Yeung",
      "Jie Zhou"
    ],
    "abstract": "While LLMs have exhibited strong performance on various NLP tasks, it is\nnoteworthy that most of these tasks rely on utilizing the vast amount of\nknowledge encoded in LLMs' parameters, rather than solving new problems without\nprior knowledge. In cognitive research, the latter ability is referred to as\nfluid intelligence, which is considered to be critical for assessing human\nintelligence. Recent research on fluid intelligence assessments has highlighted\nsignificant deficiencies in LLMs' abilities. In this paper, we analyze the\nchallenges LLMs face in demonstrating fluid intelligence through controlled\nexperiments, using the most representative ARC task as an example. Our study\nrevealed three major limitations in existing LLMs: limited ability for skill\ncomposition, unfamiliarity with abstract input formats, and the intrinsic\ndeficiency of left-to-right decoding. Our data and code can be found in\nhttps://wujunjie1998.github.io/araoc-benchmark.github.io/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 9 figures, accepted by NAACL 2025 main conference",
    "pdf_url": "http://arxiv.org/pdf/2502.07190v2",
    "published_date": "2025-02-11 02:31:09 UTC",
    "updated_date": "2025-03-03 06:50:25 UTC"
  },
  {
    "arxiv_id": "2502.07184v1",
    "title": "Refine Knowledge of Large Language Models via Adaptive Contrastive Learning",
    "authors": [
      "Yinghui Li",
      "Haojing Huang",
      "Jiayi Kuang",
      "Yangning Li",
      "Shu-Yu Guo",
      "Chao Qu",
      "Xiaoyu Tan",
      "Hai-Tao Zheng",
      "Ying Shen",
      "Philip S. Yu"
    ],
    "abstract": "How to alleviate the hallucinations of Large Language Models (LLMs) has\nalways been the fundamental goal pursued by the LLMs research community.\nLooking through numerous hallucination-related studies, a mainstream category\nof methods is to reduce hallucinations by optimizing the knowledge\nrepresentation of LLMs to change their output. Considering that the core focus\nof these works is the knowledge acquired by models, and knowledge has long been\na central theme in human societal progress, we believe that the process of\nmodels refining knowledge can greatly benefit from the way humans learn. In our\nwork, by imitating the human learning process, we design an Adaptive\nContrastive Learning strategy. Our method flexibly constructs different\npositive and negative samples for contrastive learning based on LLMs' actual\nmastery of knowledge. This strategy helps LLMs consolidate the correct\nknowledge they already possess, deepen their understanding of the correct\nknowledge they have encountered but not fully grasped, forget the incorrect\nknowledge they previously learned, and honestly acknowledge the knowledge they\nlack. Extensive experiments and detailed analyses on widely used datasets\ndemonstrate the effectiveness of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07184v1",
    "published_date": "2025-02-11 02:19:13 UTC",
    "updated_date": "2025-02-11 02:19:13 UTC"
  },
  {
    "arxiv_id": "2502.07179v1",
    "title": "Improved YOLOv7 model for insulator defect detection",
    "authors": [
      "Zhenyue Wang",
      "Guowu Yuan",
      "Hao Zhou",
      "Yi Ma",
      "Yutang Ma",
      "Dong Chen"
    ],
    "abstract": "Insulators are crucial insulation components and structural supports in power\ngrids, playing a vital role in the transmission lines. Due to temperature\nfluctuations, internal stress, or damage from hail, insulators are prone to\ninjury. Automatic detection of damaged insulators faces challenges such as\ndiverse types, small defect targets, and complex backgrounds and shapes. Most\nresearch for detecting insulator defects has focused on a single defect type or\na specific material. However, the insulators in the grid's transmission lines\nhave different colors and materials. Various insulator defects coexist, and the\nexisting methods have difficulty meeting the practical application\nrequirements. Current methods suffer from low detection accuracy and mAP0.5\ncannot meet application requirements. This paper proposes an improved YOLOv7\nmodel for multi-type insulator defect detection. First, our model replaces the\nSPPCSPC module with the RFB module to enhance the network's feature extraction\ncapability. Second, a CA mechanism is introduced into the head part to enhance\nthe network's feature representation ability and to improve detection accuracy.\nThird, a WIoU loss function is employed to address the low-quality samples\nhindering model generalization during training, thereby improving the model's\noverall performance. The experimental results indicate that the proposed model\nexhibits enhancements across various performance metrics. Specifically, there\nis a 1.6% advancement in mAP_0.5, a corresponding 1.6% enhancement in\nmAP_0.5:0.95, a 1.3% elevation in precision, and a 1% increase in recall.\nMoreover, the model achieves parameter reduction by 3.2 million, leading to a\ndecrease of 2.5 GFLOPS in computational cost. Notably, there is also an\nimprovement of 2.81 milliseconds in single-image detection speed.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07179v1",
    "published_date": "2025-02-11 02:09:30 UTC",
    "updated_date": "2025-02-11 02:09:30 UTC"
  },
  {
    "arxiv_id": "2502.07175v1",
    "title": "Foreign-Object Detection in High-Voltage Transmission Line Based on Improved YOLOv8m",
    "authors": [
      "Zhenyue Wang",
      "Guowu Yuan",
      "Hao Zhou",
      "Yi Ma",
      "Yutang Ma"
    ],
    "abstract": "The safe operation of high-voltage transmission lines ensures the power\ngrid's security. Various foreign objects attached to the transmission lines,\nsuch as balloons, kites and nesting birds, can significantly affect the safe\nand stable operation of high-voltage transmission lines. With the advancement\nof computer vision technology, periodic automatic inspection of foreign objects\nis efficient and necessary. Existing detection methods have low accuracy\nbecause foreign objects at-tached to the transmission lines are complex,\nincluding occlusions, diverse object types, significant scale variations, and\ncomplex backgrounds. In response to the practical needs of the Yunnan Branch of\nChina Southern Power Grid Co., Ltd., this paper proposes an improved\nYOLOv8m-based model for detecting foreign objects on transmission lines.\nExperiments are conducted on a dataset collected from Yunnan Power Grid. The\nproposed model enhances the original YOLOv8m by in-corporating a Global\nAttention Module (GAM) into the backbone to focus on occluded foreign objects,\nreplacing the SPPF module with the SPPCSPC module to augment the model's\nmultiscale feature extraction capability, and introducing the Focal-EIoU loss\nfunction to address the issue of high- and low-quality sample imbalances. These\nimprovements accelerate model convergence and enhance detection accuracy. The\nexperimental results demonstrate that our proposed model achieves a 2.7%\nincrease in mAP_0.5, a 4% increase in mAP_0.5:0.95, and a 6% increase in\nrecall.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07175v1",
    "published_date": "2025-02-11 01:58:32 UTC",
    "updated_date": "2025-02-11 01:58:32 UTC"
  },
  {
    "arxiv_id": "2502.07172v3",
    "title": "SemiHMER: Semi-supervised Handwritten Mathematical Expression Recognition using pseudo-labels",
    "authors": [
      "Kehua Chen",
      "Haoyang Shen"
    ],
    "abstract": "In this paper, we study semi-supervised Handwritten Mathematical Expression\nRecognition (HMER) via exploring both labeled data and extra unlabeled data. We\npropose a novel consistency regularization framework, termed SemiHMER, which\nintroduces dual-branch semi-supervised learning. Specifically, we enforce\nconsistency between the two networks for the same input image. The\npseudo-label, generated by one perturbed recognition network, is utilized to\nsupervise the other network using the standard cross-entropy loss. The SemiHMER\nconsistency encourages high similarity between the predictions of the two\nperturbed networks for the same input image and expands the training data by\nleveraging unlabeled data with pseudo-labels. We further introduce a\nweak-to-strong strategy by applying different levels of augmentation to each\nbranch, effectively expanding the training data and enhancing the quality of\nnetwork training. Additionally, we propose a novel module, the Global Dynamic\nCounting Module (GDCM), to enhance the performance of the HMER decoder by\nalleviating recognition inaccuracies in long-distance formula recognition and\nreducing the occurrence of repeated characters. The experimental results\ndemonstrate that our work achieves significant performance improvements, with\nan average accuracy increase of 5.47% on CROHME14, 4.87% on CROHME16, and 5.25%\non CROHME19, compared to our baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07172v3",
    "published_date": "2025-02-11 01:39:11 UTC",
    "updated_date": "2025-02-20 01:17:01 UTC"
  },
  {
    "arxiv_id": "2502.07835v1",
    "title": "Bridging LLM-Generated Code and Requirements: Reverse Generation technique and SBC Metric for Developer Insights",
    "authors": [
      "Ahilan Ayyachamy Nadar Ponnusamy"
    ],
    "abstract": "The rise of Large Language Models (LLMs) in software engineering,\nparticularly in code generation, has garnered significant attention. However,\nassessing the quality of AI-generated code remains a challenge due to the\ninherent complexity of programming tasks and the lack of robust evaluation\nmetrics that align well with human judgment. Traditional token-based metrics\nsuch as BLEU and ROUGE, while commonly used in natural language processing,\nexhibit weak correlations with human assessments in code intelligence and\nverification tasks. Furthermore, these metrics are primarily research focused\nand are not designed for seamless integration into the software development\nlifecycle, limiting their practical utility for developers seeking to improve\ncode quality and security.\n  AI-assisted coding has been shown to be more beneficial for senior\ndevelopers, as they possess the expertise to critically evaluate the generated\ncode for correctness, completeness, and compliance. In contrast, junior\ndevelopers may struggle to identify hallucinations, missing functionality, or\nincorrect logic in AI-generated code. To bridge this gap, This paper introduces\na novel scoring mechanism called the SBC score, which is based on a reverse\ngeneration technique that leverages the natural language generation\ncapabilities of LLMs. Unlike direct code analysis, our approach reconstructs\nsystem requirements from AI-generated code and compares them with the original\nspecifications to quantify accuracy. The SBC score combines semantic\nsimilarity, BLEU, and completeness analysis, providing actionable insights to\ndevelopers by highlighting missing features and hallucinations. Our code and\ndatasets are available on GitHub",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07835v1",
    "published_date": "2025-02-11 01:12:11 UTC",
    "updated_date": "2025-02-11 01:12:11 UTC"
  },
  {
    "arxiv_id": "2502.07165v1",
    "title": "Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification",
    "authors": [
      "Peipei Wei",
      "Dimitris Dimitriadis",
      "Yan Xu",
      "Mingwei Shen"
    ],
    "abstract": "We present PRINCIPLE-BASED PROMPTING, a simple but effective multi-agent\nprompting strategy for text classification. It first asks multiple LLM agents\nto independently generate candidate principles based on analysis of\ndemonstration samples with or without labels, consolidates them into final\nprinciples via a finalizer agent, and then sends them to a classifier agent to\nperform downstream classification tasks. Extensive experiments on binary and\nmulti-class classification datasets with different sizes of LLMs show that our\napproach not only achieves substantial performance gains (1.55% - 19.37%) over\nzero-shot prompting on macro-F1 score but also outperforms other strong\nbaselines (CoT and stepback prompting). Principles generated by our approach\nhelp LLMs perform better on classification tasks than human crafted principles\non two private datasets. Our multi-agent PRINCIPLE-BASED PROMPTING approach\nalso shows on-par or better performance compared to demonstration-based\nfew-shot prompting approaches, yet with substantially lower inference costs.\nAblation studies show that label information and the multi-agent cooperative\nLLM framework play an important role in generating high-quality principles to\nfacilitate downstream classification tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in AAAI 2025 Workshop on Advancing LLM-Based\n  Multi-Agent Collaboration",
    "pdf_url": "http://arxiv.org/pdf/2502.07165v1",
    "published_date": "2025-02-11 01:10:13 UTC",
    "updated_date": "2025-02-11 01:10:13 UTC"
  },
  {
    "arxiv_id": "2502.07164v2",
    "title": "Does Training on Synthetic Data Make Models Less Robust?",
    "authors": [
      "Lingze Zhang",
      "Ellie Pavlick"
    ],
    "abstract": "An increasingly common practice is to train large language models (LLMs)\nusing synthetic data. Often this synthetic data is produced by the same or\nsimilar LLMs as those it is being used to train. This raises the question of\nwhether the synthetic data might in fact exacerbate certain \"blindspots\" by\nreinforcing heuristics that the LLM already encodes. In this paper, we conduct\nsimulated experiments on the natural language inference (NLI) task with\nLlama-2-7B-hf models. We use MultiNLI as the general task and HANS, a targeted\nevaluation set designed to measure the presence of specific heuristic\nstrategies for NLI, as our \"blindspot\" task. Our goal is to determine whether\nperformance disparities between the general and blind spot tasks emerge. Our\nresults indicate that synthetic data does not reinforce blindspots in the way\nwe expected. Specifically, we see that, while fine-tuning with synthetic data\ndoesn't necessarily reduce the use of the heuristic, it also does not make it\nworse as we hypothesized.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07164v2",
    "published_date": "2025-02-11 01:03:33 UTC",
    "updated_date": "2025-03-16 03:45:42 UTC"
  },
  {
    "arxiv_id": "2502.07161v1",
    "title": "A Survey on Mamba Architecture for Vision Applications",
    "authors": [
      "Fady Ibrahim",
      "Guangjun Liu",
      "Guanghui Wang"
    ],
    "abstract": "Transformers have become foundational for visual tasks such as object\ndetection, semantic segmentation, and video understanding, but their quadratic\ncomplexity in attention mechanisms presents scalability challenges. To address\nthese limitations, the Mamba architecture utilizes state-space models (SSMs)\nfor linear scalability, efficient processing, and improved contextual\nawareness. This paper investigates Mamba architecture for visual domain\napplications and its recent advancements, including Vision Mamba (ViM) and\nVideoMamba, which introduce bidirectional scanning, selective scanning\nmechanisms, and spatiotemporal processing to enhance image and video\nunderstanding. Architectural innovations like position embeddings, cross-scan\nmodules, and hierarchical designs further optimize the Mamba framework for\nglobal and local feature extraction. These advancements position Mamba as a\npromising architecture in computer vision research and applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07161v1",
    "published_date": "2025-02-11 00:59:30 UTC",
    "updated_date": "2025-02-11 00:59:30 UTC"
  },
  {
    "arxiv_id": "2502.07158v3",
    "title": "Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer",
    "authors": [
      "Jiaying Lu",
      "Stephanie R. Brown",
      "Songyuan Liu",
      "Shifan Zhao",
      "Kejun Dong",
      "Del Bold",
      "Michael Fundora",
      "Alaa Aljiffry",
      "Alex Fedorov",
      "Jocelyn Grunwell",
      "Xiao Hu"
    ],
    "abstract": "Early prediction of pediatric cardiac arrest (CA) is critical for timely\nintervention in high-risk intensive care settings. We introduce PedCA-FT, a\nnovel transformer-based framework that fuses tabular view of EHR with the\nderived textual view of EHR to fully unleash the interactions of\nhigh-dimensional risk factors and their dynamics. By employing dedicated\ntransformer modules for each modality view, PedCA-FT captures complex temporal\nand contextual patterns to produce robust CA risk estimates. Evaluated on a\ncurated pediatric cohort from the CHOA-CICU database, our approach outperforms\nten other artificial intelligence models across five key performance metrics\nand identifies clinically meaningful risk factors. These findings underscore\nthe potential of multimodal fusion techniques to enhance early CA detection and\nimprove patient care.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07158v3",
    "published_date": "2025-02-11 00:53:36 UTC",
    "updated_date": "2025-05-20 17:53:08 UTC"
  },
  {
    "arxiv_id": "2502.07834v1",
    "title": "MEMHD: Memory-Efficient Multi-Centroid Hyperdimensional Computing for Fully-Utilized In-Memory Computing Architectures",
    "authors": [
      "Do Yeong Kang",
      "Yeong Hwan Oh",
      "Chanwook Hwang",
      "Jinhee Kim",
      "Kang Eun Jeon",
      "Jong Hwan Ko"
    ],
    "abstract": "The implementation of Hyperdimensional Computing (HDC) on In-Memory Computing\n(IMC) architectures faces significant challenges due to the mismatch between\nhighdimensional vectors and IMC array sizes, leading to inefficient memory\nutilization and increased computation cycles. This paper presents MEMHD, a\nMemory-Efficient Multi-centroid HDC framework designed to address these\nchallenges. MEMHD introduces a clustering-based initialization method and\nquantization aware iterative learning for multi-centroid associative memory.\nThrough these approaches and its overall architecture, MEMHD achieves a\nsignificant reduction in memory requirements while maintaining or improving\nclassification accuracy. Our approach achieves full utilization of IMC arrays\nand enables one-shot (or few-shot) associative search. Experimental results\ndemonstrate that MEMHD outperforms state-of-the-art binary HDC models,\nachieving up to 13.69% higher accuracy with the same memory usage, or 13.25x\nmore memory efficiency at the same accuracy level. Moreover, MEMHD reduces\ncomputation cycles by up to 80x and array usage by up to 71x compared to\nbaseline IMC mapping methods when mapped to 128x128 IMC arrays, while\nsignificantly improving energy and computation cycle efficiency.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted to appear at DATE 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07834v1",
    "published_date": "2025-02-11 00:53:15 UTC",
    "updated_date": "2025-02-11 00:53:15 UTC"
  },
  {
    "arxiv_id": "2503.04761v1",
    "title": "Which Economic Tasks are Performed with AI? Evidence from Millions of Claude Conversations",
    "authors": [
      "Kunal Handa",
      "Alex Tamkin",
      "Miles McCain",
      "Saffron Huang",
      "Esin Durmus",
      "Sarah Heck",
      "Jared Mueller",
      "Jerry Hong",
      "Stuart Ritchie",
      "Tim Belonax",
      "Kevin K. Troy",
      "Dario Amodei",
      "Jared Kaplan",
      "Jack Clark",
      "Deep Ganguli"
    ],
    "abstract": "Despite widespread speculation about artificial intelligence's impact on the\nfuture of work, we lack systematic empirical evidence about how these systems\nare actually being used for different tasks. Here, we present a novel framework\nfor measuring AI usage patterns across the economy. We leverage a recent\nprivacy-preserving system to analyze over four million Claude.ai conversations\nthrough the lens of tasks and occupations in the U.S. Department of Labor's\nO*NET Database. Our analysis reveals that AI usage primarily concentrates in\nsoftware development and writing tasks, which together account for nearly half\nof all total usage. However, usage of AI extends more broadly across the\neconomy, with approximately 36% of occupations using AI for at least a quarter\nof their associated tasks. We also analyze how AI is being used for tasks,\nfinding 57% of usage suggests augmentation of human capabilities (e.g.,\nlearning or iterating on an output) while 43% suggests automation (e.g.,\nfulfilling a request with minimal human involvement). While our data and\nmethods face important limitations and only paint a picture of AI usage on a\nsingle platform, they provide an automated, granular approach for tracking AI's\nevolving role in the economy and identifying leading indicators of future\nimpact as these technologies continue to advance.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04761v1",
    "published_date": "2025-02-11 00:46:43 UTC",
    "updated_date": "2025-02-11 00:46:43 UTC"
  },
  {
    "arxiv_id": "2502.07156v2",
    "title": "Explaining 3D Computed Tomography Classifiers with Counterfactuals",
    "authors": [
      "Joseph Paul Cohen",
      "Louis Blankemeier",
      "Akshay Chaudhari"
    ],
    "abstract": "Counterfactual explanations enhance the interpretability of deep learning\nmodels in medical imaging, yet adapting them to 3D CT scans poses challenges\ndue to volumetric complexity and resource demands. We extend the Latent Shift\ncounterfactual generation method from 2D applications to explain 3D computed\ntomography (CT) scans classifiers. We address the challenges associated with 3D\nclassifiers, such as limited training samples and high memory demands, by\nimplementing a slice-based autoencoder and gradient blocking except for\nspecific chunks of slices. This method leverages a 2D encoder trained on CT\nslices, which are subsequently combined to maintain 3D context. We demonstrate\nthis technique on two models for clinical phenotype prediction and lung\nsegmentation. Our approach is both memory-efficient and effective for\ngenerating interpretable counterfactuals in high-resolution 3D medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code and models: https://github.com/ieee8023/ct-counterfactuals",
    "pdf_url": "http://arxiv.org/pdf/2502.07156v2",
    "published_date": "2025-02-11 00:44:20 UTC",
    "updated_date": "2025-04-02 19:04:29 UTC"
  },
  {
    "arxiv_id": "2502.07154v2",
    "title": "Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning",
    "authors": [
      "Feng Chen",
      "Allan Raventos",
      "Nan Cheng",
      "Surya Ganguli",
      "Shaul Druckmann"
    ],
    "abstract": "Recent progress in large language models (LLMs) highlights the power of\nscaling test-time compute to achieve strong performance on complex tasks, such\nas mathematical reasoning and code generation. This raises a critical question:\nhow should model training be modified to optimize performance under a\nsubsequent test-time compute strategy and budget? To explore this, we focus on\npass@N, a simple test-time strategy that searches for a correct answer in $N$\nindependent samples. We show, surprisingly, that training with cross-entropy\n(CE) loss can be ${\\it misaligned}$ with pass@N in that pass@N accuracy ${\\it\ndecreases}$ with longer training. We explain the origins of this misalignment\nin terms of model overconfidence induced by CE, and experimentally verify our\nprediction of overconfidence as an impediment to scaling test-time compute via\npass@N. Furthermore we suggest a principled, modified training loss that is\nbetter aligned to pass@N by limiting model confidence and rescuing pass@N test\nperformance. Our algorithm demonstrates improved mathematical reasoning on MATH\nand MiniF2F benchmarks under several scenarios: (1) providing answers to math\nquestions; and (2) proving theorems by searching over proof trees of varying\nshapes. Overall our work underscores the importance of co-designing two\ntraditionally separate phases of LLM development: training-time protocols and\ntest-time search and reasoning strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07154v2",
    "published_date": "2025-02-11 00:33:31 UTC",
    "updated_date": "2025-04-15 02:44:15 UTC"
  },
  {
    "arxiv_id": "2502.07153v1",
    "title": "Feature Importance Depends on Properties of the Data: Towards Choosing the Correct Explanations for Your Data and Decision Trees based Models",
    "authors": [
      "CÃ©lia Wafa Ayad",
      "Thomas Bonnier",
      "Benjamin Bosch",
      "Sonali Parbhoo",
      "Jesse Read"
    ],
    "abstract": "In order to ensure the reliability of the explanations of machine learning\nmodels, it is crucial to establish their advantages and limits and in which\ncase each of these methods outperform. However, the current understanding of\nwhen and how each method of explanation can be used is insufficient. To fill\nthis gap, we perform a comprehensive empirical evaluation by synthesizing\nmultiple datasets with the desired properties. Our main objective is to assess\nthe quality of feature importance estimates provided by local explanation\nmethods, which are used to explain predictions made by decision tree-based\nmodels. By analyzing the results obtained from synthetic datasets as well as\npublicly available binary classification datasets, we observe notable\ndisparities in the magnitude and sign of the feature importance estimates\ngenerated by these methods. Moreover, we find that these estimates are\nsensitive to specific properties present in the data. Although some model\nhyper-parameters do not significantly influence feature importance assignment,\nit is important to recognize that each method of explanation has limitations in\nspecific contexts. Our assessment highlights these limitations and provides\nvaluable insight into the suitability and reliability of different explanatory\nmethods in various scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07153v1",
    "published_date": "2025-02-11 00:29:55 UTC",
    "updated_date": "2025-02-11 00:29:55 UTC"
  },
  {
    "arxiv_id": "2502.07832v1",
    "title": "SHARP: Accelerating Language Model Inference by SHaring Adjacent layers with Recovery Parameters",
    "authors": [
      "Yiping Wang",
      "Hanxian Huang",
      "Yifang Chen",
      "Jishen Zhao",
      "Simon Shaolei Du",
      "Yuandong Tian"
    ],
    "abstract": "While Large language models (LLMs) have advanced natural language processing\ntasks, their growing computational and memory demands make deployment on\nresource-constrained devices like mobile phones increasingly challenging. In\nthis paper, we propose SHARP (SHaring Adjacent Layers with Recovery\nParameters), a novel approach to accelerate LLM inference by sharing parameters\nacross adjacent layers, thus reducing memory load overhead, while introducing\nlow-rank recovery parameters to maintain performance. Inspired by observations\nthat consecutive layers have similar outputs, SHARP employs a two-stage\nrecovery process: Single Layer Warmup (SLW), and Supervised Fine-Tuning (SFT).\nThe SLW stage aligns the outputs of the shared layers using L_2 loss, providing\na good initialization for the following SFT stage to further restore the model\nperformance. Extensive experiments demonstrate that SHARP can recover the\nmodel's perplexity on various in-distribution tasks using no more than 50k\nfine-tuning data while reducing the number of stored MLP parameters by 38% to\n65%. We also conduct several ablation studies of SHARP and show that replacing\nlayers towards the later parts of the model yields better performance\nretention, and that different recovery parameterizations perform similarly when\nparameter counts are matched. Furthermore, SHARP saves 42.8% in model storage\nand reduces the total inference time by 42.2% compared to the original\nLlama2-7b model on mobile devices. Our results highlight SHARP as an efficient\nsolution for reducing inference costs in deploying LLMs without the need for\npretraining-scale resources.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.07832v1",
    "published_date": "2025-02-11 00:21:40 UTC",
    "updated_date": "2025-02-11 00:21:40 UTC"
  },
  {
    "arxiv_id": "2502.10442v1",
    "title": "Analysis of Overparameterization in Continual Learning under a Linear Model",
    "authors": [
      "Daniel Goldfarb",
      "Paul Hand"
    ],
    "abstract": "Autonomous machine learning systems that learn many tasks in sequence are\nprone to the catastrophic forgetting problem. Mathematical theory is needed in\norder to understand the extent of forgetting during continual learning. As a\nfoundational step towards this goal, we study continual learning and\ncatastrophic forgetting from a theoretical perspective in the simple setting of\ngradient descent with no explicit algorithmic mechanism to prevent forgetting.\nIn this setting, we analytically demonstrate that overparameterization alone\ncan mitigate forgetting in the context of a linear regression model. We\nconsider a two-task setting motivated by permutation tasks, and show that as\nthe overparameterization ratio becomes sufficiently high, a model trained on\nboth tasks in sequence results in a low-risk estimator for the first task. As\npart of this work, we establish a non-asymptotic bound of the risk of a single\nlinear regression task, which may be of independent interest to the field of\ndouble descent theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10442v1",
    "published_date": "2025-02-11 00:15:38 UTC",
    "updated_date": "2025-02-11 00:15:38 UTC"
  },
  {
    "arxiv_id": "2502.07830v2",
    "title": "Captured by Captions: On Memorization and its Mitigation in CLIP Models",
    "authors": [
      "Wenhao Wang",
      "Adam Dziedzic",
      "Grace C. Kim",
      "Michael Backes",
      "Franziska Boenisch"
    ],
    "abstract": "Multi-modal models, such as CLIP, have demonstrated strong performance in\naligning visual and textual representations, excelling in tasks like image\nretrieval and zero-shot classification. Despite this success, the mechanisms by\nwhich these models utilize training data, particularly the role of\nmemorization, remain unclear. In uni-modal models, both supervised and\nself-supervised, memorization has been shown to be essential for\ngeneralization. However, it is not well understood how these findings would\napply to CLIP, which incorporates elements from both supervised learning via\ncaptions that provide a supervisory signal similar to labels, and from\nself-supervised learning via the contrastive objective. To bridge this gap in\nunderstanding, we propose a formal definition of memorization in CLIP (CLIPMem)\nand use it to quantify memorization in CLIP models. Our results indicate that\nCLIP's memorization behavior falls between the supervised and self-supervised\nparadigms, with \"mis-captioned\" samples exhibiting highest levels of\nmemorization. Additionally, we find that the text encoder contributes more to\nmemorization than the image encoder, suggesting that mitigation strategies\nshould focus on the text domain. Building on these insights, we propose\nmultiple strategies to reduce memorization while at the same time improving\nutility--something that had not been shown before for traditional learning\nparadigms where reducing memorization typically results in utility decrease.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.07830v2",
    "published_date": "2025-02-11 00:11:13 UTC",
    "updated_date": "2025-05-19 15:22:54 UTC"
  },
  {
    "arxiv_id": "2502.07140v1",
    "title": "Few-Shot Multi-Human Neural Rendering Using Geometry Constraints",
    "authors": [
      "Qian li",
      "Victoria FernÃ ndez Abrevaya",
      "Franck Multon",
      "Adnane Boukhayma"
    ],
    "abstract": "We present a method for recovering the shape and radiance of a scene\nconsisting of multiple people given solely a few images. Multi-human scenes are\ncomplex due to additional occlusion and clutter. For single-human settings,\nexisting approaches using implicit neural representations have achieved\nimpressive results that deliver accurate geometry and appearance. However, it\nremains challenging to extend these methods for estimating multiple humans from\nsparse views. We propose a neural implicit reconstruction method that addresses\nthe inherent challenges of this task through the following contributions:\nFirst, we propose to use geometry constraints by exploiting pre-computed meshes\nusing a human body model (SMPL). Specifically, we regularize the signed\ndistances using the SMPL mesh and leverage bounding boxes for improved\nrendering. Second, we propose a ray regularization scheme to minimize rendering\ninconsistencies, and a saturation regularization for robust optimization in\nvariable illumination. Extensive experiments on both real and synthetic\ndatasets demonstrate the benefits of our approach and show state-of-the-art\nperformance against existing neural reconstruction methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07140v1",
    "published_date": "2025-02-11 00:10:58 UTC",
    "updated_date": "2025-02-11 00:10:58 UTC"
  }
]