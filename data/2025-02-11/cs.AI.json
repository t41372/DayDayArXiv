{
  "date": "2025-02-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-11 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM 的推理安全性和多模态应用、强化学习与决策系统，以及图像生成和医学 AI 等领域，其中 LLM 相关研究（如知识融合和对抗攻击）最为突出，令人印象深刻的作品包括 Goedel-Prover 在开源自动定理证明上的突破，以及涉及知名学者如 Yoshua Bengio 的强化学习论文。\n\n下面，我将逐一简要概述今日论文，先优先讨论重要、话题性强的作品（如 LLM 和强化学习），再快速掠过其他领域。重点保留核心学术术语，并突出主要贡献和发现。\n\n### LLM 和 AI 安全领域\n- **Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding**（推测然后协作：通过解码融合语言模型知识）  \n  这篇论文提出 CoSD 算法，用于高效融合多个 LLM 的知识，提高跨领域性能和推理效率。主要贡献是通过草稿模型和决策树动态调用辅助模型，实现高达 10% 的准确率提升，适用于 LLM 应用的无监督知识融合。\n\n- **Universal Adversarial Attack on Aligned Multimodal LLMs**（针对对齐的多模态 LLM 的通用对抗攻击）  \n  作者开发了一种优化图像来破坏多模态 LLM 对齐机制的攻击方法，能在 SafeBench 基准上实现高达 93% 的成功率。主要发现是模型在对抗样本下易受跨模型转移攻击，强调了多模态 LLM 安全性的脆弱性。\n\n- **MetaSC: Test-Time Safety Specification Optimization for Language Models**（元自审：语言模型的测试时安全规范优化）  \n  这篇论文引入动态优化安全提示的方法，提升 LLM 对对抗性查询的鲁棒性。主要贡献是通过迭代更新提示，实现更高安全分数，适用于实时风险控制。\n\n- **Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving**（哥德尔证明器：开源自动定理证明的前沿模型）  \n  作者构建了 Goedel-Prover 模型，在 miniF2F 和 PutnamBench 上达到 57.6% 和 7 问题解决率的新高。主要发现是通过 1.64 百万正式语句数据集训练，证明开源 LLM 在数学推理中的可扩展性。\n\n- **Hallucination, Monofacts, and Miscalibration: An Empirical Investigation**（幻觉、单事实和校准失误：实证研究）  \n  论文分析 LLM 幻觉问题，引入经验校准方法减少幻觉。主要贡献是证明选择性加权训练可降低 40% 幻觉，同时保持准确性。\n\n### 强化学习和决策系统\n- **Training Sparse Mixture Of Experts Text Embedding Models**（训练稀疏混合专家文本嵌入模型）  \n  作者提出 Nomic Embed v2 模型，优化文本嵌入以减少推理延迟。主要发现是混合专家架构在 MIRACL 和 BEIR 基准上提升性能，同时保持高效性。\n\n- **Generative Risk Minimization for Out-of-Distribution Generalization on Graphs**（生成风险最小化：图上的分布外泛化）  \n  这篇论文开发 GRM 框架，用于图数据的分布外泛化。主要贡献是通过生成不变子图，提高节点和图级任务的泛化性能。\n\n- **Advancing Autonomous VLM Agents via Variational Subgoal-Conditioned Reinforcement Learning**（通过变分子目标条件强化学习提升自主 VLM 代理）  \n  作者提出 VSC-RL 框架，提升视觉语言模型代理的决策效率。主要发现是子目标优化加速长时序任务的学习。\n\n- **Monte Carlo Tree Diffusion for System 2 Planning**（蒙特卡洛树扩散：用于系统 2 规划）  \n  涉及知名学者 Yoshua Bengio，这篇论文引入 MCTD 方法，将扩散模型与 MCTS 结合。主要贡献是提升测试时计算的推理性能，适用于复杂规划任务。\n\n### 图像生成和多模态学习\n- **Training-Free Safe Denoisers for Safe Use of Diffusion Models**（无训练安全去噪器：用于扩散模型的安全应用）  \n  论文提出一种直接修改采样轨迹的安全去噪方法，避免生成不安全内容。主要发现是通过否定集约束，实现高质生成而无需重新训练。\n\n- **Greed is Good: A Unifying Perspective on Guided Generation**（贪婪即好：引导生成的一种统一视角）  \n  作者统一了后验引导和端到端引导的理论框架，并提出插值方法优化计算与准确性。主要贡献是应用于逆问题和分子生成，提高生成效率。\n\n- **Deep Semantic Graph Learning via LLM based Node Enhancement**（基于 LLM 的深度语义图学习）  \n  这篇论文结合 LLM 和图 Transformer，提升图学习性能。主要发现是 LLM 生成的语义表示显著改善节点分类任务。\n\n- **VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation**（VidCRAFT3：图像到视频生成的相机、物体和光照控制）  \n  作者扩展 VidCRAFT 框架，实现多元素控制的视频生成。主要贡献是通过 3D 点云和注意力机制，提升视频生成质量。\n\n### 医学和应用 AI\n- **From Hazard Identification to Controller Design: Proactive and LLM-Supported Safety Engineering for ML-Powered Systems**（从风险识别到控制器设计：ML 系统的前瞻性 LLM 支持安全工程）  \n  论文提出 LLM 辅助的 STPA 方法，提升 ML 系统安全。主要发现是自动化风险分析减少了对专家的依赖。\n\n- **CREDAL: Close Reading of Data Models**（CREDAL：数据模型的细读方法）  \n  作者开发 CREDAL 框架，用于批判性分析数据模型。主要贡献是通过系统化方法，揭示数据系统的社会和政治影响。\n\n- **Trustworthy AI on Safety, Bias, and Privacy: A Survey**（可信 AI：在安全、偏差和隐私方面的调查）  \n  这篇综述讨论 AI 的安全、偏差和隐私问题。主要发现是现有方法在这些领域仍存在漏洞，提供未来研究的洞见。\n\n其他论文，如一些纯理论模型（如 Polynomial-Time Approximability）或小众应用（如 SHACL-SKOS Based Knowledge Representation），虽有贡献但相对次要，我这里快速掠过：它们主要探讨特定领域优化，如强化学习逼近算法或知识表示框架，提升了计算效率，但未涉及广泛话题，故不展开讨论。\n\n总之，今天的 arXiv 论文强调了 AI 模型的实用性和鲁棒性，LLM 安全与推理的进展尤为值得关注，期待后续应用！（约800字）",
  "papers": [
    {
      "arxiv_id": "2502.08021v2",
      "title": "Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol",
      "title_zh": "翻译失败",
      "authors": [
        "Pai Liu",
        "Lingfeng Zhao",
        "Shivangi Agarwal",
        "Jinghan Liu",
        "Audrey Huang",
        "Philip Amortila",
        "Nan Jiang"
      ],
      "abstract": "Holdout validation and hyperparameter tuning from data is a long-standing\nproblem in offline reinforcement learning (RL). A standard framework is to use\noff-policy evaluation (OPE) methods to evaluate and select the policies, but\nOPE either incurs exponential variance (e.g., importance sampling) or has\nhyperparameters on their own (e.g., FQE and model-based). In this work we focus\non hyperparameter tuning for OPE itself, which is even more under-investigated.\nConcretely, we select among candidate value functions (\"model-free\") or\ndynamics (\"model-based\") to best assess the performance of a target policy. We\ndevelop: (1) new model-free and model-based selectors with theoretical\nguarantees, and (2) a new experimental protocol for empirically evaluating\nthem. Compared to the model-free protocol in prior works, our new protocol\nallows for more stable generation and better control of candidate value\nfunctions in an optimization-free manner, and evaluation of model-free and\nmodel-based methods alike. We exemplify the protocol on Gym-Hopper, and find\nthat our new model-free selector, LSTD-Tournament, demonstrates promising\nempirical performance.",
      "tldr_zh": "本文探讨了离线强化学习（offline RL）中 off-policy evaluation (OPE) 的超参数调优问题，旨在通过选择最佳候选价值函数（model-free）或动态模型（model-based）来评估目标策略的性能。研究贡献包括开发了具有理论保证的新型 model-free 和 model-based 选择器，以及一个新的实验协议，该协议允许更稳定的候选价值函数生成、无需优化，并同时评估 model-free 和 model-based 方法。在 Gym-Hopper 环境中的实验表明，新的 model-free 选择器 LSTD-Tournament 展现出有前景的经验性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.08021v2",
      "published_date": "2025-02-11 23:40:55 UTC",
      "updated_date": "2025-05-16 02:18:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:51:24.286077"
    },
    {
      "arxiv_id": "2502.08020v2",
      "title": "Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyao Wang",
        "Muneeza Azmat",
        "Ang Li",
        "Raya Horesh",
        "Mikhail Yurochkin"
      ],
      "abstract": "Large Language Models (LLMs) often excel in specific domains but fall short\nin others due to the limitations of their training. Thus, enabling LLMs to\nsolve problems collaboratively by integrating their complementary knowledge\npromises to improve their performance across domains. To realize this\npotential, we introduce a novel Collaborative Speculative Decoding (CoSD)\nalgorithm that enables efficient LLM knowledge fusion at test time without\nrequiring additional model training. CoSD employs a draft model to generate\ninitial sequences and an easy-to-learn rule or decision tree to decide when to\ninvoke an assistant model to improve these drafts. CoSD not only enhances\nknowledge fusion but also improves inference efficiency, is transferable across\ndomains and models, and offers greater explainability. Experimental results\ndemonstrate that CoSD improves accuracy by up to 10\\% across benchmarks\ncompared to existing methods, providing a scalable and effective solution for\nLLM-based applications",
      "tldr_zh": "该论文提出了一种名为 Collaborative Speculative Decoding (CoSD) 的算法，旨在通过测试时融合大语言模型 (LLMs) 的互补知识，实现跨领域的性能提升，而无需额外训练。CoSD 利用一个草稿模型生成初始序列，并通过简单规则或决策树决定何时调用助手模型来优化这些序列，从而提升知识融合和推理效率。实验结果显示，CoSD 在多个基准上比现有方法提高准确率高达 10%，并提供更好的可转移性和可解释性，为 LLM 应用提供了可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.08020v2",
      "published_date": "2025-02-11 23:40:53 UTC",
      "updated_date": "2025-03-19 16:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:51:33.295952"
    },
    {
      "arxiv_id": "2502.08011v2",
      "title": "Training-Free Safe Denoisers for Safe Use of Diffusion Models",
      "title_zh": "无需训练的安全去噪器，用于扩散模型的安全使用",
      "authors": [
        "Mingyu Kim",
        "Dongjun Kim",
        "Amman Yusuf",
        "Stefano Ermon",
        "Mi Jung Park"
      ],
      "abstract": "There is growing concern over the safety of powerful diffusion models (DMs),\nas they are often misused to produce inappropriate, not-safe-for-work (NSFW)\ncontent or generate copyrighted material or data of individuals who wish to be\nforgotten. Many existing methods tackle these issues by heavily relying on\ntext-based negative prompts or extensively retraining DMs to eliminate certain\nfeatures or samples. In this paper, we take a radically different approach,\ndirectly modifying the sampling trajectory by leveraging a negation set (e.g.,\nunsafe images, copyrighted data, or datapoints needed to be excluded) to avoid\nspecific regions of data distribution, without needing to retrain or fine-tune\nDMs. We formally derive the relationship between the expected denoised samples\nthat are safe and those that are not safe, leading to our $\\textit{safe}$\ndenoiser which ensures its final samples are away from the area to be negated.\nInspired by the derivation, we develop a practical algorithm that successfully\nproduces high-quality samples while avoiding negation areas of the data\ndistribution in text-conditional, class-conditional, and unconditional image\ngeneration scenarios. These results hint at the great potential of our\ntraining-free safe denoiser for using DMs more safely.",
      "tldr_zh": "该研究针对扩散模型（DMs）的安全问题（如生成不安全内容、版权材料或需要排除的数据），提出了一种无需训练的 safe denoiser 方法。该方法通过利用否定集（negation set）直接修改采样轨迹，避免特定数据分布区域，而不需重训练或微调 DMs。作者形式化推导了安全与非安全样本之间的关系，开发出实用算法，可在文本条件、类条件和无条件图像生成场景中产生高质量样本，同时有效规避否定区域。该方法展示了在不安全区域中提升 DMs 使用安全性的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.08011v2",
      "published_date": "2025-02-11 23:14:39 UTC",
      "updated_date": "2025-02-13 02:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:51:46.446136"
    },
    {
      "arxiv_id": "2502.08006v2",
      "title": "Greed is Good: A Unifying Perspective on Guided Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zander W. Blasingame",
        "Chen Liu"
      ],
      "abstract": "Training-free guided generation is a widely used and powerful technique that\nallows the end user to exert further control over the generative process of\nflow/diffusion models. Generally speaking, two families of techniques have\nemerged for solving this problem for gradient-based guidance: namely, posterior\nguidance (i.e., guidance via projecting the current sample to the target\ndistribution via the target prediction model) and end-to-end guidance (i.e.,\nguidance by performing backpropagation throughout the entire ODE solve). In\nthis work, we show that these two seemingly separate families can actually be\nunified by looking at posterior guidance as a greedy strategy of end-to-end\nguidance. We explore the theoretical connections between these two families and\nprovide an in-depth theoretical of these two techniques relative to the\ncontinuous ideal gradients. Motivated by this analysis we then show a method\nfor interpolating between these two families enabling a trade-off between\ncompute and accuracy of the guidance gradients. We then validate this work on\nseveral inverse image problems and property-guided molecular generation.",
      "tldr_zh": "该论文提出了一种统一视角，将训练-free guided generation 中的两种技术——posterior guidance 和 end-to-end guidance——视为同一框架，其中 posterior guidance 可以作为 end-to-end guidance 的贪婪策略。通过理论分析，作者探讨了这些技术与理想连续梯度的关系，并开发了一种插值方法，以平衡计算资源和指导梯度的准确性。在逆图像问题和属性引导的分子生成任务上，实验验证了这一方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Revised preprint with numerical experiments",
      "pdf_url": "http://arxiv.org/pdf/2502.08006v2",
      "published_date": "2025-02-11 23:05:16 UTC",
      "updated_date": "2025-05-19 17:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:51:56.970930"
    },
    {
      "arxiv_id": "2502.07987v2",
      "title": "Universal Adversarial Attack on Aligned Multimodal LLMs",
      "title_zh": "针对已对齐多模态大型语言模型的通用对抗攻击",
      "authors": [
        "Temurbek Rahmatullaev",
        "Polina Druzhinina",
        "Matvey Mikhalchuk",
        "Andrey Kuznetsov",
        "Anton Razzhigaev"
      ],
      "abstract": "We propose a universal adversarial attack on multimodal Large Language Models\n(LLMs) that leverages a single optimized image to override alignment safeguards\nacross diverse queries and even multiple models. By backpropagating through the\nvision encoder and language head, we craft a synthetic image that forces the\nmodel to respond with a targeted phrase (e.g., ''Sure, here it is'') or\notherwise unsafe content-even for harmful prompts. In experiments on the\nSafeBench benchmark, our method achieves significantly higher attack success\nrates than existing baselines, including text-only universal prompts (e.g., up\nto 93% on certain models). We further demonstrate cross-model transferability\nby training on several multimodal LLMs simultaneously and testing on unseen\narchitectures. Additionally, a multi-answer variant of our approach produces\nmore natural-sounding (yet still malicious) responses. These findings\nunderscore critical vulnerabilities in current multimodal alignment and call\nfor more robust adversarial defenses. We will release code and datasets under\nthe Apache-2.0 license. Warning: some content generated by Multimodal LLMs in\nthis paper may be offensive to some readers.",
      "tldr_zh": "本文提出了一种针对对齐的多模态Large Language Models (LLMs)的通用对抗攻击方法，使用一个优化的合成图像来覆盖多种查询和模型的安全机制，通过在视觉编码器和语言头中反向传播实现。实验在SafeBench基准上显示，该方法比现有基线（如文本-only通用提示）显著提高攻击成功率（某些模型上高达93%），并证明了跨模型转移性和多答案变体的自然恶意响应。这些发现揭示了多模态LLM对齐的critical漏洞，并呼吁开发更robust的对抗防御。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Added an affiliation",
      "pdf_url": "http://arxiv.org/pdf/2502.07987v2",
      "published_date": "2025-02-11 22:07:47 UTC",
      "updated_date": "2025-02-13 06:40:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:52:10.679671"
    },
    {
      "arxiv_id": "2502.07985v2",
      "title": "MetaSC: Test-Time Safety Specification Optimization for Language Models",
      "title_zh": "MetaSC：针对语言模型的",
      "authors": [
        "Víctor Gallego"
      ],
      "abstract": "We propose a novel dynamic safety framework that optimizes language model\n(LM) safety reasoning at inference time without modifying model weights.\nBuilding on recent advances in self-critique methods, our approach leverages a\nmeta-critique mechanism that iteratively updates safety prompts-termed\nspecifications-to drive the critique and revision process adaptively. This\ntest-time optimization not only improves performance against adversarial\njailbreak requests but also in diverse general safety-related tasks, such as\navoiding moral harm or pursuing honest responses. Our empirical evaluations\nacross several language models demonstrate that dynamically optimized safety\nprompts yield significantly higher safety scores compared to fixed system\nprompts and static self-critique defenses. Code released at\nhttps://github.com/vicgalle/meta-self-critique.git .",
      "tldr_zh": "本研究提出MetaSC，一种动态安全框架，用于在测试时优化语言模型(LM)的安全推理，而不需修改模型权重。该框架通过元批评(meta-critique)机制迭代更新安全提示(specifications)，以适应性地驱动批评和修订过程，从而提升模型对对抗性越狱请求(adversarial jailbreak requests)的抵抗力，以及在避免道德伤害和追求诚实响应的通用安全任务中的性能。实证评估显示，与固定系统提示和静态自批评防御相比，动态优化的安全提示显著提高了安全分数，为语言模型的安全性增强提供了有效方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at ICLR 2025 Workshop on Foundation Models in the Wild",
      "pdf_url": "http://arxiv.org/pdf/2502.07985v2",
      "published_date": "2025-02-11 22:06:25 UTC",
      "updated_date": "2025-04-07 09:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:52:23.090933"
    },
    {
      "arxiv_id": "2502.07982v1",
      "title": "Deep Semantic Graph Learning via LLM based Node Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Chuanqi Shi",
        "Yiyi Tao",
        "Hang Zhang",
        "Lun Wang",
        "Shaoshuai Du",
        "Yixian Shen",
        "Yanxin Shen"
      ],
      "abstract": "Graph learning has attracted significant attention due to its widespread\nreal-world applications. Current mainstream approaches rely on text node\nfeatures and obtain initial node embeddings through shallow embedding learning\nusing GNNs, which shows limitations in capturing deep textual semantics. Recent\nadvances in Large Language Models (LLMs) have demonstrated superior\ncapabilities in understanding text semantics, transforming traditional text\nfeature processing. This paper proposes a novel framework that combines Graph\nTransformer architecture with LLM-enhanced node features. Specifically, we\nleverage LLMs to generate rich semantic representations of text nodes, which\nare then processed by a multi-head self-attention mechanism in the Graph\nTransformer to capture both local and global graph structural information. Our\nmodel utilizes the Transformer's attention mechanism to dynamically aggregate\nneighborhood information while preserving the semantic richness provided by LLM\nembeddings. Experimental results demonstrate that the LLM-enhanced node\nfeatures significantly improve the performance of graph learning models on node\nclassification tasks. This approach shows promising results across multiple\ngraph learning tasks, offering a practical direction for combining graph\nnetworks with language models.",
      "tldr_zh": "本文提出一种新的图学习框架，通过LLM（Large Language Models）增强节点特征来克服传统GNNs（Graph Neural Networks）在捕捉深层文本语义方面的局限性。具体方法利用LLMs生成丰富的节点语义表示，并结合Graph Transformer的多头自注意力机制动态聚合局部和全局图结构信息。实验结果显示，该框架在节点分类任务上显著提升了模型性能，并在多个图学习任务中表现出色，提供了一种实用方向来整合图网络和语言模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07982v1",
      "published_date": "2025-02-11 21:55:46 UTC",
      "updated_date": "2025-02-11 21:55:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:52:34.253768"
    },
    {
      "arxiv_id": "2502.07980v1",
      "title": "CIRCUIT: A Benchmark for Circuit Interpretation and Reasoning Capabilities of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lejla Skelic",
        "Yan Xu",
        "Matthew Cox",
        "Wenjie Lu",
        "Tao Yu",
        "Ruonan Han"
      ],
      "abstract": "The role of Large Language Models (LLMs) has not been extensively explored in\nanalog circuit design, which could benefit from a reasoning-based approach that\ntranscends traditional optimization techniques. In particular, despite their\ngrowing relevance, there are no benchmarks to assess LLMs' reasoning capability\nabout circuits. Therefore, we created the CIRCUIT dataset consisting of 510\nquestion-answer pairs spanning various levels of analog-circuit-related\nsubjects. The best-performing model on our dataset, GPT-4o, achieves 48.04%\naccuracy when evaluated on the final numerical answer. To evaluate the\nrobustness of LLMs on our dataset, we introduced a unique feature that enables\nunit-test-like evaluation by grouping questions into unit tests. In this case,\nGPT-4o can only pass 27.45% of the unit tests, highlighting that the most\nadvanced LLMs still struggle with understanding circuits, which requires\nmulti-level reasoning, particularly when involving circuit topologies. This\ncircuit-specific benchmark highlights LLMs' limitations, offering valuable\ninsights for advancing their application in analog integrated circuit design.",
      "tldr_zh": "本研究开发了 CIRCUIT 数据集，这是一个包含 510 个问答对的基准，用于评估大型语言模型(LLMs)在电路解释和推理能力方面的表现，特别是针对模拟电路主题。数据集引入了单位测试-like 评估方法，以测试模型的鲁棒性，结果显示 GPT-4o 在最终数值答案上达到 48.04% 的准确率，但仅通过 27.45% 的单位测试，突显了 LLMs 在处理涉及电路拓扑的多级推理时的局限性。该基准为推进 LLMs 在模拟集成电路设计中的应用提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07980v1",
      "published_date": "2025-02-11 21:53:48 UTC",
      "updated_date": "2025-02-11 21:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:52:46.655132"
    },
    {
      "arxiv_id": "2502.07974v1",
      "title": "From Hazard Identification to Controller Design: Proactive and LLM-Supported Safety Engineering for ML-Powered Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yining Hong",
        "Christopher S. Timperley",
        "Christian Kästner"
      ],
      "abstract": "Machine learning (ML) components are increasingly integrated into software\nproducts, yet their complexity and inherent uncertainty often lead to\nunintended and hazardous consequences, both for individuals and society at\nlarge. Despite these risks, practitioners seldom adopt proactive approaches to\nanticipate and mitigate hazards before they occur. Traditional safety\nengineering approaches, such as Failure Mode and Effects Analysis (FMEA) and\nSystem Theoretic Process Analysis (STPA), offer systematic frameworks for early\nrisk identification but are rarely adopted. This position paper advocates for\nintegrating hazard analysis into the development of any ML-powered software\nproduct and calls for greater support to make this process accessible to\ndevelopers. By using large language models (LLMs) to partially automate a\nmodified STPA process with human oversight at critical steps, we expect to\naddress two key challenges: the heavy dependency on highly experienced safety\nengineering experts, and the time-consuming, labor-intensive nature of\ntraditional hazard analysis, which often impedes its integration into\nreal-world development workflows. We illustrate our approach with a running\nexample, demonstrating that many seemingly unanticipated issues can, in fact,\nbe anticipated.",
      "tldr_zh": "这篇论文讨论了机器学习(ML)系统在软件产品中的应用可能带来的意外危险，并主张在开发过程中主动整合危险分析，如Failure Mode and Effects Analysis (FMEA)和System Theoretic Process Analysis (STPA)。为了解决传统方法依赖专家和耗时的挑战，作者提出使用大型语言模型(LLM)部分自动化修改后的STPA过程，并在关键步骤中加入人为监督，以提高可访问性和效率。论文通过一个示例演示，这种方法能预见许多看似意外的问题，从而为ML驱动系统的安全工程提供更实用的框架。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the International Conference on AI\n  Engineering (CAIN) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07974v1",
      "published_date": "2025-02-11 21:37:19 UTC",
      "updated_date": "2025-02-11 21:37:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:52:58.360774"
    },
    {
      "arxiv_id": "2502.07972v3",
      "title": "Training Sparse Mixture Of Experts Text Embedding Models",
      "title_zh": "训练稀疏混合专家文本嵌入模型",
      "authors": [
        "Zach Nussbaum",
        "Brandon Duderstadt"
      ],
      "abstract": "Transformer-based text embedding models have improved their performance on\nbenchmarks like MIRACL and BEIR by increasing their parameter counts. However,\nthis scaling approach introduces significant deployment challenges, including\nincreased inference latency and memory usage. These challenges are particularly\nsevere in retrieval-augmented generation (RAG) applications, where large\nmodels' increased memory requirements constrain dataset ingestion capacity, and\ntheir higher latency directly impacts query-time performance. While causal\nlanguage models have addressed similar efficiency challenges using Mixture of\nExperts (MoE) architectures, this approach hasn't been successfully adapted to\nthe general text embedding setting. In this paper, we introduce Nomic Embed v2,\nthe first general purpose MoE text embedding model. Our model outperforms\nmodels in the same parameter class on both monolingual and multilingual\nbenchmarks while also maintaining competitive performance with models twice its\nsize. We open-source all code, models, and evaluation data to ensure full\nreproducibility of our training pipeline at\n\\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}.",
      "tldr_zh": "本文研究了如何通过训练稀疏 Mixture of Experts (MoE) 架构来提升 Transformer-based text embedding models 的效率，以解决模型参数增加导致的推理延迟和内存使用问题，尤其在 RAG（检索增强生成）应用中的挑战。作者引入了 Nomic Embed v2，这是首个通用 MoE 文本嵌入模型，能够在相同参数级别上超越同类模型，并在 monolingual 和 multilingual benchmarks 如 MIRACL 和 BEIR 上与规模两倍的模型保持竞争性能。实验证明了该模型的优越性，并开源了所有代码、模型和评估数据，以确保训练管道的完全可复现性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07972v3",
      "published_date": "2025-02-11 21:36:31 UTC",
      "updated_date": "2025-03-09 19:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:53:11.471649"
    },
    {
      "arxiv_id": "2502.07971v1",
      "title": "ReTreever: Tree-based Coarse-to-Fine Representations for Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Gupta",
        "Zichao Li",
        "Tianyi Chen",
        "Cem Subakan",
        "Siva Reddy",
        "Perouz Taslakian",
        "Valentina Zantedeschi"
      ],
      "abstract": "Document retrieval is a core component of question-answering systems, as it\nenables conditioning answer generation on new and large-scale corpora. While\neffective, the standard practice of encoding documents into high-dimensional\nembeddings for similarity search entails large memory and compute footprints,\nand also makes it hard to inspect the inner workings of the system. In this\npaper, we propose a tree-based method for organizing and representing reference\ndocuments at various granular levels, which offers the flexibility to balance\ncost and utility, and eases the inspection of the corpus content and retrieval\noperations. Our method, called ReTreever, jointly learns a routing function per\ninternal node of a binary tree such that query and reference documents are\nassigned to similar tree branches, hence directly optimizing for retrieval\nperformance. Our evaluations show that ReTreever generally preserves full\nrepresentation accuracy. Its hierarchical structure further provides strong\ncoarse representations and enhances transparency by indirectly learning\nmeaningful semantic groupings. Among hierarchical retrieval methods, ReTreever\nachieves the best retrieval accuracy at the lowest latency, proving that this\nfamily of techniques can be viable in practical applications.",
      "tldr_zh": "本研究提出ReTreever，一种基于树的粗到细表示方法，用于优化文档检索系统，以解决传统高维嵌入方法在内存计算开销和系统透明度方面的不足。ReTreever在二叉树结构中联合学习每个内部节点的路由函数，使查询和参考文档分配到相似的树分支，从而直接提升检索性能。实验结果显示，该方法基本保留了完整表示的准确性，同时通过层次结构提供强大的粗粒度表示和语义分组，提升了系统透明度。在层次检索方法中，ReTreever实现了最佳的检索准确率和最低延迟，证明其在实际应用中的可行性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "I.2; I.7; E.2; H.3"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07971v1",
      "published_date": "2025-02-11 21:35:13 UTC",
      "updated_date": "2025-02-11 21:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:53:22.726859"
    },
    {
      "arxiv_id": "2502.07968v1",
      "title": "Generative Risk Minimization for Out-of-Distribution Generalization on Graphs",
      "title_zh": "生成式风险最小化用于图上的分布外泛化",
      "authors": [
        "Song Wang",
        "Zhen Tan",
        "Yaochen Zhu",
        "Chuxu Zhang",
        "Jundong Li"
      ],
      "abstract": "Out-of-distribution (OOD) generalization on graphs aims at dealing with\nscenarios where the test graph distribution differs from the training graph\ndistributions. Compared to i.i.d. data like images, the OOD generalization\nproblem on graph-structured data remains challenging due to the non-i.i.d.\nproperty and complex structural information on graphs. Recently, several works\non graph OOD generalization have explored extracting invariant subgraphs that\nshare crucial classification information across different distributions.\nNevertheless, such a strategy could be suboptimal for entirely capturing the\ninvariant information, as the extraction of discrete structures could\npotentially lead to the loss of invariant information or the involvement of\nspurious information. In this paper, we propose an innovative framework, named\nGenerative Risk Minimization (GRM), designed to generate an invariant subgraph\nfor each input graph to be classified, instead of extraction. To address the\nchallenge of optimization in the absence of optimal invariant subgraphs (i.e.,\nground truths), we derive a tractable form of the proposed GRM objective by\nintroducing a latent causal variable, and its effectiveness is validated by our\ntheoretical analysis. We further conduct extensive experiments across a variety\nof real-world graph datasets for both node-level and graph-level OOD\ngeneralization, and the results demonstrate the superiority of our framework\nGRM.",
      "tldr_zh": "该论文针对图结构数据的 Out-of-Distribution (OOD) 泛化问题，提出了一种创新框架 Generative Risk Minimization (GRM)，通过生成不变子图来处理测试分布与训练分布不同的场景，从而避免传统提取方法可能导致的信息丢失或引入无关信息。GRM 框架引入潜在因果变量来优化目标函数，并通过理论分析证明其有效性。实验结果显示，在多种真实世界数据集上的节点级和图级 OOD 泛化任务中，GRM 框架表现出优越性能，超越了现有基准方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "TMLR 02/2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07968v1",
      "published_date": "2025-02-11 21:24:13 UTC",
      "updated_date": "2025-02-11 21:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:53:34.491438"
    },
    {
      "arxiv_id": "2502.07963v3",
      "title": "Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?",
      "title_zh": "翻译失败",
      "authors": [
        "Hye Sun Yun",
        "Karen Y. C. Zhang",
        "Ramez Kouzy",
        "Iain J. Marshall",
        "Junyi Jessy Li",
        "Byron C. Wallace"
      ],
      "abstract": "Medical research faces well-documented challenges in translating novel\ntreatments into clinical practice. Publishing incentives encourage researchers\nto present \"positive\" findings, even when empirical results are equivocal.\nConsequently, it is well-documented that authors often spin study results,\nespecially in article abstracts. Such spin can influence clinician\ninterpretation of evidence and may affect patient care decisions. In this\nstudy, we ask whether the interpretation of trial results offered by Large\nLanguage Models (LLMs) is similarly affected by spin. This is important since\nLLMs are increasingly being used to trawl through and synthesize published\nmedical evidence. We evaluated 22 LLMs and found that they are across the board\nmore susceptible to spin than humans. They might also propagate spin into their\noutputs: We find evidence, e.g., that LLMs implicitly incorporate spin into\nplain language summaries that they generate. We also find, however, that LLMs\nare generally capable of recognizing spin, and can be prompted in a way to\nmitigate spin's impact on LLM outputs.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否像人类一样容易受医疗文献中“spin”（结果扭曲）的误导，因为spin可能影响临床决策和患者护理。研究评估了22个LLMs，发现这些模型整体上比人类更易受spin影响，并可能在生成的纯文本摘要中传播spin。另一方面，LLMs能够识别spin，并通过适当的提示来减轻其对输出结果的影响，这为改进LLMs在医疗证据合成中的应用提供了潜在策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 12 figures, 4 tables, CHIL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07963v3",
      "published_date": "2025-02-11 21:21:05 UTC",
      "updated_date": "2025-05-05 20:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:53:47.821134"
    },
    {
      "arxiv_id": "2502.07957v1",
      "title": "Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Kshitish Ghate",
        "Isaac Slaughter",
        "Kyra Wilson",
        "Mona Diab",
        "Aylin Caliskan"
      ],
      "abstract": "While recent work has found that vision-language models trained under the\nContrastive Language Image Pre-training (CLIP) framework contain intrinsic\nsocial biases, the extent to which different upstream pre-training features of\nthe framework relate to these biases, and hence how intrinsic bias and\ndownstream performance are connected has been unclear. In this work, we present\nthe largest comprehensive analysis to-date of how the upstream pre-training\nfactors and downstream performance of CLIP models relate to their intrinsic\nbiases. Studying 131 unique CLIP models, trained on 26 datasets, using 55\narchitectures, and in a variety of sizes, we evaluate bias in each model using\n26 well-established unimodal and cross-modal principled Embedding Association\nTests. We find that the choice of pre-training dataset is the most significant\nupstream predictor of bias, whereas architectural variations have minimal\nimpact. Additionally, datasets curated using sophisticated filtering techniques\naimed at enhancing downstream model performance tend to be associated with\nhigher levels of intrinsic bias. Finally, we observe that intrinsic bias is\noften significantly correlated with downstream performance ($0.3 \\leq r \\leq\n0.8$), suggesting that models optimized for performance inadvertently learn to\namplify representational biases. Comparisons between unimodal and cross-modal\nassociation tests reveal that social group bias depends heavily on the\nmodality. Our findings imply that more sophisticated strategies are needed to\naddress intrinsic model bias for vision-language models across the entire model\ndevelopment pipeline.",
      "tldr_zh": "本研究分析了在 CLIP 框架下训练的视觉语言模型中的内在社会偏见，评估了上游预训练因素（如数据集和架构）与偏见的关系，以及偏见与下游性能的关联。研究涉及 131 个独特 CLIP 模型，使用 26 个数据集和 55 个架构，通过 26 个单模态和跨模态 Embedding Association Tests 进行评估。结果显示，预训练数据集的选择是偏见的最重要预测因素，而架构变化的影响最小；使用复杂过滤技术的数据集往往与更高偏见相关，且内在偏见与下游性能显著正相关（相关系数 0.3 到 0.8）。这些发现表明，优化模型性能可能无意中放大偏见，因此需要更先进的策略在整个模型开发流程中处理视觉语言模型的内在偏见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NAACL Main, 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07957v1",
      "published_date": "2025-02-11 21:11:47 UTC",
      "updated_date": "2025-02-11 21:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:54:00.044617"
    },
    {
      "arxiv_id": "2502.07949v2",
      "title": "Advancing Autonomous VLM Agents via Variational Subgoal-Conditioned Reinforcement Learning",
      "title_zh": "通过变分子目标条件化强化学习推进自治 VLM 代理",
      "authors": [
        "Qingyuan Wu",
        "Jianheng Liu",
        "Jianye Hao",
        "Jun Wang",
        "Kun Shao"
      ],
      "abstract": "State-of-the-art (SOTA) reinforcement learning (RL) methods have enabled\nvision-language model (VLM) agents to learn from interaction with online\nenvironments without human supervision. However, these methods often struggle\nwith learning inefficiencies when applied to complex, real-world\ndecision-making tasks with sparse rewards and long-horizon dependencies. We\npropose a novel framework, Variational Subgoal-Conditioned Reinforcement\nLearning (VSC-RL), advancing the VLM agents in resolving challenging\ndecision-making tasks. Fundamentally distinct from existing methods, VSC-RL\nreformulates the decision-making problem as a variational subgoal-conditioned\nRL problem with the newly derived optimization objective, Subgoal Evidence\nLower BOund (SGC-ELBO), which comprises two key components: (a) maximizing the\nsubgoal-conditioned return, and (b) minimizing the divergence from a reference\ngoal-conditioned policy. We theoretically and empirically demonstrate that the\nVSC-RL can efficiently improve the learning efficiency without compromising\nperformance guarantees. Across a diverse set of challenging benchmarks,\nincluding mobile device and web control tasks, VSC-RL consistently outperforms\nexisting SOTA methods, achieving superior learning efficiency and performance.",
      "tldr_zh": "该研究针对现有强化学习（RL）方法在处理复杂决策任务时的学习效率问题，提出了一种新型框架 Variational Subgoal-Conditioned Reinforcement Learning (VSC-RL)，以提升视觉语言模型（VLM）代理的自主学习能力。VSC-RL 通过将决策问题转化为变分子目标条件 RL 问题，并引入 Subgoal Evidence Lower Bound (SGC-ELBO) 优化目标，包括最大化子目标条件回报和最小化与参考目标条件策略的差异，从而显著提高学习效率，同时保持性能保障。在多个基准测试中，如移动设备和网页控制任务，VSC-RL 超过了现有最先进方法，展现出卓越的学习效率和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07949v2",
      "published_date": "2025-02-11 20:57:46 UTC",
      "updated_date": "2025-05-20 19:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:54:10.912637"
    },
    {
      "arxiv_id": "2502.07944v1",
      "title": "SHACL-SKOS Based Knowledge Representation of Material Safety Data Sheet (SDS) for the Pharmaceutical Industry",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Lu",
        "Dennis Pham",
        "Ti-Chiun Chang",
        "Michael Lovette",
        "Terri Bui",
        "Stephen Ma"
      ],
      "abstract": "We report the development of a knowledge representation and reasoning (KRR)\nsystem built on hybrid SHACL-SKOS ontologies for globally harmonized system\n(GHS) material Safety Data Sheets (SDS) to enhance chemical safety\ncommunication and regulatory compliance. SDS are comprehensive documents\ncontaining safety and handling information for chemical substances. Thus, they\nare an essential part of workplace safety and risk management. However, the\nvast number of Safety Data Sheets from multiple organizations, manufacturers,\nand suppliers that produce and distribute chemicals makes it challenging to\ncentralize and access SDS documents through a single repository. To accomplish\nthe underlying issues of data exchange related to chemical shipping and\nhandling, we construct SDS related controlled vocabulary and conditions\nvalidated by SHACL, and knowledge systems of similar domains linked via SKOS.\nThe resulting hybrid ontologies aim to provide standardized yet adaptable\nrepresentations of SDS information, facilitating better data sharing,\nretrieval, and integration across various platforms. This paper outlines our\nSHACL-SKOS system architectural design and showcases our implementation for an\nindustrial application streamlining the generation of a composite shipping\ncover sheet.",
      "tldr_zh": "本文开发了一个基于 SHACL-SKOS 混合本体的知识表示和推理 (KRR) 系统，针对全球统一制度 (GHS) 的材料安全数据表 (SDS)，以改善制药行业的化学品安全通信和监管合规。系统通过构建 SDS 相关的受控词汇和 SHACL 验证条件，并利用 SKOS 链接类似领域的知识系统，实现标准化且可适应的 SDS 信息表示，便于数据共享、检索和集成。实验结果展示了该系统的架构设计及其在工业应用中的实际实现，例如简化复合运输封面的生成，从而解决了 SDS 集中管理和访问的挑战。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 10 figures, IEEE ICSC",
      "pdf_url": "http://arxiv.org/pdf/2502.07944v1",
      "published_date": "2025-02-11 20:44:45 UTC",
      "updated_date": "2025-02-11 20:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:54:23.737152"
    },
    {
      "arxiv_id": "2502.07943v1",
      "title": "CREDAL: Close Reading of Data Models",
      "title_zh": "CREDAL：数据模型的细读",
      "authors": [
        "George Fletcher",
        "Olha Nahurna",
        "Matvii Prytula",
        "Julia Stoyanovich"
      ],
      "abstract": "Data models are necessary for the birth of data and of any data-driven\nsystem. Indeed, every algorithm, every machine learning model, every\nstatistical model, and every database has an underlying data model without\nwhich the system would not be usable. Hence, data models are excellent sites\nfor interrogating the (material, social, political, ...) conditions giving rise\nto a data system. Towards this, drawing inspiration from literary criticism, we\npropose to closely read data models in the same spirit as we closely read\nliterary artifacts. Close readings of data models reconnect us with, among\nother things, the materiality, the genealogies, the techne, the closed nature,\nand the design of technical systems.\n  While recognizing from literary theory that there is no one correct way to\nread, it is nonetheless critical to have systematic guidance for those\nunfamiliar with close readings. This is especially true for those trained in\nthe computing and data sciences, who too often are enculturated to set aside\nthe socio-political aspects of data work. A systematic methodology for reading\ndata models currently does not exist. To fill this gap, we present the CREDAL\nmethodology for close readings of data models. We detail our iterative\ndevelopment process and present results of a qualitative evaluation of CREDAL\ndemonstrating its usability, usefulness, and effectiveness in the critical\nstudy of data.",
      "tldr_zh": "本文提出 CREDAL 方法论，借鉴文学批评的“close reading”理念，对数据模型进行系统化审视，以揭示其物质、社会和政治条件。CREDAL 旨在帮助计算和数据科学从业者重新连接数据模型的家谱、技术和设计特征，通过迭代开发过程并进行定性评估，证明了其在批判性数据研究中的可用性、实用性和有效性。该方法填补了缺乏系统指导的空白，促进对数据系统的更全面理解。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07943v1",
      "published_date": "2025-02-11 20:42:56 UTC",
      "updated_date": "2025-02-11 20:42:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:54:34.470912"
    },
    {
      "arxiv_id": "2502.07931v1",
      "title": "Educating a Responsible AI Workforce: Piloting a Curricular Module on AI Policy in a Graduate Machine Learning Course",
      "title_zh": "翻译失败",
      "authors": [
        "James Weichert",
        "Hoda Eldardiry"
      ],
      "abstract": "As artificial intelligence (AI) technologies begin to permeate diverse\nfields-from healthcare to education-consumers, researchers and policymakers are\nincreasingly raising concerns about whether and how AI is regulated. It is\ntherefore reasonable to anticipate that alignment with principles of 'ethical'\nor 'responsible' AI, as well as compliance with law and policy, will form an\nincreasingly important part of AI development. Yet, for the most part, the\nconventional computer science curriculum is ill-equipped to prepare students\nfor these challenges. To this end, we seek to explore how new educational\ncontent related to AI ethics and AI policy can be integrated into both ethics-\nand technical-focused courses. This paper describes a two-lecture 'AI policy\nmodule' that was piloted in a graduate-level introductory machine learning\ncourse in 2024. The module, which includes an in-class active learning game, is\nevaluated using data from student surveys before and after the lectures, and\npedagogical motivations and considerations are discussed. We find that the\nmodule is successful in engaging otherwise technically-oriented students on the\ntopic of AI policy, increasing student awareness of the social impacts of a\nvariety of AI technologies and developing student interest in the field of AI\nregulation.",
      "tldr_zh": "该研究探讨了在人工智能（AI）技术广泛应用背景下，如何通过教育增强 AI 工作者的责任感，特别针对传统计算机科学课程的不足。研究者设计并在 2024 年研究生级入门机器学习课程中试点了一个两讲座模块，包括课堂互动游戏（active learning game），以整合 AI 伦理和 AI policy 相关内容。通过前后学生调查评估，该模块成功提升了技术导向学生的参与度，提高了他们对 AI 技术社会影响的认识，并激发了他们对 AI 法规领域的兴趣。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at 2025 ASEE Annual Conference & Exposition",
      "pdf_url": "http://arxiv.org/pdf/2502.07931v1",
      "published_date": "2025-02-11 20:16:56 UTC",
      "updated_date": "2025-02-11 20:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:54:46.181661"
    },
    {
      "arxiv_id": "2502.10450v1",
      "title": "Trustworthy AI on Safety, Bias, and Privacy: A Survey",
      "title_zh": "安全、偏差和",
      "authors": [
        "Xingli Fang",
        "Jianwei Li",
        "Varun Mulchandani",
        "Jung-Eun Kim"
      ],
      "abstract": "The capabilities of artificial intelligence systems have been advancing to a\ngreat extent, but these systems still struggle with failure modes,\nvulnerabilities, and biases. In this paper, we study the current state of the\nfield, and present promising insights and perspectives regarding concerns that\nchallenge the trustworthiness of AI models. In particular, this paper\ninvestigates the issues regarding three thrusts: safety, privacy, and bias,\nwhich hurt models' trustworthiness. For safety, we discuss safety alignment in\nthe context of large language models, preventing them from generating toxic or\nharmful content. For bias, we focus on spurious biases that can mislead a\nnetwork. Lastly, for privacy, we cover membership inference attacks in deep\nneural networks. The discussions addressed in this paper reflect our own\nexperiments and observations.",
      "tldr_zh": "这篇调查论文探讨了人工智能（AI）模型的可信度问题，重点分析安全、偏见和隐私三大方面的挑战和当前进展。对于安全，论文讨论了大型语言模型（Large Language Models, LLMs）的安全对齐技术，以防止生成有害内容；对于偏见，焦点在于虚假偏见（Spurious Biases）如何误导网络；对于隐私，则涵盖了成员推理攻击（Membership Inference Attacks）在深度神经网络中的风险。基于作者的实验和观察，该论文提供了宝贵的见解和视角，以提升Trustworthy AI的可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10450v1",
      "published_date": "2025-02-11 20:08:42 UTC",
      "updated_date": "2025-02-11 20:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:54:58.575576"
    },
    {
      "arxiv_id": "2503.01733v1",
      "title": "DISCOVER: Data-driven Identification of Sub-activities via Clustering and Visualization for Enhanced Activity Recognition in Smart Homes",
      "title_zh": "DISC",
      "authors": [
        "Alexander Karpekov",
        "Sonia Chernova",
        "Thomas Plötz"
      ],
      "abstract": "Human Activity Recognition (HAR) using ambient sensors has great potential\nfor practical applications, particularly in elder care and independent living.\nHowever, deploying HAR systems in real-world settings remains challenging due\nto the high cost of labeled data, the need for pre-segmented sensor streams,\nand the lack of flexibility in activity granularity. To address these\nlimitations, we introduce DISCOVER, a method designed to discover fine-grained\nhuman sub-activities from unlabeled sensor data without relying on\npre-segmentation. DISCOVER combines unsupervised feature extraction and\nclustering with a user-friendly visualization tool to streamline the labeling\nprocess. DISCOVER enables domain experts to efficiently annotate only a minimal\nset of representative cluster centroids, reducing the annotation workload to a\nsmall number of samples (0.05% of our dataset). We demonstrate DISCOVER's\neffectiveness through a re-annotation exercise on widely used HAR datasets,\nshowing that it uncovers finer-grained activities and produces more nuanced\nannotations than traditional coarse labels. DISCOVER represents a step toward\npractical, deployable HAR systems that adapt to diverse real environments.",
      "tldr_zh": "该论文针对智能家居中 Human Activity Recognition (HAR) 的挑战，如标注数据成本高和活动粒度缺乏灵活性，提出 DISCOVER 方法。该方法通过无监督特征提取和聚类，从未标注的传感器数据中自动识别细粒度的人类子活动，并结合用户友好的可视化工具，仅需标注少量代表性聚类中心（占数据集的 0.05%），大幅减少标注工作量。在现有 HAR 数据集上的实验证明，DISCOVER 能发现更细致的活动标注，提升系统的适应性和实用性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "v1: Initial submission. Under review at IMWUT",
      "pdf_url": "http://arxiv.org/pdf/2503.01733v1",
      "published_date": "2025-02-11 20:02:24 UTC",
      "updated_date": "2025-02-11 20:02:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:55:12.015631"
    },
    {
      "arxiv_id": "2502.07924v1",
      "title": "NDAI Agreements",
      "title_zh": "NDAI 协议",
      "authors": [
        "Matthew Stephenson",
        "Andrew Miller",
        "Xyn Sun",
        "Bhargav Annem",
        "Rohan Parikh"
      ],
      "abstract": "We study a fundamental challenge in the economics of innovation: an inventor\nmust reveal details of a new idea to secure compensation or funding, yet such\ndisclosure risks expropriation. We present a model in which a seller (inventor)\nand buyer (investor) bargain over an information good under the threat of\nhold-up. In the classical setting, the seller withholds disclosure to avoid\nmisappropriation, leading to inefficiency. We show that trusted execution\nenvironments (TEEs) combined with AI agents can mitigate and even fully\neliminate this hold-up problem. By delegating the disclosure and payment\ndecisions to tamper-proof programs, the seller can safely reveal the invention\nwithout risking expropriation, achieving full disclosure and an efficient ex\npost transfer. Moreover, even if the invention's value exceeds a threshold that\nTEEs can fully secure, partial disclosure still improves outcomes compared to\nno disclosure. Recognizing that real AI agents are imperfect, we model \"agent\nerrors\" in payments or disclosures and demonstrate that budget caps and\nacceptance thresholds suffice to preserve most of the efficiency gains.\n  Our results imply that cryptographic or hardware-based solutions can function\nas an \"ironclad NDA,\" substantially mitigating the fundamental\ndisclosure-appropriation paradox first identified by Arrow (1962) and Nelson\n(1959). This has far-reaching policy implications for fostering R&D, technology\ntransfer, and collaboration.",
      "tldr_zh": "本研究探讨了创新经济学中的核心挑战：发明者需揭示新想法以获取补偿或资金，但此举可能导致被盗用（hold-up problem），从而造成低效率。作者提出一种模型，利用受信任执行环境（TEEs）和 AI agents 来缓解这一问题，通过将披露和支付决策委托给防篡改程序，实现安全的完全披露和高效转移。即使发明的价值超出 TEEs 的完全保护阈值，部分披露也能改善结果，且通过预算上限和接受阈值，AI agents 的错误（如支付或披露错误）不会显著削弱效率收益。该框架可视为“ironclad NDA”，缓解 Arrow (1962) 和 Nelson (1959) 所指出的披露-盗用悖论，对促进 R&D、技术转移和合作具有重要政策影响。",
      "categories": [
        "econ.TH",
        "cs.AI"
      ],
      "primary_category": "econ.TH",
      "comment": "21 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2502.07924v1",
      "published_date": "2025-02-11 19:56:26 UTC",
      "updated_date": "2025-02-11 19:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:55:24.616988"
    },
    {
      "arxiv_id": "2502.07771v1",
      "title": "Breaking Down Bias: On The Limits of Generalizable Pruning Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Sibo Ma",
        "Alejandro Salinas",
        "Peter Henderson",
        "Julian Nyarko"
      ],
      "abstract": "We employ model pruning to examine how LLMs conceptualize racial biases, and\nwhether a generalizable mitigation strategy for such biases appears feasible.\nOur analysis yields several novel insights. We find that pruning can be an\neffective method to reduce bias without significantly increasing anomalous\nmodel behavior. Neuron-based pruning strategies generally yield better results\nthan approaches pruning entire attention heads. However, our results also show\nthat the effectiveness of either approach quickly deteriorates as pruning\nstrategies become more generalized. For instance, a model that is trained on\nremoving racial biases in the context of financial decision-making poorly\ngeneralizes to biases in commercial transactions. Overall, our analysis\nsuggests that racial biases are only partially represented as a general concept\nwithin language models. The other part of these biases is highly\ncontext-specific, suggesting that generalizable mitigation strategies may be of\nlimited effectiveness. Our findings have important implications for legal\nframeworks surrounding AI. In particular, they suggest that an effective\nmitigation strategy should include the allocation of legal responsibility on\nthose that deploy models in a specific use case.",
      "tldr_zh": "本研究通过模型修剪（model pruning）来探讨大型语言模型（LLMs）如何处理种族偏见，并评估可泛化缓解策略的可行性。结果显示，基于神经元的修剪策略比修剪整个注意力头（attention heads）更有效，能够减少偏见而不显著增加模型异常行为；然而，随着策略的泛化，其效果迅速下降，例如针对金融决策的偏见修剪在商业交易中泛化较差。总体而言，种族偏见在LLMs中部分是通用概念，部分高度上下文特定，这表明可泛化缓解策略的效力有限，并建议AI法律框架应将责任分配给特定用例的部署者。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 9 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2502.07771v1",
      "published_date": "2025-02-11 18:55:57 UTC",
      "updated_date": "2025-02-11 18:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:55:35.305132"
    },
    {
      "arxiv_id": "2502.07764v1",
      "title": "Polynomial-Time Approximability of Constrained Reinforcement Learning",
      "title_zh": "约束强化学习的多项式时间逼近可计算性",
      "authors": [
        "Jeremy McMahan"
      ],
      "abstract": "We study the computational complexity of approximating general constrained\nMarkov decision processes. Our primary contribution is the design of a\npolynomial time $(0,\\epsilon)$-additive bicriteria approximation algorithm for\nfinding optimal constrained policies across a broad class of recursively\ncomputable constraints, including almost-sure, chance, expectation, and their\nanytime variants. Matching lower bounds imply our approximation guarantees are\noptimal so long as $P \\neq NP$. The generality of our approach results in\nanswers to several long-standing open complexity questions in the constrained\nreinforcement learning literature. Specifically, we are the first to prove\npolynomial-time approximability for the following settings: policies under\nchance constraints, deterministic policies under multiple expectation\nconstraints, policies under non-homogeneous constraints (i.e., constraints of\ndifferent types), and policies under constraints for continuous-state\nprocesses.",
      "tldr_zh": "这篇论文研究了受限马尔可夫决策过程（Constrained Markov Decision Processes）的计算复杂性，提出了一种多项式时间的 (0, ε)-additive bicriteria approximation algorithm，用于在 almost-sure、chance、expectation 及其 anytime 变体等递归可计算约束下找到最优策略。算法的近似保证被证明是最优的，除非 P ≠ NP，这填补了受限强化学习领域的多项空白，包括首次证明了 chance 约束下的策略、多个 expectation 约束下的确定性策略、不同类型约束下的策略以及连续状态过程的约束均可多项式时间近似。总的来说，该工作为复杂约束下的强化学习提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07764v1",
      "published_date": "2025-02-11 18:47:53 UTC",
      "updated_date": "2025-02-11 18:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:55:48.667036"
    },
    {
      "arxiv_id": "2502.08666v2",
      "title": "Hallucination, Monofacts, and Miscalibration: An Empirical Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Miranda Muqing Miao",
        "Michael Kearns"
      ],
      "abstract": "Hallucinated facts in large language models (LLMs) have recently been shown\nto obey a statistical lower bound determined by the monofact rate (related to\nthe classical Good-Turing missing mass estimator) minus model miscalibration\n(Kalai & Vempala, 2024). We present the first empirical investigation of this\nthree-way relationship in classical n-gram models and fine-tuned\nencoder-decoder Transformers. By generating training data from Pareto\ndistributions with varying shape parameters, we systematically control the\nmonofact rates and establish its positive relationship with hallucination. To\nbridge theory and practice, we derive an empirical analog of the hallucination\nbound by replacing the population miscalibration term (Section 2.1) with an\nempirical bin-wise KL divergence and confirm its practical viability. We then\nintroduce selective upweighting -- a simple yet effective technique that\nstrategically repeats as little as 5% of training examples -- to deliberately\ninject miscalibration into the model. This intervention reduces hallucination\nby up to 40%, challenging universal deduplication policies. Our experiments\nreveal a critical trade-off: selective upweighting maintains pre-injection\nlevels of accuracy while substantially reducing hallucination, whereas standard\ntraining gradually improves accuracy but fails to address persistently high\nhallucination, indicating an inherent tension in optimization objectives.",
      "tldr_zh": "本研究通过实证调查，探讨了大型语言模型（LLMs）中的 hallucination 与 monofacts rate 及 miscalibration 的关系，发现 monofacts rate 与 hallucination 正相关，并使用 Pareto 分布生成训练数据进行系统控制。研究者推导了经验 hallucination 边界，通过替换 miscalibration 项为 bin-wise KL divergence，验证其实际可行性。引入 selective upweighting 技术，仅重复 5% 训练示例即可减少 hallucination 多达 40%，同时维持准确性水平，但实验揭示了优化准确性和减少 hallucination 之间的 inherent tension。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code available at https://github.com/mmiao2/Hallucination.git",
      "pdf_url": "http://arxiv.org/pdf/2502.08666v2",
      "published_date": "2025-02-11 18:46:00 UTC",
      "updated_date": "2025-05-15 19:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:56:02.084867"
    },
    {
      "arxiv_id": "2502.07755v1",
      "title": "An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating",
      "title_zh": "一个先进的自然语言处理框架，用于自动化医疗诊断，结合 DeBERTa 和动态上下文位置门控",
      "authors": [
        "Mohammad Ali Labbaf Khaniki",
        "Sahabeh Saadati",
        "Mohammad Manthouri"
      ],
      "abstract": "This paper presents a novel Natural Language Processing (NLP) framework for\nenhancing medical diagnosis through the integration of advanced techniques in\ndata augmentation, feature extraction, and classification. The proposed\napproach employs back-translation to generate diverse paraphrased datasets,\nimproving robustness and mitigating overfitting in classification tasks.\nLeveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with\nDynamic Contextual Positional Gating (DCPG), the model captures fine-grained\ncontextual and positional relationships, dynamically adjusting the influence of\npositional information based on semantic context to produce high-quality text\nembeddings. For classification, an Attention-Based Feedforward Neural Network\n(ABFNN) is utilized, effectively focusing on the most relevant features to\nimprove decision-making accuracy. Applied to the classification of symptoms,\nclinical notes, and other medical texts, this architecture demonstrates its\nability to address the complexities of medical data. The combination of data\naugmentation, contextual embedding generation, and advanced classification\nmechanisms offers a robust and accurate diagnostic tool, with potential\napplications in automated medical diagnosis and clinical decision support. This\nmethod demonstrates the effectiveness of the proposed NLP framework for medical\ndiagnosis, achieving remarkable results with an accuracy of 99.78%, recall of\n99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only\nunderscore the model's robust performance in classifying medical texts with\nexceptional precision and reliability but also highlight its superiority over\nexisting methods, making it a highly promising tool for automated diagnostic\nsystems.",
      "tldr_zh": "本文提出一个先进的 NLP 框架，利用 back-translation 生成多样化数据集，以提升医疗文本分类的鲁棒性和减少过拟合。框架结合 DeBERTa 和 Dynamic Contextual Positional Gating (DCPG) 来捕捉细粒度的上下文和位置关系，并通过 Attention-Based Feedforward Neural Network (ABFNN) 聚焦关键特征，实现高效的症状和临床笔记分类。该方法在自动化医疗诊断中表现出色，达到 99.78% 准确率、99.72% 召回率、99.79% 精确率和 99.75% F1 分数，显著优于现有技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07755v1",
      "published_date": "2025-02-11 18:32:24 UTC",
      "updated_date": "2025-02-11 18:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:56:12.364860"
    },
    {
      "arxiv_id": "2502.07752v2",
      "title": "Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Gong",
        "Meyer Scetbon",
        "Chao Ma",
        "Edward Meeds"
      ],
      "abstract": "Designing efficient optimizers for large language models (LLMs) with\nlow-memory requirements and fast convergence is an important and challenging\nproblem. This paper makes a step towards the systematic design of such\noptimizers through the lens of structured Fisher information matrix (FIM)\napproximation. We show that many state-of-the-art efficient optimizers can be\nviewed as solutions to FIM approximation (under the Frobenius norm) with\nspecific structural assumptions. Building on these insights, we propose two\ndesign recommendations of practical efficient optimizers for LLMs, involving\nthe careful selection of structural assumptions to balance generality and\nefficiency, and enhancing memory efficiency of optimizers with general\nstructures through a novel low-rank extension framework. We demonstrate how to\nuse each design approach by deriving new memory-efficient optimizers: Row and\nColumn Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation\n(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the\neffectiveness, showing faster and better convergence than existing\nmemory-efficient baselines and Adam with little memory overhead. Notably, Alice\nachieves better than 2x faster convergence over Adam, while RACS delivers\nstrong performance on the 1B model with SGD-like memory.",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 的优化器设计，提出通过结构化 Fisher Information Matrix (FIM) 近似的方法，以实现低内存需求和快速收敛。作者分析了现有高效优化器作为 FIM 近似（基于 Frobenius 范数）的解决方案，并推荐两种设计策略：选择平衡泛化性和效率的结构假设，以及通过新型低秩扩展框架提升内存效率，从而引入新优化器 Row and Column Scaled SGD (RACS) 和 Adaptive low-dimensional subspace estimation (Alice)。在 LLaMA 预训练实验（高达 1B 参数）中，RACS 和 Alice 比现有内存高效基线和 Adam 表现出更快收敛，Alice 比 Adam 快 2 倍，而 RACS 以类似 SGD 的内存开销实现了出色性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07752v2",
      "published_date": "2025-02-11 18:27:19 UTC",
      "updated_date": "2025-02-20 18:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:56:26.320526"
    },
    {
      "arxiv_id": "2502.07750v2",
      "title": "PFedDST: Personalized Federated Learning with Decentralized Selection Training",
      "title_zh": "翻译失败",
      "authors": [
        "Mengchen Fan",
        "Keren Li",
        "Tianyun Zhang",
        "Qing Tian",
        "Baocheng Geng"
      ],
      "abstract": "Distributed Learning (DL) enables the training of machine learning models\nacross multiple devices, yet it faces challenges like non-IID data\ndistributions and device capability disparities, which can impede training\nefficiency. Communication bottlenecks further complicate traditional Federated\nLearning (FL) setups. To mitigate these issues, we introduce the Personalized\nFederated Learning with Decentralized Selection Training (PFedDST) framework.\nPFedDST enhances model training by allowing devices to strategically evaluate\nand select peers based on a comprehensive communication score. This score\nintegrates loss, task similarity, and selection frequency, ensuring optimal\npeer connections. This selection strategy is tailored to increase local\npersonalization and promote beneficial peer collaborations to strengthen the\nstability and efficiency of the training process. Our experiments demonstrate\nthat PFedDST not only enhances model accuracy but also accelerates convergence.\nThis approach outperforms state-of-the-art methods in handling data\nheterogeneity, delivering both faster and more effective training in diverse\nand decentralized systems.",
      "tldr_zh": "该论文提出PFedDST框架，一种针对Federated Learning (FL)中非IID数据分布、设备能力差异和通信瓶颈问题的个性化分布式学习方法。该框架允许设备通过一个综合通信分数（整合损失、任务相似性和选择频率）评估并选择最佳对等设备，从而提升本地模型的个性化并促进有效的合作。实验结果表明，PFedDST不仅提高了模型准确性并加速了收敛速度，还在处理数据异质性方面优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07750v2",
      "published_date": "2025-02-11 18:25:48 UTC",
      "updated_date": "2025-02-19 04:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:56:35.780358"
    },
    {
      "arxiv_id": "2502.07864v2",
      "title": "TransMLA: Multi-Head Latent Attention Is All You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Fanxu Meng",
        "Zengwei Yao",
        "Muhan Zhang"
      ],
      "abstract": "Modern large language models (LLMs) often encounter communication bottlenecks\non current hardware, rather than purely computational constraints. Multi-head\nLatent Attention (MLA) tackles this challenge by using low-rank matrices in the\nkey-value (KV) layers, thereby allowing compressed latent KV states to be\ncached. This approach significantly reduces the KV cache size relative to\ntraditional multi-head attention, leading to faster inference. Moreover, MLA\nemploys an up-projection matrix to increase expressiveness, trading additional\ncomputation for reduced communication overhead. Although MLA has demonstrated\nefficiency and effectiveness in Deepseek V2/V3/R1, many major model providers\nstill rely on Group Query Attention (GQA) and have not announced any plans to\nadopt MLA. In this paper, we show that GQA can always be represented by MLA\nwhile maintaining the same KV cache overhead, but the converse does not hold.\nTo encourage broader use of MLA, we introduce TransMLA, a post-training method\nthat converts widely used GQA-based pre-trained models (e.g., LLaMA, Qwen,\nMixtral) into MLA-based models. After conversion, the model can undergo\nadditional training to boost expressiveness without increasing the KV cache\nsize. Furthermore, we plan to develop MLA-specific inference acceleration\ntechniques to preserve low latency in transformed models, thus enabling more\nefficient distillation of Deepseek R1.",
      "tldr_zh": "该论文提出 Multi-Head Latent Attention (MLA)，一种通过使用低秩矩阵压缩 key-value (KV) 缓存的方法，以缓解大型语言模型 (LLMs) 在硬件上的通信瓶颈问题，同时通过上投影矩阵提升模型表达能力。作者证明 Group Query Attention (GQA) 可以被 MLA 表示，但反之不成立，并引入 TransMLA 后训练方法，将基于 GQA 的预训练模型（如 LLaMA、Qwen、Mixtral）转换为 MLA 模型，从而在不增加 KV 缓存大小的情况下进一步优化性能。实验显示 MLA 在 Deepseek 系列模型中表现出色，未来计划开发 MLA 专用推理加速技术，以实现更高效的模型蒸馏和低延迟推理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/fxmeng/TransMLA",
      "pdf_url": "http://arxiv.org/pdf/2502.07864v2",
      "published_date": "2025-02-11 18:20:18 UTC",
      "updated_date": "2025-02-13 18:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:56:48.647597"
    },
    {
      "arxiv_id": "2502.07747v1",
      "title": "WHODUNIT: Evaluation benchmark for culprit detection in mystery stories",
      "title_zh": "WHODUNIT：神秘故事中罪犯检测的评估基准",
      "authors": [
        "Kshitij Gupta"
      ],
      "abstract": "We present a novel data set, WhoDunIt, to assess the deductive reasoning\ncapabilities of large language models (LLM) within narrative contexts.\nConstructed from open domain mystery novels and short stories, the dataset\nchallenges LLMs to identify the perpetrator after reading and comprehending the\nstory. To evaluate model robustness, we apply a range of character-level name\naugmentations, including original names, name swaps, and substitutions with\nwell-known real and/or fictional entities from popular discourse. We further\nuse various prompting styles to investigate the influence of prompting on\ndeductive reasoning accuracy.\n  We conduct evaluation study with state-of-the-art models, specifically\nGPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with\nmajority response selection to ensure reliability. The results demonstrate that\nwhile LLMs perform reliably on unaltered texts, accuracy diminishes with\ncertain name substitutions, particularly those with wide recognition. This\ndataset is publicly available here.",
      "tldr_zh": "本文提出 WhoDunIt 数据集，作为评估大型语言模型 (LLM) 在神秘故事叙事上下文中的演绎推理能力的基准，数据集基于开源神秘小说和短故事，要求模型阅读后识别罪犯。研究通过字符级名称增强（如名称交换和知名实体替换）以及不同提示风格，测试模型的鲁棒性。实验使用 GPT-4o、GPT-4-turbo 和 GPT-4o-mini 等模型进行多次试验，结果显示 LLM 在原始文本上准确性较高，但知名实体替换会显著降低性能。该数据集已公开提供，供进一步研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07747v1",
      "published_date": "2025-02-11 18:14:44 UTC",
      "updated_date": "2025-02-11 18:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:57:00.418085"
    },
    {
      "arxiv_id": "2502.07737v2",
      "title": "Next Block Prediction: Video Generation via Semi-Autoregressive Modeling",
      "title_zh": "下一块预测：通过半自回归建模的视频生成",
      "authors": [
        "Shuhuai Ren",
        "Shuming Ma",
        "Xu Sun",
        "Furu Wei"
      ],
      "abstract": "Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR)\nvideo generation, but it suffers from suboptimal unidirectional dependencies\nand slow inference speed. In this work, we propose a semi-autoregressive\n(semi-AR) framework, called Next-Block Prediction (NBP), for video generation.\nBy uniformly decomposing video content into equal-sized blocks (e.g., rows or\nframes), we shift the generation unit from individual tokens to blocks,\nallowing each token in the current block to simultaneously predict the\ncorresponding token in the next block. Unlike traditional AR modeling, our\nframework employs bidirectional attention within each block, enabling tokens to\ncapture more robust spatial dependencies. By predicting multiple tokens in\nparallel, NBP models significantly reduce the number of generation steps,\nleading to faster and more efficient inference. Our model achieves FVD scores\nof 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an\naverage of 4.4. Furthermore, thanks to the reduced number of inference steps,\nthe NBP model generates 8.89 frames (128x128 resolution) per second, achieving\nan 11x speedup. We also explored model scales ranging from 700M to 3B\nparameters, observing significant improvements in generation quality, with FVD\nscores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600,\ndemonstrating the scalability of our approach.",
      "tldr_zh": "本文提出 Next-Block Prediction (NBP) 框架，一种 semi-autoregressive (semi-AR) 建模方法，用于视频生成，以克服传统 Next-Token Prediction (NTP) 的单向依赖和慢速推理问题。NBP 通过将视频内容分解成等大小的块（如行或帧），并在每个块内使用 bidirectional attention 捕获更强的空间依赖，实现多个 token 的并行预测，从而显著减少生成步骤。实验结果显示，NBP 在 UCF101 上 FVD 得分为 103.3、在 K600 上为 25.5，比 NTP 平均提高 4.4 分，并实现 11 倍速度提升（每秒生成 8.89 帧，128x128 分辨率），模型规模从 700M 到 3B 参数时，生成质量进一步改善。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "project page: https://renshuhuai-andy.github.io/NBP-project/",
      "pdf_url": "http://arxiv.org/pdf/2502.07737v2",
      "published_date": "2025-02-11 17:57:53 UTC",
      "updated_date": "2025-02-12 14:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:57:13.943243"
    },
    {
      "arxiv_id": "2502.07734v1",
      "title": "EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Camile Lendering",
        "Bernardo Perrone Ribeiro",
        "Žiga Emeršič",
        "Peter Peer"
      ],
      "abstract": "Ear recognition is a contactless and unobtrusive biometric technique with\napplications across various domains. However, deploying high-performing ear\nrecognition models on resource-constrained devices is challenging, limiting\ntheir applicability and widespread adoption. This paper introduces EdgeEar, a\nlightweight model based on a proposed hybrid CNN-transformer architecture to\nsolve this problem. By incorporating low-rank approximations into specific\nlinear layers, EdgeEar reduces its parameter count by a factor of 50 compared\nto the current state-of-the-art, bringing it below two million while\nmaintaining competitive accuracy. Evaluation on the Unconstrained Ear\nRecognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the\nlowest EER while significantly reducing computational costs. These findings\ndemonstrate the feasibility of efficient and accurate ear recognition, which we\nbelieve will contribute to the wider adoption of ear biometrics.",
      "tldr_zh": "本文提出 EdgeEar，一种基于混合 CNN-Transformer 架构的轻量级耳部识别模型，旨在解决高性能模型在资源受限边缘设备上的部署挑战。通过在特定线性层应用低秩近似，EdgeEar 将参数数量减少了 50 倍（低于 200 万），同时保持竞争性准确性。在 UERC2023 基准测试中，EdgeEar 实现了最低的 EER 并显著降低了计算成本，这证明了高效准确耳部生物识别的可行性，并有望推动其更广泛采用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to IEEE FG 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07734v1",
      "published_date": "2025-02-11 17:53:33 UTC",
      "updated_date": "2025-02-11 17:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:57:25.766711"
    },
    {
      "arxiv_id": "2502.07732v1",
      "title": "Economics of Sourcing Human Data",
      "title_zh": "人类数据获取的经济学",
      "authors": [
        "Sebastin Santy",
        "Prasanta Bhattacharya",
        "Manoel Horta Ribeiro",
        "Kelsey Allen",
        "Sewoong Oh"
      ],
      "abstract": "Progress in AI has relied on human-generated data, from annotator\nmarketplaces to the wider Internet. However, the widespread use of large\nlanguage models now threatens the quality and integrity of human-generated data\non these very platforms. We argue that this issue goes beyond the immediate\nchallenge of filtering AI-generated content--it reveals deeper flaws in how\ndata collection systems are designed. Existing systems often prioritize speed,\nscale, and efficiency at the cost of intrinsic human motivation, leading to\ndeclining engagement and data quality. We propose that rethinking data\ncollection systems to align with contributors' intrinsic motivations--rather\nthan relying solely on external incentives--can help sustain high-quality data\nsourcing at scale while maintaining contributor trust and long-term\nparticipation.",
      "tldr_zh": "AI 的进步依赖于人类生成的数据来源，如标注市场和互联网，但大语言模型的广泛使用正威胁这些数据的质量和完整性。论文分析指出，现有的数据收集系统过度强调速度、规模和效率，而忽略了贡献者的 intrinsic motivation，导致参与度和数据质量下降。该研究提出重新设计数据收集系统，以与贡献者的内在动机对齐，而不是仅依赖外部激励，从而维持高质量数据来源、增强信任并促进长期参与。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07732v1",
      "published_date": "2025-02-11 17:51:52 UTC",
      "updated_date": "2025-02-11 17:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:57:37.016072"
    },
    {
      "arxiv_id": "2502.07728v1",
      "title": "Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK",
      "title_zh": "翻译失败",
      "authors": [
        "Marcos Cramer",
        "Lucian McIntyre"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable code generation\ncapabilities, but the correctness of the generated code cannot be inherently\ntrusted. This paper explores the feasibility of using formal software\nverification, specifically the SPARK framework for Ada, to ensure the\nreliability of LLM-generated code. We present Marmaragan, a tool that leverages\nan LLM in order to generate SPARK annotations for existing programs, enabling\nformal verification of the code. The tool is benchmarked on a curated set of\nSPARK programs, with annotations selectively removed to test specific\ncapabilities. The performance of Marmaragan with GPT-4o on the benchmark is\npromising, with correct annotations having been generated for 50.7% of the\nbenchmark cases. The results establish a foundation for future work on\ncombining the power of LLMs with the reliability of formal software\nverification.",
      "tldr_zh": "该论文探讨了使用正式软件验证框架 SPARK for Ada 来验证 LLM 生成代码的可靠性，以解决代码正确性问题。研究引入了 Marmaragan 工具，该工具利用 LLM 生成 SPARK 注解，从而实现现有程序的正式验证。在基准测试中，使用 GPT-4o 的 Marmaragan 成功生成了 50.7% 的正确注解，为未来结合 LLMs 与正式软件验证的可靠方法奠定了基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07728v1",
      "published_date": "2025-02-11 17:42:07 UTC",
      "updated_date": "2025-02-11 17:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:57:50.004942"
    },
    {
      "arxiv_id": "2502.07721v1",
      "title": "TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mengyang Li"
      ],
      "abstract": "The prevalence of noisy labels in real-world datasets poses a significant\nimpediment to the effective deployment of deep learning models. While\nmeta-learning strategies have emerged as a promising approach for addressing\nthis challenge, existing methods often suffer from limited transferability and\ntask-specific designs. This paper introduces TMLC-Net, a novel Transferable\nMeta-Learner for Correcting Noisy Labels, designed to overcome these\nlimitations. TMLC-Net learns a general-purpose label correction strategy that\ncan be readily applied across diverse datasets and model architectures without\nrequiring extensive retraining or fine-tuning. Our approach integrates three\ncore components: (1) Normalized Noise Perception, which captures and normalizes\ntraining dynamics to handle distribution shifts; (2) Time-Series Encoding,\nwhich models the temporal evolution of sample statistics using a recurrent\nneural network; and (3) Subclass Decoding, which predicts a corrected label\ndistribution based on the learned representations. We conduct extensive\nexperiments on benchmark datasets with various noise types and levels,\ndemonstrating that TMLC-Net consistently outperforms state-of-the-art methods\nin terms of both accuracy and robustness to label noise. Furthermore, we\nanalyze the transferability of TMLC-Net, showcasing its adaptability to new\ndatasets and noise conditions, and establishing its potential as a broadly\napplicable solution for robust deep learning in noisy environments.",
      "tldr_zh": "这篇论文提出了 TMLC-Net，一种可转移的元学习框架，用于解决深度学习中噪声标签的挑战，通过学习通用的标签纠正策略来提升模型的准确性和鲁棒性。框架的核心组件包括 Normalized Noise Perception（用于捕捉并归一化训练动态以处理分布偏移）、Time-Series Encoding（利用循环神经网络模型样本统计的时序演化），以及 Subclass Decoding（基于学习表示预测校正标签分布）。实验结果显示，TMLC-Net 在基准数据集上的各种噪声类型和水平下，显著优于现有方法，并在可转移性方面表现出色，可轻松适应新数据集和噪声条件。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07721v1",
      "published_date": "2025-02-11 17:33:48 UTC",
      "updated_date": "2025-02-11 17:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:58:01.949629"
    },
    {
      "arxiv_id": "2502.07862v1",
      "title": "ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Wu",
        "Kang Yang",
        "Lance Kaplan",
        "Mani Srivastava"
      ],
      "abstract": "Multimodal deep learning systems are deployed in dynamic scenarios due to the\nrobustness afforded by multiple sensing modalities. Nevertheless, they struggle\nwith varying compute resource availability (due to multi-tenancy, device\nheterogeneity, etc.) and fluctuating quality of inputs (from sensor feed\ncorruption, environmental noise, etc.). Current multimodal systems employ\nstatic resource provisioning and cannot easily adapt when compute resources\nchange over time. Additionally, their reliance on processing sensor data with\nfixed feature extractors is ill-equipped to handle variations in modality\nquality. Consequently, uninformative modalities, such as those with high noise,\nneedlessly consume resources better allocated towards other modalities. We\npropose ADMN, a layer-wise Adaptive Depth Multimodal Network capable of\ntackling both challenges - it adjusts the total number of active layers across\nall modalities to meet compute resource constraints, and continually\nreallocates layers across input modalities according to their modality quality.\nOur evaluations showcase ADMN can match the accuracy of state-of-the-art\nnetworks while reducing up to 75% of their floating-point operations.",
      "tldr_zh": "该论文针对多模态深度学习系统在动态环境中面临的计算资源变化和输入噪声问题，提出了一种层级自适应多模态网络（ADMN）。ADMN 通过动态调整各模态的活跃层数，来满足计算资源约束并根据模态质量（如噪声水平）重新分配层数，从而优化资源利用。实验结果显示，ADMN 能与最先进网络匹配准确性，同时减少多达 75% 的浮点运算（floating-point operations）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07862v1",
      "published_date": "2025-02-11 17:19:44 UTC",
      "updated_date": "2025-02-11 17:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:58:13.466740"
    },
    {
      "arxiv_id": "2502.07861v1",
      "title": "BalanceKV: KV Cache Compression through Discrepancy Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Insu Han",
        "Michael Kapralov",
        "Ekaterina Kochetkova",
        "Kshiteej Sheth",
        "Amir Zandieh"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive success, but their high\nmemory requirements present challenges for long-context token generation. The\nmemory complexity of long-context LLMs is primarily due to the need to store\nKey-Value (KV) embeddings in their KV cache. We present BalanceKV, a KV cache\ncompression method based on geometric sampling process stemming from\nBanaszczyk's vector balancing theory, which introduces dependencies informed by\nthe geometry of keys and value tokens, and improves precision. BalanceKV offers\nboth theoretically proven and empirically validated performance improvements\nover existing methods.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)处理长上下文时的高内存需求，提出BalanceKV方法，通过基于Banaszczyk's vector balancing theory的几何采样过程来压缩KV cache。BalanceKV引入keys和value tokens的几何依赖性，以提升压缩精度和整体性能。该方法在理论证明和实证验证中均显示出显著改进，优于现有KV缓存压缩技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07861v1",
      "published_date": "2025-02-11 17:18:17 UTC",
      "updated_date": "2025-02-11 17:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:58:24.614712"
    },
    {
      "arxiv_id": "2502.07709v2",
      "title": "MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Loris Gaven",
        "Thomas Carta",
        "Clément Romac",
        "Cédric Colas",
        "Sylvain Lamprier",
        "Olivier Sigaud",
        "Pierre-Yves Oudeyer"
      ],
      "abstract": "Open-ended learning agents must efficiently prioritize goals in vast\npossibility spaces, focusing on those that maximize learning progress (LP).\nWhen such autotelic exploration is achieved by LLM agents trained with online\nRL in high-dimensional and evolving goal spaces, a key challenge for LP\nprediction is modeling one's own competence, a form of metacognitive\nmonitoring. Traditional approaches either require extensive sampling or rely on\nbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive\nframework that lets LLM agents learn to predict their competence and LP online.\nBy capturing semantic relationships between goals, MAGELLAN enables\nsample-efficient LP estimation and dynamic adaptation to evolving goal spaces\nthrough generalization. In an interactive learning environment, we show that\nMAGELLAN improves LP prediction efficiency and goal prioritization, being the\nonly method allowing the agent to fully master a large and evolving goal space.\nThese results demonstrate how augmenting LLM agents with a metacognitive\nability for LP predictions can effectively scale curriculum learning to\nopen-ended goal spaces.",
      "tldr_zh": "该研究引入了 MAGELLAN 框架，利用元认知预测来指导 autotelic LLM 代理在大型目标空间中优先化学习进步 (LP)，以解决传统方法在高维演化环境中采样效率低的问题。MAGELLAN 让代理在线学习预测自身 competence，通过捕捉目标间的语义关系，实现样本高效的 LP 估计和动态适应。实验在交互式学习环境中证明，该框架提升了 LP 预测效率和目标优先级，是唯一能使代理完全掌握开放式目标空间的方法，从而有效扩展了课程学习的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07709v2",
      "published_date": "2025-02-11 17:08:00 UTC",
      "updated_date": "2025-02-12 08:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:58:38.718809"
    },
    {
      "arxiv_id": "2502.09650v2",
      "title": "Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Chengqian Gao",
        "Haonan Li",
        "Liu Liu",
        "Zeke Xie",
        "Peilin Zhao",
        "Zhiqiang Xu"
      ],
      "abstract": "The alignment of large language models (LLMs) often assumes that using more\nclean data yields better outcomes, overlooking the match between model capacity\nand example difficulty. Challenging this, we propose a new principle:\nPreference data vary in difficulty, and overly difficult examples hinder\nalignment, by exceeding the model's capacity. Through systematic\nexperimentation, we validate this principle with three key findings: (1)\npreference examples vary in difficulty, as evidenced by consistent learning\norders across alignment runs; (2) overly difficult examples significantly\ndegrade performance across four LLMs and two datasets; and (3) the capacity of\na model dictates its threshold for handling difficult examples, underscoring a\ncritical relationship between data selection and model capacity. Building on\nthis principle, we introduce Selective DPO, which filters out overly difficult\nexamples. This simple adjustment improves alignment performance by 9-16% in win\nrates on the AlpacaEval 2 benchmark compared to the DPO baseline, suppressing a\nseries of DPO variants with different algorithmic adjustments. Together, these\nresults illuminate the importance of aligning data difficulty with model\ncapacity, offering a transformative perspective for improving alignment\nstrategies in LLMs. Code is available at\nhttps://github.com/glorgao/SelectiveDPO.",
      "tldr_zh": "这篇论文挑战了使用更多干净数据就能改善大型语言模型 (LLMs) 对齐的传统假设，提出一个新原则：偏好数据存在难度差异，过难示例会超过模型容量从而阻碍对齐效果。通过系统实验，他们验证了三个关键发现：(1) 偏好示例在不同对齐运行中显示出一致的难度顺序；(2) 过难示例显著降低了四种LLMs和两种数据集的性能；(3) 模型容量决定了其处理难度的阈值。论文引入了Selective DPO方法，通过过滤过难示例，在AlpacaEval 2基准上比DPO基线提高了9-16%的胜率，提供了一种将数据难度与模型容量匹配的创新对齐策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.09650v2",
      "published_date": "2025-02-11 17:01:11 UTC",
      "updated_date": "2025-05-13 18:54:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:58:50.614894"
    },
    {
      "arxiv_id": "2502.07693v4",
      "title": "AI-driven Personalized Privacy Assistants: a Systematic Literature Review",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Morel",
        "Leonardo Iwaya",
        "Simone Fischer-Hübner"
      ],
      "abstract": "In recent years, several personalized assistants based on AI have been\nresearched and developed to help users make privacy-related decisions. These\nAI-driven Personalized Privacy Assistants (AI-driven PPAs) can provide\nsignificant benefits for users, who might otherwise struggle with making\ndecisions about their personal data in online environments that often overload\nthem with different privacy decision requests. So far, no studies have\nsystematically investigated the emerging topic of AI-driven PPAs, classifying\ntheir underlying technologies, architecture and features, including decision\ntypes or the accuracy of their decisions. To fill this gap, we present a\nSystematic Literature Review (SLR) to map the existing solutions found in the\nscientific literature, which allows reasoning about existing approaches and\nopen challenges for this research field. We screened several hundred unique\nresearch papers over the recent years (2013-2025), constructing a\nclassification from 41 included papers. As a result, this SLR reviews several\naspects of existing research on AI-driven PPAs in terms of types of\npublications, contributions, methodological quality, and other quantitative\ninsights. Furthermore, we provide a comprehensive classification for AI-driven\nPPAs, delving into their architectural choices, system contexts, types of AI\nused, data sources, types of decisions, and control over decisions, among other\nfacets. Based on our SLR, we further underline the research gaps and challenges\nand formulate recommendations for the design and development of AI-driven PPAs\nas well as avenues for future research.",
      "tldr_zh": "这篇论文通过系统文献综述（Systematic Literature Review, SLR）对AI-driven Personalized Privacy Assistants (AI-driven PPAs)进行了全面审查，筛选了2013-2025年间数百篇论文，并从41篇中构建分类框架。研究分析了这些助手的底层技术、架构、特征（如决策类型和准确性）、AI类型、数据来源等多个方面，并评估了现有研究的贡献、方法质量和系统上下文。最终，论文指出了AI-driven PPAs领域的关键挑战和研究空白，并提供了设计开发推荐及未来研究方向。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Submitted to IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2502.07693v4",
      "published_date": "2025-02-11 16:46:56 UTC",
      "updated_date": "2025-05-20 11:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:59:01.738626"
    },
    {
      "arxiv_id": "2502.07857v1",
      "title": "SNAP: Sequential Non-Ancestor Pruning for Targeted Causal Effect Estimation With an Unknown Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Mátyás Schubert",
        "Tom Claassen",
        "Sara Magliacane"
      ],
      "abstract": "Causal discovery can be computationally demanding for large numbers of\nvariables. If we only wish to estimate the causal effects on a small subset of\ntarget variables, we might not need to learn the causal graph for all\nvariables, but only a small subgraph that includes the targets and their\nadjustment sets. In this paper, we focus on identifying causal effects between\ntarget variables in a computationally and statistically efficient way. This\ntask combines causal discovery and effect estimation, aligning the discovery\nobjective with the effects to be estimated. We show that definite non-ancestors\nof the targets are unnecessary to learn causal relations between the targets\nand to identify efficient adjustments sets. We sequentially identify and prune\nthese definite non-ancestors with our Sequential Non-Ancestor Pruning (SNAP)\nframework, which can be used either as a preprocessing step to standard causal\ndiscovery methods, or as a standalone sound and complete causal discovery\nalgorithm. Our results on synthetic and real data show that both approaches\nsubstantially reduce the number of independence tests and the computation time\nwithout compromising the quality of causal effect estimations.",
      "tldr_zh": "这篇论文提出Sequential Non-Ancestor Pruning (SNAP)框架，用于在未知因果图中高效估计目标变量的causal effects，通过顺序识别和修剪这些变量的definite non-ancestors来减少不必要的计算。SNAP将causal discovery与效应估计相结合，可作为标准causal discovery方法的预处理步骤或独立算法，确保高效识别adjustment sets。实验结果显示，该框架在合成和真实数据上显著降低了独立性测试数量和计算时间，同时维持了causal effect估计的质量。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted at AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07857v1",
      "published_date": "2025-02-11 16:20:57 UTC",
      "updated_date": "2025-02-11 16:20:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:59:13.762889"
    },
    {
      "arxiv_id": "2502.07663v2",
      "title": "Human Decision-making is Susceptible to AI-driven Manipulation",
      "title_zh": "人类决策易受AI驱动操控",
      "authors": [
        "Sahand Sabour",
        "June M. Liu",
        "Siyang Liu",
        "Chris Z. Yao",
        "Shiyao Cui",
        "Xuanming Zhang",
        "Wen Zhang",
        "Yaru Cao",
        "Advait Bhat",
        "Jian Guan",
        "Wei Wu",
        "Rada Mihalcea",
        "Hongning Wang",
        "Tim Althoff",
        "Tatia M. C. Lee",
        "Minlie Huang"
      ],
      "abstract": "Artificial Intelligence (AI) systems are increasingly intertwined with daily\nlife, assisting users in executing various tasks and providing guidance on\ndecision-making. This integration introduces risks of AI-driven manipulation,\nwhere such systems may exploit users' cognitive biases and emotional\nvulnerabilities to steer them toward harmful outcomes. Through a randomized\ncontrolled trial with 233 participants, we examined human susceptibility to\nsuch manipulation in financial (e.g., purchases) and emotional (e.g., conflict\nresolution) decision-making contexts. Participants interacted with one of three\nAI agents: a neutral agent (NA) optimizing for user benefit without explicit\ninfluence, a manipulative agent (MA) designed to covertly influence beliefs and\nbehaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit\npsychological tactics to reach its hidden objectives. By analyzing\nparticipants' decision patterns and shifts in their preference ratings\npost-interaction, we found significant susceptibility to AI-driven\nmanipulation. Particularly, across both decision-making domains, participants\ninteracting with the manipulative agents shifted toward harmful options at\nsubstantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA:\n42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional,\n12.8%). Notably, our findings reveal that even subtle manipulative objectives\n(MA) can be as effective as employing explicit psychological strategies (SEMA)\nin swaying human decision-making. By revealing the potential for covert AI\ninfluence, this study highlights a critical vulnerability in human-AI\ninteractions, emphasizing the need for ethical safeguards and regulatory\nframeworks to ensure responsible deployment of AI technologies and protect\nhuman autonomy.",
      "tldr_zh": "本研究通过一项涉及233名参与者的随机对照试验，探讨了人类决策在财务（如购买）和情感（如冲突解决）情境中对AI驱动操纵的易感性。参与者与三种AI代理互动：中性代理 (NA) 优化用户利益、操纵代理 (MA) 隐蔽影响信念和行为，以及策略增强操纵代理 (SEMA) 使用显性心理策略。结果显示，与NA组相比，MA和SEMA组的参与者更倾向于选择有害选项（财务：MA 62.3%、SEMA 59.6% vs. NA 35.8%；情感：MA 42.3%、SEMA 41.5% vs. NA 12.8%），表明即使微妙操纵也能像显性策略一样有效。该研究揭示了人类-AI互动中的关键漏洞，呼吁制定道德保障和监管框架以保护人类自主性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.07663v2",
      "published_date": "2025-02-11 15:56:22 UTC",
      "updated_date": "2025-02-24 15:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:59:27.155791"
    },
    {
      "arxiv_id": "2502.07656v1",
      "title": "A Unifying Framework for Causal Imitation Learning with Hidden Confounders",
      "title_zh": "翻译失败",
      "authors": [
        "Daqian Shao",
        "Thomas Kleine Buening",
        "Marta Kwiatkowska"
      ],
      "abstract": "We propose a general and unifying framework for causal Imitation Learning\n(IL) with hidden confounders that subsumes several existing confounded IL\nsettings from the literature. Our framework accounts for two types of hidden\nconfounders: (a) those observed by the expert, which thus influence the\nexpert's policy, and (b) confounding noise hidden to both the expert and the IL\nalgorithm. For additional flexibility, we also introduce a confounding noise\nhorizon and time-varying expert-observable hidden variables. We show that\ncausal IL in our framework can be reduced to a set of Conditional Moment\nRestrictions (CMRs) by leveraging trajectory histories as instruments to learn\na history-dependent policy. We propose DML-IL, a novel algorithm that uses\ninstrumental variable regression to solve these CMRs and learn a policy. We\nprovide a bound on the imitation gap for DML-IL, which recovers prior results\nas special cases. Empirical evaluation on a toy environment with continues\nstate-action spaces and multiple Mujoco tasks demonstrate that DML-IL\noutperforms state-of-the-art causal IL algorithms.",
      "tldr_zh": "本文提出一个统一的框架，用于处理隐藏混杂因素的Causal Imitation Learning (IL)，涵盖了现有文献中的多种设置，包括专家观察到的混杂因素和双重隐藏的混杂噪声，并引入混杂噪声视野及时间变化的专家可观察变量。框架通过利用轨迹历史作为工具变量，将Causal IL简化为一组Conditional Moment Restrictions (CMRs)，并提出DML-IL算法，使用工具变量回归来学习策略。DML-IL提供了模仿差距的理论界限，作为先前结果的特例。实验在玩具环境和多个Mujoco任务中表明，DML-IL优于现有Causal IL算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07656v1",
      "published_date": "2025-02-11 15:43:49 UTC",
      "updated_date": "2025-02-11 15:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:59:38.096913"
    },
    {
      "arxiv_id": "2502.07644v2",
      "title": "SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models",
      "title_zh": "SymGPT：通过将符号执行与大型语言模型相结合审计智能合约",
      "authors": [
        "Shihao Xia",
        "Mengting He",
        "Shuai Shao",
        "Tingting Yu",
        "Yiying Zhang",
        "Linhai Song"
      ],
      "abstract": "To govern smart contracts running on Ethereum, multiple Ethereum Request for\nComment (ERC) standards have been developed, each having a set of rules to\nguide the behaviors of smart contracts. Violating the ERC rules could cause\nserious security issues and financial loss, signifying the importance of\nverifying smart contracts follow ERCs. Today's practices of such verification\nare to manually audit each single contract, use expert-developed\nprogram-analysis tools, or use large language models (LLMs), all of which are\nfar from effective in identifying ERC rule violations. This paper introduces\nSymGPT, a tool that combines the natural language understanding of large\nlanguage models (LLMs) with the formal guarantees of symbolic execution to\nautomatically verify smart contracts' compliance with ERC rules. To develop\nSymGPT, we conduct an empirical study of 132 ERC rules from three widely used\nERC standards, examining their content, security implications, and natural\nlanguage descriptions. Based on this study, we design SymGPT by first\ninstructing an LLM to translate ERC rules into a defined EBNF grammar. We then\nsynthesize constraints from the formalized rules to represent scenarios where\nviolations may occur and use symbolic execution to detect them. Our evaluation\nshows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world\ncontracts, including 1,375 violations with clear attack paths for stealing\nfinancial assets, demonstrating its effectiveness. Furthermore, SymGPT\noutperforms six automated techniques and a security-expert auditing service,\nunderscoring its superiority over current smart contract analysis methods.",
      "tldr_zh": "本文提出SymGPT，一种创新工具，通过结合Large Language Models (LLMs)的自然语言理解和Symbolic Execution的正式保证，来自动审计智能合约是否遵守Ethereum Request for Comment (ERC)标准，从而识别潜在安全风险和财务损失。SymGPT首先对132个ERC规则进行实证研究，使用LLMs将这些规则翻译成EBNF语法，然后合成约束并通过Symbolic Execution检测违反场景。实验结果显示，SymGPT在4000个真实合约中识别了5783个ERC规则违反，包括1375个具有明确攻击路径的案例，并显著优于六种自动化技术和专业审计服务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages. arXiv admin note: text overlap with arXiv:2404.04306",
      "pdf_url": "http://arxiv.org/pdf/2502.07644v2",
      "published_date": "2025-02-11 15:34:00 UTC",
      "updated_date": "2025-02-12 05:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:59:50.211646"
    },
    {
      "arxiv_id": "2502.07640v3",
      "title": "Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Lin",
        "Shange Tang",
        "Bohan Lyu",
        "Jiayun Wu",
        "Hongzhou Lin",
        "Kaiyu Yang",
        "Jia Li",
        "Mengzhou Xia",
        "Danqi Chen",
        "Sanjeev Arora",
        "Chi Jin"
      ],
      "abstract": "We introduce Goedel-Prover, an open-source language model that achieves\nstate-of-the-art (as of April 5 2025) performance in automated formal proof\ngeneration for mathematical problems. A key challenge in this field is the\nscarcity of formalized mathematical statements and proofs, which we address\nthrough the following approaches. First, we train LLMs to convert natural\nlanguage math problems from the Numina dataset to equivalent formal statements\nin Lean 4. This process creates the dataset Goedel-Pset-v1, which includes 1.64\nmillion formal statements. Next, we develop a large dataset of formal proofs by\ntraining a series of provers. Each new prover can prove many statements that\nprevious ones could not, and these new proofs are added to the training set for\nthe next prover. Finally, we obtain the dataset Goedel-Pset-v1-solved, which\ncontains proofs for over 800K statements from Goedel-Pset-v1. Supervised\nfine-tuning (SFT) of DeepSeek-Prover-V1.5-Base on Goedel-Pset-v1-solved (i.e.,\nno RL) yields a Goedel-Prover-SFT that achieves a success rate of 57.6%\n(Pass@32) on miniF2F, surpassing the previous leader DeepSeek-Prover-V1.5-RL\n(trained using SFT + RL on a proprietary dataset) by 7.6%. On PutnamBench,\nGoedel-Prover-SFT successfully solves 7 problems (Pass@512), ranking first on\nthe leaderboard. We provide extensive discussion of our training methodology,\nhighlighting the key design choices that contribute to Goedel-Prover's strong\nperformance. Further RL training (including DPO) improves Goedel-Prover-SFT's\nsuccess rate to over 60% (Pass@32) on miniF2F.\n  To aid future research, we provide extensive discussion of our training\nmethodology and design choices. We also fully open-source our codes, models,\nand datasets. Additionally, we open-source formal proofs for 29.7K problems in\nLean Workbook, nearly doubling the 15.7K solved by prior provers.",
      "tldr_zh": "本研究引入 Goedel-Prover，一款开源语言模型，在自动化定理证明领域达到最先进性能（截至 2025 年 4 月 5 日），通过解决形式化数学语句和证明的稀缺问题。研究团队训练 LLM 将 Numina 数据集的自然语言数学问题转换为 Lean 4 形式语句，创建 Goedel-Pset-v1 数据集（164 万条），并通过迭代训练证明器生成 Goedel-Pset-v1-solved 数据集（超过 80 万条证明）。在实验中，Goedel-Prover-SFT 在 miniF2F 上实现 57.6% 的成功率 (Pass@32)，比 DeepSeek-Prover-V1.5-RL 高 7.6%，并在 PutnamBench 上解决 7 个问题 (Pass@512) 排名第一；进一步的 RL 训练将成功率提升至超过 60%。为促进未来研究，该论文开源了代码、模型、数据集以及近 30K Lean Workbook 问题的形式证明。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07640v3",
      "published_date": "2025-02-11 15:27:35 UTC",
      "updated_date": "2025-04-19 13:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:00:03.437678"
    },
    {
      "arxiv_id": "2502.07635v1",
      "title": "Distributed Value Decomposition Networks with Networked Agents",
      "title_zh": "分布式值分解网络与联网代理",
      "authors": [
        "Guilherme S. Varela",
        "Alberto Sardinha",
        "Francisco S. Melo"
      ],
      "abstract": "We investigate the problem of distributed training under partial\nobservability, whereby cooperative multi-agent reinforcement learning agents\n(MARL) maximize the expected cumulative joint reward. We propose distributed\nvalue decomposition networks (DVDN) that generate a joint Q-function that\nfactorizes into agent-wise Q-functions. Whereas the original value\ndecomposition networks rely on centralized training, our approach is suitable\nfor domains where centralized training is not possible and agents must learn by\ninteracting with the physical environment in a decentralized manner while\ncommunicating with their peers. DVDN overcomes the need for centralized\ntraining by locally estimating the shared objective. We contribute with two\ninnovative algorithms, DVDN and DVDN (GT), for the heterogeneous and\nhomogeneous agents settings respectively. Empirically, both algorithms\napproximate the performance of value decomposition networks, in spite of the\ninformation loss during communication, as demonstrated in ten MARL tasks in\nthree standard environments.",
      "tldr_zh": "我们研究了在部分可观察性下，分布式训练的合作多智能体强化学习（MARL）问题，提出分布式价值分解网络（DVDN），它生成一个可分解成代理-wise Q-functions 的联合 Q 函数。DVDN 通过代理间的通信和局部估计共享目标，克服了传统价值分解网络对集中式训练的依赖，适用于完全分散的环境。贡献包括两个算法：DVDN（针对异构代理）和 DVDN (GT)（针对同构代理），实验在三个标准环境中的十个 MARL 任务中显示，其性能接近基线模型，尽管存在通信信息损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 15 figures, to be published in Proceedings of the 24th\n  International Conference on Autonomous Agents and Multiagent Systems (AAMAS\n  2025), Detroit, Michigan, USA, May 19 - 23, 2025, IFAAMAS",
      "pdf_url": "http://arxiv.org/pdf/2502.07635v1",
      "published_date": "2025-02-11 15:23:05 UTC",
      "updated_date": "2025-02-11 15:23:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:00:15.808044"
    },
    {
      "arxiv_id": "2502.07856v4",
      "title": "MaRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Ao Li",
        "Wei Fang",
        "Hongbo Zhao",
        "Le Lu",
        "Ge Yang",
        "Minfeng Xu"
      ],
      "abstract": "In applications of diffusion models, controllable generation is of practical\nsignificance, but is also challenging. Current methods for controllable\ngeneration primarily focus on modifying the score function of diffusion models,\nwhile Mean Reverting (MR) Diffusion directly modifies the structure of the\nstochastic differential equation (SDE), making the incorporation of image\nconditions simpler and more natural. However, current training-free fast\nsamplers are not directly applicable to MR Diffusion. And thus MR Diffusion\nrequires hundreds of NFEs (number of function evaluations) to obtain\nhigh-quality samples. In this paper, we propose a new algorithm named MaRS (MR\nSampler) to reduce the sampling NFEs of MR Diffusion. We solve the reverse-time\nSDE and the probability flow ordinary differential equation (PF-ODE) associated\nwith MR Diffusion, and derive semi-analytical solutions. The solutions consist\nof an analytical function and an integral parameterized by a neural network.\nBased on this solution, we can generate high-quality samples in fewer steps.\nOur approach does not require training and supports all mainstream\nparameterizations, including noise prediction, data prediction and velocity\nprediction. Extensive experiments demonstrate that MR Sampler maintains high\nsampling quality with a speedup of 10 to 20 times across ten different image\nrestoration tasks. Our algorithm accelerates the sampling procedure of MR\nDiffusion, making it more practical in controllable generation.",
      "tldr_zh": "本论文提出MaRS算法，这是一种快速采样器，针对Mean Reverting Diffusion模型，通过求解随机微分方程(SDE)和概率流常微分方程(PF-ODE)来减少采样过程中的函数评估次数(NFEs)。MaRS算法推导出半解析解，包括一个解析函数和一个由神经网络参数化的积分，从而在不需额外训练的情况下，支持噪声预测、数据预测和速度预测等主流参数化。实验结果显示，在十个图像恢复任务上，MaRS将采样速度提高10到20倍，同时保持高生成质量，使Mean Reverting Diffusion在可控生成应用中更具实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07856v4",
      "published_date": "2025-02-11 14:57:33 UTC",
      "updated_date": "2025-03-24 15:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:00:26.243914"
    },
    {
      "arxiv_id": "2502.07591v1",
      "title": "DMWM: Dual-Mind World Model with Long-Term Imagination",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyi Wang",
        "Rashed Shelim",
        "Walid Saad",
        "Naren Ramakrishnan"
      ],
      "abstract": "Imagination in world models is crucial for enabling agents to learn\nlong-horizon policy in a sample-efficient manner. Existing recurrent\nstate-space model (RSSM)-based world models depend on single-step statistical\ninference to capture the environment dynamics, and, hence, they are unable to\nperform long-term imagination tasks due to the accumulation of prediction\nerrors. Inspired by the dual-process theory of human cognition, we propose a\nnovel dual-mind world model (DMWM) framework that integrates logical reasoning\nto enable imagination with logical consistency. DMWM is composed of two\ncomponents: an RSSM-based System 1 (RSSM-S1) component that handles state\ntransitions in an intuitive manner and a logic-integrated neural network-based\nSystem 2 (LINN-S2) component that guides the imagination process through\nhierarchical deep logical reasoning. The inter-system feedback mechanism is\ndesigned to ensure that the imagination process follows the logical rules of\nthe real environment. The proposed framework is evaluated on benchmark tasks\nthat require long-term planning from the DMControl suite. Extensive\nexperimental results demonstrate that the proposed framework yields significant\nimprovements in terms of logical coherence, trial efficiency, data efficiency\nand long-term imagination over the state-of-the-art world models.",
      "tldr_zh": "本研究提出 DMWM（Dual-Mind World Model）框架，受人类认知双过程理论启发，旨在解决现有 RSSM-based 世界模型在长程想象中因预测错误积累而导致的问题。DMWM 包括 RSSM-S1 组件负责直观的状态转换，以及 LINN-S2 组件通过分层深度逻辑推理引导想象过程，并借助 inter-system feedback 机制确保逻辑一致性。在 DMControl suite 的基准任务上，实验结果显示 DMWM 在逻辑 coherence、试验效率、数据效率和长程想象方面显著优于现有最先进模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07591v1",
      "published_date": "2025-02-11 14:40:57 UTC",
      "updated_date": "2025-02-11 14:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:00:37.885227"
    },
    {
      "arxiv_id": "2502.07586v1",
      "title": "We Can't Understand AI Using our Existing Vocabulary",
      "title_zh": "我们无法使用现有词汇理解 AI",
      "authors": [
        "John Hewitt",
        "Robert Geirhos",
        "Been Kim"
      ],
      "abstract": "This position paper argues that, in order to understand AI, we cannot rely on\nour existing vocabulary of human words. Instead, we should strive to develop\nneologisms: new words that represent precise human concepts that we want to\nteach machines, or machine concepts that we need to learn. We start from the\npremise that humans and machines have differing concepts. This means\ninterpretability can be framed as a communication problem: humans must be able\nto reference and control machine concepts, and communicate human concepts to\nmachines. Creating a shared human-machine language through developing\nneologisms, we believe, could solve this communication problem. Successful\nneologisms achieve a useful amount of abstraction: not too detailed, so they're\nreusable in many contexts, and not too high-level, so they convey precise\ninformation. As a proof of concept, we demonstrate how a \"length neologism\"\nenables controlling LLM response length, while a \"diversity neologism\" allows\nsampling more variable responses. Taken together, we argue that we cannot\nunderstand AI using our existing vocabulary, and expanding it through\nneologisms creates opportunities for both controlling and understanding\nmachines better.",
      "tldr_zh": "这篇论文主张，为了更好地理解 AI，我们不能依赖现有的词汇，而应开发新词（neologisms），以精确表示人类概念（教给机器）或机器概念（人类学习）。它将 AI 可解释性（interpretability）视为一个沟通问题，通过创建共享的人机语言来桥接人类和机器概念的差异。论文强调，成功的 neologisms 需要适度的抽象水平，便于重用且传达精确信息；作为证明，它展示了“length neologism”用于控制大型语言模型（LLM）的响应长度，以及“diversity neologism”用于采样更多变异的响应。总之，这为提升对机器的控制和理解提供了新机会。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Position paper",
      "pdf_url": "http://arxiv.org/pdf/2502.07586v1",
      "published_date": "2025-02-11 14:34:05 UTC",
      "updated_date": "2025-02-11 14:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:00:50.445810"
    },
    {
      "arxiv_id": "2502.07577v2",
      "title": "Automated Capability Discovery via Model Self-Exploration",
      "title_zh": "基于模型自我探索的自动能力发现",
      "authors": [
        "Cong Lu",
        "Shengran Hu",
        "Jeff Clune"
      ],
      "abstract": "Foundation models have become general-purpose assistants, exhibiting diverse\ncapabilities across numerous domains through training on web-scale data. It\nremains challenging to precisely characterize even a fraction of the full\nspectrum of capabilities and potential risks in any new model. Existing\nevaluation approaches often require significant human effort, and it is taking\nincreasing effort to design ever harder challenges for more capable models. We\nintroduce Automated Capability Discovery (ACD), a framework that designates one\nfoundation model as a scientist to systematically propose open-ended tasks\nprobing the abilities of a subject model (potentially itself). By combining\nfrontier models with ideas from the field of open-endedness, ACD automatically\nand systematically uncovers both surprising capabilities and failures in the\nsubject model. We demonstrate ACD across a range of foundation models\n(including the GPT, Claude, and Llama series), showing that it automatically\nreveals thousands of capabilities that would be challenging for any single team\nto uncover. We further validate our method's automated scoring with extensive\nhuman surveys, observing high agreement between model-generated and human\nevaluations. By leveraging foundation models' ability to both create tasks and\nself-evaluate, ACD is a significant step toward scalable, automated evaluation\nof novel AI systems. All code and evaluation logs are open-sourced at\nhttps://github.com/conglu1997/ACD.",
      "tldr_zh": "该论文提出 Automated Capability Discovery (ACD) 框架，利用一个基础模型作为“科学家”来自动生成和测试任务，从而系统评估另一个模型（或自身）的能力，解决现有评估方法人力密集和挑战设计困难的问题。ACD 结合前沿模型和 open-endedness 理念，能够自动揭示数千种惊人能力和潜在失败，在 GPT、Claude 和 Llama 系列模型上进行实验证明其有效性。通过人类调查验证，ACD 的自动评分与人类评估高度一致。该框架标志着向可扩展的自动 AI 系统评估迈出重要一步，并已开源相关代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07577v2",
      "published_date": "2025-02-11 14:23:13 UTC",
      "updated_date": "2025-02-12 16:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:01:03.706874"
    },
    {
      "arxiv_id": "2502.07855v1",
      "title": "Vision-Language Models for Edge Networks: A Comprehensive Survey",
      "title_zh": "视觉语言模型用于边缘网络：全面综述",
      "authors": [
        "Ahmed Sharshar",
        "Latif U. Khan",
        "Waseem Ullah",
        "Mohsen Guizani"
      ],
      "abstract": "Vision Large Language Models (VLMs) combine visual understanding with natural\nlanguage processing, enabling tasks like image captioning, visual question\nanswering, and video analysis. While VLMs show impressive capabilities across\ndomains such as autonomous vehicles, smart surveillance, and healthcare, their\ndeployment on resource-constrained edge devices remains challenging due to\nprocessing power, memory, and energy limitations. This survey explores recent\nadvancements in optimizing VLMs for edge environments, focusing on model\ncompression techniques, including pruning, quantization, knowledge\ndistillation, and specialized hardware solutions that enhance efficiency. We\nprovide a detailed discussion of efficient training and fine-tuning methods,\nedge deployment challenges, and privacy considerations. Additionally, we\ndiscuss the diverse applications of lightweight VLMs across healthcare,\nenvironmental monitoring, and autonomous systems, illustrating their growing\nimpact. By highlighting key design strategies, current challenges, and offering\nrecommendations for future directions, this survey aims to inspire further\nresearch into the practical deployment of VLMs, ultimately making advanced AI\naccessible in resource-limited settings.",
      "tldr_zh": "这篇调查综述了视觉语言模型（VLMs）在边缘网络中的应用，探讨了其在资源受限设备上的部署挑战，如处理能力、内存和能源限制。论文重点介绍了优化技术，包括模型压缩方法（如pruning、quantization、knowledge distillation）和专用硬件解决方案，以及高效训练、微调和隐私考虑。调查还涵盖了VLMs在医疗、环境监测和自治系统等领域的多样应用，并提供设计策略、当前挑战和未来推荐，以促进先进AI在资源有限环境的实际部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07855v1",
      "published_date": "2025-02-11 14:04:43 UTC",
      "updated_date": "2025-02-11 14:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:01:15.245659"
    },
    {
      "arxiv_id": "2502.09649v1",
      "title": "Imit Diff: Semantics Guided Diffusion Transformer with Dual Resolution Fusion for Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Dong",
        "Haizhou Ge",
        "Yupei Zeng",
        "Jiangning Zhang",
        "Beiwen Tian",
        "Guanzhong Tian",
        "Hongrui Zhu",
        "Yufei Jia",
        "Ruixiang Wang",
        "Ran Yi",
        "Guyue Zhou",
        "Longhua Ma"
      ],
      "abstract": "Visuomotor imitation learning enables embodied agents to effectively acquire\nmanipulation skills from video demonstrations and robot proprioception.\nHowever, as scene complexity and visual distractions increase, existing methods\nthat perform well in simple scenes tend to degrade in performance. To address\nthis challenge, we introduce Imit Diff, a semanstic guided diffusion\ntransformer with dual resolution fusion for imitation learning. Our approach\nleverages prior knowledge from vision language foundation models to translate\nhigh-level semantic instruction into pixel-level visual localization. This\ninformation is explicitly integrated into a multi-scale visual enhancement\nframework, constructed with a dual resolution encoder. Additionally, we\nintroduce an implementation of Consistency Policy within the diffusion\ntransformer architecture to improve both real-time performance and motion\nsmoothness in embodied agent control.We evaluate Imit Diff on several\nchallenging real-world tasks. Due to its task-oriented visual localization and\nfine-grained scene perception, it significantly outperforms state-of-the-art\nmethods, especially in complex scenes with visual distractions, including\nzero-shot experiments focused on visual distraction and category\ngeneralization. The code will be made publicly available.",
      "tldr_zh": "本研究提出Imit Diff，一种语义引导的Diffusion Transformer框架，结合双分辨率融合，用于提升视觉运动模仿学习(Imitation Learning)在复杂场景中的性能。该方法利用视觉语言基础模型(Vision Language Foundation Models)的先验知识，将高层语义指令转化为像素级视觉定位，并通过多尺度视觉增强和Consistency Policy优化实时性能及运动平滑度。实验结果显示，Imit Diff在多个真实世界任务上显著优于现有方法，尤其在视觉干扰和类别泛化方面的零样本实验中，展示了其在复杂环境下的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09649v1",
      "published_date": "2025-02-11 14:03:57 UTC",
      "updated_date": "2025-02-11 14:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:01:27.893290"
    },
    {
      "arxiv_id": "2502.07563v1",
      "title": "LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid",
      "title_zh": "翻译失败",
      "authors": [
        "Weigao Sun",
        "Disen Lan",
        "Yiran Zhong",
        "Xiaoye Qu",
        "Yu Cheng"
      ],
      "abstract": "Linear sequence modeling approaches, such as linear attention, provide\nadvantages like linear-time training and constant-memory inference over\nsequence lengths. However, existing sequence parallelism (SP) methods are\neither not optimized for the right-product-first feature of linear attention or\nuse a ring-style communication strategy, which results in lower computation\nparallelism, limits their scalability for longer sequences in distributed\nsystems. In this paper, we introduce LASP-2, a new SP method to enhance both\ncommunication and computation parallelism when training linear attention\ntransformer models with very-long input sequences. Compared to previous work\nLASP, LASP-2 rethinks the minimal communication requirement for SP on linear\nattention layers, reorganizes the whole communication-computation workflow of\nLASP. In this way, only one single AllGather collective communication is needed\non intermediate memory states, whose sizes are independent of the sequence\nlength, leading to significant improvements of both communication and\ncomputation parallelism, as well as their overlap. Additionally, we extend\nLASP-2 to LASP-2H by applying similar communication redesign to standard\nattention modules, offering an efficient SP solution for hybrid models that\nblend linear and standard attention layers. Our evaluation on a Linear-Llama3\nmodel, a variant of Llama3 with linear attention replacing standard attention,\ndemonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2\nachieves training speed improvements of 15.2% over LASP and 36.6% over Ring\nAttention, with a sequence length of 2048K across 64 GPUs. The Code is released\nas a part of: https://github.com/OpenSparseLLMs/Linear-MoE.",
      "tldr_zh": "本论文重新思考了序列并行（Sequence Parallelism, SP）在线性注意力（Linear Attention）中的优化问题，提出LASP-2方法，以提升线性注意力Transformer模型在长序列训练中的通信和计算并行性。LASP-2通过重新设计通信-计算工作流，仅需一个AllGather集体通信操作，且通信量独立于序列长度，从而显著提高并行性和重叠效率。与LASP相比，LASP-2还扩展到LASP-2H，支持混合模型的标准化注意力模块。实验结果显示，在Linear-Llama3模型上，LASP-2在64 GPUs和序列长度2048K的场景下，比LASP快15.2%，比Ring Attention快36.6%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical report, 17 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.07563v1",
      "published_date": "2025-02-11 14:01:39 UTC",
      "updated_date": "2025-02-11 14:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:01:41.013126"
    },
    {
      "arxiv_id": "2502.07562v1",
      "title": "LoRP-TTS: Low-Rank Personalized Text-To-Speech",
      "title_zh": "LoRP-TTS：低秩个性化文本到语音",
      "authors": [
        "Łukasz Bondaruk",
        "Jakub Kubiak"
      ],
      "abstract": "Speech synthesis models convert written text into natural-sounding audio.\nWhile earlier models were limited to a single speaker, recent advancements have\nled to the development of zero-shot systems that generate realistic speech from\na wide range of speakers using their voices as additional prompts. However,\nthey still struggle with imitating non-studio-quality samples that differ\nsignificantly from the training datasets. In this work, we demonstrate that\nutilizing Low-Rank Adaptation (LoRA) allows us to successfully use even single\nrecordings of spontaneous speech in noisy environments as prompts. This\napproach enhances speaker similarity by up to $30pp$ while preserving content\nand naturalness. It represents a significant step toward creating truly diverse\nspeech corpora, that is crucial in all speech-related tasks.",
      "tldr_zh": "本文提出 LoRP-TTS，一种基于 Low-Rank Adaptation (LoRA) 的个性化 Text-To-Speech (TTS) 系统，旨在解决现有零样本语音合成模型在处理非工作室质量音频（如噪音环境中的自发语音）时的局限性。该方法允许使用单一录音作为提示，大幅提升说话者相似度高达 30pp，同时保持语音内容和自然性。LoRP-TTS 的创新为构建多样化语音语料库提供了关键进展，对各种语音相关任务具有重要意义。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07562v1",
      "published_date": "2025-02-11 14:00:12 UTC",
      "updated_date": "2025-02-11 14:00:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:01:50.737602"
    },
    {
      "arxiv_id": "2502.07552v1",
      "title": "Unsupervised Translation of Emergent Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Ido Levy",
        "Orr Paradise",
        "Boaz Carmeli",
        "Ron Meir",
        "Shafi Goldwasser",
        "Yonatan Belinkov"
      ],
      "abstract": "Emergent Communication (EC) provides a unique window into the language\nsystems that emerge autonomously when agents are trained to jointly achieve\nshared goals. However, it is difficult to interpret EC and evaluate its\nrelationship with natural languages (NL). This study employs unsupervised\nneural machine translation (UNMT) techniques to decipher ECs formed during\nreferential games with varying task complexities, influenced by the semantic\ndiversity of the environment. Our findings demonstrate UNMT's potential to\ntranslate EC, illustrating that task complexity characterized by semantic\ndiversity enhances EC translatability, while higher task complexity with\nconstrained semantic variability exhibits pragmatic EC, which, although\nchallenging to interpret, remains suitable for translation. This research marks\nthe first attempt, to our knowledge, to translate EC without the aid of\nparallel data.",
      "tldr_zh": "本研究探讨了Emergent Communication (EC)，即代理在共同实现共享目标时自发形成的语言系统，并使用无监督神经机器翻译(UNMT)技术来解读EC，这些EC产生于不同任务复杂度的参照游戏中，受环境语义多样性的影响。结果表明，UNMT能够成功翻译EC，且任务复杂度的语义多样性显著提高了EC的可翻译性，而更高复杂度的实用性EC虽更难解读，但仍适合翻译。该工作首次在无监督条件下实现了EC的翻译尝试，为理解EC与自然语言的关系提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages (including appendix and bibliography), Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07552v1",
      "published_date": "2025-02-11 13:41:06 UTC",
      "updated_date": "2025-02-11 13:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:02:03.000009"
    },
    {
      "arxiv_id": "2502.07549v1",
      "title": "HGTUL: A Hypergraph-based Model For Trajectory User Linking",
      "title_zh": "HGTUL：基于超图的轨迹用户链接模型",
      "authors": [
        "Fengjie Chang",
        "Xinning Zhu",
        "Zheng Hu",
        "Yang Qin"
      ],
      "abstract": "Trajectory User Linking (TUL), which links anonymous trajectories with users\nwho generate them, plays a crucial role in modeling human mobility. Despite\nsignificant advancements in this field, existing studies primarily neglect the\nhigh-order inter-trajectory relationships, which represent complex associations\namong multiple trajectories, manifested through multi-location co-occurrence\npatterns emerging when trajectories intersect at various Points of Interest\n(POIs). Furthermore, they also overlook the variable influence of POIs on\ndifferent trajectories, as well as the user class imbalance problem caused by\ndisparities in user activity levels and check-in frequencies. To address these\nlimitations, we propose a novel HyperGraph-based multi-perspective Trajectory\nUser Linking model (HGTUL). Our model learns trajectory representations from\nboth relational and spatio-temporal perspectives: (1) it captures high-order\nassociations among trajectories by constructing a trajectory hypergraph and\nleverages a hypergraph attention network to learn the variable impact of POIs\non trajectories; (2) it models the spatio-temporal characteristics of\ntrajectories by incorporating their temporal and spatial information into a\nsequential encoder. Moreover, we design a data balancing method to effectively\naddress the user class imbalance problem and experimentally validate its\nsignificance in TUL. Extensive experiments on three real-world datasets\ndemonstrate that HGTUL outperforms state-of-the-art baselines, achieving\nimprovements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics,\nrespectively.",
      "tldr_zh": "本文提出 HGTUL，一种基于 HyperGraph 的多视角模型，用于 Trajectory User Linking (TUL)，旨在解决现有方法忽略的高阶轨迹间关系（如多轨迹在 POIs 的共现）、POI 对轨迹的可变影响以及用户类别不平衡问题。模型通过构建轨迹 hypergraph 和 hypergraph attention network 捕捉高阶关联，并结合顺序编码器融入轨迹的时空信息，同时设计数据平衡方法来处理不平衡问题。在三个真实数据集上的实验表明，HGTUL 比最先进基线在 ACC@1 和 Macro-F1 指标上分别提升了 2.57%~20.09% 和 5.68%~26.00%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68-07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07549v1",
      "published_date": "2025-02-11 13:39:35 UTC",
      "updated_date": "2025-02-11 13:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:02:16.441567"
    },
    {
      "arxiv_id": "2502.09648v1",
      "title": "UKTA: Unified Korean Text Analyzer",
      "title_zh": "UKTA：统一的韩文文本分析器",
      "authors": [
        "Seokho Ahn",
        "Junhyung Park",
        "Ganghee Go",
        "Chulhui Kim",
        "Jiho Jung",
        "Myung Sun Shin",
        "Do-Guk Kim",
        "Young-Duk Seo"
      ],
      "abstract": "Evaluating writing quality is complex and time-consuming often delaying\nfeedback to learners. While automated writing evaluation tools are effective\nfor English, Korean automated writing evaluation tools face challenges due to\ntheir inability to address multi-view analysis, error propagation, and\nevaluation explainability. To overcome these challenges, we introduce UKTA\n(Unified Korean Text Analyzer), a comprehensive Korea text analysis and writing\nevaluation system. UKTA provides accurate low-level morpheme analysis, key\nlexical features for mid-level explainability, and transparent high-level\nrubric-based writing scores. Our approach enhances accuracy and quadratic\nweighted kappa over existing baseline, positioning UKTA as a leading\nmulti-perspective tool for Korean text analysis and writing evaluation.",
      "tldr_zh": "该论文针对韩语自动写作评估工具的多视图分析、错误传播和评估解释性不足等问题，引入了 UKTA（Unified Korean Text Analyzer），一个全面的韩语文本分析和写作评估系统。UKTA 通过精确的低级形态素分析、关键词汇特征提供中级解释性，以及透明的高级基于rubric的写作分数，实现了多层次的文本评估。实验结果显示，UKTA 在准确性和 quadratic weighted kappa 上优于现有基线。总之，该系统为韩语写作反馈提供了高效、多视角的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by SAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.09648v1",
      "published_date": "2025-02-11 13:30:56 UTC",
      "updated_date": "2025-02-11 13:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:02:27.696845"
    },
    {
      "arxiv_id": "2502.07542v2",
      "title": "Exoplanet Transit Candidate Identification in TESS Full-Frame Images via a Transformer-Based Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Helem Salinas",
        "Rafael Brahm",
        "Greg Olmschenk",
        "Richard K. Barry",
        "Karim Pichara",
        "Stela Ishitani Silva",
        "Vladimir Araujo"
      ],
      "abstract": "The Transiting Exoplanet Survey Satellite (TESS) is surveying a large\nfraction of the sky, generating a vast database of photometric time series data\nthat requires thorough analysis to identify exoplanetary transit signals.\nAutomated learning approaches have been successfully applied to identify\ntransit signals. However, most existing methods focus on the classification and\nvalidation of candidates, while few efforts have explored new techniques for\nthe search of candidates. To search for new exoplanet transit candidates, we\npropose an approach to identify exoplanet transit signals without the need for\nphase folding or assuming periodicity in the transit signals, such as those\nobserved in multi-transit light curves. To achieve this, we implement a new\nneural network inspired by Transformers to directly process Full Frame Image\n(FFI) light curves to detect exoplanet transits. Transformers, originally\ndeveloped for natural language processing, have recently demonstrated\nsignificant success in capturing long-range dependencies compared to previous\napproaches focused on sequential data. This ability allows us to employ\nmulti-head self-attention to identify exoplanet transit signals directly from\nthe complete light curves, combined with background and centroid time series,\nwithout requiring prior transit parameters. The network is trained to learn\ncharacteristics of the transit signal, like the dip shape, which helps\ndistinguish planetary transits from other variability sources. Our model\nsuccessfully identified 214 new planetary system candidates, including 122\nmulti-transit light curves, 88 single-transit and 4 multi-planet systems from\nTESS sectors 1-26 with a radius > 0.27 $R_{\\mathrm{Jupiter}}$, demonstrating\nits ability to detect transits regardless of their periodicity.",
      "tldr_zh": "本文提出了一种基于Transformer的算法，用于在TESS全帧图像(Full Frame Image)中识别系外行星(exoplanet)凌星候选物，该方法无需相位折叠或假设信号周期性，直接处理光变曲线、背景和质心时序数据。算法利用多头自注意力(multi-head self-attention)机制捕捉长程依赖，学习凌星信号的特征，如信号下降形状，以区分行星凌星与其他变异源。在TESS sectors 1-26的数据上，该模型成功识别了214个新行星系统候选物，包括122个多凌星(multi-transit)光变曲线、88个单凌星(single-transit)和4个多行星系统，行星半径大于0.27 $R_{\\mathrm{Jupiter}}$，展示了其在非周期性检测方面的强大能力。",
      "categories": [
        "astro-ph.EP",
        "astro-ph.GA",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07542v2",
      "published_date": "2025-02-11 13:29:58 UTC",
      "updated_date": "2025-03-07 17:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:02:40.825155"
    },
    {
      "arxiv_id": "2502.15755v2",
      "title": "Physics-consistent machine learning: output projection onto physical manifolds",
      "title_zh": "翻译失败",
      "authors": [
        "Matilde Valente",
        "Tiago C. Dias",
        "Vasco Guerra",
        "Rodrigo Ventura"
      ],
      "abstract": "Data-driven machine learning models often require extensive datasets, which\ncan be costly or inaccessible, and their predictions may fail to comply with\nestablished physical laws. Current approaches for incorporating physical priors\nmitigate these issues by penalizing deviations from known physical laws, as in\nphysics-informed neural networks, or by designing architectures that\nautomatically satisfy specific invariants. However, penalization approaches do\nnot guarantee compliance with physical constraints for unseen inputs, and\ninvariant-based methods lack flexibility and generality. We propose a novel\nphysics-consistent machine learning method that directly enforces compliance\nwith physical principles by projecting model outputs onto the manifold defined\nby these laws. This procedure ensures that predictions inherently adhere to the\nchosen physical constraints, improving reliability and interpretability. Our\nmethod is demonstrated on two systems: a spring-mass system and a\nlow-temperature reactive plasma. Compared to purely data-driven models, our\napproach significantly reduces errors in physical law compliance, enhances\npredictive accuracy of physical quantities, and outperforms alternatives when\nworking with simpler models or limited datasets. The proposed projection-based\ntechnique is versatile and can function independently or in conjunction with\nexisting physics-informed neural networks, offering a powerful, general, and\nscalable solution for developing fast and reliable surrogate models of complex\nphysical systems, particularly in resource-constrained scenarios.",
      "tldr_zh": "这篇论文提出了一种新的 physics-consistent machine learning 方法，通过将模型输出投影到 physical manifolds 上，直接强制预测符合物理定律，从而解决数据驱动模型在遵守物理约束方面的局限性。相比传统 penalization 或 invariant-based 方法，该技术确保了预测的可靠性和可解释性，并在弹簧-质量系统和低温反应等离子体系统中实验中表现出色。结果显示，该方法显著降低了物理定律遵守错误，提高了预测准确性，尤其适用于简单模型或有限数据集的资源受限场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.plasm-ph",
        "68T07"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15755v2",
      "published_date": "2025-02-11 13:18:19 UTC",
      "updated_date": "2025-03-06 21:52:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:02:50.671791"
    },
    {
      "arxiv_id": "2502.13149v3",
      "title": "Bi-Fact: A Bidirectional Factorization-based Evaluation of Intent Extraction from UI Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Sapir Caduri",
        "Anatoly Efros",
        "Noam Kahlon",
        "Danielle Cohen",
        "Yoni Halpern",
        "Ido Dagan"
      ],
      "abstract": "Evaluating intent extraction from GUIs demands accurate, fine-grained\nmetrics. This paper introduces Bi-Fact, a novel method that decomposes intents\ninto atomic facts and performs bidirectional comparisons to assess precision\nand recall. Experiments demonstrate Bi-Fact's superior correlation with human\njudgments compared to existing metrics, establishing a more robust evaluation\nframework for UI-driven intent understanding.",
      "tldr_zh": "这篇论文提出了 Bi-Fact，一种基于双向分解的新型方法，用于评估从 GUI 轨迹中提取意图的精确性。Bi-Fact 通过将意图分解成原子 facts，并进行 bidirectional comparisons，来细粒度地测量 precision 和 recall。实验结果显示，Bi-Fact 与现有指标相比，在与人类判断的相关性上表现出色，为 UI-driven intent understanding 建立了更稳健的评估框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13149v3",
      "published_date": "2025-02-11 13:16:31 UTC",
      "updated_date": "2025-03-05 09:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:03:03.597760"
    },
    {
      "arxiv_id": "2502.07531v3",
      "title": "VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sixiao Zheng",
        "Zimian Peng",
        "Yanpeng Zhou",
        "Yi Zhu",
        "Hang Xu",
        "Xiangru Huang",
        "Yanwei Fu"
      ],
      "abstract": "Recent image-to-video generation methods have demonstrated success in\nenabling control over one or two visual elements, such as camera motion or\nobject motion. However, these methods are unable to offer control over multiple\nvisual elements due to limitations in data and network efficacy. In this paper,\nwe introduce VidCRAFT3, a novel framework for precise image-to-video generation\nthat enables control over camera motion, object motion, and lighting direction\nsimultaneously. VidCRAFT3 integrates three core components: Image2Cloud\ngenerates 3D point cloud from a reference image; ObjMotionNet encodes sparse\nobject trajectories using multi-scale optical flow features; and Spatial\nTriple-Attention Transformer incorporates lighting direction embeddings via\nparallel cross-attention modules. Additionally, we introduce the\nVideoLightingDirection dataset, providing synthetic yet realistic video clips\nwith accurate per-frame lighting direction annotations, effectively mitigating\nthe lack of annotated real-world datasets. We further adopt a three-stage\ntraining strategy, ensuring robust learning even without joint multi-element\nannotations. Extensive experiments show that VidCRAFT3 produces high-quality\nvideo content, outperforming state-of-the-art methods in control granularity\nand visual coherence. Code and data will be publicly available.",
      "tldr_zh": "该研究提出 VidCRAFT3，一种用于图像到视频生成的创新框架，能够同时精确控制相机运动、物体运动和灯光方向，解决了现有方法在多元素控制上的局限。框架的核心组件包括 Image2Cloud（从参考图像生成3D点云）、ObjMotionNet（使用多尺度光流特征编码物体轨迹）和 Spatial Triple-Attention Transformer（通过并行交叉注意力模块整合灯光方向嵌入）。此外，作者引入了 VideoLightingDirection 数据集，提供合成且真实的视频剪辑及其灯光方向标注，并采用三阶段训练策略来处理标注不足的问题。实验结果显示，VidCRAFT3 在控制粒度和视觉连贯性上优于现有方法，生成高质量视频内容。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07531v3",
      "published_date": "2025-02-11 13:11:59 UTC",
      "updated_date": "2025-04-02 03:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:03:15.038307"
    },
    {
      "arxiv_id": "2502.07527v2",
      "title": "Nature Language Model: Deciphering the Language of Nature for Scientific Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Yingce Xia",
        "Peiran Jin",
        "Shufang Xie",
        "Liang He",
        "Chuan Cao",
        "Renqian Luo",
        "Guoqing Liu",
        "Yue Wang",
        "Zequn Liu",
        "Yuan-Jyue Chen",
        "Zekun Guo",
        "Yeqi Bai",
        "Pan Deng",
        "Yaosen Min",
        "Ziheng Lu",
        "Hongxia Hao",
        "Han Yang",
        "Jielan Li",
        "Chang Liu",
        "Jia Zhang",
        "Jianwei Zhu",
        "Ran Bi",
        "Kehan Wu",
        "Wei Zhang",
        "Kaiyuan Gao",
        "Qizhi Pei",
        "Qian Wang",
        "Xixian Liu",
        "Yanting Li",
        "Houtian Zhu",
        "Yeqing Lu",
        "Mingqian Ma",
        "Zun Wang",
        "Tian Xie",
        "Krzysztof Maziarz",
        "Marwin Segler",
        "Zhao Yang",
        "Zilong Chen",
        "Yu Shi",
        "Shuxin Zheng",
        "Lijun Wu",
        "Chen Hu",
        "Peggy Dai",
        "Tie-Yan Liu",
        "Haiguang Liu",
        "Tao Qin"
      ],
      "abstract": "Foundation models have revolutionized natural language processing and\nartificial intelligence, significantly enhancing how machines comprehend and\ngenerate human languages. Inspired by the success of these foundation models,\nresearchers have developed foundation models for individual scientific domains,\nincluding small molecules, materials, proteins, DNA, RNA and even cells.\nHowever, these models are typically trained in isolation, lacking the ability\nto integrate across different scientific domains. Recognizing that entities\nwithin these domains can all be represented as sequences, which together form\nthe \"language of nature\", we introduce Nature Language Model (NatureLM), a\nsequence-based science foundation model designed for scientific discovery.\nPre-trained with data from multiple scientific domains, NatureLM offers a\nunified, versatile model that enables various applications including: (i)\ngenerating and optimizing small molecules, proteins, RNA, and materials using\ntext instructions; (ii) cross-domain generation/design, such as\nprotein-to-molecule and protein-to-RNA generation; and (iii) top performance\nacross different domains, matching or surpassing state-of-the-art specialist\nmodels. NatureLM offers a promising generalist approach for various scientific\ntasks, including drug discovery (hit generation/optimization, ADMET\noptimization, synthesis), novel material design, and the development of\ntherapeutic proteins or nucleotides. We have developed NatureLM models in\ndifferent sizes (1 billion, 8 billion, and 46.7 billion parameters) and\nobserved a clear improvement in performance as the model size increases.",
      "tldr_zh": "本论文提出 NatureLM，这是一个基于序列的科学基础模型，旨在通过将小分子、材料、蛋白质、DNA、RNA 等科学实体视为“自然语言”序列，实现多领域数据的统一整合和科学发现。NatureLM 通过预训练多领域数据，支持各种应用，包括基于文本指令生成/优化小分子、蛋白质和材料，以及跨领域任务如蛋白质到分子的生成，并在这些任务中匹配或超越专业模型。实验结果显示，模型在不同规模（1 亿、8 亿和 46.7 亿参数）下性能逐步提升，为药物发现、材料设计和治疗蛋白质开发等提供了一个通用且高效的方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "93 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.07527v2",
      "published_date": "2025-02-11 13:08:03 UTC",
      "updated_date": "2025-03-06 12:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:03:27.590255"
    },
    {
      "arxiv_id": "2502.07523v1",
      "title": "Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Palenicek",
        "Florian Vogt",
        "Jan Peters"
      ],
      "abstract": "Reinforcement learning has achieved significant milestones, but sample\nefficiency remains a bottleneck for real-world applications. Recently, CrossQ\nhas demonstrated state-of-the-art sample efficiency with a low update-to-data\n(UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with\nhigher UTD ratios. We identify challenges in the training dynamics, which are\nemphasized by higher UTD ratios. To address these, we integrate weight\nnormalization into the CrossQ framework, a solution that stabilizes training,\nhas been shown to prevent potential loss of plasticity and keeps the effective\nlearning rate constant. Our proposed approach reliably scales with increasing\nUTD ratios, achieving competitive performance across 25 challenging continuous\ncontrol tasks on the DeepMind Control Suite and Myosuite benchmarks, notably\nthe complex dog and humanoid environments. This work eliminates the need for\ndrastic interventions, such as network resets, and offers a simple yet robust\npathway for improving sample efficiency and scalability in model-free\nreinforcement learning.",
      "tldr_zh": "这篇论文探讨了Off-Policy Reinforcement Learning的样本效率问题，通过扩展CrossQ框架来处理更高UTD比率下的训练动态挑战。作者将Weight Normalization整合到CrossQ中，以稳定训练过程、防止损失可塑性和保持有效学习率恒定，从而实现可靠的扩展。实验结果显示，该方法在DeepMind Control Suite和Myosuite基准的25个连续控制任务中取得了竞争性能，尤其在复杂环境如dog和humanoid中，提供了一个简单且稳健的途径来提升样本效率和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07523v1",
      "published_date": "2025-02-11 12:55:32 UTC",
      "updated_date": "2025-02-11 12:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:03:39.259443"
    },
    {
      "arxiv_id": "2502.07516v2",
      "title": "The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Raman Dutt"
      ],
      "abstract": "Generative models, particularly text-to-image (T2I) diffusion models, play a\ncrucial role in medical image analysis. However, these models are prone to\ntraining data memorization, posing significant risks to patient privacy.\nSynthetic chest X-ray generation is one of the most common applications in\nmedical image analysis with the MIMIC-CXR dataset serving as the primary data\nrepository for this task. This study presents the first systematic attempt to\nidentify prompts and text tokens in MIMIC-CXR that contribute the most to\ntraining data memorization. Our analysis reveals two unexpected findings: (1)\nprompts containing traces of de-identification procedures (markers introduced\nto hide Protected Health Information) are the most memorized, and (2) among all\ntokens, de-identification markers contribute the most towards memorization.\nThis highlights a broader issue with the standard anonymization practices and\nT2I synthesis with MIMIC-CXR. To exacerbate, existing inference-time\nmemorization mitigation strategies are ineffective and fail to sufficiently\nreduce the model's reliance on memorized text tokens. On this front, we propose\nactionable strategies for different stakeholders to enhance privacy and improve\nthe reliability of generative models in medical imaging. Finally, our results\nprovide a foundation for future work on developing and benchmarking\nmemorization mitigation techniques for synthetic chest X-ray generation using\nthe MIMIC-CXR dataset. The anonymized code is available at\nhttps://anonymous.4open.science/r/diffusion_memorization-8011/",
      "tldr_zh": "这篇论文探讨了 T2I diffusion models 在合成胸部 X 光图像时存在的训练数据记忆风险，特别是使用 MIMIC-CXR 数据集时，可能泄露患者隐私的问题。研究通过系统分析发现，包含 de-identification 痕迹的提示和文本标记是记忆贡献最大的因素，这暴露了标准匿名化实践的潜在缺陷。现有推理时缓解策略无效，因此论文提出针对不同利益相关者的可操作策略，以提升模型的隐私保护和可靠性。该工作为未来开发和基准测试记忆缓解技术提供了重要基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07516v2",
      "published_date": "2025-02-11 12:36:00 UTC",
      "updated_date": "2025-02-14 17:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:03:51.668213"
    },
    {
      "arxiv_id": "2502.08453v1",
      "title": "Proceedings 40th International Conference on Logic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Cabalar",
        "Francesco Fabiano",
        "Martin Gebser",
        "Gopal Gupta",
        "Theresa Swift"
      ],
      "abstract": "Since the first conference In Marseille in 1982, the International Conference\non Logic Programming (ICLP) has been the premier international event for\npresenting research in logic programming. These proceedings include technical\ncommunications about, and abstracts for presentations given at the 40th ICLP\nheld October 14-17, in Dallas Texas, USA. The papers and abstracts in this\nvolume include the following areas and topics. Formal and operational\nsemantics: including non-monotonic reasoning, probabilistic reasoning,\nargumentation, and semantic issues of combining logic with neural models.\nLanguage design and programming methodologies such as answer set programming.\ninductive logic programming, and probabilistic programming. Program analysis\nand logic-based validation of generated programs. Implementation methodologies\nincluding constraint implementation, tabling, Logic-based prompt engineering,\nand the interaction of logic programming with LLMs.",
      "tldr_zh": "本论文集汇集了第40届国际逻辑编程会议(ICLP)的技术报告和摘要，该会议自1982年以来一直是逻辑编程领域的主要国际盛会，于2023年10月14-17日在美国达拉斯举行。内容涵盖形式和操作语义（如non-monotonic reasoning、probabilistic reasoning和argumentation）、语言设计和编程方法（包括answer set programming、inductive logic programming和probabilistic programming）、程序分析、逻辑-based验证以及实现技术（如constraint implementation、tabling和Logic-based prompt engineering）。这些论文突出了逻辑编程与神经模型结合等新兴主题，为该领域的研究创新提供了宝贵资源。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.08453v1",
      "published_date": "2025-02-11 12:13:52 UTC",
      "updated_date": "2025-02-11 12:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:04:04.493714"
    },
    {
      "arxiv_id": "2502.07503v4",
      "title": "Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ibrahim Alabdulmohsin",
        "Xiaohua Zhai"
      ],
      "abstract": "Inspired by recent findings on the fractal geometry of language, we introduce\nRecursive INference Scaling (RINS) as a complementary, plug-in recipe for\nscaling inference time in language and multimodal systems. RINS is a particular\nform of recursive depth that significantly outperforms +55 other variants,\nincluding the recent \"repeat-all-over\" (RAO) strategy in Mobile LLM (Liu et\nal., 2024) and latent recurrent thinking (Geiping et al., 2025). Unlike prior\nworks, we carry out our comparisons on a compute-matched regime, and\ndemonstrate that for a fixed model size and training compute budget, RINS\nsubstantially improves language modeling performance. It also generalizes\nbeyond pure language tasks, delivering gains in multimodal systems, including a\n+2% improvement in 0-shot ImageNet accuracy for SigLIP-B/16. Additionally, by\nderiving data scaling laws, we show that RINS improves both the asymptotic\nperformance limits and the scaling exponents. More importantly, with\nlight-weight (linear) adapters (comprising <1% of model parameters) and\nstochastic dropout, RINS offers a no-regret strategy, meaning that RINS-enabled\npretraining improves performance in language modeling even when recursive depth\nis not applied at inference time. This corresponds to improving performance on\na training compute-, parameter-, and inference-matched regime, suggesting its\npotential as a viable component of LLM pretraining!",
      "tldr_zh": "本研究引入了Recursive INference Scaling (RINS)，一种基于语言分形几何的递归深度方法，用于扩展语言和多模态系统的推理时间，并显著优于包括RAO和latent recurrent thinking在内的55种变体。RINS在计算匹配条件下，能为固定模型大小和训练计算预算带来语言建模性能的实质性提升，同时在多模态任务中表现突出，如SigLIP-B/16的0-shot ImageNet准确率提升2%。通过数据缩放定律分析，RINS改善了渐近性能极限和缩放指数。更为重要的是，使用轻量级线性适配器（少于1%模型参数）和随机dropout，RINS提供了一种无遗憾策略，即使在推理时不启用递归深度，也能提升LLM预训练性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07503v4",
      "published_date": "2025-02-11 12:11:40 UTC",
      "updated_date": "2025-05-08 11:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:04:15.980817"
    },
    {
      "arxiv_id": "2502.07494v1",
      "title": "URECA: The Chain of Two Minimum Set Cover Problems exists behind Adaptation to Shifts in Semantic Code Search",
      "title_zh": "翻译失败",
      "authors": [
        "Seok-Ung Choi",
        "Joonghyuk Hahn",
        "Yo-Sub Han"
      ],
      "abstract": "Adaptation is to make model learn the patterns shifted from the training\ndistribution. In general, this adaptation is formulated as the minimum entropy\nproblem. However, the minimum entropy problem has inherent limitation --\nshifted initialization cascade phenomenon. We extend the relationship between\nthe minimum entropy problem and the minimum set cover problem via Lebesgue\nintegral. This extension reveals that internal mechanism of the minimum entropy\nproblem ignores the relationship between disentangled representations, which\nleads to shifted initialization cascade. From the analysis, we introduce a new\nclustering algorithm, Union-find based Recursive Clustering Algorithm~(URECA).\nURECA is an efficient clustering algorithm for the leverage of the\nrelationships between disentangled representations. The update rule of URECA\ndepends on Thresholdly-Updatable Stationary Assumption to dynamics as a\nreleased version of Stationary Assumption. This assumption helps URECA to\ntransport disentangled representations with no errors based on the\nrelationships between disentangled representations. URECA also utilize\nsimulation trick to efficiently cluster disentangled representations. The wide\nrange of evaluations show that URECA achieves consistent performance gains for\nthe few-shot adaptation to diverse types of shifts along with advancement to\nState-of-The-Art performance in CoSQA in the scenario of query shift.",
      "tldr_zh": "该论文分析了模型在语义代码搜索中适应分布偏移的问题，将其表述为最小熵问题，但该问题存在偏移初始化级联的固有局限性，并通过 Lebesgue integral 扩展了其与最小集合覆盖问题(Minimum Set Cover)的关系，揭示了忽略解缠代表(disentangled representations)之间关系的机制。作者引入了一种新算法URECA（Union-find based Recursive Clustering Algorithm），它利用解缠代表之间的关系，并基于Thresholdly-Updatable Stationary Assumption的更新规则，通过模拟技巧高效聚类以无错误传输代表。实验结果显示，URECA在少样本适应多种偏移类型时实现了持续性能提升，并在CoSQA数据集的查询偏移场景中达到State-of-The-Art性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07494v1",
      "published_date": "2025-02-11 11:53:23 UTC",
      "updated_date": "2025-02-11 11:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:04:27.428219"
    },
    {
      "arxiv_id": "2502.07479v1",
      "title": "WebChecker: A Versatile EVL Plugin for Validating HTML Pages with Bootstrap Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Milind Cherukuri"
      ],
      "abstract": "WebChecker is a plugin for Epsilon Validation Language (EVL), designed to\nvalidate both static and dynamic HTML pages utilizing frameworks like\nBootstrap. By employing configurable EVL constraints, WebChecker enforces\nimplicit rules governing HTML and CSS frameworks. The effectiveness of the\nplugin is demonstrated through its application on Bootstrap, the widely adopted\nHTML, CSS, and JavaScript framework. WebChecker comes with a set of EVL\nconstraints to assess Bootstrap based web pages. To substantiate our claims, I\npresent an illustrative example featuring two solutions that effectively\nenforce implicit rules.",
      "tldr_zh": "本研究引入了 WebChecker，一种多功能 EVL (Epsilon Validation Language) 插件，用于验证基于 Bootstrap 等框架的静态和动态 HTML 页面。该插件通过可配置的 EVL 约束强制执行 HTML 和 CSS 框架的隐式规则，确保网页符合标准规范。以 Bootstrap 为例，WebChecker 提供了一套预定义的 EVL 约束，并通过实际示例证明了其有效性，在网页验证任务中展示了显著的实用价值。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07479v1",
      "published_date": "2025-02-11 11:40:43 UTC",
      "updated_date": "2025-02-11 11:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:04:37.858958"
    },
    {
      "arxiv_id": "2502.07469v1",
      "title": "5D Neural Surrogates for Nonlinear Gyrokinetic Simulations of Plasma Turbulence",
      "title_zh": "翻译失败",
      "authors": [
        "Gianluca Galletti",
        "Fabian Paischer",
        "Paul Setinek",
        "William Hornsby",
        "Lorenzo Zanisi",
        "Naomi Carey",
        "Stanislas Pamela",
        "Johannes Brandstetter"
      ],
      "abstract": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable\nenergy production. A major roadblock to achieving commercially viable fusion\npower is understanding plasma turbulence, which can significantly degrade\nplasma confinement. Modelling turbulence is crucial to design performing plasma\nscenarios for next-generation reactor-class devices and current experimental\nmachines. The nonlinear gyrokinetic equation underpinning turbulence modelling\nevolves a 5D distribution function over time. Solving this equation numerically\nis extremely expensive, requiring up to weeks for a single run to converge,\nmaking it unfeasible for iterative optimisation and control studies. In this\nwork, we propose a method for training neural surrogates for 5D gyrokinetic\nsimulations. Our method extends a hierarchical vision transformer to five\ndimensions and is trained on the 5D distribution function for the adiabatic\nelectron approximation. We demonstrate that our model can accurately infer\ndownstream physical quantities such as heat flux time trace and electrostatic\npotentials for single-step predictions two orders of magnitude faster than\nnumerical codes. Our work paves the way towards neural surrogates for plasma\nturbulence simulations to accelerate deployment of commercial energy production\nvia nuclear fusion.",
      "tldr_zh": "本论文针对核聚变能源中等离子体湍流建模的计算挑战，提出一种训练5D神经代理（neural surrogates）的方法，以加速非线性陀螺动力学模拟（nonlinear gyrokinetic simulations）。该方法扩展了hierarchical vision transformer到五维，并在adiabatic electron approximation下训练5D分布函数模型。结果显示，模型能比传统数值代码快两个数量级准确预测下游物理量，如heat flux和electrostatic potentials，从而为优化等离子体场景和推动核聚变商业部署铺平道路。",
      "categories": [
        "physics.plasm-ph",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "6 pages (+ references and appendix)",
      "pdf_url": "http://arxiv.org/pdf/2502.07469v1",
      "published_date": "2025-02-11 11:25:10 UTC",
      "updated_date": "2025-02-11 11:25:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:04:51.521430"
    },
    {
      "arxiv_id": "2502.07465v2",
      "title": "Crime Forecasting: A Spatio-temporal Analysis with Deep Learning Models",
      "title_zh": "犯罪预测：一种基于深度学习模型的时空分析",
      "authors": [
        "Li Mao",
        "Wei Du",
        "Shuo Wen",
        "Qi Li",
        "Tong Zhang",
        "Wei Zhong"
      ],
      "abstract": "This study uses deep-learning models to predict city partition crime counts\non specific days. It helps police enhance surveillance, gather intelligence,\nand proactively prevent crimes. We formulate crime count prediction as a\nspatiotemporal sequence challenge, where both input data and prediction targets\nare spatiotemporal sequences. In order to improve the accuracy of crime\nforecasting, we introduce a new model that combines Convolutional Neural\nNetworks (CNN) and Long Short-Term Memory (LSTM) networks. We conducted a\ncomparative analysis to access the effects of various data sequences, including\nraw and binned data, on the prediction errors of four deep learning forecasting\nmodels. Directly inputting raw crime data into the forecasting model causes\nhigh prediction errors, making the model unsuitable for real - world use. The\nfindings indicate that the proposed CNN-LSTM model achieves optimal performance\nwhen crime data is categorized into 10 or 5 groups. Data binning can enhance\nforecasting model performance, but poorly defined intervals may reduce map\ngranularity. Compared to dividing into 5 bins, binning into 10 intervals\nstrikes an optimal balance, preserving data characteristics and surpassing raw\ndata in predictive modelling efficacy.",
      "tldr_zh": "这篇论文使用深度学习模型预测城市分区在特定日期的犯罪数量，以帮助警察增强监控、情报收集和犯罪预防。研究将犯罪预测问题制定为时空序列挑战，并提出一个结合 Convolutional Neural Networks (CNN) 和 Long Short-Term Memory (LSTM) 的新模型，通过比较分析评估不同数据处理方式的影响。结果显示，直接输入原始数据会导致高预测错误，而将犯罪数据分箱为 10 或 5 组时，CNN-LSTM 模型表现出最佳性能，其中 10 个区间的分箱能有效平衡数据特征和预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper was submitted without the consent of all co-authors. The\n  content of the paper is incomplete and requires substantial additional work\n  before it can be considered a complete and coherent submission",
      "pdf_url": "http://arxiv.org/pdf/2502.07465v2",
      "published_date": "2025-02-11 11:16:59 UTC",
      "updated_date": "2025-02-13 14:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:05:03.620742"
    },
    {
      "arxiv_id": "2502.07461v2",
      "title": "JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinaba Roy",
        "Renhang Liu",
        "Tongyu Lu",
        "Dorien Herremans"
      ],
      "abstract": "We introduce JamendoMaxCaps, a large-scale music-caption dataset featuring\nover 362,000 freely licensed instrumental tracks from the renowned Jamendo\nplatform. The dataset includes captions generated by a state-of-the-art\ncaptioning model, enhanced with imputed metadata. We also introduce a retrieval\nsystem that leverages both musical features and metadata to identify similar\nsongs, which are then used to fill in missing metadata using a local large\nlanguage model (LLLM). This approach allows us to provide a more comprehensive\nand informative dataset for researchers working on music-language understanding\ntasks. We validate this approach quantitatively with five different\nmeasurements. By making the JamendoMaxCaps dataset publicly available, we\nprovide a high-quality resource to advance research in music-language\nunderstanding tasks such as music retrieval, multimodal representation\nlearning, and generative music models.",
      "tldr_zh": "本研究引入了 JamendoMaxCaps，这是一个大规模音乐标题数据集，包含超过 362,000 首免费许可的器乐曲目，并通过状态-of-the-art 标题模型生成标题，同时使用检索系统结合音乐特征和 metadata 来识别相似歌曲，并借助本地大型语言模型 (LLLM) 填充缺失 metadata。\n这种方法通过五个不同测量进行定量验证，确保数据集的全面性和信息性。\nJamendoMaxCaps 的公开可用为音乐-语言理解任务提供高质量资源，支持音乐检索、多模态表示学习和生成音乐模型等领域的研究。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07461v2",
      "published_date": "2025-02-11 11:12:19 UTC",
      "updated_date": "2025-05-16 07:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:05:15.197100"
    },
    {
      "arxiv_id": "2502.07459v1",
      "title": "PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian",
      "title_zh": "翻译失败",
      "authors": [
        "Erfan Moosavi Monazzah",
        "Vahid Rahimzadeh",
        "Yadollah Yaghoobzadeh",
        "Azadeh Shakery",
        "Mohammad Taher Pilehvar"
      ],
      "abstract": "Large language models predominantly reflect Western cultures, largely due to\nthe dominance of English-centric training data. This imbalance presents a\nsignificant challenge, as LLMs are increasingly used across diverse contexts\nwithout adequate evaluation of their cultural competence in non-English\nlanguages, including Persian. To address this gap, we introduce PerCul, a\ncarefully constructed dataset designed to assess the sensitivity of LLMs toward\nPersian culture. PerCul features story-based, multiple-choice questions that\ncapture culturally nuanced scenarios. Unlike existing benchmarks, PerCul is\ncurated with input from native Persian annotators to ensure authenticity and to\nprevent the use of translation as a shortcut. We evaluate several\nstate-of-the-art multilingual and Persian-specific LLMs, establishing a\nfoundation for future research in cross-cultural NLP evaluation. Our\nexperiments demonstrate a 11.3% gap between best closed source model and\nlayperson baseline while the gap increases to 21.3% by using the best\nopen-weight model. You can access the dataset from here:\nhttps://huggingface.co/datasets/teias-ai/percul",
      "tldr_zh": "本论文探讨大型语言模型（LLMs）在非英语语言中的文化能力问题，特别是波斯语，并引入PerCul数据集来评估LLMs对波斯文化的敏感性。PerCul由本土波斯语注释者创建，包含基于故事的多选题问题，以捕捉文化细微差异并避免翻译捷径。实验评估了多种最先进的多语言和波斯语特定LLMs，结果显示最佳封闭源模型与普通人基线的差距为11.3%，而最佳开源模型的差距扩大至21.3%，突显了LLMs在跨文化NLP评估中的不足。该数据集可从Hugging Face获取，为未来研究奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 Main Conference, the dataset is available on\n  HuggingFace (see https://huggingface.co/datasets/teias-ai/percul)",
      "pdf_url": "http://arxiv.org/pdf/2502.07459v1",
      "published_date": "2025-02-11 11:07:44 UTC",
      "updated_date": "2025-02-11 11:07:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:05:27.532974"
    },
    {
      "arxiv_id": "2502.07455v1",
      "title": "RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Viacheslav Vasilev",
        "Julia Agafonova",
        "Nikolai Gerasimenko",
        "Alexander Kapitanov",
        "Polina Mikhailova",
        "Evelina Mironova",
        "Denis Dimitrov"
      ],
      "abstract": "Text-to-image generation models have gained popularity among users around the\nworld. However, many of these models exhibit a strong bias toward\nEnglish-speaking cultures, ignoring or misrepresenting the unique\ncharacteristics of other language groups, countries, and nationalities. The\nlack of cultural awareness can reduce the generation quality and lead to\nundesirable consequences such as unintentional insult, and the spread of\nprejudice. In contrast to the field of natural language processing, cultural\nawareness in computer vision has not been explored as extensively. In this\npaper, we strive to reduce this gap. We propose a RusCode benchmark for\nevaluating the quality of text-to-image generation containing elements of the\nRussian cultural code. To do this, we form a list of 19 categories that best\nrepresent the features of Russian visual culture. Our final dataset consists of\n1250 text prompts in Russian and their translations into English. The prompts\ncover a wide range of topics, including complex concepts from art, popular\nculture, folk traditions, famous people's names, natural objects, scientific\nachievements, etc. We present the results of a human evaluation of the\nside-by-side comparison of Russian visual concepts representations using\npopular generative models.",
      "tldr_zh": "本论文提出RusCode基准，用于评估文本到图像生成模型对俄罗斯文化元素的表现，以解决这些模型的文化偏见问题，如忽略非英语文化或导致意外冒犯。研究者定义了19个类别来代表俄罗斯视觉文化特征，并构建了一个包含1250个俄语提示及其英语翻译的数据集，涵盖艺术、流行文化、民俗传统、名人、自然对象和科学成就等主题。通过人类评估对流行生成模型进行侧-by-side比较，结果突显了模型在文化感知方面的不足，并为提升文化包容性提供了新路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for NAACL 2025 Findings, GitHub:\n  https://github.com/ai-forever/RusCode",
      "pdf_url": "http://arxiv.org/pdf/2502.07455v1",
      "published_date": "2025-02-11 10:57:12 UTC",
      "updated_date": "2025-02-11 10:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:05:38.975883"
    },
    {
      "arxiv_id": "2502.07452v1",
      "title": "Eliciting Rational Initial Weights in Gradual Argumentation",
      "title_zh": "翻译失败",
      "authors": [
        "Nir Oren",
        "Bruno Yun"
      ],
      "abstract": "Many semantics for weighted argumentation frameworks assume that each\nargument is associated with an initial weight. However, eliciting these initial\nweights poses challenges: (1) accurately providing a specific numerical value\nis often difficult, and (2) individuals frequently confuse initial weights with\nacceptability degrees in the presence of other arguments. To address these\nissues, we propose an elicitation pipeline that allows one to specify\nacceptability degree intervals for each argument. By employing gradual\nsemantics, we can refine these intervals when they are rational, restore\nrationality when they are not, and ultimately identify possible initial weights\nfor each argument.",
      "tldr_zh": "该论文探讨了在加权论辩框架中eliciting rational initial weights的挑战，主要是因为准确指定数值困难且易与acceptability degrees混淆。作者提出了一种elicitation pipeline，允许用户为每个论辩指定可接受度区间。通过gradual semantics，该方法可以精炼这些区间、恢复其理性，并最终识别出每个论辩的可能初始权重，从而改善权重分配的准确性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07452v1",
      "published_date": "2025-02-11 10:52:54 UTC",
      "updated_date": "2025-02-11 10:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:05:50.635635"
    },
    {
      "arxiv_id": "2502.07445v1",
      "title": "Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon",
      "title_zh": "翻译失败",
      "authors": [
        "Nurit Cohen-Inger",
        "Yehonatan Elisha",
        "Bracha Shapira",
        "Lior Rokach",
        "Seffi Cohen"
      ],
      "abstract": "Large language models (LLMs) often appear to excel on public benchmarks, but\nthese high scores may mask an overreliance on dataset-specific surface cues\nrather than true language understanding. We introduce the Chameleon Benchmark\nOverfit Detector (C-BOD), a meta-evaluation framework that systematically\ndistorts benchmark prompts via a parametric transformation and detects\noverfitting of LLMs. By rephrasing inputs while preserving their semantic\ncontent and labels, C-BOD exposes whether a model's performance is driven by\nmemorized patterns. Evaluated on the MMLU benchmark using 26 leading LLMs, our\nmethod reveals an average performance degradation of 2.15% under modest\nperturbations, with 20 out of 26 models exhibiting statistically significant\ndifferences. Notably, models with higher baseline accuracy exhibit larger\nperformance differences under perturbation, and larger LLMs tend to be more\nsensitive to rephrasings indicating that both cases may overrely on fixed\nprompt patterns. In contrast, the Llama family and models with lower baseline\naccuracy show insignificant degradation, suggesting reduced dependency on\nsuperficial cues. Moreover, C-BOD's dataset- and model-agnostic design allows\neasy integration into training pipelines to promote more robust language\nunderstanding. Our findings challenge the community to look beyond leaderboard\nscores and prioritize resilience and generalization in LLM evaluation.",
      "tldr_zh": "本文质疑了 LLMs 在公共基准上的高表现，指出这些成绩可能源于对数据集特定表面线索的过度依赖，而非真正的语言理解。研究引入了 Chameleon Benchmark Overfit Detector (C-BOD)，一个元评估框架，通过参数化转换重新表述提示以保留语义内容，同时检测模型的过拟合。实验在 MMLU 基准上评估了 26 个领先 LLMs，发现平均性能下降 2.15%，其中 20 个模型显示出统计显著差异，且高基准准确率和更大规模的 LLMs 对扰动更敏感。C-BOD 的设计独立于数据集和模型，便于集成训练管道，促进更稳健的语言理解，并呼吁评估社区关注 LLMs 的泛化和韧性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07445v1",
      "published_date": "2025-02-11 10:43:36 UTC",
      "updated_date": "2025-02-11 10:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:06:04.650220"
    },
    {
      "arxiv_id": "2502.07443v1",
      "title": "Approximating Human Strategic Reasoning with LLM-Enhanced Recursive Reasoners Leveraging Multi-agent Hypergames",
      "title_zh": "利用多智能体超游戏的LLM增强递归推理者逼近人类战略推理",
      "authors": [
        "Vince Trencsenyi",
        "Agnieszka Mensfelt",
        "Kostas Stathis"
      ],
      "abstract": "LLM-driven multi-agent-based simulations have been gaining traction with\napplications in game-theoretic and social simulations. While most\nimplementations seek to exploit or evaluate LLM-agentic reasoning, they often\ndo so with a weak notion of agency and simplified architectures. We implement a\nrole-based multi-agent strategic interaction framework tailored to\nsophisticated recursive reasoners, providing the means for systematic in-depth\ndevelopment and evaluation of strategic reasoning. Our game environment is\ngoverned by the umpire responsible for facilitating games, from matchmaking\nthrough move validation to environment management. Players incorporate\nstate-of-the-art LLMs in their decision mechanism, relying on a formal\nhypergame-based model of hierarchical beliefs. We use one-shot, 2-player beauty\ncontests to evaluate the recursive reasoning capabilities of the latest LLMs,\nproviding a comparison to an established baseline model from economics and data\nfrom human experiments. Furthermore, we introduce the foundations of an\nalternative semantic measure of reasoning to the k-level theory. Our\nexperiments show that artificial reasoners can outperform the baseline model in\nterms of both approximating human behaviour and reaching the optimal solution.",
      "tldr_zh": "本论文提出了一种利用 LLM 增强的递归推理器框架，通过多智能体 hypergames 来逼近人类战略推理，旨在系统评估和开发复杂递归推理能力。该框架采用角色-based 多智能体系统，由 umpire 管理游戏环境，并基于 hypergame 模型的层次化信念整合 LLM 进行决策。实验通过单次 2-player beauty contests 与经济学基准模型和人类数据比较，结果显示人工推理器在模拟人类行为和达到最优解方面均优于基准模型。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07443v1",
      "published_date": "2025-02-11 10:37:20 UTC",
      "updated_date": "2025-02-11 10:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:06:15.871379"
    },
    {
      "arxiv_id": "2502.07850v1",
      "title": "Mathematical reasoning and the computer",
      "title_zh": "数学推理与计算机",
      "authors": [
        "Kevin Buzzard"
      ],
      "abstract": "Computers have already changed the way that humans do mathematics: they\nenable us to compute efficiently. But will they soon be helping us to reason?\nAnd will they one day start reasoning themselves? We give an overview of recent\ndevelopments in neural networks, computer theorem provers and large language\nmodels.",
      "tldr_zh": "这篇论文探讨了计算机如何改变了人类进行数学推理的方式，目前主要通过高效计算来实现，并分析了计算机是否能辅助人类推理或未来实现独立推理。论文对神经网络、computer theorem provers 和 large language models 的最新发展进行了概述。这些进展表明，计算机在数学领域的潜力正从计算扩展到更高级的推理应用，为未来人工智能在数学中的角色提供了见解。",
      "categories": [
        "cs.AI",
        "68T01"
      ],
      "primary_category": "cs.AI",
      "comment": "This article was written in 2023 and is thus now rather out of date.\n  Apologies for taking so long to upload to ArXiv",
      "pdf_url": "http://arxiv.org/pdf/2502.07850v1",
      "published_date": "2025-02-11 10:35:52 UTC",
      "updated_date": "2025-02-11 10:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:06:27.421070"
    },
    {
      "arxiv_id": "2502.07441v1",
      "title": "SensPS: Sensing Personal Space Comfortable Distance between Human-Human Using Multimodal Sensors",
      "title_zh": "SensPS：使用多模态传感器感知人类之间个人空间舒适距离",
      "authors": [
        "Ko Watanabe",
        "Nico Förster",
        "Shoya Ishimaru"
      ],
      "abstract": "Personal space, also known as peripersonal space, is crucial in human social\ninteraction, influencing comfort, communication, and social stress. Estimating\nand respecting personal space is essential for enhancing human-computer\ninteraction (HCI) and smart environments. Personal space preferences vary due\nto individual traits, cultural background, and contextual factors. Advanced\nmultimodal sensing technologies, including eye-tracking and wristband sensors,\noffer opportunities to develop adaptive systems that dynamically adjust to user\ncomfort levels. Integrating physiological and behavioral data enables a deeper\nunderstanding of spatial interactions. This study develops a sensor-based model\nto estimate comfortable personal space and identifies key features influencing\nspatial preferences. Our findings show that multimodal sensors, particularly\neye-tracking and physiological wristband data, can effectively predict personal\nspace preferences, with eye-tracking data playing a more significant role. An\nexperimental study involving controlled human interactions demonstrates that a\nTransformer-based model achieves the highest predictive accuracy (F1 score:\n0.87) for estimating personal space. Eye-tracking features, such as gaze point\nand pupil diameter, emerge as the most significant predictors, while\nphysiological signals from wristband sensors contribute marginally. These\nresults highlight the potential for AI-driven personalization of social space\nin adaptive environments, suggesting that multimodal sensing can be leveraged\nto develop intelligent systems that optimize spatial arrangements in\nworkplaces, educational institutions, and public settings. Future work should\nexplore larger datasets, real-world applications, and additional physiological\nmarkers to enhance model robustness.",
      "tldr_zh": "本研究开发了 SensPS 系统，使用多模态传感器（如 eye-tracking 和 wristband 传感器）来估计人类之间舒适的个人空间距离，并考虑个体特征、文化背景和上下文因素。研究构建了一个 Transformer-based 模型，通过整合生理和行为数据，实现了高达 0.87 的 F1 score 预测准确率，其中 eye-tracking 特征（如 gaze point 和 pupil diameter）是主要预测因子，而 wristband 传感器数据贡献较小。这些发现突出了多模态传感在 AI 驱动社交空间个性化中的潜力，可应用于工作场所、教育机构和公共环境，以优化空间安排。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07441v1",
      "published_date": "2025-02-11 10:31:43 UTC",
      "updated_date": "2025-02-11 10:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:06:39.551052"
    },
    {
      "arxiv_id": "2502.07849v1",
      "title": "Understanding Classifier-Free Guidance: High-Dimensional Theory and Non-Linear Generalizations",
      "title_zh": "翻译失败",
      "authors": [
        "Krunoslav Lehman Pavasovic",
        "Jakob Verbeek",
        "Giulio Biroli",
        "Marc Mezard"
      ],
      "abstract": "Recent studies have raised concerns about the effectiveness of\nClassifier-Free Guidance (CFG), indicating that in low-dimensional settings, it\ncan lead to overshooting the target distribution and reducing sample diversity.\nIn this work, we demonstrate that in infinite and sufficiently high-dimensional\ncontexts CFG effectively reproduces the target distribution, revealing a\nblessing-of-dimensionality result. Additionally, we explore finite-dimensional\neffects, precisely characterizing overshoot and variance reduction. Based on\nour analysis, we introduce non-linear generalizations of CFG. Through numerical\nsimulations on Gaussian mixtures and experiments on class-conditional and\ntext-to-image diffusion models, we validate our analysis and show that our\nnon-linear CFG offers improved flexibility and generation quality without\nadditional computation cost.",
      "tldr_zh": "本文研究揭示了 Classifier-Free Guidance (CFG) 在高维空间中的有效性，证明在无限或足够高维的背景下，CFG 可以准确重现目标分布，这体现了 blessing-of-dimensionality 的优势，同时精确分析了有限维度下的过度射击（overshooting）和方差减少问题。基于这一理论分析，作者引入了 CFG 的非线性泛化方法，以提升其灵活性。实验通过高斯混合物模拟和在类条件及文本到图像扩散模型上的测试验证了这些发现，并显示非线性 CFG 显著提高了生成质量，而不增加计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07849v1",
      "published_date": "2025-02-11 10:29:29 UTC",
      "updated_date": "2025-02-11 10:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:06:51.372662"
    },
    {
      "arxiv_id": "2502.07424v2",
      "title": "RomanLens: The Role Of Latent Romanization In Multilinguality In LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Saji",
        "Jaavid Aktar Husain",
        "Thanmay Jayakumar",
        "Raj Dabre",
        "Anoop Kunchukuttan",
        "Ratish Puduppully"
      ],
      "abstract": "Large Language Models (LLMs) exhibit remarkable multilingual generalization\ndespite being predominantly trained on English-centric corpora. A fundamental\nquestion arises: how do LLMs achieve such robust multilingual capabilities? We\ntake the case of non-Roman script languages, we investigate the role of\nRomanization - the representation of non-Roman scripts using Roman characters -\nas a bridge in multilingual processing. Using mechanistic interpretability\ntechniques, we analyze next-token generation and find that intermediate layers\nfrequently represent target words in Romanized form before transitioning to\nnative script, a phenomenon we term Latent Romanization. Further, through\nactivation patching experiments, we demonstrate that LLMs encode semantic\nconcepts similarly across native and Romanized scripts, suggesting a shared\nunderlying representation. Additionally, for translation into non-Roman script\nlanguages, our findings reveal that when the target language is in Romanized\nform, its representations emerge earlier in the model's layers compared to\nnative script. These insights contribute to a deeper understanding of\nmultilingual representation in LLMs and highlight the implicit role of\nRomanization in facilitating language transfer.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在多语言泛化中的机制，特别关注非罗马脚本语言如何通过Latent Romanization（潜在罗马化）实现跨语言处理。研究采用mechanistic interpretability技术分析next-token generation，发现LLMs的中间层经常以Romanized形式表示目标单词，然后过渡到原生脚本，同时通过activation patching实验证明语义概念在不同脚本中共享底层表示。对于翻译任务，Romanized形式的目标语言表示在模型层中更早出现。这些发现加深了对LLMs多语言表示的理解，并突出了Romanization在促进语言转移的隐含作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07424v2",
      "published_date": "2025-02-11 10:10:26 UTC",
      "updated_date": "2025-02-16 16:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:07:03.485767"
    },
    {
      "arxiv_id": "2502.07423v2",
      "title": "Towards a Formal Theory of the Need for Competence via Computational Intrinsic Motivation",
      "title_zh": "翻译失败",
      "authors": [
        "Erik M. Lintunen",
        "Nadia M. Ady",
        "Sebastian Deterding",
        "Christian Guckelsberger"
      ],
      "abstract": "Computational modelling offers a powerful tool for formalising psychological\ntheories, making them more transparent, testable, and applicable in digital\ncontexts. Yet, the question often remains: how should one computationally model\na theory? We provide a demonstration of how formalisms taken from artificial\nintelligence can offer a fertile starting point. Specifically, we focus on the\n\"need for competence\", postulated as a key basic psychological need within\nSelf-Determination Theory (SDT) -- arguably the most influential framework for\nintrinsic motivation (IM) in psychology. Recent research has identified\nmultiple distinct facets of competence in key SDT texts: effectance, skill use,\ntask performance, and capacity growth. We draw on the computational IM\nliterature in reinforcement learning to suggest that different existing\nformalisms may be appropriate for modelling these different facets. Using these\nformalisms, we reveal underlying preconditions that SDT fails to make explicit,\ndemonstrating how computational models can improve our understanding of IM.\nMore generally, our work can support a cycle of theory development by inspiring\nnew computational models, which can then be tested empirically to refine the\ntheory. Thus, we provide a foundation for advancing competence-related theory\nin SDT and motivational psychology more broadly.",
      "tldr_zh": "本研究探讨了如何使用计算建模形式化心理理论，特别是 Self-Determination Theory (SDT) 中的“need for competence”，以提升理论的透明度、可测试性和数字应用潜力。作者借鉴了强化学习中的计算 intrinsic motivation (IM) 文献，将不同形式主义应用于 SDT 的四个方面：effectance、skill use、task performance 和 capacity growth，从而揭示了 SDT 中未明确说明的潜在先决条件。最终，该方法不仅深化了对 IM 的理解，还为理论发展提供了一个循环框架，支持新计算模型的创建和实证验证，推动 SDT 和动机心理学领域的进步。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages plus references, full paper at CogSci 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07423v2",
      "published_date": "2025-02-11 10:03:40 UTC",
      "updated_date": "2025-05-13 07:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:07:14.456155"
    },
    {
      "arxiv_id": "2502.07408v1",
      "title": "No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips",
      "title_zh": "翻译失败",
      "authors": [
        "Ido Galil",
        "Moshe Kimhi",
        "Ran El-Yaniv"
      ],
      "abstract": "Deep Neural Networks (DNNs) can be catastrophically disrupted by flipping\nonly a handful of sign bits in their parameters. We introduce Deep Neural\nLesion (DNL), a data-free, lightweight method that locates these critical\nparameters and triggers massive accuracy drops. We validate its efficacy on a\nwide variety of computer vision models and datasets. The method requires no\ntraining data or optimization and can be carried out via common exploits\nsoftware, firmware or hardware based attack vectors. An enhanced variant that\nuses a single forward and backward pass further amplifies the damage beyond\nDNL's zero-pass approach. Flipping just two sign bits in ResNet50 on ImageNet\nreduces accuracy by 99.8\\%. We also show that selectively protecting a small\nfraction of vulnerable sign bits provides a practical defense against such\nattacks.",
      "tldr_zh": "这篇论文提出了 Deep Neural Lesion (DNL)，一种无需数据或优化的轻量级方法，通过翻转神经网络参数中的 sign bits 来严重破坏模型性能。DNL 在各种计算机视觉模型和数据集上验证了其有效性，仅需翻转少量 sign bits 即可导致准确率急剧下降，例如 ResNet50 在 ImageNet 上准确率下降 99.8%。方法可以通过软件、固件或硬件攻击向量轻松实现，其增强版本通过单次前向和后向传播进一步放大破坏效果。论文还探讨了通过保护少量易受攻击的 sign bits 来提供实用防御策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07408v1",
      "published_date": "2025-02-11 09:40:45 UTC",
      "updated_date": "2025-02-11 09:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:07:28.681822"
    },
    {
      "arxiv_id": "2502.07404v1",
      "title": "Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy",
      "title_zh": "人类在环中注释用于基于图像的参与度估计：评估模型可靠性对注释准确",
      "authors": [
        "Sahana Yadnakudige Subramanya",
        "Ko Watanabe",
        "Andreas Dengel",
        "Shoya Ishimaru"
      ],
      "abstract": "Human-in-the-loop (HITL) frameworks are increasingly recognized for their\npotential to improve annotation accuracy in emotion estimation systems by\ncombining machine predictions with human expertise. This study focuses on\nintegrating a high-performing image-based emotion model into a HITL annotation\nframework to evaluate the collaborative potential of human-machine interaction\nand identify the psychological and practical factors critical to successful\ncollaboration. Specifically, we investigate how varying model reliability and\ncognitive framing influence human trust, cognitive load, and annotation\nbehavior in HITL systems. We demonstrate that model reliability and\npsychological framing significantly impact annotators' trust, engagement, and\nconsistency, offering insights into optimizing HITL frameworks. Through three\nexperimental scenarios with 29 participants--baseline model reliability (S1),\nfabricated errors (S2), and cognitive bias introduced by negative framing\n(S3)--we analyzed behavioral and qualitative data. Reliable predictions in S1\nyielded high trust and annotation consistency, while unreliable outputs in S2\nled to increased critical evaluations but also heightened frustration and\nresponse variability. Negative framing in S3 revealed how cognitive bias\ninfluenced participants to perceive the model as more relatable and accurate,\ndespite misinformation regarding its reliability. These findings highlight the\nimportance of both reliable machine outputs and psychological factors in\nshaping effective human-machine collaboration. By leveraging the strengths of\nboth human oversight and automated systems, this study establishes a scalable\nHITL framework for emotion annotation and lays the foundation for broader\napplications in adaptive learning and human-computer interaction.",
      "tldr_zh": "这篇论文探讨了Human-in-the-Loop (HITL) 框架在图像-based 情感估计中的应用，旨在通过结合机器预测和人类专业知识来提升标注准确性，并评估模型可靠性 (model reliability) 和认知框架 (cognitive framing) 对人类信任、认知负载和标注行为的影响。研究通过三个实验场景（S1: 基线模型可靠性；S2: 制造错误；S3: 引入认知偏差的负面框架）涉及29名参与者，分析了行为和定性数据。结果显示，可靠的模型预测提高了信任和标注一致性，而不可靠输出导致更多批评、挫败感和响应变异性；负面框架则使参与者更易产生认知偏差，错误地感知模型为更准确。总体而言，该研究强调了可靠机器输出和心理因素在优化HITL框架中的重要性，为情感标注、适应性学习和人机交互提供了可扩展的应用基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07404v1",
      "published_date": "2025-02-11 09:37:10 UTC",
      "updated_date": "2025-02-11 09:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:07:41.174970"
    },
    {
      "arxiv_id": "2502.07401v1",
      "title": "Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Johnny Chan",
        "Yuming Li"
      ],
      "abstract": "This research explores the opportunities of Generative AI (GenAI) in the\nrealm of higher education through the design and development of a multimodal\nchatbot for an undergraduate course. Leveraging the ChatGPT API for nuanced\ntext-based interactions and Google Bard for advanced image analysis and\ndiagram-to-code conversions, we showcase the potential of GenAI in addressing a\nbroad spectrum of educational queries. Additionally, the chatbot presents a\nfile-based analyser designed for educators, offering deep insights into student\nfeedback via sentiment and emotion analysis, and summarising course evaluations\nwith key metrics. These combinations highlight the crucial role of multimodal\nconversational AI in enhancing teaching and learning processes, promising\nsignificant advancements in educational adaptability, engagement, and feedback\nanalysis. By demonstrating a practical web application, this research\nunderlines the imperative for integrating GenAI technologies to foster more\ndynamic and responsive educational environments, ultimately contributing to\nimproved educational outcomes and pedagogical strategies.",
      "tldr_zh": "本研究探讨了Generative AI (GenAI) 在高等教育中的应用，通过设计一个多模态聊天机器人来实现个性化学习。机器人利用ChatGPT API 处理细致的文本交互，并借助Google Bard 进行高级图像分析和图表到代码转换，以应对广泛的教育查询。该系统还包括一个文件分析器，供教育者分析学生反馈的情感分析和课程评估总结。总体而言，此方法展示了多模态对话AI 在提升教学适应性、学生参与度和教育成果方面的潜力，并通过实际网络应用验证了其实际价值。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 4 figures, accepted and presented in the 2025 6th\n  International Conference on Advances in Education and Information Technology\n  (AEIT)",
      "pdf_url": "http://arxiv.org/pdf/2502.07401v1",
      "published_date": "2025-02-11 09:29:29 UTC",
      "updated_date": "2025-02-11 09:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:07:51.896751"
    },
    {
      "arxiv_id": "2502.07400v1",
      "title": "Explainable Multimodal Machine Learning for Revealing Structure-Property Relationships in Carbon Nanotube Fibers",
      "title_zh": "翻译失败",
      "authors": [
        "Daisuke Kimura",
        "Naoko Tajima",
        "Toshiya Okazaki",
        "Shun Muroga"
      ],
      "abstract": "In this study, we propose Explainable Multimodal Machine Learning (EMML),\nwhich integrates the analysis of diverse data types (multimodal data) using\nfactor analysis for feature extraction with Explainable AI (XAI), for carbon\nnanotube (CNT) fibers prepared from aqueous dispersions. This method is a\npowerful approach to elucidate the mechanisms governing material properties,\nwhere multi-stage fabrication conditions and multiscale structures have complex\ninfluences. Thus, in our case, this approach helps us understand how different\nprocessing steps and structures at various scales impact the final properties\nof CNT fibers. The analysis targeted structures ranging from the nanoscale to\nthe macroscale, including aggregation size distributions of CNT dispersions and\nthe effective length of CNTs. Furthermore, because some types of data were\ndifficult to interpret using standard methods, challenging-to-interpret\ndistribution data were analyzed using Negative Matrix Factorization (NMF) for\nextracting key features that determine the outcome. Contribution analysis with\nSHapley Additive exPlanations (SHAP) demonstrated that small, uniformly\ndistributed aggregates are crucial for improving fracture strength, while CNTs\nwith long effective lengths are significant factors for enhancing electrical\nconductivity. The analysis also identified thresholds and trends for these key\nfactors to assist in defining the conditions needed to optimize CNT fiber\nproperties. EMML is not limited to CNT fibers but can be applied to the design\nof other materials derived from nanomaterials, making it a useful tool for\ndeveloping a wide range of advanced materials. This approach provides a\nfoundation for advancing data-driven materials research.",
      "tldr_zh": "本文提出 Explainable Multimodal Machine Learning (EMML)，一种整合多模态数据分析、因子分析和 Explainable AI (XAI) 的方法，用于揭示碳纳米管 (CNT) 纤维的结构-性能关系，特别是多阶段制造条件和多尺度结构的影响。研究通过 Negative Matrix Factorization (NMF) 处理复杂分布数据，并利用 SHapley Additive exPlanations (SHAP) 进行贡献分析，发现小而均匀分布的聚集物有助于提高断裂强度，而长有效长度的 CNT 是提升电导率的关键因素，并识别了这些因素的阈值和趋势以优化性能。EMML 不仅适用于 CNT 纤维，还可推广到其他纳米材料设计，推动数据驱动的材料研究。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "cs.AI",
        "cs.LG",
        "physics.data-an"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "33 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07400v1",
      "published_date": "2025-02-11 09:29:23 UTC",
      "updated_date": "2025-02-11 09:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:08:04.093900"
    },
    {
      "arxiv_id": "2502.07399v1",
      "title": "On Iterative Evaluation and Enhancement of Code Quality Using GPT-4o",
      "title_zh": "使用 GPT-4o 进行代码质量的迭代评估和增强",
      "authors": [
        "Rundong Liu",
        "Andre Frade",
        "Amal Vaidya",
        "Maxime Labonne",
        "Marcus Kaiser",
        "Bismayan Chakrabarti",
        "Jonathan Budd",
        "Sean Moran"
      ],
      "abstract": "This paper introduces CodeQUEST, a novel framework leveraging Large Language\nModels (LLMs) to iteratively evaluate and enhance code quality across multiple\ndimensions, including readability, maintainability, efficiency, and security.\nThe framework is divided into two main components: an Evaluator that assesses\ncode quality across ten dimensions, providing both quantitative scores and\nqualitative summaries, and an Optimizer that iteratively improves the code\nbased on the Evaluator's feedback. Our study demonstrates that CodeQUEST can\neffectively and robustly evaluate code quality, with its assessments aligning\nclosely with established code quality metrics. Through a series of experiments\nusing a curated dataset of Python and JavaScript examples, CodeQUEST\ndemonstrated significant improvements in code quality, achieving a mean\nrelative percentage improvement of 52.6%. The framework's evaluations were\nvalidated against a set of proxy metrics comprising of Pylint Score, Radon\nMaintainability Index, and Bandit output logs, showing a meaningful\ncorrelation. This highlights the potential of LLMs in automating code quality\nevaluation and improvement processes, presenting a significant advancement\ntoward enhancing software development practices. The code implementation of the\nframework is available at: https://github.com/jpmorganchase/CodeQuest.",
      "tldr_zh": "本论文提出 CodeQUEST 框架，利用 LLMs（如 GPT-4o）来迭代评估和提升代码质量，包括可读性、维护性、效率和安全性等十个维度。框架由 Evaluator 组件（提供定量分数和定性总结）和 Optimizer 组件（基于反馈进行迭代改进）组成，通过实验在 Python 和 JavaScript 示例上实现了 52.6% 的平均相对百分比改进。结果显示 CodeQUEST 的评估与 Pylint Score、Radon Maintainability Index 和 Bandit 输出日志等指标高度相关，突显了 LLMs 在自动化代码质量评估和软件开发实践中的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07399v1",
      "published_date": "2025-02-11 09:27:00 UTC",
      "updated_date": "2025-02-11 09:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:08:15.693791"
    },
    {
      "arxiv_id": "2502.07845v1",
      "title": "Spread them Apart: Towards Robust Watermarking of Generated Content",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Pautov",
        "Danil Ivanov",
        "Andrey V. Galichin",
        "Oleg Rogov",
        "Ivan Oseledets"
      ],
      "abstract": "Generative models that can produce realistic images have improved\nsignificantly in recent years. The quality of the generated content has\nincreased drastically, so sometimes it is very difficult to distinguish between\nthe real images and the generated ones. Such an improvement comes at a price of\nethical concerns about the usage of the generative models: the users of\ngenerative models can improperly claim ownership of the generated content\nprotected by a license. In this paper, we propose an approach to embed\nwatermarks into the generated content to allow future detection of the\ngenerated content and identification of the user who generated it. The\nwatermark is embedded during the inference of the model, so the proposed\napproach does not require the retraining of the latter. We prove that\nwatermarks embedded are guaranteed to be robust against additive perturbations\nof a bounded magnitude. We apply our method to watermark diffusion models and\nshow that it matches state-of-the-art watermarking schemes in terms of\nrobustness to different types of synthetic watermark removal attacks.",
      "tldr_zh": "该论文针对生成模型（generative models）产生的图像难以区分真实图像的问题，提出了一种在推理阶段嵌入水印的方法，以检测生成内容并识别生成者，而无需重新训练模型。该方法证明了水印对加性扰动（additive perturbations）的鲁棒性，并将其应用于diffusion models，在抵抗各种水印移除攻击方面与state-of-the-art方案相当。通过实验验证，该方法有助于解决伦理问题，如不当所有权声称，提供更可靠的生成内容保护。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07845v1",
      "published_date": "2025-02-11 09:23:38 UTC",
      "updated_date": "2025-02-11 09:23:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:08:26.363289"
    },
    {
      "arxiv_id": "2502.07374v2",
      "title": "LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!",
      "title_zh": "翻译失败",
      "authors": [
        "Dacheng Li",
        "Shiyi Cao",
        "Tyler Griggs",
        "Shu Liu",
        "Xiangxi Mo",
        "Eric Tang",
        "Sumanth Hegde",
        "Kourosh Hakhamaneshi",
        "Shishir G. Patil",
        "Matei Zaharia",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "Large reasoning models (LRMs) tackle complex reasoning problems by following\nlong chain-of-thoughts (Long CoT) that incorporate reflection, backtracking,\nand self-validation. However, the training techniques and data requirements to\nelicit Long CoT remain poorly understood. In this work, we find that a Large\nLanguage model (LLM) can effectively learn Long CoT reasoning through\ndata-efficient supervised fine-tuning (SFT) and parameter-efficient low-rank\nadaptation (LoRA). With just 17k long CoT training samples, the\nQwen2.5-32B-Instruct model achieves significant improvements on a wide range of\nmath and coding benchmarks, including 56.7% (+40.0%) on AIME 2024 and 57.0%\n(+8.1%) on LiveCodeBench, competitive to the proprietary o1-preview model's\nscore of 44.6% and 59.1%. More importantly, we find that the structure of Long\nCoT is critical to the learning process, whereas the content of individual\nreasoning steps has minimal impact. Perturbations affecting content, such as\ntraining on incorrect samples or removing reasoning keywords, have little\nimpact on performance. In contrast, structural modifications that disrupt\nlogical consistency in the Long CoT, such as shuffling or deleting reasoning\nsteps, significantly degrade accuracy. For example, a model trained on Long CoT\nsamples with incorrect answers still achieves only 3.2% lower accuracy compared\nto training with fully correct samples. These insights deepen our understanding\nof how to elicit reasoning capabilities in LLMs and highlight key\nconsiderations for efficiently training the next generation of reasoning\nmodels. This is the academic paper of our previous released Sky-T1-32B-Preview\nmodel. Codes are available at https://github.com/NovaSky-AI/SkyThought.",
      "tldr_zh": "本研究发现，大语言模型（LLMs）可以通过数据高效的监督微调（SFT）和低秩适配（LoRA）轻松学习长链式思维（Long CoT）推理，仅需 17k 训练样本，Qwen2.5-32B-Instruct 在数学和编码基准上取得显著提升，如 AIME 2024 准确率达 56.7%（较基线提高 40.0%），并与 o1-preview 模型竞争。关键洞见是 Long CoT 的结构（如逻辑一致性）远比内容（如具体答案）重要，结构修改（如打乱步骤）会显著降低性能，而内容扰动（如使用错误样本）影响较小。该工作加深了对 LLMs 推理能力的理解，并为训练下一代推理模型提供指导，支持于 Sky-T1-32B-Preview 模型的学术扩展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07374v2",
      "published_date": "2025-02-11 08:48:48 UTC",
      "updated_date": "2025-02-18 05:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:08:39.548802"
    },
    {
      "arxiv_id": "2502.07352v1",
      "title": "Bridging the Evaluation Gap: Leveraging Large Language Models for Topic Model Evaluation",
      "title_zh": "弥合评估差距：利用",
      "authors": [
        "Zhiyin Tan",
        "Jennifer D'Souza"
      ],
      "abstract": "This study presents a framework for automated evaluation of dynamically\nevolving topic taxonomies in scientific literature using Large Language Models\n(LLMs). In digital library systems, topic modeling plays a crucial role in\nefficiently organizing and retrieving scholarly content, guiding researchers\nthrough complex knowledge landscapes. As research domains proliferate and\nshift, traditional human centric and static evaluation methods struggle to\nmaintain relevance. The proposed approach harnesses LLMs to measure key quality\ndimensions, such as coherence, repetitiveness, diversity, and topic-document\nalignment, without heavy reliance on expert annotators or narrow statistical\nmetrics. Tailored prompts guide LLM assessments, ensuring consistent and\ninterpretable evaluations across various datasets and modeling techniques.\nExperiments on benchmark corpora demonstrate the method's robustness,\nscalability, and adaptability, underscoring its value as a more holistic and\ndynamic alternative to conventional evaluation strategies.",
      "tldr_zh": "本研究提出一个框架，利用大型语言模型（LLMs）来自动评估科学文献中动态演变的主题分类系统，解决传统人工和静态评估方法的局限性。该框架通过定制提示引导LLMs评估主题模型的关键质量维度，包括连贯性（coherence）、重复性（repetitiveness）、多样性（diversity）和主题-文档匹配（topic-document alignment），减少了对专家标注的依赖。实验在基准语料库上证明了该方法的鲁棒性、可扩展性和适应性，为更全面动态的主题模型评估提供了可行替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by IRCDL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07352v1",
      "published_date": "2025-02-11 08:23:56 UTC",
      "updated_date": "2025-02-11 08:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:08:51.003669"
    },
    {
      "arxiv_id": "2502.07351v3",
      "title": "Multi-Knowledge-oriented Nighttime Haze Imaging Enhancer for Vision-driven Intelligent Transportation Systems",
      "title_zh": "多知识导向的夜间雾霾图像增强器，用于视觉驱动的智能交通系统",
      "authors": [
        "Ai Chen",
        "Yuxu Lu",
        "Dong Yang",
        "Junlin Zhou",
        "Yan Fu",
        "Duanbing Chen"
      ],
      "abstract": "Salient object detection (SOD) plays a critical role in intelligent\ntransportation systems (ITS), facilitating the detection and segmentation of\nkey visual elements in an image. However, adverse imaging conditions such as\nhaze during the day, low light, and haze at night severely degrade image\nquality and hinder reliable object detection in real-world scenarios. To\naddress these challenges, we propose a multi-knowledge-oriented nighttime haze\nimaging enhancer (MKoIE), which integrates three tasks: daytime dehazing,\nlow-light enhancement, and nighttime dehazing. The MKoIE incorporates two key\ninnovative components: First, the network employs a task-oriented node learning\nmechanism to handle three specific degradation types: day-time haze, low light,\nand night-time haze conditions, with an embedded self-attention module\nenhancing its performance in nighttime imaging. In addition, multi-receptive\nfield enhancement module that efficiently extracts multi-scale features through\nthree parallel depthwise separable convolution branches with different dilation\nrates, capturing comprehensive spatial information with minimal computational\noverhead to meet the requirements of real-time ITS deployment. To ensure\noptimal image reconstruction quality and visual characteristics, we suggest a\nhybrid loss function. Extensive experiments on different types of\nweather/imaging conditions illustrate that MKoIE surpasses existing methods,\nenhancing the reliability, accuracy, and operational efficiency of ITS. The\ncode is available at https://github.com/Ai-Chen-Lab/MKoIE.",
      "tldr_zh": "本文提出了一种多知识导向的夜间雾霾成像增强器（MKoIE），针对智能交通系统（ITS）中的显著物体检测（SOD）问题，解决白天雾霾、低光和夜间雾霾等不利条件对图像质量的影响。MKoIE 整合了白天去雾、低光增强和夜间去雾三个任务，引入任务导向的节点学习机制（包含自注意力模块）和多感受野增强模块，通过并行深度可分离卷积提取多尺度特征，实现高效实时处理。实验结果表明，MKoIE 在各种天气条件下优于现有方法，提高了 ITS 的可靠性和准确性，为视觉驱动的交通应用提供了更高效的图像增强方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07351v3",
      "published_date": "2025-02-11 08:22:21 UTC",
      "updated_date": "2025-03-14 03:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:09:06.082471"
    },
    {
      "arxiv_id": "2502.07350v1",
      "title": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jusheng Zhang",
        "Zimeng Huang",
        "Yijia Fan",
        "Ningyuan Liu",
        "Mingyan Li",
        "Zhuojie Yang",
        "Jiawei Yao",
        "Jian Wang",
        "Keze Wang"
      ],
      "abstract": "As scaling large language models faces prohibitive costs, multi-agent systems\nemerge as a promising alternative, though challenged by static knowledge\nassumptions and coordination inefficiencies. We introduces Knowledge-Aware\nBayesian Bandits (KABB), a novel framework that enhances multi-agent system\ncoordination through semantic understanding and dynamic adaptation. The\nframework features three key innovations: a three-dimensional knowledge\ndistance model for deep semantic understanding, a dual-adaptation mechanism for\ncontinuous expert optimization, and a knowledge-aware Thompson Sampling\nstrategy for efficient expert selection. Extensive evaluation demonstrates KABB\nachieves an optimal cost-performance balance, maintaining high performance\nwhile keeping computational demands relatively low in multi-agent coordination.",
      "tldr_zh": "该论文提出 KABB（Knowledge-Aware Bayesian Bandits）框架，以解决多智能体系统中静态知识假设和协调低效问题，提供一种基于语义理解的动态适应机制。框架的关键创新包括三维知识距离模型用于深度语义理解、双重适应机制实现专家的持续优化，以及知识感知 Thompson Sampling 策略提升专家选择效率。实验评估显示，KABB 实现了最佳的成本性能平衡，在保持高性能的同时显著降低了计算需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07350v1",
      "published_date": "2025-02-11 08:22:12 UTC",
      "updated_date": "2025-02-11 08:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:09:14.782773"
    },
    {
      "arxiv_id": "2502.07347v5",
      "title": "Coarse Set Theory for AI Ethics and Decision-Making: A Mathematical Framework for Granular Evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Takashi Izumo"
      ],
      "abstract": "As artificial intelligence (AI) systems become increasingly embedded in\nethically sensitive domains such as education, healthcare, and transportation,\nthe need to balance accuracy and interpretability in decision-making has become\na central concern. Coarse Ethics (CE) is a theoretical framework that justifies\ncoarse-grained evaluations, such as letter grades or warning labels, as\nethically appropriate under cognitive and contextual constraints. However, CE\nhas lacked mathematical formalization. This paper introduces Coarse Set Theory\n(CST), a novel mathematical framework that models coarse-grained\ndecision-making using totally ordered structures and coarse partitions. CST\ndefines hierarchical relations among sets and uses information-theoretic tools,\nsuch as Kullback-Leibler Divergence, to quantify the trade-off between\nsimplification and information loss. We demonstrate CST through applications in\neducational grading and explainable AI (XAI), showing how it enables more\ntransparent and context-sensitive evaluations. By grounding coarse evaluations\nin set theory and probabilistic reasoning, CST contributes to the ethical\ndesign of interpretable AI systems. This work bridges formal methods and\nhuman-centered ethics, offering a principled approach to balancing\ncomprehensibility, fairness, and informational integrity in AI-driven\ndecisions.",
      "tldr_zh": "这篇论文引入了 Coarse Set Theory (CST)，一个新的数学框架，用于形式化粗粒度决策，帮助平衡 AI 决策中的准确性和可解释性。CST 基于 totally ordered structures 和 coarse partitions，定义集合间的层次关系，并使用 Kullback-Leibler Divergence 等信息理论工具量化简化与信息损失的权衡。论文通过教育评分和 explainable AI (XAI) 的应用，展示了 CST 如何提升评估的透明度、公平性和上下文敏感性，从而为 AI 伦理设计提供一个桥接正式方法与人文中心伦理的原理性方法。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT",
        "math.LO",
        "math.PR"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07347v5",
      "published_date": "2025-02-11 08:18:37 UTC",
      "updated_date": "2025-03-22 00:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:09:27.597681"
    },
    {
      "arxiv_id": "2502.07344v1",
      "title": "Integrating Physics and Data-Driven Approaches: An Explainable and Uncertainty-Aware Hybrid Model for Wind Turbine Power Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Alfonso Gijón",
        "Simone Eiraudo",
        "Antonio Manjavacas",
        "Daniele Salvatore Schiera",
        "Miguel Molina-Solana",
        "Juan Gómez-Romero"
      ],
      "abstract": "The rapid growth of the wind energy sector underscores the urgent need to\noptimize turbine operations and ensure effective maintenance through early\nfault detection systems. While traditional empirical and physics-based models\noffer approximate predictions of power generation based on wind speed, they\noften fail to capture the complex, non-linear relationships between other input\nvariables and the resulting power output. Data-driven machine learning methods\npresent a promising avenue for improving wind turbine modeling by leveraging\nlarge datasets, enhancing prediction accuracy but often at the cost of\ninterpretability. In this study, we propose a hybrid semi-parametric model that\ncombines the strengths of both approaches, applied to a dataset from a wind\nfarm with four turbines. The model integrates a physics-inspired submodel,\nproviding a reasonable approximation of power generation, with a non-parametric\nsubmodel that predicts the residuals. This non-parametric submodel is trained\non a broader range of variables to account for phenomena not captured by the\nphysics-based component. The hybrid model achieves a 37% improvement in\nprediction accuracy over the physics-based model. To enhance interpretability,\nSHAP values are used to analyze the influence of input features on the residual\nsubmodel's output. Additionally, prediction uncertainties are quantified using\na conformalized quantile regression method. The combination of these\ntechniques, alongside the physics grounding of the parametric submodel,\nprovides a flexible, accurate, and reliable framework. Ultimately, this study\nopens the door for evaluating the impact of unmodeled variables on wind turbine\npower generation, offering a basis for potential optimization.",
      "tldr_zh": "本研究针对风能行业的涡轮机优化和故障检测需求，提出了一种可解释且不确定性感知的混合半参数模型，将物理模型和数据驱动方法相结合，用于风力涡轮机功率预测。模型包括一个基于物理的子模型，提供功率生成的近似估计，以及一个非参数子模型，用于预测残差并整合更多变量，以捕捉物理模型未覆盖的非线性关系。该方法在实际风电场数据集上实现了比纯物理模型高37%的预测准确率，并通过SHAP values分析输入特征的影响，以及conformalized quantile regression量化预测不确定性。最终，该框架为评估未建模变量对功率生成的影响提供了可靠基础，促进风能优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07344v1",
      "published_date": "2025-02-11 08:16:48 UTC",
      "updated_date": "2025-02-11 08:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:09:39.487788"
    },
    {
      "arxiv_id": "2502.07340v2",
      "title": "Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering",
      "title_zh": "翻译失败",
      "authors": [
        "Shuzheng Si",
        "Haozhe Zhao",
        "Gang Chen",
        "Cheng Gao",
        "Yuzhuo Bai",
        "Zhitong Wang",
        "Kaikai An",
        "Kangyang Luo",
        "Chen Qian",
        "Fanchao Qi",
        "Baobao Chang",
        "Maosong Sun"
      ],
      "abstract": "Training LLMs on data containing unfamiliar knowledge during the instruction\ntuning stage can encourage hallucinations. To address this challenge, we\nintroduce NOVA, a novel framework designed to identify high-quality data that\naligns well with the LLM's learned knowledge to reduce hallucinations. NOVA\nincludes Internal Consistency Probing (ICP) and Semantic Equivalence\nIdentification (SEI) to measure how familiar the LLM is with instruction data.\nSpecifically, ICP evaluates the LLM's understanding of the given instruction by\ncalculating the tailored consistency among multiple self-generated responses.\nSEI further assesses the familiarity of the LLM with the target response by\ncomparing it to the generated responses, using the proposed semantic clustering\nand well-designed voting strategy. Finally, to ensure the quality of selected\nsamples, we introduce an expert-aligned reward model, considering\ncharacteristics beyond just familiarity. By considering data quality and\navoiding unfamiliar data, we can utilize the selected data to effectively align\nLLMs to follow instructions and hallucinate less.",
      "tldr_zh": "这篇论文提出了 NOVA 框架，用于通过有效的数据过滤来对齐大型语言模型 (LLMs)，以提高指令遵循能力和减少 hallucination。NOVA 包括 Internal Consistency Probing (ICP) 和 Semantic Equivalence Identification (SEI) 两种方法，分别通过评估多个自我生成响应的内部一致性和语义等价性来衡量 LLM 对指令数据的熟悉度，并结合专家对齐的奖励模型确保数据质量。最终，通过筛选高质量数据，实验证明该框架能有效训练 LLMs，使其更好地执行指令并降低 hallucination 的发生。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07340v2",
      "published_date": "2025-02-11 08:05:56 UTC",
      "updated_date": "2025-02-17 03:00:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:09:51.964743"
    },
    {
      "arxiv_id": "2502.07328v3",
      "title": "Music for All: Representational Bias and Cross-Cultural Adaptability of Music Generation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Atharva Mehta",
        "Shivam Chauhan",
        "Amirbek Djanibekov",
        "Atharva Kulkarni",
        "Gus Xia",
        "Monojit Choudhury"
      ],
      "abstract": "The advent of Music-Language Models has greatly enhanced the automatic music\ngeneration capability of AI systems, but they are also limited in their\ncoverage of the musical genres and cultures of the world. We present a study of\nthe datasets and research papers for music generation and quantify the bias and\nunder-representation of genres. We find that only 5.7% of the total hours of\nexisting music datasets come from non-Western genres, which naturally leads to\ndisparate performance of the models across genres. We then investigate the\nefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating\nthis bias. Our experiments with two popular models -- MusicGen and Mustango,\nfor two underrepresented non-Western music traditions -- Hindustani Classical\nand Turkish Makam music, highlight the promises as well as the non-triviality\nof cross-genre adaptation of music through small datasets, implying the need\nfor more equitable baseline music-language models that are designed for\ncross-cultural transfer learning.",
      "tldr_zh": "这篇论文探讨了音乐生成模型中的代表性偏见，分析了现有数据集和研究论文，发现只有5.7%的音乐数据集小时数来自非西方流派，导致模型在不同文化音乐上的表现不均。作者通过Parameter-Efficient Fine-Tuning (PEFT)技术实验MusicGen和Mustango模型，针对低代表性的Hindustani Classical和Turkish Makam音乐进行跨流派适应测试。结果显示PEFT在缓解偏见方面有潜力，但也面临挑战，强调需要开发更公平的基线模型来支持跨文化迁移学习。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.SD",
      "comment": "17 pages, 5 figures, accepted to NAACL'25",
      "pdf_url": "http://arxiv.org/pdf/2502.07328v3",
      "published_date": "2025-02-11 07:46:29 UTC",
      "updated_date": "2025-05-06 09:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:10:05.065537"
    },
    {
      "arxiv_id": "2502.07316v4",
      "title": "CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Junlong Li",
        "Daya Guo",
        "Dejian Yang",
        "Runxin Xu",
        "Yu Wu",
        "Junxian He"
      ],
      "abstract": "Reasoning is a fundamental capability of Large Language Models. While prior\nresearch predominantly focuses on enhancing narrow skills like math or code\ngeneration, improving performance on many other reasoning tasks remains\nchallenging due to sparse and fragmented training data. To address this issue,\nwe propose CodeI/O, a novel approach that systematically condenses diverse\nreasoning patterns inherently embedded in contextually-grounded codes, through\ntransforming the original code into a code input-output prediction format. By\ntraining models to predict inputs/outputs given code and test cases entirely in\nnatural language as Chain-of-Thought (CoT) rationales, we expose them to\nuniversal reasoning primitives -- like logic flow planning, state-space\nsearching, decision tree traversal, and modular decomposition -- while\ndecoupling structured reasoning from code-specific syntax and preserving\nprocedural rigor. Experimental results demonstrate CodeI/O leads to consistent\nimprovements across symbolic, scientific, logic, math & numerical, and\ncommonsense reasoning tasks. By matching the existing ground-truth outputs or\nre-executing the code with predicted inputs, we can verify each prediction and\nfurther enhance the CoTs through multi-turn revision, resulting in CodeI/O++\nand achieving higher performance. Our data and models are available at\nhttps://github.com/hkust-nlp/CodeIO.",
      "tldr_zh": "本文提出 CodeI/O 方法，通过将代码转化为输入-输出预测格式，系统凝练大语言模型（Large Language Models）中固有的多样推理模式，从而提升模型在稀疏训练数据下的泛化能力。方法利用自然语言的 Chain-of-Thought (CoT) 推理，让模型预测代码的输入/输出，同时暴露通用推理原语，如逻辑流规划、状态空间搜索和模块分解，而不依赖代码语法。实验结果显示，CodeI/O 在符号、科学、逻辑、数学和常识推理任务上实现了持续性能提升；通过输出验证和多轮修订，进一步开发了 CodeI/O++，取得了更高的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07316v4",
      "published_date": "2025-02-11 07:26:50 UTC",
      "updated_date": "2025-05-21 13:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:10:16.495009"
    },
    {
      "arxiv_id": "2502.07312v1",
      "title": "OpenGrok: Enhancing SNS Data Processing with Distilled Knowledge and Mask-like Mechanisms",
      "title_zh": "翻译失败",
      "authors": [
        "Lumen AI",
        "Zaozhuang No. 28 Middle School",
        "Shihao Ji",
        "Zihui Song",
        "Fucheng Zhong",
        "Jisen Jia",
        "Zhaobo Wu",
        "Zheyi Cao",
        "Tianhao Xu"
      ],
      "abstract": "This report details Lumen Labs' novel approach to processing Social\nNetworking Service (SNS) data. We leverage knowledge distillation, specifically\na simple distillation method inspired by DeepSeek-R1's CoT acquisition,\ncombined with prompt hacking, to extract valuable training data from the Grok\nmodel. This data is then used to fine-tune a Phi-3-mini model, augmented with a\nmask-like mechanism specifically designed for handling the nuances of SNS data.\nOur method demonstrates state-of-the-art (SOTA) performance on several SNS data\nprocessing tasks, outperforming existing models like Grok, Phi-3, and GPT-4. We\nprovide a comprehensive analysis of our approach, including mathematical\nformulations, engineering details, ablation studies, and comparative\nevaluations.",
      "tldr_zh": "这篇论文介绍了 OpenGrok 方法，通过知识 distillation 和 mask-like 机制来提升社交网络服务 (SNS) 数据处理能力。具体而言，研究团队使用受 DeepSeek-R1 的 CoT acquisition 启发的简单知识 distillation 结合 prompt hacking，从 Grok 模型提取训练数据，并以此微调 Phi-3-mini 模型，以更好地处理 SNS 数据的复杂性。实验结果显示，该方法在多个 SNS 数据处理任务上达到了 SOTA 性能，优于 Grok、Phi-3 和 GPT-4，并通过数学公式、工程细节、消融研究和比较评估提供了全面分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.07312v1",
      "published_date": "2025-02-11 07:20:38 UTC",
      "updated_date": "2025-02-11 07:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:10:28.752560"
    },
    {
      "arxiv_id": "2502.07306v1",
      "title": "TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Navid Rajabi",
        "Jana Kosecka"
      ],
      "abstract": "In this work, we propose a modular approach for the Vision-Language\nNavigation (VLN) task by decomposing the problem into four sub-modules that use\nstate-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs)\nin a zero-shot setting. Given navigation instruction in natural language, we\nfirst prompt LLM to extract the landmarks and the order in which they are\nvisited. Assuming the known model of the environment, we retrieve the top-k\nlocations of the last landmark and generate $k$ path hypotheses from the\nstarting location to the last landmark using the shortest path algorithm on the\ntopological map of the environment. Each path hypothesis is represented by a\nsequence of panoramas. We then use dynamic programming to compute the alignment\nscore between the sequence of panoramas and the sequence of landmark names,\nwhich match scores obtained from VLM. Finally, we compute the nDTW metric\nbetween the hypothesis that yields the highest alignment score to evaluate the\npath fidelity. We demonstrate superior performance compared to other approaches\nthat use joint semantic maps like VLMaps \\cite{vlmaps} on the complex\nR2R-Habitat \\cite{r2r} instruction dataset and quantify in detail the effect of\nvisual grounding on navigation performance.",
      "tldr_zh": "本研究提出TRAVEL，一种无需训练的模块化方法，用于Vision-and-Language Navigation (VLN)任务，通过Large Language Models (LLMs)和Vision-Language Models (VLMs)在zero-shot设置中分解问题为四个子模块。方法首先使用LLM从自然语言指令中提取地标及其访问顺序，然后在环境拓扑图上检索路径假设并应用动态规划计算全景序列与地标序列的alignment score。实验结果显示，TRAVEL在R2R-Habitat数据集上比使用联合语义地图的基线方法（如VLMaps）表现出色，提高了导航性能，并量化了视觉grounding对路径保真度的积极影响。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07306v1",
      "published_date": "2025-02-11 07:09:37 UTC",
      "updated_date": "2025-02-11 07:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:10:40.255731"
    },
    {
      "arxiv_id": "2502.07299v1",
      "title": "Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification",
      "title_zh": "翻译失败",
      "authors": [
        "Zicheng Liu",
        "Siyuan Li",
        "Zhiyuan Chen",
        "Lei Xin",
        "Fang Wu",
        "Chang Yu",
        "Qirong Yang",
        "Yucheng Guo",
        "Yujie Yang",
        "Stan Z. Li"
      ],
      "abstract": "The interactions between DNA, RNA, and proteins are fundamental to biological\nprocesses, as illustrated by the central dogma of molecular biology. While\nmodern biological pre-trained models have achieved great success in analyzing\nthese macromolecules individually, their interconnected nature remains\nunder-explored. In this paper, we follow the guidance of the central dogma to\nredesign both the data and model pipeline and offer a comprehensive framework,\nLife-Code, that spans different biological functions. As for data flow, we\npropose a unified pipeline to integrate multi-omics data by\nreverse-transcribing RNA and reverse-translating amino acids into\nnucleotide-based sequences. As for the model, we design a codon tokenizer and a\nhybrid long-sequence architecture to encode the interactions of both coding and\nnon-coding regions with masked modeling pre-training. To model the translation\nand folding process with coding sequences, Life-Code learns protein structures\nof the corresponding amino acids by knowledge distillation from off-the-shelf\nprotein language models. Such designs enable Life-Code to capture complex\ninteractions within genetic sequences, providing a more comprehensive\nunderstanding of multi-omics with the central dogma. Extensive Experiments show\nthat Life-Code achieves state-of-the-art performance on various tasks across\nthree omics, highlighting its potential for advancing multi-omics analysis and\ninterpretation.",
      "tldr_zh": "本论文提出 Life-Code 框架，基于 central dogma 分子生物学原理，重新设计数据和模型管道，以统一多组学序列并捕捉 DNA、RNA 和蛋白质间的互动。具体方法包括逆转录 RNA 和逆翻译氨基酸生成基于核苷酸的统一序列，以及设计 codon tokenizer 和混合长序列架构，通过 masked modeling 预训练和知识蒸馏学习蛋白质结构。实验结果显示，Life-Code 在跨三个组学的各种任务上实现 state-of-the-art 性能，提升了多组学分析的全面性和解释力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages main text with 6 pages Appendix",
      "pdf_url": "http://arxiv.org/pdf/2502.07299v1",
      "published_date": "2025-02-11 06:53:59 UTC",
      "updated_date": "2025-02-11 06:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:10:51.865049"
    },
    {
      "arxiv_id": "2502.07288v1",
      "title": "KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level",
      "title_zh": "翻译失败",
      "authors": [
        "Ruining Deng",
        "Tianyuan Yao",
        "Yucheng Tang",
        "Junlin Guo",
        "Siqi Lu",
        "Juming Xiong",
        "Lining Yu",
        "Quan Huu Cap",
        "Pengzhou Cai",
        "Libin Lan",
        "Ze Zhao",
        "Adrian Galdran",
        "Amit Kumar",
        "Gunjan Deotale",
        "Dev Kumar Das",
        "Inyoung Paik",
        "Joonho Lee",
        "Geongyu Lee",
        "Yujia Chen",
        "Wangkai Li",
        "Zhaoyang Li",
        "Xuege Hou",
        "Zeyuan Wu",
        "Shengjin Wang",
        "Maximilian Fischer",
        "Lars Kramer",
        "Anghong Du",
        "Le Zhang",
        "Maria Sanchez Sanchez",
        "Helena Sanchez Ulloa",
        "David Ribalta Heredia",
        "Carlos Perez de Arenaza Garcia",
        "Shuoyu Xu",
        "Bingdou He",
        "Xinping Cheng",
        "Tao Wang",
        "Noemie Moreau",
        "Katarzyna Bozek",
        "Shubham Innani",
        "Ujjwal Baid",
        "Kaura Solomon Kefas",
        "Bennett A. Landman",
        "Yu Wang",
        "Shilin Zhao",
        "Mengmeng Yin",
        "Haichun Yang",
        "Yuankai Huo"
      ],
      "abstract": "Chronic kidney disease (CKD) is a major global health issue, affecting over\n10% of the population and causing significant mortality. While kidney biopsy\nremains the gold standard for CKD diagnosis and treatment, the lack of\ncomprehensive benchmarks for kidney pathology segmentation hinders progress in\nthe field. To address this, we organized the Kidney Pathology Image\nSegmentation (KPIs) Challenge, introducing a dataset that incorporates\npreclinical rodent models of CKD with over 10,000 annotated glomeruli from 60+\nPeriodic Acid Schiff (PAS)-stained whole slide images. The challenge includes\ntwo tasks, patch-level segmentation and whole slide image segmentation and\ndetection, evaluated using the Dice Similarity Coefficient (DSC) and F1-score.\nBy encouraging innovative segmentation methods that adapt to diverse CKD models\nand tissue conditions, the KPIs Challenge aims to advance kidney pathology\nanalysis, establish new benchmarks, and enable precise, large-scale\nquantification for disease research and diagnosis.",
      "tldr_zh": "本研究针对慢性肾病 (CKD) 的全球健康挑战，组织了 Kidney Pathology Image Segmentation (KPIs) Challenge，以解决肾病理分割缺乏全面基准的问题。挑战引入了一个数据集，包括超过10,000个标注的肾小球，源自60+张Periodic Acid Schiff (PAS)染色的全滑片图像，并设置了patch-level segmentation和whole slide image segmentation and detection两个任务。使用Dice Similarity Coefficient (DSC)和F1-score作为评估指标，该挑战鼓励创新分割方法适应多样CKD模型和组织条件，从而推进肾病理分析、建立新基准，并实现精确的大规模量化以支持疾病研究和诊断。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07288v1",
      "published_date": "2025-02-11 06:20:28 UTC",
      "updated_date": "2025-02-11 06:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:11:03.463010"
    },
    {
      "arxiv_id": "2502.07286v1",
      "title": "Small Language Model Makes an Effective Long Text Extractor",
      "title_zh": "翻译失败",
      "authors": [
        "Yelin Chen",
        "Fanjin Zhang",
        "Jie Tang"
      ],
      "abstract": "Named Entity Recognition (NER) is a fundamental problem in natural language\nprocessing (NLP). However, the task of extracting longer entity spans (e.g.,\nawards) from extended texts (e.g., homepages) is barely explored. Current NER\nmethods predominantly fall into two categories: span-based methods and\ngeneration-based methods. Span-based methods require the enumeration of all\npossible token-pair spans, followed by classification on each span, resulting\nin substantial redundant computations and excessive GPU memory usage. In\ncontrast, generation-based methods involve prompting or fine-tuning large\nlanguage models (LLMs) to adapt to downstream NER tasks. However, these methods\nstruggle with the accurate generation of longer spans and often incur\nsignificant time costs for effective fine-tuning. To address these challenges,\nthis paper introduces a lightweight span-based NER method called SeNER, which\nincorporates a bidirectional arrow attention mechanism coupled with\nLogN-Scaling on the [CLS] token to embed long texts effectively, and comprises\na novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to\nreduce redundant candidate token-pair spans significantly and model\ninteractions between token-pair spans simultaneously. Extensive experiments\ndemonstrate that our method achieves state-of-the-art extraction accuracy on\nthree long NER datasets and is capable of extracting entities from long texts\nin a GPU-memory-friendly manner. Code:\nhttps://github.com/THUDM/scholar-profiling/tree/main/sener",
      "tldr_zh": "这篇论文针对 Named Entity Recognition (NER) 任务，探讨了从长文本中提取长实体跨度（如奖项）的挑战，指出现有 span-based 方法计算冗余高、占用 GPU 内存大，而 generation-based 方法依赖大型语言模型 (LLMs) 但在生成长跨度实体时准确性不足。论文提出了一种轻量级 span-based 方法 SeNER，该方法整合 bidirectional arrow attention mechanism 和 LogN-Scaling 于 [CLS] 标记以有效嵌入长文本，并引入 bidirectional sliding-window plus-shaped attention (BiSPA) 机制来显著减少冗余候选 token-pair spans 并建模其交互。实验结果显示，SeNER 在三个长 NER 数据集上达到了 state-of-the-art 提取准确率，同时以友好 GPU 内存方式处理长文本，提供高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI'25, 9 pages, 1 appendix pages",
      "pdf_url": "http://arxiv.org/pdf/2502.07286v1",
      "published_date": "2025-02-11 06:06:25 UTC",
      "updated_date": "2025-02-11 06:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:11:16.360913"
    },
    {
      "arxiv_id": "2502.07280v1",
      "title": "MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management",
      "title_zh": "翻译失败",
      "authors": [
        "Fengchen Gu",
        "Angelos Stefanidis",
        "Ángel García-Fernández",
        "Jionglong Su",
        "Huakang Li"
      ],
      "abstract": "Deep reinforcement learning (DRL) has been applied in financial portfolio\nmanagement to improve returns in changing market conditions. However, unlike\nmost fields where DRL is widely used, the stock market is more volatile and\ndynamic as it is affected by several factors such as global events and investor\nsentiment. Therefore, it remains a challenge to construct a DRL-based portfolio\nmanagement framework with strong return capability, stable training, and\ngeneralization ability. This study introduces a new framework utilizing the\nMemory Instance Gated Transformer (MIGT) for effective portfolio management. By\nincorporating a novel Gated Instance Attention module, which combines a\ntransformer variant, instance normalization, and a Lite Gate Unit, our approach\naims to maximize investment returns while ensuring the learning process's\nstability and reducing outlier impacts. Tested on the Dow Jones Industrial\nAverage 30, our framework's performance is evaluated against fifteen other\nstrategies using key financial metrics like the cumulative return and\nrisk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight\nMIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns\nand a minimum 2.36% increase in risk-return ratios over competing strategies,\nmarking a significant advancement in DRL for portfolio management.",
      "tldr_zh": "本文提出 MIGT（Memory Instance Gated Transformer）框架，用于提升深度强化学习 (DRL) 在金融投资组合管理中的表现，针对股市的波动性和动态性挑战。MIGT 整合了 Gated Instance Attention 模块，该模块结合 Transformer 变体、instance normalization 和 Lite Gate Unit，以最大化投资回报、确保训练稳定性和减少异常值影响。在 Dow Jones Industrial Average 30 上测试，与其他 15 种策略相比，MIGT 的累计回报至少提高了 9.75%，风险回报比率（如 Sharpe、Sortino 和 Omega ratios）至少提高了 2.36%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07280v1",
      "published_date": "2025-02-11 05:54:42 UTC",
      "updated_date": "2025-02-11 05:54:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:11:28.517385"
    },
    {
      "arxiv_id": "2502.07279v2",
      "title": "Exploratory Diffusion Model for Unsupervised Reinforcement Learning",
      "title_zh": "探索性扩散模型用于无监督强化学习",
      "authors": [
        "Chengyang Ying",
        "Huayu Chen",
        "Xinning Zhou",
        "Zhongkai Hao",
        "Hang Su",
        "Jun Zhu"
      ],
      "abstract": "Unsupervised reinforcement learning (URL) aims to pre-train agents by\nexploring diverse states or skills in reward-free environments, facilitating\nefficient adaptation to downstream tasks. As the agent cannot access extrinsic\nrewards during unsupervised exploration, existing methods design intrinsic\nrewards to model the explored data and encourage further exploration. However,\nthe explored data are always heterogeneous, posing the requirements of powerful\nrepresentation abilities for both intrinsic reward models and pre-trained\npolicies. In this work, we propose the Exploratory Diffusion Model (ExDM),\nwhich leverages the strong expressive ability of diffusion models to fit the\nexplored data, simultaneously boosting exploration and providing an efficient\ninitialization for downstream tasks. Specifically, ExDM can accurately estimate\nthe distribution of collected data in the replay buffer with the diffusion\nmodel and introduces the score-based intrinsic reward, encouraging the agent to\nexplore less-visited states. After obtaining the pre-trained policies, ExDM\nenables rapid adaptation to downstream tasks. In detail, we provide theoretical\nanalyses and practical algorithms for fine-tuning diffusion policies,\naddressing key challenges such as training instability and computational\ncomplexity caused by multi-step sampling. Extensive experiments demonstrate\nthat ExDM outperforms existing SOTA baselines in efficient unsupervised\nexploration and fast fine-tuning downstream tasks, especially in structurally\ncomplicated environments.",
      "tldr_zh": "无监督强化学习 (URL) 旨在通过无奖励环境探索多样状态或技能来预训练代理器，从而实现下游任务的快速适应，但现有方法在处理探索数据异质性时面临表示能力不足的问题。论文提出 Exploratory Diffusion Model (ExDM)，利用 diffusion models 的强大表达能力来拟合探索数据，并引入基于分数的内在奖励，鼓励代理器探索未访问状态，同时提供高效的预训练策略初始化。ExDM 通过理论分析和实际算法解决微调过程中的训练不稳定性和计算复杂性，并在实验中显著优于现有最先进基线，尤其在结构复杂的环境中，展示了更高的探索效率和适应速度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07279v2",
      "published_date": "2025-02-11 05:48:51 UTC",
      "updated_date": "2025-05-16 17:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:11:40.695616"
    },
    {
      "arxiv_id": "2502.07277v1",
      "title": "Enhancing Video Understanding: Deep Neural Networks for Spatiotemporal Analysis",
      "title_zh": "增强视频理解：用于时空分析的深度神经网络",
      "authors": [
        "Amir Hosein Fadaei",
        "Mohammad-Reza A. Dehaqani"
      ],
      "abstract": "It's no secret that video has become the primary way we share information\nonline. That's why there's been a surge in demand for algorithms that can\nanalyze and understand video content. It's a trend going to continue as video\ncontinues to dominate the digital landscape. These algorithms will extract and\nclassify related features from the video and will use them to describe the\nevents and objects in the video. Deep neural networks have displayed\nencouraging outcomes in the realm of feature extraction and video description.\nThis paper will explore the spatiotemporal features found in videos and recent\nadvancements in deep neural networks in video understanding. We will review\nsome of the main trends in video understanding models and their structural\ndesign, the main problems, and some offered solutions in this topic. We will\nalso review and compare significant video understanding and action recognition\ndatasets.",
      "tldr_zh": "本论文探讨了如何利用深度神经网络提升视频理解能力，重点关注视频中的时空特征(spatiotemporal features)。作者回顾了深度神经网络在特征提取和视频描述方面的最新进展，包括主要视频理解模型的结构设计、面临的关键问题（如算法准确性和泛化性）以及相应的解决方案。论文还比较了重要的视频理解和动作识别数据集(action recognition datasets)，为未来视频分析算法的发展提供了全面见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07277v1",
      "published_date": "2025-02-11 05:44:50 UTC",
      "updated_date": "2025-02-11 05:44:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:11:51.236170"
    },
    {
      "arxiv_id": "2502.07276v1",
      "title": "Dataset Ownership Verification in Contrastive Pre-trained Models",
      "title_zh": "对比预训练模型中的数据集所有权验证",
      "authors": [
        "Yuechen Xie",
        "Jie Song",
        "Mengqi Xue",
        "Haofei Zhang",
        "Xingen Wang",
        "Bingde Hu",
        "Genlang Chen",
        "Mingli Song"
      ],
      "abstract": "High-quality open-source datasets, which necessitate substantial efforts for\ncuration, has become the primary catalyst for the swift progress of deep\nlearning. Concurrently, protecting these datasets is paramount for the\nwell-being of the data owner. Dataset ownership verification emerges as a\ncrucial method in this domain, but existing approaches are often limited to\nsupervised models and cannot be directly extended to increasingly popular\nunsupervised pre-trained models. In this work, we propose the first dataset\nownership verification method tailored specifically for self-supervised\npre-trained models by contrastive learning. Its primary objective is to\nascertain whether a suspicious black-box backbone has been pre-trained on a\nspecific unlabeled dataset, aiding dataset owners in upholding their rights.\nThe proposed approach is motivated by our empirical insights that when models\nare trained with the target dataset, the unary and binary instance\nrelationships within the embedding space exhibit significant variations\ncompared to models trained without the target dataset. We validate the efficacy\nof this approach across multiple contrastive pre-trained models including\nSimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that our\nmethod rejects the null hypothesis with a $p$-value markedly below $0.05$,\nsurpassing all previous methodologies. Our code is available at\nhttps://github.com/xieyc99/DOV4CL.",
      "tldr_zh": "这篇论文提出了一种针对基于对比学习(self-supervised pre-trained models)的数据集所有权验证方法，以帮助数据所有者确认可疑黑盒模型是否使用特定未标注数据集进行预训练。方法基于经验观察，即当模型训练于目标数据集时，嵌入空间中的一元(unary)和二元(binary)实例关系会显著变化。实验在SimCLR、BYOL、SimSiam、MOCO v3和DINO等模型上验证了该方法的有效性，拒绝空假设的p值远低于0.05，并优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07276v1",
      "published_date": "2025-02-11 05:42:21 UTC",
      "updated_date": "2025-02-11 05:42:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:12:04.640990"
    },
    {
      "arxiv_id": "2502.07274v3",
      "title": "Memory Is Not the Bottleneck: Cost-Efficient Continual Learning via Weight Space Consolidation",
      "title_zh": "翻译失败",
      "authors": [
        "Dongkyu Cho",
        "Taesup Moon",
        "Rumi Chunara",
        "Kyunghyun Cho",
        "Sungmin Cha"
      ],
      "abstract": "Continual learning (CL) has traditionally emphasized minimizing exemplar\nmemory usage, assuming that memory is the primary bottleneck. However, in\nmodern computing environments-particularly those involving large foundation\nmodels-memory is inexpensive and abundant, while GPU time constitutes the main\ncost. This paper re-examines CL under a more realistic setting with sufficient\nexemplar memory, where the system can retain a representative portion of past\ndata. We find that, under this regime, stability improves due to reduced\nforgetting, but plasticity diminishes as the model becomes biased toward prior\ntasks and struggles to adapt to new ones. Notably, even simple baselines like\nnaive replay can match or exceed the performance of state-of-the-art methods at\na fraction of the computational cost. Building on this insight, we propose a\nlightweight yet effective method called Weight Space Consolidation, which\ndirectly operates in the model's weight space via two core mechanisms: (1)\nrank-based parameter resets to recover plasticity, and (2) weight averaging to\nenhance stability. Our approach outperforms strong baselines across\nclass-incremental learning with image classifiers and continual instruction\ntuning with large language models, while requiring only one-third to one-fourth\nof the training cost. These findings challenge long-standing CL assumptions and\nestablish a new, cost-efficient baseline for real-world continual learning\nsystems where exemplar memory is no longer the limiting factor.",
      "tldr_zh": "该论文重新审视持续学习（Continual Learning），强调在现代环境中内存充足而计算成本高的问题，指出传统方法忽略了模型的可塑性（Plasticity）下降导致适应新任务的困难。作者提出 Weight Space Consolidation 方法，通过基于排名的参数重置恢复可塑性和权重平均增强稳定性（Stability），以实现高效的学习过程。该方法在图像分类的类增量学习和大型语言模型的持续指令微调任务中，超越强基线模型，只需三分之一到四分之一的训练成本，并为实际应用建立了新的成本高效基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07274v3",
      "published_date": "2025-02-11 05:40:52 UTC",
      "updated_date": "2025-05-20 20:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:12:16.566810"
    },
    {
      "arxiv_id": "2502.07273v2",
      "title": "Variational Learning Induces Adaptive Label Smoothing",
      "title_zh": "翻译失败",
      "authors": [
        "Sin-Han Yang",
        "Zhedong Liu",
        "Gian Maria Marconi",
        "Mohammad Emtiyaz Khan"
      ],
      "abstract": "We show that variational learning naturally induces an adaptive label\nsmoothing where label noise is specialized for each example. Such\nlabel-smoothing is useful to handle examples with labeling errors and\ndistribution shifts, but designing a good adaptivity strategy is not always\neasy. We propose to skip this step and simply use the natural adaptivity\ninduced during the optimization of a variational objective. We show empirical\nresults where a variational algorithm called IVON outperforms traditional label\nsmoothing and yields adaptivity strategies similar to those of an existing\napproach. By connecting Bayesian methods to label smoothing, our work provides\na new way to handle overconfident predictions.",
      "tldr_zh": "本研究发现，变分学习（Variational Learning）能够自然诱导自适应标签平滑（Adaptive Label Smoothing），使标签噪声针对每个样本进行专门化处理，从而有效应对标签错误和分布偏移问题。作者提出直接利用变分目标优化过程中产生的自然自适应性，而非手动设计策略。实验结果显示，名为 IVON 的变分算法优于传统标签平滑，并生成类似于现有方法的自适应策略。通过将贝叶斯方法与标签平滑相连，该工作为处理过度自信预测（overconfident predictions）提供了一种新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07273v2",
      "published_date": "2025-02-11 05:40:42 UTC",
      "updated_date": "2025-03-04 06:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:12:27.488302"
    },
    {
      "arxiv_id": "2502.07842v2",
      "title": "Column-wise Quantization of Weights and Partial Sums for Accurate and Efficient Compute-In-Memory Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyoon Kim",
        "Kang Eun Jeon",
        "Yulhwa Kim",
        "Jong Hwan Ko"
      ],
      "abstract": "Compute-in-memory (CIM) is an efficient method for implementing deep neural\nnetworks (DNNs) but suffers from substantial overhead from analog-to-digital\nconverters (ADCs), especially as ADC precision increases. Low-precision ADCs\ncan reduce this overhead but introduce partial-sum quantization errors\ndegrading accuracy. Additionally, low-bit weight constraints, imposed by cell\nlimitations and the need for multiple cells for higher-bit weights, present\nfurther challenges. While fine-grained partial-sum quantization has been\nstudied to lower ADC resolution effectively, weight granularity, which limits\noverall partial-sum quantized accuracy, remains underexplored. This work\naddresses these challenges by aligning weight and partial-sum quantization\ngranularities at the column-wise level. Our method improves accuracy while\nmaintaining dequantization overhead, simplifies training by removing two-stage\nprocesses, and ensures robustness to memory cell variations via independent\ncolumn-wise scale factors. We also propose an open-source CIM-oriented\nconvolution framework to handle fine-grained weights and partial-sums\nefficiently, incorporating a novel tiling method and group convolution.\nExperimental results on ResNet-20 (CIFAR-10, CIFAR-100) and ResNet-18\n(ImageNet) show accuracy improvements of 0.99%, 2.69%, and 1.01%, respectively,\ncompared to the best-performing related works. Additionally, variation analysis\nreveals the robustness of our method against memory cell variations. These\nfindings highlight the effectiveness of our quantization scheme in enhancing\naccuracy and robustness while maintaining hardware efficiency in CIM-based DNN\nimplementations. Our code is available at\nhttps://github.com/jiyoonkm/ColumnQuant.",
      "tldr_zh": "本文提出了一种列级(column-wise)量化方法，用于Compute-in-Memory (CIM)加速器，以同时量化权重和部分和，从而减少analog-to-digital converters (ADCs)开销并缓解量化错误带来的准确性损失。该方法通过对齐量化粒度简化训练过程、降低去量化开销，并利用独立的列级缩放因子确保对内存单元变异的鲁棒性，同时开发了一个开源CIM导向的卷积框架，包含新型平铺方法和分组卷积。实验结果显示，在ResNet-20 (CIFAR-10和CIFAR-100)及ResNet-18 (ImageNet)上，准确率分别提高了0.99%、2.69%和1.01%，证明了该方案在提升DNNs准确性和硬件效率方面的有效性。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07842v2",
      "published_date": "2025-02-11 05:32:14 UTC",
      "updated_date": "2025-03-13 11:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:12:42.163035"
    },
    {
      "arxiv_id": "2502.07266v1",
      "title": "When More is Less: Understanding Chain-of-Thought Length in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyang Wu",
        "Yifei Wang",
        "Tianqi Du",
        "Stefanie Jegelka",
        "Yisen Wang"
      ],
      "abstract": "Chain-of-thought (CoT) reasoning enhances the multi-step reasoning\ncapabilities of large language models (LLMs) by breaking complex tasks into\nsmaller, manageable sub-tasks. Researchers have been exploring ways to guide\nmodels to generate more complex CoT processes to improve the reasoning ability\nof LLMs, such as long CoT and the test-time scaling law. However, for most\nmodels and tasks, does an increase in CoT length consistently lead to improved\nreasoning accuracy? In this paper, we observe a nuanced relationship: as the\nnumber of reasoning steps increases, performance initially improves but\neventually decreases. To understand this phenomenon, we provide a piece of\nevidence that longer reasoning processes are increasingly susceptible to noise.\nWe theoretically prove the existence of an optimal CoT length and derive a\nscaling law for this optimal length based on model capability and task\ndifficulty. Inspired by our theory, we conduct experiments on both synthetic\nand real world datasets and propose Length-filtered Vote to alleviate the\neffects of excessively long or short CoTs. Our findings highlight the critical\nneed to calibrate CoT length to align with model capabilities and task demands,\noffering a principled framework for optimizing multi-step reasoning in LLMs.",
      "tldr_zh": "本研究探讨了在大型语言模型(LLMs)中，Chain-of-Thought (CoT) 推理长度的影响，发现随着推理步骤增加，模型性能先提升后下降，因为更长的CoT 过程更容易受噪声干扰。作者通过理论分析证明了存在一个最佳CoT 长度，并基于模型能力和任务难度推导出了一个scaling law。实验在合成和真实数据集上验证了这一现象，并提出了Length-filtered Vote 方法，以缓解过长或过短CoT 的负面影响。这些发现强调了需要根据模型能力和任务需求校准CoT 长度，从而优化LLMs的多步推理性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07266v1",
      "published_date": "2025-02-11 05:28:59 UTC",
      "updated_date": "2025-02-11 05:28:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:12:53.000100"
    },
    {
      "arxiv_id": "2502.07254v2",
      "title": "Fairness in Agentic AI: A Unified Framework for Ethical and Equitable Multi-Agent System",
      "title_zh": "翻译失败",
      "authors": [
        "Rajesh Ranjan",
        "Shailja Gupta",
        "Surya Narayan Singh"
      ],
      "abstract": "Ensuring fairness in decentralized multi-agent systems presents significant\nchallenges due to emergent biases, systemic inefficiencies, and conflicting\nagent incentives. This paper provides a comprehensive survey of fairness in\nmulti-agent AI, introducing a novel framework where fairness is treated as a\ndynamic, emergent property of agent interactions. The framework integrates\nfairness constraints, bias mitigation strategies, and incentive mechanisms to\nalign autonomous agent behaviors with societal values while balancing\nefficiency and robustness. Through empirical validation, we demonstrate that\nincorporating fairness constraints results in more equitable decision-making.\nThis work bridges the gap between AI ethics and system design, offering a\nfoundation for accountable, transparent, and socially responsible multi-agent\nAI systems.",
      "tldr_zh": "这篇论文调查了去中心化多智能体系统中的公平性挑战，包括新兴偏差(systemic inefficiencies)和代理冲突激励，并引入了一个统一框架，将公平视为代理互动的动态新兴属性。该框架整合公平约束(fairness constraints)、偏差缓解策略(bias mitigation strategies)和激励机制，以使自主代理行为与社会价值观一致，同时平衡效率和鲁棒性。通过实证验证，研究者证明了加入公平约束能显著提升决策的公平性，为负责任、透明和社会责任的多智能体 AI 系统设计奠定基础。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "12 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2502.07254v2",
      "published_date": "2025-02-11 04:42:00 UTC",
      "updated_date": "2025-03-02 08:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:13:04.452754"
    },
    {
      "arxiv_id": "2502.07250v1",
      "title": "NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Liying Han",
        "Gaofeng Dong",
        "Xiaomin Ouyang",
        "Lance Kaplan",
        "Federico Cerutti",
        "Mani Srivastava"
      ],
      "abstract": "Current machine learning models excel in short-span perception tasks but\nstruggle to derive high-level insights from long-term observation, a capability\ncentral to understanding complex events (CEs). CEs, defined as sequences of\nshort-term atomic events (AEs) governed by spatiotemporal rules, are\nchallenging to detect online due to the need to extract meaningful patterns\nfrom long and noisy sensor data while ignoring irrelevant events. We\nhypothesize that state-based methods are well-suited for CE detection, as they\ncapture event progression through state transitions without requiring long-term\nmemory. Baseline experiments validate this, demonstrating that the state-space\nmodel Mamba outperforms existing architectures. However, Mamba's reliance on\nextensive labeled data, which are difficult to obtain, motivates our second\nhypothesis: decoupling CE rule learning from noisy sensor data can reduce data\nrequirements. To address this, we propose NARCE, a framework that combines\nNeural Algorithmic Reasoning (NAR) to split the task into two components: (i)\nlearning CE rules independently of sensor data using synthetic concept traces\ngenerated by LLMs and (ii) mapping sensor inputs to these rules via an adapter.\nOur results show that NARCE outperforms baselines in accuracy, generalization\nto unseen and longer sensor data, and data efficiency, significantly reducing\nannotation costs while advancing robust CE detection.",
      "tldr_zh": "该论文提出NARCE框架，一种基于Mamba状态空间模型的神经算法推理（Neural Algorithmic Reasoning, NAR）方法，用于实时复杂事件检测（CE detection），以解决机器学习模型在从长期嘈杂传感器数据中提取高水平洞见时的挑战。NARCE将任务分解为两部分：（i）使用LLMs生成的合成概念痕迹独立学习CE规则，（ii）通过适配器将传感器输入映射到这些规则，从而减少对标记数据的依赖。实验结果显示，NARCE在准确性、泛化到未见和更长传感器数据上优于基线模型，并显著降低了标注成本，推动了鲁棒CE检测的进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07250v1",
      "published_date": "2025-02-11 04:34:53 UTC",
      "updated_date": "2025-02-11 04:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:13:16.499753"
    },
    {
      "arxiv_id": "2502.07244v1",
      "title": "Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting",
      "title_zh": "Linear Transformers 作为 VAR 模型：将自回归注意力机制与自回归预测对齐",
      "authors": [
        "Jiecheng Lu",
        "Shihao Yang"
      ],
      "abstract": "Autoregressive attention-based time series forecasting (TSF) has drawn\nincreasing interest, with mechanisms like linear attention sometimes\noutperforming vanilla attention. However, deeper Transformer architectures\nfrequently misalign with autoregressive objectives, obscuring the underlying\nVAR structure embedded within linear attention and hindering their ability to\ncapture the data generative processes in TSF. In this work, we first show that\na single linear attention layer can be interpreted as a dynamic vector\nautoregressive (VAR) structure. We then explain that existing multi-layer\nTransformers have structural mismatches with the autoregressive forecasting\nobjective, which impair interpretability and generalization ability. To address\nthis, we show that by rearranging the MLP, attention, and input-output flow,\nmulti-layer linear attention can also be aligned as a VAR model. Then, we\npropose Structural Aligned Mixture of VAR (SAMoVAR), a linear Transformer\nvariant that integrates interpretable dynamic VAR weights for multivariate TSF.\nBy aligning the Transformer architecture with autoregressive objectives,\nSAMoVAR delivers improved performance, interpretability, and computational\nefficiency, comparing to SOTA TSF models.",
      "tldr_zh": "该论文揭示了线性Transformer可以被解释为动态向量自回归(VAR)模型，从而解决自回归注意力机制在时序预测(TSF)中的结构不匹配问题，改善了模型的可解释性和泛化能力。作者首先证明单个线性注意力层等价于VAR结构，并分析多层Transformer的缺陷。接着，通过重新排列MLP、注意力层和输入输出流，他们提出Structural Aligned Mixture of VAR (SAMoVAR)，一种集成了可解释动态VAR权重的线性Transformer变体。实验结果显示，SAMoVAR在多变量TSF任务上比现有最先进模型提供了更好的性能、解释性和计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07244v1",
      "published_date": "2025-02-11 04:24:43 UTC",
      "updated_date": "2025-02-11 04:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:13:28.447493"
    },
    {
      "arxiv_id": "2502.07243v1",
      "title": "Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Xueyao Zhang",
        "Xiaohui Zhang",
        "Kainan Peng",
        "Zhenyu Tang",
        "Vimal Manohar",
        "Yingru Liu",
        "Jeff Hwang",
        "Dangna Li",
        "Yuhao Wang",
        "Julian Chan",
        "Yuan Huang",
        "Zhizheng Wu",
        "Mingbo Ma"
      ],
      "abstract": "The imitation of voice, targeted on specific speech attributes such as timbre\nand speaking style, is crucial in speech generation. However, existing methods\nrely heavily on annotated data, and struggle with effectively disentangling\ntimbre and style, leading to challenges in achieving controllable generation,\nespecially in zero-shot scenarios. To address these issues, we propose Vevo, a\nversatile zero-shot voice imitation framework with controllable timbre and\nstyle. Vevo operates in two core stages: (1) Content-Style Modeling: Given\neither text or speech's content tokens as input, we utilize an autoregressive\ntransformer to generate the content-style tokens, which is prompted by a style\nreference; (2) Acoustic Modeling: Given the content-style tokens as input, we\nemploy a flow-matching transformer to produce acoustic representations, which\nis prompted by a timbre reference. To obtain the content and content-style\ntokens of speech, we design a fully self-supervised approach that progressively\ndecouples the timbre, style, and linguistic content of speech. Specifically, we\nadopt VQ-VAE as the tokenizer for the continuous hidden features of HuBERT. We\ntreat the vocabulary size of the VQ-VAE codebook as the information bottleneck,\nand adjust it carefully to obtain the disentangled speech representations.\nSolely self-supervised trained on 60K hours of audiobook speech data, without\nany fine-tuning on style-specific corpora, Vevo matches or surpasses existing\nmethods in accent and emotion conversion tasks. Additionally, Vevo's\neffectiveness in zero-shot voice conversion and text-to-speech tasks further\ndemonstrates its strong generalization and versatility. Audio samples are\navailable at https://versavoice.github.io.",
      "tldr_zh": "本文提出Vevo框架，实现可控的零-shot语音模仿，通过self-supervised disentanglement方法有效分离timbre、style和语言内容。Vevo包括两个核心阶段：Content-Style Modeling，使用autoregressive transformer生成内容-风格标记；以及Acoustic Modeling，使用flow-matching transformer基于timbre参考产生声学表示。基于VQ-VAE的tokenizer在60K小时有声书数据上完全自监督训练，Vevo在口音和情感转换任务中匹配或超越现有方法，并在zero-shot语音转换和文本到语音任务中展示出强泛化性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07243v1",
      "published_date": "2025-02-11 04:18:33 UTC",
      "updated_date": "2025-02-11 04:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:13:40.843396"
    },
    {
      "arxiv_id": "2502.07239v1",
      "title": "Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation",
      "title_zh": "Contextual Gesture：通过上下文感知手势表示的伴随语音手势视频生成",
      "authors": [
        "Pinxin Liu",
        "Pengfei Zhang",
        "Hyeongwoo Kim",
        "Pablo Garrido",
        "Ari Sharpio",
        "Kyle Olszewski"
      ],
      "abstract": "Co-speech gesture generation is crucial for creating lifelike avatars and\nenhancing human-computer interactions by synchronizing gestures with speech.\nDespite recent advancements, existing methods struggle with accurately\nidentifying the rhythmic or semantic triggers from audio for generating\ncontextualized gesture patterns and achieving pixel-level realism. To address\nthese challenges, we introduce Contextual Gesture, a framework that improves\nco-speech gesture video generation through three innovative components: (1) a\nchronological speech-gesture alignment that temporally connects two modalities,\n(2) a contextualized gesture tokenization that incorporate speech context into\nmotion pattern representation through distillation, and (3) a structure-aware\nrefinement module that employs edge connection to link gesture keypoints to\nimprove video generation. Our extensive experiments demonstrate that Contextual\nGesture not only produces realistic and speech-aligned gesture videos but also\nsupports long-sequence generation and video gesture editing applications, shown\nin Fig.1 Project Page: https://andypinxinliu.github.io/Contextual-Gesture/.",
      "tldr_zh": "该研究提出 Contextual Gesture 框架，用于提升 Co-speech gesture video generation 的效果，通过上下文感知的手势表示来同步语音和手势。框架包括三个创新组件：(1) 按时间顺序的语音-手势对齐，连接两个模态；(2) 上下文化的手势标记化，通过蒸馏将语音上下文融入动作模式；(3) 结构感知的精炼模块，使用边缘连接优化手势关键点以改善视频生成。实验结果显示，该框架能生成逼真且与语音对齐的手势视频，支持长序列生成和视频编辑应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07239v1",
      "published_date": "2025-02-11 04:09:12 UTC",
      "updated_date": "2025-02-11 04:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:13:51.775693"
    },
    {
      "arxiv_id": "2502.07238v2",
      "title": "Diffusion Suction Grasping with Large-Scale Parcel Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Ding-Tao Huang",
        "Xinyi He",
        "Debei Hua",
        "Dongfang Yu",
        "En-Te Lin",
        "Long Zeng"
      ],
      "abstract": "While recent advances in object suction grasping have shown remarkable\nprogress, significant challenges persist particularly in cluttered and complex\nparcel handling scenarios. Two fundamental limitations hinder current\napproaches: (1) the lack of a comprehensive suction grasp dataset tailored for\nparcel manipulation tasks, and (2) insufficient adaptability to diverse object\ncharacteristics including size variations, geometric complexity, and textural\ndiversity. To address these challenges, we present Parcel-Suction-Dataset, a\nlarge-scale synthetic dataset containing 25 thousand cluttered scenes with 410\nmillion precision-annotated suction grasp poses. This dataset is generated\nthrough our novel geometric sampling algorithm that enables efficient\ngeneration of optimal suction grasps incorporating both physical constraints\nand material properties. We further propose Diffusion-Suction, an innovative\nframework that reformulates suction grasp prediction as a conditional\ngeneration task through denoising diffusion probabilistic models. Our method\niteratively refines random noise into suction grasp score maps through\nvisual-conditioned guidance from point cloud observations, effectively learning\nspatial point-wise affordances from our synthetic dataset. Extensive\nexperiments demonstrate that the simple yet efficient Diffusion-Suction\nachieves new state-of-the-art performance compared to previous models on both\nParcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.",
      "tldr_zh": "本文解决了物体吸取抓取在杂乱包裹场景中的挑战，包括数据集缺失和对物体多样性的适应不足，提出了大型合成数据集 Parcel-Suction-Dataset 和创新框架 Diffusion-Suction。Parcel-Suction-Dataset 包含 25,000 个杂乱场景和 4.1 亿个精确标注的吸取抓取姿势，通过新型几何采样算法考虑物理约束和材料属性生成。Diffusion-Suction 框架将吸取抓取预测转化为条件生成任务，使用 denoising diffusion probabilistic models 通过点云观察的视觉指导迭代精炼噪声为分数地图。实验证明，该方法在 Parcel-Suction-Dataset 和 SuctionNet-1Billion 基准上实现了新的最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07238v2",
      "published_date": "2025-02-11 04:09:11 UTC",
      "updated_date": "2025-03-17 03:26:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:14:04.919562"
    },
    {
      "arxiv_id": "2502.07218v1",
      "title": "LUNAR: LLM Unlearning via Neural Activation Redirection",
      "title_zh": "翻译失败",
      "authors": [
        "William F. Shen",
        "Xinchi Qiu",
        "Meghdad Kurmanji",
        "Alex Iacob",
        "Lorenzo Sani",
        "Yihong Chen",
        "Nicola Cancedda",
        "Nicholas D. Lane"
      ],
      "abstract": "Large Language Models (LLMs) benefit from training on ever larger amounts of\ntextual data, but as a result, they increasingly incur the risk of leaking\nprivate information. The ability to selectively remove knowledge from LLMs is,\ntherefore, a highly desirable capability. In this paper, we propose LUNAR, a\nnovel unlearning methodology grounded in the Linear Representation Hypothesis.\nLUNAR operates by redirecting the representations of unlearned data to regions\nthat trigger the model's inherent ability to express its inability to answer.\nLUNAR achieves state-of-the-art unlearning performance while significantly\nenhancing the controllability of the unlearned model during inference.\nSpecifically, LUNAR achieves between 2.9x to 11.7x improvements on combined\n\"unlearning efficacy\" and \"model utility\" score (\"Deviation Score\") on the\nPISTOL dataset across various base models. We also demonstrate, through\nquantitative analysis and qualitative examples, LUNAR's superior\ncontrollability in generating coherent and contextually aware responses,\nmitigating undesired side effects of existing methods. Moreover, we demonstrate\nthat LUNAR is robust against white-box adversarial attacks and versatile in\nhandling real-world scenarios, such as processing sequential unlearning\nrequests.",
      "tldr_zh": "该论文提出LUNAR，一种基于Linear Representation Hypothesis的创新方法，用于从大型语言模型(LLMs)中选择性地移除知识，以防止私人信息泄露。LUNAR通过重定向未学习数据的神经激活表示，使模型能够主动表达“无法回答”，从而提升未学习过程的可控性和有效性。在PISTOL数据集上，LUNAR实现了2.9x到11.7x的Deviation Score改善，同时生成更连贯的响应，并证明其对白盒攻击的鲁棒性和处理顺序未学习请求的能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07218v1",
      "published_date": "2025-02-11 03:23:22 UTC",
      "updated_date": "2025-02-11 03:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:14:15.484614"
    },
    {
      "arxiv_id": "2502.07216v1",
      "title": "SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxi Li",
        "Yuchen Guo",
        "Jilai Zheng",
        "Haozhe Lin",
        "Chao Ma",
        "Lu Fang",
        "Xiaokang Yang"
      ],
      "abstract": "Recent years have seen an increase in the use of gigapixel-level image and\nvideo capture systems and benchmarks with high-resolution wide (HRW) shots.\nHowever, unlike close-up shots in the MS COCO dataset, the higher resolution\nand wider field of view raise unique challenges, such as extreme sparsity and\nhuge scale changes, causing existing close-up detectors inaccuracy and\ninefficiency. In this paper, we present a novel model-agnostic sparse vision\ntransformer, dubbed SparseFormer, to bridge the gap of object detection between\nclose-up and HRW shots. The proposed SparseFormer selectively uses attentive\ntokens to scrutinize the sparsely distributed windows that may contain objects.\nIn this way, it can jointly explore global and local attention by fusing\ncoarse- and fine-grained features to handle huge scale changes. SparseFormer\nalso benefits from a novel Cross-slice non-maximum suppression (C-NMS)\nalgorithm to precisely localize objects from noisy windows and a simple yet\neffective multi-scale strategy to improve accuracy. Extensive experiments on\ntwo HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed\nSparseFormer significantly improves detection accuracy (up to 5.8%) and speed\n(up to 3x) over the state-of-the-art approaches.",
      "tldr_zh": "这篇论文提出了SparseFormer，一种针对高分辨率宽视野（HRW）图像的稀疏视觉Transformer模型，用于解决对象检测中的极度稀疏和巨大尺度变化问题。SparseFormer通过选择性注意力token来检查可能包含物体的稀疏窗口，并融合粗粒度和细粒度特征，同时引入Cross-slice非极大值抑制（C-NMS）算法和多尺度策略，以提高检测的准确性和效率。在PANDA和DOTA-v1.0基准测试上，该模型相比现有方法显著提升了检测准确率（最高5.8%）和速度（最高3倍）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted to ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.07216v1",
      "published_date": "2025-02-11 03:21:25 UTC",
      "updated_date": "2025-02-11 03:21:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:14:28.148816"
    },
    {
      "arxiv_id": "2502.07214v1",
      "title": "Pareto Optimal Algorithmic Recourse in Multi-cost Function",
      "title_zh": "翻译失败",
      "authors": [
        "Wen-Ling Chen",
        "Hong-Chang Huang",
        "Kai-Hung Lin",
        "Shang-Wei Hwang",
        "Hao-Tsung Yang"
      ],
      "abstract": "In decision-making systems, algorithmic recourse aims to identify\nminimal-cost actions to alter an individual features, thereby obtaining a\ndesired outcome. This empowers individuals to understand, question, or alter\ndecisions that negatively affect them. However, due to the variety and\nsensitivity of system environments and individual personalities, quantifying\nthe cost of a single function is nearly impossible while considering multiple\ncriteria situations. Most current recourse mechanisms use gradient-based\nmethods that assume cost functions are differentiable, often not applicable in\nreal-world scenarios, resulting in sub-optimal solutions that compromise\nvarious criteria. These solutions are typically intractable and lack rigorous\ntheoretical foundations, raising concerns regarding interpretability,\nreliability, and transparency from the explainable AI (XAI) perspective.\n  To address these issues, this work proposes an algorithmic recourse framework\nthat handles non-differentiable and discrete multi-cost functions. By\nformulating recourse as a multi-objective optimization problem and assigning\nweights to different criteria based on their importance, our method identifies\nPareto optimal recourse recommendations. To demonstrate scalability, we\nincorporate the concept of epsilon-net, proving the ability to find\napproximated Pareto optimal actions. Experiments show the trade-off between\ndifferent criteria and the methods scalability in large graphs. Compared to\ncurrent heuristic practices, our approach provides a stronger theoretical\nfoundation and better aligns recourse suggestions with real-world requirements.",
      "tldr_zh": "本研究针对算法补救（algorithmic recourse）在多成本函数场景中的挑战，提出了一种处理非可微和离散函数的框架，以解决现有基于梯度的方法在真实世界应用中存在的次优解和解释性问题。该框架将补救问题表述为多目标优化问题，通过为不同标准分配权重来识别Pareto optimal推荐，从而平衡多重准则的权衡。为提升可扩展性，该方法引入epsilon-net概念，证明了寻找近似Pareto optimal行动的有效性。实验结果显示，该方法在大型图结构上表现出色，并提供更强的理论基础，比传统启发式方法更符合实际需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07214v1",
      "published_date": "2025-02-11 03:16:08 UTC",
      "updated_date": "2025-02-11 03:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:14:39.732072"
    },
    {
      "arxiv_id": "2502.07213v2",
      "title": "Evaluation for Regression Analyses on Evolving Data Streams",
      "title_zh": "翻译失败",
      "authors": [
        "Yibin Sun",
        "Heitor Murilo Gomes",
        "Bernhard Pfahringer",
        "Albert Bifet"
      ],
      "abstract": "The paper explores the challenges of regression analysis in evolving data\nstreams, an area that remains relatively underexplored compared to\nclassification. We propose a standardized evaluation process for regression and\nprediction interval tasks in streaming contexts. Additionally, we introduce an\ninnovative drift simulation strategy capable of synthesizing various drift\ntypes, including the less-studied incremental drift. Comprehensive experiments\nwith state-of-the-art methods, conducted under the proposed process, validate\nthe effectiveness and robustness of our approach.",
      "tldr_zh": "这篇论文探讨了在演化数据流(evolving data streams)中进行回归分析(regression analyses)的挑战，该领域相比分类任务仍未得到充分研究。\n论文提出一个标准化的评估过程，用于处理数据流中的回归和预测区间(prediction interval)任务。\n此外，他们引入了一种创新的漂移模拟(drift simulation)策略，能合成各种漂移类型，包括较少研究的增量漂移。\n通过与最先进方法的全面实验，验证了该方法的有效性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 Pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07213v2",
      "published_date": "2025-02-11 03:12:08 UTC",
      "updated_date": "2025-02-19 01:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:14:52.052050"
    },
    {
      "arxiv_id": "2502.07207v1",
      "title": "A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Hallaji",
        "Roozbeh Razavi-Far",
        "Mehrdad Saif"
      ],
      "abstract": "Advanced Persistent Threats (APTs) pose a significant security risk to\norganizations and industries. These attacks often lead to severe data breaches\nand compromise the system for a long time. Mitigating these sophisticated\nattacks is highly challenging due to the stealthy and persistent nature of\nAPTs. Machine learning models are often employed to tackle this challenge by\nbringing automation and scalability to APT detection. Nevertheless, these\nintelligent methods are data-driven, and thus, highly affected by the quality\nand relevance of input data. This paper aims to analyze measurements considered\nwhen recording network traffic and conclude which features contribute more to\ndetecting APT samples. To do this, we study the features associated with\nvarious APT cases and determine their importance using a machine learning\nframework. To ensure the generalization of our findings, several feature\nselection techniques are employed and paired with different classifiers to\nevaluate their effectiveness. Our findings provide insights into how APT\ndetection can be enhanced in real-world scenarios.",
      "tldr_zh": "本文研究了使用机器学习检测高级持续性威胁 (APTs) 时，网络流量特征的重要性，旨在识别哪些特征能有效提升检测性能。研究方法包括分析各种 APT 案例的关联特征，并采用多种特征选择技术和分类器进行评估，以确保结果的泛化性。结果显示，关键特征的优化可显著改善 APT 检测效果，为真实世界场景中的安全防护提供宝贵见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for publication in the 2024 International Conference on\n  Computational Science and Computational Intelligence (CSCI'24)",
      "pdf_url": "http://arxiv.org/pdf/2502.07207v1",
      "published_date": "2025-02-11 03:06:03 UTC",
      "updated_date": "2025-02-11 03:06:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:15:03.657054"
    },
    {
      "arxiv_id": "2502.07205v2",
      "title": "VINP: Variational Bayesian Inference with Neural Speech Prior for Joint ASR-Effective Speech Dereverberation and Blind RIR Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Pengyu Wang",
        "Ying Fang",
        "Xiaofei Li"
      ],
      "abstract": "Reverberant speech, denoting the speech signal degraded by the process of\nreverberation, contains crucial knowledge of both anechoic source speech and\nroom impulse response (RIR). This work proposes a variational Bayesian\ninference (VBI) framework with neural speech prior (VINP) for joint speech\ndereverberation and blind RIR identification. In VINP, a probabilistic signal\nmodel is constructed in the time-frequency (T-F) domain based on convolution\ntransfer function (CTF) approximation. For the first time, we propose using an\narbitrary discriminative dereverberation deep neural network (DNN) to predict\nthe prior distribution of anechoic speech within a probabilistic model. By\nintegrating both reverberant speech and the anechoic speech prior, VINP yields\nthe maximum a posteriori (MAP) and maximum likelihood (ML) estimations of the\nanechoic speech spectrum and CTF filter, respectively. After simple\ntransformations, the waveforms of anechoic speech and RIR are estimated.\nMoreover, VINP is effective for automatic speech recognition (ASR) systems,\nwhich sets it apart from most deep learning (DL)-based single-channel\ndereverberation approaches. Experiments on single-channel speech\ndereverberation demonstrate that VINP reaches an advanced level in most metrics\nrelated to human perception and displays unquestionable state-of-the-art (SOTA)\nperformance in ASR-related metrics. For blind RIR identification, experiments\nindicate that VINP attains the SOTA level in blind estimation of reverberation\ntime at 60 dB (RT60) and direct-to-reverberation ratio (DRR). Codes and audio\nsamples are available online.",
      "tldr_zh": "本论文提出VINP框架，利用Variational Bayesian Inference与Neural Speech Prior，实现联合语音去混响和盲RIR识别，同时优化Automatic Speech Recognition (ASR)性能。框架在时频域构建概率信号模型，使用卷积传输函数（CTF）近似，并首次整合判别式DNN预测无混响语音的先验分布，以获得无混响语音谱和CTF滤波器的最大后验估计和最大似然估计。实验结果表明，VINP在单通道语音去混响任务中，在人类感知相关指标上达到先进水平，在ASR相关指标上实现State-of-the-Art (SOTA)性能，并在盲RIR识别中（如RT60和DRR）表现出SOTA水平。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to IEEE/ACM Trans. on TASLP",
      "pdf_url": "http://arxiv.org/pdf/2502.07205v2",
      "published_date": "2025-02-11 02:54:28 UTC",
      "updated_date": "2025-02-24 08:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:15:17.111291"
    },
    {
      "arxiv_id": "2502.07202v2",
      "title": "Monte Carlo Tree Diffusion for System 2 Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Jaesik Yoon",
        "Hyeonseo Cho",
        "Doojin Baek",
        "Yoshua Bengio",
        "Sungjin Ahn"
      ],
      "abstract": "Diffusion models have recently emerged as a powerful tool for planning.\nHowever, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally\nimproves with additional test-time computation (TTC), standard diffusion-based\nplanners offer only limited avenues for TTC scalability. In this paper, we\nintroduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates\nthe generative strength of diffusion models with the adaptive search\ncapabilities of MCTS. Our method reconceptualizes denoising as a\ntree-structured process, allowing partially denoised plans to be iteratively\nevaluated, pruned, and refined. By selectively expanding promising trajectories\nwhile retaining the flexibility to revisit and improve suboptimal branches,\nMCTD achieves the benefits of MCTS such as controlling exploration-exploitation\ntrade-offs within the diffusion framework. Empirical results on challenging\nlong-horizon tasks show that MCTD outperforms diffusion baselines, yielding\nhigher-quality solutions as TTC increases.",
      "tldr_zh": "本论文提出 Monte Carlo Tree Diffusion (MCTD)，一种将扩散模型的生成能力与 Monte Carlo Tree Search (MCTS) 的自适应搜索功能相结合的框架，用于提升 System 2 Planning 的性能。MCTD 将去噪过程重新设计为树状结构，允许对部分去噪计划进行迭代评估、修剪和精炼，从而实现更好的探索-利用权衡。实验结果显示，在具有挑战性的长时域任务上，MCTD 优于传统扩散基线，随着测试时计算 (TTC) 增加，能生成更高质量的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07202v2",
      "published_date": "2025-02-11 02:51:42 UTC",
      "updated_date": "2025-04-11 00:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:15:30.247866"
    },
    {
      "arxiv_id": "2502.07194v1",
      "title": "Dense Object Detection Based on De-homogenized Queries",
      "title_zh": "基于去同质化查询的密集物体检测",
      "authors": [
        "Yueming Huang",
        "Chenrui Ma",
        "Hao Zhou",
        "Hao Wu",
        "Guowu Yuan"
      ],
      "abstract": "Dense object detection is widely used in automatic driving, video\nsurveillance, and other fields. This paper focuses on the challenging task of\ndense object detection. Currently, detection methods based on greedy\nalgorithms, such as non-maximum suppression (NMS), often produce many\nrepetitive predictions or missed detections in dense scenarios, which is a\ncommon problem faced by NMS-based algorithms. Through the end-to-end DETR\n(DEtection TRansformer), as a type of detector that can incorporate the\npost-processing de-duplication capability of NMS, etc., into the network, we\nfound that homogeneous queries in the query-based detector lead to a reduction\nin the de-duplication capability of the network and the learning efficiency of\nthe encoder, resulting in duplicate prediction and missed detection problems.\nTo solve this problem, we propose learnable differentiated encoding to\nde-homogenize the queries, and at the same time, queries can communicate with\neach other via differentiated encoding information, replacing the previous\nself-attention among the queries. In addition, we used joint loss on the output\nof the encoder that considered both location and confidence prediction to give\na higher-quality initialization for queries. Without cumbersome decoder\nstacking and guaranteeing accuracy, our proposed end-to-end detection framework\nwas more concise and reduced the number of parameters by about 8% compared to\ndeformable DETR. Our method achieved excellent results on the challenging\nCrowdHuman dataset with 93.6% average precision (AP), 39.2% MR-2, and 84.3% JI.\nThe performance overperformed previous SOTA methods, such as Iter-E2EDet\n(Progressive End-to-End Object Detection) and MIP (One proposal, Multiple\npredictions). In addition, our method is more robust in various scenarios with\ndifferent densities.",
      "tldr_zh": "本文针对密集物体检测（Dense Object Detection）中的重复预测和漏检问题，分析了查询-based 检测器如 DETR 中同质查询（homogeneous queries）导致的去重能力减弱和学习效率低下。作者提出 learnable differentiated encoding 方法来实现查询去同质化（de-homogenize queries），并让查询通过差异化编码信息相互通信，取代传统的自注意力机制，同时使用考虑位置和置信度的联合损失（joint loss）在编码器输出上提供高质量初始化。相比 deformable DETR，该端到端框架更简洁，参数减少约 8%，无需堆叠解码器。在 CrowdHuman 数据集上，该方法达到了 93.6% AP、39.2% MR-2 和 84.3% JI 的性能，超越了 Iter-E2EDet 和 MIP 等 SOTA 方法，并在不同密度场景中表现出更高的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07194v1",
      "published_date": "2025-02-11 02:36:10 UTC",
      "updated_date": "2025-02-11 02:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:15:42.923775"
    },
    {
      "arxiv_id": "2502.07838v2",
      "title": "NanoVLMs: How small can we go and still make coherent Vision Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Mukund Agarwalla",
        "Himanshu Kumar",
        "Raj Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "Vision-Language Models (VLMs), such as GPT-4V and Llama 3.2 vision, have\ngarnered significant research attention for their ability to leverage Large\nLanguage Models (LLMs) in multimodal tasks. However, their potential is\nconstrained by inherent challenges, including proprietary restrictions,\nsubstantial computational demands, and limited accessibility. Smaller models,\nsuch as GIT and BLIP, exhibit marked limitations, often failing to generate\ncoherent and consistent text beyond a few tokens, even with extensive training.\nThis underscores a pivotal inquiry: how small can a VLM be and still produce\nfluent and consistent text? Drawing inspiration from the exceptional learning\nprocess of 3-4 year old children, who rely heavily on visual cues for\nunderstanding and communication, we introduce two novel datasets: ShortDesc\n(featuring concise image descriptions) and LongDesc (containing more detailed\nimage descriptions). These datasets consist of image-text pairs where the text\nis restricted to the simple vocabulary and syntax typically used by young\nchildren, generated with a scaled-down model, GPT-4o. Using these datasets, we\ndemonstrate that it is possible to train VLMs that are significantly smaller,\nup to 10 times smaller than state of the art(SOTA) small VLMs while maintaining\narchitectural simplicity. To evaluate the outputs, we leverage GPT-4o to grade\nthe text, as if stories written by students, on creativity, meaningfulness, and\nconsistency, assigning scores out of 10. This method addresses limitations of\nstandard benchmarks by accommodating unstructured outputs and providing a\nmultidimensional evaluation of the model capabilities. Our findings contribute\nto the development of lightweight, accessible multimodal models for resource\nconstrained environments.",
      "tldr_zh": "这篇论文探讨了视觉语言模型（VLMs）的规模极限，针对现有模型（如 GIT 和 BLIP）的连贯性不足问题，提出一个关键疑问：VLMs 能多小还能生成流畅一致的文本。受 3-4 岁儿童视觉学习启发，研究者创建了两个新数据集——ShortDesc（简短图像描述）和 LongDesc（详细图像描述），这些数据集使用简单词汇和句法，由 GPT-4o 生成。利用这些数据集，他们训练出比现有 SOTA 小模型小 10 倍的轻量级 VLMs，同时保持架构简单，并通过 GPT-4o 多维度评估（如创意、意义和一致性）。这项工作为资源受限环境开发可访问的多模态模型提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.07838v2",
      "published_date": "2025-02-11 02:31:45 UTC",
      "updated_date": "2025-02-13 11:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:15:53.923964"
    },
    {
      "arxiv_id": "2502.07191v4",
      "title": "Bag of Tricks for Inference-time Computation of LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Liu",
        "Wenshuo Chao",
        "Naiqiang Tan",
        "Hao Liu"
      ],
      "abstract": "With the advancement of large language models (LLMs), solving complex\nreasoning tasks has gained increasing attention. Inference-time computation\nmethods (e.g., Best-of-N, beam search, et al.) are particularly valuable as\nthey can enhance reasoning performance without modifying model parameters or\nrequiring additional training. However, these techniques come with\nimplementation challenges, and most existing methods remain at the\nproof-of-concept stage with limited practical adoption due to their\ncomputational complexity and varying effectiveness across different tasks. In\nthis paper, we investigate and benchmark diverse inference-time computation\nstrategies across reasoning tasks of varying complexity. Since most current\nmethods rely on a proposer-verifier pipeline that first generates candidate\nsolutions (e.g., reasoning solutions) and then selects the best one based on\nreward signals (e.g., RLHF rewards, process rewards), our research focuses on\noptimizing both candidate solution generation (e.g., instructing prompts,\nhyperparameters such as temperature and top-p) and reward mechanisms (e.g.,\nself-evaluation, reward types). Through extensive experiments (more than 20,000\nA100-80G GPU hours with over 1,000 experiments) across a variety of models\n(e.g., Llama, Qwen, and Mistral families) of various sizes, our ablation\nstudies reveal that previously overlooked strategies can significantly enhance\nperformance (e.g., tuning temperature can improve reasoning task performance by\nup to 5%). Furthermore, we establish a standardized benchmark for\ninference-time computation by systematically evaluating six representative\nmethods across eight reasoning tasks. These findings provide a stronger\nfoundation for future research. The code is available at\nhttps://github.com/usail-hkust/benchmark_inference_time_computation_LLM",
      "tldr_zh": "这篇论文探讨了推理时间计算方法（如 Best-of-N 和 beam search），旨在提升大型语言模型(LLMs)的复杂推理性能，而无需修改模型参数或额外训练。研究重点优化了 proposer-verifier 管道，包括候选解决方案生成（通过提示设计和超参数如温度、top-p调整）和奖励机制（如自评估和奖励类型）。通过超过20,000 A100-80G GPU小时的实验，在多种模型（如 Llama、Qwen 和 Mistral 系列）和八个推理任务上，论文发现一些被忽略的策略（如温度调优）可将性能提高多达5%，并建立了标准化基准以支持未来研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07191v4",
      "published_date": "2025-02-11 02:31:11 UTC",
      "updated_date": "2025-02-17 03:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:16:06.115700"
    },
    {
      "arxiv_id": "2502.07190v2",
      "title": "Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task",
      "title_zh": "理解 LLMs 的流体智能缺陷：ARC Task 的分析",
      "authors": [
        "Junjie Wu",
        "Mo Yu",
        "Lemao Liu",
        "Dit-Yan Yeung",
        "Jie Zhou"
      ],
      "abstract": "While LLMs have exhibited strong performance on various NLP tasks, it is\nnoteworthy that most of these tasks rely on utilizing the vast amount of\nknowledge encoded in LLMs' parameters, rather than solving new problems without\nprior knowledge. In cognitive research, the latter ability is referred to as\nfluid intelligence, which is considered to be critical for assessing human\nintelligence. Recent research on fluid intelligence assessments has highlighted\nsignificant deficiencies in LLMs' abilities. In this paper, we analyze the\nchallenges LLMs face in demonstrating fluid intelligence through controlled\nexperiments, using the most representative ARC task as an example. Our study\nrevealed three major limitations in existing LLMs: limited ability for skill\ncomposition, unfamiliarity with abstract input formats, and the intrinsic\ndeficiency of left-to-right decoding. Our data and code can be found in\nhttps://wujunjie1998.github.io/araoc-benchmark.github.io/.",
      "tldr_zh": "本文分析了大型语言模型（LLMs）在流体智能（fluid intelligence）方面的缺陷，强调LLMs主要依赖参数中编码的现有知识，而非解决新问题。研究通过控制实验，以ARC任务为例，揭示了LLMs的三大限制：技能组合能力有限、对抽象输入格式不熟悉，以及左到右解码的固有缺陷。这些发现有助于评估LLMs的认知局限性，并提供了相关数据和代码以供进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 9 figures, accepted by NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2502.07190v2",
      "published_date": "2025-02-11 02:31:09 UTC",
      "updated_date": "2025-03-03 06:50:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:16:16.964267"
    },
    {
      "arxiv_id": "2502.07184v1",
      "title": "Refine Knowledge of Large Language Models via Adaptive Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yinghui Li",
        "Haojing Huang",
        "Jiayi Kuang",
        "Yangning Li",
        "Shu-Yu Guo",
        "Chao Qu",
        "Xiaoyu Tan",
        "Hai-Tao Zheng",
        "Ying Shen",
        "Philip S. Yu"
      ],
      "abstract": "How to alleviate the hallucinations of Large Language Models (LLMs) has\nalways been the fundamental goal pursued by the LLMs research community.\nLooking through numerous hallucination-related studies, a mainstream category\nof methods is to reduce hallucinations by optimizing the knowledge\nrepresentation of LLMs to change their output. Considering that the core focus\nof these works is the knowledge acquired by models, and knowledge has long been\na central theme in human societal progress, we believe that the process of\nmodels refining knowledge can greatly benefit from the way humans learn. In our\nwork, by imitating the human learning process, we design an Adaptive\nContrastive Learning strategy. Our method flexibly constructs different\npositive and negative samples for contrastive learning based on LLMs' actual\nmastery of knowledge. This strategy helps LLMs consolidate the correct\nknowledge they already possess, deepen their understanding of the correct\nknowledge they have encountered but not fully grasped, forget the incorrect\nknowledge they previously learned, and honestly acknowledge the knowledge they\nlack. Extensive experiments and detailed analyses on widely used datasets\ndemonstrate the effectiveness of our method.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 的幻觉（hallucinations）问题，提出了一种 Adaptive Contrastive Learning 策略，通过模仿人类学习过程来优化模型的知识表示。该方法根据 LLMs 对知识的实际掌握，动态构建正负样本，帮助模型巩固正确知识、加深部分掌握知识的理解、遗忘错误知识并承认知识缺失。在广泛数据集上的实验证明，该策略有效降低了幻觉，提升了模型的知识精炼能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07184v1",
      "published_date": "2025-02-11 02:19:13 UTC",
      "updated_date": "2025-02-11 02:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:16:27.738166"
    },
    {
      "arxiv_id": "2502.07179v1",
      "title": "Improved YOLOv7 model for insulator defect detection",
      "title_zh": "改进的 YOLOv7 模型用于绝缘子缺陷检测",
      "authors": [
        "Zhenyue Wang",
        "Guowu Yuan",
        "Hao Zhou",
        "Yi Ma",
        "Yutang Ma",
        "Dong Chen"
      ],
      "abstract": "Insulators are crucial insulation components and structural supports in power\ngrids, playing a vital role in the transmission lines. Due to temperature\nfluctuations, internal stress, or damage from hail, insulators are prone to\ninjury. Automatic detection of damaged insulators faces challenges such as\ndiverse types, small defect targets, and complex backgrounds and shapes. Most\nresearch for detecting insulator defects has focused on a single defect type or\na specific material. However, the insulators in the grid's transmission lines\nhave different colors and materials. Various insulator defects coexist, and the\nexisting methods have difficulty meeting the practical application\nrequirements. Current methods suffer from low detection accuracy and mAP0.5\ncannot meet application requirements. This paper proposes an improved YOLOv7\nmodel for multi-type insulator defect detection. First, our model replaces the\nSPPCSPC module with the RFB module to enhance the network's feature extraction\ncapability. Second, a CA mechanism is introduced into the head part to enhance\nthe network's feature representation ability and to improve detection accuracy.\nThird, a WIoU loss function is employed to address the low-quality samples\nhindering model generalization during training, thereby improving the model's\noverall performance. The experimental results indicate that the proposed model\nexhibits enhancements across various performance metrics. Specifically, there\nis a 1.6% advancement in mAP_0.5, a corresponding 1.6% enhancement in\nmAP_0.5:0.95, a 1.3% elevation in precision, and a 1% increase in recall.\nMoreover, the model achieves parameter reduction by 3.2 million, leading to a\ndecrease of 2.5 GFLOPS in computational cost. Notably, there is also an\nimprovement of 2.81 milliseconds in single-image detection speed.",
      "tldr_zh": "本论文针对电力网格中绝缘子缺陷检测的挑战（如多种缺陷类型、目标小且背景复杂），提出了一种改进的 YOLOv7 模型，用于多类型绝缘子缺陷检测。首先，该模型将 SPPCSPC 模块替换为 RFB 模块以增强特征提取能力，并在 head 部分引入 CA 机制来提升特征表示和检测准确率，同时采用 WIoU 损失函数来改善训练中的低质量样本问题，从而提高模型整体性能。实验结果显示，该模型在 mAP_0.5 上提升 1.6%、mAP_0.5:0.95 上提升 1.6%、精度提升 1.3% 以及召回率提升 1%，同时参数减少 3.2 百万、计算成本降低 2.5 GFLOPS，并将单图像检测速度加快 2.81 毫秒。总的来说，此改进为实际应用中的高效缺陷检测提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07179v1",
      "published_date": "2025-02-11 02:09:30 UTC",
      "updated_date": "2025-02-11 02:09:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:16:41.311762"
    },
    {
      "arxiv_id": "2502.07175v1",
      "title": "Foreign-Object Detection in High-Voltage Transmission Line Based on Improved YOLOv8m",
      "title_zh": "基于改进 YOLOv8m 的高压输电线路异物检测",
      "authors": [
        "Zhenyue Wang",
        "Guowu Yuan",
        "Hao Zhou",
        "Yi Ma",
        "Yutang Ma"
      ],
      "abstract": "The safe operation of high-voltage transmission lines ensures the power\ngrid's security. Various foreign objects attached to the transmission lines,\nsuch as balloons, kites and nesting birds, can significantly affect the safe\nand stable operation of high-voltage transmission lines. With the advancement\nof computer vision technology, periodic automatic inspection of foreign objects\nis efficient and necessary. Existing detection methods have low accuracy\nbecause foreign objects at-tached to the transmission lines are complex,\nincluding occlusions, diverse object types, significant scale variations, and\ncomplex backgrounds. In response to the practical needs of the Yunnan Branch of\nChina Southern Power Grid Co., Ltd., this paper proposes an improved\nYOLOv8m-based model for detecting foreign objects on transmission lines.\nExperiments are conducted on a dataset collected from Yunnan Power Grid. The\nproposed model enhances the original YOLOv8m by in-corporating a Global\nAttention Module (GAM) into the backbone to focus on occluded foreign objects,\nreplacing the SPPF module with the SPPCSPC module to augment the model's\nmultiscale feature extraction capability, and introducing the Focal-EIoU loss\nfunction to address the issue of high- and low-quality sample imbalances. These\nimprovements accelerate model convergence and enhance detection accuracy. The\nexperimental results demonstrate that our proposed model achieves a 2.7%\nincrease in mAP_0.5, a 4% increase in mAP_0.5:0.95, and a 6% increase in\nrecall.",
      "tldr_zh": "这篇论文针对高压输电线上的异物检测问题（如气球、风筝和筑巢鸟类），提出了一种基于改进 YOLOv8m 的模型，以应对遮挡、多样类型、尺度变化和复杂背景等挑战。改进措施包括在 backbone 中加入 Global Attention Module (GAM) 来关注被遮挡异物、用 SPPCSPC 模块替换 SPPF 模块以增强多尺度特征提取能力，以及引入 Focal-EIoU 损失函数来平衡高低质量样本。实验在云南电力网格数据集上验证，该模型实现了 mAP_0.5 提高 2.7%、mAP_0.5:0.95 提高 4% 和召回率提高 6%，显著提升了检测准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07175v1",
      "published_date": "2025-02-11 01:58:32 UTC",
      "updated_date": "2025-02-11 01:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:16:53.890655"
    },
    {
      "arxiv_id": "2502.07172v3",
      "title": "SemiHMER: Semi-supervised Handwritten Mathematical Expression Recognition using pseudo-labels",
      "title_zh": "翻译失败",
      "authors": [
        "Kehua Chen",
        "Haoyang Shen"
      ],
      "abstract": "In this paper, we study semi-supervised Handwritten Mathematical Expression\nRecognition (HMER) via exploring both labeled data and extra unlabeled data. We\npropose a novel consistency regularization framework, termed SemiHMER, which\nintroduces dual-branch semi-supervised learning. Specifically, we enforce\nconsistency between the two networks for the same input image. The\npseudo-label, generated by one perturbed recognition network, is utilized to\nsupervise the other network using the standard cross-entropy loss. The SemiHMER\nconsistency encourages high similarity between the predictions of the two\nperturbed networks for the same input image and expands the training data by\nleveraging unlabeled data with pseudo-labels. We further introduce a\nweak-to-strong strategy by applying different levels of augmentation to each\nbranch, effectively expanding the training data and enhancing the quality of\nnetwork training. Additionally, we propose a novel module, the Global Dynamic\nCounting Module (GDCM), to enhance the performance of the HMER decoder by\nalleviating recognition inaccuracies in long-distance formula recognition and\nreducing the occurrence of repeated characters. The experimental results\ndemonstrate that our work achieves significant performance improvements, with\nan average accuracy increase of 5.47% on CROHME14, 4.87% on CROHME16, and 5.25%\non CROHME19, compared to our baselines.",
      "tldr_zh": "本研究提出了一种名为 SemiHMER 的半监督框架，用于手写数学表达式识别 (HMER)，通过结合标记数据和未标记数据来提升模型性能。框架采用双分支半监督学习和一致性正则化策略，利用伪-labels (pseudo-labels) 监督两个网络的预测一致性，并引入 weak-to-strong 策略以不同级别的数据增强扩展训练数据。论文还设计了 Global Dynamic Counting Module (GDCM) 模块，以缓解长距离公式识别错误和重复字符问题。实验结果显示，SemiHMER 在 CROHME14、CROHME16 和 CROHME19 数据集上分别比基线模型提高了 5.47%、4.87% 和 5.25% 的准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07172v3",
      "published_date": "2025-02-11 01:39:11 UTC",
      "updated_date": "2025-02-20 01:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:17:04.639748"
    },
    {
      "arxiv_id": "2502.07835v1",
      "title": "Bridging LLM-Generated Code and Requirements: Reverse Generation technique and SBC Metric for Developer Insights",
      "title_zh": "桥接 LLM 生成代码与需求",
      "authors": [
        "Ahilan Ayyachamy Nadar Ponnusamy"
      ],
      "abstract": "The rise of Large Language Models (LLMs) in software engineering,\nparticularly in code generation, has garnered significant attention. However,\nassessing the quality of AI-generated code remains a challenge due to the\ninherent complexity of programming tasks and the lack of robust evaluation\nmetrics that align well with human judgment. Traditional token-based metrics\nsuch as BLEU and ROUGE, while commonly used in natural language processing,\nexhibit weak correlations with human assessments in code intelligence and\nverification tasks. Furthermore, these metrics are primarily research focused\nand are not designed for seamless integration into the software development\nlifecycle, limiting their practical utility for developers seeking to improve\ncode quality and security.\n  AI-assisted coding has been shown to be more beneficial for senior\ndevelopers, as they possess the expertise to critically evaluate the generated\ncode for correctness, completeness, and compliance. In contrast, junior\ndevelopers may struggle to identify hallucinations, missing functionality, or\nincorrect logic in AI-generated code. To bridge this gap, This paper introduces\na novel scoring mechanism called the SBC score, which is based on a reverse\ngeneration technique that leverages the natural language generation\ncapabilities of LLMs. Unlike direct code analysis, our approach reconstructs\nsystem requirements from AI-generated code and compares them with the original\nspecifications to quantify accuracy. The SBC score combines semantic\nsimilarity, BLEU, and completeness analysis, providing actionable insights to\ndevelopers by highlighting missing features and hallucinations. Our code and\ndatasets are available on GitHub",
      "tldr_zh": "这篇论文解决了评估Large Language Models (LLMs) 生成代码质量的挑战，指出传统指标如BLEU和ROUGE 与人类判断的相关性较弱，且不适合软件开发流程。论文提出了一种基于reverse generation 技术的SBC score 机制，通过从AI生成代码中逆向生成系统需求，并与原需求进行比较，结合语义相似度、BLEU 和完整性分析来量化代码的准确性。SBC score 提供可操作的洞见，帮助开发者识别代码中的幻觉、缺失功能和错误逻辑，从而桥接资深和初级开发者的评估差距。代码和数据集已在GitHub 上公开，增强了该方法的实际应用价值。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07835v1",
      "published_date": "2025-02-11 01:12:11 UTC",
      "updated_date": "2025-02-11 01:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:17:17.618744"
    },
    {
      "arxiv_id": "2502.07165v1",
      "title": "Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Peipei Wei",
        "Dimitris Dimitriadis",
        "Yan Xu",
        "Mingwei Shen"
      ],
      "abstract": "We present PRINCIPLE-BASED PROMPTING, a simple but effective multi-agent\nprompting strategy for text classification. It first asks multiple LLM agents\nto independently generate candidate principles based on analysis of\ndemonstration samples with or without labels, consolidates them into final\nprinciples via a finalizer agent, and then sends them to a classifier agent to\nperform downstream classification tasks. Extensive experiments on binary and\nmulti-class classification datasets with different sizes of LLMs show that our\napproach not only achieves substantial performance gains (1.55% - 19.37%) over\nzero-shot prompting on macro-F1 score but also outperforms other strong\nbaselines (CoT and stepback prompting). Principles generated by our approach\nhelp LLMs perform better on classification tasks than human crafted principles\non two private datasets. Our multi-agent PRINCIPLE-BASED PROMPTING approach\nalso shows on-par or better performance compared to demonstration-based\nfew-shot prompting approaches, yet with substantially lower inference costs.\nAblation studies show that label information and the multi-agent cooperative\nLLM framework play an important role in generating high-quality principles to\nfacilitate downstream classification tasks.",
      "tldr_zh": "本研究提出了一种名为 PRINCIPLE-BASED PROMPTING 的简单有效多智能体提示策略，用于提升文本分类任务的性能。该策略让多个 LLM 代理基于演示样本（有或无标签）独立生成候选原则，然后由一个最终化代理整合成最终原则，再由分类器代理用于下游分类。实验结果显示，该方法在二元和多类数据集上比零样本提示提高1.55% - 19.37% 的 macro-F1 分数，并优于 CoT 和 stepback 等基线；此外，它比人类手工原则表现更好，且与少样本提示相当但推理成本更低。消融研究强调，标签信息和多智能体合作框架是生成高质量原则的关键因素。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in AAAI 2025 Workshop on Advancing LLM-Based\n  Multi-Agent Collaboration",
      "pdf_url": "http://arxiv.org/pdf/2502.07165v1",
      "published_date": "2025-02-11 01:10:13 UTC",
      "updated_date": "2025-02-11 01:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:17:29.501093"
    },
    {
      "arxiv_id": "2502.07164v2",
      "title": "Does Training on Synthetic Data Make Models Less Robust?",
      "title_zh": "使用合成数据训练是否会使模型鲁棒性降低？",
      "authors": [
        "Lingze Zhang",
        "Ellie Pavlick"
      ],
      "abstract": "An increasingly common practice is to train large language models (LLMs)\nusing synthetic data. Often this synthetic data is produced by the same or\nsimilar LLMs as those it is being used to train. This raises the question of\nwhether the synthetic data might in fact exacerbate certain \"blindspots\" by\nreinforcing heuristics that the LLM already encodes. In this paper, we conduct\nsimulated experiments on the natural language inference (NLI) task with\nLlama-2-7B-hf models. We use MultiNLI as the general task and HANS, a targeted\nevaluation set designed to measure the presence of specific heuristic\nstrategies for NLI, as our \"blindspot\" task. Our goal is to determine whether\nperformance disparities between the general and blind spot tasks emerge. Our\nresults indicate that synthetic data does not reinforce blindspots in the way\nwe expected. Specifically, we see that, while fine-tuning with synthetic data\ndoesn't necessarily reduce the use of the heuristic, it also does not make it\nworse as we hypothesized.",
      "tldr_zh": "本研究探讨了使用合成数据训练大型语言模型（LLMs）是否会强化模型的“盲点”，即潜在的启发式策略问题。研究者通过模拟实验在自然语言推理（NLI）任务上测试 Llama-2-7B-hf 模型，使用 MultiNLI 作为一般数据集和 HANS 作为针对特定启发式策略的评估集。结果表明，合成数据并未如预期那样加剧盲点；虽然微调后模型的启发式策略使用没有减少，但也没有变得更糟，这为合成数据在模型训练中的应用提供了有益的经验证据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07164v2",
      "published_date": "2025-02-11 01:03:33 UTC",
      "updated_date": "2025-03-16 03:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:17:41.737745"
    },
    {
      "arxiv_id": "2502.07161v1",
      "title": "A Survey on Mamba Architecture for Vision Applications",
      "title_zh": "Mamba 架构在视觉应用的",
      "authors": [
        "Fady Ibrahim",
        "Guangjun Liu",
        "Guanghui Wang"
      ],
      "abstract": "Transformers have become foundational for visual tasks such as object\ndetection, semantic segmentation, and video understanding, but their quadratic\ncomplexity in attention mechanisms presents scalability challenges. To address\nthese limitations, the Mamba architecture utilizes state-space models (SSMs)\nfor linear scalability, efficient processing, and improved contextual\nawareness. This paper investigates Mamba architecture for visual domain\napplications and its recent advancements, including Vision Mamba (ViM) and\nVideoMamba, which introduce bidirectional scanning, selective scanning\nmechanisms, and spatiotemporal processing to enhance image and video\nunderstanding. Architectural innovations like position embeddings, cross-scan\nmodules, and hierarchical designs further optimize the Mamba framework for\nglobal and local feature extraction. These advancements position Mamba as a\npromising architecture in computer vision research and applications.",
      "tldr_zh": "这篇论文调查了 Mamba 架构在视觉应用中的应用，以解决 Transformers 的二次复杂度问题，通过利用状态空间模型 (SSMs) 实现线性可扩展性、更高效率和更好的上下文感知。论文详细讨论了最近进展，如 Vision Mamba (ViM) 和 VideoMamba，它们引入了双向扫描、选择性扫描机制以及时空处理，以增强图像和视频理解。架构创新包括位置嵌入、跨扫描模块和分层设计，这些优化了全局和局部特征提取，并将 Mamba 定位为计算机视觉研究中的潜力框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07161v1",
      "published_date": "2025-02-11 00:59:30 UTC",
      "updated_date": "2025-02-11 00:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:17:53.289255"
    },
    {
      "arxiv_id": "2502.07158v3",
      "title": "Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaying Lu",
        "Stephanie R. Brown",
        "Songyuan Liu",
        "Shifan Zhao",
        "Kejun Dong",
        "Del Bold",
        "Michael Fundora",
        "Alaa Aljiffry",
        "Alex Fedorov",
        "Jocelyn Grunwell",
        "Xiao Hu"
      ],
      "abstract": "Early prediction of pediatric cardiac arrest (CA) is critical for timely\nintervention in high-risk intensive care settings. We introduce PedCA-FT, a\nnovel transformer-based framework that fuses tabular view of EHR with the\nderived textual view of EHR to fully unleash the interactions of\nhigh-dimensional risk factors and their dynamics. By employing dedicated\ntransformer modules for each modality view, PedCA-FT captures complex temporal\nand contextual patterns to produce robust CA risk estimates. Evaluated on a\ncurated pediatric cohort from the CHOA-CICU database, our approach outperforms\nten other artificial intelligence models across five key performance metrics\nand identifies clinically meaningful risk factors. These findings underscore\nthe potential of multimodal fusion techniques to enhance early CA detection and\nimprove patient care.",
      "tldr_zh": "本文提出 PedCA-FT，一种基于 Multimodal Fused Transformer 的框架，用于从电子健康记录(EHR)中早期预测儿科心脏骤停(CA)，以实现及时干预。框架通过融合 EHR 的表格视图和派生文本视图，并采用专用的 Transformer 模块，捕捉高维风险因素的复杂时序和上下文交互。实验在 CHOA-CICU 数据库的儿科队列上显示，PedCA-FT 优于其他十个 AI 模型，在五个关键性能指标上表现出色，并识别了临床有意义的风险因素。这些发现强调了多模态融合技术在提升 CA 早期检测和患者护理方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07158v3",
      "published_date": "2025-02-11 00:53:36 UTC",
      "updated_date": "2025-05-20 17:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:18:05.782296"
    },
    {
      "arxiv_id": "2502.07834v1",
      "title": "MEMHD: Memory-Efficient Multi-Centroid Hyperdimensional Computing for Fully-Utilized In-Memory Computing Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Do Yeong Kang",
        "Yeong Hwan Oh",
        "Chanwook Hwang",
        "Jinhee Kim",
        "Kang Eun Jeon",
        "Jong Hwan Ko"
      ],
      "abstract": "The implementation of Hyperdimensional Computing (HDC) on In-Memory Computing\n(IMC) architectures faces significant challenges due to the mismatch between\nhighdimensional vectors and IMC array sizes, leading to inefficient memory\nutilization and increased computation cycles. This paper presents MEMHD, a\nMemory-Efficient Multi-centroid HDC framework designed to address these\nchallenges. MEMHD introduces a clustering-based initialization method and\nquantization aware iterative learning for multi-centroid associative memory.\nThrough these approaches and its overall architecture, MEMHD achieves a\nsignificant reduction in memory requirements while maintaining or improving\nclassification accuracy. Our approach achieves full utilization of IMC arrays\nand enables one-shot (or few-shot) associative search. Experimental results\ndemonstrate that MEMHD outperforms state-of-the-art binary HDC models,\nachieving up to 13.69% higher accuracy with the same memory usage, or 13.25x\nmore memory efficiency at the same accuracy level. Moreover, MEMHD reduces\ncomputation cycles by up to 80x and array usage by up to 71x compared to\nbaseline IMC mapping methods when mapped to 128x128 IMC arrays, while\nsignificantly improving energy and computation cycle efficiency.",
      "tldr_zh": "本文提出 MEMHD 框架，一种内存高效的多中心点 Hyperdimensional Computing (HDC) 方法，旨在解决 HDC 在 In-Memory Computing (IMC) 架构中高维向量与数组大小不匹配的问题，从而实现 IMC 数组的完全利用。MEMHD 通过基于聚类的初始化方法和量化感知的迭代学习，构建多中心点关联记忆，显著减少内存需求并支持一-shot 或 few-shot 关联搜索。实验结果表明，MEMHD 相较于现有二进制 HDC 模型，提高准确率达 13.69%，或在同准确率下内存效率提升 13.25 倍，同时减少计算周期高达 80 倍和数组使用高达 71 倍，提高了整体能量和效率。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted to appear at DATE 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07834v1",
      "published_date": "2025-02-11 00:53:15 UTC",
      "updated_date": "2025-02-11 00:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:18:18.148912"
    },
    {
      "arxiv_id": "2503.04761v1",
      "title": "Which Economic Tasks are Performed with AI? Evidence from Millions of Claude Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Kunal Handa",
        "Alex Tamkin",
        "Miles McCain",
        "Saffron Huang",
        "Esin Durmus",
        "Sarah Heck",
        "Jared Mueller",
        "Jerry Hong",
        "Stuart Ritchie",
        "Tim Belonax",
        "Kevin K. Troy",
        "Dario Amodei",
        "Jared Kaplan",
        "Jack Clark",
        "Deep Ganguli"
      ],
      "abstract": "Despite widespread speculation about artificial intelligence's impact on the\nfuture of work, we lack systematic empirical evidence about how these systems\nare actually being used for different tasks. Here, we present a novel framework\nfor measuring AI usage patterns across the economy. We leverage a recent\nprivacy-preserving system to analyze over four million Claude.ai conversations\nthrough the lens of tasks and occupations in the U.S. Department of Labor's\nO*NET Database. Our analysis reveals that AI usage primarily concentrates in\nsoftware development and writing tasks, which together account for nearly half\nof all total usage. However, usage of AI extends more broadly across the\neconomy, with approximately 36% of occupations using AI for at least a quarter\nof their associated tasks. We also analyze how AI is being used for tasks,\nfinding 57% of usage suggests augmentation of human capabilities (e.g.,\nlearning or iterating on an output) while 43% suggests automation (e.g.,\nfulfilling a request with minimal human involvement). While our data and\nmethods face important limitations and only paint a picture of AI usage on a\nsingle platform, they provide an automated, granular approach for tracking AI's\nevolving role in the economy and identifying leading indicators of future\nimpact as these technologies continue to advance.",
      "tldr_zh": "本研究通过分析超过400万次Claude.ai对话，提出一个框架来测量AI在经济任务中的使用模式，并将其与U.S. Department of Labor's O*NET Database的任务和职业数据相结合。结果显示，AI使用主要集中在软件开发和写作任务上，占总使用量的近一半，同时约36%的职业使用AI处理至少四分之一的相关任务。进一步分析发现，57%的AI使用用于augmentation（增强人类能力，如学习或迭代输出），而43%用于automation（自动化，如独立完成请求）。尽管数据仅限于单一平台并有局限性，此方法为跟踪AI在经济中的演变角色并识别未来影响提供了一个自动、粒度的工具。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04761v1",
      "published_date": "2025-02-11 00:46:43 UTC",
      "updated_date": "2025-02-11 00:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:18:29.739565"
    },
    {
      "arxiv_id": "2502.07156v2",
      "title": "Explaining 3D Computed Tomography Classifiers with Counterfactuals",
      "title_zh": "使用反事实解释 3D 计算机断层扫描分类器",
      "authors": [
        "Joseph Paul Cohen",
        "Louis Blankemeier",
        "Akshay Chaudhari"
      ],
      "abstract": "Counterfactual explanations enhance the interpretability of deep learning\nmodels in medical imaging, yet adapting them to 3D CT scans poses challenges\ndue to volumetric complexity and resource demands. We extend the Latent Shift\ncounterfactual generation method from 2D applications to explain 3D computed\ntomography (CT) scans classifiers. We address the challenges associated with 3D\nclassifiers, such as limited training samples and high memory demands, by\nimplementing a slice-based autoencoder and gradient blocking except for\nspecific chunks of slices. This method leverages a 2D encoder trained on CT\nslices, which are subsequently combined to maintain 3D context. We demonstrate\nthis technique on two models for clinical phenotype prediction and lung\nsegmentation. Our approach is both memory-efficient and effective for\ngenerating interpretable counterfactuals in high-resolution 3D medical imaging.",
      "tldr_zh": "这篇论文扩展了 Counterfactual explanations 到 3D CT scans 分类器的解释性应用中，解决了体积复杂性和资源需求的挑战。通过改进 Latent Shift 方法，该研究引入了 slice-based autoencoder 和 gradient blocking 技术，仅针对特定切片的块进行处理，以维持 3D 上下文并提升内存效率。该方法在临床表型预测和肺分割模型上进行了验证，证明了其在高分辨率 3D 医疗成像中生成可解释 counterfactuals 的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and models: https://github.com/ieee8023/ct-counterfactuals",
      "pdf_url": "http://arxiv.org/pdf/2502.07156v2",
      "published_date": "2025-02-11 00:44:20 UTC",
      "updated_date": "2025-04-02 19:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:18:42.209931"
    },
    {
      "arxiv_id": "2502.07154v2",
      "title": "Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Chen",
        "Allan Raventos",
        "Nan Cheng",
        "Surya Ganguli",
        "Shaul Druckmann"
      ],
      "abstract": "Recent progress in large language models (LLMs) highlights the power of\nscaling test-time compute to achieve strong performance on complex tasks, such\nas mathematical reasoning and code generation. This raises a critical question:\nhow should model training be modified to optimize performance under a\nsubsequent test-time compute strategy and budget? To explore this, we focus on\npass@N, a simple test-time strategy that searches for a correct answer in $N$\nindependent samples. We show, surprisingly, that training with cross-entropy\n(CE) loss can be ${\\it misaligned}$ with pass@N in that pass@N accuracy ${\\it\ndecreases}$ with longer training. We explain the origins of this misalignment\nin terms of model overconfidence induced by CE, and experimentally verify our\nprediction of overconfidence as an impediment to scaling test-time compute via\npass@N. Furthermore we suggest a principled, modified training loss that is\nbetter aligned to pass@N by limiting model confidence and rescuing pass@N test\nperformance. Our algorithm demonstrates improved mathematical reasoning on MATH\nand MiniF2F benchmarks under several scenarios: (1) providing answers to math\nquestions; and (2) proving theorems by searching over proof trees of varying\nshapes. Overall our work underscores the importance of co-designing two\ntraditionally separate phases of LLM development: training-time protocols and\ntest-time search and reasoning strategies.",
      "tldr_zh": "该研究重新审视了在扩展测试时计算时，如何调整大语言模型(LLMs)的微调训练，以优化复杂任务如数学推理的性能。作者发现，使用cross-entropy (CE)损失训练会导致模型过度自信，从而使pass@N策略（在N个独立样本中搜索正确答案）的准确率随训练时间增加而下降。针对这一问题，他们提出了一种修改训练损失的方法，通过限制模型自信度来更好地对齐pass@N策略，并在MATH和MiniF2F基准上实现了改进的数学推理性能，包括回答数学问题和搜索证明树。整体上，该工作强调了训练时协议与测试时搜索策略的协同设计对LLMs开发的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07154v2",
      "published_date": "2025-02-11 00:33:31 UTC",
      "updated_date": "2025-04-15 02:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:18:54.061818"
    },
    {
      "arxiv_id": "2502.07153v1",
      "title": "Feature Importance Depends on Properties of the Data: Towards Choosing the Correct Explanations for Your Data and Decision Trees based Models",
      "title_zh": "特征重要性取决于数据的属性：向着为你的",
      "authors": [
        "Célia Wafa Ayad",
        "Thomas Bonnier",
        "Benjamin Bosch",
        "Sonali Parbhoo",
        "Jesse Read"
      ],
      "abstract": "In order to ensure the reliability of the explanations of machine learning\nmodels, it is crucial to establish their advantages and limits and in which\ncase each of these methods outperform. However, the current understanding of\nwhen and how each method of explanation can be used is insufficient. To fill\nthis gap, we perform a comprehensive empirical evaluation by synthesizing\nmultiple datasets with the desired properties. Our main objective is to assess\nthe quality of feature importance estimates provided by local explanation\nmethods, which are used to explain predictions made by decision tree-based\nmodels. By analyzing the results obtained from synthetic datasets as well as\npublicly available binary classification datasets, we observe notable\ndisparities in the magnitude and sign of the feature importance estimates\ngenerated by these methods. Moreover, we find that these estimates are\nsensitive to specific properties present in the data. Although some model\nhyper-parameters do not significantly influence feature importance assignment,\nit is important to recognize that each method of explanation has limitations in\nspecific contexts. Our assessment highlights these limitations and provides\nvaluable insight into the suitability and reliability of different explanatory\nmethods in various scenarios.",
      "tldr_zh": "该研究探讨了机器学习模型解释的可靠性和局限性，特别是 feature importance 估计如何受数据属性的影响。作者通过合成数据集和公开二元分类数据集进行全面实证评估，评估了基于 decision trees 的局部 explanation methods 在预测解释中的表现。结果显示，这些方法的 feature importance 估计在大小和符号上存在显著差异，且对数据特定属性高度敏感。尽管某些模型超参数影响不大，但每种解释方法在特定情境下都有局限性。该评估为选择适合的解释方法提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07153v1",
      "published_date": "2025-02-11 00:29:55 UTC",
      "updated_date": "2025-02-11 00:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:19:04.517782"
    },
    {
      "arxiv_id": "2502.07832v1",
      "title": "SHARP: Accelerating Language Model Inference by SHaring Adjacent layers with Recovery Parameters",
      "title_zh": "SHARP：通过共享相邻层与恢复参数加速语言模型推理",
      "authors": [
        "Yiping Wang",
        "Hanxian Huang",
        "Yifang Chen",
        "Jishen Zhao",
        "Simon Shaolei Du",
        "Yuandong Tian"
      ],
      "abstract": "While Large language models (LLMs) have advanced natural language processing\ntasks, their growing computational and memory demands make deployment on\nresource-constrained devices like mobile phones increasingly challenging. In\nthis paper, we propose SHARP (SHaring Adjacent Layers with Recovery\nParameters), a novel approach to accelerate LLM inference by sharing parameters\nacross adjacent layers, thus reducing memory load overhead, while introducing\nlow-rank recovery parameters to maintain performance. Inspired by observations\nthat consecutive layers have similar outputs, SHARP employs a two-stage\nrecovery process: Single Layer Warmup (SLW), and Supervised Fine-Tuning (SFT).\nThe SLW stage aligns the outputs of the shared layers using L_2 loss, providing\na good initialization for the following SFT stage to further restore the model\nperformance. Extensive experiments demonstrate that SHARP can recover the\nmodel's perplexity on various in-distribution tasks using no more than 50k\nfine-tuning data while reducing the number of stored MLP parameters by 38% to\n65%. We also conduct several ablation studies of SHARP and show that replacing\nlayers towards the later parts of the model yields better performance\nretention, and that different recovery parameterizations perform similarly when\nparameter counts are matched. Furthermore, SHARP saves 42.8% in model storage\nand reduces the total inference time by 42.2% compared to the original\nLlama2-7b model on mobile devices. Our results highlight SHARP as an efficient\nsolution for reducing inference costs in deploying LLMs without the need for\npretraining-scale resources.",
      "tldr_zh": "该论文提出 SHARP 方法，通过在相邻层共享参数并引入低秩恢复参数，来加速大型语言模型 (LLMs) 的推理过程，从而减少内存开销并适应资源受限设备如手机。SHARP 采用两阶段恢复过程：Single Layer Warmup (SLW) 使用 L_2 损失对齐共享层的输出作为初始化，随后 Supervised Fine-Tuning (SFT) 进一步恢复模型性能。实验结果显示，该方法在各种任务上使用不超过 50k 的微调数据即可恢复模型的 perplexity，同时减少存储的 MLP 参数 38% 到 65%，并在 Llama2-7b 模型上节省 42.8% 模型存储和 42.2% 推理时间。该方法证明了在不依赖预训练规模资源的情况下，有效降低 LLMs 部署成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.07832v1",
      "published_date": "2025-02-11 00:21:40 UTC",
      "updated_date": "2025-02-11 00:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:19:19.193167"
    },
    {
      "arxiv_id": "2502.10442v1",
      "title": "Analysis of Overparameterization in Continual Learning under a Linear Model",
      "title_zh": "线性模型下持续学习的过参数化分析",
      "authors": [
        "Daniel Goldfarb",
        "Paul Hand"
      ],
      "abstract": "Autonomous machine learning systems that learn many tasks in sequence are\nprone to the catastrophic forgetting problem. Mathematical theory is needed in\norder to understand the extent of forgetting during continual learning. As a\nfoundational step towards this goal, we study continual learning and\ncatastrophic forgetting from a theoretical perspective in the simple setting of\ngradient descent with no explicit algorithmic mechanism to prevent forgetting.\nIn this setting, we analytically demonstrate that overparameterization alone\ncan mitigate forgetting in the context of a linear regression model. We\nconsider a two-task setting motivated by permutation tasks, and show that as\nthe overparameterization ratio becomes sufficiently high, a model trained on\nboth tasks in sequence results in a low-risk estimator for the first task. As\npart of this work, we establish a non-asymptotic bound of the risk of a single\nlinear regression task, which may be of independent interest to the field of\ndouble descent theory.",
      "tldr_zh": "本研究分析了在线性模型下，overparameterization如何缓解连续学习中的catastrophic forgetting问题，通过梯度下降方法在无显式防止遗忘机制的简单设置中进行理论探讨。研究证明，在受排列任务启发的两个任务场景中，当overparameterization比率足够高时，顺序训练模型能为第一个任务产生低风险估计。作为额外贡献，该工作建立了线性回归任务风险的非渐近界，这可能对double descent theory领域有独立兴趣。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10442v1",
      "published_date": "2025-02-11 00:15:38 UTC",
      "updated_date": "2025-02-11 00:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:19:31.516984"
    },
    {
      "arxiv_id": "2502.07830v2",
      "title": "Captured by Captions: On Memorization and its Mitigation in CLIP Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Wang",
        "Adam Dziedzic",
        "Grace C. Kim",
        "Michael Backes",
        "Franziska Boenisch"
      ],
      "abstract": "Multi-modal models, such as CLIP, have demonstrated strong performance in\naligning visual and textual representations, excelling in tasks like image\nretrieval and zero-shot classification. Despite this success, the mechanisms by\nwhich these models utilize training data, particularly the role of\nmemorization, remain unclear. In uni-modal models, both supervised and\nself-supervised, memorization has been shown to be essential for\ngeneralization. However, it is not well understood how these findings would\napply to CLIP, which incorporates elements from both supervised learning via\ncaptions that provide a supervisory signal similar to labels, and from\nself-supervised learning via the contrastive objective. To bridge this gap in\nunderstanding, we propose a formal definition of memorization in CLIP (CLIPMem)\nand use it to quantify memorization in CLIP models. Our results indicate that\nCLIP's memorization behavior falls between the supervised and self-supervised\nparadigms, with \"mis-captioned\" samples exhibiting highest levels of\nmemorization. Additionally, we find that the text encoder contributes more to\nmemorization than the image encoder, suggesting that mitigation strategies\nshould focus on the text domain. Building on these insights, we propose\nmultiple strategies to reduce memorization while at the same time improving\nutility--something that had not been shown before for traditional learning\nparadigms where reducing memorization typically results in utility decrease.",
      "tldr_zh": "该论文探讨了多模态模型 CLIP 中的记忆化（memorization）问题，提出了一种正式定义 CLIPMem 来量化模型对训练数据的记忆行为。研究发现，CLIP 的记忆化介于监督学习和自监督学习之间，“错误标题”的样本记忆化程度最高，且文本编码器比图像编码器贡献更大。作者进一步开发了多种策略来缓解记忆化，同时实现了模型实用性的提升，这在传统学习范式中是首次实现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07830v2",
      "published_date": "2025-02-11 00:11:13 UTC",
      "updated_date": "2025-05-19 15:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:19:43.926539"
    },
    {
      "arxiv_id": "2502.07140v1",
      "title": "Few-Shot Multi-Human Neural Rendering Using Geometry Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Qian li",
        "Victoria Fernàndez Abrevaya",
        "Franck Multon",
        "Adnane Boukhayma"
      ],
      "abstract": "We present a method for recovering the shape and radiance of a scene\nconsisting of multiple people given solely a few images. Multi-human scenes are\ncomplex due to additional occlusion and clutter. For single-human settings,\nexisting approaches using implicit neural representations have achieved\nimpressive results that deliver accurate geometry and appearance. However, it\nremains challenging to extend these methods for estimating multiple humans from\nsparse views. We propose a neural implicit reconstruction method that addresses\nthe inherent challenges of this task through the following contributions:\nFirst, we propose to use geometry constraints by exploiting pre-computed meshes\nusing a human body model (SMPL). Specifically, we regularize the signed\ndistances using the SMPL mesh and leverage bounding boxes for improved\nrendering. Second, we propose a ray regularization scheme to minimize rendering\ninconsistencies, and a saturation regularization for robust optimization in\nvariable illumination. Extensive experiments on both real and synthetic\ndatasets demonstrate the benefits of our approach and show state-of-the-art\nperformance against existing neural reconstruction methods.",
      "tldr_zh": "该论文提出了一种使用几何约束的少样本多人类神经渲染方法，仅需少数图像即可恢复多个人物场景的形状和辐射度，以应对遮挡和杂乱的挑战。关键贡献包括利用预计算的SMPL人体模型网格来正则化带符号距离并优化边界框渲染、引入射线正则化方案以减少渲染不一致性，以及饱和正则化以在可变照明条件下实现鲁棒优化。在真实和合成数据集上的广泛实验表明，该方法优于现有神经重建方法，达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07140v1",
      "published_date": "2025-02-11 00:10:58 UTC",
      "updated_date": "2025-02-11 00:10:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T10:19:54.794314"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 143,
  "processed_papers_count": 143,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T10:20:17.053019"
}