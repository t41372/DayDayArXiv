[
  {
    "arxiv_id": "2501.13230v2",
    "title": "Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions",
    "authors": [
      "Yan Ru Pei"
    ],
    "abstract": "We introduce Centaurus, a class of networks composed of generalized\nstate-space model (SSM) blocks, where the SSM operations can be treated as\ntensor contractions during training. The optimal order of tensor contractions\ncan then be systematically determined for every SSM block to maximize training\nefficiency. This allows more flexibility in designing SSM blocks beyond the\ndepthwise-separable configuration commonly implemented. The new design choices\nwill take inspiration from classical convolutional blocks including group\nconvolutions, full convolutions, and bottleneck blocks. We architect the\nCentaurus network with a mixture of these blocks, to balance between network\nsize and performance, as well as memory and computational efficiency during\nboth training and inference. We show that this heterogeneous network design\noutperforms its homogeneous counterparts in raw audio processing tasks\nincluding keyword spotting, speech denoising, and automatic speech recognition\n(ASR). For ASR, Centaurus is the first network with competitive performance\nthat can be made fully state-space based, without using any nonlinear\nrecurrence (LSTMs), explicit convolutions (CNNs), or (surrogate) attention\nmechanism. The source code is available as supplementary material on\nhttps://openreview.net/forum?id=PkpNRmBZ32",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13230v2",
    "published_date": "2025-01-22 21:30:49 UTC",
    "updated_date": "2025-04-09 19:05:31 UTC"
  },
  {
    "arxiv_id": "2501.16371v3",
    "title": "Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?",
    "authors": [
      "Elham Kiyani",
      "Khemraj Shukla",
      "Jorge F. Urbán",
      "Jérôme Darbon",
      "George Em Karniadakis"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) have revolutionized the computation\nof PDE solutions by integrating partial differential equations (PDEs) into the\nneural network's training process as soft constraints, becoming an important\ncomponent of the scientific machine learning (SciML) ecosystem. More recently,\nphysics-informed Kolmogorv-Arnold networks (PIKANs) have also shown to be\neffective and comparable in accuracy with PINNs. In their current\nimplementation, both PINNs and PIKANs are mainly optimized using first-order\nmethods like Adam, as well as quasi-Newton methods such as BFGS and its\nlow-memory variant, L-BFGS. However, these optimizers often struggle with\nhighly non-linear and non-convex loss landscapes, leading to challenges such as\nslow convergence, local minima entrapment, and (non)degenerate saddle points.\nIn this study, we investigate the performance of Self-Scaled BFGS (SSBFGS),\nSelf-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton\nschemes, including BFGS and L-BFGS with different line search strategies\napproaches. These methods dynamically rescale updates based on historical\ngradient information, thus enhancing training efficiency and accuracy. We\nsystematically compare these optimizers -- using both PINNs and PIKANs -- on\nkey challenging linear, stiff, multi-scale and non-linear PDEs, including the\nBurgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations. Our\nfindings provide state-of-the-art results with orders-of-magnitude accuracy\nimprovements without the use of adaptive weights or any other enhancements\ntypically employed in PINNs. More broadly, our results reveal insights into the\neffectiveness of second-order optimization strategies in significantly\nimproving the convergence and accurate generalization of PINNs and PIKANs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages, 27 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16371v3",
    "published_date": "2025-01-22 21:19:42 UTC",
    "updated_date": "2025-04-17 13:26:56 UTC"
  },
  {
    "arxiv_id": "2501.13200v1",
    "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
    "authors": [
      "Alsu Sagirova",
      "Yuri Kuratov",
      "Mikhail Burtsev"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) demonstrates significant progress\nin solving cooperative and competitive multi-agent problems in various\nenvironments. One of the principal challenges in MARL is the need for explicit\nprediction of the agents' behavior to achieve cooperation. To resolve this\nissue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends\nmemory transformers to multi-agent settings by pooling and globally\nbroadcasting individual working memories, enabling agents to exchange\ninformation implicitly and coordinate their actions. We evaluate SRMT on the\nPartially Observable Multi-Agent Pathfinding problem in a toy Bottleneck\nnavigation task that requires agents to pass through a narrow corridor and on a\nPOGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently\noutperforms a variety of reinforcement learning baselines, especially under\nsparse rewards, and generalizes effectively to longer corridors than those seen\nduring training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is\ncompetitive with recent MARL, hybrid, and planning-based algorithms. These\nresults suggest that incorporating shared recurrent memory into the\ntransformer-based architectures can enhance coordination in decentralized\nmulti-agent systems. The source code for training and evaluation is available\non GitHub: https://github.com/Aloriosa/srmt.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13200v1",
    "published_date": "2025-01-22 20:08:53 UTC",
    "updated_date": "2025-01-22 20:08:53 UTC"
  },
  {
    "arxiv_id": "2501.16370v2",
    "title": "Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations",
    "authors": [
      "Mahdi Movahedian Moghaddam",
      "Kourosh Parand",
      "Saeed Reza Kheradpisheh"
    ],
    "abstract": "In this paper, we present the Residual Integral Solver Network (RISN), a\nnovel neural network architecture designed to solve a wide range of integral\nand integro-differential equations, including one-dimensional,\nmulti-dimensional, ordinary and partial integro-differential, systems,\nfractional types, and Helmholtz-type integral equations involving oscillatory\nkernels. RISN integrates residual connections with high-accuracy numerical\nmethods such as Gaussian quadrature and fractional derivative operational\nmatrices, enabling it to achieve higher accuracy and stability than traditional\nPhysics-Informed Neural Networks (PINN). The residual connections help mitigate\nvanishing gradient issues, allowing RISN to handle deeper networks and more\ncomplex kernels, particularly in multi-dimensional problems. Through extensive\nexperiments, we demonstrate that RISN consistently outperforms not only\nclassical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and\nSelf-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute\nErrors (MAE) across various types of equations. These results highlight RISN's\nrobustness and efficiency in solving challenging integral and\nintegro-differential problems, making it a valuable tool for real-world\napplications where traditional methods often struggle.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "cs.NE",
      "math.NA",
      "68T07, 65R20"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16370v2",
    "published_date": "2025-01-22 19:47:03 UTC",
    "updated_date": "2025-05-01 12:29:08 UTC"
  },
  {
    "arxiv_id": "2501.13973v1",
    "title": "A Spatio-temporal Graph Network Allowing Incomplete Trajectory Input for Pedestrian Trajectory Prediction",
    "authors": [
      "Juncen Long",
      "Gianluca Bardaro",
      "Simone Mentasti",
      "Matteo Matteucci"
    ],
    "abstract": "Pedestrian trajectory prediction is important in the research of mobile robot\nnavigation in environments with pedestrians. Most pedestrian trajectory\nprediction algorithms require the input historical trajectories to be complete.\nIf a pedestrian is unobservable in any frame in the past, then its historical\ntrajectory become incomplete, the algorithm will not predict its future\ntrajectory. To address this limitation, we propose the STGN-IT, a\nspatio-temporal graph network allowing incomplete trajectory input, which can\npredict the future trajectories of pedestrians with incomplete historical\ntrajectories. STGN-IT uses the spatio-temporal graph with an additional\nencoding method to represent the historical trajectories and observation states\nof pedestrians. Moreover, STGN-IT introduces static obstacles in the\nenvironment that may affect the future trajectories as nodes to further improve\nthe prediction accuracy. A clustering algorithm is also applied in the\nconstruction of spatio-temporal graphs. Experiments on public datasets show\nthat STGN-IT outperforms state of the art algorithms on these metrics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13973v1",
    "published_date": "2025-01-22 19:32:07 UTC",
    "updated_date": "2025-01-22 19:32:07 UTC"
  },
  {
    "arxiv_id": "2501.13181v1",
    "title": "Learning in Log-Domain: Subthreshold Analog AI Accelerator Based on Stochastic Gradient Descent",
    "authors": [
      "Momen K Tageldeen",
      "Yacine Belgaid",
      "Vivek Mohan",
      "Zhou Wang",
      "Emmanuel M Drakakis"
    ],
    "abstract": "The rapid proliferation of AI models, coupled with growing demand for edge\ndeployment, necessitates the development of AI hardware that is both\nhigh-performance and energy-efficient. In this paper, we propose a novel analog\naccelerator architecture designed for AI/ML training workloads using stochastic\ngradient descent with L2 regularization (SGDr). The architecture leverages\nlog-domain circuits in subthreshold MOS and incorporates volatile memory. We\nestablish a mathematical framework for solving SGDr in the continuous time\ndomain and detail the mapping of SGDr learning equations to log-domain\ncircuits. By operating in the analog domain and utilizing weak inversion, the\nproposed design achieves significant reductions in transistor area and power\nconsumption compared to digital implementations. Experimental results\ndemonstrate that the architecture closely approximates ideal behavior, with a\nmean square error below 0.87% and precision as low as 8 bits. Furthermore, the\narchitecture supports a wide range of hyperparameters. This work paves the way\nfor energy-efficient analog AI hardware with on-chip training capabilities.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13181v1",
    "published_date": "2025-01-22 19:26:36 UTC",
    "updated_date": "2025-01-22 19:26:36 UTC"
  },
  {
    "arxiv_id": "2501.13165v1",
    "title": "QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks",
    "authors": [
      "Naman Jain",
      "Amir Kalev"
    ],
    "abstract": "We introduce Quantum Feature Extraction (QuFeX), a novel quantum machine\nlearning module. The proposed module enables feature extraction in a\nreduced-dimensional space, significantly decreasing the number of parallel\nevaluations required in typical quantum convolutional neural network\narchitectures. Its design allows seamless integration into deep classical\nneural networks, making it particularly suitable for hybrid quantum-classical\nmodels. As an application of QuFeX, we propose Qu-Net -- a hybrid architecture\nwhich integrates QuFeX at the bottleneck of a U-Net architecture. The latter is\nwidely used for image segmentation tasks such as medical imaging and autonomous\ndriving. Our numerical analysis indicates that the Qu-Net can achieve superior\nsegmentation performance compared to a U-Net baseline. These results highlight\nthe potential of QuFeX to enhance deep neural networks by leveraging hybrid\ncomputational paradigms, providing a path towards a robust framework for\nreal-world applications requiring precise feature extraction.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "12 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13165v1",
    "published_date": "2025-01-22 19:00:09 UTC",
    "updated_date": "2025-01-22 19:00:09 UTC"
  },
  {
    "arxiv_id": "2502.15713v1",
    "title": "UAV-assisted Internet of Vehicles: A Framework Empowered by Reinforcement Learning and Blockchain",
    "authors": [
      "Ahmed Alagha",
      "Maha Kadadha",
      "Rabeb Mizouni",
      "Shakti Singh",
      "Jamal Bentahar",
      "Hadi Otrok"
    ],
    "abstract": "This paper addresses the challenges of selecting relay nodes and coordinating\namong them in UAV-assisted Internet-of-Vehicles (IoV). The selection of UAV\nrelay nodes in IoV employs mechanisms executed either at centralized servers or\ndecentralized nodes, which have two main limitations: 1) the traceability of\nthe selection mechanism execution and 2) the coordination among the selected\nUAVs, which is currently offered in a centralized manner and is not coupled\nwith the relay selection. Existing UAV coordination methods often rely on\noptimization methods, which are not adaptable to different environment\ncomplexities, or on centralized deep reinforcement learning, which lacks\nscalability in multi-UAV settings. Overall, there is a need for a comprehensive\nframework where relay selection and coordination are coupled and executed in a\ntransparent and trusted manner. This work proposes a framework empowered by\nreinforcement learning and Blockchain for UAV-assisted IoV networks. It\nconsists of three main components: a two-sided UAV relay selection mechanism\nfor UAV-assisted IoV, a decentralized Multi-Agent Deep Reinforcement Learning\n(MDRL) model for autonomous UAV coordination, and a Blockchain implementation\nfor transparency and traceability in the interactions between vehicles and\nUAVs. The relay selection considers the two-sided preferences of vehicles and\nUAVs based on the Quality-of-UAV (QoU) and the Quality-of-Vehicle (QoV). Upon\nselection of relay UAVs, the decentralized coordination between them is enabled\nthrough an MDRL model trained to control their mobility and maintain the\nnetwork coverage and connectivity using Proximal Policy Optimization (PPO). The\nevaluation results demonstrate that the proposed selection and coordination\nmechanisms improve the stability of the selected relays and maximize the\ncoverage and connectivity achieved by the UAVs.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15713v1",
    "published_date": "2025-01-22 18:54:59 UTC",
    "updated_date": "2025-01-22 18:54:59 UTC"
  },
  {
    "arxiv_id": "2501.16369v1",
    "title": "Blockchain-based Crowdsourced Deep Reinforcement Learning as a Service",
    "authors": [
      "Ahmed Alagha",
      "Hadi Otrok",
      "Shakti Singh",
      "Rabeb Mizouni",
      "Jamal Bentahar"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) has emerged as a powerful paradigm for\nsolving complex problems. However, its full potential remains inaccessible to a\nbroader audience due to its complexity, which requires expertise in training\nand designing DRL solutions, high computational capabilities, and sometimes\naccess to pre-trained models. This necessitates the need for hassle-free\nservices that increase the availability of DRL solutions to a variety of users.\nTo enhance the accessibility to DRL services, this paper proposes a novel\nblockchain-based crowdsourced DRL as a Service (DRLaaS) framework. The\nframework provides DRL-related services to users, covering two types of tasks:\nDRL training and model sharing. Through crowdsourcing, users could benefit from\nthe expertise and computational capabilities of workers to train DRL solutions.\nModel sharing could help users gain access to pre-trained models, shared by\nworkers in return for incentives, which can help train new DRL solutions using\nmethods in knowledge transfer. The DRLaaS framework is built on top of a\nConsortium Blockchain to enable traceable and autonomous execution. Smart\nContracts are designed to manage worker and model allocation, which are stored\nusing the InterPlanetary File System (IPFS) to ensure tamper-proof data\ndistribution. The framework is tested on several DRL applications, proving its\nefficacy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16369v1",
    "published_date": "2025-01-22 18:54:39 UTC",
    "updated_date": "2025-01-22 18:54:39 UTC"
  },
  {
    "arxiv_id": "2501.16368v2",
    "title": "Foundation Models for CPS-IoT: Opportunities and Challenges",
    "authors": [
      "Ozan Baris",
      "Yizhuo Chen",
      "Gaofeng Dong",
      "Liying Han",
      "Tomoyoshi Kimura",
      "Pengrui Quan",
      "Ruijie Wang",
      "Tianchen Wang",
      "Tarek Abdelzaher",
      "Mario Bergés",
      "Paul Pu Liang",
      "Mani Srivastava"
    ],
    "abstract": "Methods from machine learning (ML) have transformed the implementation of\nPerception-Cognition-Communication-Action loops in Cyber-Physical Systems (CPS)\nand the Internet of Things (IoT), replacing mechanistic and basic statistical\nmodels with those derived from data. However, the first generation of ML\napproaches, which depend on supervised learning with annotated data to create\ntask-specific models, faces significant limitations in scaling to the diverse\nsensor modalities, deployment configurations, application tasks, and operating\ndynamics characterizing real-world CPS-IoT systems. The success of\ntask-agnostic foundation models (FMs), including multimodal large language\nmodels (LLMs), in addressing similar challenges across natural language,\ncomputer vision, and human speech has generated considerable enthusiasm for and\nexploration of FMs and LLMs as flexible building blocks in CPS-IoT analytics\npipelines, promising to reduce the need for costly task-specific engineering.\n  Nonetheless, a significant gap persists between the current capabilities of\nFMs and LLMs in the CPS-IoT domain and the requirements they must meet to be\nviable for CPS-IoT applications. In this paper, we analyze and characterize\nthis gap through a thorough examination of the state of the art and our\nresearch, which extends beyond it in various dimensions. Based on the results\nof our analysis and research, we identify essential desiderata that CPS-IoT\ndomain-specific FMs and LLMs must satisfy to bridge this gap. We also propose\nactions by CPS-IoT researchers to collaborate in developing key community\nresources necessary for establishing FMs and LLMs as foundational tools for the\nnext generation of CPS-IoT systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16368v2",
    "published_date": "2025-01-22 18:52:41 UTC",
    "updated_date": "2025-02-04 21:21:49 UTC"
  },
  {
    "arxiv_id": "2501.13094v1",
    "title": "Robust Representation Consistency Model via Contrastive Denoising",
    "authors": [
      "Jiachen Lei",
      "Julius Berner",
      "Jiongxiao Wang",
      "Zhongzhu Chen",
      "Zhongjia Ba",
      "Kui Ren",
      "Jun Zhu",
      "Anima Anandkumar"
    ],
    "abstract": "Robustness is essential for deep neural networks, especially in\nsecurity-sensitive applications. To this end, randomized smoothing provides\ntheoretical guarantees for certifying robustness against adversarial\nperturbations. Recently, diffusion models have been successfully employed for\nrandomized smoothing to purify noise-perturbed samples before making\npredictions with a standard classifier. While these methods excel at small\nperturbation radii, they struggle with larger perturbations and incur a\nsignificant computational overhead during inference compared to classical\nmethods. To address this, we reformulate the generative modeling task along the\ndiffusion trajectories in pixel space as a discriminative task in the latent\nspace. Specifically, we use instance discrimination to achieve consistent\nrepresentations along the trajectories by aligning temporally adjacent points.\nAfter fine-tuning based on the learned representations, our model enables\nimplicit denoising-then-classification via a single prediction, substantially\nreducing inference costs. We conduct extensive experiments on various datasets\nand achieve state-of-the-art performance with minimal computation budget during\ninference. For example, our method outperforms the certified accuracy of\ndiffusion-based methods on ImageNet across all perturbation radii by 5.3% on\naverage, with up to 11.6% at larger radii, while reducing inference costs by\n85$\\times$ on average. Codes are available at:\nhttps://github.com/jiachenlei/rRCM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13094v1",
    "published_date": "2025-01-22 18:52:06 UTC",
    "updated_date": "2025-01-22 18:52:06 UTC"
  },
  {
    "arxiv_id": "2501.13093v3",
    "title": "Guaranteed Recovery of Unambiguous Clusters",
    "authors": [
      "Kayvon Mazooji",
      "Ilan Shomorony"
    ],
    "abstract": "Clustering is often a challenging problem because of the inherent ambiguity\nin what the \"correct\" clustering should be. Even when the number of clusters\n$K$ is known, this ambiguity often still exists, particularly when there is\nvariation in density among different clusters, and clusters have multiple\nrelatively separated regions of high density. In this paper we propose an\ninformation-theoretic characterization of when a $K$-clustering is ambiguous,\nand design an algorithm that recovers the clustering whenever it is\nunambiguous. This characterization formalizes the situation when two high\ndensity regions within a cluster are separable enough that they look more like\ntwo distinct clusters than two truly distinct clusters in the $K$-clustering.\nThe algorithm first identifies $K$ partial clusters (or \"seeds\") using a\ndensity-based approach, and then adds unclustered points to the initial $K$\npartial clusters in a greedy manner to form a complete clustering. We implement\nand test a version of the algorithm that is modified to effectively handle\noverlapping clusters, and observe that it requires little parameter selection\nand displays improved performance on many datasets compared to widely used\nalgorithms for non-convex cluster recovery.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.DS",
      "cs.LG",
      "math.IT",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.IT",
    "comment": "12 pages, includes minor changes and some new content compared to\n  previous version",
    "pdf_url": "http://arxiv.org/pdf/2501.13093v3",
    "published_date": "2025-01-22 18:51:25 UTC",
    "updated_date": "2025-05-07 18:33:19 UTC"
  },
  {
    "arxiv_id": "2501.13084v1",
    "title": "Attention-Driven Hierarchical Reinforcement Learning with Particle Filtering for Source Localization in Dynamic Fields",
    "authors": [
      "Yiwei Shi",
      "Mengyue Yang",
      "Qi Zhang",
      "Weinan Zhang",
      "Cunjia Liu",
      "Weiru Liu"
    ],
    "abstract": "In many real-world scenarios, such as gas leak detection or environmental\npollutant tracking, solving the Inverse Source Localization and\nCharacterization problem involves navigating complex, dynamic fields with\nsparse and noisy observations. Traditional methods face significant challenges,\nincluding partial observability, temporal and spatial dynamics,\nout-of-distribution generalization, and reward sparsity. To address these\nissues, we propose a hierarchical framework that integrates Bayesian inference\nand reinforcement learning. The framework leverages an attention-enhanced\nparticle filtering mechanism for efficient and accurate belief updates, and\nincorporates two complementary execution strategies: Attention Particle\nFiltering Planning and Attention Particle Filtering Reinforcement Learning.\nThese approaches optimize exploration and adaptation under uncertainty.\nTheoretical analysis proves the convergence of the attention-enhanced particle\nfilter, while extensive experiments across diverse scenarios validate the\nframework's superior accuracy, adaptability, and computational efficiency. Our\nresults highlight the framework's potential for broad applications in dynamic\nfield estimation tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13084v1",
    "published_date": "2025-01-22 18:45:29 UTC",
    "updated_date": "2025-01-22 18:45:29 UTC"
  },
  {
    "arxiv_id": "2501.13083v1",
    "title": "Boosting MCTS with Free Energy Minimization",
    "authors": [
      "Mawaba Pascal Dao",
      "Adrian M. Peter"
    ],
    "abstract": "Active Inference, grounded in the Free Energy Principle, provides a powerful\nlens for understanding how agents balance exploration and goal-directed\nbehavior in uncertain environments. Here, we propose a new planning framework,\nthat integrates Monte Carlo Tree Search (MCTS) with active inference objectives\nto systematically reduce epistemic uncertainty while pursuing extrinsic\nrewards. Our key insight is that MCTS already renowned for its search\nefficiency can be naturally extended to incorporate free energy minimization by\nblending expected rewards with information gain. Concretely, the Cross-Entropy\nMethod (CEM) is used to optimize action proposals at the root node, while tree\nexpansions leverage reward modeling alongside intrinsic exploration bonuses.\nThis synergy allows our planner to maintain coherent estimates of value and\nuncertainty throughout planning, without sacrificing computational\ntractability. Empirically, we benchmark our planner on a diverse set of\ncontinuous control tasks, where it demonstrates performance gains over both\nstandalone CEM and MCTS with random rollouts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13083v1",
    "published_date": "2025-01-22 18:45:15 UTC",
    "updated_date": "2025-01-22 18:45:15 UTC"
  },
  {
    "arxiv_id": "2501.13075v1",
    "title": "Evolution and The Knightian Blindspot of Machine Learning",
    "authors": [
      "Joel Lehman",
      "Elliot Meyerson",
      "Tarek El-Gaaly",
      "Kenneth O. Stanley",
      "Tarin Ziyaee"
    ],
    "abstract": "This paper claims that machine learning (ML) largely overlooks an important\nfacet of general intelligence: robustness to a qualitatively unknown future in\nan open world. Such robustness relates to Knightian uncertainty (KU) in\neconomics, i.e. uncertainty that cannot be quantified, which is excluded from\nconsideration in ML's key formalisms. This paper aims to identify this blind\nspot, argue its importance, and catalyze research into addressing it, which we\nbelieve is necessary to create truly robust open-world AI. To help illuminate\nthe blind spot, we contrast one area of ML, reinforcement learning (RL), with\nthe process of biological evolution. Despite staggering ongoing progress, RL\nstill struggles in open-world situations, often failing under unforeseen\nsituations. For example, the idea of zero-shot transferring a self-driving car\npolicy trained only in the US to the UK currently seems exceedingly ambitious.\nIn dramatic contrast, biological evolution routinely produces agents that\nthrive within an open world, sometimes even to situations that are remarkably\nout-of-distribution (e.g. invasive species; or humans, who do undertake such\nzero-shot international driving). Interestingly, evolution achieves such\nrobustness without explicit theory, formalisms, or mathematical gradients. We\nexplore the assumptions underlying RL's typical formalisms, showing how they\nlimit RL's engagement with the unknown unknowns characteristic of an\never-changing complex world. Further, we identify mechanisms through which\nevolutionary processes foster robustness to novel and unpredictable challenges,\nand discuss potential pathways to algorithmically embody them. The conclusion\nis that the intriguing remaining fragility of ML may result from blind spots in\nits formalisms, and that significant gains may result from direct confrontation\nwith the challenge of KU.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13075v1",
    "published_date": "2025-01-22 18:38:41 UTC",
    "updated_date": "2025-01-22 18:38:41 UTC"
  },
  {
    "arxiv_id": "2501.13074v1",
    "title": "Autonomy-of-Experts Models",
    "authors": [
      "Ang Lv",
      "Ruobing Xie",
      "Yining Qian",
      "Songhao Wu",
      "Xingwu Sun",
      "Zhanhui Kang",
      "Di Wang",
      "Rui Yan"
    ],
    "abstract": "Mixture-of-Experts (MoE) models mostly use a router to assign tokens to\nspecific expert modules, activating only partial parameters and often\noutperforming dense models. We argue that the separation between the router's\ndecision-making and the experts' execution is a critical yet overlooked issue,\nleading to suboptimal expert selection and ineffective learning. To address\nthis, we propose Autonomy-of-Experts (AoE), a novel MoE paradigm in which\nexperts autonomously select themselves to process inputs. AoE is based on the\ninsight that an expert is aware of its own capacity to effectively process a\ntoken, an awareness reflected in the scale of its internal activations. In AoE,\nrouters are removed; instead, experts pre-compute internal activations for\ninputs and are ranked based on their activation norms. Only the top-ranking\nexperts proceed with the forward pass, while the others abort. The overhead of\npre-computing activations is reduced through a low-rank weight factorization.\nThis self-evaluating-then-partner-comparing approach ensures improved expert\nselection and effective learning. We pre-train language models having 700M up\nto 4B parameters, demonstrating that AoE outperforms traditional MoE models\nwith comparable efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13074v1",
    "published_date": "2025-01-22 18:37:08 UTC",
    "updated_date": "2025-01-22 18:37:08 UTC"
  },
  {
    "arxiv_id": "2501.13072v2",
    "title": "AdaWM: Adaptive World Model based Planning for Autonomous Driving",
    "authors": [
      "Hang Wang",
      "Xin Ye",
      "Feng Tao",
      "Chenbin Pan",
      "Abhirup Mallik",
      "Burhaneddin Yaman",
      "Liu Ren",
      "Junshan Zhang"
    ],
    "abstract": "World model based reinforcement learning (RL) has emerged as a promising\napproach for autonomous driving, which learns a latent dynamics model and uses\nit to train a planning policy. To speed up the learning process, the\npretrain-finetune paradigm is often used, where online RL is initialized by a\npretrained model and a policy learned offline. However, naively performing such\ninitialization in RL may result in dramatic performance degradation during the\nonline interactions in the new task. To tackle this challenge, we first analyze\nthe performance degradation and identify two primary root causes therein: the\nmismatch of the planning policy and the mismatch of the dynamics model, due to\ndistribution shift. We further analyze the effects of these factors on\nperformance degradation during finetuning, and our findings reveal that the\nchoice of finetuning strategies plays a pivotal role in mitigating these\neffects. We then introduce AdaWM, an Adaptive World Model based planning\nmethod, featuring two key steps: (a) mismatch identification, which quantifies\nthe mismatches and informs the finetuning strategy, and (b) alignment-driven\nfinetuning, which selectively updates either the policy or the model as needed\nusing efficient low-rank updates. Extensive experiments on the challenging\nCARLA driving tasks demonstrate that AdaWM significantly improves the\nfinetuning process, resulting in more robust and efficient performance in\nautonomous driving systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.13072v2",
    "published_date": "2025-01-22 18:34:51 UTC",
    "updated_date": "2025-01-23 04:15:32 UTC"
  },
  {
    "arxiv_id": "2502.15712v1",
    "title": "GPUs, CPUs, and... NICs: Rethinking the Network's Role in Serving Complex AI Pipelines",
    "authors": [
      "Mike Wong",
      "Ulysses Butler",
      "Emma Farkash",
      "Praveen Tammana",
      "Anirudh Sivaraman",
      "Ravi Netravali"
    ],
    "abstract": "The increasing prominence of AI necessitates the deployment of inference\nplatforms for efficient and effective management of AI pipelines and compute\nresources. As these pipelines grow in complexity, the demand for distributed\nserving rises and introduces much-dreaded network delays. In this paper, we\ninvestigate how the network can instead be a boon to the excessively high\nresource overheads of AI pipelines. To alleviate these overheads, we discuss\nhow resource-intensive data processing tasks -- a key facet of growing AI\npipeline complexity -- are well-matched for the computational characteristics\nof packet processing pipelines and how they can be offloaded onto SmartNICs. We\nexplore the challenges and opportunities of offloading, and propose a research\nagenda for integrating network hardware into AI pipelines, unlocking new\nopportunities for optimization.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.OS"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15712v1",
    "published_date": "2025-01-22 18:32:12 UTC",
    "updated_date": "2025-01-22 18:32:12 UTC"
  },
  {
    "arxiv_id": "2501.13028v1",
    "title": "Optimizing Return Distributions with Distributional Dynamic Programming",
    "authors": [
      "Bernardo Ávila Pires",
      "Mark Rowland",
      "Diana Borsa",
      "Zhaohan Daniel Guo",
      "Khimya Khetarpal",
      "André Barreto",
      "David Abel",
      "Rémi Munos",
      "Will Dabney"
    ],
    "abstract": "We introduce distributional dynamic programming (DP) methods for optimizing\nstatistical functionals of the return distribution, with standard reinforcement\nlearning as a special case. Previous distributional DP methods could optimize\nthe same class of expected utilities as classic DP. To go beyond expected\nutilities, we combine distributional DP with stock augmentation, a technique\npreviously introduced for classic DP in the context of risk-sensitive RL, where\nthe MDP state is augmented with a statistic of the rewards obtained so far\n(since the first time step). We find that a number of recently studied problems\ncan be formulated as stock-augmented return distribution optimization, and we\nshow that we can use distributional DP to solve them. We analyze distributional\nvalue and policy iteration, with bounds and a study of what objectives these\ndistributional DP methods can or cannot optimize. We describe a number of\napplications outlining how to use distributional DP to solve different\nstock-augmented return distribution optimization problems, for example\nmaximizing conditional value-at-risk, and homeostatic regulation. To highlight\nthe practical potential of stock-augmented return distribution optimization and\ndistributional DP, we combine the core ideas of distributional value iteration\nwith the deep RL agent DQN, and empirically evaluate it for solving instances\nof the applications discussed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13028v1",
    "published_date": "2025-01-22 17:20:43 UTC",
    "updated_date": "2025-01-22 17:20:43 UTC"
  },
  {
    "arxiv_id": "2502.10409v1",
    "title": "Data Science Students Perspectives on Learning Analytics: An Application of Human-Led and LLM Content Analysis",
    "authors": [
      "Raghda Zahran",
      "Jianfei Xu",
      "Huizhi Liang",
      "Matthew Forshaw"
    ],
    "abstract": "Objective This study is part of a series of initiatives at a UK university\ndesigned to cultivate a deep understanding of students' perspectives on\nanalytics that resonate with their unique learning needs. It explores\ncollaborative data processing undertaken by postgraduate students who examined\nan Open University Learning Analytics Dataset (OULAD).\n  Methods A qualitative approach was adopted, integrating a Retrieval-Augmented\nGeneration (RAG) and a Large Language Model (LLM) technique with human-led\ncontent analysis to gather information about students' perspectives based on\ntheir submitted work. The study involved 72 postgraduate students in 12 groups.\n  Findings The analysis of group work revealed diverse insights into essential\nlearning analytics from the students' perspectives. All groups adopted a\nstructured data science methodology. The questions formulated by the groups\nwere categorised into seven themes, reflecting their specific areas of\ninterest. While there was variation in the selected variables to interpret\ncorrelations, a consensus was found regarding the general results.\n  Conclusion A significant outcome of this study is that students specialising\nin data science exhibited a deeper understanding of learning analytics,\neffectively articulating their interests through inferences drawn from their\nanalyses. While human-led content analysis provided a general understanding of\nstudents' perspectives, the LLM offered nuanced insights.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "stat.AP"
    ],
    "primary_category": "cs.CY",
    "comment": "17 Pages, 2 Tables, 1 Figure",
    "pdf_url": "http://arxiv.org/pdf/2502.10409v1",
    "published_date": "2025-01-22 17:16:01 UTC",
    "updated_date": "2025-01-22 17:16:01 UTC"
  },
  {
    "arxiv_id": "2501.13023v2",
    "title": "Provably-Safe Neural Network Training Using Hybrid Zonotope Reachability Analysis",
    "authors": [
      "Long Kiu Chung",
      "Shreyas Kousik"
    ],
    "abstract": "Even though neural networks are being increasingly deployed in\nsafety-critical control applications, it remains difficult to enforce\nconstraints on their output, meaning that it is hard to guarantee safety in\nsuch settings. While many existing methods seek to verify a neural network's\nsatisfaction of safety constraints, few address how to correct an unsafe\nnetwork. The handful of works that extract a training signal from verification\ncannot handle non-convex sets, and are either conservative or slow. To begin\naddressing these challenges, this work proposes a neural network training\nmethod that can encourage the exact image of a non-convex input set for a\nneural network with rectified linear unit (ReLU) nonlinearities to avoid a\nnon-convex unsafe region. This is accomplished by reachability analysis with\nscaled hybrid zonotopes, a modification of the existing hybrid zonotope set\nrepresentation that enables parameterized scaling of non-convex polytopic sets\nwith a differentiable collision check via mixed-integer linear programs\n(MILPs). The proposed method was shown to be effective and fast for networks\nwith up to 240 neurons, with the computational complexity dominated by inverse\noperations on matrices that scale linearly in size with the number of neurons\nand complexity of input and unsafe sets. We demonstrate the practicality of our\nmethod by training a forward-invariant neural network controller for a\nnon-convex input set to an affine system, as well as generating safe\nreach-avoid plans for a black-box dynamical system.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13023v2",
    "published_date": "2025-01-22 17:13:48 UTC",
    "updated_date": "2025-04-01 01:01:48 UTC"
  },
  {
    "arxiv_id": "2501.13014v1",
    "title": "Paper Quality Assessment based on Individual Wisdom Metrics from Open Peer Review",
    "authors": [
      "Andrii Zahorodnii",
      "Jasper J. F. van den Bosch",
      "Ian Charest",
      "Christopher Summerfield",
      "Ila R. Fiete"
    ],
    "abstract": "This study proposes a data-driven framework for enhancing the accuracy and\nefficiency of scientific peer review through an open, bottom-up process that\nestimates reviewer quality. Traditional closed peer review systems, while\nessential for quality control, are often slow, costly, and subject to biases\nthat can impede scientific progress. Here, we introduce a method that evaluates\nindividual reviewer reliability by quantifying agreement with community\nconsensus scores and applying Bayesian weighting to refine paper quality\nassessments. We analyze open peer review data from two major scientific\nconferences, and demonstrate that reviewer-specific quality scores\nsignificantly improve the reliability of paper quality estimation. Perhaps\nsurprisingly, we find that reviewer quality scores are unrelated to authorship\nquality. Our model incorporates incentive structures to recognize high-quality\nreviewers and encourage broader coverage of submitted papers, thereby\nmitigating the common \"rich-get-richer\" pitfall of social media. These findings\nsuggest that open peer review, with mechanisms for estimating and incentivizing\nreviewer quality, offers a scalable and equitable alternative for scientific\npublishing, with potential to enhance the speed, fairness, and transparency of\nthe peer review process.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.SI",
    "comment": "15 pages, 5 main text figures, 3 supplementary figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13014v1",
    "published_date": "2025-01-22 17:00:27 UTC",
    "updated_date": "2025-01-22 17:00:27 UTC"
  },
  {
    "arxiv_id": "2501.13011v2",
    "title": "MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking",
    "authors": [
      "Sebastian Farquhar",
      "Vikrant Varma",
      "David Lindner",
      "David Elson",
      "Caleb Biddulph",
      "Ian Goodfellow",
      "Rohin Shah"
    ],
    "abstract": "Future advanced AI systems may learn sophisticated strategies through\nreinforcement learning (RL) that humans cannot understand well enough to safely\nevaluate. We propose a training method which avoids agents learning undesired\nmulti-step plans that receive high reward (multi-step \"reward hacks\") even if\nhumans are not able to detect that the behaviour is undesired. The method,\nMyopic Optimization with Non-myopic Approval (MONA), works by combining\nshort-sighted optimization with far-sighted reward. We demonstrate that MONA\ncan prevent multi-step reward hacking that ordinary RL causes, even without\nbeing able to detect the reward hacking and without any extra information that\nordinary RL does not get access to. We study MONA empirically in three settings\nwhich model different misalignment failure modes including 2-step environments\nwith LLMs representing delegated oversight and encoded reasoning and\nlonger-horizon gridworld environments representing sensor tampering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13011v2",
    "published_date": "2025-01-22 16:53:08 UTC",
    "updated_date": "2025-04-10 16:25:31 UTC"
  },
  {
    "arxiv_id": "2501.12997v1",
    "title": "Ehrenfeucht-Haussler Rank and Chain of Thought",
    "authors": [
      "Pablo Barceló",
      "Alexander Kozachinskiy",
      "Tomasz Steifer"
    ],
    "abstract": "The notion of rank of a Boolean function has been a cornerstone in the theory\nof PAC learning, enabling quasipolynomial-time learning algorithms for\npolynomial-size decision trees. We present a novel characterization of rank,\ngrounded in the well-known Transformer architecture. We show that the rank of a\nfunction $f$ corresponds to the minimum number of Chain of Thought (CoT) steps\nrequired by a single-layer transformer decoder with hard attention to compute\n$f$. Based on this characterization we establish tight bounds on the number of\nCoT steps required for specific problems, showing that $\\ell$-fold function\ncomposition necessitates exactly $\\ell$ CoT steps. Furthermore, we analyze the\nproblem of identifying the position of the $k$-th occurrence of 1 in a Boolean\nsequence, proving that it requires $k$ CoT steps.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12997v1",
    "published_date": "2025-01-22 16:30:58 UTC",
    "updated_date": "2025-01-22 16:30:58 UTC"
  },
  {
    "arxiv_id": "2501.12979v1",
    "title": "FlanEC: Exploring Flan-T5 for Post-ASR Error Correction",
    "authors": [
      "Moreno La Quatra",
      "Valerio Mario Salerno",
      "Yu Tsao",
      "Sabato Marco Siniscalchi"
    ],
    "abstract": "In this paper, we present an encoder-decoder model leveraging Flan-T5 for\npost-Automatic Speech Recognition (ASR) Generative Speech Error Correction\n(GenSEC), and we refer to it as FlanEC. We explore its application within the\nGenSEC framework to enhance ASR outputs by mapping n-best hypotheses into a\nsingle output sentence. By utilizing n-best lists from ASR models, we aim to\nimprove the linguistic correctness, accuracy, and grammaticality of final ASR\ntranscriptions. Specifically, we investigate whether scaling the training data\nand incorporating diverse datasets can lead to significant improvements in\npost-ASR error correction. We evaluate FlanEC using the HyPoradise dataset,\nproviding a comprehensive analysis of the model's effectiveness in this domain.\nFurthermore, we assess the proposed approach under different settings to\nevaluate model scalability and efficiency, offering valuable insights into the\npotential of instruction-tuned encoder-decoder models for this task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the 2024 IEEE Workshop on Spoken Language Technology\n  (SLT) - GenSEC Challenge",
    "pdf_url": "http://arxiv.org/pdf/2501.12979v1",
    "published_date": "2025-01-22 16:06:04 UTC",
    "updated_date": "2025-01-22 16:06:04 UTC"
  },
  {
    "arxiv_id": "2501.12978v1",
    "title": "Galois groups of polynomials and neurosymbolic networks",
    "authors": [
      "Elira Shaska",
      "Tony Shaska"
    ],
    "abstract": "This paper introduces a novel approach to understanding Galois theory, one of\nthe foundational areas of algebra, through the lens of machine learning. By\nanalyzing polynomial equations with machine learning techniques, we aim to\nstreamline the process of determining solvability by radicals and explore\nbroader applications within Galois theory. This summary encapsulates the\nbackground, methodology, potential applications, and challenges of using data\nscience in Galois theory.\n  More specifically, we design a neurosymbolic network to classify Galois\ngroups and show how this is more efficient than usual neural networks. We\ndiscover some very interesting distribution of polynomials for groups not\nisomorphic to the symmetric groups and alternating groups.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.HO",
      "I.2.3"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12978v1",
    "published_date": "2025-01-22 16:05:59 UTC",
    "updated_date": "2025-01-22 16:05:59 UTC"
  },
  {
    "arxiv_id": "2501.12972v1",
    "title": "Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs",
    "authors": [
      "Jan Corazza",
      "Ivan Gavran",
      "Gabriela Moreira",
      "Daniel Neider"
    ],
    "abstract": "When blockchain systems are said to be trustless, what this really means is\nthat all the trust is put into software. Thus, there are strong incentives to\nensure blockchain software is correct -- vulnerabilities here cost millions and\nbreak businesses. One of the most powerful ways of establishing software\ncorrectness is by using formal methods. Approaches based on formal methods,\nhowever, induce a significant overhead in terms of time and expertise required\nto successfully employ them. Our work addresses this critical disadvantage by\nautomating the creation of a formal model -- a mathematical abstraction of the\nsoftware system -- which is often a core task when employing formal methods. We\nperform model synthesis in three phases: we first transpile the code into model\nstubs; then we \"fill in the blanks\" using a large language model (LLM);\nfinally, we iteratively repair the generated model, on both syntactical and\nsemantical level. In this way, we significantly reduce the amount of time\nnecessary to create formal models and increase accessibility of valuable\nsoftware verification methods that rely on them. The practical context of our\nwork was reducing the time-to-value of using formal models for correctness\naudits of smart contracts.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12972v1",
    "published_date": "2025-01-22 15:57:29 UTC",
    "updated_date": "2025-01-22 15:57:29 UTC"
  },
  {
    "arxiv_id": "2501.12962v2",
    "title": "It's complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU AI Act",
    "authors": [
      "Kristof Meding"
    ],
    "abstract": "What constitutes a fair decision? This question is not only difficult for\nhumans but becomes more challenging when Artificial Intelligence (AI) models\nare used. In light of discriminatory algorithmic behaviors, the EU has recently\npassed the AI Act, which mandates specific rules for AI models, incorporating\nboth traditional legal non-discrimination regulations and machine learning\nbased algorithmic fairness concepts. This paper aims to bridge these two\ndifferent concepts in the AI Act through: First a high-level introduction of\nboth concepts targeting legal and computer science-oriented scholars, and\nsecond an in-depth analysis of the AI Act's relationship between legal\nnon-discrimination regulations and algorithmic fairness. Our analysis reveals\nthree key findings: (1.), most non-discrimination regulations target only\nhigh-risk AI systems. (2.), the regulation of high-risk systems encompasses\nboth data input requirements and output monitoring, though these regulations\nare often inconsistent and raise questions of computational feasibility. (3.)\nRegulations for General Purpose AI Models, such as Large Language Models that\nare not simultaneously classified as high-risk systems, currently lack\nspecificity compared to other regulations. Based on these findings, we\nrecommend developing more specific auditing and testing methodologies for AI\nsystems. This paper aims to serve as a foundation for future interdisciplinary\ncollaboration between legal scholars and computer science-oriented machine\nlearning researchers studying discrimination in AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12962v2",
    "published_date": "2025-01-22 15:38:09 UTC",
    "updated_date": "2025-03-14 15:05:09 UTC"
  },
  {
    "arxiv_id": "2501.12958v1",
    "title": "A Novel Tracking Framework for Devices in X-ray Leveraging Supplementary Cue-Driven Self-Supervised Features",
    "authors": [
      "Saahil Islam",
      "Venkatesh N. Murthy",
      "Dominik Neumann",
      "Serkan Cimen",
      "Puneet Sharma",
      "Andreas Maier",
      "Dorin Comaniciu",
      "Florin C. Ghesu"
    ],
    "abstract": "To restore proper blood flow in blocked coronary arteries via angioplasty\nprocedure, accurate placement of devices such as catheters, balloons, and\nstents under live fluoroscopy or diagnostic angiography is crucial. Identified\nballoon markers help in enhancing stent visibility in X-ray sequences, while\nthe catheter tip aids in precise navigation and co-registering vessel\nstructures, reducing the need for contrast in angiography. However, accurate\ndetection of these devices in interventional X-ray sequences faces significant\nchallenges, particularly due to occlusions from contrasted vessels and other\ndevices and distractions from surrounding, resulting in the failure to track\nsuch small objects. While most tracking methods rely on spatial correlation of\npast and current appearance, they often lack strong motion comprehension\nessential for navigating through these challenging conditions, and fail to\neffectively detect multiple instances in the scene. To overcome these\nlimitations, we propose a self-supervised learning approach that enhances its\nspatio-temporal understanding by incorporating supplementary cues and learning\nacross multiple representation spaces on a large dataset. Followed by that, we\nintroduce a generic real-time tracking framework that effectively leverages the\npretrained spatio-temporal network and also takes the historical appearance and\ntrajectory data into account. This results in enhanced localization of multiple\ninstances of device landmarks. Our method outperforms state-of-the-art methods\nin interventional X-ray device tracking, especially stability and robustness,\nachieving an 87% reduction in max error for balloon marker detection and a 61%\nreduction in max error for catheter tip detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12958v1",
    "published_date": "2025-01-22 15:32:07 UTC",
    "updated_date": "2025-01-22 15:32:07 UTC"
  },
  {
    "arxiv_id": "2501.12956v2",
    "title": "GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models",
    "authors": [
      "Pengxiang Zhao",
      "Xiaoming Yuan"
    ],
    "abstract": "Large Language Models (LLMs) face significant deployment challenges due to\ntheir substantial resource requirements. While low-bit quantized weights can\nreduce memory usage and improve inference efficiency, current hardware lacks\nnative support for mixed-precision General Matrix Multiplication (mpGEMM),\nresulting in inefficient dequantization-based implementations. Moreover,\nuniform quantization methods often fail to capture weight distributions\nadequately, leading to performance degradation. We propose GANQ (GPU-Adaptive\nNon-Uniform Quantization), a layer-wise post-training non-uniform quantization\nframework optimized for hardware-efficient lookup table-based mpGEMM. GANQ\nachieves superior quantization performance by utilizing a training-free,\nGPU-adaptive optimization algorithm to efficiently reduce layer-wise\nquantization errors. Extensive experiments demonstrate GANQ's ability to reduce\nthe perplexity gap from the FP16 baseline compared to state-of-the-art methods\nfor both 3-bit and 4-bit quantization. Furthermore, when deployed on a single\nNVIDIA RTX 4090 GPU, GANQ's quantized models achieve up to 2.57$\\times$ speedup\nover the baseline, advancing memory and inference efficiency in LLM deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12956v2",
    "published_date": "2025-01-22 15:29:09 UTC",
    "updated_date": "2025-02-11 11:50:15 UTC"
  },
  {
    "arxiv_id": "2501.12948v1",
    "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
    "authors": [
      "DeepSeek-AI",
      "Daya Guo",
      "Dejian Yang",
      "Haowei Zhang",
      "Junxiao Song",
      "Ruoyu Zhang",
      "Runxin Xu",
      "Qihao Zhu",
      "Shirong Ma",
      "Peiyi Wang",
      "Xiao Bi",
      "Xiaokang Zhang",
      "Xingkai Yu",
      "Yu Wu",
      "Z. F. Wu",
      "Zhibin Gou",
      "Zhihong Shao",
      "Zhuoshu Li",
      "Ziyi Gao",
      "Aixin Liu",
      "Bing Xue",
      "Bingxuan Wang",
      "Bochao Wu",
      "Bei Feng",
      "Chengda Lu",
      "Chenggang Zhao",
      "Chengqi Deng",
      "Chenyu Zhang",
      "Chong Ruan",
      "Damai Dai",
      "Deli Chen",
      "Dongjie Ji",
      "Erhang Li",
      "Fangyun Lin",
      "Fucong Dai",
      "Fuli Luo",
      "Guangbo Hao",
      "Guanting Chen",
      "Guowei Li",
      "H. Zhang",
      "Han Bao",
      "Hanwei Xu",
      "Haocheng Wang",
      "Honghui Ding",
      "Huajian Xin",
      "Huazuo Gao",
      "Hui Qu",
      "Hui Li",
      "Jianzhong Guo",
      "Jiashi Li",
      "Jiawei Wang",
      "Jingchang Chen",
      "Jingyang Yuan",
      "Junjie Qiu",
      "Junlong Li",
      "J. L. Cai",
      "Jiaqi Ni",
      "Jian Liang",
      "Jin Chen",
      "Kai Dong",
      "Kai Hu",
      "Kaige Gao",
      "Kang Guan",
      "Kexin Huang",
      "Kuai Yu",
      "Lean Wang",
      "Lecong Zhang",
      "Liang Zhao",
      "Litong Wang",
      "Liyue Zhang",
      "Lei Xu",
      "Leyi Xia",
      "Mingchuan Zhang",
      "Minghua Zhang",
      "Minghui Tang",
      "Meng Li",
      "Miaojun Wang",
      "Mingming Li",
      "Ning Tian",
      "Panpan Huang",
      "Peng Zhang",
      "Qiancheng Wang",
      "Qinyu Chen",
      "Qiushi Du",
      "Ruiqi Ge",
      "Ruisong Zhang",
      "Ruizhe Pan",
      "Runji Wang",
      "R. J. Chen",
      "R. L. Jin",
      "Ruyi Chen",
      "Shanghao Lu",
      "Shangyan Zhou",
      "Shanhuang Chen",
      "Shengfeng Ye",
      "Shiyu Wang",
      "Shuiping Yu",
      "Shunfeng Zhou",
      "Shuting Pan",
      "S. S. Li",
      "Shuang Zhou",
      "Shaoqing Wu",
      "Shengfeng Ye",
      "Tao Yun",
      "Tian Pei",
      "Tianyu Sun",
      "T. Wang",
      "Wangding Zeng",
      "Wanjia Zhao",
      "Wen Liu",
      "Wenfeng Liang",
      "Wenjun Gao",
      "Wenqin Yu",
      "Wentao Zhang",
      "W. L. Xiao",
      "Wei An",
      "Xiaodong Liu",
      "Xiaohan Wang",
      "Xiaokang Chen",
      "Xiaotao Nie",
      "Xin Cheng",
      "Xin Liu",
      "Xin Xie",
      "Xingchao Liu",
      "Xinyu Yang",
      "Xinyuan Li",
      "Xuecheng Su",
      "Xuheng Lin",
      "X. Q. Li",
      "Xiangyue Jin",
      "Xiaojin Shen",
      "Xiaosha Chen",
      "Xiaowen Sun",
      "Xiaoxiang Wang",
      "Xinnan Song",
      "Xinyi Zhou",
      "Xianzu Wang",
      "Xinxia Shan",
      "Y. K. Li",
      "Y. Q. Wang",
      "Y. X. Wei",
      "Yang Zhang",
      "Yanhong Xu",
      "Yao Li",
      "Yao Zhao",
      "Yaofeng Sun",
      "Yaohui Wang",
      "Yi Yu",
      "Yichao Zhang",
      "Yifan Shi",
      "Yiliang Xiong",
      "Ying He",
      "Yishi Piao",
      "Yisong Wang",
      "Yixuan Tan",
      "Yiyang Ma",
      "Yiyuan Liu",
      "Yongqiang Guo",
      "Yuan Ou",
      "Yuduan Wang",
      "Yue Gong",
      "Yuheng Zou",
      "Yujia He",
      "Yunfan Xiong",
      "Yuxiang Luo",
      "Yuxiang You",
      "Yuxuan Liu",
      "Yuyang Zhou",
      "Y. X. Zhu",
      "Yanhong Xu",
      "Yanping Huang",
      "Yaohui Li",
      "Yi Zheng",
      "Yuchen Zhu",
      "Yunxian Ma",
      "Ying Tang",
      "Yukun Zha",
      "Yuting Yan",
      "Z. Z. Ren",
      "Zehui Ren",
      "Zhangli Sha",
      "Zhe Fu",
      "Zhean Xu",
      "Zhenda Xie",
      "Zhengyan Zhang",
      "Zhewen Hao",
      "Zhicheng Ma",
      "Zhigang Yan",
      "Zhiyu Wu",
      "Zihui Gu",
      "Zijia Zhu",
      "Zijun Liu",
      "Zilin Li",
      "Ziwei Xie",
      "Ziyang Song",
      "Zizheng Pan",
      "Zhen Huang",
      "Zhipeng Xu",
      "Zhongyu Zhang",
      "Zhen Zhang"
    ],
    "abstract": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and\nDeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement\nlearning (RL) without supervised fine-tuning (SFT) as a preliminary step,\ndemonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero\nnaturally emerges with numerous powerful and intriguing reasoning behaviors.\nHowever, it encounters challenges such as poor readability, and language\nmixing. To address these issues and further enhance reasoning performance, we\nintroduce DeepSeek-R1, which incorporates multi-stage training and cold-start\ndata before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217\non reasoning tasks. To support the research community, we open-source\nDeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B,\n70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12948v1",
    "published_date": "2025-01-22 15:19:35 UTC",
    "updated_date": "2025-01-22 15:19:35 UTC"
  },
  {
    "arxiv_id": "2501.12942v1",
    "title": "Offline Critic-Guided Diffusion Policy for Multi-User Delay-Constrained Scheduling",
    "authors": [
      "Zhuoran Li",
      "Ruishuo Chen",
      "Hai Zhong",
      "Longbo Huang"
    ],
    "abstract": "Effective multi-user delay-constrained scheduling is crucial in various\nreal-world applications, such as instant messaging, live streaming, and data\ncenter management. In these scenarios, schedulers must make real-time decisions\nto satisfy both delay and resource constraints without prior knowledge of\nsystem dynamics, which are often time-varying and challenging to estimate.\nCurrent learning-based methods typically require interactions with actual\nsystems during the training stage, which can be difficult or impractical, as it\nis capable of significantly degrading system performance and incurring\nsubstantial service costs. To address these challenges, we propose a novel\noffline reinforcement learning-based algorithm, named \\underline{S}cheduling By\n\\underline{O}ffline Learning with \\underline{C}ritic Guidance and\n\\underline{D}iffusion Generation (SOCD), to learn efficient scheduling policies\npurely from pre-collected \\emph{offline data}. SOCD innovatively employs a\ndiffusion-based policy network, complemented by a sampling-free critic network\nfor policy guidance. By integrating the Lagrangian multiplier optimization into\nthe offline reinforcement learning, SOCD effectively trains high-quality\nconstraint-aware policies exclusively from available datasets, eliminating the\nneed for online interactions with the system. Experimental results demonstrate\nthat SOCD is resilient to various system dynamics, including partially\nobservable and large-scale environments, and delivers superior performance\ncompared to existing methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12942v1",
    "published_date": "2025-01-22 15:13:21 UTC",
    "updated_date": "2025-01-22 15:13:21 UTC"
  },
  {
    "arxiv_id": "2501.12910v1",
    "title": "PreciseCam: Precise Camera Control for Text-to-Image Generation",
    "authors": [
      "Edurne Bernal-Berdun",
      "Ana Serrano",
      "Belen Masia",
      "Matheus Gadelha",
      "Yannick Hold-Geoffroy",
      "Xin Sun",
      "Diego Gutierrez"
    ],
    "abstract": "Images as an artistic medium often rely on specific camera angles and lens\ndistortions to convey ideas or emotions; however, such precise control is\nmissing in current text-to-image models. We propose an efficient and general\nsolution that allows precise control over the camera when generating both\nphotographic and artistic images. Unlike prior methods that rely on predefined\nshots, we rely solely on four simple extrinsic and intrinsic camera parameters,\nremoving the need for pre-existing geometry, reference 3D objects, and\nmulti-view data. We also present a novel dataset with more than 57,000 images,\nalong with their text prompts and ground-truth camera parameters. Our\nevaluation shows precise camera control in text-to-image generation, surpassing\ntraditional prompt engineering approaches. Our data, model, and code are\npublicly available at https://graphics.unizar.es/projects/PreciseCam2024.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12910v1",
    "published_date": "2025-01-22 14:37:01 UTC",
    "updated_date": "2025-01-22 14:37:01 UTC"
  },
  {
    "arxiv_id": "2501.13141v1",
    "title": "AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks",
    "authors": [
      "Qiongyan Wang",
      "Yutong Xia",
      "Siru ZHong",
      "Weichuang Li",
      "Yuankai Wu",
      "Shifen Cheng",
      "Junbo Zhang",
      "Yu Zheng",
      "Yuxuan Liang"
    ],
    "abstract": "Monitoring real-time air quality is essential for safeguarding public health\nand fostering social progress. However, the widespread deployment of air\nquality monitoring stations is constrained by their significant costs. To\naddress this limitation, we introduce \\emph{AirRadar}, a deep neural network\ndesigned to accurately infer real-time air quality in locations lacking\nmonitoring stations by utilizing data from existing ones. By leveraging\nlearnable mask tokens, AirRadar reconstructs air quality features in\nunmonitored regions. Specifically, it operates in two stages: first capturing\nspatial correlations and then adjusting for distribution shifts. We validate\nAirRadar's efficacy using a year-long dataset from 1,085 monitoring stations\nacross China, demonstrating its superiority over multiple baselines, even with\nvarying degrees of unobserved data. The source code can be accessed at\nhttps://github.com/CityMind-Lab/AirRadar.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13141v1",
    "published_date": "2025-01-22 14:32:20 UTC",
    "updated_date": "2025-01-22 14:32:20 UTC"
  },
  {
    "arxiv_id": "2501.12901v1",
    "title": "Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration",
    "authors": [
      "Offa Kingsleigh",
      "Alfred Abercrombie",
      "David Woolstencroft",
      "Beorhtric Meadowcroft",
      "Marcus Irvin"
    ],
    "abstract": "Contextual Partitioning introduces an innovative approach to enhancing the\narchitectural design of large-scale computational models through the dynamic\nsegmentation of parameters into context-aware regions. This methodology\nemphasizes the importance of task-specific specialization, achieved through\nadaptive parameter allocation mechanisms that align with the linguistic\nfeatures of input data. Experimental evaluations demonstrated substantial\nimprovements in accuracy, perplexity, and contextual coherence across a variety\nof linguistic tasks, highlighting the adaptability and scalability of the\nproposed framework. By reducing redundancy and enhancing computational\nefficiency, Contextual Partitioning not only streamlines model operations but\nalso expands the scope of applications for advanced language processing\nsystems. The approach operates autonomously, requiring no external fine-tuning,\nthereby addressing a significant limitation in conventional parameter\noptimization techniques. Empirical results demonstrate the effectiveness of\ngradient-driven segmentation, enabling models to dynamically recalibrate and\nspecialize in response to task-specific demands. Furthermore, resource\nutilization metrics reveal notable reductions in memory usage and training\ntimes, confirming the efficiency of the approach. Observations from qualitative\nanalyses illustrate improved contextual coherence and logical flow in generated\noutputs, reinforcing the practical value of this technique. The findings\ncollectively demonstrate the potential for Contextual Partitioning to redefine\nthe scalability and adaptability of computational language architectures in\ndiverse and complex domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12901v1",
    "published_date": "2025-01-22 14:21:04 UTC",
    "updated_date": "2025-01-22 14:21:04 UTC"
  },
  {
    "arxiv_id": "2503.15502v1",
    "title": "MapColorAI: Designing Contextually Relevant Choropleth Map Color Schemes Using a Large Language Model",
    "authors": [
      "Nai Yang",
      "Yijie Wang",
      "Fan Wu",
      "Zhiwei Wei"
    ],
    "abstract": "Choropleth maps, which utilize color schemes to visualize spatial patterns\nand trends, are simple yet effective tools for geographic data analysis. As\nsuch, color scheme design is a critical aspect of choropleth map creation. The\ntraditional coloring methods offered by GIS tools such as ArcGIS and QGIS are\nnot user-friendly for non-professionals. On the one hand, these tools provide\nnumerous color schemes, making it hard to decide which one best matches the\ntheme. On the other hand, it is difficult to fulfill some ambiguous and\npersonalized coloring needs of users, such as requests for 'summer-like' map\ncolors. To address these shortcomings, we develop a novel system that leverages\na large language model and map color design principles to generate contextually\nrelevant and user-aligned choropleth map color schemes. The system follows a\nthree-stage process: Data processing, which provides an overview of the data\nand classifies the data into meaningful classes; Color Concept Design, where\nthe color theme and color mode are conceptualized based on data characteristics\nand user intentions; and Color Scheme Design, where specific colors are\nassigned to classes based on generated color theme, color mode, and user\nrequirements. Our system incorporates an interactive interface, providing\nnecessary visualization for choropleth map color design and allowing users to\ncustomize and refine color choices flexibly. Through user studies and\nevaluations, the system demonstrates acceptable usability, accuracy, and\nflexibility, with users highlighting the tool's efficiency and ease of use.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15502v1",
    "published_date": "2025-01-22 14:18:07 UTC",
    "updated_date": "2025-01-22 14:18:07 UTC"
  },
  {
    "arxiv_id": "2502.10408v1",
    "title": "Knowledge Tracing in Programming Education Integrating Students' Questions",
    "authors": [
      "Doyoun Kim",
      "Suin Kim",
      "Yojan Jo"
    ],
    "abstract": "Knowledge tracing (KT) in programming education presents unique challenges\ndue to the complexity of coding tasks and the diverse methods students use to\nsolve problems. Although students' questions often contain valuable signals\nabout their understanding and misconceptions, traditional KT models often\nneglect to incorporate these questions as inputs to address these challenges.\nThis paper introduces SQKT (Students' Question-based Knowledge Tracing), a\nknowledge tracing model that leverages students' questions and automatically\nextracted skill information to enhance the accuracy of predicting students'\nperformance on subsequent problems in programming education. Our method creates\nsemantically rich embeddings that capture not only the surface-level content of\nthe questions but also the student's mastery level and conceptual\nunderstanding. Experimental results demonstrate SQKT's superior performance in\npredicting student completion across various Python programming courses of\ndiffering difficulty levels. In in-domain experiments, SQKT achieved a 33.1\\%\nabsolute improvement in AUC compared to baseline models. The model also\nexhibited robust generalization capabilities in cross-domain settings,\neffectively addressing data scarcity issues in advanced programming courses.\nSQKT can be used to tailor educational content to individual learning needs and\ndesign adaptive learning systems in computer science education.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10408v1",
    "published_date": "2025-01-22 14:13:40 UTC",
    "updated_date": "2025-01-22 14:13:40 UTC"
  },
  {
    "arxiv_id": "2501.12884v1",
    "title": "Learning Graph Node Embeddings by Smooth Pair Sampling",
    "authors": [
      "Konstantin Kutzkov"
    ],
    "abstract": "Random walk-based node embedding algorithms have attracted a lot of attention\ndue to their scalability and ease of implementation. Previous research has\nfocused on different walk strategies, optimization objectives, and embedding\nlearning models. Inspired by observations on real data, we take a different\napproach and propose a new regularization technique. More precisely, the\nfrequencies of node pairs generated by the skip-gram model on random walk node\nsequences follow a highly skewed distribution which causes learning to be\ndominated by a fraction of the pairs. We address the issue by designing an\nefficient sampling procedure that generates node pairs according to their {\\em\nsmoothed frequency}. Theoretical and experimental results demonstrate the\nadvantages of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for oral presentation at AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12884v1",
    "published_date": "2025-01-22 13:51:33 UTC",
    "updated_date": "2025-01-22 13:51:33 UTC"
  },
  {
    "arxiv_id": "2501.12881v1",
    "title": "Reinforcement learning Based Automated Design of Differential Evolution Algorithm for Black-box Optimization",
    "authors": [
      "Xu Yang",
      "Rui Wang",
      "Kaiwen Li",
      "Ling Wang"
    ],
    "abstract": "Differential evolution (DE) algorithm is recognized as one of the most\neffective evolutionary algorithms, demonstrating remarkable efficacy in\nblack-box optimization due to its derivative-free nature. Numerous enhancements\nto the fundamental DE have been proposed, incorporating innovative mutation\nstrategies and sophisticated parameter tuning techniques to improve\nperformance. However, no single variant has proven universally superior across\nall problems. To address this challenge, we introduce a novel framework that\nemploys reinforcement learning (RL) to automatically design DE for black-box\noptimization through meta-learning. RL acts as an advanced meta-optimizer,\ngenerating a customized DE configuration that includes an optimal\ninitialization strategy, update rule, and hyperparameters tailored to a\nspecific black-box optimization problem. This process is informed by a detailed\nanalysis of the problem characteristics. In this proof-of-concept study, we\nutilize a double deep Q-network for implementation, considering a subset of 40\npossible strategy combinations and parameter optimizations simultaneously. The\nframework's performance is evaluated against black-box optimization benchmarks\nand compared with state-of-the-art algorithms. The experimental results\nhighlight the promising potential of our proposed framework.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12881v1",
    "published_date": "2025-01-22 13:41:47 UTC",
    "updated_date": "2025-01-22 13:41:47 UTC"
  },
  {
    "arxiv_id": "2501.12869v1",
    "title": "Drone Carrier: An Integrated Unmanned Surface Vehicle for Autonomous Inspection and Intervention in GNSS-Denied Maritime Environment",
    "authors": [
      "Yihao Dong",
      "Muhayyu Ud Din",
      "Francesco Lagala",
      "Hailiang Kuang",
      "Jianjun Sun",
      "Siyuan Yang",
      "Irfan Hussain",
      "Shaoming He"
    ],
    "abstract": "This paper introduces an innovative drone carrier concept that is applied in\nmaritime port security or offshore rescue. This system works with a\nheterogeneous system consisting of multiple Unmanned Aerial Vehicles (UAVs) and\nUnmanned Surface Vehicles (USVs) to perform inspection and intervention tasks\nin GNSS-denied or interrupted environments. The carrier, an electric catamaran\nmeasuring 4m by 7m, features a 4m by 6m deck supporting automated takeoff and\nlanding for four DJI M300 drones, along with a 10kg-payload manipulator\noperable in up to level 3 sea conditions. Utilizing an offshore gimbal camera\nfor navigation, the carrier can autonomously navigate, approach and dock with\nnon-cooperative vessels, guided by an onboard camera, LiDAR, and Doppler\nVelocity Log (DVL) over a 3 km$^2$ area. UAVs equipped with onboard\nUltra-Wideband (UWB) technology execute mapping, detection, and manipulation\ntasks using a versatile gripper designed for wet, saline conditions.\nAdditionally, two UAVs can coordinate to transport large objects to the\nmanipulator or interact directly with them. These procedures are fully\nautomated and were successfully demonstrated at the Mohammed Bin Zayed\nInternational Robotic Competition (MBZIRC2024), where the drone carrier\nequipped with four UAVS and one manipulator, automatically accomplished the\nintervention tasks in sea-level-3 (wave height 1.25m) based on the rough target\ninformation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 12pages",
    "pdf_url": "http://arxiv.org/pdf/2501.12869v1",
    "published_date": "2025-01-22 13:25:52 UTC",
    "updated_date": "2025-01-22 13:25:52 UTC"
  },
  {
    "arxiv_id": "2501.12868v1",
    "title": "As Confidence Aligns: Exploring the Effect of AI Confidence on Human Self-confidence in Human-AI Decision Making",
    "authors": [
      "Jingshu Li",
      "Yitian Yang",
      "Q. Vera Liao",
      "Junti Zhang",
      "Yi-Chieh Lee"
    ],
    "abstract": "Complementary collaboration between humans and AI is essential for human-AI\ndecision making. One feasible approach to achieving it involves accounting for\nthe calibrated confidence levels of both AI and users. However, this process\nwould likely be made more difficult by the fact that AI confidence may\ninfluence users' self-confidence and its calibration. To explore these\ndynamics, we conducted a randomized behavioral experiment. Our results indicate\nthat in human-AI decision-making, users' self-confidence aligns with AI\nconfidence and such alignment can persist even after AI ceases to be involved.\nThis alignment then affects users' self-confidence calibration. We also found\nthe presence of real-time correctness feedback of decisions reduced the degree\nof alignment. These findings suggest that users' self-confidence is not\nindependent of AI confidence, which practitioners aiming to achieve better\nhuman-AI collaboration need to be aware of. We call for research focusing on\nthe alignment of human cognition and behavior with AI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12868v1",
    "published_date": "2025-01-22 13:25:14 UTC",
    "updated_date": "2025-01-22 13:25:14 UTC"
  },
  {
    "arxiv_id": "2501.12862v1",
    "title": "Mutation-Guided LLM-based Test Generation at Meta",
    "authors": [
      "Christopher Foster",
      "Abhishek Gulati",
      "Mark Harman",
      "Inna Harper",
      "Ke Mao",
      "Jillian Ritchey",
      "Hervé Robert",
      "Shubho Sengupta"
    ],
    "abstract": "This paper describes Meta's ACH system for mutation-guided LLM-based test\ngeneration. ACH generates relatively few mutants (aka simulated faults),\ncompared to traditional mutation testing. Instead, it focuses on generating\ncurrently undetected faults that are specific to an issue of concern. From\nthese currently uncaught faults, ACH generates tests that can catch them,\nthereby `killing' the mutants and consequently hardening the platform against\nregressions. We use privacy concerns to illustrate our approach, but ACH can\nharden code against {\\em any} type of regression. In total, ACH was applied to\n10,795 Android Kotlin classes in 7 software platforms deployed by Meta, from\nwhich it generated 9,095 mutants and 571 privacy-hardening test cases. ACH also\ndeploys an LLM-based equivalent mutant detection agent that achieves a\nprecision of 0.79 and a recall of 0.47 (rising to 0.95 and 0.96 with simple\npre-processing). ACH was used by Messenger and WhatsApp test-a-thons where\nengineers accepted 73% of its tests, judging 36% to privacy relevant. We\nconclude that ACH hardens code against specific concerns and that, even when\nits tests do not directly tackle the specific concern, engineers find them\nuseful for their other benefits.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Submitted to FSE 2025 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2501.12862v1",
    "published_date": "2025-01-22 13:14:02 UTC",
    "updated_date": "2025-01-22 13:14:02 UTC"
  },
  {
    "arxiv_id": "2501.12844v2",
    "title": "GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model for Multi-organ Segmentation",
    "authors": [
      "Ruicheng Zhang",
      "Haowei Guo",
      "Zeyu Zhang",
      "Puxin Yan",
      "Shen Zhao"
    ],
    "abstract": "Multi-organ segmentation is a critical yet challenging task due to complex\nanatomical backgrounds, blurred boundaries, and diverse morphologies. This\nstudy introduces the Gradient-aware Adaptive Momentum Evolution Deep Snake\n(GAMED-Snake) model, which establishes a novel paradigm for contour-based\nsegmentation by integrating gradient-based learning with adaptive momentum\nevolution mechanisms. The GAMED-Snake model incorporates three major\ninnovations: First, the Distance Energy Map Prior (DEMP) generates a\npixel-level force field that effectively attracts contour points towards the\ntrue boundaries, even in scenarios with complex backgrounds and blurred edges.\nSecond, the Differential Convolution Inception Module (DCIM) precisely extracts\ncomprehensive energy gradients, significantly enhancing segmentation accuracy.\nThird, the Adaptive Momentum Evolution Mechanism (AMEM) employs cross-attention\nto establish dynamic features across different iterations of evolution,\nenabling precise boundary alignment for diverse morphologies. Experimental\nresults on four challenging multi-organ segmentation datasets demonstrate that\nGAMED-Snake improves the mDice metric by approximately 2% compared to\nstate-of-the-art methods. Code will be available at\nhttps://github.com/SYSUzrc/GAMED-Snake.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12844v2",
    "published_date": "2025-01-22 12:45:09 UTC",
    "updated_date": "2025-03-03 03:18:40 UTC"
  },
  {
    "arxiv_id": "2501.14828v1",
    "title": "An Ensemble Model with Attention Based Mechanism for Image Captioning",
    "authors": [
      "Israa Al Badarneh",
      "Bassam Hammo",
      "Omar Al-Kadi"
    ],
    "abstract": "Image captioning creates informative text from an input image by creating a\nrelationship between the words and the actual content of an image. Recently,\ndeep learning models that utilize transformers have been the most successful in\nautomatically generating image captions. The capabilities of transformer\nnetworks have led to notable progress in several activities related to vision.\nIn this paper, we thoroughly examine transformer models, emphasizing the\ncritical role that attention mechanisms play. The proposed model uses a\ntransformer encoder-decoder architecture to create textual captions and a deep\nlearning convolutional neural network to extract features from the images. To\ncreate the captions, we present a novel ensemble learning framework that\nimproves the richness of the generated captions by utilizing several deep\nneural network architectures based on a voting mechanism that chooses the\ncaption with the highest bilingual evaluation understudy (BLEU) score. The\nproposed model was evaluated using publicly available datasets. Using the\nFlickr8K dataset, the proposed model achieved the highest BLEU-[1-3] scores\nwith rates of 0.728, 0.495, and 0.323, respectively. The suggested model\noutperformed the latest methods in Flickr30k datasets, determined by BLEU-[1-4]\nscores with rates of 0.798, 0.561, 0.387, and 0.269, respectively. The model\nefficacy was also obtained by the Semantic propositional image caption\nevaluation (SPICE) metric with a scoring rate of 0.164 for the Flicker8k\ndataset and 0.387 for the Flicker30k. Finally, ensemble learning significantly\nadvances the process of image captioning and, hence, can be leveraged in\nvarious applications across different domains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "35 pages, 10 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.14828v1",
    "published_date": "2025-01-22 12:28:37 UTC",
    "updated_date": "2025-01-22 12:28:37 UTC"
  },
  {
    "arxiv_id": "2501.12829v1",
    "title": "A transformer-based deep q learning approach for dynamic load balancing in software-defined networks",
    "authors": [
      "Evans Tetteh Owusu",
      "Kwame Agyemang-Prempeh Agyekum",
      "Marinah Benneh",
      "Pius Ayorna",
      "Justice Owusu Agyemang",
      "George Nii Martey Colley",
      "James Dzisi Gazde"
    ],
    "abstract": "This study proposes a novel approach for dynamic load balancing in\nSoftware-Defined Networks (SDNs) using a Transformer-based Deep Q-Network\n(DQN). Traditional load balancing mechanisms, such as Round Robin (RR) and\nWeighted Round Robin (WRR), are static and often struggle to adapt to\nfluctuating traffic conditions, leading to inefficiencies in network\nperformance. In contrast, SDNs offer centralized control and flexibility,\nproviding an ideal platform for implementing machine learning-driven\noptimization strategies. The core of this research combines a Temporal Fusion\nTransformer (TFT) for accurate traffic prediction with a DQN model to perform\nreal-time dynamic load balancing. The TFT model predicts future traffic loads,\nwhich the DQN uses as input, allowing it to make intelligent routing decisions\nthat optimize throughput, minimize latency, and reduce packet loss. The\nproposed model was tested against RR and WRR in simulated environments with\nvarying data rates, and the results demonstrate significant improvements in\nnetwork performance. For the 500MB data rate, the DQN model achieved an average\nthroughput of 0.275 compared to 0.202 and 0.205 for RR and WRR, respectively.\nAdditionally, the DQN recorded lower average latency and packet loss. In the\n1000MB simulation, the DQN model outperformed the traditional methods in\nthroughput, latency, and packet loss, reinforcing its effectiveness in managing\nnetwork loads dynamically. This research presents an important step towards\nenhancing network performance through the integration of machine learning\nmodels within SDNs, potentially paving the way for more adaptive, intelligent\nnetwork management systems.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.NI",
    "comment": "24 pages, 26 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12829v1",
    "published_date": "2025-01-22 12:16:30 UTC",
    "updated_date": "2025-01-22 12:16:30 UTC"
  },
  {
    "arxiv_id": "2501.12826v1",
    "title": "Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek",
    "authors": [
      "John Pavlopoulos",
      "Juli Bakagianni",
      "Kanella Pouli",
      "Maria Gavriilidou"
    ],
    "abstract": "Natural Language Processing (NLP) for lesser-resourced languages faces\npersistent challenges, including limited datasets, inherited biases from\nhigh-resource languages, and the need for domain-specific solutions. This study\naddresses these gaps for Modern Greek through three key contributions. First,\nwe evaluate the performance of open-source (Llama-70b) and closed-source\n(GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset\navailability, revealing task-specific strengths, weaknesses, and parity in\ntheir performance. Second, we expand the scope of Greek NLP by reframing\nAuthorship Attribution as a tool to assess potential data usage by LLMs in\npre-training, with high 0-shot accuracy suggesting ethical implications for\ndata provenance. Third, we showcase a legal NLP case study, where a Summarize,\nTranslate, and Embed (STE) methodology outperforms the traditional TF-IDF\napproach for clustering \\emph{long} legal texts. Together, these contributions\nprovide a roadmap to advance NLP in lesser-resourced languages, bridging gaps\nin model evaluation, task innovation, and real-world impact.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NLP, Modern Greek, benchmark, machine learning, language resources",
    "pdf_url": "http://arxiv.org/pdf/2501.12826v1",
    "published_date": "2025-01-22 12:06:16 UTC",
    "updated_date": "2025-01-22 12:06:16 UTC"
  },
  {
    "arxiv_id": "2501.12823v1",
    "title": "To Measure or Not: A Cost-Sensitive, Selective Measuring Environment for Agricultural Management Decisions with Reinforcement Learning",
    "authors": [
      "Hilmy Baja",
      "Michiel Kallenberg",
      "Ioannis N. Athanasiadis"
    ],
    "abstract": "Farmers rely on in-field observations to make well-informed crop management\ndecisions to maximize profit and minimize adverse environmental impact.\nHowever, obtaining real-world crop state measurements is labor-intensive,\ntime-consuming and expensive. In most cases, it is not feasible to gather crop\nstate measurements before every decision moment. Moreover, in previous research\npertaining to farm management optimization, these observations are often\nassumed to be readily available without any cost, which is unrealistic. Hence,\nenabling optimization without the need to have temporally complete crop state\nobservations is important. An approach to that problem is to include measuring\nas part of decision making. As a solution, we apply reinforcement learning (RL)\nto recommend opportune moments to simultaneously measure crop features and\napply nitrogen fertilizer. With realistic considerations, we design an RL\nenvironment with explicit crop feature measuring costs. While balancing costs,\nwe find that an RL agent, trained with recurrent PPO, discovers adaptive\nmeasuring policies that follow critical crop development stages, with results\naligned by what domain experts would consider a sensible approach. Our results\nhighlight the importance of measuring when crop feature measurements are not\nreadily available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures, accepted after peer-review at the 39th Annual\n  AAAI Conference on Artificial Intelligence, AI for Social Impact Track,\n  February 2025, Philadelphia, Pennsylvania, USA",
    "pdf_url": "http://arxiv.org/pdf/2501.12823v1",
    "published_date": "2025-01-22 12:03:53 UTC",
    "updated_date": "2025-01-22 12:03:53 UTC"
  },
  {
    "arxiv_id": "2501.12811v1",
    "title": "Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments",
    "authors": [
      "Lafedi Svet",
      "Arthur Brightwell",
      "Augustus Wildflower",
      "Cecily Marshwood"
    ],
    "abstract": "Modern cybersecurity landscapes increasingly demand sophisticated detection\nframeworks capable of identifying evolving threats with precision and\nadaptability. The proposed Zero-Space Detection framework introduces a novel\napproach that dynamically identifies latent behavioral patterns through\nunsupervised clustering and advanced deep learning techniques. Designed to\naddress the limitations of signature-based and heuristic methods, it operates\neffectively in high-velocity environments by integrating multi-phase filtering\nand ensemble learning for refined decision-making. Experimental evaluation\nreveals high detection rates across diverse ransomware families, including\nLockBit, Conti, REvil, and BlackMatter, while maintaining low false positive\nrates and scalable performance. Computational overhead remains minimal, with\naverage processing times ensuring compatibility with real-time systems even\nunder peak operational loads. The framework demonstrates resilience against\nadversarial strategies such as obfuscation and encryption speed variability,\nwhich frequently challenge conventional detection systems. Analysis across\nmultiple data sources highlights its versatility in handling diverse file types\nand operational contexts. Comprehensive metrics, including detection\nprobability, latency, and resource efficiency, validate its efficacy under\nreal-world conditions. Through its modular architecture, the framework achieves\nseamless integration with existing cybersecurity infrastructures without\nsignificant reconfiguration. The results demonstrate its robustness and\nscalability, offering a transformative paradigm for ransomware identification\nin dynamic and resource-constrained environments.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12811v1",
    "published_date": "2025-01-22 11:41:44 UTC",
    "updated_date": "2025-01-22 11:41:44 UTC"
  },
  {
    "arxiv_id": "2501.12810v1",
    "title": "Machine Learning Modeling for Multi-order Human Visual Motion Processing",
    "authors": [
      "Zitang Sun",
      "Yen-Ju Chen",
      "Yung-Hao Yang",
      "Yuan Li",
      "Shin'ya Nishida"
    ],
    "abstract": "Our research aims to develop machines that learn to perceive visual motion as\ndo humans. While recent advances in computer vision (CV) have enabled DNN-based\nmodels to accurately estimate optical flow in naturalistic images, a\nsignificant disparity remains between CV models and the biological visual\nsystem in both architecture and behavior. This disparity includes humans'\nability to perceive the motion of higher-order image features (second-order\nmotion), which many CV models fail to capture because of their reliance on the\nintensity conservation law. Our model architecture mimics the cortical V1-MT\nmotion processing pathway, utilizing a trainable motion energy sensor bank and\na recurrent graph network. Supervised learning employing diverse naturalistic\nvideos allows the model to replicate psychophysical and physiological findings\nabout first-order (luminance-based) motion perception. For second-order motion,\ninspired by neuroscientific findings, the model includes an additional sensing\npathway with nonlinear preprocessing before motion energy sensing, implemented\nusing a simple multilayer 3D CNN block. When exploring how the brain acquired\nthe ability to perceive second-order motion in natural environments, in which\npure second-order signals are rare, we hypothesized that second-order\nmechanisms were critical when estimating robust object motion amidst optical\nfluctuations, such as highlights on glossy surfaces. We trained our\ndual-pathway model on novel motion datasets with varying material properties of\nmoving objects. We found that training to estimate object motion from\nnon-Lambertian materials naturally endowed the model with the capacity to\nperceive second-order motion, as can humans. The resulting model effectively\naligns with biological systems while generalizing to both first- and\nsecond-order motion phenomena in natural scenes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12810v1",
    "published_date": "2025-01-22 11:41:41 UTC",
    "updated_date": "2025-01-22 11:41:41 UTC"
  },
  {
    "arxiv_id": "2501.12793v1",
    "title": "Revisit Self-Debugging with Self-Generated Tests for Code Generation",
    "authors": [
      "Xiancai Chen",
      "Zhengwei Tao",
      "Kechi Zhang",
      "Changzhi Zhou",
      "Wanli Gu",
      "Yuanpeng He",
      "Mengdi Zhang",
      "Xunliang Cai",
      "Haiyan Zhao",
      "Zhi Jin"
    ],
    "abstract": "Large language models (LLMs) have shown significant advancements in code\ngeneration, but still face challenges on tasks beyond their basic capabilities.\nRecently, the notion of self-debugging has been proposed to boost the\nperformance of code generation by leveraging execution feedback from tests.\nDespite its promise, the availability of high-quality tests in real-world\nscenarios is limited. In this context, self-debugging with self-generated tests\nis a promising solution but lacks a full exploration of its limitations and\npractical potential. Therefore, we investigate its efficacy on diverse\nprogramming problems. To deepen our understanding, we propose two distinct\nparadigms for the process: post-execution and in-execution self-debugging.\nWithin the scope of self-contained Python programming tasks, we find that\npost-execution self-debugging struggles on basic problems but shows potential\nfor improvement on competitive ones, due to the bias introduced by\nself-generated tests. On the other hand, in-execution self-debugging enables\nLLMs to mitigate the bias by solely leveraging intermediate states during\nexecution, thereby enhancing code generation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2501.12793v1",
    "published_date": "2025-01-22 10:54:19 UTC",
    "updated_date": "2025-01-22 10:54:19 UTC"
  },
  {
    "arxiv_id": "2502.06789v1",
    "title": "Information-theoretic Bayesian Optimization: Survey and Tutorial",
    "authors": [
      "Eduardo C. Garrido-Merchán"
    ],
    "abstract": "Several scenarios require the optimization of non-convex black-box functions,\nthat are noisy expensive to evaluate functions with unknown analytical\nexpression, whose gradients are hence not accessible. For example, the\nhyper-parameter tuning problem of machine learning models. Bayesian\noptimization is a class of methods with state-of-the-art performance delivering\na solution to this problem in real scenarios. It uses an iterative process that\nemploys a probabilistic surrogate model, typically a Gaussian process, of the\nobjective function to be optimized computing a posterior predictive\ndistribution of the black-box function. Based on the information given by this\nposterior predictive distribution, Bayesian optimization includes the\ncomputation of an acquisition function that represents, for every input space\npoint, the utility of evaluating that point in the next iteraiton if the\nobjective of the process is to retrieve a global extremum. This paper is a\nsurvey of the information theoretical acquisition functions, whose performance\ntypically outperforms the rest of acquisition functions. The main concepts of\nthe field of information theory are also described in detail to make the reader\naware of why information theory acquisition functions deliver great results in\nBayesian optimization and how can we approximate them when they are\nintractable. We also cover how information theory acquisition functions can be\nadapted to complex optimization scenarios such as the multi-objective,\nconstrained, non-myopic, multi-fidelity, parallel and asynchronous settings and\nprovide further lines of research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "None",
    "pdf_url": "http://arxiv.org/pdf/2502.06789v1",
    "published_date": "2025-01-22 10:54:15 UTC",
    "updated_date": "2025-01-22 10:54:15 UTC"
  },
  {
    "arxiv_id": "2501.12776v1",
    "title": "Data re-uploading in Quantum Machine Learning for time series: application to traffic forecasting",
    "authors": [
      "Nikolaos Schetakis",
      "Paolo Bonfini",
      "Negin Alisoltani",
      "Konstantinos Blazakis",
      "Symeon I. Tsintzos",
      "Alexis Askitopoulos",
      "Davit Aghamalyan",
      "Panagiotis Fafoutellis",
      "Eleni I. Vlahogianni"
    ],
    "abstract": "Accurate traffic forecasting plays a crucial role in modern Intelligent\nTransportation Systems (ITS), as it enables real-time traffic flow management,\nreduces congestion, and improves the overall efficiency of urban transportation\nnetworks. With the rise of Quantum Machine Learning (QML), it has emerged a new\nparadigm possessing the potential to enhance predictive capabilities beyond\nwhat classical machine learning models can achieve. In the present work we\npursue a heuristic approach to explore the potential of QML, and focus on a\nspecific transport issue. In particular, as a case study we investigate a\ntraffic forecast task for a major urban area in Athens (Greece), for which we\npossess high-resolution data. In this endeavor we explore the application of\nQuantum Neural Networks (QNN), and, notably, we present the first application\nof quantum data re-uploading in the context of transport forecasting. This\ntechnique allows quantum models to better capture complex patterns, such as\ntraffic dynamics, by repeatedly encoding classical data into a quantum state.\nAside from providing a prediction model, we spend considerable effort in\ncomparing the performance of our hybrid quantum-classical neural networks with\nclassical deep learning approaches. Our results show that hybrid models achieve\ncompetitive accuracy with state-of-the-art classical methods, especially when\nthe number of qubits and re-uploading blocks is increased. While the classical\nmodels demonstrate lower computational demands, we provide evidence that\nincreasing the complexity of the quantum model improves predictive accuracy.\nThese findings indicate that QML techniques, and specifically the data\nre-uploading approach, hold promise for advancing traffic forecasting models\nand could be instrumental in addressing challenges inherent in ITS\nenvironments.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12776v1",
    "published_date": "2025-01-22 10:21:00 UTC",
    "updated_date": "2025-01-22 10:21:00 UTC"
  },
  {
    "arxiv_id": "2502.10407v1",
    "title": "Addressing Bias in Generative AI: Challenges and Research Opportunities in Information Management",
    "authors": [
      "Xiahua Wei",
      "Naveen Kumar",
      "Han Zhang"
    ],
    "abstract": "Generative AI technologies, particularly Large Language Models (LLMs), have\ntransformed information management systems but introduced substantial biases\nthat can compromise their effectiveness in informing business decision-making.\nThis challenge presents information management scholars with a unique\nopportunity to advance the field by identifying and addressing these biases\nacross extensive applications of LLMs. Building on the discussion on bias\nsources and current methods for detecting and mitigating bias, this paper seeks\nto identify gaps and opportunities for future research. By incorporating\nethical considerations, policy implications, and sociotechnical perspectives,\nwe focus on developing a framework that covers major stakeholders of Generative\nAI systems, proposing key research questions, and inspiring discussion. Our\ngoal is to provide actionable pathways for researchers to address bias in LLM\napplications, thereby advancing research in information management that\nultimately informs business practices. Our forward-looking framework and\nresearch agenda advocate interdisciplinary approaches, innovative methods,\ndynamic perspectives, and rigorous evaluation to ensure fairness and\ntransparency in Generative AI-driven information systems. We expect this study\nto serve as a call to action for information management scholars to tackle this\ncritical issue, guiding the improvement of fairness and effectiveness in\nLLM-based systems for business practice.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Information & Management, forthcoming",
    "pdf_url": "http://arxiv.org/pdf/2502.10407v1",
    "published_date": "2025-01-22 10:14:31 UTC",
    "updated_date": "2025-01-22 10:14:31 UTC"
  },
  {
    "arxiv_id": "2501.12770v1",
    "title": "On Tradeoffs in Learning-Augmented Algorithms",
    "authors": [
      "Ziyad Benomar",
      "Vianney Perchet"
    ],
    "abstract": "The field of learning-augmented algorithms has gained significant attention\nin recent years. These algorithms, using potentially inaccurate predictions,\nmust exhibit three key properties: consistency, robustness, and smoothness. In\nscenarios where distributional information about predictions is available, a\nstrong expected performance is required. Typically, the design of these\nalgorithms involves a natural tradeoff between consistency and robustness, and\nprevious works aimed to achieve Pareto-optimal tradeoffs for specific problems.\nHowever, in some settings, this comes at the expense of smoothness. This paper\ndemonstrates that certain problems involve multiple tradeoffs between\nconsistency, robustness, smoothness, and average performance.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "Accepted as a conference paper at AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.12770v1",
    "published_date": "2025-01-22 10:12:18 UTC",
    "updated_date": "2025-01-22 10:12:18 UTC"
  },
  {
    "arxiv_id": "2501.12766v1",
    "title": "NExtLong: Toward Effective Long-Context Training without Long Documents",
    "authors": [
      "Chaochen Gao",
      "Xing Wu",
      "Zijia Lin",
      "Debing Zhang",
      "Songlin Hu"
    ],
    "abstract": "Large language models (LLMs) with extended context windows have made\nsignificant strides yet remain a challenge due to the scarcity of long\ndocuments. Existing methods tend to synthesize long-context data but lack a\nclear mechanism to reinforce the long-range dependency modeling. To address\nthis limitation, we propose NExtLong, a novel framework for synthesizing\nlong-context data through Negative document Extension. NExtLong decomposes a\ndocument into multiple meta-chunks and extends the context by interleaving hard\nnegative distractors retrieved from pretraining corpora. This approach compels\nthe model to discriminate long-range dependent context from distracting\ncontent, enhancing its ability to model long-range dependencies. Extensive\nexperiments demonstrate that NExtLong achieves significant performance\nimprovements on the HELMET and RULER benchmarks compared to existing\nlong-context synthesis approaches and leading models, which are trained on\nnon-synthetic long documents. These findings highlight NExtLong's ability to\nreduce reliance on non-synthetic long documents, making it an effective\nframework for developing advanced long-context LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Corresponding authors: xing wu, and songlin hu",
    "pdf_url": "http://arxiv.org/pdf/2501.12766v1",
    "published_date": "2025-01-22 10:01:54 UTC",
    "updated_date": "2025-01-22 10:01:54 UTC"
  },
  {
    "arxiv_id": "2501.12749v1",
    "title": "Estimating the Conformal Prediction Threshold from Noisy Labels",
    "authors": [
      "Coby Penso",
      "Jacob Goldberger",
      "Ethan Fetaya"
    ],
    "abstract": "Conformal Prediction (CP) is a method to control prediction uncertainty by\nproducing a small prediction set, ensuring a predetermined probability that the\ntrue class lies within this set. This is commonly done by defining a score,\nbased on the model predictions, and setting a threshold on this score using a\nvalidation set. In this study, we address the problem of CP calibration when we\nonly have access to a validation set with noisy labels. We show how we can\nestimate the noise-free conformal threshold based on the noisy labeled data.\nOur solution is flexible and can accommodate various modeling assumptions\nregarding the label contamination process, without needing any information\nabout the underlying data distribution or the internal mechanisms of the\nmachine learning classifier. We develop a coverage guarantee for uniform noise\nthat is effective even in tasks with a large number of classes. We dub our\napproach Noise-Aware Conformal Prediction (NACP) and show on several natural\nand medical image classification datasets, including ImageNet, that it\nsignificantly outperforms current noisy label methods and achieves results\ncomparable to those obtained with a clean validation set.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12749v1",
    "published_date": "2025-01-22 09:35:58 UTC",
    "updated_date": "2025-01-22 09:35:58 UTC"
  },
  {
    "arxiv_id": "2501.13136v1",
    "title": "Forecasting of Bitcoin Prices Using Hashrate Features: Wavelet and Deep Stacking Approach",
    "authors": [
      "Ramin Mousa",
      "Meysam Afrookhteh",
      "Hooman Khaloo",
      "Amir Ali Bengari",
      "Gholamreza Heidary"
    ],
    "abstract": "Digital currencies have become popular in the last decade due to their\nnon-dependency and decentralized nature. The price of these currencies has seen\na lot of fluctuations at times, which has increased the need for prediction. As\ntheir most popular, Bitcoin(BTC) has become a research hotspot. The main\nchallenge and trend of digital currencies, especially BTC, is price\nfluctuations, which require studying the basic price prediction model. This\nresearch presents a classification and regression model based on stack deep\nlearning that uses a wavelet to remove noise to predict movements and prices of\nBTC at different time intervals. The proposed model based on the stacking\ntechnique uses models based on deep learning, especially neural networks and\ntransformers, for one, seven, thirty and ninety-day forecasting. Three feature\nselection models, Chi2, RFE and Embedded, were also applied to the data in the\npre-processing stage. The classification model achieved 63\\% accuracy for\npredicting the next day and 64\\%, 67\\% and 82\\% for predicting the seventh,\nthirty and ninety days, respectively. For daily price forecasting, the\npercentage error was reduced to 0.58, while the error ranged from 2.72\\% to\n2.85\\% for seven- to ninety-day horizons. These results show that the proposed\nmodel performed better than other models in the literature.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "arXiv admin note: text overlap with arXiv:2402.05943 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2501.13136v1",
    "published_date": "2025-01-22 09:31:00 UTC",
    "updated_date": "2025-01-22 09:31:00 UTC"
  },
  {
    "arxiv_id": "2501.12746v4",
    "title": "EvidenceMap: Learning Evidence Analysis to Unleash the Power of Small Language Models for Biomedical Question Answering",
    "authors": [
      "Chang Zong",
      "Jian Wan",
      "Siliang Tang",
      "Lei Zhang"
    ],
    "abstract": "When addressing professional questions in the biomedical domain, humans\ntypically acquire multiple pieces of information as evidence and engage in\nmultifaceted analysis to provide high-quality answers. Current LLM-based\nquestion answering methods lack a detailed definition and learning process for\nevidence analysis, leading to the risk of error propagation and hallucinations\nwhile using evidence. Although increasing the parameter size of LLMs can\nalleviate these issues, it also presents challenges in training and deployment\nwith limited resources. In this study, we propose EvidenceMap, which aims to\nenable a tiny pre-trained language model to explicitly learn multiple aspects\nof biomedical evidence, including supportive evaluation, logical correlation\nand content summarization, thereby latently guiding a small generative model\n(around 3B parameters) to provide textual responses. Experimental results\ndemonstrate that our method, learning evidence analysis by fine-tuning a model\nwith only 66M parameters, exceeds the RAG method with an 8B LLM by 19.9% and\n5.7% in reference-based quality and accuracy, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12746v4",
    "published_date": "2025-01-22 09:27:11 UTC",
    "updated_date": "2025-02-14 01:02:04 UTC"
  },
  {
    "arxiv_id": "2501.12728v1",
    "title": "A Call for Critically Rethinking and Reforming Data Analysis in Empirical Software Engineering",
    "authors": [
      "Matteo Esposito",
      "Mikel Robredo",
      "Murali Sridharan",
      "Guilherme Horta Travassos",
      "Rafael Peñaloza",
      "Valentina Lenarduzzi"
    ],
    "abstract": "Context: Empirical Software Engineering (ESE) drives innovation in SE through\nqualitative and quantitative studies. However, concerns about the correct\napplication of empirical methodologies have existed since the 2006 Dagstuhl\nseminar on SE. Objective: To analyze three decades of SE research, identify\nmistakes in statistical methods, and evaluate experts' ability to detect and\naddress these issues. Methods: We conducted a literature survey of ~27,000\nempirical studies, using LLMs to classify statistical methodologies as adequate\nor inadequate. Additionally, we selected 30 primary studies and held a workshop\nwith 33 ESE experts to assess their ability to identify and resolve statistical\nissues. Results: Significant statistical issues were found in the primary\nstudies, and experts showed limited ability to detect and correct these\nmethodological problems, raising concerns about the broader ESE community's\nproficiency in this area. Conclusions. Despite our study's eventual\nlimitations, its results shed light on recurring issues from promoting\ninformation copy-and-paste from past authors' works and the continuous\npublication of inadequate approaches that promote dubious results and\njeopardize the spread of the correct statistical strategies among researchers.\nBesides, it justifies further investigation into empirical rigor in software\nengineering to expose these recurring issues and establish a framework for\nreassessing our field's foundation of statistical methodology application.\nTherefore, this work calls for critically rethinking and reforming data\nanalysis in empirical software engineering, paving the way for our work soon.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12728v1",
    "published_date": "2025-01-22 09:05:01 UTC",
    "updated_date": "2025-01-22 09:05:01 UTC"
  },
  {
    "arxiv_id": "2501.13135v1",
    "title": "Applications and Challenges of AI and Microscopy in Life Science Research: A Review",
    "authors": [
      "Himanshu Buckchash",
      "Gyanendra Kumar Verma",
      "Dilip K. Prasad"
    ],
    "abstract": "The complexity of human biology and its intricate systems holds immense\npotential for advancing human health, disease treatment, and scientific\ndiscovery. However, traditional manual methods for studying biological\ninteractions are often constrained by the sheer volume and complexity of\nbiological data. Artificial Intelligence (AI), with its proven ability to\nanalyze vast datasets, offers a transformative approach to addressing these\nchallenges. This paper explores the intersection of AI and microscopy in life\nsciences, emphasizing their potential applications and associated challenges.\nWe provide a detailed review of how various biological systems can benefit from\nAI, highlighting the types of data and labeling requirements unique to this\ndomain. Particular attention is given to microscopy data, exploring the\nspecific AI techniques required to process and interpret this information. By\naddressing challenges such as data heterogeneity and annotation scarcity, we\noutline potential solutions and emerging trends in the field. Written primarily\nfrom an AI perspective, this paper aims to serve as a valuable resource for\nresearchers working at the intersection of AI, microscopy, and biology. It\nsummarizes current advancements, key insights, and open problems, fostering an\nunderstanding that encourages interdisciplinary collaborations. By offering a\ncomprehensive yet concise synthesis of the field, this paper aspires to\ncatalyze innovation, promote cross-disciplinary engagement, and accelerate the\nadoption of AI in life science research.",
    "categories": [
      "q-bio.OT",
      "cs.AI",
      "physics.med-ph",
      "q-bio.SC"
    ],
    "primary_category": "q-bio.OT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13135v1",
    "published_date": "2025-01-22 08:32:36 UTC",
    "updated_date": "2025-01-22 08:32:36 UTC"
  },
  {
    "arxiv_id": "2501.12709v1",
    "title": "Practical quantum federated learning and its experimental demonstration",
    "authors": [
      "Zhi-Ping Liu",
      "Xiao-Yu Cao",
      "Hao-Wen Liu",
      "Xiao-Ran Sun",
      "Yu Bao",
      "Yu-Shuo Lu",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "abstract": "Federated learning is essential for decentralized, privacy-preserving model\ntraining in the data-driven era. Quantum-enhanced federated learning leverages\nquantum resources to address privacy and scalability challenges, offering\nsecurity and efficiency advantages beyond classical methods. However, practical\nand scalable frameworks addressing privacy concerns in the quantum computing\nera remain undeveloped. Here, we propose a practical quantum federated learning\nframework on quantum networks, utilizing distributed quantum secret keys to\nprotect local model updates and enable secure aggregation with\ninformation-theoretic security. We experimentally validate our framework on a\n4-client quantum network with a scalable structure. Extensive numerical\nexperiments on both quantum and classical datasets show that adding a quantum\nclient significantly enhances the trained global model's ability to classify\nmultipartite entangled and non-stabilizer quantum datasets. Simulations further\ndemonstrate scalability to 200 clients with classical models trained on the\nMNIST dataset, reducing communication costs by $75\\%$ through advanced model\ncompression techniques and achieving rapid training convergence. Our work\nprovides critical insights for building scalable, efficient, and quantum-secure\nmachine learning systems for the coming quantum internet era.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "quant-ph",
    "comment": "21 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.12709v1",
    "published_date": "2025-01-22 08:28:11 UTC",
    "updated_date": "2025-01-22 08:28:11 UTC"
  },
  {
    "arxiv_id": "2501.12703v1",
    "title": "HEPPO: Hardware-Efficient Proximal Policy Optimization -- A Universal Pipelined Architecture for Generalized Advantage Estimation",
    "authors": [
      "Hazem Taha",
      "Ameer M. S. Abdelhadi"
    ],
    "abstract": "This paper introduces HEPPO, an FPGA-based accelerator designed to optimize\nthe Generalized Advantage Estimation (GAE) stage in Proximal Policy\nOptimization (PPO). Unlike previous approaches that focused on trajectory\ncollection and actor-critic updates, HEPPO addresses GAE's computational\ndemands with a parallel, pipelined architecture implemented on a single\nSystem-on-Chip (SoC). This design allows for the adaptation of various hardware\naccelerators tailored for different PPO phases. A key innovation is our\nstrategic standardization technique, which combines dynamic reward\nstandardization and block standardization for values, followed by 8-bit uniform\nquantization. This method stabilizes learning, enhances performance, and\nmanages memory bottlenecks, achieving a 4x reduction in memory usage and a 1.5x\nincrease in cumulative rewards. We propose a solution on a single SoC device\nwith programmable logic and embedded processors, delivering throughput orders\nof magnitude higher than traditional CPU-GPU systems. Our single-chip solution\nminimizes communication latency and throughput bottlenecks, significantly\nboosting PPO training efficiency. Experimental results show a 30% increase in\nPPO speed and a substantial reduction in memory access time, underscoring\nHEPPO's potential for broad applicability in hardware-efficient reinforcement\nlearning algorithms.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "B.2; B.3; B.5; B.6; B.7; C.1; C.3; I.2"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted at the 2024 International Conference on Field Programmable\n  Technology (ICFPT 2023)",
    "pdf_url": "http://arxiv.org/pdf/2501.12703v1",
    "published_date": "2025-01-22 08:18:56 UTC",
    "updated_date": "2025-01-22 08:18:56 UTC"
  },
  {
    "arxiv_id": "2501.12690v2",
    "title": "Growth strategies for arbitrary DAG neural architectures",
    "authors": [
      "Stella Douka",
      "Manon Verbockhaven",
      "Théo Rudkiewicz",
      "Stéphane Rivaud",
      "François P. Landes",
      "Sylvain Chevallier",
      "Guillaume Charpiat"
    ],
    "abstract": "Deep learning has shown impressive results obtained at the cost of training\nhuge neural networks. However, the larger the architecture, the higher the\ncomputational, financial, and environmental costs during training and\ninference. We aim at reducing both training and inference durations. We focus\non Neural Architecture Growth, which can increase the size of a small model\nwhen needed, directly during training using information from the\nbackpropagation. We expand existing work and freely grow neural networks in the\nform of any Directed Acyclic Graph by reducing expressivity bottlenecks in the\narchitecture. We explore strategies to reduce excessive computations and steer\nnetwork growth toward more parameter-efficient architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12690v2",
    "published_date": "2025-01-22 08:02:01 UTC",
    "updated_date": "2025-02-14 08:28:29 UTC"
  },
  {
    "arxiv_id": "2501.13133v1",
    "title": "Graph Representation Learning with Diffusion Generative Models",
    "authors": [
      "Daniel Wesego"
    ],
    "abstract": "Diffusion models have established themselves as state-of-the-art generative\nmodels across various data modalities, including images and videos, due to\ntheir ability to accurately approximate complex data distributions. Unlike\ntraditional generative approaches such as VAEs and GANs, diffusion models\nemploy a progressive denoising process that transforms noise into meaningful\ndata over multiple iterative steps. This gradual approach enhances their\nexpressiveness and generation quality. Not only that, diffusion models have\nalso been shown to extract meaningful representations from data while learning\nto generate samples. Despite their success, the application of diffusion models\nto graph-structured data remains relatively unexplored, primarily due to the\ndiscrete nature of graphs, which necessitates discrete diffusion processes\ndistinct from the continuous methods used in other domains. In this work, we\nleverage the representational capabilities of diffusion models to learn\nmeaningful embeddings for graph data. By training a discrete diffusion model\nwithin an autoencoder framework, we enable both effective autoencoding and\nrepresentation learning tailored to the unique characteristics of\ngraph-structured data. We only need the encoder at the end to extract\nrepresentations. Our approach demonstrates the potential of discrete diffusion\nmodels to be used for graph representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13133v1",
    "published_date": "2025-01-22 07:12:10 UTC",
    "updated_date": "2025-01-22 07:12:10 UTC"
  },
  {
    "arxiv_id": "2501.13967v2",
    "title": "FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis",
    "authors": [
      "Haoxuan Che",
      "Yifei Wu",
      "Haibo Jin",
      "Yong Xia",
      "Hao Chen"
    ],
    "abstract": "Federated domain generalization aims to train a global model from multiple\nsource domains and ensure its generalization ability to unseen target domains.\nDue to the target domain being with unknown domain shifts, attempting to\napproximate these gaps by source domains may be the key to improving model\ngeneralization capability. Existing works mainly focus on sharing and\nrecombining local domain-specific attributes to increase data diversity and\nsimulate potential domain shifts. However, these methods may be insufficient\nsince only the local attribute recombination can be hard to touch the\nout-of-distribution of global data. In this paper, we propose a\nsimple-yet-efficient framework named Federated Domain Adversarial Generation\n(FedDAG). It aims to simulate the domain shift and improve the model\ngeneralization by adversarially generating novel domains different from local\nand global source domains. Specifically, it generates novel-style images by\nmaximizing the instance-level feature discrepancy between original and\ngenerated images and trains a generalizable task model by minimizing their\nfeature discrepancy. Further, we observed that FedDAG could cause different\nperformance improvements for local models. It may be due to inherent data\nisolation and heterogeneity among clients, exacerbating the imbalance in their\ngeneralization contributions to the global model. Ignoring this imbalance can\nlead the global model's generalization ability to be sub-optimal, further\nlimiting the novel domain generation procedure. Thus, to mitigate this\nimbalance, FedDAG hierarchically aggregates local models at the within-client\nand across-client levels by using the sharpness concept to evaluate client\nmodel generalization contributions. Extensive experiments across four medical\nbenchmarks demonstrate FedDAG's ability to enhance generalization in federated\nmedical scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13967v2",
    "published_date": "2025-01-22 07:08:45 UTC",
    "updated_date": "2025-01-27 07:48:49 UTC"
  },
  {
    "arxiv_id": "2501.16365v1",
    "title": "CAND: Cross-Domain Ambiguity Inference for Early Detecting Nuanced Illness Deterioration",
    "authors": [
      "Lo Pang-Yun Ting",
      "Zhen Tan",
      "Hong-Pei Chen",
      "Cheng-Te Li",
      "Po-Lin Chen",
      "Kun-Ta Chuang",
      "Huan Liu"
    ],
    "abstract": "Early detection of patient deterioration is essential for timely treatment,\nwith vital signs like heart rates being key health indicators. Existing methods\ntend to solely analyze vital sign waveforms, ignoring transition relationships\nof waveforms within each vital sign and the correlation strengths among various\nvital signs. Such studies often overlook nuanced illness deterioration, which\nis the early sign of worsening health but is difficult to detect. In this\npaper, we introduce CAND, a novel method that organizes the transition\nrelationships and the correlations within and among vital signs as\ndomain-specific and cross-domain knowledge. CAND jointly models these knowledge\nin a unified representation space, considerably enhancing the early detection\nof nuanced illness deterioration. In addition, CAND integrates a Bayesian\ninference method that utilizes augmented knowledge from domain-specific and\ncross-domain knowledge to address the ambiguities in correlation strengths.\nWith this architecture, the correlation strengths can be effectively inferred\nto guide joint modeling and enhance representations of vital signs. This allows\na more holistic and accurate interpretation of patient health. Our experiments\non a real-world ICU dataset demonstrate that CAND significantly outperforms\nexisting methods in both effectiveness and earliness in detecting nuanced\nillness deterioration. Moreover, we conduct a case study for the interpretable\ndetection process to showcase the practicality of CAND.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16365v1",
    "published_date": "2025-01-22 06:44:43 UTC",
    "updated_date": "2025-01-22 06:44:43 UTC"
  },
  {
    "arxiv_id": "2502.10406v1",
    "title": "FishBargain: An LLM-Empowered Bargaining Agent for Online Fleamarket Platform Sellers",
    "authors": [
      "Dexin Kong",
      "Xu Yan",
      "Ming Chen",
      "Shuguang Han",
      "Jufeng Chen",
      "Fei Huang"
    ],
    "abstract": "Different from traditional Business-to-Consumer e-commerce platforms~(e.g.,\nAmazon), online fleamarket platforms~(e.g., Craigslist) mainly focus on\nindividual sellers who are lack of time investment and business proficiency.\nIndividual sellers often struggle with the bargaining process and thus the deal\nis unaccomplished. Recent advancements in Large Language Models(LLMs)\ndemonstrate huge potential in various dialogue tasks, but those tasks are\nmainly in the form of passively following user's instruction. Bargaining, as a\nform of proactive dialogue task, represents a distinct art of dialogue\nconsidering the dynamism of environment and uncertainty of adversary\nstrategies. In this paper, we propose an LLM-empowered bargaining agent\ndesigned for online fleamarket platform sellers, named as FishBargain.\nSpecifically, FishBargain understands the chat context and product information,\nchooses both action and language skill considering possible adversary actions\nand generates utterances. FishBargain has been tested by thousands of\nindividual sellers on one of the largest online fleamarket platforms~(Xianyu)\nin China. Both qualitative and quantitative experiments demonstrate that\nFishBargain can effectively help sellers make more deals.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10406v1",
    "published_date": "2025-01-22 06:12:25 UTC",
    "updated_date": "2025-01-22 06:12:25 UTC"
  },
  {
    "arxiv_id": "2501.12668v3",
    "title": "NBDI: A Simple and Effective Termination Condition for Skill Extraction from Task-Agnostic Demonstrations",
    "authors": [
      "Myunsoo Kim",
      "Hayeong Lee",
      "Seong-Woong Shim",
      "JunHo Seo",
      "Byung-Jun Lee"
    ],
    "abstract": "Intelligent agents are able to make decisions based on different levels of\ngranularity and duration. Recent advances in skill learning enabled the agent\nto solve complex, long-horizon tasks by effectively guiding the agent in\nchoosing appropriate skills. However, the practice of using fixed-length skills\ncan easily result in skipping valuable decision points, which ultimately limits\nthe potential for further exploration and faster policy learning. In this work,\nwe propose to learn a simple and effective termination condition that\nidentifies decision points through a state-action novelty module that leverages\nagent experience data. Our approach, Novelty-based Decision Point\nIdentification (NBDI), outperforms previous baselines in complex, long-horizon\ntasks, and remains effective even in the presence of significant variations in\nthe environment configurations of downstream tasks, highlighting the importance\nof decision point identification in skill learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12668v3",
    "published_date": "2025-01-22 06:08:15 UTC",
    "updated_date": "2025-05-20 04:44:56 UTC"
  },
  {
    "arxiv_id": "2502.17443v1",
    "title": "AI Agentic workflows and Enterprise APIs: Adapting API architectures for the age of AI agents",
    "authors": [
      "Vaibhav Tupe",
      "Shrinath Thube"
    ],
    "abstract": "The rapid advancement of Generative AI has catalyzed the emergence of\nautonomous AI agents, presenting unprecedented challenges for enterprise\ncomputing infrastructures. Current enterprise API architectures are\npredominantly designed for human-driven, predefined interaction patterns,\nrendering them ill-equipped to support intelligent agents' dynamic,\ngoal-oriented behaviors. This research systematically examines the\narchitectural adaptations for enterprise APIs to support AI agentic workflows\neffectively. Through a comprehensive analysis of existing API design paradigms,\nagent interaction models, and emerging technological constraints, the paper\ndevelops a strategic framework for API transformation. The study employs a\nmixed-method approach, combining theoretical modeling, comparative analysis,\nand exploratory design principles to address critical challenges in\nstandardization, performance, and intelligent interaction. The proposed\nresearch contributes a conceptual model for next-generation enterprise APIs\nthat can seamlessly integrate with autonomous AI agent ecosystems, offering\nsignificant implications for future enterprise computing architectures.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2.0; D.2.11; D.2.12; K.6.5; I.2.11"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17443v1",
    "published_date": "2025-01-22 05:55:16 UTC",
    "updated_date": "2025-01-22 05:55:16 UTC"
  },
  {
    "arxiv_id": "2501.16364v1",
    "title": "Multivariate Time Series Anomaly Detection by Capturing Coarse-Grained Intra- and Inter-Variate Dependencies",
    "authors": [
      "Yongzheng Xie",
      "Hongyu Zhang",
      "Muhammad Ali Babar"
    ],
    "abstract": "Multivariate time series anomaly detection is essential for failure\nmanagement in web application operations, as it directly influences the\neffectiveness and timeliness of implementing remedial or preventive measures.\nThis task is often framed as a semi-supervised learning problem, where only\nnormal data are available for model training, primarily due to the\nlabor-intensive nature of data labeling and the scarcity of anomalous data.\nExisting semi-supervised methods often detect anomalies by capturing\nintra-variate temporal dependencies and/or inter-variate relationships to learn\nnormal patterns, flagging timestamps that deviate from these patterns as\nanomalies. However, these approaches often fail to capture salient\nintra-variate temporal and inter-variate dependencies in time series due to\ntheir focus on excessively fine granularity, leading to suboptimal performance.\nIn this study, we introduce MtsCID, a novel semi-supervised multivariate time\nseries anomaly detection method. MtsCID employs a dual network architecture:\none network operates on the attention maps of multi-scale intra-variate patches\nfor coarse-grained temporal dependency learning, while the other works on\nvariates to capture coarse-grained inter-variate relationships through\nconvolution and interaction with sinusoidal prototypes. This design enhances\nthe ability to capture the patterns from both intra-variate temporal\ndependencies and inter-variate relationships, resulting in improved\nperformance. Extensive experiments across seven widely used datasets\ndemonstrate that MtsCID achieves performance comparable or superior to\nstate-of-the-art benchmark methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures, Accepted to TheWebConference 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.16364v1",
    "published_date": "2025-01-22 05:53:12 UTC",
    "updated_date": "2025-01-22 05:53:12 UTC"
  },
  {
    "arxiv_id": "2501.12651v1",
    "title": "The potential -- and the pitfalls -- of using pre-trained language models as cognitive science theories",
    "authors": [
      "Raj Sanjay Shah",
      "Sashank Varma"
    ],
    "abstract": "Many studies have evaluated the cognitive alignment of Pre-trained Language\nModels (PLMs), i.e., their correspondence to adult performance across a range\nof cognitive domains. Recently, the focus has expanded to the developmental\nalignment of these models: identifying phases during training where\nimprovements in model performance track improvements in children's thinking\nover development. However, there are many challenges to the use of PLMs as\ncognitive science theories, including different architectures, different\ntraining data modalities and scales, and limited model interpretability. In\nthis paper, we distill lessons learned from treating PLMs, not as engineering\nartifacts but as cognitive science and developmental science models. We review\nassumptions used by researchers to map measures of PLM performance to measures\nof human performance. We identify potential pitfalls of this approach to\nunderstanding human thinking, and we end by enumerating criteria for using PLMs\nas credible accounts of cognition and cognitive development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12651v1",
    "published_date": "2025-01-22 05:24:23 UTC",
    "updated_date": "2025-01-22 05:24:23 UTC"
  },
  {
    "arxiv_id": "2501.12640v1",
    "title": "Dynamics of Toxicity in Political Podcasts",
    "authors": [
      "Naquee Rizwan",
      "Nayandeep Deb",
      "Sarthak Roy",
      "Vishwajeet Singh Solanki",
      "Kiran Garimella",
      "Animesh Mukherjee"
    ],
    "abstract": "Toxicity in digital media poses significant challenges, yet little attention\nhas been given to its dynamics within the rapidly growing medium of podcasts.\nThis paper addresses this gap by analyzing political podcast data to study the\nemergence and propagation of toxicity, focusing on conversation\nchains-structured reply patterns within podcast transcripts. Leveraging\nstate-of-the-art transcription models and advanced conversational analysis\ntechniques, we systematically examine toxic discourse in over 30 popular\npolitical podcasts in the United States. Our key contributions include: (1)\ncreating a comprehensive dataset of transcribed and diarized political\npodcasts, identifying thousands of toxic instances using Google's Perspective\nAPI, (2) uncovering concerning trends where a majority of episodes contain at\nleast one toxic instance, (3) introducing toxic conversation chains and\nanalyzing their structural and linguistic properties, revealing characteristics\nsuch as longer durations, repetitive patterns, figurative language, and\nemotional cues tied to anger and annoyance, (4) identifying demand-related\nwords like 'want', 'like', and 'know' as precursors to toxicity, and (5)\ndeveloping predictive models to anticipate toxicity shifts based on annotated\nchange points. Our findings provide critical insights into podcast toxicity and\nestablish a foundation for future research on real-time monitoring and\nintervention mechanisms to foster healthier discourse in this influential\nmedium.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12640v1",
    "published_date": "2025-01-22 04:58:50 UTC",
    "updated_date": "2025-01-22 04:58:50 UTC"
  },
  {
    "arxiv_id": "2501.12633v1",
    "title": "Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors",
    "authors": [
      "Jingyang Ke",
      "Feiyang Wu",
      "Jiyi Wang",
      "Jeffrey Markowitz",
      "Anqi Wu"
    ],
    "abstract": "Traditional approaches to studying decision-making in neuroscience focus on\nsimplified behavioral tasks where animals perform repetitive, stereotyped\nactions to receive explicit rewards. While informative, these methods constrain\nour understanding of decision-making to short timescale behaviors driven by\nexplicit goals. In natural environments, animals exhibit more complex,\nlong-term behaviors driven by intrinsic motivations that are often\nunobservable. Recent works in time-varying inverse reinforcement learning (IRL)\naim to capture shifting motivations in long-term, freely moving behaviors.\nHowever, a crucial challenge remains: animals make decisions based on their\nhistory, not just their current state. To address this, we introduce SWIRL\n(SWitching IRL), a novel framework that extends traditional IRL by\nincorporating time-varying, history-dependent reward functions. SWIRL models\nlong behavioral sequences as transitions between short-term decision-making\nprocesses, each governed by a unique reward function. SWIRL incorporates\nbiologically plausible history dependency to capture how past decisions and\nenvironmental contexts shape behavior, offering a more accurate description of\nanimal decision-making. We apply SWIRL to simulated and real-world animal\nbehavior datasets and show that it outperforms models lacking history\ndependency, both quantitatively and qualitatively. This work presents the first\nIRL model to incorporate history-dependent policies and rewards to advance our\nunderstanding of complex, naturalistic decision-making in animals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12633v1",
    "published_date": "2025-01-22 04:38:33 UTC",
    "updated_date": "2025-01-22 04:38:33 UTC"
  },
  {
    "arxiv_id": "2501.12622v1",
    "title": "Towards Robust Multi-tab Website Fingerprinting",
    "authors": [
      "Xinhao Deng",
      "Xiyuan Zhao",
      "Qilei Yin",
      "Zhuotao Liu",
      "Qi Li",
      "Mingwei Xu",
      "Ke Xu",
      "Jianping Wu"
    ],
    "abstract": "Website fingerprinting enables an eavesdropper to determine which websites a\nuser is visiting over an encrypted connection. State-of-the-art website\nfingerprinting (WF) attacks have demonstrated effectiveness even against\nTor-protected network traffic. However, existing WF attacks have critical\nlimitations on accurately identifying websites in multi-tab browsing sessions,\nwhere the holistic pattern of individual websites is no longer preserved, and\nthe number of tabs opened by a client is unknown a priori. In this paper, we\npropose ARES, a novel WF framework natively designed for multi-tab WF attacks.\nARES formulates the multi-tab attack as a multi-label classification problem\nand solves it using the novel Transformer-based models. Specifically, ARES\nextracts local patterns based on multi-level traffic aggregation features and\nutilizes the improved self-attention mechanism to analyze the correlations\nbetween these local patterns, effectively identifying websites. We implement a\nprototype of ARES and extensively evaluate its effectiveness using our\nlarge-scale datasets collected over multiple months. The experimental results\nillustrate that ARES achieves optimal performance in several realistic\nscenarios. Further, ARES remains robust even against various WF defenses.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12622v1",
    "published_date": "2025-01-22 04:10:53 UTC",
    "updated_date": "2025-01-22 04:10:53 UTC"
  },
  {
    "arxiv_id": "2501.12620v1",
    "title": "Adaptive Data Exploitation in Deep Reinforcement Learning",
    "authors": [
      "Mingqi Yuan",
      "Bo Li",
      "Xin Jin",
      "Wenjun Zeng"
    ],
    "abstract": "We introduce ADEPT: Adaptive Data ExPloiTation, a simple yet powerful\nframework to enhance the **data efficiency** and **generalization** in deep\nreinforcement learning (RL). Specifically, ADEPT adaptively manages the use of\nsampled data across different learning stages via multi-armed bandit (MAB)\nalgorithms, optimizing data utilization while mitigating overfitting. Moreover,\nADEPT can significantly reduce the computational overhead and accelerate a wide\nrange of RL algorithms. We test ADEPT on benchmarks including Procgen,\nMiniGrid, and PyBullet. Extensive simulation demonstrates that ADEPT can\nachieve superior performance with remarkable computational efficiency, offering\na practical solution to data-efficient RL. Our code is available at\nhttps://github.com/yuanmingqi/ADEPT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "40 pages, 37 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12620v1",
    "published_date": "2025-01-22 04:01:17 UTC",
    "updated_date": "2025-01-22 04:01:17 UTC"
  },
  {
    "arxiv_id": "2501.12617v1",
    "title": "Deep Learning-Based Identification of Inconsistent Method Names: How Far Are We?",
    "authors": [
      "Taiming Wang",
      "Yuxia Zhang",
      "Lin Jiang",
      "Yi Tang",
      "Guangjie Li",
      "Hui Liu"
    ],
    "abstract": "Concise and meaningful method names are crucial for program comprehension and\nmaintenance. However, method names may become inconsistent with their\ncorresponding implementations, causing confusion and errors. Several deep\nlearning (DL)-based approaches have been proposed to identify such\ninconsistencies, with initial evaluations showing promising results. However,\nthese evaluations typically use a balanced dataset, where the number of\ninconsistent and consistent names are equal. This setup, along with flawed\ndataset construction, leads to false positives, making reported performance\nless reliable in real-world scenarios, where most method names are consistent.\nIn this paper, we present an empirical study that evaluates state-of-the-art\nDL-based methods for identifying inconsistent method names. We create a new\nbenchmark by combining automatic identification from commit histories and\nmanual developer inspections, reducing false positives. We evaluate five\nrepresentative DL approaches (one retrieval-based and four generation-based) on\nthis benchmark. Our results show that performance drops substantially when\nmoving from the balanced dataset to the new benchmark. We further conduct\nquantitative and qualitative analyses to understand the strengths and\nweaknesses of the approaches. Retrieval-based methods perform well on simple\nmethods and those with popular name sub-tokens but fail due to inefficient\nrepresentation techniques. Generation-based methods struggle with inaccurate\nsimilarity calculations and immature name generation. Based on these findings,\nwe propose improvements using contrastive learning and large language models\n(LLMs). Our study suggests that significant improvements are needed before\nthese DL approaches can be effectively applied to real-world software systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12617v1",
    "published_date": "2025-01-22 03:51:56 UTC",
    "updated_date": "2025-01-22 03:51:56 UTC"
  },
  {
    "arxiv_id": "2501.17171v1",
    "title": "Separated Inter/Intra-Modal Fusion Prompts for Compositional Zero-Shot Learning",
    "authors": [
      "Sua Jung"
    ],
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize subtle differences\nin meaning or the combination of states and objects through the use of known\nand unknown concepts during training. Existing methods either focused on prompt\nconfiguration or on using prompts to tune the pre-trained Vision-Language\nmodel. However, these methods faced challenges in accurately identifying subtle\ndifferences in meaning or combining states with objects. To jointly eradicate\nthe above issues and construct an efficient and effective CZSL technique, we\nsuggest a method to improve attribute recognition performance by utilizing\ndiverse Prompt Learning with an Inter/Intra-Modality Fusion Synthesizer in\nscene understanding involving subtle semantic differences and multiple objects.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "AIAP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17171v1",
    "published_date": "2025-01-22 03:49:12 UTC",
    "updated_date": "2025-01-22 03:49:12 UTC"
  },
  {
    "arxiv_id": "2501.12615v1",
    "title": "GATE: Adaptive Learning with Working Memory by Information Gating in Multi-lamellar Hippocampal Formation",
    "authors": [
      "Yuechen Liu",
      "Zishun Wang",
      "Chen Qiao",
      "Zongben Xu"
    ],
    "abstract": "Hippocampal formation (HF) can rapidly adapt to varied environments and build\nflexible working memory (WM). To mirror the HF's mechanism on generalization\nand WM, we propose a model named Generalization and Associative Temporary\nEncoding (GATE), which deploys a 3-D multi-lamellar dorsoventral (DV)\narchitecture, and learns to build up internally representation from externally\ndriven information layer-wisely. In each lamella, regions of HF:\nEC3-CA1-EC5-EC3 forms a re-entrant loop that discriminately maintains\ninformation by EC3 persistent activity, and selectively readouts the retained\ninformation by CA1 neurons. CA3 and EC5 further provides gating function that\ncontrols these processes. After learning complex WM tasks, GATE forms neuron\nrepresentations that align with experimental records, including splitter, lap,\nevidence, trace, delay-active cells, as well as conventional place cells.\nCrucially, DV architecture in GATE also captures information, range from\ndetailed to abstract, which enables a rapid generalization ability when cue,\nenvironment or task changes, with learned representations inherited. GATE\npromises a viable framework for understanding the HF's flexible memory\nmechanisms and for progressively developing brain-inspired intelligent systems.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12615v1",
    "published_date": "2025-01-22 03:41:35 UTC",
    "updated_date": "2025-01-22 03:41:35 UTC"
  },
  {
    "arxiv_id": "2501.12599v2",
    "title": "Kimi k1.5: Scaling Reinforcement Learning with LLMs",
    "authors": [
      "Kimi Team",
      "Angang Du",
      "Bofei Gao",
      "Bowei Xing",
      "Changjiu Jiang",
      "Cheng Chen",
      "Cheng Li",
      "Chenjun Xiao",
      "Chenzhuang Du",
      "Chonghua Liao",
      "Chuning Tang",
      "Congcong Wang",
      "Dehao Zhang",
      "Enming Yuan",
      "Enzhe Lu",
      "Fengxiang Tang",
      "Flood Sung",
      "Guangda Wei",
      "Guokun Lai",
      "Haiqing Guo",
      "Han Zhu",
      "Hao Ding",
      "Hao Hu",
      "Hao Yang",
      "Hao Zhang",
      "Haotian Yao",
      "Haotian Zhao",
      "Haoyu Lu",
      "Haoze Li",
      "Haozhen Yu",
      "Hongcheng Gao",
      "Huabin Zheng",
      "Huan Yuan",
      "Jia Chen",
      "Jianhang Guo",
      "Jianlin Su",
      "Jianzhou Wang",
      "Jie Zhao",
      "Jin Zhang",
      "Jingyuan Liu",
      "Junjie Yan",
      "Junyan Wu",
      "Lidong Shi",
      "Ling Ye",
      "Longhui Yu",
      "Mengnan Dong",
      "Neo Zhang",
      "Ningchen Ma",
      "Qiwei Pan",
      "Qucheng Gong",
      "Shaowei Liu",
      "Shengling Ma",
      "Shupeng Wei",
      "Sihan Cao",
      "Siying Huang",
      "Tao Jiang",
      "Weihao Gao",
      "Weimin Xiong",
      "Weiran He",
      "Weixiao Huang",
      "Wenhao Wu",
      "Wenyang He",
      "Xianghui Wei",
      "Xianqing Jia",
      "Xingzhe Wu",
      "Xinran Xu",
      "Xinxing Zu",
      "Xinyu Zhou",
      "Xuehai Pan",
      "Y. Charles",
      "Yang Li",
      "Yangyang Hu",
      "Yangyang Liu",
      "Yanru Chen",
      "Yejie Wang",
      "Yibo Liu",
      "Yidao Qin",
      "Yifeng Liu",
      "Ying Yang",
      "Yiping Bao",
      "Yulun Du",
      "Yuxin Wu",
      "Yuzhi Wang",
      "Zaida Zhou",
      "Zhaoji Wang",
      "Zhaowei Li",
      "Zhen Zhu",
      "Zheng Zhang",
      "Zhexu Wang",
      "Zhilin Yang",
      "Zhiqi Huang",
      "Zihao Huang",
      "Ziyao Xu",
      "Zonghan Yang"
    ],
    "abstract": "Language model pretraining with next token prediction has proved effective\nfor scaling compute but is limited to the amount of available training data.\nScaling reinforcement learning (RL) unlocks a new axis for the continued\nimprovement of artificial intelligence, with the promise that large language\nmodels (LLMs) can scale their training data by learning to explore with\nrewards. However, prior published work has not produced competitive results. In\nlight of this, we report on the training practice of Kimi k1.5, our latest\nmulti-modal LLM trained with RL, including its RL training techniques,\nmulti-modal data recipes, and infrastructure optimization. Long context scaling\nand improved policy optimization methods are key ingredients of our approach,\nwhich establishes a simplistic, effective RL framework without relying on more\ncomplex techniques such as Monte Carlo tree search, value functions, and\nprocess reward models. Notably, our system achieves state-of-the-art reasoning\nperformance across multiple benchmarks and modalities -- e.g., 77.5 on AIME,\n96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista -- matching\nOpenAI's o1. Moreover, we present effective long2short methods that use\nlong-CoT techniques to improve short-CoT models, yielding state-of-the-art\nshort-CoT reasoning results -- e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on\nLiveCodeBench -- outperforming existing short-CoT models such as GPT-4o and\nClaude Sonnet 3.5 by a large margin (up to +550%).",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.12599v2",
    "published_date": "2025-01-22 02:48:14 UTC",
    "updated_date": "2025-03-05 02:16:32 UTC"
  },
  {
    "arxiv_id": "2501.12595v1",
    "title": "A Unified Invariant Learning Framework for Graph Classification",
    "authors": [
      "Yongduo Sui",
      "Jie Sun",
      "Shuyao Wang",
      "Zemin Liu",
      "Qing Cui",
      "Longfei Li",
      "Xiang Wang"
    ],
    "abstract": "Invariant learning demonstrates substantial potential for enhancing the\ngeneralization of graph neural networks (GNNs) with out-of-distribution (OOD)\ndata. It aims to recognize stable features in graph data for classification,\nbased on the premise that these features causally determine the target label,\nand their influence is invariant to changes in distribution. Along this line,\nmost studies have attempted to pinpoint these stable features by emphasizing\nexplicit substructures in the graph, such as masked or attentive subgraphs, and\nprimarily enforcing the invariance principle in the semantic space, i.e., graph\nrepresentations. However, we argue that focusing only on the semantic space may\nnot accurately identify these stable features. To address this, we introduce\nthe Unified Invariant Learning (UIL) framework for graph classification. It\nprovides a unified perspective on invariant graph learning, emphasizing both\nstructural and semantic invariance principles to identify more robust stable\nfeatures. In the graph space, UIL adheres to the structural invariance\nprinciple by reducing the distance between graphons over a set of stable\nfeatures across different environments. Simultaneously, to confirm semantic\ninvariance, UIL underscores that the acquired graph representations should\ndemonstrate exemplary performance across diverse environments. We present both\ntheoretical and empirical evidence to confirm our method's ability to recognize\nsuperior stable features. Moreover, through a series of comprehensive\nexperiments complemented by in-depth analyses, we demonstrate that UIL\nconsiderably enhances OOD generalization, surpassing the performance of leading\nbaseline methods. Our codes are available at https://github.com/yongduosui/UIL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12595v1",
    "published_date": "2025-01-22 02:45:21 UTC",
    "updated_date": "2025-01-22 02:45:21 UTC"
  },
  {
    "arxiv_id": "2501.13132v1",
    "title": "A Hierarchical Reinforcement Learning Framework for Multi-UAV Combat Using Leader-Follower Strategy",
    "authors": [
      "Jinhui Pang",
      "Jinglin He",
      "Noureldin Mohamed Abdelaal Ahmed Mohamed",
      "Changqing Lin",
      "Zhihui Zhang",
      "Xiaoshuai Hao"
    ],
    "abstract": "Multi-UAV air combat is a complex task involving multiple autonomous UAVs, an\nevolving field in both aerospace and artificial intelligence. This paper aims\nto enhance adversarial performance through collaborative strategies. Previous\napproaches predominantly discretize the action space into predefined actions,\nlimiting UAV maneuverability and complex strategy implementation. Others\nsimplify the problem to 1v1 combat, neglecting the cooperative dynamics among\nmultiple UAVs. To address the high-dimensional challenges inherent in\nsix-degree-of-freedom space and improve cooperation, we propose a hierarchical\nframework utilizing the Leader-Follower Multi-Agent Proximal Policy\nOptimization (LFMAPPO) strategy. Specifically, the framework is structured into\nthree levels. The top level conducts a macro-level assessment of the\nenvironment and guides execution policy. The middle level determines the angle\nof the desired action. The bottom level generates precise action commands for\nthe high-dimensional action space. Moreover, we optimize the state-value\nfunctions by assigning distinct roles with the leader-follower strategy to\ntrain the top-level policy, followers estimate the leader's utility, promoting\neffective cooperation among agents. Additionally, the incorporation of a target\nselector, aligned with the UAVs' posture, assesses the threat level of targets.\nFinally, simulation experiments validate the effectiveness of our proposed\nmethod.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13132v1",
    "published_date": "2025-01-22 02:41:36 UTC",
    "updated_date": "2025-01-22 02:41:36 UTC"
  },
  {
    "arxiv_id": "2503.15501v1",
    "title": "Development of an Inclusive Educational Platform Using Open Technologies and Machine Learning: A Case Study on Accessibility Enhancement",
    "authors": [
      "Jimi Togni"
    ],
    "abstract": "This study addresses the pressing challenge of educational inclusion for\nstudents with special needs by proposing and developing an inclusive\neducational platform. Integrating machine learning, natural language\nprocessing, and cross-platform interfaces, the platform features key\nfunctionalities such as speech recognition functionality to support voice\ncommands and text generation via voice input; real-time object recognition\nusing the YOLOv5 model, adapted for educational environments;\nGrapheme-to-Phoneme (G2P) conversion for Text-to-Speech systems using seq2seq\nmodels with attention, ensuring natural and fluent voice synthesis; and the\ndevelopment of a cross-platform mobile application in Flutter with on-device\ninference execution using TensorFlow Lite. The results demonstrated high\naccuracy, usability, and positive impact in educational scenarios, validating\nthe proposal as an effective tool for educational inclusion. This project\nunderscores the importance of open and accessible technologies in promoting\ninclusive and quality education.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "68T50",
      "I.2.7; D.2.3"
    ],
    "primary_category": "cs.HC",
    "comment": "14 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2503.15501v1",
    "published_date": "2025-01-22 02:38:23 UTC",
    "updated_date": "2025-01-22 02:38:23 UTC"
  },
  {
    "arxiv_id": "2501.12592v2",
    "title": "FedGrAINS: Personalized SubGraph Federated Learning with Adaptive Neighbor Sampling",
    "authors": [
      "Emir Ceyani",
      "Han Xie",
      "Baturalp Buyukates",
      "Carl Yang",
      "Salman Avestimehr"
    ],
    "abstract": "Graphs are crucial for modeling relational and biological data. As datasets\ngrow larger in real-world scenarios, the risk of exposing sensitive information\nincreases, making privacy-preserving training methods like federated learning\n(FL) essential to ensure data security and compliance with privacy regulations.\nRecently proposed personalized subgraph FL methods have become the de-facto\nstandard for training personalized Graph Neural Networks (GNNs) in a federated\nmanner while dealing with the missing links across clients' subgraphs due to\nprivacy restrictions. However, personalized subgraph FL faces significant\nchallenges due to the heterogeneity in client subgraphs, such as degree\ndistributions among the nodes, which complicate federated training of graph\nmodels. To address these challenges, we propose \\textit{FedGrAINS}, a novel\ndata-adaptive and sampling-based regularization method for subgraph FL.\nFedGrAINS leverages generative flow networks (GFlowNets) to evaluate node\nimportance concerning clients' tasks, dynamically adjusting the message-passing\nstep in clients' GNNs. This adaptation reflects task-optimized sampling aligned\nwith a trajectory balance objective. Experimental results demonstrate that the\ninclusion of \\textit{FedGrAINS} as a regularizer consistently improves the FL\nperformance compared to baselines that do not leverage such regularization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to SDM2025 (SIAM Data Mining 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.12592v2",
    "published_date": "2025-01-22 02:35:20 UTC",
    "updated_date": "2025-01-23 13:03:43 UTC"
  },
  {
    "arxiv_id": "2501.12573v1",
    "title": "Leveraging LLMs to Create a Haptic Devices' Recommendation System",
    "authors": [
      "Yang Liu",
      "Haiwei Dong",
      "Abdulmotaleb El Saddik"
    ],
    "abstract": "Haptic technology has seen significant growth, yet a lack of awareness of\nexisting haptic device design knowledge hinders development. This paper\naddresses these limitations by leveraging advancements in Large Language Models\n(LLMs) to develop a haptic agent, focusing specifically on Grounded Force\nFeedback (GFF) devices recommendation. Our approach involves automating the\ncreation of a structured haptic device database using information from research\npapers and product specifications. This database enables the recommendation of\nrelevant GFF devices based on user queries. To ensure precise and contextually\nrelevant recommendations, the system employs a dynamic retrieval method that\ncombines both conditional and semantic searches. Benchmarking against the\nestablished UEQ and existing haptic device searching tools, the proposed haptic\nrecommendation agent ranks in the top 10\\% across all UEQ categories with mean\ndifferences favoring the agent in nearly all subscales, and maintains no\nsignificant performance bias across different user groups, showcasing superior\nusability and user satisfaction.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.HC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12573v1",
    "published_date": "2025-01-22 01:41:05 UTC",
    "updated_date": "2025-01-22 01:41:05 UTC"
  },
  {
    "arxiv_id": "2501.12557v1",
    "title": "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review",
    "authors": [
      "Rock Yuren Pang",
      "Hope Schroeder",
      "Kynnedy Simone Smith",
      "Solon Barocas",
      "Ziang Xiao",
      "Emily Tseng",
      "Danielle Bragg"
    ],
    "abstract": "Large language models (LLMs) have been positioned to revolutionize HCI, by\nreshaping not only the interfaces, design patterns, and sociotechnical systems\nthat we study, but also the research practices we use. To-date, however, there\nhas been little understanding of LLMs' uptake in HCI. We address this gap via a\nsystematic literature review of 153 CHI papers from 2020-24 that engage with\nLLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in\nHCI projects; (3) contribution types; and (4) acknowledged limitations and\nrisks. We find LLM work in 10 diverse domains, primarily via empirical and\nartifact contributions. Authors use LLMs in five distinct roles, including as\nresearch tools or simulated users. Still, authors often raise validity and\nreproducibility concerns, and overwhelmingly study closed models. We outline\nopportunities to improve HCI research with and on LLMs, and provide guiding\nquestions for researchers to consider the validity and appropriateness of\nLLM-related work.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "This is a preprint version of the paper conditionally accepted to\n  CHI'25",
    "pdf_url": "http://arxiv.org/pdf/2501.12557v1",
    "published_date": "2025-01-22 00:31:51 UTC",
    "updated_date": "2025-01-22 00:31:51 UTC"
  }
]