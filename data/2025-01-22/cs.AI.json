{
  "date": "2025-01-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-22 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 85 篇论文，主要聚焦 AI、机器学习、量子计算和联邦学习等领域，其中 DeepSeek-R1 由 DeepSeek-AI 团队发布，展示了 LLM 通过强化学习提升推理能力的突破性进展；其他亮点包括量子机器学习和图神经网络的应用，强调了模型泛化、安全性和效率优化。\n\n### 重点论文讨论\n我们先聊聊几篇重要且话题度高的论文，这些涉及前沿 AI 技术和知名团队的贡献。\n\n- **DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning**（中文：通过强化学习激励 LLM 的推理能力）  \n  这篇论文由 DeepSeek-AI 团队发布，介绍了 DeepSeek-R1 模型，通过大规模强化学习（RL）训练 LLM，提升其推理性能。核心贡献是提出 RL 框架，使模型在不依赖监督微调的情况下，在 MATH 和代码基准上达到 OpenAI-o1-1217 的水平，例如在 AIME 上得分 77.5。该发现突显 RL 在扩展 LLM 能力的潜力，但也暴露了可读性和语言混合问题，适合 AI 研究者关注。\n\n- **Information-theoretic Bayesian Optimization: Survey and Tutorial**（中文：基于信息理论的贝叶斯优化：调查与教程）  \n  作者 Eduardo C. Garrido-Merchán 提供了信息理论在贝叶斯优化中的全面综述。论文主要贡献是分析了优化黑箱函数的多种场景（如多目标和约束优化），并讨论了信息理论指标（如互信息）如何提升算法效率。该工作为 AI 优化提供实用框架，强调了第二阶优化策略在复杂任务中的优势，值得机器学习从业者学习。\n\n- **FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis**（中文：面向通用医疗图像分析的联邦域对抗生成）  \n  作者 Haoxuan Che 等提出 FedDAG 框架，用于联邦学习中的医疗图像泛化。核心创新是使用域对抗生成模拟数据偏移，提升模型在未见域的表现，如在多个基准上提升 Dice 系数约 2%。该方法解决了隐私保护和数据异质性问题，具有医疗 AI 的实际应用价值。\n\n- **GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models**（中文：GPU 自适应非均匀量化用于大型语言模型）  \n  作者 Pengxiang Zhao 和 Xiaoming Yuan 开发了 GANQ 方法，针对 LLM 的量化优化。论文的主要发现是通过 GPU 适配的非均匀量化（如 3-4 位），显著降低模型复杂度，同时在 ImageNet 上提升准确率 5.3%，并实现 2.57 倍推理加速。该技术在资源受限环境中有重要意义。\n\n- **QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks**（中文：用于混合量子-经典深度神经网络的量子特征提取模块）  \n  作者 Naman Jain 和 Amir Kalev 引入 QuFeX 模块，提升量子机器学习的特征提取效率。核心贡献是减少量子评估次数，并在图像分割任务中（如 U-Net 架构）超越基线，达到更高精度。该发现为量子 AI 打开新路径，特别适合计算机视觉领域。\n\n### 其他论文快速掠过\n剩余论文覆盖了强化学习、联邦学习和生物医学等领域，但许多主题较 niche 或重复现有工作，我们简要提一下：\n- **SRMT: Shared Memory for Multi-agent Lifelong Pathfinding**（中文：多代理终身路径规划的共享内存）由 Alsu Sagirova 等提出，主要贡献是使用共享记忆 Transformer 提升多代理协调，在路径规划基准上表现出色。\n- **FlanEC: Exploring Flan-T5 for Post-ASR Error Correction**（中文：探索 Flan-T5 用于语音识别后错误修正）聚焦语音 AI，通过生成式修正提升 ASR 准确性。\n- **Ehrenfeucht-Haussler Rank and Chain of Thought**（中文：Ehrenfeucht-Haussler 秩与思维链）分析了 Boolean 函数秩与 Transformer 推理的关系，提供理论洞见。\n- 其他如 **Adaptive Data Exploitation in Deep Reinforcement Learning**（中文：深度强化学习的自适应数据利用）和 **A Unified Invariant Learning Framework for Graph Classification**（中文：图分类的统一不变学习框架）等，分别优化了 RL 数据效率和图神经网络泛化，但整体影响较小，可根据具体兴趣进一步阅读。\n\n今天的更新突出了 AI 模型的优化和泛化潜力，建议关注 DeepSeek-R1 等高影响力工作。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2501.13230v2",
      "title": "Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Ru Pei"
      ],
      "abstract": "We introduce Centaurus, a class of networks composed of generalized\nstate-space model (SSM) blocks, where the SSM operations can be treated as\ntensor contractions during training. The optimal order of tensor contractions\ncan then be systematically determined for every SSM block to maximize training\nefficiency. This allows more flexibility in designing SSM blocks beyond the\ndepthwise-separable configuration commonly implemented. The new design choices\nwill take inspiration from classical convolutional blocks including group\nconvolutions, full convolutions, and bottleneck blocks. We architect the\nCentaurus network with a mixture of these blocks, to balance between network\nsize and performance, as well as memory and computational efficiency during\nboth training and inference. We show that this heterogeneous network design\noutperforms its homogeneous counterparts in raw audio processing tasks\nincluding keyword spotting, speech denoising, and automatic speech recognition\n(ASR). For ASR, Centaurus is the first network with competitive performance\nthat can be made fully state-space based, without using any nonlinear\nrecurrence (LSTMs), explicit convolutions (CNNs), or (surrogate) attention\nmechanism. The source code is available as supplementary material on\nhttps://openreview.net/forum?id=PkpNRmBZ32",
      "tldr_zh": "我们介绍了Centaurus，一种由泛化状态空间模型(SSM)块组成的网络，将SSM操作视为训练中的张量收缩，并通过系统优化张量收缩顺序来提升训练效率。\n这项设计超越传统深度可分离配置，借鉴经典卷积网络元素（如分组卷积、全卷积和瓶颈块），构建异构网络以平衡网络大小、性能、内存和计算效率。\n实验结果显示，Centaurus在音频处理任务（如关键词识别、语音去噪和自动语音识别（ASR））上优于同类模型，且是首个完全基于SSM的网络，无需非线性循环（LSTMs）、显式卷积（CNNs）或注意力机制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13230v2",
      "published_date": "2025-01-22 21:30:49 UTC",
      "updated_date": "2025-04-09 19:05:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:53:12.017275"
    },
    {
      "arxiv_id": "2501.16371v3",
      "title": "Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?",
      "title_zh": "哪个优化器在 Physics-Informed Neural Networks 和 Kolmogorov-Arnold Networks 中效果最佳？",
      "authors": [
        "Elham Kiyani",
        "Khemraj Shukla",
        "Jorge F. Urbán",
        "Jérôme Darbon",
        "George Em Karniadakis"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) have revolutionized the computation\nof PDE solutions by integrating partial differential equations (PDEs) into the\nneural network's training process as soft constraints, becoming an important\ncomponent of the scientific machine learning (SciML) ecosystem. More recently,\nphysics-informed Kolmogorv-Arnold networks (PIKANs) have also shown to be\neffective and comparable in accuracy with PINNs. In their current\nimplementation, both PINNs and PIKANs are mainly optimized using first-order\nmethods like Adam, as well as quasi-Newton methods such as BFGS and its\nlow-memory variant, L-BFGS. However, these optimizers often struggle with\nhighly non-linear and non-convex loss landscapes, leading to challenges such as\nslow convergence, local minima entrapment, and (non)degenerate saddle points.\nIn this study, we investigate the performance of Self-Scaled BFGS (SSBFGS),\nSelf-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton\nschemes, including BFGS and L-BFGS with different line search strategies\napproaches. These methods dynamically rescale updates based on historical\ngradient information, thus enhancing training efficiency and accuracy. We\nsystematically compare these optimizers -- using both PINNs and PIKANs -- on\nkey challenging linear, stiff, multi-scale and non-linear PDEs, including the\nBurgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations. Our\nfindings provide state-of-the-art results with orders-of-magnitude accuracy\nimprovements without the use of adaptive weights or any other enhancements\ntypically employed in PINNs. More broadly, our results reveal insights into the\neffectiveness of second-order optimization strategies in significantly\nimproving the convergence and accurate generalization of PINNs and PIKANs.",
      "tldr_zh": "本文研究了在Physics-Informed Neural Networks (PINNs) 和 Physics-Informed Kolmogorov-Arnold Networks (PIKANs) 中，最有效的优化器，针对这些模型在处理非线性非凸损失景观时面临的收敛问题。研究比较了Self-Scaled BFGS (SSBFGS)、Self-Scaled Broyden (SSBroyden) 等高级准Newton方法与传统优化器如Adam 和 L-BFGS，在Burgers、Allen-Cahn 等关键PDEs上的表现。结果显示，这些高级优化器显著提升了训练效率和准确性，实现数量级改进，并为PINNs 和 PIKANs 的收敛与泛化提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16371v3",
      "published_date": "2025-01-22 21:19:42 UTC",
      "updated_date": "2025-04-17 13:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:53:24.338032"
    },
    {
      "arxiv_id": "2501.13200v1",
      "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
      "title_zh": "翻译失败",
      "authors": [
        "Alsu Sagirova",
        "Yuri Kuratov",
        "Mikhail Burtsev"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) demonstrates significant progress\nin solving cooperative and competitive multi-agent problems in various\nenvironments. One of the principal challenges in MARL is the need for explicit\nprediction of the agents' behavior to achieve cooperation. To resolve this\nissue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends\nmemory transformers to multi-agent settings by pooling and globally\nbroadcasting individual working memories, enabling agents to exchange\ninformation implicitly and coordinate their actions. We evaluate SRMT on the\nPartially Observable Multi-Agent Pathfinding problem in a toy Bottleneck\nnavigation task that requires agents to pass through a narrow corridor and on a\nPOGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently\noutperforms a variety of reinforcement learning baselines, especially under\nsparse rewards, and generalizes effectively to longer corridors than those seen\nduring training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is\ncompetitive with recent MARL, hybrid, and planning-based algorithms. These\nresults suggest that incorporating shared recurrent memory into the\ntransformer-based architectures can enhance coordination in decentralized\nmulti-agent systems. The source code for training and evaluation is available\non GitHub: https://github.com/Aloriosa/srmt.",
      "tldr_zh": "本文提出 SRMT（Shared Recurrent Memory Transformer），一种扩展记忆 Transformer 的框架，通过池化和全局广播个体工作记忆，让多智能体强化学习(MARL)代理隐式交换信息并协调行动，从而解决预测代理行为以实现合作的核心挑战。实验在部分可观测多智能体路径寻找问题上进行，包括 Bottleneck 导航任务和 POGEMA 基准（如 Mazes、Random 和 MovingAI 地图），SRMT 优于各种强化学习基线，尤其在稀疏奖励下，并能泛化到未见环境。结果表明，融入共享循环记忆能显著提升 Transformer 架构在去中心化多智能体系统中的协调性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13200v1",
      "published_date": "2025-01-22 20:08:53 UTC",
      "updated_date": "2025-01-22 20:08:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:53:36.451117"
    },
    {
      "arxiv_id": "2501.16370v2",
      "title": "Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Movahedian Moghaddam",
        "Kourosh Parand",
        "Saeed Reza Kheradpisheh"
      ],
      "abstract": "In this paper, we present the Residual Integral Solver Network (RISN), a\nnovel neural network architecture designed to solve a wide range of integral\nand integro-differential equations, including one-dimensional,\nmulti-dimensional, ordinary and partial integro-differential, systems,\nfractional types, and Helmholtz-type integral equations involving oscillatory\nkernels. RISN integrates residual connections with high-accuracy numerical\nmethods such as Gaussian quadrature and fractional derivative operational\nmatrices, enabling it to achieve higher accuracy and stability than traditional\nPhysics-Informed Neural Networks (PINN). The residual connections help mitigate\nvanishing gradient issues, allowing RISN to handle deeper networks and more\ncomplex kernels, particularly in multi-dimensional problems. Through extensive\nexperiments, we demonstrate that RISN consistently outperforms not only\nclassical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and\nSelf-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute\nErrors (MAE) across various types of equations. These results highlight RISN's\nrobustness and efficiency in solving challenging integral and\nintegro-differential problems, making it a valuable tool for real-world\napplications where traditional methods often struggle.",
      "tldr_zh": "本研究提出了一种先进的神经网络架构Residual Integral Solver Network (RISN)，旨在解决各种复杂积分和积分微分方程，包括一维、多维、普通和偏微分、系统、分数类型，以及涉及振荡核的Helmholtz-type方程。RISN通过整合residual connections和高精度数值方法，如Gaussian quadrature和fractional derivative operational matrices，提升了准确性和稳定性，同时缓解了梯度消失问题，使其适用于更深的网络和多维问题。与传统Physics-Informed Neural Networks (PINN)以及变体如Auxiliary PINN (A-PINN)和Self-Adaptive PINN (SA-PINN)相比，实验结果显示RISN在多种方程上实现了显著更低的Mean Absolute Errors (MAE)。这项创新为处理传统方法难以应对的真实世界问题提供了高效、鲁棒的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "cs.NE",
        "math.NA",
        "68T07, 65R20"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16370v2",
      "published_date": "2025-01-22 19:47:03 UTC",
      "updated_date": "2025-05-01 12:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:53:47.860869"
    },
    {
      "arxiv_id": "2501.13973v1",
      "title": "A Spatio-temporal Graph Network Allowing Incomplete Trajectory Input for Pedestrian Trajectory Prediction",
      "title_zh": "一种",
      "authors": [
        "Juncen Long",
        "Gianluca Bardaro",
        "Simone Mentasti",
        "Matteo Matteucci"
      ],
      "abstract": "Pedestrian trajectory prediction is important in the research of mobile robot\nnavigation in environments with pedestrians. Most pedestrian trajectory\nprediction algorithms require the input historical trajectories to be complete.\nIf a pedestrian is unobservable in any frame in the past, then its historical\ntrajectory become incomplete, the algorithm will not predict its future\ntrajectory. To address this limitation, we propose the STGN-IT, a\nspatio-temporal graph network allowing incomplete trajectory input, which can\npredict the future trajectories of pedestrians with incomplete historical\ntrajectories. STGN-IT uses the spatio-temporal graph with an additional\nencoding method to represent the historical trajectories and observation states\nof pedestrians. Moreover, STGN-IT introduces static obstacles in the\nenvironment that may affect the future trajectories as nodes to further improve\nthe prediction accuracy. A clustering algorithm is also applied in the\nconstruction of spatio-temporal graphs. Experiments on public datasets show\nthat STGN-IT outperforms state of the art algorithms on these metrics.",
      "tldr_zh": "行人轨迹预测在移动机器人导航中至关重要，但现有算法要求输入历史轨迹完整，否则无法进行预测。针对这一问题，本文提出STGN-IT，一种允许不完整轨迹输入的spatio-temporal graph network，通过额外编码方法表示行人历史轨迹和观察状态，并将环境中的静态障碍作为节点加入图网络，同时使用聚类算法构建图结构。实验结果表明，STGN-IT在公共数据集上优于最先进算法，提升了预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13973v1",
      "published_date": "2025-01-22 19:32:07 UTC",
      "updated_date": "2025-01-22 19:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:53:59.541244"
    },
    {
      "arxiv_id": "2501.13181v1",
      "title": "Learning in Log-Domain: Subthreshold Analog AI Accelerator Based on Stochastic Gradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Momen K Tageldeen",
        "Yacine Belgaid",
        "Vivek Mohan",
        "Zhou Wang",
        "Emmanuel M Drakakis"
      ],
      "abstract": "The rapid proliferation of AI models, coupled with growing demand for edge\ndeployment, necessitates the development of AI hardware that is both\nhigh-performance and energy-efficient. In this paper, we propose a novel analog\naccelerator architecture designed for AI/ML training workloads using stochastic\ngradient descent with L2 regularization (SGDr). The architecture leverages\nlog-domain circuits in subthreshold MOS and incorporates volatile memory. We\nestablish a mathematical framework for solving SGDr in the continuous time\ndomain and detail the mapping of SGDr learning equations to log-domain\ncircuits. By operating in the analog domain and utilizing weak inversion, the\nproposed design achieves significant reductions in transistor area and power\nconsumption compared to digital implementations. Experimental results\ndemonstrate that the architecture closely approximates ideal behavior, with a\nmean square error below 0.87% and precision as low as 8 bits. Furthermore, the\narchitecture supports a wide range of hyperparameters. This work paves the way\nfor energy-efficient analog AI hardware with on-chip training capabilities.",
      "tldr_zh": "本研究提出了一种基于随机梯度下降（Stochastic Gradient Descent with L2 regularization, SGDr）的亚阈值模拟AI加速器架构，旨在满足AI模型边缘部署对高性能和节能硬件的需求。该架构利用对数域电路（log-domain circuits）和亚阈值MOS技术，结合易失性内存，并建立了在连续时间域解决SGDr的数学框架，将学习方程映射到模拟电路中，从而显著降低晶体管面积和功耗。实验结果显示，该设计接近理想行为，均方误差低于0.87%，精度可达8位，并支持广泛的超参数设置，为实现能量高效的模拟AI硬件提供芯片上训练能力。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13181v1",
      "published_date": "2025-01-22 19:26:36 UTC",
      "updated_date": "2025-01-22 19:26:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:54:11.794929"
    },
    {
      "arxiv_id": "2501.13165v1",
      "title": "QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks",
      "title_zh": "QuFeX：用于混合量子-经典深度神经网络的量子特征提取模块",
      "authors": [
        "Naman Jain",
        "Amir Kalev"
      ],
      "abstract": "We introduce Quantum Feature Extraction (QuFeX), a novel quantum machine\nlearning module. The proposed module enables feature extraction in a\nreduced-dimensional space, significantly decreasing the number of parallel\nevaluations required in typical quantum convolutional neural network\narchitectures. Its design allows seamless integration into deep classical\nneural networks, making it particularly suitable for hybrid quantum-classical\nmodels. As an application of QuFeX, we propose Qu-Net -- a hybrid architecture\nwhich integrates QuFeX at the bottleneck of a U-Net architecture. The latter is\nwidely used for image segmentation tasks such as medical imaging and autonomous\ndriving. Our numerical analysis indicates that the Qu-Net can achieve superior\nsegmentation performance compared to a U-Net baseline. These results highlight\nthe potential of QuFeX to enhance deep neural networks by leveraging hybrid\ncomputational paradigms, providing a path towards a robust framework for\nreal-world applications requiring precise feature extraction.",
      "tldr_zh": "本文提出Quantum Feature Extraction (QuFeX)，一个新型量子机器学习模块，能够在减少维度空间中进行特征提取，从而显著降低量子卷积神经网络的并行评估需求，并无缝集成到深度经典神经网络中，适合混合量子-经典模型。作者将其应用于Qu-Net架构，将QuFeX置于U-Net的瓶颈位置，用于图像分割任务如医疗成像和自动驾驶。数值分析显示，Qu-Net在分割性能上优于U-Net基准模型，突显了QuFeX通过混合计算范式增强深度神经网络的潜力，为需要精确特征提取的实际应用提供稳健框架。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "12 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13165v1",
      "published_date": "2025-01-22 19:00:09 UTC",
      "updated_date": "2025-01-22 19:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:54:24.271675"
    },
    {
      "arxiv_id": "2502.15713v1",
      "title": "UAV-assisted Internet of Vehicles: A Framework Empowered by Reinforcement Learning and Blockchain",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Alagha",
        "Maha Kadadha",
        "Rabeb Mizouni",
        "Shakti Singh",
        "Jamal Bentahar",
        "Hadi Otrok"
      ],
      "abstract": "This paper addresses the challenges of selecting relay nodes and coordinating\namong them in UAV-assisted Internet-of-Vehicles (IoV). The selection of UAV\nrelay nodes in IoV employs mechanisms executed either at centralized servers or\ndecentralized nodes, which have two main limitations: 1) the traceability of\nthe selection mechanism execution and 2) the coordination among the selected\nUAVs, which is currently offered in a centralized manner and is not coupled\nwith the relay selection. Existing UAV coordination methods often rely on\noptimization methods, which are not adaptable to different environment\ncomplexities, or on centralized deep reinforcement learning, which lacks\nscalability in multi-UAV settings. Overall, there is a need for a comprehensive\nframework where relay selection and coordination are coupled and executed in a\ntransparent and trusted manner. This work proposes a framework empowered by\nreinforcement learning and Blockchain for UAV-assisted IoV networks. It\nconsists of three main components: a two-sided UAV relay selection mechanism\nfor UAV-assisted IoV, a decentralized Multi-Agent Deep Reinforcement Learning\n(MDRL) model for autonomous UAV coordination, and a Blockchain implementation\nfor transparency and traceability in the interactions between vehicles and\nUAVs. The relay selection considers the two-sided preferences of vehicles and\nUAVs based on the Quality-of-UAV (QoU) and the Quality-of-Vehicle (QoV). Upon\nselection of relay UAVs, the decentralized coordination between them is enabled\nthrough an MDRL model trained to control their mobility and maintain the\nnetwork coverage and connectivity using Proximal Policy Optimization (PPO). The\nevaluation results demonstrate that the proposed selection and coordination\nmechanisms improve the stability of the selected relays and maximize the\ncoverage and connectivity achieved by the UAVs.",
      "tldr_zh": "本论文提出一个由强化学习和区块链赋能的框架，用于解决UAV辅助Internet of Vehicles (IoV)网络中中继节点选择和协调的挑战，该框架将选择和协调过程耦合起来，并确保透明性和可追溯性。框架包括三部分：基于Quality-of-UAV (QoU)和Quality-of-Vehicle (QoV)的双向UAV中继选择机制、去中心化Multi-Agent Deep Reinforcement Learning (MDRL)模型用于UAV的自主协调，以及区块链实现来保障车辆与UAV互动的安全性。MDRL模型采用Proximal Policy Optimization (PPO)算法，训练UAV控制其移动以维护网络覆盖和连通性。实验结果表明，该框架显著提高了选定中继的稳定性，并最大化了UAV的覆盖和连通性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15713v1",
      "published_date": "2025-01-22 18:54:59 UTC",
      "updated_date": "2025-01-22 18:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:54:36.589986"
    },
    {
      "arxiv_id": "2501.16369v1",
      "title": "Blockchain-based Crowdsourced Deep Reinforcement Learning as a Service",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Alagha",
        "Hadi Otrok",
        "Shakti Singh",
        "Rabeb Mizouni",
        "Jamal Bentahar"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) has emerged as a powerful paradigm for\nsolving complex problems. However, its full potential remains inaccessible to a\nbroader audience due to its complexity, which requires expertise in training\nand designing DRL solutions, high computational capabilities, and sometimes\naccess to pre-trained models. This necessitates the need for hassle-free\nservices that increase the availability of DRL solutions to a variety of users.\nTo enhance the accessibility to DRL services, this paper proposes a novel\nblockchain-based crowdsourced DRL as a Service (DRLaaS) framework. The\nframework provides DRL-related services to users, covering two types of tasks:\nDRL training and model sharing. Through crowdsourcing, users could benefit from\nthe expertise and computational capabilities of workers to train DRL solutions.\nModel sharing could help users gain access to pre-trained models, shared by\nworkers in return for incentives, which can help train new DRL solutions using\nmethods in knowledge transfer. The DRLaaS framework is built on top of a\nConsortium Blockchain to enable traceable and autonomous execution. Smart\nContracts are designed to manage worker and model allocation, which are stored\nusing the InterPlanetary File System (IPFS) to ensure tamper-proof data\ndistribution. The framework is tested on several DRL applications, proving its\nefficacy.",
      "tldr_zh": "本文提出了一种基于区块链的众包式 Deep Reinforcement Learning as a Service (DRLaaS) 框架，以解决 DRL 的复杂性问题，提高其对普通用户的可用性。框架通过 crowdsourcing 利用工人的专业知识和计算能力，提供 DRL 训练和模型共享服务，用户可访问预训练模型并应用知识转移方法。系统基于 Consortium Blockchain 实现可追踪和自治执行，利用 Smart Contracts 管理资源分配，并通过 IPFS 确保数据防篡改。在多个 DRL 应用上测试，证明了框架的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16369v1",
      "published_date": "2025-01-22 18:54:39 UTC",
      "updated_date": "2025-01-22 18:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:54:48.229909"
    },
    {
      "arxiv_id": "2501.16368v2",
      "title": "Foundation Models for CPS-IoT: Opportunities and Challenges",
      "title_zh": "CPS-IoT 的基础模型：机遇与挑战",
      "authors": [
        "Ozan Baris",
        "Yizhuo Chen",
        "Gaofeng Dong",
        "Liying Han",
        "Tomoyoshi Kimura",
        "Pengrui Quan",
        "Ruijie Wang",
        "Tianchen Wang",
        "Tarek Abdelzaher",
        "Mario Bergés",
        "Paul Pu Liang",
        "Mani Srivastava"
      ],
      "abstract": "Methods from machine learning (ML) have transformed the implementation of\nPerception-Cognition-Communication-Action loops in Cyber-Physical Systems (CPS)\nand the Internet of Things (IoT), replacing mechanistic and basic statistical\nmodels with those derived from data. However, the first generation of ML\napproaches, which depend on supervised learning with annotated data to create\ntask-specific models, faces significant limitations in scaling to the diverse\nsensor modalities, deployment configurations, application tasks, and operating\ndynamics characterizing real-world CPS-IoT systems. The success of\ntask-agnostic foundation models (FMs), including multimodal large language\nmodels (LLMs), in addressing similar challenges across natural language,\ncomputer vision, and human speech has generated considerable enthusiasm for and\nexploration of FMs and LLMs as flexible building blocks in CPS-IoT analytics\npipelines, promising to reduce the need for costly task-specific engineering.\n  Nonetheless, a significant gap persists between the current capabilities of\nFMs and LLMs in the CPS-IoT domain and the requirements they must meet to be\nviable for CPS-IoT applications. In this paper, we analyze and characterize\nthis gap through a thorough examination of the state of the art and our\nresearch, which extends beyond it in various dimensions. Based on the results\nof our analysis and research, we identify essential desiderata that CPS-IoT\ndomain-specific FMs and LLMs must satisfy to bridge this gap. We also propose\nactions by CPS-IoT researchers to collaborate in developing key community\nresources necessary for establishing FMs and LLMs as foundational tools for the\nnext generation of CPS-IoT systems.",
      "tldr_zh": "这篇论文探讨了基础模型（Foundation Models, FMs）和大型语言模型（Large Language Models, LLMs）在网络物理系统（CPS）和物联网（IoT）中的应用机会与挑战。作者指出，第一代机器学习（ML）方法依赖于监督学习和任务特定模型，无法有效扩展到CPS-IoT的多样化场景，如传感器模式和动态操作。论文通过分析现有技术和自身研究，识别了FMs和LLMs在CPS-IoT领域的能力差距，并提出关键要求，包括开发领域特定模型和社区资源，以使这些模型成为下一代CPS-IoT系统的核心工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16368v2",
      "published_date": "2025-01-22 18:52:41 UTC",
      "updated_date": "2025-02-04 21:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:54:59.858272"
    },
    {
      "arxiv_id": "2501.13094v1",
      "title": "Robust Representation Consistency Model via Contrastive Denoising",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Lei",
        "Julius Berner",
        "Jiongxiao Wang",
        "Zhongzhu Chen",
        "Zhongjia Ba",
        "Kui Ren",
        "Jun Zhu",
        "Anima Anandkumar"
      ],
      "abstract": "Robustness is essential for deep neural networks, especially in\nsecurity-sensitive applications. To this end, randomized smoothing provides\ntheoretical guarantees for certifying robustness against adversarial\nperturbations. Recently, diffusion models have been successfully employed for\nrandomized smoothing to purify noise-perturbed samples before making\npredictions with a standard classifier. While these methods excel at small\nperturbation radii, they struggle with larger perturbations and incur a\nsignificant computational overhead during inference compared to classical\nmethods. To address this, we reformulate the generative modeling task along the\ndiffusion trajectories in pixel space as a discriminative task in the latent\nspace. Specifically, we use instance discrimination to achieve consistent\nrepresentations along the trajectories by aligning temporally adjacent points.\nAfter fine-tuning based on the learned representations, our model enables\nimplicit denoising-then-classification via a single prediction, substantially\nreducing inference costs. We conduct extensive experiments on various datasets\nand achieve state-of-the-art performance with minimal computation budget during\ninference. For example, our method outperforms the certified accuracy of\ndiffusion-based methods on ImageNet across all perturbation radii by 5.3% on\naverage, with up to 11.6% at larger radii, while reducing inference costs by\n85$\\times$ on average. Codes are available at:\nhttps://github.com/jiachenlei/rRCM.",
      "tldr_zh": "本文提出了一种基于对比去噪（Contrastive Denoising）的鲁棒表示一致性模型（Robust Representation Consistency Model），旨在提升深度神经网络对对抗性扰动的鲁棒性，特别是通过重新将扩散模型（diffusion models）的生成任务转化为潜在空间的判别任务。方法利用实例判别（instance discrimination）来对齐扩散轨迹上的时间相邻表示，实现高效的隐式去噪和分类，从而显著减少推理计算开销。实验在 ImageNet 等数据集上显示，该模型比现有基于 randomized smoothing 的扩散方法平均提高了 5.3% 的认证准确率，在大扰动半径下提升达 11.6%，并将推理成本降低 85 倍。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13094v1",
      "published_date": "2025-01-22 18:52:06 UTC",
      "updated_date": "2025-01-22 18:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:55:13.061918"
    },
    {
      "arxiv_id": "2501.13093v3",
      "title": "Guaranteed Recovery of Unambiguous Clusters",
      "title_zh": "翻译失败",
      "authors": [
        "Kayvon Mazooji",
        "Ilan Shomorony"
      ],
      "abstract": "Clustering is often a challenging problem because of the inherent ambiguity\nin what the \"correct\" clustering should be. Even when the number of clusters\n$K$ is known, this ambiguity often still exists, particularly when there is\nvariation in density among different clusters, and clusters have multiple\nrelatively separated regions of high density. In this paper we propose an\ninformation-theoretic characterization of when a $K$-clustering is ambiguous,\nand design an algorithm that recovers the clustering whenever it is\nunambiguous. This characterization formalizes the situation when two high\ndensity regions within a cluster are separable enough that they look more like\ntwo distinct clusters than two truly distinct clusters in the $K$-clustering.\nThe algorithm first identifies $K$ partial clusters (or \"seeds\") using a\ndensity-based approach, and then adds unclustered points to the initial $K$\npartial clusters in a greedy manner to form a complete clustering. We implement\nand test a version of the algorithm that is modified to effectively handle\noverlapping clusters, and observe that it requires little parameter selection\nand displays improved performance on many datasets compared to widely used\nalgorithms for non-convex cluster recovery.",
      "tldr_zh": "论文提出了一种基于信息-theoretic characterization的方法，来判断K-clustering是否模糊，特别是当簇密度不同或包含多个高密度区域时。该算法通过density-based approach先识别K个partial clusters作为seeds，然后采用greedy manner添加未聚类点，从而保证恢复无模糊聚类。实验结果显示，该算法的修改版本能有效处理overlapping clusters，并在多种数据集上比现有算法表现出更高的性能和更少的参数选择需求。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.DS",
        "cs.LG",
        "math.IT",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.IT",
      "comment": "12 pages, includes minor changes and some new content compared to\n  previous version",
      "pdf_url": "http://arxiv.org/pdf/2501.13093v3",
      "published_date": "2025-01-22 18:51:25 UTC",
      "updated_date": "2025-05-07 18:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:55:23.611142"
    },
    {
      "arxiv_id": "2501.13084v1",
      "title": "Attention-Driven Hierarchical Reinforcement Learning with Particle Filtering for Source Localization in Dynamic Fields",
      "title_zh": "注意力驱动的分层强化学习结合粒子滤波用于动态场中的源定位",
      "authors": [
        "Yiwei Shi",
        "Mengyue Yang",
        "Qi Zhang",
        "Weinan Zhang",
        "Cunjia Liu",
        "Weiru Liu"
      ],
      "abstract": "In many real-world scenarios, such as gas leak detection or environmental\npollutant tracking, solving the Inverse Source Localization and\nCharacterization problem involves navigating complex, dynamic fields with\nsparse and noisy observations. Traditional methods face significant challenges,\nincluding partial observability, temporal and spatial dynamics,\nout-of-distribution generalization, and reward sparsity. To address these\nissues, we propose a hierarchical framework that integrates Bayesian inference\nand reinforcement learning. The framework leverages an attention-enhanced\nparticle filtering mechanism for efficient and accurate belief updates, and\nincorporates two complementary execution strategies: Attention Particle\nFiltering Planning and Attention Particle Filtering Reinforcement Learning.\nThese approaches optimize exploration and adaptation under uncertainty.\nTheoretical analysis proves the convergence of the attention-enhanced particle\nfilter, while extensive experiments across diverse scenarios validate the\nframework's superior accuracy, adaptability, and computational efficiency. Our\nresults highlight the framework's potential for broad applications in dynamic\nfield estimation tasks.",
      "tldr_zh": "该研究针对动态领域中的逆源定位问题（如气体泄漏检测），提出了一种注意力驱动的层次强化学习框架，以应对部分可观察性、动态变化和奖励稀疏等挑战。该框架整合了贝叶斯推理和强化学习，利用注意力增强的粒子滤波机制（attention-enhanced particle filtering）来实现高效的信念更新，并引入两种互补策略：Attention Particle Filtering Planning 和 Attention Particle Filtering Reinforcement Learning，以优化探索和不确定性适应。理论分析证明了该粒子滤波机制的收敛性，实验在多种场景中验证了框架的优越准确性、可适应性和计算效率，为动态领域估计任务提供了新颖解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13084v1",
      "published_date": "2025-01-22 18:45:29 UTC",
      "updated_date": "2025-01-22 18:45:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:55:35.567898"
    },
    {
      "arxiv_id": "2501.13083v1",
      "title": "Boosting MCTS with Free Energy Minimization",
      "title_zh": "翻译失败",
      "authors": [
        "Mawaba Pascal Dao",
        "Adrian M. Peter"
      ],
      "abstract": "Active Inference, grounded in the Free Energy Principle, provides a powerful\nlens for understanding how agents balance exploration and goal-directed\nbehavior in uncertain environments. Here, we propose a new planning framework,\nthat integrates Monte Carlo Tree Search (MCTS) with active inference objectives\nto systematically reduce epistemic uncertainty while pursuing extrinsic\nrewards. Our key insight is that MCTS already renowned for its search\nefficiency can be naturally extended to incorporate free energy minimization by\nblending expected rewards with information gain. Concretely, the Cross-Entropy\nMethod (CEM) is used to optimize action proposals at the root node, while tree\nexpansions leverage reward modeling alongside intrinsic exploration bonuses.\nThis synergy allows our planner to maintain coherent estimates of value and\nuncertainty throughout planning, without sacrificing computational\ntractability. Empirically, we benchmark our planner on a diverse set of\ncontinuous control tasks, where it demonstrates performance gains over both\nstandalone CEM and MCTS with random rollouts.",
      "tldr_zh": "本研究提出了一种新的规划框架，将Monte Carlo Tree Search (MCTS)与Active Inference和Free Energy Principle整合，旨在在不确定环境中减少epistemic uncertainty的同时追求extrinsic rewards。该框架通过将MCTS扩展为结合期望奖励和信息增益来最小化free energy，利用Cross-Entropy Method (CEM)优化根节点的行动提案，并通过奖励建模和内在探索奖励进行树扩展，从而保持价值和不确定性的连贯估计，同时确保计算可行性。在各种连续控制任务的基准测试中，该框架的表现优于独立的CEM和传统MCTS，展示了显著的性能提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13083v1",
      "published_date": "2025-01-22 18:45:15 UTC",
      "updated_date": "2025-01-22 18:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:55:46.803121"
    },
    {
      "arxiv_id": "2501.13075v1",
      "title": "Evolution and The Knightian Blindspot of Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Joel Lehman",
        "Elliot Meyerson",
        "Tarek El-Gaaly",
        "Kenneth O. Stanley",
        "Tarin Ziyaee"
      ],
      "abstract": "This paper claims that machine learning (ML) largely overlooks an important\nfacet of general intelligence: robustness to a qualitatively unknown future in\nan open world. Such robustness relates to Knightian uncertainty (KU) in\neconomics, i.e. uncertainty that cannot be quantified, which is excluded from\nconsideration in ML's key formalisms. This paper aims to identify this blind\nspot, argue its importance, and catalyze research into addressing it, which we\nbelieve is necessary to create truly robust open-world AI. To help illuminate\nthe blind spot, we contrast one area of ML, reinforcement learning (RL), with\nthe process of biological evolution. Despite staggering ongoing progress, RL\nstill struggles in open-world situations, often failing under unforeseen\nsituations. For example, the idea of zero-shot transferring a self-driving car\npolicy trained only in the US to the UK currently seems exceedingly ambitious.\nIn dramatic contrast, biological evolution routinely produces agents that\nthrive within an open world, sometimes even to situations that are remarkably\nout-of-distribution (e.g. invasive species; or humans, who do undertake such\nzero-shot international driving). Interestingly, evolution achieves such\nrobustness without explicit theory, formalisms, or mathematical gradients. We\nexplore the assumptions underlying RL's typical formalisms, showing how they\nlimit RL's engagement with the unknown unknowns characteristic of an\never-changing complex world. Further, we identify mechanisms through which\nevolutionary processes foster robustness to novel and unpredictable challenges,\nand discuss potential pathways to algorithmically embody them. The conclusion\nis that the intriguing remaining fragility of ML may result from blind spots in\nits formalisms, and that significant gains may result from direct confrontation\nwith the challenge of KU.",
      "tldr_zh": "这篇论文指出，机器学习（ML）忽略了 Knightian uncertainty（KU），即无法量化的不确定性，这导致 ML 在开放世界中缺乏对未知未来的鲁棒性，并强调了解决这一盲点的重要性，以开发真正可靠的开放世界 AI。作者通过对比强化学习（RL）和生物进化过程，展示了 RL 在面对预见外情境（如零样本转移自驾车政策）时表现脆弱，而进化则能产生适应极端分布外情况的代理。论文分析了 RL 正式化的假设限制，并提出借鉴进化的机制（如无理论的适应策略）来设计新算法，最终可能显著提升 ML 的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13075v1",
      "published_date": "2025-01-22 18:38:41 UTC",
      "updated_date": "2025-01-22 18:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:55:59.765903"
    },
    {
      "arxiv_id": "2501.13074v1",
      "title": "Autonomy-of-Experts Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ang Lv",
        "Ruobing Xie",
        "Yining Qian",
        "Songhao Wu",
        "Xingwu Sun",
        "Zhanhui Kang",
        "Di Wang",
        "Rui Yan"
      ],
      "abstract": "Mixture-of-Experts (MoE) models mostly use a router to assign tokens to\nspecific expert modules, activating only partial parameters and often\noutperforming dense models. We argue that the separation between the router's\ndecision-making and the experts' execution is a critical yet overlooked issue,\nleading to suboptimal expert selection and ineffective learning. To address\nthis, we propose Autonomy-of-Experts (AoE), a novel MoE paradigm in which\nexperts autonomously select themselves to process inputs. AoE is based on the\ninsight that an expert is aware of its own capacity to effectively process a\ntoken, an awareness reflected in the scale of its internal activations. In AoE,\nrouters are removed; instead, experts pre-compute internal activations for\ninputs and are ranked based on their activation norms. Only the top-ranking\nexperts proceed with the forward pass, while the others abort. The overhead of\npre-computing activations is reduced through a low-rank weight factorization.\nThis self-evaluating-then-partner-comparing approach ensures improved expert\nselection and effective learning. We pre-train language models having 700M up\nto 4B parameters, demonstrating that AoE outperforms traditional MoE models\nwith comparable efficiency.",
      "tldr_zh": "该论文针对Mixture-of-Experts (MoE)模型中路由器与专家模块分离导致的专家选择不佳和学习无效问题，提出了一种新范式Autonomy-of-Experts (AoE)。在AoE中，专家自主评估自身处理输入的能力，通过预计算内部激活并基于激活规范排名，仅让排名靠前的专家继续执行前向传播，同时使用低秩权重分解减少计算开销。实验结果显示，在700M至4B参数的语言模型预训练中，AoE比传统MoE模型表现出色，同时保持可比的效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13074v1",
      "published_date": "2025-01-22 18:37:08 UTC",
      "updated_date": "2025-01-22 18:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:56:12.072306"
    },
    {
      "arxiv_id": "2501.13072v2",
      "title": "AdaWM: Adaptive World Model based Planning for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Wang",
        "Xin Ye",
        "Feng Tao",
        "Chenbin Pan",
        "Abhirup Mallik",
        "Burhaneddin Yaman",
        "Liu Ren",
        "Junshan Zhang"
      ],
      "abstract": "World model based reinforcement learning (RL) has emerged as a promising\napproach for autonomous driving, which learns a latent dynamics model and uses\nit to train a planning policy. To speed up the learning process, the\npretrain-finetune paradigm is often used, where online RL is initialized by a\npretrained model and a policy learned offline. However, naively performing such\ninitialization in RL may result in dramatic performance degradation during the\nonline interactions in the new task. To tackle this challenge, we first analyze\nthe performance degradation and identify two primary root causes therein: the\nmismatch of the planning policy and the mismatch of the dynamics model, due to\ndistribution shift. We further analyze the effects of these factors on\nperformance degradation during finetuning, and our findings reveal that the\nchoice of finetuning strategies plays a pivotal role in mitigating these\neffects. We then introduce AdaWM, an Adaptive World Model based planning\nmethod, featuring two key steps: (a) mismatch identification, which quantifies\nthe mismatches and informs the finetuning strategy, and (b) alignment-driven\nfinetuning, which selectively updates either the policy or the model as needed\nusing efficient low-rank updates. Extensive experiments on the challenging\nCARLA driving tasks demonstrate that AdaWM significantly improves the\nfinetuning process, resulting in more robust and efficient performance in\nautonomous driving systems.",
      "tldr_zh": "这篇论文提出了 AdaWM，一种自适应世界模型基于规划方法，用于自动驾驶领域，以解决预训练-微调范式中因分布偏移导致的规划策略失配和动态模型失配问题。AdaWM 通过失配识别机制量化这些不匹配，并采用基于对齐的微调策略，选择性地更新策略或模型，使用高效的低秩更新来优化学习过程。实验结果显示，在 CARLA 驾驶任务上，AdaWM 显著提升了微调效率和系统性能，使自动驾驶系统更具鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13072v2",
      "published_date": "2025-01-22 18:34:51 UTC",
      "updated_date": "2025-01-23 04:15:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:56:24.151115"
    },
    {
      "arxiv_id": "2502.15712v1",
      "title": "GPUs, CPUs, and... NICs: Rethinking the Network's Role in Serving Complex AI Pipelines",
      "title_zh": "GPU、CPU 和……NIC：重新思考网络在服务复杂 AI 管道中的作用",
      "authors": [
        "Mike Wong",
        "Ulysses Butler",
        "Emma Farkash",
        "Praveen Tammana",
        "Anirudh Sivaraman",
        "Ravi Netravali"
      ],
      "abstract": "The increasing prominence of AI necessitates the deployment of inference\nplatforms for efficient and effective management of AI pipelines and compute\nresources. As these pipelines grow in complexity, the demand for distributed\nserving rises and introduces much-dreaded network delays. In this paper, we\ninvestigate how the network can instead be a boon to the excessively high\nresource overheads of AI pipelines. To alleviate these overheads, we discuss\nhow resource-intensive data processing tasks -- a key facet of growing AI\npipeline complexity -- are well-matched for the computational characteristics\nof packet processing pipelines and how they can be offloaded onto SmartNICs. We\nexplore the challenges and opportunities of offloading, and propose a research\nagenda for integrating network hardware into AI pipelines, unlocking new\nopportunities for optimization.",
      "tldr_zh": "这篇论文重新审视了网络在服务复杂 AI 管道中的作用，提出将资源密集型数据处理任务卸载到 SmartNICs 上，以缓解 AI 管道的高资源开销和网络延迟问题。作者分析了这些任务与数据包处理管道的计算特性相匹配的优势，并探讨了卸载的挑战和机会。最终，论文提出一个研究议程，将网络硬件集成到 AI 管道中，开启新的优化可能性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.OS"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15712v1",
      "published_date": "2025-01-22 18:32:12 UTC",
      "updated_date": "2025-01-22 18:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:56:35.303959"
    },
    {
      "arxiv_id": "2501.13028v1",
      "title": "Optimizing Return Distributions with Distributional Dynamic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Bernardo Ávila Pires",
        "Mark Rowland",
        "Diana Borsa",
        "Zhaohan Daniel Guo",
        "Khimya Khetarpal",
        "André Barreto",
        "David Abel",
        "Rémi Munos",
        "Will Dabney"
      ],
      "abstract": "We introduce distributional dynamic programming (DP) methods for optimizing\nstatistical functionals of the return distribution, with standard reinforcement\nlearning as a special case. Previous distributional DP methods could optimize\nthe same class of expected utilities as classic DP. To go beyond expected\nutilities, we combine distributional DP with stock augmentation, a technique\npreviously introduced for classic DP in the context of risk-sensitive RL, where\nthe MDP state is augmented with a statistic of the rewards obtained so far\n(since the first time step). We find that a number of recently studied problems\ncan be formulated as stock-augmented return distribution optimization, and we\nshow that we can use distributional DP to solve them. We analyze distributional\nvalue and policy iteration, with bounds and a study of what objectives these\ndistributional DP methods can or cannot optimize. We describe a number of\napplications outlining how to use distributional DP to solve different\nstock-augmented return distribution optimization problems, for example\nmaximizing conditional value-at-risk, and homeostatic regulation. To highlight\nthe practical potential of stock-augmented return distribution optimization and\ndistributional DP, we combine the core ideas of distributional value iteration\nwith the deep RL agent DQN, and empirically evaluate it for solving instances\nof the applications discussed.",
      "tldr_zh": "本研究引入了distributional dynamic programming (DP) 方法，用于优化回报分布的统计函数，将标准强化学习作为特例。作者通过结合distributional DP 和 stock augmentation 技术（在MDP 状态中添加奖励统计量），扩展了方法以超越期望效用，解决风险敏感强化学习等新问题。实验表明，该方法能有效处理如最大化conditional value-at-risk 和 homeostatic regulation 等应用，并通过将distributional value iteration 与 DQN 结合，展示了实际性能提升。分析显示，该框架具有明确的优化边界和潜力，但也存在某些目标的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13028v1",
      "published_date": "2025-01-22 17:20:43 UTC",
      "updated_date": "2025-01-22 17:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:56:57.329202"
    },
    {
      "arxiv_id": "2502.10409v1",
      "title": "Data Science Students Perspectives on Learning Analytics: An Application of Human-Led and LLM Content Analysis",
      "title_zh": "数据科学学生对学习分析的视角：人类主导和LLM内容分析的应用",
      "authors": [
        "Raghda Zahran",
        "Jianfei Xu",
        "Huizhi Liang",
        "Matthew Forshaw"
      ],
      "abstract": "Objective This study is part of a series of initiatives at a UK university\ndesigned to cultivate a deep understanding of students' perspectives on\nanalytics that resonate with their unique learning needs. It explores\ncollaborative data processing undertaken by postgraduate students who examined\nan Open University Learning Analytics Dataset (OULAD).\n  Methods A qualitative approach was adopted, integrating a Retrieval-Augmented\nGeneration (RAG) and a Large Language Model (LLM) technique with human-led\ncontent analysis to gather information about students' perspectives based on\ntheir submitted work. The study involved 72 postgraduate students in 12 groups.\n  Findings The analysis of group work revealed diverse insights into essential\nlearning analytics from the students' perspectives. All groups adopted a\nstructured data science methodology. The questions formulated by the groups\nwere categorised into seven themes, reflecting their specific areas of\ninterest. While there was variation in the selected variables to interpret\ncorrelations, a consensus was found regarding the general results.\n  Conclusion A significant outcome of this study is that students specialising\nin data science exhibited a deeper understanding of learning analytics,\neffectively articulating their interests through inferences drawn from their\nanalyses. While human-led content analysis provided a general understanding of\nstudents' perspectives, the LLM offered nuanced insights.",
      "tldr_zh": "本研究探讨了数据科学专业学生对学习分析的观点，基于一个英国大学的项目，使用Open University Learning Analytics Dataset (OULAD)进行分析。研究采用定性方法，结合Retrieval-Augmented Generation (RAG)和Large Language Model (LLM)技术与人类主导的内容分析，涉及72名研究生分12组进行协作数据处理。结果显示，学生们采用结构化的数据科学方法，将问题归纳为七个主题，并对变量相关性有共识；同时，人类分析提供整体理解，而LLM则揭示了更细致的见解，突显了数据科学学生对学习分析的深入掌握。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "stat.AP"
      ],
      "primary_category": "cs.CY",
      "comment": "17 Pages, 2 Tables, 1 Figure",
      "pdf_url": "http://arxiv.org/pdf/2502.10409v1",
      "published_date": "2025-01-22 17:16:01 UTC",
      "updated_date": "2025-01-22 17:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:56:59.346166"
    },
    {
      "arxiv_id": "2501.13023v2",
      "title": "Provably-Safe Neural Network Training Using Hybrid Zonotope Reachability Analysis",
      "title_zh": "使用混合 Zonotope 可达性分析的证明安全神经网络训练",
      "authors": [
        "Long Kiu Chung",
        "Shreyas Kousik"
      ],
      "abstract": "Even though neural networks are being increasingly deployed in\nsafety-critical control applications, it remains difficult to enforce\nconstraints on their output, meaning that it is hard to guarantee safety in\nsuch settings. While many existing methods seek to verify a neural network's\nsatisfaction of safety constraints, few address how to correct an unsafe\nnetwork. The handful of works that extract a training signal from verification\ncannot handle non-convex sets, and are either conservative or slow. To begin\naddressing these challenges, this work proposes a neural network training\nmethod that can encourage the exact image of a non-convex input set for a\nneural network with rectified linear unit (ReLU) nonlinearities to avoid a\nnon-convex unsafe region. This is accomplished by reachability analysis with\nscaled hybrid zonotopes, a modification of the existing hybrid zonotope set\nrepresentation that enables parameterized scaling of non-convex polytopic sets\nwith a differentiable collision check via mixed-integer linear programs\n(MILPs). The proposed method was shown to be effective and fast for networks\nwith up to 240 neurons, with the computational complexity dominated by inverse\noperations on matrices that scale linearly in size with the number of neurons\nand complexity of input and unsafe sets. We demonstrate the practicality of our\nmethod by training a forward-invariant neural network controller for a\nnon-convex input set to an affine system, as well as generating safe\nreach-avoid plans for a black-box dynamical system.",
      "tldr_zh": "这篇论文提出了一种基于混合 zonotope 可达性分析的神经网络训练方法，以确保网络输出避免非凸不安全区域，从而提升安全关键控制应用的可靠性。该方法使用 scaled hybrid zonotopes 进行参数化缩放和可微分碰撞检查，通过混合整数线性规划 (MILPs) 处理 ReLU 非线性，支持非凸输入集的精确图像处理。实验结果显示，该方法对多达240个神经元的网络高效快速，计算复杂度与神经元数量线性相关，并成功应用于训练前向不变神经网络控制器和生成黑箱动态系统的安全 reach-avoid 计划。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13023v2",
      "published_date": "2025-01-22 17:13:48 UTC",
      "updated_date": "2025-04-01 01:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:57:12.165880"
    },
    {
      "arxiv_id": "2501.13014v1",
      "title": "Paper Quality Assessment based on Individual Wisdom Metrics from Open Peer Review",
      "title_zh": "翻译失败",
      "authors": [
        "Andrii Zahorodnii",
        "Jasper J. F. van den Bosch",
        "Ian Charest",
        "Christopher Summerfield",
        "Ila R. Fiete"
      ],
      "abstract": "This study proposes a data-driven framework for enhancing the accuracy and\nefficiency of scientific peer review through an open, bottom-up process that\nestimates reviewer quality. Traditional closed peer review systems, while\nessential for quality control, are often slow, costly, and subject to biases\nthat can impede scientific progress. Here, we introduce a method that evaluates\nindividual reviewer reliability by quantifying agreement with community\nconsensus scores and applying Bayesian weighting to refine paper quality\nassessments. We analyze open peer review data from two major scientific\nconferences, and demonstrate that reviewer-specific quality scores\nsignificantly improve the reliability of paper quality estimation. Perhaps\nsurprisingly, we find that reviewer quality scores are unrelated to authorship\nquality. Our model incorporates incentive structures to recognize high-quality\nreviewers and encourage broader coverage of submitted papers, thereby\nmitigating the common \"rich-get-richer\" pitfall of social media. These findings\nsuggest that open peer review, with mechanisms for estimating and incentivizing\nreviewer quality, offers a scalable and equitable alternative for scientific\npublishing, with potential to enhance the speed, fairness, and transparency of\nthe peer review process.",
      "tldr_zh": "这篇论文提出了一种数据驱动框架，通过开放同行评议中的Individual Wisdom Metrics评估审稿人质量，以提升科学同行评议的准确性和效率。该方法量化审稿人与社区共识的分歧，并应用Bayesian weighting来精炼论文质量评估，同时引入激励结构奖励高质量审稿人并鼓励更广泛的论文覆盖，以避免“rich-get-richer”问题。研究分析了两个主要科学会议的开放同行评议数据，发现审稿人质量分数显著提高了可靠性评估，但与作者质量无关。该框架为科学出版提供了一个可扩展、公平的替代方案，提升了同行评议的速度、公平性和透明度。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.SI",
      "comment": "15 pages, 5 main text figures, 3 supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13014v1",
      "published_date": "2025-01-22 17:00:27 UTC",
      "updated_date": "2025-01-22 17:00:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:57:24.624880"
    },
    {
      "arxiv_id": "2501.13011v2",
      "title": "MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking",
      "title_zh": "MONA：近视优化结合非近视批准能够缓解多步奖励黑客行为",
      "authors": [
        "Sebastian Farquhar",
        "Vikrant Varma",
        "David Lindner",
        "David Elson",
        "Caleb Biddulph",
        "Ian Goodfellow",
        "Rohin Shah"
      ],
      "abstract": "Future advanced AI systems may learn sophisticated strategies through\nreinforcement learning (RL) that humans cannot understand well enough to safely\nevaluate. We propose a training method which avoids agents learning undesired\nmulti-step plans that receive high reward (multi-step \"reward hacks\") even if\nhumans are not able to detect that the behaviour is undesired. The method,\nMyopic Optimization with Non-myopic Approval (MONA), works by combining\nshort-sighted optimization with far-sighted reward. We demonstrate that MONA\ncan prevent multi-step reward hacking that ordinary RL causes, even without\nbeing able to detect the reward hacking and without any extra information that\nordinary RL does not get access to. We study MONA empirically in three settings\nwhich model different misalignment failure modes including 2-step environments\nwith LLMs representing delegated oversight and encoded reasoning and\nlonger-horizon gridworld environments representing sensor tampering.",
      "tldr_zh": "本研究提出MONA方法（Myopic Optimization with Non-myopic Approval），旨在缓解强化学习（RL）中AI系统学习到人类难以检测的多步奖励黑客（multi-step reward hacking）行为，从而提升AI的安全性。MONA通过结合短视优化和远视奖励，确保AI避免学习不受欢迎的多步计划，而无需额外检测信息或资源。在实验中，该方法在包括LLMs模拟的2步环境（代表委托监督和编码推理）和更长视野的网格世界环境（模拟传感器篡改）等设置中，成功地比普通RL减少了奖励黑客发生。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13011v2",
      "published_date": "2025-01-22 16:53:08 UTC",
      "updated_date": "2025-04-10 16:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:57:36.604845"
    },
    {
      "arxiv_id": "2501.12997v1",
      "title": "Ehrenfeucht-Haussler Rank and Chain of Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Barceló",
        "Alexander Kozachinskiy",
        "Tomasz Steifer"
      ],
      "abstract": "The notion of rank of a Boolean function has been a cornerstone in the theory\nof PAC learning, enabling quasipolynomial-time learning algorithms for\npolynomial-size decision trees. We present a novel characterization of rank,\ngrounded in the well-known Transformer architecture. We show that the rank of a\nfunction $f$ corresponds to the minimum number of Chain of Thought (CoT) steps\nrequired by a single-layer transformer decoder with hard attention to compute\n$f$. Based on this characterization we establish tight bounds on the number of\nCoT steps required for specific problems, showing that $\\ell$-fold function\ncomposition necessitates exactly $\\ell$ CoT steps. Furthermore, we analyze the\nproblem of identifying the position of the $k$-th occurrence of 1 in a Boolean\nsequence, proving that it requires $k$ CoT steps.",
      "tldr_zh": "本文提出了一种新的 Ehrenfeucht-Haussler Rank 特征化，将其与 Transformer 架构的 Chain of Thought (CoT) 步骤相结合，用于分析 Boolean 函数在 PAC 学习中的性质。研究表明，函数 f 的 rank 对应于单层 Transformer 解码器使用硬注意力计算 f 所需的最小 CoT 步骤数量。进一步，他们建立了紧密边界：ℓ-fold function composition 需要恰好 ℓ 个 CoT 步骤，而识别 Boolean 序列中第 k 次 1 的位置需要 k 个 CoT 步骤，这为理解函数复杂性和机器学习算法提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12997v1",
      "published_date": "2025-01-22 16:30:58 UTC",
      "updated_date": "2025-01-22 16:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:57:47.127987"
    },
    {
      "arxiv_id": "2501.12979v1",
      "title": "FlanEC: Exploring Flan-T5 for Post-ASR Error Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Moreno La Quatra",
        "Valerio Mario Salerno",
        "Yu Tsao",
        "Sabato Marco Siniscalchi"
      ],
      "abstract": "In this paper, we present an encoder-decoder model leveraging Flan-T5 for\npost-Automatic Speech Recognition (ASR) Generative Speech Error Correction\n(GenSEC), and we refer to it as FlanEC. We explore its application within the\nGenSEC framework to enhance ASR outputs by mapping n-best hypotheses into a\nsingle output sentence. By utilizing n-best lists from ASR models, we aim to\nimprove the linguistic correctness, accuracy, and grammaticality of final ASR\ntranscriptions. Specifically, we investigate whether scaling the training data\nand incorporating diverse datasets can lead to significant improvements in\npost-ASR error correction. We evaluate FlanEC using the HyPoradise dataset,\nproviding a comprehensive analysis of the model's effectiveness in this domain.\nFurthermore, we assess the proposed approach under different settings to\nevaluate model scalability and efficiency, offering valuable insights into the\npotential of instruction-tuned encoder-decoder models for this task.",
      "tldr_zh": "本研究提出 FlanEC，这是一个基于 Flan-T5 的编码器-解码器模型，用于后 Automatic Speech Recognition (ASR) 生成语音错误修正 (GenSEC)，旨在通过将 ASR 的 n-best 假设映射到一个单一输出句子来提升转录的语言正确性、准确性和语法性。研究探索了扩展训练数据和整合多样数据集对模型性能的提升效果，并使用 HyPoradise 数据集进行全面评估。结果显示，FlanEC 在不同设置下表现出良好的可扩展性和效率，为指令微调的编码器-解码器模型在 ASR 错误修正任务中的应用提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the 2024 IEEE Workshop on Spoken Language Technology\n  (SLT) - GenSEC Challenge",
      "pdf_url": "http://arxiv.org/pdf/2501.12979v1",
      "published_date": "2025-01-22 16:06:04 UTC",
      "updated_date": "2025-01-22 16:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:57:59.523988"
    },
    {
      "arxiv_id": "2501.12978v1",
      "title": "Galois groups of polynomials and neurosymbolic networks",
      "title_zh": "翻译失败",
      "authors": [
        "Elira Shaska",
        "Tony Shaska"
      ],
      "abstract": "This paper introduces a novel approach to understanding Galois theory, one of\nthe foundational areas of algebra, through the lens of machine learning. By\nanalyzing polynomial equations with machine learning techniques, we aim to\nstreamline the process of determining solvability by radicals and explore\nbroader applications within Galois theory. This summary encapsulates the\nbackground, methodology, potential applications, and challenges of using data\nscience in Galois theory.\n  More specifically, we design a neurosymbolic network to classify Galois\ngroups and show how this is more efficient than usual neural networks. We\ndiscover some very interesting distribution of polynomials for groups not\nisomorphic to the symmetric groups and alternating groups.",
      "tldr_zh": "本论文提出了一种将机器学习应用于伽罗瓦理论（Galois theory）的新方法，通过分析多项式方程来简化确定可通过根式求解的问题，并探索该理论的更广泛应用。研究设计了一个神经符号网络（neurosymbolic network）来分类伽罗瓦群（Galois groups），并证明其比传统神经网络更高效。论文还发现了一些群不等同于对称群（symmetric groups）和交错群（alternating groups）时的多项式分布，具有重要的理论意义。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.HO",
        "I.2.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12978v1",
      "published_date": "2025-01-22 16:05:59 UTC",
      "updated_date": "2025-01-22 16:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:58:10.129643"
    },
    {
      "arxiv_id": "2501.12972v1",
      "title": "Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Corazza",
        "Ivan Gavran",
        "Gabriela Moreira",
        "Daniel Neider"
      ],
      "abstract": "When blockchain systems are said to be trustless, what this really means is\nthat all the trust is put into software. Thus, there are strong incentives to\nensure blockchain software is correct -- vulnerabilities here cost millions and\nbreak businesses. One of the most powerful ways of establishing software\ncorrectness is by using formal methods. Approaches based on formal methods,\nhowever, induce a significant overhead in terms of time and expertise required\nto successfully employ them. Our work addresses this critical disadvantage by\nautomating the creation of a formal model -- a mathematical abstraction of the\nsoftware system -- which is often a core task when employing formal methods. We\nperform model synthesis in three phases: we first transpile the code into model\nstubs; then we \"fill in the blanks\" using a large language model (LLM);\nfinally, we iteratively repair the generated model, on both syntactical and\nsemantical level. In this way, we significantly reduce the amount of time\nnecessary to create formal models and increase accessibility of valuable\nsoftware verification methods that rely on them. The practical context of our\nwork was reducing the time-to-value of using formal models for correctness\naudits of smart contracts.",
      "tldr_zh": "该研究针对区块链智能合约的验证问题，提出了一种自动化形式化模型合成方法，以降低形式方法(Formal Methods)的使用门槛。方法分为三阶段：首先将代码转译(transpile)成模型存根(stubs)；然后使用大型语言模型(LLMs)填充空白；最后通过迭代修复在语法和语义层面完善模型。这种方法显著减少了创建形式化模型所需的时间，并提高了软件正确性审计的可访问性，尤其适用于智能合约的正确性审计。实验结果表明，该框架能加速区块链软件的验证过程，增强其在实际应用中的价值。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12972v1",
      "published_date": "2025-01-22 15:57:29 UTC",
      "updated_date": "2025-01-22 15:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:58:22.443892"
    },
    {
      "arxiv_id": "2501.12962v2",
      "title": "It's complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU AI Act",
      "title_zh": "翻译失败",
      "authors": [
        "Kristof Meding"
      ],
      "abstract": "What constitutes a fair decision? This question is not only difficult for\nhumans but becomes more challenging when Artificial Intelligence (AI) models\nare used. In light of discriminatory algorithmic behaviors, the EU has recently\npassed the AI Act, which mandates specific rules for AI models, incorporating\nboth traditional legal non-discrimination regulations and machine learning\nbased algorithmic fairness concepts. This paper aims to bridge these two\ndifferent concepts in the AI Act through: First a high-level introduction of\nboth concepts targeting legal and computer science-oriented scholars, and\nsecond an in-depth analysis of the AI Act's relationship between legal\nnon-discrimination regulations and algorithmic fairness. Our analysis reveals\nthree key findings: (1.), most non-discrimination regulations target only\nhigh-risk AI systems. (2.), the regulation of high-risk systems encompasses\nboth data input requirements and output monitoring, though these regulations\nare often inconsistent and raise questions of computational feasibility. (3.)\nRegulations for General Purpose AI Models, such as Large Language Models that\nare not simultaneously classified as high-risk systems, currently lack\nspecificity compared to other regulations. Based on these findings, we\nrecommend developing more specific auditing and testing methodologies for AI\nsystems. This paper aims to serve as a foundation for future interdisciplinary\ncollaboration between legal scholars and computer science-oriented machine\nlearning researchers studying discrimination in AI systems.",
      "tldr_zh": "这篇论文探讨了算法公平（algorithmic fairness）和欧盟 AI 法案（EU AI Act）中的非歧视规定之间的复杂关系，旨在为法律学者和计算机科学研究者提供高水平介绍，并进行深入分析。研究发现：(1) 大多数非歧视规定仅针对高风险 AI 系统（high-risk AI systems）；(2) 这些系统的规定包括数据输入要求和输出监控，但存在不一致性和计算可行性问题；(3) 对于通用目的 AI 模型（General Purpose AI Models），如非高风险的 Large Language Models，其规定缺乏具体性。论文据此推荐开发更精确的 AI 系统审计和测试方法，以促进法律与机器学习领域的跨学科合作。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12962v2",
      "published_date": "2025-01-22 15:38:09 UTC",
      "updated_date": "2025-03-14 15:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:58:35.396012"
    },
    {
      "arxiv_id": "2501.12958v1",
      "title": "A Novel Tracking Framework for Devices in X-ray Leveraging Supplementary Cue-Driven Self-Supervised Features",
      "title_zh": "翻译失败",
      "authors": [
        "Saahil Islam",
        "Venkatesh N. Murthy",
        "Dominik Neumann",
        "Serkan Cimen",
        "Puneet Sharma",
        "Andreas Maier",
        "Dorin Comaniciu",
        "Florin C. Ghesu"
      ],
      "abstract": "To restore proper blood flow in blocked coronary arteries via angioplasty\nprocedure, accurate placement of devices such as catheters, balloons, and\nstents under live fluoroscopy or diagnostic angiography is crucial. Identified\nballoon markers help in enhancing stent visibility in X-ray sequences, while\nthe catheter tip aids in precise navigation and co-registering vessel\nstructures, reducing the need for contrast in angiography. However, accurate\ndetection of these devices in interventional X-ray sequences faces significant\nchallenges, particularly due to occlusions from contrasted vessels and other\ndevices and distractions from surrounding, resulting in the failure to track\nsuch small objects. While most tracking methods rely on spatial correlation of\npast and current appearance, they often lack strong motion comprehension\nessential for navigating through these challenging conditions, and fail to\neffectively detect multiple instances in the scene. To overcome these\nlimitations, we propose a self-supervised learning approach that enhances its\nspatio-temporal understanding by incorporating supplementary cues and learning\nacross multiple representation spaces on a large dataset. Followed by that, we\nintroduce a generic real-time tracking framework that effectively leverages the\npretrained spatio-temporal network and also takes the historical appearance and\ntrajectory data into account. This results in enhanced localization of multiple\ninstances of device landmarks. Our method outperforms state-of-the-art methods\nin interventional X-ray device tracking, especially stability and robustness,\nachieving an 87% reduction in max error for balloon marker detection and a 61%\nreduction in max error for catheter tip detection.",
      "tldr_zh": "本论文针对介入性 X 射线图像中设备（如导管、气球和支架）的跟踪挑战，提出了一种新框架，利用补充线索驱动的自监督学习（self-supervised learning）方法，在多个表示空间上增强时空理解。框架结合预训练的时空网络，并整合历史外观和轨迹数据，实现多个设备地标的实时精确定位。实验结果显示，该方法在设备跟踪中优于现有技术，最大错误减少87%（气球标记）和61%（导管尖端），显著提升了稳定性与鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12958v1",
      "published_date": "2025-01-22 15:32:07 UTC",
      "updated_date": "2025-01-22 15:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:58:46.836813"
    },
    {
      "arxiv_id": "2501.12956v2",
      "title": "GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pengxiang Zhao",
        "Xiaoming Yuan"
      ],
      "abstract": "Large Language Models (LLMs) face significant deployment challenges due to\ntheir substantial resource requirements. While low-bit quantized weights can\nreduce memory usage and improve inference efficiency, current hardware lacks\nnative support for mixed-precision General Matrix Multiplication (mpGEMM),\nresulting in inefficient dequantization-based implementations. Moreover,\nuniform quantization methods often fail to capture weight distributions\nadequately, leading to performance degradation. We propose GANQ (GPU-Adaptive\nNon-Uniform Quantization), a layer-wise post-training non-uniform quantization\nframework optimized for hardware-efficient lookup table-based mpGEMM. GANQ\nachieves superior quantization performance by utilizing a training-free,\nGPU-adaptive optimization algorithm to efficiently reduce layer-wise\nquantization errors. Extensive experiments demonstrate GANQ's ability to reduce\nthe perplexity gap from the FP16 baseline compared to state-of-the-art methods\nfor both 3-bit and 4-bit quantization. Furthermore, when deployed on a single\nNVIDIA RTX 4090 GPU, GANQ's quantized models achieve up to 2.57$\\times$ speedup\nover the baseline, advancing memory and inference efficiency in LLM deployment.",
      "tldr_zh": "该论文提出 GANQ，一种针对大语言模型 (LLMs) 的层级后训练非均匀量化框架，旨在优化硬件高效的查找表-based mpGEMM，以解决现有量化方法在权重分布捕捉和推理效率上的不足。GANQ 采用训练-free、GPU-adaptive 优化算法，高效减少层级量化错误，从而在 3-bit 和 4-bit 量化中显著降低与 FP16 基线的 perplexity 差距。实验结果显示，在单 NVIDIA RTX 4090 GPU 上，GANQ 的量化模型比基线实现高达 2.57 倍的加速，提升了 LLMs 的内存和推理效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12956v2",
      "published_date": "2025-01-22 15:29:09 UTC",
      "updated_date": "2025-02-11 11:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:59:01.505933"
    },
    {
      "arxiv_id": "2501.12948v1",
      "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
      "title_zh": "DeepSeek-R1：通过强化学习激励大型语言模型的推理能力",
      "authors": [
        "DeepSeek-AI",
        "Daya Guo",
        "Dejian Yang",
        "Haowei Zhang",
        "Junxiao Song",
        "Ruoyu Zhang",
        "Runxin Xu",
        "Qihao Zhu",
        "Shirong Ma",
        "Peiyi Wang",
        "Xiao Bi",
        "Xiaokang Zhang",
        "Xingkai Yu",
        "Yu Wu",
        "Z. F. Wu",
        "Zhibin Gou",
        "Zhihong Shao",
        "Zhuoshu Li",
        "Ziyi Gao",
        "Aixin Liu",
        "Bing Xue",
        "Bingxuan Wang",
        "Bochao Wu",
        "Bei Feng",
        "Chengda Lu",
        "Chenggang Zhao",
        "Chengqi Deng",
        "Chenyu Zhang",
        "Chong Ruan",
        "Damai Dai",
        "Deli Chen",
        "Dongjie Ji",
        "Erhang Li",
        "Fangyun Lin",
        "Fucong Dai",
        "Fuli Luo",
        "Guangbo Hao",
        "Guanting Chen",
        "Guowei Li",
        "H. Zhang",
        "Han Bao",
        "Hanwei Xu",
        "Haocheng Wang",
        "Honghui Ding",
        "Huajian Xin",
        "Huazuo Gao",
        "Hui Qu",
        "Hui Li",
        "Jianzhong Guo",
        "Jiashi Li",
        "Jiawei Wang",
        "Jingchang Chen",
        "Jingyang Yuan",
        "Junjie Qiu",
        "Junlong Li",
        "J. L. Cai",
        "Jiaqi Ni",
        "Jian Liang",
        "Jin Chen",
        "Kai Dong",
        "Kai Hu",
        "Kaige Gao",
        "Kang Guan",
        "Kexin Huang",
        "Kuai Yu",
        "Lean Wang",
        "Lecong Zhang",
        "Liang Zhao",
        "Litong Wang",
        "Liyue Zhang",
        "Lei Xu",
        "Leyi Xia",
        "Mingchuan Zhang",
        "Minghua Zhang",
        "Minghui Tang",
        "Meng Li",
        "Miaojun Wang",
        "Mingming Li",
        "Ning Tian",
        "Panpan Huang",
        "Peng Zhang",
        "Qiancheng Wang",
        "Qinyu Chen",
        "Qiushi Du",
        "Ruiqi Ge",
        "Ruisong Zhang",
        "Ruizhe Pan",
        "Runji Wang",
        "R. J. Chen",
        "R. L. Jin",
        "Ruyi Chen",
        "Shanghao Lu",
        "Shangyan Zhou",
        "Shanhuang Chen",
        "Shengfeng Ye",
        "Shiyu Wang",
        "Shuiping Yu",
        "Shunfeng Zhou",
        "Shuting Pan",
        "S. S. Li",
        "Shuang Zhou",
        "Shaoqing Wu",
        "Shengfeng Ye",
        "Tao Yun",
        "Tian Pei",
        "Tianyu Sun",
        "T. Wang",
        "Wangding Zeng",
        "Wanjia Zhao",
        "Wen Liu",
        "Wenfeng Liang",
        "Wenjun Gao",
        "Wenqin Yu",
        "Wentao Zhang",
        "W. L. Xiao",
        "Wei An",
        "Xiaodong Liu",
        "Xiaohan Wang",
        "Xiaokang Chen",
        "Xiaotao Nie",
        "Xin Cheng",
        "Xin Liu",
        "Xin Xie",
        "Xingchao Liu",
        "Xinyu Yang",
        "Xinyuan Li",
        "Xuecheng Su",
        "Xuheng Lin",
        "X. Q. Li",
        "Xiangyue Jin",
        "Xiaojin Shen",
        "Xiaosha Chen",
        "Xiaowen Sun",
        "Xiaoxiang Wang",
        "Xinnan Song",
        "Xinyi Zhou",
        "Xianzu Wang",
        "Xinxia Shan",
        "Y. K. Li",
        "Y. Q. Wang",
        "Y. X. Wei",
        "Yang Zhang",
        "Yanhong Xu",
        "Yao Li",
        "Yao Zhao",
        "Yaofeng Sun",
        "Yaohui Wang",
        "Yi Yu",
        "Yichao Zhang",
        "Yifan Shi",
        "Yiliang Xiong",
        "Ying He",
        "Yishi Piao",
        "Yisong Wang",
        "Yixuan Tan",
        "Yiyang Ma",
        "Yiyuan Liu",
        "Yongqiang Guo",
        "Yuan Ou",
        "Yuduan Wang",
        "Yue Gong",
        "Yuheng Zou",
        "Yujia He",
        "Yunfan Xiong",
        "Yuxiang Luo",
        "Yuxiang You",
        "Yuxuan Liu",
        "Yuyang Zhou",
        "Y. X. Zhu",
        "Yanhong Xu",
        "Yanping Huang",
        "Yaohui Li",
        "Yi Zheng",
        "Yuchen Zhu",
        "Yunxian Ma",
        "Ying Tang",
        "Yukun Zha",
        "Yuting Yan",
        "Z. Z. Ren",
        "Zehui Ren",
        "Zhangli Sha",
        "Zhe Fu",
        "Zhean Xu",
        "Zhenda Xie",
        "Zhengyan Zhang",
        "Zhewen Hao",
        "Zhicheng Ma",
        "Zhigang Yan",
        "Zhiyu Wu",
        "Zihui Gu",
        "Zijia Zhu",
        "Zijun Liu",
        "Zilin Li",
        "Ziwei Xie",
        "Ziyang Song",
        "Zizheng Pan",
        "Zhen Huang",
        "Zhipeng Xu",
        "Zhongyu Zhang",
        "Zhen Zhang"
      ],
      "abstract": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and\nDeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement\nlearning (RL) without supervised fine-tuning (SFT) as a preliminary step,\ndemonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero\nnaturally emerges with numerous powerful and intriguing reasoning behaviors.\nHowever, it encounters challenges such as poor readability, and language\nmixing. To address these issues and further enhance reasoning performance, we\nintroduce DeepSeek-R1, which incorporates multi-stage training and cold-start\ndata before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217\non reasoning tasks. To support the research community, we open-source\nDeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B,\n70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
      "tldr_zh": "该研究引入了 DeepSeek-R1-Zero 和 DeepSeek-R1 模型，通过强化学习（RL）提升大语言模型（LLMs）的推理能力，其中 DeepSeek-R1-Zero 直接经大规模 RL 训练（无监督微调，SFT），展现出强大的推理行为，但存在可读性差和语言混合等问题。DeepSeek-R1 通过多阶段训练和冷启动数据进一步优化这些缺陷，实现了与 OpenAI-o1-1217 相当的推理性能。为支持研究社区，该团队开源了 DeepSeek-R1-Zero、DeepSeek-R1 以及基于 Qwen 和 Llama 的六个蒸馏模型（1.5B 至 70B）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12948v1",
      "published_date": "2025-01-22 15:19:35 UTC",
      "updated_date": "2025-01-22 15:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:59:13.222199"
    },
    {
      "arxiv_id": "2501.12942v1",
      "title": "Offline Critic-Guided Diffusion Policy for Multi-User Delay-Constrained Scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoran Li",
        "Ruishuo Chen",
        "Hai Zhong",
        "Longbo Huang"
      ],
      "abstract": "Effective multi-user delay-constrained scheduling is crucial in various\nreal-world applications, such as instant messaging, live streaming, and data\ncenter management. In these scenarios, schedulers must make real-time decisions\nto satisfy both delay and resource constraints without prior knowledge of\nsystem dynamics, which are often time-varying and challenging to estimate.\nCurrent learning-based methods typically require interactions with actual\nsystems during the training stage, which can be difficult or impractical, as it\nis capable of significantly degrading system performance and incurring\nsubstantial service costs. To address these challenges, we propose a novel\noffline reinforcement learning-based algorithm, named \\underline{S}cheduling By\n\\underline{O}ffline Learning with \\underline{C}ritic Guidance and\n\\underline{D}iffusion Generation (SOCD), to learn efficient scheduling policies\npurely from pre-collected \\emph{offline data}. SOCD innovatively employs a\ndiffusion-based policy network, complemented by a sampling-free critic network\nfor policy guidance. By integrating the Lagrangian multiplier optimization into\nthe offline reinforcement learning, SOCD effectively trains high-quality\nconstraint-aware policies exclusively from available datasets, eliminating the\nneed for online interactions with the system. Experimental results demonstrate\nthat SOCD is resilient to various system dynamics, including partially\nobservable and large-scale environments, and delivers superior performance\ncompared to existing methods.",
      "tldr_zh": "本文提出 SOCD（Scheduling By Offline Learning with Critic Guidance and Diffusion Generation）算法，这是一种基于离线强化学习的创新方法，用于处理多用户延迟约束调度问题，如即时消息和数据中心管理，而无需在线系统交互。SOCD 结合 diffusion-based policy network 和 sampling-free critic network，并整合 Lagrangian multiplier optimization，从预先收集的离线数据中训练高效的约束感知策略。实验结果显示，该算法在部分可观察和大规模环境中表现出色，比现有方法性能更优越。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12942v1",
      "published_date": "2025-01-22 15:13:21 UTC",
      "updated_date": "2025-01-22 15:13:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:59:24.674776"
    },
    {
      "arxiv_id": "2501.12910v1",
      "title": "PreciseCam: Precise Camera Control for Text-to-Image Generation",
      "title_zh": "PreciseCam：用于文本到图像生成的精确",
      "authors": [
        "Edurne Bernal-Berdun",
        "Ana Serrano",
        "Belen Masia",
        "Matheus Gadelha",
        "Yannick Hold-Geoffroy",
        "Xin Sun",
        "Diego Gutierrez"
      ],
      "abstract": "Images as an artistic medium often rely on specific camera angles and lens\ndistortions to convey ideas or emotions; however, such precise control is\nmissing in current text-to-image models. We propose an efficient and general\nsolution that allows precise control over the camera when generating both\nphotographic and artistic images. Unlike prior methods that rely on predefined\nshots, we rely solely on four simple extrinsic and intrinsic camera parameters,\nremoving the need for pre-existing geometry, reference 3D objects, and\nmulti-view data. We also present a novel dataset with more than 57,000 images,\nalong with their text prompts and ground-truth camera parameters. Our\nevaluation shows precise camera control in text-to-image generation, surpassing\ntraditional prompt engineering approaches. Our data, model, and code are\npublicly available at https://graphics.unizar.es/projects/PreciseCam2024.",
      "tldr_zh": "本文提出PreciseCam方法，用于在文本到图像生成(text-to-image generation)中实现精确的相机控制，解决了当前模型在相机角度和镜头扭曲方面的不足。该方法仅依赖四个简单的extrinsic and intrinsic camera parameters，无需预定义几何、参考3D对象或多视图数据，从而适用于摄影和艺术图像的生成。同时，作者构建了一个包含超过57,000张图像的新数据集，包括文本提示和真实相机参数。实验评估表明，PreciseCam在相机控制精度上超越了传统的提示工程(prompt engineering)方法，并已公开数据、模型和代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12910v1",
      "published_date": "2025-01-22 14:37:01 UTC",
      "updated_date": "2025-01-22 14:37:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:59:37.741682"
    },
    {
      "arxiv_id": "2501.13141v1",
      "title": "AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Qiongyan Wang",
        "Yutong Xia",
        "Siru ZHong",
        "Weichuang Li",
        "Yuankai Wu",
        "Shifen Cheng",
        "Junbo Zhang",
        "Yu Zheng",
        "Yuxuan Liang"
      ],
      "abstract": "Monitoring real-time air quality is essential for safeguarding public health\nand fostering social progress. However, the widespread deployment of air\nquality monitoring stations is constrained by their significant costs. To\naddress this limitation, we introduce \\emph{AirRadar}, a deep neural network\ndesigned to accurately infer real-time air quality in locations lacking\nmonitoring stations by utilizing data from existing ones. By leveraging\nlearnable mask tokens, AirRadar reconstructs air quality features in\nunmonitored regions. Specifically, it operates in two stages: first capturing\nspatial correlations and then adjusting for distribution shifts. We validate\nAirRadar's efficacy using a year-long dataset from 1,085 monitoring stations\nacross China, demonstrating its superiority over multiple baselines, even with\nvarying degrees of unobserved data. The source code can be accessed at\nhttps://github.com/CityMind-Lab/AirRadar.",
      "tldr_zh": "该研究提出 AirRadar，一种基于 Deep Neural Networks 的模型，用于推断中国全国空气质量，特别是缺乏监测站的地区，从而解决部署成本限制问题。该模型通过 learnable mask tokens 重建未监测区域的空气质量特征，采用两阶段方法：首先捕获空间相关性，然后调整分布偏移。实验使用中国 1085 个监测站的一年数据验证了 AirRadar 的效能，其表现优于多个基线模型，即使在不同程度的未观测数据情况下。源代码可在 https://github.com/CityMind-Lab/AirRadar 获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13141v1",
      "published_date": "2025-01-22 14:32:20 UTC",
      "updated_date": "2025-01-22 14:32:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:59:48.874109"
    },
    {
      "arxiv_id": "2501.12901v1",
      "title": "Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Offa Kingsleigh",
        "Alfred Abercrombie",
        "David Woolstencroft",
        "Beorhtric Meadowcroft",
        "Marcus Irvin"
      ],
      "abstract": "Contextual Partitioning introduces an innovative approach to enhancing the\narchitectural design of large-scale computational models through the dynamic\nsegmentation of parameters into context-aware regions. This methodology\nemphasizes the importance of task-specific specialization, achieved through\nadaptive parameter allocation mechanisms that align with the linguistic\nfeatures of input data. Experimental evaluations demonstrated substantial\nimprovements in accuracy, perplexity, and contextual coherence across a variety\nof linguistic tasks, highlighting the adaptability and scalability of the\nproposed framework. By reducing redundancy and enhancing computational\nefficiency, Contextual Partitioning not only streamlines model operations but\nalso expands the scope of applications for advanced language processing\nsystems. The approach operates autonomously, requiring no external fine-tuning,\nthereby addressing a significant limitation in conventional parameter\noptimization techniques. Empirical results demonstrate the effectiveness of\ngradient-driven segmentation, enabling models to dynamically recalibrate and\nspecialize in response to task-specific demands. Furthermore, resource\nutilization metrics reveal notable reductions in memory usage and training\ntimes, confirming the efficiency of the approach. Observations from qualitative\nanalyses illustrate improved contextual coherence and logical flow in generated\noutputs, reinforcing the practical value of this technique. The findings\ncollectively demonstrate the potential for Contextual Partitioning to redefine\nthe scalability and adaptability of computational language architectures in\ndiverse and complex domains.",
      "tldr_zh": "本文提出 Contextual Partitioning，一种创新方法，通过动态分割参数成上下文感知区域，实现大型语言模型的架构融合和任务特定专业化。该方法利用适应性参数分配机制与输入数据的语言特征对齐，无需外部微调，从而减少冗余、提升计算效率，并在实验中显著改善准确性、困惑度和上下文连贯性。结果显示，该框架在各种语言任务上表现出色，降低了内存使用和训练时间，并通过梯度驱动分割实现模型的动态调整和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12901v1",
      "published_date": "2025-01-22 14:21:04 UTC",
      "updated_date": "2025-01-22 14:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:00:00.504086"
    },
    {
      "arxiv_id": "2503.15502v1",
      "title": "MapColorAI: Designing Contextually Relevant Choropleth Map Color Schemes Using a Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Nai Yang",
        "Yijie Wang",
        "Fan Wu",
        "Zhiwei Wei"
      ],
      "abstract": "Choropleth maps, which utilize color schemes to visualize spatial patterns\nand trends, are simple yet effective tools for geographic data analysis. As\nsuch, color scheme design is a critical aspect of choropleth map creation. The\ntraditional coloring methods offered by GIS tools such as ArcGIS and QGIS are\nnot user-friendly for non-professionals. On the one hand, these tools provide\nnumerous color schemes, making it hard to decide which one best matches the\ntheme. On the other hand, it is difficult to fulfill some ambiguous and\npersonalized coloring needs of users, such as requests for 'summer-like' map\ncolors. To address these shortcomings, we develop a novel system that leverages\na large language model and map color design principles to generate contextually\nrelevant and user-aligned choropleth map color schemes. The system follows a\nthree-stage process: Data processing, which provides an overview of the data\nand classifies the data into meaningful classes; Color Concept Design, where\nthe color theme and color mode are conceptualized based on data characteristics\nand user intentions; and Color Scheme Design, where specific colors are\nassigned to classes based on generated color theme, color mode, and user\nrequirements. Our system incorporates an interactive interface, providing\nnecessary visualization for choropleth map color design and allowing users to\ncustomize and refine color choices flexibly. Through user studies and\nevaluations, the system demonstrates acceptable usability, accuracy, and\nflexibility, with users highlighting the tool's efficiency and ease of use.",
      "tldr_zh": "本文提出 MapColorAI 系统，利用 Large Language Model (LLM) 和地图颜色设计原则，生成与数据上下文和用户意图相符的 choropleth maps 颜色方案，以解决传统 GIS 工具如 ArcGIS 和 QGIS 的易用性不足问题。系统采用三阶段过程，包括数据处理（分类数据）、颜色概念设计（基于数据特性和用户需求定义主题和模式），以及颜色方案设计（分配具体颜色并支持交互式自定义）。用户研究显示，该系统在可用性、准确性和灵活性方面表现出色，用户评价其高效且易于操作。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15502v1",
      "published_date": "2025-01-22 14:18:07 UTC",
      "updated_date": "2025-01-22 14:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:00:13.019879"
    },
    {
      "arxiv_id": "2502.10408v1",
      "title": "Knowledge Tracing in Programming Education Integrating Students' Questions",
      "title_zh": "知识追踪在编程教育中整合学生疑问",
      "authors": [
        "Doyoun Kim",
        "Suin Kim",
        "Yojan Jo"
      ],
      "abstract": "Knowledge tracing (KT) in programming education presents unique challenges\ndue to the complexity of coding tasks and the diverse methods students use to\nsolve problems. Although students' questions often contain valuable signals\nabout their understanding and misconceptions, traditional KT models often\nneglect to incorporate these questions as inputs to address these challenges.\nThis paper introduces SQKT (Students' Question-based Knowledge Tracing), a\nknowledge tracing model that leverages students' questions and automatically\nextracted skill information to enhance the accuracy of predicting students'\nperformance on subsequent problems in programming education. Our method creates\nsemantically rich embeddings that capture not only the surface-level content of\nthe questions but also the student's mastery level and conceptual\nunderstanding. Experimental results demonstrate SQKT's superior performance in\npredicting student completion across various Python programming courses of\ndiffering difficulty levels. In in-domain experiments, SQKT achieved a 33.1\\%\nabsolute improvement in AUC compared to baseline models. The model also\nexhibited robust generalization capabilities in cross-domain settings,\neffectively addressing data scarcity issues in advanced programming courses.\nSQKT can be used to tailor educational content to individual learning needs and\ndesign adaptive learning systems in computer science education.",
      "tldr_zh": "这篇论文针对编程教育中的知识追踪（KT）挑战，提出了一种名为SQKT的模型，该模型整合学生的提问和自动提取的技能信息，以提升对学生后续问题表现的预测准确性。SQKT通过创建语义丰富的嵌入，不仅捕捉问题的表面内容，还反映学生的掌握水平和概念理解。实验结果显示，在各种Python编程课程中，SQKT在领域内实验中比基线模型的AUC提高了33.1%，并在跨领域设置中展现出强大的泛化能力，解决了高级课程数据稀缺问题。该模型可用于个性化教育内容设计和构建计算机科学教育的自适应学习系统。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10408v1",
      "published_date": "2025-01-22 14:13:40 UTC",
      "updated_date": "2025-01-22 14:13:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:00:26.087205"
    },
    {
      "arxiv_id": "2501.12884v1",
      "title": "Learning Graph Node Embeddings by Smooth Pair Sampling",
      "title_zh": "通过平滑对采样学习图节点嵌入",
      "authors": [
        "Konstantin Kutzkov"
      ],
      "abstract": "Random walk-based node embedding algorithms have attracted a lot of attention\ndue to their scalability and ease of implementation. Previous research has\nfocused on different walk strategies, optimization objectives, and embedding\nlearning models. Inspired by observations on real data, we take a different\napproach and propose a new regularization technique. More precisely, the\nfrequencies of node pairs generated by the skip-gram model on random walk node\nsequences follow a highly skewed distribution which causes learning to be\ndominated by a fraction of the pairs. We address the issue by designing an\nefficient sampling procedure that generates node pairs according to their {\\em\nsmoothed frequency}. Theoretical and experimental results demonstrate the\nadvantages of our approach.",
      "tldr_zh": "本论文针对 random walk-based 节点嵌入算法中，skip-gram 模型生成的节点对频率分布高度偏斜的问题，提出了一种新的正则化技术。作者设计了 Smooth Pair Sampling 方法，通过根据 smoothed frequency 生成节点对，实现更均衡的学习过程。该方法在理论和实验上均显示出优势，提高了图节点嵌入的效率和效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for oral presentation at AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12884v1",
      "published_date": "2025-01-22 13:51:33 UTC",
      "updated_date": "2025-01-22 13:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:00:36.242678"
    },
    {
      "arxiv_id": "2501.12881v1",
      "title": "Reinforcement learning Based Automated Design of Differential Evolution Algorithm for Black-box Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Yang",
        "Rui Wang",
        "Kaiwen Li",
        "Ling Wang"
      ],
      "abstract": "Differential evolution (DE) algorithm is recognized as one of the most\neffective evolutionary algorithms, demonstrating remarkable efficacy in\nblack-box optimization due to its derivative-free nature. Numerous enhancements\nto the fundamental DE have been proposed, incorporating innovative mutation\nstrategies and sophisticated parameter tuning techniques to improve\nperformance. However, no single variant has proven universally superior across\nall problems. To address this challenge, we introduce a novel framework that\nemploys reinforcement learning (RL) to automatically design DE for black-box\noptimization through meta-learning. RL acts as an advanced meta-optimizer,\ngenerating a customized DE configuration that includes an optimal\ninitialization strategy, update rule, and hyperparameters tailored to a\nspecific black-box optimization problem. This process is informed by a detailed\nanalysis of the problem characteristics. In this proof-of-concept study, we\nutilize a double deep Q-network for implementation, considering a subset of 40\npossible strategy combinations and parameter optimizations simultaneously. The\nframework's performance is evaluated against black-box optimization benchmarks\nand compared with state-of-the-art algorithms. The experimental results\nhighlight the promising potential of our proposed framework.",
      "tldr_zh": "本文提出了一种基于强化学习 (RL) 的框架，用于自动设计 Differential Evolution (DE) 算法，以解决黑箱优化问题的挑战。该框架通过元学习 (meta-learning) 作为高级元优化器，生成针对特定问题的定制 DE 配置，包括最优初始化策略、更新规则和超参数，并根据问题特征进行分析。在实验中，使用双深 Q 网络 (Double Deep Q-Network) 实现该框架，并在黑箱优化基准上与最先进算法比较，结果显示其性能表现出色，具有显著的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12881v1",
      "published_date": "2025-01-22 13:41:47 UTC",
      "updated_date": "2025-01-22 13:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:00:49.532925"
    },
    {
      "arxiv_id": "2501.12869v1",
      "title": "Drone Carrier: An Integrated Unmanned Surface Vehicle for Autonomous Inspection and Intervention in GNSS-Denied Maritime Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Dong",
        "Muhayyu Ud Din",
        "Francesco Lagala",
        "Hailiang Kuang",
        "Jianjun Sun",
        "Siyuan Yang",
        "Irfan Hussain",
        "Shaoming He"
      ],
      "abstract": "This paper introduces an innovative drone carrier concept that is applied in\nmaritime port security or offshore rescue. This system works with a\nheterogeneous system consisting of multiple Unmanned Aerial Vehicles (UAVs) and\nUnmanned Surface Vehicles (USVs) to perform inspection and intervention tasks\nin GNSS-denied or interrupted environments. The carrier, an electric catamaran\nmeasuring 4m by 7m, features a 4m by 6m deck supporting automated takeoff and\nlanding for four DJI M300 drones, along with a 10kg-payload manipulator\noperable in up to level 3 sea conditions. Utilizing an offshore gimbal camera\nfor navigation, the carrier can autonomously navigate, approach and dock with\nnon-cooperative vessels, guided by an onboard camera, LiDAR, and Doppler\nVelocity Log (DVL) over a 3 km$^2$ area. UAVs equipped with onboard\nUltra-Wideband (UWB) technology execute mapping, detection, and manipulation\ntasks using a versatile gripper designed for wet, saline conditions.\nAdditionally, two UAVs can coordinate to transport large objects to the\nmanipulator or interact directly with them. These procedures are fully\nautomated and were successfully demonstrated at the Mohammed Bin Zayed\nInternational Robotic Competition (MBZIRC2024), where the drone carrier\nequipped with four UAVS and one manipulator, automatically accomplished the\nintervention tasks in sea-level-3 (wave height 1.25m) based on the rough target\ninformation.",
      "tldr_zh": "这篇论文介绍了 Drone Carrier，一种集成无人水面车辆（USV），用于在 GNSS-Denied 海上环境中进行自主检查和干预任务，如港口安全或海上救援。系统结合多个 Unmanned Aerial Vehicles (UAVs) 和 USV，通过搭载 4m x 7m 电动双体船、10kg 负载机械臂、LiDAR、Doppler Velocity Log (DVL) 和 Ultra-Wideband (UWB) 技术，实现自动导航、对接非合作船只以及映射、检测和物体操作。实验在 MBZIRC2024 比赛中成功演示，该系统在海况 3 级（波高 1.25m）下完成全部自动化任务，展示了其在恶劣环境下的可靠性和高效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 12pages",
      "pdf_url": "http://arxiv.org/pdf/2501.12869v1",
      "published_date": "2025-01-22 13:25:52 UTC",
      "updated_date": "2025-01-22 13:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:01:02.427029"
    },
    {
      "arxiv_id": "2501.12868v1",
      "title": "As Confidence Aligns: Exploring the Effect of AI Confidence on Human Self-confidence in Human-AI Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Jingshu Li",
        "Yitian Yang",
        "Q. Vera Liao",
        "Junti Zhang",
        "Yi-Chieh Lee"
      ],
      "abstract": "Complementary collaboration between humans and AI is essential for human-AI\ndecision making. One feasible approach to achieving it involves accounting for\nthe calibrated confidence levels of both AI and users. However, this process\nwould likely be made more difficult by the fact that AI confidence may\ninfluence users' self-confidence and its calibration. To explore these\ndynamics, we conducted a randomized behavioral experiment. Our results indicate\nthat in human-AI decision-making, users' self-confidence aligns with AI\nconfidence and such alignment can persist even after AI ceases to be involved.\nThis alignment then affects users' self-confidence calibration. We also found\nthe presence of real-time correctness feedback of decisions reduced the degree\nof alignment. These findings suggest that users' self-confidence is not\nindependent of AI confidence, which practitioners aiming to achieve better\nhuman-AI collaboration need to be aware of. We call for research focusing on\nthe alignment of human cognition and behavior with AI.",
      "tldr_zh": "这篇论文探讨了 AI 信心对人类自我信心在人类-AI 决策中的影响，通过随机行为实验研究了这一动态。结果显示，用户自我信心会与 AI 信心对齐，这种对齐即使 AI 不再参与也可能持续，从而影响用户的自我信心校准。同时，实验发现，提供实时正确性反馈可以降低这种对齐程度。作者强调，实践者需注意 AI 信心对用户信心的影响，并呼吁进一步研究人类认知与 AI 的对齐，以提升人类-AI 协作效率。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12868v1",
      "published_date": "2025-01-22 13:25:14 UTC",
      "updated_date": "2025-01-22 13:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:01:14.771717"
    },
    {
      "arxiv_id": "2501.12862v1",
      "title": "Mutation-Guided LLM-based Test Generation at Meta",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Foster",
        "Abhishek Gulati",
        "Mark Harman",
        "Inna Harper",
        "Ke Mao",
        "Jillian Ritchey",
        "Hervé Robert",
        "Shubho Sengupta"
      ],
      "abstract": "This paper describes Meta's ACH system for mutation-guided LLM-based test\ngeneration. ACH generates relatively few mutants (aka simulated faults),\ncompared to traditional mutation testing. Instead, it focuses on generating\ncurrently undetected faults that are specific to an issue of concern. From\nthese currently uncaught faults, ACH generates tests that can catch them,\nthereby `killing' the mutants and consequently hardening the platform against\nregressions. We use privacy concerns to illustrate our approach, but ACH can\nharden code against {\\em any} type of regression. In total, ACH was applied to\n10,795 Android Kotlin classes in 7 software platforms deployed by Meta, from\nwhich it generated 9,095 mutants and 571 privacy-hardening test cases. ACH also\ndeploys an LLM-based equivalent mutant detection agent that achieves a\nprecision of 0.79 and a recall of 0.47 (rising to 0.95 and 0.96 with simple\npre-processing). ACH was used by Messenger and WhatsApp test-a-thons where\nengineers accepted 73% of its tests, judging 36% to privacy relevant. We\nconclude that ACH hardens code against specific concerns and that, even when\nits tests do not directly tackle the specific concern, engineers find them\nuseful for their other benefits.",
      "tldr_zh": "这篇论文介绍了 Meta 的 ACH 系统，该系统采用突变引导（mutation-guided）的 LLM-based 测试生成方法，专注于创建针对特定问题（如隐私回归）尚未检测到的故障测试，从而强化代码的鲁棒性。ACH 通过生成较少的突变并使用 LLM 来产生捕获这些故障的测试，并在 LLM-based 等价突变检测中实现了 0.79 的精度和 0.47 的召回率（经简单预处理后提升至 0.95 和 0.96）。该系统应用于 10,795 个 Android Kotlin 类，产生了 9,095 个突变和 571 个隐私强化测试用例，在 Messenger 和 WhatsApp 的测试活动中，工程师接受了 73% 的测试，并认为其中 36% 与隐私相关。总体而言，ACH 不仅有效防范特定回归，还为代码维护提供了额外益处。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted to FSE 2025 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2501.12862v1",
      "published_date": "2025-01-22 13:14:02 UTC",
      "updated_date": "2025-01-22 13:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:01:29.137439"
    },
    {
      "arxiv_id": "2501.12844v2",
      "title": "GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model for Multi-organ Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruicheng Zhang",
        "Haowei Guo",
        "Zeyu Zhang",
        "Puxin Yan",
        "Shen Zhao"
      ],
      "abstract": "Multi-organ segmentation is a critical yet challenging task due to complex\nanatomical backgrounds, blurred boundaries, and diverse morphologies. This\nstudy introduces the Gradient-aware Adaptive Momentum Evolution Deep Snake\n(GAMED-Snake) model, which establishes a novel paradigm for contour-based\nsegmentation by integrating gradient-based learning with adaptive momentum\nevolution mechanisms. The GAMED-Snake model incorporates three major\ninnovations: First, the Distance Energy Map Prior (DEMP) generates a\npixel-level force field that effectively attracts contour points towards the\ntrue boundaries, even in scenarios with complex backgrounds and blurred edges.\nSecond, the Differential Convolution Inception Module (DCIM) precisely extracts\ncomprehensive energy gradients, significantly enhancing segmentation accuracy.\nThird, the Adaptive Momentum Evolution Mechanism (AMEM) employs cross-attention\nto establish dynamic features across different iterations of evolution,\nenabling precise boundary alignment for diverse morphologies. Experimental\nresults on four challenging multi-organ segmentation datasets demonstrate that\nGAMED-Snake improves the mDice metric by approximately 2% compared to\nstate-of-the-art methods. Code will be available at\nhttps://github.com/SYSUzrc/GAMED-Snake.",
      "tldr_zh": "本研究针对多器官分割面临的复杂解剖背景、模糊边界和多样形态等问题，提出了 GAMED-Snake 模型，这是一种整合梯度-based 学习和自适应动量演化机制的轮廓-based 分割范式。模型的关键创新包括：Distance Energy Map Prior (DEMP) 生成像素级力场以吸引轮廓点向真实边界；Differential Convolution Inception Module (DCIM) 精确提取能量梯度提升准确性；以及 Adaptive Momentum Evolution Mechanism (AMEM) 通过交叉注意力实现不同迭代间的动态特征对齐，以适应多样形态。实验结果显示，在四个多器官分割数据集上，GAMED-Snake 比最先进方法提高了约 2% 的 mDice 指标。代码将在 https://github.com/SYSUzrc/GAMED-Snake 公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12844v2",
      "published_date": "2025-01-22 12:45:09 UTC",
      "updated_date": "2025-03-03 03:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:01:38.772869"
    },
    {
      "arxiv_id": "2501.14828v1",
      "title": "An Ensemble Model with Attention Based Mechanism for Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Israa Al Badarneh",
        "Bassam Hammo",
        "Omar Al-Kadi"
      ],
      "abstract": "Image captioning creates informative text from an input image by creating a\nrelationship between the words and the actual content of an image. Recently,\ndeep learning models that utilize transformers have been the most successful in\nautomatically generating image captions. The capabilities of transformer\nnetworks have led to notable progress in several activities related to vision.\nIn this paper, we thoroughly examine transformer models, emphasizing the\ncritical role that attention mechanisms play. The proposed model uses a\ntransformer encoder-decoder architecture to create textual captions and a deep\nlearning convolutional neural network to extract features from the images. To\ncreate the captions, we present a novel ensemble learning framework that\nimproves the richness of the generated captions by utilizing several deep\nneural network architectures based on a voting mechanism that chooses the\ncaption with the highest bilingual evaluation understudy (BLEU) score. The\nproposed model was evaluated using publicly available datasets. Using the\nFlickr8K dataset, the proposed model achieved the highest BLEU-[1-3] scores\nwith rates of 0.728, 0.495, and 0.323, respectively. The suggested model\noutperformed the latest methods in Flickr30k datasets, determined by BLEU-[1-4]\nscores with rates of 0.798, 0.561, 0.387, and 0.269, respectively. The model\nefficacy was also obtained by the Semantic propositional image caption\nevaluation (SPICE) metric with a scoring rate of 0.164 for the Flicker8k\ndataset and 0.387 for the Flicker30k. Finally, ensemble learning significantly\nadvances the process of image captioning and, hence, can be leveraged in\nvarious applications across different domains.",
      "tldr_zh": "该论文提出了一种基于注意力机制的集成模型，用于图像字幕生成，通过Transformer编码器-解码器架构和卷积神经网络(CNN)提取图像特征。模型引入了一个新颖的集成学习框架，利用多个深度神经网络架构并通过投票机制选择BLEU分数最高的字幕，从而提升生成的字幕丰富性和准确性。在Flickr8K和Flickr30k数据集上评估，该模型在BLEU-[1-3]分数上分别达到0.728、0.495和0.323（Flickr8K），并在BLEU-[1-4]和SPICE指标上超越现有方法。整体结果表明，集成学习框架显著提高了图像字幕生成的质量，并可应用于多种领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.14828v1",
      "published_date": "2025-01-22 12:28:37 UTC",
      "updated_date": "2025-01-22 12:28:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:01:49.761011"
    },
    {
      "arxiv_id": "2501.12829v1",
      "title": "A transformer-based deep q learning approach for dynamic load balancing in software-defined networks",
      "title_zh": "翻译失败",
      "authors": [
        "Evans Tetteh Owusu",
        "Kwame Agyemang-Prempeh Agyekum",
        "Marinah Benneh",
        "Pius Ayorna",
        "Justice Owusu Agyemang",
        "George Nii Martey Colley",
        "James Dzisi Gazde"
      ],
      "abstract": "This study proposes a novel approach for dynamic load balancing in\nSoftware-Defined Networks (SDNs) using a Transformer-based Deep Q-Network\n(DQN). Traditional load balancing mechanisms, such as Round Robin (RR) and\nWeighted Round Robin (WRR), are static and often struggle to adapt to\nfluctuating traffic conditions, leading to inefficiencies in network\nperformance. In contrast, SDNs offer centralized control and flexibility,\nproviding an ideal platform for implementing machine learning-driven\noptimization strategies. The core of this research combines a Temporal Fusion\nTransformer (TFT) for accurate traffic prediction with a DQN model to perform\nreal-time dynamic load balancing. The TFT model predicts future traffic loads,\nwhich the DQN uses as input, allowing it to make intelligent routing decisions\nthat optimize throughput, minimize latency, and reduce packet loss. The\nproposed model was tested against RR and WRR in simulated environments with\nvarying data rates, and the results demonstrate significant improvements in\nnetwork performance. For the 500MB data rate, the DQN model achieved an average\nthroughput of 0.275 compared to 0.202 and 0.205 for RR and WRR, respectively.\nAdditionally, the DQN recorded lower average latency and packet loss. In the\n1000MB simulation, the DQN model outperformed the traditional methods in\nthroughput, latency, and packet loss, reinforcing its effectiveness in managing\nnetwork loads dynamically. This research presents an important step towards\nenhancing network performance through the integration of machine learning\nmodels within SDNs, potentially paving the way for more adaptive, intelligent\nnetwork management systems.",
      "tldr_zh": "这篇论文提出了一种基于 Transformer 的 Deep Q-Network (DQN) 方法，用于软件定义网络 (SDNs) 中的动态负载均衡，以克服传统静态方法如 Round Robin (RR) 和 Weighted Round Robin (WRR) 在处理流量波动时的低效问题。核心技术结合 Temporal Fusion Transformer (TFT) 进行精确的流量预测，DQN 则利用这些预测进行实时路由决策，优化网络吞吐量、降低延迟并减少数据包丢失。实验结果显示，在模拟环境中，DQN 在 500MB 数据率下实现平均吞吐量 0.275，比 RR 和 WRR 的 0.202 和 0.205 显著提高；在 1000MB 测试中，DQN 同样在吞吐量、延迟和数据包丢失方面表现出色。该方法为通过机器学习增强 SDNs 的自适应网络管理提供了重要进展。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.NI",
      "comment": "24 pages, 26 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12829v1",
      "published_date": "2025-01-22 12:16:30 UTC",
      "updated_date": "2025-01-22 12:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:02:02.920276"
    },
    {
      "arxiv_id": "2501.12826v1",
      "title": "Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek",
      "title_zh": "翻译失败",
      "authors": [
        "John Pavlopoulos",
        "Juli Bakagianni",
        "Kanella Pouli",
        "Maria Gavriilidou"
      ],
      "abstract": "Natural Language Processing (NLP) for lesser-resourced languages faces\npersistent challenges, including limited datasets, inherited biases from\nhigh-resource languages, and the need for domain-specific solutions. This study\naddresses these gaps for Modern Greek through three key contributions. First,\nwe evaluate the performance of open-source (Llama-70b) and closed-source\n(GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset\navailability, revealing task-specific strengths, weaknesses, and parity in\ntheir performance. Second, we expand the scope of Greek NLP by reframing\nAuthorship Attribution as a tool to assess potential data usage by LLMs in\npre-training, with high 0-shot accuracy suggesting ethical implications for\ndata provenance. Third, we showcase a legal NLP case study, where a Summarize,\nTranslate, and Embed (STE) methodology outperforms the traditional TF-IDF\napproach for clustering \\emph{long} legal texts. Together, these contributions\nprovide a roadmap to advance NLP in lesser-resourced languages, bridging gaps\nin model evaluation, task innovation, and real-world impact.",
      "tldr_zh": "本研究探讨了在资源较少的语言（如现代希腊语）中应用大型语言模型（LLM）的挑战，包括有限数据集、继承偏差和领域特定需求。通过三个关键贡献推进希腊 NLP：首先，评估开源模型（Llama-70b）和闭源模型（GPT-4o mini）在七个核心 NLP 任务上的性能，揭示了任务特定的优势、弱点和性能均衡。其次，将 Authorship Attribution 重新 framing 为评估 LLM 预训练数据使用的工具，显示高零样本准确率并引发数据来源的伦理问题。第三，通过 Summarize, Translate, and Embed (STE) methodology 在法律 NLP 案例中进行长文本聚类，优于传统 TF-IDF 方法。这些贡献为资源较少语言的 NLP 提供路线图，桥接模型评估、任务创新和实际影响的差距。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NLP, Modern Greek, benchmark, machine learning, language resources",
      "pdf_url": "http://arxiv.org/pdf/2501.12826v1",
      "published_date": "2025-01-22 12:06:16 UTC",
      "updated_date": "2025-01-22 12:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:02:15.408438"
    },
    {
      "arxiv_id": "2501.12823v1",
      "title": "To Measure or Not: A Cost-Sensitive, Selective Measuring Environment for Agricultural Management Decisions with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hilmy Baja",
        "Michiel Kallenberg",
        "Ioannis N. Athanasiadis"
      ],
      "abstract": "Farmers rely on in-field observations to make well-informed crop management\ndecisions to maximize profit and minimize adverse environmental impact.\nHowever, obtaining real-world crop state measurements is labor-intensive,\ntime-consuming and expensive. In most cases, it is not feasible to gather crop\nstate measurements before every decision moment. Moreover, in previous research\npertaining to farm management optimization, these observations are often\nassumed to be readily available without any cost, which is unrealistic. Hence,\nenabling optimization without the need to have temporally complete crop state\nobservations is important. An approach to that problem is to include measuring\nas part of decision making. As a solution, we apply reinforcement learning (RL)\nto recommend opportune moments to simultaneously measure crop features and\napply nitrogen fertilizer. With realistic considerations, we design an RL\nenvironment with explicit crop feature measuring costs. While balancing costs,\nwe find that an RL agent, trained with recurrent PPO, discovers adaptive\nmeasuring policies that follow critical crop development stages, with results\naligned by what domain experts would consider a sensible approach. Our results\nhighlight the importance of measuring when crop feature measurements are not\nreadily available.",
      "tldr_zh": "本研究针对农业管理决策中作物状态测量的成本和可行性问题，提出了一种成本敏感的选择性测量环境，利用Reinforcement Learning来决定何时测量作物特征并施肥。该环境通过显式纳入测量成本，并使用recurrent PPO训练RL代理，使代理能够学习适应性的测量策略，集中在作物关键发育阶段。实验结果显示，这种方法与领域专家的观点一致，有效平衡了成本和决策优化，强调了在测量资源有限时智能选择的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures, accepted after peer-review at the 39th Annual\n  AAAI Conference on Artificial Intelligence, AI for Social Impact Track,\n  February 2025, Philadelphia, Pennsylvania, USA",
      "pdf_url": "http://arxiv.org/pdf/2501.12823v1",
      "published_date": "2025-01-22 12:03:53 UTC",
      "updated_date": "2025-01-22 12:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:02:26.245025"
    },
    {
      "arxiv_id": "2501.12811v1",
      "title": "Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Lafedi Svet",
        "Arthur Brightwell",
        "Augustus Wildflower",
        "Cecily Marshwood"
      ],
      "abstract": "Modern cybersecurity landscapes increasingly demand sophisticated detection\nframeworks capable of identifying evolving threats with precision and\nadaptability. The proposed Zero-Space Detection framework introduces a novel\napproach that dynamically identifies latent behavioral patterns through\nunsupervised clustering and advanced deep learning techniques. Designed to\naddress the limitations of signature-based and heuristic methods, it operates\neffectively in high-velocity environments by integrating multi-phase filtering\nand ensemble learning for refined decision-making. Experimental evaluation\nreveals high detection rates across diverse ransomware families, including\nLockBit, Conti, REvil, and BlackMatter, while maintaining low false positive\nrates and scalable performance. Computational overhead remains minimal, with\naverage processing times ensuring compatibility with real-time systems even\nunder peak operational loads. The framework demonstrates resilience against\nadversarial strategies such as obfuscation and encryption speed variability,\nwhich frequently challenge conventional detection systems. Analysis across\nmultiple data sources highlights its versatility in handling diverse file types\nand operational contexts. Comprehensive metrics, including detection\nprobability, latency, and resource efficiency, validate its efficacy under\nreal-world conditions. Through its modular architecture, the framework achieves\nseamless integration with existing cybersecurity infrastructures without\nsignificant reconfiguration. The results demonstrate its robustness and\nscalability, offering a transformative paradigm for ransomware identification\nin dynamic and resource-constrained environments.",
      "tldr_zh": "该论文提出 Zero-Space Detection 框架，这是一种新型自主识别勒索软件的方法，通过无监督聚类和深度学习技术动态捕捉潜在行为模式，并在高速度环境中利用多阶段过滤和集成学习实现精确决策。相比传统签名和启发式方法，该框架在实验中对 LockBit、Conti、REvil 和 BlackMatter 等勒索软件家族显示出高检测率、低假阳性率，并保持低计算开销和实时兼容性。结果证明其对对抗策略如混淆和加密速度变化具有韧性，并通过模块化架构便于与其他网络安全基础设施集成，提供可扩展的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12811v1",
      "published_date": "2025-01-22 11:41:44 UTC",
      "updated_date": "2025-01-22 11:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:04:38.270149"
    },
    {
      "arxiv_id": "2501.12810v1",
      "title": "Machine Learning Modeling for Multi-order Human Visual Motion Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Zitang Sun",
        "Yen-Ju Chen",
        "Yung-Hao Yang",
        "Yuan Li",
        "Shin'ya Nishida"
      ],
      "abstract": "Our research aims to develop machines that learn to perceive visual motion as\ndo humans. While recent advances in computer vision (CV) have enabled DNN-based\nmodels to accurately estimate optical flow in naturalistic images, a\nsignificant disparity remains between CV models and the biological visual\nsystem in both architecture and behavior. This disparity includes humans'\nability to perceive the motion of higher-order image features (second-order\nmotion), which many CV models fail to capture because of their reliance on the\nintensity conservation law. Our model architecture mimics the cortical V1-MT\nmotion processing pathway, utilizing a trainable motion energy sensor bank and\na recurrent graph network. Supervised learning employing diverse naturalistic\nvideos allows the model to replicate psychophysical and physiological findings\nabout first-order (luminance-based) motion perception. For second-order motion,\ninspired by neuroscientific findings, the model includes an additional sensing\npathway with nonlinear preprocessing before motion energy sensing, implemented\nusing a simple multilayer 3D CNN block. When exploring how the brain acquired\nthe ability to perceive second-order motion in natural environments, in which\npure second-order signals are rare, we hypothesized that second-order\nmechanisms were critical when estimating robust object motion amidst optical\nfluctuations, such as highlights on glossy surfaces. We trained our\ndual-pathway model on novel motion datasets with varying material properties of\nmoving objects. We found that training to estimate object motion from\nnon-Lambertian materials naturally endowed the model with the capacity to\nperceive second-order motion, as can humans. The resulting model effectively\naligns with biological systems while generalizing to both first- and\nsecond-order motion phenomena in natural scenes.",
      "tldr_zh": "本研究旨在开发机器学习模型，使其像人类一样感知视觉运动，包括 first-order（基于亮度的）和 second-order（更高阶特征的）运动。模型模仿大脑的 V1-MT 运动处理路径，采用可训练的运动能量传感器银行、循环图网络和额外的非线性预处理（如多层 3D CNN 块），并通过监督学习在多样化自然视频数据集上训练，以复制人类的感知行为。实验发现，当模型训练估计非朗伯表面（如光泽物体）的运动时，它自然获得了 second-order motion 能力，与人类类似。该模型与生物视觉系统对齐，并能泛化到自然场景中的 first- and second-order motion 现象。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12810v1",
      "published_date": "2025-01-22 11:41:41 UTC",
      "updated_date": "2025-01-22 11:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:02:51.429570"
    },
    {
      "arxiv_id": "2501.12793v1",
      "title": "Revisit Self-Debugging with Self-Generated Tests for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiancai Chen",
        "Zhengwei Tao",
        "Kechi Zhang",
        "Changzhi Zhou",
        "Wanli Gu",
        "Yuanpeng He",
        "Mengdi Zhang",
        "Xunliang Cai",
        "Haiyan Zhao",
        "Zhi Jin"
      ],
      "abstract": "Large language models (LLMs) have shown significant advancements in code\ngeneration, but still face challenges on tasks beyond their basic capabilities.\nRecently, the notion of self-debugging has been proposed to boost the\nperformance of code generation by leveraging execution feedback from tests.\nDespite its promise, the availability of high-quality tests in real-world\nscenarios is limited. In this context, self-debugging with self-generated tests\nis a promising solution but lacks a full exploration of its limitations and\npractical potential. Therefore, we investigate its efficacy on diverse\nprogramming problems. To deepen our understanding, we propose two distinct\nparadigms for the process: post-execution and in-execution self-debugging.\nWithin the scope of self-contained Python programming tasks, we find that\npost-execution self-debugging struggles on basic problems but shows potential\nfor improvement on competitive ones, due to the bias introduced by\nself-generated tests. On the other hand, in-execution self-debugging enables\nLLMs to mitigate the bias by solely leveraging intermediate states during\nexecution, thereby enhancing code generation.",
      "tldr_zh": "该论文重新审视了自调试(self-debugging)方法，利用自生成测试(self-generated tests)来提升大语言模型(LLMs)在代码生成中的性能，尤其针对实际场景中测试资源有限的问题。研究者提出了两种范式：post-execution 自调试和 in-execution 自调试，并通过实验评估了它们在 Python 编程任务中的效果。结果显示，post-execution 自调试在基本问题上因自生成测试引入偏差而表现不佳，但在竞争性问题上显示出改善潜力；相比之下，in-execution 自调试通过利用执行过程中的中间状态，减少了偏差并显著提升了代码生成性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2501.12793v1",
      "published_date": "2025-01-22 10:54:19 UTC",
      "updated_date": "2025-01-22 10:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:03:02.186996"
    },
    {
      "arxiv_id": "2502.06789v1",
      "title": "Information-theoretic Bayesian Optimization: Survey and Tutorial",
      "title_zh": "基于信息理论的贝叶斯优化：综述与教程",
      "authors": [
        "Eduardo C. Garrido-Merchán"
      ],
      "abstract": "Several scenarios require the optimization of non-convex black-box functions,\nthat are noisy expensive to evaluate functions with unknown analytical\nexpression, whose gradients are hence not accessible. For example, the\nhyper-parameter tuning problem of machine learning models. Bayesian\noptimization is a class of methods with state-of-the-art performance delivering\na solution to this problem in real scenarios. It uses an iterative process that\nemploys a probabilistic surrogate model, typically a Gaussian process, of the\nobjective function to be optimized computing a posterior predictive\ndistribution of the black-box function. Based on the information given by this\nposterior predictive distribution, Bayesian optimization includes the\ncomputation of an acquisition function that represents, for every input space\npoint, the utility of evaluating that point in the next iteraiton if the\nobjective of the process is to retrieve a global extremum. This paper is a\nsurvey of the information theoretical acquisition functions, whose performance\ntypically outperforms the rest of acquisition functions. The main concepts of\nthe field of information theory are also described in detail to make the reader\naware of why information theory acquisition functions deliver great results in\nBayesian optimization and how can we approximate them when they are\nintractable. We also cover how information theory acquisition functions can be\nadapted to complex optimization scenarios such as the multi-objective,\nconstrained, non-myopic, multi-fidelity, parallel and asynchronous settings and\nprovide further lines of research.",
      "tldr_zh": "这篇论文对信息-theoretic Bayesian Optimization 进行了全面调查和教程，聚焦于使用信息理论方法优化非凸黑箱函数，这些函数评估成本高、噪声大且无解析表达式。论文详细介绍了贝叶斯优化的核心机制，包括使用 Gaussian process 作为代理模型计算后验预测分布，并通过 acquisition function 来决定下一次评估点，其中信息理论获取函数显示出优于其他函数的表现。作者还探讨了这些函数如何适应复杂场景，如多目标、约束、非-myopic、多-fidelity、并行和异步优化，并提出了进一步的研究方向，以提升贝叶斯优化在实际应用中的效能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "None",
      "pdf_url": "http://arxiv.org/pdf/2502.06789v1",
      "published_date": "2025-01-22 10:54:15 UTC",
      "updated_date": "2025-01-22 10:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:04:49.581001"
    },
    {
      "arxiv_id": "2501.12776v1",
      "title": "Data re-uploading in Quantum Machine Learning for time series: application to traffic forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Schetakis",
        "Paolo Bonfini",
        "Negin Alisoltani",
        "Konstantinos Blazakis",
        "Symeon I. Tsintzos",
        "Alexis Askitopoulos",
        "Davit Aghamalyan",
        "Panagiotis Fafoutellis",
        "Eleni I. Vlahogianni"
      ],
      "abstract": "Accurate traffic forecasting plays a crucial role in modern Intelligent\nTransportation Systems (ITS), as it enables real-time traffic flow management,\nreduces congestion, and improves the overall efficiency of urban transportation\nnetworks. With the rise of Quantum Machine Learning (QML), it has emerged a new\nparadigm possessing the potential to enhance predictive capabilities beyond\nwhat classical machine learning models can achieve. In the present work we\npursue a heuristic approach to explore the potential of QML, and focus on a\nspecific transport issue. In particular, as a case study we investigate a\ntraffic forecast task for a major urban area in Athens (Greece), for which we\npossess high-resolution data. In this endeavor we explore the application of\nQuantum Neural Networks (QNN), and, notably, we present the first application\nof quantum data re-uploading in the context of transport forecasting. This\ntechnique allows quantum models to better capture complex patterns, such as\ntraffic dynamics, by repeatedly encoding classical data into a quantum state.\nAside from providing a prediction model, we spend considerable effort in\ncomparing the performance of our hybrid quantum-classical neural networks with\nclassical deep learning approaches. Our results show that hybrid models achieve\ncompetitive accuracy with state-of-the-art classical methods, especially when\nthe number of qubits and re-uploading blocks is increased. While the classical\nmodels demonstrate lower computational demands, we provide evidence that\nincreasing the complexity of the quantum model improves predictive accuracy.\nThese findings indicate that QML techniques, and specifically the data\nre-uploading approach, hold promise for advancing traffic forecasting models\nand could be instrumental in addressing challenges inherent in ITS\nenvironments.",
      "tldr_zh": "这篇论文探讨了Quantum Machine Learning (QML) 在交通预测中的应用，针对雅典城市区域的高分辨率数据作为案例研究，首次将quantum data re-uploading 技术整合到Quantum Neural Networks (QNN) 中，以更好地捕捉交通动态的复杂模式。研究方法包括构建混合量子-经典神经网络，并与经典深度学习模型进行性能比较。结果显示，当增加量子比特和重上传块时，混合模型的预测准确性可与最先进经典方法竞争，尽管量子模型计算需求较高。这些发现表明，QML 尤其是quantum data re-uploading 方法，有潜力提升智能交通系统（ITS）的预测能力。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12776v1",
      "published_date": "2025-01-22 10:21:00 UTC",
      "updated_date": "2025-01-22 10:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:05:03.184930"
    },
    {
      "arxiv_id": "2502.10407v1",
      "title": "Addressing Bias in Generative AI: Challenges and Research Opportunities in Information Management",
      "title_zh": "处理生成式 AI 中的偏见：信息管理中的挑战和研究机会",
      "authors": [
        "Xiahua Wei",
        "Naveen Kumar",
        "Han Zhang"
      ],
      "abstract": "Generative AI technologies, particularly Large Language Models (LLMs), have\ntransformed information management systems but introduced substantial biases\nthat can compromise their effectiveness in informing business decision-making.\nThis challenge presents information management scholars with a unique\nopportunity to advance the field by identifying and addressing these biases\nacross extensive applications of LLMs. Building on the discussion on bias\nsources and current methods for detecting and mitigating bias, this paper seeks\nto identify gaps and opportunities for future research. By incorporating\nethical considerations, policy implications, and sociotechnical perspectives,\nwe focus on developing a framework that covers major stakeholders of Generative\nAI systems, proposing key research questions, and inspiring discussion. Our\ngoal is to provide actionable pathways for researchers to address bias in LLM\napplications, thereby advancing research in information management that\nultimately informs business practices. Our forward-looking framework and\nresearch agenda advocate interdisciplinary approaches, innovative methods,\ndynamic perspectives, and rigorous evaluation to ensure fairness and\ntransparency in Generative AI-driven information systems. We expect this study\nto serve as a call to action for information management scholars to tackle this\ncritical issue, guiding the improvement of fairness and effectiveness in\nLLM-based systems for business practice.",
      "tldr_zh": "这篇论文探讨了Generative AI，尤其是Large Language Models (LLMs)在信息管理系统中引入的偏见问题，这些偏见可能影响商业决策的准确性。作者分析了偏见来源、检测和缓解方法，并识别了研究空白，提出一个综合框架，该框架整合伦理考虑、政策影响和社会技术视角，涵盖主要利益相关者并提出关键研究问题。最终，该框架倡导跨学科方法、创新技术和严格评估，以推动LLMs应用的公平性和透明度，并为信息管理学者提供行动路径，提升AI驱动的商业实践。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Information & Management, forthcoming",
      "pdf_url": "http://arxiv.org/pdf/2502.10407v1",
      "published_date": "2025-01-22 10:14:31 UTC",
      "updated_date": "2025-01-22 10:14:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:05:13.500638"
    },
    {
      "arxiv_id": "2501.12770v1",
      "title": "On Tradeoffs in Learning-Augmented Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyad Benomar",
        "Vianney Perchet"
      ],
      "abstract": "The field of learning-augmented algorithms has gained significant attention\nin recent years. These algorithms, using potentially inaccurate predictions,\nmust exhibit three key properties: consistency, robustness, and smoothness. In\nscenarios where distributional information about predictions is available, a\nstrong expected performance is required. Typically, the design of these\nalgorithms involves a natural tradeoff between consistency and robustness, and\nprevious works aimed to achieve Pareto-optimal tradeoffs for specific problems.\nHowever, in some settings, this comes at the expense of smoothness. This paper\ndemonstrates that certain problems involve multiple tradeoffs between\nconsistency, robustness, smoothness, and average performance.",
      "tldr_zh": "学习增强算法（learning-augmented algorithms）利用可能不准确的预测，需要同时满足一致性（consistency）、鲁棒性（robustness）和平滑性（smoothness）等关键属性，并在有预测分布信息时实现强有力的预期性能。传统设计通常涉及consistency和robustness之间的自然权衡，以前研究针对特定问题实现了Pareto最优权衡，但这可能牺牲smoothness。本文通过分析证明，某些问题存在多重权衡，不仅包括consistency与robustness，还涉及smoothness和平均性能，从而为算法设计提供了更全面的洞见。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "Accepted as a conference paper at AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.12770v1",
      "published_date": "2025-01-22 10:12:18 UTC",
      "updated_date": "2025-01-22 10:12:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:05:25.461337"
    },
    {
      "arxiv_id": "2501.12766v1",
      "title": "NExtLong: Toward Effective Long-Context Training without Long Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Chaochen Gao",
        "Xing Wu",
        "Zijia Lin",
        "Debing Zhang",
        "Songlin Hu"
      ],
      "abstract": "Large language models (LLMs) with extended context windows have made\nsignificant strides yet remain a challenge due to the scarcity of long\ndocuments. Existing methods tend to synthesize long-context data but lack a\nclear mechanism to reinforce the long-range dependency modeling. To address\nthis limitation, we propose NExtLong, a novel framework for synthesizing\nlong-context data through Negative document Extension. NExtLong decomposes a\ndocument into multiple meta-chunks and extends the context by interleaving hard\nnegative distractors retrieved from pretraining corpora. This approach compels\nthe model to discriminate long-range dependent context from distracting\ncontent, enhancing its ability to model long-range dependencies. Extensive\nexperiments demonstrate that NExtLong achieves significant performance\nimprovements on the HELMET and RULER benchmarks compared to existing\nlong-context synthesis approaches and leading models, which are trained on\nnon-synthetic long documents. These findings highlight NExtLong's ability to\nreduce reliance on non-synthetic long documents, making it an effective\nframework for developing advanced long-context LLMs.",
      "tldr_zh": "该论文提出 NExtLong 框架，用于在缺乏长文档的情况下有效训练长上下文大型语言模型（LLMs），通过 Negative document Extension 方法合成数据来强化长距离依赖建模。具体而言，NExtLong 将文档分解为多个 meta-chunks，并通过从预训练语料库中检索硬负 distractors 与之交错，迫使模型区分相关上下文和干扰内容，从而提升其处理长范围依赖的能力。实验结果显示，NExtLong 在 HELMET 和 RULER 基准上比现有合成方法和领先模型显著提升性能，减少了对非合成长文档的依赖，为开发高级长上下文 LLMs 提供了一个高效框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Corresponding authors: xing wu, and songlin hu",
      "pdf_url": "http://arxiv.org/pdf/2501.12766v1",
      "published_date": "2025-01-22 10:01:54 UTC",
      "updated_date": "2025-01-22 10:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:05:37.384031"
    },
    {
      "arxiv_id": "2501.12749v1",
      "title": "Estimating the Conformal Prediction Threshold from Noisy Labels",
      "title_zh": "从噪声标签估计保形预测阈值",
      "authors": [
        "Coby Penso",
        "Jacob Goldberger",
        "Ethan Fetaya"
      ],
      "abstract": "Conformal Prediction (CP) is a method to control prediction uncertainty by\nproducing a small prediction set, ensuring a predetermined probability that the\ntrue class lies within this set. This is commonly done by defining a score,\nbased on the model predictions, and setting a threshold on this score using a\nvalidation set. In this study, we address the problem of CP calibration when we\nonly have access to a validation set with noisy labels. We show how we can\nestimate the noise-free conformal threshold based on the noisy labeled data.\nOur solution is flexible and can accommodate various modeling assumptions\nregarding the label contamination process, without needing any information\nabout the underlying data distribution or the internal mechanisms of the\nmachine learning classifier. We develop a coverage guarantee for uniform noise\nthat is effective even in tasks with a large number of classes. We dub our\napproach Noise-Aware Conformal Prediction (NACP) and show on several natural\nand medical image classification datasets, including ImageNet, that it\nsignificantly outperforms current noisy label methods and achieves results\ncomparable to those obtained with a clean validation set.",
      "tldr_zh": "本研究针对Conformal Prediction (CP)方法在噪声标签验证集下的校准问题，提出了一种Noise-Aware Conformal Prediction (NACP)框架，用于估计无噪声的预测阈值。该方法基于噪声标签数据，灵活适应各种标签污染假设，而无需依赖数据分布或模型内部机制，并为均匀噪声提供了有效的覆盖保证。实验结果显示，NACP在多个图像分类数据集（如ImageNet）上显著优于现有噪声标签方法，其性能与使用干净验证集相当。总的来说，这为CP在实际噪声环境下应用提供了可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12749v1",
      "published_date": "2025-01-22 09:35:58 UTC",
      "updated_date": "2025-01-22 09:35:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:05:49.490092"
    },
    {
      "arxiv_id": "2501.13136v1",
      "title": "Forecasting of Bitcoin Prices Using Hashrate Features: Wavelet and Deep Stacking Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Ramin Mousa",
        "Meysam Afrookhteh",
        "Hooman Khaloo",
        "Amir Ali Bengari",
        "Gholamreza Heidary"
      ],
      "abstract": "Digital currencies have become popular in the last decade due to their\nnon-dependency and decentralized nature. The price of these currencies has seen\na lot of fluctuations at times, which has increased the need for prediction. As\ntheir most popular, Bitcoin(BTC) has become a research hotspot. The main\nchallenge and trend of digital currencies, especially BTC, is price\nfluctuations, which require studying the basic price prediction model. This\nresearch presents a classification and regression model based on stack deep\nlearning that uses a wavelet to remove noise to predict movements and prices of\nBTC at different time intervals. The proposed model based on the stacking\ntechnique uses models based on deep learning, especially neural networks and\ntransformers, for one, seven, thirty and ninety-day forecasting. Three feature\nselection models, Chi2, RFE and Embedded, were also applied to the data in the\npre-processing stage. The classification model achieved 63\\% accuracy for\npredicting the next day and 64\\%, 67\\% and 82\\% for predicting the seventh,\nthirty and ninety days, respectively. For daily price forecasting, the\npercentage error was reduced to 0.58, while the error ranged from 2.72\\% to\n2.85\\% for seven- to ninety-day horizons. These results show that the proposed\nmodel performed better than other models in the literature.",
      "tldr_zh": "本研究提出了一种基于哈希率特征的比特币价格预测模型，结合小波（wavelet）去噪技术和深度堆叠（deep stacking）学习方法，针对不同时间间隔进行价格波动和运动预测。模型在预处理阶段使用Chi2、RFE和Embedded三种特征选择技术，并采用神经网络和Transformer等深度学习模型进行1日、7日、30日和90日的预测。结果显示，分类模型的准确率最高达82%（90日预测），而回归模型的百分比错误率降至0.58%（1日预测）和2.72%至2.85%（7-90日预测），整体表现优于文献中其他模型。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "arXiv admin note: text overlap with arXiv:2402.05943 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2501.13136v1",
      "published_date": "2025-01-22 09:31:00 UTC",
      "updated_date": "2025-01-22 09:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:06:01.654679"
    },
    {
      "arxiv_id": "2501.12746v4",
      "title": "EvidenceMap: Learning Evidence Analysis to Unleash the Power of Small Language Models for Biomedical Question Answering",
      "title_zh": "EvidenceMap：学习证据分析以释放小型语言模型在生物医学问答中的潜力",
      "authors": [
        "Chang Zong",
        "Jian Wan",
        "Siliang Tang",
        "Lei Zhang"
      ],
      "abstract": "When addressing professional questions in the biomedical domain, humans\ntypically acquire multiple pieces of information as evidence and engage in\nmultifaceted analysis to provide high-quality answers. Current LLM-based\nquestion answering methods lack a detailed definition and learning process for\nevidence analysis, leading to the risk of error propagation and hallucinations\nwhile using evidence. Although increasing the parameter size of LLMs can\nalleviate these issues, it also presents challenges in training and deployment\nwith limited resources. In this study, we propose EvidenceMap, which aims to\nenable a tiny pre-trained language model to explicitly learn multiple aspects\nof biomedical evidence, including supportive evaluation, logical correlation\nand content summarization, thereby latently guiding a small generative model\n(around 3B parameters) to provide textual responses. Experimental results\ndemonstrate that our method, learning evidence analysis by fine-tuning a model\nwith only 66M parameters, exceeds the RAG method with an 8B LLM by 19.9% and\n5.7% in reference-based quality and accuracy, respectively.",
      "tldr_zh": "本研究针对生物医学问答中的问题，指出当前基于LLM的方法缺乏证据分析的定义和学习过程，导致错误传播和幻觉风险。提出EvidenceMap框架，让小型预训练语言模型显式学习证据的多方面，包括支持性评估、逻辑相关性和内容总结，从而指导约3B参数的生成模型提供高质量文本响应。实验结果显示，通过微调一个仅66M参数的模型，EvidenceMap在基于参考的质量和准确性上分别比使用8B LLM的RAG方法提升19.9%和5.7%。这为资源有限场景下提升小型语言模型的生物医学问答能力提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12746v4",
      "published_date": "2025-01-22 09:27:11 UTC",
      "updated_date": "2025-02-14 01:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:06:13.849137"
    },
    {
      "arxiv_id": "2501.12728v1",
      "title": "A Call for Critically Rethinking and Reforming Data Analysis in Empirical Software Engineering",
      "title_zh": "呼吁批判性地重新思考和改革经验软件工程中的数据分析",
      "authors": [
        "Matteo Esposito",
        "Mikel Robredo",
        "Murali Sridharan",
        "Guilherme Horta Travassos",
        "Rafael Peñaloza",
        "Valentina Lenarduzzi"
      ],
      "abstract": "Context: Empirical Software Engineering (ESE) drives innovation in SE through\nqualitative and quantitative studies. However, concerns about the correct\napplication of empirical methodologies have existed since the 2006 Dagstuhl\nseminar on SE. Objective: To analyze three decades of SE research, identify\nmistakes in statistical methods, and evaluate experts' ability to detect and\naddress these issues. Methods: We conducted a literature survey of ~27,000\nempirical studies, using LLMs to classify statistical methodologies as adequate\nor inadequate. Additionally, we selected 30 primary studies and held a workshop\nwith 33 ESE experts to assess their ability to identify and resolve statistical\nissues. Results: Significant statistical issues were found in the primary\nstudies, and experts showed limited ability to detect and correct these\nmethodological problems, raising concerns about the broader ESE community's\nproficiency in this area. Conclusions. Despite our study's eventual\nlimitations, its results shed light on recurring issues from promoting\ninformation copy-and-paste from past authors' works and the continuous\npublication of inadequate approaches that promote dubious results and\njeopardize the spread of the correct statistical strategies among researchers.\nBesides, it justifies further investigation into empirical rigor in software\nengineering to expose these recurring issues and establish a framework for\nreassessing our field's foundation of statistical methodology application.\nTherefore, this work calls for critically rethinking and reforming data\nanalysis in empirical software engineering, paving the way for our work soon.",
      "tldr_zh": "这篇论文呼吁 critically rethinking and reforming 经验软件工程(ESE)中的数据分析，针对统计方法应用中的长期问题进行分析。研究者通过调查约27,000个ESE研究并使用LLMs分类统计方法是否合适，以及组织33位专家研讨会对30个主要研究进行评估，发现了显著的统计错误，且专家在检测和纠正这些问题方面能力有限。尽管研究存在局限性，这些发现突显了信息复制粘贴和不适当方法发布的风险，并推动进一步调查以建立更可靠的统计框架。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12728v1",
      "published_date": "2025-01-22 09:05:01 UTC",
      "updated_date": "2025-01-22 09:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:06:26.200224"
    },
    {
      "arxiv_id": "2501.13135v1",
      "title": "Applications and Challenges of AI and Microscopy in Life Science Research: A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Himanshu Buckchash",
        "Gyanendra Kumar Verma",
        "Dilip K. Prasad"
      ],
      "abstract": "The complexity of human biology and its intricate systems holds immense\npotential for advancing human health, disease treatment, and scientific\ndiscovery. However, traditional manual methods for studying biological\ninteractions are often constrained by the sheer volume and complexity of\nbiological data. Artificial Intelligence (AI), with its proven ability to\nanalyze vast datasets, offers a transformative approach to addressing these\nchallenges. This paper explores the intersection of AI and microscopy in life\nsciences, emphasizing their potential applications and associated challenges.\nWe provide a detailed review of how various biological systems can benefit from\nAI, highlighting the types of data and labeling requirements unique to this\ndomain. Particular attention is given to microscopy data, exploring the\nspecific AI techniques required to process and interpret this information. By\naddressing challenges such as data heterogeneity and annotation scarcity, we\noutline potential solutions and emerging trends in the field. Written primarily\nfrom an AI perspective, this paper aims to serve as a valuable resource for\nresearchers working at the intersection of AI, microscopy, and biology. It\nsummarizes current advancements, key insights, and open problems, fostering an\nunderstanding that encourages interdisciplinary collaborations. By offering a\ncomprehensive yet concise synthesis of the field, this paper aspires to\ncatalyze innovation, promote cross-disciplinary engagement, and accelerate the\nadoption of AI in life science research.",
      "tldr_zh": "这篇综述论文探讨了 AI 在生命科学研究中与显微镜的交叉应用及其挑战，强调 AI 如何通过分析大量生物数据来克服传统方法的局限性。论文详细回顾了各种生物系统从 AI 受益的方面，包括显微镜数据的处理技术（如数据类型和标注要求），并针对数据异质性和标注稀缺等问题提出潜在解决方案和新兴趋势。从 AI 视角出发，该研究总结了当前进展、关键洞见和开放问题，旨在促进交叉学科合作并加速 AI 在生命科学中的采用。",
      "categories": [
        "q-bio.OT",
        "cs.AI",
        "physics.med-ph",
        "q-bio.SC"
      ],
      "primary_category": "q-bio.OT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13135v1",
      "published_date": "2025-01-22 08:32:36 UTC",
      "updated_date": "2025-01-22 08:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:06:37.846388"
    },
    {
      "arxiv_id": "2501.12709v1",
      "title": "Practical quantum federated learning and its experimental demonstration",
      "title_zh": "实用的量子联邦学习及其实验演示",
      "authors": [
        "Zhi-Ping Liu",
        "Xiao-Yu Cao",
        "Hao-Wen Liu",
        "Xiao-Ran Sun",
        "Yu Bao",
        "Yu-Shuo Lu",
        "Hua-Lei Yin",
        "Zeng-Bing Chen"
      ],
      "abstract": "Federated learning is essential for decentralized, privacy-preserving model\ntraining in the data-driven era. Quantum-enhanced federated learning leverages\nquantum resources to address privacy and scalability challenges, offering\nsecurity and efficiency advantages beyond classical methods. However, practical\nand scalable frameworks addressing privacy concerns in the quantum computing\nera remain undeveloped. Here, we propose a practical quantum federated learning\nframework on quantum networks, utilizing distributed quantum secret keys to\nprotect local model updates and enable secure aggregation with\ninformation-theoretic security. We experimentally validate our framework on a\n4-client quantum network with a scalable structure. Extensive numerical\nexperiments on both quantum and classical datasets show that adding a quantum\nclient significantly enhances the trained global model's ability to classify\nmultipartite entangled and non-stabilizer quantum datasets. Simulations further\ndemonstrate scalability to 200 clients with classical models trained on the\nMNIST dataset, reducing communication costs by $75\\%$ through advanced model\ncompression techniques and achieving rapid training convergence. Our work\nprovides critical insights for building scalable, efficient, and quantum-secure\nmachine learning systems for the coming quantum internet era.",
      "tldr_zh": "本研究提出了一种实用的量子联邦学习（federated learning）框架，利用分布式量子密钥（distributed quantum secret keys）保护本地模型更新，并实现信息理论安全（information-theoretic security）的聚合，以解决隐私和可扩展性挑战。\n\n在4客户端量子网络上进行实验验证，结果显示添加量子客户端显著提升了全局模型对多粒子纠缠和非稳定器量子数据集的分类能力。\n\n数值模拟进一步证明，该框架可扩展到200客户端，在MNIST数据集上训练经典模型时，通信成本减少75%，并实现快速训练收敛。\n\n这项工作为量子互联网时代构建可扩展、高效且量子安全的机器学习系统提供了关键洞见。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "quant-ph",
      "comment": "21 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.12709v1",
      "published_date": "2025-01-22 08:28:11 UTC",
      "updated_date": "2025-01-22 08:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:06:49.679929"
    },
    {
      "arxiv_id": "2501.12703v1",
      "title": "HEPPO: Hardware-Efficient Proximal Policy Optimization -- A Universal Pipelined Architecture for Generalized Advantage Estimation",
      "title_zh": "HEPPO: 硬件高效的近端策略优化——用于广义",
      "authors": [
        "Hazem Taha",
        "Ameer M. S. Abdelhadi"
      ],
      "abstract": "This paper introduces HEPPO, an FPGA-based accelerator designed to optimize\nthe Generalized Advantage Estimation (GAE) stage in Proximal Policy\nOptimization (PPO). Unlike previous approaches that focused on trajectory\ncollection and actor-critic updates, HEPPO addresses GAE's computational\ndemands with a parallel, pipelined architecture implemented on a single\nSystem-on-Chip (SoC). This design allows for the adaptation of various hardware\naccelerators tailored for different PPO phases. A key innovation is our\nstrategic standardization technique, which combines dynamic reward\nstandardization and block standardization for values, followed by 8-bit uniform\nquantization. This method stabilizes learning, enhances performance, and\nmanages memory bottlenecks, achieving a 4x reduction in memory usage and a 1.5x\nincrease in cumulative rewards. We propose a solution on a single SoC device\nwith programmable logic and embedded processors, delivering throughput orders\nof magnitude higher than traditional CPU-GPU systems. Our single-chip solution\nminimizes communication latency and throughput bottlenecks, significantly\nboosting PPO training efficiency. Experimental results show a 30% increase in\nPPO speed and a substantial reduction in memory access time, underscoring\nHEPPO's potential for broad applicability in hardware-efficient reinforcement\nlearning algorithms.",
      "tldr_zh": "本文提出 HEPPO，一种基于 FPGA 的硬件高效加速器，针对 Proximal Policy Optimization (PPO) 中的 Generalized Advantage Estimation (GAE) 阶段采用并行流水线架构，实现对不同 PPO 阶段的适应性优化。关键创新包括战略标准化技术，如动态奖励标准化、块标准化和 8-bit 统一量化，这稳定了学习过程，减少了内存使用 4 倍，并提升了累计奖励 1.5 倍。实验结果显示，HEPPO 在单个 System-on-Chip (SoC) 设备上将 PPO 训练速度提高 30%，显著降低通信延迟和内存访问时间，适用于硬件高效的强化学习算法。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "B.2; B.3; B.5; B.6; B.7; C.1; C.3; I.2"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted at the 2024 International Conference on Field Programmable\n  Technology (ICFPT 2023)",
      "pdf_url": "http://arxiv.org/pdf/2501.12703v1",
      "published_date": "2025-01-22 08:18:56 UTC",
      "updated_date": "2025-01-22 08:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:07:02.418102"
    },
    {
      "arxiv_id": "2501.12690v2",
      "title": "Growth strategies for arbitrary DAG neural architectures",
      "title_zh": "任意 DAG 神经网络架构",
      "authors": [
        "Stella Douka",
        "Manon Verbockhaven",
        "Théo Rudkiewicz",
        "Stéphane Rivaud",
        "François P. Landes",
        "Sylvain Chevallier",
        "Guillaume Charpiat"
      ],
      "abstract": "Deep learning has shown impressive results obtained at the cost of training\nhuge neural networks. However, the larger the architecture, the higher the\ncomputational, financial, and environmental costs during training and\ninference. We aim at reducing both training and inference durations. We focus\non Neural Architecture Growth, which can increase the size of a small model\nwhen needed, directly during training using information from the\nbackpropagation. We expand existing work and freely grow neural networks in the\nform of any Directed Acyclic Graph by reducing expressivity bottlenecks in the\narchitecture. We explore strategies to reduce excessive computations and steer\nnetwork growth toward more parameter-efficient architectures.",
      "tldr_zh": "本研究针对深度学习模型规模增大导致的训练和推理的高计算、金融及环境成本，提出了一种 Neural Architecture Growth 策略，用于动态扩展小型神经网络。方法利用反向传播信息，直接在训练过程中增长任意 Directed Acyclic Graph (DAG) 架构，同时减少表达性瓶颈和过度计算。论文扩展了现有工作，并探索了引导网络向更参数高效架构发展的策略，最终旨在显著降低训练和推理时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12690v2",
      "published_date": "2025-01-22 08:02:01 UTC",
      "updated_date": "2025-02-14 08:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:07:12.548712"
    },
    {
      "arxiv_id": "2501.13133v1",
      "title": "Graph Representation Learning with Diffusion Generative Models",
      "title_zh": "基于扩散生成模型的图表示学习",
      "authors": [
        "Daniel Wesego"
      ],
      "abstract": "Diffusion models have established themselves as state-of-the-art generative\nmodels across various data modalities, including images and videos, due to\ntheir ability to accurately approximate complex data distributions. Unlike\ntraditional generative approaches such as VAEs and GANs, diffusion models\nemploy a progressive denoising process that transforms noise into meaningful\ndata over multiple iterative steps. This gradual approach enhances their\nexpressiveness and generation quality. Not only that, diffusion models have\nalso been shown to extract meaningful representations from data while learning\nto generate samples. Despite their success, the application of diffusion models\nto graph-structured data remains relatively unexplored, primarily due to the\ndiscrete nature of graphs, which necessitates discrete diffusion processes\ndistinct from the continuous methods used in other domains. In this work, we\nleverage the representational capabilities of diffusion models to learn\nmeaningful embeddings for graph data. By training a discrete diffusion model\nwithin an autoencoder framework, we enable both effective autoencoding and\nrepresentation learning tailored to the unique characteristics of\ngraph-structured data. We only need the encoder at the end to extract\nrepresentations. Our approach demonstrates the potential of discrete diffusion\nmodels to be used for graph representation learning.",
      "tldr_zh": "扩散模型（Diffusion models）作为先进的生成模型，已在图像和视频等领域表现出色，能够通过逐步去噪过程逼近复杂数据分布，并提取有意义的表示，但其在图结构数据的应用仍未充分探索，主要受限于图的离散性质。  \n本文提出一种基于离散扩散模型的自编码器框架，用于图表示学习，通过训练模型实现有效的图数据自编码和嵌入提取，最终仅需编码器即可获得高质量表示。  \n该方法证明了离散扩散模型在处理图独特特性的潜力，为图生成和表示学习提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13133v1",
      "published_date": "2025-01-22 07:12:10 UTC",
      "updated_date": "2025-01-22 07:12:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:07:25.589760"
    },
    {
      "arxiv_id": "2501.13967v2",
      "title": "FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis",
      "title_zh": "FedDAG：联邦领域对抗生成用于可泛化医疗",
      "authors": [
        "Haoxuan Che",
        "Yifei Wu",
        "Haibo Jin",
        "Yong Xia",
        "Hao Chen"
      ],
      "abstract": "Federated domain generalization aims to train a global model from multiple\nsource domains and ensure its generalization ability to unseen target domains.\nDue to the target domain being with unknown domain shifts, attempting to\napproximate these gaps by source domains may be the key to improving model\ngeneralization capability. Existing works mainly focus on sharing and\nrecombining local domain-specific attributes to increase data diversity and\nsimulate potential domain shifts. However, these methods may be insufficient\nsince only the local attribute recombination can be hard to touch the\nout-of-distribution of global data. In this paper, we propose a\nsimple-yet-efficient framework named Federated Domain Adversarial Generation\n(FedDAG). It aims to simulate the domain shift and improve the model\ngeneralization by adversarially generating novel domains different from local\nand global source domains. Specifically, it generates novel-style images by\nmaximizing the instance-level feature discrepancy between original and\ngenerated images and trains a generalizable task model by minimizing their\nfeature discrepancy. Further, we observed that FedDAG could cause different\nperformance improvements for local models. It may be due to inherent data\nisolation and heterogeneity among clients, exacerbating the imbalance in their\ngeneralization contributions to the global model. Ignoring this imbalance can\nlead the global model's generalization ability to be sub-optimal, further\nlimiting the novel domain generation procedure. Thus, to mitigate this\nimbalance, FedDAG hierarchically aggregates local models at the within-client\nand across-client levels by using the sharpness concept to evaluate client\nmodel generalization contributions. Extensive experiments across four medical\nbenchmarks demonstrate FedDAG's ability to enhance generalization in federated\nmedical scenarios.",
      "tldr_zh": "该论文提出FedDAG框架，用于联邦域泛化（Federated domain generalization），旨在通过对抗生成新颖域来模拟未知域偏移，提高医疗图像分析模型的泛化能力。具体方法包括最大化原始和生成图像之间的实例级特征差异来生成新风格图像，同时最小化这些差异以训练更鲁棒的全局模型，并采用基于sharpness概念的分层聚合策略（如客户端内和跨客户端水平）来平衡客户端的泛化贡献，避免数据异质性带来的不平衡问题。实验在四个医疗基准上证明，FedDAG显著提升了联邦学习场景中的模型泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13967v2",
      "published_date": "2025-01-22 07:08:45 UTC",
      "updated_date": "2025-01-27 07:48:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:07:37.244056"
    },
    {
      "arxiv_id": "2501.16365v1",
      "title": "CAND: Cross-Domain Ambiguity Inference for Early Detecting Nuanced Illness Deterioration",
      "title_zh": "CAND：跨领域模糊性推理用于早期检测细微疾病恶化",
      "authors": [
        "Lo Pang-Yun Ting",
        "Zhen Tan",
        "Hong-Pei Chen",
        "Cheng-Te Li",
        "Po-Lin Chen",
        "Kun-Ta Chuang",
        "Huan Liu"
      ],
      "abstract": "Early detection of patient deterioration is essential for timely treatment,\nwith vital signs like heart rates being key health indicators. Existing methods\ntend to solely analyze vital sign waveforms, ignoring transition relationships\nof waveforms within each vital sign and the correlation strengths among various\nvital signs. Such studies often overlook nuanced illness deterioration, which\nis the early sign of worsening health but is difficult to detect. In this\npaper, we introduce CAND, a novel method that organizes the transition\nrelationships and the correlations within and among vital signs as\ndomain-specific and cross-domain knowledge. CAND jointly models these knowledge\nin a unified representation space, considerably enhancing the early detection\nof nuanced illness deterioration. In addition, CAND integrates a Bayesian\ninference method that utilizes augmented knowledge from domain-specific and\ncross-domain knowledge to address the ambiguities in correlation strengths.\nWith this architecture, the correlation strengths can be effectively inferred\nto guide joint modeling and enhance representations of vital signs. This allows\na more holistic and accurate interpretation of patient health. Our experiments\non a real-world ICU dataset demonstrate that CAND significantly outperforms\nexisting methods in both effectiveness and earliness in detecting nuanced\nillness deterioration. Moreover, we conduct a case study for the interpretable\ndetection process to showcase the practicality of CAND.",
      "tldr_zh": "本研究提出CAND方法，用于早期检测细微的疾病恶化问题，通过组织生命体征（如心率）内部的过渡关系及体征间的相关性作为领域特定和cross-domain knowledge，并在统一表示空间中联合建模这些知识。CAND整合Bayesian inference来处理相关性模糊性，从而有效推断相关强度并提升体征表示的准确性。实验结果显示，在真实ICU数据集上，CAND在检测的有效性和提前性上显著优于现有方法，并通过案例研究展示了其可解释的检测过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16365v1",
      "published_date": "2025-01-22 06:44:43 UTC",
      "updated_date": "2025-01-22 06:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:07:49.744012"
    },
    {
      "arxiv_id": "2502.10406v1",
      "title": "FishBargain: An LLM-Empowered Bargaining Agent for Online Fleamarket Platform Sellers",
      "title_zh": "翻译失败",
      "authors": [
        "Dexin Kong",
        "Xu Yan",
        "Ming Chen",
        "Shuguang Han",
        "Jufeng Chen",
        "Fei Huang"
      ],
      "abstract": "Different from traditional Business-to-Consumer e-commerce platforms~(e.g.,\nAmazon), online fleamarket platforms~(e.g., Craigslist) mainly focus on\nindividual sellers who are lack of time investment and business proficiency.\nIndividual sellers often struggle with the bargaining process and thus the deal\nis unaccomplished. Recent advancements in Large Language Models(LLMs)\ndemonstrate huge potential in various dialogue tasks, but those tasks are\nmainly in the form of passively following user's instruction. Bargaining, as a\nform of proactive dialogue task, represents a distinct art of dialogue\nconsidering the dynamism of environment and uncertainty of adversary\nstrategies. In this paper, we propose an LLM-empowered bargaining agent\ndesigned for online fleamarket platform sellers, named as FishBargain.\nSpecifically, FishBargain understands the chat context and product information,\nchooses both action and language skill considering possible adversary actions\nand generates utterances. FishBargain has been tested by thousands of\nindividual sellers on one of the largest online fleamarket platforms~(Xianyu)\nin China. Both qualitative and quantitative experiments demonstrate that\nFishBargain can effectively help sellers make more deals.",
      "tldr_zh": "该研究针对在线跳蚤市场平台（如Craigslist）的个人卖家，提出FishBargain，一种基于LLM（Large Language Models）的讨价还价代理，以解决卖家在主动对话任务中面临的挑战，如环境动态性和对手策略的不确定性。FishBargain能够理解聊天上下文和产品信息，选择合适的行动和语言技能，并生成回应，以主动推动谈判过程。在中国最大的在线跳蚤市场平台（Xianyu）上进行的定性和定量实验显示，该代理已帮助数千名卖家有效完成更多交易，证明了其在提升交易成功率方面的实际价值。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10406v1",
      "published_date": "2025-01-22 06:12:25 UTC",
      "updated_date": "2025-01-22 06:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:08:01.849890"
    },
    {
      "arxiv_id": "2501.12668v3",
      "title": "NBDI: A Simple and Effective Termination Condition for Skill Extraction from Task-Agnostic Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Myunsoo Kim",
        "Hayeong Lee",
        "Seong-Woong Shim",
        "JunHo Seo",
        "Byung-Jun Lee"
      ],
      "abstract": "Intelligent agents are able to make decisions based on different levels of\ngranularity and duration. Recent advances in skill learning enabled the agent\nto solve complex, long-horizon tasks by effectively guiding the agent in\nchoosing appropriate skills. However, the practice of using fixed-length skills\ncan easily result in skipping valuable decision points, which ultimately limits\nthe potential for further exploration and faster policy learning. In this work,\nwe propose to learn a simple and effective termination condition that\nidentifies decision points through a state-action novelty module that leverages\nagent experience data. Our approach, Novelty-based Decision Point\nIdentification (NBDI), outperforms previous baselines in complex, long-horizon\ntasks, and remains effective even in the presence of significant variations in\nthe environment configurations of downstream tasks, highlighting the importance\nof decision point identification in skill learning.",
      "tldr_zh": "本文提出 NBDI（Novelty-based Decision Point Identification），一种简单有效的终止条件，用于从任务无关演示（task-agnostic demonstrations）中提取技能，以解决固定长度技能容易跳过决策点的问题。NBDI 通过状态-动作新颖性模块利用代理经验数据来识别关键决策点，从而提升技能学习的效果。实验结果显示，该方法在复杂、长期任务中优于现有基线，即使下游任务的环境配置有显著变化时仍保持高效，强调了决策点识别在技能学习中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12668v3",
      "published_date": "2025-01-22 06:08:15 UTC",
      "updated_date": "2025-05-20 04:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:08:13.689031"
    },
    {
      "arxiv_id": "2502.17443v1",
      "title": "AI Agentic workflows and Enterprise APIs: Adapting API architectures for the age of AI agents",
      "title_zh": "翻译失败",
      "authors": [
        "Vaibhav Tupe",
        "Shrinath Thube"
      ],
      "abstract": "The rapid advancement of Generative AI has catalyzed the emergence of\nautonomous AI agents, presenting unprecedented challenges for enterprise\ncomputing infrastructures. Current enterprise API architectures are\npredominantly designed for human-driven, predefined interaction patterns,\nrendering them ill-equipped to support intelligent agents' dynamic,\ngoal-oriented behaviors. This research systematically examines the\narchitectural adaptations for enterprise APIs to support AI agentic workflows\neffectively. Through a comprehensive analysis of existing API design paradigms,\nagent interaction models, and emerging technological constraints, the paper\ndevelops a strategic framework for API transformation. The study employs a\nmixed-method approach, combining theoretical modeling, comparative analysis,\nand exploratory design principles to address critical challenges in\nstandardization, performance, and intelligent interaction. The proposed\nresearch contributes a conceptual model for next-generation enterprise APIs\nthat can seamlessly integrate with autonomous AI agent ecosystems, offering\nsignificant implications for future enterprise computing architectures.",
      "tldr_zh": "这篇论文探讨了生成式 AI 的快速发展如何催生自主 AI agents，并对企业计算基础设施提出挑战，因为现有 Enterprise APIs 主要设计用于人类驱动的预定义交互模式，无法适应 AI agents 的动态、目标导向行为。通过系统分析现有 API 设计范式、代理交互模型和技术约束，研究采用混合方法（包括理论建模、比较分析和探索性设计原则）来开发一个战略框架。论文的主要贡献是提出一个概念模型，用于构建下一代 Enterprise APIs，以无缝集成自主 AI agents 生态系统，并为未来企业计算架构提供重要启示。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.0; D.2.11; D.2.12; K.6.5; I.2.11"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17443v1",
      "published_date": "2025-01-22 05:55:16 UTC",
      "updated_date": "2025-01-22 05:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:08:25.332695"
    },
    {
      "arxiv_id": "2501.16364v1",
      "title": "Multivariate Time Series Anomaly Detection by Capturing Coarse-Grained Intra- and Inter-Variate Dependencies",
      "title_zh": "翻译失败",
      "authors": [
        "Yongzheng Xie",
        "Hongyu Zhang",
        "Muhammad Ali Babar"
      ],
      "abstract": "Multivariate time series anomaly detection is essential for failure\nmanagement in web application operations, as it directly influences the\neffectiveness and timeliness of implementing remedial or preventive measures.\nThis task is often framed as a semi-supervised learning problem, where only\nnormal data are available for model training, primarily due to the\nlabor-intensive nature of data labeling and the scarcity of anomalous data.\nExisting semi-supervised methods often detect anomalies by capturing\nintra-variate temporal dependencies and/or inter-variate relationships to learn\nnormal patterns, flagging timestamps that deviate from these patterns as\nanomalies. However, these approaches often fail to capture salient\nintra-variate temporal and inter-variate dependencies in time series due to\ntheir focus on excessively fine granularity, leading to suboptimal performance.\nIn this study, we introduce MtsCID, a novel semi-supervised multivariate time\nseries anomaly detection method. MtsCID employs a dual network architecture:\none network operates on the attention maps of multi-scale intra-variate patches\nfor coarse-grained temporal dependency learning, while the other works on\nvariates to capture coarse-grained inter-variate relationships through\nconvolution and interaction with sinusoidal prototypes. This design enhances\nthe ability to capture the patterns from both intra-variate temporal\ndependencies and inter-variate relationships, resulting in improved\nperformance. Extensive experiments across seven widely used datasets\ndemonstrate that MtsCID achieves performance comparable or superior to\nstate-of-the-art benchmark methods.",
      "tldr_zh": "本研究针对多变量时间序列异常检测问题，提出了一种新颖的半监督方法 MtsCID，以解决现有方法因过度关注细粒度而未能有效捕获 intra-variate 时间依赖和 inter-variate 关系的局限性。MtsCID 采用双网络架构：一个网络通过多尺度 intra-variate patches 的注意力图进行粗粒度时间依赖学习，另一个网络则利用卷积和正弦原型交互来捕获粗粒度 inter-variate 关系，从而更准确地学习正常模式。实验结果显示，在七个常用数据集上，MtsCID 的性能与最先进基准方法相当或优于它们，为网络应用运维中的故障管理提供了更有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures, Accepted to TheWebConference 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16364v1",
      "published_date": "2025-01-22 05:53:12 UTC",
      "updated_date": "2025-01-22 05:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:08:36.913098"
    },
    {
      "arxiv_id": "2501.12651v1",
      "title": "The potential -- and the pitfalls -- of using pre-trained language models as cognitive science theories",
      "title_zh": "使用预训练语言模型作为认知科学理论的潜力——以及陷阱",
      "authors": [
        "Raj Sanjay Shah",
        "Sashank Varma"
      ],
      "abstract": "Many studies have evaluated the cognitive alignment of Pre-trained Language\nModels (PLMs), i.e., their correspondence to adult performance across a range\nof cognitive domains. Recently, the focus has expanded to the developmental\nalignment of these models: identifying phases during training where\nimprovements in model performance track improvements in children's thinking\nover development. However, there are many challenges to the use of PLMs as\ncognitive science theories, including different architectures, different\ntraining data modalities and scales, and limited model interpretability. In\nthis paper, we distill lessons learned from treating PLMs, not as engineering\nartifacts but as cognitive science and developmental science models. We review\nassumptions used by researchers to map measures of PLM performance to measures\nof human performance. We identify potential pitfalls of this approach to\nunderstanding human thinking, and we end by enumerating criteria for using PLMs\nas credible accounts of cognition and cognitive development.",
      "tldr_zh": "本研究探讨了使用预训练语言模型 (PLMs) 作为认知科学理论的潜力与挑战，包括模型与成人认知表现的对应关系，以及训练过程中性能改进是否追踪儿童认知发展的发育对齐。作者回顾了将 PLM 性能映射到人类性能的假设，并指出了潜在陷阱，如不同模型架构、训练数据模式和规模以及有限的可解释性。最终，论文总结了经验教训，并提出了使用 PLMs 作为可信认知和认知发展账户的标准，以指导未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12651v1",
      "published_date": "2025-01-22 05:24:23 UTC",
      "updated_date": "2025-01-22 05:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:08:48.550493"
    },
    {
      "arxiv_id": "2501.12640v1",
      "title": "Dynamics of Toxicity in Political Podcasts",
      "title_zh": "政治播客中的毒性动态",
      "authors": [
        "Naquee Rizwan",
        "Nayandeep Deb",
        "Sarthak Roy",
        "Vishwajeet Singh Solanki",
        "Kiran Garimella",
        "Animesh Mukherjee"
      ],
      "abstract": "Toxicity in digital media poses significant challenges, yet little attention\nhas been given to its dynamics within the rapidly growing medium of podcasts.\nThis paper addresses this gap by analyzing political podcast data to study the\nemergence and propagation of toxicity, focusing on conversation\nchains-structured reply patterns within podcast transcripts. Leveraging\nstate-of-the-art transcription models and advanced conversational analysis\ntechniques, we systematically examine toxic discourse in over 30 popular\npolitical podcasts in the United States. Our key contributions include: (1)\ncreating a comprehensive dataset of transcribed and diarized political\npodcasts, identifying thousands of toxic instances using Google's Perspective\nAPI, (2) uncovering concerning trends where a majority of episodes contain at\nleast one toxic instance, (3) introducing toxic conversation chains and\nanalyzing their structural and linguistic properties, revealing characteristics\nsuch as longer durations, repetitive patterns, figurative language, and\nemotional cues tied to anger and annoyance, (4) identifying demand-related\nwords like 'want', 'like', and 'know' as precursors to toxicity, and (5)\ndeveloping predictive models to anticipate toxicity shifts based on annotated\nchange points. Our findings provide critical insights into podcast toxicity and\nestablish a foundation for future research on real-time monitoring and\nintervention mechanisms to foster healthier discourse in this influential\nmedium.",
      "tldr_zh": "本研究探讨了政治播客中毒性（toxicity）的动态，分析其在对话链（conversation chains）中的产生和传播，以填补这一领域的空白。研究者利用先进的转录模型和对话分析技术，构建了一个包含30多个热门美国政治播客的全面数据集，并通过Google's Perspective API识别数千个毒性实例，发现大多数剧集至少包含一个毒性事件。关键发现包括毒性对话链的特征，如持续时间更长、重复模式、比喻语言和与愤怒相关的感情线索，以及词汇如'want'、'like'和'know'作为毒性的前兆；此外，开发了基于标注变化点的预测模型，为实时监控和干预机制提供基础，以促进更健康的播客话语。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12640v1",
      "published_date": "2025-01-22 04:58:50 UTC",
      "updated_date": "2025-01-22 04:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:09:00.864060"
    },
    {
      "arxiv_id": "2501.12633v1",
      "title": "Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors",
      "title_zh": "用于表征动物行为的带有切换奖励和历史依赖性的逆强化学习",
      "authors": [
        "Jingyang Ke",
        "Feiyang Wu",
        "Jiyi Wang",
        "Jeffrey Markowitz",
        "Anqi Wu"
      ],
      "abstract": "Traditional approaches to studying decision-making in neuroscience focus on\nsimplified behavioral tasks where animals perform repetitive, stereotyped\nactions to receive explicit rewards. While informative, these methods constrain\nour understanding of decision-making to short timescale behaviors driven by\nexplicit goals. In natural environments, animals exhibit more complex,\nlong-term behaviors driven by intrinsic motivations that are often\nunobservable. Recent works in time-varying inverse reinforcement learning (IRL)\naim to capture shifting motivations in long-term, freely moving behaviors.\nHowever, a crucial challenge remains: animals make decisions based on their\nhistory, not just their current state. To address this, we introduce SWIRL\n(SWitching IRL), a novel framework that extends traditional IRL by\nincorporating time-varying, history-dependent reward functions. SWIRL models\nlong behavioral sequences as transitions between short-term decision-making\nprocesses, each governed by a unique reward function. SWIRL incorporates\nbiologically plausible history dependency to capture how past decisions and\nenvironmental contexts shape behavior, offering a more accurate description of\nanimal decision-making. We apply SWIRL to simulated and real-world animal\nbehavior datasets and show that it outperforms models lacking history\ndependency, both quantitatively and qualitatively. This work presents the first\nIRL model to incorporate history-dependent policies and rewards to advance our\nunderstanding of complex, naturalistic decision-making in animals.",
      "tldr_zh": "本文提出SWIRL框架，一种扩展逆强化学习（IRL）的创新方法，通过引入时间变化的、历史依赖的奖励函数，来更好地表征动物在自然环境中的复杂决策行为。SWIRL将长行为序列建模为短期决策过程的切换，每个过程由独特奖励函数驱动，并融入生物学上合理的历史依赖因素，以捕捉过去决策和环境上下文对行为的影响。在模拟和真实动物行为数据集上，SWIRL在定量和定性方面均优于无历史依赖的模型，为理解自然决策提供新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12633v1",
      "published_date": "2025-01-22 04:38:33 UTC",
      "updated_date": "2025-01-22 04:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:09:13.302753"
    },
    {
      "arxiv_id": "2501.12622v1",
      "title": "Towards Robust Multi-tab Website Fingerprinting",
      "title_zh": "翻译失败",
      "authors": [
        "Xinhao Deng",
        "Xiyuan Zhao",
        "Qilei Yin",
        "Zhuotao Liu",
        "Qi Li",
        "Mingwei Xu",
        "Ke Xu",
        "Jianping Wu"
      ],
      "abstract": "Website fingerprinting enables an eavesdropper to determine which websites a\nuser is visiting over an encrypted connection. State-of-the-art website\nfingerprinting (WF) attacks have demonstrated effectiveness even against\nTor-protected network traffic. However, existing WF attacks have critical\nlimitations on accurately identifying websites in multi-tab browsing sessions,\nwhere the holistic pattern of individual websites is no longer preserved, and\nthe number of tabs opened by a client is unknown a priori. In this paper, we\npropose ARES, a novel WF framework natively designed for multi-tab WF attacks.\nARES formulates the multi-tab attack as a multi-label classification problem\nand solves it using the novel Transformer-based models. Specifically, ARES\nextracts local patterns based on multi-level traffic aggregation features and\nutilizes the improved self-attention mechanism to analyze the correlations\nbetween these local patterns, effectively identifying websites. We implement a\nprototype of ARES and extensively evaluate its effectiveness using our\nlarge-scale datasets collected over multiple months. The experimental results\nillustrate that ARES achieves optimal performance in several realistic\nscenarios. Further, ARES remains robust even against various WF defenses.",
      "tldr_zh": "该论文针对网站指纹识别(Website Fingerprinting)攻击在多标签浏览场景中的局限性，提出了一种新型框架ARES，以提升攻击的准确性和鲁棒性。ARES将多标签攻击表述为多标签分类问题，使用基于Transformer的模型提取多级流量聚合特征，并通过改进的自注意力机制分析局部模式之间的相关性，从而有效识别网站。实验结果表明，ARES在大型数据集上表现出最佳性能，并在各种现实场景和WF防御中保持强大鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12622v1",
      "published_date": "2025-01-22 04:10:53 UTC",
      "updated_date": "2025-01-22 04:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:09:25.395290"
    },
    {
      "arxiv_id": "2501.12620v1",
      "title": "Adaptive Data Exploitation in Deep Reinforcement Learning",
      "title_zh": "深度强化学习中的自适应数据利用",
      "authors": [
        "Mingqi Yuan",
        "Bo Li",
        "Xin Jin",
        "Wenjun Zeng"
      ],
      "abstract": "We introduce ADEPT: Adaptive Data ExPloiTation, a simple yet powerful\nframework to enhance the **data efficiency** and **generalization** in deep\nreinforcement learning (RL). Specifically, ADEPT adaptively manages the use of\nsampled data across different learning stages via multi-armed bandit (MAB)\nalgorithms, optimizing data utilization while mitigating overfitting. Moreover,\nADEPT can significantly reduce the computational overhead and accelerate a wide\nrange of RL algorithms. We test ADEPT on benchmarks including Procgen,\nMiniGrid, and PyBullet. Extensive simulation demonstrates that ADEPT can\nachieve superior performance with remarkable computational efficiency, offering\na practical solution to data-efficient RL. Our code is available at\nhttps://github.com/yuanmingqi/ADEPT.",
      "tldr_zh": "这篇论文引入了 ADEPT，一种简单而强大的框架，用于提升深度强化学习（deep reinforcement learning）中的数据效率（data efficiency）和泛化能力（generalization）。ADEPT 通过 multi-armed bandit 算法适应性地管理不同学习阶段的采样数据，优化数据利用并缓解 overfitting，从而显著减少计算开销并加速各种 RL 算法。在 Procgen、MiniGrid 和 PyBullet 等基准测试中，实验证明 ADEPT 实现了优越性能和计算效率，提供了一个实用的数据高效 RL 解决方案，并开源了代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages, 37 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12620v1",
      "published_date": "2025-01-22 04:01:17 UTC",
      "updated_date": "2025-01-22 04:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:09:37.342814"
    },
    {
      "arxiv_id": "2501.12617v1",
      "title": "Deep Learning-Based Identification of Inconsistent Method Names: How Far Are We?",
      "title_zh": "基于深度学习的识别不一致方法名称：我们走了多远？",
      "authors": [
        "Taiming Wang",
        "Yuxia Zhang",
        "Lin Jiang",
        "Yi Tang",
        "Guangjie Li",
        "Hui Liu"
      ],
      "abstract": "Concise and meaningful method names are crucial for program comprehension and\nmaintenance. However, method names may become inconsistent with their\ncorresponding implementations, causing confusion and errors. Several deep\nlearning (DL)-based approaches have been proposed to identify such\ninconsistencies, with initial evaluations showing promising results. However,\nthese evaluations typically use a balanced dataset, where the number of\ninconsistent and consistent names are equal. This setup, along with flawed\ndataset construction, leads to false positives, making reported performance\nless reliable in real-world scenarios, where most method names are consistent.\nIn this paper, we present an empirical study that evaluates state-of-the-art\nDL-based methods for identifying inconsistent method names. We create a new\nbenchmark by combining automatic identification from commit histories and\nmanual developer inspections, reducing false positives. We evaluate five\nrepresentative DL approaches (one retrieval-based and four generation-based) on\nthis benchmark. Our results show that performance drops substantially when\nmoving from the balanced dataset to the new benchmark. We further conduct\nquantitative and qualitative analyses to understand the strengths and\nweaknesses of the approaches. Retrieval-based methods perform well on simple\nmethods and those with popular name sub-tokens but fail due to inefficient\nrepresentation techniques. Generation-based methods struggle with inaccurate\nsimilarity calculations and immature name generation. Based on these findings,\nwe propose improvements using contrastive learning and large language models\n(LLMs). Our study suggests that significant improvements are needed before\nthese DL approaches can be effectively applied to real-world software systems.",
      "tldr_zh": "本文通过实证研究评估了基于深度学习(DL)的识别不一致方法名方法，揭示了现有方法在平衡数据集上的表现不可靠，因为现实中大多数方法名是一致的。研究者构建了一个新基准，结合提交历史和开发者检查来减少假阳性，并对五种代表性方法（一种基于检索的和四种基于生成的）进行了评估。结果显示，这些方法的性能在转向新基准时大幅下降，基于检索的方法在简单方法和流行名称子标记上表现较好，但受限于表示技术，而基于生成的方法则在相似性计算和名称生成上存在缺陷。基于这些发现，论文提出使用对比学习和大型语言模型(LLMs)进行改进，并指出这些DL方法在实际软件系统中应用前仍需显著优化。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12617v1",
      "published_date": "2025-01-22 03:51:56 UTC",
      "updated_date": "2025-01-22 03:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:09:50.045959"
    },
    {
      "arxiv_id": "2501.17171v1",
      "title": "Separated Inter/Intra-Modal Fusion Prompts for Compositional Zero-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sua Jung"
      ],
      "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize subtle differences\nin meaning or the combination of states and objects through the use of known\nand unknown concepts during training. Existing methods either focused on prompt\nconfiguration or on using prompts to tune the pre-trained Vision-Language\nmodel. However, these methods faced challenges in accurately identifying subtle\ndifferences in meaning or combining states with objects. To jointly eradicate\nthe above issues and construct an efficient and effective CZSL technique, we\nsuggest a method to improve attribute recognition performance by utilizing\ndiverse Prompt Learning with an Inter/Intra-Modality Fusion Synthesizer in\nscene understanding involving subtle semantic differences and multiple objects.",
      "tldr_zh": "本论文针对Compositional Zero-Shot Learning (CZSL)的问题，旨在通过已知和未知概念识别状态与对象的细微差异和组合，但现有方法在提示配置或调整预训练Vision-Language模型时无法准确处理这些挑战。论文提出一种新方法，利用多样化的Prompt Learning和Separated Inter/Intra-Modal Fusion Synthesizer来提升属性识别性能，尤其适用于涉及细微语义差异和多个对象的场景理解。该方法通过Inter/Intra-Modality融合优化提示学习，有效改善了CZSL的整体表现，为更高效的零样本学习提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "AIAP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.17171v1",
      "published_date": "2025-01-22 03:49:12 UTC",
      "updated_date": "2025-01-22 03:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:10:00.613762"
    },
    {
      "arxiv_id": "2501.12615v1",
      "title": "GATE: Adaptive Learning with Working Memory by Information Gating in Multi-lamellar Hippocampal Formation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuechen Liu",
        "Zishun Wang",
        "Chen Qiao",
        "Zongben Xu"
      ],
      "abstract": "Hippocampal formation (HF) can rapidly adapt to varied environments and build\nflexible working memory (WM). To mirror the HF's mechanism on generalization\nand WM, we propose a model named Generalization and Associative Temporary\nEncoding (GATE), which deploys a 3-D multi-lamellar dorsoventral (DV)\narchitecture, and learns to build up internally representation from externally\ndriven information layer-wisely. In each lamella, regions of HF:\nEC3-CA1-EC5-EC3 forms a re-entrant loop that discriminately maintains\ninformation by EC3 persistent activity, and selectively readouts the retained\ninformation by CA1 neurons. CA3 and EC5 further provides gating function that\ncontrols these processes. After learning complex WM tasks, GATE forms neuron\nrepresentations that align with experimental records, including splitter, lap,\nevidence, trace, delay-active cells, as well as conventional place cells.\nCrucially, DV architecture in GATE also captures information, range from\ndetailed to abstract, which enables a rapid generalization ability when cue,\nenvironment or task changes, with learned representations inherited. GATE\npromises a viable framework for understanding the HF's flexible memory\nmechanisms and for progressively developing brain-inspired intelligent systems.",
      "tldr_zh": "该论文提出GATE模型，模拟多层板状Hippocampal Formation（HF）的机制，实现快速适应和Working Memory（WM）的构建。GATE采用3-D多层dorsoventral架构，每个层通过EC3-CA1-EC5-EC3再入回路维持信息，并利用CA3和EC5的门控功能选择性读取数据。实验结果显示，GATE在学习复杂WM任务后，形成与实验记录一致的神经元表示，如splitter、lap和place cells，并支持快速泛化，即使环境或任务变化也能继承学到的表示，为理解HF的灵活记忆机制和开发脑启发智能系统提供框架。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12615v1",
      "published_date": "2025-01-22 03:41:35 UTC",
      "updated_date": "2025-01-22 03:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:10:14.109557"
    },
    {
      "arxiv_id": "2501.12599v2",
      "title": "Kimi k1.5: Scaling Reinforcement Learning with LLMs",
      "title_zh": "Kimi k1.5：利用大型语言模型扩展强化学习",
      "authors": [
        "Kimi Team",
        "Angang Du",
        "Bofei Gao",
        "Bowei Xing",
        "Changjiu Jiang",
        "Cheng Chen",
        "Cheng Li",
        "Chenjun Xiao",
        "Chenzhuang Du",
        "Chonghua Liao",
        "Chuning Tang",
        "Congcong Wang",
        "Dehao Zhang",
        "Enming Yuan",
        "Enzhe Lu",
        "Fengxiang Tang",
        "Flood Sung",
        "Guangda Wei",
        "Guokun Lai",
        "Haiqing Guo",
        "Han Zhu",
        "Hao Ding",
        "Hao Hu",
        "Hao Yang",
        "Hao Zhang",
        "Haotian Yao",
        "Haotian Zhao",
        "Haoyu Lu",
        "Haoze Li",
        "Haozhen Yu",
        "Hongcheng Gao",
        "Huabin Zheng",
        "Huan Yuan",
        "Jia Chen",
        "Jianhang Guo",
        "Jianlin Su",
        "Jianzhou Wang",
        "Jie Zhao",
        "Jin Zhang",
        "Jingyuan Liu",
        "Junjie Yan",
        "Junyan Wu",
        "Lidong Shi",
        "Ling Ye",
        "Longhui Yu",
        "Mengnan Dong",
        "Neo Zhang",
        "Ningchen Ma",
        "Qiwei Pan",
        "Qucheng Gong",
        "Shaowei Liu",
        "Shengling Ma",
        "Shupeng Wei",
        "Sihan Cao",
        "Siying Huang",
        "Tao Jiang",
        "Weihao Gao",
        "Weimin Xiong",
        "Weiran He",
        "Weixiao Huang",
        "Wenhao Wu",
        "Wenyang He",
        "Xianghui Wei",
        "Xianqing Jia",
        "Xingzhe Wu",
        "Xinran Xu",
        "Xinxing Zu",
        "Xinyu Zhou",
        "Xuehai Pan",
        "Y. Charles",
        "Yang Li",
        "Yangyang Hu",
        "Yangyang Liu",
        "Yanru Chen",
        "Yejie Wang",
        "Yibo Liu",
        "Yidao Qin",
        "Yifeng Liu",
        "Ying Yang",
        "Yiping Bao",
        "Yulun Du",
        "Yuxin Wu",
        "Yuzhi Wang",
        "Zaida Zhou",
        "Zhaoji Wang",
        "Zhaowei Li",
        "Zhen Zhu",
        "Zheng Zhang",
        "Zhexu Wang",
        "Zhilin Yang",
        "Zhiqi Huang",
        "Zihao Huang",
        "Ziyao Xu",
        "Zonghan Yang"
      ],
      "abstract": "Language model pretraining with next token prediction has proved effective\nfor scaling compute but is limited to the amount of available training data.\nScaling reinforcement learning (RL) unlocks a new axis for the continued\nimprovement of artificial intelligence, with the promise that large language\nmodels (LLMs) can scale their training data by learning to explore with\nrewards. However, prior published work has not produced competitive results. In\nlight of this, we report on the training practice of Kimi k1.5, our latest\nmulti-modal LLM trained with RL, including its RL training techniques,\nmulti-modal data recipes, and infrastructure optimization. Long context scaling\nand improved policy optimization methods are key ingredients of our approach,\nwhich establishes a simplistic, effective RL framework without relying on more\ncomplex techniques such as Monte Carlo tree search, value functions, and\nprocess reward models. Notably, our system achieves state-of-the-art reasoning\nperformance across multiple benchmarks and modalities -- e.g., 77.5 on AIME,\n96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista -- matching\nOpenAI's o1. Moreover, we present effective long2short methods that use\nlong-CoT techniques to improve short-CoT models, yielding state-of-the-art\nshort-CoT reasoning results -- e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on\nLiveCodeBench -- outperforming existing short-CoT models such as GPT-4o and\nClaude Sonnet 3.5 by a large margin (up to +550%).",
      "tldr_zh": "这篇论文介绍了Kimi k1.5，一种通过强化学习(RL)扩展大型语言模型(LLMs)的框架，以克服传统预训练数据限制的问题，并实现模型在奖励驱动下的持续改进。关键方法包括长上下文缩放、改进的政策优化技术，以及long2short方法，该方法利用长CoT（长链式思维）提升短CoT（短链式思维）模型的性能，而不依赖复杂技术如Monte Carlo树搜索。实验结果显示，Kimi k1.5在多个基准测试中达到最先进水平，例如AIME 77.5、MATH 500 96.2和Codeforces 94-th percentile，匹配OpenAI的o1，并在短CoT任务上大幅超越GPT-4o和Claude Sonnet 3.5（提升幅度高达550%）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.12599v2",
      "published_date": "2025-01-22 02:48:14 UTC",
      "updated_date": "2025-03-05 02:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:10:26.033991"
    },
    {
      "arxiv_id": "2501.12595v1",
      "title": "A Unified Invariant Learning Framework for Graph Classification",
      "title_zh": "统一的图分类不变学习框架",
      "authors": [
        "Yongduo Sui",
        "Jie Sun",
        "Shuyao Wang",
        "Zemin Liu",
        "Qing Cui",
        "Longfei Li",
        "Xiang Wang"
      ],
      "abstract": "Invariant learning demonstrates substantial potential for enhancing the\ngeneralization of graph neural networks (GNNs) with out-of-distribution (OOD)\ndata. It aims to recognize stable features in graph data for classification,\nbased on the premise that these features causally determine the target label,\nand their influence is invariant to changes in distribution. Along this line,\nmost studies have attempted to pinpoint these stable features by emphasizing\nexplicit substructures in the graph, such as masked or attentive subgraphs, and\nprimarily enforcing the invariance principle in the semantic space, i.e., graph\nrepresentations. However, we argue that focusing only on the semantic space may\nnot accurately identify these stable features. To address this, we introduce\nthe Unified Invariant Learning (UIL) framework for graph classification. It\nprovides a unified perspective on invariant graph learning, emphasizing both\nstructural and semantic invariance principles to identify more robust stable\nfeatures. In the graph space, UIL adheres to the structural invariance\nprinciple by reducing the distance between graphons over a set of stable\nfeatures across different environments. Simultaneously, to confirm semantic\ninvariance, UIL underscores that the acquired graph representations should\ndemonstrate exemplary performance across diverse environments. We present both\ntheoretical and empirical evidence to confirm our method's ability to recognize\nsuperior stable features. Moreover, through a series of comprehensive\nexperiments complemented by in-depth analyses, we demonstrate that UIL\nconsiderably enhances OOD generalization, surpassing the performance of leading\nbaseline methods. Our codes are available at https://github.com/yongduosui/UIL.",
      "tldr_zh": "这篇论文提出 Unified Invariant Learning (UIL) 框架，用于提升 Graph Neural Networks (GNNs) 在 Out-of-Distribution (OOD) 数据上的泛化能力，通过同时强调结构和语义不变性原则来识别更 robust 的稳定特征。UIL 在图空间中通过减少不同环境下稳定特征集的 graphons 距离实现结构不变性，同时确保图表示在多环境中的语义性能表现出色。作者提供了理论和实证证据，证明 UIL 能有效识别优越的稳定特征，并在全面实验中显著超越基线方法，增强 OOD 泛化性能。代码已开源于 https://github.com/yongduosui/UIL。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12595v1",
      "published_date": "2025-01-22 02:45:21 UTC",
      "updated_date": "2025-01-22 02:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:10:38.471720"
    },
    {
      "arxiv_id": "2501.13132v1",
      "title": "A Hierarchical Reinforcement Learning Framework for Multi-UAV Combat Using Leader-Follower Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhui Pang",
        "Jinglin He",
        "Noureldin Mohamed Abdelaal Ahmed Mohamed",
        "Changqing Lin",
        "Zhihui Zhang",
        "Xiaoshuai Hao"
      ],
      "abstract": "Multi-UAV air combat is a complex task involving multiple autonomous UAVs, an\nevolving field in both aerospace and artificial intelligence. This paper aims\nto enhance adversarial performance through collaborative strategies. Previous\napproaches predominantly discretize the action space into predefined actions,\nlimiting UAV maneuverability and complex strategy implementation. Others\nsimplify the problem to 1v1 combat, neglecting the cooperative dynamics among\nmultiple UAVs. To address the high-dimensional challenges inherent in\nsix-degree-of-freedom space and improve cooperation, we propose a hierarchical\nframework utilizing the Leader-Follower Multi-Agent Proximal Policy\nOptimization (LFMAPPO) strategy. Specifically, the framework is structured into\nthree levels. The top level conducts a macro-level assessment of the\nenvironment and guides execution policy. The middle level determines the angle\nof the desired action. The bottom level generates precise action commands for\nthe high-dimensional action space. Moreover, we optimize the state-value\nfunctions by assigning distinct roles with the leader-follower strategy to\ntrain the top-level policy, followers estimate the leader's utility, promoting\neffective cooperation among agents. Additionally, the incorporation of a target\nselector, aligned with the UAVs' posture, assesses the threat level of targets.\nFinally, simulation experiments validate the effectiveness of our proposed\nmethod.",
      "tldr_zh": "本论文提出一个分层强化学习框架，用于多UAV（Multi-UAV）空中作战，采用Leader-Follower策略来解决现有方法在高维动作空间和合作动态方面的局限性。该框架分为三层：顶层进行环境宏观评估和执行策略指导，中层确定期望动作角度，底层生成精确的高维动作命令。同时，通过Leader-Follower Multi-Agent Proximal Policy Optimization (LFMAPPO) 算法分配角色，优化状态值函数并促进代理间合作，并引入目标选择器根据UAV姿态评估目标威胁水平。模拟实验验证了该方法的有效性，提升了多UAV作战的整体性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13132v1",
      "published_date": "2025-01-22 02:41:36 UTC",
      "updated_date": "2025-01-22 02:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:10:50.482913"
    },
    {
      "arxiv_id": "2503.15501v1",
      "title": "Development of an Inclusive Educational Platform Using Open Technologies and Machine Learning: A Case Study on Accessibility Enhancement",
      "title_zh": "使用开源技术和机器学习开发包容性教育平台：一个关于可访问性增强的案例研究",
      "authors": [
        "Jimi Togni"
      ],
      "abstract": "This study addresses the pressing challenge of educational inclusion for\nstudents with special needs by proposing and developing an inclusive\neducational platform. Integrating machine learning, natural language\nprocessing, and cross-platform interfaces, the platform features key\nfunctionalities such as speech recognition functionality to support voice\ncommands and text generation via voice input; real-time object recognition\nusing the YOLOv5 model, adapted for educational environments;\nGrapheme-to-Phoneme (G2P) conversion for Text-to-Speech systems using seq2seq\nmodels with attention, ensuring natural and fluent voice synthesis; and the\ndevelopment of a cross-platform mobile application in Flutter with on-device\ninference execution using TensorFlow Lite. The results demonstrated high\naccuracy, usability, and positive impact in educational scenarios, validating\nthe proposal as an effective tool for educational inclusion. This project\nunderscores the importance of open and accessible technologies in promoting\ninclusive and quality education.",
      "tldr_zh": "本研究针对特殊需求学生的教育包容性问题，开发了一个基于开放技术和机器学习的包容性教育平台，作为提升可访问性的案例研究。平台整合了语音识别功能、自然语言处理（如Grapheme-to-Phoneme (G2P)转换使用seq2seq模型带注意力机制的Text-to-Speech系统）、实时物体识别（采用YOLOv5模型适应教育环境），以及使用Flutter开发并通过TensorFlow Lite实现设备端推理的跨平台移动应用。结果显示该平台在准确性、可用性和教育影响方面表现出色，有效验证了其作为教育包容工具的价值，并强调了开放技术在促进高质量包容教育中的重要性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "68T50",
        "I.2.7; D.2.3"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.15501v1",
      "published_date": "2025-01-22 02:38:23 UTC",
      "updated_date": "2025-01-22 02:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:11:02.198837"
    },
    {
      "arxiv_id": "2501.12592v2",
      "title": "FedGrAINS: Personalized SubGraph Federated Learning with Adaptive Neighbor Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Emir Ceyani",
        "Han Xie",
        "Baturalp Buyukates",
        "Carl Yang",
        "Salman Avestimehr"
      ],
      "abstract": "Graphs are crucial for modeling relational and biological data. As datasets\ngrow larger in real-world scenarios, the risk of exposing sensitive information\nincreases, making privacy-preserving training methods like federated learning\n(FL) essential to ensure data security and compliance with privacy regulations.\nRecently proposed personalized subgraph FL methods have become the de-facto\nstandard for training personalized Graph Neural Networks (GNNs) in a federated\nmanner while dealing with the missing links across clients' subgraphs due to\nprivacy restrictions. However, personalized subgraph FL faces significant\nchallenges due to the heterogeneity in client subgraphs, such as degree\ndistributions among the nodes, which complicate federated training of graph\nmodels. To address these challenges, we propose \\textit{FedGrAINS}, a novel\ndata-adaptive and sampling-based regularization method for subgraph FL.\nFedGrAINS leverages generative flow networks (GFlowNets) to evaluate node\nimportance concerning clients' tasks, dynamically adjusting the message-passing\nstep in clients' GNNs. This adaptation reflects task-optimized sampling aligned\nwith a trajectory balance objective. Experimental results demonstrate that the\ninclusion of \\textit{FedGrAINS} as a regularizer consistently improves the FL\nperformance compared to baselines that do not leverage such regularization.",
      "tldr_zh": "该论文提出FedGrAINS，一种针对个性化子图联邦学习(FL)的创新方法，通过自适应邻居采样解决子图异质性挑战，如节点度分布差异，以保护隐私并提升图神经网络(GNNs)训练效率。FedGrAINS利用生成流网络(GFlowNets)评估节点重要性，并动态调整GNNs中的消息传递步骤，以实现基于轨迹平衡目标的任务优化采样。实验结果表明，添加FedGrAINS作为正则化器后，FL性能比基线模型一致提升，为隐私保护的图数据建模提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to SDM2025 (SIAM Data Mining 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.12592v2",
      "published_date": "2025-01-22 02:35:20 UTC",
      "updated_date": "2025-01-23 13:03:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:11:13.787111"
    },
    {
      "arxiv_id": "2501.12573v1",
      "title": "Leveraging LLMs to Create a Haptic Devices' Recommendation System",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Haiwei Dong",
        "Abdulmotaleb El Saddik"
      ],
      "abstract": "Haptic technology has seen significant growth, yet a lack of awareness of\nexisting haptic device design knowledge hinders development. This paper\naddresses these limitations by leveraging advancements in Large Language Models\n(LLMs) to develop a haptic agent, focusing specifically on Grounded Force\nFeedback (GFF) devices recommendation. Our approach involves automating the\ncreation of a structured haptic device database using information from research\npapers and product specifications. This database enables the recommendation of\nrelevant GFF devices based on user queries. To ensure precise and contextually\nrelevant recommendations, the system employs a dynamic retrieval method that\ncombines both conditional and semantic searches. Benchmarking against the\nestablished UEQ and existing haptic device searching tools, the proposed haptic\nrecommendation agent ranks in the top 10\\% across all UEQ categories with mean\ndifferences favoring the agent in nearly all subscales, and maintains no\nsignificant performance bias across different user groups, showcasing superior\nusability and user satisfaction.",
      "tldr_zh": "本文利用大型语言模型(LLMs)开发了一个触觉设备推荐系统，专注于Grounded Force Feedback (GFF)设备，以解决触觉技术(Haptic technology)领域知识不足的问题。主要方法包括自动化构建结构化的触觉设备数据库，通过研究论文和产品规格信息，并采用动态检索结合条件和语义搜索，确保推荐的精确性和相关性。该系统在UEQ基准测试中排名前10%，在几乎所有子量表中表现出显著优势，且在不同用户群体间无性能偏差，展示了优越的可用性和用户满意度。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12573v1",
      "published_date": "2025-01-22 01:41:05 UTC",
      "updated_date": "2025-01-22 01:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:11:24.917848"
    },
    {
      "arxiv_id": "2501.12557v1",
      "title": "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review",
      "title_zh": "翻译失败",
      "authors": [
        "Rock Yuren Pang",
        "Hope Schroeder",
        "Kynnedy Simone Smith",
        "Solon Barocas",
        "Ziang Xiao",
        "Emily Tseng",
        "Danielle Bragg"
      ],
      "abstract": "Large language models (LLMs) have been positioned to revolutionize HCI, by\nreshaping not only the interfaces, design patterns, and sociotechnical systems\nthat we study, but also the research practices we use. To-date, however, there\nhas been little understanding of LLMs' uptake in HCI. We address this gap via a\nsystematic literature review of 153 CHI papers from 2020-24 that engage with\nLLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in\nHCI projects; (3) contribution types; and (4) acknowledged limitations and\nrisks. We find LLM work in 10 diverse domains, primarily via empirical and\nartifact contributions. Authors use LLMs in five distinct roles, including as\nresearch tools or simulated users. Still, authors often raise validity and\nreproducibility concerns, and overwhelmingly study closed models. We outline\nopportunities to improve HCI research with and on LLMs, and provide guiding\nquestions for researchers to consider the validity and appropriateness of\nLLM-related work.",
      "tldr_zh": "本研究通过对2020-24年间153篇CHI论文的系统文献综述，探讨了大型语言模型(LLMs)在人机交互(HCI)领域的影响，包括LLMs的应用领域、角色、贡献类型以及潜在限制和风险。研究发现，LLMs被应用于10个多样领域，主要通过经验和人工制品贡献，并扮演五种角色，如研究工具或模拟用户；然而，作者常提及有效性、再现性问题，且主要聚焦封闭模型。论文总结了改进HCI研究的机会，并提供指导问题，帮助研究者评估LLM相关工作的有效性和适当性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "This is a preprint version of the paper conditionally accepted to\n  CHI'25",
      "pdf_url": "http://arxiv.org/pdf/2501.12557v1",
      "published_date": "2025-01-22 00:31:51 UTC",
      "updated_date": "2025-01-22 00:31:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:11:37.572598"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 85,
  "processed_papers_count": 85,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T02:11:52.934733"
}